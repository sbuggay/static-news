<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1714986073264" as="style"/><link rel="stylesheet" href="styles.css?v=1714986073264"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://arxiv.org/abs/2401.17377">Infini-Gram: Scaling unbounded n-gram language models to a trillion tokens</a> <span class="domain">(<a href="https://arxiv.org">arxiv.org</a>)</span></div><div class="subtext"><span>nsagent</span> | <span>43 comments</span></div><br/><div><div id="40267719" class="c"><input type="checkbox" id="c-40267719" checked=""/><div class="controls bullet"><span class="by">kmeisthax</span><span>|</span><a href="#40268196">next</a><span>|</span><label class="collapse" for="c-40267719">[-]</label><label class="expand" for="c-40267719">[14 more]</label></div><br/><div class="children"><div class="content">My current mental model of LLMs is that attention refines information from the input (e.g. &quot;red balloon&quot; becomes some vector that means red + balloon), and that the feed-forward layers are lossy compressed indexes into the training set.<p>From the paper, having a better n-gram index is giving as much perplexity improvement as a 10x increase in parameters. I wonder if it would make sense to train new foundation models with more attention heads and use infinigram in lieu of the feed-forward layer.</div><br/><div id="40268067" class="c"><input type="checkbox" id="c-40268067" checked=""/><div class="controls bullet"><span class="by">sigmoid10</span><span>|</span><a href="#40267719">parent</a><span>|</span><a href="#40268196">next</a><span>|</span><label class="collapse" for="c-40268067">[-]</label><label class="expand" for="c-40268067">[13 more]</label></div><br/><div class="children"><div class="content">Attention just allows the model to attend to elements across the input sequence. The feed forward is what gives it (and basically all other architectures) its universal function abilities. The only reason why we don&#x27;t use dense layers directly across the input sequence and instead go for things like convolution, recursion or transformers, is because that is prohibitively expensive computationally. But replacing the dense layer with n-grams would make LLMs exactly what so many people falsely believe them to be right now: Pure stochastic parrots instead of functions that can actually learn to generalize from examples.</div><br/><div id="40269430" class="c"><input type="checkbox" id="c-40269430" checked=""/><div class="controls bullet"><span class="by">Chrupiter</span><span>|</span><a href="#40267719">root</a><span>|</span><a href="#40268067">parent</a><span>|</span><a href="#40268196">next</a><span>|</span><label class="collapse" for="c-40269430">[-]</label><label class="expand" for="c-40269430">[12 more]</label></div><br/><div class="children"><div class="content">Aren&#x27;t human stochastic parrots in the end? I mean, when we &quot;learn&quot;, don&#x27;t we model our internal stochastic functions? Whether it is walking, learning a language, or anything else.</div><br/><div id="40271349" class="c"><input type="checkbox" id="c-40271349" checked=""/><div class="controls bullet"><span class="by">jillesvangurp</span><span>|</span><a href="#40267719">root</a><span>|</span><a href="#40269430">parent</a><span>|</span><a href="#40270820">next</a><span>|</span><label class="collapse" for="c-40271349">[-]</label><label class="expand" for="c-40271349">[2 more]</label></div><br/><div class="children"><div class="content">If you&#x27;ve ever had a conversation with a toddler, they do sound a bit like stochastic parrots. It takes us a while to be able to talk coherently. The learning process in schools involves a lot of repetition. From learning the abc to mastering calculus.</div><br/><div id="40271929" class="c"><input type="checkbox" id="c-40271929" checked=""/><div class="controls bullet"><span class="by">sigmoid10</span><span>|</span><a href="#40267719">root</a><span>|</span><a href="#40271349">parent</a><span>|</span><a href="#40270820">next</a><span>|</span><label class="collapse" for="c-40271929">[-]</label><label class="expand" for="c-40271929">[1 more]</label></div><br/><div class="children"><div class="content">Toddlers are just learning the building blocks of language. You could make the same statement about any new skill. However, at some point, most humans gain the ability to take two concepts they have heard about before and create a third concept that they have never encountered. You can also get that with artificial neural networks, but it is fundamentally impossible with n-grams.</div><br/></div></div></div></div><div id="40270820" class="c"><input type="checkbox" id="c-40270820" checked=""/><div class="controls bullet"><span class="by">imtringued</span><span>|</span><a href="#40267719">root</a><span>|</span><a href="#40269430">parent</a><span>|</span><a href="#40271349">prev</a><span>|</span><a href="#40269523">next</a><span>|</span><label class="collapse" for="c-40270820">[-]</label><label class="expand" for="c-40270820">[3 more]</label></div><br/><div class="children"><div class="content">If I asked you what 5+3+9 is, then you wouldn&#x27;t be allowed to calculate the intermediate values inside your head. Is it really that hard to believe that humans have internal thoughts and that they think before they speak? Is it really such a revelation that I have to remind you of it?</div><br/><div id="40270873" class="c"><input type="checkbox" id="c-40270873" checked=""/><div class="controls bullet"><span class="by">knome</span><span>|</span><a href="#40267719">root</a><span>|</span><a href="#40270820">parent</a><span>|</span><a href="#40269523">next</a><span>|</span><label class="collapse" for="c-40270873">[-]</label><label class="expand" for="c-40270873">[2 more]</label></div><br/><div class="children"><div class="content">Creating a small group of bot &#x27;personalities&#x27; that have an internal dialog, generating and sharing intermediate values before coming to a consensus and issuing a response to a user is trivial. I did it in my earliest experiments with GPT-3<p>You could use the same framework to generate an internal dialog for a bot.<p>A lot of people don&#x27;t think before they speak. If you tell me you have a small conversation with yourself before each thing you say out loud during a conversation, I will have doubts. Quick wit and fast paced conversation do not leave time for any real internal narration, just &quot;stream of consciousness&quot;.<p>There is a time for carefully choosing and reflecting on your words, surely, but there are many times staying in tune with a real time conversation takes precedence.</div><br/><div id="40272591" class="c"><input type="checkbox" id="c-40272591" checked=""/><div class="controls bullet"><span class="by">littlestymaar</span><span>|</span><a href="#40267719">root</a><span>|</span><a href="#40270873">parent</a><span>|</span><a href="#40269523">next</a><span>|</span><label class="collapse" for="c-40272591">[-]</label><label class="expand" for="c-40272591">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Creating a small group of bot &#x27;personalities&#x27; that have an internal dialog, generating and sharing intermediate values before coming to a consensus and issuing a response to a user is trivial. I did it in my earliest experiments with GPT-3<p>&gt; You could use the same framework to generate an internal dialog for a bot.<p>We can, for sure. But will it works? Given my (admittedly limited) experience with feeding LLM-generated stuff back in the LLM, I&#x27;d suspect it may actually lower the output quality. But maybe fine-tuning for this specific work-case could be a solution to this problem, as I suspect the instruction-tuning to be a culprit in the poor behavior I&#x27;ve witnessed (the bots have been instruction-tuned to believe the human, and apologize if you tell them they&#x27;ve made mistakes for instance, even if they were right in the first place, so this blind trust is likely polluting the results).</div><br/></div></div></div></div></div></div><div id="40269523" class="c"><input type="checkbox" id="c-40269523" checked=""/><div class="controls bullet"><span class="by">fnordpiglet</span><span>|</span><a href="#40267719">root</a><span>|</span><a href="#40269430">parent</a><span>|</span><a href="#40270820">prev</a><span>|</span><a href="#40268196">next</a><span>|</span><label class="collapse" for="c-40269523">[-]</label><label class="expand" for="c-40269523">[6 more]</label></div><br/><div class="children"><div class="content">No, because we are able to extrapolate from our experience. The ability to synthesize something coherent that doesn’t map directly into our training set is a major difference between human intelligence and what we call AI today.</div><br/><div id="40269766" class="c"><input type="checkbox" id="c-40269766" checked=""/><div class="controls bullet"><span class="by">alexeldeib</span><span>|</span><a href="#40267719">root</a><span>|</span><a href="#40269523">parent</a><span>|</span><a href="#40272289">next</a><span>|</span><label class="collapse" for="c-40269766">[-]</label><label class="expand" for="c-40269766">[2 more]</label></div><br/><div class="children"><div class="content">Isn’t there an argument we’re simply better at brain statistics and modeling than current AI? Forget architectural limitations. What is the nature of the extrapolation? How do individuals balance their experiences and determine likely outcomes?</div><br/><div id="40272057" class="c"><input type="checkbox" id="c-40272057" checked=""/><div class="controls bullet"><span class="by">fnordpiglet</span><span>|</span><a href="#40267719">root</a><span>|</span><a href="#40269766">parent</a><span>|</span><a href="#40272289">next</a><span>|</span><label class="collapse" for="c-40272057">[-]</label><label class="expand" for="c-40272057">[1 more]</label></div><br/><div class="children"><div class="content">Maybe! But even so there’s facilities AI lack that are more capability based than model based. For instance we demonstrate agency, we can simulate things in our mind alone, such as arriving at Maxwells Equations, or general relativity, or any number of other profound insights that aren’t based on our training data but are an extrapolation through our mind into domains we’ve no experience with and arrive at profound insights never conceived of before. Statistical models generally aren’t able to do this - they’re reflections of their training set, even if very complex ones. The human mind can create its own training set and that’s a remarkable capability.</div><br/></div></div></div></div><div id="40272289" class="c"><input type="checkbox" id="c-40272289" checked=""/><div class="controls bullet"><span class="by">Der_Einzige</span><span>|</span><a href="#40267719">root</a><span>|</span><a href="#40269523">parent</a><span>|</span><a href="#40269766">prev</a><span>|</span><a href="#40270435">next</a><span>|</span><label class="collapse" for="c-40272289">[-]</label><label class="expand" for="c-40272289">[1 more]</label></div><br/><div class="children"><div class="content">The overwhelming majority of human advancements is interpolation. Extrapolation is rare and we tend to only realize something was extrapolation after the fact.</div><br/></div></div><div id="40270435" class="c"><input type="checkbox" id="c-40270435" checked=""/><div class="controls bullet"><span class="by">strangescript</span><span>|</span><a href="#40267719">root</a><span>|</span><a href="#40269523">parent</a><span>|</span><a href="#40272289">prev</a><span>|</span><a href="#40268196">next</a><span>|</span><label class="collapse" for="c-40270435">[-]</label><label class="expand" for="c-40270435">[2 more]</label></div><br/><div class="children"><div class="content">&quot;extrapolate from our experience&quot;
&quot;synthesize something coherent&quot;<p>These are non-scientific concepts. You are basically saying &quot;humans are doing something more, but we can&#x27;t really explain it&quot;.<p>That assumption is getting weaker by the day. Our entire existence is a single, linear, time sequence data set. Am I &quot;extrapolating from my experience&quot; when I decide to scratch my head? No, I got a sequential data point of an &quot;itch&quot; and my reward programming has learned to output &quot;scratch&quot;.</div><br/><div id="40271900" class="c"><input type="checkbox" id="c-40271900" checked=""/><div class="controls bullet"><span class="by">fnordpiglet</span><span>|</span><a href="#40267719">root</a><span>|</span><a href="#40270435">parent</a><span>|</span><a href="#40268196">next</a><span>|</span><label class="collapse" for="c-40271900">[-]</label><label class="expand" for="c-40271900">[1 more]</label></div><br/><div class="children"><div class="content">Are you saying the discovery of relativity happened because Einstein was reacting to some reward &#x2F; stimulus in his environment?  Galois’ discoveries were a stochastic parrot regurgitating stimulus from his life?<p>There are known faculties humans have that LLMs especially do not, such as actual memory, the ability to simulate the world independently via the imagination and structured thought, as well as facilities we don’t really understand but AIs definitely don’t have which are the source of our fundamental agency. We are absolutely able to create thought and reasoning without direct stimulus or as a response to something in the environment - and it’s frankly bizarre a human being can believe they’ve never done something as a reaction to their internal state rather than extrinsic.<p>LLMs literally can not “do” anything that isn’t predicated on their training set.  This means, more or less, they can only interpolate within their populated vector space. The emergent properties are astounding and they absolutely demonstrate what appears to be some form of pseudo abductive reasoning which is powerful. I think it’s probably the most important advance of computing in the last 30 years. But people have confused a remarkable capability for a human like capability, and have simultaneously missed the importance of the advance as well as inexplicably diminished the remarkable capabilities of the human mind. It’s possible with more research we will bridge the gaps, and I’m not appealing to magic of the soul here.<p>But the human mind has a remarkable ability to reason, synthesize, extrapolate beyond their experience, and those are all things LLMs fundamentally - from a rigorous mathematical basis - can not do and will never do alone.  Any thing that bridges that will need an ensemble of AI and classical computing techniques - and maybe LLMs will be a core part of a part of something even more amazing. But we aren’t there yet and I’ve not seen a roadmap that takes us there.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="40268196" class="c"><input type="checkbox" id="c-40268196" checked=""/><div class="controls bullet"><span class="by">matt4711</span><span>|</span><a href="#40267719">prev</a><span>|</span><a href="#40272051">next</a><span>|</span><label class="collapse" for="c-40268196">[-]</label><label class="expand" for="c-40268196">[3 more]</label></div><br/><div class="children"><div class="content">A paper [1] we wrote in 2015 (cited by the authors) uses some more sophisticated data structures (compressed suffix trees) and Kneser–Ney smoothing to get the same &quot;unlimited&quot; context. I imagine with better smoothing and the same larger corpus sizes as the authors use this could improve on some of the results the authors provide.<p>Back then neural LMs were just beginning to emerge and we briefly experimented with using one of these unlimited N-gram models for pre-training but never got any results.<p>[1] <a href="https:&#x2F;&#x2F;aclanthology.org&#x2F;D15-1288.pdf" rel="nofollow">https:&#x2F;&#x2F;aclanthology.org&#x2F;D15-1288.pdf</a></div><br/><div id="40268699" class="c"><input type="checkbox" id="c-40268699" checked=""/><div class="controls bullet"><span class="by">inciampati</span><span>|</span><a href="#40268196">parent</a><span>|</span><a href="#40272051">next</a><span>|</span><label class="collapse" for="c-40268699">[-]</label><label class="expand" for="c-40268699">[2 more]</label></div><br/><div class="children"><div class="content">The formulation of a succinct full text index as an &quot;infinite n-gram model&quot; is both genius in connecting with the ML literature, but also blind-eye, in that it ignores all the work on using exactly this data structure (well, the FM-index) over DNA. bwa mem is the OG ∞-gram aligner.</div><br/><div id="40270182" class="c"><input type="checkbox" id="c-40270182" checked=""/><div class="controls bullet"><span class="by">jltsiren</span><span>|</span><a href="#40268196">root</a><span>|</span><a href="#40268699">parent</a><span>|</span><a href="#40272051">next</a><span>|</span><label class="collapse" for="c-40270182">[-]</label><label class="expand" for="c-40270182">[1 more]</label></div><br/><div class="children"><div class="content">The idea is far older than BWA. The entire point of the Burrows-Wheeler transform is to create a compact order-k &quot;language model&quot; for every value of k simultaneously. And then use that for data compression.<p>David Wheeler reportedly had the idea in the early 80s, but he rejected it as impractical. Then he tried publishing it with Michael Burrows in the early 90s, but it was rejected from the Data Compression Conference. Algorithms researchers found the BWT more interesting than data compression researchers, especially after the discovery of the FM-index in 2000. There was a lot of theoretical work done in the 2000s, and the paper mentioned by GP cites some of that.<p>The primary application imagined for the FM-index was usually information retrieval, mostly due to the people involved. But some people considered using it for DNA sequences and started focusing on efficient construction and approximate pattern matching instead of better compression. And when sequencing technology advanced to the point where BWT-based aligners became relevant, a few of them were published almost simultaneously.<p>And if you ask Heng Li, he gives credit to Tak-Wah Lam: <a href="https:&#x2F;&#x2F;lh3.github.io&#x2F;2024&#x2F;04&#x2F;12&#x2F;where-did-bwa-come-from" rel="nofollow">https:&#x2F;&#x2F;lh3.github.io&#x2F;2024&#x2F;04&#x2F;12&#x2F;where-did-bwa-come-from</a></div><br/></div></div></div></div></div></div><div id="40272051" class="c"><input type="checkbox" id="c-40272051" checked=""/><div class="controls bullet"><span class="by">thesz</span><span>|</span><a href="#40268196">prev</a><span>|</span><a href="#40267471">next</a><span>|</span><label class="collapse" for="c-40272051">[-]</label><label class="expand" for="c-40272051">[1 more]</label></div><br/><div class="children"><div class="content">The paper does not cite [1], which describes prediction by partial match algorithm with unbounded context length.<p>[1] <a href="https:&#x2F;&#x2F;www.researchgate.net&#x2F;publication&#x2F;2473004_Unbounded_Length_Contexts_for_PPM" rel="nofollow">https:&#x2F;&#x2F;www.researchgate.net&#x2F;publication&#x2F;2473004_Unbounded_L...</a><p>That is from 2003 and actually quite interesting. It shows, for example, that these models were applied to rather small texts, because of the presence of context with length of -1 (uniform distribution). When text is large the need for such context vanishes, but for small texts it can give an advantage.</div><br/></div></div><div id="40267471" class="c"><input type="checkbox" id="c-40267471" checked=""/><div class="controls bullet"><span class="by">Genbox</span><span>|</span><a href="#40272051">prev</a><span>|</span><a href="#40268504">next</a><span>|</span><label class="collapse" for="c-40267471">[-]</label><label class="expand" for="c-40267471">[1 more]</label></div><br/><div class="children"><div class="content">A web interface for the Infini-gram engine can be found here: <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;liujch1998&#x2F;infini-gram" rel="nofollow">https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;liujch1998&#x2F;infini-gram</a></div><br/></div></div><div id="40268504" class="c"><input type="checkbox" id="c-40268504" checked=""/><div class="controls bullet"><span class="by">snats</span><span>|</span><a href="#40267471">prev</a><span>|</span><a href="#40268025">next</a><span>|</span><label class="collapse" for="c-40268504">[-]</label><label class="expand" for="c-40268504">[2 more]</label></div><br/><div class="children"><div class="content">I recently wrote a writeup on bigrams and the infinigram outputs[1]. I genuinely believe that ngrams are making a comeback. For query searching it&#x27;s really good.<p>[1] <a href="https:&#x2F;&#x2F;snats.xyz&#x2F;pages&#x2F;articles&#x2F;from_bigram_to_infinigram.html" rel="nofollow">https:&#x2F;&#x2F;snats.xyz&#x2F;pages&#x2F;articles&#x2F;from_bigram_to_infinigram.h...</a></div><br/><div id="40271817" class="c"><input type="checkbox" id="c-40271817" checked=""/><div class="controls bullet"><span class="by">tarasglek</span><span>|</span><a href="#40268504">parent</a><span>|</span><a href="#40268025">next</a><span>|</span><label class="collapse" for="c-40271817">[-]</label><label class="expand" for="c-40271817">[1 more]</label></div><br/><div class="children"><div class="content">Would love to follow your blog but no rss</div><br/></div></div></div></div><div id="40268025" class="c"><input type="checkbox" id="c-40268025" checked=""/><div class="controls bullet"><span class="by">tgv</span><span>|</span><a href="#40268504">prev</a><span>|</span><a href="#40268273">next</a><span>|</span><label class="collapse" for="c-40268025">[-]</label><label class="expand" for="c-40268025">[3 more]</label></div><br/><div class="children"><div class="content">What this shows, IMO, is that quite a lot of the expected output is almost literally present in the training data.</div><br/><div id="40268664" class="c"><input type="checkbox" id="c-40268664" checked=""/><div class="controls bullet"><span class="by">flawsofar</span><span>|</span><a href="#40268025">parent</a><span>|</span><a href="#40268273">next</a><span>|</span><label class="collapse" for="c-40268664">[-]</label><label class="expand" for="c-40268664">[2 more]</label></div><br/><div class="children"><div class="content">Phrases and ideas repeat, because the universe has patterns and structure.</div><br/><div id="40271785" class="c"><input type="checkbox" id="c-40271785" checked=""/><div class="controls bullet"><span class="by">tgv</span><span>|</span><a href="#40268025">root</a><span>|</span><a href="#40268664">parent</a><span>|</span><a href="#40268273">next</a><span>|</span><label class="collapse" for="c-40271785">[-]</label><label class="expand" for="c-40271785">[1 more]</label></div><br/><div class="children"><div class="content">But it also suggests that the neural networks are not the miracle as some proclaim. They get their knowledge from compressing a very large amount of text, but add little in terms of inference. Its success is then a function of its size, but that size cannot grow much. It also ties in with the idea that the current ANNs don&#x27;t discriminate text, and repeat bad input as readily as anything else.</div><br/></div></div></div></div></div></div><div id="40268273" class="c"><input type="checkbox" id="c-40268273" checked=""/><div class="controls bullet"><span class="by">drdeca</span><span>|</span><a href="#40268025">prev</a><span>|</span><a href="#40269850">next</a><span>|</span><label class="collapse" for="c-40268273">[-]</label><label class="expand" for="c-40268273">[1 more]</label></div><br/><div class="children"><div class="content">A few thoughts this brings to mind:<p>1) this reminds me of how I was thinking about “what if you tried to modify an n-gram model to incorporate a poor-man’s approximation of the copying heads found in transformer models? (one which is also based just on counting)”<p>2) What if you trained a model to, given a sequence of tokens, predict how many times that sequence of tokens appeared in the training set? And&#x2F;or trained a model to, given a sequence of tokens, predict the length of longest suffix of it which appears in the training set. Could this be done in a way that gave a good approximation to the actual counts, while being substantially smaller? (Though, of course, this would fail to have the attribution property that they mentioned.)<p>3) It surprised me that they just always use the largest n such that there  is a sample in the training set. My thought would have been to combine the different choices of n with some weighting.<p>Like, if you have one example in the training set of “a b c d”, and a million examples of “b c e”, and only one or two other examples of “b c d”  other than the single instance of “a b c d”, 
does increasing the number of samples of “b c e” (which aren’t preceded by “a”) really give no weight towards “e” rather than “d” for the next token?</div><br/></div></div><div id="40269850" class="c"><input type="checkbox" id="c-40269850" checked=""/><div class="controls bullet"><span class="by">om8</span><span>|</span><a href="#40268273">prev</a><span>|</span><a href="#40271880">next</a><span>|</span><label class="collapse" for="c-40269850">[-]</label><label class="expand" for="c-40269850">[2 more]</label></div><br/><div class="children"><div class="content">Perplexity results are impressive. I wonder, how does combined models perform on MMLU and other problem-solving benchmarks. It can be that this infini-gram method is exactly the thing that “hacks” perplexity without adding any “understanding” to the model.</div><br/><div id="40270054" class="c"><input type="checkbox" id="c-40270054" checked=""/><div class="controls bullet"><span class="by">om8</span><span>|</span><a href="#40269850">parent</a><span>|</span><a href="#40271880">next</a><span>|</span><label class="collapse" for="c-40270054">[-]</label><label class="expand" for="c-40270054">[1 more]</label></div><br/><div class="children"><div class="content">P.S. They acknowledge this:
“... our preliminary experiments show that such method might not be helpful, and even harmful, to open-ended text generation tasks. During generation, ∞-gram can make odd mistakes (e.g., predicting totally irrelevant tokens) which makes the model to digress. Thus this combined model is not ready to replace neural LMs. Additional investigation is required to make inf-gram best contribute to text generation.”</div><br/></div></div></div></div><div id="40271880" class="c"><input type="checkbox" id="c-40271880" checked=""/><div class="controls bullet"><span class="by">mirekrusin</span><span>|</span><a href="#40269850">prev</a><span>|</span><a href="#40269216">next</a><span>|</span><label class="collapse" for="c-40271880">[-]</label><label class="expand" for="c-40271880">[1 more]</label></div><br/><div class="children"><div class="content">Could be used to dedup training data.</div><br/></div></div><div id="40269216" class="c"><input type="checkbox" id="c-40269216" checked=""/><div class="controls bullet"><span class="by">mfornet</span><span>|</span><a href="#40271880">prev</a><span>|</span><a href="#40268793">next</a><span>|</span><label class="collapse" for="c-40269216">[-]</label><label class="expand" for="c-40269216">[1 more]</label></div><br/><div class="children"><div class="content">As I see it, this model will be able to predict “easy” to derive tokens but will no chance on “hard” tokens.<p>For example doing a sum of random numbers. If the token you are trying to predict is not in the training data, even if similar patterns exist, this model defaults to the Neural Model.<p>I guess then it is an aide to the neural model on filling the easy patterns.</div><br/></div></div><div id="40268793" class="c"><input type="checkbox" id="c-40268793" checked=""/><div class="controls bullet"><span class="by">omeze</span><span>|</span><a href="#40269216">prev</a><span>|</span><a href="#40269867">next</a><span>|</span><label class="collapse" for="c-40268793">[-]</label><label class="expand" for="c-40268793">[1 more]</label></div><br/><div class="children"><div class="content">This is a really cool paper, reminds me of the simple exercise Karpathy goes through in his NN vid series with a bigram predictor. Looks like in practice there’s still some grounding issues when attempting to use them for instruction-tuned applications, but clever direction to explore!</div><br/></div></div><div id="40269867" class="c"><input type="checkbox" id="c-40269867" checked=""/><div class="controls bullet"><span class="by">FloatArtifact</span><span>|</span><a href="#40268793">prev</a><span>|</span><a href="#40267637">next</a><span>|</span><label class="collapse" for="c-40269867">[-]</label><label class="expand" for="c-40269867">[2 more]</label></div><br/><div class="children"><div class="content">I can&#x27;t help but want complex grammers for speech recognition :-). There really needs to be a hybrid between speech recognition grammar based commands and natural language for commands.</div><br/><div id="40269951" class="c"><input type="checkbox" id="c-40269951" checked=""/><div class="controls bullet"><span class="by">bmc7505</span><span>|</span><a href="#40269867">parent</a><span>|</span><a href="#40267637">next</a><span>|</span><label class="collapse" for="c-40269951">[-]</label><label class="expand" for="c-40269951">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s coming! CMUSphinx used to have something like this, and there are some [1] solutions [2] on the horizon.<p>[1]: <a href="https:&#x2F;&#x2F;github.com&#x2F;alphacep&#x2F;vosk-api&#x2F;issues&#x2F;55">https:&#x2F;&#x2F;github.com&#x2F;alphacep&#x2F;vosk-api&#x2F;issues&#x2F;55</a><p>[2]: <a href="https:&#x2F;&#x2F;github.com&#x2F;outlines-dev&#x2F;outlines?tab=readme-ov-file#using-context-free-grammars-to-guide-generation">https:&#x2F;&#x2F;github.com&#x2F;outlines-dev&#x2F;outlines?tab=readme-ov-file#...</a></div><br/></div></div></div></div><div id="40267637" class="c"><input type="checkbox" id="c-40267637" checked=""/><div class="controls bullet"><span class="by">novaomnidev</span><span>|</span><a href="#40269867">prev</a><span>|</span><a href="#40267863">next</a><span>|</span><label class="collapse" for="c-40267637">[-]</label><label class="expand" for="c-40267637">[1 more]</label></div><br/><div class="children"><div class="content">The hugging face demo site doesn&#x27;t seem to work with any of the examples. It returns an error in every case.</div><br/></div></div><div id="40267863" class="c"><input type="checkbox" id="c-40267863" checked=""/><div class="controls bullet"><span class="by">bglazer</span><span>|</span><a href="#40267637">prev</a><span>|</span><a href="#40267829">next</a><span>|</span><label class="collapse" for="c-40267863">[-]</label><label class="expand" for="c-40267863">[6 more]</label></div><br/><div class="children"><div class="content">Somewhat off-topic, but has anyone tried training a random forest at LLM scale? Like an RF with millions of trees and billions of branches? My intuition says it could be much more efficient on CPUs, provided it works at all.</div><br/><div id="40272301" class="c"><input type="checkbox" id="c-40272301" checked=""/><div class="controls bullet"><span class="by">Der_Einzige</span><span>|</span><a href="#40267863">parent</a><span>|</span><a href="#40269852">next</a><span>|</span><label class="collapse" for="c-40272301">[-]</label><label class="expand" for="c-40272301">[1 more]</label></div><br/><div class="children"><div class="content">I’ve been talking about this for years! It’s fully possible!</div><br/></div></div><div id="40269852" class="c"><input type="checkbox" id="c-40269852" checked=""/><div class="controls bullet"><span class="by">solresol</span><span>|</span><a href="#40267863">parent</a><span>|</span><a href="#40272301">prev</a><span>|</span><a href="#40268161">next</a><span>|</span><label class="collapse" for="c-40269852">[-]</label><label class="expand" for="c-40269852">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m working on it, but with a loss function that penalises hypernyms&#x2F;hyponyms less than other kinds of mistakes. I&#x27;m vaguely optimistic that this is going to be more efficient.</div><br/></div></div><div id="40268161" class="c"><input type="checkbox" id="c-40268161" checked=""/><div class="controls bullet"><span class="by">skyde</span><span>|</span><a href="#40267863">parent</a><span>|</span><a href="#40269852">prev</a><span>|</span><a href="#40267829">next</a><span>|</span><label class="collapse" for="c-40268161">[-]</label><label class="expand" for="c-40268161">[3 more]</label></div><br/><div class="children"><div class="content">Forest are good at classification but they cannot leverage pre-training on unclassified data.</div><br/><div id="40271948" class="c"><input type="checkbox" id="c-40271948" checked=""/><div class="controls bullet"><span class="by">thesz</span><span>|</span><a href="#40267863">root</a><span>|</span><a href="#40268161">parent</a><span>|</span><a href="#40269644">next</a><span>|</span><label class="collapse" for="c-40271948">[-]</label><label class="expand" for="c-40271948">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;gradientdescending.com&#x2F;unsupervised-random-forest-example&#x2F;" rel="nofollow">https:&#x2F;&#x2F;gradientdescending.com&#x2F;unsupervised-random-forest-ex...</a><p>You can cluster data using unsupervised random forests and then use these cluster indices as features.</div><br/></div></div><div id="40269644" class="c"><input type="checkbox" id="c-40269644" checked=""/><div class="controls bullet"><span class="by">ColonelPhantom</span><span>|</span><a href="#40267863">root</a><span>|</span><a href="#40268161">parent</a><span>|</span><a href="#40271948">prev</a><span>|</span><a href="#40267829">next</a><span>|</span><label class="collapse" for="c-40269644">[-]</label><label class="expand" for="c-40269644">[1 more]</label></div><br/><div class="children"><div class="content">Aren&#x27;t LLMs a classification problem in a sense? &quot;Given this text, classify it based on the next token&quot; seems like a viable interpretation of the problem. Although there are a couple thousand or so classes, which might be a lot (but I know very little about this field).</div><br/></div></div></div></div></div></div><div id="40267829" class="c"><input type="checkbox" id="c-40267829" checked=""/><div class="controls bullet"><span class="by">throwaway81523</span><span>|</span><a href="#40267863">prev</a><span>|</span><a href="#40268376">next</a><span>|</span><label class="collapse" for="c-40267829">[-]</label><label class="expand" for="c-40267829">[1 more]</label></div><br/><div class="children"><div class="content">Is this sort of like Dissociated Press in Emacs?</div><br/></div></div><div id="40268376" class="c"><input type="checkbox" id="c-40268376" checked=""/><div class="controls bullet"><span class="by">hiddencost</span><span>|</span><a href="#40267829">prev</a><span>|</span><a href="#40267766">next</a><span>|</span><label class="collapse" for="c-40268376">[-]</label><label class="expand" for="c-40268376">[1 more]</label></div><br/><div class="children"><div class="content">Unfortunately, single digit millisecond is quite slow for n-gram language models.<p>Weighted Finite State Transducers are where they really shine; you tend to want to do massive parallel operations, and you want to do the without being bottle necked on memory access. I think these challenges make this framework challenging to adopt.</div><br/></div></div><div id="40267766" class="c"><input type="checkbox" id="c-40267766" checked=""/><div class="controls bullet"><span class="by">novaRom</span><span>|</span><a href="#40268376">prev</a><span>|</span><label class="collapse" for="c-40267766">[-]</label><label class="expand" for="c-40267766">[1 more]</label></div><br/><div class="children"><div class="content">TL;DR  we&#x27;ve trained n-gram model implemented in a form of suffix array on very large data set, it shows good perplexity</div><br/></div></div></div></div></div></div></div></body></html>