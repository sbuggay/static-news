<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1724749263960" as="style"/><link rel="stylesheet" href="styles.css?v=1724749263960"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a>Launch HN: Parity (YC S24) – AI for on-call engineers working with Kubernetes</a> </div><div class="subtext"><span>wilson090</span> | <span>67 comments</span></div><br/><div><div id="41358129" class="c"><input type="checkbox" id="c-41358129" checked=""/><div class="controls bullet"><span class="by">Atotalnoob</span><span>|</span><a href="#41358560">next</a><span>|</span><label class="collapse" for="c-41358129">[-]</label><label class="expand" for="c-41358129">[7 more]</label></div><br/><div class="children"><div class="content">It would be kind of interesting if, based on an engineer accepting the suggestion, parity generated a new run book.<p>This would allow repeated issues to be well documented.<p>On iOS Firefox, when clicking “pricing” on the menu, it scrolls to the proper location, but does not close the menu. Closing the menu causes it to jump to the top of the page. Super annoying.</div><br/><div id="41358210" class="c"><input type="checkbox" id="c-41358210" checked=""/><div class="controls bullet"><span class="by">wilson090</span><span>|</span><a href="#41358129">parent</a><span>|</span><a href="#41358748">next</a><span>|</span><label class="collapse" for="c-41358210">[-]</label><label class="expand" for="c-41358210">[1 more]</label></div><br/><div class="children"><div class="content">Agreed, this feature is on our todo list. Another big problem we&#x27;re aiming to tackle is the tribal knowledge that builds up on teams in part due to a lack of documentation. We want to make it easy to build new runbooks and keep existing runbooks up to date<p>And thanks for the bug report, I&#x27;ll take a look</div><br/></div></div><div id="41358748" class="c"><input type="checkbox" id="c-41358748" checked=""/><div class="controls bullet"><span class="by">upon_drumhead</span><span>|</span><a href="#41358129">parent</a><span>|</span><a href="#41358210">prev</a><span>|</span><a href="#41358560">next</a><span>|</span><label class="collapse" for="c-41358748">[-]</label><label class="expand" for="c-41358748">[5 more]</label></div><br/><div class="children"><div class="content">If an issue can be automatically detected and remediated, do you really need a runbook? That space has to be huge. I don&#x27;t see a purpose for documenting it.<p>That said, a tool that runs through existing runbooks and improves them or suggests new ones would be extremely useful IMHO.</div><br/><div id="41360984" class="c"><input type="checkbox" id="c-41360984" checked=""/><div class="controls bullet"><span class="by">cortesoft</span><span>|</span><a href="#41358129">root</a><span>|</span><a href="#41358748">parent</a><span>|</span><a href="#41359799">next</a><span>|</span><label class="collapse" for="c-41360984">[-]</label><label class="expand" for="c-41360984">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I don&#x27;t see a purpose for documenting it.<p>Because when it goes wrong you will want to know what it did. When you discover something new, you are going to want to be able to change the runbook. New employees are going to want to learn how things work from the runbook.<p>Why WOULDN&#x27;T you want to document what it is doing? I would never trust an AI that didn&#x27;t tell me what it was doing and why.</div><br/></div></div><div id="41359799" class="c"><input type="checkbox" id="c-41359799" checked=""/><div class="controls bullet"><span class="by">threeseed</span><span>|</span><a href="#41358129">root</a><span>|</span><a href="#41358748">parent</a><span>|</span><a href="#41360984">prev</a><span>|</span><a href="#41358790">next</a><span>|</span><label class="collapse" for="c-41359799">[-]</label><label class="expand" for="c-41359799">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I don&#x27;t see a purpose for documenting it.<p>Enterprises implement stringent Change Management procedures.<p>If you are making <i>any</i> change to a Prod environment it needs to be thoroughly documented.</div><br/></div></div><div id="41358790" class="c"><input type="checkbox" id="c-41358790" checked=""/><div class="controls bullet"><span class="by">Atotalnoob</span><span>|</span><a href="#41358129">root</a><span>|</span><a href="#41358748">parent</a><span>|</span><a href="#41359799">prev</a><span>|</span><a href="#41358560">next</a><span>|</span><label class="collapse" for="c-41358790">[-]</label><label class="expand" for="c-41358790">[2 more]</label></div><br/><div class="children"><div class="content">Improving documentation.<p>Keep in mind, they are suggestions. It sounds like the product will automatically execute runbooks but hold suggestions for engineer input. This would move it from “suggestion” to “automatically do X”<p>Also, sometimes LLMs are wrong.</div><br/><div id="41359061" class="c"><input type="checkbox" id="c-41359061" checked=""/><div class="controls bullet"><span class="by">jtsaw</span><span>|</span><a href="#41358129">root</a><span>|</span><a href="#41358790">parent</a><span>|</span><a href="#41358560">next</a><span>|</span><label class="collapse" for="c-41359061">[-]</label><label class="expand" for="c-41359061">[1 more]</label></div><br/><div class="children"><div class="content">The product will automatically execute runbooks for you. So far we&#x27;ve focused on using runbooks customers already have, since they know they work for them. We&#x27;ve also added the ability to turn of automatic execution for cases like a suggested runbook, so the customer can make any edits if necessary before approving it to be executed automatically.<p>Yea, this is a big challenge for us. We&#x27;re using a variety of strategies to make sure hallucinations are rare, but that&#x27;s why we&#x27;re also committed to not executing actions that modify your cluster unless explicitly specified in a runbook</div><br/></div></div></div></div></div></div></div></div><div id="41358560" class="c"><input type="checkbox" id="c-41358560" checked=""/><div class="controls bullet"><span class="by">stackskipton</span><span>|</span><a href="#41358129">prev</a><span>|</span><a href="#41362192">next</a><span>|</span><label class="collapse" for="c-41358560">[-]</label><label class="expand" for="c-41358560">[10 more]</label></div><br/><div class="children"><div class="content">Azure Kubernetes Wrangler (SRE) here, before I turn some LLM loose on my cluster, I need to know what it supports, how it supports it and how I can integrate into my workflow.<p>Videos show CrashLoopBackOff pod and analyzing logs. This works if Pod is writing to stdout but I&#x27;ve got some stuff doing straight to ElasticSearch. Does LLM speak Elastic Search? How about Log Files in the Pod? (Don&#x27;t get me started on that nightmare)<p>You also show fixing by editing YAML in place. That&#x27;s great except my FluxCD is going revert since you violated principle of &quot;All goes through GitOps&quot;. So if you are going to change anything, you need to update the proper git repo. Also in said GitOps is Kustomize so hope you understand all interactions there.<p>Personally, the stuff that takes most troubleshooting time is Kubernetes infrastructure. Network CNI is acting up. Ingress Controller is missing proper path based routing. NetworkPolicy says No to Pod talking to PostGres Server. CertManager is on strike and certificate has expired. If LLM is quick at identifying those, it has some uses but selling me on &quot;Dev made mistake with Pod Config&quot; is likely not to move the needle because I&#x27;m really quick at identifying that.<p>Maybe I&#x27;m not the target market and target market is &quot;Small Dev team that bought Kubernetes without realizing what they were signing up for&quot;</div><br/><div id="41358927" class="c"><input type="checkbox" id="c-41358927" checked=""/><div class="controls bullet"><span class="by">wilson090</span><span>|</span><a href="#41358560">parent</a><span>|</span><a href="#41360935">next</a><span>|</span><label class="collapse" for="c-41358927">[-]</label><label class="expand" for="c-41358927">[3 more]</label></div><br/><div class="children"><div class="content">Your comment brings up a good point (and also one of our big challenges): there is a huge diversity in the tools teams use to setup and operate their infra. Right now our platform only speaks to your cluster directly through kubectl commands. We’ll build other integrations so it can communicate with things like Elastic Search to broaden its context as needed, but we’ll have to be somewhat thoughtful in picking the highest ROI integrations to build.<p>Currently, we only handle the investigation piece and suggest a remediation to the on-call engineer. But to properly move into automatically applying a fix, which we hope to do at some point, we’ll need to integrate into CI&#x2F;CD<p>As for the demo example, I agree that the issue itself isn’t the most compelling. We used it as an example since it is easy to visualize and set up for a demo. The agent is capable of investigating more complex issues we&#x27;ve seen in our customer&#x27;s production clusters, but we&#x27;re still looking for a way to better simulate these on our test environment, so if you&#x2F;anyone has ideas we’d love to hear them.<p>We do think this has more value for engineers&#x2F;teams with less expertise in k8s, but we think SREs will still find it useful</div><br/><div id="41359052" class="c"><input type="checkbox" id="c-41359052" checked=""/><div class="controls bullet"><span class="by">stackskipton</span><span>|</span><a href="#41358560">root</a><span>|</span><a href="#41358927">parent</a><span>|</span><a href="#41361019">next</a><span>|</span><label class="collapse" for="c-41359052">[-]</label><label class="expand" for="c-41359052">[1 more]</label></div><br/><div class="children"><div class="content">&gt;we&#x27;re still looking for a way to better simulate these on our test environment, so if you&#x2F;anyone has ideas we’d love to hear them.<p>Pick Kubernetes offering from big 3, deploy it then blow it up.<p>(I couldn&#x27;t get HackerNews to format properly and done fighting it)<p>On Azure, deploy a Kubernetes cluster with following:<p>Azure CNI with Network Policies<p>Application Gateway for Containers<p>External DNS hooked to Azure DNS<p>Ingress Nginx<p>Flexible PostGres Server (outside the cluster)<p>FluxCD&#x2F;Argo<p>Something with using Workload Identity<p>Once all that is configured, put some fake workloads on it and start misconfiguring it with your LLM wired up. When the fireworks start, identify the failures and train your LLM properly.</div><br/></div></div><div id="41361019" class="c"><input type="checkbox" id="c-41361019" checked=""/><div class="controls bullet"><span class="by">solatic</span><span>|</span><a href="#41358560">root</a><span>|</span><a href="#41358927">parent</a><span>|</span><a href="#41359052">prev</a><span>|</span><a href="#41360935">next</a><span>|</span><label class="collapse" for="c-41361019">[-]</label><label class="expand" for="c-41361019">[1 more]</label></div><br/><div class="children"><div class="content">&gt; we think SREs will still find it useful<p>There are two kinds of outages: people being idiots and legit hard-to-track-down bugs. SREs worth their salt don&#x27;t need help with the former. They may find an AI bot somewhat useful to find root cause quicker, but usually not so valuable as to justify paying the kind of price you would need to charge to make your business viable to VCs. As for the latter, good luck collecting enough training data.<p>Otherwise, you&#x27;re selling a self-driving car to executives who want the chauffeur without the salary. Sounds like a great idea, until you think about the tail cases. Then you wish you had a chauffeur (or picked up driving skills yourself).<p>Maybe you&#x27;ll find a market, but as an SRE, I wouldn&#x27;t want to sell it.</div><br/></div></div></div></div><div id="41360935" class="c"><input type="checkbox" id="c-41360935" checked=""/><div class="controls bullet"><span class="by">solatic</span><span>|</span><a href="#41358560">parent</a><span>|</span><a href="#41358927">prev</a><span>|</span><a href="#41358911">next</a><span>|</span><label class="collapse" for="c-41360935">[-]</label><label class="expand" for="c-41360935">[1 more]</label></div><br/><div class="children"><div class="content">I basically want to +1 this. OP isn&#x27;t selling to any place that is already spending six figures on SRE salaries. Actual competitors are companies like Komodor and Robusta who sell &quot;we know Kubernetes better than you&quot; solutions to companies that don&#x27;t want to spend money on SRE salaries. Companies in this situation should just seriously reconsider hosting on Kubernetes and go back to higher-level managed services like ECS&#x2F;Fargate, Fly&#x2F;Railway, etc.</div><br/></div></div><div id="41358911" class="c"><input type="checkbox" id="c-41358911" checked=""/><div class="controls bullet"><span class="by">pmccarren</span><span>|</span><a href="#41358560">parent</a><span>|</span><a href="#41360935">prev</a><span>|</span><a href="#41360976">next</a><span>|</span><label class="collapse" for="c-41358911">[-]</label><label class="expand" for="c-41358911">[2 more]</label></div><br/><div class="children"><div class="content">&gt; CertManager is on strike and certificate has expired<p>Had a good chuckle here, hah.</div><br/><div id="41364344" class="c"><input type="checkbox" id="c-41364344" checked=""/><div class="controls bullet"><span class="by">mad_vill</span><span>|</span><a href="#41358560">root</a><span>|</span><a href="#41358911">parent</a><span>|</span><a href="#41360976">next</a><span>|</span><label class="collapse" for="c-41364344">[-]</label><label class="expand" for="c-41364344">[1 more]</label></div><br/><div class="children"><div class="content">Same. Typically call it “hung” but maybe stating certmanager is on strike will get the point across better.<p>But sigh does it really get to the state of the kubernetes ecosystem. All these projects need to be operated, can’t just set it and forget it.</div><br/></div></div></div></div><div id="41360976" class="c"><input type="checkbox" id="c-41360976" checked=""/><div class="controls bullet"><span class="by">shmatt</span><span>|</span><a href="#41358560">parent</a><span>|</span><a href="#41358911">prev</a><span>|</span><a href="#41362192">next</a><span>|</span><label class="collapse" for="c-41360976">[-]</label><label class="expand" for="c-41360976">[3 more]</label></div><br/><div class="children"><div class="content">Im sure this is on their roadmap, but honestly a pre-requisite should be a separate piece of software that analyzes and suggests changes to your error handling.<p>This is a cool proof of concept but almost useless otherwise in a production system<p>I can already feed Claude or ChatGPT my kubectl output pretty easily<p>Error handling and logging that are tailored for consumption of a specific pre trained model, thats where this will be ground breaking</div><br/><div id="41362246" class="c"><input type="checkbox" id="c-41362246" checked=""/><div class="controls bullet"><span class="by">stackskipton</span><span>|</span><a href="#41358560">root</a><span>|</span><a href="#41360976">parent</a><span>|</span><a href="#41361054">next</a><span>|</span><label class="collapse" for="c-41362246">[-]</label><label class="expand" for="c-41362246">[1 more]</label></div><br/><div class="children"><div class="content">The AI needs to be integrated into Dev IDE. All my logging screaming is terrible decisions made by long ago Devs but getting them fixed now is impossible because they don&#x27;t want to do it and no one is going to make them.</div><br/></div></div><div id="41361054" class="c"><input type="checkbox" id="c-41361054" checked=""/><div class="controls bullet"><span class="by">wilson090</span><span>|</span><a href="#41358560">root</a><span>|</span><a href="#41360976">parent</a><span>|</span><a href="#41362246">prev</a><span>|</span><a href="#41362192">next</a><span>|</span><label class="collapse" for="c-41361054">[-]</label><label class="expand" for="c-41361054">[1 more]</label></div><br/><div class="children"><div class="content">That is something we&#x27;re working on -- good observability is a place where teams usually fall short and often the limiting factor to better incident response. We&#x27;re working on logging integrations as a first step.</div><br/></div></div></div></div></div></div><div id="41362192" class="c"><input type="checkbox" id="c-41362192" checked=""/><div class="controls bullet"><span class="by">ronald_petty</span><span>|</span><a href="#41358560">prev</a><span>|</span><a href="#41361187">next</a><span>|</span><label class="collapse" for="c-41362192">[-]</label><label class="expand" for="c-41362192">[2 more]</label></div><br/><div class="children"><div class="content">I think this kind of tooling is one positive aspect of integrating LLM tech in certain workflows&#x2F;pipelines. Tools like k8sgpt are similar in purpose and show a strong potential to be useful. Look forward to seeing how this progresses.</div><br/><div id="41362249" class="c"><input type="checkbox" id="c-41362249" checked=""/><div class="controls bullet"><span class="by">wilson090</span><span>|</span><a href="#41362192">parent</a><span>|</span><a href="#41361187">next</a><span>|</span><label class="collapse" for="c-41362249">[-]</label><label class="expand" for="c-41362249">[1 more]</label></div><br/><div class="children"><div class="content">Thanks! k8sgpt is great, it was one of our inspirations</div><br/></div></div></div></div><div id="41361187" class="c"><input type="checkbox" id="c-41361187" checked=""/><div class="controls bullet"><span class="by">drawnwren</span><span>|</span><a href="#41362192">prev</a><span>|</span><a href="#41358144">next</a><span>|</span><label class="collapse" for="c-41361187">[-]</label><label class="expand" for="c-41361187">[2 more]</label></div><br/><div class="children"><div class="content">This is a great idea. I use claude for my most of my unknown K8s bugs and it&#x27;s impressive how useful it is (far more than my coding bugs).</div><br/><div id="41361429" class="c"><input type="checkbox" id="c-41361429" checked=""/><div class="controls bullet"><span class="by">wilson090</span><span>|</span><a href="#41361187">parent</a><span>|</span><a href="#41358144">next</a><span>|</span><label class="collapse" for="c-41361429">[-]</label><label class="expand" for="c-41361429">[1 more]</label></div><br/><div class="children"><div class="content">Thanks! We&#x27;ve also been impressed with the performance of out-of-the-box LLMs on this use case. I think in part it is because k8s is a significantly more constrained problem-space than coding, and because of that we&#x27;ll get to a much more complete solution with the existing state of LLMs than we would for a product like a general software engineer agent.</div><br/></div></div></div></div><div id="41358144" class="c"><input type="checkbox" id="c-41358144" checked=""/><div class="controls bullet"><span class="by">raunakchowdhuri</span><span>|</span><a href="#41361187">prev</a><span>|</span><a href="#41358922">next</a><span>|</span><label class="collapse" for="c-41358144">[-]</label><label class="expand" for="c-41358144">[3 more]</label></div><br/><div class="children"><div class="content">hmmm idk how I would feel about giving an llm cluster access from a security pov</div><br/><div id="41358332" class="c"><input type="checkbox" id="c-41358332" checked=""/><div class="controls bullet"><span class="by">wilson090</span><span>|</span><a href="#41358144">parent</a><span>|</span><a href="#41358922">next</a><span>|</span><label class="collapse" for="c-41358332">[-]</label><label class="expand" for="c-41358332">[2 more]</label></div><br/><div class="children"><div class="content">Valid concern, security and safety are essential for anything that can access a production system. We use k8s RBAC to ensure that the access is read-only, so even if the LLM hallucinates and tries to destroy something, it can&#x27;t<p>As we will eventually move towards write-access, we&#x27;re closely following the work in LLM safety. There has been some interesting work to use smaller models to evaluate tool calls&#x2F;completions against a set of criteria to ensure safety</div><br/><div id="41358710" class="c"><input type="checkbox" id="c-41358710" checked=""/><div class="controls bullet"><span class="by">martinald</span><span>|</span><a href="#41358144">root</a><span>|</span><a href="#41358332">parent</a><span>|</span><a href="#41358922">next</a><span>|</span><label class="collapse" for="c-41358710">[-]</label><label class="expand" for="c-41358710">[1 more]</label></div><br/><div class="children"><div class="content">Other problem is that you become an extremely big target for bad actors as you have read&#x2F;write (or just even read) access to all these k8s clusters. Obviously you can mitigate against that to a fairly high degree with on prem, but for users not on that...<p>Cool idea though!</div><br/></div></div></div></div></div></div><div id="41358922" class="c"><input type="checkbox" id="c-41358922" checked=""/><div class="controls bullet"><span class="by">henning</span><span>|</span><a href="#41358144">prev</a><span>|</span><a href="#41360025">next</a><span>|</span><label class="collapse" for="c-41358922">[-]</label><label class="expand" for="c-41358922">[3 more]</label></div><br/><div class="children"><div class="content">An AI agent to triage the production issues caused by code generated by some other startup&#x27;s generative AI bot. I fucking love tech in 2024.</div><br/><div id="41359221" class="c"><input type="checkbox" id="c-41359221" checked=""/><div class="controls bullet"><span class="by">dockerd</span><span>|</span><a href="#41358922">parent</a><span>|</span><a href="#41363515">next</a><span>|</span><label class="collapse" for="c-41359221">[-]</label><label class="expand" for="c-41359221">[1 more]</label></div><br/><div class="children"><div class="content">You forget the AI tech which help test the AI tech</div><br/></div></div><div id="41363515" class="c"><input type="checkbox" id="c-41363515" checked=""/><div class="controls bullet"><span class="by">meiraleal</span><span>|</span><a href="#41358922">parent</a><span>|</span><a href="#41359221">prev</a><span>|</span><a href="#41360025">next</a><span>|</span><label class="collapse" for="c-41363515">[-]</label><label class="expand" for="c-41363515">[1 more]</label></div><br/><div class="children"><div class="content">In a gold rush, sell shovel handles, gloves to hold the shovel, newsletter courses on how to dig...</div><br/></div></div></div></div><div id="41360025" class="c"><input type="checkbox" id="c-41360025" checked=""/><div class="controls bullet"><span class="by">nerdjon</span><span>|</span><a href="#41358922">prev</a><span>|</span><a href="#41360236">next</a><span>|</span><label class="collapse" for="c-41360025">[-]</label><label class="expand" for="c-41360025">[2 more]</label></div><br/><div class="children"><div class="content">Well the website seems to be down so I can&#x27;t actually see any information about what LLM you are using, but I seriously hope you are not just sending the data to OpenAI API or something like that and are forcing the use of a private (ideally self hosted) service.<p>I would not want any data about my infrastructure sent to a public LLM, regardless of how sanitized things are.<p>Otherwise, on paper it seems cool. But I worry about getting complicit with this tech. It is going to fail, that is just the reality. We know LLM&#x27;s will hallucinate and there is not much we can do about it, it is the nature of the tech.<p>SO it might work most of the time, but when it doesn&#x27;t and you&#x27;re bashing your head against the wall trying to figure out what is broken. This system is telling you that all of these things are fine, but one of them actually isn&#x27;t. But it worked enough times that you trust it, so you don&#x27;t bother double checking.<p>That is before we even talk about having this thing running code for automatic remediation, which I hope no one seriously considers ever doing that.</div><br/><div id="41360388" class="c"><input type="checkbox" id="c-41360388" checked=""/><div class="controls bullet"><span class="by">wilson090</span><span>|</span><a href="#41360025">parent</a><span>|</span><a href="#41360236">next</a><span>|</span><label class="collapse" for="c-41360388">[-]</label><label class="expand" for="c-41360388">[1 more]</label></div><br/><div class="children"><div class="content">Hmm we&#x27;re not seeing any issues with the website on our end -- tryparity.com is down for you?<p>The data security point with LLMs is definitely relevant. There&#x27;s a broader conversation ongoing right now about how teams will securely use LLMs, but from our conversations so far teams have been willing to adopt the tech. We&#x27;ve been working with startups up to this point, so we&#x27;ll likely need to offer support self-hosted LLMs if we were to support enterprise or bring-your-own-keys for larger startups.<p>The hallucination point is interesting. I think a lot of products will need to solve this problem of having so much trust with the user that they&#x27;ll blindly follow the outputs, but occasionally failing due to hallucination. Our approach has been to 1) only focus on investigation&#x2F;root cause and 2) make sure it&#x27;s easy to audit the results by sharing all of the results + supporting evidence</div><br/></div></div></div></div><div id="41360236" class="c"><input type="checkbox" id="c-41360236" checked=""/><div class="controls bullet"><span class="by">manveerc</span><span>|</span><a href="#41360025">prev</a><span>|</span><a href="#41358611">next</a><span>|</span><label class="collapse" for="c-41360236">[-]</label><label class="expand" for="c-41360236">[4 more]</label></div><br/><div class="children"><div class="content">Congratulations on the launch! I&#x27;m curious—how is what you&#x27;re building different from other AI SRE solutions out there, like Cleric, Onegrep, Resolve, Beeps, and others?</div><br/><div id="41360508" class="c"><input type="checkbox" id="c-41360508" checked=""/><div class="controls bullet"><span class="by">wilson090</span><span>|</span><a href="#41360236">parent</a><span>|</span><a href="#41358611">next</a><span>|</span><label class="collapse" for="c-41360508">[-]</label><label class="expand" for="c-41360508">[3 more]</label></div><br/><div class="children"><div class="content">Thanks! Hard to make a comparison to Cleric since their site doesn&#x27;t really have any features or a demo. Onegrep is a fellow YC company, and we love what they&#x27;re building! They seem to be more focused on workflows and pulling together context (also a very important problem in the space), we we&#x27;ve put more of a focus on root causing infra issues specifically. Resolve seems to come from the same category as Temporal, which are more traditional automation platforms. These end up being somewhat rigid tools in that you have to very explicitly define each step and they require a certain level of CI&#x2F;CD or monitoring sophistication to be useful. Using LLMs allows us to relax these requirements and follow workflows like an actual engineer would.<p>I haven&#x27;t heard of Beeps and can&#x27;t find it, could you share the URL?</div><br/><div id="41360726" class="c"><input type="checkbox" id="c-41360726" checked=""/><div class="controls bullet"><span class="by">manveerc</span><span>|</span><a href="#41360236">root</a><span>|</span><a href="#41360508">parent</a><span>|</span><a href="#41358611">next</a><span>|</span><label class="collapse" for="c-41360726">[-]</label><label class="expand" for="c-41360726">[2 more]</label></div><br/><div class="children"><div class="content">&gt; They seem to be more focused on workflows and pulling together context (also a very important problem in the space), we we&#x27;ve put more of a focus on root causing infra issues specifically.<p>So just to clarify, are you saying that Parity is focused on infrastructure issues, while something like Onegrep addresses the broader problem by providing context?<p>&gt; I haven&#x27;t heard of Beeps and can&#x27;t find it, could you share the URL?<p><a href="https:&#x2F;&#x2F;www.beeps.co&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.beeps.co&#x2F;</a></div><br/><div id="41360850" class="c"><input type="checkbox" id="c-41360850" checked=""/><div class="controls bullet"><span class="by">wilson090</span><span>|</span><a href="#41360236">root</a><span>|</span><a href="#41360726">parent</a><span>|</span><a href="#41358611">next</a><span>|</span><label class="collapse" for="c-41360850">[-]</label><label class="expand" for="c-41360850">[1 more]</label></div><br/><div class="children"><div class="content">Yes, my understanding is that Onegrep is meant to provide context from your documentation and past incidents, which can be helpful when trying to solve an alert. We&#x27;re focused on root-causing underlying infrastructure issues by actually looking into the logs&#x2F;configurations&#x2F;metrics.<p>Ah I actually did see beeps a while back. I haven&#x27;t tried their product, but they seem to be similar to rootly&#x2F;Onegrep in that they&#x27;re working on on-call management&#x2F;post-mortems</div><br/></div></div></div></div></div></div></div></div><div id="41358611" class="c"><input type="checkbox" id="c-41358611" checked=""/><div class="controls bullet"><span class="by">mdaniel</span><span>|</span><a href="#41360236">prev</a><span>|</span><a href="#41359104">next</a><span>|</span><label class="collapse" for="c-41358611">[-]</label><label class="expand" for="c-41358611">[1 more]</label></div><br/><div class="children"><div class="content">Why would you have your demo video set to &quot;unlisted&quot;? (on what appears to be your official channel) I&#x27;d think you&#x27;d want to show up in as many places as possible</div><br/></div></div><div id="41359104" class="c"><input type="checkbox" id="c-41359104" checked=""/><div class="controls bullet"><span class="by">klinquist</span><span>|</span><a href="#41358611">prev</a><span>|</span><a href="#41360884">next</a><span>|</span><label class="collapse" for="c-41359104">[-]</label><label class="expand" for="c-41359104">[3 more]</label></div><br/><div class="children"><div class="content">Website won&#x27;t load - just me?</div><br/><div id="41359151" class="c"><input type="checkbox" id="c-41359151" checked=""/><div class="controls bullet"><span class="by">jtsaw</span><span>|</span><a href="#41359104">parent</a><span>|</span><a href="#41360884">next</a><span>|</span><label class="collapse" for="c-41359151">[-]</label><label class="expand" for="c-41359151">[2 more]</label></div><br/><div class="children"><div class="content">which website doesn&#x27;t load for you?</div><br/><div id="41360730" class="c"><input type="checkbox" id="c-41360730" checked=""/><div class="controls bullet"><span class="by">klinquist</span><span>|</span><a href="#41359104">root</a><span>|</span><a href="#41359151">parent</a><span>|</span><a href="#41360884">next</a><span>|</span><label class="collapse" for="c-41360730">[-]</label><label class="expand" for="c-41360730">[1 more]</label></div><br/><div class="children"><div class="content">trtparity.com, looks like it&#x27;s a local problem, loads on cellular.</div><br/></div></div></div></div></div></div><div id="41364110" class="c"><input type="checkbox" id="c-41364110" checked=""/><div class="controls bullet"><span class="by">andrewguy9</span><span>|</span><a href="#41360884">prev</a><span>|</span><a href="#41359750">next</a><span>|</span><label class="collapse" for="c-41364110">[-]</label><label class="expand" for="c-41364110">[8 more]</label></div><br/><div class="children"><div class="content">For god sakes, SREs need to give up on K8. It was a bad idea, just move on.<p>The answer is not, “let an ai figure it out.”<p>That is legitimately scary.</div><br/><div id="41364511" class="c"><input type="checkbox" id="c-41364511" checked=""/><div class="controls bullet"><span class="by">hotchip</span><span>|</span><a href="#41364110">parent</a><span>|</span><a href="#41364127">next</a><span>|</span><label class="collapse" for="c-41364511">[-]</label><label class="expand" for="c-41364511">[1 more]</label></div><br/><div class="children"><div class="content">What’s more “legitimately scary” is that people wanna run it back to monoliths like it’s the 90s and think building a modern scalable system is too hard</div><br/></div></div><div id="41364127" class="c"><input type="checkbox" id="c-41364127" checked=""/><div class="controls bullet"><span class="by">wilson090</span><span>|</span><a href="#41364110">parent</a><span>|</span><a href="#41364511">prev</a><span>|</span><a href="#41359750">next</a><span>|</span><label class="collapse" for="c-41364127">[-]</label><label class="expand" for="c-41364127">[6 more]</label></div><br/><div class="children"><div class="content">What would you propose as an alternative to k8s?</div><br/><div id="41364599" class="c"><input type="checkbox" id="c-41364599" checked=""/><div class="controls bullet"><span class="by">andrewguy9</span><span>|</span><a href="#41364110">root</a><span>|</span><a href="#41364127">parent</a><span>|</span><a href="#41364158">next</a><span>|</span><label class="collapse" for="c-41364599">[-]</label><label class="expand" for="c-41364599">[1 more]</label></div><br/><div class="children"><div class="content">I think the big problem is it tries to do too much. We used to have many tools as SRE but now teams are really limited. We handed the keys to the engineers which I think is overall a good intention. But we didn’t set them up with sensible defaults, which left them open to making really bad decisions. We made it easy to increase the diversity in the fleet and we removed observability. I think things are more opaque, more complicated, and I have fewer tools to deal with it.<p>I miss having lots of tools to reach for. Lots of different solutions, depending on where my company was and what they were trying to do.<p>I don’t think one T-shirt size fits all. But here are some specific things that annoy me.<p>Puppet had a richer change management language than docker. When I lost puppet, we had to revert back to shitty bash scripts, and nondeterminism from the cicd builds. The worst software in your org is always the build scripts. But now that is the whole host state! So SREs are held captive by nonsense in the cicd box. If you were using Jenkins 1.x, the job config wasn’t even checked in! With puppet I could use git to tell me what config changed, for tracked state anyway. Docker is nice in that the images are consistent, which is a huge pain point with bad puppet code. So it’s a mixed bag.<p>The clouds and network infrastructure have a lot of old assumptions about hosts&#x2F;ips&#x2F;ports. This comes up a lot in network security, and service discovery, and cache infrastructure. Dealing with this in the k8 world is so much harder, and the cost and performance so much worse. It’s really shocking to me how much people pay because they are using these software based networks.<p>The Hypervisors and native cloud solutions were much better at noisy neighbor protection, and a better abstraction for carving up workloads. When I worked at AWS I got to see the huge lengths the ebs and ec2 teams put into providing consistent performance. VMWare has also done a ton of work on QoS. The os kernels are just a lot less mature on this. Running in the cloud inside a single vm removed most of the value of this work.<p>In the early 2010s, lots of teams were provisioning ec2 instances and their bills were easy to see in the bill as dollars and cents. At my last company, we were describing workloads as replicas&#x2F;gbs&#x2F;cpus&#x2F;clusters on a huge shared cluster. Thousands of hosts, a dozen data centers.<p>This added layer of obfuscation hides true cost of a workload. I watched a presentation from a large well known software service company say that their k8 migration increased their cloud spend because teams were no longer accountable to spend. At my company, I saw the same thing. Engineers were given the keys on provisioning but were not in the loop for cost cutting. That fell to the SREs, who were blamed for exploding costs. The engineers are really just not prepared to handle this kind of work. They have no understanding about the implications in terms of cost and performance. We didn’t train them on these things. But we took the keys away from the SRE’s and handed it to the engineers.<p>The debugging story is particularly weak. Once we shipped on docker and K8 we lost ssh access to production. 10 years into the docker experiment, we now have a generation of senior engineers who don’t know how to debug. I’ve spent dozens of hours on conference calls while the engineers fumbled around. Most of these issues could have been diagnosed with netstat&#x2F;lsof&#x2F;perl -pe&#x2F;ping&#x2F;traceroute. If the issue didn’t appear in New Relic, then they were totally helpless. The loss of the bash one-liner is really detrimental to engineers progress.<p>There is too much diversity in the docker base images and too many of them stuck. The tool encourages every engineer to pick a different one. To solve this my org promised to converge on alpine. But if you use a docker distribution, now you are shipping all of user mode to every process. I was on the hook for fixing a libc exploit for our fleet. I had everyone on a common base image, so fixing all 80 of my host classes took me about a few days. But my coworkers in other orgs who had hundreds of different docker images were working on it a year later. Answering the question, which LibC am I on became very difficult.<p>Terraform has a better provisioning&#x2F;migration story. Use that to design your network, perform migrations. Use the cloud native networking constructs. Use them for security boundaries. Having workloads move seamlessly between these “anything can be on me hosts” make security, a real nightmare.<p>I left being an SRE behind when I saw management get convinced docker&#x2F;k8 was a cancer treatment, a desert topping and a floor wax. it’s been five years and I think I made the right call.</div><br/></div></div><div id="41364158" class="c"><input type="checkbox" id="c-41364158" checked=""/><div class="controls bullet"><span class="by">jyscao</span><span>|</span><a href="#41364110">root</a><span>|</span><a href="#41364127">parent</a><span>|</span><a href="#41364599">prev</a><span>|</span><a href="#41359750">next</a><span>|</span><label class="collapse" for="c-41364158">[-]</label><label class="expand" for="c-41364158">[4 more]</label></div><br/><div class="children"><div class="content">go back to building monoliths</div><br/><div id="41364348" class="c"><input type="checkbox" id="c-41364348" checked=""/><div class="controls bullet"><span class="by">stevefan1999</span><span>|</span><a href="#41364110">root</a><span>|</span><a href="#41364158">parent</a><span>|</span><a href="#41364457">next</a><span>|</span><label class="collapse" for="c-41364348">[-]</label><label class="expand" for="c-41364348">[1 more]</label></div><br/><div class="children"><div class="content">As a software engineer, DevOps engineer, platform engineer and SRE in a mixed bag, I would say not building monoliths -- instead build a microservice but slightly larger that can still be easily cloneable, scalable and fault tolerant. A mix of monolith and microservice, you may say, and I would like to call that &quot;siloservice&quot;.<p>Silo: A silo is a cylindrical tower used for bulk storage, like grain silos that stand tall near farms. Another kind of silo is harder to see — military silos are underground.<p>Obviously, you don&#x27;t need 10 fragmented microservices interdepending on each other, that&#x27;s one of the biggest overengineering for microservices in real world practices, but you can build multiple &quot;siloservices&quot; that does the same stuff more effectively while getting easy maintenance. I got this inspiration from working with monorepos in the past.</div><br/></div></div><div id="41364457" class="c"><input type="checkbox" id="c-41364457" checked=""/><div class="controls bullet"><span class="by">hughesjj</span><span>|</span><a href="#41364110">root</a><span>|</span><a href="#41364158">parent</a><span>|</span><a href="#41364348">prev</a><span>|</span><a href="#41364214">next</a><span>|</span><label class="collapse" for="c-41364457">[-]</label><label class="expand" for="c-41364457">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t get how that solves the scalability and deployment&#x2F;sdlc problems k8s is used for<p>Like, monoliths and k8s seem orthogonal to me.  It&#x27;s like saying &#x27;docker was a failure we should go back to writing Java&#x27; to me.</div><br/></div></div><div id="41364214" class="c"><input type="checkbox" id="c-41364214" checked=""/><div class="controls bullet"><span class="by">wilson090</span><span>|</span><a href="#41364110">root</a><span>|</span><a href="#41364158">parent</a><span>|</span><a href="#41364457">prev</a><span>|</span><a href="#41359750">next</a><span>|</span><label class="collapse" for="c-41364214">[-]</label><label class="expand" for="c-41364214">[1 more]</label></div><br/><div class="children"><div class="content">While I agree that there are certainly cases of microservices being used in places they shouldn’t be, I have trouble imagining that monoliths are strictly better in every case. Do you have suggestions for running monoliths at scale?</div><br/></div></div></div></div></div></div></div></div><div id="41359750" class="c"><input type="checkbox" id="c-41359750" checked=""/><div class="controls bullet"><span class="by">threeseed</span><span>|</span><a href="#41364110">prev</a><span>|</span><label class="collapse" for="c-41359750">[-]</label><label class="expand" for="c-41359750">[20 more]</label></div><br/><div class="children"><div class="content">&gt; This agent is a combination of separate LLM agents each responsible for a single step of the runbook<p>Someone needs to explain to me how this is expected to work.<p>Percentage of Hallucinations&#x2F;Errors x Steps in Runbook = Total Errors<p>0.05 x 10 = 0.5 = 50%</div><br/><div id="41359817" class="c"><input type="checkbox" id="c-41359817" checked=""/><div class="controls bullet"><span class="by">bicx</span><span>|</span><a href="#41359750">parent</a><span>|</span><a href="#41359849">next</a><span>|</span><label class="collapse" for="c-41359817">[-]</label><label class="expand" for="c-41359817">[12 more]</label></div><br/><div class="children"><div class="content">Getting tired of seeing this concept of practically guaranteed hallucinations from any LLM used in production. I&#x27;ve used LLMs for various tasks, and if you tune your system correctly, it can be very reliable. It&#x27;s just not always plug-and-play reliability. You need to set up your fine-tuning and prompts and then test well for consistent results.</div><br/><div id="41359942" class="c"><input type="checkbox" id="c-41359942" checked=""/><div class="controls bullet"><span class="by">nerdjon</span><span>|</span><a href="#41359750">root</a><span>|</span><a href="#41359817">parent</a><span>|</span><a href="#41359874">next</a><span>|</span><label class="collapse" for="c-41359942">[-]</label><label class="expand" for="c-41359942">[5 more]</label></div><br/><div class="children"><div class="content">&gt; You need to set up your fine-tuning and prompts and then test well for consistent results.<p>Tell that to Google...<p>Seriously, it is well established that these systems hallucinate. Trying to say otherwise shows you are trying to push something that just is not true.<p>They can be right, yes. But when they are wrong they can be catastrophically wrong. You could be wasting time looking into the wrong problem with something like this.</div><br/><div id="41364831" class="c"><input type="checkbox" id="c-41364831" checked=""/><div class="controls bullet"><span class="by">hobofan</span><span>|</span><a href="#41359750">root</a><span>|</span><a href="#41359942">parent</a><span>|</span><a href="#41364465">next</a><span>|</span><label class="collapse" for="c-41364831">[-]</label><label class="expand" for="c-41364831">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Tell that to Google...<p>Yeah, because Google&#x27;s LLMs have an completely open question&#x2F;answer space.<p>For e.g. a Kubernetes AI, you can nowadays just feed in the whole Kubernetes docs + a few reference Helm charts, tell it to stick close to the material, and you&#x27;ll have next to no hallucinations. Same thing for simple data extraction tasks, where in the past you couldn&#x27;t use LLMs because they would just hallucinate data into the output that wasn&#x27;t there in the input (e.g. completely mangling an ID), which nowadays is essentially a non-issue.<p>As soon as you have a restrictable space in which the LLM acts, you have a lot of options to tune them that hallucinations are not a major issue nowadays.</div><br/></div></div><div id="41364465" class="c"><input type="checkbox" id="c-41364465" checked=""/><div class="controls bullet"><span class="by">hughesjj</span><span>|</span><a href="#41359750">root</a><span>|</span><a href="#41359942">parent</a><span>|</span><a href="#41364831">prev</a><span>|</span><a href="#41361235">next</a><span>|</span><label class="collapse" for="c-41364465">[-]</label><label class="expand" for="c-41364465">[1 more]</label></div><br/><div class="children"><div class="content">The most common hallucinations I&#x27;ve seen are phantom GitHub repos and issues, and this usually appears when I ask for a source.</div><br/></div></div><div id="41361235" class="c"><input type="checkbox" id="c-41361235" checked=""/><div class="controls bullet"><span class="by">drawnwren</span><span>|</span><a href="#41359750">root</a><span>|</span><a href="#41359942">parent</a><span>|</span><a href="#41364465">prev</a><span>|</span><a href="#41359874">next</a><span>|</span><label class="collapse" for="c-41361235">[-]</label><label class="expand" for="c-41361235">[2 more]</label></div><br/><div class="children"><div class="content">If you&#x27;re curious what the state of the art in multi-agent is looking like, I really recommend <a href="https:&#x2F;&#x2F;thinkwee.top&#x2F;multiagent_ebook&#x2F;" rel="nofollow">https:&#x2F;&#x2F;thinkwee.top&#x2F;multiagent_ebook&#x2F;</a></div><br/><div id="41363660" class="c"><input type="checkbox" id="c-41363660" checked=""/><div class="controls bullet"><span class="by">meiraleal</span><span>|</span><a href="#41359750">root</a><span>|</span><a href="#41361235">parent</a><span>|</span><a href="#41359874">next</a><span>|</span><label class="collapse" for="c-41363660">[-]</label><label class="expand" for="c-41363660">[1 more]</label></div><br/><div class="children"><div class="content">This looks great! Unfortunately doesn&#x27;t well on firefox but I take it as being Mozilla&#x27;s fault nowadays.</div><br/></div></div></div></div></div></div><div id="41359874" class="c"><input type="checkbox" id="c-41359874" checked=""/><div class="controls bullet"><span class="by">threeseed</span><span>|</span><a href="#41359750">root</a><span>|</span><a href="#41359817">parent</a><span>|</span><a href="#41359942">prev</a><span>|</span><a href="#41360491">next</a><span>|</span><label class="collapse" for="c-41359874">[-]</label><label class="expand" for="c-41359874">[5 more]</label></div><br/><div class="children"><div class="content">&gt; it can be very reliable<p>You need to quantify this. With actual numbers.<p>I am getting very tired of seeing everyone pushing LLMs and being disingenuous about exactly how often it is getting things wrong. And what the impact of that is. There is a reason that AI is not taking off in the enterprise and that is because people who take their job seriously are getting tired too.</div><br/><div id="41361009" class="c"><input type="checkbox" id="c-41361009" checked=""/><div class="controls bullet"><span class="by">bicx</span><span>|</span><a href="#41359750">root</a><span>|</span><a href="#41359874">parent</a><span>|</span><a href="#41360491">next</a><span>|</span><label class="collapse" for="c-41361009">[-]</label><label class="expand" for="c-41361009">[4 more]</label></div><br/><div class="children"><div class="content">I understand your sentiment, but I also don&#x27;t think it&#x27;s fair to say people are being disingenuous. I don&#x27;t work for an AI company, I just use it with decent results.<p>My last project needed a way to tag certain types of business activity indicated in 17,000 user reviews. I wrote a prompt with 5 different tags along with descriptions for each business activity, took a few-shot approach by defining 8 different examples and how I would tag them, and then ran the tagging prompt on batches of indexed reviews, giving it 100 reviews per batch. I did a random sampling of about 200 items, and the success rate was roughly 89%. I could have improved it by doing more iterations, and possibly fine-tuning if I felt that it was worth it.<p>In every run, it generated matching results for the input JSON in a corresponding output JSON with no errors in any run.<p>That&#x27;s the only example I have numbers on off the top of my head.<p>EDIT: This was using `gpt-4o-2024-05-13`</div><br/><div id="41362866" class="c"><input type="checkbox" id="c-41362866" checked=""/><div class="controls bullet"><span class="by">deathanatos</span><span>|</span><a href="#41359750">root</a><span>|</span><a href="#41361009">parent</a><span>|</span><a href="#41362886">prev</a><span>|</span><a href="#41360491">next</a><span>|</span><label class="collapse" for="c-41362866">[-]</label><label class="expand" for="c-41362866">[2 more]</label></div><br/><div class="children"><div class="content">(Reader beware: basically everything the LLM emits in here is wrong.)<p>I was attempting to find formats that used a particular quoting style — SQL style double-the-character-to-espace — and bizarrely JSON came up.<p>Gemini:<p>&gt; <i>JSON: In JSON, double quotes are used to delimit strings. If a double quote needs to be included within the string itself, it&#x27;s escaped by doubling it (e.g., &quot;This is a string with a &quot;quote&quot; in it.&quot;).</i><p>That is,<p><pre><code>  &quot;This is a string with a &quot;quote&quot; in it.&quot;
</code></pre>
Me: <i>Does your JSON example parse as valid JSON?</i><p>Gemini:<p>&gt; <i>Yes, the JSON example I provided (&quot;This is a string with a &quot;quote&quot; in it.&quot;) is actually valid JSON.</i><p>&gt; <i>The reason it&#x27;s valid is because the doubled quote within the string is interpreted as an escaped character, representing a single literal quote within the string itself. The JSON parser recognizes the double quotes at the beginning and end as delimiters for the entire string, not the escaped quote within.</i><p>It also called out,<p>&gt; <i>XML: Use a backslash (\) to escape characters, including quotes.</i><p>In a different context, and more towards &quot;working with k8s&quot; that the OP&#x27;s AI is focused on,<p>Me: <i>Regex to extract the replica number from a statefulset pod&#x27;s name?</i><p>Gemini:<p>&gt; <i>Use kubectl: The kubectl get pods command with output formatting can directly show replica numbers. Here&#x27;s an example:</i><p><pre><code>  kubectl get pods -o jsonpath=&#x27;{.items[*].metadata.name}{&quot; - replica: &quot;}{.metadata.labels.replicaset-序号}&#x27;
</code></pre>
The Chinese here, as best as I can tell, reads &quot;serial number&quot; … which sort of contextually makes sense in the sense of an LLM, I guess. The command is utter nonsense, of course.</div><br/><div id="41364273" class="c"><input type="checkbox" id="c-41364273" checked=""/><div class="controls bullet"><span class="by">bicx</span><span>|</span><a href="#41359750">root</a><span>|</span><a href="#41362866">parent</a><span>|</span><a href="#41360491">next</a><span>|</span><label class="collapse" for="c-41364273">[-]</label><label class="expand" for="c-41364273">[1 more]</label></div><br/><div class="children"><div class="content">Gemini is apparently hot garbage. I passed this input into ChatGPT (GPT-4o) and I got sensible answers.</div><br/></div></div></div></div></div></div></div></div><div id="41360491" class="c"><input type="checkbox" id="c-41360491" checked=""/><div class="controls bullet"><span class="by">mplewis</span><span>|</span><a href="#41359750">root</a><span>|</span><a href="#41359817">parent</a><span>|</span><a href="#41359874">prev</a><span>|</span><a href="#41359849">next</a><span>|</span><label class="collapse" for="c-41360491">[-]</label><label class="expand" for="c-41360491">[1 more]</label></div><br/><div class="children"><div class="content">Every LLM conversation is guaranteed to contain some level of hallucination. You will never get the percentage down to zero.</div><br/></div></div></div></div><div id="41359849" class="c"><input type="checkbox" id="c-41359849" checked=""/><div class="controls bullet"><span class="by">wilson090</span><span>|</span><a href="#41359750">parent</a><span>|</span><a href="#41359817">prev</a><span>|</span><label class="collapse" for="c-41359849">[-]</label><label class="expand" for="c-41359849">[7 more]</label></div><br/><div class="children"><div class="content">We separated out the runbook such that each step is a separate LLM in the agent. Between each step, there&#x27;s sort of a &quot;supervisor&quot; that ensures that the step was completed correctly, and then routes to another step based on the results. So in reality, a single step failing requires two hallucinations. Hallucinations are also not a fixed percentage across all calls -- you can make them less likely by maintaining focused goals (this is why we made runbooks agentic rather than a single long conversation)</div><br/><div id="41360163" class="c"><input type="checkbox" id="c-41360163" checked=""/><div class="controls bullet"><span class="by">nerdjon</span><span>|</span><a href="#41359750">root</a><span>|</span><a href="#41359849">parent</a><span>|</span><a href="#41359918">next</a><span>|</span><label class="collapse" for="c-41360163">[-]</label><label class="expand" for="c-41360163">[2 more]</label></div><br/><div class="children"><div class="content">That second step hallucinating is far more likely when you are feeding it incorrect information from the first hallucination.<p>LLM&#x27;s are very easy to manipulate.<p>At one point with a system prompt telling Claude it was OpenAI, I was able to ask what its model is and it would confidently tell me it was OpenAI. Garbage data in, garbage data out.<p>Admittedly that is an extreme case, but you&#x27;re giving that second prompt wrong data in the hopes that it will identify it instead of just thinking it&#x27;s fine when it is part of its new context.</div><br/><div id="41360545" class="c"><input type="checkbox" id="c-41360545" checked=""/><div class="controls bullet"><span class="by">jtsaw</span><span>|</span><a href="#41359750">root</a><span>|</span><a href="#41360163">parent</a><span>|</span><a href="#41359918">next</a><span>|</span><label class="collapse" for="c-41360545">[-]</label><label class="expand" for="c-41360545">[1 more]</label></div><br/><div class="children"><div class="content">yea. We&#x27;re definitely concerned about hallucinations and are using a variety of techniques to try and mitigate it (there&#x27;s some existing discussion here, but using committees and sub-agents responsible for smaller tasks has helped).<p>What&#x27;s helped the most, though, is using cluster information to back up decision making. That way we know the data it&#x27;s considering isn&#x27;t garbage, and the outputs are backed up by actual data.</div><br/></div></div></div></div><div id="41359918" class="c"><input type="checkbox" id="c-41359918" checked=""/><div class="controls bullet"><span class="by">threeseed</span><span>|</span><a href="#41359750">root</a><span>|</span><a href="#41359849">parent</a><span>|</span><a href="#41360163">prev</a><span>|</span><label class="collapse" for="c-41359918">[-]</label><label class="expand" for="c-41359918">[4 more]</label></div><br/><div class="children"><div class="content">And what is your average error rate per runbook step.</div><br/><div id="41360082" class="c"><input type="checkbox" id="c-41360082" checked=""/><div class="controls bullet"><span class="by">jtsaw</span><span>|</span><a href="#41359750">root</a><span>|</span><a href="#41359918">parent</a><span>|</span><label class="collapse" for="c-41360082">[-]</label><label class="expand" for="c-41360082">[3 more]</label></div><br/><div class="children"><div class="content">one thing we&#x27;re experimenting to help with the hallucinations&#x2F;error rate issue is using a committee framework where we take a majority vote.<p>If the error rate of 1 expert is 5%, then for a committee of 10 experts, the probability a majority of the committee errors is around 0.00276% (binomial distribution with p=0.05). For 10 steps, this would be an error rate of 0.0276%</div><br/><div id="41360786" class="c"><input type="checkbox" id="c-41360786" checked=""/><div class="controls bullet"><span class="by">threeseed</span><span>|</span><a href="#41359750">root</a><span>|</span><a href="#41360082">parent</a><span>|</span><label class="collapse" for="c-41360786">[-]</label><label class="expand" for="c-41360786">[2 more]</label></div><br/><div class="children"><div class="content">Pretty bad maths there. Those committee members are not independent.<p>They are highly correlated even amongst LLMs from different vendors.</div><br/><div id="41361014" class="c"><input type="checkbox" id="c-41361014" checked=""/><div class="controls bullet"><span class="by">jtsaw</span><span>|</span><a href="#41359750">root</a><span>|</span><a href="#41360786">parent</a><span>|</span><label class="collapse" for="c-41361014">[-]</label><label class="expand" for="c-41361014">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not sure they are highly correlated. A committee uses the same LLM with the same input context to generate different outputs.  Given the same context LLMs should produce the same next token output distribution (assuming fixed model parameters, temperature, etc). So, while tokens in a specific output are highly correlated, complete outputs should be independent since they are generated independently from the same distribution. You are right they are not iid but the calculation was just a simplification.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></body></html>