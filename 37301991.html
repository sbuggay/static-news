<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1693299664915" as="style"/><link rel="stylesheet" href="styles.css?v=1693299664915"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://webllm.mlc.ai/">WebLLM: Llama2 in the Browser</a> <span class="domain">(<a href="https://webllm.mlc.ai">webllm.mlc.ai</a>)</span></div><div class="subtext"><span>meiraleal</span> | <span>17 comments</span></div><br/><div><div id="37303229" class="c"><input type="checkbox" id="c-37303229" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#37303540">next</a><span>|</span><label class="collapse" for="c-37303229">[-]</label><label class="expand" for="c-37303229">[4 more]</label></div><br/><div class="children"><div class="content">I ran Llama 2 70B in my browser (Chrome Canary on a 64GB MacBook M2) using this. It took a long time to start running, but then:<p>prefill: 0.9654 tokens&#x2F;sec, decoding: 3.2589 tokens&#x2F;sec<p>Honestly amazed that this is even possible. I haven&#x27;t even run Llama 2 70B on my laptop NOT using a web browser yet.</div><br/><div id="37304413" class="c"><input type="checkbox" id="c-37304413" checked=""/><div class="controls bullet"><span class="by">muskmusk</span><span>|</span><a href="#37303229">parent</a><span>|</span><a href="#37304432">next</a><span>|</span><label class="collapse" for="c-37304413">[-]</label><label class="expand" for="c-37304413">[2 more]</label></div><br/><div class="children"><div class="content">That is impressive. Interesting that the prefill (i am guessing this is prompt processing) is so much slower than decoding.<p>Its my understanding that under normal circumstances decoding is memory bandwidth bound which prompt processing isn&#x27;t due to batching. Is there some quirk in your setup?</div><br/><div id="37304618" class="c"><input type="checkbox" id="c-37304618" checked=""/><div class="controls bullet"><span class="by">larrysalibra</span><span>|</span><a href="#37303229">root</a><span>|</span><a href="#37304413">parent</a><span>|</span><a href="#37304432">next</a><span>|</span><label class="collapse" for="c-37304618">[-]</label><label class="expand" for="c-37304618">[1 more]</label></div><br/><div class="children"><div class="content">Strange. I&#x27;m running Llama2 70b on Chrome Canary on a 64GB MacBook M1 Max...~1.5 older...and seeing better performance.<p>It&#x27;s slow but usable!<p>prefill: 2.1963 tokens&#x2F;sec, decoding: 3.4708 tokens&#x2F;sec</div><br/></div></div></div></div><div id="37304432" class="c"><input type="checkbox" id="c-37304432" checked=""/><div class="controls bullet"><span class="by">3abiton</span><span>|</span><a href="#37303229">parent</a><span>|</span><a href="#37304413">prev</a><span>|</span><a href="#37303540">next</a><span>|</span><label class="collapse" for="c-37304432">[-]</label><label class="expand" for="c-37304432">[1 more]</label></div><br/><div class="children"><div class="content">This is a crazy good performance!</div><br/></div></div></div></div><div id="37303540" class="c"><input type="checkbox" id="c-37303540" checked=""/><div class="controls bullet"><span class="by">dmarcos</span><span>|</span><a href="#37303229">prev</a><span>|</span><a href="#37304329">next</a><span>|</span><label class="collapse" for="c-37303540">[-]</label><label class="expand" for="c-37303540">[3 more]</label></div><br/><div class="children"><div class="content">Related. I built karpathy’s llama2.c (<a href="https:&#x2F;&#x2F;github.com&#x2F;karpathy&#x2F;llama2.c">https:&#x2F;&#x2F;github.com&#x2F;karpathy&#x2F;llama2.c</a>) without modifications to WASM and run it in the browser. It was a fun exercise to directly compare native vs. Web perf. Getting 80% of native performance on my M1 Macbook Air and haven’t spent anytime optimizing the WASM side.<p>Demo: <a href="https:&#x2F;&#x2F;diegomarcos.com&#x2F;llama2.c-web&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;diegomarcos.com&#x2F;llama2.c-web&#x2F;</a><p>Code:
<a href="https:&#x2F;&#x2F;github.com&#x2F;dmarcos&#x2F;llama2.c-web">https:&#x2F;&#x2F;github.com&#x2F;dmarcos&#x2F;llama2.c-web</a></div><br/><div id="37303595" class="c"><input type="checkbox" id="c-37303595" checked=""/><div class="controls bullet"><span class="by">TheRoque</span><span>|</span><a href="#37303540">parent</a><span>|</span><a href="#37304329">next</a><span>|</span><label class="collapse" for="c-37303595">[-]</label><label class="expand" for="c-37303595">[2 more]</label></div><br/><div class="children"><div class="content">Thanks a lot for this ! I was looking for the equivalent of  WebLLM that runs on CPU only.</div><br/><div id="37303601" class="c"><input type="checkbox" id="c-37303601" checked=""/><div class="controls bullet"><span class="by">dmarcos</span><span>|</span><a href="#37303540">root</a><span>|</span><a href="#37303595">parent</a><span>|</span><a href="#37304329">next</a><span>|</span><label class="collapse" for="c-37303601">[-]</label><label class="expand" for="c-37303601">[1 more]</label></div><br/><div class="children"><div class="content">You’re welcome. Any feedback and contributions super appreciated</div><br/></div></div></div></div></div></div><div id="37304329" class="c"><input type="checkbox" id="c-37304329" checked=""/><div class="controls bullet"><span class="by">jankovicsandras</span><span>|</span><a href="#37303540">prev</a><span>|</span><a href="#37304282">next</a><span>|</span><label class="collapse" for="c-37304329">[-]</label><label class="expand" for="c-37304329">[1 more]</label></div><br/><div class="children"><div class="content">Cool. Nice example of Atwood&#x27;s Law. [0] (however not really JS of course)<p>If somebody hasn&#x27;t tried running LLMs yet, here are some lines that do the job in Google Colab or locally.<p><pre><code>  ! git clone https:&#x2F;&#x2F;github.com&#x2F;ggerganov&#x2F;llama.cpp.git

  ! wget &quot;https:&#x2F;&#x2F;huggingface.co&#x2F;TheBloke&#x2F;CodeLlama-7B-GGUF&#x2F;resolve&#x2F;main&#x2F;codellama-7b.Q8_0.gguf&quot; -P llama.cpp&#x2F;models

  ! cd llama.cpp &amp;&amp; make

  ! .&#x2F;llama.cpp&#x2F;main -m .&#x2F;llama.cpp&#x2F;models&#x2F;codellama-7b.Q8_0.gguf --color --ctx_size 2048 -n -1 -ins -b 256 --top_k 10000 --temp 0.2 --repeat_penalty 1.1 -t 8

</code></pre>
[0] : <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Atwood&#x27;s_Law" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Atwood&#x27;s_Law</a></div><br/></div></div><div id="37304282" class="c"><input type="checkbox" id="c-37304282" checked=""/><div class="controls bullet"><span class="by">gvv</span><span>|</span><a href="#37304329">prev</a><span>|</span><a href="#37303850">next</a><span>|</span><label class="collapse" for="c-37304282">[-]</label><label class="expand" for="c-37304282">[2 more]</label></div><br/><div class="children"><div class="content">great but wth is wrong with it <a href="https:&#x2F;&#x2F;i.imgur.com&#x2F;gWIilWU.png" rel="nofollow noreferrer">https:&#x2F;&#x2F;i.imgur.com&#x2F;gWIilWU.png</a></div><br/><div id="37304538" class="c"><input type="checkbox" id="c-37304538" checked=""/><div class="controls bullet"><span class="by">littlestymaar</span><span>|</span><a href="#37304282">parent</a><span>|</span><a href="#37303850">next</a><span>|</span><label class="collapse" for="c-37304538">[-]</label><label class="expand" for="c-37304538">[1 more]</label></div><br/><div class="children"><div class="content">I suspect they&#x27;ve trained it on old stories on which they added this caveat, and now “once upon a time” became tightly coupled to the caveat in the model.</div><br/></div></div></div></div><div id="37303850" class="c"><input type="checkbox" id="c-37303850" checked=""/><div class="controls bullet"><span class="by">modeless</span><span>|</span><a href="#37304282">prev</a><span>|</span><a href="#37303568">next</a><span>|</span><label class="collapse" for="c-37303850">[-]</label><label class="expand" for="c-37303850">[4 more]</label></div><br/><div class="children"><div class="content">How do they load 70B weights with the ~4GB heap limit of JS&#x2F;WASM?</div><br/><div id="37304265" class="c"><input type="checkbox" id="c-37304265" checked=""/><div class="controls bullet"><span class="by">andy_ppp</span><span>|</span><a href="#37303850">parent</a><span>|</span><a href="#37304238">next</a><span>|</span><label class="collapse" for="c-37304265">[-]</label><label class="expand" for="c-37304265">[2 more]</label></div><br/><div class="children"><div class="content">It uses WebGPU which I’m guessing is allocated differently than the 4gb limit?</div><br/><div id="37304758" class="c"><input type="checkbox" id="c-37304758" checked=""/><div class="controls bullet"><span class="by">modeless</span><span>|</span><a href="#37303850">root</a><span>|</span><a href="#37304265">parent</a><span>|</span><a href="#37304238">next</a><span>|</span><label class="collapse" for="c-37304758">[-]</label><label class="expand" for="c-37304758">[1 more]</label></div><br/><div class="children"><div class="content">WebGPU doesn&#x27;t ingest data directly, it always goes through JS&#x2F;WASM. Presumably they are streaming the data in small chunks through into WebGPU. I could imagine several ways of doing it, but sometimes in browsers, things that ought to work don&#x27;t, so a demonstrated working method would be interesting to know about, if someone can locate the actual code that does it. (Also, it&#x27;s pretty silly that you can allocate far more VRAM than RAM on the web platform.)</div><br/></div></div></div></div></div></div><div id="37303568" class="c"><input type="checkbox" id="c-37303568" checked=""/><div class="controls bullet"><span class="by">jecvay</span><span>|</span><a href="#37303850">prev</a><span>|</span><label class="collapse" for="c-37303568">[-]</label><label class="expand" for="c-37303568">[2 more]</label></div><br/><div class="children"><div class="content">*GTX 1650* prefill: 5.2211 tokens&#x2F;sec, decoding: 0.4233 tokens&#x2F;sec</div><br/><div id="37303783" class="c"><input type="checkbox" id="c-37303783" checked=""/><div class="controls bullet"><span class="by">teaearlgraycold</span><span>|</span><a href="#37303568">parent</a><span>|</span><label class="collapse" for="c-37303783">[-]</label><label class="expand" for="c-37303783">[1 more]</label></div><br/><div class="children"><div class="content">What model variant?</div><br/></div></div></div></div></div></div></div></div></div></body></html>