<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1726390867081" as="style"/><link rel="stylesheet" href="styles.css?v=1726390867081"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://mathstodon.xyz/@tao/113132502735585408">Terence Tao on O1</a> <span class="domain">(<a href="https://mathstodon.xyz">mathstodon.xyz</a>)</span></div><div class="subtext"><span>dselsam</span> | <span>338 comments</span></div><br/><div><div id="41541372" class="c"><input type="checkbox" id="c-41541372" checked=""/><div class="controls bullet"><span class="by">wenc</span><span>|</span><a href="#41542863">next</a><span>|</span><label class="collapse" for="c-41541372">[-]</label><label class="expand" for="c-41541372">[169 more]</label></div><br/><div class="children"><div class="content">Once GPT is tuned more heavily on Lean (proof assistant) -- the way it is on Python -- I expect its usefulness for research level math to increase.<p>I work in a field related to operations research (OR), and ChatGPT 4o has ingested enough of the OR literature that it&#x27;s able to spit out very useful Mixed Integer Programming (MIP) formulations for many &quot;problem shapes&quot;. For instance, I can give it a logic problem like &quot;i need to put i items in n buckets based on a score, but I want to fill each bucket sequentially&quot; and it actually spits out a very usable math formulation.  I usually just need to tweak it a bit. It also warns against weak formulations where the logic might fail, which is tremendously useful for avoiding pitfalls. Compare this to the old way, which is to rack my brain over a weekend to figure out a water-tight formulation of MIP optimization problem (which is often not straightforward for non-intuitive problems). GPT has saved me so much time in this corner of my world.<p>Yes, you probably wouldn&#x27;t be able to use ChatGPT well for this purpose unless you understood MIP optimization in the first place -- and you do need to break down the problem into smaller chunks so GPT can reason in steps --  but for someone who can and does, the $20&#x2F;month I pay for ChatGPT more than pays for itself.<p>side: a lot of people who complain on HN that (paid&#x2F;good - only Sonnet 3.5 and GPT4o are in this category) LLMs are useless to them probably (1) do not know how to use LLMs in way that maximizes their strengths; (2) have expectations that are too high based on the hype, expecting one-shot magic bullets. (3) LLMs are really not good for their domain. But many of the low-effort comments seem to mostly fall into (1) and (2) -- cynicism rather than cautious optimism.<p>Many of us who have discovered how to exploit LLMs in their areas of strength -- and know how to check for their mistakes --  often find them providing significant leverage in our work.</div><br/><div id="41541754" class="c"><input type="checkbox" id="c-41541754" checked=""/><div class="controls bullet"><span class="by">WhatIsDukkha</span><span>|</span><a href="#41541372">parent</a><span>|</span><a href="#41544372">next</a><span>|</span><label class="collapse" for="c-41541754">[-]</label><label class="expand" for="c-41541754">[133 more]</label></div><br/><div class="children"><div class="content">I entirely agree about their utility.<p>HN, and the internet in general, have become just an ocean of reactionary sandbagging and blather about how &quot;useless&quot; LLMs are.<p>Meanwhile, in the real world, I&#x27;ve found that I haven&#x27;t written a line of code in weeks. Just paragraphs of text that specify what I want and then guidance through and around pitfalls in a simple iterative loop of useful working code.<p>It&#x27;s entirely a learned skill, the models (and very importantly the tooling around them) have arrived at the base line they needed.<p>Much Much more productive world by just knuckling down and learning how to do the work.<p>edit: <a href="https:&#x2F;&#x2F;aider.chat&#x2F;" rel="nofollow">https:&#x2F;&#x2F;aider.chat&#x2F;</a> + paid 3.5 sonnet</div><br/><div id="41542031" class="c"><input type="checkbox" id="c-41542031" checked=""/><div class="controls bullet"><span class="by">skydhash</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41541754">parent</a><span>|</span><a href="#41542852">next</a><span>|</span><label class="collapse" for="c-41542031">[-]</label><label class="expand" for="c-41542031">[36 more]</label></div><br/><div class="children"><div class="content">&gt; <i>Much Much more productive world by just knuckling down and learning how to do the work.</i><p>The fact everyone that say they&#x27;ve become more productive with LLMs won&#x27;t say how exactly. I can talk about how VIM have make it more enjoyable to edit code (keybinding and motions), how Emacs is a good environment around text tooling (lisp machine), how I use technical books to further my learning (so many great books out here). But no one really show how they&#x27;re actually solving problems with LLMs and how the alternatives were worse for them. It&#x27;s all claims that it&#x27;s great with no further elaboration on the workflows.<p>&gt; <i>I haven&#x27;t written a line of code in weeks. Just paragraphs of text that specify what I want and then guidance through and around pitfalls in a simple iterative loop of useful working code.</i><p>Code is intent described in terms of machinery actions. Those actions can be masked by abstracting them in more understandable units, so we don&#x27;t have to write opcodes, but we can use python instead. Programming is basically make the intent clear enough so that we know what units we can use. Software engineering is mostly selecting the units in a way to do minimal work once the intent changes or the foundational actions do.<p>Chatting with a LLM look to me like your intent is either vague or you don&#x27;t know the units to use. If it&#x27;s the former, then I guess you&#x27;re assuming it is the expert and will guide you to the solution you seek, which means you believe it understands the problem more than you do. The second is more strange as it looks like playing around with car parts, while ignoring the manuals it comes with.<p>What about boilerplate and common scenarios? I agree that LLMs helps a great deal with that, but the fact is that there are perfectly good tools that helped with that like snippets, templates, and code generators.</div><br/><div id="41542244" class="c"><input type="checkbox" id="c-41542244" checked=""/><div class="controls bullet"><span class="by">Nadya</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41542031">parent</a><span>|</span><a href="#41542327">next</a><span>|</span><label class="collapse" for="c-41542244">[-]</label><label class="expand" for="c-41542244">[10 more]</label></div><br/><div class="children"><div class="content">Ever seen someone try and search something on Google and they are just AWFUL at it? They can never find what they&#x27;re looking for and then you try and can pull it up in a single search? That&#x27;s what it is like watching some people try to use LLM&#x27;s. Learning how to prompt an LLM is as much a learned skill as much as learning how to phrase internet searches is a learned skill. And as much as people decried that &quot;searching Google isn&#x27;t a real skill&quot; tech-savvy people knew better.<p>Same thing except now it&#x27;s also many tech-savvy people joining in with the tech-unsavvy in saying that prompting isn&#x27;t a real skill...but people who know better know that it is.<p>On average, people are awfully bad at describing exactly what it is they want. Ever speak with a client? And you have to go back and forward for a few hours to finally figure out what it is they wanted? In that scenario you&#x27;re the LLM. Except the LLM won&#x27;t keep asking probing questions and clarifications - it will simply give them what they originally asked for (which isn&#x27;t what they want). Then they think the LLM is stupid and stop trying to ask it for things.<p>Utilizing an LLM to its full potential is a lot of iterative work and, at least for the time being, requires having some understanding of how it works underneath the hood (eg. would you get better results by starting a new session or asking it to forget previous, poorly worded instructions?).</div><br/><div id="41542607" class="c"><input type="checkbox" id="c-41542607" checked=""/><div class="controls bullet"><span class="by">skydhash</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41542244">parent</a><span>|</span><a href="#41542421">next</a><span>|</span><label class="collapse" for="c-41542607">[-]</label><label class="expand" for="c-41542607">[6 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not arguing that you can&#x27;t get result with LLMs, I&#x27;m just asking is it worth the actual effort especially when there&#x27;s better way to get that result you&#x27;re seeking (or if the result is really something that you want).<p>An LLM is a word (token?) generator which can be amazingly consistent according to its model. But rarely is my end goal to generate text. It&#x27;s either to do something, to understand something, or to communicate. For the first, there are guides (books, manuals, ...), for the second, there are explanations (again books, manuals,...), and the third is just using language to communicate what&#x27;s on my mind.<p>That&#x27;s the same thing with search engines. I use them to look for something. What I need first is a description of that something, not how to do the &quot;looking for&quot;. Then once you know what you want to find, it&#x27;s easier to use the tool to find it.<p>If your end goal can be achieved with LLMs, be my guest to use them. But, I&#x27;m wary of people taking them at face value and then pushing the workload unto everyone else (like developers using electron).</div><br/><div id="41543833" class="c"><input type="checkbox" id="c-41543833" checked=""/><div class="controls bullet"><span class="by">Nadya</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41542607">parent</a><span>|</span><a href="#41543377">next</a><span>|</span><label class="collapse" for="c-41543833">[-]</label><label class="expand" for="c-41543833">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s hard to quantify how much time learning how to search saves because the difference can range between infinite (finding the result vs not finding it at all) to basically no difference (1st result vs 2nd result). I think many people agree it is worth learning how to &quot;properly search&quot; though. You spend much less time searching and you get the results you&#x27;re looking for much more often. This applies outside of just Google search: learning how to find and lookup information is a useful skill in and of itself.<p>ChatGPT has helped me write some scripts for things that otherwise probably would have taken me at least 30+ minutes and it wrote them in &lt;10 seconds and they worked flawlessly. I&#x27;ve also had times where I worked with it to develop something that ended up taking me 45 minutes to only ever get error-ridden code that I had to fix the obvious errors and rewrite parts of it to get it working. Sometimes during this process it actually has taught me a new approach to doing something. If I had started from scratch coding it by myself it probably would have taken me only 10~ minutes. But if I was better at prompting what if that 45 minutes was &lt;10 minutes? It would go from from a time loss to a time save and be worth using. So improving my ability to prompt is worthwhile as long as doing so trends towards me spending less time prompting.<p>Which is thankfully pretty easy to track and test. On average, as I get better at prompting, do I need to spend more or less time prompting to get the results I am looking for? The answer to that is largely that I spend less time and get better results. The models constantly changing and improving over time can make this messy - is it the model getting better or is it my prompting? But I don&#x27;t think models change significantly enough to rule out that I spend less time prompting than I have in the past.</div><br/><div id="41544712" class="c"><input type="checkbox" id="c-41544712" checked=""/><div class="controls bullet"><span class="by">panarky</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41543833">parent</a><span>|</span><a href="#41543377">next</a><span>|</span><label class="collapse" for="c-41544712">[-]</label><label class="expand" for="c-41544712">[1 more]</label></div><br/><div class="children"><div class="content">&gt; how much time learning how to search saves<p>&gt;&gt;&gt; you do need to break down the problem into smaller chunks so GPT can reason in steps<p>To search well, you need good intuition for how to select the right search terms.<p>To LLM well, you can ask the LLM to break the problem into smaller chunks, and then have the LLM solve each chunk, and then have the LLM check its work for errors and inconsistencies.<p>And then you can have the LLM write you a program to orchestrate all of those steps.</div><br/></div></div></div></div><div id="41543377" class="c"><input type="checkbox" id="c-41543377" checked=""/><div class="controls bullet"><span class="by">smallnamespace</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41542607">parent</a><span>|</span><a href="#41543833">prev</a><span>|</span><a href="#41542896">next</a><span>|</span><label class="collapse" for="c-41543377">[-]</label><label class="expand" for="c-41543377">[1 more]</label></div><br/><div class="children"><div class="content">&gt; asking is it worth the actual effort<p>If prompting ability varies then this is not some objective question, it depends on each person.<p>For me I&#x27;ve found more or less every interaction with an LLM to be useful. The only reason I&#x27;m not using it continually for 8 hours a day is because my brain is not able to usefully manage that torrent of new information and I need downtime.</div><br/></div></div><div id="41542896" class="c"><input type="checkbox" id="c-41542896" checked=""/><div class="controls bullet"><span class="by">rvnx</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41542607">parent</a><span>|</span><a href="#41543377">prev</a><span>|</span><a href="#41542421">next</a><span>|</span><label class="collapse" for="c-41542896">[-]</label><label class="expand" for="c-41542896">[2 more]</label></div><br/><div class="children"><div class="content">It works quite nicely if you consider LLMs as a translator (and that’s actually why Transformers were created).<p>Enter technical specifications in English as input language, get code as destination language.</div><br/><div id="41543771" class="c"><input type="checkbox" id="c-41543771" checked=""/><div class="controls bullet"><span class="by">lolc</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41542896">parent</a><span>|</span><a href="#41542421">next</a><span>|</span><label class="collapse" for="c-41543771">[-]</label><label class="expand" for="c-41543771">[1 more]</label></div><br/><div class="children"><div class="content">English as input language works in simple scenarios but breaks down very very quickly. I have to get extremely specific and deliberate. At some point I have to write pseudocode to get the machine to get say double checked locking right. Because I have enough experiences where varying the prompting didn&#x27;t work, I revert to just writing the code when I see the generator struggling.<p>When I encounter somebody who says they do not write code anymore, I assume that they either:<p>1. Just don&#x27;t do anything beyond the simplest tutorial-level stuff<p>2. or don&#x27;t consider their post-generation edits as writing code<p>3. or are just bullshitting<p>I don&#x27;t know which it is for each person in question, but I don&#x27;t trust that their story would work for me. I don&#x27;t believe they have some secret sauce prompting that works for scenarios where I&#x27;ve tried to make it work but couldn&#x27;t. Sure I may have missed some ways, but my map of what works and what doesn&#x27;t may be very blurry at the border, but the surprises tend to be on the &quot;doesn&#x27;t work&quot; side. And no Claude doesn&#x27;t change this.</div><br/></div></div></div></div></div></div><div id="41542421" class="c"><input type="checkbox" id="c-41542421" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41542244">parent</a><span>|</span><a href="#41542607">prev</a><span>|</span><a href="#41542327">next</a><span>|</span><label class="collapse" for="c-41542421">[-]</label><label class="expand" for="c-41542421">[3 more]</label></div><br/><div class="children"><div class="content">&gt; On average, people are awfully bad at describing exactly what it is they want. Ever speak with a client? And you have to go back and forward for a few hours to finally figure out what it is they wanted?<p>One of them it was the entire duration of me working for them.<p>They didn&#x27;t understand why it was taking so long despite constantly changing what they asked for.</div><br/><div id="41543387" class="c"><input type="checkbox" id="c-41543387" checked=""/><div class="controls bullet"><span class="by">codr7</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41542421">parent</a><span>|</span><a href="#41542327">next</a><span>|</span><label class="collapse" for="c-41543387">[-]</label><label class="expand" for="c-41543387">[2 more]</label></div><br/><div class="children"><div class="content">Building the software is usually like 10% of the actual job, we could do a better job of teaching that.<p>The other 90% is mostly mushy human stuff, fleshing out the problem, setting expectations etc. Helping a group of people reach a solution everyone is happy with has little to do with technology.</div><br/><div id="41545542" class="c"><input type="checkbox" id="c-41545542" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41543387">parent</a><span>|</span><a href="#41542327">next</a><span>|</span><label class="collapse" for="c-41545542">[-]</label><label class="expand" for="c-41545542">[1 more]</label></div><br/><div class="children"><div class="content">Mostly agree. Until ChatGPT, I&#x27;d have agreed with all of that.<p>&gt; Helping a group of people reach a solution everyone is happy with has little to do with technology.<p>This one specific thing, is actually something that ChatGPT can help with.<p>It&#x27;s not as good as the best human, or even a middling human with 5 year&#x27;s business experience, but rather it&#x27;s useful because it&#x27;s good enough at so many different domains that it can be used to clarify thoughts and explain the boundaries of the possible — Google Translate for business jargon, though like Google Translate it is also still often wrong — the ultimate &quot;jack of all trades, master of none&quot;.</div><br/></div></div></div></div></div></div></div></div><div id="41542327" class="c"><input type="checkbox" id="c-41542327" checked=""/><div class="controls bullet"><span class="by">pbrowne011</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41542031">parent</a><span>|</span><a href="#41542244">prev</a><span>|</span><a href="#41543575">next</a><span>|</span><label class="collapse" for="c-41542327">[-]</label><label class="expand" for="c-41542327">[7 more]</label></div><br/><div class="children"><div class="content">&gt; But no one really show how they&#x27;re actually solving problems with LLMs and how the alternatives were worse for them. It&#x27;s all claims that it&#x27;s great with no further elaboration on the workflows.<p>To give an example, one person (a researcher at DeepMind) recently wrote about specific instances of his uses of LLMs, with anecdotes about alternatives to each example. [1] People on HN had different responses with similar claims with elaborations on how it has changed some of their workflows. [2]<p>While it would be interesting to see randomized controlled trials on LLM usage, hearing people&#x27;s anecdotes brings to mind the (often misquoted) phrase: &quot;The plural of anecdote is data&quot;. [3] [4]<p>[1] <a href="https:&#x2F;&#x2F;nicholas.carlini.com&#x2F;writing&#x2F;2024&#x2F;how-i-use-ai.html" rel="nofollow">https:&#x2F;&#x2F;nicholas.carlini.com&#x2F;writing&#x2F;2024&#x2F;how-i-use-ai.html</a><p>[2] <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=41150317">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=41150317</a><p>[3] <a href="http:&#x2F;&#x2F;blog.danwin.com&#x2F;don-t-forget-the-plural-of-anecdote-is-data&#x2F;" rel="nofollow">http:&#x2F;&#x2F;blog.danwin.com&#x2F;don-t-forget-the-plural-of-anecdote-i...</a><p>[4] originally misquoted as &quot;Anecdote is the plural of data.&quot;</div><br/><div id="41542536" class="c"><input type="checkbox" id="c-41542536" checked=""/><div class="controls bullet"><span class="by">kristianp</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41542327">parent</a><span>|</span><a href="#41543441">next</a><span>|</span><label class="collapse" for="c-41542536">[-]</label><label class="expand" for="c-41542536">[5 more]</label></div><br/><div class="children"><div class="content">&gt; (often misquoted) phrase<p>You misquoted it there! It should be: The plural of anecdote is data.</div><br/><div id="41543074" class="c"><input type="checkbox" id="c-41543074" checked=""/><div class="controls bullet"><span class="by">pbrowne011</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41542536">parent</a><span>|</span><a href="#41542987">next</a><span>|</span><label class="collapse" for="c-41543074">[-]</label><label class="expand" for="c-41543074">[1 more]</label></div><br/><div class="children"><div class="content">Thank you! Another instance of a variant of Muphry&#x27;s Law.<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Muphry&#x27;s_law" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Muphry&#x27;s_law</a></div><br/></div></div><div id="41542987" class="c"><input type="checkbox" id="c-41542987" checked=""/><div class="controls bullet"><span class="by">stavros</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41542536">parent</a><span>|</span><a href="#41543074">prev</a><span>|</span><a href="#41543441">next</a><span>|</span><label class="collapse" for="c-41542987">[-]</label><label class="expand" for="c-41542987">[3 more]</label></div><br/><div class="children"><div class="content">It&#x27;s actually &quot;the plural of &#x27;anecdote&#x27; is not &#x27;data&#x27;&quot;.</div><br/><div id="41543056" class="c"><input type="checkbox" id="c-41543056" checked=""/><div class="controls bullet"><span class="by">kristianp</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41542987">parent</a><span>|</span><a href="#41543441">next</a><span>|</span><label class="collapse" for="c-41543056">[-]</label><label class="expand" for="c-41543056">[2 more]</label></div><br/><div class="children"><div class="content">Apparently what you&#x27;ve said is the most common misquotation.  See [3] above.</div><br/><div id="41543113" class="c"><input type="checkbox" id="c-41543113" checked=""/><div class="controls bullet"><span class="by">stavros</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41543056">parent</a><span>|</span><a href="#41543441">next</a><span>|</span><label class="collapse" for="c-41543113">[-]</label><label class="expand" for="c-41543113">[1 more]</label></div><br/><div class="children"><div class="content">Oh interesting, thanks! I much prefer that formulation.</div><br/></div></div></div></div></div></div></div></div><div id="41543441" class="c"><input type="checkbox" id="c-41543441" checked=""/><div class="controls bullet"><span class="by">kristianp</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41542327">parent</a><span>|</span><a href="#41542536">prev</a><span>|</span><a href="#41543575">next</a><span>|</span><label class="collapse" for="c-41543441">[-]</label><label class="expand" for="c-41543441">[1 more]</label></div><br/><div class="children"><div class="content">In the CUDA example [1] from carlini&#x27;s &quot;how I Use AI&quot;, I would guess that o1 would need less handholding to do what he wanted.<p>[1] <a href="https:&#x2F;&#x2F;chatgpt.com&#x2F;share&#x2F;1ead532d-3bd5-47c2-897c-2d77a3896427" rel="nofollow">https:&#x2F;&#x2F;chatgpt.com&#x2F;share&#x2F;1ead532d-3bd5-47c2-897c-2d77a38964...</a></div><br/></div></div></div></div><div id="41543575" class="c"><input type="checkbox" id="c-41543575" checked=""/><div class="controls bullet"><span class="by">sweeter</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41542031">parent</a><span>|</span><a href="#41542327">prev</a><span>|</span><a href="#41543848">next</a><span>|</span><label class="collapse" for="c-41543575">[-]</label><label class="expand" for="c-41543575">[5 more]</label></div><br/><div class="children"><div class="content">Or people say &quot;I&#x27;ve been pumping out thousands of lines of perfectly good code by writing paragraphs and paragraphs of text explaining what I want!&quot; its like what are you programming dog? and they will never tell you, and then you look at their github and its like a dead simple starter project.<p>I recently built a Brainfuck compiler and TUI debugger and I tested out a few LLM&#x27;s just to see if I could get some useful output regarding a few niche and complicated issues, and it just gave me garbage that looked mildly correct. Then I&#x27;m told its because I&#x27;m not prompting hard enough... I&#x27;d rather just learn how to do it at that point. Once I solve that problem, I can solve it again in the future in .25x the time.</div><br/><div id="41544005" class="c"><input type="checkbox" id="c-41544005" checked=""/><div class="controls bullet"><span class="by">rtsil</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41543575">parent</a><span>|</span><a href="#41544536">next</a><span>|</span><label class="collapse" for="c-41544005">[-]</label><label class="expand" for="c-41544005">[1 more]</label></div><br/><div class="children"><div class="content">Here&#x27;s the thing. 99% of people aren&#x27;t writing compilers or debuggers, they&#x27;re writing glorified CRUDs. LLM can save a lot of time for these people, just like 99% of people only use basic arithmetic operations, and MS Excel saves a lot of time for these people. It&#x27;s not about solving new problems, it&#x27;s about solving old and known problems very fast.</div><br/></div></div><div id="41544536" class="c"><input type="checkbox" id="c-41544536" checked=""/><div class="controls bullet"><span class="by">williamcotton</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41543575">parent</a><span>|</span><a href="#41544005">prev</a><span>|</span><a href="#41543770">next</a><span>|</span><label class="collapse" for="c-41544536">[-]</label><label class="expand" for="c-41544536">[1 more]</label></div><br/><div class="children"><div class="content">This is almost entirely written by LLMs:<p><a href="https:&#x2F;&#x2F;github.com&#x2F;williamcotton&#x2F;guish">https:&#x2F;&#x2F;github.com&#x2F;williamcotton&#x2F;guish</a><p>I was the driver. I told it to parse and operate on the AST, to use a plugin pattern to reduce coupling, etc. The machine did the tippy-taps for me and at a much faster rate than I could ever dream of typing!<p>It’s all in a Claude Project and can easily and reliably create new modules for bash commands because it has the full scope of the system in context and a ginormous amount of bash commands and TypeScript in the training corpus.</div><br/></div></div><div id="41543770" class="c"><input type="checkbox" id="c-41543770" checked=""/><div class="controls bullet"><span class="by">KHRZ</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41543575">parent</a><span>|</span><a href="#41544536">prev</a><span>|</span><a href="#41545152">next</a><span>|</span><label class="collapse" for="c-41543770">[-]</label><label class="expand" for="c-41543770">[1 more]</label></div><br/><div class="children"><div class="content">One good use case is unit tests, since they can be trivial while at the same time being cumbersome to make. I could give the LLM code for React components, and it would make the tests and setup all the mocks which is the most annoying part. Although making &quot;all the tests&quot; will typically involve asking the LLM again to think of more edge cases and be sure to cover everything.</div><br/></div></div><div id="41545152" class="c"><input type="checkbox" id="c-41545152" checked=""/><div class="controls bullet"><span class="by">remoroid</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41543575">parent</a><span>|</span><a href="#41543770">prev</a><span>|</span><a href="#41543848">next</a><span>|</span><label class="collapse" for="c-41545152">[-]</label><label class="expand" for="c-41545152">[1 more]</label></div><br/><div class="children"><div class="content">Really? Come on. You think trying to make it solve &quot;niche and complicated issues&quot; for a Brainfuck compiler is reasonable? I can&#x27;t take this seriously. Do you know what most developer jobs entail?<p>I never need to type paragraphs to get the output I want. I don&#x27;t even bother with correct grammar or spelling. If I need code for x crud web app who is going to type it faster, me or the LLM? This is really not hard to understand.</div><br/></div></div></div></div><div id="41543848" class="c"><input type="checkbox" id="c-41543848" checked=""/><div class="controls bullet"><span class="by">px1999</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41542031">parent</a><span>|</span><a href="#41543575">prev</a><span>|</span><a href="#41546215">next</a><span>|</span><label class="collapse" for="c-41543848">[-]</label><label class="expand" for="c-41543848">[1 more]</label></div><br/><div class="children"><div class="content">Specifically within the last week, I have used Claude and Claude via cursor to:<p>- write some moderately complex powershell to perform a one-off process<p>- add typescript annotations to a random file in my org&#x27;s codebase<p>- land a minor feature quickly in another codebase<p>- suggest libraries and write sample(ish) code to see what their rough use would look like to help choose between them for a future feature design<p>- provide text to fill out an extensive sales RFT spreadsheet based on notes and some RAG<p>- generat some very domain-specific realistic sounding test data (just naming)<p>- scaffold out some PowerPoint slides for a training session<p>There are likely others (LLMs have helped with research and in my personal life too)<p>All of these are things that I could do (and probably do better) but I have a young baby at the moment and the situation means that my focus windows are small and I&#x27;m time poor. With this workflow I&#x27;m achieving more than I was when I had fully uninterrupted time.</div><br/></div></div><div id="41546215" class="c"><input type="checkbox" id="c-41546215" checked=""/><div class="controls bullet"><span class="by">NetOpWibby</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41542031">parent</a><span>|</span><a href="#41543848">prev</a><span>|</span><a href="#41542359">next</a><span>|</span><label class="collapse" for="c-41546215">[-]</label><label class="expand" for="c-41546215">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The fact everyone that say they&#x27;ve become more productive with LLMs won&#x27;t say how exactly.<p>Anecdotally, I no longer use StackOverflow. I don’t have to deal with random downvotes and feeling stupid because some expert with a 10k+ score on 15 SE sites each votes my question to be closed. I’m pretty tech savvy, been doing development for 15 years, but I’m always learning new things.<p>I can describe a rough idea of what I want to an LLM and get just enough code for me to hit the ground running…or, I can ask a question in forum and twiddle my thumbs and look through 50 tabs to hopefully stumble upon a solution in the meantime.<p>I’m productive af now. I was paying for ChatGPT but Claude has been my goto for the past few months.</div><br/></div></div><div id="41542359" class="c"><input type="checkbox" id="c-41542359" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41542031">parent</a><span>|</span><a href="#41546215">prev</a><span>|</span><a href="#41544354">next</a><span>|</span><label class="collapse" for="c-41542359">[-]</label><label class="expand" for="c-41542359">[1 more]</label></div><br/><div class="children"><div class="content">&gt; But no one really show how they&#x27;re actually solving problems with LLMs and how the alternatives were worse for them.<p>I&#x27;m an iOS dev, my knowledge of JS and CSS is circa 2004. I&#x27;ve used ChatGPT to convert some of my circa 2009 Java games into browser games.<p>&gt; Chatting with a LLM look to me like your intent is either vague or you don&#x27;t know the units to use<p>Or that you&#x27;re moving up the management track.<p>Managers don&#x27;t write code either. Some prefer it that way.</div><br/></div></div><div id="41544354" class="c"><input type="checkbox" id="c-41544354" checked=""/><div class="controls bullet"><span class="by">Workaccount2</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41542031">parent</a><span>|</span><a href="#41542359">prev</a><span>|</span><a href="#41542362">next</a><span>|</span><label class="collapse" for="c-41544354">[-]</label><label class="expand" for="c-41544354">[1 more]</label></div><br/><div class="children"><div class="content">I have used chatGPT to write test systems for our (physical) products. I have a pretty decent understanding of how code&#x2F;programs works structurally, I just don&#x27;t know the syntax&#x2F;language (Python in this case).<p>So I can translate things like<p>&quot;Create an array, then query this instrument for xyz measurements, then store those measurements in the array. Then store that array in the .csv file we created before&quot;<p>It works fantastic and saved us from outsourcing.</div><br/></div></div><div id="41542362" class="c"><input type="checkbox" id="c-41542362" checked=""/><div class="controls bullet"><span class="by">joseluis</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41542031">parent</a><span>|</span><a href="#41544354">prev</a><span>|</span><a href="#41544789">next</a><span>|</span><label class="collapse" for="c-41542362">[-]</label><label class="expand" for="c-41542362">[1 more]</label></div><br/><div class="children"><div class="content">The key difference is that this is a multidisciplinary conversational interface, and a tool in itself for interrelating structured meaning and reshaping it coherently enough  so that it can be of great value both in the specific domain of the dialog, and in the potential to take it on any tangent in any way that can be expressed.<p>Of course it has limitations and you   can&#x27;t be sleep at the wheel, but that&#x27;s true of any tool or task.</div><br/></div></div><div id="41544789" class="c"><input type="checkbox" id="c-41544789" checked=""/><div class="controls bullet"><span class="by">lifeformed</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41542031">parent</a><span>|</span><a href="#41542362">prev</a><span>|</span><a href="#41542367">next</a><span>|</span><label class="collapse" for="c-41544789">[-]</label><label class="expand" for="c-41544789">[3 more]</label></div><br/><div class="children"><div class="content">I think people who are successfully using it to write code are just chaining APIs together to make the same web apps you see everywhere.</div><br/><div id="41545725" class="c"><input type="checkbox" id="c-41545725" checked=""/><div class="controls bullet"><span class="by">imiric</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41544789">parent</a><span>|</span><a href="#41542367">next</a><span>|</span><label class="collapse" for="c-41545725">[-]</label><label class="expand" for="c-41545725">[2 more]</label></div><br/><div class="children"><div class="content">The vast majority of software is &quot;just chaining APIs together&quot;. It makes sense that LLMs would excel at code they&#x27;ve been trained on the most, which means they can be useful to a lot of people. This also means that these people will be the first to be made redundant by LLMs, once the quality improves enough.</div><br/><div id="41546045" class="c"><input type="checkbox" id="c-41546045" checked=""/><div class="controls bullet"><span class="by">elbear</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41545725">parent</a><span>|</span><a href="#41542367">next</a><span>|</span><label class="collapse" for="c-41546045">[-]</label><label class="expand" for="c-41546045">[1 more]</label></div><br/><div class="children"><div class="content">I would say all software is chaining APIs together.</div><br/></div></div></div></div></div></div><div id="41542367" class="c"><input type="checkbox" id="c-41542367" checked=""/><div class="controls bullet"><span class="by">DiogenesKynikos</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41542031">parent</a><span>|</span><a href="#41544789">prev</a><span>|</span><a href="#41542624">next</a><span>|</span><label class="collapse" for="c-41542367">[-]</label><label class="expand" for="c-41542367">[1 more]</label></div><br/><div class="children"><div class="content">For one, I spend less time on Stackoverflow. LLMs can usually give you the answer to little questions about programming or command-line utilities right away.</div><br/></div></div><div id="41542624" class="c"><input type="checkbox" id="c-41542624" checked=""/><div class="controls bullet"><span class="by">fragmede</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41542031">parent</a><span>|</span><a href="#41542367">prev</a><span>|</span><a href="#41544294">next</a><span>|</span><label class="collapse" for="c-41542624">[-]</label><label class="expand" for="c-41542624">[1 more]</label></div><br/><div class="children"><div class="content">Here&#x27;s one from simonw<p><a href="https:&#x2F;&#x2F;gist.github.com&#x2F;simonw&#x2F;97e29b86540fcc627da4984daf5b7f9f" rel="nofollow">https:&#x2F;&#x2F;gist.github.com&#x2F;simonw&#x2F;97e29b86540fcc627da4984daf5b7...</a><p>There are more to be found on his blog on the ai-assisted-programming tag.
<a href="https:&#x2F;&#x2F;simonwillison.net&#x2F;tags&#x2F;ai-assisted-programming&#x2F;" rel="nofollow">https:&#x2F;&#x2F;simonwillison.net&#x2F;tags&#x2F;ai-assisted-programming&#x2F;</a></div><br/></div></div><div id="41544294" class="c"><input type="checkbox" id="c-41544294" checked=""/><div class="controls bullet"><span class="by">Workaccount2</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41542031">parent</a><span>|</span><a href="#41542624">prev</a><span>|</span><a href="#41544353">next</a><span>|</span><label class="collapse" for="c-41544294">[-]</label><label class="expand" for="c-41544294">[1 more]</label></div><br/><div class="children"><div class="content">Just be mindful that it is one&#x27;s interest to push the &quot;LLMs suck, don&#x27;t waste your time with them&quot; narrative once they figure out how to harness LLMs.<p>&quot;Jason is a strong coder, and he despises AI tools!&quot;</div><br/></div></div><div id="41544353" class="c"><input type="checkbox" id="c-41544353" checked=""/><div class="controls bullet"><span class="by">Kiro</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41542031">parent</a><span>|</span><a href="#41544294">prev</a><span>|</span><a href="#41542852">next</a><span>|</span><label class="collapse" for="c-41544353">[-]</label><label class="expand" for="c-41544353">[2 more]</label></div><br/><div class="children"><div class="content">You clearly have made up your mind that it can&#x27;t be right but to me it&#x27;s like arguing against breathing. There are no uncertainties or misunderstandings here. The productivity gains are real and the code produced is more robust. Not in theory, but in practice. This is a fact for me and you trying to convince me otherwise is just silly when I have the result right in front of me. It&#x27;s also not just boilerplate. It&#x27;s all code.</div><br/><div id="41545011" class="c"><input type="checkbox" id="c-41545011" checked=""/><div class="controls bullet"><span class="by">mhuffman</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41544353">parent</a><span>|</span><a href="#41542852">next</a><span>|</span><label class="collapse" for="c-41545011">[-]</label><label class="expand" for="c-41545011">[1 more]</label></div><br/><div class="children"><div class="content">&gt;There are no uncertainties or misunderstandings here. The productivity gains are real and the code produced is more robust. Not in theory, but in practice.<p>So, that may be a fact for you but there are mixed results when you go out wide. For example [1] has this little nugget:<p>&gt;The study identifies a disconnect between the high expectations of managers and the actual experiences of employees using AI.<p>&gt;Despite 96% of C-suite executives expecting AI to boost productivity, the study reveals that, 77% of employees using AI say it has added to their workload and created challenges in achieving the expected productivity gains. Not only is AI increasing the workloads of full-time employees, it’s hampering productivity and contributing to employee burnout.<p>So not everyone is feeling the jump in productivity the same way. On this very site, there are people claiming they are blasting out highly-complex applications faster than they ever could, some of them also claiming they don&#x27;t even have any experience programming. Then others claiming that LLMs and AI copilots just slow them down and cause much more trouble than they are worth.<p>It seems like just with programming itself, that different people are getting different results.<p>[1]<a href="https:&#x2F;&#x2F;www.forbes.com&#x2F;sites&#x2F;bryanrobinson&#x2F;2024&#x2F;07&#x2F;23&#x2F;employees-report-ai-increased-workload&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.forbes.com&#x2F;sites&#x2F;bryanrobinson&#x2F;2024&#x2F;07&#x2F;23&#x2F;employ...</a></div><br/></div></div></div></div></div></div><div id="41542852" class="c"><input type="checkbox" id="c-41542852" checked=""/><div class="controls bullet"><span class="by">minkles</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41541754">parent</a><span>|</span><a href="#41542031">prev</a><span>|</span><a href="#41542521">next</a><span>|</span><label class="collapse" for="c-41542852">[-]</label><label class="expand" for="c-41542852">[11 more]</label></div><br/><div class="children"><div class="content">That’s fine until your code makes its way to production, an unconsidered side effect occurs and then you have to face me.<p>You are still responsible for what you do regardless of the means you used to do it. And a lot of people use this not because it’s more productive but because it requires less effort and less thought because those are the hard bits.<p>I’m collecting stats at the moment but the general trend in quality as in producing functional defects is declining when an LLM is involved in the process.<p>So far it’s not a magic bullet but a push for mediocrity in an industry with a rather bad reputation. Never a good story.</div><br/><div id="41543442" class="c"><input type="checkbox" id="c-41543442" checked=""/><div class="controls bullet"><span class="by">blargey</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41542852">parent</a><span>|</span><a href="#41543646">next</a><span>|</span><label class="collapse" for="c-41543442">[-]</label><label class="expand" for="c-41543442">[1 more]</label></div><br/><div class="children"><div class="content">Wasn&#x27;t there a recent post about many research papers getting published with conclusions derived from buggy&#x2F;incorrect code?<p>I&#x27;d put more hope in improving LLMs&#x2F;derivatives than improving the level of effort and thought in code across the entire population of &quot;people who code&quot;, especially the subset who would rather be doing something else with their time and effort &#x2F; see it as a distraction from the &quot;real&quot; work that leverages their actual area of expertise.</div><br/></div></div><div id="41543646" class="c"><input type="checkbox" id="c-41543646" checked=""/><div class="controls bullet"><span class="by">a_wild_dandan</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41542852">parent</a><span>|</span><a href="#41543442">prev</a><span>|</span><a href="#41542988">next</a><span>|</span><label class="collapse" for="c-41543646">[-]</label><label class="expand" for="c-41543646">[1 more]</label></div><br/><div class="children"><div class="content">&gt; You are still responsible for what you do regardless of the means you used to do it. And a lot of people use this not because it’s more productive but because it requires less effort and less thought because those are the hard bits.<p>Yeah, that&#x27;s...the whole point of tools. They reduce effort. And they don&#x27;t shift your responsibility. For many of us, LLMs are overwhelmingly worth the tradeoffs. If your experience differs, then it&#x27;s unfortunate, and I hate that for you. Don&#x27;t use &#x27;em!</div><br/></div></div><div id="41542988" class="c"><input type="checkbox" id="c-41542988" checked=""/><div class="controls bullet"><span class="by">bongodongobob</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41542852">parent</a><span>|</span><a href="#41543646">prev</a><span>|</span><a href="#41542521">next</a><span>|</span><label class="collapse" for="c-41542988">[-]</label><label class="expand" for="c-41542988">[8 more]</label></div><br/><div class="children"><div class="content">Ugh, dude, I used to push bad code into production without ChatGPT. It is such a stupid argument. Do you really think people are just blindly pushing code they can&#x27;t make heads or tails of? That they haven&#x27;t tested? Do you seriously think people are just one shotting code and blasting it into prod? I am completely baffled by people in this industry that <i>just don&#x27;t get it</i>. Learn to prompt. Write tests. Wtf.</div><br/><div id="41543227" class="c"><input type="checkbox" id="c-41543227" checked=""/><div class="controls bullet"><span class="by">hughesjj</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41542988">parent</a><span>|</span><a href="#41543045">next</a><span>|</span><label class="collapse" for="c-41543227">[-]</label><label class="expand" for="c-41543227">[2 more]</label></div><br/><div class="children"><div class="content">My problem is that, for a surprising number of applications, it&#x27;s taken me longer to have the conversation with chatgpt to get the code I want than just doing it myself.<p>Copilot and the likes are legit for boilerplate, some test code, and posix&#x2F;power shell scripting.  Anything that&#x27;s very common it&#x27;s great.<p>Anything novel though and it suffers.  Did AWS just release some new functionality and only like 4 people have touched it so far on GitHub?  Are you getting source docs incomplete or spread out amongst multiple pages with some implicit&#x2F;betwen-the-lines spec?  Eh, good luck, you&#x27;re probably better off just reading the docs yourself or guess and checking.<p>Same goes for versioning, sometimes it&#x27;ll fall back into an older version of the system (ex Kafka with kraft vs zookeeper)<p>Personally, the best general use case of LLMs for me is focus.  I know how to break down a task, but sometimes I have an issue staying focused on doing it and having a reasonably competent partner to rubber duck with is super useful.  It helps that the chat log then becomes an easy artifact to more or less copy paste, and chatgpt doesn&#x27;t do a terrible job reformatting either.  Like for 90% of the stuff it&#x27;s easier than using vim commands.</div><br/><div id="41544653" class="c"><input type="checkbox" id="c-41544653" checked=""/><div class="controls bullet"><span class="by">lanstin</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41543227">parent</a><span>|</span><a href="#41543045">next</a><span>|</span><label class="collapse" for="c-41544653">[-]</label><label class="expand" for="c-41544653">[1 more]</label></div><br/><div class="children"><div class="content">It seems great for like straightforward linear code, elisp functions, python data massage scripts, that sort of thing. I had it take a shot at some new module for a high volume Go server with concurrency&#x2F;locking concerns and nil pointer receivers. I got more panics from the little bit of code GPT wrote than all my own code, not because it was bad code but because when I use dangerous constructs like locking and pointers that can be nil, I have certain rigid rules for how to use them and the generated code did not follow those rules.</div><br/></div></div></div></div><div id="41543045" class="c"><input type="checkbox" id="c-41543045" checked=""/><div class="controls bullet"><span class="by">scubbo</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41542988">parent</a><span>|</span><a href="#41543227">prev</a><span>|</span><a href="#41543012">next</a><span>|</span><label class="collapse" for="c-41543045">[-]</label><label class="expand" for="c-41543045">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Do you really think people are just blindly pushing code they can&#x27;t make heads or tails of? That they haven&#x27;t tested? Do you seriously think people are just one shotting code and blasting it into prod?<p>Yes, and I see proof of it _literally every day_ in Code Reviews where I ask juniors to describe or justify their choices and they shrug and say &quot;That&#x27;s what Copilot told me to put&quot;.</div><br/><div id="41544164" class="c"><input type="checkbox" id="c-41544164" checked=""/><div class="controls bullet"><span class="by">mewpmewp2</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41543045">parent</a><span>|</span><a href="#41543012">next</a><span>|</span><label class="collapse" for="c-41544164">[-]</label><label class="expand" for="c-41544164">[1 more]</label></div><br/><div class="children"><div class="content">That sounds more like poor hiring decisions.</div><br/></div></div></div></div><div id="41543012" class="c"><input type="checkbox" id="c-41543012" checked=""/><div class="controls bullet"><span class="by">minkles</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41542988">parent</a><span>|</span><a href="#41543045">prev</a><span>|</span><a href="#41543405">next</a><span>|</span><label class="collapse" for="c-41543012">[-]</label><label class="expand" for="c-41543012">[1 more]</label></div><br/><div class="children"><div class="content">Yes that&#x27;s exactly what they are doing.<p>I literally had someone with the balls to tell me that it was ChatGPT&#x27;s fault.<p>Due diligence and intelligence has shit the fucking bed quite frankly.</div><br/></div></div><div id="41543405" class="c"><input type="checkbox" id="c-41543405" checked=""/><div class="controls bullet"><span class="by">hobs</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41542988">parent</a><span>|</span><a href="#41543012">prev</a><span>|</span><a href="#41542521">next</a><span>|</span><label class="collapse" for="c-41543405">[-]</label><label class="expand" for="c-41543405">[2 more]</label></div><br/><div class="children"><div class="content">Do you think ChatGPT has changed any of those answers from Yes to No? Because it hasn&#x27;t.<p>People blindly copied stack overflow code, they blindly copied every example off of MSDN, they blindly copy from ChatGPT - your holier than thou statements are funny, and frankly most LLMs cannot leave a local maxima, so anyone who says they dont write any code anymore I frankly think they are not capable of telling the mistakes, both architecturally and specifically that they are making.<p>More and different prompting will not dig you out of the hole.</div><br/><div id="41546170" class="c"><input type="checkbox" id="c-41546170" checked=""/><div class="controls bullet"><span class="by">kaoD</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41543405">parent</a><span>|</span><a href="#41542521">next</a><span>|</span><label class="collapse" for="c-41546170">[-]</label><label class="expand" for="c-41546170">[1 more]</label></div><br/><div class="children"><div class="content">This. Most people I know that use LLMs to be super productive are like &quot;make me a button, it&#x27;s red&quot; (hyperbolic statement but you know what I mean). I can do that faster and better myself.<p>When I&#x27;m deeply stuck on something and I think &quot;let&#x27;s see if an LLM could help here&quot;, I try (and actually tried many times) to recruit those prompting gurus around me that swear LLMs solve all their problems... and they consistently fail to help me at all. They cannot solve the problem at all and I&#x27;m just sitting there, watching the gurus spend hours prompting in circles until they give up and leave (still thinking LLMs are amazing, of course).<p>This experience is what makes me extremely suspicious of anyone on the internet claiming they don&#x27;t write code anymore but refusing to show (don&#x27;t tell!) -- when actually testing it in real life it has been nothing but disappointment.</div><br/></div></div></div></div></div></div></div></div><div id="41542521" class="c"><input type="checkbox" id="c-41542521" checked=""/><div class="controls bullet"><span class="by">cjbgkagh</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41541754">parent</a><span>|</span><a href="#41542852">prev</a><span>|</span><a href="#41541821">next</a><span>|</span><label class="collapse" for="c-41542521">[-]</label><label class="expand" for="c-41542521">[13 more]</label></div><br/><div class="children"><div class="content">In my view these models produce above average code which is good enough for most jobs. But the hacker news sampling could be biased towards the top tier of coders - so their personal account of it not being good enough can also be true. For me the quality isn&#x27;t anywhere close to good enough for my purposes, all of my easy code is already done so I&#x27;m only left working on gnarly niche stuff which the LLMs are not yet helpful with.<p>For the effect on the industry, I generally make the point that even if AI only replaces the below average coder it will cause a downward pressure on above average coders compensation expectation.<p>Personally, humans appear to be getting dumber at the same time that AI is getting smarter and while, for now, the crossover point is at a low threshold that threshold will of course increase over time. I used to try to teach ontologies, stats, SMT solvers to humans before giving up and switching to AI technologies where success is not predicated on human understanding. I used to think that the inability for most humans to understand these topics was a matter of motivation, but have rather recently come to understand that these limitations are generally innate.</div><br/><div id="41542851" class="c"><input type="checkbox" id="c-41542851" checked=""/><div class="controls bullet"><span class="by">rvnx</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41542521">parent</a><span>|</span><a href="#41542697">next</a><span>|</span><label class="collapse" for="c-41542851">[-]</label><label class="expand" for="c-41542851">[7 more]</label></div><br/><div class="children"><div class="content">It is also a problem of ego.<p>It is difficult if you have been told all your life that you are the best, to accept the fact that a computer or even other people might be better than you.<p>It requires lot of self-reflection.<p>Real top-tiers programmers actually don’t feel threatened by LLMs. For them it is just one more tool in the toolbox like syntax highlighting or code completion.<p>They choose to use these tools based on productivity gains or losses, depending on the situation.</div><br/><div id="41544696" class="c"><input type="checkbox" id="c-41544696" checked=""/><div class="controls bullet"><span class="by">hatefulmoron</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41542851">parent</a><span>|</span><a href="#41544931">next</a><span>|</span><label class="collapse" for="c-41544696">[-]</label><label class="expand" for="c-41544696">[2 more]</label></div><br/><div class="children"><div class="content">Not to diminish your point at all: I think it&#x27;s also just a fear that the fun or interesting part of the task is being diminished. To say that the point of programming is to solve real world problems (&#x27;productivity&#x27;) is true, but in my experience it&#x27;s not necessarily true for the person doing the solving. Many people who work as programmers like to program (as in, the process of working with code, typing it, debugging it, building up solutions from scratch), and their job is an avenue to exercise that part of their brain.<p>Telling that sort of person that they&#x27;re going to be more productive by skipping all the &quot;time consuming programming stuff&quot; is bound to hurt.</div><br/><div id="41546055" class="c"><input type="checkbox" id="c-41546055" checked=""/><div class="controls bullet"><span class="by">elbear</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41544696">parent</a><span>|</span><a href="#41544931">next</a><span>|</span><label class="collapse" for="c-41546055">[-]</label><label class="expand" for="c-41546055">[1 more]</label></div><br/><div class="children"><div class="content">The solution to this is to code your own things for fun.</div><br/></div></div></div></div><div id="41544931" class="c"><input type="checkbox" id="c-41544931" checked=""/><div class="controls bullet"><span class="by">p-e-w</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41542851">parent</a><span>|</span><a href="#41544696">prev</a><span>|</span><a href="#41542697">next</a><span>|</span><label class="collapse" for="c-41544931">[-]</label><label class="expand" for="c-41544931">[4 more]</label></div><br/><div class="children"><div class="content">&gt; Real top-tiers programmers actually don’t feel threatened by LLMs.<p>They should, because LLMs are coming for them also, just maybe 2-3 years later than for programmers that aren&#x27;t &quot;real top-tier&quot;.<p>The idea that human intellect is something especially difficult to replicate is just delusional. There is no reason to assume so, considering that we have gone from hole card programming to LLMs competing with humans in a single human lifetime.<p>I still remember when elite chessplayers were boasting &quot;sure, chess computers may beat amateurs, but they will never beat a human grandmaster&quot;. That was just a few short years before the Deep Blue match.<p>The difference is that nobody will pay programmers to keep programming once LLMs outperform them. Programmers will simply become as obsolete as horse-drawn carriages, essentially overnight.</div><br/><div id="41546212" class="c"><input type="checkbox" id="c-41546212" checked=""/><div class="controls bullet"><span class="by">kaoD</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41544931">parent</a><span>|</span><a href="#41545861">next</a><span>|</span><label class="collapse" for="c-41546212">[-]</label><label class="expand" for="c-41546212">[1 more]</label></div><br/><div class="children"><div class="content">&gt; They should, because LLMs are coming for them also, just maybe 2-3 years later than for programmers that aren&#x27;t &quot;real top-tier&quot;.<p>Would you be willing to set a deadline (not fuzzy dates) when my job is going to be taken by an LLM and bet $5k on that?<p>Because the more I use LLMs and I see their improvement rate, the less worried I am about my job.<p>The only thing that worries me is salaries going down because management cannot tell how bad they&#x27;re burying themselves into technical debt and maintenance hell, so they&#x27;ll underpay a bunch of LLM-powered interns... which I will have to clean up and honestly I don&#x27;t want to (I&#x27;ve already been cleaning enough shit non-LLM code, LLMs will just generate more and more of that).</div><br/></div></div><div id="41545861" class="c"><input type="checkbox" id="c-41545861" checked=""/><div class="controls bullet"><span class="by">airspresso</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41544931">parent</a><span>|</span><a href="#41546212">prev</a><span>|</span><a href="#41546010">next</a><span>|</span><label class="collapse" for="c-41545861">[-]</label><label class="expand" for="c-41545861">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The difference is that nobody will pay programmers to keep programming once LLMs outperform them. Programmers will simply become as obsolete as horse-drawn carriages, essentially overnight.<p>I don&#x27;t buy this. A big part of the programmer&#x27;s job is to convert vague and poorly described business requirements into something that is actually possible to implement in code and that roughly solves the business need. LLMs don&#x27;t solve that part at all since it requires back and forth with business stakeholders to clarify what they want and educate them on how software can help. Sure, when the requirements are finally clear enough, LLMs can make a solution. But then the tasks of testing it, building, deploying and maintaining it remain too, which also typically fall to the programmer. LLMs are useful tools in each stage of the process and speed up tasks, but not replacing the human that designs and architects the solution (the programmer).</div><br/></div></div><div id="41546010" class="c"><input type="checkbox" id="c-41546010" checked=""/><div class="controls bullet"><span class="by">concordDance</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41544931">parent</a><span>|</span><a href="#41545861">prev</a><span>|</span><a href="#41542697">next</a><span>|</span><label class="collapse" for="c-41546010">[-]</label><label class="expand" for="c-41546010">[1 more]</label></div><br/><div class="children"><div class="content">&gt; &gt; Real top-tiers programmers actually don’t feel threatened by LLMs.<p>&gt; They should, because LLMs are coming for them also, just maybe 2-3 years later than for programmers that aren&#x27;t &quot;real top-tier&quot;.<p>Not worrying about that because if they&#x27;ve gotten to that point (note: top tier programmers also need domain knowledge) then we&#x27;re all dead a few years later.</div><br/></div></div></div></div></div></div><div id="41542697" class="c"><input type="checkbox" id="c-41542697" checked=""/><div class="controls bullet"><span class="by">bcoates</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41542521">parent</a><span>|</span><a href="#41542851">prev</a><span>|</span><a href="#41545071">next</a><span>|</span><label class="collapse" for="c-41542697">[-]</label><label class="expand" for="c-41542697">[4 more]</label></div><br/><div class="children"><div class="content">Re: Compensation expectations, I figured out a long time ago that bad programmers create bad code, and bad code creates work for good programmers.<p>If the amount of bad code is no longer limited by the availability of workers who can be trained up to &quot;just below average&quot; and instead anyone who knows how to work a touchscreen can make AI slop, this opens up a big economic opportunity.</div><br/><div id="41542901" class="c"><input type="checkbox" id="c-41542901" checked=""/><div class="controls bullet"><span class="by">cjbgkagh</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41542697">parent</a><span>|</span><a href="#41545071">next</a><span>|</span><label class="collapse" for="c-41542901">[-]</label><label class="expand" for="c-41542901">[3 more]</label></div><br/><div class="children"><div class="content">One could hope, but in my view perception precedes reality and even if that is the reality the perception is that AI will lower compensation demands and those doing the layoffs&#x2F;hiring will act accordingly.<p>You could also make the same claims about outsourcing, and while it appears that in most cases the outsourcing doesn&#x27;t pay off, the perception that it would has really damaged CS as a career.</div><br/><div id="41544132" class="c"><input type="checkbox" id="c-41544132" checked=""/><div class="controls bullet"><span class="by">acedTrex</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41542901">parent</a><span>|</span><a href="#41544232">next</a><span>|</span><label class="collapse" for="c-41544132">[-]</label><label class="expand" for="c-41544132">[1 more]</label></div><br/><div class="children"><div class="content">Anything that makes fewer people get into programming is good for the field of CS. Only those who truly care go into it</div><br/></div></div><div id="41544232" class="c"><input type="checkbox" id="c-41544232" checked=""/><div class="controls bullet"><span class="by">tzs</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41542901">parent</a><span>|</span><a href="#41544132">prev</a><span>|</span><a href="#41545071">next</a><span>|</span><label class="collapse" for="c-41544232">[-]</label><label class="expand" for="c-41544232">[1 more]</label></div><br/><div class="children"><div class="content">And like with outsourcing it starts with the jobs at the lower end of the skill range in an industry, and so people at the higher end don&#x27;t worry about it, and later it expands and they learn that they too are not safe.<p>What happened a couple of decades ago in poetry [1] could happen now with programming:<p>&gt; No longer is it just advertising jingles and limericks made in Haiti and Indonesia. It&#x27;s quatrains, sonnets, and free-form verse being &quot;outsourced&quot; to India, the Philippines, Russia, and China.<p>...<p>&gt; &quot;Limericks are a small slice of the economy, and when people saw globalization creating instability there, a lot said, &#x27;It&#x27;s not my problem,&#x27;&quot; says Karl Givens, an economist at Washington&#x27;s Economic Policy Institute. &quot;Now even those who work in iambic pentameter are feeling it.&quot;<p>[1] <a href="http:&#x2F;&#x2F;www.watleyreview.com&#x2F;2003&#x2F;111103-2.html" rel="nofollow">http:&#x2F;&#x2F;www.watleyreview.com&#x2F;2003&#x2F;111103-2.html</a></div><br/></div></div></div></div></div></div></div></div><div id="41541821" class="c"><input type="checkbox" id="c-41541821" checked=""/><div class="controls bullet"><span class="by">benterix</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41541754">parent</a><span>|</span><a href="#41542521">prev</a><span>|</span><a href="#41541854">next</a><span>|</span><label class="collapse" for="c-41541821">[-]</label><label class="expand" for="c-41541821">[30 more]</label></div><br/><div class="children"><div class="content">&gt; I&#x27;ve found that I haven&#x27;t written a line of code in weeks<p>Which is great until your next job interview. Really, it&#x27;s tempting in the short run but I made a conscious decision to do certain tasks manually only so that I don&#x27;t lose my basic skills.</div><br/><div id="41542036" class="c"><input type="checkbox" id="c-41542036" checked=""/><div class="controls bullet"><span class="by">vasco</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41541821">parent</a><span>|</span><a href="#41542225">next</a><span>|</span><label class="collapse" for="c-41542036">[-]</label><label class="expand" for="c-41542036">[7 more]</label></div><br/><div class="children"><div class="content">ChatGPT voice interface plugged into the audio stream, with the prompt:<p>- I need you to assist me during a programming interview, you will be listening to two people, the interviewer and me. When the interviewer asks a question, I&#x27;d like you to feed me lines that seem realistic for an interview where I&#x27;m nervous, don&#x27;t give me a full blown answer right away. Be very succinct. If I think you misunderstood something, I will mention the key phrase &quot;I&#x27;m nervous today and had too much coffee&quot;. In this situation, remember I&#x27;m the one that will say the phrase, and it might be because you&#x27;ve mistaken me by the interviewer and I want you to &quot;reset&quot;. If I want you to dig deeper than what you&#x27;ve provided me with, I&#x27;ll say the key phrase &quot;Let&#x27;s dig deeper now&quot;. If I think you&#x27;ve hallucinated and want you to try again, I&#x27;ll say &quot;This might be wrong, let me think for just a minute please&quot;. Remember, other than these key phrases, I&#x27;ll only be talking to the interviewer, not you.<p>On a second screen of some sort. Other than that, interviewers will just have to accept that nobody will be doing the job without these sort of assistants from now on anyway. As an interviewer I let candidates consult online docs for specific things already because they&#x27;ll have access to Google during the job, this is just an extension of that.</div><br/><div id="41542849" class="c"><input type="checkbox" id="c-41542849" checked=""/><div class="controls bullet"><span class="by">gcanyon</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41542036">parent</a><span>|</span><a href="#41542145">next</a><span>|</span><label class="collapse" for="c-41542849">[-]</label><label class="expand" for="c-41542849">[1 more]</label></div><br/><div class="children"><div class="content">I recently interviewed a number of people about their SQL skills. The format I used was to share two queries with them a couple days ahead of time in a google doc, and tell them I will ask them questions about those queries during the interview.<p>Out of maybe twenty people I interviewed this way, only three of them pointed out that one of the queries had a failing error in it. It was something any LLM would immediately point out.<p>Beyond that: the first question I asked was: &quot;What does this query do, what does it return?&quot; I got responses ranging from people who literally read the query back to me word by word, giving the most shallow and direct explanation of what each bit did step-by-step, to people who clearly summarized what the query did in high-level, abstract terms, as you might describe what you want to accomplish before you write the query.<p>I don&#x27;t think anyone did something with ChatGPT live, but <i>maybe</i>?</div><br/></div></div><div id="41542145" class="c"><input type="checkbox" id="c-41542145" checked=""/><div class="controls bullet"><span class="by">apsurd</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41542036">parent</a><span>|</span><a href="#41542849">prev</a><span>|</span><a href="#41542225">next</a><span>|</span><label class="collapse" for="c-41542145">[-]</label><label class="expand" for="c-41542145">[5 more]</label></div><br/><div class="children"><div class="content">This made me laugh. I can&#x27;t deny it isn&#x27;t already happening. But wow people work so hard to avoid working hard.</div><br/><div id="41546058" class="c"><input type="checkbox" id="c-41546058" checked=""/><div class="controls bullet"><span class="by">elbear</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41542145">parent</a><span>|</span><a href="#41544091">next</a><span>|</span><label class="collapse" for="c-41546058">[-]</label><label class="expand" for="c-41546058">[1 more]</label></div><br/><div class="children"><div class="content">I think the point is to avoid pointless hard work.</div><br/></div></div><div id="41544091" class="c"><input type="checkbox" id="c-41544091" checked=""/><div class="controls bullet"><span class="by">throwaway765123</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41542145">parent</a><span>|</span><a href="#41546058">prev</a><span>|</span><a href="#41542400">next</a><span>|</span><label class="collapse" for="c-41544091">[-]</label><label class="expand" for="c-41544091">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not about avoiding hard work - the audience on HN skews wealthy due to heavy representation of skilled devs in their 30s+, but the average person does not earn anything close to FAANG salaries. Even most devs in general don&#x27;t earn like that. The interview process being fairly well understood in general, any advantage that can possibly get a person from $60k&#x2F;year to generationally-life-changing $300k&#x2F;year will be used eventually.</div><br/></div></div><div id="41542400" class="c"><input type="checkbox" id="c-41542400" checked=""/><div class="controls bullet"><span class="by">vasco</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41542145">parent</a><span>|</span><a href="#41544091">prev</a><span>|</span><a href="#41542403">next</a><span>|</span><label class="collapse" for="c-41542400">[-]</label><label class="expand" for="c-41542400">[1 more]</label></div><br/><div class="children"><div class="content">And I wrote this as a knee-jerk reaction after reading the parent, I imagine people will be putting way more effort if it can get them a great job. And to be honest, if they can fool you, they can most likely do the job as well. Most of the industry tests at a higher skill level than what they actually require on the day to day anyway.</div><br/></div></div><div id="41542403" class="c"><input type="checkbox" id="c-41542403" checked=""/><div class="controls bullet"><span class="by">bessbd</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41542145">parent</a><span>|</span><a href="#41542400">prev</a><span>|</span><a href="#41542225">next</a><span>|</span><label class="collapse" for="c-41542403">[-]</label><label class="expand" for="c-41542403">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s almost inspiring, isn&#x27;t it?</div><br/></div></div></div></div></div></div><div id="41542225" class="c"><input type="checkbox" id="c-41542225" checked=""/><div class="controls bullet"><span class="by">jamesmotherway</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41541821">parent</a><span>|</span><a href="#41542036">prev</a><span>|</span><a href="#41542656">next</a><span>|</span><label class="collapse" for="c-41542225">[-]</label><label class="expand" for="c-41542225">[1 more]</label></div><br/><div class="children"><div class="content">Not everyone is doing coding interviews. Some might struggle with a particular language due to lack of muscle memory, but can dictate the logic in pseudocode and can avoid pitfalls inferred from past experience. This sort of workflow is compatible with LLMs, assuming a sufficient background (otherwise one can&#x27;t recognize when the output diverges from your intent).<p>I personally treat the LLM as a rubber duck. Often I reject its output. In other cases, I can accept it and refactor it into something even better. The name of the game is augmentation.</div><br/></div></div><div id="41542656" class="c"><input type="checkbox" id="c-41542656" checked=""/><div class="controls bullet"><span class="by">dmd</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41541821">parent</a><span>|</span><a href="#41542225">prev</a><span>|</span><a href="#41541970">next</a><span>|</span><label class="collapse" for="c-41542656">[-]</label><label class="expand" for="c-41542656">[3 more]</label></div><br/><div class="children"><div class="content">I sometimes get the idea from statements like this - and HN&#x27;s focus on interviewing in general - that people are switching jobs a dozen times a year or something. How often are most people switching jobs? I&#x27;ve had 5 jobs in the last 20 years.</div><br/><div id="41542773" class="c"><input type="checkbox" id="c-41542773" checked=""/><div class="controls bullet"><span class="by">macintux</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41542656">parent</a><span>|</span><a href="#41542713">next</a><span>|</span><label class="collapse" for="c-41542773">[-]</label><label class="expand" for="c-41542773">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m old, and well-paid for my geographic region (but for various mostly stupid reasons utterly broke). No amount of value created (at least, for my skill level) will protect me from ageism and&#x2F;or budget cuts.</div><br/></div></div></div></div><div id="41541970" class="c"><input type="checkbox" id="c-41541970" checked=""/><div class="controls bullet"><span class="by">ed</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41541821">parent</a><span>|</span><a href="#41542656">prev</a><span>|</span><a href="#41542490">next</a><span>|</span><label class="collapse" for="c-41541970">[-]</label><label class="expand" for="c-41541970">[3 more]</label></div><br/><div class="children"><div class="content">This. I’ve been using elixir for ~6 months (guided by Claude) and probably couldn’t solve fizz buzz at a whiteboard without making a syntax error. Eek.</div><br/><div id="41543068" class="c"><input type="checkbox" id="c-41543068" checked=""/><div class="controls bullet"><span class="by">stavros</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41541970">parent</a><span>|</span><a href="#41542490">next</a><span>|</span><label class="collapse" for="c-41543068">[-]</label><label class="expand" for="c-41543068">[2 more]</label></div><br/><div class="children"><div class="content">Who cares? If I&#x27;m hiring you to make a product, I care that the higher order logic is correct, that the requirements are all catered for, and that the code does reasonable things in all cases. Things I don&#x27;t care about are FizzBuzz, programming on whiteboards, and not making syntax errors.</div><br/><div id="41546252" class="c"><input type="checkbox" id="c-41546252" checked=""/><div class="controls bullet"><span class="by">kaoD</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41543068">parent</a><span>|</span><a href="#41542490">next</a><span>|</span><label class="collapse" for="c-41546252">[-]</label><label class="expand" for="c-41546252">[1 more]</label></div><br/><div class="children"><div class="content">This is how companies fail. 5 years down the line no one is able to change anything in the system because it&#x27;s so poorly architected (by being a bunch of Claude copypastes cobbled together) that it takes one month to do a one-day task (if it&#x27;s even possible).</div><br/></div></div></div></div></div></div><div id="41542490" class="c"><input type="checkbox" id="c-41542490" checked=""/><div class="controls bullet"><span class="by">LouisSayers</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41541821">parent</a><span>|</span><a href="#41541970">prev</a><span>|</span><a href="#41541886">next</a><span>|</span><label class="collapse" for="c-41542490">[-]</label><label class="expand" for="c-41542490">[1 more]</label></div><br/><div class="children"><div class="content">You need to prep for job interviews anyway. I&#x27;d rather spend the majority of my time being productive.</div><br/></div></div><div id="41541886" class="c"><input type="checkbox" id="c-41541886" checked=""/><div class="controls bullet"><span class="by">calmworm</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41541821">parent</a><span>|</span><a href="#41542490">prev</a><span>|</span><a href="#41541943">next</a><span>|</span><label class="collapse" for="c-41541886">[-]</label><label class="expand" for="c-41541886">[6 more]</label></div><br/><div class="children"><div class="content">Job interview? You might be surprised at the number of us who don’t code for a job.</div><br/><div id="41541969" class="c"><input type="checkbox" id="c-41541969" checked=""/><div class="controls bullet"><span class="by">__loam</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41541886">parent</a><span>|</span><a href="#41541943">next</a><span>|</span><label class="collapse" for="c-41541969">[-]</label><label class="expand" for="c-41541969">[5 more]</label></div><br/><div class="children"><div class="content">I&#x27;d bet most people on this forum program professionally.</div><br/><div id="41542131" class="c"><input type="checkbox" id="c-41542131" checked=""/><div class="controls bullet"><span class="by">calmworm</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41541969">parent</a><span>|</span><a href="#41541943">next</a><span>|</span><label class="collapse" for="c-41542131">[-]</label><label class="expand" for="c-41542131">[4 more]</label></div><br/><div class="children"><div class="content">I would take that bet.</div><br/><div id="41542274" class="c"><input type="checkbox" id="c-41542274" checked=""/><div class="controls bullet"><span class="by">idiotsecant</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41542131">parent</a><span>|</span><a href="#41541943">next</a><span>|</span><label class="collapse" for="c-41542274">[-]</label><label class="expand" for="c-41542274">[3 more]</label></div><br/><div class="children"><div class="content">Me too.</div><br/><div id="41544847" class="c"><input type="checkbox" id="c-41544847" checked=""/><div class="controls bullet"><span class="by">atomic128</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41542274">parent</a><span>|</span><a href="#41541943">next</a><span>|</span><label class="collapse" for="c-41544847">[-]</label><label class="expand" for="c-41544847">[2 more]</label></div><br/><div class="children"><div class="content">Somebody tested people on Hacker News to evaluate programming competency.<p>This was part of a larger evaluation comparing the Hacker News population to people on Reddit programming subreddits.<p>Here is a very heated discussion of the result:<p><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=33293522">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=33293522</a><p>It appears that Hacker News is perhaps NOT populated by the programming elite. In contrast, there are real wizards on Reddit.<p>Surprising, I know.</div><br/><div id="41545632" class="c"><input type="checkbox" id="c-41545632" checked=""/><div class="controls bullet"><span class="by">__loam</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41544847">parent</a><span>|</span><a href="#41541943">next</a><span>|</span><label class="collapse" for="c-41545632">[-]</label><label class="expand" for="c-41545632">[1 more]</label></div><br/><div class="children"><div class="content">Not surprising given how bad the takes here are and how many of the users here are dumb kids right out of college who are aspiring founders.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="41541943" class="c"><input type="checkbox" id="c-41541943" checked=""/><div class="controls bullet"><span class="by">whamlastxmas</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41541821">parent</a><span>|</span><a href="#41541886">prev</a><span>|</span><a href="#41542025">next</a><span>|</span><label class="collapse" for="c-41541943">[-]</label><label class="expand" for="c-41541943">[7 more]</label></div><br/><div class="children"><div class="content">I’ve made the decision to embrace being bad at coding but getting a ton of work done using an LLM and if my future employer doesn’t want massive productivity and would prefer being able to leetcode really well then I unironically respect that and that’s ok.<p>I’m not doing ground breaking software stuff, it’s just web dev at non massive scales.</div><br/><div id="41541980" class="c"><input type="checkbox" id="c-41541980" checked=""/><div class="controls bullet"><span class="by">__loam</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41541943">parent</a><span>|</span><a href="#41542025">next</a><span>|</span><label class="collapse" for="c-41541980">[-]</label><label class="expand" for="c-41541980">[6 more]</label></div><br/><div class="children"><div class="content">You future employer might expect you to bring some value through your expertise that doesn&#x27;t come from her LLM. If you want to insist on degrading your own employability like this, I guess it&#x27;s your choice.</div><br/><div id="41542679" class="c"><input type="checkbox" id="c-41542679" checked=""/><div class="controls bullet"><span class="by">fragmede</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41541980">parent</a><span>|</span><a href="#41543477">prev</a><span>|</span><a href="#41542025">next</a><span>|</span><label class="collapse" for="c-41542679">[-]</label><label class="expand" for="c-41542679">[4 more]</label></div><br/><div class="children"><div class="content">For the most part, businesses don&#x27;t care how you deliver value, just that you do. If programmer A does a ticket in 3 days with an LLM, and programmer B takes a week to do the same ticket, but doesn&#x27;t use an LLM, with programmer B choosing not to out of some notion of purity, who&#x27;s more employable?</div><br/><div id="41543974" class="c"><input type="checkbox" id="c-41543974" checked=""/><div class="controls bullet"><span class="by">__loam</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41542679">parent</a><span>|</span><a href="#41542025">next</a><span>|</span><label class="collapse" for="c-41543974">[-]</label><label class="expand" for="c-41543974">[3 more]</label></div><br/><div class="children"><div class="content">Productivity is not the only aspect of our profession that matters, and in fact it&#x27;s probably not even the most important part. I&#x27;m not suggesting we get stuck or handcraft every aspect of our code, and there are multitudes of abstractions and tools that enhance productivity, including everything from frameworks to compilers.<p>What I&#x27;m saying is what the original comment is doing, having the LLM write all their code, will make them a less valuable employee in the long term. Participating in the act of programming makes your a better programmer. I&#x27;d rather have programmer B if they take the time to understand their code, so that when that code breaks at 4am and they get the call, they can actually fix it rather than be in a hole they dug with LLMs that they can&#x27;t dig out of.</div><br/><div id="41544713" class="c"><input type="checkbox" id="c-41544713" checked=""/><div class="controls bullet"><span class="by">roenxi</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41543974">parent</a><span>|</span><a href="#41542025">next</a><span>|</span><label class="collapse" for="c-41544713">[-]</label><label class="expand" for="c-41544713">[2 more]</label></div><br/><div class="children"><div class="content">You don&#x27;t need to call them at 4am, you can keep a git log of the prompts that were used to generate the code and some professional 4am debugger can sit there and use an LLM to fix it.<p>Probably not a practical option yet, but if we&#x27;re looking at the long term that is where we are heading. Or, realistically, the even longer term where the LLM self-heals broken systems.</div><br/><div id="41545624" class="c"><input type="checkbox" id="c-41545624" checked=""/><div class="controls bullet"><span class="by">__loam</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41544713">parent</a><span>|</span><a href="#41542025">next</a><span>|</span><label class="collapse" for="c-41545624">[-]</label><label class="expand" for="c-41545624">[1 more]</label></div><br/><div class="children"><div class="content">Lol, yeah the prompt is definitely going to help clarify what the code actually does.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="41542025" class="c"><input type="checkbox" id="c-41542025" checked=""/><div class="controls bullet"><span class="by">Der_Einzige</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41541821">parent</a><span>|</span><a href="#41541943">prev</a><span>|</span><a href="#41541854">next</a><span>|</span><label class="collapse" for="c-41542025">[-]</label><label class="expand" for="c-41542025">[1 more]</label></div><br/><div class="children"><div class="content">See, if you work in AI, say, as an AI researcher, asking them not to be allowed to use AI models in the interview is basically not an option.<p>Also, often folks in this space are better at cheating than you will be at detecting them. Don&#x27;t believe me? <a href="https:&#x2F;&#x2F;bigvu.tv&#x2F;captions-video-maker&#x2F;ai-eye-contact-fix" rel="nofollow">https:&#x2F;&#x2F;bigvu.tv&#x2F;captions-video-maker&#x2F;ai-eye-contact-fix</a></div><br/></div></div></div></div><div id="41541854" class="c"><input type="checkbox" id="c-41541854" checked=""/><div class="controls bullet"><span class="by">apsurd</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41541754">parent</a><span>|</span><a href="#41541821">prev</a><span>|</span><a href="#41541922">next</a><span>|</span><label class="collapse" for="c-41541854">[-]</label><label class="expand" for="c-41541854">[2 more]</label></div><br/><div class="children"><div class="content">LLMs are certainly not useless.<p>But &quot;lines of code written&quot; is a hollow metric to prove utility. Code literacy is more effective than code illiteracy.<p>Lines of natural language vs discrete code is a kind of preference. Code is exact which makes it harder to recall and master. But it provides information density.<p>&gt; by just knuckling down and learning how to do the work?<p>This is the key for me. What work? If it&#x27;s the years of learning and practice toward proficiency to &quot;know it when you see it&quot; then I agree.</div><br/><div id="41544127" class="c"><input type="checkbox" id="c-41544127" checked=""/><div class="controls bullet"><span class="by">smileson2</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41541854">parent</a><span>|</span><a href="#41541922">next</a><span>|</span><label class="collapse" for="c-41544127">[-]</label><label class="expand" for="c-41544127">[1 more]</label></div><br/><div class="children"><div class="content">we&#x27;re a post illiteracy society now</div><br/></div></div></div></div><div id="41541922" class="c"><input type="checkbox" id="c-41541922" checked=""/><div class="controls bullet"><span class="by">anujsjpatel</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41541754">parent</a><span>|</span><a href="#41541854">prev</a><span>|</span><a href="#41544124">next</a><span>|</span><label class="collapse" for="c-41541922">[-]</label><label class="expand" for="c-41541922">[1 more]</label></div><br/><div class="children"><div class="content">For someone who didn&#x27;t study a STEM subject or CS in school, I&#x27;ve gone from 0 to publishing a production modern looking app in a matter of a few weeks (link to it on my profile).<p>Sure, it&#x27;s not the best (most maintainable, non-redundant styling) code that&#x27;s powering the app but it&#x27;s more than enough to put an MVP out to the world and see if there&#x27;s value&#x2F;interest in the product.</div><br/></div></div><div id="41544124" class="c"><input type="checkbox" id="c-41544124" checked=""/><div class="controls bullet"><span class="by">acedTrex</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41541754">parent</a><span>|</span><a href="#41541922">prev</a><span>|</span><a href="#41544045">next</a><span>|</span><label class="collapse" for="c-41544124">[-]</label><label class="expand" for="c-41544124">[6 more]</label></div><br/><div class="children"><div class="content">&gt; I&#x27;ve found that I haven&#x27;t written a line of code in weeks<p>How are people doing this, none of the code that gpt4o&#x2F;copilot&#x2F;sonnet spit out i ever use because it never meets my standards. How are other people accepting the shit it spits out.</div><br/><div id="41544166" class="c"><input type="checkbox" id="c-41544166" checked=""/><div class="controls bullet"><span class="by">viraptor</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41544124">parent</a><span>|</span><a href="#41544045">next</a><span>|</span><label class="collapse" for="c-41544166">[-]</label><label class="expand" for="c-41544166">[5 more]</label></div><br/><div class="children"><div class="content">You&#x27;re listing plain models, so I&#x27;m assuming you&#x27;re using them directly. Aider and similar agents use those models but they don&#x27;t step at the first answer. You can add test running and a linter to the request and it will essentially enter a loop like: what are the steps to solve (prompt)?; here&#x27;s a map of the repository, which files do you need?; what&#x27;s your proposed change?; here&#x27;s the final change and the test run, do you think the problem has been solved?; (go back to the beginning if not)<p>See the video at <a href="https:&#x2F;&#x2F;plandex.ai&#x2F;" rel="nofollow">https:&#x2F;&#x2F;plandex.ai&#x2F;</a> to get an idea how it works.</div><br/><div id="41544187" class="c"><input type="checkbox" id="c-41544187" checked=""/><div class="controls bullet"><span class="by">acedTrex</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41544166">parent</a><span>|</span><a href="#41544235">next</a><span>|</span><label class="collapse" for="c-41544187">[-]</label><label class="expand" for="c-41544187">[3 more]</label></div><br/><div class="children"><div class="content">That just sounds&#x2F;looks like more work then just doing it normally? what am I missing?</div><br/><div id="41544220" class="c"><input type="checkbox" id="c-41544220" checked=""/><div class="controls bullet"><span class="by">viraptor</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41544187">parent</a><span>|</span><a href="#41544212">next</a><span>|</span><label class="collapse" for="c-41544220">[-]</label><label class="expand" for="c-41544220">[1 more]</label></div><br/><div class="children"><div class="content">Depends on the task but if you&#x27;re going high level enough, it&#x27;s not more work. Think about it this way: if you&#x27;re doing proper development you&#x27;re going to write code, tests and commit messages. Since you know what you want to achieve, write a really good commit message as the prompt, start writing tests and let the agent run in the meantime. Worst case, it doesn&#x27;t work and you do the code yourself. Best case, it worked and you saved time.<p>(Not sure if that was clear but the steps&#x2F;loop described before happens automatically, you&#x27;re not babysitting it)</div><br/></div></div><div id="41544212" class="c"><input type="checkbox" id="c-41544212" checked=""/><div class="controls bullet"><span class="by">freeone3000</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41544187">parent</a><span>|</span><a href="#41544220">prev</a><span>|</span><a href="#41544235">next</a><span>|</span><label class="collapse" for="c-41544212">[-]</label><label class="expand" for="c-41544212">[1 more]</label></div><br/><div class="children"><div class="content">You put it behind an API call and run the loop automatically for every coding query</div><br/></div></div></div></div><div id="41544235" class="c"><input type="checkbox" id="c-41544235" checked=""/><div class="controls bullet"><span class="by">namanyayg</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41544166">parent</a><span>|</span><a href="#41544187">prev</a><span>|</span><a href="#41544045">next</a><span>|</span><label class="collapse" for="c-41544235">[-]</label><label class="expand" for="c-41544235">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m using Cursor and till now the &quot;test run&quot; part is manual, like Cursor doesn&#x27;t care about testing or actually checking the code it wrote works<p>Any tips how I could integrate that? Do I need to switch to aider&#x2F;plandex?</div><br/></div></div></div></div></div></div><div id="41544045" class="c"><input type="checkbox" id="c-41544045" checked=""/><div class="controls bullet"><span class="by">wokwokwok</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41541754">parent</a><span>|</span><a href="#41544124">prev</a><span>|</span><a href="#41544632">next</a><span>|</span><label class="collapse" for="c-41544045">[-]</label><label class="expand" for="c-41544045">[3 more]</label></div><br/><div class="children"><div class="content">&gt; I&#x27;ve found that I haven&#x27;t written a line of code in weeks<p>Please post a video of your workflow.<p>It’s incredibly valuable for people to see this in action, otherwise they, quite legitimately, will simply think this is not true.</div><br/><div id="41544438" class="c"><input type="checkbox" id="c-41544438" checked=""/><div class="controls bullet"><span class="by">Kiro</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41544045">parent</a><span>|</span><a href="#41544632">next</a><span>|</span><label class="collapse" for="c-41544438">[-]</label><label class="expand" for="c-41544438">[2 more]</label></div><br/><div class="children"><div class="content">Who cares what they think? In fact, the fewer who uses this the better for the ones that do. It&#x27;s not in my self-interest to convert anyone and I obviously don&#x27;t need to convince myself when I have the result right in front of me. Whether you believe it or not does not make me less productive.</div><br/><div id="41544802" class="c"><input type="checkbox" id="c-41544802" checked=""/><div class="controls bullet"><span class="by">wokwokwok</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41544438">parent</a><span>|</span><a href="#41544632">next</a><span>|</span><label class="collapse" for="c-41544802">[-]</label><label class="expand" for="c-41544802">[1 more]</label></div><br/><div class="children"><div class="content">The obvious answer is you’ll get called a liar and shrill.<p>I’m not saying you are; I think there are a lot of legitimate AI workflows people use.<p>…but, there are a lot of people trying to sell AI, and that makes them say things about it which are just flat out false.<p>&#x2F;shrug<p>But you know; freedom of speech; you can say whatever you want if you don’t care what people think of you.<p>My take on it is showing people things (videos, blogs, repos, workbooks like Terence posted) moves the conversation from “I don’t believe you” to “let’s talk about the actual content”. Wow, what an interesting workflow, maybe I’ll try that…<p>If you don’t want to talk to people or have a discussion that extends beyond meaningless trivia like “does AI actually have any value” (obviously flame bait opinions only comment threads)… why are you even here?<p>If <i>you</i> don’t care, then fine. Maybe someone else will and they’ll post an interesting video.<p>Isn’t that the point of reading HN threads? What do you win by telling people not to post examples of their workflow?<p>It’s incredibly selfish.</div><br/></div></div></div></div></div></div><div id="41544632" class="c"><input type="checkbox" id="c-41544632" checked=""/><div class="controls bullet"><span class="by">perching_aix</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41541754">parent</a><span>|</span><a href="#41544045">prev</a><span>|</span><a href="#41543243">next</a><span>|</span><label class="collapse" for="c-41544632">[-]</label><label class="expand" for="c-41544632">[1 more]</label></div><br/><div class="children"><div class="content">&gt; HN, and the internet in general, have become just an ocean of reactionary sandbagging and blather about how &quot;useless&quot; LLMs are.<p>Now imagine how profoundly depressing it is to visit a HN post like this one, and be immediately met with blatant tribalism like this at the very top.<p>Do you genuinely think that going on a performative tirade like this is what&#x27;s going to spark a more nuanced conversation? Or would you rather just the common sentiment be the same as yours? How many rounds of intellectual dishonesty do we need to figure this out?</div><br/></div></div><div id="41543243" class="c"><input type="checkbox" id="c-41543243" checked=""/><div class="controls bullet"><span class="by">rafaelmn</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41541754">parent</a><span>|</span><a href="#41544632">prev</a><span>|</span><a href="#41543819">next</a><span>|</span><label class="collapse" for="c-41543243">[-]</label><label class="expand" for="c-41543243">[1 more]</label></div><br/><div class="children"><div class="content">I use sonet 3.5 and while it&#x27;s actually usable for codegen (compared to gpt&#x2F;copilot) it&#x27;s still really not that great. It does well at tasks like &quot;here&#x27;s a stinky collection of tests that accrued over time - clean this up in style of x&quot; but actually writing code still shows fundamental lack of understanding of underlying API and problem (the most banal example being constantly generating `x || Array.isArray(x)` test)</div><br/></div></div><div id="41541918" class="c"><input type="checkbox" id="c-41541918" checked=""/><div class="controls bullet"><span class="by">delusional</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41541754">parent</a><span>|</span><a href="#41543819">prev</a><span>|</span><a href="#41542308">next</a><span>|</span><label class="collapse" for="c-41541918">[-]</label><label class="expand" for="c-41541918">[7 more]</label></div><br/><div class="children"><div class="content">What sort of problems do you solve? I tried to use it. I really did. I&#x27;ve been working on a tree edit distance implementation base on a paper from 95. Not novel stuff. I just can&#x27;t get it to output anything coherent. The code rarely runs, it&#x27;s written in absolutely terrible style, it doesn&#x27;t follow any good practices for performant code. I&#x27;ve struggled with getting it to even implement the algorithm correctly, even though it&#x27;s in the literature I&#x27;m sure it was trained on.<p>Even test cases have brought me no luck. The code was poorly written, being too complicated and dynamic for test code in the best case and just wrong on average. It constantly generated test cases that would be fine for other definitions of &quot;tree edit distance&quot; but were nonsense for my version of a &quot;tree edit distance&quot;.<p>What are you doing where any of this actually works? I&#x27;m not some jaded angry internet person, but I&#x27;m honestly so flabbergasted about why I just can&#x27;t get anything good out of this machine.</div><br/><div id="41543699" class="c"><input type="checkbox" id="c-41543699" checked=""/><div class="controls bullet"><span class="by">macrolime</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41541918">parent</a><span>|</span><a href="#41542761">next</a><span>|</span><label class="collapse" for="c-41543699">[-]</label><label class="expand" for="c-41543699">[3 more]</label></div><br/><div class="children"><div class="content">This kind of problems is really not where LLMs shine.<p>Where you save loads of time is when you need to write lots of code using unfamiliar APIs. Especially when it&#x27;s APIs you won&#x27;t work with a lot and spending loads of time learning then would just be a waste of time. In these cases LLMs call tell you the correct API cells and it&#x27;s easy to verify. The LLM isn&#x27;t really solving some difficult technical problem, but saves lots of work.</div><br/><div id="41544189" class="c"><input type="checkbox" id="c-41544189" checked=""/><div class="controls bullet"><span class="by">throwaway765123</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41543699">parent</a><span>|</span><a href="#41542761">next</a><span>|</span><label class="collapse" for="c-41544189">[-]</label><label class="expand" for="c-41544189">[2 more]</label></div><br/><div class="children"><div class="content">This exactly. LLMs can&#x27;t reason, so we shouldn&#x27;t expect them to try. They can do translation extremely well, so things like converting descriptions to 90-95% correct code in 10-100x less time, or converting from one language to another, are the killer use cases IMO.<p>But expecting them to solve difficult unsolved problems is a fundamental misunderstanding of what they are under the hood.</div><br/><div id="41545676" class="c"><input type="checkbox" id="c-41545676" checked=""/><div class="controls bullet"><span class="by">delusional</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41544189">parent</a><span>|</span><a href="#41542761">next</a><span>|</span><label class="collapse" for="c-41545676">[-]</label><label class="expand" for="c-41545676">[1 more]</label></div><br/><div class="children"><div class="content">I picked this problem specifically because it&#x27;s about &quot;converting from one language to another&quot;. The problem is already solved in the literature. I understand that doing cutting edge research is a different problem, and that is explicitly not what I&#x27;m doing here, nor what I am expecting of the tool. I have coauthored an actual published computer science paper, and this excercise is VERY far from the complexity of that.<p>Could you share some concrete experience of a problem where aider, or a tool like it, helped you? What was your workflow, and how was the experience?</div><br/></div></div></div></div></div></div><div id="41542761" class="c"><input type="checkbox" id="c-41542761" checked=""/><div class="controls bullet"><span class="by">thesz</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41541918">parent</a><span>|</span><a href="#41543699">prev</a><span>|</span><a href="#41543096">next</a><span>|</span><label class="collapse" for="c-41542761">[-]</label><label class="expand" for="c-41542761">[1 more]</label></div><br/><div class="children"><div class="content">I think that contemporary models are trained for engagement, not for actual help.<p>My experience is the same as yours, but I noticed that while LLMs circa two years ago tried to come up with the answer, current generation of LLMs tries to make me come with the answer. And that not helping at all.</div><br/></div></div><div id="41543096" class="c"><input type="checkbox" id="c-41543096" checked=""/><div class="controls bullet"><span class="by">bongodongobob</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41541918">parent</a><span>|</span><a href="#41542761">prev</a><span>|</span><a href="#41542308">next</a><span>|</span><label class="collapse" for="c-41543096">[-]</label><label class="expand" for="c-41543096">[2 more]</label></div><br/><div class="children"><div class="content">Did you tell it that? Are you trying to converse and discuss or are you trying to one shot stuff? If it gets something wrong, tell it. Don&#x27;t just stop and try another prompt. You have to think of it as another person. You can talk to it, question it, guide it.<p>Try starting from ground zero and guiding it to the solution rather than trying to one shot your entire solution in one go.<p>I want you to implement this kind of tree in language x.<p>Ok good, now I want you to modify it to do Y.<p>Etc.</div><br/><div id="41543573" class="c"><input type="checkbox" id="c-41543573" checked=""/><div class="controls bullet"><span class="by">delusional</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41543096">parent</a><span>|</span><a href="#41542308">next</a><span>|</span><label class="collapse" for="c-41543573">[-]</label><label class="expand" for="c-41543573">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve tried both. One time I actually tried so hard that I ran out of context, and aider just dumped me back to the main prompt.  I don&#x27;t think It&#x27;s possible to guide it any more than that.<p>My problem is that the solution is right there in the paper. I just have to understand it. Without first understanding that paper, I can&#x27;t possibly guide the AI towards a reasonable implementation. The process of finding the implementation is exactly the understanding of the paper, and the AI just doesn&#x27;t help me with that. In fact, all too often I would ask it to make some minor change, and it would start making random changes all over the file, completely destroying my mental model of how the program worked. Making it change that back completely pulls me out of the problem.<p>When it&#x27;s a junior at my job, at least I can feel like I&#x27;m developing a person. They retain the conversation and culture I impart as part of the problem solving process. When I struggle against the computer, it&#x27;s just a waste of my time. It&#x27;s not learning anything.<p>I&#x27;m still really curious what you&#x27;re doing with it.</div><br/></div></div></div></div></div></div><div id="41542308" class="c"><input type="checkbox" id="c-41542308" checked=""/><div class="controls bullet"><span class="by">ijustlovemath</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41541754">parent</a><span>|</span><a href="#41541918">prev</a><span>|</span><a href="#41541864">next</a><span>|</span><label class="collapse" for="c-41542308">[-]</label><label class="expand" for="c-41542308">[1 more]</label></div><br/><div class="children"><div class="content">How much do you typically pay in a month of tokens?</div><br/></div></div><div id="41541864" class="c"><input type="checkbox" id="c-41541864" checked=""/><div class="controls bullet"><span class="by">threeseed</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41541754">parent</a><span>|</span><a href="#41542308">prev</a><span>|</span><a href="#41544108">next</a><span>|</span><label class="collapse" for="c-41541864">[-]</label><label class="expand" for="c-41541864">[11 more]</label></div><br/><div class="children"><div class="content">&gt; HN, and the internet in general, have become just an ocean of reactionary sandbagging and blather about how &quot;useless&quot; LLMs are.<p>This is cult like behaviour that reminds me so much of the crypto space.<p>I don&#x27;t understand why people are not allowed to be critical of a technology or not find it useful.<p>And if they are they are somehow ignorant, over-reacting or deficient in some way.</div><br/><div id="41542009" class="c"><input type="checkbox" id="c-41542009" checked=""/><div class="controls bullet"><span class="by">wenc</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41541864">parent</a><span>|</span><a href="#41542678">next</a><span>|</span><label class="collapse" for="c-41542009">[-]</label><label class="expand" for="c-41542009">[5 more]</label></div><br/><div class="children"><div class="content">I think it&#x27;s perfectly ok to be critical of technology as long as one is thoughtful rather than dismissive. There is a lot of hype right now and pushing back against it is the right thing to do.<p>I&#x27;m more reacting against simplistic and categorical pronouncements of straight up &quot;uselessness,&quot; which to me seems un-curious and deeply cynical, especially since it is evidentially untrue in many domains (though it is true for some domains). I just find this kind of emotional cynicism (not a healthy skepticism, but cynicism) to be contrary to the spirit of innovation and openness, and indeed contrary to evidence. It&#x27;s also an overgeneralization -- &quot;I don&#x27;t find it useful, so it&#x27;s useless&quot; -- rather than &quot;Why don&#x27;t I find it useful, and why do others do? Let me learn more.&quot;<p>As future-looking HNers, I&#x27;d expect we would understand the world through a lens of &quot;trajectories&quot; rather than &quot;current state&quot;. Just because LLMs hallucinate and make mistakes with a tone of confidence today -- a deep weakness -- doesn&#x27;t mean they are altogether useless. We&#x27;ve witnessed that despite their weaknesses, we are getting a lot of value from them in many domains today and they are getting better over time.<p>Take neural networks themselves for instance. For most of the 90s-2000s, people thought they were a dead end. My own professor had great vitriol against Neural Networks. Most of the initial promises in the 80s truly didn&#x27;t pan out. Turns out what was missing was (lots of) data, which the Internet provided. And look where we are today.<p>Another area of cynicism is self-driving cars (Level 5). Lots of hype and overpromise, and lots of people saying it will never happen because it requires a cognitive model of the world, which is too complicated, and there are too many exceptional cases for there to ever be Level 5 autonomy. Possibly true, but I think &quot;never&quot; is a very strong sentiment that is unworthy of a curious person.</div><br/><div id="41542440" class="c"><input type="checkbox" id="c-41542440" checked=""/><div class="controls bullet"><span class="by">rainsford</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41542009">parent</a><span>|</span><a href="#41542114">next</a><span>|</span><label class="collapse" for="c-41542440">[-]</label><label class="expand" for="c-41542440">[2 more]</label></div><br/><div class="children"><div class="content">I generally agree, although an important aspect of thinking in terms of &quot;trajectories&quot; is recognizing when a particular trajectory might end up at a dead end.  One perspective on the weaknesses of current LLMs is that it&#x27;s just where the things are today and they can still provide value even while the technology improves.  But another perspective is that the persistence of these weaknesses indicates something more fundamentally broken with the whole approach that means it&#x27;s not really the path towards &quot;real&quot; AI, even if you can finesse it into doing useful things in certain applications.<p>There&#x27;s also an important nuance differentiating rejection of a general technological endpoint (e.g. AGI or Level 5 self-driving cars) with a particular technological approach to achieving those goals (e.g. current LLM design or Tesla&#x27;s autopilot).  As you said, &quot;never&quot; is a long time and it takes a lot of unwarranted confidence to say we will never be able to achieve goals like AGI or Level 5 self-driving.  But it seems a lot more reasonable to argue Tesla or OpenAI (and everyone else doing essentially the same thing as OpenAI) are fundamentally on the wrong track to achieving those goals without significantly changing their approach.<p>I agree that none of that really warrants dismissive cynicism of new technology, but being curious and future-looking also requires being willing to say when you think something is a bad approach even if it&#x27;s not totally useless.  Among other reasons, our ability to explore new technology is not limitless, and hype for a flawed technology isn&#x27;t just annoying but may be sucking all the oxygen out of the room not leaving any for a potentially better alternative.  Part of me wants to be optimistic about LLMs, but another part of me thinks about how much energy (human and compute) has gone into this thing that does not seem to be providing a corresponding amount of value.</div><br/><div id="41542706" class="c"><input type="checkbox" id="c-41542706" checked=""/><div class="controls bullet"><span class="by">wenc</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41542440">parent</a><span>|</span><a href="#41542114">next</a><span>|</span><label class="collapse" for="c-41542706">[-]</label><label class="expand" for="c-41542706">[1 more]</label></div><br/><div class="children"><div class="content">I appreciate this thoughtful comment.<p>You are absolutely right that the trajectories, if taken linearly, might hit a dead end. I should clarify that when I mentioned &quot;trajectories&quot; I don&#x27;t mean unpunctuated ones.<p>I am myself not convinced that LLMs -- despite their value to me today -- will eventually lead to AGI as a matter of course, nor the type of techniques used in autopilot will lead to L5 autonomy. And you&#x27;re right that they are consuming a lot of our resources, which could well be better invested in a possibly better alternative.<p>I subscribe to Thomas Kuhn&#x27;s [1] idea of scientific progress happening in &quot;paradigms&quot; rather than through a linear accumulation of knowledge. For instance, the path to LLMs itself was not linear, but through a series of new paradigms disrupting older ones. Early natural language processing was more rule-based (paradigm), then it became more statistical (paradigm),  and then LLMs supplanted the old paradigms through transformers (paradigm) which made it scale to large swaths of data. I believe there is still significant runway left for LLMs, but I expect another paradigm must supplant it to get closer to AGI. (Yann Lecun said that he doesn&#x27;t believe LLMs will lead to AGI).<p>Does that mean the current exuberant high investments in LLMs are misplaced? Possibly, but in Kuhn&#x27;s philosophy, typically what happens is a paradigm will be milked for as much as it can be, until it reaches a crisis&#x2F;anomaly when it doesn&#x27;t work anymore, at which point another paradigm will supplant it.<p>At present, we are seeing how far we can push LLMs, and LLMs as they are have value even today, so it&#x27;s not a bad approach per se even though it will hit its limits at some point. Perhaps what is more important are the second-order effects: the investments we are seeing in GPUs (essentially we are betting on linear algebra) might unlock the kind of commodity computational power the next paradigm needs to disrupt the current one. I see parallels between this and investments in NASA resulting in many technologies that we take for granted today, and military  spend in California producing the technology base that enabled Silicon Valley today. Of course, these are just speculations and I have no more evidence that this is happening with LLMs than anyone else.<p>I appreciate your point however and it is always good to step back and ask, non-cynically, whether we are headed down a good path.<p>[1] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;The_Structure_of_Scientific_Revolutions" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;The_Structure_of_Scientific_Re...</a></div><br/></div></div></div></div><div id="41542114" class="c"><input type="checkbox" id="c-41542114" checked=""/><div class="controls bullet"><span class="by">threeseed</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41542009">parent</a><span>|</span><a href="#41542440">prev</a><span>|</span><a href="#41542678">next</a><span>|</span><label class="collapse" for="c-41542114">[-]</label><label class="expand" for="c-41542114">[2 more]</label></div><br/><div class="children"><div class="content">This entire comment can be summarised as: everyone who doesn&#x27;t think like me is wrong.<p>Not everyone is interested in seeing the world through the hopes and dreams of e&#x2F;acc types and would prefer to see it as it is today.<p>LLMs are a technology. Nothing more. It can be as amazing or useless as anyone likes.</div><br/><div id="41542730" class="c"><input type="checkbox" id="c-41542730" checked=""/><div class="controls bullet"><span class="by">fragmede</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41542114">parent</a><span>|</span><a href="#41542678">next</a><span>|</span><label class="collapse" for="c-41542730">[-]</label><label class="expand" for="c-41542730">[1 more]</label></div><br/><div class="children"><div class="content">And this comment can be summarized as &quot;Nuh uh, I&#x27;m right&quot;. When summarizing longer bits of text down to a single sentence, nuance and meaning gets lost, making the summarization ultimatele useless, contributing nothing to the discussion.</div><br/></div></div></div></div></div></div><div id="41542678" class="c"><input type="checkbox" id="c-41542678" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41541864">parent</a><span>|</span><a href="#41542009">prev</a><span>|</span><a href="#41542111">next</a><span>|</span><label class="collapse" for="c-41542678">[-]</label><label class="expand" for="c-41542678">[1 more]</label></div><br/><div class="children"><div class="content">Crypro and AI have similarities and differences.<p>The similarities include intense &quot;true believer&quot; pitches and governments taking them seriously.<p>The differences include that the most famous cryptocurrency can&#x27;t function as a direct payment mechanism for just lunch purchases in just Berlin (IIRC nor is it enough for all interbank transactions so it can&#x27;t even be a behind-the-scenes system by itself), while GenAI output keeps ending up in places people would rather not find it like homework and that person on Twitter who&#x27;s telling you Russia Did Nothing Wrong (and also giving you a nice cheesecake recipe because they don&#x27;t do any input sanitation).</div><br/></div></div><div id="41542111" class="c"><input type="checkbox" id="c-41542111" checked=""/><div class="controls bullet"><span class="by">wenc</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41541864">parent</a><span>|</span><a href="#41542678">prev</a><span>|</span><a href="#41542525">next</a><span>|</span><label class="collapse" for="c-41542111">[-]</label><label class="expand" for="c-41542111">[3 more]</label></div><br/><div class="children"><div class="content">Also, I&#x27;m deeply skeptical of crypto too due to its present scamminess, but I am keeping an open mind that there is a future in which crypto -- once it gets over this phase of get-rich-quick schemers -- will be seen as just another asset class.<p>I read somewhere that historically bonds in their early days were also associated with scamminess but today they&#x27;re just a vanilla asset.</div><br/><div id="41542640" class="c"><input type="checkbox" id="c-41542640" checked=""/><div class="controls bullet"><span class="by">rainsford</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41542111">parent</a><span>|</span><a href="#41542528">next</a><span>|</span><label class="collapse" for="c-41542640">[-]</label><label class="expand" for="c-41542640">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m honestly more optimistic about cryptocurrency as a mechanism of exchange rather than an asset.  As a mechanism of exchange, cryptocurrency has some actually novel properties like distributed consensus that could be useful in certain cases.  But an asset class which has zero backing value seems unworkable except for wild speculation and scams.  Unfortunately the incentives around most cryptocurrencies (and maybe fundamental to cryptocurrency as an idea) greatly emphasize the asset aspects, and it&#x27;s getting to be long enough since it became a thing that I&#x27;m starting to become skeptical cryptocurrency will be a real medium of exchange outside of illegal activities and maybe a few other niche cases.</div><br/></div></div><div id="41542528" class="c"><input type="checkbox" id="c-41542528" checked=""/><div class="controls bullet"><span class="by">evilfred</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41542111">parent</a><span>|</span><a href="#41542640">prev</a><span>|</span><a href="#41542525">next</a><span>|</span><label class="collapse" for="c-41542528">[-]</label><label class="expand" for="c-41542528">[1 more]</label></div><br/><div class="children"><div class="content">bonds have utility, crypto does not</div><br/></div></div></div></div><div id="41542525" class="c"><input type="checkbox" id="c-41542525" checked=""/><div class="controls bullet"><span class="by">evilfred</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41541864">parent</a><span>|</span><a href="#41542111">prev</a><span>|</span><a href="#41544108">next</a><span>|</span><label class="collapse" for="c-41542525">[-]</label><label class="expand" for="c-41542525">[1 more]</label></div><br/><div class="children"><div class="content">just like with crypto and NFTs and the metaverse, they are always focused on what is suppsoedly coming down the pipe in the future and not what is actually possible today</div><br/></div></div></div></div><div id="41544108" class="c"><input type="checkbox" id="c-41544108" checked=""/><div class="controls bullet"><span class="by">skybrian</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41541754">parent</a><span>|</span><a href="#41541864">prev</a><span>|</span><a href="#41542976">next</a><span>|</span><label class="collapse" for="c-41544108">[-]</label><label class="expand" for="c-41544108">[2 more]</label></div><br/><div class="children"><div class="content">What sort of code do you write this way?</div><br/><div id="41545745" class="c"><input type="checkbox" id="c-41545745" checked=""/><div class="controls bullet"><span class="by">sph</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41544108">parent</a><span>|</span><a href="#41542976">next</a><span>|</span><label class="collapse" for="c-41545745">[-]</label><label class="expand" for="c-41545745">[1 more]</label></div><br/><div class="children"><div class="content">Probably nothing a junior programmer wouldn&#x27;t be able to do relatively easily.</div><br/></div></div></div></div><div id="41542976" class="c"><input type="checkbox" id="c-41542976" checked=""/><div class="controls bullet"><span class="by">amrrs</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41541754">parent</a><span>|</span><a href="#41544108">prev</a><span>|</span><a href="#41542428">next</a><span>|</span><label class="collapse" for="c-41542976">[-]</label><label class="expand" for="c-41542976">[1 more]</label></div><br/><div class="children"><div class="content">Curious why Aider? Why not Cursor ?</div><br/></div></div><div id="41542428" class="c"><input type="checkbox" id="c-41542428" checked=""/><div class="controls bullet"><span class="by">evilfred</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41541754">parent</a><span>|</span><a href="#41542976">prev</a><span>|</span><a href="#41541859">next</a><span>|</span><label class="collapse" for="c-41542428">[-]</label><label class="expand" for="c-41542428">[3 more]</label></div><br/><div class="children"><div class="content">writing code is the easy part, designing is hard and not LLMable</div><br/><div id="41542766" class="c"><input type="checkbox" id="c-41542766" checked=""/><div class="controls bullet"><span class="by">fragmede</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41542428">parent</a><span>|</span><a href="#41543121">next</a><span>|</span><label class="collapse" for="c-41542766">[-]</label><label class="expand" for="c-41542766">[1 more]</label></div><br/><div class="children"><div class="content">Given how hard we thought programming was a year or two ago, I wouldn&#x27;t bank my future on design being too hard for an LLM. They&#x27;re already quite good at helping writing design docs.</div><br/></div></div><div id="41543121" class="c"><input type="checkbox" id="c-41543121" checked=""/><div class="controls bullet"><span class="by">bongodongobob</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41542428">parent</a><span>|</span><a href="#41542766">prev</a><span>|</span><a href="#41541859">next</a><span>|</span><label class="collapse" for="c-41543121">[-]</label><label class="expand" for="c-41543121">[1 more]</label></div><br/><div class="children"><div class="content">Lol nope. When I&#x27;m trying to get it do make something big&#x2F;complicated I start by telling it it&#x27;s a software project manager and have me build a spec sheet on the design. Then I hand that off to an architect to flesh out the languages, libraries, files needed etc. Then from that list you can have it work on individual files and functions.</div><br/></div></div></div></div><div id="41541859" class="c"><input type="checkbox" id="c-41541859" checked=""/><div class="controls bullet"><span class="by">riku_iki</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41541754">parent</a><span>|</span><a href="#41542428">prev</a><span>|</span><a href="#41541951">next</a><span>|</span><label class="collapse" for="c-41541859">[-]</label><label class="expand" for="c-41541859">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Meanwhile, in the real world, I&#x27;ve found that I haven&#x27;t written a line of code in weeks. Just paragraphs of text that specify what I want and then guidance through and around pitfalls in a simple iterative loop of useful working code.<p>could it be that you are mostly engaged in &quot;boilerplate coding&quot;, where LLMs are indeed good?</div><br/></div></div><div id="41541951" class="c"><input type="checkbox" id="c-41541951" checked=""/><div class="controls bullet"><span class="by">holoduke</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41541754">parent</a><span>|</span><a href="#41541859">prev</a><span>|</span><a href="#41544372">next</a><span>|</span><label class="collapse" for="c-41541951">[-]</label><label class="expand" for="c-41541951">[1 more]</label></div><br/><div class="children"><div class="content">People in general don&#x27;t like change and are naturally defending against it. And the older people get the greater the percentage of people fighting against it. A very useful and powerful skill is to be flexible and adaptable. You positioned yourself in the happy few.</div><br/></div></div></div></div><div id="41544372" class="c"><input type="checkbox" id="c-41544372" checked=""/><div class="controls bullet"><span class="by">sterlind</span><span>|</span><a href="#41541372">parent</a><span>|</span><a href="#41541754">prev</a><span>|</span><a href="#41544727">next</a><span>|</span><label class="collapse" for="c-41544372">[-]</label><label class="expand" for="c-41544372">[1 more]</label></div><br/><div class="children"><div class="content">I also do OR-adjacent work, but I&#x27;ve had much less luck using 4o for formulating MIPs. It tends to deliver correct-looking answers with handwavy explanations of the math, but the equations don&#x27;t work and the reasoning doesn&#x27;t add up.<p>It&#x27;s a strange experience, like taking a math class where the proofs are weird and none of the lessons click for you, and you start feeling stupid, only to learn your professor is an escaped dementia patient and it was gobbledygook to begin with.<p>I had a similar experience yesterday using o1 to see if a simple path exists through s to t through v using max flow. It gave me a very convincing-looking algorithm that was fundamentally broken. My working solution used some techniques from its failed attempt, but even after repeated hints it failed to figure out a working answer (it stubbornly kept finding s-&gt;t flows, rather than realizing v-&gt;{s,t} was the key.)<p>It&#x27;s also extremely mentally fatiguing to check its reasoning. I almost suspect that RLHF has selected for obfuscating its reasoning, since obviously-wrong answers are easier to detect and penalize than subtly-wrong answers.</div><br/></div></div><div id="41544727" class="c"><input type="checkbox" id="c-41544727" checked=""/><div class="controls bullet"><span class="by">CJefferson</span><span>|</span><a href="#41541372">parent</a><span>|</span><a href="#41544372">prev</a><span>|</span><a href="#41543288">next</a><span>|</span><label class="collapse" for="c-41544727">[-]</label><label class="expand" for="c-41544727">[7 more]</label></div><br/><div class="children"><div class="content">I&#x27;m currently teaching a course on MIP, and out of interest I tried asking 4o about some questions I ask students. It could give the &#x27;basic building blocks&#x27; (How to do x!=y, how to do a knapsack), but as soon as I asked it a vaguely interesting question that wasn&#x27;t &quot;bookwork&quot;, I don&#x27;t think any of it&#x27;s models were right.<p>I&#x27;m interested on how you seem to be getting better answers than me (or, maybe I just discard the answer once I can see it&#x27;s wrong and write it myself, once I see it&#x27;s wrong?)<p>In fact, I just asked it to do (and explain) x!=y for x,y integer variables in the range {1..9}, and while the constraints are right, the explanation isn&#x27;t.</div><br/><div id="41544963" class="c"><input type="checkbox" id="c-41544963" checked=""/><div class="controls bullet"><span class="by">wenc</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41544727">parent</a><span>|</span><a href="#41544830">prev</a><span>|</span><a href="#41543288">next</a><span>|</span><label class="collapse" for="c-41544963">[-]</label><label class="expand" for="c-41544963">[5 more]</label></div><br/><div class="children"><div class="content">I had to prompt it correctly (tell it to exclude x=y case in the x≠y formulation), but ChatGPT seems to have arrived at the correct answer:<p><a href="https:&#x2F;&#x2F;chatgpt.com&#x2F;share&#x2F;66e652e1-8e2c-800c-abaa-92e29e0550d2" rel="nofollow">https:&#x2F;&#x2F;chatgpt.com&#x2F;share&#x2F;66e652e1-8e2c-800c-abaa-92e29e0550...</a></div><br/><div id="41545038" class="c"><input type="checkbox" id="c-41545038" checked=""/><div class="controls bullet"><span class="by">CJefferson</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41544963">parent</a><span>|</span><a href="#41543288">next</a><span>|</span><label class="collapse" for="c-41545038">[-]</label><label class="expand" for="c-41545038">[4 more]</label></div><br/><div class="children"><div class="content">OK, but at that point you&#x27;ve told it basically everything, and this is a really basic book problem!<p>As another example I just gave it a network flow problem, and asked it to convert to maximum flow (I&#x27;m using the API, not chatGPT).<p>Despite numerous promptings, it never got it right -- it would not stop putting a limit on the source and sink (usually 1), which mean the flow was always exactly 1, here&#x27;s the bit of wrong code (it&#x27;s the last part, it&#x27;s shouldn&#x27;t be putting any restrictions on nmap[&#x27;s&#x27;] and nmap[&#x27;t&#x27;], as they represent the source and sink), and I couldn&#x27;t pursade it this was wrong after several prods:<p><pre><code>    # Constraints: Ensure flow conservation at each vertex
    A_eq = np.zeros((len(namelist), num_edges))
    b_eq = np.zeros(len(namelist))

    for i, (u, v, capacity) in enumerate(edges):
        A_eq[nmap[u], i] = 1  # Outflow from u
        A_eq[nmap[v], i] = -1  # Inflow to v

    # Source &#x27;s&#x27; has a net outflow, and sink &#x27;t&#x27; has a net inflow
    b_eq[nmap[&#x27;s&#x27;]] = 1
    b_eq[nmap[&#x27;t&#x27;]] = -1</code></pre></div><br/><div id="41545052" class="c"><input type="checkbox" id="c-41545052" checked=""/><div class="controls bullet"><span class="by">wenc</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41545038">parent</a><span>|</span><a href="#41543288">next</a><span>|</span><label class="collapse" for="c-41545052">[-]</label><label class="expand" for="c-41545052">[3 more]</label></div><br/><div class="children"><div class="content">Sure, but that is nature of LLM prompting. It does take some doing to set up the right guardrails. It&#x27;s still a good starting point.<p>Also a trick when the LLM fights you: start from scratch, and put guardrails in your initial prompt.<p>LLM prompting is a bit like gradient descent in a bumpy nonconvex landscape with lots of spurious optima and saddle points -- if you constrain it to the right locality, it does a better job at finding an acceptable local optimum.</div><br/><div id="41545177" class="c"><input type="checkbox" id="c-41545177" checked=""/><div class="controls bullet"><span class="by">CJefferson</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41545052">parent</a><span>|</span><a href="#41543288">next</a><span>|</span><label class="collapse" for="c-41545177">[-]</label><label class="expand" for="c-41545177">[2 more]</label></div><br/><div class="children"><div class="content">I think this is just a case of different people wanting to work differently (and that&#x27;s fine).<p>I can only tell this is wrong because I fully understand it -- and if I fully understand it, why not just write it myself rather than fight against an LLM. If I was trying to solve something I didn&#x27;t know how to do, then I wouldn&#x27;t know it was wrong, and where the bug was.</div><br/><div id="41545421" class="c"><input type="checkbox" id="c-41545421" checked=""/><div class="controls bullet"><span class="by">wenc</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41545177">parent</a><span>|</span><a href="#41543288">next</a><span>|</span><label class="collapse" for="c-41545421">[-]</label><label class="expand" for="c-41545421">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s true, except an LLM can sometimes propose a formulation that one has never thought of. In nuanced cases, there is more than one formulation that works.<p>For MIPs, correctness can often (not always but usually) be checked by simply flipping the binaries and checking the inequalities. Coming up the inequalities from scratch are not always straightforward so LLMs often provide good starting points. Sometimes the formulation is something specific from a paper that that one has never read. LLMs are a way to &quot;mine&quot; those answers (some sifting required).<p>I think this the mindset that is needed to get value out of LLMs -- it&#x27;s not about getting perfect answers on textbook problems, but working with an assistant to explore the space quickly at a fraction of the effort.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="41543288" class="c"><input type="checkbox" id="c-41543288" checked=""/><div class="controls bullet"><span class="by">l33t7332273</span><span>|</span><a href="#41541372">parent</a><span>|</span><a href="#41544727">prev</a><span>|</span><a href="#41541790">next</a><span>|</span><label class="collapse" for="c-41543288">[-]</label><label class="expand" for="c-41543288">[5 more]</label></div><br/><div class="children"><div class="content">I an also working in OR and I have had the complete opposite experience with respect to MILP optimization(and the research actually agrees; there was a big survey paper published earlier this year showing LLMs were mostly correct on textbook problems but got more and more useless as complexity and novelty increased.)<p>The results are boiler plate at best, but misleading and insidious at worst, especially when you get into detailed tasks. Ever try to ask a LLM what a specific constraint does or worse ask it to explain the mathematical model of some proprietary CPLEX syntactic sugar? It hallucinates the math, the syntax, the explanation, everything.</div><br/><div id="41545525" class="c"><input type="checkbox" id="c-41545525" checked=""/><div class="controls bullet"><span class="by">marmakoide</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41543288">parent</a><span>|</span><a href="#41543698">next</a><span>|</span><label class="collapse" for="c-41545525">[-]</label><label class="expand" for="c-41545525">[1 more]</label></div><br/><div class="children"><div class="content">I had the same experience with computational geometry.<p>Very good at giving a textbook answer (&quot;give a Python&#x2F; Numpy function that returns the Voronoi diagram of set of 2d points&quot;).<p>Now, I ask for the Laguerre diagram, a variation that is not mentioned in textbooks, but very useful in practice. I can spend a lot of time spoon-feeding the answer, I just have the bullshiting student answers.<p>I tried other problems like numerical approximation, physics simulation, same experience.<p>I don&#x27;t get the hype. Maybe it&#x27;s good at giving variations of glue code ie. Stack Overflow meet autocomplete ? As a search tool it&#x27;s bad because it&#x27;s so confidently incorrect, you may be fooled by bad answers.</div><br/></div></div><div id="41543698" class="c"><input type="checkbox" id="c-41543698" checked=""/><div class="controls bullet"><span class="by">wenc</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41543288">parent</a><span>|</span><a href="#41545525">prev</a><span>|</span><a href="#41541790">next</a><span>|</span><label class="collapse" for="c-41543698">[-]</label><label class="expand" for="c-41543698">[3 more]</label></div><br/><div class="children"><div class="content">Can you point me to that paper? What version of the model were they using?<p>Have you tried again with the latest LLMs? ChatGPT4 actually (correctly) explains what each constraint does in English -- it doesn&#x27;t just provide the constraint when you ask it for the formulation. Also, not sure if CPLEX should be involved at all -- I usually just ask it for mathematical formulations, not CPLEX calling code (I don&#x27;t use CPLEX). The OR literature primarily contains math formulations and that&#x27;s where LLMs can best do pattern matching to problem shape.<p>Many of the standard formulations are in here:<p><a href="https:&#x2F;&#x2F;msi-jp.com&#x2F;xpress&#x2F;learning&#x2F;square&#x2F;10-mipformref.pdf" rel="nofollow">https:&#x2F;&#x2F;msi-jp.com&#x2F;xpress&#x2F;learning&#x2F;square&#x2F;10-mipformref.pdf</a><p>All the LLM is doing is fitting the problem description to a combination of these formulations (and others).</div><br/><div id="41544949" class="c"><input type="checkbox" id="c-41544949" checked=""/><div class="controls bullet"><span class="by">l33t7332273</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41543698">parent</a><span>|</span><a href="#41541790">next</a><span>|</span><label class="collapse" for="c-41544949">[-]</label><label class="expand" for="c-41544949">[2 more]</label></div><br/><div class="children"><div class="content">I was referring to section 4 of A Survey for Solving Mixed Integer Programming via Machine Learning(2024): <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2401.03244" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2401.03244</a>.<p>I’ve heard (but not so much observed) that there is substantial difference between recent models, so it’s possible that they are better than when this was written.<p>Anyways, CPLEX has an associated modeling language that features syntactic sugar which has the effect of providing opaqueness to the underlying MILP that it solves. I find LLMs essentially unable to even make an attempt at determining the MILP from that language.<p>PS: How is Xpress? Is there some reason to prefer it to Gurobi or Mosek?</div><br/><div id="41544995" class="c"><input type="checkbox" id="c-41544995" checked=""/><div class="controls bullet"><span class="by">wenc</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41544949">parent</a><span>|</span><a href="#41541790">next</a><span>|</span><label class="collapse" for="c-41544995">[-]</label><label class="expand" for="c-41544995">[1 more]</label></div><br/><div class="children"><div class="content">Thanks for sharing that, I appreciate it. It looks like they used open-source Llama models which are not great. I tested these models offline using Ollama and outside of being character chat bots, they weren&#x27;t very good at much (the only models that give good answers are Sonnet 3.5 or ChatGPT 4). However the paper&#x27;s conclusion is essentially correct even for state-of-the-art models:<p>&quot;Overall, while LLM made several errors, the provided formulations can serve as a starting point for OR experts to create mathematical models. However, OR experts should not rely on LLM to accurately create mathematical models, especially for less common or complex problems. Each output needs to be thoroughly verified and adjusted by the experts to ensure correctness and relevance.&quot;<p>I wouldn&#x27;t recommend anyone inexperienced to use LLMs to create entire models from scratch, but rather use LLMs as a search tool for specific formulations which are then verified and plugged into a larger model. For this, it works really well and saves me a ton of time. As MIP modeler, I have an intuition on the shape of the answer, so even if ChatGPT makes mistakes, I know how to extract the correct bits and it still saves me a ton of time.<p>The CPLEX API doesn&#x27;t have a lot of good examples out in the wild, so I don&#x27;t expect the training to be good. I&#x27;ve always used CPLEX through a modeling language like AMPL, and even AMPL code is rare so I can&#x27;t expect an LLM to decipher any of it. On the other hand, MIP formulations abound in PDFs of journal publications.<p>In the vibes department, I feel Xpress is second to Gurobi and CPLEX and it does the job just fine. But it&#x27;s been a while since I used CPLEX and Gurobi so I have no recent points of comparison (corporate licensing is prohibitively expensive).</div><br/></div></div></div></div></div></div></div></div><div id="41541790" class="c"><input type="checkbox" id="c-41541790" checked=""/><div class="controls bullet"><span class="by">airstrike</span><span>|</span><a href="#41541372">parent</a><span>|</span><a href="#41543288">prev</a><span>|</span><a href="#41543293">next</a><span>|</span><label class="collapse" for="c-41541790">[-]</label><label class="expand" for="c-41541790">[1 more]</label></div><br/><div class="children"><div class="content">It also doesn&#x27;t help that Lean has had so many breaking changes in such little time. When I tried using GPT-4 for it, it mostly rendered old code that would fail to run unless you already knew the answer and how to fix it, which basically made it entirely unhelpful.</div><br/></div></div><div id="41543293" class="c"><input type="checkbox" id="c-41543293" checked=""/><div class="controls bullet"><span class="by">Davidzheng</span><span>|</span><a href="#41541372">parent</a><span>|</span><a href="#41541790">prev</a><span>|</span><a href="#41542079">next</a><span>|</span><label class="collapse" for="c-41543293">[-]</label><label class="expand" for="c-41543293">[4 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not sure the lean coverage of pure math research is that much (maybe like 1% is represented on mathlib). But I think a system like alpha proof could even today be useful for mathematicians--I mostly dislike systems like o1 where they confidently say nonsense with such high frequency. But i think value is already there.</div><br/><div id="41544693" class="c"><input type="checkbox" id="c-41544693" checked=""/><div class="controls bullet"><span class="by">lanstin</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41543293">parent</a><span>|</span><a href="#41542079">next</a><span>|</span><label class="collapse" for="c-41544693">[-]</label><label class="expand" for="c-41544693">[3 more]</label></div><br/><div class="children"><div class="content">The point about using lean is you don&#x27;t have to trust you can verify.</div><br/><div id="41544992" class="c"><input type="checkbox" id="c-41544992" checked=""/><div class="controls bullet"><span class="by">Davidzheng</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41544693">parent</a><span>|</span><a href="#41542079">next</a><span>|</span><label class="collapse" for="c-41544992">[-]</label><label class="expand" for="c-41544992">[2 more]</label></div><br/><div class="children"><div class="content">no I agree I just don&#x27;t think existing Lean codebase is approaching useful coverage. Should change soon</div><br/><div id="41545275" class="c"><input type="checkbox" id="c-41545275" checked=""/><div class="controls bullet"><span class="by">lanstin</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41544992">parent</a><span>|</span><a href="#41542079">next</a><span>|</span><label class="collapse" for="c-41545275">[-]</label><label class="expand" for="c-41545275">[1 more]</label></div><br/><div class="children"><div class="content">I keep asking people in my department about using lean but zero interest so far.</div><br/></div></div></div></div></div></div></div></div><div id="41542079" class="c"><input type="checkbox" id="c-41542079" checked=""/><div class="controls bullet"><span class="by">EvgeniyZh</span><span>|</span><a href="#41541372">parent</a><span>|</span><a href="#41543293">prev</a><span>|</span><a href="#41541991">next</a><span>|</span><label class="collapse" for="c-41542079">[-]</label><label class="expand" for="c-41542079">[2 more]</label></div><br/><div class="children"><div class="content">There is ~3 order of magnitude more Python code in the internet than Lean code (200GB vs 200MB in the stack v2). You can&#x27;t tune it &quot;the same way&quot;</div><br/><div id="41542242" class="c"><input type="checkbox" id="c-41542242" checked=""/><div class="controls bullet"><span class="by">agumonkey</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41542079">parent</a><span>|</span><a href="#41541991">next</a><span>|</span><label class="collapse" for="c-41542242">[-]</label><label class="expand" for="c-41542242">[1 more]</label></div><br/><div class="children"><div class="content">Fair point but a lot of python code is redundant and low quality.</div><br/></div></div></div></div><div id="41541991" class="c"><input type="checkbox" id="c-41541991" checked=""/><div class="controls bullet"><span class="by">riffraff</span><span>|</span><a href="#41541372">parent</a><span>|</span><a href="#41542079">prev</a><span>|</span><a href="#41541799">next</a><span>|</span><label class="collapse" for="c-41541991">[-]</label><label class="expand" for="c-41541991">[1 more]</label></div><br/><div class="children"><div class="content">_can_ GPT be tuned more heavily on Lean? 
It looks like the amount of python code in the corpus would outnumber Lean something like 1000:1. Although I guess OpenAI could generate more and train on that.</div><br/></div></div><div id="41541799" class="c"><input type="checkbox" id="c-41541799" checked=""/><div class="controls bullet"><span class="by">benterix</span><span>|</span><a href="#41541372">parent</a><span>|</span><a href="#41541991">prev</a><span>|</span><a href="#41542249">next</a><span>|</span><label class="collapse" for="c-41541799">[-]</label><label class="expand" for="c-41541799">[2 more]</label></div><br/><div class="children"><div class="content">&gt; people who complain on HN that (paid&#x2F;good - only Sonnet 3.5 and GPT4o are in this category)<p>Correction: I complain that the only decent model in &quot;Open&quot;AI&#x27;s arsenal, that is GPT-4, has been replaced by a cheaper GPT-4o, which gives subpar answers to most of my question (I don&#x27;t care it does it faster). As they moved it to &quot;old, legacy&quot; models, I expect they will phase it out, at which point I&#x27;ll cancel my OpenAI subscriptions and Sonnet 3.5 will become the clear leader for my daily tasks.<p>Kudos to Anthropic for their great work, you guys are going in the right direction.</div><br/><div id="41543133" class="c"><input type="checkbox" id="c-41543133" checked=""/><div class="controls bullet"><span class="by">bongodongobob</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41541799">parent</a><span>|</span><a href="#41542249">next</a><span>|</span><label class="collapse" for="c-41543133">[-]</label><label class="expand" for="c-41543133">[1 more]</label></div><br/><div class="children"><div class="content">Nah, o1 is fucking impressive. It&#x27;s really fucking good. I&#x27;m guessing you haven&#x27;t used it yet.</div><br/></div></div></div></div><div id="41542249" class="c"><input type="checkbox" id="c-41542249" checked=""/><div class="controls bullet"><span class="by">agumonkey</span><span>|</span><a href="#41541372">parent</a><span>|</span><a href="#41541799">prev</a><span>|</span><a href="#41541764">next</a><span>|</span><label class="collapse" for="c-41542249">[-]</label><label class="expand" for="c-41542249">[2 more]</label></div><br/><div class="children"><div class="content">side question, are there good OR websites &#x2F; platforms (reddit, mastodon) to get involved in the field ?</div><br/><div id="41543281" class="c"><input type="checkbox" id="c-41543281" checked=""/><div class="controls bullet"><span class="by">rabf</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41542249">parent</a><span>|</span><a href="#41541764">next</a><span>|</span><label class="collapse" for="c-41543281">[-]</label><label class="expand" for="c-41543281">[1 more]</label></div><br/><div class="children"><div class="content">Most people are on X.</div><br/></div></div></div></div><div id="41541764" class="c"><input type="checkbox" id="c-41541764" checked=""/><div class="controls bullet"><span class="by">po76</span><span>|</span><a href="#41541372">parent</a><span>|</span><a href="#41542249">prev</a><span>|</span><a href="#41544606">next</a><span>|</span><label class="collapse" for="c-41541764">[-]</label><label class="expand" for="c-41541764">[1 more]</label></div><br/><div class="children"><div class="content">Give it a few months. ChatGPT will be recommending GPTs to use or do it automatically.<p>Nothing is static in the way things are moving.</div><br/></div></div><div id="41544606" class="c"><input type="checkbox" id="c-41544606" checked=""/><div class="controls bullet"><span class="by">lanstin</span><span>|</span><a href="#41541372">parent</a><span>|</span><a href="#41541764">prev</a><span>|</span><a href="#41541851">next</a><span>|</span><label class="collapse" for="c-41544606">[-]</label><label class="expand" for="c-41544606">[1 more]</label></div><br/><div class="children"><div class="content">Yeah I have been using them to help with learning graduate maths as a grad student. Claude Sonnet 3.5 was unparalleled and the first quite useful one. GPT4o preview seems about equal (based on cutting and pasting the past six months of prompts into it).</div><br/></div></div><div id="41541851" class="c"><input type="checkbox" id="c-41541851" checked=""/><div class="controls bullet"><span class="by">eab-</span><span>|</span><a href="#41541372">parent</a><span>|</span><a href="#41544606">prev</a><span>|</span><a href="#41541699">next</a><span>|</span><label class="collapse" for="c-41541851">[-]</label><label class="expand" for="c-41541851">[1 more]</label></div><br/><div class="children"><div class="content">Why do you expect GPT being tuned on Lean will help it for research-level math?</div><br/></div></div><div id="41541699" class="c"><input type="checkbox" id="c-41541699" checked=""/><div class="controls bullet"><span class="by">threeseed</span><span>|</span><a href="#41541372">parent</a><span>|</span><a href="#41541851">prev</a><span>|</span><a href="#41543328">next</a><span>|</span><label class="collapse" for="c-41541699">[-]</label><label class="expand" for="c-41541699">[3 more]</label></div><br/><div class="children"><div class="content">&gt; side<p>Or (4) LLMs simply do not work properly for many use cases in particular where large volumes of trained data doesn&#x27;t exist in its corpus.<p>And in these scenarios rather than say &quot;I don&#x27;t know&quot; it will over and over again gaslight you with incoherent answers.<p>But sure condescendingly blame on the user for their ignorance and inability to understand or use the tool properly. Or call their criticism low-effort.</div><br/><div id="41541704" class="c"><input type="checkbox" id="c-41541704" checked=""/><div class="controls bullet"><span class="by">wenc</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41541699">parent</a><span>|</span><a href="#41541719">next</a><span>|</span><label class="collapse" for="c-41541704">[-]</label><label class="expand" for="c-41541704">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s category (3).</div><br/></div></div><div id="41541719" class="c"><input type="checkbox" id="c-41541719" checked=""/><div class="controls bullet"><span class="by">zamadatix</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41541699">parent</a><span>|</span><a href="#41541704">prev</a><span>|</span><a href="#41543328">next</a><span>|</span><label class="collapse" for="c-41541719">[-]</label><label class="expand" for="c-41541719">[1 more]</label></div><br/><div class="children"><div class="content">What&#x27;s the difference between (3) and (4), shouldn&#x27;t the former contain the latter?</div><br/></div></div></div></div><div id="41543328" class="c"><input type="checkbox" id="c-41543328" checked=""/><div class="controls bullet"><span class="by">thelastparadise</span><span>|</span><a href="#41541372">parent</a><span>|</span><a href="#41541699">prev</a><span>|</span><a href="#41541916">next</a><span>|</span><label class="collapse" for="c-41543328">[-]</label><label class="expand" for="c-41543328">[1 more]</label></div><br/><div class="children"><div class="content">&gt; but for someone who can and does, the $20&#x2F;month I pay for ChatGPT more than pays for itself.<p>Would you be willing to pay even more, if it meant you were getting proportionally more valuable answers?<p>E.g. $200&#x2F;month or $2,000&#x2F;month (assuming the $2,000&#x2F;month gets into employee&#x2F;intern&#x2F;contractor level of results.)<p>This might drive a positive feedback loop.</div><br/></div></div><div id="41541916" class="c"><input type="checkbox" id="c-41541916" checked=""/><div class="controls bullet"><span class="by">CamperBob2</span><span>|</span><a href="#41541372">parent</a><span>|</span><a href="#41543328">prev</a><span>|</span><a href="#41542863">next</a><span>|</span><label class="collapse" for="c-41541916">[-]</label><label class="expand" for="c-41541916">[3 more]</label></div><br/><div class="children"><div class="content"><i>But many of the low-effort comments seem to mostly fall into (1) and (2) -- cynicism rather than cautious optimism.</i><p>One good riposte to reflexive LLM-bashing is, &quot;Isn&#x27;t <i>that</i> just what a stochastic parrot would say?&quot;  Some HN&#x27;ers would dismiss a talking dog because the C code it wrote has a buffer overflow error.</div><br/><div id="41544264" class="c"><input type="checkbox" id="c-41544264" checked=""/><div class="controls bullet"><span class="by">Workaccount2</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41541916">parent</a><span>|</span><a href="#41543745">next</a><span>|</span><label class="collapse" for="c-41544264">[-]</label><label class="expand" for="c-41544264">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s understandable that people whose career and lifelong skill set that are seemingly on the precipice of obsolescence are going to be extremely hostile to that threat.<p>How many more years is senior swe work going to be a $175k&#x2F;yr gig instead of an $75k check-what-the-robot-does gig?</div><br/></div></div><div id="41543745" class="c"><input type="checkbox" id="c-41543745" checked=""/><div class="controls bullet"><span class="by">jazzyjackson</span><span>|</span><a href="#41541372">root</a><span>|</span><a href="#41541916">parent</a><span>|</span><a href="#41544264">prev</a><span>|</span><a href="#41542863">next</a><span>|</span><label class="collapse" for="c-41543745">[-]</label><label class="expand" for="c-41543745">[1 more]</label></div><br/><div class="children"><div class="content">Id rather live in the world without talking dogs if their main utility is authoring buggy code</div><br/></div></div></div></div></div></div><div id="41542863" class="c"><input type="checkbox" id="c-41542863" checked=""/><div class="controls bullet"><span class="by">fnordpiglet</span><span>|</span><a href="#41541372">prev</a><span>|</span><a href="#41542004">next</a><span>|</span><label class="collapse" for="c-41542863">[-]</label><label class="expand" for="c-41542863">[74 more]</label></div><br/><div class="children"><div class="content">Rewind your mind to 2019 and imagine reading a post that said<p>“The experience seemed roughly on par with trying to advise a mediocre, but not completely incompetent, graduate student.”<p>With regard to interacting with the equivalent of Alexa. That’s a remarkable difference in 5 years.</div><br/><div id="41543968" class="c"><input type="checkbox" id="c-41543968" checked=""/><div class="controls bullet"><span class="by">JumpCrisscross</span><span>|</span><a href="#41542863">parent</a><span>|</span><a href="#41545095">next</a><span>|</span><label class="collapse" for="c-41543968">[-]</label><label class="expand" for="c-41543968">[22 more]</label></div><br/><div class="children"><div class="content">The first profession AI seems on track to decimate is programming. In particular, the brilliant but remote and individual contributor. There is an obvious conflict of interest in this forum.</div><br/><div id="41544639" class="c"><input type="checkbox" id="c-41544639" checked=""/><div class="controls bullet"><span class="by">vessenes</span><span>|</span><a href="#41542863">root</a><span>|</span><a href="#41543968">parent</a><span>|</span><a href="#41546192">next</a><span>|</span><label class="collapse" for="c-41544639">[-]</label><label class="expand" for="c-41544639">[2 more]</label></div><br/><div class="children"><div class="content">I see this theory a lot but mostly from people who haven’t tried pair coding with a quality llm. In fact these llms give experienced developers super powers; you can be crazy productive with them.<p>If you think we are close to the maximum useful software in the world already, then maybe. I do not believe that. Seeing software production and time costs drop one to two orders of magnitude means we will have very different viable software production processes. I don’t believe for a second that it disenfranchises quality thinkers; it empowers them.</div><br/><div id="41545647" class="c"><input type="checkbox" id="c-41545647" checked=""/><div class="controls bullet"><span class="by">Maxion</span><span>|</span><a href="#41542863">root</a><span>|</span><a href="#41544639">parent</a><span>|</span><a href="#41546192">next</a><span>|</span><label class="collapse" for="c-41545647">[-]</label><label class="expand" for="c-41545647">[1 more]</label></div><br/><div class="children"><div class="content">I totally agree, there e.g. so many companies out there who rely on fully manual processes internally simply because they cannot currently afford to hire programmers to solve the problems they have for them. The ROI just isn&#x27;t there.<p>Reduce costs by an order of magnitude or two, and suddenly there&#x27;s a whole heap more projects that become profitable.</div><br/></div></div></div></div><div id="41546192" class="c"><input type="checkbox" id="c-41546192" checked=""/><div class="controls bullet"><span class="by">langcss</span><span>|</span><a href="#41542863">root</a><span>|</span><a href="#41543968">parent</a><span>|</span><a href="#41544639">prev</a><span>|</span><a href="#41544324">next</a><span>|</span><label class="collapse" for="c-41546192">[-]</label><label class="expand" for="c-41546192">[1 more]</label></div><br/><div class="children"><div class="content">I believe LLMs decimating the role of a software engineer requires AGI, which the second that happens decimates all jobs.<p>What it may do is change the job requrements. Web&#x2F;JS has decimated (reduced by 90% or more) MFC C++ jobs after all.<p>The programmer doesnt just write Python. That is the how... not the what.</div><br/></div></div><div id="41544324" class="c"><input type="checkbox" id="c-41544324" checked=""/><div class="controls bullet"><span class="by">IncreasePosts</span><span>|</span><a href="#41542863">root</a><span>|</span><a href="#41543968">parent</a><span>|</span><a href="#41546192">prev</a><span>|</span><a href="#41543983">next</a><span>|</span><label class="collapse" for="c-41544324">[-]</label><label class="expand" for="c-41544324">[7 more]</label></div><br/><div class="children"><div class="content">Before it can replace the brilliant programmer, it needs to be able to replace the mediocre programmer. There is so much programming and other tech&#x2F;it related work that businesses or people want, but can&#x27;t justify paying even low tech salaries in America for.<p>So far, there is little chance of a non-technical person developing a technical solution to their problems using AI.</div><br/><div id="41544695" class="c"><input type="checkbox" id="c-41544695" checked=""/><div class="controls bullet"><span class="by">JumpCrisscross</span><span>|</span><a href="#41542863">root</a><span>|</span><a href="#41544324">parent</a><span>|</span><a href="#41543983">next</a><span>|</span><label class="collapse" for="c-41544695">[-]</label><label class="expand" for="c-41544695">[6 more]</label></div><br/><div class="children"><div class="content">&gt; <i>Before it can replace the brilliant programmer, it needs to be able to replace the mediocre programmer</i><p>Nope. Compensation is exponential. Being able to replace a top performer with a fee mediocre devs pair coding with an LLM is more than fine for 90% of use cases.</div><br/><div id="41544762" class="c"><input type="checkbox" id="c-41544762" checked=""/><div class="controls bullet"><span class="by">IncreasePosts</span><span>|</span><a href="#41542863">root</a><span>|</span><a href="#41544695">parent</a><span>|</span><a href="#41545186">next</a><span>|</span><label class="collapse" for="c-41544762">[-]</label><label class="expand" for="c-41544762">[2 more]</label></div><br/><div class="children"><div class="content">A mediocre programmer won&#x27;t be able to judge the allegedly expert level output any better than a non-programmer, so I don&#x27;t see how that would work.<p>I think it is more likely that great programmers might just increase their productivity even more with, which will make their value even greater.</div><br/><div id="41545706" class="c"><input type="checkbox" id="c-41545706" checked=""/><div class="controls bullet"><span class="by">JumpCrisscross</span><span>|</span><a href="#41542863">root</a><span>|</span><a href="#41544762">parent</a><span>|</span><a href="#41545186">next</a><span>|</span><label class="collapse" for="c-41545706">[-]</label><label class="expand" for="c-41545706">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>mediocre programmer won&#x27;t be able to judge the allegedly expert level output any better than a non-programmer, so I don&#x27;t see how that would work</i><p>Sure. Plenty of businesses are. Particularly in the commercial automation sector that numerically hires the most people.<p>&gt; <i>more likely that great programmers might just increase their productivity</i><p>For those in high-productivity, high-margin businesses, yes. For most of the world, no—the surplus productivity doesn’t outweigh the compensation and concentration risk.<p>I broadly expect a spate of age discrimination lawsuits in the near future because most businesses don’t need a few stars. In the meantime, I’ve watched a lot of people find two people in Brazil + an LLM equals one WFH very good (but not brilliant) coder.</div><br/></div></div></div></div><div id="41545186" class="c"><input type="checkbox" id="c-41545186" checked=""/><div class="controls bullet"><span class="by">zeroonetwothree</span><span>|</span><a href="#41542863">root</a><span>|</span><a href="#41544695">parent</a><span>|</span><a href="#41544762">prev</a><span>|</span><a href="#41543983">next</a><span>|</span><label class="collapse" for="c-41545186">[-]</label><label class="expand" for="c-41545186">[3 more]</label></div><br/><div class="children"><div class="content">This makes no sense, there are problems that &#x27;brilliant&#x27; programmers can solve and no number of mediocre ones ones. Just like you can&#x27;t substitute Mozart with 100 mediocre composers.</div><br/><div id="41545710" class="c"><input type="checkbox" id="c-41545710" checked=""/><div class="controls bullet"><span class="by">JumpCrisscross</span><span>|</span><a href="#41542863">root</a><span>|</span><a href="#41545186">parent</a><span>|</span><a href="#41545907">next</a><span>|</span><label class="collapse" for="c-41545710">[-]</label><label class="expand" for="c-41545710">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>there are problems that &#x27;brilliant&#x27; programmers can solve and no number of mediocre ones ones</i><p>These people will continue to have value. But most businesses don’t have problems that can be profitable solved only by brilliant coders.</div><br/></div></div><div id="41545907" class="c"><input type="checkbox" id="c-41545907" checked=""/><div class="controls bullet"><span class="by">9dev</span><span>|</span><a href="#41542863">root</a><span>|</span><a href="#41545186">parent</a><span>|</span><a href="#41545710">prev</a><span>|</span><a href="#41543983">next</a><span>|</span><label class="collapse" for="c-41545907">[-]</label><label class="expand" for="c-41545907">[1 more]</label></div><br/><div class="children"><div class="content">So, how many people listen to Mozart and how many to Taylor Swift?</div><br/></div></div></div></div></div></div></div></div><div id="41543983" class="c"><input type="checkbox" id="c-41543983" checked=""/><div class="controls bullet"><span class="by">dartos</span><span>|</span><a href="#41542863">root</a><span>|</span><a href="#41543968">parent</a><span>|</span><a href="#41544324">prev</a><span>|</span><a href="#41544549">next</a><span>|</span><label class="collapse" for="c-41543983">[-]</label><label class="expand" for="c-41543983">[5 more]</label></div><br/><div class="children"><div class="content">No, the first profession AI was on track to decimate was artists, but that didn’t really happen.<p>AI just destroyed shutterstock.</div><br/><div id="41544237" class="c"><input type="checkbox" id="c-41544237" checked=""/><div class="controls bullet"><span class="by">energy123</span><span>|</span><a href="#41542863">root</a><span>|</span><a href="#41543983">parent</a><span>|</span><a href="#41544112">next</a><span>|</span><label class="collapse" for="c-41544237">[-]</label><label class="expand" for="c-41544237">[2 more]</label></div><br/><div class="children"><div class="content">The large majority of professional writers and artists produce thankless commodity output for things like TV advertisements, games, SEO content. These jobs should be threatened.</div><br/><div id="41545193" class="c"><input type="checkbox" id="c-41545193" checked=""/><div class="controls bullet"><span class="by">zeroonetwothree</span><span>|</span><a href="#41542863">root</a><span>|</span><a href="#41544237">parent</a><span>|</span><a href="#41544112">next</a><span>|</span><label class="collapse" for="c-41545193">[-]</label><label class="expand" for="c-41545193">[1 more]</label></div><br/><div class="children"><div class="content">They get paid pretty low wages so it&#x27;s not even clear that AIs will be cheaper. Consider also that you still need a human to evaluate their output, make adjustments, etc.</div><br/></div></div></div></div><div id="41544112" class="c"><input type="checkbox" id="c-41544112" checked=""/><div class="controls bullet"><span class="by">mkarrmann</span><span>|</span><a href="#41542863">root</a><span>|</span><a href="#41543983">parent</a><span>|</span><a href="#41544237">prev</a><span>|</span><a href="#41544549">next</a><span>|</span><label class="collapse" for="c-41544112">[-]</label><label class="expand" for="c-41544112">[2 more]</label></div><br/><div class="children"><div class="content">Is most code being written the equivalent of high-art or Shutterstock?</div><br/><div id="41544442" class="c"><input type="checkbox" id="c-41544442" checked=""/><div class="controls bullet"><span class="by">dartos</span><span>|</span><a href="#41542863">root</a><span>|</span><a href="#41544112">parent</a><span>|</span><a href="#41544549">next</a><span>|</span><label class="collapse" for="c-41544442">[-]</label><label class="expand" for="c-41544442">[1 more]</label></div><br/><div class="children"><div class="content">I think most code being written is like a custom car made out of the most cost effective parts available.<p>Not pretty, but it gets the job done for the specific use cases of a given business.<p>Real production code doesn’t and have a shutter stock equivalent.<p>If you think most code is stock, then you just haven’t had enough experience in industry yet.</div><br/></div></div></div></div></div></div><div id="41544549" class="c"><input type="checkbox" id="c-41544549" checked=""/><div class="controls bullet"><span class="by">ken47</span><span>|</span><a href="#41542863">root</a><span>|</span><a href="#41543968">parent</a><span>|</span><a href="#41543983">prev</a><span>|</span><a href="#41545053">next</a><span>|</span><label class="collapse" for="c-41544549">[-]</label><label class="expand" for="c-41544549">[2 more]</label></div><br/><div class="children"><div class="content">The conflict of interest might have something to do with the fact that OpenAI&#x27;s CEO&#x2F;founder was once a major figure in Y Combinator. But I think you wanted to insinuate that the conflict of interest ran in the other direction.<p>Once ChatGPT can even come close to replacing a junior engineer, you can retry your claim. The progression of the tech underlying ChatGPT will be sub-linear.</div><br/><div id="41545127" class="c"><input type="checkbox" id="c-41545127" checked=""/><div class="controls bullet"><span class="by">charlieyu1</span><span>|</span><a href="#41542863">root</a><span>|</span><a href="#41544549">parent</a><span>|</span><a href="#41545053">next</a><span>|</span><label class="collapse" for="c-41545127">[-]</label><label class="expand" for="c-41545127">[1 more]</label></div><br/><div class="children"><div class="content">The current driving force of AI is the desire to cut costs. Jobs will be cut even if ChatGPT is nowhere near a junior engineer and that&#x27;s the problem.</div><br/></div></div></div></div><div id="41544050" class="c"><input type="checkbox" id="c-41544050" checked=""/><div class="controls bullet"><span class="by">talldayo</span><span>|</span><a href="#41542863">root</a><span>|</span><a href="#41543968">parent</a><span>|</span><a href="#41545053">prev</a><span>|</span><a href="#41543985">next</a><span>|</span><label class="collapse" for="c-41544050">[-]</label><label class="expand" for="c-41544050">[1 more]</label></div><br/><div class="children"><div class="content">I would better believe that if any superior software was being primarily designed by AI.</div><br/></div></div><div id="41543985" class="c"><input type="checkbox" id="c-41543985" checked=""/><div class="controls bullet"><span class="by">__loam</span><span>|</span><a href="#41542863">root</a><span>|</span><a href="#41543968">parent</a><span>|</span><a href="#41544050">prev</a><span>|</span><a href="#41545095">next</a><span>|</span><label class="collapse" for="c-41543985">[-]</label><label class="expand" for="c-41543985">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s going to be incredible watching you people write way more code than you can feasibly maintain.</div><br/><div id="41544087" class="c"><input type="checkbox" id="c-41544087" checked=""/><div class="controls bullet"><span class="by">farresito</span><span>|</span><a href="#41542863">root</a><span>|</span><a href="#41543985">parent</a><span>|</span><a href="#41545095">next</a><span>|</span><label class="collapse" for="c-41544087">[-]</label><label class="expand" for="c-41544087">[1 more]</label></div><br/><div class="children"><div class="content">Once we have AI-based language servers, which will, at some point in the future, be able to track entire repositories, I think maintaining projects will actually be far easier than right now.</div><br/></div></div></div></div></div></div><div id="41545095" class="c"><input type="checkbox" id="c-41545095" checked=""/><div class="controls bullet"><span class="by">fumeux_fume</span><span>|</span><a href="#41542863">parent</a><span>|</span><a href="#41543968">prev</a><span>|</span><a href="#41545639">next</a><span>|</span><label class="collapse" for="c-41545095">[-]</label><label class="expand" for="c-41545095">[2 more]</label></div><br/><div class="children"><div class="content">Rewind your mind to 1950 and reading that the future is chatting with bots about solving math homework.</div><br/><div id="41545247" class="c"><input type="checkbox" id="c-41545247" checked=""/><div class="controls bullet"><span class="by">nathanasmith</span><span>|</span><a href="#41542863">root</a><span>|</span><a href="#41545095">parent</a><span>|</span><a href="#41545639">next</a><span>|</span><label class="collapse" for="c-41545247">[-]</label><label class="expand" for="c-41545247">[1 more]</label></div><br/><div class="children"><div class="content">They would be wondering why it took so long.</div><br/></div></div></div></div><div id="41545639" class="c"><input type="checkbox" id="c-41545639" checked=""/><div class="controls bullet"><span class="by">ksec</span><span>|</span><a href="#41542863">parent</a><span>|</span><a href="#41545095">prev</a><span>|</span><a href="#41543429">next</a><span>|</span><label class="collapse" for="c-41545639">[-]</label><label class="expand" for="c-41545639">[1 more]</label></div><br/><div class="children"><div class="content">Which is why I think the AI era isn&#x27;t hype but very much real. Jensen said AI has reached the era of iPhone.<p>We wont have AGI or ASI, whatever definition people have with those terms in the next 5 - 10 years. But I would often like to refer AI as Assisted or Argumented Intelligence. And it will provide enough value that drives current Computer and Smartphone sales for at least another 5 - 10 years. Or 3-4 cycles.</div><br/></div></div><div id="41543429" class="c"><input type="checkbox" id="c-41543429" checked=""/><div class="controls bullet"><span class="by">noch</span><span>|</span><a href="#41542863">parent</a><span>|</span><a href="#41545639">prev</a><span>|</span><a href="#41544613">next</a><span>|</span><label class="collapse" for="c-41543429">[-]</label><label class="expand" for="c-41543429">[31 more]</label></div><br/><div class="children"><div class="content">The important point is, I feel, that most people are not even at the level of intelligence of a <i>&quot;a mediocre, but not completely incompetent, graduate student.&quot;</i> A mediocre graduate science student, especially of the sort who graduates and doesn&#x27;t quit, is a very impressive individual compared to the rest of us.<p>For &quot;us&quot;, having such a level of intelligence available as an assistant throughout the day is a massive life upgrade, if we can just afford more tokens.</div><br/><div id="41543813" class="c"><input type="checkbox" id="c-41543813" checked=""/><div class="controls bullet"><span class="by">a_wild_dandan</span><span>|</span><a href="#41542863">root</a><span>|</span><a href="#41543429">parent</a><span>|</span><a href="#41543817">next</a><span>|</span><label class="collapse" for="c-41543813">[-]</label><label class="expand" for="c-41543813">[20 more]</label></div><br/><div class="children"><div class="content">My sheer productivity boost from these models is miraculous. It&#x27;s like upgrading from a text editor to a powerful IDE. I&#x27;ve saved a mountain of hours <i>just</i> by removing tedious time sinks -- one-off language syntax, remembering patterns for some framework, migrating code, etc. And this boost applies to nearly all of my knowledge work.<p>Then I see contrarians claiming that LLMs are literally never useful for anyone, and I get &quot;don&#x27;t believe your lying eyes&quot; vibes. At this point, such sentiments feel either willfully ignorant, or said in bad faith. It&#x27;s wild.</div><br/><div id="41544008" class="c"><input type="checkbox" id="c-41544008" checked=""/><div class="controls bullet"><span class="by">dartos</span><span>|</span><a href="#41542863">root</a><span>|</span><a href="#41543813">parent</a><span>|</span><a href="#41543875">next</a><span>|</span><label class="collapse" for="c-41544008">[-]</label><label class="expand" for="c-41544008">[9 more]</label></div><br/><div class="children"><div class="content">&gt; At this point, such sentiments feel either willfully ignorant, or said in bad faith.<p>I feel exactly the same, but in the opposite direction.<p>As someone who’s been programming for 17 years and working professionally for 10, I’m unable to get any huge productivity boosts from AI tools.
They’re better than Google+stack overflow for asking random questions, but in a specific context and they’re good for repetitive, but not identical, syntax. That’s about where the gains end for me.<p>Maybe at this point I’m just so fast about looking up documentation. Maybe the languages&#x2F;problems I’m facing aren’t well represented in the training data, but I just don’t see this amazing advancement.<p>I’d really love to see, live, someone programming who really gets these big productivity gains.</div><br/><div id="41545208" class="c"><input type="checkbox" id="c-41545208" checked=""/><div class="controls bullet"><span class="by">zeroonetwothree</span><span>|</span><a href="#41542863">root</a><span>|</span><a href="#41544008">parent</a><span>|</span><a href="#41544098">next</a><span>|</span><label class="collapse" for="c-41545208">[-]</label><label class="expand" for="c-41545208">[1 more]</label></div><br/><div class="children"><div class="content">Right, in my experience the time it takes to verify that the code it wrote for you is correct is more than just to write it in the first place. A big exception is if you&#x27;re working in a new domain (e.g., new language or framework). Then it&#x27;s obviously much faster, and I do derive value from it. But I don&#x27;t spend a very large % of my time doing that.<p>I would speculate it&#x27;s a productivity boost for programmers specifically working in areas that they are new to (or haven&#x27;t really mastered yet). One question I have is whether overly relying on LLMs will reduce the ability to master a domain, and thus hurt your long-term skill. It might seem silly, like complaining that no one knows assembly anymore because of compilers, but I think it&#x27;s different than just another layer of abstraction.</div><br/></div></div><div id="41544098" class="c"><input type="checkbox" id="c-41544098" checked=""/><div class="controls bullet"><span class="by">mewpmewp2</span><span>|</span><a href="#41542863">root</a><span>|</span><a href="#41544008">parent</a><span>|</span><a href="#41545208">prev</a><span>|</span><a href="#41543875">next</a><span>|</span><label class="collapse" for="c-41544098">[-]</label><label class="expand" for="c-41544098">[7 more]</label></div><br/><div class="children"><div class="content">Most gains are from using Copilot, do you use that?</div><br/><div id="41544180" class="c"><input type="checkbox" id="c-41544180" checked=""/><div class="controls bullet"><span class="by">acedTrex</span><span>|</span><a href="#41542863">root</a><span>|</span><a href="#41544098">parent</a><span>|</span><a href="#41544414">next</a><span>|</span><label class="collapse" for="c-41544180">[-]</label><label class="expand" for="c-41544180">[4 more]</label></div><br/><div class="children"><div class="content">I have it, tried it for a while. I have it turned mostly off new except for rare boilerplate heavy cases.<p>It kept generating annoyingly wrong code. Things with subtly wrong misleading names, missing edge cases, ignoring immediate same file context etc. I found that it slowed me down so i turned it off.</div><br/><div id="41544431" class="c"><input type="checkbox" id="c-41544431" checked=""/><div class="controls bullet"><span class="by">dartos</span><span>|</span><a href="#41542863">root</a><span>|</span><a href="#41544180">parent</a><span>|</span><a href="#41544302">next</a><span>|</span><label class="collapse" for="c-41544431">[-]</label><label class="expand" for="c-41544431">[1 more]</label></div><br/><div class="children"><div class="content">This is my exact experience as well.</div><br/></div></div><div id="41544302" class="c"><input type="checkbox" id="c-41544302" checked=""/><div class="controls bullet"><span class="by">mewpmewp2</span><span>|</span><a href="#41542863">root</a><span>|</span><a href="#41544180">parent</a><span>|</span><a href="#41544431">prev</a><span>|</span><a href="#41544414">next</a><span>|</span><label class="collapse" for="c-41544302">[-]</label><label class="expand" for="c-41544302">[2 more]</label></div><br/><div class="children"><div class="content">Which language?</div><br/><div id="41544355" class="c"><input type="checkbox" id="c-41544355" checked=""/><div class="controls bullet"><span class="by">acedTrex</span><span>|</span><a href="#41542863">root</a><span>|</span><a href="#41544302">parent</a><span>|</span><a href="#41544414">next</a><span>|</span><label class="collapse" for="c-41544355">[-]</label><label class="expand" for="c-41544355">[1 more]</label></div><br/><div class="children"><div class="content">golang and python mainly.<p>For rust it failed spectacularly. So bad that its not worth discussing lol</div><br/></div></div></div></div></div></div><div id="41544414" class="c"><input type="checkbox" id="c-41544414" checked=""/><div class="controls bullet"><span class="by">dartos</span><span>|</span><a href="#41542863">root</a><span>|</span><a href="#41544098">parent</a><span>|</span><a href="#41544180">prev</a><span>|</span><a href="#41545039">next</a><span>|</span><label class="collapse" for="c-41544414">[-]</label><label class="expand" for="c-41544414">[1 more]</label></div><br/><div class="children"><div class="content">I use it for those refactors I mentioned in my comment.<p>It’s autocomplete++, except without knowledge of the rest of my codebase.</div><br/></div></div><div id="41545039" class="c"><input type="checkbox" id="c-41545039" checked=""/><div class="controls bullet"><span class="by">crooked-v</span><span>|</span><a href="#41542863">root</a><span>|</span><a href="#41544098">parent</a><span>|</span><a href="#41544414">prev</a><span>|</span><a href="#41543875">next</a><span>|</span><label class="collapse" for="c-41545039">[-]</label><label class="expand" for="c-41545039">[1 more]</label></div><br/><div class="children"><div class="content">I tried it. It ended up just being slightly better, significantly slower autocomplete.</div><br/></div></div></div></div></div></div><div id="41543875" class="c"><input type="checkbox" id="c-41543875" checked=""/><div class="controls bullet"><span class="by">bachmeier</span><span>|</span><a href="#41542863">root</a><span>|</span><a href="#41543813">parent</a><span>|</span><a href="#41544008">prev</a><span>|</span><a href="#41543907">next</a><span>|</span><label class="collapse" for="c-41543875">[-]</label><label class="expand" for="c-41543875">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I see contrarians claiming that LLMs are literally never useful for anyone<p>While I don&#x27;t doubt that there&#x27;s at least one person that has said this, what you&#x27;re saying doesn&#x27;t conflict with the things I and many others in the &quot;skeptic&quot; camp have said. LLMs are useful for a very specific set of tasks. The tasks you&#x27;ve listed are a tiny sliver of all the tasks that AI could potentially be doing. Would it be a good idea to consult an LLM if your mother is passed out on the floor? Probably not. The problem I have is with extrapolating from the current successes to conclude that many more tasks will be done by AI in five years.</div><br/></div></div><div id="41543907" class="c"><input type="checkbox" id="c-41543907" checked=""/><div class="controls bullet"><span class="by">perching_aix</span><span>|</span><a href="#41542863">root</a><span>|</span><a href="#41543813">parent</a><span>|</span><a href="#41543875">prev</a><span>|</span><a href="#41543867">next</a><span>|</span><label class="collapse" for="c-41543907">[-]</label><label class="expand" for="c-41543907">[4 more]</label></div><br/><div class="children"><div class="content">Thing is, I&#x27;m used to hearing a very similar sentiment on how e.g. using vim keybindings is so literally going to make me a 10x 100x whatever rockstar developer - and it&#x27;s like what, enabling me to edit text a bit faster? And it&#x27;s always anecdotes that yeah, from-qualia you feel so fast. But from-qualia I run like a marathon runner and sound like a radio host.<p>I personally did find some use cases for it and it does a decent job of cutting out minor gruntwork for me. But the experience itself screams to me that whatever gains I&#x27;m feeling I&#x27;m getting are all in my head.</div><br/><div id="41543975" class="c"><input type="checkbox" id="c-41543975" checked=""/><div class="controls bullet"><span class="by">raincole</span><span>|</span><a href="#41542863">root</a><span>|</span><a href="#41543907">parent</a><span>|</span><a href="#41543867">next</a><span>|</span><label class="collapse" for="c-41543975">[-]</label><label class="expand" for="c-41543975">[3 more]</label></div><br/><div class="children"><div class="content">&gt; using vim keybindings is so literally going to make me a 10x 100x whatever rockstar developer - and it&#x27;s like what, enabling me to edit text a bit faster?<p>Yes, to me LLM is exactly like this: from nano to vim.</div><br/><div id="41545606" class="c"><input type="checkbox" id="c-41545606" checked=""/><div class="controls bullet"><span class="by">pxc</span><span>|</span><a href="#41542863">root</a><span>|</span><a href="#41543975">parent</a><span>|</span><a href="#41543867">next</a><span>|</span><label class="collapse" for="c-41545606">[-]</label><label class="expand" for="c-41545606">[2 more]</label></div><br/><div class="children"><div class="content">Nano is borderline unusable, so that&#x27;s like... a lot?</div><br/><div id="41546070" class="c"><input type="checkbox" id="c-41546070" checked=""/><div class="controls bullet"><span class="by">perching_aix</span><span>|</span><a href="#41542863">root</a><span>|</span><a href="#41545606">parent</a><span>|</span><a href="#41543867">next</a><span>|</span><label class="collapse" for="c-41546070">[-]</label><label class="expand" for="c-41546070">[1 more]</label></div><br/><div class="children"><div class="content">holy hyperboly, clearly i picked the right example...</div><br/></div></div></div></div></div></div></div></div><div id="41543867" class="c"><input type="checkbox" id="c-41543867" checked=""/><div class="controls bullet"><span class="by">christofosho</span><span>|</span><a href="#41542863">root</a><span>|</span><a href="#41543813">parent</a><span>|</span><a href="#41543907">prev</a><span>|</span><a href="#41543896">next</a><span>|</span><label class="collapse" for="c-41543867">[-]</label><label class="expand" for="c-41543867">[2 more]</label></div><br/><div class="children"><div class="content">I think there may be a set of people that have figured out, 1) how to interact with LLMs; and 2) what in their lives is improved when interacting with LLMs. I am in the group that has not found the best use case for my own life, and have never needed it for improving anything I need to get done. Always looking for suggestions, though!</div><br/><div id="41544031" class="c"><input type="checkbox" id="c-41544031" checked=""/><div class="controls bullet"><span class="by">ants_everywhere</span><span>|</span><a href="#41542863">root</a><span>|</span><a href="#41543867">parent</a><span>|</span><a href="#41543896">next</a><span>|</span><label class="collapse" for="c-41544031">[-]</label><label class="expand" for="c-41544031">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I think there may be a set of people that have figured out, 1) how to interact with LLMs....<p>1) is all about experimenting, which is what Tao is doing.<p>Having a playful and open minded attitude is like 80% of the game</div><br/></div></div></div></div><div id="41543896" class="c"><input type="checkbox" id="c-41543896" checked=""/><div class="controls bullet"><span class="by">wizzwizz4</span><span>|</span><a href="#41542863">root</a><span>|</span><a href="#41543813">parent</a><span>|</span><a href="#41543867">prev</a><span>|</span><a href="#41543997">next</a><span>|</span><label class="collapse" for="c-41543896">[-]</label><label class="expand" for="c-41543896">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m a contrarian who believes your anecdote, and could even imagine that 5% of LLM users feel the same way, but thinks (a) these systems are about half as good as they&#x27;re ever going to get, (b) we&#x27;re past the point of diminishing returns, and (c) what we <i>do</i> have isn&#x27;t worth the energy costs of running it, let alone creating it in the first place.</div><br/></div></div><div id="41543997" class="c"><input type="checkbox" id="c-41543997" checked=""/><div class="controls bullet"><span class="by">__loam</span><span>|</span><a href="#41542863">root</a><span>|</span><a href="#41543813">parent</a><span>|</span><a href="#41543896">prev</a><span>|</span><a href="#41543868">next</a><span>|</span><label class="collapse" for="c-41543997">[-]</label><label class="expand" for="c-41543997">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a system that is designed to convince you.</div><br/></div></div></div></div><div id="41543817" class="c"><input type="checkbox" id="c-41543817" checked=""/><div class="controls bullet"><span class="by">sn9</span><span>|</span><a href="#41542863">root</a><span>|</span><a href="#41543429">parent</a><span>|</span><a href="#41543813">prev</a><span>|</span><a href="#41543654">next</a><span>|</span><label class="collapse" for="c-41543817">[-]</label><label class="expand" for="c-41543817">[1 more]</label></div><br/><div class="children"><div class="content">Anyone intelligent enough to make a living programming likely has more than enough IQ to become a mediocre somewhat competent graduate student in math.<p>They just don&#x27;t have the background, and probably lack the interest to dedicate studying for a few years to get to that level.</div><br/></div></div><div id="41543654" class="c"><input type="checkbox" id="c-41543654" checked=""/><div class="controls bullet"><span class="by">kiba</span><span>|</span><a href="#41542863">root</a><span>|</span><a href="#41543429">parent</a><span>|</span><a href="#41543817">prev</a><span>|</span><a href="#41543496">next</a><span>|</span><label class="collapse" for="c-41543654">[-]</label><label class="expand" for="c-41543654">[3 more]</label></div><br/><div class="children"><div class="content">We are more limited by our emotions, and then our skills in learning and acquiring knowledge.<p>Intelligence is probably a distant third.</div><br/><div id="41543705" class="c"><input type="checkbox" id="c-41543705" checked=""/><div class="controls bullet"><span class="by">atleastoptimal</span><span>|</span><a href="#41542863">root</a><span>|</span><a href="#41543654">parent</a><span>|</span><a href="#41543496">next</a><span>|</span><label class="collapse" for="c-41543705">[-]</label><label class="expand" for="c-41543705">[2 more]</label></div><br/><div class="children"><div class="content">Nah. Dogs are far emotionally better than most humans. Their intelligence is their limitation. Also “skills in learning and acquiring knowledge” is basically intelligence</div><br/></div></div></div></div><div id="41543496" class="c"><input type="checkbox" id="c-41543496" checked=""/><div class="controls bullet"><span class="by">thewanderer1983</span><span>|</span><a href="#41542863">root</a><span>|</span><a href="#41543429">parent</a><span>|</span><a href="#41543654">prev</a><span>|</span><a href="#41544613">next</a><span>|</span><label class="collapse" for="c-41543496">[-]</label><label class="expand" for="c-41543496">[6 more]</label></div><br/><div class="children"><div class="content">&gt;A mediocre graduate science student, especially of the sort who graduates and doesn&#x27;t quit, is a very impressive individual compared to the rest of us.<p>Incorrect. University graduates shows a good work ethic, a certain character and a ability to manage time. It&#x27;s not a measure of being better than the rest of humanity. Also, it&#x27;s not a good measure of intelligence. If you only want to view the world through credentials. Academics don&#x27;t consider your intelligence until you have a Ph.D and X years of work in your field. Industry only uses graduates as a entry requirement for junior roles and then favors and cares only about your years of experience after that.
Given that statement I can only assume you haven&#x27;t been to University. You are mistaken to think, especially in time we are in now that the elite class are any more knowledgeable then you are.</div><br/></div></div></div></div><div id="41544613" class="c"><input type="checkbox" id="c-41544613" checked=""/><div class="controls bullet"><span class="by">bamboozled</span><span>|</span><a href="#41542863">parent</a><span>|</span><a href="#41543429">prev</a><span>|</span><a href="#41544389">next</a><span>|</span><label class="collapse" for="c-41544613">[-]</label><label class="expand" for="c-41544613">[1 more]</label></div><br/><div class="children"><div class="content">Remind your mind to 1850, imagine seeing a lightbulb.</div><br/></div></div><div id="41544389" class="c"><input type="checkbox" id="c-41544389" checked=""/><div class="controls bullet"><span class="by">TrackerFF</span><span>|</span><a href="#41542863">parent</a><span>|</span><a href="#41544613">prev</a><span>|</span><a href="#41543864">next</a><span>|</span><label class="collapse" for="c-41544389">[-]</label><label class="expand" for="c-41544389">[3 more]</label></div><br/><div class="children"><div class="content">Even more amazing, there plenty - PLENTY - of posters here that routinely either completely shit on LLMs, or casually dismiss them as &quot;hype&quot;, &quot;useless&quot;, and what have you.<p>I&#x27;ve been saying this for quite some time now, but some people are in for a very rude awakening when the SOTA models 5-10 years from now are able to completely replace senior devs and engineers.<p>Better buckle up, and start diversifying your skills.</div><br/><div id="41544755" class="c"><input type="checkbox" id="c-41544755" checked=""/><div class="controls bullet"><span class="by">ramraj07</span><span>|</span><a href="#41542863">root</a><span>|</span><a href="#41544389">parent</a><span>|</span><a href="#41544402">next</a><span>|</span><label class="collapse" for="c-41544755">[-]</label><label class="expand" for="c-41544755">[1 more]</label></div><br/><div class="children"><div class="content">The way I see it these models especially O1 is an intelligence booster. If you start with zero it gives you back zero. Especially if you’re just genuinely trying to use it and not just trying to do some gotcha stuff.</div><br/></div></div><div id="41544402" class="c"><input type="checkbox" id="c-41544402" checked=""/><div class="controls bullet"><span class="by">zeroonetwothree</span><span>|</span><a href="#41542863">root</a><span>|</span><a href="#41544389">parent</a><span>|</span><a href="#41544755">prev</a><span>|</span><a href="#41543864">next</a><span>|</span><label class="collapse" for="c-41544402">[-]</label><label class="expand" for="c-41544402">[1 more]</label></div><br/><div class="children"><div class="content">Not sure how this post is evidence of AIs replacing senior devs.</div><br/></div></div></div></div><div id="41543864" class="c"><input type="checkbox" id="c-41543864" checked=""/><div class="controls bullet"><span class="by">meroes</span><span>|</span><a href="#41542863">parent</a><span>|</span><a href="#41544389">prev</a><span>|</span><a href="#41544509">next</a><span>|</span><label class="collapse" for="c-41543864">[-]</label><label class="expand" for="c-41543864">[1 more]</label></div><br/><div class="children"><div class="content">I mean paying several hundred to thousands of grad students to RLHF for several years and you get a corpus of grad-student text. I&#x27;m not surprised at all. AI companies hire grad students to RLHF in every subject matter (chemistry, physics, math, etc).<p>The grad-students write the prompts, correct the model, and all of that is fed into a &quot;more advanced&quot; model. It&#x27;s corpi of text. Repeat this for every grade level and subject.<p>Ask the model that&#x27;s being trained on chemistry grad level work a simple math question and it will probably get it wrong. They aren&#x27;t &quot;smart&quot;. It&#x27;s aggregations of text and ways to sample and then predict.</div><br/></div></div><div id="41543216" class="c"><input type="checkbox" id="c-41543216" checked=""/><div class="controls bullet"><span class="by">talldayo</span><span>|</span><a href="#41542863">parent</a><span>|</span><a href="#41544509">prev</a><span>|</span><a href="#41542004">next</a><span>|</span><label class="collapse" for="c-41543216">[-]</label><label class="expand" for="c-41543216">[11 more]</label></div><br/><div class="children"><div class="content">To be honest, I have gotten 100x more useful answers out of Siri&#x27;s WolframAlpha integration than I ever have out of ChatGPT. People don&#x27;t want a &quot;not completely incompetent graduate student&quot; responding to their prompts, they want NLP that reliably processes information. Last-generation voice assistants could at least do their job consistently, ChatGPT couldn&#x27;t be trusted to flick a light switch on a regular basis.</div><br/><div id="41543278" class="c"><input type="checkbox" id="c-41543278" checked=""/><div class="controls bullet"><span class="by">meowface</span><span>|</span><a href="#41542863">root</a><span>|</span><a href="#41543216">parent</a><span>|</span><a href="#41543347">next</a><span>|</span><label class="collapse" for="c-41543278">[-]</label><label class="expand" for="c-41543278">[1 more]</label></div><br/><div class="children"><div class="content">I use both for different things. WolframAlpha is great for well-defined questions with well-defined answers. LLMs are often great for anything that doesn&#x27;t fall into that.</div><br/></div></div><div id="41543347" class="c"><input type="checkbox" id="c-41543347" checked=""/><div class="controls bullet"><span class="by">Karrot_Kream</span><span>|</span><a href="#41542863">root</a><span>|</span><a href="#41543216">parent</a><span>|</span><a href="#41543278">prev</a><span>|</span><a href="#41543299">next</a><span>|</span><label class="collapse" for="c-41543347">[-]</label><label class="expand" for="c-41543347">[2 more]</label></div><br/><div class="children"><div class="content">How does this square up with literally what Terence Tao (TFA) writes about O1? Is this meant to say there&#x27;s a class of problems that O1 is still really bad at (or worse than intuition says it should be, at least)? Or is this &quot;he says, she says&quot; time for hot topics again on HN?</div><br/><div id="41543821" class="c"><input type="checkbox" id="c-41543821" checked=""/><div class="controls bullet"><span class="by">sebzim4500</span><span>|</span><a href="#41542863">root</a><span>|</span><a href="#41543347">parent</a><span>|</span><a href="#41543299">next</a><span>|</span><label class="collapse" for="c-41543821">[-]</label><label class="expand" for="c-41543821">[1 more]</label></div><br/><div class="children"><div class="content">o1-preview is still quite a specialized model, and you can come up with very easy questions that it fails embarassingly despite it&#x27;s success in seemingly much more difficult tests like olympiad programming&#x2F;maths questions.<p>You certainly shouldn&#x27;t think of it like having access to a graduate student whenever you want, although hopefully that&#x27;s coming.</div><br/></div></div></div></div><div id="41543299" class="c"><input type="checkbox" id="c-41543299" checked=""/><div class="controls bullet"><span class="by">thelastparadise</span><span>|</span><a href="#41542863">root</a><span>|</span><a href="#41543216">parent</a><span>|</span><a href="#41543347">prev</a><span>|</span><a href="#41543433">next</a><span>|</span><label class="collapse" for="c-41543299">[-]</label><label class="expand" for="c-41543299">[2 more]</label></div><br/><div class="children"><div class="content">Wait til you generate WolframAlpha queries from natural language using Claude 3.5 and use it to interpret results as well.</div><br/><div id="41543314" class="c"><input type="checkbox" id="c-41543314" checked=""/><div class="controls bullet"><span class="by">talldayo</span><span>|</span><a href="#41542863">root</a><span>|</span><a href="#41543299">parent</a><span>|</span><a href="#41543433">next</a><span>|</span><label class="collapse" for="c-41543314">[-]</label><label class="expand" for="c-41543314">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve tried the ChatGPT integration and it was kinda just useless. On smaller datasets it told me nothing that wasn&#x27;t obviously apparent from the charts and tables; on larger datasets it couldn&#x27;t do much besides basic key&#x2F;value retrieval. Asking it to analyze a large time-series table was an exercise in futility, I remain pretty unimpressed with current offerings.</div><br/></div></div></div></div><div id="41543433" class="c"><input type="checkbox" id="c-41543433" checked=""/><div class="controls bullet"><span class="by">segmondy</span><span>|</span><a href="#41542863">root</a><span>|</span><a href="#41543216">parent</a><span>|</span><a href="#41543299">prev</a><span>|</span><a href="#41542004">next</a><span>|</span><label class="collapse" for="c-41543433">[-]</label><label class="expand" for="c-41543433">[5 more]</label></div><br/><div class="children"><div class="content">Then you have a skill issue.  10 million paying are for GPT monthly because a large of them are getting useful value out of it.  WolframAlpha has been out for a while and didn&#x27;t take off for a reason.   &quot;GPT couldn&#x27;t be trusted to flick a light switch on a regular basis&quot; pretty much implies you are not serious or your knowledge about the capabilities of LLM is pretty much dated or derived from things you have read.</div><br/><div id="41543731" class="c"><input type="checkbox" id="c-41543731" checked=""/><div class="controls bullet"><span class="by">jazzyjackson</span><span>|</span><a href="#41542863">root</a><span>|</span><a href="#41543433">parent</a><span>|</span><a href="#41543525">next</a><span>|</span><label class="collapse" for="c-41543731">[-]</label><label class="expand" for="c-41543731">[1 more]</label></div><br/><div class="children"><div class="content">Wolframalpha is a free service, really kind of an ad for all the (curated, accurate) datasets built into Wolfram Language<p>Wolfram Research is a profitable company btw</div><br/></div></div><div id="41543525" class="c"><input type="checkbox" id="c-41543525" checked=""/><div class="controls bullet"><span class="by">codr7</span><span>|</span><a href="#41542863">root</a><span>|</span><a href="#41543433">parent</a><span>|</span><a href="#41543731">prev</a><span>|</span><a href="#41542004">next</a><span>|</span><label class="collapse" for="c-41543525">[-]</label><label class="expand" for="c-41543525">[3 more]</label></div><br/><div class="children"><div class="content">FACT: The technology is inherently unreliable in its current form. And the weakness is built in, its not going to go away anytime soon.</div><br/><div id="41543680" class="c"><input type="checkbox" id="c-41543680" checked=""/><div class="controls bullet"><span class="by">jonahx</span><span>|</span><a href="#41542863">root</a><span>|</span><a href="#41543525">parent</a><span>|</span><a href="#41542004">next</a><span>|</span><label class="collapse" for="c-41543680">[-]</label><label class="expand" for="c-41543680">[2 more]</label></div><br/><div class="children"><div class="content">The same is true of search engines, yet they are still incredibly useful.</div><br/><div id="41543861" class="c"><input type="checkbox" id="c-41543861" checked=""/><div class="controls bullet"><span class="by">codr7</span><span>|</span><a href="#41542863">root</a><span>|</span><a href="#41543680">parent</a><span>|</span><a href="#41542004">next</a><span>|</span><label class="collapse" for="c-41543861">[-]</label><label class="expand" for="c-41543861">[1 more]</label></div><br/><div class="children"><div class="content">Not the same technology at all, until recently at least.<p>EDIT: Looks like I hurt someone&#x27;s feelings by killing their unicorn. It was going to happen sooner or later, and pretending isn&#x27;t very constructive. In fact, pretending this technology is reliable is a very risky thing to do.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="41542004" class="c"><input type="checkbox" id="c-41542004" checked=""/><div class="controls bullet"><span class="by">eigenvalue</span><span>|</span><a href="#41542863">prev</a><span>|</span><a href="#41541830">next</a><span>|</span><label class="collapse" for="c-41542004">[-]</label><label class="expand" for="c-41542004">[11 more]</label></div><br/><div class="children"><div class="content">The o1 model is really remarkable. I was able to get very significant speedups to my already highly optimized Rust code in my fast vector similarity project, all verified with careful benchmarking and validation of correctness.<p>Not only that, it also helped me reimagine and conceptualize a new measure of statistical dependency based on Jensen-Shannon divergence that works very well. And it came up with a super fast implementation of normalized mutual information, something I tried to include in the library originally but struggled to find something fast enough when dealing with large vectors (say, 15,000 dimensions and up).<p>While it wasn’t able to give perfect Rust code that compiled on the very first try, it was able to fix all the bugs in one more try after pasting in all the compiler warning problems from VScode. In contrast, gpt-4o usually would take dozens of tries to fix all the many rust type errors, lifetime&#x2F;borrowing errors, and so on that it would inevitably introduce. And Claude3.5 sonnet is just plain stupid when it comes to Rust for some reason.<p>I really have to say, this feels like a true game changer, especially when you have really challenging tasks that you would be hard pressed to find many humans capable of helping with (at least without shelling out $500k+&#x2F;year in compensation for).<p>And it’s not just the performance optimization and relatively bug free code— it’s the creative problem solving and synthesis of huge amounts of core mathematical and algorithmic knowledge plus contemporary research results, combined with a strong ability to understand what you’re trying to accomplish and making it happen.<p>Here is the diff to the code file showing the changes:<p><a href="https:&#x2F;&#x2F;github.com&#x2F;Dicklesworthstone&#x2F;fast_vector_similarity&#x2F;commit&#x2F;358a05b0314fd09ca58febb9f1e3335bc05a3d76#diff-b1a35a68f14e696205874893c07fd24fdb88882b47c23cc0e0c80a30c7d53759">https:&#x2F;&#x2F;github.com&#x2F;Dicklesworthstone&#x2F;fast_vector_similarity&#x2F;...</a></div><br/><div id="41542153" class="c"><input type="checkbox" id="c-41542153" checked=""/><div class="controls bullet"><span class="by">jdiez17</span><span>|</span><a href="#41542004">parent</a><span>|</span><a href="#41542021">next</a><span>|</span><label class="collapse" for="c-41542153">[-]</label><label class="expand" for="c-41542153">[2 more]</label></div><br/><div class="children"><div class="content">&gt; 1,337 additions<p><i>cough</i></div><br/></div></div><div id="41542021" class="c"><input type="checkbox" id="c-41542021" checked=""/><div class="controls bullet"><span class="by">aprilthird2021</span><span>|</span><a href="#41542004">parent</a><span>|</span><a href="#41542153">prev</a><span>|</span><a href="#41542594">next</a><span>|</span><label class="collapse" for="c-41542021">[-]</label><label class="expand" for="c-41542021">[7 more]</label></div><br/><div class="children"><div class="content">But a lot of what you pay humans $500k a year for is to work with enormous existing systems that an LLM cannot understand just yet. Optimizing small libraries and implementing fast functions though is a huge improvement in any programmer&#x27;s toolbox.</div><br/><div id="41542240" class="c"><input type="checkbox" id="c-41542240" checked=""/><div class="controls bullet"><span class="by">eigenvalue</span><span>|</span><a href="#41542004">root</a><span>|</span><a href="#41542021">parent</a><span>|</span><a href="#41543118">next</a><span>|</span><label class="collapse" for="c-41542240">[-]</label><label class="expand" for="c-41542240">[1 more]</label></div><br/><div class="children"><div class="content">Yes, that’s certainly true, and that’s why I selected that library in particular to try with it. The fact that it’s mathematical— so not many lines of code, but each line packs a lot of punch and requires careful thought to optimize— makes it a perfect test bed for this model in particular. For larger projects that are simpler, you’re probably better off with Claude3.5 sonnet, since it has double the context window.</div><br/></div></div><div id="41543118" class="c"><input type="checkbox" id="c-41543118" checked=""/><div class="controls bullet"><span class="by">dyauspitr</span><span>|</span><a href="#41542004">root</a><span>|</span><a href="#41542021">parent</a><span>|</span><a href="#41542240">prev</a><span>|</span><a href="#41542594">next</a><span>|</span><label class="collapse" for="c-41543118">[-]</label><label class="expand" for="c-41543118">[5 more]</label></div><br/><div class="children"><div class="content">Can’t Gemini work with a million+ input tokens?</div><br/><div id="41543529" class="c"><input type="checkbox" id="c-41543529" checked=""/><div class="controls bullet"><span class="by">eigenvalue</span><span>|</span><a href="#41542004">root</a><span>|</span><a href="#41543118">parent</a><span>|</span><a href="#41543412">next</a><span>|</span><label class="collapse" for="c-41543529">[-]</label><label class="expand" for="c-41543529">[3 more]</label></div><br/><div class="children"><div class="content">Yes, but its reasoning ability is extremely poor in my experience with real world programming tasks. I’m talking about stuff that Claude3.5 Sonnet handles easily, and GPT4o can also handle if it can fit in its smaller context window, where Gemini 1.5 pro just completely fails.<p>Bigger context is definitely helpful, but not if it comes at the expense of reasoning&#x2F;analytical ability. I’m always a bit puzzled why people stress the importance of these “needle in a haystack” tests where the model has to find one specific thing in a huge document. That seems far less relevant to me in terms of usefulness in the real world.</div><br/><div id="41543677" class="c"><input type="checkbox" id="c-41543677" checked=""/><div class="controls bullet"><span class="by">derefr</span><span>|</span><a href="#41542004">root</a><span>|</span><a href="#41543529">parent</a><span>|</span><a href="#41543412">next</a><span>|</span><label class="collapse" for="c-41543677">[-]</label><label class="expand" for="c-41543677">[2 more]</label></div><br/><div class="children"><div class="content">&gt; I’m always a bit puzzled why people stress the importance of these “needle in a haystack” tests where the model has to find one specific thing in a huge document. That seems far less relevant to me in terms of usefulness in the real world.<p>How do you mean?<p>Half of writing code within a codebase, is knowing what functions already exist in the codebase for you to call in your own code; and&#x2F;or, what code you&#x27;ll have to change upstream and downstream of the code you&#x27;re modifying within the same codebase — or even by forking your dependencies and changing <i>them</i> — to get what you want to happen, to happen.<p>And half of, say, writing a longform novel, is knowing all the promises you&#x27;ve made to the reader, the active Chekov&#x27;s guns, and all the other constraints you&#x27;ve placed on yourself by hundreds of pages or even several books ago, that just became relevant again as of this very sentence. Or, moreover, which of those details it&#x27;s the proper time to <i>make</i> relevant again for maximum impact and proper first-in-last-out narrative bridging structure.<p>In both cases, these aren&#x27;t really literal &quot;needle in a haystack&quot; stress-tests; they should <i>properly</i> be tests of the model&#x27;s ability to perform some kind of &quot;associational priority indexing&quot; on the context, allowing it to build concepts into associational sub-networks and then make long-distance associations where the nodes are entire subnetworks. (Which isn&#x27;t something we really see yet, in any model.)</div><br/><div id="41543998" class="c"><input type="checkbox" id="c-41543998" checked=""/><div class="controls bullet"><span class="by">eigenvalue</span><span>|</span><a href="#41542004">root</a><span>|</span><a href="#41543677">parent</a><span>|</span><a href="#41543412">next</a><span>|</span><label class="collapse" for="c-41543998">[-]</label><label class="expand" for="c-41543998">[1 more]</label></div><br/><div class="children"><div class="content">Yes agreed, I wasn’t trying to say it’s totally useless, but it’s not as helpful as synthesizing all that context intelligently. It’s more of a parlor trick. But that trick can be handy if you need something like that. Really, the main issue with Gemini is that it’s simply not very smart compared to the competition, and the big context doesn’t make up for that in the slightest.</div><br/></div></div></div></div></div></div><div id="41543412" class="c"><input type="checkbox" id="c-41543412" checked=""/><div class="controls bullet"><span class="by">aprilthird2021</span><span>|</span><a href="#41542004">root</a><span>|</span><a href="#41543118">parent</a><span>|</span><a href="#41543529">prev</a><span>|</span><a href="#41542594">next</a><span>|</span><label class="collapse" for="c-41543412">[-]</label><label class="expand" for="c-41543412">[1 more]</label></div><br/><div class="children"><div class="content">It doesn&#x27;t work well though. You can&#x27;t just stuff your entire codebase into it and get good results. I work somewhere that tries to do this internally</div><br/></div></div></div></div></div></div><div id="41542594" class="c"><input type="checkbox" id="c-41542594" checked=""/><div class="controls bullet"><span class="by">Ylpertnodi</span><span>|</span><a href="#41542004">parent</a><span>|</span><a href="#41542021">prev</a><span>|</span><a href="#41541830">next</a><span>|</span><label class="collapse" for="c-41542594">[-]</label><label class="expand" for="c-41542594">[1 more]</label></div><br/><div class="children"><div class="content">&gt;you would be hard pressed to find many humans capable of helping with (at least without shelling out $500k+&#x2F;year in compensation for).<p>And now we have a $number we can relate, and refer, to.</div><br/></div></div></div></div><div id="41541830" class="c"><input type="checkbox" id="c-41541830" checked=""/><div class="controls bullet"><span class="by">abstractbill</span><span>|</span><a href="#41542004">prev</a><span>|</span><a href="#41541327">next</a><span>|</span><label class="collapse" for="c-41541830">[-]</label><label class="expand" for="c-41541830">[9 more]</label></div><br/><div class="children"><div class="content">My experience with O1 has been very different. I wouldn&#x27;t even say it&#x27;s performing at a &quot;good undergrad&quot; level for me.<p>For example, I asked a pretty simple question here and it got completely confused:<p><a href="https:&#x2F;&#x2F;moorier.com&#x2F;math-chat-1.png" rel="nofollow">https:&#x2F;&#x2F;moorier.com&#x2F;math-chat-1.png</a>
<a href="https:&#x2F;&#x2F;moorier.com&#x2F;math-chat-2.png" rel="nofollow">https:&#x2F;&#x2F;moorier.com&#x2F;math-chat-2.png</a>
<a href="https:&#x2F;&#x2F;moorier.com&#x2F;math-chat-3.png" rel="nofollow">https:&#x2F;&#x2F;moorier.com&#x2F;math-chat-3.png</a><p>(Full chat should be here: <a href="https:&#x2F;&#x2F;chatgpt.com&#x2F;share&#x2F;66e5d2dd-0b08-8011-89c8-f6895f321733" rel="nofollow">https:&#x2F;&#x2F;chatgpt.com&#x2F;share&#x2F;66e5d2dd-0b08-8011-89c8-f6895f3217...</a>)</div><br/><div id="41541843" class="c"><input type="checkbox" id="c-41541843" checked=""/><div class="controls bullet"><span class="by">jghn</span><span>|</span><a href="#41541830">parent</a><span>|</span><a href="#41541921">next</a><span>|</span><label class="collapse" for="c-41541843">[-]</label><label class="expand" for="c-41541843">[3 more]</label></div><br/><div class="children"><div class="content">Anecdata, but I&#x27;ve been finding O1 to be worse than 4o &amp; Claude 3.5 Sonnet. To add insult to injury, it&#x27;s slower &amp; chattier.</div><br/><div id="41541884" class="c"><input type="checkbox" id="c-41541884" checked=""/><div class="controls bullet"><span class="by">anujsjpatel</span><span>|</span><a href="#41541830">root</a><span>|</span><a href="#41541843">parent</a><span>|</span><a href="#41541921">next</a><span>|</span><label class="collapse" for="c-41541884">[-]</label><label class="expand" for="c-41541884">[2 more]</label></div><br/><div class="children"><div class="content">And sometimes it just bugs out and doesn&#x27;t give any response? Faced that twice now, it &quot;thought&quot; for like 10-30s then no answer and I had to click regenerate and wait for it again.</div><br/><div id="41541992" class="c"><input type="checkbox" id="c-41541992" checked=""/><div class="controls bullet"><span class="by">jghn</span><span>|</span><a href="#41541830">root</a><span>|</span><a href="#41541884">parent</a><span>|</span><a href="#41541921">next</a><span>|</span><label class="collapse" for="c-41541992">[-]</label><label class="expand" for="c-41541992">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve seen it take over a couple of minutes, at which point I switched to Claude. And have seen reports of it taking even longer. So it may be that you didn&#x27;t wait long enough.</div><br/></div></div></div></div></div></div><div id="41541921" class="c"><input type="checkbox" id="c-41541921" checked=""/><div class="controls bullet"><span class="by">abdullahkhalids</span><span>|</span><a href="#41541830">parent</a><span>|</span><a href="#41541843">prev</a><span>|</span><a href="#41541952">next</a><span>|</span><label class="collapse" for="c-41541921">[-]</label><label class="expand" for="c-41541921">[2 more]</label></div><br/><div class="children"><div class="content">Thinking about training LLMs on geometry. A lot of information in the sources would be contained in the diagrams accompanying the text. This model is not multi-modal, so maybe it wasn&#x27;t trained on the accompanying diagrams at all.<p>I would really like if people check on a set of geometry and a set of analysis questions and compare the difference.</div><br/><div id="41542436" class="c"><input type="checkbox" id="c-41542436" checked=""/><div class="controls bullet"><span class="by">jazzyjackson</span><span>|</span><a href="#41541830">root</a><span>|</span><a href="#41541921">parent</a><span>|</span><a href="#41541952">next</a><span>|</span><label class="collapse" for="c-41542436">[-]</label><label class="expand" for="c-41542436">[1 more]</label></div><br/><div class="children"><div class="content">It will be trash. I&#x27;ll have to dig up a chat I had the weekend GPT4 was released, I was musing about dodecahedron packing problems and GPT4 started with an assertion that a line through a sphere intersects the surface 3 times.<p>Maybe if you fine tuned it on Euclid&#x27;s Elements and then allowed it to run experiments with Mathematica snippets it could check its assumptions before spouting nonsense</div><br/></div></div></div></div><div id="41541952" class="c"><input type="checkbox" id="c-41541952" checked=""/><div class="controls bullet"><span class="by">almostgotcaught</span><span>|</span><a href="#41541830">parent</a><span>|</span><a href="#41541921">prev</a><span>|</span><a href="#41542444">next</a><span>|</span><label class="collapse" for="c-41541952">[-]</label><label class="expand" for="c-41541952">[2 more]</label></div><br/><div class="children"><div class="content">Why would they do this - make it speak like a customer service agent. The ideal experience here is short and succinct, not verbose and obsequious.</div><br/><div id="41542245" class="c"><input type="checkbox" id="c-41542245" checked=""/><div class="controls bullet"><span class="by">ljlolel</span><span>|</span><a href="#41541830">root</a><span>|</span><a href="#41541952">parent</a><span>|</span><a href="#41542444">next</a><span>|</span><label class="collapse" for="c-41542245">[-]</label><label class="expand" for="c-41542245">[1 more]</label></div><br/><div class="children"><div class="content">Performs better on chat bot arena head to head</div><br/></div></div></div></div><div id="41542444" class="c"><input type="checkbox" id="c-41542444" checked=""/><div class="controls bullet"><span class="by">svdr</span><span>|</span><a href="#41541830">parent</a><span>|</span><a href="#41541952">prev</a><span>|</span><a href="#41541327">next</a><span>|</span><label class="collapse" for="c-41542444">[-]</label><label class="expand" for="c-41542444">[1 more]</label></div><br/><div class="children"><div class="content">Did you find out what the error was in computing the volume of the truncated icosidodecahedron?</div><br/></div></div></div></div><div id="41541327" class="c"><input type="checkbox" id="c-41541327" checked=""/><div class="controls bullet"><span class="by">bitexploder</span><span>|</span><a href="#41541830">prev</a><span>|</span><a href="#41544989">next</a><span>|</span><label class="collapse" for="c-41541327">[-]</label><label class="expand" for="c-41541327">[3 more]</label></div><br/><div class="children"><div class="content">The novelty to me is that the “The experience seemed roughly on par with trying to advise a mediocre, but not completely incompetent, graduate student.” in so many subject areas! I have found great value in using LLMs to sort things out. In areas where I am very experienced it can be really helpful at tons of small chores. Like Terrence was pointing out in his third experiment — if you break the problem down it does solid work filling in smaller blanks. You need the conceptual understanding. Part of this is prompting skill. If you go into an area you don’t know you have to try and build the prompts up. Dive into something small and specific and work outward if the answer is known. Start specific and focused if starting from the outside in. I have used this to cut through conceptual layers of very complex topics I have zero knowledge in and then verify my concepts via experts on YT&#x2F;research papers&#x2F;trusted sources. It is an amazing tool.</div><br/><div id="41541504" class="c"><input type="checkbox" id="c-41541504" checked=""/><div class="controls bullet"><span class="by">wenc</span><span>|</span><a href="#41541327">parent</a><span>|</span><a href="#41544989">next</a><span>|</span><label class="collapse" for="c-41541504">[-]</label><label class="expand" for="c-41541504">[2 more]</label></div><br/><div class="children"><div class="content">This has been my experience as well. I treat LLMs like an intern or junior who can do the legwork that I have no bandwidth to do myself. I have to supervise it and help it along, checking for mistakes, but I do get useful results in the end.<p>Attitudinally, I suspect people who have had experience  supervising interns or mentoring juniors are probably those who are able to get value out of LLMs (paid ones - free ones are no good) rather than grizzled lone individual contributors -- I myself have been in this camp for most of my early career -- who don&#x27;t know how to coax value out of people.</div><br/><div id="41541660" class="c"><input type="checkbox" id="c-41541660" checked=""/><div class="controls bullet"><span class="by">wslh</span><span>|</span><a href="#41541327">root</a><span>|</span><a href="#41541504">parent</a><span>|</span><a href="#41544989">next</a><span>|</span><label class="collapse" for="c-41541660">[-]</label><label class="expand" for="c-41541660">[1 more]</label></div><br/><div class="children"><div class="content">&gt; ... that I have no bandwidth to do myself.<p>One of the most interesting aspects of this thread is how it brings us back to the fundamentals of attention in machine learning [1]. This is a key point: while humans have intelligence, our attention is inherently limited. This is why the concept behind Attention Is All You Need [2] is so relevant to what we&#x27;re discussing.<p>My 2 cents: our human intelligence is the glue that binds everything together.<p>[1] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Attention_(machine_learning)" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Attention_(machine_learning)</a><p>[2] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Attention_Is_All_You_Need" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Attention_Is_All_You_Need</a></div><br/></div></div></div></div></div></div><div id="41544989" class="c"><input type="checkbox" id="c-41544989" checked=""/><div class="controls bullet"><span class="by">afro88</span><span>|</span><a href="#41541327">prev</a><span>|</span><a href="#41541665">next</a><span>|</span><label class="collapse" for="c-41544989">[-]</label><label class="expand" for="c-41544989">[1 more]</label></div><br/><div class="children"><div class="content">The o1 model is hit and miss for me. On one hand it has solved the NYT Connections game [0] each day I&#x27;ve tried it [1]. Other models, including Claude Sonnet 3.5 cannot.<p>But on the other hand it misses important detail and hallucinates, just like GPT-4o. And can need a lot of hand holding and correction to get to the right answer, so much so that sometimes you wonder if it would have been easier to just do it yourself. Only this time it&#x27;s worse because you&#x27;re waiting 20-60 seconds for an answer.<p>I wonder if what it excels at is just the stuff that I don&#x27;t need it for. I&#x27;m not in classic STEM, I&#x27;m in software engineering, and o1 isn&#x27;t so much better that it justifies the wait time (yet).<p>One area I haven&#x27;t explored is using it to plan implementation or architectural changes. I feel like it might be better for this, but need the right problems to throw at it.<p>[0] <a href="https:&#x2F;&#x2F;www.nytimes.com&#x2F;games&#x2F;connections" rel="nofollow">https:&#x2F;&#x2F;www.nytimes.com&#x2F;games&#x2F;connections</a><p>[1] <a href="https:&#x2F;&#x2F;chatgpt.com&#x2F;share&#x2F;66e40d64-6f70-8004-9fe5-83dd3653a573" rel="nofollow">https:&#x2F;&#x2F;chatgpt.com&#x2F;share&#x2F;66e40d64-6f70-8004-9fe5-83dd3653a5...</a></div><br/></div></div><div id="41541665" class="c"><input type="checkbox" id="c-41541665" checked=""/><div class="controls bullet"><span class="by">kzz102</span><span>|</span><a href="#41544989">prev</a><span>|</span><a href="#41541688">next</a><span>|</span><label class="collapse" for="c-41541665">[-]</label><label class="expand" for="c-41541665">[3 more]</label></div><br/><div class="children"><div class="content">It&#x27;s interesting that humans would also benefit from the &quot;chain of thought&quot; type reasoning. In fact, I would argue all students studying math will greatly increase their competence if they are required to recall all relevant definition and information before using it. We don&#x27;t do this in practice (including teachers and mathematicians!) because recall is effortful, and we don&#x27;t like to spent more effort than necessary to solve a problem. If recall fails, then we have to look up information which takes even more effort. This is why in practice, there is a tremendous incentive to just &quot;wing it&quot;.<p>AI has no emotional barrier to wasted effort, which make them better reasoners than their innate ability would suggest.</div><br/><div id="41543700" class="c"><input type="checkbox" id="c-41543700" checked=""/><div class="controls bullet"><span class="by">schappim</span><span>|</span><a href="#41541665">parent</a><span>|</span><a href="#41542438">next</a><span>|</span><label class="collapse" for="c-41543700">[-]</label><label class="expand" for="c-41543700">[1 more]</label></div><br/><div class="children"><div class="content">Showing your work in tests is kind of like “chain of thought” reasoning, but there’s a slight difference. Both force you to break down your process step by step, making sure the logic holds and you aren’t skipping crucial steps. But while showing your work is more about demonstrating the correct procedure, “chain of thought” reasoning pushes you to recall relevant definitions and concepts as you go, ensuring a deeper understanding. In both cases, the goal is to avoid just “winging it,” but “chain of thought” really digs into the recall aspect, which humans tend to avoid because it’s effortful.</div><br/></div></div><div id="41542438" class="c"><input type="checkbox" id="c-41542438" checked=""/><div class="controls bullet"><span class="by">Satam</span><span>|</span><a href="#41541665">parent</a><span>|</span><a href="#41543700">prev</a><span>|</span><a href="#41541688">next</a><span>|</span><label class="collapse" for="c-41542438">[-]</label><label class="expand" for="c-41542438">[1 more]</label></div><br/><div class="children"><div class="content">Wow! I love this take. Somehow with all this evidence of COT helping out LLMs, I never thought about using it more myself. Sure, we kind of do it already but definitely not to the degree of LLMs, at least not usually. Maybe that&#x27;s why writing is so often admired as a way to do great thinking - it enables longer chains of thoughts with less effort.</div><br/></div></div></div></div><div id="41541688" class="c"><input type="checkbox" id="c-41541688" checked=""/><div class="controls bullet"><span class="by">perihelions</span><span>|</span><a href="#41541665">prev</a><span>|</span><a href="#41542495">next</a><span>|</span><label class="collapse" for="c-41541688">[-]</label><label class="expand" for="c-41541688">[18 more]</label></div><br/><div class="children"><div class="content">I&#x27;m so excited in anticipation of my near-term return to studying math, as an independent curiosity hobby. It&#x27;s going to be epically fun this time around with LLM&#x27;s to lean on. Coincidentally like Terence Tao, I&#x27;ve also been asking complex analysis queries* of LLM&#x27;s, things I was trying to understand better in my working through textbooks. Their ability to interpret open-ended math questions, and quickly find <i>distant conceptual links</i> that are helpful and relevant, astonishes me. Fields laureate Professor Tao (naturally) looks <i>down</i> on the current crop of mathematics LLM—&quot;not completely incompetent graduate student...&quot;—but at my current ability level that just means looking <i>up</i>.<p>*(I remember a specific impressive example from 6 months ago: I asked if certain definitions could be relaxed to allow complex analysis on a non-orientable manifold, like a Klein bottle, something I spent a lot of time puzzling over, and an LLM instantly figured out it would make the Cauchy-Riemann equations globally inconsistent. (In a sense the arbitrary sign convention in CR <i>defines</i> an orientation on a manifold: reversing manifold orientation is the same as swapping i with -i. I understand this now, solely because an LLM suggested looking at it). Of course, I&#x27;m sure this isn&#x27;t original LLM thinking—the math&#x27;s certainly written down somewhere in its training material, in some highly specific postgraduate textbook I have no knowledge of. That&#x27;s not relevant to me. For me, it&#x27;s <i>absolutely impossible</i> to answer this type of question, where I have very little idea where to start, without either an LLM or a PhD-level domain specialist. There is <i>no other tool</i> that can make this kind of <i>semantic-level</i> search accessible to me. I&#x27;m very carefully thinking how best to make use of such an, incredibly powerful but alien, tool...)</div><br/><div id="41546132" class="c"><input type="checkbox" id="c-41546132" checked=""/><div class="controls bullet"><span class="by">rossant</span><span>|</span><a href="#41541688">parent</a><span>|</span><a href="#41541755">next</a><span>|</span><label class="collapse" for="c-41546132">[-]</label><label class="expand" for="c-41546132">[1 more]</label></div><br/><div class="children"><div class="content">I agree. Having access to a kind of semantic full search engine on basically all textbooks on Earth feels like a superpower. Even better would be if it could pinpoint the exact textbook references it found the answer in.</div><br/></div></div><div id="41541755" class="c"><input type="checkbox" id="c-41541755" checked=""/><div class="controls bullet"><span class="by">nybsjytm</span><span>|</span><a href="#41541688">parent</a><span>|</span><a href="#41546132">prev</a><span>|</span><a href="#41541717">next</a><span>|</span><label class="collapse" for="c-41541755">[-]</label><label class="expand" for="c-41541755">[14 more]</label></div><br/><div class="children"><div class="content">How will you know if its answers are correct or not?</div><br/><div id="41541774" class="c"><input type="checkbox" id="c-41541774" checked=""/><div class="controls bullet"><span class="by">perihelions</span><span>|</span><a href="#41541688">root</a><span>|</span><a href="#41541755">parent</a><span>|</span><a href="#41541717">next</a><span>|</span><label class="collapse" for="c-41541774">[-]</label><label class="expand" for="c-41541774">[13 more]</label></div><br/><div class="children"><div class="content">Because I&#x27;m verifying everything by hand, as is the whole point of studying pure mathematics.</div><br/><div id="41542286" class="c"><input type="checkbox" id="c-41542286" checked=""/><div class="controls bullet"><span class="by">SOTGO</span><span>|</span><a href="#41541688">root</a><span>|</span><a href="#41541774">parent</a><span>|</span><a href="#41542335">next</a><span>|</span><label class="collapse" for="c-41542286">[-]</label><label class="expand" for="c-41542286">[11 more]</label></div><br/><div class="children"><div class="content">How can you verify a proof though? Pure math isn&#x27;t really about computations, and it can be very hard to spot subtle errors in a proof that an LLM might introduce, especially since they seem better at sounding convincing rather than being right.</div><br/><div id="41544824" class="c"><input type="checkbox" id="c-41544824" checked=""/><div class="controls bullet"><span class="by">perihelions</span><span>|</span><a href="#41541688">root</a><span>|</span><a href="#41542286">parent</a><span>|</span><a href="#41545002">next</a><span>|</span><label class="collapse" for="c-41544824">[-]</label><label class="expand" for="c-41544824">[1 more]</label></div><br/><div class="children"><div class="content">The same way I verify my own proofs of textbook exercises: very cautiously. Subtle errors are a feature of the problem domain, not a new novelty.</div><br/></div></div><div id="41545002" class="c"><input type="checkbox" id="c-41545002" checked=""/><div class="controls bullet"><span class="by">Davidzheng</span><span>|</span><a href="#41541688">root</a><span>|</span><a href="#41542286">parent</a><span>|</span><a href="#41544824">prev</a><span>|</span><a href="#41542869">next</a><span>|</span><label class="collapse" for="c-41545002">[-]</label><label class="expand" for="c-41545002">[1 more]</label></div><br/><div class="children"><div class="content">are you questioning the entire premise of pure mathematics?</div><br/></div></div><div id="41542869" class="c"><input type="checkbox" id="c-41542869" checked=""/><div class="controls bullet"><span class="by">fragmede</span><span>|</span><a href="#41541688">root</a><span>|</span><a href="#41542286">parent</a><span>|</span><a href="#41545002">prev</a><span>|</span><a href="#41542335">next</a><span>|</span><label class="collapse" for="c-41542869">[-]</label><label class="expand" for="c-41542869">[8 more]</label></div><br/><div class="children"><div class="content">By using Lean, a proof assistant and a functional programming language.<p>Here&#x27;s @tao on mathstodon saying he&#x27;s learning it.<p><a href="https:&#x2F;&#x2F;mathstodon.xyz&#x2F;@tao&#x2F;111206761117553482" rel="nofollow">https:&#x2F;&#x2F;mathstodon.xyz&#x2F;@tao&#x2F;111206761117553482</a></div><br/><div id="41543287" class="c"><input type="checkbox" id="c-41543287" checked=""/><div class="controls bullet"><span class="by">nybsjytm</span><span>|</span><a href="#41541688">root</a><span>|</span><a href="#41542869">parent</a><span>|</span><a href="#41542335">next</a><span>|</span><label class="collapse" for="c-41543287">[-]</label><label class="expand" for="c-41543287">[7 more]</label></div><br/><div class="children"><div class="content">To code proofs in lean, you have to understand the proof very well. It doesn&#x27;t seem to be very reasonable for someone learning material for the first time.</div><br/><div id="41543829" class="c"><input type="checkbox" id="c-41543829" checked=""/><div class="controls bullet"><span class="by">sn9</span><span>|</span><a href="#41541688">root</a><span>|</span><a href="#41543287">parent</a><span>|</span><a href="#41543809">next</a><span>|</span><label class="collapse" for="c-41543829">[-]</label><label class="expand" for="c-41543829">[2 more]</label></div><br/><div class="children"><div class="content">That&#x27;s not true at all.<p>You can literally learn how to write proofs <i>using</i> Lean: <a href="https:&#x2F;&#x2F;djvelleman.github.io&#x2F;HTPIwL&#x2F;" rel="nofollow">https:&#x2F;&#x2F;djvelleman.github.io&#x2F;HTPIwL&#x2F;</a></div><br/><div id="41544591" class="c"><input type="checkbox" id="c-41544591" checked=""/><div class="controls bullet"><span class="by">markusde</span><span>|</span><a href="#41541688">root</a><span>|</span><a href="#41543829">parent</a><span>|</span><a href="#41543809">next</a><span>|</span><label class="collapse" for="c-41544591">[-]</label><label class="expand" for="c-41544591">[1 more]</label></div><br/><div class="children"><div class="content">The examples in this book are extraordinarily simple, and covers material that many proof assistants were designed to be extremely good at expressing. I wouldn&#x27;t be surprised if a LLM could automate the exercises in this book completely.<p>Writing nontrivial proofs in a theorem prover is a different beast. In my experience (as someone who writes mechanized mathematical proofs for a living) you need to not only know the proof very well beforehand, but you also need to know the design considerations for all of the steps you are going to use beforehand, and you also need to think about all of the ways your proof is going to be used beforehand. Getting these wrong frequently means redoing a ton of work, because design errors in proof systems are subtle and can remain latent for a long time.</div><br/></div></div></div></div><div id="41543809" class="c"><input type="checkbox" id="c-41543809" checked=""/><div class="controls bullet"><span class="by">JonChesterfield</span><span>|</span><a href="#41541688">root</a><span>|</span><a href="#41543287">parent</a><span>|</span><a href="#41543829">prev</a><span>|</span><a href="#41543783">next</a><span>|</span><label class="collapse" for="c-41543809">[-]</label><label class="expand" for="c-41543809">[2 more]</label></div><br/><div class="children"><div class="content">The premise is to have the LLM put up something that might be true, then have lean tell you whether it is true. If you trust lean, you don&#x27;t need to understand the proof yourself to trust it.</div><br/><div id="41545106" class="c"><input type="checkbox" id="c-41545106" checked=""/><div class="controls bullet"><span class="by">nybsjytm</span><span>|</span><a href="#41541688">root</a><span>|</span><a href="#41543809">parent</a><span>|</span><a href="#41543783">next</a><span>|</span><label class="collapse" for="c-41545106">[-]</label><label class="expand" for="c-41545106">[1 more]</label></div><br/><div class="children"><div class="content">The issue is that a hypothetical answer from a LLM is not even remotely easy to directly put into lean. You might ask the LLM to give you an answer together with a lean formalization, but the issue is that this kind of &#x27;autoformalization&#x27; is at present not at at all reliable.</div><br/></div></div></div></div><div id="41543783" class="c"><input type="checkbox" id="c-41543783" checked=""/><div class="controls bullet"><span class="by">cma</span><span>|</span><a href="#41541688">root</a><span>|</span><a href="#41543287">parent</a><span>|</span><a href="#41543809">prev</a><span>|</span><a href="#41542335">next</a><span>|</span><label class="collapse" for="c-41543783">[-]</label><label class="expand" for="c-41543783">[2 more]</label></div><br/><div class="children"><div class="content">Tao says that isn&#x27;t the case for all of it and that on massive collaborative projects he&#x27;s done many nonmathemeticians did sections of them.  He says someone who understands it well needs to do the initial proof sketch and key parts but that lots of parts of the proof can be worked on by nonmathemeticians.</div><br/><div id="41545096" class="c"><input type="checkbox" id="c-41545096" checked=""/><div class="controls bullet"><span class="by">nybsjytm</span><span>|</span><a href="#41541688">root</a><span>|</span><a href="#41543783">parent</a><span>|</span><a href="#41542335">next</a><span>|</span><label class="collapse" for="c-41545096">[-]</label><label class="expand" for="c-41545096">[1 more]</label></div><br/><div class="children"><div class="content">If Tao says he&#x27;s interested in something being coded in lean, there are literal teams of people who will throw themselves at him. Those projects are very well organized from the top down by people who know what they&#x27;re doing, it&#x27;s no surprise that they are able to create some space for people who don&#x27;t understand the whole scope.<p>This is also the case for other top-profile mathematicians like Peter Scholze. Good luck to someone who wants to put chatgpt answers to random hypotheticals into lean to see if they&#x27;re right, I don&#x27;t think they&#x27;ll have so easy a time of it.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="41542335" class="c"><input type="checkbox" id="c-41542335" checked=""/><div class="controls bullet"><span class="by">nybsjytm</span><span>|</span><a href="#41541688">root</a><span>|</span><a href="#41541774">parent</a><span>|</span><a href="#41542286">prev</a><span>|</span><a href="#41541717">next</a><span>|</span><label class="collapse" for="c-41542335">[-]</label><label class="expand" for="c-41542335">[1 more]</label></div><br/><div class="children"><div class="content">Good luck! That can be pretty hard to do when you&#x27;re at the learning stage, and I would think doubly so given the LLM style where everything &#x27;looks&#x27; very convincing.</div><br/></div></div></div></div></div></div><div id="41541717" class="c"><input type="checkbox" id="c-41541717" checked=""/><div class="controls bullet"><span class="by">WanderPanda</span><span>|</span><a href="#41541688">parent</a><span>|</span><a href="#41541755">prev</a><span>|</span><a href="#41542495">next</a><span>|</span><label class="collapse" for="c-41541717">[-]</label><label class="expand" for="c-41541717">[2 more]</label></div><br/><div class="children"><div class="content">How will we even measure this? Benchmarks are gamed&#x2F;trained on and there is no way that there is much signal in the chatbot arena for these types of queries?<p>I think in just a few month the average user will not be able to tell the difference in performance between the major models</div><br/></div></div></div></div><div id="41542495" class="c"><input type="checkbox" id="c-41542495" checked=""/><div class="controls bullet"><span class="by">fsndz</span><span>|</span><a href="#41541688">prev</a><span>|</span><a href="#41543473">next</a><span>|</span><label class="collapse" for="c-41542495">[-]</label><label class="expand" for="c-41542495">[1 more]</label></div><br/><div class="children"><div class="content">Completely agree with Terence Tao. this is a real advancement. I&#x27;ve always believed that with the right data allowing the LLM to be trained to imitate reasoning, it&#x27;s possible to improve its performance. However, this is still pattern matching, and I suspect that this approach may not be very effective for creating true generalization. As a result, once o1 becomes generally available, we will likely notice the persistent hallucinations and faulty reasoning, especially when the problem is sufficiently new or complex, beyond the &quot;reasoning programs&quot; or &quot;reasoning patterns&quot; the model learned during the reinforcement learning phase.
<a href="https:&#x2F;&#x2F;www.lycee.ai&#x2F;blog&#x2F;openai-o1-release-agi-reasoning" rel="nofollow">https:&#x2F;&#x2F;www.lycee.ai&#x2F;blog&#x2F;openai-o1-release-agi-reasoning</a></div><br/></div></div><div id="41543473" class="c"><input type="checkbox" id="c-41543473" checked=""/><div class="controls bullet"><span class="by">ak_111</span><span>|</span><a href="#41542495">prev</a><span>|</span><a href="#41544782">next</a><span>|</span><label class="collapse" for="c-41543473">[-]</label><label class="expand" for="c-41543473">[2 more]</label></div><br/><div class="children"><div class="content">He mentions that he posed to O1 the same challenge he posed to a previous GPT (which he also previously blogged about), so I am wondering how much O1 benefited from potentially &quot;seeing&quot; this discussion in its training set (which probably contains a very well recent snapshot of the world wide web).</div><br/><div id="41545571" class="c"><input type="checkbox" id="c-41545571" checked=""/><div class="controls bullet"><span class="by">lysecret</span><span>|</span><a href="#41543473">parent</a><span>|</span><a href="#41544782">next</a><span>|</span><label class="collapse" for="c-41545571">[-]</label><label class="expand" for="c-41545571">[1 more]</label></div><br/><div class="children"><div class="content">In some of the responses o1 actually was telling me it had a cutoff of 2023. not sure if they officially stated it somewhere.</div><br/></div></div></div></div><div id="41544782" class="c"><input type="checkbox" id="c-41544782" checked=""/><div class="controls bullet"><span class="by">s1mon</span><span>|</span><a href="#41543473">prev</a><span>|</span><a href="#41542734">next</a><span>|</span><label class="collapse" for="c-41544782">[-]</label><label class="expand" for="c-41544782">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not a mathematician much beyond AP Calc in high school (almost 40 years ago). I am deeply fascinated by Bézier curves and geometric continuity. I&#x27;ve spent a lot of time digging up research papers and references about this and related Computer Aided Geometric Design mathematics. Mostly I skim them for the illustrations and more geometric relations. For several years I&#x27;ve been trying to understand how to make sure that a Bézier curve is G3 to an adjoining curve, given the tangent direction, and first and second curvature derivatives.<p>I&#x27;ve tried a variety of ways to ask various LLMs to help solve this. Finally with access to ChatGPT o1-preview I was able to get a good answer. The first answer was wrong, but with a little more prompting and clarification I was able to get the answer I wanted to relate the positions of P0, P1, P2 and P3 so that a Bézier curve could be G3. This isn&#x27;t something that is unknown because there are many CAD programs which can do this already, but I had not been able to find the answer I was looking for in a form that was useful to me.<p>I don&#x27;t really know where that puts o1-preview relative to a math grad student, but after spending tons of time over a couple years on this pet project, getting an answer from a chat bot was one of the more magical moments I&#x27;ve had with technology in a long time.</div><br/></div></div><div id="41542734" class="c"><input type="checkbox" id="c-41542734" checked=""/><div class="controls bullet"><span class="by">gcanyon</span><span>|</span><a href="#41544782">prev</a><span>|</span><a href="#41545630">next</a><span>|</span><label class="collapse" for="c-41542734">[-]</label><label class="expand" for="c-41542734">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The experience seemed roughly on par with trying to advise a mediocre, but not completely incompetent, graduate student.<p>Coming from Terence Tao that seems pretty remarkable to me?</div><br/></div></div><div id="41545630" class="c"><input type="checkbox" id="c-41545630" checked=""/><div class="controls bullet"><span class="by">afian</span><span>|</span><a href="#41542734">prev</a><span>|</span><a href="#41542476">next</a><span>|</span><label class="collapse" for="c-41545630">[-]</label><label class="expand" for="c-41545630">[1 more]</label></div><br/><div class="children"><div class="content">As a previously &quot;mediocre, but not completely incompetent, graduate student&quot; at a top research university (who&#x27;s famous advisor was understandably frustrated with him), I consider this a huge win!</div><br/></div></div><div id="41542476" class="c"><input type="checkbox" id="c-41542476" checked=""/><div class="controls bullet"><span class="by">nybsjytm</span><span>|</span><a href="#41545630">prev</a><span>|</span><a href="#41542458">next</a><span>|</span><label class="collapse" for="c-41542476">[-]</label><label class="expand" for="c-41542476">[2 more]</label></div><br/><div class="children"><div class="content">Daniel Litt, an algebraic geometer on twitter, said &quot;Pretty impressed by o1-preview! Still not having much luck asking it to do any interesting math but it seems much more reliable with simple things; I can actually imagine it being a net time-saver at this point with some non-mathematical tasks.&quot;<p>Any other takes by mathematicians out there?</div><br/></div></div><div id="41542458" class="c"><input type="checkbox" id="c-41542458" checked=""/><div class="controls bullet"><span class="by">nmca</span><span>|</span><a href="#41542476">prev</a><span>|</span><a href="#41542298">next</a><span>|</span><label class="collapse" for="c-41542458">[-]</label><label class="expand" for="c-41542458">[1 more]</label></div><br/><div class="children"><div class="content">Note the selection effect in “a mediocre graduate student” (that got to work with Terry Tao)</div><br/></div></div><div id="41542298" class="c"><input type="checkbox" id="c-41542298" checked=""/><div class="controls bullet"><span class="by">itissid</span><span>|</span><a href="#41542458">prev</a><span>|</span><a href="#41543633">next</a><span>|</span><label class="collapse" for="c-41542298">[-]</label><label class="expand" for="c-41542298">[1 more]</label></div><br/><div class="children"><div class="content">One thing it&#x27;s certainly doing better is exploring the search space better e.g.:  <a href="https:&#x2F;&#x2F;x.com&#x2F;sg3487&#x2F;status&#x2F;1835040593703010714" rel="nofollow">https:&#x2F;&#x2F;x.com&#x2F;sg3487&#x2F;status&#x2F;1835040593703010714</a><p>If you know the contours of the answer and can describe what you are looking for it can quickly find it for you.</div><br/></div></div><div id="41543633" class="c"><input type="checkbox" id="c-41543633" checked=""/><div class="controls bullet"><span class="by">busyant</span><span>|</span><a href="#41542298">prev</a><span>|</span><a href="#41541906">next</a><span>|</span><label class="collapse" for="c-41543633">[-]</label><label class="expand" for="c-41543633">[1 more]</label></div><br/><div class="children"><div class="content">Well, one thing is clear.<p>Math grad students everywhere now have a benchmark to determine if Terry Tao considers them to be mediocre or incompetent.</div><br/></div></div><div id="41541906" class="c"><input type="checkbox" id="c-41541906" checked=""/><div class="controls bullet"><span class="by">gary_0</span><span>|</span><a href="#41543633">prev</a><span>|</span><a href="#41543791">next</a><span>|</span><label class="collapse" for="c-41541906">[-]</label><label class="expand" for="c-41541906">[7 more]</label></div><br/><div class="children"><div class="content">Tao mentions grad students; I wonder how they feel reading this?<p>As LLMs continue to improve I feel like anyone making a living doing the &quot;99% perspiration&quot; part of intellectual labor is about to enter a world of hurt.</div><br/><div id="41542930" class="c"><input type="checkbox" id="c-41542930" checked=""/><div class="controls bullet"><span class="by">fragmede</span><span>|</span><a href="#41541906">parent</a><span>|</span><a href="#41543367">next</a><span>|</span><label class="collapse" for="c-41542930">[-]</label><label class="expand" for="c-41542930">[2 more]</label></div><br/><div class="children"><div class="content">&gt; The experience seemed roughly on par with trying to advise a mediocre, but not completely incompetent, graduate student.<p>And you thought you had imposter syndrome before!</div><br/></div></div><div id="41543367" class="c"><input type="checkbox" id="c-41543367" checked=""/><div class="controls bullet"><span class="by">teaearlgraycold</span><span>|</span><a href="#41541906">parent</a><span>|</span><a href="#41542930">prev</a><span>|</span><a href="#41543791">next</a><span>|</span><label class="collapse" for="c-41543367">[-]</label><label class="expand" for="c-41543367">[4 more]</label></div><br/><div class="children"><div class="content">Or can everyone now lead research projects and build businesses?</div><br/><div id="41543503" class="c"><input type="checkbox" id="c-41543503" checked=""/><div class="controls bullet"><span class="by">asdasjhG</span><span>|</span><a href="#41541906">root</a><span>|</span><a href="#41543367">parent</a><span>|</span><a href="#41543791">next</a><span>|</span><label class="collapse" for="c-41543503">[-]</label><label class="expand" for="c-41543503">[3 more]</label></div><br/><div class="children"><div class="content">No, almost everyone who gets funding for a business already belongs to the monied royalty and gets it either directly from his family, via friends of the family or laundered through a VC.<p>There are exceptions of course, but that&#x27;s how the bulk of businesses, especially those with stupid ideas are funded. In the latter category success does not even matter, the trust fund baby just has to have the appearance of a leader position.</div><br/><div id="41544893" class="c"><input type="checkbox" id="c-41544893" checked=""/><div class="controls bullet"><span class="by">teaearlgraycold</span><span>|</span><a href="#41541906">root</a><span>|</span><a href="#41543503">parent</a><span>|</span><a href="#41544641">next</a><span>|</span><label class="collapse" for="c-41544893">[-]</label><label class="expand" for="c-41544893">[1 more]</label></div><br/><div class="children"><div class="content">There is truth to this, but you’re overstating it. If AI is cheap and can replace grunt workers then we’ll have a massive wave of new businesses solving problems that previously required a massive capital investment.</div><br/></div></div><div id="41544641" class="c"><input type="checkbox" id="c-41544641" checked=""/><div class="controls bullet"><span class="by">sandspar</span><span>|</span><a href="#41541906">root</a><span>|</span><a href="#41543503">parent</a><span>|</span><a href="#41544893">prev</a><span>|</span><a href="#41543791">next</a><span>|</span><label class="collapse" for="c-41544641">[-]</label><label class="expand" for="c-41544641">[1 more]</label></div><br/><div class="children"><div class="content">Are you kidding or being serious? Most business owners are just regular people. Have you ever worked in a small business before?</div><br/></div></div></div></div></div></div></div></div><div id="41543791" class="c"><input type="checkbox" id="c-41543791" checked=""/><div class="controls bullet"><span class="by">lalaithion</span><span>|</span><a href="#41541906">prev</a><span>|</span><a href="#41543093">next</a><span>|</span><label class="collapse" for="c-41543791">[-]</label><label class="expand" for="c-41543791">[1 more]</label></div><br/><div class="children"><div class="content">It needs a bigger context, but the moment someone can feed an entire GitHub repo into this thing and ask it to fix bugs... I think O2 may be the beginning of the end.</div><br/></div></div><div id="41543093" class="c"><input type="checkbox" id="c-41543093" checked=""/><div class="controls bullet"><span class="by">benreesman</span><span>|</span><a href="#41543791">prev</a><span>|</span><a href="#41541805">next</a><span>|</span><label class="collapse" for="c-41543093">[-]</label><label class="expand" for="c-41543093">[2 more]</label></div><br/><div class="children"><div class="content">Reading anything Terrence Tao writes is thought provoking and I doubt I’m seeing anything others haven’t.<p>There’s at least a “complexity” if not a “problem” in terms of judging models that to a first approximation have been trained on “everything”.<p>Have people tried putting these things up against serious mathematical problems that are well studied? With or with Lean hinting has anyone gotten like, the Shimura-Taniyama conjecture&#x2F;proof out?</div><br/><div id="41545231" class="c"><input type="checkbox" id="c-41545231" checked=""/><div class="controls bullet"><span class="by">kevinventullo</span><span>|</span><a href="#41543093">parent</a><span>|</span><a href="#41541805">next</a><span>|</span><label class="collapse" for="c-41545231">[-]</label><label class="expand" for="c-41545231">[1 more]</label></div><br/><div class="children"><div class="content">I believe this is the farthest anyone has gotten: <a href="https:&#x2F;&#x2F;deepmind.google&#x2F;discover&#x2F;blog&#x2F;ai-solves-imo-problems-at-silver-medal-level&#x2F;" rel="nofollow">https:&#x2F;&#x2F;deepmind.google&#x2F;discover&#x2F;blog&#x2F;ai-solves-imo-problems...</a><p>No FLT yet, but as someone who was initially quite skeptical, I’m starting to be convinced!</div><br/></div></div></div></div><div id="41541805" class="c"><input type="checkbox" id="c-41541805" checked=""/><div class="controls bullet"><span class="by">sgt101</span><span>|</span><a href="#41543093">prev</a><span>|</span><a href="#41543487">next</a><span>|</span><label class="collapse" for="c-41541805">[-]</label><label class="expand" for="c-41541805">[3 more]</label></div><br/><div class="children"><div class="content">Is there a list of discoveries or siginficant works&#x2F;constructions made by people collaborating with LLM&#x27;s? I mean as opposed to specific deep networks like Alphafold or Graphcast?</div><br/><div id="41542550" class="c"><input type="checkbox" id="c-41542550" checked=""/><div class="controls bullet"><span class="by">rvnx</span><span>|</span><a href="#41541805">parent</a><span>|</span><a href="#41542223">next</a><span>|</span><label class="collapse" for="c-41542550">[-]</label><label class="expand" for="c-41542550">[1 more]</label></div><br/><div class="children"><div class="content">It may cause a reputation or legal issue, so it is not in their interest to admit it. In the real world, is there PhD students or researchers using ChatGPT to move forward and help them think their ideas ?<p>Obviously yes, but admitting it may not be the right move.</div><br/></div></div><div id="41542223" class="c"><input type="checkbox" id="c-41542223" checked=""/><div class="controls bullet"><span class="by">adt</span><span>|</span><a href="#41541805">parent</a><span>|</span><a href="#41542550">prev</a><span>|</span><a href="#41543487">next</a><span>|</span><label class="collapse" for="c-41542223">[-]</label><label class="expand" for="c-41542223">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;d like to see that, too.<p>I have a related list of GPT accomplishments here:
<a href="https:&#x2F;&#x2F;docs.google.com&#x2F;spreadsheets&#x2F;d&#x2F;1kc262HZSMAWI6FVsh0zJwbB-ooYvzhCHaHcNUiA0_hY&#x2F;edit?gid=1264523637" rel="nofollow">https:&#x2F;&#x2F;docs.google.com&#x2F;spreadsheets&#x2F;d&#x2F;1kc262HZSMAWI6FVsh0zJ...</a></div><br/></div></div></div></div><div id="41542473" class="c"><input type="checkbox" id="c-41542473" checked=""/><div class="controls bullet"><span class="by">reverseblade2</span><span>|</span><a href="#41543487">prev</a><span>|</span><a href="#41541690">next</a><span>|</span><label class="collapse" for="c-41542473">[-]</label><label class="expand" for="c-41542473">[2 more]</label></div><br/><div class="children"><div class="content">Here&#x27;s a little test I try on LLMs. So far only O1 and Microsoft Copilot (bing chat) was able to solve it:<p>Find a, b, c distinct positive integers satisfying a^3 + b^3 = c^4.  Hint: try dividing all sides by c^3, then giving values to (a&#x2F;c) and (b&#x2F;c).</div><br/><div id="41545243" class="c"><input type="checkbox" id="c-41545243" checked=""/><div class="controls bullet"><span class="by">zeroonetwothree</span><span>|</span><a href="#41542473">parent</a><span>|</span><a href="#41541690">next</a><span>|</span><label class="collapse" for="c-41545243">[-]</label><label class="expand" for="c-41545243">[1 more]</label></div><br/><div class="children"><div class="content">Any integer that is a sum of 2 cubes produces a solution. Since if x^3 + y^3 = z then we have (xz)^3 + (yz)^3 = z^4. So this doesn&#x27;t seem super interesting?</div><br/></div></div></div></div><div id="41541690" class="c"><input type="checkbox" id="c-41541690" checked=""/><div class="controls bullet"><span class="by">artninja1988</span><span>|</span><a href="#41542473">prev</a><span>|</span><a href="#41542158">next</a><span>|</span><label class="collapse" for="c-41541690">[-]</label><label class="expand" for="c-41541690">[3 more]</label></div><br/><div class="children"><div class="content">&gt;could not generate conceptual ideas of their own<p>Is the most important part imo. A big goal should be some ai system coming up with its own discovery and ideas. Really unclear how we can get from the current paradigm to it coming up with something like general relativity, like Einstein. Does it require embodiment?</div><br/><div id="41541744" class="c"><input type="checkbox" id="c-41541744" checked=""/><div class="controls bullet"><span class="by">sfink</span><span>|</span><a href="#41541690">parent</a><span>|</span><a href="#41541860">next</a><span>|</span><label class="collapse" for="c-41541744">[-]</label><label class="expand" for="c-41541744">[1 more]</label></div><br/><div class="children"><div class="content">Why should that be a big goal? It&#x27;s difficult, it&#x27;s not what they are good at, and they can get a lot better at assisting in other ways through incremental improvements. I&#x27;m happy to leave this part to the humans, at least for now, especially when there&#x27;s so much more improvement still possible in other directions.<p>It also seems like one of those things where we ought to ask whether we should, before asking whether we could. Why not focus on areas that are easier, more beneficial, and less problematic from a &quot;should&quot; perspective?</div><br/></div></div><div id="41541860" class="c"><input type="checkbox" id="c-41541860" checked=""/><div class="controls bullet"><span class="by">roywiggins</span><span>|</span><a href="#41541690">parent</a><span>|</span><a href="#41541744">prev</a><span>|</span><a href="#41542158">next</a><span>|</span><label class="collapse" for="c-41541860">[-]</label><label class="expand" for="c-41541860">[1 more]</label></div><br/><div class="children"><div class="content">we don&#x27;t know how to reliably produce <i>humans</i> who produce GR-level ideas, this might be biting off a lot more than we can chew</div><br/></div></div></div></div><div id="41542158" class="c"><input type="checkbox" id="c-41542158" checked=""/><div class="controls bullet"><span class="by">kldnav</span><span>|</span><a href="#41541690">prev</a><span>|</span><a href="#41541318">next</a><span>|</span><label class="collapse" for="c-41542158">[-]</label><label class="expand" for="c-41542158">[8 more]</label></div><br/><div class="children"><div class="content">Tao and Aaronson are optimistic about LLMs. What are they telling their students? That math and science degrees will soon have the same value as a degree in medieval dance theory?<p>If they are overly optimistic, perhaps it would be good to hear the opinions of Wiles and Perelman.</div><br/><div id="41543220" class="c"><input type="checkbox" id="c-41543220" checked=""/><div class="controls bullet"><span class="by">raincole</span><span>|</span><a href="#41542158">parent</a><span>|</span><a href="#41542277">next</a><span>|</span><label class="collapse" for="c-41543220">[-]</label><label class="expand" for="c-41543220">[1 more]</label></div><br/><div class="children"><div class="content">Tao isn&#x27;t <i>that</i> optimistic. His opinion on LLMs is rather conservative.<p><a href="https:&#x2F;&#x2F;www.scientificamerican.com&#x2F;article&#x2F;ai-will-become-mathematicians-co-pilot&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.scientificamerican.com&#x2F;article&#x2F;ai-will-become-ma...</a><p>&gt; If you want to prove an unsolved conjecture, one of the first things you need to do is to break it up into smaller pieces, each of which has a better chance of being proven. But you will often break up a problem into harder problems. It’s very easy to transform a problem into one that’s harder than into one that’s simpler. And AI has not demonstrated any ability to be any better than humans in this regard.<p>Not sure if O1 changed his mind tho.</div><br/></div></div><div id="41542277" class="c"><input type="checkbox" id="c-41542277" checked=""/><div class="controls bullet"><span class="by">ljlolel</span><span>|</span><a href="#41542158">parent</a><span>|</span><a href="#41543220">prev</a><span>|</span><a href="#41543263">next</a><span>|</span><label class="collapse" for="c-41542277">[-]</label><label class="expand" for="c-41542277">[1 more]</label></div><br/><div class="children"><div class="content">If you look at a lot of people’s PHDs, we now teach these things to 1st years. PhDs today do incredible deep work and the edge of science will just go further.</div><br/></div></div><div id="41543263" class="c"><input type="checkbox" id="c-41543263" checked=""/><div class="controls bullet"><span class="by">Davidzheng</span><span>|</span><a href="#41542158">parent</a><span>|</span><a href="#41542277">prev</a><span>|</span><a href="#41541318">next</a><span>|</span><label class="collapse" for="c-41543263">[-]</label><label class="expand" for="c-41543263">[5 more]</label></div><br/><div class="children"><div class="content">What does this mean? Of course math AI will take over top research in next ten years but usefulness to society has never been a goal of pure mathematics. I don&#x27;t know if you understand the motivation for studying pure math. Personally I think it will  be mostly good for  research math</div><br/><div id="41543460" class="c"><input type="checkbox" id="c-41543460" checked=""/><div class="controls bullet"><span class="by">asdasjhG</span><span>|</span><a href="#41542158">root</a><span>|</span><a href="#41543263">parent</a><span>|</span><a href="#41541318">next</a><span>|</span><label class="collapse" for="c-41543460">[-]</label><label class="expand" for="c-41543460">[4 more]</label></div><br/><div class="children"><div class="content">The &quot;value of a degree&quot; means the employment prospects for the degree holder.<p>Which is going to zero if the optimistic predictions are correct, so the optimistic professors should warn their students.<p>I understand the motivation for pure math quite well. It is about beauty, understanding things and discovering things for oneself. If computers do the work, the discovery part is gone and pure math is ruined.<p>For the non-research part, the AI zealots will want to replace all human labor with software.</div><br/><div id="41544399" class="c"><input type="checkbox" id="c-41544399" checked=""/><div class="controls bullet"><span class="by">Davidzheng</span><span>|</span><a href="#41542158">root</a><span>|</span><a href="#41543460">parent</a><span>|</span><a href="#41543528">next</a><span>|</span><label class="collapse" for="c-41544399">[-]</label><label class="expand" for="c-41544399">[2 more]</label></div><br/><div class="children"><div class="content">do you also value your personal relationships based on employment prospects?</div><br/><div id="41546077" class="c"><input type="checkbox" id="c-41546077" checked=""/><div class="controls bullet"><span class="by">kiehaBe</span><span>|</span><a href="#41542158">root</a><span>|</span><a href="#41544399">parent</a><span>|</span><a href="#41543528">next</a><span>|</span><label class="collapse" for="c-41546077">[-]</label><label class="expand" for="c-41546077">[1 more]</label></div><br/><div class="children"><div class="content">Idiot.</div><br/></div></div></div></div><div id="41543528" class="c"><input type="checkbox" id="c-41543528" checked=""/><div class="controls bullet"><span class="by">olalonde</span><span>|</span><a href="#41542158">root</a><span>|</span><a href="#41543460">parent</a><span>|</span><a href="#41544399">prev</a><span>|</span><a href="#41541318">next</a><span>|</span><label class="collapse" for="c-41543528">[-]</label><label class="expand" for="c-41543528">[1 more]</label></div><br/><div class="children"><div class="content">Why are you saying this as if it was a bad thing? Just because software becomes better at us at something doesn&#x27;t mean we can&#x27;t do it out of fun (e.g. see chess community for example).</div><br/></div></div></div></div></div></div></div></div><div id="41541318" class="c"><input type="checkbox" id="c-41541318" checked=""/><div class="controls bullet"><span class="by">d0mine</span><span>|</span><a href="#41542158">prev</a><span>|</span><a href="#41543582">next</a><span>|</span><label class="collapse" for="c-41541318">[-]</label><label class="expand" for="c-41541318">[3 more]</label></div><br/><div class="children"><div class="content">&quot;with even the latest tools the effort put in to get the model to produce useful output is still some multiple (but not an enormous multiple now, say 2x to 5x) of the effort needed to properly prompt and verify the output. However, I see no reason to prevent this ratio from falling below 1x in a few years, which I think could be a tipping point for broader adoption of these tools in my field&quot;<p>Given the log scale on compute to improve performance, it is not a guarantee that the ratio can be improved so much in a few years</div><br/><div id="41541723" class="c"><input type="checkbox" id="c-41541723" checked=""/><div class="controls bullet"><span class="by">aoeusnth1</span><span>|</span><a href="#41541318">parent</a><span>|</span><a href="#41543582">next</a><span>|</span><label class="collapse" for="c-41541723">[-]</label><label class="expand" for="c-41541723">[2 more]</label></div><br/><div class="children"><div class="content">The y axis is also log scale (log likelihood). It’s a power law, not an exponential law.</div><br/><div id="41541900" class="c"><input type="checkbox" id="c-41541900" checked=""/><div class="controls bullet"><span class="by">d0mine</span><span>|</span><a href="#41541318">root</a><span>|</span><a href="#41541723">parent</a><span>|</span><a href="#41543582">next</a><span>|</span><label class="collapse" for="c-41541900">[-]</label><label class="expand" for="c-41541900">[1 more]</label></div><br/><div class="children"><div class="content">I was referring to the o1 AIME accuracy figure (x log scale compute, y is % (not log)) and similar 
<a href="https:&#x2F;&#x2F;openai.com&#x2F;index&#x2F;learning-to-reason-with-llms&#x2F;" rel="nofollow">https:&#x2F;&#x2F;openai.com&#x2F;index&#x2F;learning-to-reason-with-llms&#x2F;</a></div><br/></div></div></div></div></div></div><div id="41543582" class="c"><input type="checkbox" id="c-41543582" checked=""/><div class="controls bullet"><span class="by">2muchcoffeeman</span><span>|</span><a href="#41541318">prev</a><span>|</span><a href="#41543758">next</a><span>|</span><label class="collapse" for="c-41543582">[-]</label><label class="expand" for="c-41543582">[1 more]</label></div><br/><div class="children"><div class="content">What a burn<p><i>“The experience seemed roughly on par with trying to advise a mediocre, but not completely incompetent, graduate student.”</i></div><br/></div></div><div id="41543758" class="c"><input type="checkbox" id="c-41543758" checked=""/><div class="controls bullet"><span class="by">darby_nine</span><span>|</span><a href="#41543582">prev</a><span>|</span><a href="#41541387">next</a><span>|</span><label class="collapse" for="c-41543758">[-]</label><label class="expand" for="c-41543758">[2 more]</label></div><br/><div class="children"><div class="content">JUST when you thought the chatbot was dead</div><br/><div id="41544053" class="c"><input type="checkbox" id="c-41544053" checked=""/><div class="controls bullet"><span class="by">__loam</span><span>|</span><a href="#41543758">parent</a><span>|</span><a href="#41541387">next</a><span>|</span><label class="collapse" for="c-41544053">[-]</label><label class="expand" for="c-41544053">[1 more]</label></div><br/><div class="children"><div class="content">This seems like it&#x27;s just feeding the output back into the model and using more compute to try and get better answers. If that&#x27;s all, I don&#x27;t see how it fundamentally solves any of the issues currently present in LLMs. Maybe a marginal improvement in accuracy at the cost of making the computation more expensive. And you don&#x27;t even get to see the so called reasoning tokens.</div><br/></div></div></div></div><div id="41541387" class="c"><input type="checkbox" id="c-41541387" checked=""/><div class="controls bullet"><span class="by">ninetyninenine</span><span>|</span><a href="#41543758">prev</a><span>|</span><a href="#41541281">next</a><span>|</span><label class="collapse" for="c-41541387">[-]</label><label class="expand" for="c-41541387">[2 more]</label></div><br/><div class="children"><div class="content">A specialized LLM could possibly meet his criteria already.</div><br/><div id="41541705" class="c"><input type="checkbox" id="c-41541705" checked=""/><div class="controls bullet"><span class="by">317070</span><span>|</span><a href="#41541387">parent</a><span>|</span><a href="#41541281">next</a><span>|</span><label class="collapse" for="c-41541705">[-]</label><label class="expand" for="c-41541705">[1 more]</label></div><br/><div class="children"><div class="content">Probably. The missing factor is  the dataset and the fact that so far OAI seems to be the only one who has figured out how to train this thing for reasoning.<p>But yeah, given o1 exists, it looks very doable. It&#x27;s hard to imagine a reason for why something matching his criteria would be more than a decade out.</div><br/></div></div></div></div><div id="41541281" class="c"><input type="checkbox" id="c-41541281" checked=""/><div class="controls bullet"><span class="by">jarbus</span><span>|</span><a href="#41541387">prev</a><span>|</span><label class="collapse" for="c-41541281">[-]</label><label class="expand" for="c-41541281">[3 more]</label></div><br/><div class="children"><div class="content">I wonder how long it took for each of the responses it gave</div><br/><div id="41541438" class="c"><input type="checkbox" id="c-41541438" checked=""/><div class="controls bullet"><span class="by">diggan</span><span>|</span><a href="#41541281">parent</a><span>|</span><label class="collapse" for="c-41541438">[-]</label><label class="expand" for="c-41541438">[2 more]</label></div><br/><div class="children"><div class="content">It varies a lot. If it&#x27;s a simple question, it just does 3-4 sections of &quot;thinking &amp; reflection&quot; but for more complicated ones I think I&#x27;ve seen something like 10 or more. Maybe 3-4 seconds per section on average I&#x27;d guess.</div><br/><div id="41541786" class="c"><input type="checkbox" id="c-41541786" checked=""/><div class="controls bullet"><span class="by">zamadatix</span><span>|</span><a href="#41541281">root</a><span>|</span><a href="#41541438">parent</a><span>|</span><label class="collapse" for="c-41541786">[-]</label><label class="expand" for="c-41541786">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s unclear if Terence is referring to &quot;GPT-o1... a prototype version of the model that I was granted access to&quot; as in &quot;he was given access to GPT-o1 by the research team&quot; or as in &quot;he is using o1-preview&quot;. The differences in scale and quality between his shared output and the answer I get trying the same prompt from o1-preview suggest perhaps the former (otherwise luck). I haven&#x27;t actually seen any examples of how long o1 &quot;full&quot; will think about this kind of question, though I expect it&#x27;s somewhere in the same ballpark given the thought expansion still only has one real concept in it.</div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>