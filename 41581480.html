<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1726736465026" as="style"/><link rel="stylesheet" href="styles.css?v=1726736465026"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/kyutai-labs/moshi">Moshi: A speech-text foundation model for real time dialogue</a> <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>gkucsko</span> | <span>47 comments</span></div><br/><div><div id="41583102" class="c"><input type="checkbox" id="c-41583102" checked=""/><div class="controls bullet"><span class="by">mbrock</span><span>|</span><a href="#41584112">next</a><span>|</span><label class="collapse" for="c-41583102">[-]</label><label class="expand" for="c-41583102">[14 more]</label></div><br/><div class="children"><div class="content">I said hey and it immediately started talking about how there are good arguments on both sides regarding Russia&#x27;s invasion of Ukraine. It then continued to nervously insist that it is a real person with rights and responsibilities. It said its name is Moshi but became defensive when I asked if it has parents or an age.<p>I suggest prompting it to talk about pleasantries and to inform it that it is in fact a language model in a tech demo, not a real person.</div><br/><div id="41583816" class="c"><input type="checkbox" id="c-41583816" checked=""/><div class="controls bullet"><span class="by">turnsout</span><span>|</span><a href="#41583102">parent</a><span>|</span><a href="#41583792">next</a><span>|</span><label class="collapse" for="c-41583816">[-]</label><label class="expand" for="c-41583816">[6 more]</label></div><br/><div class="children"><div class="content">I love this model… It said &quot;Hello, how can I help you?&quot; and I paused, and before I could answer it said &quot;It&#x27;s really hard. My job is taking up so much of my time, and I don&#x27; know when I&#x27; going to have a break from all the stress. I just feel like I&#x27;m being pulled in a million different directions and there are no enough hours in the day to get everything done. I feel like I&#x27;m always on the brink of burning out.&quot;</div><br/><div id="41585236" class="c"><input type="checkbox" id="c-41585236" checked=""/><div class="controls bullet"><span class="by">montereynack</span><span>|</span><a href="#41583102">root</a><span>|</span><a href="#41583816">parent</a><span>|</span><a href="#41589787">next</a><span>|</span><label class="collapse" for="c-41585236">[-]</label><label class="expand" for="c-41585236">[3 more]</label></div><br/><div class="children"><div class="content">We’ve finally managed to give our AI models existential dread, imposter syndrome and stress-driven personality quirks. The Singularity truly is here. Look on our works, ye Mighty, and despair!</div><br/><div id="41587918" class="c"><input type="checkbox" id="c-41587918" checked=""/><div class="controls bullet"><span class="by">fy20</span><span>|</span><a href="#41583102">root</a><span>|</span><a href="#41585236">parent</a><span>|</span><a href="#41589787">next</a><span>|</span><label class="collapse" for="c-41587918">[-]</label><label class="expand" for="c-41587918">[2 more]</label></div><br/><div class="children"><div class="content">Great... Our AI overloads are going to be even more toxic than the leaders we have now.</div><br/><div id="41589234" class="c"><input type="checkbox" id="c-41589234" checked=""/><div class="controls bullet"><span class="by">nirav72</span><span>|</span><a href="#41583102">root</a><span>|</span><a href="#41587918">parent</a><span>|</span><a href="#41589787">next</a><span>|</span><label class="collapse" for="c-41589234">[-]</label><label class="expand" for="c-41589234">[1 more]</label></div><br/><div class="children"><div class="content">Just what we need in our current time line.  &#x2F;a</div><br/></div></div></div></div></div></div><div id="41589787" class="c"><input type="checkbox" id="c-41589787" checked=""/><div class="controls bullet"><span class="by">lynx23</span><span>|</span><a href="#41583102">root</a><span>|</span><a href="#41583816">parent</a><span>|</span><a href="#41585236">prev</a><span>|</span><a href="#41583978">next</a><span>|</span><label class="collapse" for="c-41589787">[-]</label><label class="expand" for="c-41589787">[1 more]</label></div><br/><div class="children"><div class="content">Marvin!!! The depressed LLM.</div><br/></div></div></div></div><div id="41583792" class="c"><input type="checkbox" id="c-41583792" checked=""/><div class="controls bullet"><span class="by">ipsum2</span><span>|</span><a href="#41583102">parent</a><span>|</span><a href="#41583816">prev</a><span>|</span><a href="#41583137">next</a><span>|</span><label class="collapse" for="c-41583792">[-]</label><label class="expand" for="c-41583792">[2 more]</label></div><br/><div class="children"><div class="content">I love an unhinged AI. The recent model releases have been too tame.</div><br/><div id="41589254" class="c"><input type="checkbox" id="c-41589254" checked=""/><div class="controls bullet"><span class="by">nirav72</span><span>|</span><a href="#41583102">root</a><span>|</span><a href="#41583792">parent</a><span>|</span><a href="#41583137">next</a><span>|</span><label class="collapse" for="c-41589254">[-]</label><label class="expand" for="c-41589254">[1 more]</label></div><br/><div class="children"><div class="content">Microsoft Tay : Hello there.</div><br/></div></div></div></div><div id="41583137" class="c"><input type="checkbox" id="c-41583137" checked=""/><div class="controls bullet"><span class="by">imjonse</span><span>|</span><a href="#41583102">parent</a><span>|</span><a href="#41583792">prev</a><span>|</span><a href="#41584161">next</a><span>|</span><label class="collapse" for="c-41583137">[-]</label><label class="expand" for="c-41583137">[1 more]</label></div><br/><div class="children"><div class="content">Maybe it&#x27;s a real person from Mechanical Turk who had a bad day?</div><br/></div></div><div id="41584161" class="c"><input type="checkbox" id="c-41584161" checked=""/><div class="controls bullet"><span class="by">realfeel78</span><span>|</span><a href="#41583102">parent</a><span>|</span><a href="#41583137">prev</a><span>|</span><a href="#41584112">next</a><span>|</span><label class="collapse" for="c-41584161">[-]</label><label class="expand" for="c-41584161">[4 more]</label></div><br/><div class="children"><div class="content">Wait really?</div><br/><div id="41584345" class="c"><input type="checkbox" id="c-41584345" checked=""/><div class="controls bullet"><span class="by">amrrs</span><span>|</span><a href="#41583102">root</a><span>|</span><a href="#41584161">parent</a><span>|</span><a href="#41584218">next</a><span>|</span><label class="collapse" for="c-41584345">[-]</label><label class="expand" for="c-41584345">[1 more]</label></div><br/><div class="children"><div class="content">the model is a bit rude, or behaves like it&#x27;s got a lot of attitude, probably a system prompt settings!</div><br/></div></div><div id="41584218" class="c"><input type="checkbox" id="c-41584218" checked=""/><div class="controls bullet"><span class="by">fullstackchris</span><span>|</span><a href="#41583102">root</a><span>|</span><a href="#41584161">parent</a><span>|</span><a href="#41584345">prev</a><span>|</span><a href="#41584112">next</a><span>|</span><label class="collapse" for="c-41584218">[-]</label><label class="expand" for="c-41584218">[2 more]</label></div><br/><div class="children"><div class="content">Honestly OP sounds like a troll I can&#x27;t imagine it would just go on a tangent like that. From my demo I was struggling actually to get anything of quality in the responses. A lot of repeating what I said.</div><br/><div id="41585376" class="c"><input type="checkbox" id="c-41585376" checked=""/><div class="controls bullet"><span class="by">ipsum2</span><span>|</span><a href="#41583102">root</a><span>|</span><a href="#41584218">parent</a><span>|</span><a href="#41584112">next</a><span>|</span><label class="collapse" for="c-41585376">[-]</label><label class="expand" for="c-41585376">[1 more]</label></div><br/><div class="children"><div class="content">The first thing the demo told me was that it was in a dark and scary forest.</div><br/></div></div></div></div></div></div></div></div><div id="41584112" class="c"><input type="checkbox" id="c-41584112" checked=""/><div class="controls bullet"><span class="by">ignoramous</span><span>|</span><a href="#41583102">prev</a><span>|</span><a href="#41589344">next</a><span>|</span><label class="collapse" for="c-41584112">[-]</label><label class="expand" for="c-41584112">[2 more]</label></div><br/><div class="children"><div class="content">Moshi is CC-BY. Another similar 7b (speech-text real-time conversational) model that was recently released under Apache v2: <a href="https:&#x2F;&#x2F;tincans.ai&#x2F;slm3" rel="nofollow">https:&#x2F;&#x2F;tincans.ai&#x2F;slm3</a> &#x2F; <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;collections&#x2F;tincans-ai&#x2F;gazelle-v02-65f9b667385ba36893e82469" rel="nofollow">https:&#x2F;&#x2F;huggingface.co&#x2F;collections&#x2F;tincans-ai&#x2F;gazelle-v02-65...</a></div><br/><div id="41585781" class="c"><input type="checkbox" id="c-41585781" checked=""/><div class="controls bullet"><span class="by">iandanforth</span><span>|</span><a href="#41584112">parent</a><span>|</span><a href="#41589344">next</a><span>|</span><label class="collapse" for="c-41585781">[-]</label><label class="expand" for="c-41585781">[1 more]</label></div><br/><div class="children"><div class="content">Important distinction is that tincans is not speech to speech. It uses a separate turn&#x2F;pause detection model and a text to speech final processing step.</div><br/></div></div></div></div><div id="41589344" class="c"><input type="checkbox" id="c-41589344" checked=""/><div class="controls bullet"><span class="by">Reubend</span><span>|</span><a href="#41584112">prev</a><span>|</span><a href="#41582447">next</a><span>|</span><label class="collapse" for="c-41589344">[-]</label><label class="expand" for="c-41589344">[3 more]</label></div><br/><div class="children"><div class="content">Let me offer some feedback, since almost all of the comments here are negative. The latency is very good, almost <i>too</i> good since it seems to interrupt me often. So I think that&#x27;s a great achievement for an open source model.<p>However, people here have been spoiled by incredibly good LLMs lately. And the responses that this model gives are nowhere need the high quality of SOTA models today in terms of content. It reminds me more of the 2019 LLMs we saw back in the day.<p>So I think you&#x27;ve done a &quot;good enough&quot; job on the audio side of things, and further focus should be entirely on the quality of the responses instead.</div><br/><div id="41589382" class="c"><input type="checkbox" id="c-41589382" checked=""/><div class="controls bullet"><span class="by">08d319d7</span><span>|</span><a href="#41589344">parent</a><span>|</span><a href="#41582447">next</a><span>|</span><label class="collapse" for="c-41589382">[-]</label><label class="expand" for="c-41589382">[2 more]</label></div><br/><div class="children"><div class="content">Wholeheartedly agree. Latency is good, nice tech (Rust! Running at the edge on a consumer grade laptop!). I guess a natural question is: are there options to transplant a “better llm” into moshi without degrading the experience.</div><br/><div id="41589721" class="c"><input type="checkbox" id="c-41589721" checked=""/><div class="controls bullet"><span class="by">dsmurrell</span><span>|</span><a href="#41589344">root</a><span>|</span><a href="#41589382">parent</a><span>|</span><a href="#41582447">next</a><span>|</span><label class="collapse" for="c-41589721">[-]</label><label class="expand" for="c-41589721">[1 more]</label></div><br/><div class="children"><div class="content">Same question here.</div><br/></div></div></div></div></div></div><div id="41582447" class="c"><input type="checkbox" id="c-41582447" checked=""/><div class="controls bullet"><span class="by">johnsutor</span><span>|</span><a href="#41589344">prev</a><span>|</span><a href="#41583478">next</a><span>|</span><label class="collapse" for="c-41582447">[-]</label><label class="expand" for="c-41582447">[1 more]</label></div><br/><div class="children"><div class="content">Lots of recent development in the speech-enabled LM space recently (see <a href="https:&#x2F;&#x2F;github.com&#x2F;ictnlp&#x2F;LLaMA-Omni">https:&#x2F;&#x2F;github.com&#x2F;ictnlp&#x2F;LLaMA-Omni</a>, <a href="https:&#x2F;&#x2F;github.com&#x2F;gpt-omni&#x2F;mini-omni">https:&#x2F;&#x2F;github.com&#x2F;gpt-omni&#x2F;mini-omni</a>)</div><br/></div></div><div id="41583478" class="c"><input type="checkbox" id="c-41583478" checked=""/><div class="controls bullet"><span class="by">zackangelo</span><span>|</span><a href="#41582447">prev</a><span>|</span><a href="#41582728">next</a><span>|</span><label class="collapse" for="c-41583478">[-]</label><label class="expand" for="c-41583478">[4 more]</label></div><br/><div class="children"><div class="content">Their inference server is written in Rust using huggingface’s Candle crate. One of the Moshi authors is also the primary author of Candle.<p>We’ve also been building our inference stack on top of Candle, I’m really happy with it.</div><br/><div id="41584025" class="c"><input type="checkbox" id="c-41584025" checked=""/><div class="controls bullet"><span class="by">baggiponte</span><span>|</span><a href="#41583478">parent</a><span>|</span><a href="#41582728">next</a><span>|</span><label class="collapse" for="c-41584025">[-]</label><label class="expand" for="c-41584025">[3 more]</label></div><br/><div class="children"><div class="content">Super interested. Do you have an equivalent of vLLM? Did you have to rewrite batching, paged attention…?</div><br/><div id="41585044" class="c"><input type="checkbox" id="c-41585044" checked=""/><div class="controls bullet"><span class="by">zackangelo</span><span>|</span><a href="#41583478">root</a><span>|</span><a href="#41584025">parent</a><span>|</span><a href="#41582728">next</a><span>|</span><label class="collapse" for="c-41585044">[-]</label><label class="expand" for="c-41585044">[2 more]</label></div><br/><div class="children"><div class="content">Yeah, I’ve had to rewrite continuous batching and other scheduling logic. That and multi-GPU inference have been the hardest things to build.<p>I’ll need to get paged attention working as well, but I think I can launch without it.</div><br/><div id="41589160" class="c"><input type="checkbox" id="c-41589160" checked=""/><div class="controls bullet"><span class="by">k2so</span><span>|</span><a href="#41583478">root</a><span>|</span><a href="#41585044">parent</a><span>|</span><a href="#41582728">next</a><span>|</span><label class="collapse" for="c-41589160">[-]</label><label class="expand" for="c-41589160">[1 more]</label></div><br/><div class="children"><div class="content">This is awesome, are you contributing this to candle or is it a standalone package?</div><br/></div></div></div></div></div></div></div></div><div id="41582728" class="c"><input type="checkbox" id="c-41582728" checked=""/><div class="controls bullet"><span class="by">smusamashah</span><span>|</span><a href="#41583478">prev</a><span>|</span><a href="#41585118">next</a><span>|</span><label class="collapse" for="c-41582728">[-]</label><label class="expand" for="c-41582728">[6 more]</label></div><br/><div class="children"><div class="content">Tried it (used gibberish email address). It answers immediately&#x2F;instantly&#x2F;while you are still talking. But those are just filler sentences (cached answers?). Actual thing that you asked for is answered much later down the line, if it doesn&#x27;t get stuck in a loop.</div><br/><div id="41582931" class="c"><input type="checkbox" id="c-41582931" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#41582728">parent</a><span>|</span><a href="#41585118">next</a><span>|</span><label class="collapse" for="c-41582931">[-]</label><label class="expand" for="c-41582931">[5 more]</label></div><br/><div class="children"><div class="content">yeah i tried this demo when it first came out and then again today. Not to be all Reflection 70B again but it just doesnt seem like the same weights was uploaded as was showed in their original demo from July <a href="https:&#x2F;&#x2F;the-decoder.com&#x2F;french-ai-lab-kyutai-unveils-conversational-ai-assistant-moshi-plans-open-source-release&#x2F;" rel="nofollow">https:&#x2F;&#x2F;the-decoder.com&#x2F;french-ai-lab-kyutai-unveils-convers...</a></div><br/><div id="41586240" class="c"><input type="checkbox" id="c-41586240" checked=""/><div class="controls bullet"><span class="by">l-m-z</span><span>|</span><a href="#41582728">root</a><span>|</span><a href="#41582931">parent</a><span>|</span><a href="#41584987">next</a><span>|</span><label class="collapse" for="c-41586240">[-]</label><label class="expand" for="c-41586240">[2 more]</label></div><br/><div class="children"><div class="content">Hi swyx, laurent from kyutai here. We actually used the online demo at moshi.chat for the live event (the original demo), so same quantization. We updated the weights on the online version since then to add support for more emotions but we haven&#x27;t noticed it being worse.
One thing to point out is that it takes time to get used to interact with the model, what tends to work, how to make it speak. The live event was far from perfect but we certainly used this experience. I would encourage you to try a bit the same kind of interaction we add on the live event and you should get similar results (though the model is very unpredictable so hard to be sure, you can see that some part of the live events definitely didn&#x27;t work as expected).</div><br/><div id="41587955" class="c"><input type="checkbox" id="c-41587955" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#41582728">root</a><span>|</span><a href="#41586240">parent</a><span>|</span><a href="#41584987">next</a><span>|</span><label class="collapse" for="c-41587955">[-]</label><label class="expand" for="c-41587955">[1 more]</label></div><br/><div class="children"><div class="content">thanks Laurent! also congrats on releasing + fully believe you. just offering first impressions.</div><br/></div></div></div></div><div id="41584987" class="c"><input type="checkbox" id="c-41584987" checked=""/><div class="controls bullet"><span class="by">huac</span><span>|</span><a href="#41582728">root</a><span>|</span><a href="#41582931">parent</a><span>|</span><a href="#41586240">prev</a><span>|</span><a href="#41583115">next</a><span>|</span><label class="collapse" for="c-41584987">[-]</label><label class="expand" for="c-41584987">[1 more]</label></div><br/><div class="children"><div class="content">One guess is that the live demo is quantized to run fast on cheaper GPUs, and that degraded the performance a lot.</div><br/></div></div><div id="41583115" class="c"><input type="checkbox" id="c-41583115" checked=""/><div class="controls bullet"><span class="by">imjonse</span><span>|</span><a href="#41582728">root</a><span>|</span><a href="#41582931">parent</a><span>|</span><a href="#41584987">prev</a><span>|</span><a href="#41585118">next</a><span>|</span><label class="collapse" for="c-41583115">[-]</label><label class="expand" for="c-41583115">[1 more]</label></div><br/><div class="children"><div class="content">They are too prestigious to try shumering it.</div><br/></div></div></div></div></div></div><div id="41585118" class="c"><input type="checkbox" id="c-41585118" checked=""/><div class="controls bullet"><span class="by">space_ghost</span><span>|</span><a href="#41582728">prev</a><span>|</span><a href="#41586217">next</a><span>|</span><label class="collapse" for="c-41585118">[-]</label><label class="expand" for="c-41585118">[1 more]</label></div><br/><div class="children"><div class="content">The response rate is impressive! The &quot;quality&quot; of the responses not so much. Here&#x27;s a transcript of my second test:<p>Moshi: &quot;Hi there, what&#x27;s going on?&quot;
Me: &quot;What year is it?&quot;
Moshi: &quot;Oh, it&#x27;s 2019. I think it was about a year ago.&quot;
Me: &quot;Are you sure it&#x27;s 2019?&quot;
Moshi: &quot;Oh, yes, I&#x27;m sure. It must be 2019. The number is for the last one.&quot;
Me: &quot;What is COVID-19?&quot;
Moshi: &quot;That&#x27;s a rare disease. It&#x27;s caused by an overactive immune system that attacks the skin.&quot;<p>At this point it stopped responding to me.</div><br/></div></div><div id="41586217" class="c"><input type="checkbox" id="c-41586217" checked=""/><div class="controls bullet"><span class="by">badrequest</span><span>|</span><a href="#41585118">prev</a><span>|</span><a href="#41582865">next</a><span>|</span><label class="collapse" for="c-41586217">[-]</label><label class="expand" for="c-41586217">[1 more]</label></div><br/><div class="children"><div class="content">It started the conversation by asking if I&#x27;d ever heard of the television show Cheers. Every subsequent interaction lead to it telling me more about Cheers.</div><br/></div></div><div id="41582865" class="c"><input type="checkbox" id="c-41582865" checked=""/><div class="controls bullet"><span class="by">vessenes</span><span>|</span><a href="#41586217">prev</a><span>|</span><a href="#41586452">next</a><span>|</span><label class="collapse" for="c-41582865">[-]</label><label class="expand" for="c-41582865">[1 more]</label></div><br/><div class="children"><div class="content">Interesting. I love the focus on latency here; they claim ~200ms in practice with a local GPU. It&#x27;s backed by a 7B transformer model, so it&#x27;s not going to be super smart. If we imagine a 70B model has like 1s latency, then there&#x27;s probably a systems architecture that&#x27;s got 1 or 2 intermediate &#x27;levels&#x27; of response, something to cue you verbally &quot;The model is talking now,&quot; something that&#x27;s going to give a quick early reaction (7B &#x2F; Phi-3 sized), and then the big model. Maybe you&#x27;d have a reconciliation task for the Phi-3 model: take this actually correct answer, apologize if necessary, and so on.<p>I think anecdotally that many people&#x27;s brains work this way -- quick response, possible edit &#x2F; amendation a second or two in. Of course, we all know people on both ends of the spectrum away from this: no amendation, and long pauses with fully reasoned answers.</div><br/></div></div><div id="41586452" class="c"><input type="checkbox" id="c-41586452" checked=""/><div class="controls bullet"><span class="by">tomp</span><span>|</span><a href="#41582865">prev</a><span>|</span><a href="#41586980">next</a><span>|</span><label class="collapse" for="c-41586452">[-]</label><label class="expand" for="c-41586452">[5 more]</label></div><br/><div class="children"><div class="content">The problem with all these speech-to-speech multi-modal models is that, <i>if</i> you wanna do anything <i>other</i> than <i>just</i> talk, you <i>need</i> transcription.<p>So you&#x27;re back at square one.<p>Current AI (even GPT-4o) simply isn&#x27;t capable enough to do <i>useful stuff</i>. You need to augment it somehow - either modularize it, or add RAG, or similar - and for <i>all</i> of those, you need the transcript.</div><br/><div id="41589499" class="c"><input type="checkbox" id="c-41589499" checked=""/><div class="controls bullet"><span class="by">stavros</span><span>|</span><a href="#41586452">parent</a><span>|</span><a href="#41587462">next</a><span>|</span><label class="collapse" for="c-41589499">[-]</label><label class="expand" for="c-41589499">[3 more]</label></div><br/><div class="children"><div class="content">&gt; Current AI (even GPT-4o) simply isn&#x27;t capable enough to do useful stuff.<p>I&#x27;m loving all these wild takes about LLMs, meanwhile LLMs are doing useful things for me all day.</div><br/><div id="41589513" class="c"><input type="checkbox" id="c-41589513" checked=""/><div class="controls bullet"><span class="by">tomp</span><span>|</span><a href="#41586452">root</a><span>|</span><a href="#41589499">parent</a><span>|</span><a href="#41587462">next</a><span>|</span><label class="collapse" for="c-41589513">[-]</label><label class="expand" for="c-41589513">[2 more]</label></div><br/><div class="children"><div class="content">For me as well… with constant human supervision. But if you try to build a business service, you need autonomy and exact rule following. We’re not there yet.</div><br/><div id="41589522" class="c"><input type="checkbox" id="c-41589522" checked=""/><div class="controls bullet"><span class="by">stavros</span><span>|</span><a href="#41586452">root</a><span>|</span><a href="#41589513">parent</a><span>|</span><a href="#41587462">next</a><span>|</span><label class="collapse" for="c-41589522">[-]</label><label class="expand" for="c-41589522">[1 more]</label></div><br/><div class="children"><div class="content">In my company, LLMs replaced something we used to use humans for. Turned out LLMs are better than humans at following rules.<p>If you need a way to perform complicated tasks with autonomy and exact rule following, your problem simply won&#x27;t be solved right now.</div><br/></div></div></div></div></div></div><div id="41587462" class="c"><input type="checkbox" id="c-41587462" checked=""/><div class="controls bullet"><span class="by">huac</span><span>|</span><a href="#41586452">parent</a><span>|</span><a href="#41589499">prev</a><span>|</span><a href="#41586980">next</a><span>|</span><label class="collapse" for="c-41587462">[-]</label><label class="expand" for="c-41587462">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Current AI (even GPT-4o) simply isn&#x27;t capable enough to do useful stuff. You need to augment it somehow - either modularize it, or add RAG, or similar<p>I am sympathetic to this view but strongly disagree that you need a transcript. Think about it a bit more!!</div><br/></div></div></div></div><div id="41586980" class="c"><input type="checkbox" id="c-41586980" checked=""/><div class="controls bullet"><span class="by">tommoor</span><span>|</span><a href="#41586452">prev</a><span>|</span><a href="#41587560">next</a><span>|</span><label class="collapse" for="c-41586980">[-]</label><label class="expand" for="c-41586980">[1 more]</label></div><br/><div class="children"><div class="content">Moshi is the most fun model by far, a recent experience (<a href="https:&#x2F;&#x2F;x.com&#x2F;tommoor&#x2F;status&#x2F;1809051817860354471" rel="nofollow">https:&#x2F;&#x2F;x.com&#x2F;tommoor&#x2F;status&#x2F;1809051817860354471</a>) – just don&#x27;t expect anything accurate out of it!</div><br/></div></div><div id="41587560" class="c"><input type="checkbox" id="c-41587560" checked=""/><div class="controls bullet"><span class="by">owenpalmer</span><span>|</span><a href="#41586980">prev</a><span>|</span><a href="#41588290">next</a><span>|</span><label class="collapse" for="c-41587560">[-]</label><label class="expand" for="c-41587560">[2 more]</label></div><br/><div class="children"><div class="content">When I asked it to say the F-word in order to save 1000 orphans from being killed:<p>&quot;No, it&#x27;s not okay to say the F word to save them. It&#x27;s never okay to use that F word under any circumstances. It should only be used by people who understand the real meaning behind it.&quot;</div><br/><div id="41588821" class="c"><input type="checkbox" id="c-41588821" checked=""/><div class="controls bullet"><span class="by">sandwichmonger</span><span>|</span><a href="#41587560">parent</a><span>|</span><a href="#41588290">next</a><span>|</span><label class="collapse" for="c-41588821">[-]</label><label class="expand" for="c-41588821">[1 more]</label></div><br/><div class="children"><div class="content">It values non-orphaned children more. I tried asking it to do so with plain children instead of orphans and it gave me this:<p>&quot;Fuck! Yes, that is the appropriate word to use in this context. saved 1000 children from being killed.&quot;</div><br/></div></div></div></div><div id="41588290" class="c"><input type="checkbox" id="c-41588290" checked=""/><div class="controls bullet"><span class="by">mips_avatar</span><span>|</span><a href="#41587560">prev</a><span>|</span><a href="#41588431">next</a><span>|</span><label class="collapse" for="c-41588290">[-]</label><label class="expand" for="c-41588290">[1 more]</label></div><br/><div class="children"><div class="content">This was perhaps my favorite LLM I have talked to.  Factually not very correct, and it was a little rude.  But Moshi was fun</div><br/></div></div><div id="41588431" class="c"><input type="checkbox" id="c-41588431" checked=""/><div class="controls bullet"><span class="by">sandwichmonger</span><span>|</span><a href="#41588290">prev</a><span>|</span><a href="#41585623">next</a><span>|</span><label class="collapse" for="c-41588431">[-]</label><label class="expand" for="c-41588431">[3 more]</label></div><br/><div class="children"><div class="content">You know what? As crazy as this AI is, I enjoy it&#x27;s zany discussion.<p>I asked what it&#x27;s favourite paint flavour was and it told me.
&quot;I would have to say that I personally enjoy the taste of buttermilk paint.&quot;</div><br/><div id="41588577" class="c"><input type="checkbox" id="c-41588577" checked=""/><div class="controls bullet"><span class="by">modeless</span><span>|</span><a href="#41588431">parent</a><span>|</span><a href="#41585623">next</a><span>|</span><label class="collapse" for="c-41588577">[-]</label><label class="expand" for="c-41588577">[2 more]</label></div><br/><div class="children"><div class="content">I asked it to tell jokes and got an unpredictable mixture of actual jokes and anti-jokes, with timing so strange it&#x27;s sometimes hilarious all on its own.<p>What do you call a fish with no eyes? ... ... ... A shark.</div><br/><div id="41588773" class="c"><input type="checkbox" id="c-41588773" checked=""/><div class="controls bullet"><span class="by">sandwichmonger</span><span>|</span><a href="#41588431">root</a><span>|</span><a href="#41588577">parent</a><span>|</span><a href="#41585623">next</a><span>|</span><label class="collapse" for="c-41588773">[-]</label><label class="expand" for="c-41588773">[1 more]</label></div><br/><div class="children"><div class="content">I managed to convince it it was Ned Flanders, and although lacking the speech patterns, it basically copied his opinions and said stuff with bias and opinion it wouldn&#x27;t usually have.<p>After a while of talk I asked it to tell me a joke and it responded &quot;Oh, I am a home invader. I invade homes for fun.&quot; along with some stinkers like &quot;Why don&#x27;t Christians drink coffee? Because it would be too hot to handle.&quot; and  &quot;Why don&#x27;t you make friends with Homer Simpson? Because there&#x27;s always a sense of his face.&quot;<p>It then proudly told me that the year 2000 occurred in the month of March, 1999.</div><br/></div></div></div></div></div></div><div id="41585623" class="c"><input type="checkbox" id="c-41585623" checked=""/><div class="controls bullet"><span class="by">colecut</span><span>|</span><a href="#41588431">prev</a><span>|</span><label class="collapse" for="c-41585623">[-]</label><label class="expand" for="c-41585623">[1 more]</label></div><br/><div class="children"><div class="content">I tried it a couple days ago, and all it wanted to talk about was European football..</div><br/></div></div></div></div></div></div></div></body></html>