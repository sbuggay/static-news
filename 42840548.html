<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1738054866593" as="style"/><link rel="stylesheet" href="styles.css?v=1738054866593"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://evanhahn.com/my-failed-attempt-to-shrink-all-npm-packages-by-5-percent/">My failed attempt to shrink all NPM packages by 5%</a> <span class="domain">(<a href="https://evanhahn.com">evanhahn.com</a>)</span></div><div class="subtext"><span>todsacerdoti</span> | <span>154 comments</span></div><br/><div><div id="42840916" class="c"><input type="checkbox" id="c-42840916" checked=""/><div class="controls bullet"><span class="by">sd9</span><span>|</span><a href="#42841364">next</a><span>|</span><label class="collapse" for="c-42840916">[-]</label><label class="expand" for="c-42840916">[59 more]</label></div><br/><div class="children"><div class="content">The final pro&#x2F;cons list: <a href="https:&#x2F;&#x2F;github.com&#x2F;npm&#x2F;rfcs&#x2F;pull&#x2F;595#issuecomment-1200480148">https:&#x2F;&#x2F;github.com&#x2F;npm&#x2F;rfcs&#x2F;pull&#x2F;595#issuecomment-1200480148</a><p>I don&#x27;t find the cons all that compelling to be honest, or at least I think they warrant further discussion to see if there are workarounds (e.g. a choice of compression scheme for a library like typescript, if they would prefer faster publishes).<p>It would have been interesting to see what eventually played out if the author hadn&#x27;t closed the RFC themselves. It could have been the sort of thing that eventually happens after 2 years, but then quietly makes everybody&#x27;s lives better.</div><br/><div id="42841475" class="c"><input type="checkbox" id="c-42841475" checked=""/><div class="controls bullet"><span class="by">jerf</span><span>|</span><a href="#42840916">parent</a><span>|</span><a href="#42843279">next</a><span>|</span><label class="collapse" for="c-42841475">[-]</label><label class="expand" for="c-42841475">[34 more]</label></div><br/><div class="children"><div class="content">&quot;I don&#x27;t find the cons all that compelling to be honest&quot;<p>This is a solid example of how things change at scale. Concerns I wouldn&#x27;t even think about for my personal website become things I need to think about for the download site being hit by 50,000 of my customers become big deals when operating at the scale of npm.<p>You&#x27;ll find those arguments the pointless nitpicking of entrenched interests who just don&#x27;t want to make any changes, until you experience your very own &quot;oh man, I really thought this change was perfectly safe and now my entire customer base is trashed&quot; moment, and then suddenly things like &quot;hey, we need to consider how this affects old signatures and the speed of decompression and just generally whether this is worth the non-zero risks for what are in the end not really that substantial benefits&quot;.<p>I do not say this as the wise Zen guru sitting cross-legged and meditating from a position of being above it all; I say it looking at my own battle scars from the Perfectly Safe things I&#x27;ve pushed out to my customer base, only to discover some tiny little nit caused me trouble. Fortunately I haven&#x27;t caused any true catastrophes, but that&#x27;s as much luck as skill.<p>Attaining the proper balance between moving forward even though it incurs risk and just not changing things that are working is the hardest part of being a software maintainer, because both extremes are definitely bad. Everyone tends to start out in the former situation, but then when they are inevitably bitten it is important not to overcorrect into terrified fear of ever changing anything.</div><br/><div id="42841748" class="c"><input type="checkbox" id="c-42841748" checked=""/><div class="controls bullet"><span class="by">pif</span><span>|</span><a href="#42840916">root</a><span>|</span><a href="#42841475">parent</a><span>|</span><a href="#42841496">next</a><span>|</span><label class="collapse" for="c-42841748">[-]</label><label class="expand" for="c-42841748">[29 more]</label></div><br/><div class="children"><div class="content">&gt; This is a solid example of how things change at scale.<p>5% is 5% at any scale.</div><br/><div id="42842076" class="c"><input type="checkbox" id="c-42842076" checked=""/><div class="controls bullet"><span class="by">michaelmior</span><span>|</span><a href="#42840916">root</a><span>|</span><a href="#42841748">parent</a><span>|</span><a href="#42850181">next</a><span>|</span><label class="collapse" for="c-42842076">[-]</label><label class="expand" for="c-42842076">[7 more]</label></div><br/><div class="children"><div class="content">Yes and no. If I&#x27;m paying $5 a month for storage, I probably don&#x27;t care about saving 5% of my storage costs. If I&#x27;m paying $50,000&#x2F;month in storage costs, 5% savings is a lot more worthwhile to pursue</div><br/><div id="42842239" class="c"><input type="checkbox" id="c-42842239" checked=""/><div class="controls bullet"><span class="by">PaulHoule</span><span>|</span><a href="#42840916">root</a><span>|</span><a href="#42842076">parent</a><span>|</span><a href="#42850181">next</a><span>|</span><label class="collapse" for="c-42842239">[-]</label><label class="expand" for="c-42842239">[6 more]</label></div><br/><div class="children"><div class="content">Doesn&#x27;t npm belong to Microsoft?  It must be hosted in Azure which they own so they must be paying a rock bottom rate for storage, bandwidth, everything.</div><br/><div id="42842448" class="c"><input type="checkbox" id="c-42842448" checked=""/><div class="controls bullet"><span class="by">cwmma</span><span>|</span><a href="#42840916">root</a><span>|</span><a href="#42842239">parent</a><span>|</span><a href="#42850181">next</a><span>|</span><label class="collapse" for="c-42842448">[-]</label><label class="expand" for="c-42842448">[5 more]</label></div><br/><div class="children"><div class="content">It&#x27;s probably less about MS and more about the people downloading the packages</div><br/><div id="42842823" class="c"><input type="checkbox" id="c-42842823" checked=""/><div class="controls bullet"><span class="by">PaulHoule</span><span>|</span><a href="#42840916">root</a><span>|</span><a href="#42842448">parent</a><span>|</span><a href="#42850181">next</a><span>|</span><label class="collapse" for="c-42842823">[-]</label><label class="expand" for="c-42842823">[4 more]</label></div><br/><div class="children"><div class="content">For them it is 5% of something tiny.</div><br/><div id="42844082" class="c"><input type="checkbox" id="c-42844082" checked=""/><div class="controls bullet"><span class="by">imoverclocked</span><span>|</span><a href="#42840916">root</a><span>|</span><a href="#42842823">parent</a><span>|</span><a href="#42848938">next</a><span>|</span><label class="collapse" for="c-42844082">[-]</label><label class="expand" for="c-42844082">[2 more]</label></div><br/><div class="children"><div class="content">Maybe, maybe not. If you are on a bandwidth limited connection and you have a bunch of NPM packages to install, 5% of an hour is a few minutes saved. It&#x27;s likely more than that because long-transfers often need to be restarted.</div><br/><div id="42844254" class="c"><input type="checkbox" id="c-42844254" checked=""/><div class="controls bullet"><span class="by">PaulHoule</span><span>|</span><a href="#42840916">root</a><span>|</span><a href="#42844082">parent</a><span>|</span><a href="#42848938">next</a><span>|</span><label class="collapse" for="c-42844254">[-]</label><label class="expand" for="c-42844254">[1 more]</label></div><br/><div class="children"><div class="content">A properly working cache and download manager that supports resume goes a long way.<p>I could never get Docker to work on my ADSL when it was 2 Mbps (FTTN got it up to 20) though it was fine in the Montreal office which had gigabit.</div><br/></div></div></div></div><div id="42848938" class="c"><input type="checkbox" id="c-42848938" checked=""/><div class="controls bullet"><span class="by">sneak</span><span>|</span><a href="#42840916">root</a><span>|</span><a href="#42842823">parent</a><span>|</span><a href="#42844082">prev</a><span>|</span><a href="#42850181">next</a><span>|</span><label class="collapse" for="c-42848938">[-]</label><label class="expand" for="c-42848938">[1 more]</label></div><br/><div class="children"><div class="content">The amount of modules my docker hosts download from npm is anything but tiny.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="42842196" class="c"><input type="checkbox" id="c-42842196" checked=""/><div class="controls bullet"><span class="by">gregmac</span><span>|</span><a href="#42840916">root</a><span>|</span><a href="#42841748">parent</a><span>|</span><a href="#42850181">prev</a><span>|</span><a href="#42842571">next</a><span>|</span><label class="collapse" for="c-42842196">[-]</label><label class="expand" for="c-42842196">[12 more]</label></div><br/><div class="children"><div class="content">5% off your next lunch and 5% off your next car are very much not the same thing.</div><br/><div id="42843740" class="c"><input type="checkbox" id="c-42843740" checked=""/><div class="controls bullet"><span class="by">JZerf</span><span>|</span><a href="#42840916">root</a><span>|</span><a href="#42842196">parent</a><span>|</span><a href="#42843638">next</a><span>|</span><label class="collapse" for="c-42843740">[-]</label><label class="expand" for="c-42843740">[2 more]</label></div><br/><div class="children"><div class="content">Those lunches could add up to something significant over time. If you&#x27;re paying $10 per lunch for 10 years, that&#x27;s $36,500 which is pretty comparable to the cost of a car.</div><br/><div id="42847162" class="c"><input type="checkbox" id="c-42847162" checked=""/><div class="controls bullet"><span class="by">Julien_r2</span><span>|</span><a href="#42840916">root</a><span>|</span><a href="#42843740">parent</a><span>|</span><a href="#42843638">next</a><span>|</span><label class="collapse" for="c-42847162">[-]</label><label class="expand" for="c-42847162">[1 more]</label></div><br/><div class="children"><div class="content">Which is, then, supporting the fact that scale matter, isn&#x27;t it?<p>Here the scale of time is larger and does make the 5$ significant, while it isn&#x27;t at the scale of a few days.</div><br/></div></div></div></div><div id="42843638" class="c"><input type="checkbox" id="c-42843638" checked=""/><div class="controls bullet"><span class="by">dgfitz</span><span>|</span><a href="#42840916">root</a><span>|</span><a href="#42842196">parent</a><span>|</span><a href="#42843740">prev</a><span>|</span><a href="#42842571">next</a><span>|</span><label class="collapse" for="c-42843638">[-]</label><label class="expand" for="c-42843638">[9 more]</label></div><br/><div class="children"><div class="content">So what, instead of 50k for a car you spend 47.5k?<p>If that moves the needle on your ability to purchase the car, you probably shouldn&#x27;t be buying it.<p>5% is 5%.</div><br/><div id="42844163" class="c"><input type="checkbox" id="c-42844163" checked=""/><div class="controls bullet"><span class="by">kemitche</span><span>|</span><a href="#42840916">root</a><span>|</span><a href="#42843638">parent</a><span>|</span><a href="#42843776">next</a><span>|</span><label class="collapse" for="c-42844163">[-]</label><label class="expand" for="c-42844163">[5 more]</label></div><br/><div class="children"><div class="content">If it takes 1 hour of effort to save 5%:<p>- Doing 1 hour of effort to save 5% on your $20 lunch is foolhardy for most people. $1&#x2F;hr is well below US minimum wage.
- Doing 1 hour of effort to save 5% on your $50k car is wise. $2500&#x2F;hr is well above what most people are making at work.<p>It&#x27;s not about whether the $2500 affects my ability to buy the car. It&#x27;s about whether the time it takes me to save that 5% ends up being worthwhile to me given the actual amount saved.<p>The question is really &quot;given the person-hours it takes to apply the savings, and the real value of the savings, is the savings worth the person-hours spent?&quot;</div><br/><div id="42845233" class="c"><input type="checkbox" id="c-42845233" checked=""/><div class="controls bullet"><span class="by">jay_kyburz</span><span>|</span><a href="#42840916">root</a><span>|</span><a href="#42844163">parent</a><span>|</span><a href="#42843776">next</a><span>|</span><label class="collapse" for="c-42845233">[-]</label><label class="expand" for="c-42845233">[4 more]</label></div><br/><div class="children"><div class="content">This is something we often do in our house. We talk about things in terms of hours worked rather than price. I think more people should do it.</div><br/><div id="42847624" class="c"><input type="checkbox" id="c-42847624" checked=""/><div class="controls bullet"><span class="by">dgfitz</span><span>|</span><a href="#42840916">root</a><span>|</span><a href="#42845233">parent</a><span>|</span><a href="#42843776">next</a><span>|</span><label class="collapse" for="c-42847624">[-]</label><label class="expand" for="c-42847624">[3 more]</label></div><br/><div class="children"><div class="content">By that logic I waste time reading books instead of paying someone else to read them for me.</div><br/><div id="42848083" class="c"><input type="checkbox" id="c-42848083" checked=""/><div class="controls bullet"><span class="by">viceroyalbean</span><span>|</span><a href="#42840916">root</a><span>|</span><a href="#42847624">parent</a><span>|</span><a href="#42848630">next</a><span>|</span><label class="collapse" for="c-42848083">[-]</label><label class="expand" for="c-42848083">[1 more]</label></div><br/><div class="children"><div class="content">If you can get the exact same result for less cost (time and money), why not? Things like enjoyment don&#x27;t factor in since they can&#x27;t be directly converted into money.</div><br/></div></div><div id="42848630" class="c"><input type="checkbox" id="c-42848630" checked=""/><div class="controls bullet"><span class="by">jay_kyburz</span><span>|</span><a href="#42840916">root</a><span>|</span><a href="#42847624">parent</a><span>|</span><a href="#42848083">prev</a><span>|</span><a href="#42843776">next</a><span>|</span><label class="collapse" for="c-42848630">[-]</label><label class="expand" for="c-42848630">[1 more]</label></div><br/><div class="children"><div class="content">Paying somebody else to read the book means you don&#x27;t get the benefit of the book.<p>Also, this is exactly what you company is doing, paying you to &quot;read the book&quot; so they don&#x27;t have to.</div><br/></div></div></div></div></div></div></div></div><div id="42843776" class="c"><input type="checkbox" id="c-42843776" checked=""/><div class="controls bullet"><span class="by">ziddoap</span><span>|</span><a href="#42840916">root</a><span>|</span><a href="#42843638">parent</a><span>|</span><a href="#42844163">prev</a><span>|</span><a href="#42843686">next</a><span>|</span><label class="collapse" for="c-42843776">[-]</label><label class="expand" for="c-42843776">[1 more]</label></div><br/><div class="children"><div class="content">Why do so many people take illustrative examples literally?<p>I&#x27;m sure you can use your imagination to substitute &quot;lunch&quot; and &quot;car&quot; with other examples where the absolute change makes a difference despite the percent change being the same.<p>Even taking it literally... The 5% might not tip the scale of whether or not I <i>can</i> purchase the car, but I&#x27;ll spend a few hours of my time comparing prices at different dealers to save $2500. Most people would consider it dumb if you didn&#x27;t shop around when making a large purchase.<p>On the other hand, I&#x27;m not going to spend a few hours of my time at lunch so that I can save an extra $1 on a meal.</div><br/></div></div><div id="42843686" class="c"><input type="checkbox" id="c-42843686" checked=""/><div class="controls bullet"><span class="by">post-it</span><span>|</span><a href="#42840916">root</a><span>|</span><a href="#42843638">parent</a><span>|</span><a href="#42843776">prev</a><span>|</span><a href="#42842571">next</a><span>|</span><label class="collapse" for="c-42843686">[-]</label><label class="expand" for="c-42843686">[2 more]</label></div><br/><div class="children"><div class="content">I wouldn&#x27;t pick 5¢ up off the ground but I would certainly pick up $2500.</div><br/><div id="42848415" class="c"><input type="checkbox" id="c-42848415" checked=""/><div class="controls bullet"><span class="by">ggm</span><span>|</span><a href="#42840916">root</a><span>|</span><a href="#42843686">parent</a><span>|</span><a href="#42842571">next</a><span>|</span><label class="collapse" for="c-42848415">[-]</label><label class="expand" for="c-42848415">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;d keep 5c. A significant number of people who find sums up around $2500 give it back unconditionally, with no expectation of reward. Whoever lost $2500 is having a really bad day.</div><br/></div></div></div></div></div></div></div></div><div id="42842571" class="c"><input type="checkbox" id="c-42842571" checked=""/><div class="controls bullet"><span class="by">horsawlarway</span><span>|</span><a href="#42840916">root</a><span>|</span><a href="#42841748">parent</a><span>|</span><a href="#42842196">prev</a><span>|</span><a href="#42843705">next</a><span>|</span><label class="collapse" for="c-42842571">[-]</label><label class="expand" for="c-42842571">[5 more]</label></div><br/><div class="children"><div class="content">5% of newly published packages, with a potentially serious degradation to package publish times for those who have to do that step.<p>Given his numbers, let&#x27;s say he saves 100Tb of bandwidth over a year.  At AWS egress pricing... that&#x27;s $5,000 total saved.<p>And arguably - NPM is getting at least some of that savings by adding CPU costs to publishers at package time.<p>Feels like... not enough to warrant a risky ecosystem change to me.</div><br/><div id="42843310" class="c"><input type="checkbox" id="c-42843310" checked=""/><div class="controls bullet"><span class="by">true_religion</span><span>|</span><a href="#42840916">root</a><span>|</span><a href="#42842571">parent</a><span>|</span><a href="#42842982">next</a><span>|</span><label class="collapse" for="c-42843310">[-]</label><label class="expand" for="c-42843310">[3 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;webdev&#x2F;comments&#x2F;1ff3ps5&#x2F;these_5000_npm_packages_consume_45_pb_of_traffic&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;webdev&#x2F;comments&#x2F;1ff3ps5&#x2F;these_5000_...</a><p>NPM uses at least 5 petabytes per week. 5% of that is 250 terabytes.<p>So $15,000 a week, or $780,000 a year in savings could’ve been gained.</div><br/><div id="42846180" class="c"><input type="checkbox" id="c-42846180" checked=""/><div class="controls bullet"><span class="by">canucker2016</span><span>|</span><a href="#42840916">root</a><span>|</span><a href="#42843310">parent</a><span>|</span><a href="#42842982">next</a><span>|</span><label class="collapse" for="c-42846180">[-]</label><label class="expand" for="c-42846180">[2 more]</label></div><br/><div class="children"><div class="content">In a great example of the Pareto Principle (80&#x2F;20), or actually even more extreme, let&#x27;s only apply this Zopfli optimization if the package download total is equal or more than 1GiB (from the Weekly Traffic in GiB column of the Top 5000 Weekly by Traffic tab of the Google Sheets file from the reddit post).<p>For reference, total bandwidth used by all 5000 packages is 4_752_397 GiB.<p>Packages &gt;= 1GiB bandwidth&#x2F;week - That turns out to be 437 packages (there&#x27;s a header row, so it&#x27;s rows 2-438) which uses 4_205_510 GiB.<p>So 88% of the top 5000 bandwidth is consumed by downloading the top 8.7% (437) packages.<p>5% is about 210 TiB.<p>Limiting to the top 100 packages by bandwidth results in 3_217_584 GiB, which is 68% of total bandwidth used by 2% of the total packages.<p>5% is about 161 TiB.</div><br/><div id="42847001" class="c"><input type="checkbox" id="c-42847001" checked=""/><div class="controls bullet"><span class="by">canucker2016</span><span>|</span><a href="#42840916">root</a><span>|</span><a href="#42846180">parent</a><span>|</span><a href="#42842982">next</a><span>|</span><label class="collapse" for="c-42847001">[-]</label><label class="expand" for="c-42847001">[1 more]</label></div><br/><div class="children"><div class="content">Packages with &gt;= 20GiB bandwidth == 47 packages totaling 2,536,902.81 GiB&#x2F;week.<p>Less than 1% of top 5000 packages took 53% of the bandwidth.<p>5% would be about 127 TiB (rounded up).</div><br/></div></div></div></div></div></div><div id="42842982" class="c"><input type="checkbox" id="c-42842982" checked=""/><div class="controls bullet"><span class="by">AlotOfReading</span><span>|</span><a href="#42840916">root</a><span>|</span><a href="#42842571">parent</a><span>|</span><a href="#42843310">prev</a><span>|</span><a href="#42843705">next</a><span>|</span><label class="collapse" for="c-42842982">[-]</label><label class="expand" for="c-42842982">[1 more]</label></div><br/><div class="children"><div class="content">How often are individuals publishing to NPM? Once a day at most, more typically once a week or month? A few dozen seconds of one person&#x27;s day every month isn&#x27;t a terrible trade-off.<p>Even that&#x27;s addressable though if there&#x27;s motivation, since something like transcoding server side during publication just for popular packages would probably get 80% of the benefit with no client-side increase in publication time.</div><br/></div></div></div></div><div id="42843705" class="c"><input type="checkbox" id="c-42843705" checked=""/><div class="controls bullet"><span class="by">syncsynchalt</span><span>|</span><a href="#42840916">root</a><span>|</span><a href="#42841748">parent</a><span>|</span><a href="#42842571">prev</a><span>|</span><a href="#42843565">next</a><span>|</span><label class="collapse" for="c-42843705">[-]</label><label class="expand" for="c-42843705">[1 more]</label></div><br/><div class="children"><div class="content">In some scenarios the equation flips, and the enterprise is looking for _more_ scale.<p>The more bandwidth that Cloudflare needs, the more leverage they have at the peering table. As GitHub&#x27;s largest repo (the @types &#x2F; DefinitelyTyped repo owned by Microsoft) gets larger, the more experience the owner of GitHub (also Microsoft) gets in hosting the world&#x27;s largest git repos.<p>I would say this qualifies as one of those cases, as npmjs is hosted on Azure. The more resources that NPM needs, the more Microsoft can build towards parity with AWS&#x27;s footprint.</div><br/></div></div><div id="42843565" class="c"><input type="checkbox" id="c-42843565" checked=""/><div class="controls bullet"><span class="by">Aicy</span><span>|</span><a href="#42840916">root</a><span>|</span><a href="#42841748">parent</a><span>|</span><a href="#42843705">prev</a><span>|</span><a href="#42842815">next</a><span>|</span><label class="collapse" for="c-42843565">[-]</label><label class="expand" for="c-42843565">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s right, and 5% of a very small number is a very small number. 5% of a very big number is a big number.</div><br/></div></div><div id="42842815" class="c"><input type="checkbox" id="c-42842815" checked=""/><div class="controls bullet"><span class="by">knighthack</span><span>|</span><a href="#42840916">root</a><span>|</span><a href="#42841748">parent</a><span>|</span><a href="#42843565">prev</a><span>|</span><a href="#42841496">next</a><span>|</span><label class="collapse" for="c-42842815">[-]</label><label class="expand" for="c-42842815">[1 more]</label></div><br/><div class="children"><div class="content">Do you even know how absolute numbers work vis-à-vis percentages?</div><br/></div></div></div></div><div id="42841496" class="c"><input type="checkbox" id="c-42841496" checked=""/><div class="controls bullet"><span class="by">sd9</span><span>|</span><a href="#42840916">root</a><span>|</span><a href="#42841475">parent</a><span>|</span><a href="#42841748">prev</a><span>|</span><a href="#42843279">next</a><span>|</span><label class="collapse" for="c-42841496">[-]</label><label class="expand" for="c-42841496">[4 more]</label></div><br/><div class="children"><div class="content">I agree with everything you said, but it doesn’t contradict my point</div><br/><div id="42841579" class="c"><input type="checkbox" id="c-42841579" checked=""/><div class="controls bullet"><span class="by">jerf</span><span>|</span><a href="#42840916">root</a><span>|</span><a href="#42841496">parent</a><span>|</span><a href="#42843279">next</a><span>|</span><label class="collapse" for="c-42841579">[-]</label><label class="expand" for="c-42841579">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;m saying you probably don&#x27;t find them compelling because from your point of view, the problems don&#x27;t look important to you. They don&#x27;t from my point of view either. But my point of view is the wrong point of view. From their point of view this would be plenty to make me think twice and several times over past that from changing something so deeply fundamental to the system for what is a benefit that nobody who is actually paying the price for the package size seems to be particularly enthusiastic about. If the people paying the bandwidth bill aren&#x27;t even that excited about a 5% reduction, then the cost&#x2F;benefits analysis tips over into essentially &quot;zero benefit, non-zero cost&quot;, and that&#x27;s not very compelling.</div><br/><div id="42841846" class="c"><input type="checkbox" id="c-42841846" checked=""/><div class="controls bullet"><span class="by">sd9</span><span>|</span><a href="#42840916">root</a><span>|</span><a href="#42841579">parent</a><span>|</span><a href="#42841720">next</a><span>|</span><label class="collapse" for="c-42841846">[-]</label><label class="expand" for="c-42841846">[1 more]</label></div><br/><div class="children"><div class="content">The problems look important but underexplored</div><br/></div></div><div id="42841720" class="c"><input type="checkbox" id="c-42841720" checked=""/><div class="controls bullet"><span class="by">ffsm8</span><span>|</span><a href="#42840916">root</a><span>|</span><a href="#42841579">parent</a><span>|</span><a href="#42841846">prev</a><span>|</span><a href="#42843279">next</a><span>|</span><label class="collapse" for="c-42841720">[-]</label><label class="expand" for="c-42841720">[1 more]</label></div><br/><div class="children"><div class="content">Or you&#x27;re not understanding how he meant it: there are countless ways to roll out such changes, a hard change is likely a very bad idea as you&#x27;ve correctly pointed out.<p>But it is possible to do it more gradually, I.e. by sneaking it in with a new API that&#x27;s used by new npm version or similar.<p>But it was his choice to make, and it&#x27;s fine that he didn&#x27;t feel enough value in pursuing such a tiny file size change</div><br/></div></div></div></div></div></div></div></div><div id="42843279" class="c"><input type="checkbox" id="c-42843279" checked=""/><div class="controls bullet"><span class="by">advisedwang</span><span>|</span><a href="#42840916">parent</a><span>|</span><a href="#42841475">prev</a><span>|</span><a href="#42841026">next</a><span>|</span><label class="collapse" for="c-42843279">[-]</label><label class="expand" for="c-42843279">[3 more]</label></div><br/><div class="children"><div class="content">The pros aren&#x27;t all that compelling either. The npm repo is the only group that this would really be remotely significant for, and there seemed to be no interest.  So it doesn&#x27;t take much of a con to nix a solution to a non-problem.</div><br/><div id="42843948" class="c"><input type="checkbox" id="c-42843948" checked=""/><div class="controls bullet"><span class="by">ForOldHack</span><span>|</span><a href="#42840916">root</a><span>|</span><a href="#42843279">parent</a><span>|</span><a href="#42841026">next</a><span>|</span><label class="collapse" for="c-42843948">[-]</label><label class="expand" for="c-42843948">[2 more]</label></div><br/><div class="children"><div class="content">Every single download, until the end of time is affected: It speeds up the servers, speeds up the updates, saves disk space on the update servers, and saves on bandwidth costs and usage.<p>Everyone benefits, the only cost is a ultra microscopic time on the front end, and a tiny cost on the client end, and for a very significant number of users, time and money saved. The examples of compression here...</div><br/><div id="42848236" class="c"><input type="checkbox" id="c-42848236" checked=""/><div class="controls bullet"><span class="by">pclmulqdq</span><span>|</span><a href="#42840916">root</a><span>|</span><a href="#42843948">parent</a><span>|</span><a href="#42841026">next</a><span>|</span><label class="collapse" for="c-42848236">[-]</label><label class="expand" for="c-42848236">[1 more]</label></div><br/><div class="children"><div class="content">Plus a few years of a compression expert writing a JS implementation of what was likely some very cursed C. And someone auditing its security. And someone maintaining it.</div><br/></div></div></div></div></div></div><div id="42841026" class="c"><input type="checkbox" id="c-42841026" checked=""/><div class="controls bullet"><span class="by">alt227</span><span>|</span><a href="#42840916">parent</a><span>|</span><a href="#42843279">prev</a><span>|</span><a href="#42841359">next</a><span>|</span><label class="collapse" for="c-42841026">[-]</label><label class="expand" for="c-42841026">[9 more]</label></div><br/><div class="children"><div class="content">I feel massively increasing publish time is a valid reason not to push this though considering such small gains and who the gains apply to.</div><br/><div id="42841277" class="c"><input type="checkbox" id="c-42841277" checked=""/><div class="controls bullet"><span class="by">scott_w</span><span>|</span><a href="#42840916">root</a><span>|</span><a href="#42841026">parent</a><span>|</span><a href="#42841428">next</a><span>|</span><label class="collapse" for="c-42841277">[-]</label><label class="expand" for="c-42841277">[2 more]</label></div><br/><div class="children"><div class="content">I agree, going from 1 second to 2.5 minutes is a huge negative change, in my opinion. I know publishing a package isn&#x27;t something you do 10x a day but it&#x27;s probably a big enough change that, were I doing it, I&#x27;d think the publish process is hanging and keep retrying it.</div><br/><div id="42842269" class="c"><input type="checkbox" id="c-42842269" checked=""/><div class="controls bullet"><span class="by">pletnes</span><span>|</span><a href="#42840916">root</a><span>|</span><a href="#42841277">parent</a><span>|</span><a href="#42841428">next</a><span>|</span><label class="collapse" for="c-42842269">[-]</label><label class="expand" for="c-42842269">[1 more]</label></div><br/><div class="children"><div class="content">If you’re working on the build process itself, you’ll notice it a lot!</div><br/></div></div></div></div><div id="42841428" class="c"><input type="checkbox" id="c-42841428" checked=""/><div class="controls bullet"><span class="by">rererereferred</span><span>|</span><a href="#42840916">root</a><span>|</span><a href="#42841026">parent</a><span>|</span><a href="#42841277">prev</a><span>|</span><a href="#42842051">next</a><span>|</span><label class="collapse" for="c-42841428">[-]</label><label class="expand" for="c-42841428">[1 more]</label></div><br/><div class="children"><div class="content">Since it&#x27;s backwards compatible, individual maintainers could enable it in their own pipeline if they don&#x27;t have issues with the slowdown. It sounds like it could be a single flag in the publish command.</div><br/></div></div><div id="42842051" class="c"><input type="checkbox" id="c-42842051" checked=""/><div class="controls bullet"><span class="by">michaelmior</span><span>|</span><a href="#42840916">root</a><span>|</span><a href="#42841026">parent</a><span>|</span><a href="#42841428">prev</a><span>|</span><a href="#42841359">next</a><span>|</span><label class="collapse" for="c-42842051">[-]</label><label class="expand" for="c-42842051">[5 more]</label></div><br/><div class="children"><div class="content">Probably not worth the added complexity, but in theory, the package could be published immediately with the existing compression and then in the background, replaced with the Zopfli-compressed version.</div><br/><div id="42843974" class="c"><input type="checkbox" id="c-42843974" checked=""/><div class="controls bullet"><span class="by">aja12</span><span>|</span><a href="#42840916">root</a><span>|</span><a href="#42842051">parent</a><span>|</span><a href="#42842136">next</a><span>|</span><label class="collapse" for="c-42843974">[-]</label><label class="expand" for="c-42843974">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Probably not worth the added complexity, but in theory, the package could be published immediately with the existing compression and then in the background, replaced with the Zopfli-compressed version.<p>Checksum matters aside, wouldn&#x27;t that turn the 5% bandwidth savings  into an almost double bandwidth increase though?
IMHO, considering the complexity to even make it a build time option, the author made the right call.</div><br/></div></div><div id="42842136" class="c"><input type="checkbox" id="c-42842136" checked=""/><div class="controls bullet"><span class="by">Null-Set</span><span>|</span><a href="#42840916">root</a><span>|</span><a href="#42842051">parent</a><span>|</span><a href="#42843974">prev</a><span>|</span><a href="#42842200">next</a><span>|</span><label class="collapse" for="c-42842136">[-]</label><label class="expand" for="c-42842136">[2 more]</label></div><br/><div class="children"><div class="content">No, it can&#x27;t because the checksums won&#x27;t match.</div><br/><div id="42843749" class="c"><input type="checkbox" id="c-42843749" checked=""/><div class="controls bullet"><span class="by">michaelmior</span><span>|</span><a href="#42840916">root</a><span>|</span><a href="#42842136">parent</a><span>|</span><a href="#42842200">next</a><span>|</span><label class="collapse" for="c-42843749">[-]</label><label class="expand" for="c-42843749">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think that&#x27;s actually a problem, but it would require continuing to host both versions (at distinct URLs) for any users who may have installed the package before the Zopfli-compressed version completed. Although I think you could also get around this by tracking whether the newly-released package was ever served by the API. If not, which is probably the common case, the old gzip-compressed version could be deleted.</div><br/></div></div></div></div><div id="42842200" class="c"><input type="checkbox" id="c-42842200" checked=""/><div class="controls bullet"><span class="by">hiatus</span><span>|</span><a href="#42840916">root</a><span>|</span><a href="#42842051">parent</a><span>|</span><a href="#42842136">prev</a><span>|</span><a href="#42841359">next</a><span>|</span><label class="collapse" for="c-42842200">[-]</label><label class="expand" for="c-42842200">[1 more]</label></div><br/><div class="children"><div class="content">Wouldn&#x27;t that result in a different checksum for package-lock.json?</div><br/></div></div></div></div></div></div><div id="42841359" class="c"><input type="checkbox" id="c-42841359" checked=""/><div class="controls bullet"><span class="by">macspoofing</span><span>|</span><a href="#42840916">parent</a><span>|</span><a href="#42841026">prev</a><span>|</span><a href="#42840965">next</a><span>|</span><label class="collapse" for="c-42841359">[-]</label><label class="expand" for="c-42841359">[4 more]</label></div><br/><div class="children"><div class="content">&gt; I don&#x27;t find the cons all that compelling to be honest<p>I found it reasonable.<p>The 5% improvement was balanced against the cons of increased cli complexity, lack of native JS zopfli implementation, and slower compression .. and 5% just wasn&#x27;t worth it at the moment - and I agree.<p>&gt;or at least I think they warrant further discussion<p>I think that was the final statement.</div><br/><div id="42841509" class="c"><input type="checkbox" id="c-42841509" checked=""/><div class="controls bullet"><span class="by">sd9</span><span>|</span><a href="#42840916">root</a><span>|</span><a href="#42841359">parent</a><span>|</span><a href="#42840965">next</a><span>|</span><label class="collapse" for="c-42841509">[-]</label><label class="expand" for="c-42841509">[3 more]</label></div><br/><div class="children"><div class="content">Yes, but there’s a difference between “this warrants further discussion” and “this warrants further discussion and I’m closing the RFC”. The latter all but guarantees that no further discussion will take place.</div><br/><div id="42842300" class="c"><input type="checkbox" id="c-42842300" checked=""/><div class="controls bullet"><span class="by">philipwhiuk</span><span>|</span><a href="#42840916">root</a><span>|</span><a href="#42841509">parent</a><span>|</span><a href="#42840965">next</a><span>|</span><label class="collapse" for="c-42842300">[-]</label><label class="expand" for="c-42842300">[2 more]</label></div><br/><div class="children"><div class="content">No it doesn&#x27;t. It only does that if you think discussion around future improvements belongs in RFCs.</div><br/><div id="42843545" class="c"><input type="checkbox" id="c-42843545" checked=""/><div class="controls bullet"><span class="by">mcherm</span><span>|</span><a href="#42840916">root</a><span>|</span><a href="#42842300">parent</a><span>|</span><a href="#42840965">next</a><span>|</span><label class="collapse" for="c-42843545">[-]</label><label class="expand" for="c-42843545">[1 more]</label></div><br/><div class="children"><div class="content">Where DOES it belong, if not there?</div><br/></div></div></div></div></div></div></div></div><div id="42840965" class="c"><input type="checkbox" id="c-42840965" checked=""/><div class="controls bullet"><span class="by">n4r9</span><span>|</span><a href="#42840916">parent</a><span>|</span><a href="#42841359">prev</a><span>|</span><a href="#42848169">next</a><span>|</span><label class="collapse" for="c-42840965">[-]</label><label class="expand" for="c-42840965">[6 more]</label></div><br/><div class="children"><div class="content">I felt the same. The proposal wasn&#x27;t rejected! Also, performance gains go beyond user stories - e.g. they reduce infra costs and environmental impact - so I think the main concerns of the maintainers could have been addressed.</div><br/><div id="42841721" class="c"><input type="checkbox" id="c-42841721" checked=""/><div class="controls bullet"><span class="by">IshKebab</span><span>|</span><a href="#42840916">root</a><span>|</span><a href="#42840965">parent</a><span>|</span><a href="#42848169">next</a><span>|</span><label class="collapse" for="c-42841721">[-]</label><label class="expand" for="c-42841721">[5 more]</label></div><br/><div class="children"><div class="content">&gt; The proposal wasn&#x27;t rejected!<p>They soft-rejected by requiring more validation than was reasonable. I see this all the time. &quot;But did you consider &lt;extremely unlikely issue&gt;? Please go and run more tests.&quot;<p>It&#x27;s pretty clear that the people making the decision didn&#x27;t actually care about the bandwidth savings, otherwise they would have put the work in themselves to do this, e.g. by requiring Zopfli for popular packages. I doubt Microsoft cares if it takes an extra 2 minutes to publish Typescript.<p>Kind of a wild decision considering NPM uses 4.5 PB of traffic per week. 5% of that is 225 TB&#x2F;week, which according to my brief checks costs around $10k&#x2F;week!<p>I guess this is a &quot;not my money&quot; problem fundamentally.</div><br/><div id="42844459" class="c"><input type="checkbox" id="c-42844459" checked=""/><div class="controls bullet"><span class="by">johnfn</span><span>|</span><a href="#42840916">root</a><span>|</span><a href="#42841721">parent</a><span>|</span><a href="#42844834">next</a><span>|</span><label class="collapse" for="c-42844459">[-]</label><label class="expand" for="c-42844459">[1 more]</label></div><br/><div class="children"><div class="content">This doesn&#x27;t seem quite correct to me. They weren&#x27;t asking for &quot;more validation than was reasonable&quot;. They were asking for literally any proof that users would benefit from the proposal. That seems like an entirely reasonable thing to ask before changing the way every single NPM package gets published, ever.<p>I do agree that 10k&#x2F;week is non-negligible. Perhaps that means the people responsible for the 10k weren&#x27;t in the room?</div><br/></div></div><div id="42844834" class="c"><input type="checkbox" id="c-42844834" checked=""/><div class="controls bullet"><span class="by">bombcar</span><span>|</span><a href="#42840916">root</a><span>|</span><a href="#42841721">parent</a><span>|</span><a href="#42844459">prev</a><span>|</span><a href="#42845942">next</a><span>|</span><label class="collapse" for="c-42844834">[-]</label><label class="expand" for="c-42844834">[1 more]</label></div><br/><div class="children"><div class="content">Or another way to look at it is it&#x27;s just (at most!) 5% off an already large bill, and it might cost more than that elsewhere.<p>And I can buy 225 TB of bandwidth for less than $2k, I assume Microsoft can get better than some HN idiot buying Linode.</div><br/></div></div><div id="42845942" class="c"><input type="checkbox" id="c-42845942" checked=""/><div class="controls bullet"><span class="by">arccy</span><span>|</span><a href="#42840916">root</a><span>|</span><a href="#42841721">parent</a><span>|</span><a href="#42844834">prev</a><span>|</span><a href="#42843071">next</a><span>|</span><label class="collapse" for="c-42845942">[-]</label><label class="expand" for="c-42845942">[1 more]</label></div><br/><div class="children"><div class="content">massively increase the open source github actions bill for runners running longer (compute is generally more expensive) to publish for a small decrease in network traffic (bandwidth is cheap at scale)?</div><br/></div></div><div id="42843071" class="c"><input type="checkbox" id="c-42843071" checked=""/><div class="controls bullet"><span class="by">lyu07282</span><span>|</span><a href="#42840916">root</a><span>|</span><a href="#42841721">parent</a><span>|</span><a href="#42845942">prev</a><span>|</span><a href="#42848169">next</a><span>|</span><label class="collapse" for="c-42843071">[-]</label><label class="expand" for="c-42843071">[1 more]</label></div><br/><div class="children"><div class="content">&gt; which according to my brief checks costs around $10k&#x2F;week<p>That&#x27;s the market price though, for Microsoft its a tiny fraction of that.</div><br/></div></div></div></div></div></div><div id="42848169" class="c"><input type="checkbox" id="c-42848169" checked=""/><div class="controls bullet"><span class="by">mootothemax</span><span>|</span><a href="#42840916">parent</a><span>|</span><a href="#42840965">prev</a><span>|</span><a href="#42841024">next</a><span>|</span><label class="collapse" for="c-42848169">[-]</label><label class="expand" for="c-42848169">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I don&#x27;t find the cons all that compelling to be honest, or at least I think they warrant further discussion<p>It needs a novel JS port of a C compresison library, which will be wired into a heavily-used and public-facing toolchain, and is something that will ruin a significant number of peoples&#x27; days if it breaks.<p>For me, that kind of ask needs a compelling use case from the start.</div><br/></div></div></div></div><div id="42841364" class="c"><input type="checkbox" id="c-42841364" checked=""/><div class="controls bullet"><span class="by">cedws</span><span>|</span><a href="#42840916">prev</a><span>|</span><a href="#42841063">next</a><span>|</span><label class="collapse" for="c-42841364">[-]</label><label class="expand" for="c-42841364">[17 more]</label></div><br/><div class="children"><div class="content">Last I checked npm packages were full of garbage including non-source code. There&#x27;s no reason for node_modules to be as big as it usually is, text compresses extremely well. It&#x27;s just general sloppiness endemic to the JavaScript ecosystem.</div><br/><div id="42843741" class="c"><input type="checkbox" id="c-42843741" checked=""/><div class="controls bullet"><span class="by">eitau_1</span><span>|</span><a href="#42841364">parent</a><span>|</span><a href="#42841819">next</a><span>|</span><label class="collapse" for="c-42843741">[-]</label><label class="expand" for="c-42843741">[4 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not even funny:<p><pre><code>  $ ll &#x2F;nix&#x2F;store&#x2F;*-insect-5.9.0&#x2F;lib&#x2F;node_modules&#x2F;insect&#x2F;node_modules&#x2F;clipboardy&#x2F;fallbacks&#x2F;*
  &#x2F;nix&#x2F;store&#x2F;…-insect-5.9.0&#x2F;lib&#x2F;node_modules&#x2F;insect&#x2F;node_modules&#x2F;clipboardy&#x2F;fallbacks&#x2F;linux:
  .r-xr-xr-x 129k root  1 Jan  1970 xsel

  &#x2F;nix&#x2F;store&#x2F;…-insect-5.9.0&#x2F;lib&#x2F;node_modules&#x2F;insect&#x2F;node_modules&#x2F;clipboardy&#x2F;fallbacks&#x2F;windows:
  .r-xr-xr-x 444k root  1 Jan  1970 clipboard_i686.exe
  .r-xr-xr-x 331k root  1 Jan  1970 clipboard_x86_64.exe
</code></pre>
(clipboardy ships executables and none of them can be run on NixOS btw)</div><br/><div id="42846726" class="c"><input type="checkbox" id="c-42846726" checked=""/><div class="controls bullet"><span class="by">dicytea</span><span>|</span><a href="#42841364">root</a><span>|</span><a href="#42843741">parent</a><span>|</span><a href="#42845563">next</a><span>|</span><label class="collapse" for="c-42846726">[-]</label><label class="expand" for="c-42846726">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t know why, but clipboard libraries tend to be really poorly implemented, especially in scripting languages.<p>I just checked out clipboardy and all they do is dispatch binaries from the path and hope it&#x27;s the right one (or if it&#x27;s even there at all). I think I had a similar experience with Python and Lua scripts. There&#x27;s an unfunny amount of poorly-written one-off clipboard scripts out there just waiting to be exploited.<p>I&#x27;m only glad that the go-to clipboard library in Rust (arboard) seems solid.</div><br/></div></div><div id="42845563" class="c"><input type="checkbox" id="c-42845563" checked=""/><div class="controls bullet"><span class="by">cedws</span><span>|</span><a href="#42841364">root</a><span>|</span><a href="#42843741">parent</a><span>|</span><a href="#42846726">prev</a><span>|</span><a href="#42841819">next</a><span>|</span><label class="collapse" for="c-42845563">[-]</label><label class="expand" for="c-42845563">[2 more]</label></div><br/><div class="children"><div class="content">Are they reproducible? Shipping binaries in JS packages is dodgy AF - a Jia Tan attack waiting to happen.</div><br/><div id="42845649" class="c"><input type="checkbox" id="c-42845649" checked=""/><div class="controls bullet"><span class="by">eitau_1</span><span>|</span><a href="#42841364">root</a><span>|</span><a href="#42845563">parent</a><span>|</span><a href="#42841819">next</a><span>|</span><label class="collapse" for="c-42845649">[-]</label><label class="expand" for="c-42845649">[1 more]</label></div><br/><div class="children"><div class="content">The executables are vendored in the repo [0].<p>[0] <a href="https:&#x2F;&#x2F;github.com&#x2F;sindresorhus&#x2F;clipboardy&#x2F;tree&#x2F;main&#x2F;fallbacks">https:&#x2F;&#x2F;github.com&#x2F;sindresorhus&#x2F;clipboardy&#x2F;tree&#x2F;main&#x2F;fallbac...</a></div><br/></div></div></div></div></div></div><div id="42841819" class="c"><input type="checkbox" id="c-42841819" checked=""/><div class="controls bullet"><span class="by">vinnymac</span><span>|</span><a href="#42841364">parent</a><span>|</span><a href="#42843741">prev</a><span>|</span><a href="#42841408">next</a><span>|</span><label class="collapse" for="c-42841819">[-]</label><label class="expand" for="c-42841819">[2 more]</label></div><br/><div class="children"><div class="content">You might be interested in e18e if you would like to see that change: <a href="https:&#x2F;&#x2F;e18e.dev&#x2F;" rel="nofollow">https:&#x2F;&#x2F;e18e.dev&#x2F;</a><p>They’ve done a lot of great work already.</div><br/><div id="42842282" class="c"><input type="checkbox" id="c-42842282" checked=""/><div class="controls bullet"><span class="by">KTibow</span><span>|</span><a href="#42841364">root</a><span>|</span><a href="#42841819">parent</a><span>|</span><a href="#42841408">next</a><span>|</span><label class="collapse" for="c-42842282">[-]</label><label class="expand" for="c-42842282">[1 more]</label></div><br/><div class="children"><div class="content">Does this replace ljharb stuff?</div><br/></div></div></div></div><div id="42841408" class="c"><input type="checkbox" id="c-42841408" checked=""/><div class="controls bullet"><span class="by">MortyWaves</span><span>|</span><a href="#42841364">parent</a><span>|</span><a href="#42841819">prev</a><span>|</span><a href="#42845565">next</a><span>|</span><label class="collapse" for="c-42841408">[-]</label><label class="expand" for="c-42841408">[1 more]</label></div><br/><div class="children"><div class="content">Totally agree with you. I wish npm did a better job of filtering the crap files out of packages.</div><br/></div></div><div id="42845565" class="c"><input type="checkbox" id="c-42845565" checked=""/><div class="controls bullet"><span class="by">hombre_fatal</span><span>|</span><a href="#42841364">parent</a><span>|</span><a href="#42841408">prev</a><span>|</span><a href="#42841658">next</a><span>|</span><label class="collapse" for="c-42845565">[-]</label><label class="expand" for="c-42845565">[1 more]</label></div><br/><div class="children"><div class="content">One of the things I like about node_modules is that it&#x27;s not purely source code and it&#x27;s not purely build artifacts.<p>You can read the code and you can usually read the actual README&#x2F;docs&#x2F;tests of the package instead of having to find it online. And you can usually edit library code for debugging purposes.<p>If node_modules is taking up a lot of space across a bunch of old projects, just write the `find` script that recursively deletes them all; You can always run `npm install` in the future when you need to work on that project again.</div><br/></div></div><div id="42841658" class="c"><input type="checkbox" id="c-42841658" checked=""/><div class="controls bullet"><span class="by">Alifatisk</span><span>|</span><a href="#42841364">parent</a><span>|</span><a href="#42845565">prev</a><span>|</span><a href="#42843407">next</a><span>|</span><label class="collapse" for="c-42841658">[-]</label><label class="expand" for="c-42841658">[5 more]</label></div><br/><div class="children"><div class="content">At least, switch to pnpm minimize the bloat</div><br/><div id="42848754" class="c"><input type="checkbox" id="c-42848754" checked=""/><div class="controls bullet"><span class="by">MBCook</span><span>|</span><a href="#42841364">root</a><span>|</span><a href="#42841658">parent</a><span>|</span><a href="#42842255">next</a><span>|</span><label class="collapse" for="c-42848754">[-]</label><label class="expand" for="c-42848754">[1 more]</label></div><br/><div class="children"><div class="content">As someone who mostly works in Java it continues to floor me that this isn’t the default. Why does every project I work on need an identical copy of possibly hundreds of packages if they’re the same version?<p>I also like Yarn pnp’s model of leaving node_modules as zip files. CPUs are way faster than storage, they can decompress on the fly. Less disk space at rest, less disk slack, less filesystem bookkeeping.<p>Every single filesystem is way faster at dealing with one file than dozens&#x2F;hundreds. Now multiply that by the the hundreds if does, it add up.</div><br/></div></div><div id="42842255" class="c"><input type="checkbox" id="c-42842255" checked=""/><div class="controls bullet"><span class="by">jefozabuss</span><span>|</span><a href="#42841364">root</a><span>|</span><a href="#42841658">parent</a><span>|</span><a href="#42848754">prev</a><span>|</span><a href="#42843407">next</a><span>|</span><label class="collapse" for="c-42842255">[-]</label><label class="expand" for="c-42842255">[3 more]</label></div><br/><div class="children"><div class="content">I just installed a project with pnpm about 120 packages mostly react&#x2F;webpack&#x2F;eslint&#x2F;redux related<p>with prod env: 700MB<p>without prod env: 900MB<p>sadly the bloat cannot be avoided that well :&#x2F;</div><br/><div id="42843722" class="c"><input type="checkbox" id="c-42843722" checked=""/><div class="controls bullet"><span class="by">jeffhuys</span><span>|</span><a href="#42841364">root</a><span>|</span><a href="#42842255">parent</a><span>|</span><a href="#42843407">next</a><span>|</span><label class="collapse" for="c-42843722">[-]</label><label class="expand" for="c-42843722">[2 more]</label></div><br/><div class="children"><div class="content">pnpm stores them in a central place and symlinks them. You’ll see the benefits when you have multiple projects with a lot of the same packages.</div><br/><div id="42843761" class="c"><input type="checkbox" id="c-42843761" checked=""/><div class="controls bullet"><span class="by">syncsynchalt</span><span>|</span><a href="#42841364">root</a><span>|</span><a href="#42843722">parent</a><span>|</span><a href="#42843407">next</a><span>|</span><label class="collapse" for="c-42843761">[-]</label><label class="expand" for="c-42843761">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;ll also see the benefit when `rm -rf`ing a `node_modules` and re-installing, as pnpm still has a local copy that it can re-link after validating its integrity.</div><br/></div></div></div></div></div></div></div></div><div id="42843407" class="c"><input type="checkbox" id="c-42843407" checked=""/><div class="controls bullet"><span class="by">TheRealPomax</span><span>|</span><a href="#42841364">parent</a><span>|</span><a href="#42841658">prev</a><span>|</span><a href="#42842811">next</a><span>|</span><label class="collapse" for="c-42843407">[-]</label><label class="expand" for="c-42843407">[2 more]</label></div><br/><div class="children"><div class="content">That&#x27;s on the package publishers, not NPM. They give you an `.npmignore` that&#x27;s trivially filled out to ensure your package isn&#x27;t full of garbage, so if someone doesn&#x27;t bother using that: that&#x27;s on them, not NPM.<p>(And it&#x27;s also a little on the folks who install dependencies: if the cruft in a specific library bothers you, hit up the repo and file an issue (or even MR&#x2F;PR) to get that .npmignore file filled out. I&#x27;ve helped folks reduce their packages by 50+MB in some cases, it&#x27;s worth your own time as much as it is theirs)</div><br/><div id="42847663" class="c"><input type="checkbox" id="c-42847663" checked=""/><div class="controls bullet"><span class="by">silverwind</span><span>|</span><a href="#42841364">root</a><span>|</span><a href="#42843407">parent</a><span>|</span><a href="#42842811">next</a><span>|</span><label class="collapse" for="c-42847663">[-]</label><label class="expand" for="c-42847663">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s much better to allowlist the files meant to be published using `files` in package.json because you never know what garbage the user has in their folder at the time of publish.<p>On a typical project with a build step, only a `dist` folder would published.</div><br/></div></div></div></div><div id="42842811" class="c"><input type="checkbox" id="c-42842811" checked=""/><div class="controls bullet"><span class="by">hinkley</span><span>|</span><a href="#42841364">parent</a><span>|</span><a href="#42843407">prev</a><span>|</span><a href="#42841063">next</a><span>|</span><label class="collapse" for="c-42842811">[-]</label><label class="expand" for="c-42842811">[1 more]</label></div><br/><div class="children"><div class="content">I believe I knocked 10% off of our node_modules directory by filing .npmignore PRs or bug reports to tools we used.<p>Now if rxjs weren’t a dumpster fire…</div><br/></div></div></div></div><div id="42841063" class="c"><input type="checkbox" id="c-42841063" checked=""/><div class="controls bullet"><span class="by">fergie</span><span>|</span><a href="#42841364">prev</a><span>|</span><a href="#42850055">next</a><span>|</span><label class="collapse" for="c-42841063">[-]</label><label class="expand" for="c-42841063">[4 more]</label></div><br/><div class="children"><div class="content">Props to anyone who tries to make the world a better place.<p>Its not always obvious who has the most important use cases. In the case of NPM they are prioritizing the user experience of module authors. I totally see how this change would be great for module consumers, yet create potentially massive inconvenience for module authors.<p>Interesting write-up</div><br/><div id="42841248" class="c"><input type="checkbox" id="c-42841248" checked=""/><div class="controls bullet"><span class="by">atiedebee</span><span>|</span><a href="#42841063">parent</a><span>|</span><a href="#42850055">next</a><span>|</span><label class="collapse" for="c-42841248">[-]</label><label class="expand" for="c-42841248">[3 more]</label></div><br/><div class="children"><div class="content">I think &quot;massive&quot; is overstating it. I don&#x27;t think deploying a new version of a package is something that happens many times a day, so it wouldn&#x27;t be a constant pain point.<p>Also, since this is a case of having something compressed once and decompressed potentially thousands of times, it seems like the perfect tool for the job.</div><br/><div id="42842324" class="c"><input type="checkbox" id="c-42842324" checked=""/><div class="controls bullet"><span class="by">philipwhiuk</span><span>|</span><a href="#42841063">root</a><span>|</span><a href="#42841248">parent</a><span>|</span><a href="#42850055">next</a><span>|</span><label class="collapse" for="c-42842324">[-]</label><label class="expand" for="c-42842324">[2 more]</label></div><br/><div class="children"><div class="content">Every build in a CI system would probably create the package.<p>This is changing every build in every CI system to make it slower.</div><br/><div id="42846440" class="c"><input type="checkbox" id="c-42846440" checked=""/><div class="controls bullet"><span class="by">mkesper</span><span>|</span><a href="#42841063">root</a><span>|</span><a href="#42842324">parent</a><span>|</span><a href="#42850055">next</a><span>|</span><label class="collapse" for="c-42846440">[-]</label><label class="expand" for="c-42846440">[1 more]</label></div><br/><div class="children"><div class="content">Just use it on the release build.</div><br/></div></div></div></div></div></div></div></div><div id="42850055" class="c"><input type="checkbox" id="c-42850055" checked=""/><div class="controls bullet"><span class="by">kavenkanum</span><span>|</span><a href="#42841063">prev</a><span>|</span><a href="#42841722">next</a><span>|</span><label class="collapse" for="c-42850055">[-]</label><label class="expand" for="c-42850055">[1 more]</label></div><br/><div class="children"><div class="content">If OP wanted to shrink nom packages then npm could introduce two types of npm package - the build package and source one. This way a lot of packages would be smaller, because package code could be safely distributed through a separate package and not kept in the build package. There are a lot npm packages that explicitly include whole git repo in the package and they do so because there&#x27;s only one type of package they can use</div><br/></div></div><div id="42841722" class="c"><input type="checkbox" id="c-42841722" checked=""/><div class="controls bullet"><span class="by">abound</span><span>|</span><a href="#42850055">prev</a><span>|</span><a href="#42841728">next</a><span>|</span><label class="collapse" for="c-42841722">[-]</label><label class="expand" for="c-42841722">[4 more]</label></div><br/><div class="children"><div class="content">A few people have mentioned the environmental angle, but I&#x27;d care more about if&#x2F;how much this slows down decompression on the client. Compressing React 20x slower once is one thing, but 50 million decompressions being even 1% slower is likely net more energy intensive, even accounting for the saved energy transmitting 4-5% fewer bits on the wire.</div><br/><div id="42849322" class="c"><input type="checkbox" id="c-42849322" checked=""/><div class="controls bullet"><span class="by">DannyBee</span><span>|</span><a href="#42841722">parent</a><span>|</span><a href="#42842007">next</a><span>|</span><label class="collapse" for="c-42849322">[-]</label><label class="expand" for="c-42849322">[1 more]</label></div><br/><div class="children"><div class="content">I can speak to this - there is no meaningful decompression effect across an insane set of tested data at Google and elsewhere.  Zopfli was invented prior to brotli<p>Zopfli is easiest to think of as something that just tries harder than gzip to find matches and better encodings.
Much harder.<p>decompression speed is linear either way.<p>It&#x27;s easiest to think of decompression as a linear time vm executor[1], where the bytecoded instructions are basically<p>go back &lt;distance&gt; bytes, output the next &lt;length&gt; bytes you see, then output character &lt;c&gt;<p>(outputting literal data is the instruction &lt;0,0,{character to output}&gt;)<p>Assuming you did not output a file larger than the original uncompressed file (why would you bother?), you will, worst case, process N bytes during decompression, where N is the size of the original input file.<p>The practical decompression speed is driven by cache behavior, but it thrashes the cache no matter what.<p>In practice, reduction of size vs gzip occurs by either finding larger runs, or encodings that are smaller than the existing ones.<p>After all, if you want the compressed file to shrink, you need output less instructions somehow, or make more of the instructions identical (so they can be represented in less bits by later huffman coding).<p>In practice, this has almost exclusively positive effects on decompression speed - either the vm has less things to process (which is faster), or more of the things it does look the same (which has better cache behavior).<p>[1] this is one way archive formats will sometimes choose to deal with multiple compression method support -  encode them all to the same kind of bytecode (usually some form of copy + literal instruction set), and then decoding is the same for all of them.   ~all compression algorithms output some bytecode like the above on their own already, so it&#x27;s not a lot of work.
This doesn&#x27;t help you support <i>other archive formats</i>, but if you want to have a bunch of per-file compression options that you pick from based on what works best, this enables you to still only have to have one decoder.</div><br/></div></div><div id="42842007" class="c"><input type="checkbox" id="c-42842007" checked=""/><div class="controls bullet"><span class="by">web007</span><span>|</span><a href="#42841722">parent</a><span>|</span><a href="#42849322">prev</a><span>|</span><a href="#42842113">next</a><span>|</span><label class="collapse" for="c-42842007">[-]</label><label class="expand" for="c-42842007">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s very likely zero or positive impact on the decompression side of things.<p>Starting with smaller data means everything ends up smaller. It&#x27;s the same decompression algorithm in all cases, so it&#x27;s not some special &#x2F; unoptimized branch of code. It&#x27;s yielding the same data in the end, so writes equal out plus or minus disk queue fullness and power cycles. It&#x27;s _maybe_ better for RAM and CPU because more data fits in cache, so less memory is used and the compute is idle less often.<p>It&#x27;s relatively easy to test decompression efficiency if you think CPU time is a good proxy for energy usage: go find something like React and test the decomp time of gzip -9 vs zopfli. Or even better, find something similar but much bigger so you can see the delta and it&#x27;s not lost in rounding errors.</div><br/></div></div><div id="42842113" class="c"><input type="checkbox" id="c-42842113" checked=""/><div class="controls bullet"><span class="by">sltkr</span><span>|</span><a href="#42841722">parent</a><span>|</span><a href="#42842007">prev</a><span>|</span><a href="#42841728">next</a><span>|</span><label class="collapse" for="c-42842113">[-]</label><label class="expand" for="c-42842113">[1 more]</label></div><br/><div class="children"><div class="content">For formats like deflate, decompression time doesn&#x27;t generally depend on compressed size. (zstd is similar, though memory use can depend on the compression level used).<p>This means an optimization like this is virtually guaranteed to be a net positive on the receiving end, since you always save a bit of time&#x2F;energy when downloading a smaller compressed file.</div><br/></div></div></div></div><div id="42841728" class="c"><input type="checkbox" id="c-42841728" checked=""/><div class="controls bullet"><span class="by">adgjlsfhk1</span><span>|</span><a href="#42841722">prev</a><span>|</span><a href="#42842218">next</a><span>|</span><label class="collapse" for="c-42841728">[-]</label><label class="expand" for="c-42841728">[4 more]</label></div><br/><div class="children"><div class="content">This seems like a place where the more ambitious version that switches to ZSTD might have better tradeoffs. You would get similar or better compression, with faster decompression and recompression than zstd.It would lose backward compatibility though...</div><br/><div id="42843339" class="c"><input type="checkbox" id="c-42843339" checked=""/><div class="controls bullet"><span class="by">vlovich123</span><span>|</span><a href="#42841728">parent</a><span>|</span><a href="#42841821">next</a><span>|</span><label class="collapse" for="c-42843339">[-]</label><label class="expand" for="c-42843339">[1 more]</label></div><br/><div class="children"><div class="content">Not necessarily - could retain backward compat by publishing both gzip and zstd variants and having downloaders with newer npm’s prefer to download zstd. Over time, you could require packages only upload zstd going forward and either generate zstd versions of the backlog of unmaintained packages or at least those that see some amount of traffic over some time period if you’re willing to drop very old packages. The ability to install arbitrary versions of packages probably means you’re probably better off reprocessing the backlog although that may cost more than doing nothing.<p>The package lock checksum is probably a more solvable issue with some coordination.<p>The benefit of doing this though is less immediate - it will take a few years to show payoff and these kinds of payoffs are not typically made by the kind of committee decisions process described (for better or worse).</div><br/></div></div><div id="42841821" class="c"><input type="checkbox" id="c-42841821" checked=""/><div class="controls bullet"><span class="by">bufferoverflow</span><span>|</span><a href="#42841728">parent</a><span>|</span><a href="#42843339">prev</a><span>|</span><a href="#42848785">next</a><span>|</span><label class="collapse" for="c-42841821">[-]</label><label class="expand" for="c-42841821">[1 more]</label></div><br/><div class="children"><div class="content">Brotli and lzo1b have good compression ratios and pretty fast decompression speeds. Compression speed should not matter that much, since you only do it once.<p><a href="https:&#x2F;&#x2F;quixdb.github.io&#x2F;squash-benchmark&#x2F;" rel="nofollow">https:&#x2F;&#x2F;quixdb.github.io&#x2F;squash-benchmark&#x2F;</a><p>There even more obscure options:<p><a href="https:&#x2F;&#x2F;www.mattmahoney.net&#x2F;dc&#x2F;text.html" rel="nofollow">https:&#x2F;&#x2F;www.mattmahoney.net&#x2F;dc&#x2F;text.html</a></div><br/></div></div><div id="42848785" class="c"><input type="checkbox" id="c-42848785" checked=""/><div class="controls bullet"><span class="by">MBCook</span><span>|</span><a href="#42841728">parent</a><span>|</span><a href="#42841821">prev</a><span>|</span><a href="#42842218">next</a><span>|</span><label class="collapse" for="c-42848785">[-]</label><label class="expand" for="c-42848785">[1 more]</label></div><br/><div class="children"><div class="content">Thats a much higher hurdle to jump. I don’t blame the author for trying this first.<p>If accepted, it might have been a good stepping stone too. A chance to get to know everyone and their concerns and how they think.<p>So if you wanted to see how this works (proposal + in prod) and then come back later proposing something bigger by switching off zip that would make sense to me as a possible follow up.</div><br/></div></div></div></div><div id="42842218" class="c"><input type="checkbox" id="c-42842218" checked=""/><div class="controls bullet"><span class="by">PaulHoule</span><span>|</span><a href="#42841728">prev</a><span>|</span><a href="#42845421">next</a><span>|</span><label class="collapse" for="c-42842218">[-]</label><label class="expand" for="c-42842218">[3 more]</label></div><br/><div class="children"><div class="content">Years back I came to the conclusion that conda using bzip2 for compression was a big mistake.<p>Back then if you wanted to use a particular neural network it was meant for a certain version of Tensorflow which expected you to have a certain version of the CUDA libs.<p>If you had to work with multiple models the &quot;normal&quot; way to do things was use the developer unfriendly [1][2] installers from NVIDIA to install a single version of the libs at a time.<p>Turned out you could have many versions of CUDA installed as long as you kept them in different directories and set the library path accordingly,  it made sense to pack them up for conda and install them together with everything else.<p>But oh boy was it slow to unpack those bzip2 packages!  Since conda had good caching,  if you build environments often at all you could be paying more in decompress time than you pay in compression time.<p>If you were building a new system today you&#x27;d probably use zstd since it beats gzip on both speed and compression.<p>[1] click... click... click...<p>[2] like they&#x27;re really going to do something useful with my email address</div><br/><div id="42845592" class="c"><input type="checkbox" id="c-42845592" checked=""/><div class="controls bullet"><span class="by">zahlman</span><span>|</span><a href="#42842218">parent</a><span>|</span><a href="#42845421">next</a><span>|</span><label class="collapse" for="c-42845592">[-]</label><label class="expand" for="c-42845592">[2 more]</label></div><br/><div class="children"><div class="content">&gt;But oh boy was it slow to unpack those bzip2 packages! Since conda had good caching, if you build environments often at all you could be paying more in decompress time than you pay in compression time.<p>For Paper, I&#x27;m planning to cache both the wheel archives (so that they&#x27;re available without recompressing on demand) and unpacked versions (installing into new environments will generally use hard links to the unpacked cache, where possible).<p>&gt; If you were building a new system today you&#x27;d probably use zstd since it beats gzip on both speed and compression.<p>FWIW, in my testing LZMA is a big win (and I&#x27;m sure zstd would be as well, but LZMA has standard library support already). But there are serious roadblocks to adopting a change like that in the Python ecosystem. This sort of idea puts them several layers deep in meta-discussion - see for example <a href="https:&#x2F;&#x2F;discuss.python.org&#x2F;t&#x2F;pep-777-how-to-re-invent-the-wheel&#x2F;67484" rel="nofollow">https:&#x2F;&#x2F;discuss.python.org&#x2F;t&#x2F;pep-777-how-to-re-invent-the-wh...</a> . In general, progress on Python packaging gets stuck in a double-bind: try to change too little and you won&#x27;t get any buy-in that it&#x27;s worthwhile, but try to change too much and everyone will freak out about backwards compatibility.</div><br/><div id="42847291" class="c"><input type="checkbox" id="c-42847291" checked=""/><div class="controls bullet"><span class="by">PaulHoule</span><span>|</span><a href="#42842218">root</a><span>|</span><a href="#42845592">parent</a><span>|</span><a href="#42845421">next</a><span>|</span><label class="collapse" for="c-42847291">[-]</label><label class="expand" for="c-42847291">[1 more]</label></div><br/><div class="children"><div class="content">I designed a system which was a lot like uv but written in Python and when I looked at the politics I decided not to go forward with it.  (My system also had the problem that it had to be isolated from other Pythons so it would not get its environment trashed,  with the ability for software developers to trash their environment I wasn&#x27;t sure it was a problem that could be 100% solved.  uv solved it by <i>not being written in Python.</i>  Genius!)</div><br/></div></div></div></div></div></div><div id="42845421" class="c"><input type="checkbox" id="c-42845421" checked=""/><div class="controls bullet"><span class="by">hinkley</span><span>|</span><a href="#42842218">prev</a><span>|</span><a href="#42840933">next</a><span>|</span><label class="collapse" for="c-42845421">[-]</label><label class="expand" for="c-42845421">[1 more]</label></div><br/><div class="children"><div class="content">Pulling on this thread, there are a few people who have looked at the ways zopfli is inefficient. Including this guy who forked it, and tried to contribute a couple improvements back to master:<p><a href="https:&#x2F;&#x2F;github.com&#x2F;fhanau&#x2F;Efficient-Compression-Tool">https:&#x2F;&#x2F;github.com&#x2F;fhanau&#x2F;Efficient-Compression-Tool</a><p>These days if you’re going to iterate on a solution you’d better make it multithreaded. We have laptops where sequential code uses 8% of the available cpu.</div><br/></div></div><div id="42840933" class="c"><input type="checkbox" id="c-42840933" checked=""/><div class="controls bullet"><span class="by">stabbles</span><span>|</span><a href="#42845421">prev</a><span>|</span><a href="#42840924">next</a><span>|</span><label class="collapse" for="c-42840933">[-]</label><label class="expand" for="c-42840933">[5 more]</label></div><br/><div class="children"><div class="content">One thing that&#x27;s excellent about zopfli (apart from being gzip compatible) is how easy it is to bootstrap:<p><pre><code>    git clone https:&#x2F;&#x2F;github.com&#x2F;google&#x2F;zopfli.git
    cc -O2 zopfli&#x2F;src&#x2F;zopfli&#x2F;*.c -lm
</code></pre>
It just requires a C compiler and linker.</div><br/><div id="42841168" class="c"><input type="checkbox" id="c-42841168" checked=""/><div class="controls bullet"><span class="by">stabbles</span><span>|</span><a href="#42840933">parent</a><span>|</span><a href="#42840924">next</a><span>|</span><label class="collapse" for="c-42841168">[-]</label><label class="expand" for="c-42841168">[4 more]</label></div><br/><div class="children"><div class="content">The main downside though, it&#x27;s impressively slow.<p>Comparing to gzip isn&#x27;t really worth it. Combine pigz (threaded) with zlib-ng (simd) and you get decent performance. pigz is used in `docker push`.<p>For example, gzipping llvm.tar (624MB) takes less than a second for me:<p><pre><code>    $ time &#x2F;home&#x2F;harmen&#x2F;spack&#x2F;opt&#x2F;spack&#x2F;linux-ubuntu24.04-zen2&#x2F;gcc-13.2.0&#x2F;pigz-2.8-5ptdjrmudifhjvhb757ym2bzvgtcsoqc&#x2F;bin&#x2F;pigz -k hello.tar 
    
    real    0m0.779s
    user    0m11.126s
    sys     0m0.460s
</code></pre>
At the same time, zopfli compiled with -O3 -march=native takes 35 minutes. No wonder it&#x27;s not popular.<p>It is almost <i>2700x</i> slower than the state of the art for just 6.8% bytes saved.</div><br/><div id="42841486" class="c"><input type="checkbox" id="c-42841486" checked=""/><div class="controls bullet"><span class="by">Levitating</span><span>|</span><a href="#42840933">root</a><span>|</span><a href="#42841168">parent</a><span>|</span><a href="#42840924">next</a><span>|</span><label class="collapse" for="c-42841486">[-]</label><label class="expand" for="c-42841486">[3 more]</label></div><br/><div class="children"><div class="content">&gt; 2700x slower<p>That is impressively slow.<p>In my opinion even the 28x decrease in performance mentioned would be a no-go. Sure the package saves a few bytes but I don&#x27;t need my entire pc to grind to a halt every time I publish a package.<p>Besides, storage is cheap but CPU power draw is not. Imagine the additional CO2 that would have to be produced if this RFC was merged.<p>&gt; 2 gigabytes of bandwidth per year across all installations<p>This must be a really rough estimate and I am curious how it was calculated. In any case 2 gigabytes over <i>a year</i> is absolutely nothing. Just my home network can produce a terabyte a day.</div><br/><div id="42841683" class="c"><input type="checkbox" id="c-42841683" checked=""/><div class="controls bullet"><span class="by">bonzini</span><span>|</span><a href="#42840933">root</a><span>|</span><a href="#42841486">parent</a><span>|</span><a href="#42840924">next</a><span>|</span><label class="collapse" for="c-42841683">[-]</label><label class="expand" for="c-42841683">[2 more]</label></div><br/><div class="children"><div class="content">2 GB for the author&#x27;s package which is neither extremely common nor large; it would be 2 TB&#x2F;year just for react core.</div><br/><div id="42841771" class="c"><input type="checkbox" id="c-42841771" checked=""/><div class="controls bullet"><span class="by">Levitating</span><span>|</span><a href="#42840933">root</a><span>|</span><a href="#42841683">parent</a><span>|</span><a href="#42840924">next</a><span>|</span><label class="collapse" for="c-42841771">[-]</label><label class="expand" for="c-42841771">[1 more]</label></div><br/><div class="children"><div class="content">I am confused, how is this number calculated?<p>Because the authors mentioned package, Helmet[1], is 103KB <i>uncompressed</i> and has had 132 versions in 13 years. Meaning downloading every Helmet version uncompressed would result in 132*103KB = 13.7MB.<p>I feel like I must be missing something really obvious.<p>Edit: Oh it&#x27;s 2GB&#x2F;year <i>across</i> all installations.<p>[1]: <a href="https:&#x2F;&#x2F;www.npmjs.com&#x2F;package&#x2F;helmet?activeTab=versions" rel="nofollow">https:&#x2F;&#x2F;www.npmjs.com&#x2F;package&#x2F;helmet?activeTab=versions</a></div><br/></div></div></div></div></div></div></div></div></div></div><div id="42840924" class="c"><input type="checkbox" id="c-42840924" checked=""/><div class="controls bullet"><span class="by">orta</span><span>|</span><a href="#42840933">prev</a><span>|</span><a href="#42845687">next</a><span>|</span><label class="collapse" for="c-42840924">[-]</label><label class="expand" for="c-42840924">[1 more]</label></div><br/><div class="children"><div class="content">Congrats on a great write-up. Sometimes trying to ship something at that sorta scale turns out to just not really make sense in a way that is hard to see at the beginning.<p>Another personal win is that you got a very thorough understanding of the people involved and how the outreach parts of the RFC process works. I&#x27;ve also had a few fail, but I&#x27;ve also had a few pass! Always easier to do the next time</div><br/></div></div><div id="42845687" class="c"><input type="checkbox" id="c-42845687" checked=""/><div class="controls bullet"><span class="by">zahlman</span><span>|</span><a href="#42840924">prev</a><span>|</span><a href="#42841131">next</a><span>|</span><label class="collapse" for="c-42845687">[-]</label><label class="expand" for="c-42845687">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;d love to see an effort like like this succeed in the Python ecosystem. Right now, PyPI is dependent upon Fastly to serve files, on the order of &gt;1 petabyte per day. That&#x27;s a truly massive in-kind donation, compared to the PSF&#x27;s operating budget (only a few million dollars per year - far smaller than Linux or Mozilla).</div><br/><div id="42846738" class="c"><input type="checkbox" id="c-42846738" checked=""/><div class="controls bullet"><span class="by">cozzyd</span><span>|</span><a href="#42845687">parent</a><span>|</span><a href="#42841131">next</a><span>|</span><label class="collapse" for="c-42846738">[-]</label><label class="expand" for="c-42846738">[1 more]</label></div><br/><div class="children"><div class="content">No problem, I&#x27;m sure if Fastly stopped doing it JiaTanCo would step up</div><br/></div></div></div></div><div id="42841131" class="c"><input type="checkbox" id="c-42841131" checked=""/><div class="controls bullet"><span class="by">jsheard</span><span>|</span><a href="#42845687">prev</a><span>|</span><a href="#42846649">next</a><span>|</span><label class="collapse" for="c-42841131">[-]</label><label class="expand" for="c-42841131">[3 more]</label></div><br/><div class="children"><div class="content">I wonder if it would make more sense to pursue Brotli at this point, Node has had it built-in since 10.x so it should be pretty ubiquitous by now. It would require an update to NPM itself though.</div><br/><div id="42847682" class="c"><input type="checkbox" id="c-42847682" checked=""/><div class="controls bullet"><span class="by">silverwind</span><span>|</span><a href="#42841131">parent</a><span>|</span><a href="#42846649">next</a><span>|</span><label class="collapse" for="c-42847682">[-]</label><label class="expand" for="c-42847682">[2 more]</label></div><br/><div class="children"><div class="content">+1 to brotli. Newly published packages could use brotli by default, so old ones stay compatible.</div><br/><div id="42850087" class="c"><input type="checkbox" id="c-42850087" checked=""/><div class="controls bullet"><span class="by">canucker2016</span><span>|</span><a href="#42841131">root</a><span>|</span><a href="#42847682">parent</a><span>|</span><a href="#42846649">next</a><span>|</span><label class="collapse" for="c-42850087">[-]</label><label class="expand" for="c-42850087">[1 more]</label></div><br/><div class="children"><div class="content">Here&#x27;s the Brotli supporter&#x27;s blog post about adding Brotli support to NPM packages.<p><a href="https:&#x2F;&#x2F;jamiemagee.co.uk&#x2F;blog&#x2F;honey-i-shrunk-the-npm-package&#x2F;" rel="nofollow">https:&#x2F;&#x2F;jamiemagee.co.uk&#x2F;blog&#x2F;honey-i-shrunk-the-npm-package...</a><p>and the related HN discussion from that time:<p><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37754489">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37754489</a></div><br/></div></div></div></div></div></div><div id="42846649" class="c"><input type="checkbox" id="c-42846649" checked=""/><div class="controls bullet"><span class="by">luzifer42</span><span>|</span><a href="#42841131">prev</a><span>|</span><a href="#42845680">next</a><span>|</span><label class="collapse" for="c-42846649">[-]</label><label class="expand" for="c-42846649">[1 more]</label></div><br/><div class="children"><div class="content">I created once a maven plugin to recompress Java artefacts with zopfli. I rewrote it in Java and runs entirely in the JVM. This means, the speed is worse and may contain bugs:<p><a href="https:&#x2F;&#x2F;luccappellaro.github.io&#x2F;2015&#x2F;03&#x2F;01&#x2F;ZopfliMaven.html" rel="nofollow">https:&#x2F;&#x2F;luccappellaro.github.io&#x2F;2015&#x2F;03&#x2F;01&#x2F;ZopfliMaven.html</a></div><br/></div></div><div id="42845680" class="c"><input type="checkbox" id="c-42845680" checked=""/><div class="controls bullet"><span class="by">frabjoused</span><span>|</span><a href="#42846649">prev</a><span>|</span><a href="#42841718">next</a><span>|</span><label class="collapse" for="c-42845680">[-]</label><label class="expand" for="c-42845680">[2 more]</label></div><br/><div class="children"><div class="content">This reminds me of a time I lost an argument with John-David Dalton about cleaning up&#x2F;minifying lodash as an npm dependency, because when including the readme and license for every sub-library, a lodash import came to ~2.5MB at the time. This also took a lot of seeking time for disks because there were so many individual files.<p>The conversation started and ended at the word cache.</div><br/><div id="42848822" class="c"><input type="checkbox" id="c-42848822" checked=""/><div class="controls bullet"><span class="by">MBCook</span><span>|</span><a href="#42845680">parent</a><span>|</span><a href="#42841718">next</a><span>|</span><label class="collapse" for="c-42848822">[-]</label><label class="expand" for="c-42848822">[1 more]</label></div><br/><div class="children"><div class="content">&gt; This also took a lot of seeking time for disks because there were so many individual files.<p>The fact NPM keeps things in node_modules unzipped seems wild to me. Filesystems are not great at hundreds of thousands of little files. Some are bad, others are terrible.<p>Zip files are easier to store, take up less space, and CPUs are faster than disks so the decompression in memory is probably faster reading the unzipped files.<p>That was one of my favorite features of Yarn when I tried it - pnp mode. But since it’s not what NPM does it requires a shim that doesn’t work with all ps mage’s. Or at least didn’t a few years ago.</div><br/></div></div></div></div><div id="42841718" class="c"><input type="checkbox" id="c-42841718" checked=""/><div class="controls bullet"><span class="by">nikeee</span><span>|</span><a href="#42845680">prev</a><span>|</span><a href="#42842379">next</a><span>|</span><label class="collapse" for="c-42841718">[-]</label><label class="expand" for="c-42841718">[2 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t see why it wouldn&#x27;t be possible to hide behind a flag once Node.js supports zopfli natively.
In case of CI&#x2F;CD, it&#x27;s totally feasible to just add a --strong-compression flag. In that case, the user expects it to take its time.<p>TS releases a non-preview version every few months, so using 2.5 minutes for compression would work.</div><br/><div id="42848685" class="c"><input type="checkbox" id="c-42848685" checked=""/><div class="controls bullet"><span class="by">jopsen</span><span>|</span><a href="#42841718">parent</a><span>|</span><a href="#42842379">next</a><span>|</span><label class="collapse" for="c-42848685">[-]</label><label class="expand" for="c-42848685">[1 more]</label></div><br/><div class="children"><div class="content">Think of the complexity involved, think of having to fix bugs because something went wrong.<p>Such effort would be better spent preparing npm&#x2F;node for a future where packages with a lower-bound npm version constraint can be compressed with zstd or similar.<p>Every feature you add to a program is complexity, you need to really decide if you want it.</div><br/></div></div></div></div><div id="42842379" class="c"><input type="checkbox" id="c-42842379" checked=""/><div class="controls bullet"><span class="by">bhouston</span><span>|</span><a href="#42841718">prev</a><span>|</span><a href="#42841240">next</a><span>|</span><label class="collapse" for="c-42842379">[-]</label><label class="expand" for="c-42842379">[7 more]</label></div><br/><div class="children"><div class="content">What about a different approach - an optional npm proxy that recompresses popular packages with 7z&#x2F;etc in the background?<p>Could verify package integrity by hashing contents rather than archives, plus digital signatures for recompressed versions. Only kicks in for frequently downloaded packages once compression is ready.<p>Benefits: No npm changes needed, opt-in only, potential for big bandwidth savings on popular packages. Main tradeoff is additional verification steps, but they could be optional given a digital signature approach.<p>Curious if others see major security holes in this approach?</div><br/><div id="42843603" class="c"><input type="checkbox" id="c-42843603" checked=""/><div class="controls bullet"><span class="by">ndriscoll</span><span>|</span><a href="#42842379">parent</a><span>|</span><a href="#42841240">next</a><span>|</span><label class="collapse" for="c-42843603">[-]</label><label class="expand" for="c-42843603">[6 more]</label></div><br/><div class="children"><div class="content">This felt like the obvious way to do things to me: hash a .tar file, not a .tar.gz file. Use Accept-Encoding to negotiate the compression scheme for transfers. CDN can compress on the fly or optionally cache precompressed files. i.e. just use standard off-the-shelf HTTP features. These days I prefer uncompressed .tar files anyway because ZFS has transparent zstd, so decompressed archive files are generally smaller than a .gz.</div><br/><div id="42844843" class="c"><input type="checkbox" id="c-42844843" checked=""/><div class="controls bullet"><span class="by">cesarb</span><span>|</span><a href="#42842379">root</a><span>|</span><a href="#42843603">parent</a><span>|</span><a href="#42845818">next</a><span>|</span><label class="collapse" for="c-42844843">[-]</label><label class="expand" for="c-42844843">[2 more]</label></div><br/><div class="children"><div class="content">&gt; hash a .tar file, not a .tar.gz file<p>For security reasons, it&#x27;s usually better to hash the compressed file, since it reduces the attack surface: the decompressor is not exposed to unverified data. There have already been vulnerabilities in decompressor implementations which can be exploited through malformed compressed data (and this includes IIRC at least one vulnerability in zlib, which is the standard decompressor for .gz).</div><br/><div id="42845759" class="c"><input type="checkbox" id="c-42845759" checked=""/><div class="controls bullet"><span class="by">bhouston</span><span>|</span><a href="#42842379">root</a><span>|</span><a href="#42844843">parent</a><span>|</span><a href="#42845818">next</a><span>|</span><label class="collapse" for="c-42845759">[-]</label><label class="expand" for="c-42845759">[1 more]</label></div><br/><div class="children"><div class="content">This suggests one should just upload a tar rather than a compressed file.  Makes sense because one can scan the contents for malicious files without risking a decompressor bug.<p>BTW npm decompressed all packages anyhow because it lets you view the contents these days on its website.</div><br/></div></div></div></div><div id="42845818" class="c"><input type="checkbox" id="c-42845818" checked=""/><div class="controls bullet"><span class="by">bhouston</span><span>|</span><a href="#42842379">root</a><span>|</span><a href="#42843603">parent</a><span>|</span><a href="#42844843">prev</a><span>|</span><a href="#42846820">next</a><span>|</span><label class="collapse" for="c-42845818">[-]</label><label class="expand" for="c-42845818">[1 more]</label></div><br/><div class="children"><div class="content">You are correct.  They should be uploading and downloading dumb tar files and let the HTTP connection negotiate the compression method.  All hashes should be based on the uncompressed raw tar dump.  This would be proper separation of concerns.</div><br/></div></div><div id="42846820" class="c"><input type="checkbox" id="c-42846820" checked=""/><div class="controls bullet"><span class="by">cozzyd</span><span>|</span><a href="#42842379">root</a><span>|</span><a href="#42843603">parent</a><span>|</span><a href="#42845818">prev</a><span>|</span><a href="#42841240">next</a><span>|</span><label class="collapse" for="c-42846820">[-]</label><label class="expand" for="c-42846820">[2 more]</label></div><br/><div class="children"><div class="content">Enjoy zipbomb.js</div><br/><div id="42846879" class="c"><input type="checkbox" id="c-42846879" checked=""/><div class="controls bullet"><span class="by">bhouston</span><span>|</span><a href="#42842379">root</a><span>|</span><a href="#42846820">parent</a><span>|</span><a href="#42841240">next</a><span>|</span><label class="collapse" for="c-42846879">[-]</label><label class="expand" for="c-42846879">[1 more]</label></div><br/><div class="children"><div class="content">But npm already decompresses every package because it shows the contents on its website.  So yeah it can be malicious but it already has dealt with that risk.</div><br/></div></div></div></div></div></div></div></div><div id="42841240" class="c"><input type="checkbox" id="c-42841240" checked=""/><div class="controls bullet"><span class="by">choobacker</span><span>|</span><a href="#42842379">prev</a><span>|</span><a href="#42847207">next</a><span>|</span><label class="collapse" for="c-42841240">[-]</label><label class="expand" for="c-42841240">[1 more]</label></div><br/><div class="children"><div class="content">Nice write up!<p>&gt; When it was finally my turn, I stammered.<p>&gt; Watching it back, I cringe a bit. I was wordy, unclear, and unconvincing.<p>&gt; You can watch my mumbling in the recording<p>I watched this, and the author was articulate and presented well. The author is too harsh!<p>Good job for trying to push the boundaries.</div><br/></div></div><div id="42847207" class="c"><input type="checkbox" id="c-42847207" checked=""/><div class="controls bullet"><span class="by">Julien_r2</span><span>|</span><a href="#42841240">prev</a><span>|</span><a href="#42848758">next</a><span>|</span><label class="collapse" for="c-42847207">[-]</label><label class="expand" for="c-42847207">[1 more]</label></div><br/><div class="children"><div class="content">A pro could have been an extra narrative about carbon footprint savings.<p>I&#x27;m surprised it hasn&#x27;t been raised when talking about saving 2Tb&#x2F;year only for React. It represents costs, which doesn&#x27;t seem to be an issue, but also computing power and storage. (Event with a higher&#x2F;longer computing power due to slower compression, it&#x27;s done once per version, which isn&#x27;t really comprable to the amount of downloads anyway)<p>Hard to calculate the exact saving, but it would represent a smaller CO2 footprint..</div><br/></div></div><div id="42848758" class="c"><input type="checkbox" id="c-42848758" checked=""/><div class="controls bullet"><span class="by">vivzkestrel</span><span>|</span><a href="#42847207">prev</a><span>|</span><a href="#42847704">next</a><span>|</span><label class="collapse" for="c-42848758">[-]</label><label class="expand" for="c-42848758">[1 more]</label></div><br/><div class="children"><div class="content">I ll give you an even better idea but it ll need atleast a 100 volunteers, maybe a 1000. Take each package and rewrite it without external dependencies. That will cut tech debt for that package significantly. Just like how we have a @types&#x2F;xyz where some dude named DefinitelyTyped is busy making typescript packages for everything, lets make a namespace like @efficient&#x2F;cors @efficient&#x2F;jsdom @efficient&#x2F;jest etc and eliminate all external dependencies completely for every library on npm</div><br/></div></div><div id="42847704" class="c"><input type="checkbox" id="c-42847704" checked=""/><div class="controls bullet"><span class="by">wallunit</span><span>|</span><a href="#42848758">prev</a><span>|</span><a href="#42845803">next</a><span>|</span><label class="collapse" for="c-42847704">[-]</label><label class="expand" for="c-42847704">[1 more]</label></div><br/><div class="children"><div class="content">I used zopflipng in the past to optimize PNG images. It made sense since there was no better alternative to store lossless image data than the PNG format at the given time in the given environment. Zopfli is awesome when you are locked in on deflate compression. I feel like if the npm folks would want to optimize for smaller package size a better strategy would be switching to some more effective text compression (e.g. bzip2, xz). That would result into a larger file size reduction than 5% for a smaller CPU time increase compared to Zopfli. You would need to come up with some migration strategy though as this change isn&#x27;t per-se backwards compatible, but that seems manageable if you are in control of the tooling and infrastructure.</div><br/></div></div><div id="42845803" class="c"><input type="checkbox" id="c-42845803" checked=""/><div class="controls bullet"><span class="by">JoeAltmaier</span><span>|</span><a href="#42847704">prev</a><span>|</span><a href="#42841073">next</a><span>|</span><label class="collapse" for="c-42845803">[-]</label><label class="expand" for="c-42845803">[1 more]</label></div><br/><div class="children"><div class="content">These days technology moves so fast it&#x27;s hard to keep up. The slowest link in the system is the human being.<p>That&#x27;s a strong argument that &#x27;if it isn&#x27;t broke, don&#x27;t fix it.&quot;<p>LOts of numbers being thrown around, you add up tiny things enough times you can get a big number. But is npm package download the thing that&#x27;s tanking the internet? No? Then this is a second- or thirt-order optimization.</div><br/></div></div><div id="42841073" class="c"><input type="checkbox" id="c-42841073" checked=""/><div class="controls bullet"><span class="by">avodonosov</span><span>|</span><a href="#42845803">prev</a><span>|</span><a href="#42841559">next</a><span>|</span><label class="collapse" for="c-42841073">[-]</label><label class="expand" for="c-42841073">[14 more]</label></div><br/><div class="children"><div class="content">My experiment on how to reduce javascript size of every web app by 30-50% : <a href="https:&#x2F;&#x2F;github.com&#x2F;avodonosov&#x2F;pocl">https:&#x2F;&#x2F;github.com&#x2F;avodonosov&#x2F;pocl</a><p>Working approach, but in the end I abandoned the project - I doubt people care about such js size savings.</div><br/><div id="42842900" class="c"><input type="checkbox" id="c-42842900" checked=""/><div class="controls bullet"><span class="by">hinkley</span><span>|</span><a href="#42841073">parent</a><span>|</span><a href="#42841137">next</a><span>|</span><label class="collapse" for="c-42842900">[-]</label><label class="expand" for="c-42842900">[3 more]</label></div><br/><div class="children"><div class="content">I got measurable decreases in deployment time by shrinking the node_modules directory in our docker images.<p>I think people forget that, when you’re copying the same images to dozens and dozens of boxes, any improvement starts to add up to real numbers.</div><br/><div id="42843821" class="c"><input type="checkbox" id="c-42843821" checked=""/><div class="controls bullet"><span class="by">syncsynchalt</span><span>|</span><a href="#42841073">root</a><span>|</span><a href="#42842900">parent</a><span>|</span><a href="#42841137">next</a><span>|</span><label class="collapse" for="c-42843821">[-]</label><label class="expand" for="c-42843821">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve not done it, but have you considered using `pnpm` and volume-mounting a shared persistent `pnpm-store` into the containers?  It seems like you&#x27;d get near-instant npm installs that way.</div><br/><div id="42843924" class="c"><input type="checkbox" id="c-42843924" checked=""/><div class="controls bullet"><span class="by">hinkley</span><span>|</span><a href="#42841073">root</a><span>|</span><a href="#42843821">parent</a><span>|</span><a href="#42841137">next</a><span>|</span><label class="collapse" for="c-42843924">[-]</label><label class="expand" for="c-42843924">[1 more]</label></div><br/><div class="children"><div class="content">The only time npm install was on the critical path was hotfixes. It’s definitely worth considering. But I was already deep into doing people giant favors that they didn’t even notice, so I was juggling many other goals. I think the only thank you I got was from the UI lead, who had some soda straw internet connection and this and another thing I did saved him a bunch of hard to recover timeouts.</div><br/></div></div></div></div></div></div><div id="42841137" class="c"><input type="checkbox" id="c-42841137" checked=""/><div class="controls bullet"><span class="by">dagelf</span><span>|</span><a href="#42841073">parent</a><span>|</span><a href="#42842900">prev</a><span>|</span><a href="#42842333">next</a><span>|</span><label class="collapse" for="c-42841137">[-]</label><label class="expand" for="c-42841137">[6 more]</label></div><br/><div class="children"><div class="content">Wdym?? 50% is a big deal</div><br/><div id="42841211" class="c"><input type="checkbox" id="c-42841211" checked=""/><div class="controls bullet"><span class="by">bluGill</span><span>|</span><a href="#42841073">root</a><span>|</span><a href="#42841137">parent</a><span>|</span><a href="#42842333">next</a><span>|</span><label class="collapse" for="c-42841211">[-]</label><label class="expand" for="c-42841211">[5 more]</label></div><br/><div class="children"><div class="content">50% size savings isn&#x27;t important to the people who pay for it.  They pay at most pennies for 100% savings (that is somehow all the functionality in zero bytes - not worth anything to those paying the bills)</div><br/><div id="42841345" class="c"><input type="checkbox" id="c-42841345" checked=""/><div class="controls bullet"><span class="by">tyre</span><span>|</span><a href="#42841073">root</a><span>|</span><a href="#42841211">parent</a><span>|</span><a href="#42842333">next</a><span>|</span><label class="collapse" for="c-42841345">[-]</label><label class="expand" for="c-42841345">[4 more]</label></div><br/><div class="children"><div class="content">Size savings translates to latency improvements which directly affects conversion rates. Smaller size isn’t about reducing costs but increased revenue. People care.</div><br/><div id="42841627" class="c"><input type="checkbox" id="c-42841627" checked=""/><div class="controls bullet"><span class="by">soared</span><span>|</span><a href="#42841073">root</a><span>|</span><a href="#42841345">parent</a><span>|</span><a href="#42842317">next</a><span>|</span><label class="collapse" for="c-42841627">[-]</label><label class="expand" for="c-42841627">[1 more]</label></div><br/><div class="children"><div class="content">Agreed - often a CTO of an ecom site is very very focused on site speed and has it as their #1 priority since it directly increases revenue.</div><br/></div></div><div id="42842317" class="c"><input type="checkbox" id="c-42842317" checked=""/><div class="controls bullet"><span class="by">fwip</span><span>|</span><a href="#42841073">root</a><span>|</span><a href="#42841345">parent</a><span>|</span><a href="#42841627">prev</a><span>|</span><a href="#42842333">next</a><span>|</span><label class="collapse" for="c-42842317">[-]</label><label class="expand" for="c-42842317">[2 more]</label></div><br/><div class="children"><div class="content">Note that this proof-of-concept implementation saves latency on first load, but may add latency at surprising points while using the website. Any user invoking a rarely-used function would see a delay before the javascript executes, without the traditional UI affordances (spinners etc) to indicate that the application was waiting on the network. Further, these secretly-slow paths may change from visit to visit. Many users know how to &quot;wait for the app to be ready,&quot; but the traditional expectation is that once it&#x27;s loaded, the page&#x2F;app will work, and any further delays will be signposted.<p>I&#x27;m sure it works great when you&#x27;ve got high-speed internet, but might break things unacceptably for users on mobile or satellite connections.</div><br/><div id="42843428" class="c"><input type="checkbox" id="c-42843428" checked=""/><div class="controls bullet"><span class="by">vlovich123</span><span>|</span><a href="#42841073">root</a><span>|</span><a href="#42842317">parent</a><span>|</span><a href="#42842333">next</a><span>|</span><label class="collapse" for="c-42843428">[-]</label><label class="expand" for="c-42843428">[1 more]</label></div><br/><div class="children"><div class="content">&gt; without the traditional UI affordances (spinners etc) to indicate that the application was waiting on the network.<p>This part is obviously trivially solvable. I think the same basic idea is going to at some point make it but it’ll have to be through explicit annotations first and then there will be tooling to automatically do this for your code based upon historical visits where you get to tune the % of visitors that get additional fetches. Also, you could probably fetch the split off script in the background anyway as a prefetch + download everything rather than just 1 function at a time (or even downloading related groups of functions together)<p>The idea has lots of merit and you just have to execute it right.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="42842333" class="c"><input type="checkbox" id="c-42842333" checked=""/><div class="controls bullet"><span class="by">philipwhiuk</span><span>|</span><a href="#42841073">parent</a><span>|</span><a href="#42841137">prev</a><span>|</span><a href="#42842336">next</a><span>|</span><label class="collapse" for="c-42842333">[-]</label><label class="expand" for="c-42842333">[1 more]</label></div><br/><div class="children"><div class="content">How do you evaluate call usage?</div><br/></div></div><div id="42842336" class="c"><input type="checkbox" id="c-42842336" checked=""/><div class="controls bullet"><span class="by">KTibow</span><span>|</span><a href="#42841073">parent</a><span>|</span><a href="#42842333">prev</a><span>|</span><a href="#42841559">next</a><span>|</span><label class="collapse" for="c-42842336">[-]</label><label class="expand" for="c-42842336">[3 more]</label></div><br/><div class="children"><div class="content">I think this is called tree shaking and Vite&#x2F;Rollup do this by default these days. Of course, it&#x27;s easy when you explicitly say what you&#x27;re importing.</div><br/><div id="42842672" class="c"><input type="checkbox" id="c-42842672" checked=""/><div class="controls bullet"><span class="by">avodonosov</span><span>|</span><a href="#42841073">root</a><span>|</span><a href="#42842336">parent</a><span>|</span><a href="#42841559">next</a><span>|</span><label class="collapse" for="c-42842672">[-]</label><label class="expand" for="c-42842672">[2 more]</label></div><br/><div class="children"><div class="content">That&#x27;s not tree-shaking.</div><br/><div id="42847004" class="c"><input type="checkbox" id="c-42847004" checked=""/><div class="controls bullet"><span class="by">KTibow</span><span>|</span><a href="#42841073">root</a><span>|</span><a href="#42842672">parent</a><span>|</span><a href="#42841559">next</a><span>|</span><label class="collapse" for="c-42847004">[-]</label><label class="expand" for="c-42847004">[1 more]</label></div><br/><div class="children"><div class="content">Oh, I guess you would need something like dynamic imports to not include uncommonly used functionality in the main bundle</div><br/></div></div></div></div></div></div></div></div><div id="42841559" class="c"><input type="checkbox" id="c-42841559" checked=""/><div class="controls bullet"><span class="by">glenjamin</span><span>|</span><a href="#42841073">prev</a><span>|</span><a href="#42844555">next</a><span>|</span><label class="collapse" for="c-42841559">[-]</label><label class="expand" for="c-42841559">[2 more]</label></div><br/><div class="children"><div class="content">This strikes me as something that could be done for the highest traffic packages at the backend, rather than be driven by the client at pubish-time.</div><br/><div id="42841706" class="c"><input type="checkbox" id="c-42841706" checked=""/><div class="controls bullet"><span class="by">fastest963</span><span>|</span><a href="#42841559">parent</a><span>|</span><a href="#42844555">next</a><span>|</span><label class="collapse" for="c-42841706">[-]</label><label class="expand" for="c-42841706">[1 more]</label></div><br/><div class="children"><div class="content">The article talks about this. There are hashes that are generated for the tarball so the backend can&#x27;t recompress anything.</div><br/></div></div></div></div><div id="42844555" class="c"><input type="checkbox" id="c-42844555" checked=""/><div class="controls bullet"><span class="by">omoikane</span><span>|</span><a href="#42841559">prev</a><span>|</span><a href="#42841133">next</a><span>|</span><label class="collapse" for="c-42844555">[-]</label><label class="expand" for="c-42844555">[3 more]</label></div><br/><div class="children"><div class="content">&gt; Integrating Zopfli into the npm CLI would be difficult.<p>Is it possible to modify &quot;gzip -9&quot; or zlib to invoke zopfli?  This way everyone who wants to compress better will get the extra compression automatically, in addition to npm.<p>There will be an increase in compression time, but since &quot;gzip -9&quot; is not the default, people preferring compression speed might not be affected.</div><br/><div id="42844849" class="c"><input type="checkbox" id="c-42844849" checked=""/><div class="controls bullet"><span class="by">bombcar</span><span>|</span><a href="#42844555">parent</a><span>|</span><a href="#42841133">next</a><span>|</span><label class="collapse" for="c-42844849">[-]</label><label class="expand" for="c-42844849">[2 more]</label></div><br/><div class="children"><div class="content">You&#x27;d have more problems here, but you could do it - if you let it take ages and ages to percolate though all environments.<p>It&#x27;s been almost 30 years since bzip2 was released and even now not everything can handle tar.bz2</div><br/><div id="42846120" class="c"><input type="checkbox" id="c-42846120" checked=""/><div class="controls bullet"><span class="by">arccy</span><span>|</span><a href="#42844555">root</a><span>|</span><a href="#42844849">parent</a><span>|</span><a href="#42841133">next</a><span>|</span><label class="collapse" for="c-42846120">[-]</label><label class="expand" for="c-42846120">[1 more]</label></div><br/><div class="children"><div class="content">probably because bzip2 isn&#x27;t a very good format</div><br/></div></div></div></div></div></div><div id="42841133" class="c"><input type="checkbox" id="c-42841133" checked=""/><div class="controls bullet"><span class="by">pornel</span><span>|</span><a href="#42844555">prev</a><span>|</span><a href="#42843085">next</a><span>|</span><label class="collapse" for="c-42841133">[-]</label><label class="expand" for="c-42841133">[1 more]</label></div><br/><div class="children"><div class="content">It only doesn&#x27;t apply to existing <i>versions</i> of existing packages. Newer releases would apply Zopfli, so over time likely the majority of actively used&#x2F;maintained packages would be recompressed.</div><br/></div></div><div id="42843085" class="c"><input type="checkbox" id="c-42843085" checked=""/><div class="controls bullet"><span class="by">woadwarrior01</span><span>|</span><a href="#42841133">prev</a><span>|</span><a href="#42842584">next</a><span>|</span><label class="collapse" for="c-42843085">[-]</label><label class="expand" for="c-42843085">[3 more]</label></div><br/><div class="children"><div class="content">From the RFC on github[1].<p>&gt; Zopfli is written in C, which presents challenges. Unless it was added to Node core, the CLI would need to (1) rewrite Zopfli in JS, possibly impacting performance (2) rely on a native module, impacting reliability (3) rely on a WebAssembly module. All of these options add complexity.<p>Wow! Who&#x27;s going to tell them that V8 is written in C++? :)<p>[1]: <a href="https:&#x2F;&#x2F;github.com&#x2F;npm&#x2F;rfcs&#x2F;pull&#x2F;595">https:&#x2F;&#x2F;github.com&#x2F;npm&#x2F;rfcs&#x2F;pull&#x2F;595</a></div><br/><div id="42843832" class="c"><input type="checkbox" id="c-42843832" checked=""/><div class="controls bullet"><span class="by">kmacdough</span><span>|</span><a href="#42843085">parent</a><span>|</span><a href="#42842584">next</a><span>|</span><label class="collapse" for="c-42843832">[-]</label><label class="expand" for="c-42843832">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not about C per-se, as much as each native compiled dependency creates additional maintenance concerns. Changes to hardware&#x2F;OS can require a recompile or even fixes. NPM build system already requires a JavaScript runtime, so is already handled as part of existing maintenance. The point is that Zopfli either needs to be rewritten for a platform-agnostic abstraction they already support, or else Zopfli will be added to a list of native modules to maintain.</div><br/><div id="42844210" class="c"><input type="checkbox" id="c-42844210" checked=""/><div class="controls bullet"><span class="by">woadwarrior01</span><span>|</span><a href="#42843085">root</a><span>|</span><a href="#42843832">parent</a><span>|</span><a href="#42842584">next</a><span>|</span><label class="collapse" for="c-42844210">[-]</label><label class="expand" for="c-42844210">[1 more]</label></div><br/><div class="children"><div class="content">&gt; It&#x27;s not about C per-se, as much as each native compiled dependency creates additional maintenance concerns. Changes to hardware&#x2F;OS can require a recompile or even fixes.<p>This is a canard. zopfli is written in portable C and is far more portable than the nodejs runtime. On any hardware&#x2F;OS combo that one can build the nodejs runtime, they certainly can also build and run zopfli.</div><br/></div></div></div></div></div></div><div id="42842584" class="c"><input type="checkbox" id="c-42842584" checked=""/><div class="controls bullet"><span class="by">snizovtsev</span><span>|</span><a href="#42843085">prev</a><span>|</span><a href="#42842397">next</a><span>|</span><label class="collapse" for="c-42842584">[-]</label><label class="expand" for="c-42842584">[1 more]</label></div><br/><div class="children"><div class="content">Yes, but it was expected. It&#x27;s like prioritising code readability over performance everywhere but the hot path.<p>Earlier in my career, I managed to use Zopfli once to compress gigabytes of PNG assets into a fast in-memory database supporting a 50K+ RPS web page. We wanted to keep it simple and avoid the complexity of horizontal scaling, and it was OK to drop some rarely used images. So the more images we could pack into a single server, the more coverage we had. In that sense Zopfli was beneficial.</div><br/></div></div><div id="42842397" class="c"><input type="checkbox" id="c-42842397" checked=""/><div class="controls bullet"><span class="by">jefozabuss</span><span>|</span><a href="#42842584">prev</a><span>|</span><a href="#42845243">next</a><span>|</span><label class="collapse" for="c-42842397">[-]</label><label class="expand" for="c-42842397">[2 more]</label></div><br/><div class="children"><div class="content">I wonder what is the tarball size difference on average if you&#x27;d for example download everything in one tarball (full package list) instead of 1-by-1 as the gzip compression would work way better in that case.<p>Also for bigger companies this is not really a &quot;big&quot; problem as they usually have in-house proxies (as you cannot rely on a 3rd party repository in CI&#x2F;CD for multiple reasons (security, audit, speed, etc)).</div><br/><div id="42849021" class="c"><input type="checkbox" id="c-42849021" checked=""/><div class="controls bullet"><span class="by">Dylan16807</span><span>|</span><a href="#42842397">parent</a><span>|</span><a href="#42845243">next</a><span>|</span><label class="collapse" for="c-42849021">[-]</label><label class="expand" for="c-42849021">[1 more]</label></div><br/><div class="children"><div class="content">You might save a little bit by putting similar very small files next to each other in the same tarball, but in general I would not expect significant improvements.  Gzip can only compress repetitions that are within 32KB of each other.</div><br/></div></div></div></div><div id="42845243" class="c"><input type="checkbox" id="c-42845243" checked=""/><div class="controls bullet"><span class="by">rafaelmn</span><span>|</span><a href="#42842397">prev</a><span>|</span><a href="#42841934">next</a><span>|</span><label class="collapse" for="c-42845243">[-]</label><label class="expand" for="c-42845243">[5 more]</label></div><br/><div class="children"><div class="content">I wonder if you could get better results if you built a dictionary over entire npm. I suspect most common words could easily be reduced to 16k word index. Would be much faster, dictionary would probably fit in cache, can even optimize it in memory for cache prefetch.</div><br/><div id="42845627" class="c"><input type="checkbox" id="c-42845627" checked=""/><div class="controls bullet"><span class="by">zahlman</span><span>|</span><a href="#42845243">parent</a><span>|</span><a href="#42841934">next</a><span>|</span><label class="collapse" for="c-42845627">[-]</label><label class="expand" for="c-42845627">[4 more]</label></div><br/><div class="children"><div class="content">This seems like a non-starter to me - new packages are added to npm all the time, and will alter the word frequency distribution. If you aren&#x27;t prepared to re-build constantly and accept that the dictionary isn&#x27;t optimal, then it&#x27;s hard to imagine it being significantly better than what you build with a more naive approach. Basically - why try to fine-tune to a moving target?</div><br/><div id="42846818" class="c"><input type="checkbox" id="c-42846818" checked=""/><div class="controls bullet"><span class="by">rafaelmn</span><span>|</span><a href="#42845243">root</a><span>|</span><a href="#42845627">parent</a><span>|</span><a href="#42846146">next</a><span>|</span><label class="collapse" for="c-42846818">[-]</label><label class="expand" for="c-42846818">[2 more]</label></div><br/><div class="children"><div class="content">But is it really moving that fast ? I suspect most fundamental terms in programming and the variations do not change often. You will always have keywords, built ins and the most popular concepts from libs&#x2F;frameworks.<p>So it is basically downloading a few hundred kb dictionary every year ?</div><br/><div id="42848852" class="c"><input type="checkbox" id="c-42848852" checked=""/><div class="controls bullet"><span class="by">MBCook</span><span>|</span><a href="#42845243">root</a><span>|</span><a href="#42846818">parent</a><span>|</span><a href="#42846146">next</a><span>|</span><label class="collapse" for="c-42848852">[-]</label><label class="expand" for="c-42848852">[1 more]</label></div><br/><div class="children"><div class="content">You’d have language keywords and such, yeah.<p>But past that the most common words in a React project are going to be very different from a Vue project right?</div><br/></div></div></div></div><div id="42846146" class="c"><input type="checkbox" id="c-42846146" checked=""/><div class="controls bullet"><span class="by">arccy</span><span>|</span><a href="#42845243">root</a><span>|</span><a href="#42845627">parent</a><span>|</span><a href="#42846818">prev</a><span>|</span><a href="#42841934">next</a><span>|</span><label class="collapse" for="c-42846146">[-]</label><label class="expand" for="c-42846146">[1 more]</label></div><br/><div class="children"><div class="content">would it really change that quickly? you might get significant savings from just having keywords, common variable names, standard library functions</div><br/></div></div></div></div></div></div><div id="42841934" class="c"><input type="checkbox" id="c-42841934" checked=""/><div class="controls bullet"><span class="by">chuckadams</span><span>|</span><a href="#42845243">prev</a><span>|</span><label class="collapse" for="c-42841934">[-]</label><label class="expand" for="c-42841934">[1 more]</label></div><br/><div class="children"><div class="content">Switching to a shared cache in the fashion of pnpm would eliminate far more redundant downloads than a compression algorithm needing 20x more CPU.</div><br/></div></div></div></div></div></div></div></body></html>