<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1687338073373" as="style"/><link rel="stylesheet" href="styles.css?v=1687338073373"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.johndcook.com/blog/2011/09/27/bayesian-amazon/">A Bayesian view of Amazon resellers (2011)</a> <span class="domain">(<a href="https://www.johndcook.com">www.johndcook.com</a>)</span></div><div class="subtext"><span>DantesKite</span> | <span>34 comments</span></div><br/><div><div id="36412403" class="c"><input type="checkbox" id="c-36412403" checked=""/><div class="controls bullet"><span class="by">bbminner</span><span>|</span><a href="#36410007">next</a><span>|</span><label class="collapse" for="c-36412403">[-]</label><label class="expand" for="c-36412403">[3 more]</label></div><br/><div class="children"><div class="content">When I started learning about Bayesian statistics years ago, I was fascinated by the idea that a statistical procedure might take some data in a form like &quot;94% positive out of 85,193 reviews, 98% positive out of 20,785 reviews, 99% positive out of 840 reviews&quot; and give you an objective estimate of who is a more reliable seller. Unfortunately, over time, it become clear that a magic bullet does not exist, and in order for it to give you some estimate of who is a better seller, YOU have to provide it with a rule for how to discount positive reviews based on their count (in a form of a prior). And if you try to cheat by encoding &quot;I don&#x27;t really have a good idea of know how important the number of reviews is&quot;, the statistical procedure will (unsurprisingly) respond with &quot;in that case, I don&#x27;t know really how to re-rank them&quot; :(</div><br/><div id="36412736" class="c"><input type="checkbox" id="c-36412736" checked=""/><div class="controls bullet"><span class="by">MontyCarloHall</span><span>|</span><a href="#36412403">parent</a><span>|</span><a href="#36410007">next</a><span>|</span><label class="collapse" for="c-36412736">[-]</label><label class="expand" for="c-36412736">[2 more]</label></div><br/><div class="children"><div class="content">With that many reviews, any reasonable prior would have an infinitesimally small effect on the posterior. Assuming the Bernoulli model in the blog post, the posterior on the fraction f of good reviews is proportional to<p><pre><code>  p(f|good = 85k*0.94, bad = 85k*0.06) ∝ f^79900*(1 - f)^5100 * f^&lt;p_good = prior number of good review&gt; * (1 - f)^&lt;p_bad = prior number of bad reviews&gt;
  ∝ f^(79900 + p_good)*(1 - f)^(5100 + p_bad)
</code></pre>
Recall that the prior parameters mean that the confidence of your prior knowledge of f is equivalent to having observed p_good positive reviews and p_bad negative reviews. So unless the prior parameters are unreasonably strong (&gt;&gt;1000), any choice of p_good and p_bad will have negligible effect on the posterior.<p>The main reason Bayesian statistics is not a magic bullet is because it&#x27;s up to you to interpret the posterior distribution. What <i>really</i> does it mean that the fraction of positive reviews from seller A is greater than the fraction for seller B with probability 0.713? What if it were 0.64? 0.93? That&#x27;s for you to decide.</div><br/><div id="36412826" class="c"><input type="checkbox" id="c-36412826" checked=""/><div class="controls bullet"><span class="by">nextos</span><span>|</span><a href="#36412403">root</a><span>|</span><a href="#36412736">parent</a><span>|</span><a href="#36410007">next</a><span>|</span><label class="collapse" for="c-36412826">[-]</label><label class="expand" for="c-36412826">[1 more]</label></div><br/><div class="children"><div class="content">Yes, two extra notes on this:<p>1. Weakly informative priors can be good to regularize and stabilize inference in scenarios with a low amount of data.<p>2. In case of the review scenario presented by the OP, a hierarchical model could be even better as it would achieve regularization (and shrinking) by borrowing information across different sellers.<p>In other words, one would learn the overall distribution of seller reliability at the same time as individual ones. This has two advantages: a) Just one (hyper)prior for the overall distribution, but no priors needed at seller level and b) seller predictions are pulled towards the mean in a principled way.<p>Most scientific publications that find unusually large effects coming from some association turn out to be false. If they used shrinking (2), they would avoid excessively optimistic predictions. See: <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Stein%27s_example" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Stein%27s_example</a></div><br/></div></div></div></div></div></div><div id="36410007" class="c"><input type="checkbox" id="c-36410007" checked=""/><div class="controls bullet"><span class="by">frakt0x90</span><span>|</span><a href="#36412403">prev</a><span>|</span><a href="#36411673">next</a><span>|</span><label class="collapse" for="c-36410007">[-]</label><label class="expand" for="c-36410007">[5 more]</label></div><br/><div class="children"><div class="content">If anyone wants to get more into Bayesian stats, I will always recommend Statistical Rethinking by Richard McElreath. Maybe my all time favorite text book. He has an accompanying youtube lecture series as well.</div><br/><div id="36410202" class="c"><input type="checkbox" id="c-36410202" checked=""/><div class="controls bullet"><span class="by">0cf8612b2e1e</span><span>|</span><a href="#36410007">parent</a><span>|</span><a href="#36412149">next</a><span>|</span><label class="collapse" for="c-36410202">[-]</label><label class="expand" for="c-36410202">[2 more]</label></div><br/><div class="children"><div class="content">I thought the book was so-so, but I find his lectures excellent. His second “season” of lectures has some amazing visualizations.</div><br/><div id="36411674" class="c"><input type="checkbox" id="c-36411674" checked=""/><div class="controls bullet"><span class="by">dlivingston</span><span>|</span><a href="#36410007">root</a><span>|</span><a href="#36410202">parent</a><span>|</span><a href="#36412149">next</a><span>|</span><label class="collapse" for="c-36411674">[-]</label><label class="expand" for="c-36411674">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve never seen a &quot;theatrical trailer&quot; for a lecture series before: <a href="https:&#x2F;&#x2F;youtu.be&#x2F;BYUykHScxj8" rel="nofollow noreferrer">https:&#x2F;&#x2F;youtu.be&#x2F;BYUykHScxj8</a></div><br/></div></div></div></div><div id="36412149" class="c"><input type="checkbox" id="c-36412149" checked=""/><div class="controls bullet"><span class="by">Solvency</span><span>|</span><a href="#36410007">parent</a><span>|</span><a href="#36410202">prev</a><span>|</span><a href="#36411673">next</a><span>|</span><label class="collapse" for="c-36412149">[-]</label><label class="expand" for="c-36412149">[2 more]</label></div><br/><div class="children"><div class="content">What prerequisite in math do you need to understand it? Calc&#x2F;linear algebra sufficient?</div><br/><div id="36412356" class="c"><input type="checkbox" id="c-36412356" checked=""/><div class="controls bullet"><span class="by">jihadjihad</span><span>|</span><a href="#36410007">root</a><span>|</span><a href="#36412149">parent</a><span>|</span><a href="#36411673">next</a><span>|</span><label class="collapse" for="c-36412356">[-]</label><label class="expand" for="c-36412356">[1 more]</label></div><br/><div class="children"><div class="content">Really just Algebra II from high school, and Calc I if you want to go deeper. In all honesty if you have a solid handle on Algebra II and some intuition with geometry there is nothing in all of higher math that will be beyond your reach.</div><br/></div></div></div></div></div></div><div id="36411673" class="c"><input type="checkbox" id="c-36411673" checked=""/><div class="controls bullet"><span class="by">akamoonknight</span><span>|</span><a href="#36410007">prev</a><span>|</span><a href="#36409911">next</a><span>|</span><label class="collapse" for="c-36411673">[-]</label><label class="expand" for="c-36411673">[6 more]</label></div><br/><div class="children"><div class="content">Is there an adaptation of Bayesian statistics that also takes into account timeliness of the data ?
e.g. a more recent string of negative reviews would potentially indicate something compared to a more smooth distribution</div><br/><div id="36414031" class="c"><input type="checkbox" id="c-36414031" checked=""/><div class="controls bullet"><span class="by">wenc</span><span>|</span><a href="#36411673">parent</a><span>|</span><a href="#36412071">next</a><span>|</span><label class="collapse" for="c-36414031">[-]</label><label class="expand" for="c-36414031">[1 more]</label></div><br/><div class="children"><div class="content">There two approaches:<p>1) A moving window: you only calculate your updates from the values in the window (say the last n reviews). The downside of this method is that older values drop off precipitously.<p>2) A forgetting factor: there are many possibilities but one simple one is the EWMA (exponentially weighted moving average). This is pretty standard, and takes the form<p><pre><code>  Y_updated = alpha x Y_current + (1 - alpha) x Y_previous
</code></pre>
with alpha in [0,1]. Applying this recursively, it &quot;forgets&quot; older values by weight alpha. This is also known as exponential smoothing in time series. The advantage of this method is that older values are simply weighed less and drop out more gradually.</div><br/></div></div><div id="36412071" class="c"><input type="checkbox" id="c-36412071" checked=""/><div class="controls bullet"><span class="by">MontyCarloHall</span><span>|</span><a href="#36411673">parent</a><span>|</span><a href="#36414031">prev</a><span>|</span><a href="#36412109">next</a><span>|</span><label class="collapse" for="c-36412071">[-]</label><label class="expand" for="c-36412071">[1 more]</label></div><br/><div class="children"><div class="content">Sure—you just use a likelihood function that doesn’t assume reviews are independently and identically distributed (where each review is an independent Bernoulli trial) but rather have some dependence on other reviews that are nearby in time. For example, a (Markov) switching autoregressive model, e.g. [0].<p>Everything else about Bayes’ rule (weighting likelihood by a prior distribution and re-normalizing to obtain a distribution over model parameters) applies just the same.<p>[0] <a href="https:&#x2F;&#x2F;www.statsmodels.org&#x2F;dev&#x2F;examples&#x2F;notebooks&#x2F;generated&#x2F;markov_autoregression.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.statsmodels.org&#x2F;dev&#x2F;examples&#x2F;notebooks&#x2F;generated...</a></div><br/></div></div><div id="36412109" class="c"><input type="checkbox" id="c-36412109" checked=""/><div class="controls bullet"><span class="by">nuclearnice3</span><span>|</span><a href="#36411673">parent</a><span>|</span><a href="#36412071">prev</a><span>|</span><a href="#36412412">next</a><span>|</span><label class="collapse" for="c-36412109">[-]</label><label class="expand" for="c-36412109">[1 more]</label></div><br/><div class="children"><div class="content">Two thoughts.<p>1. There is a vast literature in &quot;Bayesian Change Point Detection.&quot; So you might find a point where something changed and a string of negative reviews began.<p><a href="https:&#x2F;&#x2F;dataorigami.net&#x2F;Probabilistic-Programming-and-Bayesian-Methods-for-Hackers&#x2F;#examples" rel="nofollow noreferrer">https:&#x2F;&#x2F;dataorigami.net&#x2F;Probabilistic-Programming-and-Bayesi...</a><p>2. Similarly, there a bajillion ways to weight recent data. One way is to increase the gain on a kalman filter. That will make recent observations more important. There are bayesian implementations of the Kalman filter.<p><a href="http:&#x2F;&#x2F;stefanosnikolaidis.net&#x2F;course-files&#x2F;CS545&#x2F;Lecture6.pdf" rel="nofollow noreferrer">http:&#x2F;&#x2F;stefanosnikolaidis.net&#x2F;course-files&#x2F;CS545&#x2F;Lecture6.pd...</a></div><br/></div></div><div id="36412412" class="c"><input type="checkbox" id="c-36412412" checked=""/><div class="controls bullet"><span class="by">inimino</span><span>|</span><a href="#36411673">parent</a><span>|</span><a href="#36412109">prev</a><span>|</span><a href="#36411797">next</a><span>|</span><label class="collapse" for="c-36412412">[-]</label><label class="expand" for="c-36412412">[1 more]</label></div><br/><div class="children"><div class="content">Bayesian analysis means you set up at least two models and evaluate the likelihood of the observed data under each. In this case rather than assume a fixed probability of good reviews, you might model a sudden switch (for example if an account was taken over or sold) or a gradual decline (for example if a manufacturer gradually lowers quality). Then you proceed as usual from that point. (I.e. find likelihoods and assign priors for each hypothesis&#x2F;model, and use Bayes&#x27; rule.)</div><br/></div></div><div id="36411797" class="c"><input type="checkbox" id="c-36411797" checked=""/><div class="controls bullet"><span class="by">jeffreyrogers</span><span>|</span><a href="#36411673">parent</a><span>|</span><a href="#36412412">prev</a><span>|</span><a href="#36409911">next</a><span>|</span><label class="collapse" for="c-36411797">[-]</label><label class="expand" for="c-36411797">[1 more]</label></div><br/><div class="children"><div class="content">I think you would change the prior in that situation under the assumption that it indicates some sort of underlying shift. I&#x27;m not sure that there is any theory guiding how you do that though.</div><br/></div></div></div></div><div id="36409911" class="c"><input type="checkbox" id="c-36409911" checked=""/><div class="controls bullet"><span class="by">OscarCunningham</span><span>|</span><a href="#36411673">prev</a><span>|</span><a href="#36409880">next</a><span>|</span><label class="collapse" for="c-36409911">[-]</label><label class="expand" for="c-36409911">[2 more]</label></div><br/><div class="children"><div class="content">(2011) The old days when Amazon reviews carried information.</div><br/><div id="36410600" class="c"><input type="checkbox" id="c-36410600" checked=""/><div class="controls bullet"><span class="by">jldugger</span><span>|</span><a href="#36409911">parent</a><span>|</span><a href="#36409880">next</a><span>|</span><label class="collapse" for="c-36410600">[-]</label><label class="expand" for="c-36410600">[1 more]</label></div><br/><div class="children"><div class="content">Yea, things get a bit more dire if you build an adversarial model where resellers are allowed to declare reputation bankruptcy.</div><br/></div></div></div></div><div id="36409880" class="c"><input type="checkbox" id="c-36409880" checked=""/><div class="controls bullet"><span class="by">dataflow</span><span>|</span><a href="#36409911">prev</a><span>|</span><a href="#36413371">next</a><span>|</span><label class="collapse" for="c-36409880">[-]</label><label class="expand" for="c-36409880">[4 more]</label></div><br/><div class="children"><div class="content">See also <a href="https:&#x2F;&#x2F;www.evanmiller.org&#x2F;how-not-to-sort-by-average-rating.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.evanmiller.org&#x2F;how-not-to-sort-by-average-rating...</a></div><br/><div id="36413137" class="c"><input type="checkbox" id="c-36413137" checked=""/><div class="controls bullet"><span class="by">10000truths</span><span>|</span><a href="#36409880">parent</a><span>|</span><a href="#36411957">next</a><span>|</span><label class="collapse" for="c-36413137">[-]</label><label class="expand" for="c-36413137">[1 more]</label></div><br/><div class="children"><div class="content">Even more relevant, Evan Miller has an article on this exact topic (using Bayesian statistics to calculate ratings) that goes into further detail than the original article:<p><a href="https:&#x2F;&#x2F;www.evanmiller.org&#x2F;bayesian-average-ratings.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.evanmiller.org&#x2F;bayesian-average-ratings.html</a></div><br/></div></div><div id="36411957" class="c"><input type="checkbox" id="c-36411957" checked=""/><div class="controls bullet"><span class="by">KerrickStaley</span><span>|</span><a href="#36409880">parent</a><span>|</span><a href="#36413137">prev</a><span>|</span><a href="#36413371">next</a><span>|</span><label class="collapse" for="c-36411957">[-]</label><label class="expand" for="c-36411957">[2 more]</label></div><br/><div class="children"><div class="content">I like Evan’s 2009 post a lot, but I like John’s analysis here even better. John seems to make fewer assumptions; in particular, Evan assumes a 95% confidence bound.</div><br/><div id="36412565" class="c"><input type="checkbox" id="c-36412565" checked=""/><div class="controls bullet"><span class="by">wenc</span><span>|</span><a href="#36409880">root</a><span>|</span><a href="#36411957">parent</a><span>|</span><a href="#36413371">next</a><span>|</span><label class="collapse" for="c-36412565">[-]</label><label class="expand" for="c-36412565">[1 more]</label></div><br/><div class="children"><div class="content">In Evan’s derivation, which derives the lower Wilson confidence interval on a binomial distribution, the confidence level is a parameter — you can replace it with any level desired. He just happened to use 1.96 for 95%.<p>John’s derivation is not based on the Wilson score but a Bayesian update on a beta distribution. They’re actually different algorithms. He starts a beta(1,1) and keeps updating. The advantage of John’s method is you get the variance as well but now to sort you have to technically calculate differences between normal distributions which is more involved (or you can ignore the variance and sort by the mean)<p>Both work for normalizing sort order so that small samples don’t get biased. But as the sample sizes get larger they both converge to the expectation by the law of large numbers.<p>I personally use the Wilson score method in my work and it’s easy to calculate and good enough for all practical purposes.</div><br/></div></div></div></div></div></div><div id="36413371" class="c"><input type="checkbox" id="c-36413371" checked=""/><div class="controls bullet"><span class="by">jtrip</span><span>|</span><a href="#36409880">prev</a><span>|</span><a href="#36413127">next</a><span>|</span><label class="collapse" for="c-36413371">[-]</label><label class="expand" for="c-36413371">[2 more]</label></div><br/><div class="children"><div class="content">Can someone tell me the answer to the problem in plain english? I have no idea what a beta is.</div><br/><div id="36413978" class="c"><input type="checkbox" id="c-36413978" checked=""/><div class="controls bullet"><span class="by">fumeux_fume</span><span>|</span><a href="#36413371">parent</a><span>|</span><a href="#36413127">next</a><span>|</span><label class="collapse" for="c-36413978">[-]</label><label class="expand" for="c-36413978">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a poorly written article that&#x27;s almost completely useless for people actually interested in this type of problem. The Beta distribution models the uncertainty of a seller&#x27;s positive ratio given their total count of positive reviews (a) and negative reviews (b).</div><br/></div></div></div></div><div id="36413196" class="c"><input type="checkbox" id="c-36413196" checked=""/><div class="controls bullet"><span class="by">derbOac</span><span>|</span><a href="#36413127">prev</a><span>|</span><a href="#36410055">next</a><span>|</span><label class="collapse" for="c-36413196">[-]</label><label class="expand" for="c-36413196">[1 more]</label></div><br/><div class="children"><div class="content">I think Amazon used to use the lower bound of a CI to sort? Or it used to be an option, then some sellers sued or threatened to based on the argument that it discriminated against smaller sellers?</div><br/></div></div><div id="36410055" class="c"><input type="checkbox" id="c-36410055" checked=""/><div class="controls bullet"><span class="by">dwighttk</span><span>|</span><a href="#36413196">prev</a><span>|</span><a href="#36409997">next</a><span>|</span><label class="collapse" for="c-36410055">[-]</label><label class="expand" for="c-36410055">[1 more]</label></div><br/><div class="children"><div class="content">hmm... I might start discounting sellers with too many reviews. Not sure where the cutoff would be and some sellers might actually be high volume and get lots of reviews, but a huge number of reviews makes me think they are fake.</div><br/></div></div><div id="36409997" class="c"><input type="checkbox" id="c-36409997" checked=""/><div class="controls bullet"><span class="by">great_psy</span><span>|</span><a href="#36410055">prev</a><span>|</span><a href="#36413151">next</a><span>|</span><label class="collapse" for="c-36409997">[-]</label><label class="expand" for="c-36409997">[6 more]</label></div><br/><div class="children"><div class="content">A lot of words to describe bayes rule</div><br/><div id="36411653" class="c"><input type="checkbox" id="c-36411653" checked=""/><div class="controls bullet"><span class="by">ted_bunny</span><span>|</span><a href="#36409997">parent</a><span>|</span><a href="#36411080">next</a><span>|</span><label class="collapse" for="c-36411653">[-]</label><label class="expand" for="c-36411653">[2 more]</label></div><br/><div class="children"><div class="content">Am I the only one who finds it intuitive and simple? Every article seems to give it a whole chapter of explanation, and vaunt it as the most groundbreaking concept ever. First I thought that was just Rationalists sniffing their farts, but I see it in a lot of places.</div><br/><div id="36412158" class="c"><input type="checkbox" id="c-36412158" checked=""/><div class="controls bullet"><span class="by">Solvency</span><span>|</span><a href="#36409997">root</a><span>|</span><a href="#36411653">parent</a><span>|</span><a href="#36411080">next</a><span>|</span><label class="collapse" for="c-36412158">[-]</label><label class="expand" for="c-36412158">[1 more]</label></div><br/><div class="children"><div class="content">How would you summarize and convey it to be as simple and intuitive as you understand it?</div><br/></div></div></div></div><div id="36411080" class="c"><input type="checkbox" id="c-36411080" checked=""/><div class="controls bullet"><span class="by">DaiPlusPlus</span><span>|</span><a href="#36409997">parent</a><span>|</span><a href="#36411653">prev</a><span>|</span><a href="#36411563">next</a><span>|</span><label class="collapse" for="c-36411080">[-]</label><label class="expand" for="c-36411080">[1 more]</label></div><br/><div class="children"><div class="content">Sometimes that&#x27;s necessary - a lot of Bayesian-<i>stuff</i> is very counter-intuitive.</div><br/></div></div><div id="36411563" class="c"><input type="checkbox" id="c-36411563" checked=""/><div class="controls bullet"><span class="by">mathgeek</span><span>|</span><a href="#36409997">parent</a><span>|</span><a href="#36411080">prev</a><span>|</span><a href="#36410531">next</a><span>|</span><label class="collapse" for="c-36411563">[-]</label><label class="expand" for="c-36411563">[1 more]</label></div><br/><div class="children"><div class="content">Essentially this. There are many more variables involved in that specific example, such as time since last negative feedback, total age of account, feedback over the last 90 days, etc.</div><br/></div></div><div id="36410531" class="c"><input type="checkbox" id="c-36410531" checked=""/><div class="controls bullet"><span class="by">DarkNova6</span><span>|</span><a href="#36409997">parent</a><span>|</span><a href="#36411563">prev</a><span>|</span><a href="#36413151">next</a><span>|</span><label class="collapse" for="c-36410531">[-]</label><label class="expand" for="c-36410531">[1 more]</label></div><br/><div class="children"><div class="content">This and nothing else</div><br/></div></div></div></div><div id="36412443" class="c"><input type="checkbox" id="c-36412443" checked=""/><div class="controls bullet"><span class="by">jjtheblunt</span><span>|</span><a href="#36413151">prev</a><span>|</span><label class="collapse" for="c-36412443">[-]</label><label class="expand" for="c-36412443">[1 more]</label></div><br/><div class="children"><div class="content">needs 2011</div><br/></div></div></div></div></div></div></div></body></html>