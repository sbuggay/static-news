<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1722070848590" as="style"/><link rel="stylesheet" href="styles.css?v=1722070848590"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://statmodeling.stat.columbia.edu/2024/07/10/three-cultures-bayes-subjective-objective-pragmatic/">Bayesian Statistics: The three cultures</a> <span class="domain">(<a href="https://statmodeling.stat.columbia.edu">statmodeling.stat.columbia.edu</a>)</span></div><div class="subtext"><span>luu</span> | <span>97 comments</span></div><br/><div><div id="41081746" class="c"><input type="checkbox" id="c-41081746" checked=""/><div class="controls bullet"><span class="by">tfehring</span><span>|</span><a href="#41085192">next</a><span>|</span><label class="collapse" for="c-41081746">[-]</label><label class="expand" for="c-41081746">[14 more]</label></div><br/><div class="children"><div class="content">The author is claiming that Bayesians vary along two axes: (1) whether they generally try to inform their priors with their knowledge or beliefs about the world, and (2) whether they iterate on the functional form of the model based on its goodness-of-fit and the reasonableness and utility of its outputs. He then labels 3 of the 4 resulting combinations as follows:<p><pre><code>    ┌───────────────┬───────────┬──────────────┐
    │               │ iteration │ no iteration │
    ├───────────────┼───────────┼──────────────┤
    │ informative   │ pragmatic │ subjective   │
    │ uninformative │     -     │ objective    │
    └───────────────┴───────────┴──────────────┘
</code></pre>
My main disagreement with this model is the empty bottom-left box - in fact, I think that&#x27;s where most self-labeled Bayesians in industry fall:<p>- Iterating on the functional form of the model (and therefore the assumed underlying data generating process) is generally considered obviously good and necessary, in my experience.<p>- Priors are <i>usually</i> uninformative or weakly informative, partly because data is often big enough to overwhelm the prior.<p>The need for iteration feels so obvious to me that the entire &quot;no iteration&quot; column feels like a straw man. But the author, who knows far more academic statisticians than I do, explicitly says that he had the same belief and &quot;was shocked to learn that statisticians didn’t think this way.&quot;</div><br/><div id="41081867" class="c"><input type="checkbox" id="c-41081867" checked=""/><div class="controls bullet"><span class="by">klysm</span><span>|</span><a href="#41081746">parent</a><span>|</span><a href="#41084103">next</a><span>|</span><label class="collapse" for="c-41081867">[-]</label><label class="expand" for="c-41081867">[8 more]</label></div><br/><div class="children"><div class="content">The no iteration thing is very real and I don’t think it’s even for particularly bad reasons. We iterate on models to make them better, by some definition of better. It’s no secret that scientific work is subject to rather perverse incentives around thresholds of significance and positive results. Publish or perish. Perverse incentives lead to perverse statistics.<p>The iteration itself is sometimes viewed directly as a problem. The “garden of forking paths”, where the analysis depends on the data, is viewed as a direct cause for some of the statistical and epistemological crises in science today.<p>Iteration itself isn’t inherently bad. It’s just that the objective function usually isn’t what we want from a scientific perspective.<p>To those actually doing scientific work, I suspect iterating on their models feels like they’re doing something unfaithful.<p>Furthermore, I believe a lot of these issues are strongly related to the flawed epistemological framework which many scientific fields seem to have converged: p&lt;0.05 means it’s true, otherwise it’s false.<p>edit:<p>Perhaps another way to characterize this discomfort is by the number of degrees of freedom that the analyst controls. In a Bayesian context where we are picking priors either by belief or previous data, the analyst has a _lot_ of control over how the results come out the other end.<p>I think this is why fields have trended towards a set of ‘standard’ tests instead of building good statistical models. These take most of the knobs out of the hands of the analyst, and generally are more conservative.</div><br/><div id="41082720" class="c"><input type="checkbox" id="c-41082720" checked=""/><div class="controls bullet"><span class="by">joeyo</span><span>|</span><a href="#41081746">root</a><span>|</span><a href="#41081867">parent</a><span>|</span><a href="#41081904">next</a><span>|</span><label class="collapse" for="c-41082720">[-]</label><label class="expand" for="c-41082720">[2 more]</label></div><br/><div class="children"><div class="content"><p><pre><code>  &gt; Iteration itself isn’t inherently bad. It’s just that the objective
  &gt; function usually isn’t what we want from a scientific perspective.
</code></pre>
I think this is exactly right and touches on a key difference between science and engineering.<p><i>Science</i>: Is treatment A better than treatment B?<p><i>Engineering</i>: I would like to make a better treatment B.<p>Iteration is harmful for the first goal yet essential for the second. I work in an applied science&#x2F;engineering field where both perspectives exist. (and are necessary!) Which specific path is taken for any given experiment or analysis will depends on which goal one is trying to achieve. Conflict will sometimes arise when it&#x27;s not clear which of these two objectives is the important one.</div><br/><div id="41082852" class="c"><input type="checkbox" id="c-41082852" checked=""/><div class="controls bullet"><span class="by">jiggawatts</span><span>|</span><a href="#41081746">root</a><span>|</span><a href="#41082720">parent</a><span>|</span><a href="#41081904">next</a><span>|</span><label class="collapse" for="c-41082852">[-]</label><label class="expand" for="c-41082852">[1 more]</label></div><br/><div class="children"><div class="content">There is <i>no difference</i> between comparing A versus B or B1 versus B2. The data  collection process and and the mathematical methods are (typically) identical or subject to the same issues.<p>E.g.: profiling an existing application and tuning its performance is comparing two products, it just so happens that they’re different versions of the same series. If you compared it to a competing vendor’s product you should use the same mathematical analysis process.</div><br/></div></div></div></div><div id="41081904" class="c"><input type="checkbox" id="c-41081904" checked=""/><div class="controls bullet"><span class="by">slashdave</span><span>|</span><a href="#41081746">root</a><span>|</span><a href="#41081867">parent</a><span>|</span><a href="#41082720">prev</a><span>|</span><a href="#41082486">next</a><span>|</span><label class="collapse" for="c-41081904">[-]</label><label class="expand" for="c-41081904">[3 more]</label></div><br/><div class="children"><div class="content">In particle physics, it was quite fashionable (and may still be) to iterate on blinded data (data deliberated altered by a secret, random number, and&#x2F;or relying entirely on Monte Carlo simulation).</div><br/><div id="41082107" class="c"><input type="checkbox" id="c-41082107" checked=""/><div class="controls bullet"><span class="by">klysm</span><span>|</span><a href="#41081746">root</a><span>|</span><a href="#41081904">parent</a><span>|</span><a href="#41082159">next</a><span>|</span><label class="collapse" for="c-41082107">[-]</label><label class="expand" for="c-41082107">[1 more]</label></div><br/><div class="children"><div class="content">Interesting I wasn’t aware of that. Another thing I’ve only briefly read about is registering studies in advance, and quite literally preventing iteration.</div><br/></div></div><div id="41082159" class="c"><input type="checkbox" id="c-41082159" checked=""/><div class="controls bullet"><span class="by">bordercases</span><span>|</span><a href="#41081746">root</a><span>|</span><a href="#41081904">parent</a><span>|</span><a href="#41082107">prev</a><span>|</span><a href="#41082486">next</a><span>|</span><label class="collapse" for="c-41082159">[-]</label><label class="expand" for="c-41082159">[1 more]</label></div><br/><div class="children"><div class="content">Yeah it&#x27;s essentially a way to reflect parsimonious assumptions so that your output distribution can be characterized as a law.</div><br/></div></div></div></div><div id="41082486" class="c"><input type="checkbox" id="c-41082486" checked=""/><div class="controls bullet"><span class="by">j7ake</span><span>|</span><a href="#41081746">root</a><span>|</span><a href="#41081867">parent</a><span>|</span><a href="#41081904">prev</a><span>|</span><a href="#41084103">next</a><span>|</span><label class="collapse" for="c-41082486">[-]</label><label class="expand" for="c-41082486">[2 more]</label></div><br/><div class="children"><div class="content">Iteration is necessary for any analysis. To safeguard yourself from overfitting, be sure to have a hold out dataset that hasn’t been touched until the end.</div><br/><div id="41084424" class="c"><input type="checkbox" id="c-41084424" checked=""/><div class="controls bullet"><span class="by">laichzeit0</span><span>|</span><a href="#41081746">root</a><span>|</span><a href="#41082486">parent</a><span>|</span><a href="#41084103">next</a><span>|</span><label class="collapse" for="c-41084424">[-]</label><label class="expand" for="c-41084424">[1 more]</label></div><br/><div class="children"><div class="content">What about automated predictive modeling pipelines? In other words, I want the best possible point estimates only on future data. I’d think, regardless of the model selection process, I want to reestimate the parameters on the entire dataset before I deploy it, so as not to “waste” data? I.e. I want to use the hold out test data in the final model. Is this valid?</div><br/></div></div></div></div></div></div><div id="41084103" class="c"><input type="checkbox" id="c-41084103" checked=""/><div class="controls bullet"><span class="by">opensandwich</span><span>|</span><a href="#41081746">parent</a><span>|</span><a href="#41081867">prev</a><span>|</span><a href="#41082105">next</a><span>|</span><label class="collapse" for="c-41084103">[-]</label><label class="expand" for="c-41084103">[2 more]</label></div><br/><div class="children"><div class="content">As someone who isn&#x27;t particularly well-versed in Bayesian &quot;stuff&quot;. Does Bayesian non-parametric methods fall under &quot;uninformative&quot; + &quot;iteration&quot; approach?<p>I have a feeling I&#x27;m just totally barking up the wrong tree, but don&#x27;t know where my thinking&#x2F;understanding is just off.</div><br/><div id="41085201" class="c"><input type="checkbox" id="c-41085201" checked=""/><div class="controls bullet"><span class="by">mjburgess</span><span>|</span><a href="#41081746">root</a><span>|</span><a href="#41084103">parent</a><span>|</span><a href="#41082105">next</a><span>|</span><label class="collapse" for="c-41085201">[-]</label><label class="expand" for="c-41085201">[1 more]</label></div><br/><div class="children"><div class="content">Non-parametric models can be generically understood as parametric on order statistics.</div><br/></div></div></div></div><div id="41082105" class="c"><input type="checkbox" id="c-41082105" checked=""/><div class="controls bullet"><span class="by">Onavo</span><span>|</span><a href="#41081746">parent</a><span>|</span><a href="#41084103">prev</a><span>|</span><a href="#41085192">next</a><span>|</span><label class="collapse" for="c-41082105">[-]</label><label class="expand" for="c-41082105">[3 more]</label></div><br/><div class="children"><div class="content">Interesting, in my experience modern ML runs almost entirely on pragmatic Bayes. You find your ELBO, you choose the latest latent variable du jour that best models your problem domain (these days it&#x27;s all transformers), and then you start running experiments.</div><br/><div id="41082455" class="c"><input type="checkbox" id="c-41082455" checked=""/><div class="controls bullet"><span class="by">tfehring</span><span>|</span><a href="#41081746">root</a><span>|</span><a href="#41082105">parent</a><span>|</span><a href="#41085192">next</a><span>|</span><label class="collapse" for="c-41082455">[-]</label><label class="expand" for="c-41082455">[2 more]</label></div><br/><div class="children"><div class="content">I think each category of Bayesian described in the article generally falls under Breiman&#x27;s [0] &quot;data modeling&quot; culture, while ML practitioners, even when using Bayesian methods, almost invariably fall under the &quot;algorithmic modeling&quot; culture. In particular, the article&#x27;s definition of pragmatic Bayes says that &quot;the model should be consistent with knowledge about the underlying scientific problem and the data collection process,&quot; which I don&#x27;t consider the norm in ML at all.<p>I do think ML practitioners in general align with the &quot;iteration&quot; category in my characterization, though you could joke that that miscategorizes people who just use (boosted trees|transformers) for everything.<p>[0] <a href="https:&#x2F;&#x2F;projecteuclid.org&#x2F;journals&#x2F;statistical-science&#x2F;volume-16&#x2F;issue-3&#x2F;Statistical-Modeling--The-Two-Cultures-with-comments-and-a&#x2F;10.1214&#x2F;ss&#x2F;1009213726.full" rel="nofollow">https:&#x2F;&#x2F;projecteuclid.org&#x2F;journals&#x2F;statistical-science&#x2F;volum...</a></div><br/><div id="41083670" class="c"><input type="checkbox" id="c-41083670" checked=""/><div class="controls bullet"><span class="by">nextos</span><span>|</span><a href="#41081746">root</a><span>|</span><a href="#41082455">parent</a><span>|</span><a href="#41085192">next</a><span>|</span><label class="collapse" for="c-41083670">[-]</label><label class="expand" for="c-41083670">[1 more]</label></div><br/><div class="children"><div class="content">&gt; the model should be consistent with knowledge about the problem [...] which I don&#x27;t consider the norm in ML at all.<p>I don&#x27;t think that is so niche. Murphy&#x27;s vol II, a mainstream book, starts with this quote:<p><i>&quot;Intelligence is not just about pattern recognition and function approximation. It’s about modeling the world.&quot;</i>
— Josh Tenenbaum, NeurIPS 2021.<p>Goodman &amp; Tenenbaum have written e.g. <a href="https:&#x2F;&#x2F;probmods.org" rel="nofollow">https:&#x2F;&#x2F;probmods.org</a>, which is very much about modeling data-generating processes.<p>The same can be said about large parts of Murphy&#x27;s book, Lee &amp; Wagenmakers or Lunn et al. (the BUGS book).</div><br/></div></div></div></div></div></div></div></div><div id="41085192" class="c"><input type="checkbox" id="c-41085192" checked=""/><div class="controls bullet"><span class="by">usgroup</span><span>|</span><a href="#41081746">prev</a><span>|</span><a href="#41081759">next</a><span>|</span><label class="collapse" for="c-41085192">[-]</label><label class="expand" for="c-41085192">[1 more]</label></div><br/><div class="children"><div class="content">Bare in mind that Breiman&#x27;s polemic was about generative vs discriminative methods. I.e. that we should not start an analysis by thinking about how the data generation can be modelled, but instead we should start with prediction. From that vein came boosted trees, bagging, random forests, xgboost and so on: non generative black box methods.<p>Still today most of the classical machine learning toolbox is not generative.</div><br/></div></div><div id="41081759" class="c"><input type="checkbox" id="c-41081759" checked=""/><div class="controls bullet"><span class="by">derbOac</span><span>|</span><a href="#41085192">prev</a><span>|</span><a href="#41080693">next</a><span>|</span><label class="collapse" for="c-41081759">[-]</label><label class="expand" for="c-41081759">[1 more]</label></div><br/><div class="children"><div class="content">I never liked the clubs you were expected to put yourself in, what &quot;side&quot; you were on, or the idea that problems in science that we see today could somehow be reduced to the inferential philosophy you adopt. In a lot of ways I see myself as information-theoretic in orientation, so maybe objective Bayesian, although it&#x27;s really neither frequentist nor Bayesian.<p>This three cultures idea is a bit of slight of hand in my opinion, as the &quot;pragmatic&quot; culture isn&#x27;t really exclusive of subjective or objective Bayesianism and in that sense says nothing about how you should approach prior specification or interpretation or anything. Maybe Gelman would say a better term is &quot;flexibility&quot; or something but then that leaves the question of when you go objective and when you go subjective and why. Seems better to formalize that than leave it as a bit of smoke and mirrors. I&#x27;m not saying some flexibility about prior interpretation and specification isn&#x27;t a good idea, just that I&#x27;m not sure that approaching theoretical basics with the answer &quot;we&#x27;ll just ignore the issues and pretend we&#x27;re doing something different&quot; is quite the right answer.<p>Playing a bit of devil&#x27;s advocate too, the &quot;pragmatic&quot; culture reveals a bit about <i>why</i> Bayesianism is looked at with a bit of skepticism and doubt. &quot;Choosing a prior&quot; followed by &quot;seeing how well everything fits&quot; and then &quot;repeating&quot; looks a lot like model tweaking or p-hacking. I know that&#x27;s not the intent, and it&#x27;s impossible to do modeling without tweaking, but if you approach things that way, the prior just looks like one more degree of freedom to nudge things around and fish with.<p>I&#x27;ve published and edited papers on Bayesian inference, and my feeling is that the problems with it have never been in the theory, which is solid. It&#x27;s in how people use and abuse it in practice.</div><br/></div></div><div id="41080693" class="c"><input type="checkbox" id="c-41080693" checked=""/><div class="controls bullet"><span class="by">thegginthesky</span><span>|</span><a href="#41081759">prev</a><span>|</span><a href="#41082012">next</a><span>|</span><label class="collapse" for="c-41080693">[-]</label><label class="expand" for="c-41080693">[38 more]</label></div><br/><div class="children"><div class="content">I miss the college days where professors would argue endlessly on Bayesian vs Frequentist.<p>The article is very well succinct and even explains why even my Bayesian professors had different approaches to research and analysis. I never knew about the third camp, Pragmatic Bayes, but definitely is in line with a professor&#x27;s research that was very through on probability fit and the many iteration to get the prior and joint PDF just right.<p>Andrew Gelman has a very cool talk &quot;Andrew Gelman - Bayes, statistics, and reproducibility (Rutgers, Foundations of Probability)&quot;, which I highly recommend for many Data Scientists</div><br/><div id="41080990" class="c"><input type="checkbox" id="c-41080990" checked=""/><div class="controls bullet"><span class="by">bunderbunder</span><span>|</span><a href="#41080693">parent</a><span>|</span><a href="#41080841">next</a><span>|</span><label class="collapse" for="c-41080990">[-]</label><label class="expand" for="c-41080990">[2 more]</label></div><br/><div class="children"><div class="content">Link to talk: <a href="https:&#x2F;&#x2F;youtu.be&#x2F;xgUBdi2wcDI" rel="nofollow">https:&#x2F;&#x2F;youtu.be&#x2F;xgUBdi2wcDI</a></div><br/><div id="41081202" class="c"><input type="checkbox" id="c-41081202" checked=""/><div class="controls bullet"><span class="by">mturmon</span><span>|</span><a href="#41080693">root</a><span>|</span><a href="#41080990">parent</a><span>|</span><a href="#41080841">next</a><span>|</span><label class="collapse" for="c-41081202">[-]</label><label class="expand" for="c-41081202">[1 more]</label></div><br/><div class="children"><div class="content">Thank you.<p>In fact, the whole talk series (<a href="https:&#x2F;&#x2F;foundationsofprobabilityseminar.com&#x2F;" rel="nofollow">https:&#x2F;&#x2F;foundationsofprobabilityseminar.com&#x2F;</a>) and channel (<a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;@foundationsofprobabilitypa2408&#x2F;videos" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;@foundationsofprobabilitypa2408&#x2F;vide...</a>) seem interesting.</div><br/></div></div></div></div><div id="41080841" class="c"><input type="checkbox" id="c-41080841" checked=""/><div class="controls bullet"><span class="by">spootze</span><span>|</span><a href="#41080693">parent</a><span>|</span><a href="#41080990">prev</a><span>|</span><a href="#41080979">next</a><span>|</span><label class="collapse" for="c-41080841">[-]</label><label class="expand" for="c-41080841">[15 more]</label></div><br/><div class="children"><div class="content">Regarding the frequentist vs bayesian debates, my slightly provocative take on these three cultures is<p>- subjective Bayes is the strawman that frequentist academics like to attack<p>- objective Bayes is a naive self-image that many Bayesian academics tend to possess<p>- pragmatic Bayes is the approach taken by practitioners that actually apply statistics to something (or in Gelman’s terms, do science)</div><br/><div id="41081400" class="c"><input type="checkbox" id="c-41081400" checked=""/><div class="controls bullet"><span class="by">DebtDeflation</span><span>|</span><a href="#41080693">root</a><span>|</span><a href="#41080841">parent</a><span>|</span><a href="#41083494">next</a><span>|</span><label class="collapse" for="c-41081400">[-]</label><label class="expand" for="c-41081400">[3 more]</label></div><br/><div class="children"><div class="content">A few things I wish I knew when took Statistics courses at university some 25 or so years ago:<p>- Statistical significance testing and hypothesis testing are two completely different approaches with different philosophies behind them developed by different groups of people that kinda do the same thing but not quite and textbooks tend to completely blur this distinction out.<p>- The above approaches were developed in the early 1900s in the context of farms and breweries where 3 things were true - 1) data was extremely limited, often there were only 5 or 6 data points available, 2) there were no electronic computers, so computation was limited to pen and paper and slide rules, and 3) the cost in terms of time and money of running experiments (e.g., planting a crop differently and waiting for harvest) were enormous.<p>- The majority of classical statistics was focused on two simple questions - 1) what can I reliably say about a population based on a sample taken from it and 2) what can I reliably about the differences between two populations based on the samples taken from each?  That&#x27;s it.  An enormous mathematical apparatus was built around answering those two questions in the context of the limitations in point #2.</div><br/><div id="41084820" class="c"><input type="checkbox" id="c-41084820" checked=""/><div class="controls bullet"><span class="by">lottin</span><span>|</span><a href="#41080693">root</a><span>|</span><a href="#41081400">parent</a><span>|</span><a href="#41081784">next</a><span>|</span><label class="collapse" for="c-41084820">[-]</label><label class="expand" for="c-41084820">[1 more]</label></div><br/><div class="children"><div class="content">My understanding is that frequentist statistics was developed <i>in response</i> to the Bayesian methodology which was prevalent in the 1800s and which was starting to be perceived as having important flaws.  The idea that the invention of Bayesian statistics made frequentist statistics obsolete doesn&#x27;t quite agree with the historical facts.</div><br/></div></div><div id="41081784" class="c"><input type="checkbox" id="c-41081784" checked=""/><div class="controls bullet"><span class="by">ivan_ah</span><span>|</span><a href="#41080693">root</a><span>|</span><a href="#41081400">parent</a><span>|</span><a href="#41084820">prev</a><span>|</span><a href="#41083494">next</a><span>|</span><label class="collapse" for="c-41081784">[-]</label><label class="expand" for="c-41081784">[1 more]</label></div><br/><div class="children"><div class="content">That was a nice summary.<p>The data-poor and computation-poor context of old school statistics definitely biased the methods towards the &quot;recipe&quot; approach scientists are supposed to follow mechanically, where each recipe is some predefined sequence of steps, justified based on an analytical approximations to a sampling distribution (given lots of assumptions).<p>In modern computation-rich days, we can get away from the recipes by using resampling methods (e.g. permutation tests and bootstrap), so we don&#x27;t need the analytical approximation formulas anymore.<p>I think there is still room for small sample methods though... it&#x27;s not like biological and social sciences are dealing with very large samples.</div><br/></div></div></div></div><div id="41083494" class="c"><input type="checkbox" id="c-41083494" checked=""/><div class="controls bullet"><span class="by">skissane</span><span>|</span><a href="#41080693">root</a><span>|</span><a href="#41080841">parent</a><span>|</span><a href="#41081400">prev</a><span>|</span><a href="#41081070">next</a><span>|</span><label class="collapse" for="c-41083494">[-]</label><label class="expand" for="c-41083494">[1 more]</label></div><br/><div class="children"><div class="content">&gt; - subjective Bayes is the strawman that frequentist academics like to attack<p>I don’t get what all the hate for subjective Bayesianism is. It seems the most philosophically defensible approach, in that all it assumes is our own subjective judgements of likelihood, the idea that we can quantify them (however in exactly), and the idea (avoid Dutch books) that we want to be consistent (most people do).<p>Whereas, objective Bayes is basically subjective Bayes from the viewpoint of an idealised perfectly rational agent - and “perfectly rational” seems philosophically a lot more expensive than anything subjective Bayes relies on.</div><br/></div></div><div id="41081070" class="c"><input type="checkbox" id="c-41081070" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#41080693">root</a><span>|</span><a href="#41080841">parent</a><span>|</span><a href="#41083494">prev</a><span>|</span><a href="#41080979">next</a><span>|</span><label class="collapse" for="c-41081070">[-]</label><label class="expand" for="c-41081070">[10 more]</label></div><br/><div class="children"><div class="content">I see, so academics are frequentists (attackers) or objective Bayes (naive), and the people Doing Science are pragmatic (correct).<p>The article gave me the same vibe, nice, short set of labels for me to apply as a heuristic.<p>I never really understood this particular war, I&#x27;m a simpleton, A in Stats 101, that&#x27;s it. I guess I need to bone up on Wikipedia to understand what&#x27;s going on here more.</div><br/><div id="41081312" class="c"><input type="checkbox" id="c-41081312" checked=""/><div class="controls bullet"><span class="by">thegginthesky</span><span>|</span><a href="#41080693">root</a><span>|</span><a href="#41081070">parent</a><span>|</span><a href="#41081242">next</a><span>|</span><label class="collapse" for="c-41081312">[-]</label><label class="expand" for="c-41081312">[2 more]</label></div><br/><div class="children"><div class="content">Frequentist and Bayesian are correct if both have scientific rigor in their research and methodology. Both can be wrong if the research is whack or sloppy.</div><br/><div id="41081940" class="c"><input type="checkbox" id="c-41081940" checked=""/><div class="controls bullet"><span class="by">slashdave</span><span>|</span><a href="#41080693">root</a><span>|</span><a href="#41081312">parent</a><span>|</span><a href="#41081242">next</a><span>|</span><label class="collapse" for="c-41081940">[-]</label><label class="expand" for="c-41081940">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve used both in some papers and report two results (why not?). The golden rule in my mind is to fully describe your process and assumptions, then let the reader decide.</div><br/></div></div></div></div><div id="41081242" class="c"><input type="checkbox" id="c-41081242" checked=""/><div class="controls bullet"><span class="by">sgt101</span><span>|</span><a href="#41080693">root</a><span>|</span><a href="#41081070">parent</a><span>|</span><a href="#41081312">prev</a><span>|</span><a href="#41081106">next</a><span>|</span><label class="collapse" for="c-41081242">[-]</label><label class="expand" for="c-41081242">[5 more]</label></div><br/><div class="children"><div class="content">Bayes lets you use your priors, which can be very helpful.<p>I got all riled up when I saw you wrote &quot;correct&quot;, I can&#x27;t really explain why... but I just feel that we need to keep an open mind. These approaches to data are choices at the end of the day... Was Einstein a Bayesian? (spoiler: no)</div><br/><div id="41081474" class="c"><input type="checkbox" id="c-41081474" checked=""/><div class="controls bullet"><span class="by">0cf8612b2e1e</span><span>|</span><a href="#41080693">root</a><span>|</span><a href="#41081242">parent</a><span>|</span><a href="#41081356">next</a><span>|</span><label class="collapse" for="c-41081474">[-]</label><label class="expand" for="c-41081474">[3 more]</label></div><br/><div class="children"><div class="content">Using your priors is another way of saying you know something about the problem. It is exceedingly difficult to objectively analyze a dataset without interjecting any bias. There are too many decision points where something needs to be done to massage the data into shape. Priors is just an explicit encoding of some of that knowledge.</div><br/><div id="41083562" class="c"><input type="checkbox" id="c-41083562" checked=""/><div class="controls bullet"><span class="by">ants_everywhere</span><span>|</span><a href="#41080693">root</a><span>|</span><a href="#41081474">parent</a><span>|</span><a href="#41081356">next</a><span>|</span><label class="collapse" for="c-41083562">[-]</label><label class="expand" for="c-41083562">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Priors is just an explicit encoding of some of that knowledge.<p>A classic example is analyzing data on mind reading or ghost detection. Your experiment shows you that your ghost detector has detected a haunting with p &lt; .001. What is the probability the house is haunted?</div><br/><div id="41085205" class="c"><input type="checkbox" id="c-41085205" checked=""/><div class="controls bullet"><span class="by">lupusreal</span><span>|</span><a href="#41080693">root</a><span>|</span><a href="#41083562">parent</a><span>|</span><a href="#41081356">next</a><span>|</span><label class="collapse" for="c-41085205">[-]</label><label class="expand" for="c-41085205">[1 more]</label></div><br/><div class="children"><div class="content">With a prior like that, why would you even bother pretending to do the research?</div><br/></div></div></div></div></div></div><div id="41081356" class="c"><input type="checkbox" id="c-41081356" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#41080693">root</a><span>|</span><a href="#41081242">parent</a><span>|</span><a href="#41081474">prev</a><span>|</span><a href="#41081106">next</a><span>|</span><label class="collapse" for="c-41081356">[-]</label><label class="expand" for="c-41081356">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;re absolutely right, trying to walk a delicate tightrope that doesn&#x27;t end up with me giving my unfiltered &quot;you&#x27;re wrong so lets end conversation&quot; response.<p>Me 6 months ago would have written: &quot;this comment is unhelpful and boring, but honestly, that&#x27;s slightly unfair to you, as it just made me realize how little help the article is, and it set the tone. is this even a real argument with sides?&quot;<p>For people who want to improve on this aspect of themselves, like I did for years:<p>- show, don&#x27;t tell (ex. here, I made the oddities more explicit, enough that people could reply to me spelling out what I shouldn&#x27;t.)<p>- Don&#x27;t assert anything that wasn&#x27;t said directly, ex. don&#x27;t remark on the commenter, or subjective qualities you assess in the comment.</div><br/></div></div></div></div><div id="41081106" class="c"><input type="checkbox" id="c-41081106" checked=""/><div class="controls bullet"><span class="by">Yossarrian22</span><span>|</span><a href="#41080693">root</a><span>|</span><a href="#41081070">parent</a><span>|</span><a href="#41081242">prev</a><span>|</span><a href="#41081388">next</a><span>|</span><label class="collapse" for="c-41081106">[-]</label><label class="expand" for="c-41081106">[1 more]</label></div><br/><div class="children"><div class="content">Academics can be pragmatic, I&#x27;ve know ones who&#x27;ve sued both Bayesian statistics and MLE</div><br/></div></div><div id="41081388" class="c"><input type="checkbox" id="c-41081388" checked=""/><div class="controls bullet"><span class="by">runarberg</span><span>|</span><a href="#41080693">root</a><span>|</span><a href="#41081070">parent</a><span>|</span><a href="#41081106">prev</a><span>|</span><a href="#41080979">next</a><span>|</span><label class="collapse" for="c-41081388">[-]</label><label class="expand" for="c-41081388">[1 more]</label></div><br/><div class="children"><div class="content">I understand the war between bayesians and frequentists. Frequentist methods have been misused for over a century now to justify all sorts of pseudoscience and hoaxes (as well as created a fair share of honest mistakes), so it is understandable that people would come forward and claim there must be a better way.<p>What I don’t understand is the war between naive bayes and pragmatic bayes. If it is real, it seems like the extension of philosophers vs. engineers. Scientists should see value in both. Naive Bayes is important to the philosophy of science, without which there would be a lot of junk science which would go unscrutinized for far to long, and engineers should be able to see the value of philosophers saving them works by debunking wrong science before they start to implement theories which simply will not work in practice.</div><br/></div></div></div></div></div></div><div id="41080979" class="c"><input type="checkbox" id="c-41080979" checked=""/><div class="controls bullet"><span class="by">RandomThoughts3</span><span>|</span><a href="#41080693">parent</a><span>|</span><a href="#41080841">prev</a><span>|</span><a href="#41082012">next</a><span>|</span><label class="collapse" for="c-41080979">[-]</label><label class="expand" for="c-41080979">[20 more]</label></div><br/><div class="children"><div class="content">I’m always puzzled by this because while I come from a country where the frequentist approach generally dominates, the fight with Bayesian basically doesn’t exist. That’s just a bunch of mathematical theories and tools. Just use what’s useful.<p>I’m still convinced that Americans tend to dislike the frequentist view because it requires a stronger background in mathematics.</div><br/><div id="41081068" class="c"><input type="checkbox" id="c-41081068" checked=""/><div class="controls bullet"><span class="by">parpfish</span><span>|</span><a href="#41080693">root</a><span>|</span><a href="#41080979">parent</a><span>|</span><a href="#41081566">next</a><span>|</span><label class="collapse" for="c-41081068">[-]</label><label class="expand" for="c-41081068">[2 more]</label></div><br/><div class="children"><div class="content">I don’t think mathematical ability has much to do with it.<p>I think it’s useful to break down the anti-Bayesians into statisticians and non-statistician scientists.<p>The former are mathematically savvy enough to understand bayes but object on philosophical grounds; the later don’t care about the philosophy so much as they feel like an attack on frequentism is an attack on their previous research and they take it personally</div><br/><div id="41081239" class="c"><input type="checkbox" id="c-41081239" checked=""/><div class="controls bullet"><span class="by">mturmon</span><span>|</span><a href="#41080693">root</a><span>|</span><a href="#41081068">parent</a><span>|</span><a href="#41081566">next</a><span>|</span><label class="collapse" for="c-41081239">[-]</label><label class="expand" for="c-41081239">[1 more]</label></div><br/><div class="children"><div class="content">This is a reasonable heuristic. I studied in a program that (for both philosophical and practical reasons) questioned whether the Bayesian formalism should be applied as widely as it is. (Which for many people is, basically everywhere.)<p>There are some cases, that do arise in practice, where you can’t impose a prior, and&#x2F;or where the “Dutch book” arguments to justify Bayesian decisions don’t apply.</div><br/></div></div></div></div><div id="41081566" class="c"><input type="checkbox" id="c-41081566" checked=""/><div class="controls bullet"><span class="by">ordu</span><span>|</span><a href="#41080693">root</a><span>|</span><a href="#41080979">parent</a><span>|</span><a href="#41081068">prev</a><span>|</span><a href="#41081982">next</a><span>|</span><label class="collapse" for="c-41081566">[-]</label><label class="expand" for="c-41081566">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;d suggest you to read &quot;The Book of Why&quot;[1]. It is mostly about Judea&#x27;s Pearl next creation, about causality, but he also covers bayesian approach, the history of statistics, his motivation behind bayesian statistics, and some success stories also.<p>To read this book will be much better, then to apply &quot;Hanlon&#x27;s Razor&quot;[2] because you see no other explanation.<p>[1] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;The_Book_of_Why" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;The_Book_of_Why</a><p>[2] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Hanlon&#x27;s_razor" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Hanlon&#x27;s_razor</a></div><br/></div></div><div id="41081982" class="c"><input type="checkbox" id="c-41081982" checked=""/><div class="controls bullet"><span class="by">gnulinux</span><span>|</span><a href="#41080693">root</a><span>|</span><a href="#41080979">parent</a><span>|</span><a href="#41081566">prev</a><span>|</span><a href="#41081349">next</a><span>|</span><label class="collapse" for="c-41081982">[-]</label><label class="expand" for="c-41081982">[2 more]</label></div><br/><div class="children"><div class="content">This statement is correct only on a very basic, fundamental sense, but it disregards the research practice. Let&#x27;s say you&#x27;re a mathematician who studies analysis or algebra. Sure, technically there is no fundamental reason for constructive logic and classical logic to &quot;compete&quot;, you can simply choose whichever one is useful for the problem you&#x27;re solving, in fact {constructive + lem + choice axioms} will be equivalent to classical math, so why not just study constructive math since it&#x27;s higher level of abstraction and you can always add those axioms &quot;later&quot; when you have a particular application.<p>In reality, on a human level, it doesn&#x27;t work like that because, when you have disagreements on the very foundations of your field, although both camps can agree that their results do follow, the fact that their results (and thus terminology) are incompatible makes it too difficult to research both at the same time. This basically means, practically speaking, you need to be familiar with both, but definitely specialize in one. Which creates hubs of different sorts of math&#x2F;stats&#x2F;cs departments etc.<p>If you&#x27;re, for example, working on constructive analysis, you&#x27;ll have to spend tremendous amount of energy on understanding contemporary techniques like localization etc just to work around a basic logical axiom, which is likely irrelevant to a lot of applications. Really, this is like trying to understand the mathematical properties of binary arithmetic (Z&#x2F;2Z) but day-to-day studying group theory in general. Well, sure Z&#x2F;2Z is a group, but really you&#x27;re simply interested in a single, tiny, finite abelian group, but now you need to do a whole bunch of work on non-abelian groups, infinite groups, non-cyclic groups etc just to ignore all those facts.</div><br/><div id="41083330" class="c"><input type="checkbox" id="c-41083330" checked=""/><div class="controls bullet"><span class="by">RandomThoughts3</span><span>|</span><a href="#41080693">root</a><span>|</span><a href="#41081982">parent</a><span>|</span><a href="#41081349">next</a><span>|</span><label class="collapse" for="c-41083330">[-]</label><label class="expand" for="c-41083330">[1 more]</label></div><br/><div class="children"><div class="content">I would follow but neither Bayesian nor frequentist probabilities are rocket science.<p>I’m not following your exemple about binary and group theory either. Nobody looks at the properties of binary and stops there. If you are interested in number theory, group theory will be a useful part of your toolbox for sure.</div><br/></div></div></div></div><div id="41081349" class="c"><input type="checkbox" id="c-41081349" checked=""/><div class="controls bullet"><span class="by">bb86754</span><span>|</span><a href="#41080693">root</a><span>|</span><a href="#41080979">parent</a><span>|</span><a href="#41081982">prev</a><span>|</span><a href="#41081297">next</a><span>|</span><label class="collapse" for="c-41081349">[-]</label><label class="expand" for="c-41081349">[4 more]</label></div><br/><div class="children"><div class="content">I can attest that the frequentist view is still very much the mainstream here too and fills almost every college curriculum across the United States. You may get one or two Bayesian classes if you&#x27;re a stats major, but generally it&#x27;s hypothesis testing, point estimates, etc.<p>Regardless, the idea that frequentist stats requires a stronger background in mathematics is just flat out silly though, not even sure what you mean by that.</div><br/><div id="41081646" class="c"><input type="checkbox" id="c-41081646" checked=""/><div class="controls bullet"><span class="by">blt</span><span>|</span><a href="#41080693">root</a><span>|</span><a href="#41081349">parent</a><span>|</span><a href="#41083370">next</a><span>|</span><label class="collapse" for="c-41081646">[-]</label><label class="expand" for="c-41081646">[2 more]</label></div><br/><div class="children"><div class="content">I also thought it was silly, but maybe they mean that frequentist methods still have analytical solutions in some settings where Bayesian methods must resort to Monte Carlo methods?</div><br/><div id="41083255" class="c"><input type="checkbox" id="c-41083255" checked=""/><div class="controls bullet"><span class="by">kgwgk</span><span>|</span><a href="#41080693">root</a><span>|</span><a href="#41081646">parent</a><span>|</span><a href="#41083370">next</a><span>|</span><label class="collapse" for="c-41083255">[-]</label><label class="expand" for="c-41083255">[1 more]</label></div><br/><div class="children"><div class="content">Note that Bayesian methods also have analytical solutions in some settings.<p>There is a reason why conjugate priors were a thing.</div><br/></div></div></div></div></div></div><div id="41081297" class="c"><input type="checkbox" id="c-41081297" checked=""/><div class="controls bullet"><span class="by">thegginthesky</span><span>|</span><a href="#41080693">root</a><span>|</span><a href="#41080979">parent</a><span>|</span><a href="#41081349">prev</a><span>|</span><a href="#41083467">next</a><span>|</span><label class="collapse" for="c-41081297">[-]</label><label class="expand" for="c-41081297">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s because practicioners of one says that the other camp is wrong and question each other&#x27;s methodologies. And in academia, questioning one&#x27;s methodology is akin to saying one is dumb.<p>To understand both camps I summarize like this.<p>Frequentist statistics has very sound theory but is misapplied by using many heuristics, rule of thumbs and prepared tables. It&#x27;s very easy to use any method and hack the p-value away to get statistically significant results.<p>Bayesian statistics has an interesting premise and inference methods, but until recently with the advancements of computing power, it was near impossible to do simulations to validate the complex distributions used, the goodness of fit and so on. And even in the current year, some bayesian statisticians don&#x27;t question the priors and iterate on their research.<p>I recommend using methods both whenever it&#x27;s convenient and fits the problem at hand.</div><br/></div></div><div id="41083467" class="c"><input type="checkbox" id="c-41083467" checked=""/><div class="controls bullet"><span class="by">ants_everywhere</span><span>|</span><a href="#41080693">root</a><span>|</span><a href="#41080979">parent</a><span>|</span><a href="#41081297">prev</a><span>|</span><a href="#41081328">next</a><span>|</span><label class="collapse" for="c-41083467">[-]</label><label class="expand" for="c-41083467">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I’m still convinced that Americans tend to dislike the frequentist view because it requires a stronger background in mathematics.<p>The opposite is true. Bayesian approaches require more mathematics. The Bayesian approach is perhaps more similar to PDE where problems are so difficult that the only way we can currently solve them is with numerical methods.</div><br/></div></div><div id="41081328" class="c"><input type="checkbox" id="c-41081328" checked=""/><div class="controls bullet"><span class="by">runarberg</span><span>|</span><a href="#41080693">root</a><span>|</span><a href="#41080979">parent</a><span>|</span><a href="#41083467">prev</a><span>|</span><a href="#41082012">next</a><span>|</span><label class="collapse" for="c-41081328">[-]</label><label class="expand" for="c-41081328">[7 more]</label></div><br/><div class="children"><div class="content">I think the distaste Americans have to frequentists has much more to do with history of science. The Eugenics movement had a massive influence on science in America a and they used frequentist methods to justify (or rather validate) their scientific racism. Authors like Gould brought this up in the 1980s, particularly in relation to factor analysis and intelligence testing, and was kind of proven right when Hernstein and Murray published <i>The Bell Curve</i> in 1994.<p>The p-hacking exposures of the 1990s only fermented the notion that it is very easy to get away with junk science using frequentest methods to unjustly validate your claims.<p>That said, frequentists are still the default statistics in social sciences, which ironically is where the damage was the worst.</div><br/><div id="41082808" class="c"><input type="checkbox" id="c-41082808" checked=""/><div class="controls bullet"><span class="by">TeaBrain</span><span>|</span><a href="#41080693">root</a><span>|</span><a href="#41081328">parent</a><span>|</span><a href="#41081714">next</a><span>|</span><label class="collapse" for="c-41082808">[-]</label><label class="expand" for="c-41082808">[2 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think the guy&#x27;s basic assertion is true that frequentist statistics is less favored in American academia.</div><br/><div id="41083165" class="c"><input type="checkbox" id="c-41083165" checked=""/><div class="controls bullet"><span class="by">runarberg</span><span>|</span><a href="#41080693">root</a><span>|</span><a href="#41082808">parent</a><span>|</span><a href="#41081714">next</a><span>|</span><label class="collapse" for="c-41083165">[-]</label><label class="expand" for="c-41083165">[1 more]</label></div><br/><div class="children"><div class="content">I’m not actually in any statistician circles (although I did work at a statistical startup that used Kalman Filters in Reykjavík 10 years ago; and I did dropout from learning statistics in University of Iceland).<p>But what I gathered after moving to Seattle is that Bayesian statistics are a lot more trendy (accepted even) here west of the ocean. Frequentists is very much the default, especially in hypothesis testing, so you are not wrong. However I’m seeing a lot more Bayesian advocacy over here than I did back in Iceland. So I’m not sure my parent is wrong either, that Americans tend to dislike frequentist methods, at least more than Europeans do.</div><br/></div></div></div></div><div id="41081714" class="c"><input type="checkbox" id="c-41081714" checked=""/><div class="controls bullet"><span class="by">lupire</span><span>|</span><a href="#41080693">root</a><span>|</span><a href="#41081328">parent</a><span>|</span><a href="#41082808">prev</a><span>|</span><a href="#41082012">next</a><span>|</span><label class="collapse" for="c-41081714">[-]</label><label class="expand" for="c-41081714">[4 more]</label></div><br/><div class="children"><div class="content">What is the protection against someone using a Bayesian analysis but abusing it with hidden bias?</div><br/><div id="41081839" class="c"><input type="checkbox" id="c-41081839" checked=""/><div class="controls bullet"><span class="by">analog31</span><span>|</span><a href="#41080693">root</a><span>|</span><a href="#41081714">parent</a><span>|</span><a href="#41081905">next</a><span>|</span><label class="collapse" for="c-41081839">[-]</label><label class="expand" for="c-41081839">[1 more]</label></div><br/><div class="children"><div class="content">My knee jerk reaction is replication, and studying a problem from multiple angles such as experimentation and theory.</div><br/></div></div><div id="41081905" class="c"><input type="checkbox" id="c-41081905" checked=""/><div class="controls bullet"><span class="by">runarberg</span><span>|</span><a href="#41080693">root</a><span>|</span><a href="#41081714">parent</a><span>|</span><a href="#41081839">prev</a><span>|</span><a href="#41082012">next</a><span>|</span><label class="collapse" for="c-41081905">[-]</label><label class="expand" for="c-41081905">[2 more]</label></div><br/><div class="children"><div class="content">I’m sure there are creative ways to misuse bayesian statistics, although I think it is harder to hide your intentions as you do that. With frequentist approaches your intentions become obscure in the whole mess of computations and at the end of it you get to claim this is a simple “objective” truth because the p value shows &lt; 0.05. In bayesan statistics the data you put into it is front and center: <i>The chances of my theory being true given this data is greater than 95%</i> (or was it chances of getting this data given my theory?). In reality most hoaxes and junk science was because of bad data which didn’t get scrutinized until much too late (this is what Gould did).<p>But I think the crux of the matter is that bad science has been demonstrated with frequentists and is now a part of our history. So people must either find a way to fix the frequentist approaches or throw it out for something different. Bayesian statistics is that something different.</div><br/><div id="41084891" class="c"><input type="checkbox" id="c-41084891" checked=""/><div class="controls bullet"><span class="by">lottin</span><span>|</span><a href="#41080693">root</a><span>|</span><a href="#41081905">parent</a><span>|</span><a href="#41082012">next</a><span>|</span><label class="collapse" for="c-41084891">[-]</label><label class="expand" for="c-41084891">[1 more]</label></div><br/><div class="children"><div class="content">&gt; &quot;The chances of my theory being true given this data is greater than 95% (or was it chances of getting this data given my theory?)&quot;<p>The first statement assumes that parameters (i.e. a state of nature) are random variables.  That&#x27;s the Bayesan approach.  The second statement assumes that parameters are fixed values, not random, but unknown.  That&#x27;s the frequentist approach.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="41082012" class="c"><input type="checkbox" id="c-41082012" checked=""/><div class="controls bullet"><span class="by">bayesian_trout</span><span>|</span><a href="#41080693">prev</a><span>|</span><a href="#41081674">next</a><span>|</span><label class="collapse" for="c-41082012">[-]</label><label class="expand" for="c-41082012">[11 more]</label></div><br/><div class="children"><div class="content">If you want to get an informed opinion on modern Frequentist methods check out the book &quot;In All Likelihood&quot; by Yudi Pawitawn.<p>In an early chapter it outlines, rather eloquently, the distinctions between the Frequentist and Bayesian paradigms and in particular the power of well-designed Frequentist or likelihood-based models. With few exceptions, an analyst should get the same answer using a Bayesian vs. Frequentist model if the Bayesian is actually using uninformative priors.  In the worlds I work in, 99% of the time I see researchers using Bayesian methods they are also claiming to use uninformative priors, which makes me wonder if they are just using Bayesian methods to sound cool and skip through peer review.<p>One potential problem with Bayesian statistics lies in the fact that for complicated models (100s or even 1000s of parameters) it can be extremely difficult to know if the priors are truly uninformative in the context of a particular dataset.  One has to wait for models to run, and when systematically changing priors this can take an extraordinary amount of time, even when using high powered computing resources.  Additionally, in the Bayesian setting it becomes easy to accidentally &quot;glue&quot; a model together with a prior or set of priors that would simply bomb out and give a non-positive definite hessian in the Frequentist world (read: a diagnostic telling you that your model is likely bogus and&#x2F;or too complex for a given dataset). One might scoff at models of this complexity, but that is the reality in many applied settings, for example spatio-temporal models facing the &quot;big n&quot; problem or for stuff like integrated fisheries assessment models used to assess status and provide information on stock sustainability.<p>So my primary beef with Bayesian statistics (and I say this as someone who teaches graduate level courses on the Bayesian inference) is that it can very easily be misused by non-statisticians and beginners, particularly given the extremely flexible software programs that currently are available to non-statisticians like biologists etc.  In general though, both paradigms are subjective and Gelman&#x27;s argument that it is turtles (i.e., subjectivity) all the way down is spot on and really resonates with me.</div><br/><div id="41082587" class="c"><input type="checkbox" id="c-41082587" checked=""/><div class="controls bullet"><span class="by">usgroup</span><span>|</span><a href="#41082012">parent</a><span>|</span><a href="#41082734">prev</a><span>|</span><a href="#41082795">next</a><span>|</span><label class="collapse" for="c-41082587">[-]</label><label class="expand" for="c-41082587">[2 more]</label></div><br/><div class="children"><div class="content">+1 for “in all likelihood” but it should be stated that the book explains a third approach which doesn’t lean on either subjective or objective probability.</div><br/><div id="41082632" class="c"><input type="checkbox" id="c-41082632" checked=""/><div class="controls bullet"><span class="by">bayesian_trout</span><span>|</span><a href="#41082012">root</a><span>|</span><a href="#41082587">parent</a><span>|</span><a href="#41082795">next</a><span>|</span><label class="collapse" for="c-41082632">[-]</label><label class="expand" for="c-41082632">[1 more]</label></div><br/><div class="children"><div class="content">fair :)</div><br/></div></div></div></div><div id="41082795" class="c"><input type="checkbox" id="c-41082795" checked=""/><div class="controls bullet"><span class="by">kgwgk</span><span>|</span><a href="#41082012">parent</a><span>|</span><a href="#41082587">prev</a><span>|</span><a href="#41081674">next</a><span>|</span><label class="collapse" for="c-41082795">[-]</label><label class="expand" for="c-41082795">[7 more]</label></div><br/><div class="children"><div class="content">&gt; So my primary beef with Bayesian statistics (...) is that it can very easily be misused by non-statisticians and beginners<p>Unlike frequentist statistics? :-)</div><br/><div id="41083364" class="c"><input type="checkbox" id="c-41083364" checked=""/><div class="controls bullet"><span class="by">bayesian_trout</span><span>|</span><a href="#41082012">root</a><span>|</span><a href="#41082795">parent</a><span>|</span><a href="#41081674">next</a><span>|</span><label class="collapse" for="c-41083364">[-]</label><label class="expand" for="c-41083364">[6 more]</label></div><br/><div class="children"><div class="content">hard to accidentally glue a frequentist model together with a prior ;)</div><br/><div id="41083478" class="c"><input type="checkbox" id="c-41083478" checked=""/><div class="controls bullet"><span class="by">kgwgk</span><span>|</span><a href="#41082012">root</a><span>|</span><a href="#41083364">parent</a><span>|</span><a href="#41083543">next</a><span>|</span><label class="collapse" for="c-41083478">[-]</label><label class="expand" for="c-41083478">[1 more]</label></div><br/><div class="children"><div class="content">Also hard to interpret correctly frequentist results.<p>--<p>Misinterpretations of P-values and statistical tests persists among researchers and professionals working with statistics and epidemiology<p>&quot;Correct inferences to both questions, which is that a statistically significant finding cannot be inferred as either proof or a measure of a hypothesis’ probability, were given by 10.7% of doctoral students and 12.5% of statisticians&#x2F;epidemiologists.&quot;<p><a href="https:&#x2F;&#x2F;www.ncbi.nlm.nih.gov&#x2F;pmc&#x2F;articles&#x2F;PMC9383044&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.ncbi.nlm.nih.gov&#x2F;pmc&#x2F;articles&#x2F;PMC9383044&#x2F;</a><p>--<p>Robust misinterpretation of confidence intervals<p>&quot;Only 8 first-year students (2%), no master students, and 3 postmasters researchers (3%) correctly indicated that all statements were wrong.&quot;<p><a href="https:&#x2F;&#x2F;link.springer.com&#x2F;article&#x2F;10.3758&#x2F;s13423-013-0572-3" rel="nofollow">https:&#x2F;&#x2F;link.springer.com&#x2F;article&#x2F;10.3758&#x2F;s13423-013-0572-3</a><p>--<p>P-Value, Confidence Intervals, and Statistical Inference: A New Dataset of Misinterpretation<p>&quot;The data indicates that 99% subjects have at least 1 wrong answer of P-value understanding (Figure 1A) and 93% subjects have at least 1 wrong answer of CI understanding (Figure 1B).&quot;<p><a href="https:&#x2F;&#x2F;www.frontiersin.org&#x2F;journals&#x2F;psychology&#x2F;articles&#x2F;10.3389&#x2F;fpsyg.2018.00868&#x2F;full" rel="nofollow">https:&#x2F;&#x2F;www.frontiersin.org&#x2F;journals&#x2F;psychology&#x2F;articles&#x2F;10....</a></div><br/></div></div><div id="41083543" class="c"><input type="checkbox" id="c-41083543" checked=""/><div class="controls bullet"><span class="by">ants_everywhere</span><span>|</span><a href="#41082012">root</a><span>|</span><a href="#41083364">parent</a><span>|</span><a href="#41083478">prev</a><span>|</span><a href="#41081674">next</a><span>|</span><label class="collapse" for="c-41083543">[-]</label><label class="expand" for="c-41083543">[4 more]</label></div><br/><div class="children"><div class="content">Oh it happens all the time. I&#x27;ve been in several lab meetings where the experiment was redesigned because the results came out &quot;wrong.&quot; I.e. the (frequentist) statistics didn&#x27;t match with the (implicit) prior.</div><br/><div id="41083718" class="c"><input type="checkbox" id="c-41083718" checked=""/><div class="controls bullet"><span class="by">bayesian_trout</span><span>|</span><a href="#41082012">root</a><span>|</span><a href="#41083543">parent</a><span>|</span><a href="#41081674">next</a><span>|</span><label class="collapse" for="c-41083718">[-]</label><label class="expand" for="c-41083718">[3 more]</label></div><br/><div class="children"><div class="content">This is not a statistics problem, but instead an ethics problem, ha.</div><br/><div id="41083724" class="c"><input type="checkbox" id="c-41083724" checked=""/><div class="controls bullet"><span class="by">ants_everywhere</span><span>|</span><a href="#41082012">root</a><span>|</span><a href="#41083718">parent</a><span>|</span><a href="#41081674">next</a><span>|</span><label class="collapse" for="c-41083724">[-]</label><label class="expand" for="c-41083724">[2 more]</label></div><br/><div class="children"><div class="content">I agree totally.<p>But it&#x27;s also a statistics problem because ethically you should incorporate your assumptions into the model. If the assumptions are statistical, then you can incorporate them in a prior.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="41081674" class="c"><input type="checkbox" id="c-41081674" checked=""/><div class="controls bullet"><span class="by">mjhay</span><span>|</span><a href="#41082012">prev</a><span>|</span><a href="#41083029">next</a><span>|</span><label class="collapse" for="c-41081674">[-]</label><label class="expand" for="c-41081674">[3 more]</label></div><br/><div class="children"><div class="content">The great thing about Bayesian statistics is that it&#x27;s subjective. You don&#x27;t have to be in the subjectivist school. You can choose your own interpretation based on your (subjective) judgment.<p>I think this is a strength of Bayesianism. Any statistical work is infused with the subjective judgement of individual humans. I think it is more objective to not shy away from this immutable fact.</div><br/><div id="41081936" class="c"><input type="checkbox" id="c-41081936" checked=""/><div class="controls bullet"><span class="by">klysm</span><span>|</span><a href="#41081674">parent</a><span>|</span><a href="#41083029">next</a><span>|</span><label class="collapse" for="c-41081936">[-]</label><label class="expand" for="c-41081936">[2 more]</label></div><br/><div class="children"><div class="content">The appropriateness of each approach is very much a function of what is being modeled and the corresponding consequences for error.</div><br/><div id="41081965" class="c"><input type="checkbox" id="c-41081965" checked=""/><div class="controls bullet"><span class="by">mjhay</span><span>|</span><a href="#41081674">root</a><span>|</span><a href="#41081936">parent</a><span>|</span><a href="#41083029">next</a><span>|</span><label class="collapse" for="c-41081965">[-]</label><label class="expand" for="c-41081965">[1 more]</label></div><br/><div class="children"><div class="content">Of course. The best approach for a particular problem depends on your best judgment.<p>I guess that means I&#x27;m in the pragmatist school in this article&#x27;s nomenclature (I&#x27;m a big fan of Gelman and all the other stats folks there), but what one thinks is pragmatic is also subjective.</div><br/></div></div></div></div></div></div><div id="41083029" class="c"><input type="checkbox" id="c-41083029" checked=""/><div class="controls bullet"><span class="by">prmph</span><span>|</span><a href="#41081674">prev</a><span>|</span><a href="#41082096">next</a><span>|</span><label class="collapse" for="c-41083029">[-]</label><label class="expand" for="c-41083029">[14 more]</label></div><br/><div class="children"><div class="content">So my theory is that probability is an ill-defined, unfalsifiable concept. And yet, it _seems_ to model aspects of the world pretty well, empirically. However, might it be leading us astray?<p>Consider the statement p(X) = 0.5 (probability of event X is 0.5). What does this actually mean? It it a proposition? If so, is it falsifiable? And how?<p>If it is not a proposition, what does it actually mean? If someone with more knowledge can chime in here, I&#x27;d be grateful. I&#x27;ve got much more to say on this, but only after I hear from those with a rigorous grounding the theory.</div><br/><div id="41084108" class="c"><input type="checkbox" id="c-41084108" checked=""/><div class="controls bullet"><span class="by">enasterosophes</span><span>|</span><a href="#41083029">parent</a><span>|</span><a href="#41083541">next</a><span>|</span><label class="collapse" for="c-41084108">[-]</label><label class="expand" for="c-41084108">[1 more]</label></div><br/><div class="children"><div class="content">As a mathematical theory, probability is well-defined. It is an application of a larger topic called measure theory, which also gives us the theoretical underpinnings for calculus.<p>Every probability is defined in terms of three things: a set, a set of subsets of that set (in plain language: a way of grouping things together), and a function which maps the subsets to numbers between 0 and 1. To be valid, the set of subsets, aka the events, need to satisfy additional rules.<p>All your example p(X) = 0.5 says is that some function assigns the value of 0.5 to some subset which you&#x27;ve called X.<p>That it seems to be good at modelling the real world can be attributed to the origins of the theory: it didn&#x27;t arise ex nihilo, it was constructed exactly because it was desirable to formalize a model for seemingly random events in the real world.</div><br/></div></div><div id="41083541" class="c"><input type="checkbox" id="c-41083541" checked=""/><div class="controls bullet"><span class="by">skissane</span><span>|</span><a href="#41083029">parent</a><span>|</span><a href="#41084108">prev</a><span>|</span><a href="#41084029">next</a><span>|</span><label class="collapse" for="c-41083541">[-]</label><label class="expand" for="c-41083541">[3 more]</label></div><br/><div class="children"><div class="content">&gt; So my theory is that probability is an ill-defined, unfalsifiable concept<p>Probability isn’t a single concept, it is a family of related concepts - epistemic probability (as in subjective Bayesianism) is a different concept from frequentist probability - albeit obviously related in some ways. It is unsurprising that a term looks like an “ill-defined, unfalsifiable concept” if you are mushing together mutually incompatible definitions of it.<p>&gt; Consider the statement p(X) = 0.5 (probability of event X is 0.5). What does this actually mean?<p>From a subjective Bayesian perspective, p(X) is a measure of how much confidence I - or any other specified person - have in the truth of a  proposition, or my own judgement of the weight of evidence for or against it, or my judgement of the degree of my own knowledge of its truth or falsehood. And 0.5 means I have zero confidence either way, I have zero evidence either way (or else, the evidence on each side perfectly cancels each other out), I have a complete lack of knowledge as to whether the proposition is true.<p>&gt; It it a proposition?<p>It is a proposition just in the same sense that “the Pope believes that God exists” is a proposition. Whether or not God actually exists, it seems very likely true that the Pope believes he does<p>&gt; If so, is it falsifiable? And how?<p>And obviously that’s falsifiable, in the same sense that claims about my own beliefs are trivially falsifiable by me, using my introspection. And claims about other people’s beliefs are also falsifiable, if we ask them, and if assuming they are happy to answer, and we have no good reason to think they are being untruthful.</div><br/><div id="41083743" class="c"><input type="checkbox" id="c-41083743" checked=""/><div class="controls bullet"><span class="by">prmph</span><span>|</span><a href="#41083029">root</a><span>|</span><a href="#41083541">parent</a><span>|</span><a href="#41084029">next</a><span>|</span><label class="collapse" for="c-41083743">[-]</label><label class="expand" for="c-41083743">[2 more]</label></div><br/><div class="children"><div class="content">So you response actually strengthens my point, rather than rebuts it.<p>&gt; From a subjective Bayesian perspective, p(X) is a measure of how much confidence I - or any other specified person - have in the truth of a proposition, or my own judgement of the weight of evidence for or against it, or my judgement of the degree of my own knowledge of its truth or falsehood.<p>See how inexact and vague all these measures are. How do you know your confidence is (or should be) 0.5 ( and not 0.49) for example? Or, how to know you have judged correctly the weight of evidence? Or how do you know the transition from &quot;knowledge about this event&quot; to &quot;what it indicates about its probability&quot; you make in your mind is valid? You cannot disprove these things, can you?<p>Unless you you want to say the actual values do not actually matter, but the way the probabilities are updated in the face of new information is. But in any case, the significance of new evidence still has to be interpreted; there is no objective interpretation, is there?.</div><br/><div id="41083841" class="c"><input type="checkbox" id="c-41083841" checked=""/><div class="controls bullet"><span class="by">skissane</span><span>|</span><a href="#41083029">root</a><span>|</span><a href="#41083743">parent</a><span>|</span><a href="#41084029">next</a><span>|</span><label class="collapse" for="c-41083841">[-]</label><label class="expand" for="c-41083841">[1 more]</label></div><br/><div class="children"><div class="content">&gt; See how inexact and vague all these measures are. How do you know your confidence is (or should be) 0.5 ( and not 0.49) for example?<p>Well, you don&#x27;t, but does it matter? The idea is it is an <i>estimate</i>.<p>Let me put it this way: we all informally engage in reasoning about how likely it is (given the evidence available to us) that a given proposition is true. The idea is that assigning a numerical estimate to our sense of likelihood can (sometimes) be a helpful tool in carrying out reasoning. I might think &quot;X is slightly more likely than ~X&quot;, but do I know whether (for me) p(X) = 0.51 or 0.501 or 0.52? Probably not. But I don&#x27;t need a precise estimate for an estimate to be helpful. And that&#x27;s true in many other fields, including things that have nothing to do with probability – &quot;he&#x27;s about six feet tall&quot; can be useful information even though it isn&#x27;t accurate to the millimetre.<p>&gt; Or, how to know you have judged correctly the weight of evidence?<p>That (largely) doesn&#x27;t matter from a subjective Bayesian perspective. Epistemic probabilities are just an attempt to numerically estimate the outcome of my own process of weighing the evidence – how &quot;correctly&quot; I&#x27;ve performed that process (per any given standard of correctness) doesn&#x27;t change the actual result.<p>From an objective Bayesian perspective, it does – since objective Bayesianism is about, not any individual&#x27;s actual sense of likelihood, rather what sense of likelihood they <i>ought</i> to have (in that evidential situation), what an idealised perfectly rational agent ought to have (in that evidential situation). But that&#x27;s arguably a <i>different</i> definition of probability from the subjective Bayesian, so even if you can poke holes in that definition, those holes don&#x27;t apply to the subjective Bayesian definition.<p>&gt; Or how do you know the transition from &quot;knowledge about this event&quot; to &quot;what it indicates about its probability&quot; you make in your mind is valid?<p>I feel like you are mixing up subjective Bayesianism and objective Bayesianism and failing to carefully distinguish them in your argument.<p>&gt; But in any case, the significance of new evidence still has to be interpreted; there is no objective interpretation, is there?.<p>Well, objective Bayesianism requires there be some objective standard of rationality, subjective Bayesianism doesn&#x27;t (or, to the extent that it does, the kind of objective rationality it requires is a lot weaker, mere avoidance of blatant inconsistency, and the minimal degree of rationality needed to coherently engage in discourse and mathematics.)</div><br/></div></div></div></div></div></div><div id="41084029" class="c"><input type="checkbox" id="c-41084029" checked=""/><div class="controls bullet"><span class="by">canjobear</span><span>|</span><a href="#41083029">parent</a><span>|</span><a href="#41083541">prev</a><span>|</span><a href="#41083535">next</a><span>|</span><label class="collapse" for="c-41084029">[-]</label><label class="expand" for="c-41084029">[1 more]</label></div><br/><div class="children"><div class="content">You’re right that a particular claim like p(X=x)=a can’t be falsified in general. But whole functions p can be compared and we can say one fits the data better than another.<p>For example, say Nate Silver and Andrew Gelman both publish probabilities for the outcomes of all the races in the election in November. After the election results are in, we can’t say any <i>individual</i> probability was right or wrong. But we will be able to say whether Nate Silver or Andrew Gelman was more accurate.</div><br/></div></div><div id="41083535" class="c"><input type="checkbox" id="c-41083535" checked=""/><div class="controls bullet"><span class="by">ants_everywhere</span><span>|</span><a href="#41083029">parent</a><span>|</span><a href="#41084029">prev</a><span>|</span><a href="#41083730">next</a><span>|</span><label class="collapse" for="c-41083535">[-]</label><label class="expand" for="c-41083535">[6 more]</label></div><br/><div class="children"><div class="content">So here&#x27;s a sort of hard-nosed answer: probability is just as well-defined as any other mathematics.<p>&gt; Consider the statement p(X) = 0.5 (probability of event X is 0.5). What does this actually mean?<p>It means X is a random variable from some sample space to a measurable space and P is a probability function.<p>&gt; If so, is it falsifiable? And how?<p>Yes, by calculating P(X) in the given sample space. For example, if X is the event &quot;you get 100 heads in a row when flipping a fair coin&quot; then it is false that P(X) = 0.5.<p>It&#x27;s a bit like asking whether 2^2 = 4 is falsifiable.<p>There are definitely meaningful questions to ask about whether you&#x27;ve modeled the problem correctly, just as it&#x27;s meaningful to ask what &quot;2&quot; and &quot;4&quot; mean. But those are separate questions from whether the statements of probability are falsifiable. If you can show that the probability axioms hold for your problem, then you can use probability theory on it.<p>There&#x27;s a Wikipedia article on interpretations of probability here: <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Probability_interpretations" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Probability_interpretations</a>. But it is pretty short and doesn&#x27;t seem quite so complete.</div><br/><div id="41083696" class="c"><input type="checkbox" id="c-41083696" checked=""/><div class="controls bullet"><span class="by">prmph</span><span>|</span><a href="#41083029">root</a><span>|</span><a href="#41083535">parent</a><span>|</span><a href="#41083730">next</a><span>|</span><label class="collapse" for="c-41083696">[-]</label><label class="expand" for="c-41083696">[5 more]</label></div><br/><div class="children"><div class="content">&gt; For example, if X is the event &quot;you get 100 heads in a row when flipping a fair coin&quot; then it is false that P(X) = 0.5<p>I think you haven&#x27;t thought about this deeply enough yet. You take it as self evident that P(X) = 0.5 is false for that event, but how do you prove that? Assuming you flip a coin and you indeed get 100 heads in a row, does that invalidate the calculated probability? If not, then what would?<p>I guess what I&#x27;m driving at is this notion (already noted by others) that probability is recursive. If we say p(X) = 0.7, we mean the probability is high that in a large number of trials, X occurs 70% of the time. Or that the proportion of times that X occurs tends to 70% with high probability as the number of trials increase. Note that this second order probability can be expressed with another probability ad infinitum.</div><br/><div id="41083764" class="c"><input type="checkbox" id="c-41083764" checked=""/><div class="controls bullet"><span class="by">ants_everywhere</span><span>|</span><a href="#41083029">root</a><span>|</span><a href="#41083696">parent</a><span>|</span><a href="#41083730">next</a><span>|</span><label class="collapse" for="c-41083764">[-]</label><label class="expand" for="c-41083764">[4 more]</label></div><br/><div class="children"><div class="content">&gt; I think you haven&#x27;t thought about this deeply enough yet.<p>On the contrary, I&#x27;ve thought about it quite deeply. Or at least deeply enough to talk about it in this context.<p>&gt; You take it as self evident that P(X) = 0.5 is false for that event, but how do you prove that?<p>By definition a fair coin is one for which P(H) = P(T) = 1&#x2F;2. See e.g. <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Fair_coin" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Fair_coin</a>. Fair coins flips are also by definition independent, so you have a series of independent Bernoulli trials. So P(H^k) = P(H)^k = 1&#x2F;2^k. And P(H^k) != 1&#x2F;2 unless k = 1.<p>&gt; Assuming you flip a coin and you indeed get 100 heads in a row, does that invalidate the calculated probability? If not, then what would?<p>Why would that invalidate the calculated probability?<p>&gt;  If not, then what would?<p>P(X) = 0.5 is a statement about measures on sample spaces. So any proof that P(X) != 0.5 falsifies it.<p>I think what you&#x27;re really trying to ask is something more like &quot;is there really any such thing as a fair coin?&quot; If you probe that question far enough you eventually get down to quantum computation.<p>But there is some good research on coin flipping. You may like Persi Diaconis&#x27;s work. For example his Numberphile appearance on coin flipping <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=AYnJv68T3MM" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=AYnJv68T3MM</a></div><br/><div id="41083813" class="c"><input type="checkbox" id="c-41083813" checked=""/><div class="controls bullet"><span class="by">prmph</span><span>|</span><a href="#41083029">root</a><span>|</span><a href="#41083764">parent</a><span>|</span><a href="#41083730">next</a><span>|</span><label class="collapse" for="c-41083813">[-]</label><label class="expand" for="c-41083813">[3 more]</label></div><br/><div class="children"><div class="content">&gt; By definition a fair coin is one for which P(H) = P(T) = 1&#x2F;2. See e.g. <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Fair_coin" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Fair_coin</a>.<p>But that&#x27;s a circular tautology, isn&#x27;t it?<p>You say a fair coin is one where the probability of heads or tails are equal. So let&#x27;s assume the universe of coins is divided into those which are fair, and those which are not. Now, given a coin, how do we determine it is fair?<p>If we toss it 100 times and get all heads, do we conclude it is fair or not? I await your answer.</div><br/><div id="41083900" class="c"><input type="checkbox" id="c-41083900" checked=""/><div class="controls bullet"><span class="by">ants_everywhere</span><span>|</span><a href="#41083029">root</a><span>|</span><a href="#41083813">parent</a><span>|</span><a href="#41083730">next</a><span>|</span><label class="collapse" for="c-41083900">[-]</label><label class="expand" for="c-41083900">[2 more]</label></div><br/><div class="children"><div class="content">&gt; But that&#x27;s a circular tautology, isn&#x27;t it?<p>No it&#x27;s not a tautology... it&#x27;s a definition of fairness.<p>&gt; If we toss it 100 times and get all heads, do we conclude it is fair or not?<p>This is covered in any elementary stats or probability book.<p>&gt; Now, given a coin, how do we determine it is fair?<p>I addressed this in my last two paragraphs. There&#x27;s a literature on it and you may enjoy it. But it&#x27;s not about whether statistics is falsifiable, it&#x27;s about the physics of coin tossing.</div><br/><div id="41083928" class="c"><input type="checkbox" id="c-41083928" checked=""/><div class="controls bullet"><span class="by">prmph</span><span>|</span><a href="#41083029">root</a><span>|</span><a href="#41083900">parent</a><span>|</span><a href="#41083730">next</a><span>|</span><label class="collapse" for="c-41083928">[-]</label><label class="expand" for="c-41083928">[1 more]</label></div><br/><div class="children"><div class="content">&gt; This is covered in any elementary stats or probability book.<p>No, it is really not. That you are avoiding giving me a straightforward answer says a lot. If you mean this:<p>&gt; So any proof that P(X) != 0.5 falsifies it<p>Then the fact that we got all heads does not prove P(X) != 0.5. We could get a billions heads and still that is not proof that P(X) != 0.5 (although it is evidence in favor of it).<p>&gt; I addressed this in my last two paragraphs...<p>No you did not. Again you are avoiding giving a straightforward answer. That tell me you are aware of the paradox and are simply avoiding grappling with it.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="41083730" class="c"><input type="checkbox" id="c-41083730" checked=""/><div class="controls bullet"><span class="by">meroes</span><span>|</span><a href="#41083029">parent</a><span>|</span><a href="#41083535">prev</a><span>|</span><a href="#41083141">next</a><span>|</span><label class="collapse" for="c-41083730">[-]</label><label class="expand" for="c-41083730">[1 more]</label></div><br/><div class="children"><div class="content">This is the truly enlightened answer. Pick some reasonably defined concept of it if forced. Mainly though, you notice it works and apply the conventions.</div><br/></div></div><div id="41083141" class="c"><input type="checkbox" id="c-41083141" checked=""/><div class="controls bullet"><span class="by">kgwgk</span><span>|</span><a href="#41083029">parent</a><span>|</span><a href="#41083730">prev</a><span>|</span><a href="#41082096">next</a><span>|</span><label class="collapse" for="c-41083141">[-]</label><label class="expand" for="c-41083141">[1 more]</label></div><br/><div class="children"><div class="content">&gt; If it is not a proposition, what does it actually mean?<p>It&#x27;s a measure of plausibility - enabling plausible reasoning.<p><a href="https:&#x2F;&#x2F;www.lesswrong.com&#x2F;posts&#x2F;KN3BYDkWei9ADXnBy&#x2F;e-t-jaynes-probability-theory-the-logic-of-science-i" rel="nofollow">https:&#x2F;&#x2F;www.lesswrong.com&#x2F;posts&#x2F;KN3BYDkWei9ADXnBy&#x2F;e-t-jaynes...</a><p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Cox%27s_theorem" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Cox%27s_theorem</a></div><br/></div></div></div></div><div id="41081254" class="c"><input type="checkbox" id="c-41081254" checked=""/><div class="controls bullet"><span class="by">brcmthrowaway</span><span>|</span><a href="#41082096">prev</a><span>|</span><a href="#41082760">next</a><span>|</span><label class="collapse" for="c-41081254">[-]</label><label class="expand" for="c-41081254">[8 more]</label></div><br/><div class="children"><div class="content">Where does Deep Learning come in?</div><br/><div id="41081343" class="c"><input type="checkbox" id="c-41081343" checked=""/><div class="controls bullet"><span class="by">thegginthesky</span><span>|</span><a href="#41081254">parent</a><span>|</span><a href="#41081817">next</a><span>|</span><label class="collapse" for="c-41081343">[-]</label><label class="expand" for="c-41081343">[3 more]</label></div><br/><div class="children"><div class="content">Most models are derived of Machine Learning principles that are a mix of classic probability theory, Frequentist and Bayesian statistics and lots of Computer Science fundamentals. But there have been advancements in Bayesian Inference and Bayesian Deep Learning, you should check the work of frameworks like Pyro (built on top of PyTorch)<p>Edit: corrected my sentence, but see 0xdde reply for better info.</div><br/><div id="41081458" class="c"><input type="checkbox" id="c-41081458" checked=""/><div class="controls bullet"><span class="by">0xdde</span><span>|</span><a href="#41081254">root</a><span>|</span><a href="#41081343">parent</a><span>|</span><a href="#41081817">next</a><span>|</span><label class="collapse" for="c-41081458">[-]</label><label class="expand" for="c-41081458">[2 more]</label></div><br/><div class="children"><div class="content">I could be wrong, but my sense is that ML has leaned Bayesian for a very long time. For example, even Bishop&#x27;s widely used book from 2006 [1] is Bayesian. Not sure how Bayesian his new deep learning book is.<p>[1] <a href="https:&#x2F;&#x2F;www.microsoft.com&#x2F;en-us&#x2F;research&#x2F;publication&#x2F;pattern-recognition-machine-learning&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.microsoft.com&#x2F;en-us&#x2F;research&#x2F;publication&#x2F;pattern...</a></div><br/><div id="41081786" class="c"><input type="checkbox" id="c-41081786" checked=""/><div class="controls bullet"><span class="by">thegginthesky</span><span>|</span><a href="#41081254">root</a><span>|</span><a href="#41081458">parent</a><span>|</span><a href="#41081817">next</a><span>|</span><label class="collapse" for="c-41081786">[-]</label><label class="expand" for="c-41081786">[1 more]</label></div><br/><div class="children"><div class="content">I stand corrected! It was my impression that many methods used in ML such as Support Vector Machines, Decision Trees, Random Forests, Boosting, Bagging and so on have very deep roots in Frequentist Methods, although current CS implementations lean heavily on optimizations such as Gradient Descent.<p>Giving a cursory look into Bishop&#x27;s book I see that I am wrong, as there&#x27;s deep root in Bayesian Inference as well.<p>On another note, I find it very interesting that there&#x27;s not a bigger emphasis on using the correct distributions in ML models, as the methods are much more concerned in optimizing objective functions.</div><br/></div></div></div></div></div></div><div id="41081817" class="c"><input type="checkbox" id="c-41081817" checked=""/><div class="controls bullet"><span class="by">vermarish</span><span>|</span><a href="#41081254">parent</a><span>|</span><a href="#41081343">prev</a><span>|</span><a href="#41081808">next</a><span>|</span><label class="collapse" for="c-41081817">[-]</label><label class="expand" for="c-41081817">[1 more]</label></div><br/><div class="children"><div class="content">At a high level, Bayesian statistics and DL share the same objective of fitting parameters to models.<p>In particular, <i>variational inference</i> is a family of techniques that makes these kinds of problems computationally tractable. It shows up everywhere from variational autoencoders, to time-series state-space modeling, to reinforcement learning.<p>If you want to learn more, I recommend reading Murphy&#x27;s textbooks on ML: <a href="https:&#x2F;&#x2F;probml.github.io&#x2F;pml-book&#x2F;book2.html" rel="nofollow">https:&#x2F;&#x2F;probml.github.io&#x2F;pml-book&#x2F;book2.html</a></div><br/></div></div><div id="41081808" class="c"><input type="checkbox" id="c-41081808" checked=""/><div class="controls bullet"><span class="by">tfehring</span><span>|</span><a href="#41081254">parent</a><span>|</span><a href="#41081817">prev</a><span>|</span><a href="#41082236">next</a><span>|</span><label class="collapse" for="c-41081808">[-]</label><label class="expand" for="c-41081808">[1 more]</label></div><br/><div class="children"><div class="content">An implicit shared belief of all of the practitioners the author mentions is that they attempt to construct models that correspond to some underlying &quot;data generating process&quot;. Machine learning practitioners may use similar models or even the same models as Bayesian statisticians, but they tend to evaluate their models primarily or entirely based on their predictive performance, <i>not</i> on intuitions about why the data is taking on the values that it is.<p>See Breiman&#x27;s classic &quot;Two Cultures&quot; paper that this post&#x27;s title is referencing: <a href="https:&#x2F;&#x2F;projecteuclid.org&#x2F;journals&#x2F;statistical-science&#x2F;volume-16&#x2F;issue-3&#x2F;Statistical-Modeling--The-Two-Cultures-with-comments-and-a&#x2F;10.1214&#x2F;ss&#x2F;1009213726.full" rel="nofollow">https:&#x2F;&#x2F;projecteuclid.org&#x2F;journals&#x2F;statistical-science&#x2F;volum...</a></div><br/></div></div><div id="41082236" class="c"><input type="checkbox" id="c-41082236" checked=""/><div class="controls bullet"><span class="by">samch93</span><span>|</span><a href="#41081254">parent</a><span>|</span><a href="#41081808">prev</a><span>|</span><a href="#41081946">next</a><span>|</span><label class="collapse" for="c-41082236">[-]</label><label class="expand" for="c-41082236">[1 more]</label></div><br/><div class="children"><div class="content">A (deep) NN is just a really complicated data model, the way one treats the estimation of its parameters and prediction of new data determines whether one is a Bayesian or a frequentist. The Bayesian assigns a distribution to the parameters and then conditions on the data to obtain a posterior distribution based on which a posterior predictive distribution is obtained for new data, while the frequentist treats parameters as fixed quantities and estimates them from the likelihood alone, e.g., with maximum likelihood (potentially using some hacks such as regularization, which themselves can be given a Bayesian interpretation).</div><br/></div></div><div id="41081946" class="c"><input type="checkbox" id="c-41081946" checked=""/><div class="controls bullet"><span class="by">klysm</span><span>|</span><a href="#41081254">parent</a><span>|</span><a href="#41082236">prev</a><span>|</span><a href="#41082760">next</a><span>|</span><label class="collapse" for="c-41081946">[-]</label><label class="expand" for="c-41081946">[1 more]</label></div><br/><div class="children"><div class="content">Not sure why this is being downvoted, as it’s mentioned peripherally in the article. I think it’s primary used as an extreme example of a model where the inner mechanism is entirely inscrutable.</div><br/></div></div></div></div><div id="41082760" class="c"><input type="checkbox" id="c-41082760" checked=""/><div class="controls bullet"><span class="by">davidgerard</span><span>|</span><a href="#41081254">prev</a><span>|</span><a href="#41081448">next</a><span>|</span><label class="collapse" for="c-41082760">[-]</label><label class="expand" for="c-41082760">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Subjective Bayes<p>&gt; I’m not sure if anyone ever followed this philosophy strictly, nor do I know if anyone would register their affiliation as subjective Bayesian these days.<p>lol the lesswrong&#x2F;rationalist &quot;Bayesians&quot; do this <i>all the time</i>.<p>* I have priors<p>* YOU have biases<p>* HE is a toxoplasmotic culture warrior</div><br/></div></div><div id="41081448" class="c"><input type="checkbox" id="c-41081448" checked=""/><div class="controls bullet"><span class="by">tonymet</span><span>|</span><a href="#41082760">prev</a><span>|</span><label class="collapse" for="c-41081448">[-]</label><label class="expand" for="c-41081448">[4 more]</label></div><br/><div class="children"><div class="content">A priori distributions are a form of stereotyping.  How do people reconcile that?</div><br/><div id="41081959" class="c"><input type="checkbox" id="c-41081959" checked=""/><div class="controls bullet"><span class="by">klysm</span><span>|</span><a href="#41081448">parent</a><span>|</span><a href="#41081731">next</a><span>|</span><label class="collapse" for="c-41081959">[-]</label><label class="expand" for="c-41081959">[2 more]</label></div><br/><div class="children"><div class="content">What? Maybe in a very specific context where you are modeling joint distributions of people and traits, but that’s barely a critique of the method itself.</div><br/><div id="41082223" class="c"><input type="checkbox" id="c-41082223" checked=""/><div class="controls bullet"><span class="by">tonymet</span><span>|</span><a href="#41081448">root</a><span>|</span><a href="#41081959">parent</a><span>|</span><a href="#41081731">next</a><span>|</span><label class="collapse" for="c-41082223">[-]</label><label class="expand" for="c-41082223">[1 more]</label></div><br/><div class="children"><div class="content">it&#x27;s not a critique of the method</div><br/></div></div></div></div><div id="41081731" class="c"><input type="checkbox" id="c-41081731" checked=""/><div class="controls bullet"><span class="by">lupire</span><span>|</span><a href="#41081448">parent</a><span>|</span><a href="#41081959">prev</a><span>|</span><label class="collapse" for="c-41081731">[-]</label><label class="expand" for="c-41081731">[1 more]</label></div><br/><div class="children"><div class="content">A Bayesian analysis lets you see how the posterior varies as a function of the prior, instead of forcing you to pick a prior before you start.<p>The tighter the range of this function, the more confidence you have in the result.<p>You can never know anything if you absolutely refuse to have a prior, because that gives division by 0 in the posterior.</div><br/></div></div></div></div></div></div></div></div></div></body></html>