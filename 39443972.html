<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1708506072825" as="style"/><link rel="stylesheet" href="styles.css?v=1708506072825"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://blog.llamaindex.ai/introducing-llamacloud-and-llamaparse-af8cedf9006b">LlamaCloud and LlamaParse</a> <span class="domain">(<a href="https://blog.llamaindex.ai">blog.llamaindex.ai</a>)</span></div><div class="subtext"><span>eferreira_</span> | <span>68 comments</span></div><br/><div><div id="39444932" class="c"><input type="checkbox" id="c-39444932" checked=""/><div class="controls bullet"><span class="by">pierre</span><span>|</span><a href="#39446772">next</a><span>|</span><label class="collapse" for="c-39444932">[-]</label><label class="expand" for="c-39444932">[23 more]</label></div><br/><div class="children"><div class="content">I&#x27;m part of the team that build LlamaParse. It&#x27;s net improvement compare to other PDF-&gt;Structured Text extractors (I build several in the past, includig <a href="https:&#x2F;&#x2F;github.com&#x2F;axa-group&#x2F;Parsr">https:&#x2F;&#x2F;github.com&#x2F;axa-group&#x2F;Parsr</a>).<p>For character extraction, LlamaParse use a mixture of OCR &#x2F; character extraction from the PDF (it&#x27;s the only parser I&#x27;m aware of that address some of the buggy PDF font issues, check the &#x27;text&#x27; mode to see raw document before reconstruction), use a mixture of heuristic and Machine learning models to reconstruct the document.<p>Once plug with a Recursive retrieval strategy, allow you to get Sota result on question answering over complexe text (see notebook: <a href="https:&#x2F;&#x2F;github.com&#x2F;run-llama&#x2F;llama_parse&#x2F;blob&#x2F;main&#x2F;examples&#x2F;demo_advanced.ipynb">https:&#x2F;&#x2F;github.com&#x2F;run-llama&#x2F;llama_parse&#x2F;blob&#x2F;main&#x2F;examples&#x2F;...</a>).<p>AMA</div><br/><div id="39450682" class="c"><input type="checkbox" id="c-39450682" checked=""/><div class="controls bullet"><span class="by">brendanashworth</span><span>|</span><a href="#39444932">parent</a><span>|</span><a href="#39448745">next</a><span>|</span><label class="collapse" for="c-39450682">[-]</label><label class="expand" for="c-39450682">[2 more]</label></div><br/><div class="children"><div class="content">I am confused by the benchmarks you provided.<p>(1) The &quot;baseline&quot; comparison was to PyPDF + Naive RAG. For the LlamaParse evaluation, you appear to have used a different RAG pipeline, called &quot;recursive retrieval.&quot; Why not use the same pipeline to demonstrate the improvement from LlamaParse? Can you share the code to your evaluation for LlamaParse?<p>(2) I ran the benchmark for the PyPDF + Naive RAG solution, directly copying the code on the linked LlamaIndex repo [1]<p>I got very different numbers:
mean_correctness_score 3.941
mean_relevancy_score 0.826
mean_faithfulness_score 0.980<p>You reported:
mean_correctness_score 3.874
mean_relevancy_score 0.844
mean_faithfulness_score 0.667<p>Notably, the faithfulness score I measured for the baseline solution was actually higher than that reported for your proprietary LlamaParse based solution.<p>[1] <a href="https:&#x2F;&#x2F;github.com&#x2F;run-llama&#x2F;llama-hub&#x2F;tree&#x2F;main&#x2F;llama_hub&#x2F;llama_datasets&#x2F;10k&#x2F;uber_2021">https:&#x2F;&#x2F;github.com&#x2F;run-llama&#x2F;llama-hub&#x2F;tree&#x2F;main&#x2F;llama_hub&#x2F;l...</a></div><br/><div id="39451263" class="c"><input type="checkbox" id="c-39451263" checked=""/><div class="controls bullet"><span class="by">freezed8</span><span>|</span><a href="#39444932">root</a><span>|</span><a href="#39450682">parent</a><span>|</span><a href="#39448745">next</a><span>|</span><label class="collapse" for="c-39451263">[-]</label><label class="expand" for="c-39451263">[1 more]</label></div><br/><div class="children"><div class="content">(jerry here)<p>Thanks for running through the benchmark! Just to clarify some things: 
(1) The idea is that LlamaParse&#x27;s markdown representation lends itself to the rest of LlamaIndex advanced indexing&#x2F;retrieval abstractions. Recursive retrieval is a fancy retrieval method designed to model documents with embedded objects, but depends on good PDF parsing. Naive PyPDF parsing can&#x27;t be used with recursive retrieval. Our goal is to demonstrate the e2e RAG capabilities of LlamaParse + advanced retrieval vs. what you can build with a naive PDF parser.<p>(2). Since we use LLM-based evals, your correctness and relevancy metric look to be consistent and within margin of error (and lower than our llamaparse metrics). The faithfulness score seems way off though and quite high from your side, so not sure what&#x27;s going on there. maybe hop in our discord and share the results in our channel?</div><br/></div></div></div></div><div id="39448745" class="c"><input type="checkbox" id="c-39448745" checked=""/><div class="controls bullet"><span class="by">pryelluw</span><span>|</span><a href="#39444932">parent</a><span>|</span><a href="#39450682">prev</a><span>|</span><a href="#39446637">next</a><span>|</span><label class="collapse" for="c-39448745">[-]</label><label class="expand" for="c-39448745">[5 more]</label></div><br/><div class="children"><div class="content">For context: I’m an engineering manager for the production systems of one of the biggest mortgage companies. Think millions of millions of all kinds of PDF.<p>1. The comparison with the open source pdf libraries is rather strange. They are self contained libraries. Not ML augmented services. Does this mean you plan to open source the underlying technology and offer it under the same licenses as pypdf or pymupdf?<p>2. How does this compare to AWS Kendra? I have one of the bigger deployments out there and am looking for alternatives.<p>3. How fast is the pdf extraction? In terms of microseconds given we pay for execution time.</div><br/><div id="39448815" class="c"><input type="checkbox" id="c-39448815" checked=""/><div class="controls bullet"><span class="by">analyte123</span><span>|</span><a href="#39444932">root</a><span>|</span><a href="#39448745">parent</a><span>|</span><a href="#39450103">next</a><span>|</span><label class="collapse" for="c-39448815">[-]</label><label class="expand" for="c-39448815">[1 more]</label></div><br/><div class="children"><div class="content">Making something appear as if it might be an open source library, but is actually just a wrapper to a paid hosted service is endemic in the Python world in general and the LLM space in particular.</div><br/></div></div><div id="39450103" class="c"><input type="checkbox" id="c-39450103" checked=""/><div class="controls bullet"><span class="by">redactive</span><span>|</span><a href="#39444932">root</a><span>|</span><a href="#39448745">parent</a><span>|</span><a href="#39448815">prev</a><span>|</span><a href="#39446637">next</a><span>|</span><label class="collapse" for="c-39450103">[-]</label><label class="expand" for="c-39450103">[3 more]</label></div><br/><div class="children"><div class="content">Out of interest - Why are you looking to move from Kendra? I havent heard much good about it but keen to understand what your issues with it are.</div><br/><div id="39450379" class="c"><input type="checkbox" id="c-39450379" checked=""/><div class="controls bullet"><span class="by">pryelluw</span><span>|</span><a href="#39444932">root</a><span>|</span><a href="#39450103">parent</a><span>|</span><a href="#39446637">next</a><span>|</span><label class="collapse" for="c-39450379">[-]</label><label class="expand" for="c-39450379">[2 more]</label></div><br/><div class="children"><div class="content">It’s too expensive for the features it provides. The person who estimated the cost got it wrong and were paying 3x. But I can’t just rip it out due to it powering a very important piece of software.</div><br/><div id="39450593" class="c"><input type="checkbox" id="c-39450593" checked=""/><div class="controls bullet"><span class="by">mahmoudimus</span><span>|</span><a href="#39444932">root</a><span>|</span><a href="#39450379">parent</a><span>|</span><a href="#39446637">next</a><span>|</span><label class="collapse" for="c-39450593">[-]</label><label class="expand" for="c-39450593">[1 more]</label></div><br/><div class="children"><div class="content">If you&#x27;re serious about this, I&#x27;m working on a new startup about this that is 100% working on using different techniques to help with this. I&#x27;d love to talk to you about what your needs are as it would help me have more data points as I take this to market. My email is in my profile if you shoot a message.</div><br/></div></div></div></div></div></div></div></div><div id="39446637" class="c"><input type="checkbox" id="c-39446637" checked=""/><div class="controls bullet"><span class="by">chasd00</span><span>|</span><a href="#39444932">parent</a><span>|</span><a href="#39448745">prev</a><span>|</span><a href="#39446830">next</a><span>|</span><label class="collapse" for="c-39446637">[-]</label><label class="expand" for="c-39446637">[2 more]</label></div><br/><div class="children"><div class="content">One of the things I&#x27;ve been helping a team with is dealign with mountains of ppt decks, converted to pdf, and then parsed&#x2F;chunked&#x2F;embedded into vector storage. It doesn&#x27;t work that well because a ppt is not a document. What are your thoughts when dealing with other formats first converted to pdf?</div><br/><div id="39450484" class="c"><input type="checkbox" id="c-39450484" checked=""/><div class="controls bullet"><span class="by">pierre</span><span>|</span><a href="#39444932">root</a><span>|</span><a href="#39446637">parent</a><span>|</span><a href="#39446830">next</a><span>|</span><label class="collapse" for="c-39450484">[-]</label><label class="expand" for="c-39450484">[1 more]</label></div><br/><div class="children"><div class="content">For PPT, chuncking &#x27;per page&#x27; work often quite well. With LlamaParse this will mean splitting on the &quot;\n---\n&quot; page separator token.</div><br/></div></div></div></div><div id="39446830" class="c"><input type="checkbox" id="c-39446830" checked=""/><div class="controls bullet"><span class="by">a2code</span><span>|</span><a href="#39444932">parent</a><span>|</span><a href="#39446637">prev</a><span>|</span><a href="#39446375">next</a><span>|</span><label class="collapse" for="c-39446830">[-]</label><label class="expand" for="c-39446830">[2 more]</label></div><br/><div class="children"><div class="content">Does it work with other filetype converted into PDFs? For example docx, ppt, png, etc.</div><br/><div id="39449924" class="c"><input type="checkbox" id="c-39449924" checked=""/><div class="controls bullet"><span class="by">pierre</span><span>|</span><a href="#39444932">root</a><span>|</span><a href="#39446830">parent</a><span>|</span><a href="#39446375">next</a><span>|</span><label class="collapse" for="c-39449924">[-]</label><label class="expand" for="c-39449924">[1 more]</label></div><br/><div class="children"><div class="content">Yes, however we will soon support other filetypes natively, and this will lead to better results (when converting from one format to another, there is often some information loss)</div><br/></div></div></div></div><div id="39446375" class="c"><input type="checkbox" id="c-39446375" checked=""/><div class="controls bullet"><span class="by">amelius</span><span>|</span><a href="#39444932">parent</a><span>|</span><a href="#39446830">prev</a><span>|</span><a href="#39445685">next</a><span>|</span><label class="collapse" for="c-39446375">[-]</label><label class="expand" for="c-39446375">[1 more]</label></div><br/><div class="children"><div class="content">Can it detect and strip out advertisements?</div><br/></div></div><div id="39445685" class="c"><input type="checkbox" id="c-39445685" checked=""/><div class="controls bullet"><span class="by">binarymax</span><span>|</span><a href="#39444932">parent</a><span>|</span><a href="#39446375">prev</a><span>|</span><a href="#39447697">next</a><span>|</span><label class="collapse" for="c-39445685">[-]</label><label class="expand" for="c-39445685">[9 more]</label></div><br/><div class="children"><div class="content">Cool!  Which OCR engine&#x2F;model do you use?</div><br/><div id="39446076" class="c"><input type="checkbox" id="c-39446076" checked=""/><div class="controls bullet"><span class="by">pierre</span><span>|</span><a href="#39444932">root</a><span>|</span><a href="#39445685">parent</a><span>|</span><a href="#39447697">next</a><span>|</span><label class="collapse" for="c-39446076">[-]</label><label class="expand" for="c-39446076">[8 more]</label></div><br/><div class="children"><div class="content">EasyOCR, may switch to paddleOCR in the future.</div><br/><div id="39446544" class="c"><input type="checkbox" id="c-39446544" checked=""/><div class="controls bullet"><span class="by">vikp</span><span>|</span><a href="#39444932">root</a><span>|</span><a href="#39446076">parent</a><span>|</span><a href="#39448928">next</a><span>|</span><label class="collapse" for="c-39446544">[-]</label><label class="expand" for="c-39446544">[5 more]</label></div><br/><div class="children"><div class="content">You may want to try <a href="https:&#x2F;&#x2F;github.com&#x2F;VikParuchuri&#x2F;surya">https:&#x2F;&#x2F;github.com&#x2F;VikParuchuri&#x2F;surya</a> (I&#x27;m the author).  I&#x27;ve only benchmarked against tesseract, but it outperforms it by a lot (benchmarks in repo). Happy to discuss.<p>You could also try <a href="https:&#x2F;&#x2F;github.com&#x2F;VikParuchuri&#x2F;marker">https:&#x2F;&#x2F;github.com&#x2F;VikParuchuri&#x2F;marker</a> for general PDF parsing (I&#x27;m also the author) - it seems like you&#x27;re more focused on tables.</div><br/><div id="39448382" class="c"><input type="checkbox" id="c-39448382" checked=""/><div class="controls bullet"><span class="by">raffraffraff</span><span>|</span><a href="#39444932">root</a><span>|</span><a href="#39446544">parent</a><span>|</span><a href="#39448847">next</a><span>|</span><label class="collapse" for="c-39448382">[-]</label><label class="expand" for="c-39448382">[3 more]</label></div><br/><div class="children"><div class="content">How does surya compare to AWS  Textract? A previous employer went through a bunch of different OCRs and ended up using Textract because they found it to be the most accurate overall.</div><br/><div id="39450946" class="c"><input type="checkbox" id="c-39450946" checked=""/><div class="controls bullet"><span class="by">kergonath</span><span>|</span><a href="#39444932">root</a><span>|</span><a href="#39448382">parent</a><span>|</span><a href="#39449744">next</a><span>|</span><label class="collapse" for="c-39450946">[-]</label><label class="expand" for="c-39450946">[1 more]</label></div><br/><div class="children"><div class="content">That’s my experience as well. I am still looking for alternatives, but Textract is now the baseline.</div><br/></div></div><div id="39449744" class="c"><input type="checkbox" id="c-39449744" checked=""/><div class="controls bullet"><span class="by">vikp</span><span>|</span><a href="#39444932">root</a><span>|</span><a href="#39448382">parent</a><span>|</span><a href="#39450946">prev</a><span>|</span><a href="#39448847">next</a><span>|</span><label class="collapse" for="c-39449744">[-]</label><label class="expand" for="c-39449744">[1 more]</label></div><br/><div class="children"><div class="content">I unfortunately haven&#x27;t had time to benchmark against more than tesseract.</div><br/></div></div></div></div><div id="39448847" class="c"><input type="checkbox" id="c-39448847" checked=""/><div class="controls bullet"><span class="by">pryelluw</span><span>|</span><a href="#39444932">root</a><span>|</span><a href="#39446544">parent</a><span>|</span><a href="#39448382">prev</a><span>|</span><a href="#39448928">next</a><span>|</span><label class="collapse" for="c-39448847">[-]</label><label class="expand" for="c-39448847">[1 more]</label></div><br/><div class="children"><div class="content">Thanks for sharing.</div><br/></div></div></div></div><div id="39448928" class="c"><input type="checkbox" id="c-39448928" checked=""/><div class="controls bullet"><span class="by">helloericsf</span><span>|</span><a href="#39444932">root</a><span>|</span><a href="#39446076">parent</a><span>|</span><a href="#39446544">prev</a><span>|</span><a href="#39447697">next</a><span>|</span><label class="collapse" for="c-39448928">[-]</label><label class="expand" for="c-39448928">[2 more]</label></div><br/><div class="children"><div class="content">Grateful for your insight!
Could you explain the reason for the switch? 
Is there any benchmark data available for sharing?</div><br/><div id="39450080" class="c"><input type="checkbox" id="c-39450080" checked=""/><div class="controls bullet"><span class="by">pierre</span><span>|</span><a href="#39444932">root</a><span>|</span><a href="#39448928">parent</a><span>|</span><a href="#39447697">next</a><span>|</span><label class="collapse" for="c-39450080">[-]</label><label class="expand" for="c-39450080">[1 more]</label></div><br/><div class="children"><div class="content">Performance depend on the language &#x2F; type of docs. Main reason for contemplating switching is that easyOCR seems to not be maintained anymore (no commit in the repo in last 5 months)</div><br/></div></div></div></div></div></div></div></div></div></div><div id="39446772" class="c"><input type="checkbox" id="c-39446772" checked=""/><div class="controls bullet"><span class="by">behnamoh</span><span>|</span><a href="#39444932">prev</a><span>|</span><a href="#39445495">next</a><span>|</span><label class="collapse" for="c-39446772">[-]</label><label class="expand" for="c-39446772">[3 more]</label></div><br/><div class="children"><div class="content">&gt; This is where LlamaParse comes in. We’ve developed a proprietary parsing service that is incredibly good at parsing PDFs with complex tables into a well-structured markdown format.<p>This is my problem with projects that start off as open source and become famous because of their community contributions and attention, then the project leaders get that sweet VC money (or not) and make something proprietary.<p>We&#x27;ve seen it with Langchain and several other &quot;fake open source&quot; projects.</div><br/><div id="39446941" class="c"><input type="checkbox" id="c-39446941" checked=""/><div class="controls bullet"><span class="by">siquick</span><span>|</span><a href="#39446772">parent</a><span>|</span><a href="#39445495">next</a><span>|</span><label class="collapse" for="c-39446941">[-]</label><label class="expand" for="c-39446941">[2 more]</label></div><br/><div class="children"><div class="content">LlamaParse is proprietary but the main LI package isn’t and you don’t need the former to use the latter.<p>Why shouldn’t they make money? LI is a fantastic way to do RAG.</div><br/><div id="39447171" class="c"><input type="checkbox" id="c-39447171" checked=""/><div class="controls bullet"><span class="by">zmmmmm</span><span>|</span><a href="#39446772">root</a><span>|</span><a href="#39446941">parent</a><span>|</span><a href="#39445495">next</a><span>|</span><label class="collapse" for="c-39447171">[-]</label><label class="expand" for="c-39447171">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t disagree but I think it&#x27;s not a question of &quot;why&quot; but &quot;how&quot;.<p>It could still be licensed in a restricted way, but keeping secret <i>how</i> it works is unfortunate - it breaks the chain of learning that is happening across the open ecosystem and, if the technique is any good, all it does is force open models to build an actually open equivalent so that further progress can be made (and if it&#x27;s not really any good then it&#x27;s snake oil, which is worse). Even if it&#x27;s great it essentially becomes a dead end for the people who actually need and want an open model ecosystem.</div><br/></div></div></div></div></div></div><div id="39445495" class="c"><input type="checkbox" id="c-39445495" checked=""/><div class="controls bullet"><span class="by">srameshc</span><span>|</span><a href="#39446772">prev</a><span>|</span><a href="#39445424">next</a><span>|</span><label class="collapse" for="c-39445495">[-]</label><label class="expand" for="c-39445495">[5 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t understand why post this on medium ? Medium doesn&#x27;t let me even read anymore. If you have a blog post on it so your audience can reach you.</div><br/><div id="39445761" class="c"><input type="checkbox" id="c-39445761" checked=""/><div class="controls bullet"><span class="by">seldo</span><span>|</span><a href="#39445495">parent</a><span>|</span><a href="#39445533">next</a><span>|</span><label class="collapse" for="c-39445761">[-]</label><label class="expand" for="c-39445761">[2 more]</label></div><br/><div class="children"><div class="content">We are planning to move our blog off of Medium (we&#x27;ve been busy!), but this post is public so you can actually just click through the nag screen if you see one.</div><br/></div></div><div id="39445533" class="c"><input type="checkbox" id="c-39445533" checked=""/><div class="controls bullet"><span class="by">eferreira_</span><span>|</span><a href="#39445495">parent</a><span>|</span><a href="#39445761">prev</a><span>|</span><a href="#39445424">next</a><span>|</span><label class="collapse" for="c-39445533">[-]</label><label class="expand" for="c-39445533">[2 more]</label></div><br/><div class="children"><div class="content">Also, have a X (formerly Twitter) thread:<p><a href="https:&#x2F;&#x2F;x.com&#x2F;llama_index&#x2F;status&#x2F;1759987390435996120?s=20" rel="nofollow">https:&#x2F;&#x2F;x.com&#x2F;llama_index&#x2F;status&#x2F;1759987390435996120?s=20</a></div><br/><div id="39445546" class="c"><input type="checkbox" id="c-39445546" checked=""/><div class="controls bullet"><span class="by">diggan</span><span>|</span><a href="#39445495">root</a><span>|</span><a href="#39445533">parent</a><span>|</span><a href="#39445424">next</a><span>|</span><label class="collapse" for="c-39445546">[-]</label><label class="expand" for="c-39445546">[1 more]</label></div><br/><div class="children"><div class="content">Which also isn&#x27;t really available to unregistered users, can only see the first tweet: <a href="https:&#x2F;&#x2F;i.imgur.com&#x2F;SJA2Gzs.png" rel="nofollow">https:&#x2F;&#x2F;i.imgur.com&#x2F;SJA2Gzs.png</a></div><br/></div></div></div></div></div></div><div id="39445424" class="c"><input type="checkbox" id="c-39445424" checked=""/><div class="controls bullet"><span class="by">johnsutor</span><span>|</span><a href="#39445495">prev</a><span>|</span><a href="#39448395">next</a><span>|</span><label class="collapse" for="c-39445424">[-]</label><label class="expand" for="c-39445424">[5 more]</label></div><br/><div class="children"><div class="content">I wonder how LlamaParse compares head to head with <a href="https:&#x2F;&#x2F;unstructured.io" rel="nofollow">https:&#x2F;&#x2F;unstructured.io</a></div><br/><div id="39447978" class="c"><input type="checkbox" id="c-39447978" checked=""/><div class="controls bullet"><span class="by">infecto</span><span>|</span><a href="#39445424">parent</a><span>|</span><a href="#39446764">next</a><span>|</span><label class="collapse" for="c-39447978">[-]</label><label class="expand" for="c-39447978">[3 more]</label></div><br/><div class="children"><div class="content">I would also like how it compares to any of the commercial offerings from Azure&#x2F;AWS&#x2F;GCP. They all have document parsing tools that I have found better than tools like unstructured. Sure you don&#x27;t have some of the &quot;magic&quot; of segmenting text for vectorization and RAG but imo thats the easy part. The hard part is pulling data, forms, tables, text out of the PDF which I find the cloud tools to do a superior job.</div><br/><div id="39448952" class="c"><input type="checkbox" id="c-39448952" checked=""/><div class="controls bullet"><span class="by">bugglebeetle</span><span>|</span><a href="#39445424">root</a><span>|</span><a href="#39447978">parent</a><span>|</span><a href="#39446764">next</a><span>|</span><label class="collapse" for="c-39448952">[-]</label><label class="expand" for="c-39448952">[2 more]</label></div><br/><div class="children"><div class="content">Nothing beats Google text extraction tasks in my testing, especially for East Asian languages. I wish something else worked better, because their services are fairly expensive.</div><br/><div id="39449116" class="c"><input type="checkbox" id="c-39449116" checked=""/><div class="controls bullet"><span class="by">infecto</span><span>|</span><a href="#39445424">root</a><span>|</span><a href="#39448952">parent</a><span>|</span><a href="#39446764">next</a><span>|</span><label class="collapse" for="c-39449116">[-]</label><label class="expand" for="c-39449116">[1 more]</label></div><br/><div class="children"><div class="content">I mostly have used Textract but have found all 3 to be fairly similar in accuracy with differences in structure and compatible languages. I think my call out here is that I don&#x27;t think any of these libraries, llamaindex or unstructured, can compete in this area. I would rather use GCP&#x2F;Azure&#x2F;AWS to define the structure from a PDF and these for the rag portion if anything.</div><br/></div></div></div></div></div></div><div id="39446764" class="c"><input type="checkbox" id="c-39446764" checked=""/><div class="controls bullet"><span class="by">justanotheratom</span><span>|</span><a href="#39445424">parent</a><span>|</span><a href="#39447978">prev</a><span>|</span><a href="#39448395">next</a><span>|</span><label class="collapse" for="c-39446764">[-]</label><label class="expand" for="c-39446764">[1 more]</label></div><br/><div class="children"><div class="content">not clear to me why this got downvoted. sensible question.</div><br/></div></div></div></div><div id="39448395" class="c"><input type="checkbox" id="c-39448395" checked=""/><div class="controls bullet"><span class="by">kurts_mustache</span><span>|</span><a href="#39445424">prev</a><span>|</span><a href="#39447730">next</a><span>|</span><label class="collapse" for="c-39448395">[-]</label><label class="expand" for="c-39448395">[2 more]</label></div><br/><div class="children"><div class="content">Hmm, I have to say I&#x27;m pretty unimpressed with my initial experience here.<p>1. The sign up with email just endlessly redirected, click link in email, ask to sign up with email, put in email, click link in email, etc.<p>2. Fine, I&#x27;ll sign in with Google.<p>3. A PDF parser? Seriously that&#x27;s what all this fuss is about? There are so many options already out there, PDFBox, iText, Unstructured, PyPDF, PDF.js, PdfMiner not to mention extraction services available from the hyperscalers. Super confused why anyone needs this.</div><br/><div id="39450420" class="c"><input type="checkbox" id="c-39450420" checked=""/><div class="controls bullet"><span class="by">verdverm</span><span>|</span><a href="#39448395">parent</a><span>|</span><a href="#39447730">next</a><span>|</span><label class="collapse" for="c-39450420">[-]</label><label class="expand" for="c-39450420">[1 more]</label></div><br/><div class="children"><div class="content">LLaMA Index is way more than a PDF parser. It&#x27;s the most widely used RAG tool chain and their cloud looks to be a managed version of that.<p>Specific to the parser, they do show where tools like those you mentioned fail and their LLM based parser captures the full data the aforementioned miss.</div><br/></div></div></div></div><div id="39447730" class="c"><input type="checkbox" id="c-39447730" checked=""/><div class="controls bullet"><span class="by">lolpanda</span><span>|</span><a href="#39448395">prev</a><span>|</span><a href="#39447375">next</a><span>|</span><label class="collapse" for="c-39447730">[-]</label><label class="expand" for="c-39447730">[3 more]</label></div><br/><div class="children"><div class="content">I think LlamaParse is trying to solve a hard problem. Many enterprise customers I know have strong need to parse PDF files and extract data accurately.
I found the interface a bit confusing. From your blog post, LlamaParse can extract numbers in tables, but it appears that the output isn&#x27;t provided in tabular format. Instead, access to these numbers is only available through a question-answering. Is this accurate?</div><br/><div id="39448328" class="c"><input type="checkbox" id="c-39448328" checked=""/><div class="controls bullet"><span class="by">cheesyFishes</span><span>|</span><a href="#39447730">parent</a><span>|</span><a href="#39447375">next</a><span>|</span><label class="collapse" for="c-39448328">[-]</label><label class="expand" for="c-39448328">[2 more]</label></div><br/><div class="children"><div class="content">The output is either text or markdown, and from there you can handle it however you need.<p>In LlamaIndex for example, there are a a few markdown-specific classes that work well with this.<p>You can find an example over in the repo -- <a href="https:&#x2F;&#x2F;github.com&#x2F;run-llama&#x2F;llama_parse&#x2F;blob&#x2F;main&#x2F;examples&#x2F;demo_advanced.ipynb">https:&#x2F;&#x2F;github.com&#x2F;run-llama&#x2F;llama_parse&#x2F;blob&#x2F;main&#x2F;examples&#x2F;...</a></div><br/><div id="39448373" class="c"><input type="checkbox" id="c-39448373" checked=""/><div class="controls bullet"><span class="by">lolpanda</span><span>|</span><a href="#39447730">root</a><span>|</span><a href="#39448328">parent</a><span>|</span><a href="#39447375">next</a><span>|</span><label class="collapse" for="c-39448373">[-]</label><label class="expand" for="c-39448373">[1 more]</label></div><br/><div class="children"><div class="content">I was hoping to get structured data. For example, parsing an voice will give results like 
{&quot;title&quot;... &quot;line_items&quot;: [...], &quot;date&quot;:...}</div><br/></div></div></div></div></div></div><div id="39447375" class="c"><input type="checkbox" id="c-39447375" checked=""/><div class="controls bullet"><span class="by">_pdp_</span><span>|</span><a href="#39447730">prev</a><span>|</span><a href="#39446602">next</a><span>|</span><label class="collapse" for="c-39447375">[-]</label><label class="expand" for="c-39447375">[1 more]</label></div><br/><div class="children"><div class="content">Question, why build this when you can use LLMS to extract the data in the most appropriate format to begin with? Isn&#x27;t this a bit redundant? Perhaps it makes sense in the short term due to cost but in the long run this problem can be solved generically with LLMS.</div><br/></div></div><div id="39446602" class="c"><input type="checkbox" id="c-39446602" checked=""/><div class="controls bullet"><span class="by">lxe</span><span>|</span><a href="#39447375">prev</a><span>|</span><a href="#39445251">next</a><span>|</span><label class="collapse" for="c-39446602">[-]</label><label class="expand" for="c-39446602">[1 more]</label></div><br/><div class="children"><div class="content">LlamaParse solves exactly the problem I&#x27;ve encountered over and over with RAG. Getting structured info from unstructured data is a pain.</div><br/></div></div><div id="39445251" class="c"><input type="checkbox" id="c-39445251" checked=""/><div class="controls bullet"><span class="by">bx376</span><span>|</span><a href="#39446602">prev</a><span>|</span><a href="#39446651">next</a><span>|</span><label class="collapse" for="c-39445251">[-]</label><label class="expand" for="c-39445251">[1 more]</label></div><br/><div class="children"><div class="content">What will the pricing be like?</div><br/></div></div><div id="39446651" class="c"><input type="checkbox" id="c-39446651" checked=""/><div class="controls bullet"><span class="by">pknerd</span><span>|</span><a href="#39445251">prev</a><span>|</span><a href="#39446745">next</a><span>|</span><label class="collapse" for="c-39446651">[-]</label><label class="expand" for="c-39446651">[10 more]</label></div><br/><div class="children"><div class="content">Sorry for offtopic: Are there any LLM services that I can use in cloud similar to OpenAI? I do not have good enough Macbook to run different models locally</div><br/><div id="39451566" class="c"><input type="checkbox" id="c-39451566" checked=""/><div class="controls bullet"><span class="by">fredb-ai21</span><span>|</span><a href="#39446651">parent</a><span>|</span><a href="#39446888">next</a><span>|</span><label class="collapse" for="c-39451566">[-]</label><label class="expand" for="c-39451566">[1 more]</label></div><br/><div class="children"><div class="content">AI21 Labs provides access to its Jurassic-2 LLM (and derived models for summarization, grammatical error correction etc.) via a web UI [1] and an API.<p>Disclaimer: I&#x27;m a software engineer at AI21.<p>[1] <a href="https:&#x2F;&#x2F;www.ai21.com&#x2F;studio" rel="nofollow">https:&#x2F;&#x2F;www.ai21.com&#x2F;studio</a></div><br/></div></div><div id="39446888" class="c"><input type="checkbox" id="c-39446888" checked=""/><div class="controls bullet"><span class="by">sebastiennight</span><span>|</span><a href="#39446651">parent</a><span>|</span><a href="#39451566">prev</a><span>|</span><a href="#39446693">next</a><span>|</span><label class="collapse" for="c-39446888">[-]</label><label class="expand" for="c-39446888">[1 more]</label></div><br/><div class="children"><div class="content">If you use the LLM Chatbot arena[1], you can get two bots to compete to solve your prompts!<p>[1]: <a href="https:&#x2F;&#x2F;chat.lmsys.org&#x2F;?arena" rel="nofollow">https:&#x2F;&#x2F;chat.lmsys.org&#x2F;?arena</a></div><br/></div></div><div id="39446693" class="c"><input type="checkbox" id="c-39446693" checked=""/><div class="controls bullet"><span class="by">tslmy</span><span>|</span><a href="#39446651">parent</a><span>|</span><a href="#39446888">prev</a><span>|</span><a href="#39449908">next</a><span>|</span><label class="collapse" for="c-39446693">[-]</label><label class="expand" for="c-39446693">[5 more]</label></div><br/><div class="children"><div class="content">Hmmm... OpenAI itself?<p>Did you intend to rule out OpenAI from consideration?<p>You mentioned hardware being a constraint, but that doesn&#x27;t tell me why you specifically wanted to find an alternative to OpenAI.</div><br/><div id="39446859" class="c"><input type="checkbox" id="c-39446859" checked=""/><div class="controls bullet"><span class="by">pknerd</span><span>|</span><a href="#39446651">root</a><span>|</span><a href="#39446693">parent</a><span>|</span><a href="#39446791">next</a><span>|</span><label class="collapse" for="c-39446859">[-]</label><label class="expand" for="c-39446859">[2 more]</label></div><br/><div class="children"><div class="content">I have used openAI but I want to try several other LLMs as well.</div><br/></div></div><div id="39446791" class="c"><input type="checkbox" id="c-39446791" checked=""/><div class="controls bullet"><span class="by">simion314</span><span>|</span><a href="#39446651">root</a><span>|</span><a href="#39446693">parent</a><span>|</span><a href="#39446859">prev</a><span>|</span><a href="#39449908">next</a><span>|</span><label class="collapse" for="c-39446791">[-]</label><label class="expand" for="c-39446791">[2 more]</label></div><br/><div class="children"><div class="content">Not OP, in my case OpenAI does not want my money, they only accept credit cards. For example netflix wants my money so they have more choices.<p>Also I would like to pay for an equivalent alternative that  is less censored, like ChatGPT had a bug one day that it refused to tell me how to force a type cast in TypeScript, it showed me a moderation error.  So I want an AI that is targeted for adults and not children in some religious school in USA.</div><br/><div id="39449129" class="c"><input type="checkbox" id="c-39449129" checked=""/><div class="controls bullet"><span class="by">123yawaworht456</span><span>|</span><a href="#39446651">root</a><span>|</span><a href="#39446791">parent</a><span>|</span><a href="#39449908">next</a><span>|</span><label class="collapse" for="c-39449129">[-]</label><label class="expand" for="c-39449129">[1 more]</label></div><br/><div class="children"><div class="content">there is a <i>somewhat</i> unfiltered GPT4 at Azure, but they <i>really</i> don&#x27;t want anybody&#x27;s money (afaik only &quot;trusted&quot; corporate entities can access it)<p>at this time, your only option is local models. if you don&#x27;t have the hardware to run them yourself, there are plenty of hosts - poe&#x2F;perplexity&#x2F;together etc.<p>llama3 is (hopefully) coming soon, and if it has improved as much as llama2 improved over llama1, and provides at least 16k baseline context size, it will be in between gpt3.5 and gpt4 in terms of quality, which is mostly enough.</div><br/></div></div></div></div></div></div><div id="39449908" class="c"><input type="checkbox" id="c-39449908" checked=""/><div class="controls bullet"><span class="by">nl</span><span>|</span><a href="#39446651">parent</a><span>|</span><a href="#39446693">prev</a><span>|</span><a href="#39446744">next</a><span>|</span><label class="collapse" for="c-39449908">[-]</label><label class="expand" for="c-39449908">[1 more]</label></div><br/><div class="children"><div class="content">TogetherAI: Unaffiliated, but I&#x27;ve found it good.<p>Others include Runpod, Replicate, probably others.</div><br/></div></div><div id="39446744" class="c"><input type="checkbox" id="c-39446744" checked=""/><div class="controls bullet"><span class="by">adhamsalama</span><span>|</span><a href="#39446651">parent</a><span>|</span><a href="#39449908">prev</a><span>|</span><a href="#39446745">next</a><span>|</span><label class="collapse" for="c-39446744">[-]</label><label class="expand" for="c-39446744">[1 more]</label></div><br/><div class="children"><div class="content">I think Anthropic and Mistral offer this but you have to join their waiting lists first.</div><br/></div></div></div></div><div id="39446745" class="c"><input type="checkbox" id="c-39446745" checked=""/><div class="controls bullet"><span class="by">technics256</span><span>|</span><a href="#39446651">prev</a><span>|</span><a href="#39446876">next</a><span>|</span><label class="collapse" for="c-39446745">[-]</label><label class="expand" for="c-39446745">[1 more]</label></div><br/><div class="children"><div class="content">LlamaParse looks nice. Is there way to return page numbers also with the markdown? This is important for our use case.</div><br/></div></div><div id="39446876" class="c"><input type="checkbox" id="c-39446876" checked=""/><div class="controls bullet"><span class="by">baby</span><span>|</span><a href="#39446745">prev</a><span>|</span><a href="#39444891">next</a><span>|</span><label class="collapse" for="c-39446876">[-]</label><label class="expand" for="c-39446876">[2 more]</label></div><br/><div class="children"><div class="content">what is RAG?</div><br/><div id="39446895" class="c"><input type="checkbox" id="c-39446895" checked=""/><div class="controls bullet"><span class="by">doublerabbit</span><span>|</span><a href="#39446876">parent</a><span>|</span><a href="#39444891">next</a><span>|</span><label class="collapse" for="c-39446895">[-]</label><label class="expand" for="c-39446895">[1 more]</label></div><br/><div class="children"><div class="content">retrieval augmented generation.<p>Explained by gpt itself as if you were a teddy bear.<p>----<p>Okay little teddybears, let me explain what retrieval augmented generation is in a way you can understand!<p>You see, sometimes when big AI models like Claude want to talk about something, they may not know all the facts. But they have a friend named the knowledge base who knows lots of information!<p>When Claude wants to talk about something new, he first asks the knowledge base &quot;What do you know about X?&quot;. The knowledge base looks through all its facts and finds the most helpful ones. Then it shares them with Claude so he has more context before talking.<p>This process of Claude asking the knowledge base for facts is called retrieval augmented generation. It helps Claude sound smarter and avoid mistakes, because he has extra information from his knowledgeable friend the knowledge base.<p>The next time Claude wants to chat with you teddybears, he will be even better prepared with facts from the knowledge base to have an interesting conversation!</div><br/></div></div></div></div><div id="39444891" class="c"><input type="checkbox" id="c-39444891" checked=""/><div class="controls bullet"><span class="by">coding123</span><span>|</span><a href="#39446876">prev</a><span>|</span><a href="#39445389">next</a><span>|</span><label class="collapse" for="c-39444891">[-]</label><label class="expand" for="c-39444891">[3 more]</label></div><br/><div class="children"><div class="content">What&#x27;s a RAG application</div><br/><div id="39444984" class="c"><input type="checkbox" id="c-39444984" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#39444891">parent</a><span>|</span><a href="#39444919">next</a><span>|</span><label class="collapse" for="c-39444984">[-]</label><label class="expand" for="c-39444984">[1 more]</label></div><br/><div class="children"><div class="content">RAG stands for Retrieval Augmented Generation.<p>It&#x27;s the trick where a user asks you a question: &quot;Who worked on the billing UI refresh last year?&quot; - and you turn that question into a search against a bunch of private documents, find the top matches, copy them into a big prompt to an LLM and ask it to use that data to answer the user&#x27;s question.<p>There&#x27;s a HUGE amount of depth to building this well - it&#x27;s one of the most actively explored parts of LLM&#x2F;generative-AI at the moment, because being able to ask human-language questions of large private datasets is incredibly useful.</div><br/></div></div><div id="39444919" class="c"><input type="checkbox" id="c-39444919" checked=""/><div class="controls bullet"><span class="by">seldo</span><span>|</span><a href="#39444891">parent</a><span>|</span><a href="#39444984">prev</a><span>|</span><a href="#39445389">next</a><span>|</span><label class="collapse" for="c-39444919">[-]</label><label class="expand" for="c-39444919">[1 more]</label></div><br/><div class="children"><div class="content">Retrieval-Augmented Generation, where you ask an LLM to answer a question by giving it some context information that you have retrieved from your own data rather than just the data it was trained on.</div><br/></div></div></div></div><div id="39445389" class="c"><input type="checkbox" id="c-39445389" checked=""/><div class="controls bullet"><span class="by">ldjkfkdsjnv</span><span>|</span><a href="#39444891">prev</a><span>|</span><a href="#39445661">next</a><span>|</span><label class="collapse" for="c-39445389">[-]</label><label class="expand" for="c-39445389">[4 more]</label></div><br/><div class="children"><div class="content">Modern playbook:<p>1. Build janky open source code base<p>2. Sell compute to run it<p>3. Build features that create compute lock in (vercel is a master at this)</div><br/><div id="39446753" class="c"><input type="checkbox" id="c-39446753" checked=""/><div class="controls bullet"><span class="by">tslmy</span><span>|</span><a href="#39445389">parent</a><span>|</span><a href="#39445661">next</a><span>|</span><label class="collapse" for="c-39446753">[-]</label><label class="expand" for="c-39446753">[3 more]</label></div><br/><div class="children"><div class="content">Here&#x27;s an alternative:<p>Spend seed round investments on building a solid software but not building an income stream that can satisfy investors, thus not receiving any new funding and let the company die.</div><br/><div id="39448986" class="c"><input type="checkbox" id="c-39448986" checked=""/><div class="controls bullet"><span class="by">gbickford</span><span>|</span><a href="#39445389">root</a><span>|</span><a href="#39446753">parent</a><span>|</span><a href="#39445661">next</a><span>|</span><label class="collapse" for="c-39448986">[-]</label><label class="expand" for="c-39448986">[2 more]</label></div><br/><div class="children"><div class="content">There&#x27;s gotta be somewhere in the middle. Vercel&#x27;s movements feel a lot like the &quot;Embrace, extend, and extinguish&quot; playbook.<p>Maybe there is a class of developer out there that doesn&#x27;t get spooked by that but it definitely has created an adversarial place for Vercel in my mind. I feel like I need to be careful when touching anything Vercel have touched so that I don&#x27;t fall into a trap.</div><br/><div id="39450444" class="c"><input type="checkbox" id="c-39450444" checked=""/><div class="controls bullet"><span class="by">verdverm</span><span>|</span><a href="#39445389">root</a><span>|</span><a href="#39448986">parent</a><span>|</span><a href="#39445661">next</a><span>|</span><label class="collapse" for="c-39450444">[-]</label><label class="expand" for="c-39450444">[1 more]</label></div><br/><div class="children"><div class="content">I just stopped using their NextJS project because you can no longer self host the middleware, they now only support edge runtime and several libraries don&#x27;t work with it.<p>I&#x27;m calling this situation Fauxpen Source. The recent moves definitely feel anticompetitive or at least trying to force you into using their products<p>I&#x27;m migrating to vite+vike (next&#x2F;nuxt like experience for any framework)</div><br/></div></div></div></div></div></div></div></div><div id="39445661" class="c"><input type="checkbox" id="c-39445661" checked=""/><div class="controls bullet"><span class="by">miohtama</span><span>|</span><a href="#39445389">prev</a><span>|</span><label class="collapse" for="c-39445661">[-]</label><label class="expand" for="c-39445661">[3 more]</label></div><br/><div class="children"><div class="content">&gt; PDFs are specifically a problem: I have complex docs with lots of messy formatting. How do I represent this in the right way so the LLM can understand it?<p>40 years after PostScript and this is still a problem that one needs to throw AI at. I feel the software development and human-computer interaction took a wrong turn along the way. What happened to the semantic web?</div><br/><div id="39445694" class="c"><input type="checkbox" id="c-39445694" checked=""/><div class="controls bullet"><span class="by">avhon1</span><span>|</span><a href="#39445661">parent</a><span>|</span><a href="#39445787">next</a><span>|</span><label class="collapse" for="c-39445694">[-]</label><label class="expand" for="c-39445694">[1 more]</label></div><br/><div class="children"><div class="content">It turns out that it takes thought effort to semantically tag&#x2F;classify everything consistently and completely, so rather than make the decisions, it&#x27;s easier to just not do it.</div><br/></div></div><div id="39445787" class="c"><input type="checkbox" id="c-39445787" checked=""/><div class="controls bullet"><span class="by">madeofpalk</span><span>|</span><a href="#39445661">parent</a><span>|</span><a href="#39445694">prev</a><span>|</span><label class="collapse" for="c-39445787">[-]</label><label class="expand" for="c-39445787">[1 more]</label></div><br/><div class="children"><div class="content">What?<p>We still have &#x27;the web&#x27;. PDFs are something different and separate.</div><br/></div></div></div></div></div></div></div></div></div></body></html>