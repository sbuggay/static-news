<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1737104455656" as="style"/><link rel="stylesheet" href="styles.css?v=1737104455656"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://blog.yfzhou.fyi/posts/tdd-llm/">Test-driven development with an LLM for fun and profit</a> <span class="domain">(<a href="https://blog.yfzhou.fyi">blog.yfzhou.fyi</a>)</span></div><div class="subtext"><span>crazylogger</span> | <span>65 comments</span></div><br/><div><div id="42728570" class="c"><input type="checkbox" id="c-42728570" checked=""/><div class="controls bullet"><span class="by">xianshou</span><span>|</span><a href="#42728826">next</a><span>|</span><label class="collapse" for="c-42728570">[-]</label><label class="expand" for="c-42728570">[26 more]</label></div><br/><div class="children"><div class="content">One trend I&#x27;ve noticed, framed as a logical deduction:<p>1. Coding assistants based on o1 and Sonnet are pretty great at coding with &lt;50k context, but degrade rapidly beyond that.<p>2. Coding agents do massively better when they have a test-driven reward signal.<p>3. If a problem can be framed in a way that a coding agent can solve, that speeds up development at least 10x from the base case of human + assistant.<p>4. From (1)-(3), if you can get all the necessary context into 50k tokens and measure progress via tests, you can speed up development by 10x.<p>5. Therefore all new development should be microservices written from scratch and interacting via cleanly defined APIs.<p>Sure enough, I see HN projects evolving in that direction.</div><br/><div id="42730016" class="c"><input type="checkbox" id="c-42730016" checked=""/><div class="controls bullet"><span class="by">swatcoder</span><span>|</span><a href="#42728570">parent</a><span>|</span><a href="#42729039">next</a><span>|</span><label class="collapse" for="c-42730016">[-]</label><label class="expand" for="c-42730016">[5 more]</label></div><br/><div class="children"><div class="content">&gt; 3. If a problem can be framed in a way that a coding agent can solve...<p>This reminds me of the South Park underwear gnomes. You picked a tool and set an expectation, then just kind of hand wave over the hard part in the middle, as though framing problems &quot;in a way coding agents can solve&quot; is itself a well-understood or bounded problem.<p>Does it sometimes take 50x effort to understand a problem and the agent well enough to get that done? Are there classes of problems where it can&#x27;t be done? Are either of those concerns something you can recognize before they impact you? At commercial quality, is it an accessible skill for inexperienced people or do you need a mastery of coding, the problem domain, or the coding agent to be able to rely on it? Can teams recruit people who can reliable achieve any of this? How expensive is <i>that</i> talent? etc</div><br/><div id="42731937" class="c"><input type="checkbox" id="c-42731937" checked=""/><div class="controls bullet"><span class="by">hitchstory</span><span>|</span><a href="#42728570">root</a><span>|</span><a href="#42730016">parent</a><span>|</span><a href="#42731292">next</a><span>|</span><label class="collapse" for="c-42731937">[-]</label><label class="expand" for="c-42731937">[1 more]</label></div><br/><div class="children"><div class="content">&gt;as though framing problems &quot;in a way coding agents can solve&quot; is itself a well-understood or bounded problem.<p>It&#x27;s not, but if you can A) make it cheap to try out different types of framings - not all of them have to work and B) automate everything else then the labor intensity of programming decreases drastically.<p>&gt;At commercial quality, is it an accessible skill for inexperienced people<p>I&#x27;d expect the opposite, it would be an extremely inaccessible skill requiring high skill and high pay. But, if 2 people can deliver as much as 15 people at a higher quality and they&#x27;re paid triple, it&#x27;s still way cheaper overall.<p>I would still expect somebody following this development pattern to routinely discover a problem the LLM can&#x27;t deal with and have to dive under the hood to fix it - digging down below multiple levels of abstraction. This would be <i>Hard</i> with a capital H.</div><br/></div></div><div id="42731292" class="c"><input type="checkbox" id="c-42731292" checked=""/><div class="controls bullet"><span class="by">emptiestplace</span><span>|</span><a href="#42728570">root</a><span>|</span><a href="#42730016">parent</a><span>|</span><a href="#42731937">prev</a><span>|</span><a href="#42729039">next</a><span>|</span><label class="collapse" for="c-42731292">[-]</label><label class="expand" for="c-42731292">[3 more]</label></div><br/><div class="children"><div class="content">We&#x27;ve had failed projects since long before LLMs. I think there is a tendency for people to gloss over this (3.) regardless, but working with an LLM it tends to become obvious much more quickly, without investing tens&#x2F;hundreds of person-hours. I know it&#x27;s not perfect, but I find a lot of the things people complain about would&#x27;ve been a problem either way - especially when people think they are going to go from &#x27;hello world&#x27; to SaaS-billionaire in an hour.<p>I think mastery of the problem domain is still important, and until we have effectively infinite context windows (that work perfectly), you will need to understand how and when to refactor to maximize quality and relevance of data in context.</div><br/><div id="42731453" class="c"><input type="checkbox" id="c-42731453" checked=""/><div class="controls bullet"><span class="by">dingnuts</span><span>|</span><a href="#42728570">root</a><span>|</span><a href="#42731292">parent</a><span>|</span><a href="#42729039">next</a><span>|</span><label class="collapse" for="c-42731453">[-]</label><label class="expand" for="c-42731453">[2 more]</label></div><br/><div class="children"><div class="content">well according to xianshou&#x27;s profile they work in finance so it makes sense to me that they would gloss over the hard part of programming when describing how AI is going to improve it</div><br/><div id="42731836" class="c"><input type="checkbox" id="c-42731836" checked=""/><div class="controls bullet"><span class="by">ziddoap</span><span>|</span><a href="#42728570">root</a><span>|</span><a href="#42731453">parent</a><span>|</span><a href="#42729039">next</a><span>|</span><label class="collapse" for="c-42731836">[-]</label><label class="expand" for="c-42731836">[1 more]</label></div><br/><div class="children"><div class="content">Working in one domain does not preclude knowledge of others. I work in cybersec but spent my first working decade in construction estimation for institutional builds. I can talk confidently about firewalls or the hospital you want to build.<p>No need to make assumptions based on a one-line hacker news profile.</div><br/></div></div></div></div></div></div></div></div><div id="42729039" class="c"><input type="checkbox" id="c-42729039" checked=""/><div class="controls bullet"><span class="by">Arcuru</span><span>|</span><a href="#42728570">parent</a><span>|</span><a href="#42730016">prev</a><span>|</span><a href="#42730842">next</a><span>|</span><label class="collapse" for="c-42729039">[-]</label><label class="expand" for="c-42729039">[4 more]</label></div><br/><div class="children"><div class="content">&gt; 5. Therefore all new development should be microservices written from scratch and interacting via cleanly defined APIs.<p>Not necessarily. You can get the same benefits you described in (1)-(3) by using clearly defined modules in your codebase, they don&#x27;t need to be separate microservices.</div><br/><div id="42729689" class="c"><input type="checkbox" id="c-42729689" checked=""/><div class="controls bullet"><span class="by">sdesol</span><span>|</span><a href="#42728570">root</a><span>|</span><a href="#42729039">parent</a><span>|</span><a href="#42730842">next</a><span>|</span><label class="collapse" for="c-42729689">[-]</label><label class="expand" for="c-42729689">[3 more]</label></div><br/><div class="children"><div class="content">Agreed. If the microservice does not provide any value from being isolated, it is just a function call with extra steps.</div><br/><div id="42731310" class="c"><input type="checkbox" id="c-42731310" checked=""/><div class="controls bullet"><span class="by">__MatrixMan__</span><span>|</span><a href="#42728570">root</a><span>|</span><a href="#42729689">parent</a><span>|</span><a href="#42730842">next</a><span>|</span><label class="collapse" for="c-42731310">[-]</label><label class="expand" for="c-42731310">[2 more]</label></div><br/><div class="children"><div class="content">I think the argument is that the extra value provided is a small enough context window for working with an LLM.  Although I&#x27;d suggest making it a library if one can manage, that gives you the desired context reduction bounded by interfaces without taking on the complexities of adding an additional microservice.<p>I imagine throwing a test at an LLM and saying:<p>&gt; hold the component under test constant (as well as the test itself), and walk the versions of the library until you can tell me where they&#x27;re compatible and where they break.<p>If you tried to do that with a git bisect and everything in the same codebase, you&#x27;d end up varying all three (test, component, library) which is worse science than holding two constant and varying the third would be.</div><br/><div id="42732302" class="c"><input type="checkbox" id="c-42732302" checked=""/><div class="controls bullet"><span class="by">sdesol</span><span>|</span><a href="#42728570">root</a><span>|</span><a href="#42731310">parent</a><span>|</span><a href="#42730842">next</a><span>|</span><label class="collapse" for="c-42732302">[-]</label><label class="expand" for="c-42732302">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I think the argument is that the extra value provided is a small enough context window for working with an LLM.<p>I&#x27;m not sure moving something that could work as function to a microservice would save much context.  If anything, I think you are adding more context, since you would need to talk about the endpoint and having it route to the function that does what you need. When it is all over, you need to describe what the input and output is.</div><br/></div></div></div></div></div></div></div></div><div id="42730842" class="c"><input type="checkbox" id="c-42730842" checked=""/><div class="controls bullet"><span class="by">steeeeeve</span><span>|</span><a href="#42728570">parent</a><span>|</span><a href="#42729039">prev</a><span>|</span><a href="#42729788">next</a><span>|</span><label class="collapse" for="c-42730842">[-]</label><label class="expand" for="c-42730842">[3 more]</label></div><br/><div class="children"><div class="content">So having clear requirements, a focused purpose for software, and a clear boundary of software responsibility makes for a software development task that can be accomplished?<p>If only people had figured out at some point that the same thing applies when communicating to human software engineers.</div><br/><div id="42732835" class="c"><input type="checkbox" id="c-42732835" checked=""/><div class="controls bullet"><span class="by">PoppinFreshDo</span><span>|</span><a href="#42728570">root</a><span>|</span><a href="#42730842">parent</a><span>|</span><a href="#42729788">next</a><span>|</span><label class="collapse" for="c-42732835">[-]</label><label class="expand" for="c-42732835">[2 more]</label></div><br/><div class="children"><div class="content">If human software engineers refused to work unless those conditions were met, what a wonderful world it would be.</div><br/><div id="42735054" class="c"><input type="checkbox" id="c-42735054" checked=""/><div class="controls bullet"><span class="by">intelVISA</span><span>|</span><a href="#42728570">root</a><span>|</span><a href="#42732835">parent</a><span>|</span><a href="#42729788">next</a><span>|</span><label class="collapse" for="c-42735054">[-]</label><label class="expand" for="c-42735054">[1 more]</label></div><br/><div class="children"><div class="content">They do implicitly: you can only be accidentally productive without those preconditions.</div><br/></div></div></div></div></div></div><div id="42729788" class="c"><input type="checkbox" id="c-42729788" checked=""/><div class="controls bullet"><span class="by">sdesol</span><span>|</span><a href="#42728570">parent</a><span>|</span><a href="#42730842">prev</a><span>|</span><a href="#42733881">next</a><span>|</span><label class="collapse" for="c-42729788">[-]</label><label class="expand" for="c-42729788">[2 more]</label></div><br/><div class="children"><div class="content">&gt; you can speed up development by 10x.<p>If you know what you are doing, then yes. If you are a domain expert and can articulate your thoughts clearly in a prompt, you will most likely see a boost—perhaps two to three times—but ten times is unlikely. And if you don&#x27;t fully understand the problem, you may experience a negative effect.</div><br/><div id="42730079" class="c"><input type="checkbox" id="c-42730079" checked=""/><div class="controls bullet"><span class="by">throwup238</span><span>|</span><a href="#42728570">root</a><span>|</span><a href="#42729788">parent</a><span>|</span><a href="#42733881">next</a><span>|</span><label class="collapse" for="c-42730079">[-]</label><label class="expand" for="c-42730079">[1 more]</label></div><br/><div class="children"><div class="content">I think it also depends on how much yak-shaving is involved in the domain, regardless of expertise. Whether that’s something simple like remembering the right bash incantation or something more complex like learning enough Terraform and providers to be able to spin up cloud infrastructure.<p>Some projects just have a lot of stuff to do around the edges and LLMs excel at that.</div><br/></div></div></div></div><div id="42733881" class="c"><input type="checkbox" id="c-42733881" checked=""/><div class="controls bullet"><span class="by">andrewchambers</span><span>|</span><a href="#42728570">parent</a><span>|</span><a href="#42729788">prev</a><span>|</span><a href="#42731468">next</a><span>|</span><label class="collapse" for="c-42733881">[-]</label><label class="expand" for="c-42733881">[1 more]</label></div><br/><div class="children"><div class="content">You don&#x27;t need microservices for that, just factor your code into libraries that can fit into the context window. Also write functions that have clear inputs and outputs and don&#x27;t need to know the full state of the software.<p>This has always been good practice anyway.</div><br/></div></div><div id="42731468" class="c"><input type="checkbox" id="c-42731468" checked=""/><div class="controls bullet"><span class="by">phaedrus</span><span>|</span><a href="#42728570">parent</a><span>|</span><a href="#42733881">prev</a><span>|</span><a href="#42729413">next</a><span>|</span><label class="collapse" for="c-42731468">[-]</label><label class="expand" for="c-42731468">[1 more]</label></div><br/><div class="children"><div class="content">50K context is an interesting number because I think there&#x27;s a lot to explore with software within an order of magnitude that size.  With apologies to Richard Feynman, I call it, &quot;There&#x27;s plenty of room in the middle.&quot;  My idea there is the rapid expansion of computing power during the reign of Moore&#x27;s law left the design space of &quot;medium sized&quot; programs under-explored.  These would be programs in the range of 100&#x27;s of kilobytes to low megabytes.</div><br/></div></div><div id="42729413" class="c"><input type="checkbox" id="c-42729413" checked=""/><div class="controls bullet"><span class="by">whoisnnamdi</span><span>|</span><a href="#42728570">parent</a><span>|</span><a href="#42731468">prev</a><span>|</span><a href="#42729713">next</a><span>|</span><label class="collapse" for="c-42729413">[-]</label><label class="expand" for="c-42729413">[2 more]</label></div><br/><div class="children"><div class="content">This is a helpful breakdown of a trend, thank you<p>Might be a boon for test-driven development. Could turn out that AI coding is the killer app for TDD. I had a similar thought about a year ago but had forgotten, appreciate the reminder</div><br/><div id="42733494" class="c"><input type="checkbox" id="c-42733494" checked=""/><div class="controls bullet"><span class="by">MarcelOlsz</span><span>|</span><a href="#42728570">root</a><span>|</span><a href="#42729413">parent</a><span>|</span><a href="#42729713">next</a><span>|</span><label class="collapse" for="c-42733494">[-]</label><label class="expand" for="c-42733494">[1 more]</label></div><br/><div class="children"><div class="content">Hey I reached out on twitter to chat :)</div><br/></div></div></div></div><div id="42729713" class="c"><input type="checkbox" id="c-42729713" checked=""/><div class="controls bullet"><span class="by">Swizec</span><span>|</span><a href="#42728570">parent</a><span>|</span><a href="#42729413">prev</a><span>|</span><a href="#42728826">next</a><span>|</span><label class="collapse" for="c-42729713">[-]</label><label class="expand" for="c-42729713">[7 more]</label></div><br/><div class="children"><div class="content">&gt; 5. Therefore all new development should be ~~microservices~~ modules written from scratch and interacting via cleanly defined APIs.<p>We figured this out for humans almost 20 years ago. Some really good empirical research. It&#x27;s the only approach to large scale software development that works.<p>But it requires leadership that gives a shit about the quality of their product and value long-term outcomes over short-term rewards.</div><br/><div id="42731085" class="c"><input type="checkbox" id="c-42731085" checked=""/><div class="controls bullet"><span class="by">p1necone</span><span>|</span><a href="#42728570">root</a><span>|</span><a href="#42729713">parent</a><span>|</span><a href="#42732841">next</a><span>|</span><label class="collapse" for="c-42731085">[-]</label><label class="expand" for="c-42731085">[5 more]</label></div><br/><div class="children"><div class="content">By large scale do you mean large software or large amounts of developers? Because there&#x27;s some absolutely massive software in terms of feature set, usefulness and even LoC (not that that is a useful measurement) etc out there made by very small teams.<p>I&#x27;m not sure that you&#x27;ve got the causal relationship the right way around here re: architecture:team size.</div><br/><div id="42731675" class="c"><input type="checkbox" id="c-42731675" checked=""/><div class="controls bullet"><span class="by">Swizec</span><span>|</span><a href="#42728570">root</a><span>|</span><a href="#42731085">parent</a><span>|</span><a href="#42732841">next</a><span>|</span><label class="collapse" for="c-42731675">[-]</label><label class="expand" for="c-42731675">[4 more]</label></div><br/><div class="children"><div class="content">What does team size have to do with this? Small teams can (and should) absolutely build modularized software ...<p>You simply cannot build a [working&#x2F;maintainable] large piece of software if everything is connected to everything and any one change may cause issues in conceptually unrelated pieces of code. As soon as your codebase is bigger than what you can fully memorize, you need modules, separation of concerns, etc.</div><br/><div id="42732440" class="c"><input type="checkbox" id="c-42732440" checked=""/><div class="controls bullet"><span class="by">p1necone</span><span>|</span><a href="#42728570">root</a><span>|</span><a href="#42731675">parent</a><span>|</span><a href="#42732841">next</a><span>|</span><label class="collapse" for="c-42732440">[-]</label><label class="expand" for="c-42732440">[3 more]</label></div><br/><div class="children"><div class="content">Sure I agree with that, but microservices are just one of many ways to modularize software&#x2F;achieve separation of concerns.<p>I assumed you were talking about team size specifically because that is the thing that a microservice architecture uniquely enables in my experience.</div><br/><div id="42733948" class="c"><input type="checkbox" id="c-42733948" checked=""/><div class="controls bullet"><span class="by">reitzensteinm</span><span>|</span><a href="#42728570">root</a><span>|</span><a href="#42732440">parent</a><span>|</span><a href="#42732841">next</a><span>|</span><label class="collapse" for="c-42733948">[-]</label><label class="expand" for="c-42733948">[2 more]</label></div><br/><div class="children"><div class="content">I think you might be missing that Swizec edited the quote, crossing out microservices and correcting it to modular systems. It seems to me you&#x27;re both in violent agreement.</div><br/><div id="42734954" class="c"><input type="checkbox" id="c-42734954" checked=""/><div class="controls bullet"><span class="by">p1necone</span><span>|</span><a href="#42728570">root</a><span>|</span><a href="#42733948">parent</a><span>|</span><a href="#42732841">next</a><span>|</span><label class="collapse" for="c-42734954">[-]</label><label class="expand" for="c-42734954">[1 more]</label></div><br/><div class="children"><div class="content">Ahh, the strike through doesn&#x27;t render on mobile. Yes, I think we are just agreeing with each other.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="42728826" class="c"><input type="checkbox" id="c-42728826" checked=""/><div class="controls bullet"><span class="by">smusamashah</span><span>|</span><a href="#42728570">prev</a><span>|</span><a href="#42728170">next</a><span>|</span><label class="collapse" for="c-42728826">[-]</label><label class="expand" for="c-42728826">[19 more]</label></div><br/><div class="children"><div class="content">On a similar note, has anyone found themselves absolutely not trusting non-code LLM output?<p>The code is at least testable and verifiable. For everything else I am left wondering if it&#x27;s the truth or a hallucination. It incurs more mental burden that I was trying to avoid using LLM in the first place.</div><br/><div id="42728915" class="c"><input type="checkbox" id="c-42728915" checked=""/><div class="controls bullet"><span class="by">joshstrange</span><span>|</span><a href="#42728826">parent</a><span>|</span><a href="#42729926">next</a><span>|</span><label class="collapse" for="c-42728915">[-]</label><label class="expand" for="c-42728915">[1 more]</label></div><br/><div class="children"><div class="content">Absolutely. LLMs are a &quot;need to verify&quot; the results almost always. LLMs (for me) shine by pointing me in the right direction, getting a &quot;first draft&quot;, or for things like code where I can test it.</div><br/></div></div><div id="42729926" class="c"><input type="checkbox" id="c-42729926" checked=""/><div class="controls bullet"><span class="by">Marceltan</span><span>|</span><a href="#42728826">parent</a><span>|</span><a href="#42728915">prev</a><span>|</span><a href="#42729640">next</a><span>|</span><label class="collapse" for="c-42729926">[-]</label><label class="expand" for="c-42729926">[1 more]</label></div><br/><div class="children"><div class="content">Agree. My biggest pain point with LLM code review tools is that they sometimes add 40 comments for a PR changing 100 lines of code. Gets noisy and hard to decipher what really matters.<p>Along the lines of verifiability, my take is that running a comprehensive suite of tests in CI&#x2F;CD is going to be table stakes soon given that LLMs are only going to be contributing more and more code.</div><br/></div></div><div id="42729640" class="c"><input type="checkbox" id="c-42729640" checked=""/><div class="controls bullet"><span class="by">sdesol</span><span>|</span><a href="#42728826">parent</a><span>|</span><a href="#42729926">prev</a><span>|</span><a href="#42729219">next</a><span>|</span><label class="collapse" for="c-42729640">[-]</label><label class="expand" for="c-42729640">[7 more]</label></div><br/><div class="children"><div class="content">&gt; On a similar note, has anyone found themselves absolutely not trusting non-code LLM output?<p>I&#x27;m working on a LLM chat app that is built around mistrust. The basic idea is that it is unlikely a supermajority of quality LLMs can get it wrong.<p>This isn&#x27;t foolproof though, but it does provide some level of confidence in the answer.<p>Here is a quick example in which I analyze results from multiple LLMs that answered, &quot;When did Homer Simpson go to Mars?&quot;<p><a href="https:&#x2F;&#x2F;beta.gitsense.com&#x2F;?chat=4d28f283-24f4-4657-89e0-5abfc8752e59" rel="nofollow">https:&#x2F;&#x2F;beta.gitsense.com&#x2F;?chat=4d28f283-24f4-4657-89e0-5abf...</a><p>If you look at the yes and no table, all except GPT-4o and GPT-4o mini said no.  After asking GPT-4o who was correct, it provided &quot;evidence&quot; on an episode so I asked for more information on that episode. Based on what it said, it looks like the mission to Mars was a hoax and when I challenged GPT-4o on this, it agreed and said Homer never went to Mars, like others have said.<p>I then asked Sonnet 3.5 about the episode and it said GPT-4o misinterpreted the plot.<p><a href="https:&#x2F;&#x2F;beta.gitsense.com&#x2F;?chat=4d28f283-24f4-4657-89e0-5abfc8752e59&amp;model=Claude+3.5+Sonnet" rel="nofollow">https:&#x2F;&#x2F;beta.gitsense.com&#x2F;?chat=4d28f283-24f4-4657-89e0-5abf...</a><p>At this point, I am confident (but not 100% sure) Homer never went to Mars and if I really needed to know, I&#x27;ll need to search the web.</div><br/><div id="42733497" class="c"><input type="checkbox" id="c-42733497" checked=""/><div class="controls bullet"><span class="by">ehnto</span><span>|</span><a href="#42728826">root</a><span>|</span><a href="#42729640">parent</a><span>|</span><a href="#42731507">next</a><span>|</span><label class="collapse" for="c-42733497">[-]</label><label class="expand" for="c-42733497">[3 more]</label></div><br/><div class="children"><div class="content">It&#x27;s the backwards reasoning that really frustrates me when using LLMs. You ask a question, it says sure do these things, they don&#x27;t work out and you ask the LLM why not, and it replies yes that thing I told you to do wouldn&#x27;t work because of these clear reasons.<p>It would be nice to start at the end of that chain of reasoning instead of the other side.<p>Another regular example is when it &quot;invents&quot; functions or classes that don&#x27;t exist, when pressed about them, it will reply of course that won&#x27;t work, that function doesn&#x27;t exist.<p>Okay great, so don&#x27;t tell me it does with such certainty, is what I would tell a human feeding me imagination as facts all the time. But of course an LLM is not reasoning in the same sense, so this reverse chain of thought is the outcome.<p>I am finding LLMs far more useful for soft skill topics than engineering type work, simply because of how often it leads me down a path that is eventually a dead end, because of some small detail that was wrong at the very beginning.</div><br/><div id="42733813" class="c"><input type="checkbox" id="c-42733813" checked=""/><div class="controls bullet"><span class="by">sdesol</span><span>|</span><a href="#42728826">root</a><span>|</span><a href="#42733497">parent</a><span>|</span><a href="#42733809">next</a><span>|</span><label class="collapse" for="c-42733813">[-]</label><label class="expand" for="c-42733813">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I am finding LLMs far more useful for soft skill topics than engineering type work, simply because of how often it leads me down a path that is eventually a dead end, because of some small detail that was wrong at the very beginning.<p>Yeah I felt the same way in the beginning which is why I ended up writing my own chat app. What I&#x27;ve found while developing my spelling and grammar checker is that it is very unlikely for multiple LLMs to mess up at the same time.  I know they will mess up, but I&#x27;m also pretty sure they won&#x27;t at the same time.<p>So far, I&#x27;ve been able to successfully create working features that actually saved me time by pitting LLMs against their own responses and others. My process right now is, I&#x27;ll ask 6+ models to implement something and then I will ask models to evaluate everyone&#x27;s responses.  More often than not, a model will find fault or make a suggestion that can be used to improve the prompt or code.  And depending on my confidence level, I might repeat this a couple of times.<p>The issue right now is tracking this &quot;chain of questioning&quot; which is why I am writing my own chat app. I need an easy way to backtrack and fork from different points in the &quot;chain of questioning&quot;. I think once we get a better understanding of what LLMs can and can&#x27;t do as a group, we should be able to produce working solutions easier.</div><br/></div></div><div id="42733809" class="c"><input type="checkbox" id="c-42733809" checked=""/><div class="controls bullet"><span class="by">willy_k</span><span>|</span><a href="#42728826">root</a><span>|</span><a href="#42733497">parent</a><span>|</span><a href="#42733813">prev</a><span>|</span><a href="#42731507">next</a><span>|</span><label class="collapse" for="c-42733809">[-]</label><label class="expand" for="c-42733809">[1 more]</label></div><br/><div class="children"><div class="content">I believe that this is what chain of thought models attempt to address.</div><br/></div></div></div></div><div id="42731507" class="c"><input type="checkbox" id="c-42731507" checked=""/><div class="controls bullet"><span class="by">horsawlarway</span><span>|</span><a href="#42728826">root</a><span>|</span><a href="#42729640">parent</a><span>|</span><a href="#42733497">prev</a><span>|</span><a href="#42730175">next</a><span>|</span><label class="collapse" for="c-42731507">[-]</label><label class="expand" for="c-42731507">[2 more]</label></div><br/><div class="children"><div class="content">Isn&#x27;t this essentially making the point of the post above you?<p>For comparison - if I just do a web search for &quot;Did homer simpson go to mars&quot; I get immediately linked to the wikipedia page for that exact episode (<a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;The_Marge-ian_Chronicles" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;The_Marge-ian_Chronicles</a>), and the plot summary is less to read than your LLM output - It clearly summarizes that Marge &amp; Lisa (note - NOT homer) almost went to mars, but did not go.  Further - the summary correctly includes the outro which <i>does</i> show Marge and Lisa on mars in the year 2051.<p>Basically - for factual content, the LLM output was a garbage game of telephone.</div><br/><div id="42732233" class="c"><input type="checkbox" id="c-42732233" checked=""/><div class="controls bullet"><span class="by">sdesol</span><span>|</span><a href="#42728826">root</a><span>|</span><a href="#42731507">parent</a><span>|</span><a href="#42730175">next</a><span>|</span><label class="collapse" for="c-42732233">[-]</label><label class="expand" for="c-42732233">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Isn&#x27;t this essentially making the point of the post above you?<p>Yes. This is why I wrote the chat app, because I mistrust LLMs, but I do find them extremely useful when you approach them with the right mindset. If answering &quot;Did Homer Simpson go to Mars?&quot; correctly is critical, then you can choose to require a 100% consensus, otherwise you will need a fallback plan.<p>When I asked all the LLMs about the Wikipedia article, they all correctly answered &quot;No&quot; and talked about Marge and Lisa in the future without Homer.</div><br/></div></div></div></div><div id="42730175" class="c"><input type="checkbox" id="c-42730175" checked=""/><div class="controls bullet"><span class="by">manmal</span><span>|</span><a href="#42728826">root</a><span>|</span><a href="#42729640">parent</a><span>|</span><a href="#42731507">prev</a><span>|</span><a href="#42729219">next</a><span>|</span><label class="collapse" for="c-42730175">[-]</label><label class="expand" for="c-42730175">[1 more]</label></div><br/><div class="children"><div class="content">Relatedly, asking LLMs what happens in a TV episode, or a series in general, I usually get very low quality and mostly flat out wrong answers. That baffles me, as I thought there are multiple well structured synopses for any TV series in the training data.</div><br/></div></div></div></div><div id="42729219" class="c"><input type="checkbox" id="c-42729219" checked=""/><div class="controls bullet"><span class="by">nyrikki</span><span>|</span><a href="#42728826">parent</a><span>|</span><a href="#42729640">prev</a><span>|</span><a href="#42730292">next</a><span>|</span><label class="collapse" for="c-42729219">[-]</label><label class="expand" for="c-42729219">[1 more]</label></div><br/><div class="children"><div class="content">It is really the only safe way to use it IMHO.<p>Even in most simple forms of automation, humans suffer from Automation Bias and Complacency and one of the better ways to avoid those issues is to instill a fundamental mistrust of those systems.<p>IMHO it is important to look at other fields and the human factors studies to understand this.<p>As an example ABS was originally sold as a technology that would help you &#x27;stop faster&#x27;. Which it may do in some situations, and it is obviously mandatory in the US.  But they had to shift how they &#x27;sell&#x27; it now, to ensure that people didn&#x27;t rely on it.<p><a href="https:&#x2F;&#x2F;www.fmcsa.dot.gov&#x2F;sites&#x2F;fmcsa.dot.gov&#x2F;files&#x2F;docs&#x2F;2005%20CDL%20Driver%20Manual%20-July%202014%20-%20FINAL.pdf" rel="nofollow">https:&#x2F;&#x2F;www.fmcsa.dot.gov&#x2F;sites&#x2F;fmcsa.dot.gov&#x2F;files&#x2F;docs&#x2F;200...</a><p><pre><code>    2.18 – Antilock Braking Systems (ABS)

    ABS is a computerized system that keeps your wheels from locking up during hard brake applications.
    ABS is an addition to your normal brakes. It does not decrease or increase your normal braking capability. ABS only activates when wheels are about to lock up.
    ABS does not necessarily shorten your stopping distance, but it does help you keep the vehicle under control during hard braking.

</code></pre>
Transformers will <i>always</i> produce code that doesn&#x27;t work, it doesn&#x27;t matter if that is due to what they call hallucinations, Rice&#x27;s theory, etc...<p>Maintaining that mistrust is the mark of someone who understands and can leverage the technology.  It is just yet another context specific tradeoff analysis that we will need to assess.<p>I think forcing people into the quasi-TDD thinking model, where they focus on what needs to be done first vs jumping into the implementation details will probably be a positive thing for the industry, no matter where on the spectrum LLM coding assistants arrive.<p>That is one of the hardest things to teach when trying to introduce TDD, focusing on what is far closer to an ADT than implementation specific unit tests to begin with is very different but very useful.<p>I am hopeful that required tacit experience will help get past the issues with formal frameworks that run into many barriers that block teaching that one skill.<p>As LLM&#x27;s failure mode is <i>Always Confident, Often Competent, and Inevitably Wrong</i>, it is super critical to always realize the third option is likely and that you are the expert.</div><br/></div></div><div id="42730292" class="c"><input type="checkbox" id="c-42730292" checked=""/><div class="controls bullet"><span class="by">iamnotagenius</span><span>|</span><a href="#42728826">parent</a><span>|</span><a href="#42729219">prev</a><span>|</span><a href="#42730263">next</a><span>|</span><label class="collapse" for="c-42730292">[-]</label><label class="expand" for="c-42730292">[1 more]</label></div><br/><div class="children"><div class="content">Yes, it is good for suumarizing existing text, explaining something or coding; in short any generative&#x2F;transformative tasks. Not good for information retrieval. Having said that even tiny Qwen 3b&#x2F;7b coding llms turned out to be very useful in my use experience.</div><br/></div></div><div id="42730263" class="c"><input type="checkbox" id="c-42730263" checked=""/><div class="controls bullet"><span class="by">redcobra762</span><span>|</span><a href="#42728826">parent</a><span>|</span><a href="#42730292">prev</a><span>|</span><a href="#42731632">next</a><span>|</span><label class="collapse" for="c-42730263">[-]</label><label class="expand" for="c-42730263">[2 more]</label></div><br/><div class="children"><div class="content">You&#x27;re going to fall behind eventually, if you continue to treat LLMs with this level of skepticism, as others won&#x27;t, and the output is accurate enough that it can be useful to improve the efficiency of work in a great many situations.<p>Rarely are day-to-day written documents (e.g. an email asking for clarification on an issue or to schedule an appointment) of such importance that the occasional error is unforgivable. In situations where a mistake <i>is</i> fatal, yes I would not trust GenAI. But how many of us really work in that kind of a field?<p>Besides, AI shines when used for creative purposes. Coming up with new ideas or rewording a paragraph for clarity isn&#x27;t something one does blindly. GenAI is a coworker, not an authority. It&#x27;ll generate a draft, I may edit that draft or rewrite it significantly, but to preclude it because it <i>could</i> error will eventually slow you down in your field.</div><br/><div id="42732131" class="c"><input type="checkbox" id="c-42732131" checked=""/><div class="controls bullet"><span class="by">thuuuomas</span><span>|</span><a href="#42728826">root</a><span>|</span><a href="#42730263">parent</a><span>|</span><a href="#42731632">next</a><span>|</span><label class="collapse" for="c-42732131">[-]</label><label class="expand" for="c-42732131">[1 more]</label></div><br/><div class="children"><div class="content">You’re narrowly addressing LLM use cases &amp; omitting the most problematic one - LLMs as search engine replacements.</div><br/></div></div></div></div><div id="42731632" class="c"><input type="checkbox" id="c-42731632" checked=""/><div class="controls bullet"><span class="by">energy123</span><span>|</span><a href="#42728826">parent</a><span>|</span><a href="#42730263">prev</a><span>|</span><a href="#42728170">next</a><span>|</span><label class="collapse" for="c-42731632">[-]</label><label class="expand" for="c-42731632">[5 more]</label></div><br/><div class="children"><div class="content">We need a hallucination benchmark.<p>My experience is, o1 is very good at avoiding hallucinations and I trust it more, but o1-mini and 4o are awful.</div><br/><div id="42732332" class="c"><input type="checkbox" id="c-42732332" checked=""/><div class="controls bullet"><span class="by">sdesol</span><span>|</span><a href="#42728826">root</a><span>|</span><a href="#42731632">parent</a><span>|</span><a href="#42728170">next</a><span>|</span><label class="collapse" for="c-42732332">[-]</label><label class="expand" for="c-42732332">[4 more]</label></div><br/><div class="children"><div class="content">Well given the price $15.00 &#x2F; 1M input tokens and $60.00 &#x2F; 1M output* tokens, I would hope so. Given the price, I think it is fair to say it is doing a lot of checks in the background.</div><br/><div id="42732460" class="c"><input type="checkbox" id="c-42732460" checked=""/><div class="controls bullet"><span class="by">energy123</span><span>|</span><a href="#42728826">root</a><span>|</span><a href="#42732332">parent</a><span>|</span><a href="#42728170">next</a><span>|</span><label class="collapse" for="c-42732460">[-]</label><label class="expand" for="c-42732460">[3 more]</label></div><br/><div class="children"><div class="content">It is expensive. But if I&#x27;m correct about o1, it means user mistrust of LLMs is going to be a short-lived thing as costs come down and more people use o1 (or better) models as their daily driver.</div><br/><div id="42732737" class="c"><input type="checkbox" id="c-42732737" checked=""/><div class="controls bullet"><span class="by">sdesol</span><span>|</span><a href="#42728826">root</a><span>|</span><a href="#42732460">parent</a><span>|</span><a href="#42728170">next</a><span>|</span><label class="collapse" for="c-42732737">[-]</label><label class="expand" for="c-42732737">[2 more]</label></div><br/><div class="children"><div class="content">&gt; mistrust of LLMs is going to be a short-lived thing as costs come down and more people use o1<p>I think the biggest question is, is o1 scalable. I think o1 does well because it is going back and forth hundreds if not thousands of times.  Somebody mentioned in a thread that I was participating in that they let o1 crunch things for 10 minutes. It sounded like it saved them a lot work, so it was well worth it.<p>Whether or not o1 is practical for the general public is something we will have to wait and see.</div><br/><div id="42732826" class="c"><input type="checkbox" id="c-42732826" checked=""/><div class="controls bullet"><span class="by">energy123</span><span>|</span><a href="#42728826">root</a><span>|</span><a href="#42732737">parent</a><span>|</span><a href="#42728170">next</a><span>|</span><label class="collapse" for="c-42732826">[-]</label><label class="expand" for="c-42732826">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m going to wager &quot;yes&quot; because o3-mini (High) gets equal benchmark scores to o1 despite using 1&#x2F;3rd as much compute, and because the consistent trend has been towards rapid order-of-magnitude decreases in price for a fixed level of intelligence (trend has many components dovetailing, both hardware and software related). Can&#x27;t forecast the future, but this would be my bet on a time horizon of &lt; 3 years.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="42728170" class="c"><input type="checkbox" id="c-42728170" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#42728826">prev</a><span>|</span><a href="#42732601">next</a><span>|</span><label class="collapse" for="c-42728170">[-]</label><label class="expand" for="c-42728170">[1 more]</label></div><br/><div class="children"><div class="content">Here&#x27;s the Go app described in the post: <a href="https:&#x2F;&#x2F;github.com&#x2F;yfzhou0904&#x2F;tdd-with-llm-go">https:&#x2F;&#x2F;github.com&#x2F;yfzhou0904&#x2F;tdd-with-llm-go</a><p>Example usage from that README (and the blog post):<p><pre><code>  % go run main.go \
  --spec &#x27;develop a function to take in a large text, recognize and parse any and all ipv4 and ipv6 addresses and CIDRs contained within it (these may be surrounded by random words or symbols like commas), then return them as a list&#x27; \
  --sig &#x27;func ParseCidrs(input string) ([]*net.IPNet, error)&#x27;
</code></pre>
The all important prompts it uses are in <a href="https:&#x2F;&#x2F;github.com&#x2F;yfzhou0904&#x2F;tdd-with-llm-go&#x2F;blob&#x2F;main&#x2F;prompts&#x2F;prompts.go">https:&#x2F;&#x2F;github.com&#x2F;yfzhou0904&#x2F;tdd-with-llm-go&#x2F;blob&#x2F;main&#x2F;prom...</a></div><br/></div></div><div id="42732601" class="c"><input type="checkbox" id="c-42732601" checked=""/><div class="controls bullet"><span class="by">voiceofunreason</span><span>|</span><a href="#42728170">prev</a><span>|</span><a href="#42733161">next</a><span>|</span><label class="collapse" for="c-42732601">[-]</label><label class="expand" for="c-42732601">[1 more]</label></div><br/><div class="children"><div class="content">I have yet to see an LLM + TDD essay where the author demonstrates any mastery of Test Driven Development.<p>Is the label &quot;TDD&quot; being hijacked for something new? Did that already happen? Are LLMs now responsible for defining TDD?</div><br/></div></div><div id="42733161" class="c"><input type="checkbox" id="c-42733161" checked=""/><div class="controls bullet"><span class="by">vydra</span><span>|</span><a href="#42732601">prev</a><span>|</span><a href="#42728926">next</a><span>|</span><label class="collapse" for="c-42733161">[-]</label><label class="expand" for="c-42733161">[1 more]</label></div><br/><div class="children"><div class="content">We implemented something similar for our Java backend project based on my rant here: <a href="https:&#x2F;&#x2F;testdriven.com&#x2F;testdriven-2-0-8354e8ad73d7" rel="nofollow">https:&#x2F;&#x2F;testdriven.com&#x2F;testdriven-2-0-8354e8ad73d7</a> Works great! I only look at generated code if it passes the tests. Now, can we use LLMs to generate tests from requirements? Maybe, but tests are mostly declarative and are easier to write than production code most of the time. This approach also allows us to use cheaper models, because the tool will automatically tell the model about compile error and failed tests. Usually, we give it up to five attempts to fix the code.</div><br/></div></div><div id="42728926" class="c"><input type="checkbox" id="c-42728926" checked=""/><div class="controls bullet"><span class="by">blopker</span><span>|</span><a href="#42733161">prev</a><span>|</span><a href="#42731651">next</a><span>|</span><label class="collapse" for="c-42728926">[-]</label><label class="expand" for="c-42728926">[2 more]</label></div><br/><div class="children"><div class="content">In Rust, there&#x27;s a controversial practice around putting unit tests in the same file as the actual code. I was put off by it at first, but I&#x27;m finding LLM autocomplete is able to be much more effective just being able to see the tests.<p>No clunky loop needed.<p>It&#x27;s gotten me back into TDD.</div><br/><div id="42730891" class="c"><input type="checkbox" id="c-42730891" checked=""/><div class="controls bullet"><span class="by">sitkack</span><span>|</span><a href="#42728926">parent</a><span>|</span><a href="#42731651">next</a><span>|</span><label class="collapse" for="c-42730891">[-]</label><label class="expand" for="c-42730891">[1 more]</label></div><br/><div class="children"><div class="content">If the LLM can&#x27;t complete a task, you add a test the shows it how to do it. This is multishot incontext learning and programming by example.<p>As for real TDD, you start with the tests and code until they pass. I haven&#x27;t used an LLM to do this in Rust yet, but in Python due its dynamic nature, it is much simpler.<p>You can write the tests, then have the LLM sketch the code out enough so that they pass or at least exist enough to pass a linter. Dev tools are going to feel like magic 18 months from now.</div><br/></div></div></div></div><div id="42731651" class="c"><input type="checkbox" id="c-42731651" checked=""/><div class="controls bullet"><span class="by">mmikeff</span><span>|</span><a href="#42728926">prev</a><span>|</span><a href="#42732482">next</a><span>|</span><label class="collapse" for="c-42731651">[-]</label><label class="expand" for="c-42731651">[1 more]</label></div><br/><div class="children"><div class="content">Writing a whole load of tests up front and then coding until all the tests pass is not TDD.</div><br/></div></div><div id="42732482" class="c"><input type="checkbox" id="c-42732482" checked=""/><div class="controls bullet"><span class="by">jacobpedd</span><span>|</span><a href="#42731651">prev</a><span>|</span><a href="#42733778">next</a><span>|</span><label class="collapse" for="c-42732482">[-]</label><label class="expand" for="c-42732482">[2 more]</label></div><br/><div class="children"><div class="content">&gt; For best results, our project structure needs to be set up with LLM workflows in mind. Specifically, we should carefully manage and keep the cognitive load required to understand and contribute code to a project at a minimum.<p>What&#x27;s the main barrier to doing this all the time? Sounds like a good practice in general.</div><br/><div id="42732532" class="c"><input type="checkbox" id="c-42732532" checked=""/><div class="controls bullet"><span class="by">krapp</span><span>|</span><a href="#42732482">parent</a><span>|</span><a href="#42733778">next</a><span>|</span><label class="collapse" for="c-42732532">[-]</label><label class="expand" for="c-42732532">[1 more]</label></div><br/><div class="children"><div class="content">It isn&#x27;t good practice. You don&#x27;t want people contributing to a project who don&#x27;t understand the code they submit or the project they&#x27;re contributing to, because you&#x27;ll just need to make that up with more effort debugging garbage code. The cognitive load required to actually learn how things work is a necessary filter for minimum effort and quality.</div><br/></div></div></div></div><div id="42733778" class="c"><input type="checkbox" id="c-42733778" checked=""/><div class="controls bullet"><span class="by">jappgar</span><span>|</span><a href="#42732482">prev</a><span>|</span><a href="#42729609">next</a><span>|</span><label class="collapse" for="c-42733778">[-]</label><label class="expand" for="c-42733778">[1 more]</label></div><br/><div class="children"><div class="content">&gt; 5. Therefore all new development should be microservices written from scratch and interacting via cleanly defined APIs.<p>That&#x27;s what the software industry has been trying and failing at for more than a decade.</div><br/></div></div><div id="42729609" class="c"><input type="checkbox" id="c-42729609" checked=""/><div class="controls bullet"><span class="by">agentultra</span><span>|</span><a href="#42733778">prev</a><span>|</span><a href="#42732684">next</a><span>|</span><label class="collapse" for="c-42729609">[-]</label><label class="expand" for="c-42729609">[5 more]</label></div><br/><div class="children"><div class="content">This is not a good idea.<p>If you want better tests with more cases exercising your code: write property based tests.<p>Tests form an executable, informal specification of what your software is supposed to do. It should absolutely be written by hand, by a human, for other humans to use and understand. Natural language is not precise enough for even informal specifications of software modules, let alone software systems.<p>If using LLM&#x27;s to help you write the code is your jam, I can&#x27;t stop you, but at least write the tests. They&#x27;re more important.<p>As an aside, I understand how this antipathy towards TDD develops. People write unit tests, after writing the implementation, because they see it as boilerplate code that mirrors what the code they&#x27;re testing already does. They&#x27;re missing the point of what makes a good test useful and sufficient. I would not expect generating more tests of this nature is going to improve software much.<p><i>Edit</i> added some wording for clarity</div><br/><div id="42730693" class="c"><input type="checkbox" id="c-42730693" checked=""/><div class="controls bullet"><span class="by">ozten</span><span>|</span><a href="#42729609">parent</a><span>|</span><a href="#42732684">next</a><span>|</span><label class="collapse" for="c-42730693">[-]</label><label class="expand" for="c-42730693">[4 more]</label></div><br/><div class="children"><div class="content">I got massive productivity gains from having an LLM fill out my test suite.<p>It is like autocomplete and macros... &quot;Based on these two unit tests, fill out the suite considering b, c, and d. Add any critical corner case tests I have missed or suggest them if they don&#x27;t fit well.&quot;<p>It is on the human to look at the generated test to ensure a) they are comprehensive and b) useful and c) communicate clearly</div><br/><div id="42731269" class="c"><input type="checkbox" id="c-42731269" checked=""/><div class="controls bullet"><span class="by">lifeisstillgood</span><span>|</span><a href="#42729609">root</a><span>|</span><a href="#42730693">parent</a><span>|</span><a href="#42732684">next</a><span>|</span><label class="collapse" for="c-42731269">[-]</label><label class="expand" for="c-42731269">[3 more]</label></div><br/><div class="children"><div class="content">Can you extend that - what was the domain, how did you start? I would like to give this a try but am not quite sure I get it?</div><br/><div id="42731385" class="c"><input type="checkbox" id="c-42731385" checked=""/><div class="controls bullet"><span class="by">ozten</span><span>|</span><a href="#42729609">root</a><span>|</span><a href="#42731269">parent</a><span>|</span><a href="#42732684">next</a><span>|</span><label class="collapse" for="c-42731385">[-]</label><label class="expand" for="c-42731385">[2 more]</label></div><br/><div class="children"><div class="content">Backend coding for web services.<p>In the past I would hand write 8 or 9 unit tests. Now I write the first one or two and then brain dump anything else into the LLM prompt. It then outputs mine plus 6 or more.<p>I delete any that seem low value or ridiculous or have a follow up prompt to ask for refinements. Then just copy&#x2F;pasta back into the codebase out of the chat.</div><br/><div id="42732144" class="c"><input type="checkbox" id="c-42732144" checked=""/><div class="controls bullet"><span class="by">lifeisstillgood</span><span>|</span><a href="#42729609">root</a><span>|</span><a href="#42731385">parent</a><span>|</span><a href="#42732684">next</a><span>|</span><label class="collapse" for="c-42732144">[-]</label><label class="expand" for="c-42732144">[1 more]</label></div><br/><div class="children"><div class="content">That simple ? I’ll try it</div><br/></div></div></div></div></div></div></div></div></div></div><div id="42732684" class="c"><input type="checkbox" id="c-42732684" checked=""/><div class="controls bullet"><span class="by">czhu12</span><span>|</span><a href="#42729609">prev</a><span>|</span><a href="#42731033">next</a><span>|</span><label class="collapse" for="c-42732684">[-]</label><label class="expand" for="c-42732684">[1 more]</label></div><br/><div class="children"><div class="content">I did something similar for autogenerating RSpec tests in a Rails project.<p><a href="https:&#x2F;&#x2F;gist.github.com&#x2F;czhu12&#x2F;b3fe42454f9fdf626baeaf9c83ab352b" rel="nofollow">https:&#x2F;&#x2F;gist.github.com&#x2F;czhu12&#x2F;b3fe42454f9fdf626baeaf9c83ab3...</a><p>It basically starts from some model or controller, and then parses the Ruby code into an AST, and load all the references, and then parses that code into an AST, up to X number of files, and ships them all off to GPT4-o1 for writing a spec.<p>I found sometimes, without further prompting, the LLM would write specs that were so heavily mocked that it became almost useless like:<p>```
mock(add_two_numbers).and_return(3)
...
expect(add_two_numbers(1, 2)).to_return(3)
```
(Not that bad, just an illustrating example)<p>But the tests it generates is quite good overall, and sometimes shockingly good.</div><br/></div></div><div id="42731033" class="c"><input type="checkbox" id="c-42731033" checked=""/><div class="controls bullet"><span class="by">zephraph</span><span>|</span><a href="#42732684">prev</a><span>|</span><a href="#42729565">next</a><span>|</span><label class="collapse" for="c-42731033">[-]</label><label class="expand" for="c-42731033">[2 more]</label></div><br/><div class="children"><div class="content">Hey, yeah, this is a fun idea. I built a little toy llm-tdd loop as a Saturday morning side project a little while back: <a href="https:&#x2F;&#x2F;github.com&#x2F;zephraph&#x2F;llm-tdd">https:&#x2F;&#x2F;github.com&#x2F;zephraph&#x2F;llm-tdd</a>.<p>This doesn&#x27;t actually work out that well in practice though because the implementations the llm tended to generate were highly specific to pass the tests. There were several times it would cheat and just return hard coded strings that matched the expects of the tests. I&#x27;m sure better prompt engineering could help, but it was a fairly funny outcome.<p>Something I&#x27;ve found more valuable is generating the tests themselves. Obviously you don&#x27;t wholesale rely on what&#x27;s generated. Tests can have a certain activation energy just to figure out how to set up correctly (especially if you&#x27;re in a new project). Having an LLM take a first pass at it and then ensuring it&#x27;s well structured and testing important codepaths instead of implementation details makes it a lot faster to write tests.</div><br/><div id="42732002" class="c"><input type="checkbox" id="c-42732002" checked=""/><div class="controls bullet"><span class="by">feznyng</span><span>|</span><a href="#42731033">parent</a><span>|</span><a href="#42729565">next</a><span>|</span><label class="collapse" for="c-42732002">[-]</label><label class="expand" for="c-42732002">[1 more]</label></div><br/><div class="children"><div class="content">Did you show the test cases to it? Maybe blinding it would solve the tailoring problem.</div><br/></div></div></div></div><div id="42729565" class="c"><input type="checkbox" id="c-42729565" checked=""/><div class="controls bullet"><span class="by">eesmith</span><span>|</span><a href="#42731033">prev</a><span>|</span><a href="#42728291">next</a><span>|</span><label class="collapse" for="c-42729565">[-]</label><label class="expand" for="c-42729565">[1 more]</label></div><br/><div class="children"><div class="content">&gt; recognize and parse any and all ipv4 and ipv6 addresses and CIDRs contained within it (these may be surrounded by random words or symbols like commas), then return them as a list&#x27;<p>Did I miss the generated code and test cases? I would like to see how complete it was.<p>For example, for IPv4 does it only handle quad-dotted IP addresses, or does it also handle decimal and hex formats?<p>For that matter, <i>should</i> it handle those, and if so, where there clarification of what exactly &#x27;all ipv4 ... addresses&#x27; means?<p>I can think of a lot of tricky cases (like 1.2.3.4.5 and 3::2::1 as invalid cases, or <a href="http:&#x2F;&#x2F;[2001:db8:4006:812::200e]" rel="nofollow">http:&#x2F;&#x2F;[2001:db8:4006:812::200e]</a> to test for &quot;symbols like commas&quot;), and would like to see if the result handles them.</div><br/></div></div><div id="42728291" class="c"><input type="checkbox" id="c-42728291" checked=""/><div class="controls bullet"><span class="by">picografix</span><span>|</span><a href="#42729565">prev</a><span>|</span><label class="collapse" for="c-42728291">[-]</label><label class="expand" for="c-42728291">[1 more]</label></div><br/><div class="children"><div class="content">very few times we are encountered with developing from scratch</div><br/></div></div></div></div></div></div></div></body></html>