<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1687251655311" as="style"/><link rel="stylesheet" href="styles.css?v=1687251655311"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.theregister.com/2023/06/19/even_google_warns_its_own/">Google warns its own employees: Do not use code generated by Bard</a> <span class="domain">(<a href="https://www.theregister.com">www.theregister.com</a>)</span></div><div class="subtext"><span>Brajeshwar</span> | <span>58 comments</span></div><br/><div><div id="36400266" class="c"><input type="checkbox" id="c-36400266" checked=""/><div class="controls bullet"><span class="by">buro9</span><span>|</span><a href="#36400763">next</a><span>|</span><label class="collapse" for="c-36400266">[-]</label><label class="expand" for="c-36400266">[5 more]</label></div><br/><div class="children"><div class="content">This is Google, who have a monorepo, who are afraid of the legal risks to the monorepo.<p>The copyright of the output of these tools is not yet determined, it&#x27;s a risk.<p>The advice not to use the tools in a risky way not only directly mitigates the risk but like an &quot;employees must wash hands&quot; sign in a restaurant restroom, it can be seen as a reasonable step that transfers some of the liability to the staff member.<p>It&#x27;s not a verdict on the output of the tools, it&#x27;s a reflection of risk aversion in a monorepo company that is very protective of what is in the monorepo.</div><br/><div id="36400671" class="c"><input type="checkbox" id="c-36400671" checked=""/><div class="controls bullet"><span class="by">samwillis</span><span>|</span><a href="#36400266">parent</a><span>|</span><a href="#36400746">next</a><span>|</span><label class="collapse" for="c-36400671">[-]</label><label class="expand" for="c-36400671">[2 more]</label></div><br/><div class="children"><div class="content">I doubt the fact they use a monorepo has any impact on this thinking. A versioned sourced repository is no different from a file server. If some &quot;ai copyright infringed&quot; code made it into the monorepo it doesn&#x27;t compromise the whole thing. There are still clear distinct projects and products.<p>But exactly, this is a hygiene thing. Staff will still be using these tools anyway.</div><br/><div id="36400770" class="c"><input type="checkbox" id="c-36400770" checked=""/><div class="controls bullet"><span class="by">praptak</span><span>|</span><a href="#36400266">root</a><span>|</span><a href="#36400671">parent</a><span>|</span><a href="#36400746">next</a><span>|</span><label class="collapse" for="c-36400770">[-]</label><label class="expand" for="c-36400770">[1 more]</label></div><br/><div class="children"><div class="content">I agree that monorepo does not make a fundamental difference. Still it makes it easier for some undesirable things to happen.<p>The tainted code can become a critical dependency. It can get copy-pasted elsewhere. An engineer could look at the code before writing their own (obviously not illegal per se but makes it harder to repeal bullshit claims later). An engineer can just write similar code and then have no way to prove they didn&#x27;t look (ditto).</div><br/></div></div></div></div><div id="36400746" class="c"><input type="checkbox" id="c-36400746" checked=""/><div class="controls bullet"><span class="by">bPspGiJT8Y</span><span>|</span><a href="#36400266">parent</a><span>|</span><a href="#36400671">prev</a><span>|</span><a href="#36400763">next</a><span>|</span><label class="collapse" for="c-36400746">[-]</label><label class="expand" for="c-36400746">[2 more]</label></div><br/><div class="children"><div class="content">&gt; who are afraid of the legal risks to the monorepo<p>You&#x27;re talking about a company which happily pays billions in fines because its just a fraction of what they otherwise manage to get away with. They&#x27;re not at all afraid of doing a lot of illegal stuff, I find it highly unlikely they&#x27;d be afraid to step into a minor grey area.</div><br/><div id="36400851" class="c"><input type="checkbox" id="c-36400851" checked=""/><div class="controls bullet"><span class="by">praptak</span><span>|</span><a href="#36400266">root</a><span>|</span><a href="#36400746">parent</a><span>|</span><a href="#36400763">next</a><span>|</span><label class="collapse" for="c-36400851">[-]</label><label class="expand" for="c-36400851">[1 more]</label></div><br/><div class="children"><div class="content">The risk-reward balance is totally reverted. Profiteering from privacy breaches - big reward, fixed risk (the fines are basically capped). Using risky code - small reward (some worker time), big risk (suddenly everyone and their dog can sue you for bullshit copyright claims).</div><br/></div></div></div></div></div></div><div id="36400763" class="c"><input type="checkbox" id="c-36400763" checked=""/><div class="controls bullet"><span class="by">redbell</span><span>|</span><a href="#36400266">prev</a><span>|</span><a href="#36400554">next</a><span>|</span><label class="collapse" for="c-36400763">[-]</label><label class="expand" for="c-36400763">[5 more]</label></div><br/><div class="children"><div class="content">&gt; Cautioning its own workers not to directly use code generated by Bard <i>undermines</i> Google&#x27;s claims its chatbot can help developers become more productive<p>The definitive definition of <i>irony</i> o_O<p>This reminds me of two pictures that were circulating on social media a while ago. The first was Zuckerberg holding a book while billions of people are wasting their time in endless scrolling in the Metas; the second was that Turkish chef known as Burak eating a healthy lite salad.<p>The bottom line is that <i>we sell stuff that we are not convinced to consume</i>.</div><br/><div id="36401002" class="c"><input type="checkbox" id="c-36401002" checked=""/><div class="controls bullet"><span class="by">ilitirit</span><span>|</span><a href="#36400763">parent</a><span>|</span><a href="#36400939">next</a><span>|</span><label class="collapse" for="c-36401002">[-]</label><label class="expand" for="c-36401002">[1 more]</label></div><br/><div class="children"><div class="content">I asked Bard to suggest improvements to a SQL query I wrote. It suggested that I change my filter to improvement performance. The filter I had was:<p><pre><code>   WHERE Column1 &lt;&gt; Column2

</code></pre>
The suggested improvement:<p><pre><code>   WHERE Column1 &lt;&gt; Column2

</code></pre>
When I pointed out that it just gave me exactly the same code, it apologised and suggested this improvement instead:<p><pre><code>   WHERE Column1 &gt; Column2

</code></pre>
I&#x27;m trying to understand how this helps me become more productive...</div><br/></div></div><div id="36400939" class="c"><input type="checkbox" id="c-36400939" checked=""/><div class="controls bullet"><span class="by">soultrees</span><span>|</span><a href="#36400763">parent</a><span>|</span><a href="#36401002">prev</a><span>|</span><a href="#36400867">next</a><span>|</span><label class="collapse" for="c-36400939">[-]</label><label class="expand" for="c-36400939">[1 more]</label></div><br/><div class="children"><div class="content">This is less of a productivity risk than a legal risk. Nobody is denying that these tools enable productivity like we haven’t seen before, but google is afraid of outputting protected code while the courts haven’t fully decided the stance on things.<p>Imagine Google Bard outputs a piece of code for a major new feature, making them a shit ton of money. It’s then found out that code was actually taken copied, almost directly from average Joe’s hobby app, and now you’ve got a situation on your hands. Amazing for the average joe who’s expected to get a big pay day if the courts ruled in his favour but less so for the business owner.<p>Frankly, I can’t wait to see what happens when all copyright is out of the window. Obviously within reason, but wait until you see the innovation that comes about when the gates are open. The free-for-all of ideas is a fun time to live in that’s for sure.</div><br/></div></div><div id="36400867" class="c"><input type="checkbox" id="c-36400867" checked=""/><div class="controls bullet"><span class="by">lynx23</span><span>|</span><a href="#36400763">parent</a><span>|</span><a href="#36400939">prev</a><span>|</span><a href="#36400801">next</a><span>|</span><label class="collapse" for="c-36400867">[-]</label><label class="expand" for="c-36400867">[1 more]</label></div><br/><div class="children"><div class="content">Drug dealers have figured this out long ago.  Never get high on your own stuff... No surprise this is the same with tech.</div><br/></div></div></div></div><div id="36400554" class="c"><input type="checkbox" id="c-36400554" checked=""/><div class="controls bullet"><span class="by">lastangryman</span><span>|</span><a href="#36400763">prev</a><span>|</span><a href="#36401356">next</a><span>|</span><label class="collapse" for="c-36400554">[-]</label><label class="expand" for="c-36400554">[1 more]</label></div><br/><div class="children"><div class="content">With all the those leetcode-style interviews and dynamic programming problems in the interview process, surely the genius &quot;Googlers&quot;, the worthy few, that make it through this process wouldn&#x27;t need to use AI to generate code.</div><br/></div></div><div id="36401356" class="c"><input type="checkbox" id="c-36401356" checked=""/><div class="controls bullet"><span class="by">skc</span><span>|</span><a href="#36400554">prev</a><span>|</span><a href="#36399253">next</a><span>|</span><label class="collapse" for="c-36401356">[-]</label><label class="expand" for="c-36401356">[1 more]</label></div><br/><div class="children"><div class="content">Curious to know if Bard regurgitates the Quake code that everyone was up in arms about over ChatGPT a few months ago</div><br/></div></div><div id="36399253" class="c"><input type="checkbox" id="c-36399253" checked=""/><div class="controls bullet"><span class="by">vsskanth</span><span>|</span><a href="#36401356">prev</a><span>|</span><a href="#36399457">next</a><span>|</span><label class="collapse" for="c-36399253">[-]</label><label class="expand" for="c-36399253">[10 more]</label></div><br/><div class="children"><div class="content">Yeah Google Bard seems to make up stuff way more than chatgpt and gives just wrong code. I asked for numpy code to fit a polyline rejecting outliers and it just made up an argument &quot;robust&quot; for polyfit. Chatgpt on the other hand generated a function that calculated standard deviation and removed points outside two sigma.</div><br/><div id="36399432" class="c"><input type="checkbox" id="c-36399432" checked=""/><div class="controls bullet"><span class="by">sedatk</span><span>|</span><a href="#36399253">parent</a><span>|</span><a href="#36401018">next</a><span>|</span><label class="collapse" for="c-36399432">[-]</label><label class="expand" for="c-36399432">[4 more]</label></div><br/><div class="children"><div class="content">Google Bard shamelessly tells my World War II stories[1]. Bing Chat refuses to answer such a question or says “no information” depending on its creativity level.<p>[1] <a href="https:&#x2F;&#x2F;twitter.com&#x2F;esesci&#x2F;status&#x2F;1669066574366646274" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;esesci&#x2F;status&#x2F;1669066574366646274</a></div><br/><div id="36399474" class="c"><input type="checkbox" id="c-36399474" checked=""/><div class="controls bullet"><span class="by">eyegor</span><span>|</span><a href="#36399253">root</a><span>|</span><a href="#36399432">parent</a><span>|</span><a href="#36400972">next</a><span>|</span><label class="collapse" for="c-36399474">[-]</label><label class="expand" for="c-36399474">[2 more]</label></div><br/><div class="children"><div class="content">Although that&#x27;s garbage for factual tasks, the creative writing behavior is a perfect fit for fleshing out dnd characters for example. On the other hand, Google is a search&#x2F;ad company... I&#x27;d think they&#x27;d be the most interested in integrating search&#x2F;facts into an llm. Hallucinating details about your customers is a good way to cause problems (some lawsuits already filed).</div><br/><div id="36400807" class="c"><input type="checkbox" id="c-36400807" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#36399253">root</a><span>|</span><a href="#36399474">parent</a><span>|</span><a href="#36400972">next</a><span>|</span><label class="collapse" for="c-36400807">[-]</label><label class="expand" for="c-36400807">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>On the other hand, Google is a search&#x2F;ad company... I&#x27;d think they&#x27;d be the most interested in integrating search&#x2F;facts into an llm.</i><p>At its core, an advertisement is made of two components: the <i>subject</i> - a store, a brand, a product, etc. - with which the victim is supposed to develop positive associations, ideally strong enough to motivate a purchase and&#x2F;or advertising the subject to their acquaintances, and the <i>message</i>, which is meant to create those associations. Only the first part, the <i>subject</i>, has to be factual. The <i>message</i> does <i>not</i>, and in fact it usually isn&#x27;t - manipulative bullshit performs much, much better, and generally the optimum for advertising seems to be asymptotically close to the line past which it would be legally fraud.<p>The only factual part, the <i>subject</i>, needs accurate handling, and is best suited for classical database systems - which is exactly how Google, and everyone else, is handling it. The <i>message</i> part - that&#x27;s a good match to LLMs, which excel at producing convincingly sounding bullshit. For advertising, it seems what you need is to crank <i>up</i> the hallucinations a bit, but have some plausible deniability built into the whole system, so that when the LLM hallucinates in too obvious a way, no one can actually be held responsible.</div><br/></div></div></div></div><div id="36400972" class="c"><input type="checkbox" id="c-36400972" checked=""/><div class="controls bullet"><span class="by">sofixa</span><span>|</span><a href="#36399253">root</a><span>|</span><a href="#36399432">parent</a><span>|</span><a href="#36399474">prev</a><span>|</span><a href="#36401018">next</a><span>|</span><label class="collapse" for="c-36400972">[-]</label><label class="expand" for="c-36400972">[1 more]</label></div><br/><div class="children"><div class="content">Wow that&#x27;s a lot of creativity - not only did it make up a bunch of information, that information doesn&#x27;t even make sense within the well known and understood historical context of WW2 (Turkey was neutral so there is no scenario under which a Turkish soldier is &quot;sent to the Eastern Front to fight the Soviet Union&quot;).</div><br/></div></div></div></div><div id="36401018" class="c"><input type="checkbox" id="c-36401018" checked=""/><div class="controls bullet"><span class="by">ec109685</span><span>|</span><a href="#36399253">parent</a><span>|</span><a href="#36399432">prev</a><span>|</span><a href="#36400046">next</a><span>|</span><label class="collapse" for="c-36401018">[-]</label><label class="expand" for="c-36401018">[2 more]</label></div><br/><div class="children"><div class="content">Here’s an example where Bard is making up studies to support RFK’s thesis that drinking water causes transgenderism: <a href="https:&#x2F;&#x2F;twitter.com&#x2F;EbenThurston&#x2F;status&#x2F;1670619027608092674?s=20" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;EbenThurston&#x2F;status&#x2F;1670619027608092674?...</a><p>It’s flat out lying, yet folks are using its output in arguments.</div><br/><div id="36401348" class="c"><input type="checkbox" id="c-36401348" checked=""/><div class="controls bullet"><span class="by">logicchains</span><span>|</span><a href="#36399253">root</a><span>|</span><a href="#36401018">parent</a><span>|</span><a href="#36400046">next</a><span>|</span><label class="collapse" for="c-36401348">[-]</label><label class="expand" for="c-36401348">[1 more]</label></div><br/><div class="children"><div class="content">Here&#x27;s a real study: <a href="https:&#x2F;&#x2F;pubmed.ncbi.nlm.nih.gov&#x2F;29314190&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;pubmed.ncbi.nlm.nih.gov&#x2F;29314190&#x2F;</a> . It found when frogs were exposed to atrazine (a herbicide) in wastewater runoff, &quot;female minnows were defeminized, whereas male frogs were feminized&quot;. Similarly <a href="https:&#x2F;&#x2F;www.pnas.org&#x2F;doi&#x2F;10.1073&#x2F;pnas.0909519107" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.pnas.org&#x2F;doi&#x2F;10.1073&#x2F;pnas.0909519107</a> found that &quot;Atrazine-exposed males were both demasculinized (chemically castrated) and completely feminized as adults. Ten percent of the exposed genetic males developed into functional females that copulated with unexposed males and produced viable eggs.&quot; So Atrazine can cause frogs to change their gender, and contaminates drinking waters in part of the US (<a href="https:&#x2F;&#x2F;www.ncbi.nlm.nih.gov&#x2F;pmc&#x2F;articles&#x2F;PMC6164008&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.ncbi.nlm.nih.gov&#x2F;pmc&#x2F;articles&#x2F;PMC6164008&#x2F;</a>), so it&#x27;s not beyond the realm of possibility that it also influences gender expression in humans to some degree.</div><br/></div></div></div></div><div id="36400046" class="c"><input type="checkbox" id="c-36400046" checked=""/><div class="controls bullet"><span class="by">sakesun</span><span>|</span><a href="#36399253">parent</a><span>|</span><a href="#36401018">prev</a><span>|</span><a href="#36399471">next</a><span>|</span><label class="collapse" for="c-36400046">[-]</label><label class="expand" for="c-36400046">[1 more]</label></div><br/><div class="children"><div class="content">ํYes. Google Bard often make up imaginary syntax and commands.</div><br/></div></div><div id="36399440" class="c"><input type="checkbox" id="c-36399440" checked=""/><div class="controls bullet"><span class="by">nonrepeating</span><span>|</span><a href="#36399253">parent</a><span>|</span><a href="#36399471">prev</a><span>|</span><a href="#36399457">next</a><span>|</span><label class="collapse" for="c-36399440">[-]</label><label class="expand" for="c-36399440">[1 more]</label></div><br/><div class="children"><div class="content">Sorry, I’m sure this was annoying at the time, but making up that argument is hilarious in retrospect, no?</div><br/></div></div></div></div><div id="36399457" class="c"><input type="checkbox" id="c-36399457" checked=""/><div class="controls bullet"><span class="by">Lerc</span><span>|</span><a href="#36399253">prev</a><span>|</span><a href="#36401215">next</a><span>|</span><label class="collapse" for="c-36399457">[-]</label><label class="expand" for="c-36399457">[16 more]</label></div><br/><div class="children"><div class="content">Is this because of the accuracy of the results, or is it the rights to the content that is the problem?<p>Barring any AI court case setting a precedent, We&#x27;re still at &#x27;AI generated works are public domain&#x27; aren&#x27;t we?<p>There&#x27;s probably going to be some big money arguing for the right to own content generated by their AI. I can&#x27;t really see that being in the public interest though.</div><br/><div id="36400160" class="c"><input type="checkbox" id="c-36400160" checked=""/><div class="controls bullet"><span class="by">tsimionescu</span><span>|</span><a href="#36399457">parent</a><span>|</span><a href="#36400516">next</a><span>|</span><label class="collapse" for="c-36400160">[-]</label><label class="expand" for="c-36400160">[5 more]</label></div><br/><div class="children"><div class="content">&gt; AI generated works are public domain<p>That&#x27;s not the status quo. The biggest concern is that AI can sometimes generate code from the training set verbatim, in which case that code has the copyright of the original training set - which might be GPL or proprietary or whatever else.</div><br/><div id="36400594" class="c"><input type="checkbox" id="c-36400594" checked=""/><div class="controls bullet"><span class="by">JoshTriplett</span><span>|</span><a href="#36399457">root</a><span>|</span><a href="#36400160">parent</a><span>|</span><a href="#36400187">next</a><span>|</span><label class="collapse" for="c-36400594">[-]</label><label class="expand" for="c-36400594">[3 more]</label></div><br/><div class="children"><div class="content">&gt; The biggest concern is that AI can sometimes generate code from the training set verbatim<p>Not just verbatim: AI-generated code is arguably a derivative work of code in the training set even if it doesn&#x27;t generate <i>verbatim</i> copies of training data, in the same way that any code can be a derivative work even if it doesn&#x27;t contain bitwise-identical lines.<p>If you take a piece of Python code, and translate it to C code, without a single line being copied verbatim, the resulting C code is still almost certainly a derivative work of the Python code.</div><br/><div id="36400967" class="c"><input type="checkbox" id="c-36400967" checked=""/><div class="controls bullet"><span class="by">soultrees</span><span>|</span><a href="#36399457">root</a><span>|</span><a href="#36400594">parent</a><span>|</span><a href="#36400187">next</a><span>|</span><label class="collapse" for="c-36400967">[-]</label><label class="expand" for="c-36400967">[2 more]</label></div><br/><div class="children"><div class="content">Everything you do or know is a derivative of your own training set. True original thoughts without context don’t exist, well at least in any way we can find out as every human is the product of their own training set.<p>Just out curiosity, what makes the code you write, more original than an LLMs who’s training set is way bigger than yours and likely will more variance in how to achieve same goal.<p>I’m not trying to be facetious but rather stoke the philosophical idea of the reality that humans aren’t as special and unique as we think we are.</div><br/><div id="36401065" class="c"><input type="checkbox" id="c-36401065" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#36399457">root</a><span>|</span><a href="#36400967">parent</a><span>|</span><a href="#36400187">next</a><span>|</span><label class="collapse" for="c-36401065">[-]</label><label class="expand" for="c-36401065">[1 more]</label></div><br/><div class="children"><div class="content">While I would say GPT is creative, the law doesn&#x27;t have to agree with me.<p>Also, there&#x27;s the possibility that all things creative are the human form of peacocks&#x27; tails, and if that&#x27;s the case then the cost and difficulty matters more than the outcome, and any discussion based on capitalist incentives is fundamentally flawed.<p><a href="https:&#x2F;&#x2F;kitsunesoftware.wordpress.com&#x2F;2022&#x2F;10&#x2F;09&#x2F;an-end-to-copyright&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;kitsunesoftware.wordpress.com&#x2F;2022&#x2F;10&#x2F;09&#x2F;an-end-to-c...</a><p>(I wrote this 52 days before ChatGPT came out, the reference to GPT-3 is based on the stuff OpenAI released before the chat interface).</div><br/></div></div></div></div></div></div><div id="36400187" class="c"><input type="checkbox" id="c-36400187" checked=""/><div class="controls bullet"><span class="by">SkyPuncher</span><span>|</span><a href="#36399457">root</a><span>|</span><a href="#36400160">parent</a><span>|</span><a href="#36400594">prev</a><span>|</span><a href="#36400516">next</a><span>|</span><label class="collapse" for="c-36400187">[-]</label><label class="expand" for="c-36400187">[1 more]</label></div><br/><div class="children"><div class="content">I’m sure there are other ways do to this, but simply asking OpenAI to repeat a letter 100 times will eventually get you back to content that looks like it’s training set.</div><br/></div></div></div></div><div id="36400516" class="c"><input type="checkbox" id="c-36400516" checked=""/><div class="controls bullet"><span class="by">6gvONxR4sf7o</span><span>|</span><a href="#36399457">parent</a><span>|</span><a href="#36400160">prev</a><span>|</span><a href="#36400651">next</a><span>|</span><label class="collapse" for="c-36400516">[-]</label><label class="expand" for="c-36400516">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Barring any AI court case setting a precedent, We&#x27;re still at &#x27;AI generated works are public domain&#x27; aren&#x27;t we?<p>Barring a court case, we’re more in an uncertain place. I think it’s more likely for courts to hold that many model uses aren’t transformative enough to get a fair use exemption. But until a court says either way, it most definitely does NOT just default to public domain.</div><br/></div></div><div id="36400651" class="c"><input type="checkbox" id="c-36400651" checked=""/><div class="controls bullet"><span class="by">csdreamer7</span><span>|</span><a href="#36399457">parent</a><span>|</span><a href="#36400516">prev</a><span>|</span><a href="#36399490">next</a><span>|</span><label class="collapse" for="c-36400651">[-]</label><label class="expand" for="c-36400651">[1 more]</label></div><br/><div class="children"><div class="content">&gt; We&#x27;re still at &#x27;AI generated works are public domain&#x27; aren&#x27;t we?<p>As far as the US Copyright Office is concerned. I do not believe other countries have weighed in yet.<p>Also, when your training data is based on copyleft source code, and in some cases is a direct ripoff of it, will that license be applied to it?</div><br/></div></div><div id="36399490" class="c"><input type="checkbox" id="c-36399490" checked=""/><div class="controls bullet"><span class="by">caturopath</span><span>|</span><a href="#36399457">parent</a><span>|</span><a href="#36400651">prev</a><span>|</span><a href="#36400298">next</a><span>|</span><label class="collapse" for="c-36399490">[-]</label><label class="expand" for="c-36399490">[7 more]</label></div><br/><div class="children"><div class="content">&gt; We&#x27;re still at<p>I didn&#x27;t hear we were ever there?</div><br/><div id="36399516" class="c"><input type="checkbox" id="c-36399516" checked=""/><div class="controls bullet"><span class="by">wernercd</span><span>|</span><a href="#36399457">root</a><span>|</span><a href="#36399490">parent</a><span>|</span><a href="#36400298">next</a><span>|</span><label class="collapse" for="c-36399516">[-]</label><label class="expand" for="c-36399516">[6 more]</label></div><br/><div class="children"><div class="content">Were we ever <i>NOT</i> there?<p><a href="https:&#x2F;&#x2F;builtin.com&#x2F;artificial-intelligence&#x2F;ai-copyright" rel="nofollow noreferrer">https:&#x2F;&#x2F;builtin.com&#x2F;artificial-intelligence&#x2F;ai-copyright</a><p>&quot;Can AI Art Be Copyrighted? It has long been the posture of the U.S. Copyright Office that there is no copyright protection for works created by non-humans, including machines. Therefore, the product of a generative AI model cannot be copyrighted.&quot;</div><br/><div id="36400029" class="c"><input type="checkbox" id="c-36400029" checked=""/><div class="controls bullet"><span class="by">jeffparsons</span><span>|</span><a href="#36399457">root</a><span>|</span><a href="#36399516">parent</a><span>|</span><a href="#36400054">next</a><span>|</span><label class="collapse" for="c-36400029">[-]</label><label class="expand" for="c-36400029">[3 more]</label></div><br/><div class="children"><div class="content">&gt; Therefore, the product of a generative AI model cannot be copyrighted<p>Is that last bit from the Copyright Office, or is it the author&#x27;s interpretation? Because I could just as easily imagine the battle being over who or what was the actual creator of the content (i.e. is it a derivative work), rather than whether the thing the machine created is eligible for copyright.<p>To remove the AI from the equation for a second, imagine that I took four images of living artists&#x27; work, placed them in a 2x2 grid, and called that a new artwork. There are two seperate questions to consider: (1) have I infringed upon the original authors&#x27; copyrights, and (2) is the new thing I have created eligible for copyright.<p>The stance that there is &quot;no copyright protection for works created by non-humans&quot; only addresses the second question, not the first question of how it interacts with existing copyrights.</div><br/><div id="36400092" class="c"><input type="checkbox" id="c-36400092" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#36399457">root</a><span>|</span><a href="#36400029">parent</a><span>|</span><a href="#36400054">next</a><span>|</span><label class="collapse" for="c-36400092">[-]</label><label class="expand" for="c-36400092">[2 more]</label></div><br/><div class="children"><div class="content">If you make art combining generative AI  with manual work, you get copyright over the exact portions of a work you made yourself. You have to indicate which parts. The parts generated by AI are not copyrightable.</div><br/><div id="36400148" class="c"><input type="checkbox" id="c-36400148" checked=""/><div class="controls bullet"><span class="by">danielmarkbruce</span><span>|</span><a href="#36399457">root</a><span>|</span><a href="#36400092">parent</a><span>|</span><a href="#36400054">next</a><span>|</span><label class="collapse" for="c-36400148">[-]</label><label class="expand" for="c-36400148">[1 more]</label></div><br/><div class="children"><div class="content">You missed the question.</div><br/></div></div></div></div></div></div><div id="36400054" class="c"><input type="checkbox" id="c-36400054" checked=""/><div class="controls bullet"><span class="by">Aerroon</span><span>|</span><a href="#36399457">root</a><span>|</span><a href="#36399516">parent</a><span>|</span><a href="#36400029">prev</a><span>|</span><a href="#36400298">next</a><span>|</span><label class="collapse" for="c-36400054">[-]</label><label class="expand" for="c-36400054">[2 more]</label></div><br/><div class="children"><div class="content">Wait, so the US copyright office considers the AI model to be the sole creator of the work? So the prompt - the actual intent behind the use of the tool - is irrelevant?<p>Then where is the line? If I use a painting program that runs a Math.random() on a brush and I use this brush to draw something then is that also created by a non-human?<p>If I program a robot arm to draw a picture then is that picture also created by a non-human? What if I use a printer?</div><br/><div id="36400100" class="c"><input type="checkbox" id="c-36400100" checked=""/><div class="controls bullet"><span class="by">jstummbillig</span><span>|</span><a href="#36399457">root</a><span>|</span><a href="#36400054">parent</a><span>|</span><a href="#36400298">next</a><span>|</span><label class="collapse" for="c-36400100">[-]</label><label class="expand" for="c-36400100">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Wait, so the US copyright office considers the AI model to be the sole creator of the work?<p>From what I gather, they just don&#x27;t consider it a creation in a way that pertains to copyright laws. Like a rock on the beach.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="36401215" class="c"><input type="checkbox" id="c-36401215" checked=""/><div class="controls bullet"><span class="by">alexhjones</span><span>|</span><a href="#36399457">prev</a><span>|</span><a href="#36400367">next</a><span>|</span><label class="collapse" for="c-36401215">[-]</label><label class="expand" for="c-36401215">[1 more]</label></div><br/><div class="children"><div class="content">This isn’t referring to Google’s code generation tool DuetAI &#x2F; Codey though, it is referring to their general chatbot which is not marketed as a code generation tool. If they issued this for DuetAI it would be a bigger deal.</div><br/></div></div><div id="36400367" class="c"><input type="checkbox" id="c-36400367" checked=""/><div class="controls bullet"><span class="by">lyu07282</span><span>|</span><a href="#36401215">prev</a><span>|</span><a href="#36399192">next</a><span>|</span><label class="collapse" for="c-36400367">[-]</label><label class="expand" for="c-36400367">[11 more]</label></div><br/><div class="children"><div class="content">But has anyone actually tried Bard for coding in practice? It&#x27;s so awful, practically unusable. GPT4 feels several generations ahead of Bard.</div><br/><div id="36400433" class="c"><input type="checkbox" id="c-36400433" checked=""/><div class="controls bullet"><span class="by">londons_explore</span><span>|</span><a href="#36400367">parent</a><span>|</span><a href="#36399192">next</a><span>|</span><label class="collapse" for="c-36400433">[-]</label><label class="expand" for="c-36400433">[10 more]</label></div><br/><div class="children"><div class="content">Agreed.   I frequently use GPT-4&#x27;s code.    It is especially useful coding in a domain I&#x27;m not familiar with.  I recently asked it to write a blender plugin to export certain polygons to a spreadsheet (with coordinates projected and transformed in certain ways), and it did admirably.    I had never used blender before, and it would have taken me hours otherwise.</div><br/><div id="36400552" class="c"><input type="checkbox" id="c-36400552" checked=""/><div class="controls bullet"><span class="by">oxygen_crisis</span><span>|</span><a href="#36400367">root</a><span>|</span><a href="#36400433">parent</a><span>|</span><a href="#36400910">next</a><span>|</span><label class="collapse" for="c-36400552">[-]</label><label class="expand" for="c-36400552">[8 more]</label></div><br/><div class="children"><div class="content">If you can&#x27;t write the code yourself, you&#x27;re not a good judge of how competent it is. If you admire any code that simply works at all when you don&#x27;t know how it should be done, then your admiration isn&#x27;t a measurement worth considering.<p>Ask an LLM how to do something you already know very well how to do properly, only then can you see its flaws through its mindless bravado.</div><br/><div id="36401323" class="c"><input type="checkbox" id="c-36401323" checked=""/><div class="controls bullet"><span class="by">jstummbillig</span><span>|</span><a href="#36400367">root</a><span>|</span><a href="#36400552">parent</a><span>|</span><a href="#36400695">next</a><span>|</span><label class="collapse" for="c-36401323">[-]</label><label class="expand" for="c-36401323">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t have to have built a car to be able to judge the quality of a car to a decent approximation. And with code, surely, skill carry over is very real. Being able to generalize is literally our entire thing.</div><br/></div></div><div id="36400695" class="c"><input type="checkbox" id="c-36400695" checked=""/><div class="controls bullet"><span class="by">Me1000</span><span>|</span><a href="#36400367">root</a><span>|</span><a href="#36400552">parent</a><span>|</span><a href="#36401323">prev</a><span>|</span><a href="#36400758">next</a><span>|</span><label class="collapse" for="c-36400695">[-]</label><label class="expand" for="c-36400695">[4 more]</label></div><br/><div class="children"><div class="content">This doesn’t ring true for me. I have ChatGPT write code for me that I could write myself. I’ve had ChatGPT even rewrite code for me to make it more legible. It’s pretty good at it, especially when it comes to more popular languages.</div><br/><div id="36400833" class="c"><input type="checkbox" id="c-36400833" checked=""/><div class="controls bullet"><span class="by">plewd</span><span>|</span><a href="#36400367">root</a><span>|</span><a href="#36400695">parent</a><span>|</span><a href="#36401099">next</a><span>|</span><label class="collapse" for="c-36400833">[-]</label><label class="expand" for="c-36400833">[1 more]</label></div><br/><div class="children"><div class="content">&gt;&gt; If you can&#x27;t write the code yourself<p>&gt; that I could write myself<p>I don&#x27;t think your comment is very relevant, given how they specified it.</div><br/></div></div><div id="36401099" class="c"><input type="checkbox" id="c-36401099" checked=""/><div class="controls bullet"><span class="by">mejutoco</span><span>|</span><a href="#36400367">root</a><span>|</span><a href="#36400695">parent</a><span>|</span><a href="#36400833">prev</a><span>|</span><a href="#36400853">next</a><span>|</span><label class="collapse" for="c-36401099">[-]</label><label class="expand" for="c-36401099">[1 more]</label></div><br/><div class="children"><div class="content">You are agreeing with OP. You could evaluate the quality of ChatGPT because you could write the code yourself.</div><br/></div></div><div id="36400853" class="c"><input type="checkbox" id="c-36400853" checked=""/><div class="controls bullet"><span class="by">londons_explore</span><span>|</span><a href="#36400367">root</a><span>|</span><a href="#36400695">parent</a><span>|</span><a href="#36401099">prev</a><span>|</span><a href="#36400758">next</a><span>|</span><label class="collapse" for="c-36400853">[-]</label><label class="expand" for="c-36400853">[1 more]</label></div><br/><div class="children"><div class="content">I tried asking it to write code to swap columns 1 and 3 of a CSV file, written in only x86 assembly.     It refused, claiming that while it was theoretically possible, it would be stupid to do such a thing.    It couldn&#x27;t be persuaded...</div><br/></div></div></div></div><div id="36400758" class="c"><input type="checkbox" id="c-36400758" checked=""/><div class="controls bullet"><span class="by">interroboink</span><span>|</span><a href="#36400367">root</a><span>|</span><a href="#36400552">parent</a><span>|</span><a href="#36400695">prev</a><span>|</span><a href="#36400910">next</a><span>|</span><label class="collapse" for="c-36400758">[-]</label><label class="expand" for="c-36400758">[2 more]</label></div><br/><div class="children"><div class="content">On the other hand, somewhat in the style of NP-Completeness, it is often easier to verify that something is correct than it is to generate it from scratch. Even if I can&#x27;t cook, I can say it&#x27;s a tasty meal (:</div><br/><div id="36401219" class="c"><input type="checkbox" id="c-36401219" checked=""/><div class="controls bullet"><span class="by">LiamPowell</span><span>|</span><a href="#36400367">root</a><span>|</span><a href="#36400758">parent</a><span>|</span><a href="#36400910">next</a><span>|</span><label class="collapse" for="c-36401219">[-]</label><label class="expand" for="c-36401219">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s usually somewhat easy to verify a piece of code is not obviously wrong, what&#x27;s much harder is proving that a piece of code is not subtlety wrong. When given a complete piece of code that appears to work, it can be very easy to convince yourself that you understand it well enough to know that it is correct, even when it&#x27;s not. This problem isn&#x27;t unique to LLMs, refer to the case of programmers copying binary search from textbooks without understanding how it works in their programming language of choice [1]. The problem is avoided (or at least minimised) by formal verification, which is where I think we should be heading with LLM code generation; this additionally avoids the problems with trying to accurately provide a specification in plain English.<p>[1] <a href="https:&#x2F;&#x2F;ai.googleblog.com&#x2F;2006&#x2F;06&#x2F;extra-extra-read-all-about-it-nearly.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;ai.googleblog.com&#x2F;2006&#x2F;06&#x2F;extra-extra-read-all-about...</a></div><br/></div></div></div></div></div></div><div id="36400910" class="c"><input type="checkbox" id="c-36400910" checked=""/><div class="controls bullet"><span class="by">lyu07282</span><span>|</span><a href="#36400367">root</a><span>|</span><a href="#36400433">parent</a><span>|</span><a href="#36400552">prev</a><span>|</span><a href="#36399192">next</a><span>|</span><label class="collapse" for="c-36400910">[-]</label><label class="expand" for="c-36400910">[1 more]</label></div><br/><div class="children"><div class="content">Yeah it has a pretty solid grip on the python API of blender, which is really surprising given how badly documented it is. There is even an addon now that integrates it directly in Blender:<p><a href="https:&#x2F;&#x2F;twitter.com&#x2F;rowancheung&#x2F;status&#x2F;1639702313186230272" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;rowancheung&#x2F;status&#x2F;1639702313186230272</a>?</div><br/></div></div></div></div></div></div><div id="36399192" class="c"><input type="checkbox" id="c-36399192" checked=""/><div class="controls bullet"><span class="by">metadat</span><span>|</span><a href="#36400367">prev</a><span>|</span><a href="#36401319">next</a><span>|</span><label class="collapse" for="c-36399192">[-]</label><label class="expand" for="c-36399192">[1 more]</label></div><br/><div class="children"><div class="content">Discussed 5 days ago:<p><i>Google warns staff about chatbots</i><p><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36341188">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36341188</a> (107 comments)</div><br/></div></div><div id="36401319" class="c"><input type="checkbox" id="c-36401319" checked=""/><div class="controls bullet"><span class="by">Borrible</span><span>|</span><a href="#36399192">prev</a><span>|</span><a href="#36399852">next</a><span>|</span><label class="collapse" for="c-36401319">[-]</label><label class="expand" for="c-36401319">[1 more]</label></div><br/><div class="children"><div class="content">Ah, the Ourobous Language Problem.</div><br/></div></div><div id="36399852" class="c"><input type="checkbox" id="c-36399852" checked=""/><div class="controls bullet"><span class="by">travisr</span><span>|</span><a href="#36401319">prev</a><span>|</span><a href="#36400881">next</a><span>|</span><label class="collapse" for="c-36399852">[-]</label><label class="expand" for="c-36399852">[3 more]</label></div><br/><div class="children"><div class="content">This isn’t surprising. It’s like saying “don’t post sensitive&#x2F;proprietary info on stackoverflow and don’t blindly paste code from there into your professional work.”</div><br/><div id="36399970" class="c"><input type="checkbox" id="c-36399970" checked=""/><div class="controls bullet"><span class="by">ineedasername</span><span>|</span><a href="#36399852">parent</a><span>|</span><a href="#36400881">next</a><span>|</span><label class="collapse" for="c-36399970">[-]</label><label class="expand" for="c-36399970">[2 more]</label></div><br/><div class="children"><div class="content">Except they have an offering in the market for other people to do just that. Put stackoverflow aside, that’s not Google.<p>Gooogle telling staff to not use Bard would be like telling them a decade ago “don’t use android”</div><br/><div id="36400572" class="c"><input type="checkbox" id="c-36400572" checked=""/><div class="controls bullet"><span class="by">pgeorgi</span><span>|</span><a href="#36399852">root</a><span>|</span><a href="#36399970">parent</a><span>|</span><a href="#36400881">next</a><span>|</span><label class="collapse" for="c-36400572">[-]</label><label class="expand" for="c-36400572">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Except they have an offering in the market for other people to do just that.<p>bard.google.com states right on the front page: &quot;Bard is an experiment and may give inaccurate or inappropriate responses.&quot;<p>Also, the warning is about _all_ LLMs.</div><br/></div></div></div></div></div></div><div id="36400848" class="c"><input type="checkbox" id="c-36400848" checked=""/><div class="controls bullet"><span class="by">skilled</span><span>|</span><a href="#36400881">prev</a><span>|</span><label class="collapse" for="c-36400848">[-]</label><label class="expand" for="c-36400848">[1 more]</label></div><br/><div class="children"><div class="content">The irony being that Google is releasing disruptive AI features and enforcing them on users, all the while telling their employees not to use these features because they are dogshit and inaccurate.</div><br/></div></div></div></div></div></div></div></body></html>