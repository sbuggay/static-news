<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1703667654884" as="style"/><link rel="stylesheet" href="styles.css?v=1703667654884"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2812620">Performance of Large Language Models on a Neurology Board–Style Examination</a> <span class="domain">(<a href="https://jamanetwork.com">jamanetwork.com</a>)</span></div><div class="subtext"><span>geox</span> | <span>6 comments</span></div><br/><div><div id="38779862" class="c"><input type="checkbox" id="c-38779862" checked=""/><div class="controls bullet"><span class="by">nopinsight</span><span>|</span><a href="#38779436">next</a><span>|</span><label class="collapse" for="c-38779862">[-]</label><label class="expand" for="c-38779862">[1 more]</label></div><br/><div class="children"><div class="content">This finding could be quite useful (LLM 1 refers to GPT-3.5 and LLM 2, GPT-4):<p>&quot;Reproducibility analyses revealed that highly reproducible answers were more likely to be answered correctly than inconsistent answers by LLM 1 (66 of 88 [75.0%] vs 5 of 13 [38.5%]; P = .02), potentially indicating another marker of confidence of LLMs that might be leveraged to filter out invalid responses. The same observation was made with LLM 2, with 78 of 96 correct answers (81.3%) in those with high reproducibility vs 1 of 4 (25.0%) in answers with low reproducibility (P = .04).&quot;<p>The paper submitted 50 independent queries to assess self-consistency. Exploring the trade-off graph between the number of queries and the effectiveness to filter likely invalid responses would be interesting.</div><br/></div></div><div id="38779436" class="c"><input type="checkbox" id="c-38779436" checked=""/><div class="controls bullet"><span class="by">hackerlight</span><span>|</span><a href="#38779862">prev</a><span>|</span><label class="collapse" for="c-38779436">[-]</label><label class="expand" for="c-38779436">[4 more]</label></div><br/><div class="children"><div class="content">&gt; 85.0% of questions correctly compared with the mean human score of 73.8%<p>&gt; These questions are either behind a paywall (in the case of the question bank) or published after 2021 and therefore out-of-training data for both LLMs.<p>&gt; Despite their strengths, both models demonstrated weaker performance in tasks requiring higher-order thinking compared with questions requiring only lower-order thinking.<p>&gt; Interestingly, both models exhibited confident language when answering questions, even when their responses were incorrect.</div><br/><div id="38779841" class="c"><input type="checkbox" id="c-38779841" checked=""/><div class="controls bullet"><span class="by">cjbprime</span><span>|</span><a href="#38779436">parent</a><span>|</span><label class="collapse" for="c-38779841">[-]</label><label class="expand" for="c-38779841">[3 more]</label></div><br/><div class="children"><div class="content">&gt; These questions are either behind a paywall (in the case of the question bank) or published after 2021 and therefore out-of-training data for both LLMs<p>I&#x27;m not sure that it&#x27;s true that GPT-4&#x27;s web scrape is currently from before 2021. And even if it was, this still doesn&#x27;t seem like an effective analysis of test data contamination. (For example, have any questions that differ only in insignificant ways been asked before?)<p>I&#x27;m not skeptical of GPT-4&#x27;s capability in the way many (most?) people are, but I&#x27;d still like to see the level of dialogue around training set data improve.</div><br/><div id="38779891" class="c"><input type="checkbox" id="c-38779891" checked=""/><div class="controls bullet"><span class="by">nopinsight</span><span>|</span><a href="#38779436">root</a><span>|</span><a href="#38779841">parent</a><span>|</span><label class="collapse" for="c-38779891">[-]</label><label class="expand" for="c-38779891">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m intrigued as well. Here&#x27;s my Q&amp;A with GPT-4 itself:<p>&quot;Q: What was the data cutoff date when GPT-4 was first released?<p>A: The data cutoff for GPT-4, which means the point at which it stopped being trained on new data, was September 2021. This cutoff date is significant as it means GPT-4&#x27;s training did not include information or events that occurred after this time.&quot;</div><br/><div id="38780191" class="c"><input type="checkbox" id="c-38780191" checked=""/><div class="controls bullet"><span class="by">hooo</span><span>|</span><a href="#38779436">root</a><span>|</span><a href="#38779891">parent</a><span>|</span><label class="collapse" for="c-38780191">[-]</label><label class="expand" for="c-38780191">[1 more]</label></div><br/><div class="children"><div class="content">I just asked “what is your training cut off date?” and it responded “ My training includes data up to April 2023.”</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></body></html>