<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1718701258927" as="style"/><link rel="stylesheet" href="styles.css?v=1718701258927"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/AgentOps-AI/tokencost">Show HN: Token price calculator for 400+ LLMs</a> <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>Areibman</span> | <span>41 comments</span></div><br/><div><div id="40711000" class="c"><input type="checkbox" id="c-40711000" checked=""/><div class="controls bullet"><span class="by">yelnatz</span><span>|</span><a href="#40710871">next</a><span>|</span><label class="collapse" for="c-40711000">[-]</label><label class="expand" for="c-40711000">[6 more]</label></div><br/><div class="children"><div class="content">Can you do a column and normalize them?<p>Too many zeroes for my blind ass making it hard to compare.</div><br/><div id="40711040" class="c"><input type="checkbox" id="c-40711040" checked=""/><div class="controls bullet"><span class="by">ryaneager</span><span>|</span><a href="#40711000">parent</a><span>|</span><a href="#40710871">next</a><span>|</span><label class="collapse" for="c-40711040">[-]</label><label class="expand" for="c-40711040">[5 more]</label></div><br/><div class="children"><div class="content">Yeah a Tokens per $1 column would vastly help the readability.</div><br/><div id="40711163" class="c"><input type="checkbox" id="c-40711163" checked=""/><div class="controls bullet"><span class="by">qeternity</span><span>|</span><a href="#40711000">root</a><span>|</span><a href="#40711040">parent</a><span>|</span><a href="#40710871">next</a><span>|</span><label class="collapse" for="c-40711163">[-]</label><label class="expand" for="c-40711163">[4 more]</label></div><br/><div class="children"><div class="content">$&#x2F;million tokens is the standard pricing metric.</div><br/><div id="40713082" class="c"><input type="checkbox" id="c-40713082" checked=""/><div class="controls bullet"><span class="by">Tao3300</span><span>|</span><a href="#40711000">root</a><span>|</span><a href="#40711163">parent</a><span>|</span><a href="#40710871">next</a><span>|</span><label class="collapse" for="c-40713082">[-]</label><label class="expand" for="c-40713082">[3 more]</label></div><br/><div class="children"><div class="content">standard ≠ good</div><br/><div id="40713795" class="c"><input type="checkbox" id="c-40713795" checked=""/><div class="controls bullet"><span class="by">andenacitelli</span><span>|</span><a href="#40711000">root</a><span>|</span><a href="#40713082">parent</a><span>|</span><a href="#40710871">next</a><span>|</span><label class="collapse" for="c-40713795">[-]</label><label class="expand" for="c-40713795">[2 more]</label></div><br/><div class="children"><div class="content">Yes, but it’s true in the general case. Defaults are usually the defaults for a reason — someone putting thought into what makes sense for most users.</div><br/><div id="40713808" class="c"><input type="checkbox" id="c-40713808" checked=""/><div class="controls bullet"><span class="by">Tao3300</span><span>|</span><a href="#40711000">root</a><span>|</span><a href="#40713795">parent</a><span>|</span><a href="#40710871">next</a><span>|</span><label class="collapse" for="c-40713808">[-]</label><label class="expand" for="c-40713808">[1 more]</label></div><br/><div class="children"><div class="content">Not necessarily so when you&#x27;re trying to sell stuff...</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="40710871" class="c"><input type="checkbox" id="c-40710871" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#40711000">prev</a><span>|</span><a href="#40714390">next</a><span>|</span><label class="collapse" for="c-40710871">[-]</label><label class="expand" for="c-40710871">[11 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t understand how the Claude functionality works.<p>As far as I know Anthropic haven&#x27;t released the tokenizer for Claude - unlike OpenAI&#x27;s tiktoken - but your tool lists the Claude 3 models as supported. How are you counting tokens for those?</div><br/><div id="40711374" class="c"><input type="checkbox" id="c-40711374" checked=""/><div class="controls bullet"><span class="by">Areibman</span><span>|</span><a href="#40710871">parent</a><span>|</span><a href="#40710980">next</a><span>|</span><label class="collapse" for="c-40711374">[-]</label><label class="expand" for="c-40711374">[7 more]</label></div><br/><div class="children"><div class="content">Anthropic actually has a Claude 3 tokenizer tucked away in one of their repos: <a href="https:&#x2F;&#x2F;github.com&#x2F;anthropics&#x2F;anthropic-tokenizer-typescript">https:&#x2F;&#x2F;github.com&#x2F;anthropics&#x2F;anthropic-tokenizer-typescript</a><p>At this moment, Tokencost uses the OpenAI tokenizer as a default tokenizer, but this would be a welcome PR!</div><br/><div id="40711504" class="c"><input type="checkbox" id="c-40711504" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#40710871">root</a><span>|</span><a href="#40711374">parent</a><span>|</span><a href="#40710980">next</a><span>|</span><label class="collapse" for="c-40711504">[-]</label><label class="expand" for="c-40711504">[6 more]</label></div><br/><div class="children"><div class="content">&quot;This package can be used to count tokens for Anthropic&#x27;s older models. As of the Claude 3 models, this algorithm is no longer accurate [...]&quot;<p>I&#x27;ve been bugging Anthropic about this for a while, they said that releasing a new tokenizer is not on their current roadmap.</div><br/><div id="40711734" class="c"><input type="checkbox" id="c-40711734" checked=""/><div class="controls bullet"><span class="by">throwaway211</span><span>|</span><a href="#40710871">root</a><span>|</span><a href="#40711504">parent</a><span>|</span><a href="#40710980">next</a><span>|</span><label class="collapse" for="c-40711734">[-]</label><label class="expand" for="c-40711734">[5 more]</label></div><br/><div class="children"><div class="content">Imagine a coffee shop refusing to have a price list until after the coffee&#x27;s been made.</div><br/><div id="40712333" class="c"><input type="checkbox" id="c-40712333" checked=""/><div class="controls bullet"><span class="by">kevindamm</span><span>|</span><a href="#40710871">root</a><span>|</span><a href="#40711734">parent</a><span>|</span><a href="#40715060">next</a><span>|</span><label class="collapse" for="c-40712333">[-]</label><label class="expand" for="c-40712333">[3 more]</label></div><br/><div class="children"><div class="content">In many countries a taxi won&#x27;t tell you how much the ride will cost.  The first time I traveled to somewhere that negotiated the cost up front it blew my mind.<p>Frequently, contracts will have room for additional charges if circumstances change even a little, or products will have a market rate (fish, equity, etc.).<p>It might seem absurd but variable cost things are not uncommon.</div><br/><div id="40714914" class="c"><input type="checkbox" id="c-40714914" checked=""/><div class="controls bullet"><span class="by">_flux</span><span>|</span><a href="#40710871">root</a><span>|</span><a href="#40712333">parent</a><span>|</span><a href="#40712570">next</a><span>|</span><label class="collapse" for="c-40714914">[-]</label><label class="expand" for="c-40714914">[1 more]</label></div><br/><div class="children"><div class="content">In this case there&#x27;s nothing that&#x27;s variable, though, and the competition is able to pull it off precisely. Indeed, they themselves were able to do it before!</div><br/></div></div><div id="40712570" class="c"><input type="checkbox" id="c-40712570" checked=""/><div class="controls bullet"><span class="by">MattGaiser</span><span>|</span><a href="#40710871">root</a><span>|</span><a href="#40712333">parent</a><span>|</span><a href="#40714914">prev</a><span>|</span><a href="#40715060">next</a><span>|</span><label class="collapse" for="c-40712570">[-]</label><label class="expand" for="c-40712570">[1 more]</label></div><br/><div class="children"><div class="content">In Oman, every tax fare was basically just of the bills. So 5 rials, 10 rials, or 20 rials. So many different ways people price things around the world.</div><br/></div></div></div></div><div id="40715060" class="c"><input type="checkbox" id="c-40715060" checked=""/><div class="controls bullet"><span class="by">itake</span><span>|</span><a href="#40710871">root</a><span>|</span><a href="#40711734">parent</a><span>|</span><a href="#40712333">prev</a><span>|</span><a href="#40710980">next</a><span>|</span><label class="collapse" for="c-40715060">[-]</label><label class="expand" for="c-40715060">[1 more]</label></div><br/><div class="children"><div class="content">reminds me of the coffee shop incident in seattle last week with the hammer</div><br/></div></div></div></div></div></div></div></div><div id="40710980" class="c"><input type="checkbox" id="c-40710980" checked=""/><div class="controls bullet"><span class="by">dudeinhawaii</span><span>|</span><a href="#40710871">parent</a><span>|</span><a href="#40711374">prev</a><span>|</span><a href="#40714390">next</a><span>|</span><label class="collapse" for="c-40710980">[-]</label><label class="expand" for="c-40710980">[3 more]</label></div><br/><div class="children"><div class="content">It&#x27;s open source so you can take a look (I&#x27;m not the author): <a href="https:&#x2F;&#x2F;github.com&#x2F;AgentOps-AI&#x2F;tokencost&#x2F;blob&#x2F;main&#x2F;tokencost&#x2F;costs.py">https:&#x2F;&#x2F;github.com&#x2F;AgentOps-AI&#x2F;tokencost&#x2F;blob&#x2F;main&#x2F;tokencost...</a><p>It looks like tiktoken is the default for most of the methods.<p>Disclaimer: I didn&#x27;t fully trace which are being used in each case&#x2F;model.</div><br/><div id="40711095" class="c"><input type="checkbox" id="c-40711095" checked=""/><div class="controls bullet"><span class="by">refibrillator</span><span>|</span><a href="#40710871">root</a><span>|</span><a href="#40710980">parent</a><span>|</span><a href="#40711161">next</a><span>|</span><label class="collapse" for="c-40711095">[-]</label><label class="expand" for="c-40711095">[1 more]</label></div><br/><div class="children"><div class="content"><i>&gt; # TODO: Add Claude support </i><p>There are no cases for Claude models yet.<p>I wonder if anyone has run a bunch of messages through Anthropic&#x27;s API and used the returned token count to approximate the tokenizer?</div><br/></div></div><div id="40711161" class="c"><input type="checkbox" id="c-40711161" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#40710871">root</a><span>|</span><a href="#40710980">parent</a><span>|</span><a href="#40711095">prev</a><span>|</span><a href="#40714390">next</a><span>|</span><label class="collapse" for="c-40711161">[-]</label><label class="expand" for="c-40711161">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, I asked here because I dug around in the code and couldn&#x27;t see how they were doing this, wanted to check I hadn&#x27;t missed something.</div><br/></div></div></div></div></div></div><div id="40714390" class="c"><input type="checkbox" id="c-40714390" checked=""/><div class="controls bullet"><span class="by">oopsallmagic</span><span>|</span><a href="#40710871">prev</a><span>|</span><a href="#40711341">next</a><span>|</span><label class="collapse" for="c-40714390">[-]</label><label class="expand" for="c-40714390">[2 more]</label></div><br/><div class="children"><div class="content">Can we get conversions for kg of CO2 emitted, too?</div><br/><div id="40714663" class="c"><input type="checkbox" id="c-40714663" checked=""/><div class="controls bullet"><span class="by">_flux</span><span>|</span><a href="#40714390">parent</a><span>|</span><a href="#40711341">next</a><span>|</span><label class="collapse" for="c-40714663">[-]</label><label class="expand" for="c-40714663">[1 more]</label></div><br/><div class="children"><div class="content">It would be nice, but how do we get this information required for the conversion?</div><br/></div></div></div></div><div id="40711341" class="c"><input type="checkbox" id="c-40711341" checked=""/><div class="controls bullet"><span class="by">Lerc</span><span>|</span><a href="#40714390">prev</a><span>|</span><a href="#40711063">next</a><span>|</span><label class="collapse" for="c-40711341">[-]</label><label class="expand" for="c-40711341">[4 more]</label></div><br/><div class="children"><div class="content">With all the options there seems like an opportunity for a single point API that can take a series of prompts, a budget and a quality hint to distribute batches for most bang for buck.<p>Maybe a small triage AI to decide how effectively models handle certain prompts to preserve spending for the difficult tasks.<p>Does anything like this exist yet?</div><br/><div id="40712921" class="c"><input type="checkbox" id="c-40712921" checked=""/><div class="controls bullet"><span class="by">curious_cat_163</span><span>|</span><a href="#40711341">parent</a><span>|</span><a href="#40711063">next</a><span>|</span><label class="collapse" for="c-40712921">[-]</label><label class="expand" for="c-40712921">[3 more]</label></div><br/><div class="children"><div class="content">I have yet to find a use case where quality can be traded off.<p>Would love to hear what you had in mind.</div><br/><div id="40713472" class="c"><input type="checkbox" id="c-40713472" checked=""/><div class="controls bullet"><span class="by">Lerc</span><span>|</span><a href="#40711341">root</a><span>|</span><a href="#40712921">parent</a><span>|</span><a href="#40713311">next</a><span>|</span><label class="collapse" for="c-40713472">[-]</label><label class="expand" for="c-40713472">[1 more]</label></div><br/><div class="children"><div class="content">It is not so much a drop in quality as there are tasks that every model above a certain threshold will perform equally.<p>Most can do 2+2 = 4.<p>One test prompt I use on LLMs is asking it to produce a JavaScript function that takes an ImageData object and returns a new ImageData object with an all direction Sobel edge detection.  Quite a lot of even quite small models can generate functions like this.<p>In general, I don&#x27;t even think this is a question that needs to be answered.  A lot of API providers have different quality&#x2F;price tiers.  The fact that people are using the different tiers should be sufficient to show that at least some people are finding cases where cheaper models are good enough.</div><br/></div></div><div id="40713311" class="c"><input type="checkbox" id="c-40713311" checked=""/><div class="controls bullet"><span class="by">mvdtnz</span><span>|</span><a href="#40711341">root</a><span>|</span><a href="#40712921">parent</a><span>|</span><a href="#40713472">prev</a><span>|</span><a href="#40711063">next</a><span>|</span><label class="collapse" for="c-40713311">[-]</label><label class="expand" for="c-40713311">[1 more]</label></div><br/><div class="children"><div class="content">Every single use case of LLMs inherently sacrifices quality, whether the developers are willing to admit it or not. I agree with you though that there aren&#x27;t many use cases where end users would knowingly accept the trade off.</div><br/></div></div></div></div></div></div><div id="40711063" class="c"><input type="checkbox" id="c-40711063" checked=""/><div class="controls bullet"><span class="by">Ilasky</span><span>|</span><a href="#40711341">prev</a><span>|</span><a href="#40712600">next</a><span>|</span><label class="collapse" for="c-40711063">[-]</label><label class="expand" for="c-40711063">[3 more]</label></div><br/><div class="children"><div class="content">I dig it! Kind of related, but I made a comparison of LLM API costs vs their leaderboard performance to gauge which models can be more bang for the buck [0]<p>[0] <a href="https:&#x2F;&#x2F;llmcompare.net" rel="nofollow">https:&#x2F;&#x2F;llmcompare.net</a></div><br/><div id="40714327" class="c"><input type="checkbox" id="c-40714327" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#40711063">parent</a><span>|</span><a href="#40711502">next</a><span>|</span><label class="collapse" for="c-40714327">[-]</label><label class="expand" for="c-40714327">[1 more]</label></div><br/><div class="children"><div class="content">Nice, can you make a triangle with (cost, performance, speed)? That would show the tradeoffs.</div><br/></div></div><div id="40711502" class="c"><input type="checkbox" id="c-40711502" checked=""/><div class="controls bullet"><span class="by">SubiculumCode</span><span>|</span><a href="#40711063">parent</a><span>|</span><a href="#40714327">prev</a><span>|</span><a href="#40712600">next</a><span>|</span><label class="collapse" for="c-40711502">[-]</label><label class="expand" for="c-40711502">[1 more]</label></div><br/><div class="children"><div class="content">Sure makes the case for Gemini Pro, doesn&#x27;t it.</div><br/></div></div></div></div><div id="40712600" class="c"><input type="checkbox" id="c-40712600" checked=""/><div class="controls bullet"><span class="by">zackfield</span><span>|</span><a href="#40711063">prev</a><span>|</span><a href="#40714720">next</a><span>|</span><label class="collapse" for="c-40712600">[-]</label><label class="expand" for="c-40712600">[2 more]</label></div><br/><div class="children"><div class="content">Very cool! Is this cost directory you&#x27;re using the best source for historical cost per 1M tokens? <a href="https:&#x2F;&#x2F;github.com&#x2F;BerriAI&#x2F;litellm&#x2F;blob&#x2F;main&#x2F;model_prices_and_context_window.json">https:&#x2F;&#x2F;github.com&#x2F;BerriAI&#x2F;litellm&#x2F;blob&#x2F;main&#x2F;model_prices_an...</a></div><br/><div id="40712982" class="c"><input type="checkbox" id="c-40712982" checked=""/><div class="controls bullet"><span class="by">Areibman</span><span>|</span><a href="#40712600">parent</a><span>|</span><a href="#40714720">next</a><span>|</span><label class="collapse" for="c-40712982">[-]</label><label class="expand" for="c-40712982">[1 more]</label></div><br/><div class="children"><div class="content">Best one I&#x27;ve found out there. If there&#x27;s another, very open to replacing</div><br/></div></div></div></div><div id="40714720" class="c"><input type="checkbox" id="c-40714720" checked=""/><div class="controls bullet"><span class="by">jaredliu233</span><span>|</span><a href="#40712600">prev</a><span>|</span><a href="#40712031">next</a><span>|</span><label class="collapse" for="c-40714720">[-]</label><label class="expand" for="c-40714720">[1 more]</label></div><br/><div class="children"><div class="content">wow, this is really useful!! Just the price list alone has given me a lot of inspiration, thank you</div><br/></div></div><div id="40712031" class="c"><input type="checkbox" id="c-40712031" checked=""/><div class="controls bullet"><span class="by">Karrot_Kream</span><span>|</span><a href="#40714720">prev</a><span>|</span><a href="#40711050">next</a><span>|</span><label class="collapse" for="c-40712031">[-]</label><label class="expand" for="c-40712031">[1 more]</label></div><br/><div class="children"><div class="content">A whole bunch of the costs are listed as zeroes, with multiple decimal points. I noticed y&#x27;all used the Decimal library and tried to hold onto precision so I&#x27;m not sure what&#x27;s going on, but certainly some of the cheaper models just show up as &quot;free&quot;.</div><br/></div></div><div id="40711050" class="c"><input type="checkbox" id="c-40711050" checked=""/><div class="controls bullet"><span class="by">ilaksh</span><span>|</span><a href="#40712031">prev</a><span>|</span><a href="#40712467">next</a><span>|</span><label class="collapse" for="c-40711050">[-]</label><label class="expand" for="c-40711050">[2 more]</label></div><br/><div class="children"><div class="content">Nice. Any plans to add calculations for image input for the models that allow that?</div><br/><div id="40711455" class="c"><input type="checkbox" id="c-40711455" checked=""/><div class="controls bullet"><span class="by">Areibman</span><span>|</span><a href="#40711050">parent</a><span>|</span><a href="#40712467">next</a><span>|</span><label class="collapse" for="c-40711455">[-]</label><label class="expand" for="c-40711455">[1 more]</label></div><br/><div class="children"><div class="content">Perhaps at some point! Right now, we haven&#x27;t been seeing most demand on the language side of things as multi-modal image really hasn&#x27;t popped off yet</div><br/></div></div></div></div><div id="40712467" class="c"><input type="checkbox" id="c-40712467" checked=""/><div class="controls bullet"><span class="by">jacobglowbom</span><span>|</span><a href="#40711050">prev</a><span>|</span><a href="#40714113">next</a><span>|</span><label class="collapse" for="c-40712467">[-]</label><label class="expand" for="c-40712467">[1 more]</label></div><br/><div class="children"><div class="content">Nice. Does it add Vision costs too?</div><br/></div></div><div id="40714113" class="c"><input type="checkbox" id="c-40714113" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#40712467">prev</a><span>|</span><label class="collapse" for="c-40714113">[-]</label><label class="expand" for="c-40714113">[7 more]</label></div><br/><div class="children"><div class="content">It makes me extremely uncomfortable that you have a <i>GPT-3.5&#x2F;4.0 tokenizer, not even GPT4o</i> that you are advertising as a calculator for 400+ LLMs. You should really be ashamed of yourself for doing this. You will cost people significant amounts of money, and AFAICT you don&#x27;t have a grap of what&#x27;s going on beyond the most basic of basics, &quot;tiktoken does tokens and i&#x27;m supposed to use it for GPT&quot;</div><br/><div id="40714433" class="c"><input type="checkbox" id="c-40714433" checked=""/><div class="controls bullet"><span class="by">Areibman</span><span>|</span><a href="#40714113">parent</a><span>|</span><a href="#40714335">next</a><span>|</span><label class="collapse" for="c-40714433">[-]</label><label class="expand" for="c-40714433">[2 more]</label></div><br/><div class="children"><div class="content">This is unnecessarily harsh. Not every model has a publicly available tokenizer, and using a fallback like cl100k is usually a decent enough estimator from my experience.<p>Besides, there&#x27;s a warning message for when you specify a model without a known tokenizer.<p>If you&#x27;re upset with the implementation, you can always raise an issue or fix it yourself</div><br/><div id="40714775" class="c"><input type="checkbox" id="c-40714775" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#40714113">root</a><span>|</span><a href="#40714433">parent</a><span>|</span><a href="#40714335">next</a><span>|</span><label class="collapse" for="c-40714775">[-]</label><label class="expand" for="c-40714775">[1 more]</label></div><br/><div class="children"><div class="content">&gt; This is unnecessarily harsh.<p>Which part? All I can tease out from your comment are &quot;the lies are impossible&quot; (agreed!) and &quot;close enough afaik&quot;. (it&#x27;s not, the closest in the Big 5 has <i>percent error of 32%</i>, see end of comment. ex. GPT4o has a tokenizer with 2x the vocab so you&#x27;d expect ~1&#x2F;2 the tokens)<p>&gt; Not every model has a publicly available tokenizer,<p>Right. Ex. Claude 3s and Geminis. So why are Claude 3s and Geminis listed as supported models?<p>&gt; using a fallback<p>CL100K isn&#x27;t a fallback, <i>its the only tokenizer.</i><p>&gt; like cl100k is usually a decent enough estimator from my experience.<p>I&#x27;m very surprised to hear this, per stats demonstrating minimum error of 32%.<p>&gt; If you&#x27;re upset with the implementation, you can always raise an issue<p>I&#x27;m not &quot;upset with the implementation&quot;, I&#x27;m sharing that the claims about being able to make financial calculations for 400 different LLMs is lying.<p>&gt; or fix it yourself<p>How?<p>As you pointed out, its unfixable for at least <i>some</i> subset of the ones they&#x27;re claiming, ex. Gemini and Claude 3s.<p>Let&#x27;s pretend it was possible.<p>Why?<p>If someone puts out a library making wildly false claims, is th right thing to do to stay quiet and fix the library making false claims until its claims are true?<p>&gt; usually a decent enough estimator<p>No, not for financial things certainly, which is the <i>stated core purpose of the library.</i><p>As promised, data: I picked the simplest example from my unit tests because you won&#x27;t believe the divergence on larger ones.<p>OpenAI (CL100K) - 18 in&#x2F;1 out = 19.<p>Gemini 1.5      - 41 in&#x2F;14 out = 55. (65% error)<p>Claude 3        - 21 in&#x2F;4 out = 25. (24% error)<p>Llama 3         - 23 in&#x2F;5 out = 28. (32% error)<p>Mistral         - 10 in&#x2F;3 out = 13. (46% error)</div><br/></div></div></div></div><div id="40714335" class="c"><input type="checkbox" id="c-40714335" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#40714113">parent</a><span>|</span><a href="#40714433">prev</a><span>|</span><label class="collapse" for="c-40714335">[-]</label><label class="expand" for="c-40714335">[4 more]</label></div><br/><div class="children"><div class="content">You don&#x27;t like a repo, you don&#x27;t use it. Stop shaming people for their open source repos.</div><br/><div id="40714397" class="c"><input type="checkbox" id="c-40714397" checked=""/><div class="controls bullet"><span class="by">oopsallmagic</span><span>|</span><a href="#40714113">root</a><span>|</span><a href="#40714335">parent</a><span>|</span><label class="collapse" for="c-40714397">[-]</label><label class="expand" for="c-40714397">[3 more]</label></div><br/><div class="children"><div class="content">When did the software community get so bad at handling legitimate critique?</div><br/><div id="40714847" class="c"><input type="checkbox" id="c-40714847" checked=""/><div class="controls bullet"><span class="by">fbdab103</span><span>|</span><a href="#40714113">root</a><span>|</span><a href="#40714397">parent</a><span>|</span><label class="collapse" for="c-40714847">[-]</label><label class="expand" for="c-40714847">[2 more]</label></div><br/><div class="children"><div class="content">&quot;You should really be ashamed of yourself for doing this&quot; is an inappropriate response for basically anything but kicking puppies.</div><br/><div id="40714946" class="c"><input type="checkbox" id="c-40714946" checked=""/><div class="controls bullet"><span class="by">anoncareer0212</span><span>|</span><a href="#40714113">root</a><span>|</span><a href="#40714847">parent</a><span>|</span><label class="collapse" for="c-40714946">[-]</label><label class="expand" for="c-40714946">[1 more]</label></div><br/><div class="children"><div class="content">That sounds somewhat specious, lying about what you support in your cost calculation library is a pretty big oof. It&#x27;s hard to rank it versus kicking puppys, but, I don&#x27;t think we have to stack-rank bad things to figure out if it&#x27;s okay to call out unethical behavior.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></body></html>