<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1712653274363" as="style"/><link rel="stylesheet" href="styles.css?v=1712653274363"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://blog.allenai.org/hello-olmo-a-truly-open-llm-43f7e7359222?gi=760105621962">Hello OLMo: A truly open LLM</a> <span class="domain">(<a href="https://blog.allenai.org">blog.allenai.org</a>)</span></div><div class="subtext"><span>tosh</span> | <span>43 comments</span></div><br/><div><div id="39975746" class="c"><input type="checkbox" id="c-39975746" checked=""/><div class="controls bullet"><span class="by">vjeux</span><span>|</span><a href="#39975483">next</a><span>|</span><label class="collapse" for="c-39975746">[-]</label><label class="expand" for="c-39975746">[6 more]</label></div><br/><div class="children"><div class="content">If I read the license correctly, it seems that if you want to use the LLM, you need to tell the authors what you are doing with it.<p>Am I reading this correctly? <a href="https:&#x2F;&#x2F;allenai.org&#x2F;licenses&#x2F;impact-mr" rel="nofollow">https:&#x2F;&#x2F;allenai.org&#x2F;licenses&#x2F;impact-mr</a><p>“Derivative Impact Reports. AI2 seeks to encourage transparency around Derivatives through the use of Derivative Impact Reports, available here. Before releasing a Model Derivative or Data Derivative, You will share with AI2 the intended use(s) of Your Derivative by completing a Derivative Impact Report or otherwise providing AI2 with substantially similar information in writing. You agree that AI2 may publish, post, or make available such information about Your Derivative for review by the general public.<p>You will use good faith efforts to be transparent about the intended use(s) of Your Derivatives by making the information freely available to others who may access or use Your Derivatives.
You acknowledge that Derivative Impact Reports are not intended to penalize any good faith disclosures about Derivatives. Accordingly, if You initiate or participate in any lawsuit or other legal action against a Third Party based on information in such Third Party’s Derivative Impact Report, then this MR Agreement will terminate immediately as of the date such lawsuit or legal action is filed or commenced.”</div><br/><div id="39975809" class="c"><input type="checkbox" id="c-39975809" checked=""/><div class="controls bullet"><span class="by">blackeyeblitzar</span><span>|</span><a href="#39975746">parent</a><span>|</span><a href="#39975818">next</a><span>|</span><label class="collapse" for="c-39975809">[-]</label><label class="expand" for="c-39975809">[1 more]</label></div><br/><div class="children"><div class="content">Interesting. I recall seeing Apache licenses in their official repositories. I wonder how these additional restrictions get pulled in.</div><br/></div></div><div id="39975818" class="c"><input type="checkbox" id="c-39975818" checked=""/><div class="controls bullet"><span class="by">mkl</span><span>|</span><a href="#39975746">parent</a><span>|</span><a href="#39975809">prev</a><span>|</span><a href="#39975859">next</a><span>|</span><label class="collapse" for="c-39975818">[-]</label><label class="expand" for="c-39975818">[1 more]</label></div><br/><div class="children"><div class="content">Does that apply to this model?  On huggingface it says &quot;License: The code and model are released under Apache 2.0.&quot;</div><br/></div></div><div id="39975859" class="c"><input type="checkbox" id="c-39975859" checked=""/><div class="controls bullet"><span class="by">whimsicalism</span><span>|</span><a href="#39975746">parent</a><span>|</span><a href="#39975818">prev</a><span>|</span><a href="#39975483">next</a><span>|</span><label class="collapse" for="c-39975859">[-]</label><label class="expand" for="c-39975859">[3 more]</label></div><br/><div class="children"><div class="content">no, this is apache license-d. yes it is confusing that AI2 has custom licenses but they aren&#x27;t using them here</div><br/><div id="39976122" class="c"><input type="checkbox" id="c-39976122" checked=""/><div class="controls bullet"><span class="by">lolinder</span><span>|</span><a href="#39975746">root</a><span>|</span><a href="#39975859">parent</a><span>|</span><a href="#39975483">next</a><span>|</span><label class="collapse" for="c-39976122">[-]</label><label class="expand" for="c-39976122">[2 more]</label></div><br/><div class="children"><div class="content">It looks like the weights [0] and code [1] are Apache licensed, but the training data [2] is using the license that OP is quoting from.<p>[0] <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;allenai&#x2F;OLMo-7B" rel="nofollow">https:&#x2F;&#x2F;huggingface.co&#x2F;allenai&#x2F;OLMo-7B</a><p>[1] <a href="https:&#x2F;&#x2F;github.com&#x2F;allenai&#x2F;OLMo">https:&#x2F;&#x2F;github.com&#x2F;allenai&#x2F;OLMo</a><p>[2] <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;datasets&#x2F;allenai&#x2F;dolma" rel="nofollow">https:&#x2F;&#x2F;huggingface.co&#x2F;datasets&#x2F;allenai&#x2F;dolma</a></div><br/><div id="39976247" class="c"><input type="checkbox" id="c-39976247" checked=""/><div class="controls bullet"><span class="by">6gvONxR4sf7o</span><span>|</span><a href="#39975746">root</a><span>|</span><a href="#39976122">parent</a><span>|</span><a href="#39975483">next</a><span>|</span><label class="collapse" for="c-39976247">[-]</label><label class="expand" for="c-39976247">[1 more]</label></div><br/><div class="children"><div class="content">Is the license not transitive? Like could your impact report be “i want to remove this part of the license?”</div><br/></div></div></div></div></div></div></div></div><div id="39975483" class="c"><input type="checkbox" id="c-39975483" checked=""/><div class="controls bullet"><span class="by">timsuchanek</span><span>|</span><a href="#39975746">prev</a><span>|</span><a href="#39977248">next</a><span>|</span><label class="collapse" for="c-39975483">[-]</label><label class="expand" for="c-39975483">[2 more]</label></div><br/><div class="children"><div class="content">Great to see e2e openness. One of the only true OSS models out there, vs most of the models releasing the binaries (weights).
Surprised that they didn’t mention Mistral 7b in the comparisons.</div><br/><div id="39975510" class="c"><input type="checkbox" id="c-39975510" checked=""/><div class="controls bullet"><span class="by">sanxiyn</span><span>|</span><a href="#39975483">parent</a><span>|</span><a href="#39977248">next</a><span>|</span><label class="collapse" for="c-39975510">[-]</label><label class="expand" for="c-39975510">[1 more]</label></div><br/><div class="children"><div class="content">Falcon also released open dataset.</div><br/></div></div></div></div><div id="39977248" class="c"><input type="checkbox" id="c-39977248" checked=""/><div class="controls bullet"><span class="by">ein0p</span><span>|</span><a href="#39975483">prev</a><span>|</span><a href="#39975096">next</a><span>|</span><label class="collapse" for="c-39977248">[-]</label><label class="expand" for="c-39977248">[1 more]</label></div><br/><div class="children"><div class="content">Seems to be surprisingly fast at smaller sizes, too.</div><br/></div></div><div id="39975096" class="c"><input type="checkbox" id="c-39975096" checked=""/><div class="controls bullet"><span class="by">Havoc</span><span>|</span><a href="#39977248">prev</a><span>|</span><a href="#39976184">next</a><span>|</span><label class="collapse" for="c-39975096">[-]</label><label class="expand" for="c-39975096">[9 more]</label></div><br/><div class="children"><div class="content">Notably “The Pile” doesn’t seem to be part of the training data. So this might be more sound legally than many other “open” LLMs</div><br/><div id="39975118" class="c"><input type="checkbox" id="c-39975118" checked=""/><div class="controls bullet"><span class="by">sgu999</span><span>|</span><a href="#39975096">parent</a><span>|</span><a href="#39976184">next</a><span>|</span><label class="collapse" for="c-39975118">[-]</label><label class="expand" for="c-39975118">[8 more]</label></div><br/><div class="children"><div class="content">For those also wondering: <a href="https:&#x2F;&#x2F;pile.eleuther.ai" rel="nofollow">https:&#x2F;&#x2F;pile.eleuther.ai</a><p>&gt; The Pile is a 825 GiB diverse, open source language modelling data set that consists of 22 smaller, high-quality datasets combined together.<p>By what&#x27;s the legal complication with it?</div><br/><div id="39975178" class="c"><input type="checkbox" id="c-39975178" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#39975096">root</a><span>|</span><a href="#39975118">parent</a><span>|</span><a href="#39975749">next</a><span>|</span><label class="collapse" for="c-39975178">[-]</label><label class="expand" for="c-39975178">[5 more]</label></div><br/><div class="children"><div class="content">It is absolutely absolutely packed with unlicensed, copyrighted data.<p>Books3 is the most notable example - nearly 200,000 pirated ebooks - but a lot of the rest of it is (unlicensed) scraped web data.<p>The legal questions over whether this is a problem are currently still unresolved. Many people are also bothered by the ethical implications, which is a separate issue from the legal questions.</div><br/><div id="39975885" class="c"><input type="checkbox" id="c-39975885" checked=""/><div class="controls bullet"><span class="by">23B1</span><span>|</span><a href="#39975096">root</a><span>|</span><a href="#39975178">parent</a><span>|</span><a href="#39975360">next</a><span>|</span><label class="collapse" for="c-39975885">[-]</label><label class="expand" for="c-39975885">[3 more]</label></div><br/><div class="children"><div class="content">Ironic that even our everyday governance has little &#x27;Alignment&#x27; between ethics and law.</div><br/><div id="39976551" class="c"><input type="checkbox" id="c-39976551" checked=""/><div class="controls bullet"><span class="by">jacobn</span><span>|</span><a href="#39975096">root</a><span>|</span><a href="#39975885">parent</a><span>|</span><a href="#39976748">next</a><span>|</span><label class="collapse" for="c-39976551">[-]</label><label class="expand" for="c-39976551">[1 more]</label></div><br/><div class="children"><div class="content">Ethics are a lot more nuanced and change a lot faster than laws.<p>Heck, a large fraction of ethics seem to be so fickle that they’re subject to potential revision by every generation.<p>In fact, I’d argue that those revisions are a significant portion of how one generation distinguishes itself from their parents.<p>Yet strangely every generation feels like they have arrived at a set of “universal laws” in their ethics.</div><br/></div></div><div id="39976748" class="c"><input type="checkbox" id="c-39976748" checked=""/><div class="controls bullet"><span class="by">KarlKemp</span><span>|</span><a href="#39975096">root</a><span>|</span><a href="#39975885">parent</a><span>|</span><a href="#39976551">prev</a><span>|</span><a href="#39975360">next</a><span>|</span><label class="collapse" for="c-39976748">[-]</label><label class="expand" for="c-39976748">[1 more]</label></div><br/><div class="children"><div class="content">In this case, both ethics and the law are murky.<p>Pretty excellent alignment, for once?</div><br/></div></div></div></div></div></div><div id="39975749" class="c"><input type="checkbox" id="c-39975749" checked=""/><div class="controls bullet"><span class="by">codazoda</span><span>|</span><a href="#39975096">root</a><span>|</span><a href="#39975118">parent</a><span>|</span><a href="#39975178">prev</a><span>|</span><a href="#39975133">next</a><span>|</span><label class="collapse" for="c-39975749">[-]</label><label class="expand" for="c-39975749">[1 more]</label></div><br/><div class="children"><div class="content">I took a quick peak at this last time it was mentioned and it had dozens of my own repos of unlicensed source code in it. All of that was published on GitHub and made public, but much of it has no license specified.</div><br/></div></div><div id="39975133" class="c"><input type="checkbox" id="c-39975133" checked=""/><div class="controls bullet"><span class="by">blackeyeblitzar</span><span>|</span><a href="#39975096">root</a><span>|</span><a href="#39975118">parent</a><span>|</span><a href="#39975749">prev</a><span>|</span><a href="#39976184">next</a><span>|</span><label class="collapse" for="c-39975133">[-]</label><label class="expand" for="c-39975133">[1 more]</label></div><br/><div class="children"><div class="content">It received DMCA takedowns: <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;The_Pile_(dataset)" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;The_Pile_(dataset)</a><p>&gt; The Books3 component of the dataset contains copyrighted material compiled from Bibliotik, a pirate website. In July 2023, the Rights Alliance took copies of The Pile down through DMCA notices. Users responded by creating copies of The Pile with the offending content removed.</div><br/></div></div></div></div></div></div><div id="39976184" class="c"><input type="checkbox" id="c-39976184" checked=""/><div class="controls bullet"><span class="by">kikoreis</span><span>|</span><a href="#39975096">prev</a><span>|</span><a href="#39975206">next</a><span>|</span><label class="collapse" for="c-39976184">[-]</label><label class="expand" for="c-39976184">[1 more]</label></div><br/><div class="children"><div class="content">What does the risk classification applied to the dataset actually mean? The licensing page [1] AI2 provides for their datasets is really nice but it doesn&#x27;t really explain [2] what risk means in the context.<p>Does it mean &quot;risk that the items contained in this set are licensed in a manner incompatible with its use in a training dataset&quot;?<p>[1] <a href="https:&#x2F;&#x2F;allenai.org&#x2F;impact-license" rel="nofollow">https:&#x2F;&#x2F;allenai.org&#x2F;impact-license</a><p>[2] &quot;the AI2 ImpACT Licenses are artifact-agnostic and are instead structured according to the risk level we’ve assigned a given artifact&quot;</div><br/></div></div><div id="39975206" class="c"><input type="checkbox" id="c-39975206" checked=""/><div class="controls bullet"><span class="by">mysteria</span><span>|</span><a href="#39976184">prev</a><span>|</span><a href="#39976744">next</a><span>|</span><label class="collapse" for="c-39975206">[-]</label><label class="expand" for="c-39975206">[2 more]</label></div><br/><div class="children"><div class="content">Is this one of the first LLMs of note that was successfully trained on AMD GPUs? I wonder how seamless the process was and if they faced any issues there.</div><br/><div id="39975450" class="c"><input type="checkbox" id="c-39975450" checked=""/><div class="controls bullet"><span class="by">sanxiyn</span><span>|</span><a href="#39975206">parent</a><span>|</span><a href="#39976744">next</a><span>|</span><label class="collapse" for="c-39975450">[-]</label><label class="expand" for="c-39975450">[1 more]</label></div><br/><div class="children"><div class="content">Databricks (who also participated in OLMo, it&#x27;s probably the same codebase) trained on AMD before, see 2023 post <a href="https:&#x2F;&#x2F;www.databricks.com&#x2F;blog&#x2F;amd-mi250" rel="nofollow">https:&#x2F;&#x2F;www.databricks.com&#x2F;blog&#x2F;amd-mi250</a>. It was probably seamless, as any issues were fixed by Databricks in 2023.</div><br/></div></div></div></div><div id="39976744" class="c"><input type="checkbox" id="c-39976744" checked=""/><div class="controls bullet"><span class="by">pksebben</span><span>|</span><a href="#39975206">prev</a><span>|</span><a href="#39975282">next</a><span>|</span><label class="collapse" for="c-39976744">[-]</label><label class="expand" for="c-39976744">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s odd.  Running inference on this (and other models in its class) and I keep running into a &quot;repeating token&quot; situation with moderate-to-long context windows.<p>It feels almost as if, during inference, the model hits some format of local minimum that it careens around, and while temperature <i>seems</i> to affect this - it doesn&#x27;t really <i>fix</i> it.<p>at temp 0.2:<p>&gt; [{&#x27;generated_text&#x27;: &#x27;What follows is a transcript of a talk between a mysterious man and an agent of a bureau dedicated to investigating things which is typically referred to by some assortment of letters in the alphabet.  The identity, origins, and motivations of the man were not known then and remain so.  This transcript is not meant to scare, but provided simply to enlighten the concerned citizen of all the various and sundry things that may or may not go bump in the night.  AGENT: Please state your name for the record.  MYSTERIOUS STRANGER:  I am the man.  AGENT:  Thank you.  I am an agent of the Bureau of Investigation.  I am here to investigate the following:  1.  The following:  2.  The following:  3.  The following:  4.  The following:  5.  The following:  6.  The following:  7.  The following:  8.  The following:  9.  The following:  10.  The following:  11.  The following:  12.  The following:  13.  The following:  14.  The following:  15.  The following:  16.  The following:  17.  The following:  18.  The following:  19.  The following:  20.  The following:  21.  The following:  22.  The following:  23.  The following:  24.  The following&#x27;}]<p>...and at temp 0.4:<p>&gt; [{&#x27;generated_text&#x27;: &#x27;What follows is a transcript of a talk between a mysterious man and an agent of a bureau dedicated to investigating things which is typically referred to by some assortment of letters in the alphabet.  The identity, origins, and motivations of the man were not known then and remain so.  This transcript is not meant to scare, but provided simply to enlighten the concerned citizen of all the various and sundry things that may or may not go bump in the night.  AGENT: Please state your name for the record.  MYSTERIOUS STRANGER:  My name is not important.  AGENT:  My name is Agent Cyanide.  MYSTERIOUS STRANGER:  Agent Cyanide.  AGENT:  I am an agent of the Bureau of Investigations.  MYSTERIOUS STRANGER:  The Bureau of Investigations.  AGENT:  The Bureau of Investigations.  MYSTERIOUS STRANGER:  The Bureau of Investigations.  AGENT:  The Bureau of Investigations.  MYSTERIOUS STRANGER:  The Bureau of Investigations.  AGENT:  The Bureau of Investigations.  MYSTERIOUS STRANGER:  The Bureau of Investigations.  AGENT:  The Bureau of Investigations.  MYSTERIOUS STRANGER:  The Bureau of Investigations.  AGENT:  The Bureau of Investigations.  MYSTERIOUS STRANGER:  The Bureau of Investigations&#x27;}]</div><br/><div id="39976780" class="c"><input type="checkbox" id="c-39976780" checked=""/><div class="controls bullet"><span class="by">pksebben</span><span>|</span><a href="#39976744">parent</a><span>|</span><a href="#39975282">next</a><span>|</span><label class="collapse" for="c-39976780">[-]</label><label class="expand" for="c-39976780">[1 more]</label></div><br/><div class="children"><div class="content">... this can get a little goofy even with do_sample=False and no temp:<p>| [{&#x27;generated_text&#x27;: &quot;DAUGHTER: tell me a story FATHER: but it&#x27;s late  DAUGHTER: please? FATHER: okay, once upon a time  there was a little girl who lived in a little house  with her mother and father and her brother and sister  and her dog and her cat and her hamster and her fish  and her bird and her rabbit and her horse and her cow  and her sheep and her goat and her pig and her chicken  and her duck and her turkey and her goose and her llama  and her alpaca and her camel and her zebra and her giraffe  and her elephant and her hippopotamus and her rhinoceros  and her kangaroo and her koala and her panda and her bear  and her wolf and her fox and her cat and her dog and her bird  and her fish and her hamster and her cat and her dog and her bird  and her fish and her hamster and her cat and her dog and her bird  and her fish and her hamster and her cat and her dog and her bird  and her fish and her hamster and&quot;}]</div><br/></div></div></div></div><div id="39975282" class="c"><input type="checkbox" id="c-39975282" checked=""/><div class="controls bullet"><span class="by">lostmsu</span><span>|</span><a href="#39976744">prev</a><span>|</span><a href="#39975003">next</a><span>|</span><label class="collapse" for="c-39975282">[-]</label><label class="expand" for="c-39975282">[2 more]</label></div><br/><div class="children"><div class="content">Too bad they did not put any comparison tables into the blog post.</div><br/><div id="39975329" class="c"><input type="checkbox" id="c-39975329" checked=""/><div class="controls bullet"><span class="by">mysteria</span><span>|</span><a href="#39975282">parent</a><span>|</span><a href="#39975003">next</a><span>|</span><label class="collapse" for="c-39975329">[-]</label><label class="expand" for="c-39975329">[1 more]</label></div><br/><div class="children"><div class="content">They&#x27;re on Hugging Face. Interestingly enough they don&#x27;t compare it against Mistral 7B.<p><a href="https:&#x2F;&#x2F;huggingface.co&#x2F;allenai&#x2F;OLMo-7B" rel="nofollow">https:&#x2F;&#x2F;huggingface.co&#x2F;allenai&#x2F;OLMo-7B</a></div><br/></div></div></div></div><div id="39975003" class="c"><input type="checkbox" id="c-39975003" checked=""/><div class="controls bullet"><span class="by">blackeyeblitzar</span><span>|</span><a href="#39975282">prev</a><span>|</span><a href="#39975436">next</a><span>|</span><label class="collapse" for="c-39975003">[-]</label><label class="expand" for="c-39975003">[12 more]</label></div><br/><div class="children"><div class="content">This is the only LLM that is exciting to me. Clearly, LLMs are powerful tools that may end up replacing search and even go much further than simple searches by performing the research for you and producing final answers. Closed models like those from Open AI (ironically) or Anthropic cannot be audited. When most users will end up blindly hitting Microsoft’s Copilot button, which they are forcing OEMs to adopt, who’s to say how the information a user gets is being curated or manipulated by OpenAI or Microsoft or whoever?<p>We’ve already seen real world examples of severe bias injected into LLMs. For example, Google’s Gemini had secret meta prompts that biased it towards certain types of answers and also caused it to produce hallucinated images that were funny but also dystopian (<a href="https:&#x2F;&#x2F;arstechnica.com&#x2F;information-technology&#x2F;2024&#x2F;02&#x2F;googles-hidden-ai-diversity-prompts-lead-to-outcry-over-historically-inaccurate-images&#x2F;" rel="nofollow">https:&#x2F;&#x2F;arstechnica.com&#x2F;information-technology&#x2F;2024&#x2F;02&#x2F;googl...</a>). I don’t think we can just let closed AI systems take over society when they can easily be manipulated by the model owners without transparency.<p>What I like about AI2’s approach with OLMo is that they are <i>actually open</i>, not just trading on the marketing benefits of the word “open”. Most “open” models are just open <i>weights</i> not open <i>source</i>. That’s like sharing an executable and not the source code. In my view, being open means that others have to be able to reproduce the final product (the model) if they wanted to and had the means (in terms of training hardware). It also means that they should be able to use whatever is provided freely for any purpose, rather than being subject to proprietary licensing. AI2 shares the training source code, training data, evaluation suite, and the model weights that they’ve produced by running the training process. It all uses the Apache license. And it’s also interesting that they used AMD hardware to train this LLM rather than Nvidia&#x2F;CUDA.<p>Open weight models like Llama keep repeatedly catching up to the best closed models from OpenAI or Anthropic or others. My hope is that truly open models like OLMa keep developing quickly enough to also keep up. Lastly, I hope that regulation does not block open source private development of AI systems. These systems will be the vehicle for speech for much of society in the future, so blocking private AI systems is a lot like restricting speech. But leaving that aside, open development will also drive innovation and reducing competitive pressure will hurt innovation.</div><br/><div id="39975272" class="c"><input type="checkbox" id="c-39975272" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#39975003">parent</a><span>|</span><a href="#39975087">next</a><span>|</span><label class="collapse" for="c-39975272">[-]</label><label class="expand" for="c-39975272">[2 more]</label></div><br/><div class="children"><div class="content">Pet peeve: Google&#x27;s Gemini LLM model was not to blame for the image generation weirdness.<p>That would be like blaming DALL-E weirdness on GPT-4.<p>Unfortunately, Google marketing decided to slap the &quot;Gemini&quot; brand on both the end-user interface used to interact with the model AND the actual model itself, hence people constantly calling out Gemini-the-model for weird decisions made as part of Gemini-the-user-interface.</div><br/><div id="39975995" class="c"><input type="checkbox" id="c-39975995" checked=""/><div class="controls bullet"><span class="by">yk</span><span>|</span><a href="#39975003">root</a><span>|</span><a href="#39975272">parent</a><span>|</span><a href="#39975087">next</a><span>|</span><label class="collapse" for="c-39975995">[-]</label><label class="expand" for="c-39975995">[1 more]</label></div><br/><div class="children"><div class="content">Did anybody manage to get the entire prompt out of gemini, or what are you basing your claim on?</div><br/></div></div></div></div><div id="39975087" class="c"><input type="checkbox" id="c-39975087" checked=""/><div class="controls bullet"><span class="by">blackeyeblitzar</span><span>|</span><a href="#39975003">parent</a><span>|</span><a href="#39975272">prev</a><span>|</span><a href="#39976903">next</a><span>|</span><label class="collapse" for="c-39975087">[-]</label><label class="expand" for="c-39975087">[3 more]</label></div><br/><div class="children"><div class="content">One thing I wanted to add and call attention to is the importance of licensing in open models. This is often overlooked when we blindly accept the vague branding of models as “open”, but I am noticing that many open weight models are actually using encumbered proprietary licenses rather than standard open source licenses that are OSI approved (<a href="https:&#x2F;&#x2F;opensource.org&#x2F;licenses" rel="nofollow">https:&#x2F;&#x2F;opensource.org&#x2F;licenses</a>). As an example, Databricks’s DBRX model has a proprietary license that forces adherence to their highly restrictive Acceptable Use Policy <i>by referencing a live website hosting their AUP</i> (<a href="https:&#x2F;&#x2F;github.com&#x2F;databricks&#x2F;dbrx&#x2F;blob&#x2F;main&#x2F;LICENSE">https:&#x2F;&#x2F;github.com&#x2F;databricks&#x2F;dbrx&#x2F;blob&#x2F;main&#x2F;LICENSE</a>), which means as they change their AUP, you may be further restricted in the future. Meta’s Llama is similar (<a href="https:&#x2F;&#x2F;github.com&#x2F;meta-llama&#x2F;llama&#x2F;blob&#x2F;main&#x2F;LICENSE">https:&#x2F;&#x2F;github.com&#x2F;meta-llama&#x2F;llama&#x2F;blob&#x2F;main&#x2F;LICENSE</a> ). I’m not sure who can depend on these models given this flaw.</div><br/><div id="39975599" class="c"><input type="checkbox" id="c-39975599" checked=""/><div class="controls bullet"><span class="by">idle_zealot</span><span>|</span><a href="#39975003">root</a><span>|</span><a href="#39975087">parent</a><span>|</span><a href="#39976903">next</a><span>|</span><label class="collapse" for="c-39975599">[-]</label><label class="expand" for="c-39975599">[2 more]</label></div><br/><div class="children"><div class="content">Do we even know if these licenses are binding? AFAIK we have no ruling on whether model weights are even eligible for copyright. They&#x27;re machine-produced derivatives of other work, so it&#x27;s not a guarantee that copyright protects them.</div><br/><div id="39975872" class="c"><input type="checkbox" id="c-39975872" checked=""/><div class="controls bullet"><span class="by">blackeyeblitzar</span><span>|</span><a href="#39975003">root</a><span>|</span><a href="#39975599">parent</a><span>|</span><a href="#39976903">next</a><span>|</span><label class="collapse" for="c-39975872">[-]</label><label class="expand" for="c-39975872">[1 more]</label></div><br/><div class="children"><div class="content">That’s a great point and I hope more people speak up to treat models as just numerical derivative works so they aren’t automatically granted these protections. It’s better if society meaningfully debates this and chooses the right approach.</div><br/></div></div></div></div></div></div><div id="39976903" class="c"><input type="checkbox" id="c-39976903" checked=""/><div class="controls bullet"><span class="by">theshackleford</span><span>|</span><a href="#39975003">parent</a><span>|</span><a href="#39975087">prev</a><span>|</span><a href="#39975212">next</a><span>|</span><label class="collapse" for="c-39976903">[-]</label><label class="expand" for="c-39976903">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Open weight models like Llama keep repeatedly catching up to the best closed models from OpenAI or Anthropic or others.<p>Since when? I’ve had the complete opposite experience.</div><br/></div></div><div id="39975212" class="c"><input type="checkbox" id="c-39975212" checked=""/><div class="controls bullet"><span class="by">gremlinunderway</span><span>|</span><a href="#39975003">parent</a><span>|</span><a href="#39976903">prev</a><span>|</span><a href="#39975219">next</a><span>|</span><label class="collapse" for="c-39975212">[-]</label><label class="expand" for="c-39975212">[3 more]</label></div><br/><div class="children"><div class="content">&gt; For example, Google’s Gemini had secret meta prompts that biased it towards certain types of answers and also caused it to produce hallucinated images that were funny but also dystopian (<a href="https:&#x2F;&#x2F;arstechnica.com&#x2F;information-technology&#x2F;2024&#x2F;02&#x2F;googl" rel="nofollow">https:&#x2F;&#x2F;arstechnica.com&#x2F;information-technology&#x2F;2024&#x2F;02&#x2F;googl</a>...).<p>Such a bizarre take to call this &quot;dystopian&quot;.<p>The model happened to create some out-there pictures. I mean, it&#x27;s no more outlandish then giant dragons and snakes and such being created yet the thought of a person of color being something historically inaccurate is this massive outcry against revisionism? Who cares?<p>Besides, the article identifies the probable goal which was to eliminate very known biases in existing models (i.e. when generating &quot;angry person&quot; you mainly got black people). Clearly this one wasnt tuned well for that goal, but the objective is not only noble but absolutely should be required for anyone producing LLM models.</div><br/><div id="39975320" class="c"><input type="checkbox" id="c-39975320" checked=""/><div class="controls bullet"><span class="by">blackeyeblitzar</span><span>|</span><a href="#39975003">root</a><span>|</span><a href="#39975212">parent</a><span>|</span><a href="#39977357">next</a><span>|</span><label class="collapse" for="c-39975320">[-]</label><label class="expand" for="c-39975320">[1 more]</label></div><br/><div class="children"><div class="content">If I may explain: the dystopian part to me is the lack of transparency around training code, training data sources, tuning, meta prompting, and so forth. In Google’s case, they’re a large corporation that controls how much of society accesses information. If they’re secretly curating what that information is, rather than presenting it as neutrally as they can, it does feel dystopian to me. I’d like transparency as a consumer of information, so I know to the extent possible, what the sources of information were or how I am being manipulated by choices the humans building these systems made.<p>I appreciate the issue you’re drawing attention to in the example you shared about images of an angry person. I think I agree that focused tuning for situations like that might be noble and I would be okay with a model correcting for that specific example you shared. But I also struggle with how to <i>clearly</i> draw that line where such tuning may go too far, which is why I favor less manual biasing. But I disagree that such tuning should be <i>required</i>, if you meant required <i>by the law</i>. Like with speech or art in general, I think anyone should be able to produce software systems that generate controversial or offensive speech or art. Individual consumers can choose what they want to interact with, and reject LLMs that don’t meet their personal standards.</div><br/></div></div><div id="39977357" class="c"><input type="checkbox" id="c-39977357" checked=""/><div class="controls bullet"><span class="by">lynx23</span><span>|</span><a href="#39975003">root</a><span>|</span><a href="#39975212">parent</a><span>|</span><a href="#39975320">prev</a><span>|</span><a href="#39975219">next</a><span>|</span><label class="collapse" for="c-39977357">[-]</label><label class="expand" for="c-39977357">[1 more]</label></div><br/><div class="children"><div class="content">Right, &quot;who cares&quot; about the truth in our dystopian world?  1984 is apparently too long ago for people to remember the ministry of truth...</div><br/></div></div></div></div></div></div><div id="39975436" class="c"><input type="checkbox" id="c-39975436" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#39975003">prev</a><span>|</span><a href="#39975089">next</a><span>|</span><label class="collapse" for="c-39975436">[-]</label><label class="expand" for="c-39975436">[4 more]</label></div><br/><div class="children"><div class="content">This is 2 months old.</div><br/><div id="39975737" class="c"><input type="checkbox" id="c-39975737" checked=""/><div class="controls bullet"><span class="by">btbuildem</span><span>|</span><a href="#39975436">parent</a><span>|</span><a href="#39975572">prev</a><span>|</span><a href="#39975913">next</a><span>|</span><label class="collapse" for="c-39975737">[-]</label><label class="expand" for="c-39975737">[1 more]</label></div><br/><div class="children"><div class="content">And yet it&#x27;s topical and relevant.</div><br/></div></div></div></div><div id="39975089" class="c"><input type="checkbox" id="c-39975089" checked=""/><div class="controls bullet"><span class="by">timmg</span><span>|</span><a href="#39975436">prev</a><span>|</span><label class="collapse" for="c-39975089">[-]</label><label class="expand" for="c-39975089">[1 more]</label></div><br/><div class="children"><div class="content">Has their site been hugged-to-death or is it my hotel wifi?</div><br/></div></div></div></div></div></div></div></body></html>