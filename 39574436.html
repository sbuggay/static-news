<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1709456456555" as="style"/><link rel="stylesheet" href="styles.css?v=1709456456555"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.di.ens.fr/%7Efbach/ltfp_book.pdf">Learning Theory from First Principles [pdf]</a> <span class="domain">(<a href="https://www.di.ens.fr">www.di.ens.fr</a>)</span></div><div class="subtext"><span>magnio</span> | <span>43 comments</span></div><br/><div><div id="39575781" class="c"><input type="checkbox" id="c-39575781" checked=""/><div class="controls bullet"><span class="by">sampo</span><span>|</span><a href="#39577915">next</a><span>|</span><label class="collapse" for="c-39575781">[-]</label><label class="expand" for="c-39575781">[10 more]</label></div><br/><div class="children"><div class="content">&gt; 2.5 No free lunch theorem
&gt;
&gt; Although it may be tempting to deﬁne the optimal learning algorithm that works optimally for all distributions, this is impossible. In other words, learning is only possible with assumptions.<p>A mention of no free lunch theorem should come with a disclaimer that the theorem is not relevant in practice. An assumption that your data originates from the real world, is sufficient that the no free lunch theorem is not a hindrance.<p>This book doesn&#x27;t discuss this at all. Maybe mention that &quot;all distributions&quot; means a generalization to higher dimensional spaces of discontinuous functions (including the tiny subset of continuous functions) of something similar to all possible bit sequences generated by tossing a coin. So basically if you data is generated from an even random distribution of &quot;all possibilities&quot;, you cannot learn to predict the outcome of the next coin tosses, or similar.</div><br/><div id="39579511" class="c"><input type="checkbox" id="c-39579511" checked=""/><div class="controls bullet"><span class="by">magnio</span><span>|</span><a href="#39575781">parent</a><span>|</span><a href="#39575819">next</a><span>|</span><label class="collapse" for="c-39579511">[-]</label><label class="expand" for="c-39579511">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t see how your disclaimer applies. My interpretation of no free lunch theorems is that no single algorithm works well for all classes of problems, not that some problems are unlearnable. The example in its proof might be contrived, but in actuality, additional assumptions can and do lead to different algorithms being picked, no?</div><br/></div></div><div id="39575819" class="c"><input type="checkbox" id="c-39575819" checked=""/><div class="controls bullet"><span class="by">nextos</span><span>|</span><a href="#39575781">parent</a><span>|</span><a href="#39579511">prev</a><span>|</span><a href="#39577671">next</a><span>|</span><label class="collapse" for="c-39575819">[-]</label><label class="expand" for="c-39575819">[7 more]</label></div><br/><div class="children"><div class="content">Yes, most free lunch theorems and results of this kind, which make overly general assumptions, tend to be too pessimistic.<p>For example, many people naively think that static program analysis is unfeasible due to the halting problem, Rice&#x27;s theorem, etc.</div><br/><div id="39576651" class="c"><input type="checkbox" id="c-39576651" checked=""/><div class="controls bullet"><span class="by">boberoni</span><span>|</span><a href="#39575781">root</a><span>|</span><a href="#39575819">parent</a><span>|</span><a href="#39577671">next</a><span>|</span><label class="collapse" for="c-39576651">[-]</label><label class="expand" for="c-39576651">[6 more]</label></div><br/><div class="children"><div class="content">Just curious, how does program analysis on real-world programs exactly circumvent the problems of the halting problem or Rice’s theorem? In the real world, do we only ever have statically analyze a special subset of all programs?</div><br/><div id="39577406" class="c"><input type="checkbox" id="c-39577406" checked=""/><div class="controls bullet"><span class="by">nextos</span><span>|</span><a href="#39575781">root</a><span>|</span><a href="#39576651">parent</a><span>|</span><a href="#39576839">next</a><span>|</span><label class="collapse" for="c-39577406">[-]</label><label class="expand" for="c-39577406">[1 more]</label></div><br/><div class="children"><div class="content">The main strategy is to build sound but imperfect analyzers, i.e. analyzers that never raise false negatives but that may raise some false positives. See §1.6 in [1], a simplified version of the classic <i>Principles of Program Analysis</i>. Good analyzers are practical, rarely raising false positives for well-written programs. The Astreé analyzer reported zero false positives for the 1 MLOC fly-by-wire A380 code.<p>Another complementary strategy is to avoid Turing-complete constructs as much as possible, i.e. use DSLs with restricted semantics. This way, advanced semantic properties such as termination are provable.<p>[1] Program Analysis, An Appetizer. <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2012.10086.pdf" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2012.10086.pdf</a></div><br/></div></div><div id="39576839" class="c"><input type="checkbox" id="c-39576839" checked=""/><div class="controls bullet"><span class="by">Legend2440</span><span>|</span><a href="#39575781">root</a><span>|</span><a href="#39576651">parent</a><span>|</span><a href="#39577406">prev</a><span>|</span><a href="#39576749">next</a><span>|</span><label class="collapse" for="c-39576839">[-]</label><label class="expand" for="c-39576839">[1 more]</label></div><br/><div class="children"><div class="content">Halting problem only applies in the general case. I can trivially tell you that while(1) will never halt.<p>There are many examples of programs whose halting behavior is not known (collatz conjecture for example) but many others where program analysis works just fine.</div><br/></div></div><div id="39576749" class="c"><input type="checkbox" id="c-39576749" checked=""/><div class="controls bullet"><span class="by">gryn</span><span>|</span><a href="#39575781">root</a><span>|</span><a href="#39576651">parent</a><span>|</span><a href="#39576839">prev</a><span>|</span><a href="#39577671">next</a><span>|</span><label class="collapse" for="c-39576749">[-]</label><label class="expand" for="c-39576749">[3 more]</label></div><br/><div class="children"><div class="content">In the real World Turing machines don&#x27;t exist only finite state Machines. (No infinite tape or infinite time)<p>I guess something related to this one way or another.</div><br/><div id="39577065" class="c"><input type="checkbox" id="c-39577065" checked=""/><div class="controls bullet"><span class="by">pdonis</span><span>|</span><a href="#39575781">root</a><span>|</span><a href="#39576749">parent</a><span>|</span><a href="#39577671">next</a><span>|</span><label class="collapse" for="c-39577065">[-]</label><label class="expand" for="c-39577065">[2 more]</label></div><br/><div class="children"><div class="content">You don&#x27;t need an infinite tape to make a finite state machine that never halts. As Legend2440 pointed out upthread, while(1) is a simple finite state machine that never halts.</div><br/><div id="39577787" class="c"><input type="checkbox" id="c-39577787" checked=""/><div class="controls bullet"><span class="by">grekiki</span><span>|</span><a href="#39575781">root</a><span>|</span><a href="#39577065">parent</a><span>|</span><a href="#39577671">next</a><span>|</span><label class="collapse" for="c-39577787">[-]</label><label class="expand" for="c-39577787">[1 more]</label></div><br/><div class="children"><div class="content">Sure but halting problem is solvable for finite state machines.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="39577915" class="c"><input type="checkbox" id="c-39577915" checked=""/><div class="controls bullet"><span class="by">jabowery</span><span>|</span><a href="#39575781">prev</a><span>|</span><a href="#39576086">next</a><span>|</span><label class="collapse" for="c-39577915">[-]</label><label class="expand" for="c-39577915">[1 more]</label></div><br/><div class="children"><div class="content">Learning theory is the attempt to formalize natural science up to decision.  Natural science&#x27;s unstated assumption is that a sufficiently sophisticated algorithmic world model can be used to predict future observations from past observations.  Since this is the same assumption as Solomonoff&#x27;s assumption in his proof of inductive inference, you have to start there:  with Turing complete coding rather than Rissanen&#x27;s so-called &quot;universal&quot; coding.<p>It&#x27;s ok* to depart from that starting point in creating subtheories but if you don&#x27;t start there you&#x27;ll end up with garbage like the last 50 years of confusion over what &quot;The Minimum Description Length Principle&quot; really means.<p>*It is, however, _not_ &quot;ok&quot; if what you are trying to do is come up with causal models.  You can&#x27;t get away from Turing complete codes if you&#x27;re trying to model dynamical systems even though dynamical systems can be thought of as finite state machines with very large numbers of states. In order to make optimally compact codes you need Turing complete semantics that execute on a finite state machine that just so happens to have a really large but finite number of flipflops or other directed cyclic graph of universal (eg NOR, NAND, etc.) gates.</div><br/></div></div><div id="39576086" class="c"><input type="checkbox" id="c-39576086" checked=""/><div class="controls bullet"><span class="by">throwaway81523</span><span>|</span><a href="#39577915">prev</a><span>|</span><a href="#39575278">next</a><span>|</span><label class="collapse" for="c-39576086">[-]</label><label class="expand" for="c-39576086">[7 more]</label></div><br/><div class="children"><div class="content">This is pretty hard to read.  For example, on the first page of chapter 1, it talks about &quot;minimization of quadratic forms&quot; and shows what looks like the formula for linear least squares.  Is that right?  It doesn&#x27;t say anything about this.  Some more exposition would help.<p>I do like that there are lots of exercises.</div><br/><div id="39576275" class="c"><input type="checkbox" id="c-39576275" checked=""/><div class="controls bullet"><span class="by">guimplen</span><span>|</span><a href="#39576086">parent</a><span>|</span><a href="#39576420">next</a><span>|</span><label class="collapse" for="c-39576275">[-]</label><label class="expand" for="c-39576275">[2 more]</label></div><br/><div class="children"><div class="content">I think the text is geared towards people with some mathematical background who want to understand learning theory. Besides it is clearly stated that this chapter is a review (so its assumed that you learned or will learn these things elsewhere).</div><br/><div id="39576434" class="c"><input type="checkbox" id="c-39576434" checked=""/><div class="controls bullet"><span class="by">throwaway81523</span><span>|</span><a href="#39576086">root</a><span>|</span><a href="#39576275">parent</a><span>|</span><a href="#39576420">next</a><span>|</span><label class="collapse" for="c-39576434">[-]</label><label class="expand" for="c-39576434">[1 more]</label></div><br/><div class="children"><div class="content">Well I have some math background but that section is brisk and slow at the same time, as it were.  Such as how it explains how to find inverses of 2x2 matrices.<p>This is older but is supposed to be good: <a href="https:&#x2F;&#x2F;www.deeplearningbook.org&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.deeplearningbook.org&#x2F;</a></div><br/></div></div></div></div><div id="39576420" class="c"><input type="checkbox" id="c-39576420" checked=""/><div class="controls bullet"><span class="by">nerdponx</span><span>|</span><a href="#39576086">parent</a><span>|</span><a href="#39576275">prev</a><span>|</span><a href="#39577099">next</a><span>|</span><label class="collapse" for="c-39576420">[-]</label><label class="expand" for="c-39576420">[1 more]</label></div><br/><div class="children"><div class="content">The sibling comment is right in that this is clearly not intended for first timers.<p>But your instincts are correct here. When you write out the objective function for ordinary least squares, it turns out to be a quadratic form. The choice of the word &quot;quadratic&quot; here is not a coincidence: it is the generalization of quadratic functions to matrices. That section covers the vector equivalent of minimizing quadratic functions.</div><br/></div></div><div id="39577099" class="c"><input type="checkbox" id="c-39577099" checked=""/><div class="controls bullet"><span class="by">dawnofdusk</span><span>|</span><a href="#39576086">parent</a><span>|</span><a href="#39576420">prev</a><span>|</span><a href="#39576451">next</a><span>|</span><label class="collapse" for="c-39577099">[-]</label><label class="expand" for="c-39577099">[1 more]</label></div><br/><div class="children"><div class="content">First principles doesn&#x27;t mean easy to read unfortunately</div><br/></div></div><div id="39576451" class="c"><input type="checkbox" id="c-39576451" checked=""/><div class="controls bullet"><span class="by">garydevenay</span><span>|</span><a href="#39576086">parent</a><span>|</span><a href="#39577099">prev</a><span>|</span><a href="#39576638">next</a><span>|</span><label class="collapse" for="c-39576451">[-]</label><label class="expand" for="c-39576451">[1 more]</label></div><br/><div class="children"><div class="content">Certainly doesn&#x27;t seem like first principles...</div><br/></div></div><div id="39576638" class="c"><input type="checkbox" id="c-39576638" checked=""/><div class="controls bullet"><span class="by">wenc</span><span>|</span><a href="#39576086">parent</a><span>|</span><a href="#39576451">prev</a><span>|</span><a href="#39575278">next</a><span>|</span><label class="collapse" for="c-39576638">[-]</label><label class="expand" for="c-39576638">[1 more]</label></div><br/><div class="children"><div class="content">Least squares is quadratic.<p>Quadratic means square terms.</div><br/></div></div></div></div><div id="39575278" class="c"><input type="checkbox" id="c-39575278" checked=""/><div class="controls bullet"><span class="by">canjobear</span><span>|</span><a href="#39576086">prev</a><span>|</span><a href="#39578943">next</a><span>|</span><label class="collapse" for="c-39575278">[-]</label><label class="expand" for="c-39575278">[6 more]</label></div><br/><div class="children"><div class="content">Have they figured out what causes double descent yet?</div><br/><div id="39576005" class="c"><input type="checkbox" id="c-39576005" checked=""/><div class="controls bullet"><span class="by">tel</span><span>|</span><a href="#39575278">parent</a><span>|</span><a href="#39575601">next</a><span>|</span><label class="collapse" for="c-39576005">[-]</label><label class="expand" for="c-39576005">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t know if it&#x27;s a generalized result, but the Circuits team at Anthropic has a very compelling thesis: the first phase of descent corresponds to the model memorizing data points, the second phase corresponds to it shifting geometrically toward learning &quot;features&quot;.<p>Here a &quot;feature&quot; might be seen as an abstract, very, very high dimensional vector space. The team is pretty deep in investigating the idea of superposition, where individual neurons encode for multiple concepts. They experiment with a toy model and toy data set where the latent features are represented explicitly and then compressed into a small set of data dimensions. This forces superposition. Then they show how that superposition looks under varying sizes of training data.<p>It&#x27;s obviously a toy model, but it&#x27;s a compelling idea. At least for any model which might suffer from superposition.<p><a href="https:&#x2F;&#x2F;transformer-circuits.pub&#x2F;2023&#x2F;toy-double-descent&#x2F;index.html" rel="nofollow">https:&#x2F;&#x2F;transformer-circuits.pub&#x2F;2023&#x2F;toy-double-descent&#x2F;ind...</a></div><br/></div></div><div id="39575601" class="c"><input type="checkbox" id="c-39575601" checked=""/><div class="controls bullet"><span class="by">arolihas</span><span>|</span><a href="#39575278">parent</a><span>|</span><a href="#39576005">prev</a><span>|</span><a href="#39575947">next</a><span>|</span><label class="collapse" for="c-39575601">[-]</label><label class="expand" for="c-39575601">[1 more]</label></div><br/><div class="children"><div class="content">There was actually a very recent blog post claiming that statistical mechanics can explain double descent <a href="https:&#x2F;&#x2F;calculatedcontent.com&#x2F;2024&#x2F;03&#x2F;01&#x2F;describing-double-descent-with-weightwatcher&#x2F;" rel="nofollow">https:&#x2F;&#x2F;calculatedcontent.com&#x2F;2024&#x2F;03&#x2F;01&#x2F;describing-double-d...</a><p>Some more detail here: <a href="https:&#x2F;&#x2F;calculatedcontent.com&#x2F;2019&#x2F;12&#x2F;03&#x2F;towards-a-new-theory-of-learning-statistical-mechanics-of-deep-neural-networks&#x2F;" rel="nofollow">https:&#x2F;&#x2F;calculatedcontent.com&#x2F;2019&#x2F;12&#x2F;03&#x2F;towards-a-new-theor...</a></div><br/></div></div><div id="39575947" class="c"><input type="checkbox" id="c-39575947" checked=""/><div class="controls bullet"><span class="by">iaseiadit</span><span>|</span><a href="#39575278">parent</a><span>|</span><a href="#39575601">prev</a><span>|</span><a href="#39575386">next</a><span>|</span><label class="collapse" for="c-39575947">[-]</label><label class="expand" for="c-39575947">[1 more]</label></div><br/><div class="children"><div class="content">Not an expert, but this paper explores double descent with simple models. The  interpretation there: when you extend into the overparameterized regime, that permits optimization towards small-norm weights, which generalize well again. Does that explain  DD generally? Does it apply to other models (e.g. DNNs)?<p><a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2303.14151.pdf" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2303.14151.pdf</a></div><br/></div></div><div id="39575386" class="c"><input type="checkbox" id="c-39575386" checked=""/><div class="controls bullet"><span class="by">a_wild_dandan</span><span>|</span><a href="#39575278">parent</a><span>|</span><a href="#39575947">prev</a><span>|</span><a href="#39578943">next</a><span>|</span><label class="collapse" for="c-39575386">[-]</label><label class="expand" for="c-39575386">[2 more]</label></div><br/><div class="children"><div class="content">No. We don&#x27;t know. My favorite hypothesis: SGD is...well, stochastic. Meaning you&#x27;re not optimizing w.r.t the training corpus, but a tiny subset, so your gradient isn&#x27;t <i>quite</i> right. Over-training allows you to bulldoze over local optima and recurse toward the true distribution rather than drive around a local over-fitting basin.</div><br/><div id="39575433" class="c"><input type="checkbox" id="c-39575433" checked=""/><div class="controls bullet"><span class="by">canjobear</span><span>|</span><a href="#39575278">root</a><span>|</span><a href="#39575386">parent</a><span>|</span><a href="#39578943">next</a><span>|</span><label class="collapse" for="c-39575433">[-]</label><label class="expand" for="c-39575433">[1 more]</label></div><br/><div class="children"><div class="content">You can get it with full gradient descent though... <a href="https:&#x2F;&#x2F;www.nature.com&#x2F;articles&#x2F;s41467-020-14663-9" rel="nofollow">https:&#x2F;&#x2F;www.nature.com&#x2F;articles&#x2F;s41467-020-14663-9</a><p>Honestly the fact that there doesn&#x27;t seem to be a good explanation for this makes me think that we just fundamentally don&#x27;t understand learning.</div><br/></div></div></div></div></div></div><div id="39578943" class="c"><input type="checkbox" id="c-39578943" checked=""/><div class="controls bullet"><span class="by">ogogmad</span><span>|</span><a href="#39575278">prev</a><span>|</span><a href="#39575197">next</a><span>|</span><label class="collapse" for="c-39578943">[-]</label><label class="expand" for="c-39578943">[1 more]</label></div><br/><div class="children"><div class="content">Minor nitpick: The title is confusing. The first word should be substituted with &quot;Machine-Learning&quot; or &quot;Statistical-Learning&quot;. Ideally, the author of the piece should do that at some point.</div><br/></div></div><div id="39575197" class="c"><input type="checkbox" id="c-39575197" checked=""/><div class="controls bullet"><span class="by">scythmic_waves</span><span>|</span><a href="#39578943">prev</a><span>|</span><a href="#39575412">next</a><span>|</span><label class="collapse" for="c-39575197">[-]</label><label class="expand" for="c-39575197">[4 more]</label></div><br/><div class="children"><div class="content">Interesting! I’ll have to look over it when I have more time.<p>From a quick glance, it looks like it covers much of the same material as this text [1]. I wonder how they compare.<p>[1]: <a href="https:&#x2F;&#x2F;www.cambridge.org&#x2F;core&#x2F;books&#x2F;understanding-machine-learning&#x2F;3059695661405D25673058E43C8BE2A6" rel="nofollow">https:&#x2F;&#x2F;www.cambridge.org&#x2F;core&#x2F;books&#x2F;understanding-machine-l...</a></div><br/><div id="39575817" class="c"><input type="checkbox" id="c-39575817" checked=""/><div class="controls bullet"><span class="by">throwaway81523</span><span>|</span><a href="#39575197">parent</a><span>|</span><a href="#39575412">next</a><span>|</span><label class="collapse" for="c-39575817">[-]</label><label class="expand" for="c-39575817">[3 more]</label></div><br/><div class="children"><div class="content">A 2014 book on machine learning sounds quaint and historical.</div><br/><div id="39577048" class="c"><input type="checkbox" id="c-39577048" checked=""/><div class="controls bullet"><span class="by">dawnofdusk</span><span>|</span><a href="#39575197">root</a><span>|</span><a href="#39575817">parent</a><span>|</span><a href="#39576601">next</a><span>|</span><label class="collapse" for="c-39577048">[-]</label><label class="expand" for="c-39577048">[1 more]</label></div><br/><div class="children"><div class="content">Depends on what you want from a (text)book. In my mind books should be authoritative, they should include things that have had some thought put into them and are fairly well studied&#x2F;verified. Modern advances in deep learning&#x2F;ML are exciting but are very often not this. I would not a read a book which is just some recent hype papers from NeurIPS&#x2F;ICML stapled together.</div><br/></div></div><div id="39576601" class="c"><input type="checkbox" id="c-39576601" checked=""/><div class="controls bullet"><span class="by">nerdponx</span><span>|</span><a href="#39575197">root</a><span>|</span><a href="#39575817">parent</a><span>|</span><a href="#39577048">prev</a><span>|</span><a href="#39575412">next</a><span>|</span><label class="collapse" for="c-39576601">[-]</label><label class="expand" for="c-39576601">[1 more]</label></div><br/><div class="children"><div class="content">It depends on the particular subtopics it covers. <i>Machine Learning: A Probabilistic Perspective</i> is from 2012 and it&#x27;s still a great resource, although Murphy&#x27;s newer book will certainly cover more up-to-date material.</div><br/></div></div></div></div></div></div><div id="39575412" class="c"><input type="checkbox" id="c-39575412" checked=""/><div class="controls bullet"><span class="by">da39a3ee</span><span>|</span><a href="#39575197">prev</a><span>|</span><a href="#39575216">next</a><span>|</span><label class="collapse" for="c-39575412">[-]</label><label class="expand" for="c-39575412">[3 more]</label></div><br/><div class="children"><div class="content">There are so many great mathematical PDFs available for free on the Internet, written by academics&#x2F;educators&#x2F;engineers. A problem is that there is a huge amount of overlap. I wonder if an AI model could be developed that would do a really good job of synthesizing an overlapping collection into a coherent single PDF without duplication.</div><br/><div id="39575616" class="c"><input type="checkbox" id="c-39575616" checked=""/><div class="controls bullet"><span class="by">hef19898</span><span>|</span><a href="#39575412">parent</a><span>|</span><a href="#39576616">next</a><span>|</span><label class="collapse" for="c-39575616">[-]</label><label class="expand" for="c-39575616">[1 more]</label></div><br/><div class="children"><div class="content">One could also just pick the books used in the corresponding university courses.</div><br/></div></div><div id="39576616" class="c"><input type="checkbox" id="c-39576616" checked=""/><div class="controls bullet"><span class="by">nerdponx</span><span>|</span><a href="#39575412">parent</a><span>|</span><a href="#39575616">prev</a><span>|</span><a href="#39575216">next</a><span>|</span><label class="collapse" for="c-39576616">[-]</label><label class="expand" for="c-39576616">[1 more]</label></div><br/><div class="children"><div class="content">No need for an AI model. <i>Probabilistic Machine Learning</i> by Murphy is an excellent reference and resource.</div><br/></div></div></div></div><div id="39575216" class="c"><input type="checkbox" id="c-39575216" checked=""/><div class="controls bullet"><span class="by">p1esk</span><span>|</span><a href="#39575412">prev</a><span>|</span><label class="collapse" for="c-39575216">[-]</label><label class="expand" for="c-39575216">[10 more]</label></div><br/><div class="children"><div class="content">I can’t wait until I tell GPT-5 “I have this idea I want to try, read this book and tell me there’s anything relevant there to make it work better”.</div><br/><div id="39575594" class="c"><input type="checkbox" id="c-39575594" checked=""/><div class="controls bullet"><span class="by">ralphist</span><span>|</span><a href="#39575216">parent</a><span>|</span><a href="#39575653">next</a><span>|</span><label class="collapse" for="c-39575594">[-]</label><label class="expand" for="c-39575594">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve never heard of an LLM making up a new idea. Shouldn&#x27;t this only work if your thing has already been tried before?</div><br/><div id="39576318" class="c"><input type="checkbox" id="c-39576318" checked=""/><div class="controls bullet"><span class="by">westoncb</span><span>|</span><a href="#39575216">root</a><span>|</span><a href="#39575594">parent</a><span>|</span><a href="#39576056">next</a><span>|</span><label class="collapse" for="c-39576318">[-]</label><label class="expand" for="c-39576318">[1 more]</label></div><br/><div class="children"><div class="content">How people define &quot;new&quot; varies a lot in this context. I&#x27;ve spent a lot of time talking with ChatGPT exploring interdisciplinary ideas and while I think it frequently says things that qualify as new, I&#x27;ve only run into one situation where I was trying to find some way of doing something technical and it just invented something non-trivially original to handle it: <a href="https:&#x2F;&#x2F;x.com&#x2F;Westoncb&#x2F;status&#x2F;1763733064478335326?s=20" rel="nofollow">https:&#x2F;&#x2F;x.com&#x2F;Westoncb&#x2F;status&#x2F;1763733064478335326?s=20</a></div><br/></div></div><div id="39576056" class="c"><input type="checkbox" id="c-39576056" checked=""/><div class="controls bullet"><span class="by">p1esk</span><span>|</span><a href="#39575216">root</a><span>|</span><a href="#39575594">parent</a><span>|</span><a href="#39576318">prev</a><span>|</span><a href="#39575653">next</a><span>|</span><label class="collapse" for="c-39576056">[-]</label><label class="expand" for="c-39576056">[1 more]</label></div><br/><div class="children"><div class="content">In my example I already have an idea, but I’m not sure how good or novel it is, or perhaps I tried it and it didn’t work but I don’t understand why.</div><br/></div></div></div></div><div id="39575653" class="c"><input type="checkbox" id="c-39575653" checked=""/><div class="controls bullet"><span class="by">erbdex</span><span>|</span><a href="#39575216">parent</a><span>|</span><a href="#39575594">prev</a><span>|</span><a href="#39575438">next</a><span>|</span><label class="collapse" for="c-39575653">[-]</label><label class="expand" for="c-39575653">[2 more]</label></div><br/><div class="children"><div class="content">I am realising that passing context for $this is the tricky part as-<p>1. It is very difficult for me to tell you about my context as a user within low dimension variables.<p>2. I do not understand my situation in the universe to be able to tell AI.<p>3. I dont have a vocabulary with AI. Internet i feel aced this with shared HTTP protocol to consistently share agreed upon state. For ex within Uber I am a very narrow request response universe with.. POST phone, car, gps(a,b,c,d), now, payment.<p>But as a student wanting to learn algorithms how do I pass that I&#x27;m $age $internet-type from $place and prefer graphical explanations of algorithms, have tried but gotten scared of that thick book and these $milestones-cs50, know $python upto $proficiency(which again is a fractal variable with research papers on how to define for learning).<p>Similarly how do I help you understand what stage my startup idea is beyond low traction, but want to know have $networks&#x2F;(VC, devs, sales) APIs, have $these successful partnerships with such evidence $attendance, $sales. Who should I speak to? Could you pls write the needful in mails and engage in partnership with other bots under $budget.<p>Even in the real world this vocabulary is in smaller pockets as our contexts are too different.<p>4. Learning assumes knowledge exists as a global forever variable in a wider than we understand universe. $meteor being a non maskable interrupt to the power supply at unicorn temperatures in a decade. Similarly one time trends in disposable $companies that $ecosystem uses to learn. I&#x27;m in a desert village with with absent electricity might mean those machines never reach me and perhaps most people don&#x27;t have a basic phone in the world to be able to share state. Their local power mafia politics and absent governance might mean the pdf AI recommends i read might or might not help.<p>I don&#x27;t know how this will evolve but to think of the possibilities has been so interesting. It&#x27;s like computers can talk to us easily and they&#x27;re such smart babies on day 1 and &quot;folks we aren&#x27;t able to put right, enough, cheap data in&quot; is perhaps the real bottleneck to how much usefulness we are being able to uncover.</div><br/><div id="39576805" class="c"><input type="checkbox" id="c-39576805" checked=""/><div class="controls bullet"><span class="by">p1esk</span><span>|</span><a href="#39575216">root</a><span>|</span><a href="#39575653">parent</a><span>|</span><a href="#39575438">next</a><span>|</span><label class="collapse" for="c-39576805">[-]</label><label class="expand" for="c-39576805">[1 more]</label></div><br/><div class="children"><div class="content">What you described is what some of the recent startups are working on: <a href="https:&#x2F;&#x2F;www.rewind.ai" rel="nofollow">https:&#x2F;&#x2F;www.rewind.ai</a> (I’m not associated with them). To me it seems like a rather trivial problem to solve, compared to creating an LLM in the first place.</div><br/></div></div></div></div><div id="39575627" class="c"><input type="checkbox" id="c-39575627" checked=""/><div class="controls bullet"><span class="by">hef19898</span><span>|</span><a href="#39575216">parent</a><span>|</span><a href="#39575438">prev</a><span>|</span><label class="collapse" for="c-39575627">[-]</label><label class="expand" for="c-39575627">[3 more]</label></div><br/><div class="children"><div class="content">Ypur idea would become even better so if <i>you</i> read the book <i>yourself</i>... You might even learn something new along the way.</div><br/><div id="39575728" class="c"><input type="checkbox" id="c-39575728" checked=""/><div class="controls bullet"><span class="by">dkarras</span><span>|</span><a href="#39575216">root</a><span>|</span><a href="#39575627">parent</a><span>|</span><label class="collapse" for="c-39575728">[-]</label><label class="expand" for="c-39575728">[2 more]</label></div><br/><div class="children"><div class="content">we are optimizing for time here, not learning. I&#x27;m gonna die anyways and anything I learn will be dust. If I just need the info to make something work, spending months (of which I have limited number of) to see if something has something useful in it for me vs. spending and afternoon to probe it to get most of the benefits is a no-brainer.</div><br/><div id="39576170" class="c"><input type="checkbox" id="c-39576170" checked=""/><div class="controls bullet"><span class="by">makapuf</span><span>|</span><a href="#39575216">root</a><span>|</span><a href="#39575728">parent</a><span>|</span><label class="collapse" for="c-39576170">[-]</label><label class="expand" for="c-39576170">[1 more]</label></div><br/><div class="children"><div class="content">Maybe, but dont expect otherwise from a book explicitly named &quot;Learning Theory from First principles&quot;, not &quot;learn large language models in 21 days&quot;.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></body></html>