<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1725872472874" as="style"/><link rel="stylesheet" href="styles.css?v=1725872472874"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://chipsandcheese.com/2024/09/08/telum-ii-at-hot-chips-2024-mainframe-with-a-unique-caching-strategy/">Telum II at Hot Chips 2024: Mainframe with a Unique Caching Strategy</a> <span class="domain">(<a href="https://chipsandcheese.com">chipsandcheese.com</a>)</span></div><div class="subtext"><span>mfiguiere</span> | <span>25 comments</span></div><br/><div><div id="41486574" class="c"><input type="checkbox" id="c-41486574" checked=""/><div class="controls bullet"><span class="by">chihwei</span><span>|</span><a href="#41484393">next</a><span>|</span><label class="collapse" for="c-41486574">[-]</label><label class="expand" for="c-41486574">[1 more]</label></div><br/><div class="children"><div class="content">Mainframe sounds like a good idea to solve many of today&#x27;s problems. Why don&#x27;t people start thinking about making a RISC-V or x86 Mainframe?</div><br/></div></div><div id="41484393" class="c"><input type="checkbox" id="c-41484393" checked=""/><div class="controls bullet"><span class="by">virgulino</span><span>|</span><a href="#41486574">prev</a><span>|</span><a href="#41485004">next</a><span>|</span><label class="collapse" for="c-41484393">[-]</label><label class="expand" for="c-41484393">[3 more]</label></div><br/><div class="children"><div class="content"><i>&quot;Why Do Mainframes Still Exist? What&#x27;s Inside One? 40TB, 200+ Cores, AI, and more! - Dave explores the IBM z16 mainframe from design to assembly and testing.  What&#x27;s inside a modern IBM z16 mainframe that makes it relevant today?&quot;</i> - by Dave Plummer.<p>This is an amazing 23-minute video by the Microsoft programmer who developed the Windows NT Task Manager, among other things. He visits IBM and talks to engineers about the Telum chip architecture (Hot Chips 2023), used in the z16 mainframe. Special attention is paid to the cache.<p><a href="https:&#x2F;&#x2F;youtu.be&#x2F;ouAG4vXFORc" rel="nofollow">https:&#x2F;&#x2F;youtu.be&#x2F;ouAG4vXFORc</a></div><br/><div id="41485631" class="c"><input type="checkbox" id="c-41485631" checked=""/><div class="controls bullet"><span class="by">pclmulqdq</span><span>|</span><a href="#41484393">parent</a><span>|</span><a href="#41485004">next</a><span>|</span><label class="collapse" for="c-41485631">[-]</label><label class="expand" for="c-41485631">[2 more]</label></div><br/><div class="children"><div class="content">Dave Plummer seems to be a bit careless with facts in his videos, and I wouldn&#x27;t generally trust him as a source of information.<p>In an episode on hard drives, he talked about how drivers for hard drives still report a constant number of sectors per track, so they must have a physical layout that matches that. Hard drive manufacturers are open about the actual layout of their drives and that they virtualize the hard drive for the OS so that it behaves well.<p>A few Microsoft engineers also dispute a lot of the facts of his stories about the development of the start menu.<p>Caveat emptor.</div><br/><div id="41486093" class="c"><input type="checkbox" id="c-41486093" checked=""/><div class="controls bullet"><span class="by">froh</span><span>|</span><a href="#41484393">root</a><span>|</span><a href="#41485631">parent</a><span>|</span><a href="#41485004">next</a><span>|</span><label class="collapse" for="c-41486093">[-]</label><label class="expand" for="c-41486093">[1 more]</label></div><br/><div class="children"><div class="content">do you happen to have factual.insights into false reporting on the Mainframe in this specific video?<p>afaict (and I&#x27;ve worked with mainframes for a couple of years) this is spot on.  poor signal&#x2F;noise ratio but the facts are right.</div><br/></div></div></div></div></div></div><div id="41485004" class="c"><input type="checkbox" id="c-41485004" checked=""/><div class="controls bullet"><span class="by">nxobject</span><span>|</span><a href="#41484393">prev</a><span>|</span><a href="#41483899">next</a><span>|</span><label class="collapse" for="c-41485004">[-]</label><label class="expand" for="c-41485004">[1 more]</label></div><br/><div class="children"><div class="content">Another good article by Chips and Cheese on Telum II @ Hot Chips – an interview with IBM directors of development at the processor and system levels. [1]<p>[1] <a href="https:&#x2F;&#x2F;chipsandcheese.com&#x2F;2024&#x2F;09&#x2F;05&#x2F;an-interview-with-susan-eickoff-and-christian-jacobi-from-ibm-at-hot-chips-2024&#x2F;" rel="nofollow">https:&#x2F;&#x2F;chipsandcheese.com&#x2F;2024&#x2F;09&#x2F;05&#x2F;an-interview-with-susa...</a></div><br/></div></div><div id="41483899" class="c"><input type="checkbox" id="c-41483899" checked=""/><div class="controls bullet"><span class="by">mikewarot</span><span>|</span><a href="#41485004">prev</a><span>|</span><a href="#41483021">next</a><span>|</span><label class="collapse" for="c-41483899">[-]</label><label class="expand" for="c-41483899">[3 more]</label></div><br/><div class="children"><div class="content">That&#x27;s a huge amount of effort to let most of the transistors in a computer (in the RAM) sit idle most of the time. Surely there are viable non-Von Neuman alternatives that could be spun out into general purpose computing.</div><br/><div id="41484127" class="c"><input type="checkbox" id="c-41484127" checked=""/><div class="controls bullet"><span class="by">MichaelZuo</span><span>|</span><a href="#41483899">parent</a><span>|</span><a href="#41483021">next</a><span>|</span><label class="collapse" for="c-41484127">[-]</label><label class="expand" for="c-41484127">[2 more]</label></div><br/><div class="children"><div class="content">The vast majority of transistors in any modern CPU are ‘idle’ at any given moment.</div><br/><div id="41485303" class="c"><input type="checkbox" id="c-41485303" checked=""/><div class="controls bullet"><span class="by">kev009</span><span>|</span><a href="#41483899">root</a><span>|</span><a href="#41484127">parent</a><span>|</span><a href="#41483021">next</a><span>|</span><label class="collapse" for="c-41485303">[-]</label><label class="expand" for="c-41485303">[1 more]</label></div><br/><div class="children"><div class="content">With the cascade of different clock domains on a core and package, the control loops can spend that thermal budget effectively elsewhere; idling is one of the benefits of CMOS.</div><br/></div></div></div></div></div></div><div id="41483021" class="c"><input type="checkbox" id="c-41483021" checked=""/><div class="controls bullet"><span class="by">jmclnx</span><span>|</span><a href="#41483899">prev</a><span>|</span><a href="#41483912">next</a><span>|</span><label class="collapse" for="c-41483021">[-]</label><label class="expand" for="c-41483021">[3 more]</label></div><br/><div class="children"><div class="content">To bad the mainframe business will not be spun off from IBM.
Then you may see innovation, but IBM see it as a cash cow.</div><br/><div id="41483457" class="c"><input type="checkbox" id="c-41483457" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#41483021">parent</a><span>|</span><a href="#41483912">next</a><span>|</span><label class="collapse" for="c-41483457">[-]</label><label class="expand" for="c-41483457">[2 more]</label></div><br/><div class="children"><div class="content">Do the customers want innovation?</div><br/><div id="41484417" class="c"><input type="checkbox" id="c-41484417" checked=""/><div class="controls bullet"><span class="by">kev009</span><span>|</span><a href="#41483021">root</a><span>|</span><a href="#41483457">parent</a><span>|</span><a href="#41483912">next</a><span>|</span><label class="collapse" for="c-41484417">[-]</label><label class="expand" for="c-41484417">[1 more]</label></div><br/><div class="children"><div class="content">The CPUs has been a tour de force from the S&#x2F;360, they have never relented, so empirically yes the customers care a lot or they wouldn&#x27;t keep doing this.<p>The software side seems to be more a tale of dichotomy.  The MVS lineage is technically impressive but undoubtedly bizarre and old feeling.  The TPF lineage seems like eventually somewhere the cloud movement will dip for certain cases so it is ahead of time.  Linux is neither stale nor avant-garde, I guess that is their strategy to remain &quot;contemporary&quot;.  VM was always the most delightful one but internally forever the odd one out.</div><br/></div></div></div></div></div></div><div id="41483912" class="c"><input type="checkbox" id="c-41483912" checked=""/><div class="controls bullet"><span class="by">tedunangst</span><span>|</span><a href="#41483021">prev</a><span>|</span><a href="#41482938">next</a><span>|</span><label class="collapse" for="c-41483912">[-]</label><label class="expand" for="c-41483912">[10 more]</label></div><br/><div class="children"><div class="content">I wonder what workloads would benefit from having an L4 victim cache on another CPU, but that other CPU doesn&#x27;t need its own L2 cache.</div><br/><div id="41486120" class="c"><input type="checkbox" id="c-41486120" checked=""/><div class="controls bullet"><span class="by">unnah</span><span>|</span><a href="#41483912">parent</a><span>|</span><a href="#41484340">next</a><span>|</span><label class="collapse" for="c-41486120">[-]</label><label class="expand" for="c-41486120">[1 more]</label></div><br/><div class="children"><div class="content">At a basic level, anything with a working set on the order of 360 MB should benefit from 360 MB of combined L3 with a worst-case latency of 11.5 ns, regardless of which parts end up in which L2 slice (and the cache allocation heuristics described in the article look pretty smart to me). Similarly, if you have a total working set of a couple of GB then the 2.8 GB combined L4 at 48.5 ns latency should be great. Is there any other hardware on the market that can offer so much memory at such a low latency?</div><br/></div></div><div id="41484340" class="c"><input type="checkbox" id="c-41484340" checked=""/><div class="controls bullet"><span class="by">kev009</span><span>|</span><a href="#41483912">parent</a><span>|</span><a href="#41486120">prev</a><span>|</span><a href="#41484128">next</a><span>|</span><label class="collapse" for="c-41484340">[-]</label><label class="expand" for="c-41484340">[1 more]</label></div><br/><div class="children"><div class="content">The claimed latency for it seems not far off from some other vendor&#x27;s L3 caches which may be by virtue of rethinking where to share and therefore paying interconnection coherency taxes.<p>The innovation here seems to be adaptive sizing so if by whatever algorithm&#x2F;metric a remote core is idle, it can volunteer cache to L4.<p>Presumably the interconnect is much richer than contemporary processors in typical IBM fashion and they can do all the control at a very low level (hw state machines&amp;microcoding) so it is fast and transparent.  It will be interesting to hear how it works in practice and if POWER12 gets a similar feature since it shares a lot of R&amp;D.</div><br/></div></div><div id="41484128" class="c"><input type="checkbox" id="c-41484128" checked=""/><div class="controls bullet"><span class="by">_a_a_a_</span><span>|</span><a href="#41483912">parent</a><span>|</span><a href="#41484340">prev</a><span>|</span><a href="#41482938">next</a><span>|</span><label class="collapse" for="c-41484128">[-]</label><label class="expand" for="c-41484128">[7 more]</label></div><br/><div class="children"><div class="content">At a guess, a single thread which benefits from as much cache as it can get.</div><br/><div id="41484453" class="c"><input type="checkbox" id="c-41484453" checked=""/><div class="controls bullet"><span class="by">tedunangst</span><span>|</span><a href="#41483912">root</a><span>|</span><a href="#41484128">parent</a><span>|</span><a href="#41482938">next</a><span>|</span><label class="collapse" for="c-41484453">[-]</label><label class="expand" for="c-41484453">[6 more]</label></div><br/><div class="children"><div class="content">Sure, but having to buy entire CPUs filled with idle cores to scale up cache seems very expensive.</div><br/><div id="41486539" class="c"><input type="checkbox" id="c-41486539" checked=""/><div class="controls bullet"><span class="by">twic</span><span>|</span><a href="#41483912">root</a><span>|</span><a href="#41484453">parent</a><span>|</span><a href="#41484521">next</a><span>|</span><label class="collapse" for="c-41486539">[-]</label><label class="expand" for="c-41486539">[1 more]</label></div><br/><div class="children"><div class="content">People buy whole machines to run memcached!</div><br/></div></div><div id="41484521" class="c"><input type="checkbox" id="c-41484521" checked=""/><div class="controls bullet"><span class="by">kev009</span><span>|</span><a href="#41483912">root</a><span>|</span><a href="#41484453">parent</a><span>|</span><a href="#41486539">prev</a><span>|</span><a href="#41484986">next</a><span>|</span><label class="collapse" for="c-41484521">[-]</label><label class="expand" for="c-41484521">[1 more]</label></div><br/><div class="children"><div class="content">These cores are typically licensed with class&#x2F;restrictions so in absolute terms yes but in the financial engineering of how the system is delivered with excess and restricted hardware no (see core types on the prior&#x2F;shipping generation here <a href="https:&#x2F;&#x2F;www.ibm.com&#x2F;downloads&#x2F;cas&#x2F;6NW3RPQV" rel="nofollow">https:&#x2F;&#x2F;www.ibm.com&#x2F;downloads&#x2F;cas&#x2F;6NW3RPQV</a>)<p>There are probably design reuse and RAS considerations that make it not currently worthwhile to i.e. have a distinct physical design for SAP or whatever cores.</div><br/></div></div><div id="41484986" class="c"><input type="checkbox" id="c-41484986" checked=""/><div class="controls bullet"><span class="by">nxobject</span><span>|</span><a href="#41483912">root</a><span>|</span><a href="#41484453">parent</a><span>|</span><a href="#41484521">prev</a><span>|</span><a href="#41485547">next</a><span>|</span><label class="collapse" for="c-41484986">[-]</label><label class="expand" for="c-41484986">[1 more]</label></div><br/><div class="children"><div class="content">I wouldn&#x27;t be surprised as well if there was some binning that occurred – the dies are huge, so why not overprovision in the design? (Although erring on the side of slighlty more surprise in the case of some binning, since IBM mainframes seem to exist beyond the laws of commodity economics, and it looks like they&#x27;re using a 5nm node.)</div><br/></div></div><div id="41485547" class="c"><input type="checkbox" id="c-41485547" checked=""/><div class="controls bullet"><span class="by">nullc</span><span>|</span><a href="#41483912">root</a><span>|</span><a href="#41484453">parent</a><span>|</span><a href="#41484986">prev</a><span>|</span><a href="#41484480">next</a><span>|</span><label class="collapse" for="c-41485547">[-]</label><label class="expand" for="c-41485547">[1 more]</label></div><br/><div class="children"><div class="content">the CPU&#x27;s only appear to use about 1&#x2F;3rd of the die area. Most of the space is cache.</div><br/></div></div><div id="41484480" class="c"><input type="checkbox" id="c-41484480" checked=""/><div class="controls bullet"><span class="by">_a_a_a_</span><span>|</span><a href="#41483912">root</a><span>|</span><a href="#41484453">parent</a><span>|</span><a href="#41485547">prev</a><span>|</span><a href="#41482938">next</a><span>|</span><label class="collapse" for="c-41484480">[-]</label><label class="expand" for="c-41484480">[1 more]</label></div><br/><div class="children"><div class="content">I said this is where it would help (AFAICS), not that it was the best solution.</div><br/></div></div></div></div></div></div></div></div><div id="41482938" class="c"><input type="checkbox" id="c-41482938" checked=""/><div class="controls bullet"><span class="by">_a_a_a_</span><span>|</span><a href="#41483912">prev</a><span>|</span><label class="collapse" for="c-41482938">[-]</label><label class="expand" for="c-41482938">[3 more]</label></div><br/><div class="children"><div class="content">Seems very complex therefore very expensive (and possibly slow where it matters, at L2). Or it might just work.</div><br/><div id="41483315" class="c"><input type="checkbox" id="c-41483315" checked=""/><div class="controls bullet"><span class="by">jauntywundrkind</span><span>|</span><a href="#41482938">parent</a><span>|</span><label class="collapse" for="c-41483315">[-]</label><label class="expand" for="c-41483315">[2 more]</label></div><br/><div class="children"><div class="content">On the contrary!<p>Yes there&#x27;s a lot of cache. But rather than try to have a bunch of cores reading each cache (sharing 96MB L3 for AMD&#x27;s consumer cores), now there&#x27;s a lot of separate 36MB L2 caches.<p>(And yes, then again, some fancy protocols to create a virtual L3 cache from these L2 caches. But less cache heirarchy &amp; more like networking. It still seems beautifully simpler in many ways to me!)</div><br/><div id="41486326" class="c"><input type="checkbox" id="c-41486326" checked=""/><div class="controls bullet"><span class="by">buildbot</span><span>|</span><a href="#41482938">root</a><span>|</span><a href="#41483315">parent</a><span>|</span><label class="collapse" for="c-41486326">[-]</label><label class="expand" for="c-41486326">[1 more]</label></div><br/><div class="children"><div class="content">L3 caches are already basically distributed and networked through a ring bus or other NoC on many x86 chips, for example sapphire rapids has 1.875MB of L3 per core, which is pooled into a single coherent L3. Fun fact, this is smaller than each cores L2 (2MB).<p>From
<a href="https:&#x2F;&#x2F;chipsandcheese.com&#x2F;2023&#x2F;03&#x2F;12&#x2F;a-peek-at-sapphire-rapids&#x2F;" rel="nofollow">https:&#x2F;&#x2F;chipsandcheese.com&#x2F;2023&#x2F;03&#x2F;12&#x2F;a-peek-at-sapphire-rap...</a>
“ the chip appears to be set up to expose all four chiplets as a monolithic entity, with a single large L3 instance. Interconnect optimization gets harder when you have to connect more nodes, and SPR is a showcase of this. Intel’s mesh has to connect 56 cores with 56 L3 slices.”</div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>