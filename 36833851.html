<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1690275648550" as="style"/><link rel="stylesheet" href="styles.css?v=1690275648550"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://shane.ai/posts/threads-and-goroutines/">Threads and Goroutines</a> <span class="domain">(<a href="https://shane.ai">shane.ai</a>)</span></div><div class="subtext"><span>mpweiher</span> | <span>23 comments</span></div><br/><div><div id="36857110" class="c"><input type="checkbox" id="c-36857110" checked=""/><div class="controls bullet"><span class="by">mamcx</span><span>|</span><a href="#36859087">next</a><span>|</span><label class="collapse" for="c-36857110">[-]</label><label class="expand" for="c-36857110">[1 more]</label></div><br/><div class="children"><div class="content">One of the question asked but not answered is &quot;why is more&#x2F;less expensive to use threads&#x2F;coroutines?&quot;<p>This is my attempt to the answer: (related to working in a database engine and there you also get &quot;why is not a good idea to let the OS handle things for you&quot;.)<p>- Is partially historical<p>- ... and change it could break in funny ways (you bet code depend in this numbers in code somehow!)<p>- And this is because this is a GLOBAL choice for all the apps running, so the OS is blind to what could be optimal (and even if you can tweak it the OS CAN&#x27;T optimize for that rare event)<p>- It must work across many workloads<p>- MOST code run Process-&gt; Small threads and CPU intensive taks (ie: &quot;I pay $$$$$ for a thread-ripper and my app is equally slow!&quot;)<p>And probably the #1:<p>- The main switch is 1 UI thread * Small-N background threads, so is better to <i>pre-allocate for &quot;bigger&quot; capacity</i><p>---<p>Then, &quot;why coroutines and similar are better?&quot; (Is <i>easier</i> to see when you implement it (coroutines) but lets ignore that and use the same mental framework as above)<p>- Even a &quot;general&quot; purpose language have a more defined role (&quot;Go is for networking apps&quot;) and this leak, <i>strongly</i>, if this lang is biased for coroutines&#x2F;other OR threads (Note how Rust <i>can&#x27;t</i> because the role for it is as broad as a full OS)<p>- Langs that use coroutines&#x2F;other VS Threads are optimized for high concurrency <i>because</i> is expected that the developers WILL create significant libraries&#x2F;frameworks <i>for</i> the smaller subset of high concurrency apps (like web servers)<p>- Langs that use Threads VS coroutines&#x2F;other are more general in purpose (Rust, Java, ...) or need to run faster for CPU-intensive&#x2F;Parallel code and there Threads are in fact faster than coroutines.</div><br/></div></div><div id="36859087" class="c"><input type="checkbox" id="c-36859087" checked=""/><div class="controls bullet"><span class="by">nmehner</span><span>|</span><a href="#36857110">prev</a><span>|</span><a href="#36857148">next</a><span>|</span><label class="collapse" for="c-36859087">[-]</label><label class="expand" for="c-36859087">[2 more]</label></div><br/><div class="children"><div class="content">Don&#x27;t most applications that use threads also use thread pools because thread creation is expensive?<p>I guess these comparisons are nice to get a feeling how expensive operations are. But has it a lot real world relevancy?<p>In practice my beef with coroutines is that with unlimited concurrency you run into resource limits when the system gets some load (file descriptors, open connections, ... whatever the coroutine does that is limited) or starts a DOS attack. Which is something no one ever tests and something that appears randomly in production depending on the data fed to the system.<p>With many developers using them as default solution when things get slow that creates brittle systems. How is everyone else dealing with things like this?</div><br/><div id="36859258" class="c"><input type="checkbox" id="c-36859258" checked=""/><div class="controls bullet"><span class="by">jmaker</span><span>|</span><a href="#36859087">parent</a><span>|</span><a href="#36857148">next</a><span>|</span><label class="collapse" for="c-36859258">[-]</label><label class="expand" for="c-36859258">[1 more]</label></div><br/><div class="children"><div class="content">Well, ordinarily, you just know your specs and your requirements, and install rate limiting and load balancing. Just standard availability &amp; resilience. With proper resource constraints and observability in place, your system should be fine in most cases.<p>I think it’s standard practice to plan for failure and simulate adversary access patterns. On the other hand you say “no one ever tests” stuff like that. I suppose it’s not that standard after all.</div><br/></div></div></div></div><div id="36857148" class="c"><input type="checkbox" id="c-36857148" checked=""/><div class="controls bullet"><span class="by">anarazel</span><span>|</span><a href="#36859087">prev</a><span>|</span><a href="#36856060">next</a><span>|</span><label class="collapse" for="c-36857148">[-]</label><label class="expand" for="c-36857148">[2 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think the 8KB calculation is quite right - there are allocations in the kernel for every thread as well, and I don&#x27;t think that&#x27;ll be accounted for by &#x2F;use&#x2F;bin&#x2F;time.</div><br/><div id="36857442" class="c"><input type="checkbox" id="c-36857442" checked=""/><div class="controls bullet"><span class="by">anarazel</span><span>|</span><a href="#36857148">parent</a><span>|</span><a href="#36856060">next</a><span>|</span><label class="collapse" for="c-36857442">[-]</label><label class="expand" for="c-36857442">[1 more]</label></div><br/><div class="children"><div class="content">Indeed. Making the program wait (using a barrier) after all the threads have started, I see a a substantially higher memory usage than reported by time. I only used 100k threads. For me time reports 1018376kB, but looking at &#x2F;proc&#x2F;meminfo I see a difference of 5231092kB - so about 52kB per thread. That&#x27;s a far cry from 8MB, but also not 8kB.<p>&#x2F;proc&#x2F;slabinfo shows some drastic differences:<p>slabtop -o|head -n 15<p>with 100k threads running:<p><pre><code>   Active &#x2F; Total Objects (% used)    : 10134567 &#x2F; 10280497 (98.6%)
   Active &#x2F; Total Slabs (% used)      : 337756 &#x2F; 337756 (100.0%)
   Active &#x2F; Total Caches (% used)     : 132 &#x2F; 175 (75.4%)
   Active &#x2F; Total Size (% used)       : 3598333.95K &#x2F; 3674904.09K (97.9%)
   Minimum &#x2F; Average &#x2F; Maximum Object : 0.01K &#x2F; 0.36K &#x2F; 11.81K

    OBJS ACTIVE  USE OBJ SIZE  SLABS OBJ&#x2F;SLAB CACHE SIZE NAME
  3419013 3418579  99%    0.10K  87667       39    350668K buffer_head
  1485372 1484947  99%    0.19K  35366       42    282928K dentry
  635299 635038  99%    0.68K  13517       47    432544K proc_inode_cache
  575792 575708  99%    1.14K  20564       28    658048K ext4_inode_cache
  514794 514703  99%    0.04K   5047      102     20188K extent_status
  503140 502198  99%    0.18K  11435       44     91480K vm_area_struct
  501738 500514  99%    0.04K   4919      102     19676K vma_lock
  381304 378068  99%    0.57K  13618       28    217888K radix_tree_node
</code></pre>
without:<p><pre><code>   Active &#x2F; Total Objects (% used)    : 7235070 &#x2F; 7678039 (94.2%)
   Active &#x2F; Total Slabs (% used)      : 187813 &#x2F; 187813 (100.0%)
   Active &#x2F; Total Caches (% used)     : 132 &#x2F; 175 (75.4%)
   Active &#x2F; Total Size (% used)       : 1751469.45K &#x2F; 1851083.31K (94.6%)
   Minimum &#x2F; Average &#x2F; Maximum Object : 0.01K &#x2F; 0.24K &#x2F; 11.81K

    OBJS ACTIVE  USE OBJ SIZE  SLABS OBJ&#x2F;SLAB CACHE SIZE NAME
  3419013 3418579  99%    0.10K  87667       39    350668K buffer_head
  898296 887716  98%    0.19K  21388       42    171104K dentry
  575792 575708  99%    1.14K  20564       28    658048K ext4_inode_cache
  514794 514703  99%    0.04K   5047      102     20188K extent_status
  381304 376987  98%    0.57K  13618       28    217888K radix_tree_node
  164352 164352 100%    0.06K   2568       64     10272K kmalloc-rcl-64
  157360  53925  34%    0.07K   2810       56     11240K vmap_area
  139638 109093  78%    0.04K   1369      102      5476K vma_lock</code></pre></div><br/></div></div></div></div><div id="36856060" class="c"><input type="checkbox" id="c-36856060" checked=""/><div class="controls bullet"><span class="by">nsm</span><span>|</span><a href="#36857148">prev</a><span>|</span><a href="#36856901">next</a><span>|</span><label class="collapse" for="c-36856060">[-]</label><label class="expand" for="c-36856060">[8 more]</label></div><br/><div class="children"><div class="content">I feel like this glossed over how when entering something like epoll, Go can optimize switching to another goroutine. Wouldn&#x27;t the epoll block until the calling kernel thread had a file descriptor ready?</div><br/><div id="36856759" class="c"><input type="checkbox" id="c-36856759" checked=""/><div class="controls bullet"><span class="by">ridiculous_fish</span><span>|</span><a href="#36856060">parent</a><span>|</span><a href="#36856251">next</a><span>|</span><label class="collapse" for="c-36856759">[-]</label><label class="expand" for="c-36856759">[2 more]</label></div><br/><div class="children"><div class="content">Go can multiplex goroutines into a single syscall invocation. Two goroutines waiting on distinct file descriptors will use a single epoll (or similar) syscall. However not all syscalls can be multiplexed this way.<p>IMO this partially undermines the &quot;Go doesn&#x27;t have colored functions&quot; claim. 1k goroutines calling read is fine, because read is multiplexed, but 1k goroutines calling stat will be painful, because you get 1k kernel threads. Go&#x27;s &quot;red functions&quot; are those which require a dedicated kernel thread.</div><br/><div id="36857626" class="c"><input type="checkbox" id="c-36857626" checked=""/><div class="controls bullet"><span class="by">insanitybit</span><span>|</span><a href="#36856060">root</a><span>|</span><a href="#36856759">parent</a><span>|</span><a href="#36856251">next</a><span>|</span><label class="collapse" for="c-36857626">[-]</label><label class="expand" for="c-36857626">[1 more]</label></div><br/><div class="children"><div class="content">I think it just undermines &quot;colorless functions are good&quot;, not that go&#x27;s functions are colored - they aren&#x27;t. The problem is that &quot;colors&quot; (ie: &quot;this is async&quot;) are helpful to the caller, they let them know which context they should be in when they perform that work.</div><br/></div></div></div></div><div id="36856251" class="c"><input type="checkbox" id="c-36856251" checked=""/><div class="controls bullet"><span class="by">sharkbot</span><span>|</span><a href="#36856060">parent</a><span>|</span><a href="#36856759">prev</a><span>|</span><a href="#36857439">next</a><span>|</span><label class="collapse" for="c-36856251">[-]</label><label class="expand" for="c-36856251">[1 more]</label></div><br/><div class="children"><div class="content">I don’t have your answers, but the runtime source has some pointers that would likely get you the answer you seek: <a href="https:&#x2F;&#x2F;github.com&#x2F;golang&#x2F;go&#x2F;blob&#x2F;master&#x2F;src&#x2F;runtime&#x2F;HACKING.md">https:&#x2F;&#x2F;github.com&#x2F;golang&#x2F;go&#x2F;blob&#x2F;master&#x2F;src&#x2F;runtime&#x2F;HACKING...</a><p>It sounds like blocking calls switch to a system stack and return the Go stack to the executor pool, but I don’t have source links to back up that claim.</div><br/></div></div><div id="36857439" class="c"><input type="checkbox" id="c-36857439" checked=""/><div class="controls bullet"><span class="by">wahern</span><span>|</span><a href="#36856060">parent</a><span>|</span><a href="#36856251">prev</a><span>|</span><a href="#36856520">next</a><span>|</span><label class="collapse" for="c-36857439">[-]</label><label class="expand" for="c-36857439">[2 more]</label></div><br/><div class="children"><div class="content">epoll_wait takes a timeout, which if 0 means it will return immediately even if no events are pending.<p>You wouldn&#x27;t necessarily need to make use of this feature to implement something like Go&#x27;s scheduler. Jumping to the semantics of epoll skips most of the interesting bits about how Goroutines work. The source code will always beat a blog post. If you&#x27;re curious, you could work backwards from here: <a href="https:&#x2F;&#x2F;go.dev&#x2F;src&#x2F;runtime&#x2F;netpoll_epoll.go" rel="nofollow noreferrer">https:&#x2F;&#x2F;go.dev&#x2F;src&#x2F;runtime&#x2F;netpoll_epoll.go</a> Note that interface does indeed expose the timeout argument to the higher-level scheduling code; see line 92.</div><br/><div id="36858173" class="c"><input type="checkbox" id="c-36858173" checked=""/><div class="controls bullet"><span class="by">nsm</span><span>|</span><a href="#36856060">root</a><span>|</span><a href="#36857439">parent</a><span>|</span><a href="#36856520">next</a><span>|</span><label class="collapse" for="c-36858173">[-]</label><label class="expand" for="c-36858173">[1 more]</label></div><br/><div class="children"><div class="content">I am aware of epoll_wait and friends (select&#x2F;poll) accepting timeouts, and how that plugs into a general event loop like in libuv.<p>However if memory serves, these calls are reasonably expensive (on the order of microseconds, and _worse_ if readiness requires putting the current thread to sleep and then waking it up again). However <a href="https:&#x2F;&#x2F;www.ardanlabs.com&#x2F;blog&#x2F;2018&#x2F;08&#x2F;scheduling-in-go-part2.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.ardanlabs.com&#x2F;blog&#x2F;2018&#x2F;08&#x2F;scheduling-in-go-part...</a> says goroutines are closer to 200ns.<p>However the same source above does a decent job of explaining how epoll is being called &quot;out of band&quot;. I am guessing when they talk about context switching costs, they are doing some sort of amortization of these system call costs. Since the actual OS threads try to remain CPU-affine (thread-per-core, LMAX disruptor etc. etc.), a lot of the OS scheduling costs can be skipped.<p>Thank you for the pointer to the source code. It gives me a starting point.</div><br/></div></div></div></div><div id="36856520" class="c"><input type="checkbox" id="c-36856520" checked=""/><div class="controls bullet"><span class="by">seabrookmx</span><span>|</span><a href="#36856060">parent</a><span>|</span><a href="#36857439">prev</a><span>|</span><a href="#36856901">next</a><span>|</span><label class="collapse" for="c-36856520">[-]</label><label class="expand" for="c-36856520">[2 more]</label></div><br/><div class="children"><div class="content">The key is that epoll _isn&#x27;t_ blocking: epoll_create returns immediately with a file descriptor. Go can use it to issue some sort of i&#x2F;o operation and rather than blocking the kernel thread, it swaps it to another goroutine that needs work done. When epoll notifies the go scheduler the task is complete via that file descriptor, it will then resume the original goroutine.</div><br/><div id="36856628" class="c"><input type="checkbox" id="c-36856628" checked=""/><div class="controls bullet"><span class="by">nsm</span><span>|</span><a href="#36856060">root</a><span>|</span><a href="#36856520">parent</a><span>|</span><a href="#36856901">next</a><span>|</span><label class="collapse" for="c-36856628">[-]</label><label class="expand" for="c-36856628">[1 more]</label></div><br/><div class="children"><div class="content">The crucial operation here is epoll_wait, not epoll_create.<p>Are you saying that the system call is performed on another kernel thread while goroutine continue running on the GOMAXPROCS threads?</div><br/></div></div></div></div></div></div><div id="36856901" class="c"><input type="checkbox" id="c-36856901" checked=""/><div class="controls bullet"><span class="by">tick_tock_tick</span><span>|</span><a href="#36856060">prev</a><span>|</span><a href="#36855643">next</a><span>|</span><label class="collapse" for="c-36856901">[-]</label><label class="expand" for="c-36856901">[5 more]</label></div><br/><div class="children"><div class="content">&gt; Rust threads on linux use 8kb of memory<p>Seemly wildly off unless Rust&#x27;s docs are just wrong? So it&#x27;s literally the “kilobytes vs megabytes” claim he dismisses....<p><a href="https:&#x2F;&#x2F;doc.rust-lang.org&#x2F;std&#x2F;thread&#x2F;#stack-size" rel="nofollow noreferrer">https:&#x2F;&#x2F;doc.rust-lang.org&#x2F;std&#x2F;thread&#x2F;#stack-size</a><p>The default stack size is platform-dependent and subject to change. Currently, it is 2 MiB on all Tier-1 platforms.</div><br/><div id="36856947" class="c"><input type="checkbox" id="c-36856947" checked=""/><div class="controls bullet"><span class="by">p1necone</span><span>|</span><a href="#36856901">parent</a><span>|</span><a href="#36857650">next</a><span>|</span><label class="collapse" for="c-36856947">[-]</label><label class="expand" for="c-36856947">[2 more]</label></div><br/><div class="children"><div class="content">The stack size starts at 2mb, but unless the code in the thread actually <i>uses</i> that it doesn&#x27;t really get consumed, because virtual memory.</div><br/></div></div><div id="36857650" class="c"><input type="checkbox" id="c-36857650" checked=""/><div class="controls bullet"><span class="by">insanitybit</span><span>|</span><a href="#36856901">parent</a><span>|</span><a href="#36856947">prev</a><span>|</span><a href="#36855643">next</a><span>|</span><label class="collapse" for="c-36857650">[-]</label><label class="expand" for="c-36857650">[2 more]</label></div><br/><div class="children"><div class="content">I think this is pretty well covered in the article:<p>&gt; Now you might think that to make a new thread I need 8 megabytes of RAM free. But thanks to the magic of virtual memory and overcommit, that’s not necessarily the case. The right way to think about this is that the OS, let’s assume 64bit, is going to allocate you your own private range but this doesn’t really have to be backed by anything. There are alot of 8mb blocks in a 64bit address space. However there is some book keeping overhead as the kernel tracks it’s IOUs.<p>This is to say that just because you allocate 8MB doesn&#x27;t mean you create the backing pages and page them in.</div><br/><div id="36858015" class="c"><input type="checkbox" id="c-36858015" checked=""/><div class="controls bullet"><span class="by">tick_tock_tick</span><span>|</span><a href="#36856901">root</a><span>|</span><a href="#36857650">parent</a><span>|</span><a href="#36855643">next</a><span>|</span><label class="collapse" for="c-36858015">[-]</label><label class="expand" for="c-36858015">[1 more]</label></div><br/><div class="children"><div class="content">I know how virtual memory works they are just arguing both sides in the article.</div><br/></div></div></div></div></div></div><div id="36855643" class="c"><input type="checkbox" id="c-36855643" checked=""/><div class="controls bullet"><span class="by">yveezy</span><span>|</span><a href="#36856901">prev</a><span>|</span><label class="collapse" for="c-36855643">[-]</label><label class="expand" for="c-36855643">[4 more]</label></div><br/><div class="children"><div class="content">This was a good read! Thanks for sharing</div><br/><div id="36856093" class="c"><input type="checkbox" id="c-36856093" checked=""/><div class="controls bullet"><span class="by">renox</span><span>|</span><a href="#36855643">parent</a><span>|</span><label class="collapse" for="c-36856093">[-]</label><label class="expand" for="c-36856093">[3 more]</label></div><br/><div class="children"><div class="content">A good part of the article is about a non-realistic microbenchmark (nobody spawns <i>empty threads</i>)..<p>Also measuring the performance difference with threads making  some work would be more interesting IMHO.</div><br/><div id="36858800" class="c"><input type="checkbox" id="c-36858800" checked=""/><div class="controls bullet"><span class="by">akvadrako</span><span>|</span><a href="#36855643">root</a><span>|</span><a href="#36856093">parent</a><span>|</span><a href="#36856459">next</a><span>|</span><label class="collapse" for="c-36858800">[-]</label><label class="expand" for="c-36858800">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a good place to start since empty threads should show you the maximum advantage of goroutines.<p>It also shows that the overhead of a million threads is reasonable if you can actually handle them doing something.</div><br/></div></div><div id="36856459" class="c"><input type="checkbox" id="c-36856459" checked=""/><div class="controls bullet"><span class="by">marcus0x62</span><span>|</span><a href="#36855643">root</a><span>|</span><a href="#36856093">parent</a><span>|</span><a href="#36858800">prev</a><span>|</span><label class="collapse" for="c-36856459">[-]</label><label class="expand" for="c-36856459">[1 more]</label></div><br/><div class="children"><div class="content">I did some non-scientific testing with this last week and, at least for my problem (brute-forcing RC4 keys with relatively small numbers of long-lives threads,) threads and go routines were approximately equal in terms of performance with goroutines very slightly faster (around 5% or so.)<p>I have another test I&#x27;m running with the same workload, but with more dynamically created threads (n keys dispatched to a pool of threads&#x2F;goroutines until the key space is exhausted) but I haven&#x27;t finished the threaded version for comparison yet.</div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>