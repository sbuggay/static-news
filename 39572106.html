<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1709456456555" as="style"/><link rel="stylesheet" href="styles.css?v=1709456456555"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://phys.org/news/2024-03-mathematicians-plya-conjecture-eigenvalues-disk.html">Mathematicians prove Pólya&#x27;s conjecture for the eigenvalues of a disk</a> <span class="domain">(<a href="https://phys.org">phys.org</a>)</span></div><div class="subtext"><span>rbanffy</span> | <span>58 comments</span></div><br/><div><div id="39573743" class="c"><input type="checkbox" id="c-39573743" checked=""/><div class="controls bullet"><span class="by">perihelions</span><span>|</span><a href="#39573335">next</a><span>|</span><label class="collapse" for="c-39573743">[-]</label><label class="expand" for="c-39573743">[1 more]</label></div><br/><div class="children"><div class="content">What do the eigenfunctions look like? I didn&#x27;t know the circular disk was such an exotic problem for Laplace&#x27;s equation.<p>edit: Ah, I misunderstood the problem. The eigenfunctions <i>are</i> exactly solved; the problem of <i>sorting and ordering</i> their eigenvalues is apparently not! From their page 4,<p>- <i>&quot;Although all the eigenvalues of the Dirichlet and Neumann Laplacians on the unit disk are explicitly known in terms of zeros of the Bessel functions or their derivatives, see §2 below, in each case the spectrum is given by a two-parametric family, and rearranging it into a single monotone sequence appears to be an unfeasible task.&quot;</i><p><a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2203.07696" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2203.07696</a></div><br/></div></div><div id="39573335" class="c"><input type="checkbox" id="c-39573335" checked=""/><div class="controls bullet"><span class="by">mikhailfranco</span><span>|</span><a href="#39573743">prev</a><span>|</span><a href="#39572954">next</a><span>|</span><label class="collapse" for="c-39573335">[-]</label><label class="expand" for="c-39573335">[32 more]</label></div><br/><div class="children"><div class="content">The title words remind of an unrelated fact, Gershgorin Disks:<p><pre><code>  The eigenvalues of any N x N matrix, A, 
  are contained in the union of N discs in the complex plane. 
  The center of the i_th disc is the i_th diagonal element of A. 
  The radius of the i_th disc is the absolute values 
  of the off-diagonal elements in the i_th row. 
</code></pre>
<a href="https:&#x2F;&#x2F;blogs.sas.com&#x2F;content&#x2F;iml&#x2F;2019&#x2F;05&#x2F;22&#x2F;gershgorin-discs-location-eigenvalues.html" rel="nofollow">https:&#x2F;&#x2F;blogs.sas.com&#x2F;content&#x2F;iml&#x2F;2019&#x2F;05&#x2F;22&#x2F;gershgorin-disc...</a><p>It&#x27;s rather remarkable, unexpected, and perhaps shocking, when you first hear it. There does not seem to be enough information to make it true. But it is.<p>I used it in a real project to cancel noise.</div><br/><div id="39573564" class="c"><input type="checkbox" id="c-39573564" checked=""/><div class="controls bullet"><span class="by">jonathan_landy</span><span>|</span><a href="#39573335">parent</a><span>|</span><a href="#39573839">next</a><span>|</span><label class="collapse" for="c-39573564">[-]</label><label class="expand" for="c-39573564">[6 more]</label></div><br/><div class="children"><div class="content">Matrix theory by Franklin is a great, affordable book containing many interesting results such as this — can highly recommend for those interested in linear algebra.<p><a href="https:&#x2F;&#x2F;www.amazon.com&#x2F;Matrix-Theory-Dover-Books-Mathematics-ebook&#x2F;dp&#x2F;B00ETILFJY&#x2F;ref=mp_s_a_1_19?crid=3JUNVOR3GU1L6&amp;dib=eyJ2IjoiMSJ9.Dz9HnlmPCSgeNm4dWXb1ZinOKcdux1W3BUqr5wNcNdqypiK3eUCHigud2h1G1Sn554SGD0fEaUPy8vwch35r0VQg-RoWT8JtkaNmmnYFjIKY8Mcv_QstKiCSl5mQFTGL3L4F2zQyfIdR-34pktqkOSydU8MhE5-IG6MjD_v2vVmzmI_Stakw2HxeQDwkAwZ5UjSVQJ28pbsH72mdxFWL4w.U64o1ByTGKd2dHZC8rL9_BzQlzRlzwEzjrrHVRHQjwU&amp;dib_tag=se&amp;keywords=matrix+theory&amp;qid=1709396559&amp;sprefix=matrix+theory%2Caps%2C145&amp;sr=8-19" rel="nofollow">https:&#x2F;&#x2F;www.amazon.com&#x2F;Matrix-Theory-Dover-Books-Mathematics...</a></div><br/><div id="39576334" class="c"><input type="checkbox" id="c-39576334" checked=""/><div class="controls bullet"><span class="by">kwkelly</span><span>|</span><a href="#39573335">root</a><span>|</span><a href="#39573564">parent</a><span>|</span><a href="#39576302">next</a><span>|</span><label class="collapse" for="c-39576334">[-]</label><label class="expand" for="c-39576334">[1 more]</label></div><br/><div class="children"><div class="content">Matrix Analysis by Horn and Johnson is another great book, though it is a bit pricier than a Dover book.</div><br/></div></div><div id="39576302" class="c"><input type="checkbox" id="c-39576302" checked=""/><div class="controls bullet"><span class="by">homerowilson</span><span>|</span><a href="#39573335">root</a><span>|</span><a href="#39573564">parent</a><span>|</span><a href="#39576334">prev</a><span>|</span><a href="#39573809">next</a><span>|</span><label class="collapse" for="c-39576302">[-]</label><label class="expand" for="c-39576302">[1 more]</label></div><br/><div class="children"><div class="content">You may enjoy this:<p><a href="https:&#x2F;&#x2F;bwlewis.github.io&#x2F;cassini&#x2F;" rel="nofollow">https:&#x2F;&#x2F;bwlewis.github.io&#x2F;cassini&#x2F;</a></div><br/></div></div><div id="39573809" class="c"><input type="checkbox" id="c-39573809" checked=""/><div class="controls bullet"><span class="by">packetlost</span><span>|</span><a href="#39573335">root</a><span>|</span><a href="#39573564">parent</a><span>|</span><a href="#39576302">prev</a><span>|</span><a href="#39574991">next</a><span>|</span><label class="collapse" for="c-39573809">[-]</label><label class="expand" for="c-39573809">[2 more]</label></div><br/><div class="children"><div class="content">If I have an atrophied high school level understanding of linear algebra, will I get anything out of that book?</div><br/><div id="39574232" class="c"><input type="checkbox" id="c-39574232" checked=""/><div class="controls bullet"><span class="by">jonathan_landy</span><span>|</span><a href="#39573335">root</a><span>|</span><a href="#39573809">parent</a><span>|</span><a href="#39574991">next</a><span>|</span><label class="collapse" for="c-39574232">[-]</label><label class="expand" for="c-39574232">[1 more]</label></div><br/><div class="children"><div class="content">Certainly a useful reference, if you might deal with the topic for some project … but not the best refresher out there for the basics.</div><br/></div></div></div></div><div id="39574991" class="c"><input type="checkbox" id="c-39574991" checked=""/><div class="controls bullet"><span class="by">doubloon</span><span>|</span><a href="#39573335">root</a><span>|</span><a href="#39573564">parent</a><span>|</span><a href="#39573809">prev</a><span>|</span><a href="#39573839">next</a><span>|</span><label class="collapse" for="c-39574991">[-]</label><label class="expand" for="c-39574991">[1 more]</label></div><br/><div class="children"><div class="content">or<p><a href="https:&#x2F;&#x2F;store.doverpublications.com&#x2F;products&#x2F;9780486411798" rel="nofollow">https:&#x2F;&#x2F;store.doverpublications.com&#x2F;products&#x2F;9780486411798</a></div><br/></div></div></div></div><div id="39573839" class="c"><input type="checkbox" id="c-39573839" checked=""/><div class="controls bullet"><span class="by">stabbles</span><span>|</span><a href="#39573335">parent</a><span>|</span><a href="#39573564">prev</a><span>|</span><a href="#39573391">next</a><span>|</span><label class="collapse" for="c-39573839">[-]</label><label class="expand" for="c-39573839">[9 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not that remarkable at all? The proof requires the definition and triangle inequality, that&#x27;s all?<p>Given Ax=λx, take i for which |xᵢ| is largest. Look at the i&#x27;th equation: sum aᵢⱼxⱼ = λxᵢ, move the aᵢᵢxᵢ term to the rhs, take absolute values, divide by |xᵢ|, apply triangle inequality, and you have |aᵢᵢ - λ| ≤ sum |aᵢⱼ| over j≠i. So for every eigenvalue you can find such a disc.<p>That&#x27;s by column, for row use Aᵀ.</div><br/><div id="39574364" class="c"><input type="checkbox" id="c-39574364" checked=""/><div class="controls bullet"><span class="by">kmm</span><span>|</span><a href="#39573335">root</a><span>|</span><a href="#39573839">parent</a><span>|</span><a href="#39574367">next</a><span>|</span><label class="collapse" for="c-39574364">[-]</label><label class="expand" for="c-39574364">[3 more]</label></div><br/><div class="children"><div class="content">Being easy to prove doesn&#x27;t make it unremarkable. Lots of theorems, including this one, have straightforward proofs once you are given the exact formulation. The tricky part is coming up with the idea for the theorem itself. I remember being (mildly) shocked when I was taught this in undergrad, it just seemed too good to be true.</div><br/><div id="39574748" class="c"><input type="checkbox" id="c-39574748" checked=""/><div class="controls bullet"><span class="by">stabbles</span><span>|</span><a href="#39573335">root</a><span>|</span><a href="#39574364">parent</a><span>|</span><a href="#39575156">next</a><span>|</span><label class="collapse" for="c-39574748">[-]</label><label class="expand" for="c-39574748">[1 more]</label></div><br/><div class="children"><div class="content">I think that&#x27;s just how textbooks present it. A fact is stated but you&#x27;re lacking intuition.<p>If you had played around a bit with Laplacian matrices, like tri-diagonal matrices with stencil [-1, 2, -1], and found that its eigenvalues are within 2 ± 2, and if you also realized that A + τI has the same eigenvalues shifted by τ, then it&#x27;s a small step to consider that the magnitude of the off-diagonal may have something to do with the spread of eigenvalues.<p>It&#x27;s likely that Gerschgorin stumbled upon it like this.</div><br/></div></div><div id="39575156" class="c"><input type="checkbox" id="c-39575156" checked=""/><div class="controls bullet"><span class="by">llmzero</span><span>|</span><a href="#39573335">root</a><span>|</span><a href="#39574364">parent</a><span>|</span><a href="#39574748">prev</a><span>|</span><a href="#39574367">next</a><span>|</span><label class="collapse" for="c-39575156">[-]</label><label class="expand" for="c-39575156">[1 more]</label></div><br/><div class="children"><div class="content">Just thinking about some intuition for the result of the theorem: If the off diagonal elements are zero then the diagonal element is an eigenvalue, by continuity of the determinant, if the off diagonal element are small then $det(A-a_{ii}\lambda)$ is almost zero, that is the new eigenvalue is near aii. So it suggests that the off diagonal elements measure how far is aii from being an eigenvalue.</div><br/></div></div></div></div><div id="39574367" class="c"><input type="checkbox" id="c-39574367" checked=""/><div class="controls bullet"><span class="by">nine_k</span><span>|</span><a href="#39573335">root</a><span>|</span><a href="#39573839">parent</a><span>|</span><a href="#39574364">prev</a><span>|</span><a href="#39575375">next</a><span>|</span><label class="collapse" for="c-39574367">[-]</label><label class="expand" for="c-39574367">[2 more]</label></div><br/><div class="children"><div class="content">The Euler&#x27;s identity is also trivial to deduce, but this doesn&#x27;t diminish its beauty.</div><br/><div id="39574576" class="c"><input type="checkbox" id="c-39574576" checked=""/><div class="controls bullet"><span class="by">xanderlewis</span><span>|</span><a href="#39573335">root</a><span>|</span><a href="#39574367">parent</a><span>|</span><a href="#39575375">next</a><span>|</span><label class="collapse" for="c-39574576">[-]</label><label class="expand" for="c-39574576">[1 more]</label></div><br/><div class="children"><div class="content">The Yoneda lemma is another great example of <i>(once you&#x27;ve got the right setup) trivial but beautiful</i></div><br/></div></div></div></div><div id="39575375" class="c"><input type="checkbox" id="c-39575375" checked=""/><div class="controls bullet"><span class="by">jonahx</span><span>|</span><a href="#39573335">root</a><span>|</span><a href="#39573839">parent</a><span>|</span><a href="#39574367">prev</a><span>|</span><a href="#39575144">next</a><span>|</span><label class="collapse" for="c-39575375">[-]</label><label class="expand" for="c-39575375">[2 more]</label></div><br/><div class="children"><div class="content">removed</div><br/><div id="39575944" class="c"><input type="checkbox" id="c-39575944" checked=""/><div class="controls bullet"><span class="by">tsimionescu</span><span>|</span><a href="#39573335">root</a><span>|</span><a href="#39575375">parent</a><span>|</span><a href="#39575144">next</a><span>|</span><label class="collapse" for="c-39575944">[-]</label><label class="expand" for="c-39575944">[1 more]</label></div><br/><div class="children"><div class="content">They are saying that the Greshgorin theorem that the OP is talking about is simple to prove, not the Polya conjecture that took 70 years from the article.</div><br/></div></div></div></div><div id="39575144" class="c"><input type="checkbox" id="c-39575144" checked=""/><div class="controls bullet"><span class="by">moralestapia</span><span>|</span><a href="#39573335">root</a><span>|</span><a href="#39573839">parent</a><span>|</span><a href="#39575375">prev</a><span>|</span><a href="#39573391">next</a><span>|</span><label class="collapse" for="c-39575144">[-]</label><label class="expand" for="c-39575144">[1 more]</label></div><br/><div class="children"><div class="content">Huh?<p>Math 101, simple is better.</div><br/></div></div></div></div><div id="39573391" class="c"><input type="checkbox" id="c-39573391" checked=""/><div class="controls bullet"><span class="by">abetusk</span><span>|</span><a href="#39573335">parent</a><span>|</span><a href="#39573839">prev</a><span>|</span><a href="#39573387">next</a><span>|</span><label class="collapse" for="c-39573391">[-]</label><label class="expand" for="c-39573391">[3 more]</label></div><br/><div class="children"><div class="content">What was the noise cancelling project? How did you use this fact to cancel noise?</div><br/><div id="39574134" class="c"><input type="checkbox" id="c-39574134" checked=""/><div class="controls bullet"><span class="by">sdenton4</span><span>|</span><a href="#39573335">root</a><span>|</span><a href="#39573391">parent</a><span>|</span><a href="#39573387">next</a><span>|</span><label class="collapse" for="c-39574134">[-]</label><label class="expand" for="c-39574134">[2 more]</label></div><br/><div class="children"><div class="content">Just guessing, but....<p>A common noise cancellation technique is to throw away small eigenvalues, as in PCA. This result relates eigenvalues to the structure of the matrix, so might be helpful for reducing ev&#x27;s without bothering with diagonalization?<p>[Edit] This would presumably involve just zeroing out the rows with small diagonal elements and small-ish off-diagonal norm... Center the eigenvalue estimate disk at zero, and then zero out the rest of the row to make the estimate exact.</div><br/><div id="39576114" class="c"><input type="checkbox" id="c-39576114" checked=""/><div class="controls bullet"><span class="by">sdenton4</span><span>|</span><a href="#39573335">root</a><span>|</span><a href="#39574134">parent</a><span>|</span><a href="#39573387">next</a><span>|</span><label class="collapse" for="c-39576114">[-]</label><label class="expand" for="c-39576114">[1 more]</label></div><br/><div class="children"><div class="content">(and after one more thought about it, one would zero out the row &#x2F;and column&#x2F; to preserve the symmetry of the matrix, if applicable, and thus keep the eigenvalues real. and one would probably want to think a bit about whether this kind of deletion actually makes sense for the problem... doing real PCA isn&#x27;t &#x2F;that&#x2F; hard in most cases - I think I would do something this janky only for extremely large matrices or for realtime operation on a microcontroller or something, and then only after thinking hard about it.)</div><br/></div></div></div></div></div></div><div id="39573387" class="c"><input type="checkbox" id="c-39573387" checked=""/><div class="controls bullet"><span class="by">frutiger</span><span>|</span><a href="#39573335">parent</a><span>|</span><a href="#39573391">prev</a><span>|</span><a href="#39577024">next</a><span>|</span><label class="collapse" for="c-39573387">[-]</label><label class="expand" for="c-39573387">[9 more]</label></div><br/><div class="children"><div class="content">Sounds very cool. One thing I didn’t understand though:<p>&gt; The radius of the i_th disc is the absolute values<p>How can a radius of a single disc (i.e. a single value) correspond to multiple values?</div><br/><div id="39576197" class="c"><input type="checkbox" id="c-39576197" checked=""/><div class="controls bullet"><span class="by">Infinity315</span><span>|</span><a href="#39573335">root</a><span>|</span><a href="#39573387">parent</a><span>|</span><a href="#39573442">next</a><span>|</span><label class="collapse" for="c-39576197">[-]</label><label class="expand" for="c-39576197">[1 more]</label></div><br/><div class="children"><div class="content">An intuitive explaination is imagine a nearly diagonal matrix where the values along the diagonal are much larger than values on the off diagonal.  We know the eigenvalues of a diagonal matrix is simply the values on the diagonal, so for nearly diagonal matrices you can be pretty sure that the true eigenvalues are going to be pretty close to those diagonal entries, but a natural question to ask is how far we&#x27;d deviate from those diagonal entries.<p>The answer to the above question is Gerschgorin disks and it&#x27;s closely related cousin Brauer&#x27;s Oval of Cassini.<p>For matrices with real eigenvalues it&#x27;s moreso along the real number line, only for cases where the eigenvalues are imaginary do we imagine disks.</div><br/></div></div><div id="39573442" class="c"><input type="checkbox" id="c-39573442" checked=""/><div class="controls bullet"><span class="by">ximeng</span><span>|</span><a href="#39573335">root</a><span>|</span><a href="#39573387">parent</a><span>|</span><a href="#39576197">prev</a><span>|</span><a href="#39573423">next</a><span>|</span><label class="collapse" for="c-39573442">[-]</label><label class="expand" for="c-39573442">[2 more]</label></div><br/><div class="children"><div class="content">If you look at the link there’s a formula showing it’s the sum.</div><br/><div id="39573521" class="c"><input type="checkbox" id="c-39573521" checked=""/><div class="controls bullet"><span class="by">abetusk</span><span>|</span><a href="#39573335">root</a><span>|</span><a href="#39573442">parent</a><span>|</span><a href="#39573423">next</a><span>|</span><label class="collapse" for="c-39573521">[-]</label><label class="expand" for="c-39573521">[1 more]</label></div><br/><div class="children"><div class="content">Specifically:<p><pre><code>    r_i = \sum_{i \ne j} |A_{i j}|</code></pre></div><br/></div></div></div></div><div id="39573423" class="c"><input type="checkbox" id="c-39573423" checked=""/><div class="controls bullet"><span class="by">reactordev</span><span>|</span><a href="#39573335">root</a><span>|</span><a href="#39573387">parent</a><span>|</span><a href="#39573442">prev</a><span>|</span><a href="#39573788">next</a><span>|</span><label class="collapse" for="c-39573423">[-]</label><label class="expand" for="c-39573423">[4 more]</label></div><br/><div class="children"><div class="content">I’m assuming, but could be wrong as my matrix math ended with GameDev, that the radius of the disk = the absolute values of the other things. +\- depending on which side of the disk they fall?<p>That line got me as well.</div><br/><div id="39573556" class="c"><input type="checkbox" id="c-39573556" checked=""/><div class="controls bullet"><span class="by">Sharlin</span><span>|</span><a href="#39573335">root</a><span>|</span><a href="#39573423">parent</a><span>|</span><a href="#39573788">next</a><span>|</span><label class="collapse" for="c-39573556">[-]</label><label class="expand" for="c-39573556">[3 more]</label></div><br/><div class="children"><div class="content">It&#x27;s missing the word &quot;sum&quot;. Which apparently my brain auto-deduced for me because I didn&#x27;t notice anything off in the sentence on the first reading.</div><br/><div id="39573981" class="c"><input type="checkbox" id="c-39573981" checked=""/><div class="controls bullet"><span class="by">_zoltan_</span><span>|</span><a href="#39573335">root</a><span>|</span><a href="#39573556">parent</a><span>|</span><a href="#39573788">next</a><span>|</span><label class="collapse" for="c-39573981">[-]</label><label class="expand" for="c-39573981">[2 more]</label></div><br/><div class="children"><div class="content">My brain also automatically added sum and also haven&#x27;t noticed anything, but I have a math degree, maybe it&#x27;s just assuming things :-)</div><br/><div id="39574053" class="c"><input type="checkbox" id="c-39574053" checked=""/><div class="controls bullet"><span class="by">frutiger</span><span>|</span><a href="#39573335">root</a><span>|</span><a href="#39573981">parent</a><span>|</span><a href="#39573788">next</a><span>|</span><label class="collapse" for="c-39574053">[-]</label><label class="expand" for="c-39574053">[1 more]</label></div><br/><div class="children"><div class="content">I have a physics degree and did not assume it, that might explain the difference :)</div><br/></div></div></div></div></div></div></div></div><div id="39573788" class="c"><input type="checkbox" id="c-39573788" checked=""/><div class="controls bullet"><span class="by">tomrod</span><span>|</span><a href="#39573335">root</a><span>|</span><a href="#39573387">parent</a><span>|</span><a href="#39573423">prev</a><span>|</span><a href="#39577024">next</a><span>|</span><label class="collapse" for="c-39573788">[-]</label><label class="expand" for="c-39573788">[1 more]</label></div><br/><div class="children"><div class="content">Sum the absolute values of a row for all the off diagonal elements</div><br/></div></div></div></div><div id="39577024" class="c"><input type="checkbox" id="c-39577024" checked=""/><div class="controls bullet"><span class="by">Tommah</span><span>|</span><a href="#39573335">parent</a><span>|</span><a href="#39573387">prev</a><span>|</span><a href="#39574525">next</a><span>|</span><label class="collapse" for="c-39577024">[-]</label><label class="expand" for="c-39577024">[1 more]</label></div><br/><div class="children"><div class="content">bee_rider already touched on this in another comment, but the theorem makes sense if you consider a matrix with large diagonal values and small off-diagonal values (in magnitude).  If I have a matrix with 1,000,000 on the diagonal and 1 everywhere else, I&#x27;d expect the eigenvalues to be 1,000,000 plus or minus some small error.  The Gershgorin disk theorem proves this and puts an upper bound on the error.<p>The diagonal elements of matrices have a lot of rather &quot;magical&quot; properties if you think about it.  Their sum is also the sum of the eigenvalues of the matrix.  And if you have a matrix A that is singular, you can choose any value x that is not an eigenvalue, and then A - xI is invertible but still mostly behaves like A.</div><br/></div></div><div id="39574525" class="c"><input type="checkbox" id="c-39574525" checked=""/><div class="controls bullet"><span class="by">bee_rider</span><span>|</span><a href="#39573335">parent</a><span>|</span><a href="#39577024">prev</a><span>|</span><a href="#39574005">next</a><span>|</span><label class="collapse" for="c-39574525">[-]</label><label class="expand" for="c-39574525">[1 more]</label></div><br/><div class="children"><div class="content">It has an intuitive element to it; we’re looking for the eigenvalue, the vector&#x2F;scalar pair where the scalar has the same effect on the vector as multiplying by the matrix. And we’re comparing against something that looks vaguely like the magnitude of the matrix (shifted by the diagonal, and of course if you had a diagonal matrix, the eigenvalues would just be the diagonal).<p>Not a proof or anything, of course the proof is on Wikipedia and nice and elegant. Just a thought on the gut feeling.<p>I agree that it is a very nice result.</div><br/></div></div><div id="39576162" class="c"><input type="checkbox" id="c-39576162" checked=""/><div class="controls bullet"><span class="by">Infinity315</span><span>|</span><a href="#39573335">parent</a><span>|</span><a href="#39574005">prev</a><span>|</span><a href="#39572954">next</a><span>|</span><label class="collapse" for="c-39576162">[-]</label><label class="expand" for="c-39576162">[1 more]</label></div><br/><div class="children"><div class="content">See also Brauer&#x27;s oval of Cassini which give an equivalent or even better approximation of the eigenvalues of a matrix.</div><br/></div></div></div></div><div id="39572954" class="c"><input type="checkbox" id="c-39572954" checked=""/><div class="controls bullet"><span class="by">VyseofArcadia</span><span>|</span><a href="#39573335">prev</a><span>|</span><a href="#39576878">next</a><span>|</span><label class="collapse" for="c-39572954">[-]</label><label class="expand" for="c-39572954">[1 more]</label></div><br/><div class="children"><div class="content">arXiv link: <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2203.07696" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2203.07696</a></div><br/></div></div><div id="39576878" class="c"><input type="checkbox" id="c-39576878" checked=""/><div class="controls bullet"><span class="by">mikeiavelli</span><span>|</span><a href="#39572954">prev</a><span>|</span><a href="#39573349">next</a><span>|</span><label class="collapse" for="c-39576878">[-]</label><label class="expand" for="c-39576878">[2 more]</label></div><br/><div class="children"><div class="content">From the paper &quot;Pólya’s conjecture for Euclidean balls&quot;
<a href="https:&#x2F;&#x2F;dms.umontreal.ca&#x2F;~iossif&#x2F;polya.pdf" rel="nofollow">https:&#x2F;&#x2F;dms.umontreal.ca&#x2F;~iossif&#x2F;polya.pdf</a><p>&quot;The celebrated Pólya’s conjecture (1954) in spectral geometry states that the eigenvalue counting functions of the Dirichlet and Neumann Laplacian on a bounded Euclidean domain can be estimated from above and below, respectively, by the leading term of Weyl’s asymptotics. Pólya’s conjecture is known to be true for domains which tile Euclidean space, and, in addition, for some special domains in higher dimensions. In this paper, we prove Pólya’s conjecture for the disk, making it the first non-tiling planar domain for which the conjecture is verified. We also confirm Pólya’s conjecture for arbitrary planar sectors, and, in the Dirichlet case, for balls of any dimension. Along the way, we develop the known links between the spectral problems in the disk and certain lattice counting problems. A key novel ingredient is the observation, made in recent work of the last named author, that the corresponding eigenvalue and lattice counting functions are related not only asymptotically, but in fact satisfy certain uniform bounds.&quot;</div><br/></div></div><div id="39573349" class="c"><input type="checkbox" id="c-39573349" checked=""/><div class="controls bullet"><span class="by">esafak</span><span>|</span><a href="#39576878">prev</a><span>|</span><a href="#39572976">next</a><span>|</span><label class="collapse" for="c-39573349">[-]</label><label class="expand" for="c-39573349">[2 more]</label></div><br/><div class="children"><div class="content">I haven&#x27;t read the paper, but does it apply to arbitrarily shaped drums? And if the basis can be arbitrarily large, is this an exciting result? It just says that the spectral domain is isomorphic?</div><br/><div id="39573671" class="c"><input type="checkbox" id="c-39573671" checked=""/><div class="controls bullet"><span class="by">eigenket</span><span>|</span><a href="#39573349">parent</a><span>|</span><a href="#39572976">next</a><span>|</span><label class="collapse" for="c-39573671">[-]</label><label class="expand" for="c-39573671">[1 more]</label></div><br/><div class="children"><div class="content">This result only applies to circular disks, spherical balls and their generalisations in higher dimensions. Previously it was known for shapes which tile the plane or tessellate the space in higher dimensions.</div><br/></div></div></div></div><div id="39572976" class="c"><input type="checkbox" id="c-39572976" checked=""/><div class="controls bullet"><span class="by">snitty</span><span>|</span><a href="#39573349">prev</a><span>|</span><a href="#39573988">next</a><span>|</span><label class="collapse" for="c-39572976">[-]</label><label class="expand" for="c-39572976">[9 more]</label></div><br/><div class="children"><div class="content">Mathematicians prove that you can deduce the shape of disk based on the frequencies it produces when you hit it with a stick.</div><br/><div id="39573856" class="c"><input type="checkbox" id="c-39573856" checked=""/><div class="controls bullet"><span class="by">gus_massa</span><span>|</span><a href="#39572976">parent</a><span>|</span><a href="#39573309">next</a><span>|</span><label class="collapse" for="c-39573856">[-]</label><label class="expand" for="c-39573856">[1 more]</label></div><br/><div class="children"><div class="content">The first sentense is very misleading:<p>&gt; <i>Is it possible to deduce the shape of a drum from the sounds it makes?</i><p>That&#x27;s a known problem with a (very nice) negative answer <a href="https:&#x2F;&#x2F;www.ams.org&#x2F;publicoutreach&#x2F;feature-column&#x2F;fcarc-199706" rel="nofollow">https:&#x2F;&#x2F;www.ams.org&#x2F;publicoutreach&#x2F;feature-column&#x2F;fcarc-1997...</a><p>IIUC this article is about the problem in the other direction, i.e. from the shape (a disk!) to the frecuencies of the sound (eigenvalues).It&#x27;s not about an exact calculation, but about an aproximation of them.<p>&gt; <i>The conjecture bears on the estimation of the frequencies of a round drum or, in mathematical terms, the eigenvalues of a disk.</i><p>From the research paper:<p>&gt; <i>The celebrated Pólya’s conjecture (1954) in spectral geometry states that the eigenvalue counting functions of the Dirichlet and Neumann Laplacian on a bounded Euclidean domain can be estimated from above and below, respectively, by the leading term of Weyl’s asymptotics.</i><p>&lt;guessing&gt; The Weyl&#x27;s asymtotics is probably a good estimation of the very high frecuencies&#x2F;eigenvalues, and the conjeture is probabbly that you can use the estimation as upper or lower bounds instead of just an aproximation.&lt;guessing&gt; [Sorry, not my area and I have not enough time to read the paper.]</div><br/></div></div><div id="39573309" class="c"><input type="checkbox" id="c-39573309" checked=""/><div class="controls bullet"><span class="by">kadoban</span><span>|</span><a href="#39572976">parent</a><span>|</span><a href="#39573856">prev</a><span>|</span><a href="#39573121">next</a><span>|</span><label class="collapse" for="c-39573309">[-]</label><label class="expand" for="c-39573309">[2 more]</label></div><br/><div class="children"><div class="content">I can deduce the disk&#x27;s shape without even hitting it. It&#x27;s a disk.</div><br/></div></div><div id="39573121" class="c"><input type="checkbox" id="c-39573121" checked=""/><div class="controls bullet"><span class="by">m3kw9</span><span>|</span><a href="#39572976">parent</a><span>|</span><a href="#39573309">prev</a><span>|</span><a href="#39573199">next</a><span>|</span><label class="collapse" for="c-39573121">[-]</label><label class="expand" for="c-39573121">[1 more]</label></div><br/><div class="children"><div class="content">Useful as a magic trick, guessing the shape of your disc when you hit it</div><br/></div></div></div></div><div id="39574894" class="c"><input type="checkbox" id="c-39574894" checked=""/><div class="controls bullet"><span class="by">colesantiago</span><span>|</span><a href="#39573701">prev</a><span>|</span><label class="collapse" for="c-39574894">[-]</label><label class="expand" for="c-39574894">[6 more]</label></div><br/><div class="children"><div class="content">Nice, what are the potential use cases for this? Can I use this for my business?</div><br/><div id="39578650" class="c"><input type="checkbox" id="c-39578650" checked=""/><div class="controls bullet"><span class="by">bubblyworld</span><span>|</span><a href="#39574894">parent</a><span>|</span><a href="#39578251">next</a><span>|</span><label class="collapse" for="c-39578650">[-]</label><label class="expand" for="c-39578650">[1 more]</label></div><br/><div class="children"><div class="content">Probably not - in applications, heuristics&#x2F;approximations and &quot;probably true&quot; are king. And in this case the relevant approximations have been known for decades at least.<p>That&#x27;s a very different beast to the game mathematicians play, which demands rigorous proof (or at least a fairly close social version of it, it&#x27;s turtles all the way down).</div><br/></div></div><div id="39578251" class="c"><input type="checkbox" id="c-39578251" checked=""/><div class="controls bullet"><span class="by">VyseofArcadia</span><span>|</span><a href="#39574894">parent</a><span>|</span><a href="#39578650">prev</a><span>|</span><a href="#39579258">next</a><span>|</span><label class="collapse" for="c-39578251">[-]</label><label class="expand" for="c-39578251">[1 more]</label></div><br/><div class="children"><div class="content">This is the sort of thing that comes up in simulations for various engineering subfields. So if your business is computer aided engineering tools or perhaps CAD, then probably yes.</div><br/></div></div><div id="39579258" class="c"><input type="checkbox" id="c-39579258" checked=""/><div class="controls bullet"><span class="by">userbinator</span><span>|</span><a href="#39574894">parent</a><span>|</span><a href="#39578251">prev</a><span>|</span><a href="#39576488">next</a><span>|</span><label class="collapse" for="c-39579258">[-]</label><label class="expand" for="c-39579258">[1 more]</label></div><br/><div class="children"><div class="content">These days, you&#x27;d probably want to know the eigenvalues of an SSD instead. &#x2F;s</div><br/></div></div><div id="39576488" class="c"><input type="checkbox" id="c-39576488" checked=""/><div class="controls bullet"><span class="by">colesantiago</span><span>|</span><a href="#39574894">parent</a><span>|</span><a href="#39579258">prev</a><span>|</span><label class="collapse" for="c-39576488">[-]</label><label class="expand" for="c-39576488">[2 more]</label></div><br/><div class="children"><div class="content">This is a valid question????</div><br/><div id="39577998" class="c"><input type="checkbox" id="c-39577998" checked=""/><div class="controls bullet"><span class="by">yreg</span><span>|</span><a href="#39574894">root</a><span>|</span><a href="#39576488">parent</a><span>|</span><label class="collapse" for="c-39577998">[-]</label><label class="expand" for="c-39577998">[1 more]</label></div><br/><div class="children"><div class="content">Doesn&#x27;t seem so.</div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>