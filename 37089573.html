<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1691917258801" as="style"/><link rel="stylesheet" href="styles.css?v=1691917258801"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.aisnakeoil.com/p/machine-learning-is-useful-for-many">ML is useful for many things, but not for predicting scientific replicability</a> <span class="domain">(<a href="https://www.aisnakeoil.com">www.aisnakeoil.com</a>)</span></div><div class="subtext"><span>randomwalker</span> | <span>24 comments</span></div><br/><div><div id="37105881" class="c"><input type="checkbox" id="c-37105881" checked=""/><div class="controls bullet"><span class="by">morkalork</span><span>|</span><a href="#37106469">next</a><span>|</span><label class="collapse" for="c-37105881">[-]</label><label class="expand" for="c-37105881">[20 more]</label></div><br/><div class="children"><div class="content">From the OG paper:<p>&gt;Our  machine  learning  model  used  an ensemble of random forest and logistic regression models to predict a paper’s likelihood of replication based on the paper’s text.<p>&gt;We trained a model using word2vec on a corpus of 2 million social science publication abstracts published between 2000 and 2017<p>&gt;converting publications into vectors. To do this, we multiplied the normalized frequency of each word in each paper in the training sample by its corresponding 200-dimension word  vector,  which  produced  a  paper-level  vector  representing  the textual content of the paper<p>If you took a paper and rearranged the words to have a completely different meaning, their method would produce the same prediction. It also has no understanding of, or the ability to differentiate between, quotation and references within the paper and content written by the authors themselves. Good luck with that! It&#x27;s basically just learning some known shitty combinations of keywords.</div><br/><div id="37107328" class="c"><input type="checkbox" id="c-37107328" checked=""/><div class="controls bullet"><span class="by">seanhunter</span><span>|</span><a href="#37105881">parent</a><span>|</span><a href="#37106662">next</a><span>|</span><label class="collapse" for="c-37107328">[-]</label><label class="expand" for="c-37107328">[3 more]</label></div><br/><div class="children"><div class="content">&gt; If you took a paper and rearranged the words to have a completely different meaning, their method would produce the same prediction.<p>It&#x27;s entirely possible for this to be true and their methodology to still be effective and valid. What that would mean is that the ordering of words adds little predictive power to the classification (whether or not the paper is replicable).  I can easily imagine that to be the case. For example, it is a commonly-held belief that it would be a struggle to replicate many papers in the social sciences. If that was the case, this &quot;bag of words&quot; approach would work for those papers, because the mere existence of social science vocabulary would raise the likelihood of failure to replicate.<p>Secondly this is also the case for<p>&gt; It also has no understanding of, or the ability to differentiate between, quotation and references within the paper and content written by the authors themselves.<p>In my example, social science papers would reference social science references. So those references in and of themselves could indicate a higher likelihood of failure to replicate.<p>One of the most important general themes in NLP is that a lot of the structure that humans find important to understand a document (eg word ordering, parsing structural differences like your text vs reference vs quotation distinction) is sometimes unnecessary for ML to have predictive power.<p>A common approach is to try something simple like this (bag of words) and then to try something where you add in position vectors (so the model includes word order) or part-of-speech or other structural tagging to see whether that improves classification performance.  It&#x27;s not always required.</div><br/><div id="37107720" class="c"><input type="checkbox" id="c-37107720" checked=""/><div class="controls bullet"><span class="by">notahacker</span><span>|</span><a href="#37105881">root</a><span>|</span><a href="#37107328">parent</a><span>|</span><a href="#37106662">next</a><span>|</span><label class="collapse" for="c-37107720">[-]</label><label class="expand" for="c-37107720">[2 more]</label></div><br/><div class="children"><div class="content">&gt; It&#x27;s entirely possible for this to be true and their methodology to still be effective and valid. What that would mean is that the ordering of words adds little predictive power to the classification (whether or not the paper is replicable). I can easily imagine that to be the case. For example, it is a commonly-held belief that it would be a struggle to replicate many papers in the social sciences. If that was the case, this &quot;bag of words&quot; approach would work for those papers, because the mere existence of social science vocabulary would raise the likelihood of failure to replicate.<p>What is this is true, it would also mean that the model was of zero or negative value for actual real world use. It is not new insight - least of all to academics - that papers on subjects like cancer cures, consumer prices, or perceptions of well-being are more difficult to replicate than papers on subjects like molecular bonds or the behaviour of steel under torsion.<p>On the other hand, academics also have an understanding of study power, study construction, how [un]expected the findings are, and the actual significance of the results to the field, all hugely significant information the ML organism does not incorporate. So the model is less useful than the human judgements it purports to replace. Just because a curve fits doesn&#x27;t mean the model is an improvement on existing understanding<p>Indeed, as the model described appears to be based on naive keyword associations across a very small number of papers, it&#x27;s likely less useful even than a Reddit contrarian saying &quot;bah economics&quot; to every economics paper, as at least the Reddit contrarian might occasionally be able to highlight conspicuously suspect-sounding elements of some abstracts, and won&#x27;t classify a bad economics paper on the steel industry as better than its peers because it contains terms associated with engineering papers and the name of the prestigious institution the author is an <i>undergraduate</i> at</div><br/><div id="37107890" class="c"><input type="checkbox" id="c-37107890" checked=""/><div class="controls bullet"><span class="by">seanhunter</span><span>|</span><a href="#37105881">root</a><span>|</span><a href="#37107720">parent</a><span>|</span><a href="#37106662">next</a><span>|</span><label class="collapse" for="c-37107890">[-]</label><label class="expand" for="c-37107890">[1 more]</label></div><br/><div class="children"><div class="content">A model doesn&#x27;t necessarily need to be an improvement on existing understanding to be useful though. It could have other attributes which are valuable. The map of London (where I live) that I use to navigate on my phone is not in any sense the best map of London that has ever been created.  It is definitely not an improvement on existing understanding, but it&#x27;s a great improvement on not having a map.<p>Say you need to classify all of arxiv for some reason. A model like this might give you the classification performance you need while also being easy to build and not too computationally expensive. It might give better out of sample classification performance than a model that attempts to more realistically model the problem domain.  Or it might have a distribution of errors that is more tolerable for a particular use case (like say you&#x27;re less worried about misclassifications of extreme cases but you really really need to be accurate in the middle of the distribution or vice versa for some reason).  Or it might be more robust to over fitting or whatever.<p>Having a wide analytical toolbox is very useful for data science and this type of NLP has its place for some use cases.  While it may seem fun to poke holes in the approach taken in this case I don&#x27;t think the approach is necessarily intrinsically bad in any way. It&#x27;s obviously (like all tools) bad if misused in the same way that a screwdriver can be used as a hammer, but it will suck.</div><br/></div></div></div></div></div></div><div id="37106662" class="c"><input type="checkbox" id="c-37106662" checked=""/><div class="controls bullet"><span class="by">swsieber</span><span>|</span><a href="#37105881">parent</a><span>|</span><a href="#37107328">prev</a><span>|</span><a href="#37106196">next</a><span>|</span><label class="collapse" for="c-37106662">[-]</label><label class="expand" for="c-37106662">[2 more]</label></div><br/><div class="children"><div class="content">&gt;&gt; on a corpus of ... abstracts<p>Wait a minute. Isn&#x27;t the abstract the summary? I&#x27;ve read accounts of people digging through a paper and seeing impossible, obviously fabricated numbers. I don&#x27;t think those types of issues would surface in an abstract.</div><br/><div id="37107721" class="c"><input type="checkbox" id="c-37107721" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#37105881">root</a><span>|</span><a href="#37106662">parent</a><span>|</span><a href="#37106196">next</a><span>|</span><label class="collapse" for="c-37107721">[-]</label><label class="expand" for="c-37107721">[1 more]</label></div><br/><div class="children"><div class="content">What they are doing is just conditioning on the topic, author, institution and media attention to predict replicability. But they predict averages, can&#x27;t make reliable predictions about specific papers. And the study is focusing only on Psychology, even though they trained their embeddings on 2m paper abstracts.</div><br/></div></div></div></div><div id="37106196" class="c"><input type="checkbox" id="c-37106196" checked=""/><div class="controls bullet"><span class="by">enigmurl</span><span>|</span><a href="#37105881">parent</a><span>|</span><a href="#37106662">prev</a><span>|</span><a href="#37106404">next</a><span>|</span><label class="collapse" for="c-37106196">[-]</label><label class="expand" for="c-37106196">[1 more]</label></div><br/><div class="children"><div class="content">In general, it&#x27;s pretty hard to establish that an algorithm is &quot;not useful&quot; for a particular discipline.</div><br/></div></div><div id="37106404" class="c"><input type="checkbox" id="c-37106404" checked=""/><div class="controls bullet"><span class="by">mirekrusin</span><span>|</span><a href="#37105881">parent</a><span>|</span><a href="#37106196">prev</a><span>|</span><a href="#37106584">next</a><span>|</span><label class="collapse" for="c-37106404">[-]</label><label class="expand" for="c-37106404">[2 more]</label></div><br/><div class="children"><div class="content">Reads like release notes for some early bayesian spam filter.</div><br/><div id="37107460" class="c"><input type="checkbox" id="c-37107460" checked=""/><div class="controls bullet"><span class="by">mdp2021</span><span>|</span><a href="#37105881">root</a><span>|</span><a href="#37106404">parent</a><span>|</span><a href="#37106584">next</a><span>|</span><label class="collapse" for="c-37107460">[-]</label><label class="expand" for="c-37107460">[1 more]</label></div><br/><div class="children"><div class="content">I saw the same: I was writing my comment (then I noticed this parent) as «Without the implementation of Understanding, a ML system would see, if not a bag of words, an ordered set of words (anything more?)... May or may not get more input Information than a Bayesian filter».</div><br/></div></div></div></div><div id="37106584" class="c"><input type="checkbox" id="c-37106584" checked=""/><div class="controls bullet"><span class="by">a-dub</span><span>|</span><a href="#37105881">parent</a><span>|</span><a href="#37106404">prev</a><span>|</span><a href="#37107081">next</a><span>|</span><label class="collapse" for="c-37106584">[-]</label><label class="expand" for="c-37106584">[1 more]</label></div><br/><div class="children"><div class="content">bag of words style representations actually can work quite well in many document classification tasks.<p>wouldn&#x27;t surprise me at all if affect bleeds through word choice and indicates some emotions like uncertainty or overconfidence that are frequently associated with irreplicable results.<p>but yes, predictive models of any kind should not take the place of more rigorous validation of past results.</div><br/></div></div><div id="37107081" class="c"><input type="checkbox" id="c-37107081" checked=""/><div class="controls bullet"><span class="by">thwarted</span><span>|</span><a href="#37105881">parent</a><span>|</span><a href="#37106584">prev</a><span>|</span><a href="#37106249">next</a><span>|</span><label class="collapse" for="c-37107081">[-]</label><label class="expand" for="c-37107081">[3 more]</label></div><br/><div class="children"><div class="content"><i>Our machine learning model used an ensemble of random forest and logistic regression models to predict a paper’s likelihood of replication based on the paper’s text.</i><p>This reads like a description of phrenology.</div><br/><div id="37107134" class="c"><input type="checkbox" id="c-37107134" checked=""/><div class="controls bullet"><span class="by">eimrine</span><span>|</span><a href="#37105881">root</a><span>|</span><a href="#37107081">parent</a><span>|</span><a href="#37107880">next</a><span>|</span><label class="collapse" for="c-37107134">[-]</label><label class="expand" for="c-37107134">[1 more]</label></div><br/><div class="children"><div class="content">ML able to predict likelihood of replication, which is also a prediction (about something in Nature) to me is a perfect example of GIGO.</div><br/></div></div><div id="37107880" class="c"><input type="checkbox" id="c-37107880" checked=""/><div class="controls bullet"><span class="by">onigirij</span><span>|</span><a href="#37105881">root</a><span>|</span><a href="#37107081">parent</a><span>|</span><a href="#37107134">prev</a><span>|</span><a href="#37106249">next</a><span>|</span><label class="collapse" for="c-37107880">[-]</label><label class="expand" for="c-37107880">[1 more]</label></div><br/><div class="children"><div class="content">That is an excellent point&#x2F;</div><br/></div></div></div></div><div id="37106249" class="c"><input type="checkbox" id="c-37106249" checked=""/><div class="controls bullet"><span class="by">light_hue_1</span><span>|</span><a href="#37105881">parent</a><span>|</span><a href="#37107081">prev</a><span>|</span><a href="#37106257">next</a><span>|</span><label class="collapse" for="c-37106249">[-]</label><label class="expand" for="c-37106249">[2 more]</label></div><br/><div class="children"><div class="content">Yes. It&#x27;s hard to believe this paper just came out.<p>It reads like it was written 7 or 8 years ago.</div><br/><div id="37106290" class="c"><input type="checkbox" id="c-37106290" checked=""/><div class="controls bullet"><span class="by">morkalork</span><span>|</span><a href="#37105881">root</a><span>|</span><a href="#37106249">parent</a><span>|</span><a href="#37106257">next</a><span>|</span><label class="collapse" for="c-37106290">[-]</label><label class="expand" for="c-37106290">[1 more]</label></div><br/><div class="children"><div class="content">Indeed it does!</div><br/></div></div></div></div><div id="37106257" class="c"><input type="checkbox" id="c-37106257" checked=""/><div class="controls bullet"><span class="by">crakenzak</span><span>|</span><a href="#37105881">parent</a><span>|</span><a href="#37106249">prev</a><span>|</span><a href="#37106260">next</a><span>|</span><label class="collapse" for="c-37106257">[-]</label><label class="expand" for="c-37106257">[4 more]</label></div><br/><div class="children"><div class="content">Very interesting, so you’re basically saying that a proper technique <i>could</i> potentially predict a papers chance of being successfully replicated?<p>If so, could be great for the field!</div><br/><div id="37106282" class="c"><input type="checkbox" id="c-37106282" checked=""/><div class="controls bullet"><span class="by">morkalork</span><span>|</span><a href="#37105881">root</a><span>|</span><a href="#37106257">parent</a><span>|</span><a href="#37106772">next</a><span>|</span><label class="collapse" for="c-37106282">[-]</label><label class="expand" for="c-37106282">[1 more]</label></div><br/><div class="children"><div class="content">Sure, when we&#x27;ve got something approaching AGI that has in-depth knowledge of a field of research and some &quot;intuition&quot; from experience, then yeah why not.</div><br/></div></div><div id="37106772" class="c"><input type="checkbox" id="c-37106772" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#37105881">root</a><span>|</span><a href="#37106257">parent</a><span>|</span><a href="#37106282">prev</a><span>|</span><a href="#37106525">next</a><span>|</span><label class="collapse" for="c-37106772">[-]</label><label class="expand" for="c-37106772">[1 more]</label></div><br/><div class="children"><div class="content">It would save us a lot of money wasted on experiments, the motivation is strong, so why are we still experimenting? Because you can&#x27;t get from the model what is not in the model. But you just ask a LLM to review papers, it&#x27;s not completely useless, you can get some manner of feedback. I used the prompt &quot;write an openreview.net style review on this paper&quot; + attach PDF, on Claude with 100k token window.</div><br/></div></div><div id="37106525" class="c"><input type="checkbox" id="c-37106525" checked=""/><div class="controls bullet"><span class="by">mhh__</span><span>|</span><a href="#37105881">root</a><span>|</span><a href="#37106257">parent</a><span>|</span><a href="#37106772">prev</a><span>|</span><a href="#37106260">next</a><span>|</span><label class="collapse" for="c-37106525">[-]</label><label class="expand" for="c-37106525">[1 more]</label></div><br/><div class="children"><div class="content">AI Linting of papers isn&#x27;t such a bad idea. There&#x27;s a lot of crappy papers out there.</div><br/></div></div></div></div><div id="37106260" class="c"><input type="checkbox" id="c-37106260" checked=""/><div class="controls bullet"><span class="by">saithound</span><span>|</span><a href="#37105881">parent</a><span>|</span><a href="#37106257">prev</a><span>|</span><a href="#37106469">next</a><span>|</span><label class="collapse" for="c-37106260">[-]</label><label class="expand" for="c-37106260">[1 more]</label></div><br/><div class="children"><div class="content">This observation reminds me of trying to counter Betteridge&#x27;s law of headlines [1] with the observation that if you were to negate the question in the headline, you would clearly get a question whose answer is not No.<p>Of course, the question you get is no longer an actual _headline_, so there&#x27;s no reason to expect Betteridge&#x27;s law to apply.<p>A similar thing happens here: if you take a scientific article, and rearrange its words to change its meaning, what you get is no longer a scientific article, so outside the scope of the classification task &quot;classify scientific articles based on how likely they are to reproduce&quot;. It&#x27;s not even meaningful to ask whether it will reproduce: what you have is no longer a scientific article reporting on research that actually took place and got a certain result, it&#x27;s merely a bag of words that you generated by permuting the words of an actual scientific article.<p>Your observations are irrelevant: they cannot be used to tell apart models which accomplish the stated task (correctly classify scientific articles based on how likely they are to reproduce) from those which do not. This doesn&#x27;t mean the proposed model actually works (I for one think it almost certainly doesn&#x27;t), but it cannot be strong evidence either way.<p>It&#x27;s like somebody proposing a model that can identify an animal based on children&#x27;s pencil drawings of the animal, then you countering that if you rearrange the photo of a man standing next to a horse into a centaur, the model still returns &quot;horse&quot;. Such rearranged, synthetic data is well outside the scope of the inputs the model was meant to handle, so you cannot draw any strong conclusions about the model&#x27;s ability to perform its actual, advertised task.<p>[1] <a href="https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Betteridge%27s_law_of_headlines" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Betteridge%27s_law_of_headli...</a></div><br/></div></div></div></div><div id="37106469" class="c"><input type="checkbox" id="c-37106469" checked=""/><div class="controls bullet"><span class="by">personjerry</span><span>|</span><a href="#37105881">prev</a><span>|</span><label class="collapse" for="c-37106469">[-]</label><label class="expand" for="c-37106469">[3 more]</label></div><br/><div class="children"><div class="content">I feel like this is another way of saying &quot;past data can&#x27;t predict the future&quot;</div><br/><div id="37106706" class="c"><input type="checkbox" id="c-37106706" checked=""/><div class="controls bullet"><span class="by">throwaway290</span><span>|</span><a href="#37106469">parent</a><span>|</span><label class="collapse" for="c-37106706">[-]</label><label class="expand" for="c-37106706">[2 more]</label></div><br/><div class="children"><div class="content">Yeah. If you can check reproducibility with AI then you can just randomly generate a million of texts and predict what will reproduce. But AI is not this magic since it is trained on past texts.</div><br/><div id="37106788" class="c"><input type="checkbox" id="c-37106788" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#37106469">root</a><span>|</span><a href="#37106706">parent</a><span>|</span><label class="collapse" for="c-37106788">[-]</label><label class="expand" for="c-37106788">[1 more]</label></div><br/><div class="children"><div class="content">I hope people start expecting less magic from AI.</div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>