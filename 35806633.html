<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1683190851271" as="style"/><link rel="stylesheet" href="styles.css?v=1683190851271"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://lemire.me/blog/2023/05/03/graviton-3-apple-m2-and-qualcomm-8cx-3rd-gen-a-url-parsing-benchmark/">Graviton 3, Apple M2 and Qualcomm 8cx 3rd gen: a URL parsing benchmark</a> <span class="domain">(<a href="https://lemire.me">lemire.me</a>)</span></div><div class="subtext"><span>ibobev</span> | <span>84 comments</span></div><br/><div><div id="35807196" class="c"><input type="checkbox" id="c-35807196" checked=""/><div class="controls bullet"><span class="by">Kwpolska</span><span>|</span><a href="#35807177">next</a><span>|</span><label class="collapse" for="c-35807196">[-]</label><label class="expand" for="c-35807196">[33 more]</label></div><br/><div class="children"><div class="content">A comparison with x86_64 CPUs (e.g. those seen in comparable MacBooks and AWS machines) would be useful.<p>Also, I&#x27;m not sure if &quot;correcting&quot; the numbers for 3 GHz is reasonable and reflects real-life performance. Perhaps some throttling could be applied to test the CPUs using a common frequency?</div><br/><div id="35807467" class="c"><input type="checkbox" id="c-35807467" checked=""/><div class="controls bullet"><span class="by">zamalek</span><span>|</span><a href="#35807196">parent</a><span>|</span><a href="#35808986">next</a><span>|</span><label class="collapse" for="c-35807467">[-]</label><label class="expand" for="c-35807467">[13 more]</label></div><br/><div class="children"><div class="content">&gt; I&#x27;m not sure if &quot;correcting&quot; the numbers for 3 GHz is reasonable and reflects real-life performance<p>It&#x27;s not useful at all. It effectively measures IPC (instructions per clock), which is just chip vendor bragging rights.<p>Assuming that all the chips meet some baseline performance criteria: for datacenter and portable devices, the real benchmark would be &quot;instructions per joule.&quot;<p>For desktop devices &quot;instructions per dollar&quot; would be most relevant.</div><br/><div id="35808884" class="c"><input type="checkbox" id="c-35808884" checked=""/><div class="controls bullet"><span class="by">aylmao</span><span>|</span><a href="#35807196">root</a><span>|</span><a href="#35807467">parent</a><span>|</span><a href="#35810129">next</a><span>|</span><label class="collapse" for="c-35808884">[-]</label><label class="expand" for="c-35808884">[1 more]</label></div><br/><div class="children"><div class="content">&gt; It&#x27;s not useful at all. It effectively measures IPC (instructions per clock), which is just chip vendor bragging rights.<p>+1. Moreover the author then seems to conclude from this benchmark:<p>&gt; Overall, these numbers suggest that the Qualcomm processor is competitive.<p>This is an odd conclusion to draw from this test and these numbers, given how little this benchmark tests (just string operations). Does this benchmark want to test raw CPU power? Then why &quot;normalize&quot; to 3GHz? Does it want to test CPU capabilities? If so why use such a &quot;narrow&quot; test?<p>IMO this benchmarking does for a good data-point, but far from enough to draw much of a conclusion from.</div><br/></div></div><div id="35810129" class="c"><input type="checkbox" id="c-35810129" checked=""/><div class="controls bullet"><span class="by">xoa</span><span>|</span><a href="#35807196">root</a><span>|</span><a href="#35807467">parent</a><span>|</span><a href="#35808884">prev</a><span>|</span><a href="#35810357">next</a><span>|</span><label class="collapse" for="c-35810129">[-]</label><label class="expand" for="c-35810129">[1 more]</label></div><br/><div class="children"><div class="content">&gt;<i>For desktop devices &quot;instructions per dollar&quot; would be most relevant.</i><p>Well, it&#x27;s one measure, but scaling potential and absolute performance limit matters as well. In use cases where a desktop is performing work to help one or more humans, the cost of salary and other support may utterly drown out even a very expensive extremely high power system. Ie., a 1200W workstation being used at maximum power 10 hours a day 365 days a year (an absurd utilization ratio) at $0.15&#x2F;kWh (average US electricity cost) would still only be around $650&#x2F;year. If it boosted the productivity of a typical tech worker even 1% it&#x27;d pay for itself no problem. It&#x27;s easy to lose sight sometimes of how historically incredible the bang for the buck is in tech.<p>I think it&#x27;s important to remember because some designs that do incredibly well at small sizes run into challenges scaling. Like with CPUs, the nature of silicon fabrication makes it ever more difficult to grow a monolithic die. Switching to a chiplet-based design does mean absolute efficiency and minimum power challenges amongst others, but dramatically improves scalability at the high end. It&#x27;s a sort of infrastructure tradeoff. Apple for example has done incredibly well with its big silicon SoCs from handhelds to portable Macs, but it&#x27;s been struggling to do a Mac Pro or even updated Studio. It&#x27;s not clear that they physically can do something on the level of a modern Epyc chip anymore than Intel could with monolithic Xeons.<p>So normalized performance&#x2F;watt and performance&#x2F;$ and so on do matter, but absolute final density and scale up are another part of the matrix for certain use cases too.</div><br/></div></div><div id="35810357" class="c"><input type="checkbox" id="c-35810357" checked=""/><div class="controls bullet"><span class="by">Aeolun</span><span>|</span><a href="#35807196">root</a><span>|</span><a href="#35807467">parent</a><span>|</span><a href="#35810129">prev</a><span>|</span><a href="#35810541">next</a><span>|</span><label class="collapse" for="c-35810357">[-]</label><label class="expand" for="c-35810357">[2 more]</label></div><br/><div class="children"><div class="content">Maybe for you? If I’m looking at a new CPU for my desktop the only thing really relevant is how many instructions it can crank out per second.<p>I’m not trying to optimize for cost or energy efficiency.</div><br/><div id="35812748" class="c"><input type="checkbox" id="c-35812748" checked=""/><div class="controls bullet"><span class="by">gpderetta</span><span>|</span><a href="#35807196">root</a><span>|</span><a href="#35810357">parent</a><span>|</span><a href="#35810541">next</a><span>|</span><label class="collapse" for="c-35812748">[-]</label><label class="expand" for="c-35812748">[1 more]</label></div><br/><div class="children"><div class="content">Instruction per seconds is an useful perfromance metric. Instruction per clock isn&#x27;t.</div><br/></div></div></div></div><div id="35810541" class="c"><input type="checkbox" id="c-35810541" checked=""/><div class="controls bullet"><span class="by">adfghuibnuio</span><span>|</span><a href="#35807196">root</a><span>|</span><a href="#35807467">parent</a><span>|</span><a href="#35810357">prev</a><span>|</span><a href="#35810582">next</a><span>|</span><label class="collapse" for="c-35810541">[-]</label><label class="expand" for="c-35810541">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s pretty amusing to me how the Megahertz Myth has been inverted nowadays. It used to be everyone cared about the fastest clock speed and irrationally discounted IPC. Now people care about IPC and irrationally discount clock speed. Pretty weird, in my opinion.</div><br/><div id="35811734" class="c"><input type="checkbox" id="c-35811734" checked=""/><div class="controls bullet"><span class="by">saagarjha</span><span>|</span><a href="#35807196">root</a><span>|</span><a href="#35810541">parent</a><span>|</span><a href="#35810582">next</a><span>|</span><label class="collapse" for="c-35811734">[-]</label><label class="expand" for="c-35811734">[1 more]</label></div><br/><div class="children"><div class="content">Clock speed is comparatively easier to boost.</div><br/></div></div></div></div><div id="35810582" class="c"><input type="checkbox" id="c-35810582" checked=""/><div class="controls bullet"><span class="by">foobiekr</span><span>|</span><a href="#35807196">root</a><span>|</span><a href="#35807467">parent</a><span>|</span><a href="#35810541">prev</a><span>|</span><a href="#35807647">next</a><span>|</span><label class="collapse" for="c-35810582">[-]</label><label class="expand" for="c-35810582">[2 more]</label></div><br/><div class="children"><div class="content">Your typical DSP beats your typical CPU on power and instructions&#x2F;sec&#x2F;dollar by a pretty wide margin.</div><br/><div id="35812760" class="c"><input type="checkbox" id="c-35812760" checked=""/><div class="controls bullet"><span class="by">gpderetta</span><span>|</span><a href="#35807196">root</a><span>|</span><a href="#35810582">parent</a><span>|</span><a href="#35807647">next</a><span>|</span><label class="collapse" for="c-35812760">[-]</label><label class="expand" for="c-35812760">[1 more]</label></div><br/><div class="children"><div class="content">You have to measure effective (not theoretical peak) instructions on a specific workload.<p>DSPs will beat CPUs on DSP workloads, but, as expected, utterly fail for any general purpose workload.</div><br/></div></div></div></div><div id="35807647" class="c"><input type="checkbox" id="c-35807647" checked=""/><div class="controls bullet"><span class="by">Octoth0rpe</span><span>|</span><a href="#35807196">root</a><span>|</span><a href="#35807467">parent</a><span>|</span><a href="#35810582">prev</a><span>|</span><a href="#35808986">next</a><span>|</span><label class="collapse" for="c-35807647">[-]</label><label class="expand" for="c-35807647">[4 more]</label></div><br/><div class="children"><div class="content">&gt; For desktop devices &quot;instructions per dollar&quot; would be most relevant.<p>For cloud customers as well</div><br/><div id="35808910" class="c"><input type="checkbox" id="c-35808910" checked=""/><div class="controls bullet"><span class="by">zamalek</span><span>|</span><a href="#35807196">root</a><span>|</span><a href="#35807647">parent</a><span>|</span><a href="#35808131">next</a><span>|</span><label class="collapse" for="c-35808910">[-]</label><label class="expand" for="c-35808910">[2 more]</label></div><br/><div class="children"><div class="content">&gt; For cloud customers as well<p>Cloud costs are dominated by power delivery and cooling. Both of those are directly influenced by how much power the chip uses to achieve it&#x27;s performance target.<p>I guess it does indirectly influence dollar cost, but I was referring to MSRP of the chip. As a simple example: the per-chip cost of Graviton is probably enormous (if you factor R&amp;D into the cost of a chip), but it&#x27;s still cheaper for Amazon customers. Why? Power and cooling.</div><br/><div id="35810099" class="c"><input type="checkbox" id="c-35810099" checked=""/><div class="controls bullet"><span class="by">boulos</span><span>|</span><a href="#35807196">root</a><span>|</span><a href="#35808910">parent</a><span>|</span><a href="#35808131">next</a><span>|</span><label class="collapse" for="c-35810099">[-]</label><label class="expand" for="c-35810099">[1 more]</label></div><br/><div class="children"><div class="content">Disclosure: I used to work on GCE.<p>I don&#x27;t understand where these power and cooling mantras came from, but large-scale cloud providers have very low PUE (Google publishes historical data at <a href="https:&#x2F;&#x2F;www.google.com&#x2F;about&#x2F;datacenters&#x2F;efficiency&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.google.com&#x2F;about&#x2F;datacenters&#x2F;efficiency&#x2F;</a>). That means you can take the basic power from a thread, add some for memory, and multiply by just a bit to get Watts. Take that and plug in your favorite $&#x2F;kWh guess and get a price.<p>Ignoring Graviton, which doesn&#x27;t have published power data to my knowledge, you can look up the TDP for a bunch of chips and see that it&#x27;s a a few Watts per thread [1]. Similar calculations can be done for RAM. You end up at 5<i>ish</i> Watts per thread with some RAM attached. Let&#x27;s call it <i>10</i> all in with cooling or other stuff. Since 10W is 1% of a kW, we end up with .01 kWh per hour. The top hit for &quot;us power commercial rates&quot; [2] says that we should assume 7c per kWh or so. That means our instance with cooling and overheads, needs to include .01 x .07 =&gt; $.0007&#x2F;hr of power and cooling costs.<p>A single core w&#x2F; 4 GiB of memory on GCP at 3yr commitment rates (so we&#x27;re focused on the long-term depreciation price) is .009815 + 4x.001316 =&gt; $.015&#x2F;hr or about 20x as much as the power.<p>tl;dr: Power costs add up, but they are not even close to dominating the costs of cloud pricing.<p>[1] <a href="https:&#x2F;&#x2F;wccftech.com&#x2F;amd-epyc-7h12-cpu-64-core-zen-2-280w-tdp-liquid-cooled&#x2F;" rel="nofollow">https:&#x2F;&#x2F;wccftech.com&#x2F;amd-epyc-7h12-cpu-64-core-zen-2-280w-td...</a><p>[2] <a href="https:&#x2F;&#x2F;www.statista.com&#x2F;statistics&#x2F;190680&#x2F;us-industrial-consumer-price-estimates-for-retail-electricity-since-1970" rel="nofollow">https:&#x2F;&#x2F;www.statista.com&#x2F;statistics&#x2F;190680&#x2F;us-industrial-con...</a></div><br/></div></div></div></div><div id="35808131" class="c"><input type="checkbox" id="c-35808131" checked=""/><div class="controls bullet"><span class="by">cubefox</span><span>|</span><a href="#35807196">root</a><span>|</span><a href="#35807647">parent</a><span>|</span><a href="#35808910">prev</a><span>|</span><a href="#35808986">next</a><span>|</span><label class="collapse" for="c-35808131">[-]</label><label class="expand" for="c-35808131">[1 more]</label></div><br/><div class="children"><div class="content">Which would probably include the cost of the chips in some way, not just electricity.</div><br/></div></div></div></div></div></div><div id="35808986" class="c"><input type="checkbox" id="c-35808986" checked=""/><div class="controls bullet"><span class="by">pr0zac</span><span>|</span><a href="#35807196">parent</a><span>|</span><a href="#35807467">prev</a><span>|</span><a href="#35807439">next</a><span>|</span><label class="collapse" for="c-35808986">[-]</label><label class="expand" for="c-35808986">[1 more]</label></div><br/><div class="children"><div class="content">It feels like a pretty useless benchmark as far as translating to real world performance but for the heck of it I did ten benchmarks on my three year old Thinkpad with a 4.5Ghz Intel i7-9750H running Ubuntu and got a best of ns&#x2F;url=225.63 and worst of ns&#x2F;url=275.118 whatever those scores mean.</div><br/></div></div><div id="35807439" class="c"><input type="checkbox" id="c-35807439" checked=""/><div class="controls bullet"><span class="by">stingraycharles</span><span>|</span><a href="#35807196">parent</a><span>|</span><a href="#35808986">prev</a><span>|</span><a href="#35807254">next</a><span>|</span><label class="collapse" for="c-35807439">[-]</label><label class="expand" for="c-35807439">[8 more]</label></div><br/><div class="children"><div class="content">In my totally unscientific (but consistent) benchmarks for our CI build servers, m6g.8xlarge compile our c++ codebase in about 9.5 minutes, where m6a.8xlarge takes about 11 minutes. The price difference is about 20% as well iirc, so it’s generally a good deal.<p>Of course the types of optimisations that a compiler may (or may not) do on aarch64 vs x86_64 are completely different and may explain the difference (we actually compile with -march=haswell for x86_64), but generally Graviton seems like a really good deal.</div><br/><div id="35808116" class="c"><input type="checkbox" id="c-35808116" checked=""/><div class="controls bullet"><span class="by">foota</span><span>|</span><a href="#35807196">root</a><span>|</span><a href="#35807439">parent</a><span>|</span><a href="#35810391">next</a><span>|</span><label class="collapse" for="c-35808116">[-]</label><label class="expand" for="c-35808116">[5 more]</label></div><br/><div class="children"><div class="content">You&#x27;re probably leaving a lot of performance on the floor if you&#x27;re building for haskell and running on skylakeish or newer.<p>Edit: yes, haswell:-)</div><br/><div id="35808216" class="c"><input type="checkbox" id="c-35808216" checked=""/><div class="controls bullet"><span class="by">nickpeterson</span><span>|</span><a href="#35807196">root</a><span>|</span><a href="#35808116">parent</a><span>|</span><a href="#35811441">next</a><span>|</span><label class="collapse" for="c-35808216">[-]</label><label class="expand" for="c-35808216">[3 more]</label></div><br/><div class="children"><div class="content">*haswell, in case the Haskell people come after you.</div><br/><div id="35808629" class="c"><input type="checkbox" id="c-35808629" checked=""/><div class="controls bullet"><span class="by">speed_spread</span><span>|</span><a href="#35807196">root</a><span>|</span><a href="#35808216">parent</a><span>|</span><a href="#35808430">next</a><span>|</span><label class="collapse" for="c-35808629">[-]</label><label class="expand" for="c-35808629">[1 more]</label></div><br/><div class="children"><div class="content">&quot;don&#x27;t poke the endofunctor&quot;</div><br/></div></div><div id="35808430" class="c"><input type="checkbox" id="c-35808430" checked=""/><div class="controls bullet"><span class="by">paulddraper</span><span>|</span><a href="#35807196">root</a><span>|</span><a href="#35808216">parent</a><span>|</span><a href="#35808629">prev</a><span>|</span><a href="#35811441">next</a><span>|</span><label class="collapse" for="c-35808430">[-]</label><label class="expand" for="c-35808430">[1 more]</label></div><br/><div class="children"><div class="content">Ah, that makes more sense.</div><br/></div></div></div></div><div id="35811441" class="c"><input type="checkbox" id="c-35811441" checked=""/><div class="controls bullet"><span class="by">stingraycharles</span><span>|</span><a href="#35807196">root</a><span>|</span><a href="#35808116">parent</a><span>|</span><a href="#35808216">prev</a><span>|</span><a href="#35810391">next</a><span>|</span><label class="collapse" for="c-35811441">[-]</label><label class="expand" for="c-35811441">[1 more]</label></div><br/><div class="children"><div class="content">Yeah we know, it’s just that we ship these binaries to customers and need a reasonably old architecture that we know “almost everyone” uses.</div><br/></div></div></div></div><div id="35810391" class="c"><input type="checkbox" id="c-35810391" checked=""/><div class="controls bullet"><span class="by">Aeolun</span><span>|</span><a href="#35807196">root</a><span>|</span><a href="#35807439">parent</a><span>|</span><a href="#35808116">prev</a><span>|</span><a href="#35807254">next</a><span>|</span><label class="collapse" for="c-35810391">[-]</label><label class="expand" for="c-35810391">[2 more]</label></div><br/><div class="children"><div class="content">Why not use the c type instances? Is the compilation memory bound? I’d expect it to be the cpu that’s the limiting factor.</div><br/><div id="35811431" class="c"><input type="checkbox" id="c-35811431" checked=""/><div class="controls bullet"><span class="by">stingraycharles</span><span>|</span><a href="#35807196">root</a><span>|</span><a href="#35810391">parent</a><span>|</span><a href="#35807254">next</a><span>|</span><label class="collapse" for="c-35811431">[-]</label><label class="expand" for="c-35811431">[1 more]</label></div><br/><div class="children"><div class="content">Heavy C++ template metaprogramming, we need up to 4GB of memory per process in some situations.</div><br/></div></div></div></div></div></div><div id="35807254" class="c"><input type="checkbox" id="c-35807254" checked=""/><div class="controls bullet"><span class="by">deltaci</span><span>|</span><a href="#35807196">parent</a><span>|</span><a href="#35807439">prev</a><span>|</span><a href="#35807177">next</a><span>|</span><label class="collapse" for="c-35807254">[-]</label><label class="expand" for="c-35807254">[10 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a benchmark of GitHub Actions(Azure) vs a really old Macbook Pro 15, not exactly what you are looking for, but it tells the vibe already.<p><a href="https:&#x2F;&#x2F;buildjet.com&#x2F;for-github-actions&#x2F;blog&#x2F;a-performance-review-of-github-actions-the-cost-of-slow-hardware">https:&#x2F;&#x2F;buildjet.com&#x2F;for-github-actions&#x2F;blog&#x2F;a-performance-r...</a></div><br/><div id="35807438" class="c"><input type="checkbox" id="c-35807438" checked=""/><div class="controls bullet"><span class="by">015a</span><span>|</span><a href="#35807196">root</a><span>|</span><a href="#35807254">parent</a><span>|</span><a href="#35807782">next</a><span>|</span><label class="collapse" for="c-35807438">[-]</label><label class="expand" for="c-35807438">[8 more]</label></div><br/><div class="children"><div class="content">This is a big, general problem with CI providers I don&#x27;t hear talked about enough: because they charge per-minute, they are actively incentivized to run on old hardware, slowing builds and milking more from customers in the process. Doubly-so when your CI is hosted by a major cloud provider who would otherwise have to scrap these old machines.<p>I wish this were only a theoretical concern, a theoretical incentive, but its not. Github Actions is slow, and Gitlab suffers from a similar problem; their hosted SaaS runners are on GCP n1-standard-1 machines. The oldest machine type in GCP&#x27;s fleet, the n1-standard-1 is powered by a variety of dusty, old CPUs Google Cloud has no other use for, from Sandy Bridge to Skylake. That&#x27;s a 12 year old CPU.</div><br/><div id="35808212" class="c"><input type="checkbox" id="c-35808212" checked=""/><div class="controls bullet"><span class="by">AnthonyMouse</span><span>|</span><a href="#35807196">root</a><span>|</span><a href="#35807438">parent</a><span>|</span><a href="#35807782">next</a><span>|</span><label class="collapse" for="c-35808212">[-]</label><label class="expand" for="c-35808212">[7 more]</label></div><br/><div class="children"><div class="content">There are workloads where newer CPUs are dramatically faster (e.g. AVX-512), but in general the difference isn&#x27;t huge. Most of what the newer CPUs get you is more cores and higher power efficiency, which you don&#x27;t care about when you&#x27;re paying per-vCPU. Which vCPU is faster, a ten year old Xeon E5-2643 v2 at 3.5GHz or a two year old Xeon Platinum 8352V at 2.1GHz? It depends on the workload. Which has more memory bandwidth <i>per core</i>?<p>But the cloud provider prefers the latter because it has 500% more cores for 50% more power. Which is why the latter still goes for &gt;$2000 and the former is &lt;$15.</div><br/><div id="35809157" class="c"><input type="checkbox" id="c-35809157" checked=""/><div class="controls bullet"><span class="by">015a</span><span>|</span><a href="#35807196">root</a><span>|</span><a href="#35808212">parent</a><span>|</span><a href="#35807782">next</a><span>|</span><label class="collapse" for="c-35809157">[-]</label><label class="expand" for="c-35809157">[6 more]</label></div><br/><div class="children"><div class="content">&gt; Which vCPU is faster, a ten year old Xeon E5-2643 v2 at 3.5GHz or a two year old Xeon Platinum 8352V at 2.1GHz? It depends on the workload.<p>It really does not depend on the workload, when those workloads we&#x27;re talking about are by-and-large bounded to 1vCPU or less (CI jobs, serverless functions, etc). Ice Lake cores are substantially faster than Ivy Bridge; the 8352V will be faster in practically any workload we&#x27;re talking about.<p>However, I do agree with this take, if we&#x27;re talking about, say, lambda functions. The reason being that the vast majority of workloads built on lambda functions are bounded by IO, not compute; so newer core designs won&#x27;t result in a meaningful improvement in function execution. Put another way: Is a function executing in 75ms instead of 80ms worth paying 30% more? (I made these numbers up, but its the illustration that matters).<p>CI is a different story. CI runs are only bound by IO for the smallest of projects; downloading that 800mb node:18 base docker image takes some time, but it can very easily and quickly be dwarfed by all the things that happen afterward. This is not an uncontroversial opinion; &quot;the CI is slow&quot; is such a meme of a problem at engineering companies nowadays that you&#x27;d think more people would have the sense to look at the common denominator (the CI hosts suck) and not blame themselves (though, often there&#x27;s blame to go around). We&#x27;ve got a project that can build locally, M2 Pro, docker pull and push included, in something like 40 seconds; the CI takes 4 minutes. Its the crusty CPUs; its slow networking; its the &quot;step 1 is finished, wait 10 seconds for the orchestrator to realize it and start step 2&quot;.<p>And I think we, the community, need to be more vocal about this when speaking on platforms that charge by the minute. They are clearly incentivized to leave it shitty. It should even surface in discussions about, for example, the markup of lambda versus EC2. A 4096mb lambda function would cost $172&#x2F;mo if ran 24&#x2F;7, back-to-back. A comparable c6i-large: $62&#x2F;mo; a third the price. That&#x27;s bad enough on the surface, and we <i>need</i> to be cognizant that its <i>even worse</i> than it initially appears because Amazon runs Lambda on whatever they have collecting dust in the closet, and people still report getting Ivy Bridge and Haswell cores sometimes, in 2023; and the better comparison is probably a t2-medium @ $33&#x2F;mo; a 5-6x markup.<p>This isn&#x27;t new information; lambda is crazy expensive; blah blah blah; but I don&#x27;t hear that dimension brought up enough. Calling back to my previous point: Is a function executing in 75ms instead of 80ms worth paying 30% more? Well, we&#x27;re already paying 550% more; the fact that it doesn&#x27;t execute in 75ms <i>by default</i> is abhorrent. Put another way: if Lambda, and other serverless systems like it such as hosted CI runners, enables cloud providers to keep old hardware around far longer than performance improvements say it should be; the markup <i>should not</i> be 500%. We&#x27;re doing Amazon a <i>favor</i> by using Lambda.</div><br/><div id="35812198" class="c"><input type="checkbox" id="c-35812198" checked=""/><div class="controls bullet"><span class="by">AnthonyMouse</span><span>|</span><a href="#35807196">root</a><span>|</span><a href="#35809157">parent</a><span>|</span><a href="#35810225">next</a><span>|</span><label class="collapse" for="c-35812198">[-]</label><label class="expand" for="c-35812198">[1 more]</label></div><br/><div class="children"><div class="content">&gt; It really does not depend on the workload, when those workloads we&#x27;re talking about are by-and-large bounded to 1vCPU or less (CI jobs, serverless functions, etc). Ice Lake cores are substantially faster than Ivy Bridge; the 8352V will be faster in practically any workload we&#x27;re talking about.<p>If you were comparing e.g. the E5-2667v2 to the Xeon Gold 6334 you would be right, because they have the same number of cores and the 6334 has a higher rather than lower clock speed.<p>But the newer CPUs support more cores per socket. The E5-2643v2 has 6, the Xeon Platinum 8352V has 36.<p>To make that fit in the power budget, it has a lower base clock, which eats a huge chunk out of Ice Lake&#x27;s IPC advantage. Then the newer CPU has around twice as much L3 cache, 54MB vs. 25MB, but that&#x27;s for six times as many cores. You get 1.5MB&#x2F;core instead of &gt;4MB&#x2F;core. It has just over three times the memory bandwidth (8xDDR4-2933 vs. 4xDDR3-1866), but again six times as many cores, so around half as much per core. It can easily be slower despite being newer, even when you&#x27;re compute bound.<p>&gt; We&#x27;ve got a project that can build locally, M2 Pro, docker pull and push included, in something like 40 seconds; the CI takes 4 minutes. Its the crusty CPUs; its slow networking; its the &quot;step 1 is finished, wait 10 seconds for the orchestrator to realize it and start step 2&quot;.<p>Inefficient code and slow hardware are two different things. You can have the fastest machine in the world that finishes step 1 in 4ms and still be waiting 10 full seconds if the system is using a timer.<p>But they&#x27;re operating in a competitive market. If you want a faster system, patronize a company that provides one. Just don&#x27;t be surprised if it costs more.</div><br/></div></div><div id="35810225" class="c"><input type="checkbox" id="c-35810225" checked=""/><div class="controls bullet"><span class="by">icedchai</span><span>|</span><a href="#35807196">root</a><span>|</span><a href="#35809157">parent</a><span>|</span><a href="#35812198">prev</a><span>|</span><a href="#35810083">next</a><span>|</span><label class="collapse" for="c-35810225">[-]</label><label class="expand" for="c-35810225">[1 more]</label></div><br/><div class="children"><div class="content">Lambda is good for bursty, typically low activity applications, where it just wouldn&#x27;t make sense to have EC2 instances running 24x7. There about some line-of-business app that gets a couple of requests every minute or so. Maybe once a quarter there will be a spike in usage. Lambda scales up and just handles it. If requests execute in 50ms (unlikely!) or 500ms, it just doesn&#x27;t matter.</div><br/></div></div><div id="35810083" class="c"><input type="checkbox" id="c-35810083" checked=""/><div class="controls bullet"><span class="by">throwaway2990</span><span>|</span><a href="#35807196">root</a><span>|</span><a href="#35809157">parent</a><span>|</span><a href="#35810225">prev</a><span>|</span><a href="#35807782">next</a><span>|</span><label class="collapse" for="c-35810083">[-]</label><label class="expand" for="c-35810083">[3 more]</label></div><br/><div class="children"><div class="content">Lambda is not crazy expensive. It’s expensive if you’re running something 24&#x2F;7 in place of a physical server or VM.</div><br/><div id="35811009" class="c"><input type="checkbox" id="c-35811009" checked=""/><div class="controls bullet"><span class="by">spockz</span><span>|</span><a href="#35807196">root</a><span>|</span><a href="#35810083">parent</a><span>|</span><a href="#35807782">next</a><span>|</span><label class="collapse" for="c-35811009">[-]</label><label class="expand" for="c-35811009">[2 more]</label></div><br/><div class="children"><div class="content">It would be nice if I could still use all lambda functionality and tooling but instead have it running in my own vms with long time commitment.</div><br/><div id="35811271" class="c"><input type="checkbox" id="c-35811271" checked=""/><div class="controls bullet"><span class="by">throwaway2990</span><span>|</span><a href="#35807196">root</a><span>|</span><a href="#35811009">parent</a><span>|</span><a href="#35807782">next</a><span>|</span><label class="collapse" for="c-35811271">[-]</label><label class="expand" for="c-35811271">[1 more]</label></div><br/><div class="children"><div class="content">Not quite sure I follow. But I built an asp.net api and deployed it into lambda and it cost $2&#x2F;m and when it started to get more traffic and the cost got to $20&#x2F;m I moved it to a t4g instance.<p>When I moved it, I didn’t need to make any code changes :) I just made a systemd file and deployed it.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="35807782" class="c"><input type="checkbox" id="c-35807782" checked=""/><div class="controls bullet"><span class="by">willcipriano</span><span>|</span><a href="#35807196">root</a><span>|</span><a href="#35807254">parent</a><span>|</span><a href="#35807438">prev</a><span>|</span><a href="#35807177">next</a><span>|</span><label class="collapse" for="c-35807782">[-]</label><label class="expand" for="c-35807782">[1 more]</label></div><br/><div class="children"><div class="content">Sometimes when I run a lot of builds in a short period of time I feel like I get demoted to the slower boxes.</div><br/></div></div></div></div></div></div><div id="35807177" class="c"><input type="checkbox" id="c-35807177" checked=""/><div class="controls bullet"><span class="by">mhh__</span><span>|</span><a href="#35807196">prev</a><span>|</span><a href="#35811757">next</a><span>|</span><label class="collapse" for="c-35807177">[-]</label><label class="expand" for="c-35807177">[7 more]</label></div><br/><div class="children"><div class="content">Without more context about what the code actually does this doesn&#x27;t tell me all that much, other than what I could guess from the intended usecases of the chips.<p>The strength of Apple silicon is that it can crush benchmarks and transfer that power very well to real world concurrent workloads too e.g. is this basically just measuring the L1 latency? If not are the compilers generating the right instructions etc. (One would assume they are but I have had issues with getting good arm codegen previously, only to find that the compiler couldn&#x27;t work out what ISA to target other than a conservative guess)</div><br/><div id="35808132" class="c"><input type="checkbox" id="c-35808132" checked=""/><div class="controls bullet"><span class="by">dan-robertson</span><span>|</span><a href="#35807177">parent</a><span>|</span><a href="#35807263">next</a><span>|</span><label class="collapse" for="c-35808132">[-]</label><label class="expand" for="c-35808132">[1 more]</label></div><br/><div class="children"><div class="content">It does seem the benchmark has its data in cache, based on the timings.<p>If the benchmark were only measuring L1 latency, what would that imply about the ‘scaling by inverse clock speed’ bit? My guess is as follows. Chips with higher clock rates will be penalised: (a) it is harder to decrease latencies (memory, pipeline length, etc) in absolute terms than run at a higher clock speed to maybe do non-memory things faster; and (b) if you’re waiting 5ns to read some data, that hurts you more after the scaling if your clock speed is higher. The fact that the M1 wins after the scaling despite the higher clock rate suggests to me that either they have a big advantage on memory latency or there’s some non-memory-latency advantage in scheduling or branch prediction that leads to more useful instructions being retired per cycle.<p>But maybe I’m interpreting it the wrong way.</div><br/></div></div><div id="35807263" class="c"><input type="checkbox" id="c-35807263" checked=""/><div class="controls bullet"><span class="by">KerrAvon</span><span>|</span><a href="#35807177">parent</a><span>|</span><a href="#35808132">prev</a><span>|</span><a href="#35807250">next</a><span>|</span><label class="collapse" for="c-35807263">[-]</label><label class="expand" for="c-35807263">[3 more]</label></div><br/><div class="children"><div class="content">Yes. Since it&#x27;s Ada, I&#x27;m suspicious of codegen tuning being a major factor here.</div><br/><div id="35807769" class="c"><input type="checkbox" id="c-35807769" checked=""/><div class="controls bullet"><span class="by">zimpenfish</span><span>|</span><a href="#35807177">root</a><span>|</span><a href="#35807263">parent</a><span>|</span><a href="#35807729">next</a><span>|</span><label class="collapse" for="c-35807769">[-]</label><label class="expand" for="c-35807769">[1 more]</label></div><br/><div class="children"><div class="content">&quot;Ada is a fast and spec-compliant URL parser written in C++.&quot;<p>Wouldn&#x27;t modern C++ compilers have decent codegen tuning for all these platforms?</div><br/></div></div><div id="35807729" class="c"><input type="checkbox" id="c-35807729" checked=""/><div class="controls bullet"><span class="by">wtallis</span><span>|</span><a href="#35807177">root</a><span>|</span><a href="#35807263">parent</a><span>|</span><a href="#35807769">prev</a><span>|</span><a href="#35807250">next</a><span>|</span><label class="collapse" for="c-35807729">[-]</label><label class="expand" for="c-35807729">[1 more]</label></div><br/><div class="children"><div class="content">Is there something specific about this library that makes you suspicious, or are you assuming from the name that this is using the Ada programming language?</div><br/></div></div></div></div><div id="35807250" class="c"><input type="checkbox" id="c-35807250" checked=""/><div class="controls bullet"><span class="by">renewiltord</span><span>|</span><a href="#35807177">parent</a><span>|</span><a href="#35807263">prev</a><span>|</span><a href="#35811757">next</a><span>|</span><label class="collapse" for="c-35807250">[-]</label><label class="expand" for="c-35807250">[2 more]</label></div><br/><div class="children"><div class="content">Git repo available from post.</div><br/><div id="35807292" class="c"><input type="checkbox" id="c-35807292" checked=""/><div class="controls bullet"><span class="by">mhh__</span><span>|</span><a href="#35807177">root</a><span>|</span><a href="#35807250">parent</a><span>|</span><a href="#35811757">next</a><span>|</span><label class="collapse" for="c-35807292">[-]</label><label class="expand" for="c-35807292">[1 more]</label></div><br/><div class="children"><div class="content">I ain&#x27;t readin&#x27; all that (OK maybe I will but lemire does do this quite a lot, his blog is 40% gems 60% slightly sloppy borderline factoids that only make sense if you think in exactly the same way he does)</div><br/></div></div></div></div></div></div><div id="35811757" class="c"><input type="checkbox" id="c-35811757" checked=""/><div class="controls bullet"><span class="by">ksec</span><span>|</span><a href="#35807177">prev</a><span>|</span><a href="#35807430">next</a><span>|</span><label class="collapse" for="c-35811757">[-]</label><label class="expand" for="c-35811757">[1 more]</label></div><br/><div class="children"><div class="content">If I remember correctly,<p>The 8cx 3rd Gen is based on Cortex X1, the same as Snapdragon 888.<p>The Graviton 3 is based on Neoverse V1 which in itself is tweaked version of Neoverse N1 with relaxed pref &#x2F; watt &#x2F; die area and much improved SIMD work load. And N1 is based on Cortex X1.<p>The current Snapdragon is on Cortex X3. With Cortex X4 coming soon.</div><br/></div></div><div id="35807430" class="c"><input type="checkbox" id="c-35807430" checked=""/><div class="controls bullet"><span class="by">monocasa</span><span>|</span><a href="#35811757">prev</a><span>|</span><a href="#35807246">next</a><span>|</span><label class="collapse" for="c-35807430">[-]</label><label class="expand" for="c-35807430">[1 more]</label></div><br/><div class="children"><div class="content">Part of what they don&#x27;t mention is that Graviton 3 and the Snapdragon 8cx Gen 3 have pretty much the same processor core.  The Neoverse V1 is only a slightly modified Cortex X1.  Hence the same results when you account for clock frequency.</div><br/></div></div><div id="35807246" class="c"><input type="checkbox" id="c-35807246" checked=""/><div class="controls bullet"><span class="by">jeffbee</span><span>|</span><a href="#35807430">prev</a><span>|</span><a href="#35807324">next</a><span>|</span><label class="collapse" for="c-35807246">[-]</label><label class="expand" for="c-35807246">[19 more]</label></div><br/><div class="children"><div class="content">To me it would be somewhat more interesting to compare head-to-head mobile CPUs instead of comparing laptops and servers. In this particular microbenchmark, mobile 12th and 13th-generation Core performance cores, and even the efficiency cores on the 13th generation, are faster than the M2.</div><br/><div id="35807385" class="c"><input type="checkbox" id="c-35807385" checked=""/><div class="controls bullet"><span class="by">Dalewyn</span><span>|</span><a href="#35807246">parent</a><span>|</span><a href="#35808041">next</a><span>|</span><label class="collapse" for="c-35807385">[-]</label><label class="expand" for="c-35807385">[4 more]</label></div><br/><div class="children"><div class="content">Intel 12th and 13th gen both use the same efficiency cores.</div><br/><div id="35807420" class="c"><input type="checkbox" id="c-35807420" checked=""/><div class="controls bullet"><span class="by">jeffbee</span><span>|</span><a href="#35807246">root</a><span>|</span><a href="#35807385">parent</a><span>|</span><a href="#35808041">next</a><span>|</span><label class="collapse" for="c-35807420">[-]</label><label class="expand" for="c-35807420">[3 more]</label></div><br/><div class="children"><div class="content">Well, on the ones I happen to have on hand the 12th gen hits 3300MHz and the 13th gen goes all the way to 4200MHz.</div><br/><div id="35807484" class="c"><input type="checkbox" id="c-35807484" checked=""/><div class="controls bullet"><span class="by">Dalewyn</span><span>|</span><a href="#35807246">root</a><span>|</span><a href="#35807420">parent</a><span>|</span><a href="#35808041">next</a><span>|</span><label class="collapse" for="c-35807484">[-]</label><label class="expand" for="c-35807484">[2 more]</label></div><br/><div class="children"><div class="content">Yeah well, the efficiency cores on a 12900K will be faster than those on an N100, so what is your point?<p>We&#x27;re discussing overall compute power differences between CPU architectures, minute differences in performance between  identical-architecture CPU cores stemming from higher clock speeds is outside the scope of this discussion.</div><br/><div id="35809496" class="c"><input type="checkbox" id="c-35809496" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#35807246">root</a><span>|</span><a href="#35807484">parent</a><span>|</span><a href="#35808041">next</a><span>|</span><label class="collapse" for="c-35809496">[-]</label><label class="expand" for="c-35809496">[1 more]</label></div><br/><div class="children"><div class="content">Not for me, I understand and have had this reaction and it sort of undervalues the value of related info. I learned a bit from him and your response for example</div><br/></div></div></div></div></div></div></div></div><div id="35808041" class="c"><input type="checkbox" id="c-35808041" checked=""/><div class="controls bullet"><span class="by">scns</span><span>|</span><a href="#35807246">parent</a><span>|</span><a href="#35807385">prev</a><span>|</span><a href="#35807324">next</a><span>|</span><label class="collapse" for="c-35808041">[-]</label><label class="expand" for="c-35808041">[14 more]</label></div><br/><div class="children"><div class="content">Even when they are faster, the M2 is on the same die as the RAM and the bandwidth and latency are way better. That matters for compilation or am i mistaken?</div><br/><div id="35808294" class="c"><input type="checkbox" id="c-35808294" checked=""/><div class="controls bullet"><span class="by">jeffbee</span><span>|</span><a href="#35807246">root</a><span>|</span><a href="#35808041">parent</a><span>|</span><a href="#35807324">next</a><span>|</span><label class="collapse" for="c-35808294">[-]</label><label class="expand" for="c-35808294">[13 more]</label></div><br/><div class="children"><div class="content">You are mistaken. Just like everyone else who has ever repeated the myth that Apple puts large-scale, high-performance logic and high density DRAM on the same die, which is impossible.<p>Apple uses LPDDR4 modules soldered to a PCB, sourced from the same Korean company that everyone else uses. Intel has used the exact same architecture since Cannon Lake, in 2018.</div><br/><div id="35808795" class="c"><input type="checkbox" id="c-35808795" checked=""/><div class="controls bullet"><span class="by">wtallis</span><span>|</span><a href="#35807246">root</a><span>|</span><a href="#35808294">parent</a><span>|</span><a href="#35808684">next</a><span>|</span><label class="collapse" for="c-35808795">[-]</label><label class="expand" for="c-35808795">[3 more]</label></div><br/><div class="children"><div class="content">Cannon Lake is a weird red herring to bring in to the discussion, because it was only a real product in the narrowest sense possible. It may have technically been the first CPU Intel shipped with LPDDR4 support (or was it one of their Atom-based chips?), but the exact generation of LPDDR isn&#x27;t really relevant because both Apple and Intel have supported multiple generations of LPDDR over the years and both have moved past 4 and 4x to 5 now.<p>What is somewhat relevant as the source of confusion here is that Apple puts the DRAM on the same <i>package</i> as the processor rather than on the motherboard nearby like is almost always done for x86 systems that use LPDDR. (But there&#x27;s at least one upcoming Intel system that&#x27;s been announced as putting the processor and LPDDR on a shared module that is itself then soldered to the motherboard.) That packaging detail probably doesn&#x27;t matter much for the entry-level Apple chips that use the same memory bus width as x86 processors, but may be more important for the high-end parts with GPU-like wide memory busses.</div><br/><div id="35809546" class="c"><input type="checkbox" id="c-35809546" checked=""/><div class="controls bullet"><span class="by">jeffbee</span><span>|</span><a href="#35807246">root</a><span>|</span><a href="#35808795">parent</a><span>|</span><a href="#35808684">next</a><span>|</span><label class="collapse" for="c-35809546">[-]</label><label class="expand" for="c-35809546">[2 more]</label></div><br/><div class="children"><div class="content">Look, I had to go one way or the other: either I said it originated with Ice Lake mobile, and a pedant would come along and say Cannon Lake even though almost nobody physically possesses a Cannon Lake laptop, or I could say Cannon Lake, be pedantically correct, and get your response. Tiger Lake was probably even more widespread and that <i>also</i> predates Apple Silicon.</div><br/><div id="35809913" class="c"><input type="checkbox" id="c-35809913" checked=""/><div class="controls bullet"><span class="by">wtallis</span><span>|</span><a href="#35807246">root</a><span>|</span><a href="#35809546">parent</a><span>|</span><a href="#35808684">next</a><span>|</span><label class="collapse" for="c-35809913">[-]</label><label class="expand" for="c-35809913">[1 more]</label></div><br/><div class="children"><div class="content">None of those possibilities get you anywhere closer to being right. LPDDR didn&#x27;t start with LPDDR4 so it doesn&#x27;t matter which Intel processor was first to support LPDDR4. There&#x27;s nothing special about that generation for Intel or Apple.</div><br/></div></div></div></div></div></div><div id="35808684" class="c"><input type="checkbox" id="c-35808684" checked=""/><div class="controls bullet"><span class="by">ricw</span><span>|</span><a href="#35807246">root</a><span>|</span><a href="#35808294">parent</a><span>|</span><a href="#35808795">prev</a><span>|</span><a href="#35810932">next</a><span>|</span><label class="collapse" for="c-35808684">[-]</label><label class="expand" for="c-35808684">[4 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think that is true.<p>Last I checked apple M1 max chips have up to 800GB&#x2F;s throughput, whilst AMDs high end chips taper out at around ~250GB&#x2F;s or so, closer to what a standard M2 chip does (not max, or pro version). at the top end they&#x27;ve got at least 2x the memory bandwidth than other CPU vendors, and that&#x27;s likely the case further down too.</div><br/><div id="35809543" class="c"><input type="checkbox" id="c-35809543" checked=""/><div class="controls bullet"><span class="by">jsheard</span><span>|</span><a href="#35807246">root</a><span>|</span><a href="#35808684">parent</a><span>|</span><a href="#35808756">next</a><span>|</span><label class="collapse" for="c-35809543">[-]</label><label class="expand" for="c-35809543">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s worth noting that Apples stated bandwidth numbers aren&#x27;t really attainable in CPU-only workloads, so for the sake of comparison to discrete CPUs they&#x27;re not that useful. The M1 Max is advertised as having 400GB&#x2F;sec bandwidth but the CPU cores can only use about half of that - still impressive, but not as impressive as you might think from the marketing.<p>(The M1 Ultra is the one with 800GB&#x2F;sec bandwidth on paper)</div><br/><div id="35810347" class="c"><input type="checkbox" id="c-35810347" checked=""/><div class="controls bullet"><span class="by">inkyoto</span><span>|</span><a href="#35807246">root</a><span>|</span><a href="#35809543">parent</a><span>|</span><a href="#35808756">next</a><span>|</span><label class="collapse" for="c-35810347">[-]</label><label class="expand" for="c-35810347">[1 more]</label></div><br/><div class="children"><div class="content">Anandtech has measured the 104 Gb&#x2F;sec per a CPU <i>core</i> for the M1 Max and 210 Gb&#x2F;sec circa per a CPU <i>cluster</i> bandwidths. M1 Max has 3x CPU clusters: 1x power effecient (2x cores) and 2x performance ones (4x cores each).<p>Where it gets interesting is how access to the memory is multiplexed in the most extreme case where 3x CPU clusters, 32x GPU and 16x ANE cores are attempting to fetch memory blocks at different locations <i>and</i> at once. It is not unreasonable to presuppose that Apple Silicon contraptions use the switched memory architecture, however with such a high degree of parallelism it is very intriguing to know how the memory architecture has been actually designed and optimised. High performant memory access has always been a big deal that usually comes with big money attached to it via a, naturally, non-memory bus associated connection.</div><br/></div></div></div></div><div id="35808756" class="c"><input type="checkbox" id="c-35808756" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#35807246">root</a><span>|</span><a href="#35808684">parent</a><span>|</span><a href="#35809543">prev</a><span>|</span><a href="#35810932">next</a><span>|</span><label class="collapse" for="c-35808756">[-]</label><label class="expand" for="c-35808756">[1 more]</label></div><br/><div class="children"><div class="content">The Mx Max should be compared to a discrete CPU+GPU combination that does have comparable total memory bandwidth. It isn&#x27;t automatically better to put everything on one chip.</div><br/></div></div></div></div><div id="35810932" class="c"><input type="checkbox" id="c-35810932" checked=""/><div class="controls bullet"><span class="by">MBCook</span><span>|</span><a href="#35807246">root</a><span>|</span><a href="#35808294">parent</a><span>|</span><a href="#35808684">prev</a><span>|</span><a href="#35809688">next</a><span>|</span><label class="collapse" for="c-35810932">[-]</label><label class="expand" for="c-35810932">[2 more]</label></div><br/><div class="children"><div class="content">It’s not on die, but isn’t it on package? Thus making signal lengths much shorter and allowing more lines making the memory bandwidth much higher than a (theoretical) equivalent chip with the memory soldered to the motherboard like the Intel machines were?</div><br/><div id="35811002" class="c"><input type="checkbox" id="c-35811002" checked=""/><div class="controls bullet"><span class="by">kcb</span><span>|</span><a href="#35807246">root</a><span>|</span><a href="#35810932">parent</a><span>|</span><a href="#35809688">next</a><span>|</span><label class="collapse" for="c-35811002">[-]</label><label class="expand" for="c-35811002">[1 more]</label></div><br/><div class="children"><div class="content">Yea theoretically, but in memory latency tests the M series chips are well behind Intel and AMD systems.</div><br/></div></div></div></div><div id="35809688" class="c"><input type="checkbox" id="c-35809688" checked=""/><div class="controls bullet"><span class="by">inkyoto</span><span>|</span><a href="#35807246">root</a><span>|</span><a href="#35808294">parent</a><span>|</span><a href="#35810932">prev</a><span>|</span><a href="#35808738">next</a><span>|</span><label class="collapse" for="c-35809688">[-]</label><label class="expand" for="c-35809688">[2 more]</label></div><br/><div class="children"><div class="content">For the sake of the conversation,<p>&gt; Apple uses LPDDR4 modules soldered to a PCB, sourced from the same Korean company that everyone else uses.<p>Apple might have sourced and soldered on LPDDR modules from the same company, but it is not LPDDR4 and it is LPDDR5 <i>6400</i> connected via a 256 (Pro), 512 (Max) or 1024 (Ultra) bit wide memory bus.<p>&gt; Intel has used the exact same architecture since Cannon Lake, in 2018.<p>Other than LPDDR5 6400 had not existed in 2018, no Intel CPU has ever used a 512, leave alone 1024, bit wide memory bus even in the server setup. Wide memory bus is conducive of faster concurrent complex builds, and Rust &#x2F; Haskell builds show significantly faster build speeds as well.</div><br/><div id="35810748" class="c"><input type="checkbox" id="c-35810748" checked=""/><div class="controls bullet"><span class="by">kiratp</span><span>|</span><a href="#35807246">root</a><span>|</span><a href="#35809688">parent</a><span>|</span><a href="#35808738">next</a><span>|</span><label class="collapse" for="c-35810748">[-]</label><label class="expand" for="c-35810748">[1 more]</label></div><br/><div class="children"><div class="content">Case in point<p>&gt; Rust, cargo build for our &quot;test world binary&quot;.:
64 core Threadripper 3990x @ PBO level 3, ~400w, with Optane drive - 1 min 37s
M1 Max, 64 GB, on battery @ 30% charge - 1:34s<p><a href="https:&#x2F;&#x2F;twitter.com&#x2F;kiratpandya&#x2F;status&#x2F;1457438725680480257" rel="nofollow">https:&#x2F;&#x2F;twitter.com&#x2F;kiratpandya&#x2F;status&#x2F;1457438725680480257</a></div><br/></div></div></div></div><div id="35808738" class="c"><input type="checkbox" id="c-35808738" checked=""/><div class="controls bullet"><span class="by">scns</span><span>|</span><a href="#35807246">root</a><span>|</span><a href="#35808294">parent</a><span>|</span><a href="#35809688">prev</a><span>|</span><a href="#35807324">next</a><span>|</span><label class="collapse" for="c-35808738">[-]</label><label class="expand" for="c-35808738">[1 more]</label></div><br/><div class="children"><div class="content">Thank you for the correction then. Ah yes the soldered LPDDR4 dies allow higher bandwiths since more pins allow parallel access.</div><br/></div></div></div></div></div></div></div></div><div id="35807324" class="c"><input type="checkbox" id="c-35807324" checked=""/><div class="controls bullet"><span class="by">psanford</span><span>|</span><a href="#35807246">prev</a><span>|</span><a href="#35808181">next</a><span>|</span><label class="collapse" for="c-35807324">[-]</label><label class="expand" for="c-35807324">[1 more]</label></div><br/><div class="children"><div class="content">It looks like there&#x27;s been some good progress on getting Linux running natively on the Windows Dev Kit 2023 hardware[0]. There was a previous discussion here about this hardware back in 2022-11[1].<p>[0]: <a href="https:&#x2F;&#x2F;github.com&#x2F;linux-surface&#x2F;surface-pro-x&#x2F;issues&#x2F;43">https:&#x2F;&#x2F;github.com&#x2F;linux-surface&#x2F;surface-pro-x&#x2F;issues&#x2F;43</a><p>[1]: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=33418044" rel="nofollow">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=33418044</a></div><br/></div></div><div id="35808181" class="c"><input type="checkbox" id="c-35808181" checked=""/><div class="controls bullet"><span class="by">seiferteric</span><span>|</span><a href="#35807324">prev</a><span>|</span><a href="#35807655">next</a><span>|</span><label class="collapse" for="c-35808181">[-]</label><label class="expand" for="c-35808181">[6 more]</label></div><br/><div class="children"><div class="content">Not that it&#x27;s for sure, but M3 is probably coming out late this year&#x2F;early next year and will be on 3nm, so once again having a huge node advantage. Just seems like Apple will have the latest node before everyone else for the foreseeable future.</div><br/><div id="35808244" class="c"><input type="checkbox" id="c-35808244" checked=""/><div class="controls bullet"><span class="by">webaholic</span><span>|</span><a href="#35808181">parent</a><span>|</span><a href="#35807655">next</a><span>|</span><label class="collapse" for="c-35808244">[-]</label><label class="expand" for="c-35808244">[5 more]</label></div><br/><div class="children"><div class="content">Apple pays a premium to TSMC to reserve the early runs on the next gen nodes. They can do this because they can charge their users a premium for Apple devices. I am not sure the rest of the players have that much pricing power or margins.</div><br/><div id="35810984" class="c"><input type="checkbox" id="c-35810984" checked=""/><div class="controls bullet"><span class="by">MBCook</span><span>|</span><a href="#35808181">root</a><span>|</span><a href="#35808244">parent</a><span>|</span><a href="#35809230">next</a><span>|</span><label class="collapse" for="c-35810984">[-]</label><label class="expand" for="c-35810984">[2 more]</label></div><br/><div class="children"><div class="content">Plus they can guarantee big volumes. Even if only the pros get the new chip this year as rumored that’s still a very large order to make.<p>Next year it’s likely all iPhones (plus possibly iPads) will also be on the new process.<p>It looks like Apple sells around 200 million iPhones a year, and the two pro models are somewhat more popular combined than the non-pros.<p>So even if we assume 2&#x2F;3rds of Apple sales are older models, the pros would still need around 40 million chips on the new process in the first year.<p>For comparison it looks like AMD sells about 80 million chips a year, across all CPU models.</div><br/><div id="35811801" class="c"><input type="checkbox" id="c-35811801" checked=""/><div class="controls bullet"><span class="by">kramerger</span><span>|</span><a href="#35808181">root</a><span>|</span><a href="#35810984">parent</a><span>|</span><a href="#35809230">next</a><span>|</span><label class="collapse" for="c-35811801">[-]</label><label class="expand" for="c-35811801">[1 more]</label></div><br/><div class="children"><div class="content">Actually, both Apple and AMD have reduced their orders with TSMC due to expected drop in sales.<p><a href="https:&#x2F;&#x2F;wccftech.com&#x2F;tsmc-faces-order-cutback-from-major-5nm-and-7nm-customers-report&#x2F;" rel="nofollow">https:&#x2F;&#x2F;wccftech.com&#x2F;tsmc-faces-order-cutback-from-major-5nm...</a></div><br/></div></div></div></div><div id="35809230" class="c"><input type="checkbox" id="c-35809230" checked=""/><div class="controls bullet"><span class="by">smoldesu</span><span>|</span><a href="#35808181">root</a><span>|</span><a href="#35808244">parent</a><span>|</span><a href="#35810984">prev</a><span>|</span><a href="#35807655">next</a><span>|</span><label class="collapse" for="c-35809230">[-]</label><label class="expand" for="c-35809230">[2 more]</label></div><br/><div class="children"><div class="content">Nvidia does, which is why they bought out the 4nm node (and beat Apple in GPU compute by a country mile).</div><br/><div id="35809538" class="c"><input type="checkbox" id="c-35809538" checked=""/><div class="controls bullet"><span class="by">monocasa</span><span>|</span><a href="#35808181">root</a><span>|</span><a href="#35809230">parent</a><span>|</span><a href="#35807655">next</a><span>|</span><label class="collapse" for="c-35809538">[-]</label><label class="expand" for="c-35809538">[1 more]</label></div><br/><div class="children"><div class="content">Apple A16 is on N4 too.</div><br/></div></div></div></div></div></div></div></div><div id="35807858" class="c"><input type="checkbox" id="c-35807858" checked=""/><div class="controls bullet"><span class="by">bushbaba</span><span>|</span><a href="#35807655">prev</a><span>|</span><a href="#35809534">next</a><span>|</span><label class="collapse" for="c-35807858">[-]</label><label class="expand" for="c-35807858">[2 more]</label></div><br/><div class="children"><div class="content">Seems weird to compare the c7g.large vs m2 and not the largest VM sizes.</div><br/><div id="35809433" class="c"><input type="checkbox" id="c-35809433" checked=""/><div class="controls bullet"><span class="by">monocasa</span><span>|</span><a href="#35807858">parent</a><span>|</span><a href="#35809534">next</a><span>|</span><label class="collapse" for="c-35809433">[-]</label><label class="expand" for="c-35809433">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a single threaded test that doesn&#x27;t use a lot of memory.</div><br/></div></div></div></div><div id="35809534" class="c"><input type="checkbox" id="c-35809534" checked=""/><div class="controls bullet"><span class="by">cpascal</span><span>|</span><a href="#35807858">prev</a><span>|</span><a href="#35809848">next</a><span>|</span><label class="collapse" for="c-35809534">[-]</label><label class="expand" for="c-35809534">[3 more]</label></div><br/><div class="children"><div class="content">There&#x27;s probably some virtualization overhead on the c7g.large, right?</div><br/><div id="35809684" class="c"><input type="checkbox" id="c-35809684" checked=""/><div class="controls bullet"><span class="by">likeabbas</span><span>|</span><a href="#35809534">parent</a><span>|</span><a href="#35809938">next</a><span>|</span><label class="collapse" for="c-35809684">[-]</label><label class="expand" for="c-35809684">[1 more]</label></div><br/><div class="children"><div class="content">Not a lot of its using firecracker <a href="https:&#x2F;&#x2F;firecracker-microvm.github.io&#x2F;" rel="nofollow">https:&#x2F;&#x2F;firecracker-microvm.github.io&#x2F;</a></div><br/></div></div><div id="35809938" class="c"><input type="checkbox" id="c-35809938" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#35809534">parent</a><span>|</span><a href="#35809684">prev</a><span>|</span><a href="#35809848">next</a><span>|</span><label class="collapse" for="c-35809938">[-]</label><label class="expand" for="c-35809938">[1 more]</label></div><br/><div class="children"><div class="content">EC2 has <i>virtually</i> no overhead these days.</div><br/></div></div></div></div><div id="35809848" class="c"><input type="checkbox" id="c-35809848" checked=""/><div class="controls bullet"><span class="by">avrionov</span><span>|</span><a href="#35809534">prev</a><span>|</span><a href="#35807364">next</a><span>|</span><label class="collapse" for="c-35809848">[-]</label><label class="expand" for="c-35809848">[2 more]</label></div><br/><div class="children"><div class="content">For comparison I got ns&#x2F;url=194.976 on Apple MacBook Pro M1.</div><br/><div id="35810994" class="c"><input type="checkbox" id="c-35810994" checked=""/><div class="controls bullet"><span class="by">MBCook</span><span>|</span><a href="#35809848">parent</a><span>|</span><a href="#35807364">next</a><span>|</span><label class="collapse" for="c-35810994">[-]</label><label class="expand" for="c-35810994">[1 more]</label></div><br/><div class="children"><div class="content">That makes sense. The M2 is extremely similar to the M1 for a single core.</div><br/></div></div></div></div><div id="35807364" class="c"><input type="checkbox" id="c-35807364" checked=""/><div class="controls bullet"><span class="by">Thaxll</span><span>|</span><a href="#35809848">prev</a><span>|</span><a href="#35807277">next</a><span>|</span><label class="collapse" for="c-35807364">[-]</label><label class="expand" for="c-35807364">[3 more]</label></div><br/><div class="children"><div class="content">I think the performance of my oracle free instance ( arm cpu ) is 10x worse than those results.</div><br/><div id="35807419" class="c"><input type="checkbox" id="c-35807419" checked=""/><div class="controls bullet"><span class="by">dylan604</span><span>|</span><a href="#35807364">parent</a><span>|</span><a href="#35807277">next</a><span>|</span><label class="collapse" for="c-35807419">[-]</label><label class="expand" for="c-35807419">[2 more]</label></div><br/><div class="children"><div class="content">my oracle free instance uses mariadb instead of mysql, but i&#x27;m guessing you meant that as the free instance provided by oracle instead of an instance not using anything from oracle. =)</div><br/><div id="35807686" class="c"><input type="checkbox" id="c-35807686" checked=""/><div class="controls bullet"><span class="by">Thaxll</span><span>|</span><a href="#35807364">root</a><span>|</span><a href="#35807419">parent</a><span>|</span><a href="#35807277">next</a><span>|</span><label class="collapse" for="c-35807686">[-]</label><label class="expand" for="c-35807686">[1 more]</label></div><br/><div class="children"><div class="content">Yes I&#x27;m talking about: <a href="https:&#x2F;&#x2F;docs.oracle.com&#x2F;en-us&#x2F;iaas&#x2F;Content&#x2F;FreeTier&#x2F;freetier_topic-Always_Free_Resources.htm" rel="nofollow">https:&#x2F;&#x2F;docs.oracle.com&#x2F;en-us&#x2F;iaas&#x2F;Content&#x2F;FreeTier&#x2F;freetier...</a><p>Ampere A1 Compute instances</div><br/></div></div></div></div></div></div><div id="35807277" class="c"><input type="checkbox" id="c-35807277" checked=""/><div class="controls bullet"><span class="by">smoldesu</span><span>|</span><a href="#35807364">prev</a><span>|</span><a href="#35807493">next</a><span>|</span><label class="collapse" for="c-35807277">[-]</label><label class="expand" for="c-35807277">[3 more]</label></div><br/><div class="children"><div class="content">&gt; Note that you cannot blindly correct for frequency in this manner because it is not physically possible to just change the frequency as I did<p>They&#x27;re also not the same core architecture? Comparing ARM chips that conform to the same spec won&#x27;t necessarily scale the same across frequencies. Even if all of these CPUs did have scaling clock speeds, their core logic is not the same. Hell, even the Firestorm and Icestorm cores on the M1 SOC shouldn&#x27;t be considered directly comparable if you scale the clock speeds.</div><br/><div id="35808035" class="c"><input type="checkbox" id="c-35808035" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#35807277">parent</a><span>|</span><a href="#35807498">next</a><span>|</span><label class="collapse" for="c-35808035">[-]</label><label class="expand" for="c-35808035">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s the point. He knows they&#x27;re different architectures (although X1 and V1 are related) so normalizing frequency exposes the architectural differences.</div><br/></div></div></div></div></div></div></div></div></div></body></html>