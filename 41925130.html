<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1730019650594" as="style"/><link rel="stylesheet" href="styles.css?v=1730019650594"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://thevccorner.substack.com/p/from-sci-fi-to-reality">Using a BCI with LLM for enabling ALS patients to speak again with family</a> <span class="domain">(<a href="https://thevccorner.substack.com">thevccorner.substack.com</a>)</span></div><div class="subtext"><span>vasco_</span> | <span>17 comments</span></div><br/><div><div id="41960732" class="c"><input type="checkbox" id="c-41960732" checked=""/><div class="controls bullet"><span class="by">JPLeRouzic</span><span>|</span><a href="#41959965">next</a><span>|</span><label class="collapse" for="c-41960732">[-]</label><label class="expand" for="c-41960732">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s good that people are trying to help ALS patients with technology, but most ALS patients are not in the terminal phase of their disease.<p>Most pALS have difficulties speaking, their voice is weak and sometimes there is a pronunciation problem. Many pALS use simple assistive devices like a personal voice amplifier, or a text to speech device.<p>Sometimes the problem is that &quot;normal&quot; people think pALS are deaf so they speak loudly but the patient can hear quite normally. Or doctors or other people ignore the patient and insist on speaking to the carer as if the patient cannot comprehend it.<p><a href="https:&#x2F;&#x2F;alsnewstoday.com&#x2F;forums&#x2F;forums&#x2F;topic&#x2F;artificial-voice-speech-equipment&#x2F;" rel="nofollow">https:&#x2F;&#x2F;alsnewstoday.com&#x2F;forums&#x2F;forums&#x2F;topic&#x2F;artificial-voic...</a><p><a href="https:&#x2F;&#x2F;alsnewstoday.com&#x2F;columns&#x2F;microphone-voice-hear&#x2F;" rel="nofollow">https:&#x2F;&#x2F;alsnewstoday.com&#x2F;columns&#x2F;microphone-voice-hear&#x2F;</a></div><br/></div></div><div id="41959965" class="c"><input type="checkbox" id="c-41959965" checked=""/><div class="controls bullet"><span class="by">jazzyjackson</span><span>|</span><a href="#41960732">prev</a><span>|</span><a href="#41959726">next</a><span>|</span><label class="collapse" for="c-41959965">[-]</label><label class="expand" for="c-41959965">[1 more]</label></div><br/><div class="children"><div class="content">Have they only demo&#x27;d it with patients who can&#x27;t speak? Seems like if they cracked mind reading it would work just as well on someone with full faculties to confirm it&#x27;s accurate.</div><br/></div></div><div id="41959726" class="c"><input type="checkbox" id="c-41959726" checked=""/><div class="controls bullet"><span class="by">labelra</span><span>|</span><a href="#41959965">prev</a><span>|</span><a href="#41925131">next</a><span>|</span><label class="collapse" for="c-41959726">[-]</label><label class="expand" for="c-41959726">[6 more]</label></div><br/><div class="children"><div class="content">Are there any details on how this works? Based on what is available in the linked article, it looks like they have an LLM+RAG and are trying to pass off the responses as speech from the user. Done with full transparency, and right protections, this could be useful, but calling it BCI, and overselling it as user&#x27;s voice (especially given voice cloning is also being done) can be misrepresenting it.</div><br/><div id="41959776" class="c"><input type="checkbox" id="c-41959776" checked=""/><div class="controls bullet"><span class="by">Sanzig</span><span>|</span><a href="#41959726">parent</a><span>|</span><a href="#41959738">next</a><span>|</span><label class="collapse" for="c-41959776">[-]</label><label class="expand" for="c-41959776">[4 more]</label></div><br/><div class="children"><div class="content">Agreed - I don&#x27;t want to come across as negative, but this is certainly in the &quot;extraordinary claims&quot; category for me right now. If this works, it&#x27;s obviously <i>huge</i>, but I really want to see third party validation before I can let go of my skepticism.<p>I would be very curious to hear about interviews with the patients (conducted through their current means of communication, eg: eye gaze interfaces). Are they finding that the speech generated by the system reflects their intentions accurately?<p>EDIT: the EEG peripheral they are using is 4 channels &#x2F; 250 Hz sample rate. I freely admit I have little knowledge of neuroscience and happily defer to the experts, but that really doesn&#x27;t seem like a lot of data to be able to infer speech intentions.</div><br/><div id="41959842" class="c"><input type="checkbox" id="c-41959842" checked=""/><div class="controls bullet"><span class="by">throwup238</span><span>|</span><a href="#41959726">root</a><span>|</span><a href="#41959776">parent</a><span>|</span><a href="#41959738">next</a><span>|</span><label class="collapse" for="c-41959842">[-]</label><label class="expand" for="c-41959842">[3 more]</label></div><br/><div class="children"><div class="content">Even if the LLM hallucinates every word, just knowing when to say something versus stay quiet based on EEG data would be a huge breakthrough.</div><br/><div id="41959901" class="c"><input type="checkbox" id="c-41959901" checked=""/><div class="controls bullet"><span class="by">Sanzig</span><span>|</span><a href="#41959726">root</a><span>|</span><a href="#41959842">parent</a><span>|</span><a href="#41959738">next</a><span>|</span><label class="collapse" for="c-41959901">[-]</label><label class="expand" for="c-41959901">[2 more]</label></div><br/><div class="children"><div class="content">If that&#x27;s all they were doing - showing when the patient wanted to speak - that would be fine. Presenting speech as attributable to that patient, though? That feels irresponsible without solid evidence, or at least informing the families of the risk that the interface may be just totally hallucinating. Imagine someone talking to an LLM they think is their loved one, all while that person has to watch.</div><br/><div id="41959956" class="c"><input type="checkbox" id="c-41959956" checked=""/><div class="controls bullet"><span class="by">throwup238</span><span>|</span><a href="#41959726">root</a><span>|</span><a href="#41959901">parent</a><span>|</span><a href="#41959738">next</a><span>|</span><label class="collapse" for="c-41959956">[-]</label><label class="expand" for="c-41959956">[1 more]</label></div><br/><div class="children"><div class="content">You’ll get no argument from me there. The whole LLM part seems like a gimmick unless it’s doing error correction on a messy data stream like a drunk person fat fingering in a question to ChatGPT except with an EEG. It might be a really fancy autocorrect.<p>I’m just saying that EEG data is so unreliable and requires so much calibration&#x2F;training per person that reliably isolating speech in paralyzed patient would be a significant development.</div><br/></div></div></div></div></div></div></div></div><div id="41959738" class="c"><input type="checkbox" id="c-41959738" checked=""/><div class="controls bullet"><span class="by">4b11b4</span><span>|</span><a href="#41959726">parent</a><span>|</span><a href="#41959776">prev</a><span>|</span><a href="#41925131">next</a><span>|</span><label class="collapse" for="c-41959738">[-]</label><label class="expand" for="c-41959738">[1 more]</label></div><br/><div class="children"><div class="content">seems like they have built on top of HALO using generative AI now (with partnership from unababel?)</div><br/></div></div></div></div><div id="41925131" class="c"><input type="checkbox" id="c-41925131" checked=""/><div class="controls bullet"><span class="by">vasco_</span><span>|</span><a href="#41959726">prev</a><span>|</span><a href="#41959797">next</a><span>|</span><label class="collapse" for="c-41925131">[-]</label><label class="expand" for="c-41925131">[1 more]</label></div><br/><div class="children"><div class="content">Halo, developed by Unbabel, combines a non invasive BCI with an LLM to enable ALS patients to regain the ability to talk with loved ones. The search for a CEO is on.</div><br/></div></div><div id="41959797" class="c"><input type="checkbox" id="c-41959797" checked=""/><div class="controls bullet"><span class="by">xk_id</span><span>|</span><a href="#41925131">prev</a><span>|</span><a href="#41959367">next</a><span>|</span><label class="collapse" for="c-41959797">[-]</label><label class="expand" for="c-41959797">[5 more]</label></div><br/><div class="children"><div class="content">Those non-invasive headbands (which work very differently from implanted electrodes) are notoriously inaccurate at recording brain signals. Even scientific studies, which use advanced setups like the 10-20 system for scalp EEG, face unsolved challenges in removing noise from the data and in using the data to reconstruct underlying brain activity [0] – let alone making meaningful inferences about it.<p>Patients with locked-in syndrome (one of the use cases mentioned in the article, also called a pseudo-coma), or with other disorders of consciousness, are unable to protest, or to confirm the accuracy of the <i>generative</i> message which is being attributed to them. Communicating on your <i>own</i> terms and in your <i>own</i> words is fundamental to human dignity.<p>Meanwhile, this coincides with lukewarm reception of generative AI from consumers; perhaps it is the lack of autonomy of locked-in patients, which makes them an interesting segment to this new generation of ventures, scrambling for a ROI on the enormous over-investment in the sector.<p>The conference venues look lush tho.<p>[0] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Electroencephalography#Artifacts" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Electroencephalography#Artifac...</a></div><br/><div id="41959837" class="c"><input type="checkbox" id="c-41959837" checked=""/><div class="controls bullet"><span class="by">y-curious</span><span>|</span><a href="#41959797">parent</a><span>|</span><a href="#41960392">next</a><span>|</span><label class="collapse" for="c-41959837">[-]</label><label class="expand" for="c-41959837">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve spoken to a lot of smart people on the topic of EEG (I&#x27;m in a very related field). I agree with you.<p>It&#x27;s an extremely powerful tool for diagnosis of a limited range of conditions but it is not magic. Electrical signal gets attenuated heavily when signals are not on the outside of the brain. Even still, a headband like this is susceptible to noise from movement and other factors. You either need to correct for this with AI, which introduces a second source for error, or you need a very still user. I&#x27;m not convinced by the ability to &quot;read minds&quot; with the technology; I would need the man in the video answer some specific questions to be convinced.<p>Is this better than not being able to communicate at all? Yes.</div><br/><div id="41959860" class="c"><input type="checkbox" id="c-41959860" checked=""/><div class="controls bullet"><span class="by">Sanzig</span><span>|</span><a href="#41959797">root</a><span>|</span><a href="#41959837">parent</a><span>|</span><a href="#41960392">next</a><span>|</span><label class="collapse" for="c-41959860">[-]</label><label class="expand" for="c-41959860">[2 more]</label></div><br/><div class="children"><div class="content">What they need to provide is surveys from the patients without the device (even locked in patients can often communicate slowly via eye-scan interfaces). How well do the patients rate the system at aligning with what they want to say?<p>If they don&#x27;t find that it aligns at all, then honestly that <i>is</i> worse than nothing. Imagine being locked in and your family communicating with an LLM pretending to be you - all while you have to watch and can&#x27;t do anything about it.</div><br/><div id="41959915" class="c"><input type="checkbox" id="c-41959915" checked=""/><div class="controls bullet"><span class="by">anonzzzies</span><span>|</span><a href="#41959797">root</a><span>|</span><a href="#41959860">parent</a><span>|</span><a href="#41960392">next</a><span>|</span><label class="collapse" for="c-41959915">[-]</label><label class="expand" for="c-41959915">[1 more]</label></div><br/><div class="children"><div class="content">It might be beneficial to the family though, but indeed not to you.</div><br/></div></div></div></div></div></div><div id="41960392" class="c"><input type="checkbox" id="c-41960392" checked=""/><div class="controls bullet"><span class="by">sakras</span><span>|</span><a href="#41959797">parent</a><span>|</span><a href="#41959837">prev</a><span>|</span><a href="#41959367">next</a><span>|</span><label class="collapse" for="c-41960392">[-]</label><label class="expand" for="c-41960392">[1 more]</label></div><br/><div class="children"><div class="content">I spent a long time trying to do some sort of machine learning over the OpenBCI helmet&#x27;s data with the eventual goal of moving a cursor, but I didn&#x27;t seem to get anywhere. The data was indeed _extremely_ noisy, and I don&#x27;t believe my model ever converged to anything useful.<p>That said, I was just a high schooler and so my method of collecting training data was to run the script and &quot;think really hard about moving left&quot;. Probably could have been a good deal more sophisticated too.</div><br/></div></div></div></div><div id="41959367" class="c"><input type="checkbox" id="c-41959367" checked=""/><div class="controls bullet"><span class="by">xk_id</span><span>|</span><a href="#41959797">prev</a><span>|</span><label class="collapse" for="c-41959367">[-]</label><label class="expand" for="c-41959367">[2 more]</label></div><br/><div class="children"><div class="content">[flagged]</div><br/><div id="41959377" class="c"><input type="checkbox" id="c-41959377" checked=""/><div class="controls bullet"><span class="by">dang</span><span>|</span><a href="#41959367">parent</a><span>|</span><label class="collapse" for="c-41959377">[-]</label><label class="expand" for="c-41959377">[1 more]</label></div><br/><div class="children"><div class="content">&quot;<i>Please don&#x27;t fulminate.</i>&quot;<p>&quot;<i>Please don&#x27;t post shallow dismissals, especially of other people&#x27;s work. A good critical comment teaches us something.</i>&quot;<p><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;newsguidelines.html">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;newsguidelines.html</a></div><br/></div></div></div></div></div></div></div></div></div></body></html>