<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1700557264901" as="style"/><link rel="stylesheet" href="styles.css?v=1700557264901"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/joennlae/halutmatmul">Show HN: Stella Nera – Maddness Hardware Accelerator</a> <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>joennlae</span> | <span>4 comments</span></div><br/><div><div id="38361155" class="c"><input type="checkbox" id="c-38361155" checked=""/><div class="controls bullet"><span class="by">fxtentacle</span><span>|</span><a href="#38361156">next</a><span>|</span><label class="collapse" for="c-38361155">[-]</label><label class="expand" for="c-38361155">[1 more]</label></div><br/><div class="children"><div class="content">I am surprised that they do not mention comparing against quantized matrix multiplication because their &quot;encoding&quot; appears to be something like a quantization step with unevenly sized buckets. And then their approximate multiplication step to me looks like multiplying a quantized input vector against a 1-bit quantized matrix.<p>But overall this is an extremely exciting development because it shows how one could convert a NN into an efficient hardware implementation. And due to them working only on quantized data with LUTs, one can also embed low-dimensional matrices directly into the silicon.</div><br/></div></div><div id="38361156" class="c"><input type="checkbox" id="c-38361156" checked=""/><div class="controls bullet"><span class="by">larodi</span><span>|</span><a href="#38361155">prev</a><span>|</span><a href="#38361116">next</a><span>|</span><label class="collapse" for="c-38361156">[-]</label><label class="expand" for="c-38361156">[1 more]</label></div><br/><div class="children"><div class="content">Next level algorithm design with approximation of everything. I’m getting high from such proposed technology.</div><br/></div></div><div id="38361116" class="c"><input type="checkbox" id="c-38361116" checked=""/><div class="controls bullet"><span class="by">ggambetta</span><span>|</span><a href="#38361156">prev</a><span>|</span><label class="collapse" for="c-38361116">[-]</label><label class="expand" for="c-38361116">[1 more]</label></div><br/><div class="children"><div class="content">&quot;Black star&quot; in Italian. Cool name :)</div><br/></div></div></div></div></div></div></div></body></html>