<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1728378068696" as="style"/><link rel="stylesheet" href="styles.css?v=1728378068696"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://johncostella.com/magic/">The magic (image resampling) kernel</a> <span class="domain">(<a href="https://johncostella.com">johncostella.com</a>)</span></div><div class="subtext"><span>BoingBoomTschak</span> | <span>28 comments</span></div><br/><div><div id="41770028" class="c"><input type="checkbox" id="c-41770028" checked=""/><div class="controls bullet"><span class="by">svantana</span><span>|</span><a href="#41771612">next</a><span>|</span><label class="collapse" for="c-41770028">[-]</label><label class="expand" for="c-41770028">[4 more]</label></div><br/><div class="children"><div class="content">I feel like this article is really overselling this filter. A 4-point symmetric interpolation kernel can be parameterized as [k, 1-k, 1-k, k]&#x2F;2, i.e. it has a single degree of freedom. k=-1&#x2F;4 is bicubic, k=1&#x2F;4 is this &#x27;magic&#x27;, and k=0 is bilinear. Bicubic is sharper, and &#x27;magic&#x27; has better alias rejection. Which looks better depends on the image and the viewer&#x27;s subjective preference. For insta photos, it&#x27;s probably better to go for &#x27;magic&#x27;, while for text, one might prefer bicubic. Neither is &quot;simpler&quot; as this article keeps suggesting, they just have different filter coefficients, that&#x27;s all. But any other value of k is an equally valid choice.</div><br/><div id="41770208" class="c"><input type="checkbox" id="c-41770208" checked=""/><div class="controls bullet"><span class="by">BoingBoomTschak</span><span>|</span><a href="#41770028">parent</a><span>|</span><a href="#41771612">next</a><span>|</span><label class="collapse" for="c-41770208">[-]</label><label class="expand" for="c-41770208">[3 more]</label></div><br/><div class="children"><div class="content">It certainly is. Especially lacking in proper comparisons of the final filter with the competition. I myself default to RobidouxSharp for downscaling and something like <a href="https:&#x2F;&#x2F;www.imagemagick.org&#x2F;discourse-server&#x2F;viewtopic.php?t=21695" rel="nofollow">https:&#x2F;&#x2F;www.imagemagick.org&#x2F;discourse-server&#x2F;viewtopic.php?t...</a> for upscaling.</div><br/><div id="41772115" class="c"><input type="checkbox" id="c-41772115" checked=""/><div class="controls bullet"><span class="by">BoingBoomTschak</span><span>|</span><a href="#41770028">root</a><span>|</span><a href="#41770208">parent</a><span>|</span><a href="#41771612">next</a><span>|</span><label class="collapse" for="c-41772115">[-]</label><label class="expand" for="c-41772115">[2 more]</label></div><br/><div class="children"><div class="content">Took the time to make such a comparison using the article&#x27;s sample images (even if the filter isn&#x27;t sharpened in those), same thrice doubling of the small picture: <a href="http:&#x2F;&#x2F;0x0.st&#x2F;XEEZ.png" rel="nofollow">http:&#x2F;&#x2F;0x0.st&#x2F;XEEZ.png</a><p>I find such a test strange and irrelevant, though.</div><br/><div id="41772349" class="c"><input type="checkbox" id="c-41772349" checked=""/><div class="controls bullet"><span class="by">dahart</span><span>|</span><a href="#41770028">root</a><span>|</span><a href="#41772115">parent</a><span>|</span><a href="#41771612">next</a><span>|</span><label class="collapse" for="c-41772349">[-]</label><label class="expand" for="c-41772349">[1 more]</label></div><br/><div class="children"><div class="content">Ooh the animated comparison is really helpful. I couldn’t see it in the article, but with your version the Magic version feels flatter, almost like it’s a bokeh blur and not just a low pass. The Sigmoid seems far better than either Magic or Bicubic.</div><br/></div></div></div></div></div></div></div></div><div id="41771612" class="c"><input type="checkbox" id="c-41771612" checked=""/><div class="controls bullet"><span class="by">raphlinus</span><span>|</span><a href="#41770028">prev</a><span>|</span><a href="#41771026">next</a><span>|</span><label class="collapse" for="c-41771612">[-]</label><label class="expand" for="c-41771612">[3 more]</label></div><br/><div class="children"><div class="content">The page mostly talks about image resampling where the goal is more or less preserving all frequencies, but it&#x27;s also extremely effective at implementing Gaussian blur. Basically, you do n iterations of sampling by 1&#x2F;2 using this kernel, followed by a very small FIR filter, then n iterations of upsampling 2x using the same kernel. Here, n is essentially log2 of the blur radius, and the total amount of computation is essentially invariant to that radius. All these computations are efficient on GPU - in particular, the upsampling can be done using vanilla bilinear texture sampling (which is very cheap), just being slightly clever about the fractional coordinates.<p>It works well because, as stated, the kernel does a good job rejecting frequencies prone to aliasing. So, in particular, you don&#x27;t get any real quality loss from doing 2x scale changes as opposed to bigger steps (and thus considerably larger FIR support).<p>I have some Python notebooks with some of these results, haven&#x27;t gotten around to publishing them yet.</div><br/><div id="41773560" class="c"><input type="checkbox" id="c-41773560" checked=""/><div class="controls bullet"><span class="by">leguminous</span><span>|</span><a href="#41771612">parent</a><span>|</span><a href="#41773228">next</a><span>|</span><label class="collapse" for="c-41773560">[-]</label><label class="expand" for="c-41773560">[1 more]</label></div><br/><div class="children"><div class="content">I have done something like this with a Lanczos kernel (a=1) downsizing repeatedly by 2x, a small Gaussian kernel, and then repeatedly upsizing by 2x with simple hardware bilinear sampling.<p>The (2D) Lanczos downsizing can be done with only four samples using the bilinear sampling tricks that you mention, and I avoided expensive trigonometric functions, divisions, and the singularity at 0 by using an even 8th order polynomial approximation. I would be curious to see the results using this kernel, but the Lanczos is so far the best that I&#x27;ve tried.</div><br/></div></div><div id="41773228" class="c"><input type="checkbox" id="c-41773228" checked=""/><div class="controls bullet"><span class="by">kragen</span><span>|</span><a href="#41771612">parent</a><span>|</span><a href="#41773560">prev</a><span>|</span><a href="#41771026">next</a><span>|</span><label class="collapse" for="c-41773228">[-]</label><label class="expand" for="c-41773228">[1 more]</label></div><br/><div class="children"><div class="content">I look forward to being able to read your notebooks!</div><br/></div></div></div></div><div id="41771026" class="c"><input type="checkbox" id="c-41771026" checked=""/><div class="controls bullet"><span class="by">herf</span><span>|</span><a href="#41771612">prev</a><span>|</span><a href="#41770954">next</a><span>|</span><label class="collapse" for="c-41771026">[-]</label><label class="expand" for="c-41771026">[1 more]</label></div><br/><div class="children"><div class="content">This uniform b-spline is the same one used often as a &quot;Gaussian&quot; approximation (three box filters) - see Paul Heckbert&#x27;s 1986 paper here (apparently done at NYIT in the early 1980s with help from Ken Perlin):<p><a href="https:&#x2F;&#x2F;dl.acm.org&#x2F;doi&#x2F;pdf&#x2F;10.1145&#x2F;15886.15921" rel="nofollow">https:&#x2F;&#x2F;dl.acm.org&#x2F;doi&#x2F;pdf&#x2F;10.1145&#x2F;15886.15921</a></div><br/></div></div><div id="41770954" class="c"><input type="checkbox" id="c-41770954" checked=""/><div class="controls bullet"><span class="by">rnhmjoj</span><span>|</span><a href="#41771026">prev</a><span>|</span><a href="#41770014">next</a><span>|</span><label class="collapse" for="c-41770954">[-]</label><label class="expand" for="c-41770954">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Fourthly, and most importantly, as noted above: m(x) is a partition of unity: it “fits into itself”; [...] if we place a copy of m(x) at integral positions, and sum up the results, we get a constant (unity) across all x. [...] This remarkable property can help prevent “beat” artifacts across a resized image.<p>So, basically the reason why this works better than other visually similar filters is that it happens to satify the Nyquist ISI criterion[1].<p>[1]: <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Nyquist_ISI_criterion" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Nyquist_ISI_criterion</a></div><br/></div></div><div id="41770014" class="c"><input type="checkbox" id="c-41770014" checked=""/><div class="controls bullet"><span class="by">pseudosavant</span><span>|</span><a href="#41770954">prev</a><span>|</span><a href="#41770955">next</a><span>|</span><label class="collapse" for="c-41770014">[-]</label><label class="expand" for="c-41770014">[4 more]</label></div><br/><div class="children"><div class="content">I was surprised I hadn&#x27;t heard of this, or his related project JPEG-Clear. I have thought for years that the JPEG-Clear method is how responsive images should have been handled in a browser. A single-file format that can be progressively downloaded only up to the resolution it is being displayed at. If you zoom in, the rest of the data can be downloaded for more detail. Doesn&#x27;t require complex multi-file image authoring steps, keeps simple &lt;img src&gt; grammar, and is more efficient than downloading multiple completely separate images.</div><br/><div id="41770803" class="c"><input type="checkbox" id="c-41770803" checked=""/><div class="controls bullet"><span class="by">meindnoch</span><span>|</span><a href="#41770014">parent</a><span>|</span><a href="#41770955">next</a><span>|</span><label class="collapse" for="c-41770803">[-]</label><label class="expand" for="c-41770803">[3 more]</label></div><br/><div class="children"><div class="content">JPEG-Clear? The guy &quot;reinvented&quot; progressive JPEGs?</div><br/><div id="41774397" class="c"><input type="checkbox" id="c-41774397" checked=""/><div class="controls bullet"><span class="by">Dwedit</span><span>|</span><a href="#41770014">root</a><span>|</span><a href="#41770803">parent</a><span>|</span><a href="#41770955">next</a><span>|</span><label class="collapse" for="c-41774397">[-]</label><label class="expand" for="c-41774397">[2 more]</label></div><br/><div class="children"><div class="content">Loading a more detailed version of an image as you zoom in is different from what a progressive JPEG does.<p>Loading a Progressive JPEG means you still unconditionally load the entire file, you just are able to show a low detail version before it is fully loaded.  The last time I saw a progressive JPEG actually take time to load was when I had dialup.</div><br/><div id="41774752" class="c"><input type="checkbox" id="c-41774752" checked=""/><div class="controls bullet"><span class="by">meindnoch</span><span>|</span><a href="#41770014">root</a><span>|</span><a href="#41774397">parent</a><span>|</span><a href="#41770955">next</a><span>|</span><label class="collapse" for="c-41774752">[-]</label><label class="expand" for="c-41774752">[1 more]</label></div><br/><div class="children"><div class="content">1. You can terminate the loading process as soon as you&#x27;re satisfied with the quality. It&#x27;s just that browser don&#x27;t do that.<p>2. The OPs JPEG-Clear proposal [1] also loads the entire file no matter what. It&#x27;s literally just a reinvention of progressive JPEGs, presenting it as something novel.<p>[1] <a href="https:&#x2F;&#x2F;johncostella.com&#x2F;jpegclear&#x2F;" rel="nofollow">https:&#x2F;&#x2F;johncostella.com&#x2F;jpegclear&#x2F;</a></div><br/></div></div></div></div></div></div></div></div><div id="41770955" class="c"><input type="checkbox" id="c-41770955" checked=""/><div class="controls bullet"><span class="by">layer8</span><span>|</span><a href="#41770014">prev</a><span>|</span><a href="#41769360">next</a><span>|</span><label class="collapse" for="c-41770955">[-]</label><label class="expand" for="c-41770955">[1 more]</label></div><br/><div class="children"><div class="content">In the “Bicubic: note the artifacts” comparison images, the bicubic version, regardless of the aliasing, is less blurry and has more detail than the “magic kernel” version. I therefore don’t agree that the latter is “visually, far superior”. There is at least some trade-off.</div><br/></div></div><div id="41769360" class="c"><input type="checkbox" id="c-41769360" checked=""/><div class="controls bullet"><span class="by">bhouston</span><span>|</span><a href="#41770955">prev</a><span>|</span><a href="#41769887">next</a><span>|</span><label class="collapse" for="c-41769360">[-]</label><label class="expand" for="c-41769360">[2 more]</label></div><br/><div class="children"><div class="content">Super cool.  How did I not know about this before?</div><br/><div id="41769822" class="c"><input type="checkbox" id="c-41769822" checked=""/><div class="controls bullet"><span class="by">BoingBoomTschak</span><span>|</span><a href="#41769360">parent</a><span>|</span><a href="#41769887">next</a><span>|</span><label class="collapse" for="c-41769822">[-]</label><label class="expand" for="c-41769822">[1 more]</label></div><br/><div class="children"><div class="content">I was also pretty surprised, as I consider myself decently knowledgeable in the field. Learned of it via <a href="https:&#x2F;&#x2F;github.com&#x2F;libvips&#x2F;libvips&#x2F;issues&#x2F;4089">https:&#x2F;&#x2F;github.com&#x2F;libvips&#x2F;libvips&#x2F;issues&#x2F;4089</a>.</div><br/></div></div></div></div><div id="41769887" class="c"><input type="checkbox" id="c-41769887" checked=""/><div class="controls bullet"><span class="by">BoingBoomTschak</span><span>|</span><a href="#41769360">prev</a><span>|</span><a href="#41770755">next</a><span>|</span><label class="collapse" for="c-41769887">[-]</label><label class="expand" for="c-41769887">[1 more]</label></div><br/><div class="children"><div class="content">These previous discussions (including the author in the second one) were pretty fruitful:<p><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=10404517">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=10404517</a> (2015)<p><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=26513518">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=26513518</a> (2021)</div><br/></div></div><div id="41770755" class="c"><input type="checkbox" id="c-41770755" checked=""/><div class="controls bullet"><span class="by">DustinBrett</span><span>|</span><a href="#41769887">prev</a><span>|</span><a href="#41770692">next</a><span>|</span><label class="collapse" for="c-41770755">[-]</label><label class="expand" for="c-41770755">[1 more]</label></div><br/><div class="children"><div class="content">Would be cooler if images on FB didn&#x27;t suck.</div><br/></div></div><div id="41770692" class="c"><input type="checkbox" id="c-41770692" checked=""/><div class="controls bullet"><span class="by">CyberDildonics</span><span>|</span><a href="#41770755">prev</a><span>|</span><label class="collapse" for="c-41770692">[-]</label><label class="expand" for="c-41770692">[9 more]</label></div><br/><div class="children"><div class="content">I guess anything is magic if you don&#x27;t know how it works or if you need some clicks to promote your personal site.<p>This is basically a slightly different gaussian kernel and the &quot;incredible results&quot; of a small image becoming a larger resolution blurry image is completely normal.<p>Also you don&#x27;t want negative lobes in image kernels no matter how theoretically ideal it is, because it will give you ringing artifacts.<p>If you work with image kernels &#x2F; reconstruction filters long enough you will eventually learn that 90% of the time you want a gauss kernel.</div><br/><div id="41771538" class="c"><input type="checkbox" id="c-41771538" checked=""/><div class="controls bullet"><span class="by">pixelpoet</span><span>|</span><a href="#41770692">parent</a><span>|</span><label class="collapse" for="c-41771538">[-]</label><label class="expand" for="c-41771538">[8 more]</label></div><br/><div class="children"><div class="content">&gt; If you work with image kernels &#x2F; reconstruction filters long enough you will eventually learn that 90% of the time you want a gauss kernel.<p>Strongly disagree, and my commercial software is known for its high image quality and antialiasing. Gaussian is way too blurry unless you&#x27;re rendering for film.</div><br/><div id="41772333" class="c"><input type="checkbox" id="c-41772333" checked=""/><div class="controls bullet"><span class="by">dahart</span><span>|</span><a href="#41770692">root</a><span>|</span><a href="#41771538">parent</a><span>|</span><a href="#41772035">next</a><span>|</span><label class="collapse" for="c-41772333">[-]</label><label class="expand" for="c-41772333">[6 more]</label></div><br/><div class="children"><div class="content">In my film experience, I think most film people don’t like Gaussian either; too blurry for them as well. At least, I’ve sat in on filter evaluations with a couple of directors &amp; VFX sups many years ago, and they said Gaussian was too soft and preferred a sharper Mitchell. But I am curious, perhaps similar to the sibling comment - how do you determine the optimal Gaussian width? You can certainly go narrower&#x2F;sharper and get less blur at the cost of more artifacts similar to a sharper filter, right? BTW have we discussed this recently? ;) I love Gaussian’s ability to hide any hint of the pixel grid, which I find very few filters can do. I also tend to believe that, perceptually speaking, over-blurring slightly doesn’t hurt while under-blurring does, especially for moving things, but that might be more personal bias than objective reality. I would be interested to look at any comparisons or results from your software or in general, if you have some.</div><br/><div id="41774125" class="c"><input type="checkbox" id="c-41774125" checked=""/><div class="controls bullet"><span class="by">a_e_k</span><span>|</span><a href="#41770692">root</a><span>|</span><a href="#41772333">parent</a><span>|</span><a href="#41772715">next</a><span>|</span><label class="collapse" for="c-41774125">[-]</label><label class="expand" for="c-41774125">[1 more]</label></div><br/><div class="children"><div class="content">Historically, Pixar&#x27;s RenderMan defaulted to a 2x2 Gaussian filter [1], and from what I can see, that hasn&#x27;t changed [2].<p>Essentially it uses a truncated isotropic (non-separable) Gaussian defined by exp(-2.0 * (x*x + y*y)) with a 2x2 pixel support [3], which is slightly soft and completely avoids ringing.<p>Gaussian also plays very nicely with filtered importance sampling [4] since it has no negative lobes.<p>(Though I remember a number of studios using RenderMan preferring filters with a bit of sharpening.)<p>[1] <a href="https:&#x2F;&#x2F;paulbourke.net&#x2F;dataformats&#x2F;rib&#x2F;RISpec3_2.pdf#page=40" rel="nofollow">https:&#x2F;&#x2F;paulbourke.net&#x2F;dataformats&#x2F;rib&#x2F;RISpec3_2.pdf#page=40</a><p>[2] <a href="https:&#x2F;&#x2F;rmanwiki-26.pixar.com&#x2F;space&#x2F;REN26&#x2F;19661819&#x2F;Filtering" rel="nofollow">https:&#x2F;&#x2F;rmanwiki-26.pixar.com&#x2F;space&#x2F;REN26&#x2F;19661819&#x2F;Filtering</a><p>[3] <a href="https:&#x2F;&#x2F;paulbourke.net&#x2F;dataformats&#x2F;rib&#x2F;RISpec3_2.pdf#page=207" rel="nofollow">https:&#x2F;&#x2F;paulbourke.net&#x2F;dataformats&#x2F;rib&#x2F;RISpec3_2.pdf#page=20...</a><p>[4] <a href="https:&#x2F;&#x2F;citeseerx.ist.psu.edu&#x2F;document?repid=rep1&amp;type=pdf&amp;doi=d5d120ae2c47e38fc4a2d379cfcf9953f5e23ada" rel="nofollow">https:&#x2F;&#x2F;citeseerx.ist.psu.edu&#x2F;document?repid=rep1&amp;type=pdf&amp;d...</a></div><br/></div></div><div id="41772715" class="c"><input type="checkbox" id="c-41772715" checked=""/><div class="controls bullet"><span class="by">CyberDildonics</span><span>|</span><a href="#41770692">root</a><span>|</span><a href="#41772333">parent</a><span>|</span><a href="#41774125">prev</a><span>|</span><a href="#41772035">next</a><span>|</span><label class="collapse" for="c-41772715">[-]</label><label class="expand" for="c-41772715">[4 more]</label></div><br/><div class="children"><div class="content">The truth is that when people test out filters they are looking close up at the pixels, trying to squeeze out detail, but the reality is that whatever minute detail might get slightly softened by a 2.2-2.5 gauss filter will get chewed up by the process of color correction and compression anyway.<p>The aliasing you can end up with from a mitchell filter though can be noticeable all through the process.  Not only that, but what will the compositor do when they see the aliasing? They&#x27;ll blur it.<p>Basically it is trying to squeeze blood from a stone and the image out of renderer is going to be far sharper than anyone will see because it will go through multiple stages. Even compositing almost never leaves a render verbatim. There is usually some sort of slight softening, chromatic aberration, lens distortion and&#x2F;or other transforms that require resampling anyway.<p>It is picking up pennies in front of a bulldozer and only causes problems to have a filter that&#x27;s too sharp, let alone one that has negative lobes.</div><br/><div id="41774245" class="c"><input type="checkbox" id="c-41774245" checked=""/><div class="controls bullet"><span class="by">a_e_k</span><span>|</span><a href="#41770692">root</a><span>|</span><a href="#41772715">parent</a><span>|</span><a href="#41773612">next</a><span>|</span><label class="collapse" for="c-41774245">[-]</label><label class="expand" for="c-41774245">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Basically it is trying to squeeze blood from a stone and the image out of renderer is going to be far sharper than anyone will see because it will go through multiple stages. Even compositing almost never leaves a render verbatim.<p>Don&#x27;t forget that these days, it&#x27;s all going through some ML-based denoiser, anyway.  I wouldn&#x27;t be surprised if filter choice is nearly irrelevant at this point (except for training).</div><br/></div></div><div id="41773612" class="c"><input type="checkbox" id="c-41773612" checked=""/><div class="controls bullet"><span class="by">dahart</span><span>|</span><a href="#41770692">root</a><span>|</span><a href="#41772715">parent</a><span>|</span><a href="#41774245">prev</a><span>|</span><a href="#41772035">next</a><span>|</span><label class="collapse" for="c-41773612">[-]</label><label class="expand" for="c-41773612">[2 more]</label></div><br/><div class="children"><div class="content">Oh FWIW, the sessions I remember most vividly were for the first Shrek movie, which was printed to actual film, projected to a theater screen, and final render was at slightly lower than 1080p resolution. The digitizing to film does add a little blur, of course, but not a lot since the resolution was so low and the pixels so big. The filter did kinda matter, and the compositors did not add extra blur in this case. I was highly impressed with how sensitive the director and lighting&#x2F;fx supes were to filter differences, and how quickly they could spot them in animated clips that were often less than one second long. The main thing they were doing was trying to avoid texture sizzle without overblurring.</div><br/><div id="41773953" class="c"><input type="checkbox" id="c-41773953" checked=""/><div class="controls bullet"><span class="by">CyberDildonics</span><span>|</span><a href="#41770692">root</a><span>|</span><a href="#41773612">parent</a><span>|</span><a href="#41772035">next</a><span>|</span><label class="collapse" for="c-41773953">[-]</label><label class="expand" for="c-41773953">[1 more]</label></div><br/><div class="children"><div class="content"><i>The digitizing to film</i><p>Scanning film would be digitizing it, going out to film could be called printing.<p><i>does add a little blur</i><p>A lot of blur. 35mm film had a lot of folk wisdom built up around it and even though it would be scanned and worked on at 2k resolution for live action vfx, if you actually zoomed in it would be extremely soft.<p>You could get away with 1.5k just for printing to the first generation film, let alone the 2nd gen master prints and the third gen prints that went out to theaters.<p><i>The filter did kinda matter</i><p>It is extremely unlikely lighters were changing the actual pixel sample filters on a shot by shot basis. This is something that is set globally. Also if you set it differently for different passes and you use holdouts, your CG will not line up with the other CG renders and you will get edges from the compositing algebra not being exact.<p><i>I was highly impressed with how sensitive the director and lighting&#x2F;fx supes were to filter differences,</i><p>No one is changing the pixel sampling filters on a shot by shot basis and no one is going to be able to tell the filter just by looking at playing back on film. This is simply not reality.<p><i>and how quickly they could spot them in animated clips that were often less than one second long</i><p>Absolutely not. Whatever you are talking about is not different pixel sample filters. Aliasing in general yes, but that&#x27;s much more complex.<p><i>The main thing they were doing was trying to avoid texture sizzle without overblurring.</i><p>This has nothing to do with the renderer&#x27;s pixel sample filters which is what would be the only analog to the article here. Maybe you are talking about texture filtering, although that is not a difficult problem due to mipmapping and summed area mapping. Even back then a geforce 2 could do great texture filtering in real time.<p>Maybe you are talking about large filter sizes in shadow maps, which need a lot of samples when using percentage closer filtering, but that has nothing to do with this.</div><br/></div></div></div></div></div></div></div></div><div id="41772035" class="c"><input type="checkbox" id="c-41772035" checked=""/><div class="controls bullet"><span class="by">CyberDildonics</span><span>|</span><a href="#41770692">root</a><span>|</span><a href="#41771538">parent</a><span>|</span><a href="#41772333">prev</a><span>|</span><label class="collapse" for="c-41772035">[-]</label><label class="expand" for="c-41772035">[1 more]</label></div><br/><div class="children"><div class="content">Then your filter width is too wide. Try 2.2 - 2.5</div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>