<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1693645255709" as="style"/><link rel="stylesheet" href="styles.css?v=1693645255709"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://garymarcus.substack.com/p/doug-lenat-1950-2023">Doug Lenat has died</a> <span class="domain">(<a href="https://garymarcus.substack.com">garymarcus.substack.com</a>)</span></div><div class="subtext"><span>snewman</span> | <span>121 comments</span></div><br/><div><div id="37354753" class="c"><input type="checkbox" id="c-37354753" checked=""/><div class="controls bullet"><span class="by">brundolf</span><span>|</span><a href="#37355402">next</a><span>|</span><label class="collapse" for="c-37354753">[-]</label><label class="expand" for="c-37354753">[10 more]</label></div><br/><div class="children"><div class="content">Doug was at times blunt, but he was fundamentally a kind and generous person, and he had a dedication to his vision and to the people who worked alongside him that has to be admired. He will be missed.<p>I worked at Cycorp (not directly with Doug very often, but it wasn&#x27;t a big office) between 2016 and 2020<p>An anecdote: during our weekly all-hands lunch in the big conference room, he mentioned he was getting a new car (his old one was pretty old, but well-kept) and he asked if anybody could use the old car. One of the staff raised his hand sheepishly and said his daughter was about to start driving. Doug gifted him the car on the spot, without a second thought.<p>He also loved board games, and was in a D&amp;D group with some others at the company. I was told he only ever played lawful good characters, he didn&#x27;t know how to do otherwise :)<p>Happy to answer what questions I can</div><br/><div id="37355672" class="c"><input type="checkbox" id="c-37355672" checked=""/><div class="controls bullet"><span class="by">zitterbewegung</span><span>|</span><a href="#37354753">parent</a><span>|</span><a href="#37355471">next</a><span>|</span><label class="collapse" for="c-37355672">[-]</label><label class="expand" for="c-37355672">[3 more]</label></div><br/><div class="children"><div class="content">I would expect lawful good because it would be the most logical.</div><br/><div id="37358986" class="c"><input type="checkbox" id="c-37358986" checked=""/><div class="controls bullet"><span class="by">djha-skin</span><span>|</span><a href="#37354753">root</a><span>|</span><a href="#37355672">parent</a><span>|</span><a href="#37358977">next</a><span>|</span><label class="collapse" for="c-37358986">[-]</label><label class="expand" for="c-37358986">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s a very neutral thing to say.</div><br/></div></div><div id="37358977" class="c"><input type="checkbox" id="c-37358977" checked=""/><div class="controls bullet"><span class="by">colordrops</span><span>|</span><a href="#37354753">root</a><span>|</span><a href="#37355672">parent</a><span>|</span><a href="#37358986">prev</a><span>|</span><a href="#37355471">next</a><span>|</span><label class="collapse" for="c-37358977">[-]</label><label class="expand" for="c-37358977">[1 more]</label></div><br/><div class="children"><div class="content">Why is that?</div><br/></div></div></div></div><div id="37355471" class="c"><input type="checkbox" id="c-37355471" checked=""/><div class="controls bullet"><span class="by">late25</span><span>|</span><a href="#37354753">parent</a><span>|</span><a href="#37355672">prev</a><span>|</span><a href="#37355402">next</a><span>|</span><label class="collapse" for="c-37355471">[-]</label><label class="expand" for="c-37355471">[6 more]</label></div><br/><div class="children"><div class="content">I don’t know much about him. What makes you start by saying he’s blunt?</div><br/><div id="37356386" class="c"><input type="checkbox" id="c-37356386" checked=""/><div class="controls bullet"><span class="by">brundolf</span><span>|</span><a href="#37354753">root</a><span>|</span><a href="#37355471">parent</a><span>|</span><a href="#37355402">next</a><span>|</span><label class="collapse" for="c-37356386">[-]</label><label class="expand" for="c-37356386">[5 more]</label></div><br/><div class="children"><div class="content">It was a part of his personality, as it is for many people who are intelligent and opinionated, and some can mistake that for unkindness. But I wanted to emphasize that in his case it wasn&#x27;t.</div><br/><div id="37358416" class="c"><input type="checkbox" id="c-37358416" checked=""/><div class="controls bullet"><span class="by">chefandy</span><span>|</span><a href="#37354753">root</a><span>|</span><a href="#37356386">parent</a><span>|</span><a href="#37356469">next</a><span>|</span><label class="collapse" for="c-37358416">[-]</label><label class="expand" for="c-37358416">[2 more]</label></div><br/><div class="children"><div class="content">I haven&#x27;t read much by Lenat, and haven&#x27;t seen anything that would lead me to believe he was particularly blunt, I disagree with attributing bluntness to intelligence. Some of the most intellectually blunt people I&#x27;ve met were some of the most conversationally blunt, and some of the most brilliant were absolute social butterflies. Making people needlessly uncomfortable when communicating is a <i>shortcoming</i> regardless of your intellectual capacity. Even if difficulty communicating appropriately and intelligence are correlated somewhat through common neuropsychiatric profiles, the relationship is not causal.</div><br/><div id="37358652" class="c"><input type="checkbox" id="c-37358652" checked=""/><div class="controls bullet"><span class="by">chmod775</span><span>|</span><a href="#37354753">root</a><span>|</span><a href="#37358416">parent</a><span>|</span><a href="#37356469">next</a><span>|</span><label class="collapse" for="c-37358652">[-]</label><label class="expand" for="c-37358652">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Making people needlessly uncomfortable when communicating is a shortcoming regardless of your intellectual capacity.<p>Emphasis on <i>needlessly</i>. Some bluntness is a good thing, even if it makes people uncomfortable. The alternative usually is prolonged awkwardness and beating around the bush, which likely will make people uncomfortable anyways. Just get it over with like an adult. Don&#x27;t drag an uncomfortable thing out or even risk people not getting the message at all the first time around.</div><br/></div></div></div></div><div id="37356469" class="c"><input type="checkbox" id="c-37356469" checked=""/><div class="controls bullet"><span class="by">late25</span><span>|</span><a href="#37354753">root</a><span>|</span><a href="#37356386">parent</a><span>|</span><a href="#37358416">prev</a><span>|</span><a href="#37355402">next</a><span>|</span><label class="collapse" for="c-37356469">[-]</label><label class="expand" for="c-37356469">[2 more]</label></div><br/><div class="children"><div class="content">Got it. I was merely curious if there were any particular stories, rumors, or legends about his bluntness (like there is Linus).</div><br/><div id="37356572" class="c"><input type="checkbox" id="c-37356572" checked=""/><div class="controls bullet"><span class="by">brundolf</span><span>|</span><a href="#37354753">root</a><span>|</span><a href="#37356469">parent</a><span>|</span><a href="#37355402">next</a><span>|</span><label class="collapse" for="c-37356572">[-]</label><label class="expand" for="c-37356572">[1 more]</label></div><br/><div class="children"><div class="content">No, it was never anything at that level. I would describe (pre-reformed) Linus as more than just &quot;blunt&quot;</div><br/></div></div></div></div></div></div></div></div></div></div><div id="37355402" class="c"><input type="checkbox" id="c-37355402" checked=""/><div class="controls bullet"><span class="by">snowmaker</span><span>|</span><a href="#37354753">prev</a><span>|</span><a href="#37358387">next</a><span>|</span><label class="collapse" for="c-37355402">[-]</label><label class="expand" for="c-37355402">[3 more]</label></div><br/><div class="children"><div class="content">I interviewed with Doug Lenat was I was a 17 year old high school student, and he hired me as a summer intern for Cycorp - my first actual programming job.<p>That internship was life-changing for me, and I&#x27;ll always be grateful to him for taking a wild bet on a literally a kid.<p>Doug was a brilliant computer scientist, and a pioneer of artificial intelligence.  Though I was very junior at Cycorp, it was a small company so I sat in many meetings with him.  It was obvious that he understood every detail of how technology worked, and was extremely smart.<p>Cycorp was 30 years ahead of its time and never actually worked.  For those who don&#x27;t know, it was essentially the first OpenAI - the first large-scale commercial effort to create general artificial intelligence.<p>I learned a lot from Doug about how to be incredibly ambitious, and how to not give up.  Doug worked on Cycorp for multiple decades.  It never really took off, but he managed to keep funding it and keep hiring great people so he could keep plugging away at the problem.  I know very few people who have stuck with an idea for so long.</div><br/><div id="37356417" class="c"><input type="checkbox" id="c-37356417" checked=""/><div class="controls bullet"><span class="by">xNeil</span><span>|</span><a href="#37355402">parent</a><span>|</span><a href="#37358387">next</a><span>|</span><label class="collapse" for="c-37356417">[-]</label><label class="expand" for="c-37356417">[2 more]</label></div><br/><div class="children"><div class="content">That sounds awesome! Was coming back to Cycorp to permanently work ever in the works for you? Or did you think the intern was nice but you didn&#x27;t want a career in the field?<p>Also - what exactly did you do in the internship as a 17 year old - what skills did you have?</div><br/><div id="37357138" class="c"><input type="checkbox" id="c-37357138" checked=""/><div class="controls bullet"><span class="by">snowmaker</span><span>|</span><a href="#37355402">root</a><span>|</span><a href="#37356417">parent</a><span>|</span><a href="#37358387">next</a><span>|</span><label class="collapse" for="c-37357138">[-]</label><label class="expand" for="c-37357138">[1 more]</label></div><br/><div class="children"><div class="content">I was certainly interested in working at Cycorp full-time.  But after two summers there, I could tell that the technical approach they were taking was just not working.<p>My first summer, I was an ontologist, which was a role they created where people would literally hand-enter facts into Cyc using formal logic like &quot;A cat has four legs&quot;.  My second summer I programmed (poorly) in Lisp for them.</div><br/></div></div></div></div></div></div><div id="37358387" class="c"><input type="checkbox" id="c-37358387" checked=""/><div class="controls bullet"><span class="by">gumby</span><span>|</span><a href="#37355402">prev</a><span>|</span><a href="#37356069">next</a><span>|</span><label class="collapse" for="c-37358387">[-]</label><label class="expand" for="c-37358387">[1 more]</label></div><br/><div class="children"><div class="content">I worked with Doug on Cyc from ~85-89 (we had overlapped at PARC but didn’t interact much there). The first thing undid was scrap the old implementation and start from scratch, designing the levels system and all the bootstrap code.<p>It was a fun time with a small core team (mainly me, guha, and Doug) but over time I became dissatisfied with some of the arbitrariness of the KB. By the time I left the Cyc project (for my own reasons unrelated to work) I was somewhat negative towards the foundations of the project, despite the tight relationship we’d had and the fact it ran on my code!  But over time I became smarter and came to appreciate once again its value.  I had too much of a “pure math” view of things back then.<p>As I moved on to other things I lost touch with Doug and Mary, and I’m sorry for that.</div><br/></div></div><div id="37356069" class="c"><input type="checkbox" id="c-37356069" checked=""/><div class="controls bullet"><span class="by">symbolicAGI</span><span>|</span><a href="#37358387">prev</a><span>|</span><a href="#37354304">next</a><span>|</span><label class="collapse" for="c-37356069">[-]</label><label class="expand" for="c-37356069">[19 more]</label></div><br/><div class="children"><div class="content">Doug Lenat, RIP.
I worked at Cycorp in Austin from 2000-2006. Taken from us way too soon, Doug none the less had the opportunity to help our country advance military and intelligence community computer science research.<p>One day, the rapid advancement of AI via LLMs will slow down and attention will again return to logical reasoning and knowledge representation as championed by the Cyc Project, Cycorp, its cyclists and Dr. Doug Lenat.<p>Why? If NN inference were so fast, we would compile C programs with it instead of using deductive logical inference that is executed efficiently by the compiler.</div><br/><div id="37356827" class="c"><input type="checkbox" id="c-37356827" checked=""/><div class="controls bullet"><span class="by">nextos</span><span>|</span><a href="#37356069">parent</a><span>|</span><a href="#37356348">next</a><span>|</span><label class="collapse" for="c-37356827">[-]</label><label class="expand" for="c-37356827">[4 more]</label></div><br/><div class="children"><div class="content">Exactly. When I hear books such as <i>Paradigms of AI Programming</i> are outdated because of LLMs, I disagree. They are more current than ever, thanks to LLMs!<p>Neural and symbolic AI will eventually merge. Symbolic models bring much needed efficiency and robustness via regularization.</div><br/><div id="37357110" class="c"><input type="checkbox" id="c-37357110" checked=""/><div class="controls bullet"><span class="by">mnemonicsloth</span><span>|</span><a href="#37356069">root</a><span>|</span><a href="#37356827">parent</a><span>|</span><a href="#37358284">next</a><span>|</span><label class="collapse" for="c-37357110">[-]</label><label class="expand" for="c-37357110">[2 more]</label></div><br/><div class="children"><div class="content">If you want to learn about symbolic AI, there are a lot of more recent  sources than PAIP (you could try the first half of <i>AI: A Modern Approach</i> by Russel and Norvig), and this has been true for a while.<p>If you read PAIP today, the most likely reason is that you want a master class in Lisp programming and&#x2F;or want to learn a lot of tricks for getting good performance out of complex programs (which used to be <i>part of</i> AI and is in many ways being outsourced to hardware today).<p>None of this is to say you shouldn&#x27;t read PAIP.  You absolutely should.  It&#x27;s awesome.  But its role is different now.</div><br/><div id="37357509" class="c"><input type="checkbox" id="c-37357509" checked=""/><div class="controls bullet"><span class="by">nextos</span><span>|</span><a href="#37356069">root</a><span>|</span><a href="#37357110">parent</a><span>|</span><a href="#37358284">next</a><span>|</span><label class="collapse" for="c-37357509">[-]</label><label class="expand" for="c-37357509">[1 more]</label></div><br/><div class="children"><div class="content">Some parts of PAIP might be outdated, but it still has really current material on e.g. embedding Prolog in Lisp or building a term-rewriting system. That&#x27;s relevant for pursuing current neuro-symbolic research, e.g. <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2006.08381.pdf" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2006.08381.pdf</a>.<p>Other parts like coding an Eliza chatbot are indeed outdated. I have read AIMA and followed a long course that used it, but I didn&#x27;t really like it. I found it too broad and shallow.</div><br/></div></div></div></div><div id="37358284" class="c"><input type="checkbox" id="c-37358284" checked=""/><div class="controls bullet"><span class="by">keepamovin</span><span>|</span><a href="#37356069">root</a><span>|</span><a href="#37356827">parent</a><span>|</span><a href="#37357110">prev</a><span>|</span><a href="#37356348">next</a><span>|</span><label class="collapse" for="c-37358284">[-]</label><label class="expand" for="c-37358284">[1 more]</label></div><br/><div class="children"><div class="content">It would be cool if we could find the algorithmic neurological basis for this, the analogy with LLMs being more obvious multi-layer brain circuits, the neurological analogy with symbolic reasoning must exist too.<p>My hunch is it emerges naturally out of the hierarchical generalization capabilities of multiple layer circuits. But then you need something to coordinate the acquired labels: a tweak on attention perhaps?<p>Another characteristic is probably some (limited) form of recursion, so the generalized labels emitted at the small end can be fed back in as tokens to be further processed at the big end.</div><br/></div></div></div></div><div id="37356348" class="c"><input type="checkbox" id="c-37356348" checked=""/><div class="controls bullet"><span class="by">optimalsolver</span><span>|</span><a href="#37356069">parent</a><span>|</span><a href="#37356827">prev</a><span>|</span><a href="#37356214">next</a><span>|</span><label class="collapse" for="c-37356348">[-]</label><label class="expand" for="c-37356348">[6 more]</label></div><br/><div class="children"><div class="content">The best thing Cycorp could do now is open source its accumulated database of logical relations so it can be ingested by some monster LLM.<p>What&#x27;s the point of all that data collecting dust and accomplishing not much of anything?</div><br/><div id="37358997" class="c"><input type="checkbox" id="c-37358997" checked=""/><div class="controls bullet"><span class="by">zozbot234</span><span>|</span><a href="#37356069">root</a><span>|</span><a href="#37356348">parent</a><span>|</span><a href="#37357111">next</a><span>|</span><label class="collapse" for="c-37358997">[-]</label><label class="expand" for="c-37358997">[1 more]</label></div><br/><div class="children"><div class="content">OpenCyc is already a thing and there&#x27;s been very little interest in it.  These days we also have general-purpose semantic KB&#x27;s like Wikidata, that are available for free and go way beyond what Cyc or OpenCyc was trying to do.</div><br/></div></div><div id="37357111" class="c"><input type="checkbox" id="c-37357111" checked=""/><div class="controls bullet"><span class="by">adastra22</span><span>|</span><a href="#37356069">root</a><span>|</span><a href="#37356348">parent</a><span>|</span><a href="#37358997">prev</a><span>|</span><a href="#37358397">next</a><span>|</span><label class="collapse" for="c-37357111">[-]</label><label class="expand" for="c-37357111">[2 more]</label></div><br/><div class="children"><div class="content">It seems the direction of flow would be the opposite: LLMs are a great source of logical data for Cyc-like things. Distill your LLM into logical statements, then run your Cyc algorithms on it.</div><br/><div id="37357925" class="c"><input type="checkbox" id="c-37357925" checked=""/><div class="controls bullet"><span class="by">xpe</span><span>|</span><a href="#37356069">root</a><span>|</span><a href="#37357111">parent</a><span>|</span><a href="#37358397">next</a><span>|</span><label class="collapse" for="c-37357925">[-]</label><label class="expand" for="c-37357925">[1 more]</label></div><br/><div class="children"><div class="content">&gt; It seems the direction of flow would be the opposite: LLMs are a great source of logical data for Cyc-like things. Distill your LLM into logical statements, then run your Cyc algorithms on it.<p>This is hugely problematic. If you get the premises wrong, many fallacies will follow.<p>LLMs can play many roles around this area, but their output cannot be trusted with significant verification and validation.</div><br/></div></div></div></div><div id="37358397" class="c"><input type="checkbox" id="c-37358397" checked=""/><div class="controls bullet"><span class="by">xpe</span><span>|</span><a href="#37356069">root</a><span>|</span><a href="#37356348">parent</a><span>|</span><a href="#37357111">prev</a><span>|</span><a href="#37357075">next</a><span>|</span><label class="collapse" for="c-37358397">[-]</label><label class="expand" for="c-37358397">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The best thing Cycorp could do now is open source its accumulated database of logical relations...<p>This is unpersuasive without laying out your assumptions and reasoning.<p>Counter points:<p>(a) It would be unethical for such a knowledge base to be put out in the open without considerable guardrails and appropriate licensing. The details matter.<p>(b) Cycorp gets some funding from the U.S. Government; this changes both the set of options available and the calculus of weighing them.<p>(c) Not all nations have equivalent values. Unless one is a moral relativist, these differences should not be deemed equivalent nor irrelevant. As such, despite the flaws of U.S. values and some horrific decision-making throughout history, there are known worse actors and states. Such parties would make worse use of an extensive human-curated knowledge base.</div><br/></div></div><div id="37357075" class="c"><input type="checkbox" id="c-37357075" checked=""/><div class="controls bullet"><span class="by">vtr132</span><span>|</span><a href="#37356069">root</a><span>|</span><a href="#37356348">parent</a><span>|</span><a href="#37358397">prev</a><span>|</span><a href="#37356214">next</a><span>|</span><label class="collapse" for="c-37357075">[-]</label><label class="expand" for="c-37357075">[1 more]</label></div><br/><div class="children"><div class="content">I think military will take over his work.Snowden documents reveled the cyc was been used to come up with Terror attack scenarios.</div><br/></div></div></div></div><div id="37356214" class="c"><input type="checkbox" id="c-37356214" checked=""/><div class="controls bullet"><span class="by">halflings</span><span>|</span><a href="#37356069">parent</a><span>|</span><a href="#37356348">prev</a><span>|</span><a href="#37354304">next</a><span>|</span><label class="collapse" for="c-37356214">[-]</label><label class="expand" for="c-37356214">[8 more]</label></div><br/><div class="children"><div class="content">&gt; If NN inference were so fast, we would compile C programs with it instead of using deductive logical inference that is executed efficiently by the compiler.<p>This is the definition of a strawman. Who is claiming that NN inference is always the fastest way to run computation?<p>Instead of trying to bring down another technology (neural networks), how about you focus on making symbolic methods usable to solve real-world problems; e.g. how can I build a robust email spam detection system with symbolic methods?</div><br/><div id="37357952" class="c"><input type="checkbox" id="c-37357952" checked=""/><div class="controls bullet"><span class="by">xpe</span><span>|</span><a href="#37356069">root</a><span>|</span><a href="#37356214">parent</a><span>|</span><a href="#37358015">next</a><span>|</span><label class="collapse" for="c-37357952">[-]</label><label class="expand" for="c-37357952">[1 more]</label></div><br/><div class="children"><div class="content">&gt;&gt; If NN inference were so fast, we would compile C programs with it instead of using deductive logical inference that is executed efficiently by the compiler.<p>&gt; This is the definition of a strawman.<p>(Actually, it is an <i>example</i> of a strawman.) Anyhow, rather than a strawman, I&#x27;d rather us get right into the fundamentals.<p>1. Feed-forward NN computation (&#x27;inference&#x27;, which is an unfortunate word choice IMO) can provably provide universal function approximation under known conditions. And it can do so efficiently as well, with a lot of recent research getting into both the how and why. One &quot;pays the cost&quot; up-front with training in order to get fast prediction-time performance. The tradeoff is often worth it.<p>2. Function approximation is not as powerful as Turing completeness. FF NNs are not Turing complete.<p>3. Deductive chaining is a well-studied, well understood area of algorithms.<p>4. But... modeling of computational architectures (including processors, caches, busses, and RAM) with sufficient detail to optimize compilation is a hard problem. I wouldn&#x27;t be surprised if this stretches these algorithms to the limit in terms of what developers will tolerate in terms of compile times. This is a strong incentive, so I&#x27;d expect there is at least some research that pushes outside the usual contours here.</div><br/></div></div><div id="37358015" class="c"><input type="checkbox" id="c-37358015" checked=""/><div class="controls bullet"><span class="by">xpe</span><span>|</span><a href="#37356069">root</a><span>|</span><a href="#37356214">parent</a><span>|</span><a href="#37357952">prev</a><span>|</span><a href="#37356444">next</a><span>|</span><label class="collapse" for="c-37358015">[-]</label><label class="expand" for="c-37358015">[4 more]</label></div><br/><div class="children"><div class="content">&gt; Instead of trying to bring down another technology (neural networks), how about you focus on making symbolic methods usable to solve real-world problems; e.g. how can I build a robust email spam detection system with symbolic methods?<p>I have two concerns. First, just after pointing out a logical fallacy from someone else, you added a fallacy: the either-or fallacy. (One can criticize a technology <i>and</i> do other things too.)<p>Second, you selected an example that illustrates a known and predictable weakness of symbolic systems. Still, there are plenty of real-world problems that symbolic systems address well. So your comment cherry-picks.<p>It appears as if you are trying to land a counter punch here. I&#x27;m weary of this kind of conversational pattern. Many of us know that tends to escalate. I don&#x27;t want HN to go that direction. We all have varying experience and points of view to contribute. Let&#x27;s try to be charitable, clear, and logical.</div><br/><div id="37358171" class="c"><input type="checkbox" id="c-37358171" checked=""/><div class="controls bullet"><span class="by">Nevermark</span><span>|</span><a href="#37356069">root</a><span>|</span><a href="#37358015">parent</a><span>|</span><a href="#37356444">next</a><span>|</span><label class="collapse" for="c-37358171">[-]</label><label class="expand" for="c-37358171">[3 more]</label></div><br/><div class="children"><div class="content">I am desperately vetting your comment for something I can criticize. An inadvertent, irrelevant, imagined infraction. Anything! But you have left me no opening.<p>Well done, sir, well done.</div><br/><div id="37358237" class="c"><input type="checkbox" id="c-37358237" checked=""/><div class="controls bullet"><span class="by">xpe</span><span>|</span><a href="#37356069">root</a><span>|</span><a href="#37358171">parent</a><span>|</span><a href="#37356444">next</a><span>|</span><label class="collapse" for="c-37358237">[-]</label><label class="expand" for="c-37358237">[2 more]</label></div><br/><div class="children"><div class="content">Thanks, but if I didn&#x27;t blunder here, I can assure you I have in many other places. I strive to be mindful. I try not to &quot;blame&quot; anyone for strong reactions. But when we see certain unhelpful behaviors directed at other people, I try to identify&#x2F;name it without making it worse. Awareness helps.</div><br/><div id="37358779" class="c"><input type="checkbox" id="c-37358779" checked=""/><div class="controls bullet"><span class="by">Nevermark</span><span>|</span><a href="#37356069">root</a><span>|</span><a href="#37358237">parent</a><span>|</span><a href="#37356444">next</a><span>|</span><label class="collapse" for="c-37358779">[-]</label><label class="expand" for="c-37358779">[1 more]</label></div><br/><div class="children"><div class="content">Without awareness we are just untagged data in a sea of uncompressed noise.</div><br/></div></div></div></div></div></div></div></div><div id="37356444" class="c"><input type="checkbox" id="c-37356444" checked=""/><div class="controls bullet"><span class="by">symbolicAGI</span><span>|</span><a href="#37356069">root</a><span>|</span><a href="#37356214">parent</a><span>|</span><a href="#37358015">prev</a><span>|</span><a href="#37356714">next</a><span>|</span><label class="collapse" for="c-37356444">[-]</label><label class="expand" for="c-37356444">[1 more]</label></div><br/><div class="children"><div class="content">The point is that symbolic computation as performed by Cycorp was held back by the need to train the Knowledge Base by hand in a supervised manner. NNs and LLMs in particular became ascendant when unsupervised training was employed at scale.<p>Perhaps LLMs can automate in large part the manual operations of building a future symbolic knowledge base organized by a universal upper ontology. Considering the amazing emergent features of sufficiently-large LLMs, what could emerge from a sufficiently large, reflective symbolic knowledge base?</div><br/></div></div><div id="37356714" class="c"><input type="checkbox" id="c-37356714" checked=""/><div class="controls bullet"><span class="by">detourdog</span><span>|</span><a href="#37356069">root</a><span>|</span><a href="#37356214">parent</a><span>|</span><a href="#37356444">prev</a><span>|</span><a href="#37354304">next</a><span>|</span><label class="collapse" for="c-37356714">[-]</label><label class="expand" for="c-37356714">[1 more]</label></div><br/><div class="children"><div class="content">That what I have settled on. The need for a symbolic library of standard hardware circuits.<p>I’m making a sloppy version that will contain all the symbols needed to run a multi-unit building.</div><br/></div></div></div></div></div></div><div id="37354304" class="c"><input type="checkbox" id="c-37354304" checked=""/><div class="controls bullet"><span class="by">mindcrime</span><span>|</span><a href="#37356069">prev</a><span>|</span><a href="#37355190">next</a><span>|</span><label class="collapse" for="c-37354304">[-]</label><label class="expand" for="c-37354304">[12 more]</label></div><br/><div class="children"><div class="content">If anybody wants to hear more about Doug&#x27;s work and ideas, here is a (fairly long) interview with Doug by Lex Fridman, from last year.<p><a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=3wMKoSRbGVs&amp;pp=ygUabGV4IGZyaWRtYW4gZG91Z2xhcyBsZW5hdCA%3D">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=3wMKoSRbGVs&amp;pp=ygUabGV4IGZya...</a></div><br/><div id="37358450" class="c"><input type="checkbox" id="c-37358450" checked=""/><div class="controls bullet"><span class="by">chubot</span><span>|</span><a href="#37354304">parent</a><span>|</span><a href="#37357475">next</a><span>|</span><label class="collapse" for="c-37358450">[-]</label><label class="expand" for="c-37358450">[1 more]</label></div><br/><div class="children"><div class="content">Thanks for the link.  I watched the first part, and an interesting story&#x2F;claim is that before Cyc started, many &quot;smart people&quot; including Marvin Minsky came up with &quot;~1 million&quot; as the number of things you would have to encode in a system for it to have &quot;common sense&quot;.<p>He said they learned after ~5 years that this was an order of magnitude off -- it&#x27;s more like 10 M things.<p>Is there any literature about this?   Did they publish?<p>To me, the obvious questions are -<p>- how do they know it&#x27;s not 100M things?<p>- how do they know it&#x27;s even bounded?  Why isn&#x27;t there a combinatorial explosion?<p>I mean I guess they were evaluating the system all along.  You don&#x27;t go for 38 years without having some clear metrics.  But I am having some problems with the logic -- I&#x27;d be interested in links to references &#x2F; criticism.<p>I&#x27;d be interested in any arguments for and against ~10 M.  Naively speaking, the argument seems a bit flawed to me.<p>FWIW I heard of Cyc back in the 90&#x27;s, but I had no idea it was still alive.  It is impressive that he kept it alive for so long.<p>---<p>Actually the wikipedia article is pretty good<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Cyc#Criticisms" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Cyc#Criticisms</a><p>Though I&#x27;m still interested in the ~1M or ~10M claim.  It seems like a strong claim to hold onto for decades, unless they had really strong metrics backing it up.</div><br/></div></div><div id="37357475" class="c"><input type="checkbox" id="c-37357475" checked=""/><div class="controls bullet"><span class="by">replwoacause</span><span>|</span><a href="#37354304">parent</a><span>|</span><a href="#37358450">prev</a><span>|</span><a href="#37354915">next</a><span>|</span><label class="collapse" for="c-37357475">[-]</label><label class="expand" for="c-37357475">[1 more]</label></div><br/><div class="children"><div class="content">Enjoyed watching that. Doug sounds very impressive. RIP.</div><br/></div></div><div id="37354915" class="c"><input type="checkbox" id="c-37354915" checked=""/><div class="controls bullet"><span class="by">mistrial9</span><span>|</span><a href="#37354304">parent</a><span>|</span><a href="#37357475">prev</a><span>|</span><a href="#37354490">next</a><span>|</span><label class="collapse" for="c-37354915">[-]</label><label class="expand" for="c-37354915">[4 more]</label></div><br/><div class="children"><div class="content">reading the bio of Lex Fridman on wikipedia.. &quot;Learning of Identity from Behavioral Biometrics for Active Authentication&quot;  what?</div><br/><div id="37355341" class="c"><input type="checkbox" id="c-37355341" checked=""/><div class="controls bullet"><span class="by">dang</span><span>|</span><a href="#37354304">root</a><span>|</span><a href="#37354915">parent</a><span>|</span><a href="#37355302">next</a><span>|</span><label class="collapse" for="c-37355341">[-]</label><label class="expand" for="c-37355341">[1 more]</label></div><br/><div class="children"><div class="content">Please don&#x27;t go offtopic in predictable&#x2F;nasty ways - more at <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37355320">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37355320</a>.</div><br/></div></div><div id="37355302" class="c"><input type="checkbox" id="c-37355302" checked=""/><div class="controls bullet"><span class="by">modeless</span><span>|</span><a href="#37354304">root</a><span>|</span><a href="#37354915">parent</a><span>|</span><a href="#37355341">prev</a><span>|</span><a href="#37355222">next</a><span>|</span><label class="collapse" for="c-37355302">[-]</label><label class="expand" for="c-37355302">[1 more]</label></div><br/><div class="children"><div class="content">Makes sense to me. He basically made a system that detects when someone else is using your computer by e.g. comparing patterns of mouse and keyboard input to your typical usage. It would be useful in a situation such as if you left your screen unlocked and a coworker sat down at your desk to prank you by sending an email from you to your boss (or worse, obviously). The computer would lock itself as soon as it suspects someone else is using it instead of you.</div><br/></div></div><div id="37355222" class="c"><input type="checkbox" id="c-37355222" checked=""/><div class="controls bullet"><span class="by">lionkor</span><span>|</span><a href="#37354304">root</a><span>|</span><a href="#37354915">parent</a><span>|</span><a href="#37355302">prev</a><span>|</span><a href="#37354490">next</a><span>|</span><label class="collapse" for="c-37355222">[-]</label><label class="expand" for="c-37355222">[1 more]</label></div><br/><div class="children"><div class="content">Like anything reasonably complex, it means little to you if its not your field - that said, I have no clue either.</div><br/></div></div></div></div><div id="37354490" class="c"><input type="checkbox" id="c-37354490" checked=""/><div class="controls bullet"><span class="by">lern_too_spel</span><span>|</span><a href="#37354304">parent</a><span>|</span><a href="#37354915">prev</a><span>|</span><a href="#37355190">next</a><span>|</span><label class="collapse" for="c-37354490">[-]</label><label class="expand" for="c-37354490">[5 more]</label></div><br/><div class="children"><div class="content">Just search for Doug Lenat on YouTube. I can guarantee that any one of the other videos will be better than a Fridman interview.</div><br/><div id="37355320" class="c"><input type="checkbox" id="c-37355320" checked=""/><div class="controls bullet"><span class="by">dang</span><span>|</span><a href="#37354304">root</a><span>|</span><a href="#37354490">parent</a><span>|</span><a href="#37354558">next</a><span>|</span><label class="collapse" for="c-37355320">[-]</label><label class="expand" for="c-37355320">[1 more]</label></div><br/><div class="children"><div class="content">Hey you guys, please don&#x27;t go offtopic like this. Whimsical offtopicness can be ok, but offtopicness in the intersection of:<p>(1) generic (e.g. swerves the thread toward larger&#x2F;general topic rather than something more specific);<p>(2) flamey (e.g. provocative on a divisive issue); and<p>(3) predictable (e.g. has been hashed so many times already that comments will likely fall in a few already-tiresome hash buckets)<p>- is the bad kind of offtopicness: the kind that brings little new information and eventually lots of nastiness. We&#x27;re trying for the opposite here—lots of information and little nastiness.<p><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;newsguidelines.html">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;newsguidelines.html</a></div><br/></div></div><div id="37354558" class="c"><input type="checkbox" id="c-37354558" checked=""/><div class="controls bullet"><span class="by">mindcrime</span><span>|</span><a href="#37354304">root</a><span>|</span><a href="#37354490">parent</a><span>|</span><a href="#37355320">prev</a><span>|</span><a href="#37355190">next</a><span>|</span><label class="collapse" for="c-37354558">[-]</label><label class="expand" for="c-37354558">[3 more]</label></div><br/><div class="children"><div class="content">Only about two of them will be more contemporary though, and both are academic talks, not interviews. I get that you don&#x27;t like Lex Fridman, which is a perfectly fine position to hold. But there is something to be said for seeing two people just sit and talk, as opposed to seeing somebody monologue for an hour. The Fridman interview with Doug is, IMO, absolutely worth watching. And so are all of the other videos by &#x2F; about Doug. <i>shrug</i></div><br/><div id="37354935" class="c"><input type="checkbox" id="c-37354935" checked=""/><div class="controls bullet"><span class="by">yarpen_z</span><span>|</span><a href="#37354304">root</a><span>|</span><a href="#37354558">parent</a><span>|</span><a href="#37355190">next</a><span>|</span><label class="collapse" for="c-37354935">[-]</label><label class="expand" for="c-37354935">[2 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t know this particular interview, but it&#x27;s not necessarily about not liking Lex. I listened to many episodes of his podcast and while I appreciate the selection of guests from the CS domain, many of these interviews aren&#x27;t very good. They are not completely terrible but they should have been so much better: Lex had so many passionate, educated, experienced and gifted guests, yet his ability to ask interesting and focused questions is not on the same level.</div><br/><div id="37356165" class="c"><input type="checkbox" id="c-37356165" checked=""/><div class="controls bullet"><span class="by">pengaru</span><span>|</span><a href="#37354304">root</a><span>|</span><a href="#37354935">parent</a><span>|</span><a href="#37355190">next</a><span>|</span><label class="collapse" for="c-37356165">[-]</label><label class="expand" for="c-37356165">[1 more]</label></div><br/><div class="children"><div class="content">He&#x27;s a shitty interviewer.  Often doesn&#x27;t even engage with his guest&#x27;s responses, as if he&#x27;s not even listening to what they&#x27;re saying, instead moving mechanically to his next bullet-point.  Which is completely ridiculous for what&#x27;s supposed to be a long-format conversational interview.<p>The best episodes are ones where the guest drives the interview and has a lot of interesting things to say.  Fridman&#x27;s just useful for attracting interesting domain experts somewhere we can hear them speak for hours on end.<p>The Jim Keller episodes are excellent IMO, despite Fridman.  Guests like Keller and Carmack don&#x27;t need a good interviewer for it to be a worthwhile listen.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="37355190" class="c"><input type="checkbox" id="c-37355190" checked=""/><div class="controls bullet"><span class="by">tunesmith</span><span>|</span><a href="#37354304">prev</a><span>|</span><a href="#37354928">next</a><span>|</span><label class="collapse" for="c-37355190">[-]</label><label class="expand" for="c-37355190">[10 more]</label></div><br/><div class="children"><div class="content">It&#x27;s fun reading through the paper he links just because I&#x27;ve always been enamored by taking a lot of those principles that they believe should be internal to a computer, and instead making them external to a community.<p>In other words, I think it would be so highly useful to have a browseable corpus of arguments and conclusions, where people could collaborate on them and perhaps disagree with portions of the argument graph, adding to it and enriching it over time, so other people could read and perhaps adopt the same reasoning.<p>I play around with ideas with this site I occasionally work on, <a href="http:&#x2F;&#x2F;concludia.org&#x2F;" rel="nofollow noreferrer">http:&#x2F;&#x2F;concludia.org&#x2F;</a> - really more an excuse at this point to mess around with the concept and also get better at Akka (Pekko) programming. At some point I&#x27;ll add user accounts and editable arguments and make it a real website.</div><br/><div id="37355258" class="c"><input type="checkbox" id="c-37355258" checked=""/><div class="controls bullet"><span class="by">tomodachi94</span><span>|</span><a href="#37355190">parent</a><span>|</span><a href="#37356265">next</a><span>|</span><label class="collapse" for="c-37355258">[-]</label><label class="expand" for="c-37355258">[7 more]</label></div><br/><div class="children"><div class="content">So basically a multi-person Zettelkasten? The idea with a Zettelkasten (zk for short) is that each note is a singular idea, concept, or argument that is all linked together. Arguments can link to their evidence, concepts can link to other related concepts, and so on.<p><a href="https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Zettelkasten" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Zettelkasten</a></div><br/><div id="37355324" class="c"><input type="checkbox" id="c-37355324" checked=""/><div class="controls bullet"><span class="by">tunesmith</span><span>|</span><a href="#37355190">root</a><span>|</span><a href="#37355258">parent</a><span>|</span><a href="#37358259">next</a><span>|</span><label class="collapse" for="c-37355324">[-]</label><label class="expand" for="c-37355324">[5 more]</label></div><br/><div class="children"><div class="content">Sort of except that it also tracks truth propagation - one person disagreeing would inform others that portion of the graph is contested. So the graph has behavior. And, the links have logical meaning, beyond just &quot;is related to&quot; - it respects boolean logic.<p>You can see some of the explanation at <a href="http:&#x2F;&#x2F;concludia.org&#x2F;instructions" rel="nofollow noreferrer">http:&#x2F;&#x2F;concludia.org&#x2F;instructions</a> .</div><br/><div id="37356823" class="c"><input type="checkbox" id="c-37356823" checked=""/><div class="controls bullet"><span class="by">quickthrower2</span><span>|</span><a href="#37355190">root</a><span>|</span><a href="#37355324">parent</a><span>|</span><a href="#37355457">next</a><span>|</span><label class="collapse" for="c-37356823">[-]</label><label class="expand" for="c-37356823">[2 more]</label></div><br/><div class="children"><div class="content">You would need a highly disciplined and motivated set of people in the team. I have been on courses where teams do this on pen&#x2F;paper and it is a real skill and it is <i>all</i> you do for days. Forget anything else like programming, finishing work, etc.</div><br/><div id="37358313" class="c"><input type="checkbox" id="c-37358313" checked=""/><div class="controls bullet"><span class="by">xpe</span><span>|</span><a href="#37355190">root</a><span>|</span><a href="#37356823">parent</a><span>|</span><a href="#37355457">next</a><span>|</span><label class="collapse" for="c-37358313">[-]</label><label class="expand" for="c-37358313">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;d be stoked if you wrote more about this experience and shared it somewhere.</div><br/></div></div></div></div><div id="37355457" class="c"><input type="checkbox" id="c-37355457" checked=""/><div class="controls bullet"><span class="by">couchand</span><span>|</span><a href="#37355190">root</a><span>|</span><a href="#37355324">parent</a><span>|</span><a href="#37356823">prev</a><span>|</span><a href="#37358259">next</a><span>|</span><label class="collapse" for="c-37355457">[-]</label><label class="expand" for="c-37355457">[2 more]</label></div><br/><div class="children"><div class="content">&gt; it respects boolean logic.<p>Intuitionist or classical?</div><br/><div id="37355511" class="c"><input type="checkbox" id="c-37355511" checked=""/><div class="controls bullet"><span class="by">tunesmith</span><span>|</span><a href="#37355190">root</a><span>|</span><a href="#37355457">parent</a><span>|</span><a href="#37358259">next</a><span>|</span><label class="collapse" for="c-37355511">[-]</label><label class="expand" for="c-37355511">[1 more]</label></div><br/><div class="children"><div class="content">Intuitionist. Truth is provability; the propagation model is basically digital logic. If you mark a premise to a conclusion false, the conclusion is then marked &quot;false&quot; but it really just means &quot;it is false that it is proven&quot;; vitiated. Might still be true, just needs further work.</div><br/></div></div></div></div></div></div><div id="37358259" class="c"><input type="checkbox" id="c-37358259" checked=""/><div class="controls bullet"><span class="by">gitgud</span><span>|</span><a href="#37355190">root</a><span>|</span><a href="#37355258">parent</a><span>|</span><a href="#37355324">prev</a><span>|</span><a href="#37356265">next</a><span>|</span><label class="collapse" for="c-37358259">[-]</label><label class="expand" for="c-37358259">[1 more]</label></div><br/><div class="children"><div class="content">Isn’t this what Wikipedia <i>is</i> in essence? Ideas, concepts linked together, with supporting evidence</div><br/></div></div></div></div><div id="37356265" class="c"><input type="checkbox" id="c-37356265" checked=""/><div class="controls bullet"><span class="by">high_priest</span><span>|</span><a href="#37355190">parent</a><span>|</span><a href="#37355258">prev</a><span>|</span><a href="#37356191">next</a><span>|</span><label class="collapse" for="c-37356265">[-]</label><label class="expand" for="c-37356265">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think this is the goal of your project, so let me ask this way.
Is there any similiar project, where we provide truths and fallacies, combine them with logical arguments and have a language model generate sets of probable conclusions?<p>Would be great for brainstorming.</div><br/></div></div><div id="37356191" class="c"><input type="checkbox" id="c-37356191" checked=""/><div class="controls bullet"><span class="by">frenchwhisker</span><span>|</span><a href="#37355190">parent</a><span>|</span><a href="#37356265">prev</a><span>|</span><a href="#37354928">next</a><span>|</span><label class="collapse" for="c-37356191">[-]</label><label class="expand" for="c-37356191">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve had the same idea (er, came to the same conclusion) but never acted on it. Awesome to see that someone has! Great name too.<p>I thought of it while daydreaming about how to converge public opinion in a nation with major political polarization. It&#x27;d be a sort of structured public debate forum and people could better see exactly where in the hierarchy they disagreed and, perhaps more importantly, how much they in fact agreed upon.</div><br/></div></div></div></div><div id="37354928" class="c"><input type="checkbox" id="c-37354928" checked=""/><div class="controls bullet"><span class="by">eigenvalue</span><span>|</span><a href="#37355190">prev</a><span>|</span><a href="#37356435">next</a><span>|</span><label class="collapse" for="c-37354928">[-]</label><label class="expand" for="c-37354928">[6 more]</label></div><br/><div class="children"><div class="content">I have always thought of Cyc as being the AI equivalent of Russell and Whitehead&#x27;s Principia--something that is technically ambitious and interesting in its own right, but ultimately just the wrong approach that will never really work well on a standalone basis, no matter how long you work on it or keep adding more and more rules. That being said, I do think it could prove to be useful for testing and teaching neural net models.<p>In any case, at the time Lenat starting working on Cyc, we didn&#x27;t really have the compute required to do NN models at the level where they start exhibiting what most would call &quot;common sense reasoning,&quot; so it makes total sense why he started out on that path. RIP.</div><br/><div id="37357391" class="c"><input type="checkbox" id="c-37357391" checked=""/><div class="controls bullet"><span class="by">PaulDavisThe1st</span><span>|</span><a href="#37354928">parent</a><span>|</span><a href="#37356435">next</a><span>|</span><label class="collapse" for="c-37357391">[-]</label><label class="expand" for="c-37357391">[5 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2308.04445.pdf" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2308.04445.pdf</a><p>&quot;Getting from Generative AI to Trustworthy AI: What LLMs might learn from Cyc&quot;<p>Lenat&#x27;s last paper (July 31st, with Gary Marcus)<p><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37354601">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37354601</a><p>This may disabuse you of two ideas:<p><pre><code>   1. that NN models (LLMs) exhibit common sense reasoning today
   2. that the approach to AI represented by Cyc and the one represented by LLMs are mutually exclusive</code></pre></div><br/><div id="37357934" class="c"><input type="checkbox" id="c-37357934" checked=""/><div class="controls bullet"><span class="by">sshumaker</span><span>|</span><a href="#37354928">root</a><span>|</span><a href="#37357391">parent</a><span>|</span><a href="#37356435">next</a><span>|</span><label class="collapse" for="c-37357934">[-]</label><label class="expand" for="c-37357934">[4 more]</label></div><br/><div class="children"><div class="content">I don’t know about [1]. I asked an example from the paper above to GPT-4:
“[If you had to guess] how many thumbs did Lincoln’s maternal grandmother have?”<p>Response:
There is no widely available historical information to suggest that Abraham Lincoln&#x27;s maternal grandmother had an unusual number of thumbs. It would be reasonable to guess that she had the typical two thumbs, one on each hand, unless stated otherwise.</div><br/><div id="37358377" class="c"><input type="checkbox" id="c-37358377" checked=""/><div class="controls bullet"><span class="by">billyjmc</span><span>|</span><a href="#37354928">root</a><span>|</span><a href="#37357934">parent</a><span>|</span><a href="#37358334">next</a><span>|</span><label class="collapse" for="c-37358377">[-]</label><label class="expand" for="c-37358377">[1 more]</label></div><br/><div class="children"><div class="content">You didn’t ask something novel enough and&#x2F;or the LLM got “lucky”. There’s plenty of occasions where they just get it flat wrong. It’s a very bimodal distribution of competence – sometimes almost scarily superhumanly capable, and sometimes the dumbest collection of words that still form a coherent sentence.<p>The mildly entertaining YouTube video below discusses this.
<a href="https:&#x2F;&#x2F;youtu.be&#x2F;QrSCwxrLrRc" rel="nofollow noreferrer">https:&#x2F;&#x2F;youtu.be&#x2F;QrSCwxrLrRc</a></div><br/></div></div><div id="37358334" class="c"><input type="checkbox" id="c-37358334" checked=""/><div class="controls bullet"><span class="by">xpe</span><span>|</span><a href="#37354928">root</a><span>|</span><a href="#37357934">parent</a><span>|</span><a href="#37358377">prev</a><span>|</span><a href="#37358042">next</a><span>|</span><label class="collapse" for="c-37358334">[-]</label><label class="expand" for="c-37358334">[1 more]</label></div><br/><div class="children"><div class="content">ChatGPT is a hybrid system; it isn&#x27;t &quot;just&quot; an LLM any longer. What people associate with &quot;LLM&quot; is fluid. It changes over time.<p>So it is essential to clarify architecture when making claims about capabilities.<p>I&#x27;ll start simple: Plain sequence to sequence feed-forward NN models are not Turing complete. Therefore they cannot do full reasoning, because that requires arbitrary chaining.</div><br/></div></div><div id="37358042" class="c"><input type="checkbox" id="c-37358042" checked=""/><div class="controls bullet"><span class="by">PaulDavisThe1st</span><span>|</span><a href="#37354928">root</a><span>|</span><a href="#37357934">parent</a><span>|</span><a href="#37358334">prev</a><span>|</span><a href="#37356435">next</a><span>|</span><label class="collapse" for="c-37358042">[-]</label><label class="expand" for="c-37358042">[1 more]</label></div><br/><div class="children"><div class="content">You can&#x27;t show reasoning in LLMs via the answers they get right, I assert (without citations).</div><br/></div></div></div></div></div></div></div></div><div id="37356435" class="c"><input type="checkbox" id="c-37356435" checked=""/><div class="controls bullet"><span class="by">hu3</span><span>|</span><a href="#37354928">prev</a><span>|</span><a href="#37355659">next</a><span>|</span><label class="collapse" for="c-37356435">[-]</label><label class="expand" for="c-37356435">[2 more]</label></div><br/><div class="children"><div class="content">The end of the article [1] reminds me to publish more of what I make and think. I&#x27;m no Doug Lenat and my content would probably just add noise to the internet but still, don&#x27;t let your ideas die with you or become controlled by some board of stakeholders. I&#x27;m also no open-source zealot but open-source is a nice way to let others continue what you started.<p>[1]<p>&quot;Over the last year, Doug and I tried to write a long, complex paper that we never got to finish. Cyc was both awesome in its scope, and unwieldy in its implementation. The biggest problem with Cyc from an academic perspective is that it’s proprietary.<p>To help more people understand it, I tried to bring out of him what lessons he learned from Cyc, for a future generation of researchers to use. Why did it work as well as it did when it did, why did fail when it did, what was hard to implement, and what did he wish that he had done differently? ...<p>...One of his last emails to me, about six weeks ago, was an entreaty to get the paper out ASAP; on July 31, after a nerve-wracking false-start, it came out, on arXiv, Getting from Generative AI to Trustworthy AI: What LLMs might learn from Cyc (<a href="https:&#x2F;&#x2F;arxiv.org&#x2F;ftp&#x2F;arxiv&#x2F;papers&#x2F;2308&#x2F;2308.04445.pdf" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;ftp&#x2F;arxiv&#x2F;papers&#x2F;2308&#x2F;2308.04445.pdf</a>).<p>The brief article is simultaneously a review of what Cyc tried to do, an encapsulation of what we should expect from genuine artificial intelligence, and a call for reconciliation between the deep symbolic tradition that he worked in with modern Large Language Models.&quot;</div><br/><div id="37358350" class="c"><input type="checkbox" id="c-37358350" checked=""/><div class="controls bullet"><span class="by">xpe</span><span>|</span><a href="#37356435">parent</a><span>|</span><a href="#37355659">next</a><span>|</span><label class="collapse" for="c-37358350">[-]</label><label class="expand" for="c-37358350">[1 more]</label></div><br/><div class="children"><div class="content">Right on.<p>&gt; my content would probably just add noise to the internet<p>Maybe, but there is worse noise out there for sure. :) Anyhow, some unsolicited advice from me: don&#x27;t replay this quote to yourself any more than necessary; it isn&#x27;t exactly a motivational mantra masterpiece. Share what you think is important.<p>Why? Even small, &quot;improbable&quot; improvements to knowledge can to matter. Given enough of them, statistically speaking, we can move the needle. Yeah, and we need to be able to find the relevant stuff; a big problem in of itself.</div><br/></div></div></div></div><div id="37355659" class="c"><input type="checkbox" id="c-37355659" checked=""/><div class="controls bullet"><span class="by">varjag</span><span>|</span><a href="#37356435">prev</a><span>|</span><a href="#37359189">next</a><span>|</span><label class="collapse" for="c-37355659">[-]</label><label class="expand" for="c-37355659">[1 more]</label></div><br/><div class="children"><div class="content">Never met the guy but his work was one of my biggest inspirations in computing.<p>I feel it&#x27;s appropriate to link a blog post of mine from 2018. It&#x27;s a quick recap of Lenat works on the trajectory that brought him towards Cyc, with links to the papers.<p><a href="http:&#x2F;&#x2F;blog.funcall.org&#x2F;&#x2F;lisp&#x2F;2018&#x2F;11&#x2F;03&#x2F;am-eurisko-lenat-documents&#x2F;" rel="nofollow noreferrer">http:&#x2F;&#x2F;blog.funcall.org&#x2F;&#x2F;lisp&#x2F;2018&#x2F;11&#x2F;03&#x2F;am-eurisko-lenat-do...</a></div><br/></div></div><div id="37359189" class="c"><input type="checkbox" id="c-37359189" checked=""/><div class="controls bullet"><span class="by">az226</span><span>|</span><a href="#37355659">prev</a><span>|</span><a href="#37354194">next</a><span>|</span><label class="collapse" for="c-37359189">[-]</label><label class="expand" for="c-37359189">[1 more]</label></div><br/><div class="children"><div class="content">Maybe it&#x27;s a bit on the nose but I had his article summarized by Anthropic&#x27;s Claude 2 100k model (LLMs are good at summarization) for those who don&#x27;t have time to read the whole thing:<p>The article discusses generative AI models like ChatGPT and contrasts them with knowledge-based AI systems like Cyc.<p>Generative models can produce very fluent text, but they lack true reasoning abilities and can make up plausible-sounding but false information. This makes them untrustworthy.<p>In contrast, Cyc represents knowledge explicitly and can logically reason over it. This makes it more reliable, though it struggles with natural language and speed.<p>The article proposes 16 capabilities an ideal AI system should have, including explanation, reasoning, knowledge, ethics, and language skills. Cyc and generative models each have strengths and weaknesses on these dimensions.<p>The authors suggest combining symbolic systems like Cyc with generative models to get the best of both approaches. Ways to synergize them include:<p>Using Cyc to filter out false information from generative models.<p>Using Cyc&#x27;s knowledge to train generative models to be more correct.<p>Using generative models to suggest knowledge to add to Cyc&#x27;s knowledge base.<p>Using Cyc&#x27;s reasoning to expand what generative models can say.<p>Using Cyc to explain the reasoning behind generative model outputs.<p>Overall, the article argues combining reasoning-focused systems like Cyc with data-driven generative models could produce more robust and trustworthy AI. Each approach can shore up weaknesses of the other.<p>May he rest in peace.</div><br/></div></div><div id="37354194" class="c"><input type="checkbox" id="c-37354194" checked=""/><div class="controls bullet"><span class="by">dredmorbius</span><span>|</span><a href="#37359189">prev</a><span>|</span><a href="#37354203">next</a><span>|</span><label class="collapse" for="c-37354194">[-]</label><label class="expand" for="c-37354194">[28 more]</label></div><br/><div class="children"><div class="content">Cyc (&quot;Syke&quot;) is one of those projects I&#x27;ve long found vaguely fascinating though I&#x27;ve never had the time &#x2F; spoons to look into it significantly.  It&#x27;s an AI project based on a comprehensive ontology and knowledgebase.<p>Wikipedia&#x27;s overview:  &lt;<a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Cyc" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Cyc</a>&gt;<p>Project &#x2F; company homepage:  &lt;<a href="https:&#x2F;&#x2F;cyc.com&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;cyc.com&#x2F;</a>&gt;</div><br/><div id="37354471" class="c"><input type="checkbox" id="c-37354471" checked=""/><div class="controls bullet"><span class="by">jfengel</span><span>|</span><a href="#37354194">parent</a><span>|</span><a href="#37358759">next</a><span>|</span><label class="collapse" for="c-37354471">[-]</label><label class="expand" for="c-37354471">[25 more]</label></div><br/><div class="children"><div class="content">I worked with Cyc. It was an impressive attempt to do the thing that it does, but it didn&#x27;t work out. It was the last great attempt to do AI in the &quot;neat&quot; fashion, and its failure helped bring about the current, wildly successful &quot;scruffy&quot; approaches to AI.<p>It&#x27;s failure is no shade against Doug. Somebody had to try it, and I&#x27;m glad it was one of the brightest guys around. I think he clung on to it long after it was clear that it wasn&#x27;t going to work out, but breakthroughs do happen. (The current round of machine learning itself is a revival of a technique that had been abandoned, but people who stuck with it anyway discovered the tricks that made it go.)</div><br/><div id="37354856" class="c"><input type="checkbox" id="c-37354856" checked=""/><div class="controls bullet"><span class="by">dredmorbius</span><span>|</span><a href="#37354194">root</a><span>|</span><a href="#37354471">parent</a><span>|</span><a href="#37355713">next</a><span>|</span><label class="collapse" for="c-37354856">[-]</label><label class="expand" for="c-37354856">[3 more]</label></div><br/><div class="children"><div class="content">&quot;Neat&quot; vs. &quot;scruffy&quot; syncs well with my general take on Cyc.  Thanks for that.<p>I <i>do</i> suspect that well-curated and hand-tuned corpora, including possibly Cyc&#x27;s, <i>are</i> of significant use to LLM AI.  And will likely be more so as the feedback &#x2F; autophagy problem exacerbates.</div><br/><div id="37355501" class="c"><input type="checkbox" id="c-37355501" checked=""/><div class="controls bullet"><span class="by">pwillia7</span><span>|</span><a href="#37354194">root</a><span>|</span><a href="#37354856">parent</a><span>|</span><a href="#37355713">next</a><span>|</span><label class="collapse" for="c-37355501">[-]</label><label class="expand" for="c-37355501">[2 more]</label></div><br/><div class="children"><div class="content">Wow -- I hadn&#x27;t thought of this but makes total sense. We&#x27;ll need giant definitely-human-curated databases of information for AIs to consume as more information becomes generated by the AIs.</div><br/><div id="37355834" class="c"><input type="checkbox" id="c-37355834" checked=""/><div class="controls bullet"><span class="by">dredmorbius</span><span>|</span><a href="#37354194">root</a><span>|</span><a href="#37355501">parent</a><span>|</span><a href="#37355713">next</a><span>|</span><label class="collapse" for="c-37355834">[-]</label><label class="expand" for="c-37355834">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s a long history of informational classification, going back to Aristotle and earlier (&quot;Categories&quot;).  See especially Melville Dewey, the US Library of Congress Classification, and the work of Paul Otlet.  All are based on <i>exogenous classification</i>, that is, subjects and&#x2F;or works classification catalogues which are <i>independent</i> of the works classified.<p>Natural-language content-based classification as by Google and Web text-based search relies effectively on documents self-descriptions (that is, their content itself) to classify and search works, though a ranking scheme (e.g., PageRank) is typically layered on top of that.  What distinguished early Google from prior full-text search was that the latter had <i>no</i> ranking criteria, leading to keyword stuffing.  An alternative approach was Yahoo, originally Yet Another Hierarchical Officious Oracle, which was a <i>curated and ontological</i> classification of websites.  This was already proving infeasible by 1997&#x2F;98 <i>as a whole</i>, though as training data for machine classification might prove useful.</div><br/></div></div></div></div></div></div><div id="37355713" class="c"><input type="checkbox" id="c-37355713" checked=""/><div class="controls bullet"><span class="by">sanderjd</span><span>|</span><a href="#37354194">root</a><span>|</span><a href="#37354471">parent</a><span>|</span><a href="#37354856">prev</a><span>|</span><a href="#37355373">next</a><span>|</span><label class="collapse" for="c-37355713">[-]</label><label class="expand" for="c-37355713">[5 more]</label></div><br/><div class="children"><div class="content">I&#x27;m so looking forward to the next swing of the pendulum back to &quot;neat&quot;, incorporating all the progress that has been made on &quot;scruffy&quot; during this current turn of the wheel.</div><br/><div id="37355759" class="c"><input type="checkbox" id="c-37355759" checked=""/><div class="controls bullet"><span class="by">kevin_thibedeau</span><span>|</span><a href="#37354194">root</a><span>|</span><a href="#37355713">parent</a><span>|</span><a href="#37356800">next</a><span>|</span><label class="collapse" for="c-37355759">[-]</label><label class="expand" for="c-37355759">[1 more]</label></div><br/><div class="children"><div class="content">Definitely would be nice to have a ChatGPT that could reference an ontology to fact check itself.</div><br/></div></div><div id="37356800" class="c"><input type="checkbox" id="c-37356800" checked=""/><div class="controls bullet"><span class="by">DonHopkins</span><span>|</span><a href="#37354194">root</a><span>|</span><a href="#37355713">parent</a><span>|</span><a href="#37355759">prev</a><span>|</span><a href="#37355373">next</a><span>|</span><label class="collapse" for="c-37356800">[-]</label><label class="expand" for="c-37356800">[3 more]</label></div><br/><div class="children"><div class="content">The GP had the terms &quot;neat&quot; and &quot;scruffy&quot; reversed. CYC is scruffy like biology, and neural nets are neat like physics.<p>See my sibling post citing Roger Schank who coined the terms, and quoting Marvin Minsky&#x27;s paper, &quot;Logical Versus Analogical or Symbolic Versus Connectionist or Neat Versus Scruffy&quot; and the &quot;Neats and Scruffies&quot; wikipedia page.<p><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37354564">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37354564</a></div><br/><div id="37357713" class="c"><input type="checkbox" id="c-37357713" checked=""/><div class="controls bullet"><span class="by">sanderjd</span><span>|</span><a href="#37354194">root</a><span>|</span><a href="#37356800">parent</a><span>|</span><a href="#37355373">next</a><span>|</span><label class="collapse" for="c-37357713">[-]</label><label class="expand" for="c-37357713">[2 more]</label></div><br/><div class="children"><div class="content">The OPs usage seems a lot more intuitive to me, :shrug:. Neural nets don&#x27;t seem at all &quot;neat like physics&quot; to me.<p>But I guess I also don&#x27;t know enough about the CYC approach to say. Maybe neither of them fit what I think of as &quot;neat&quot;.</div><br/><div id="37358504" class="c"><input type="checkbox" id="c-37358504" checked=""/><div class="controls bullet"><span class="by">DonHopkins</span><span>|</span><a href="#37354194">root</a><span>|</span><a href="#37357713">parent</a><span>|</span><a href="#37355373">next</a><span>|</span><label class="collapse" for="c-37358504">[-]</label><label class="expand" for="c-37358504">[1 more]</label></div><br/><div class="children"><div class="content">Pamela McCorduck wrote in &quot;Machines Who Think&quot; (2004) that Cyc is &quot;a determinedly scruffy enterprise&quot;. Robert Abelson credited the terms to his &quot;unnamed but easily guessable colleague&quot; Roger Shank in his 1981 essay &quot;Constraint, Construal, and Cognitive Science&quot; in the Proceedings of the 3rd Annual Conference of the Cognitive Science, and Marvin Minsky discusses the terms in Patrick Henry Winston&#x27;s 1990 book &quot;Artificial Intelligence at MIT, Expanding Frontiers, Vol 1&quot;, and his own 1991 AI Magazine article, &quot;Logical Versus Analogical or Symbolic Versus Connectionist or Neat Versus Scruffy&quot;, but the long standing terms go back to the 70&#x27;s:<p><a href="https:&#x2F;&#x2F;ojs.aaai.org&#x2F;aimagazine&#x2F;index.php&#x2F;aimagazine&#x2F;article&#x2F;view&#x2F;894" rel="nofollow noreferrer">https:&#x2F;&#x2F;ojs.aaai.org&#x2F;aimagazine&#x2F;index.php&#x2F;aimagazine&#x2F;article...</a><p><a href="https:&#x2F;&#x2F;ojs.aaai.org&#x2F;aimagazine&#x2F;index.php&#x2F;aimagazine&#x2F;article&#x2F;download&#x2F;894&#x2F;812" rel="nofollow noreferrer">https:&#x2F;&#x2F;ojs.aaai.org&#x2F;aimagazine&#x2F;index.php&#x2F;aimagazine&#x2F;article...</a><p>&quot;We should take our cue from biology rather than physics...&quot; -Marvin Minsky<p><a href="https:&#x2F;&#x2F;grandtextauto.soe.ucsc.edu&#x2F;2008&#x2F;02&#x2F;14&#x2F;ep-44-ai-neat-and-scruffy&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;grandtextauto.soe.ucsc.edu&#x2F;2008&#x2F;02&#x2F;14&#x2F;ep-44-ai-neat-...</a><p>EP 4.4: AI, Neat and Scruffy<p>by Noah Wardrip-Fruin, 6:11 am<p>A name that does appear in Weizenbaum’s book, however, is that of Roger Schank, Abelson’s most famous collaborator. When Schank arrived from Stanford to join Abelson at Yale, together they represented the most identifiable center for a particular approach to artificial intelligence: what would later (in the early 1980s) come to be known as the “scruffy” approach. [7] Meanwhile, perhaps the most identifiable proponent of what would later be called the “neat” approach, John McCarthy, remained at Stanford.<p>McCarthy had coined the term “artificial intelligence” in the application for the field-defining workshop he organized at Dartmouth in 1956. Howard Gardner, in his influential reflection on the field, The Mind’s New Science (1985), characterized McCarthy’s neat approach this way: “McCarthy believes that the route to making machines intelligent is through a rigorous formal approach in which the acts that make up intelligence are reduced to a set of logical relationships or axioms that can be expressed precisely in mathematical terms” (154).<p>This sort of approach lent itself well to problems easily cast in formal and mathematical terms. But the scruffy branch of AI, growing out of fields such as linguistics and psychology, wanted to tackle problems of a different nature. Scruffy AI built systems for tasks as diverse as rephrasing newspaper reports, generating fictions, translating between languages, and (as we have seen) modeling ideological reasoning. In order to accomplish this, Abelson, Schank, and their collaborators developed an approach quite unlike formal reasoning from first principles. One foundation for their work was Schank’s “conceptual dependency” structure for language-independent semantic representation. Another foundation was the notion of “scripts” (later “cases”) an embryonic form of which could be seen in the calling sequence of the ideology machine’s executive. Both of these will be considered in more detail in the next chapter.<p>Scruffy AI got attention because it achieved results in areas that seemed much more “real world” than those of other approaches. For comparison’s sake, consider that the MIT AI lab, at the time of Schank’s move to Yale, was celebrating success at building systems that could understand the relationships in stacks of children’s wooden blocks. But scruffy AI was also critiqued — both within and outside the AI field — for its “unscientific” ad-hoc approach. Weizenbaum was unimpressed, in particular, with the conceptual dependency structures underlying many of the projects, writing, “Schank provides no demonstration that his scheme is more than a collection of heuristics that happen to work on specific classes of examples” (199). Whichever side one took in the debate, there can be no doubt that scruffy projects depending on coding large amounts of human knowledge into AI systems — often more than the authors acknowledged, and perhaps much more than they realized.<p>[...]<p>[7] After the terms “neat” and “scruffy” were introduced into the AI and cognitive science discourse by Abelson’s 1981 essay, in which he attributes the coinage to “an unnamed but easily guessable colleague” — Schank.<p><a href="https:&#x2F;&#x2F;cse.buffalo.edu&#x2F;~rapaport&#x2F;676&#x2F;F01&#x2F;neat.scruffy.txt" rel="nofollow noreferrer">https:&#x2F;&#x2F;cse.buffalo.edu&#x2F;~rapaport&#x2F;676&#x2F;F01&#x2F;neat.scruffy.txt</a><p><pre><code>    Article: 35704 of comp.ai
    From: engelson@bimacs.cs.biu.ac.il (Dr. Shlomo (Sean) Engelson)
    Newsgroups: comp.ai
    Subject: Re: who first used &quot;scruffy&quot; and &quot;neat&quot;?
    Date: 25 Jan 1996 08:17:13 GMT
    Organization: Bar-Ilan University Computer Science

    In article &lt;4e2th9$lkm@cantaloupe.srv.cs.cmu.edu&gt; Lonnie Chrisman &lt;ldc+@cs.cmu.edu&gt; writes:

        so@brownie.cs.wisc.edu (Bryan So) wrote:
        &gt;A question of curiosity.  Who first used the terms &quot;scruffy&quot; and &quot;neat&quot;?
        &gt;And in what document?  How about &quot;strong&quot; and &quot;weak&quot;?

        Since I don&#x27;t see a response yet, I&#x27;ll take a stab.  The earliest use of
        &quot;scruffy&quot; and &quot;neat&quot; that comes to my mind was in David Chapman&#x27;s &quot;Planning
        for Conjunctive Goals&quot;, Artificial Intelligence 32:333-377, 1987.  &quot;Weak&quot;
        evidence for this being the earliest use is that he does not cite any earlier
        use of the terms, but perhaps someone else will correct me and give an 
        earlier citation.

    One earlier citation is Eugene Charniak&#x27;s paper in AAAI 1986, &quot;A Neat
    Theory of Marker Passing&quot;.  I think, though, that the terms go way
    back in common parlance, almost certainly to the 70s at least.  Any of
    the &quot;old-timers&quot; out there like to comment?
</code></pre>
[...]<p><pre><code>    Article: 35781 of comp.ai
    From: fass@cs.sfu.ca (Dan Fass)
    Newsgroups: comp.ai
    Subject: Re: who first used &quot;scruffy&quot; and &quot;neat&quot;?
    Date: 26 Jan 1996 10:03:35 -0800
    Organization: Simon Fraser University, Burnaby, B.C.

    Abelson (1981) credits the neat&#x2F;scruffy distinction to Roger Schank. 
    Abelson says, ``an unnamed but easily guessable colleague of mine 
    ... claims that the major clashes in human affairs are between the
    &quot;neats&quot; and the &quot;scruffies&quot;.  The primary concern of the neat is
    that things should be orderly and predictable while the scruffy 
    seeks the rough-and-tumble of life as it comes&#x27;&#x27; (p. 1).

    Abelson (1981) argues that these two prototypic identities --- neat 
    and scruffy --- ``cause a very serious clash&#x27;&#x27; in cognitive science 
    and explores ``some areas in which a fusion of identities seems 
    possible&#x27;&#x27; (p. 1).

    - Dan Fass

    REF

    Abelson, Robert P. (1981).
    Constraint, Construal, and Cognitive Science.
    Proceedings of the 3rd Annual Conference of the Cognitive Science 
    Society, Berkeley, CA, pp. 1-9.
</code></pre>
[...]<p>Aaron Sloman, 1989: &quot;Introduction: Neats vs Scruffies&quot;<p><a href="https:&#x2F;&#x2F;www.cs.bham.ac.uk&#x2F;&#x2F;research&#x2F;projects&#x2F;cogaff&#x2F;misc&#x2F;scruffy.ai.text" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.cs.bham.ac.uk&#x2F;&#x2F;research&#x2F;projects&#x2F;cogaff&#x2F;misc&#x2F;scr...</a><p>&gt;There has been a long-standing opposition within AI between &quot;neats&quot; and
&quot;scruffies&quot; (I think the terms were first invented in the late 70s by
Roger Schank and&#x2F;or Bob Abelson at Yale University).<p>&gt;The neats regard it as a disgrace that many AI programs are complex,
ill-structured, and so hard to understand that it is not possible to
explain or predict their behaviour, let alone prove that they do what
they are intended to do. John McCarthy in a televised debate in 1972
once complained about the &quot;Look Ma no hands!&quot; approach. Similarly, Carl
Hewitt, complained around the same time, in seminars, about the &quot;Hairy
kludge (pronounced klooge) a month&quot; approach to software development.
(His &quot;actor&quot; system was going to be a partial solution to this.)<p>&gt;The scruffies regard messy complexity as inevitable in intelligent
systems and point to the failure so far of all attempts to find workable
clear and general mechanisms, or mathematical solutions to any important
AI problems. There are nice ideas in the General Problem Solver, logical
theorem provers, and suchlike but when confronted with non-toy problems
they normally get bogged down in combinatorial explosions. Messy
complexity, according to scruffies, lies in the nature of problem
domains (e.g. our physical environment) and only by using large numbers
of ad-hoc special-purpose rules or heuristics, and specially tailored
representational devices can problems be solved in a reasonable time.<p>Roger Schank<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Roger_Schank" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Roger_Schank</a><p>Robert Abelson<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Robert_Abelson" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Robert_Abelson</a><p>Marvin Minsky<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Marvin_Minsky" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Marvin_Minsky</a><p>Neats and scruffies<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Neats_and_scruffies" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Neats_and_scruffies</a><p>&gt;Scruffy projects in the 1980s<p>&gt;The scruffy approach was applied to robotics by Rodney Brooks in the mid-1980s. He advocated building robots that were, as he put it, Fast, Cheap and Out of Control, the title of a 1989 paper co-authored with Anita Flynn. Unlike earlier robots such as Shakey or the Stanford cart, they did not build up representations of the world by analyzing visual information with algorithms drawn from mathematical machine learning techniques, and they did not plan their actions using formalizations based on logic, such as the &#x27;Planner&#x27; language. They simply reacted to their sensors in a way that tended to help them survive and move.[13]<p>&gt;Douglas Lenat&#x27;s Cyc project was initiated in 1984 one of earliest and most ambitious projects to capture all of human knowledge in machine readable form, is &quot;a determinedly scruffy enterprise&quot;.[14] The Cyc database contains millions of facts about all the complexities of the world, each of which must be entered one at a time, by knowledge engineers. Each of these entries is an ad hoc addition to the intelligence of the system. While there may be a &quot;neat&quot; solution to the problem of commonsense knowledge (such as machine learning algorithms with natural language processing that could study the text available over the internet), no such project has yet been successful.<p>[...]<p>&gt;John Brockman writes &quot;Chomsky has always adopted the physicist&#x27;s philosophy of science, which is that you have hypotheses you check out, and that you could be wrong. This is absolutely antithetical to the AI philosophy of science, which is much more like the way a biologist looks at the world. The biologist&#x27;s philosophy of science says that human beings are what they are, you find what you find, you try to understand it, categorize it, name it, and organize it. If you build a model and it doesn&#x27;t work quite right, you have to fix it. It&#x27;s much more of a &quot;discovery&quot; view of the world.&quot;[4]</div><br/></div></div></div></div></div></div></div></div><div id="37355373" class="c"><input type="checkbox" id="c-37355373" checked=""/><div class="controls bullet"><span class="by">rvbissell</span><span>|</span><a href="#37354194">root</a><span>|</span><a href="#37354471">parent</a><span>|</span><a href="#37355713">prev</a><span>|</span><a href="#37354564">next</a><span>|</span><label class="collapse" for="c-37355373">[-]</label><label class="expand" for="c-37355373">[5 more]</label></div><br/><div class="children"><div class="content">Why not combine the two approaches?  A bicameral mind, of sorts?</div><br/><div id="37355575" class="c"><input type="checkbox" id="c-37355575" checked=""/><div class="controls bullet"><span class="by">jfengel</span><span>|</span><a href="#37354194">root</a><span>|</span><a href="#37355373">parent</a><span>|</span><a href="#37355878">next</a><span>|</span><label class="collapse" for="c-37355575">[-]</label><label class="expand" for="c-37355575">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m sure somebody somewhere is working on it. I&#x27;ve already seen articles teaching LLMs offload math problems onto a separate module, rather than trying to solve them via the murk of neural network.<p>I suppose you&#x27;d architect it as a layer. It wants to say something, and the ontology layer says, &quot;No, that&#x27;s stupid, say something else&quot;. The ontology layer can recognize ontology-like statements and use them to build and evolve the ontology.<p>It would be even more interesting built into the visual&#x2F;image models.<p>I have no idea if that&#x27;s any kind of real progress, or if it&#x27;s merely filtering out the dumb stuff. A good service, to be sure, but still not &quot;AGI&quot;, whatever the hell that turns out to be.<p>Unless it turns out to be the missing element that puts it over the top. If I had any idea I wouldn&#x27;t have been working with Cyc in the first place.</div><br/></div></div><div id="37355878" class="c"><input type="checkbox" id="c-37355878" checked=""/><div class="controls bullet"><span class="by">mindcrime</span><span>|</span><a href="#37354194">root</a><span>|</span><a href="#37355373">parent</a><span>|</span><a href="#37355575">prev</a><span>|</span><a href="#37357399">next</a><span>|</span><label class="collapse" for="c-37355878">[-]</label><label class="expand" for="c-37355878">[1 more]</label></div><br/><div class="children"><div class="content">There are absolutely people working on this concept. In fact, the two day long &quot;Neuro-Symbolic AI Summer School 2023&quot;[1] just concluded earlier this week. It was two days of hearing about cutting edge research at the intersection of &quot;neural&quot; approaches (taking a big-tent view where that included most probabilistic approaches) and &quot;symbolic&quot; (eg, &quot;logic based&quot;) approaches. And while this approach might not be <i>the</i> contemporary mainstream approach, there were some heavy hitters presenting, including the likes of Leslie Valiant and Yoshua Bengio.<p>[1]: <a href="https:&#x2F;&#x2F;neurosymbolic.github.io&#x2F;nsss2023&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;neurosymbolic.github.io&#x2F;nsss2023&#x2F;</a></div><br/></div></div><div id="37357399" class="c"><input type="checkbox" id="c-37357399" checked=""/><div class="controls bullet"><span class="by">PaulDavisThe1st</span><span>|</span><a href="#37354194">root</a><span>|</span><a href="#37355373">parent</a><span>|</span><a href="#37355878">prev</a><span>|</span><a href="#37359235">next</a><span>|</span><label class="collapse" for="c-37357399">[-]</label><label class="expand" for="c-37357399">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2308.04445.pdf" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2308.04445.pdf</a><p>is precisely Doug Lenat &amp; Gary Marcus&#x27; thoughts on how to combine them (July 31st 2023, Lenat&#x27;s last paper)</div><br/></div></div><div id="37359235" class="c"><input type="checkbox" id="c-37359235" checked=""/><div class="controls bullet"><span class="by">DonHopkins</span><span>|</span><a href="#37354194">root</a><span>|</span><a href="#37355373">parent</a><span>|</span><a href="#37357399">prev</a><span>|</span><a href="#37354564">next</a><span>|</span><label class="collapse" for="c-37359235">[-]</label><label class="expand" for="c-37359235">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s right, and left! ;) Fusing the &quot;scruffy&quot; and &quot;neat&quot; approaches has been the idea since the terms were coined by Roger Schank in the 70&#x27;s and written about in 1982 by Robert Abelson in his Major Address of the Proceedings of the 3rd Annual Conference of the Cognitive Science Society in &quot;Constraint, Construal, and Cognitive Science&quot; (page 1).<p>His question is: Is it preferable for scruffies to become neater, or for neats to become scruffier? His answer explains why he aspires to be a neater scruffy.<p>&quot;But I use the example as symptomatic of one kind of approach to the cognitive science fusion problem: you start from a neat, right-wing point of view, but acknowledge some limited role for scruffy, left-wing orientations. The other type of approach is the obvious mirror: you start from the disorderly leftwing side and struggle to be neater about what you are doing. I prefer the latter approach to the former. I will tell you why, and then lay out the beginnings of such an approach.&quot;<p><a href="https:&#x2F;&#x2F;cse.buffalo.edu&#x2F;~rapaport&#x2F;676&#x2F;F01&#x2F;neat.scruffy.txt" rel="nofollow noreferrer">https:&#x2F;&#x2F;cse.buffalo.edu&#x2F;~rapaport&#x2F;676&#x2F;F01&#x2F;neat.scruffy.txt</a><p><pre><code>    Article: 35781 of comp.ai
    From: fass@cs.sfu.ca (Dan Fass)
    Newsgroups: comp.ai
    Subject: Re: who first used &quot;scruffy&quot; and &quot;neat&quot;?
    Date: 26 Jan 1996 10:03:35 -0800
    Organization: Simon Fraser University, Burnaby, B.C.

    Abelson (1981) credits the neat&#x2F;scruffy distinction to Roger Schank. 
    Abelson says, ``an unnamed but easily guessable colleague of mine 
    ... claims that the major clashes in human affairs are between the
    &quot;neats&quot; and the &quot;scruffies&quot;.  The primary concern of the neat is
    that things should be orderly and predictable while the scruffy 
    seeks the rough-and-tumble of life as it comes&#x27;&#x27; (p. 1).

    Abelson (1981) argues that these two prototypic identities --- neat 
    and scruffy --- ``cause a very serious clash&#x27;&#x27; in cognitive science 
    and explores ``some areas in which a fusion of identities seems 
    possible&#x27;&#x27; (p. 1).

    - Dan Fass

    REF

    Abelson, Robert P. (1981).
    Constraint, Construal, and Cognitive Science.
    Proceedings of the 3rd Annual Conference of the Cognitive Science 
    Society, Berkeley, CA, pp. 1-9.
</code></pre>
<a href="https:&#x2F;&#x2F;cognitivesciencesociety.org&#x2F;wp-content&#x2F;uploads&#x2F;2019&#x2F;01&#x2F;cogsci_3.pdf" rel="nofollow noreferrer">https:&#x2F;&#x2F;cognitivesciencesociety.org&#x2F;wp-content&#x2F;uploads&#x2F;2019&#x2F;...</a><p>[I&#x27;ll quote the most relevant first part of the article, which is still worth reading in its entirety if you have time, since scanned two column pdf files are so hard to read on mobile, and it&#x27;s so interesting and relevant to Douglas Lenat&#x27;s work on Cyc.]<p>CONSTRAINT, CONSTRUAL, AND COGNITIVE SCIENCE<p>Robert P. Abelson, Yale University<p>Cognitive science has barely emerged as a
discipline -- or an interdiscipline, or whatever it
is -- and already it is having an identity crisis.<p>Within us and among us we have many competing
identities. Two particular prototypic identities
cause a very serious clash, and I would like to
explicate this conflict and then explore some areas
in which a fusion of identities seems possible.
Consider the two-word name &quot;cognitive science&quot;.
It represents a hybridization of two different
impulses. On the one hand, we want to study human
and artificial cognition, the structure of mental
representatives, the nature of mind. On the other
hand, we want to be scientific, be principled,
be exact. These two impulses are not necessarily
incompatible, but given free rein they can develop
what seems to be a diametric opposition.<p>The study of the knowledge in a mental system
tends toward both naturalism and phenomenology.
The mind needs to represent what is out there
in the real world, and it needs to manipulate it
for particular purposes. But the world is messy,
and purposes are manifold. Models of mind,
therefore, can become garrulous and intractable
as they become more and more realistic. If one&#x27;s
emphasis is on science more than on cognition,
however, the canons of hard science dictate a strategy
of the isolation of idealized subsystems which can
be modeled with elegant productive formalisms.
Clarity and precision are highly prized, even at
the expense of common sense realism. To caricature
this tendency with a phrase from John Tukey (1959),
the motto of the narrow hard scientist is, &quot;Be
exactly wrong, rather than approximately right&quot;.<p>The one tendency points inside the mind, to see
what might be there. The other points outside the
mind, to some formal system which can be logically
manipulated (Kintsch et al., 1981). Neither camp
grants the other a legitimate claim on cognitive
science. One side says, &quot;What you&#x27;re doing may seem
to be science, but it&#x27;s got nothing to do with
cognition.&quot; The other side says, &quot;What you&#x27;re
doing may seem to be about cognition, but it&#x27;s
got nothing to do with science.&quot;<p>Superficially, it may seem that the trouble
arises primarily because of the two-headed name
cognitive science. I well remember the discussions
of possible names, even though I never liked
&quot;cognitive science&quot;, the alternatives were worse;
abominations like &quot;epistology&quot; or &quot;representonomy&quot;.<p>But in any case, the conflict goes far deeper
than the name itself. Indeed, the stylistic division
is the same polarization than arises in all fields
of science, as well as in art, in politics, in
religion, in child rearing -- and in all spheres
of human endeavor. Psychologist Silvan Tomkins
(1965) characterizes this overriding conflict as
that between characterologically left-wing and
right-wing world views. The left-wing personality
finds the sources of value and truth to lie within
individuals, whose reactions to the world define
what is important. The right-wing personality
asserts that all human behavior is to be understood 
and judged according to rules or norms which
exist independent of human reaction. A similar
distinction has been made by an unnamed but easily
guessable colleague of mine, who claims that the
major clashes in human affairs are between the &quot;neats&quot;
and the &quot;scruffies&quot;. The primary concern of the
neat is that things should be orderly and predictable
while the scruffy seeks the rough-and-tumble of
life as it comes.<p>I am exaggerating slightly, but only slightly,
in saying that the major disagreements within
cognitive science are instantiations of a ubiquitous
division between neat right-wing analysis and scruffy
left-wing ideation. In truth there are some signs
of an attempt to fuse or to compromise these two
tendencies. Indeed, one could view the success of
cognitive science as primarily dependent not upon
the cooperation of linguistics, AI, psychology, etc.,
but rather, upon the union of clashing world views
about the fundamental nature of mentation. Hopefully,
we can be open minded and realistic about the
important contents of thought at the same time we
are principled, even elegant, in our characterizations 
of the forms of thought.<p>The fusion task is not easy. It is hard to
neaten up a scruffy or scruffy up a neat. It is
difficult to formalize aspects of human thought
which are variable, disorderly, and seemingly
irrational, or to build tightly principled models
of realistic language processing in messy natural
domains. Writings about cognitive science are
beginning to show a recognition of the need for
world-view unification, but the signs of strain are
clear. Consider the following passage from a
recent article by Frank Keil (1981) in Pscyhological
Review, giving background for a discussion of his
formalistic analysis of the concept of constraint:<p>&quot;Constraints will be defined...as formal
restrictions that limit the class of logically
possible knowledge structures that can normally
be used in a given cognitive domain.&quot; (p. 198).<p>Now, what is the word &quot;normally&quot; doing in a
statement about logical possibility? Does it mean
that something which is logically impossible can be
used if conditions are not normal? This seems to
require a cognitive hyperspace where the impossible
is possible.<p>It is not my intention to disparage an author
on the basis of a single statement infelicitously
put. I think he was genuinely trying to come to
grips with the reality that there is some boundary
somewhere to the penetration of his formal constraint
analysis into the viscissitudes of human affairs.
But I use the example as symptomatic of one kind of
approach to the cognitive science fusion problem:
you start from a neat, right-wing point of view, but
acknowledge some limited role for scruffy, left-wing
orientations. The other type of approach is the
obvious mirror: you start from the disorderly leftwing 
side and struggle to be neater about what you
are doing. I prefer the latter approach to the
former. I will tell you why, and then lay out the
beginnings of such an approach.<p>[...]<p>To read why and how:<p><a href="https:&#x2F;&#x2F;cognitivesciencesociety.org&#x2F;wp-content&#x2F;uploads&#x2F;2019&#x2F;01&#x2F;cogsci_3.pdf" rel="nofollow noreferrer">https:&#x2F;&#x2F;cognitivesciencesociety.org&#x2F;wp-content&#x2F;uploads&#x2F;2019&#x2F;...</a></div><br/></div></div></div></div><div id="37354564" class="c"><input type="checkbox" id="c-37354564" checked=""/><div class="controls bullet"><span class="by">DonHopkins</span><span>|</span><a href="#37354194">root</a><span>|</span><a href="#37354471">parent</a><span>|</span><a href="#37355373">prev</a><span>|</span><a href="#37354789">next</a><span>|</span><label class="collapse" for="c-37354564">[-]</label><label class="expand" for="c-37354564">[2 more]</label></div><br/><div class="children"><div class="content">As Roger Schank defined the terms in the 70&#x27;s, &quot;Neat&quot; refers to using a single formal paradigm, logic, math, neural networks, and LLMs, like physics. &quot;Scruffy&quot; refers to combining many different algorithms and approaches, symbolic manipulation, hand coded logic, knowledge engineering, and CYC, like biology.<p>I believe both approaches are useful and can be combined and layered and fed back into each other, to reinforce and transcend complement each others advantages and limitations.<p>Kind of like how Hailey and Justin Bieber make the perfect couple: ;)<p><a href="https:&#x2F;&#x2F;edition.cnn.com&#x2F;style&#x2F;hailey-justin-bieber-couples-fashion-lotw&#x2F;index.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;edition.cnn.com&#x2F;style&#x2F;hailey-justin-bieber-couples-f...</a><p>Marvin L Minsky: Logical Versus Analogical or Symbolic Versus Connectionist or Neat Versus Scruffy<p><a href="https:&#x2F;&#x2F;ojs.aaai.org&#x2F;aimagazine&#x2F;index.php&#x2F;aimagazine&#x2F;article&#x2F;view&#x2F;894" rel="nofollow noreferrer">https:&#x2F;&#x2F;ojs.aaai.org&#x2F;aimagazine&#x2F;index.php&#x2F;aimagazine&#x2F;article...</a><p><a href="https:&#x2F;&#x2F;ojs.aaai.org&#x2F;aimagazine&#x2F;index.php&#x2F;aimagazine&#x2F;article&#x2F;download&#x2F;894&#x2F;812" rel="nofollow noreferrer">https:&#x2F;&#x2F;ojs.aaai.org&#x2F;aimagazine&#x2F;index.php&#x2F;aimagazine&#x2F;article...</a><p>&quot;We should take our cue from biology rather than physics...&quot; -Marvin Minsky<p>&gt;To get around these limitations, we must develop systems that combine the expressiveness and procedural versatility of symbolic systems with the fuzziness and adaptiveness of connectionist representations. Why has there been so little work on synthesizing these techniques? I suspect that it is because both of these AI communities suffer from a common cultural-philosophical disposition: They would like to explain intelligence in the image of what was successful in physics—by minimizing the amount and variety of its assumptions. But this seems to be a wrong ideal. We should take our cue from biology rather than physics because what we call thinking does not directly emerge from a few fundamental principles of wave-function symmetry and exclusion rules. Mental activities are not the sort of unitary or elementary phenomenon that can be described by a few mathematical operations on logical axioms. Instead, the functions performed by the brain are the products of the work of thousands of different, specialized subsystems, the intricate product of hundreds of millions of years of biological evolution. We cannot hope to understand such an organization by emulating the techniques of those particle physicists who search for the simplest possible unifying conceptions. Constructing a mind is simply a different kind of problem—how to synthesize organizational systems that can support a large enough diversity of different schemes yet enable them to work together to exploit one another’s abilities.<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Neats_and_scruffies" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Neats_and_scruffies</a><p>&gt;In the history of artificial intelligence, neat and scruffy are two contrasting approaches to artificial intelligence (AI) research. The distinction was made in the 70s and was a subject of discussion until the middle 80s.[1][2][3]<p>&gt;&quot;Neats&quot; use algorithms based on a single formal paradigms, such as logic, mathematical optimization or neural networks. Neats verify their programs are correct with theorems and mathematical rigor. Neat researchers and analysts tend to express the hope that this single formal paradigm can be extended and improved to achieve general intelligence and superintelligence.<p>&gt;&quot;Scruffies&quot; use any number of different algorithms and methods to achieve intelligent behavior. Scruffies rely on incremental testing to verify their programs and scruffy programming requires large amounts of hand coding or knowledge engineering. Scruffies have argued that general intelligence can only be implemented by solving a large number of essentially unrelated problems, and that there is no magic bullet that will allow programs to develop general intelligence autonomously.<p>&gt;John Brockman compares the neat approach to physics, in that it uses simple mathematical models as its foundation. The scruffy approach is more like biology, where much of the work involves studying and categorizing diverse phenomena.[a]<p>[...]<p>&gt;Modern AI as both neat and scruffy<p>&gt;New statistical and mathematical approaches to AI were developed in the 1990s, using highly developed formalisms such as mathematical optimization and neural networks. Pamela McCorduck wrote that &quot;As I write, AI enjoys a Neat hegemony, people who believe that machine intelligence, at least, is best expressed in logical, even mathematical terms.&quot;[6] This general trend towards more formal methods in AI was described as &quot;the victory of the neats&quot; by Peter Norvig and Stuart Russell in 2003.[18]<p>&gt;However, by 2021, Russell and Norvig had changed their minds.[19] Deep learning networks and machine learning in general require extensive fine tuning -- they must be iteratively tested until they begin to show the desired behavior. This is a scruffy methodology.</div><br/><div id="37354646" class="c"><input type="checkbox" id="c-37354646" checked=""/><div class="controls bullet"><span class="by">at_a_remove</span><span>|</span><a href="#37354194">root</a><span>|</span><a href="#37354564">parent</a><span>|</span><a href="#37354789">next</a><span>|</span><label class="collapse" for="c-37354646">[-]</label><label class="expand" for="c-37354646">[1 more]</label></div><br/><div class="children"><div class="content">Neats and scruffies also showed up in The X-Files in their first AI episode.</div><br/></div></div></div></div><div id="37354789" class="c"><input type="checkbox" id="c-37354789" checked=""/><div class="controls bullet"><span class="by">Kuinox</span><span>|</span><a href="#37354194">root</a><span>|</span><a href="#37354471">parent</a><span>|</span><a href="#37354564">prev</a><span>|</span><a href="#37358759">next</a><span>|</span><label class="collapse" for="c-37354789">[-]</label><label class="expand" for="c-37354789">[9 more]</label></div><br/><div class="children"><div class="content">Why did it didn&#x27;t work out ?</div><br/><div id="37355104" class="c"><input type="checkbox" id="c-37355104" checked=""/><div class="controls bullet"><span class="by">jfengel</span><span>|</span><a href="#37354194">root</a><span>|</span><a href="#37354789">parent</a><span>|</span><a href="#37354930">next</a><span>|</span><label class="collapse" for="c-37355104">[-]</label><label class="expand" for="c-37355104">[5 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t know if there&#x27;s really an answer to that, beyond noting that it never turned out to be more than the sum of its parts. It was a large ontology and a hefty logic engine. You put in queries and you got back answers.<p>The goal was that in a decade it would become self-sustaining. It would have enough knowledge that it could start reading natural language. And it just... didn&#x27;t.<p>Contrast it with LLMs and diffusion and such. They make stupid, asinine mistakes -- real howlers, because they don&#x27;t understand anything at all about the world. If it could draw, Cyc would never draw a human with 7 fingers on each hand, because it knows that most humans have 5. (It had a decent-ish ontology of human anatomy which could handle injuries and birth defects, but would default reason over the normal case.) I often see ChatGPT stumped by simple variations of brain teasers, and Cyc wouldn&#x27;t make those mistakes -- once you&#x27;d translated them into CycL (its language, because it couldn&#x27;t read natural language in any meaningful way).<p>But those same models do a scary job of passing the Turing Test. Nobody would ever have thought to try it on Cyc. It was never anywhere close.<p>Philosophically I can&#x27;t say why Cyc never developed &quot;magic&quot; and LLMs (seemingly) do. And I&#x27;m still not convinced that they&#x27;re on the right path, though they actually have some legitimate usages right now. I tried to find uses for Cyc in exactly the opposite direction, guaranteeing data quality, but it turned out nobody really wanted that.</div><br/><div id="37355287" class="c"><input type="checkbox" id="c-37355287" checked=""/><div class="controls bullet"><span class="by">dredmorbius</span><span>|</span><a href="#37354194">root</a><span>|</span><a href="#37355104">parent</a><span>|</span><a href="#37357073">next</a><span>|</span><label class="collapse" for="c-37355287">[-]</label><label class="expand" for="c-37355287">[1 more]</label></div><br/><div class="children"><div class="content">One sense that I&#x27;ve had of LLM &#x2F; generative AIs is that they lack &quot;bones&quot;, in the sense that there&#x27;s no underlying structure to which they adhere, only outward appearances which are statistically correlated (using fantastically complex statistical correlation maps).<p>Cyc, on the other hand, lacks flesh and skin.  It&#x27;s <i>all</i> skeleton and can generate facts but not embellish them into narratives.<p>The best human writing has <i>both</i>, much as artists (traditional painters, sculptors, and more recently computer animators) has a <i>skeleton</i> (outline, index cards, Zettlekasten, wireframe) to which flesh, skin, and fur are attached.  LLM generative AIs are <i>too</i> plastic, Cyc is <i>insufficiently</i> plastic.<p>I suspect there&#x27;s some sort of a middle path between the two.  Though that path and its destination also increasingly terrify me.</div><br/></div></div><div id="37357073" class="c"><input type="checkbox" id="c-37357073" checked=""/><div class="controls bullet"><span class="by">Kuinox</span><span>|</span><a href="#37354194">root</a><span>|</span><a href="#37355104">parent</a><span>|</span><a href="#37355287">prev</a><span>|</span><a href="#37355745">next</a><span>|</span><label class="collapse" for="c-37357073">[-]</label><label class="expand" for="c-37357073">[1 more]</label></div><br/><div class="children"><div class="content">Thanks - that&#x27;s was the kind of answer I wanted.  
Is there any work trying to &quot;merge&quot; the two together ?</div><br/></div></div><div id="37355745" class="c"><input type="checkbox" id="c-37355745" checked=""/><div class="controls bullet"><span class="by">bpiche</span><span>|</span><a href="#37354194">root</a><span>|</span><a href="#37355104">parent</a><span>|</span><a href="#37357073">prev</a><span>|</span><a href="#37356478">next</a><span>|</span><label class="collapse" for="c-37355745">[-]</label><label class="expand" for="c-37355745">[1 more]</label></div><br/><div class="children"><div class="content">Had? Cycorp is still around and deploying their software.</div><br/></div></div><div id="37356478" class="c"><input type="checkbox" id="c-37356478" checked=""/><div class="controls bullet"><span class="by">ushakov</span><span>|</span><a href="#37354194">root</a><span>|</span><a href="#37355104">parent</a><span>|</span><a href="#37355745">prev</a><span>|</span><a href="#37354930">next</a><span>|</span><label class="collapse" for="c-37356478">[-]</label><label class="expand" for="c-37356478">[1 more]</label></div><br/><div class="children"><div class="content">Sounds similar to WolframAlpha?</div><br/></div></div></div></div><div id="37354930" class="c"><input type="checkbox" id="c-37354930" checked=""/><div class="controls bullet"><span class="by">jfoutz</span><span>|</span><a href="#37354194">root</a><span>|</span><a href="#37354789">parent</a><span>|</span><a href="#37355104">prev</a><span>|</span><a href="#37358759">next</a><span>|</span><label class="collapse" for="c-37354930">[-]</label><label class="expand" for="c-37354930">[3 more]</label></div><br/><div class="children"><div class="content">Take a look at <a href="https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;SHRDLU" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;SHRDLU</a><p>Cyc is sort of like that, but for everything. Not just a small limited world. I believe it didn’t work out because it’s really hard.</div><br/><div id="37355184" class="c"><input type="checkbox" id="c-37355184" checked=""/><div class="controls bullet"><span class="by">ansible</span><span>|</span><a href="#37354194">root</a><span>|</span><a href="#37354930">parent</a><span>|</span><a href="#37358759">next</a><span>|</span><label class="collapse" for="c-37355184">[-]</label><label class="expand" for="c-37355184">[2 more]</label></div><br/><div class="children"><div class="content">If we are to develop understandable AGI, I think that some kind of (mathematically correct) probabilistic reasoning based on a symbolic knowledge base is the way to go. You would probably need to have some version of a Neural Net on the front end to make it useful though.<p>So you&#x27;d use the NN to recognize that the thing in front of the camera is a cat, and that would be fed into the symbolic knowledge base for further reasoning.<p>The knowledge base will contain facts like the cat is likely to &quot;meow&quot; at some point, especially if it wants attention. Based on the relevant context, the knowledge base would also know that the cat is unlikely to be able to talk, unless it is a cat in a work of fiction, for example.</div><br/><div id="37357035" class="c"><input type="checkbox" id="c-37357035" checked=""/><div class="controls bullet"><span class="by">DonHopkins</span><span>|</span><a href="#37354194">root</a><span>|</span><a href="#37355184">parent</a><span>|</span><a href="#37358759">next</a><span>|</span><label class="collapse" for="c-37357035">[-]</label><label class="expand" for="c-37357035">[1 more]</label></div><br/><div class="children"><div class="content">At Leela AI we&#x27;re developing hybrid symbolic-connectionist constructivist AI, combining &quot;neat&quot; neural networks with &quot;scruffy&quot; symbolic logic, enabling unsupervised machine learning that understands cause and effect and teaches itself, motivated by intrinsic curiosity.<p>Leela AI was founded by Henry Minsky and Cyrus Shaoul, and is inspired by ideas about child development by Jean Piaget, Seymour Papert, Marvin Minsky, and Gary Drescher (described in his book “Made-Up Minds”).<p><a href="https:&#x2F;&#x2F;mitpress.mit.edu&#x2F;9780262517089&#x2F;made-up-minds&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;mitpress.mit.edu&#x2F;9780262517089&#x2F;made-up-minds&#x2F;</a><p><a href="https:&#x2F;&#x2F;leela.ai&#x2F;leela-core" rel="nofollow noreferrer">https:&#x2F;&#x2F;leela.ai&#x2F;leela-core</a><p>&gt;Leela Platform is powered by Leela Core, an innovative AI engine based on research at the MIT Artificial Intelligence Lab. With its dynamic combination of traditional neural networks for pattern recognition and causal-symbolic networks for self-discovery, Leela Core goes beyond accurately recognizing objects to comprehend processes, concepts, and causal connections.<p>&gt;Leela Core is much faster to train than conventional NNs, using 100x less data and enabling 10x less time-to-value. This highly resilient AI can quickly adjust to changes and explain what it is sensing and doing via the Leela Viewer dashboard. [...]<p>The key to regulating AI is explainability. The key to explainability may be causal AI.<p><a href="https:&#x2F;&#x2F;leela.ai&#x2F;post&#x2F;the-key-to-regulating-ai-is-explainability-the-key-to-explainability-may-be-causal-ai" rel="nofollow noreferrer">https:&#x2F;&#x2F;leela.ai&#x2F;post&#x2F;the-key-to-regulating-ai-is-explainabi...</a><p>&gt;[...] For example, the Leela Core engine that drives the Leela Platform for visual intelligence in manufacturing adds a symbolic causal agent that can reason about the world in a way that is more familiar to the human mind than neural networks. The causal layer can cross-check Leela Core&#x27;s traditional NN components in a hybrid causal&#x2F;neural architecture. Leela Core is already better at explaining its decisions than NN-only platforms, making it easier to troubleshoot and customize. Much greater transparency is expected in future versions. [...]</div><br/></div></div></div></div></div></div></div></div></div></div><div id="37358759" class="c"><input type="checkbox" id="c-37358759" checked=""/><div class="controls bullet"><span class="by">ks2048</span><span>|</span><a href="#37354194">parent</a><span>|</span><a href="#37354471">prev</a><span>|</span><a href="#37357158">next</a><span>|</span><label class="collapse" for="c-37358759">[-]</label><label class="expand" for="c-37358759">[1 more]</label></div><br/><div class="children"><div class="content">Unfortunately visiting cyc.com, I only see a bunch of business BS and the &quot;Documention&quot; page shows nothing without logging in.</div><br/></div></div><div id="37357158" class="c"><input type="checkbox" id="c-37357158" checked=""/><div class="controls bullet"><span class="by">tootie</span><span>|</span><a href="#37354194">parent</a><span>|</span><a href="#37358759">prev</a><span>|</span><a href="#37354203">next</a><span>|</span><label class="collapse" for="c-37357158">[-]</label><label class="expand" for="c-37357158">[1 more]</label></div><br/><div class="children"><div class="content">As far as I can tell it was more of an aspiration than a product. I worked with a consulting firm that tried to get into AI a few years back and chose Cyc as the platform they wanted to sell to (mostly financial) clients. I don&#x27;t think a single project ever even started nor was there a clear picture of what could be sold. I hate to think Lenat was a fraud because he certainly seemed like a sincere and brilliant person, but I think Cyc was massively oversold despite never doing much of anything useful. The website is full technical language and not a single case study after 40 years in business.</div><br/></div></div></div></div><div id="37354203" class="c"><input type="checkbox" id="c-37354203" checked=""/><div class="controls bullet"><span class="by">ftxbro</span><span>|</span><a href="#37354194">prev</a><span>|</span><a href="#37356169">next</a><span>|</span><label class="collapse" for="c-37354203">[-]</label><label class="expand" for="c-37354203">[1 more]</label></div><br/><div class="children"><div class="content">Here&#x27;s a 2016 Wired article about Doug Lenat, he was the guy who made Eurisko and CYC <a href="https:&#x2F;&#x2F;www.wired.com&#x2F;2016&#x2F;03&#x2F;doug-lenat-artificial-intelligence-common-sense-engine&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.wired.com&#x2F;2016&#x2F;03&#x2F;doug-lenat-artificial-intellig...</a></div><br/></div></div><div id="37356169" class="c"><input type="checkbox" id="c-37356169" checked=""/><div class="controls bullet"><span class="by">nyx_land</span><span>|</span><a href="#37354203">prev</a><span>|</span><a href="#37354795">next</a><span>|</span><label class="collapse" for="c-37356169">[-]</label><label class="expand" for="c-37356169">[1 more]</label></div><br/><div class="children"><div class="content">Weird, I interviewed with him summer 2021 hoping to be able to land an ontologist job at Cycorp. It went spectacularly badly because it turned out I really needed to brush up more on my formal logic skills, but I was surprised to even get an interview, let alone with the man himself. He still encouraged me to work on reviewing logic and to apply again in the future but I stopped seeing listings at Cycorp for ontologists and started putting off returning to that aspiration thinking Cycorp has been around long enough that there was no rush. Memento mori</div><br/></div></div><div id="37354795" class="c"><input type="checkbox" id="c-37354795" checked=""/><div class="controls bullet"><span class="by">nikolay</span><span>|</span><a href="#37356169">prev</a><span>|</span><a href="#37358059">next</a><span>|</span><label class="collapse" for="c-37354795">[-]</label><label class="expand" for="c-37354795">[1 more]</label></div><br/><div class="children"><div class="content">Even being a controversial figure, he was one of my heroes. Getting excited about Eurisko in the &#x27;80s and &#x27;90s was a big driver for me at the time! Rest in piece, dear computer pioneer!</div><br/></div></div><div id="37358059" class="c"><input type="checkbox" id="c-37358059" checked=""/><div class="controls bullet"><span class="by">xpe</span><span>|</span><a href="#37354795">prev</a><span>|</span><a href="#37356201">next</a><span>|</span><label class="collapse" for="c-37358059">[-]</label><label class="expand" for="c-37358059">[2 more]</label></div><br/><div class="children"><div class="content">Perhaps some here aren&#x27;t familiar with the existence of a (relatively useless in my opinion) POV that pits symbolic systems against statistical methods. But it isn&#x27;t a zero-sum game. Informed, insightful comparisons are useful, but &quot;holy wars&quot; are not. See also [1] for broad commentary and [2] for a particular application.<p>[1] <a href="https:&#x2F;&#x2F;medium.com&#x2F;@jcbaillie&#x2F;beyond-the-symbolic-vs-non-symbolic-ai-debate-96dffce7270c" rel="nofollow noreferrer">https:&#x2F;&#x2F;medium.com&#x2F;@jcbaillie&#x2F;beyond-the-symbolic-vs-non-sym...</a><p>[2] <a href="https:&#x2F;&#x2F;past.date-conference.com&#x2F;proceedings-archive&#x2F;2016&#x2F;pdf&#x2F;0954.pdf" rel="nofollow noreferrer">https:&#x2F;&#x2F;past.date-conference.com&#x2F;proceedings-archive&#x2F;2016&#x2F;pd...</a></div><br/><div id="37358359" class="c"><input type="checkbox" id="c-37358359" checked=""/><div class="controls bullet"><span class="by">xpe</span><span>|</span><a href="#37358059">parent</a><span>|</span><a href="#37356201">next</a><span>|</span><label class="collapse" for="c-37358359">[-]</label><label class="expand" for="c-37358359">[1 more]</label></div><br/><div class="children"><div class="content">This sibling thread is apropos too: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37356435">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37356435</a></div><br/></div></div></div></div><div id="37356201" class="c"><input type="checkbox" id="c-37356201" checked=""/><div class="controls bullet"><span class="by">mrcwinn</span><span>|</span><a href="#37358059">prev</a><span>|</span><a href="#37347849">next</a><span>|</span><label class="collapse" for="c-37356201">[-]</label><label class="expand" for="c-37356201">[1 more]</label></div><br/><div class="children"><div class="content">Here&#x27;s one for you, Doug. My condolences.<p><a href="https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;dbd59c92-696b-45d3-8097-c09a2350d7b6" rel="nofollow noreferrer">https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;dbd59c92-696b-45d3-8097-c09a23...</a></div><br/></div></div><div id="37347849" class="c"><input type="checkbox" id="c-37347849" checked=""/><div class="controls bullet"><span class="by">Rochus</span><span>|</span><a href="#37356201">prev</a><span>|</span><a href="#37347581">next</a><span>|</span><label class="collapse" for="c-37347849">[-]</label><label class="expand" for="c-37347849">[2 more]</label></div><br/><div class="children"><div class="content">He was a hero of knowledge representation and ontology. A bit odd that we learn about his sad passing from a Wikipedia article, while at the time of this comment there is still no mention on e.g. <a href="https:&#x2F;&#x2F;cyc.com&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;cyc.com&#x2F;</a>.</div><br/><div id="37355343" class="c"><input type="checkbox" id="c-37355343" checked=""/><div class="controls bullet"><span class="by">Rochus</span><span>|</span><a href="#37347849">parent</a><span>|</span><a href="#37347581">next</a><span>|</span><label class="collapse" for="c-37355343">[-]</label><label class="expand" for="c-37355343">[1 more]</label></div><br/><div class="children"><div class="content">Thirteen hours later still no mention on the Cycorp website. Also the press doesn&#x27;t seem to notice. Pretty odd.<p>The post originally pointed to Lenat&#x27;s Wikipedia page; now it&#x27;s an obituary by Gary Marcus which seems more appropriate.</div><br/></div></div></div></div><div id="37347581" class="c"><input type="checkbox" id="c-37347581" checked=""/><div class="controls bullet"><span class="by">mrmincent</span><span>|</span><a href="#37347849">prev</a><span>|</span><a href="#37358731">next</a><span>|</span><label class="collapse" for="c-37347581">[-]</label><label class="expand" for="c-37347581">[1 more]</label></div><br/><div class="children"><div class="content">Sad to hear of his passing, I remember building my uni project around OpenCyc in my one “Intelligent Systems” class many many years ago. It was a dismal failure as my ambition far exceeded my skills, but it was so enjoyable reading about Cyc and the dedicated work Douglas had put in over such a long time.</div><br/></div></div><div id="37358731" class="c"><input type="checkbox" id="c-37358731" checked=""/><div class="controls bullet"><span class="by">dpq</span><span>|</span><a href="#37347581">prev</a><span>|</span><a href="#37354669">next</a><span>|</span><label class="collapse" for="c-37358731">[-]</label><label class="expand" for="c-37358731">[1 more]</label></div><br/><div class="children"><div class="content">Doug was one of my childhood heroes, thanks to a certain book telling the story of his work on AM and Eurisko. My great regret is that I never got the chance to meet him or contribute to his work in any way. RIP Doug, you are a legend.</div><br/></div></div><div id="37354669" class="c"><input type="checkbox" id="c-37354669" checked=""/><div class="controls bullet"><span class="by">toomuchtodo</span><span>|</span><a href="#37358731">prev</a><span>|</span><a href="#37358126">next</a><span>|</span><label class="collapse" for="c-37354669">[-]</label><label class="expand" for="c-37354669">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Douglas_Lenat" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Douglas_Lenat</a><p><a href="https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20230901183515&#x2F;https:&#x2F;&#x2F;garymarcus.substack.com&#x2F;p&#x2F;doug-lenat-1950-2023" rel="nofollow noreferrer">https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20230901183515&#x2F;https:&#x2F;&#x2F;garymarcu...</a><p><a href="https:&#x2F;&#x2F;archive.ph&#x2F;icb92" rel="nofollow noreferrer">https:&#x2F;&#x2F;archive.ph&#x2F;icb92</a></div><br/></div></div><div id="37358126" class="c"><input type="checkbox" id="c-37358126" checked=""/><div class="controls bullet"><span class="by">Nevermark</span><span>|</span><a href="#37354669">prev</a><span>|</span><a href="#37354769">next</a><span>|</span><label class="collapse" for="c-37358126">[-]</label><label class="expand" for="c-37358126">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I have spent my whole career […], Lenat was light-years ahead of me […]<p>Lenat is on a short list of people I expected&#x2F;hoped to meet at some point when context provided the practical reason.<p>He has been a hero to me for his creativity and fearlessness regarding his symbolic vision.<p>So sad I will never meet him, but my appreciation for him will never die.</div><br/></div></div><div id="37354769" class="c"><input type="checkbox" id="c-37354769" checked=""/><div class="controls bullet"><span class="by">dang</span><span>|</span><a href="#37358126">prev</a><span>|</span><a href="#37355078">next</a><span>|</span><label class="collapse" for="c-37354769">[-]</label><label class="expand" for="c-37354769">[2 more]</label></div><br/><div class="children"><div class="content">Related. Others?<p><i>Cyc</i> - <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=33011596">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=33011596</a> - Sept 2022 (2 comments)<p><i>Why AM and Eurisko Appear to Work (1983) [pdf]</i> - <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=28343118">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=28343118</a> - Aug 2021 (17 comments)<p><i>Early AI: “Eurisko, the Computer with a Mind of Its Own” (1984)</i> - <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=27298167">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=27298167</a> - May 2021 (2 comments)<p><i>Cyc</i> - <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=21781597">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=21781597</a> - Dec 2019 (173 comments)<p><i>Some documents on AM and EURISKO</i> - <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=18443607">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=18443607</a> - Nov 2018 (10 comments)<p><i>One genius&#x27;s lonely crusade to teach a computer common sense (2016)</i> - <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=16510766">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=16510766</a> - March 2018 (1 comment)<p><i>Douglas Lenat&#x27;s Cyc is now being commercialized</i> - <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=11300567">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=11300567</a> - March 2016 (49 comments)<p><i>Why AM and Eurisko Appear to Work (1983) [pdf]</i> - <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=9750349">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=9750349</a> - June 2015 (5 comments)<p><i>Ask HN: Cyc – Whatever happened to its connection to AI?</i> - <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=9566015">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=9566015</a> - May 2015 (3 comments)<p><i>Eurisko, The Computer With A Mind Of Its Own</i> - <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=2111826">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=2111826</a> - Jan 2011 (9 comments)<p><i>Open Cyc (open source common sense)</i> - <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=1913994">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=1913994</a> - Nov 2010 (22 comments)<p><i>Lenat (of Cyc) reviews Wolfram Alpha</i> - <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=510579">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=510579</a> - March 2009 (16 comments)<p><i>Eurisko, The Computer With A Mind Of Its Own</i> - <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=396796">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=396796</a> - Dec 2008 (13 comments)<p><i>Cycorp, Inc. (Attempt at Common Sense AI)</i> - <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=20725">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=20725</a> - May 2007 (1 comment)</div><br/><div id="37357419" class="c"><input type="checkbox" id="c-37357419" checked=""/><div class="controls bullet"><span class="by">PaulDavisThe1st</span><span>|</span><a href="#37354769">parent</a><span>|</span><a href="#37355078">next</a><span>|</span><label class="collapse" for="c-37357419">[-]</label><label class="expand" for="c-37357419">[1 more]</label></div><br/><div class="children"><div class="content">* Getting from Generative AI to Trustworthy AI: What LLMs Might Learn from Cyc* -  <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37354601">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37354601</a> - RIGHT NOW<p>HN location for discussion of Lenat&#x27;s last paper (with Gary Marcus) about ways to reconcile Cyc&#x27;s strengths with LLMs.</div><br/></div></div></div></div><div id="37355078" class="c"><input type="checkbox" id="c-37355078" checked=""/><div class="controls bullet"><span class="by">Jun8</span><span>|</span><a href="#37354769">prev</a><span>|</span><a href="#37354555">next</a><span>|</span><label class="collapse" for="c-37355078">[-]</label><label class="expand" for="c-37355078">[4 more]</label></div><br/><div class="children"><div class="content">Ahh, another one of the old guard has moved on. Here are two excerpts from the book <i>AI: The Tumultuous History Of The Search For Artificial Intelligence</i> (a fantastic read of the early days of AI) to remember him by;<p>&quot;Lenat found out about computers in a a manner typical of his entrepreneurial spirit. As a high school student in Philadelphia, working for $1.00 an hour to clean the cages of experimental animals, he discovered that another student was earning $1.50 to program the institution&#x27;s minicomputer. Finding this occupation more to his liking, he taught himself programming over a weekend and squeezed his competitor out of the job by offering to work for fifty cents an hour less.31 A few years later, Lenat was programming Automated Mathematician (AM, for short) as a doctoral thesis project at the Stanford AI Laboratory.&quot; p. 178<p>And here&#x27;s an count of an early victory for AI in gaming against humans by Lenat&#x27;s EURISKO system (<a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Eurisko" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Eurisko</a>):<p>&quot;Ever the achiever, Lenat was looking for a more dramatic way to prove teh capabilities of his creation. The identified the occasion space-war game called Traveler TCS, then quite popular with the public Lenat wanted to reach. The idea was for each player to design a fleet of space battleships according to a thick, hundred-page set of rules. Within a budget limit of one trillion galactic credits, one could adjust such parameters as the size, speed, armor thickness, autonomy and armament of each ship: about fifty adjustments per ship were needed. Since the fleet size could reach a hundred ships, the game thus offered ample room for ingenuity in spite of the anticlimactic character of the battles. These were fought by throwing dice following complex tables based on probability of survival of each ship according to its design. The winner of the yearly national championship was commissioned inter galactic admiral and received title to a planet of his or her choice ouside the solar system.<p>Several months before the 1981 competition, Lenat fed into EURISKO 146 Traveler concepts, ranging from the nature of games in general to the technicalities of meson guns. He then instructed the program to develop heuristics for making winning war-fleet designs. The now familiar routine of nightly computer runs turned into a merciless Darwinian contest: Lenat and EURISKO together designed fleets that battled each other. Designs were evaluated by how well they won battles, and heuristics by how well they designed fleets. This rating method required several battles per design, and several designs per heuristic, which amounted to a lot of battles: ten thousand in all, fought over two thousand hours of computer time.<p>To participants in the national championship of San Mateo,California, the resulting fleet of ninety-six small, heavily armored ships looked ludicrous. Accepted wisdom dictated fleets of about twenty behemoth ships, and many couldn&#x27;t help laughing. When engagements started, they found out that the weird armada held more than met the eye. One interesting ace up Lenat&#x27;s sleeve was a small ship so fast as to be almost unstoppable, which guaranteed at least a draw. EURISKO had conceived of it through the &quot;look for extreme cases&quot; heuristic (which had mutated, incidentally, into mutated, incidentally, into &quot;look for almost extreme cases&quot;).&quot; p. 182<p>If you&#x27;re a young person working in AI, by which I mean you&#x27;re less than 30, and if you have not already done so, you should read about AI history in three decade 60s - 90s.</div><br/><div id="37356463" class="c"><input type="checkbox" id="c-37356463" checked=""/><div class="controls bullet"><span class="by">brundolf</span><span>|</span><a href="#37355078">parent</a><span>|</span><a href="#37354555">next</a><span>|</span><label class="collapse" for="c-37356463">[-]</label><label class="expand" for="c-37356463">[3 more]</label></div><br/><div class="children"><div class="content">I may be getting this wrong, but I think I remember hearing that his auto-generated fleets won Traveller so entirely, several years in a row, that they had to shut down the entire competition because it had been broken<p>Edit: Fixed wrong name for the competition</div><br/><div id="37356764" class="c"><input type="checkbox" id="c-37356764" checked=""/><div class="controls bullet"><span class="by">mindcrime</span><span>|</span><a href="#37355078">root</a><span>|</span><a href="#37356463">parent</a><span>|</span><a href="#37354555">next</a><span>|</span><label class="collapse" for="c-37356764">[-]</label><label class="expand" for="c-37356764">[2 more]</label></div><br/><div class="children"><div class="content">I think you mean &quot;EURISKO won the Traveller championship so entirely...&quot;<p>In which case, yes, something like that did happen. Per the Wikipedia page:<p><i>Lenat and Eurisko gained notoriety by submitting the winning fleet (a large number of stationary, lightly-armored ships with many small weapons)[3] to the United States Traveller TCS national championship in 1981, forcing extensive changes to the game&#x27;s rules. However, Eurisko won again in 1982 when the program discovered that the rules permitted the program to destroy its own ships, permitting it to continue to use much the same strategy.[3] Tournament officials announced that if Eurisko won another championship the competition would be abolished; Lenat retired Eurisko from the game.[4] The Traveller TCS wins brought Lenat to the attention of DARPA,[5] which has funded much of his subsequent work.</i></div><br/><div id="37356793" class="c"><input type="checkbox" id="c-37356793" checked=""/><div class="controls bullet"><span class="by">brundolf</span><span>|</span><a href="#37355078">root</a><span>|</span><a href="#37356764">parent</a><span>|</span><a href="#37354555">next</a><span>|</span><label class="collapse" for="c-37356793">[-]</label><label class="expand" for="c-37356793">[1 more]</label></div><br/><div class="children"><div class="content">Whoops yes :)</div><br/></div></div></div></div></div></div></div></div><div id="37354555" class="c"><input type="checkbox" id="c-37354555" checked=""/><div class="controls bullet"><span class="by">detourdog</span><span>|</span><a href="#37355078">prev</a><span>|</span><a href="#37357790">next</a><span>|</span><label class="collapse" for="c-37354555">[-]</label><label class="expand" for="c-37354555">[1 more]</label></div><br/><div class="children"><div class="content">I still intend to integrate OpenCyc.</div><br/></div></div><div id="37357790" class="c"><input type="checkbox" id="c-37357790" checked=""/><div class="controls bullet"><span class="by">brindlejim</span><span>|</span><a href="#37354555">prev</a><span>|</span><a href="#37356615">next</a><span>|</span><label class="collapse" for="c-37357790">[-]</label><label class="expand" for="c-37357790">[2 more]</label></div><br/><div class="children"><div class="content">While I respect Doug&#x27;s intelligence, he showed a kind of perverse persistence in a failed idea, and I think it&#x27;s telling that aspiring AI czar Gary Marcus admires the ruins of Cyc while neglecting to acknowledge that it represents a dead end in AI. Like science, the field of AI advances one funeral at a time. Doug pursued a pipe dream, and convinced others to do the same, despite the brittle and static nature of the AI he sought to build. Cyc was not a precursor to OpenAI, contrary to other comments in this thread. That would be like calling  the zeppelin the precursor of the jet. It represents a different school of technology, and a much less effective one.</div><br/><div id="37358366" class="c"><input type="checkbox" id="c-37358366" checked=""/><div class="controls bullet"><span class="by">Nevermark</span><span>|</span><a href="#37357790">parent</a><span>|</span><a href="#37356615">next</a><span>|</span><label class="collapse" for="c-37358366">[-]</label><label class="expand" for="c-37358366">[1 more]</label></div><br/><div class="children"><div class="content">It’s not going to be popular to highlight the less than hoped for successes of Lenat’s greatest project.<p>But I think that is one of the things he should be admired for. How can anyone know how an ambitious approach will pan out without the great risk of going all in?<p>Anyone willing to risk a Don Quixote aspect to their career, in pursuit of a breakthrough, is someone who cares deeply about something beyond themselves.<p>And recognizing the limits of Lenat’s impact today doesn’t preclude both the direct and indirect impact on future progress.<p>I found him inspiring on multiple levels.</div><br/></div></div></div></div><div id="37356615" class="c"><input type="checkbox" id="c-37356615" checked=""/><div class="controls bullet"><span class="by">bpiche</span><span>|</span><a href="#37357790">prev</a><span>|</span><a href="#37358157">next</a><span>|</span><label class="collapse" for="c-37356615">[-]</label><label class="expand" for="c-37356615">[1 more]</label></div><br/><div class="children"><div class="content">Worked with their ontologists for a couple of years. Someone once told me that they employed more philosophers per capita than any other software company. A dubious distinction, maybe. But it describes the culture of inquisitiveness there pretty well too</div><br/></div></div><div id="37358157" class="c"><input type="checkbox" id="c-37358157" checked=""/><div class="controls bullet"><span class="by">Eliezer</span><span>|</span><a href="#37356615">prev</a><span>|</span><a href="#37359018">next</a><span>|</span><label class="collapse" for="c-37358157">[-]</label><label class="expand" for="c-37358157">[1 more]</label></div><br/><div class="children"><div class="content">Very visceral oof.  I don&#x27;t remember a time when I knew about AI but not about Eurisko.</div><br/></div></div><div id="37359018" class="c"><input type="checkbox" id="c-37359018" checked=""/><div class="controls bullet"><span class="by">martin1975</span><span>|</span><a href="#37358157">prev</a><span>|</span><a href="#37357398">next</a><span>|</span><label class="collapse" for="c-37359018">[-]</label><label class="expand" for="c-37359018">[1 more]</label></div><br/><div class="children"><div class="content">72 isn&#x27;t really too old. Does anyone know what caused his death? Revenge of the COVID?</div><br/></div></div><div id="37357398" class="c"><input type="checkbox" id="c-37357398" checked=""/><div class="controls bullet"><span class="by">satychary</span><span>|</span><a href="#37359018">prev</a><span>|</span><a href="#37354456">next</a><span>|</span><label class="collapse" for="c-37357398">[-]</label><label class="expand" for="c-37357398">[1 more]</label></div><br/><div class="children"><div class="content">I worked on Cyc in the early 90s, briefly [<a href="https:&#x2F;&#x2F;dl.acm.org&#x2F;doi&#x2F;pdf&#x2F;10.1145&#x2F;165529.993430" rel="nofollow noreferrer">https:&#x2F;&#x2F;dl.acm.org&#x2F;doi&#x2F;pdf&#x2F;10.1145&#x2F;165529.993430</a> shows my MCC address on p.10 :)]. I cherish wonderful memories of being on that project.<p>Doug was amazing - bold, brilliant, visionary, charismatic.<p>RIP, dear leader.</div><br/></div></div><div id="37354456" class="c"><input type="checkbox" id="c-37354456" checked=""/><div class="controls bullet"><span class="by">at_a_remove</span><span>|</span><a href="#37357398">prev</a><span>|</span><label class="collapse" for="c-37354456">[-]</label><label class="expand" for="c-37354456">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve often thought that Cyc had an enormous value as some kind of component for AI, a &quot;baseline truth&quot; about the universe (to the degree that we understand it and have &quot;explained&quot; our understanding to Cyc in terms of its frames).  AM (no relation to any need for screaming) was a taste of the AI dream.</div><br/><div id="37356987" class="c"><input type="checkbox" id="c-37356987" checked=""/><div class="controls bullet"><span class="by">optimalsolver</span><span>|</span><a href="#37354456">parent</a><span>|</span><label class="collapse" for="c-37356987">[-]</label><label class="expand" for="c-37356987">[1 more]</label></div><br/><div class="children"><div class="content">&gt;I&#x27;ve often thought that Cyc had an enormous value as some kind of component for AI<p>Same. I wonder if training an LLM on the database would make it more &quot;grounded&quot;? 
We&#x27;ll probably never know as Cycorp will keep the data locked away in their vaults forever. For what purpose? Probably even they don&#x27;t know.<p>&gt;AM (no relation to any need for screaming)<p>heh.</div><br/></div></div></div></div></div></div></div></div></div></body></html>