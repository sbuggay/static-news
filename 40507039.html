<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1716973278411" as="style"/><link rel="stylesheet" href="styles.css?v=1716973278411"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/2noise/ChatTTS">ChatTTS-Best open source TTS Model</a> <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>informal007</span> | <span>35 comments</span></div><br/><div><div id="40508445" class="c"><input type="checkbox" id="c-40508445" checked=""/><div class="controls bullet"><span class="by">modeless</span><span>|</span><a href="#40508025">next</a><span>|</span><label class="collapse" for="c-40508445">[-]</label><label class="expand" for="c-40508445">[9 more]</label></div><br/><div class="children"><div class="content">A good time to link the TTS leaderboard: <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;TTS-AGI&#x2F;TTS-Arena" rel="nofollow">https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;TTS-AGI&#x2F;TTS-Arena</a><p>Eleven Labs is still very far above open source models in quality. But StyleTTS2 (MIT license) is impressively good and quite fast. It&#x27;ll be interesting to see where this new one ends up. The code-switching ability is quite interesting. Most open source TTS models are strictly one language per sentence, often one language per voice.<p>In general though, TTS as an isolated system is mostly a dead end IMO. The future is in multimodal end-to-end audio-to-audio (or anything-to-audio) models, as demonstrated by OpenAI with GPT-4o&#x27;s voice mode (though I&#x27;ve been saying this since long before their demo: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38339222">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38339222</a>). Text is very useful as training data but as a way to represent other modalities like audio or image data it is far too lossy.</div><br/><div id="40508897" class="c"><input type="checkbox" id="c-40508897" checked=""/><div class="controls bullet"><span class="by">ugh123</span><span>|</span><a href="#40508445">parent</a><span>|</span><a href="#40508755">next</a><span>|</span><label class="collapse" for="c-40508897">[-]</label><label class="expand" for="c-40508897">[6 more]</label></div><br/><div class="children"><div class="content">&gt; In general though, TTS as an isolated system is mostly a dead end IMO<p>Do you mean like as a simple text to speech application? There is a huge need for better quality audiobook output.</div><br/><div id="40508946" class="c"><input type="checkbox" id="c-40508946" checked=""/><div class="controls bullet"><span class="by">modeless</span><span>|</span><a href="#40508445">root</a><span>|</span><a href="#40508897">parent</a><span>|</span><a href="#40508755">next</a><span>|</span><label class="collapse" for="c-40508946">[-]</label><label class="expand" for="c-40508946">[5 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think recording an audiobook with human-level quality is &quot;simple&quot;. It&#x27;s really a kind of acting. TTS models do very poorly at acting because they generally process one sentence at a time, or at most a paragraph, and have very little context or understanding. They just kind of fake it like a newscaster reading an unrehearsed script from a teleprompter.<p>True human-level audiobook reading would require understanding the whole story, which often assumes general cultural knowledge, which you&#x27;ll only get from a model trained on LLM-scale data. If you asked GPT-4o&#x27;s new end-to-end voice mode to read an audiobook you&#x27;d probably get a better result than any TTS model. I bet it would even do different voices for the characters if you asked it to.</div><br/><div id="40509443" class="c"><input type="checkbox" id="c-40509443" checked=""/><div class="controls bullet"><span class="by">fhe</span><span>|</span><a href="#40508445">root</a><span>|</span><a href="#40508946">parent</a><span>|</span><a href="#40509111">next</a><span>|</span><label class="collapse" for="c-40509443">[-]</label><label class="expand" for="c-40509443">[1 more]</label></div><br/><div class="children"><div class="content">for non-fiction books TTS is already good enough. what&#x27;s needed is the convenience and speed for turning text to audio. if with one click on my ebook app I can start listening, it&#x27;ll be a darn good feature for me.</div><br/></div></div><div id="40509111" class="c"><input type="checkbox" id="c-40509111" checked=""/><div class="controls bullet"><span class="by">sandreas</span><span>|</span><a href="#40508445">root</a><span>|</span><a href="#40508946">parent</a><span>|</span><a href="#40509443">prev</a><span>|</span><a href="#40509026">next</a><span>|</span><label class="collapse" for="c-40509111">[-]</label><label class="expand" for="c-40509111">[1 more]</label></div><br/><div class="children"><div class="content">Not only the whole story, but also which character is currently speaking, what place and mood he is in, whether it is sarcasm or irony and many many more aspects.<p>However, in my opinion it would be a huge benefit, if this kind of metadata would be put into the ebook file in some way, so that it would be something extractable and not has to be detected. I think it would be enough to ID the characters and tag a gender and a mood in the book together with citations, so that you could add different speech models for different characters. That would also allow to use different voices for different characters.<p>I wrote a little tool called voicebuilder (which I will open source next year). It&#x27;s a &quot;sentence splitter&quot; which is able to extract an LJSpeech training dataset for an audio file, epub file and length matching. Works pretty accurate for now, although it needs manual polish of the extracted model. Still way faster than doing it manually.<p>This way you can build speech sets of your favorite narrators and although you would never be allowed to publish them, I think for private use they are great!</div><br/></div></div><div id="40509026" class="c"><input type="checkbox" id="c-40509026" checked=""/><div class="controls bullet"><span class="by">maxglute</span><span>|</span><a href="#40508445">root</a><span>|</span><a href="#40508946">parent</a><span>|</span><a href="#40509111">prev</a><span>|</span><a href="#40508755">next</a><span>|</span><label class="collapse" for="c-40509026">[-]</label><label class="expand" for="c-40509026">[2 more]</label></div><br/><div class="children"><div class="content">Maybe authors can tag sentences&#x2F;paragraphs with acting directions while they write to facilitate acting. Seems like there&#x27;s ways for some human input to streamline process.</div><br/><div id="40509240" class="c"><input type="checkbox" id="c-40509240" checked=""/><div class="controls bullet"><span class="by">modeless</span><span>|</span><a href="#40508445">root</a><span>|</span><a href="#40509026">parent</a><span>|</span><a href="#40508755">next</a><span>|</span><label class="collapse" for="c-40509240">[-]</label><label class="expand" for="c-40509240">[1 more]</label></div><br/><div class="children"><div class="content">Approaches based on tagging and interpreting metadata are tempting. Building structured human knowledge into the system seems like a good idea. But ultimately it isn&#x27;t scalable or effective compared to general learning from large amounts of data. It&#x27;s exactly the famous Bitter Lesson. <a href="http:&#x2F;&#x2F;www.incompleteideas.net&#x2F;IncIdeas&#x2F;BitterLesson.html" rel="nofollow">http:&#x2F;&#x2F;www.incompleteideas.net&#x2F;IncIdeas&#x2F;BitterLesson.html</a><p>To the extent that authors provide supplemental notes or instructions to human actors reading their books, that information would be helpful to provide to an automated audiobook reading model. But there is no reason for it to be in a different form than a human actor would get. Additional structure or detail would be neither necessary nor helpful.</div><br/></div></div></div></div></div></div></div></div><div id="40508755" class="c"><input type="checkbox" id="c-40508755" checked=""/><div class="controls bullet"><span class="by">dartos</span><span>|</span><a href="#40508445">parent</a><span>|</span><a href="#40508897">prev</a><span>|</span><a href="#40508025">next</a><span>|</span><label class="collapse" for="c-40508755">[-]</label><label class="expand" for="c-40508755">[2 more]</label></div><br/><div class="children"><div class="content">Isn’t gpt 4o voice not audio to audio, but audio to text to audio?</div><br/><div id="40508799" class="c"><input type="checkbox" id="c-40508799" checked=""/><div class="controls bullet"><span class="by">modeless</span><span>|</span><a href="#40508445">root</a><span>|</span><a href="#40508755">parent</a><span>|</span><a href="#40508025">next</a><span>|</span><label class="collapse" for="c-40508799">[-]</label><label class="expand" for="c-40508799">[1 more]</label></div><br/><div class="children"><div class="content">It isn&#x27;t released yet, but the new one that they demoed is audio-to-audio. That&#x27;s why it can do things like sing songs, and detect emotion in voices.<p>The one that you can currently access in the ChatGPT app (with subscription) is the old one which is ASR-&gt;LLM-&gt;TTS.</div><br/></div></div></div></div></div></div><div id="40508025" class="c"><input type="checkbox" id="c-40508025" checked=""/><div class="controls bullet"><span class="by">NobodyNada</span><span>|</span><a href="#40508445">prev</a><span>|</span><a href="#40509821">next</a><span>|</span><label class="collapse" for="c-40508025">[-]</label><label class="expand" for="c-40508025">[3 more]</label></div><br/><div class="children"><div class="content">&gt; Attribution-NonCommercial-NoDerivatives 4.0 International<p>Strictly speaking, this is not open source, as the commonly accepted definitions of open-source software include freedom of use and modification.<p>But in an industry where &quot;OpenAI&quot; is 100% proprietary, I guess &quot;open-source&quot; doesn&#x27;t really mean much.</div><br/><div id="40508832" class="c"><input type="checkbox" id="c-40508832" checked=""/><div class="controls bullet"><span class="by">abetusk</span><span>|</span><a href="#40508025">parent</a><span>|</span><a href="#40509821">next</a><span>|</span><label class="collapse" for="c-40508832">[-]</label><label class="expand" for="c-40508832">[2 more]</label></div><br/><div class="children"><div class="content">Note that the repo itself doesn&#x27;t claim it&#x27;s open source, it&#x27;s the title of the link that (incorrectly) claims it is.</div><br/><div id="40509088" class="c"><input type="checkbox" id="c-40509088" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#40508025">root</a><span>|</span><a href="#40508832">parent</a><span>|</span><a href="#40509821">next</a><span>|</span><label class="collapse" for="c-40509088">[-]</label><label class="expand" for="c-40509088">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, I think the link title should be &quot;ChatTTS: Best openly licensed TTS model&quot; instead.</div><br/></div></div></div></div></div></div><div id="40509821" class="c"><input type="checkbox" id="c-40509821" checked=""/><div class="controls bullet"><span class="by">stakhanov</span><span>|</span><a href="#40508025">prev</a><span>|</span><a href="#40509629">next</a><span>|</span><label class="collapse" for="c-40509821">[-]</label><label class="expand" for="c-40509821">[1 more]</label></div><br/><div class="children"><div class="content">This is somewhat off-topic, but here goes:<p>It seems to me that English TTS is already extremely good, even if you&#x27;re looking at implementations that are far from being the best ones for English.<p>...and sometimes I wonder, if it&#x27;s really economically efficient for that many players to compete on making English TTS yet another hair&#x27;s breadth better than the next guy&#x27;s, while TTS for languages other than English is this vast field of unmet market demand.  At least these guys are doing Chinese, so: good for them.<p>Last time I looked into TTS systems for German, Google was the only game in town.  What I wouldn&#x27;t give for a viable alternative!  It doesn&#x27;t even need to be open source, I&#x27;d be quite ready to pay top dollar.</div><br/></div></div><div id="40509629" class="c"><input type="checkbox" id="c-40509629" checked=""/><div class="controls bullet"><span class="by">psychoslave</span><span>|</span><a href="#40509821">prev</a><span>|</span><a href="#40508593">next</a><span>|</span><label class="collapse" for="c-40509629">[-]</label><label class="expand" for="c-40509629">[1 more]</label></div><br/><div class="children"><div class="content">Could it be used to teach me Mandarin? Actually since it&#x27;s only voice synthesis, I guess it would still miss the voice recognition and capability the quality of my attempt to reproduce tonal language sentences.</div><br/></div></div><div id="40508593" class="c"><input type="checkbox" id="c-40508593" checked=""/><div class="controls bullet"><span class="by">luyu_wu</span><span>|</span><a href="#40509629">prev</a><span>|</span><a href="#40509540">next</a><span>|</span><label class="collapse" for="c-40508593">[-]</label><label class="expand" for="c-40508593">[1 more]</label></div><br/><div class="children"><div class="content">I have to say the Chinese female voice sounds the most natural. It&#x27;s really amazing how far these have got!<p>Video with examples: <a href="https:&#x2F;&#x2F;b23.tv&#x2F;uumKPam" rel="nofollow">https:&#x2F;&#x2F;b23.tv&#x2F;uumKPam</a> (bilibili)</div><br/></div></div><div id="40509540" class="c"><input type="checkbox" id="c-40509540" checked=""/><div class="controls bullet"><span class="by">acheong08</span><span>|</span><a href="#40508593">prev</a><span>|</span><a href="#40509249">next</a><span>|</span><label class="collapse" for="c-40509540">[-]</label><label class="expand" for="c-40509540">[6 more]</label></div><br/><div class="children"><div class="content">Beyond a certain level of quality, what is the purpose of improving similarity with human voice other than scamming? I’m asking because I genuinely don’t know. It seems even a rudimentary TTS is usable as long as you can tell what it’s saying.</div><br/><div id="40509888" class="c"><input type="checkbox" id="c-40509888" checked=""/><div class="controls bullet"><span class="by">kebsup</span><span>|</span><a href="#40509540">parent</a><span>|</span><a href="#40509623">next</a><span>|</span><label class="collapse" for="c-40509888">[-]</label><label class="expand" for="c-40509888">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m always on a lookout for the best TTS for my language learning app.</div><br/></div></div><div id="40509623" class="c"><input type="checkbox" id="c-40509623" checked=""/><div class="controls bullet"><span class="by">qwertox</span><span>|</span><a href="#40509540">parent</a><span>|</span><a href="#40509888">prev</a><span>|</span><a href="#40509557">next</a><span>|</span><label class="collapse" for="c-40509623">[-]</label><label class="expand" for="c-40509623">[1 more]</label></div><br/><div class="children"><div class="content">This is why I don&#x27;t get why OpenAI doesn&#x27;t open source their TTS. I&#x27;ve read that it is because of the risk of misuse, but if they release it with only two voices, one male and one female voice, and ensure that these voices are recognizable AI voices (in the sense of popular), there shouldn&#x27;t be any risk?<p>Most of us just need a machine to have the ability to speak to us in a way that sounds halfway human, but not as horrible as old open source TTS systems.</div><br/></div></div><div id="40509557" class="c"><input type="checkbox" id="c-40509557" checked=""/><div class="controls bullet"><span class="by">edvards</span><span>|</span><a href="#40509540">parent</a><span>|</span><a href="#40509623">prev</a><span>|</span><a href="#40509249">next</a><span>|</span><label class="collapse" for="c-40509557">[-]</label><label class="expand" for="c-40509557">[3 more]</label></div><br/><div class="children"><div class="content">In voice assistants, robocalls, e-books, even singing, live voice interpretation&#x2F;translation... a lot of stuff.</div><br/><div id="40509682" class="c"><input type="checkbox" id="c-40509682" checked=""/><div class="controls bullet"><span class="by">acheong08</span><span>|</span><a href="#40509540">root</a><span>|</span><a href="#40509557">parent</a><span>|</span><a href="#40509691">next</a><span>|</span><label class="collapse" for="c-40509682">[-]</label><label class="expand" for="c-40509682">[1 more]</label></div><br/><div class="children"><div class="content">Voice assistants -&gt; Siri sounds just fine<p>Robocalls -&gt; I want to know I’m speaking to a robot<p>Audio books -&gt; reasonable. An accurate tone is pleasant<p>Singing -&gt; ever heard of vocaloids? They’ve existed for at least a decade or two</div><br/></div></div><div id="40509691" class="c"><input type="checkbox" id="c-40509691" checked=""/><div class="controls bullet"><span class="by">lupusreal</span><span>|</span><a href="#40509540">root</a><span>|</span><a href="#40509557">parent</a><span>|</span><a href="#40509682">prev</a><span>|</span><a href="#40509249">next</a><span>|</span><label class="collapse" for="c-40509691">[-]</label><label class="expand" for="c-40509691">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>robocalls</i><p>E.g. scamming.  For anything that is just about conveying information through audio, like voice assistants, traditional TTS already works fine.</div><br/></div></div></div></div></div></div><div id="40509249" class="c"><input type="checkbox" id="c-40509249" checked=""/><div class="controls bullet"><span class="by">thomasfromcdnjs</span><span>|</span><a href="#40509540">prev</a><span>|</span><a href="#40508501">next</a><span>|</span><label class="collapse" for="c-40509249">[-]</label><label class="expand" for="c-40509249">[1 more]</label></div><br/><div class="children"><div class="content">I hadn&#x27;t heard any good prosodic laugh implementations yet.<p>In my mind that was the last hurdle to cross before being able to fool people regularly with a non-human voice.<p>Great work!<p>Hook that DSL into a prompt, [uv_break]gg. [laugh]</div><br/></div></div><div id="40508501" class="c"><input type="checkbox" id="c-40508501" checked=""/><div class="controls bullet"><span class="by">thorum</span><span>|</span><a href="#40509249">prev</a><span>|</span><a href="#40507487">next</a><span>|</span><label class="collapse" for="c-40508501">[-]</label><label class="expand" for="c-40508501">[1 more]</label></div><br/><div class="children"><div class="content">Wow - the most impressive thing about this is the control options. I’m not aware of any other TTS systems with the same balance of control, quality and language support. Looking forward to testing this out…</div><br/></div></div><div id="40507487" class="c"><input type="checkbox" id="c-40507487" checked=""/><div class="controls bullet"><span class="by">estheryo</span><span>|</span><a href="#40508501">prev</a><span>|</span><a href="#40507710">next</a><span>|</span><label class="collapse" for="c-40507487">[-]</label><label class="expand" for="c-40507487">[3 more]</label></div><br/><div class="children"><div class="content">The completion level is impressive! I can hardly tell the difference from a human voice, especially with the natural pauses and laughter, which surpasses ChatGPT’s quality. However, there’s a noticeable electric noise at the end of sentences, which feels unnatural. (As a native Chinese speaker, I find the Chinese output even better in comparison.)</div><br/><div id="40508964" class="c"><input type="checkbox" id="c-40508964" checked=""/><div class="controls bullet"><span class="by">nshm</span><span>|</span><a href="#40507487">parent</a><span>|</span><a href="#40507801">next</a><span>|</span><label class="collapse" for="c-40508964">[-]</label><label class="expand" for="c-40508964">[1 more]</label></div><br/><div class="children"><div class="content">There is also a glitch in &quot;dialogue&quot;</div><br/></div></div><div id="40507801" class="c"><input type="checkbox" id="c-40507801" checked=""/><div class="controls bullet"><span class="by">informal007</span><span>|</span><a href="#40507487">parent</a><span>|</span><a href="#40508964">prev</a><span>|</span><a href="#40507710">next</a><span>|</span><label class="collapse" for="c-40507801">[-]</label><label class="expand" for="c-40507801">[1 more]</label></div><br/><div class="children"><div class="content">Yes, it&#x27;s just a new born project, looking forward the next verison.</div><br/></div></div></div></div><div id="40507710" class="c"><input type="checkbox" id="c-40507710" checked=""/><div class="controls bullet"><span class="by">maxglute</span><span>|</span><a href="#40507487">prev</a><span>|</span><a href="#40507055">next</a><span>|</span><label class="collapse" for="c-40507710">[-]</label><label class="expand" for="c-40507710">[2 more]</label></div><br/><div class="children"><div class="content">Sounds natural and intelligible at 3x speed, which is plus.<p>&gt;The Real-Time Factor (RTF) is around 0.65.<p>What is the state of real time tts models?</div><br/><div id="40509861" class="c"><input type="checkbox" id="c-40509861" checked=""/><div class="controls bullet"><span class="by">regularfry</span><span>|</span><a href="#40507710">parent</a><span>|</span><a href="#40507055">next</a><span>|</span><label class="collapse" for="c-40509861">[-]</label><label class="expand" for="c-40509861">[1 more]</label></div><br/><div class="children"><div class="content">0.65 isn&#x27;t that big a gap.  This is probably less than one jart away from being optimised to real-time.</div><br/></div></div></div></div><div id="40507055" class="c"><input type="checkbox" id="c-40507055" checked=""/><div class="controls bullet"><span class="by">cchance</span><span>|</span><a href="#40507710">prev</a><span>|</span><a href="#40508311">next</a><span>|</span><label class="collapse" for="c-40507055">[-]</label><label class="expand" for="c-40507055">[2 more]</label></div><br/><div class="children"><div class="content">Sounds good but feel like theirs something slightly off to the cadence of the voice in the sample, but maybe i&#x27;m imagining</div><br/><div id="40507304" class="c"><input type="checkbox" id="c-40507304" checked=""/><div class="controls bullet"><span class="by">informal007</span><span>|</span><a href="#40507055">parent</a><span>|</span><a href="#40508311">next</a><span>|</span><label class="collapse" for="c-40507304">[-]</label><label class="expand" for="c-40507304">[1 more]</label></div><br/><div class="children"><div class="content">I think you are right, It is not the completely same.</div><br/></div></div></div></div><div id="40508311" class="c"><input type="checkbox" id="c-40508311" checked=""/><div class="controls bullet"><span class="by">JoeDeanx</span><span>|</span><a href="#40507055">prev</a><span>|</span><a href="#40509115">next</a><span>|</span><label class="collapse" for="c-40508311">[-]</label><label class="expand" for="c-40508311">[2 more]</label></div><br/><div class="children"><div class="content">Where is the demo that can be used?</div><br/><div id="40508684" class="c"><input type="checkbox" id="c-40508684" checked=""/><div class="controls bullet"><span class="by">informal007</span><span>|</span><a href="#40508311">parent</a><span>|</span><a href="#40509115">next</a><span>|</span><label class="collapse" for="c-40508684">[-]</label><label class="expand" for="c-40508684">[1 more]</label></div><br/><div class="children"><div class="content">You can try to run this code to use<p><a href="https:&#x2F;&#x2F;github.com&#x2F;2noise&#x2F;ChatTTS&#x2F;blob&#x2F;main&#x2F;infer.ipynb">https:&#x2F;&#x2F;github.com&#x2F;2noise&#x2F;ChatTTS&#x2F;blob&#x2F;main&#x2F;infer.ipynb</a></div><br/></div></div></div></div><div id="40509115" class="c"><input type="checkbox" id="c-40509115" checked=""/><div class="controls bullet"><span class="by">rowanG077</span><span>|</span><a href="#40508311">prev</a><span>|</span><a href="#40508300">next</a><span>|</span><label class="collapse" for="c-40509115">[-]</label><label class="expand" for="c-40509115">[1 more]</label></div><br/><div class="children"><div class="content">Is there any good voice2voice open source model?</div><br/></div></div><div id="40508300" class="c"><input type="checkbox" id="c-40508300" checked=""/><div class="controls bullet"><span class="by">ex3ndr</span><span>|</span><a href="#40509115">prev</a><span>|</span><label class="collapse" for="c-40508300">[-]</label><label class="expand" for="c-40508300">[1 more]</label></div><br/><div class="children"><div class="content">Looks like it is yet another xtts fork</div><br/></div></div></div></div></div></div></div></body></html>