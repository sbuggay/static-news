<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1716022854490" as="style"/><link rel="stylesheet" href="styles.css?v=1716022854490"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://bdtechtalks.com/2020/09/16/deep-learning-game-of-life/">Why neural networks struggle with the Game of Life (2020)</a> <span class="domain">(<a href="https://bdtechtalks.com">bdtechtalks.com</a>)</span></div><div class="subtext"><span>DeathArrow</span> | <span>79 comments</span></div><br/><div><div id="40388532" class="c"><input type="checkbox" id="c-40388532" checked=""/><div class="controls bullet"><span class="by">moconnor</span><span>|</span><a href="#40388507">next</a><span>|</span><label class="collapse" for="c-40388532">[-]</label><label class="expand" for="c-40388532">[34 more]</label></div><br/><div class="children"><div class="content">For everyone reading neither the article nor the paper:<p>- both show neural networks can learn the game of life just fine<p>- the finding is that to learn the rules reliably the networks need to be very over-parameterised (e.g. many times larger than the minimal size needed for hand-crafted weights to perfectly solve the problem)<p>This is not really a new result nor a surprising one, nor does it say anything about the kinds of functions a neural network can represent.<p>It&#x27;s an attempt to understand an existing observation: once we have trained a large overparameterized neural network we can often compress it to a smaller one with very little loss. So why can&#x27;t we learn the smaller one directly?<p>One of the theories referred to in the article and paper is the lottery hypothesis, which states that a large network is a superposition of many small networks and the larger you are the more likely at least one of those gets a &quot;lucky&quot; set of weights and converges quickly to the right solution. There is already interesting evidence for this.</div><br/><div id="40389108" class="c"><input type="checkbox" id="c-40389108" checked=""/><div class="controls bullet"><span class="by">G3rn0ti</span><span>|</span><a href="#40388532">parent</a><span>|</span><a href="#40388605">next</a><span>|</span><label class="collapse" for="c-40389108">[-]</label><label class="expand" for="c-40389108">[11 more]</label></div><br/><div class="children"><div class="content">&gt; the lottery hypothesis<p>Isn’t that another way of saying the optimization algorithm used in finding the network‘s weights (gradient descent) can not find the global optimum? I mean this is nothing new, the curse of dimension prevents any numeric optimizer to completely minimize any complicated error function and it’s been known for decades. AFAIK there is no algorithm that can find the global minimum of any function. And this is what currently limits neural network models: They could be much simpler and less resource hungry if we had better optimizers.</div><br/><div id="40389735" class="c"><input type="checkbox" id="c-40389735" checked=""/><div class="controls bullet"><span class="by">staunton</span><span>|</span><a href="#40388532">root</a><span>|</span><a href="#40389108">parent</a><span>|</span><a href="#40390040">next</a><span>|</span><label class="collapse" for="c-40389735">[-]</label><label class="expand" for="c-40389735">[7 more]</label></div><br/><div class="children"><div class="content">In practice, you <i>don&#x27;t want</i> the global optimum because you can&#x27;t put <i>all</i> possible inputs in the training data and need your system to &quot;generalize&quot; instead. Global optimum would mean overfitting.</div><br/><div id="40396789" class="c"><input type="checkbox" id="c-40396789" checked=""/><div class="controls bullet"><span class="by">badrunaway</span><span>|</span><a href="#40388532">root</a><span>|</span><a href="#40389735">parent</a><span>|</span><a href="#40390050">next</a><span>|</span><label class="collapse" for="c-40396789">[-]</label><label class="expand" for="c-40396789">[2 more]</label></div><br/><div class="children"><div class="content">Can someone explain this? Isn&#x27;t it possible for the global optimum to be also be the right generalisation optimum?</div><br/><div id="40397409" class="c"><input type="checkbox" id="c-40397409" checked=""/><div class="controls bullet"><span class="by">rcxdude</span><span>|</span><a href="#40388532">root</a><span>|</span><a href="#40396789">parent</a><span>|</span><a href="#40390050">next</a><span>|</span><label class="collapse" for="c-40397409">[-]</label><label class="expand" for="c-40397409">[1 more]</label></div><br/><div class="children"><div class="content">it&#x27;s <i>possible</i>, but unlikely. The issue is your training examples are essentially a noisy representation of the general function you are trying to get it to learn. Generally any representation that fits too well will be incorporating the noise and that will distort the general function (in the case of NN it&#x27;ll generally mean memorising the input data). Most function-fitting approaches are vulnerable to this.</div><br/></div></div></div></div><div id="40390050" class="c"><input type="checkbox" id="c-40390050" checked=""/><div class="controls bullet"><span class="by">WithinReason</span><span>|</span><a href="#40388532">root</a><span>|</span><a href="#40389735">parent</a><span>|</span><a href="#40396789">prev</a><span>|</span><a href="#40390040">next</a><span>|</span><label class="collapse" for="c-40390050">[-]</label><label class="expand" for="c-40390050">[4 more]</label></div><br/><div class="children"><div class="content">Regularisation should not be done with the optimiser but with the loss function and the architecture.</div><br/><div id="40393007" class="c"><input type="checkbox" id="c-40393007" checked=""/><div class="controls bullet"><span class="by">staunton</span><span>|</span><a href="#40388532">root</a><span>|</span><a href="#40390050">parent</a><span>|</span><a href="#40391756">next</a><span>|</span><label class="collapse" for="c-40393007">[-]</label><label class="expand" for="c-40393007">[1 more]</label></div><br/><div class="children"><div class="content">Maybe it <i>should</i> not be done but the large neutral networks this decade absolutely rely on this. A network at the global minimum of any of the (regularized) loss functions that are used these days would be <i>waaay</i> overfitted.</div><br/></div></div><div id="40391756" class="c"><input type="checkbox" id="c-40391756" checked=""/><div class="controls bullet"><span class="by">redox99</span><span>|</span><a href="#40388532">root</a><span>|</span><a href="#40390050">parent</a><span>|</span><a href="#40393007">prev</a><span>|</span><a href="#40393548">next</a><span>|</span><label class="collapse" for="c-40391756">[-]</label><label class="expand" for="c-40391756">[1 more]</label></div><br/><div class="children"><div class="content">Regularization only helps you so much.</div><br/></div></div><div id="40393548" class="c"><input type="checkbox" id="c-40393548" checked=""/><div class="controls bullet"><span class="by">uoaei</span><span>|</span><a href="#40388532">root</a><span>|</span><a href="#40390050">parent</a><span>|</span><a href="#40391756">prev</a><span>|</span><a href="#40390040">next</a><span>|</span><label class="collapse" for="c-40393548">[-]</label><label class="expand" for="c-40393548">[1 more]</label></div><br/><div class="children"><div class="content">The entire reason SGD works is because the stochastic nature of updates on minibatches is an implicit regularizer. This one perspective built the foundations for all of modern machine learning.<p>I completely agree that the most effective regularization is inductive bias in the architecture. But bang for buck, given all the memory&#x2F;compute savings it accomplishes, SGD is the exemplar of implicit regularization techniques.</div><br/></div></div></div></div></div></div><div id="40390040" class="c"><input type="checkbox" id="c-40390040" checked=""/><div class="controls bullet"><span class="by">WithinReason</span><span>|</span><a href="#40388532">root</a><span>|</span><a href="#40389108">parent</a><span>|</span><a href="#40389735">prev</a><span>|</span><a href="#40388605">next</a><span>|</span><label class="collapse" for="c-40390040">[-]</label><label class="expand" for="c-40390040">[3 more]</label></div><br/><div class="children"><div class="content">I think you&#x27;re right, but the issue might be local minima which a better optimiser wouldn&#x27;t help with much. A reason a larger network might work better is that there are fewer local minima in a higher dimension too.</div><br/><div id="40392604" class="c"><input type="checkbox" id="c-40392604" checked=""/><div class="controls bullet"><span class="by">jxy</span><span>|</span><a href="#40388532">root</a><span>|</span><a href="#40390040">parent</a><span>|</span><a href="#40388605">next</a><span>|</span><label class="collapse" for="c-40392604">[-]</label><label class="expand" for="c-40392604">[2 more]</label></div><br/><div class="children"><div class="content">&gt; there are fewer local minima in a higher dimension<p>Is it actually proven, or another hypothesis? What is the reason behind this?</div><br/><div id="40392969" class="c"><input type="checkbox" id="c-40392969" checked=""/><div class="controls bullet"><span class="by">jcrites</span><span>|</span><a href="#40388532">root</a><span>|</span><a href="#40392604">parent</a><span>|</span><a href="#40388605">next</a><span>|</span><label class="collapse" for="c-40392969">[-]</label><label class="expand" for="c-40392969">[1 more]</label></div><br/><div class="children"><div class="content">Just reasoning about this from first principles, but intuitively, the more dimensions you have, the more likely that you are to find a gradient in some dimension. In an N-dimensional space, a local minimum needs to be a minimum in all N dimensions, right? Otherwise the algorithm will keep exploring down the gradient. (Not an expert on this stuff.) The more dimensions there are, the more likely it seems to be that a gradient exists down to some greater minimum from any given point.</div><br/></div></div></div></div></div></div></div></div><div id="40388605" class="c"><input type="checkbox" id="c-40388605" checked=""/><div class="controls bullet"><span class="by">actionfromafar</span><span>|</span><a href="#40388532">parent</a><span>|</span><a href="#40389108">prev</a><span>|</span><a href="#40389657">next</a><span>|</span><label class="collapse" for="c-40388605">[-]</label><label class="expand" for="c-40388605">[15 more]</label></div><br/><div class="children"><div class="content">&gt; once we have trained a large overparameterized neural network we can often compress it to a smaller one with very little loss. So why can&#x27;t we learn the smaller one directly?<p>I feel something similar goes on in us humans. Interesting to think about.</div><br/><div id="40392601" class="c"><input type="checkbox" id="c-40392601" checked=""/><div class="controls bullet"><span class="by">seanhunter</span><span>|</span><a href="#40388532">root</a><span>|</span><a href="#40388605">parent</a><span>|</span><a href="#40388952">next</a><span>|</span><label class="collapse" for="c-40392601">[-]</label><label class="expand" for="c-40392601">[1 more]</label></div><br/><div class="children"><div class="content">Yes.  My naive intuition about this is you need the extra parameters precisely to do the learning because learning a thing is more complicated than doing the thing once you have learned how.  There are lots of natural examples that fit this intuition eg in my mind &quot;junk&quot; DNA is needed because the evolutionary mechanism is learning the sequences which work in a similar way. You don&#x27;t need all that extra DNA once you have it working but once you have it working there&#x27;s little selection pressure to clean up&#x2F;optimise the DNA sequence so the junk stays.</div><br/></div></div><div id="40388952" class="c"><input type="checkbox" id="c-40388952" checked=""/><div class="controls bullet"><span class="by">patcon</span><span>|</span><a href="#40388532">root</a><span>|</span><a href="#40388605">parent</a><span>|</span><a href="#40392601">prev</a><span>|</span><a href="#40388793">next</a><span>|</span><label class="collapse" for="c-40388952">[-]</label><label class="expand" for="c-40388952">[8 more]</label></div><br/><div class="children"><div class="content">Also perhaps why the evolved pattern of death is important: a subnetwork is selected in a brain, which is suited to a specific geological, physical, biological and cognitive environment that the brain is navigating. But when the environment shifts beneath the organisim (as culture does and the living world in general does), then the subnetwork is no longer the correct one, and needs to be reinitialized.<p>Or in other words, even in an information theoretic sense, it&#x27;s true: you can&#x27;t teach a old dogs new tricks. You need a new dog.</div><br/><div id="40391946" class="c"><input type="checkbox" id="c-40391946" checked=""/><div class="controls bullet"><span class="by">batshit_beaver</span><span>|</span><a href="#40388532">root</a><span>|</span><a href="#40388952">parent</a><span>|</span><a href="#40388998">next</a><span>|</span><label class="collapse" for="c-40391946">[-]</label><label class="expand" for="c-40391946">[1 more]</label></div><br/><div class="children"><div class="content">Neuroplasticity is a thing though, with plenty of cases of brains recovering from pretty significant damage. They also do evolve and adjust over time to gradual changes in environment. Lots of elderly people are keeping up with cultural and technological change.<p>Can&#x27;t say the same about neural networks (yet?).</div><br/></div></div><div id="40388998" class="c"><input type="checkbox" id="c-40388998" checked=""/><div class="controls bullet"><span class="by">yumong</span><span>|</span><a href="#40388532">root</a><span>|</span><a href="#40388952">parent</a><span>|</span><a href="#40391946">prev</a><span>|</span><a href="#40388793">next</a><span>|</span><label class="collapse" for="c-40388998">[-]</label><label class="expand" for="c-40388998">[6 more]</label></div><br/><div class="children"><div class="content">From an evolutionary perspective, wouldn&#x27;t we expect to have developed a way to &quot;reset&quot; parts of our brain then?</div><br/><div id="40389072" class="c"><input type="checkbox" id="c-40389072" checked=""/><div class="controls bullet"><span class="by">sitkack</span><span>|</span><a href="#40388532">root</a><span>|</span><a href="#40388998">parent</a><span>|</span><a href="#40388793">next</a><span>|</span><label class="collapse" for="c-40389072">[-]</label><label class="expand" for="c-40389072">[5 more]</label></div><br/><div class="children"><div class="content">That is what kids are for.</div><br/><div id="40392366" class="c"><input type="checkbox" id="c-40392366" checked=""/><div class="controls bullet"><span class="by">ianmcgowan</span><span>|</span><a href="#40388532">root</a><span>|</span><a href="#40389072">parent</a><span>|</span><a href="#40389369">next</a><span>|</span><label class="collapse" for="c-40392366">[-]</label><label class="expand" for="c-40392366">[3 more]</label></div><br/><div class="children"><div class="content">This reminds me of a hacker news comment that blew my mind - basically &quot;I&quot; am really my genetic code, and this particular body &quot;I&quot; am in is just another computer that the code has been moved to, because the old one is scheduled to be decommissioned.  So I am really just the latest instance of a program that has been running continuously since the first DNA&#x2F;RNA molecules started to replicate.</div><br/><div id="40392448" class="c"><input type="checkbox" id="c-40392448" checked=""/><div class="controls bullet"><span class="by">interroboink</span><span>|</span><a href="#40388532">root</a><span>|</span><a href="#40392366">parent</a><span>|</span><a href="#40389369">next</a><span>|</span><label class="collapse" for="c-40392448">[-]</label><label class="expand" for="c-40392448">[2 more]</label></div><br/><div class="children"><div class="content">If you&#x27;re interested in such things, then start layering on epigenetics. The &quot;I&quot; is a product not just of genes, but of your environment as you developed. I was just reading about bees&#x27; &quot;royal jelly&quot; recently, and how genetically identical larvae can become a queen or a worker based on their exposure to it.<p>So the program is not just the zeroes and ones, so to speak, but also more nebulous real-time activity, passed on through time. Like a wave on the ocean.</div><br/><div id="40392722" class="c"><input type="checkbox" id="c-40392722" checked=""/><div class="controls bullet"><span class="by">sitkack</span><span>|</span><a href="#40388532">root</a><span>|</span><a href="#40392448">parent</a><span>|</span><a href="#40389369">next</a><span>|</span><label class="collapse" for="c-40392722">[-]</label><label class="expand" for="c-40392722">[1 more]</label></div><br/><div class="children"><div class="content">And my children are not only my offspring, but everyone I come into memetic contact with.</div><br/></div></div></div></div></div></div><div id="40389369" class="c"><input type="checkbox" id="c-40389369" checked=""/><div class="controls bullet"><span class="by">actionfromafar</span><span>|</span><a href="#40388532">root</a><span>|</span><a href="#40389072">parent</a><span>|</span><a href="#40392366">prev</a><span>|</span><a href="#40388793">next</a><span>|</span><label class="collapse" for="c-40389369">[-]</label><label class="expand" for="c-40389369">[1 more]</label></div><br/><div class="children"><div class="content">Haha, exactly. &quot;We did&quot;.</div><br/></div></div></div></div></div></div></div></div><div id="40388793" class="c"><input type="checkbox" id="c-40388793" checked=""/><div class="controls bullet"><span class="by">rmnclmnt</span><span>|</span><a href="#40388532">root</a><span>|</span><a href="#40388605">parent</a><span>|</span><a href="#40388952">prev</a><span>|</span><a href="#40391910">next</a><span>|</span><label class="collapse" for="c-40388793">[-]</label><label class="expand" for="c-40388793">[3 more]</label></div><br/><div class="children"><div class="content">Indeed, you have to over-engineer something before converge to a leaner solution to a problem</div><br/><div id="40388978" class="c"><input type="checkbox" id="c-40388978" checked=""/><div class="controls bullet"><span class="by">brookst</span><span>|</span><a href="#40388532">root</a><span>|</span><a href="#40388793">parent</a><span>|</span><a href="#40391910">next</a><span>|</span><label class="collapse" for="c-40388978">[-]</label><label class="expand" for="c-40388978">[2 more]</label></div><br/><div class="children"><div class="content">And I think this is because the ideal complex system is one where all the subsystems and parts combine to produce adequate reliability.<p>Exponentiation means it is more efficient to start by far exceeding the required reliability and then optimizing the most expensive subsystems&#x2F;parts. It is less efficient and far more frustrating if multiple things have to be improved to meet requirements.</div><br/><div id="40390402" class="c"><input type="checkbox" id="c-40390402" checked=""/><div class="controls bullet"><span class="by">actionfromafar</span><span>|</span><a href="#40388532">root</a><span>|</span><a href="#40388978">parent</a><span>|</span><a href="#40391910">next</a><span>|</span><label class="collapse" for="c-40390402">[-]</label><label class="expand" for="c-40390402">[1 more]</label></div><br/><div class="children"><div class="content">This is really insightful.</div><br/></div></div></div></div></div></div><div id="40388879" class="c"><input type="checkbox" id="c-40388879" checked=""/><div class="controls bullet"><span class="by">nopinsight</span><span>|</span><a href="#40388532">root</a><span>|</span><a href="#40388605">parent</a><span>|</span><a href="#40391910">prev</a><span>|</span><a href="#40389657">next</a><span>|</span><label class="collapse" for="c-40388879">[-]</label><label class="expand" for="c-40388879">[1 more]</label></div><br/><div class="children"><div class="content">There is indeed an analogous process in the brain.<p>&quot;The number of synapses in the brain reaches its peak around ages 2-3, with about 15,000 synapses per neuron. As adolescents, the brain undergoes synaptic pruning. In adulthood, the brain stabilizes at around 7,500 synapses per neuron, roughly half the peak in early childhood.<p>This figure can vary based on individual experiences and learning.&quot; -- written by GPT-4o<p>Confirmed by e.g. <a href="https:&#x2F;&#x2F;extension.umaine.edu&#x2F;publications&#x2F;4356e&#x2F;" rel="nofollow">https:&#x2F;&#x2F;extension.umaine.edu&#x2F;publications&#x2F;4356e&#x2F;</a></div><br/></div></div></div></div><div id="40389657" class="c"><input type="checkbox" id="c-40389657" checked=""/><div class="controls bullet"><span class="by">tomxor</span><span>|</span><a href="#40388532">parent</a><span>|</span><a href="#40388605">prev</a><span>|</span><a href="#40389349">next</a><span>|</span><label class="collapse" for="c-40389657">[-]</label><label class="expand" for="c-40389657">[1 more]</label></div><br/><div class="children"><div class="content">&gt; So why can&#x27;t we learn the smaller one directly?<p>The lottery hypothesis intuitively makes sense, but as an outsider I find this concept for evaluating learning methods really interesting - To hand craft a tiny optimal networks for simple yet computationally irreducible problems like GoL as a way to benchmark learning algorithms. Or is it more than that? for a sufficiently small network maybe there aren&#x27;t that many combinations of &quot;correct solutions&quot;, so perhaps the way the network emerges internally could really be interrogated by comparison.</div><br/></div></div><div id="40389349" class="c"><input type="checkbox" id="c-40389349" checked=""/><div class="controls bullet"><span class="by">DrScientist</span><span>|</span><a href="#40388532">parent</a><span>|</span><a href="#40389657">prev</a><span>|</span><a href="#40392553">next</a><span>|</span><label class="collapse" for="c-40389349">[-]</label><label class="expand" for="c-40389349">[3 more]</label></div><br/><div class="children"><div class="content">This may be a silly question but - so rather than train a big network and hope a subnetwork wins the lottery - why not just train a smaller network with multiple runs with different starting weights?</div><br/><div id="40394705" class="c"><input type="checkbox" id="c-40394705" checked=""/><div class="controls bullet"><span class="by">scarmig</span><span>|</span><a href="#40388532">root</a><span>|</span><a href="#40389349">parent</a><span>|</span><a href="#40389487">next</a><span>|</span><label class="collapse" for="c-40394705">[-]</label><label class="expand" for="c-40394705">[1 more]</label></div><br/><div class="children"><div class="content">The larger network contains exponentially more subnetworks. 10x the size contains far more than 10x subnetworks (although it&#x27;d also take more than 10x as long to train).</div><br/></div></div><div id="40389487" class="c"><input type="checkbox" id="c-40389487" checked=""/><div class="controls bullet"><span class="by">MalphasWats</span><span>|</span><a href="#40388532">root</a><span>|</span><a href="#40389349">parent</a><span>|</span><a href="#40394705">prev</a><span>|</span><a href="#40392553">next</a><span>|</span><label class="collapse" for="c-40389487">[-]</label><label class="expand" for="c-40389487">[1 more]</label></div><br/><div class="children"><div class="content">Largely for the same reason people don&#x27;t &quot;just win&quot; the lottery by buying every possible ticket (any more).</div><br/></div></div></div></div><div id="40392553" class="c"><input type="checkbox" id="c-40392553" checked=""/><div class="controls bullet"><span class="by">dilyevsky</span><span>|</span><a href="#40388532">parent</a><span>|</span><a href="#40389349">prev</a><span>|</span><a href="#40388842">next</a><span>|</span><label class="collapse" for="c-40392553">[-]</label><label class="expand" for="c-40392553">[2 more]</label></div><br/><div class="children"><div class="content">Isn’t this basically the idea behind dropout technique?</div><br/><div id="40396363" class="c"><input type="checkbox" id="c-40396363" checked=""/><div class="controls bullet"><span class="by">Grimblewald</span><span>|</span><a href="#40388532">root</a><span>|</span><a href="#40392553">parent</a><span>|</span><a href="#40388842">next</a><span>|</span><label class="collapse" for="c-40396363">[-]</label><label class="expand" for="c-40396363">[1 more]</label></div><br/><div class="children"><div class="content">No,the idea behind dropout is to reduce an over-reliance on specific outputs thereby, in theory and typically in practice, making the network learn more reliable representations reducing the chance of overfitting.</div><br/></div></div></div></div><div id="40388842" class="c"><input type="checkbox" id="c-40388842" checked=""/><div class="controls bullet"><span class="by">mysecretaccount</span><span>|</span><a href="#40388532">parent</a><span>|</span><a href="#40392553">prev</a><span>|</span><a href="#40388507">next</a><span>|</span><label class="collapse" for="c-40388842">[-]</label><label class="expand" for="c-40388842">[1 more]</label></div><br/><div class="children"><div class="content">Thanks, very clear explanation!</div><br/></div></div></div></div><div id="40388507" class="c"><input type="checkbox" id="c-40388507" checked=""/><div class="controls bullet"><span class="by">red75prime</span><span>|</span><a href="#40388532">prev</a><span>|</span><a href="#40392033">next</a><span>|</span><label class="collapse" for="c-40388507">[-]</label><label class="expand" for="c-40388507">[3 more]</label></div><br/><div class="children"><div class="content">I struggled with the Game of Life too. I was fascinated by it and evolved cell populations on graph paper by hand (yeah, I&#x27;m that old). When I&#x27;ve got a computer, I checked my drawings and all of them were wrong.</div><br/><div id="40390635" class="c"><input type="checkbox" id="c-40390635" checked=""/><div class="controls bullet"><span class="by">maxbond</span><span>|</span><a href="#40388507">parent</a><span>|</span><a href="#40388968">next</a><span>|</span><label class="collapse" for="c-40390635">[-]</label><label class="expand" for="c-40390635">[1 more]</label></div><br/><div class="children"><div class="content">Reminds me of Knuth&#x27;s dragon mosaic, which also contains a mistake.<p><a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=v678Em6qyzk" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=v678Em6qyzk</a></div><br/></div></div><div id="40388968" class="c"><input type="checkbox" id="c-40388968" checked=""/><div class="controls bullet"><span class="by">zaphar</span><span>|</span><a href="#40388507">parent</a><span>|</span><a href="#40390635">prev</a><span>|</span><a href="#40392033">next</a><span>|</span><label class="collapse" for="c-40388968">[-]</label><label class="expand" for="c-40388968">[1 more]</label></div><br/><div class="children"><div class="content">I used to do this as a kid on long car trips. I would play GoL on paper. It&#x27;s a good way to eat up time enjoyably.</div><br/></div></div></div></div><div id="40392033" class="c"><input type="checkbox" id="c-40392033" checked=""/><div class="controls bullet"><span class="by">phaedrus</span><span>|</span><a href="#40388507">prev</a><span>|</span><a href="#40388483">next</a><span>|</span><label class="collapse" for="c-40392033">[-]</label><label class="expand" for="c-40392033">[1 more]</label></div><br/><div class="children"><div class="content">I wonder if anyone has tried to approach the problem from the other end: start with the hand-tuned network and randomize just some of the weights (or all of the weights a small amount), and see at what point the learning algorithm can no longer get back to the correct formulation of the problem.  Map the boundary between almost-solved and failure to converge, instead of starting from a random point trying to get to almost-solved.</div><br/></div></div><div id="40388483" class="c"><input type="checkbox" id="c-40388483" checked=""/><div class="controls bullet"><span class="by">kozlovsky</span><span>|</span><a href="#40392033">prev</a><span>|</span><a href="#40392162">next</a><span>|</span><label class="collapse" for="c-40388483">[-]</label><label class="expand" for="c-40388483">[20 more]</label></div><br/><div class="children"><div class="content">If we show a neural network some examples from the Game of Life and expect it to master the rules of a cellular automaton, then aren&#x27;t we asking too much from it? In some ways, this is analogous to expecting that if we show the neural network examples from the physical world, it will automatically derive Newton&#x27;s three laws. Not every person observing the world around him can independently deduce Newton&#x27;s laws from scratch, no matter how many examples he sees.</div><br/><div id="40388702" class="c"><input type="checkbox" id="c-40388702" checked=""/><div class="controls bullet"><span class="by">moconnor</span><span>|</span><a href="#40388483">parent</a><span>|</span><a href="#40388539">next</a><span>|</span><label class="collapse" for="c-40388702">[-]</label><label class="expand" for="c-40388702">[1 more]</label></div><br/><div class="children"><div class="content">This is exactly what we ask of neural networks and in the case of the game of life the article and paper show that yes they do derive the rules. Equally, we can expect them to derive the laws of physics by observation - certainly diffusion networks appear to derive some of them as they pertrain to light.</div><br/></div></div><div id="40388539" class="c"><input type="checkbox" id="c-40388539" checked=""/><div class="controls bullet"><span class="by">passwordoops</span><span>|</span><a href="#40388483">parent</a><span>|</span><a href="#40388702">prev</a><span>|</span><a href="#40392162">next</a><span>|</span><label class="collapse" for="c-40388539">[-]</label><label class="expand" for="c-40388539">[18 more]</label></div><br/><div class="children"><div class="content">&quot;then aren&#x27;t we asking too much from it&quot;<p>Not according to the hype merchants, hucksters, and VCs who think word models are displaying emergence and we&#x27;re 6 months from AGI, if only we can have more data</div><br/><div id="40396144" class="c"><input type="checkbox" id="c-40396144" checked=""/><div class="controls bullet"><span class="by">int_19h</span><span>|</span><a href="#40388483">root</a><span>|</span><a href="#40388539">parent</a><span>|</span><a href="#40396841">next</a><span>|</span><label class="collapse" for="c-40396144">[-]</label><label class="expand" for="c-40396144">[1 more]</label></div><br/><div class="children"><div class="content">Not according to the actual article that you&#x27;re commenting on, either.<p>&quot;As the researchers added more layers and parameters to the neural network, the results improved and the training process eventually yielded a solution that reached near-perfect accuracy.&quot;<p>So, no, we aren&#x27;t asking too much from it. We just need more compute.</div><br/></div></div><div id="40396841" class="c"><input type="checkbox" id="c-40396841" checked=""/><div class="controls bullet"><span class="by">HeatrayEnjoyer</span><span>|</span><a href="#40388483">root</a><span>|</span><a href="#40388539">parent</a><span>|</span><a href="#40396144">prev</a><span>|</span><a href="#40388945">next</a><span>|</span><label class="collapse" for="c-40396841">[-]</label><label class="expand" for="c-40396841">[1 more]</label></div><br/><div class="children"><div class="content">??<p>They <i>are</i> displaying emergence. They might as well be the walking definition of it.</div><br/></div></div><div id="40388945" class="c"><input type="checkbox" id="c-40388945" checked=""/><div class="controls bullet"><span class="by">danielbln</span><span>|</span><a href="#40388483">root</a><span>|</span><a href="#40388539">parent</a><span>|</span><a href="#40396841">prev</a><span>|</span><a href="#40388690">next</a><span>|</span><label class="collapse" for="c-40388945">[-]</label><label class="expand" for="c-40388945">[3 more]</label></div><br/><div class="children"><div class="content">From the HN comment rules:<p>&gt; Be kind. Don&#x27;t be snarky. Converse curiously; don&#x27;t cross-examine. Edit out swipes.<p>&gt; Please don&#x27;t fulminate. Please don&#x27;t sneer, including at the rest of the community.</div><br/><div id="40389068" class="c"><input type="checkbox" id="c-40389068" checked=""/><div class="controls bullet"><span class="by">bell-cot</span><span>|</span><a href="#40388483">root</a><span>|</span><a href="#40388945">parent</a><span>|</span><a href="#40394576">next</a><span>|</span><label class="collapse" for="c-40389068">[-]</label><label class="expand" for="c-40389068">[1 more]</label></div><br/><div class="children"><div class="content">My read of the comment is: &quot;You are correct, but bear in mind that the world seems infested with people who are far less realistic and honest than you.&quot;</div><br/></div></div><div id="40394576" class="c"><input type="checkbox" id="c-40394576" checked=""/><div class="controls bullet"><span class="by">iiovemiku</span><span>|</span><a href="#40388483">root</a><span>|</span><a href="#40388945">parent</a><span>|</span><a href="#40389068">prev</a><span>|</span><a href="#40388690">next</a><span>|</span><label class="collapse" for="c-40394576">[-]</label><label class="expand" for="c-40394576">[1 more]</label></div><br/><div class="children"><div class="content">The rules also say &quot;Please don&#x27;t complain that a submission is inappropriate. If a story is spam or off-topic, flag it. Don&#x27;t feed egregious comments by replying; flag them instead. If you flag, please don&#x27;t also comment that you did.&quot;<p>I&#x27;m not really sure it&#x27;s the best idea to accuse someone of breaking the rules if in doing so you&#x27;re also breaking one yourself.</div><br/></div></div></div></div><div id="40388690" class="c"><input type="checkbox" id="c-40388690" checked=""/><div class="controls bullet"><span class="by">nottorp</span><span>|</span><a href="#40388483">root</a><span>|</span><a href="#40388539">parent</a><span>|</span><a href="#40388945">prev</a><span>|</span><a href="#40393816">next</a><span>|</span><label class="collapse" for="c-40388690">[-]</label><label class="expand" for="c-40388690">[10 more]</label></div><br/><div class="children"><div class="content">Let&#x27;s be snarky a bit:<p>Can you do a neural network that, given a starting position of the game of life, decides if it cycles or not? ;)<p>Ok, not cycles... dies, stabilizes, goes into a loop etc.</div><br/><div id="40388845" class="c"><input type="checkbox" id="c-40388845" checked=""/><div class="controls bullet"><span class="by">GrantMoyer</span><span>|</span><a href="#40388483">root</a><span>|</span><a href="#40388690">parent</a><span>|</span><a href="#40394673">next</a><span>|</span><label class="collapse" for="c-40388845">[-]</label><label class="expand" for="c-40388845">[7 more]</label></div><br/><div class="children"><div class="content">So Oracle&#x27;s working on an LLM too, eh?</div><br/><div id="40388929" class="c"><input type="checkbox" id="c-40388929" checked=""/><div class="controls bullet"><span class="by">nottorp</span><span>|</span><a href="#40388483">root</a><span>|</span><a href="#40388845">parent</a><span>|</span><a href="#40388905">next</a><span>|</span><label class="collapse" for="c-40388929">[-]</label><label class="expand" for="c-40388929">[3 more]</label></div><br/><div class="children"><div class="content">&lt;cough&gt; halting problem. But now I&#x27;m spoiling it.</div><br/><div id="40389114" class="c"><input type="checkbox" id="c-40389114" checked=""/><div class="controls bullet"><span class="by">markisus</span><span>|</span><a href="#40388483">root</a><span>|</span><a href="#40388929">parent</a><span>|</span><a href="#40388905">next</a><span>|</span><label class="collapse" for="c-40389114">[-]</label><label class="expand" for="c-40389114">[2 more]</label></div><br/><div class="children"><div class="content">We know neural networks cannot solve the halting problem. But isn’t the question whether they can learn the transition table for game of life? Since each cell depends only on neighbors, this is as easy as memorizing how each 3x3 tile transitions.</div><br/><div id="40389167" class="c"><input type="checkbox" id="c-40389167" checked=""/><div class="controls bullet"><span class="by">nottorp</span><span>|</span><a href="#40388483">root</a><span>|</span><a href="#40389114">parent</a><span>|</span><a href="#40388905">next</a><span>|</span><label class="collapse" for="c-40389167">[-]</label><label class="expand" for="c-40389167">[1 more]</label></div><br/><div class="children"><div class="content">The original question, maybe. Mine is basically the halting problem, I think.<p>The other difference is I don&#x27;t take it seriously.</div><br/></div></div></div></div></div></div><div id="40388905" class="c"><input type="checkbox" id="c-40388905" checked=""/><div class="controls bullet"><span class="by">DeathArrow</span><span>|</span><a href="#40388483">root</a><span>|</span><a href="#40388845">parent</a><span>|</span><a href="#40388929">prev</a><span>|</span><a href="#40394673">next</a><span>|</span><label class="collapse" for="c-40388905">[-]</label><label class="expand" for="c-40388905">[3 more]</label></div><br/><div class="children"><div class="content">Everybody and their mom are into LLMs.</div><br/><div id="40389023" class="c"><input type="checkbox" id="c-40389023" checked=""/><div class="controls bullet"><span class="by">yumong</span><span>|</span><a href="#40388483">root</a><span>|</span><a href="#40388905">parent</a><span>|</span><a href="#40389005">next</a><span>|</span><label class="collapse" for="c-40389023">[-]</label><label class="expand" for="c-40389023">[1 more]</label></div><br/><div class="children"><div class="content">And Second Life and Myspace.</div><br/></div></div><div id="40389005" class="c"><input type="checkbox" id="c-40389005" checked=""/><div class="controls bullet"><span class="by">brookst</span><span>|</span><a href="#40388483">root</a><span>|</span><a href="#40388905">parent</a><span>|</span><a href="#40389023">prev</a><span>|</span><a href="#40394673">next</a><span>|</span><label class="collapse" for="c-40389005">[-]</label><label class="expand" for="c-40389005">[1 more]</label></div><br/><div class="children"><div class="content">Same thing happened with the Internet.</div><br/></div></div></div></div></div></div><div id="40394673" class="c"><input type="checkbox" id="c-40394673" checked=""/><div class="controls bullet"><span class="by">scarmig</span><span>|</span><a href="#40388483">root</a><span>|</span><a href="#40388690">parent</a><span>|</span><a href="#40388845">prev</a><span>|</span><a href="#40389187">next</a><span>|</span><label class="collapse" for="c-40394673">[-]</label><label class="expand" for="c-40394673">[1 more]</label></div><br/><div class="children"><div class="content">The halting problem doesn&#x27;t mean you can never decide if something cycles etc, just that you can&#x27;t always decide.<p>As it stands, my guess is that the LLM would always confidently make a decision, even if it were wrong, and then politely backtrack if you pushed backed, even if it were originally right.</div><br/></div></div><div id="40389187" class="c"><input type="checkbox" id="c-40389187" checked=""/><div class="controls bullet"><span class="by">catlifeonmars</span><span>|</span><a href="#40388483">root</a><span>|</span><a href="#40388690">parent</a><span>|</span><a href="#40394673">prev</a><span>|</span><a href="#40393816">next</a><span>|</span><label class="collapse" for="c-40389187">[-]</label><label class="expand" for="c-40389187">[1 more]</label></div><br/><div class="children"><div class="content">For a grid of a fixed size, yes.</div><br/></div></div></div></div><div id="40393816" class="c"><input type="checkbox" id="c-40393816" checked=""/><div class="controls bullet"><span class="by">elevatedastalt</span><span>|</span><a href="#40388483">root</a><span>|</span><a href="#40388539">parent</a><span>|</span><a href="#40388690">prev</a><span>|</span><a href="#40394341">next</a><span>|</span><label class="collapse" for="c-40393816">[-]</label><label class="expand" for="c-40393816">[1 more]</label></div><br/><div class="children"><div class="content">Every other day we see demos of AIs doing things that were thought of an impossible 6 months earlier, but sure, sounds like it&#x27;s the &quot;hype merchants&quot; who are out of touch with reality.</div><br/></div></div></div></div></div></div><div id="40392162" class="c"><input type="checkbox" id="c-40392162" checked=""/><div class="controls bullet"><span class="by">phaedrus</span><span>|</span><a href="#40388483">prev</a><span>|</span><a href="#40388949">next</a><span>|</span><label class="collapse" for="c-40392162">[-]</label><label class="expand" for="c-40392162">[1 more]</label></div><br/><div class="children"><div class="content">Philosophically, why should it be the case that aggregations of statistical calculations (one way of viewing the matrix multiplications of ANNs) can approximate intelligence?  I think it&#x27;s because our ability to know reality is inherently statistical.<p>To be clear, I&#x27;m not suggesting macro scale, i.e. not quantum, reality itself is probabilistic, only that our ability to interpret perception of it and model it is statistical.  That is, an observation or a sensor doesn&#x27;t actually tell you the state of the world; it is a measurement from which you infer things.<p>Viewed through this standpoint, maybe the Game of Life and other discrete, fully-knowable toy problem worlds aren&#x27;t as applicable to the problem of general intelligence as we imagine.  A way to put this into practice could be to introduce a level of error in both the hand-tuned and learned networks&#x27; ability to accurately measure the input states of the Life tableau (and&#x2F;or introduce some randomness in the application of the Life rules on the simulation), and see whether the superiority of the hand-tuned network persists or if the learned network is more robust in the face of uncertain inputs or fallible rule-applications.</div><br/></div></div><div id="40388949" class="c"><input type="checkbox" id="c-40388949" checked=""/><div class="controls bullet"><span class="by">ngrilly</span><span>|</span><a href="#40392162">prev</a><span>|</span><a href="#40390203">next</a><span>|</span><label class="collapse" for="c-40388949">[-]</label><label class="expand" for="c-40388949">[1 more]</label></div><br/><div class="children"><div class="content">This paper from 2020 has been peer reviewed: <a href="https:&#x2F;&#x2F;openreview.net&#x2F;forum?id=uKZsVyFKbaj" rel="nofollow">https:&#x2F;&#x2F;openreview.net&#x2F;forum?id=uKZsVyFKbaj</a></div><br/></div></div><div id="40390203" class="c"><input type="checkbox" id="c-40390203" checked=""/><div class="controls bullet"><span class="by">hamilyon2</span><span>|</span><a href="#40388949">prev</a><span>|</span><a href="#40389996">next</a><span>|</span><label class="collapse" for="c-40390203">[-]</label><label class="expand" for="c-40390203">[1 more]</label></div><br/><div class="children"><div class="content">&gt; In machine learning, one of the popular ways to improve the accuracy of a model that is underperforming is to increase its complexity. And this technique worked with the Game of Life.<p>For those who didn&#x27;t read the article, the content doesn&#x27;t support the title.</div><br/></div></div><div id="40389996" class="c"><input type="checkbox" id="c-40389996" checked=""/><div class="controls bullet"><span class="by">scotty79</span><span>|</span><a href="#40390203">prev</a><span>|</span><a href="#40388961">next</a><span>|</span><label class="collapse" for="c-40389996">[-]</label><label class="expand" for="c-40389996">[1 more]</label></div><br/><div class="children"><div class="content">&gt; These findings are in line with “The Lottery Ticket Hypothesis,”<p>If the fit was due to a lucky subset of weights you could have train smaller networks many times instead of using many times bigger network.<p>So it must be something more. Like increased opportunity to create best solution out of large number of random lucky parts.<p>I think there should be way more research on neural pruning. After all it&#x27;s what our brains do to reach the correct architecture and weights during our development.</div><br/></div></div><div id="40388961" class="c"><input type="checkbox" id="c-40388961" checked=""/><div class="controls bullet"><span class="by">rasca</span><span>|</span><a href="#40389996">prev</a><span>|</span><a href="#40393751">next</a><span>|</span><label class="collapse" for="c-40388961">[-]</label><label class="expand" for="c-40388961">[1 more]</label></div><br/><div class="children"><div class="content">Here&#x27;s a nice article about how another team solved Game of Life in LLMs using Claude 3 Opus: <a href="https:&#x2F;&#x2F;x.com&#x2F;ctjlewis&#x2F;status&#x2F;1786948443472339247" rel="nofollow">https:&#x2F;&#x2F;x.com&#x2F;ctjlewis&#x2F;status&#x2F;1786948443472339247</a> .<p>It&#x27;s a really nice read.</div><br/></div></div><div id="40393751" class="c"><input type="checkbox" id="c-40393751" checked=""/><div class="controls bullet"><span class="by">ellis0n</span><span>|</span><a href="#40388961">prev</a><span>|</span><a href="#40388142">next</a><span>|</span><label class="collapse" for="c-40393751">[-]</label><label class="expand" for="c-40393751">[1 more]</label></div><br/><div class="children"><div class="content">Amazing idea! GoL&#x2F;LLM</div><br/></div></div><div id="40388142" class="c"><input type="checkbox" id="c-40388142" checked=""/><div class="controls bullet"><span class="by">leric</span><span>|</span><a href="#40393751">prev</a><span>|</span><a href="#40388516">next</a><span>|</span><label class="collapse" for="c-40388142">[-]</label><label class="expand" for="c-40388142">[3 more]</label></div><br/><div class="children"><div class="content">A good example of irreducible complexity</div><br/><div id="40393534" class="c"><input type="checkbox" id="c-40393534" checked=""/><div class="controls bullet"><span class="by">rustcleaner</span><span>|</span><a href="#40388142">parent</a><span>|</span><a href="#40389036">next</a><span>|</span><label class="collapse" for="c-40393534">[-]</label><label class="expand" for="c-40393534">[1 more]</label></div><br/><div class="children"><div class="content">based<p>Simple systems built on simple rules creating universally complete computation behaviors are both unintuitive to and underrated by common man.</div><br/></div></div></div></div><div id="40388516" class="c"><input type="checkbox" id="c-40388516" checked=""/><div class="controls bullet"><span class="by">K0balt</span><span>|</span><a href="#40388142">prev</a><span>|</span><a href="#40388453">next</a><span>|</span><label class="collapse" for="c-40388516">[-]</label><label class="expand" for="c-40388516">[2 more]</label></div><br/><div class="children"><div class="content">What’s not clear to me is if it is non trivial to (a)create a GOL NN that models the game cells directly as neurons (which would seem to be an efficient and effective method) or if it’s just (b) nontrivial to create a transformer architecture model that can model the game state n-turns in the future.<p>I would be very surprised if (a) was not effective, but that (b) is difficult is not surprising, since that is a very nontrivial task that requires intermediary modelling tools to perform for humans (arguably the most advanced NN that we have access to at the moment)<p>(a) is actually a form of (b) in the form of a modelling tool.</div><br/><div id="40388710" class="c"><input type="checkbox" id="c-40388710" checked=""/><div class="controls bullet"><span class="by">moconnor</span><span>|</span><a href="#40388516">parent</a><span>|</span><a href="#40388453">next</a><span>|</span><label class="collapse" for="c-40388710">[-]</label><label class="expand" for="c-40388710">[1 more]</label></div><br/><div class="children"><div class="content">Both are ~trivial as detailed in the paper and article.</div><br/></div></div></div></div><div id="40388453" class="c"><input type="checkbox" id="c-40388453" checked=""/><div class="controls bullet"><span class="by">nottorp</span><span>|</span><a href="#40388516">prev</a><span>|</span><a href="#40388995">next</a><span>|</span><label class="collapse" for="c-40388453">[-]</label><label class="expand" for="c-40388453">[8 more]</label></div><br/><div class="children"><div class="content">&gt; Interestingly, no matter how complex a grid becomes, you can predict the state of each cell in the next timestep with the same rules.<p>How is that interesting? It&#x27;s the definition of the Game of Life... it&#x27;s not like it&#x27;s a natural system that you don&#x27;t know the full rules for...</div><br/><div id="40388994" class="c"><input type="checkbox" id="c-40388994" checked=""/><div class="controls bullet"><span class="by">brookst</span><span>|</span><a href="#40388453">parent</a><span>|</span><a href="#40389246">next</a><span>|</span><label class="collapse" for="c-40388994">[-]</label><label class="expand" for="c-40388994">[5 more]</label></div><br/><div class="children"><div class="content">It’s interesting the way Go is interesting: very simple rules can produce extreme complexity. At least, I think that’s interesting.</div><br/><div id="40389012" class="c"><input type="checkbox" id="c-40389012" checked=""/><div class="controls bullet"><span class="by">yumong</span><span>|</span><a href="#40388453">root</a><span>|</span><a href="#40388994">parent</a><span>|</span><a href="#40389517">next</a><span>|</span><label class="collapse" for="c-40389012">[-]</label><label class="expand" for="c-40389012">[1 more]</label></div><br/><div class="children"><div class="content">Stephen Wolfram pushes this to the extreme.<p>Surprised that nobody mentioned him yet.</div><br/></div></div><div id="40389517" class="c"><input type="checkbox" id="c-40389517" checked=""/><div class="controls bullet"><span class="by">nottorp</span><span>|</span><a href="#40388453">root</a><span>|</span><a href="#40388994">parent</a><span>|</span><a href="#40389012">prev</a><span>|</span><a href="#40389246">next</a><span>|</span><label class="collapse" for="c-40389517">[-]</label><label class="expand" for="c-40389517">[3 more]</label></div><br/><div class="children"><div class="content">I wouldn&#x27;t compare the game of life that has exactly one &quot;next state&quot; with something like Go.</div><br/><div id="40389587" class="c"><input type="checkbox" id="c-40389587" checked=""/><div class="controls bullet"><span class="by">brookst</span><span>|</span><a href="#40388453">root</a><span>|</span><a href="#40389517">parent</a><span>|</span><a href="#40392128">next</a><span>|</span><label class="collapse" for="c-40389587">[-]</label><label class="expand" for="c-40389587">[1 more]</label></div><br/><div class="children"><div class="content">It’s interesting that you wouldn’t, yet I would.They aren’t isomorphic, for sure.<p>Go’s complexity comes from two players alternately picking one out of a very large number of options.<p>GoL’s complexity comes from a very large number of nodes “picking” between two states. That’s not precise, just illustrating that there is some symmetry of simplicity&#x2F;complexity, at least to my eyes.</div><br/></div></div><div id="40392128" class="c"><input type="checkbox" id="c-40392128" checked=""/><div class="controls bullet"><span class="by">SkyBelow</span><span>|</span><a href="#40388453">root</a><span>|</span><a href="#40389517">parent</a><span>|</span><a href="#40389587">prev</a><span>|</span><a href="#40389246">next</a><span>|</span><label class="collapse" for="c-40392128">[-]</label><label class="expand" for="c-40392128">[1 more]</label></div><br/><div class="children"><div class="content">Why not?<p>We could even think of both as collections of 3d structures showing all valid structures possible for a board of size n by n.  There are some differences, every single 3d Conway structure has a unique top layer, while Go does not.  But that seems like an overall minor difference.  There are many more Go shapes than Conway shapes given the same N, but both are already so numerous that I&#x27;m not sure that is a difference worth stopping the comparison.</div><br/></div></div></div></div></div></div><div id="40389013" class="c"><input type="checkbox" id="c-40389013" checked=""/><div class="controls bullet"><span class="by">bell-cot</span><span>|</span><a href="#40388453">parent</a><span>|</span><a href="#40389246">prev</a><span>|</span><a href="#40388995">next</a><span>|</span><label class="collapse" for="c-40389013">[-]</label><label class="expand" for="c-40389013">[1 more]</label></div><br/><div class="children"><div class="content">From a quick skim, then string search for &quot;interesting&quot; - I&#x27;d say that word is fluff, added to keep their audience reading through their dull background intro.</div><br/></div></div></div></div></div></div></div></div></div></body></html>