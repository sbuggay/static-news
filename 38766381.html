<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1703581254762" as="style"/><link rel="stylesheet" href="styles.css?v=1703581254762"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://arxiv.org/abs/2312.06695">Evolving Reservoirs for Meta Reinforcement Learning</a>Â <span class="domain">(<a href="https://arxiv.org">arxiv.org</a>)</span></div><div class="subtext"><span>PaulHoule</span> | <span>5 comments</span></div><br/><div><div id="38767976" class="c"><input type="checkbox" id="c-38767976" checked=""/><div class="controls bullet"><span class="by">p1esk</span><span>|</span><a href="#38768001">next</a><span>|</span><label class="collapse" for="c-38767976">[-]</label><label class="expand" for="c-38767976">[1 more]</label></div><br/><div class="children"><div class="content">I wonder if it would be better to use randomly initialized transformer blocks inside RC, rather than RNNs.</div><br/></div></div><div id="38768001" class="c"><input type="checkbox" id="c-38768001" checked=""/><div class="controls bullet"><span class="by">deyiao</span><span>|</span><a href="#38767976">prev</a><span>|</span><label class="collapse" for="c-38768001">[-]</label><label class="expand" for="c-38768001">[3 more]</label></div><br/><div class="children"><div class="content">honestly, I fail to understand this paper. might vaguely grasp what it aims to do, but totally lost when it comes to the framework and the objectives of its experiments.</div><br/><div id="38768512" class="c"><input type="checkbox" id="c-38768512" checked=""/><div class="controls bullet"><span class="by">samstave</span><span>|</span><a href="#38768001">parent</a><span>|</span><label class="collapse" for="c-38768512">[-]</label><label class="expand" for="c-38768512">[2 more]</label></div><br/><div class="children"><div class="content">&gt;&gt;&gt;<i>capture features of environments shared between generations to bias and speed up lifetime learning. ... propose a computational model for studying a mechanism that can enable such a process</i><p>through looking at how<p>&gt;&gt;&gt;<i>a reservoir encodes the environment state before providing it to an action policy.</i><p>-<p>This instantly reminds me of the genetic wonder that is the Monarch Butterflies Multi-Generational Migration.<p>--<p>&gt;&gt; <i>The monarch is the only butterfly known to make a two-way migration as birds do</i><p>&gt;&gt; <i>Monarchs have four generations in a year</i><p>&gt;&gt; <i>The first generation is tasked with migrating from Mexico to the southern United States</i><p>&gt;&gt; <i>The second and third generations emerge and lay many eggs in the north but do not have any role in migration</i><p>&gt;&gt; <i>The fourth generation must trek south towards the forested mountains in central Mexico2</i><p>But here is the real kicker, the 4th generation is a super generation - and each of these generations are encoded with the &quot;reservoir&quot; of the state &#x2F; role they play.<p>&gt;&gt; <i>aging milkweed and other nectar sources, trigger the birth of the super generation and their epic migration. They live eight times longer than their parents and grandparents - up to eight months - and travel 10 times farther</i><p>Milkweed is their only food and egg-laying symbiotic plant - and its #1 enemy is Glyphosate (RoundUp) which is killing the entire natural eco-system)<p>--<p>Anyway, the butterfly is able to encode a multi-generational, alternating &#x27;role&#x27; via a method of triggering which genome to express due to mapping to external stimulae. Such as the aging of the milkweed, the weather, and such.<p>SO<p>If you can have these external triggers presenting as a particular &#x27;reservoir&#x27; from the genome, maybe you could associate external patterns with a particular &#x27;reservoir&#x27; of knowledge to find context faster...<p>Especially when the GPT Store gets massive, to the point where you have many layers of GPTs woven together (entangled - but thats a bad word)... you might want to recognize the patterns of GPTs that one may want to weave into a tapestry based on the &quot;state of the reservoir&quot; which really is &quot;the incentive&quot; and then the appropriate reservoir will provide the appropriate set of GPTs for the outcome.<p>But the reservoirs are created through reinforcing positive feedback for particular GPTs to stack well. This will be an interesting problem to solve in the GPT store. Seems like a GPT&lt;--$API$--&gt;GPT &#x27;peering connection&#x27; like ISP fee might end up in a commercial GPT agent market?<p>(a very long winded  way of saying PAID TEMPLATES :-)</div><br/><div id="38769362" class="c"><input type="checkbox" id="c-38769362" checked=""/><div class="controls bullet"><span class="by">samstave</span><span>|</span><a href="#38768001">root</a><span>|</span><a href="#38768512">parent</a><span>|</span><label class="collapse" for="c-38769362">[-]</label><label class="expand" for="c-38769362">[1 more]</label></div><br/><div class="children"><div class="content">They should be training on ferret:<p>&gt;<i>&gt; We introduce Ferret, a new Multimodal Large Language Model (MLLM) capable of understanding spatial referring of any shape or granularity within an image and accurately grounding open-vocabulary descriptions. To unify referring and grounding in the LLM paradigm, Ferret employs a novel and powerful hybrid region representation that integrates discrete coordinates and continuous features jointly to represent a region in the image. To extract the continuous features of versatile regions, we propose a spatial-aware visual sampler, adept at handling varying sparsity across different shapes. Consequently, Ferret can accept diverse region inputs, such as points, bounding boxes, and free-form shapes. To bolster the desired capability of Ferret, we curate GRIT, a comprehensive refer-and-ground instruction tuning dataset including 1.1M samples that contain rich hierarchical spatial knowledge, with 95K hard negative data to promote model robustness. The resulting model not only achieves superior performance in classical referring and grounding tasks, but also greatly outperforms existing MLLMs in region-based and localization-demanded multimodal chatting. Our evaluations also reveal a significantly improved capability of describing image details and a remarkable alleviation in object hallucination.</i><p>-<p>Whereby, I surmise This will make Drone-based AI image context for behavior extremely powerful - especially when aspects of that MLLM handling for spatial-sitrep extremely precise for autonomous movement, then ultimately for decision making WRT interacting with humans (positive interactions and negative interactions).<p>Is it just me, or doesnt this MLLM seem particularly useful for flying objects with vision?<p>however the more that I think about it, it seems like reservoirs can be applied to more than just &quot;situational reactionary &quot;dejaVu&quot; which is what I think they are getting at (think LUCY where she ODs on a neurotropic and suddenly knows martial arts) (Also, lucy is a remake of Lawnmower Man if you hadnt noticed.<p>but i like the idea of reservoirs as an ability to know which gpt agent can work well together to solve to an outcome based on the weaving of other GPTs together to have a tapestry with similar relationships.<p>Forgot, wanted to add<p><a href="https:&#x2F;&#x2F;imgur.com&#x2F;gallery&#x2F;bRCfnFv" rel="nofollow noreferrer">https:&#x2F;&#x2F;imgur.com&#x2F;gallery&#x2F;bRCfnFv</a><p>The logo for the new DHS&#x27; <i>&#x27;Department of Entangled Agent Technologies and Humanity&#x27;</i><p>:-)</div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>