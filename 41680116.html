<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1727600469032" as="style"/><link rel="stylesheet" href="styles.css?v=1727600469032"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.reuters.com/technology/artificial-intelligence/if-your-ai-seems-smarter-its-thanks-smarter-human-trainers-2024-09-28/">If AI seems smarter, it&#x27;s thanks to smarter human trainers</a> <span class="domain">(<a href="https://www.reuters.com">www.reuters.com</a>)</span></div><div class="subtext"><span>getwiththeprog</span> | <span>122 comments</span></div><br/><div><div id="41683980" class="c"><input type="checkbox" id="c-41683980" checked=""/><div class="controls bullet"><span class="by">throwaway_2968</span><span>|</span><a href="#41685711">next</a><span>|</span><label class="collapse" for="c-41683980">[-]</label><label class="expand" for="c-41683980">[5 more]</label></div><br/><div class="children"><div class="content">Throwaway account here. I recently spent a few months as a trainer for a major AI company&#x27;s project. The well-paid gig mainly involved crafting specialized, reasoning-heavy questions that were supposed to stump the current top models. Most of the trainers had PhDs, and the company&#x27;s idea was to use our questions to benchmark future AI systems.<p>It was a real challenge. I managed to come up with a handful of questions that tripped up the models, but it was clear they stumbled for pretty mundane reasons—outdated info or faulty string parsing due to tokenization. A common gripe among the trainers was the project&#x27;s insistence on questions with clear-cut right&#x2F;wrong answers. Many of us worked in fields where good research tends to be more nuanced and open to interpretation. I saw plenty of questions from other trainers that only had definitive answers if you bought into specific (and often contentious) theoretical frameworks in psychology, sociology, linguistics, history, and so on.<p>The AI company people running the projects seemed a bit out of their depth, too. Their detailed guidelines for us actually contained some fundamental contradictions that they had missed. (Ironically, when I ran those guidelines by Claude, ChatGPT, and Gemini, they all spotted the issues straight away.)<p>After finishing the project, I came away even more impressed by how smart the current models can be.</div><br/><div id="41685159" class="c"><input type="checkbox" id="c-41685159" checked=""/><div class="controls bullet"><span class="by">godelski</span><span>|</span><a href="#41683980">parent</a><span>|</span><a href="#41684093">next</a><span>|</span><label class="collapse" for="c-41685159">[-]</label><label class="expand" for="c-41685159">[1 more]</label></div><br/><div class="children"><div class="content"><p><pre><code>  &gt; Many of us worked in fields where good research tends to be more nuanced and open to interpretation
</code></pre>
I&#x27;ve had a hard time getting people to understand this. It&#x27;s always felt odd tbh. It&#x27;s what&#x27;s meant by &quot;truth doesn&#x27;t exist&quot;. Because it doesn&#x27;t exist with infinite precision, though they are plenty of times where there&#x27;s good answers. In our modern world I think one of the big challenges is that we&#x27;ve advanced enough that low order approximations are no longer good enough. It should make sense, as we get better we need more complex models. We need to account for more.<p>In many optimization problems there are no global solutions. This isn&#x27;t because we lack good enough models, it&#x27;s just how things are. And the environment is constantly changing, the targets moving. So the complexity will always exist. There&#x27;s beauty in that, because what fun is a game when you beat it? With a universe like this, there&#x27;s always a new level ahead of us.</div><br/></div></div><div id="41684093" class="c"><input type="checkbox" id="c-41684093" checked=""/><div class="controls bullet"><span class="by">layer8</span><span>|</span><a href="#41683980">parent</a><span>|</span><a href="#41685159">prev</a><span>|</span><a href="#41684420">next</a><span>|</span><label class="collapse" for="c-41684093">[-]</label><label class="expand" for="c-41684093">[1 more]</label></div><br/><div class="children"><div class="content">I wouldn’t look for questions with yes&#x2F;no answers, but for questions where the answers can have correct&#x2F;incorrect reasoning. Of course, you can’t turn those into automated benchmarks, but that’s maybe kinda the point.</div><br/></div></div><div id="41684420" class="c"><input type="checkbox" id="c-41684420" checked=""/><div class="controls bullet"><span class="by">spencerchubb</span><span>|</span><a href="#41683980">parent</a><span>|</span><a href="#41684093">prev</a><span>|</span><a href="#41684242">next</a><span>|</span><label class="collapse" for="c-41684420">[-]</label><label class="expand" for="c-41684420">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I saw plenth of questions that only had definitive answers if you bought into specific theoretical frameworks<p>That kind of stuff would be great to train on. As long as the answer says something like &quot;If you abide by x framework, then y&quot;</div><br/></div></div><div id="41684242" class="c"><input type="checkbox" id="c-41684242" checked=""/><div class="controls bullet"><span class="by">DavidSJ</span><span>|</span><a href="#41683980">parent</a><span>|</span><a href="#41684420">prev</a><span>|</span><a href="#41685711">next</a><span>|</span><label class="collapse" for="c-41684242">[-]</label><label class="expand" for="c-41684242">[1 more]</label></div><br/><div class="children"><div class="content">What were the contradictions?</div><br/></div></div></div></div><div id="41685711" class="c"><input type="checkbox" id="c-41685711" checked=""/><div class="controls bullet"><span class="by">fsndz</span><span>|</span><a href="#41683980">prev</a><span>|</span><a href="#41680509">next</a><span>|</span><label class="collapse" for="c-41685711">[-]</label><label class="expand" for="c-41685711">[1 more]</label></div><br/><div class="children"><div class="content">&gt; &quot;In the early years, getting AI models like ChatGPT or its rival Cohere to spit out human-like responses required vast teams of low-cost workers helping models distinguish basic facts such as if an image was of a car or a carrot.&quot;<p>Starting the article by comparing what is necessary for ChatGPT to work and image labelling is a bit weird</div><br/></div></div><div id="41680509" class="c"><input type="checkbox" id="c-41680509" checked=""/><div class="controls bullet"><span class="by">JCharante</span><span>|</span><a href="#41685711">prev</a><span>|</span><a href="#41683326">next</a><span>|</span><label class="collapse" for="c-41680509">[-]</label><label class="expand" for="c-41680509">[44 more]</label></div><br/><div class="children"><div class="content">&gt; AI models now require trainers with advanced degrees<p>Companies that create data for FM (foundational model) companies have been hiring people with degrees for years<p>&gt; Invisible Tech employs 5,000 specialized trainers globally<p>Some of those companies have almost a million freelancers on their platforms, so 5k is honestly kinda medium sized.<p>&gt; It takes smart humans to avoid hallucinations in AI<p>Many smart humans fail at critical thinking. I&#x27;ve seen people with masters fail at spotting hallucinations in elementary level word problems.</div><br/><div id="41680567" class="c"><input type="checkbox" id="c-41680567" checked=""/><div class="controls bullet"><span class="by">aleph_minus_one</span><span>|</span><a href="#41680509">parent</a><span>|</span><a href="#41683186">next</a><span>|</span><label class="collapse" for="c-41680567">[-]</label><label class="expand" for="c-41680567">[39 more]</label></div><br/><div class="children"><div class="content">&gt; Many smart humans fail at critical thinking. I&#x27;ve seen people with masters fail at spotting hallucinations in elementary level word problems.<p>This is like lamenting that a person who has a doctoral degree, say, in mathematics or physics often don&#x27;t have a more than basic knowledge about, for example, medicine or pharmacy.</div><br/><div id="41680841" class="c"><input type="checkbox" id="c-41680841" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#41680509">root</a><span>|</span><a href="#41680567">parent</a><span>|</span><a href="#41680623">next</a><span>|</span><label class="collapse" for="c-41680841">[-]</label><label class="expand" for="c-41680841">[8 more]</label></div><br/><div class="children"><div class="content">&gt; This is like lamenting that a person who has a doctoral degree, say, in mathematics or physics often don&#x27;t have a more than basic knowledge in, for example, medicine or pharmacy.<p>It was word problems not rocket science. That tells a lot about human intelligence. We&#x27;re much less smart than we imagine, and most of our intelligence is based on book learning, not original discovery. Causal reasoning is based on learning and checking exceptions to rules. Truly novel ideation is actually rare.<p>We spent years implementing transformers in a naive way until someone figured out you can do it with much less memory (FlashAttention). That was such a face palm, it was a trivial idea thousands of PhDs missed. And the code is just 3 for loops, with a multiplication, a sum and an exponential. An algorithm that fits on a napkin in its abstract form.</div><br/><div id="41683271" class="c"><input type="checkbox" id="c-41683271" checked=""/><div class="controls bullet"><span class="by">klabb3</span><span>|</span><a href="#41680509">root</a><span>|</span><a href="#41680841">parent</a><span>|</span><a href="#41685541">next</a><span>|</span><label class="collapse" for="c-41683271">[-]</label><label class="expand" for="c-41683271">[4 more]</label></div><br/><div class="children"><div class="content">&gt; And the code is just 3 for loops, with a multiplication, a sum and an exponential.<p>All invented&#x2F;discovered and formalized by humans. That we found so much (unexpected) power in such simple abstractions is not a failure but a testament to the absolute ingenuity of human pursuit of knowledge.<p>The mistake is we’re over-estimating isolated discoveries and underestimating their second order effects.</div><br/><div id="41685201" class="c"><input type="checkbox" id="c-41685201" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#41680509">root</a><span>|</span><a href="#41683271">parent</a><span>|</span><a href="#41683794">next</a><span>|</span><label class="collapse" for="c-41685201">[-]</label><label class="expand" for="c-41685201">[1 more]</label></div><br/><div class="children"><div class="content">&gt; a testament to the absolute ingenuity of human pursuit of knowledge<p>I think it is more like searching and stumbling onto some great idea than pure-brain-ingenuity. That is why searching and social collaboration is essential and why I say we&#x27;re not that smart individually, but we search together. It&#x27;s slow, it took us years to get to Flash version of attention, but we get there, someone finds their way onto a major discovery eventually.<p>It took humanity 200K years to accumulate our current level of understanding, and if we lost it, it would take us another 200k years. Not even a whole human generation is that smart. It&#x27;s also why I don&#x27;t fault LLMs for mass-learning from human text. We do the same thing, 99% is inherited knowledge. The whole process of knowledge discovery moves slowly, and over large populations.</div><br/></div></div><div id="41683794" class="c"><input type="checkbox" id="c-41683794" checked=""/><div class="controls bullet"><span class="by">sdenton4</span><span>|</span><a href="#41680509">root</a><span>|</span><a href="#41683271">parent</a><span>|</span><a href="#41685201">prev</a><span>|</span><a href="#41685191">next</a><span>|</span><label class="collapse" for="c-41683794">[-]</label><label class="expand" for="c-41683794">[1 more]</label></div><br/><div class="children"><div class="content">Of course, all of this pales next to the invention of the actual human brain, which was not driven by humans or AI.</div><br/></div></div></div></div><div id="41685541" class="c"><input type="checkbox" id="c-41685541" checked=""/><div class="controls bullet"><span class="by">jokethrowaway</span><span>|</span><a href="#41680509">root</a><span>|</span><a href="#41680841">parent</a><span>|</span><a href="#41683271">prev</a><span>|</span><a href="#41680925">next</a><span>|</span><label class="collapse" for="c-41685541">[-]</label><label class="expand" for="c-41685541">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve also been impressed by how simple transformers, mamba and co are.<p>Maybe we get an llm to design the next evolution and benchmark how potential improvements fare?</div><br/></div></div><div id="41680925" class="c"><input type="checkbox" id="c-41680925" checked=""/><div class="controls bullet"><span class="by">beepbooptheory</span><span>|</span><a href="#41680509">root</a><span>|</span><a href="#41680841">parent</a><span>|</span><a href="#41685541">prev</a><span>|</span><a href="#41680623">next</a><span>|</span><label class="collapse" for="c-41680925">[-]</label><label class="expand" for="c-41680925">[2 more]</label></div><br/><div class="children"><div class="content">Doesn&#x27;t this lead you to, perhaps, question the category and measure of &quot;intelligence&quot; in general, especially how it is mobilized in this kind of context? Like this very angle does a lot to point out the contradictions in some speculative metaphysical category of &quot;intelligence&quot; or &quot;being smart,&quot; but then you just seem to accept it in this particular kind of fatalism.<p>Why not take away from this that &quot;intelligence&quot; is a word that obtains something relative to a particular society, namely, one which values some kind of behavior and speech over others.   &quot;Intelligence&quot; is something important to society, its the individual who negotiates (or not) the way they think and learn with what this particular signifier connects with at a given place and time.<p>Like I assume you don&#x27;t agree, but just perhaps if we use our &quot;intelligence&quot; here we could maybe come to some different conclusions here! Everyone is just dying to be like mid-20th century behaviorist now, I just don&#x27;t understand!</div><br/><div id="41685197" class="c"><input type="checkbox" id="c-41685197" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#41680509">root</a><span>|</span><a href="#41680925">parent</a><span>|</span><a href="#41680623">next</a><span>|</span><label class="collapse" for="c-41685197">[-]</label><label class="expand" for="c-41685197">[1 more]</label></div><br/><div class="children"><div class="content">Yes, I think intelligence is social and we kind of write off the social part and prefer to think in heroic terms, like &quot;Einstein was so smart!&quot;<p>I prefer to use the concept of search instead, it is better defined in search space and goal space. It doesn&#x27;t hide the environment, the external part of intelligence, or the learning process.</div><br/></div></div></div></div></div></div><div id="41680623" class="c"><input type="checkbox" id="c-41680623" checked=""/><div class="controls bullet"><span class="by">JCharante</span><span>|</span><a href="#41680509">root</a><span>|</span><a href="#41680567">parent</a><span>|</span><a href="#41680841">prev</a><span>|</span><a href="#41681042">next</a><span>|</span><label class="collapse" for="c-41680623">[-]</label><label class="expand" for="c-41680623">[24 more]</label></div><br/><div class="children"><div class="content">It depends on your definition of smart. I think that holding a degree != smart.</div><br/><div id="41680776" class="c"><input type="checkbox" id="c-41680776" checked=""/><div class="controls bullet"><span class="by">aniviacat</span><span>|</span><a href="#41680509">root</a><span>|</span><a href="#41680623">parent</a><span>|</span><a href="#41680858">next</a><span>|</span><label class="collapse" for="c-41680776">[-]</label><label class="expand" for="c-41680776">[2 more]</label></div><br/><div class="children"><div class="content">&gt; I think that holding a degree != smart.<p>Does this mean that these two sentences are completely unrelated and only happen to exist within the same paragraph?<p>&gt; Many smart humans fail at critical thinking. I&#x27;ve seen people with masters [...]<p>I&#x27;ve understood you to use &quot;people with masters&quot; as an example of &quot;smart humans&quot;.</div><br/><div id="41681328" class="c"><input type="checkbox" id="c-41681328" checked=""/><div class="controls bullet"><span class="by">JCharante</span><span>|</span><a href="#41680509">root</a><span>|</span><a href="#41680776">parent</a><span>|</span><a href="#41680858">next</a><span>|</span><label class="collapse" for="c-41681328">[-]</label><label class="expand" for="c-41681328">[1 more]</label></div><br/><div class="children"><div class="content">Well the article began by talking about how before these data training companies would just hire generalists for $2&#x2F;hr, but now they&#x27;re hiring degree holders. And it mentions that smart people will be necessary. I&#x27;m just saying that degree holding != smart and it&#x27;s a trap that those data training companies have to avoid.</div><br/></div></div></div></div><div id="41680858" class="c"><input type="checkbox" id="c-41680858" checked=""/><div class="controls bullet"><span class="by">aleph_minus_one</span><span>|</span><a href="#41680509">root</a><span>|</span><a href="#41680623">parent</a><span>|</span><a href="#41680776">prev</a><span>|</span><a href="#41684428">next</a><span>|</span><label class="collapse" for="c-41680858">[-]</label><label class="expand" for="c-41680858">[18 more]</label></div><br/><div class="children"><div class="content">&gt; It depends on your definition of smart. I think that holding a degree != smart.<p>You wrote:<p>&gt; I&#x27;ve seen people with masters fail at spotting hallucinations in elementary level word problems.<p>I wanted to express that having a master in some (even complicated) subject does not make you a master at [pun intended] spotting hallucinations. To give evidence for this statement, I gave a different, more down-to-earth example of a similar situation.</div><br/><div id="41681364" class="c"><input type="checkbox" id="c-41681364" checked=""/><div class="controls bullet"><span class="by">JCharante</span><span>|</span><a href="#41680509">root</a><span>|</span><a href="#41680858">parent</a><span>|</span><a href="#41684428">next</a><span>|</span><label class="collapse" for="c-41681364">[-]</label><label class="expand" for="c-41681364">[17 more]</label></div><br/><div class="children"><div class="content">It was a math problem, like this.<p>Q: A farmer has 72 chickens. He sells 15 chickens at the market and buys 8 new chicks. Later that week, a fox sneaks into the coop and eats 6 chickens. How many chickens could the farmer sell at the market tomorrow?<p>AI Answer: The farmer started with 72 chickens. After selling 15, he had 57 chickens left. Then he bought 8 new chicks, bringing the total to 65. Finally, the fox ate 6 chickens, so we subtract 6 from 65. This gives us 59 chickens. Therefore, the farmer now has 59 chickens that he could sell at the market tomorrow.<p>--<p>You&#x27;d expect someone who can read&#x2F;understand proofs to be able to spot a a flow in the logic that it takes longer than 1 week for chicks to turn into chickens.</div><br/><div id="41683254" class="c"><input type="checkbox" id="c-41683254" checked=""/><div class="controls bullet"><span class="by">echoangle</span><span>|</span><a href="#41680509">root</a><span>|</span><a href="#41681364">parent</a><span>|</span><a href="#41681727">next</a><span>|</span><label class="collapse" for="c-41683254">[-]</label><label class="expand" for="c-41683254">[5 more]</label></div><br/><div class="children"><div class="content">As a layman, i have no clue at what point a chick turns into a chicken. I also think this isn’t even answerable, because „new chick“ doesn’t really imply „newborn“ but only means „new to the farmer“, so the chicks could be at an age where they would be chickens a week later, no?</div><br/><div id="41683644" class="c"><input type="checkbox" id="c-41683644" checked=""/><div class="controls bullet"><span class="by">Kerb_</span><span>|</span><a href="#41680509">root</a><span>|</span><a href="#41683254">parent</a><span>|</span><a href="#41681727">next</a><span>|</span><label class="collapse" for="c-41683644">[-]</label><label class="expand" for="c-41683644">[4 more]</label></div><br/><div class="children"><div class="content">I still call my 12 year old cat a &quot;kitty&quot;. If someone marked my answer as incorrect because &quot;chicks aren&#x27;t chickens yet&quot; I would think they&#x27;re wasting their time with riddles instead of actual intelligence testing. Besides, if the chicks were sellable <i>to</i> the farmer, why the hell wouldn&#x27;t the farmer be able to sell them?</div><br/><div id="41683705" class="c"><input type="checkbox" id="c-41683705" checked=""/><div class="controls bullet"><span class="by">echoangle</span><span>|</span><a href="#41680509">root</a><span>|</span><a href="#41683644">parent</a><span>|</span><a href="#41684644">next</a><span>|</span><label class="collapse" for="c-41683705">[-]</label><label class="expand" for="c-41683705">[1 more]</label></div><br/><div class="children"><div class="content">Now I have to think of this Reddit thread that made me react pretty similarly: <a href="https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;ChatGPT&#x2F;s&#x2F;jWlSqhJsOH" rel="nofollow">https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;ChatGPT&#x2F;s&#x2F;jWlSqhJsOH</a><p>The OP there also has a pretty bad riddle (due to a grammatical error that completely changes the meaning and makes the intended solution nonsensical, and a solution that many people wouldn’t even have heard of).</div><br/></div></div><div id="41684644" class="c"><input type="checkbox" id="c-41684644" checked=""/><div class="controls bullet"><span class="by">resoluteteeth</span><span>|</span><a href="#41680509">root</a><span>|</span><a href="#41683644">parent</a><span>|</span><a href="#41683705">prev</a><span>|</span><a href="#41681727">next</a><span>|</span><label class="collapse" for="c-41684644">[-]</label><label class="expand" for="c-41684644">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Besides, if the chicks were sellable to the farmer, why the hell wouldn&#x27;t the farmer be able to sell them?<p>I think maybe the original poster is making some sort of additional assumption that the farmer must be selling chickens as meat at the market and a chick wouldn&#x27;t be sold for that purpose until it&#x27;s a mature chicken?<p>(Of course depending on how you interpret the question a chick is a chicken (species) and there&#x27;s nothing inherently preventing reselling the chicks so I don&#x27;t really understand why OP thinks the ai answer is clearly objectively wrong. It seems more like a matter of interpretation.)</div><br/><div id="41684889" class="c"><input type="checkbox" id="c-41684889" checked=""/><div class="controls bullet"><span class="by">JCharante</span><span>|</span><a href="#41680509">root</a><span>|</span><a href="#41684644">parent</a><span>|</span><a href="#41681727">next</a><span>|</span><label class="collapse" for="c-41684889">[-]</label><label class="expand" for="c-41684889">[1 more]</label></div><br/><div class="children"><div class="content">After posting I realized that the farmer bought some chicks so it could be interpreted that way. I should have modified it to say that 6 chickens hatched.<p>Anyways this thread is a perfect example of the chaotic datasets that are being used to train FMs. These arguments of whether it’s reasonable to assume a chick could mature into a chicken within a week are happening everyday and have been taking place for years. Safe to say a billion dollars has been spent on datasets to train FMs where everybody has a different interpretation and the datasets are not aligned.</div><br/></div></div></div></div></div></div></div></div><div id="41681727" class="c"><input type="checkbox" id="c-41681727" checked=""/><div class="controls bullet"><span class="by">aleph_minus_one</span><span>|</span><a href="#41680509">root</a><span>|</span><a href="#41681364">parent</a><span>|</span><a href="#41683254">prev</a><span>|</span><a href="#41681735">next</a><span>|</span><label class="collapse" for="c-41681727">[-]</label><label class="expand" for="c-41681727">[4 more]</label></div><br/><div class="children"><div class="content">&gt; You&#x27;d expect someone who can read&#x2F;understand proofs to be able to spot a a flow in the logic that it takes longer than 1 week for chicks to turn into chickens.<p>Rather, I&#x27;d assume that someone who is capable of spotting the flow in the logic has a decent  knowledge of the English language (in this case referring to the difference in meaning between &quot;chick&quot; and &quot;chicken&quot;).<p>Many people who are good mathematicians (i.e. capable of &quot;reading&#x2F;understanding proofs&quot; as you expressed it) are not native English speakers or have a great L2 level of English.</div><br/><div id="41682829" class="c"><input type="checkbox" id="c-41682829" checked=""/><div class="controls bullet"><span class="by">Viliam1234</span><span>|</span><a href="#41680509">root</a><span>|</span><a href="#41681727">parent</a><span>|</span><a href="#41684901">next</a><span>|</span><label class="collapse" for="c-41682829">[-]</label><label class="expand" for="c-41682829">[2 more]</label></div><br/><div class="children"><div class="content">But I was told that humans have this thing called &quot;general intelligence&quot;, which means they should be capable to do both math <i>and</i> English!<p>If an AI made a similar mistake, people would laugh at it.</div><br/><div id="41683105" class="c"><input type="checkbox" id="c-41683105" checked=""/><div class="controls bullet"><span class="by">aleph_minus_one</span><span>|</span><a href="#41680509">root</a><span>|</span><a href="#41682829">parent</a><span>|</span><a href="#41684901">next</a><span>|</span><label class="collapse" for="c-41683105">[-]</label><label class="expand" for="c-41683105">[1 more]</label></div><br/><div class="children"><div class="content">&gt; But I was told that humans have this thing called &quot;general intelligence&quot;, which means they should be capable to do both math and English!<p>You confuse &quot;intelligence&quot; with &quot;knowledge&quot;. To keep to your example: there exist quite a lot of highly intelligent people on earth who don&#x27;t or barely know English.</div><br/></div></div></div></div><div id="41684901" class="c"><input type="checkbox" id="c-41684901" checked=""/><div class="controls bullet"><span class="by">JCharante</span><span>|</span><a href="#41680509">root</a><span>|</span><a href="#41681727">parent</a><span>|</span><a href="#41682829">prev</a><span>|</span><a href="#41681735">next</a><span>|</span><label class="collapse" for="c-41684901">[-]</label><label class="expand" for="c-41684901">[1 more]</label></div><br/><div class="children"><div class="content">That’s also true and a HUGE problem when companies are hiring non native English speakers to work on English datasets.</div><br/></div></div></div></div><div id="41681735" class="c"><input type="checkbox" id="c-41681735" checked=""/><div class="controls bullet"><span class="by">jonahx</span><span>|</span><a href="#41680509">root</a><span>|</span><a href="#41681364">parent</a><span>|</span><a href="#41681727">prev</a><span>|</span><a href="#41685372">next</a><span>|</span><label class="collapse" for="c-41681735">[-]</label><label class="expand" for="c-41681735">[2 more]</label></div><br/><div class="children"><div class="content">When an educated person misses this question, it&#x27;s not because the temporal logic is out of their reach.  It&#x27;s because they scanned the problem and answered quickly.  They&#x27;re pattern matching to a type of problem that wouldn&#x27;t include the &quot;tomorrow&#x2F;next week&quot; trick, and then giving the correct answer to that.<p>Imo it&#x27;s evidence that humans make assumptions and aren&#x27;t always thorough more than evidence of smart people being unable to perform elementary logic.</div><br/><div id="41684912" class="c"><input type="checkbox" id="c-41684912" checked=""/><div class="controls bullet"><span class="by">JCharante</span><span>|</span><a href="#41680509">root</a><span>|</span><a href="#41681735">parent</a><span>|</span><a href="#41685372">next</a><span>|</span><label class="collapse" for="c-41684912">[-]</label><label class="expand" for="c-41684912">[1 more]</label></div><br/><div class="children"><div class="content">The humans were prompted to read the AI responses very carefully because their hallucinations are very good at convincing you with words. It takes a certain skillset to question every word that comes out of a language model because most people will go “hmm yeah that logic seems right”. So hiring “smart” people is insufficient, you need very paranoid people who question every assumption.</div><br/></div></div></div></div><div id="41685372" class="c"><input type="checkbox" id="c-41685372" checked=""/><div class="controls bullet"><span class="by">mkl</span><span>|</span><a href="#41680509">root</a><span>|</span><a href="#41681364">parent</a><span>|</span><a href="#41681735">prev</a><span>|</span><a href="#41683634">next</a><span>|</span><label class="collapse" for="c-41685372">[-]</label><label class="expand" for="c-41685372">[1 more]</label></div><br/><div class="children"><div class="content">Chicks are chickens, just like puppies are dogs, kittens are cats, etc.  &quot;Chicken&quot; is the name of the species: <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Chicken#Nomenclature" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Chicken#Nomenclature</a><p>If you&#x27;d said &quot;hens&quot; you&#x27;d have a stronger point, but then you&#x27;d need to be talking about chicks and hens (and they could still cross whatever adulthood threshold you like within the week, as you didn&#x27;t specify how young they are - &quot;new&quot; could just mean new to the farmer).</div><br/></div></div><div id="41683634" class="c"><input type="checkbox" id="c-41683634" checked=""/><div class="controls bullet"><span class="by">IanCal</span><span>|</span><a href="#41680509">root</a><span>|</span><a href="#41681364">parent</a><span>|</span><a href="#41685372">prev</a><span>|</span><a href="#41684458">next</a><span>|</span><label class="collapse" for="c-41683634">[-]</label><label class="expand" for="c-41683634">[2 more]</label></div><br/><div class="children"><div class="content">O1-preview I think gets this right. It assumes a distinction between adult chickens and chicks.<p><a href="https:&#x2F;&#x2F;chatgpt.com&#x2F;share&#x2F;66f890b2-04bc-8002-9724-2deaf3985daf" rel="nofollow">https:&#x2F;&#x2F;chatgpt.com&#x2F;share&#x2F;66f890b2-04bc-8002-9724-2deaf3985d...</a></div><br/><div id="41684923" class="c"><input type="checkbox" id="c-41684923" checked=""/><div class="controls bullet"><span class="by">JCharante</span><span>|</span><a href="#41680509">root</a><span>|</span><a href="#41683634">parent</a><span>|</span><a href="#41684458">next</a><span>|</span><label class="collapse" for="c-41684923">[-]</label><label class="expand" for="c-41684923">[1 more]</label></div><br/><div class="children"><div class="content">Nice. I used Claude 3.5 Sonnet to generate a word problem &amp; false solution for my example.</div><br/></div></div></div></div><div id="41684458" class="c"><input type="checkbox" id="c-41684458" checked=""/><div class="controls bullet"><span class="by">fragmede</span><span>|</span><a href="#41680509">root</a><span>|</span><a href="#41681364">parent</a><span>|</span><a href="#41683634">prev</a><span>|</span><a href="#41684428">next</a><span>|</span><label class="collapse" for="c-41684458">[-]</label><label class="expand" for="c-41684458">[2 more]</label></div><br/><div class="children"><div class="content">Or the other one, a flock of 8 birds are sitting on a fence. The farmer shoots 1. How many are left? 8-1 is 7, but the answer is zero, because the gun shot scared the rest of them off. Fwiw, ChatGPT says zero.<p>At some point, we decided that compilers were good enough to convert code into assembly to just use them. even if an absolute master could write better assembly than the complier, we moved over to using compilers because of the advantages offered.</div><br/><div id="41684925" class="c"><input type="checkbox" id="c-41684925" checked=""/><div class="controls bullet"><span class="by">JCharante</span><span>|</span><a href="#41680509">root</a><span>|</span><a href="#41684458">parent</a><span>|</span><a href="#41684428">next</a><span>|</span><label class="collapse" for="c-41684925">[-]</label><label class="expand" for="c-41684925">[1 more]</label></div><br/><div class="children"><div class="content">Sorry I fail to see your point. Is it that conflating chicks and chickens is good enough performance?</div><br/></div></div></div></div></div></div></div></div><div id="41684428" class="c"><input type="checkbox" id="c-41684428" checked=""/><div class="controls bullet"><span class="by">spencerchubb</span><span>|</span><a href="#41680509">root</a><span>|</span><a href="#41680623">parent</a><span>|</span><a href="#41680858">prev</a><span>|</span><a href="#41681042">next</a><span>|</span><label class="collapse" for="c-41684428">[-]</label><label class="expand" for="c-41684428">[3 more]</label></div><br/><div class="children"><div class="content">Do you believe that holding a degree is dumb, or just that holding a degree is an insufficient condition for smartness? Technically what you wrote says the former</div><br/><div id="41684872" class="c"><input type="checkbox" id="c-41684872" checked=""/><div class="controls bullet"><span class="by">JCharante</span><span>|</span><a href="#41680509">root</a><span>|</span><a href="#41684428">parent</a><span>|</span><a href="#41681042">next</a><span>|</span><label class="collapse" for="c-41684872">[-]</label><label class="expand" for="c-41684872">[2 more]</label></div><br/><div class="children"><div class="content">Thanks. I meant that holding a degree does not guarantee that you are smart.</div><br/></div></div></div></div></div></div><div id="41681042" class="c"><input type="checkbox" id="c-41681042" checked=""/><div class="controls bullet"><span class="by">dilawar</span><span>|</span><a href="#41680509">root</a><span>|</span><a href="#41680567">parent</a><span>|</span><a href="#41680623">prev</a><span>|</span><a href="#41683186">next</a><span>|</span><label class="collapse" for="c-41681042">[-]</label><label class="expand" for="c-41681042">[6 more]</label></div><br/><div class="children"><div class="content">I think many people like to believe that solving puzzles will somehow make them better at combinatorics. Lateral skill transfer in non-motor skills e.g. office works, academics works etc may not be any better than motor skills. It&#x27;s easier to convince people that playing soccer everyday wouldn&#x27;t make them any better at cricket, or even hockey.</div><br/><div id="41681538" class="c"><input type="checkbox" id="c-41681538" checked=""/><div class="controls bullet"><span class="by">thatcat</span><span>|</span><a href="#41680509">root</a><span>|</span><a href="#41681042">parent</a><span>|</span><a href="#41681224">next</a><span>|</span><label class="collapse" for="c-41681538">[-]</label><label class="expand" for="c-41681538">[1 more]</label></div><br/><div class="children"><div class="content">Kobe Bryant played soccer, Michael Jordan played baseball, Lebron played football.. it actually makes you even better because you learn non traditional strategies to apply to the other sport you&#x27;re playing.</div><br/></div></div><div id="41681224" class="c"><input type="checkbox" id="c-41681224" checked=""/><div class="controls bullet"><span class="by">sudosysgen</span><span>|</span><a href="#41680509">root</a><span>|</span><a href="#41681042">parent</a><span>|</span><a href="#41681538">prev</a><span>|</span><a href="#41683186">next</a><span>|</span><label class="collapse" for="c-41681224">[-]</label><label class="expand" for="c-41681224">[4 more]</label></div><br/><div class="children"><div class="content">But motor skills transfer extremely well. It&#x27;s not uncommon for professional athletes to switch sports, some even repeatedly.</div><br/><div id="41681380" class="c"><input type="checkbox" id="c-41681380" checked=""/><div class="controls bullet"><span class="by">Der_Einzige</span><span>|</span><a href="#41680509">root</a><span>|</span><a href="#41681224">parent</a><span>|</span><a href="#41683186">next</a><span>|</span><label class="collapse" for="c-41681380">[-]</label><label class="expand" for="c-41681380">[3 more]</label></div><br/><div class="children"><div class="content">There’s some famous ass basketball players with mediocre but still existent MLB careers.</div><br/><div id="41681486" class="c"><input type="checkbox" id="c-41681486" checked=""/><div class="controls bullet"><span class="by">jononor</span><span>|</span><a href="#41680509">root</a><span>|</span><a href="#41681380">parent</a><span>|</span><a href="#41685154">next</a><span>|</span><label class="collapse" for="c-41681486">[-]</label><label class="expand" for="c-41681486">[1 more]</label></div><br/><div class="children"><div class="content">Wealth, network and fame transfers incredibly well between fields. Possibly better than anything else. It should be accounted for when reasoning about success in disparate fields. In addition to luck, of course.</div><br/></div></div><div id="41685154" class="c"><input type="checkbox" id="c-41685154" checked=""/><div class="controls bullet"><span class="by">mmooss</span><span>|</span><a href="#41680509">root</a><span>|</span><a href="#41681380">parent</a><span>|</span><a href="#41681486">prev</a><span>|</span><a href="#41683186">next</a><span>|</span><label class="collapse" for="c-41685154">[-]</label><label class="expand" for="c-41685154">[1 more]</label></div><br/><div class="children"><div class="content">&gt; mediocre but still existent MLB careers.<p>If you have a MLB career at all, you are an elite baseball player.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="41683186" class="c"><input type="checkbox" id="c-41683186" checked=""/><div class="controls bullet"><span class="by">39896880</span><span>|</span><a href="#41680509">parent</a><span>|</span><a href="#41680567">prev</a><span>|</span><a href="#41681140">next</a><span>|</span><label class="collapse" for="c-41683186">[-]</label><label class="expand" for="c-41683186">[3 more]</label></div><br/><div class="children"><div class="content">All the models do is hallucinate. They just sometimes hallucinate the truth.</div><br/><div id="41684543" class="c"><input type="checkbox" id="c-41684543" checked=""/><div class="controls bullet"><span class="by">vharuck</span><span>|</span><a href="#41680509">root</a><span>|</span><a href="#41683186">parent</a><span>|</span><a href="#41683899">next</a><span>|</span><label class="collapse" for="c-41684543">[-]</label><label class="expand" for="c-41684543">[1 more]</label></div><br/><div class="children"><div class="content">Nice George Box paraphrasing.</div><br/></div></div><div id="41683899" class="c"><input type="checkbox" id="c-41683899" checked=""/><div class="controls bullet"><span class="by">therealdrag0</span><span>|</span><a href="#41680509">root</a><span>|</span><a href="#41683186">parent</a><span>|</span><a href="#41684543">prev</a><span>|</span><a href="#41681140">next</a><span>|</span><label class="collapse" for="c-41683899">[-]</label><label class="expand" for="c-41683899">[1 more]</label></div><br/><div class="children"><div class="content">A great deal of my own thinking could be described as hallucinating, given a sufficiently loose definition.</div><br/></div></div></div></div></div></div><div id="41683326" class="c"><input type="checkbox" id="c-41683326" checked=""/><div class="controls bullet"><span class="by">recursive</span><span>|</span><a href="#41680509">prev</a><span>|</span><a href="#41680437">next</a><span>|</span><label class="collapse" for="c-41683326">[-]</label><label class="expand" for="c-41683326">[2 more]</label></div><br/><div class="children"><div class="content">It kind of seems like it got dumber to me.  Maybe because my first exposure to it was so magical.  But now, I just notice all  the ways it&#x27;s wrong.</div><br/><div id="41683992" class="c"><input type="checkbox" id="c-41683992" checked=""/><div class="controls bullet"><span class="by">joe_the_user</span><span>|</span><a href="#41683326">parent</a><span>|</span><a href="#41680437">next</a><span>|</span><label class="collapse" for="c-41683992">[-]</label><label class="expand" for="c-41683992">[1 more]</label></div><br/><div class="children"><div class="content">I think any given model is going to decay over time. The data used in them becomes out-dated and the models cost money to run and various cost-saving short-cuts are thus made to reduce accuracy. Also, having your old model seem clunky can make your new model seem great.<p>Obviously, there are real ways new model get better too. But if we have diminishing returns, as many speculate, it will take a while for it to be entirely obvious.</div><br/></div></div></div></div><div id="41680437" class="c"><input type="checkbox" id="c-41680437" checked=""/><div class="controls bullet"><span class="by">Stem0037</span><span>|</span><a href="#41683326">prev</a><span>|</span><a href="#41685604">next</a><span>|</span><label class="collapse" for="c-41680437">[-]</label><label class="expand" for="c-41680437">[20 more]</label></div><br/><div class="children"><div class="content">AI, at least in its current form, is not so much replacing human expertise as it is augmenting and redistributing it.</div><br/><div id="41680814" class="c"><input type="checkbox" id="c-41680814" checked=""/><div class="controls bullet"><span class="by">alephnerd</span><span>|</span><a href="#41680437">parent</a><span>|</span><a href="#41683232">next</a><span>|</span><label class="collapse" for="c-41680814">[-]</label><label class="expand" for="c-41680814">[18 more]</label></div><br/><div class="children"><div class="content">Yep. And that&#x27;s the real value add that is happening right now.<p>HN concentrates on the hype but ignores the massive growth in startups that are applying commoditized foundational models to specific domains and applications.<p>Early Stage investments are made with a 5-7 year timeline in mind (either for later stage funding if successful or acquisition if less successful).<p>People also seem to ignore the fact that foundational models are on the verge of being commoditized over the next 5-7 years, which decreases the overall power of foundational ML companies, as applications become the key differentiator, and domain experience is hard to build (look at how it took Google 15 years to finally get on track in the cloud computing world)</div><br/><div id="41681238" class="c"><input type="checkbox" id="c-41681238" checked=""/><div class="controls bullet"><span class="by">MostlyStable</span><span>|</span><a href="#41680437">root</a><span>|</span><a href="#41680814">parent</a><span>|</span><a href="#41681484">next</a><span>|</span><label class="collapse" for="c-41681238">[-]</label><label class="expand" for="c-41681238">[6 more]</label></div><br/><div class="children"><div class="content">I notice that a lot of people seem to only focus on the things that AI <i>can&#x27;t</i> do or the cases where it breaks, and seem unwilling or incapable of focusing on things it <i>can</i> do.<p>The reality is that both things are important. It is necessary to know the limitations of AI (and keep up with them as they change), to avoid getting yourself in trouble, but if you ignore the things that AI can do (which are many, and constantly increasing), you are leaving a ton of value on the table.</div><br/><div id="41683493" class="c"><input type="checkbox" id="c-41683493" checked=""/><div class="controls bullet"><span class="by">vladms</span><span>|</span><a href="#41680437">root</a><span>|</span><a href="#41681238">parent</a><span>|</span><a href="#41682194">next</a><span>|</span><label class="collapse" for="c-41683493">[-]</label><label class="expand" for="c-41683493">[1 more]</label></div><br/><div class="children"><div class="content">How do you define &quot;can do&quot; ? Would answering correctly 9 out of 10 questions correctly for a type of question (like give directions knowing a map) mean it &quot;can do&quot; or that it &quot;can&#x27;t do&quot; ?<p>Considering it works for so many cases, I think it is naturally to point out the examples where it does not work - to better understand the limit.<p>Not to mention that practically, I did not see anything proving that it will always &quot;be able&quot; to do something . Yes, it works most of the times for many things, but it&#x27;s important to remember it can (randomly?) fail and we don&#x27;t seem to be able to fix that (humans do that too, but having computers fail randomly is something new). Other software lets say a numerical solver or a compiler, are more stable and predictable (and if they don&#x27;t work there is a clear bug-fix that can be implemented).</div><br/></div></div><div id="41682194" class="c"><input type="checkbox" id="c-41682194" checked=""/><div class="controls bullet"><span class="by">aleph_minus_one</span><span>|</span><a href="#41680437">root</a><span>|</span><a href="#41681238">parent</a><span>|</span><a href="#41683493">prev</a><span>|</span><a href="#41681361">next</a><span>|</span><label class="collapse" for="c-41682194">[-]</label><label class="expand" for="c-41682194">[2 more]</label></div><br/><div class="children"><div class="content">&gt; I notice that a lot of people seem to only focus on the things that AI <i>can&#x27;t</i> do or the cases where it breaks, and seem unwilling or incapable of focusing on things it <i>can</i> do.<p>I might be one of these people, but in my opinion, one should not concentrate on things that it <i>can</i> do, but for how many of the things where an AI might be of help for you,<p>- it does work<p>- it only &quot;can&quot; do it in a very broken way<p>- it can&#x27;t do that<p>At least for the things that <i>I</i> am interested in an AI doing for me, the record is rather bad.</div><br/><div id="41685078" class="c"><input type="checkbox" id="c-41685078" checked=""/><div class="controls bullet"><span class="by">signatoremo</span><span>|</span><a href="#41680437">root</a><span>|</span><a href="#41682194">parent</a><span>|</span><a href="#41681361">next</a><span>|</span><label class="collapse" for="c-41685078">[-]</label><label class="expand" for="c-41685078">[1 more]</label></div><br/><div class="children"><div class="content">Just because AI doesn’t work for you, doesn’t mean it doesn’t work for other people. Ozempic may have no effect, or even harmful to you, but it’s a godsend for many others. Acknowledge that, instead of blindly insisting on your use cases. It’s fine to resist the hype, but it’s foolish to be willfully ignorant.</div><br/></div></div></div></div><div id="41681361" class="c"><input type="checkbox" id="c-41681361" checked=""/><div class="controls bullet"><span class="by">alephnerd</span><span>|</span><a href="#41680437">root</a><span>|</span><a href="#41681238">parent</a><span>|</span><a href="#41682194">prev</a><span>|</span><a href="#41681484">next</a><span>|</span><label class="collapse" for="c-41681361">[-]</label><label class="expand" for="c-41681361">[2 more]</label></div><br/><div class="children"><div class="content">Yep! Nuance is critical, and sadly it feels like nuance is dying on HN.</div><br/><div id="41685058" class="c"><input type="checkbox" id="c-41685058" checked=""/><div class="controls bullet"><span class="by">Tepix</span><span>|</span><a href="#41680437">root</a><span>|</span><a href="#41681361">parent</a><span>|</span><a href="#41681484">next</a><span>|</span><label class="collapse" for="c-41685058">[-]</label><label class="expand" for="c-41685058">[1 more]</label></div><br/><div class="children"><div class="content">This very discussion feels nuanced so i don&#x27;t share your sentiment.</div><br/></div></div></div></div></div></div><div id="41681484" class="c"><input type="checkbox" id="c-41681484" checked=""/><div class="controls bullet"><span class="by">skybrian</span><span>|</span><a href="#41680437">root</a><span>|</span><a href="#41680814">parent</a><span>|</span><a href="#41681238">prev</a><span>|</span><a href="#41681313">next</a><span>|</span><label class="collapse" for="c-41681484">[-]</label><label class="expand" for="c-41681484">[5 more]</label></div><br/><div class="children"><div class="content">It would be nice to have more examples. Without specifics, “massive growth in startups” isn’t easily distinguishable from hype.<p>A trend towards domain-specific tools makes sense, though.</div><br/><div id="41681918" class="c"><input type="checkbox" id="c-41681918" checked=""/><div class="controls bullet"><span class="by">alephnerd</span><span>|</span><a href="#41680437">root</a><span>|</span><a href="#41681484">parent</a><span>|</span><a href="#41681313">next</a><span>|</span><label class="collapse" for="c-41681918">[-]</label><label class="expand" for="c-41681918">[4 more]</label></div><br/><div class="children"><div class="content">DevTools&#x2F;Configuration Management and Automated SOC are two fairly significant example.</div><br/><div id="41683268" class="c"><input type="checkbox" id="c-41683268" checked=""/><div class="controls bullet"><span class="by">jayd16</span><span>|</span><a href="#41680437">root</a><span>|</span><a href="#41681918">parent</a><span>|</span><a href="#41683230">next</a><span>|</span><label class="collapse" for="c-41683268">[-]</label><label class="expand" for="c-41683268">[2 more]</label></div><br/><div class="children"><div class="content">Am I the only one unimpressed by the dev tool situation?  Debugging and verifying the generated code is more work than simply writing it.<p>I&#x27;m much more impressed with the advances in computer vision and image generation.<p>Either way, what are the startups that I should be looking at?</div><br/><div id="41683391" class="c"><input type="checkbox" id="c-41683391" checked=""/><div class="controls bullet"><span class="by">Terr_</span><span>|</span><a href="#41680437">root</a><span>|</span><a href="#41683268">parent</a><span>|</span><a href="#41683230">next</a><span>|</span><label class="collapse" for="c-41683391">[-]</label><label class="expand" for="c-41683391">[1 more]</label></div><br/><div class="children"><div class="content">And even when the output is perfect, it may be that the tool is helping you write the same thing a hundred times instead of abstracting it into a better library or helper function.<p>Search&#x2F;Replace as a service.</div><br/></div></div></div></div><div id="41683230" class="c"><input type="checkbox" id="c-41683230" checked=""/><div class="controls bullet"><span class="by">skybrian</span><span>|</span><a href="#41680437">root</a><span>|</span><a href="#41681918">parent</a><span>|</span><a href="#41683268">prev</a><span>|</span><a href="#41681313">next</a><span>|</span><label class="collapse" for="c-41683230">[-]</label><label class="expand" for="c-41683230">[1 more]</label></div><br/><div class="children"><div class="content">Those are more like broad categories than examples of startups, though.</div><br/></div></div></div></div></div></div><div id="41681313" class="c"><input type="checkbox" id="c-41681313" checked=""/><div class="controls bullet"><span class="by">danielbln</span><span>|</span><a href="#41680437">root</a><span>|</span><a href="#41680814">parent</a><span>|</span><a href="#41681484">prev</a><span>|</span><a href="#41681290">next</a><span>|</span><label class="collapse" for="c-41681313">[-]</label><label class="expand" for="c-41681313">[3 more]</label></div><br/><div class="children"><div class="content">Same with consultancy. There is a huge amount of automation that can be done with current gen LLMs, as long as you keep their shortcomings in mind. The &quot;stochastic parrot&quot; crowd seems an over correction to the hype bros.</div><br/><div id="41681348" class="c"><input type="checkbox" id="c-41681348" checked=""/><div class="controls bullet"><span class="by">alephnerd</span><span>|</span><a href="#41680437">root</a><span>|</span><a href="#41681313">parent</a><span>|</span><a href="#41681290">next</a><span>|</span><label class="collapse" for="c-41681348">[-]</label><label class="expand" for="c-41681348">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s because the kind of person who understands nuance isn&#x27;t the kind of person to post in HN flame wars.<p>The industry is still in it&#x27;s infancy right now, and stuff can change in 3-5 years.<p>Heck, 5 years ago models like GPT-4o were considered unrealistic in scale, and funding in the AI&#x2F;ML space was drying up at the expense of crypto and cybersecurity. Yet look at the industry today.<p>We&#x27;re still very early and there are a lot of opportunities that are going to be discovered or are in the process of being discovered.</div><br/><div id="41684990" class="c"><input type="checkbox" id="c-41684990" checked=""/><div class="controls bullet"><span class="by">parineum</span><span>|</span><a href="#41680437">root</a><span>|</span><a href="#41681348">parent</a><span>|</span><a href="#41681290">next</a><span>|</span><label class="collapse" for="c-41684990">[-]</label><label class="expand" for="c-41684990">[1 more]</label></div><br/><div class="children"><div class="content">GPT4o is unrealistic at scale. OpenAI isn&#x27;t making a profit running it.</div><br/></div></div></div></div></div></div><div id="41681290" class="c"><input type="checkbox" id="c-41681290" checked=""/><div class="controls bullet"><span class="by">Workaccount2</span><span>|</span><a href="#41680437">root</a><span>|</span><a href="#41680814">parent</a><span>|</span><a href="#41681313">prev</a><span>|</span><a href="#41683232">next</a><span>|</span><label class="collapse" for="c-41681290">[-]</label><label class="expand" for="c-41681290">[3 more]</label></div><br/><div class="children"><div class="content">...and then being blown up when the AI company integrates their idea.</div><br/><div id="41681338" class="c"><input type="checkbox" id="c-41681338" checked=""/><div class="controls bullet"><span class="by">alephnerd</span><span>|</span><a href="#41680437">root</a><span>|</span><a href="#41681290">parent</a><span>|</span><a href="#41683232">next</a><span>|</span><label class="collapse" for="c-41681338">[-]</label><label class="expand" for="c-41681338">[2 more]</label></div><br/><div class="children"><div class="content">Not exactly.<p>At least in the cybersecurity space, most startups have 3-5 year plans to build their own foundational models and&#x2F;or work with foundational model companies to not directly compete with each other.<p>Furthermore, GTM is relationship and solution, and an &quot;everything&quot; company has a difficult time sympathizing or understanding GTM on a sector to sector basis.<p>Instead, the foundational ML companies like OpenAI have worked to instead give seed&#x2F;pre-seed funding to startups applying foundational MLs per domain.</div><br/><div id="41683799" class="c"><input type="checkbox" id="c-41683799" checked=""/><div class="controls bullet"><span class="by">HeatrayEnjoyer</span><span>|</span><a href="#41680437">root</a><span>|</span><a href="#41681338">parent</a><span>|</span><a href="#41683232">next</a><span>|</span><label class="collapse" for="c-41683799">[-]</label><label class="expand" for="c-41683799">[1 more]</label></div><br/><div class="children"><div class="content">OpenAI&#x2F;Microsoft are building a $100B+ datacenter for foundation models and pitching ideas for $1T+. Compute is the primary bottleneck, startup competitors will not be physically possible.</div><br/></div></div></div></div></div></div></div></div><div id="41683232" class="c"><input type="checkbox" id="c-41683232" checked=""/><div class="controls bullet"><span class="by">hanniabu</span><span>|</span><a href="#41680437">parent</a><span>|</span><a href="#41680814">prev</a><span>|</span><a href="#41685604">next</a><span>|</span><label class="collapse" for="c-41683232">[-]</label><label class="expand" for="c-41683232">[1 more]</label></div><br/><div class="children"><div class="content">Yes, it should really be called collective intelligence not artificial intelligence</div><br/></div></div></div></div><div id="41685604" class="c"><input type="checkbox" id="c-41685604" checked=""/><div class="controls bullet"><span class="by">tiku</span><span>|</span><a href="#41680437">prev</a><span>|</span><a href="#41681412">next</a><span>|</span><label class="collapse" for="c-41685604">[-]</label><label class="expand" for="c-41685604">[1 more]</label></div><br/><div class="children"><div class="content">I was watching the video of someone using openai voice chat, asking for a joke. Then I&#x27;ve tried it myself, asking for a joke and I got the exact same one. (Why don&#x27;t skeletons fight eachother?).<p>Seems like if then else haha.</div><br/></div></div><div id="41681412" class="c"><input type="checkbox" id="c-41681412" checked=""/><div class="controls bullet"><span class="by">yawnxyz</span><span>|</span><a href="#41685604">prev</a><span>|</span><a href="#41681010">next</a><span>|</span><label class="collapse" for="c-41681412">[-]</label><label class="expand" for="c-41681412">[3 more]</label></div><br/><div class="children"><div class="content">&quot;raw dogging&quot; non-RLHF&#x27;d language models (and getting good and unique output) is going to be a rare and sought-after skill soon. It&#x27;s going to be a new art form<p>someone should write a story about that!</div><br/><div id="41683813" class="c"><input type="checkbox" id="c-41683813" checked=""/><div class="controls bullet"><span class="by">zmgsabst</span><span>|</span><a href="#41681412">parent</a><span>|</span><a href="#41681010">next</a><span>|</span><label class="collapse" for="c-41683813">[-]</label><label class="expand" for="c-41683813">[2 more]</label></div><br/><div class="children"><div class="content">I’m personally waiting on AI psychology to take off.<p>Eg, why does ChatGPT like the concept of harmony so much and use it as a principle for its political analysis?</div><br/><div id="41683868" class="c"><input type="checkbox" id="c-41683868" checked=""/><div class="controls bullet"><span class="by">yawnxyz</span><span>|</span><a href="#41681412">root</a><span>|</span><a href="#41683813">parent</a><span>|</span><a href="#41681010">next</a><span>|</span><label class="collapse" for="c-41683868">[-]</label><label class="expand" for="c-41683868">[1 more]</label></div><br/><div class="children"><div class="content">I thought it&#x27;s b&#x2F;c of RLHF?<p>I think the earliest GPT-3 wasn&#x27;t too keen on harmony, but I might be mis-remembering</div><br/></div></div></div></div></div></div><div id="41681010" class="c"><input type="checkbox" id="c-41681010" checked=""/><div class="controls bullet"><span class="by">SamGyamfi</span><span>|</span><a href="#41681412">prev</a><span>|</span><a href="#41681632">next</a><span>|</span><label class="collapse" for="c-41681010">[-]</label><label class="expand" for="c-41681010">[1 more]</label></div><br/><div class="children"><div class="content">There is a cost-quality tradeoff companies are willing to make for AI model training using synthetic data. It shows up fairly often with AI research labs and their papers. There are also upcoming tools that remove the noise that would trip up some advanced models during annotation. Knowing this, I don&#x27;t think the &quot;human-labeled data is better&quot; argument will last that long.</div><br/></div></div><div id="41681632" class="c"><input type="checkbox" id="c-41681632" checked=""/><div class="controls bullet"><span class="by">theptip</span><span>|</span><a href="#41681010">prev</a><span>|</span><a href="#41684034">next</a><span>|</span><label class="collapse" for="c-41681632">[-]</label><label class="expand" for="c-41681632">[5 more]</label></div><br/><div class="children"><div class="content">I feel this is one of the major ways that most pundits failed with their “the data is going to run out” predictions.<p>First and foremost a chatbot generates plenty of new data (plus feedback!), but you can also commission new high-quality content.<p>Karpathy recently commented that GPT-3 needs so many parameters because most of the training set is garbage, and that he expects eventually a GPT-2 sized model could reach GPT-3 level, if trained exclusively on high-quality textbooks.<p>This is one of the ways you get textbooks to push the frontier capabilities.</div><br/><div id="41683558" class="c"><input type="checkbox" id="c-41683558" checked=""/><div class="controls bullet"><span class="by">llm_trw</span><span>|</span><a href="#41681632">parent</a><span>|</span><a href="#41682073">next</a><span>|</span><label class="collapse" for="c-41683558">[-]</label><label class="expand" for="c-41683558">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve not done pre-training for LLMs, but years ago I generated a completely synthetic dataset for table recognition using an off the shelf document segmentation model, raw TeX, a random table generator, a discriminator and an evolutionary algorithm to generate different styles of tables.<p>The project got killed due to management but I still got results on that dataset better than state of the art in 2023 with no human annotation.<p>The Venn diagram of people who know TeX well enough to write a modular script for table generation with metadata and people who know how to train LLMs has an intersection of a dozen people I imagine.</div><br/><div id="41685573" class="c"><input type="checkbox" id="c-41685573" checked=""/><div class="controls bullet"><span class="by">theptip</span><span>|</span><a href="#41681632">root</a><span>|</span><a href="#41683558">parent</a><span>|</span><a href="#41682073">next</a><span>|</span><label class="collapse" for="c-41685573">[-]</label><label class="expand" for="c-41685573">[1 more]</label></div><br/><div class="children"><div class="content">This is a great example. Areas where an expert can write a synthetic data generator (eg code, physics simulators, etc) are the dream scenario here.<p>It seems to me there is a huge amount of unharvested low-hanging fruit here, for example IIUC GPT is not trained on synthetic code in languages other than Python (and maybe JS, I don’t recall).</div><br/></div></div></div></div><div id="41682073" class="c"><input type="checkbox" id="c-41682073" checked=""/><div class="controls bullet"><span class="by">from-nibly</span><span>|</span><a href="#41681632">parent</a><span>|</span><a href="#41683558">prev</a><span>|</span><a href="#41684034">next</a><span>|</span><label class="collapse" for="c-41682073">[-]</label><label class="expand" for="c-41682073">[2 more]</label></div><br/><div class="children"><div class="content">At a good cost though? Last time I checked generating good data costs a tiny bit more than an http request to somebody elses website.</div><br/><div id="41685550" class="c"><input type="checkbox" id="c-41685550" checked=""/><div class="controls bullet"><span class="by">theptip</span><span>|</span><a href="#41681632">root</a><span>|</span><a href="#41682073">parent</a><span>|</span><a href="#41684034">next</a><span>|</span><label class="collapse" for="c-41685550">[-]</label><label class="expand" for="c-41685550">[1 more]</label></div><br/><div class="children"><div class="content">If the cost is not “good enough”, why are the big guys buying a lot of it?</div><br/></div></div></div></div></div></div><div id="41684034" class="c"><input type="checkbox" id="c-41684034" checked=""/><div class="controls bullet"><span class="by">jwrallie</span><span>|</span><a href="#41681632">prev</a><span>|</span><a href="#41680231">next</a><span>|</span><label class="collapse" for="c-41684034">[-]</label><label class="expand" for="c-41684034">[2 more]</label></div><br/><div class="children"><div class="content">I wonder how much prompt skill is actually influencing the quality of the response.<p>After using LLMs daily for some time, I have developed a feeling on how to phrase my requests as to get better quality answers.<p>For example, ensure that it can process the information  linearly, like asking to classify items in a list and adding the label directly after the item so that the order remains, instead of allowing it to create multiple lists as the output (which it tends to do by default).<p>So, at least for me, the prompts are getting smarter.</div><br/><div id="41684140" class="c"><input type="checkbox" id="c-41684140" checked=""/><div class="controls bullet"><span class="by">layer8</span><span>|</span><a href="#41684034">parent</a><span>|</span><a href="#41680231">next</a><span>|</span><label class="collapse" for="c-41684140">[-]</label><label class="expand" for="c-41684140">[1 more]</label></div><br/><div class="children"><div class="content">Smarter, but also more tedious. It would be great to have technology that automates this tedious work. ;)</div><br/></div></div></div></div><div id="41680231" class="c"><input type="checkbox" id="c-41680231" checked=""/><div class="controls bullet"><span class="by">GaggiX</span><span>|</span><a href="#41684034">prev</a><span>|</span><a href="#41680353">next</a><span>|</span><label class="collapse" for="c-41680231">[-]</label><label class="expand" for="c-41680231">[5 more]</label></div><br/><div class="children"><div class="content">Let&#x27;s not ignore better architectures, training techniques and computing power.</div><br/><div id="41680882" class="c"><input type="checkbox" id="c-41680882" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#41680231">parent</a><span>|</span><a href="#41680344">next</a><span>|</span><label class="collapse" for="c-41680882">[-]</label><label class="expand" for="c-41680882">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s both. I recently saw a comparison of various models on two IQ tests, one of which was public and the other of which was carefully curated to be not directly learnable from the likely training sets.<p>On public tests, LLMs vary between &quot;just below average human&quot; and &quot;genius&quot;.<p>On the hopefully-private test (it&#x27;s difficult to be sure*), the best was o1, which was &quot;merely&quot; just below an average human, Claude-3 Opus which was stupid, and all the rest were &quot;would need a full time caretaker&quot;.<p>In both cases, the improvements to the models came with higher scores; but there&#x27;s still a lot you can do by learning for the test — and one thing that LLMs are definitely superhuman at is that.<p><a href="https:&#x2F;&#x2F;www.maximumtruth.org&#x2F;p&#x2F;massive-breakthrough-in-ai-intelligence" rel="nofollow">https:&#x2F;&#x2F;www.maximumtruth.org&#x2F;p&#x2F;massive-breakthrough-in-ai-in...</a><p>* I could have said the same last year about last year&#x27;s models, so I&#x27;m emphatically <i>not</i> saying o1 really is as smart as this test claims; I&#x27;m <i>only</i> saying this demonstrates these IQ tests are a learnable skill up to at least this magnitude of difference.</div><br/></div></div><div id="41680344" class="c"><input type="checkbox" id="c-41680344" checked=""/><div class="controls bullet"><span class="by">kaycebasques</span><span>|</span><a href="#41680231">parent</a><span>|</span><a href="#41680882">prev</a><span>|</span><a href="#41680532">next</a><span>|</span><label class="collapse" for="c-41680344">[-]</label><label class="expand" for="c-41680344">[2 more]</label></div><br/><div class="children"><div class="content">Suppose you are competing to create the &quot;best&quot; frontier model and have finite R&amp;D budget to allocate into the 4 buckets (plus a catchall in case we&#x27;re missing something):<p>* Data<p>* Architecture<p>* Training techniques<p>* Compute<p>* Other<p>What allocation gives you the best chance for success? And how are you defining &quot;best&quot;?</div><br/><div id="41680620" class="c"><input type="checkbox" id="c-41680620" checked=""/><div class="controls bullet"><span class="by">NitpickLawyer</span><span>|</span><a href="#41680231">root</a><span>|</span><a href="#41680344">parent</a><span>|</span><a href="#41680532">next</a><span>|</span><label class="collapse" for="c-41680620">[-]</label><label class="expand" for="c-41680620">[1 more]</label></div><br/><div class="children"><div class="content">Right now I&#x27;d prioritise compute over anything, because it allows for more experiments, and some of those experiments might turn out to be the key to better models (either specific applications or overall generalist models).<p>Meta did this with L3. They used L2 to pre-filter the training data, filtering out a lot of junk. They also used it to classify datasets. Then after pre-training (involving lots of compute) they also used almost exclusively synthetic data for fine-tuning (forgoing RLHF when it was surpassed). So yet more compute. The results are pretty good, L3, 3.1 and 3.2 are pretty high up there in terms of open access SotA.<p>oAI did this with their o1 models. They used lots of compute to have the models go over the space of generating tokens, analysing, correcting, and so on. They RLd the &quot;reasoning traces&quot; in a way. Lots of compute. The results seem to be pretty good, with impressive showings on &quot;reasoning&quot; tasks, math, code, and so on.<p>The thing is, they weren&#x27;t the first ones to propose these techniques! What differentiates them is the available compute.<p>WizardML tried and were really successful with their RLAIF implementation (tho never released code afaik) about a year ago. And while they were connected to MS research, they probably didn&#x27;t have as much compute available as Meta. But the WizardML fine-tunes on open models like Mistral and Mixtral were pretty much SotA when released, scoring way higher than the creator&#x27;s own fine-tunes.<p>In the same vein, but at lower scales is the team behind DeepSeek. They used RL on math problems, in their DeepSeekMath-7bRL model, and that model was SotA at the time of release as well. It took a team of multiple really talented folks to fine-tune a better model (in the AIMO kaggle competition) and everyone except the 1st place used the RL model. The 1st place used the base model, with different fine-tuning. So again, the methods were tried, just at much lower scales.<p>Yeah, I think compute would be my bet in the short run.</div><br/></div></div></div></div><div id="41680532" class="c"><input type="checkbox" id="c-41680532" checked=""/><div class="controls bullet"><span class="by">JCharante</span><span>|</span><a href="#41680231">parent</a><span>|</span><a href="#41680344">prev</a><span>|</span><a href="#41680353">next</a><span>|</span><label class="collapse" for="c-41680532">[-]</label><label class="expand" for="c-41680532">[1 more]</label></div><br/><div class="children"><div class="content">using human feedback for reinforcement learning is a training technique</div><br/></div></div></div></div><div id="41680353" class="c"><input type="checkbox" id="c-41680353" checked=""/><div class="controls bullet"><span class="by">CamperBob2</span><span>|</span><a href="#41680231">prev</a><span>|</span><a href="#41683327">next</a><span>|</span><label class="collapse" for="c-41680353">[-]</label><label class="expand" for="c-41680353">[7 more]</label></div><br/><div class="children"><div class="content">Which is fine.  If all AI does is represent human knowledge in a way that makes it explainable and transformable rather than merely searchable, then the hype is justified... along with Google&#x27;s howling, terrified panic.<p>The role played by humans on the training side is of little interest when considering the technology from a user&#x27;s perspective.</div><br/><div id="41681046" class="c"><input type="checkbox" id="c-41681046" checked=""/><div class="controls bullet"><span class="by">jumping_frog</span><span>|</span><a href="#41680353">parent</a><span>|</span><a href="#41680371">next</a><span>|</span><label class="collapse" for="c-41681046">[-]</label><label class="expand" for="c-41681046">[1 more]</label></div><br/><div class="children"><div class="content">The problem is my back and forth with Claude is just Claude&#x27;s data not available to any other. Unlike stack overflow which is fair game for every AI.</div><br/></div></div><div id="41680371" class="c"><input type="checkbox" id="c-41680371" checked=""/><div class="controls bullet"><span class="by">iwontberude</span><span>|</span><a href="#41680353">parent</a><span>|</span><a href="#41681046">prev</a><span>|</span><a href="#41683327">next</a><span>|</span><label class="collapse" for="c-41680371">[-]</label><label class="expand" for="c-41680371">[5 more]</label></div><br/><div class="children"><div class="content">I think the most interesting aspect of it is the human training. Human blindsides, dogma, ignorance, etc. All on demand and faster than you can validate its accuracy or utility. This is good.</div><br/><div id="41680390" class="c"><input type="checkbox" id="c-41680390" checked=""/><div class="controls bullet"><span class="by">CamperBob2</span><span>|</span><a href="#41680353">root</a><span>|</span><a href="#41680371">parent</a><span>|</span><a href="#41683327">next</a><span>|</span><label class="collapse" for="c-41680390">[-]</label><label class="expand" for="c-41680390">[4 more]</label></div><br/><div class="children"><div class="content">Shrug... I don&#x27;t know what anyone expected, once humans got involved.  Like all of us (and all of our tools), AI is vulnerable to human flaws.</div><br/><div id="41680445" class="c"><input type="checkbox" id="c-41680445" checked=""/><div class="controls bullet"><span class="by">ddulaney</span><span>|</span><a href="#41680353">root</a><span>|</span><a href="#41680390">parent</a><span>|</span><a href="#41683327">next</a><span>|</span><label class="collapse" for="c-41680445">[-]</label><label class="expand" for="c-41680445">[3 more]</label></div><br/><div class="children"><div class="content">I think that’s really important to reinforce! You probably know better, but lots of the less technical people I talk to don’t think that way. It’s not at all obvious to an observer who doesn’t know how this stuff works that a computer could be racist or misogynist.</div><br/><div id="41680789" class="c"><input type="checkbox" id="c-41680789" checked=""/><div class="controls bullet"><span class="by">CamperBob2</span><span>|</span><a href="#41680353">root</a><span>|</span><a href="#41680445">parent</a><span>|</span><a href="#41683327">next</a><span>|</span><label class="collapse" for="c-41680789">[-]</label><label class="expand" for="c-41680789">[2 more]</label></div><br/><div class="children"><div class="content">Yeah, I do think that&#x27;s going to be a problem.<p>Years ago, my GF asked me why we bother with judges and juries, given all the uneven sentencing practices and other issues with the current legal system.  &quot;Why can&#x27;t the courts run on computers?&quot;  This was back in the pre-Alpha Go era, so when I answered her, I focused on technical reasons why Computers Can&#x27;t Do That... reasons that are all basically obsolete now, or soon will be.<p>The real answer lies in the original premise of her question: because Humans Also Can&#x27;t Do That with the degree of accuracy and accountability that she was asking for.  Our laws simply aren&#x27;t compatible with perfect mechanized jurisprudence and enforcement.  Code may be law, but law isn&#x27;t code.<p>That problem exists in a lot of areas where people will be looking to AI to save us from our own faults.  Again, this has little to do with how training is conducted, or how humans participate in it.  Just getting the racism and misogyny out of the training data isn&#x27;t going to be enough.</div><br/><div id="41683412" class="c"><input type="checkbox" id="c-41683412" checked=""/><div class="controls bullet"><span class="by">Terr_</span><span>|</span><a href="#41680353">root</a><span>|</span><a href="#41680789">parent</a><span>|</span><a href="#41683327">next</a><span>|</span><label class="collapse" for="c-41683412">[-]</label><label class="expand" for="c-41683412">[1 more]</label></div><br/><div class="children"><div class="content">Also: It&#x27;s not just about what task can&#x2F;can&#x27;t can&#x27;t be done, but what other frameworks you&#x2F;can&#x27;t build around the executor to detect errors and handle exceptional cases.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="41683327" class="c"><input type="checkbox" id="c-41683327" checked=""/><div class="controls bullet"><span class="by">bdjsiqoocwk</span><span>|</span><a href="#41680353">prev</a><span>|</span><a href="#41683415">next</a><span>|</span><label class="collapse" for="c-41683327">[-]</label><label class="expand" for="c-41683327">[1 more]</label></div><br/><div class="children"><div class="content">Submarine article placed by Cohere. Wtf is cohere.</div><br/></div></div><div id="41683415" class="c"><input type="checkbox" id="c-41683415" checked=""/><div class="controls bullet"><span class="by">wlindley</span><span>|</span><a href="#41683327">prev</a><span>|</span><a href="#41680481">next</a><span>|</span><label class="collapse" for="c-41683415">[-]</label><label class="expand" for="c-41683415">[1 more]</label></div><br/><div class="children"><div class="content">a&#x2F;k&#x2F;a It is all a clever scam.  True, or true?</div><br/></div></div><div id="41680481" class="c"><input type="checkbox" id="c-41680481" checked=""/><div class="controls bullet"><span class="by">ysofunny</span><span>|</span><a href="#41683415">prev</a><span>|</span><label class="collapse" for="c-41680481">[-]</label><label class="expand" for="c-41680481">[23 more]</label></div><br/><div class="children"><div class="content">I feel weird being stubborn against free tier google gemini<p>I feel as though it &#x27;extracts&#x27; some sort of &quot;smartness&quot; out of me (if any) and then whatever intelligence from me becomes part of google gemini<p>this is why I would never want to pay for using these tools, anything good that comes from me in the chat becomes google&#x27;s by AI training, which is ok so long as it&#x27;s free to use<p>i.e. I won&#x27;t pay to make their stuff better through my own work</div><br/><div id="41681075" class="c"><input type="checkbox" id="c-41681075" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#41680481">parent</a><span>|</span><a href="#41680597">next</a><span>|</span><label class="collapse" for="c-41681075">[-]</label><label class="expand" for="c-41681075">[13 more]</label></div><br/><div class="children"><div class="content">Several LLM providers have solid promises that they won&#x27;t train on your inputs to them. OpenAI have this if you are using their paid API (though frustratingly not for their paid ChatGPT users, at least to my knowledge), and Anthropic have that for input to their free apps as well: <a href="https:&#x2F;&#x2F;support.anthropic.com&#x2F;en&#x2F;articles&#x2F;7996885-how-do-you-use-personal-data-in-model-training#h_5f5f5f9b0b" rel="nofollow">https:&#x2F;&#x2F;support.anthropic.com&#x2F;en&#x2F;articles&#x2F;7996885-how-do-you...</a><p>I was hoping I could say the same for Gemini, but unfortunately their policy at <a href="https:&#x2F;&#x2F;support.google.com&#x2F;gemini&#x2F;answer&#x2F;13594961?visit_id=638631360245451590-850445512&amp;p=privacy_help&amp;rd=1#what_data" rel="nofollow">https:&#x2F;&#x2F;support.google.com&#x2F;gemini&#x2F;answer&#x2F;13594961?visit_id=6...</a> says &quot;Google uses this data, consistent with our Privacy Policy, to provide, improve, and develop Google products and services and machine-learning technologies&quot;<p>My intuition is that Google don&#x27;t directly train on user conversations (because user conversations are full of both junk and sensitive information that no model would want to train on), but I can&#x27;t state that with any credibility.</div><br/><div id="41681223" class="c"><input type="checkbox" id="c-41681223" checked=""/><div class="controls bullet"><span class="by">fhdsgbbcaA</span><span>|</span><a href="#41680481">root</a><span>|</span><a href="#41681075">parent</a><span>|</span><a href="#41685831">next</a><span>|</span><label class="collapse" for="c-41681223">[-]</label><label class="expand" for="c-41681223">[1 more]</label></div><br/><div class="children"><div class="content">I’m sure there’s absolutely zero chance that Sam Altman would lie about that, especially now that he’s gutted all oversight and senior-level opposition.</div><br/></div></div><div id="41685831" class="c"><input type="checkbox" id="c-41685831" checked=""/><div class="controls bullet"><span class="by">immibis</span><span>|</span><a href="#41680481">root</a><span>|</span><a href="#41681075">parent</a><span>|</span><a href="#41681223">prev</a><span>|</span><a href="#41681232">next</a><span>|</span><label class="collapse" for="c-41685831">[-]</label><label class="expand" for="c-41685831">[1 more]</label></div><br/><div class="children"><div class="content">OpenAI also promised to remain open forever.</div><br/></div></div><div id="41681232" class="c"><input type="checkbox" id="c-41681232" checked=""/><div class="controls bullet"><span class="by">light_hue_1</span><span>|</span><a href="#41680481">root</a><span>|</span><a href="#41681075">parent</a><span>|</span><a href="#41685831">prev</a><span>|</span><a href="#41680597">next</a><span>|</span><label class="collapse" for="c-41681232">[-]</label><label class="expand" for="c-41681232">[10 more]</label></div><br/><div class="children"><div class="content">Ah yes. Solid promises you can never verify. That companies would benefit massively from violating.<p>That&#x27;s worth literally nothing.</div><br/><div id="41681331" class="c"><input type="checkbox" id="c-41681331" checked=""/><div class="controls bullet"><span class="by">Workaccount2</span><span>|</span><a href="#41680481">root</a><span>|</span><a href="#41681232">parent</a><span>|</span><a href="#41681301">next</a><span>|</span><label class="collapse" for="c-41681331">[-]</label><label class="expand" for="c-41681331">[6 more]</label></div><br/><div class="children"><div class="content">I know this sounds heretical, but companies generally do not go against what they say they are doing. They might use clever language or do slimey things, but it&#x27;s very rare that they will say &quot;We do not do xyz&quot; while they are in fact doing xyz. Especially for big companies.<p>Reputation has far more value than whatever they gain by lying. Besides, they can just say &quot;We do xyz&quot; because &lt;1% of users read the TOS and less than &lt;0.1% care enough to not use the service.</div><br/><div id="41683437" class="c"><input type="checkbox" id="c-41683437" checked=""/><div class="controls bullet"><span class="by">blooalien</span><span>|</span><a href="#41680481">root</a><span>|</span><a href="#41681331">parent</a><span>|</span><a href="#41681423">next</a><span>|</span><label class="collapse" for="c-41683437">[-]</label><label class="expand" for="c-41683437">[3 more]</label></div><br/><div class="children"><div class="content">&gt; Google: &quot;Don&#x27;t Be Evil&quot; is our motto!<p>&gt; Also Google: &quot;Let&#x27;s do <i>all</i> the evil things...&quot; ~ heavily &quot;paraphrased&quot; ;)<p>My &quot;tongue-in-cheek point&quot; is that it seems like corporations beyond a certain point of &quot;filthy-richness&quot; just do as they please, and say what they please, and mostly neither thing has to agree with the other, nor does either one need affect their profits &quot;bottom line&quot; all that seriously much.  Most of your typical &quot;mega-corps&quot; are really only able to be affected much by the laws and legal system, which they&#x27;ve been increasingly &quot;capturing&quot; in various ways so that happens very rarely anymore these days, and when it does it&#x27;s most often a &quot;slap on the wrist&quot; and &quot;don&#x27;t do that!&quot; sorta thing, followed by more business-as-usual.<p>You know the old worry about the &quot;paperclip production maximizer AI&quot; eating everything to create paperclips?  That&#x27;s kinda where we&#x27;re pretty-much <i>already</i> at with mega-corps.  They&#x27;re so utterly laser-focused on maximizing to extract every last dime of profit out of <i>everything</i> that they&#x27;re gonna end up literally consuming all matter in the universe if they don&#x27;t just destroy us all in the process of trying to get there.</div><br/><div id="41683702" class="c"><input type="checkbox" id="c-41683702" checked=""/><div class="controls bullet"><span class="by">ahazred8ta</span><span>|</span><a href="#41680481">root</a><span>|</span><a href="#41683437">parent</a><span>|</span><a href="#41683610">next</a><span>|</span><label class="collapse" for="c-41683702">[-]</label><label class="expand" for="c-41683702">[1 more]</label></div><br/><div class="children"><div class="content"><i>It looks like you&#x27;re trying to maximize paperclips. Would you like help?</i><p><a href="https:&#x2F;&#x2F;www.decisionproblem.com&#x2F;paperclips&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.decisionproblem.com&#x2F;paperclips&#x2F;</a> #-the-game</div><br/></div></div><div id="41683610" class="c"><input type="checkbox" id="c-41683610" checked=""/><div class="controls bullet"><span class="by">Workaccount2</span><span>|</span><a href="#41680481">root</a><span>|</span><a href="#41683437">parent</a><span>|</span><a href="#41683702">prev</a><span>|</span><a href="#41681423">next</a><span>|</span><label class="collapse" for="c-41683610">[-]</label><label class="expand" for="c-41683610">[1 more]</label></div><br/><div class="children"><div class="content">I mean from a non-subjective legal TOS perspective.<p>I&#x27;m not arguing that the grocery store saying &quot;fresh produce&quot; guarantees that the produce is fresh. Fresh, like evil, is subjective.<p>I&#x27;m saying that if the grocery puts &quot;All our produce is no older than 10 days&quot; you can be pretty sure they adhere to that and train employees to follow it. &quot;10 days&quot; is not subjective.</div><br/></div></div></div></div><div id="41681423" class="c"><input type="checkbox" id="c-41681423" checked=""/><div class="controls bullet"><span class="by">pton_xd</span><span>|</span><a href="#41680481">root</a><span>|</span><a href="#41681331">parent</a><span>|</span><a href="#41683437">prev</a><span>|</span><a href="#41681301">next</a><span>|</span><label class="collapse" for="c-41681423">[-]</label><label class="expand" for="c-41681423">[2 more]</label></div><br/><div class="children"><div class="content">This is supremely naive, in my opinion.<p>Big companies not only lie, some of them do so routinely, including breaking the law. Look at the banking industry: Wells Fargo fraudulent &#x2F; fake account scandal, JPMorgan Chase UST and precious metals future fraud. Standard Charter bank caught money laundering for Iran, twice. Deutsche Bank caught laundering for Russia, twice. UBS laundering and tax evasion. Credit Suisse caught laundering for Iran. And so on.<p>Really it comes down to what a company believes it can get away with, and what the consequences will be. If there are minimal consequences they&#x27;d be dumb not to try.<p>Oh I just remembered a funny one: remember when it came out that Uber employees were using &quot;God view&quot; to spy on ex-partners, etc? For years. Yeah I&#x27;m pretty sure the TOS didn&#x27;t have a section &quot;Our employees may, from time to time, spy on you at their discretion.&quot; Actually the opposite, Uber explicitly said they couldn&#x27;t access ride information for its users.</div><br/><div id="41681617" class="c"><input type="checkbox" id="c-41681617" checked=""/><div class="controls bullet"><span class="by">startupsfail</span><span>|</span><a href="#41680481">root</a><span>|</span><a href="#41681423">parent</a><span>|</span><a href="#41681301">next</a><span>|</span><label class="collapse" for="c-41681617">[-]</label><label class="expand" for="c-41681617">[1 more]</label></div><br/><div class="children"><div class="content">The company can certainly make a calculated risk of going against their TOS and their promise to the customers at the cost of potential risk of their reputation.<p>Note that such reputation risks are external and internal. The reputation reflects on the executive team and there is a risk that the executive team members may leave or attempt to get the unscrupulous employee fired.</div><br/></div></div></div></div></div></div><div id="41681301" class="c"><input type="checkbox" id="c-41681301" checked=""/><div class="controls bullet"><span class="by">choilive</span><span>|</span><a href="#41680481">root</a><span>|</span><a href="#41681232">parent</a><span>|</span><a href="#41681331">prev</a><span>|</span><a href="#41680597">next</a><span>|</span><label class="collapse" for="c-41681301">[-]</label><label class="expand" for="c-41681301">[3 more]</label></div><br/><div class="children"><div class="content">It would also destroy these companies if they were ever caught lying.</div><br/><div id="41681663" class="c"><input type="checkbox" id="c-41681663" checked=""/><div class="controls bullet"><span class="by">atq2119</span><span>|</span><a href="#41680481">root</a><span>|</span><a href="#41681301">parent</a><span>|</span><a href="#41681937">next</a><span>|</span><label class="collapse" for="c-41681663">[-]</label><label class="expand" for="c-41681663">[1 more]</label></div><br/><div class="children"><div class="content">That seems awfully optimistic, given what Sam Altman is getting away with transforming the governing structure of OpenAI.</div><br/></div></div><div id="41681937" class="c"><input type="checkbox" id="c-41681937" checked=""/><div class="controls bullet"><span class="by">jart</span><span>|</span><a href="#41680481">root</a><span>|</span><a href="#41681301">parent</a><span>|</span><a href="#41681663">prev</a><span>|</span><a href="#41680597">next</a><span>|</span><label class="collapse" for="c-41681937">[-]</label><label class="expand" for="c-41681937">[1 more]</label></div><br/><div class="children"><div class="content">Not if the government required them to do it.</div><br/></div></div></div></div></div></div></div></div><div id="41680626" class="c"><input type="checkbox" id="c-41680626" checked=""/><div class="controls bullet"><span class="by">buzzerbetrayed</span><span>|</span><a href="#41680481">parent</a><span>|</span><a href="#41680597">prev</a><span>|</span><a href="#41681396">next</a><span>|</span><label class="collapse" for="c-41680626">[-]</label><label class="expand" for="c-41680626">[7 more]</label></div><br/><div class="children"><div class="content">I totally sympathize with the sentiment. But how long until people who are taking a moral stand against AI are simply obsoleted by the people who don’t? Today it’s easy to code effectively without relying on AI. But in 10 years will you simply be too slow? Same argument can be made with nearly any industry.</div><br/><div id="41680878" class="c"><input type="checkbox" id="c-41680878" checked=""/><div class="controls bullet"><span class="by">croes</span><span>|</span><a href="#41680481">root</a><span>|</span><a href="#41680626">parent</a><span>|</span><a href="#41680779">next</a><span>|</span><label class="collapse" for="c-41680878">[-]</label><label class="expand" for="c-41680878">[5 more]</label></div><br/><div class="children"><div class="content">That&#x27;s same logic as for frameworks like react.<p>With react you are more productive, my web experience is worse than without a those frameworks.<p>And LLMs get worse if they are trained on AI generated text.
At the current speed I don&#x27;t know if in 10 years AI is still worse the high costs.</div><br/><div id="41681022" class="c"><input type="checkbox" id="c-41681022" checked=""/><div class="controls bullet"><span class="by">joshstrange</span><span>|</span><a href="#41680481">root</a><span>|</span><a href="#41680878">parent</a><span>|</span><a href="#41680779">next</a><span>|</span><label class="collapse" for="c-41681022">[-]</label><label class="expand" for="c-41681022">[4 more]</label></div><br/><div class="children"><div class="content">&gt; With react you are more productive, my web experience is worse than without a those frameworks.<p>You cannot begin to know that for sure and really makes little to no sense if you think about it.<p>As with the anti-electron crowd the options are not:<p>* Electron app<p>or<p>* Bespoke, hand-crafted, made with love, native app<p>The options are normally “electron app” or “nothing”.<p>Same deal here. Taking away React&#x2F;Angular&#x2F;Vue won’t magically make people write more performant websites. I’m sure people bitched about (and continue to) PHP for making it easy for people to create websites that aren’t performant or Wordpress for all its flaws. It’s the same story that’s repeated over and over in tech circles and I find it both silly and incredibly short-sighted. Actually I find it tiring because you can always go one level deeper to one-up these absurd statements. It’s No True Scotsman all the way down.</div><br/><div id="41681337" class="c"><input type="checkbox" id="c-41681337" checked=""/><div class="controls bullet"><span class="by">emptiestplace</span><span>|</span><a href="#41680481">root</a><span>|</span><a href="#41681022">parent</a><span>|</span><a href="#41683126">next</a><span>|</span><label class="collapse" for="c-41681337">[-]</label><label class="expand" for="c-41681337">[1 more]</label></div><br/><div class="children"><div class="content">I feel like I (probably?) agree with what you are saying, but this is a very confusing comment. You started out with an epistemological argument, and then jumped into an analogy that&#x27;s so close to what is being discussed that on first read I thought you were just confused. I&#x27;m not sure anyone can continue the discussion in a meaningful way from what you&#x27;ve written because so many aspects of your comment are ambiguous or contradictory.</div><br/></div></div><div id="41683126" class="c"><input type="checkbox" id="c-41683126" checked=""/><div class="controls bullet"><span class="by">smileson2</span><span>|</span><a href="#41680481">root</a><span>|</span><a href="#41681022">parent</a><span>|</span><a href="#41681337">prev</a><span>|</span><a href="#41681528">next</a><span>|</span><label class="collapse" for="c-41683126">[-]</label><label class="expand" for="c-41683126">[1 more]</label></div><br/><div class="children"><div class="content">I hate this analogy, even things from the rad days like vb were better than electron</div><br/></div></div><div id="41681528" class="c"><input type="checkbox" id="c-41681528" checked=""/><div class="controls bullet"><span class="by">croes</span><span>|</span><a href="#41680481">root</a><span>|</span><a href="#41681022">parent</a><span>|</span><a href="#41683126">prev</a><span>|</span><a href="#41680779">next</a><span>|</span><label class="collapse" for="c-41681528">[-]</label><label class="expand" for="c-41681528">[1 more]</label></div><br/><div class="children"><div class="content">I mean retrospectively.<p>In the time before all those framework like react the UX was better for me than now.<p>Less flashy, animated but faster.</div><br/></div></div></div></div></div></div><div id="41680779" class="c"><input type="checkbox" id="c-41680779" checked=""/><div class="controls bullet"><span class="by">pixl97</span><span>|</span><a href="#41680481">root</a><span>|</span><a href="#41680626">parent</a><span>|</span><a href="#41680878">prev</a><span>|</span><a href="#41681396">next</a><span>|</span><label class="collapse" for="c-41680779">[-]</label><label class="expand" for="c-41680779">[1 more]</label></div><br/><div class="children"><div class="content">Pretty much like the people that don&#x27;t care about privacy. You still get captured and tagged in their information and uploaded to the web. As an individual it&#x27;s difficult to do much about it.</div><br/></div></div></div></div><div id="41681396" class="c"><input type="checkbox" id="c-41681396" checked=""/><div class="controls bullet"><span class="by">JCharante</span><span>|</span><a href="#41680481">parent</a><span>|</span><a href="#41680626">prev</a><span>|</span><label class="collapse" for="c-41681396">[-]</label><label class="expand" for="c-41681396">[1 more]</label></div><br/><div class="children"><div class="content">tbh your data would be too unstructured, it&#x27;s not really being used to train unless you flag it deliberately with a feedback mechanism</div><br/></div></div></div></div></div></div></div></div></div></body></html>