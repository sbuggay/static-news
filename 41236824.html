<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1723798872370" as="style"/><link rel="stylesheet" href="styles.css?v=1723798872370"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.together.ai/blog/a-practitioners-guide-to-testing-and-running-large-gpu-clusters-for-training-generative-ai-models">A practitioner&#x27;s guide to testing and running GPU clusters</a>Â <span class="domain">(<a href="https://www.together.ai">www.together.ai</a>)</span></div><div class="subtext"><span>nutlope</span> | <span>6 comments</span></div><br/><div><div id="41263451" class="c"><input type="checkbox" id="c-41263451" checked=""/><div class="controls bullet"><span class="by">gdiamos</span><span>|</span><a href="#41263272">next</a><span>|</span><label class="collapse" for="c-41263451">[-]</label><label class="expand" for="c-41263451">[1 more]</label></div><br/><div class="children"><div class="content">Glad to see the use of SLURM<p>The number of times I see people trying to reinvent the HPC wheel astounds me</div><br/></div></div><div id="41263272" class="c"><input type="checkbox" id="c-41263272" checked=""/><div class="controls bullet"><span class="by">The-Toon</span><span>|</span><a href="#41263451">prev</a><span>|</span><a href="#41263257">next</a><span>|</span><label class="collapse" for="c-41263272">[-]</label><label class="expand" for="c-41263272">[3 more]</label></div><br/><div class="children"><div class="content">Sorry to hijack the thread, but how would one get into managing GPU clusters? Modern GPUs are expensive, so it seems difficult to build a homelab to play around with them. Is learning how to run software on a cluster at the end-users level + playing around with VMs enough experience to enter the field?</div><br/><div id="41263736" class="c"><input type="checkbox" id="c-41263736" checked=""/><div class="controls bullet"><span class="by">marcyb5st</span><span>|</span><a href="#41263272">parent</a><span>|</span><a href="#41263875">next</a><span>|</span><label class="collapse" for="c-41263736">[-]</label><label class="expand" for="c-41263736">[1 more]</label></div><br/><div class="children"><div class="content">(Disclaimer, I&#x27;m working for Google)
In my opinion this is a great question. I believe you can go two ways:<p>1) Get your hands on few physical computers and &quot;old&quot; gpus (like nVidia 1000 series or something like that). Put them as part of a K8S cluster and you have an amazing setup to play around with. Try to squeeze as much flops from your hardware as you can. Bonus points if you also architect around failures and test that by pulling off network cables.<p>2) Using some Cloud provider use preemptible&#x2F;spot instances with a bunch of GPUs for few hours at the time. Not sure with other clouds, but with GCP you can create a GKE nodepool that only uses spot instances and in conjuction with cluster autoscaler makes what I described very easy and you don&#x27;t really have to clean much after you&#x27;re done messing around for the day. GPUs like K80, T4, or P4s are relatively cheap and, if you use them for just 10s of hours a month, you can get away with a bill of 10s of dollars [1].<p>Either option works fine (IMHO).<p>Another option I am unsure about because I never tried it is to use something like [2] to multiplex your GPU(s) so that you can pretend you have more GPUs to mess around with. However, if your goal is to learn how to manage&#x2F;write software for multi-gpus&#x2F;multi-machine clusters this is somewhat limiting because 1) it doesn&#x27;t teach you much about data locality&#x2F;compact placement since transfers between virtual GPUs will be extremely fast (i.e. they are sharing the same VRAM pool after all) and 2) you will still have a single machine (even if you are using multiple virtual K8s nodes).<p>[1] 3 instances with 4 GPUs each used for 24h in a month cost you 46$ according to: <a href="https:&#x2F;&#x2F;cloud.google.com&#x2F;products&#x2F;calculator&#x2F;?hl=en&amp;dl=CiRhYjhkZDRkNS02OTU0LTQ1ZWUtODNjYi0zYzU0MDE5ODI2YTkQCBokRUQwQTNEMkMtNDIxNS00M0JBLThBRTYtMjY1RTgzQjkwQzFC" rel="nofollow">https:&#x2F;&#x2F;cloud.google.com&#x2F;products&#x2F;calculator&#x2F;?hl=en&amp;dl=CiRhY...</a><p>[2] <a href="https:&#x2F;&#x2F;github.com&#x2F;NVIDIA&#x2F;k8s-device-plugin">https:&#x2F;&#x2F;github.com&#x2F;NVIDIA&#x2F;k8s-device-plugin</a></div><br/></div></div><div id="41263875" class="c"><input type="checkbox" id="c-41263875" checked=""/><div class="controls bullet"><span class="by">latchkey</span><span>|</span><a href="#41263272">parent</a><span>|</span><a href="#41263736">prev</a><span>|</span><a href="#41263257">next</a><span>|</span><label class="collapse" for="c-41263875">[-]</label><label class="expand" for="c-41263875">[1 more]</label></div><br/><div class="children"><div class="content">There isn&#x27;t really a school for this stuff. The way I learned was to go work for a company that was building out GPU compute.<p>It is a lot more than just software, especially on the high end of things.</div><br/></div></div></div></div><div id="41263257" class="c"><input type="checkbox" id="c-41263257" checked=""/><div class="controls bullet"><span class="by">timzaman</span><span>|</span><a href="#41263272">prev</a><span>|</span><label class="collapse" for="c-41263257">[-]</label><label class="expand" for="c-41263257">[1 more]</label></div><br/><div class="children"><div class="content">decent starter guide for 28 nodes scale. Would be cute to do a follow up around how to do health checks. Eg catching your transceivers from overheating, etc.</div><br/></div></div></div></div></div></div></div></body></html>