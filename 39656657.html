<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1710147663537" as="style"/><link rel="stylesheet" href="styles.css?v=1710147663537"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://calpaterson.com/s3.html">S3 is files, but not a filesystem</a> <span class="domain">(<a href="https://calpaterson.com">calpaterson.com</a>)</span></div><div class="subtext"><span>todsacerdoti</span> | <span>282 comments</span></div><br/><div><div id="39660019" class="c"><input type="checkbox" id="c-39660019" checked=""/><div class="controls bullet"><span class="by">breckognize</span><span>|</span><a href="#39658507">next</a><span>|</span><label class="collapse" for="c-39660019">[-]</label><label class="expand" for="c-39660019">[67 more]</label></div><br/><div class="children"><div class="content">&gt; I haven&#x27;t heard of people having problems [with S3&#x27;s Durability] but equally: I&#x27;ve never seen these claims tested. I am at least a bit curious about these claims.<p>Believe the hype. S3&#x27;s durability is industry leading and traditional file systems don&#x27;t compare. It&#x27;s not just the software - it&#x27;s the physical infrastructure and safety culture.<p>AWS&#x27; availability zone isolation is better than the other cloud providers. When I worked at S3, customers would beat us up over pricing compared to GCP blob storage, but the comparison was unfair because Google would store your data in the same building (or maybe different rooms of the same building) - not with the separation AWS did.<p>The entire organization was unbelievably paranoid about data integrity (checksum all the things) and bigger events like natural disasters. S3 even operates at a scale where we could detect &quot;bitrot&quot; - random bit flips caused by gamma rays hitting a hard drive platter (roughly one per second across trillions of objects iirc). We even measured failure rates by hard drive vendor&#x2F;vintage to minimize the chance of data loss if a batch of disks went bad.<p>I wouldn&#x27;t store critical data anywhere else.<p>Source: I wrote the S3 placement system.</div><br/><div id="39660579" class="c"><input type="checkbox" id="c-39660579" checked=""/><div class="controls bullet"><span class="by">treflop</span><span>|</span><a href="#39660019">parent</a><span>|</span><a href="#39660216">next</a><span>|</span><label class="collapse" for="c-39660579">[-]</label><label class="expand" for="c-39660579">[25 more]</label></div><br/><div class="children"><div class="content">What’s your experience like at other storage outfits?<p>I only ask because your post is a bit like singing praises for Cinnabon that they make their own dough.<p>The things that you mentioned are standard storage company activities.<p>Checksum-all-the-things is a basic feature of a lot of file systems. If you can already set up your home computer to detect bitrot and alert you, you can bet big storage vendors do it.<p>Keeping track of hard drive failure rates by vendor is  normal. Storage companies publicly publish their own reports. The tiny 6-person IT operation I was in had a spreadsheet. Hell, I toured a friend’s friend’s major data center last year and he managed to find time to talk hard drive vendors. Now you. I get it — y’all make spreadsheets.<p>There are a lot of smart people working on storage outside AWS and long before AWS existed.</div><br/><div id="39660953" class="c"><input type="checkbox" id="c-39660953" checked=""/><div class="controls bullet"><span class="by">pclmulqdq</span><span>|</span><a href="#39660019">root</a><span>|</span><a href="#39660579">parent</a><span>|</span><a href="#39663406">next</a><span>|</span><label class="collapse" for="c-39660953">[-]</label><label class="expand" for="c-39660953">[18 more]</label></div><br/><div class="children"><div class="content">When I worked at Google in storage, we had our own figures of merit that showed that we were the best and Amazon&#x27;s durability was trash in comparison to us.<p>As far as I can tell, every cloud provider&#x27;s object store is too durable to actually measure (&quot;14 9&#x27;s&quot;), and it&#x27;s not a problem.</div><br/><div id="39661126" class="c"><input type="checkbox" id="c-39661126" checked=""/><div class="controls bullet"><span class="by">breckognize</span><span>|</span><a href="#39660019">root</a><span>|</span><a href="#39660953">parent</a><span>|</span><a href="#39663406">next</a><span>|</span><label class="collapse" for="c-39661126">[-]</label><label class="expand" for="c-39661126">[17 more]</label></div><br/><div class="children"><div class="content">9&#x27;s are overblown. When cloud providers report that, they&#x27;re really saying &quot;Assuming random hard drive failure at the rates we&#x27;ve historically measured and how we quickly we detect and fix those failures, what&#x27;s the mean time to data loss&quot;.<p>But that&#x27;s burying the lede. By far the greatest risks to a file&#x27;s durability are:
1. Bugs (which aren&#x27;t captured by a durability model). This is mitigated by deploying slowly and having good isolation between regions.
2. An act of God that wipes out a facility.<p>The point of my comment was that it&#x27;s not just about checksums. That&#x27;s table stakes. The main driver of data loss for storage organizations with competent software is safety culture and physical infrastructure.<p>My experience was that S3&#x27;s safety culture is outstanding.  In terms of physical separation and how &quot;solid&quot; the AZs are, AWS is overbuilt compared to the other players.</div><br/><div id="39661545" class="c"><input type="checkbox" id="c-39661545" checked=""/><div class="controls bullet"><span class="by">pclmulqdq</span><span>|</span><a href="#39660019">root</a><span>|</span><a href="#39661126">parent</a><span>|</span><a href="#39662446">next</a><span>|</span><label class="collapse" for="c-39661545">[-]</label><label class="expand" for="c-39661545">[9 more]</label></div><br/><div class="children"><div class="content">That was not how we treated the 9&#x27;s at Google. Those had been tested through natural experiments (disasters).<p>I was not at Google for the Clichy fire, but it wasn&#x27;t the first datacenter fire Google experienced. I think your information about Google&#x27;s data placement may be incorrect, or you may be mapping AWS concepts onto Google internal infrastructure in the wrong way.</div><br/><div id="39662287" class="c"><input type="checkbox" id="c-39662287" checked=""/><div class="controls bullet"><span class="by">breckognize</span><span>|</span><a href="#39660019">root</a><span>|</span><a href="#39661545">parent</a><span>|</span><a href="#39661633">next</a><span>|</span><label class="collapse" for="c-39662287">[-]</label><label class="expand" for="c-39662287">[2 more]</label></div><br/><div class="children"><div class="content">Do you mean Google included  &quot;acts of God&quot; when computing 9&#x27;s? That&#x27;s definitely not right.<p>11 9&#x27;s of durability means mean time to data loss of 100 billion years. Nothing on earth is 11 9&#x27;s durable in the face of natural (or man-made) disasters. The earth is only 4.5 billion years old.</div><br/><div id="39662301" class="c"><input type="checkbox" id="c-39662301" checked=""/><div class="controls bullet"><span class="by">pclmulqdq</span><span>|</span><a href="#39660019">root</a><span>|</span><a href="#39662287">parent</a><span>|</span><a href="#39661633">next</a><span>|</span><label class="collapse" for="c-39662301">[-]</label><label class="expand" for="c-39662301">[1 more]</label></div><br/><div class="children"><div class="content">Normally, companies store more than 1 byte of data, and the 9&#x27;s (not just for data loss, for everything) are ensemble averages.<p>By the way, I don&#x27;t doubt that AWS has plenty of 9&#x27;s by that metric - perhaps more than GCP.</div><br/></div></div></div></div><div id="39661633" class="c"><input type="checkbox" id="c-39661633" checked=""/><div class="controls bullet"><span class="by">fsociety</span><span>|</span><a href="#39660019">root</a><span>|</span><a href="#39661545">parent</a><span>|</span><a href="#39662287">prev</a><span>|</span><a href="#39662446">next</a><span>|</span><label class="collapse" for="c-39661633">[-]</label><label class="expand" for="c-39661633">[6 more]</label></div><br/><div class="children"><div class="content">I would not lose sleep over storing data on GCS, but have heard from several Google Cloud folks that their concept of zones is a mirage at best.</div><br/><div id="39661709" class="c"><input type="checkbox" id="c-39661709" checked=""/><div class="controls bullet"><span class="by">pclmulqdq</span><span>|</span><a href="#39660019">root</a><span>|</span><a href="#39661633">parent</a><span>|</span><a href="#39663509">next</a><span>|</span><label class="collapse" for="c-39661709">[-]</label><label class="expand" for="c-39661709">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, that&#x27;s definitely true. Google sort of mapped an AWS concept onto its own cluster splits. However, there are enough regional-scale outages at all the major clouds that I don&#x27;t personally place much stock in the idea of zones to begin with. The only way to get close to true 24&#x2F;7 five-9&#x27;s uptime with clouds is to be multi-region (and preferably multi-cloud).</div><br/></div></div><div id="39663509" class="c"><input type="checkbox" id="c-39663509" checked=""/><div class="controls bullet"><span class="by">kevincox</span><span>|</span><a href="#39660019">root</a><span>|</span><a href="#39661633">parent</a><span>|</span><a href="#39661709">prev</a><span>|</span><a href="#39665641">next</a><span>|</span><label class="collapse" for="c-39663509">[-]</label><label class="expand" for="c-39663509">[3 more]</label></div><br/><div class="children"><div class="content">I think also Google as a whole has pretty good diversity. But Cloud customers demanded regions in big population centers and smaller countries where Google traditionally avoided due to cost reasons. This lead to less redundant sites that were often owned and&#x2F;or operated by third parties. So in the US and Europe you can probably trust GCP zones quite literally. But other regions (I have heard lots of rumours in the APAC) they may not be quite as diverse as they appear.</div><br/><div id="39663944" class="c"><input type="checkbox" id="c-39663944" checked=""/><div class="controls bullet"><span class="by">throwaway2037</span><span>|</span><a href="#39660019">root</a><span>|</span><a href="#39663509">parent</a><span>|</span><a href="#39665641">next</a><span>|</span><label class="collapse" for="c-39663944">[-]</label><label class="expand" for="c-39663944">[2 more]</label></div><br/><div class="children"><div class="content">&gt; big population centers and smaller countries<p>Can we stop this dance on HN?  Can you just name them, please?</div><br/><div id="39665263" class="c"><input type="checkbox" id="c-39665263" checked=""/><div class="controls bullet"><span class="by">pclmulqdq</span><span>|</span><a href="#39660019">root</a><span>|</span><a href="#39663944">parent</a><span>|</span><a href="#39665641">next</a><span>|</span><label class="collapse" for="c-39665263">[-]</label><label class="expand" for="c-39665263">[1 more]</label></div><br/><div class="children"><div class="content">I think most Googlers actually don&#x27;t know the specifics (I certainly don&#x27;t know), and if they could, they probably couldn&#x27;t tell you. It&#x27;s sort of common knowledge that <i>some</i> of them are like this, but not exactly which ones.</div><br/></div></div></div></div></div></div><div id="39665641" class="c"><input type="checkbox" id="c-39665641" checked=""/><div class="controls bullet"><span class="by">flaminHotSpeedo</span><span>|</span><a href="#39660019">root</a><span>|</span><a href="#39661633">parent</a><span>|</span><a href="#39663509">prev</a><span>|</span><a href="#39662446">next</a><span>|</span><label class="collapse" for="c-39665641">[-]</label><label class="expand" for="c-39665641">[1 more]</label></div><br/><div class="children"><div class="content">See: that fire in France that took down a whole region<p>But on the other hand, GCP supports multi-region so that&#x27;s not nearly as big of a deal as it would be if AWS zones were not sufficiently isolated</div><br/></div></div></div></div></div></div><div id="39662446" class="c"><input type="checkbox" id="c-39662446" checked=""/><div class="controls bullet"><span class="by">jftuga</span><span>|</span><a href="#39660019">root</a><span>|</span><a href="#39661126">parent</a><span>|</span><a href="#39661545">prev</a><span>|</span><a href="#39663406">next</a><span>|</span><label class="collapse" for="c-39662446">[-]</label><label class="expand" for="c-39662446">[7 more]</label></div><br/><div class="children"><div class="content">If I were to upload a 50kb object to S3 (standard tier), about how many unique physical copies would exist?</div><br/><div id="39662985" class="c"><input type="checkbox" id="c-39662985" checked=""/><div class="controls bullet"><span class="by">cyberax</span><span>|</span><a href="#39660019">root</a><span>|</span><a href="#39662446">parent</a><span>|</span><a href="#39663406">next</a><span>|</span><label class="collapse" for="c-39662985">[-]</label><label class="expand" for="c-39662985">[6 more]</label></div><br/><div class="children"><div class="content">At least 3.</div><br/><div id="39663500" class="c"><input type="checkbox" id="c-39663500" checked=""/><div class="controls bullet"><span class="by">bigiain</span><span>|</span><a href="#39660019">root</a><span>|</span><a href="#39662985">parent</a><span>|</span><a href="#39665129">next</a><span>|</span><label class="collapse" for="c-39663500">[-]</label><label class="expand" for="c-39663500">[4 more]</label></div><br/><div class="children"><div class="content">At least 3, in at least 3 seperate datacenters.<p>According to <a href="https:&#x2F;&#x2F;nuclearsecrecy.com&#x2F;nukemap&#x2F;" rel="nofollow">https:&#x2F;&#x2F;nuclearsecrecy.com&#x2F;nukemap&#x2F;</a> - it&#x27;d take at least a 1 megaton warhead to take out two of the ap-southeast-2 datacenters, and over 10MT to take out 3.<p>I suspect you&#x27;d need a lot less than that though, the 1MT warhead would probably take out enough outside-the-datacenter infrastructure to take the entire AZ offline. I don&#x27;t care too much though, if someone&#x27;s dropped a warhead that close to home I have other things to worry about than whether all the cat pictures and audit logs survive.</div><br/><div id="39663660" class="c"><input type="checkbox" id="c-39663660" checked=""/><div class="controls bullet"><span class="by">tomcam</span><span>|</span><a href="#39660019">root</a><span>|</span><a href="#39663500">parent</a><span>|</span><a href="#39665129">next</a><span>|</span><label class="collapse" for="c-39663660">[-]</label><label class="expand" for="c-39663660">[3 more]</label></div><br/><div class="children"><div class="content">&gt; if someone&#x27;s dropped a warhead that close to home I have other things to worry about than whether all the cat pictures and audit logs survive.<p>Speak for yourself. Many of us love our audit logs and show them to strangers whatever we can.</div><br/><div id="39663902" class="c"><input type="checkbox" id="c-39663902" checked=""/><div class="controls bullet"><span class="by">dmvdoug</span><span>|</span><a href="#39660019">root</a><span>|</span><a href="#39663660">parent</a><span>|</span><a href="#39665129">next</a><span>|</span><label class="collapse" for="c-39663902">[-]</label><label class="expand" for="c-39663902">[2 more]</label></div><br/><div class="children"><div class="content">I’m picturing you having a slideshow of audit logs that you make guests to your home sit down and watch with you, like the vacation pictures slideshow of old.</div><br/><div id="39664112" class="c"><input type="checkbox" id="c-39664112" checked=""/><div class="controls bullet"><span class="by">tomcam</span><span>|</span><a href="#39660019">root</a><span>|</span><a href="#39663902">parent</a><span>|</span><a href="#39665129">next</a><span>|</span><label class="collapse" for="c-39664112">[-]</label><label class="expand" for="c-39664112">[1 more]</label></div><br/><div class="children"><div class="content">Yes but my audit logs are special and everyone just loves them, although they playfully act bored</div><br/></div></div></div></div></div></div></div></div><div id="39665129" class="c"><input type="checkbox" id="c-39665129" checked=""/><div class="controls bullet"><span class="by">laluser</span><span>|</span><a href="#39660019">root</a><span>|</span><a href="#39662985">parent</a><span>|</span><a href="#39663500">prev</a><span>|</span><a href="#39663406">next</a><span>|</span><label class="collapse" for="c-39665129">[-]</label><label class="expand" for="c-39665129">[1 more]</label></div><br/><div class="children"><div class="content">Probably for just a short period of time before it’s erasure coded</div><br/></div></div></div></div></div></div></div></div></div></div><div id="39663406" class="c"><input type="checkbox" id="c-39663406" checked=""/><div class="controls bullet"><span class="by">mauvehaus</span><span>|</span><a href="#39660019">root</a><span>|</span><a href="#39660579">parent</a><span>|</span><a href="#39660953">prev</a><span>|</span><a href="#39663125">next</a><span>|</span><label class="collapse" for="c-39663406">[-]</label><label class="expand" for="c-39663406">[1 more]</label></div><br/><div class="children"><div class="content">As a point of order: Not all Cinnabon locations make their own dough. The one I worked at the summer of 2001 made their own dough and frosting that summer, but switched to premade rolls partially that holiday season, and fully to premade rolls and frosting by the 2002 holiday season.<p>Also: you had to be eighteen or older to operate the mixer. It was something like a 60 quart machine, and all the recipes were pre-programmed for time and power with pauses to change from the paddle to the whip if needed.</div><br/></div></div><div id="39663125" class="c"><input type="checkbox" id="c-39663125" checked=""/><div class="controls bullet"><span class="by">4death4</span><span>|</span><a href="#39660019">root</a><span>|</span><a href="#39660579">parent</a><span>|</span><a href="#39663406">prev</a><span>|</span><a href="#39664300">next</a><span>|</span><label class="collapse" for="c-39663125">[-]</label><label class="expand" for="c-39663125">[1 more]</label></div><br/><div class="children"><div class="content">This was a few years ago, but blob storage on GCP had a global outage due to an outage in a single zone. That, among numerous other issues with GCP, lost my confidence entirely. Maybe it’s better now.</div><br/></div></div><div id="39664300" class="c"><input type="checkbox" id="c-39664300" checked=""/><div class="controls bullet"><span class="by">SlightlyLeftPad</span><span>|</span><a href="#39660019">root</a><span>|</span><a href="#39660579">parent</a><span>|</span><a href="#39663125">prev</a><span>|</span><a href="#39661877">next</a><span>|</span><label class="collapse" for="c-39664300">[-]</label><label class="expand" for="c-39664300">[1 more]</label></div><br/><div class="children"><div class="content">The beauty of proprietary systems is that the only information we can ever expect to get about how they’re built is the biased information we get from the builders of those systems.</div><br/></div></div><div id="39661877" class="c"><input type="checkbox" id="c-39661877" checked=""/><div class="controls bullet"><span class="by">FooBarWidget</span><span>|</span><a href="#39660019">root</a><span>|</span><a href="#39660579">parent</a><span>|</span><a href="#39664300">prev</a><span>|</span><a href="#39661051">next</a><span>|</span><label class="collapse" for="c-39661877">[-]</label><label class="expand" for="c-39661877">[2 more]</label></div><br/><div class="children"><div class="content">&quot;Checksum-all-the-things is a basic feature of a lot of file systems&quot;<p>&quot;A lot&quot;? Does anything but ZFS and maybe btrfs do this? Ext4 anf XFS — two very common filesystems — still don&#x27;t have data checksums.</div><br/><div id="39661949" class="c"><input type="checkbox" id="c-39661949" checked=""/><div class="controls bullet"><span class="by">Filligree</span><span>|</span><a href="#39660019">root</a><span>|</span><a href="#39661877">parent</a><span>|</span><a href="#39661051">next</a><span>|</span><label class="collapse" for="c-39661949">[-]</label><label class="expand" for="c-39661949">[1 more]</label></div><br/><div class="children"><div class="content">Bcachefs, and LVM also has a way to do it.<p>Unfortunately I’m not aware of any filesystem that does it while maintaining the full bandwidth of a modern NVMe. Not even with the extra reads factored in; on ZFS I get 800 MB&#x2F;s max.</div><br/></div></div></div></div><div id="39661051" class="c"><input type="checkbox" id="c-39661051" checked=""/><div class="controls bullet"><span class="by">fierro</span><span>|</span><a href="#39660019">root</a><span>|</span><a href="#39660579">parent</a><span>|</span><a href="#39661877">prev</a><span>|</span><a href="#39660216">next</a><span>|</span><label class="collapse" for="c-39661051">[-]</label><label class="expand" for="c-39661051">[1 more]</label></div><br/><div class="children"><div class="content">it&#x27;s well known and not debatable that Cinnabon is fire</div><br/></div></div></div></div><div id="39660216" class="c"><input type="checkbox" id="c-39660216" checked=""/><div class="controls bullet"><span class="by">rsync</span><span>|</span><a href="#39660019">parent</a><span>|</span><a href="#39660579">prev</a><span>|</span><a href="#39660090">next</a><span>|</span><label class="collapse" for="c-39660216">[-]</label><label class="expand" for="c-39660216">[17 more]</label></div><br/><div class="children"><div class="content">&quot;AWS&#x27; availability zone isolation is better than the other cloud providers.&quot;<p>Not better than <i>all</i> of them.<p>A geo-redundant rsync.net account exists in two different states (or countries) - for instance, primary in Fremont[1] and secondary in Denver.<p>&quot;S3 even operates at a scale where we could detect &quot;bitrot&quot;&quot;<p>That is not a function of scale.  My personal server running ZFS detects bitrot just fine - and the scale involved is tiny.<p>[1] he.net headquarters</div><br/><div id="39660310" class="c"><input type="checkbox" id="c-39660310" checked=""/><div class="controls bullet"><span class="by">breckognize</span><span>|</span><a href="#39660019">root</a><span>|</span><a href="#39660216">parent</a><span>|</span><a href="#39660849">next</a><span>|</span><label class="collapse" for="c-39660310">[-]</label><label class="expand" for="c-39660310">[8 more]</label></div><br/><div class="children"><div class="content">Backing up across two different regions is possible for any provider with two &quot;regions&quot; but requires either doubling your storage footprint or accepting a latency hit because you have to make a roundtrip from Fremont to Denver.<p>The neat thing about AWS&#x27; AZ architecture is that it&#x27;s a sweet spot in the middle. They&#x27;re far enough apart for good isolation, which provides durability and availability, but close enough that the network round trip time is negligible compared to the disk seek.<p>Re: bit rot, I mean the frequency of events. If you&#x27;ve got a few disks, you may see one flip every couple years. They happen frequently enough in S3 that you can have expectations about the arrival rate and alarm when that deviates from expectations.</div><br/><div id="39660832" class="c"><input type="checkbox" id="c-39660832" checked=""/><div class="controls bullet"><span class="by">logifail</span><span>|</span><a href="#39660019">root</a><span>|</span><a href="#39660310">parent</a><span>|</span><a href="#39661040">next</a><span>|</span><label class="collapse" for="c-39660832">[-]</label><label class="expand" for="c-39660832">[3 more]</label></div><br/><div class="children"><div class="content">&gt; The neat thing about AWS&#x27; AZ architecture is that it&#x27;s a sweet spot in the middle<p>What may be less of a sweet spot is AWS&#x27; pricing.</div><br/><div id="39660880" class="c"><input type="checkbox" id="c-39660880" checked=""/><div class="controls bullet"><span class="by">emodendroket</span><span>|</span><a href="#39660019">root</a><span>|</span><a href="#39660832">parent</a><span>|</span><a href="#39661040">next</a><span>|</span><label class="collapse" for="c-39660880">[-]</label><label class="expand" for="c-39660880">[2 more]</label></div><br/><div class="children"><div class="content">Sending the data to &#x2F;dev&#x2F;null is the cheapest option if that’s all you care about.</div><br/><div id="39660989" class="c"><input type="checkbox" id="c-39660989" checked=""/><div class="controls bullet"><span class="by">logifail</span><span>|</span><a href="#39660019">root</a><span>|</span><a href="#39660880">parent</a><span>|</span><a href="#39661040">next</a><span>|</span><label class="collapse" for="c-39660989">[-]</label><label class="expand" for="c-39660989">[1 more]</label></div><br/><div class="children"><div class="content">Seems the snark detector just went off :)<p>Back on topic, I&#x27;d hope all of us would expect value for money for any and all services we recommend or purchase.   Search for &quot;site:news.ycombinator.com Away From AWS&quot; to find dozens of discussions on how to save money by leaving AWS.<p>EDIT: just one article of the many I&#x27;ve read recently:<p>&quot;What I’ve always found surprising about egress is just how expensive it is. On AWS, downloading a file from S3 to your computer once costs 4 times more than storing it for an entire month&quot;<p><a href="https:&#x2F;&#x2F;robaboukhalil.medium.com&#x2F;youre-paying-too-much-for-egress-b1fe20274a6b" rel="nofollow">https:&#x2F;&#x2F;robaboukhalil.medium.com&#x2F;youre-paying-too-much-for-e...</a></div><br/></div></div></div></div></div></div><div id="39661040" class="c"><input type="checkbox" id="c-39661040" checked=""/><div class="controls bullet"><span class="by">senderista</span><span>|</span><a href="#39660019">root</a><span>|</span><a href="#39660310">parent</a><span>|</span><a href="#39660832">prev</a><span>|</span><a href="#39661477">next</a><span>|</span><label class="collapse" for="c-39661040">[-]</label><label class="expand" for="c-39661040">[2 more]</label></div><br/><div class="children"><div class="content">&gt; the network round trip time is negligible compared to the disk seek<p>Only for spinning rust, right?</div><br/><div id="39662356" class="c"><input type="checkbox" id="c-39662356" checked=""/><div class="controls bullet"><span class="by">breckognize</span><span>|</span><a href="#39660019">root</a><span>|</span><a href="#39661040">parent</a><span>|</span><a href="#39661477">next</a><span>|</span><label class="collapse" for="c-39662356">[-]</label><label class="expand" for="c-39662356">[1 more]</label></div><br/><div class="children"><div class="content">Yes, which is what all the hyperscalers use for object storage. HDD seek time is ~10ms. Inter-az network latency is a few hundred micros.</div><br/></div></div></div></div><div id="39661477" class="c"><input type="checkbox" id="c-39661477" checked=""/><div class="controls bullet"><span class="by">alexchamberlain</span><span>|</span><a href="#39660019">root</a><span>|</span><a href="#39660310">parent</a><span>|</span><a href="#39661040">prev</a><span>|</span><a href="#39660849">next</a><span>|</span><label class="collapse" for="c-39661477">[-]</label><label class="expand" for="c-39661477">[2 more]</label></div><br/><div class="children"><div class="content">&gt; They&#x27;re far enough apart for good isolation, which provides durability and availability<p>It can&#x27;t possibly be enough for critical data though, right? I&#x27;m guessing a fire in 1 is unlikely to spread to another, but could it affect the availability of another? What about a deliberate attack on the DCs or the utilities supplying the DCs?</div><br/><div id="39663136" class="c"><input type="checkbox" id="c-39663136" checked=""/><div class="controls bullet"><span class="by">immibis</span><span>|</span><a href="#39660019">root</a><span>|</span><a href="#39661477">parent</a><span>|</span><a href="#39660849">next</a><span>|</span><label class="collapse" for="c-39663136">[-]</label><label class="expand" for="c-39663136">[1 more]</label></div><br/><div class="children"><div class="content">Yes, if a terrorist blows up all of the several Amazon DCs holding your data, your data will be lost. This is true no matter how many DCs are holding your data, who owns them, or where they are. You can improve your chances, of course.<p>There have been region-wide availability outages before. They&#x27;re pretty rare and make worldwide news media due to how much of the internet they take out. I don&#x27;t think there&#x27;s been S3 data loss since they got serious about preventing S3 data loss.</div><br/></div></div></div></div></div></div><div id="39660849" class="c"><input type="checkbox" id="c-39660849" checked=""/><div class="controls bullet"><span class="by">allset_</span><span>|</span><a href="#39660019">root</a><span>|</span><a href="#39660216">parent</a><span>|</span><a href="#39660310">prev</a><span>|</span><a href="#39660228">next</a><span>|</span><label class="collapse" for="c-39660849">[-]</label><label class="expand" for="c-39660849">[2 more]</label></div><br/><div class="children"><div class="content">FWIW, both AWS S3 and GCP GCS also allow you to store data in multi-region.<p><a href="https:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;AmazonS3&#x2F;latest&#x2F;userguide&#x2F;MultiRegionAccessPoints.html" rel="nofollow">https:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;AmazonS3&#x2F;latest&#x2F;userguide&#x2F;MultiR...</a><p><a href="https:&#x2F;&#x2F;cloud.google.com&#x2F;storage&#x2F;docs&#x2F;locations#considerations" rel="nofollow">https:&#x2F;&#x2F;cloud.google.com&#x2F;storage&#x2F;docs&#x2F;locations#consideratio...</a></div><br/><div id="39662307" class="c"><input type="checkbox" id="c-39662307" checked=""/><div class="controls bullet"><span class="by">andrewguenther</span><span>|</span><a href="#39660019">root</a><span>|</span><a href="#39660849">parent</a><span>|</span><a href="#39660228">next</a><span>|</span><label class="collapse" for="c-39662307">[-]</label><label class="expand" for="c-39662307">[1 more]</label></div><br/><div class="children"><div class="content">Yes, but S3 has single region redundancy that is better than GCP. Your data in two AZs in one region is in two physically separate buildings. So multi-region is less important to durability.</div><br/></div></div></div></div><div id="39660228" class="c"><input type="checkbox" id="c-39660228" checked=""/><div class="controls bullet"><span class="by">Helmut10001</span><span>|</span><a href="#39660019">root</a><span>|</span><a href="#39660216">parent</a><span>|</span><a href="#39660849">prev</a><span>|</span><a href="#39661392">next</a><span>|</span><label class="collapse" for="c-39660228">[-]</label><label class="expand" for="c-39660228">[4 more]</label></div><br/><div class="children"><div class="content">Agree.<p>&gt; S3 even operates at a scale where we could detect &quot;bitrot&quot; - random bit flips caused by gamma rays hitting a hard drive platter (roughly one per second across trillions of objects iirc).<p>I would expect any cloud provider to be able to detect bitrot these days.</div><br/><div id="39661050" class="c"><input type="checkbox" id="c-39661050" checked=""/><div class="controls bullet"><span class="by">senderista</span><span>|</span><a href="#39660019">root</a><span>|</span><a href="#39660228">parent</a><span>|</span><a href="#39661392">next</a><span>|</span><label class="collapse" for="c-39661050">[-]</label><label class="expand" for="c-39661050">[3 more]</label></div><br/><div class="children"><div class="content">I think the point the OP was trying to make is that they <i>regularly detected</i> bitrot due to their scale, not that they were merely <i>capable</i> of doing so.</div><br/><div id="39661221" class="c"><input type="checkbox" id="c-39661221" checked=""/><div class="controls bullet"><span class="by">Helmut10001</span><span>|</span><a href="#39660019">root</a><span>|</span><a href="#39661050">parent</a><span>|</span><a href="#39661437">next</a><span>|</span><label class="collapse" for="c-39661221">[-]</label><label class="expand" for="c-39661221">[1 more]</label></div><br/><div class="children"><div class="content">Ah, thank you. This makes more sense. And I think I remember reading about it once. Apologies for the misinterpretation!</div><br/></div></div><div id="39661437" class="c"><input type="checkbox" id="c-39661437" checked=""/><div class="controls bullet"><span class="by">pclmulqdq</span><span>|</span><a href="#39660019">root</a><span>|</span><a href="#39661050">parent</a><span>|</span><a href="#39661221">prev</a><span>|</span><a href="#39661392">next</a><span>|</span><label class="collapse" for="c-39661437">[-]</label><label class="expand" for="c-39661437">[1 more]</label></div><br/><div class="children"><div class="content">Everyone with significant scale and decent software regularly detects bitrot.</div><br/></div></div></div></div></div></div><div id="39661392" class="c"><input type="checkbox" id="c-39661392" checked=""/><div class="controls bullet"><span class="by">mannyv</span><span>|</span><a href="#39660019">root</a><span>|</span><a href="#39660216">parent</a><span>|</span><a href="#39660228">prev</a><span>|</span><a href="#39660090">next</a><span>|</span><label class="collapse" for="c-39661392">[-]</label><label class="expand" for="c-39661392">[2 more]</label></div><br/><div class="children"><div class="content">How does the latest ZFS bug impact your bitrot statement?<p>I mean, technically it’s not bitrot if zeros were accidentally written out instead of data.</div><br/><div id="39662118" class="c"><input type="checkbox" id="c-39662118" checked=""/><div class="controls bullet"><span class="by">woodada</span><span>|</span><a href="#39660019">root</a><span>|</span><a href="#39661392">parent</a><span>|</span><a href="#39660090">next</a><span>|</span><label class="collapse" for="c-39662118">[-]</label><label class="expand" for="c-39662118">[1 more]</label></div><br/><div class="children"><div class="content">Probably none because they didn&#x27;t update to the exact version that had the bug</div><br/></div></div></div></div></div></div><div id="39660090" class="c"><input type="checkbox" id="c-39660090" checked=""/><div class="controls bullet"><span class="by">supriyo-biswas</span><span>|</span><a href="#39660019">parent</a><span>|</span><a href="#39660216">prev</a><span>|</span><a href="#39660246">next</a><span>|</span><label class="collapse" for="c-39660090">[-]</label><label class="expand" for="c-39660090">[2 more]</label></div><br/><div class="children"><div class="content">Checksumming the data is not based out of paranoia but simply as a result of having to detect which blocks are unusable in order to run the Reed-Solomon algorithm.<p>I&#x27;d also assume that a sufficient number of these corruption events are used as a signal to &quot;heal&quot; the system by migrating the individual data blocks onto different machines.<p>Overall, I&#x27;d say the things that you mentioned are pretty typical of a storage system, and are not at all specific to S3 :)</div><br/><div id="39660632" class="c"><input type="checkbox" id="c-39660632" checked=""/><div class="controls bullet"><span class="by">catlifeonmars</span><span>|</span><a href="#39660019">root</a><span>|</span><a href="#39660090">parent</a><span>|</span><a href="#39660246">next</a><span>|</span><label class="collapse" for="c-39660632">[-]</label><label class="expand" for="c-39660632">[1 more]</label></div><br/><div class="children"><div class="content">The S3 checksum feature applies to the objects, so that’s entirely orthogonal to erasure codes. Unless you know something I don’t and SHA256 has commutative properties. You’d still need to compute the object hash independent of any blocks.<p>Source: <a href="https:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;AmazonS3&#x2F;latest&#x2F;userguide&#x2F;checking-object-integrity.html" rel="nofollow">https:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;AmazonS3&#x2F;latest&#x2F;userguide&#x2F;checki...</a></div><br/></div></div></div></div><div id="39660246" class="c"><input type="checkbox" id="c-39660246" checked=""/><div class="controls bullet"><span class="by">medler</span><span>|</span><a href="#39660019">parent</a><span>|</span><a href="#39660090">prev</a><span>|</span><a href="#39665391">next</a><span>|</span><label class="collapse" for="c-39660246">[-]</label><label class="expand" for="c-39660246">[5 more]</label></div><br/><div class="children"><div class="content">&gt; customers would beat us up over pricing compared to GCP blob storage, but the comparison was unfair because Google would store your data in the same building<p>I don’t think this is true. Per the Google Cloud Storage docs, data is replicated across multiple zones, and each zone maps to a different cluster. 
<a href="https:&#x2F;&#x2F;cloud.google.com&#x2F;compute&#x2F;docs&#x2F;regions-zones&#x2F;zone-virtualization" rel="nofollow">https:&#x2F;&#x2F;cloud.google.com&#x2F;compute&#x2F;docs&#x2F;regions-zones&#x2F;zone-vir...</a></div><br/><div id="39661127" class="c"><input type="checkbox" id="c-39661127" checked=""/><div class="controls bullet"><span class="by">yencabulator</span><span>|</span><a href="#39660019">root</a><span>|</span><a href="#39660246">parent</a><span>|</span><a href="#39660381">next</a><span>|</span><label class="collapse" for="c-39661127">[-]</label><label class="expand" for="c-39661127">[1 more]</label></div><br/><div class="children"><div class="content">Zones are about correlated power and networking failures. Regions are about disasters. If you want multiple regions, Google can of course do that too:<p><a href="https:&#x2F;&#x2F;cloud.google.com&#x2F;storage&#x2F;docs&#x2F;locations#considerations" rel="nofollow">https:&#x2F;&#x2F;cloud.google.com&#x2F;storage&#x2F;docs&#x2F;locations#consideratio...</a></div><br/></div></div><div id="39660381" class="c"><input type="checkbox" id="c-39660381" checked=""/><div class="controls bullet"><span class="by">singron</span><span>|</span><a href="#39660019">root</a><span>|</span><a href="#39660246">parent</a><span>|</span><a href="#39661127">prev</a><span>|</span><a href="#39665391">next</a><span>|</span><label class="collapse" for="c-39660381">[-]</label><label class="expand" for="c-39660381">[3 more]</label></div><br/><div class="children"><div class="content">Google puts multiple clusters in a single building.</div><br/><div id="39660526" class="c"><input type="checkbox" id="c-39660526" checked=""/><div class="controls bullet"><span class="by">medler</span><span>|</span><a href="#39660019">root</a><span>|</span><a href="#39660381">parent</a><span>|</span><a href="#39660930">next</a><span>|</span><label class="collapse" for="c-39660526">[-]</label><label class="expand" for="c-39660526">[1 more]</label></div><br/><div class="children"><div class="content">Seems you’re right. They say each zone is a separate failure domain but you kind of have to trust their word on that.</div><br/></div></div><div id="39660930" class="c"><input type="checkbox" id="c-39660930" checked=""/><div class="controls bullet"><span class="by">navaati</span><span>|</span><a href="#39660019">root</a><span>|</span><a href="#39660381">parent</a><span>|</span><a href="#39660526">prev</a><span>|</span><a href="#39665391">next</a><span>|</span><label class="collapse" for="c-39660930">[-]</label><label class="expand" for="c-39660930">[1 more]</label></div><br/><div class="children"><div class="content">Flashback to that Clichy datacenter fire near Paris...</div><br/></div></div></div></div></div></div><div id="39665391" class="c"><input type="checkbox" id="c-39665391" checked=""/><div class="controls bullet"><span class="by">simonebrunozzi</span><span>|</span><a href="#39660019">parent</a><span>|</span><a href="#39660246">prev</a><span>|</span><a href="#39661397">next</a><span>|</span><label class="collapse" for="c-39665391">[-]</label><label class="expand" for="c-39665391">[1 more]</label></div><br/><div class="children"><div class="content">I also worked at AWS, but not in the S3 team. However, I was Tech Evangelist and met with literally thousands of customers over my 6 years tenure. S3 was one of the hottest topics, but I got a sense of how good and robust it was directly from these customers.<p>What you say resonates really well with me, and what I&#x27;ve heard during these years.</div><br/></div></div><div id="39661397" class="c"><input type="checkbox" id="c-39661397" checked=""/><div class="controls bullet"><span class="by">Veserv</span><span>|</span><a href="#39660019">parent</a><span>|</span><a href="#39665391">prev</a><span>|</span><a href="#39660079">next</a><span>|</span><label class="collapse" for="c-39661397">[-]</label><label class="expand" for="c-39661397">[5 more]</label></div><br/><div class="children"><div class="content">But they asked if the claims were audited by a unbiased third party. Are there such audits?<p>Alternatively, AWS does publicly provide legally binding availability guarantees, but I have never seen any prominently displayed legally binding durability guarantees. Are these published somewhere less prominently?</div><br/><div id="39663016" class="c"><input type="checkbox" id="c-39663016" checked=""/><div class="controls bullet"><span class="by">cyberax</span><span>|</span><a href="#39660019">root</a><span>|</span><a href="#39661397">parent</a><span>|</span><a href="#39660079">next</a><span>|</span><label class="collapse" for="c-39663016">[-]</label><label class="expand" for="c-39663016">[4 more]</label></div><br/><div class="children"><div class="content">&gt; Alternatively, AWS does publicly provide legally binding availability guarantees, but I have never seen any prominently displayed legally binding durability guarantees. Are these published somewhere less prominently?<p>It&#x27;s listed prominently in the public docs: <a href="https:&#x2F;&#x2F;aws.amazon.com&#x2F;s3&#x2F;storage-classes&#x2F;" rel="nofollow">https:&#x2F;&#x2F;aws.amazon.com&#x2F;s3&#x2F;storage-classes&#x2F;</a></div><br/><div id="39664749" class="c"><input type="checkbox" id="c-39664749" checked=""/><div class="controls bullet"><span class="by">Veserv</span><span>|</span><a href="#39660019">root</a><span>|</span><a href="#39663016">parent</a><span>|</span><a href="#39664784">next</a><span>|</span><label class="collapse" for="c-39664749">[-]</label><label class="expand" for="c-39664749">[2 more]</label></div><br/><div class="children"><div class="content">I read that page and it does not provide any contractual durability guarantees as far as I can see. It provides &quot;designed for availability&quot; and then contractual availability SLA guarantees. It provides &quot;designed for durability&quot;, but presents no contractual durability guarantee as far as I can see.<p>Given that their lawyers clearly indicate that &quot;designed for availability&quot; is not what they are contractually obligated to provide, only the letter of the SLA does that; &quot;designed for durability&quot; is similarly a marketing statement that does not incur any contractual obligations. Is there some specific statement in that document that I am missing which indicates that data durability is not fully at their convenience?</div><br/><div id="39665774" class="c"><input type="checkbox" id="c-39665774" checked=""/><div class="controls bullet"><span class="by">AdamN</span><span>|</span><a href="#39660019">root</a><span>|</span><a href="#39664749">parent</a><span>|</span><a href="#39664784">next</a><span>|</span><label class="collapse" for="c-39665774">[-]</label><label class="expand" for="c-39665774">[1 more]</label></div><br/><div class="children"><div class="content">SLAs are more of a financial construct than anything else.  Once the payback cost of missing an SLA is built into the contract then it just becomes a conversation about money.  I&#x27;ve been at plenty of shops that obviously tried to hit the SLA but if it was missed it just became a financial issue which helped smooth over what otherwise might have been a trust buster.<p>I would never ever think of an SLA as anything more than a financial commitment - if you think more of it you&#x27;ll eventually be in a world of hurt.</div><br/></div></div></div></div></div></div></div></div><div id="39660079" class="c"><input type="checkbox" id="c-39660079" checked=""/><div class="controls bullet"><span class="by">tracerbulletx</span><span>|</span><a href="#39660019">parent</a><span>|</span><a href="#39661397">prev</a><span>|</span><a href="#39660719">next</a><span>|</span><label class="collapse" for="c-39660079">[-]</label><label class="expand" for="c-39660079">[2 more]</label></div><br/><div class="children"><div class="content">My first job was at a startup in 2012 where I was expected to build things at a scale way over what I really had the experience to do. Anyways the best choice I ever made was using RDS and S3 (and django).</div><br/></div></div><div id="39660719" class="c"><input type="checkbox" id="c-39660719" checked=""/><div class="controls bullet"><span class="by">loeg</span><span>|</span><a href="#39660019">parent</a><span>|</span><a href="#39660079">prev</a><span>|</span><a href="#39663073">next</a><span>|</span><label class="collapse" for="c-39660719">[-]</label><label class="expand" for="c-39660719">[1 more]</label></div><br/><div class="children"><div class="content">Not a public cloud, but storage at Facebook is similar in terms of physical infrastructure, safety culture, and scale.</div><br/></div></div><div id="39663073" class="c"><input type="checkbox" id="c-39663073" checked=""/><div class="controls bullet"><span class="by">chupasaurus</span><span>|</span><a href="#39660019">parent</a><span>|</span><a href="#39660719">prev</a><span>|</span><a href="#39660224">next</a><span>|</span><label class="collapse" for="c-39663073">[-]</label><label class="expand" for="c-39663073">[1 more]</label></div><br/><div class="children"><div class="content">&gt; and bigger events like natural disasters<p>Outdated anecdata: I&#x27;ve worked for a company that lost some parts of buckets after the lightning strike incident in 2011, which bumped the paranoia quite a bit. AFAIK same thing couldn&#x27;t happen for more than a decade.</div><br/></div></div><div id="39660206" class="c"><input type="checkbox" id="c-39660206" checked=""/><div class="controls bullet"><span class="by">staunch</span><span>|</span><a href="#39660019">parent</a><span>|</span><a href="#39660224">prev</a><span>|</span><a href="#39661240">next</a><span>|</span><label class="collapse" for="c-39660206">[-]</label><label class="expand" for="c-39660206">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>Believe the hype.</i><p>I&#x27;d rather believe the test results.<p>Is there a neutral third-party that has validated S3&#x27;s durability&#x2F;integrity&#x2F;consistency? Something as rigorous as Jepsen?<p>It&#x27;d be really neat if someone compared all the S3 compatible cloud storage systems in a really rigorous way. I&#x27;m sure we&#x27;d discover that there are huge scary problems. Or maybe someone already has?</div><br/></div></div><div id="39661240" class="c"><input type="checkbox" id="c-39661240" checked=""/><div class="controls bullet"><span class="by">spintin</span><span>|</span><a href="#39660019">parent</a><span>|</span><a href="#39660206">prev</a><span>|</span><a href="#39662085">next</a><span>|</span><label class="collapse" for="c-39661240">[-]</label><label class="expand" for="c-39661240">[3 more]</label></div><br/><div class="children"><div class="content">Correct me if I&#x27;m wrong but bitrot only affects spinning rust since NAND uses ECC?<p>If you see this I wonder if S3 is planning on adding hardlinks?</div><br/><div id="39661378" class="c"><input type="checkbox" id="c-39661378" checked=""/><div class="controls bullet"><span class="by">sgtnoodle</span><span>|</span><a href="#39660019">root</a><span>|</span><a href="#39661240">parent</a><span>|</span><a href="#39661728">next</a><span>|</span><label class="collapse" for="c-39661378">[-]</label><label class="expand" for="c-39661378">[1 more]</label></div><br/><div class="children"><div class="content">Pretty much any modern storage medium depends on a healthy amount of error correcting code.</div><br/></div></div><div id="39661728" class="c"><input type="checkbox" id="c-39661728" checked=""/><div class="controls bullet"><span class="by">surajrmal</span><span>|</span><a href="#39660019">root</a><span>|</span><a href="#39661240">parent</a><span>|</span><a href="#39661378">prev</a><span>|</span><a href="#39662085">next</a><span>|</span><label class="collapse" for="c-39661728">[-]</label><label class="expand" for="c-39661728">[1 more]</label></div><br/><div class="children"><div class="content">Nand is constantly moving around your data to prevent it from bit rotting. If you leave data too long without moving it, you may not be able to read the data from the nand.</div><br/></div></div></div></div></div></div><div id="39658507" class="c"><input type="checkbox" id="c-39658507" checked=""/><div class="controls bullet"><span class="by">orf</span><span>|</span><a href="#39660019">prev</a><span>|</span><a href="#39660005">next</a><span>|</span><label class="collapse" for="c-39658507">[-]</label><label class="expand" for="c-39658507">[72 more]</label></div><br/><div class="children"><div class="content">&gt; And listing files is slow. While the joy of Amazon S3 is that you can read and write at extremely, extremely, high bandwidths, listing out what is there is much much slower. Slower than a slow local filesystem<p>This misses something critical. Yes, s3 has fast reading and writing, but that’s not really what makes it <i>useful</i>.<p>What makes it useful <i>is</i> listing. In an unversioned bucket (or one with no delete markers), listing any given prefix is essentially constant time: I can take any given string, in a bucket with 100 billion objects, and say “give me the next 1000 keys alphabetically that come after this random string”.<p>What’s more, using “&#x2F;“ as a delimiter is just the default - you can use any character you want and get a set of common prefixes. There are no “directories”, ”directories” are created out of thin air on demand.<p>This is super powerful, and it’s the thing that lets you partition your data in various ways, using whatever identifiers you need, without worrying about performance.<p>If listing was just “slow”, couldn’t list on file prefixes <i>and</i> got slower proportional to the number of keys (I.e a traditional unix file system), then it wouldn’t be useful at all.</div><br/><div id="39658779" class="c"><input type="checkbox" id="c-39658779" checked=""/><div class="controls bullet"><span class="by">calpaterson</span><span>|</span><a href="#39658507">parent</a><span>|</span><a href="#39660445">next</a><span>|</span><label class="collapse" for="c-39658779">[-]</label><label class="expand" for="c-39658779">[17 more]</label></div><br/><div class="children"><div class="content">I have to say that I&#x27;m not hugely convinced.  I don&#x27;t really think that being able to pull out the keys before or after a prefix is particularly impressive.  That is the basis for database indices going back to the 1970s after all.<p>Perhaps the use-cases you&#x27;re talking about are very different from mine.  That&#x27;s possible of course.<p>But for me, often the slow speed of listing the bucket gets in the way.  Your bucket doesn&#x27;t have to get very big before listing the keys takes longer than reading them.  I seem to remember that listing operations ran at sub-1mbps, but admittedly I don&#x27;t have a big bucket handy right now to test that.</div><br/><div id="39659121" class="c"><input type="checkbox" id="c-39659121" checked=""/><div class="controls bullet"><span class="by">orf</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39658779">parent</a><span>|</span><a href="#39659324">next</a><span>|</span><label class="collapse" for="c-39659121">[-]</label><label class="expand" for="c-39659121">[1 more]</label></div><br/><div class="children"><div class="content">It depends on a few factors. The list objects call hides deleted and noncurrent versions, but it has to skip over them. Grouping prefixes also takes time, if they contain a lot of noncurrent or deleted keys.<p>A pathological case would be a prefix with 100 million deleted keys, and 1 actual key at the end. Listing the parent prefix takes a long time in this case - I’ve seen it take several minutes.<p>If your bucket is pretty “normal” and doesn’t have this, or isn’t versioned, then you can do 4-5 thousand list requests a second, at any given key&#x2F;prefix, in constant time. Or or you can explicitly list object versions  (and not skip deleted keys) also in constant time.<p>It all depends on your data: if you need to list all objects then yeah it’s gonna be slow because you need to paginate through all the objects. But the point is that you don’t have to do that if you don’t want to, unlike a traditional filesystem with a directory hierarchy.<p>And this enables parallelisation: why list everything sequentially, when you can group the prefixes by some character (i.e “-“), then process each of those prefixes in parallel.<p>The world is your oyster.</div><br/></div></div><div id="39659324" class="c"><input type="checkbox" id="c-39659324" checked=""/><div class="controls bullet"><span class="by">cuno</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39658779">parent</a><span>|</span><a href="#39659121">prev</a><span>|</span><a href="#39660445">next</a><span>|</span><label class="collapse" for="c-39659324">[-]</label><label class="expand" for="c-39659324">[15 more]</label></div><br/><div class="children"><div class="content">We and our customers use S3 as a POSIX filesystem, and we generally find it faster than a local filesystem for many benchmarks. For listing directories we find it faster than Lustre (a real high performance filesystem). Our approach is to first try listing directories with a single ListObjectV2 (which on AWS S3 is in lexicographic order) and if it hasn&#x27;t made much progress, we start listing with parallel ListObjectV2. Once you start parallelising the ListObjectV2 (rather than sequentially &quot;continuing&quot;) you get massive speedups.</div><br/><div id="39665226" class="c"><input type="checkbox" id="c-39665226" checked=""/><div class="controls bullet"><span class="by">YZF</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39659324">parent</a><span>|</span><a href="#39659801">next</a><span>|</span><label class="collapse" for="c-39665226">[-]</label><label class="expand" for="c-39665226">[1 more]</label></div><br/><div class="children"><div class="content">It can&#x27;t be a POSIX filesystem if it doesn&#x27;t meet POSIX filesystem guarantees. I worked on an S3 compatible object store in a large storage company and we also had distributed filesystem products. Those are completely different animals due to the different semantics and requirements. We&#x27;ve also built compliant filesystems over object store and the other way around. Certain operations like, write-append, are tricky to simulate over object stores (S3 didn&#x27;t use to support append, I haven&#x27;t really stayed up to date, does it now?). At least when I worked on this it wasn&#x27;t possible to simulate POSIX semantics over S3 at all without needing to add additional object store primitives.</div><br/></div></div><div id="39659801" class="c"><input type="checkbox" id="c-39659801" checked=""/><div class="controls bullet"><span class="by">supriyo-biswas</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39659324">parent</a><span>|</span><a href="#39665226">prev</a><span>|</span><a href="#39659600">next</a><span>|</span><label class="collapse" for="c-39659801">[-]</label><label class="expand" for="c-39659801">[3 more]</label></div><br/><div class="children"><div class="content">&gt; Once you start parallelising the ListObjectV2 (rather than sequentially &quot;continuing&quot;)<p>How are you &quot;parallelizing&quot; the ListObjectsV2? The continuation token can be only fed in once the previous ListObjectsV2 response has completed, unless you know the name or structure of keys ahead of time, in which listing objects isn&#x27;t necessary.</div><br/><div id="39659869" class="c"><input type="checkbox" id="c-39659869" checked=""/><div class="controls bullet"><span class="by">cuno</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39659801">parent</a><span>|</span><a href="#39659874">next</a><span>|</span><label class="collapse" for="c-39659869">[-]</label><label class="expand" for="c-39659869">[1 more]</label></div><br/><div class="children"><div class="content">For example, you can do separate parallel ListObjectV2 for files starting a-f and g-k, etc.. covering the whole key space. You can parallelize recursively based on what is found in the first 1000 entries so that it matches the statistics of the keys. Yes there may be pathological cases, but in practice we find this works very well.</div><br/></div></div><div id="39659874" class="c"><input type="checkbox" id="c-39659874" checked=""/><div class="controls bullet"><span class="by">johnmaguire</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39659801">parent</a><span>|</span><a href="#39659869">prev</a><span>|</span><a href="#39659600">next</a><span>|</span><label class="collapse" for="c-39659874">[-]</label><label class="expand" for="c-39659874">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;re right that it won&#x27;t work for all use cases, but starting two threads with prefixes A and M, for example, is one way you might achieve this.</div><br/></div></div></div></div><div id="39659600" class="c"><input type="checkbox" id="c-39659600" checked=""/><div class="controls bullet"><span class="by">crabbone</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39659324">parent</a><span>|</span><a href="#39659801">prev</a><span>|</span><a href="#39661772">next</a><span>|</span><label class="collapse" for="c-39659600">[-]</label><label class="expand" for="c-39659600">[8 more]</label></div><br/><div class="children"><div class="content">&gt; find it faster than a local filesystem for many benchmarks.<p>What did you measure?  How did you compare?  This claim seems <i>very</i> contrary to my experience and understanding of how things work...<p>Let me refine the question: did you measure metadata or data operations?  What kind of storage medium is used by the filesystem you use?  How much memory (and subsequently the filesystem cache) does your system have?<p>----<p>The thing is: you should expect, in the best case, something like 5 ms latency on network calls over the Internet in an ideal case.  Within the datacenter, maybe you can achieve sub-ms latency, but that&#x27;s hard.  AWS within region but different zones tends to be around 1 ms latency.<p>This is while NVMe latency, even on consumer products, is 10-20 <i>micro</i> seconds.  I.e. we are talking about roughly 100 times faster than anything going through the network can offer.</div><br/><div id="39659684" class="c"><input type="checkbox" id="c-39659684" checked=""/><div class="controls bullet"><span class="by">cuno</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39659600">parent</a><span>|</span><a href="#39661772">next</a><span>|</span><label class="collapse" for="c-39659684">[-]</label><label class="expand" for="c-39659684">[7 more]</label></div><br/><div class="children"><div class="content">For AWS, we&#x27;re comparing against filesystems in the datacenter - so EBS, EFS and FSx Lustre. Compared to these, you can see in the graphs where S3 is much faster for workloads with big files and small files:
<a href="https:&#x2F;&#x2F;cuno.io&#x2F;technology&#x2F;" rel="nofollow">https:&#x2F;&#x2F;cuno.io&#x2F;technology&#x2F;</a><p>and in even more detail of different types of EBS&#x2F;EFS&#x2F;FSx Lustre here:
<a href="https:&#x2F;&#x2F;cuno.io&#x2F;blog&#x2F;making-the-right-choice-comparing-the-cost-performance-of-different-efs-options-and-alternatives&#x2F;" rel="nofollow">https:&#x2F;&#x2F;cuno.io&#x2F;blog&#x2F;making-the-right-choice-comparing-the-c...</a></div><br/><div id="39659882" class="c"><input type="checkbox" id="c-39659882" checked=""/><div class="controls bullet"><span class="by">hnlmorg</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39659684">parent</a><span>|</span><a href="#39660908">next</a><span>|</span><label class="collapse" for="c-39659882">[-]</label><label class="expand" for="c-39659882">[3 more]</label></div><br/><div class="children"><div class="content">EFS is ridiculously slow though. Almost to the point where I fail to see how it’s actually useful for any of the  traditional use cases for NFS.</div><br/><div id="39660132" class="c"><input type="checkbox" id="c-39660132" checked=""/><div class="controls bullet"><span class="by">dekhn</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39659882">parent</a><span>|</span><a href="#39660908">next</a><span>|</span><label class="collapse" for="c-39660132">[-]</label><label class="expand" for="c-39660132">[2 more]</label></div><br/><div class="children"><div class="content">if you turn all the EFS performance knobs up (at a high cost), it&#x27;s quite fast.</div><br/><div id="39660375" class="c"><input type="checkbox" id="c-39660375" checked=""/><div class="controls bullet"><span class="by">hnlmorg</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39660132">parent</a><span>|</span><a href="#39660908">next</a><span>|</span><label class="collapse" for="c-39660375">[-]</label><label class="expand" for="c-39660375">[1 more]</label></div><br/><div class="children"><div class="content">Fast<i>er</i>, sure. But I wouldn’t got so far as to say it is <i>fast</i></div><br/></div></div></div></div></div></div><div id="39660908" class="c"><input type="checkbox" id="c-39660908" checked=""/><div class="controls bullet"><span class="by">wenc</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39659684">parent</a><span>|</span><a href="#39659882">prev</a><span>|</span><a href="#39661129">next</a><span>|</span><label class="collapse" for="c-39660908">[-]</label><label class="expand" for="c-39660908">[1 more]</label></div><br/><div class="children"><div class="content">S3 is really high latency though. I store parquet files on S3 and querying them through DuckDB is much slower than file system because random access patterns. I can see S3 being decent if it’s bulk access but definitely not for random access.<p>This is why there’s a new S3 Express offering that is low latency (but costs more).</div><br/></div></div><div id="39661129" class="c"><input type="checkbox" id="c-39661129" checked=""/><div class="controls bullet"><span class="by">crabbone</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39659684">parent</a><span>|</span><a href="#39660908">prev</a><span>|</span><a href="#39661772">next</a><span>|</span><label class="collapse" for="c-39661129">[-]</label><label class="expand" for="c-39661129">[2 more]</label></div><br/><div class="children"><div class="content">The tests are very weird...<p>Normally, from someone working in the storage, you&#x27;d expect tests to be in IOPS, and the goto tool for reproducible tests is FIO.  I mean, of course &quot;reproducibility&quot; is a very broad subject, but people are so used to this tool that they develop certain intuition and interpretation for it &#x2F; its results.<p>On the other hand, seeing throughput figures is kinda... it tells you very little about how the system performs.  Just to give you some reasons: a system can be configured to do compression or deduplication on client &#x2F; server, and this will significantly impact your throughput, depending on what do you actually measure: the amount of useful information presented to the user or the amount of information transferred.  Also throughput at the expense of higher latency may or may not be a good thing...  Really, if you ask anyone who ever worked on a storage product about how they could crank up throughput numbers, they&#x27;d tell you: &quot;write bigger blocks asynchronously&quot;.  This is the basic recipe, if that&#x27;s what you want.  Whether this makes a good all around system or not... I&#x27;d say, probably not.<p>Of course, there are many other concerns.  Data consistency is a big one, and this is a typical tradeoff when it comes to choosing between object store and a filesystem, since filesystem offers more data consistency guarantees, whereas object store can do certain things faster, while breaking them.<p>BTW, I don&#x27;t think most readers would understand Lustre and similar to be the &quot;local filesystem&quot;, since it operates over network and network performance will have a significant impact, of course, it will also put it in the same ballpark as other networked systems.<p>I&#x27;d also say that Ceph is kinda missing from this benchmark... Again, if we are talking about filesystem on top of object store, it&#x27;s the prime example...</div><br/><div id="39662573" class="c"><input type="checkbox" id="c-39662573" checked=""/><div class="controls bullet"><span class="by">cuno</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39661129">parent</a><span>|</span><a href="#39661772">next</a><span>|</span><label class="collapse" for="c-39662573">[-]</label><label class="expand" for="c-39662573">[1 more]</label></div><br/><div class="children"><div class="content">IOPS is a really lazy benchmark that we believe can greatly diverge from most real life workloads, except for truly random I&#x2F;O in applications such as databases. For example, in Machine Learning, training usually consists of taking large datasets (sometimes many PBs in scale), randomly shuffling them each Epoch, and feeding them into the engine as fast as possible. Because of this, we see storage vendors for ML workloads concentrate on IOPS numbers. The GPUs however only really care about throughput. Indeed, we find a great many applications only really care about the throughput, and IOPS is only relevant if it helps to accomplish that throughput. For ML, we realised that the shuffling isn&#x27;t actually random - there&#x27;s no real reason for it to be random versus pseudo-random. And if its pseudo-random then it is predictable, and if its predictable then we can exploit that to great effect - yielding a 60x boost in throughput on S3, beating out a bunch of other solutions. S3 is not going to do great for truly random I&#x2F;O, however, we find that most scientific, media and finance workloads are actually deterministic or semi-deterministic, and this is where cunoFS, by peering inside each process, can better predict intra-file and inter-file access patterns, so that we can hide the latencies present in S3. At the end of the day, the right benchmark is the one that reflects real world usage of applications, but that&#x27;s a lot of effort to document one by one.<p>I agree that things like dedupe and compression can affect things, so in our large file benchmarks each file is actually random. The small file benchmarks aren&#x27;t affected by &quot;write bigger blocks&quot; because there&#x27;s nothing bigger than the file itself. Yes, data consistency can be an issue, and we&#x27;ve had to do all sorts of things to ensure POSIX consistency guarantees beyond what S3 (or compatible) can provide. These come with restrictions (such as on concurrent writes to the same file on multiple nodes), but so does NFS. In practice, we introduced a cunoFS Fusion mode that relies on a traditional high-IOPS filesystem for such workloads and consistency (automatically migrating data to that tier), and high throughput object for other workloads that don&#x27;t need it.</div><br/></div></div></div></div></div></div></div></div><div id="39661772" class="c"><input type="checkbox" id="c-39661772" checked=""/><div class="controls bullet"><span class="by">fijiaarone</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39659324">parent</a><span>|</span><a href="#39659600">prev</a><span>|</span><a href="#39660445">next</a><span>|</span><label class="collapse" for="c-39661772">[-]</label><label class="expand" for="c-39661772">[2 more]</label></div><br/><div class="children"><div class="content">If you think s3 is fast, you should try FTP. It’s at least a hundred times faster. And combined with rsync, dozens of times more reliable.</div><br/><div id="39663787" class="c"><input type="checkbox" id="c-39663787" checked=""/><div class="controls bullet"><span class="by">orf</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39661772">parent</a><span>|</span><a href="#39660445">next</a><span>|</span><label class="collapse" for="c-39663787">[-]</label><label class="expand" for="c-39663787">[1 more]</label></div><br/><div class="children"><div class="content">Neither of those are true though? Not sure if this is sarcastic or not, if so make it more clear in the future</div><br/></div></div></div></div></div></div></div></div><div id="39660445" class="c"><input type="checkbox" id="c-39660445" checked=""/><div class="controls bullet"><span class="by">nh2</span><span>|</span><a href="#39658507">parent</a><span>|</span><a href="#39658779">prev</a><span>|</span><a href="#39660080">next</a><span>|</span><label class="collapse" for="c-39660445">[-]</label><label class="expand" for="c-39660445">[2 more]</label></div><br/><div class="children"><div class="content">The key difference between lexicographically keyed flat hierarchies, and directory-nested filesystem hierarchies, becomes clear based on this example:<p><pre><code>    dir1&#x2F;a&#x2F;000000
    dir1&#x2F;a&#x2F;...
    dir1&#x2F;a&#x2F;999999
    dir1&#x2F;b
</code></pre>
On a proper hierarchical file file system with directories as tree interior nodes, `ls dir1&#x2F;` needs to traverse and return only 2 entries (&quot;a&quot; and &quot;b&quot;).<p>A flat string-indexed KV store that only supports lexicographic order, without special handling of delimters, needs to traverse 1 million dirents (&quot;a&#x2F;00000&quot; throuh &quot;a&#x2F;999999&quot;) before arriving at &quot;b&quot;.<p>Thus, simple flat hierarchies are much slower at listing the contents of a single dir:
O(all recursive children), vs. O(immediate children) on a &quot;proper&quot; filesystem.<p>Lexicographic strings cannot model multi-level tree structures with the same complexities; this may give it the reputation of &quot;listing files is slow&quot;.<p>UNLESS you tell the listing algorithm what the delimter character is (e.g. `&#x2F;`).
Then a lexicographical prefix tree can efficiently skip over all subtrees at the next `&#x2F;`.<p>Amazon S3 supports that, with the docs explicitly mentioning &quot;skipping over and summarizing the (possibly millions of) keys nested at deeper levels&quot; in the `CommonPrefixes` field:
<a href="https:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;AmazonS3&#x2F;latest&#x2F;userguide&#x2F;using-prefixes.html#prefixes-list-example" rel="nofollow">https:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;AmazonS3&#x2F;latest&#x2F;userguide&#x2F;using-...</a><p>I have not tested whether Amazon&#x27;s implemented actually saves the traversal (or whether it traverses and just returns less results), but I&#x27;d hope so.</div><br/><div id="39660991" class="c"><input type="checkbox" id="c-39660991" checked=""/><div class="controls bullet"><span class="by">nh2</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39660445">parent</a><span>|</span><a href="#39660080">next</a><span>|</span><label class="collapse" for="c-39660991">[-]</label><label class="expand" for="c-39660991">[1 more]</label></div><br/><div class="children"><div class="content">For completeness: The orignal post says:<p><pre><code>    S3 has no rename or move operation.
    Renaming is CopyObject and then DeleteObject.
    CopyObject takes linear time to the size of the file(s).
    This comes up fairly often when someone has written a lot of files
    to the wrong place - moving the files back is very slow.
</code></pre>
This is right:<p>In a normal file system, renaming a directory is fast O(1), in S3 it&#x27;s slow O(all recursive children).<p>And Amazon S3 has not added a delimiter-based function to reduce its complexity, even though that would be easily possible in a lexicographic prefix tree (re-rooting the subtree).<p>So here the original post has indeed found a case where S3 is much slower than a normal file system.</div><br/></div></div></div></div><div id="39660080" class="c"><input type="checkbox" id="c-39660080" checked=""/><div class="controls bullet"><span class="by">gamache</span><span>|</span><a href="#39658507">parent</a><span>|</span><a href="#39660445">prev</a><span>|</span><a href="#39658595">next</a><span>|</span><label class="collapse" for="c-39660080">[-]</label><label class="expand" for="c-39660080">[4 more]</label></div><br/><div class="children"><div class="content">&gt; ...listing any given prefix is essentially constant time: I can take any given string, in a bucket with 100 billion objects, and say “give me the next 1000 keys alphabetically that come after this random string”.<p>I&#x27;m not sure we agree on the definition of &quot;constant time&quot; here. Just because you get 1000 keys in one network call doesn&#x27;t imply anything about the complexity of the backend!</div><br/><div id="39660151" class="c"><input type="checkbox" id="c-39660151" checked=""/><div class="controls bullet"><span class="by">orf</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39660080">parent</a><span>|</span><a href="#39658595">next</a><span>|</span><label class="collapse" for="c-39660151">[-]</label><label class="expand" for="c-39660151">[3 more]</label></div><br/><div class="children"><div class="content">Constant time irregardless of the number of objects in the bucket and irregardless of the initial starting position of your list request.</div><br/><div id="39660317" class="c"><input type="checkbox" id="c-39660317" checked=""/><div class="controls bullet"><span class="by">hobobaggins</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39660151">parent</a><span>|</span><a href="#39658595">next</a><span>|</span><label class="collapse" for="c-39660317">[-]</label><label class="expand" for="c-39660317">[2 more]</label></div><br/><div class="children"><div class="content">The technical implementation is indeed impressive that it operates more-or-less within constant time, but probably very few use cases actually fit that narrow window, so this technical strength is moot when it comes to actual usage.<p>Since each request is dependent upon the position received in the last request, 1000 arbitrary keys on your 3rd or 1000th attempt doesn&#x27;t really help unless you found your needle in the haystack in <i>that</i> request (and in that case the rest of that 1000 key listing was wasted.)</div><br/><div id="39660567" class="c"><input type="checkbox" id="c-39660567" checked=""/><div class="controls bullet"><span class="by">orf</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39660317">parent</a><span>|</span><a href="#39658595">next</a><span>|</span><label class="collapse" for="c-39660567">[-]</label><label class="expand" for="c-39660567">[1 more]</label></div><br/><div class="children"><div class="content">You’re assuming you’re paginating through all objects from start to finish.<p>A request to list objects under “foo&#x2F;“ is a request to list all objects starting with “foo&#x2F;“, which is constant time irregardless of the number of keys before. Same applies for “foo&#x2F;bar-“, or any other list request for any given prefix. There are no directories on s3.</div><br/></div></div></div></div></div></div></div></div><div id="39658595" class="c"><input type="checkbox" id="c-39658595" checked=""/><div class="controls bullet"><span class="by">adrian_b</span><span>|</span><a href="#39658507">parent</a><span>|</span><a href="#39660080">prev</a><span>|</span><a href="#39658677">next</a><span>|</span><label class="collapse" for="c-39658595">[-]</label><label class="expand" for="c-39658595">[12 more]</label></div><br/><div class="children"><div class="content">Since 30 years ago (starting with XFS in 1993, which was inspired by HPFS) all the good UNIX file systems implement the directories as some kind of B trees.<p>Therefore they do not get slower proportional to the number of entries and listing based on file prefixes is extremely fast.</div><br/><div id="39658820" class="c"><input type="checkbox" id="c-39658820" checked=""/><div class="controls bullet"><span class="by">nh2</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39658595">parent</a><span>|</span><a href="#39659906">next</a><span>|</span><label class="collapse" for="c-39658820">[-]</label><label class="expand" for="c-39658820">[1 more]</label></div><br/><div class="children"><div class="content">&gt; listing based on file prefixes is extremely fast<p>This functionality does not exist to my knowledge.<p>ext4 and XFS return directory entries in pseudo-random order (due to hashing), not lexicographically.<p>For an example, see e.g. <a href="https:&#x2F;&#x2F;righteousit.wordpress.com&#x2F;2022&#x2F;01&#x2F;13&#x2F;xfs-part-6-btree-directories&#x2F;" rel="nofollow">https:&#x2F;&#x2F;righteousit.wordpress.com&#x2F;2022&#x2F;01&#x2F;13&#x2F;xfs-part-6-btre...</a><p>If you know a way to return lexicographical order directly from the file system, without the need to sort, please link it.</div><br/></div></div><div id="39659906" class="c"><input type="checkbox" id="c-39659906" checked=""/><div class="controls bullet"><span class="by">kbolino</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39658595">parent</a><span>|</span><a href="#39658820">prev</a><span>|</span><a href="#39658620">next</a><span>|</span><label class="collapse" for="c-39659906">[-]</label><label class="expand" for="c-39659906">[1 more]</label></div><br/><div class="children"><div class="content">Resolving random file system paths still gets slower proportional to their <i>depth</i>, which is not the case for S3, where the prefix is on the entire object key and not just the &quot;basename&quot; part of it, like in a filesystem.</div><br/></div></div><div id="39658620" class="c"><input type="checkbox" id="c-39658620" checked=""/><div class="controls bullet"><span class="by">orf</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39658595">parent</a><span>|</span><a href="#39659906">prev</a><span>|</span><a href="#39658677">next</a><span>|</span><label class="collapse" for="c-39658620">[-]</label><label class="expand" for="c-39658620">[9 more]</label></div><br/><div class="children"><div class="content">Yes they do. What APIs does Linux offer that allows you to list a directories contents alphabetically <i>starting at a specific filename</i> in constant time? You have to iterate the <i>directory</i> contents.<p>You can maybe use “d_off” with readdir in some way, but that’s specific to the filesystem. There’s no portable way to do this with POSIX.<p>Regardless of if you can do it with a single directory, you can’t do it for all files recursively under a given prefix. You can’t just ignore directories, or say that “for this list request, ‘-‘ is my directory separator”.<p>The use of b-trees in file systems is completely beside the point.</div><br/><div id="39658646" class="c"><input type="checkbox" id="c-39658646" checked=""/><div class="controls bullet"><span class="by">adrian_b</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39658620">parent</a><span>|</span><a href="#39658677">next</a><span>|</span><label class="collapse" for="c-39658646">[-]</label><label class="expand" for="c-39658646">[8 more]</label></div><br/><div class="children"><div class="content">The POSIX API is indeed even older, so it is not helpful.<p>But as you say, there are filesystem-specific methods or operating-system specific methods to reach the true performance of the filesystem.<p>It is likely that for maximum performance one would have to write custom directory search functions using directly the Linux syscalls, instead of using the standard libc functions, but I would rather do that instead of paying for S3 or something like it.</div><br/><div id="39658669" class="c"><input type="checkbox" id="c-39658669" checked=""/><div class="controls bullet"><span class="by">orf</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39658646">parent</a><span>|</span><a href="#39658745">next</a><span>|</span><label class="collapse" for="c-39658669">[-]</label><label class="expand" for="c-39658669">[6 more]</label></div><br/><div class="children"><div class="content">Yes. You could also just use a SQLite table with two columns (path, contents), then just query that. Or do any number of other things.<p>The question isn’t if it’s possible, because of course it is, the question is if it’s portable and well supported with the POSIX interface. Because if it’s not, then…</div><br/><div id="39658697" class="c"><input type="checkbox" id="c-39658697" checked=""/><div class="controls bullet"><span class="by">anamexis</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39658669">parent</a><span>|</span><a href="#39658745">next</a><span>|</span><label class="collapse" for="c-39658697">[-]</label><label class="expand" for="c-39658697">[5 more]</label></div><br/><div class="children"><div class="content">&gt; The question isn’t if it’s possible, because of course it is, the question is if it’s portable and well supported with the POSIX interface. Because if it’s not, then…<p>Where did this goalpost come from? S3 is not portable or POSIX compliant.</div><br/><div id="39658743" class="c"><input type="checkbox" id="c-39658743" checked=""/><div class="controls bullet"><span class="by">orf</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39658697">parent</a><span>|</span><a href="#39658745">next</a><span>|</span><label class="collapse" for="c-39658743">[-]</label><label class="expand" for="c-39658743">[4 more]</label></div><br/><div class="children"><div class="content">From the article we&#x27;re commenting on, which is comparing the interface of S3 to the POSIX interface. Not any given filesystem + platform specific interface.</div><br/><div id="39658809" class="c"><input type="checkbox" id="c-39658809" checked=""/><div class="controls bullet"><span class="by">anamexis</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39658743">parent</a><span>|</span><a href="#39658745">next</a><span>|</span><label class="collapse" for="c-39658809">[-]</label><label class="expand" for="c-39658809">[3 more]</label></div><br/><div class="children"><div class="content">The article does not mention POSIX, or anything about listing files, at all.</div><br/><div id="39659182" class="c"><input type="checkbox" id="c-39659182" checked=""/><div class="controls bullet"><span class="by">orf</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39658809">parent</a><span>|</span><a href="#39658954">next</a><span>|</span><label class="collapse" for="c-39659182">[-]</label><label class="expand" for="c-39659182">[1 more]</label></div><br/><div class="children"><div class="content">It mistakenly mentions UNIX whilst referencing the POSIX filesystem API, and I literally quoted where it talks about listing in my original comment.</div><br/></div></div><div id="39658954" class="c"><input type="checkbox" id="c-39658954" checked=""/><div class="controls bullet"><span class="by">zaphar</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39658809">parent</a><span>|</span><a href="#39659182">prev</a><span>|</span><a href="#39658745">next</a><span>|</span><label class="collapse" for="c-39658954">[-]</label><label class="expand" for="c-39658954">[1 more]</label></div><br/><div class="children"><div class="content">The article starts out by making a comparison between the posix api filesystem calls and S3&#x27;s api. The context is very much a comparison between those two api surface areas.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="39658745" class="c"><input type="checkbox" id="c-39658745" checked=""/><div class="controls bullet"><span class="by">justincormack</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39658646">parent</a><span>|</span><a href="#39658669">prev</a><span>|</span><a href="#39658677">next</a><span>|</span><label class="collapse" for="c-39658745">[-]</label><label class="expand" for="c-39658745">[1 more]</label></div><br/><div class="children"><div class="content">There are no specific syscalls that you can use for this. The libc functions and the syscalls are extremely similar.</div><br/></div></div></div></div></div></div></div></div><div id="39658677" class="c"><input type="checkbox" id="c-39658677" checked=""/><div class="controls bullet"><span class="by">aeyes</span><span>|</span><a href="#39658507">parent</a><span>|</span><a href="#39658595">prev</a><span>|</span><a href="#39658685">next</a><span>|</span><label class="collapse" for="c-39658677">[-]</label><label class="expand" for="c-39658677">[1 more]</label></div><br/><div class="children"><div class="content">And if for some reason you need a complete listing along with object sizes and other attributes you can get one every 24 hours with S3 inventory report.<p>That has always been good enough for me.</div><br/></div></div><div id="39658685" class="c"><input type="checkbox" id="c-39658685" checked=""/><div class="controls bullet"><span class="by">tjoff</span><span>|</span><a href="#39658507">parent</a><span>|</span><a href="#39658677">prev</a><span>|</span><a href="#39658602">next</a><span>|</span><label class="collapse" for="c-39658685">[-]</label><label class="expand" for="c-39658685">[21 more]</label></div><br/><div class="children"><div class="content">Is listing really such a key feature that people use it as a database to find objects?<p>Have not used S3, but that is not how I imagined using it.</div><br/><div id="39658730" class="c"><input type="checkbox" id="c-39658730" checked=""/><div class="controls bullet"><span class="by">orf</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39658685">parent</a><span>|</span><a href="#39659187">next</a><span>|</span><label class="collapse" for="c-39658730">[-]</label><label class="expand" for="c-39658730">[10 more]</label></div><br/><div class="children"><div class="content">Sure. It&#x27;s kind of an index - limited to prefix-only searching, but useful.<p>Say you store uploads associated with a company and a user. You&#x27;d maybe naively store them as `[company-uuid]&#x2F;[user-id].[timestamp]`.<p>If you need to list a given users (123) uploads after a given date, you&#x27;d list keys after `[company-uuid]&#x2F;123.[date]`. If you need to list all users uploads, you&#x27;d list `[company-uuid]&#x2F;123.`. If you need to get a set of all users who have photos, you&#x27;d list `[company-uuid]&#x2F;` with a Delimiter set to `.`<p>The point is that it&#x27;s flexible and with a bit of thought it allows you to &quot;remove all a users uploads between two dates&quot;, &quot;remove all a companies uploads&quot; or &quot;remove all a users uploads&quot; with a single call. Or whatever specific stuff is important to your use-case, that might otherwise need a separate DB.<p>It&#x27;s not perfect - you can&#x27;t reverse the listing (i.e you can&#x27;t get the <i>latest</i> photo for a given user by sorting descending for example), and needs some thought about your key structure.</div><br/><div id="39658817" class="c"><input type="checkbox" id="c-39658817" checked=""/><div class="controls bullet"><span class="by">tjoff</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39658730">parent</a><span>|</span><a href="#39659187">next</a><span>|</span><label class="collapse" for="c-39658817">[-]</label><label class="expand" for="c-39658817">[9 more]</label></div><br/><div class="children"><div class="content">But surely you need to track that elsewhere anyway?<p>That some niche edge-case runs efficiently doesn&#x27;t sound like a defining feature of S3. On the contrary many common operations map terrible to S3, so you kind of need the logic to be elsewhere.</div><br/><div id="39659226" class="c"><input type="checkbox" id="c-39659226" checked=""/><div class="controls bullet"><span class="by">orf</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39658817">parent</a><span>|</span><a href="#39659790">next</a><span>|</span><label class="collapse" for="c-39659226">[-]</label><label class="expand" for="c-39659226">[3 more]</label></div><br/><div class="children"><div class="content">My overall point can be summarised as this:<p>- Listing things is a very common operation to do.<p>- The POSIX api and the directory&#x2F;file hierarchy it provides is a restrictive one.<p>- S3 does not suffer from this, you can recursively list and group keys into directories at “list time”.<p>- If you find yourself needing to list gigantic numbers of keys in one go, you can do better by only listing a subset. S3 isn’t a filesystem, you shouldn’t need to list 1k+ keys sequentially apart from during maintenance tasks.<p>- This is actually quite fast, compared to alternatives.<p>Whether or not you see a use case for this is sort of irrelevant: they exist. it’s what allows you to easily put data into s3 and flexibly group&#x2F;scan it by specific attributes.</div><br/><div id="39659395" class="c"><input type="checkbox" id="c-39659395" checked=""/><div class="controls bullet"><span class="by">tjoff</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39659226">parent</a><span>|</span><a href="#39659790">next</a><span>|</span><label class="collapse" for="c-39659395">[-]</label><label class="expand" for="c-39659395">[2 more]</label></div><br/><div class="children"><div class="content">Listing things is very common, so why would you outsource that to S3 when all your bookkeeping is elsewhere? It&#x27;s not like you would ever rely on the POSIX API for that anyway, even for when your files actually are on a POSIX filesystem.<p>For sure, for maintenance tasks etc. it sounds quite useful. And good hygiene with prefixes sounds like a sane idea. But listing being a critical part of what &quot;makes S3 useful&quot;? That seems like an huge stretch that your points don&#x27;t seem to address.</div><br/><div id="39661189" class="c"><input type="checkbox" id="c-39661189" checked=""/><div class="controls bullet"><span class="by">orf</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39659395">parent</a><span>|</span><a href="#39659790">next</a><span>|</span><label class="collapse" for="c-39661189">[-]</label><label class="expand" for="c-39661189">[1 more]</label></div><br/><div class="children"><div class="content">&gt; It&#x27;s not like you would ever rely on the POSIX API for that anyway, even for when your files actually are on a POSIX filesystem.<p>Because there <i>is no</i> POSIX api for this. Depending on your requirements and query patterns, you may not need a completely separate database that you need to keep in sync.</div><br/></div></div></div></div></div></div><div id="39659790" class="c"><input type="checkbox" id="c-39659790" checked=""/><div class="controls bullet"><span class="by">kbolino</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39658817">parent</a><span>|</span><a href="#39659226">prev</a><span>|</span><a href="#39659187">next</a><span>|</span><label class="collapse" for="c-39659790">[-]</label><label class="expand" for="c-39659790">[5 more]</label></div><br/><div class="children"><div class="content">&gt; But surely you need to track that elsewhere anyway?<p>Why? If the S3 structure and listing is sufficient, I don&#x27;t need to store anything else anywhere else.<p>Many use cases may involve other requirements that S3 can&#x27;t meet, such as being able to find the same object via different keys, or being able to search through the metadata fields. However, if the requirements match up with S3&#x27;s structure, then additional services are unnecessary and keeping them in sync with S3 is more hassle than it&#x27;s worth.</div><br/><div id="39660008" class="c"><input type="checkbox" id="c-39660008" checked=""/><div class="controls bullet"><span class="by">tjoff</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39659790">parent</a><span>|</span><a href="#39659187">next</a><span>|</span><label class="collapse" for="c-39660008">[-]</label><label class="expand" for="c-39660008">[4 more]</label></div><br/><div class="children"><div class="content">I agree, but something as simple (in functionality) as that ought to be an edge-case. Not a defining feature of S3.</div><br/><div id="39660197" class="c"><input type="checkbox" id="c-39660197" checked=""/><div class="controls bullet"><span class="by">orf</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39660008">parent</a><span>|</span><a href="#39660152">next</a><span>|</span><label class="collapse" for="c-39660197">[-]</label><label class="expand" for="c-39660197">[2 more]</label></div><br/><div class="children"><div class="content">It’s fundamental to how S3 works and its ability to scale, so it is a defining feature of S3.<p>If you think wider, a bucket itself is just a prefix.</div><br/><div id="39662486" class="c"><input type="checkbox" id="c-39662486" checked=""/><div class="controls bullet"><span class="by">tjoff</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39660197">parent</a><span>|</span><a href="#39660152">next</a><span>|</span><label class="collapse" for="c-39662486">[-]</label><label class="expand" for="c-39662486">[1 more]</label></div><br/><div class="children"><div class="content">From amazons perspective, sure!<p>But that&#x27;s not what we are discussing.</div><br/></div></div></div></div><div id="39660152" class="c"><input type="checkbox" id="c-39660152" checked=""/><div class="controls bullet"><span class="by">dekhn</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39660008">parent</a><span>|</span><a href="#39660197">prev</a><span>|</span><a href="#39659187">next</a><span>|</span><label class="collapse" for="c-39660152">[-]</label><label class="expand" for="c-39660152">[1 more]</label></div><br/><div class="children"><div class="content">it&#x27;s a property of the system that I, as an architect, would seriously consider as part of my system&#x27;s design.  I&#x27;ve worked with many systems where iterating over items in order starting from a prefix is extremely cheap (sstables).</div><br/></div></div></div></div></div></div></div></div></div></div><div id="39659187" class="c"><input type="checkbox" id="c-39659187" checked=""/><div class="controls bullet"><span class="by">belter</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39658685">parent</a><span>|</span><a href="#39658730">prev</a><span>|</span><a href="#39658602">next</a><span>|</span><label class="collapse" for="c-39659187">[-]</label><label class="expand" for="c-39659187">[10 more]</label></div><br/><div class="children"><div class="content">No. The standard practice is to use a DynamoDB table as the index for your objects in S3.<p>This article misunderstood S3 and could as well have the title: &quot;An Airplane is not a Car&quot; :-)</div><br/><div id="39660006" class="c"><input type="checkbox" id="c-39660006" checked=""/><div class="controls bullet"><span class="by">macintux</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39659187">parent</a><span>|</span><a href="#39661891">next</a><span>|</span><label class="collapse" for="c-39660006">[-]</label><label class="expand" for="c-39660006">[6 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t know that you can characterize that as a &quot;standard practice&quot;.<p>Maybe it&#x27;s widespread, but I&#x27;ve not encountered it.</div><br/><div id="39660245" class="c"><input type="checkbox" id="c-39660245" checked=""/><div class="controls bullet"><span class="by">belter</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39660006">parent</a><span>|</span><a href="#39665016">next</a><span>|</span><label class="collapse" for="c-39660245">[-]</label><label class="expand" for="c-39660245">[4 more]</label></div><br/><div class="children"><div class="content">&quot;Building and Maintaining an Amazon S3 Metadata Index without Servers&quot; - <a href="https:&#x2F;&#x2F;aws.amazon.com&#x2F;pt&#x2F;blogs&#x2F;big-data&#x2F;building-and-maintaining-an-amazon-s3-metadata-index-without-servers&#x2F;" rel="nofollow">https:&#x2F;&#x2F;aws.amazon.com&#x2F;pt&#x2F;blogs&#x2F;big-data&#x2F;building-and-mainta...</a><p>Here is the architecture of Amazon Drive and the storage of metadata.<p>&quot;AWS re:Invent 2014 | (ARC309) Building and Scaling Amazon Cloud Drive to Millions of Users&quot; - <a href="https:&#x2F;&#x2F;youtu.be&#x2F;R2pKtmhyNoA" rel="nofollow">https:&#x2F;&#x2F;youtu.be&#x2F;R2pKtmhyNoA</a><p>And you can see the use here at correct time: <a href="https:&#x2F;&#x2F;youtu.be&#x2F;R2pKtmhyNoA?t=546" rel="nofollow">https:&#x2F;&#x2F;youtu.be&#x2F;R2pKtmhyNoA?t=546</a></div><br/><div id="39660921" class="c"><input type="checkbox" id="c-39660921" checked=""/><div class="controls bullet"><span class="by">ianburrell</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39660245">parent</a><span>|</span><a href="#39665016">next</a><span>|</span><label class="collapse" for="c-39660921">[-]</label><label class="expand" for="c-39660921">[3 more]</label></div><br/><div class="children"><div class="content">That article is old. DynamoDB was used because of the old, weak consistency model of S3. Writes were atomic, but lists could return old results so needed consistent list of objects.<p>But in 2020, S3 changed to strong consistency model. There is no need to use DynamoDB now.</div><br/><div id="39663758" class="c"><input type="checkbox" id="c-39663758" checked=""/><div class="controls bullet"><span class="by">belter</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39660921">parent</a><span>|</span><a href="#39665016">next</a><span>|</span><label class="collapse" for="c-39663758">[-]</label><label class="expand" for="c-39663758">[2 more]</label></div><br/><div class="children"><div class="content">The problem was not the eventual consistency model, was the speed of the object list.<p>&quot;...Finding objects based on other attributes, however, requires doing a linear search using the LIST operation. Because each listing can return at most 1000 keys, it may require many requests before finding the object. Because of these additional requests, implementing attribute-based queries in S3 alone can be challenging...&quot;</div><br/><div id="39663812" class="c"><input type="checkbox" id="c-39663812" checked=""/><div class="controls bullet"><span class="by">orf</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39663758">parent</a><span>|</span><a href="#39665016">next</a><span>|</span><label class="collapse" for="c-39663812">[-]</label><label class="expand" for="c-39663812">[1 more]</label></div><br/><div class="children"><div class="content">It was both actually, but more for the listing issue. Netflix built a lot of tooling around this.<p>But yeah: things like filtering on tags or created at dates requires another approach.</div><br/></div></div></div></div></div></div></div></div><div id="39665016" class="c"><input type="checkbox" id="c-39665016" checked=""/><div class="controls bullet"><span class="by">mr_toad</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39660006">parent</a><span>|</span><a href="#39660245">prev</a><span>|</span><a href="#39661891">next</a><span>|</span><label class="collapse" for="c-39665016">[-]</label><label class="expand" for="c-39665016">[1 more]</label></div><br/><div class="children"><div class="content">Hive stores metadata in a relational database.  So does Snowflake.</div><br/></div></div></div></div><div id="39661891" class="c"><input type="checkbox" id="c-39661891" checked=""/><div class="controls bullet"><span class="by">fijiaarone</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39659187">parent</a><span>|</span><a href="#39660006">prev</a><span>|</span><a href="#39658602">next</a><span>|</span><label class="collapse" for="c-39661891">[-]</label><label class="expand" for="c-39661891">[3 more]</label></div><br/><div class="children"><div class="content">So in reality S3 takes about 2 seconds to retrieve a single file, under ideal conditions. 1 second round trip for the request to DynamoDB to get the object key of the file and 1 second round trip to S3 to get the file contents (assuming no CPU cost on the search because you’re getting the key by ID from the DynamoDB in a flat single table store. And that the file has no network IO because it is a trivial number of bytes, so the HTTP header overwhelmed the content.)<p>I know what you’re thinking — 2 seconds, that’s faster than I can type the 300 character file key with its pseudo prefixes)!<p>Ah, but what if you wanted to get 2 files from S3?</div><br/><div id="39664336" class="c"><input type="checkbox" id="c-39664336" checked=""/><div class="controls bullet"><span class="by">deathanatos</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39661891">parent</a><span>|</span><a href="#39663817">next</a><span>|</span><label class="collapse" for="c-39664336">[-]</label><label class="expand" for="c-39664336">[1 more]</label></div><br/><div class="children"><div class="content">… S3&#x27;s response time is nowhere near 2 seconds. (Or even 1 second.) Like a sibling poster says, 50ms is a much more realistic ballpark for TTFB.</div><br/></div></div><div id="39663817" class="c"><input type="checkbox" id="c-39663817" checked=""/><div class="controls bullet"><span class="by">orf</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39661891">parent</a><span>|</span><a href="#39664336">prev</a><span>|</span><a href="#39658602">next</a><span>|</span><label class="collapse" for="c-39663817">[-]</label><label class="expand" for="c-39663817">[1 more]</label></div><br/><div class="children"><div class="content">2 seconds is a nuts response time, but I guess it depends entirely on your file size. TTFB is usually 50ms.</div><br/></div></div></div></div></div></div></div></div><div id="39658602" class="c"><input type="checkbox" id="c-39658602" checked=""/><div class="controls bullet"><span class="by">jacobsimon</span><span>|</span><a href="#39658507">parent</a><span>|</span><a href="#39658685">prev</a><span>|</span><a href="#39658980">next</a><span>|</span><label class="collapse" for="c-39658602">[-]</label><label class="expand" for="c-39658602">[10 more]</label></div><br/><div class="children"><div class="content">What is it about S3 that enables this speed, and why can’t traditional Unix file systems do the same?</div><br/><div id="39658656" class="c"><input type="checkbox" id="c-39658656" checked=""/><div class="controls bullet"><span class="by">orf</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39658602">parent</a><span>|</span><a href="#39658980">next</a><span>|</span><label class="collapse" for="c-39658656">[-]</label><label class="expand" for="c-39658656">[9 more]</label></div><br/><div class="children"><div class="content">S3 doesn’t have directories, it could be thought of a flat + sorted list of keys.<p>UNIX (and all operating systems) differentiate between a file and a directory. To list the contents of a directory, you need to make an explicit call. That call might return files or directories.<p>So to list all files recursively, you need to list, sort, check if an entry is a directory, recurse”. This isn’t great.</div><br/><div id="39660737" class="c"><input type="checkbox" id="c-39660737" checked=""/><div class="controls bullet"><span class="by">mechanicalpulse</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39658656">parent</a><span>|</span><a href="#39658707">next</a><span>|</span><label class="collapse" for="c-39660737">[-]</label><label class="expand" for="c-39660737">[1 more]</label></div><br/><div class="children"><div class="content">Isn&#x27;t that a limitation imposed by the POSIX APIs, though, as a direct consequence of the interface&#x27;s representation of hierarchical filesystems as trees?  As you&#x27;ve illustrated, that necessitates walking the tree.  Many tools, I suppose, walk the tree via a single thread, further serializing the process.  In an admittedly haphazard test, I ran `find(1)` on ext4, xfs, and zfs filesystems and saw only one thread.<p>I imagine there&#x27;s at least one POSIX-compatible file system out there that supports another, more performant method of dumping its internal metadata via some system call or another.  But then we would no longer be comparing the S3 and POSIX APIs.</div><br/></div></div><div id="39658707" class="c"><input type="checkbox" id="c-39658707" checked=""/><div class="controls bullet"><span class="by">bradleyjg</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39658656">parent</a><span>|</span><a href="#39660737">prev</a><span>|</span><a href="#39658980">next</a><span>|</span><label class="collapse" for="c-39658707">[-]</label><label class="expand" for="c-39658707">[7 more]</label></div><br/><div class="children"><div class="content">Code written against s3 is not portable either. It doesn’t support azure or gcp, much less some random proprietary cloud.</div><br/><div id="39659452" class="c"><input type="checkbox" id="c-39659452" checked=""/><div class="controls bullet"><span class="by">cuno</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39658707">parent</a><span>|</span><a href="#39658869">next</a><span>|</span><label class="collapse" for="c-39659452">[-]</label><label class="expand" for="c-39659452">[4 more]</label></div><br/><div class="children"><div class="content">Actually we&#x27;ve found it&#x27;s often much worse than that. Code written against AWS S3 using the AWS SDK often doesn&#x27;t work on a great many &quot;S3-compatible&quot; vendors (including on-prem versions). Although there&#x27;s documentation on S3, it&#x27;s vague in many ways, and the AWS SDKs rely on actual AWS behaviour. We&#x27;ve had to deal with a lot of commercial and cloud vendors that subtly break things. This includes giant public cloud companies. In one case a giant vendor only failed at high loads, making it appear to &quot;work&quot; until it didn&#x27;t, because its backoff response was not what the AWS SDK expected. It&#x27;s been a headache that we&#x27;ve had to deal for cunoFS, as well as making it work with GCP and Azure. At the big HPC conference Supercomputing 2023, when we mentioned supporting &quot;S3 compatible&quot; systems, we would often be told stories about applications not working with their supposedly &quot;S3 compatible&quot; one (from a mix of vendors).</div><br/><div id="39661420" class="c"><input type="checkbox" id="c-39661420" checked=""/><div class="controls bullet"><span class="by">yencabulator</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39659452">parent</a><span>|</span><a href="#39658869">next</a><span>|</span><label class="collapse" for="c-39661420">[-]</label><label class="expand" for="c-39661420">[3 more]</label></div><br/><div class="children"><div class="content">Back in 2011 when I was working on making Ceph&#x27;s RadosGW more S3-compatible, it was pretty common that AWS S3 behavior differed from their documentation too. I wrote a test suite to run against AWS and Ceph, just to figure out the differences. That lives on at <a href="https:&#x2F;&#x2F;github.com&#x2F;ceph&#x2F;s3-tests">https:&#x2F;&#x2F;github.com&#x2F;ceph&#x2F;s3-tests</a></div><br/><div id="39663823" class="c"><input type="checkbox" id="c-39663823" checked=""/><div class="controls bullet"><span class="by">orf</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39661420">parent</a><span>|</span><a href="#39658869">next</a><span>|</span><label class="collapse" for="c-39663823">[-]</label><label class="expand" for="c-39663823">[2 more]</label></div><br/><div class="children"><div class="content">What differences in behaviour from the AWS docs did you find, out of interest?</div><br/><div id="39663905" class="c"><input type="checkbox" id="c-39663905" checked=""/><div class="controls bullet"><span class="by">yencabulator</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39663823">parent</a><span>|</span><a href="#39658869">next</a><span>|</span><label class="collapse" for="c-39663905">[-]</label><label class="expand" for="c-39663905">[1 more]</label></div><br/><div class="children"><div class="content">What I can dig up today is that back in 2011, they documented that bucket names cannot look like IPv4 addresses and the character set was a-z0-9.-, but they failed to prevent 192.168.5.123 or _foo.<p>I recall there were more edge cases around HTTP headers, but they don&#x27;t seem to have been recorded as test cases -- it&#x27;s been too long for me to remember details, I may have simply ran out of time &#x2F; real world interop got good enough to prioritize something else.<p>2011 state, search for fails_on_aws:
<a href="https:&#x2F;&#x2F;github.com&#x2F;tv42&#x2F;s3-tests&#x2F;blob&#x2F;master&#x2F;s3tests&#x2F;functional&#x2F;test_s3.py">https:&#x2F;&#x2F;github.com&#x2F;tv42&#x2F;s3-tests&#x2F;blob&#x2F;master&#x2F;s3tests&#x2F;functio...</a><p>Current state, I can&#x27;t speak to the exact semantics of the annotations today, they could simply be annotating non-AWS features: <a href="https:&#x2F;&#x2F;github.com&#x2F;ceph&#x2F;s3-tests&#x2F;blob&#x2F;master&#x2F;s3tests&#x2F;functional&#x2F;test_s3.py">https:&#x2F;&#x2F;github.com&#x2F;ceph&#x2F;s3-tests&#x2F;blob&#x2F;master&#x2F;s3tests&#x2F;functio...</a></div><br/></div></div></div></div></div></div></div></div><div id="39658869" class="c"><input type="checkbox" id="c-39658869" checked=""/><div class="controls bullet"><span class="by">arcfour</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39658707">parent</a><span>|</span><a href="#39659452">prev</a><span>|</span><a href="#39658967">next</a><span>|</span><label class="collapse" for="c-39658869">[-]</label><label class="expand" for="c-39658869">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve seen several S3-compatible APIs and there are open-source clients. If anything it&#x27;s the de-facto standard.</div><br/></div></div><div id="39658967" class="c"><input type="checkbox" id="c-39658967" checked=""/><div class="controls bullet"><span class="by">zaphar</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39658707">parent</a><span>|</span><a href="#39658869">prev</a><span>|</span><a href="#39658980">next</a><span>|</span><label class="collapse" for="c-39658967">[-]</label><label class="expand" for="c-39658967">[1 more]</label></div><br/><div class="children"><div class="content">GCP storage buckets implement the S3 api. You can treat them like they were an s3 bucket. Something I do all the time.</div><br/></div></div></div></div></div></div></div></div><div id="39658980" class="c"><input type="checkbox" id="c-39658980" checked=""/><div class="controls bullet"><span class="by">hayd</span><span>|</span><a href="#39658507">parent</a><span>|</span><a href="#39658602">prev</a><span>|</span><a href="#39659330">next</a><span>|</span><label class="collapse" for="c-39658980">[-]</label><label class="expand" for="c-39658980">[1 more]</label></div><br/><div class="children"><div class="content">You can set up cloud watch events to trigger a lambda function to store meta data about the s3 file in a regular database. That way you can index it how you expect to list.<p>Very effective for our use case.</div><br/></div></div><div id="39659330" class="c"><input type="checkbox" id="c-39659330" checked=""/><div class="controls bullet"><span class="by">foldr</span><span>|</span><a href="#39658507">parent</a><span>|</span><a href="#39658980">prev</a><span>|</span><a href="#39659318">next</a><span>|</span><label class="collapse" for="c-39659330">[-]</label><label class="expand" for="c-39659330">[2 more]</label></div><br/><div class="children"><div class="content">&gt;What makes it useful is listing.<p>I think 99% of S3 usage just consists of retrieving objects with known keys. It seems odd to me to consider prefix listing as a key feature.</div><br/><div id="39659414" class="c"><input type="checkbox" id="c-39659414" checked=""/><div class="controls bullet"><span class="by">bostik</span><span>|</span><a href="#39658507">root</a><span>|</span><a href="#39659330">parent</a><span>|</span><a href="#39659318">next</a><span>|</span><label class="collapse" for="c-39659414">[-]</label><label class="expand" for="c-39659414">[1 more]</label></div><br/><div class="children"><div class="content">When you embed the relevant (not necessarily that of object creation) timestamp as a prefix, it sure becomes one. Whether that prefix is part of the &quot;path&quot; (object&#x2F;path&#x2F;prefix&#x2F;with&#x2F;&lt;4-digit year&#x2F;)&quot; or directly part of the basename (object&#x2F;path&#x2F;prefix&#x2F;to&#x2F;app-specific&#x2F;files&#x2F;&lt;4-digit year&gt;-&lt;2-digit month&gt;-....), being able to limit the search space server-side becomes incredibly useful.<p>You can try it yourself: list objects in a bucket prefix with <i>lots</i> of files, and measure the time it takes to list all of them vs. the time it takes to list only a subset of them that share a common prefix.</div><br/></div></div></div></div></div></div><div id="39660005" class="c"><input type="checkbox" id="c-39660005" checked=""/><div class="controls bullet"><span class="by">donatj</span><span>|</span><a href="#39658507">prev</a><span>|</span><a href="#39660833">next</a><span>|</span><label class="collapse" for="c-39660005">[-]</label><label class="expand" for="c-39660005">[30 more]</label></div><br/><div class="children"><div class="content">&gt; And listing files is slow. While the joy of Amazon S3 is that you can read and write at extremely, extremely, high bandwidths, listing out what is there is much much slower. Slower than a slow local filesystem.<p>I was taken aback by this recently. At my coworkers request, I was putting some work into a script we have to manage assets in S3. It has a cache for the file listing, and my coworker who wrote it sent me his pre-populated cache. My initial thought was “this can’t really be necessary” and started poking.<p>We have ~100,000 root level directories for our individual assets. Each of those have five or six directories with a handful of files. Probably less than a million files total, maybe 3 levels deep at its deepest.<p>Recursively listing these files takes literally fifteen minutes. I poked and prodded suggestions from stack overflow and ChatGPT at potential ways to speed up the process and got nothing notable. That’s absurdly slow. Why on earth is it so slow?<p>Why is this something Amazon has not fixed? From the outside really seems like they could slap some B-trees on the individual buckets and call it a day.<p>If it is a difficult problem, I’m sure it would be for fascinating reasons I’d love to hear about.</div><br/><div id="39660676" class="c"><input type="checkbox" id="c-39660676" checked=""/><div class="controls bullet"><span class="by">catlifeonmars</span><span>|</span><a href="#39660005">parent</a><span>|</span><a href="#39661534">next</a><span>|</span><label class="collapse" for="c-39660676">[-]</label><label class="expand" for="c-39660676">[7 more]</label></div><br/><div class="children"><div class="content">S3 is fundamentally a key value store. The fact that you can view objects in “directories” is nothing more than a prefix filter. It is not a file system and has no concept of directories.</div><br/><div id="39661029" class="c"><input type="checkbox" id="c-39661029" checked=""/><div class="controls bullet"><span class="by">anonymous-panda</span><span>|</span><a href="#39660005">root</a><span>|</span><a href="#39660676">parent</a><span>|</span><a href="#39660968">next</a><span>|</span><label class="collapse" for="c-39661029">[-]</label><label class="expand" for="c-39661029">[4 more]</label></div><br/><div class="children"><div class="content">Directories make up a hierarchical filesystem, but it’s not a necessary condition. A filesystem at its core is just a way of organizing files. If you’re storing and organizing files in s3 then it’s a filesystem for you. Saying it’s “fundamentally a key value store” like it’s something different is confusing because a filesystem is just a key value store of path to contents of file.<p>Indeed there’s every reason to believe that a modern file system would perform significantly faster if the hierarchy was implemented as a prefix filter than actually maintaining the hierarchical data structures (at least for most operations). You can guess that this might be the case that file creation is extremely slow on modern file systems (on the order of hundreds or maybe thousands per second on a modern NVME disk that can otherwise do millions of IOPs and listing the contents of an extremely large directory is exceedingly slow)</div><br/><div id="39661155" class="c"><input type="checkbox" id="c-39661155" checked=""/><div class="controls bullet"><span class="by">catlifeonmars</span><span>|</span><a href="#39660005">root</a><span>|</span><a href="#39661029">parent</a><span>|</span><a href="#39661124">next</a><span>|</span><label class="collapse" for="c-39661155">[-]</label><label class="expand" for="c-39661155">[2 more]</label></div><br/><div class="children"><div class="content">In context of the comment I was addressing, it’s clear that filesystem means more than just a key value store. I’d argue that this is generally true in common vernacular.</div><br/><div id="39662036" class="c"><input type="checkbox" id="c-39662036" checked=""/><div class="controls bullet"><span class="by">anonymous-panda</span><span>|</span><a href="#39660005">root</a><span>|</span><a href="#39661155">parent</a><span>|</span><a href="#39661124">next</a><span>|</span><label class="collapse" for="c-39662036">[-]</label><label class="expand" for="c-39662036">[1 more]</label></div><br/><div class="children"><div class="content">This is a technical website discussing the nuances of filesystems. Common vernacular is how you choose to define it but even the Wikipedia definition says that directories and hierarchy are just one property of some filesystems. That they became the dominant model on local machines doesn’t take away from the more general definition that can describe distributed filesystems.</div><br/></div></div></div></div><div id="39661124" class="c"><input type="checkbox" id="c-39661124" checked=""/><div class="controls bullet"><span class="by">senderista</span><span>|</span><a href="#39660005">root</a><span>|</span><a href="#39661029">parent</a><span>|</span><a href="#39661155">prev</a><span>|</span><a href="#39660968">next</a><span>|</span><label class="collapse" for="c-39661124">[-]</label><label class="expand" for="c-39661124">[1 more]</label></div><br/><div class="children"><div class="content">A real hierarchy makes global constraints easier to scale, e.g. globally unique names or hierarchical access controls. These policies only need to scale to a single node rather than to the whole namespace (via some sort of global index).</div><br/></div></div></div></div><div id="39660968" class="c"><input type="checkbox" id="c-39660968" checked=""/><div class="controls bullet"><span class="by">Spivak</span><span>|</span><a href="#39660005">root</a><span>|</span><a href="#39660676">parent</a><span>|</span><a href="#39661029">prev</a><span>|</span><a href="#39661534">next</a><span>|</span><label class="collapse" for="c-39660968">[-]</label><label class="expand" for="c-39660968">[2 more]</label></div><br/><div class="children"><div class="content">If I wanted to use S3 as a filesystem in the manner people are describing I would probably start looking at storing filesystem metadata in a sidecar database so you can get directory listings, permissions bits, xattrs and only have to round-trip to S3 when you need the content.</div><br/><div id="39661128" class="c"><input type="checkbox" id="c-39661128" checked=""/><div class="controls bullet"><span class="by">SOLAR_FIELDS</span><span>|</span><a href="#39660005">root</a><span>|</span><a href="#39660968">parent</a><span>|</span><a href="#39661534">next</a><span>|</span><label class="collapse" for="c-39661128">[-]</label><label class="expand" for="c-39661128">[1 more]</label></div><br/><div class="children"><div class="content">Isn&#x27;t this essentially what systems like Minio and SeaweedFS do with their S3 integrations&#x2F;mirroring&#x2F;caching? What you describe sounds a lot like SeaweedFS Filer when backed by S3</div><br/></div></div></div></div></div></div><div id="39661534" class="c"><input type="checkbox" id="c-39661534" checked=""/><div class="controls bullet"><span class="by">electroly</span><span>|</span><a href="#39660005">parent</a><span>|</span><a href="#39660676">prev</a><span>|</span><a href="#39660407">next</a><span>|</span><label class="collapse" for="c-39661534">[-]</label><label class="expand" for="c-39661534">[4 more]</label></div><br/><div class="children"><div class="content">The way that you said &quot;recursively&quot; and spent a lot of time describing &quot;directories&quot; and &quot;levels&quot; worries me. The fastest way to list objects in S3 wouldn&#x27;t involve recursion at all; you just list all objects under a prefix. If you&#x27;re using the path delimiter to pretend that S3 keys are a folder structure (they&#x27;re not) and go &quot;folder by folder&quot;, it&#x27;s going to be way slower. When calling ListObjectsV2, make sure you are NOT passing &quot;delimiter&quot;. The &quot;directories&quot; and &quot;levels&quot; have no impact on performance when you&#x27;re not using the delimiter functionality. Split the one list operation into multiple parallel lists on separate prefixes to attain any total time goal you&#x27;d like.</div><br/><div id="39662109" class="c"><input type="checkbox" id="c-39662109" checked=""/><div class="controls bullet"><span class="by">blakesley</span><span>|</span><a href="#39660005">root</a><span>|</span><a href="#39661534">parent</a><span>|</span><a href="#39661902">next</a><span>|</span><label class="collapse" for="c-39662109">[-]</label><label class="expand" for="c-39662109">[2 more]</label></div><br/><div class="children"><div class="content">All these comments saying merely &quot;S3 has no concept of directories&quot; without an explanation (or at least a link to an explanation) are pretty unhelpful, IMO. I dismissed your comment, but then I came upon this later one explaining why: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=39660445">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=39660445</a><p>After reading that, I now understand your comment.</div><br/><div id="39662782" class="c"><input type="checkbox" id="c-39662782" checked=""/><div class="controls bullet"><span class="by">electroly</span><span>|</span><a href="#39660005">root</a><span>|</span><a href="#39662109">parent</a><span>|</span><a href="#39661902">next</a><span>|</span><label class="collapse" for="c-39662782">[-]</label><label class="expand" for="c-39662782">[1 more]</label></div><br/><div class="children"><div class="content">I appreciate you sharing that point of view. There&#x27;s a &quot;curse of knowledge&quot; effect with AWS where its card-carrying proponents (myself included) lose perspective on how complex it actually is.</div><br/></div></div></div></div><div id="39661902" class="c"><input type="checkbox" id="c-39661902" checked=""/><div class="controls bullet"><span class="by">petters</span><span>|</span><a href="#39660005">root</a><span>|</span><a href="#39661534">parent</a><span>|</span><a href="#39662109">prev</a><span>|</span><a href="#39660407">next</a><span>|</span><label class="collapse" for="c-39661902">[-]</label><label class="expand" for="c-39661902">[1 more]</label></div><br/><div class="children"><div class="content">Yes, this is very good advice and will likely solve their problem</div><br/></div></div></div></div><div id="39660407" class="c"><input type="checkbox" id="c-39660407" checked=""/><div class="controls bullet"><span class="by">anonymous-panda</span><span>|</span><a href="#39660005">parent</a><span>|</span><a href="#39661534">prev</a><span>|</span><a href="#39661876">next</a><span>|</span><label class="collapse" for="c-39660407">[-]</label><label class="expand" for="c-39660407">[3 more]</label></div><br/><div class="children"><div class="content">I think it’s far more mundane a reason. You can list 10k objects per request and getting the next 10k requires the result of the previous request, so it’s all serial. That means to list 1M files, you’re looking at 100 back to back requests. Assuming a ping time of 50ms, that’s easily 5s of just going back and forth, not including the cost of doing the listing itself on a flat iteration. The cost of a 10k item list is about the cost of a write which is kinda slow. Additionally, I suspect each listing is a strongly consistent snapshot which adds to the cost of the operation (it can be hard to provide an inconsistent view).<p>I don’t think btrees would help unless you’re doing directory traversals, but even then I suspect that’s not that beneficial as your bottleneck is going to be the network operations and exposed operations. Ultimately, file listing isn’t that critical a use case and typically most use cases are accomplished through things like object lifecycles where you tell S3 what you want done and it does it efficiently at the FS layer for you.</div><br/><div id="39661122" class="c"><input type="checkbox" id="c-39661122" checked=""/><div class="controls bullet"><span class="by">tsimionescu</span><span>|</span><a href="#39660005">root</a><span>|</span><a href="#39660407">parent</a><span>|</span><a href="#39661876">next</a><span>|</span><label class="collapse" for="c-39661122">[-]</label><label class="expand" for="c-39661122">[2 more]</label></div><br/><div class="children"><div class="content">That&#x27;s 5s of a 15m duration. I don&#x27;t think it matters in the least.</div><br/><div id="39662017" class="c"><input type="checkbox" id="c-39662017" checked=""/><div class="controls bullet"><span class="by">anonymous-panda</span><span>|</span><a href="#39660005">root</a><span>|</span><a href="#39661122">parent</a><span>|</span><a href="#39661876">next</a><span>|</span><label class="collapse" for="c-39662017">[-]</label><label class="expand" for="c-39662017">[1 more]</label></div><br/><div class="children"><div class="content">Depends how you’re iterating. If your iterating by hierarchy level, then you could easily see this being several orders of magnitude more requests.</div><br/></div></div></div></div></div></div><div id="39661876" class="c"><input type="checkbox" id="c-39661876" checked=""/><div class="controls bullet"><span class="by">jameshart</span><span>|</span><a href="#39660005">parent</a><span>|</span><a href="#39660407">prev</a><span>|</span><a href="#39660900">next</a><span>|</span><label class="collapse" for="c-39661876">[-]</label><label class="expand" for="c-39661876">[5 more]</label></div><br/><div class="children"><div class="content">A fun corollary of this issue:<p><i>Deleting</i> an S3 bucket is nontrivial!<p>You can&#x27;t delete a bucket with objects in it. And you can&#x27;t just tell S3 to delete all the objects. You need to send individual API requests to S3 to delete each object. Which means sending requests to S3 to list out the objects, 1000 at a time. Which takes time. And those list calls cost money to execute.<p>This is a good summary of the situation: <a href="https:&#x2F;&#x2F;cloudcasts.io&#x2F;article&#x2F;deleting-an-s3-bucket-costs-money" rel="nofollow">https:&#x2F;&#x2F;cloudcasts.io&#x2F;article&#x2F;deleting-an-s3-bucket-costs-mo...</a><p>The fastest way to quickly dispose of an S3 bucket turns out to be to <i>delete the AWS account it belongs to</i>.</div><br/><div id="39661997" class="c"><input type="checkbox" id="c-39661997" checked=""/><div class="controls bullet"><span class="by">electroly</span><span>|</span><a href="#39660005">root</a><span>|</span><a href="#39661876">parent</a><span>|</span><a href="#39661956">next</a><span>|</span><label class="collapse" for="c-39661997">[-]</label><label class="expand" for="c-39661997">[3 more]</label></div><br/><div class="children"><div class="content">No, don&#x27;t do that. Set up a lifecycle rule that expires all of the objects and wait 24 hours. You won&#x27;t pay for API calls and even the cost of storing the objects themselves is waived once they are marked for expiration.<p>The article has a mistake about this too: expirations do NOT count as lifecycle transitions and you don&#x27;t get charged as such. You will, of course, get charged if you prematurely delete objects that are in a storage class with a minimum storage duration that they haven&#x27;t reached yet. This is what they&#x27;re actually talking about when they mention Infrequent Access and other lower tiers.</div><br/><div id="39662046" class="c"><input type="checkbox" id="c-39662046" checked=""/><div class="controls bullet"><span class="by">jameshart</span><span>|</span><a href="#39660005">root</a><span>|</span><a href="#39661997">parent</a><span>|</span><a href="#39661956">next</a><span>|</span><label class="collapse" for="c-39662046">[-]</label><label class="expand" for="c-39662046">[2 more]</label></div><br/><div class="children"><div class="content">Still counts as nontrivial.</div><br/><div id="39662058" class="c"><input type="checkbox" id="c-39662058" checked=""/><div class="controls bullet"><span class="by">electroly</span><span>|</span><a href="#39660005">root</a><span>|</span><a href="#39662046">parent</a><span>|</span><a href="#39661956">next</a><span>|</span><label class="collapse" for="c-39662058">[-]</label><label class="expand" for="c-39662058">[1 more]</label></div><br/><div class="children"><div class="content">This is really easy; much easier than trying to delete them by hand. AWS does all the work for you. It takes longer to log into the AWS Management Console than it does to set up this lifecycle rule.</div><br/></div></div></div></div></div></div></div></div><div id="39660900" class="c"><input type="checkbox" id="c-39660900" checked=""/><div class="controls bullet"><span class="by">jamesrat</span><span>|</span><a href="#39660005">parent</a><span>|</span><a href="#39661876">prev</a><span>|</span><a href="#39660340">next</a><span>|</span><label class="collapse" for="c-39660900">[-]</label><label class="expand" for="c-39660900">[1 more]</label></div><br/><div class="children"><div class="content">I implemented a solution by threading the listing. Get the files in the root then spin a separate process to do the recursion for each directory.</div><br/></div></div><div id="39660340" class="c"><input type="checkbox" id="c-39660340" checked=""/><div class="controls bullet"><span class="by">returningfory2</span><span>|</span><a href="#39660005">parent</a><span>|</span><a href="#39660900">prev</a><span>|</span><a href="#39665045">next</a><span>|</span><label class="collapse" for="c-39660340">[-]</label><label class="expand" for="c-39660340">[4 more]</label></div><br/><div class="children"><div class="content">Are you performing list calls sequentially? If you have O(100k) directories and are doing O(100k) requests sequentially, 15 minutes works out at O(10ms) per request which doesn’t seem that bad? (assuming my math is correct…)</div><br/><div id="39661900" class="c"><input type="checkbox" id="c-39661900" checked=""/><div class="controls bullet"><span class="by">luhn</span><span>|</span><a href="#39660005">root</a><span>|</span><a href="#39660340">parent</a><span>|</span><a href="#39665045">next</a><span>|</span><label class="collapse" for="c-39661900">[-]</label><label class="expand" for="c-39661900">[3 more]</label></div><br/><div class="children"><div class="content">At risk of being pedantic, you seem to be using big O to mean “approximately” or “in the order of”, but that’s not what it means at all. Big O is an expression of the growth rate of a function. Any constant value has a growth rate of 0, so  O(100k) isn’t meaningful:  It’s exactly the same as O(1).</div><br/><div id="39663589" class="c"><input type="checkbox" id="c-39663589" checked=""/><div class="controls bullet"><span class="by">wetmore</span><span>|</span><a href="#39660005">root</a><span>|</span><a href="#39661900">parent</a><span>|</span><a href="#39663915">next</a><span>|</span><label class="collapse" for="c-39663589">[-]</label><label class="expand" for="c-39663589">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;re right technically, it&#x27;s an abuse of notation that isn&#x27;t uncommon. My physics profs would do it in college.</div><br/></div></div><div id="39663915" class="c"><input type="checkbox" id="c-39663915" checked=""/><div class="controls bullet"><span class="by">returningfory2</span><span>|</span><a href="#39660005">root</a><span>|</span><a href="#39661900">parent</a><span>|</span><a href="#39663589">prev</a><span>|</span><a href="#39665045">next</a><span>|</span><label class="collapse" for="c-39663915">[-]</label><label class="expand" for="c-39663915">[1 more]</label></div><br/><div class="children"><div class="content">Fair point, I guess the notation ~100k, ~10ms would be better.</div><br/></div></div></div></div></div></div><div id="39665045" class="c"><input type="checkbox" id="c-39665045" checked=""/><div class="controls bullet"><span class="by">inopinatus</span><span>|</span><a href="#39660005">parent</a><span>|</span><a href="#39660340">prev</a><span>|</span><a href="#39663295">next</a><span>|</span><label class="collapse" for="c-39665045">[-]</label><label class="expand" for="c-39665045">[1 more]</label></div><br/><div class="children"><div class="content">Take this opportunity to read the docs and discard assumptions. Enumerating buckets as though they’re directories will seem peculiar when you understand it is designed for billions of items and up. Index your objects separately, in whatever form makes sense to your application.</div><br/></div></div><div id="39663295" class="c"><input type="checkbox" id="c-39663295" checked=""/><div class="controls bullet"><span class="by">jasonwatkinspdx</span><span>|</span><a href="#39660005">parent</a><span>|</span><a href="#39665045">prev</a><span>|</span><a href="#39663301">next</a><span>|</span><label class="collapse" for="c-39663295">[-]</label><label class="expand" for="c-39663295">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Why is this something Amazon has not fixed?<p>It&#x27;s common to store metadata on DynamoDB where it can be queried, and just have whatever arbitrary links to the values in the buckets.</div><br/></div></div><div id="39663301" class="c"><input type="checkbox" id="c-39663301" checked=""/><div class="controls bullet"><span class="by">quasarj</span><span>|</span><a href="#39660005">parent</a><span>|</span><a href="#39663295">prev</a><span>|</span><a href="#39661022">next</a><span>|</span><label class="collapse" for="c-39663301">[-]</label><label class="expand" for="c-39663301">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not &quot;fixed&quot; because it&#x27;s not a problem. You&#x27;re just using it wrong.</div><br/></div></div><div id="39661022" class="c"><input type="checkbox" id="c-39661022" checked=""/><div class="controls bullet"><span class="by">perryizgr8</span><span>|</span><a href="#39660005">parent</a><span>|</span><a href="#39663301">prev</a><span>|</span><a href="#39664052">next</a><span>|</span><label class="collapse" for="c-39661022">[-]</label><label class="expand" for="c-39661022">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not a good model to think of S3 has having directories in a bucket. It&#x27;s all objects. The web interface has a visual way of representing prefixes separated by slashes. But that&#x27;s just a nice way to present the objects. Each object has a key, and that key can contain slashes, and you can think of each segment to be a directory for your ease of mind.<p>But that illusion breaks when you try to do operations you usually do with&#x2F;on directories.</div><br/></div></div><div id="39664052" class="c"><input type="checkbox" id="c-39664052" checked=""/><div class="controls bullet"><span class="by">paulddraper</span><span>|</span><a href="#39660005">parent</a><span>|</span><a href="#39661022">prev</a><span>|</span><a href="#39660833">next</a><span>|</span><label class="collapse" for="c-39664052">[-]</label><label class="expand" for="c-39664052">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Recursively listing these files<p>There&#x27;s no &quot;recursive&quot; nature to S3 buckets. &quot;Listing a directory&quot; is simply listing keys by a prefix.<p>So list by the upper-most prefix that you want. If you have 1,000,000 files, it will take 1,000 API calls to list everything.<p>If each call takes 1s (I have no idea what your latency to the S3 bucket region is), then it will indeed take 15 min.<p><a href="https:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;AmazonS3&#x2F;latest&#x2F;API&#x2F;API_ListObjectsV2.html" rel="nofollow">https:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;AmazonS3&#x2F;latest&#x2F;API&#x2F;API_ListObje...</a></div><br/></div></div></div></div><div id="39660833" class="c"><input type="checkbox" id="c-39660833" checked=""/><div class="controls bullet"><span class="by">somedudetbh</span><span>|</span><a href="#39660005">prev</a><span>|</span><a href="#39659881">next</a><span>|</span><label class="collapse" for="c-39660833">[-]</label><label class="expand" for="c-39660833">[3 more]</label></div><br/><div class="children"><div class="content">&gt; Amazon S3 is the original cloud technology: it came out in 2006. &quot;Objects&quot; were popular at the time and S3 was labelled an &quot;object store&quot;, but everyone really knows that S3 is for files. S3<p>Alternative theory: everyone who worked on this knew that it was not a filesystem and &quot;object store&quot; is a description intended to describe everything else pointed out in this post.<p>&quot;Objects were really popular&quot; is about objects as software component that combines executable code with local state. None of the original S3 examples were about &quot;hey you can serialize live objects to this store and then deserialize them into another live process!&quot; It was all like &quot;hey you know how you have all those static assets for your website...&quot;  &quot;Objects&quot; was used in this sense in databases at the time in the phrase &quot;binary large object&quot; or &quot;blob&quot;. S3 was like &quot;hey, stuff that doesn&#x27;t fit in your database, you know...objects...this is a store for them.&quot;<p>This is meant to describe precisely things like &quot;listing is slow&quot; because when S3 was designed, the launch usecases assumed an index of contents existed _somewhere else_, because, yeah, it&#x27;s not a filesystem. it&#x27;s an object store.</div><br/><div id="39662004" class="c"><input type="checkbox" id="c-39662004" checked=""/><div class="controls bullet"><span class="by">senderista</span><span>|</span><a href="#39660833">parent</a><span>|</span><a href="#39664064">next</a><span>|</span><label class="collapse" for="c-39662004">[-]</label><label class="expand" for="c-39662004">[1 more]</label></div><br/><div class="children"><div class="content">Yes, the author doesn&#x27;t seem to realize that &quot;object storage&quot; is a term of art in storage systems that has nothing to do with OOP.<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Object_storage" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Object_storage</a></div><br/></div></div><div id="39664064" class="c"><input type="checkbox" id="c-39664064" checked=""/><div class="controls bullet"><span class="by">paulddraper</span><span>|</span><a href="#39660833">parent</a><span>|</span><a href="#39662004">prev</a><span>|</span><a href="#39659881">next</a><span>|</span><label class="collapse" for="c-39664064">[-]</label><label class="expand" for="c-39664064">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, I&#x27;m really worried the author is confusing OOP with an object store.<p>To quote GCP:<p>&gt; Object storage is a data storage architecture for storing unstructured data, which sections data into units—objects—and stores them in a structurally flat data environment<p>&gt; <a href="https:&#x2F;&#x2F;cloud.google.com&#x2F;learn&#x2F;what-is-object-storage" rel="nofollow">https:&#x2F;&#x2F;cloud.google.com&#x2F;learn&#x2F;what-is-object-storage</a><p>That is (1) unstructured (2) flat organization (3) whole-item operations (read, write)</div><br/></div></div></div></div><div id="39659881" class="c"><input type="checkbox" id="c-39659881" checked=""/><div class="controls bullet"><span class="by">alphazard</span><span>|</span><a href="#39660833">prev</a><span>|</span><a href="#39658332">next</a><span>|</span><label class="collapse" for="c-39659881">[-]</label><label class="expand" for="c-39659881">[9 more]</label></div><br/><div class="children"><div class="content">S3 is not even files, and definitely not a filesystem.<p>The thing I would expect from a file abstraction is mutability.  I should be able to edit pieces of a file, grow it, shrink it, read and write at random offsets.  I shouldn&#x27;t have to go back up to the root, or a higher level concept once I have the file in hand. S3 provides a mutable listing of immutable objects, if I want to do any of the mutability business, I need to make a copy and re-upload.  As originally conceived, the file abstraction finds some sectors on disk, and presents them to the client as a contiguous buffer.  S3 solves a different problem.<p>Many people misinterpret the Good Idea from UNIX &quot;everything is a file&quot; to mean that everything should look like a contiguous virtual buffer.  That&#x27;s not what the real Good Idea is.  Really: everything can be listed in a directory, including directories.  There will be base leaves, which could be files, or any object the system wants to present to a process, and there will be recursive trees (which are directories).  The directories are what make the filesystem, not the type of a particular leaf.  Adding a new type of leaf, like a socket or a frame buffer, or whatever, is almost boring, and doesn&#x27;t erode the integrity of the real good idea.  Adding a different kind of container like a list, would make the structure of the filesystem more complex, and that <i>would</i> erode the conceptual integrity.<p>S3 doesn&#x27;t do any of these things, and that&#x27;s fine.  I just want a place to put things that won&#x27;t fit in the database, and know they won&#x27;t bitrot when I&#x27;m not looking.  The desire to make S3 look more like a filesystem comes from client misunderstanding of what it&#x27;s good at&#x2F;for, and poor product management indulging that misunderstanding instead of guarding the system from it.</div><br/><div id="39660871" class="c"><input type="checkbox" id="c-39660871" checked=""/><div class="controls bullet"><span class="by">thinkharderdev</span><span>|</span><a href="#39659881">parent</a><span>|</span><a href="#39659931">next</a><span>|</span><label class="collapse" for="c-39660871">[-]</label><label class="expand" for="c-39660871">[2 more]</label></div><br/><div class="children"><div class="content">&gt; S3 is not even files, and definitely not a filesystem.<p>I agree. To me the correct analog for S3 is a block storage device (a very weird one where blocks can be any size and can have a key associated with them) and not a filesystem. A filesystem is an abstraction that sits on top of a block storage device and so an &quot;S3 filesystem&quot; would have to be an abstraction that sits on top of S3 as the underlying block storage.</div><br/><div id="39664076" class="c"><input type="checkbox" id="c-39664076" checked=""/><div class="controls bullet"><span class="by">paulddraper</span><span>|</span><a href="#39659881">root</a><span>|</span><a href="#39660871">parent</a><span>|</span><a href="#39659931">next</a><span>|</span><label class="collapse" for="c-39664076">[-]</label><label class="expand" for="c-39664076">[1 more]</label></div><br/><div class="children"><div class="content">&gt; a very weird one where blocks can be any size and can have a key associated with them<p>That is a very weird one</div><br/></div></div></div></div><div id="39659931" class="c"><input type="checkbox" id="c-39659931" checked=""/><div class="controls bullet"><span class="by">akerl_</span><span>|</span><a href="#39659881">parent</a><span>|</span><a href="#39660871">prev</a><span>|</span><a href="#39658332">next</a><span>|</span><label class="collapse" for="c-39659931">[-]</label><label class="expand" for="c-39659931">[6 more]</label></div><br/><div class="children"><div class="content">How do read-only filesystems align with your definition?</div><br/><div id="39665758" class="c"><input type="checkbox" id="c-39665758" checked=""/><div class="controls bullet"><span class="by">mr_toad</span><span>|</span><a href="#39659881">root</a><span>|</span><a href="#39659931">parent</a><span>|</span><a href="#39664084">next</a><span>|</span><label class="collapse" for="c-39665758">[-]</label><label class="expand" for="c-39665758">[1 more]</label></div><br/><div class="children"><div class="content">You can read individual blocks on a read only file system.  With S3 you’re stuck with range requests which are much larger.</div><br/></div></div><div id="39664084" class="c"><input type="checkbox" id="c-39664084" checked=""/><div class="controls bullet"><span class="by">paulddraper</span><span>|</span><a href="#39659881">root</a><span>|</span><a href="#39659931">parent</a><span>|</span><a href="#39665758">prev</a><span>|</span><a href="#39661445">next</a><span>|</span><label class="collapse" for="c-39664084">[-]</label><label class="expand" for="c-39664084">[1 more]</label></div><br/><div class="children"><div class="content">All of the read stuff still applies (list, open, read, seek).</div><br/></div></div><div id="39661445" class="c"><input type="checkbox" id="c-39661445" checked=""/><div class="controls bullet"><span class="by">yencabulator</span><span>|</span><a href="#39659881">root</a><span>|</span><a href="#39659931">parent</a><span>|</span><a href="#39664084">prev</a><span>|</span><a href="#39658332">next</a><span>|</span><label class="collapse" for="c-39661445">[-]</label><label class="expand" for="c-39661445">[3 more]</label></div><br/><div class="children"><div class="content">You can&#x27;t create new things on a read-only filesystem, you can in S3; not a good analogy.</div><br/><div id="39663522" class="c"><input type="checkbox" id="c-39663522" checked=""/><div class="controls bullet"><span class="by">akerl_</span><span>|</span><a href="#39659881">root</a><span>|</span><a href="#39661445">parent</a><span>|</span><a href="#39658332">next</a><span>|</span><label class="collapse" for="c-39663522">[-]</label><label class="expand" for="c-39663522">[2 more]</label></div><br/><div class="children"><div class="content">I wasn’t making an analogy. I was asking how read-only filesystem works given the parent commenters description of what makes something a filesystem.</div><br/><div id="39663603" class="c"><input type="checkbox" id="c-39663603" checked=""/><div class="controls bullet"><span class="by">yencabulator</span><span>|</span><a href="#39659881">root</a><span>|</span><a href="#39663522">parent</a><span>|</span><a href="#39658332">next</a><span>|</span><label class="collapse" for="c-39663603">[-]</label><label class="expand" for="c-39663603">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a filesystem where many operations return an error (historically, EROFS). There are many things you can&#x27;t do with one. Is that interesting somehow?<p>I don&#x27;t agree with defining a filesystem as something that has to be backed by a block device, but the shape of a filesystem API is historically very different from the shape of the S3 API.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="39658332" class="c"><input type="checkbox" id="c-39658332" checked=""/><div class="controls bullet"><span class="by">tison</span><span>|</span><a href="#39659881">prev</a><span>|</span><a href="#39658379">next</a><span>|</span><label class="collapse" for="c-39658332">[-]</label><label class="expand" for="c-39658332">[3 more]</label></div><br/><div class="children"><div class="content">It&#x27;s ever discussed in <a href="https:&#x2F;&#x2F;github.com&#x2F;apache&#x2F;arrow-rs&#x2F;issues&#x2F;3888">https:&#x2F;&#x2F;github.com&#x2F;apache&#x2F;arrow-rs&#x2F;issues&#x2F;3888</a> for comparing object_store in Apache Arrow to the APIs provided by Apache OpenDAL.<p>Briefly, Apache OpenDAL is a library providing FS-like APIs over multiple storage backends, including S3 and many other cloud storage.<p>A few database systems, such as GreptimeDB and Databend, use OpenDAL as a better S3 SDK to access data on cloud storage.<p>Other solutions exist to manage filesystem-like interfaces over S3, including Alluxio and JuiceFS. Unlike Apache OpenDAL, Alluxio and JuiceFS need to be deployed standalone and have a dedicated internal metadata service.</div><br/><div id="39658673" class="c"><input type="checkbox" id="c-39658673" checked=""/><div class="controls bullet"><span class="by">Lucasoato</span><span>|</span><a href="#39658332">parent</a><span>|</span><a href="#39658379">next</a><span>|</span><label class="collapse" for="c-39658673">[-]</label><label class="expand" for="c-39658673">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not sure if Alluxio could be substituted by OpenDAL as a local cache layer for TrinoDB.</div><br/><div id="39665145" class="c"><input type="checkbox" id="c-39665145" checked=""/><div class="controls bullet"><span class="by">tison</span><span>|</span><a href="#39658332">root</a><span>|</span><a href="#39658673">parent</a><span>|</span><a href="#39658379">next</a><span>|</span><label class="collapse" for="c-39665145">[-]</label><label class="expand" for="c-39665145">[1 more]</label></div><br/><div class="children"><div class="content">If I get &quot;local cache layer&quot; correctly, it&#x27;s possible. And it&#x27;s even desired if you want to reduce the deployment burden.<p>Here are some related codes on how we implement such a layer in GreptimeDB:<p>* <a href="https:&#x2F;&#x2F;github.com&#x2F;GreptimeTeam&#x2F;greptimedb&#x2F;blob&#x2F;v0.7.0&#x2F;src&#x2F;object-store&#x2F;src&#x2F;layers&#x2F;lru_cache.rs">https:&#x2F;&#x2F;github.com&#x2F;GreptimeTeam&#x2F;greptimedb&#x2F;blob&#x2F;v0.7.0&#x2F;src&#x2F;o...</a>
* <a href="https:&#x2F;&#x2F;github.com&#x2F;GreptimeTeam&#x2F;greptimedb&#x2F;blob&#x2F;v0.7.0&#x2F;src&#x2F;mito2&#x2F;src&#x2F;sst&#x2F;parquet&#x2F;helper.rs">https:&#x2F;&#x2F;github.com&#x2F;GreptimeTeam&#x2F;greptimedb&#x2F;blob&#x2F;v0.7.0&#x2F;src&#x2F;m...</a></div><br/></div></div></div></div></div></div><div id="39658379" class="c"><input type="checkbox" id="c-39658379" checked=""/><div class="controls bullet"><span class="by">cynicalsecurity</span><span>|</span><a href="#39658332">prev</a><span>|</span><a href="#39657805">next</a><span>|</span><label class="collapse" for="c-39658379">[-]</label><label class="expand" for="c-39658379">[10 more]</label></div><br/><div class="children"><div class="content">Backblaze B2 is worth mentioning while we are speaking of S3. I&#x27;m absolutely in love with their prices (3 times lower than of S3). (I&#x27;m not their representative).</div><br/><div id="39660335" class="c"><input type="checkbox" id="c-39660335" checked=""/><div class="controls bullet"><span class="by">overstay8930</span><span>|</span><a href="#39658379">parent</a><span>|</span><a href="#39658414">next</a><span>|</span><label class="collapse" for="c-39660335">[-]</label><label class="expand" for="c-39660335">[5 more]</label></div><br/><div class="children"><div class="content">We liked B2 but not enough to pay for IPv4 addresses, insane they advertise as a multi-cloud solution but basically kill any chance at adoption when NAT gateways and IPv4 charges are everywhere. We would literally save money paying B2 bandwidth fees (high read low write) but not when being pushed through a NAT64 gateway, or paying an hourly charge just to be able to access B2.</div><br/><div id="39660428" class="c"><input type="checkbox" id="c-39660428" checked=""/><div class="controls bullet"><span class="by">Kwpolska</span><span>|</span><a href="#39658379">root</a><span>|</span><a href="#39660335">parent</a><span>|</span><a href="#39662416">next</a><span>|</span><label class="collapse" for="c-39660428">[-]</label><label class="expand" for="c-39660428">[1 more]</label></div><br/><div class="children"><div class="content">How could they launch a cloud service like this and not have IPv6 in 2015? What other basic things did they cheap out on?</div><br/></div></div><div id="39662416" class="c"><input type="checkbox" id="c-39662416" checked=""/><div class="controls bullet"><span class="by">miyuru</span><span>|</span><a href="#39658379">root</a><span>|</span><a href="#39660335">parent</a><span>|</span><a href="#39660428">prev</a><span>|</span><a href="#39663620">next</a><span>|</span><label class="collapse" for="c-39662416">[-]</label><label class="expand" for="c-39662416">[1 more]</label></div><br/><div class="children"><div class="content">I also migrated, after asking for IPv6 for more than 3 years on reddit.<p>they does not seem to understand users on the b2 product. it&#x27;s almost as if b2 is just a supplementary service from their backup service.<p><a href="https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;backblaze&#x2F;comments&#x2F;ij9y9s&#x2F;b2_s3_not_accessible_over_ipv6&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;backblaze&#x2F;comments&#x2F;ij9y9s&#x2F;b2_s3_not...</a></div><br/></div></div><div id="39663620" class="c"><input type="checkbox" id="c-39663620" checked=""/><div class="controls bullet"><span class="by">pl4nty</span><span>|</span><a href="#39658379">root</a><span>|</span><a href="#39660335">parent</a><span>|</span><a href="#39662416">prev</a><span>|</span><a href="#39661349">next</a><span>|</span><label class="collapse" for="c-39663620">[-]</label><label class="expand" for="c-39663620">[1 more]</label></div><br/><div class="children"><div class="content">they&#x27;ve started internal v6 rollout with external coming afterwards. no timelines though, and I&#x27;ve waited for years<p><a href="https:&#x2F;&#x2F;old.reddit.com&#x2F;r&#x2F;backblaze&#x2F;comments&#x2F;1av4r3g&#x2F;b2_ipv6_support&#x2F;krblg4n&#x2F;" rel="nofollow">https:&#x2F;&#x2F;old.reddit.com&#x2F;r&#x2F;backblaze&#x2F;comments&#x2F;1av4r3g&#x2F;b2_ipv6_...</a></div><br/></div></div></div></div><div id="39658414" class="c"><input type="checkbox" id="c-39658414" checked=""/><div class="controls bullet"><span class="by">silvertaza</span><span>|</span><a href="#39658379">parent</a><span>|</span><a href="#39660335">prev</a><span>|</span><a href="#39660259">next</a><span>|</span><label class="collapse" for="c-39658414">[-]</label><label class="expand" for="c-39658414">[3 more]</label></div><br/><div class="children"><div class="content">With every alternative, the prevailing issue is the fact that your data is as safe as the company your data is with. But I think this can be remedied by doubly external backups.</div><br/><div id="39658473" class="c"><input type="checkbox" id="c-39658473" checked=""/><div class="controls bullet"><span class="by">didgeoridoo</span><span>|</span><a href="#39658379">root</a><span>|</span><a href="#39658414">parent</a><span>|</span><a href="#39658520">next</a><span>|</span><label class="collapse" for="c-39658473">[-]</label><label class="expand" for="c-39658473">[1 more]</label></div><br/><div class="children"><div class="content">B2 having an S3-compatible API available makes this particularly easy :)</div><br/></div></div><div id="39658520" class="c"><input type="checkbox" id="c-39658520" checked=""/><div class="controls bullet"><span class="by">OJFord</span><span>|</span><a href="#39658379">root</a><span>|</span><a href="#39658414">parent</a><span>|</span><a href="#39658473">prev</a><span>|</span><a href="#39660259">next</a><span>|</span><label class="collapse" for="c-39658520">[-]</label><label class="expand" for="c-39658520">[1 more]</label></div><br/><div class="children"><div class="content">Backblaze is like if Amazon spun AWS S3 out as its own business (and it added some backup helper tooling as a result) though, I wouldn&#x27;t really worry any more about it. You could write a second copy to S3 Glacier Deep Archive (using B2 for instant access when you wanted to restore or on a new device) and still be much cheaper.</div><br/></div></div></div></div></div></div><div id="39657805" class="c"><input type="checkbox" id="c-39657805" checked=""/><div class="controls bullet"><span class="by">nickcw</span><span>|</span><a href="#39658379">prev</a><span>|</span><a href="#39660242">next</a><span>|</span><label class="collapse" for="c-39657805">[-]</label><label class="expand" for="c-39657805">[6 more]</label></div><br/><div class="children"><div class="content">Great article - would have been useful to read before starting out on the journey of making rclone mount (mount your cloud storage via fuse)!<p>After a lot of iterating we eventually came up with the VFS layer in rclone which adapts S3 (or any other similar storage system like Google Cloud Storage, Azure Blob, Openstack Swift, Oracle Object Storage, etc) into a POSIX-ish file system layer in rclone. The actual rclone mount code is quite a thin layer on top of this.<p>The VFS layer has various levels of compatibility &quot;off&quot; where it just does directory caching. In this mode, like the article states you can&#x27;t read and write to a file simultaneously and you can&#x27;t write to the middle of a file and you can only write files sequentially. Surprisingly quite a lot of things work OK with these limitations. The next level up is &quot;writes&quot; - this supports nearly all the POSIX features that applications want like being able to read and write to the same file at the same time, write to the middle of the file, etc. The cost for that though is a local copy of the file which is uploaded asynchronously when it is closed.<p>Here are some docs for the VFS caching modes - these mirror the limitations in the article nicely!<p><a href="https:&#x2F;&#x2F;rclone.org&#x2F;commands&#x2F;rclone_mount&#x2F;#vfs-file-caching" rel="nofollow">https:&#x2F;&#x2F;rclone.org&#x2F;commands&#x2F;rclone_mount&#x2F;#vfs-file-caching</a><p>By default S3 doesn&#x27;t have real directories either. This means you can&#x27;t have a directory with no files in, and directories don&#x27;t have valid metadata (like modification time). You can create zero length files ending in &#x2F; which are known as directory markers and a lot of tools (including rclone) support these. Not being able to have empty directories isn&#x27;t too much of a problem normally as the VFS layer fakes them and most apps then write something into their empty directories pretty quickly.<p>So it is really quite a lot of work trying to convert something which looks like S3 into something which looks like a POSIX file system. There is a whole lot of smoke and mirrors behind the scene when things like renaming an open file happens and other nasty corner cases like that.<p>Rclone&#x27;s lower level move&#x2F;sync&#x2F;copy commands don&#x27;t bother though and use the S3 API pretty much as-is.<p>If I could change one thing about S3&#x27;s API I would like an option to read the metadata with the listings. Rclone stores modification times of files as metadata on the object and there isn&#x27;t a bulk way of reading these, you have to HEAD the object. Or alternatively a way of setting the Last-Modified on an object when you upload it would do too.</div><br/><div id="39658090" class="c"><input type="checkbox" id="c-39658090" checked=""/><div class="controls bullet"><span class="by">Hakkin</span><span>|</span><a href="#39657805">parent</a><span>|</span><a href="#39658314">next</a><span>|</span><label class="collapse" for="c-39658090">[-]</label><label class="expand" for="c-39658090">[2 more]</label></div><br/><div class="children"><div class="content">&gt; If I could change one thing about S3&#x27;s API I would like an option to read the metadata with the listings. Rclone stores modification times of files as metadata on the object and there isn&#x27;t a bulk way of reading these, you have to HEAD the object. Or alternatively a way of setting the Last-Modified on an object when you upload it would do too.<p>I wonder if you couldn&#x27;t hack this in by storing the metadata in the key name itself? Obviously with the key length limit of 1024 you would be limited in how much metadata you could store, but it&#x27;s still quite a lot of space, even taking into account the file path. You could use a deliminator that would be invalid in a normalized path, like &#x27;&#x2F;&#x2F;&#x27;, for example: &#x2F;path&#x2F;to&#x2F;file.txt&#x2F;&#x2F;mtime=1710066090<p>You would still be able to fetch &quot;directories&quot; via prefixes and direct files by using &#x27;&lt;filename&gt;&#x2F;&#x2F;&#x27; as the prefix.<p>This kind of formatting would probably make it pretty incompatible with other software though.</div><br/><div id="39658452" class="c"><input type="checkbox" id="c-39658452" checked=""/><div class="controls bullet"><span class="by">nickcw</span><span>|</span><a href="#39657805">root</a><span>|</span><a href="#39658090">parent</a><span>|</span><a href="#39658314">next</a><span>|</span><label class="collapse" for="c-39658452">[-]</label><label class="expand" for="c-39658452">[1 more]</label></div><br/><div class="children"><div class="content">I think that is a nice idea - maybe something we could implement in an overlay backend. However people really like the fact that the object they upload with rclone arrive with the filenames they had originally on s3, so I think the incompatible with other software downside would make it unattractive for most users.</div><br/></div></div></div></div><div id="39658314" class="c"><input type="checkbox" id="c-39658314" checked=""/><div class="controls bullet"><span class="by">klauspost</span><span>|</span><a href="#39657805">parent</a><span>|</span><a href="#39658090">prev</a><span>|</span><a href="#39662772">next</a><span>|</span><label class="collapse" for="c-39658314">[-]</label><label class="expand" for="c-39658314">[2 more]</label></div><br/><div class="children"><div class="content">&gt; If I could change one thing about S3&#x27;s API I would like an option to read the metadata with the listings.<p>Agree. In MinIO (disclaimer: I work there) we added a &quot;secret&quot; parameter (metadata=true) to include metadata and tags in listings if the user has the appropriate permissions. Of course it being an extension it is not really something that you can reliably use. But rclone can of course always try it and use it if available :)<p>&gt; You can create zero length files ending in &#x2F;<p>Yeah. Though you could also consider &quot;shared prefixes&quot; in listings as directories by itself. That of course makes directories &quot;stateless&quot; and unable to exist if there are no objects in there - which has pros and cons.<p>&gt; Or alternatively a way of setting the Last-Modified on an object when you upload it would do too.<p>Yes, that gives severe limitations to clients. However it does make the &quot;server&quot; time the reference. But we have to deal with the same limitation for client side replication&#x2F;mirroring.<p>My personal biggest complaint is that there isn&#x27;t a `HeadObjectVersions` that returns version information for a single object. `ListObjectVersions` is always going to be a &quot;cluster-wide&quot; operation, since you cannot know if the given prefix is actually a prefix or an object key. AWS recently added &quot;GetObjectAttributes&quot; - but it doesn&#x27;t add version information, which would have fit in nicely there.</div><br/><div id="39658416" class="c"><input type="checkbox" id="c-39658416" checked=""/><div class="controls bullet"><span class="by">nickcw</span><span>|</span><a href="#39657805">root</a><span>|</span><a href="#39658314">parent</a><span>|</span><a href="#39662772">next</a><span>|</span><label class="collapse" for="c-39658416">[-]</label><label class="expand" for="c-39658416">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Agree. In MinIO (disclaimer: I work there) we added a &quot;secret&quot; parameter (metadata=true) to include metadata and tags in listings if the user has the appropriate permissions. Of course it being an extension it is not really something that you can reliably use. But rclone can of course always try it and use it if available :)<p>Is this &quot;secret&quot; parameter documented somewhere? Sounds very useful :-) Rclone knows when it is talking to Minio so we could easily wedge that in.<p>&gt; My personal biggest complaint is that there isn&#x27;t a `HeadObjectVersions` that returns version information for a single object. `ListObjectVersions` is always going to be a &quot;cluster-wide&quot; operation, since you cannot know if the given prefix is actually a prefix or an object key<p>Yes that is annoying having to do a List just to figure out which object Version is being referred to. (Rclone has this problem when using --s3-list-version).</div><br/></div></div></div></div><div id="39662772" class="c"><input type="checkbox" id="c-39662772" checked=""/><div class="controls bullet"><span class="by">glitchcrab</span><span>|</span><a href="#39657805">parent</a><span>|</span><a href="#39658314">prev</a><span>|</span><a href="#39660242">next</a><span>|</span><label class="collapse" for="c-39662772">[-]</label><label class="expand" for="c-39662772">[1 more]</label></div><br/><div class="children"><div class="content">Hey Nick :wave:</div><br/></div></div></div></div><div id="39660242" class="c"><input type="checkbox" id="c-39660242" checked=""/><div class="controls bullet"><span class="by">d-z-m</span><span>|</span><a href="#39657805">prev</a><span>|</span><a href="#39660169">next</a><span>|</span><label class="collapse" for="c-39660242">[-]</label><label class="expand" for="c-39660242">[2 more]</label></div><br/><div class="children"><div class="content">&gt; S3 is a cloud filesystem, not an object-whatever. [...]I think the idea that S3 is really &quot;Amazon Cloud Filesystem&quot; is a bit of a load bearing fiction.<p>Does anyone actually think this? I have never encountered anyone who has described S3 in these terms.</div><br/><div id="39660909" class="c"><input type="checkbox" id="c-39660909" checked=""/><div class="controls bullet"><span class="by">teaearlgraycold</span><span>|</span><a href="#39660242">parent</a><span>|</span><a href="#39660169">next</a><span>|</span><label class="collapse" for="c-39660909">[-]</label><label class="expand" for="c-39660909">[1 more]</label></div><br/><div class="children"><div class="content">Not sure if the author is aware of EFS</div><br/></div></div></div></div><div id="39660169" class="c"><input type="checkbox" id="c-39660169" checked=""/><div class="controls bullet"><span class="by">svat</span><span>|</span><a href="#39660242">prev</a><span>|</span><a href="#39662415">next</a><span>|</span><label class="collapse" for="c-39660169">[-]</label><label class="expand" for="c-39660169">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s nice to see Ousterhout&#x27;s idea of module depth (the main idea from his <i>A Philosophy of Software Design</i>) getting more mainstream — mentioned in this article with attribution only in &quot;Other notes&quot;, which suggests the author found it natural enough not to require elaboration. Being obvious-in-hindsight like this is a sign of a good idea. :-)<p>&gt; <i>The concept of deep vs shallow modules comes from John Ousterhout&#x27;s excellent book. The book is [effectively] a list of ideas on software design. Some are real hits with me, others not, but well worth reading overall. Praise for making it succinct.</i></div><br/></div></div><div id="39662415" class="c"><input type="checkbox" id="c-39662415" checked=""/><div class="controls bullet"><span class="by">ein0p</span><span>|</span><a href="#39660169">prev</a><span>|</span><a href="#39663688">next</a><span>|</span><label class="collapse" for="c-39662415">[-]</label><label class="expand" for="c-39662415">[3 more]</label></div><br/><div class="children"><div class="content">A bit off topic but also related: I use Minio as a local &quot;S3&quot; to store datasets and model checkpoints for my garage compute. Minio, however, has a bunch of features that I simply don&#x27;t need. I just want to be able copy to&#x2F;from, list prefixes, and delete every now and then. I could use nfs I suppose, but that&#x27;d be a bit inconvenient since I also use Minio to store build deps (which Bazel then downloads), and I&#x27;d like to be able to comfortably build stuff on my laptop. In particular, one feature I do not need is the constant disk access than Minio does to &quot;protect against bit rot&quot; and whatever. That protection is already provided by periodic scrubs on my raidz6.<p>So what&#x27;s the current best (preferably statically linked) self-hosted, single-node option for minimal S3 like &quot;thing&quot; that just lets me CRUD the files and list them?</div><br/><div id="39665788" class="c"><input type="checkbox" id="c-39665788" checked=""/><div class="controls bullet"><span class="by">mr_toad</span><span>|</span><a href="#39662415">parent</a><span>|</span><a href="#39664108">next</a><span>|</span><label class="collapse" for="c-39665788">[-]</label><label class="expand" for="c-39665788">[1 more]</label></div><br/><div class="children"><div class="content">A web server?</div><br/></div></div><div id="39664108" class="c"><input type="checkbox" id="c-39664108" checked=""/><div class="controls bullet"><span class="by">paulddraper</span><span>|</span><a href="#39662415">parent</a><span>|</span><a href="#39665788">prev</a><span>|</span><a href="#39663688">next</a><span>|</span><label class="collapse" for="c-39664108">[-]</label><label class="expand" for="c-39664108">[1 more]</label></div><br/><div class="children"><div class="content">FYI, Minio used to have a &quot;File System&quot; mode that did exactly this.<p>But they deprecated it.<p>(You can still use it, but it&#x27;s not getting updates.)</div><br/></div></div></div></div><div id="39663688" class="c"><input type="checkbox" id="c-39663688" checked=""/><div class="controls bullet"><span class="by">SirOibaf</span><span>|</span><a href="#39662415">prev</a><span>|</span><a href="#39657517">next</a><span>|</span><label class="collapse" for="c-39663688">[-]</label><label class="expand" for="c-39663688">[1 more]</label></div><br/><div class="children"><div class="content">At Hopsworks we built HopsFS-S3 to improve things like listing (becomes a partition pruned scan of a in-memory DB), atomic renames and added a block&#x2F;object caching layer using NVMe drives.<p>You can read the research paper here if you are curious: <a href="https:&#x2F;&#x2F;www.hopsworks.ai&#x2F;research-papers&#x2F;hopsfs-s3-extending-object-stores-with-posix-like-semantics" rel="nofollow">https:&#x2F;&#x2F;www.hopsworks.ai&#x2F;research-papers&#x2F;hopsfs-s3-extending...</a></div><br/></div></div><div id="39657517" class="c"><input type="checkbox" id="c-39657517" checked=""/><div class="controls bullet"><span class="by">type_Ben_struct</span><span>|</span><a href="#39663688">prev</a><span>|</span><a href="#39657575">next</a><span>|</span><label class="collapse" for="c-39657517">[-]</label><label class="expand" for="c-39657517">[4 more]</label></div><br/><div class="children"><div class="content">Tools like LucidLink and Weka go a way to making S3 even more of a “file system”. They break files into smaller chunks (S3 objects) which helps with partial writes, reads and performance. Alongside tiering of data from S3 to disk when needed for performance.</div><br/><div id="39658267" class="c"><input type="checkbox" id="c-39658267" checked=""/><div class="controls bullet"><span class="by">rwmj</span><span>|</span><a href="#39657517">parent</a><span>|</span><a href="#39662668">next</a><span>|</span><label class="collapse" for="c-39658267">[-]</label><label class="expand" for="c-39658267">[1 more]</label></div><br/><div class="children"><div class="content">Someone contributed an nbdkit S3 plugin which basically works the way you described.  It uses numbered S3 chunks using the pattern &quot;key&#x2F;%16x&quot;, allowing the virtual disk to be updated.  (<a href="https:&#x2F;&#x2F;libguestfs.org&#x2F;nbdkit-S3-plugin.1.html" rel="nofollow">https:&#x2F;&#x2F;libguestfs.org&#x2F;nbdkit-S3-plugin.1.html</a> <a href="https:&#x2F;&#x2F;gitlab.com&#x2F;nbdkit&#x2F;nbdkit&#x2F;-&#x2F;tree&#x2F;master&#x2F;plugins&#x2F;S3" rel="nofollow">https:&#x2F;&#x2F;gitlab.com&#x2F;nbdkit&#x2F;nbdkit&#x2F;-&#x2F;tree&#x2F;master&#x2F;plugins&#x2F;S3</a>)</div><br/></div></div><div id="39662668" class="c"><input type="checkbox" id="c-39662668" checked=""/><div class="controls bullet"><span class="by">cuno</span><span>|</span><a href="#39657517">parent</a><span>|</span><a href="#39658267">prev</a><span>|</span><a href="#39657659">next</a><span>|</span><label class="collapse" for="c-39662668">[-]</label><label class="expand" for="c-39662668">[1 more]</label></div><br/><div class="children"><div class="content">The problem with these approaches is that the data is scrambled on the backend, so you can&#x27;t access the files directly from S3 anymore. Instead you need an S3 gateway to convert from scrambled S3 to unscrambled S3. They rely on a separate database to reassemble the pieces back together again.</div><br/></div></div><div id="39657659" class="c"><input type="checkbox" id="c-39657659" checked=""/><div class="controls bullet"><span class="by">hnlmorg</span><span>|</span><a href="#39657517">parent</a><span>|</span><a href="#39662668">prev</a><span>|</span><a href="#39657575">next</a><span>|</span><label class="collapse" for="c-39657659">[-]</label><label class="expand" for="c-39657659">[1 more]</label></div><br/><div class="children"><div class="content">I don’t know a whole lot about LucidLink but Weka basically uses S3 as a dataplane for their own file system.</div><br/></div></div></div></div><div id="39657575" class="c"><input type="checkbox" id="c-39657575" checked=""/><div class="controls bullet"><span class="by">hiAndrewQuinn</span><span>|</span><a href="#39657517">prev</a><span>|</span><a href="#39659350">next</a><span>|</span><label class="collapse" for="c-39657575">[-]</label><label class="expand" for="c-39657575">[3 more]</label></div><br/><div class="children"><div class="content">I feel like I understand the lasting popularity of the humble FTP fileserver a bit better now. Thank you.</div><br/><div id="39659811" class="c"><input type="checkbox" id="c-39659811" checked=""/><div class="controls bullet"><span class="by">jugg1es</span><span>|</span><a href="#39657575">parent</a><span>|</span><a href="#39659350">next</a><span>|</span><label class="collapse" for="c-39659811">[-]</label><label class="expand" for="c-39659811">[2 more]</label></div><br/><div class="children"><div class="content">oh but amazon offers SFTP on top of S3 so you don&#x27;t have to miss out.</div><br/><div id="39659952" class="c"><input type="checkbox" id="c-39659952" checked=""/><div class="controls bullet"><span class="by">hiAndrewQuinn</span><span>|</span><a href="#39657575">root</a><span>|</span><a href="#39659811">parent</a><span>|</span><a href="#39659350">next</a><span>|</span><label class="collapse" for="c-39659952">[-]</label><label class="expand" for="c-39659952">[1 more]</label></div><br/><div class="children"><div class="content">If it&#x27;s offered on top of S3, though, doesn&#x27;t it still have all the same issues of needing to totally overwrite files?</div><br/></div></div></div></div></div></div><div id="39659350" class="c"><input type="checkbox" id="c-39659350" checked=""/><div class="controls bullet"><span class="by">arvindamirtaa</span><span>|</span><a href="#39657575">prev</a><span>|</span><a href="#39660860">next</a><span>|</span><label class="collapse" for="c-39659350">[-]</label><label class="expand" for="c-39659350">[1 more]</label></div><br/><div class="children"><div class="content">Like Gmail is emails but not IMAP. It&#x27;s fine. We have seen that these kinds of wrappers work pretty well most of the time considering the performance and simplicity they bring in building and managing these systems.</div><br/></div></div><div id="39660860" class="c"><input type="checkbox" id="c-39660860" checked=""/><div class="controls bullet"><span class="by">tutfbhuf</span><span>|</span><a href="#39659350">prev</a><span>|</span><a href="#39663275">next</a><span>|</span><label class="collapse" for="c-39660860">[-]</label><label class="expand" for="c-39660860">[1 more]</label></div><br/><div class="children"><div class="content">S3 is obviously not a filesystem in the sense of a POSIX filesystem. And I would argue it is not a filesystem, even if we were to relax POSIX filesystem semantics (do not implement the full spec). But what is certainly possible is to span a filesystem on top of S3. It is basically possible to span a filesystem on anything that can store data. You can even go crazy for demonstration purposes and put a filesystem on top of YouTube (there are some tech demos for that on GitHub).<p>I think a better question is whether there are any good filesystem implementations on top of S3. There are many attempts like s3fs-fuse[^1] or seaweedfs[^2], but I have not heard many stories about their use at scale from big companies. Just recently there was a post here about cunoFS[^3]. It is a startup that implements a POSIX-compliant (supports symlinks, hard links (emulated), UIDs &amp; GIDs, permissions, random writes, etc.) filesystem on top of S3&#x2F;AZ&#x2F;GCP storage and claims to have really good performance. I think only time will tell if it works out in practice for companies to use S3 as a filesystem through fs implementations on top of S3.<p>[^1]: <a href="https:&#x2F;&#x2F;github.com&#x2F;s3fs-fuse&#x2F;s3fs-fuse">https:&#x2F;&#x2F;github.com&#x2F;s3fs-fuse&#x2F;s3fs-fuse</a><p>[^2]: <a href="https:&#x2F;&#x2F;github.com&#x2F;seaweedfs&#x2F;seaweedfs">https:&#x2F;&#x2F;github.com&#x2F;seaweedfs&#x2F;seaweedfs</a><p>[^3]: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=39640307">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=39640307</a></div><br/></div></div><div id="39663275" class="c"><input type="checkbox" id="c-39663275" checked=""/><div class="controls bullet"><span class="by">yellowapple</span><span>|</span><a href="#39660860">prev</a><span>|</span><a href="#39657558">next</a><span>|</span><label class="collapse" for="c-39663275">[-]</label><label class="expand" for="c-39663275">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Filesystem software, especially databases, can&#x27;t be ported to Amazon S3<p>Except they can be.  You don&#x27;t need to overwrite the whole DB file on every INSERT&#x2F;UPDATE&#x2F;DELETE; those can be (and often are) stored in memory and periodically checkpointed.  You might lose some writes if the process goes down between checkpoints, but for a lot of applications that&#x27;s entirely acceptable.<p>Indeed, for SQLite in particular there are tools like Litestream that support replication to and restoration from S3.<p>Alternately, you could split the DB across multiple files, and then an INSERT&#x2F;UPDATE&#x2F;DELETE would only need to overwrite the files actually affected.  This is already how server-based RDBMSs usually work.</div><br/></div></div><div id="39657558" class="c"><input type="checkbox" id="c-39657558" checked=""/><div class="controls bullet"><span class="by">hn72774</span><span>|</span><a href="#39663275">prev</a><span>|</span><a href="#39660230">next</a><span>|</span><label class="collapse" for="c-39657558">[-]</label><label class="expand" for="c-39657558">[6 more]</label></div><br/><div class="children"><div class="content">&gt; Filesystem software, especially databases, can&#x27;t be ported to Amazon S3<p>Hudi, Delta, iceberg bridge that gap now.  Databricks built a company around it.<p>Don&#x27;t try to do relational on object storage on your own.  Use one of those libraries.  It seems simple but it&#x27;s not.  Late arriving data, deletes, updates, primary key column values changing, etc.</div><br/><div id="39657621" class="c"><input type="checkbox" id="c-39657621" checked=""/><div class="controls bullet"><span class="by">albert_e</span><span>|</span><a href="#39657558">parent</a><span>|</span><a href="#39657791">next</a><span>|</span><label class="collapse" for="c-39657621">[-]</label><label class="expand" for="c-39657621">[4 more]</label></div><br/><div class="children"><div class="content">There is specifically block storage service (EBS) and falvirs of it like EBS multi-attach and EFS that can ne used if there is a need to port software&#x2F;databases to the cloud with low level filesystem support.<p>Why would we need to do it on object storage which addresses a different type of storage need.<p>Nevertheless there are projects like EMRFS and S3 file system mount points that try to provide files stem interfaces to workloads that need to see S3 as a filesystem.</div><br/><div id="39659756" class="c"><input type="checkbox" id="c-39659756" checked=""/><div class="controls bullet"><span class="by">hn72774</span><span>|</span><a href="#39657558">root</a><span>|</span><a href="#39657621">parent</a><span>|</span><a href="#39659201">next</a><span>|</span><label class="collapse" for="c-39659756">[-]</label><label class="expand" for="c-39659756">[2 more]</label></div><br/><div class="children"><div class="content">S3 is better for large datasets.  It&#x27;s cheaper and handles large file sizes with ease.<p>It has become a de-facto standard for distributed, data-intensive workloads like those common with spark.<p>A key benefit is decoupling the data from the compute so that they can scale independently.  EBS is tightly coupled to iops and you pay extra for that.<p>(Source: a long time working in data engineering)</div><br/><div id="39660655" class="c"><input type="checkbox" id="c-39660655" checked=""/><div class="controls bullet"><span class="by">albert_e</span><span>|</span><a href="#39657558">root</a><span>|</span><a href="#39659756">parent</a><span>|</span><a href="#39659201">next</a><span>|</span><label class="collapse" for="c-39660655">[-]</label><label class="expand" for="c-39660655">[1 more]</label></div><br/><div class="children"><div class="content">Yes and I also believe:<p>Experienced Spark &#x2F; Data Engineering teams would not assume S3 is readily useable as a filesystem.<p>This [1] seems like a good guide on how to configure spark for working with Cloud object stores, while recognizing the limitations and pitfalls.<p>[1]: <a href="https:&#x2F;&#x2F;spark.apache.org&#x2F;docs&#x2F;latest&#x2F;cloud-integration.html" rel="nofollow">https:&#x2F;&#x2F;spark.apache.org&#x2F;docs&#x2F;latest&#x2F;cloud-integration.html</a><p>---<p>Amazon EMR offers a managed way to run hadoop or spark clusters and it implements an &quot;EMR FS&quot; [2] system to interface with S3 as storage.<p>[2]: <a href="https:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;emr&#x2F;latest&#x2F;ReleaseGuide&#x2F;emr-fs.html" rel="nofollow">https:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;emr&#x2F;latest&#x2F;ReleaseGuide&#x2F;emr-fs.h...</a><p>AWS Glue is another option which is &quot;serverless&quot; ETL. Source and Destination can be S3 data lakes read through a data catalog (hive or glue data catalog). During processing AWs Glue can optionally use S3 [3,4,5] for shuffle partition.<p>[3]: <a href="https:&#x2F;&#x2F;aws.amazon.com&#x2F;blogs&#x2F;big-data&#x2F;introducing-amazon-s3-shuffle-in-aws-glue&#x2F;" rel="nofollow">https:&#x2F;&#x2F;aws.amazon.com&#x2F;blogs&#x2F;big-data&#x2F;introducing-amazon-s3-...</a><p>[4]: <a href="https:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;glue&#x2F;latest&#x2F;dg&#x2F;monitor-spark-shuffle-manager.html" rel="nofollow">https:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;glue&#x2F;latest&#x2F;dg&#x2F;monitor-spark-shu...</a><p>[5]: <a href="https:&#x2F;&#x2F;aws.amazon.com&#x2F;blogs&#x2F;big-data&#x2F;introducing-the-cloud-shuffle-storage-plugin-for-apache-spark&#x2F;" rel="nofollow">https:&#x2F;&#x2F;aws.amazon.com&#x2F;blogs&#x2F;big-data&#x2F;introducing-the-cloud-...</a></div><br/></div></div></div></div><div id="39659201" class="c"><input type="checkbox" id="c-39659201" checked=""/><div class="controls bullet"><span class="by">albert_e</span><span>|</span><a href="#39657558">root</a><span>|</span><a href="#39657621">parent</a><span>|</span><a href="#39659756">prev</a><span>|</span><a href="#39657791">next</a><span>|</span><label class="collapse" for="c-39659201">[-]</label><label class="expand" for="c-39659201">[1 more]</label></div><br/><div class="children"><div class="content">*flavors<p>*can be used<p>*file system<p>(Apologies for typos. The &quot;noprocrast&quot; setting sometimes locks us out of HN right after submitting a comment. And it is now too late, not editable)</div><br/></div></div></div></div><div id="39657791" class="c"><input type="checkbox" id="c-39657791" checked=""/><div class="controls bullet"><span class="by">8n4vidtmkvmk</span><span>|</span><a href="#39657558">parent</a><span>|</span><a href="#39657621">prev</a><span>|</span><a href="#39660230">next</a><span>|</span><label class="collapse" for="c-39657791">[-]</label><label class="expand" for="c-39657791">[1 more]</label></div><br/><div class="children"><div class="content">I still don&#x27;t understand why you&#x27;d want to do it in the first place. Just by some contiguous storage.</div><br/></div></div></div></div><div id="39660230" class="c"><input type="checkbox" id="c-39660230" checked=""/><div class="controls bullet"><span class="by">ahepp</span><span>|</span><a href="#39657558">prev</a><span>|</span><a href="#39659991">next</a><span>|</span><label class="collapse" for="c-39660230">[-]</label><label class="expand" for="c-39660230">[3 more]</label></div><br/><div class="children"><div class="content">Are filesystems the correct abstraction to build databases on? Isn’t a filesystem a database in a way? Is there a reason to build a database on top of a filesystem abstraction rather than a block abstraction?<p>To say you can’t build an efficient database on top of S3 makes sense to me. S3 is already a certain kind of data-storing abstraction optimized for certain usages. If you try and build another data-storing abstraction optimized for incompatible usages on top of that, you are going to have a difficult time.</div><br/><div id="39661489" class="c"><input type="checkbox" id="c-39661489" checked=""/><div class="controls bullet"><span class="by">jandrewrogers</span><span>|</span><a href="#39660230">parent</a><span>|</span><a href="#39660269">next</a><span>|</span><label class="collapse" for="c-39661489">[-]</label><label class="expand" for="c-39661489">[1 more]</label></div><br/><div class="children"><div class="content">The traditional POSIX filesystem is the wrong abstraction for a database, but not filesystems per se. All databases that care about performance and scalability implement their own filesystems, either directly against raw block devices or as an overlay on top of a POSIX filesystem that bypasses some of its limitations. The performance and scalability gains by doing so are not small.<p>The issue with POSIX filesystems is that they are required to make a set of tradeoffs to support features a database engine doesn&#x27;t need, to the significant detriment of scalability and performance in areas that databases care about a lot. For example, one such database filesystem I&#x27;ve used occasionally over the years, while a bit dated at this point, is designed such that you can have tens of millions of files in a single directory where you are creating and destroying tens of thousands of files every second, on upwards of a petabyte of storage. Very far from being POSIX compatible but you don&#x27;t get anything like that type of scalability on POSIX.<p>Object storage is far from ideal as database storage. The biggest issue, though, is the terrible storage bandwidth available in the cloud. It is a small fraction of what is available in a normal server and modern database engines are capable of fully exploiting a large JBOD of NVMe.</div><br/></div></div><div id="39660269" class="c"><input type="checkbox" id="c-39660269" checked=""/><div class="controls bullet"><span class="by">d0gsg0w00f</span><span>|</span><a href="#39660230">parent</a><span>|</span><a href="#39661489">prev</a><span>|</span><a href="#39659991">next</a><span>|</span><label class="collapse" for="c-39660269">[-]</label><label class="expand" for="c-39660269">[1 more]</label></div><br/><div class="children"><div class="content">In my $dayjob as cloud architect I sometimes suggest S3 as an alternative to pulling massive JSON blobs from RDS Postgres&#x2F;Redis etc. As long as their latency minimums are high enough there&#x27;s no reason you can&#x27;t.</div><br/></div></div></div></div><div id="39659991" class="c"><input type="checkbox" id="c-39659991" checked=""/><div class="controls bullet"><span class="by">remram</span><span>|</span><a href="#39660230">prev</a><span>|</span><a href="#39660609">next</a><span>|</span><label class="collapse" for="c-39659991">[-]</label><label class="expand" for="c-39659991">[2 more]</label></div><br/><div class="children"><div class="content">I am currently pondering this exact problem. I want to run a file-sharing web application (think: NextCloud) but I don&#x27;t want to use expensive block storage or the dedicated server&#x27;s disk space for the files, as some of them will be accessed infrequently.<p>I am wondering if s3fs&#x2F;rclone-mount is sufficient, or if I should use something like JuiceFS that adds random-access, renaming, etc on top of it. Are those really necessary APIs for my use case? Is there only one way to find out?<p>(The app doesn&#x27;t have native S3 support)</div><br/><div id="39660722" class="c"><input type="checkbox" id="c-39660722" checked=""/><div class="controls bullet"><span class="by">cuno</span><span>|</span><a href="#39659991">parent</a><span>|</span><a href="#39660609">next</a><span>|</span><label class="collapse" for="c-39660722">[-]</label><label class="expand" for="c-39660722">[1 more]</label></div><br/><div class="children"><div class="content">It depends on if you want to expose filesystem semantics or metadata to applications using it. For example random access writes are done by ffmpeg, which is a workhorse of the media industry, but most things can&#x27;t handle that or are too slow. We had to build our own solution cunoFS to make it work properly at high speeds.</div><br/></div></div></div></div><div id="39660609" class="c"><input type="checkbox" id="c-39660609" checked=""/><div class="controls bullet"><span class="by">BirAdam</span><span>|</span><a href="#39659991">prev</a><span>|</span><a href="#39657134">next</a><span>|</span><label class="collapse" for="c-39660609">[-]</label><label class="expand" for="c-39660609">[5 more]</label></div><br/><div class="children"><div class="content">Underneath the software, there’s still a filesystem with files.<p>If you stand up an S3 instance with Ceph, you still have a filesystem on spinning rust or fancy SSDs. There’s just a bunch of stuff on top of that. It’s cool, but to say that there’s no filesystem is simply what the customer or middle person sees, not what is actually happening.</div><br/><div id="39660918" class="c"><input type="checkbox" id="c-39660918" checked=""/><div class="controls bullet"><span class="by">seabrookmx</span><span>|</span><a href="#39660609">parent</a><span>|</span><a href="#39661607">next</a><span>|</span><label class="collapse" for="c-39660918">[-]</label><label class="expand" for="c-39660918">[1 more]</label></div><br/><div class="children"><div class="content">S3 actually uses a completely custom system[1] for writing bytes to disk. I haven&#x27;t seen much in the way of details on the on-disk format but I certainly wouldn&#x27;t assume it resembles a normal filesystem.<p>[1]: <a href="https:&#x2F;&#x2F;aws.amazon.com&#x2F;blogs&#x2F;storage&#x2F;how-automated-reasoning-helps-us-innovate-at-s3-scale&#x2F;" rel="nofollow">https:&#x2F;&#x2F;aws.amazon.com&#x2F;blogs&#x2F;storage&#x2F;how-automated-reasoning...</a></div><br/></div></div><div id="39661607" class="c"><input type="checkbox" id="c-39661607" checked=""/><div class="controls bullet"><span class="by">jandrewrogers</span><span>|</span><a href="#39660609">parent</a><span>|</span><a href="#39660918">prev</a><span>|</span><a href="#39661302">next</a><span>|</span><label class="collapse" for="c-39661607">[-]</label><label class="expand" for="c-39661607">[1 more]</label></div><br/><div class="children"><div class="content">I seriously doubt this is correct. It is common for database engines to install directly on raw block devices, bypassing the Linux kernel and effectively becoming the filesystem for those storage devices. Why would S3 work any differently? There are no advantages to building on top of a filesystem and many disadvantages for this kind of thing.<p>It would be a poor engineering choice to build something like S3 on top of some other filesystem. There are often ways to do it by using an overlay that converts a filesystem into a pseudo block device, but that is usually considered a compatibility shim used for environments that lacking dedicated storage, at the cost of robustness and performance.</div><br/></div></div><div id="39661302" class="c"><input type="checkbox" id="c-39661302" checked=""/><div class="controls bullet"><span class="by">aseipp</span><span>|</span><a href="#39660609">parent</a><span>|</span><a href="#39661607">prev</a><span>|</span><a href="#39661560">next</a><span>|</span><label class="collapse" for="c-39661302">[-]</label><label class="expand" for="c-39661302">[1 more]</label></div><br/><div class="children"><div class="content">No there isn&#x27;t. AWS does not use the traditional filesystem layer to store data; that would be a massive mistake from a performance and reliability POV; the POSIX filesystem specification is notoriously vague about things like fsync consistency under particular scenarios, i.e. &quot;do I need to fsync the parent directory before or after fsyncing the contents&quot; for instance and has many bizarre performance cliffs if you aren&#x27;t careful. At the scale AWS is at even a 10% performance cliff or performance delta would be worth clawing back if it meant removing the POSIX filesystem.<p>Filesystems are not free; they incur &quot;complexity&quot; (that favorite bugbear everyone on HN loves to complain about) just as much as any other component in the stack does.<p>&gt; If you stand up an S3 instance with Ceph,<p>Okay, but AWS does not run on Ceph. Even then, Ceph is an example that recommends the opposite. Nowadays they recommend solutions like the Bluestore OSD backend to store actual data directly on raw block devices, completely bypassing the filesystem layer -- for the exact same reasons I outlined above and many, many others (the actual metadata does use &quot;BlueFS&quot; which is a small FS shim, but this is mostly so that RocksDB can write directly to the block device too, next to the data segments, and BlueFS is in no way a real POSIX filesystem, it&#x27;s just a shim for existing software).<p>See &quot;File Systems Unfit as Distributed Storage Backends: Lessons from 10 Years of Ceph Evolution&quot; written by the Ceph authors[1] about why they finally gave in and wrote Bluestore. The spoiler alert is they got rid of the filesystem precisely because &quot;a filesystem with files&quot; underneath, as you describe, was problematic and worked poorly in comparison (see the conclusion in Section 9.)<p>Many places do use POSIX filesystems for various reasons, even at large scale, of course.<p>[1] <a href="https:&#x2F;&#x2F;pdl.cmu.edu&#x2F;PDL-FTP&#x2F;Storage&#x2F;ceph-exp-sosp19.pdf" rel="nofollow">https:&#x2F;&#x2F;pdl.cmu.edu&#x2F;PDL-FTP&#x2F;Storage&#x2F;ceph-exp-sosp19.pdf</a></div><br/></div></div><div id="39661560" class="c"><input type="checkbox" id="c-39661560" checked=""/><div class="controls bullet"><span class="by">yencabulator</span><span>|</span><a href="#39660609">parent</a><span>|</span><a href="#39661302">prev</a><span>|</span><a href="#39657134">next</a><span>|</span><label class="collapse" for="c-39661560">[-]</label><label class="expand" for="c-39661560">[1 more]</label></div><br/><div class="children"><div class="content">Ceph&#x27;s BlueStore has talked direct to block devices, no filesystem in between, since 2017.<p><a href="https:&#x2F;&#x2F;ceph.com&#x2F;community&#x2F;new-luminous-bluestore&#x2F;" rel="nofollow">https:&#x2F;&#x2F;ceph.com&#x2F;community&#x2F;new-luminous-bluestore&#x2F;</a><p>[Disclaimer: ex-Ceph employee, from before BlueStore]</div><br/></div></div></div></div><div id="39657134" class="c"><input type="checkbox" id="c-39657134" checked=""/><div class="controls bullet"><span class="by">YouWhy</span><span>|</span><a href="#39660609">prev</a><span>|</span><a href="#39657131">next</a><span>|</span><label class="collapse" for="c-39657134">[-]</label><label class="expand" for="c-39657134">[14 more]</label></div><br/><div class="children"><div class="content">The article is well written, but I am annoyed at the attempt to gatekeep the definition of a filesystem.<p>Like literally any abstraction out there, filesystems are associated with a multitude of possible approaches with conceptually different semantics. It&#x27;s a bit sophistic to say that Postgres cannot be run on S3 because S3 is not a filesystem; a better choice would have been to explore the underlying assumptions; (I suspect latency would kill the hypothetical use case of Postgres over S3 even if S3 had incorporated the necessary API semantics - could somebody more knowledgeable chime in?).<p>A more interesting venue to pursue would be - what other additions could be made to the S3 API to make it more usable on its own right - for example, why doesn&#x27;t S3 offer more than one filename per blob? (e.g., a similar to what links do in POSIX)</div><br/><div id="39658325" class="c"><input type="checkbox" id="c-39658325" checked=""/><div class="controls bullet"><span class="by">jillesvangurp</span><span>|</span><a href="#39657134">parent</a><span>|</span><a href="#39657236">next</a><span>|</span><label class="collapse" for="c-39658325">[-]</label><label class="expand" for="c-39658325">[2 more]</label></div><br/><div class="children"><div class="content">The notion of postgres not being able to run on s3 has more to do with the characteristics of how it works than with it not being a filesystem. After all, people have developed fuse drivers for s3 so they can actually pretend it&#x27;s a filesystem. But using that to store a database is going to end in tears for the same reasons that using e.g. NFS for this is also likely to end in tears. You might get it to work but it won&#x27;t be fast or even reliable. And since NFS actually stands for networked file system, it&#x27;s hard to argue that NFS isn&#x27;t a filesystem.<p>Whether something is or isn&#x27;t a filesystem requires defining what that actually is. A system that stores files would be a simple explanation. Which is clearly something S3 is capable of. This probably upsets the definition gatekeepers for whatever more specific definitions they are guarding. But it has a nice simple logic to it.<p>It&#x27;s worth considering that file systems have had a long history, weren&#x27;t always the way they are now, and predate the invention of relational databases (like postgres). Technically before hard disks were invented in the fifties, we had no file systems. Just tapes and punch cards. A tape would consist a single blob of bits, which you&#x27;d load in memory. Or it would have multiple such blobs at known offsets. I had cassettes full of games for my commodore 64. But no disk drive. These blobs were called files but there was no file system. Sometime, after the invention of disks file systems were invented in the early sixties.<p>Hierarchical databases were common before relational databases and filesystems with directories are basically a hierarchical database. S3 lacking hierarchy as a simpler key value store clearly isn&#x27;t a hierarchical database. But of course it&#x27;s easy to mimic one simply by using &#x2F; characters in the keys. Which is how the fuse driver probably fakes directories. And S3 even has APIs to listfiles with a common prefix. A bigger deal is the inability to modify files. You can only replace them with other files (delete and add). That kind of is a show stopper for a database. Replacing the entire database on every write isn&#x27;t very practical.</div><br/><div id="39661770" class="c"><input type="checkbox" id="c-39661770" checked=""/><div class="controls bullet"><span class="by">buremba</span><span>|</span><a href="#39657134">root</a><span>|</span><a href="#39658325">parent</a><span>|</span><a href="#39657236">next</a><span>|</span><label class="collapse" for="c-39661770">[-]</label><label class="expand" for="c-39661770">[1 more]</label></div><br/><div class="children"><div class="content">Neon.tech runs Postgresql runs on S3. They persist the WAL to S3 so that they can replicate the data and bring it to local ssds I assume.</div><br/></div></div></div></div><div id="39657236" class="c"><input type="checkbox" id="c-39657236" checked=""/><div class="controls bullet"><span class="by">zX41ZdbW</span><span>|</span><a href="#39657134">parent</a><span>|</span><a href="#39658325">prev</a><span>|</span><a href="#39657156">next</a><span>|</span><label class="collapse" for="c-39657236">[-]</label><label class="expand" for="c-39657236">[7 more]</label></div><br/><div class="children"><div class="content">ClickHouse can work with S3 as a main storage. This is possible because a table is a set of immutable data parts. Data parts can be written once and deleted, possibly as a result of a background merge operation. S3 API is almost enough, except for cases of concurrent database updates. In this case, it is not possible to rely on S3 only because it does not support an atomic &quot;write if not exists&quot; operation. That&#x27;s why external, strongly consistent metadata storage is needed, which is handled by ClickHouse Keeper.</div><br/><div id="39661666" class="c"><input type="checkbox" id="c-39661666" checked=""/><div class="controls bullet"><span class="by">yencabulator</span><span>|</span><a href="#39657134">root</a><span>|</span><a href="#39657236">parent</a><span>|</span><a href="#39660331">next</a><span>|</span><label class="collapse" for="c-39661666">[-]</label><label class="expand" for="c-39661666">[1 more]</label></div><br/><div class="children"><div class="content">Google Cloud Storage supports create-if-not-exist and compare-and-swap on generation counter. S3 is much harder to use as a building block without tying your code into a second system like DynamoDB etc.<p><a href="https:&#x2F;&#x2F;pkg.go.dev&#x2F;cloud.google.com&#x2F;go&#x2F;storage#Conditions" rel="nofollow">https:&#x2F;&#x2F;pkg.go.dev&#x2F;cloud.google.com&#x2F;go&#x2F;storage#Conditions</a></div><br/></div></div><div id="39660331" class="c"><input type="checkbox" id="c-39660331" checked=""/><div class="controls bullet"><span class="by">mlhpdx</span><span>|</span><a href="#39657134">root</a><span>|</span><a href="#39657236">parent</a><span>|</span><a href="#39661666">prev</a><span>|</span><a href="#39657887">next</a><span>|</span><label class="collapse" for="c-39660331">[-]</label><label class="expand" for="c-39660331">[2 more]</label></div><br/><div class="children"><div class="content">Conditional PUT would be a great addition to S3, indeed.</div><br/><div id="39661734" class="c"><input type="checkbox" id="c-39661734" checked=""/><div class="controls bullet"><span class="by">buremba</span><span>|</span><a href="#39657134">root</a><span>|</span><a href="#39660331">parent</a><span>|</span><a href="#39657887">next</a><span>|</span><label class="collapse" for="c-39661734">[-]</label><label class="expand" for="c-39661734">[1 more]</label></div><br/><div class="children"><div class="content">That would probably require them to rewrite a non-trivial part of S3 from scratch.</div><br/></div></div></div></div><div id="39657887" class="c"><input type="checkbox" id="c-39657887" checked=""/><div class="controls bullet"><span class="by">afiori</span><span>|</span><a href="#39657134">root</a><span>|</span><a href="#39657236">parent</a><span>|</span><a href="#39660331">prev</a><span>|</span><a href="#39657156">next</a><span>|</span><label class="collapse" for="c-39657887">[-]</label><label class="expand" for="c-39657887">[3 more]</label></div><br/><div class="children"><div class="content">Is a &quot;write if not exists&quot; atomic operation enouhg as a concurrency primitive for database locks?</div><br/><div id="39661630" class="c"><input type="checkbox" id="c-39661630" checked=""/><div class="controls bullet"><span class="by">yencabulator</span><span>|</span><a href="#39657134">root</a><span>|</span><a href="#39657887">parent</a><span>|</span><a href="#39658897">next</a><span>|</span><label class="collapse" for="c-39661630">[-]</label><label class="expand" for="c-39661630">[1 more]</label></div><br/><div class="children"><div class="content">When talking about analytical databases for &quot;big data&quot;, yeah. They generally just want a &quot;atomically replace the list of Parquet files that make up this table&quot;, with one writer succeeding at a time.<p>That would not be a great base to build a transactional database on.</div><br/></div></div><div id="39658897" class="c"><input type="checkbox" id="c-39658897" checked=""/><div class="controls bullet"><span class="by">justincormack</span><span>|</span><a href="#39657134">root</a><span>|</span><a href="#39657887">parent</a><span>|</span><a href="#39661630">prev</a><span>|</span><a href="#39657156">next</a><span>|</span><label class="collapse" for="c-39658897">[-]</label><label class="expand" for="c-39658897">[1 more]</label></div><br/><div class="children"><div class="content">Yes, its not necessarily the most efficient mechanism (could be a lot of retries) but its sufficient. See the Delta Lake paper for example [0]<p>[0] <a href="https:&#x2F;&#x2F;people.eecs.berkeley.edu&#x2F;~matei&#x2F;papers&#x2F;2020&#x2F;vldb_delta_lake.pdf" rel="nofollow">https:&#x2F;&#x2F;people.eecs.berkeley.edu&#x2F;~matei&#x2F;papers&#x2F;2020&#x2F;vldb_del...</a></div><br/></div></div></div></div></div></div><div id="39657156" class="c"><input type="checkbox" id="c-39657156" checked=""/><div class="controls bullet"><span class="by">bilalq</span><span>|</span><a href="#39657134">parent</a><span>|</span><a href="#39657236">prev</a><span>|</span><a href="#39660549">next</a><span>|</span><label class="collapse" for="c-39657156">[-]</label><label class="expand" for="c-39657156">[1 more]</label></div><br/><div class="children"><div class="content">This might be of interest to you: <a href="https:&#x2F;&#x2F;neon.tech&#x2F;blog&#x2F;bring-your-own-s3-to-neon" rel="nofollow">https:&#x2F;&#x2F;neon.tech&#x2F;blog&#x2F;bring-your-own-s3-to-neon</a>.<p>There&#x27;s also the OG Aurora whitepaper: <a href="https:&#x2F;&#x2F;www.amazon.science&#x2F;publications&#x2F;amazon-aurora-design-considerations-for-high-throughput-cloud-native-relational-databases" rel="nofollow">https:&#x2F;&#x2F;www.amazon.science&#x2F;publications&#x2F;amazon-aurora-design...</a></div><br/></div></div><div id="39660549" class="c"><input type="checkbox" id="c-39660549" checked=""/><div class="controls bullet"><span class="by">defaultcompany</span><span>|</span><a href="#39657134">parent</a><span>|</span><a href="#39657156">prev</a><span>|</span><a href="#39658228">next</a><span>|</span><label class="collapse" for="c-39660549">[-]</label><label class="expand" for="c-39660549">[1 more]</label></div><br/><div class="children"><div class="content">I’ve wondered this also because it can be handy to have multiple ways of accessing the same file. For example to obfuscate database uuids if they are used in the key. In theory you could implement soft links in AWS by just storing a file with the path to the linked file. But it would be a lot of manual work.</div><br/></div></div></div></div><div id="39657131" class="c"><input type="checkbox" id="c-39657131" checked=""/><div class="controls bullet"><span class="by">dmarinus</span><span>|</span><a href="#39657134">prev</a><span>|</span><a href="#39657904">next</a><span>|</span><label class="collapse" for="c-39657131">[-]</label><label class="expand" for="c-39657131">[5 more]</label></div><br/><div class="children"><div class="content">I talked to people at AWS who work in RDS Aurora and they hinted they use S3 internally as a backend for MySQL and PostgreSQL.</div><br/><div id="39661049" class="c"><input type="checkbox" id="c-39661049" checked=""/><div class="controls bullet"><span class="by">WatchDog</span><span>|</span><a href="#39657131">parent</a><span>|</span><a href="#39664334">next</a><span>|</span><label class="collapse" for="c-39661049">[-]</label><label class="expand" for="c-39661049">[1 more]</label></div><br/><div class="children"><div class="content">Maybe for snapshots, but certainly not for live data.</div><br/></div></div><div id="39664334" class="c"><input type="checkbox" id="c-39664334" checked=""/><div class="controls bullet"><span class="by">shell_game</span><span>|</span><a href="#39657131">parent</a><span>|</span><a href="#39661049">prev</a><span>|</span><a href="#39657258">next</a><span>|</span><label class="collapse" for="c-39664334">[-]</label><label class="expand" for="c-39664334">[1 more]</label></div><br/><div class="children"><div class="content">EBS not S3</div><br/></div></div><div id="39657258" class="c"><input type="checkbox" id="c-39657258" checked=""/><div class="controls bullet"><span class="by">readyman</span><span>|</span><a href="#39657131">parent</a><span>|</span><a href="#39664334">prev</a><span>|</span><a href="#39657904">next</a><span>|</span><label class="collapse" for="c-39657258">[-]</label><label class="expand" for="c-39657258">[2 more]</label></div><br/><div class="children"><div class="content">Big if true. That was definitely not in the AWS cert I took lol.</div><br/><div id="39657472" class="c"><input type="checkbox" id="c-39657472" checked=""/><div class="controls bullet"><span class="by">multani</span><span>|</span><a href="#39657131">root</a><span>|</span><a href="#39657258">parent</a><span>|</span><a href="#39657904">next</a><span>|</span><label class="collapse" for="c-39657472">[-]</label><label class="expand" for="c-39657472">[1 more]</label></div><br/><div class="children"><div class="content">Separating compute and storage is one of the core idea behind Aurora. They talked about it in several places, for instance:<p>* <a href="https:&#x2F;&#x2F;www.amazon.science&#x2F;publications&#x2F;amazon-aurora-design-considerations-for-high-throughput-cloud-native-relational-databases" rel="nofollow">https:&#x2F;&#x2F;www.amazon.science&#x2F;publications&#x2F;amazon-aurora-design...</a>
* <a href="https:&#x2F;&#x2F;d1.awsstatic.com&#x2F;events&#x2F;reinvent&#x2F;2019&#x2F;REPEAT_Amazon_Aurora_storage_demystified_How_it_all_works_DAT309-R.pdf" rel="nofollow">https:&#x2F;&#x2F;d1.awsstatic.com&#x2F;events&#x2F;reinvent&#x2F;2019&#x2F;REPEAT_Amazon_...</a></div><br/></div></div></div></div></div></div><div id="39657904" class="c"><input type="checkbox" id="c-39657904" checked=""/><div class="controls bullet"><span class="by">wodenokoto</span><span>|</span><a href="#39657131">prev</a><span>|</span><a href="#39658529">next</a><span>|</span><label class="collapse" for="c-39657904">[-]</label><label class="expand" for="c-39657904">[6 more]</label></div><br/><div class="children"><div class="content">Is there a generic name for these distributed cloud file storages?<p>AWS is S3, google is buckets, Azure is blob storage, the open source version is … ?</div><br/><div id="39657941" class="c"><input type="checkbox" id="c-39657941" checked=""/><div class="controls bullet"><span class="by">dexwiz</span><span>|</span><a href="#39657904">parent</a><span>|</span><a href="#39659495">next</a><span>|</span><label class="collapse" for="c-39657941">[-]</label><label class="expand" for="c-39657941">[3 more]</label></div><br/><div class="children"><div class="content">Object Storage</div><br/><div id="39658295" class="c"><input type="checkbox" id="c-39658295" checked=""/><div class="controls bullet"><span class="by">jeffbr13</span><span>|</span><a href="#39657904">root</a><span>|</span><a href="#39657941">parent</a><span>|</span><a href="#39659495">next</a><span>|</span><label class="collapse" for="c-39658295">[-]</label><label class="expand" for="c-39658295">[2 more]</label></div><br/><div class="children"><div class="content">I tend to go by Binary Large OBject (BLOB) storage to discern between this kind of object storage and “object” as in OOP. BLOB is also what databases call files stored in columns.</div><br/><div id="39658526" class="c"><input type="checkbox" id="c-39658526" checked=""/><div class="controls bullet"><span class="by">OJFord</span><span>|</span><a href="#39657904">root</a><span>|</span><a href="#39658295">parent</a><span>|</span><a href="#39659495">next</a><span>|</span><label class="collapse" for="c-39658526">[-]</label><label class="expand" for="c-39658526">[1 more]</label></div><br/><div class="children"><div class="content">When would that be confusing? As in what would an AWS service offering OOP object storage be&#x2F;mean?</div><br/></div></div></div></div></div></div><div id="39659495" class="c"><input type="checkbox" id="c-39659495" checked=""/><div class="controls bullet"><span class="by">surajrmal</span><span>|</span><a href="#39657904">parent</a><span>|</span><a href="#39657941">prev</a><span>|</span><a href="#39659462">next</a><span>|</span><label class="collapse" for="c-39659495">[-]</label><label class="expand" for="c-39659495">[1 more]</label></div><br/><div class="children"><div class="content">Google buckets is a bit off - the product is called Google storage. Buckets are also a term used by s3 and are equivalent to azure blob storage containers. They are an intermediary layer that determines attributes for the objects stored within it such as ACLs and storage class (and therefore cost and performance).<p>As to your question, object storage[1] seems to be the generic term for the technology. Internally they all rely on naming files based on the hash of their contents for quick lookup, deduplication, and avoiding name clashes.<p>1: <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Object_storage" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Object_storage</a></div><br/></div></div><div id="39659462" class="c"><input type="checkbox" id="c-39659462" checked=""/><div class="controls bullet"><span class="by">gilbetron</span><span>|</span><a href="#39657904">parent</a><span>|</span><a href="#39659495">prev</a><span>|</span><a href="#39658529">next</a><span>|</span><label class="collapse" for="c-39659462">[-]</label><label class="expand" for="c-39659462">[1 more]</label></div><br/><div class="children"><div class="content">&quot;blob storage&quot; is the usual generic term, even though Azure uses it explicitly. It&#x27;s like calling adhesive bandages, &quot;bandaids&quot; even though that is a specific company&#x27;s term.</div><br/></div></div></div></div><div id="39658529" class="c"><input type="checkbox" id="c-39658529" checked=""/><div class="controls bullet"><span class="by">finalhacker</span><span>|</span><a href="#39657904">prev</a><span>|</span><a href="#39663236">next</a><span>|</span><label class="collapse" for="c-39658529">[-]</label><label class="expand" for="c-39658529">[1 more]</label></div><br/><div class="children"><div class="content">S3 not implementate vfs api, but you can treat it as a software defined storage filesystem. Just like Ceph.<p>there are so many applications depends on file storage, such as Mysql. But horizontal scale for those app still difficult in many case. Replace from vfs api to s3 storage perhaps is trending in my experience.</div><br/></div></div><div id="39663236" class="c"><input type="checkbox" id="c-39663236" checked=""/><div class="controls bullet"><span class="by">siliconc0w</span><span>|</span><a href="#39658529">prev</a><span>|</span><a href="#39659234">next</a><span>|</span><label class="collapse" for="c-39663236">[-]</label><label class="expand" for="c-39663236">[1 more]</label></div><br/><div class="children"><div class="content">I feel like a lot of applications can S3 but due to latency needs typically build a layer that sits in front that basically writes logs out to SSDs and then tiers to S3.  If S3 offered a fast, reasonably priced Append() API that probably go a long way in capturing those use-cases.</div><br/></div></div><div id="39659234" class="c"><input type="checkbox" id="c-39659234" checked=""/><div class="controls bullet"><span class="by">MatthiasPortzel</span><span>|</span><a href="#39663236">prev</a><span>|</span><a href="#39659859">next</a><span>|</span><label class="collapse" for="c-39659234">[-]</label><label class="expand" for="c-39659234">[3 more]</label></div><br/><div class="children"><div class="content">This article was an epiphany for me because I realized I&#x27;ve been thinking of the Unix filesystem as if it has two functions: read_file and write_file. (And then getting frustrated with the filesystem APIs in programming languages.)</div><br/><div id="39660862" class="c"><input type="checkbox" id="c-39660862" checked=""/><div class="controls bullet"><span class="by">markhahn</span><span>|</span><a href="#39659234">parent</a><span>|</span><a href="#39659859">next</a><span>|</span><label class="collapse" for="c-39660862">[-]</label><label class="expand" for="c-39660862">[2 more]</label></div><br/><div class="children"><div class="content">So you came from an S3 or other put-get world, and found actual filesystems odd?<p>I suppose that&#x27;s not so different from a WMP user&#x27;s epiphany when they discover processes, shells, etc.</div><br/><div id="39661142" class="c"><input type="checkbox" id="c-39661142" checked=""/><div class="controls bullet"><span class="by">MatthiasPortzel</span><span>|</span><a href="#39659234">root</a><span>|</span><a href="#39660862">parent</a><span>|</span><a href="#39659859">next</a><span>|</span><label class="collapse" for="c-39661142">[-]</label><label class="expand" for="c-39661142">[1 more]</label></div><br/><div class="children"><div class="content">Well I’m used to an application-level view of the file system.<p>A document editor or text editor opens files and saves files, but these are whole-document operations. I can’t open a document in Sublime Text without reading it, and I can’t save part of a file without saving all of it. So it’s not obvious that these would be different at an OS level.<p>As the post points out, there are uses for Unix’s sub-file-level read-and-write commands, but I’ve never needed them.</div><br/></div></div></div></div></div></div><div id="39659859" class="c"><input type="checkbox" id="c-39659859" checked=""/><div class="controls bullet"><span class="by">chrisblackwell</span><span>|</span><a href="#39659234">prev</a><span>|</span><a href="#39656978">next</a><span>|</span><label class="collapse" for="c-39659859">[-]</label><label class="expand" for="c-39659859">[4 more]</label></div><br/><div class="children"><div class="content">Random note: Has anyone noticed how fast the author&#x27;s webpage is? I know it&#x27;s static, but I mean it&#x27;s fast even for the DNS lookup. I would love to know what they have on.</div><br/><div id="39659961" class="c"><input type="checkbox" id="c-39659961" checked=""/><div class="controls bullet"><span class="by">adverbly</span><span>|</span><a href="#39659859">parent</a><span>|</span><a href="#39662099">next</a><span>|</span><label class="collapse" for="c-39659961">[-]</label><label class="expand" for="c-39659961">[1 more]</label></div><br/><div class="children"><div class="content">The response headers include<p>server: cloudflare<p>You said it though - the reason is that its static without any js&#x2F;frameworks&#x2F;SPA round trip requests.</div><br/></div></div><div id="39662099" class="c"><input type="checkbox" id="c-39662099" checked=""/><div class="controls bullet"><span class="by">wooptoo</span><span>|</span><a href="#39659859">parent</a><span>|</span><a href="#39659961">prev</a><span>|</span><a href="#39660352">next</a><span>|</span><label class="collapse" for="c-39662099">[-]</label><label class="expand" for="c-39662099">[1 more]</label></div><br/><div class="children"><div class="content">Could be using Cloudflare pages hosted on a R2 bucket: 
<a href="https:&#x2F;&#x2F;pages.cloudflare.com&#x2F;" rel="nofollow">https:&#x2F;&#x2F;pages.cloudflare.com&#x2F;</a></div><br/></div></div><div id="39660352" class="c"><input type="checkbox" id="c-39660352" checked=""/><div class="controls bullet"><span class="by">overstay8930</span><span>|</span><a href="#39659859">parent</a><span>|</span><a href="#39662099">prev</a><span>|</span><a href="#39656978">next</a><span>|</span><label class="collapse" for="c-39660352">[-]</label><label class="expand" for="c-39660352">[1 more]</label></div><br/><div class="children"><div class="content">Full stack Cloudflare is really fast</div><br/></div></div></div></div><div id="39656978" class="c"><input type="checkbox" id="c-39656978" checked=""/><div class="controls bullet"><span class="by">3weeksearlier</span><span>|</span><a href="#39659859">prev</a><span>|</span><a href="#39662896">next</a><span>|</span><label class="collapse" for="c-39656978">[-]</label><label class="expand" for="c-39656978">[13 more]</label></div><br/><div class="children"><div class="content">I dunno, are features like partial file overwrites necessary to make something a filesystem? This reminds me of how there are lots of internal systems at Google whose maintainers keep asserting are not filesystems, but everyone considers them so, to the point where &quot;_____ is not a filesystem&quot; has become an inside joke.</div><br/><div id="39657417" class="c"><input type="checkbox" id="c-39657417" checked=""/><div class="controls bullet"><span class="by">CobrastanJorji</span><span>|</span><a href="#39656978">parent</a><span>|</span><a href="#39661852">next</a><span>|</span><label class="collapse" for="c-39657417">[-]</label><label class="expand" for="c-39657417">[3 more]</label></div><br/><div class="children"><div class="content">They are necessary because as soon as someone decides that S3 is a filesystem, they will look at the other cloud &quot;filesystems,&quot; notice that S3 is cheaper than most of them, and then for some reason they will decide to run giant Hadoop fs stuff on it or mount a relational database on it or all other manner of stupidity. I guarantee you S3&#x27;s customer-facing engineers are fielding multiple calls per week from customers who are angry that S3 isn&#x27;t as fast as some real filesystem solution that the customer migrated from because S3 was cheaper.<p>When people decide that X is a filesystem, they try to use it like it&#x27;s a local, POSIX filesystem, and that&#x27;s terrible because it won&#x27;t be immediately obvious why it&#x27;s a stupid plan.</div><br/><div id="39657646" class="c"><input type="checkbox" id="c-39657646" checked=""/><div class="controls bullet"><span class="by">albert_e</span><span>|</span><a href="#39656978">root</a><span>|</span><a href="#39657417">parent</a><span>|</span><a href="#39661852">next</a><span>|</span><label class="collapse" for="c-39657646">[-]</label><label class="expand" for="c-39657646">[2 more]</label></div><br/><div class="children"><div class="content">If a customer makes an IT decision as big as running Hadoop or RDBMS with S3 as storage ... but does not consult at least a Associate level AWS Certified architect (who are doke a dozen) for at least one day worth of advice which is probably a couple of hundred dollars at most ...<p>Can we really blame AWS?<p>I am sure none of official AWS documentations or examples show such an architecture.<p>----<p>Amazon EMR can run Hadoop and use Amazon S3 as storage via EMR FS.<p>&quot;S3 mountpoints&quot; are a feature specifically for workloads that need to see S3 as a file system.<p>For block storage workloads there is EBS and EFS and FSx that AWS heavily advertises.</div><br/><div id="39659185" class="c"><input type="checkbox" id="c-39659185" checked=""/><div class="controls bullet"><span class="by">albert_e</span><span>|</span><a href="#39656978">root</a><span>|</span><a href="#39657646">parent</a><span>|</span><a href="#39661852">next</a><span>|</span><label class="collapse" for="c-39659185">[-]</label><label class="expand" for="c-39659185">[1 more]</label></div><br/><div class="children"><div class="content">*dime a dozen<p>(Apologies for typos. The &quot;noprocrast&quot; setting sometimes locks us out of HN right after submitting a comment. And it is now too late, not editable)</div><br/></div></div></div></div></div></div><div id="39661852" class="c"><input type="checkbox" id="c-39661852" checked=""/><div class="controls bullet"><span class="by">yencabulator</span><span>|</span><a href="#39656978">parent</a><span>|</span><a href="#39657417">prev</a><span>|</span><a href="#39657078">next</a><span>|</span><label class="collapse" for="c-39661852">[-]</label><label class="expand" for="c-39661852">[1 more]</label></div><br/><div class="children"><div class="content">The problem is once you let go of those semantics, a lot of software stops working if run against such a &quot;filesystem&quot;. If you dilute the meaning of &quot;filesystem&quot; too much, it becomes less useful as a term.<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Andrew_File_System" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Andrew_File_System</a> was interesting, I&#x27;d actually love to see something similar re-implemented with modern ideas, but it&#x27;s more of an direct-access archival system than a general-purpose filesystem[1], you can&#x27;t just put files written by arbitrary software on it. It&#x27;s a bit like NFS without locks&amp;leases, but even less like a normal filesystem; only really good for files created once that &quot;settle down&quot; into effectively being read-only.<p>[1]: I wrote <a href="https:&#x2F;&#x2F;github.com&#x2F;bazil&#x2F;plop">https:&#x2F;&#x2F;github.com&#x2F;bazil&#x2F;plop</a> that is (unfortunately undocumented) content-addressed immutable file storage over object storage, used in conjunction with a git repo with symlinks to it to manage the &quot;naming layer&quot;. See <a href="https:&#x2F;&#x2F;bazil.org&#x2F;doc&#x2F;" rel="nofollow">https:&#x2F;&#x2F;bazil.org&#x2F;doc&#x2F;</a> for background, plop is basically a simplification of the ideas to get to working code easier. Site hasn&#x27;t been updated in almost a decade, wow. It&#x27;s in everyday use though!</div><br/></div></div><div id="39657078" class="c"><input type="checkbox" id="c-39657078" checked=""/><div class="controls bullet"><span class="by">fiddlerwoaroof</span><span>|</span><a href="#39656978">parent</a><span>|</span><a href="#39661852">prev</a><span>|</span><a href="#39657861">next</a><span>|</span><label class="collapse" for="c-39657078">[-]</label><label class="expand" for="c-39657078">[6 more]</label></div><br/><div class="children"><div class="content">Yeah, it’s sort of funny how “POSIXish semantics” has become our definition of these things, when it’s just one kind of thing that’s been called a filesystem historically.</div><br/><div id="39657117" class="c"><input type="checkbox" id="c-39657117" checked=""/><div class="controls bullet"><span class="by">mickael-kerjean</span><span>|</span><a href="#39656978">root</a><span>|</span><a href="#39657078">parent</a><span>|</span><a href="#39657751">next</a><span>|</span><label class="collapse" for="c-39657117">[-]</label><label class="expand" for="c-39657117">[4 more]</label></div><br/><div class="children"><div class="content">Fun experiment I made with my mum, building a storage independent dropbox like UI [1] for anything that implement this interface:<p><pre><code>  type IBackend interface {
    Ls(path string) ([]os.FileInfo, error)
    Cat(path string) (io.ReadCloser, error)
    Mkdir(path string) error
    Rm(path string) error
    Mv(from string, to string) error
    Save(path string, file io.Reader) error
    Touch(path string) error
  }
</code></pre>
My mum really couldn&#x27;t care less about the posix semantic as soon as she can see the pictures of my kid which happen to be on S3<p>[1] <a href="https:&#x2F;&#x2F;github.com&#x2F;mickael-kerjean&#x2F;filestash">https:&#x2F;&#x2F;github.com&#x2F;mickael-kerjean&#x2F;filestash</a></div><br/><div id="39657148" class="c"><input type="checkbox" id="c-39657148" checked=""/><div class="controls bullet"><span class="by">wwalexander</span><span>|</span><a href="#39656978">root</a><span>|</span><a href="#39657117">parent</a><span>|</span><a href="#39658600">next</a><span>|</span><label class="collapse" for="c-39657148">[-]</label><label class="expand" for="c-39657148">[1 more]</label></div><br/><div class="children"><div class="content">Reducing things to basically the interface you laid out is the point of 9p [1], and is what Plan 9’s UNIX-but-distributed design was built on top of. Same inventor as Go! If you haven’t dived down the Plan 9 rabbit hole yet, it’s a beautiful and haunting vision of how simple cloud computing could have been.<p>[1] <a href="https:&#x2F;&#x2F;9fans.github.io&#x2F;plan9port&#x2F;man&#x2F;man9&#x2F;intro.html" rel="nofollow">https:&#x2F;&#x2F;9fans.github.io&#x2F;plan9port&#x2F;man&#x2F;man9&#x2F;intro.html</a></div><br/></div></div><div id="39658600" class="c"><input type="checkbox" id="c-39658600" checked=""/><div class="controls bullet"><span class="by">MrJohz</span><span>|</span><a href="#39656978">root</a><span>|</span><a href="#39657117">parent</a><span>|</span><a href="#39657148">prev</a><span>|</span><a href="#39657751">next</a><span>|</span><label class="collapse" for="c-39658600">[-]</label><label class="expand" for="c-39658600">[2 more]</label></div><br/><div class="children"><div class="content">I think this interface is less interesting than the semantics behind it, particularly when it comes to concurrency: what happens when you delete a folder, and then try and create a file in that folder at the same time? What happens when you move a folder to a new location, and during that move, delete the new or old folders?<p>Like yes, for your mum&#x27;s use case, with a single user, it&#x27;s probably not all that important that you cover those edge cases, but every time I&#x27;ve built pseudo-filesystems on top of non-filesystem storage APIs, those sorts of semantic questions have been where all the problems have hidden. It&#x27;s not particularly hard to implement the interface you&#x27;ve described, but it&#x27;s very hard to do it in such a way that, for example, you never have dangling files that exist but aren&#x27;t contained in any folder, or that you never have multiple files with the same path, and so on.</div><br/><div id="39663328" class="c"><input type="checkbox" id="c-39663328" checked=""/><div class="controls bullet"><span class="by">mickael-kerjean</span><span>|</span><a href="#39656978">root</a><span>|</span><a href="#39658600">parent</a><span>|</span><a href="#39657751">next</a><span>|</span><label class="collapse" for="c-39663328">[-]</label><label class="expand" for="c-39663328">[1 more]</label></div><br/><div class="children"><div class="content">All those considerations are important when implementing the interface but the interface itself isn&#x27;t invalidated by those concerns and can cope with those constraints fine.</div><br/></div></div></div></div></div></div><div id="39657751" class="c"><input type="checkbox" id="c-39657751" checked=""/><div class="controls bullet"><span class="by">DonHopkins</span><span>|</span><a href="#39656978">root</a><span>|</span><a href="#39657078">parent</a><span>|</span><a href="#39657117">prev</a><span>|</span><a href="#39657861">next</a><span>|</span><label class="collapse" for="c-39657751">[-]</label><label class="expand" for="c-39657751">[1 more]</label></div><br/><div class="children"><div class="content">Can S3 murder your wife like ReiserFS and Reiser4?<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;w&#x2F;index.php?title=Comparison_of_file_systems&amp;oldid=209063556#Features" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;w&#x2F;index.php?title=Comparison_of_fil...</a></div><br/></div></div></div></div><div id="39657861" class="c"><input type="checkbox" id="c-39657861" checked=""/><div class="controls bullet"><span class="by">karmasimida</span><span>|</span><a href="#39656978">parent</a><span>|</span><a href="#39657078">prev</a><span>|</span><a href="#39658225">next</a><span>|</span><label class="collapse" for="c-39657861">[-]</label><label class="expand" for="c-39657861">[1 more]</label></div><br/><div class="children"><div class="content">Exactly, especially when the concept of filesystem really is defined before the whole internet scale becomes a thing or reality.<p>Maybe S3 isn&#x27;t a filesystem according to this definition, but does it really matter to make it one? I doubt it. The Elastic Filesystem is also an AWS product, but you can&#x27;t really work as one as you have locally, any folder over 20k files basically will timeout if you do a ls. Does it make EFS a filesystem or not?</div><br/></div></div></div></div><div id="39662896" class="c"><input type="checkbox" id="c-39662896" checked=""/><div class="controls bullet"><span class="by">OnlyMortal</span><span>|</span><a href="#39656978">prev</a><span>|</span><label class="collapse" for="c-39662896">[-]</label><label class="expand" for="c-39662896">[1 more]</label></div><br/><div class="children"><div class="content">It can be a file system.<p>I’ve written my own FUSE that uses Rabin Chunking and stores the data (and meta) in S3. The C++&#x2F;AWS SDK FUSE is connected to a Go SMB server that runs locally on my Mac and works with (local) TimeMachine.<p>I use Wasabi for cost and speed reasons.</div><br/></div></div></div></div></div></div></div></body></html>