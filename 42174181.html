<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1732266086309" as="style"/><link rel="stylesheet" href="styles.css?v=1732266086309"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.cs.toronto.edu/~duvenaud/distill_bayes_net/public/">Bayesian Neural Networks</a> <span class="domain">(<a href="https://www.cs.toronto.edu">www.cs.toronto.edu</a>)</span></div><div class="subtext"><span>reqo</span> | <span>30 comments</span></div><br/><div><div id="42209710" class="c"><input type="checkbox" id="c-42209710" checked=""/><div class="controls bullet"><span class="by">dccsillag</span><span>|</span><a href="#42210395">next</a><span>|</span><label class="collapse" for="c-42209710">[-]</label><label class="expand" for="c-42209710">[14 more]</label></div><br/><div class="children"><div class="content">Bayesian Neural Networks just seem like a failed approach, unfortunately.
For one, Bayesian inference and UQ fundamentally depends on the choice of the prior, but this is rarely discussed in the Bayesian NN literature and practice, and is further compounded by how fundamentally hard to interpret and choose these priors are (what is the intuition behind a NN&#x27;s parameters?). Add to that the fact that the Bayesian inference is very much approximate, and you should see the trouble.<p>If you want UQ, &#x27;frequentist nonparametric&#x27; approaches like Conformal Prediction and Calibration&#x2F;Multi-Calibration methods seem to work quite well (especilly when combined with the standard ML machinery of taking a log-likelihood as your loss), and do not suffer from any of the issues above while also giving you formal guarantees of correctness. They are a strict improvement over Bayesian NNs, IMO.</div><br/><div id="42210714" class="c"><input type="checkbox" id="c-42210714" checked=""/><div class="controls bullet"><span class="by">waldrews</span><span>|</span><a href="#42209710">parent</a><span>|</span><a href="#42210454">next</a><span>|</span><label class="collapse" for="c-42210714">[-]</label><label class="expand" for="c-42210714">[2 more]</label></div><br/><div class="children"><div class="content">The Conformal Prediction advocates (especially a certain prominent Twitter account) tend to rehash old frequentist-vs-bayesian arguments with more heated rhetoric than strictly necessary.  That fight has been going on for almost a century now.  Bayesian counterargument (in caricature form) would be that MLE frequentists just choose an arbitrary (flat) prior, and penalty hyperparameters (common in NN) are a de facto prior.  The formal guarantees only have bite in the asymptotic setting or require convoluted statements about probabilities over repeated experiments; and asymptotically, the choice of prior doesn&#x27;t matter anyway.<p>(I&#x27;m a moderate that uses both approaches, seeing them as part of a general hierarchical modeling method, which means I get mocked by either side for lack of purity).<p>Bayesians are losing ground at the moment because their computational methods haven&#x27;t been advanced as fast by the GPU revolution for reasons having to do with difficulty in parallelization, but there&#x27;s serious practical work (especially using JAX) to catch up, and the whole normalizing flow literature might just get us past the limitations of MCMC for hard problems.<p>But having said that, Conformal Prediction works as advertised for UQ as a wrapper on any point estimating model.  If you&#x27;ve got the data for it - and in the ML setting you do - and you don&#x27;t care about things like missing data imputation, error in inputs, non-iid spatio-temporal and hierarchical structures, mixtures of models, evidence decay, unbalanced data where small-data islands coexist big data - all the complicated situations where Bayesian methods just automatically work and other methods require elaborate workarounds, yup, use Conformal Prediction.<p>Calibration is also a pretty magical way to improve just about any estimator.  It&#x27;s cheap to do and it works (although hard to guarantee anything with that in the general case...)<p>And don&#x27;t forget quantile regression penalties!  Awkward to apply in the NN setting, but an easy and effective way to do UQ in XGBoost world.</div><br/><div id="42211116" class="c"><input type="checkbox" id="c-42211116" checked=""/><div class="controls bullet"><span class="by">dccsillag</span><span>|</span><a href="#42209710">root</a><span>|</span><a href="#42210714">parent</a><span>|</span><a href="#42210454">next</a><span>|</span><label class="collapse" for="c-42211116">[-]</label><label class="expand" for="c-42211116">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, I know the account you are talking about, it really is a bit over the top. It&#x27;s a shame, I&#x27;ve met a bunch of people who mentioned that they were actually turned away from Conformal Prediction due to them.<p>&gt; But having said that, Conformal Prediction works as advertised for UQ as a wrapper on any point estimating model. If you&#x27;ve got the data for it - and in the ML setting you do - and you don&#x27;t care about things like missing data imputation, error in inputs, non-iid spatio-temporal and hierarchical structures, mixtures of models, evidence decay, unbalanced data where small-data islands coexist big data - all the complicated situations where Bayesian methods just automatically work and other methods require elaborate workarounds, yup, use Conformal Prediction.<p>Many of these things can actually work really well with Conformal Prediction, but the algorithms require extensions (much like if you are doing Bayesian inference, you also need to update your model accordingly!). They generally end up being some form of reweighting to compensate for the distribution shifts (excluding the Online Conformal Prediction literature, which is another beast entirely). Also, worth noting that if you have iid data then Conformal Prediction is remarkably data-efficient; as little as 20 samples are enough for it to start working for 95% predictive intervals, and with 50 samples (and with almost surely unique conformity scores) it&#x27;s going to match 95% coverage fairly tightly.</div><br/></div></div></div></div><div id="42210454" class="c"><input type="checkbox" id="c-42210454" checked=""/><div class="controls bullet"><span class="by">duvenaud</span><span>|</span><a href="#42209710">parent</a><span>|</span><a href="#42210714">prev</a><span>|</span><a href="#42211431">next</a><span>|</span><label class="collapse" for="c-42210454">[-]</label><label class="expand" for="c-42210454">[5 more]</label></div><br/><div class="children"><div class="content">I agree that Bayesian neural networks haven&#x27;t been worth it in practice for many applications, but I think the main problem is that it&#x27;s usually better to spend your compute training a single set of weights for a larger model, rather than doing approximate inference over weights in a smaller model.  The exception is probably scientific applications where you mostly know the model, but then you don&#x27;t really need a neural net anymore.<p>Choosing a prior is hard, but I&#x27;d say it&#x27;s analogously hard to choosing an architecture - if all else fails, you can do a brute force search, and you even have the marginal likelihood to guide you.  I don&#x27;t think it&#x27;s the main reason why people don&#x27;t use BNNs much.</div><br/><div id="42211548" class="c"><input type="checkbox" id="c-42211548" checked=""/><div class="controls bullet"><span class="by">dkga</span><span>|</span><a href="#42209710">root</a><span>|</span><a href="#42210454">parent</a><span>|</span><a href="#42211431">next</a><span>|</span><label class="collapse" for="c-42211548">[-]</label><label class="expand" for="c-42211548">[4 more]</label></div><br/><div class="children"><div class="content">I disagree with one conceptual point; if you are truly Bayesian you don’t “choose” a prior, by definition you “already have” a prior that you are updating with data to get to a posterior.</div><br/><div id="42211942" class="c"><input type="checkbox" id="c-42211942" checked=""/><div class="controls bullet"><span class="by">abm53</span><span>|</span><a href="#42209710">root</a><span>|</span><a href="#42211548">parent</a><span>|</span><a href="#42211922">next</a><span>|</span><label class="collapse" for="c-42211942">[-]</label><label class="expand" for="c-42211942">[2 more]</label></div><br/><div class="children"><div class="content">100% correct, but there are ways to push Bayesian inference back a step to justify this sort of thing.<p>It of course makes the problem even more complex and likely requires further approximations to computing the posterior (or even the MAP solution).<p>This stretches the notion that you are still doing Bayesian reasoning but can still lead to useful insights.</div><br/><div id="42212177" class="c"><input type="checkbox" id="c-42212177" checked=""/><div class="controls bullet"><span class="by">DiscourseFan</span><span>|</span><a href="#42209710">root</a><span>|</span><a href="#42211942">parent</a><span>|</span><a href="#42211922">next</a><span>|</span><label class="collapse" for="c-42212177">[-]</label><label class="expand" for="c-42212177">[1 more]</label></div><br/><div class="children"><div class="content">Probably should just call it something else then; though, I gather that the simplicity of Bayes theorom belies the complexity of what it hides.</div><br/></div></div></div></div><div id="42211922" class="c"><input type="checkbox" id="c-42211922" checked=""/><div class="controls bullet"><span class="by">hgomersall</span><span>|</span><a href="#42209710">root</a><span>|</span><a href="#42211548">parent</a><span>|</span><a href="#42211942">prev</a><span>|</span><a href="#42211431">next</a><span>|</span><label class="collapse" for="c-42211922">[-]</label><label class="expand" for="c-42211922">[1 more]</label></div><br/><div class="children"><div class="content">At some level, you have to choose something. You can&#x27;t know every level in your hierarchy.</div><br/></div></div></div></div></div></div><div id="42211431" class="c"><input type="checkbox" id="c-42211431" checked=""/><div class="controls bullet"><span class="by">fjkdlsjflkds</span><span>|</span><a href="#42209710">parent</a><span>|</span><a href="#42210454">prev</a><span>|</span><a href="#42211539">next</a><span>|</span><label class="collapse" for="c-42211431">[-]</label><label class="expand" for="c-42211431">[1 more]</label></div><br/><div class="children"><div class="content">&gt; For one, Bayesian inference and UQ fundamentally depends on the choice of the prior, but this is rarely discussed in the Bayesian NN literature and practice, and is further compounded by how fundamentally hard to interpret and choose these priors are (what is the intuition behind a NN&#x27;s parameters?).<p>I agree that, computationally, it is hard to justify the use of Bayesian methods on large-scale neural networks when stochastic gradient descent (and friends) is so damn efficient and effective.<p>On the other hand, the fact that there&#x27;s a dependence on (subjective) priors is hardly a fair critique: non-Bayesian training of neural networks also depends on the use of (subjective) loss functions with (subjective) regularization terms (in fact, it can be shown that, mathematically, the use of priors is precisely equivalent to adding regularization to a loss function). Non-Bayesian training of neural networks is not &quot;a failed approach&quot; just because someone can arbitrarily choose L1 regularization (i.e., a Laplacian prior) over L2 regularization (i.e., a Gaussian prior).<p>Furthermore, we do have <i>some</i> intuition over NN parameters (particularly when inputs and outputs are properly scaled): a value of 10^15 should be less likely than a value of 0. Note that, in Bayesian practice, people often use weakly-informative priors (see, e.g., <a href="http:&#x2F;&#x2F;www.stat.columbia.edu&#x2F;~gelman&#x2F;presentations&#x2F;weakpriorstalk.pdf" rel="nofollow">http:&#x2F;&#x2F;www.stat.columbia.edu&#x2F;~gelman&#x2F;presentations&#x2F;weakprior...</a>) to encode such intuitive statements while ensuring that (for all practical purposes) the data will effectively overwhelm the prior (again, this is equivalent to adding a minimal amount of regularization to a loss function, to make a problem well-posed when e.g. you have more parameters than data points).</div><br/></div></div><div id="42211539" class="c"><input type="checkbox" id="c-42211539" checked=""/><div class="controls bullet"><span class="by">dkga</span><span>|</span><a href="#42209710">parent</a><span>|</span><a href="#42211431">prev</a><span>|</span><a href="#42210339">next</a><span>|</span><label class="collapse" for="c-42211539">[-]</label><label class="expand" for="c-42211539">[1 more]</label></div><br/><div class="children"><div class="content">I’m not an expert in BNNs but the prior does not need to be justified in terms of each parameter. Bayesian analysis frequently uses hyperparameters to set the overall tightness or looseness of the parameters (a la Minnesota priors in the econometric literature for example). This would be a similar regularisation intuition as, eg, L1 and L2 regularisation in traditional NN training. This is of course just one example.</div><br/></div></div><div id="42210339" class="c"><input type="checkbox" id="c-42210339" checked=""/><div class="controls bullet"><span class="by">bravura</span><span>|</span><a href="#42209710">parent</a><span>|</span><a href="#42211539">prev</a><span>|</span><a href="#42211553">next</a><span>|</span><label class="collapse" for="c-42210339">[-]</label><label class="expand" for="c-42210339">[2 more]</label></div><br/><div class="children"><div class="content">Conformal learning is relatively new to me. Tell me if I&#x27;m getting any of this wrong: Conformal learning is a frequentist approach that uses a calibration set to determine how unusual a prediction is.<p>It seems like the main time they aren&#x27;t a strict improvement over bayesian methods is when it is difficult to define your calibration set? I know this scenario isn&#x27;t so commonplace, but I&#x27;m working in a scenario where I quickly looked at conformal learning and wasn&#x27;t sure if it is applicable.</div><br/><div id="42211092" class="c"><input type="checkbox" id="c-42211092" checked=""/><div class="controls bullet"><span class="by">dccsillag</span><span>|</span><a href="#42209710">root</a><span>|</span><a href="#42210339">parent</a><span>|</span><a href="#42211553">next</a><span>|</span><label class="collapse" for="c-42211092">[-]</label><label class="expand" for="c-42211092">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s a particular form of Conformal Prediction, called Split Conformal Prediction. Incidentally, it&#x27;s also one of the best ones (i.e., most extensible, strongest guarantees, easiest to implement, remarkably sample-efficient).<p>Making a calibration set is pretty easy, it&#x27;s just a data split (just like the train&#x2F;test split). The hardest part (which is still fairly easy) is creating a &#x27;conformity score&#x27;, which is a function that receives the input and a candidate output and scores how well this candidate output &#x27;conforms&#x27; to the input. This is where an underlying ML model can come in handy: it can, itself, estimate this! Split Conformal Prediction then does a fairly simple quantile calculation on these scores (or some variant thereof) to then form the set prediction.<p>In a sense, you could use Bayesian NNs to produce a conformity score. But that doesn&#x27;t seem to be much better than just using e.g. the model&#x27;s logits for your conformity score. Theory-wise, Conformal Prediction methods have a number of favorable guarantees that Bayesian models (and especially Bayesian NNs) generally don&#x27;t, and in practice we&#x27;ve seen that conditional on the model giving calibrated outputs (which is guaranteed for Conformal Prediction, but not for Bayesian NNs), Conformal Prediction predicted sets seem to be tighter than the Bayesian NN ones.</div><br/></div></div></div></div><div id="42211553" class="c"><input type="checkbox" id="c-42211553" checked=""/><div class="controls bullet"><span class="by">nvrmnd</span><span>|</span><a href="#42209710">parent</a><span>|</span><a href="#42210339">prev</a><span>|</span><a href="#42210395">next</a><span>|</span><label class="collapse" for="c-42211553">[-]</label><label class="expand" for="c-42211553">[2 more]</label></div><br/><div class="children"><div class="content">What is &#x27;UQ&#x27;, I assume some measure of uncertainty over your model outputs?</div><br/><div id="42211798" class="c"><input type="checkbox" id="c-42211798" checked=""/><div class="controls bullet"><span class="by">rscho</span><span>|</span><a href="#42209710">root</a><span>|</span><a href="#42211553">parent</a><span>|</span><a href="#42210395">next</a><span>|</span><label class="collapse" for="c-42211798">[-]</label><label class="expand" for="c-42211798">[1 more]</label></div><br/><div class="children"><div class="content">Unbiased quantifier</div><br/></div></div></div></div></div></div><div id="42210395" class="c"><input type="checkbox" id="c-42210395" checked=""/><div class="controls bullet"><span class="by">duvenaud</span><span>|</span><a href="#42209710">prev</a><span>|</span><a href="#42209622">next</a><span>|</span><label class="collapse" for="c-42210395">[-]</label><label class="expand" for="c-42210395">[4 more]</label></div><br/><div class="children"><div class="content">Author here!  What a surprise.  This was an abandoned project from 2019, that we never linked or advertised anywhere as far as I know.  Anyways, happy to answer questions.</div><br/><div id="42211237" class="c"><input type="checkbox" id="c-42211237" checked=""/><div class="controls bullet"><span class="by">idontknowmuch</span><span>|</span><a href="#42210395">parent</a><span>|</span><a href="#42210924">next</a><span>|</span><label class="collapse" for="c-42211237">[-]</label><label class="expand" for="c-42211237">[1 more]</label></div><br/><div class="children"><div class="content">Somewhat related — I’d love to hear your thoughts on dex-Lang and Haskell for array programming?</div><br/></div></div><div id="42210924" class="c"><input type="checkbox" id="c-42210924" checked=""/><div class="controls bullet"><span class="by">esafak</span><span>|</span><a href="#42210395">parent</a><span>|</span><a href="#42211237">prev</a><span>|</span><a href="#42211309">next</a><span>|</span><label class="collapse" for="c-42210924">[-]</label><label class="expand" for="c-42210924">[1 more]</label></div><br/><div class="children"><div class="content">just a little typo, but it&#x27;s Kullback-<i>Leibler</i>.</div><br/></div></div><div id="42211309" class="c"><input type="checkbox" id="c-42211309" checked=""/><div class="controls bullet"><span class="by">mugivarra69</span><span>|</span><a href="#42210395">parent</a><span>|</span><a href="#42210924">prev</a><span>|</span><a href="#42209622">next</a><span>|</span><label class="collapse" for="c-42211309">[-]</label><label class="expand" for="c-42211309">[1 more]</label></div><br/><div class="children"><div class="content">why (if) was this not picked for further research? i know that oatml did quite amount of work on this front as well and it seems the direction is still being worked on. want to get ur 2 cent on this approach.</div><br/></div></div></div></div><div id="42209622" class="c"><input type="checkbox" id="c-42209622" checked=""/><div class="controls bullet"><span class="by">datastoat</span><span>|</span><a href="#42210395">prev</a><span>|</span><a href="#42210346">next</a><span>|</span><label class="collapse" for="c-42209622">[-]</label><label class="expand" for="c-42209622">[7 more]</label></div><br/><div class="children"><div class="content">I like Bayesian inference for few-parameter models where I have solid grounds for choosing my priors. For neural networks, I like to ask people &quot;what&#x27;s your prior for ReLU versus LeakyReLU versus sigmoid?&quot; and I&#x27;ve never gotten a convincing answer.</div><br/><div id="42210422" class="c"><input type="checkbox" id="c-42210422" checked=""/><div class="controls bullet"><span class="by">duvenaud</span><span>|</span><a href="#42209622">parent</a><span>|</span><a href="#42210016">next</a><span>|</span><label class="collapse" for="c-42210422">[-]</label><label class="expand" for="c-42210422">[1 more]</label></div><br/><div class="children"><div class="content">I agree choosing priors is hard, but choosing ReLU versus LeakyReLU versus sigmoid seems like a problem with using neural nets in general, not Bayesian neural nets in particular.  Am I misunderstanding?</div><br/></div></div><div id="42210016" class="c"><input type="checkbox" id="c-42210016" checked=""/><div class="controls bullet"><span class="by">pkoird</span><span>|</span><a href="#42209622">parent</a><span>|</span><a href="#42210422">prev</a><span>|</span><a href="#42209708">next</a><span>|</span><label class="collapse" for="c-42210016">[-]</label><label class="expand" for="c-42210016">[4 more]</label></div><br/><div class="children"><div class="content">Kolmogorov Arnold nets might have an answer for you!</div><br/><div id="42211129" class="c"><input type="checkbox" id="c-42211129" checked=""/><div class="controls bullet"><span class="by">dccsillag</span><span>|</span><a href="#42209622">root</a><span>|</span><a href="#42210016">parent</a><span>|</span><a href="#42210051">next</a><span>|</span><label class="collapse" for="c-42211129">[-]</label><label class="expand" for="c-42211129">[1 more]</label></div><br/><div class="children"><div class="content">Ah, Kolmogorov Arnold Networks. Perhaps the only model I have ever tried that managed to fairly often get AUCs below 0.5 in my tabular ML benchmarks. It even managed to get a frankly disturbing 0.33, where pretty much any other method (including linear regression, IIRC) would get &gt;=0.99!</div><br/></div></div><div id="42210051" class="c"><input type="checkbox" id="c-42210051" checked=""/><div class="controls bullet"><span class="by">jwuphysics</span><span>|</span><a href="#42209622">root</a><span>|</span><a href="#42210016">parent</a><span>|</span><a href="#42211129">prev</a><span>|</span><a href="#42209708">next</a><span>|</span><label class="collapse" for="c-42210051">[-]</label><label class="expand" for="c-42210051">[2 more]</label></div><br/><div class="children"><div class="content">Could you say a bit more about how so?</div><br/><div id="42210105" class="c"><input type="checkbox" id="c-42210105" checked=""/><div class="controls bullet"><span class="by">pkoird</span><span>|</span><a href="#42209622">root</a><span>|</span><a href="#42210051">parent</a><span>|</span><a href="#42209708">next</a><span>|</span><label class="collapse" for="c-42210105">[-]</label><label class="expand" for="c-42210105">[1 more]</label></div><br/><div class="children"><div class="content">KANs have learnable activations based on splines parameterized on few variables. You can specify a prior over those variables, effectively establishing a prior over your activation function.</div><br/></div></div></div></div></div></div><div id="42209708" class="c"><input type="checkbox" id="c-42209708" checked=""/><div class="controls bullet"><span class="by">salty_biscuits</span><span>|</span><a href="#42209622">parent</a><span>|</span><a href="#42210016">prev</a><span>|</span><a href="#42210346">next</a><span>|</span><label class="collapse" for="c-42209708">[-]</label><label class="expand" for="c-42209708">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m sure there is a way of interpreting a relu as a sparsity prior on the layer.</div><br/></div></div></div></div><div id="42209683" class="c"><input type="checkbox" id="c-42209683" checked=""/><div class="controls bullet"><span class="by">sideshowb</span><span>|</span><a href="#42210346">prev</a><span>|</span><a href="#42210175">next</a><span>|</span><label class="collapse" for="c-42209683">[-]</label><label class="expand" for="c-42209683">[2 more]</label></div><br/><div class="children"><div class="content">I like Bayes, but I thought the &quot;surprising&quot; result is that double descent is supposed to prevent nns from overfitting?</div><br/><div id="42210492" class="c"><input type="checkbox" id="c-42210492" checked=""/><div class="controls bullet"><span class="by">duvenaud</span><span>|</span><a href="#42209683">parent</a><span>|</span><a href="#42210175">next</a><span>|</span><label class="collapse" for="c-42210492">[-]</label><label class="expand" for="c-42210492">[1 more]</label></div><br/><div class="children"><div class="content">Good point.  We wrote this pre-double descent, and a massively overparameterized model would make a nice addition to the tutorial as a baseline.  However, if you want a rich predictive distribution, it might still make sense to use a Bayesian NN.</div><br/></div></div></div></div></div></div></div></div></div></body></html>