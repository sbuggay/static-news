<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="apple-mobile-web-app-capable" content="yes"/><link rel="preload" href="styles.css?v=1682522832960" as="style"/><link rel="stylesheet" href="styles.css?v=1682522832960"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.oneusefulthing.org/p/a-guide-to-prompting-ai-for-what">A guide to prompting AI, for what it is worth</a> <span class="domain">(<a href="https://www.oneusefulthing.org">www.oneusefulthing.org</a>)</span></div><div class="subtext"><span>jger15</span> | <span>19 comments</span></div><br/><div><div id="35713569" class="c"><input type="checkbox" id="c-35713569" checked=""/><div class="controls bullet"><span class="by">calny</span><span>|</span><a href="#35713872">next</a><span>|</span><label class="collapse" for="c-35713569">[-]</label><label class="expand" for="c-35713569">[12 more]</label></div><br/><div class="children"><div class="content">Good article. The rise of &quot;prompt influencers&quot; is frustrating, since it makes it a bit trickier to find the signal of interesting AI content through the noise. I miss when the influencers were all just hawking altcoins. Guess I&#x27;ll stick to watching Two Minute Papers[0] and reading papers that ak[1] tweets.<p>&gt; Being “good at prompting” is a temporary state of affairs.<p>Valid point. Sam A said he thinks prompt engineering won&#x27;t even be a thing in 5 years. And in the shorter term, prompts that work with a specific model like GPT-4 might not work well for future models, or even updates to the same model.<p>That said, I see prompt engineering as the beginning of a new paradigm of &quot;intent engineering&quot;--where developers use AI to understand and anticipate user intent with minimal user effort. It&#x27;ll be fun to see what that looks like in 5 years.<p>[0] <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;channel&#x2F;UCbfYPyITQ-7l4upoX8nvctg">https:&#x2F;&#x2F;www.youtube.com&#x2F;channel&#x2F;UCbfYPyITQ-7l4upoX8nvctg</a><p>[1] <a href="https:&#x2F;&#x2F;twitter.com&#x2F;_akhaliq" rel="nofollow">https:&#x2F;&#x2F;twitter.com&#x2F;_akhaliq</a></div><br/><div id="35714618" class="c"><input type="checkbox" id="c-35714618" checked=""/><div class="controls bullet"><span class="by">Jevon23</span><span>|</span><a href="#35713569">parent</a><span>|</span><a href="#35714096">next</a><span>|</span><label class="collapse" for="c-35714618">[-]</label><label class="expand" for="c-35714618">[4 more]</label></div><br/><div class="children"><div class="content">&gt;Sam A said he thinks prompt engineering won&#x27;t even be a thing in 5 years.<p>I don’t understand what this could mean. I have to do “prompt engineering” when I talk to other people all the time - when I need to ask them to do tasks, when I need to clarify requirements, etc. As long as we’re communicating through text and not mind reading, some level of “engineering” will be required. AI is intelligent but it’s not magic.</div><br/><div id="35715053" class="c"><input type="checkbox" id="c-35715053" checked=""/><div class="controls bullet"><span class="by">Mezzie</span><span>|</span><a href="#35713569">root</a><span>|</span><a href="#35714618">parent</a><span>|</span><a href="#35714693">next</a><span>|</span><label class="collapse" for="c-35715053">[-]</label><label class="expand" for="c-35715053">[1 more]</label></div><br/><div class="children"><div class="content">Yes. The problem isn&#x27;t the AI not understanding the human&#x27;s intent. The problem is the <i>human</i> not understanding what the human wants&#x2F;thinking it knows what it wants but being wrong.<p>Watching whole communities crowd-source&#x2F;stumble their way into basic reference question principles is kind of fun, though.</div><br/></div></div><div id="35714693" class="c"><input type="checkbox" id="c-35714693" checked=""/><div class="controls bullet"><span class="by">ekanes</span><span>|</span><a href="#35713569">root</a><span>|</span><a href="#35714618">parent</a><span>|</span><a href="#35715053">prev</a><span>|</span><a href="#35714980">next</a><span>|</span><label class="collapse" for="c-35714693">[-]</label><label class="expand" for="c-35714693">[1 more]</label></div><br/><div class="children"><div class="content">Prompt engineering now (as I understand it) is you&#x27;re refining and refining the prompt itself.  Perhaps what we might see is you give it a prompt then just keep adjusting the response dynamically, and then it can remember the entire concept as a saved prompt.</div><br/></div></div><div id="35714980" class="c"><input type="checkbox" id="c-35714980" checked=""/><div class="controls bullet"><span class="by">ModernMech</span><span>|</span><a href="#35713569">root</a><span>|</span><a href="#35714618">parent</a><span>|</span><a href="#35714693">prev</a><span>|</span><a href="#35714096">next</a><span>|</span><label class="collapse" for="c-35714980">[-]</label><label class="expand" for="c-35714980">[1 more]</label></div><br/><div class="children"><div class="content">I see a general trend for developers to want to put syntax and semantics back into the prompting. This whole idea that we can just get rid of formal languages entirely and replace them with natural languages isn&#x27;t going to pan out; we have formal languages for a reason -- you don&#x27;t have to guess the magic spell that will cause the output you want, you can get the output you want because you know how the system works. It&#x27;s a much less frustrating and consistent way of dealing with computers unless you fancy yourself a bureaucrat.<p>If this actually happens, I would imagine that talking to an LLM would be a combination of formal syntax and natural language, so the task will look more like software engineering than black magic.</div><br/></div></div></div></div><div id="35714096" class="c"><input type="checkbox" id="c-35714096" checked=""/><div class="controls bullet"><span class="by">noobcoder</span><span>|</span><a href="#35713569">parent</a><span>|</span><a href="#35714618">prev</a><span>|</span><a href="#35714083">next</a><span>|</span><label class="collapse" for="c-35714096">[-]</label><label class="expand" for="c-35714096">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, while all the other stuff is important, prompts are a big deal, especially for generative image tasks. They need to be just right for the checkpoint, but if you nail it, you can get an awesome image straight away. Sadly, most people just give up too quickly.<p>But with ChatGPT, even if you give it a terrible prompt, it can still &quot;get&quot; what you&#x27;re trying to say. You can keep chatting until you get the image you want. It&#x27;s way easier than with Txt2img, which can be pretty unforgiving.<p>And those courses? Total scam, don&#x27;t bother with them.</div><br/></div></div><div id="35714083" class="c"><input type="checkbox" id="c-35714083" checked=""/><div class="controls bullet"><span class="by">nonethewiser</span><span>|</span><a href="#35713569">parent</a><span>|</span><a href="#35714096">prev</a><span>|</span><a href="#35714215">next</a><span>|</span><label class="collapse" for="c-35714083">[-]</label><label class="expand" for="c-35714083">[4 more]</label></div><br/><div class="children"><div class="content">How can prompt engineering not be a thing so long as prompts are needed? If a different range of inputs produces a different range of outputs how could there be no room for nuances? Or how is intent engineering really any different? It’s all based off an prompt input right?<p>I think part of this comes from the fact that the same input will produce a different output.</div><br/><div id="35714235" class="c"><input type="checkbox" id="c-35714235" checked=""/><div class="controls bullet"><span class="by">newswasboring</span><span>|</span><a href="#35713569">root</a><span>|</span><a href="#35714083">parent</a><span>|</span><a href="#35714215">next</a><span>|</span><label class="collapse" for="c-35714235">[-]</label><label class="expand" for="c-35714235">[3 more]</label></div><br/><div class="children"><div class="content">Prompt engineering will be a thing, but I don&#x27;t think it will be as prevalent as people think it will be. Look at projects like langchain. To me its biggest value is the library of standard prompts it provides. So I think prompt engineering will probably be a &quot;niche&quot; job the same way C programming is a &quot;niche&quot; job. Its super specialized and most people doing C programming are also experts in specific architectures they are programming in.</div><br/><div id="35714351" class="c"><input type="checkbox" id="c-35714351" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#35713569">root</a><span>|</span><a href="#35714235">parent</a><span>|</span><a href="#35714215">next</a><span>|</span><label class="collapse" for="c-35714351">[-]</label><label class="expand" for="c-35714351">[2 more]</label></div><br/><div class="children"><div class="content">Saying that LangChain removes the value of learning to write prompts sounds to me like saying that the existence of ORMs removes the value of learning SQL.</div><br/><div id="35714518" class="c"><input type="checkbox" id="c-35714518" checked=""/><div class="controls bullet"><span class="by">newswasboring</span><span>|</span><a href="#35713569">root</a><span>|</span><a href="#35714351">parent</a><span>|</span><a href="#35714215">next</a><span>|</span><label class="collapse" for="c-35714518">[-]</label><label class="expand" for="c-35714518">[1 more]</label></div><br/><div class="children"><div class="content">I never said langchain &quot;removes the value of learning to write prompts&quot;. My point is it abstracts it out enough that not everyone working with LLMs will need to know how to do it at a very high level. Just like most programmers can&#x27;t write assembly&#x2F;C, but we have tools which abstract it out so that experts can write&#x2F;generate it for us. I don&#x27;t know about SQL and ORM to respond to your analogy.</div><br/></div></div></div></div></div></div></div></div><div id="35714215" class="c"><input type="checkbox" id="c-35714215" checked=""/><div class="controls bullet"><span class="by">ChatGTP</span><span>|</span><a href="#35713569">parent</a><span>|</span><a href="#35714083">prev</a><span>|</span><a href="#35713872">next</a><span>|</span><label class="collapse" for="c-35714215">[-]</label><label class="expand" for="c-35714215">[2 more]</label></div><br/><div class="children"><div class="content"><i>Valid point. Sam A said he thinks prompt engineering won&#x27;t even be a thing in 5 years.</i><p>Who cares what Sam A thinks on the matter. Of course he is going to say things like that he wants to make his product sound as amazing as possible.</div><br/><div id="35714323" class="c"><input type="checkbox" id="c-35714323" checked=""/><div class="controls bullet"><span class="by">coding123</span><span>|</span><a href="#35713569">root</a><span>|</span><a href="#35714215">parent</a><span>|</span><a href="#35713872">next</a><span>|</span><label class="collapse" for="c-35714323">[-]</label><label class="expand" for="c-35714323">[1 more]</label></div><br/><div class="children"><div class="content">Probably a lot of people, as he has more knowledge of upcoming features.</div><br/></div></div></div></div></div></div><div id="35713872" class="c"><input type="checkbox" id="c-35713872" checked=""/><div class="controls bullet"><span class="by">armchairhacker</span><span>|</span><a href="#35713569">prev</a><span>|</span><a href="#35713628">next</a><span>|</span><label class="collapse" for="c-35713872">[-]</label><label class="expand" for="c-35713872">[1 more]</label></div><br/><div class="children"><div class="content">My experience is that LLMs are really good at interpreting prompts, so you really don&#x27;t have to craft them any way to get &quot;better&quot; results.<p>The most important part is that the prompt has the necessary information so that it <i>can</i> be interpreted correctly. The other important part is, if you&#x27;re trying to get a response you can feed to a computer (e.g. raw JSON), you need to really clearly specify this. And even then the current LLMs are really bad at stopping or providing invalid output; so bad, we may need to create another type of language model which takes LLM &quot;English&quot; output and converts it into raw data.<p>LLMs are (or at least GPT-4 is) also really good at selective attention. Even if you slip in a subtle detail the model is good at picking it up.</div><br/></div></div><div id="35713628" class="c"><input type="checkbox" id="c-35713628" checked=""/><div class="controls bullet"><span class="by">code51</span><span>|</span><a href="#35713872">prev</a><span>|</span><a href="#35714456">next</a><span>|</span><label class="collapse" for="c-35713628">[-]</label><label class="expand" for="c-35713628">[3 more]</label></div><br/><div class="children"><div class="content">This will just come to the point: &quot;8 billion people have a brain and 99% of them use it wrong. a thread&quot;</div><br/><div id="35714090" class="c"><input type="checkbox" id="c-35714090" checked=""/><div class="controls bullet"><span class="by">pwndByDeath</span><span>|</span><a href="#35713628">parent</a><span>|</span><a href="#35714456">next</a><span>|</span><label class="collapse" for="c-35714090">[-]</label><label class="expand" for="c-35714090">[2 more]</label></div><br/><div class="children"><div class="content">99? That seems generous, but more likely I&#x27;m in the majority.<p>On a technical note, there isn&#x27;t abstract comprehension going on, like the discovery that chess dosen&#x27;t require intelligence, what happens when creative people recognize they don&#x27;t either ;p</div><br/><div id="35714244" class="c"><input type="checkbox" id="c-35714244" checked=""/><div class="controls bullet"><span class="by">ChatGTP</span><span>|</span><a href="#35713628">root</a><span>|</span><a href="#35714090">parent</a><span>|</span><a href="#35714456">next</a><span>|</span><label class="collapse" for="c-35714244">[-]</label><label class="expand" for="c-35714244">[1 more]</label></div><br/><div class="children"><div class="content">&quot;Right? Everyone is so dumb...&quot;</div><br/></div></div></div></div></div></div><div id="35714456" class="c"><input type="checkbox" id="c-35714456" checked=""/><div class="controls bullet"><span class="by">coding123</span><span>|</span><a href="#35713628">prev</a><span>|</span><label class="collapse" for="c-35714456">[-]</label><label class="expand" for="c-35714456">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s kind of comical that we have &quot;prompts&quot; rather than people that use GPT directly, which is &quot;completions&quot;.</div><br/><div id="35714592" class="c"><input type="checkbox" id="c-35714592" checked=""/><div class="controls bullet"><span class="by">newswasboring</span><span>|</span><a href="#35714456">parent</a><span>|</span><label class="collapse" for="c-35714592">[-]</label><label class="expand" for="c-35714592">[1 more]</label></div><br/><div class="children"><div class="content">At this point, I don&#x27;t see the difference.</div><br/></div></div></div></div></div></div></div></div></div></body></html>