<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1736931675383" as="style"/><link rel="stylesheet" href="styles.css?v=1736931675383"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://arena-ai.github.io/structured-logprobs/">Show HN: Value likelihoods for OpenAI structured output</a> <span class="domain">(<a href="https://arena-ai.github.io">arena-ai.github.io</a>)</span></div><div class="subtext"><span>ngrislain</span> | <span>36 comments</span></div><br/><div><div id="42699282" class="c"><input type="checkbox" id="c-42699282" checked=""/><div class="controls bullet"><span class="by">yodon</span><span>|</span><a href="#42703511">next</a><span>|</span><label class="collapse" for="c-42699282">[-]</label><label class="expand" for="c-42699282">[17 more]</label></div><br/><div class="children"><div class="content">This looks super valuable!<p>That said, it&#x27;s concerning to see the reported probability for getting a 4 on a die roll is 65%.<p>Hopefully OpenAI isn&#x27;t that biased at generating die rolls, so is that number actually giving us information about the accuracy of the probability assessments?</div><br/><div id="42702958" class="c"><input type="checkbox" id="c-42702958" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#42699282">parent</a><span>|</span><a href="#42704846">next</a><span>|</span><label class="collapse" for="c-42702958">[-]</label><label class="expand" for="c-42702958">[1 more]</label></div><br/><div class="children"><div class="content">&gt; That said, it&#x27;s concerning to see the reported probability for getting a 4 on a die roll is 65%.<p>Finding that an LLM is biased toward inventing die rolls that are the median result rounded to an available result by the most common rounding method is...not particularly surprising. If you want a fair RNG, use an RNG deigned to be fair, not an LLM where that would be, at best, an emergent accidental property.</div><br/></div></div><div id="42704846" class="c"><input type="checkbox" id="c-42704846" checked=""/><div class="controls bullet"><span class="by">teej</span><span>|</span><a href="#42699282">parent</a><span>|</span><a href="#42702958">prev</a><span>|</span><a href="#42699597">next</a><span>|</span><label class="collapse" for="c-42704846">[-]</label><label class="expand" for="c-42704846">[6 more]</label></div><br/><div class="children"><div class="content">Fair dice rolls is not an objective that cloud LLMs are optimized for. You should assume that LLMs cannot perform this task.<p>This is a problem when people naively use &quot;give an answer on a scale of 1-10&quot; in their prompts. LLMs are biased towards particular numbers (like humans!) and cannot linearly map an answer to a scale.<p>It&#x27;s extremely concerning when teams do this in a context like medicine. Asking an LLM &quot;how severe is this condition&quot; on a numeric scale is fraudulent and dangerous.</div><br/><div id="42707587" class="c"><input type="checkbox" id="c-42707587" checked=""/><div class="controls bullet"><span class="by">low_tech_love</span><span>|</span><a href="#42699282">root</a><span>|</span><a href="#42704846">parent</a><span>|</span><a href="#42705837">next</a><span>|</span><label class="collapse" for="c-42707587">[-]</label><label class="expand" for="c-42707587">[4 more]</label></div><br/><div class="children"><div class="content">This week I was on a meeting for a rather important scientific project at the university, and I asked the other participants “can we somehow reliably cluster this data to try to detect groups of similar outcomes?” to which a colleague promptly responded “oh yeah, chatGPT can do that easily”.</div><br/><div id="42707916" class="c"><input type="checkbox" id="c-42707916" checked=""/><div class="controls bullet"><span class="by">stanislavb</span><span>|</span><a href="#42699282">root</a><span>|</span><a href="#42707587">parent</a><span>|</span><a href="#42705837">next</a><span>|</span><label class="collapse" for="c-42707916">[-]</label><label class="expand" for="c-42707916">[3 more]</label></div><br/><div class="children"><div class="content">I guess, he&#x27;s right - it will be easy and relatively accurate. Relatively&#x2F;seemingly.</div><br/><div id="42708056" class="c"><input type="checkbox" id="c-42708056" checked=""/><div class="controls bullet"><span class="by">low_tech_love</span><span>|</span><a href="#42699282">root</a><span>|</span><a href="#42707916">parent</a><span>|</span><a href="#42705837">next</a><span>|</span><label class="collapse" for="c-42708056">[-]</label><label class="expand" for="c-42708056">[2 more]</label></div><br/><div class="children"><div class="content">So that’s it then? We replace every well-understood, objective algorithm with well-hidden, fake, superficial surrogate answers from an AI?</div><br/><div id="42708720" class="c"><input type="checkbox" id="c-42708720" checked=""/><div class="controls bullet"><span class="by">yorwba</span><span>|</span><a href="#42699282">root</a><span>|</span><a href="#42708056">parent</a><span>|</span><a href="#42705837">next</a><span>|</span><label class="collapse" for="c-42708720">[-]</label><label class="expand" for="c-42708720">[1 more]</label></div><br/><div class="children"><div class="content">&quot;cluster this data to try to detect groups of similar outcomes&quot; is typically a fairly subjective task. If the objective algorithm optimizes for an objective criterion that doesn&#x27;t match the subjective criteria that will be used to evaluate it, that objectivity is just as superficial.</div><br/></div></div></div></div></div></div></div></div><div id="42705837" class="c"><input type="checkbox" id="c-42705837" checked=""/><div class="controls bullet"><span class="by">Terr_</span><span>|</span><a href="#42699282">root</a><span>|</span><a href="#42704846">parent</a><span>|</span><a href="#42707587">prev</a><span>|</span><a href="#42699597">next</a><span>|</span><label class="collapse" for="c-42705837">[-]</label><label class="expand" for="c-42705837">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;ll also give you different results based on logically-irrelevant numbers that might appear elsewhere in the collaborative fiction document.</div><br/></div></div></div></div><div id="42699597" class="c"><input type="checkbox" id="c-42699597" checked=""/><div class="controls bullet"><span class="by">ngrislain</span><span>|</span><a href="#42699282">parent</a><span>|</span><a href="#42704846">prev</a><span>|</span><a href="#42702767">next</a><span>|</span><label class="collapse" for="c-42699597">[-]</label><label class="expand" for="c-42699597">[4 more]</label></div><br/><div class="children"><div class="content">Thank you! The number is the the sum of the logprobs from the token constituting the individual values. So it does represent the likelihood of seeing this value.
So yes OpenAI is super-biased as a random number generator.
We sampled other values from OpenAI and got other die roll values, but with much lower probs (5 has 8% chances ).</div><br/><div id="42700100" class="c"><input type="checkbox" id="c-42700100" checked=""/><div class="controls bullet"><span class="by">ngrislain</span><span>|</span><a href="#42699282">root</a><span>|</span><a href="#42699597">parent</a><span>|</span><a href="#42702767">next</a><span>|</span><label class="collapse" for="c-42700100">[-]</label><label class="expand" for="c-42700100">[3 more]</label></div><br/><div class="children"><div class="content">More precisely it represents the likelihood of seeing this value conditional on the tokens before it.</div><br/><div id="42708209" class="c"><input type="checkbox" id="c-42708209" checked=""/><div class="controls bullet"><span class="by">elcritch</span><span>|</span><a href="#42699282">root</a><span>|</span><a href="#42700100">parent</a><span>|</span><a href="#42704961">next</a><span>|</span><label class="collapse" for="c-42708209">[-]</label><label class="expand" for="c-42708209">[1 more]</label></div><br/><div class="children"><div class="content">Even without other tokens before it the LLM is probably showing the probability of dice rolls based on its training data. I’d guess humans tend to prefer “3” or “4” as it’s nearer the avg&#x2F;median and feels fairer.<p>AFAICT, the LLMs aren’t creating new mental mappings of “dice are a symmetric and should give equal probability to land on any side followed by using that info to infer they should use a RNG.”</div><br/></div></div><div id="42704961" class="c"><input type="checkbox" id="c-42704961" checked=""/><div class="controls bullet"><span class="by">radarsat1</span><span>|</span><a href="#42699282">root</a><span>|</span><a href="#42700100">parent</a><span>|</span><a href="#42708209">prev</a><span>|</span><a href="#42702767">next</a><span>|</span><label class="collapse" for="c-42704961">[-]</label><label class="expand" for="c-42704961">[1 more]</label></div><br/><div class="children"><div class="content">and i guess includes other possibilities than numbers, like &#x27;f&#x27; which could lead to four or five. There&#x27;s probably a separate probability for &#x27;fi&#x27; and &#x27;fo&#x27; too.</div><br/></div></div></div></div></div></div><div id="42702767" class="c"><input type="checkbox" id="c-42702767" checked=""/><div class="controls bullet"><span class="by">mmcwilliams</span><span>|</span><a href="#42699282">parent</a><span>|</span><a href="#42699597">prev</a><span>|</span><a href="#42702926">next</a><span>|</span><label class="collapse" for="c-42702767">[-]</label><label class="expand" for="c-42702767">[2 more]</label></div><br/><div class="children"><div class="content">What about the models they offer would make you think that it <i>wouldn&#x27;t</i> be biased at generating random die rolls?</div><br/><div id="42708076" class="c"><input type="checkbox" id="c-42708076" checked=""/><div class="controls bullet"><span class="by">low_tech_love</span><span>|</span><a href="#42699282">root</a><span>|</span><a href="#42702767">parent</a><span>|</span><a href="#42702926">next</a><span>|</span><label class="collapse" for="c-42708076">[-]</label><label class="expand" for="c-42708076">[1 more]</label></div><br/><div class="children"><div class="content">I think the problem is that for every person who actually understands that ChatGPT should not be used for objective things like a die roll, there are 10 or 20 who would say “well, it looks ok, and it’s fast, convenient, and it passes nicely for an answer”. People are pushing the boundaries and waiting for the backlash, but the backlash never actually comes… so they keep pushing.<p>Think about this: suppose you’re reading a scientific paper and the author writes “I did a study with 52 participants, and here are the answers”. Would there be any reason to believe that data is real?</div><br/></div></div></div></div><div id="42702926" class="c"><input type="checkbox" id="c-42702926" checked=""/><div class="controls bullet"><span class="by">supernewton</span><span>|</span><a href="#42699282">parent</a><span>|</span><a href="#42702767">prev</a><span>|</span><a href="#42703511">next</a><span>|</span><label class="collapse" for="c-42702926">[-]</label><label class="expand" for="c-42702926">[3 more]</label></div><br/><div class="children"><div class="content">I feel like <a href="https:&#x2F;&#x2F;xkcd.com&#x2F;221&#x2F;" rel="nofollow">https:&#x2F;&#x2F;xkcd.com&#x2F;221&#x2F;</a> might be heavily influencing what the typical &quot;random&quot; die roll looks like on the internet ;)</div><br/><div id="42703188" class="c"><input type="checkbox" id="c-42703188" checked=""/><div class="controls bullet"><span class="by">prerok</span><span>|</span><a href="#42699282">root</a><span>|</span><a href="#42702926">parent</a><span>|</span><a href="#42703884">next</a><span>|</span><label class="collapse" for="c-42703188">[-]</label><label class="expand" for="c-42703188">[1 more]</label></div><br/><div class="children"><div class="content">Based on this comic I&#x27;ve seen unit tests use 4 as replacement for random generated number to ensure non flakiness (of course, only when needed). But it might explain the LLM&#x27;s bias?</div><br/></div></div><div id="42703884" class="c"><input type="checkbox" id="c-42703884" checked=""/><div class="controls bullet"><span class="by">ngrislain</span><span>|</span><a href="#42699282">root</a><span>|</span><a href="#42702926">parent</a><span>|</span><a href="#42703188">prev</a><span>|</span><a href="#42703511">next</a><span>|</span><label class="collapse" for="c-42703884">[-]</label><label class="expand" for="c-42703884">[1 more]</label></div><br/><div class="children"><div class="content">Haha, I didn&#x27;t know that one! It&#x27;s consistent with OpenAI&#x27;s conception of a &quot;random&quot; dice roll :-D.
Joke appart, I&#x27;m quite convinced many people would not find 1 or 6 to look &quot;random&quot; enough to be chosen as an example dice roll.</div><br/></div></div></div></div></div></div><div id="42703511" class="c"><input type="checkbox" id="c-42703511" checked=""/><div class="controls bullet"><span class="by">HanClinto</span><span>|</span><a href="#42699282">prev</a><span>|</span><a href="#42708566">next</a><span>|</span><label class="collapse" for="c-42703511">[-]</label><label class="expand" for="c-42703511">[3 more]</label></div><br/><div class="children"><div class="content">This is really brilliant stuff! Somehow I didn&#x27;t realize that logprobs were being returned as part of the OAI requests, and I really like this application of it.<p>Any interest in seeing this sort of thing being added to llama.cpp?</div><br/><div id="42703584" class="c"><input type="checkbox" id="c-42703584" checked=""/><div class="controls bullet"><span class="by">HanClinto</span><span>|</span><a href="#42703511">parent</a><span>|</span><a href="#42708566">next</a><span>|</span><label class="collapse" for="c-42703584">[-]</label><label class="expand" for="c-42703584">[2 more]</label></div><br/><div class="children"><div class="content">Looking at llama.cpp, it already supports the logprob field in its OAI API emulation, so it shouldn&#x27;t be too difficult to use this library with it.<p>It feels like this would be useful enough to build around -- I especially like the idea of asking the API to return the top K results for each field, and denoting their likelyhood -- almost like a dropdown box with percentages attached for each possible result.</div><br/><div id="42704554" class="c"><input type="checkbox" id="c-42704554" checked=""/><div class="controls bullet"><span class="by">DrPhish</span><span>|</span><a href="#42703511">root</a><span>|</span><a href="#42703584">parent</a><span>|</span><a href="#42708566">next</a><span>|</span><label class="collapse" for="c-42704554">[-]</label><label class="expand" for="c-42704554">[1 more]</label></div><br/><div class="children"><div class="content">I believe mikupad[0] supports showing logprobs from a llama.cpp backend.<p>[0]:<a href="https:&#x2F;&#x2F;github.com&#x2F;lmg-anon&#x2F;mikupad">https:&#x2F;&#x2F;github.com&#x2F;lmg-anon&#x2F;mikupad</a></div><br/></div></div></div></div></div></div><div id="42708566" class="c"><input type="checkbox" id="c-42708566" checked=""/><div class="controls bullet"><span class="by">lyu07282</span><span>|</span><a href="#42703511">prev</a><span>|</span><a href="#42702910">next</a><span>|</span><label class="collapse" for="c-42708566">[-]</label><label class="expand" for="c-42708566">[3 more]</label></div><br/><div class="children"><div class="content">I was under the impression that log probabilities don&#x27;t work like that &#x2F; they aren&#x27;t really useful to be interpreted as probabilities?<p><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=42684629">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=42684629</a><p>&gt; the logits aren&#x27;t telling you anything like &#x27;what is the probability in a random sample of Internet text of the next token&#x27;, but are closer to a Bellman value function, expressing the model&#x27;s belief as to what would be the net reward from picking each possible BPE as an &#x27;action&#x27; and then continuing to pick the optimal BPE after that (ie. following its policy until the episode terminates). Because there is usually 1 best action, it tries to put the largest value on that action, and assign very small values to the rest (no matter how plausible each of them might be if you were looking at random Internet text)</div><br/><div id="42708640" class="c"><input type="checkbox" id="c-42708640" checked=""/><div class="controls bullet"><span class="by">ngrislain</span><span>|</span><a href="#42708566">parent</a><span>|</span><a href="#42708610">next</a><span>|</span><label class="collapse" for="c-42708640">[-]</label><label class="expand" for="c-42708640">[1 more]</label></div><br/><div class="children"><div class="content">Yes it is true that the model has undergone SFT, and RLHF, and other alignment procedures, and hence the logprobs do not reflect the probability of the next token as in the pre-training corpus.
Nevertheless, in concrete applications such as our main internal use-case: <i>structured data extraction from pdf documents</i> it revealed very valuable.
When the value was obviously well extracted, the logprob was high and when the information was super hard to find or impossible the model would output - or hallucinate - some value with much lower logprob.</div><br/></div></div><div id="42708610" class="c"><input type="checkbox" id="c-42708610" checked=""/><div class="controls bullet"><span class="by">gardnr</span><span>|</span><a href="#42708566">parent</a><span>|</span><a href="#42708640">prev</a><span>|</span><a href="#42702910">next</a><span>|</span><label class="collapse" for="c-42708610">[-]</label><label class="expand" for="c-42708610">[1 more]</label></div><br/><div class="children"><div class="content">Perplexity: a metric, often used to evaluate LLMs, is derived from the negative average logprob of the tokens in a test set. Lower perplexity indicates that the model assigns higher probabilities to the observed tokens, reflecting better language modeling.</div><br/></div></div></div></div><div id="42702910" class="c"><input type="checkbox" id="c-42702910" checked=""/><div class="controls bullet"><span class="by">juxtaposicion</span><span>|</span><a href="#42708566">prev</a><span>|</span><a href="#42705682">next</a><span>|</span><label class="collapse" for="c-42702910">[-]</label><label class="expand" for="c-42702910">[5 more]</label></div><br/><div class="children"><div class="content">This looks great; very useful for (example) ranking outputs by confidence so you can do human reviews of the not-confident ones.<p>Any chance we can get Pydantic support?</div><br/><div id="42707659" class="c"><input type="checkbox" id="c-42707659" checked=""/><div class="controls bullet"><span class="by">themanmaran</span><span>|</span><a href="#42702910">parent</a><span>|</span><a href="#42703956">next</a><span>|</span><label class="collapse" for="c-42707659">[-]</label><label class="expand" for="c-42707659">[1 more]</label></div><br/><div class="children"><div class="content">Fyi logprobs !== confidence.<p>If you run &quot;bananas,fishbowl,phonebook,&quot; and get {&quot;sponge&quot;: 0.76}<p>It doesn&#x27;t mean that &quot;placemat&quot; was the 76% correct answer. Just that the word &quot;sponge&quot; was the next most likely word for the model to generate.</div><br/></div></div><div id="42703956" class="c"><input type="checkbox" id="c-42703956" checked=""/><div class="controls bullet"><span class="by">ngrislain</span><span>|</span><a href="#42702910">parent</a><span>|</span><a href="#42707659">prev</a><span>|</span><a href="#42705682">next</a><span>|</span><label class="collapse" for="c-42703956">[-]</label><label class="expand" for="c-42703956">[3 more]</label></div><br/><div class="children"><div class="content">Actually, OpenAI provides Pydantic support for structured output (see client.beta.chat.completions.parse in <a href="https:&#x2F;&#x2F;platform.openai.com&#x2F;docs&#x2F;guides&#x2F;structured-outputs" rel="nofollow">https:&#x2F;&#x2F;platform.openai.com&#x2F;docs&#x2F;guides&#x2F;structured-outputs</a>).<p>The library is compatible with that but does not use Pydantic further than that.</div><br/><div id="42704175" class="c"><input type="checkbox" id="c-42704175" checked=""/><div class="controls bullet"><span class="by">juxtaposicion</span><span>|</span><a href="#42702910">root</a><span>|</span><a href="#42703956">parent</a><span>|</span><a href="#42705682">next</a><span>|</span><label class="collapse" for="c-42704175">[-]</label><label class="expand" for="c-42704175">[2 more]</label></div><br/><div class="children"><div class="content">Right the hope was to go further. E.g. if the input is:<p>```<p>class Classification(BaseModel):<p><pre><code>    color: Literal[&#x27;red&#x27;, &#x27;blue&#x27;, &#x27;green&#x27;]
</code></pre>
```<p>then the output type would be:<p>```<p>class ClassificationWithLogProbs(BaseModel):<p><pre><code>    color: Dict[Literal[&#x27;red&#x27;, &#x27;blue&#x27;, &#x27;green&#x27;], float]
</code></pre>
```<p>Don&#x27;t take this too literally; I&#x27;m not convinced that this is the right way to do it. But it would provide structure and scores without dealing with a mess of complex JSON.</div><br/><div id="42708529" class="c"><input type="checkbox" id="c-42708529" checked=""/><div class="controls bullet"><span class="by">lyu07282</span><span>|</span><a href="#42702910">root</a><span>|</span><a href="#42704175">parent</a><span>|</span><a href="#42705682">next</a><span>|</span><label class="collapse" for="c-42708529">[-]</label><label class="expand" for="c-42708529">[1 more]</label></div><br/><div class="children"><div class="content">but this ultimately just converts to json schema, or the openai function calling definition format.<p>One question I always had was what about the descriptions you can attach to the class and attributes? ( = Field(description=...) in pydantic) is the model made aware of those descriptions?</div><br/></div></div></div></div></div></div></div></div><div id="42705682" class="c"><input type="checkbox" id="c-42705682" checked=""/><div class="controls bullet"><span class="by">kelsolaar</span><span>|</span><a href="#42702910">prev</a><span>|</span><a href="#42704053">next</a><span>|</span><label class="collapse" for="c-42705682">[-]</label><label class="expand" for="c-42705682">[2 more]</label></div><br/><div class="children"><div class="content">I briefly took a look at the code, what is the reason to use Lark and not Python native JSON parser, is it to handle cases where the structured output is not JSON compatible?</div><br/><div id="42707887" class="c"><input type="checkbox" id="c-42707887" checked=""/><div class="controls bullet"><span class="by">ngrislain</span><span>|</span><a href="#42705682">parent</a><span>|</span><a href="#42704053">next</a><span>|</span><label class="collapse" for="c-42707887">[-]</label><label class="expand" for="c-42707887">[1 more]</label></div><br/><div class="children"><div class="content">We need to build a syntax tree and be able to map each value (number, boolean, string) to a range of character and then to a GPT token (for which OpenAi produces logprobs).
This is the reason we use Lark.</div><br/></div></div></div></div><div id="42704053" class="c"><input type="checkbox" id="c-42704053" checked=""/><div class="controls bullet"><span class="by">potatoman22</span><span>|</span><a href="#42705682">prev</a><span>|</span><a href="#42703676">next</a><span>|</span><label class="collapse" for="c-42704053">[-]</label><label class="expand" for="c-42704053">[3 more]</label></div><br/><div class="children"><div class="content">How does the token usage compare to vanilla structured output? Many of these libraries do multiple requests to constrain output and measure logprobs.</div><br/><div id="42704320" class="c"><input type="checkbox" id="c-42704320" checked=""/><div class="controls bullet"><span class="by">ngrislain</span><span>|</span><a href="#42704053">parent</a><span>|</span><a href="#42703676">next</a><span>|</span><label class="collapse" for="c-42704320">[-]</label><label class="expand" for="c-42704320">[2 more]</label></div><br/><div class="children"><div class="content">Same token usage.
Actually OpenAI returns the logprob of each token conditional on the previous ones with the option logprobs=true.
This lib <i>simply</i> parses the output json string with `lark` into an AST with value nodes. The value nodes are mapped back to a range of characters in the json string. Then the characters are mapped back to the GPT tokens overlapping the character ranges and the logprobs of the tokens are summed.</div><br/><div id="42704625" class="c"><input type="checkbox" id="c-42704625" checked=""/><div class="controls bullet"><span class="by">potatoman22</span><span>|</span><a href="#42704053">root</a><span>|</span><a href="#42704320">parent</a><span>|</span><a href="#42703676">next</a><span>|</span><label class="collapse" for="c-42704625">[-]</label><label class="expand" for="c-42704625">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s great to hear, thanks for the explanation! Super excited to try this out.</div><br/></div></div></div></div></div></div><div id="42703676" class="c"><input type="checkbox" id="c-42703676" checked=""/><div class="controls bullet"><span class="by">Der_Einzige</span><span>|</span><a href="#42704053">prev</a><span>|</span><label class="collapse" for="c-42703676">[-]</label><label class="expand" for="c-42703676">[2 more]</label></div><br/><div class="children"><div class="content">BTW - Structured&#x2F;Constrained Generation is the KEY to making AI agents better&#x2F;scary good. Without it, you&#x27;re leaving so much on the table. This library is awesome for augmenting that capability!!!!<p>Also, if you&#x27;re &quot;studying LLM based chess&quot; and you don&#x27;t use dynamic grammar&#x27;s to enforce that models can only make &quot;valid&quot; moves at each time step, you&#x27;re research is basically invalid.<p>And don&#x27;t meme me with claims that structured&#x2F;constrained generation harms creativity. The devs of outlines debunked that FUD already: <a href="https:&#x2F;&#x2F;blog.dottxt.co&#x2F;say-what-you-mean.html" rel="nofollow">https:&#x2F;&#x2F;blog.dottxt.co&#x2F;say-what-you-mean.html</a><p>Similarly, if you think that RLHF&#x2F;DPO or Lora or any of that harms creativity, you&#x27;re really outing yourself as not having played with high temperature sampling.</div><br/><div id="42703826" class="c"><input type="checkbox" id="c-42703826" checked=""/><div class="controls bullet"><span class="by">ngrislain</span><span>|</span><a href="#42703676">parent</a><span>|</span><label class="collapse" for="c-42703826">[-]</label><label class="expand" for="c-42703826">[1 more]</label></div><br/><div class="children"><div class="content">Thank you!
Yes indeed, structured output was instrumental in reliably extracting structured data from images from a client.</div><br/></div></div></div></div></div></div></div></div></div></body></html>