<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1684054842543" as="style"/><link rel="stylesheet" href="styles.css?v=1684054842543"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://arxiv.org/abs/2108.12409">Attention with Linear Biases (ALiBi)</a>Â <span class="domain">(<a href="https://arxiv.org">arxiv.org</a>)</span></div><div class="subtext"><span>pmoriarty</span> | <span>9 comments</span></div><br/><div><div id="35936024" class="c"><input type="checkbox" id="c-35936024" checked=""/><div class="controls bullet"><span class="by">ofirpress</span><span>|</span><a href="#35936367">next</a><span>|</span><label class="collapse" for="c-35936024">[-]</label><label class="expand" for="c-35936024">[1 more]</label></div><br/><div class="children"><div class="content">(I wrote ALiBi)<p>Thanks for posting this! You can view a video where I explain what we did and why it&#x27;s useful at: <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=Pp61ShI9VGc">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=Pp61ShI9VGc</a></div><br/></div></div><div id="35936367" class="c"><input type="checkbox" id="c-35936367" checked=""/><div class="controls bullet"><span class="by">amrb</span><span>|</span><a href="#35936024">prev</a><span>|</span><a href="#35935352">next</a><span>|</span><label class="collapse" for="c-35936367">[-]</label><label class="expand" for="c-35936367">[1 more]</label></div><br/><div class="children"><div class="content">The &quot;one weird trick&quot; to squeeze limes for extra juice</div><br/></div></div><div id="35935352" class="c"><input type="checkbox" id="c-35935352" checked=""/><div class="controls bullet"><span class="by">chaxor</span><span>|</span><a href="#35936367">prev</a><span>|</span><label class="collapse" for="c-35935352">[-]</label><label class="expand" for="c-35935352">[6 more]</label></div><br/><div class="children"><div class="content">This seems suboptimal considering the simple output from the original Viswani PE,      which is solidly based on a well grounded foundation of eigenvectors     for the discrete Fourier transform relation to the circulant matrix of a linear chain graph which is natural language of the sentence</div><br/><div id="35936031" class="c"><input type="checkbox" id="c-35936031" checked=""/><div class="controls bullet"><span class="by">ofirpress</span><span>|</span><a href="#35935352">parent</a><span>|</span><a href="#35935891">next</a><span>|</span><label class="collapse" for="c-35936031">[-]</label><label class="expand" for="c-35936031">[1 more]</label></div><br/><div class="children"><div class="content">The ALiBi paper shows that our method beats the sinusoidal PE you refer to across many benchmarks. <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2108.12409" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2108.12409</a></div><br/></div></div><div id="35935891" class="c"><input type="checkbox" id="c-35935891" checked=""/><div class="controls bullet"><span class="by">taliesinb</span><span>|</span><a href="#35935352">parent</a><span>|</span><a href="#35936031">prev</a><span>|</span><a href="#35935426">next</a><span>|</span><label class="collapse" for="c-35935891">[-]</label><label class="expand" for="c-35935891">[1 more]</label></div><br/><div class="children"><div class="content">please clarify your suffix &quot;which is natural language of the sentence&quot;? are you referring to the positional encoding?</div><br/></div></div><div id="35935426" class="c"><input type="checkbox" id="c-35935426" checked=""/><div class="controls bullet"><span class="by">KRAKRISMOTT</span><span>|</span><a href="#35935352">parent</a><span>|</span><a href="#35935891">prev</a><span>|</span><a href="#35935772">next</a><span>|</span><label class="collapse" for="c-35935426">[-]</label><label class="expand" for="c-35935426">[2 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t recall there being a DFT in the original attention is all you need paper.</div><br/><div id="35936103" class="c"><input type="checkbox" id="c-35936103" checked=""/><div class="controls bullet"><span class="by">just_a_quack</span><span>|</span><a href="#35935352">root</a><span>|</span><a href="#35935426">parent</a><span>|</span><a href="#35935772">next</a><span>|</span><label class="collapse" for="c-35936103">[-]</label><label class="expand" for="c-35936103">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s not. The positional encodings are generated using sines and cosines such that any offset in position can be described as a linear function on the original position. Using the DFT here would not make sense as the positional encodings are fixed anyway and during inference this method generalizes nicely because of the geometric progression created by the arguments of the positional encoding functions.</div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>