<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1722869859016" as="style"/><link rel="stylesheet" href="styles.css?v=1722869859016"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://arxiv.org/abs/2301.13142">Self-Compressing Neural Networks</a> <span class="domain">(<a href="https://arxiv.org">arxiv.org</a>)</span></div><div class="subtext"><span>bilsbie</span> | <span>48 comments</span></div><br/><div><div id="41161404" class="c"><input type="checkbox" id="c-41161404" checked=""/><div class="controls bullet"><span class="by">dpkingma</span><span>|</span><a href="#41156237">next</a><span>|</span><label class="collapse" for="c-41161404">[-]</label><label class="expand" for="c-41161404">[1 more]</label></div><br/><div class="children"><div class="content">There seems to be some relevant prior work that is not referenced by this paper, such as our work on training sparse neural networks:<p><a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1712.01312" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1712.01312</a><p>Abstract: &quot;We propose a practical method for L0 norm regularization for neural networks: pruning the network during training by encouraging weights to become exactly zero. Such regularization is interesting since (1) it can greatly speed up training and inference, and (2) it can improve generalization. [...]&quot;</div><br/></div></div><div id="41156237" class="c"><input type="checkbox" id="c-41156237" checked=""/><div class="controls bullet"><span class="by">w-m</span><span>|</span><a href="#41161404">prev</a><span>|</span><a href="#41154779">next</a><span>|</span><label class="collapse" for="c-41156237">[-]</label><label class="expand" for="c-41156237">[3 more]</label></div><br/><div class="children"><div class="content">Using as little computational resources (memory and&#x2F;or FLOPS) as possible as an additional optimization criterion when training NNs is an interesting avenue. I think the current state of pre-trained model families is weird. Take Llama 3.1 or Segment Anything 2: you get tiny&#x2F;small&#x2F;medium&#x2F;larger&#x2F;huge models, where for each tier the model size was predefined, and they are trained somewhat (completely?) independently. This feels iffy, patchy, and like we haven&#x27;t really arrived yet.<p>I&#x27;d want a model that scales up and down depending on the task given at inference, and a model that doesn&#x27;t have a fixed size when starting the training. Shouldn&#x27;t it specialize over training progress, when seeing more tokens, and grow larger where needed? Without some human fixing a size beforehand?<p>Self-organization is a fascinating topic to me. This last year I&#x27;ve been working on Self-Organizing Gaussian Splats [0]. With a lot of squinting, this lives in a similar space as the Self-Compressing Neural Networks from the link above. The idea of the Gaussians was to build on Self-Organizing Maps (lovely 90s concept, look for some GIFs if you don&#x27;t know it), and use that to represent 3D scenes in a memory-efficient way. By mapping attributes into a locally smooth 2D grid. It&#x27;s quite a simple algorithm, but works really well, and better than many quite complicated coding schemes. So this has me excited that we&#x27;ll (re-)discover great methods in this space in the near future.<p>[0]: <a href="https:&#x2F;&#x2F;fraunhoferhhi.github.io&#x2F;Self-Organizing-Gaussians&#x2F;" rel="nofollow">https:&#x2F;&#x2F;fraunhoferhhi.github.io&#x2F;Self-Organizing-Gaussians&#x2F;</a></div><br/><div id="41156936" class="c"><input type="checkbox" id="c-41156936" checked=""/><div class="controls bullet"><span class="by">idontknowmuch</span><span>|</span><a href="#41156237">parent</a><span>|</span><a href="#41160462">next</a><span>|</span><label class="collapse" for="c-41156936">[-]</label><label class="expand" for="c-41156936">[1 more]</label></div><br/><div class="children"><div class="content">Afaik, they aren&#x27;t really trained independently -- for most models, e.g. DINO, etc., the smaller sizes are actually distilled from larger models. It&#x27;s much easier to generate performant models at smaller size via distillation.<p>And I&#x27;d be curious of the utility of model that scales up and down at inference - if this was the case you&#x27;d still need to have storage that is the same as the maximum model size. This would essentially be useless for embedded applications, etc., unless you have heavy quantization - but quantization in a small parameter space would probably make the smaller modes useless. I could see the benefit here in terms of optimizing latency for different applications but maybe you have other ideas.<p>Given all that, I think training for smaller number of parameters, as noted in OP, would kind of beat out some model that scales at inference time - especially when most people know what kind of application they are aiming to build and the required level of performance.</div><br/></div></div><div id="41160462" class="c"><input type="checkbox" id="c-41160462" checked=""/><div class="controls bullet"><span class="by">nwoli</span><span>|</span><a href="#41156237">parent</a><span>|</span><a href="#41156936">prev</a><span>|</span><a href="#41154779">next</a><span>|</span><label class="collapse" for="c-41160462">[-]</label><label class="expand" for="c-41160462">[1 more]</label></div><br/><div class="children"><div class="content">One elegant approach for this I’ve found is this <a href="https:&#x2F;&#x2F;github.com&#x2F;mit-han-lab&#x2F;gan-compression">https:&#x2F;&#x2F;github.com&#x2F;mit-han-lab&#x2F;gan-compression</a> They basically train an “all in one” network from which you can extract small or large models afterwards (with optional additional finetuning to improve the selected channel size combinations)</div><br/></div></div></div></div><div id="41154779" class="c"><input type="checkbox" id="c-41154779" checked=""/><div class="controls bullet"><span class="by">throwup238</span><span>|</span><a href="#41156237">prev</a><span>|</span><a href="#41154427">next</a><span>|</span><label class="collapse" for="c-41154779">[-]</label><label class="expand" for="c-41154779">[19 more]</label></div><br/><div class="children"><div class="content">I think this might be the first step to making neural networks that actually mimic biological brains. IMO the biggest piece missing from NN architectures is a mechanism like neuroplasticity that modifies the topology of neurons. Brains reorganize themselves around the things they learn.<p>This paper is a long way from implementing synaptic pruning&#x2F;strengthening&#x2F;weakening, neurogenesis, or synaptogenesis but it’s the first one I’ve seen where the network is self optimizing.</div><br/><div id="41155226" class="c"><input type="checkbox" id="c-41155226" checked=""/><div class="controls bullet"><span class="by">nyrikki</span><span>|</span><a href="#41154779">parent</a><span>|</span><a href="#41157054">next</a><span>|</span><label class="collapse" for="c-41155226">[-]</label><label class="expand" for="c-41155226">[7 more]</label></div><br/><div class="children"><div class="content">Unfortunately dendritic compartmentalization, spike timing etc are still not present.  All efforts at models of SNNs that I know of have hit problems like riddled basins so far, that is what to look for to move past the limits of perceptron based networks IMHO.<p>As PAC learning with autograd and perceptrons is just compression, or  set shattering, this paper is more of an optimization method that reduces ANN expressiveness through additional compression. Being able to control loss of precision is exciting though.<p>It may help in some cases, especially for practical use cases, but their unaddressed mention of potential problems with noisy loss functions needs to be addressed.<p>Human biological neurons can do XOR in the dendrites without hitting the soma at all is another example.<p>If you haven&#x27;t heard about dendritic compartmentalization and plasticity, here is a paper.<p><a href="https:&#x2F;&#x2F;www.cell.com&#x2F;neuron&#x2F;fulltext&#x2F;S0896-6273(11)00993-7" rel="nofollow">https:&#x2F;&#x2F;www.cell.com&#x2F;neuron&#x2F;fulltext&#x2F;S0896-6273(11)00993-7</a><p>&gt; In conclusion our results support the view that experience can drive clustered synaptic enhancement onto neuronal dendritic subcompartments, providing fundamental architecture to circuit development and function</div><br/><div id="41155451" class="c"><input type="checkbox" id="c-41155451" checked=""/><div class="controls bullet"><span class="by">IIAOPSW</span><span>|</span><a href="#41154779">root</a><span>|</span><a href="#41155226">parent</a><span>|</span><a href="#41155466">next</a><span>|</span><label class="collapse" for="c-41155451">[-]</label><label class="expand" for="c-41155451">[1 more]</label></div><br/><div class="children"><div class="content">You piqued my curiosity, so I looked for a paper. I found something tangential but fascinating.<p>&quot;Naud and Sprekeler (2018) suggest that this could be achieved using a synaptic strategy that facilitates summation for simple action potentials arriving on the basal dendrites and depresses faster burst-like events arriving on the distal tuft&quot;<p>Oh, its frequency multiplexing with a band pass filter. Same trick the analog phone system used to reduce the amount of wire needed in the network. Same problem, same solution. Convergent evolution.<p>I wonder if there&#x27;s ways to do phreaking on neurons.<p><a href="https:&#x2F;&#x2F;www.sciencedirect.com&#x2F;science&#x2F;article&#x2F;pii&#x2F;S0306452221002852" rel="nofollow">https:&#x2F;&#x2F;www.sciencedirect.com&#x2F;science&#x2F;article&#x2F;pii&#x2F;S030645222...</a></div><br/></div></div><div id="41155466" class="c"><input type="checkbox" id="c-41155466" checked=""/><div class="controls bullet"><span class="by">dontwearitout</span><span>|</span><a href="#41154779">root</a><span>|</span><a href="#41155226">parent</a><span>|</span><a href="#41155451">prev</a><span>|</span><a href="#41155436">next</a><span>|</span><label class="collapse" for="c-41155466">[-]</label><label class="expand" for="c-41155466">[3 more]</label></div><br/><div class="children"><div class="content">Are dendritic sub-compartments necessary to explicitly model, or does this work just imply that biological neurons are complicated and are better modeled as a multi-layered artificial network, rather than a single simple computational unit?<p>Similarly, do you think that spiking networks are important, or just a specific mechanism used in the brain to transmit information, which dense (or sparse) vectors of floats do in artificial neural networks?</div><br/><div id="41156090" class="c"><input type="checkbox" id="c-41156090" checked=""/><div class="controls bullet"><span class="by">nyrikki</span><span>|</span><a href="#41154779">root</a><span>|</span><a href="#41155466">parent</a><span>|</span><a href="#41155436">next</a><span>|</span><label class="collapse" for="c-41156090">[-]</label><label class="expand" for="c-41156090">[2 more]</label></div><br/><div class="children"><div class="content">If the goal was to create an artificial neural network that better approximated the biological human brain, yes the perceptron model is insufficient.<p>If your goal is to produce a useful model on real hardware and it works...no<p>Remember the constraints of ANNs being universal approximaters (in theory)<p>1) The function you are learning needs to be continuous
2) Your model is over a closed, bounded subset of R^n
3) The activation function is bounded and monodial<p>Obviously that is the theoretical UAT constraints.  For gradient decent typically used in real ML models, the constraint of finding only smooth approximations of continuous functions can be problematic depending on your needs.<p>But people leveraged phlogiston theory for beer brewing with great success and obviously Newtonian Mechanics is good enough for many tasks.<p>SNNs in theory should be able to solve problems that are challenging for perceptron models, but as I said, features like riddled basins are problematic so far.<p><a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1711.02160" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1711.02160</a></div><br/><div id="41159941" class="c"><input type="checkbox" id="c-41159941" checked=""/><div class="controls bullet"><span class="by">Jensson</span><span>|</span><a href="#41154779">root</a><span>|</span><a href="#41156090">parent</a><span>|</span><a href="#41155436">next</a><span>|</span><label class="collapse" for="c-41159941">[-]</label><label class="expand" for="c-41159941">[1 more]</label></div><br/><div class="children"><div class="content">&gt; 1) The function you are learning needs to be continuous<p>Seems like a bad limitation when you try to model reasoning based on facts and logic, there are many things there that are just true or false and no spectrum to it. There is no &quot;kinda true&quot; in those circumstances, you should only get 1 or 0 and never any value between.</div><br/></div></div></div></div></div></div><div id="41155436" class="c"><input type="checkbox" id="c-41155436" checked=""/><div class="controls bullet"><span class="by">derefr</span><span>|</span><a href="#41154779">root</a><span>|</span><a href="#41155226">parent</a><span>|</span><a href="#41155466">prev</a><span>|</span><a href="#41157054">next</a><span>|</span><label class="collapse" for="c-41155436">[-]</label><label class="expand" for="c-41155436">[2 more]</label></div><br/><div class="children"><div class="content">&gt; reduces ANN expressiveness<p>But does it? It’s been my hypothesis for a while that every grad-trained NN is hauling around a lot of “nascent” nodes — nodes that were on their way to being useful, but haven’t received enough input <i>yet</i> to actually have their outputs be distinguishable from noise &#x2F; ever influence the output. Sort of the neuroplastic equivalent of an evolutionary <i>pre-adaptation</i>.<p>If such nodes exist in NNs, they would be important to decreasing training time to learning new concepts <i>given further training</i>; but if there will <i>be</i> no more training, then they could be pruned for literally no change in expressivity (i.e. the optimality of the NN as an autoencoder of the existing training data.)</div><br/><div id="41155913" class="c"><input type="checkbox" id="c-41155913" checked=""/><div class="controls bullet"><span class="by">nyrikki</span><span>|</span><a href="#41154779">root</a><span>|</span><a href="#41155436">parent</a><span>|</span><a href="#41157054">next</a><span>|</span><label class="collapse" for="c-41155913">[-]</label><label class="expand" for="c-41155913">[1 more]</label></div><br/><div class="children"><div class="content">Easiest way I can figure out how to explain my claim.<p>Consider when you use &#x27;partial connectivity&#x27;, E.G. convolution or pooling layers for local feature extraction on say MNIST.<p>While useful, those partial connection layers are explicitly used because fully connected layers do not have translational invariance.<p>So with a fully connected network, shifting the letter &#x27;i&#x27; a few pixels to the right wouldn&#x27;t match.<p>We choose to discard some of those connections for local feature detection.  But as the reason that the fully connected model lacks translational invariance is because it maintains that position data.<p>Note how that is more &#x27;expressive&#x27;, even if counterproductive for the actual use case.<p>Another lens is the fact that neural networks have extreme simplicity bias. In that they learn only the simplest features to solve a task at hand.<p>If you want to recognize an i, irrespective of the translational location, that bias is useful.  But you &#x27;throw away&#x27; (in a very loose sense) the positional data to do so.<p>Horses for courses, not good vs bad.</div><br/></div></div></div></div></div></div><div id="41157054" class="c"><input type="checkbox" id="c-41157054" checked=""/><div class="controls bullet"><span class="by">eru</span><span>|</span><a href="#41154779">parent</a><span>|</span><a href="#41155226">prev</a><span>|</span><a href="#41158100">next</a><span>|</span><label class="collapse" for="c-41157054">[-]</label><label class="expand" for="c-41157054">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I think this might be the first step to making neural networks that actually mimic biological brains.<p>I don&#x27;t think that&#x27;s actually a good goal.  I suspect the whole term &#x27;neural network&#x27; is just misleading and leads to these kinds of misconceptions.<p>&#x27;Neural networks&#x27; are mostly just matrix multiplications interleaved with some simple non-linear functions like \x -&gt; max(0, x).  Nothing biological about that.</div><br/></div></div><div id="41158100" class="c"><input type="checkbox" id="c-41158100" checked=""/><div class="controls bullet"><span class="by">Salgat</span><span>|</span><a href="#41154779">parent</a><span>|</span><a href="#41157054">prev</a><span>|</span><a href="#41155518">next</a><span>|</span><label class="collapse" for="c-41158100">[-]</label><label class="expand" for="c-41158100">[1 more]</label></div><br/><div class="children"><div class="content">If you remove the speech centers of the brain all at once, you completely and permanently lose the ability to speak or understand speech. Do the same but very slowly, and the brain is able to compensate, even if you completely lose your original speech centers in the process. NN with pruning is the same thing, where you prune iteratively while retraining to regain most of the lost regressions. If you prune too much all at once, you have to restart from scratch.</div><br/></div></div><div id="41155518" class="c"><input type="checkbox" id="c-41155518" checked=""/><div class="controls bullet"><span class="by">TheDudeMan</span><span>|</span><a href="#41154779">parent</a><span>|</span><a href="#41158100">prev</a><span>|</span><a href="#41154904">next</a><span>|</span><label class="collapse" for="c-41155518">[-]</label><label class="expand" for="c-41155518">[7 more]</label></div><br/><div class="children"><div class="content">Stop trying to mimic brains.  Do what works best for transistors.</div><br/><div id="41155990" class="c"><input type="checkbox" id="c-41155990" checked=""/><div class="controls bullet"><span class="by">sva_</span><span>|</span><a href="#41154779">root</a><span>|</span><a href="#41155518">parent</a><span>|</span><a href="#41157126">next</a><span>|</span><label class="collapse" for="c-41155990">[-]</label><label class="expand" for="c-41155990">[4 more]</label></div><br/><div class="children"><div class="content">It would be foolish not to look for inspiration in a system that had billions of years of evolution invested in it.</div><br/><div id="41156103" class="c"><input type="checkbox" id="c-41156103" checked=""/><div class="controls bullet"><span class="by">p1esk</span><span>|</span><a href="#41154779">root</a><span>|</span><a href="#41155990">parent</a><span>|</span><a href="#41157126">next</a><span>|</span><label class="collapse" for="c-41156103">[-]</label><label class="expand" for="c-41156103">[3 more]</label></div><br/><div class="children"><div class="content">We already found the inspiration. That’s how we invented neural networks. Now we need to focus on what works.</div><br/><div id="41159535" class="c"><input type="checkbox" id="c-41159535" checked=""/><div class="controls bullet"><span class="by">dkersten</span><span>|</span><a href="#41154779">root</a><span>|</span><a href="#41156103">parent</a><span>|</span><a href="#41157071">next</a><span>|</span><label class="collapse" for="c-41159535">[-]</label><label class="expand" for="c-41159535">[1 more]</label></div><br/><div class="children"><div class="content">How do we know that current artificial neural networks aren’t the local maximum of modelling, and there isn’t a better model (biologically inspired or otherwise) that we haven’t explored yet?<p>We need both to work on improving what we have that works, and to explore other avenues and inspirations (both to try entirely new things, and to improve the things we already have working in new ways). I don’t think it wise to throw out what we have working to try again with something biologically inspired, but I also don’t think it wise to say ok we’ve learned enough from biology, let’s focus purely on what we have now, when we don’t understand so much about biological brains, intelligence, and consciousness.</div><br/></div></div><div id="41157071" class="c"><input type="checkbox" id="c-41157071" checked=""/><div class="controls bullet"><span class="by">eru</span><span>|</span><a href="#41154779">root</a><span>|</span><a href="#41156103">parent</a><span>|</span><a href="#41159535">prev</a><span>|</span><a href="#41157126">next</a><span>|</span><label class="collapse" for="c-41157071">[-]</label><label class="expand" for="c-41157071">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s good for some people to keep looking for more inspiration.  Not just from brains, but also from all other aspects of the world.<p>Eg dropout was (allegedly) inspired by our doubled up chromosomes and evolutionary selection.</div><br/></div></div></div></div></div></div><div id="41157126" class="c"><input type="checkbox" id="c-41157126" checked=""/><div class="controls bullet"><span class="by">smegger001</span><span>|</span><a href="#41154779">root</a><span>|</span><a href="#41155518">parent</a><span>|</span><a href="#41155990">prev</a><span>|</span><a href="#41156973">next</a><span>|</span><label class="collapse" for="c-41157126">[-]</label><label class="expand" for="c-41157126">[1 more]</label></div><br/><div class="children"><div class="content">except copying biology (neural networks) has worked better than other approaches tried so far (reasoning as search, symbolic and semantic nets, expert systems...) so stick with whats working and we have a working reference model to study and we can build optimized hardware to match if it keeps working better than other methods</div><br/></div></div><div id="41156973" class="c"><input type="checkbox" id="c-41156973" checked=""/><div class="controls bullet"><span class="by">kromem</span><span>|</span><a href="#41154779">root</a><span>|</span><a href="#41155518">parent</a><span>|</span><a href="#41157126">prev</a><span>|</span><a href="#41154904">next</a><span>|</span><label class="collapse" for="c-41156973">[-]</label><label class="expand" for="c-41156973">[1 more]</label></div><br/><div class="children"><div class="content">Or grow beyond both with optics.</div><br/></div></div></div></div><div id="41154904" class="c"><input type="checkbox" id="c-41154904" checked=""/><div class="controls bullet"><span class="by">wigster</span><span>|</span><a href="#41154779">parent</a><span>|</span><a href="#41155518">prev</a><span>|</span><a href="#41155975">next</a><span>|</span><label class="collapse" for="c-41154904">[-]</label><label class="expand" for="c-41154904">[1 more]</label></div><br/><div class="children"><div class="content">i know nothing of which i speak.... but the theme reminded me of the insect brains, with very relatively few Neurons that manage pretty extraordinary feats. 
i guess random evolution pruning happens and if there is no detrimental effect, cheerio.</div><br/></div></div><div id="41155975" class="c"><input type="checkbox" id="c-41155975" checked=""/><div class="controls bullet"><span class="by">kklisura</span><span>|</span><a href="#41154779">parent</a><span>|</span><a href="#41154904">prev</a><span>|</span><a href="#41154427">next</a><span>|</span><label class="collapse" for="c-41155975">[-]</label><label class="expand" for="c-41155975">[1 more]</label></div><br/><div class="children"><div class="content">&gt; mechanism like neuroplasticity that modifies the topology of neurons<p>Isn&#x27;t this already accomplished via weights?</div><br/></div></div></div></div><div id="41154427" class="c"><input type="checkbox" id="c-41154427" checked=""/><div class="controls bullet"><span class="by">mlajtos</span><span>|</span><a href="#41154779">prev</a><span>|</span><a href="#41154781">next</a><span>|</span><label class="collapse" for="c-41154427">[-]</label><label class="expand" for="c-41154427">[1 more]</label></div><br/><div class="children"><div class="content">That is pretty cool. I found a follow up work that applies this technique to LLM: <a href="https:&#x2F;&#x2F;konczer.github.io&#x2F;doc&#x2F;Poster_EEML23_JozsefKonczer.pdf" rel="nofollow">https:&#x2F;&#x2F;konczer.github.io&#x2F;doc&#x2F;Poster_EEML23_JozsefKonczer.pd...</a></div><br/></div></div><div id="41154781" class="c"><input type="checkbox" id="c-41154781" checked=""/><div class="controls bullet"><span class="by">Version467</span><span>|</span><a href="#41154427">prev</a><span>|</span><a href="#41160662">next</a><span>|</span><label class="collapse" for="c-41154781">[-]</label><label class="expand" for="c-41154781">[4 more]</label></div><br/><div class="children"><div class="content">This is super cool. It&#x27;s surprising to me that it took so long for someone to try this. It seems like such an obvious idea (in hindsight). But I guess that&#x27;s easy to say now that someone came up with it.
If this turns out to work well even for much larger models, then we might see loss functions that incorporate ever more specific performance metrics, conceivably even actual execution times on specific hardware.</div><br/><div id="41160328" class="c"><input type="checkbox" id="c-41160328" checked=""/><div class="controls bullet"><span class="by">szcs</span><span>|</span><a href="#41154781">parent</a><span>|</span><a href="#41156877">next</a><span>|</span><label class="collapse" for="c-41160328">[-]</label><label class="expand" for="c-41160328">[1 more]</label></div><br/><div class="children"><div class="content">Author here. I actually came up with the idea a long time ago, I first experimented with variants of this in Caffe (before Tensorflow was a thing).</div><br/></div></div><div id="41156877" class="c"><input type="checkbox" id="c-41156877" checked=""/><div class="controls bullet"><span class="by">xpe</span><span>|</span><a href="#41154781">parent</a><span>|</span><a href="#41160328">prev</a><span>|</span><a href="#41160662">next</a><span>|</span><label class="collapse" for="c-41156877">[-]</label><label class="expand" for="c-41156877">[2 more]</label></div><br/><div class="children"><div class="content">There was related work that happened before, as mentioned in the paper.</div><br/><div id="41158393" class="c"><input type="checkbox" id="c-41158393" checked=""/><div class="controls bullet"><span class="by">Version467</span><span>|</span><a href="#41154781">root</a><span>|</span><a href="#41156877">parent</a><span>|</span><a href="#41160662">next</a><span>|</span><label class="collapse" for="c-41158393">[-]</label><label class="expand" for="c-41158393">[1 more]</label></div><br/><div class="children"><div class="content">Whoops, missed that. Thanks.</div><br/></div></div></div></div></div></div><div id="41160662" class="c"><input type="checkbox" id="c-41160662" checked=""/><div class="controls bullet"><span class="by">szcs</span><span>|</span><a href="#41154781">prev</a><span>|</span><a href="#41155031">next</a><span>|</span><label class="collapse" for="c-41160662">[-]</label><label class="expand" for="c-41160662">[1 more]</label></div><br/><div class="children"><div class="content">Author here, I just noticed this. If you have any questions I can try answering them.</div><br/></div></div><div id="41155031" class="c"><input type="checkbox" id="c-41155031" checked=""/><div class="controls bullet"><span class="by">spacemanspiff01</span><span>|</span><a href="#41160662">prev</a><span>|</span><a href="#41159334">next</a><span>|</span><label class="collapse" for="c-41155031">[-]</label><label class="expand" for="c-41155031">[3 more]</label></div><br/><div class="children"><div class="content">So this was published a year and a half ago? Is there a reason it did not catch on?</div><br/><div id="41155145" class="c"><input type="checkbox" id="c-41155145" checked=""/><div class="controls bullet"><span class="by">svantana</span><span>|</span><a href="#41155031">parent</a><span>|</span><a href="#41160503">next</a><span>|</span><label class="collapse" for="c-41155145">[-]</label><label class="expand" for="c-41155145">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not really that innovative. As the paper notes, there are several similar previous works. Also, it sounds like they have done a bunch of tweaking to reduce the &quot;irreversible forgetting&quot; specifically for this particular dataset and network, which is not very scientific. Further testing is required to see if this method really has legs.</div><br/></div></div></div></div><div id="41159334" class="c"><input type="checkbox" id="c-41159334" checked=""/><div class="controls bullet"><span class="by">octocop</span><span>|</span><a href="#41155031">prev</a><span>|</span><a href="#41153043">next</a><span>|</span><label class="collapse" for="c-41159334">[-]</label><label class="expand" for="c-41159334">[3 more]</label></div><br/><div class="children"><div class="content">What advantages does this have over applying neural network compression methods after training?</div><br/><div id="41160384" class="c"><input type="checkbox" id="c-41160384" checked=""/><div class="controls bullet"><span class="by">szcs</span><span>|</span><a href="#41159334">parent</a><span>|</span><a href="#41159964">next</a><span>|</span><label class="collapse" for="c-41160384">[-]</label><label class="expand" for="c-41160384">[1 more]</label></div><br/><div class="children"><div class="content">Here is a quick graph I just generated from data I had. Horizontal axis is average bit depth, vertical is accuracy. PTQ is Post Training Quantisation, QAT is Quantisation Aware Training. It&#x27;s a simple ResNet trained on CIFAR-10, I don&#x27;t have the resources to train anything bigger.<p><a href="https:&#x2F;&#x2F;i.imgur.com&#x2F;yiVLljh.png" rel="nofollow">https:&#x2F;&#x2F;i.imgur.com&#x2F;yiVLljh.png</a></div><br/></div></div><div id="41159964" class="c"><input type="checkbox" id="c-41159964" checked=""/><div class="controls bullet"><span class="by">Jensson</span><span>|</span><a href="#41159334">parent</a><span>|</span><a href="#41160384">prev</a><span>|</span><a href="#41153043">next</a><span>|</span><label class="collapse" for="c-41159964">[-]</label><label class="expand" for="c-41159964">[1 more]</label></div><br/><div class="children"><div class="content">If you do it during training you automatically check that the compressed model still do what you want after compression, and can even correct some small issues by continuing the training on the smaller model.<p>Edit: In general the more a compression function understands of what your goals are the better, so it is naturally advantageous to make the compression function look like training since then it is fully aware of what to optimize for.</div><br/></div></div></div></div><div id="41153043" class="c"><input type="checkbox" id="c-41153043" checked=""/><div class="controls bullet"><span class="by">bilsbie</span><span>|</span><a href="#41159334">prev</a><span>|</span><a href="#41161336">next</a><span>|</span><label class="collapse" for="c-41153043">[-]</label><label class="expand" for="c-41153043">[3 more]</label></div><br/><div class="children"><div class="content">dynamic quantization-aware training that puts size (in bytes) of the model in the loss</div><br/><div id="41154259" class="c"><input type="checkbox" id="c-41154259" checked=""/><div class="controls bullet"><span class="by">diimdeep</span><span>|</span><a href="#41153043">parent</a><span>|</span><a href="#41161336">next</a><span>|</span><label class="collapse" for="c-41154259">[-]</label><label class="expand" for="c-41154259">[2 more]</label></div><br/><div class="children"><div class="content">I know where you saw that<p><a href="https:&#x2F;&#x2F;x.com&#x2F;realGeorgeHotz&#x2F;status&#x2F;1819963680739512550" rel="nofollow">https:&#x2F;&#x2F;x.com&#x2F;realGeorgeHotz&#x2F;status&#x2F;1819963680739512550</a><p>&gt; This is one of the coolest papers I&#x27;ve seen in a while. &quot;Self-Compressing Neural Networks&quot; is dynamic quantization-aware training that puts size (in bytes) of the model in the loss!
&gt; My implementation (in @__tinygrad__):<p><a href="https:&#x2F;&#x2F;github.com&#x2F;geohot&#x2F;ai-notebooks&#x2F;blob&#x2F;master&#x2F;mnist_self_compression.ipynb">https:&#x2F;&#x2F;github.com&#x2F;geohot&#x2F;ai-notebooks&#x2F;blob&#x2F;master&#x2F;mnist_sel...</a></div><br/><div id="41161873" class="c"><input type="checkbox" id="c-41161873" checked=""/><div class="controls bullet"><span class="by">bilsbie</span><span>|</span><a href="#41153043">root</a><span>|</span><a href="#41154259">parent</a><span>|</span><a href="#41161336">next</a><span>|</span><label class="collapse" for="c-41161873">[-]</label><label class="expand" for="c-41161873">[1 more]</label></div><br/><div class="children"><div class="content">True. It seemed like a good, concise summary. Maybe I should have credited him.</div><br/></div></div></div></div></div></div><div id="41154738" class="c"><input type="checkbox" id="c-41154738" checked=""/><div class="controls bullet"><span class="by">andrewflnr</span><span>|</span><a href="#41161336">prev</a><span>|</span><label class="collapse" for="c-41154738">[-]</label><label class="expand" for="c-41154738">[8 more]</label></div><br/><div class="children"><div class="content">This kind of thing, much more than LLMs, makes me worry about AGI takeoff.</div><br/><div id="41154798" class="c"><input type="checkbox" id="c-41154798" checked=""/><div class="controls bullet"><span class="by">tazu</span><span>|</span><a href="#41154738">parent</a><span>|</span><label class="collapse" for="c-41154798">[-]</label><label class="expand" for="c-41154798">[7 more]</label></div><br/><div class="children"><div class="content">Why? Do you think lossless compression is intelligence?</div><br/><div id="41155083" class="c"><input type="checkbox" id="c-41155083" checked=""/><div class="controls bullet"><span class="by">andrewflnr</span><span>|</span><a href="#41154738">root</a><span>|</span><a href="#41154798">parent</a><span>|</span><a href="#41154870">next</a><span>|</span><label class="collapse" for="c-41155083">[-]</label><label class="expand" for="c-41155083">[1 more]</label></div><br/><div class="children"><div class="content">No, but since you mentioned it: <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Hutter_Prize" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Hutter_Prize</a><p>Anyway, OP is about lossy compression. I can&#x27;t fully follow it but they talk about techniques for mitigating loss later in the paper.</div><br/></div></div><div id="41154870" class="c"><input type="checkbox" id="c-41154870" checked=""/><div class="controls bullet"><span class="by">luckystarr</span><span>|</span><a href="#41154738">root</a><span>|</span><a href="#41154798">parent</a><span>|</span><a href="#41155083">prev</a><span>|</span><a href="#41155176">next</a><span>|</span><label class="collapse" for="c-41154870">[-]</label><label class="expand" for="c-41154870">[3 more]</label></div><br/><div class="children"><div class="content">Parents thinking was probably: If you can achieve similar results with a fraction of memory&#x2F;compute usage then capability at the same hardware level will increase even more.</div><br/><div id="41158485" class="c"><input type="checkbox" id="c-41158485" checked=""/><div class="controls bullet"><span class="by">HeatrayEnjoyer</span><span>|</span><a href="#41154738">root</a><span>|</span><a href="#41154870">parent</a><span>|</span><a href="#41155009">next</a><span>|</span><label class="collapse" for="c-41158485">[-]</label><label class="expand" for="c-41158485">[1 more]</label></div><br/><div class="children"><div class="content">&quot;Hardware overhang&quot; is the term of art.<p>My meek opinion is this is obvious. Human-level intelligence requires at most 20 watts and substrate no more complicated than can be constructed from simple organic molecules in a dirty environment.<p>What is possible with 20 kilowatts and wafer fabricators?</div><br/></div></div><div id="41155009" class="c"><input type="checkbox" id="c-41155009" checked=""/><div class="controls bullet"><span class="by">andrewflnr</span><span>|</span><a href="#41154738">root</a><span>|</span><a href="#41154870">parent</a><span>|</span><a href="#41158485">prev</a><span>|</span><a href="#41155176">next</a><span>|</span><label class="collapse" for="c-41155009">[-]</label><label class="expand" for="c-41155009">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s specifically the fact that the network is directing its own optimization. Which yes, could then potentially be used to get more capability from the hardware, but that&#x27;s true of manually optimized networks as well. Needing less human help is the... interesting part.</div><br/></div></div></div></div><div id="41155176" class="c"><input type="checkbox" id="c-41155176" checked=""/><div class="controls bullet"><span class="by">idiotsecant</span><span>|</span><a href="#41154738">root</a><span>|</span><a href="#41154798">parent</a><span>|</span><a href="#41154870">prev</a><span>|</span><label class="collapse" for="c-41155176">[-]</label><label class="expand" for="c-41155176">[2 more]</label></div><br/><div class="children"><div class="content">Compressing understanding (not just information) in a way that uses semantic links in information is a big part of intelligence, I&#x27;d say.</div><br/><div id="41156183" class="c"><input type="checkbox" id="c-41156183" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#41154738">root</a><span>|</span><a href="#41155176">parent</a><span>|</span><label class="collapse" for="c-41156183">[-]</label><label class="expand" for="c-41156183">[1 more]</label></div><br/><div class="children"><div class="content">We&#x27;re doing a double search - searching for experience outside, collecting data - and searching for understanding inside, by compressing the data. Search and learn, they define both AI and us.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></body></html>