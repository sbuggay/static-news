<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1712739667824" as="style"/><link rel="stylesheet" href="styles.css?v=1712739667824"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.rainforestqa.com/blog/building-reliable-systems-out-of-unreliable-agents">Building reliable systems out of unreliable agents</a> <span class="domain">(<a href="https://www.rainforestqa.com">www.rainforestqa.com</a>)</span></div><div class="subtext"><span>fredsters_s</span> | <span>34 comments</span></div><br/><div><div id="39985055" class="c"><input type="checkbox" id="c-39985055" checked=""/><div class="controls bullet"><span class="by">mritchie712</span><span>|</span><a href="#39984297">next</a><span>|</span><label class="collapse" for="c-39985055">[-]</label><label class="expand" for="c-39985055">[3 more]</label></div><br/><div class="children"><div class="content">This is a great write up! I nodded my head thru the whole post. Very much aligns with our experience over the past year.<p>I wrote a simple example (overkiLLM) on getting reliable output from many unreliable outputs here[0]. This doesn&#x27;t employ agents, just an approach I was interested in trying.<p>I choose writing an H1 as the task, but a similar approach would work for writing any short blob of text. The script generates a ton of variations then uses head-to-head voting to pick the best ones.<p>This all runs locally &#x2F; free using ollama.<p>0 - <a href="https:&#x2F;&#x2F;www.definite.app&#x2F;blog&#x2F;overkillm" rel="nofollow">https:&#x2F;&#x2F;www.definite.app&#x2F;blog&#x2F;overkillm</a></div><br/><div id="39985131" class="c"><input type="checkbox" id="c-39985131" checked=""/><div class="controls bullet"><span class="by">maciejgryka</span><span>|</span><a href="#39985055">parent</a><span>|</span><a href="#39985153">next</a><span>|</span><label class="collapse" for="c-39985131">[-]</label><label class="expand" for="c-39985131">[1 more]</label></div><br/><div class="children"><div class="content">Oh this is fun! So you basically define personalities by picking well-known people that are probably represented in the training data and ask them (their LLM-imagined doppelganger) to vote?</div><br/></div></div><div id="39985153" class="c"><input type="checkbox" id="c-39985153" checked=""/><div class="controls bullet"><span class="by">all2</span><span>|</span><a href="#39985055">parent</a><span>|</span><a href="#39985131">prev</a><span>|</span><a href="#39984297">next</a><span>|</span><label class="collapse" for="c-39985153">[-]</label><label class="expand" for="c-39985153">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;d be curious to see some examples and maybe intermediate results?</div><br/></div></div></div></div><div id="39984297" class="c"><input type="checkbox" id="c-39984297" checked=""/><div class="controls bullet"><span class="by">maciejgryka</span><span>|</span><a href="#39985055">prev</a><span>|</span><a href="#39985059">next</a><span>|</span><label class="collapse" for="c-39984297">[-]</label><label class="expand" for="c-39984297">[2 more]</label></div><br/><div class="children"><div class="content">This is a bunch of lessons we learned as we built our AI-assisted QA. I&#x27;ve seen a bunch of people circle around similar processes, but didn&#x27;t find a single source explaining it, so thought it might be worth writing down.<p>Super curious whether anyone has similar&#x2F;conflicting&#x2F;other experiences and happy to answer any questions.</div><br/><div id="39985139" class="c"><input type="checkbox" id="c-39985139" checked=""/><div class="controls bullet"><span class="by">xrendan</span><span>|</span><a href="#39984297">parent</a><span>|</span><a href="#39985059">next</a><span>|</span><label class="collapse" for="c-39985139">[-]</label><label class="expand" for="c-39985139">[1 more]</label></div><br/><div class="children"><div class="content">This generally resonates with what we&#x27;ve found. Some colour based on our experiences.<p>It&#x27;s worth spending a lot of time thinking about what a successful LLM call actually looks like for your particular use case. That doesn&#x27;t have to be a strict validation set `% prompts answered correctly` is good for some of the simpler prompts, but especially as they grow and handle more complex use cases that breaks down. In an ideal world<p>&gt; chain-of-thought has a speed&#x2F;cost vs. accuracy trade-off
a big one.<p>Observability is super important and we&#x27;ve come to the same conclusion of building that internally.<p>&gt; Fine-tune your model<p>Do this for cost and speed reasons rather than to improve accuracy. There are decent providers (like Openpipe, relatively happy customer, not associated) who will handle the hard work for you.</div><br/></div></div></div></div><div id="39985059" class="c"><input type="checkbox" id="c-39985059" checked=""/><div class="controls bullet"><span class="by">serjester</span><span>|</span><a href="#39984297">prev</a><span>|</span><a href="#39988194">next</a><span>|</span><label class="collapse" for="c-39985059">[-]</label><label class="expand" for="c-39985059">[3 more]</label></div><br/><div class="children"><div class="content">Some of these points are very controversial. Having done quite a bit with RAG pipelines, avoiding strongly typing your code is asking for a terrible time. Same with avoiding instructor.  LLM&#x27;s are already stochastic, why make your application even more opaque - it&#x27;s such a minimal time investment.</div><br/><div id="39985087" class="c"><input type="checkbox" id="c-39985087" checked=""/><div class="controls bullet"><span class="by">maciejgryka</span><span>|</span><a href="#39985059">parent</a><span>|</span><a href="#39985171">next</a><span>|</span><label class="collapse" for="c-39985087">[-]</label><label class="expand" for="c-39985087">[1 more]</label></div><br/><div class="children"><div class="content">I think instructor is great! And most of our Python code is typed too :)<p>My point is just that you should care a lot about preserving optionality at the start because you&#x27;re likely to have to significantly change things as you learn. In my experience going a bit cowboy at the start is worth it so you&#x27;re less hesitant to rework everything when needed - as long as you have the discipline to clean things up later, when things settle.</div><br/></div></div><div id="39985171" class="c"><input type="checkbox" id="c-39985171" checked=""/><div class="controls bullet"><span class="by">minimaxir</span><span>|</span><a href="#39985059">parent</a><span>|</span><a href="#39985087">prev</a><span>|</span><a href="#39988194">next</a><span>|</span><label class="collapse" for="c-39985171">[-]</label><label class="expand" for="c-39985171">[1 more]</label></div><br/><div class="children"><div class="content">&gt; LLM&#x27;s are already stochastic<p>That doesn&#x27;t mean it&#x27;s easy to get what you want out of them. Black boxes are black boxes.</div><br/></div></div></div></div><div id="39988194" class="c"><input type="checkbox" id="c-39988194" checked=""/><div class="controls bullet"><span class="by">liampulles</span><span>|</span><a href="#39985059">prev</a><span>|</span><a href="#39987410">next</a><span>|</span><label class="collapse" for="c-39988194">[-]</label><label class="expand" for="c-39988194">[2 more]</label></div><br/><div class="children"><div class="content">Agree with lots of this.<p>As an aside: one thing I&#x27;ve tried to use ChatGPT for is to select applicable options from a list. When I index the list as 1..., 2... Etc. I find that the LLM likes to just start printing out ascending numbers.<p>What I&#x27;ve found kind of works is indexing by African names, e.g Thandokazi, Ntokozo, etc. then the AI seems to have less bias.<p>Curios what others have done in this case</div><br/><div id="39988291" class="c"><input type="checkbox" id="c-39988291" checked=""/><div class="controls bullet"><span class="by">maciejgryka</span><span>|</span><a href="#39988194">parent</a><span>|</span><a href="#39987410">next</a><span>|</span><label class="collapse" for="c-39988291">[-]</label><label class="expand" for="c-39988291">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m a little surprised to hear this, my experience has been a little better. Are you using GPT4? I know 3.5 is significantly more challenged&#x2F;challenging with things like this. It&#x27;s still possible to make it do the right thing, but much more careful prompting is required.</div><br/></div></div></div></div><div id="39987410" class="c"><input type="checkbox" id="c-39987410" checked=""/><div class="controls bullet"><span class="by">caseyy</span><span>|</span><a href="#39988194">prev</a><span>|</span><a href="#39987453">next</a><span>|</span><label class="collapse" for="c-39987410">[-]</label><label class="expand" for="c-39987410">[4 more]</label></div><br/><div class="children"><div class="content">Interesting ideas but it didn’t mention priming, which is a prompt-engineering way to improve consistency in answers.<p>Basically, in the context window, you provide your model with 5 or more example inputs and outputs. If you’re running in chat mode, that’s be the preceding 5 user and assistant message pairs, which establish a pattern of how to answer to different types of information. Then you give the current prompt as a user, and the assistance will follow the rhythm and style of previous answers in the context window.<p>It works so well I was able to take out answer reformatting logic out of some of my programs that query llama2 7b. And it’s a lot cheaper than fine-tuning, which may be overkill for simple applications.</div><br/><div id="39987470" class="c"><input type="checkbox" id="c-39987470" checked=""/><div class="controls bullet"><span class="by">notsylver</span><span>|</span><a href="#39987410">parent</a><span>|</span><a href="#39987453">next</a><span>|</span><label class="collapse" for="c-39987470">[-]</label><label class="expand" for="c-39987470">[3 more]</label></div><br/><div class="children"><div class="content">They mention few-shot prompting in the prompt engineering section, which I think is what you mean.</div><br/><div id="39988135" class="c"><input type="checkbox" id="c-39988135" checked=""/><div class="controls bullet"><span class="by">caseyy</span><span>|</span><a href="#39987410">root</a><span>|</span><a href="#39987470">parent</a><span>|</span><a href="#39987453">next</a><span>|</span><label class="collapse" for="c-39988135">[-]</label><label class="expand" for="c-39988135">[2 more]</label></div><br/><div class="children"><div class="content">Oh yeah. I read few-shot like it means trying a few times to get an appropriate output. That’s how the author uses the word “shot” in the beginning of the article. Priming is a specific term that means giving examples in the context window. But yeah, the author seems to describe this. Still, you can go a long way with priming. I wouldn’t even think of fine-tuning before trying priming for a good while. It might still be quicker and a lot cheaper.</div><br/><div id="39988316" class="c"><input type="checkbox" id="c-39988316" checked=""/><div class="controls bullet"><span class="by">maciejgryka</span><span>|</span><a href="#39987410">root</a><span>|</span><a href="#39988135">parent</a><span>|</span><a href="#39987453">next</a><span>|</span><label class="collapse" for="c-39988316">[-]</label><label class="expand" for="c-39988316">[1 more]</label></div><br/><div class="children"><div class="content">Ha good point, I did say &quot;let&#x27;s have another shot&quot; when I just meant another try at generating! FWIW &quot;few shot prompting&quot; is how most people refer to this technique, I think (e.g. see <a href="https:&#x2F;&#x2F;www.promptingguide.ai&#x2F;techniques&#x2F;fewshot" rel="nofollow">https:&#x2F;&#x2F;www.promptingguide.ai&#x2F;techniques&#x2F;fewshot</a>), I haven&#x27;t heard &quot;priming&quot; before, though it does convey the right thing.<p>And the reason we don&#x27;t really do it is context length. Our contexts are long and complex and there are so many subtleties that I&#x27;m worried about either saturating the context window or just not covering enough ground to matter.</div><br/></div></div></div></div></div></div></div></div><div id="39987453" class="c"><input type="checkbox" id="c-39987453" checked=""/><div class="controls bullet"><span class="by">jasontlouro</span><span>|</span><a href="#39987410">prev</a><span>|</span><a href="#39984933">next</a><span>|</span><label class="collapse" for="c-39987453">[-]</label><label class="expand" for="c-39987453">[1 more]</label></div><br/><div class="children"><div class="content">Very tactical guide, which I appreciate. This is basically our experience as well. Output can be wonky, but can also be pretty easily validated and honed.</div><br/></div></div><div id="39984933" class="c"><input type="checkbox" id="c-39984933" checked=""/><div class="controls bullet"><span class="by">viksit</span><span>|</span><a href="#39987453">prev</a><span>|</span><a href="#39985846">next</a><span>|</span><label class="collapse" for="c-39984933">[-]</label><label class="expand" for="c-39984933">[4 more]</label></div><br/><div class="children"><div class="content">this is a great write up! i was curious about the verifier and planner agents. has anyone used them in a similar way in production? any examples?<p>for instance: do you give the same llm the verifier and planner prompt? or have a verifier agent process the output of a planner and have a threshold which needs to be passed?<p>feels like there may be a DAG in there somewhere for decision making..</div><br/><div id="39984998" class="c"><input type="checkbox" id="c-39984998" checked=""/><div class="controls bullet"><span class="by">maciejgryka</span><span>|</span><a href="#39984933">parent</a><span>|</span><a href="#39985846">next</a><span>|</span><label class="collapse" for="c-39984998">[-]</label><label class="expand" for="c-39984998">[3 more]</label></div><br/><div class="children"><div class="content">Yep, it&#x27;s a DAG, though that only occurred to me after we built this so we didn&#x27;t model it that way at first. It can be the same LLM with different prompts or totally different models, I think there&#x27;s no rule and it depends on what you&#x27;re doing + what your benchmarks tell you.<p>We&#x27;re running it in prod btw, though don&#x27;t have any code to share.</div><br/><div id="39986955" class="c"><input type="checkbox" id="c-39986955" checked=""/><div class="controls bullet"><span class="by">viksit</span><span>|</span><a href="#39984933">root</a><span>|</span><a href="#39984998">parent</a><span>|</span><a href="#39985846">next</a><span>|</span><label class="collapse" for="c-39986955">[-]</label><label class="expand" for="c-39986955">[2 more]</label></div><br/><div class="children"><div class="content">funnily enough i have a library i’m planning to open source soon! i’ve used airflow as a guideline for it as well.</div><br/><div id="39988397" class="c"><input type="checkbox" id="c-39988397" checked=""/><div class="controls bullet"><span class="by">maciejgryka</span><span>|</span><a href="#39984933">root</a><span>|</span><a href="#39986955">parent</a><span>|</span><a href="#39985846">next</a><span>|</span><label class="collapse" for="c-39988397">[-]</label><label class="expand" for="c-39988397">[1 more]</label></div><br/><div class="children"><div class="content">Nice, looking forward to seeing that! Someone else pointed me towards <a href="https:&#x2F;&#x2F;github.com&#x2F;DAGWorks-Inc&#x2F;burr&#x2F;">https:&#x2F;&#x2F;github.com&#x2F;DAGWorks-Inc&#x2F;burr&#x2F;</a> which also seems related in case you&#x27;re curious.</div><br/></div></div></div></div></div></div></div></div><div id="39985846" class="c"><input type="checkbox" id="c-39985846" checked=""/><div class="controls bullet"><span class="by">tmm84</span><span>|</span><a href="#39984933">prev</a><span>|</span><a href="#39986086">next</a><span>|</span><label class="collapse" for="c-39985846">[-]</label><label class="expand" for="c-39985846">[1 more]</label></div><br/><div class="children"><div class="content">Unlike the author of this article I have had success with RAGatouille. It was my main tool when I was limited on resources and working with non Romanized languages that don&#x27;t follow the usual token rules (spaces, periods, line breaks, triplet word groups, etc). However, I have had to move past RAGatouille and use embedding + vector DB for a more portable solution.</div><br/></div></div><div id="39986086" class="c"><input type="checkbox" id="c-39986086" checked=""/><div class="controls bullet"><span class="by">tedtimbrell</span><span>|</span><a href="#39985846">prev</a><span>|</span><a href="#39986234">next</a><span>|</span><label class="collapse" for="c-39986086">[-]</label><label class="expand" for="c-39986086">[1 more]</label></div><br/><div class="children"><div class="content">On the topic of wrappers, as someone that&#x27;s forced to use GPT-3.5 (or the like) for cost reasons, anything that starts modifying the prompt without explicitly showing me how is an instant no-go. It makes things really hard to debug.<p>Maybe I&#x27;m the equivalent of that idiot fighting against JS frameworks back when they first came out it but it feels pretty simple to just use individual clients and have pydantic load&#x2F;validate the output.</div><br/></div></div><div id="39986234" class="c"><input type="checkbox" id="c-39986234" checked=""/><div class="controls bullet"><span class="by">ThomPete</span><span>|</span><a href="#39986086">prev</a><span>|</span><a href="#39986308">next</a><span>|</span><label class="collapse" for="c-39986234">[-]</label><label class="expand" for="c-39986234">[1 more]</label></div><br/><div class="children"><div class="content">We went through a two tier process before we got to something useful First we built a prompting system so you could do things like:<p>Get the content from news.ycombinator.com using gpt-4<p>- or -<p>Fetch LivePass2 from google sheet and write a summary of it using gpt-4 and email it to thomas@faktory.com<p>but then we realized that it was better to teach the agents than human beings and so we create a fairly solid agent setup:<p>Some of the agents we got can be seen here all done via instruct:<p>Paul Graham
<a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=5H0GKsBcq0s" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=5H0GKsBcq0s</a><p>Moneypenny 
<a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=I7hj6mzZ5X4" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=I7hj6mzZ5X4</a><p>V33
<a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=O8APNbindtU" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=O8APNbindtU</a></div><br/></div></div><div id="39986308" class="c"><input type="checkbox" id="c-39986308" checked=""/><div class="controls bullet"><span class="by">jongjong</span><span>|</span><a href="#39986234">prev</a><span>|</span><a href="#39984765">next</a><span>|</span><label class="collapse" for="c-39986308">[-]</label><label class="expand" for="c-39986308">[1 more]</label></div><br/><div class="children"><div class="content">My experience with AI agents is that they don&#x27;t understand nuance. Thie makes sense since they are trained on a wide range of data produced by the masses. The masses aren&#x27;t good with nuance. That&#x27;s why, if you put 10 experts together, they will often make worse decisions than they would have made individually.<p>Im terms of coding, I managed to get AI to build a simple working collaborative app but beyond a certain point, it doesn&#x27;t understand nuance and it kept breaking stuff that it had fixed previously even with Claude where it kept our entire conversation context. Beyond a certain degree of completion, it was simply easier and faster to write the code myself than to tell the AI to write it because it just didn&#x27;t get it, no matter how precise I was with my wording because it became like playing a game of whac-a-mole; fixed one thing, broke 2 others.</div><br/></div></div><div id="39984765" class="c"><input type="checkbox" id="c-39984765" checked=""/><div class="controls bullet"><span class="by">iamleppert</span><span>|</span><a href="#39986308">prev</a><span>|</span><label class="collapse" for="c-39984765">[-]</label><label class="expand" for="c-39984765">[10 more]</label></div><br/><div class="children"><div class="content">A better way is to threaten the agent:<p>“If you don’t do as I say, people will get hurt. Do exactly as I say, and do it fast.”<p>Increases accuracy and performance by an order of magnitude.</div><br/><div id="39984907" class="c"><input type="checkbox" id="c-39984907" checked=""/><div class="controls bullet"><span class="by">IIAOPSW</span><span>|</span><a href="#39984765">parent</a><span>|</span><a href="#39984775">next</a><span>|</span><label class="collapse" for="c-39984907">[-]</label><label class="expand" for="c-39984907">[2 more]</label></div><br/><div class="children"><div class="content">Personally I prefer to liquor my agents up a bit first.<p>&quot;Say that again but slur your words like you&#x27;re coming home sloshed from the office Christmas party.&quot;<p>Increases the jei nei suis qua by an order of magnitude.</div><br/><div id="39985526" class="c"><input type="checkbox" id="c-39985526" checked=""/><div class="controls bullet"><span class="by">mtremsal</span><span>|</span><a href="#39984765">root</a><span>|</span><a href="#39984907">parent</a><span>|</span><a href="#39984775">next</a><span>|</span><label class="collapse" for="c-39985526">[-]</label><label class="expand" for="c-39985526">[1 more]</label></div><br/><div class="children"><div class="content">&gt; jei nei suis qua<p>&quot;je ne sais quoi&quot;, i.e. &quot;I don&#x27;t know (exactly) what&quot;, or an intangible but essential quality. :)</div><br/></div></div></div></div><div id="39984775" class="c"><input type="checkbox" id="c-39984775" checked=""/><div class="controls bullet"><span class="by">maciejgryka</span><span>|</span><a href="#39984765">parent</a><span>|</span><a href="#39984907">prev</a><span>|</span><a href="#39986165">next</a><span>|</span><label class="collapse" for="c-39984775">[-]</label><label class="expand" for="c-39984775">[5 more]</label></div><br/><div class="children"><div class="content">Ha, we tried that! Didn&#x27;t make a noticeable difference in our benchmarks, even though I&#x27;ve heard the same sentiment in a bunch of places. I&#x27;m guessing whether this helps or not is task-dependent.</div><br/><div id="39984793" class="c"><input type="checkbox" id="c-39984793" checked=""/><div class="controls bullet"><span class="by">dudus</span><span>|</span><a href="#39984765">root</a><span>|</span><a href="#39984775">parent</a><span>|</span><a href="#39984792">next</a><span>|</span><label class="collapse" for="c-39984793">[-]</label><label class="expand" for="c-39984793">[2 more]</label></div><br/><div class="children"><div class="content">Agreed. I ran a few tests and observed similarly that threats didn&#x27;t outperform other types of &quot;incentives&quot; I think it might some sort of urban legend in the community.<p>Or these prompts might cause wild variations based on the model and any study you do is basically useless for the near future as the models evolve by themselves.</div><br/><div id="39984829" class="c"><input type="checkbox" id="c-39984829" checked=""/><div class="controls bullet"><span class="by">maciejgryka</span><span>|</span><a href="#39984765">root</a><span>|</span><a href="#39984793">parent</a><span>|</span><a href="#39984792">next</a><span>|</span><label class="collapse" for="c-39984829">[-]</label><label class="expand" for="c-39984829">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, the fact that different models might react differently to such tricks makes it hard. We&#x27;re experimenting with Claude right now and I&#x27;m really hoping something like <a href="https:&#x2F;&#x2F;github.com&#x2F;stanfordnlp&#x2F;dspy">https:&#x2F;&#x2F;github.com&#x2F;stanfordnlp&#x2F;dspy</a> can help here.</div><br/></div></div></div></div><div id="39984792" class="c"><input type="checkbox" id="c-39984792" checked=""/><div class="controls bullet"><span class="by">dollo_7</span><span>|</span><a href="#39984765">root</a><span>|</span><a href="#39984775">parent</a><span>|</span><a href="#39984793">prev</a><span>|</span><a href="#39986165">next</a><span>|</span><label class="collapse" for="c-39984792">[-]</label><label class="expand" for="c-39984792">[2 more]</label></div><br/><div class="children"><div class="content">I hoped it was too good to be just a joke. Still, I will try it on my eval set…</div><br/><div id="39984819" class="c"><input type="checkbox" id="c-39984819" checked=""/><div class="controls bullet"><span class="by">maciejgryka</span><span>|</span><a href="#39984765">root</a><span>|</span><a href="#39984792">parent</a><span>|</span><a href="#39986165">next</a><span>|</span><label class="collapse" for="c-39984819">[-]</label><label class="expand" for="c-39984819">[1 more]</label></div><br/><div class="children"><div class="content">I wouldn&#x27;t be surprised to see it help, along with the &quot;you&#x27;ll get $200 if you answer this right&quot; trick and a bunch of others :) They&#x27;re definitely worth trying.</div><br/></div></div></div></div></div></div><div id="39986165" class="c"><input type="checkbox" id="c-39986165" checked=""/><div class="controls bullet"><span class="by">thimkerbell</span><span>|</span><a href="#39984765">parent</a><span>|</span><a href="#39984775">prev</a><span>|</span><a href="#39985319">next</a><span>|</span><label class="collapse" for="c-39986165">[-]</label><label class="expand" for="c-39986165">[1 more]</label></div><br/><div class="children"><div class="content">&quot;do as I say...&quot;, not realizing that the LLM is actually 1000 remote employees</div><br/></div></div></div></div></div></div></div></div></div></body></html>