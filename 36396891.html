<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1687251655311" as="style"/><link rel="stylesheet" href="styles.css?v=1687251655311"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://mastodon.gamedev.place/@rygorous/110572829749524388">The least interesting part about AVX-512 is the 512 bits vector width</a> <span class="domain">(<a href="https://mastodon.gamedev.place">mastodon.gamedev.place</a>)</span></div><div class="subtext"><span>luu</span> | <span>68 comments</span></div><br/><div><div id="36397667" class="c"><input type="checkbox" id="c-36397667" checked=""/><div class="controls bullet"><span class="by">bombela</span><span>|</span><a href="#36398457">next</a><span>|</span><label class="collapse" for="c-36397667">[-]</label><label class="expand" for="c-36397667">[11 more]</label></div><br/><div class="children"><div class="content">Summary:<p>AVX-512 adds many instructions that can replace what used to take 3 less efficient instructions.<p>This instruction set also double the number of available SIMD (single instruction multiple data) registers.<p>Those instructions are very useful on 128 bits vectors. And not a lot of people actually need 512 bit vectors.<p>Because of the number of registers and 512 bits width, it takes a lot of space in silicon. This makes it costly, and so is reserved for more expensive CPUs.<p>Had it been limited to, or also offered in a 256 bits version, this instruction set would have most likely be included in many more CPUs. Making it much more useful.</div><br/><div id="36399771" class="c"><input type="checkbox" id="c-36399771" checked=""/><div class="controls bullet"><span class="by">reitzensteinm</span><span>|</span><a href="#36397667">parent</a><span>|</span><a href="#36398161">next</a><span>|</span><label class="collapse" for="c-36399771">[-]</label><label class="expand" for="c-36399771">[2 more]</label></div><br/><div class="children"><div class="content">The physical register file is much larger than the logical register count. A budget option could simply reduce the amount of renaming done to save space.<p>In Intel&#x27;s case, Cannon Lake did have AVX 512, but was blocked from being a mainstream part due to 10nm yields. And then their rushed efficiency core strategy effectively disabled AVX-512 just as they were getting back on track.<p>I don&#x27;t think there&#x27;s an intrinsic reason you couldn&#x27;t have efficiency cores run AVX-512 albeit slowly and expect we&#x27;ll see just that.</div><br/><div id="36400861" class="c"><input type="checkbox" id="c-36400861" checked=""/><div class="controls bullet"><span class="by">phh</span><span>|</span><a href="#36397667">root</a><span>|</span><a href="#36399771">parent</a><span>|</span><a href="#36398161">next</a><span>|</span><label class="collapse" for="c-36400861">[-]</label><label class="expand" for="c-36400861">[1 more]</label></div><br/><div class="children"><div class="content">&gt; And then their rushed efficiency core strategy effectively disabled AVX-512 just as they were getting back on track.<p>I partly blame Linux for that. I remember asking at Kernel Recipes about supporting truly heterogenous multi - processor systems and got shrugged &quot;don&#x27;t buy broken hardware&quot;.
Back then, it was for a Broadcom home gateway product, which has an asymmetrical dual core, one with a FPU, the other without. Since then we have seen many examples of such assymetry: most HMP smartphones have asymmetrical instruction set. Mono (and probably all JIT VMs)  hit issues of varying cache length so the perfect abstraction is already gone. And now we have Intel E vs P.
This is a rather hard problem, I won&#x27;t pretend otherwise but the amount of dead silicon, and lost power efficiency accumulates significantly.</div><br/></div></div></div></div><div id="36398161" class="c"><input type="checkbox" id="c-36398161" checked=""/><div class="controls bullet"><span class="by">mtklein</span><span>|</span><a href="#36397667">parent</a><span>|</span><a href="#36399771">prev</a><span>|</span><a href="#36398457">next</a><span>|</span><label class="collapse" for="c-36398161">[-]</label><label class="expand" for="c-36398161">[8 more]</label></div><br/><div class="children"><div class="content">IIRC what you’re describing here is indeed what shipped. All the AVX-512 instructions are available for 128-bit, 256-bit and 512-bit registers (xmm, ymm, zmm).  If not strictly all, essentially all?</div><br/><div id="36398199" class="c"><input type="checkbox" id="c-36398199" checked=""/><div class="controls bullet"><span class="by">moonchild</span><span>|</span><a href="#36397667">root</a><span>|</span><a href="#36398161">parent</a><span>|</span><a href="#36398591">next</a><span>|</span><label class="collapse" for="c-36398199">[-]</label><label class="expand" for="c-36398199">[3 more]</label></div><br/><div class="children"><div class="content">Base avx512, on the first phis, did in fact only work for 512-bit registers (it also used a slightly different encoding).  A later extension is avx512vl (included on all &#x27;normal&#x27; cpus implementing avx512), which adds support for the instructions on smaller vector sizes.  But there is no standard mode which allows the hardware to support the instructions <i>only</i> for 256- or 128-bit registers; they must be supported at least for 512-bit registers or else not at all.</div><br/><div id="36398277" class="c"><input type="checkbox" id="c-36398277" checked=""/><div class="controls bullet"><span class="by">mtklein</span><span>|</span><a href="#36397667">root</a><span>|</span><a href="#36398199">parent</a><span>|</span><a href="#36399065">next</a><span>|</span><label class="collapse" for="c-36398277">[-]</label><label class="expand" for="c-36398277">[1 more]</label></div><br/><div class="children"><div class="content">Oh!  Yeah!  I do forget about “base” avx-512 sometimes.  No one but HPC folks really ever had any proximity to that.  In practice if you’ve got a computer that supports avx-512, it supports VL.</div><br/></div></div><div id="36399065" class="c"><input type="checkbox" id="c-36399065" checked=""/><div class="controls bullet"><span class="by">namibj</span><span>|</span><a href="#36397667">root</a><span>|</span><a href="#36398199">parent</a><span>|</span><a href="#36398277">prev</a><span>|</span><a href="#36398591">next</a><span>|</span><label class="collapse" for="c-36399065">[-]</label><label class="expand" for="c-36399065">[1 more]</label></div><br/><div class="children"><div class="content">You can microcode them on top of high density SRAM if need be.</div><br/></div></div></div></div><div id="36398591" class="c"><input type="checkbox" id="c-36398591" checked=""/><div class="controls bullet"><span class="by">saagarjha</span><span>|</span><a href="#36397667">root</a><span>|</span><a href="#36398161">parent</a><span>|</span><a href="#36398199">prev</a><span>|</span><a href="#36398457">next</a><span>|</span><label class="collapse" for="c-36398591">[-]</label><label class="expand" for="c-36398591">[4 more]</label></div><br/><div class="children"><div class="content">Right, but the issue is you can&#x27;t &quot;just&quot; offer AVX-512 with a 256-bit vector length. You have to also offer the 512-bit options too, which has costs that your processor vendor may not be willing to pay. So you end up only getting AVX2 support.</div><br/><div id="36399142" class="c"><input type="checkbox" id="c-36399142" checked=""/><div class="controls bullet"><span class="by">borissk</span><span>|</span><a href="#36397667">root</a><span>|</span><a href="#36398591">parent</a><span>|</span><a href="#36398457">next</a><span>|</span><label class="collapse" for="c-36399142">[-]</label><label class="expand" for="c-36399142">[3 more]</label></div><br/><div class="children"><div class="content">Hmmm, there are only two desktop processor vendors. Is AVX-512 at all available on mobile?<p>From the two desktop vendors AMD has AVX-512 support on all their AM5 CPUs. Intel has support of AVX-512 on all 11th gen CPUs and on some 12th gen CPUs. The supports is there in the silicon on all P-cores in 12&#x2F;13th gen CPUs, just disabled in microcode.<p>So AMD and Intel have already paid the cost.</div><br/><div id="36400415" class="c"><input type="checkbox" id="c-36400415" checked=""/><div class="controls bullet"><span class="by">adrian_b</span><span>|</span><a href="#36397667">root</a><span>|</span><a href="#36399142">parent</a><span>|</span><a href="#36399667">next</a><span>|</span><label class="collapse" for="c-36400415">[-]</label><label class="expand" for="c-36400415">[1 more]</label></div><br/><div class="children"><div class="content">Previously Intel had AVX-512 support in 3 generations of mobile CPUs, Cannon Lake U, Ice Lake U, Tiger Lake H&#x2F;U, but only the last generation had widespread availability.<p>Starting with Alder Lake, Intel has dropped the AVX-512 support in non-server CPUs.<p>On the other hand, AMD has just launched their Phoenix mobile CPUs (Ryzen x 7x40 HS or U), which have excellent AVX-512 support.</div><br/></div></div><div id="36399667" class="c"><input type="checkbox" id="c-36399667" checked=""/><div class="controls bullet"><span class="by">ben-schaaf</span><span>|</span><a href="#36397667">root</a><span>|</span><a href="#36399142">parent</a><span>|</span><a href="#36400415">prev</a><span>|</span><a href="#36398457">next</a><span>|</span><label class="collapse" for="c-36399667">[-]</label><label class="expand" for="c-36399667">[1 more]</label></div><br/><div class="children"><div class="content">AMD - until AM5 - has not been willing to pay the cost. Intel was not willing to pay the cost for their E-cores. AVX-512 is almost 10 years old at this point and because of adoption issues still can&#x27;t be relied upon.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="36398457" class="c"><input type="checkbox" id="c-36398457" checked=""/><div class="controls bullet"><span class="by">ridiculous_fish</span><span>|</span><a href="#36397667">prev</a><span>|</span><a href="#36398147">next</a><span>|</span><label class="collapse" for="c-36398457">[-]</label><label class="expand" for="c-36398457">[9 more]</label></div><br/><div class="children"><div class="content">VPTERNLOGD is a mouthful but is fun to think about.<p>Notice there are 4 functions mapping 1 bit -&gt; 1 bit: const 0, const 1, copy, invert.<p>There are 16 functions mapping 2 bits -&gt; 1 bit. Think 4 possible inputs, 2 possible output values for each input (0 or 1), so there are 2^4 = 16 such functions.<p>Likewise 256 functions mapping 3 bits -&gt; 1 bit: 8 possible inputs, 2 possible output values for each input, so 2^8 = 256 such functions.<p>This means that the set of functions 3 bits -&gt; 1 bit may be indexed by a single byte! With this instruction, you specify the byte as an immediate, it is interpreted as an index into a function table, and so you get any 3-valued boolean function.<p>I wonder if we&#x27;ll see a similar instruction for 2 bits -&gt; 2 bits? Could be useful!</div><br/><div id="36401398" class="c"><input type="checkbox" id="c-36401398" checked=""/><div class="controls bullet"><span class="by">Tuna-Fish</span><span>|</span><a href="#36398457">parent</a><span>|</span><a href="#36400774">next</a><span>|</span><label class="collapse" for="c-36401398">[-]</label><label class="expand" for="c-36401398">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I wonder if we&#x27;ll see a similar instruction for 2 bits -&gt; 2 bits? Could be useful!<p>No, because the way all modern high-performance CPUs work implies that an instruction with two destinations cannot really be any faster than two instructions with a single destination. So you can implement 3 bits -&gt; 2 bits with two VPTERNLOGDs and can&#x27;t do any better than that for 2 -&gt; 2.</div><br/></div></div><div id="36400774" class="c"><input type="checkbox" id="c-36400774" checked=""/><div class="controls bullet"><span class="by">bonzini</span><span>|</span><a href="#36398457">parent</a><span>|</span><a href="#36401398">prev</a><span>|</span><a href="#36400176">next</a><span>|</span><label class="collapse" for="c-36400774">[-]</label><label class="expand" for="c-36400774">[2 more]</label></div><br/><div class="children"><div class="content">Fun fact, the third byte of the last argument to the Windows BitBlt function describes a 3 bits -&gt; 1 bit function (inputs being source, destination and brush) in exactly this way.<p>However, the two bytes below encode the formula for the function, so that the transfer could be JITted more easily. This is not really necessary, since you could just use 512 bytes for the mapping, but memory tradeoffs were different back then...</div><br/><div id="36401134" class="c"><input type="checkbox" id="c-36401134" checked=""/><div class="controls bullet"><span class="by">unnah</span><span>|</span><a href="#36398457">root</a><span>|</span><a href="#36400774">parent</a><span>|</span><a href="#36400176">next</a><span>|</span><label class="collapse" for="c-36401134">[-]</label><label class="expand" for="c-36401134">[1 more]</label></div><br/><div class="children"><div class="content">It was also how you fed the operation to the Amiga blitter hardware. A nice introduction to minterms for many teenage hackers at the time... (<a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Canonical_normal_form#Minterm" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Canonical_normal_form#Minterm</a>)</div><br/></div></div></div></div><div id="36400176" class="c"><input type="checkbox" id="c-36400176" checked=""/><div class="controls bullet"><span class="by">moonchild</span><span>|</span><a href="#36398457">parent</a><span>|</span><a href="#36400774">prev</a><span>|</span><a href="#36400240">next</a><span>|</span><label class="collapse" for="c-36400176">[-]</label><label class="expand" for="c-36400176">[2 more]</label></div><br/><div class="children"><div class="content">We&#x27;ve seen (+, and) multiply (that&#x27;s just standard multiplication) and (xor, and) multiply (&#x27;carryless multiply&#x27;); it would be interesting to see a carryless multiply where both combining functions are user-controllable.  (See also: &lt;<a href="https:&#x2F;&#x2F;twitter.com&#x2F;moon_chilled&#x2F;status&#x2F;1639829366304821249" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;moon_chilled&#x2F;status&#x2F;1639829366304821249</a>&gt;; I forget why this works, though.)</div><br/><div id="36400273" class="c"><input type="checkbox" id="c-36400273" checked=""/><div class="controls bullet"><span class="by">RaisingSpear</span><span>|</span><a href="#36398457">root</a><span>|</span><a href="#36400176">parent</a><span>|</span><a href="#36400240">next</a><span>|</span><label class="collapse" for="c-36400273">[-]</label><label class="expand" for="c-36400273">[1 more]</label></div><br/><div class="children"><div class="content">You might find this post interesting: <a href="https:&#x2F;&#x2F;bitmath.blogspot.com&#x2F;2023&#x2F;05&#x2F;grevmul.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;bitmath.blogspot.com&#x2F;2023&#x2F;05&#x2F;grevmul.html</a></div><br/></div></div></div></div><div id="36400240" class="c"><input type="checkbox" id="c-36400240" checked=""/><div class="controls bullet"><span class="by">RaisingSpear</span><span>|</span><a href="#36398457">parent</a><span>|</span><a href="#36400176">prev</a><span>|</span><a href="#36398147">next</a><span>|</span><label class="collapse" for="c-36400240">[-]</label><label class="expand" for="c-36400240">[3 more]</label></div><br/><div class="children"><div class="content">&gt; I wonder if we&#x27;ll see a similar instruction for 2 bits -&gt; 2 bits? Could be useful!<p>You don&#x27;t even need to support all 16 functions, as a number are duplicates or could be implemented with others.  The following list covers all possibilities:<p>- AND, OR, XOR [supported basically everywhere]<p>- AND-NOT (a&amp;~b), OR-NOT (a|~b) [sometimes supported]<p>- NOT-AND (~(a&amp;b)), NOT-OR (~(a|b)), NOT-XOR (aka XNOR)<p>So only a few basic instructions need to exist to support all combinations of 2-operand bitwise logic.</div><br/><div id="36400912" class="c"><input type="checkbox" id="c-36400912" checked=""/><div class="controls bullet"><span class="by">bruce343434</span><span>|</span><a href="#36398457">root</a><span>|</span><a href="#36400240">parent</a><span>|</span><a href="#36400474">next</a><span>|</span><label class="collapse" for="c-36400912">[-]</label><label class="expand" for="c-36400912">[1 more]</label></div><br/><div class="children"><div class="content">Lisp has all 16!<p><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=32802308">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=32802308</a></div><br/></div></div><div id="36400474" class="c"><input type="checkbox" id="c-36400474" checked=""/><div class="controls bullet"><span class="by">adrian_b</span><span>|</span><a href="#36398457">root</a><span>|</span><a href="#36400240">parent</a><span>|</span><a href="#36400912">prev</a><span>|</span><a href="#36398147">next</a><span>|</span><label class="collapse" for="c-36400474">[-]</label><label class="expand" for="c-36400474">[1 more]</label></div><br/><div class="children"><div class="content">That is why the IBM POWER ISA includes only the 8 of the 16 functions of 2 Boolean variables that cannot be obtained from the others by reversing the operand order or by using for both operands the same register (which is enough to obtain the maximum instruction count reduction in comparison with the ISAs that only include AND&#x2F;OR&#x2F;XOR).</div><br/></div></div></div></div></div></div><div id="36398147" class="c"><input type="checkbox" id="c-36398147" checked=""/><div class="controls bullet"><span class="by">mattst88</span><span>|</span><a href="#36398457">prev</a><span>|</span><a href="#36397986">next</a><span>|</span><label class="collapse" for="c-36398147">[-]</label><label class="expand" for="c-36398147">[16 more]</label></div><br/><div class="children"><div class="content">I am a happy owner of a Tigerlake (Intel 11th Gen) Framework laptop. I&#x27;ve considered upgrading to a 12th or 13th Gen motherboard, and while I have no doubt they&#x27;d be great for me as a Gentoo developer with the greatly increased core counts, my hesitation is that the new CPUs have AVX-512 disabled.<p>Maybe this doesn&#x27;t matter, almost certainly wouldn&#x27;t for most people, but I&#x27;m compiling the whole system myself so the compiler at least has the freedom to use AVX-512 wherever it pleases. Does anyone know if AVX-512 actually makes a difference in workloads that aren&#x27;t specifically tuned for it?<p>My guess is that given news like <a href="https:&#x2F;&#x2F;www.phoronix.com&#x2F;news&#x2F;GCC-AVX-512-Fully-Masked-Vector" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.phoronix.com&#x2F;news&#x2F;GCC-AVX-512-Fully-Masked-Vecto...</a> that compilers basically don&#x27;t do anything interesting with AVX-512 without hand-written code.</div><br/><div id="36398253" class="c"><input type="checkbox" id="c-36398253" checked=""/><div class="controls bullet"><span class="by">mtklein</span><span>|</span><a href="#36398147">parent</a><span>|</span><a href="#36400577">next</a><span>|</span><label class="collapse" for="c-36398253">[-]</label><label class="expand" for="c-36398253">[1 more]</label></div><br/><div class="children"><div class="content">The promise of the AVX-512 instruction set really was that it would be much easier to (auto-)vectorize code that wasn’t written with vectorization in mind, with tools like masked execution and gather&#x2F;scatter that either didn’t exist at all before (SSE) or were very minimal (AVX).<p>The tools are there in the instruction set, but that still leaves the issues of time and effort to implement in compilers, and enough performance improvement on enough machines in some market (browsers, games, etc) capable of running it all before any of this possibility becomes real.<p>The skylake-xeon&#x2F;icelake false start here really can’t have helped.  It’s still a much more pragmatic thing to target the haswell feature set that all the intel chips and most amd chips can run (and run well).</div><br/></div></div><div id="36400577" class="c"><input type="checkbox" id="c-36400577" checked=""/><div class="controls bullet"><span class="by">adrian_b</span><span>|</span><a href="#36398147">parent</a><span>|</span><a href="#36398253">prev</a><span>|</span><a href="#36398628">next</a><span>|</span><label class="collapse" for="c-36400577">[-]</label><label class="expand" for="c-36400577">[1 more]</label></div><br/><div class="children"><div class="content">Now you may choose a new AMD Phoenix-based laptop, with great AVX-512 support (e.g. with Ryzen 7 7840HS or Ryzen 9 7940HS or Ryzen 7 7840U).<p>AMD Phoenix is far better than any current Intel mobile CPU anyway, so it is an easy choice (and it compiles code much faster than Intel Raptor Lake, which counts for a Gentoo user or developer).<p>The only reason to not choose an AMD Phoenix for an upgrade would be to wait for an Intel Meteor Lake a.k.a. Intel Core Ultra. Meteor Lake will be faster in single-thread (the relative performance in multi-thread is unknown) and it will have a bigger GPU (with 1024 FP32 ALUs vs. 768 for AMD).<p>However, Meteor Lake will not have AVX-512 support.<p>For compiling code, the AVX-512 support should not matter, but it should matter a lot for the code generated by the compiler, as it enables the efficient auto-vectorization of many loops that cannot be vectorized efficiently with AVX2.<p>While gcc and clang will never be as smart as hand-written code, their automatic use of AVX-512 can be improved a lot and announcements like that linked by you show progress in this direction.</div><br/></div></div><div id="36398628" class="c"><input type="checkbox" id="c-36398628" checked=""/><div class="controls bullet"><span class="by">johnklos</span><span>|</span><a href="#36398147">parent</a><span>|</span><a href="#36400577">prev</a><span>|</span><a href="#36398878">next</a><span>|</span><label class="collapse" for="c-36398628">[-]</label><label class="expand" for="c-36398628">[1 more]</label></div><br/><div class="children"><div class="content">Funny that if you want AVX-512 now, it&#x27;s AMD that&#x27;s offering it and Intel that isn&#x27;t.<p>Sometimes the second comer to a game has the advantage of taking their time to implement something, with fewer compromises and a better overall fit.</div><br/></div></div><div id="36398878" class="c"><input type="checkbox" id="c-36398878" checked=""/><div class="controls bullet"><span class="by">jeffbee</span><span>|</span><a href="#36398147">parent</a><span>|</span><a href="#36398628">prev</a><span>|</span><a href="#36399734">next</a><span>|</span><label class="collapse" for="c-36398878">[-]</label><label class="expand" for="c-36398878">[6 more]</label></div><br/><div class="children"><div class="content">The compiler will only choose to use AVX-512 if you give it the right `-m` flags. Most people who are running generic distros that target the basic k8 instructions benefit from AVX-512 only when some library has runtime dispatch that detects the presence of the feature and enables optimized routines. This is common in, for example, cryptography libraries.</div><br/><div id="36399357" class="c"><input type="checkbox" id="c-36399357" checked=""/><div class="controls bullet"><span class="by">mattst88</span><span>|</span><a href="#36398147">root</a><span>|</span><a href="#36398878">parent</a><span>|</span><a href="#36399734">next</a><span>|</span><label class="collapse" for="c-36399357">[-]</label><label class="expand" for="c-36399357">[5 more]</label></div><br/><div class="children"><div class="content">Right. Since I&#x27;m using Gentoo and compiling my whole system with `-march=tigerlake`, the compiler is free to use AVX-512.<p>My question is just... does it? (And does it use AVX-512 profitably?)</div><br/><div id="36401350" class="c"><input type="checkbox" id="c-36401350" checked=""/><div class="controls bullet"><span class="by">nwallin</span><span>|</span><a href="#36398147">root</a><span>|</span><a href="#36399357">parent</a><span>|</span><a href="#36401170">next</a><span>|</span><label class="collapse" for="c-36401350">[-]</label><label class="expand" for="c-36401350">[1 more]</label></div><br/><div class="children"><div class="content">It will not use AVX-512 if you have CFLAGS=&quot;-march=tigerlake -O2&quot;. You will, at the very least, need CFLAGS=&quot;-march=tigerlake -O3&quot; to get it to actually use AVX2, and tigerlake&#x27;s AVX512 implementation is so poor (clock throttling etc) that gcc will not use AVX-512 on tigerlake. AVX-512 is used if you have -march=znver4 though, so the support for autovectorizing to AVX-512 is clearly there.<p><a href="https:&#x2F;&#x2F;godbolt.org&#x2F;z&#x2F;1a39Mf3bv" rel="nofollow noreferrer">https:&#x2F;&#x2F;godbolt.org&#x2F;z&#x2F;1a39Mf3bv</a></div><br/></div></div><div id="36401170" class="c"><input type="checkbox" id="c-36401170" checked=""/><div class="controls bullet"><span class="by">secondcoming</span><span>|</span><a href="#36398147">root</a><span>|</span><a href="#36399357">parent</a><span>|</span><a href="#36401350">prev</a><span>|</span><a href="#36400120">next</a><span>|</span><label class="collapse" for="c-36401170">[-]</label><label class="expand" for="c-36401170">[1 more]</label></div><br/><div class="children"><div class="content">In my experience it depends on the compiler. clang seems far more willing to autovectorise than gcc. Also, when writing the code you have to write it in a way that strongly hints to the compiler that it can be autovectorised. So lots of handholding.</div><br/></div></div><div id="36400120" class="c"><input type="checkbox" id="c-36400120" checked=""/><div class="controls bullet"><span class="by">oconnor663</span><span>|</span><a href="#36398147">root</a><span>|</span><a href="#36399357">parent</a><span>|</span><a href="#36401170">prev</a><span>|</span><a href="#36399734">next</a><span>|</span><label class="collapse" for="c-36400120">[-]</label><label class="expand" for="c-36400120">[2 more]</label></div><br/><div class="children"><div class="content">Why not use -march=native?</div><br/><div id="36400440" class="c"><input type="checkbox" id="c-36400440" checked=""/><div class="controls bullet"><span class="by">aew4ytasghe5</span><span>|</span><a href="#36398147">root</a><span>|</span><a href="#36400120">parent</a><span>|</span><a href="#36399734">next</a><span>|</span><label class="collapse" for="c-36400440">[-]</label><label class="expand" for="c-36400440">[1 more]</label></div><br/><div class="children"><div class="content">Why not use -march=snark?</div><br/></div></div></div></div></div></div></div></div><div id="36399734" class="c"><input type="checkbox" id="c-36399734" checked=""/><div class="controls bullet"><span class="by">PragmaticPulp</span><span>|</span><a href="#36398147">parent</a><span>|</span><a href="#36398878">prev</a><span>|</span><a href="#36398189">next</a><span>|</span><label class="collapse" for="c-36399734">[-]</label><label class="expand" for="c-36399734">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I&#x27;ve considered upgrading to a 12th or 13th Gen motherboard, and while I have no doubt they&#x27;d be great for me as a Gentoo developer with the greatly increased core counts, my hesitation is that the new CPUs have AVX-512 disabled.<p>Unless you have a very specific AVX-512 workload or you need to run AVX-512 code for local testing, you won’t see any net benefit of keeping your older AVX-512 part.<p>Newer parts will have higher clock speed and better performance that will benefit you everywhere. Skipping that for the possibility of maybe having some workload in the future where AVX-512 might help is a net loss.</div><br/></div></div><div id="36398189" class="c"><input type="checkbox" id="c-36398189" checked=""/><div class="controls bullet"><span class="by">causality0</span><span>|</span><a href="#36398147">parent</a><span>|</span><a href="#36399734">prev</a><span>|</span><a href="#36397986">next</a><span>|</span><label class="collapse" for="c-36398189">[-]</label><label class="expand" for="c-36398189">[5 more]</label></div><br/><div class="children"><div class="content"><i>Does anyone know if AVX-512 actually makes a difference in workloads that aren&#x27;t specifically tuned for it?</i><p>I know game console emulators use it to great effect with significant performance increases.</div><br/><div id="36398212" class="c"><input type="checkbox" id="c-36398212" checked=""/><div class="controls bullet"><span class="by">jsheard</span><span>|</span><a href="#36398147">root</a><span>|</span><a href="#36398189">parent</a><span>|</span><a href="#36398645">next</a><span>|</span><label class="collapse" for="c-36398212">[-]</label><label class="expand" for="c-36398212">[3 more]</label></div><br/><div class="children"><div class="content">Incidentally that&#x27;s another case where the 512bit-ness is the least interesting part, the new instructions are useful for efficiently emulating ARM NEON (Switch) and Cell SPU (Playstation 3) code but those platforms are themselves only 128bits wide so I don&#x27;t believe the emulators have any use for the 512bit (or even 256bit?) variants of the AVX512 instructions.</div><br/><div id="36398635" class="c"><input type="checkbox" id="c-36398635" checked=""/><div class="controls bullet"><span class="by">tarnith</span><span>|</span><a href="#36398147">root</a><span>|</span><a href="#36398212">parent</a><span>|</span><a href="#36400451">next</a><span>|</span><label class="collapse" for="c-36398635">[-]</label><label class="expand" for="c-36398635">[1 more]</label></div><br/><div class="children"><div class="content">I haven&#x27;t looked into the code for these but are they possibly pipelining multiple ops per clock? If it&#x27;s not dependency chained they probably calculate a few cycles at once.</div><br/></div></div><div id="36400451" class="c"><input type="checkbox" id="c-36400451" checked=""/><div class="controls bullet"><span class="by">aew4ytasghe5</span><span>|</span><a href="#36398147">root</a><span>|</span><a href="#36398212">parent</a><span>|</span><a href="#36398635">prev</a><span>|</span><a href="#36398645">next</a><span>|</span><label class="collapse" for="c-36400451">[-]</label><label class="expand" for="c-36400451">[1 more]</label></div><br/><div class="children"><div class="content">Specifically RPCS3 had a huge speedup using AVX-512 [1]<p>1: <a href="https:&#x2F;&#x2F;www.tomshardware.com&#x2F;news&#x2F;ps3-emulation-i9-12900k-vs-i9-11900k" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.tomshardware.com&#x2F;news&#x2F;ps3-emulation-i9-12900k-vs...</a></div><br/></div></div></div></div><div id="36398645" class="c"><input type="checkbox" id="c-36398645" checked=""/><div class="controls bullet"><span class="by">saagarjha</span><span>|</span><a href="#36398147">root</a><span>|</span><a href="#36398189">parent</a><span>|</span><a href="#36398212">prev</a><span>|</span><a href="#36397986">next</a><span>|</span><label class="collapse" for="c-36398645">[-]</label><label class="expand" for="c-36398645">[1 more]</label></div><br/><div class="children"><div class="content">Game console emulators are of course specifically tuned for this.</div><br/></div></div></div></div></div></div><div id="36397986" class="c"><input type="checkbox" id="c-36397986" checked=""/><div class="controls bullet"><span class="by">inopinatus</span><span>|</span><a href="#36398147">prev</a><span>|</span><a href="#36397706">next</a><span>|</span><label class="collapse" for="c-36397986">[-]</label><label class="expand" for="c-36397986">[8 more]</label></div><br/><div class="children"><div class="content">The masked variants of most operations are a killer AVX-512 feature for me.  Vectorised conditional execution was&#x2F;is the last piece of the puzzle.<p>It baffles me that clang in particular disregards them. Clang’s intrinsics and builtins generally use the unmasked forms and fake it with subsequent combining operations. This always benchmarks slower in loops, and often demands an extra register. I haven’t delved deeply, but it feels like either the cost model is mispredicting potential k-register bottleneck, or it doesn’t know about masked AVX-512 instructions at all. In comparison, GCC does, but it falls down (on my code at least) in needing more explicit vectorisation than clang.</div><br/><div id="36398185" class="c"><input type="checkbox" id="c-36398185" checked=""/><div class="controls bullet"><span class="by">brigade</span><span>|</span><a href="#36397986">parent</a><span>|</span><a href="#36397706">next</a><span>|</span><label class="collapse" for="c-36398185">[-]</label><label class="expand" for="c-36398185">[7 more]</label></div><br/><div class="children"><div class="content">&gt; This always benchmarks slower in loops<p>Really? It&#x27;s a forced read-write dependency on the destination register. Which makes sense for cores with limited superscalar. But for ops with &gt;1 cycle latency or &gt;1&#x2F;cycle throughput, chained masks are likely to inhibit ILP and be slower...</div><br/><div id="36398469" class="c"><input type="checkbox" id="c-36398469" checked=""/><div class="controls bullet"><span class="by">sparkie</span><span>|</span><a href="#36397986">root</a><span>|</span><a href="#36398185">parent</a><span>|</span><a href="#36398524">next</a><span>|</span><label class="collapse" for="c-36398469">[-]</label><label class="expand" for="c-36398469">[3 more]</label></div><br/><div class="children"><div class="content">A big benefit comes from having branchless code. For example, if you have an if&#x2F;else statement where the consequent acts on some elements of the vector and the antecedent acts on the others, you can perform them all with no branch, by taking the mask resulting from the condition for the consequent instructions, then complementing the mask and applying the antecedent to the same registers. This can also have predictable performance, because all instructions from the consequent and antecedent are executed each time, and there are no branch prediction misses to worry about. It&#x27;s very useful for timing sensitive code (cryptography), and situations where you want a measurable WCET.</div><br/><div id="36399967" class="c"><input type="checkbox" id="c-36399967" checked=""/><div class="controls bullet"><span class="by">inopinatus</span><span>|</span><a href="#36397986">root</a><span>|</span><a href="#36398469">parent</a><span>|</span><a href="#36398608">next</a><span>|</span><label class="collapse" for="c-36399967">[-]</label><label class="expand" for="c-36399967">[1 more]</label></div><br/><div class="children"><div class="content">It is possible that even masked vectorised branchless code is susceptible to side-channel attacks based on power consumption, nor would I rule
out timing attacks if you can somehow get subnormal or exceptional values loaded. Is it a joy to code in this style? Perhaps. Is it a silver bullet? It is not.</div><br/></div></div><div id="36398608" class="c"><input type="checkbox" id="c-36398608" checked=""/><div class="controls bullet"><span class="by">brigade</span><span>|</span><a href="#36397986">root</a><span>|</span><a href="#36398469">parent</a><span>|</span><a href="#36399967">prev</a><span>|</span><a href="#36398524">next</a><span>|</span><label class="collapse" for="c-36398608">[-]</label><label class="expand" for="c-36398608">[1 more]</label></div><br/><div class="children"><div class="content">Masked instructions vs subsequent merging are both branchless and have no implicit data-dependent timing relative to each other.</div><br/></div></div></div></div><div id="36398524" class="c"><input type="checkbox" id="c-36398524" checked=""/><div class="controls bullet"><span class="by">colejohnson66</span><span>|</span><a href="#36397986">root</a><span>|</span><a href="#36398185">parent</a><span>|</span><a href="#36398469">prev</a><span>|</span><a href="#36397706">next</a><span>|</span><label class="collapse" for="c-36398524">[-]</label><label class="expand" for="c-36398524">[3 more]</label></div><br/><div class="children"><div class="content">Mask with zeroing would solve that. The EVEX prefix supports both merge and zero masking.</div><br/><div id="36398615" class="c"><input type="checkbox" id="c-36398615" checked=""/><div class="controls bullet"><span class="by">brigade</span><span>|</span><a href="#36397986">root</a><span>|</span><a href="#36398524">parent</a><span>|</span><a href="#36397706">next</a><span>|</span><label class="collapse" for="c-36398615">[-]</label><label class="expand" for="c-36398615">[2 more]</label></div><br/><div class="children"><div class="content">All that solves is changing the merging instruction from a masked merge to a maskless OR.</div><br/></div></div></div></div></div></div></div></div><div id="36397706" class="c"><input type="checkbox" id="c-36397706" checked=""/><div class="controls bullet"><span class="by">celeritascelery</span><span>|</span><a href="#36397986">prev</a><span>|</span><a href="#36397782">next</a><span>|</span><label class="collapse" for="c-36397706">[-]</label><label class="expand" for="c-36397706">[7 more]</label></div><br/><div class="children"><div class="content">Fascinating. I wonder why intel never released “AVX256”. Was it to drive adoption of their new extra wide SIMD hardware? Do the extra instructions add a lot of complexity outside of just the increased register size?<p>Either way I recently had to write a SIMD implementation in both SSE (Intel) and Neon (Arm). This was my first time writing SIMD. I found the neon instruction set much more intuitive and complete than SSE. There are all these weird limitations in SSE (such as trying to do a reduction sum across a vector or shifting across vectors) that made it feel incomplete. Never had a chance to try out AVX.</div><br/><div id="36401341" class="c"><input type="checkbox" id="c-36401341" checked=""/><div class="controls bullet"><span class="by">janwas</span><span>|</span><a href="#36397706">parent</a><span>|</span><a href="#36397857">next</a><span>|</span><label class="collapse" for="c-36401341">[-]</label><label class="expand" for="c-36401341">[1 more]</label></div><br/><div class="children"><div class="content">Cool that you started with SIMD :)
FYI github.com&#x2F;google&#x2F;highway allows you to write your code once and target many instruction sets. It also fills in many of the gaps, including reductions.<p>Disclosure: I am the main author.</div><br/></div></div><div id="36397857" class="c"><input type="checkbox" id="c-36397857" checked=""/><div class="controls bullet"><span class="by">jsheard</span><span>|</span><a href="#36397706">parent</a><span>|</span><a href="#36401341">prev</a><span>|</span><a href="#36400356">next</a><span>|</span><label class="collapse" for="c-36397857">[-]</label><label class="expand" for="c-36397857">[4 more]</label></div><br/><div class="children"><div class="content">That was around the time when Intel was struggling to get 10nm out of the door, when they were designing AVX512 it might have seemed that the initial implementation on 14nm was just a stop-gap and it would be more practical to implement such wide units on the next process that&#x27;s <i>just around the corner,</i> but little did they know they would end up running in circles rehashing Skylake&#x2F;14nm for the next six years while they waited for 10nm to finally come online. If they had known things would go that way, perhaps they would have done &quot;AVX256&quot;.</div><br/><div id="36398511" class="c"><input type="checkbox" id="c-36398511" checked=""/><div class="controls bullet"><span class="by">dopa42365</span><span>|</span><a href="#36397706">root</a><span>|</span><a href="#36397857">parent</a><span>|</span><a href="#36397922">next</a><span>|</span><label class="collapse" for="c-36398511">[-]</label><label class="expand" for="c-36398511">[2 more]</label></div><br/><div class="children"><div class="content">&gt;10nm<p>aka 10nm Enhanced SuperFin aka Intel 7 (12000 and 13000 series)<p>Which funnily enough don&#x27;t support AVX512, unlike the previous 10000 (14nm++) and 11000 (14nm+++) series.</div><br/><div id="36398527" class="c"><input type="checkbox" id="c-36398527" checked=""/><div class="controls bullet"><span class="by">jsheard</span><span>|</span><a href="#36397706">root</a><span>|</span><a href="#36398511">parent</a><span>|</span><a href="#36397922">next</a><span>|</span><label class="collapse" for="c-36398527">[-]</label><label class="expand" for="c-36398527">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s a whole other mess, the 12th and 13th gen P-core design <i>does</i> technically support AVX512 but the smaller E-cores don&#x27;t, and rather than try to reconcile that mismatch in software they just disabled AVX512 altogether to make the cores all behave the same. If they hadn&#x27;t decided to implement E-cores then 12th&#x2F;13th gen would have had AVX512 support.<p>Some motherboards allowed you to enable AVX512 on those chips if you disabled the E-cores, but then Intel started permanently fusing off AVX512 in hardware on later batches.</div><br/></div></div></div></div><div id="36397922" class="c"><input type="checkbox" id="c-36397922" checked=""/><div class="controls bullet"><span class="by">moonchild</span><span>|</span><a href="#36397706">root</a><span>|</span><a href="#36397857">parent</a><span>|</span><a href="#36398511">prev</a><span>|</span><a href="#36400356">next</a><span>|</span><label class="collapse" for="c-36397922">[-]</label><label class="expand" for="c-36397922">[1 more]</label></div><br/><div class="children"><div class="content">Indeed, and to add on to this, I suspect that they had their own plans about where to take the client space in general, which involved more avx512 (which a couple of generations prior to alderlake supported!), but depended on their having a near-monopoly.  The competitiveness of zen forced them to pivot, and avx512 fell to the wayside, largely because of its lack of users (which in turn is in large part because no one really cares about performance on clients).</div><br/></div></div></div></div><div id="36400356" class="c"><input type="checkbox" id="c-36400356" checked=""/><div class="controls bullet"><span class="by">RaisingSpear</span><span>|</span><a href="#36397706">parent</a><span>|</span><a href="#36397857">prev</a><span>|</span><a href="#36397782">next</a><span>|</span><label class="collapse" for="c-36400356">[-]</label><label class="expand" for="c-36400356">[1 more]</label></div><br/><div class="children"><div class="content">Intel kinda messed up the ISA by requiring AVX-512F across all AVX-512 subsets.  If AVX-512VL didn&#x27;t depend on F, you could have a 256-bit only variant of &quot;AVX-512&quot;.<p>(and instead of making a new feature that allows VL without F, Intel&#x27;s &quot;solution&quot; seems to be about piecemeal backporting EVEX instructions to VEX (e.g. VNNI, IFMA))<p>NEON is generally a more &quot;complete&quot; SIMD ISA than SSE&#x2F;AVX, though it has less &quot;fancy&quot; stuff.  AVX-512 fills in a bunch of gaps that was missing in earlier ISAs, but still has odd omissions (like no 8-bit bitwise shift).</div><br/></div></div></div></div><div id="36397782" class="c"><input type="checkbox" id="c-36397782" checked=""/><div class="controls bullet"><span class="by">dan-robertson</span><span>|</span><a href="#36397706">prev</a><span>|</span><a href="#36400919">next</a><span>|</span><label class="collapse" for="c-36397782">[-]</label><label class="expand" for="c-36397782">[1 more]</label></div><br/><div class="children"><div class="content">I never thought that just the registers for AVX-512 were so large compared to L1. (Though some newer chips have 48kb instead of 32). But I think I’m mostly surprised because I hadn’t thought of the size of the register file (which is comparable) when considering renaming.<p>Some interesting replies too, eg <a href="https:&#x2F;&#x2F;mastodon.gamedev.place&#x2F;@TomF&#x2F;110572967731705754" rel="nofollow noreferrer">https:&#x2F;&#x2F;mastodon.gamedev.place&#x2F;@TomF&#x2F;110572967731705754</a><p>A story I would have believed was that the instruction set was designed with some useful seeming instructions and a hope that compilers would improve. But it sounds like it was designed much more closely with actual example programs and a compiler, just not the kind that attempts to vectorise scalar code.</div><br/></div></div><div id="36400919" class="c"><input type="checkbox" id="c-36400919" checked=""/><div class="controls bullet"><span class="by">rwmj</span><span>|</span><a href="#36397782">prev</a><span>|</span><a href="#36398345">next</a><span>|</span><label class="collapse" for="c-36400919">[-]</label><label class="expand" for="c-36400919">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a little annoying that valgrind doesn&#x27;t support AVX-512 still (since patches were first posted in 2017).  We like to test our binaries using valgrind, so need to compile everything with -mno-avx512f.<p><a href="https:&#x2F;&#x2F;bugs.kde.org&#x2F;show_bug.cgi?id=383010" rel="nofollow noreferrer">https:&#x2F;&#x2F;bugs.kde.org&#x2F;show_bug.cgi?id=383010</a></div><br/></div></div><div id="36398345" class="c"><input type="checkbox" id="c-36398345" checked=""/><div class="controls bullet"><span class="by">lifthrasiir</span><span>|</span><a href="#36400919">prev</a><span>|</span><a href="#36397732">next</a><span>|</span><label class="collapse" for="c-36398345">[-]</label><label class="expand" for="c-36398345">[1 more]</label></div><br/><div class="children"><div class="content">AVX-512F also introduced an embedded rounding and exception control in the instruction itself, which was a great pain for everyone doing accurate maths (e.g. interval arithmetic). It&#x27;s a great shame that Intel made all good bits of AVX-512 a hostage to the less important 512-bit vector width.</div><br/></div></div><div id="36397732" class="c"><input type="checkbox" id="c-36397732" checked=""/><div class="controls bullet"><span class="by">crest</span><span>|</span><a href="#36398345">prev</a><span>|</span><a href="#36397997">next</a><span>|</span><label class="collapse" for="c-36397732">[-]</label><label class="expand" for="c-36397732">[1 more]</label></div><br/><div class="children"><div class="content">Didn&#x27;t some of the DEC Alpha and IBM Power designs use a cached register-file for lack of a better terminology. Allowing them to support more architectural state than the wide multi-ported register file could fit? Would a small double&#x2F;quad pumped AVX-512 implementation with a dual ported register file + caching&#x2F;queuing the recently produced results at the functional units that produced them safe die size and still allow useful throughput?</div><br/></div></div><div id="36397997" class="c"><input type="checkbox" id="c-36397997" checked=""/><div class="controls bullet"><span class="by">bee_rider</span><span>|</span><a href="#36397732">prev</a><span>|</span><a href="#36398115">next</a><span>|</span><label class="collapse" for="c-36397997">[-]</label><label class="expand" for="c-36397997">[5 more]</label></div><br/><div class="children"><div class="content">&gt; This, combined with the 512b vectors that are the &quot;-512&quot; part, quadruples the amount of architectural FP&#x2F;SIMD state, which is one of the main reasons we _don&#x27;t_ get any AVX-512 in the &quot;small&quot; cores.<p>That’s an interesting point. Does anyone know—the Knights Landing Phi had AVX-512 and was based on Atom cores. Did they bolt on all these extra registers?</div><br/><div id="36401255" class="c"><input type="checkbox" id="c-36401255" checked=""/><div class="controls bullet"><span class="by">detaro</span><span>|</span><a href="#36397997">parent</a><span>|</span><a href="#36399075">next</a><span>|</span><label class="collapse" for="c-36401255">[-]</label><label class="expand" for="c-36401255">[1 more]</label></div><br/><div class="children"><div class="content">All variants of Phi were quite small&#x2F;simple cores (I think the early ones were derivatives of early Pentium designs(!), just lots of them in more modern processes) with massive vector units strapped to the side. Which was fine for that purpose, since they really only were intended to feed the vector units and not expected to be any good at general-purpose computing tasks.</div><br/></div></div><div id="36399075" class="c"><input type="checkbox" id="c-36399075" checked=""/><div class="controls bullet"><span class="by">Dylan16807</span><span>|</span><a href="#36397997">parent</a><span>|</span><a href="#36401255">prev</a><span>|</span><a href="#36398175">next</a><span>|</span><label class="collapse" for="c-36399075">[-]</label><label class="expand" for="c-36399075">[1 more]</label></div><br/><div class="children"><div class="content">Note that quadrupling the architectural state doesn&#x27;t mean quadrupling the actual state.<p>In fact, it looks like Haswell and Skylake-X had the <i>same</i> number of physical registers, 168.  So that&#x27;s a straightforward doubling from 256x168 to 512x168.<p>But further into the thread it looks like the first gen E cores had about 200 <i>128-bit</i> register lines, so trying to fit 512x32 would have been very tight.<p>To put some of that a different way: The vector design headed for E cores was 128 bits stretching to 256 bits.  If it had been 256 bits all the way through, it&#x27;s likely they would have added AVX-512 support, even if they couldn&#x27;t increase the size of the register file at all.</div><br/></div></div><div id="36398175" class="c"><input type="checkbox" id="c-36398175" checked=""/><div class="controls bullet"><span class="by">moonchild</span><span>|</span><a href="#36397997">parent</a><span>|</span><a href="#36399075">prev</a><span>|</span><a href="#36399103">next</a><span>|</span><label class="collapse" for="c-36398175">[-]</label><label class="expand" for="c-36398175">[1 more]</label></div><br/><div class="children"><div class="content">Yes.  Phi was a massive vector processor bolted onto a tiny scalar processor.  This seems to have worked pretty well, for what it was.  But it wouldn&#x27;t be suitable for the applications where intel is using gracemont, because client workloads tend not to use avx512.</div><br/></div></div><div id="36399103" class="c"><input type="checkbox" id="c-36399103" checked=""/><div class="controls bullet"><span class="by">namibj</span><span>|</span><a href="#36397997">parent</a><span>|</span><a href="#36398175">prev</a><span>|</span><a href="#36398115">next</a><span>|</span><label class="collapse" for="c-36399103">[-]</label><label class="expand" for="c-36399103">[1 more]</label></div><br/><div class="children"><div class="content">They actually separated architectural registers from physical ones, due to being SMT4.<p>There&#x27;s a chips and cheese article on this.</div><br/></div></div></div></div><div id="36398115" class="c"><input type="checkbox" id="c-36398115" checked=""/><div class="controls bullet"><span class="by">gnu8</span><span>|</span><a href="#36397997">prev</a><span>|</span><label class="collapse" for="c-36398115">[-]</label><label class="expand" for="c-36398115">[7 more]</label></div><br/><div class="children"><div class="content">&gt; * VPTERNLOGD (your swiss army railgun for bitwise logic, can often fuse 2 or even 3 ops into one)<p>I wonder if this would be useful for implementing cryptographic algorithms.</div><br/><div id="36398367" class="c"><input type="checkbox" id="c-36398367" checked=""/><div class="controls bullet"><span class="by">sparkie</span><span>|</span><a href="#36398115">parent</a><span>|</span><a href="#36400375">next</a><span>|</span><label class="collapse" for="c-36398367">[-]</label><label class="expand" for="c-36398367">[4 more]</label></div><br/><div class="children"><div class="content">I doubt it would be much use as cryptographic operations tend to mainly use xor on two inputs.<p>VPTERNLOGD basically works by constructing a truth table for 3 inputs.<p><pre><code>    | A | B | C |  R
    | 0 | 0 | 0 |  x
    | 0 | 0 | 1 |  x
    | 0 | 1 | 0 |  x
    | 0 | 1 | 1 |  x
    | 1 | 0 | 0 |  x
    | 1 | 0 | 1 |  x
    | 1 | 1 | 0 |  x
    | 1 | 1 | 1 |  x
</code></pre>
You pick the values you want for R, then pass this 8-bit value as the operand to the instruction along with the 3 values.<p>For example, A ∧ B ∧ C would be 0b10000000. A ∧ ¬B ∧ ¬C would be 0xb00010000<p>There are 256 such tables and many of them can be represented by multiple boolean expressions.</div><br/><div id="36399010" class="c"><input type="checkbox" id="c-36399010" checked=""/><div class="controls bullet"><span class="by">mmozeiko</span><span>|</span><a href="#36398115">root</a><span>|</span><a href="#36398367">parent</a><span>|</span><a href="#36398898">next</a><span>|</span><label class="collapse" for="c-36399010">[-]</label><label class="expand" for="c-36399010">[1 more]</label></div><br/><div class="children"><div class="content">Here&#x27;s a fancy trick from LLVM source: <a href="https:&#x2F;&#x2F;github.com&#x2F;llvm&#x2F;llvm-project&#x2F;blob&#x2F;main&#x2F;llvm&#x2F;lib&#x2F;Target&#x2F;X86&#x2F;X86ISelDAGToDAG.cpp#L4397-L4401">https:&#x2F;&#x2F;github.com&#x2F;llvm&#x2F;llvm-project&#x2F;blob&#x2F;main&#x2F;llvm&#x2F;lib&#x2F;Targ...</a><p><pre><code>  #define A 0xf0
  #define B 0xcc
  #define C 0xaa
</code></pre>
And then you can build immediate for VPTERNLOG operation by writing bitwise expression with A&#x2F;B&#x2F;C values in source code.<p>For example, A^B^C=150. A^(~B&amp;C)=210. And so on...<p>Also mentioned by Fabian here: <a href="https:&#x2F;&#x2F;twitter.com&#x2F;rygorous&#x2F;status&#x2F;1187032693944410114" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;rygorous&#x2F;status&#x2F;1187032693944410114</a></div><br/></div></div><div id="36398898" class="c"><input type="checkbox" id="c-36398898" checked=""/><div class="controls bullet"><span class="by">addaon</span><span>|</span><a href="#36398115">root</a><span>|</span><a href="#36398367">parent</a><span>|</span><a href="#36399010">prev</a><span>|</span><a href="#36398553">next</a><span>|</span><label class="collapse" for="c-36398898">[-]</label><label class="expand" for="c-36398898">[1 more]</label></div><br/><div class="children"><div class="content">This is basically the same way as the basic primitive of an FPGA, a LUT (look-up table) works. It&#x27;s a small ROM or RAM of size 2^N x 1, that is looked up by the N-bit &quot;address&quot; of the inputs. Modern FPGAs tend to use N=4 to N=6, with some additional fanciness occasionally present to make the up-to-64-bits of ROM&#x2F;RAM useful in other ways as well.</div><br/></div></div><div id="36398553" class="c"><input type="checkbox" id="c-36398553" checked=""/><div class="controls bullet"><span class="by">marssaxman</span><span>|</span><a href="#36398115">root</a><span>|</span><a href="#36398367">parent</a><span>|</span><a href="#36398898">prev</a><span>|</span><a href="#36400375">next</a><span>|</span><label class="collapse" for="c-36398553">[-]</label><label class="expand" for="c-36398553">[1 more]</label></div><br/><div class="children"><div class="content">That is <i>delightful</i>. Thanks for explaining it so clearly.</div><br/></div></div></div></div><div id="36400375" class="c"><input type="checkbox" id="c-36400375" checked=""/><div class="controls bullet"><span class="by">Nyan</span><span>|</span><a href="#36398115">parent</a><span>|</span><a href="#36398367">prev</a><span>|</span><a href="#36399138">next</a><span>|</span><label class="collapse" for="c-36400375">[-]</label><label class="expand" for="c-36400375">[1 more]</label></div><br/><div class="children"><div class="content">Very useful. In fact, it speeds up a <i>single instance</i> (i.e. not taking advantage of SIMD) of MD5 by 20%: <a href="https:&#x2F;&#x2F;github.com&#x2F;animetosho&#x2F;md5-optimisation#x86-avx512-vl-extension">https:&#x2F;&#x2F;github.com&#x2F;animetosho&#x2F;md5-optimisation#x86-avx512-vl...</a></div><br/></div></div><div id="36399138" class="c"><input type="checkbox" id="c-36399138" checked=""/><div class="controls bullet"><span class="by">dougall</span><span>|</span><a href="#36398115">parent</a><span>|</span><a href="#36400375">prev</a><span>|</span><label class="collapse" for="c-36399138">[-]</label><label class="expand" for="c-36399138">[1 more]</label></div><br/><div class="children"><div class="content">Yeah – ARM specifically added EOR3 and BCAX instructions to accelerate SHA-3 hashes, both of which can be handled by VPTERNLOGD.</div><br/></div></div></div></div></div></div></div></div></div></body></html>