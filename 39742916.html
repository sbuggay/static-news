<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1710838876782" as="style"/><link rel="stylesheet" href="styles.css?v=1710838876782"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.pinaraf.info/2024/03/look-ma-i-wrote-a-new-jit-compiler-for-postgresql/">I wrote a new JIT compiler for PostgreSQL</a> <span class="domain">(<a href="https://www.pinaraf.info">www.pinaraf.info</a>)</span></div><div class="subtext"><span>mattashii</span> | <span>34 comments</span></div><br/><div><div id="39744585" class="c"><input type="checkbox" id="c-39744585" checked=""/><div class="controls bullet"><span class="by">weliveindetail</span><span>|</span><a href="#39743917">next</a><span>|</span><label class="collapse" for="c-39744585">[-]</label><label class="expand" for="c-39744585">[7 more]</label></div><br/><div class="children"><div class="content">&gt; There is one way to make the LLVM JIT compiler more usable, but I fear it’s going to take years to be implemented: being able to cache and reuse compiled queries.<p>Actually, it&#x27;s implemented in LLVM for years :) <a href="https:&#x2F;&#x2F;github.com&#x2F;llvm&#x2F;llvm-project&#x2F;commit&#x2F;a98546ebcd2a692e0634c5b1a7e77471316ab6e0">https:&#x2F;&#x2F;github.com&#x2F;llvm&#x2F;llvm-project&#x2F;commit&#x2F;a98546ebcd2a692e...</a></div><br/><div id="39744716" class="c"><input type="checkbox" id="c-39744716" checked=""/><div class="controls bullet"><span class="by">pinaraf</span><span>|</span><a href="#39744585">parent</a><span>|</span><a href="#39745796">next</a><span>|</span><label class="collapse" for="c-39744716">[-]</label><label class="expand" for="c-39744716">[2 more]</label></div><br/><div class="children"><div class="content">Yeah, well, sorry, I should have been more explicit here: the issue is with PostgreSQL, not LLVM. The JIT compiler has to inject direct memory addresses, making the generated code specific to your query and process.</div><br/><div id="39750465" class="c"><input type="checkbox" id="c-39750465" checked=""/><div class="controls bullet"><span class="by">weliveindetail</span><span>|</span><a href="#39744585">root</a><span>|</span><a href="#39744716">parent</a><span>|</span><a href="#39745796">next</a><span>|</span><label class="collapse" for="c-39750465">[-]</label><label class="expand" for="c-39750465">[1 more]</label></div><br/><div class="children"><div class="content">Interesting, because we store relocatable objects. And process symbols can be resolved by name if you really want. It might be yet another performance trade-off though.</div><br/></div></div></div></div><div id="39745796" class="c"><input type="checkbox" id="c-39745796" checked=""/><div class="controls bullet"><span class="by">SigmundA</span><span>|</span><a href="#39744585">parent</a><span>|</span><a href="#39744716">prev</a><span>|</span><a href="#39743917">next</a><span>|</span><label class="collapse" for="c-39745796">[-]</label><label class="expand" for="c-39745796">[4 more]</label></div><br/><div class="children"><div class="content">Since PG uses one process per connection and the LLVM JIT code is process specific the code can&#x27;t be shared amongst all connections to the DB.<p>Plans themselves suffer from this since they are in memory data structures not designed to be shared amongst different processes.<p>DB&#x27;s like MSSQL don&#x27;t have this issue since they use a single process with threads which is also why it can handle more concurrent connections without an external pooler. Although MSSQL can also serialize plans to a non process specific representation and store them in the DB for things like plan locking.</div><br/><div id="39749471" class="c"><input type="checkbox" id="c-39749471" checked=""/><div class="controls bullet"><span class="by">hinkley</span><span>|</span><a href="#39744585">root</a><span>|</span><a href="#39745796">parent</a><span>|</span><a href="#39746109">next</a><span>|</span><label class="collapse" for="c-39749471">[-]</label><label class="expand" for="c-39749471">[1 more]</label></div><br/><div class="children"><div class="content">Way back on Oracle 9i, we had a mystery stall problem. We couldn’t saturate the network, the CPU, or the fiber channel links. We were stuck at ~50% and stumped. Some fuckery was going on and we had to call in a professional.<p>Turned out 9i could only run queries that currently resided in the query cache, and some idiot (who was now my boss) had fucked up our query builder code so that we were getting too many unique queries. Not enough bind variables.<p>So it’s clear Oracle was using a shared cache back then, but like other people here, I’m scratching my head how this would work with Postgres’s flavor of MVCC. Maybe share query plans when the transaction completes?<p>I feel like that would get you 90% of the way but with some head of queue nastiness.</div><br/></div></div><div id="39746109" class="c"><input type="checkbox" id="c-39746109" checked=""/><div class="controls bullet"><span class="by">hans_castorp</span><span>|</span><a href="#39744585">root</a><span>|</span><a href="#39745796">parent</a><span>|</span><a href="#39749471">prev</a><span>|</span><a href="#39743917">next</a><span>|</span><label class="collapse" for="c-39746109">[-]</label><label class="expand" for="c-39746109">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Plans themselves suffer from this since they are in memory data structures not designed to be shared amongst different processes.<p>Oracle uses a process-per-connection model as well (at least on Linux), and they are able to share execution plans across connections. They put all the plans into the &quot;global&quot; shared memory.</div><br/><div id="39746363" class="c"><input type="checkbox" id="c-39746363" checked=""/><div class="controls bullet"><span class="by">SigmundA</span><span>|</span><a href="#39744585">root</a><span>|</span><a href="#39746109">parent</a><span>|</span><a href="#39743917">next</a><span>|</span><label class="collapse" for="c-39746363">[-]</label><label class="expand" for="c-39746363">[1 more]</label></div><br/><div class="children"><div class="content">Looks like you can change that with THREADED_EXECUTION to make it act like it does on Windows with a single process and threads:<p>&gt;On UNIX, starting with Oracle Database 12c Release 2 (12.2), Oracle Database can use an operating system process or an operating system thread to implement each background task such as database writer (DBW0), log writer (LGWR), shared server process dispatchers, and shared servers.<p>The use of operating system threads instead of processes allow resource sharing and reduce resource consumption.<p>On Windows, each background process is implemented as a thread inside a single, large process.<p><a href="https:&#x2F;&#x2F;docs.oracle.com&#x2F;en&#x2F;database&#x2F;oracle&#x2F;oracle-database&#x2F;12.2&#x2F;ntqrf&#x2F;processes-and-threads.html" rel="nofollow">https:&#x2F;&#x2F;docs.oracle.com&#x2F;en&#x2F;database&#x2F;oracle&#x2F;oracle-database&#x2F;1...</a><p>Processes in Windows are much more expensive than Unix typically so using threads has always been preferred to multi process, perhaps thats why MSSQL only has that option with an almost fully recreated internal process model that you can list and kill etc.<p>Even Oracle says it helps with resource usage, even on Unix&#x2F;Linux. Also looks like Oracle has had some kind shared mode for a long time where it basically has a built in pooler to keep actual OS process count down, not 1:1 like PG.<p>Sharing plans can obviously be done using shared memory but it&#x27;s not a simple as just creating some C++ object model (which I believe is what PG has internally) for the plan it must have a process agnostic data format that is then executed probably by deserializing into a executable model from shared memory. Fully jitted code is even trickier vs just a set of logical plan operations. With threads you just share executable code.</div><br/></div></div></div></div></div></div></div></div><div id="39743917" class="c"><input type="checkbox" id="c-39743917" checked=""/><div class="controls bullet"><span class="by">pinaraf</span><span>|</span><a href="#39744585">prev</a><span>|</span><a href="#39744268">next</a><span>|</span><label class="collapse" for="c-39743917">[-]</label><label class="expand" for="c-39743917">[12 more]</label></div><br/><div class="children"><div class="content">Author here. Thanks for submitting my article on hackernews. I&#x27;ll do my best to answer any question.</div><br/><div id="39753342" class="c"><input type="checkbox" id="c-39753342" checked=""/><div class="controls bullet"><span class="by">o11c</span><span>|</span><a href="#39743917">parent</a><span>|</span><a href="#39746397">next</a><span>|</span><label class="collapse" for="c-39753342">[-]</label><label class="expand" for="c-39753342">[1 more]</label></div><br/><div class="children"><div class="content">Is copy-and-patch really a new idea, or just a new name for an old idea?<p>When I learned programming (and interpreters particularly) around 2010, I thought it was well-known that you could memcpy chunks of executable code that your compiler produced if you were careful ... the major gotcha was that the NX bit was just starting to take off at the time (Even on Linux, most people still assumed 32-bit distros and might be surprised that their CPUs even supported 64-bit. At some point I ended up with a netbook that didn&#x27;t support 64-bit code at all ...).<p>Unfortunately I ended up spending too much time on the rest of the code to actually look deeply enough into it to build something useful.</div><br/></div></div><div id="39746397" class="c"><input type="checkbox" id="c-39746397" checked=""/><div class="controls bullet"><span class="by">winternewt</span><span>|</span><a href="#39743917">parent</a><span>|</span><a href="#39753342">prev</a><span>|</span><a href="#39744106">next</a><span>|</span><label class="collapse" for="c-39746397">[-]</label><label class="expand" for="c-39746397">[3 more]</label></div><br/><div class="children"><div class="content">Is there a fundamental difference between copy and patch with C and what compilers do when they target intermediate representations? It seems to me that traditional compilation methods are also &quot;copy and patch&quot; but with another intermediate language than C.</div><br/><div id="39747700" class="c"><input type="checkbox" id="c-39747700" checked=""/><div class="controls bullet"><span class="by">tetha</span><span>|</span><a href="#39743917">root</a><span>|</span><a href="#39746397">parent</a><span>|</span><a href="#39744106">next</a><span>|</span><label class="collapse" for="c-39747700">[-]</label><label class="expand" for="c-39747700">[2 more]</label></div><br/><div class="children"><div class="content">I think conceptually, there is no real difference. In the end, a compiler outputting machine code uses very small stencils, like &quot;mov _ _&quot;, which are rather simple to patch.<p>Practically though, it&#x27;s an enormous difference, as the copy and patch approach re-uses the years of work going into clang &#x2F; gcc supporting platforms, optimizations for different platforms and so on. The approach enables a much larger pool of people (&quot;People capable of writing C&quot; vs &quot;People capable of writing assembly &#x2F; machine code&quot;) to implement very decent JIT compilers.</div><br/><div id="39751041" class="c"><input type="checkbox" id="c-39751041" checked=""/><div class="controls bullet"><span class="by">pinaraf</span><span>|</span><a href="#39743917">root</a><span>|</span><a href="#39747700">parent</a><span>|</span><a href="#39744106">next</a><span>|</span><label class="collapse" for="c-39751041">[-]</label><label class="expand" for="c-39751041">[1 more]</label></div><br/><div class="children"><div class="content">The real difference is in the possible optimizations. If you consider the full scope of JIT compilation in for instance a web browser or the JVM, you could use copy and patch as a tier 0 compiler, and once really hot paths are identified, trigger a complete compiler with all the optimizer steps. Some optimizations are more complicated to implement with copy-patch, esp. if you can&#x27;t use all the tricks described in the paper (for instance they use the ghccc calling convention to get a much finer register allocation, but from the documentation I don&#x27;t think it&#x27;s going to make it for PostgreSQL).<p>But as you say, yes, this enables people capable of writing C and reading assembly (or you have to be perfect and never have to go into gdb on your compiled code), and it makes the job so much faster and easier... Writing several machine code emitters is painful, and having the required optimization strategies for each ISA is quickly out of reach.</div><br/></div></div></div></div></div></div><div id="39744106" class="c"><input type="checkbox" id="c-39744106" checked=""/><div class="controls bullet"><span class="by">pgaddict</span><span>|</span><a href="#39743917">parent</a><span>|</span><a href="#39746397">prev</a><span>|</span><a href="#39743964">next</a><span>|</span><label class="collapse" for="c-39744106">[-]</label><label class="expand" for="c-39744106">[3 more]</label></div><br/><div class="children"><div class="content">Would be a great topic for pgconf.eu in June (pgcon moved to Vancouver). Too bad the CfP is over, but there&#x27;s the &quot;unconference&quot; part (but the topics are decided at the event, no guarantees).</div><br/><div id="39745129" class="c"><input type="checkbox" id="c-39745129" checked=""/><div class="controls bullet"><span class="by">mattashii</span><span>|</span><a href="#39743917">root</a><span>|</span><a href="#39744106">parent</a><span>|</span><a href="#39743964">next</a><span>|</span><label class="collapse" for="c-39745129">[-]</label><label class="expand" for="c-39745129">[2 more]</label></div><br/><div class="children"><div class="content">Did you mean pgconf.dev in May (which has the unconference), or pgconf.eu in October (which doesn&#x27;t have an unconference, but the CfP will open sometime in the - hopefully near - future)?</div><br/><div id="39746399" class="c"><input type="checkbox" id="c-39746399" checked=""/><div class="controls bullet"><span class="by">pgaddict</span><span>|</span><a href="#39743917">root</a><span>|</span><a href="#39745129">parent</a><span>|</span><a href="#39743964">next</a><span>|</span><label class="collapse" for="c-39746399">[-]</label><label class="expand" for="c-39746399">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, I meant May. Sorry :-( Too many conferences around that time, I got confused.<p>That being said, submitting this into the pgconf.eu CfP is a good idea too. It&#x27;s just that it seems like a nice development topic, and the pgcon unconference was always a great place to discuss this sort of stuff. There are a couple more topics in the JIT area, so having a session or two to talk about those and how to move that forward would be beneficial.</div><br/></div></div></div></div></div></div><div id="39743964" class="c"><input type="checkbox" id="c-39743964" checked=""/><div class="controls bullet"><span class="by">frizlab</span><span>|</span><a href="#39743917">parent</a><span>|</span><a href="#39744106">prev</a><span>|</span><a href="#39744104">next</a><span>|</span><label class="collapse" for="c-39743964">[-]</label><label class="expand" for="c-39743964">[1 more]</label></div><br/><div class="children"><div class="content">Not a question, but I love this. I’m eager to see its evolution.</div><br/></div></div><div id="39744123" class="c"><input type="checkbox" id="c-39744123" checked=""/><div class="controls bullet"><span class="by">can3p</span><span>|</span><a href="#39743917">parent</a><span>|</span><a href="#39744104">prev</a><span>|</span><a href="#39744268">next</a><span>|</span><label class="collapse" for="c-39744123">[-]</label><label class="expand" for="c-39744123">[2 more]</label></div><br/><div class="children"><div class="content">Nice post, thanks! Do I read it right that using jit results in the worst max times? What could be a reason in your opinion?</div><br/><div id="39744269" class="c"><input type="checkbox" id="c-39744269" checked=""/><div class="controls bullet"><span class="by">pinaraf</span><span>|</span><a href="#39743917">root</a><span>|</span><a href="#39744123">parent</a><span>|</span><a href="#39744268">next</a><span>|</span><label class="collapse" for="c-39744269">[-]</label><label class="expand" for="c-39744269">[1 more]</label></div><br/><div class="children"><div class="content">Two parts: I did the benchmark on a laptop and didn&#x27;t spend enough time forcing its runtime PM in a fixed state, I&#x27;ll run a real pgbench on my desktop once I implement all required opcodes for it. And since JIT requires a minimum amount of time (about 300us on my tests), on such small runtimes this can quickly overcome the benefits.</div><br/></div></div></div></div></div></div><div id="39744268" class="c"><input type="checkbox" id="c-39744268" checked=""/><div class="controls bullet"><span class="by">adzm</span><span>|</span><a href="#39743917">prev</a><span>|</span><a href="#39750341">next</a><span>|</span><label class="collapse" for="c-39744268">[-]</label><label class="expand" for="c-39744268">[11 more]</label></div><br/><div class="children"><div class="content">I&#x27;m still surprised there isn&#x27;t a query&#x2F;plan cache for PostgreSQL. I could easily see these two approaches working in harmony once it does, as frequent queries could end up being cached and more aggressively optimized with a cache to offset the compilation cost. Of course that adds a whole new layer of complexity and trouble.</div><br/><div id="39744438" class="c"><input type="checkbox" id="c-39744438" checked=""/><div class="controls bullet"><span class="by">williamdclt</span><span>|</span><a href="#39744268">parent</a><span>|</span><a href="#39744324">next</a><span>|</span><label class="collapse" for="c-39744438">[-]</label><label class="expand" for="c-39744438">[4 more]</label></div><br/><div class="children"><div class="content">(The article goes a bit above my head so my excuses if I am a bit off-topic)<p>There is a form of query plan caching in PG: for prepared statements, if PG determines that the actual value of parameters won&#x27;t affect the query plan much, it uses a &quot;generic plan&quot; so that it reuses the same query plan for every execution of the prepared statement (<a href="https:&#x2F;&#x2F;www.postgresql.org&#x2F;docs&#x2F;current&#x2F;sql-prepare.html" rel="nofollow">https:&#x2F;&#x2F;www.postgresql.org&#x2F;docs&#x2F;current&#x2F;sql-prepare.html</a>, see &quot;notes&quot;)</div><br/><div id="39744480" class="c"><input type="checkbox" id="c-39744480" checked=""/><div class="controls bullet"><span class="by">pinaraf</span><span>|</span><a href="#39744268">root</a><span>|</span><a href="#39744438">parent</a><span>|</span><a href="#39745694">next</a><span>|</span><label class="collapse" for="c-39744480">[-]</label><label class="expand" for="c-39744480">[2 more]</label></div><br/><div class="children"><div class="content">Indeed, and right now it&#x27;s the only possible way since it remains in a single session, doing otherwise would be very hard.</div><br/><div id="39746719" class="c"><input type="checkbox" id="c-39746719" checked=""/><div class="controls bullet"><span class="by">cbsmith</span><span>|</span><a href="#39744268">root</a><span>|</span><a href="#39744480">parent</a><span>|</span><a href="#39745694">next</a><span>|</span><label class="collapse" for="c-39746719">[-]</label><label class="expand" for="c-39746719">[1 more]</label></div><br/><div class="children"><div class="content">Unless you count stored procs...</div><br/></div></div></div></div><div id="39745694" class="c"><input type="checkbox" id="c-39745694" checked=""/><div class="controls bullet"><span class="by">SigmundA</span><span>|</span><a href="#39744268">root</a><span>|</span><a href="#39744438">parent</a><span>|</span><a href="#39744480">prev</a><span>|</span><a href="#39744324">next</a><span>|</span><label class="collapse" for="c-39745694">[-]</label><label class="expand" for="c-39745694">[1 more]</label></div><br/><div class="children"><div class="content">Yes its manual and per session, DB&#x27;s like MSSQL have that was well but are very rarely used anymore because it got automatic plan caching about 20 years ago which basically eliminates any advantage to manually preparing. Its actually better since it can be shared across all sessions</div><br/></div></div></div></div><div id="39744324" class="c"><input type="checkbox" id="c-39744324" checked=""/><div class="controls bullet"><span class="by">pinaraf</span><span>|</span><a href="#39744268">parent</a><span>|</span><a href="#39744438">prev</a><span>|</span><a href="#39745232">next</a><span>|</span><label class="collapse" for="c-39744324">[-]</label><label class="expand" for="c-39744324">[3 more]</label></div><br/><div class="children"><div class="content">Honestly I thought the same as you, then I wrote this, and I now understand it&#x27;s going to be really hard to do. To make it very simple: there are pointers to query parts &quot;leaking&quot; everywhere across the execution engine. Removing them will require a significant overall of the execution engine, the planner and who knows what else. Even in a single session, two compiled queries will have different compiled code because of that (both llvm and my copyjit have to inject the adresses of various structs in asm code)</div><br/><div id="39744534" class="c"><input type="checkbox" id="c-39744534" checked=""/><div class="controls bullet"><span class="by">adzm</span><span>|</span><a href="#39744268">root</a><span>|</span><a href="#39744324">parent</a><span>|</span><a href="#39745232">next</a><span>|</span><label class="collapse" for="c-39744534">[-]</label><label class="expand" for="c-39744534">[2 more]</label></div><br/><div class="children"><div class="content">Just going to say, I&#x27;m blown away by how simple this JIT is though. Really quite a beautiful JIT approach.</div><br/><div id="39744690" class="c"><input type="checkbox" id="c-39744690" checked=""/><div class="controls bullet"><span class="by">pinaraf</span><span>|</span><a href="#39744268">root</a><span>|</span><a href="#39744534">parent</a><span>|</span><a href="#39745232">next</a><span>|</span><label class="collapse" for="c-39744690">[-]</label><label class="expand" for="c-39744690">[1 more]</label></div><br/><div class="children"><div class="content">Same for me, that&#x27;s why I did this after finding out this research paper. With the proper compiler settings and small tricks you can remove some parts and already end up faster than the interpreter (because you remove some branches and a few memory accesses) and it&#x27;s even possible to create &quot;super-stencils&quot; covering typical opcodes series and optimizing them further. Or the opposite, &quot;sub-stencils&quot; in order to do some loop unrolling for instance.</div><br/></div></div></div></div></div></div><div id="39745232" class="c"><input type="checkbox" id="c-39745232" checked=""/><div class="controls bullet"><span class="by">aeyes</span><span>|</span><a href="#39744268">parent</a><span>|</span><a href="#39744324">prev</a><span>|</span><a href="#39750341">next</a><span>|</span><label class="collapse" for="c-39745232">[-]</label><label class="expand" for="c-39745232">[3 more]</label></div><br/><div class="children"><div class="content">The plan cache on Oracle in combination with prepared statements where the optimizer can&#x27;t peek into the parameters has been really problematic for me in the past. I usually had to go in and either add hints or force a plan.<p>Even simple queries like SELECT * FROM t WHERE x = TRUE; could turn into a nightmare depending on the distribution of the x values in the table.<p>With Postgres I rarely encountered such problems but I must admit that I haven&#x27;t used Postgres with prepared statements.<p>I have seen some queries with slow planning time (&gt;100ms) where a cache could have been useful but I don&#x27;t remember ever really needing to optimize one.</div><br/><div id="39745726" class="c"><input type="checkbox" id="c-39745726" checked=""/><div class="controls bullet"><span class="by">SigmundA</span><span>|</span><a href="#39744268">root</a><span>|</span><a href="#39745232">parent</a><span>|</span><a href="#39750341">next</a><span>|</span><label class="collapse" for="c-39745726">[-]</label><label class="expand" for="c-39745726">[2 more]</label></div><br/><div class="children"><div class="content">Is x a parameter because it doesn&#x27;t look like it? MSSQL has parameter sniffing and will make multiple plans based on incoming parameters I would be surprised if Oracle does not do the same. It can actually be problematic to sniff parameters sometimes and it can be disabled with a hint!</div><br/><div id="39746041" class="c"><input type="checkbox" id="c-39746041" checked=""/><div class="controls bullet"><span class="by">aeyes</span><span>|</span><a href="#39744268">root</a><span>|</span><a href="#39745726">parent</a><span>|</span><a href="#39750341">next</a><span>|</span><label class="collapse" for="c-39746041">[-]</label><label class="expand" for="c-39746041">[1 more]</label></div><br/><div class="children"><div class="content">I just made up something simple but yes, I had these problems with bind variables in prepared statements.<p>&gt; SELECT * FROM t WHERE x = :var;<p>But I haven&#x27;t used Oracle in years and back in the day, there was no bind variable peeking.</div><br/></div></div></div></div></div></div></div></div><div id="39750341" class="c"><input type="checkbox" id="c-39750341" checked=""/><div class="controls bullet"><span class="by">miohtama</span><span>|</span><a href="#39744268">prev</a><span>|</span><a href="#39744099">next</a><span>|</span><label class="collapse" for="c-39750341">[-]</label><label class="expand" for="c-39750341">[1 more]</label></div><br/><div class="children"><div class="content">Back in 386 era, there was a concept of self-modifying code (assembly). A similar like stencils presented here, but because code was a singleton, rarely a copy was made.<p>E.g. Doom on DOS used this optimisation techique, because otherwise you could not cram out enough performance from tight rendering loops on old CPUs.</div><br/></div></div></div></div></div></div></div></body></html>