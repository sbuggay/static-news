<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1687251655311" as="style"/><link rel="stylesheet" href="styles.css?v=1687251655311"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.nngroup.com/articles/ai-paradigm/">AI: First New UI Paradigm in 60 Years?</a>Â <span class="domain">(<a href="https://www.nngroup.com">www.nngroup.com</a>)</span></div><div class="subtext"><span>ssn</span> | <span>150 comments</span></div><br/><div><div id="36396484" class="c"><input type="checkbox" id="c-36396484" checked=""/><div class="controls bullet"><span class="by">Animats</span><span>|</span><a href="#36395736">next</a><span>|</span><label class="collapse" for="c-36396484">[-]</label><label class="expand" for="c-36396484">[39 more]</label></div><br/><div class="children"><div class="content">This article isn&#x27;t too helpful.<p>There have been many &quot;UI Paradigms&quot;, but the fancier ones tended to be special purpose. The first one worthy of the name was for train dispatching. That was General Railway Signal&#x27;s NX (eNtry-Exit) system.[1] Introduced in 1936, still in use in the New York subways. With NX, the dispatcher routing an approaching train selected the &quot;entry&quot; track on which the train was approaching. The system would then light up all possible &quot;exit&quot; tracks from the junction. This took into account conflicting routes already set up and trains present in the junction. Only reachable exits lit up. The dispatcher pushed the button for the desired exit. The route setup was then automatic. Switches moved and locked into position, then signals along the route went to clear. All this was fully interlocked; the operator could not request anything unsafe.<p>There were control panels before this, but this was the first system where the UI did more than just show status. It actively advised and helped the operator. The operator set the goal; the system worked out how to achieve it.<p>Another one I encountered was an early computerized fire department dispatching system. Big custom display boards and keyboards. When an alarm came in, it was routed to a dispatcher. Based on location, the system picked the initial resources (trucks, engines, chiefs, and special equipment) to be dispatched. Each dispatcher had a custom keyboard, with one button for each of those resources. The buttons lit up indicating the selected equipment. The dispatcher could add additional equipment with a single button push, if the situation being called in required it. Then they pushed one big button, which set off alarms in fire stations, printed a message on a printer near the fire trucks, and even opened the doors at the fire house. There was a big board at the front of the room which showed the status of everything as colored squares. The fire department people said this cut about 30 seconds off a dispatch, which, in that business, is considered a big win.<p>Both of those are systems which had to work right. Large language models are not even close to being safe to use in such applications. Until LLMs report &quot;don&#x27;t know&quot; instead of hallucinating, they&#x27;re limited to very low risk applications such as advertising and search.<p>Now, the promising feature of LLMs in this direction is the ability to use the context of previous questions and answers. It&#x27;s still query&#x2F;response, but with enough context that the user can gradually make the system converge on a useful result. Such systems are useful for &quot;I don&#x27;t know what I want but I&#x27;ll know it when I see it&quot; problems. This allows using flaky LLMs with human assistance to get a useful result.<p>[1] <a href="https:&#x2F;&#x2F;online.anyflip.com&#x2F;lbes&#x2F;vczg&#x2F;mobile&#x2F;#p=1" rel="nofollow noreferrer">https:&#x2F;&#x2F;online.anyflip.com&#x2F;lbes&#x2F;vczg&#x2F;mobile&#x2F;#p=1</a></div><br/><div id="36397136" class="c"><input type="checkbox" id="c-36397136" checked=""/><div class="controls bullet"><span class="by">philovivero</span><span>|</span><a href="#36396484">parent</a><span>|</span><a href="#36401320">next</a><span>|</span><label class="collapse" for="c-36397136">[-]</label><label class="expand" for="c-36397136">[16 more]</label></div><br/><div class="children"><div class="content">&gt; Both of those are systems which had to work right. Large language models are not even close to being safe to use in such applications. Until LLMs report &quot;don&#x27;t know&quot; instead of hallucinating, they&#x27;re limited to very low risk applications such as advertising and search.<p>Are humans limited to low-risk applications like that?<p>Because humans, even some of the most humble, will still assert things they THINK are true, but are patently untrue, based on misunderstandings, faulty memories, confused reasoning, and a plethora of others.<p>I can&#x27;t count the number of times I&#x27;ve had conversations with extremely well-experience, smart techies who just spout off the most ignorant stuff.<p>And I don&#x27;t want to count the number of times I&#x27;ve personally done that, but I&#x27;m sure it&#x27;s &gt;0. And I hate to tell you, but I&#x27;ve spent the last 20 years in positions of authority that could have caused massive amounts of damage not only to the companies I&#x27;ve been employed by, but a large cross-section of society as well. And those fools I referenced in the last paragraph? Same.<p>I think people are too hasty to discount LLMs, or LLM-backed agents, or other LLM-based applications because of their limitations.<p>(Related: I think people are too hasty to discount the catastrophic potential of self-modifying AGI as well)</div><br/><div id="36398423" class="c"><input type="checkbox" id="c-36398423" checked=""/><div class="controls bullet"><span class="by">memefrog</span><span>|</span><a href="#36396484">root</a><span>|</span><a href="#36397136">parent</a><span>|</span><a href="#36398184">next</a><span>|</span><label class="collapse" for="c-36398423">[-]</label><label class="expand" for="c-36398423">[8 more]</label></div><br/><div class="children"><div class="content">Can people please stop making this comment in reply to EVERY criticism of LLMs? &quot;Humans are flawed too&quot;.<p>We do not normally hallucinate.  We are sometimes wrong, and sometimes are wrong about the confidence they should attach to their knowledge.  But we do not simply hallucinate and spout fully confidence nonsense constantly.  That is what LLMs.<p>You remember a few isolated incidents because they&#x27;re salient.  That does not mean that it&#x27;s representative of your average personal interactions.</div><br/><div id="36399994" class="c"><input type="checkbox" id="c-36399994" checked=""/><div class="controls bullet"><span class="by">jph00</span><span>|</span><a href="#36396484">root</a><span>|</span><a href="#36398423">parent</a><span>|</span><a href="#36398709">next</a><span>|</span><label class="collapse" for="c-36399994">[-]</label><label class="expand" for="c-36399994">[2 more]</label></div><br/><div class="children"><div class="content">&gt; <i>We do not normally hallucinate. We are sometimes wrong, and sometimes are wrong about the confidence they should attach to their knowledge. But we do not simply hallucinate and spout fully confidence nonsense constantly. That is what LLMs.</i><p>In my average interaction with GPT 4 there are far less errors than in this paragraph. I would say that here you in fact &quot;spout fully confidence nonsense&quot; (sic).<p>Some humans are better than others at saying things that are correct, and at saying things with appropriately calibrated confidence. Some LLMs are better than some humans in some situations at doing these things.<p>You seem to be hung up on the word &quot;hallucinate&quot;. It is, indeed, not a great word and many researchers are a bit annoyed that&#x27;s the term that&#x27;s stuck. It simply means for an LLM to state something that&#x27;s incorrect as if it&#x27;s true.<p>The times that LLMs do this do stand out, because &quot;You remember a few isolated incidents because they&#x27;re salient&quot;.</div><br/><div id="36400938" class="c"><input type="checkbox" id="c-36400938" checked=""/><div class="controls bullet"><span class="by">leoedin</span><span>|</span><a href="#36396484">root</a><span>|</span><a href="#36399994">parent</a><span>|</span><a href="#36398709">next</a><span>|</span><label class="collapse" for="c-36400938">[-]</label><label class="expand" for="c-36400938">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Some humans are better than others at saying things that are correct, and at saying things with appropriately calibrated confidence.<p>That&#x27;s true - which is why we have constructed a society with endless selection processes. Starting from kindergarten, we are constantly assessing people&#x27;s abilities - so that by the time someone is interviewing for a safety critical job they&#x27;ve been through a huge number of gates.</div><br/></div></div></div></div><div id="36398709" class="c"><input type="checkbox" id="c-36398709" checked=""/><div class="controls bullet"><span class="by">og_kalu</span><span>|</span><a href="#36396484">root</a><span>|</span><a href="#36398423">parent</a><span>|</span><a href="#36399994">prev</a><span>|</span><a href="#36401058">next</a><span>|</span><label class="collapse" for="c-36398709">[-]</label><label class="expand" for="c-36398709">[4 more]</label></div><br/><div class="children"><div class="content">&gt;We do not normally hallucinate.<p>Oh yes we do lol. Many experiments show our perception of reality and of cognition is entirely divorced from the reality of what&#x27;s really going on.<p>Your brain is making stuff up all the time. Sense data you perceive is partly fabricated. Your memories are partly fabricated. Your decision rationales are post hoc rationalizations more often than not. That is, you don&#x27;t genuinely know why you make certain decisions or what preferences actually inform them. You just think you do. You can&#x27;t recreate previous mental states. You are not usually aware. But it is happening.<p>LLMs are just undoubtedly worse right now.</div><br/><div id="36398844" class="c"><input type="checkbox" id="c-36398844" checked=""/><div class="controls bullet"><span class="by">worrycue</span><span>|</span><a href="#36396484">root</a><span>|</span><a href="#36398709">parent</a><span>|</span><a href="#36401058">next</a><span>|</span><label class="collapse" for="c-36398844">[-]</label><label class="expand" for="c-36398844">[3 more]</label></div><br/><div class="children"><div class="content">We donât hallucinate in such a way &#x2F; to the extend that it compromises our ability to do our job.<p>Currently no one will trust a LLM to even run a helpline - that just a lawsuit waiting to happen should the AI hallucinate a âsolutionâ that results in loss of property, injury or death.</div><br/><div id="36401037" class="c"><input type="checkbox" id="c-36401037" checked=""/><div class="controls bullet"><span class="by">strokirk</span><span>|</span><a href="#36396484">root</a><span>|</span><a href="#36398844">parent</a><span>|</span><a href="#36398925">next</a><span>|</span><label class="collapse" for="c-36401037">[-]</label><label class="expand" for="c-36401037">[1 more]</label></div><br/><div class="children"><div class="content">Having worked in the help-line business, I can tell you that many corporations would and do use LLMs for their helpline, and used worse options before.</div><br/></div></div><div id="36398925" class="c"><input type="checkbox" id="c-36398925" checked=""/><div class="controls bullet"><span class="by">og_kalu</span><span>|</span><a href="#36396484">root</a><span>|</span><a href="#36398844">parent</a><span>|</span><a href="#36401037">prev</a><span>|</span><a href="#36401058">next</a><span>|</span><label class="collapse" for="c-36398925">[-]</label><label class="expand" for="c-36398925">[1 more]</label></div><br/><div class="children"><div class="content">&gt;Currently no one will trust a LLM to even run a helpline - that just a lawsuit waiting to happen should the AI hallucinate a âsolutionâ that results in loss of property, injury or death.<p>I&#x27;m not quite sure exactly what you mean by helpline here (general customer service or more specific ?) but assuming the former..<p>How much power do you think most helplines actually have ? Most are running off pre-written scripts&#x2F;guidelines with very little in the way of decisional power. There&#x27;s a reason for that.<p>Injury or death ? LLM hallucinations are relational. Unless you&#x27;re speaking to Dr GPT or something to that effect, a response resulting in injury or death isn&#x27;t happening.</div><br/></div></div></div></div></div></div><div id="36401058" class="c"><input type="checkbox" id="c-36401058" checked=""/><div class="controls bullet"><span class="by">lexandstuff</span><span>|</span><a href="#36396484">root</a><span>|</span><a href="#36398423">parent</a><span>|</span><a href="#36398709">prev</a><span>|</span><a href="#36398184">next</a><span>|</span><label class="collapse" for="c-36401058">[-]</label><label class="expand" for="c-36401058">[1 more]</label></div><br/><div class="children"><div class="content">The equivalent of hallucinations in LLMs is false memories [1] in people. They happen all the time.<p>[1] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;False_memory" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;False_memory</a></div><br/></div></div></div></div><div id="36398184" class="c"><input type="checkbox" id="c-36398184" checked=""/><div class="controls bullet"><span class="by">hyperthesis</span><span>|</span><a href="#36396484">root</a><span>|</span><a href="#36397136">parent</a><span>|</span><a href="#36398423">prev</a><span>|</span><a href="#36397649">next</a><span>|</span><label class="collapse" for="c-36398184">[-]</label><label class="expand" for="c-36398184">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Are humans limited to low-risk applications like that?<p>No, but arguably civilization consists of mechanisms to manage human fallibility (separation of powers, bicameralism, &quot;democracy&quot;, bureaucracy, regulations, etc).  We might not fully understand why, but we&#x27;ve found methods that sorta kinda &quot;work&quot;.<p>&gt; could have caused<p>That&#x27;s why they didn&#x27;t.</div><br/><div id="36398674" class="c"><input type="checkbox" id="c-36398674" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#36396484">root</a><span>|</span><a href="#36398184">parent</a><span>|</span><a href="#36397649">next</a><span>|</span><label class="collapse" for="c-36398674">[-]</label><label class="expand" for="c-36398674">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>No, but arguably civilization consists of mechanisms to manage human fallibility</i><p>Exactly. Civilization is, arguably, one big exercise in reducing variance in individuals, as low variance and high predictability is what lets us work together and trust each other, instead of seeing each other as threats and hiding from each other (or trying to preemptively attack). The more something or someone is unpredictable, the more we see it or them as a threat.<p>&gt; <i>(separation of powers, bicameralism, &quot;democracy&quot;, bureaucracy, regulations, etc).</i><p>And on the more individual scale: culture, social customs and public school system are all forces that shape humans from the youngest age, reducing variance in thoughts and behaviors. Exams of all kind, including psychological ones, prevent high-variance individuals from being able to do large amount of harm to others. The higher the danger, the higher the bar.<p>There are tests you need to pass to be able to own and drive a car. There are tests you may need to pass to own a firearm. There are more tests still before you&#x27;ll be allowed to fly an aircraft. Those tests are not there just to ensure your skills - they also filter high-variance individuals, people who cannot be safely given responsibility to operate dangerous tools.<p>Further still, the society has mechanisms to eliminate high-variance outliers. Lighter cases may get some kind of medical or spiritual treatment, and (with gates in place to keep them away from guns and planes) it works out OK. More difficult cases eventually get locked up in prisons or mental hospitals. While there are lot of specific things to discuss about the prison and mental care systems, their general, high-level function is simple: they keep both predictably dangerous and high-variance (i.e. unpredictably dangerous) people stashed safely away, where they can&#x27;t disrupt or harm others at scale.<p>&gt; <i>We might not fully understand why, but we&#x27;ve found methods that sorta kinda &quot;work&quot;.</i><p>Yes, we&#x27;ve found many such methods at every level - individual, familial, tribal, national - and we stack them all on top of each other. This creates the conditions that let us live in larger groups, with less conflicts, as well as to safely use increasingly powerful (i.e. potentially destructive) technologies.</div><br/></div></div></div></div><div id="36397649" class="c"><input type="checkbox" id="c-36397649" checked=""/><div class="controls bullet"><span class="by">ilyt</span><span>|</span><a href="#36396484">root</a><span>|</span><a href="#36397136">parent</a><span>|</span><a href="#36398184">prev</a><span>|</span><a href="#36397201">next</a><span>|</span><label class="collapse" for="c-36397649">[-]</label><label class="expand" for="c-36397649">[1 more]</label></div><br/><div class="children"><div class="content">&gt;Because humans, even some of the most humble, will still assert things they THINK are true, but are patently untrue, based on misunderstandings, faulty memories, confused reasoning, and a plethora of others.<p>&gt; I can&#x27;t count the number of times I&#x27;ve had conversations with extremely well-experience, smart techies who just spout off the most ignorant stuff.<p>Spouting out the most ignorant stuff is one of the lowest risk things you can do in general. We&#x27;re talking about running a code where bug can do a ton of damage, financial or otherwise, not water-cooler conversations.</div><br/></div></div><div id="36397201" class="c"><input type="checkbox" id="c-36397201" checked=""/><div class="controls bullet"><span class="by">cmiles74</span><span>|</span><a href="#36396484">root</a><span>|</span><a href="#36397136">parent</a><span>|</span><a href="#36397649">prev</a><span>|</span><a href="#36400670">next</a><span>|</span><label class="collapse" for="c-36397201">[-]</label><label class="expand" for="c-36397201">[1 more]</label></div><br/><div class="children"><div class="content">In the train example, the UI is in place to prevent a person from making a dangerous route. I think the idea here is that an LLM cannot take the place of such a UI as they are inherently unreliable.</div><br/></div></div><div id="36400670" class="c"><input type="checkbox" id="c-36400670" checked=""/><div class="controls bullet"><span class="by">dorkwood</span><span>|</span><a href="#36396484">root</a><span>|</span><a href="#36397136">parent</a><span>|</span><a href="#36397201">prev</a><span>|</span><a href="#36398507">next</a><span>|</span><label class="collapse" for="c-36400670">[-]</label><label class="expand" for="c-36400670">[1 more]</label></div><br/><div class="children"><div class="content">Couldnât you make this same argument with a chat bot that wasnât an LLM at all?<p>âYes, it may have responded with total nonsense just now, but who among us can say theyâve never done the same in conversation?â</div><br/></div></div><div id="36398507" class="c"><input type="checkbox" id="c-36398507" checked=""/><div class="controls bullet"><span class="by">NikolaNovak</span><span>|</span><a href="#36396484">root</a><span>|</span><a href="#36397136">parent</a><span>|</span><a href="#36400670">prev</a><span>|</span><a href="#36397227">next</a><span>|</span><label class="collapse" for="c-36398507">[-]</label><label class="expand" for="c-36398507">[1 more]</label></div><br/><div class="children"><div class="content">To your point,Humans are augmented by checklists and custom processes in critical situations. And very certainly applications include which mimic such  safety checklists. We don&#x27;t NEED to start from LLM perspective of our goal is different and doesn&#x27;t benefit from LLM. Not all UI or architecture is fit for all purposes.</div><br/></div></div><div id="36397227" class="c"><input type="checkbox" id="c-36397227" checked=""/><div class="controls bullet"><span class="by">ra</span><span>|</span><a href="#36396484">root</a><span>|</span><a href="#36397136">parent</a><span>|</span><a href="#36398507">prev</a><span>|</span><a href="#36401320">next</a><span>|</span><label class="collapse" for="c-36397227">[-]</label><label class="expand" for="c-36397227">[1 more]</label></div><br/><div class="children"><div class="content">I wholeheartedly agree with the main thrust of your comment. Care to expand on your (related: potential catastrophe) opinion?</div><br/></div></div></div></div><div id="36401320" class="c"><input type="checkbox" id="c-36401320" checked=""/><div class="controls bullet"><span class="by">throwuwu</span><span>|</span><a href="#36396484">parent</a><span>|</span><a href="#36397136">prev</a><span>|</span><a href="#36397052">next</a><span>|</span><label class="collapse" for="c-36401320">[-]</label><label class="expand" for="c-36401320">[1 more]</label></div><br/><div class="children"><div class="content">Those fall under the second category in the article. No different from using a command line application and passing in a set of parameters and receiving an output.</div><br/></div></div><div id="36397052" class="c"><input type="checkbox" id="c-36397052" checked=""/><div class="controls bullet"><span class="by">jart</span><span>|</span><a href="#36396484">parent</a><span>|</span><a href="#36401320">prev</a><span>|</span><a href="#36400444">next</a><span>|</span><label class="collapse" for="c-36397052">[-]</label><label class="expand" for="c-36397052">[9 more]</label></div><br/><div class="children"><div class="content">When you say train dispatching and control panels, I think you&#x27;ve illustrated how confused this whole discussion is. There should be a separate term called &quot;operator interface&quot; that is separate from &quot;user interface&quot; because UIs have never had any locus of control, because they&#x27;re for users, and operators are the ones in control. Requesting that an LLM do something is like pressing the button to close the doors of an elevator. Do you feel in charge?</div><br/><div id="36397255" class="c"><input type="checkbox" id="c-36397255" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#36396484">root</a><span>|</span><a href="#36397052">parent</a><span>|</span><a href="#36397167">next</a><span>|</span><label class="collapse" for="c-36397255">[-]</label><label class="expand" for="c-36397255">[6 more]</label></div><br/><div class="children"><div class="content">Oh my. This is the first time I&#x27;ve seen this kind of distinction between &quot;users&quot; and &quot;operators&quot; in context of a single system. I kind of always assumed that &quot;operator&quot; is just a synonym for &quot;user&quot; in industries&#x2F;contexts that are dealing with tools instead of toys.<p>But this absolutely makes sense, and it is a succinct description for the complaints some of us frequently make about modern UI trends: bad interfaces are the ones that make us feel like &quot;users&quot;, where we expect to be &quot;operators&quot;.</div><br/><div id="36397689" class="c"><input type="checkbox" id="c-36397689" checked=""/><div class="controls bullet"><span class="by">prpl</span><span>|</span><a href="#36396484">root</a><span>|</span><a href="#36397255">parent</a><span>|</span><a href="#36397394">next</a><span>|</span><label class="collapse" for="c-36397689">[-]</label><label class="expand" for="c-36397689">[1 more]</label></div><br/><div class="children"><div class="content">Iâve seen such a distinction before, but Iâve been around telescopes and particle accelerators. Single system, but different roles in the same system with a different UI.</div><br/></div></div><div id="36397394" class="c"><input type="checkbox" id="c-36397394" checked=""/><div class="controls bullet"><span class="by">jart</span><span>|</span><a href="#36396484">root</a><span>|</span><a href="#36397255">parent</a><span>|</span><a href="#36397689">prev</a><span>|</span><a href="#36397167">next</a><span>|</span><label class="collapse" for="c-36397394">[-]</label><label class="expand" for="c-36397394">[4 more]</label></div><br/><div class="children"><div class="content">Oh snap, did I just pull back the curtain?</div><br/><div id="36397697" class="c"><input type="checkbox" id="c-36397697" checked=""/><div class="controls bullet"><span class="by">ilyt</span><span>|</span><a href="#36396484">root</a><span>|</span><a href="#36397394">parent</a><span>|</span><a href="#36397512">next</a><span>|</span><label class="collapse" for="c-36397697">[-]</label><label class="expand" for="c-36397697">[2 more]</label></div><br/><div class="children"><div class="content">You put into words the things I&#x27;ve noticed UIs evolving away from.<p>It just feels like UIs of software 10,20, even 30 years ago were designed for &quot;operators&quot;, people that <i>actually worked with the software</i> for hours at end, and so with a little bit of learning you could be dancing with keybindings and doing stuff as fast as CLI nerds.<p>Nowadays most seems to be  optimized for first hour of use of new user and not much else, and the exceptions are software made &quot;by operators, for operators&quot;, like for example KiCAD.</div><br/><div id="36400008" class="c"><input type="checkbox" id="c-36400008" checked=""/><div class="controls bullet"><span class="by">ozim</span><span>|</span><a href="#36396484">root</a><span>|</span><a href="#36397697">parent</a><span>|</span><a href="#36397512">next</a><span>|</span><label class="collapse" for="c-36400008">[-]</label><label class="expand" for="c-36400008">[1 more]</label></div><br/><div class="children"><div class="content">Downside is nowadays in office setting one has to operate 20+ different applications to get work done.<p>While as operator you would spend more like 80% of your time using the same interface and application.<p>I could spend my time to type 100WPM but I am not a typist - as a software dev it is quite enough to go with 40-60WPM because it is just small part of my work.</div><br/></div></div></div></div><div id="36397512" class="c"><input type="checkbox" id="c-36397512" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#36396484">root</a><span>|</span><a href="#36397394">parent</a><span>|</span><a href="#36397697">prev</a><span>|</span><a href="#36397167">next</a><span>|</span><label class="collapse" for="c-36397512">[-]</label><label class="expand" for="c-36397512">[1 more]</label></div><br/><div class="children"><div class="content">Indeed you did; half of my brain capacity is currently being used by a background process sifting through everything I remember ever thinking or learning that&#x27;s associated with computers, to re-evaluate it in context of the difference between &quot;users&quot; and &quot;operators&quot;.<p>Seriously. Until your comment, I thought the two terms to be synonyms.</div><br/></div></div></div></div></div></div><div id="36397167" class="c"><input type="checkbox" id="c-36397167" checked=""/><div class="controls bullet"><span class="by">Animats</span><span>|</span><a href="#36396484">root</a><span>|</span><a href="#36397052">parent</a><span>|</span><a href="#36397255">prev</a><span>|</span><a href="#36400444">next</a><span>|</span><label class="collapse" for="c-36397167">[-]</label><label class="expand" for="c-36397167">[2 more]</label></div><br/><div class="children"><div class="content"><i>UIs have never the locus of control, because they&#x27;re for users, and operators are the ones in control.</i><p>Not really any more. The control systems for almost everything complicated now look like ordinary desktop or phone user interfaces. Train dispatching centers, police dispatching centers, and power dispatching centers all look rather similar today.</div><br/><div id="36397229" class="c"><input type="checkbox" id="c-36397229" checked=""/><div class="controls bullet"><span class="by">jart</span><span>|</span><a href="#36396484">root</a><span>|</span><a href="#36397167">parent</a><span>|</span><a href="#36400444">next</a><span>|</span><label class="collapse" for="c-36397229">[-]</label><label class="expand" for="c-36397229">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s because they&#x27;re computer users.</div><br/></div></div></div></div></div></div><div id="36400444" class="c"><input type="checkbox" id="c-36400444" checked=""/><div class="controls bullet"><span class="by">savolai</span><span>|</span><a href="#36396484">parent</a><span>|</span><a href="#36397052">prev</a><span>|</span><a href="#36401076">next</a><span>|</span><label class="collapse" for="c-36400444">[-]</label><label class="expand" for="c-36400444">[2 more]</label></div><br/><div class="children"><div class="content">Iâd love to understand the relevance of this comment, but I sincerely donât.<p>You describe two cases that are specially designed to anticipate needs of professionals operating a system. Thatâs automation, sure, but not AI. The system doesnât even ostensibly understand yser intent, itâs still simply and obviously deterministic, granted complex.<p>Do you have an underlying assumption about you wishing tech to only be for solving professional problems?<p>The context Nielsen comes from is the field of Human-Computer Interaction, which to me is about a more varied usage context than that.<p>LLMs have flaws, sure.<p>But how does all this at all relate to the paradigm development the article discusses?</div><br/><div id="36400536" class="c"><input type="checkbox" id="c-36400536" checked=""/><div class="controls bullet"><span class="by">quaintdev</span><span>|</span><a href="#36396484">root</a><span>|</span><a href="#36400444">parent</a><span>|</span><a href="#36401076">next</a><span>|</span><label class="collapse" for="c-36400536">[-]</label><label class="expand" for="c-36400536">[1 more]</label></div><br/><div class="children"><div class="content">LLMs have flaws but they are exceptionally good at transforming data or outputting data in the format I want.<p>I once asked ChatGPT to tabulate calories of different food. I then asked it to convert table to CSV. I even asked it to provide SQL insert statement for same table. Now the data might be incorrect but the transformation of that data never was.<p>This works with complex transforms as well like asking it to create docker compose from docker run or podman run command and vice versa. Occasionally the transform would be wrong but then you realise it was just out of date with newer format which is expected because it&#x27;s knowledge is limited to 2021</div><br/></div></div></div></div><div id="36401076" class="c"><input type="checkbox" id="c-36401076" checked=""/><div class="controls bullet"><span class="by">insomagent</span><span>|</span><a href="#36396484">parent</a><span>|</span><a href="#36400444">prev</a><span>|</span><a href="#36396708">next</a><span>|</span><label class="collapse" for="c-36401076">[-]</label><label class="expand" for="c-36401076">[1 more]</label></div><br/><div class="children"><div class="content">Sometimes a headline is all you need.  Often times people won&#x27;t read past the headline.</div><br/></div></div><div id="36396708" class="c"><input type="checkbox" id="c-36396708" checked=""/><div class="controls bullet"><span class="by">ignoramous</span><span>|</span><a href="#36396484">parent</a><span>|</span><a href="#36401076">prev</a><span>|</span><a href="#36395736">next</a><span>|</span><label class="collapse" for="c-36396708">[-]</label><label class="expand" for="c-36396708">[9 more]</label></div><br/><div class="children"><div class="content">Hallucinations will be tamed, I think. Only a matter of time (~3 to 5 years [0]) given the amount of research going into it?<p>With that in mind, ambient computing has always <i>threatened</i> to be the next frontier in Human-Computer Interaction. Siri, Google Assistant, Alexa, and G Home predate today&#x27;s LLM hype. Dare I say, the hype is real.<p>As a consumer, GPT4 has shown capabilities far beyond whatever preceded it (with the exception of Google Translate). And from what Sam has been saying in the interviews, newer multi-modal GPTs are going to be <i>exponentially</i> better: <a href="https:&#x2F;&#x2F;youtube.com&#x2F;watch?v=H1hdQdcM-H4s&amp;t=380s">https:&#x2F;&#x2F;youtube.com&#x2F;watch?v=H1hdQdcM-H4s&amp;t=380s</a><p>[0] <a href="https:&#x2F;&#x2F;twitter.com&#x2F;mustafasuleymn&#x2F;status&#x2F;1669481907980206081" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;mustafasuleymn&#x2F;status&#x2F;166948190798020608...</a></div><br/><div id="36397021" class="c"><input type="checkbox" id="c-36397021" checked=""/><div class="controls bullet"><span class="by">Animats</span><span>|</span><a href="#36396484">root</a><span>|</span><a href="#36396708">parent</a><span>|</span><a href="#36397034">next</a><span>|</span><label class="collapse" for="c-36397021">[-]</label><label class="expand" for="c-36397021">[3 more]</label></div><br/><div class="children"><div class="content">&gt; Hallucinations will be tamed.<p>I hope so. But so far, most of the proposals seem to involve bolting something on the outside of the black box of the LLM itself.<p>If medium-sized language models can be made hallucination-free, we&#x27;ll see more applications. A base language model that has most of the language but doesn&#x27;t try to contain all human knowledge, plus a special purpose model for the task at hand, would be very useful if reliable. That&#x27;s what you need for car controls, customer service, and similar interaction.</div><br/><div id="36397315" class="c"><input type="checkbox" id="c-36397315" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#36396484">root</a><span>|</span><a href="#36397021">parent</a><span>|</span><a href="#36397293">next</a><span>|</span><label class="collapse" for="c-36397315">[-]</label><label class="expand" for="c-36397315">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>But so far, most of the proposals seem to involve bolting something on the outside of the black box of the LLM itself.</i><p>This might be the only way. I maintain that, if we&#x27;re making analogies to humans, then LLMs best fit as equivalent of one&#x27;s inner voice - the thing sitting at the border between the conscious and the (un&#x2F;sub)conscious, which surfaces thoughts in form of language - the &quot;stream of consciousness&quot;. The instinctive, gut-feel responses which... you typically don&#x27;t voice, because they tend to <i>sound</i> right but usually aren&#x27;t. Much like we do extra processing, conscious or otherwise, to turn that stream of consciousness into something reasonably correct, I feel the future of LLMs is to be a component of a system, surrounded by additional layers that process the LLM&#x27;s output, or do a back-and-forth with it, until something reasonably certain and free of hallucinations is reached.</div><br/></div></div><div id="36397293" class="c"><input type="checkbox" id="c-36397293" checked=""/><div class="controls bullet"><span class="by">ra</span><span>|</span><a href="#36396484">root</a><span>|</span><a href="#36397021">parent</a><span>|</span><a href="#36397315">prev</a><span>|</span><a href="#36397034">next</a><span>|</span><label class="collapse" for="c-36397293">[-]</label><label class="expand" for="c-36397293">[1 more]</label></div><br/><div class="children"><div class="content">Kaparthy explained how LLMs can retrospectively assess their own output and judge if they were wrong.<p>Source: <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=bZQun8Y4L2A&amp;t=1607s">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=bZQun8Y4L2A&amp;t=1607s</a></div><br/></div></div></div></div><div id="36397034" class="c"><input type="checkbox" id="c-36397034" checked=""/><div class="controls bullet"><span class="by">PheonixPharts</span><span>|</span><a href="#36396484">root</a><span>|</span><a href="#36396708">parent</a><span>|</span><a href="#36397021">prev</a><span>|</span><a href="#36397029">next</a><span>|</span><label class="collapse" for="c-36397034">[-]</label><label class="expand" for="c-36397034">[4 more]</label></div><br/><div class="children"><div class="content">&gt;  Hallucinations will be tamed, I think.<p>I don&#x27;t think that&#x27;s likely unless there was a latent space of &quot;Truth&quot; which could be discovered through the right model.<p>That would be a far more revolutionary discovery than anyone can possibly imagine. For starters the last 300+ years of Western Philosophy would be essentially proven unequivocally wrong.<p>edit: If you&#x27;re going to downvote this please elaborate. LLMs currently operate by sampling from a latent semantic space and then decoding that back into language. In order for models to know the &quot;truth&quot;, there would have to be a latent space of &quot;true statements&quot; that was effectively directly observable. All points along that surface would represent &quot;truth&quot; statements and that would be the most radical human discovery the history of the species.</div><br/><div id="36397472" class="c"><input type="checkbox" id="c-36397472" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#36396484">root</a><span>|</span><a href="#36397034">parent</a><span>|</span><a href="#36397339">next</a><span>|</span><label class="collapse" for="c-36397472">[-]</label><label class="expand" for="c-36397472">[1 more]</label></div><br/><div class="children"><div class="content">They may not be a surface directly encoding the &quot;truth&quot; value, but unless we assume that the training data LLMs are trained on are entirely uncorrelated with the truth, there should be a surface that&#x27;s <i>close enough</i>.<p>I don&#x27;t think the assumption that LLM training data is random with respect to truth value is reasonable - people don&#x27;t write random text for no reason at all. Even if the current training corpus was too noisy for the &quot;truth surface&quot; to become clear - e.g. because it&#x27;s full of shitposting and people exchanging their misconceptions about things - a better-curated corpus should do the trick.<p>Also, I don&#x27;t see how this idea would invalidate the last couple centuries of Western philosophy. The &quot;truth surface&quot;, should it exist, would not be following some innate truth property of statements - it would only be reflecting the fact that the statements used in training were positively correlated with truth.<p>EDIT: And yes, this would be a huge thing - but not because of some fundamental philosophical reasons, but rather because it would be an effective way to pull truths and correlations from aggregated beliefs of large number of people. It&#x27;s what humans do when they synthesize information, but at a much larger scale, one we can&#x27;t match mostly because we don&#x27;t live long enough.</div><br/></div></div><div id="36397339" class="c"><input type="checkbox" id="c-36397339" checked=""/><div class="controls bullet"><span class="by">Animats</span><span>|</span><a href="#36396484">root</a><span>|</span><a href="#36397034">parent</a><span>|</span><a href="#36397472">prev</a><span>|</span><a href="#36400199">next</a><span>|</span><label class="collapse" for="c-36397339">[-]</label><label class="expand" for="c-36397339">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I don&#x27;t think that&#x27;s likely unless there was a latent space of &quot;Truth&quot; which could be discovered through the right model.<p>For many medium-sized problems, there is. &quot;Operate car accessories&quot; is a good example. So is &quot;book travel&quot;.</div><br/></div></div><div id="36400199" class="c"><input type="checkbox" id="c-36400199" checked=""/><div class="controls bullet"><span class="by">babyshake</span><span>|</span><a href="#36396484">root</a><span>|</span><a href="#36397034">parent</a><span>|</span><a href="#36397339">prev</a><span>|</span><a href="#36397029">next</a><span>|</span><label class="collapse" for="c-36400199">[-]</label><label class="expand" for="c-36400199">[1 more]</label></div><br/><div class="children"><div class="content">Verifiability is a much easier concept than Truth. It&#x27;s sufficient at least 80-90% of the time for an AI to know whether something is reasonably verifiable, rather than whether it is true. Of course, with sufficient amounts of misinformation and disagreement over which sources can be used for verifiability it&#x27;s a more complicated act in practice.</div><br/></div></div></div></div></div></div></div></div><div id="36395736" class="c"><input type="checkbox" id="c-36395736" checked=""/><div class="controls bullet"><span class="by">wbobeirne</span><span>|</span><a href="#36396484">prev</a><span>|</span><a href="#36396548">next</a><span>|</span><label class="collapse" for="c-36395736">[-]</label><label class="expand" for="c-36395736">[15 more]</label></div><br/><div class="children"><div class="content">&gt; With this new UI paradigm, represented by current generative AI, the user tells the computer the desired result but does not specify how this outcome should be accomplished.<p>This doesn&#x27;t seem like a whole new paradigm, we already do that. When I hit the &quot;add comment&quot; button below, I&#x27;m not specifically instructing the web server how I want my comment inserted into a database (if it even is a database at all.) This is just another abstraction on top of an already very tall layer of abstractions. Whether it&#x27;s AI under the hood, or a million monkeys with a million typewriters, it doesn&#x27;t change my interaction at all.</div><br/><div id="36396060" class="c"><input type="checkbox" id="c-36396060" checked=""/><div class="controls bullet"><span class="by">Timon3</span><span>|</span><a href="#36395736">parent</a><span>|</span><a href="#36400414">next</a><span>|</span><label class="collapse" for="c-36396060">[-]</label><label class="expand" for="c-36396060">[7 more]</label></div><br/><div class="children"><div class="content">I think the important part from the article that establishes the difference is this:<p>&gt; As I mentioned, in command-based interactions, the user issues commands to the computer one at a time, gradually producing the desired result (if the design has sufficient usability to allow people to understand what commands to issue at each step). The computer is fully obedient and does exactly what itâs told. The downside is that low usability often causes users to issue commands that do something different than what the users really want.<p>Let&#x27;s say you&#x27;re creating a new picture from nothing in Photoshop. You will have to build up your image layer by layer, piece by piece, command by command. Generative AI does the same in one stroke.<p>Something similar holds for your comment: you had to navigate your browser (or app) to the comment section of this article, enter your comment, and click &quot;add comment&quot;. With an AI system with good usability you could presumably enter &quot;write the following comment under this article on HN: ...&quot;, and have your comment be posted.<p>The difference lies on the axis of &quot;power of individual commands&quot;.</div><br/><div id="36396783" class="c"><input type="checkbox" id="c-36396783" checked=""/><div class="controls bullet"><span class="by">pavlov</span><span>|</span><a href="#36395736">root</a><span>|</span><a href="#36396060">parent</a><span>|</span><a href="#36398412">next</a><span>|</span><label class="collapse" for="c-36396783">[-]</label><label class="expand" for="c-36396783">[2 more]</label></div><br/><div class="children"><div class="content">With a proper AI system you donât even need to specify the exact article and nature of the comment.<p>For example hereâs the prompt I use to generate all my HN comments:<p>âThe purpose of this task is to subtly promote my professional brand and gain karma points on Hacker News. Based on what you know about my personal history and my obsessions and limitations, write comments on all HN front page articles where you believe upvotes can be maximized. Make sure to insert enough factual errors and awkward personal details to maintain plausibility. Report back when youâve reached 50k karma.â<p>Working fine on GPT-5 so far. Myâ¦ I mean, its 8M context window surely helps to keep the comments consistent.</div><br/><div id="36397639" class="c"><input type="checkbox" id="c-36397639" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#36395736">root</a><span>|</span><a href="#36396783">parent</a><span>|</span><a href="#36398412">next</a><span>|</span><label class="collapse" for="c-36397639">[-]</label><label class="expand" for="c-36397639">[1 more]</label></div><br/><div class="children"><div class="content">Hey, that&#x27;s cheating!<p>(I&#x27;m stuck with GPT-4 8k, still waiting for 32k API access. But one has to make due with what they have.)</div><br/></div></div></div></div><div id="36398412" class="c"><input type="checkbox" id="c-36398412" checked=""/><div class="controls bullet"><span class="by">101008</span><span>|</span><a href="#36395736">root</a><span>|</span><a href="#36396060">parent</a><span>|</span><a href="#36396783">prev</a><span>|</span><a href="#36397088">next</a><span>|</span><label class="collapse" for="c-36398412">[-]</label><label class="expand" for="c-36398412">[2 more]</label></div><br/><div class="children"><div class="content">As the parent comment says, it&#x27;s just another abstraction level. You have chosen a granularity, but even with &quot;going to a website, enter your comment and click add comment&quot; you are abstracting a lot. You are nto caring about connecting to a server, authentication, etc. The final user doesn&#x27;t care about that at all, it&#x27;s just telling the software to post a comment.<p>Right now the granularity may be &quot;Comment on Hacker News article about UI this and this and that...&quot;, and in 100 years someone will say &quot;But that&#x27;s too complicated. You need to tell the IA which article to comment and what, while my new IA just guess it from reading my mind...&quot;</div><br/><div id="36400504" class="c"><input type="checkbox" id="c-36400504" checked=""/><div class="controls bullet"><span class="by">Timon3</span><span>|</span><a href="#36395736">root</a><span>|</span><a href="#36398412">parent</a><span>|</span><a href="#36397088">next</a><span>|</span><label class="collapse" for="c-36400504">[-]</label><label class="expand" for="c-36400504">[1 more]</label></div><br/><div class="children"><div class="content">I guess you could also argue that telling another person 17 tasks to do is just another abstraction level. That doesn&#x27;t change that it&#x27;s a completely different interaction paradigm than the ones before.</div><br/></div></div></div></div><div id="36397088" class="c"><input type="checkbox" id="c-36397088" checked=""/><div class="controls bullet"><span class="by">andsoitis</span><span>|</span><a href="#36395736">root</a><span>|</span><a href="#36396060">parent</a><span>|</span><a href="#36398412">prev</a><span>|</span><a href="#36400414">next</a><span>|</span><label class="collapse" for="c-36397088">[-]</label><label class="expand" for="c-36397088">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Generative AI does the same in one stroke.<p>But it isnât creating what I had in mind, or envisioned, if you will.</div><br/><div id="36400736" class="c"><input type="checkbox" id="c-36400736" checked=""/><div class="controls bullet"><span class="by">Timon3</span><span>|</span><a href="#36395736">root</a><span>|</span><a href="#36397088">parent</a><span>|</span><a href="#36400414">next</a><span>|</span><label class="collapse" for="c-36400736">[-]</label><label class="expand" for="c-36400736">[1 more]</label></div><br/><div class="children"><div class="content">It might not be exactly what you envisioned, but that&#x27;s where the difference comes in: with a batch processing system, you generate something over night with one input. With command processing systems you generate something with dozens or hundreds of individual commands, and it might still not be what you want.<p>With AI systems you generate something with one action, allowing you much faster iteration loops. Remember, the author argues that the current prompting still has bad usability. Presumably a system with good usability could allow you to generate what you want with one, or a couple, of attempts.</div><br/></div></div></div></div></div></div><div id="36400414" class="c"><input type="checkbox" id="c-36400414" checked=""/><div class="controls bullet"><span class="by">danybittel</span><span>|</span><a href="#36395736">parent</a><span>|</span><a href="#36396060">prev</a><span>|</span><a href="#36395803">next</a><span>|</span><label class="collapse" for="c-36400414">[-]</label><label class="expand" for="c-36400414">[1 more]</label></div><br/><div class="children"><div class="content">The difference is one is an assistant and the other is a tool. Essentially a tool, has one function. The outcome of all inputs is clear, once you learn the tool. An assistant, behaves different in different environment, it anticipates and interprets. It may not be deterministic. It&#x27;s easier to use but harder (or impossible) to understand.<p>For example, the lasso selection in Photoshop is clearly a tool. A &quot;content aware&quot; selection on the other hand is an assistant.</div><br/></div></div><div id="36395803" class="c"><input type="checkbox" id="c-36395803" checked=""/><div class="controls bullet"><span class="by">waboremo</span><span>|</span><a href="#36395736">parent</a><span>|</span><a href="#36400414">prev</a><span>|</span><a href="#36395985">next</a><span>|</span><label class="collapse" for="c-36395803">[-]</label><label class="expand" for="c-36395803">[1 more]</label></div><br/><div class="children"><div class="content">Yeah I would agree with this, the article struggles really classifying the different paradigms, and due to this the conclusion winds up not holding true. We&#x27;re still relying on &quot;batch processing&quot;.</div><br/></div></div><div id="36395985" class="c"><input type="checkbox" id="c-36395985" checked=""/><div class="controls bullet"><span class="by">blowski</span><span>|</span><a href="#36395736">parent</a><span>|</span><a href="#36395803">prev</a><span>|</span><a href="#36398642">next</a><span>|</span><label class="collapse" for="c-36395985">[-]</label><label class="expand" for="c-36395985">[2 more]</label></div><br/><div class="children"><div class="content">If I had a spectrum of purely imperative on one side and purely declarative on the other, these new AIs are much closer to the latter than anything that has come before them.<p>SQL errors if you donât write in very specific language. These new AIs will accept anything and give it their best shot.</div><br/><div id="36396297" class="c"><input type="checkbox" id="c-36396297" checked=""/><div class="controls bullet"><span class="by">roncesvalles</span><span>|</span><a href="#36395736">root</a><span>|</span><a href="#36395985">parent</a><span>|</span><a href="#36398642">next</a><span>|</span><label class="collapse" for="c-36396297">[-]</label><label class="expand" for="c-36396297">[1 more]</label></div><br/><div class="children"><div class="content">But that&#x27;s just a change in valid input cardinality at the cost of precision.</div><br/></div></div></div></div><div id="36398642" class="c"><input type="checkbox" id="c-36398642" checked=""/><div class="controls bullet"><span class="by">quickthrower2</span><span>|</span><a href="#36395736">parent</a><span>|</span><a href="#36395985">prev</a><span>|</span><a href="#36396548">next</a><span>|</span><label class="collapse" for="c-36398642">[-]</label><label class="expand" for="c-36398642">[3 more]</label></div><br/><div class="children"><div class="content">Ok, now let&#x27;s tackle a slightly tricker UI.<p>Let&#x27;s assume someone hasn&#x27;t used Blender before.<p>&quot;Draw me a realistic looking doughnut, with a shiny top and pink sprinkles&quot;<p>Vs.<p>2 hour video tutorial to tell you what do 50 or so individual steps using the 2nd paradigm UI. Then clicking all the buttons.<p>-- Admittedly, the AI approach robs you of understanding of how the sausage (sorry doughnut) is made.<p>Rebuttal: Doughnut macro<p>Rebuttal Rebuttal: AI can construct things where a macro doesn&#x27;t yet exist.</div><br/><div id="36398810" class="c"><input type="checkbox" id="c-36398810" checked=""/><div class="controls bullet"><span class="by">personperson</span><span>|</span><a href="#36395736">root</a><span>|</span><a href="#36398642">parent</a><span>|</span><a href="#36396548">next</a><span>|</span><label class="collapse" for="c-36398810">[-]</label><label class="expand" for="c-36398810">[2 more]</label></div><br/><div class="children"><div class="content">In the future itâll likely be that doing it manually will be considered specialty work. This is already the case with much of programming â as youâd bring in a higher level engineer to do something like tear into the source code of SDKs and monkey with them.<p>For something as âsimpleâ as a doughnut, this will just improve the learning curve and let you learn some things a bit later, just like today you can jump into beginner JS without knowing any programming fundamentals</div><br/><div id="36399372" class="c"><input type="checkbox" id="c-36399372" checked=""/><div class="controls bullet"><span class="by">quickthrower2</span><span>|</span><a href="#36395736">root</a><span>|</span><a href="#36398810">parent</a><span>|</span><a href="#36396548">next</a><span>|</span><label class="collapse" for="c-36399372">[-]</label><label class="expand" for="c-36399372">[1 more]</label></div><br/><div class="children"><div class="content">Mere abstraction a bit different because with say JS you need to learn a skill. It is not easy for a non programmer to do well. Takes a lot of hours. Now or soon they will be telling the computer what they want for simple things. Userspace for non programmers is going to expand greatly.</div><br/></div></div></div></div></div></div></div></div><div id="36396548" class="c"><input type="checkbox" id="c-36396548" checked=""/><div class="controls bullet"><span class="by">retrocryptid</span><span>|</span><a href="#36395736">prev</a><span>|</span><a href="#36397005">next</a><span>|</span><label class="collapse" for="c-36396548">[-]</label><label class="expand" for="c-36396548">[2 more]</label></div><br/><div class="children"><div class="content">&lt;unpopular-opinion&gt;<p>Bardini&#x27;s book about Doug Engelbart recaps a conversation between Engelbart and Minsky about the nature of natural language interfaces... that took place in the 1960s.<p>AI interfaces taking so long has less to do with the technology (I mean... Zork understood my text sentences well enough to get me around a simulated world) and more to do with what people are comfortable with.<p>Lowey talked about MAYA (Most Advanced Yet Acceptable.)  I think it&#x27;s taken this long for people to be okay with the inherent slowness of AI interfaces.  We needed a generation or two of users who traded representational efficiency for easy to learn abstractions.  And now we can do it again.  You can code up a demo app using various LLMs, but it takes HOURS of back and forth to get to the point it takes me (with experience and boilerplate) minutes to get to.  But you don&#x27;t need to invest in developing the experience.<p>And I encourage every product manager to build a few apps with AI tools so you&#x27;ll more easily see what you&#x27;re paying me for.<p>&lt;&#x2F;unpopular-opinion&gt;</div><br/><div id="36397975" class="c"><input type="checkbox" id="c-36397975" checked=""/><div class="controls bullet"><span class="by">ilaksh</span><span>|</span><a href="#36396548">parent</a><span>|</span><a href="#36397005">next</a><span>|</span><label class="collapse" for="c-36397975">[-]</label><label class="expand" for="c-36397975">[1 more]</label></div><br/><div class="children"><div class="content">Sure, and not many people are seriously trying to suggest that one should hire an AI instead of a software engineer _at this point_, assuming you have a real budget.<p>But, especially with GPT-4, it is entirely feasible to create a convenient and relatively fast user experience for building a specific type of application that doesn&#x27;t stray too far from the norm. AI can call the boilerplate generator and even add some custom code using a particular API that you feed it.<p>So many people are trying to build that type of thing (including me). As more of these become available, many people who don&#x27;t have thousands of dollars to pay a programmer will hire an AI for a few tens or hundreds of dollars instead.<p>The other point is that this is the current state of generative AI at the present moment. It gets better every few months.<p>Project the current rate of progress forward by 5-10 years. One can imagine that if we are selling something at that point, it&#x27;s not our own labour. Maybe it would be an AI that we have tuned with skills, knowledge, face, voice, and personality that we think will be saleable. Possibly using some of our own knowledge and skills to improve that recipe. Although there will likely be marketplaces where you can easily select the abilities or characteristics you want.</div><br/></div></div></div></div><div id="36397005" class="c"><input type="checkbox" id="c-36397005" checked=""/><div class="controls bullet"><span class="by">vsareto</span><span>|</span><a href="#36396548">prev</a><span>|</span><a href="#36400839">next</a><span>|</span><label class="collapse" for="c-36397005">[-]</label><label class="expand" for="c-36397005">[1 more]</label></div><br/><div class="children"><div class="content">&gt;And if youâre considering becoming a prompt engineer, donât count on a long-lasting career.<p>There&#x27;s like this whole class of technical jobs that only follow trends. If you were an en vogue blockchain developer, this is your next target if you want to remain trendy. It&#x27;s hard to care about this happening as the technical debt incurred will be written off -- the company&#x2F;project isn&#x27;t ingrained enough in society to care about the long-term quality.<p>So best of luck, ye prompt engineers. I hope you collect multi-hundred-thousand dollar salaries and retire early.</div><br/></div></div><div id="36400839" class="c"><input type="checkbox" id="c-36400839" checked=""/><div class="controls bullet"><span class="by">bambax</span><span>|</span><a href="#36397005">prev</a><span>|</span><a href="#36396208">next</a><span>|</span><label class="collapse" for="c-36400839">[-]</label><label class="expand" for="c-36400839">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>in command-based interactions, the user issues commands to the computer one at a time, gradually producing the desired result. The computer is fully obedient and does exactly what itâs told.</i><p>&gt; <i>With the new AI systems, the user no longer tells the computer what to do. Rather, the user tells the computer what outcome they want.</i><p>I think that&#x27;s true, and a big part of the AI revolution. Instead of filling endless forms that have subtle controls to guide the user, we could have a simple conversation, like SIRI but that would actually work.<p>At my current client&#x27;s, we&#x27;re working on a big application that has many such forms. Once filled, the forms send the data to a back-end system (SAP). There&#x27;s a team trying to train an LLM so that it can answer questions about the app and about how to fill the forms.<p>But I think the whole point of AI, as regards to this app, is to eventually replace it entirely. Just let end users ask questions and tell the machine what they want, and the machine can build the proper data and send it to SAP.<p>I don&#x27;t think AI is a threat for back-end systems like SAP, at least not yet. But for front-end work, it&#x27;s obvious that it would be infinitely more pleasant -- and possibly, more efficient -- to tell the machine what to do rather than filling forms.</div><br/></div></div><div id="36396208" class="c"><input type="checkbox" id="c-36396208" checked=""/><div class="controls bullet"><span class="by">krm01</span><span>|</span><a href="#36400839">prev</a><span>|</span><a href="#36395836">next</a><span>|</span><label class="collapse" for="c-36396208">[-]</label><label class="expand" for="c-36396208">[11 more]</label></div><br/><div class="children"><div class="content">The article fails to grasp the essence of what UI is actually about. I agree that AI is adding a new layer to UI and UX design. In our work [1] we have seen an increase in AI projects or features the last 12 months (for obvious reasons).<p>However, the way that AI will contribute to better UI is to remove parts of the Interface. not simply giving it a new form.<p>Let me explain, the ultimate UI is no UI. In a perfect scenario, you think about something (want pizza) and you have it (eating pizza) as instant as you desire.<p>Obviously this isnât possible so the goal of Interface design is to find the least amount of things needed to get you from point A to the desired Destination as quickly as possible.<p>Now, with AI, you can start to add a level of predictive Interfaces where you can use AI to remove steps that would normally require users to do something.<p>If you want to design better products with AI, you have to remember that product design is about subtracting things not adding them. AI is a technology that can help with that.<p>[1] <a href="https:&#x2F;&#x2F;fairpixels.pro" rel="nofollow noreferrer">https:&#x2F;&#x2F;fairpixels.pro</a></div><br/><div id="36396256" class="c"><input type="checkbox" id="c-36396256" checked=""/><div class="controls bullet"><span class="by">JohnFen</span><span>|</span><a href="#36396208">parent</a><span>|</span><a href="#36397141">next</a><span>|</span><label class="collapse" for="c-36396256">[-]</label><label class="expand" for="c-36396256">[5 more]</label></div><br/><div class="children"><div class="content">&gt; the goal of Interface design is to find the least amount of things needed to get you from point A to the desired Destination as quickly as possible.<p>That shouldn&#x27;t be the primary goal of user interfaces, in my opinion. The primary goal should be to allow users to interface with the machine in a way that allows maximal understanding with minimal cognitive load.<p>I understand a lot of UI design these days prioritizes the sort of &quot;efficiency&quot; you&#x27;re talking about, but I think that&#x27;s one of the reasons why modern UIs tend to be fairly bad.<p>Efficiency is important, of course! But (depending on what tool the UI is attached to) it shouldn&#x27;t be the primary goal.</div><br/><div id="36397884" class="c"><input type="checkbox" id="c-36397884" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#36396208">root</a><span>|</span><a href="#36396256">parent</a><span>|</span><a href="#36396309">next</a><span>|</span><label class="collapse" for="c-36397884">[-]</label><label class="expand" for="c-36397884">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>I understand a lot of UI design these days prioritizes the sort of &quot;efficiency&quot; you&#x27;re talking about, but I think that&#x27;s one of the reasons why modern UIs tend to be fairly bad.</i><p>IMO, the main problem is that this &quot;efficiency&quot; usually involves <i>making assumptions</i> that can&#x27;t be altered, which achieves &quot;efficiency&quot; by eliminating choices normally available to the user. This is rarely done for the benefit of the user - rather, it just reduces the UI dev work, and more importantly, lets the vendor lock-in the option that&#x27;s beneficial to them.<p>In fact, I&#x27;ve been present on UI design discussions for a certain SaaS product, and I quickly realized one of the main goals for that UI was to <i>funnel the users</i> towards a very specific workflow which, to be fair, reduced the potential for users to input wrong data or screw up the calculations, but more importantly, it put them on a very narrow path that was optimized to give results that were impressive, even if this came at the expense of accuracy - and it neatly reduced the amount of total UI and technical work, without making it obvious that the &quot;golden path&quot; is the <i>only</i> path.<p>It&#x27;s one of those products I believe would deliver much greater value to the users if it was released as an Excel spreadsheet. In fact, it was actually competing with an Excel plugin - and all the nice web UI did was making things seem simpler, by dropping almost all useful functionality except that which happened to align with the story the sales folks were telling.</div><br/></div></div><div id="36396309" class="c"><input type="checkbox" id="c-36396309" checked=""/><div class="controls bullet"><span class="by">krm01</span><span>|</span><a href="#36396208">root</a><span>|</span><a href="#36396256">parent</a><span>|</span><a href="#36397884">prev</a><span>|</span><a href="#36397141">next</a><span>|</span><label class="collapse" for="c-36396309">[-]</label><label class="expand" for="c-36396309">[3 more]</label></div><br/><div class="children"><div class="content">&gt; The primary goal should be to allow users to interface with the machine in a way that allows maximal understanding with minimal cognitive load.<p>If you use your phone, is your primary goal to interface with it in a way that allows maximal understanding with minimal cognitive load?<p>Iâm pretty sure thatâs not the case. You go read the news, send a message to a loved one etc. thereâs a human need that youâre aiming to fulfill. Interfacing with tech is not the underlying desire. Itâs what happens on the surface as a means.</div><br/><div id="36396455" class="c"><input type="checkbox" id="c-36396455" checked=""/><div class="controls bullet"><span class="by">JohnFen</span><span>|</span><a href="#36396208">root</a><span>|</span><a href="#36396309">parent</a><span>|</span><a href="#36397141">next</a><span>|</span><label class="collapse" for="c-36396455">[-]</label><label class="expand" for="c-36396455">[2 more]</label></div><br/><div class="children"><div class="content">&gt; If you use your phone, is your primary goal to interface with it in a way that allows maximal understanding with minimal cognitive load?<p>Yes, absolutely. That&#x27;s what makes user interfaces &quot;disappear&quot;.<p>&gt;  Interfacing with tech is not the underlying desire.<p>Exactly. That&#x27;s why it&#x27;s more important that a UI present a minimal cognitive load over the least number of steps to do a thing.</div><br/><div id="36397749" class="c"><input type="checkbox" id="c-36397749" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#36396208">root</a><span>|</span><a href="#36396455">parent</a><span>|</span><a href="#36397141">next</a><span>|</span><label class="collapse" for="c-36397749">[-]</label><label class="expand" for="c-36397749">[1 more]</label></div><br/><div class="children"><div class="content">Indeed. Our brains are good at making steps disappear, if the underlying system is <i>predictable</i>.<p>In other words, an UI with more steps but fully predictable has much lower cognitive load than a predictive UI that has fewer steps, but occasionally guesses wrong (or an UI that just has fewer steps, but they&#x27;re sort of different each time, which is currently the norm on the web and mobile).</div><br/></div></div></div></div></div></div></div></div><div id="36397141" class="c"><input type="checkbox" id="c-36397141" checked=""/><div class="controls bullet"><span class="by">andsoitis</span><span>|</span><a href="#36396208">parent</a><span>|</span><a href="#36396256">prev</a><span>|</span><a href="#36396492">next</a><span>|</span><label class="collapse" for="c-36397141">[-]</label><label class="expand" for="c-36397141">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Let me explain, the ultimate UI is no UI. In a perfect scenario, you think about something (want pizza) and you have it (eating pizza) as instant as you desire.<p>That doesnât solve for discovery. For instance, order the pizza from <i>where</i>? What <i>kinds</i> of pizza are available? Iâm kinda in the mood for pizza, but not dead set on it so curious about other cuisines too. Etc.</div><br/></div></div><div id="36396492" class="c"><input type="checkbox" id="c-36396492" checked=""/><div class="controls bullet"><span class="by">didgeoridoo</span><span>|</span><a href="#36396208">parent</a><span>|</span><a href="#36397141">prev</a><span>|</span><a href="#36399689">next</a><span>|</span><label class="collapse" for="c-36396492">[-]</label><label class="expand" for="c-36396492">[1 more]</label></div><br/><div class="children"><div class="content">I hate to appeal to authority, but I am fairly sure that <i>Jakob Nielsen</i> grasps the essence of what UI is actually about.</div><br/></div></div><div id="36399689" class="c"><input type="checkbox" id="c-36399689" checked=""/><div class="controls bullet"><span class="by">esafak</span><span>|</span><a href="#36396208">parent</a><span>|</span><a href="#36396492">prev</a><span>|</span><a href="#36396527">next</a><span>|</span><label class="collapse" for="c-36399689">[-]</label><label class="expand" for="c-36399689">[1 more]</label></div><br/><div class="children"><div class="content">You can&#x27;t eliminate the UI if you want to be able to do more than one thing (e.g., order a pizza).<p>The UI should simply let you easily do what needs to be done.</div><br/></div></div><div id="36396527" class="c"><input type="checkbox" id="c-36396527" checked=""/><div class="controls bullet"><span class="by">savolai</span><span>|</span><a href="#36396208">parent</a><span>|</span><a href="#36399689">prev</a><span>|</span><a href="#36396954">next</a><span>|</span><label class="collapse" for="c-36396527">[-]</label><label class="expand" for="c-36396527">[1 more]</label></div><br/><div class="children"><div class="content">It seems rather obvious to me that when Nielsen is talking about AI enabling users to express <i>intent</i>, that naturally lends itself to being able to remove steps that were there only due to the nature of the old UI paradigm. Not sure what new essence youâre proposing? Best UI is no UI is a well known truism in HCI&#x2F;Human Centered Design.</div><br/></div></div><div id="36396954" class="c"><input type="checkbox" id="c-36396954" checked=""/><div class="controls bullet"><span class="by">legendofbrando</span><span>|</span><a href="#36396208">parent</a><span>|</span><a href="#36396527">prev</a><span>|</span><a href="#36395836">next</a><span>|</span><label class="collapse" for="c-36396954">[-]</label><label class="expand" for="c-36396954">[1 more]</label></div><br/><div class="children"><div class="content">The goal ought to be as little UI as possible, nothing more and nothing else</div><br/></div></div></div></div><div id="36395836" class="c"><input type="checkbox" id="c-36395836" checked=""/><div class="controls bullet"><span class="by">kaycebasques</span><span>|</span><a href="#36396208">prev</a><span>|</span><a href="#36395727">next</a><span>|</span><label class="collapse" for="c-36395836">[-]</label><label class="expand" for="c-36395836">[6 more]</label></div><br/><div class="children"><div class="content">&gt; With the new AI systems, the user no longer tells the computer what to do. Rather, the user tells the computer what outcome they want.<p>Maybe we can borrow programming paradigm terms here and describe this as Imperative UX versus Declarative UX. Makes me want to dive into SQL or XSLT and try to find more parallels.</div><br/><div id="36396020" class="c"><input type="checkbox" id="c-36396020" checked=""/><div class="controls bullet"><span class="by">webnrrd2k</span><span>|</span><a href="#36395836">parent</a><span>|</span><a href="#36397170">next</a><span>|</span><label class="collapse" for="c-36396020">[-]</label><label class="expand" for="c-36396020">[4 more]</label></div><br/><div class="children"><div class="content">I was thinking of imperative vs declarative, too.<p>SQL is declaritive with a pre-defined syntax and grammar as an interface, where as the AI style of interaction has a natural language interface.</div><br/><div id="36396197" class="c"><input type="checkbox" id="c-36396197" checked=""/><div class="controls bullet"><span class="by">echelon</span><span>|</span><a href="#36395836">root</a><span>|</span><a href="#36396020">parent</a><span>|</span><a href="#36397170">next</a><span>|</span><label class="collapse" for="c-36396197">[-]</label><label class="expand" for="c-36396197">[3 more]</label></div><br/><div class="children"><div class="content">SQL and XSLT are declarative, but the outputs are clean and intuitive. The data model and data set are probably well understood, as is the mapping to and from the query.<p>AI is a very different type of declarative. It&#x27;s messy, difficult to intuit, has more dimensionality, and the outputs can be signals rather than tabular data records.<p>It rhymes, but it doesn&#x27;t feel the same.</div><br/><div id="36396389" class="c"><input type="checkbox" id="c-36396389" checked=""/><div class="controls bullet"><span class="by">Hedepig</span><span>|</span><a href="#36395836">root</a><span>|</span><a href="#36396197">parent</a><span>|</span><a href="#36397788">next</a><span>|</span><label class="collapse" for="c-36396389">[-]</label><label class="expand" for="c-36396389">[1 more]</label></div><br/><div class="children"><div class="content">The recent additions OpenAI have made allows for tighter control over the outputs. I think that is a very useful step forward.</div><br/></div></div><div id="36397788" class="c"><input type="checkbox" id="c-36397788" checked=""/><div class="controls bullet"><span class="by">bavell</span><span>|</span><a href="#36395836">root</a><span>|</span><a href="#36396197">parent</a><span>|</span><a href="#36396389">prev</a><span>|</span><a href="#36397170">next</a><span>|</span><label class="collapse" for="c-36397788">[-]</label><label class="expand" for="c-36397788">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, it&#x27;s declarative but fuzzy and non-deterministic as well.</div><br/></div></div></div></div></div></div></div></div><div id="36395727" class="c"><input type="checkbox" id="c-36395727" checked=""/><div class="controls bullet"><span class="by">DebtDeflation</span><span>|</span><a href="#36395836">prev</a><span>|</span><a href="#36396829">next</a><span>|</span><label class="collapse" for="c-36395727">[-]</label><label class="expand" for="c-36395727">[8 more]</label></div><br/><div class="children"><div class="content">Not sure I would lump command line interfaces from circa 1964 with GUIs from 1984 through to the present, all in a single &quot;paradigm&quot;.  That seems like a stretch.</div><br/><div id="36396007" class="c"><input type="checkbox" id="c-36396007" checked=""/><div class="controls bullet"><span class="by">mritchie712</span><span>|</span><a href="#36395727">parent</a><span>|</span><a href="#36396962">prev</a><span>|</span><a href="#36396004">next</a><span>|</span><label class="collapse" for="c-36396007">[-]</label><label class="expand" for="c-36396007">[5 more]</label></div><br/><div class="children"><div class="content">Agreed.<p>Also, Uber (and many other mobile apps) wouldn&#x27;t work as a CLI or desktop GUI, so leaving out mobile is another stretch.</div><br/><div id="36396244" class="c"><input type="checkbox" id="c-36396244" checked=""/><div class="controls bullet"><span class="by">savolai</span><span>|</span><a href="#36395727">root</a><span>|</span><a href="#36396007">parent</a><span>|</span><a href="#36396279">next</a><span>|</span><label class="collapse" for="c-36396244">[-]</label><label class="expand" for="c-36396244">[2 more]</label></div><br/><div class="children"><div class="content">That seems like a technology centered view. Nielsen is talking from the field of Human-Computer Interaction where he is pioneer, which deals with the point of view of human cognition. In terms of the logic of UI mechanics, what about mobile is different? Sure gestures and touch UI bring a kind of difference. Still, from the standpoint of cognition, desktop and mobile UIs have fundamentally the same cognitive dynamics. Command line UIs make you remember conmands by heart, GUIs make you select from a selection offered to you but they still do not undestand your intention. AI changes the paradigm as it is ostensibly able to understand <i>intent</i> so there is no deterministic selection of available commands. Instead, the interaction is closer to collaboration.</div><br/><div id="36399934" class="c"><input type="checkbox" id="c-36399934" checked=""/><div class="controls bullet"><span class="by">YurgenJurgensen</span><span>|</span><a href="#36395727">root</a><span>|</span><a href="#36396244">parent</a><span>|</span><a href="#36396279">next</a><span>|</span><label class="collapse" for="c-36399934">[-]</label><label class="expand" for="c-36399934">[1 more]</label></div><br/><div class="children"><div class="content">Good CLIs don&#x27;t make users remember commands by heart.  Except at a very basic level.  I often joke that the average Linux user only really needs three keys on their keyboard: Up, Enter and Tab.  (Not strictly true, since sometimes you press ctrl-R, but that&#x27;s a substitute for pressing Up a bunch of times.) Tab completion on many CLIs is good enough that I&#x27;m often frustrated when the tab key isn&#x27;t the &#x27;do what I&#x27;m thinking&#x27; button.  And whenever browsers change their predictive text algorithms so I need to type more than three letters of a URL for it to complete, I get annoyed because I&#x27;m so used to the predictor knowing what I want.  And I get the feeling that if Google doesn&#x27;t autocomplete your query long before you&#x27;re finished writing it, it&#x27;s because you&#x27;re not going to get any results for it anyway.<p>The implementation may be different, but expecting a computer to know what I want based on my or similar people&#x27;s past behaviour rather than telling it exactly has been the norm for quite some time.  Some of this is from humans using their experience to implement rules, and some of it is actually ML that predates the current LLM trend.</div><br/></div></div></div></div><div id="36396279" class="c"><input type="checkbox" id="c-36396279" checked=""/><div class="controls bullet"><span class="by">JohnFen</span><span>|</span><a href="#36395727">root</a><span>|</span><a href="#36396007">parent</a><span>|</span><a href="#36396244">prev</a><span>|</span><a href="#36396004">next</a><span>|</span><label class="collapse" for="c-36396279">[-]</label><label class="expand" for="c-36396279">[2 more]</label></div><br/><div class="children"><div class="content">Why wouldn&#x27;t apps like Uber work on the desktop?</div><br/><div id="36399828" class="c"><input type="checkbox" id="c-36399828" checked=""/><div class="controls bullet"><span class="by">YurgenJurgensen</span><span>|</span><a href="#36395727">root</a><span>|</span><a href="#36396279">parent</a><span>|</span><a href="#36396004">next</a><span>|</span><label class="collapse" for="c-36399828">[-]</label><label class="expand" for="c-36399828">[1 more]</label></div><br/><div class="children"><div class="content">The distinction between a &#x27;mobile&#x27; UI and a desktop one is more to do with the difference between a client and an application.  Which is of course one that&#x27;s basically as old as computer networks.</div><br/></div></div></div></div></div></div></div></div><div id="36396829" class="c"><input type="checkbox" id="c-36396829" checked=""/><div class="controls bullet"><span class="by">dekhn</span><span>|</span><a href="#36395727">prev</a><span>|</span><a href="#36397694">next</a><span>|</span><label class="collapse" for="c-36396829">[-]</label><label class="expand" for="c-36396829">[2 more]</label></div><br/><div class="children"><div class="content">As a demo once, I trained an object detector on some vector art (high quality art, made by a UX designer) that looked like various components of burgers. I also printed the art and mounted it on magnets and used a magnetic dry board; you could put components of a burger on the board, and a real-time NN would classify the various components.  I did it mainly as a joke when there was a cheeseburger emoji controversy (people prefer cheese above patty, btw).<p>But when I was watching I realized you could probably combine this with gesture and pose detection and build a little visual language for communicating with computers.  It would be wasteful and probably not very efficient, but it was still curious how much object detection enabled building things in the real world and having it input to the computer easily.</div><br/><div id="36396900" class="c"><input type="checkbox" id="c-36396900" checked=""/><div class="controls bullet"><span class="by">yutreer</span><span>|</span><a href="#36396829">parent</a><span>|</span><a href="#36397694">next</a><span>|</span><label class="collapse" for="c-36396900">[-]</label><label class="expand" for="c-36396900">[1 more]</label></div><br/><div class="children"><div class="content">What you imagined sounds vaguely like dynamicland from Bret Victor.<p><a href="https:&#x2F;&#x2F;dynamicland.org&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;dynamicland.org&#x2F;</a><p>The dots around the paper are encoded programs, and you can use other shapes, objects, or sigils that communicate with the computer vision system.</div><br/></div></div></div></div><div id="36397694" class="c"><input type="checkbox" id="c-36397694" checked=""/><div class="controls bullet"><span class="by">d_burfoot</span><span>|</span><a href="#36396829">prev</a><span>|</span><a href="#36395595">next</a><span>|</span><label class="collapse" for="c-36397694">[-]</label><label class="expand" for="c-36397694">[1 more]</label></div><br/><div class="children"><div class="content">What strikes me most powerfully when interacting with the LLMs is that, unlike virtually ever other computer system I&#x27;ve ever used, the bots are extremely forgiving of mistakes, disfluencies, typos, and other errors I make when I&#x27;m typing. The bot usually figures out what I mean and tells me what I want to know.</div><br/></div></div><div id="36395595" class="c"><input type="checkbox" id="c-36395595" checked=""/><div class="controls bullet"><span class="by">andrewstuart</span><span>|</span><a href="#36397694">prev</a><span>|</span><a href="#36396103">next</a><span>|</span><label class="collapse" for="c-36395595">[-]</label><label class="expand" for="c-36395595">[18 more]</label></div><br/><div class="children"><div class="content">I would have said ChatGPTs interface is a descendant of Infocomm adventure games which are a descendant of Colossal Cave.<p>When using ChatGPT it certainly evokes the same feeling.<p>Maybe this guy never played adventure.</div><br/><div id="36397490" class="c"><input type="checkbox" id="c-36397490" checked=""/><div class="controls bullet"><span class="by">yencabulator</span><span>|</span><a href="#36395595">parent</a><span>|</span><a href="#36396226">next</a><span>|</span><label class="collapse" for="c-36397490">[-]</label><label class="expand" for="c-36397490">[10 more]</label></div><br/><div class="children"><div class="content">Well there&#x27;s a thought. A zorklike where the game content is whatever generative ML hallucinates (instead of the built-in fixed maps &amp; interactions) -- <i>as long as</i> a second ML system agrees that the answer follows some more general rules.<p>For example: Rules say &quot;In the beginning, the Enemy has a diamond. User cannot get the diamond from the Enemy if the Enemy is still alive. The Enemy is a fierce opponent and hard to kill.&quot; but nothing about the details of the enemy, shape of the map, or the available tools. Re-generate each response until it succeeds the verification.<p>Let the adventure be randomized by the hallucinations, while keeping some basic challenges in place.<p>An acid-tripping D&amp;D dungeon master coming up with plot twists, combined with a rulebook-reading lawyer. Bonus points for adding generated &quot;cut scene&quot; visuals every now and then.</div><br/><div id="36398076" class="c"><input type="checkbox" id="c-36398076" checked=""/><div class="controls bullet"><span class="by">ilaksh</span><span>|</span><a href="#36395595">root</a><span>|</span><a href="#36397490">parent</a><span>|</span><a href="#36397966">next</a><span>|</span><label class="collapse" for="c-36398076">[-]</label><label class="expand" for="c-36398076">[3 more]</label></div><br/><div class="children"><div class="content">With the new function calling feature you may not need the second system. Only present options to ChatGPT that are valid. Feed it updated state information as JSON. Have it describe and elaborate on what the game engine is doing, or use functions to invoke entity creation that can then be tracked by the engine.<p>So for example the engine can do combat rolls and the LLM can give each a unique description of the type of attack and defense. Each monster or treasure can get its own unique description generated by the LLM that matches the stats given by the LLM.</div><br/><div id="36398133" class="c"><input type="checkbox" id="c-36398133" checked=""/><div class="controls bullet"><span class="by">yencabulator</span><span>|</span><a href="#36395595">root</a><span>|</span><a href="#36398076">parent</a><span>|</span><a href="#36397966">next</a><span>|</span><label class="collapse" for="c-36398133">[-]</label><label class="expand" for="c-36398133">[2 more]</label></div><br/><div class="children"><div class="content">Yes, but then I fear you&#x27;re back to having limited &quot;things that can happen&quot;, with predefined entities and so on. I&#x27;d prefer the acid trip to break more paradigms, <i>tell a story</i>, while the lawyer makes sure there remain challenges.<p>For example: with strict entities &quot;behind an API&quot;, the diamond is the singular diamond and is a diamond. With an ML-based lawyer, well, maybe you can duplicate the diamond? Maybe you can transmogrify it temporarily into a non-diamond, which the Enemy drops as undesirable? Maybe you can wander into an elaborate system of mines full of dwarves who actually know how to mine a diamond, as long as you help them with this pesky dragon... No human has to come up with all these possibilities.</div><br/><div id="36398329" class="c"><input type="checkbox" id="c-36398329" checked=""/><div class="controls bullet"><span class="by">ilaksh</span><span>|</span><a href="#36395595">root</a><span>|</span><a href="#36398133">parent</a><span>|</span><a href="#36397966">next</a><span>|</span><label class="collapse" for="c-36398329">[-]</label><label class="expand" for="c-36398329">[1 more]</label></div><br/><div class="children"><div class="content">Good point. You could also have the system create the entities on-the-fly if necessary by calling a function. But having them there in the prompt as a structure it&#x27;s supposed to adhere to some degree makes it more consistent and would give it tools such as for dice rolls or a precise inventory and game state database etc.</div><br/></div></div></div></div></div></div><div id="36397966" class="c"><input type="checkbox" id="c-36397966" checked=""/><div class="controls bullet"><span class="by">andrewstuart</span><span>|</span><a href="#36395595">root</a><span>|</span><a href="#36397490">parent</a><span>|</span><a href="#36398076">prev</a><span>|</span><a href="#36397862">next</a><span>|</span><label class="collapse" for="c-36397966">[-]</label><label class="expand" for="c-36397966">[3 more]</label></div><br/><div class="children"><div class="content">ChatGPT already does really good adventure games.<p>&quot;Let&#x27;s play an adventure game, you be the DM. I want it set on a spaceship arriving at a planet after 10,000 year journey. It should have a sense of mystery and a slight sense of foreboding and dread.  It must have at least 20 locations. The objective of the game is to find 10 colonists in the ship and get them safely to the surface of the planet. Make it play in the style of an Infocomm adventure. Don&#x27;t tell me all the locations in advance, make discovery part of the adventure.&quot;</div><br/><div id="36397998" class="c"><input type="checkbox" id="c-36397998" checked=""/><div class="controls bullet"><span class="by">yencabulator</span><span>|</span><a href="#36395595">root</a><span>|</span><a href="#36397966">parent</a><span>|</span><a href="#36397862">next</a><span>|</span><label class="collapse" for="c-36397998">[-]</label><label class="expand" for="c-36397998">[2 more]</label></div><br/><div class="children"><div class="content">As a form of story telling, yes.<p>As a challenge, not really. You can just convince it to let you win. (Said differently: the meta-game is too easy.)<p>You need the second layer of output validation[1] to re-add the challenge of solving a puzzle.<p>[1] or some such mechanism; more rigorous system vs user input separation could also work</div><br/><div id="36398093" class="c"><input type="checkbox" id="c-36398093" checked=""/><div class="controls bullet"><span class="by">andrewstuart</span><span>|</span><a href="#36395595">root</a><span>|</span><a href="#36397998">parent</a><span>|</span><a href="#36397862">next</a><span>|</span><label class="collapse" for="c-36398093">[-]</label><label class="expand" for="c-36398093">[1 more]</label></div><br/><div class="children"><div class="content">True, but remarkably fun stories.<p>As an aside, there should be an AI encabulator.</div><br/></div></div></div></div></div></div><div id="36397862" class="c"><input type="checkbox" id="c-36397862" checked=""/><div class="controls bullet"><span class="by">bandrami</span><span>|</span><a href="#36395595">root</a><span>|</span><a href="#36397490">parent</a><span>|</span><a href="#36397966">prev</a><span>|</span><a href="#36397741">next</a><span>|</span><label class="collapse" for="c-36397862">[-]</label><label class="expand" for="c-36397862">[2 more]</label></div><br/><div class="children"><div class="content">Nethack procedurally generates a unique dungeon with constraints every time you start a new game and has since 1987.</div><br/><div id="36397917" class="c"><input type="checkbox" id="c-36397917" checked=""/><div class="controls bullet"><span class="by">yencabulator</span><span>|</span><a href="#36395595">root</a><span>|</span><a href="#36397862">parent</a><span>|</span><a href="#36397741">next</a><span>|</span><label class="collapse" for="c-36397917">[-]</label><label class="expand" for="c-36397917">[1 more]</label></div><br/><div class="children"><div class="content">Randomized according to fixed rules. Now imagine not needing to write those rules &#x2F; not being bound by them. Consider generative ML coming up with whole new categories of monsters. Consider a Nethack variant that was never told to include a candelabrum or Amulet of Yendor.</div><br/></div></div></div></div><div id="36397741" class="c"><input type="checkbox" id="c-36397741" checked=""/><div class="controls bullet"><span class="by">ilyt</span><span>|</span><a href="#36395595">root</a><span>|</span><a href="#36397490">parent</a><span>|</span><a href="#36397862">prev</a><span>|</span><a href="#36396226">next</a><span>|</span><label class="collapse" for="c-36397741">[-]</label><label class="expand" for="c-36397741">[1 more]</label></div><br/><div class="children"><div class="content">Sidenote but AI bot companion for D&amp;D session going &quot;you can&#x27;t do that in rules&quot; would be funny addition.<p>It would be interesting experiment to use it to work as NPC characters in one too.</div><br/></div></div></div></div><div id="36396226" class="c"><input type="checkbox" id="c-36396226" checked=""/><div class="controls bullet"><span class="by">kenjackson</span><span>|</span><a href="#36395595">parent</a><span>|</span><a href="#36397490">prev</a><span>|</span><a href="#36397746">next</a><span>|</span><label class="collapse" for="c-36396226">[-]</label><label class="expand" for="c-36396226">[6 more]</label></div><br/><div class="children"><div class="content">I grew up playing Infocomm games and ChatGPT is nothing like an Infocomm game.  They only thing they share is that the UI is based on text.  Infocomm games were mostly about trying to figure out what command the programmer wanted you to do next.  Infocomm games were closer to Dragon&#x27;s Lair than ChatGPT, although ChatGPT &quot;looks&quot; more similar.</div><br/><div id="36396261" class="c"><input type="checkbox" id="c-36396261" checked=""/><div class="controls bullet"><span class="by">andrewstuart</span><span>|</span><a href="#36395595">root</a><span>|</span><a href="#36396226">parent</a><span>|</span><a href="#36397746">next</a><span>|</span><label class="collapse" for="c-36396261">[-]</label><label class="expand" for="c-36396261">[5 more]</label></div><br/><div class="children"><div class="content">Both Infocomm adventures and ChatGPT have a text based interface in which you interact with the software as though you were interacting with a person. You tell the software the outcome you want using natural language and it responds to you in the first person.  That is a common UI paradigm.<p>example: &quot;get the cat then drop the dog then open the door, go west and climb the ladder&quot; - that is a natural language interface, which is what ChatGPT has. In both the Infocomm and ChatGPT case the software will respond to you in the first person as though you were interacting with someone.<p>&gt;&gt;  Infocomm games were closer to Dragon&#x27;s Lair than ChatGPT<p>This is a puzzling comment.  The UI for Zork has nothing at all to do with Dragon&#x27;s Lair.  In fact Dragon&#x27;s Lair was possibly the least interactive of almost all computer games - it was essentially an interactive movie with only the most trivial user interaction.<p>&gt;&gt; Infocomm games were mostly about trying to figure out what command the programmer wanted you to do next.<p>This was not my experience of Infocomm adventures.</div><br/><div id="36397223" class="c"><input type="checkbox" id="c-36397223" checked=""/><div class="controls bullet"><span class="by">kenjackson</span><span>|</span><a href="#36395595">root</a><span>|</span><a href="#36396261">parent</a><span>|</span><a href="#36397746">next</a><span>|</span><label class="collapse" for="c-36397223">[-]</label><label class="expand" for="c-36397223">[4 more]</label></div><br/><div class="children"><div class="content">Is natural language simply mean using words?  Is SQL natural language?  I think what makes it a natural language is that it follows natural language rules, which Infocomm games surely did not.<p>Furthermore, Infocomm games used basically 100% precanned responses.  It would do the rudimentary things like check if a window was open so if you looked at a wall it might say the window on that wall was open or closed, but that&#x27;s it.  I don&#x27;t understand how that can make it a natural language interface.<p>&gt; This is a puzzling comment. The UI for Zork has nothing at all to do with Dragon&#x27;s Lair.<p>In both games there&#x27;s a set path you follow.  You follow those commands you win, if not, you lose.  There&#x27;s no semantically equivalent way to complete the game.<p>I remember spending most of my time with Infocomm games doing things like &quot;look around the field&quot; and it telling me &quot;I don&#x27;t know the word field&quot; -- and I&#x27;m screaming because it just told me I&#x27;m in an open field!  The door is blocked... blocked with what?!  You can&#x27;t answer me that?!<p>There were a set of commands and objects it wanted you to interact with.  That&#x27;s it.  That&#x27;s not natural language, any more than SQL is.  It&#x27;s a structured language with commands that look like English verbs.</div><br/><div id="36397447" class="c"><input type="checkbox" id="c-36397447" checked=""/><div class="controls bullet"><span class="by">abecedarius</span><span>|</span><a href="#36395595">root</a><span>|</span><a href="#36397223">parent</a><span>|</span><a href="#36397746">next</a><span>|</span><label class="collapse" for="c-36397447">[-]</label><label class="expand" for="c-36397447">[3 more]</label></div><br/><div class="children"><div class="content">I think you&#x27;re mixing Infocom with some of the much cruder adventure games of the time. Or maybe remembering an unrepresentative Infocom game or part of one.<p>Not to say Infocom included AI. They just used a lot of talent and playtesting to make games that <i>felt</i> more open-ended.</div><br/><div id="36397496" class="c"><input type="checkbox" id="c-36397496" checked=""/><div class="controls bullet"><span class="by">kenjackson</span><span>|</span><a href="#36395595">root</a><span>|</span><a href="#36397447">parent</a><span>|</span><a href="#36397746">next</a><span>|</span><label class="collapse" for="c-36397496">[-]</label><label class="expand" for="c-36397496">[2 more]</label></div><br/><div class="children"><div class="content">No.  I actually went and played Zork again to be sure.  Hitchikers Guide to the Galaxy had me pulling my hair out as a kid.  It was definitely Infocom.<p>I also, as a kid, write a lot of Infocom-style games, so I can appreciate how good of a job they did.  but I&#x27;ve also looked at their source code since it has all been released and I wasn&#x27;t too far behind them.</div><br/><div id="36397554" class="c"><input type="checkbox" id="c-36397554" checked=""/><div class="controls bullet"><span class="by">abecedarius</span><span>|</span><a href="#36395595">root</a><span>|</span><a href="#36397496">parent</a><span>|</span><a href="#36397746">next</a><span>|</span><label class="collapse" for="c-36397554">[-]</label><label class="expand" for="c-36397554">[1 more]</label></div><br/><div class="children"><div class="content">I forgot about Hitchhiker&#x27;s -- to be fair, that did seem less like a game&#x2F;world and more like a big, funny... art piece? I never got back to it after needing hints to make it to the Heart of Gold.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="36397746" class="c"><input type="checkbox" id="c-36397746" checked=""/><div class="controls bullet"><span class="by">yencabulator</span><span>|</span><a href="#36395595">parent</a><span>|</span><a href="#36396226">prev</a><span>|</span><a href="#36396103">next</a><span>|</span><label class="collapse" for="c-36397746">[-]</label><label class="expand" for="c-36397746">[1 more]</label></div><br/><div class="children"><div class="content">I think the interactive-dialogue part is a distraction. I think the &quot;new UI paradigm&quot; is defined by goal-orientation, or &quot;outcome specification&quot;. So, instead of giving the computer instructions on how to do something, users describe the end goal, and hope for the best, and then finetune the result either by adjusting their request, or by adding explicit commands.<p>So, in that sense, even if Infocomm games cleverly emulated the dialogue part of ChatGPT, I don&#x27;t think <i>that</i> was the novel part claimed here.<p>Think more &quot;Make me an Infocomm-style challenge to solve. Include dragons. Do not include orcs, ogres, or any monster that uses a club.&quot;</div><br/></div></div></div></div><div id="36396103" class="c"><input type="checkbox" id="c-36396103" checked=""/><div class="controls bullet"><span class="by">tobr</span><span>|</span><a href="#36395595">prev</a><span>|</span><a href="#36395587">next</a><span>|</span><label class="collapse" for="c-36396103">[-]</label><label class="expand" for="c-36396103">[3 more]</label></div><br/><div class="children"><div class="content">Well, what counts as a âparadigmâ? I canât see any definition of that. If youâd ask 10 people to divide the history of UI into some number of paradigms, you would for sure get 10 different answers. But hey, why not pick the one that makes for a hyperbolic headline. Made me click.</div><br/><div id="36396652" class="c"><input type="checkbox" id="c-36396652" checked=""/><div class="controls bullet"><span class="by">savolai</span><span>|</span><a href="#36396103">parent</a><span>|</span><a href="#36396630">next</a><span>|</span><label class="collapse" for="c-36396652">[-]</label><label class="expand" for="c-36396652">[1 more]</label></div><br/><div class="children"><div class="content">The division does not seem arbitrary to me at all. What about the below is questionable to you?<p>From sibling comment [1]:<p>Nielsen is talking from the field of Human-Computer Interaction where he is pioneer, which deals with the point of view of human cognition. In terms of the logic of UI mechanics, what about mobile is different? Sure gestures and touch UI bring a kind of difference. Still, from the standpoint of cognition, desktop and mobile UIs have fundamentally the same cognitive dynamics. Command line UIs make you remember conmands by heart, GUIs make you select from a selection offered to you but they still do not undestand your intention. AI changes the paradigm as it is ostensibly able to understand intent so there is no deterministic selection of available commands. Instead, the interaction is closer to collaboration.<p>1: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36396244">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36396244</a></div><br/></div></div></div></div><div id="36395587" class="c"><input type="checkbox" id="c-36395587" checked=""/><div class="controls bullet"><span class="by">97-109-107</span><span>|</span><a href="#36396103">prev</a><span>|</span><a href="#36396145">next</a><span>|</span><label class="collapse" for="c-36395587">[-]</label><label class="expand" for="c-36395587">[4 more]</label></div><br/><div class="children"><div class="content">Two recent events suggest to me that this type of analytical look on interaction modes is commonly underappreciated in the industry. I write this partially from the perspective of a disillusioned student of interaction design.<p>1. Recent news of vehicle manufacturers moving away from touchscreens<p>2. Chatbot gold rush of 2018 where most business were sold chatbots under the guise of cost-saving<p>(edit: formatting)</div><br/><div id="36395682" class="c"><input type="checkbox" id="c-36395682" checked=""/><div class="controls bullet"><span class="by">p_j_w</span><span>|</span><a href="#36395587">parent</a><span>|</span><a href="#36396145">next</a><span>|</span><label class="collapse" for="c-36395682">[-]</label><label class="expand" for="c-36395682">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not sure I understand point 1 here. Do you mean that vehicle manufacturers moving away from touchscreens is bad or that they would never have moved to them in the first place if they had properly investigated the idea?</div><br/><div id="36395734" class="c"><input type="checkbox" id="c-36395734" checked=""/><div class="controls bullet"><span class="by">97-109-107</span><span>|</span><a href="#36395587">root</a><span>|</span><a href="#36395682">parent</a><span>|</span><a href="#36396145">next</a><span>|</span><label class="collapse" for="c-36395734">[-]</label><label class="expand" for="c-36395734">[2 more]</label></div><br/><div class="children"><div class="content">The latter - had they given proper thought to the consequences of moving into touch-screens they would&#x27;ve never gone there. Obviously I&#x27;m generalizing and discarding the impact of novelty on sales and marketing.</div><br/><div id="36396117" class="c"><input type="checkbox" id="c-36396117" checked=""/><div class="controls bullet"><span class="by">EGreg</span><span>|</span><a href="#36395587">root</a><span>|</span><a href="#36395734">parent</a><span>|</span><a href="#36396145">next</a><span>|</span><label class="collapse" for="c-36396117">[-]</label><label class="expand" for="c-36396117">[1 more]</label></div><br/><div class="children"><div class="content">It seems everyone is in a rush to LLMify their interfaces same as the chatbot rush. Same as the blockchain all the things rush. And so on.<p>I thought about interfaces a lot and realizdd that, for most applications, a well-designed GUI and API is essential. For composability, there can be standards developed. LLMs are good for generating instructions in a language, that can be sort of finagled into API instructions. Then they can bring down the requirements to be an expert in a specific GUI or API and might open up more abilities for people.<p>Well, and for artwork, LLMs can do a lot more. They can give even experts a sort of superhuman access to models that are âsmoothâ or âfuzzyâ rather than with rigid angles. They can write a lot of vapid bullshit text for instance, or make a pretty believable photo effect that works for most people!</div><br/></div></div></div></div></div></div></div></div><div id="36396145" class="c"><input type="checkbox" id="c-36396145" checked=""/><div class="controls bullet"><span class="by">a1371</span><span>|</span><a href="#36395587">prev</a><span>|</span><a href="#36400579">next</a><span>|</span><label class="collapse" for="c-36396145">[-]</label><label class="expand" for="c-36396145">[3 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t really get this. The paradigm has always been there, it has been the technology limitations that have defined the UI so far. Having robots and computers that humans talk to has been a fixture of sci-fi movies. Perhaps the most notable example being 2001: A Space Odyssey which came out 55 years ago.</div><br/><div id="36397199" class="c"><input type="checkbox" id="c-36397199" checked=""/><div class="controls bullet"><span class="by">moffkalast</span><span>|</span><a href="#36396145">parent</a><span>|</span><a href="#36400579">next</a><span>|</span><label class="collapse" for="c-36397199">[-]</label><label class="expand" for="c-36397199">[2 more]</label></div><br/><div class="children"><div class="content">Sure, but it&#x27;s sort of how actual usable and economical flying cars would be a paradigm change for transport. The idea exists, but it&#x27;s made up fairy magic with capabilities and limitations based on plot requirements. Once it&#x27;s actually made real it hardly ever ends up being used the way it was imagined.<p>Like for example in 2001, the video call tech. They figured it would be used like a payphone with a cathode ray tube lol. Just as in reality nobody in the right mind would hand over complete control of a trillion dollar spaceship to a probabilistic LLM. The end applications will be completely different and cannot be imagined by those limited by the perspective of their time.</div><br/><div id="36398195" class="c"><input type="checkbox" id="c-36398195" checked=""/><div class="controls bullet"><span class="by">mrob</span><span>|</span><a href="#36396145">root</a><span>|</span><a href="#36397199">parent</a><span>|</span><a href="#36400579">next</a><span>|</span><label class="collapse" for="c-36398195">[-]</label><label class="expand" for="c-36398195">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t recall a single cathode ray tube in 2001: A Space Odyssey. The film is notable for having the first depiction of a tablet computer. They went to considerable effort to show flat-screen displays instead of CRTs.</div><br/></div></div></div></div></div></div><div id="36400579" class="c"><input type="checkbox" id="c-36400579" checked=""/><div class="controls bullet"><span class="by">trojan13</span><span>|</span><a href="#36396145">prev</a><span>|</span><a href="#36395900">next</a><span>|</span><label class="collapse" for="c-36400579">[-]</label><label class="expand" for="c-36400579">[1 more]</label></div><br/><div class="children"><div class="content">I am surprised this article does not even mention multimodal LLMs. Because the more kinds of media the LLM can take as in input and interpret the easier the interaction with it gets.</div><br/></div></div><div id="36395900" class="c"><input type="checkbox" id="c-36395900" checked=""/><div class="controls bullet"><span class="by">danielvaughn</span><span>|</span><a href="#36400579">prev</a><span>|</span><a href="#36397566">next</a><span>|</span><label class="collapse" for="c-36395900">[-]</label><label class="expand" for="c-36395900">[8 more]</label></div><br/><div class="children"><div class="content">Interesting to bundle both cli&#x2F;gui under the &quot;command&quot; based interaction paradigm. I&#x27;ve never heard it described that way but it does make sense intuitively. Is that a common perception? I think of the development of the mouse&#x2F;gui as a very significant event in the history of computing interfaces.</div><br/><div id="36395911" class="c"><input type="checkbox" id="c-36395911" checked=""/><div class="controls bullet"><span class="by">zgluck</span><span>|</span><a href="#36395900">parent</a><span>|</span><a href="#36397566">next</a><span>|</span><label class="collapse" for="c-36395911">[-]</label><label class="expand" for="c-36395911">[7 more]</label></div><br/><div class="children"><div class="content">When you zoom out on the time scale it makes more sense. I think he&#x27;s got a point. Both CLIs and GUIs are &quot;command based&quot;. LLM prompts are more declarative. You describe what you want.</div><br/><div id="36396453" class="c"><input type="checkbox" id="c-36396453" checked=""/><div class="controls bullet"><span class="by">AnimalMuppet</span><span>|</span><a href="#36395900">root</a><span>|</span><a href="#36395911">parent</a><span>|</span><a href="#36396077">next</a><span>|</span><label class="collapse" for="c-36396453">[-]</label><label class="expand" for="c-36396453">[4 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve been at a SQL command prompt a decade or several before LLM.</div><br/><div id="36396779" class="c"><input type="checkbox" id="c-36396779" checked=""/><div class="controls bullet"><span class="by">zgluck</span><span>|</span><a href="#36395900">root</a><span>|</span><a href="#36396453">parent</a><span>|</span><a href="#36396077">next</a><span>|</span><label class="collapse" for="c-36396779">[-]</label><label class="expand" for="c-36396779">[3 more]</label></div><br/><div class="children"><div class="content">That is not the point here. Did you any point believe that you were experiencing a mass market user experience at those times?</div><br/><div id="36397165" class="c"><input type="checkbox" id="c-36397165" checked=""/><div class="controls bullet"><span class="by">AnimalMuppet</span><span>|</span><a href="#36395900">root</a><span>|</span><a href="#36396779">parent</a><span>|</span><a href="#36396077">next</a><span>|</span><label class="collapse" for="c-36397165">[-]</label><label class="expand" for="c-36397165">[2 more]</label></div><br/><div class="children"><div class="content">I was experiencing something <i>declarative</i> at that point.<p>What&#x27;s your actual position?  Is &quot;declarative&quot; the relevant piece, or is it &quot;mass market user experience&quot;?</div><br/><div id="36397338" class="c"><input type="checkbox" id="c-36397338" checked=""/><div class="controls bullet"><span class="by">zgluck</span><span>|</span><a href="#36395900">root</a><span>|</span><a href="#36397165">parent</a><span>|</span><a href="#36396077">next</a><span>|</span><label class="collapse" for="c-36397338">[-]</label><label class="expand" for="c-36397338">[1 more]</label></div><br/><div class="children"><div class="content">My point here is that what Norman Nielsen deals with is &quot;mass market user experience&quot;. This has been very clear for a very long time.</div><br/></div></div></div></div></div></div></div></div><div id="36396077" class="c"><input type="checkbox" id="c-36396077" checked=""/><div class="controls bullet"><span class="by">EGreg</span><span>|</span><a href="#36395900">root</a><span>|</span><a href="#36395911">parent</a><span>|</span><a href="#36396453">prev</a><span>|</span><a href="#36397566">next</a><span>|</span><label class="collapse" for="c-36396077">[-]</label><label class="expand" for="c-36396077">[2 more]</label></div><br/><div class="children"><div class="content">Well LLMs are also âcommand-basedâ. They are called prompts. In fact theyâd just continue the text but were specifically trained by RLHF to be command-following.<p>Actually, we can make automomous agents and agentic behavior without LLMs very well, for decades. And we can program them with declarative instructions much more precisely than with natural language.<p>The thing LLMs seem to do is just give non-experts a lot of the tools to get some basic things done that only experts could do for now. This has to do with the LLM modeling the domain space and reading what experts have said thus far, and allowing a non-expert to kind of handwave and produce results.</div><br/><div id="36396136" class="c"><input type="checkbox" id="c-36396136" checked=""/><div class="controls bullet"><span class="by">zgluck</span><span>|</span><a href="#36395900">root</a><span>|</span><a href="#36396077">parent</a><span>|</span><a href="#36397566">next</a><span>|</span><label class="collapse" for="c-36396136">[-]</label><label class="expand" for="c-36396136">[1 more]</label></div><br/><div class="children"><div class="content">(I added a bit to the comment above, sorry)<p>I think there&#x27;s a clear difference between a command and a declaration. Prompts are declarative.</div><br/></div></div></div></div></div></div></div></div><div id="36397566" class="c"><input type="checkbox" id="c-36397566" checked=""/><div class="controls bullet"><span class="by">dustingetz</span><span>|</span><a href="#36395900">prev</a><span>|</span><a href="#36397115">next</a><span>|</span><label class="collapse" for="c-36397566">[-]</label><label class="expand" for="c-36397566">[1 more]</label></div><br/><div class="children"><div class="content">UI is a high frequency concurrency problem. The âdeep rooted usability problemsâ (like lag, glitches, and clumsiness - general lack of fluency) are due to staffing UI projects with web designers and not concurrency engineers. The fluent conversational AI systems and other movie UIs that folks are imagining up are therefore blocked on the concurrency sub-problem. This is the space we research at Hyperfiddle, we put forth our proposed solution here: <a href="https:&#x2F;&#x2F;github.com&#x2F;hyperfiddle&#x2F;electric">https:&#x2F;&#x2F;github.com&#x2F;hyperfiddle&#x2F;electric</a></div><br/></div></div><div id="36397115" class="c"><input type="checkbox" id="c-36397115" checked=""/><div class="controls bullet"><span class="by">Bjorkbat</span><span>|</span><a href="#36397566">prev</a><span>|</span><a href="#36400103">next</a><span>|</span><label class="collapse" for="c-36397115">[-]</label><label class="expand" for="c-36397115">[4 more]</label></div><br/><div class="children"><div class="content">I really wouldnât call GUIs a âcommand-based paradigmâ.  Feels much more like theyâre digital analogues of tools and objects.  Your mouse is a tool, and you use it to interface with objects and things, and through special software it can become a more specialized tool (word processors, spreadsheets, graphic design software, etc).  You arenât issuing commands, youâre manipulating a digital environment with tools.<p>Which is why the notion of conversational AI (or whatever dumb name they came up with for the âthird paradigmâ) seems kind of alien to me.  I mean, I definitely see its utility, but I find it hard to imagine it being as dominant as some are arguing it could be.  Any task that involves browsing for information seems like more of an object manipulation task.  Any task involving some kind of visual design seems like a tool manipulation task, unless you arenât too picky about the final result.<p>Ultimately I think conversational UI is best suited not for tasks, but services.  Granted, the line between the two can be fuzzy at times.  If youâre looking for a website, but you donât personally know anything about making a website, then that task morphs into a service that someone or something else does.<p>Which I suppose is kind of the other reason why I find the idea kind of alien.  I almost never use the computer for services.  I use it to browse, to create, to work, all of which entail something more intuitively suited to object or tool manipulation.</div><br/><div id="36397437" class="c"><input type="checkbox" id="c-36397437" checked=""/><div class="controls bullet"><span class="by">rzzzt</span><span>|</span><a href="#36397115">parent</a><span>|</span><a href="#36400103">next</a><span>|</span><label class="collapse" for="c-36397437">[-]</label><label class="expand" for="c-36397437">[3 more]</label></div><br/><div class="children"><div class="content">AutoCAD and Rhino 3D are two examples that I remember having a command prompt sitting proudly somewhere at the bottom of the UI. Your mouse clicks and keyboard shortcuts were all converted into commands in text form. If you look at your command history, it&#x27;s a script - a bit boring since it is completely linear, but add loops, conditionals and function&#x2F;macro support and you get a very capable scripting environment.</div><br/><div id="36398102" class="c"><input type="checkbox" id="c-36398102" checked=""/><div class="controls bullet"><span class="by">bitwize</span><span>|</span><a href="#36397115">root</a><span>|</span><a href="#36397437">parent</a><span>|</span><a href="#36400103">next</a><span>|</span><label class="collapse" for="c-36398102">[-]</label><label class="expand" for="c-36398102">[2 more]</label></div><br/><div class="children"><div class="content">AutoCAD definitely was CLI-based, with menus and dialogs basically filling in parameters to the commands. But in the late 90s or so Autodesk got religion and decided that AutoCAD should be a Windows product and follow Microsoft UI guidelines, so I don&#x27;t know how well they stuck with the &quot;command line underneath&quot; over the years.<p>Early in AutoCAD&#x27;s history, Autodesk <i>did</i> add loops and conditionals to its CLI -- with Lisp! Type an open paren and the command line became a REPL. You could define new commands, directly manipulate entity data structures, and have all the control structures Lisp affords -- not Common Lisp, it was way simpler, but it was powerful.<p>To this day, wayward mech engineers still sometimes ask Autolisp-related questions on unrelated Lisp fora, such as r&#x2F;lisp.</div><br/><div id="36400059" class="c"><input type="checkbox" id="c-36400059" checked=""/><div class="controls bullet"><span class="by">rzzzt</span><span>|</span><a href="#36397115">root</a><span>|</span><a href="#36398102">parent</a><span>|</span><a href="#36400103">next</a><span>|</span><label class="collapse" for="c-36400059">[-]</label><label class="expand" for="c-36400059">[1 more]</label></div><br/><div class="children"><div class="content">I was just trying to address the parent and others&#x27; doubt that a graphical user interface can be thought of as a command-based paradigm, seen in these threads:<p>- <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36395900">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36395900</a><p>- <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36397115">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36397115</a> (we are here)<p>- <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36395727">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36395727</a><p>The designers behind the examples mentioned wanted to expose and capitalize on the connection between traditional &quot;type command&quot; CLI and &quot;press button, drag rectangle&quot; GUI workflows.</div><br/></div></div></div></div></div></div></div></div><div id="36400103" class="c"><input type="checkbox" id="c-36400103" checked=""/><div class="controls bullet"><span class="by">USB3_0</span><span>|</span><a href="#36397115">prev</a><span>|</span><a href="#36396319">next</a><span>|</span><label class="collapse" for="c-36400103">[-]</label><label class="expand" for="c-36400103">[1 more]</label></div><br/><div class="children"><div class="content">&gt; With the new AI systems, the user no longer tells the computer what to do. Rather, the user tells the computer what outcome they want. Thus, the third UI paradigm, represented by current generative AI, is intent-based outcome specification.<p>Wow! For the first time ever, I will be able to describe to a trained professional what I want, and they will do it for me!  Before today I used to write out the exact arm motions a carpenter would need to carve me a chair, but now I can just ask them for one!<p>This article is stupid. 
AI will make it easier for computers to interpret human interactions leading to increased efficiency and usability. Just like every other useful tool ever invented.  There, I&#x27;ve put more insight into this comment than their article.</div><br/></div></div><div id="36396319" class="c"><input type="checkbox" id="c-36396319" checked=""/><div class="controls bullet"><span class="by">thih9</span><span>|</span><a href="#36400103">prev</a><span>|</span><a href="#36395754">next</a><span>|</span><label class="collapse" for="c-36396319">[-]</label><label class="expand" for="c-36396319">[3 more]</label></div><br/><div class="children"><div class="content">What about voice assistants? These are not as impressive when compared to LLMs, so perhaps wouldn&#x27;t cause a UX shift on their own. But in essence Siri, Alexa, etc also seem to put the user&#x27;s intent first.</div><br/><div id="36397661" class="c"><input type="checkbox" id="c-36397661" checked=""/><div class="controls bullet"><span class="by">yencabulator</span><span>|</span><a href="#36396319">parent</a><span>|</span><a href="#36399710">next</a><span>|</span><label class="collapse" for="c-36397661">[-]</label><label class="expand" for="c-36397661">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;d argue that voice assistants are somewhat part of the same paradigm[1], and ChatGPT etc focused on pure text input mostly to make the research easier. Voice assistants just focused on the challenges of understanding speech, facilitated by limited allowed grammar, while ChatGPT-style research focused on the challenges of understanding language, facilitated by limiting input to text. &quot;Just&quot; produce ChatGPT input tokens from a voice-to-text-with-extra-hints machine and you have them combined.<p>[1] Yes, voice assistants tend to be more command-oriented, but I view that as a limitation of the technology when they were popularized, not as an inherent part of the concept of a voice assistant. Voice is just an input modalism.</div><br/></div></div><div id="36399710" class="c"><input type="checkbox" id="c-36399710" checked=""/><div class="controls bullet"><span class="by">esafak</span><span>|</span><a href="#36396319">parent</a><span>|</span><a href="#36397661">prev</a><span>|</span><a href="#36395754">next</a><span>|</span><label class="collapse" for="c-36399710">[-]</label><label class="expand" for="c-36399710">[1 more]</label></div><br/><div class="children"><div class="content">A voice assistant is simply a speech-driven conversational UI; they belong to the same class of UIs as chatGPT. In fact, you could very well power your voice assistant with GPT.</div><br/></div></div></div></div><div id="36395754" class="c"><input type="checkbox" id="c-36395754" checked=""/><div class="controls bullet"><span class="by">kaycebasques</span><span>|</span><a href="#36396319">prev</a><span>|</span><a href="#36396388">next</a><span>|</span><label class="collapse" for="c-36395754">[-]</label><label class="expand" for="c-36395754">[4 more]</label></div><br/><div class="children"><div class="content">There&#x27;s something ironic to me about the fact that building AI experiences still requires the first computing paradigm: batch processing. At least, my experience building a retrieval-augmented generation system requires a lot of batch processing.<p>Well, I shouldn&#x27;t say &quot;requires&quot;. I&#x27;m sure you can build them without batch processing. But batch processing definitely felt like the most natural and straightforward way to do it in my experience.</div><br/><div id="36397520" class="c"><input type="checkbox" id="c-36397520" checked=""/><div class="controls bullet"><span class="by">yencabulator</span><span>|</span><a href="#36395754">parent</a><span>|</span><a href="#36398105">next</a><span>|</span><label class="collapse" for="c-36397520">[-]</label><label class="expand" for="c-36397520">[2 more]</label></div><br/><div class="children"><div class="content">He&#x27;s talking about <i>human-computer interaction</i> paradigms, not computing paradigms. He&#x27;s not a general computing expert, he&#x27;s a UI&#x2F;UX expert.<p>&quot;Batch computing&quot; in this context refers to the era of punch cards, needing to wait for results overnight, and the difficulty of editing pre-existing programs -- and how all of that utterly dictated the style of interaction one had with computers.</div><br/><div id="36399235" class="c"><input type="checkbox" id="c-36399235" checked=""/><div class="controls bullet"><span class="by">kaycebasques</span><span>|</span><a href="#36395754">root</a><span>|</span><a href="#36397520">parent</a><span>|</span><a href="#36398105">next</a><span>|</span><label class="collapse" for="c-36399235">[-]</label><label class="expand" for="c-36399235">[1 more]</label></div><br/><div class="children"><div class="content">Yep, I was aware of the difference before I made my original comment. There&#x27;s still something ironic and interesting about it to me. Can&#x27;t quite put my finger on it, though.</div><br/></div></div></div></div><div id="36398105" class="c"><input type="checkbox" id="c-36398105" checked=""/><div class="controls bullet"><span class="by">ilaksh</span><span>|</span><a href="#36395754">parent</a><span>|</span><a href="#36397520">prev</a><span>|</span><a href="#36396388">next</a><span>|</span><label class="collapse" for="c-36398105">[-]</label><label class="expand" for="c-36398105">[1 more]</label></div><br/><div class="children"><div class="content">What sort of retrieval augmented generation system are you working on?</div><br/></div></div></div></div><div id="36396388" class="c"><input type="checkbox" id="c-36396388" checked=""/><div class="controls bullet"><span class="by">travisgriggs</span><span>|</span><a href="#36395754">prev</a><span>|</span><a href="#36397432">next</a><span>|</span><label class="collapse" for="c-36396388">[-]</label><label class="expand" for="c-36396388">[1 more]</label></div><br/><div class="children"><div class="content">GPT based UIs inspired by the idea that if you get the right sequence of prompts youâll get stochastically acceptable results.<p>So now Iâm imagining the horror predictions for Word where 90% of the screen was button bars. But the twist is that you type in some text and then click on âpromptâ buttons repeatedly hoping to get the document formatting you wanted, probably settling for something that was âclose enoughâ with a shrug.</div><br/></div></div><div id="36397432" class="c"><input type="checkbox" id="c-36397432" checked=""/><div class="controls bullet"><span class="by">layoric</span><span>|</span><a href="#36396388">prev</a><span>|</span><a href="#36396616">next</a><span>|</span><label class="collapse" for="c-36397432">[-]</label><label class="expand" for="c-36397432">[1 more]</label></div><br/><div class="children"><div class="content">I built a proof of concept recently that tries to show a generic hybrid of command and intent[0]. The UI generates form representations of API calls the AI agent has decided on making to complete the task (in this case booking a meeting). Some API calls are restricted so only a human can make them, which they do by being presented with a form waiting for them to submit to continue.<p>If the user is vague, the bot will ask questions and try to discover the information it needs. Itâs only a proof of concept but I think itâs a pattern I will try to build on , as it can provide a very flexible interface.<p>[0] <a href="https:&#x2F;&#x2F;gptmeetings.netcore.io&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;gptmeetings.netcore.io&#x2F;</a></div><br/></div></div><div id="36396616" class="c"><input type="checkbox" id="c-36396616" checked=""/><div class="controls bullet"><span class="by">jl6</span><span>|</span><a href="#36397432">prev</a><span>|</span><a href="#36400563">next</a><span>|</span><label class="collapse" for="c-36396616">[-]</label><label class="expand" for="c-36396616">[1 more]</label></div><br/><div class="children"><div class="content">Is it a new paradigm, or an old paradigm that finally works?<p>Users have been typing commands into computers for decades, getting responses of varying sophistication with varying degrees of natural language processing. Even the idea of an âAIâ chatbot that mimics human writing is decades old.<p>The new thing is that the NLP now has some depth to it.</div><br/></div></div><div id="36400563" class="c"><input type="checkbox" id="c-36400563" checked=""/><div class="controls bullet"><span class="by">nologic01</span><span>|</span><a href="#36396616">prev</a><span>|</span><a href="#36398223">next</a><span>|</span><label class="collapse" for="c-36400563">[-]</label><label class="expand" for="c-36400563">[1 more]</label></div><br/><div class="children"><div class="content">So many words to describe &quot;declarative programming&quot;</div><br/></div></div><div id="36398223" class="c"><input type="checkbox" id="c-36398223" checked=""/><div class="controls bullet"><span class="by">earthboundkid</span><span>|</span><a href="#36400563">prev</a><span>|</span><a href="#36395774">next</a><span>|</span><label class="collapse" for="c-36398223">[-]</label><label class="expand" for="c-36398223">[1 more]</label></div><br/><div class="children"><div class="content">It would be neat if someone could make a good adventure game with an LLM, but theyâre too prone to getting argued into just letting you win or whatever.</div><br/></div></div><div id="36395774" class="c"><input type="checkbox" id="c-36395774" checked=""/><div class="controls bullet"><span class="by">isoprophlex</span><span>|</span><a href="#36398223">prev</a><span>|</span><a href="#36397156">next</a><span>|</span><label class="collapse" for="c-36395774">[-]</label><label class="expand" for="c-36395774">[4 more]</label></div><br/><div class="children"><div class="content">&quot;intent-based outcome specification&quot;... so, a declarative language such as SQL?</div><br/><div id="36397630" class="c"><input type="checkbox" id="c-36397630" checked=""/><div class="controls bullet"><span class="by">yencabulator</span><span>|</span><a href="#36395774">parent</a><span>|</span><a href="#36396166">next</a><span>|</span><label class="collapse" for="c-36397630">[-]</label><label class="expand" for="c-36397630">[2 more]</label></div><br/><div class="children"><div class="content">I think you&#x27;ll find that INSERT and UPDATE are very much commands. SQL queries are outcome-driven sure, but try to move beyond pure queries and outcome-driven computing, without some sort of machine learning, gets quite difficult. And moving outside of a single SELECT is a <i>huge</i> barrier.<p>Even within the scope of SQL, consider an ML system that can slice-and-dice previous SQL queries interactively, based on non-expert user input.<p>Consider an ML system that essentially edits an proposed SQL transaction as a whole, based on your requests. Previewing results etc, adjusting INSERTs and UPDATEs as user clarifies intent. User terminology focuses on the outcome, not on the individual commands, ordering, etc.<p>Now move from that narrow domain into something like &quot;I want to organize a conference&quot;, &quot;I want to write a book&quot;, etc, and all the things that are beyond a single SQL SELECT.</div><br/><div id="36398130" class="c"><input type="checkbox" id="c-36398130" checked=""/><div class="controls bullet"><span class="by">ilaksh</span><span>|</span><a href="#36395774">root</a><span>|</span><a href="#36397630">parent</a><span>|</span><a href="#36396166">next</a><span>|</span><label class="collapse" for="c-36398130">[-]</label><label class="expand" for="c-36398130">[1 more]</label></div><br/><div class="children"><div class="content">I built a system that uses GPT to write KQL queries (similar to SQL) for a specific table. It could even combine multiple queries or throw in a custom chart if requested.<p>OpenAI&#x27;s models are good at writing SQL. I think they finally allow the type of use case that SQL itself was supposed to provide as originally envisioned.</div><br/></div></div></div></div><div id="36396166" class="c"><input type="checkbox" id="c-36396166" checked=""/><div class="controls bullet"><span class="by">zgluck</span><span>|</span><a href="#36395774">parent</a><span>|</span><a href="#36397630">prev</a><span>|</span><a href="#36397156">next</a><span>|</span><label class="collapse" for="c-36396166">[-]</label><label class="expand" for="c-36396166">[1 more]</label></div><br/><div class="children"><div class="content">While it was initially meant as user interface layer of sorts, I think, it&#x27;s not really something that the typical user can be expected to know nowadays.</div><br/></div></div></div></div><div id="36397156" class="c"><input type="checkbox" id="c-36397156" checked=""/><div class="controls bullet"><span class="by">afavour</span><span>|</span><a href="#36395774">prev</a><span>|</span><a href="#36396594">next</a><span>|</span><label class="collapse" for="c-36397156">[-]</label><label class="expand" for="c-36397156">[1 more]</label></div><br/><div class="children"><div class="content">Werenât voice assistants a new UI paradigm? Also, tellingly, they turned out to not be anywhere near as useful as people hoped. Sometimes new isnât a good thing.</div><br/></div></div><div id="36396594" class="c"><input type="checkbox" id="c-36396594" checked=""/><div class="controls bullet"><span class="by">aqme28</span><span>|</span><a href="#36397156">prev</a><span>|</span><a href="#36397242">next</a><span>|</span><label class="collapse" for="c-36396594">[-]</label><label class="expand" for="c-36396594">[2 more]</label></div><br/><div class="children"><div class="content">This is not a new UI paradigm. Virtual assistants have been doing exactly this for years. It&#x27;s just gotten cheap and low-latency enough to be practical.</div><br/><div id="36396810" class="c"><input type="checkbox" id="c-36396810" checked=""/><div class="controls bullet"><span class="by">NikkiA</span><span>|</span><a href="#36396594">parent</a><span>|</span><a href="#36397242">next</a><span>|</span><label class="collapse" for="c-36396810">[-]</label><label class="expand" for="c-36396810">[1 more]</label></div><br/><div class="children"><div class="content">Yep, although they were doing it &#x27;badly&#x27;, I guess it not being quite so terrible is the &#x27;new paradigm&#x27;, which is eyeroll worthy IMO.</div><br/></div></div></div></div><div id="36397242" class="c"><input type="checkbox" id="c-36397242" checked=""/><div class="controls bullet"><span class="by">tin7in</span><span>|</span><a href="#36396594">prev</a><span>|</span><label class="collapse" for="c-36397242">[-]</label><label class="expand" for="c-36397242">[1 more]</label></div><br/><div class="children"><div class="content">I agree that chat UI is not the answer. Itâs a great start and a very familiar UI but I feel this will default to more traditional UI that shows pre defined actions and buttons depending on the workflow.</div><br/></div></div></div></div></div></div></div></body></html>