<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1686819663727" as="style"/><link rel="stylesheet" href="styles.css?v=1686819663727"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://yonom.substack.com/p/native-json-output-from-gpt-4">Native JSON Output from GPT-4</a> <span class="domain">(<a href="https://yonom.substack.com">yonom.substack.com</a>)</span></div><div class="subtext"><span>yonom</span> | <span>201 comments</span></div><br/><div><div id="36335921" class="c"><input type="checkbox" id="c-36335921" checked=""/><div class="controls bullet"><span class="by">danShumway</span><span>|</span><a href="#36331548">next</a><span>|</span><label class="collapse" for="c-36335921">[-]</label><label class="expand" for="c-36335921">[9 more]</label></div><br/><div class="children"><div class="content">I&#x27;m concerned that OpenAI&#x27;s example documentation suggests using this to A) construct SQL queries and B) summarize emails, but that their example code doesn&#x27;t include clear hooks for human validation before actions are called.<p>For a recipe builder it&#x27;s not so big a deal, but I really worry how eager people are to remove human review from these steps. It gets rid of a very important mechanism for reducing the risks of prompt injection.<p>The top comment here suggests wiring this up to allow GPT-4 to recursively call itself. Meanwhile, some of the best advice I&#x27;ve seen from security professionals on secure LLM app development is to whenever possible completely isolate queries from each other to reduce the potential damage that a compromised agent can do before its &quot;memory&quot; is wiped.<p>There are definitely ways to use this safely, and there are definitely some pretty powerful apps you could build on top of this without much risk. LLMs as a transformation layer for trusted input is a good use-case. But are devs going to stick with that? Is it going to be used safely? Do devs understand any of the risks or how to mitigate them in the first place?<p>3rd-party plugins on ChatGPT have repeatedly been vulnerable in the real world, I&#x27;m worried about what mistakes developers are going to make now that they&#x27;re actively encouraged to treat GPT as even more of a low-level data layer. Especially since OpenAI&#x27;s documentation on how to build secure apps is mostly pretty bad, and they don&#x27;t seem to be spending much time or effort educating developers&#x2F;partners on how to approach LLM security.</div><br/><div id="36337946" class="c"><input type="checkbox" id="c-36337946" checked=""/><div class="controls bullet"><span class="by">irthomasthomas</span><span>|</span><a href="#36335921">parent</a><span>|</span><a href="#36336024">next</a><span>|</span><label class="collapse" for="c-36337946">[-]</label><label class="expand" for="c-36337946">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t understand why they have done this? Like, how did the conversations go when it was  pointed out to them what a pretty darn bad idea it was to recommend  connecting chatgpt directly to a SQL database?<p>I know we are supposed to assume incompetence over malice, but no one is that incompetent. They must have had the conversations, and chose to do it anyway.</div><br/></div></div><div id="36336024" class="c"><input type="checkbox" id="c-36336024" checked=""/><div class="controls bullet"><span class="by">abhibeckert</span><span>|</span><a href="#36335921">parent</a><span>|</span><a href="#36337946">prev</a><span>|</span><a href="#36336031">next</a><span>|</span><label class="collapse" for="c-36336024">[-]</label><label class="expand" for="c-36336024">[5 more]</label></div><br/><div class="children"><div class="content">In my opinion the only way to use it safely is to ensure your AI only has access to data that the end user already has access to.<p>At that point, prompt injection is no-longer an issue - because the AI doesn&#x27;t need to hide anything.<p>Giving GPT access to your entire database, but telling it not to reveal certain bits, is never going to work. There will always be side channel vulnerabilities in those systems.</div><br/><div id="36336113" class="c"><input type="checkbox" id="c-36336113" checked=""/><div class="controls bullet"><span class="by">danShumway</span><span>|</span><a href="#36335921">root</a><span>|</span><a href="#36336024">parent</a><span>|</span><a href="#36336659">next</a><span>|</span><label class="collapse" for="c-36336113">[-]</label><label class="expand" for="c-36336113">[3 more]</label></div><br/><div class="children"><div class="content">&gt; e.g. define a function called extract_data(name: string, birthday: string), or sql_query(query: string)<p>This section in OpenAI&#x27;s product announcement really irritates me because it&#x27;s so obvious that the model should have access to a subset of API calls that themselves fetch the data, as opposed to giving the model raw access to SQL. You could have the same capabilities while eliminating a huge amount of risk. And OpenAI just sticks this right in the announcement, they&#x27;re encouraging it.<p>When I&#x27;m building a completely isolated backend with just regular code, I still usually put a data access layer in front of the database in most cases. I still don&#x27;t want my REST endpoints directly building SQL queries or directly accessing the database, and that&#x27;s without an LLM in the loop at all. It&#x27;s just safer.<p>It&#x27;s the same idea as using `innerHTML`; in general it&#x27;s better when possible to have those kinds of calls extremely isolated and to go through functions that constrain what can go wrong. But no, OpenAI just straight up telling developers to do the wrong things and to give GPT unrestricted database access.</div><br/><div id="36336344" class="c"><input type="checkbox" id="c-36336344" checked=""/><div class="controls bullet"><span class="by">BoorishBears</span><span>|</span><a href="#36335921">root</a><span>|</span><a href="#36336113">parent</a><span>|</span><a href="#36336659">next</a><span>|</span><label class="collapse" for="c-36336344">[-]</label><label class="expand" for="c-36336344">[2 more]</label></div><br/><div class="children"><div class="content">You don&#x27;t need to directly run the query it returns, you can use that query as a sub-query on a known safe set of data and let it fail if someone manages to prompt inject their way into looking at other tables&#x2F;columns.<p>That way you can support natural language to query without sending dozens of functions (which will eat up the context window)</div><br/><div id="36336541" class="c"><input type="checkbox" id="c-36336541" checked=""/><div class="controls bullet"><span class="by">danShumway</span><span>|</span><a href="#36335921">root</a><span>|</span><a href="#36336344">parent</a><span>|</span><a href="#36336659">next</a><span>|</span><label class="collapse" for="c-36336541">[-]</label><label class="expand" for="c-36336541">[1 more]</label></div><br/><div class="children"><div class="content">You can do that (I wouldn&#x27;t advise it, there are still problems that are better solved by building explicit functions; but you can use subqueries and it would be safer) -- but most developers won&#x27;t. They&#x27;ll run the query directly. Most developers also will not execute it as a readonly query, they&#x27;ll give the LLM write access to the database.<p>If OpenAI doesn&#x27;t know that, then I don&#x27;t know what to say, they haven&#x27;t spent enough time writing documentation for general users.</div><br/></div></div></div></div></div></div><div id="36336659" class="c"><input type="checkbox" id="c-36336659" checked=""/><div class="controls bullet"><span class="by">kristiandupont</span><span>|</span><a href="#36335921">root</a><span>|</span><a href="#36336024">parent</a><span>|</span><a href="#36336113">prev</a><span>|</span><a href="#36336031">next</a><span>|</span><label class="collapse" for="c-36336659">[-]</label><label class="expand" for="c-36336659">[1 more]</label></div><br/><div class="children"><div class="content">&gt;At that point, prompt injection is no-longer an issue [...]<p>As far as input goes, yes. But I am more worried about agents that can take actions that affect the outside world, like sending emails on your behalf.</div><br/></div></div></div></div><div id="36336031" class="c"><input type="checkbox" id="c-36336031" checked=""/><div class="controls bullet"><span class="by">sillysaurusx</span><span>|</span><a href="#36335921">parent</a><span>|</span><a href="#36336024">prev</a><span>|</span><a href="#36331548">next</a><span>|</span><label class="collapse" for="c-36336031">[-]</label><label class="expand" for="c-36336031">[2 more]</label></div><br/><div class="children"><div class="content">I was going to say “I look forward to it and think it’s hilarious,” but then I remembered that most victims will be people learning to code, not companies. It would really suck to suddenly lose your recipe database when you just wanted to figure out how this programming stuff worked.<p>Some kind of “heads up” tagline is probably a good idea, yeah.</div><br/><div id="36336688" class="c"><input type="checkbox" id="c-36336688" checked=""/><div class="controls bullet"><span class="by">kristiandupont</span><span>|</span><a href="#36335921">root</a><span>|</span><a href="#36336031">parent</a><span>|</span><a href="#36331548">next</a><span>|</span><label class="collapse" for="c-36336688">[-]</label><label class="expand" for="c-36336688">[1 more]</label></div><br/><div class="children"><div class="content">I think the victims will mostly be the users of the software. The personal assistant that can handle your calendar and emails and all would be able to do real damage.</div><br/></div></div></div></div></div></div><div id="36331548" class="c"><input type="checkbox" id="c-36331548" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#36335921">prev</a><span>|</span><a href="#36331206">next</a><span>|</span><label class="collapse" for="c-36331548">[-]</label><label class="expand" for="c-36331548">[91 more]</label></div><br/><div class="children"><div class="content">i think people are underestimating the potential here for agents building - it is now a lot easier for GPT4 to call other models, or itself. while i was taking notes for our emergency pod yesterday (<a href="https:&#x2F;&#x2F;www.latent.space&#x2F;p&#x2F;function-agents" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.latent.space&#x2F;p&#x2F;function-agents</a>) we had this interesting debate with Simon Willison on just how many functions will be supplied to this API. Simon thinks it will be &quot;deep&quot; rather than &quot;wide&quot; - eg a few functions that do many things, rather than many functions that do few things. I think i agree.<p>you can now trivially make GPT4 decide whether to call itself again, or to proceed to the next stage. it feels like the first XOR circuit from which we can compose a &quot;transistor&quot;, from which we can compose a new kind of CPU.</div><br/><div id="36337183" class="c"><input type="checkbox" id="c-36337183" checked=""/><div class="controls bullet"><span class="by">jillesvangurp</span><span>|</span><a href="#36331548">parent</a><span>|</span><a href="#36332614">next</a><span>|</span><label class="collapse" for="c-36337183">[-]</label><label class="expand" for="c-36337183">[1 more]</label></div><br/><div class="children"><div class="content">Exactly, we humans can use specialized models and traditional tool APIs and models and orchestrate the use of all these without understanding how these things work in detail.<p>To do accounting, GPT 4 (or future models) doesn&#x27;t have to know how to calculate. All it needs to know how to interface with tools like calculators, spreadsheets, etc. and parse their outputs. Every script, program, etc. becomes a thing that has such an API. A lot what we humans do to solve problems is breaking down big problems into problems where we know the solution already.<p>Real life tool interfaces are messy and optimized for humans with their limited language and cognitive skills. Ironically, that means they are relatively easy to figure out for AI language models. Relative to human language the grammar of these tool &quot;languages&quot; is more regular and the syntax less ambiguous and complicated. Which is why gpt 3 and 4 are reasonably proficient with even some more obscure programming languages and in the use of various frameworks; including some very obscure ones.<p>Given a lot of these tools with machine accessible APIs with some sort of description or documentation, figuring out how to call these things is relatively straightforward for a language model. The rest is just coming up with a high level plan and then executing it. Which amounts to generating some sort of script that does this. As soon as you have that, that in itself becomes a tool that may be used later. So, it can get better over time. Especially once it starts incorporating feedback about the quality of its results. It would be able to run mini experiments and run its own QA on its own output as well.</div><br/></div></div><div id="36332614" class="c"><input type="checkbox" id="c-36332614" checked=""/><div class="controls bullet"><span class="by">jonplackett</span><span>|</span><a href="#36331548">parent</a><span>|</span><a href="#36337183">prev</a><span>|</span><a href="#36331728">next</a><span>|</span><label class="collapse" for="c-36332614">[-]</label><label class="expand" for="c-36332614">[50 more]</label></div><br/><div class="children"><div class="content">It was already quite easy to get GPT-4 to output json. You just append ‘reply in json with this format’ and it does a really good job.<p>GPT-3.5 was very haphazard though and needs extensive babysitting and reminding, so if this makes gpt3 better then it’s useful - it does have an annoying disclaimer though that ‘it may not reply with valid json’ so we’ll still have to do some sense checks into he output.<p>I have been using this to make a few ‘choose your own adventure’ type games and I can see there’s a TONNE of potential useful things.</div><br/><div id="36335209" class="c"><input type="checkbox" id="c-36335209" checked=""/><div class="controls bullet"><span class="by">sheepscreek</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36332614">parent</a><span>|</span><a href="#36333643">next</a><span>|</span><label class="collapse" for="c-36335209">[-]</label><label class="expand" for="c-36335209">[4 more]</label></div><br/><div class="children"><div class="content">The solution that worked great for me - do not use JSON for GPT to agent communication. Use comma separated key=value, or something to that effect.<p>Then have another pure code layer to parse that into structured JSON.<p>I think it’s the JSON syntax (with curly braces) that does it in. So YAML or TOML might work just as well, but I haven’t tried that.</div><br/><div id="36335821" class="c"><input type="checkbox" id="c-36335821" checked=""/><div class="controls bullet"><span class="by">jacobsimon</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36335209">parent</a><span>|</span><a href="#36335803">next</a><span>|</span><label class="collapse" for="c-36335821">[-]</label><label class="expand" for="c-36335821">[1 more]</label></div><br/><div class="children"><div class="content">Coincidentally, I just published this JS library[1] over the weekend that helps prompt LLMs to return typed JSON data and validates it for you. Would love feedback on it if this is something people here are interested in. Haven’t played around with the new API yet but I think this is super exciting stuff!<p>[1] <a href="https:&#x2F;&#x2F;github.com&#x2F;jacobsimon&#x2F;prompting">https:&#x2F;&#x2F;github.com&#x2F;jacobsimon&#x2F;prompting</a></div><br/></div></div><div id="36335803" class="c"><input type="checkbox" id="c-36335803" checked=""/><div class="controls bullet"><span class="by">bombela</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36335209">parent</a><span>|</span><a href="#36335821">prev</a><span>|</span><a href="#36333643">next</a><span>|</span><label class="collapse" for="c-36335803">[-]</label><label class="expand" for="c-36335803">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s harder to form a tree with key value. I also tried the relational route. But it would always messup the cardinality (one person should have 0 or n friends, but a person has a single birth date).</div><br/><div id="36336054" class="c"><input type="checkbox" id="c-36336054" checked=""/><div class="controls bullet"><span class="by">rubyskills</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36335803">parent</a><span>|</span><a href="#36333643">next</a><span>|</span><label class="collapse" for="c-36336054">[-]</label><label class="expand" for="c-36336054">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s also harder to stream JSON? Maybe I&#x27;m overthinking this.</div><br/></div></div></div></div></div></div><div id="36333643" class="c"><input type="checkbox" id="c-36333643" checked=""/><div class="controls bullet"><span class="by">ignite</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36332614">parent</a><span>|</span><a href="#36335209">prev</a><span>|</span><a href="#36334559">next</a><span>|</span><label class="collapse" for="c-36333643">[-]</label><label class="expand" for="c-36333643">[10 more]</label></div><br/><div class="children"><div class="content">&gt; You just append ‘reply in json with this format’ and it does a really good job.<p>It does an ok job. Except when it doesn&#x27;t. Definitely misses a lot of the time, sometimes on prompts that succeeded on previous runs.</div><br/><div id="36334880" class="c"><input type="checkbox" id="c-36334880" checked=""/><div class="controls bullet"><span class="by">bel423</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36333643">parent</a><span>|</span><a href="#36334549">prev</a><span>|</span><a href="#36334559">next</a><span>|</span><label class="collapse" for="c-36334880">[-]</label><label class="expand" for="c-36334880">[8 more]</label></div><br/><div class="children"><div class="content">It literally does it everytime perfectly. I remember I put together an entire system that would validate the JSON against a zod schema and use reflection to fix it and it literally never gets triggered because GPT3.5-turbo always does it right the first time.</div><br/><div id="36335236" class="c"><input type="checkbox" id="c-36335236" checked=""/><div class="controls bullet"><span class="by">worik</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36334880">parent</a><span>|</span><a href="#36335383">next</a><span>|</span><label class="collapse" for="c-36335236">[-]</label><label class="expand" for="c-36335236">[2 more]</label></div><br/><div class="children"><div class="content">&gt; It literally does it everytime perfectly. I remember I put together an entire system that would validate the JSON against a zod schema and use reflection to fix it and it literally never gets triggered because GPT3.5-turbo always does it right the first time.<p>Danger!  There be assumptions!!<p>gpt-? is a moving target and in rapid development.  What it does Tuesday, which it did not do on Monday, it may well not do on Wednesday<p>If there is a documented method to guarantee it, it will work that way (modulo OpenAI bugs - and now Microsoft is involved....)<p>What we had before, what you are talking of, was observed behaviour.  An assumption  that what we observed in the past will continue in the future is not something to build a business on</div><br/><div id="36335462" class="c"><input type="checkbox" id="c-36335462" checked=""/><div class="controls bullet"><span class="by">travisjungroth</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36335236">parent</a><span>|</span><a href="#36335383">next</a><span>|</span><label class="collapse" for="c-36335462">[-]</label><label class="expand" for="c-36335462">[1 more]</label></div><br/><div class="children"><div class="content">ChatGPT moves fast. The API version doesn’t seem to change except with the model and documented API changes.</div><br/></div></div></div></div><div id="36335383" class="c"><input type="checkbox" id="c-36335383" checked=""/><div class="controls bullet"><span class="by">thomasfromcdnjs</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36334880">parent</a><span>|</span><a href="#36335236">prev</a><span>|</span><a href="#36335321">next</a><span>|</span><label class="collapse" for="c-36335383">[-]</label><label class="expand" for="c-36335383">[2 more]</label></div><br/><div class="children"><div class="content">Are you saying that it return only JSON before? I&#x27;m with the other commenters it was wildly variable and always at least said &quot;Here is your response&quot; which doesn&#x27;t parse well.</div><br/><div id="36335505" class="c"><input type="checkbox" id="c-36335505" checked=""/><div class="controls bullet"><span class="by">travisjungroth</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36335383">parent</a><span>|</span><a href="#36335321">next</a><span>|</span><label class="collapse" for="c-36335505">[-]</label><label class="expand" for="c-36335505">[1 more]</label></div><br/><div class="children"><div class="content">If you want a parsable response, have it wrap that with ```. Include an example request&#x2F;response in your history. Treat any message you can’t parse as an error message.<p>This works well because it has a place to put any “keep in mind” noise. You can actually include that in your example.</div><br/></div></div></div></div><div id="36335321" class="c"><input type="checkbox" id="c-36335321" checked=""/><div class="controls bullet"><span class="by">whateveracct</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36334880">parent</a><span>|</span><a href="#36335383">prev</a><span>|</span><a href="#36335824">next</a><span>|</span><label class="collapse" for="c-36335321">[-]</label><label class="expand" for="c-36335321">[2 more]</label></div><br/><div class="children"><div class="content">No it doesn&#x27;t lol. I&#x27;ve seen it just randomly not use a comma after one array element, for example.</div><br/><div id="36336458" class="c"><input type="checkbox" id="c-36336458" checked=""/><div class="controls bullet"><span class="by">LanceJones</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36335321">parent</a><span>|</span><a href="#36335824">next</a><span>|</span><label class="collapse" for="c-36336458">[-]</label><label class="expand" for="c-36336458">[1 more]</label></div><br/><div class="children"><div class="content">Yep. Incorrect trailing commas ad nauseum for me.</div><br/></div></div></div></div><div id="36335824" class="c"><input type="checkbox" id="c-36335824" checked=""/><div class="controls bullet"><span class="by">lmeyerov</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36334880">parent</a><span>|</span><a href="#36335321">prev</a><span>|</span><a href="#36334559">next</a><span>|</span><label class="collapse" for="c-36335824">[-]</label><label class="expand" for="c-36335824">[1 more]</label></div><br/><div class="children"><div class="content">Yeah no</div><br/></div></div></div></div></div></div><div id="36334559" class="c"><input type="checkbox" id="c-36334559" checked=""/><div class="controls bullet"><span class="by">sethd</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36332614">parent</a><span>|</span><a href="#36333643">prev</a><span>|</span><a href="#36332932">next</a><span>|</span><label class="collapse" for="c-36334559">[-]</label><label class="expand" for="c-36334559">[1 more]</label></div><br/><div class="children"><div class="content">I like to define a JSON schema (<a href="https:&#x2F;&#x2F;json-schema.org&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;json-schema.org&#x2F;</a>) and prompt GPT-4 to output JSON based on that schema.<p>This lets me specify general requirements (not just JSON structure) inline with the schema and in a very detailed and structured manor.</div><br/></div></div><div id="36332932" class="c"><input type="checkbox" id="c-36332932" checked=""/><div class="controls bullet"><span class="by">cwxm</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36332614">parent</a><span>|</span><a href="#36334559">prev</a><span>|</span><a href="#36335000">next</a><span>|</span><label class="collapse" for="c-36332932">[-]</label><label class="expand" for="c-36332932">[16 more]</label></div><br/><div class="children"><div class="content">even with gpt 4, it hallucinates enough that it’s not reliable, forgetting to open&#x2F;close brackets and quotes. This sounds like it’d be a big improvement.</div><br/><div id="36333249" class="c"><input type="checkbox" id="c-36333249" checked=""/><div class="controls bullet"><span class="by">jonplackett</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36332932">parent</a><span>|</span><a href="#36335324">next</a><span>|</span><label class="collapse" for="c-36333249">[-]</label><label class="expand" for="c-36333249">[11 more]</label></div><br/><div class="children"><div class="content">Not that it matters now but just doing something like this works 99% of the time or more with 4 and 90% with 3.5.<p>It is VERY IMPORTANT that you respond in valid JSON ONLY. Nothing before or after. Make sure to escape all strings. Use this format:<p>{“some_variable”: [describe the variable purpose]}</div><br/><div id="36333563" class="c"><input type="checkbox" id="c-36333563" checked=""/><div class="controls bullet"><span class="by">SamPatt</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36333249">parent</a><span>|</span><a href="#36334201">next</a><span>|</span><label class="collapse" for="c-36333563">[-]</label><label class="expand" for="c-36333563">[6 more]</label></div><br/><div class="children"><div class="content">99% of the time is still super frustrating when it fails, if you&#x27;re using it in a consumer facing app. You have to clean up the output to avoid getting an error. If it goes from 99% to 100% JSON that is a big deal for me, much simpler.</div><br/><div id="36333596" class="c"><input type="checkbox" id="c-36333596" checked=""/><div class="controls bullet"><span class="by">jonplackett</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36333563">parent</a><span>|</span><a href="#36333882">next</a><span>|</span><label class="collapse" for="c-36333596">[-]</label><label class="expand" for="c-36333596">[1 more]</label></div><br/><div class="children"><div class="content">Except it says in the small print to expect invalid JSON occasionally, so you have to write your error handling code either way</div><br/></div></div><div id="36333882" class="c"><input type="checkbox" id="c-36333882" checked=""/><div class="controls bullet"><span class="by">davepeck</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36333563">parent</a><span>|</span><a href="#36333596">prev</a><span>|</span><a href="#36334201">next</a><span>|</span><label class="collapse" for="c-36333882">[-]</label><label class="expand" for="c-36333882">[4 more]</label></div><br/><div class="children"><div class="content">Yup. Is there a good&#x2F;forgiving &quot;drunken JSON parser&quot; library that people like to use? Feels like it would be a useful (and separable) piece?</div><br/><div id="36334103" class="c"><input type="checkbox" id="c-36334103" checked=""/><div class="controls bullet"><span class="by">golol</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36333882">parent</a><span>|</span><a href="#36334201">next</a><span>|</span><label class="collapse" for="c-36334103">[-]</label><label class="expand" for="c-36334103">[3 more]</label></div><br/><div class="children"><div class="content">Honestly, I suspect asking GPT-4 to fix your JSON (in a new chat) is a good drunken JSON parser. We are only scraping the surface of what&#x27;s possible with LLMs. If Token generation was free and instant we could come up with a giant schema of interacting model calls that generates 10 suggestions, iterates over them, ranks them and picks the best one, as silly as it sounds.</div><br/><div id="36337668" class="c"><input type="checkbox" id="c-36337668" checked=""/><div class="controls bullet"><span class="by">andai</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36334103">parent</a><span>|</span><a href="#36334178">next</a><span>|</span><label class="collapse" for="c-36337668">[-]</label><label class="expand" for="c-36337668">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s hilarious... if parsing GPT&#x27;s JSON fails, keep asking GPT to fix it until it parses!</div><br/></div></div><div id="36334178" class="c"><input type="checkbox" id="c-36334178" checked=""/><div class="controls bullet"><span class="by">hhh</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36334103">parent</a><span>|</span><a href="#36337668">prev</a><span>|</span><a href="#36334201">next</a><span>|</span><label class="collapse" for="c-36334178">[-]</label><label class="expand" for="c-36334178">[1 more]</label></div><br/><div class="children"><div class="content">I already do this today to create domain-specific knowledge focused prompts and then have them iterate back and forth and a ‘moderator’ that chooses what goes in and what doesn’t.</div><br/></div></div></div></div></div></div></div></div><div id="36334201" class="c"><input type="checkbox" id="c-36334201" checked=""/><div class="controls bullet"><span class="by">8organicbits</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36333249">parent</a><span>|</span><a href="#36333563">prev</a><span>|</span><a href="#36335324">next</a><span>|</span><label class="collapse" for="c-36334201">[-]</label><label class="expand" for="c-36334201">[4 more]</label></div><br/><div class="children"><div class="content">Wouldn&#x27;t you use traditional software to validate the JSON, then ask chatgpt to try again if it wasn&#x27;t right?</div><br/><div id="36334659" class="c"><input type="checkbox" id="c-36334659" checked=""/><div class="controls bullet"><span class="by">girvo</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36334201">parent</a><span>|</span><a href="#36335324">next</a><span>|</span><label class="collapse" for="c-36334659">[-]</label><label class="expand" for="c-36334659">[3 more]</label></div><br/><div class="children"><div class="content">In my experience, telling it &quot;no thats wrong, try again&quot; just gets it to be wrong in a new different way, or restate the same wrong answer slightly differently. I&#x27;ve had to explicitly guide it to correct answers or formats at times.</div><br/><div id="36336369" class="c"><input type="checkbox" id="c-36336369" checked=""/><div class="controls bullet"><span class="by">cjbprime</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36334659">parent</a><span>|</span><a href="#36335972">next</a><span>|</span><label class="collapse" for="c-36336369">[-]</label><label class="expand" for="c-36336369">[1 more]</label></div><br/><div class="children"><div class="content">Try different phrasing, like &quot;Did your answer follow all of the criteria?&quot;.</div><br/></div></div></div></div></div></div></div></div><div id="36335324" class="c"><input type="checkbox" id="c-36335324" checked=""/><div class="controls bullet"><span class="by">whateveracct</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36332932">parent</a><span>|</span><a href="#36333249">prev</a><span>|</span><a href="#36333084">next</a><span>|</span><label class="collapse" for="c-36335324">[-]</label><label class="expand" for="c-36335324">[1 more]</label></div><br/><div class="children"><div class="content">It forgets commas too</div><br/></div></div><div id="36333084" class="c"><input type="checkbox" id="c-36333084" checked=""/><div class="controls bullet"><span class="by">ztratar</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36332932">parent</a><span>|</span><a href="#36335324">prev</a><span>|</span><a href="#36335000">next</a><span>|</span><label class="collapse" for="c-36333084">[-]</label><label class="expand" for="c-36333084">[3 more]</label></div><br/><div class="children"><div class="content">Nah, this was solved by most teams a while ago.</div><br/><div id="36334899" class="c"><input type="checkbox" id="c-36334899" checked=""/><div class="controls bullet"><span class="by">bel423</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36333084">parent</a><span>|</span><a href="#36335000">next</a><span>|</span><label class="collapse" for="c-36334899">[-]</label><label class="expand" for="c-36334899">[2 more]</label></div><br/><div class="children"><div class="content">I feel like I’m taking crazy pills with the amount of people saying this is game changing.<p>Did they not even try asking gpt to format the output as json?</div><br/><div id="36335266" class="c"><input type="checkbox" id="c-36335266" checked=""/><div class="controls bullet"><span class="by">worik</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36334899">parent</a><span>|</span><a href="#36335000">next</a><span>|</span><label class="collapse" for="c-36335266">[-]</label><label class="expand" for="c-36335266">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I feel like I’m taking crazy pills....try asking gpt to format the output as json<p>You are taking crazey pills.  Stop<p>gpt-? is unreliable!  That is not a bug in it, it is the nature of the beast.<p>It is not an expert at anything except natural language, and even then it is an idiot savant</div><br/></div></div></div></div></div></div></div></div><div id="36335000" class="c"><input type="checkbox" id="c-36335000" checked=""/><div class="controls bullet"><span class="by">muzani</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36332614">parent</a><span>|</span><a href="#36332932">prev</a><span>|</span><a href="#36334660">next</a><span>|</span><label class="collapse" for="c-36335000">[-]</label><label class="expand" for="c-36335000">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s fine, but the article makes some good points why - less cognitive load for GPT and less tokens. I think the transistor to logic gate analogy makes sense. You can build the thing perfectly with transistors, but just use the logic gate lol.</div><br/></div></div><div id="36334660" class="c"><input type="checkbox" id="c-36334660" checked=""/><div class="controls bullet"><span class="by">seizethecheese</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36332614">parent</a><span>|</span><a href="#36335000">prev</a><span>|</span><a href="#36333376">next</a><span>|</span><label class="collapse" for="c-36334660">[-]</label><label class="expand" for="c-36334660">[3 more]</label></div><br/><div class="children"><div class="content">In a production system, you don’t need easy to do most of the time, you need easy without fail.</div><br/><div id="36334730" class="c"><input type="checkbox" id="c-36334730" checked=""/><div class="controls bullet"><span class="by">pnpnp</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36334660">parent</a><span>|</span><a href="#36333376">next</a><span>|</span><label class="collapse" for="c-36334730">[-]</label><label class="expand" for="c-36334730">[2 more]</label></div><br/><div class="children"><div class="content">Ok, just playing devil&#x27;s advocate here. How many FAANG companies have you seen have an outage this year? What&#x27;s their budget?<p>I think a better way to reply to the author would have been &quot;how often does it fail&quot;?<p>Every system will have outages, it&#x27;s just a matter of how much money you can throw at the problem to reduce them.</div><br/><div id="36334754" class="c"><input type="checkbox" id="c-36334754" checked=""/><div class="controls bullet"><span class="by">jrockway</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36334730">parent</a><span>|</span><a href="#36333376">next</a><span>|</span><label class="collapse" for="c-36334754">[-]</label><label class="expand" for="c-36334754">[1 more]</label></div><br/><div class="children"><div class="content">If 99.995% correct looks bad to users, wait until they see 37%.</div><br/></div></div></div></div></div></div><div id="36333376" class="c"><input type="checkbox" id="c-36333376" checked=""/><div class="controls bullet"><span class="by">reallymental</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36332614">parent</a><span>|</span><a href="#36334660">prev</a><span>|</span><a href="#36335652">next</a><span>|</span><label class="collapse" for="c-36333376">[-]</label><label class="expand" for="c-36333376">[3 more]</label></div><br/><div class="children"><div class="content">Is there any publicly available resource replicate your work? I would love to just find the right kind of &quot;incantation&quot; for the gpt-3.5-t or gpt-4 to output a meaningful story arc etc.<p>Any examples of your work would be greatly helpful as well!</div><br/><div id="36335680" class="c"><input type="checkbox" id="c-36335680" checked=""/><div class="controls bullet"><span class="by">devbent</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36333376">parent</a><span>|</span><a href="#36333530">next</a><span>|</span><label class="collapse" for="c-36335680">[-]</label><label class="expand" for="c-36335680">[1 more]</label></div><br/><div class="children"><div class="content">I have an open source project doing exactly this at <a href="https:&#x2F;&#x2F;www.generativestorytelling.ai&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.generativestorytelling.ai&#x2F;</a> GitHub link is on the main page!</div><br/></div></div><div id="36333530" class="c"><input type="checkbox" id="c-36333530" checked=""/><div class="controls bullet"><span class="by">SamPatt</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36333376">parent</a><span>|</span><a href="#36335680">prev</a><span>|</span><a href="#36335652">next</a><span>|</span><label class="collapse" for="c-36333530">[-]</label><label class="expand" for="c-36333530">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not the person you&#x27;re asking, but I built a site that allows you to generate fiction if you have an OpenAI API key. You can see the prompts sent in console, and it&#x27;s all open source:<p><a href="https:&#x2F;&#x2F;havewords.ai&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;havewords.ai&#x2F;</a></div><br/></div></div></div></div><div id="36335652" class="c"><input type="checkbox" id="c-36335652" checked=""/><div class="controls bullet"><span class="by">throwuwu</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36332614">parent</a><span>|</span><a href="#36333376">prev</a><span>|</span><a href="#36333163">next</a><span>|</span><label class="collapse" for="c-36335652">[-]</label><label class="expand" for="c-36335652">[3 more]</label></div><br/><div class="children"><div class="content">Just end your request with<p>‘’’json<p>Or provide a few examples of user request and then agent response in json. Or both.</div><br/><div id="36335697" class="c"><input type="checkbox" id="c-36335697" checked=""/><div class="controls bullet"><span class="by">clbrmbr</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36335652">parent</a><span>|</span><a href="#36333163">next</a><span>|</span><label class="collapse" for="c-36335697">[-]</label><label class="expand" for="c-36335697">[2 more]</label></div><br/><div class="children"><div class="content">Does the ```json trick work with the chat models? Or only the earlier completion models?</div><br/><div id="36335727" class="c"><input type="checkbox" id="c-36335727" checked=""/><div class="controls bullet"><span class="by">throwuwu</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36335697">parent</a><span>|</span><a href="#36333163">next</a><span>|</span><label class="collapse" for="c-36335727">[-]</label><label class="expand" for="c-36335727">[1 more]</label></div><br/><div class="children"><div class="content">Works with chat. They’re still text completion models under all that rlhf</div><br/></div></div></div></div></div></div><div id="36333163" class="c"><input type="checkbox" id="c-36333163" checked=""/><div class="controls bullet"><span class="by">bradly</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36332614">parent</a><span>|</span><a href="#36335652">prev</a><span>|</span><a href="#36331728">next</a><span>|</span><label class="collapse" for="c-36333163">[-]</label><label class="expand" for="c-36333163">[8 more]</label></div><br/><div class="children"><div class="content">I could not get GPT-4 to reliably not give some sort of text response, even if was just a simple &quot;Sure&quot; followed by the JSON.</div><br/><div id="36335449" class="c"><input type="checkbox" id="c-36335449" checked=""/><div class="controls bullet"><span class="by">avereveard</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36333163">parent</a><span>|</span><a href="#36333533">next</a><span>|</span><label class="collapse" for="c-36335449">[-]</label><label class="expand" for="c-36335449">[1 more]</label></div><br/><div class="children"><div class="content">Pass in an agent message with &quot;Sure here is the answer in json format:&quot; after the user message. Gpt will think it has already done the preamble and the rest of the message will start right with the json.</div><br/></div></div><div id="36333533" class="c"><input type="checkbox" id="c-36333533" checked=""/><div class="controls bullet"><span class="by">rytill</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36333163">parent</a><span>|</span><a href="#36335449">prev</a><span>|</span><a href="#36331728">next</a><span>|</span><label class="collapse" for="c-36333533">[-]</label><label class="expand" for="c-36333533">[6 more]</label></div><br/><div class="children"><div class="content">Did you try using the API and providing a very clear system message followed by several examples that were pure JSON?</div><br/><div id="36334378" class="c"><input type="checkbox" id="c-36334378" checked=""/><div class="controls bullet"><span class="by">bradly</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36333533">parent</a><span>|</span><a href="#36331728">next</a><span>|</span><label class="collapse" for="c-36334378">[-]</label><label class="expand" for="c-36334378">[5 more]</label></div><br/><div class="children"><div class="content">Yep. I even gave it a JSON schema file to use. It just wouldn&#x27;t stop added extra verbage.</div><br/><div id="36334640" class="c"><input type="checkbox" id="c-36334640" checked=""/><div class="controls bullet"><span class="by">taylorfinley</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36334378">parent</a><span>|</span><a href="#36334514">next</a><span>|</span><label class="collapse" for="c-36334640">[-]</label><label class="expand" for="c-36334640">[1 more]</label></div><br/><div class="children"><div class="content">I just use a regex to select everything between the first and last curly bracket, reliable fixes the “sure, here’s your object” problem.</div><br/></div></div><div id="36334514" class="c"><input type="checkbox" id="c-36334514" checked=""/><div class="controls bullet"><span class="by">NicoJuicy</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36334378">parent</a><span>|</span><a href="#36334640">prev</a><span>|</span><a href="#36331728">next</a><span>|</span><label class="collapse" for="c-36334514">[-]</label><label class="expand" for="c-36334514">[3 more]</label></div><br/><div class="children"><div class="content">Say it&#x27;s a json API and may only reply with valid json without explanation.</div><br/><div id="36334818" class="c"><input type="checkbox" id="c-36334818" checked=""/><div class="controls bullet"><span class="by">bradly</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36334514">parent</a><span>|</span><a href="#36331728">next</a><span>|</span><label class="collapse" for="c-36334818">[-]</label><label class="expand" for="c-36334818">[2 more]</label></div><br/><div class="children"><div class="content">Lol yes of course I tried that.</div><br/><div id="36334981" class="c"><input type="checkbox" id="c-36334981" checked=""/><div class="controls bullet"><span class="by">dror</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36334818">parent</a><span>|</span><a href="#36331728">next</a><span>|</span><label class="collapse" for="c-36334981">[-]</label><label class="expand" for="c-36334981">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve had good luck with both:<p><a href="https:&#x2F;&#x2F;github.com&#x2F;drorm&#x2F;gish&#x2F;blob&#x2F;main&#x2F;tasks&#x2F;coding.txt">https:&#x2F;&#x2F;github.com&#x2F;drorm&#x2F;gish&#x2F;blob&#x2F;main&#x2F;tasks&#x2F;coding.txt</a><p>and<p><a href="https:&#x2F;&#x2F;github.com&#x2F;drorm&#x2F;gish&#x2F;blob&#x2F;main&#x2F;tasks&#x2F;webapp.txt">https:&#x2F;&#x2F;github.com&#x2F;drorm&#x2F;gish&#x2F;blob&#x2F;main&#x2F;tasks&#x2F;webapp.txt</a><p>With the second one, I reliably generated half a dozen apps with one command.<p>Not to say that it won&#x27;t fail sometimes.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="36331728" class="c"><input type="checkbox" id="c-36331728" checked=""/><div class="controls bullet"><span class="by">majormajor</span><span>|</span><a href="#36331548">parent</a><span>|</span><a href="#36332614">prev</a><span>|</span><a href="#36332459">next</a><span>|</span><label class="collapse" for="c-36331728">[-]</label><label class="expand" for="c-36331728">[4 more]</label></div><br/><div class="children"><div class="content">GPT-4 was already a massive improvement on 3.5 in terms of replying consistently in a certain JSON structure - I often don&#x27;t even need to give examples, just a sentence describing the format.<p>It&#x27;s great to see they&#x27;re making it even better, but where I&#x27;m currently hitting the limit still in GPT-4 for &quot;shelling out&quot; is about it being truly &quot;creative&quot; or &quot;introspective&quot; about &quot;do I need to ask for clarifications&quot; or &quot;can I find a truly novel away around this task&quot; type of things vs &quot;here&#x27;s a possible but half-baked sequence I&#x27;m going to follow&quot;.</div><br/><div id="36334576" class="c"><input type="checkbox" id="c-36334576" checked=""/><div class="controls bullet"><span class="by">fumar</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36331728">parent</a><span>|</span><a href="#36332459">next</a><span>|</span><label class="collapse" for="c-36334576">[-]</label><label class="expand" for="c-36334576">[3 more]</label></div><br/><div class="children"><div class="content">It is “good enough”. Where I struggle is maintaining its memory through a longer request where multiple iterations fail or succeed and then all of a sudden its memory is exceeded and starts fresh. I wish I could store “learnings” that it could revisit.</div><br/><div id="36335074" class="c"><input type="checkbox" id="c-36335074" checked=""/><div class="controls bullet"><span class="by">ehsanu1</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36334576">parent</a><span>|</span><a href="#36332459">next</a><span>|</span><label class="collapse" for="c-36335074">[-]</label><label class="expand" for="c-36335074">[2 more]</label></div><br/><div class="children"><div class="content">Sounds like you want something like tree of thoughts: <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2305.10601" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2305.10601</a></div><br/><div id="36336983" class="c"><input type="checkbox" id="c-36336983" checked=""/><div class="controls bullet"><span class="by">jimmySixDOF</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36335074">parent</a><span>|</span><a href="#36332459">next</a><span>|</span><label class="collapse" for="c-36336983">[-]</label><label class="expand" for="c-36336983">[1 more]</label></div><br/><div class="children"><div class="content">Interestingly the paper&#x27;s repo starts off :<p>Blah Blah &quot;...is NOT the correct implementation to replicate paper results. In fact, people have reported that his code cannot properly run, and is probably automatically generated by ChatGPT, and kyegomez has done so for other popular ML methods, while intentionally refusing to link to official implementations for his own interests&quot;<p>Love a good GitHub Identity Theft Star farming ML story<p>But this method could have potential  for a chain of function</div><br/></div></div></div></div></div></div></div></div><div id="36332459" class="c"><input type="checkbox" id="c-36332459" checked=""/><div class="controls bullet"><span class="by">lbeurerkellner</span><span>|</span><a href="#36331548">parent</a><span>|</span><a href="#36331728">prev</a><span>|</span><a href="#36331651">next</a><span>|</span><label class="collapse" for="c-36332459">[-]</label><label class="expand" for="c-36332459">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s interesting to think about this form of computation (LLM + function call) in terms of circuitry. It is still unclear to me however, if the sequential form of reasoning imposed by a sequence of chat messages is the right model here. LLM decoding and also more high-level &quot;reasoning algorithms&quot; like tree of thought are not that linear.<p>Ever since we started working on LMQL, the overarching vision all along was to get to a form of language model programming, where LLM calls are just the smallest primitive of the &quot;text computer&quot; you are running on. It will be interesting to see what kind of patterns emerge, now that the smallest primitive becomes more robust and reliable, at least in terms of the interface.</div><br/></div></div><div id="36331651" class="c"><input type="checkbox" id="c-36331651" checked=""/><div class="controls bullet"><span class="by">minimaxir</span><span>|</span><a href="#36331548">parent</a><span>|</span><a href="#36332459">prev</a><span>|</span><a href="#36336409">next</a><span>|</span><label class="collapse" for="c-36331651">[-]</label><label class="expand" for="c-36331651">[4 more]</label></div><br/><div class="children"><div class="content">&quot;Trivial&quot; is misleading. From OpenAI&#x27;s docs and demos, the full ReAct workflow is an order of magnitude more difficult than typical ChatGPT API usage with a new set of constaints (e.g. schema definitions)<p>Even OpenAI&#x27;s notebook demo has error handling workflows which was actually necessary since ChatGPT returned incorrect formatted output.</div><br/><div id="36332912" class="c"><input type="checkbox" id="c-36332912" checked=""/><div class="controls bullet"><span class="by">cjonas</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36331651">parent</a><span>|</span><a href="#36336409">next</a><span>|</span><label class="collapse" for="c-36332912">[-]</label><label class="expand" for="c-36332912">[3 more]</label></div><br/><div class="children"><div class="content">Maybe trivial isn&#x27;t the right word, but it&#x27;s still very straight-forward to get something basic, yet really powerful...<p>ReAct Setup Prompt (goal + available actions) -&gt; Agent &quot;ReAction&quot; -&gt; Parse &amp; Execute Action -&gt; Send Action Response (success or error) -&gt; Agent &quot;ReAction&quot; -&gt; repeat<p>As long as each action has proper validation and returns meaningful error messages, you don&#x27;t need to even change the control flow.  The agent will typically understand what went wrong, and attempt to correct it in the next &quot;ReAction&quot;.<p>I&#x27;ve been refactoring some agents to use &quot;functions&quot; and so far it seems to be a HUGE improvement in reliability vs the &quot;Return JSON matching this format&quot; approach.  Most impactful is that fact that &quot;3.5-turbo&quot; will now reliability return JSON (before you&#x27;d be forced to use GPT-4 for an ReAct style agent of modest complexity).<p>My agents also seem to be better at following other instructions now that the noise of the response format is gone (of course it&#x27;s still there, but in a way it has been specifically trained on).  This could also just be a result of the improvements to the system prompt though.</div><br/><div id="36335694" class="c"><input type="checkbox" id="c-36335694" checked=""/><div class="controls bullet"><span class="by">devbent</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36332912">parent</a><span>|</span><a href="#36333333">next</a><span>|</span><label class="collapse" for="c-36335694">[-]</label><label class="expand" for="c-36335694">[1 more]</label></div><br/><div class="children"><div class="content">For 3.5, I found it easiest to specify a simple, but parsable, format for responses and then convert that to JSON myself.<p>I&#x27;ll have to see if the new JSON schema support is easier than what I already have in place.</div><br/></div></div></div></div></div></div><div id="36336409" class="c"><input type="checkbox" id="c-36336409" checked=""/><div class="controls bullet"><span class="by">quickthrower2</span><span>|</span><a href="#36331548">parent</a><span>|</span><a href="#36331651">prev</a><span>|</span><a href="#36335398">next</a><span>|</span><label class="collapse" for="c-36336409">[-]</label><label class="expand" for="c-36336409">[1 more]</label></div><br/><div class="children"><div class="content">The first transistors were slow, and it seems this &quot;GPT3&#x2F;4 calling itself&quot; stuff is quite slow. GPT3&#x2F;4 as a direct chat is about as slow as I can take. Once this gets sped up.<p>I am sure it will, as you can scale out, scale up and build more efficient code and build more efficient architectures and &quot;tool for the job&quot; different parts of the process.<p>The problem now (using auto gpt, for example) is accuracy is bad, so you need human feedback and intervention AND it is slow. Take away the slow, or the needing human intervention and this can be very powerful.<p>I dream of the breakthrough &quot;shitty old laptop is all you need&quot; paper where they figure out how to do amazing stuff with a 1Gb of space on a spinny disk and 1Gb RAM and a CPU.</div><br/></div></div><div id="36335398" class="c"><input type="checkbox" id="c-36335398" checked=""/><div class="controls bullet"><span class="by">boringuser2</span><span>|</span><a href="#36331548">parent</a><span>|</span><a href="#36336409">prev</a><span>|</span><a href="#36336722">next</a><span>|</span><label class="collapse" for="c-36335398">[-]</label><label class="expand" for="c-36335398">[7 more]</label></div><br/><div class="children"><div class="content">Do you people always have to overhype this shit?</div><br/><div id="36335633" class="c"><input type="checkbox" id="c-36335633" checked=""/><div class="controls bullet"><span class="by">throwuwu</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36335398">parent</a><span>|</span><a href="#36335924">next</a><span>|</span><label class="collapse" for="c-36335633">[-]</label><label class="expand" for="c-36335633">[4 more]</label></div><br/><div class="children"><div class="content">What’s your problem? There’s nothing overhyped about that comment. People, including me, <i>are</i> building complex agents that can execute multi stage prompts and perform complex tasks. Comparing these first models to a basic unit of logic is more than fair given how much more capable they are. Do you just have an axe to grind?</div><br/></div></div><div id="36335924" class="c"><input type="checkbox" id="c-36335924" checked=""/><div class="controls bullet"><span class="by">delhanty</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36335398">parent</a><span>|</span><a href="#36335633">prev</a><span>|</span><a href="#36336722">next</a><span>|</span><label class="collapse" for="c-36335924">[-]</label><label class="expand" for="c-36335924">[2 more]</label></div><br/><div class="children"><div class="content">Do <i>you</i> have to be nasty?<p>That&#x27;s a person you&#x27;re replying to with feelings, so why not default to being kind in comments as per HN guidelines?<p>As it happens, swyx has built notable AI related things, for example smol-developer<p><a href="https:&#x2F;&#x2F;twitter.com&#x2F;swyx&#x2F;status&#x2F;1657892220492738560" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;swyx&#x2F;status&#x2F;1657892220492738560</a><p>and it would be nice to be able to read his and other perspectives without having to read shallow, mean, dismissive replies such as yours.</div><br/><div id="36336510" class="c"><input type="checkbox" id="c-36336510" checked=""/><div class="controls bullet"><span class="by">boringuser2</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36335924">parent</a><span>|</span><a href="#36336722">next</a><span>|</span><label class="collapse" for="c-36336510">[-]</label><label class="expand" for="c-36336510">[1 more]</label></div><br/><div class="children"><div class="content">Stop being a hall-monitor.<p>These types of posts are the absolute most ridiculous available on this website.</div><br/></div></div></div></div></div></div><div id="36336722" class="c"><input type="checkbox" id="c-36336722" checked=""/><div class="controls bullet"><span class="by">SimianLogic</span><span>|</span><a href="#36331548">parent</a><span>|</span><a href="#36335398">prev</a><span>|</span><a href="#36335653">next</a><span>|</span><label class="collapse" for="c-36336722">[-]</label><label class="expand" for="c-36336722">[1 more]</label></div><br/><div class="children"><div class="content">I agree with this. We’ve already gotten pretty good at json coercion, but this seems like it goes one step further by bundling decision making in to the model instead of junking up your prompt or requiring some kind of eval on a single json response.<p>It should also be much easier to cache these functions. If you send the same set of functions on every API hit, OpenAI should be able to cache that more intelligently than if everything was one big text prompt.</div><br/></div></div><div id="36335653" class="c"><input type="checkbox" id="c-36335653" checked=""/><div class="controls bullet"><span class="by">jarulraj</span><span>|</span><a href="#36331548">parent</a><span>|</span><a href="#36336722">prev</a><span>|</span><a href="#36334507">next</a><span>|</span><label class="collapse" for="c-36335653">[-]</label><label class="expand" for="c-36335653">[1 more]</label></div><br/><div class="children"><div class="content">Interesting observation, @swyx. There seems to be a connection to transitive closure in SQL queries, where the output of the query is fed as the input to the query in the next iteration [1]. We are thinking about how to best support such recursive functions in EvaDB [2].<p>[1] <a href="http:&#x2F;&#x2F;dwhoman.com&#x2F;blog&#x2F;sql-transitive-closure.html" rel="nofollow noreferrer">http:&#x2F;&#x2F;dwhoman.com&#x2F;blog&#x2F;sql-transitive-closure.html</a>
[2] <a href="https:&#x2F;&#x2F;evadb.readthedocs.io&#x2F;en&#x2F;stable&#x2F;source&#x2F;tutorials&#x2F;11-similarity-search-for-motif-mining.html#image-level-similarity-search-pipeline" rel="nofollow noreferrer">https:&#x2F;&#x2F;evadb.readthedocs.io&#x2F;en&#x2F;stable&#x2F;source&#x2F;tutorials&#x2F;11-s...</a></div><br/></div></div><div id="36334507" class="c"><input type="checkbox" id="c-36334507" checked=""/><div class="controls bullet"><span class="by">freezed88</span><span>|</span><a href="#36331548">parent</a><span>|</span><a href="#36335653">prev</a><span>|</span><a href="#36332495">next</a><span>|</span><label class="collapse" for="c-36334507">[-]</label><label class="expand" for="c-36334507">[2 more]</label></div><br/><div class="children"><div class="content">100%, if the API itself can choose to call a function or an LLM, then it&#x27;s way easier to build any agent loop without extensive prompt engineering + worrying about errors.<p>Tweeted about it here as well: <a href="https:&#x2F;&#x2F;twitter.com&#x2F;jerryjliu0&#x2F;status&#x2F;1668994580396621827?s=20" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;jerryjliu0&#x2F;status&#x2F;1668994580396621827?s=...</a></div><br/><div id="36334917" class="c"><input type="checkbox" id="c-36334917" checked=""/><div class="controls bullet"><span class="by">bel423</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36334507">parent</a><span>|</span><a href="#36332495">next</a><span>|</span><label class="collapse" for="c-36334917">[-]</label><label class="expand" for="c-36334917">[1 more]</label></div><br/><div class="children"><div class="content">You still have to worry about errors. You will probably have to add an error handler function that it can call out to. Otherwise the LLM will hallucinate a valid output regardless of the input. You want it to be able to throw an error and say I could produce the output given this format.</div><br/></div></div></div></div><div id="36332495" class="c"><input type="checkbox" id="c-36332495" checked=""/><div class="controls bullet"><span class="by">ftxbro</span><span>|</span><a href="#36331548">parent</a><span>|</span><a href="#36334507">prev</a><span>|</span><a href="#36333491">next</a><span>|</span><label class="collapse" for="c-36332495">[-]</label><label class="expand" for="c-36332495">[5 more]</label></div><br/><div class="children"><div class="content">&gt; &quot;you can now trivially make GPT4 decide whether to call itself again, or to proceed to the next stage.&quot;<p>Does this mean the GPT-4 API is now publicly available, or is there still a waitlist? If there&#x27;s a waitlist and you literally are not allowed to use it no matter how much you are willing to pay then it seems like it&#x27;s hard to call that trivial.</div><br/><div id="36332586" class="c"><input type="checkbox" id="c-36332586" checked=""/><div class="controls bullet"><span class="by">Tostino</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36332495">parent</a><span>|</span><a href="#36332565">next</a><span>|</span><label class="collapse" for="c-36332586">[-]</label><label class="expand" for="c-36332586">[3 more]</label></div><br/><div class="children"><div class="content">Not GP, but it&#x27;s still the latter...i&#x27;ve been (im)patiently waiting.<p>From their blog post the other day:
With these updates, we’ll be inviting many more people from the waitlist to try GPT-4 over the coming weeks, with the intent to remove the waitlist entirely with this model. Thank you to everyone who has been patiently waiting, we are excited to see what you build with GPT-4!</div><br/><div id="36333436" class="c"><input type="checkbox" id="c-36333436" checked=""/><div class="controls bullet"><span class="by">londons_explore</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36332586">parent</a><span>|</span><a href="#36332565">next</a><span>|</span><label class="collapse" for="c-36333436">[-]</label><label class="expand" for="c-36333436">[2 more]</label></div><br/><div class="children"><div class="content">If you put contact info in your HN profile - especially an email address that matches one you use to login to openai, someone will probably give you access...<p>Anyone with access can share it with any other user via the &#x27;invite to organisation&#x27; feature.   Obviously that allows the invited person do requests billed to the inviter, but since most experiments are only a few cents that doesn&#x27;t really matter much in practice.</div><br/><div id="36334278" class="c"><input type="checkbox" id="c-36334278" checked=""/><div class="controls bullet"><span class="by">Tostino</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36333436">parent</a><span>|</span><a href="#36332565">next</a><span>|</span><label class="collapse" for="c-36334278">[-]</label><label class="expand" for="c-36334278">[1 more]</label></div><br/><div class="children"><div class="content">Good to know, but I&#x27;ve racked up a decent bill for just my GPT 3.5 use. I can get by with experiments using my ChatGPT Plus subscription, but I really need my own API access to start using it for anything serious.</div><br/></div></div></div></div></div></div><div id="36332565" class="c"><input type="checkbox" id="c-36332565" checked=""/><div class="controls bullet"><span class="by">bayesianbot</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36332495">parent</a><span>|</span><a href="#36332586">prev</a><span>|</span><a href="#36333491">next</a><span>|</span><label class="collapse" for="c-36332565">[-]</label><label class="expand" for="c-36332565">[1 more]</label></div><br/><div class="children"><div class="content">&quot;With these updates, we’ll be inviting many more people from the waitlist to try GPT-4 over the coming weeks, with the intent to remove the waitlist entirely with this model. Thank you to everyone who has been patiently waiting, we are excited to see what you build with GPT-4!&quot;<p><a href="https:&#x2F;&#x2F;openai.com&#x2F;blog&#x2F;function-calling-and-other-api-updates" rel="nofollow noreferrer">https:&#x2F;&#x2F;openai.com&#x2F;blog&#x2F;function-calling-and-other-api-updat...</a></div><br/></div></div></div></div><div id="36333491" class="c"><input type="checkbox" id="c-36333491" checked=""/><div class="controls bullet"><span class="by">moneywoes</span><span>|</span><a href="#36331548">parent</a><span>|</span><a href="#36332495">prev</a><span>|</span><a href="#36333110">next</a><span>|</span><label class="collapse" for="c-36333491">[-]</label><label class="expand" for="c-36333491">[5 more]</label></div><br/><div class="children"><div class="content">Wow your brand is huge. Crazy growth. i wonder how much these subtle mentions on forums help</div><br/><div id="36333786" class="c"><input type="checkbox" id="c-36333786" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36333491">parent</a><span>|</span><a href="#36334854">next</a><span>|</span><label class="collapse" for="c-36333786">[-]</label><label class="expand" for="c-36333786">[3 more]</label></div><br/><div class="children"><div class="content">They&#x27;re the only one commenter on HN I noticed keeps writing &quot;smol&quot; instead of &quot;small&quot;, and is associated with projects with &quot;smol&quot; in their name. Surely I&#x27;m not the only one who missed it being a meme around 2015 or sth., and finds this word&#x2F;use jarring - and therefore very attention-grabbing? Wonder how much that helps with marketing.<p>This is meant with no negative intentions. It&#x27;s just that &#x27;swyx was, in my mind, &quot;that HN-er that does AI and keeps saying &#x27;smol&#x27;&quot; for far longer than I was aware of latent.space articles&#x2F;podcasts.</div><br/><div id="36334575" class="c"><input type="checkbox" id="c-36334575" checked=""/><div class="controls bullet"><span class="by">memefrog</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36333786">parent</a><span>|</span><a href="#36334863">next</a><span>|</span><label class="collapse" for="c-36334575">[-]</label><label class="expand" for="c-36334575">[1 more]</label></div><br/><div class="children"><div class="content">Personally, I associate &quot;smol&quot; with &quot;doggo&quot; and &quot;chonker&quot; and other childish redditspeak.</div><br/></div></div><div id="36334863" class="c"><input type="checkbox" id="c-36334863" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36333786">parent</a><span>|</span><a href="#36334575">prev</a><span>|</span><a href="#36334854">next</a><span>|</span><label class="collapse" for="c-36334863">[-]</label><label class="expand" for="c-36334863">[1 more]</label></div><br/><div class="children"><div class="content">and fun fact i used to work at Temporal too heheh.</div><br/></div></div></div></div><div id="36334854" class="c"><input type="checkbox" id="c-36334854" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36333491">parent</a><span>|</span><a href="#36333786">prev</a><span>|</span><a href="#36333110">next</a><span>|</span><label class="collapse" for="c-36334854">[-]</label><label class="expand" for="c-36334854">[1 more]</label></div><br/><div class="children"><div class="content">i mean hopefully its relevant content to the discussion, i hope enough pple know me here by now that i fully participate in The Discourse rather than just being here to cynically plug my stuff. i had a 1.5 hr convo with simon willison and other well known AI tinkerers on this exact thing, and so I shared it, making the most out of their time that they chose to share with me.</div><br/></div></div></div></div><div id="36333110" class="c"><input type="checkbox" id="c-36333110" checked=""/><div class="controls bullet"><span class="by">ilaksh</span><span>|</span><a href="#36331548">parent</a><span>|</span><a href="#36333491">prev</a><span>|</span><a href="#36333555">next</a><span>|</span><label class="collapse" for="c-36333110">[-]</label><label class="expand" for="c-36333110">[3 more]</label></div><br/><div class="children"><div class="content">The thing is the relevant context often depends on what it&#x27;s trying to do. You can give it a lot of context in 16k but if there are too many different types of things then I think it will be confused or at least have less capacity for the actual selected task.<p>So what I am thinking is that some functions might just be like gateways into a second menu level. So instead of just edit_file with the filename and new source, maybe only select_files_for_edit is available at the top level. In that case I can ensure it doesn&#x27;t try to overwrite an existing file without important stuff that was already in there, by providing the requested files existing contents along with the function allowing the file edit.</div><br/><div id="36335723" class="c"><input type="checkbox" id="c-36335723" checked=""/><div class="controls bullet"><span class="by">throwuwu</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36333110">parent</a><span>|</span><a href="#36333570">next</a><span>|</span><label class="collapse" for="c-36335723">[-]</label><label class="expand" for="c-36335723">[1 more]</label></div><br/><div class="children"><div class="content">Not sure that’s true. I haven’t completely filled the context with examples but I do provide 8 or so exchanges between user and assistant along with a menu of available commands and it seems to be able to generalize from that very well. No hallucinations either. Good idea about sub menus though, I’ll have to use that.</div><br/></div></div><div id="36333570" class="c"><input type="checkbox" id="c-36333570" checked=""/><div class="controls bullet"><span class="by">naiv</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36333110">parent</a><span>|</span><a href="#36335723">prev</a><span>|</span><a href="#36333555">next</a><span>|</span><label class="collapse" for="c-36333570">[-]</label><label class="expand" for="c-36333570">[1 more]</label></div><br/><div class="children"><div class="content">I think big context only makes sense for document analysis.<p>For programming you want to keep it slim. Just like you should keep your controllers and classes slim.<p>Also people with 32k access report very very long response times of up to multiple minutes which is not feasible if you only want a smaller change or analysis.</div><br/></div></div></div></div><div id="36333555" class="c"><input type="checkbox" id="c-36333555" checked=""/><div class="controls bullet"><span class="by">babyshake</span><span>|</span><a href="#36331548">parent</a><span>|</span><a href="#36333110">prev</a><span>|</span><a href="#36334897">next</a><span>|</span><label class="collapse" for="c-36333555">[-]</label><label class="expand" for="c-36333555">[2 more]</label></div><br/><div class="children"><div class="content">What would be an example where there needs to be an arbitrary level of recursive ability for GPT4 to call itself?</div><br/><div id="36335130" class="c"><input type="checkbox" id="c-36335130" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36333555">parent</a><span>|</span><a href="#36334897">next</a><span>|</span><label class="collapse" for="c-36335130">[-]</label><label class="expand" for="c-36335130">[1 more]</label></div><br/><div class="children"><div class="content">writing code of higher complexity (we know from CICERO that longer time spent on inference is worth orders of magnitude more than the equivalent in training when it comes to improving end performance), or doing real world tasks with unknown fractal depth (aka yak shave)</div><br/></div></div></div></div><div id="36334897" class="c"><input type="checkbox" id="c-36334897" checked=""/><div class="controls bullet"><span class="by">killingtime74</span><span>|</span><a href="#36331548">parent</a><span>|</span><a href="#36333555">prev</a><span>|</span><a href="#36331206">next</a><span>|</span><label class="collapse" for="c-36334897">[-]</label><label class="expand" for="c-36334897">[3 more]</label></div><br/><div class="children"><div class="content">Who is Simon Willison? Is he big in AI?</div><br/><div id="36334915" class="c"><input type="checkbox" id="c-36334915" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36334897">parent</a><span>|</span><a href="#36331206">next</a><span>|</span><label class="collapse" for="c-36334915">[-]</label><label class="expand" for="c-36334915">[2 more]</label></div><br/><div class="children"><div class="content">formerly cocreator of Django, now Datasette, but pretty much the top writer&#x2F;hacker on HN making AI topics accessible to engineers <a href="https:&#x2F;&#x2F;hn.algolia.com&#x2F;?dateRange=pastYear&amp;page=0&amp;prefix=true&amp;query=https%3A%2F%2Fsimonwillison.net%2F&amp;sort=byPopularity&amp;type=story" rel="nofollow noreferrer">https:&#x2F;&#x2F;hn.algolia.com&#x2F;?dateRange=pastYear&amp;page=0&amp;prefix=tru...</a></div><br/><div id="36334990" class="c"><input type="checkbox" id="c-36334990" checked=""/><div class="controls bullet"><span class="by">killingtime74</span><span>|</span><a href="#36331548">root</a><span>|</span><a href="#36334915">parent</a><span>|</span><a href="#36331206">next</a><span>|</span><label class="collapse" for="c-36334990">[-]</label><label class="expand" for="c-36334990">[1 more]</label></div><br/><div class="children"><div class="content">Oh wow, nice! Big fan of his work</div><br/></div></div></div></div></div></div></div></div><div id="36331206" class="c"><input type="checkbox" id="c-36331206" checked=""/><div class="controls bullet"><span class="by">minimaxir</span><span>|</span><a href="#36331548">prev</a><span>|</span><a href="#36333946">next</a><span>|</span><label class="collapse" for="c-36331206">[-]</label><label class="expand" for="c-36331206">[24 more]</label></div><br/><div class="children"><div class="content">After reading the docs for the new ChatGPT function calling yesterday, it&#x27;s structured and&#x2F;or typed data for GPT input or output that&#x27;s the key feature of these new models. The ReAct flow of tool selection that it provides is secondary.<p>As this post notes, you don&#x27;t even need to the full flow of passing a function result back to the model: getting structured data from ChatGPT in itself has a lot of fun and practical use cases. You could coax previous versions of ChatGPT to &quot;output results as JSON&quot; with a system prompt but in practice results are mixed, although even with this finetuned model the docs warn that there still could be parsing errors.<p>OpenAI&#x27;s demo for function calling is not a Hello World, to put it mildly: <a href="https:&#x2F;&#x2F;github.com&#x2F;openai&#x2F;openai-cookbook&#x2F;blob&#x2F;main&#x2F;examples&#x2F;How_to_call_functions_with_chat_models.ipynb">https:&#x2F;&#x2F;github.com&#x2F;openai&#x2F;openai-cookbook&#x2F;blob&#x2F;main&#x2F;examples...</a></div><br/><div id="36331351" class="c"><input type="checkbox" id="c-36331351" checked=""/><div class="controls bullet"><span class="by">tornato7</span><span>|</span><a href="#36331206">parent</a><span>|</span><a href="#36337252">next</a><span>|</span><label class="collapse" for="c-36331351">[-]</label><label class="expand" for="c-36331351">[13 more]</label></div><br/><div class="children"><div class="content">IIRC, there&#x27;s a way to &quot;force&quot; LLMs to output proper JSON by adding some logic to the top token selection. I.e. in the randomness function (which OpenAI calls temperature) you&#x27;d never choose a next token that results in broken JSON. The only reason it wouldn&#x27;t would be if the output exceeds the token limit. I wonder if OpenAI is doing something like this.</div><br/><div id="36331552" class="c"><input type="checkbox" id="c-36331552" checked=""/><div class="controls bullet"><span class="by">ManuelKiessling</span><span>|</span><a href="#36331206">root</a><span>|</span><a href="#36331351">parent</a><span>|</span><a href="#36331466">next</a><span>|</span><label class="collapse" for="c-36331552">[-]</label><label class="expand" for="c-36331552">[3 more]</label></div><br/><div class="children"><div class="content">Note that you don’t necessarily need to have the AI output any JSON at all — simply have it answer when being asked for the value to a specific JSON key, and handle the JSON structure part in your hallucinations-free own code: <a href="https:&#x2F;&#x2F;github.com&#x2F;manuelkiessling&#x2F;php-ai-tool-bridge">https:&#x2F;&#x2F;github.com&#x2F;manuelkiessling&#x2F;php-ai-tool-bridge</a></div><br/><div id="36335906" class="c"><input type="checkbox" id="c-36335906" checked=""/><div class="controls bullet"><span class="by">lyjackal</span><span>|</span><a href="#36331206">root</a><span>|</span><a href="#36331552">parent</a><span>|</span><a href="#36331915">next</a><span>|</span><label class="collapse" for="c-36335906">[-]</label><label class="expand" for="c-36335906">[1 more]</label></div><br/><div class="children"><div class="content">Would be nice if you could send a back and forth interaction for each key. This approach turns into lots of requests that reapply the entire context and ends up slow. I wish i could just send a Microsoft guidance template program, and process that in a single pass.</div><br/></div></div><div id="36331915" class="c"><input type="checkbox" id="c-36331915" checked=""/><div class="controls bullet"><span class="by">naiv</span><span>|</span><a href="#36331206">root</a><span>|</span><a href="#36331552">parent</a><span>|</span><a href="#36335906">prev</a><span>|</span><a href="#36331466">next</a><span>|</span><label class="collapse" for="c-36331915">[-]</label><label class="expand" for="c-36331915">[1 more]</label></div><br/><div class="children"><div class="content">Thanks for sharing!</div><br/></div></div></div></div><div id="36331466" class="c"><input type="checkbox" id="c-36331466" checked=""/><div class="controls bullet"><span class="by">senko</span><span>|</span><a href="#36331206">root</a><span>|</span><a href="#36331351">parent</a><span>|</span><a href="#36331552">prev</a><span>|</span><a href="#36331597">next</a><span>|</span><label class="collapse" for="c-36331466">[-]</label><label class="expand" for="c-36331466">[2 more]</label></div><br/><div class="children"><div class="content">It would seem not, as the official documentation mentions the arguments may be hallucinated or <i>be a malformed JSON</i>.<p>(except if the meaning is the JSON syntax is valid but may not conform to the schema, but they&#x27;re unclear on that).</div><br/><div id="36331851" class="c"><input type="checkbox" id="c-36331851" checked=""/><div class="controls bullet"><span class="by">sanxiyn</span><span>|</span><a href="#36331206">root</a><span>|</span><a href="#36331466">parent</a><span>|</span><a href="#36331597">next</a><span>|</span><label class="collapse" for="c-36331851">[-]</label><label class="expand" for="c-36331851">[1 more]</label></div><br/><div class="children"><div class="content">For various reasons, token selection may be implemented as upweighting&#x2F;downweighting instead of outright ban of invalid tokens. (Maybe it helps training?) Then the model could generate malformed JSON. I think it is premature to infer from &quot;can generate malformed JSON&quot; that OpenAI is not using token selection restriction.</div><br/></div></div></div></div><div id="36331597" class="c"><input type="checkbox" id="c-36331597" checked=""/><div class="controls bullet"><span class="by">woodrowbarlow</span><span>|</span><a href="#36331206">root</a><span>|</span><a href="#36331351">parent</a><span>|</span><a href="#36331466">prev</a><span>|</span><a href="#36335703">next</a><span>|</span><label class="collapse" for="c-36331597">[-]</label><label class="expand" for="c-36331597">[1 more]</label></div><br/><div class="children"><div class="content">the linked article hypothesizes:<p>&gt; I assume OpenAI’s implementation works conceptually similar to jsonformer, where the token selection algorithm is changed from “choose the token with the highest logit” to “choose the token with the highest logit which is valid for the schema”.</div><br/></div></div><div id="36335703" class="c"><input type="checkbox" id="c-36335703" checked=""/><div class="controls bullet"><span class="by">ttul</span><span>|</span><a href="#36331206">root</a><span>|</span><a href="#36331351">parent</a><span>|</span><a href="#36331597">prev</a><span>|</span><a href="#36331479">next</a><span>|</span><label class="collapse" for="c-36335703">[-]</label><label class="expand" for="c-36335703">[1 more]</label></div><br/><div class="children"><div class="content">I think the problem is that tokens are not characters. So even if you had access to a JSON parser state that could tell you whether or not a given character is valid as the next character, I am not sure how you would translate that into tokens to apply the logit biases appropriately. There would be a great deal of computation required at each step to scan the parser state and generate the list of prohibited or allowable tokens.<p>But if one could pull this off, it would be super cool. Similar to how Microsoft’s guidance module uses the logit_bias parameter to force the model to choose between a set of available options.</div><br/></div></div><div id="36331479" class="c"><input type="checkbox" id="c-36331479" checked=""/><div class="controls bullet"><span class="by">sanxiyn</span><span>|</span><a href="#36331206">root</a><span>|</span><a href="#36331351">parent</a><span>|</span><a href="#36335703">prev</a><span>|</span><a href="#36331484">next</a><span>|</span><label class="collapse" for="c-36331479">[-]</label><label class="expand" for="c-36331479">[2 more]</label></div><br/><div class="children"><div class="content">Note that this (token selection restriction) is even available on OpenAI API as logit_bias.</div><br/><div id="36332371" class="c"><input type="checkbox" id="c-36332371" checked=""/><div class="controls bullet"><span class="by">newhouseb</span><span>|</span><a href="#36331206">root</a><span>|</span><a href="#36331479">parent</a><span>|</span><a href="#36331484">next</a><span>|</span><label class="collapse" for="c-36332371">[-]</label><label class="expand" for="c-36332371">[1 more]</label></div><br/><div class="children"><div class="content">But only for the whole generation. So if you want to constrain things one token at a time (as you would to force things to follow a grammar) you have to make fresh calls and only request one token which makes things more or less impractical if you want true guarantees. A few months ago I built this anyway to suss out how much more expensive it was [1]<p>[1] <a href="https:&#x2F;&#x2F;github.com&#x2F;newhouseb&#x2F;clownfish#so-how-do-i-use-this-with-gpt4">https:&#x2F;&#x2F;github.com&#x2F;newhouseb&#x2F;clownfish#so-how-do-i-use-this-...</a></div><br/></div></div></div></div><div id="36331484" class="c"><input type="checkbox" id="c-36331484" checked=""/><div class="controls bullet"><span class="by">have_faith</span><span>|</span><a href="#36331206">root</a><span>|</span><a href="#36331351">parent</a><span>|</span><a href="#36331479">prev</a><span>|</span><a href="#36337252">next</a><span>|</span><label class="collapse" for="c-36331484">[-]</label><label class="expand" for="c-36331484">[3 more]</label></div><br/><div class="children"><div class="content">How would a tweaked temp enforce a non broken output exactly?</div><br/><div id="36331729" class="c"><input type="checkbox" id="c-36331729" checked=""/><div class="controls bullet"><span class="by">sanxiyn</span><span>|</span><a href="#36331206">root</a><span>|</span><a href="#36331484">parent</a><span>|</span><a href="#36331562">next</a><span>|</span><label class="collapse" for="c-36331729">[-]</label><label class="expand" for="c-36331729">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not temperature, but sampling. Output of LLM is probabilistic distribution over tokens. To get concrete tokens, you sample from that distribution. Unfortunately, OpenAI API does not expose the distribution. You only get the sampled tokens.<p>As an example, on the link JSON schema is defined such that recipe ingredient unit is one of grams&#x2F;ml&#x2F;cups&#x2F;pieces&#x2F;teaspoons. LLM may output the distribution grams(30%), cups(30%), pounds(40%). Sampling the best token &quot;pounds&quot; would generate an invalid document. Instead, you can use the schema to filter tokens and sample from the filtered distribution, which is grams(50%), cups(50%).</div><br/></div></div><div id="36331562" class="c"><input type="checkbox" id="c-36331562" checked=""/><div class="controls bullet"><span class="by">isoprophlex</span><span>|</span><a href="#36331206">root</a><span>|</span><a href="#36331484">parent</a><span>|</span><a href="#36331729">prev</a><span>|</span><a href="#36337252">next</a><span>|</span><label class="collapse" for="c-36331562">[-]</label><label class="expand" for="c-36331562">[1 more]</label></div><br/><div class="children"><div class="content">Not traditional temperature, maybe the parent worded it somewhat obtusely. Anyway, to disambiguate...<p>I think it works something like this: You let something akin to a json parser run with the output sampler. First token must be either &#x27;{&#x27; or &#x27;[&#x27;; then if you see [ has the highest probability, you select that. Ignore all other tokens, even those with high probability.<p>Second token must be ... and so on and so on.<p>Guarantee for non-broken (or at least parseable) json</div><br/></div></div></div></div></div></div><div id="36337252" class="c"><input type="checkbox" id="c-36337252" checked=""/><div class="controls bullet"><span class="by">H8crilA</span><span>|</span><a href="#36331206">parent</a><span>|</span><a href="#36331351">prev</a><span>|</span><a href="#36332210">next</a><span>|</span><label class="collapse" for="c-36337252">[-]</label><label class="expand" for="c-36337252">[1 more]</label></div><br/><div class="children"><div class="content">That SQL example is going to result in a catastrophe somewhere when someone uses it in their project. It is encouraging something very dangerous when allowed to run on untrusted inputs.</div><br/></div></div><div id="36332210" class="c"><input type="checkbox" id="c-36332210" checked=""/><div class="controls bullet"><span class="by">behnamoh</span><span>|</span><a href="#36331206">parent</a><span>|</span><a href="#36337252">prev</a><span>|</span><a href="#36335556">next</a><span>|</span><label class="collapse" for="c-36332210">[-]</label><label class="expand" for="c-36332210">[8 more]</label></div><br/><div class="children"><div class="content">What&#x27;s the implication of this new change for Microsoft Guidance, LMQL, Langchain, etc.? It looks like much of their functionality (controlling model output) just became obsolete. Am I missing something?</div><br/><div id="36332378" class="c"><input type="checkbox" id="c-36332378" checked=""/><div class="controls bullet"><span class="by">lbeurerkellner</span><span>|</span><a href="#36331206">root</a><span>|</span><a href="#36332210">parent</a><span>|</span><a href="#36334328">next</a><span>|</span><label class="collapse" for="c-36332378">[-]</label><label class="expand" for="c-36332378">[3 more]</label></div><br/><div class="children"><div class="content">If anything this removes a major roadblock for libraries&#x2F;languages that want to employ LLM calls as a primitive, no? Although, I fear the vendor lock-in intensifies here, also given how restrictive and specific the Chat API.<p>Either way, as part of the LMQL team, I am actually pretty excited about this, also with respect to what we want to build going forward. This makes language model programming much easier.</div><br/><div id="36333468" class="c"><input type="checkbox" id="c-36333468" checked=""/><div class="controls bullet"><span class="by">londons_explore</span><span>|</span><a href="#36331206">root</a><span>|</span><a href="#36332378">parent</a><span>|</span><a href="#36333367">next</a><span>|</span><label class="collapse" for="c-36333468">[-]</label><label class="expand" for="c-36333468">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Although, I fear the vendor lock-in intensifies here,<p>The openAI API is super simple - any other vendor is free to copy it, and I&#x27;m sure many will.</div><br/></div></div><div id="36333367" class="c"><input type="checkbox" id="c-36333367" checked=""/><div class="controls bullet"><span class="by">koboll</span><span>|</span><a href="#36331206">root</a><span>|</span><a href="#36332378">parent</a><span>|</span><a href="#36333468">prev</a><span>|</span><a href="#36334328">next</a><span>|</span><label class="collapse" for="c-36333367">[-]</label><label class="expand" for="c-36333367">[1 more]</label></div><br/><div class="children"><div class="content">`Although, I fear the vendor lock-in intensifies here, also given how restrictive and specific the Chat API.`<p>Eh, would be pretty easy to write a wrapper that takes a functions-like JSON Schema object and interpolates it into a traditional &quot;You MUST return ONLY JSON in the following format:&quot; prompt snippet.</div><br/></div></div></div></div><div id="36334328" class="c"><input type="checkbox" id="c-36334328" checked=""/><div class="controls bullet"><span class="by">neuronexmachina</span><span>|</span><a href="#36331206">root</a><span>|</span><a href="#36332210">parent</a><span>|</span><a href="#36332378">prev</a><span>|</span><a href="#36332346">next</a><span>|</span><label class="collapse" for="c-36334328">[-]</label><label class="expand" for="c-36334328">[3 more]</label></div><br/><div class="children"><div class="content">Langchain added support for `function_call` args yesterday:<p>* <a href="https:&#x2F;&#x2F;github.com&#x2F;hwchase17&#x2F;langchain&#x2F;pull&#x2F;6099&#x2F;files">https:&#x2F;&#x2F;github.com&#x2F;hwchase17&#x2F;langchain&#x2F;pull&#x2F;6099&#x2F;files</a><p>* <a href="https:&#x2F;&#x2F;github.com&#x2F;hwchase17&#x2F;langchain&#x2F;issues&#x2F;6104">https:&#x2F;&#x2F;github.com&#x2F;hwchase17&#x2F;langchain&#x2F;issues&#x2F;6104</a><p>IMHO, this should make Langchain much easier and less chaotic to use.</div><br/><div id="36335373" class="c"><input type="checkbox" id="c-36335373" checked=""/><div class="controls bullet"><span class="by">gawi</span><span>|</span><a href="#36331206">root</a><span>|</span><a href="#36334328">parent</a><span>|</span><a href="#36332346">next</a><span>|</span><label class="collapse" for="c-36335373">[-]</label><label class="expand" for="c-36335373">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s only been added to the OpenAI interface. Function calling is really useful when used with agents. To include that to agents would require some redesign as the tool instructions should be removed from the prompt templates in favor of function definitions in the API request. The response parsing code would also be affected.<p>I just hope they won&#x27;t come up with yet another agent type.</div><br/><div id="36337245" class="c"><input type="checkbox" id="c-36337245" checked=""/><div class="controls bullet"><span class="by">neuronexmachina</span><span>|</span><a href="#36331206">root</a><span>|</span><a href="#36335373">parent</a><span>|</span><a href="#36332346">next</a><span>|</span><label class="collapse" for="c-36337245">[-]</label><label class="expand" for="c-36337245">[1 more]</label></div><br/><div class="children"><div class="content">Like this? <a href="https:&#x2F;&#x2F;github.com&#x2F;hwchase17&#x2F;langchain&#x2F;blob&#x2F;master&#x2F;langchain&#x2F;agents&#x2F;openai_functions_agent&#x2F;base.py">https:&#x2F;&#x2F;github.com&#x2F;hwchase17&#x2F;langchain&#x2F;blob&#x2F;master&#x2F;langchain...</a></div><br/></div></div></div></div></div></div></div></div><div id="36335556" class="c"><input type="checkbox" id="c-36335556" checked=""/><div class="controls bullet"><span class="by">arbuge</span><span>|</span><a href="#36331206">parent</a><span>|</span><a href="#36332210">prev</a><span>|</span><a href="#36333946">next</a><span>|</span><label class="collapse" for="c-36335556">[-]</label><label class="expand" for="c-36335556">[1 more]</label></div><br/><div class="children"><div class="content">They have something closer to a simple Hello World example here:<p><a href="https:&#x2F;&#x2F;platform.openai.com&#x2F;docs&#x2F;guides&#x2F;gpt&#x2F;function-calling" rel="nofollow noreferrer">https:&#x2F;&#x2F;platform.openai.com&#x2F;docs&#x2F;guides&#x2F;gpt&#x2F;function-calling</a><p>That example needs a bit of work I think. In Step 3, they&#x27;re not really using the returned function_name; they&#x27;re just assuming it&#x27;s the only function that&#x27;s been defined, which I guess is equivalent for this simple example with just one function but less instructive. In Step 4, I believe they should also have sent the function definition block again a second time since model calls in the API are memory-less and independent. They didn&#x27;t, although the model appears to guess what&#x27;s needed anyway in this case.</div><br/></div></div></div></div><div id="36333946" class="c"><input type="checkbox" id="c-36333946" checked=""/><div class="controls bullet"><span class="by">Xen9</span><span>|</span><a href="#36331206">prev</a><span>|</span><a href="#36332000">next</a><span>|</span><label class="collapse" for="c-36333946">[-]</label><label class="expand" for="c-36333946">[2 more]</label></div><br/><div class="children"><div class="content">Marvin Minsky was so damn far ahead of his time with Society of Mind.<p>Engineering of cognitively advanced multiagent systems will become the area of research of this century &#x2F; multiple decades.<p>GPT-GPT &gt; GPT-API in terms of power.<p>The space of possible combinations of GPT multiagents goes beyond imagination since even GPT-4 goes so.<p>Multiagent systems are best modeled with signal theory, graph theory and cognitive science.<p>Of course &quot;programming&quot; will also play a role, in sense of abstractions and creation of systems of &#x2F; for thought.<p>Signal theory will be a significant approach for thinking about embedded agency.<p>Complex multiagent systems approach us.</div><br/><div id="36336114" class="c"><input type="checkbox" id="c-36336114" checked=""/><div class="controls bullet"><span class="by">SanderNL</span><span>|</span><a href="#36333946">parent</a><span>|</span><a href="#36332000">next</a><span>|</span><label class="collapse" for="c-36336114">[-]</label><label class="expand" for="c-36336114">[1 more]</label></div><br/><div class="children"><div class="content">Makes me think of the Freud&#x2F;Jungian notions of personas in us that are in various degrees semi-autonomously looking out for themselves. The “angry” agent, the “child” agent, so on.</div><br/></div></div></div></div><div id="36332000" class="c"><input type="checkbox" id="c-36332000" checked=""/><div class="controls bullet"><span class="by">emilsedgh</span><span>|</span><a href="#36333946">prev</a><span>|</span><a href="#36332155">next</a><span>|</span><label class="collapse" for="c-36332000">[-]</label><label class="expand" for="c-36332000">[4 more]</label></div><br/><div class="children"><div class="content">Building agents that use advanced API&#x27;s was not really practical until now. Things like Langchain&#x27;s Structured Agents worked somewhat reliably, but due to the massive token count it was so slow, the experience was _never_ going to be useful.<p>Due to this, the performance in which our agent processes results has improved 5-6 times and it does actually do a pretty good job of keeping the schema.<p>One problem that is not resolved yet is that it still hallucinates a lot of attributes. For example we have tool that allows it to create contacts in user&#x27;s CRM. I ask it to:<p>&quot;Create contacts for top 3 Barcelona players:.<p>It creates an structure like this&quot;<p>1. Lionel Messi
   - Email: lionel.messi@barcelona.com
   - Phone Number: +1234567890
   - Tags: Player, Barcelona<p>2. Gerard Pique
   - Email: gerard.pique@barcelona.com
   - Phone Number: +1234567891
   - Tags: Player, Barcelona<p>3. Marc-Andre ter Stegen
   - Email: marc-terstegen@barcelona.com
   - Phone Number: +1234567892
   - Tags: Player, Barcelona<p>And you can see it hallucinated email addresses and phone numbers.</div><br/><div id="36332238" class="c"><input type="checkbox" id="c-36332238" checked=""/><div class="controls bullet"><span class="by">pluijzer</span><span>|</span><a href="#36332000">parent</a><span>|</span><a href="#36332183">next</a><span>|</span><label class="collapse" for="c-36332238">[-]</label><label class="expand" for="c-36332238">[2 more]</label></div><br/><div class="children"><div class="content">ChatGPT can be usefully for many things, but you should really, not use it if you want to retrieve factual data. This might partly be resolved by querying the internet like bing does but purely on the language model side these hallucinations are just an unavoidable part of it.</div><br/><div id="36333689" class="c"><input type="checkbox" id="c-36333689" checked=""/><div class="controls bullet"><span class="by">Spivak</span><span>|</span><a href="#36332000">root</a><span>|</span><a href="#36332238">parent</a><span>|</span><a href="#36332183">next</a><span>|</span><label class="collapse" for="c-36333689">[-]</label><label class="expand" for="c-36333689">[1 more]</label></div><br/><div class="children"><div class="content">Yep, it&#x27;s <i>always</i> <i>always</i> write code &#x2F; query &#x2F; function &#x2F; whatever you need
that you would parse and retrieve the data from an external system.</div><br/></div></div></div></div><div id="36332183" class="c"><input type="checkbox" id="c-36332183" checked=""/><div class="controls bullet"><span class="by">037</span><span>|</span><a href="#36332000">parent</a><span>|</span><a href="#36332238">prev</a><span>|</span><a href="#36332155">next</a><span>|</span><label class="collapse" for="c-36332183">[-]</label><label class="expand" for="c-36332183">[1 more]</label></div><br/><div class="children"><div class="content">I would never rely on an LLM as a source of such information, just as I wouldn&#x27;t trust the general knowledge of a human being used as a database. Does your workflow include a step for information search? With the new json features, it should be easy to instruct it to perform a search or directly feed it the right pages to parse.</div><br/></div></div></div></div><div id="36332155" class="c"><input type="checkbox" id="c-36332155" checked=""/><div class="controls bullet"><span class="by">edwin</span><span>|</span><a href="#36332000">prev</a><span>|</span><a href="#36331180">next</a><span>|</span><label class="collapse" for="c-36332155">[-]</label><label class="expand" for="c-36332155">[6 more]</label></div><br/><div class="children"><div class="content">For those who want to test out the LLM as API idea, we are building a turnkey prompt to API product. Here&#x27;s Simon&#x27;s recipe maker deployed in a minute: <a href="https:&#x2F;&#x2F;preview.promptjoy.com&#x2F;apis&#x2F;1AgCy9" rel="nofollow noreferrer">https:&#x2F;&#x2F;preview.promptjoy.com&#x2F;apis&#x2F;1AgCy9</a> . Public preview to make and test your own API: <a href="https:&#x2F;&#x2F;preview.promptjoy.com" rel="nofollow noreferrer">https:&#x2F;&#x2F;preview.promptjoy.com</a></div><br/><div id="36334494" class="c"><input type="checkbox" id="c-36334494" checked=""/><div class="controls bullet"><span class="by">abhpro</span><span>|</span><a href="#36332155">parent</a><span>|</span><a href="#36332576">next</a><span>|</span><label class="collapse" for="c-36334494">[-]</label><label class="expand" for="c-36334494">[1 more]</label></div><br/><div class="children"><div class="content">This is really cool, I had a similar idea but didn&#x27;t build it. I was also thinking a user could take these different prompts (I called them tasks) that anyone could create, and then connect them together like a node graph or visual programming interface, with some Chat-GPT middleware that resolves the outputs to inputs.</div><br/></div></div><div id="36332576" class="c"><input type="checkbox" id="c-36332576" checked=""/><div class="controls bullet"><span class="by">yonom</span><span>|</span><a href="#36332155">parent</a><span>|</span><a href="#36334494">prev</a><span>|</span><a href="#36335888">next</a><span>|</span><label class="collapse" for="c-36332576">[-]</label><label class="expand" for="c-36332576">[3 more]</label></div><br/><div class="children"><div class="content">This is cool! Are you using one-shot learning under the hood with a user provided example?</div><br/><div id="36332850" class="c"><input type="checkbox" id="c-36332850" checked=""/><div class="controls bullet"><span class="by">edwin</span><span>|</span><a href="#36332155">root</a><span>|</span><a href="#36332576">parent</a><span>|</span><a href="#36332689">next</a><span>|</span><label class="collapse" for="c-36332850">[-]</label><label class="expand" for="c-36332850">[1 more]</label></div><br/><div class="children"><div class="content">BTW: Here&#x27;s a more performant version (fewer tokens) <a href="https:&#x2F;&#x2F;preview.promptjoy.com&#x2F;apis&#x2F;jNqCA2" rel="nofollow noreferrer">https:&#x2F;&#x2F;preview.promptjoy.com&#x2F;apis&#x2F;jNqCA2</a> that uses a smaller example but will still generate pretty good results.</div><br/></div></div><div id="36332689" class="c"><input type="checkbox" id="c-36332689" checked=""/><div class="controls bullet"><span class="by">edwin</span><span>|</span><a href="#36332155">root</a><span>|</span><a href="#36332576">parent</a><span>|</span><a href="#36332850">prev</a><span>|</span><a href="#36335888">next</a><span>|</span><label class="collapse" for="c-36332689">[-]</label><label class="expand" for="c-36332689">[1 more]</label></div><br/><div class="children"><div class="content">Thanks. We find few-shot learning to be more effective overall. So we are generating additional examples from the provided example.</div><br/></div></div></div></div><div id="36335888" class="c"><input type="checkbox" id="c-36335888" checked=""/><div class="controls bullet"><span class="by">wonderfuly</span><span>|</span><a href="#36332155">parent</a><span>|</span><a href="#36332576">prev</a><span>|</span><a href="#36331180">next</a><span>|</span><label class="collapse" for="c-36335888">[-]</label><label class="expand" for="c-36335888">[1 more]</label></div><br/><div class="children"><div class="content">I own this domain: prompts.run 
Do you wanna it?</div><br/></div></div></div></div><div id="36331180" class="c"><input type="checkbox" id="c-36331180" checked=""/><div class="controls bullet"><span class="by">thorum</span><span>|</span><a href="#36332155">prev</a><span>|</span><a href="#36332047">next</a><span>|</span><label class="collapse" for="c-36331180">[-]</label><label class="expand" for="c-36331180">[5 more]</label></div><br/><div class="children"><div class="content">The JSON schema not counting toward token usage is huge, that will really help reduce costs.</div><br/><div id="36331238" class="c"><input type="checkbox" id="c-36331238" checked=""/><div class="controls bullet"><span class="by">yonom</span><span>|</span><a href="#36331180">parent</a><span>|</span><a href="#36335096">next</a><span>|</span><label class="collapse" for="c-36331238">[-]</label><label class="expand" for="c-36331238">[1 more]</label></div><br/><div class="children"><div class="content">I believe functions do count in some way toward the token usage; but it seems to be in a more efficient way than pasting raw JSON schemas into the prompt. Nevertheless, the token usage seems to be far lower than previous alternatives, which is awesome!</div><br/></div></div><div id="36335096" class="c"><input type="checkbox" id="c-36335096" checked=""/><div class="controls bullet"><span class="by">blamy</span><span>|</span><a href="#36331180">parent</a><span>|</span><a href="#36331238">prev</a><span>|</span><a href="#36331566">next</a><span>|</span><label class="collapse" for="c-36335096">[-]</label><label class="expand" for="c-36335096">[1 more]</label></div><br/><div class="children"><div class="content">But it does count toward token usage. And they picked JSON schema which is like 6x more verbose than typescript for defining the shape of json.</div><br/></div></div><div id="36331566" class="c"><input type="checkbox" id="c-36331566" checked=""/><div class="controls bullet"><span class="by">stavros</span><span>|</span><a href="#36331180">parent</a><span>|</span><a href="#36335096">prev</a><span>|</span><a href="#36331277">next</a><span>|</span><label class="collapse" for="c-36331566">[-]</label><label class="expand" for="c-36331566">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Under the hood, functions are injected into the system message in a syntax the model has been trained on. This means functions count against the model&#x27;s context limit and are billed as input tokens. If running into context limits, we suggest limiting the number of functions or the length of documentation you provide for function parameters.</div><br/></div></div><div id="36331277" class="c"><input type="checkbox" id="c-36331277" checked=""/><div class="controls bullet"><span class="by">minimaxir</span><span>|</span><a href="#36331180">parent</a><span>|</span><a href="#36331566">prev</a><span>|</span><a href="#36332047">next</a><span>|</span><label class="collapse" for="c-36331277">[-]</label><label class="expand" for="c-36331277">[1 more]</label></div><br/><div class="children"><div class="content">That is up in the air and needs more testing. Field descriptions, for example, are important but extraneous input that would be tokenized and count in the costs.<p>At the least for ChatGPT, input token costs were cut by 25% so it evens out.</div><br/></div></div></div></div><div id="36332047" class="c"><input type="checkbox" id="c-36332047" checked=""/><div class="controls bullet"><span class="by">037</span><span>|</span><a href="#36331180">prev</a><span>|</span><a href="#36337216">next</a><span>|</span><label class="collapse" for="c-36332047">[-]</label><label class="expand" for="c-36332047">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;m wondering if introducing a system message like &quot;convert the resulting json to yaml and return the yaml only&quot; would adversely affect the optimization done for these models. The reason is that yaml uses significantly fewer tokens compared to json. For the output, where data type specification or adding comments may not be necessary, this could be beneficial. From my understanding, specifying functions in json now uses fewer tokens, but I believe the response still consumes the usual amount of tokens.</div><br/><div id="36332569" class="c"><input type="checkbox" id="c-36332569" checked=""/><div class="controls bullet"><span class="by">lbeurerkellner</span><span>|</span><a href="#36332047">parent</a><span>|</span><a href="#36336380">next</a><span>|</span><label class="collapse" for="c-36332569">[-]</label><label class="expand" for="c-36332569">[1 more]</label></div><br/><div class="children"><div class="content">I think one should not underestimate the impact on downstream performance the output format can have. From a modelling perspective it is unclear whether asking&#x2F;fine-tuning the model to generate JSON (or YAML) output is really lossless with respect to the raw reasoning powers of the model (e.g. it may perform worse on tasks when asked&#x2F;trained to always respond in JSON).<p>I am sure they ran tests on this internally, but I wonder what the concrete effects are, especially comparing different output formats like JSON, YAML, different function calling conventions and&#x2F;or forms of tool discovery.</div><br/></div></div><div id="36336380" class="c"><input type="checkbox" id="c-36336380" checked=""/><div class="controls bullet"><span class="by">gregw134</span><span>|</span><a href="#36332047">parent</a><span>|</span><a href="#36332569">prev</a><span>|</span><a href="#36337216">next</a><span>|</span><label class="collapse" for="c-36336380">[-]</label><label class="expand" for="c-36336380">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s what I&#x27;m doing. I ask ChatGPT to return inline yaml (no wasting tokens on line breaks), then I parse the yaml output into JSON once I receive it. A bit awkward but it cuts costs in half.</div><br/></div></div></div></div><div id="36337216" class="c"><input type="checkbox" id="c-36337216" checked=""/><div class="controls bullet"><span class="by">ulrikrasmussen</span><span>|</span><a href="#36332047">prev</a><span>|</span><a href="#36333274">next</a><span>|</span><label class="collapse" for="c-36337216">[-]</label><label class="expand" for="c-36337216">[1 more]</label></div><br/><div class="children"><div class="content">Has anyone tried throwing their backend Swagger at this and made ChatGPT perform user story tests?</div><br/></div></div><div id="36333274" class="c"><input type="checkbox" id="c-36333274" checked=""/><div class="controls bullet"><span class="by">jonplackett</span><span>|</span><a href="#36337216">prev</a><span>|</span><a href="#36333006">next</a><span>|</span><label class="collapse" for="c-36333274">[-]</label><label class="expand" for="c-36333274">[3 more]</label></div><br/><div class="children"><div class="content">This is useful, but for me at least, GPT-4 is unusable because it sometimes takes 30 seconds + to reply to even basic queries.</div><br/><div id="36333305" class="c"><input type="checkbox" id="c-36333305" checked=""/><div class="controls bullet"><span class="by">m3kw9</span><span>|</span><a href="#36333274">parent</a><span>|</span><a href="#36333006">next</a><span>|</span><label class="collapse" for="c-36333305">[-]</label><label class="expand" for="c-36333305">[2 more]</label></div><br/><div class="children"><div class="content">Also the rate limit is pretty bad if you want to release any type of app</div><br/><div id="36335174" class="c"><input type="checkbox" id="c-36335174" checked=""/><div class="controls bullet"><span class="by">jiggawatts</span><span>|</span><a href="#36333274">root</a><span>|</span><a href="#36333305">parent</a><span>|</span><a href="#36333006">next</a><span>|</span><label class="collapse" for="c-36335174">[-]</label><label class="expand" for="c-36335174">[1 more]</label></div><br/><div class="children"><div class="content">More importantly: there&#x27;s a waiting list.<p>Also, if you want to use both the ChatGPT web app <i>and</i> the API, you&#x27;ll be billed for <i>both</i> separately. They really should be unified and billed under a single account. The difference is literally just whether there&#x27;s a &quot;web UI&quot; on top of the API... or not.</div><br/></div></div></div></div></div></div><div id="36333006" class="c"><input type="checkbox" id="c-36333006" checked=""/><div class="controls bullet"><span class="by">m3kw9</span><span>|</span><a href="#36333274">prev</a><span>|</span><a href="#36331378">next</a><span>|</span><label class="collapse" for="c-36333006">[-]</label><label class="expand" for="c-36333006">[5 more]</label></div><br/><div class="children"><div class="content">It works pretty good.  You define a few “function” and enter a description on what it does, when user prompts, it will understand the prompt and tell you which likely “function” to use, which is just the function name.   I feel like this is a new way to program,  a sort of fuzzy logic type of programming</div><br/><div id="36334005" class="c"><input type="checkbox" id="c-36334005" checked=""/><div class="controls bullet"><span class="by">Sai_</span><span>|</span><a href="#36333006">parent</a><span>|</span><a href="#36331378">next</a><span>|</span><label class="collapse" for="c-36334005">[-]</label><label class="expand" for="c-36334005">[4 more]</label></div><br/><div class="children"><div class="content">&gt; fuzzy logic<p>Yes and no. While the choice of which function to call is dependent on an llm, ultimately, you control the function itself whose output is deterministic.<p>Even today, given an api, people can choose to call or not call based on some factor. We don’t call this fuzzy logic. E.g., people can decide to sell or buy stock through an api based on some internal calculations - doesn’t make the system “fuzzy”.</div><br/><div id="36334140" class="c"><input type="checkbox" id="c-36334140" checked=""/><div class="controls bullet"><span class="by">m3kw9</span><span>|</span><a href="#36333006">root</a><span>|</span><a href="#36334005">parent</a><span>|</span><a href="#36331378">next</a><span>|</span><label class="collapse" for="c-36334140">[-]</label><label class="expand" for="c-36334140">[3 more]</label></div><br/><div class="children"><div class="content">If you feed that result into another io box you may or may not know if that is the correct answer, which may need some sort of error detection. I think this is going to be majority of the use cases</div><br/><div id="36334333" class="c"><input type="checkbox" id="c-36334333" checked=""/><div class="controls bullet"><span class="by">Sai_</span><span>|</span><a href="#36333006">root</a><span>|</span><a href="#36334140">parent</a><span>|</span><a href="#36331378">next</a><span>|</span><label class="collapse" for="c-36334333">[-]</label><label class="expand" for="c-36334333">[2 more]</label></div><br/><div class="children"><div class="content">Hm, I see what you mean. Afaict, only the decision to call or not call a function is up to the model (fuzzy). Once it decides to call the function, it generates mostly correct JSON based on your schema and returns that to you as is (not very fuzzy).<p>It’ll be interesting to test APIs which accept user inputs. Depending on how ChatGPT populates the JSON, the API could be required to understand&#x2F;interpret&#x2F;respond to lots of variability in inputs.</div><br/><div id="36334425" class="c"><input type="checkbox" id="c-36334425" checked=""/><div class="controls bullet"><span class="by">m3kw9</span><span>|</span><a href="#36333006">root</a><span>|</span><a href="#36334333">parent</a><span>|</span><a href="#36331378">next</a><span>|</span><label class="collapse" for="c-36334425">[-]</label><label class="expand" for="c-36334425">[1 more]</label></div><br/><div class="children"><div class="content">Yeah I’ve tested, you should use the curl example they gave as you can test instantly pasting it into your terminal.  The description of the functions is prompt engineering in addition to the original system prompt, need to test the dependency more, it’s so new.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="36331378" class="c"><input type="checkbox" id="c-36331378" checked=""/><div class="controls bullet"><span class="by">mritchie712</span><span>|</span><a href="#36333006">prev</a><span>|</span><a href="#36333125">next</a><span>|</span><label class="collapse" for="c-36331378">[-]</label><label class="expand" for="c-36331378">[6 more]</label></div><br/><div class="children"><div class="content">Glad we didn&#x27;t get to far into adopting something like Guardrails. This sort of kills it&#x27;s main value prop for OpenAI.<p><a href="https:&#x2F;&#x2F;shreyar.github.io&#x2F;guardrails&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;shreyar.github.io&#x2F;guardrails&#x2F;</a></div><br/><div id="36331435" class="c"><input type="checkbox" id="c-36331435" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#36331378">parent</a><span>|</span><a href="#36335131">next</a><span>|</span><label class="collapse" for="c-36331435">[-]</label><label class="expand" for="c-36331435">[3 more]</label></div><br/><div class="children"><div class="content">i mean only at the most superficial level. she has a ton of other validators that arent superceded (eg SQL is validated by branching the database - we discussed on our pod <a href="https:&#x2F;&#x2F;www.latent.space&#x2F;p&#x2F;guaranteed-quality-and-structure" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.latent.space&#x2F;p&#x2F;guaranteed-quality-and-structure</a>)</div><br/><div id="36333198" class="c"><input type="checkbox" id="c-36333198" checked=""/><div class="controls bullet"><span class="by">mritchie712</span><span>|</span><a href="#36331378">root</a><span>|</span><a href="#36331435">parent</a><span>|</span><a href="#36335131">next</a><span>|</span><label class="collapse" for="c-36333198">[-]</label><label class="expand" for="c-36333198">[2 more]</label></div><br/><div class="children"><div class="content">yeah, listened to the pod (that&#x27;s how I found out about guardrails!).<p>fair point, I should have said: &quot;value prop for our use case&quot;... the thing I was most interested in was how well Guardrails structured output.</div><br/><div id="36335143" class="c"><input type="checkbox" id="c-36335143" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#36331378">root</a><span>|</span><a href="#36333198">parent</a><span>|</span><a href="#36335131">next</a><span>|</span><label class="collapse" for="c-36335143">[-]</label><label class="expand" for="c-36335143">[1 more]</label></div><br/><div class="children"><div class="content">haha excellent. i was quite impressed by her and the vision for guardrails. thanks for listening!</div><br/></div></div></div></div></div></div><div id="36335131" class="c"><input type="checkbox" id="c-36335131" checked=""/><div class="controls bullet"><span class="by">blamy</span><span>|</span><a href="#36331378">parent</a><span>|</span><a href="#36331435">prev</a><span>|</span><a href="#36332307">next</a><span>|</span><label class="collapse" for="c-36335131">[-]</label><label class="expand" for="c-36335131">[1 more]</label></div><br/><div class="children"><div class="content">Guardrails is an awesome project and will continue to be even after this.</div><br/></div></div><div id="36332307" class="c"><input type="checkbox" id="c-36332307" checked=""/><div class="controls bullet"><span class="by">Blahah</span><span>|</span><a href="#36331378">parent</a><span>|</span><a href="#36335131">prev</a><span>|</span><a href="#36333125">next</a><span>|</span><label class="collapse" for="c-36332307">[-]</label><label class="expand" for="c-36332307">[1 more]</label></div><br/><div class="children"><div class="content">Luckily it&#x27;s for LLMs, not openai</div><br/></div></div></div></div><div id="36333125" class="c"><input type="checkbox" id="c-36333125" checked=""/><div class="controls bullet"><span class="by">rank0</span><span>|</span><a href="#36331378">prev</a><span>|</span><a href="#36332161">next</a><span>|</span><label class="collapse" for="c-36333125">[-]</label><label class="expand" for="c-36333125">[2 more]</label></div><br/><div class="children"><div class="content">OpenAI integration is going to be a goldmine for criminals in the future.<p>Everyone and their momma is gonna start passing poorly validated&#x2F;sanitized client input to shared sessions of a non-deterministic function.<p>I love the future!</div><br/><div id="36334858" class="c"><input type="checkbox" id="c-36334858" checked=""/><div class="controls bullet"><span class="by">nextworddev</span><span>|</span><a href="#36333125">parent</a><span>|</span><a href="#36332161">next</a><span>|</span><label class="collapse" for="c-36334858">[-]</label><label class="expand" for="c-36334858">[1 more]</label></div><br/><div class="children"><div class="content">In the “future”?</div><br/></div></div></div></div><div id="36332161" class="c"><input type="checkbox" id="c-36332161" checked=""/><div class="controls bullet"><span class="by">courseofaction</span><span>|</span><a href="#36333125">prev</a><span>|</span><a href="#36332376">next</a><span>|</span><label class="collapse" for="c-36332161">[-]</label><label class="expand" for="c-36332161">[2 more]</label></div><br/><div class="children"><div class="content">Nice to have an endpoint which takes care of this. I&#x27;ve been doing this manually, it&#x27;s a fairly simple process:<p>* Add &quot;Output your response in json format, with the fields &#x27;x&#x27;, which indicates &#x27;x_explanation&#x27;, &#x27;z&#x27;, which indicates &#x27;z_explanation&#x27; (...)&quot; etc. GPT-4 does this fairly reliably.<p>* Validate the response, repeat if malformed.<p>* Bam, you&#x27;ve got a json.<p>I wonder if they&#x27;ve implemented this endpoint with validation and carefully crafted prompts on the base model, or if this is specifically fine-tuned.</div><br/><div id="36332229" class="c"><input type="checkbox" id="c-36332229" checked=""/><div class="controls bullet"><span class="by">037</span><span>|</span><a href="#36332161">parent</a><span>|</span><a href="#36332376">next</a><span>|</span><label class="collapse" for="c-36332229">[-]</label><label class="expand" for="c-36332229">[1 more]</label></div><br/><div class="children"><div class="content">It appears to be fine-tuning:<p>&quot;These models have been fine-tuned to both detect when a function needs to be called (depending on the user’s input) and to respond with JSON that adheres to the function signature.&quot;<p><a href="https:&#x2F;&#x2F;openai.com&#x2F;blog&#x2F;function-calling-and-other-api-updates" rel="nofollow noreferrer">https:&#x2F;&#x2F;openai.com&#x2F;blog&#x2F;function-calling-and-other-api-updat...</a></div><br/></div></div></div></div><div id="36332376" class="c"><input type="checkbox" id="c-36332376" checked=""/><div class="controls bullet"><span class="by">smallerfish</span><span>|</span><a href="#36332161">prev</a><span>|</span><a href="#36333418">next</a><span>|</span><label class="collapse" for="c-36332376">[-]</label><label class="expand" for="c-36332376">[1 more]</label></div><br/><div class="children"><div class="content">I will experiment with this at the weekend. Once thing I found useful with supplying a json schema in the prompt was that I could supply inline comments and tell it when to leave a field null, etc. I found that much more reliable than describing these nuances elsewhere in the prompt. Presumably I can&#x27;t do this with functions, but maybe I&#x27;ll be able to work around it in the prompt (particularly now that I have more room to play with.)</div><br/></div></div><div id="36333418" class="c"><input type="checkbox" id="c-36333418" checked=""/><div class="controls bullet"><span class="by">loughnane</span><span>|</span><a href="#36332376">prev</a><span>|</span><a href="#36334379">next</a><span>|</span><label class="collapse" for="c-36333418">[-]</label><label class="expand" for="c-36333418">[1 more]</label></div><br/><div class="children"><div class="content">Just this morning I wrote a JSON object. I told GPT to turn it into a schema. I tweaked that and then gave a list of terms for which I wanted GPT to populate the schema accordingly.<p>It worked pretty well without any functions, but I did feel like I was missing something because I was ready to be explicit and there wasn’t any way for me to tell that to GPT.<p>I look forward to trying this out.</div><br/></div></div><div id="36334379" class="c"><input type="checkbox" id="c-36334379" checked=""/><div class="controls bullet"><span class="by">runeb</span><span>|</span><a href="#36333418">prev</a><span>|</span><a href="#36335883">next</a><span>|</span><label class="collapse" for="c-36334379">[-]</label><label class="expand" for="c-36334379">[2 more]</label></div><br/><div class="children"><div class="content">The way openai implemented this is really clever, beyond how neat the plugin architecture is, as it lets them peek one layer inside your internal API surface and can infer what you intend to do with the LLM output. Collecting some good data here.</div><br/><div id="36334892" class="c"><input type="checkbox" id="c-36334892" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#36334379">parent</a><span>|</span><a href="#36335883">next</a><span>|</span><label class="collapse" for="c-36334892">[-]</label><label class="expand" for="c-36334892">[1 more]</label></div><br/><div class="children"><div class="content">huh, i never thought of it that way. i thought openai pinky swears not to train on our data tho</div><br/></div></div></div></div><div id="36335883" class="c"><input type="checkbox" id="c-36335883" checked=""/><div class="controls bullet"><span class="by">khazhoux</span><span>|</span><a href="#36334379">prev</a><span>|</span><a href="#36331529">next</a><span>|</span><label class="collapse" for="c-36335883">[-]</label><label class="expand" for="c-36335883">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m trying to experiment with the API but the response time is always in the 15-25second range.  How are people getting any interesting work done with it?<p>I see others on the OpenAPI dev forum complaining about this too, but no resolution.</div><br/></div></div><div id="36331529" class="c"><input type="checkbox" id="c-36331529" checked=""/><div class="controls bullet"><span class="by">chaxor</span><span>|</span><a href="#36335883">prev</a><span>|</span><a href="#36333970">next</a><span>|</span><label class="collapse" for="c-36331529">[-]</label><label class="expand" for="c-36331529">[2 more]</label></div><br/><div class="children"><div class="content">Is there a decent way of converting to a structure with a very constrained vocabulary?
For example, given some input text, converting it to something like  {&quot;OID-189&quot;: &quot;QQID-378&quot;, &quot;OID-478&quot;:&quot;QQID-678&quot;}. Where OID and QQID dictionaries can be e.g. millions of different items defined by a description.  The rules for mapping could be essentially what looks closest in semantic space to the descriptions given in a dictionary.<p>I know this should be able to be solvable by local LLMs and bert cosine similarity (it isn&#x27;t exactly, but it&#x27;s a start on the idea), but is there a way to do this with decoder models rather than encoder models with other logic?</div><br/><div id="36335196" class="c"><input type="checkbox" id="c-36335196" checked=""/><div class="controls bullet"><span class="by">jiggawatts</span><span>|</span><a href="#36331529">parent</a><span>|</span><a href="#36333970">next</a><span>|</span><label class="collapse" for="c-36335196">[-]</label><label class="expand" for="c-36335196">[1 more]</label></div><br/><div class="children"><div class="content">You can train custom GPT 3 models, and Azure now has vector database integration for GPT-based models in the cloud. You can feed it the data, and ask it for the embedding lookup, etc...<p>You can also host a vector database yourself and fill it up with the embeddings from the OpenAI GPT 3 API.</div><br/></div></div></div></div><div id="36333970" class="c"><input type="checkbox" id="c-36333970" checked=""/><div class="controls bullet"><span class="by">sublinear</span><span>|</span><a href="#36331529">prev</a><span>|</span><a href="#36332348">next</a><span>|</span><label class="collapse" for="c-36333970">[-]</label><label class="expand" for="c-36333970">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The process is simple enough that you can let non-technical people build something like this via a no-code interface. No-code tools can leverage this to let their users define “backend” functionality.<p>Early prototypes of software can use simple prompts like this one to become interactive. Running an LLM every time someone clicks on a button is expensive and slow in production, but <i>probably still ~10x cheaper to produce than code.</i><p>Hah wow... no. Definitely not.</div><br/></div></div><div id="36332348" class="c"><input type="checkbox" id="c-36332348" checked=""/><div class="controls bullet"><span class="by">irthomasthomas</span><span>|</span><a href="#36333970">prev</a><span>|</span><a href="#36331754">next</a><span>|</span><label class="collapse" for="c-36332348">[-]</label><label class="expand" for="c-36332348">[7 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a shame they couldn&#x27;t use yaml, instead. I compared them and yaml uses about 20% fewer tokens. However, I can understand accuracy, derived from frequency,  being more important than token budget.</div><br/><div id="36332486" class="c"><input type="checkbox" id="c-36332486" checked=""/><div class="controls bullet"><span class="by">AdrienBrault</span><span>|</span><a href="#36332348">parent</a><span>|</span><a href="#36332672">next</a><span>|</span><label class="collapse" for="c-36332486">[-]</label><label class="expand" for="c-36332486">[1 more]</label></div><br/><div class="children"><div class="content">I think YAML actually uses more tokens than JSON without indents, especially with deep data. For example &quot;,&quot; being a single token makes JSON quite compact.<p>You can compare JSON and YAML on <a href="https:&#x2F;&#x2F;platform.openai.com&#x2F;tokenizer" rel="nofollow noreferrer">https:&#x2F;&#x2F;platform.openai.com&#x2F;tokenizer</a></div><br/></div></div><div id="36332672" class="c"><input type="checkbox" id="c-36332672" checked=""/><div class="controls bullet"><span class="by">nasir</span><span>|</span><a href="#36332348">parent</a><span>|</span><a href="#36332486">prev</a><span>|</span><a href="#36335248">next</a><span>|</span><label class="collapse" for="c-36332672">[-]</label><label class="expand" for="c-36332672">[3 more]</label></div><br/><div class="children"><div class="content">Its a lot more straightforward to use JSON programmatically than YAML.</div><br/><div id="36333404" class="c"><input type="checkbox" id="c-36333404" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#36332348">root</a><span>|</span><a href="#36332672">parent</a><span>|</span><a href="#36335248">next</a><span>|</span><label class="collapse" for="c-36333404">[-]</label><label class="expand" for="c-36333404">[2 more]</label></div><br/><div class="children"><div class="content">It really shouldn&#x27;t be, though. I.e. not unless you&#x27;re parsing or emitting it ad-hoc, for example by assuming that an expression like:<p><pre><code>  &quot;{&quot; + $someKey + &quot;:&quot; + $someValue + &quot;}&quot;
</code></pre>
produces a valid JSON. It does - sometimes - and then it&#x27;s indeed easier to work with. It&#x27;ll also blow up in your face. Using JSON the right way - via a proper parser and serializer - should be identical to using YAML or any other equivalent format.</div><br/><div id="36335298" class="c"><input type="checkbox" id="c-36335298" checked=""/><div class="controls bullet"><span class="by">riwsky</span><span>|</span><a href="#36332348">root</a><span>|</span><a href="#36333404">parent</a><span>|</span><a href="#36335248">next</a><span>|</span><label class="collapse" for="c-36335298">[-]</label><label class="expand" for="c-36335298">[1 more]</label></div><br/><div class="children"><div class="content">Even if the APIs for both were equally simple, modules for manipulating json are way more likely to be available in the stdlib of whatever language you’re using.</div><br/></div></div></div></div></div></div><div id="36335248" class="c"><input type="checkbox" id="c-36335248" checked=""/><div class="controls bullet"><span class="by">blamy</span><span>|</span><a href="#36332348">parent</a><span>|</span><a href="#36332672">prev</a><span>|</span><a href="#36332397">next</a><span>|</span><label class="collapse" for="c-36335248">[-]</label><label class="expand" for="c-36335248">[1 more]</label></div><br/><div class="children"><div class="content">JSON can be minified.</div><br/></div></div><div id="36332397" class="c"><input type="checkbox" id="c-36332397" checked=""/><div class="controls bullet"><span class="by">IshKebab</span><span>|</span><a href="#36332348">parent</a><span>|</span><a href="#36335248">prev</a><span>|</span><a href="#36331754">next</a><span>|</span><label class="collapse" for="c-36332397">[-]</label><label class="expand" for="c-36332397">[1 more]</label></div><br/><div class="children"><div class="content">I would imagine JSON is easier for a LLM to understand (and for humans!) because it doesn&#x27;t rely on indentation and confusing syntax for lists, strings etc.</div><br/></div></div></div></div><div id="36331754" class="c"><input type="checkbox" id="c-36331754" checked=""/><div class="controls bullet"><span class="by">dang</span><span>|</span><a href="#36332348">prev</a><span>|</span><a href="#36331343">next</a><span>|</span><label class="collapse" for="c-36331754">[-]</label><label class="expand" for="c-36331754">[5 more]</label></div><br/><div class="children"><div class="content">Recent and related:<p><i>Function calling and other API updates</i> - <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36313348">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36313348</a> - June 2023 (154 comments)</div><br/><div id="36331775" class="c"><input type="checkbox" id="c-36331775" checked=""/><div class="controls bullet"><span class="by">minimaxir</span><span>|</span><a href="#36331754">parent</a><span>|</span><a href="#36331343">next</a><span>|</span><label class="collapse" for="c-36331775">[-]</label><label class="expand" for="c-36331775">[4 more]</label></div><br/><div class="children"><div class="content">IMO this isn&#x27;t a dupe and shouldn&#x27;t be penalized as a result.</div><br/><div id="36331914" class="c"><input type="checkbox" id="c-36331914" checked=""/><div class="controls bullet"><span class="by">dang</span><span>|</span><a href="#36331754">root</a><span>|</span><a href="#36331775">parent</a><span>|</span><a href="#36331343">next</a><span>|</span><label class="collapse" for="c-36331914">[-]</label><label class="expand" for="c-36331914">[3 more]</label></div><br/><div class="children"><div class="content">It&#x27;s certainly not a dupe. It looks like a follow-up though. No?</div><br/><div id="36332016" class="c"><input type="checkbox" id="c-36332016" checked=""/><div class="controls bullet"><span class="by">minimaxir</span><span>|</span><a href="#36331754">root</a><span>|</span><a href="#36331914">parent</a><span>|</span><a href="#36331343">next</a><span>|</span><label class="collapse" for="c-36332016">[-]</label><label class="expand" for="c-36332016">[2 more]</label></div><br/><div class="children"><div class="content">More a very timely but practical demo.</div><br/><div id="36332095" class="c"><input type="checkbox" id="c-36332095" checked=""/><div class="controls bullet"><span class="by">dang</span><span>|</span><a href="#36331754">root</a><span>|</span><a href="#36332016">parent</a><span>|</span><a href="#36331343">next</a><span>|</span><label class="collapse" for="c-36332095">[-]</label><label class="expand" for="c-36332095">[1 more]</label></div><br/><div class="children"><div class="content">Ok, thanks!</div><br/></div></div></div></div></div></div></div></div></div></div><div id="36331343" class="c"><input type="checkbox" id="c-36331343" checked=""/><div class="controls bullet"><span class="by">jamesmcintyre</span><span>|</span><a href="#36331754">prev</a><span>|</span><a href="#36335510">next</a><span>|</span><label class="collapse" for="c-36331343">[-]</label><label class="expand" for="c-36331343">[3 more]</label></div><br/><div class="children"><div class="content">In the openai blog post they mention &quot;Convert “Who are my top ten customers this month?” to an internal API call&quot; but I&#x27;m assuming they mean gpt will respond with structured json (we define via schema in function prompt) that we can use to more easily programatically make that api call?<p>I could be confused but I&#x27;m interpreting this function calling as &quot;a way to define structured input and selection of function and then structured output&quot; but not the actual ability to send it arbitrary code to execute.<p>Still amazing, just wanting to see if I&#x27;m wrong on this.</div><br/><div id="36331447" class="c"><input type="checkbox" id="c-36331447" checked=""/><div class="controls bullet"><span class="by">williamcotton</span><span>|</span><a href="#36331343">parent</a><span>|</span><a href="#36335510">next</a><span>|</span><label class="collapse" for="c-36331447">[-]</label><label class="expand" for="c-36331447">[2 more]</label></div><br/><div class="children"><div class="content">This does not execute code!</div><br/><div id="36331541" class="c"><input type="checkbox" id="c-36331541" checked=""/><div class="controls bullet"><span class="by">jamesmcintyre</span><span>|</span><a href="#36331343">root</a><span>|</span><a href="#36331447">parent</a><span>|</span><a href="#36335510">next</a><span>|</span><label class="collapse" for="c-36331541">[-]</label><label class="expand" for="c-36331541">[1 more]</label></div><br/><div class="children"><div class="content">Ok, yea this makes sense. Also for others curious of the flow here&#x27;s a video walkthrough I just skimmed through: <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=91VVM6MNVlk">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=91VVM6MNVlk</a></div><br/></div></div></div></div></div></div><div id="36335510" class="c"><input type="checkbox" id="c-36335510" checked=""/><div class="controls bullet"><span class="by">lasermatts</span><span>|</span><a href="#36331343">prev</a><span>|</span><a href="#36334864">next</a><span>|</span><label class="collapse" for="c-36335510">[-]</label><label class="expand" for="c-36335510">[1 more]</label></div><br/><div class="children"><div class="content">I thought GPT-4 was doing a pretty good job at outputting JSON (for some of the toy problems I&#x27;ve given it like some of my gardening projects.) Interesting to see this hit the very top of HN</div><br/></div></div><div id="36334864" class="c"><input type="checkbox" id="c-36334864" checked=""/><div class="controls bullet"><span class="by">bel423</span><span>|</span><a href="#36335510">prev</a><span>|</span><a href="#36335369">next</a><span>|</span><label class="collapse" for="c-36334864">[-]</label><label class="expand" for="c-36334864">[4 more]</label></div><br/><div class="children"><div class="content">Did people really struggle with getting JSON outputs from GPT4. You can literally do it zero shot by just saying match this typescript type.<p>GPT3.5 would output perfect JSON with a single example.<p>I have no idea why people are talking about this like it’s a new development.</div><br/><div id="36334894" class="c"><input type="checkbox" id="c-36334894" checked=""/><div class="controls bullet"><span class="by">brolumir</span><span>|</span><a href="#36334864">parent</a><span>|</span><a href="#36335369">next</a><span>|</span><label class="collapse" for="c-36334894">[-]</label><label class="expand" for="c-36334894">[3 more]</label></div><br/><div class="children"><div class="content">Unfortunately, in practice that works only <i>most of the time</i>. At least in our experience (and the article says something similar) sometimes ChatGPT would return something completely different when JSON-formatted response would be expected.</div><br/><div id="36335099" class="c"><input type="checkbox" id="c-36335099" checked=""/><div class="controls bullet"><span class="by">blamy</span><span>|</span><a href="#36334864">root</a><span>|</span><a href="#36334894">parent</a><span>|</span><a href="#36335163">next</a><span>|</span><label class="collapse" for="c-36335099">[-]</label><label class="expand" for="c-36335099">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve been using the same prompts for months and have never seen this happen on 3.5-turbo let alone 4.<p><a href="https:&#x2F;&#x2F;gist.github.com&#x2F;BLamy&#x2F;244eec016beb9ad8ed48cf61fd205428" rel="nofollow noreferrer">https:&#x2F;&#x2F;gist.github.com&#x2F;BLamy&#x2F;244eec016beb9ad8ed48cf61fd2054...</a></div><br/></div></div><div id="36335163" class="c"><input type="checkbox" id="c-36335163" checked=""/><div class="controls bullet"><span class="by">tornato7</span><span>|</span><a href="#36334864">root</a><span>|</span><a href="#36334894">parent</a><span>|</span><a href="#36335099">prev</a><span>|</span><a href="#36335369">next</a><span>|</span><label class="collapse" for="c-36335163">[-]</label><label class="expand" for="c-36335163">[1 more]</label></div><br/><div class="children"><div class="content">In my experience if you set the temperature to zero it works 99.9% of the time, and then you can just add retry logic for the remaining 0.1%</div><br/></div></div></div></div></div></div><div id="36335369" class="c"><input type="checkbox" id="c-36335369" checked=""/><div class="controls bullet"><span class="by">srameshc</span><span>|</span><a href="#36334864">prev</a><span>|</span><a href="#36334073">next</a><span>|</span><label class="collapse" for="c-36335369">[-]</label><label class="expand" for="c-36335369">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve used GCP Vertex AI for a specific task and the prompt was to generate a JSON response with keys specified and it does generate the result as JSON with said keys.</div><br/><div id="36335929" class="c"><input type="checkbox" id="c-36335929" checked=""/><div class="controls bullet"><span class="by">twelfthnight</span><span>|</span><a href="#36335369">parent</a><span>|</span><a href="#36334073">next</a><span>|</span><label class="collapse" for="c-36335929">[-]</label><label class="expand" for="c-36335929">[1 more]</label></div><br/><div class="children"><div class="content">Issue is that&#x27;s it&#x27;s not guaranteed, unlike this new openai feature. Personally, Ive found Vertex AI&#x27;s json output to be not so great, it often uses single quotes in my experience. But maybe you have figured out the right prompts? I&#x27;d be interested what you use if so.</div><br/></div></div></div></div><div id="36334073" class="c"><input type="checkbox" id="c-36334073" checked=""/><div class="controls bullet"><span class="by">amolgupta</span><span>|</span><a href="#36335369">prev</a><span>|</span><a href="#36332824">next</a><span>|</span><label class="collapse" for="c-36334073">[-]</label><label class="expand" for="c-36334073">[1 more]</label></div><br/><div class="children"><div class="content">I pass a kotlin data class and ask chatGPT to return json which can be parsed by that class. Reduces errors with date-time parsing and other formatting issues and takes up lesser tokens than the approach in the article.</div><br/></div></div><div id="36332824" class="c"><input type="checkbox" id="c-36332824" checked=""/><div class="controls bullet"><span class="by">imranq</span><span>|</span><a href="#36334073">prev</a><span>|</span><a href="#36333090">next</a><span>|</span><label class="collapse" for="c-36332824">[-]</label><label class="expand" for="c-36332824">[1 more]</label></div><br/><div class="children"><div class="content">Wouldnt this be possible with a solution like Guidance where you have a pre structured JSON format ready to go and all you need is text: <a href="https:&#x2F;&#x2F;github.com&#x2F;microsoft&#x2F;guidance">https:&#x2F;&#x2F;github.com&#x2F;microsoft&#x2F;guidance</a></div><br/></div></div><div id="36333090" class="c"><input type="checkbox" id="c-36333090" checked=""/><div class="controls bullet"><span class="by">iamflimflam1</span><span>|</span><a href="#36332824">prev</a><span>|</span><a href="#36331379">next</a><span>|</span><label class="collapse" for="c-36333090">[-]</label><label class="expand" for="c-36333090">[1 more]</label></div><br/><div class="children"><div class="content">It’s pretty interesting how the work they’ve been doing on plugins has fed into this.<p>I suspect that they’ve managed to get a lot of good training data by calling the APIs provided by plugins and detecting when it’s gone wrong from bad request responses.</div><br/></div></div><div id="36331379" class="c"><input type="checkbox" id="c-36331379" checked=""/><div class="controls bullet"><span class="by">Kiro</span><span>|</span><a href="#36333090">prev</a><span>|</span><label class="collapse" for="c-36331379">[-]</label><label class="expand" for="c-36331379">[4 more]</label></div><br/><div class="children"><div class="content">Can I use this to make it reliably output code (say JavaScript)? I haven&#x27;t managed to do it with just prompt engineering as it will still add explanations, apologies and do other unwanted things like splitting the code into two files as markdown.</div><br/><div id="36331542" class="c"><input type="checkbox" id="c-36331542" checked=""/><div class="controls bullet"><span class="by">minimaxir</span><span>|</span><a href="#36331379">parent</a><span>|</span><a href="#36331431">next</a><span>|</span><label class="collapse" for="c-36331542">[-]</label><label class="expand" for="c-36331542">[1 more]</label></div><br/><div class="children"><div class="content">Here&#x27;s a demo of some system prompt engineering which resulted in better results for the older ChatGPT: <a href="https:&#x2F;&#x2F;github.com&#x2F;minimaxir&#x2F;simpleaichat&#x2F;blob&#x2F;main&#x2F;examples&#x2F;notebooks&#x2F;simpleaichat_coding.ipynb">https:&#x2F;&#x2F;github.com&#x2F;minimaxir&#x2F;simpleaichat&#x2F;blob&#x2F;main&#x2F;examples...</a><p>Coincidentially, the new gpt-3.5-turbo-0613 model also has better system prompt guidance: for the demo above and some further prompt tweaking, it&#x27;s possible to get ChatGPT to output code super reliably.</div><br/></div></div><div id="36331431" class="c"><input type="checkbox" id="c-36331431" checked=""/><div class="controls bullet"><span class="by">williamcotton</span><span>|</span><a href="#36331379">parent</a><span>|</span><a href="#36331542">prev</a><span>|</span><a href="#36332018">next</a><span>|</span><label class="collapse" for="c-36331431">[-]</label><label class="expand" for="c-36331431">[1 more]</label></div><br/><div class="children"><div class="content">Here’s an approach to return just JavaScript:<p><a href="https:&#x2F;&#x2F;github.com&#x2F;williamcotton&#x2F;transynthetical-engine">https:&#x2F;&#x2F;github.com&#x2F;williamcotton&#x2F;transynthetical-engine</a><p>The key is the addition of few-shot exemplars.</div><br/></div></div><div id="36332018" class="c"><input type="checkbox" id="c-36332018" checked=""/><div class="controls bullet"><span class="by">sanxiyn</span><span>|</span><a href="#36331379">parent</a><span>|</span><a href="#36331431">prev</a><span>|</span><label class="collapse" for="c-36332018">[-]</label><label class="expand" for="c-36332018">[1 more]</label></div><br/><div class="children"><div class="content">Not this, but using the token selection restriction approach, you can let LLM produce output that conforms to arbitrary formal grammar completely reliably. JavaScript, Python, whatever.</div><br/></div></div></div></div></div></div></div></div></div></body></html>