<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1714122122619" as="style"/><link rel="stylesheet" href="styles.css?v=1714122122619"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://arstechnica.com/information-technology/2024/04/apple-releases-eight-small-ai-language-models-aimed-at-on-device-use/">Apple releases eight small AI language models aimed at on-device use</a> <span class="domain">(<a href="https://arstechnica.com">arstechnica.com</a>)</span></div><div class="subtext"><span>MBCook</span> | <span>12 comments</span></div><br/><div><div id="40166419" class="c"><input type="checkbox" id="c-40166419" checked=""/><div class="controls bullet"><span class="by">GeekyBear</span><span>|</span><a href="#40166257">next</a><span>|</span><label class="collapse" for="c-40166419">[-]</label><label class="expand" for="c-40166419">[4 more]</label></div><br/><div class="children"><div class="content">As is often the case, the article gets the difference between open source and open weights wrong.<p>Also, they don&#x27;t seem to understand that Apple&#x27;s variant of the MIT licence is GPL compatible.<p>&gt; This is Apple&#x27;s variant of MIT. They&#x27;ve added wording around patents, which is why it gets it own shortname. Apple did not give this license a name, so we&#x27;ve named it &quot;Apple MIT License&quot;. It is free and GPL compatible.<p><a href="https:&#x2F;&#x2F;fedoraproject.org&#x2F;wiki&#x2F;Licensing&#x2F;Apple_MIT_License" rel="nofollow">https:&#x2F;&#x2F;fedoraproject.org&#x2F;wiki&#x2F;Licensing&#x2F;Apple_MIT_License</a></div><br/><div id="40166854" class="c"><input type="checkbox" id="c-40166854" checked=""/><div class="controls bullet"><span class="by">whiplash451</span><span>|</span><a href="#40166419">parent</a><span>|</span><a href="#40166490">next</a><span>|</span><label class="collapse" for="c-40166854">[-]</label><label class="expand" for="c-40166854">[1 more]</label></div><br/><div class="children"><div class="content">The concept of open-source for a million-dollar scale LLM is not very useful, especially if you don&#x27;t provide the training set as well.<p>Open weights with a permissive license is much more useful, especially for small and midsize companies.</div><br/></div></div><div id="40166490" class="c"><input type="checkbox" id="c-40166490" checked=""/><div class="controls bullet"><span class="by">gattilorenz</span><span>|</span><a href="#40166419">parent</a><span>|</span><a href="#40166854">prev</a><span>|</span><a href="#40166570">next</a><span>|</span><label class="collapse" for="c-40166490">[-]</label><label class="expand" for="c-40166490">[1 more]</label></div><br/><div class="children"><div class="content">Also many HN commenters don’t get the distinction between open source and open weights… not very surprising that ars technica also doesn’t</div><br/></div></div><div id="40166570" class="c"><input type="checkbox" id="c-40166570" checked=""/><div class="controls bullet"><span class="by">blackeyeblitzar</span><span>|</span><a href="#40166419">parent</a><span>|</span><a href="#40166490">prev</a><span>|</span><a href="#40166257">next</a><span>|</span><label class="collapse" for="c-40166570">[-]</label><label class="expand" for="c-40166570">[1 more]</label></div><br/><div class="children"><div class="content">I’m shocked that Ars got this wrong and is helping Apple openwash their work. But I’m seeing this same utterly basic mistake with other tech media as well, like Venture Beat:<p><a href="https:&#x2F;&#x2F;venturebeat.com&#x2F;ai&#x2F;apple-releases-openelm-small-open-source-ai-models-designed-to-run-on-device&#x2F;" rel="nofollow">https:&#x2F;&#x2F;venturebeat.com&#x2F;ai&#x2F;apple-releases-openelm-small-open...</a></div><br/></div></div></div></div><div id="40166257" class="c"><input type="checkbox" id="c-40166257" checked=""/><div class="controls bullet"><span class="by">buildbot</span><span>|</span><a href="#40166419">prev</a><span>|</span><a href="#40166722">next</a><span>|</span><label class="collapse" for="c-40166257">[-]</label><label class="expand" for="c-40166257">[3 more]</label></div><br/><div class="children"><div class="content">Huh, They used the pile - that&#x27;s a pretty interesting choice for a corporate research team?</div><br/><div id="40166581" class="c"><input type="checkbox" id="c-40166581" checked=""/><div class="controls bullet"><span class="by">blackeyeblitzar</span><span>|</span><a href="#40166257">parent</a><span>|</span><a href="#40166722">next</a><span>|</span><label class="collapse" for="c-40166581">[-]</label><label class="expand" for="c-40166581">[2 more]</label></div><br/><div class="children"><div class="content">There are many variants of the pile at this point, including ones with copyrighted content removed. They are probably using one of those, like:<p><a href="https:&#x2F;&#x2F;huggingface.co&#x2F;datasets&#x2F;monology&#x2F;pile-uncopyrighted" rel="nofollow">https:&#x2F;&#x2F;huggingface.co&#x2F;datasets&#x2F;monology&#x2F;pile-uncopyrighted</a></div><br/><div id="40166687" class="c"><input type="checkbox" id="c-40166687" checked=""/><div class="controls bullet"><span class="by">buildbot</span><span>|</span><a href="#40166257">root</a><span>|</span><a href="#40166581">parent</a><span>|</span><a href="#40166722">next</a><span>|</span><label class="collapse" for="c-40166687">[-]</label><label class="expand" for="c-40166687">[1 more]</label></div><br/><div class="children"><div class="content">Oh that’s really great to know about, thank you!</div><br/></div></div></div></div></div></div><div id="40166722" class="c"><input type="checkbox" id="c-40166722" checked=""/><div class="controls bullet"><span class="by">mosselman</span><span>|</span><a href="#40166257">prev</a><span>|</span><a href="#40166754">next</a><span>|</span><label class="collapse" for="c-40166722">[-]</label><label class="expand" for="c-40166722">[1 more]</label></div><br/><div class="children"><div class="content">Does anyone know wether this will be on ollama? Is it a matter of someone caring enough to implement that or is there a technical limitation?</div><br/></div></div><div id="40166754" class="c"><input type="checkbox" id="c-40166754" checked=""/><div class="controls bullet"><span class="by">juujian</span><span>|</span><a href="#40166722">prev</a><span>|</span><a href="#40165636">next</a><span>|</span><label class="collapse" for="c-40166754">[-]</label><label class="expand" for="c-40166754">[1 more]</label></div><br/><div class="children"><div class="content">I would be curious how much less computationally expensive these models are. Full-blown LLMs are overkill for most of the things I do with them. Does running them affect battery life of mobile devices in a major way? This could actually end up saving a ton of electricity. (Or maybe induce even more demand...)</div><br/></div></div><div id="40165636" class="c"><input type="checkbox" id="c-40165636" checked=""/><div class="controls bullet"><span class="by">ChrisArchitect</span><span>|</span><a href="#40166754">prev</a><span>|</span><a href="#40164073">next</a><span>|</span><label class="collapse" for="c-40165636">[-]</label><label class="expand" for="c-40165636">[1 more]</label></div><br/><div class="children"><div class="content">[dupe]<p>Some more discussion: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=40140675">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=40140675</a></div><br/></div></div><div id="40164073" class="c"><input type="checkbox" id="c-40164073" checked=""/><div class="controls bullet"><span class="by">fouc</span><span>|</span><a href="#40165636">prev</a><span>|</span><label class="collapse" for="c-40164073">[-]</label><label class="expand" for="c-40164073">[1 more]</label></div><br/><div class="children"><div class="content">&quot;Small Language Models&quot; for on-device use. Neat.<p>&gt; The eight OpenELM models come in two flavors: four as &quot;pretrained&quot; (basically a raw, next-token version of the model) and four as instruction-tuned (fine-tuned for instruction following, which is more ideal for developing AI assistants and chatbots)</div><br/></div></div></div></div></div></div></div></body></html>