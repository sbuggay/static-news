<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1735808452641" as="style"/><link rel="stylesheet" href="styles.css?v=1735808452641"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.rwkv.com/">RWKV Language Model</a> <span class="domain">(<a href="https://www.rwkv.com">www.rwkv.com</a>)</span></div><div class="subtext"><span>simonpure</span> | <span>18 comments</span></div><br/><div><div id="42572060" class="c"><input type="checkbox" id="c-42572060" checked=""/><div class="controls bullet"><span class="by">intalentive</span><span>|</span><a href="#42572433">next</a><span>|</span><label class="collapse" for="c-42572060">[-]</label><label class="expand" for="c-42572060">[6 more]</label></div><br/><div class="children"><div class="content">Idea for killer app for recurrent models: low latency, low memory LLM &#x2F; TTS coupling. Start decoding &#x2F; generating speech as soon as new tokens are generated. When the LLM is cranking out token t, the TTS is already working on token t-1. It doesn’t have to wait. Then when the LLM is finished, the TTS is nearly finished too. The two models being colocated you just saved another network call as well.<p>Recurrent models with constant hidden state are naturally suited to streaming data, potentially opening the door to unexplored new use cases.</div><br/><div id="42572101" class="c"><input type="checkbox" id="c-42572101" checked=""/><div class="controls bullet"><span class="by">computerex</span><span>|</span><a href="#42572060">parent</a><span>|</span><a href="#42572466">next</a><span>|</span><label class="collapse" for="c-42572101">[-]</label><label class="expand" for="c-42572101">[2 more]</label></div><br/><div class="children"><div class="content">New multimodal models take raw speech input and provide raw speech output, no tts in the middle.</div><br/><div id="42572548" class="c"><input type="checkbox" id="c-42572548" checked=""/><div class="controls bullet"><span class="by">benob</span><span>|</span><a href="#42572060">root</a><span>|</span><a href="#42572101">parent</a><span>|</span><a href="#42572466">next</a><span>|</span><label class="collapse" for="c-42572548">[-]</label><label class="expand" for="c-42572548">[1 more]</label></div><br/><div class="children"><div class="content">A relatively detailed description of such systems: <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2410.00037" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2410.00037</a></div><br/></div></div></div></div><div id="42572466" class="c"><input type="checkbox" id="c-42572466" checked=""/><div class="controls bullet"><span class="by">pico_creator</span><span>|</span><a href="#42572060">parent</a><span>|</span><a href="#42572101">prev</a><span>|</span><a href="#42572246">next</a><span>|</span><label class="collapse" for="c-42572466">[-]</label><label class="expand" for="c-42572466">[2 more]</label></div><br/><div class="children"><div class="content">This is actually the hypothesis for cartesia (state space team), and hence their deep focus on voice model specifically. Taking full advantage of recurrent models constant time compute, for low latencies.<p>RWKV team&#x27;s focus is still however is first in the multi-lingual text space, then multi-modal space in the future.</div><br/><div id="42572550" class="c"><input type="checkbox" id="c-42572550" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#42572060">root</a><span>|</span><a href="#42572466">parent</a><span>|</span><a href="#42572246">next</a><span>|</span><label class="collapse" for="c-42572550">[-]</label><label class="expand" for="c-42572550">[1 more]</label></div><br/><div class="children"><div class="content">Karan from Cartesia explains SSMs+voice really well: <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=U9DPRZ0lSIQ" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=U9DPRZ0lSIQ</a><p>its one of those retrospectively obvious&#x2F;genius insights that i wish i understood when i first met him</div><br/></div></div></div></div><div id="42572246" class="c"><input type="checkbox" id="c-42572246" checked=""/><div class="controls bullet"><span class="by">cootsnuck</span><span>|</span><a href="#42572060">parent</a><span>|</span><a href="#42572466">prev</a><span>|</span><a href="#42572433">next</a><span>|</span><label class="collapse" for="c-42572246">[-]</label><label class="expand" for="c-42572246">[1 more]</label></div><br/><div class="children"><div class="content">This can currently already be done using a streaming capable LLM with a streaming input&#x2F;output TTS model.</div><br/></div></div></div></div><div id="42572433" class="c"><input type="checkbox" id="c-42572433" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#42572060">prev</a><span>|</span><a href="#42572474">next</a><span>|</span><label class="collapse" for="c-42572433">[-]</label><label class="expand" for="c-42572433">[2 more]</label></div><br/><div class="children"><div class="content">for those who want a more conversational intro, we&#x27;ve been covering RWKV for a bit!<p>2023: <a href="https:&#x2F;&#x2F;latent.space&#x2F;p&#x2F;rwkv" rel="nofollow">https:&#x2F;&#x2F;latent.space&#x2F;p&#x2F;rwkv</a><p>2024: <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=LPe6iC73lrc" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=LPe6iC73lrc</a> &lt;- offers a bit of professional compare and contrast vs state space models.<p>i think its cool that now both RNN and LSTM (with xLSTM) now have modern attention-inspired variants that solve the previous issues. I wonder if 1) its possible to overcome the &quot;hardware lottery&quot; that transformers have now won, and 2) if recurrent&#x2F;selective state can do the kind of proper lookback on extremely long context that we will want it to do to compete with full attention (easy to say no, harder to propose what to do about it).<p>there&#x27;s also Liquid AI, whatever it is that they do.</div><br/><div id="42572837" class="c"><input type="checkbox" id="c-42572837" checked=""/><div class="controls bullet"><span class="by">inciampati</span><span>|</span><a href="#42572433">parent</a><span>|</span><a href="#42572474">next</a><span>|</span><label class="collapse" for="c-42572837">[-]</label><label class="expand" for="c-42572837">[1 more]</label></div><br/><div class="children"><div class="content">the recurrent model needs a mechanism to replay past context. no need to go quadratic to access all of it. they could replay multiple times to get effects similar to attention.<p>the hardware lottery, well... imo it&#x27;s really about leveraging fully parallel training to learn how to use a memory. attention is quadratic but it can be computed in parallel. it&#x27;s an end to end learned memory. getting that kind of pattern into RNNs won&#x27;t be easy but it&#x27;s going to be crucial before we boil the ocean.</div><br/></div></div></div></div><div id="42572474" class="c"><input type="checkbox" id="c-42572474" checked=""/><div class="controls bullet"><span class="by">pico_creator</span><span>|</span><a href="#42572433">prev</a><span>|</span><a href="#42572417">next</a><span>|</span><label class="collapse" for="c-42572474">[-]</label><label class="expand" for="c-42572474">[4 more]</label></div><br/><div class="children"><div class="content">Hey there, im Eugene &#x2F; PicoCreator - co-leading the RWKV project - feel free to AMA =)</div><br/><div id="42572781" class="c"><input type="checkbox" id="c-42572781" checked=""/><div class="controls bullet"><span class="by">Ey7NFZ3P0nzAe</span><span>|</span><a href="#42572474">parent</a><span>|</span><a href="#42572766">next</a><span>|</span><label class="collapse" for="c-42572781">[-]</label><label class="expand" for="c-42572781">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m quite interested in repeng [0] (representztion engineering) for steerability of (so fzr transformer based) LLMs and was wondering if anyone had tried such methods on rwkv (or mamba for that matter). Maybe there are some low hanging fruits about it.<p>[0] <a href="https:&#x2F;&#x2F;github.com&#x2F;vgel&#x2F;repeng&#x2F;issues">https:&#x2F;&#x2F;github.com&#x2F;vgel&#x2F;repeng&#x2F;issues</a></div><br/></div></div><div id="42572766" class="c"><input type="checkbox" id="c-42572766" checked=""/><div class="controls bullet"><span class="by">Ey7NFZ3P0nzAe</span><span>|</span><a href="#42572474">parent</a><span>|</span><a href="#42572781">prev</a><span>|</span><a href="#42572617">next</a><span>|</span><label class="collapse" for="c-42572766">[-]</label><label class="expand" for="c-42572766">[1 more]</label></div><br/><div class="children"><div class="content">Has there been progress towards making RWKV multimodal? Can be use projector layers to send images to RWKV?</div><br/></div></div><div id="42572617" class="c"><input type="checkbox" id="c-42572617" checked=""/><div class="controls bullet"><span class="by">low_tech_punk</span><span>|</span><a href="#42572474">parent</a><span>|</span><a href="#42572766">prev</a><span>|</span><a href="#42572417">next</a><span>|</span><label class="collapse" for="c-42572617">[-]</label><label class="expand" for="c-42572617">[1 more]</label></div><br/><div class="children"><div class="content">Thanks! The 0.1B version looks perfect for embedded system. What is the key benefit of attention-free architecture?</div><br/></div></div></div></div><div id="42572417" class="c"><input type="checkbox" id="c-42572417" checked=""/><div class="controls bullet"><span class="by">sushidev</span><span>|</span><a href="#42572474">prev</a><span>|</span><a href="#42572039">next</a><span>|</span><label class="collapse" for="c-42572417">[-]</label><label class="expand" for="c-42572417">[3 more]</label></div><br/><div class="children"><div class="content">Interesting. Very cryptic for simple user like me. I wonder if it’s useful today and for what purposes</div><br/><div id="42572479" class="c"><input type="checkbox" id="c-42572479" checked=""/><div class="controls bullet"><span class="by">pico_creator</span><span>|</span><a href="#42572417">parent</a><span>|</span><a href="#42572039">next</a><span>|</span><label class="collapse" for="c-42572479">[-]</label><label class="expand" for="c-42572479">[2 more]</label></div><br/><div class="children"><div class="content">Currently the strongest RWKV model is 32B in size: <a href="https:&#x2F;&#x2F;substack.recursal.ai&#x2F;p&#x2F;q-rwkv-6-32b-instruct-preview" rel="nofollow">https:&#x2F;&#x2F;substack.recursal.ai&#x2F;p&#x2F;q-rwkv-6-32b-instruct-preview</a><p>This is a full drop in replacement for any transformer model use cases on model sizes 32B and under, as it has equal performance to existing open 32B models in most benchmarks<p>We are in works on a 70B, which will be a full drop in replacement for most text use cases</div><br/><div id="42572544" class="c"><input type="checkbox" id="c-42572544" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#42572417">root</a><span>|</span><a href="#42572479">parent</a><span>|</span><a href="#42572039">next</a><span>|</span><label class="collapse" for="c-42572544">[-]</label><label class="expand" for="c-42572544">[1 more]</label></div><br/><div class="children"><div class="content">how about finetuning your 32B to be R1QWQKV?</div><br/></div></div></div></div></div></div><div id="42572039" class="c"><input type="checkbox" id="c-42572039" checked=""/><div class="controls bullet"><span class="by">nullc</span><span>|</span><a href="#42572417">prev</a><span>|</span><label class="collapse" for="c-42572039">[-]</label><label class="expand" for="c-42572039">[2 more]</label></div><br/><div class="children"><div class="content">Anyone ever look at doing a MoE like composition with RWKV and a transformer?</div><br/><div id="42572451" class="c"><input type="checkbox" id="c-42572451" checked=""/><div class="controls bullet"><span class="by">pico_creator</span><span>|</span><a href="#42572039">parent</a><span>|</span><label class="collapse" for="c-42572451">[-]</label><label class="expand" for="c-42572451">[1 more]</label></div><br/><div class="children"><div class="content">Not an MoE, but we have already done hybrid models. And found it to be highly performant (as per the training budget)<p><a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2407.12077" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2407.12077</a></div><br/></div></div></div></div></div></div></div></div></div></body></html>