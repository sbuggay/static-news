<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1733648455680" as="style"/><link rel="stylesheet" href="styles.css?v=1733648455680"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://countless.dev/">Show HN: Countless.dev – A website to compare every AI model: LLMs, TTSs, STTs</a> <span class="domain">(<a href="https://countless.dev">countless.dev</a>)</span></div><div class="subtext"><span>ahmetd</span> | <span>70 comments</span></div><br/><div><div id="42350585" class="c"><input type="checkbox" id="c-42350585" checked=""/><div class="controls bullet"><span class="by">vunderba</span><span>|</span><a href="#42349387">next</a><span>|</span><label class="collapse" for="c-42350585">[-]</label><label class="expand" for="c-42350585">[4 more]</label></div><br/><div class="children"><div class="content">OP, were you inspired by this LLM comparison tool?<p><a href="https:&#x2F;&#x2F;whatllm.vercel.app" rel="nofollow">https:&#x2F;&#x2F;whatllm.vercel.app</a><p>The tables are very similar - though you&#x27;ve added a custom calculator which is a nice touch.<p>Also for the Versus Comparison, it might be nice to have a checkbox that when clicked highlights the superlative fields of each LLM at a glance.</div><br/><div id="42352972" class="c"><input type="checkbox" id="c-42352972" checked=""/><div class="controls bullet"><span class="by">Gcam</span><span>|</span><a href="#42350585">parent</a><span>|</span><a href="#42351411">next</a><span>|</span><label class="collapse" for="c-42352972">[-]</label><label class="expand" for="c-42352972">[1 more]</label></div><br/><div class="children"><div class="content">Data in this tool is from <a href="https:&#x2F;&#x2F;artificialanalysis.ai&#x2F;" rel="nofollow">https:&#x2F;&#x2F;artificialanalysis.ai&#x2F;</a> on October 13 2024 and so is a little of out date.<p>This page has up to date information of all models and providers: <a href="https:&#x2F;&#x2F;artificialanalysis.ai&#x2F;leaderboards&#x2F;providers" rel="nofollow">https:&#x2F;&#x2F;artificialanalysis.ai&#x2F;leaderboards&#x2F;providers</a>
We also on other pages cover Speech to Text, Text to Speech, Text to Image, Text to Video.<p>Note I&#x27;m one of the creators of Artificial Analysis.</div><br/></div></div><div id="42351411" class="c"><input type="checkbox" id="c-42351411" checked=""/><div class="controls bullet"><span class="by">xnx</span><span>|</span><a href="#42350585">parent</a><span>|</span><a href="#42352972">prev</a><span>|</span><a href="#42349387">next</a><span>|</span><label class="collapse" for="c-42351411">[-]</label><label class="expand" for="c-42351411">[2 more]</label></div><br/><div class="children"><div class="content">Thanks for sharing. That&#x27;s a better tool.</div><br/><div id="42352351" class="c"><input type="checkbox" id="c-42352351" checked=""/><div class="controls bullet"><span class="by">andrewmcwatters</span><span>|</span><a href="#42350585">root</a><span>|</span><a href="#42351411">parent</a><span>|</span><a href="#42349387">next</a><span>|</span><label class="collapse" for="c-42352351">[-]</label><label class="expand" for="c-42352351">[1 more]</label></div><br/><div class="children"><div class="content">Both seem to have great value. Some information is missing from Vercel&#x27;s tables.</div><br/></div></div></div></div></div></div><div id="42349387" class="c"><input type="checkbox" id="c-42349387" checked=""/><div class="controls bullet"><span class="by">ursaguild</span><span>|</span><a href="#42350585">prev</a><span>|</span><a href="#42350430">next</a><span>|</span><label class="collapse" for="c-42349387">[-]</label><label class="expand" for="c-42349387">[6 more]</label></div><br/><div class="children"><div class="content">I like the idea of more comparisons of models. Are there plans to add independent analyses of these models or is it only an aggregation of input limits?<p>How do you see this differing from or adding to other analyses such as:<p><a href="https:&#x2F;&#x2F;artificialanalysis.ai" rel="nofollow">https:&#x2F;&#x2F;artificialanalysis.ai</a><p><a href="https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;TTS-AGI&#x2F;TTS-Arena" rel="nofollow">https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;TTS-AGI&#x2F;TTS-Arena</a><p><a href="https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;hf-audio&#x2F;open_asr_leaderboard" rel="nofollow">https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;hf-audio&#x2F;open_asr_leaderboard</a><p><a href="https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;TIGER-Lab&#x2F;GenAI-Arena" rel="nofollow">https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;TIGER-Lab&#x2F;GenAI-Arena</a><p>Great work on all the aggregation. The website is nice to navigate.</div><br/><div id="42355533" class="c"><input type="checkbox" id="c-42355533" checked=""/><div class="controls bullet"><span class="by">vivzkestrel</span><span>|</span><a href="#42349387">parent</a><span>|</span><a href="#42349602">next</a><span>|</span><label class="collapse" for="c-42355533">[-]</label><label class="expand" for="c-42355533">[1 more]</label></div><br/><div class="children"><div class="content">now imagine going one step further and actually running a prompt across every AI model and showing you the best answer and the AI model that generated it</div><br/></div></div><div id="42349602" class="c"><input type="checkbox" id="c-42349602" checked=""/><div class="controls bullet"><span class="by">ahmetd</span><span>|</span><a href="#42349387">parent</a><span>|</span><a href="#42355533">prev</a><span>|</span><a href="#42351316">next</a><span>|</span><label class="collapse" for="c-42349602">[-]</label><label class="expand" for="c-42349602">[2 more]</label></div><br/><div class="children"><div class="content">the gradio ui looks ugly imo, that&#x27;s why I used shadcn and next.js to make the website look good.<p>I&#x27;ll try to make it as user-friendly as possible. Most of the websites are ugly + too technical.</div><br/><div id="42353890" class="c"><input type="checkbox" id="c-42353890" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#42349387">root</a><span>|</span><a href="#42349602">parent</a><span>|</span><a href="#42351316">next</a><span>|</span><label class="collapse" for="c-42353890">[-]</label><label class="expand" for="c-42353890">[1 more]</label></div><br/><div class="children"><div class="content">I want to point out you dodged the data question, and there&#x27;s a reason for it.<p>I like your work visually on first glance, god knows you&#x27;re right about gradio, even if its irrelevant.<p>But peddling extremely limited, out of date, versions of other people&#x27;s data, trumps that, especially with this tagline. &quot;A website to compare every AI model: LLMs, TTSs, STTs&quot;<p>It is a handful of LLMs, then one TTS model, then one STT model, both with 0 data. And it&#x27;s worth pointing out, since this endeavor is motivated by design trumping all: all the columns are for LLM data.</div><br/></div></div></div></div><div id="42351316" class="c"><input type="checkbox" id="c-42351316" checked=""/><div class="controls bullet"><span class="by">botro</span><span>|</span><a href="#42349387">parent</a><span>|</span><a href="#42349602">prev</a><span>|</span><a href="#42350430">next</a><span>|</span><label class="collapse" for="c-42351316">[-]</label><label class="expand" for="c-42351316">[2 more]</label></div><br/><div class="children"><div class="content">I made <a href="https:&#x2F;&#x2F;aimodelreview.com&#x2F;" rel="nofollow">https:&#x2F;&#x2F;aimodelreview.com&#x2F;</a> to compare the outputs of LLMs over a variety of prompts and categories, allowing a side by side comparison between them. I ran each prompt 4 times for different temperature values and that&#x27;s available as a toggle.<p>I was going to add reviews on each model but ran out of steam. Some users have messaged me saying the comparisons are still helpful to them in getting a sense of how different models respond to the same prompt and how temperature affects the same models output on the same prompt.</div><br/><div id="42355423" class="c"><input type="checkbox" id="c-42355423" checked=""/><div class="controls bullet"><span class="by">rtsil</span><span>|</span><a href="#42349387">root</a><span>|</span><a href="#42351316">parent</a><span>|</span><a href="#42350430">next</a><span>|</span><label class="collapse" for="c-42355423">[-]</label><label class="expand" for="c-42355423">[1 more]</label></div><br/><div class="children"><div class="content">I can confirm, it&#x27;s still very helful, thank you!</div><br/></div></div></div></div></div></div><div id="42350430" class="c"><input type="checkbox" id="c-42350430" checked=""/><div class="controls bullet"><span class="by">karpatic</span><span>|</span><a href="#42349387">prev</a><span>|</span><a href="#42350466">next</a><span>|</span><label class="collapse" for="c-42350430">[-]</label><label class="expand" for="c-42350430">[7 more]</label></div><br/><div class="children"><div class="content">Great! I wish there was a &quot;bang to buck&quot; value. Some way to know the cheapest model I could use for creating structured data from unstructured text, reliably. Using gpt4o-mini which is cheap but wouldn&#x27;t know if anything cheaper could do the job too.</div><br/><div id="42350528" class="c"><input type="checkbox" id="c-42350528" checked=""/><div class="controls bullet"><span class="by">jampa</span><span>|</span><a href="#42350430">parent</a><span>|</span><a href="#42351453">next</a><span>|</span><label class="collapse" for="c-42350528">[-]</label><label class="expand" for="c-42350528">[2 more]</label></div><br/><div class="children"><div class="content">Take a look at Gemini Flash 1.5. I had videos I needed to turn into structured notes, and the result was satisfactory (even better than the Gemini 1.5 Pro, for some reason). <a href="https:&#x2F;&#x2F;jampauchoa.substack.com&#x2F;i&#x2F;151329856&#x2F;ai-studio" rel="nofollow">https:&#x2F;&#x2F;jampauchoa.substack.com&#x2F;i&#x2F;151329856&#x2F;ai-studio</a>.<p>According to this website, the cost is half of the gpt4-o mini. 0.15 vs 0.07 per 1M token.</div><br/><div id="42351469" class="c"><input type="checkbox" id="c-42351469" checked=""/><div class="controls bullet"><span class="by">nostrebored</span><span>|</span><a href="#42350430">root</a><span>|</span><a href="#42350528">parent</a><span>|</span><a href="#42351453">next</a><span>|</span><label class="collapse" for="c-42351469">[-]</label><label class="expand" for="c-42351469">[1 more]</label></div><br/><div class="children"><div class="content">Seconding Gemini flash for structured outputs. Have had some quite large jobs I’ve been happy with.</div><br/></div></div></div></div><div id="42351453" class="c"><input type="checkbox" id="c-42351453" checked=""/><div class="controls bullet"><span class="by">sdesol</span><span>|</span><a href="#42350430">parent</a><span>|</span><a href="#42350528">prev</a><span>|</span><a href="#42350740">next</a><span>|</span><label class="collapse" for="c-42351453">[-]</label><label class="expand" for="c-42351453">[1 more]</label></div><br/><div class="children"><div class="content">I haven&#x27;t found a model at the price point of GPT-4o mini that is as capable.  Based on the hype surrounding Llama 3.3 70B, it might be that one though.  On Deepinfra, input tokens are more expensive, but the output token is cheaper so I would say they are probably equivalent in price.<p>Also, best bang for the buck is very subjective, since one person might need it to work for one use case vs somebody else, who needs it for more.</div><br/></div></div><div id="42350740" class="c"><input type="checkbox" id="c-42350740" checked=""/><div class="controls bullet"><span class="by">mcbuilder</span><span>|</span><a href="#42350430">parent</a><span>|</span><a href="#42351453">prev</a><span>|</span><a href="#42350466">next</a><span>|</span><label class="collapse" for="c-42350740">[-]</label><label class="expand" for="c-42350740">[3 more]</label></div><br/><div class="children"><div class="content">I always plug openrouter.ai for making cross-model comparisons. It&#x27;s my general goto for random stuff. (I am not affiliated, just a user)</div><br/><div id="42352808" class="c"><input type="checkbox" id="c-42352808" checked=""/><div class="controls bullet"><span class="by">pickettd</span><span>|</span><a href="#42350430">root</a><span>|</span><a href="#42350740">parent</a><span>|</span><a href="#42350466">next</a><span>|</span><label class="collapse" for="c-42352808">[-]</label><label class="expand" for="c-42352808">[2 more]</label></div><br/><div class="children"><div class="content">I love the idea of openrouter. I hadn&#x27;t realized until recently though that you don&#x27;t necessarily know what quantization a certain provider is running. And of course context size can vary widely from provider to provider for the same model. This blog post had great food for thought  <a href="https:&#x2F;&#x2F;aider.chat&#x2F;2024&#x2F;11&#x2F;21&#x2F;quantization.html" rel="nofollow">https:&#x2F;&#x2F;aider.chat&#x2F;2024&#x2F;11&#x2F;21&#x2F;quantization.html</a></div><br/><div id="42354752" class="c"><input type="checkbox" id="c-42354752" checked=""/><div class="controls bullet"><span class="by">avereveard</span><span>|</span><a href="#42350430">root</a><span>|</span><a href="#42352808">parent</a><span>|</span><a href="#42350466">next</a><span>|</span><label class="collapse" for="c-42354752">[-]</label><label class="expand" for="c-42354752">[1 more]</label></div><br/><div class="children"><div class="content">To expand a little, some providers may apply more aggressive optimization in periods of high load.</div><br/></div></div></div></div></div></div></div></div><div id="42350466" class="c"><input type="checkbox" id="c-42350466" checked=""/><div class="controls bullet"><span class="by">gtirloni</span><span>|</span><a href="#42350430">prev</a><span>|</span><a href="#42353783">next</a><span>|</span><label class="collapse" for="c-42350466">[-]</label><label class="expand" for="c-42350466">[6 more]</label></div><br/><div class="children"><div class="content">Tangent question: is there anything better on the desktop than ChatGPT&#x27;s native client? I find it too simple to organize chats but  I&#x27;m having a hard time evaluating the dozen or so apps (most are disguise for some company&#x27;s API service). Any recommendations? macOS&#x2F;Linux compatibility preferred.</div><br/><div id="42350995" class="c"><input type="checkbox" id="c-42350995" checked=""/><div class="controls bullet"><span class="by">ralfhn</span><span>|</span><a href="#42350466">parent</a><span>|</span><a href="#42355432">next</a><span>|</span><label class="collapse" for="c-42350995">[-]</label><label class="expand" for="c-42350995">[3 more]</label></div><br/><div class="children"><div class="content">There’s <a href="https:&#x2F;&#x2F;www.typingmind.com&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.typingmind.com&#x2F;</a> local-only (no server) and built by an indie dev</div><br/><div id="42351059" class="c"><input type="checkbox" id="c-42351059" checked=""/><div class="controls bullet"><span class="by">thelittleone</span><span>|</span><a href="#42350466">root</a><span>|</span><a href="#42350995">parent</a><span>|</span><a href="#42355432">next</a><span>|</span><label class="collapse" for="c-42351059">[-]</label><label class="expand" for="c-42351059">[2 more]</label></div><br/><div class="children"><div class="content">Peesonally im a Typing Mind user but it got too slow and buggy with long cbaglts. Ended up with boltai which is a natice mac app and found it very good after months of heavy use. I think it could also improve navigation coloring or iconography to help distinguish chats better but its my favorite so far.</div><br/><div id="42351173" class="c"><input type="checkbox" id="c-42351173" checked=""/><div class="controls bullet"><span class="by">rubymamis</span><span>|</span><a href="#42350466">root</a><span>|</span><a href="#42351059">parent</a><span>|</span><a href="#42355432">next</a><span>|</span><label class="collapse" for="c-42351173">[-]</label><label class="expand" for="c-42351173">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m working on a native LLM client that is beautiful and fast[1], developed in Qt C++ and QML - so it can run on Windows, macOS, Linux (and mobile). Would love to get your feedback once it launches.<p>[1] <a href="https:&#x2F;&#x2F;rubymamistvalove.com&#x2F;client.mp4" rel="nofollow">https:&#x2F;&#x2F;rubymamistvalove.com&#x2F;client.mp4</a></div><br/></div></div></div></div></div></div><div id="42355432" class="c"><input type="checkbox" id="c-42355432" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#42350466">parent</a><span>|</span><a href="#42350995">prev</a><span>|</span><a href="#42351259">next</a><span>|</span><label class="collapse" for="c-42355432">[-]</label><label class="expand" for="c-42355432">[1 more]</label></div><br/><div class="children"><div class="content">Telosnex: every platform, native. Also, has web. Anthropic, OpenAI, Mistral, Groq, Gemini, and any local LLM on literally every platform. and you can bring your own API keys, and the best search available. Pay as you go, with everything at cost if you pay $10&#x2F;month. Otherwise, free. Everythings stored in simple JSON.</div><br/></div></div><div id="42351259" class="c"><input type="checkbox" id="c-42351259" checked=""/><div class="controls bullet"><span class="by">shepherdjerred</span><span>|</span><a href="#42350466">parent</a><span>|</span><a href="#42355432">prev</a><span>|</span><a href="#42353783">next</a><span>|</span><label class="collapse" for="c-42351259">[-]</label><label class="expand" for="c-42351259">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve liked Machato: <a href="https:&#x2F;&#x2F;untimelyunicorn.gumroad.com&#x2F;l&#x2F;machato" rel="nofollow">https:&#x2F;&#x2F;untimelyunicorn.gumroad.com&#x2F;l&#x2F;machato</a></div><br/></div></div></div></div><div id="42353783" class="c"><input type="checkbox" id="c-42353783" checked=""/><div class="controls bullet"><span class="by">tonetegeatinst</span><span>|</span><a href="#42350466">prev</a><span>|</span><a href="#42354142">next</a><span>|</span><label class="collapse" for="c-42353783">[-]</label><label class="expand" for="c-42353783">[1 more]</label></div><br/><div class="children"><div class="content">Love the UI and table layout. Have you though about showing the different VRAM requirements for models?</div><br/></div></div><div id="42354142" class="c"><input type="checkbox" id="c-42354142" checked=""/><div class="controls bullet"><span class="by">lolinder</span><span>|</span><a href="#42353783">prev</a><span>|</span><a href="#42354981">next</a><span>|</span><label class="collapse" for="c-42354142">[-]</label><label class="expand" for="c-42354142">[7 more]</label></div><br/><div class="children"><div class="content">One thing that stands out playing with the sorting is that Google&#x27;s Gemini claims to have a context window more than 10x that of most of its competition. Has anyone experimented with this to see if its <i>useful</i> context window is actually anything close to that?<p>In my own experiments with the chat models they seem to lose the plot after about 10 replies unless constantly &quot;refreshed&quot;, which is a tiny fraction of the supposed 128000 token input length that 4o has. Does Gemini actually do something dramatically differently, or is their 3 million token context window pure marketing nonsense?</div><br/><div id="42354741" class="c"><input type="checkbox" id="c-42354741" checked=""/><div class="controls bullet"><span class="by">avereveard</span><span>|</span><a href="#42354142">parent</a><span>|</span><a href="#42354409">next</a><span>|</span><label class="collapse" for="c-42354741">[-]</label><label class="expand" for="c-42354741">[2 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;github.com&#x2F;NVIDIA&#x2F;RULER">https:&#x2F;&#x2F;github.com&#x2F;NVIDIA&#x2F;RULER</a> results in benchmark other than needle in haystack seem solid all the way to 128k</div><br/><div id="42354891" class="c"><input type="checkbox" id="c-42354891" checked=""/><div class="controls bullet"><span class="by">lolinder</span><span>|</span><a href="#42354142">root</a><span>|</span><a href="#42354741">parent</a><span>|</span><a href="#42354409">next</a><span>|</span><label class="collapse" for="c-42354891">[-]</label><label class="expand" for="c-42354891">[1 more]</label></div><br/><div class="children"><div class="content">Thanks, this is exactly the kind of info I was hoping existed.</div><br/></div></div></div></div><div id="42354409" class="c"><input type="checkbox" id="c-42354409" checked=""/><div class="controls bullet"><span class="by">danpalmer</span><span>|</span><a href="#42354142">parent</a><span>|</span><a href="#42354741">prev</a><span>|</span><a href="#42354185">next</a><span>|</span><label class="collapse" for="c-42354409">[-]</label><label class="expand" for="c-42354409">[1 more]</label></div><br/><div class="children"><div class="content">When the released it they specifically focused on the accurate recall across the context window. There are a bunch of demos of things like giving it a whole movie as input (frame every N seconds plus script or something) and asking for highly specific facts).<p>Anecdotally, I use NotebookLM a bit, and while that’s probably RAG plus large contexts (to be clear, this is a guess not based on inside knowledge), it seems very accurate.</div><br/></div></div><div id="42354185" class="c"><input type="checkbox" id="c-42354185" checked=""/><div class="controls bullet"><span class="by">wtvanhest</span><span>|</span><a href="#42354142">parent</a><span>|</span><a href="#42354409">prev</a><span>|</span><a href="#42354981">next</a><span>|</span><label class="collapse" for="c-42354185">[-]</label><label class="expand" for="c-42354185">[3 more]</label></div><br/><div class="children"><div class="content">What tactics do you use to refresh while using them?</div><br/><div id="42354254" class="c"><input type="checkbox" id="c-42354254" checked=""/><div class="controls bullet"><span class="by">zoltrix303</span><span>|</span><a href="#42354142">root</a><span>|</span><a href="#42354185">parent</a><span>|</span><a href="#42354274">next</a><span>|</span><label class="collapse" for="c-42354254">[-]</label><label class="expand" for="c-42354254">[1 more]</label></div><br/><div class="children"><div class="content">I tend to use a sentence along these lines:
&quot;Give me a straightforward summary of what we discussed so far, someone who didn&#x27;t read the above should understand the details. Don&#x27;t be too verbose.&quot;<p>Then i just continue from there or simply use this as a seed in another fresh chat.</div><br/></div></div><div id="42354274" class="c"><input type="checkbox" id="c-42354274" checked=""/><div class="controls bullet"><span class="by">lolinder</span><span>|</span><a href="#42354142">root</a><span>|</span><a href="#42354185">parent</a><span>|</span><a href="#42354254">prev</a><span>|</span><a href="#42354981">next</a><span>|</span><label class="collapse" for="c-42354274">[-]</label><label class="expand" for="c-42354274">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t have a strategy that I like—it just amounts to having to say &quot;you forgot about requirement X, try again keeping that in mind&quot;.</div><br/></div></div></div></div></div></div><div id="42354981" class="c"><input type="checkbox" id="c-42354981" checked=""/><div class="controls bullet"><span class="by">nikvdp</span><span>|</span><a href="#42354142">prev</a><span>|</span><a href="#42354905">next</a><span>|</span><label class="collapse" for="c-42354981">[-]</label><label class="expand" for="c-42354981">[1 more]</label></div><br/><div class="children"><div class="content">you guys might also like <a href="http:&#x2F;&#x2F;llmprices.dev" rel="nofollow">http:&#x2F;&#x2F;llmprices.dev</a>, similar but it&#x27;s automatically updated with the latest info every 24h</div><br/></div></div><div id="42354905" class="c"><input type="checkbox" id="c-42354905" checked=""/><div class="controls bullet"><span class="by">5563221177</span><span>|</span><a href="#42354981">prev</a><span>|</span><a href="#42349603">next</a><span>|</span><label class="collapse" for="c-42354905">[-]</label><label class="expand" for="c-42354905">[1 more]</label></div><br/><div class="children"><div class="content">Logs emitted during the build, or test results, or metrics captured during the build (such as how long it took)... these can all themselves be build outputs.<p>I&#x27;ve got one where &quot;deploying&quot; means updating a few version strings and image reverences in a different repo. The &quot;build&quot; clones that repo and makes the changes in the necessary spots and makes a commit. Yes, the side effect I want is that the commit gets pushed--which requires my ssh key which is not a build input--but I sort of prefer doing that bit by hand.</div><br/></div></div><div id="42349603" class="c"><input type="checkbox" id="c-42349603" checked=""/><div class="controls bullet"><span class="by">politelemon</span><span>|</span><a href="#42354905">prev</a><span>|</span><a href="#42354176">next</a><span>|</span><label class="collapse" for="c-42349603">[-]</label><label class="expand" for="c-42349603">[4 more]</label></div><br/><div class="children"><div class="content">There are only two audio transcription models. Is this generally true, are there no open source ones like llama but for transcribing? Or just small dataset on that site</div><br/><div id="42349903" class="c"><input type="checkbox" id="c-42349903" checked=""/><div class="controls bullet"><span class="by">rhdunn</span><span>|</span><a href="#42349603">parent</a><span>|</span><a href="#42350432">next</a><span>|</span><label class="collapse" for="c-42349903">[-]</label><label class="expand" for="c-42349903">[2 more]</label></div><br/><div class="children"><div class="content">It looks like the site is only listing hosted models from major providers, not all models available on huggingface, civit.ai, etc. -- Looking at the image generation and chat lists there are many more models that are on huggingface that are not listed.<p>See <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;models?pipeline_tag=automatic-speech-recognition&amp;sort=trending" rel="nofollow">https:&#x2F;&#x2F;huggingface.co&#x2F;models?pipeline_tag=automatic-speech-...</a><p>Note: Text to Speech and Audio Transcription&#x2F;Automatic Speech Recognition models can be trained on the same data. They currently require training separately as the models are structured differently. One of the challenges is training time as the data can run into the hundreds of hours of audio.</div><br/><div id="42350968" class="c"><input type="checkbox" id="c-42350968" checked=""/><div class="controls bullet"><span class="by">politelemon</span><span>|</span><a href="#42349603">root</a><span>|</span><a href="#42349903">parent</a><span>|</span><a href="#42350432">next</a><span>|</span><label class="collapse" for="c-42350968">[-]</label><label class="expand" for="c-42350968">[1 more]</label></div><br/><div class="children"><div class="content">Thank you both</div><br/></div></div></div></div><div id="42350432" class="c"><input type="checkbox" id="c-42350432" checked=""/><div class="controls bullet"><span class="by">woodson</span><span>|</span><a href="#42349603">parent</a><span>|</span><a href="#42349903">prev</a><span>|</span><a href="#42354176">next</a><span>|</span><label class="collapse" for="c-42350432">[-]</label><label class="expand" for="c-42350432">[1 more]</label></div><br/><div class="children"><div class="content">There are lots and lots of models, covering various use cases (e.g., on device, streaming&#x2F;low-latency, specific languages). People somehow think OpenAI invented audio transcription with whisper in 2022 when other models exist and have been used in production for decades (whisper is the only one listed on that website).</div><br/></div></div></div></div><div id="42354176" class="c"><input type="checkbox" id="c-42354176" checked=""/><div class="controls bullet"><span class="by">Bigie</span><span>|</span><a href="#42349603">prev</a><span>|</span><a href="#42349512">next</a><span>|</span><label class="collapse" for="c-42354176">[-]</label><label class="expand" for="c-42354176">[1 more]</label></div><br/><div class="children"><div class="content">I feel like the number is still a bit lacking, especially since many models made by Chinese companies are not represented, like speech-to-text.<p>As far as I know, there&#x27;s a volcano engine in China that has impressive text-to-speech capabilities. Many local companies are using this model.</div><br/></div></div><div id="42349512" class="c"><input type="checkbox" id="c-42349512" checked=""/><div class="controls bullet"><span class="by">ursaguild</span><span>|</span><a href="#42354176">prev</a><span>|</span><a href="#42351600">next</a><span>|</span><label class="collapse" for="c-42349512">[-]</label><label class="expand" for="c-42349512">[2 more]</label></div><br/><div class="children"><div class="content">Just saw that this was built for a hackathon. Huge kudos and congratulations!</div><br/><div id="42349594" class="c"><input type="checkbox" id="c-42349594" checked=""/><div class="controls bullet"><span class="by">ahmetd</span><span>|</span><a href="#42349512">parent</a><span>|</span><a href="#42351600">next</a><span>|</span><label class="collapse" for="c-42349594">[-]</label><label class="expand" for="c-42349594">[1 more]</label></div><br/><div class="children"><div class="content">thank you! although I wasn&#x27;t able to win the hackathon it was still a fun experience :)</div><br/></div></div></div></div><div id="42351600" class="c"><input type="checkbox" id="c-42351600" checked=""/><div class="controls bullet"><span class="by">robbiemitchell</span><span>|</span><a href="#42349512">prev</a><span>|</span><a href="#42349150">next</a><span>|</span><label class="collapse" for="c-42351600">[-]</label><label class="expand" for="c-42351600">[1 more]</label></div><br/><div class="children"><div class="content">One helpful addition would be Requests Per Minute (RPM), which varies wildly and is critical for streaming use cases -- especially with Bedrock where the quota is account wide.</div><br/></div></div><div id="42349150" class="c"><input type="checkbox" id="c-42349150" checked=""/><div class="controls bullet"><span class="by">mcklaw</span><span>|</span><a href="#42351600">prev</a><span>|</span><a href="#42349094">next</a><span>|</span><label class="collapse" for="c-42349150">[-]</label><label class="expand" for="c-42349150">[4 more]</label></div><br/><div class="children"><div class="content">It would be great if llmarena leadership information would also appear to compare performance vs cost.</div><br/><div id="42349437" class="c"><input type="checkbox" id="c-42349437" checked=""/><div class="controls bullet"><span class="by">ursaguild</span><span>|</span><a href="#42349150">parent</a><span>|</span><a href="#42349222">next</a><span>|</span><label class="collapse" for="c-42349437">[-]</label><label class="expand" for="c-42349437">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;lmarena.ai" rel="nofollow">https:&#x2F;&#x2F;lmarena.ai</a></div><br/></div></div><div id="42349225" class="c"><input type="checkbox" id="c-42349225" checked=""/><div class="controls bullet"><span class="by">ahmetd</span><span>|</span><a href="#42349150">parent</a><span>|</span><a href="#42349222">prev</a><span>|</span><a href="#42349094">next</a><span>|</span><label class="collapse" for="c-42349225">[-]</label><label class="expand" for="c-42349225">[1 more]</label></div><br/><div class="children"><div class="content">yep, will add this :)</div><br/></div></div></div></div><div id="42349094" class="c"><input type="checkbox" id="c-42349094" checked=""/><div class="controls bullet"><span class="by">xnx</span><span>|</span><a href="#42349150">prev</a><span>|</span><a href="#42352783">next</a><span>|</span><label class="collapse" for="c-42349094">[-]</label><label class="expand" for="c-42349094">[3 more]</label></div><br/><div class="children"><div class="content">Nice resource. Almost too comprehensive for someone who doesn&#x27;t know all the sub-version names. Would be great to have a column of the score from lmarena leaderboard. Some prices are 0.00? Is there a page that each row could link to for more detail?</div><br/><div id="42351191" class="c"><input type="checkbox" id="c-42351191" checked=""/><div class="controls bullet"><span class="by">kmoser</span><span>|</span><a href="#42349094">parent</a><span>|</span><a href="#42349243">next</a><span>|</span><label class="collapse" for="c-42351191">[-]</label><label class="expand" for="c-42351191">[1 more]</label></div><br/><div class="children"><div class="content">And a link to the company page where one can use&#x2F;subscribe to the model</div><br/></div></div><div id="42349243" class="c"><input type="checkbox" id="c-42349243" checked=""/><div class="controls bullet"><span class="by">ahmetd</span><span>|</span><a href="#42349094">parent</a><span>|</span><a href="#42351191">prev</a><span>|</span><a href="#42352783">next</a><span>|</span><label class="collapse" for="c-42349243">[-]</label><label class="expand" for="c-42349243">[1 more]</label></div><br/><div class="children"><div class="content">thank you! some models either have N&#x2F;A or 0.00, I found it is like that for the free models and ones that aren&#x27;t available.<p>As per llmarena I&#x27;ll definitely add it, a lot of other people recommended it as well.<p>over time will make the website more descriptive and detailed!</div><br/></div></div></div></div><div id="42352783" class="c"><input type="checkbox" id="c-42352783" checked=""/><div class="controls bullet"><span class="by">ProofHouse</span><span>|</span><a href="#42349094">prev</a><span>|</span><a href="#42350335">next</a><span>|</span><label class="collapse" for="c-42352783">[-]</label><label class="expand" for="c-42352783">[1 more]</label></div><br/><div class="children"><div class="content">These are hard to keep updated. I find they usually fall off. It would be cool to have one, but honestly, this one already doesn&#x27;t even have 4o and pro on it which if it was being maintained, it obviously would. Updating a table shouldn&#x27;t take days. It&#x27;s like a one minute event.</div><br/></div></div><div id="42350335" class="c"><input type="checkbox" id="c-42350335" checked=""/><div class="controls bullet"><span class="by">alif_ibrahim</span><span>|</span><a href="#42352783">prev</a><span>|</span><a href="#42352367">next</a><span>|</span><label class="collapse" for="c-42350335">[-]</label><label class="expand" for="c-42350335">[1 more]</label></div><br/><div class="children"><div class="content">thanks for the comparison table! would be great if the header is sticky so i don&#x27;t get lost in identifying which column is which.</div><br/></div></div><div id="42352367" class="c"><input type="checkbox" id="c-42352367" checked=""/><div class="controls bullet"><span class="by">tomp</span><span>|</span><a href="#42350335">prev</a><span>|</span><a href="#42351119">next</a><span>|</span><label class="collapse" for="c-42352367">[-]</label><label class="expand" for="c-42352367">[1 more]</label></div><br/><div class="children"><div class="content">&quot;every&quot;<p>you&#x27;re missing a lot<p>TTS: 11labs, PlayHT, Cartesia, iFLYTEK, AWS Polly, Deepgram Aura<p>STT: Deepgram (multiple models, including Whisper), Gladia Whisper, Soniox<p>just off the top of my head (it&#x27;s my dayjob!)</div><br/></div></div><div id="42351119" class="c"><input type="checkbox" id="c-42351119" checked=""/><div class="controls bullet"><span class="by">wiradikusuma</span><span>|</span><a href="#42352367">prev</a><span>|</span><a href="#42350091">next</a><span>|</span><label class="collapse" for="c-42351119">[-]</label><label class="expand" for="c-42351119">[1 more]</label></div><br/><div class="children"><div class="content">Suggestions:<p>1. Maybe explain what Chat
Embedding
Image generation
Completion
Audio transcription
TTS (Text To Speech) means?<p>2. Put a running number on the left, or at least just show total?</div><br/></div></div><div id="42350091" class="c"><input type="checkbox" id="c-42350091" checked=""/><div class="controls bullet"><span class="by">dangoodmanUT</span><span>|</span><a href="#42351119">prev</a><span>|</span><a href="#42350125">next</a><span>|</span><label class="collapse" for="c-42350091">[-]</label><label class="expand" for="c-42350091">[1 more]</label></div><br/><div class="children"><div class="content">This is missing... so many models... like most TTS and STT ones.<p>11labs, deepgram, etc.</div><br/></div></div><div id="42350125" class="c"><input type="checkbox" id="c-42350125" checked=""/><div class="controls bullet"><span class="by">shahzaibmushtaq</span><span>|</span><a href="#42350091">prev</a><span>|</span><a href="#42350152">next</a><span>|</span><label class="collapse" for="c-42350125">[-]</label><label class="expand" for="c-42350125">[3 more]</label></div><br/><div class="children"><div class="content">It&#x27;s weird that OpenAI has lower prices for same models and Azure has higher prices. Anyone can explain?<p>BTW impressive idea and upvoted on PH as well.</div><br/><div id="42350259" class="c"><input type="checkbox" id="c-42350259" checked=""/><div class="controls bullet"><span class="by">xrendan</span><span>|</span><a href="#42350125">parent</a><span>|</span><a href="#42350234">next</a><span>|</span><label class="collapse" for="c-42350259">[-]</label><label class="expand" for="c-42350259">[1 more]</label></div><br/><div class="children"><div class="content">Azure charges differently based on deployment zone&#x2F;latency guarantees, OpenAI doesn&#x27;t let you pick your zone so it&#x27;s equivalent to the Global Standard deployment (which is the same cost).<p>[0] <a href="https:&#x2F;&#x2F;azure.microsoft.com&#x2F;en-us&#x2F;pricing&#x2F;details&#x2F;cognitive-services&#x2F;openai-service&#x2F;" rel="nofollow">https:&#x2F;&#x2F;azure.microsoft.com&#x2F;en-us&#x2F;pricing&#x2F;details&#x2F;cognitive-...</a></div><br/></div></div><div id="42350234" class="c"><input type="checkbox" id="c-42350234" checked=""/><div class="controls bullet"><span class="by">ahmetd</span><span>|</span><a href="#42350125">parent</a><span>|</span><a href="#42350259">prev</a><span>|</span><a href="#42350152">next</a><span>|</span><label class="collapse" for="c-42350234">[-]</label><label class="expand" for="c-42350234">[1 more]</label></div><br/><div class="children"><div class="content">tysm for the support!<p>OpenAI and Azure should be the same, it&#x27;s weird that it shows it as different. I&#x27;ll look into fixing this.<p>currently #2 on PH, any help would be appreciated!</div><br/></div></div></div></div><div id="42350152" class="c"><input type="checkbox" id="c-42350152" checked=""/><div class="controls bullet"><span class="by">mentalgear</span><span>|</span><a href="#42350125">prev</a><span>|</span><a href="#42349133">next</a><span>|</span><label class="collapse" for="c-42350152">[-]</label><label class="expand" for="c-42350152">[1 more]</label></div><br/><div class="children"><div class="content">This is interesting price-wise, but quality-wise if you do not provide benchmark results, it&#x27;s not that helpful a comparision.</div><br/></div></div><div id="42349133" class="c"><input type="checkbox" id="c-42349133" checked=""/><div class="controls bullet"><span class="by">mtkd</span><span>|</span><a href="#42350152">prev</a><span>|</span><a href="#42349385">next</a><span>|</span><label class="collapse" for="c-42349133">[-]</label><label class="expand" for="c-42349133">[2 more]</label></div><br/><div class="children"><div class="content">Would poss be further useful to have a release date column, license type, whether EU restricted and also right-align &#x2F; comma-delimit those numeric cells</div><br/><div id="42349216" class="c"><input type="checkbox" id="c-42349216" checked=""/><div class="controls bullet"><span class="by">ahmetd</span><span>|</span><a href="#42349133">parent</a><span>|</span><a href="#42349385">next</a><span>|</span><label class="collapse" for="c-42349216">[-]</label><label class="expand" for="c-42349216">[1 more]</label></div><br/><div class="children"><div class="content">good idea, will look into adding this!</div><br/></div></div></div></div><div id="42349385" class="c"><input type="checkbox" id="c-42349385" checked=""/><div class="controls bullet"><span class="by">Its_Padar</span><span>|</span><a href="#42349133">prev</a><span>|</span><a href="#42351306">next</a><span>|</span><label class="collapse" for="c-42349385">[-]</label><label class="expand" for="c-42349385">[1 more]</label></div><br/><div class="children"><div class="content">Would be great if it was possible to get to the page where the pricing was found to make it easier to use the model</div><br/></div></div><div id="42351306" class="c"><input type="checkbox" id="c-42351306" checked=""/><div class="controls bullet"><span class="by">e-clinton</span><span>|</span><a href="#42349385">prev</a><span>|</span><a href="#42350956">next</a><span>|</span><label class="collapse" for="c-42351306">[-]</label><label class="expand" for="c-42351306">[1 more]</label></div><br/><div class="children"><div class="content">DeepInfra prices are significantly better than what’s listed for OS models.</div><br/></div></div><div id="42350956" class="c"><input type="checkbox" id="c-42350956" checked=""/><div class="controls bullet"><span class="by">amelius</span><span>|</span><a href="#42351306">prev</a><span>|</span><a href="#42351275">next</a><span>|</span><label class="collapse" for="c-42350956">[-]</label><label class="expand" for="c-42350956">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m missing the &quot;IQ&quot; column.</div><br/></div></div><div id="42351275" class="c"><input type="checkbox" id="c-42351275" checked=""/><div class="controls bullet"><span class="by">NoZZz</span><span>|</span><a href="#42350956">prev</a><span>|</span><a href="#42350230">next</a><span>|</span><label class="collapse" for="c-42351275">[-]</label><label class="expand" for="c-42351275">[1 more]</label></div><br/><div class="children"><div class="content">Stop feeding their machine.</div><br/></div></div><div id="42350230" class="c"><input type="checkbox" id="c-42350230" checked=""/><div class="controls bullet"><span class="by">methou</span><span>|</span><a href="#42351275">prev</a><span>|</span><a href="#42349915">next</a><span>|</span><label class="collapse" for="c-42350230">[-]</label><label class="expand" for="c-42350230">[1 more]</label></div><br/><div class="children"><div class="content">Thank you on behalf of my waifu!</div><br/></div></div><div id="42349915" class="c"><input type="checkbox" id="c-42349915" checked=""/><div class="controls bullet"><span class="by">wslh</span><span>|</span><a href="#42350230">prev</a><span>|</span><a href="#42353109">next</a><span>|</span><label class="collapse" for="c-42349915">[-]</label><label class="expand" for="c-42349915">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;d like to share a personal perspective&#x2F;rant on AI that might resonate with others: like many, I&#x27;m incredibly excited about this AI moment. The urge to dive headfirst into the field and contribute is natural after all, it&#x27;s the frontier of innovation right now.<p>But I think this moment mirrors financial markets during times of frenzy. When markets are volatile, one common piece of advice is to “wait and see”. Similarly, in AI, so many brilliant minds and organizations are racing to create groundbreaking innovations. Often, what you&#x27;re envisioning as your next big project might already be happening, or will soon be, somewhere else in the world.<p>Adopting a “wait and see” strategy could be surprisingly effective. Instead of rushing in, let the dust settle, observe trends, and focus on leveraging what emerges. In a way, the entire AI ecosystem is working for you: building the foundations for your next big idea.<p>That said, this doesn&#x27;t mean you can&#x27;t integrate the state of the art into your own (working) products and services.</div><br/><div id="42349959" class="c"><input type="checkbox" id="c-42349959" checked=""/><div class="controls bullet"><span class="by">whiplash451</span><span>|</span><a href="#42349915">parent</a><span>|</span><a href="#42353109">next</a><span>|</span><label class="collapse" for="c-42349959">[-]</label><label class="expand" for="c-42349959">[2 more]</label></div><br/><div class="children"><div class="content">Your proposal makes a lot of sense. I assume a number of companies are integrating sota models into their products.<p>That being said, there is no free lunch: when you&#x27;re doing this, you&#x27;re more reactive than proactive. You minimize risk, but you also lose any change to have a stake [1] in the few survivors that will remain and be extremely valuable.<p>Do this long enough and you&#x27;ll have no idea what people are talking about in the field. Watch the latest Dwarkesh Patel episode to get a sense of what I am talking about.<p>[1] stake to be understood broadly as: shares in a company, knowledge as an AI researcher, etc.</div><br/><div id="42350011" class="c"><input type="checkbox" id="c-42350011" checked=""/><div class="controls bullet"><span class="by">wslh</span><span>|</span><a href="#42349915">root</a><span>|</span><a href="#42349959">parent</a><span>|</span><a href="#42353109">next</a><span>|</span><label class="collapse" for="c-42350011">[-]</label><label class="expand" for="c-42350011">[1 more]</label></div><br/><div class="children"><div class="content">Thank you for your thoughtful response! I completely agree that there&#x27;s a tradeoff between being proactive and reactive in this kind of strategy: minimizing risk by waiting can mean missing out on opportunities to gain a broader &quot;stake&quot;.<p>That said, my perspective focuses more on strategic timing rather than complete passivity. It&#x27;s about being engaged with understanding trends, staying informed, and preparing to act decisively when the right opportunity emerges. It&#x27;s less about &quot;waiting on the sidelines&quot; and more about deliberate pacing, recognizing that it’s not always necessary to be at the bleeding edge to create value.<p>I&#x27;ll definitely check out Dwarkesh Patel’s latest episode. I assume it is the Gwern one, right? Thanks!</div><br/></div></div></div></div></div></div><div id="42353109" class="c"><input type="checkbox" id="c-42353109" checked=""/><div class="controls bullet"><span class="by">SubiculumCode</span><span>|</span><a href="#42349915">prev</a><span>|</span><a href="#42350547">next</a><span>|</span><label class="collapse" for="c-42353109">[-]</label><label class="expand" for="c-42353109">[1 more]</label></div><br/><div class="children"><div class="content">I was surprised: what is that the model that costs the most per token? Luminous-Supreme-Control</div><br/></div></div><div id="42350547" class="c"><input type="checkbox" id="c-42350547" checked=""/><div class="controls bullet"><span class="by">moralestapia</span><span>|</span><a href="#42353109">prev</a><span>|</span><label class="collapse" for="c-42350547">[-]</label><label class="expand" for="c-42350547">[1 more]</label></div><br/><div class="children"><div class="content">Hey this is great!<p>A small suggestion, a toggle to exclude between &quot;free&quot; and hosted models.<p>Reason is, I&#x27;m obv. interested in seeing the cheaper models first but am not interested in self-hosting which dominate the first chunk of results because they&#x27;re &quot;free&quot;.</div><br/></div></div></div></div></div></div></div></body></html>