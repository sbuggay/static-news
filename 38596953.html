<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1702285263628" as="style"/><link rel="stylesheet" href="styles.css?v=1702285263628"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://sagittarius.greg.technology/">Show HN: I Remade the Fake Google Gemini Demo, Except Using GPT-4 and It&#x27;s Real</a> <span class="domain">(<a href="https://sagittarius.greg.technology">sagittarius.greg.technology</a>)</span></div><div class="subtext"><span>gregsadetsky</span> | <span>71 comments</span></div><br/><div><div id="38597388" class="c"><input type="checkbox" id="c-38597388" checked=""/><div class="controls bullet"><span class="by">phire</span><span>|</span><a href="#38597522">next</a><span>|</span><label class="collapse" for="c-38597388">[-]</label><label class="expand" for="c-38597388">[13 more]</label></div><br/><div class="children"><div class="content">The &quot;magic&quot; of the fake Gemini demo was the way it seemed like the LLM was continually receiving audio + video input and knew when to jump in with a response.<p>It appeared to be able to wait until the user had finished the drawing, or even jumping in slightly before the drawing finished. At one point the LLM was halfway through a response and then saw the user was now colouring the duck in blue, and started talking about how the duck appearing to be blue. The LLM also appeared to know when a response wasn&#x27;t needed because the user was just agreeing with the LLM.<p>I&#x27;m not sure how many people noticed that on a conscious level, but I positive everyone noticed it subconsciously, and felt the interaction was much more natural, and much more advanced than current LLMs.<p>-----------------<p>Checking the source code, the demo takes screenshots of the video feed every 800ms, waits until the user finishes taking and then sends the last three screenshots.<p>While this demo is impressive, it kind of proves just how unnatural it feels to interact with an LLM in this manner when it doesn&#x27;t have continuous audio-video input. It&#x27;s been technically possible to do kind of thing for a while, but there is a good reason why nobody tried to present it as a product.</div><br/><div id="38597635" class="c"><input type="checkbox" id="c-38597635" checked=""/><div class="controls bullet"><span class="by">gregsadetsky</span><span>|</span><a href="#38597388">parent</a><span>|</span><a href="#38597993">next</a><span>|</span><label class="collapse" for="c-38597635">[-]</label><label class="expand" for="c-38597635">[4 more]</label></div><br/><div class="children"><div class="content">100%.<p>I made this demo in 2-3 hours, and I did use the &quot;wait until the dictation results are finalized&quot; technique which is safer (i.e. the dictation transcription is more robust) but slower.<p>For another demo - <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=fxS7OKh_4vc" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=fxS7OKh_4vc</a> - I kept feeding the &quot;in progress&quot; transcription results into GPT and that was super super awesome &amp; fast. It would just require more work to deal with all of the different timings going on (i.e. there&#x27;s the speech itself from the person, the time to transcribe, sending the request to GPT, &quot;sync&#x27;ing&quot; it to where the person is (mentally&#x2F;in their speech) at the point where GPT replies, etc.)<p>But yeah. Real time&#x2F;continuous talk is absolutely where it&#x27;s at. Should GPT be available as a websocket...?!</div><br/><div id="38598673" class="c"><input type="checkbox" id="c-38598673" checked=""/><div class="controls bullet"><span class="by">modeless</span><span>|</span><a href="#38597388">root</a><span>|</span><a href="#38597635">parent</a><span>|</span><a href="#38597993">next</a><span>|</span><label class="collapse" for="c-38598673">[-]</label><label class="expand" for="c-38598673">[3 more]</label></div><br/><div class="children"><div class="content">I have a rough demo of real time continuous voice chat here, ~1 second response latency: <a href="https:&#x2F;&#x2F;apps.microsoft.com&#x2F;detail&#x2F;9NC624PBFGB7" rel="nofollow noreferrer">https:&#x2F;&#x2F;apps.microsoft.com&#x2F;detail&#x2F;9NC624PBFGB7</a><p>Basically it starts computing a response every time a word comes out of the speech recognizer, and if it is able to finish its response before it hears another word then it starts speaking. If more words come in then it stops speaking immediately; in other words, you can interrupt it. It feels <i>so</i> much more natural in conversation than ChatGPT&#x27;s voice mode due to the low latency and continuous listening with the ability to interrupt.<p>There are a lot of things that need improvement. Most important is probably that the speech recognition system (Whisper) wasn&#x27;t designed for real time and is not that reliable or efficient in a real time mode. I think some more tweaking could improve reliability considerably. But also very important is that it doesn&#x27;t know when <i>not</i> to respond. It will always jump in if you stop speaking for a second, and it will always try to get the last word. A first pass at fixing that would be to fine tune a language model to predict whose turn it is to speak.<p>There are also a lot of things that this architecture will never be able to do. It will never be able to correct your pronunciation (e.g. for language learning), it will never be able to identify your emotions based on vocal cues or express proper emotions in its voice, it will never be able to hear the tone of a singing voice or produce singing itself. The future is in eliminating the boundaries between speech-to-text and LLM and text-to-speech, with one unified model trained end-to-end. Such a system would be able to do everything I mentioned and more, if trained on enough data. And further integrating vision will help with conversation too, allowing it to see the emotions on your face and take conversational cues from your gaze direction and hand gestures, in addition to all the other obvious things you can do with vision such as chat about something the camera can see or something displayed on your screen.</div><br/><div id="38598716" class="c"><input type="checkbox" id="c-38598716" checked=""/><div class="controls bullet"><span class="by">thom</span><span>|</span><a href="#38597388">root</a><span>|</span><a href="#38598673">parent</a><span>|</span><a href="#38597993">next</a><span>|</span><label class="collapse" for="c-38598716">[-]</label><label class="expand" for="c-38598716">[2 more]</label></div><br/><div class="children"><div class="content">What&#x27;s the horizon after which you reset the input instead of appending to it? Does that happen if the user lets the system finish speaking?</div><br/><div id="38598769" class="c"><input type="checkbox" id="c-38598769" checked=""/><div class="controls bullet"><span class="by">modeless</span><span>|</span><a href="#38597388">root</a><span>|</span><a href="#38598716">parent</a><span>|</span><a href="#38597993">next</a><span>|</span><label class="collapse" for="c-38598769">[-]</label><label class="expand" for="c-38598769">[1 more]</label></div><br/><div class="children"><div class="content">Great question. Right now that happens, somewhat arbitrarily, if the user lets the system finish speaking the first sentence of its response. If the user interrupts before that, then it&#x27;s considered a continuation of the previous input. If the user interrupts after that, it&#x27;s still an interruption (and, importantly, the language model&#x27;s response must be truncated in the conversation context because the user didn&#x27;t hear it all), but it starts a new input to the LLM. This could be handled better as well. Basically any heuristics like this that are in the system should eventually be subsumed into the AI models so that they can be responsive to the conversation context.</div><br/></div></div></div></div></div></div></div></div><div id="38597993" class="c"><input type="checkbox" id="c-38597993" checked=""/><div class="controls bullet"><span class="by">TaylorAlexander</span><span>|</span><a href="#38597388">parent</a><span>|</span><a href="#38597635">prev</a><span>|</span><a href="#38597429">next</a><span>|</span><label class="collapse" for="c-38597993">[-]</label><label class="expand" for="c-38597993">[4 more]</label></div><br/><div class="children"><div class="content">Yeah my friend and I were just talking about continuous stream input multimodal LLMs. Does anyone know if there is a technical limitation preventing continuous stream input data? Like it’s listening to you practice guitar and then when you get to a certain point it says “okay let’s go back and practice that section again”. It seems the normal approach of next token prediction falls flat when there is a continuous stream of tokens and it only sometimes needs to produce output.<p>What is that type of input called in the literature and what research has been done on it? Thanks!</div><br/><div id="38598175" class="c"><input type="checkbox" id="c-38598175" checked=""/><div class="controls bullet"><span class="by">profile53</span><span>|</span><a href="#38597388">root</a><span>|</span><a href="#38597993">parent</a><span>|</span><a href="#38597429">next</a><span>|</span><label class="collapse" for="c-38598175">[-]</label><label class="expand" for="c-38598175">[3 more]</label></div><br/><div class="children"><div class="content">At a purely technical level, no, as long as the model can output a null token. E.g. imagine training using a transcript of two people talking. What would be a single text token is a tuple of two tokens, one per person. Each segment where a person is not talking is a series of null tokens, one per ‘tick’ of time. In an actual conversation, one token in the tuple is user input and one is GPT prediction. Just disregard the user half of the tuple when determining whether the GPT should ‘speak’.<p>The real world challenge is threefold. First, null tokens would be massively over represented in training and by extent, in outputs. Second, at a computational level, outputting a continuous stream of tokens would be absurdly expensive. Third, there is not nearly as much training data of interspersed conversations as of monologues (e.g. research papers, this comment, etc.).</div><br/><div id="38598261" class="c"><input type="checkbox" id="c-38598261" checked=""/><div class="controls bullet"><span class="by">TaylorAlexander</span><span>|</span><a href="#38597388">root</a><span>|</span><a href="#38598175">parent</a><span>|</span><a href="#38597429">next</a><span>|</span><label class="collapse" for="c-38598261">[-]</label><label class="expand" for="c-38598261">[2 more]</label></div><br/><div class="children"><div class="content">Yeah it seems the notion of time is sort of not built in conceptually to current systems. You could pick a fixed time constant like 0.1 seconds or 1 second, but it&#x27;s clear that it&#x27;s sort of missing something more fundamental.</div><br/><div id="38598466" class="c"><input type="checkbox" id="c-38598466" checked=""/><div class="controls bullet"><span class="by">radarsat1</span><span>|</span><a href="#38597388">root</a><span>|</span><a href="#38598261">parent</a><span>|</span><a href="#38597429">next</a><span>|</span><label class="collapse" for="c-38598466">[-]</label><label class="expand" for="c-38598466">[1 more]</label></div><br/><div class="children"><div class="content">I think if the same LLM were trained on audio and video input instead of text, and produced audio output, including silence tokens, then the notion of time would get &quot;built in&quot;. Audio continuation without translation to text has been shown to work. Mixing it with text is also possible. But all this would require a massive network that maybe even be difficult for the world&#x27;s biggest companies to train and serve at any kind of scale. So it&#x27;s more of an engineering problem than a theoretical one imho.<p>Also imho, I think until the context&#x2F;memory problem is fully solved we won&#x27;t really see the AI as having any kind of agency. But continuous, low latency interaction would certainly feel like a step towards that.</div><br/></div></div></div></div></div></div></div></div><div id="38597429" class="c"><input type="checkbox" id="c-38597429" checked=""/><div class="controls bullet"><span class="by">og_kalu</span><span>|</span><a href="#38597388">parent</a><span>|</span><a href="#38597993">prev</a><span>|</span><a href="#38597555">next</a><span>|</span><label class="collapse" for="c-38597429">[-]</label><label class="expand" for="c-38597429">[3 more]</label></div><br/><div class="children"><div class="content">I think probably training on pause tokens or something similar would be the key to something like this. Maybe it&#x27;s not even necessary. Maybe if you just tell GPT-4 to output something like .... every time it thinks it should wait for a response (you wouldn&#x27;t need to wait for the user to finish then), things would be a lot smoother.</div><br/><div id="38597499" class="c"><input type="checkbox" id="c-38597499" checked=""/><div class="controls bullet"><span class="by">phire</span><span>|</span><a href="#38597388">root</a><span>|</span><a href="#38597429">parent</a><span>|</span><a href="#38597555">next</a><span>|</span><label class="collapse" for="c-38597499">[-]</label><label class="expand" for="c-38597499">[2 more]</label></div><br/><div class="children"><div class="content">Yes, you could probably fine-tune (or even zero-shot) a LLM to handle the &quot;knowing when to jump in&quot; use case.<p>The real problem is that it&#x27;s simply too computationally expensive to continually feed audio and video into it one of these massive LLMs just in case it might decide to jump in.<p>I was wondering if you could train a lightweight monitoring model that continually watching the audio&#x2F;video input and only tried to work out when the full-sized LLM might want to jump in and generate a response.</div><br/><div id="38597811" class="c"><input type="checkbox" id="c-38597811" checked=""/><div class="controls bullet"><span class="by">bbarnett</span><span>|</span><a href="#38597388">root</a><span>|</span><a href="#38597499">parent</a><span>|</span><a href="#38597555">next</a><span>|</span><label class="collapse" for="c-38597811">[-]</label><label class="expand" for="c-38597811">[1 more]</label></div><br/><div class="children"><div class="content">As the human brain is a clump if regions all interconnected and interacting, for example, one may focus their attention elsewhere until their name is called, having a ight model wait for an important queue makes sense more than fiscally.<p>One time I was so distracted, I missed an entire paragraph someone said to me, walked to my car, drove away, and 5 minutes later processed it.</div><br/></div></div></div></div></div></div><div id="38597555" class="c"><input type="checkbox" id="c-38597555" checked=""/><div class="controls bullet"><span class="by">nextworddev</span><span>|</span><a href="#38597388">parent</a><span>|</span><a href="#38597429">prev</a><span>|</span><a href="#38597522">next</a><span>|</span><label class="collapse" for="c-38597555">[-]</label><label class="expand" for="c-38597555">[1 more]</label></div><br/><div class="children"><div class="content">One easy improvement would be to stop the video capture automatically via a combination of silence detection and motion detection</div><br/></div></div></div></div><div id="38597522" class="c"><input type="checkbox" id="c-38597522" checked=""/><div class="controls bullet"><span class="by">godelski</span><span>|</span><a href="#38597388">prev</a><span>|</span><a href="#38598732">next</a><span>|</span><label class="collapse" for="c-38597522">[-]</label><label class="expand" for="c-38597522">[25 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t get why companies lie like this. How much do they have to gain? It seems like they actually have a lot to lose.<p>What&#x27;s crazy to me is that these tools are wildly impressive without the hype. As a ML researcher, there&#x27;s a lot of cool things we&#x27;ve done but at the same time almost everything I see is vastly over hyped from papers to products. I think there&#x27;s a kinda race to the bottom we&#x27;ve created and it&#x27;s not helpful to any of us except maybe in the short term. Playing short term games isn&#x27;t very smart, especially for companies like Google. Or maybe I completely misunderstand the environment we live in.<p>But then again, with the discussions in this thread[0] maybe there&#x27;s a lot of people so ethically bankrupt that they don&#x27;t even know how what they&#x27;re doing is deceptive. Which is an entirely different and worse problem.<p>[0] <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38559582">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38559582</a></div><br/><div id="38598063" class="c"><input type="checkbox" id="c-38598063" checked=""/><div class="controls bullet"><span class="by">CSMastermind</span><span>|</span><a href="#38597522">parent</a><span>|</span><a href="#38597544">next</a><span>|</span><label class="collapse" for="c-38598063">[-]</label><label class="expand" for="c-38598063">[3 more]</label></div><br/><div class="children"><div class="content">Because the same day they released the video our CEO was messaging me saying we have to get on Google&#x27;s new stuff because it&#x27;s so much better than GPT-4.<p>I said I was skeptical of the demo but, like all developments in the field, will try it out once they release it.</div><br/><div id="38598143" class="c"><input type="checkbox" id="c-38598143" checked=""/><div class="controls bullet"><span class="by">godelski</span><span>|</span><a href="#38597522">root</a><span>|</span><a href="#38598063">parent</a><span>|</span><a href="#38597544">next</a><span>|</span><label class="collapse" for="c-38598143">[-]</label><label class="expand" for="c-38598143">[2 more]</label></div><br/><div class="children"><div class="content">This also seems like equally poor decision making. Wouldn&#x27;t you want to at least try things out before you make a hard switch? Chasing hype is costly.</div><br/><div id="38598309" class="c"><input type="checkbox" id="c-38598309" checked=""/><div class="controls bullet"><span class="by">movedx</span><span>|</span><a href="#38597522">root</a><span>|</span><a href="#38598143">parent</a><span>|</span><a href="#38597544">next</a><span>|</span><label class="collapse" for="c-38598309">[-]</label><label class="expand" for="c-38598309">[1 more]</label></div><br/><div class="children"><div class="content">Welcome to IT.... no seriously, this is how a lot of executives behave in IT.</div><br/></div></div></div></div></div></div><div id="38597544" class="c"><input type="checkbox" id="c-38597544" checked=""/><div class="controls bullet"><span class="by">nextworddev</span><span>|</span><a href="#38597522">parent</a><span>|</span><a href="#38598063">prev</a><span>|</span><a href="#38598124">next</a><span>|</span><label class="collapse" for="c-38597544">[-]</label><label class="expand" for="c-38597544">[9 more]</label></div><br/><div class="children"><div class="content">Google stock rallied 5% ish the after the demo (though the stock didn’t move immediately). Then it gave back about 1% once the news broke that it was faked</div><br/><div id="38597627" class="c"><input type="checkbox" id="c-38597627" checked=""/><div class="controls bullet"><span class="by">lolinder</span><span>|</span><a href="#38597522">root</a><span>|</span><a href="#38597544">parent</a><span>|</span><a href="#38597623">next</a><span>|</span><label class="collapse" for="c-38597627">[-]</label><label class="expand" for="c-38597627">[3 more]</label></div><br/><div class="children"><div class="content">One question I&#x27;ve long had is why short-term changes in stock prices seem to matter so much to companies like these. Is it just that the short-term changes are seen as harbingers of longer-term trends, or is there a concrete reason to play games to get temporary boosts to stock price?</div><br/><div id="38598129" class="c"><input type="checkbox" id="c-38598129" checked=""/><div class="controls bullet"><span class="by">godelski</span><span>|</span><a href="#38597522">root</a><span>|</span><a href="#38597627">parent</a><span>|</span><a href="#38597879">next</a><span>|</span><label class="collapse" for="c-38598129">[-]</label><label class="expand" for="c-38598129">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve been using the term Goodhart&#x27;s Hell to describe what I see as a system of metric hacking and shortsightedness. I do think there&#x27;s systems encouraging people to meet metrics for metrics sake but not stopping to understand the metric or what it actually measures, and most importantly, how that differs from the actual goals. Because all metrics are proxies and far from complete, even for things that sound really simple. I think this is because we&#x27;ve gotten so good at measuring that we&#x27;ve innately forgotten about the noisiness of the system where when we weren&#x27;t good at measuring that was just forced upon us in a clear manner.<p>But I really don&#x27;t get it either. One of the things that really sets humans apart from other animals is our capacity to perform long term planning and prediction. Why abandon that skill instead of exploiting it to its maximum potential?</div><br/></div></div><div id="38597879" class="c"><input type="checkbox" id="c-38597879" checked=""/><div class="controls bullet"><span class="by">YetAnotherNick</span><span>|</span><a href="#38597522">root</a><span>|</span><a href="#38597627">parent</a><span>|</span><a href="#38598129">prev</a><span>|</span><a href="#38597623">next</a><span>|</span><label class="collapse" for="c-38597879">[-]</label><label class="expand" for="c-38597879">[1 more]</label></div><br/><div class="children"><div class="content">Short term changes definitely affect medium to long terms&#x27; price. Because at one level stock price is more like casino and isn&#x27;t actually related to the company&#x27;s performance. e.g. See the 5 year history of gamestop. Its price once increased due to random activity from redditors and its stock price is still increased due to that.</div><br/></div></div></div></div><div id="38597623" class="c"><input type="checkbox" id="c-38597623" checked=""/><div class="controls bullet"><span class="by">godelski</span><span>|</span><a href="#38597522">root</a><span>|</span><a href="#38597544">parent</a><span>|</span><a href="#38597627">prev</a><span>|</span><a href="#38598124">next</a><span>|</span><label class="collapse" for="c-38597623">[-]</label><label class="expand" for="c-38597623">[5 more]</label></div><br/><div class="children"><div class="content">That&#x27;s not a great answer. We need to know the counterfactual question of &quot;How much would google&#x27;s stock have rallied after a realistic demo was given?&quot; I would not have been surprised if the answer was also 5%. Almost certainly Google&#x27;s stock would have risen after announcing Gemini. There are other long term questions too like about how this feeds into growing dissent against Google and trust. But what the stock did is only a small part of a much bigger and far more important question.<p>Edit: Can someone explain the downvotes? Is there a error in my response? I&#x27;m glad to learn but I&#x27;d appreciate a bit better feedback signal so that I can do so better instead of guessing.</div><br/><div id="38598205" class="c"><input type="checkbox" id="c-38598205" checked=""/><div class="controls bullet"><span class="by">dkga</span><span>|</span><a href="#38597522">root</a><span>|</span><a href="#38597623">parent</a><span>|</span><a href="#38597760">next</a><span>|</span><label class="collapse" for="c-38598205">[-]</label><label class="expand" for="c-38598205">[2 more]</label></div><br/><div class="children"><div class="content">Economist here who studies exactly this type of counterfactual analysis. You are completely right: the effect of Gemini can only be estimated if we factor in what the Alphabet stock price would have been in the same time but in a world without Gemini. This is actually very standard in financial economics. This type of effect can be calculated with econometric techniques that compare before&#x2F;after for “treated” vs “untreated” units, but in instances such as these, where only one or a few units were affected, like Alphabet stock amongst hundreds of other companies, one could use techniques such as “synthetic controls”. The intuition is to use other companies’ data to estimate before Gemini how Alphabet stock prices move over time, and then use that relationship to estimate a post-Gemini version of no-Gemini Google. The difference between the actual stock price and that counterfactual is the effect of interest; whether it is a significant effect or just random noise can be established by a number of auxiliary statistical tests. For more info, see [0].<p>[0] Abadie, A. (2021). Using synthetic controls: Feasibility, data requirements, and methodological aspects. Journal of Economic Literature, 59(2), 391-425.</div><br/><div id="38598512" class="c"><input type="checkbox" id="c-38598512" checked=""/><div class="controls bullet"><span class="by">godelski</span><span>|</span><a href="#38597522">root</a><span>|</span><a href="#38598205">parent</a><span>|</span><a href="#38597760">next</a><span>|</span><label class="collapse" for="c-38598512">[-]</label><label class="expand" for="c-38598512">[1 more]</label></div><br/><div class="children"><div class="content">Well I don&#x27;t mean with&#x2F;without Gemini, I mean without the deceptive marketing of Gemini vs had they counterfactually produced a non-deceptive marketing. Other than that nitpicking, I appreciate the backup and the source. Counterfactual testing is by no means easy, so good luck with your work! My gf is an economist but on the macro side. You guys have it tough. I&#x27;m a bit confused why people are disliking my comment but mostly that they are doing so without explanation lol.</div><br/></div></div></div></div><div id="38597760" class="c"><input type="checkbox" id="c-38597760" checked=""/><div class="controls bullet"><span class="by">nextworddev</span><span>|</span><a href="#38597522">root</a><span>|</span><a href="#38597623">parent</a><span>|</span><a href="#38598205">prev</a><span>|</span><a href="#38598124">next</a><span>|</span><label class="collapse" for="c-38597760">[-]</label><label class="expand" for="c-38597760">[2 more]</label></div><br/><div class="children"><div class="content">Broad investor community was spooked by Gemini Ga being delayed to Q1 so this stunt was a good stop gap &#x2F; distraction</div><br/><div id="38598059" class="c"><input type="checkbox" id="c-38598059" checked=""/><div class="controls bullet"><span class="by">yellow_postit</span><span>|</span><a href="#38597522">root</a><span>|</span><a href="#38597760">parent</a><span>|</span><a href="#38598124">next</a><span>|</span><label class="collapse" for="c-38598059">[-]</label><label class="expand" for="c-38598059">[1 more]</label></div><br/><div class="children"><div class="content">And likely caused more long term harm since if they had to fake this they’re likely further behind</div><br/></div></div></div></div></div></div></div></div><div id="38598124" class="c"><input type="checkbox" id="c-38598124" checked=""/><div class="controls bullet"><span class="by">dkga</span><span>|</span><a href="#38597522">parent</a><span>|</span><a href="#38597544">prev</a><span>|</span><a href="#38597731">next</a><span>|</span><label class="collapse" for="c-38598124">[-]</label><label class="expand" for="c-38598124">[3 more]</label></div><br/><div class="children"><div class="content">Relatedly, I saw in the thread that people call these types of deceptions as “smoke and mirrors” or “dog and pony show”. What happened to “Potemkin”?!</div><br/><div id="38598137" class="c"><input type="checkbox" id="c-38598137" checked=""/><div class="controls bullet"><span class="by">godelski</span><span>|</span><a href="#38597522">root</a><span>|</span><a href="#38598124">parent</a><span>|</span><a href="#38598438">next</a><span>|</span><label class="collapse" for="c-38598137">[-]</label><label class="expand" for="c-38598137">[1 more]</label></div><br/><div class="children"><div class="content">I had never previously heard of that term but it does seem apt. I think idioms are often more cultural and can change rapidly while one might seem ubiquitous in your group it isn&#x27;t in another. Another term I think might be apt, but a bit less so, is snake oil or snake oils sells man.</div><br/></div></div><div id="38598438" class="c"><input type="checkbox" id="c-38598438" checked=""/><div class="controls bullet"><span class="by">Austizzle</span><span>|</span><a href="#38597522">root</a><span>|</span><a href="#38598124">parent</a><span>|</span><a href="#38598137">prev</a><span>|</span><a href="#38597731">next</a><span>|</span><label class="collapse" for="c-38598438">[-]</label><label class="expand" for="c-38598438">[1 more]</label></div><br/><div class="children"><div class="content">Perhaps this is revealing my ignorance, but I&#x27;ve never even heard of potemkin before</div><br/></div></div></div></div><div id="38597731" class="c"><input type="checkbox" id="c-38597731" checked=""/><div class="controls bullet"><span class="by">hackerlight</span><span>|</span><a href="#38597522">parent</a><span>|</span><a href="#38598124">prev</a><span>|</span><a href="#38597859">next</a><span>|</span><label class="collapse" for="c-38597731">[-]</label><label class="expand" for="c-38597731">[3 more]</label></div><br/><div class="children"><div class="content">&gt; Playing short term games isn&#x27;t very smart, especially for companies like Google. Or maybe I completely misunderstand the environment we live in.<p>It could be the principal-agent problem. The agent (employee and management) is optimizing for short-term career benefits and has no loyalty to Google&#x27;s shareholders. They can quit after 3 years, so reputation damage to Google doesn&#x27;t matter that much. But the shareholders want agents to optimize for longer-term things like reputation. Aligning those incentives is difficult. Shareholders try with good governance and material incentives tied to the stock price with a vesting schedule, but you&#x27;re still going to get a level of disalignment.<p>I suppose this is where a cult-like culture of mission alignment can deliver value. If you convince&#x2F;select your agents (employees) into actually believing in the mission, alignment follows from that.</div><br/><div id="38598168" class="c"><input type="checkbox" id="c-38598168" checked=""/><div class="controls bullet"><span class="by">godelski</span><span>|</span><a href="#38597522">root</a><span>|</span><a href="#38597731">parent</a><span>|</span><a href="#38597859">next</a><span>|</span><label class="collapse" for="c-38598168">[-]</label><label class="expand" for="c-38598168">[2 more]</label></div><br/><div class="children"><div class="content">Yeah I think that makes some sense. But you would think the CEO and top execs of the company would be trying to balance these forces rather than letting one dominate. You need pressures for short term but you can&#x27;t abandon long term planning for short term optimization. Anyone who&#x27;s worked with basic RL systems should be keenly aware of that and I&#x27;m most certain they teach this in business school. I mean it&#x27;s not like these things don&#x27;t come up multiple times a year.</div><br/><div id="38598304" class="c"><input type="checkbox" id="c-38598304" checked=""/><div class="controls bullet"><span class="by">hackerlight</span><span>|</span><a href="#38597522">root</a><span>|</span><a href="#38598168">parent</a><span>|</span><a href="#38597859">next</a><span>|</span><label class="collapse" for="c-38598304">[-]</label><label class="expand" for="c-38598304">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s some other explanations too. Maybe they thought the deception would fly under the radar, so it was rational according to cost-benefit analysis given available information. Maybe they fell for the human psychological bias of overvaluing near-term costs&#x2F;benefits and undervaluing long-term costs&#x2F;benefits. Maybe some deception was used internally when the demo was communicated to senior execs. Maybe the ego of being second place to OpenAI was too much and the shame avoidance&#x2F;prestige seeking kicked in.</div><br/></div></div></div></div></div></div><div id="38597859" class="c"><input type="checkbox" id="c-38597859" checked=""/><div class="controls bullet"><span class="by">Racing0461</span><span>|</span><a href="#38597522">parent</a><span>|</span><a href="#38597731">prev</a><span>|</span><a href="#38597645">next</a><span>|</span><label class="collapse" for="c-38597859">[-]</label><label class="expand" for="c-38597859">[4 more]</label></div><br/><div class="children"><div class="content">Here is the headline Business Today published just in case you wonder why businesses do this<p>&quot;Google Gemini Outperforms Most Human Experts &amp; GPT-4 I Artificial intelligence I Google’s DeepMind&quot;.<p>It&#x27;s all marketing. Same reason why satya publically postes sama + others are joining a new team at MSFT to continue should the openai thing not work out.</div><br/><div id="38598158" class="c"><input type="checkbox" id="c-38598158" checked=""/><div class="controls bullet"><span class="by">godelski</span><span>|</span><a href="#38597522">root</a><span>|</span><a href="#38597859">parent</a><span>|</span><a href="#38597645">next</a><span>|</span><label class="collapse" for="c-38598158">[-]</label><label class="expand" for="c-38598158">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not sure how that is really responding to my question with an explanation. I&#x27;m well aware that its marketing and I&#x27;d hope my comment makes that clear. The question is why oversell the product, and frankly by a lot. Because people are going to find out, I mean the intent is that they use it after all.<p>I&#x27;m sure the marketing team can come up with good marketing that also isn&#x27;t deceitful. The question is why pull a con when you already got something of value that customers would legitimately buy?</div><br/><div id="38598467" class="c"><input type="checkbox" id="c-38598467" checked=""/><div class="controls bullet"><span class="by">mobiuscog</span><span>|</span><a href="#38597522">root</a><span>|</span><a href="#38598158">parent</a><span>|</span><a href="#38597645">next</a><span>|</span><label class="collapse" for="c-38598467">[-]</label><label class="expand" for="c-38598467">[2 more]</label></div><br/><div class="children"><div class="content">&gt; I&#x27;m well aware that its marketing and I&#x27;d hope my comment makes that clear. The question is why oversell the product, and frankly by a lot.<p>Most marketing sells the dream, not the reality. There are just many shades of grey (although 50 tends to sell well).</div><br/><div id="38598523" class="c"><input type="checkbox" id="c-38598523" checked=""/><div class="controls bullet"><span class="by">godelski</span><span>|</span><a href="#38597522">root</a><span>|</span><a href="#38598467">parent</a><span>|</span><a href="#38597645">next</a><span>|</span><label class="collapse" for="c-38598523">[-]</label><label class="expand" for="c-38598523">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m still not sure how that is responding to my comment. Have I said something that makes me seem naive of the existence of snake oil salesmen? I&#x27;m actually operating under the assumption that my comment, and especially followup, explicitly demonstrate my awareness of this.</div><br/></div></div></div></div></div></div></div></div><div id="38597645" class="c"><input type="checkbox" id="c-38597645" checked=""/><div class="controls bullet"><span class="by">RagnarD</span><span>|</span><a href="#38597522">parent</a><span>|</span><a href="#38597859">prev</a><span>|</span><a href="#38597746">next</a><span>|</span><label class="collapse" for="c-38597645">[-]</label><label class="expand" for="c-38597645">[1 more]</label></div><br/><div class="children"><div class="content">Google screws up every business opportunity, including wantonly buying small successful businesses and killing them. Dishonesty is a fundamental part of the company.</div><br/></div></div><div id="38597746" class="c"><input type="checkbox" id="c-38597746" checked=""/><div class="controls bullet"><span class="by">parineum</span><span>|</span><a href="#38597522">parent</a><span>|</span><a href="#38597645">prev</a><span>|</span><a href="#38598732">next</a><span>|</span><label class="collapse" for="c-38597746">[-]</label><label class="expand" for="c-38597746">[1 more]</label></div><br/><div class="children"><div class="content">I think it&#x27;s because, while I think these LLMs are incredibly interesting and can be very useful, they&#x27;re less than what the hype is and the valuations are based on the hype.</div><br/></div></div></div></div><div id="38598732" class="c"><input type="checkbox" id="c-38598732" checked=""/><div class="controls bullet"><span class="by">iamleppert</span><span>|</span><a href="#38597522">prev</a><span>|</span><a href="#38597347">next</a><span>|</span><label class="collapse" for="c-38598732">[-]</label><label class="expand" for="c-38598732">[1 more]</label></div><br/><div class="children"><div class="content">I’ve recently been trying to actually use Google’s AI conversational translation app that was released awhile back and has many updates and iterations since.<p>It’s completely unusable for real conversation. I’m actually in a situation where I could benefit from it and was excited to use it because I remember watching the demo and how natural it looked but was never able to actually try it myself.<p>Now having used it, I went back and watched their original demo and I’m 100% convinced all or part of it was faked. There is just no way this thing ever worked. If they can’t manage to make conversational live translation work (which is a lot more useful than drawing a picture of a duck) I have high doubts about this new AI.<p>Seems like the exact same situation to me. It’s insane to me how much nerve it must take to completely fake something like this.</div><br/></div></div><div id="38597347" class="c"><input type="checkbox" id="c-38597347" checked=""/><div class="controls bullet"><span class="by">sheepscreek</span><span>|</span><a href="#38598732">prev</a><span>|</span><a href="#38597237">next</a><span>|</span><label class="collapse" for="c-38597347">[-]</label><label class="expand" for="c-38597347">[3 more]</label></div><br/><div class="children"><div class="content">Thank you for creating this demo. This was the point I was trying to make when the Gemini launch happened. All that hoopla for no reason.<p>Yes - GPT-4V is a beast. I’d even encourage anyone who cares about vision or multi-modality to give LLaVA a serious shot (<a href="https:&#x2F;&#x2F;github.com&#x2F;haotian-liu&#x2F;LLaVA">https:&#x2F;&#x2F;github.com&#x2F;haotian-liu&#x2F;LLaVA</a>). I have been playing with the 7B q5_k variant last couple of days and I am seriously impressed with it. Impressed enough to build a demo app&#x2F;proof-of-concept for my employer (will have to check the license first or I might only use it for the internal demo to drive a point).</div><br/><div id="38597361" class="c"><input type="checkbox" id="c-38597361" checked=""/><div class="controls bullet"><span class="by">ok_dad</span><span>|</span><a href="#38597347">parent</a><span>|</span><a href="#38597237">next</a><span>|</span><label class="collapse" for="c-38597361">[-]</label><label class="expand" for="c-38597361">[2 more]</label></div><br/><div class="children"><div class="content">I’ve been using llava via <a href="https:&#x2F;&#x2F;github.com&#x2F;Mozilla-Ocho&#x2F;llamafile">https:&#x2F;&#x2F;github.com&#x2F;Mozilla-Ocho&#x2F;llamafile</a> which runs on any modern system.</div><br/><div id="38598548" class="c"><input type="checkbox" id="c-38598548" checked=""/><div class="controls bullet"><span class="by">jart</span><span>|</span><a href="#38597347">root</a><span>|</span><a href="#38597361">parent</a><span>|</span><a href="#38597237">next</a><span>|</span><label class="collapse" for="c-38598548">[-]</label><label class="expand" for="c-38598548">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s so great. I&#x27;ve been this vision model to rename all the files in my Pictures folder. For example, the one-liner:<p><pre><code>    llamafile --temp 0 \
        --image ~&#x2F;Pictures&#x2F;lemurs.jpg \
        -m llava-v1.5-7b-Q4_K.gguf \
        --mmproj llava-v1.5-7b-mmproj-Q4_0.gguf \
        --grammar &#x27;root ::= [a-z]+ (&quot; &quot; [a-z]+)+&#x27; \
        -p $&#x27;### User: What do you see?\n### Assistant: &#x27; \
        --silent-prompt 2&gt;&#x2F;dev&#x2F;null |
      sed -e&#x27;s&#x2F; &#x2F;_&#x2F;&#x27; -e&#x27;s&#x2F;$&#x2F;.jpg&#x2F;&#x27;
</code></pre>
Prints to standard output:<p><pre><code>    a_baby_monkey_on_the_back_of_a_mother.jpg
</code></pre>
This is something that&#x27;s coming up in the next llamafile release. You have to build from source to have the ability to use grammar and --silent-prompt on a vision model right now.<p>Weights here: <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;jartine&#x2F;llava-v1.5-7B-GGUF&#x2F;tree&#x2F;main" rel="nofollow noreferrer">https:&#x2F;&#x2F;huggingface.co&#x2F;jartine&#x2F;llava-v1.5-7B-GGUF&#x2F;tree&#x2F;main</a><p>Sauce here: <a href="https:&#x2F;&#x2F;github.com&#x2F;mozilla-Ocho&#x2F;llamafile">https:&#x2F;&#x2F;github.com&#x2F;mozilla-Ocho&#x2F;llamafile</a></div><br/></div></div></div></div></div></div><div id="38597237" class="c"><input type="checkbox" id="c-38597237" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#38597347">prev</a><span>|</span><a href="#38597557">next</a><span>|</span><label class="collapse" for="c-38597237">[-]</label><label class="expand" for="c-38597237">[4 more]</label></div><br/><div class="children"><div class="content">haha yes it was entirely possible with gpt4v. literally just screenshot and feed in the images and text in chat format, aka “interleaved”. made something similar at a hackathon recently. (<a href="https:&#x2F;&#x2F;x.com&#x2F;swyx&#x2F;status&#x2F;1722662234680340823" rel="nofollow noreferrer">https:&#x2F;&#x2F;x.com&#x2F;swyx&#x2F;status&#x2F;1722662234680340823</a>). the bizarre thing is that google couldve done what you did, and we wouldve all been appropriately impressed, but instead google chose to make a misleading marketing video for the general public and leave the rest of us frustrated nerds to do the nasty work of having to explain why the technology isnt as seen on tv yet; making it seem somehow our fault<p>i am curious about the running costs of something like this</div><br/><div id="38597801" class="c"><input type="checkbox" id="c-38597801" checked=""/><div class="controls bullet"><span class="by">gregsadetsky</span><span>|</span><a href="#38597237">parent</a><span>|</span><a href="#38597557">next</a><span>|</span><label class="collapse" for="c-38597801">[-]</label><label class="expand" for="c-38597801">[3 more]</label></div><br/><div class="children"><div class="content">I made 77 requests to the GPT-vision API while developing&#x2F;demo&#x27;ing this, and that resulted in a $0.47 bill. Pretty reasonable!</div><br/><div id="38598476" class="c"><input type="checkbox" id="c-38598476" checked=""/><div class="controls bullet"><span class="by">jankovicsandras</span><span>|</span><a href="#38597237">root</a><span>|</span><a href="#38597801">parent</a><span>|</span><a href="#38597557">next</a><span>|</span><label class="collapse" for="c-38598476">[-]</label><label class="expand" for="c-38598476">[2 more]</label></div><br/><div class="children"><div class="content">Hi Greg,<p>Congratulations, great demo!
The $0.47 bill seems reasonable for an experiment, but imagine someone doing a task of this complexity as a daily job - let&#x27;s say 100x times, or a little more than 4 hours - the bill would be $47&#x2F;day. It feels like there&#x27;s still an opportunity for a cheaper solution. Have you or someone else experimented with e.g. <a href="https:&#x2F;&#x2F;localai.io&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;localai.io&#x2F;</a> ?</div><br/><div id="38598507" class="c"><input type="checkbox" id="c-38598507" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#38597237">root</a><span>|</span><a href="#38598476">parent</a><span>|</span><a href="#38597557">next</a><span>|</span><label class="collapse" for="c-38598507">[-]</label><label class="expand" for="c-38598507">[1 more]</label></div><br/><div class="children"><div class="content">if i did not have your comment history i&#x27;d have sworn you worked for localai.io</div><br/></div></div></div></div></div></div></div></div><div id="38597557" class="c"><input type="checkbox" id="c-38597557" checked=""/><div class="controls bullet"><span class="by">adtac</span><span>|</span><a href="#38597237">prev</a><span>|</span><a href="#38597350">next</a><span>|</span><label class="collapse" for="c-38597557">[-]</label><label class="expand" for="c-38597557">[3 more]</label></div><br/><div class="children"><div class="content">[tangential to this really cool demo] JPEG images being the only possible interface to GPT-4 feels wasteful. the human eye works the delta between &quot;frames&quot;, not the image itself. I wonder if the next big step that would allow real-time video processing at high resolutions is to have the model&#x27;s internal state operate on keyframes and deltas similar to how video codecs like MPEG work.</div><br/><div id="38597618" class="c"><input type="checkbox" id="c-38597618" checked=""/><div class="controls bullet"><span class="by">zwily</span><span>|</span><a href="#38597557">parent</a><span>|</span><a href="#38597350">next</a><span>|</span><label class="collapse" for="c-38597618">[-]</label><label class="expand" for="c-38597618">[2 more]</label></div><br/><div class="children"><div class="content">When Google talks about Gemini&#x27;s &quot;multi-modal&quot;, they include &quot;video&quot; in the list of modes. It&#x27;s totally possible they don&#x27;t actually mean video, and just mean frames like in this demo. They haven&#x27;t elaborated on it anywhere that I&#x27;ve seen.</div><br/><div id="38598174" class="c"><input type="checkbox" id="c-38598174" checked=""/><div class="controls bullet"><span class="by">dannyw</span><span>|</span><a href="#38597557">root</a><span>|</span><a href="#38597618">parent</a><span>|</span><a href="#38597350">next</a><span>|</span><label class="collapse" for="c-38598174">[-]</label><label class="expand" for="c-38598174">[1 more]</label></div><br/><div class="children"><div class="content">Their technical report clarifies that video is just a sequence of frames fed as images.</div><br/></div></div></div></div></div></div><div id="38597350" class="c"><input type="checkbox" id="c-38597350" checked=""/><div class="controls bullet"><span class="by">dvaun</span><span>|</span><a href="#38597557">prev</a><span>|</span><a href="#38597573">next</a><span>|</span><label class="collapse" for="c-38597350">[-]</label><label class="expand" for="c-38597350">[1 more]</label></div><br/><div class="children"><div class="content">Great demo, I laughed at the final GPT response too.<p>Honestly: it would be fun to self-host some code hooked up to a mic and speakers to let kids, or whoever, play around with GPT4. I’m thinking of doing this on my own under an agency[0] I’m starting up on the side. Seems like a no-brainer as an application.<p>[0]: <a href="https:&#x2F;&#x2F;www.divinatetech.com" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.divinatetech.com</a></div><br/></div></div><div id="38597573" class="c"><input type="checkbox" id="c-38597573" checked=""/><div class="controls bullet"><span class="by">sibeliuss</span><span>|</span><a href="#38597350">prev</a><span>|</span><a href="#38597247">next</a><span>|</span><label class="collapse" for="c-38597573">[-]</label><label class="expand" for="c-38597573">[2 more]</label></div><br/><div class="children"><div class="content">Lol at choosing the name Sagittarius, which is exactly across from Gemini in the Zodiac</div><br/><div id="38597634" class="c"><input type="checkbox" id="c-38597634" checked=""/><div class="controls bullet"><span class="by">SilasX</span><span>|</span><a href="#38597573">parent</a><span>|</span><a href="#38597247">next</a><span>|</span><label class="collapse" for="c-38597634">[-]</label><label class="expand" for="c-38597634">[1 more]</label></div><br/><div class="children"><div class="content">I remember there was speculation that Facebook named their vaporware cryptocurrency Libra (later, “Diem”) as a jab at the longtime rival Winklevoss twins, who had started a crypto exchange called Gemini. I have no idea how astrologically clever that would be.</div><br/></div></div></div></div><div id="38597247" class="c"><input type="checkbox" id="c-38597247" checked=""/><div class="controls bullet"><span class="by">zainhoda</span><span>|</span><a href="#38597573">prev</a><span>|</span><a href="#38597264">next</a><span>|</span><label class="collapse" for="c-38597247">[-]</label><label class="expand" for="c-38597247">[1 more]</label></div><br/><div class="children"><div class="content">Wow, this is super cool! From the code it seems like the speech to text and text to speech are using the browser’s built-in features. I always forget those capabilities even exist!</div><br/></div></div><div id="38597264" class="c"><input type="checkbox" id="c-38597264" checked=""/><div class="controls bullet"><span class="by">iandanforth</span><span>|</span><a href="#38597247">prev</a><span>|</span><a href="#38597320">next</a><span>|</span><label class="collapse" for="c-38597264">[-]</label><label class="expand" for="c-38597264">[10 more]</label></div><br/><div class="children"><div class="content">Looks like, again, this doesn&#x27;t have GPT-4 processing video as much as a stack of video frames, concatenated and sent as a single image. But much closer to real!</div><br/><div id="38597529" class="c"><input type="checkbox" id="c-38597529" checked=""/><div class="controls bullet"><span class="by">riwsky</span><span>|</span><a href="#38597264">parent</a><span>|</span><a href="#38597344">next</a><span>|</span><label class="collapse" for="c-38597529">[-]</label><label class="expand" for="c-38597529">[2 more]</label></div><br/><div class="children"><div class="content">I just found out it gets worse: turns out GPT-4 isn&#x27;t processing images so much as arrays of pixels!<p>And worse: turns out GPT-4 isn&#x27;t processing pixels so much as integers representing in a position in some color space like RGB!<p>And worse! turns out GPT-4 isn&#x27;t processing integers so much as series of ones and zeroes!<p>Now that this is public knowledge, I&#x27;m willing to bet this was the ugly &quot;less than candid&quot; truth that the board sacked Sam Altman over.</div><br/><div id="38597685" class="c"><input type="checkbox" id="c-38597685" checked=""/><div class="controls bullet"><span class="by">zarzavat</span><span>|</span><a href="#38597264">root</a><span>|</span><a href="#38597529">parent</a><span>|</span><a href="#38597344">next</a><span>|</span><label class="collapse" for="c-38597685">[-]</label><label class="expand" for="c-38597685">[1 more]</label></div><br/><div class="children"><div class="content">As they say, quantity has a quality all of its own. If the framerate of a video is so slow as to be a slideshow, then it’s arguably not video anymore. Video has a connotation of appearing temporally continuous to the naked eye.</div><br/></div></div></div></div><div id="38597344" class="c"><input type="checkbox" id="c-38597344" checked=""/><div class="controls bullet"><span class="by">trescenzi</span><span>|</span><a href="#38597264">parent</a><span>|</span><a href="#38597529">prev</a><span>|</span><a href="#38597479">next</a><span>|</span><label class="collapse" for="c-38597344">[-]</label><label class="expand" for="c-38597344">[3 more]</label></div><br/><div class="children"><div class="content">How does a video differ from a stack of video frames? Isn’t that all a video is? A bunch of images stuck together and played back quickly?</div><br/><div id="38597393" class="c"><input type="checkbox" id="c-38597393" checked=""/><div class="controls bullet"><span class="by">og_kalu</span><span>|</span><a href="#38597264">root</a><span>|</span><a href="#38597344">parent</a><span>|</span><a href="#38597628">next</a><span>|</span><label class="collapse" for="c-38597393">[-]</label><label class="expand" for="c-38597393">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;d guess you&#x27;d miss any audio that way. But otherwise, yeah a video is a stack of images.</div><br/></div></div><div id="38597628" class="c"><input type="checkbox" id="c-38597628" checked=""/><div class="controls bullet"><span class="by">zwily</span><span>|</span><a href="#38597264">root</a><span>|</span><a href="#38597344">parent</a><span>|</span><a href="#38597393">prev</a><span>|</span><a href="#38597479">next</a><span>|</span><label class="collapse" for="c-38597628">[-]</label><label class="expand" for="c-38597628">[1 more]</label></div><br/><div class="children"><div class="content">You could say that this demo is processing a 2.4s video that is 1.25fps.</div><br/></div></div></div></div><div id="38597479" class="c"><input type="checkbox" id="c-38597479" checked=""/><div class="controls bullet"><span class="by">adtac</span><span>|</span><a href="#38597264">parent</a><span>|</span><a href="#38597344">prev</a><span>|</span><a href="#38597450">next</a><span>|</span><label class="collapse" for="c-38597479">[-]</label><label class="expand" for="c-38597479">[2 more]</label></div><br/><div class="children"><div class="content">Is &quot;it&#x27;s just processing frames&quot; the new &quot;it&#x27;s just predicting the next token&quot;?</div><br/><div id="38598566" class="c"><input type="checkbox" id="c-38598566" checked=""/><div class="controls bullet"><span class="by">topspin</span><span>|</span><a href="#38597264">root</a><span>|</span><a href="#38597479">parent</a><span>|</span><a href="#38597450">next</a><span>|</span><label class="collapse" for="c-38598566">[-]</label><label class="expand" for="c-38598566">[1 more]</label></div><br/><div class="children"><div class="content">Nothing new here at all: trivializing the intellectual achievements of machines is SOP.  This will continue until machines have surpassed every conceivable benchmark.  At that point we&#x27;ll be left with only our epic hubris.</div><br/></div></div></div></div><div id="38597450" class="c"><input type="checkbox" id="c-38597450" checked=""/><div class="controls bullet"><span class="by">fortunefox</span><span>|</span><a href="#38597264">parent</a><span>|</span><a href="#38597479">prev</a><span>|</span><a href="#38597329">next</a><span>|</span><label class="collapse" for="c-38597450">[-]</label><label class="expand" for="c-38597450">[1 more]</label></div><br/><div class="children"><div class="content">Since audio is processed separately this isn&#x27;t just close to real. it is real.
After all what is video if not a stack of frames! :D</div><br/></div></div><div id="38597329" class="c"><input type="checkbox" id="c-38597329" checked=""/><div class="controls bullet"><span class="by">ShamelessC</span><span>|</span><a href="#38597264">parent</a><span>|</span><a href="#38597450">prev</a><span>|</span><a href="#38597320">next</a><span>|</span><label class="collapse" for="c-38597329">[-]</label><label class="expand" for="c-38597329">[1 more]</label></div><br/><div class="children"><div class="content">The video is an actual live demo without any editing or other tricks involved and even includes reasonable mistakes and the code used. It is not close to real, it&#x27;s just real.</div><br/></div></div></div></div><div id="38597320" class="c"><input type="checkbox" id="c-38597320" checked=""/><div class="controls bullet"><span class="by">ShamelessC</span><span>|</span><a href="#38597264">prev</a><span>|</span><a href="#38597223">next</a><span>|</span><label class="collapse" for="c-38597320">[-]</label><label class="expand" for="c-38597320">[2 more]</label></div><br/><div class="children"><div class="content">Sad state of affairs for Google.</div><br/><div id="38597341" class="c"><input type="checkbox" id="c-38597341" checked=""/><div class="controls bullet"><span class="by">paul7986</span><span>|</span><a href="#38597320">parent</a><span>|</span><a href="#38597223">next</a><span>|</span><label class="collapse" for="c-38597341">[-]</label><label class="expand" for="c-38597341">[1 more]</label></div><br/><div class="children"><div class="content">Indeed they&#x27;ve been sad starting in 2010 and on... (maybe before)... all the projects they kill.. their IP theft, them doing evil, etc</div><br/></div></div></div></div><div id="38597223" class="c"><input type="checkbox" id="c-38597223" checked=""/><div class="controls bullet"><span class="by">op00to</span><span>|</span><a href="#38597320">prev</a><span>|</span><a href="#38597359">next</a><span>|</span><label class="collapse" for="c-38597223">[-]</label><label class="expand" for="c-38597223">[1 more]</label></div><br/><div class="children"><div class="content">Very cool!</div><br/></div></div><div id="38597359" class="c"><input type="checkbox" id="c-38597359" checked=""/><div class="controls bullet"><span class="by">jakderrida</span><span>|</span><a href="#38597223">prev</a><span>|</span><a href="#38597289">next</a><span>|</span><label class="collapse" for="c-38597359">[-]</label><label class="expand" for="c-38597359">[1 more]</label></div><br/><div class="children"><div class="content">Lmao! So, presumably, they could have hired Greg to improvise almost the exact same demonstration, but with evidence it works. I don&#x27;t know how much Greg costs, but I&#x27;ll bet my ass it&#x27;s less than the cost in investor sentiment after getting caught committing fraud. Not saying you&#x27;re cheap. Just cheaper.</div><br/></div></div></div></div></div></div></div></body></html>