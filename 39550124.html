<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1709283672982" as="style"/><link rel="stylesheet" href="styles.css?v=1709283672982"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://ferrous-systems.com/blog/lock-free-ring-buffer/">A lock-free ring-buffer with contiguous reservations (2019)</a>Â <span class="domain">(<a href="https://ferrous-systems.com">ferrous-systems.com</a>)</span></div><div class="subtext"><span>simonpure</span> | <span>100 comments</span></div><br/><div><div id="39550776" class="c"><input type="checkbox" id="c-39550776" checked=""/><div class="controls bullet"><span class="by">jamesmunns</span><span>|</span><a href="#39551465">next</a><span>|</span><label class="collapse" for="c-39550776">[-]</label><label class="expand" for="c-39550776">[16 more]</label></div><br/><div class="children"><div class="content">Oh hey, one of the authors of this post here (James), happy to answer any questions.<p>This post has been discussed here a couple times, but AMA :)<p>edit, the most commented version of this post was the original:<p><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=20096946">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=20096946</a>.<p>This is what I&#x27;m up to these days:<p><a href="https:&#x2F;&#x2F;onevariable.com&#x2F;" rel="nofollow">https:&#x2F;&#x2F;onevariable.com&#x2F;</a></div><br/><div id="39559886" class="c"><input type="checkbox" id="c-39559886" checked=""/><div class="controls bullet"><span class="by">cangeroo</span><span>|</span><a href="#39550776">parent</a><span>|</span><a href="#39551057">next</a><span>|</span><label class="collapse" for="c-39559886">[-]</label><label class="expand" for="c-39559886">[1 more]</label></div><br/><div class="children"><div class="content">ELI5?<p>I see a lot of critique in the previous (2019) thread, but no summary in key points. What are the reasons that this is hard?<p>In multiprocessor systems, are memory writes not guaranteed to be sequential? e.g. can data be written out-of-order, after the synchronization bit is written?<p>Or is it more about the use case, that it is optimized for minimal number of instructions, e.g. avoiding additional memory reads? (e.g. by writing data to the buffer, instead writing storing pointers)?<p>Or is it that you&#x27;re trying to use constant memory (irrespective of number of threads)?<p>Because to me, it seems like a trivial problem to solve, if you have sequential writes, store data separately from the queue, and may linearly scale memory with number of threads.</div><br/></div></div><div id="39551057" class="c"><input type="checkbox" id="c-39551057" checked=""/><div class="controls bullet"><span class="by">agentultra</span><span>|</span><a href="#39550776">parent</a><span>|</span><a href="#39559886">prev</a><span>|</span><a href="#39552099">next</a><span>|</span><label class="collapse" for="c-39551057">[-]</label><label class="expand" for="c-39551057">[3 more]</label></div><br/><div class="children"><div class="content">Has there been a formal specification&#x2F;model that we can check? I love circular buffers but I&#x27;m curious how we know that the design is correct with respect to the stated properties.<p>I did a bit of link diving to the various blog posts and sites but haven&#x27;t been able to find it. Would be nice, if it exists, to have it front and centre.</div><br/><div id="39551140" class="c"><input type="checkbox" id="c-39551140" checked=""/><div class="controls bullet"><span class="by">jamesmunns</span><span>|</span><a href="#39550776">root</a><span>|</span><a href="#39551057">parent</a><span>|</span><a href="#39552099">next</a><span>|</span><label class="collapse" for="c-39551140">[-]</label><label class="expand" for="c-39551140">[2 more]</label></div><br/><div class="children"><div class="content">As far as I know, it hasn&#x27;t been formally verified.<p>Andrea Lattuada (<a href="https:&#x2F;&#x2F;andrea.lattuada.me&#x2F;" rel="nofollow">https:&#x2F;&#x2F;andrea.lattuada.me&#x2F;</a>) is more likely to have done work in his implementation of the algorithm than I did on mine.<p>I have run the testing with various dynamic analysis tools, but for sure this isn&#x27;t formal verification. If someone is interested in doing it, happy to chat with them!</div><br/><div id="39556190" class="c"><input type="checkbox" id="c-39556190" checked=""/><div class="controls bullet"><span class="by">anonymousDan</span><span>|</span><a href="#39550776">root</a><span>|</span><a href="#39551140">parent</a><span>|</span><a href="#39552099">next</a><span>|</span><label class="collapse" for="c-39556190">[-]</label><label class="expand" for="c-39556190">[1 more]</label></div><br/><div class="children"><div class="content">Shouldn&#x27;t be that hard to at least model check it in TLA+ I would have thought (albeit potentially more complex if trying to account for weak memory).</div><br/></div></div></div></div></div></div><div id="39552099" class="c"><input type="checkbox" id="c-39552099" checked=""/><div class="controls bullet"><span class="by">Fiahil</span><span>|</span><a href="#39550776">parent</a><span>|</span><a href="#39551057">prev</a><span>|</span><a href="#39558468">next</a><span>|</span><label class="collapse" for="c-39552099">[-]</label><label class="expand" for="c-39552099">[5 more]</label></div><br/><div class="children"><div class="content">I used the same approach while designing a lock-free bounded broadcast log (as in a &quot;RWLock&lt;Vec&lt;T&gt;&gt;&quot;; a MCMP, append-only Vec). It&#x27;s quite easy to do because it&#x27;s bounded. However, I could not find a way to make it both unbounded and efficient.<p>Any ideas ?</div><br/><div id="39558907" class="c"><input type="checkbox" id="c-39558907" checked=""/><div class="controls bullet"><span class="by">duped</span><span>|</span><a href="#39550776">root</a><span>|</span><a href="#39552099">parent</a><span>|</span><a href="#39557750">next</a><span>|</span><label class="collapse" for="c-39558907">[-]</label><label class="expand" for="c-39558907">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s very hard to beat locking when the queue needs grow. It&#x27;s the performance statistics - you&#x27;re going to grow more often as the app warms up, reach a steady state, and only need to grow under heavier than expected load. And in that case you probably aren&#x27;t going to see performance dominated by time spent waiting to acquire a write lock.<p>The alternative is to dive into the literature on lock-free mpmc queues, which are kind of gnarly to implement. A lot of the literature handwaves ABA problems with stuff like &quot;use hazard pointers and RCU&quot; without correct pseudo code to help you.<p>That&#x27;s why locking in unbounded queues is popular, imo. It&#x27;s not actually inefficient, and the alternatives are arcane enough to avoid. No one is going to understand or trust the code anyway.<p>It&#x27;s worth mentioning that &quot;lock free&quot; means &quot;one task does not prevent other tasks from making progress&quot; and in the case of a bounded queue, you can trivially accomplish that by busy-waiting when the queue is full. This isn&#x27;t appropriate if you need consumers to receive events in the order in which they happen, but you can kind of fix that using an atomic counter (to paraphrase Mike Acton, if you have a safe counter, you have a safe queue) and time stamp events&#x2F;sort on which ones are consumed.</div><br/></div></div><div id="39557750" class="c"><input type="checkbox" id="c-39557750" checked=""/><div class="controls bullet"><span class="by">jayshua</span><span>|</span><a href="#39550776">root</a><span>|</span><a href="#39552099">parent</a><span>|</span><a href="#39558907">prev</a><span>|</span><a href="#39553758">next</a><span>|</span><label class="collapse" for="c-39557750">[-]</label><label class="expand" for="c-39557750">[1 more]</label></div><br/><div class="children"><div class="content">Not sure if it could be extended here, but I&#x27;ve seen a lock free hash map that supported lock free reallocation by allocating new space and moving each entry one by one, either when the entry is accessed or in a separate thread concurrently. Accessing an entry during the reallocation would check the new region first, and if not found check the old region. Entries in the old region would be marked as moved and once all entries were moved the old allocation could be freed.</div><br/></div></div><div id="39553758" class="c"><input type="checkbox" id="c-39553758" checked=""/><div class="controls bullet"><span class="by">paholg</span><span>|</span><a href="#39550776">root</a><span>|</span><a href="#39552099">parent</a><span>|</span><a href="#39557750">prev</a><span>|</span><a href="#39552221">next</a><span>|</span><label class="collapse" for="c-39553758">[-]</label><label class="expand" for="c-39553758">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m no expert here, but I wonder if a linked list of bounded logs would work well.<p>So, everyone has a pointer to the current one, and there&#x27;s an atomic pointer to the next.<p>When the log fills up, you allocate a new one and set the next pointer to it using compare_and_swap. If someone beat you to it, you can walk the list and add yours to the end so that the allocation isn&#x27;t wasted.<p>This way, most of the time you&#x27;re using the efficient bounded log.</div><br/></div></div><div id="39552221" class="c"><input type="checkbox" id="c-39552221" checked=""/><div class="controls bullet"><span class="by">jamesmunns</span><span>|</span><a href="#39550776">root</a><span>|</span><a href="#39552099">parent</a><span>|</span><a href="#39553758">prev</a><span>|</span><a href="#39558468">next</a><span>|</span><label class="collapse" for="c-39552221">[-]</label><label class="expand" for="c-39552221">[1 more]</label></div><br/><div class="children"><div class="content">I am not sure! Most of the data structures I design are for embedded systems without allocators. On the desktop, I mostly defer to others.<p>I&#x27;ve used tokio&#x27;s broadcast channel quite a bit before, but it is also bounded. After talking to Eliza from the tokio project, I&#x27;m fairly convinced that unbounded queues are a scary thing to have around, operationally :).<p>But again - this is a bit out of my actual expertise!</div><br/></div></div></div></div><div id="39558468" class="c"><input type="checkbox" id="c-39558468" checked=""/><div class="controls bullet"><span class="by">SergeAx</span><span>|</span><a href="#39550776">parent</a><span>|</span><a href="#39552099">prev</a><span>|</span><a href="#39551465">next</a><span>|</span><label class="collapse" for="c-39558468">[-]</label><label class="expand" for="c-39558468">[6 more]</label></div><br/><div class="children"><div class="content">Please excuse me if my question is dumb, I have little understanding of Rust. You declaring your implementation &quot;lock-free&quot;, but are using Atomic* Rust primitives at the same time. Those are using CPU atomic instructions, if I googled correctly. Those, in their turn, are using CPU locking mechanism. Turns out that you just shifted locking from language to CPU, right?</div><br/><div id="39558720" class="c"><input type="checkbox" id="c-39558720" checked=""/><div class="controls bullet"><span class="by">DannyBee</span><span>|</span><a href="#39550776">root</a><span>|</span><a href="#39558468">parent</a><span>|</span><a href="#39558502">next</a><span>|</span><label class="collapse" for="c-39558720">[-]</label><label class="expand" for="c-39558720">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a reasonable question, because lock-free is a confusing term.<p>Lock-free here does not mean &quot;without any form of synchronization primitive&quot;. That is impossible.  Some synchronization must occur.<p>Instead, it is a term of art that means:<p>1. Thread failure can&#x27;t cause other threads to get blocked.
2. Forward progress in the algorithm is guaranteed.<p>Basically:  threads can&#x27;t block each other and death of threads does not screw things up.<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Non-blocking_algorithm" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Non-blocking_algorithm</a><p>CPU atomics often work by blocking (they have to) but they are non-interruptible instructions and there is a fixed maximum execution time.<p>(So you can still guarantee forward progress if you use them).</div><br/></div></div><div id="39558502" class="c"><input type="checkbox" id="c-39558502" checked=""/><div class="controls bullet"><span class="by">mrcode007</span><span>|</span><a href="#39550776">root</a><span>|</span><a href="#39558468">parent</a><span>|</span><a href="#39558720">prev</a><span>|</span><a href="#39551465">next</a><span>|</span><label class="collapse" for="c-39558502">[-]</label><label class="expand" for="c-39558502">[4 more]</label></div><br/><div class="children"><div class="content">Yes, this is correct and the most overlooked aspect and reason for the misnomer. Atomics imply locking at the cpu. Depending on the CPU the lock happens either for the entire memory bus (pre Intel P6 on x86) or as part of snoop disable bits on relevant cache lines in the snooping protocol</div><br/><div id="39558728" class="c"><input type="checkbox" id="c-39558728" checked=""/><div class="controls bullet"><span class="by">DannyBee</span><span>|</span><a href="#39550776">root</a><span>|</span><a href="#39558502">parent</a><span>|</span><a href="#39551465">next</a><span>|</span><label class="collapse" for="c-39558728">[-]</label><label class="expand" for="c-39558728">[3 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not a misnomer, it&#x27;s just a bad term of art.  When it was coined folks were well aware that atomics locked at the CPU level.</div><br/><div id="39558989" class="c"><input type="checkbox" id="c-39558989" checked=""/><div class="controls bullet"><span class="by">mrcode007</span><span>|</span><a href="#39550776">root</a><span>|</span><a href="#39558728">parent</a><span>|</span><a href="#39551465">next</a><span>|</span><label class="collapse" for="c-39558989">[-]</label><label class="expand" for="c-39558989">[2 more]</label></div><br/><div class="children"><div class="content">âIn discussing the question, he used to liken the case to that of the boy who, when asked how many legs his calf would have if he called its tail a leg, replied, â Five,â to which the prompt response was made that calling the tail a leg would not make it a leg.â</div><br/></div></div></div></div></div></div></div></div></div></div><div id="39551465" class="c"><input type="checkbox" id="c-39551465" checked=""/><div class="controls bullet"><span class="by">loeg</span><span>|</span><a href="#39550776">prev</a><span>|</span><a href="#39551661">next</a><span>|</span><label class="collapse" for="c-39551465">[-]</label><label class="expand" for="c-39551465">[32 more]</label></div><br/><div class="children"><div class="content">&gt; The safe thing to do here is to always choose Ordering::SeqCst, &quot;sequential consistency&quot;, which provides the strongest guarantees. ... This is often good enough in practice, and switching to a weaker Ordering is only necessary to squeeze out the last bit of performance.<p>If you&#x27;re going to write lock-free algorithms using atomics, the least you can do is learn about ordering semantics and use the correct abstract semantics for your design&#x27;s actual needs.  It is much easier to do it at design time than to try to figure out if it is safe to relax SeqCst later.  (This is one of the major flaws of C++ std::atomic&#x27;s default SeqCst semantics.)  If you aren&#x27;t going to bother understanding ordering semantics, it is unlikely you can write a safe lock-free algorithm anyway. (It&#x27;s really hard to do!)</div><br/><div id="39552243" class="c"><input type="checkbox" id="c-39552243" checked=""/><div class="controls bullet"><span class="by">jamesmunns</span><span>|</span><a href="#39551465">parent</a><span>|</span><a href="#39552324">next</a><span>|</span><label class="collapse" for="c-39552243">[-]</label><label class="expand" for="c-39552243">[13 more]</label></div><br/><div class="children"><div class="content">Back then, there weren&#x27;t as good references for explaining atomic ordering, and the blog post had gotten long enough. Mentioning SeqCst was a bit of a cop out, though both Andrea and I didn&#x27;t end up using SeqCst past the inital impl anyway.<p>Today I would have just linked to <a href="https:&#x2F;&#x2F;marabos.nl&#x2F;atomics&#x2F;" rel="nofollow">https:&#x2F;&#x2F;marabos.nl&#x2F;atomics&#x2F;</a>, Mara does a much better job of explaining atomics than I could have then or now.</div><br/><div id="39553095" class="c"><input type="checkbox" id="c-39553095" checked=""/><div class="controls bullet"><span class="by">hinkley</span><span>|</span><a href="#39551465">root</a><span>|</span><a href="#39552243">parent</a><span>|</span><a href="#39552324">next</a><span>|</span><label class="collapse" for="c-39553095">[-]</label><label class="expand" for="c-39553095">[12 more]</label></div><br/><div class="children"><div class="content">Back then? Do you mean 2019? Or a different âthenâ? Because there was plenty of material in CS about this subject even in 2010. Java was wrestling with this twenty years ago, and databases long before that.</div><br/><div id="39553777" class="c"><input type="checkbox" id="c-39553777" checked=""/><div class="controls bullet"><span class="by">anonymous-panda</span><span>|</span><a href="#39551465">root</a><span>|</span><a href="#39553095">parent</a><span>|</span><a href="#39553249">next</a><span>|</span><label class="collapse" for="c-39553777">[-]</label><label class="expand" for="c-39553777">[10 more]</label></div><br/><div class="children"><div class="content">I think the hard part of it is that x86 only has one atomic ordering and none of the other modes do anything. As such, itâs really hard to build intuition about it unless you spend a lot of time writing such code on ARM which wasnât that common in the industry and today most people use higher level abstractions.<p>By databases, do you mean those running on DEC Alphas? Cause that was a niche system that few would have had experience with. If you meant to compare in terms if consistency semantically, sure but thereâs meaningful differences between database consistency semantics of concurrent transactions and atomic ordering in a multithreaded concept.<p>Javaâs memory model âwrestlingâ was about defining it formally in an era of multithreading and itâs largely sequentially consistent - no weakly consistent ordering allowed.<p>The c++ memory model was definitely the first large scale adoption of weaker consistency models Iâm aware of and was done so that ARM CPUs could be properly optimized for since this was c++11 when mobile CPUs were very much front of mind. Weak consistency remains really difficult to reason about and even harder to play around with if you primarily work with x86 and thereâs very little tooling around to validate that can help you get confidence about whether your code is correct. Of course, you can follow common âpatternsâ (eg loads are always acquire and stores are release), but fully grokking correctness and being able to play with the model in interesting ways is no small task no matter how many learning resources are out there.</div><br/><div id="39554018" class="c"><input type="checkbox" id="c-39554018" checked=""/><div class="controls bullet"><span class="by">gpderetta</span><span>|</span><a href="#39551465">root</a><span>|</span><a href="#39553777">parent</a><span>|</span><a href="#39554592">next</a><span>|</span><label class="collapse" for="c-39554018">[-]</label><label class="expand" for="c-39554018">[6 more]</label></div><br/><div class="children"><div class="content">Nit: x86 has acquire&#x2F;release and seq_cst for load&#x2F;stores (it technically also has relaxed, but it is not useful to map it to c++11 relaxed). What x86 lacks is weaker ordering for RMW, but there are a lot of useful lock free algorithms that are implementable just or mostly with load and stores and it can be a significant win to use non-seq-cst stores for this on x86</div><br/><div id="39558169" class="c"><input type="checkbox" id="c-39558169" checked=""/><div class="controls bullet"><span class="by">vlovich123</span><span>|</span><a href="#39551465">root</a><span>|</span><a href="#39554018">parent</a><span>|</span><a href="#39554224">next</a><span>|</span><label class="collapse" for="c-39558169">[-]</label><label class="expand" for="c-39558169">[2 more]</label></div><br/><div class="children"><div class="content">I would have to imagine you mean x86-64 right? I would imagine 32bit x86 doesnât have those instructions?<p>Iâm also kind of curious if a lot of modern code compiled to x86 would see consistency issues running on old CPUs before TSO was formalized (like a p2 multiprocessor server).</div><br/><div id="39558494" class="c"><input type="checkbox" id="c-39558494" checked=""/><div class="controls bullet"><span class="by">loeg</span><span>|</span><a href="#39551465">root</a><span>|</span><a href="#39558169">parent</a><span>|</span><a href="#39554224">next</a><span>|</span><label class="collapse" for="c-39558494">[-]</label><label class="expand" for="c-39558494">[1 more]</label></div><br/><div class="children"><div class="content">32-bit x86 has many of the same instructions, including cmpxchg8b (in models dating to the 90s).</div><br/></div></div></div></div><div id="39554224" class="c"><input type="checkbox" id="c-39554224" checked=""/><div class="controls bullet"><span class="by">haberman</span><span>|</span><a href="#39551465">root</a><span>|</span><a href="#39554018">parent</a><span>|</span><a href="#39558169">prev</a><span>|</span><a href="#39554592">next</a><span>|</span><label class="collapse" for="c-39554224">[-]</label><label class="expand" for="c-39554224">[3 more]</label></div><br/><div class="children"><div class="content">Indeed there is different code generated by seq_cst for stores.  Though for loads it appears to be the same: <a href="https:&#x2F;&#x2F;godbolt.org&#x2F;z&#x2F;WbvEcM83q" rel="nofollow">https:&#x2F;&#x2F;godbolt.org&#x2F;z&#x2F;WbvEcM83q</a></div><br/><div id="39558507" class="c"><input type="checkbox" id="c-39558507" checked=""/><div class="controls bullet"><span class="by">loeg</span><span>|</span><a href="#39551465">root</a><span>|</span><a href="#39554224">parent</a><span>|</span><a href="#39554418">next</a><span>|</span><label class="collapse" for="c-39558507">[-]</label><label class="expand" for="c-39558507">[1 more]</label></div><br/><div class="children"><div class="content">Re: the godbolt example, note that release semantics are not meaningful for load operations.<p>&gt; If order is one of std::memory_order_release and std::memory_order_acq_rel, the behavior is undefined.<p><a href="https:&#x2F;&#x2F;en.cppreference.com&#x2F;w&#x2F;cpp&#x2F;atomic&#x2F;atomic&#x2F;load" rel="nofollow">https:&#x2F;&#x2F;en.cppreference.com&#x2F;w&#x2F;cpp&#x2F;atomic&#x2F;atomic&#x2F;load</a></div><br/></div></div><div id="39554418" class="c"><input type="checkbox" id="c-39554418" checked=""/><div class="controls bullet"><span class="by">gpderetta</span><span>|</span><a href="#39551465">root</a><span>|</span><a href="#39554224">parent</a><span>|</span><a href="#39558507">prev</a><span>|</span><a href="#39554592">next</a><span>|</span><label class="collapse" for="c-39554418">[-]</label><label class="expand" for="c-39554418">[1 more]</label></div><br/><div class="children"><div class="content">Yes, seqcst loads map to plain loads on x86.</div><br/></div></div></div></div></div></div><div id="39554592" class="c"><input type="checkbox" id="c-39554592" checked=""/><div class="controls bullet"><span class="by">foobiekr</span><span>|</span><a href="#39551465">root</a><span>|</span><a href="#39553777">parent</a><span>|</span><a href="#39554018">prev</a><span>|</span><a href="#39553249">next</a><span>|</span><label class="collapse" for="c-39554592">[-]</label><label class="expand" for="c-39554592">[3 more]</label></div><br/><div class="children"><div class="content">X86 might but devices connected to it in embedded world have had to be very very aware of this stuff since the 90s.</div><br/><div id="39558124" class="c"><input type="checkbox" id="c-39558124" checked=""/><div class="controls bullet"><span class="by">vlovich123</span><span>|</span><a href="#39551465">root</a><span>|</span><a href="#39554592">parent</a><span>|</span><a href="#39553249">next</a><span>|</span><label class="collapse" for="c-39558124">[-]</label><label class="expand" for="c-39558124">[2 more]</label></div><br/><div class="children"><div class="content">Embedded devices did not necessarily use the c++ memory model, and definitely not in the 90s and were highly likely in order CPUs to boot with no crazy compilers and thus atomics didnât matter too much anyway (volatile was sufficient). They had a weaker memory model maybe but at the same time multi threading on embedded did not really exist as it was only being introduced into the industry with any real seriousness around that time (threading on Linux started to shake out around the mid 90s).</div><br/><div id="39558411" class="c"><input type="checkbox" id="c-39558411" checked=""/><div class="controls bullet"><span class="by">foobiekr</span><span>|</span><a href="#39551465">root</a><span>|</span><a href="#39558124">parent</a><span>|</span><a href="#39553249">next</a><span>|</span><label class="collapse" for="c-39558411">[-]</label><label class="expand" for="c-39558411">[1 more]</label></div><br/><div class="children"><div class="content">SMP systems were widely in use in the 1990s, but youâre correct the dual core MIPS was 2003ish in emedded.</div><br/></div></div></div></div></div></div></div></div><div id="39553249" class="c"><input type="checkbox" id="c-39553249" checked=""/><div class="controls bullet"><span class="by">jamesmunns</span><span>|</span><a href="#39551465">root</a><span>|</span><a href="#39553095">parent</a><span>|</span><a href="#39553777">prev</a><span>|</span><a href="#39552324">next</a><span>|</span><label class="collapse" for="c-39553249">[-]</label><label class="expand" for="c-39553249">[1 more]</label></div><br/><div class="children"><div class="content">I meant 2019, and there weren&#x27;t any materials that I would consider as clear and well defined as Mara&#x27;s linked docs explaining the different orderings used by C, C++, and Rust (Relaxed, Release, Acquire, AcqRel, and SeqCst).<p>I&#x27;m very sure there were discussions and teaching materials then, but none (that I was aware of) focused on Rust, and something I&#x27;d link to someone who had never heard of atomic ordering before.</div><br/></div></div></div></div></div></div><div id="39552324" class="c"><input type="checkbox" id="c-39552324" checked=""/><div class="controls bullet"><span class="by">jcelerier</span><span>|</span><a href="#39551465">parent</a><span>|</span><a href="#39552243">prev</a><span>|</span><a href="#39554936">next</a><span>|</span><label class="collapse" for="c-39552324">[-]</label><label class="expand" for="c-39552324">[3 more]</label></div><br/><div class="children"><div class="content">&gt; It is much easier to do it at design time<p>Is it? I always worked the second way (starting from seq_cst and then when the core design matured enough and didn&#x27;t change for a few months, trying to see what could actually be relaxed). I&#x27;d be very afraid that in the first case, you start with say relaxed semantics somewhere, them you change the design because the requirements changed, and now you have to go again through all the atomic operations to make sure the assumptions all still hold.</div><br/><div id="39552386" class="c"><input type="checkbox" id="c-39552386" checked=""/><div class="controls bullet"><span class="by">jamesmunns</span><span>|</span><a href="#39551465">root</a><span>|</span><a href="#39552324">parent</a><span>|</span><a href="#39552435">next</a><span>|</span><label class="collapse" for="c-39552386">[-]</label><label class="expand" for="c-39552386">[1 more]</label></div><br/><div class="children"><div class="content">Back when this post was written, I would have agreed with you. But Mara&#x27;s book makes a good case for this:<p><a href="https:&#x2F;&#x2F;marabos.nl&#x2F;atomics&#x2F;memory-ordering.html#common-misconceptions" rel="nofollow">https:&#x2F;&#x2F;marabos.nl&#x2F;atomics&#x2F;memory-ordering.html#common-misco...</a><p><pre><code>  More importantly, when reading code, SeqCst basically tells the reader:
  &quot;this operation depends on the total order of every single SeqCst operation
  in the program,&quot; which is an incredibly far-reaching claim. The same code
  would likely be easier to review and verify if it used weaker memory ordering
  instead, if possible...
  
  It is advisable to see SeqCst as a warning sign.</code></pre></div><br/></div></div><div id="39552435" class="c"><input type="checkbox" id="c-39552435" checked=""/><div class="controls bullet"><span class="by">gpderetta</span><span>|</span><a href="#39551465">root</a><span>|</span><a href="#39552324">parent</a><span>|</span><a href="#39552386">prev</a><span>|</span><a href="#39554936">next</a><span>|</span><label class="collapse" for="c-39552435">[-]</label><label class="expand" for="c-39552435">[1 more]</label></div><br/><div class="children"><div class="content">If you change the design of a lock free algo you very likely have to go through all the atomic operations to make sure that all assumptions hold anyway.</div><br/></div></div></div></div><div id="39554936" class="c"><input type="checkbox" id="c-39554936" checked=""/><div class="controls bullet"><span class="by">derefr</span><span>|</span><a href="#39551465">parent</a><span>|</span><a href="#39552324">prev</a><span>|</span><a href="#39554072">next</a><span>|</span><label class="collapse" for="c-39554936">[-]</label><label class="expand" for="c-39554936">[1 more]</label></div><br/><div class="children"><div class="content">&gt; If you aren&#x27;t going to bother understanding ordering semantics, it is unlikely you can write a safe lock-free algorithm anyway.<p>I think the implicit suggestion here is that the target audience for this abstraction is actually two separate developers:<p>1. A developer who doesnât know much about locking semantics, but can write the simple-but-slow case correctly.<p>2. Another developer, much later on â probably a senior SRE type â who can revisit this code and optimize it with full understanding of the constraints.<p>(This might also be the same person, years later, with more experience under their belt.)<p>The benefit of the way this library is designed, is that the second developer doesnât have to completely rewrite everything just to optimize it. The naive devâs code has already been forced into an âalmost but not quiteâ lock-free mold by the design of the libraryâs API surface.</div><br/></div></div><div id="39554072" class="c"><input type="checkbox" id="c-39554072" checked=""/><div class="controls bullet"><span class="by">haberman</span><span>|</span><a href="#39551465">parent</a><span>|</span><a href="#39554936">prev</a><span>|</span><a href="#39552548">next</a><span>|</span><label class="collapse" for="c-39554072">[-]</label><label class="expand" for="c-39554072">[5 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve never actually seen a production lock-free algorithm that uses SeqCst.  I have a hard time even imagining an algorithm where SeqCst is the right choice.<p>It seems like SeqCst was chosen as a default to reduce the surprises and gotchas around lock-free programming.  But lock-free programming is inherently tricky; if you&#x27;re trying to avoid surprises and gotchas you should probably use a mutex.</div><br/><div id="39557874" class="c"><input type="checkbox" id="c-39557874" checked=""/><div class="controls bullet"><span class="by">senderista</span><span>|</span><a href="#39551465">root</a><span>|</span><a href="#39554072">parent</a><span>|</span><a href="#39552548">next</a><span>|</span><label class="collapse" for="c-39557874">[-]</label><label class="expand" for="c-39557874">[4 more]</label></div><br/><div class="children"><div class="content">It is the right choice whenever you need linearizability. I can&#x27;t believe you&#x27;ve never seen a (correct) production lock-free algorithm impl that used SeqCst. Many lock-free algorithms require SeqCst for correctness. Here&#x27;s a trivial example: hazard pointers. Any thread publishing its hazard pointer must use a StoreLoad barrier (equivalent to SeqCst) to ensure any GC thread scanning the publication list sees its hazard pointer, before it deallocates pointers in the limbo list that didn&#x27;t appear in the scan. MemSQL actually wrote a blog post on a nasty bug in their database arising from their use of AcqRel for this operation instead of SeqCst: <a href="https:&#x2F;&#x2F;www.singlestore.com&#x2F;blog&#x2F;common-pitfalls-in-writing-lock-free-algorithms&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.singlestore.com&#x2F;blog&#x2F;common-pitfalls-in-writing-...</a>.</div><br/><div id="39559430" class="c"><input type="checkbox" id="c-39559430" checked=""/><div class="controls bullet"><span class="by">gpderetta</span><span>|</span><a href="#39551465">root</a><span>|</span><a href="#39557874">parent</a><span>|</span><a href="#39558614">next</a><span>|</span><label class="collapse" for="c-39559430">[-]</label><label class="expand" for="c-39559430">[1 more]</label></div><br/><div class="children"><div class="content">You certainly need a #storeload to update the hazard pointer, but do you really need seq_cst? Is a total order of all updates really necessary? Wouldn&#x27;t, say, an acq_rel exchange be sufficient?<p>I need to read that article, it seems interesting.</div><br/></div></div><div id="39558614" class="c"><input type="checkbox" id="c-39558614" checked=""/><div class="controls bullet"><span class="by">loeg</span><span>|</span><a href="#39551465">root</a><span>|</span><a href="#39557874">parent</a><span>|</span><a href="#39559430">prev</a><span>|</span><a href="#39552548">next</a><span>|</span><label class="collapse" for="c-39558614">[-]</label><label class="expand" for="c-39558614">[2 more]</label></div><br/><div class="children"><div class="content">This blog post leaves a lot to the imagination.<p>&gt; Hereâs the case that broke our stack:<p><pre><code>  Thread 1, in preparation for a Pop operation, reads the head of the stack.
  Thread 1 writes the current head to its hazard pointer (using only release semantics, 
  which are weaker than sequentially consistent semantics).
  Thread 1 reads the head of the stack again.
  Thread 2 removes head from the stack, and passes it to the garbage collector thread 
  (using sequentially consistent memory semantics).
  The garbage collector scans the hazard pointers,\ and (because the assignment was not 
  done with sequentially consistent memory semantics) is not guaranteed to see thread 
  1âs hazard pointer pointing to the node.
  The garbage collector deletes the node
  Thread 1 dereferences the node, and segfaults.
</code></pre>
My interpretation is that with release semantics for the store, the 2nd read (load) in Thread 1 is actually allowed to be reordered before the release store to the hazard pointer.  But they are not very explicit about it.<p>&gt; So if thread 2 removing the pointer happens first, thread 1 will see a different value on its second read and not attempt to dereference it.<p>Thread 1 will see thread 2&#x27;s remove even with release semantics for that store -- the store has a data dependency on the first load; they cannot be reordered.<p>&gt; If thread 1 writes to its hazard pointer first, the garbage collector is guaranteed to see that value and not delete the node.<p>Yeah, this must be it.  Thread 1 fails to notice the GC happened while it was writing its HP because its second load actually happened before the HP store.<p>Folly&#x27;s hazard pointer implementation uses a release store to update the hazard pointer (here: reset_protection()), but uses some sort of SeqCst barrier between the store and the 2nd load (with acquire semantics): <a href="https:&#x2F;&#x2F;github.com&#x2F;facebook&#x2F;folly&#x2F;blob&#x2F;main&#x2F;folly&#x2F;synchronization&#x2F;HazptrHolder.h#L120-L125">https:&#x2F;&#x2F;github.com&#x2F;facebook&#x2F;folly&#x2F;blob&#x2F;main&#x2F;folly&#x2F;synchroniz...</a></div><br/><div id="39558791" class="c"><input type="checkbox" id="c-39558791" checked=""/><div class="controls bullet"><span class="by">senderista</span><span>|</span><a href="#39551465">root</a><span>|</span><a href="#39558614">parent</a><span>|</span><a href="#39552548">next</a><span>|</span><label class="collapse" for="c-39558791">[-]</label><label class="expand" for="c-39558791">[1 more]</label></div><br/><div class="children"><div class="content">Yes, the store to the HP entry must happen-before both the second load of the global pointer in the publishing thread <i>and</i> any load of the HP entry in another (GC) thread. (The first load + store + second load emulates an atomic memory-to-memory copy of the global pointer to the HP entry.)</div><br/></div></div></div></div></div></div></div></div><div id="39552548" class="c"><input type="checkbox" id="c-39552548" checked=""/><div class="controls bullet"><span class="by">ajross</span><span>|</span><a href="#39551465">parent</a><span>|</span><a href="#39554072">prev</a><span>|</span><a href="#39557111">next</a><span>|</span><label class="collapse" for="c-39552548">[-]</label><label class="expand" for="c-39552548">[8 more]</label></div><br/><div class="children"><div class="content">Completely agree, though the more iconoclastic corrolary that goes unspoken there is that putting The Final Word on memory ordering semantics into programming language standards was a terrible mistake.<p>Memory ordering is a hardware behavior.  It needs to be specified at the hardware level, and hardware vendors have been very mixed on clarity.  And more importantly, lockless algorithms (that rely on memory ordering control) are really, really hard, and demand clarity over all things.  And instead we&#x27;re crippling those poor programmers with nonsense like &quot;sequentially consistent&quot;[1] or trying to figure out what on earth &quot;consume&quot; means[2].<p>x86 does this pretty well with their comparatively simple model of serializing instructions.  Traditional ARM ISAs did only a little worse by exposing the interface as read&#x2F;write barrier instructions.  Everyone else... meh.<p>But if you really want to do this (and you probably don&#x27;t) do the analysis yourself at the level of ISA&#x2F;architecture&#x2F;hardware, cite your references, and be prepared to handle whatever portability works is needed on your own.<p>[1] A statement about desired final state, not hardware behavior!<p>[2] Nothing, on any hardware you will ever use.  Don&#x27;t ask.</div><br/><div id="39552697" class="c"><input type="checkbox" id="c-39552697" checked=""/><div class="controls bullet"><span class="by">gpderetta</span><span>|</span><a href="#39551465">root</a><span>|</span><a href="#39552548">parent</a><span>|</span><a href="#39557111">next</a><span>|</span><label class="collapse" for="c-39552697">[-]</label><label class="expand" for="c-39552697">[7 more]</label></div><br/><div class="children"><div class="content">On the contrary, fixing the memory model on a widely used language like C++ forced hardware vendors to get their act together and provide more rigorous memory model explanations. For example intel went from Processor Ordering to TSO, and arm started offering explicit acquire&#x2F;release operations.<p>Java had the opportunity as well, but by initially only providing a stronger, mostly sequentially consistent MO, the hardware vendors managed to get away a little longer.</div><br/><div id="39552759" class="c"><input type="checkbox" id="c-39552759" checked=""/><div class="controls bullet"><span class="by">ajross</span><span>|</span><a href="#39551465">root</a><span>|</span><a href="#39552697">parent</a><span>|</span><a href="#39557111">next</a><span>|</span><label class="collapse" for="c-39552759">[-]</label><label class="expand" for="c-39552759">[6 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think that&#x27;s the case with Intel at all, the events are off by a decade at least; do you have a blog or something to cite there?  I&#x27;d be curious to read it.  And as for ARM, &quot;explicit acquire&#x2F;release&quot; is objectively less informative and harder to reason about than the xxxSB instructions were (and yes, I&#x27;ve used both).  ARM went <i>backwards</i> to accommodate C++&#x27;s nonsense.<p>Again, the language standard writers aren&#x27;t remotely the experts here, the hardware designers are.  That C++ invented its own metaphors instead of listening to the experts is a bug, not a feature.</div><br/><div id="39552935" class="c"><input type="checkbox" id="c-39552935" checked=""/><div class="controls bullet"><span class="by">gpderetta</span><span>|</span><a href="#39551465">root</a><span>|</span><a href="#39552759">parent</a><span>|</span><a href="#39556719">next</a><span>|</span><label class="collapse" for="c-39552935">[-]</label><label class="expand" for="c-39552935">[3 more]</label></div><br/><div class="children"><div class="content">The hardware designers were involved on the standardization process. I don&#x27;t have citations at hand, I think most of the mailing lists were the discussion re the c++ MO happened have been lost, but (as a lurker trying to learn this stuff) I was following the process closely.<p>The question was, given PO, whether it was at all possible to recover sequential consistently on intel either with mfence or a lock xchg, given the possibility of IRIW. Intel then updated their MO to exclude IRIW, de facto standardizing on TSO.<p>This was early 2000s. I think both ARM and IBM published revisions to their architecture clarifying details around the same time.<p>This spawned a set of academic papers that proved the correctness of the agreed mapping of the C++ memory model to those architecture s.</div><br/><div id="39553160" class="c"><input type="checkbox" id="c-39553160" checked=""/><div class="controls bullet"><span class="by">ajross</span><span>|</span><a href="#39551465">root</a><span>|</span><a href="#39552935">parent</a><span>|</span><a href="#39556719">next</a><span>|</span><label class="collapse" for="c-39553160">[-]</label><label class="expand" for="c-39553160">[2 more]</label></div><br/><div class="children"><div class="content">&gt; The hardware designers were involved on the standardization process.<p>That sounds cyclic then.  You&#x27;re saying that Intel&#x27;s SDM was ambiguous[1] (which it was) and that it was sorted out as part of a standardization process.  I&#x27;m saying that it doesn&#x27;t really matter what the SDM said, it mattered whether or not you could reliably write lockless code on x86 using the hardware and docs available at the time, and you could.  And further, I&#x27;m saying that the standard ended up making things worse by perpetuating arguments like this about what some buggy English text in an SDM said and <i>not about actual hardware behavior</i>.<p>[1] In ways that AFAICT didn&#x27;t actually impact hardware.  I found this, which is probably one of the papers you&#x27;re citing.  It&#x27;s excellent work in standards-writing, but it&#x27;s also careful to note that the IRIW cases were never observed on hardware.  <a href="https:&#x2F;&#x2F;www.cl.cam.ac.uk&#x2F;~pes20&#x2F;weakmemory&#x2F;x86tso-paper.tphols.pdf" rel="nofollow">https:&#x2F;&#x2F;www.cl.cam.ac.uk&#x2F;~pes20&#x2F;weakmemory&#x2F;x86tso-paper.tpho...</a></div><br/><div id="39554380" class="c"><input type="checkbox" id="c-39554380" checked=""/><div class="controls bullet"><span class="by">gpderetta</span><span>|</span><a href="#39551465">root</a><span>|</span><a href="#39553160">parent</a><span>|</span><a href="#39556719">next</a><span>|</span><label class="collapse" for="c-39554380">[-]</label><label class="expand" for="c-39554380">[1 more]</label></div><br/><div class="children"><div class="content">It didn&#x27;t impact hardware because intel hadn&#x27;t taken advantage yet of the additional latitude offered by their original model. Then they closed the hole and they guaranteed no IRIW[1]. But in the meantime if your algorithm was susceptible to this reordering, there was no written guarantee that an mfence would fix it. But most importantly as the model was informal and not self consistent, there was no possibility to write formal proofs of correctness of an algorithm or run it against a model checker.<p>[1] in practice this means no store-forwarding from sibling hyper thread store buffers, something that for example POWER allows and is observed in real hardware.</div><br/></div></div></div></div></div></div><div id="39556719" class="c"><input type="checkbox" id="c-39556719" checked=""/><div class="controls bullet"><span class="by">bfrog</span><span>|</span><a href="#39551465">root</a><span>|</span><a href="#39552759">parent</a><span>|</span><a href="#39552935">prev</a><span>|</span><a href="#39557111">next</a><span>|</span><label class="collapse" for="c-39556719">[-]</label><label class="expand" for="c-39556719">[2 more]</label></div><br/><div class="children"><div class="content">C++ is a bug that canât be fixed</div><br/><div id="39556862" class="c"><input type="checkbox" id="c-39556862" checked=""/><div class="controls bullet"><span class="by">vacuity</span><span>|</span><a href="#39551465">root</a><span>|</span><a href="#39556719">parent</a><span>|</span><a href="#39557111">next</a><span>|</span><label class="collapse" for="c-39556862">[-]</label><label class="expand" for="c-39556862">[1 more]</label></div><br/><div class="children"><div class="content">Although, like many bugs, it&#x27;s also a feature.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="39551661" class="c"><input type="checkbox" id="c-39551661" checked=""/><div class="controls bullet"><span class="by">magnat</span><span>|</span><a href="#39551465">prev</a><span>|</span><a href="#39550677">next</a><span>|</span><label class="collapse" for="c-39551661">[-]</label><label class="expand" for="c-39551661">[2 more]</label></div><br/><div class="children"><div class="content">&gt; A typical serial port configuration is &quot;115200 8N1&quot;, which means 115,200 baud (or raw bits on the wire per second), with no parity, and 1 stop bit. This means that for every data byte sent, there will be 8 data bits, 1 unused parity bit, and 1 stop bit, to signal the end of the byte, sent over the wire. This means that we will need 40 bits on the wire to receive a 4 data bytes.<p>8N1 means there is 1 start bit, 8 data bits and 1 stop bit (10 bits total), not 8 data bits, 1 unused parity bit and 1 stop bit (also 10 bits total).</div><br/><div id="39552279" class="c"><input type="checkbox" id="c-39552279" checked=""/><div class="controls bullet"><span class="by">jamesmunns</span><span>|</span><a href="#39551661">parent</a><span>|</span><a href="#39550677">next</a><span>|</span><label class="collapse" for="c-39552279">[-]</label><label class="expand" for="c-39552279">[1 more]</label></div><br/><div class="children"><div class="content">Yep, good catch! That&#x27;s a whoops in my explanation. I don&#x27;t work at FS any more, so I&#x27;m not sure I could PR that change, but you&#x27;re definitely right :)</div><br/></div></div></div></div><div id="39550677" class="c"><input type="checkbox" id="c-39550677" checked=""/><div class="controls bullet"><span class="by">rdtsc</span><span>|</span><a href="#39551661">prev</a><span>|</span><a href="#39556126">next</a><span>|</span><label class="collapse" for="c-39550677">[-]</label><label class="expand" for="c-39550677">[12 more]</label></div><br/><div class="children"><div class="content">My favorite ring buffer structure is like the one described in <a href="https:&#x2F;&#x2F;www.gnuradio.org&#x2F;blog&#x2F;2017-01-05-buffers&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.gnuradio.org&#x2F;blog&#x2F;2017-01-05-buffers&#x2F;</a><p>&gt; It asks the operating system to give it memory-mappable memory, and map twice, âback to backâ. Blocks then get called with pointers to the âearliestâ position of a workload within this memory region â guaranteeing that they can access all memory they were offered in a linear fashion, as if theyâd actually be dealing with hardware ring buffers.<p>It imposes limitations on hardware and OS support in a way, but I think it&#x27;s pretty neat.<p>This also used by the kernel BPF ring buffer:<p><a href="https:&#x2F;&#x2F;www.kernel.org&#x2F;doc&#x2F;html&#x2F;latest&#x2F;bpf&#x2F;ringbuf.html" rel="nofollow">https:&#x2F;&#x2F;www.kernel.org&#x2F;doc&#x2F;html&#x2F;latest&#x2F;bpf&#x2F;ringbuf.html</a><p>&gt; ...data area is mapped twice contiguously back-to-back in the virtual memory. This allows to not take any special measures for samples that have to wrap around at the end of the circular buffer data area, because the next page after the last data page would be first data page again, and thus the sample will still appear completely contiguous in virtual memory</div><br/><div id="39550883" class="c"><input type="checkbox" id="c-39550883" checked=""/><div class="controls bullet"><span class="by">dist1ll</span><span>|</span><a href="#39550677">parent</a><span>|</span><a href="#39552459">next</a><span>|</span><label class="collapse" for="c-39550883">[-]</label><label class="expand" for="c-39550883">[4 more]</label></div><br/><div class="children"><div class="content">Unfortunately that means the chunks are only contiguous in virtual memory. So it won&#x27;t work with the DMA use case mentioned in the article, which requires contiguous physical addresses.<p>But it&#x27;s still a nice trick, I like it when people get creative with HW features.</div><br/><div id="39551274" class="c"><input type="checkbox" id="c-39551274" checked=""/><div class="controls bullet"><span class="by">jnwatson</span><span>|</span><a href="#39550677">root</a><span>|</span><a href="#39550883">parent</a><span>|</span><a href="#39552482">next</a><span>|</span><label class="collapse" for="c-39551274">[-]</label><label class="expand" for="c-39551274">[2 more]</label></div><br/><div class="children"><div class="content">Theoretically, the same trick could be used to double map addresses coming from an external master via an IOMMU.</div><br/><div id="39552268" class="c"><input type="checkbox" id="c-39552268" checked=""/><div class="controls bullet"><span class="by">speed_spread</span><span>|</span><a href="#39550677">root</a><span>|</span><a href="#39551274">parent</a><span>|</span><a href="#39552482">next</a><span>|</span><label class="collapse" for="c-39552268">[-]</label><label class="expand" for="c-39552268">[1 more]</label></div><br/><div class="children"><div class="content">It is unlikely that cheap microcontrollers where DMA is most helpful will have an IOMMU.</div><br/></div></div></div></div><div id="39552482" class="c"><input type="checkbox" id="c-39552482" checked=""/><div class="controls bullet"><span class="by">gpderetta</span><span>|</span><a href="#39550677">root</a><span>|</span><a href="#39550883">parent</a><span>|</span><a href="#39551274">prev</a><span>|</span><a href="#39552459">next</a><span>|</span><label class="collapse" for="c-39552482">[-]</label><label class="expand" for="c-39552482">[1 more]</label></div><br/><div class="children"><div class="content">But the hardware only needs to see on  copy of the duplicated memory and you can let it deal with the wraparound. The software can use the convenience of the double mapping.</div><br/></div></div></div></div><div id="39552459" class="c"><input type="checkbox" id="c-39552459" checked=""/><div class="controls bullet"><span class="by">gpderetta</span><span>|</span><a href="#39550677">parent</a><span>|</span><a href="#39550883">prev</a><span>|</span><a href="#39559217">next</a><span>|</span><label class="collapse" for="c-39552459">[-]</label><label class="expand" for="c-39552459">[1 more]</label></div><br/><div class="children"><div class="content">AKA the Magic Ring Buffer. It extremely convenient not having to deal with split messages, especially if you support variables size payloads.</div><br/></div></div><div id="39559217" class="c"><input type="checkbox" id="c-39559217" checked=""/><div class="controls bullet"><span class="by">signa11</span><span>|</span><a href="#39550677">parent</a><span>|</span><a href="#39552459">prev</a><span>|</span><a href="#39552550">next</a><span>|</span><label class="collapse" for="c-39559217">[-]</label><label class="expand" for="c-39559217">[1 more]</label></div><br/><div class="children"><div class="content">ah the vm-trick ! have used it current (and previous) places of work to great effect.</div><br/></div></div><div id="39552550" class="c"><input type="checkbox" id="c-39552550" checked=""/><div class="controls bullet"><span class="by">scottlamb</span><span>|</span><a href="#39550677">parent</a><span>|</span><a href="#39559217">prev</a><span>|</span><a href="#39557112">next</a><span>|</span><label class="collapse" for="c-39552550">[-]</label><label class="expand" for="c-39552550">[4 more]</label></div><br/><div class="children"><div class="content">This is a cool trick, and iirc there are a few Rust crates that implement it, including slice-deque.<p>...but I think there are a few significant downsides, even in userspace:<p>* The most obvious one: you have to write `unsafe`, non-portable code. The Linux, macOS, and Windows implementations are totally different from each other.<p>* The setup and teardown of each ring is a bit expensive (few system calls). For a regular allocation, the malloc implementation typically caches that for you. Here you have to do your own pooling if you might be frequently creating them.<p>* Using whole pages, and two mappings per ring, is wasteful in terms of not only RAM (often no big deal) but also TLB space (which often turns into significant CPU usage). If you just allocate 32 64 KiB rings from the standard allocator, on x86-64 you might be talking about a single 2 MiB huge page mapping. If you do this instead, you&#x27;re talking about 1024 4 KiB page mappings.</div><br/><div id="39554672" class="c"><input type="checkbox" id="c-39554672" checked=""/><div class="controls bullet"><span class="by">duped</span><span>|</span><a href="#39550677">root</a><span>|</span><a href="#39552550">parent</a><span>|</span><a href="#39557112">next</a><span>|</span><label class="collapse" for="c-39554672">[-]</label><label class="expand" for="c-39554672">[3 more]</label></div><br/><div class="children"><div class="content">Any real, production ready ring buffer should be using unsafe. I would consider anything that doesn&#x27;t to be a toy.<p>In Rust it&#x27;s basically impossible to do this without MaybeUninit. You <i>could</i> use Option, but then you&#x27;re paying a massive cost for a very easy to write and audit chunk of unsafe code.</div><br/><div id="39557037" class="c"><input type="checkbox" id="c-39557037" checked=""/><div class="controls bullet"><span class="by">scottlamb</span><span>|</span><a href="#39550677">root</a><span>|</span><a href="#39554672">parent</a><span>|</span><a href="#39557112">next</a><span>|</span><label class="collapse" for="c-39557037">[-]</label><label class="expand" for="c-39557037">[2 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think it&#x27;s useful to consider &quot;uses `unsafe`&quot; as a boolean. A one-line `unsafe` around `MaybeUninit::assume_init` isn&#x27;t the same as an `unsafe` module per platform wrapping VM operations.<p>Also, it&#x27;s not that crazy for a byte-oriented buffer to start with a `vec![0u8; N]` (cheap) and not need `MaybeUninit` at all. Probably doesn&#x27;t buy you that much though; you still want to be careful to not leak previous bytes.<p>Also, you might be missing the point of my comment if you&#x27;re responding to one word of &quot;the most obvious [downside]&quot; and not the other bullets...</div><br/><div id="39558943" class="c"><input type="checkbox" id="c-39558943" checked=""/><div class="controls bullet"><span class="by">duped</span><span>|</span><a href="#39550677">root</a><span>|</span><a href="#39557037">parent</a><span>|</span><a href="#39557112">next</a><span>|</span><label class="collapse" for="c-39558943">[-]</label><label class="expand" for="c-39558943">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not an attack on the wording, but the correctness of your first bullet point. `unsafe` is appropriate for the initialization of a ring buffer in Rust. That&#x27;s true for using `mmap` or anything in &quot;pure&quot; Rust using the allocator API to get the most idiomatic representation (which can&#x27;t be done in safe or stable Rust). It&#x27;s not one line. It&#x27;s also not platform dependent, the code is the same on MacOS, Linux, and Windows the last I tried it.<p>The rest of the bullet points are issues with scaling, which sure, are valid. But if your bottleneck is determined by the frequency at which channels get created or how many exist then I would call architecture into the question. A ringbuffer is a heavy hammer to synchronization problems. It&#x27;s appropriate in many, but not many times in the same application, in my experience.<p>This last month I&#x27;ve written a lock-free ring buffer to solve a problem and there&#x27;s exactly one in an application that spawns millions of concurrent tasks.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="39556126" class="c"><input type="checkbox" id="c-39556126" checked=""/><div class="controls bullet"><span class="by">dnedic</span><span>|</span><a href="#39550677">prev</a><span>|</span><a href="#39551022">next</a><span>|</span><label class="collapse" for="c-39556126">[-]</label><label class="expand" for="c-39556126">[1 more]</label></div><br/><div class="children"><div class="content">Bipartite buffers are amazing and criminally underused. For those looking for C and C++ implementations you can check out my libraries: lfbb and lockfee: <a href="https:&#x2F;&#x2F;github.com&#x2F;DNedic&#x2F;lfbb">https:&#x2F;&#x2F;github.com&#x2F;DNedic&#x2F;lfbb</a>, <a href="https:&#x2F;&#x2F;github.com&#x2F;DNedic&#x2F;lockfree">https:&#x2F;&#x2F;github.com&#x2F;DNedic&#x2F;lockfree</a> (although lockfree contains more data structures as well)</div><br/></div></div><div id="39551022" class="c"><input type="checkbox" id="c-39551022" checked=""/><div class="controls bullet"><span class="by">monocasa</span><span>|</span><a href="#39556126">prev</a><span>|</span><a href="#39556144">next</a><span>|</span><label class="collapse" for="c-39551022">[-]</label><label class="expand" for="c-39551022">[3 more]</label></div><br/><div class="children"><div class="content">&gt; Contended writes from multiple threads on the same memory location are a lot harder for the CPU&#x27;s cache coherence protocol to handle<p>FWIW, those are the same location according to most cache coherency protocols, since cache coherency generally works on the cache line level.  You&#x27;d want to split the two contexts to their own cache lines.</div><br/><div id="39554288" class="c"><input type="checkbox" id="c-39554288" checked=""/><div class="controls bullet"><span class="by">stefanha</span><span>|</span><a href="#39551022">parent</a><span>|</span><a href="#39556144">next</a><span>|</span><label class="collapse" for="c-39554288">[-]</label><label class="expand" for="c-39554288">[2 more]</label></div><br/><div class="children"><div class="content">Another cache optimization trick some ring-buffer implementations use is to keep a shadow copy of the read or write pointer to avoid frequently fetching the other context&#x27;s cache line. The latest version of the read pointer is only needed when the writer catches up with their shadow copy and vice versa.</div><br/><div id="39556204" class="c"><input type="checkbox" id="c-39556204" checked=""/><div class="controls bullet"><span class="by">anonymousDan</span><span>|</span><a href="#39551022">root</a><span>|</span><a href="#39554288">parent</a><span>|</span><a href="#39556144">next</a><span>|</span><label class="collapse" for="c-39556204">[-]</label><label class="expand" for="c-39556204">[1 more]</label></div><br/><div class="children"><div class="content">Yes this is absolutely crucial for performance.</div><br/></div></div></div></div></div></div><div id="39556144" class="c"><input type="checkbox" id="c-39556144" checked=""/><div class="controls bullet"><span class="by">nyanpasu64</span><span>|</span><a href="#39551022">prev</a><span>|</span><a href="#39551380">next</a><span>|</span><label class="collapse" for="c-39556144">[-]</label><label class="expand" for="c-39556144">[1 more]</label></div><br/><div class="children"><div class="content">&gt;In Andrea&#x27;s implementation of the lock-free ring-buffer, spsc-bip-buffer, some of the orderings are relaxed for performance. This has the downside that it can introduce subtle concurrency bugs that may only show up on some platform (ARM, for example): to be a bit more confident that everything&#x27;s still fine, Andrea&#x27;s has continous integation tests both on x86 and ARM.<p>It might be worth testing&#x2F;forking the library to test on Loom (<a href="https:&#x2F;&#x2F;github.com&#x2F;tokio-rs&#x2F;loom">https:&#x2F;&#x2F;github.com&#x2F;tokio-rs&#x2F;loom</a>), which can model atomic orderings and check for concurrency errors to some degree (though I last used it years ago). TSAN might be able to check for ordering errors in <i>visited</i> execution traces (though I haven&#x27;t tried using it in the past).</div><br/></div></div><div id="39551380" class="c"><input type="checkbox" id="c-39551380" checked=""/><div class="controls bullet"><span class="by">samsquire</span><span>|</span><a href="#39556144">prev</a><span>|</span><a href="#39558998">next</a><span>|</span><label class="collapse" for="c-39551380">[-]</label><label class="expand" for="c-39551380">[10 more]</label></div><br/><div class="children"><div class="content">I tried to write a lock free ringbuffer with weak atomics, I haven&#x27;t proved it right with TLA+ yet but I started writing a model in it. I use tagging to avoid the ABA problem.<p>they&#x27;re all on <a href="https:&#x2F;&#x2F;github.com&#x2F;samsquire&#x2F;assembly">https:&#x2F;&#x2F;github.com&#x2F;samsquire&#x2F;assembly</a>, i tried to write multiple disruptor with multiple consumers, then one with multiple producers then one with multiple consumers AND multiple producers, inspired by LMAX Disruptor. (There&#x27;s files for each of them and table in the repo. it&#x27;s not proven yet!)<p>the contention on the same memory address (the read&#x2F;write index) is the thing that seems difficult to address.<p>One thing I&#x27;ve learned about thread safety:<p>I think if you have thread-owned values then you can be thread safe with a simple semaphore, providing that you have unique, DISTINCT values for each thread.<p>If you have two threads that have this in a hot loop in parallel:<p><pre><code>  &#x2F;&#x2F; thread 0                        
  if buffer[x].available == 1:
    &#x2F;&#x2F; do stuff
    buffer[x].available = 0           

  &#x2F;&#x2F; thread 1
  if buffer[x].available == 0:
    &#x2F;&#x2F; do stuff
    buffer[x].available = 1
</code></pre>
Due to causality, no matter the interleaving, thread 0 owns the buffer[x].available and body of the if statement when it is 1 and thread 1 owns the body of the if statement buffer[x].available when it is 0.<p>The CMP is a cheap mutex with distinct valued memory locations.<p>Even though thread 1 is writing to buffer[x].available and thread 0 is writing to buffer[x].available it doesn&#x27;t matter because the causality is mutually exclusive. There is no interleaving of buffer[x].available = x because of the if statement.<p>The buffer[x].available = 0 will never run while buffer[x].available is equal to 0 overwriting or causing a data race when setting buffer[x].available to 1. So the second line cannot happen in parallel.<p>I need to write a TLA model to assert its safety.<p>If you have more than 2 threads, then you need different tokens to provide admissability to the if statement.<p>Remember to use compiler memory barrier<p><pre><code>   asm volatile (&quot;&quot; ::: &quot;memory&quot;);  
</code></pre>
so you don&#x27;t need volatile struct values.</div><br/><div id="39552622" class="c"><input type="checkbox" id="c-39552622" checked=""/><div class="controls bullet"><span class="by">gpderetta</span><span>|</span><a href="#39551380">parent</a><span>|</span><a href="#39551505">next</a><span>|</span><label class="collapse" for="c-39552622">[-]</label><label class="expand" for="c-39552622">[2 more]</label></div><br/><div class="children"><div class="content">The problem here is the<p><pre><code>  [1] &#x2F;&#x2F; Do stuff
  [2] Buffer[X]. available = Y
</code></pre>
There is no explicit nor implicit ordering between 1 and 2, so the compiler or cpu can reorder them. You need a release barrier between the two.<p>Also while most CPUs preserve the control dependency, not all do (famously Alpha), and certainly not compilers. You would need a consume barrier, except that c++11 consume is only for data dependencies and unimplemented anyway.<p>Edit: with the correct barriers in place, you can prove correctness by similitude to two size 1 SPSC queues used to exchange a mutual exclusion token, with the added quirk that as the queues are never used at the same time, they can actually be physically colocated in memory.</div><br/><div id="39553197" class="c"><input type="checkbox" id="c-39553197" checked=""/><div class="controls bullet"><span class="by">samsquire</span><span>|</span><a href="#39551380">root</a><span>|</span><a href="#39552622">parent</a><span>|</span><a href="#39551505">next</a><span>|</span><label class="collapse" for="c-39553197">[-]</label><label class="expand" for="c-39553197">[1 more]</label></div><br/><div class="children"><div class="content">Thank you for you and for sharing your knowledge gpderetta, appreciated, TIL.</div><br/></div></div></div></div><div id="39551505" class="c"><input type="checkbox" id="c-39551505" checked=""/><div class="controls bullet"><span class="by">loeg</span><span>|</span><a href="#39551380">parent</a><span>|</span><a href="#39552622">prev</a><span>|</span><a href="#39556253">next</a><span>|</span><label class="collapse" for="c-39551505">[-]</label><label class="expand" for="c-39551505">[5 more]</label></div><br/><div class="children"><div class="content">&gt; The buffer[x].available = 0 will never run while buffer[x].available is equal to 0 overwriting or causing a data race when setting buffer[x].available to 1.<p>In particular, because loads and stores of the same variable cannot be reordered out of program order.  Once your algorithm involves other variables, you would (likely) need to be a little careful about loading&#x2F;storing with acquire&#x2F;release semantics to prevent reordering other accesses relative to this protocol.<p>&gt; Remember to use compiler memory barrier<p>I would highly recommend using the language atomic types (and barriers if truly needed) instead of gcc inline assembly syntax.</div><br/><div id="39551568" class="c"><input type="checkbox" id="c-39551568" checked=""/><div class="controls bullet"><span class="by">samsquire</span><span>|</span><a href="#39551380">root</a><span>|</span><a href="#39551505">parent</a><span>|</span><a href="#39556253">next</a><span>|</span><label class="collapse" for="c-39551568">[-]</label><label class="expand" for="c-39551568">[4 more]</label></div><br/><div class="children"><div class="content">Thanks for your reply. This subject is still new to me.<p>My understanding of that syntax is that it is a compiler memory barrier, not a CPU memory barrier because the asm block is empty (no sfence or mfence).</div><br/><div id="39551774" class="c"><input type="checkbox" id="c-39551774" checked=""/><div class="controls bullet"><span class="by">loeg</span><span>|</span><a href="#39551380">root</a><span>|</span><a href="#39551568">parent</a><span>|</span><a href="#39556253">next</a><span>|</span><label class="collapse" for="c-39551774">[-]</label><label class="expand" for="c-39551774">[3 more]</label></div><br/><div class="children"><div class="content">Hey, no problem.<p>&gt; My understanding of that syntax is that it is a compiler memory barrier, not a CPU memory barrier because the asm block is empty (no sfence or mfence).<p>In C11, you can write compiler-only fences with atomic_signal_fence:<p><a href="https:&#x2F;&#x2F;en.cppreference.com&#x2F;w&#x2F;c&#x2F;atomic&#x2F;atomic_signal_fence" rel="nofollow">https:&#x2F;&#x2F;en.cppreference.com&#x2F;w&#x2F;c&#x2F;atomic&#x2F;atomic_signal_fence</a><p>(In practice, though, I think it is rare that you actually want a compiler-only fence.  Instead, correct use of acquire&#x2F;release operations prevents reorderings.)</div><br/><div id="39551856" class="c"><input type="checkbox" id="c-39551856" checked=""/><div class="controls bullet"><span class="by">samsquire</span><span>|</span><a href="#39551380">root</a><span>|</span><a href="#39551774">parent</a><span>|</span><a href="#39556253">next</a><span>|</span><label class="collapse" for="c-39551856">[-]</label><label class="expand" for="c-39551856">[2 more]</label></div><br/><div class="children"><div class="content">Thank you loeg, I appreciate you and information you brought that TIL.<p>I&#x27;ve been using a compiler fence to force reloads from memory to prevent -O3 from optimising away my variables&#x2F;structs changing by other threads and keeping data in registers rather than reloading from memory each time. I saw the volatile recommended against from the Linux kernel programmers.<p>such as my thread-&gt;running == 1 in my event loops for my threads.<p><a href="https:&#x2F;&#x2F;www.kernel.org&#x2F;doc&#x2F;html&#x2F;latest&#x2F;process&#x2F;volatile-considered-harmful.html" rel="nofollow">https:&#x2F;&#x2F;www.kernel.org&#x2F;doc&#x2F;html&#x2F;latest&#x2F;process&#x2F;volatile-cons...</a></div><br/><div id="39551903" class="c"><input type="checkbox" id="c-39551903" checked=""/><div class="controls bullet"><span class="by">loeg</span><span>|</span><a href="#39551380">root</a><span>|</span><a href="#39551856">parent</a><span>|</span><a href="#39556253">next</a><span>|</span><label class="collapse" for="c-39551903">[-]</label><label class="expand" for="c-39551903">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I&#x27;ve been using a compiler fence to force reloads from memory to prevent -O3 from optimising away my variables&#x2F;structs changing by other threads<p>I would highly recommend using the language standard atomic primitives instead.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="39556253" class="c"><input type="checkbox" id="c-39556253" checked=""/><div class="controls bullet"><span class="by">anonymousDan</span><span>|</span><a href="#39551380">parent</a><span>|</span><a href="#39551505">prev</a><span>|</span><a href="#39551696">next</a><span>|</span><label class="collapse" for="c-39556253">[-]</label><label class="expand" for="c-39556253">[1 more]</label></div><br/><div class="children"><div class="content">Regarding the contention, one thing that&#x27;s important is to cache a local copy of the shared head and tail variables every time you access them. Then for subsequent operations you can first check the local cached copy to see if you can perform the read or write without needing to check the shared variables.</div><br/></div></div><div id="39551696" class="c"><input type="checkbox" id="c-39551696" checked=""/><div class="controls bullet"><span class="by">samsquire</span><span>|</span><a href="#39551380">parent</a><span>|</span><a href="#39556253">prev</a><span>|</span><a href="#39558998">next</a><span>|</span><label class="collapse" for="c-39551696">[-]</label><label class="expand" for="c-39551696">[1 more]</label></div><br/><div class="children"><div class="content">When you check available, you might have to do it as a (__atomic_load_n(&amp;sender-&gt;realend, __ATOMIC_SEQ_CST) and do __atomic_store_n when setting available.<p>rather than just a plain load.</div><br/></div></div></div></div><div id="39558998" class="c"><input type="checkbox" id="c-39558998" checked=""/><div class="controls bullet"><span class="by">KingOfCoders</span><span>|</span><a href="#39551380">prev</a><span>|</span><a href="#39550428">next</a><span>|</span><label class="collapse" for="c-39558998">[-]</label><label class="expand" for="c-39558998">[1 more]</label></div><br/><div class="children"><div class="content">Sounds a little like LMAX architecture.</div><br/></div></div><div id="39550428" class="c"><input type="checkbox" id="c-39550428" checked=""/><div class="controls bullet"><span class="by">fritzo</span><span>|</span><a href="#39558998">prev</a><span>|</span><a href="#39551702">next</a><span>|</span><label class="collapse" for="c-39550428">[-]</label><label class="expand" for="c-39550428">[2 more]</label></div><br/><div class="children"><div class="content">See also the Java LMAX Disruptor <a href="https:&#x2F;&#x2F;github.com&#x2F;LMAX-Exchange&#x2F;disruptor">https:&#x2F;&#x2F;github.com&#x2F;LMAX-Exchange&#x2F;disruptor</a><p>I&#x27;ve built a similar lock-free ring buffer in C++11 <a href="https:&#x2F;&#x2F;github.com&#x2F;posterior&#x2F;loom&#x2F;blob&#x2F;master&#x2F;doc&#x2F;adapting.md">https:&#x2F;&#x2F;github.com&#x2F;posterior&#x2F;loom&#x2F;blob&#x2F;master&#x2F;doc&#x2F;adapting.m...</a></div><br/><div id="39551045" class="c"><input type="checkbox" id="c-39551045" checked=""/><div class="controls bullet"><span class="by">GenericCanadian</span><span>|</span><a href="#39550428">parent</a><span>|</span><a href="#39551702">next</a><span>|</span><label class="collapse" for="c-39551045">[-]</label><label class="expand" for="c-39551045">[1 more]</label></div><br/><div class="children"><div class="content">I also wrote an LMAX Disruptor in Crystal: <a href="https:&#x2F;&#x2F;github.com&#x2F;nolantait&#x2F;disruptor.cr">https:&#x2F;&#x2F;github.com&#x2F;nolantait&#x2F;disruptor.cr</a><p>Here is one in Ruby: <a href="https:&#x2F;&#x2F;github.com&#x2F;ileitch&#x2F;disruptor">https:&#x2F;&#x2F;github.com&#x2F;ileitch&#x2F;disruptor</a><p>Both languages are quite readable and I&#x27;ve used these to teach the concepts to beginners.</div><br/></div></div></div></div><div id="39551702" class="c"><input type="checkbox" id="c-39551702" checked=""/><div class="controls bullet"><span class="by">bfrog</span><span>|</span><a href="#39550428">prev</a><span>|</span><a href="#39551352">next</a><span>|</span><label class="collapse" for="c-39551702">[-]</label><label class="expand" for="c-39551702">[3 more]</label></div><br/><div class="children"><div class="content">I have to say after looking at various DMA hardware I much much prefer the scatter gather list type than the ring type of DMA.<p>The entire need of a bipbuffer allocation for DMA then goes way. You can have a simple pool of fixed sized blocks to throw at the DMA. Pretty easily done with a free list.<p>I do think the implementation here is cool though, and its nice to see some work in this area.</div><br/><div id="39551894" class="c"><input type="checkbox" id="c-39551894" checked=""/><div class="controls bullet"><span class="by">95014_refugee</span><span>|</span><a href="#39551702">parent</a><span>|</span><a href="#39551352">next</a><span>|</span><label class="collapse" for="c-39551894">[-]</label><label class="expand" for="c-39551894">[2 more]</label></div><br/><div class="children"><div class="content">To make scatter&#x2F;gather go fast, you either spend a lot of effort caching descriptor lists for pinned buffers (because you expect to see them often), or heavily optimising your VM&#x27;s v2p translation machinery, or some combination of the two.<p>And then you wind up discovering that you the driver writer aren&#x27;t actually trusted and so you need to insert at least one if not several IOMMUs between the peripheral and the memory(ies) that they may access, managed by another software component in a different address space.<p>Then someone asks you to make all of this work for clients in VMs.<p>At which point you start wondering why you didn&#x27;t just allocate a physically contiguous buffer at startup and copy to&#x2F;from your client buffers using the CPU...<p>Sorry for sounding triggered... 8)</div><br/><div id="39556772" class="c"><input type="checkbox" id="c-39556772" checked=""/><div class="controls bullet"><span class="by">bfrog</span><span>|</span><a href="#39551702">root</a><span>|</span><a href="#39551894">parent</a><span>|</span><a href="#39551352">next</a><span>|</span><label class="collapse" for="c-39556772">[-]</label><label class="expand" for="c-39556772">[1 more]</label></div><br/><div class="children"><div class="content">No need to apologize at all. I havenât seen these issues. But Iâve worked with this setup without mmu involvement.</div><br/></div></div></div></div></div></div><div id="39551352" class="c"><input type="checkbox" id="c-39551352" checked=""/><div class="controls bullet"><span class="by">piterrro</span><span>|</span><a href="#39551702">prev</a><span>|</span><a href="#39550799">next</a><span>|</span><label class="collapse" for="c-39551352">[-]</label><label class="expand" for="c-39551352">[1 more]</label></div><br/><div class="children"><div class="content">This is great article! Very detailed and explains things on a low-level.<p>For a more high-level implementation, I just released yesterday a blog post about ring buffer in Golang: <a href="https:&#x2F;&#x2F;logdy.dev&#x2F;blog&#x2F;post&#x2F;ring-buffer-in-golang" rel="nofollow">https:&#x2F;&#x2F;logdy.dev&#x2F;blog&#x2F;post&#x2F;ring-buffer-in-golang</a></div><br/></div></div><div id="39550799" class="c"><input type="checkbox" id="c-39550799" checked=""/><div class="controls bullet"><span class="by">ChrisMarshallNY</span><span>|</span><a href="#39551352">prev</a><span>|</span><a href="#39551328">next</a><span>|</span><label class="collapse" for="c-39550799">[-]</label><label class="expand" for="c-39550799">[2 more]</label></div><br/><div class="children"><div class="content">That watermark is a simple, elegant idea.<p>I haven&#x27;t really had the need for that kind of thing, in many years, but I like the idea.</div><br/><div id="39551709" class="c"><input type="checkbox" id="c-39551709" checked=""/><div class="controls bullet"><span class="by">loeg</span><span>|</span><a href="#39550799">parent</a><span>|</span><a href="#39551328">next</a><span>|</span><label class="collapse" for="c-39551709">[-]</label><label class="expand" for="c-39551709">[1 more]</label></div><br/><div class="children"><div class="content">Recently (2022) I designed a ring buffer for use as a &#x27;flight recorder&#x27; type tracing system.  (I.e., there is typically no reader; the writer needs to write over old records without blocking on any reader.  If the reader is triggered, it flips a switch that disables the writer temporarily while the buffer contents are persisted.)  In that design I subdivided the ring into several subbuffers (~8).  Each subbuffer has its own equivalent of a watermark.  That way, the valid portion of the ring always starts at the beginning of one of the subbuffers, and the writer could &#x27;free&#x27; the next subbuffer worth of space trivially (without having to scan through old contents record by record).  (Any write that did not fit in the current subbuffer was advanced to the start of the next one.)</div><br/></div></div></div></div><div id="39551328" class="c"><input type="checkbox" id="c-39551328" checked=""/><div class="controls bullet"><span class="by">liquid153</span><span>|</span><a href="#39550799">prev</a><span>|</span><a href="#39550348">next</a><span>|</span><label class="collapse" for="c-39551328">[-]</label><label class="expand" for="c-39551328">[10 more]</label></div><br/><div class="children"><div class="content">Aren&#x27;t lock free buffers usually just as expensive or more expensive to use as locks.</div><br/><div id="39551575" class="c"><input type="checkbox" id="c-39551575" checked=""/><div class="controls bullet"><span class="by">loeg</span><span>|</span><a href="#39551328">parent</a><span>|</span><a href="#39551366">next</a><span>|</span><label class="collapse" for="c-39551575">[-]</label><label class="expand" for="c-39551575">[1 more]</label></div><br/><div class="children"><div class="content">No -- for a lock-free design with a single producer and consumer, it&#x27;s possible both are typically writing to independent regions of memory.  With a lock, both have to write the same cache line to take and release the lock.</div><br/></div></div><div id="39551366" class="c"><input type="checkbox" id="c-39551366" checked=""/><div class="controls bullet"><span class="by">zengid</span><span>|</span><a href="#39551328">parent</a><span>|</span><a href="#39551575">prev</a><span>|</span><a href="#39551885">next</a><span>|</span><label class="collapse" for="c-39551366">[-]</label><label class="expand" for="c-39551366">[2 more]</label></div><br/><div class="children"><div class="content">Not if your program needs to be realtime or near realtime safe. Locks are controlled by the OS typically, and can have non-deterministic latency.</div><br/><div id="39551602" class="c"><input type="checkbox" id="c-39551602" checked=""/><div class="controls bullet"><span class="by">loeg</span><span>|</span><a href="#39551328">root</a><span>|</span><a href="#39551366">parent</a><span>|</span><a href="#39551885">next</a><span>|</span><label class="collapse" for="c-39551602">[-]</label><label class="expand" for="c-39551602">[1 more]</label></div><br/><div class="children"><div class="content">Even ignoring mutexes and OS scheduling, plain spinlocks add contention that would not otherwise exist in a SPSC ringbuffer.  <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=39551575">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=39551575</a></div><br/></div></div></div></div><div id="39551885" class="c"><input type="checkbox" id="c-39551885" checked=""/><div class="controls bullet"><span class="by">ww520</span><span>|</span><a href="#39551328">parent</a><span>|</span><a href="#39551366">prev</a><span>|</span><a href="#39551447">next</a><span>|</span><label class="collapse" for="c-39551885">[-]</label><label class="expand" for="c-39551885">[5 more]</label></div><br/><div class="children"><div class="content">Lock free has two advantages: the checking code can run in user mode and non-contested access is very cheap with just one instruction.<p>To do it correctly, lock needs to be done in the kernel thus obtaining a lock requires calling into the kernel which is more expensive.<p>I think you meant the memory barrier for syncing cache is just as expensive as the lock version, which is true.</div><br/><div id="39552204" class="c"><input type="checkbox" id="c-39552204" checked=""/><div class="controls bullet"><span class="by">scaredginger</span><span>|</span><a href="#39551328">root</a><span>|</span><a href="#39551885">parent</a><span>|</span><a href="#39551447">next</a><span>|</span><label class="collapse" for="c-39552204">[-]</label><label class="expand" for="c-39552204">[4 more]</label></div><br/><div class="children"><div class="content">Obtaining an uncontested lock absolutely doesn&#x27;t require calling into the kernel</div><br/><div id="39552375" class="c"><input type="checkbox" id="c-39552375" checked=""/><div class="controls bullet"><span class="by">jcelerier</span><span>|</span><a href="#39551328">root</a><span>|</span><a href="#39552204">parent</a><span>|</span><a href="#39551447">next</a><span>|</span><label class="collapse" for="c-39552375">[-]</label><label class="expand" for="c-39552375">[3 more]</label></div><br/><div class="children"><div class="content">How can you give hard guarantees that on Windows, Mac, Linux with the OS and&#x2F;or libc provided locks?</div><br/><div id="39557596" class="c"><input type="checkbox" id="c-39557596" checked=""/><div class="controls bullet"><span class="by">tialaramex</span><span>|</span><a href="#39551328">root</a><span>|</span><a href="#39552375">parent</a><span>|</span><a href="#39554065">next</a><span>|</span><label class="collapse" for="c-39557596">[-]</label><label class="expand" for="c-39557596">[1 more]</label></div><br/><div class="children"><div class="content">Rust (which is what we&#x27;re discussing here) actually doesn&#x27;t promise this in general. But for the three operating systems you mentioned that is in fact what it delivers because as another commenter mentioned it&#x27;s table stakes. If your OS can&#x27;t do this it&#x27;s a toy OS.<p>The Windows and Linux solutions are by Mara Bos (the MacOS one might be too, I don&#x27;t know)<p>The Windows one is very elegant but opaque. Basically Microsoft provides an appropriate API (&quot;Slim Reader&#x2F;Writer Locks&quot;) and Mara&#x27;s code just uses that API.<p>The Linux one shows exactly how to use a Futex: if you know what a futex is, yeah, Rust just uses a futex. If you don&#x27;t, go read about the Futex, it&#x27;s clever.</div><br/></div></div><div id="39554065" class="c"><input type="checkbox" id="c-39554065" checked=""/><div class="controls bullet"><span class="by">gpderetta</span><span>|</span><a href="#39551328">root</a><span>|</span><a href="#39552375">parent</a><span>|</span><a href="#39557596">prev</a><span>|</span><a href="#39551447">next</a><span>|</span><label class="collapse" for="c-39554065">[-]</label><label class="expand" for="c-39554065">[1 more]</label></div><br/><div class="children"><div class="content">If you really really really need such a guarantee, you implement your own.<p>Otherwise you inspect the implementation, but in 2024 a fast-pathed OS lock is table stakes.</div><br/></div></div></div></div></div></div></div></div><div id="39551447" class="c"><input type="checkbox" id="c-39551447" checked=""/><div class="controls bullet"><span class="by">CyberDildonics</span><span>|</span><a href="#39551328">parent</a><span>|</span><a href="#39551885">prev</a><span>|</span><a href="#39550348">next</a><span>|</span><label class="collapse" for="c-39551447">[-]</label><label class="expand" for="c-39551447">[1 more]</label></div><br/><div class="children"><div class="content">No, where are you getting that information?</div><br/></div></div></div></div><div id="39550348" class="c"><input type="checkbox" id="c-39550348" checked=""/><div class="controls bullet"><span class="by">stmblast</span><span>|</span><a href="#39551328">prev</a><span>|</span><a href="#39556001">next</a><span>|</span><label class="collapse" for="c-39550348">[-]</label><label class="expand" for="c-39550348">[1 more]</label></div><br/><div class="children"><div class="content">Awesome article! Bookmarked.</div><br/></div></div><div id="39556001" class="c"><input type="checkbox" id="c-39556001" checked=""/><div class="controls bullet"><span class="by">LAC-Tech</span><span>|</span><a href="#39550348">prev</a><span>|</span><a href="#39550401">next</a><span>|</span><label class="collapse" for="c-39556001">[-]</label><label class="expand" for="c-39556001">[1 more]</label></div><br/><div class="children"><div class="content">TIL about BipBuffers. I&#x27;ve been struggling with a similar data structure, and to see it already has a name, and a better implementation than what I&#x27;ve been doing, is very welcome.</div><br/></div></div></div></div></div></div></div></body></html>