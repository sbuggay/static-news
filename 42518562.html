<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1735290050552" as="style"/><link rel="stylesheet" href="styles.css?v=1735290050552"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://blog.codingconfessions.com/p/the-cap-theorem-of-clustering">The CAP theorem of Clustering: Why Every Algorithm Must Sacrifice Something</a>Â <span class="domain">(<a href="https://blog.codingconfessions.com">blog.codingconfessions.com</a>)</span></div><div class="subtext"><span>fagnerbrack</span> | <span>8 comments</span></div><br/><div><div id="42518888" class="c"><input type="checkbox" id="c-42518888" checked=""/><div class="controls bullet"><span class="by">throw_pm23</span><span>|</span><a href="#42518782">next</a><span>|</span><label class="collapse" for="c-42518888">[-]</label><label class="expand" for="c-42518888">[4 more]</label></div><br/><div class="children"><div class="content">A cute and thought-provoking theorem for sure, but arguably none of the three given criteria for clustering are well motivated, so the result is much less relevant than usually claimed.<p>- scale-invariance: stretching data along some dimensions should not change clustering.<p>This is clearly not true:  . . . (three well-spaced spots) may be reasonably seen as three clusters, whereas ||| (three nearby elongated bars) not.<p>- richness: all groupings must be reachable.<p>Also not quite true, both of the two cases: (1) all clusters are singleton points and (2) a single cluster that contains all points, mean the same: no useful cluster structure found. So it is enough if one of these groupings are reachable, and not both.<p>- consistency: increasing inter-cluster differences and decreasing intra-cluster differences should not change clustering.<p>Also not quite true: suppose we have 9 clusters:<p><pre><code>  . . .
  . . .
  . . .
</code></pre>
now move the points so that the columns get further apart, at some point we will get:
|  |  |, where 3 clusters are more reasonable.</div><br/><div id="42519025" class="c"><input type="checkbox" id="c-42519025" checked=""/><div class="controls bullet"><span class="by">yshklarov</span><span>|</span><a href="#42518888">parent</a><span>|</span><a href="#42520613">next</a><span>|</span><label class="collapse" for="c-42519025">[-]</label><label class="expand" for="c-42519025">[2 more]</label></div><br/><div class="children"><div class="content">Actually, scale-invariance only refers to scaling <i>all dimensions by the same scalar</i> (this is more clearly specificed in the paper linked by the article, page 3). For arbitrary scaling on <i>each</i> coordinate, of course you&#x27;re correct, it&#x27;s impossible to have a clustering algorithm that is invariant for such transformations (e.g., the 6-point group ::: may look like either 2 or 3 clusters, depending on whether it&#x27;s stretched horizontally or vertically).<p>As for your last two points, I believe I agree! It seems that in the counterexample you give for consistency, some notion of scale-invariance is implicitly assumed -- perhaps this connection plays some role in the theorem&#x27;s proof (which I haven&#x27;t read).<p>This reminds me a bit of Arrow&#x27;s impossibility theorem for voting, which similarly has questionable premises.</div><br/><div id="42520657" class="c"><input type="checkbox" id="c-42520657" checked=""/><div class="controls bullet"><span class="by">hnaccount_rng</span><span>|</span><a href="#42518888">root</a><span>|</span><a href="#42519025">parent</a><span>|</span><a href="#42520613">next</a><span>|</span><label class="collapse" for="c-42520657">[-]</label><label class="expand" for="c-42520657">[1 more]</label></div><br/><div class="children"><div class="content">But in almost all cases that doesn&#x27;t make any sense? Typically the data in different dimensions will have different &quot;units&quot;. So there isn&#x27;t any meaning in the scale in the first place. How could scaling by a single scalar be &quot;more natural&quot;?</div><br/></div></div></div></div><div id="42520613" class="c"><input type="checkbox" id="c-42520613" checked=""/><div class="controls bullet"><span class="by">nextaccountic</span><span>|</span><a href="#42518888">parent</a><span>|</span><a href="#42519025">prev</a><span>|</span><a href="#42518782">next</a><span>|</span><label class="collapse" for="c-42520613">[-]</label><label class="expand" for="c-42520613">[1 more]</label></div><br/><div class="children"><div class="content">Scale invariance is well motivated in the sense that perhaps you already normalized your data (usually to fit [-1, 1] or something) and you would be bummed to discover it fucked up your clusters<p>Or likewise: if you have physical data recorded in some units (say, meters), it would suck if the clusters changed if you had measured stuff in another unit instead</div><br/></div></div></div></div><div id="42518782" class="c"><input type="checkbox" id="c-42518782" checked=""/><div class="controls bullet"><span class="by">joe_the_user</span><span>|</span><a href="#42518888">prev</a><span>|</span><a href="#42519091">next</a><span>|</span><label class="collapse" for="c-42518782">[-]</label><label class="expand" for="c-42518782">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s interesting idea but so I don&#x27;t see it as a matter of tradeoffs since just the &quot;richness&quot; sounds undecidable by itself. I mean, dividing a set into &quot;things have low Kolmogorov complexity and things having high Kolmogorov complexity&quot; is definitely undecidable so &quot;any grouping that might make sense for your data&quot; seems impossible without any other requirements.</div><br/><div id="42519166" class="c"><input type="checkbox" id="c-42519166" checked=""/><div class="controls bullet"><span class="by">ironSkillet</span><span>|</span><a href="#42518782">parent</a><span>|</span><a href="#42519091">next</a><span>|</span><label class="collapse" for="c-42519166">[-]</label><label class="expand" for="c-42519166">[1 more]</label></div><br/><div class="children"><div class="content">The &quot;richness&quot; definition also seemed hand wavey to me so I looked at the referenced paper. The actual definition of &quot;richness&quot; of an algorithm is that for any arbitrary partition P of your original data (singletons, one cluster, etc), there is a distance function on the data, which when used in the clustering algorithm, produces P.</div><br/></div></div></div></div><div id="42519091" class="c"><input type="checkbox" id="c-42519091" checked=""/><div class="controls bullet"><span class="by">jpcom</span><span>|</span><a href="#42518782">prev</a><span>|</span><label class="collapse" for="c-42519091">[-]</label><label class="expand" for="c-42519091">[1 more]</label></div><br/><div class="children"><div class="content">Sounds like Richness is an index in SQL terms.  Would you agree?</div><br/></div></div></div></div></div></div></div></body></html>