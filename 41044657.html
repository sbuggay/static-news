<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1721898068683" as="style"/><link rel="stylesheet" href="styles.css?v=1721898068683"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://tigerbeetle.com/blog/2024-07-23-rediscovering-transaction-processing-from-history-and-first-principles">Rediscovering Transaction Processing from History and First Principles</a> <span class="domain">(<a href="https://tigerbeetle.com">tigerbeetle.com</a>)</span></div><div class="subtext"><span>todsacerdoti</span> | <span>23 comments</span></div><br/><div><div id="41065758" class="c"><input type="checkbox" id="c-41065758" checked=""/><div class="controls bullet"><span class="by">sriram_malhar</span><span>|</span><a href="#41061639">next</a><span>|</span><label class="collapse" for="c-41065758">[-]</label><label class="expand" for="c-41065758">[1 more]</label></div><br/><div class="children"><div class="content">In the banking transactional set ups I am familiar with, a transaction doesn&#x27;t succeed unless there is sufficient balance, and if not, check if there is sufficient overdraft protection, or an alternate account from which funds can be debited.<p>Are these possible to do in a tigerbeetle setup before the debit&#x2F;credit transaction is recorded?<p>What I am trying to say is,  if it is merely recording debit&#x2F;credits, it is basically a log of desired transactions.<p>Applying that log requires a possibly extensive series of checks and multiple accounts in practice, which can fail, and you&#x27;ll have to issue a compensating transaction. Much more messy than if the check were done before committing the transaction.</div><br/></div></div><div id="41061639" class="c"><input type="checkbox" id="c-41061639" checked=""/><div class="controls bullet"><span class="by">jorangreef</span><span>|</span><a href="#41065758">prev</a><span>|</span><a href="#41063985">next</a><span>|</span><label class="collapse" for="c-41061639">[-]</label><label class="expand" for="c-41061639">[5 more]</label></div><br/><div class="children"><div class="content">Joran from TigerBeetle here! Really stoked to see a bit of Jim Gray history on the front page and happy to dive into how TB&#x27;s consensus and storage engine implements these ideas (starting from main! <a href="https:&#x2F;&#x2F;github.com&#x2F;tigerbeetle&#x2F;tigerbeetle&#x2F;blob&#x2F;main&#x2F;src&#x2F;tigerbeetle&#x2F;main.zig">https:&#x2F;&#x2F;github.com&#x2F;tigerbeetle&#x2F;tigerbeetle&#x2F;blob&#x2F;main&#x2F;src&#x2F;tig...</a>).</div><br/><div id="41063525" class="c"><input type="checkbox" id="c-41063525" checked=""/><div class="controls bullet"><span class="by">nickpeterson</span><span>|</span><a href="#41061639">parent</a><span>|</span><a href="#41064634">next</a><span>|</span><label class="collapse" for="c-41063525">[-]</label><label class="expand" for="c-41063525">[2 more]</label></div><br/><div class="children"><div class="content">I’m curious if you ever came across any of the writings of Toon Koppelaars and the idea of ThickDB&#x2F;SmartDB, it seems very in alignment.</div><br/><div id="41066335" class="c"><input type="checkbox" id="c-41066335" checked=""/><div class="controls bullet"><span class="by">jorangreef</span><span>|</span><a href="#41061639">root</a><span>|</span><a href="#41063525">parent</a><span>|</span><a href="#41064634">next</a><span>|</span><label class="collapse" for="c-41066335">[-]</label><label class="expand" for="c-41066335">[1 more]</label></div><br/><div class="children"><div class="content">Thanks, I hadn&#x27;t. Looking into it, I suppose Toon is asking the question:<p>Should the DBMS expose the raw storage operations (insert, update, delete) for the application to take responsibility for the correctness of their physical composition into logical functionality? Or should the DBMS simply export that logical functionality?</div><br/></div></div></div></div><div id="41064634" class="c"><input type="checkbox" id="c-41064634" checked=""/><div class="controls bullet"><span class="by">westurner</span><span>|</span><a href="#41061639">parent</a><span>|</span><a href="#41063525">prev</a><span>|</span><a href="#41063985">next</a><span>|</span><label class="collapse" for="c-41064634">[-]</label><label class="expand" for="c-41064634">[2 more]</label></div><br/><div class="children"><div class="content">TPS: Transactions Per Second: <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Transactions_per_second" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Transactions_per_second</a><p>&quot;A Measure of Transaction Processing Power&quot; (1985)<p>&quot;A measure of transaction processing 20 years later&quot; (2005) <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;cs&#x2F;0701162" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;cs&#x2F;0701162</a> .. <a href="https:&#x2F;&#x2F;scholar.google.com&#x2F;scholar?cluster=11019087883708435479&amp;hl=en&amp;as_sdt=5,43&amp;sciodt=0,43" rel="nofollow">https:&#x2F;&#x2F;scholar.google.com&#x2F;scholar?cluster=11019087883708435...</a><p>About the cover sheet on those TPS reports.<p>Max throughput, max efficiency,<p>Network throughput: <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Network_throughput" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Network_throughput</a><p>&quot;Is measuring blockchain transactions per second (TPS) stupid in 2024? Big Questions&quot;
<a href="https:&#x2F;&#x2F;cointelegraph.com&#x2F;magazine&#x2F;blockchain-transactions-per-second-tps-stupid-big-questions&#x2F;" rel="nofollow">https:&#x2F;&#x2F;cointelegraph.com&#x2F;magazine&#x2F;blockchain-transactions-p...</a> :<p>&gt; <i>focusing on the raw TPS number is a bit like “counting the number of bills in your wallet but ignoring that some are singles, some are twenties, and some are hundreds.” </i><p><a href="https:&#x2F;&#x2F;chainspect.app&#x2F;dashboard" rel="nofollow">https:&#x2F;&#x2F;chainspect.app&#x2F;dashboard</a> describes each of their metrics: 
Real-Time TPS (tx&#x2F;s),
Max Recorded TPS (tx&#x2F;s),
Max Theoretical TPS (tx&#x2F;s),
Block Time (s), 
Finality (s)<p>USD&#x2F;day probably doesn&#x27;t predict TPS; because the <i>Average transaction value</i> is higher on networks with low TPS.<p>Other metrics: FLOPS, FLOPS&#x2F;WHr, TOPS, TOPS&#x2F;WHr, $&#x2F;OPS&#x2F;WHr<p>And then there&#x27;s Uptime; or losses due to downtime (given SLA prorated costs)</div><br/><div id="41066363" class="c"><input type="checkbox" id="c-41066363" checked=""/><div class="controls bullet"><span class="by">jorangreef</span><span>|</span><a href="#41061639">root</a><span>|</span><a href="#41064634">parent</a><span>|</span><a href="#41063985">next</a><span>|</span><label class="collapse" for="c-41066363">[-]</label><label class="expand" for="c-41066363">[1 more]</label></div><br/><div class="children"><div class="content">&gt; &quot;A measure of transaction processing 20 years later (2005)&quot;<p>This is one of my favorites. Along with <a href="https:&#x2F;&#x2F;www.microsoft.com&#x2F;en-us&#x2F;research&#x2F;wp-content&#x2F;uploads&#x2F;2005&#x2F;04&#x2F;tr-2005-39.doc" rel="nofollow">https:&#x2F;&#x2F;www.microsoft.com&#x2F;en-us&#x2F;research&#x2F;wp-content&#x2F;uploads&#x2F;...</a> (also 20 years later) which has more detail.<p>&gt; USD&#x2F;day probably doesn&#x27;t predict TPS; because the Average transaction value is higher on networks with low TPS.<p>Exactly. If you only look at the USD&#x2F;day you might not see a trend in transaction volume. What&#x27;s happened is like a TV set going from B&amp;W to full color 4K. If you look at the dimensions of the TV, it&#x27;s pretty much the same. But the number of pixels (txns) and their size (value) has become significantly higher resolution across sectors.</div><br/></div></div></div></div></div></div><div id="41063985" class="c"><input type="checkbox" id="c-41063985" checked=""/><div class="controls bullet"><span class="by">jjmarr</span><span>|</span><a href="#41061639">prev</a><span>|</span><a href="#41065344">next</a><span>|</span><label class="collapse" for="c-41063985">[-]</label><label class="expand" for="c-41063985">[1 more]</label></div><br/><div class="children"><div class="content">I went on your website and discovered your simulator:<p><a href="https:&#x2F;&#x2F;sim.tigerbeetle.com&#x2F;" rel="nofollow">https:&#x2F;&#x2F;sim.tigerbeetle.com&#x2F;</a><p>It looks cool but is confusing as it&#x27;s impossible for me to actually &quot;win&quot;.<p>Is there any chance you could add a mode with a regular database so I can get the enjoyment of learning how to break it? I can&#x27;t appreciate how hard it is to crash TigerBeetle since I don&#x27;t have a frame of reference.<p>More in-game explanations on what&#x27;s happening would be useful as well.</div><br/></div></div><div id="41065344" class="c"><input type="checkbox" id="c-41065344" checked=""/><div class="controls bullet"><span class="by">victorbjorklund</span><span>|</span><a href="#41063985">prev</a><span>|</span><a href="#41044746">next</a><span>|</span><label class="collapse" for="c-41065344">[-]</label><label class="expand" for="c-41065344">[1 more]</label></div><br/><div class="children"><div class="content">&gt; For each financial transaction, there would be 10-20 SQL queries back and forth across the network, while holding row locks.<p>Cant you do that with postgresql with custom functions? That way you just send the info once and it does all the processing in the db.</div><br/></div></div><div id="41044746" class="c"><input type="checkbox" id="c-41044746" checked=""/><div class="controls bullet"><span class="by">simonz05</span><span>|</span><a href="#41065344">prev</a><span>|</span><a href="#41061199">next</a><span>|</span><label class="collapse" for="c-41044746">[-]</label><label class="expand" for="c-41044746">[2 more]</label></div><br/><div class="children"><div class="content">In this X thead Joran comments how it all started with a HN comment back in 2019. <a href="https:&#x2F;&#x2F;x.com&#x2F;jorandirkgreef&#x2F;status&#x2F;1815702485190774957" rel="nofollow">https:&#x2F;&#x2F;x.com&#x2F;jorandirkgreef&#x2F;status&#x2F;1815702485190774957</a></div><br/><div id="41062759" class="c"><input type="checkbox" id="c-41062759" checked=""/><div class="controls bullet"><span class="by">jorangreef</span><span>|</span><a href="#41044746">parent</a><span>|</span><a href="#41061199">next</a><span>|</span><label class="collapse" for="c-41062759">[-]</label><label class="expand" for="c-41062759">[1 more]</label></div><br/><div class="children"><div class="content">It was pretty surreal to sit next to someone at a dinner in NYC two months ago, be introduced, and realize that they&#x27;re someone you had an HN exchange with 5 years ago.<p>Here&#x27;s the HN thread: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=20352439">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=20352439</a><p>And the backstory (on how this led to TigerBeetle): <a href="https:&#x2F;&#x2F;x.com&#x2F;jorandirkgreef&#x2F;status&#x2F;1788930243077853234" rel="nofollow">https:&#x2F;&#x2F;x.com&#x2F;jorandirkgreef&#x2F;status&#x2F;1788930243077853234</a></div><br/></div></div></div></div><div id="41061199" class="c"><input type="checkbox" id="c-41061199" checked=""/><div class="controls bullet"><span class="by">mihaic</span><span>|</span><a href="#41044746">prev</a><span>|</span><label class="collapse" for="c-41061199">[-]</label><label class="expand" for="c-41061199">[12 more]</label></div><br/><div class="children"><div class="content">I honestly don&#x27;t understand why this isn&#x27;t a Postgres extension. In what case is it better to have two databases?<p>Realistically, I can&#x27;t see a scenario where you need something like this but at the same time are sure that you don&#x27;t need both atomic database and financial ledger operations.</div><br/><div id="41061388" class="c"><input type="checkbox" id="c-41061388" checked=""/><div class="controls bullet"><span class="by">twic</span><span>|</span><a href="#41061199">parent</a><span>|</span><a href="#41061851">next</a><span>|</span><label class="collapse" for="c-41061388">[-]</label><label class="expand" for="c-41061388">[7 more]</label></div><br/><div class="children"><div class="content">&gt; We saw that there were greater gains to be had than settling for a Postgres extension or stored procedures.<p>&gt; Today, as we announce our Series A of $24 million<p>Can&#x27;t raise a 24 million series A for a Postgres extension!</div><br/><div id="41064468" class="c"><input type="checkbox" id="c-41064468" checked=""/><div class="controls bullet"><span class="by">sakras</span><span>|</span><a href="#41061199">root</a><span>|</span><a href="#41061388">parent</a><span>|</span><a href="#41061426">next</a><span>|</span><label class="collapse" for="c-41064468">[-]</label><label class="expand" for="c-41064468">[1 more]</label></div><br/><div class="children"><div class="content">TimescaleDB&#x27;s $110M series C would like to have a word :)</div><br/></div></div><div id="41061426" class="c"><input type="checkbox" id="c-41061426" checked=""/><div class="controls bullet"><span class="by">mihaic</span><span>|</span><a href="#41061199">root</a><span>|</span><a href="#41061388">parent</a><span>|</span><a href="#41064468">prev</a><span>|</span><a href="#41063604">next</a><span>|</span><label class="collapse" for="c-41061426">[-]</label><label class="expand" for="c-41061426">[4 more]</label></div><br/><div class="children"><div class="content">That&#x27;s true, but who are the executives that buy this and then force developers to create a monstrous architecture that has all sorts of race conditions outside of the ledger?</div><br/><div id="41062017" class="c"><input type="checkbox" id="c-41062017" checked=""/><div class="controls bullet"><span class="by">jorangreef</span><span>|</span><a href="#41061199">root</a><span>|</span><a href="#41061426">parent</a><span>|</span><a href="#41063604">next</a><span>|</span><label class="collapse" for="c-41062017">[-]</label><label class="expand" for="c-41062017">[3 more]</label></div><br/><div class="children"><div class="content">To be clear, TB moves the code to the data, rather than the data to the code, and precisely so that you don&#x27;t have &quot;race conditions outside the ledger&quot;.<p>Instead, all kinds of complicated debit&#x2F;credit contracts (up to 8k financial transactions at a time, linked together atomically) can be expressed in a single request to the database, composed in terms of a rich set of debit&#x2F;credit primitives (e.g. two-phase debit&#x2F;credit with rollback after a timeout), to enforce financial consistency directly in the database.<p>On the other hand, moving the data to the code, to make decisions outside the OLTP database was exactly the anti-pattern we were wanting to fix in the central bank switch, as it tried to implement debit&#x2F;credit primitives but over general-purpose DBMS. It&#x27;s really hard to get these things right on top of Postgres.<p>And even if you get the primitives right, the performance is fundamentally limited by row locks interacting with RTTs and contention. Again, these row locks are not only external, but also internal (i.e. how I&#x2F;O interacts with CPU inside the DBMS), and why stored procedures or extensions aren&#x27;t enough to fix the performance.</div><br/><div id="41063779" class="c"><input type="checkbox" id="c-41063779" checked=""/><div class="controls bullet"><span class="by">RaftPeople</span><span>|</span><a href="#41061199">root</a><span>|</span><a href="#41062017">parent</a><span>|</span><a href="#41063604">next</a><span>|</span><label class="collapse" for="c-41063779">[-]</label><label class="expand" for="c-41063779">[2 more]</label></div><br/><div class="children"><div class="content">Can you expand on why sproc isn&#x27;t a good solution (e.g. send set of requests, process those that are still in valid state, error those that aren&#x27;t, return responses)?<p>Maybe knowing the volumes you are dealing would help also.</div><br/></div></div></div></div></div></div></div></div><div id="41061851" class="c"><input type="checkbox" id="c-41061851" checked=""/><div class="controls bullet"><span class="by">jorangreef</span><span>|</span><a href="#41061199">parent</a><span>|</span><a href="#41061388">prev</a><span>|</span><label class="collapse" for="c-41061851">[-]</label><label class="expand" for="c-41061851">[4 more]</label></div><br/><div class="children"><div class="content">Hey mihaic! Thanks for the question.<p>&gt; I honestly don&#x27;t understand why this isn&#x27;t a Postgres extension.<p>We considered a Postgres extension at the time (as well as stored procedures or even an embedded in-process DBMS).<p>However, this wouldn’t have moved the needle to where we needed it to be. Our internal design requirements (TB started as an internal project at Coil, contracting on a central bank switch) were literally a three order of magnitude increase in performance—to keep up with where transaction workloads were going.<p>While an extension or stored procedures would reduce external locking, the general-purpose DBMS design implementing them still tends to do far too much internal locking, interleaving disk I&#x2F;O with CPU and coupling resources. In contrast, TigerBeetle explicitly decouples disk I&#x2F;O and CPU to amortize internal locking and so “pipeline in bulk” for mechanical sympathy. Think SIMD vectorization but applied to state machine execution.<p>For example, before TB’s state machine executes 1 request of 8k transactions, all data dependencies are prefetched in advance (typically from L1&#x2F;2&#x2F;3 cache) so that the CPU becomes like a sprinter running the 100 meters. This suits extreme OLTP workloads where a few million debit&#x2F;credit transactions need to be pushed through less than 10 accounts&#x2F;rows (e.g. for a small central bank switch with 10 banks around the table). This is pathological for a general-purpose DBMS design, but easy for TB because hot accounts are hot in cache, and all locking (whether external or internal) is amortized across 8k transactions.<p>I spoke at QCon SF on this (<a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=32LMicc0gRA" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=32LMicc0gRA</a>) and matklad did two IronBeetle episodes walking through the code (<a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=v5ThOoK3OFw&amp;list=PL9eL-xg48OM3pnVqFSRyBFleHtBBw-nmZ&amp;index=34" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=v5ThOoK3OFw&amp;list=PL9eL-xg48O...</a>).<p>But the big problem with extensions or stored procedures is that they still tend to have a “one transaction at a time” mindset at the network layer. In other words, they don’t typically amortize network requests beyond a 1:1 ratio of logical transaction to physical SQL transaction; they’re not ergonomic if you want to pack a few thousand logical transactions in one physical query.<p>On the other hand, TB’s design is like “stored procedures meets group commit on steroids”, packing up to 8k logical transactions in 1 physical query, and amortizing the costs not only of state machine execution (as described above) but also syscalls, networking and fsync (it’s something roughly like 4 syscalls, 4 memcopies and 4 network messages to execute 8k transactions—really hard for Postgres to match that).<p>Postgres is also nearly 30 years old. It&#x27;s an awesome database but hardware, software and research into how you would design a transaction processing database today has advanced significantly since then. For example, we wanted more safety around things like Fsyncgate by having an explicit storage fault model. We also wanted deterministic simulation testing and static memory allocation, and to follow NASA&#x27;s Power of Ten Rules for Safety-Critical code.<p>A Postgres extension would have been a showstopper for these things, but these were the technical contributions that needed to be made.<p>I also think that some of the most interesting performance innovations (static memory allocation, zero-deserialization, zero-context switches, zero-syscalls etc.) are coming out of HFT these days. For example, Martin Thompson’s Evolution of Financial Exchange Architectures: <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=qDhTjE0XmkE" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=qDhTjE0XmkE</a><p>HFT is a great precursor to see where OLTP is going, because the major contention problem of OLTP is mostly solved by HFT architectures, and because the arbitrage and volume of HFT is now moving into other sectors—as the world becomes more transactional.<p>&gt; In what case is it better to have two databases?<p>Finally, regarding two databases, this was something we wanted explicit in the architecture. Not to &quot;mix cash and customer records&quot; in one general-purpose mutable filing cabinet, but rather to have &quot;separation of concerns&quot;, the variable-length customer records in the general-purpose DBMS (or filing cabinet) in the control plane, and the cash in the immutable financial transactions database (or bank vault) in the data plane.<p>See also: <a href="https:&#x2F;&#x2F;docs.tigerbeetle.com&#x2F;coding&#x2F;system-architecture" rel="nofollow">https:&#x2F;&#x2F;docs.tigerbeetle.com&#x2F;coding&#x2F;system-architecture</a><p>It&#x27;s the same reason you would want Postgres + S3, or Postgres + Redpanda. Postgres is perfect as a general-purpose or OLGP database, but it&#x27;s not specialized for OLAP like DuckDB, or specialized for OLTP like TigerBeetle.<p>Again, appreciate the question and happy to answer more!</div><br/><div id="41064803" class="c"><input type="checkbox" id="c-41064803" checked=""/><div class="controls bullet"><span class="by">travis86</span><span>|</span><a href="#41061199">root</a><span>|</span><a href="#41061851">parent</a><span>|</span><a href="#41062074">next</a><span>|</span><label class="collapse" for="c-41064803">[-]</label><label class="expand" for="c-41064803">[1 more]</label></div><br/><div class="children"><div class="content">You mention in your post that you apply model checking on the actual code. Have you posted something where you go into more detail on that technique?</div><br/></div></div><div id="41062074" class="c"><input type="checkbox" id="c-41062074" checked=""/><div class="controls bullet"><span class="by">mihaic</span><span>|</span><a href="#41061199">root</a><span>|</span><a href="#41061851">parent</a><span>|</span><a href="#41064803">prev</a><span>|</span><label class="collapse" for="c-41062074">[-]</label><label class="expand" for="c-41062074">[2 more]</label></div><br/><div class="children"><div class="content">Thanks for taking the time for the explanation and the rundown on the architecture. Sounds a bit like an LMAX disruptor for DB, which honestly is quite a natural implementation of performance. Kudos for the Zig implementation as well, I&#x27;ve never seen a project as serious in it.<p>Personally, I still see challenges in developing on top of a system with data in two places unless there&#x27;s a nice way to sync between them, and I would have seen the mutable&#x2F;immutable classification as more of unlogged vs changes fully logged in DB, but I&#x27;m just doing armchair analysis here.</div><br/><div id="41062198" class="c"><input type="checkbox" id="c-41062198" checked=""/><div class="controls bullet"><span class="by">jorangreef</span><span>|</span><a href="#41061199">root</a><span>|</span><a href="#41062074">parent</a><span>|</span><label class="collapse" for="c-41062198">[-]</label><label class="expand" for="c-41062198">[1 more]</label></div><br/><div class="children"><div class="content">Huge pleasure! :)<p>Exactly, the Martin Thompson talk I linked above is about the LMAX architecture. He gave this at QCon London I think in May 2020 and we were designing TigerBeetle in July 2020, pretty much lapping this up (I&#x27;d been a fan of Thompson&#x27;s Mechanical Sympathy blog already for a few years by this point).<p>I think the way to see this is not as &quot;two places for the same type of data&quot; but rather as &quot;separation of concerns for radically different types of data&quot; with different compliance&#x2F;retention&#x2F;mutability&#x2F;access&#x2F;performance&#x2F;scale characteristics.<p>It&#x27;s also a natural architecture, and nothing new. How you would probably want to architect the &quot;core&quot; of a core banking system. We literally lifted the design for TigerBeetle directly out of the central bank switch&#x27;s internal core, so that it would be dead simple to &quot;heart transplant&quot; back in later.<p>The surprising thing though, was when small fintech startups, energy and gaming companies started reaching out. The primitives are easy to build with and unlock significantly more scale. Again, like using object storage in addition to Postgres is probably a good idea.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></body></html>