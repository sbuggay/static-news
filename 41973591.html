<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1730192458014" as="style"/><link rel="stylesheet" href="styles.css?v=1730192458014"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://openpipe.ai/blog/hacker-news-rlhf-part-1">Using reinforcement learning and $4.80 of GPU time to find the best HN post</a> <span class="domain">(<a href="https://openpipe.ai">openpipe.ai</a>)</span></div><div class="subtext"><span>kcorbitt</span> | <span>79 comments</span></div><br/><div><div id="41974461" class="c"><input type="checkbox" id="c-41974461" checked=""/><div class="controls bullet"><span class="by">jerjerjer</span><span>|</span><a href="#41974692">next</a><span>|</span><label class="collapse" for="c-41974461">[-]</label><label class="expand" for="c-41974461">[10 more]</label></div><br/><div class="children"><div class="content">&gt;  In this case, I included the post title, author, date, and content. All of those factors could be relevant to the chance a story gets voted up.<p>&gt; Even if the model gets extremely good at predicting final_score_if_it_hits_front_page, there’s still the inherent randomness of probability_of_hitting_front_page that is fundamentally unpredictable.<p>In addition to date, you might want to include three fields:<p>- day of week (categorical)<p>- is weekend&#x2F;holiday (boolean)<p>- hour or time of the day (categorical, you can have 24 of them or morning&#x2F;afternoon&#x2F;etc.).<p>The probability of a post hitting the front page is usually affected by these things so it can really help the model.</div><br/><div id="41975308" class="c"><input type="checkbox" id="c-41975308" checked=""/><div class="controls bullet"><span class="by">sitkack</span><span>|</span><a href="#41974461">parent</a><span>|</span><a href="#41977430">next</a><span>|</span><label class="collapse" for="c-41975308">[-]</label><label class="expand" for="c-41975308">[1 more]</label></div><br/><div class="children"><div class="content">I find that the best stories get posted by folks in EU time zones as well as the weekend (more of hacker ethos). The flame bait startup drama is M-F Pacific.</div><br/></div></div><div id="41977430" class="c"><input type="checkbox" id="c-41977430" checked=""/><div class="controls bullet"><span class="by">jedberg</span><span>|</span><a href="#41974461">parent</a><span>|</span><a href="#41975308">prev</a><span>|</span><a href="#41975357">next</a><span>|</span><label class="collapse" for="c-41977430">[-]</label><label class="expand" for="c-41977430">[5 more]</label></div><br/><div class="children"><div class="content">I haven&#x27;t run the data, but anecdotally I can tell you that those things probably don&#x27;t affect hitting the front page.  They <i>do</i> affect the total score, but that is not what is being optimized here.<p>It&#x27;s counterintuitive, but if you post at a really popular time, you&#x27;re competing with a lot of other submissions.  If you post at a really slow time, you&#x27;ll get fewer votes, but it will take fewer to reach the front page and you&#x27;ll have less competition.<p>In the end, it kinda evens out.  The number of votes it takes to get to the front page <i>and</i> the number of competing submissions are both correlated to your fields above.</div><br/><div id="41977527" class="c"><input type="checkbox" id="c-41977527" checked=""/><div class="controls bullet"><span class="by">floobertoober</span><span>|</span><a href="#41974461">root</a><span>|</span><a href="#41977430">parent</a><span>|</span><a href="#41978600">next</a><span>|</span><label class="collapse" for="c-41977527">[-]</label><label class="expand" for="c-41977527">[3 more]</label></div><br/><div class="children"><div class="content">I think that this assumes a uniform distribution of &quot;interestingness&quot; in the competing posts across all of those dimensions and I wouldn&#x27;t be surprised if that isn&#x27;t the case</div><br/><div id="41977556" class="c"><input type="checkbox" id="c-41977556" checked=""/><div class="controls bullet"><span class="by">jedberg</span><span>|</span><a href="#41974461">root</a><span>|</span><a href="#41977527">parent</a><span>|</span><a href="#41978600">next</a><span>|</span><label class="collapse" for="c-41977556">[-]</label><label class="expand" for="c-41977556">[2 more]</label></div><br/><div class="children"><div class="content">It may not be even, but I don&#x27;t think interestingness is correlated with time of day.  But I could be wrong!</div><br/><div id="41979425" class="c"><input type="checkbox" id="c-41979425" checked=""/><div class="controls bullet"><span class="by">sadeshmukh</span><span>|</span><a href="#41974461">root</a><span>|</span><a href="#41977556">parent</a><span>|</span><a href="#41978600">next</a><span>|</span><label class="collapse" for="c-41979425">[-]</label><label class="expand" for="c-41979425">[1 more]</label></div><br/><div class="children"><div class="content">Interestingness is subjective, and I would imagine different timezone people have different preferences. Interesting thing to ponder for a bit</div><br/></div></div></div></div></div></div><div id="41978600" class="c"><input type="checkbox" id="c-41978600" checked=""/><div class="controls bullet"><span class="by">4m1rk</span><span>|</span><a href="#41974461">root</a><span>|</span><a href="#41977430">parent</a><span>|</span><a href="#41977527">prev</a><span>|</span><a href="#41975357">next</a><span>|</span><label class="collapse" for="c-41978600">[-]</label><label class="expand" for="c-41978600">[1 more]</label></div><br/><div class="children"><div class="content">Popular time for voting vs posting are not the same</div><br/></div></div></div></div><div id="41975357" class="c"><input type="checkbox" id="c-41975357" checked=""/><div class="controls bullet"><span class="by">maaaaattttt</span><span>|</span><a href="#41974461">parent</a><span>|</span><a href="#41977430">prev</a><span>|</span><a href="#41974536">next</a><span>|</span><label class="collapse" for="c-41975357">[-]</label><label class="expand" for="c-41975357">[1 more]</label></div><br/><div class="children"><div class="content">I wonder if hour of day would benefit from being combined with HN&#x27;s visitors location data to be truly relevant? I think the location is embedded in the time somehow if the visitors&#x27; origins are stable over time. If 9am PT is a popular time and most of the visitors are on the PT timezone then even if this 9am PT is encoded as UTC the model will pick it up (I think). Now, if over time visitors get more diverse and a big chunk is now coming from Europe, this original 9am will make less sense to the model. Adding visitors origin stats at time of the post would probably even help surface region trends. But I guess this historical data isn&#x27;t public.</div><br/></div></div><div id="41974536" class="c"><input type="checkbox" id="c-41974536" checked=""/><div class="controls bullet"><span class="by">kcorbitt</span><span>|</span><a href="#41974461">parent</a><span>|</span><a href="#41975357">prev</a><span>|</span><a href="#41978438">next</a><span>|</span><label class="collapse" for="c-41974536">[-]</label><label class="expand" for="c-41974536">[1 more]</label></div><br/><div class="children"><div class="content">Yep that makes sense. Would be interesting to do a follow-up that explicitly includes these variables and see if it meaningfully improves the results.</div><br/></div></div><div id="41978438" class="c"><input type="checkbox" id="c-41978438" checked=""/><div class="controls bullet"><span class="by">aaron695</span><span>|</span><a href="#41974461">parent</a><span>|</span><a href="#41974536">prev</a><span>|</span><a href="#41974692">next</a><span>|</span><label class="collapse" for="c-41978438">[-]</label><label class="expand" for="c-41978438">[1 more]</label></div><br/><div class="children"><div class="content">&gt; might want to include three fields:<p>This has been studied multiple times on HN posts, most seem to have link-rotted.  Web Archive them if looking for insights - <a href="https:&#x2F;&#x2F;hn.algolia.com&#x2F;?q=best+time+to+post" rel="nofollow">https:&#x2F;&#x2F;hn.algolia.com&#x2F;?q=best+time+to+post</a></div><br/></div></div></div></div><div id="41974692" class="c"><input type="checkbox" id="c-41974692" checked=""/><div class="controls bullet"><span class="by">kelnos</span><span>|</span><a href="#41974461">prev</a><span>|</span><a href="#41974430">next</a><span>|</span><label class="collapse" for="c-41974692">[-]</label><label class="expand" for="c-41974692">[4 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t get the conclusion the author is trying to draw.  If you look at the data presented, it seems that the model was actually pretty bad at guessing the real-world behavior of the posts listed.  Out of the top ten it picked:<p>* 1 had a score that was reasonably close (8.4%) to what the model predicted<p>* 4 had scores wildly lower than the model predicted<p>* 2 had scores wildly higher than the model predicted<p>* the remaining 3 were not wildly off, but weren&#x27;t really that close either (25%-42% off)<p>Then there&#x27;s a list of 10 submissions that the model predicted would have scores ranging from 33 to 135, but they all only received a score of 1 in reality.<p>The graph shown paints a bit of a better picture, I guess, but it&#x27;s still not all that compelling to me.</div><br/><div id="41979908" class="c"><input type="checkbox" id="c-41979908" checked=""/><div class="controls bullet"><span class="by">manx</span><span>|</span><a href="#41974692">parent</a><span>|</span><a href="#41975661">next</a><span>|</span><label class="collapse" for="c-41979908">[-]</label><label class="expand" for="c-41979908">[1 more]</label></div><br/><div class="children"><div class="content">Scores are not a good metric to be compared. I did some data analysis and wrote about it here: <a href="https:&#x2F;&#x2F;felx.me&#x2F;2021&#x2F;08&#x2F;29&#x2F;improving-the-hacker-news-ranking-algorithm.html" rel="nofollow">https:&#x2F;&#x2F;felx.me&#x2F;2021&#x2F;08&#x2F;29&#x2F;improving-the-hacker-news-ranking...</a></div><br/></div></div><div id="41975661" class="c"><input type="checkbox" id="c-41975661" checked=""/><div class="controls bullet"><span class="by">kcorbitt</span><span>|</span><a href="#41974692">parent</a><span>|</span><a href="#41979908">prev</a><span>|</span><a href="#41979666">next</a><span>|</span><label class="collapse" for="c-41975661">[-]</label><label class="expand" for="c-41975661">[1 more]</label></div><br/><div class="children"><div class="content">This is a fair point. The reason why I think &quot;correlation&quot; is a better metric than &quot;predicts the exact correct score&quot; is because of how I&#x27;ll be using this model in the next post.<p>Broadly, the main use case for this model (in the RL context) will be to take two different versions of the same post, and predict which of the two is more likely to be upvoted. So what matters isn&#x27;t that it gets the exact number of upvotes correctly, but that it correctly predicts the relative difference in likely upvote count between two variants.<p>Now it still doesn&#x27;t do a <i>great</i> job at that (the correlation is only 0.53 after all) but it still does a good enough job to provide some useful signal.</div><br/></div></div><div id="41979666" class="c"><input type="checkbox" id="c-41979666" checked=""/><div class="controls bullet"><span class="by">nl</span><span>|</span><a href="#41974692">parent</a><span>|</span><a href="#41975661">prev</a><span>|</span><a href="#41974430">next</a><span>|</span><label class="collapse" for="c-41979666">[-]</label><label class="expand" for="c-41979666">[1 more]</label></div><br/><div class="children"><div class="content">The score divergence is likely because <i>if</i> a story makes the front page then it almost certainly gets comments and each comment adds one to the score.<p>But the number of comments depends on the time posted more than the story itself and that information isn&#x27;t in the model.</div><br/></div></div></div></div><div id="41974430" class="c"><input type="checkbox" id="c-41974430" checked=""/><div class="controls bullet"><span class="by">youoy</span><span>|</span><a href="#41974692">prev</a><span>|</span><a href="#41974087">next</a><span>|</span><label class="collapse" for="c-41974430">[-]</label><label class="expand" for="c-41974430">[6 more]</label></div><br/><div class="children"><div class="content">Thanks for sharing! Very interesting.<p>&gt; The correlation is actually not bad (0.53), but our model is very consistently over-estimating the score at the low end, and underestimating it at the high end. This is surprising; some variation on any given data point is expected, but such a consistent mis-estimation trend isn’t what we’d expect.<p>This is a consequence on the model objective. If you don&#x27;t know what is really happening, a good way of reducing the overall error is to do that. If you instead try to exactly predict the very highs and very lows, you can see that you will get very high errors on those, resulting in a bigger overall error.<p>Appart from that, I want to comment on AI alignment here. For me the objective of &quot;most up votes&quot; is not fully correlated with where I get the most value on HN. Most of the time, the most up voted I would have found them anyway on other platforms. It&#x27;s the middle range what I really like. So be careful implementing this algorithm at scale, it could turn the website into another platform with shitty AI recommendations.</div><br/><div id="41974696" class="c"><input type="checkbox" id="c-41974696" checked=""/><div class="controls bullet"><span class="by">kcorbitt</span><span>|</span><a href="#41974430">parent</a><span>|</span><a href="#41974087">next</a><span>|</span><label class="collapse" for="c-41974696">[-]</label><label class="expand" for="c-41974696">[5 more]</label></div><br/><div class="children"><div class="content">&gt; For me the objective of &quot;most up votes&quot; is not fully correlated with where I get the most value on HN. Most of the time, the most up voted I would have found them anyway on other platforms.<p>Yes, this is a fantastic point. I&#x27;m curious if there&#x27;s some other measurable proxy metric for &quot;things I get the most value out of on HN&quot;? Upvotes seems like the most natural but optimizing for it too strongly would definitely take HN down a dark path.</div><br/><div id="41977078" class="c"><input type="checkbox" id="c-41977078" checked=""/><div class="controls bullet"><span class="by">losteric</span><span>|</span><a href="#41974430">root</a><span>|</span><a href="#41974696">parent</a><span>|</span><a href="#41977646">next</a><span>|</span><label class="collapse" for="c-41977078">[-]</label><label class="expand" for="c-41977078">[3 more]</label></div><br/><div class="children"><div class="content">Perhaps selecting for posts with the highest quality reply engagement? If many different people were drawn to lengthy discussions, that suggests the content sparks thoughts that others then feel compelled to engage with. Or select for the emotional content of replies, awe&#x2F;empathy&#x2F;anger, depending on what one wants from HN?</div><br/><div id="41977376" class="c"><input type="checkbox" id="c-41977376" checked=""/><div class="controls bullet"><span class="by">hatthew</span><span>|</span><a href="#41974430">root</a><span>|</span><a href="#41977078">parent</a><span>|</span><a href="#41977345">next</a><span>|</span><label class="collapse" for="c-41977376">[-]</label><label class="expand" for="c-41977376">[1 more]</label></div><br/><div class="children"><div class="content">lots of platforms optimize for engagement, but all that does is encourage ragebait</div><br/></div></div><div id="41977345" class="c"><input type="checkbox" id="c-41977345" checked=""/><div class="controls bullet"><span class="by">kcorbitt</span><span>|</span><a href="#41974430">root</a><span>|</span><a href="#41977078">parent</a><span>|</span><a href="#41977376">prev</a><span>|</span><a href="#41977646">next</a><span>|</span><label class="collapse" for="c-41977345">[-]</label><label class="expand" for="c-41977345">[1 more]</label></div><br/><div class="children"><div class="content">Ohh, I really like that as a potential proxy metric!</div><br/></div></div></div></div><div id="41977646" class="c"><input type="checkbox" id="c-41977646" checked=""/><div class="controls bullet"><span class="by">coolcoder613</span><span>|</span><a href="#41974430">root</a><span>|</span><a href="#41974696">parent</a><span>|</span><a href="#41977078">prev</a><span>|</span><a href="#41974087">next</a><span>|</span><label class="collapse" for="c-41977646">[-]</label><label class="expand" for="c-41977646">[1 more]</label></div><br/><div class="children"><div class="content">Perhaps number of comments, or number of non-flamewar comments, or proportion of flamewar comments together with number of comments?</div><br/></div></div></div></div></div></div><div id="41974087" class="c"><input type="checkbox" id="c-41974087" checked=""/><div class="controls bullet"><span class="by">oli5679</span><span>|</span><a href="#41974430">prev</a><span>|</span><a href="#41980931">next</a><span>|</span><label class="collapse" for="c-41974087">[-]</label><label class="expand" for="c-41974087">[8 more]</label></div><br/><div class="children"><div class="content">If you withhold a small amount of data, or even retrain on a sample of your training data, then isotonicregression is good to solve many calibration problems.<p><a href="https:&#x2F;&#x2F;scikit-learn.org&#x2F;dev&#x2F;modules&#x2F;generated&#x2F;sklearn.isotonic.IsotonicRegression.html" rel="nofollow">https:&#x2F;&#x2F;scikit-learn.org&#x2F;dev&#x2F;modules&#x2F;generated&#x2F;sklearn.isoto...</a><p>I also agree with your intuition that if your output is censored at 0, with a large mass there, it&#x27;s good to create two models, one for likelihood of zero karma, and another expected karma, conditional on it being non-zero.</div><br/><div id="41974739" class="c"><input type="checkbox" id="c-41974739" checked=""/><div class="controls bullet"><span class="by">kcorbitt</span><span>|</span><a href="#41974087">parent</a><span>|</span><a href="#41974197">next</a><span>|</span><label class="collapse" for="c-41974739">[-]</label><label class="expand" for="c-41974739">[1 more]</label></div><br/><div class="children"><div class="content">I hadn&#x27;t heard of isotonicregression before but I like it!<p>&gt; it&#x27;s good to create two models, one for likelihood of zero karma, and another expected karma, conditional on it being non-zero.<p>Another way to do this is to keep a single model but have it predict two outputs: (1) likelihood of zero karma, and (2) expected karma if non-zero. This would require writing a custom loss function which sounds intimidating but actually isn&#x27;t too bad.<p>If I were actually putting a model like this into production at HN I&#x27;d likely try modeling the problem in that way.</div><br/></div></div><div id="41974197" class="c"><input type="checkbox" id="c-41974197" checked=""/><div class="controls bullet"><span class="by">Y_Y</span><span>|</span><a href="#41974087">parent</a><span>|</span><a href="#41974739">prev</a><span>|</span><a href="#41980931">next</a><span>|</span><label class="collapse" for="c-41974197">[-]</label><label class="expand" for="c-41974197">[6 more]</label></div><br/><div class="children"><div class="content">Did you dictate this? It looks like you typo&#x27;d&#x2F;brain I&#x27;d &quot;centered&quot; into &quot;censored&quot;, but even allowing for phonetic mistakes (of which I make many) and predictive text flubs, I still can&#x27;t understand how this happened.</div><br/><div id="41974388" class="c"><input type="checkbox" id="c-41974388" checked=""/><div class="controls bullet"><span class="by">oli5679</span><span>|</span><a href="#41974087">root</a><span>|</span><a href="#41974197">parent</a><span>|</span><a href="#41974312">next</a><span>|</span><label class="collapse" for="c-41974388">[-]</label><label class="expand" for="c-41974388">[3 more]</label></div><br/><div class="children"><div class="content">I was thinking of censoring, maybe I should have said another word like floored.<p>The reason I think of this as censoring is that there are are some classical statistical models that model a distribution with a large mass at a minimum threshold, e.g. &quot;tobit&quot; censored regression.<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Censoring_(statistics)" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Censoring_(statistics)</a></div><br/><div id="41974592" class="c"><input type="checkbox" id="c-41974592" checked=""/><div class="controls bullet"><span class="by">Y_Y</span><span>|</span><a href="#41974087">root</a><span>|</span><a href="#41974388">parent</a><span>|</span><a href="#41974312">next</a><span>|</span><label class="collapse" for="c-41974592">[-]</label><label class="expand" for="c-41974592">[2 more]</label></div><br/><div class="children"><div class="content">Thanks for the explanation. I never paid much attention in my stats lectures so I deserve to have missed out on that term-of-art. I think the physics lingo would be to call it &quot;capped&quot; or &quot;bounded&quot; or &quot;constrained&quot;.</div><br/><div id="41974665" class="c"><input type="checkbox" id="c-41974665" checked=""/><div class="controls bullet"><span class="by">oli5679</span><span>|</span><a href="#41974087">root</a><span>|</span><a href="#41974592">parent</a><span>|</span><a href="#41974312">next</a><span>|</span><label class="collapse" for="c-41974665">[-]</label><label class="expand" for="c-41974665">[1 more]</label></div><br/><div class="children"><div class="content">thanks, it&#x27;s very understandable that you thought i was mistyping &#x27;centred&#x27;.</div><br/></div></div></div></div></div></div><div id="41974312" class="c"><input type="checkbox" id="c-41974312" checked=""/><div class="controls bullet"><span class="by">CaptainFever</span><span>|</span><a href="#41974087">root</a><span>|</span><a href="#41974197">parent</a><span>|</span><a href="#41974388">prev</a><span>|</span><a href="#41975751">next</a><span>|</span><label class="collapse" for="c-41974312">[-]</label><label class="expand" for="c-41974312">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not the parent commenter, but whisper based dictation is getting pretty awesome nowadays. It&#x27;s almost as good as sci-fi.<p>(Fully dictated, no edits except for this)</div><br/></div></div><div id="41975751" class="c"><input type="checkbox" id="c-41975751" checked=""/><div class="controls bullet"><span class="by">1024core</span><span>|</span><a href="#41974087">root</a><span>|</span><a href="#41974197">parent</a><span>|</span><a href="#41974312">prev</a><span>|</span><a href="#41980931">next</a><span>|</span><label class="collapse" for="c-41975751">[-]</label><label class="expand" for="c-41975751">[1 more]</label></div><br/><div class="children"><div class="content">I also thought that the commenter spoke &quot;centered&quot; and the speech recognition model output &quot;censored&quot;.</div><br/></div></div></div></div></div></div><div id="41980931" class="c"><input type="checkbox" id="c-41980931" checked=""/><div class="controls bullet"><span class="by">octocop</span><span>|</span><a href="#41974087">prev</a><span>|</span><a href="#41979923">next</a><span>|</span><label class="collapse" for="c-41980931">[-]</label><label class="expand" for="c-41980931">[1 more]</label></div><br/><div class="children"><div class="content">Even the AI&#x27;s don&#x27;t read the content before up&#x2F;down voting.</div><br/></div></div><div id="41979923" class="c"><input type="checkbox" id="c-41979923" checked=""/><div class="controls bullet"><span class="by">manx</span><span>|</span><a href="#41980931">prev</a><span>|</span><a href="#41974489">next</a><span>|</span><label class="collapse" for="c-41979923">[-]</label><label class="expand" for="c-41979923">[1 more]</label></div><br/><div class="children"><div class="content">Very interesting! Identifying great new content is a big unsolved problem for HN IMHO. Unfortunately, scores are not a good metric to predict, because they are not comparable (see <a href="https:&#x2F;&#x2F;felx.me&#x2F;2021&#x2F;08&#x2F;29&#x2F;improving-the-hacker-news-ranking-algorithm.html" rel="nofollow">https:&#x2F;&#x2F;felx.me&#x2F;2021&#x2F;08&#x2F;29&#x2F;improving-the-hacker-news-ranking...</a>). A better metric might be &quot;upvoterate&quot;, defined as how much more or less likely users are to upvote a story compared to the average story. More about that here: <a href="https:&#x2F;&#x2F;github.com&#x2F;social-protocols&#x2F;quality-news?tab=readme-ov-file">https:&#x2F;&#x2F;github.com&#x2F;social-protocols&#x2F;quality-news?tab=readme-...</a></div><br/></div></div><div id="41974489" class="c"><input type="checkbox" id="c-41974489" checked=""/><div class="controls bullet"><span class="by">Arctic_fly</span><span>|</span><a href="#41979923">prev</a><span>|</span><a href="#41974207">next</a><span>|</span><label class="collapse" for="c-41974489">[-]</label><label class="expand" for="c-41974489">[1 more]</label></div><br/><div class="children"><div class="content">&gt; But in 2015 there is a stark discontinuity, where the number of stories (with text) shoots up by &gt;10x, and the average score drops by 5x! Is this some kind of eternal September?<p>Based on the later analysis in the post (which I agree with), the total score of a comment is disproportionately tied to whether it hits the front page, and of course how long it stays there. Regardless of the quality of the average post starting in 2015, the sheer quantity would make it impossible for all but a few to stay on the front page for very long. Hacker News got more popular, so each story got less prime time.</div><br/></div></div><div id="41974207" class="c"><input type="checkbox" id="c-41974207" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#41974489">prev</a><span>|</span><a href="#41973654">next</a><span>|</span><label class="collapse" for="c-41974207">[-]</label><label class="expand" for="c-41974207">[1 more]</label></div><br/><div class="children"><div class="content">&gt; &gt; This query took 17 seconds to load the dataset into RAM and then aggregating by type was almost instant. It is absolutely incredible to me that I can load every HN post and comment ever into RAM in a few seconds on my (admittedly beefy) dev laptop, and analyze them at will. What an age of abundance!<p><a href="https:&#x2F;&#x2F;motherduck.com&#x2F;blog&#x2F;big-data-is-dead&#x2F;" rel="nofollow">https:&#x2F;&#x2F;motherduck.com&#x2F;blog&#x2F;big-data-is-dead&#x2F;</a></div><br/></div></div><div id="41973654" class="c"><input type="checkbox" id="c-41973654" checked=""/><div class="controls bullet"><span class="by">kcorbitt</span><span>|</span><a href="#41974207">prev</a><span>|</span><a href="#41974111">next</a><span>|</span><label class="collapse" for="c-41973654">[-]</label><label class="expand" for="c-41973654">[2 more]</label></div><br/><div class="children"><div class="content">Hey all, this project was a labor of love I worked on in my spare time over the last couple of weeks. Happy to answer any questions!</div><br/><div id="41980512" class="c"><input type="checkbox" id="c-41980512" checked=""/><div class="controls bullet"><span class="by">Eisenstein</span><span>|</span><a href="#41973654">parent</a><span>|</span><a href="#41974111">next</a><span>|</span><label class="collapse" for="c-41980512">[-]</label><label class="expand" for="c-41980512">[1 more]</label></div><br/><div class="children"><div class="content">I think it is interesting, but I can&#x27;t help but feel that things like this result in the homogenizing and blandefying of content. It is like training a model to predict what movies will be successful at the box office -- the result will be the same kinds of movies over and over. No one knows what the breakthrough success is until it shows up, and no model can predict those. Essentially this is teaching people how to make HN full of nothing but complaints and indie success stories.<p>What is your take on this?</div><br/></div></div></div></div><div id="41974111" class="c"><input type="checkbox" id="c-41974111" checked=""/><div class="controls bullet"><span class="by">sdflhasjd</span><span>|</span><a href="#41973654">prev</a><span>|</span><a href="#41973938">next</a><span>|</span><label class="collapse" for="c-41974111">[-]</label><label class="expand" for="c-41974111">[14 more]</label></div><br/><div class="children"><div class="content">It&#x27;s interesting that service complaints are so popular on HN. I always feel a bit bad that my most popular HN contribution was me complaining about a popular service</div><br/><div id="41974435" class="c"><input type="checkbox" id="c-41974435" checked=""/><div class="controls bullet"><span class="by">Karrot_Kream</span><span>|</span><a href="#41974111">parent</a><span>|</span><a href="#41974729">next</a><span>|</span><label class="collapse" for="c-41974435">[-]</label><label class="expand" for="c-41974435">[9 more]</label></div><br/><div class="children"><div class="content">A popular theory on techie parts of the web is that engagement-optimizing sites create this negativity loop, but I disagree. I think negativity is naturally something that people seek no matter what the algorithm is. In an upvote based site, outrage ranks to the top. I also think text based platforms suffer from negative engagement much moreso than multimedia platforms.<p>Model correlation is decent here but there&#x27;s certainly more to do to use its outputs predictively.</div><br/><div id="41979468" class="c"><input type="checkbox" id="c-41979468" checked=""/><div class="controls bullet"><span class="by">johnfn</span><span>|</span><a href="#41974111">root</a><span>|</span><a href="#41974435">parent</a><span>|</span><a href="#41976235">next</a><span>|</span><label class="collapse" for="c-41979468">[-]</label><label class="expand" for="c-41979468">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t really agree with this. I go and hang out with my friends, and we don&#x27;t all end up getting outraged about stuff. I go for a walk in the park and no one is shouting at me; I go to a restaurant and people are sitting around normally discussing whatever. If you start quoting outrage bait that you read online, people might look at you strangely.<p>My point is I don&#x27;t think people seek out outrage. Social media&#x27;s algorithms may not explicitly reward it as transparently as `if (post.outrage &gt; 100) post.boost()`, but outrage isn&#x27;t some default rule of interaction.</div><br/></div></div><div id="41976235" class="c"><input type="checkbox" id="c-41976235" checked=""/><div class="controls bullet"><span class="by">miki123211</span><span>|</span><a href="#41974111">root</a><span>|</span><a href="#41974435">parent</a><span>|</span><a href="#41979468">prev</a><span>|</span><a href="#41975294">next</a><span>|</span><label class="collapse" for="c-41976235">[-]</label><label class="expand" for="c-41976235">[2 more]</label></div><br/><div class="children"><div class="content">As a mastodon user, I can definitely confirm this.<p>Give people the way to repost &#x2F; retweet &#x2F; boost, and your feed suddenly turns into mostly negativity, even if your algorithm is &quot;show posts from my followers only, newest to oldest&quot;</div><br/><div id="41976331" class="c"><input type="checkbox" id="c-41976331" checked=""/><div class="controls bullet"><span class="by">Karrot_Kream</span><span>|</span><a href="#41974111">root</a><span>|</span><a href="#41976235">parent</a><span>|</span><a href="#41975294">next</a><span>|</span><label class="collapse" for="c-41976331">[-]</label><label class="expand" for="c-41976331">[1 more]</label></div><br/><div class="children"><div class="content">Yeah my Bluesky followers are carefully curated to stop from swelling into negativity. I&#x27;ve been playing around with a labeller that filters followed posts into those that I find emotionally pleasant which I&#x27;ve been training based on my own labeling of followers&#x27; posts. The goal is to follow more people and have the labeller (or feed generator depending on how I go) hide the posts I don&#x27;t care for.</div><br/></div></div></div></div><div id="41975294" class="c"><input type="checkbox" id="c-41975294" checked=""/><div class="controls bullet"><span class="by">Vampiero</span><span>|</span><a href="#41974111">root</a><span>|</span><a href="#41974435">parent</a><span>|</span><a href="#41976235">prev</a><span>|</span><a href="#41977898">next</a><span>|</span><label class="collapse" for="c-41975294">[-]</label><label class="expand" for="c-41975294">[3 more]</label></div><br/><div class="children"><div class="content">If that theory were true then, what about every website on the internet pre-2010? What about 4chan?<p>See also <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Negativity_bias" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Negativity_bias</a><p>We&#x27;re just built like that.<p>Regarding text platforms suffering more than non-text platforms, I think it&#x27;s because of the lack of social cues that are otherwise there. You can infer a lot from the way someone talks, or from their body language. You can&#x27;t infer much from text, which is partly why Poe&#x27;s law exists -- sarcasm doesn&#x27;t translate well.</div><br/><div id="41975398" class="c"><input type="checkbox" id="c-41975398" checked=""/><div class="controls bullet"><span class="by">Karrot_Kream</span><span>|</span><a href="#41974111">root</a><span>|</span><a href="#41975294">parent</a><span>|</span><a href="#41977898">next</a><span>|</span><label class="collapse" for="c-41975398">[-]</label><label class="expand" for="c-41975398">[2 more]</label></div><br/><div class="children"><div class="content">&gt; what about every website on the internet pre-2010<p>It was definitely there. Plenty of forums had &quot;rant threads&quot; that were efforts to quarantine shitty reactionary behavior like this. Also a lot of the healthier forums were smaller forums. I was on plenty of forums that had 10-20 folks on them that today would just be a Telegram group chat or a small Discord &quot;server&quot;. These small spaces tend to be a lot lower on toxicity than larger fora. I was part of a few large fora like Gaia Online and they were just as toxic as today&#x27;s large platforms. Managing large communities with chronological posting is really difficult and upvote based social networks were the first real networks to be able to scale to larger userbases without having hundreds of moderators (like Gaia or the large MUDs.)<p>&gt; What about 4chan?<p>4chan is immune because the default emotional register there is indignant dismissal. Because of this it&#x27;s just a matter of choosing what else to layer ontop of the indignant dismissal, like sarcasm or anger or whatnot.<p>&gt; Regarding text platforms suffering more than non-text platforms, I think it&#x27;s because of the lack of social cues that are otherwise there. You can infer a lot from the way someone talks, or from their body language. You can&#x27;t infer much from text, which is partly why Poe&#x27;s law exists.<p>That&#x27;s an interesting theory actually. My theory was that in the age of multimedia platforms, text platforms tend to attract folks who specifically want to use text over multimedia. Generally text forums will select for folks with social or self-esteem issues. These folks are the least likely to healthily deal with their emotions or disengage positively. This leads to higher toxicity on text based platforms.</div><br/><div id="41975930" class="c"><input type="checkbox" id="c-41975930" checked=""/><div class="controls bullet"><span class="by">Vampiero</span><span>|</span><a href="#41974111">root</a><span>|</span><a href="#41975398">parent</a><span>|</span><a href="#41977898">next</a><span>|</span><label class="collapse" for="c-41975930">[-]</label><label class="expand" for="c-41975930">[1 more]</label></div><br/><div class="children"><div class="content">&gt; My theory was that in the age of multimedia platforms, text platforms tend to attract folks who specifically want to use text over multimedia. Generally text forums will select for folks with social or self-esteem issues. These folks are the least likely healthily deal with their emotions or disengage positively. This leads to higher toxicity on text based platforms.<p>Yeah that&#x27;s very plausible indeed</div><br/></div></div></div></div></div></div><div id="41977898" class="c"><input type="checkbox" id="c-41977898" checked=""/><div class="controls bullet"><span class="by">int_19h</span><span>|</span><a href="#41974111">root</a><span>|</span><a href="#41974435">parent</a><span>|</span><a href="#41975294">prev</a><span>|</span><a href="#41974607">next</a><span>|</span><label class="collapse" for="c-41977898">[-]</label><label class="expand" for="c-41977898">[1 more]</label></div><br/><div class="children"><div class="content">This video will make you angry: <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=rE3j_RHkqJc" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=rE3j_RHkqJc</a></div><br/></div></div><div id="41974607" class="c"><input type="checkbox" id="c-41974607" checked=""/><div class="controls bullet"><span class="by">jerjerjer</span><span>|</span><a href="#41974111">root</a><span>|</span><a href="#41974435">parent</a><span>|</span><a href="#41977898">prev</a><span>|</span><a href="#41974729">next</a><span>|</span><label class="collapse" for="c-41974607">[-]</label><label class="expand" for="c-41974607">[1 more]</label></div><br/><div class="children"><div class="content">Humans love having something to be righteously indignant about.</div><br/></div></div></div></div><div id="41974729" class="c"><input type="checkbox" id="c-41974729" checked=""/><div class="controls bullet"><span class="by">kelnos</span><span>|</span><a href="#41974111">parent</a><span>|</span><a href="#41974435">prev</a><span>|</span><a href="#41974182">next</a><span>|</span><label class="collapse" for="c-41974729">[-]</label><label class="expand" for="c-41974729">[1 more]</label></div><br/><div class="children"><div class="content">I flag most complaint posts, unless the complaint actually brings to light or discusses something surprising or unique that can be generalized and discussed.<p>I generally find these posts pretty boring, and most comments on them are people recounting their own stories about how that (or a similar) service screwed them over.  I suppose they can be a decent way to warn people off of a particular product (scammy, terrible customer support, whatever), but that&#x27;s not what I come to HN for.</div><br/></div></div><div id="41974182" class="c"><input type="checkbox" id="c-41974182" checked=""/><div class="controls bullet"><span class="by">Rick76</span><span>|</span><a href="#41974111">parent</a><span>|</span><a href="#41974729">prev</a><span>|</span><a href="#41974293">next</a><span>|</span><label class="collapse" for="c-41974182">[-]</label><label class="expand" for="c-41974182">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t like it, but it seems the internet always reacts more to inherently negative posts. That seems to be common across the entire internet, I think that&#x27;s why the internet doesn&#x27;t seem as fun as it did 10 years ago.<p>I&#x27;m sure it&#x27;s just human psyche but I&#x27;m trying to overcome it and make my life more positive again</div><br/></div></div><div id="41974293" class="c"><input type="checkbox" id="c-41974293" checked=""/><div class="controls bullet"><span class="by">andrewmcwatters</span><span>|</span><a href="#41974111">parent</a><span>|</span><a href="#41974182">prev</a><span>|</span><a href="#41975572">next</a><span>|</span><label class="collapse" for="c-41974293">[-]</label><label class="expand" for="c-41974293">[1 more]</label></div><br/><div class="children"><div class="content">I suspect a large percentage of Dan&#x27;s work moderating HN is downweighing posts that incite engagement from frustration. I&#x27;ve had on at least one occasion the top comment in a thread by over 100 upvotes that was purely the sentiment of several readers but did not contribute to the curated voice of the community.</div><br/></div></div></div></div><div id="41973938" class="c"><input type="checkbox" id="c-41973938" checked=""/><div class="controls bullet"><span class="by">pclmulqdq</span><span>|</span><a href="#41974111">prev</a><span>|</span><a href="#41977617">next</a><span>|</span><label class="collapse" for="c-41973938">[-]</label><label class="expand" for="c-41973938">[3 more]</label></div><br/><div class="children"><div class="content">There is a timing factor that you need to consider, too. Anecdotally, Sunday morning is the best time to get onto the front page, while Tuesday or Wednesday morning gets you the most views.</div><br/><div id="41973999" class="c"><input type="checkbox" id="c-41973999" checked=""/><div class="controls bullet"><span class="by">kcorbitt</span><span>|</span><a href="#41973938">parent</a><span>|</span><a href="#41977617">next</a><span>|</span><label class="collapse" for="c-41973999">[-]</label><label class="expand" for="c-41973999">[2 more]</label></div><br/><div class="children"><div class="content">Yep, that&#x27;s why I included the post date in the information available to the model; in theory (if it&#x27;s smart enough) it should be able to take that into account. That said I didn&#x27;t include time-of-day; it would be interesting to see whether adding that information would be able to make the model more accurate!<p>If the reward model is indeed smart enough to be able to take that into account you could actually use it to plan the optimal time of day to post a specific story! You could just use the reward model to compute a predicted score for 8 different versions of your content, holding the post title&#x2F;text constant across them all and just changing the date. Based on the differences in scores, you can determine which posting time the RM thinks is most likely to make your post successful!</div><br/><div id="41976484" class="c"><input type="checkbox" id="c-41976484" checked=""/><div class="controls bullet"><span class="by">pixl97</span><span>|</span><a href="#41973938">root</a><span>|</span><a href="#41973999">parent</a><span>|</span><a href="#41977617">next</a><span>|</span><label class="collapse" for="c-41976484">[-]</label><label class="expand" for="c-41976484">[1 more]</label></div><br/><div class="children"><div class="content">&gt;you could actually use it to plan the optimal time of day to post a specific story!<p>You see this on Reddit pretty commonly.<p>Someone posts original content at an off time and get a small&#x2F;moderate amount of upvotes. Then some time later (could be hours, days, or weeks) a bot&#x2F;karma account will post the content at an optimal time to farm upvotes.</div><br/></div></div></div></div></div></div><div id="41977617" class="c"><input type="checkbox" id="c-41977617" checked=""/><div class="controls bullet"><span class="by">gavin_gee</span><span>|</span><a href="#41973938">prev</a><span>|</span><a href="#41974530">next</a><span>|</span><label class="collapse" for="c-41977617">[-]</label><label class="expand" for="c-41977617">[1 more]</label></div><br/><div class="children"><div class="content">Take note HN, this is what great content marketing looks like.</div><br/></div></div><div id="41974530" class="c"><input type="checkbox" id="c-41974530" checked=""/><div class="controls bullet"><span class="by">6gvONxR4sf7o</span><span>|</span><a href="#41977617">prev</a><span>|</span><a href="#41973931">next</a><span>|</span><label class="collapse" for="c-41974530">[-]</label><label class="expand" for="c-41974530">[5 more]</label></div><br/><div class="children"><div class="content">Why use RL for this instead of plain old supervised learning?</div><br/><div id="41974848" class="c"><input type="checkbox" id="c-41974848" checked=""/><div class="controls bullet"><span class="by">dinobones</span><span>|</span><a href="#41974530">parent</a><span>|</span><a href="#41975102">next</a><span>|</span><label class="collapse" for="c-41974848">[-]</label><label class="expand" for="c-41974848">[3 more]</label></div><br/><div class="children"><div class="content">I am trying to understand this too.<p>Supervised learning you train on pairs of (x, y) where x is your input (title&#x2F;post text&#x2F;metadata) and y is the output score.<p>Naively, it&#x27;s a linear regression model, Y = b0 + b1x1 + b2x2 + b3x3. Where b0 is your bias (&quot;a floor for score points&quot;), and b1, b2, and b3 are bias terms for the actual data of the post. You can solve this, closed form, and find the b1&#x2F;b2&#x2F;b3 that minimize the error of fitting to Y.<p>How do these equations change with RL? I always assumed RL was a multi-step process where actions are taken to get to a reward. If there is only 1 step&#x2F;decision, to produce a &quot;random&quot; score, it feels much like supervised learning.</div><br/><div id="41975113" class="c"><input type="checkbox" id="c-41975113" checked=""/><div class="controls bullet"><span class="by">jampekka</span><span>|</span><a href="#41974530">root</a><span>|</span><a href="#41974848">parent</a><span>|</span><a href="#41975102">next</a><span>|</span><label class="collapse" for="c-41975113">[-]</label><label class="expand" for="c-41975113">[2 more]</label></div><br/><div class="children"><div class="content">The post is not doing RL. It&#x27;s just regression as you thought.</div><br/><div id="41975635" class="c"><input type="checkbox" id="c-41975635" checked=""/><div class="controls bullet"><span class="by">billmalarky</span><span>|</span><a href="#41974530">root</a><span>|</span><a href="#41975113">parent</a><span>|</span><a href="#41975102">next</a><span>|</span><label class="collapse" for="c-41975635">[-]</label><label class="expand" for="c-41975635">[1 more]</label></div><br/><div class="children"><div class="content">This post is using regression to build a reward model. The reward model will then be used (in a future post) to build the overall RL system.<p>Here&#x27;s the relevant text from the article:<p>&gt;In this post we’ll discuss how to build a reward model that can predict the upvote count that a specific HN story will get. And in follow-up posts in this series, we’ll use that reward model along with reinforcement learning to create a model that can write high-value HN stories!</div><br/></div></div></div></div></div></div><div id="41975102" class="c"><input type="checkbox" id="c-41975102" checked=""/><div class="controls bullet"><span class="by">jampekka</span><span>|</span><a href="#41974530">parent</a><span>|</span><a href="#41974848">prev</a><span>|</span><a href="#41973931">next</a><span>|</span><label class="collapse" for="c-41975102">[-]</label><label class="expand" for="c-41975102">[1 more]</label></div><br/><div class="children"><div class="content">It is just plain old supervised learning. A regression from the post features to vote count. The RL discussion in TFA is a bit confusing.<p>Such a model can be used as the &quot;reward model&quot; for the &quot;reinforcement learning from human feedback&quot; (RLHF) method.</div><br/></div></div></div></div><div id="41973931" class="c"><input type="checkbox" id="c-41973931" checked=""/><div class="controls bullet"><span class="by">Havoc</span><span>|</span><a href="#41974530">prev</a><span>|</span><a href="#41975566">next</a><span>|</span><label class="collapse" for="c-41973931">[-]</label><label class="expand" for="c-41973931">[6 more]</label></div><br/><div class="children"><div class="content">Nice write up.<p>Did you ever figure out what happened in 2016?</div><br/><div id="41974025" class="c"><input type="checkbox" id="c-41974025" checked=""/><div class="controls bullet"><span class="by">kcorbitt</span><span>|</span><a href="#41973931">parent</a><span>|</span><a href="#41975566">next</a><span>|</span><label class="collapse" for="c-41974025">[-]</label><label class="expand" for="c-41974025">[5 more]</label></div><br/><div class="children"><div class="content">Nope. I was actually planning on asking dang if he has any insights there. If he sees this thread hopefully he can chime in!</div><br/><div id="41976092" class="c"><input type="checkbox" id="c-41976092" checked=""/><div class="controls bullet"><span class="by">n2d4</span><span>|</span><a href="#41973931">root</a><span>|</span><a href="#41974025">parent</a><span>|</span><a href="#41974741">next</a><span>|</span><label class="collapse" for="c-41976092">[-]</label><label class="expand" for="c-41976092">[1 more]</label></div><br/><div class="children"><div class="content">Given that Google Trends doesn&#x27;t show that bump, I&#x27;d assume it has to do with how the data was collected. Maybe all stories with &lt; X votes&#x2F;comments older than 2015 are not included, or deleted from whatever index you used?</div><br/></div></div><div id="41974741" class="c"><input type="checkbox" id="c-41974741" checked=""/><div class="controls bullet"><span class="by">kelnos</span><span>|</span><a href="#41973931">root</a><span>|</span><a href="#41974025">parent</a><span>|</span><a href="#41976092">prev</a><span>|</span><a href="#41974154">next</a><span>|</span><label class="collapse" for="c-41974741">[-]</label><label class="expand" for="c-41974741">[1 more]</label></div><br/><div class="children"><div class="content">In case he doesn&#x27;t, you might as well email him about it.  He&#x27;s a very responsive guy and might find it interesting.</div><br/></div></div><div id="41974154" class="c"><input type="checkbox" id="c-41974154" checked=""/><div class="controls bullet"><span class="by">twoodfin</span><span>|</span><a href="#41973931">root</a><span>|</span><a href="#41974025">parent</a><span>|</span><a href="#41974741">prev</a><span>|</span><a href="#41975566">next</a><span>|</span><label class="collapse" for="c-41974154">[-]</label><label class="expand" for="c-41974154">[2 more]</label></div><br/><div class="children"><div class="content">I think text vs. link used to be XOR, but isn’t any longer.<p>It’s still outside the hn mainstream to use both in the same submission, so that might be biasing the model in strange ways.</div><br/><div id="41974368" class="c"><input type="checkbox" id="c-41974368" checked=""/><div class="controls bullet"><span class="by">jerjerjer</span><span>|</span><a href="#41973931">root</a><span>|</span><a href="#41974154">parent</a><span>|</span><a href="#41975566">next</a><span>|</span><label class="collapse" for="c-41974368">[-]</label><label class="expand" for="c-41974368">[1 more]</label></div><br/><div class="children"><div class="content">From the post:<p>&gt; But to simplify, instead I’ll just limit to stories that have only text bodies, instead of links.<p>This line implies that pre- and post- 2016 stories are text only, so this change should not affect the data so much.</div><br/></div></div></div></div></div></div></div></div><div id="41975566" class="c"><input type="checkbox" id="c-41975566" checked=""/><div class="controls bullet"><span class="by">1024core</span><span>|</span><a href="#41973931">prev</a><span>|</span><a href="#41977691">next</a><span>|</span><label class="collapse" for="c-41975566">[-]</label><label class="expand" for="c-41975566">[5 more]</label></div><br/><div class="children"><div class="content">Is it my understanding that the reward model is also similar to an LLM (with the difference being it predicts a score instead of the next token)?</div><br/><div id="41975621" class="c"><input type="checkbox" id="c-41975621" checked=""/><div class="controls bullet"><span class="by">kcorbitt</span><span>|</span><a href="#41975566">parent</a><span>|</span><a href="#41977691">next</a><span>|</span><label class="collapse" for="c-41975621">[-]</label><label class="expand" for="c-41975621">[4 more]</label></div><br/><div class="children"><div class="content">Yes! The architecture is almost identical. The only difference is in the final layer. In an LLM used for text generation, the final layer has a separate output for every potential token the model could produce, and we decide which token to generate by choosing the one with the highest likelihood at each generation step (at least that&#x27;s what the simplest sampling methods do). In an LLM used as a reward model, we only have one output in the final layer, and we interpret its value as the predicted reward.<p>Everything else in the model before that final layer is exactly identical, architecture-wise.</div><br/><div id="41975731" class="c"><input type="checkbox" id="c-41975731" checked=""/><div class="controls bullet"><span class="by">1024core</span><span>|</span><a href="#41975566">root</a><span>|</span><a href="#41975621">parent</a><span>|</span><a href="#41977691">next</a><span>|</span><label class="collapse" for="c-41975731">[-]</label><label class="expand" for="c-41975731">[3 more]</label></div><br/><div class="children"><div class="content">But a typical LLM has a feedback loop: it looks at the last token it generated and then decides, given the N tokens before that, which token to output next.<p>In the case of a reward model, are you streaming in the list of tokens; if so, what is the output after each token? Or are you feeding in all of the tokens in one shot, with the predicted reward as the output?</div><br/><div id="41976263" class="c"><input type="checkbox" id="c-41976263" checked=""/><div class="controls bullet"><span class="by">maleldil</span><span>|</span><a href="#41975566">root</a><span>|</span><a href="#41975731">parent</a><span>|</span><a href="#41977691">next</a><span>|</span><label class="collapse" for="c-41976263">[-]</label><label class="expand" for="c-41976263">[2 more]</label></div><br/><div class="children"><div class="content">There are multiple ways to model reward. You can have it be fine-grained, such that every token gets its own reward, but by far the most common is to feed in the whole sequence and generate a single reward at the end.</div><br/><div id="41976411" class="c"><input type="checkbox" id="c-41976411" checked=""/><div class="controls bullet"><span class="by">1024core</span><span>|</span><a href="#41975566">root</a><span>|</span><a href="#41976263">parent</a><span>|</span><a href="#41977691">next</a><span>|</span><label class="collapse" for="c-41976411">[-]</label><label class="expand" for="c-41976411">[1 more]</label></div><br/><div class="children"><div class="content">I guess I&#x27;m not sure how the &quot;feed in the whole sequence&quot; works, if there&#x27;s a single reward at the end.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="41977691" class="c"><input type="checkbox" id="c-41977691" checked=""/><div class="controls bullet"><span class="by">hn_throwaway_99</span><span>|</span><a href="#41975566">prev</a><span>|</span><a href="#41975586">next</a><span>|</span><label class="collapse" for="c-41977691">[-]</label><label class="expand" for="c-41977691">[1 more]</label></div><br/><div class="children"><div class="content">&gt; And in follow-up posts in this series, we’ll use that reward model along with reinforcement learning to create a model that can write high-value HN stories!<p>Well, thanks HN, you were good while it lasted...</div><br/></div></div><div id="41973880" class="c"><input type="checkbox" id="c-41973880" checked=""/><div class="controls bullet"><span class="by">eugenekolo</span><span>|</span><a href="#41975586">prev</a><span>|</span><a href="#41974351">next</a><span>|</span><label class="collapse" for="c-41973880">[-]</label><label class="expand" for="c-41973880">[3 more]</label></div><br/><div class="children"><div class="content">What does the model say about this post?</div><br/><div id="41974018" class="c"><input type="checkbox" id="c-41974018" checked=""/><div class="controls bullet"><span class="by">kcorbitt</span><span>|</span><a href="#41973880">parent</a><span>|</span><a href="#41974351">next</a><span>|</span><label class="collapse" for="c-41974018">[-]</label><label class="expand" for="c-41974018">[2 more]</label></div><br/><div class="children"><div class="content">Haha great question. Since it&#x27;s only trained on on-platform HN content and not external links, this post is a little bit out of distribution for it unfortunately. I&#x27;m thinking about scraping a corpus of external links and running the same analysis though, in which case I&#x27;d definitely run it on this story because I&#x27;m also curious about that. :)</div><br/><div id="41974193" class="c"><input type="checkbox" id="c-41974193" checked=""/><div class="controls bullet"><span class="by">Rick76</span><span>|</span><a href="#41973880">root</a><span>|</span><a href="#41974018">parent</a><span>|</span><a href="#41974351">next</a><span>|</span><label class="collapse" for="c-41974193">[-]</label><label class="expand" for="c-41974193">[1 more]</label></div><br/><div class="children"><div class="content">I would be very interested in the results of that as well</div><br/></div></div></div></div></div></div><div id="41974351" class="c"><input type="checkbox" id="c-41974351" checked=""/><div class="controls bullet"><span class="by">suyash</span><span>|</span><a href="#41973880">prev</a><span>|</span><a href="#41977033">next</a><span>|</span><label class="collapse" for="c-41974351">[-]</label><label class="expand" for="c-41974351">[2 more]</label></div><br/><div class="children"><div class="content">Very interesting project, would love to read a more technical write up on how the model was architected and trained, any pointers?</div><br/><div id="41974569" class="c"><input type="checkbox" id="c-41974569" checked=""/><div class="controls bullet"><span class="by">kcorbitt</span><span>|</span><a href="#41974351">parent</a><span>|</span><a href="#41977033">next</a><span>|</span><label class="collapse" for="c-41974569">[-]</label><label class="expand" for="c-41974569">[1 more]</label></div><br/><div class="children"><div class="content">I link to it from the post, but all the code is open source! You can find the specific training script here: <a href="https:&#x2F;&#x2F;github.com&#x2F;OpenPipe&#x2F;best-hn&#x2F;blob&#x2F;main&#x2F;stories_train_model_v3.py">https:&#x2F;&#x2F;github.com&#x2F;OpenPipe&#x2F;best-hn&#x2F;blob&#x2F;main&#x2F;stories_train_...</a><p>And all the graphs for the blog are from this notebook: <a href="https:&#x2F;&#x2F;github.com&#x2F;OpenPipe&#x2F;best-hn&#x2F;blob&#x2F;main&#x2F;blog-figures.ipynb">https:&#x2F;&#x2F;github.com&#x2F;OpenPipe&#x2F;best-hn&#x2F;blob&#x2F;main&#x2F;blog-figures.i...</a><p>Lots of other good stuff in that repo, although it&#x27;s only organized to a &quot;working researcher&quot; standard I&#x27;m afraid.</div><br/></div></div></div></div><div id="41977033" class="c"><input type="checkbox" id="c-41977033" checked=""/><div class="controls bullet"><span class="by">floobertoober</span><span>|</span><a href="#41974351">prev</a><span>|</span><a href="#41974386">next</a><span>|</span><label class="collapse" for="c-41977033">[-]</label><label class="expand" for="c-41977033">[1 more]</label></div><br/><div class="children"><div class="content">Maybe it would help to use a box cox transform on the score distribution?</div><br/></div></div><div id="41974386" class="c"><input type="checkbox" id="c-41974386" checked=""/><div class="controls bullet"><span class="by">ChrisArchitect</span><span>|</span><a href="#41977033">prev</a><span>|</span><a href="#41975497">next</a><span>|</span><label class="collapse" for="c-41974386">[-]</label><label class="expand" for="c-41974386">[1 more]</label></div><br/><div class="children"><div class="content">First problem with the submissions that supposedly &#x27;would do well on HN&#x27; is other than the Ask HN: they&#x27;re misusing the submission by putting it in a text post instead of sharing as a link post directly. And sketchy new&#x2F;inactive accounts. C&#x27;mon. Not gonna keep reading grifty post after that opening.</div><br/></div></div><div id="41975497" class="c"><input type="checkbox" id="c-41975497" checked=""/><div class="controls bullet"><span class="by">chx</span><span>|</span><a href="#41974386">prev</a><span>|</span><label class="collapse" for="c-41975497">[-]</label><label class="expand" for="c-41975497">[1 more]</label></div><br/><div class="children"><div class="content">&gt; . That’s not much time for a model that (hopefully) understands all of HN!<p>this is dangerous talk.<p>it doesn&#x27;t understand anything at all.<p>Reminder: We are more prone to anthromorphizing LLMs than to humanizing suffering humans.</div><br/></div></div></div></div></div></div></div></body></html>