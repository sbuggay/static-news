<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1706000462890" as="style"/><link rel="stylesheet" href="styles.css?v=1706000462890"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.inngest.com/blog/building-the-inngest-queue-pt-i-fairness-multi-tenancy">Building a fair multi-tenant queuing system</a>Â <span class="domain">(<a href="https://www.inngest.com">www.inngest.com</a>)</span></div><div class="subtext"><span>tonyhb</span> | <span>61 comments</span></div><br/><div><div id="39095473" class="c"><input type="checkbox" id="c-39095473" checked=""/><div class="controls bullet"><span class="by">siliconc0w</span><span>|</span><a href="#39093926">next</a><span>|</span><label class="collapse" for="c-39095473">[-]</label><label class="expand" for="c-39095473">[2 more]</label></div><br/><div class="children"><div class="content">I think you want controls around:<p>0) Load - I&#x27;m too loaded right now, I&#x27;m not processing your message.  Maybe another worker will.  This might be enqueued back into the low latency queue.<p>1) Role Limit - You&#x27;ve sent too many messages in too short of a time, I&#x27;m dequeueing this into the high latency queue.<p>2) Cost Limit - You&#x27;ve sent too many <i>expensive</i> messages, I&#x27;m dequeing this into the high latency queue.<p>3). Deadletter- Your messages are failing to be processed.  We&#x27;re going to dequeue into deadletter and maybe we&#x27;re going stop processing them for for now.<p>So you have the normal low latency queue, the high latency backlog queue, and the  deadletter queue.  Ideally you have SLOs around end to end queue times and monitoring&#x2F;alerting to let you and your senders know their expectations may be not being met (i.e 99% of messages are processed within n MS).</div><br/><div id="39097132" class="c"><input type="checkbox" id="c-39097132" checked=""/><div class="controls bullet"><span class="by">just_some_guy</span><span>|</span><a href="#39095473">parent</a><span>|</span><a href="#39093926">next</a><span>|</span><label class="collapse" for="c-39097132">[-]</label><label class="expand" for="c-39097132">[1 more]</label></div><br/><div class="children"><div class="content">As we&#x27;ve moved up in scaling the number of tenants we found tiered queues to be an anti-pattern. Inevitably some worker or upstream will get broken and you end up the high latency or dead letter queues with much more traffic than they&#x27;re really designed to handle. Clearing it out then becomes a scramble since just scaling the high latency workers will often cause cascading issues. It makes sense if you frame it as &quot;we&#x27;re having trouble managing our 1 million queues&quot; and the solution is to &quot;create up to 1 million more queues&quot;.<p>Instead we use a priority queue and adaptive concurrency. The priority queue lets you reschedule failed messages with a capped exponential backoff. That way it doesn&#x27;t significantly impair the good items in the queue while still giving plenty of time to potentially fix the failing items. Adaptive concurrency increases &amp; decreases the concurrency for that queue based on success &amp; failure of workers on the queues items up to some upper &amp; lower bounds. That way a single queue can&#x27;t waste time scheduling work that&#x27;s just going to most likely fail.<p>We still have a dead letter queue, but it only ends up containing bugs since expiration is considered a normal message lifecycle event. So dead letter items just contain messages that were too broken to either send or expire correctly.<p>The key take away is that as the number of queues increase it&#x27;s better to just operate on the concurrency &amp; ordering of the queue than to just keep creating more queues for the same work stream.</div><br/></div></div></div></div><div id="39093926" class="c"><input type="checkbox" id="c-39093926" checked=""/><div class="controls bullet"><span class="by">Nilithus</span><span>|</span><a href="#39095473">prev</a><span>|</span><a href="#39093488">next</a><span>|</span><label class="collapse" for="c-39093926">[-]</label><label class="expand" for="c-39093926">[3 more]</label></div><br/><div class="children"><div class="content">I found Amazon&#x27;s Builders Library to have a very insightful list of how to handle building multi tenant queue systems <a href="https:&#x2F;&#x2F;aws.amazon.com&#x2F;builders-library&#x2F;avoiding-insurmountable-queue-backlogs&#x2F;" rel="nofollow">https:&#x2F;&#x2F;aws.amazon.com&#x2F;builders-library&#x2F;avoiding-insurmounta...</a><p>I think one of the big tools is Shuffle Sharding. The article talks about standard sharding by itself as not being enough to provide robustness in multitenant queues. But Shuffle Sharding I.E. assigning users to virtual groups of underlying queues and enqueueing to the queue with the smallest size gets you pretty far. It can limit throughput for individual users but implementing some simple work stealing logic on the consumer helps make sure you keep your throughput up.</div><br/><div id="39099943" class="c"><input type="checkbox" id="c-39099943" checked=""/><div class="controls bullet"><span class="by">donavanm</span><span>|</span><a href="#39093926">parent</a><span>|</span><a href="#39095924">next</a><span>|</span><label class="collapse" for="c-39099943">[-]</label><label class="expand" for="c-39099943">[1 more]</label></div><br/><div class="children"><div class="content">David mentioned it but SQS `MessageGroupId` can get you really far on fair-ish work from the queue. Its effectively a virtual partition key for the queue. Set your customer id, resource id, etc as the MessageGroupId and use that to do the work allocation.<p><a href="https:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;AWSSimpleQueueService&#x2F;latest&#x2F;SQSDeveloperGuide&#x2F;using-messagegroupid-property.html" rel="nofollow">https:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;AWSSimpleQueueService&#x2F;latest&#x2F;SQS...</a></div><br/></div></div><div id="39095924" class="c"><input type="checkbox" id="c-39095924" checked=""/><div class="controls bullet"><span class="by">extractionmech</span><span>|</span><a href="#39093926">parent</a><span>|</span><a href="#39099943">prev</a><span>|</span><a href="#39093488">next</a><span>|</span><label class="collapse" for="c-39095924">[-]</label><label class="expand" for="c-39095924">[1 more]</label></div><br/><div class="children"><div class="content">That extra layer of indirection, virtual queues, is key.</div><br/></div></div></div></div><div id="39093488" class="c"><input type="checkbox" id="c-39093488" checked=""/><div class="controls bullet"><span class="by">fabian2k</span><span>|</span><a href="#39093926">prev</a><span>|</span><a href="#39093786">next</a><span>|</span><label class="collapse" for="c-39093488">[-]</label><label class="expand" for="c-39093488">[24 more]</label></div><br/><div class="children"><div class="content">There are plenty of articles about writing simple job queues in Postgres using SKIP LOCKED, and I personally like that version quite a bit for cases where you don&#x27;t want to add another separate component just for the queue. But I haven&#x27;t seen anyone addressing fairness in such a queue, e.g. for the multi-tenant case.<p>Is there a simple way to get a very rough kind of fairness between tenants in this case? Doesn&#x27;t have to be actually fair, just fair enough that no tenant gets fully stuck behind a large block of jobs from another tenant.<p>The idea behind SKIP LOCKED is that you just get the first free job (potentially ordered by e.g. a priority column). Doing that in a way that switches between tenants doesn&#x27;t seem straightforward. You could execute the query once per tenant, but that would be rather inefficient for many tenants. Is there a reasonably straightforward way to achieve this?</div><br/><div id="39099703" class="c"><input type="checkbox" id="c-39099703" checked=""/><div class="controls bullet"><span class="by">jillesvangurp</span><span>|</span><a href="#39093488">parent</a><span>|</span><a href="#39095673">next</a><span>|</span><label class="collapse" for="c-39099703">[-]</label><label class="expand" for="c-39099703">[1 more]</label></div><br/><div class="children"><div class="content">I found a nice article on skip locked last week: <a href="https:&#x2F;&#x2F;www.crunchydata.com&#x2F;blog&#x2F;message-queuing-using-native-postgresql" rel="nofollow">https:&#x2F;&#x2F;www.crunchydata.com&#x2F;blog&#x2F;message-queuing-using-nativ...</a><p>We went ahead and implemented our own little queue in postgres based on that to get rid of a wonky thing we had that built on top of redis. What I like about this is that it&#x27;s simple, robust, and transactional. So, you get some nice guarantees out of that.<p>For fairness, you might do stuff with partitioning on the priority column. Simply set up your workers to only hit a certain partition. So you have separate workers for higher and lower priority queue items. If you then dynamically lower the priority of tenants sending you lots of traffic, the system becomes more fair for the others. You could work with some simple moving average here. Just an idea, but something like this might work.</div><br/></div></div><div id="39095673" class="c"><input type="checkbox" id="c-39095673" checked=""/><div class="controls bullet"><span class="by">smallnamespace</span><span>|</span><a href="#39093488">parent</a><span>|</span><a href="#39099703">prev</a><span>|</span><a href="#39094519">next</a><span>|</span><label class="collapse" for="c-39095673">[-]</label><label class="expand" for="c-39095673">[5 more]</label></div><br/><div class="children"><div class="content">&gt; Is there a simple way to get a very rough kind of fairness between tenants in this case?<p>Yes, since the SKIP LOCKED query is just a special sort of SELECT that skips over locked rows, you can use all the normal SQL tools such as ORDER BY to accomplish what you want.<p>One way is to make the top row fair by randomizing over the tenant ID, for example<p><pre><code>  SELECT itemid
  FROM queue
  ORDER BY
    md5(tenant_id || current_timestamp::TEXT),
    item_id
  FOR UPDATE SKIP LOCKED
  LIMIT 1;
</code></pre>
Here we append the ID to the timestamp and then hash it, so each time the SELECT is run there is effectively a different ordering between tenant IDs, hence fairness.<p>Note that this will eventually have performance implications for a deep queue since it forces a scan on the whole table. Adding an index on tenant_id may mitigate that, but as always do your own profiling.</div><br/><div id="39100906" class="c"><input type="checkbox" id="c-39100906" checked=""/><div class="controls bullet"><span class="by">jimlikeslimes</span><span>|</span><a href="#39093488">root</a><span>|</span><a href="#39095673">parent</a><span>|</span><a href="#39097658">next</a><span>|</span><label class="collapse" for="c-39100906">[-]</label><label class="expand" for="c-39100906">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not addressing your point on fairness but I&#x27;ve been working on a similar program but instead of taking locks out on the queue table I maintain a consumers position for locked and acknowldeged messages on the consumers table. It makes lots of queries simpler. Here&#x27;s a simplified schema using SQL Server:<p><pre><code>  CREATE TABLE [dbo].[Nodes] (
    [Id]             UNIQUEIDENTIFIER NOT NULL,
    [NetworkId]      UNIQUEIDENTIFIER NOT NULL,    
    [Locked]         INT              NOT NULL,
    [Acknowledged]   INT              NOT NULL,
  );

  CREATE TABLE [dbo].[Messages] (
    [Id]            UNIQUEIDENTIFIER NOT NULL,
    [NetworkId]     UNIQUEIDENTIFIER NOT NULL,
    [NodeId]        UNIQUEIDENTIFIER NOT NULL,    
    [Payload]       NVARCHAR (MAX)   NULL,
    [InsertedOrder] INT DEFAULT (NEXT VALUE FOR dbo.MessageSequence) NOT NULL,
    [TimestampUtc]  DATETIME2 (7)    DEFAULT (sysutcdatetime()) NOT NULL,
  );

  Select * 
  From Nodes With (Rowlock, Holdlock)
  Where NetworkId = @networkId
  And Id = @nodeId
</code></pre>
Multi-tenancy is per database.<p>(edit: simplified sql)</div><br/></div></div><div id="39097658" class="c"><input type="checkbox" id="c-39097658" checked=""/><div class="controls bullet"><span class="by">grogers</span><span>|</span><a href="#39093488">root</a><span>|</span><a href="#39095673">parent</a><span>|</span><a href="#39100906">prev</a><span>|</span><a href="#39096356">next</a><span>|</span><label class="collapse" for="c-39097658">[-]</label><label class="expand" for="c-39097658">[2 more]</label></div><br/><div class="children"><div class="content">Having a query like this that gets slower as the queue gets bigger is a really bad idea. It&#x27;ll work just fine in the steady state when your queue is short. And then when you get overloaded and start queueing, you will be adding more load into the equation just to drain the queue. It&#x27;s a recipe for a metastable system that causes a major outage. Adding an index on tenant_id will do nothing because you are always appending the current timestamp before hashing.</div><br/><div id="39098232" class="c"><input type="checkbox" id="c-39098232" checked=""/><div class="controls bullet"><span class="by">smallnamespace</span><span>|</span><a href="#39093488">root</a><span>|</span><a href="#39097658">parent</a><span>|</span><a href="#39096356">next</a><span>|</span><label class="collapse" for="c-39098232">[-]</label><label class="expand" for="c-39098232">[1 more]</label></div><br/><div class="children"><div class="content">The query running in O(queue size) is very likely avoidable if you add an index on the tenant_id.<p>Ideally the query planner figures this out (see the sibling comment), but if not,  the query can likely be written to &quot;encourage&quot; the planner, for example by first selecting the top few values of md5(tenant_id, current_timestamp) within a subquery before lateral joining into the SKIP LOCKED table.<p>If the concern is only that the queue falls over once it gets large enough, you can also LIMIT to a fixed number of rows before doing the outer SELECT. This gives a weaker fairness bound (tenants that have fewer than O(queue size &#x2F; selected items) rows are at risk of being ignored) but you get a better guarantee of progress under contention.</div><br/></div></div></div></div><div id="39096356" class="c"><input type="checkbox" id="c-39096356" checked=""/><div class="controls bullet"><span class="by">btown</span><span>|</span><a href="#39093488">root</a><span>|</span><a href="#39095673">parent</a><span>|</span><a href="#39097658">prev</a><span>|</span><a href="#39094519">next</a><span>|</span><label class="collapse" for="c-39096356">[-]</label><label class="expand" for="c-39096356">[1 more]</label></div><br/><div class="children"><div class="content">Out of curiosity, is Postgres usually able to use a b-tree index&#x27;s representation of the columnar data for its (set of) columns to calculate a derived value for those column(s), then scan through that in-memory derived data? Certainly not as fast as the index lookup itself, but avoids needing to have the entire table in memory, I would hope?<p>The documentation under <a href="https:&#x2F;&#x2F;www.postgresql.org&#x2F;docs&#x2F;16&#x2F;indexes-types.html" rel="nofollow">https:&#x2F;&#x2F;www.postgresql.org&#x2F;docs&#x2F;16&#x2F;indexes-types.html</a> implies that it can be used to access the sorted values - but does that feed through the query planner?</div><br/></div></div></div></div><div id="39094519" class="c"><input type="checkbox" id="c-39094519" checked=""/><div class="controls bullet"><span class="by">10000truths</span><span>|</span><a href="#39093488">parent</a><span>|</span><a href="#39095673">prev</a><span>|</span><a href="#39093583">next</a><span>|</span><label class="collapse" for="c-39094519">[-]</label><label class="expand" for="c-39094519">[1 more]</label></div><br/><div class="children"><div class="content">This depends largely on your requirements.<p>* How well can you estimate job cost? How should overestimates and&#x2F;or underestimates be treated?<p>* Where, when and how often does resource contention occur between jobs? Is it from a single resource, or from multiple different resources?<p>* What constraints or behaviors does the contended resource(s) possess (e.g. rate limits, pipelining, etc.) that would materially impact how you determine which job to run next?<p>* What guarantees do you wish to make (e.g. execution latency, resource availability, etc.)?<p>* How is resource usage quota determined? Are quotas updated frequently? Are there any circumstances under which you would like to allow users to exceed their quota (e.g. temporary burst workloads, idle periods of time)?</div><br/></div></div><div id="39093583" class="c"><input type="checkbox" id="c-39093583" checked=""/><div class="controls bullet"><span class="by">dimitropoulos</span><span>|</span><a href="#39093488">parent</a><span>|</span><a href="#39094519">prev</a><span>|</span><a href="#39094416">next</a><span>|</span><label class="collapse" for="c-39093583">[-]</label><label class="expand" for="c-39093583">[6 more]</label></div><br/><div class="children"><div class="content">Skip locked seems to be the way that new queueing packages are going, though they donât solve fairness or multi-tenancy.<p>Itâs nice to keep things simple, but how does that work at scale?  If I have 1,000 users I donât think that these standard queueing systems can prevent one tenant from impacting another.  It doesnât look like thatâs possible in SQS, either.<p>On the other hand, is that even necessary?  At what scale is this important?</div><br/><div id="39095361" class="c"><input type="checkbox" id="c-39095361" checked=""/><div class="controls bullet"><span class="by">whartung</span><span>|</span><a href="#39093488">root</a><span>|</span><a href="#39093583">parent</a><span>|</span><a href="#39093702">next</a><span>|</span><label class="collapse" for="c-39095361">[-]</label><label class="expand" for="c-39095361">[1 more]</label></div><br/><div class="children"><div class="content">Seems to me a solution is to have a &quot;generic&quot; queue handler that will take any message, and then have tenant specific queue handlers.<p>Now, mind, I&#x27;m not thinking of a dedicated handler for each tenant, rather one that can round robin, or rotate through the tenants to pull items specific to that tenant off the queue. This can be the &quot;fairness&quot; arbiter.<p>With the Postgres SKIP LOCKED technique, you can be selective as to which messages you pull (you&#x27;re not limited to the head of the queue, but can dig deep if you want).<p>So, you have one general purpose &quot;head of the line&quot; handler, and then one (or several) that acts like the fellow at the Post Office &quot;Anyone here just picking up mail?&quot;, and pull them out of the queue.<p>Of course the generic version can just switch modes (every 1m, or 100 messages, go into &quot;fair mode&quot; for a short time), vs having different handlers.</div><br/></div></div><div id="39093702" class="c"><input type="checkbox" id="c-39093702" checked=""/><div class="controls bullet"><span class="by">fabian2k</span><span>|</span><a href="#39093488">root</a><span>|</span><a href="#39093583">parent</a><span>|</span><a href="#39095361">prev</a><span>|</span><a href="#39094841">next</a><span>|</span><label class="collapse" for="c-39093702">[-]</label><label class="expand" for="c-39093702">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m thinking about relatively simple systems and not &quot;real&quot; fairness. The case where I&#x27;ve seen this being a bit problematic is with such a queue in an application where jobs are sometimes inserted in large bursts. It doesn&#x27;t actually matter much if they are truly fair, but in the cases where a large number of jobs is inserted at once the result is that for some tenants the queue doesn&#x27;t seem to move at all.<p>It&#x27;s not a huge problem in that case because the regular priority system still puts the urgent jobs at the front of the queue. But it does sometimes cause confusion for someone looking at this from a single-tenant perspective because the queue looks stuck. There are other ways to fix the confusion, but it would be nice to have a very rudimentary fairness in this simple queue that would ensure that the queue iterates a bit over the tenants.</div><br/></div></div><div id="39094841" class="c"><input type="checkbox" id="c-39094841" checked=""/><div class="controls bullet"><span class="by">vosper</span><span>|</span><a href="#39093488">root</a><span>|</span><a href="#39093583">parent</a><span>|</span><a href="#39093702">prev</a><span>|</span><a href="#39096395">next</a><span>|</span><label class="collapse" for="c-39094841">[-]</label><label class="expand" for="c-39094841">[1 more]</label></div><br/><div class="children"><div class="content">&gt; On the other hand, is that even necessary? At what scale is this important?<p>I can see it being helpful in front of a shared resource that doesn&#x27;t have any way to control priority or fairness. My use case would be Elasticsearch. I don&#x27;t want to block any searches from running if there&#x27;s capacity, but also I don&#x27;t want misbehaving clients to monopolise resources, and I want to make sure that all customers&#x2F;users get to run their searches eventually, though I may prioritise some customers&#x2F;users over others. And I may need my own internal jobs to run at a lower priority than a user search, but still within a guaranteed window (to avoid timeouts on the client side).<p>Honestly for my use case this could be useful with just a handful of users - less than 10, even.</div><br/></div></div><div id="39096395" class="c"><input type="checkbox" id="c-39096395" checked=""/><div class="controls bullet"><span class="by">foofie</span><span>|</span><a href="#39093488">root</a><span>|</span><a href="#39093583">parent</a><span>|</span><a href="#39094841">prev</a><span>|</span><a href="#39094416">next</a><span>|</span><label class="collapse" for="c-39096395">[-]</label><label class="expand" for="c-39096395">[1 more]</label></div><br/><div class="children"><div class="content">&gt; On the other hand, is that even necessary? At what scale is this important?<p>That&#x27;s the critical question. To that I had that there might be a myriad of articles on how someone used postgres to build a message queue instead of using a dedicated message broker, but there isn&#x27;t a single article showing any form of benchmarking, performance tests, load test results, and more importantly report the correlation between load and performance degradation and eventual overload and resulting failure modes. This information is of critical importance to be able to design systems and pick which tool is suited for the job.</div><br/></div></div></div></div><div id="39094416" class="c"><input type="checkbox" id="c-39094416" checked=""/><div class="controls bullet"><span class="by">paulddraper</span><span>|</span><a href="#39093488">parent</a><span>|</span><a href="#39093583">prev</a><span>|</span><a href="#39096621">next</a><span>|</span><label class="collapse" for="c-39094416">[-]</label><label class="expand" for="c-39094416">[1 more]</label></div><br/><div class="children"><div class="content">The solution is to maintain two queues.<p>One queu is your normal queue.<p>A second queue that is your tenant queue (one record for each tenant that has queued items).<p>You select from your tenant queue, then select from your normal queue. All the while keeping your tenant invariant (one record for each tenant that has queued items).<p>---<p>It&#x27;s certainly more complex but no one said that fair was easy.</div><br/></div></div><div id="39093717" class="c"><input type="checkbox" id="c-39093717" checked=""/><div class="controls bullet"><span class="by">xyzzy_plugh</span><span>|</span><a href="#39093488">parent</a><span>|</span><a href="#39096621">prev</a><span>|</span><a href="#39095115">next</a><span>|</span><label class="collapse" for="c-39093717">[-]</label><label class="expand" for="c-39093717">[2 more]</label></div><br/><div class="children"><div class="content">There is probably a better way (I no longer use Postgres for this) but I solved this in the past by evaluating priority after popping an item off the queue. If the item was low priority and there was higher priority work to do, or if a customer was over their quota, I would reschedule the work item.<p>In that scenario I employed an earliest-deadline-first scheduler table so rescheduling was just re-inserting or updating with a new deadline.</div><br/><div id="39098185" class="c"><input type="checkbox" id="c-39098185" checked=""/><div class="controls bullet"><span class="by">RaftPeople</span><span>|</span><a href="#39093488">root</a><span>|</span><a href="#39093717">parent</a><span>|</span><a href="#39095115">next</a><span>|</span><label class="collapse" for="c-39098185">[-]</label><label class="expand" for="c-39098185">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>In that scenario I employed an earliest-deadline-first scheduler...</i><p>I did something that sounds similar with the skip locked technique for a request queueing system supporting conveyor routing in a DC.<p>Priority alone wouldn&#x27;t work because requests in different areas of the conveyor had different lead times until the response was required, sometimes 5 feet and sometimes 300 feet.  If I made the shorter lead times all higher priority then they could all supersede an older request for longer sections that is now nearing the divert.<p>So the requests get submitted with a deadline datetime, and that is the index used to select the next request (top 1, order by deadline), worked pretty well.</div><br/></div></div></div></div><div id="39095115" class="c"><input type="checkbox" id="c-39095115" checked=""/><div class="controls bullet"><span class="by">nurettin</span><span>|</span><a href="#39093488">parent</a><span>|</span><a href="#39093717">prev</a><span>|</span><a href="#39093767">next</a><span>|</span><label class="collapse" for="c-39095115">[-]</label><label class="expand" for="c-39095115">[1 more]</label></div><br/><div class="children"><div class="content">First, query total time spent today for each tenant. Then, pick a job from the most unfortunate tenant&#x27;s queue.</div><br/></div></div><div id="39093767" class="c"><input type="checkbox" id="c-39093767" checked=""/><div class="controls bullet"><span class="by">pphysch</span><span>|</span><a href="#39093488">parent</a><span>|</span><a href="#39095115">prev</a><span>|</span><a href="#39093786">next</a><span>|</span><label class="collapse" for="c-39093767">[-]</label><label class="expand" for="c-39093767">[5 more]</label></div><br/><div class="children"><div class="content">You have the full power of PostgreSQL at your disposal, so there are many ways you can effectively tackle this issue.<p>- Decrement priority of all tenants jobs by 1 each time their job is executed, or increment other tenants&#x27; priorities (more ops but better behavior)<p>- Maintain a separate tenant priority table and join it + use for ordering when fetching the next job<p>And so on</div><br/><div id="39093892" class="c"><input type="checkbox" id="c-39093892" checked=""/><div class="controls bullet"><span class="by">fabian2k</span><span>|</span><a href="#39093488">root</a><span>|</span><a href="#39093767">parent</a><span>|</span><a href="#39094425">next</a><span>|</span><label class="collapse" for="c-39093892">[-]</label><label class="expand" for="c-39093892">[2 more]</label></div><br/><div class="children"><div class="content">I can think of plenty of inefficient ways to do this. The nice thing about the SKIP LOCKED queue is that it is very simple and pretty fast. Postgres just has to use an index to look at the jobs in some defined order and take the first one that isn&#x27;t locked.<p>The first option here would create an enormous amount of writes for each job fetched and likely slow it down to a crawl if enough jobs are in the queue.</div><br/><div id="39094640" class="c"><input type="checkbox" id="c-39094640" checked=""/><div class="controls bullet"><span class="by">pphysch</span><span>|</span><a href="#39093488">root</a><span>|</span><a href="#39093892">parent</a><span>|</span><a href="#39094425">next</a><span>|</span><label class="collapse" for="c-39094640">[-]</label><label class="expand" for="c-39094640">[1 more]</label></div><br/><div class="children"><div class="content">Many scheduling systems have a &quot;time in queue increases priority&quot; behavior; it is not an exotic proposition and could be implement efficiently in PostgreSQL.<p>Having too many jobs in queue is a problem on its own that should be addressed. Each tenant should be rate-limited or have a reasonable cap on number of waiting jobs.</div><br/></div></div></div></div><div id="39094425" class="c"><input type="checkbox" id="c-39094425" checked=""/><div class="controls bullet"><span class="by">karldcampbell</span><span>|</span><a href="#39093488">root</a><span>|</span><a href="#39093767">parent</a><span>|</span><a href="#39093892">prev</a><span>|</span><a href="#39093786">next</a><span>|</span><label class="collapse" for="c-39094425">[-]</label><label class="expand" for="c-39094425">[2 more]</label></div><br/><div class="children"><div class="content">As long as you don&#x27;t need a strict priority and a worker can just grab the next waiting job:<p><pre><code>  SELECT * FROM jobs ORDER BY RANDOM() LIMIT 1 SKIP LOCKED
</code></pre>
should do the trick</div><br/><div id="39094842" class="c"><input type="checkbox" id="c-39094842" checked=""/><div class="controls bullet"><span class="by">gnud</span><span>|</span><a href="#39093488">root</a><span>|</span><a href="#39094425">parent</a><span>|</span><a href="#39093786">next</a><span>|</span><label class="collapse" for="c-39094842">[-]</label><label class="expand" for="c-39094842">[1 more]</label></div><br/><div class="children"><div class="content">This will give more resources to tenants that schedule more jobs.<p>If tenant A schedules 99 jobs and tenant B schedules 1 job,
a &quot;fair&quot; algorithm would pick B&#x27;s job either first or second, RANDOM() will not.</div><br/></div></div></div></div></div></div></div></div><div id="39093786" class="c"><input type="checkbox" id="c-39093786" checked=""/><div class="controls bullet"><span class="by">andrewstuart</span><span>|</span><a href="#39093488">prev</a><span>|</span><a href="#39093515">next</a><span>|</span><label class="collapse" for="c-39093786">[-]</label><label class="expand" for="c-39093786">[1 more]</label></div><br/><div class="children"><div class="content">&gt;&gt; with Postgres and SKIP LOCKED always cropping up<p>Note that SKIP LOCKED is available in Microsoft SQL Server and MySQL and I believe possibly also in Oracle and IBM DB&#x2F;2.<p>To the article, I suspect there will be alot of detail challenged here.<p>There&#x27;s talk in here about &quot;creating queues&quot; to handle the fairness problem.  I might be misunderstanding what the hard bit is, but with a database backed queue you don&#x27;t have to create a queue - queues are virtual depending on what messages are in there and what other information is available such as username or tag.  if you want to be &quot;fair&quot; around username then round robin on that, or fair around some other bit of data then tag the message when it goes into the queue and when you are processing, round robin on that.<p>What is the hard bit here, what am I missing?</div><br/></div></div><div id="39093515" class="c"><input type="checkbox" id="c-39093515" checked=""/><div class="controls bullet"><span class="by">ctvo</span><span>|</span><a href="#39093786">prev</a><span>|</span><a href="#39093363">next</a><span>|</span><label class="collapse" for="c-39093515">[-]</label><label class="expand" for="c-39093515">[4 more]</label></div><br/><div class="children"><div class="content">Is &quot;step function&quot; a term of art I&#x27;m just ignorant of in computer science? AWS Step Functions, sure. How it&#x27;s used here? No idea.<p>&gt; It enables developers to write declarative step functions...<p>&gt;  With thousands of customers running thousands of step functions containing parallel steps....<p>&gt; If you&#x27;re familiar with step functions, you probably already see what&#x27;s happening here...</div><br/><div id="39093735" class="c"><input type="checkbox" id="c-39093735" checked=""/><div class="controls bullet"><span class="by">hot_gril</span><span>|</span><a href="#39093515">parent</a><span>|</span><a href="#39096613">next</a><span>|</span><label class="collapse" for="c-39093735">[-]</label><label class="expand" for="c-39093735">[1 more]</label></div><br/><div class="children"><div class="content">&quot;Step function&quot; is sort of a standard term, yeah. Each step is some piece of code that runs at some point in the near future and persists its result for the next step to ingest. It could randomly fail (crashes, preemption, etc) before persisting, in which case the step is retried soon, so it better not have consequential side effects. Most likely you&#x27;re interacting with external systems (like credit card processors) if you&#x27;re using step functions in the first place, so idempotency is key.<p>I&#x27;ve done basically this sorta manually at a smaller scale. Each step was a Postgres table, like &quot;user order initiated,&quot; &quot;order confirmed,&quot; &quot;order fulfilled,&quot; with automated steps (sometimes cronjobs) in between. Sometimes I wanted to expose that status to users. I could see using Inngest at a larger scale.</div><br/></div></div><div id="39096613" class="c"><input type="checkbox" id="c-39096613" checked=""/><div class="controls bullet"><span class="by">rmbyrro</span><span>|</span><a href="#39093515">parent</a><span>|</span><a href="#39093735">prev</a><span>|</span><a href="#39094355">next</a><span>|</span><label class="collapse" for="c-39096613">[-]</label><label class="expand" for="c-39096613">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think that&#x27;s exactly the meaning on this article in particular, but I&#x27;ve seen people using &quot;step function&quot; as synonym to a step in a Finite-State Machine.<p>SWE technical terms are used very loosely, especially on blog posts like this.</div><br/></div></div></div></div><div id="39093363" class="c"><input type="checkbox" id="c-39093363" checked=""/><div class="controls bullet"><span class="by">jawns</span><span>|</span><a href="#39093515">prev</a><span>|</span><a href="#39096507">next</a><span>|</span><label class="collapse" for="c-39093363">[-]</label><label class="expand" for="c-39093363">[1 more]</label></div><br/><div class="children"><div class="content">This problem can be extended to systems like project management, where your workers are not computers but people.<p>For instance: Suppose you have a team of six people, and you&#x27;re being asked to tackle two projects for two clients, each of equal value to the business.  One project will take two weeks to complete; another will take four months to complete.<p>How do you determine a &quot;fair&quot; way to divide up those projects?  Do you do one before the other?  Do you divide up your team&#x27;s capacity equally and do them in parallel?<p>This is the same sort of queuing problem described in the post.  So a solution to the computer queuing problem might have interesting implications for the broader problem.</div><br/></div></div><div id="39096507" class="c"><input type="checkbox" id="c-39096507" checked=""/><div class="controls bullet"><span class="by">mbreese</span><span>|</span><a href="#39093363">prev</a><span>|</span><a href="#39094127">next</a><span>|</span><label class="collapse" for="c-39096507">[-]</label><label class="expand" for="c-39096507">[1 more]</label></div><br/><div class="children"><div class="content">Another place to look for inspiration is the HPC world. Fairshare job queues have been active on multi tenant HPC clusters for decades. Each job typically has a priority value assigned to it based on the submission time, expected resources required, and how much of the cluster the account&#x2F;user has used recently. Priorities can be continuously updated until the job is released for processing.</div><br/></div></div><div id="39094127" class="c"><input type="checkbox" id="c-39094127" checked=""/><div class="controls bullet"><span class="by">jll29</span><span>|</span><a href="#39096507">prev</a><span>|</span><a href="#39093699">next</a><span>|</span><label class="collapse" for="c-39094127">[-]</label><label class="expand" for="c-39094127">[1 more]</label></div><br/><div class="children"><div class="content">Fair queuing in multi-tenant scenarios is also what describes what is going on in some financial trading systems: these queuing mechanisms are often opened up to regulators to demonstrate the fairness.</div><br/></div></div><div id="39093699" class="c"><input type="checkbox" id="c-39093699" checked=""/><div class="controls bullet"><span class="by">ykhli</span><span>|</span><a href="#39094127">prev</a><span>|</span><a href="#39098676">next</a><span>|</span><label class="collapse" for="c-39093699">[-]</label><label class="expand" for="c-39093699">[1 more]</label></div><br/><div class="children"><div class="content">Great job abstracting away so much complexity!<p>&gt; each step is a code-level transaction backed by its own job in the queue. If the step fails, it retries automatically. Any data returned from the step is automatically captured into the function run&#x27;s state and injected on each step call.<p>This is one thing I&#x27;ve seen so many companies spending tons of time implementing themselves, and happens _everywhere_ -- no code apps, finance software, hospitals, anything that deals with ordering system...the list goes on.<p>Glad I no longer need to write this from scratch!</div><br/></div></div><div id="39098676" class="c"><input type="checkbox" id="c-39098676" checked=""/><div class="controls bullet"><span class="by">osigurdson</span><span>|</span><a href="#39093699">prev</a><span>|</span><a href="#39093723">next</a><span>|</span><label class="collapse" for="c-39098676">[-]</label><label class="expand" for="c-39098676">[1 more]</label></div><br/><div class="children"><div class="content">NATS has multi tenancy built in.</div><br/></div></div><div id="39093723" class="c"><input type="checkbox" id="c-39093723" checked=""/><div class="controls bullet"><span class="by">hot_gril</span><span>|</span><a href="#39098676">prev</a><span>|</span><a href="#39096599">next</a><span>|</span><label class="collapse" for="c-39093723">[-]</label><label class="expand" for="c-39093723">[3 more]</label></div><br/><div class="children"><div class="content">A &quot;nuclear option&quot; I&#x27;ve seen in the wild is Queue-It. Puts your entire flow behind a queue that&#x27;s user-visible, with a waiting list page. Then presumably your own site&#x27;s logic doesn&#x27;t do any queuing.</div><br/><div id="39093895" class="c"><input type="checkbox" id="c-39093895" checked=""/><div class="controls bullet"><span class="by">danfarrelly</span><span>|</span><a href="#39093723">parent</a><span>|</span><a href="#39096599">next</a><span>|</span><label class="collapse" for="c-39093895">[-]</label><label class="expand" for="c-39093895">[2 more]</label></div><br/><div class="children"><div class="content">How do they handle multi-tenancy for their users? Any post on that?</div><br/><div id="39094624" class="c"><input type="checkbox" id="c-39094624" checked=""/><div class="controls bullet"><span class="by">hot_gril</span><span>|</span><a href="#39093723">root</a><span>|</span><a href="#39093895">parent</a><span>|</span><a href="#39096599">next</a><span>|</span><label class="collapse" for="c-39094624">[-]</label><label class="expand" for="c-39094624">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t know, but the requirements are different. They manage a single huge queue for your website (or part of it), and your own backend is expected to be able to handle some trivially small number of concurrent users. The most common use case is highly contentious online ticket sales, where users might even wait an hour in line. Latency isn&#x27;t much of a concern.</div><br/></div></div></div></div></div></div><div id="39095019" class="c"><input type="checkbox" id="c-39095019" checked=""/><div class="controls bullet"><span class="by">wilgertvelinga</span><span>|</span><a href="#39096599">prev</a><span>|</span><a href="#39093238">next</a><span>|</span><label class="collapse" for="c-39095019">[-]</label><label class="expand" for="c-39095019">[1 more]</label></div><br/><div class="children"><div class="content">Sounds a lot like Azure Durable functions. Which we started using recently. Curious to know if inngest could also fit our use case.</div><br/></div></div><div id="39093238" class="c"><input type="checkbox" id="c-39093238" checked=""/><div class="controls bullet"><span class="by">quantum_bits</span><span>|</span><a href="#39095019">prev</a><span>|</span><a href="#39094242">next</a><span>|</span><label class="collapse" for="c-39093238">[-]</label><label class="expand" for="c-39093238">[1 more]</label></div><br/><div class="children"><div class="content">This is cool but pretty light on the details.  Judging by how it reads, they create queues for each function, then create queues of queues for workers.  It sounds similar to the QuiCK paper from Apple: <a href="https:&#x2F;&#x2F;www.foundationdb.org&#x2F;files&#x2F;QuiCK.pdf" rel="nofollow">https:&#x2F;&#x2F;www.foundationdb.org&#x2F;files&#x2F;QuiCK.pdf</a></div><br/></div></div><div id="39094242" class="c"><input type="checkbox" id="c-39094242" checked=""/><div class="controls bullet"><span class="by">brightball</span><span>|</span><a href="#39093238">prev</a><span>|</span><a href="#39093796">next</a><span>|</span><label class="collapse" for="c-39094242">[-]</label><label class="expand" for="c-39094242">[3 more]</label></div><br/><div class="children"><div class="content">This honestly sounds like a job for the BEAM (Erlang&#x2F;Elixir).<p>The preemptive scheduler would cover almost every need mentioned in the article.</div><br/><div id="39097784" class="c"><input type="checkbox" id="c-39097784" checked=""/><div class="controls bullet"><span class="by">clarkdave</span><span>|</span><a href="#39094242">parent</a><span>|</span><a href="#39095226">next</a><span>|</span><label class="collapse" for="c-39097784">[-]</label><label class="expand" for="c-39097784">[1 more]</label></div><br/><div class="children"><div class="content">Not sure if this is what you&#x27;re getting at, but RabbitMQ is indeed pretty great at having thousands of queues, even on modest hardware, and can be used for per-tenant queues in this way.<p>It does have some drawbacks though: if you have thousands of mirrored or quorum queues, managing the cluster becomes more cumbersome - it can take a while to replace nodes (rebalancing thousands of queues around). Also, the management tools (the web UI especially) don&#x27;t perform that well if you have 10,000s of queues and 100,000s of consumers</div><br/></div></div><div id="39095226" class="c"><input type="checkbox" id="c-39095226" checked=""/><div class="controls bullet"><span class="by">darwin67</span><span>|</span><a href="#39094242">parent</a><span>|</span><a href="#39097784">prev</a><span>|</span><a href="#39093796">next</a><span>|</span><label class="collapse" for="c-39095226">[-]</label><label class="expand" for="c-39095226">[1 more]</label></div><br/><div class="children"><div class="content">Which part of BEAM are you talking about?
I know some cases can be solved by it already, but not almost every need.<p>The fairness of the BEAM scheduler is not the same as multi-tenant fairness.
I&#x27;m aware of lcnt in Erlang that helps with contention, but that will have a hit in throughput like any other locks.<p>Unless I&#x27;m missing something?</div><br/></div></div></div></div><div id="39095931" class="c"><input type="checkbox" id="c-39095931" checked=""/><div class="controls bullet"><span class="by">1oooqooq</span><span>|</span><a href="#39093796">prev</a><span>|</span><a href="#39099014">next</a><span>|</span><label class="collapse" for="c-39095931">[-]</label><label class="expand" for="c-39095931">[1 more]</label></div><br/><div class="children"><div class="content">i thought RH had solved that. just write a systemd unit file with the cpu quotas. bam. done. &#x2F;s?</div><br/></div></div><div id="39093797" class="c"><input type="checkbox" id="c-39093797" checked=""/><div class="controls bullet"><span class="by">maerF0x0</span><span>|</span><a href="#39099014">prev</a><span>|</span><label class="collapse" for="c-39093797">[-]</label><label class="expand" for="c-39093797">[9 more]</label></div><br/><div class="children"><div class="content">btw &quot;fair&quot; is an entirely subjective and unproductive way to describe a system. There&#x27;s simply properties and priorities. Many of us have learned fair to mean a great variance of things. From per capita equal load, to you get what you pay for, to anything goes just don&#x27;t hurt anyone. In families we might see this as each child gets the same number of cookies. In capitalism fair is what you negotiate and agree to. The point isn&#x27;t what is or isn&#x27;t fair, but that there is no universal &quot;fair&quot;.<p>Should a user be able to jump the queue? What if they&#x27;re your number one driver of revenue? Or they have a time-sensitive function w&#x2F; a deadline? Or if they&#x27;ve produced no load on the system in the past $TIME_UNIT. All of these are not fair, just properties to be designed into a product.</div><br/><div id="39096716" class="c"><input type="checkbox" id="c-39096716" checked=""/><div class="controls bullet"><span class="by">0xbadcafebee</span><span>|</span><a href="#39093797">parent</a><span>|</span><a href="#39094029">next</a><span>|</span><label class="collapse" for="c-39096716">[-]</label><label class="expand" for="c-39096716">[2 more]</label></div><br/><div class="children"><div class="content"><i>Fair queueing</i> is a very old (40 years?) CS &#x2F; networking paradigm. It&#x27;s what makes your internet connection feel snappy. It is distinct from order and priority, and is not subjective; there are many forms of it and each has a specific meaning.<p>There are many other forms of queueing other than <i>fair</i>, so if you&#x27;re looking for a more specific use case, there may already be an algorithm for it.<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Fair_queuing" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Fair_queuing</a> <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Weighted_fair_queueing" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Weighted_fair_queueing</a> <a href="https:&#x2F;&#x2F;intronetworks.cs.luc.edu&#x2F;1&#x2F;html&#x2F;queuing.html" rel="nofollow">https:&#x2F;&#x2F;intronetworks.cs.luc.edu&#x2F;1&#x2F;html&#x2F;queuing.html</a></div><br/><div id="39099213" class="c"><input type="checkbox" id="c-39099213" checked=""/><div class="controls bullet"><span class="by">maerF0x0</span><span>|</span><a href="#39093797">root</a><span>|</span><a href="#39096716">parent</a><span>|</span><a href="#39094029">next</a><span>|</span><label class="collapse" for="c-39099213">[-]</label><label class="expand" for="c-39099213">[1 more]</label></div><br/><div class="children"><div class="content">even in your linked examples Fair queuing boils down to a fairness measure which themselves are defined for certain properties.<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Fairness_measure" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Fairness_measure</a></div><br/></div></div></div></div><div id="39094029" class="c"><input type="checkbox" id="c-39094029" checked=""/><div class="controls bullet"><span class="by">8n4vidtmkvmk</span><span>|</span><a href="#39093797">parent</a><span>|</span><a href="#39096716">prev</a><span>|</span><label class="collapse" for="c-39094029">[-]</label><label class="expand" for="c-39094029">[6 more]</label></div><br/><div class="children"><div class="content">Yeah I didn&#x27;t understand what the author even meant in the article. How is first come first serve not fair?</div><br/><div id="39094286" class="c"><input type="checkbox" id="c-39094286" checked=""/><div class="controls bullet"><span class="by">sjansen</span><span>|</span><a href="#39093797">root</a><span>|</span><a href="#39094029">parent</a><span>|</span><a href="#39094279">next</a><span>|</span><label class="collapse" for="c-39094286">[-]</label><label class="expand" for="c-39094286">[1 more]</label></div><br/><div class="children"><div class="content">The author defined fair in a pretty industry standard way:<p>&gt; One user should not be able to block another&#x27;s work.<p>A multi-tenant architecture implies over committing resources to achieve better economics. Once upon a time, decades ago, when computers were so expense that companies payed for batch processing instead of owning their own, FIFO was acceptable. (And for a tiny part of the market it still is.) But ever since the rise of time-sharing operating systems, users have come to expect short delays for small tasks. If you let one customer monopolize your capacity because they submitted a mountain of work before a second customer submits a handful, you probably won&#x27;t have the second customer much longer.</div><br/></div></div><div id="39094279" class="c"><input type="checkbox" id="c-39094279" checked=""/><div class="controls bullet"><span class="by">tonyhb</span><span>|</span><a href="#39093797">root</a><span>|</span><a href="#39094029">parent</a><span>|</span><a href="#39094286">prev</a><span>|</span><label class="collapse" for="c-39094279">[-]</label><label class="expand" for="c-39094279">[4 more]</label></div><br/><div class="children"><div class="content">Fair means that we should be giving users roughly the same capacity, or at least roughly the same chances to be worked on.<p>In the case of this queue, where each letter represents a user:<p>[A, Bx10000, C, D, E]<p>We&#x27;re being unfair to C, D, and E.  Realistically, while working on B&#x27;s jobs we should have some mechanism to know that latency for C, D, and E are increasing and that we can start assigning them to workers.<p>Without that, latency for any step function you run is highly variable and impacted by other users.  With multi-tenant fairness, latency is purely driven by how well we auto-scale and your own concurrency capacity.<p>The post here is about multi-tenant fairness in particular, so the intent is that fairness is viewed from a multi-tenant &#x2F; PaaS lense.</div><br/><div id="39096603" class="c"><input type="checkbox" id="c-39096603" checked=""/><div class="controls bullet"><span class="by">maerF0x0</span><span>|</span><a href="#39093797">root</a><span>|</span><a href="#39094279">parent</a><span>|</span><label class="collapse" for="c-39096603">[-]</label><label class="expand" for="c-39096603">[3 more]</label></div><br/><div class="children"><div class="content">&gt; or at least roughly the same chances to be worked on.<p>Says who? What if B pays 10000x what ACDE do combined? What if B pays for that capacity?<p>What if B was silent for the 10000 seconds prior? And is now bursting their load just like ACDE do at other times?<p>There is no objective fair.<p>Perhaps the only objectively unfair I could think of is if you paid for a service and it&#x27;s not rendered, at all, ever. That&#x27;s probably unfair. But everything else is a grey spectrum in between and depends on the agreed upon properties.</div><br/><div id="39097877" class="c"><input type="checkbox" id="c-39097877" checked=""/><div class="controls bullet"><span class="by">grogers</span><span>|</span><a href="#39093797">root</a><span>|</span><a href="#39096603">parent</a><span>|</span><label class="collapse" for="c-39097877">[-]</label><label class="expand" for="c-39097877">[2 more]</label></div><br/><div class="children"><div class="content">&gt; What if B pays 10000x what ACDE do combined? What if B pays for that capacity?<p>If B&#x27;s load is consistently that high compared to the others then presumably the system has enough total capacity that those requests don&#x27;t impact the latency for everyone else. If B pays for dedicated capacity they should ideally get their own queue.<p>&gt; What if B was silent for the 10000 seconds prior?<p>Then B should smooth out their load better.<p>In this extreme an example, not much is lost for B by prioritizing C, D, E first sometimes anyways.<p>There might not be one single definition of fairness, but preventing one noisy user from impacting other users is a pretty common way to approach it.</div><br/><div id="39099217" class="c"><input type="checkbox" id="c-39099217" checked=""/><div class="controls bullet"><span class="by">maerF0x0</span><span>|</span><a href="#39093797">root</a><span>|</span><a href="#39097877">parent</a><span>|</span><label class="collapse" for="c-39099217">[-]</label><label class="expand" for="c-39099217">[1 more]</label></div><br/><div class="children"><div class="content">All those shoulds are value statements which are not universal law. They&#x27;re opinions about what constitutes fair.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></body></html>