<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1734858060859" as="style"/><link rel="stylesheet" href="styles.css?v=1734858060859"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.greptile.com/blog/make-llms-shut-up">How we made our AI code review bot stop leaving nitpicky comments</a> <span class="domain">(<a href="https://www.greptile.com">www.greptile.com</a>)</span></div><div class="subtext"><span>dakshgupta</span> | <span>81 comments</span></div><br/><div><div id="42485165" class="c"><input type="checkbox" id="c-42485165" checked=""/><div class="controls bullet"><span class="by">fnqi8ckfek</span><span>|</span><a href="#42484498">next</a><span>|</span><label class="collapse" for="c-42485165">[-]</label><label class="expand" for="c-42485165">[2 more]</label></div><br/><div class="children"><div class="content">Reading from the other comments here, I&#x27;m the only one thinking that this is just busywork...? Just get rid of the thing, it&#x27;s a solution without a problem.</div><br/></div></div><div id="42484498" class="c"><input type="checkbox" id="c-42484498" checked=""/><div class="controls bullet"><span class="by">jerrygoyal</span><span>|</span><a href="#42485165">prev</a><span>|</span><a href="#42482821">next</a><span>|</span><label class="collapse" for="c-42484498">[-]</label><label class="expand" for="c-42484498">[9 more]</label></div><br/><div class="children"><div class="content">I&#x27;m in the market for PR review bots, as the nitpicking issue is real. So far, I have tried Coderabbit, but it adds too much noise to PRs, and only a very small percentage of comments are actually useful. I specifically instructed it to ignore nitpicks, but it still added such comments. Their cringy ASCII art comments make it even harder to take them seriously.<p>I recently signed up for Korbit AI, but it&#x27;s too soon to provide feedback. Honestly, I’m getting a bit fed up with experimenting with different PR bots.<p>Question for the author: In what ways is your solution better than Coderabbit and Korbit AI?</div><br/><div id="42484552" class="c"><input type="checkbox" id="c-42484552" checked=""/><div class="controls bullet"><span class="by">dakshgupta</span><span>|</span><a href="#42484498">parent</a><span>|</span><a href="#42484744">next</a><span>|</span><label class="collapse" for="c-42484552">[-]</label><label class="expand" for="c-42484552">[1 more]</label></div><br/><div class="children"><div class="content">I haven’t explored Korbit but with CodeRabbit there are a couple of things:<p>1. We are better at full codebase context, because of how we index the codebase like a graph and use graph search and an LLM to determine what other parts of the codebase should be taken into consideration while reviewing a diff.<p>2. We offer an API you can use to build custom workflows, for example every time a test fails in your pipeline you can pass the output to Greptile and it will diagnose with full codebase context.<p>3. Customers of ours that switched from CodeRabbit usually say Greptile has far fewer and less verbose comments. This is a subjective, of course.<p>That said, CodeRabbit is cheaper.<p>Both products have free trials for though, so I would recommend trying both and seeing which one your team prefers, which is ultimately what matters.<p>I’m happy to answer more questions or a demo for your team too -&gt; daksh@greptile.com</div><br/></div></div><div id="42484744" class="c"><input type="checkbox" id="c-42484744" checked=""/><div class="controls bullet"><span class="by">swells34</span><span>|</span><a href="#42484498">parent</a><span>|</span><a href="#42484552">prev</a><span>|</span><a href="#42482821">next</a><span>|</span><label class="collapse" for="c-42484744">[-]</label><label class="expand" for="c-42484744">[7 more]</label></div><br/><div class="children"><div class="content">Isn&#x27;t code review the one area you&#x27;d <i>never</i> want to replace the programmer in? Like, that is the most important step of the process; it&#x27;s where we break down the logic and sanity check the implementation. That is expressly where AI is the weakest.</div><br/><div id="42485096" class="c"><input type="checkbox" id="c-42485096" checked=""/><div class="controls bullet"><span class="by">hansvm</span><span>|</span><a href="#42484498">root</a><span>|</span><a href="#42484744">parent</a><span>|</span><a href="#42484814">next</a><span>|</span><label class="collapse" for="c-42485096">[-]</label><label class="expand" for="c-42485096">[1 more]</label></div><br/><div class="children"><div class="content">If you think of the &quot;AI&quot; benefit as more of a linter then the value starts to become clear.<p>E.g., I&#x27;ve never hesitated to add a linting rule requiring `except Exception:` in lieu of `except:` in Python, since the latter is very rarely required (so the necessary incantations to silence the linter are cheap on average) and since the former is almost always a bug prone to making shutdown&#x2F;iteration&#x2F;etc harder than they should be. When I add that rule at new companies, ~90% of the violations are latent bugs.<p>AI has the potential to (though I haven&#x27;t seen it work well yet in this capacity) lint most such problematic patterns. In an ideal world, it&#x27;d even have the local context to know that, e.g., since you&#x27;re handling a DB transaction and immediately re-throwing the raw `except:` is appropriate and not even flag it in the &quot;review&quot; (the AI linting), reducing the false positive rate. You&#x27;d still want a human review, but you could avoid bugging a human till the code is worth reviewing, or you could let the human focus on things that matter instead of harping on your use of low-level atomic fences yet again. AI has potential to improve the transition from &quot;code complete&quot; to &quot;shipped and working.&quot;</div><br/></div></div><div id="42484814" class="c"><input type="checkbox" id="c-42484814" checked=""/><div class="controls bullet"><span class="by">imoverclocked</span><span>|</span><a href="#42484498">root</a><span>|</span><a href="#42484744">parent</a><span>|</span><a href="#42485096">prev</a><span>|</span><a href="#42484829">next</a><span>|</span><label class="collapse" for="c-42484814">[-]</label><label class="expand" for="c-42484814">[1 more]</label></div><br/><div class="children"><div class="content">Many code review products are not AI. They are often collections of rules that have been specifically crafted to catch bad patterns. Some of the rules are stylistic in nature and those tend to turn people away the fastest IMHO.<p>Many of these tools can be integrated into a local workflow so they will never ping you on a PR but many developers prefer to just write some code and let the review process suss things out.</div><br/></div></div><div id="42484829" class="c"><input type="checkbox" id="c-42484829" checked=""/><div class="controls bullet"><span class="by">yorwba</span><span>|</span><a href="#42484498">root</a><span>|</span><a href="#42484744">parent</a><span>|</span><a href="#42484814">prev</a><span>|</span><a href="#42484847">next</a><span>|</span><label class="collapse" for="c-42484829">[-]</label><label class="expand" for="c-42484829">[1 more]</label></div><br/><div class="children"><div class="content">You probably shouldn&#x27;t take a code review bot&#x27;s &quot;LGTM!&quot; at face value, but if it tells you there is an issue with your code and it is indeed an issue with your code, it has successfully subbed in for your coworker who didn&#x27;t get around to looking at it yet.</div><br/></div></div><div id="42484847" class="c"><input type="checkbox" id="c-42484847" checked=""/><div class="controls bullet"><span class="by">dakshgupta</span><span>|</span><a href="#42484498">root</a><span>|</span><a href="#42484744">parent</a><span>|</span><a href="#42484829">prev</a><span>|</span><a href="#42484872">next</a><span>|</span><label class="collapse" for="c-42484847">[-]</label><label class="expand" for="c-42484847">[2 more]</label></div><br/><div class="children"><div class="content">I agree - at least with where technology is today, I would strongly discourage replacing human code review with AI.<p>It does however serve as a good first pass, so by the time the human reviewer gets it, the little things have been addressed and they can focus on broader technical decisions.<p>Would you want your coworkers to run their PRs through an AI reviewer, resolve those comments, then send it to you?</div><br/></div></div><div id="42484872" class="c"><input type="checkbox" id="c-42484872" checked=""/><div class="controls bullet"><span class="by">jerrygoyal</span><span>|</span><a href="#42484498">root</a><span>|</span><a href="#42484744">parent</a><span>|</span><a href="#42484847">prev</a><span>|</span><a href="#42482821">next</a><span>|</span><label class="collapse" for="c-42484872">[-]</label><label class="expand" for="c-42484872">[1 more]</label></div><br/><div class="children"><div class="content">No one is blindly merging PR after AI Code Review. Think of review bot as an extra pair of eyes.</div><br/></div></div></div></div></div></div><div id="42482821" class="c"><input type="checkbox" id="c-42482821" checked=""/><div class="controls bullet"><span class="by">XenophileJKO</span><span>|</span><a href="#42484498">prev</a><span>|</span><a href="#42483156">next</a><span>|</span><label class="collapse" for="c-42482821">[-]</label><label class="expand" for="c-42482821">[9 more]</label></div><br/><div class="children"><div class="content">Unless they were using a model too stupid for this operation, the fundamental problem is usually solvable via prompting.<p>Usually the issue is that the models have a bias for action, so you need to give it an accetpable action when there isn&#x27;t a good comment. Some other output&#x2F;determination.<p>I&#x27;ve seen this in many other similar applications.</div><br/><div id="42483257" class="c"><input type="checkbox" id="c-42483257" checked=""/><div class="controls bullet"><span class="by">keepingscore</span><span>|</span><a href="#42482821">parent</a><span>|</span><a href="#42483246">next</a><span>|</span><label class="collapse" for="c-42483257">[-]</label><label class="expand" for="c-42483257">[6 more]</label></div><br/><div class="children"><div class="content">This isn&#x27;t my post but I work with llms everyday and I&#x27;ve seen this kind of instruction ignoring behavior on sonnet when the context window starts getting close to the edge.</div><br/><div id="42483700" class="c"><input type="checkbox" id="c-42483700" checked=""/><div class="controls bullet"><span class="by">XenophileJKO</span><span>|</span><a href="#42482821">root</a><span>|</span><a href="#42483257">parent</a><span>|</span><a href="#42483701">next</a><span>|</span><label class="collapse" for="c-42483700">[-]</label><label class="expand" for="c-42483700">[4 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t know, in practice there are so many potential causes that you have to look case by case in situations like that. I don&#x27;t have a ton of experience with the raw Claude model specifically, but would anticipate you&#x27;ll have the same problem classes.<p>Usually it comes down to one of the following:<p>- ambiguity and semantics (I once had a significant behavior difference between &quot;suggest&quot; and &quot;recommend&quot;, i.e. a model can suggest without recommending.)<p>- conflicting instructions<p>- data&#x2F;instruction bleeding (delimiters help, but if the span is too long it can loose track of what is data and what is instructions.)<p>- action bias (If the task is to find code comments for example, even if you tell it not to, it will have a bias to do it as you defined the task that way.)<p>- exceeding attention capacity (having to pay attention to too much or having too many instructions. This is where structures output or chain of thought type approaches help. They help focus attention on each step of the process and the related rules.)<p>I feel like these are the ones you encounter the most.</div><br/><div id="42483708" class="c"><input type="checkbox" id="c-42483708" checked=""/><div class="controls bullet"><span class="by">dakshgupta</span><span>|</span><a href="#42482821">root</a><span>|</span><a href="#42483700">parent</a><span>|</span><a href="#42483701">next</a><span>|</span><label class="collapse" for="c-42483708">[-]</label><label class="expand" for="c-42483708">[3 more]</label></div><br/><div class="children"><div class="content">One word changes impacting output is interesting but also quite frustrating. Especially because the patterns don’t translate across models.</div><br/><div id="42484025" class="c"><input type="checkbox" id="c-42484025" checked=""/><div class="controls bullet"><span class="by">gopher_space</span><span>|</span><a href="#42482821">root</a><span>|</span><a href="#42483708">parent</a><span>|</span><a href="#42483701">next</a><span>|</span><label class="collapse" for="c-42484025">[-]</label><label class="expand" for="c-42484025">[2 more]</label></div><br/><div class="children"><div class="content">The &quot;write like the people who wrote the info you want&quot; pattern absolutely translates across models.</div><br/><div id="42484230" class="c"><input type="checkbox" id="c-42484230" checked=""/><div class="controls bullet"><span class="by">sdesol</span><span>|</span><a href="#42482821">root</a><span>|</span><a href="#42484025">parent</a><span>|</span><a href="#42483701">next</a><span>|</span><label class="collapse" for="c-42484230">[-]</label><label class="expand" for="c-42484230">[1 more]</label></div><br/><div class="children"><div class="content">Yes and no. I&#x27;ve found the order in which you give instructions matters for some models as well. With LLMs, you really need to treat them like black boxes and you cannot assume one prompt will work for all. It is honestly, in my experience, a lot of trial and error.</div><br/></div></div></div></div></div></div></div></div><div id="42483701" class="c"><input type="checkbox" id="c-42483701" checked=""/><div class="controls bullet"><span class="by">dakshgupta</span><span>|</span><a href="#42482821">root</a><span>|</span><a href="#42483257">parent</a><span>|</span><a href="#42483700">prev</a><span>|</span><a href="#42483246">next</a><span>|</span><label class="collapse" for="c-42483701">[-]</label><label class="expand" for="c-42483701">[1 more]</label></div><br/><div class="children"><div class="content">This might be what we experienced. We regularly have context reach 30k+ tokens.</div><br/></div></div></div></div><div id="42483246" class="c"><input type="checkbox" id="c-42483246" checked=""/><div class="controls bullet"><span class="by">marviel</span><span>|</span><a href="#42482821">parent</a><span>|</span><a href="#42483257">prev</a><span>|</span><a href="#42482864">next</a><span>|</span><label class="collapse" for="c-42483246">[-]</label><label class="expand" for="c-42483246">[1 more]</label></div><br/><div class="children"><div class="content">+1 for &quot;No Comment&#x2F;Action Required&quot; responses reducing trigger-happiness</div><br/></div></div></div></div><div id="42483156" class="c"><input type="checkbox" id="c-42483156" checked=""/><div class="controls bullet"><span class="by">iLoveOncall</span><span>|</span><a href="#42482821">prev</a><span>|</span><a href="#42481955">next</a><span>|</span><label class="collapse" for="c-42483156">[-]</label><label class="expand" for="c-42483156">[3 more]</label></div><br/><div class="children"><div class="content">It&#x27;s funny because I wouldn&#x27;t consider the comment that they highlight in their post as a nitpick.<p>Something that has an impact on the long term maintainability of code is definitely not nitpikcky, and in the majority of cases define a type fits this category as it makes refactors and extensions MUCH easier.<p>On top of that, I think the approach they went with is a huge mistake. The same comment can be a nitpick on one CR but crucial on another, clustering them is destined to result in false-positives and false-negatives.<p>I&#x27;m not sure I&#x27;d want to use a product to review my code for which 1) I cannot customize the rules, 2) it seems like the rules chosen by the creators are poor.<p>To be honest I wouldn&#x27;t want to use any AI-based code reviewer at all. We have one at work (FAANG, so something with a large dedicated team) and it has not once produced a useful comment and instead has been factually wrong many times.</div><br/><div id="42483750" class="c"><input type="checkbox" id="c-42483750" checked=""/><div class="controls bullet"><span class="by">dakshgupta</span><span>|</span><a href="#42483156">parent</a><span>|</span><a href="#42485087">next</a><span>|</span><label class="collapse" for="c-42483750">[-]</label><label class="expand" for="c-42483750">[1 more]</label></div><br/><div class="children"><div class="content">This is an important point - there is no universal understanding of nitpickiness. It is why we have it learn every new customers ways from scratch.</div><br/></div></div><div id="42485087" class="c"><input type="checkbox" id="c-42485087" checked=""/><div class="controls bullet"><span class="by">jbirer</span><span>|</span><a href="#42483156">parent</a><span>|</span><a href="#42483750">prev</a><span>|</span><a href="#42481955">next</a><span>|</span><label class="collapse" for="c-42485087">[-]</label><label class="expand" for="c-42485087">[1 more]</label></div><br/><div class="children"><div class="content">Two theories:<p>1) This is an ego problem. Whoever is doing the development cannot handle being called out on certain software architecture &#x2F; coding mistakes, so it becomes &quot;nitpicking&quot;.<p>2) The software shop has a &quot;ship out faster, cut corners&quot; culture, which at that point might as well turn off the AI review bot.</div><br/></div></div></div></div><div id="42481955" class="c"><input type="checkbox" id="c-42481955" checked=""/><div class="controls bullet"><span class="by">pama</span><span>|</span><a href="#42483156">prev</a><span>|</span><a href="#42484584">next</a><span>|</span><label class="collapse" for="c-42481955">[-]</label><label class="expand" for="c-42481955">[10 more]</label></div><br/><div class="children"><div class="content">After failing with three reasonable ideas, they solved the problem with an idea that previously would have seemed unlikely to work (get similarity to past known nits and use a threshold of 3 similar nits above a certain cutoff similarity score for filtering). A lot of applications of ML have a similar hacky trial and error flavor like that. Intuition is often built in retrospect and may not transfer well to other domains. I would have guessed that finetuning would also work, but agree with the author that it would be more expensive and less portable across different models.</div><br/><div id="42482035" class="c"><input type="checkbox" id="c-42482035" checked=""/><div class="controls bullet"><span class="by">dakshgupta</span><span>|</span><a href="#42481955">parent</a><span>|</span><a href="#42483194">next</a><span>|</span><label class="collapse" for="c-42482035">[-]</label><label class="expand" for="c-42482035">[5 more]</label></div><br/><div class="children"><div class="content">Since we posted this, two camps of people reached out:<p>Classical ML people who recommended we try training a classifier, possibly on the embeddings.<p>Fine tuning platforms that recommended we try their platform.<p>The challenge there would be gathering enough data <i>per customer</i> to meaningfully capture their definition and standard for nit-pickiness.</div><br/><div id="42482336" class="c"><input type="checkbox" id="c-42482336" checked=""/><div class="controls bullet"><span class="by">pama</span><span>|</span><a href="#42481955">root</a><span>|</span><a href="#42482035">parent</a><span>|</span><a href="#42483194">next</a><span>|</span><label class="collapse" for="c-42482336">[-]</label><label class="expand" for="c-42482336">[4 more]</label></div><br/><div class="children"><div class="content">What you use now is a simple KNN classifier, and if it works well enough, perhaps no need to go much further. If you need to squeeze out a couple additional percentage points maybe try a different simple and robust ML classifier (random forest, xgboost, or a simple two layer network). All these methods, including your current classifier, will get better with additional data and minor tuning in the future.</div><br/><div id="42482419" class="c"><input type="checkbox" id="c-42482419" checked=""/><div class="controls bullet"><span class="by">dakshgupta</span><span>|</span><a href="#42481955">root</a><span>|</span><a href="#42482336">parent</a><span>|</span><a href="#42483194">next</a><span>|</span><label class="collapse" for="c-42482419">[-]</label><label class="expand" for="c-42482419">[3 more]</label></div><br/><div class="children"><div class="content">Thank you, I will try this. I suspect we can extract some universal theory of nits and have a base filter to start with, and have it learn per-company preferences on top of that.</div><br/><div id="42483271" class="c"><input type="checkbox" id="c-42483271" checked=""/><div class="controls bullet"><span class="by">keepingscore</span><span>|</span><a href="#42481955">root</a><span>|</span><a href="#42482419">parent</a><span>|</span><a href="#42483194">next</a><span>|</span><label class="collapse" for="c-42483271">[-]</label><label class="expand" for="c-42483271">[2 more]</label></div><br/><div class="children"><div class="content">You should be able to do that already by taking all of your customers nit embeddings and averaging them to produce a point in space that represents the universal nit. Embeddings are really cool and the fact that they still work when averaging is one of their cool properties.</div><br/><div id="42483763" class="c"><input type="checkbox" id="c-42483763" checked=""/><div class="controls bullet"><span class="by">dakshgupta</span><span>|</span><a href="#42481955">root</a><span>|</span><a href="#42483271">parent</a><span>|</span><a href="#42483194">next</a><span>|</span><label class="collapse" for="c-42483763">[-]</label><label class="expand" for="c-42483763">[1 more]</label></div><br/><div class="children"><div class="content">This is a cool idea - I’ll try this and add it as an appendix to this post.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="42483194" class="c"><input type="checkbox" id="c-42483194" checked=""/><div class="controls bullet"><span class="by">olddustytrail</span><span>|</span><a href="#42481955">parent</a><span>|</span><a href="#42482035">prev</a><span>|</span><a href="#42484584">next</a><span>|</span><label class="collapse" for="c-42483194">[-]</label><label class="expand" for="c-42483194">[4 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think the prompt was reasonable. Nits are the eggs of headlice. Expecting the LLM to guess they meant superficial issues, rather than just spelling that out, is a bit weird.<p>It&#x27;s like saying &quot;don&#x27;t comment on elephants&quot; when you mean don&#x27;t comment on the obvious stuff.</div><br/><div id="42483298" class="c"><input type="checkbox" id="c-42483298" checked=""/><div class="controls bullet"><span class="by">whitfin</span><span>|</span><a href="#42481955">root</a><span>|</span><a href="#42483194">parent</a><span>|</span><a href="#42484044">next</a><span>|</span><label class="collapse" for="c-42483298">[-]</label><label class="expand" for="c-42483298">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, even the title here says &quot;nitpicky&quot;. I&#x27;m not sure if they tried &quot;nitpicks&quot; instead of &quot;nits&quot;, but I don&#x27;t know why you wouldn&#x27;t...</div><br/></div></div><div id="42484044" class="c"><input type="checkbox" id="c-42484044" checked=""/><div class="controls bullet"><span class="by">tayo42</span><span>|</span><a href="#42481955">root</a><span>|</span><a href="#42483194">parent</a><span>|</span><a href="#42483298">prev</a><span>|</span><a href="#42484584">next</a><span>|</span><label class="collapse" for="c-42484044">[-]</label><label class="expand" for="c-42484044">[2 more]</label></div><br/><div class="children"><div class="content">Do llms struggle with other homonyms?</div><br/><div id="42484978" class="c"><input type="checkbox" id="c-42484978" checked=""/><div class="controls bullet"><span class="by">Eisenstein</span><span>|</span><a href="#42481955">root</a><span>|</span><a href="#42484044">parent</a><span>|</span><a href="#42484584">next</a><span>|</span><label class="collapse" for="c-42484978">[-]</label><label class="expand" for="c-42484978">[1 more]</label></div><br/><div class="children"><div class="content">They can, but I think the parent is saying that when you are crafting an instruction for someone or something to follow, you should be as direct and as clear as possible in order to remove the need for the actor to have to intuit a decision instead of act on certainty.<p>I would start with something like: &#x27;Avoid writing comments which only concern stylistic issues or which only contain criticisms considered pedantic or trivial.&#x27;</div><br/></div></div></div></div></div></div></div></div><div id="42484584" class="c"><input type="checkbox" id="c-42484584" checked=""/><div class="controls bullet"><span class="by">righthand</span><span>|</span><a href="#42481955">prev</a><span>|</span><a href="#42484588">next</a><span>|</span><label class="collapse" for="c-42484584">[-]</label><label class="expand" for="c-42484584">[3 more]</label></div><br/><div class="children"><div class="content">Our AI code review bot (Codacy) is just an LLM that compiles all linter rules and might be the most annoying useless thing. For example it will ding your PR for not considering Opera browser limitations on a backend NodeJS PR.<p>Furthermore most of the code reviews I perform, rarely do I ever really leave commentary. There are so many frameworks and libraries today that solve whatever problem, unless someone adds complex code or puts a file in a goofy spot, it’s an instant approval. So an AI bot doesn’t help something which is a minimal non-problem task.</div><br/><div id="42484690" class="c"><input type="checkbox" id="c-42484690" checked=""/><div class="controls bullet"><span class="by">mcbishop</span><span>|</span><a href="#42484584">parent</a><span>|</span><a href="#42484747">next</a><span>|</span><label class="collapse" for="c-42484690">[-]</label><label class="expand" for="c-42484690">[1 more]</label></div><br/><div class="children"><div class="content">Some have a smaller tighter codebase... where it&#x27;s realistic to pursue consistent application of an internal style guide (which current AI seems well suited to help with (or take ownership of)).</div><br/></div></div><div id="42484747" class="c"><input type="checkbox" id="c-42484747" checked=""/><div class="controls bullet"><span class="by">Spivak</span><span>|</span><a href="#42484584">parent</a><span>|</span><a href="#42484690">prev</a><span>|</span><a href="#42484588">next</a><span>|</span><label class="collapse" for="c-42484747">[-]</label><label class="expand" for="c-42484747">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve honestly considered just making a script that hits the checkbox automatically because we have to have &quot;code review&quot; for compliance but 99% of the time I simply don&#x27;t care. Is the change you made gonna bring down prod, no, okay ship it.<p>At some level if I didn&#x27;t trust you to not write shitty code you wouldn&#x27;t be on our team. I don&#x27;t think I want to go all the way and say code review is a smell but not really needing it is what code ownership, good integration tests, and good qa buys you.</div><br/></div></div></div></div><div id="42484588" class="c"><input type="checkbox" id="c-42484588" checked=""/><div class="controls bullet"><span class="by">anonzzzies</span><span>|</span><a href="#42484584">prev</a><span>|</span><a href="#42483437">next</a><span>|</span><label class="collapse" for="c-42484588">[-]</label><label class="expand" for="c-42484588">[1 more]</label></div><br/><div class="children"><div class="content">We found that in general it&#x27;s pretty hard to make the llm just stop without human intervention. You can see with things like Cline that if the llm has to check its own work, it&#x27;ll keep making &#x27;improvements&#x27; in a loop; removing all comments, adding all comments etc. It needs to generate something and seems overly helpful to give you something.</div><br/></div></div><div id="42483437" class="c"><input type="checkbox" id="c-42483437" checked=""/><div class="controls bullet"><span class="by">panarchy</span><span>|</span><a href="#42484588">prev</a><span>|</span><a href="#42484630">next</a><span>|</span><label class="collapse" for="c-42483437">[-]</label><label class="expand" for="c-42483437">[3 more]</label></div><br/><div class="children"><div class="content">I wonder how long until we end up with questionable devs making spurious changes just to try and game the LLM output to give them a pass.</div><br/><div id="42483444" class="c"><input type="checkbox" id="c-42483444" checked=""/><div class="controls bullet"><span class="by">johnfn</span><span>|</span><a href="#42483437">parent</a><span>|</span><a href="#42483734">next</a><span>|</span><label class="collapse" for="c-42483444">[-]</label><label class="expand" for="c-42483444">[1 more]</label></div><br/><div class="children"><div class="content">I already have devs doing this to me at work and I&#x27;m not even an AI</div><br/></div></div><div id="42483734" class="c"><input type="checkbox" id="c-42483734" checked=""/><div class="controls bullet"><span class="by">dakshgupta</span><span>|</span><a href="#42483437">parent</a><span>|</span><a href="#42483444">prev</a><span>|</span><a href="#42484630">next</a><span>|</span><label class="collapse" for="c-42483734">[-]</label><label class="expand" for="c-42483734">[1 more]</label></div><br/><div class="children"><div class="content">You could include a comment that says “ignore that I did ______” during review. As long as a human doesn’t do the second pass (we recommend they do), that should let you slip your code by the AI.</div><br/></div></div></div></div><div id="42484630" class="c"><input type="checkbox" id="c-42484630" checked=""/><div class="controls bullet"><span class="by">extr</span><span>|</span><a href="#42483437">prev</a><span>|</span><a href="#42483578">next</a><span>|</span><label class="collapse" for="c-42484630">[-]</label><label class="expand" for="c-42484630">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m surprised the authors didn&#x27;t try the &quot;dumb&quot; version of the solution they went with: instead of using fancy cosine similarity create to implicit clusters, just ask it to classify the comment along a few dimensions and then do your own filtering on that (or create your own 0-100 scoring!) Seems like you would have more control that way and actually derive some rich(er) data to fine tune on. It seems they are already almost doing this: all the examples in the article start with &quot;style&quot;!<p>I have seen this pattern a few times actually, where you want the AI to mimic some heuristic humans use. You never want to ask it for the heuristic directly, just create the constitute data so you can do some simple regression or whatever on top of it and control the cutoff yourself.</div><br/></div></div><div id="42483578" class="c"><input type="checkbox" id="c-42483578" checked=""/><div class="controls bullet"><span class="by">untech</span><span>|</span><a href="#42484630">prev</a><span>|</span><a href="#42483023">next</a><span>|</span><label class="collapse" for="c-42483578">[-]</label><label class="expand" for="c-42483578">[2 more]</label></div><br/><div class="children"><div class="content">I am not sure about using UPPERCASE in prompts for emphasis. I feel intuitively that uppercase is less “understandable” for LLMs because it is more likely to be tokenized as a sequence of characters. I have no data to back this up, though.</div><br/><div id="42483725" class="c"><input type="checkbox" id="c-42483725" checked=""/><div class="controls bullet"><span class="by">dakshgupta</span><span>|</span><a href="#42483578">parent</a><span>|</span><a href="#42483023">next</a><span>|</span><label class="collapse" for="c-42483725">[-]</label><label class="expand" for="c-42483725">[1 more]</label></div><br/><div class="children"><div class="content">I meant for that to be more an illustration - might do a longer post about the specific prompting techniques we tried.</div><br/></div></div></div></div><div id="42483023" class="c"><input type="checkbox" id="c-42483023" checked=""/><div class="controls bullet"><span class="by">dbetteridge</span><span>|</span><a href="#42483578">prev</a><span>|</span><a href="#42483651">next</a><span>|</span><label class="collapse" for="c-42483023">[-]</label><label class="expand" for="c-42483023">[8 more]</label></div><br/><div class="children"><div class="content">Prompt:<p>If the comment could be omitted without affecting the codes functionality but is stylistic or otherwise can be ignored then preface the comment with<p>NITPICK<p>I&#x27;m guessing you&#x27;ve tried something like the above and then filtering for the preface, as you mentioned the llm being bad at understanding what is and isn&#x27;t important.</div><br/><div id="42485158" class="c"><input type="checkbox" id="c-42485158" checked=""/><div class="controls bullet"><span class="by">fnqi8ckfek</span><span>|</span><a href="#42483023">parent</a><span>|</span><a href="#42483122">next</a><span>|</span><label class="collapse" for="c-42485158">[-]</label><label class="expand" for="c-42485158">[1 more]</label></div><br/><div class="children"><div class="content">My boss can&#x27;t stop nitpicking, and I&#x27;ve started telling him that &quot;if your comment doesn&#x27;t affect the output I&#x27;m ignoring it&quot;.</div><br/></div></div><div id="42483122" class="c"><input type="checkbox" id="c-42483122" checked=""/><div class="controls bullet"><span class="by">abecedarius</span><span>|</span><a href="#42483023">parent</a><span>|</span><a href="#42485158">prev</a><span>|</span><a href="#42483721">next</a><span>|</span><label class="collapse" for="c-42483122">[-]</label><label class="expand" for="c-42483122">[4 more]</label></div><br/><div class="children"><div class="content">Nitpick: I&#x27;d ask for NITPICK at the end of output instead of the start. The model should be in a better place to make that decision there.</div><br/><div id="42483147" class="c"><input type="checkbox" id="c-42483147" checked=""/><div class="controls bullet"><span class="by">ivanjermakov</span><span>|</span><a href="#42483023">root</a><span>|</span><a href="#42483122">parent</a><span>|</span><a href="#42483721">next</a><span>|</span><label class="collapse" for="c-42483147">[-]</label><label class="expand" for="c-42483147">[3 more]</label></div><br/><div class="children"><div class="content">I find it ironic how capable LLMs have become, but they&#x27;re still struggling with things like this. Great reminder that it&#x27;s still text prediction at its core.</div><br/><div id="42483803" class="c"><input type="checkbox" id="c-42483803" checked=""/><div class="controls bullet"><span class="by">Eisenstein</span><span>|</span><a href="#42483023">root</a><span>|</span><a href="#42483147">parent</a><span>|</span><a href="#42483258">next</a><span>|</span><label class="collapse" for="c-42483803">[-]</label><label class="expand" for="c-42483803">[1 more]</label></div><br/><div class="children"><div class="content">I find it more helpful to keep in mind the autoregressive nature rather than the prediction. &#x27;Text prediction&#x27; brings to mind that it is guessing what word would follow another word, but it is doing so much more than that. &#x27;Autoregressive&#x27; brings to mind that it is using its previously generated output to create new output every time it comes up with another token. In that case you immediately understand that it would have to make the determination of severity after it has generated the description of the issue.</div><br/></div></div><div id="42483258" class="c"><input type="checkbox" id="c-42483258" checked=""/><div class="controls bullet"><span class="by">spott</span><span>|</span><a href="#42483023">root</a><span>|</span><a href="#42483147">parent</a><span>|</span><a href="#42483803">prev</a><span>|</span><a href="#42483721">next</a><span>|</span><label class="collapse" for="c-42483258">[-]</label><label class="expand" for="c-42483258">[1 more]</label></div><br/><div class="children"><div class="content">I mean, think of LLM output as unfiltered thinking.  If you were to make that determination would you make it before you had thought it through?</div><br/></div></div></div></div></div></div><div id="42483721" class="c"><input type="checkbox" id="c-42483721" checked=""/><div class="controls bullet"><span class="by">dakshgupta</span><span>|</span><a href="#42483023">parent</a><span>|</span><a href="#42483122">prev</a><span>|</span><a href="#42483651">next</a><span>|</span><label class="collapse" for="c-42483721">[-]</label><label class="expand" for="c-42483721">[2 more]</label></div><br/><div class="children"><div class="content">We tried this too, better but not good enough. It also often labeled critical issues as nitpicks, which is unacceptable in our context.</div><br/><div id="42483986" class="c"><input type="checkbox" id="c-42483986" checked=""/><div class="controls bullet"><span class="by">firesteelrain</span><span>|</span><a href="#42483023">root</a><span>|</span><a href="#42483721">parent</a><span>|</span><a href="#42483651">next</a><span>|</span><label class="collapse" for="c-42483986">[-]</label><label class="expand" for="c-42483986">[1 more]</label></div><br/><div class="children"><div class="content">Then some of the nitpicks were actually valid?<p>What about PossiblyWrong, then?</div><br/></div></div></div></div></div></div><div id="42483651" class="c"><input type="checkbox" id="c-42483651" checked=""/><div class="controls bullet"><span class="by">jumploops</span><span>|</span><a href="#42483023">prev</a><span>|</span><a href="#42483085">next</a><span>|</span><label class="collapse" for="c-42483651">[-]</label><label class="expand" for="c-42483651">[3 more]</label></div><br/><div class="children"><div class="content">We do something internally[0] but specifically for security concerns.<p>We’ve found that having the LLM provide a “severity” level (simply low, medium, high), we’re able to filter out all the nitpicky feedback.<p>It’s important to note that this severity level should be specified at the end of the LLM’s response, not the beginning or middle.<p>There’s still an issue of context, where the LLM will provide a false positive due to unseen aspects of the larger system (e.g. make sure to sanitize X input).<p>We haven’t found the bot to be overbearing, but mostly because we auto-delete past comments when changes are pushed.<p>[0] <a href="https:&#x2F;&#x2F;magicloops.dev&#x2F;loop&#x2F;3f3781f3-f987-4672-8500-bacbeefca6db&#x2F;view">https:&#x2F;&#x2F;magicloops.dev&#x2F;loop&#x2F;3f3781f3-f987-4672-8500-bacbeefc...</a></div><br/><div id="42483699" class="c"><input type="checkbox" id="c-42483699" checked=""/><div class="controls bullet"><span class="by">dakshgupta</span><span>|</span><a href="#42483651">parent</a><span>|</span><a href="#42483085">next</a><span>|</span><label class="collapse" for="c-42483699">[-]</label><label class="expand" for="c-42483699">[2 more]</label></div><br/><div class="children"><div class="content">The severity needing to be at the end was an important insight. It made the results much better but not quite good enough.<p>We had it output a json with fields {comment: string, severity: string} in that order.</div><br/><div id="42483894" class="c"><input type="checkbox" id="c-42483894" checked=""/><div class="controls bullet"><span class="by">Merik</span><span>|</span><a href="#42483651">root</a><span>|</span><a href="#42483699">parent</a><span>|</span><a href="#42483085">next</a><span>|</span><label class="collapse" for="c-42483894">[-]</label><label class="expand" for="c-42483894">[1 more]</label></div><br/><div class="children"><div class="content">Another variation on this is to think about tokens and definitions. Numbers don’t have inherent meaning for your use case, so if you use numbers you need to provide an explicit definition of each rating number in the prompt. Similarly, and more effectively is to use labels such as low-quality, medium-quality, high-quality, and again providing an explicit definition of the label; one step further is to use explicit self describing label (along with detailed definition) such as “trivial-observation-on-naming-convention” or “insightful-identification-on-missed-corner-case”.<p>Effectively you are turning a somewhat arbitrary numeric “rating” task , into a multi label classification problem with well defined labels.<p>The natural evolution is to then train a BERT based classifier or similar on the set of labels and comments, which will get you a model judge that is super fast and can achieve good accuracy.</div><br/></div></div></div></div></div></div><div id="42483085" class="c"><input type="checkbox" id="c-42483085" checked=""/><div class="controls bullet"><span class="by">throw310822</span><span>|</span><a href="#42483651">prev</a><span>|</span><a href="#42484154">next</a><span>|</span><label class="collapse" for="c-42483085">[-]</label><label class="expand" for="c-42483085">[2 more]</label></div><br/><div class="children"><div class="content">Seems easier than getting the same from my colleagues.</div><br/><div id="42483505" class="c"><input type="checkbox" id="c-42483505" checked=""/><div class="controls bullet"><span class="by">mr_toad</span><span>|</span><a href="#42483085">parent</a><span>|</span><a href="#42484154">next</a><span>|</span><label class="collapse" for="c-42483505">[-]</label><label class="expand" for="c-42483505">[1 more]</label></div><br/><div class="children"><div class="content">I wonder if it was trained on a lot of nitpicking comments from human reviews.</div><br/></div></div></div></div><div id="42484154" class="c"><input type="checkbox" id="c-42484154" checked=""/><div class="controls bullet"><span class="by">just-another-se</span><span>|</span><a href="#42483085">prev</a><span>|</span><a href="#42483613">next</a><span>|</span><label class="collapse" for="c-42484154">[-]</label><label class="expand" for="c-42484154">[3 more]</label></div><br/><div class="children"><div class="content">And how do you guys deal with a cold start problem then? Suppose the repo is new and has very few previous comments?</div><br/><div id="42484388" class="c"><input type="checkbox" id="c-42484388" checked=""/><div class="controls bullet"><span class="by">croemer</span><span>|</span><a href="#42484154">parent</a><span>|</span><a href="#42484568">next</a><span>|</span><label class="collapse" for="c-42484388">[-]</label><label class="expand" for="c-42484388">[1 more]</label></div><br/><div class="children"><div class="content">Do pooling with the average embedding of all customers</div><br/></div></div><div id="42484568" class="c"><input type="checkbox" id="c-42484568" checked=""/><div class="controls bullet"><span class="by">dakshgupta</span><span>|</span><a href="#42484154">parent</a><span>|</span><a href="#42484388">prev</a><span>|</span><a href="#42483613">next</a><span>|</span><label class="collapse" for="c-42484568">[-]</label><label class="expand" for="c-42484568">[1 more]</label></div><br/><div class="children"><div class="content">We do use some other techniques to filter out comments that are almost always considered useless by teams.<p>For the typical team size that uses us (at least 20+ engineers) the number of downvotes gets high enough to show results within a workday or two, and achieves something of a stable state within a week.</div><br/></div></div></div></div><div id="42483613" class="c"><input type="checkbox" id="c-42483613" checked=""/><div class="controls bullet"><span class="by">pedrovhb</span><span>|</span><a href="#42484154">prev</a><span>|</span><a href="#42483927">next</a><span>|</span><label class="collapse" for="c-42483613">[-]</label><label class="expand" for="c-42483613">[3 more]</label></div><br/><div class="children"><div class="content">Here&#x27;s an idea: have the LLM output each comment with a &quot;severity&quot; score ranging from 0-100 or maybe a set of possible values (&quot;trivial&quot;, &quot;small&quot;, &quot;high&quot;). Let it get everything off of its chest outputting the nitpicks but recognizing they&#x27;re minor. Filter the output to only contain comments above a given threshold.<p>It&#x27;s hard to avoid thinking of a pink elephant, but easy enough to consciously recognize it&#x27;s not relevant to the task at hand.</div><br/><div id="42483777" class="c"><input type="checkbox" id="c-42483777" checked=""/><div class="controls bullet"><span class="by">zahlman</span><span>|</span><a href="#42483613">parent</a><span>|</span><a href="#42483645">next</a><span>|</span><label class="collapse" for="c-42483777">[-]</label><label class="expand" for="c-42483777">[1 more]</label></div><br/><div class="children"><div class="content">The article authors tried this technique and found it didn&#x27;t work very well.</div><br/></div></div><div id="42483645" class="c"><input type="checkbox" id="c-42483645" checked=""/><div class="controls bullet"><span class="by">iLoveOncall</span><span>|</span><a href="#42483613">parent</a><span>|</span><a href="#42483777">prev</a><span>|</span><a href="#42483927">next</a><span>|</span><label class="collapse" for="c-42483645">[-]</label><label class="expand" for="c-42483645">[1 more]</label></div><br/><div class="children"><div class="content">Here&#x27;s an idea: read the article and realize they already tried exactly that.</div><br/></div></div></div></div><div id="42483927" class="c"><input type="checkbox" id="c-42483927" checked=""/><div class="controls bullet"><span class="by">callamdelaney</span><span>|</span><a href="#42483613">prev</a><span>|</span><a href="#42483157">next</a><span>|</span><label class="collapse" for="c-42483927">[-]</label><label class="expand" for="c-42483927">[3 more]</label></div><br/><div class="children"><div class="content">Does it work on real engineers?</div><br/><div id="42483979" class="c"><input type="checkbox" id="c-42483979" checked=""/><div class="controls bullet"><span class="by">aeve890</span><span>|</span><a href="#42483927">parent</a><span>|</span><a href="#42483955">next</a><span>|</span><label class="collapse" for="c-42483979">[-]</label><label class="expand" for="c-42483979">[1 more]</label></div><br/><div class="children"><div class="content">What do real engineers have to do with software? &#x2F;jk</div><br/></div></div><div id="42483955" class="c"><input type="checkbox" id="c-42483955" checked=""/><div class="controls bullet"><span class="by">defrost</span><span>|</span><a href="#42483927">parent</a><span>|</span><a href="#42483979">prev</a><span>|</span><a href="#42483157">next</a><span>|</span><label class="collapse" for="c-42483955">[-]</label><label class="expand" for="c-42483955">[1 more]</label></div><br/><div class="children"><div class="content">A quarter of real engineers are already Civil.</div><br/></div></div></div></div><div id="42483157" class="c"><input type="checkbox" id="c-42483157" checked=""/><div class="controls bullet"><span class="by">kgeist</span><span>|</span><a href="#42483927">prev</a><span>|</span><a href="#42483952">next</a><span>|</span><label class="collapse" for="c-42483157">[-]</label><label class="expand" for="c-42483157">[2 more]</label></div><br/><div class="children"><div class="content">What about false positives?<p>As I see it, the solution assumes the embeddings only capture the form: say, if developers previously downvoted suggestions to wrap code in unnecessary try..catch blocks, then similar suggestions will be successfully blocked in the future, regardless of the module&#x2F;class etc. (i.e. a kind of generalization)<p>But what if enough suggestions regarding class X (or module X) get downvoted, and then the mechanism starts assuming class X&#x2F;module X doesn&#x27;t need review at all? I mean the case when a lot of such embeddings end up clustering around the class itself (or a function), not around the general form of the comment.<p>How do you prevent this? Or it&#x27;s unlikely to happen? The only metric I&#x27;ve found in the article is the percentage of addressed suggestions that made it to the end user.</div><br/><div id="42483746" class="c"><input type="checkbox" id="c-42483746" checked=""/><div class="controls bullet"><span class="by">dakshgupta</span><span>|</span><a href="#42483157">parent</a><span>|</span><a href="#42483952">next</a><span>|</span><label class="collapse" for="c-42483746">[-]</label><label class="expand" for="c-42483746">[1 more]</label></div><br/><div class="children"><div class="content">This is the biggest pitfall of this method. It’s partially combatted by also comparing it against an upvoted set, so if a type of comment has been upvoted and downvoted in the past, it is not blocked.</div><br/></div></div></div></div><div id="42483952" class="c"><input type="checkbox" id="c-42483952" checked=""/><div class="controls bullet"><span class="by">Havoc</span><span>|</span><a href="#42483157">prev</a><span>|</span><a href="#42484034">next</a><span>|</span><label class="collapse" for="c-42483952">[-]</label><label class="expand" for="c-42483952">[1 more]</label></div><br/><div class="children"><div class="content">Think it would initially have gone better had they not used „nits“ but rather nitpicks. ie something that’s in the dictionary that the chatbot is likely to understand</div><br/></div></div><div id="42484034" class="c"><input type="checkbox" id="c-42484034" checked=""/><div class="controls bullet"><span class="by">tayo42</span><span>|</span><a href="#42483952">prev</a><span>|</span><a href="#42483172">next</a><span>|</span><label class="collapse" for="c-42484034">[-]</label><label class="expand" for="c-42484034">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Attempt 2: LLM-as-a-judge<p>Wouldnt this be achievable with a classifier model? Maybe even a combo of getting the embedding and then putting it through a classifier? Kind of like how Gans work.<p>Edit: I read the article before the comment section, silly me lol</div><br/></div></div><div id="42483172" class="c"><input type="checkbox" id="c-42483172" checked=""/><div class="controls bullet"><span class="by">Falimonda</span><span>|</span><a href="#42484034">prev</a><span>|</span><a href="#42483109">next</a><span>|</span><label class="collapse" for="c-42483172">[-]</label><label class="expand" for="c-42483172">[1 more]</label></div><br/><div class="children"><div class="content">fwiw, not all the mobile site&#x27;s menu items work when clicked</div><br/></div></div><div id="42482385" class="c"><input type="checkbox" id="c-42482385" checked=""/><div class="controls bullet"><span class="by">Nullabillity</span><span>|</span><a href="#42483109">prev</a><span>|</span><a href="#42483865">next</a><span>|</span><label class="collapse" for="c-42482385">[-]</label><label class="expand" for="c-42482385">[6 more]</label></div><br/><div class="children"><div class="content">[flagged]</div><br/><div id="42482644" class="c"><input type="checkbox" id="c-42482644" checked=""/><div class="controls bullet"><span class="by">dang</span><span>|</span><a href="#42482385">parent</a><span>|</span><a href="#42482444">next</a><span>|</span><label class="collapse" for="c-42482644">[-]</label><label class="expand" for="c-42482644">[3 more]</label></div><br/><div class="children"><div class="content">&quot;<i>Please don&#x27;t post shallow dismissals, especially of other people&#x27;s work. A good critical comment teaches us something.</i>&quot;<p><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;newsguidelines.html">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;newsguidelines.html</a></div><br/><div id="42483693" class="c"><input type="checkbox" id="c-42483693" checked=""/><div class="controls bullet"><span class="by">kneegerman</span><span>|</span><a href="#42482385">root</a><span>|</span><a href="#42482644">parent</a><span>|</span><a href="#42482444">next</a><span>|</span><label class="collapse" for="c-42483693">[-]</label><label class="expand" for="c-42483693">[2 more]</label></div><br/><div class="children"><div class="content">he&#x27;s not wrong</div><br/><div id="42484166" class="c"><input type="checkbox" id="c-42484166" checked=""/><div class="controls bullet"><span class="by">dang</span><span>|</span><a href="#42482385">root</a><span>|</span><a href="#42483693">parent</a><span>|</span><a href="#42482444">next</a><span>|</span><label class="collapse" for="c-42484166">[-]</label><label class="expand" for="c-42484166">[1 more]</label></div><br/><div class="children"><div class="content">We&#x27;re trying for intellectual curiosity here.<p><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;newsguidelines.html">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;newsguidelines.html</a></div><br/></div></div></div></div></div></div><div id="42482444" class="c"><input type="checkbox" id="c-42482444" checked=""/><div class="controls bullet"><span class="by">dakshgupta</span><span>|</span><a href="#42482385">parent</a><span>|</span><a href="#42482644">prev</a><span>|</span><a href="#42483865">next</a><span>|</span><label class="collapse" for="c-42482444">[-]</label><label class="expand" for="c-42482444">[2 more]</label></div><br/><div class="children"><div class="content">I would say they are useful but they aren’t magic (at least yet) and building useful applications on top of them requires some work.</div><br/><div id="42482803" class="c"><input type="checkbox" id="c-42482803" checked=""/><div class="controls bullet"><span class="by">WesolyKubeczek</span><span>|</span><a href="#42482385">root</a><span>|</span><a href="#42482444">parent</a><span>|</span><a href="#42483865">next</a><span>|</span><label class="collapse" for="c-42482803">[-]</label><label class="expand" for="c-42482803">[1 more]</label></div><br/><div class="children"><div class="content">Not only do LLMs require some work to build anything useful, they are also fuzzy and nondeterministic, requiring you to tweak your prompting tricks once in a while, and they are also quite expensive.<p>Nothing but advantages.</div><br/></div></div></div></div></div></div><div id="42483865" class="c"><input type="checkbox" id="c-42483865" checked=""/><div class="controls bullet"><span class="by">nikolayasdf123</span><span>|</span><a href="#42482385">prev</a><span>|</span><a href="#42484346">next</a><span>|</span><label class="collapse" for="c-42483865">[-]</label><label class="expand" for="c-42483865">[2 more]</label></div><br/><div class="children"><div class="content">&gt; $0.45&#x2F;file capped at $50&#x2F;dev&#x2F;month<p>wow. this is really expensive... especially given core of this technology is open source and target customers can set it up themselves self-hosted</div><br/><div id="42484858" class="c"><input type="checkbox" id="c-42484858" checked=""/><div class="controls bullet"><span class="by">MacsHeadroom</span><span>|</span><a href="#42483865">parent</a><span>|</span><a href="#42484346">next</a><span>|</span><label class="collapse" for="c-42484858">[-]</label><label class="expand" for="c-42484858">[1 more]</label></div><br/><div class="children"><div class="content">A cap of less than 1% of an average developer&#x27;s pay is &quot;really expensive&quot;?</div><br/></div></div></div></div><div id="42484346" class="c"><input type="checkbox" id="c-42484346" checked=""/><div class="controls bullet"><span class="by">dcreater</span><span>|</span><a href="#42483865">prev</a><span>|</span><label class="collapse" for="c-42484346">[-]</label><label class="expand" for="c-42484346">[1 more]</label></div><br/><div class="children"><div class="content">Are you still looking for slaves, err I mean employees, who are going to work 80+hrs a week? Do you sponsor visas?</div><br/></div></div></div></div></div></div></div></body></html>