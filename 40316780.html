<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1715504454133" as="style"/><link rel="stylesheet" href="styles.css?v=1715504454133"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://davekilian.com/acquire-release.html">Making Sense of Acquire-Release Semantics</a> <span class="domain">(<a href="https://davekilian.com">davekilian.com</a>)</span></div><div class="subtext"><span>sph</span> | <span>50 comments</span></div><br/><div><div id="40329509" class="c"><input type="checkbox" id="c-40329509" checked=""/><div class="controls bullet"><span class="by">zevv</span><span>|</span><a href="#40332492">next</a><span>|</span><label class="collapse" for="c-40329509">[-]</label><label class="expand" for="c-40329509">[6 more]</label></div><br/><div class="children"><div class="content">Well written article, nice and to the point. Do recommend.<p>Decades ago I declared myself too stupid to use shared memory with threading; I have learned to avoid this whenever possible, or abstract away the memory access under a safe layer as soon as possible. One of the greatest decisions of my career.<p>Memory model semantics is one of the parts of systems programming that is generally poorly understood; I have had long discussions with senior programmers who have spent their careers carelessly threading their code without realizing what is happening under the hood. Not only did some of them not properly understand the acquire&#x2F;release model, but they were not even aware of its existence.<p>For a more in-depth explanation, I recommend Sutter&#x27;s excellent talk &quot;Atomic &lt;&gt; weapons&quot;: <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=A8eCGOqgvH4" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=A8eCGOqgvH4</a>. It is a two hour lecture, but it will be worth your time.</div><br/><div id="40332878" class="c"><input type="checkbox" id="c-40332878" checked=""/><div class="controls bullet"><span class="by">ein0p</span><span>|</span><a href="#40329509">parent</a><span>|</span><a href="#40331452">next</a><span>|</span><label class="collapse" for="c-40332878">[-]</label><label class="expand" for="c-40332878">[1 more]</label></div><br/><div class="children"><div class="content">Not being aware of the existence of acquire&#x2F;release is strictly better than knowing about it but not understanding the details. One can have an excellent career and never use anything other than condvars and mutexes. But one can also really shit the bed if they misunderstand the semantics of atomics. I use atomics with explicit memory ordering only as a measure of last resort.</div><br/></div></div><div id="40331452" class="c"><input type="checkbox" id="c-40331452" checked=""/><div class="controls bullet"><span class="by">mcdeltat</span><span>|</span><a href="#40329509">parent</a><span>|</span><a href="#40332878">prev</a><span>|</span><a href="#40332000">next</a><span>|</span><label class="collapse" for="c-40331452">[-]</label><label class="expand" for="c-40331452">[1 more]</label></div><br/><div class="children"><div class="content">That atomics talk by Sutter is a superbly high quality explanation, albeit long. He addresses the topic with exceptional rigor and plenty of examples that show what can and can&#x27;t happen. It for sure took me from 0 to 100 knowledge on thread safety.</div><br/></div></div><div id="40332000" class="c"><input type="checkbox" id="c-40332000" checked=""/><div class="controls bullet"><span class="by">eru</span><span>|</span><a href="#40329509">parent</a><span>|</span><a href="#40331452">prev</a><span>|</span><a href="#40331079">next</a><span>|</span><label class="collapse" for="c-40332000">[-]</label><label class="expand" for="c-40332000">[1 more]</label></div><br/><div class="children"><div class="content">I agree.<p>Btw, shared memory by itself is fine, even shared memory with threading.  The really dangerous ingredient is mutability.  And mutability is already toxic waste on its own, and concurrency amplifies the danger.</div><br/></div></div><div id="40331079" class="c"><input type="checkbox" id="c-40331079" checked=""/><div class="controls bullet"><span class="by">toast0</span><span>|</span><a href="#40329509">parent</a><span>|</span><a href="#40332000">prev</a><span>|</span><a href="#40332001">next</a><span>|</span><label class="collapse" for="c-40331079">[-]</label><label class="expand" for="c-40331079">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Decades ago I declared myself too stupid to use shared memory with threading; I have learned to avoid this whenever possible, or abstract away the memory access under a safe layer as soon as possible. One of the greatest decisions of my career.<p>This probably qualifies you to do shared memory threading, when it is needed. Such as debugging those abstraction layers. Knowing you don&#x27;t understand it puts you in the right frame of mind to carefully do the work.</div><br/></div></div><div id="40332001" class="c"><input type="checkbox" id="c-40332001" checked=""/><div class="controls bullet"><span class="by">spacechild1</span><span>|</span><a href="#40329509">parent</a><span>|</span><a href="#40331079">prev</a><span>|</span><a href="#40332492">next</a><span>|</span><label class="collapse" for="c-40332001">[-]</label><label class="expand" for="c-40332001">[1 more]</label></div><br/><div class="children"><div class="content">I can highly recommend Herb&#x27;s talk as well!</div><br/></div></div></div></div><div id="40332492" class="c"><input type="checkbox" id="c-40332492" checked=""/><div class="controls bullet"><span class="by">liblfds-temp</span><span>|</span><a href="#40329509">prev</a><span>|</span><a href="#40331364">next</a><span>|</span><label class="collapse" for="c-40332492">[-]</label><label class="expand" for="c-40332492">[3 more]</label></div><br/><div class="children"><div class="content">&gt; See how we added a new fence() call to put()? That fixes the reordering problem we’ve described at length. Now if the CPU gets bored waiting for entries[i] to be read into the cache, and tries to pull up the tail++ line so it happens sooner, bonk!, the tail++ line hits that fence and stops moving. We’ve forced the entry to be written before the tail is bumped. Problem solved!<p>I may be completely wrong, it&#x27;s a complicated subject, but I think the wording here is potentially misleading.<p>As I understand it (and I may be wrong!), a full fence does the following : &quot;all reads and all writes prior to the fence must occur before any reads or writes after the fence&quot;.<p>What I&#x27;m concerned about is people thinking this is a <i>blocking</i> behaviour, i.e. when we hit the fence, then at that point all prior reads and writes occur.<p>This is <i>not</i> the case.<p>The reads and writes prior to the fence can occur <i>at any time</i> - they could occur <i>LONG AFTER</i> we pass the fence - but what we do get from the fence is that the reads and writes prior to the fence WILL occur BEFORE any reads or writes after the fence.<p>So, to put it another way, the code is executing, we come to the fence - and absolutely nothing happens.  The processor just keeps going.  No reads occur, no writes occur.<p>Then at some point later on, both in time and in code, the process comes to another (say) read.  NOW, finally, the processor MUST complete all reads and writes which were issued prior to the fence.</div><br/><div id="40333003" class="c"><input type="checkbox" id="c-40333003" checked=""/><div class="controls bullet"><span class="by">liblfds-temp</span><span>|</span><a href="#40332492">parent</a><span>|</span><a href="#40333020">next</a><span>|</span><label class="collapse" for="c-40333003">[-]</label><label class="expand" for="c-40333003">[1 more]</label></div><br/><div class="children"><div class="content">A thread which performs a write, has a fence, and then performs another write, will at the time of the second write due to the fence guarantee the first write has completed.<p>However, &quot;completed&quot; is misleading.<p>The write will still not be seen by readers.<p>&quot;Complete&quot; really means &quot;the writer has done all the work he can do, which is necessary but insufficient&quot;.<p>For a reader to see the write, the readers must issue a read memory barrier before reading the value.<p>All of this is due to store buffers and cache invalidation requests.<p>In short, in principle, a write is known about only by the processor it occurred upon; if there are any other processors in the system, then unless special magic is performed (fences and so on), any writes they see from other processors are seen purely by chance and can happen in any order (including going backwards in time), or not happen at all.<p>I once read an article which framed all this in terms of source control.<p>Memory is like SVN, or Git.<p>You make local changes (on your processor, which has its local copy of memory).  You then commit (write fence&#x2F;atomic operation).  No one else can see your changes until they update from source control and get the latest version (read fence).</div><br/></div></div><div id="40333020" class="c"><input type="checkbox" id="c-40333020" checked=""/><div class="controls bullet"><span class="by">moonchild</span><span>|</span><a href="#40332492">parent</a><span>|</span><a href="#40333003">prev</a><span>|</span><a href="#40331364">next</a><span>|</span><label class="collapse" for="c-40333020">[-]</label><label class="expand" for="c-40333020">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s more correct, but there are two points of order.<p>The first is that a cpu core is a massively distributed system, and there <i>is</i> no single point in time when an operation is executed.<p>The second is that cpus will absolutely physically do reads out of order even when those reads logically have to happen in order.  Suppose you read X, then fence, then read Y; the cpu may read Y immediately, immediately begin speculatively executing dataflows depending on Y, then later on read X.  But then if, between the time when it read Y and it read X, Y changed, then it will roll back any intermediate computation dependent on Y and try again.  But if Y didn&#x27;t change between the time when it was initially read and the time when X was read, then it&#x27;s semantically the same as if Y was read after X, so there is no problem.</div><br/></div></div></div></div><div id="40331364" class="c"><input type="checkbox" id="c-40331364" checked=""/><div class="controls bullet"><span class="by">mcdeltat</span><span>|</span><a href="#40332492">prev</a><span>|</span><a href="#40330517">next</a><span>|</span><label class="collapse" for="c-40331364">[-]</label><label class="expand" for="c-40331364">[7 more]</label></div><br/><div class="children"><div class="content">The article says a lot about CPUs reordering memory instructions - is this actually the main cause of the issues with the shown code?<p>Speaking of x86 specifically, instructions are aggressively reordered but as far as I understood it, the results are generally committed in order. The ISA has rules about what memory reorderings can occur, and looks like most reorderings are forbidden.
This stackoverflow explains it well: <a href="https:&#x2F;&#x2F;stackoverflow.com&#x2F;a&#x2F;50310563&#x2F;7064452" rel="nofollow">https:&#x2F;&#x2F;stackoverflow.com&#x2F;a&#x2F;50310563&#x2F;7064452</a><p>In this queue example I&#x27;d say the elephant in the room is the compiler, not the CPU. The code has no language-level synchronisation, therefore the compiler is free to do whatever - it&#x27;s not surprising memory ops get reordered. If you want to be pedantic, the code is UB with no synchronisation present. Perhaps besides the point to discuss CPU behaviour in this light.</div><br/><div id="40331568" class="c"><input type="checkbox" id="c-40331568" checked=""/><div class="controls bullet"><span class="by">mumblingdrunk</span><span>|</span><a href="#40331364">parent</a><span>|</span><a href="#40331955">next</a><span>|</span><label class="collapse" for="c-40331568">[-]</label><label class="expand" for="c-40331568">[3 more]</label></div><br/><div class="children"><div class="content">All CPUs commit in order and except precisely, because most other options are insane, or would drive you to it.  However: single thread commit order =&#x2F;= observability order.<p>Observability order of memory operations --- which are the only operations that matter --- are governed by the memory consistency model of the architecture.
x86 has what&#x27;s generally referred to as strong ordering on memory operations.<p>On x86, part of it means that stores from the same core cannot be observed out of order from each other, nor can loads.<p>So assuming the compiler does not move the `tail++` up, or move the assignment out of the if-statement (both of which are achieved by marking them `volatile`), the code should actually work on x86.
The `tail++` change cannot be observed before the write to the queue and the reading from the queue cannot be observed before the reading of the `tail` and `head` variables.<p>On RISC-V and Arm, you need more as they have substantially weaker memory consistency.  The RISC-V specs have some examples of <i>interesting</i> outcomes you can have.  Some of it involves time-travel.<p>But in the end: yes the reordering done by the CPU is the issue.  The compiler <i>can</i> and does reorder stuff when it thinks that it&#x27;ll unlock more instruction-level parallelism, but no amount of <i>volatile</i> is going to make that queue universally usable on RISC-V.  No matter what the compiler does.  Even perfectly preserving the single-thread semantics of the code, not reordering a single instruction, the CPU can move stuff around in terms of observability.
The alternative is that the compiler inserts a barrier&#x2F;fence after every instruction.<p>There are trade-offs.  Poorly written code for x86 can absolutely tank performance because of ordering violations requiring code to be replayed, though that is sometimes a problem in even weaker consistency models as well.</div><br/><div id="40331903" class="c"><input type="checkbox" id="c-40331903" checked=""/><div class="controls bullet"><span class="by">mcdeltat</span><span>|</span><a href="#40331364">root</a><span>|</span><a href="#40331568">parent</a><span>|</span><a href="#40331955">next</a><span>|</span><label class="collapse" for="c-40331903">[-]</label><label class="expand" for="c-40331903">[2 more]</label></div><br/><div class="children"><div class="content">Valid points, although I have another perspective on this bit:<p>&gt; But in the end: yes the reordering done by the CPU is the issue<p>I think from a programmer perspective, the CPU side of things is mostly beside the point (unless you&#x27;re writing assembly), and this contributes to the misunderstanding and air of mystery surrounding thread safety.<p>At the end of the day the CPU can do anything, really. I&#x27;d argue this doesn&#x27;t matter because the compiler is generating machine code, not us. What does matter is the contract between us and the compiler &#x2F; language spec.
Without language-level synchronisation the code is not valid C&#x2F;C++ and we will likely observe unexpected behaviour - either due to CPU reordering or compiler optimisations, doesn&#x27;t matter.<p>I think the article is somewhat missing the point by presenting the case somewhat pretending that the compiler is not part of the equation.
It seems like often people think they know how to do thread safety because they know, e.g. what reorderings the CPU may do. &quot;Just need to add volatile here and we&#x27;re good!&quot; (probably wrong). In reality they need to understand how the language models concurrency.<p>We could translate that queue code into another language with a different concurrency model - e.g. Python - and now the behaviour is different despite the CPU doing the same fundamental reorderings.</div><br/><div id="40332964" class="c"><input type="checkbox" id="c-40332964" checked=""/><div class="controls bullet"><span class="by">mattnewport</span><span>|</span><a href="#40331364">root</a><span>|</span><a href="#40331903">parent</a><span>|</span><a href="#40331955">next</a><span>|</span><label class="collapse" for="c-40332964">[-]</label><label class="expand" for="c-40332964">[1 more]</label></div><br/><div class="children"><div class="content">This is true but in practice it&#x27;s pretty common to find this sort of code seems to work fine on x64 because the compiler doesn&#x27;t actually reorder things and then sometimes blows up on ARM (or PowerPC, though that&#x27;s less commonly encountered in the wild these days).</div><br/></div></div></div></div></div></div><div id="40331955" class="c"><input type="checkbox" id="c-40331955" checked=""/><div class="controls bullet"><span class="by">eqvinox</span><span>|</span><a href="#40331364">parent</a><span>|</span><a href="#40331568">prev</a><span>|</span><a href="#40331429">next</a><span>|</span><label class="collapse" for="c-40331955">[-]</label><label class="expand" for="c-40331955">[1 more]</label></div><br/><div class="children"><div class="content">The searchable keyword to look for here (re x86) is &quot;Total Store Ordering&quot; (TSO).<p>(I&#x27;m not gonna try to summarize it here because I&#x27;d probably get it ever so subtly wrong…)<p>x86 has a very strong memory model, meaning it is a very poor test platform.  Last time I touched atomics I used PowerPC (e500mc &amp; e6500) to test, which was a good thing as it did point me at a problem.  Not sure where current ARM falls on this.  The uncontested, notorious king of weak memory ordering is DEC Alpha, but these are a bit hard to run these days.  If you want to go truly insane, look at DEC Alpha consumer dependency (non-)ordering :)</div><br/></div></div><div id="40331429" class="c"><input type="checkbox" id="c-40331429" checked=""/><div class="controls bullet"><span class="by">dbcurtis</span><span>|</span><a href="#40331364">parent</a><span>|</span><a href="#40331955">prev</a><span>|</span><a href="#40331411">next</a><span>|</span><label class="collapse" for="c-40331429">[-]</label><label class="expand" for="c-40331429">[1 more]</label></div><br/><div class="children"><div class="content">Yes, having worked on one of the out-of-order Intel CPU&#x27;s, I can tell you that you are correct.  Instructions may be &quot;complete&quot;, as in their results can be forwarded to later operations, but the instruction isn&#x27;t &quot;retired&quot; until it is known that it can not raise an exception, or be cancelled because of branch mis-predict, etc.  Programmer-visible architectural state as defined in the ISA is not written until instruction retirement.  CPU re-ordering instructions is not going to change semantics (in X86 and similar architectures... there are some archs that relax that guarantee).<p>Compilers are notorious for doing dumb things around locks.... the gnu C for AVR architecture, for instance, looks at the SEI instruction (SEt Interrupt mask bit) and notices that it doesn&#x27;t modify memory or registers, so hoists it to the top of functions.   Eh.. No, SEI; CLI; &lt;code&gt; &lt;critical section&gt; &lt;code&gt; is not what I intended...<p>Also... CPU&#x27;s with data caches can to smart things with architecturally-defined locking instructions such as &quot;test-and-set&#x27; or &#x27;compare-and-exchange&#x27; such that the instructions are always cache-coherent across CPU&#x27;s.  If you try to roll-your-own locking code, you had best understand how the cache invalidation mechanism works in your chosen CPU or you are going to have a bad day.</div><br/></div></div><div id="40331411" class="c"><input type="checkbox" id="c-40331411" checked=""/><div class="controls bullet"><span class="by">gpderetta</span><span>|</span><a href="#40331364">parent</a><span>|</span><a href="#40331429">prev</a><span>|</span><a href="#40330517">next</a><span>|</span><label class="collapse" for="c-40331411">[-]</label><label class="expand" for="c-40331411">[1 more]</label></div><br/><div class="children"><div class="content">The article does mention in the end that a trivial translation of the queue code to x86 will work.<p>It is broken on other architectures though (aside of the obvious UB because of races).</div><br/></div></div></div></div><div id="40330517" class="c"><input type="checkbox" id="c-40330517" checked=""/><div class="controls bullet"><span class="by">king_geedorah</span><span>|</span><a href="#40331364">prev</a><span>|</span><a href="#40330133">next</a><span>|</span><label class="collapse" for="c-40330517">[-]</label><label class="expand" for="c-40330517">[12 more]</label></div><br/><div class="children"><div class="content">No matter how many times I read about these, I&#x27;m always left just slightly confused. Acquire&#x2F;release is about the ordering of instructions within a thread of execution. So if I have a writer writing X, then writing Y, then I need write-release to make sure that the compiler actually puts the instructions for Y after the instructions for X in the machine code. If I want to guarantee that the results of those writes are visible to another thread, then I need a memory fence to force flushing of the caches out to main memory basically?<p>The author mentions the queue as originally written is technically correct for x86&#x2F;x86_64. This is true only in the sense that neither the producer or consumer can experience partial reads &#x2F; partial writes, right? It is still possible that if, say, the consumer were busy waiting for an item to be available then it will spin for as long as it takes for the CPU to decide to flush the producer&#x27;s writes out to main memory?<p>Whenever I see these concepts discussed, it is in the context of the C++ stdatomic library. If I were writing a program in C99, I would assume it would still be possible to communicate the same intent &#x2F; restrictions to the compiler, but I&#x27;m not sure because I haven&#x27;t been able to find any resources that discuss doing so. How might one communicate that to the compiler, assuming they are on x86&#x2F;x86_64 where in theory the CPU should just do the right thing with the right machine code?<p>Finally, does target architecture influence the compiler&#x27;s behavior in this regard at all? For example, if we take x86&#x2F;x86_64 as having acquire&#x2F;release semantics without any further work, does telling the compiler that my target architecture is x86&#x2F;x86_64 imply that those semantics should be used throughout the program?</div><br/><div id="40330832" class="c"><input type="checkbox" id="c-40330832" checked=""/><div class="controls bullet"><span class="by">neerajsi</span><span>|</span><a href="#40330517">parent</a><span>|</span><a href="#40331045">next</a><span>|</span><label class="collapse" for="c-40330832">[-]</label><label class="expand" for="c-40330832">[2 more]</label></div><br/><div class="children"><div class="content">I just wanted to clarify something about flushing caches: fences do not flush the caches in any way.  Inside the CPU there is a data structure called the load store queue.  It keeps track of pending loads and stores, of which there could be many.  This is done so that the processor can run ahead and request things from the caches or to be populated into the caches without having to stop dead the moment it has to wait for any one access.  The memory fencing influences how entries in the load store queue are allowed to provide values to the rest of the CPU execution units.  On weak orderes processors like ARM, the load store queue is allowed to forward values to the execution pipelines as soon as they are available from the caches, except if a store and load are to the same address.  X86 only allows values to go from loads to the pipeline in program order.  It can start operations early, but if it detects that a store comes in for a load that&#x27;s not the oldest it has to throw away the work done based on the speculated load.<p>Stores are a little special in that the CPU can declare a store as complete without actually writing data to the cache system.  So the stores go into a store buffer while the target cache line is still being acquired.  Loads have to check the store buffer.  On x86 the store buffer releases values to the cache in order, and on ARM the store buffer drains in any order.  However both CPU architectures allow loads to read values from the store buffer without them being in the cache and without the normal load queue ordering. They also allow loads to occur to different addresses before stora.  So on x86 a store followed by a load can execute as the load first then the store.<p>Fences logically force the store buffer to flush and the load queue to  resolve values from the cache. So everything before the fence is in the caching subsystem, where standard coherency ensures they&#x27;re visible when requested.  Then new operations start filling the load store queue, but they are known to be later than operations before the fence.</div><br/><div id="40331014" class="c"><input type="checkbox" id="c-40331014" checked=""/><div class="controls bullet"><span class="by">king_geedorah</span><span>|</span><a href="#40330517">root</a><span>|</span><a href="#40330832">parent</a><span>|</span><a href="#40331045">next</a><span>|</span><label class="collapse" for="c-40331014">[-]</label><label class="expand" for="c-40331014">[1 more]</label></div><br/><div class="children"><div class="content">That clarifies fences more for me a little bit more. Thanks for the insight.</div><br/></div></div></div></div><div id="40331045" class="c"><input type="checkbox" id="c-40331045" checked=""/><div class="controls bullet"><span class="by">JonChesterfield</span><span>|</span><a href="#40330517">parent</a><span>|</span><a href="#40330832">prev</a><span>|</span><a href="#40330789">next</a><span>|</span><label class="collapse" for="c-40331045">[-]</label><label class="expand" for="c-40331045">[4 more]</label></div><br/><div class="children"><div class="content">If you program without fences, instructions are reordered by the compiler and&#x2F;or the processor as they see fit provided the single threaded semantics are unchanged. This is why alias analysis is a big deal. A store can be moved before a load if they are independent, i.e. do not alias. A store followed by a load can be simplified to use the value already in a register if there is no other store in the meantime.<p>This doesn&#x27;t work if there are multiple threads and shared mutable state. Whatever semantics the programmer had in mind, and encoded in load&#x2F;store patterns, are usually insufficient for correctness under arbitrary interleaving of threads.<p>This is fixed by introducing additional constraints on which instructions can be reordered. Fences affect loads, stores, both. Usually with respect to all memory but potentially only a subset of it. The point is to say that moving some operation past some other one will cause unacceptable behaviour for this program, so neither compiler nor CPU shall do so.<p>On top of this there&#x27;s a C++ memory order model, where you can tag an integer add with acq_rel semantics, or specify fences, all reasoned in terms of synchronises with and a global oracle determining acceptable execution sequences. I think this is grossly over complicated and heavily obfuscates the programming model to no gain. Fortunately one can mechanically desugar it into the fences and reason with the result.</div><br/><div id="40331180" class="c"><input type="checkbox" id="c-40331180" checked=""/><div class="controls bullet"><span class="by">king_geedorah</span><span>|</span><a href="#40330517">root</a><span>|</span><a href="#40331045">parent</a><span>|</span><a href="#40330789">next</a><span>|</span><label class="collapse" for="c-40331180">[-]</label><label class="expand" for="c-40331180">[3 more]</label></div><br/><div class="children"><div class="content">Would it be correct to say that acquire-release is in some sense &quot;higher level&quot; than memory fences, with acq-rel implemented in terms of fences (and restrictions on code-gen?) and fences being all that the CPU actually knows about at least in the case of x86_64?</div><br/><div id="40331426" class="c"><input type="checkbox" id="c-40331426" checked=""/><div class="controls bullet"><span class="by">gpderetta</span><span>|</span><a href="#40330517">root</a><span>|</span><a href="#40331180">parent</a><span>|</span><a href="#40330789">next</a><span>|</span><label class="collapse" for="c-40331426">[-]</label><label class="expand" for="c-40331426">[2 more]</label></div><br/><div class="children"><div class="content">Acquire&#x2F;release is higher level because it is more of a theoretical description than an hardware description. But acq&#x2F;rel is not implemented using fences on x86. On this arch all loads and stores have implicit acquire and release semantics respectively, while all RMW are sequentially consistent acq+rel. The compiler will need to emit explicit fences very rarely on x86.</div><br/><div id="40331552" class="c"><input type="checkbox" id="c-40331552" checked=""/><div class="controls bullet"><span class="by">king_geedorah</span><span>|</span><a href="#40330517">root</a><span>|</span><a href="#40331426">parent</a><span>|</span><a href="#40330789">next</a><span>|</span><label class="collapse" for="c-40331552">[-]</label><label class="expand" for="c-40331552">[1 more]</label></div><br/><div class="children"><div class="content">Okay, that makes sense to me. Thank you.</div><br/></div></div></div></div></div></div></div></div><div id="40330789" class="c"><input type="checkbox" id="c-40330789" checked=""/><div class="controls bullet"><span class="by">moonchild</span><span>|</span><a href="#40330517">parent</a><span>|</span><a href="#40331045">prev</a><span>|</span><a href="#40330769">next</a><span>|</span><label class="collapse" for="c-40330789">[-]</label><label class="expand" for="c-40330789">[4 more]</label></div><br/><div class="children"><div class="content">&gt; If I were writing a program in C99, I would assume it would still be possible to communicate the same intent &#x2F; restrictions to the compiler, but I&#x27;m not sure because I haven&#x27;t been able to find any resources that discuss doing so<p>You cannot.  See boehm, &#x27;threads cannot be implemented as a library&#x27; (<a href="https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20240118063106if_&#x2F;https:&#x2F;&#x2F;www.hpl.hp.com&#x2F;techreports&#x2F;2004&#x2F;HPL-2004-209.pdf" rel="nofollow">https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20240118063106if_&#x2F;https:&#x2F;&#x2F;www.hp...</a>).  You can do that in c11, however, which includes functionally the same facilities as c++11 (howbeit c-flavoured, obviously).  <a href="https:&#x2F;&#x2F;en.cppreference.com&#x2F;w&#x2F;c&#x2F;atomic" rel="nofollow">https:&#x2F;&#x2F;en.cppreference.com&#x2F;w&#x2F;c&#x2F;atomic</a><p>&gt; does target architecture influence the compiler&#x27;s behavior in this regard at all? For example, if we take x86&#x2F;x86_64 as having acquire&#x2F;release semantics without any further work, does telling the compiler that my target architecture is x86&#x2F;x86_64 imply that those semantics should be used throughout the program?<p>It does not imply that.  You should completely ignore the target architecture.  C11 provides an abstract interface and a set of abstract constraints for concurrent programs; you should program against that interface, ensuring that your code is correct under those constraints.  The compiler is responsible for making sure that the constraints are satisfied on whatever target you happen to run (so your code will be portable!).<p>&gt; if I have a writer writing X, then writing Y, then I need write-release to make sure that the compiler actually puts the instructions for Y after the instructions for X in the machine code<p>You need Y to be a write-release if you would like it to be the case that, if another thread who acquire-reads and observes Y, then it will observe X.  (The classic example is &#x27;message passing&#x27;, where X is a message and Y is a flag saying that there is a message.  Obviously, it would be bad if you could see the flag but not actually the message.)  But maybe you don&#x27;t need that property.<p>&gt; If I want to guarantee that the results of those writes are visible to another thread, then I need a memory fence to force flushing of the caches out to main memory basically?<p>No.  That&#x27;s not what a fence does and that&#x27;s not how caches work.</div><br/><div id="40332105" class="c"><input type="checkbox" id="c-40332105" checked=""/><div class="controls bullet"><span class="by">cryptonector</span><span>|</span><a href="#40330517">root</a><span>|</span><a href="#40330789">parent</a><span>|</span><a href="#40331087">next</a><span>|</span><label class="collapse" for="c-40332105">[-]</label><label class="expand" for="c-40332105">[2 more]</label></div><br/><div class="children"><div class="content">And yet people did threaded programming in C before C11.  Granted, you cannot do it in plain C99 -- in practice extensions were used.  The hard part wasn&#x27;t getting the fence instructions (asm will do it) but getting the compiler to not re-order things around fences, and `asm volatile (&quot;&quot; ::: &quot;memory&quot;)` (or similar) would do that.</div><br/><div id="40332372" class="c"><input type="checkbox" id="c-40332372" checked=""/><div class="controls bullet"><span class="by">king_geedorah</span><span>|</span><a href="#40330517">root</a><span>|</span><a href="#40332105">parent</a><span>|</span><a href="#40331087">next</a><span>|</span><label class="collapse" for="c-40332372">[-]</label><label class="expand" for="c-40332372">[1 more]</label></div><br/><div class="children"><div class="content">This is essentially what I was getting at. Thank you.</div><br/></div></div></div></div><div id="40331087" class="c"><input type="checkbox" id="c-40331087" checked=""/><div class="controls bullet"><span class="by">king_geedorah</span><span>|</span><a href="#40330517">root</a><span>|</span><a href="#40330789">parent</a><span>|</span><a href="#40332105">prev</a><span>|</span><a href="#40330769">next</a><span>|</span><label class="collapse" for="c-40331087">[-]</label><label class="expand" for="c-40331087">[1 more]</label></div><br/><div class="children"><div class="content">Claro. Thank you for the threads as libraries link; very interesting.</div><br/></div></div></div></div><div id="40330769" class="c"><input type="checkbox" id="c-40330769" checked=""/><div class="controls bullet"><span class="by">gpderetta</span><span>|</span><a href="#40330517">parent</a><span>|</span><a href="#40330789">prev</a><span>|</span><a href="#40330133">next</a><span>|</span><label class="collapse" for="c-40330769">[-]</label><label class="expand" for="c-40330769">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Acquire&#x2F;release is about the ordering of instructions within a thread of execution<p>acquire&#x2F;release is about visibility. Acquire and release always go in pair. You can&#x27;t really reason purely about a release and an acquire in isolation and that&#x27;s why simply thinking about instruction reordering is not enough.<p>&gt; So if I have a writer writing X, then writing Y, then I need write-release to make sure that the compiler actually puts the instructions for Y after the instructions for X in the machine code. If I want to guarantee that the results of those writes are visible to another thread, then I need a memory fence to force flushing of the caches out to main memory basically<p>Whether an explicit memory fence is needed or not depends on the architecture (for example you do not need them on x86). But you do not need to care, if you use the atomic operation with the correct semantic, the compiler will insert any required fence for you.<p>As an aside, typically fences have nothing to do with caches. One a store or a load operation hits the cache, the coherence system takes care that everything works correctly. If fences had to flush the cache, they would be orders of magnitude slower.<p>Instead fences (explicit or otherwise) make sure that either memory operations commit (i.e. are visible at the cache layer) in the expected order or that an application can&#x27;t tell otherwise, i.e. reordering is still permitted across fences as long as conflicts can be detected and repaired, typically this can only happen for loads that can be retried without side effects.<p>&gt; Whenever I see these concepts discussed, it is in the context of the C++ stdatomic library. If I were writing a program in C99, I would assume it would still be possible to communicate the same intent &#x2F; restrictions to the compiler<p>formally in C99 multithreaded programs are UB. Of course other standards (POSIX, openmp) and implementations (the old GCC __sync_builtins) could give additional guarantees; but only C11 gave a model defined well enough to reason in depth about the overall CPU+compiler system; before that people just had to make a lot of assumptions.<p>&gt; Finally, does target architecture influence the compiler&#x27;s behavior in this regard at all? For example, if we take x86&#x2F;x86_64 as having acquire&#x2F;release semantics without any further work, does telling the compiler that my target architecture is x86&#x2F;x86_64 imply that those semantics should be used throughout the program?<p>It does, but note that the compiler will only respect acquire&#x2F;release semantics for atomic objects operations with the required ordering, not normal load and stores.</div><br/></div></div></div></div><div id="40330133" class="c"><input type="checkbox" id="c-40330133" checked=""/><div class="controls bullet"><span class="by">chrisaycock</span><span>|</span><a href="#40330517">prev</a><span>|</span><a href="#40329195">next</a><span>|</span><label class="collapse" for="c-40330133">[-]</label><label class="expand" for="c-40330133">[2 more]</label></div><br/><div class="children"><div class="content">The first explanation that really clarified memory barriers for me was from Paul E. McKenney:<p><a href="http:&#x2F;&#x2F;www.rdrop.com&#x2F;users&#x2F;paulmck&#x2F;scalability&#x2F;paper&#x2F;whymb.2010.07.23a.pdf" rel="nofollow">http:&#x2F;&#x2F;www.rdrop.com&#x2F;users&#x2F;paulmck&#x2F;scalability&#x2F;paper&#x2F;whymb.2...</a></div><br/><div id="40331056" class="c"><input type="checkbox" id="c-40331056" checked=""/><div class="controls bullet"><span class="by">JonChesterfield</span><span>|</span><a href="#40330133">parent</a><span>|</span><a href="#40329195">next</a><span>|</span><label class="collapse" for="c-40331056">[-]</label><label class="expand" for="c-40331056">[1 more]</label></div><br/><div class="children"><div class="content">That one plus the kernel notes at <a href="https:&#x2F;&#x2F;www.kernel.org&#x2F;doc&#x2F;Documentation&#x2F;memory-barriers.txt" rel="nofollow">https:&#x2F;&#x2F;www.kernel.org&#x2F;doc&#x2F;Documentation&#x2F;memory-barriers.txt</a> did the trick for me.</div><br/></div></div></div></div><div id="40329195" class="c"><input type="checkbox" id="c-40329195" checked=""/><div class="controls bullet"><span class="by">catlifeonmars</span><span>|</span><a href="#40330133">prev</a><span>|</span><a href="#40332028">next</a><span>|</span><label class="collapse" for="c-40329195">[-]</label><label class="expand" for="c-40329195">[6 more]</label></div><br/><div class="children"><div class="content">Minor quibble: you <i>can</i> linearize small amounts of memory using atomic access. You just need to ensure that your memory fits within the size of a single atomic access. For example, storing two uint32 as a uint64 when there is atomic access to uint64 available.</div><br/><div id="40331054" class="c"><input type="checkbox" id="c-40331054" checked=""/><div class="controls bullet"><span class="by">mevric</span><span>|</span><a href="#40329195">parent</a><span>|</span><a href="#40332028">next</a><span>|</span><label class="collapse" for="c-40331054">[-]</label><label class="expand" for="c-40331054">[5 more]</label></div><br/><div class="children"><div class="content">I am curious to understand how the following is achieved? Is there a material on this?<p>&quot;storing two uint32 as a uint64&quot;</div><br/><div id="40331073" class="c"><input type="checkbox" id="c-40331073" checked=""/><div class="controls bullet"><span class="by">JonChesterfield</span><span>|</span><a href="#40329195">root</a><span>|</span><a href="#40331054">parent</a><span>|</span><a href="#40332028">next</a><span>|</span><label class="collapse" for="c-40331073">[-]</label><label class="expand" for="c-40331073">[4 more]</label></div><br/><div class="children"><div class="content">Put them next to each other, 8 byte align the first one, use a compiler mechanism to disable alias analysis, do the uint64 store. Attribute((may_alias)) is the local override, fno-strict-aliasing the global one.<p>I think C++ can now do &quot;these bytes are now that type&quot;, called something like start_lifetime_as. C probably can&#x27;t, though using a union might be legitimate. The language rules in this area are a mess.</div><br/><div id="40331438" class="c"><input type="checkbox" id="c-40331438" checked=""/><div class="controls bullet"><span class="by">gpderetta</span><span>|</span><a href="#40329195">root</a><span>|</span><a href="#40331073">parent</a><span>|</span><a href="#40331219">next</a><span>|</span><label class="collapse" for="c-40331438">[-]</label><label class="expand" for="c-40331438">[2 more]</label></div><br/><div class="children"><div class="content">Note that writing 64 bits and reading 32 (or viceversa) is not a way to get around fences on x86. It is explicitly documented as begin undefined. In most cases it will fail to store-forward that will stall and act as an implicit fence, but in some cases the CPU can do partial store forwarding, breaking it.<p>AFAIK this trick does work on SPARC though.</div><br/><div id="40331496" class="c"><input type="checkbox" id="c-40331496" checked=""/><div class="controls bullet"><span class="by">moonchild</span><span>|</span><a href="#40329195">root</a><span>|</span><a href="#40331438">parent</a><span>|</span><a href="#40331219">next</a><span>|</span><label class="collapse" for="c-40331496">[-]</label><label class="expand" for="c-40331496">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not documented as being undefined; it&#x27;s simply not documented at all.<p>Intel&#x27;s latest uarch does partial store forwarding.<p>There was a paper from a few years ago trying to define semantics for mixed-size accesses (not for x86 though) <a href="https:&#x2F;&#x2F;www.cl.cam.ac.uk&#x2F;~pes20&#x2F;popl17&#x2F;mixed-size.pdf" rel="nofollow">https:&#x2F;&#x2F;www.cl.cam.ac.uk&#x2F;~pes20&#x2F;popl17&#x2F;mixed-size.pdf</a><p>I don&#x27;t think the parent was talking about this, though; they were just talking about using a single large physical location, which logically contains multiple smaller values.  Accesses to a single location happen order, so there is indeed no need for fencing between accesses to it.  Usually you get a full 128 bits (at least amd64&#x2F;aarch64&#x2F;ppc64; not riscv yet but I expect they will get there).<p>That said—mixed-size can be useful despite the lack of semantics (I think linux uses them in a few places?).  sooo</div><br/></div></div></div></div><div id="40331219" class="c"><input type="checkbox" id="c-40331219" checked=""/><div class="controls bullet"><span class="by">mevric</span><span>|</span><a href="#40329195">root</a><span>|</span><a href="#40331073">parent</a><span>|</span><a href="#40331438">prev</a><span>|</span><a href="#40332028">next</a><span>|</span><label class="collapse" for="c-40331219">[-]</label><label class="expand" for="c-40331219">[1 more]</label></div><br/><div class="children"><div class="content">Thank you!!</div><br/></div></div></div></div></div></div></div></div><div id="40332028" class="c"><input type="checkbox" id="c-40332028" checked=""/><div class="controls bullet"><span class="by">cryptonector</span><span>|</span><a href="#40329195">prev</a><span>|</span><a href="#40329925">next</a><span>|</span><label class="collapse" for="c-40332028">[-]</label><label class="expand" for="c-40332028">[1 more]</label></div><br/><div class="children"><div class="content">Solaris&#x2F;Illumos has a better name for this: `membar_producer()` and `membar_consumer()`.  The first is release semantics, and it&#x27;s what a <i>producer</i> must do before it finishes publishing some memory to a consumer.  The second is what a <i>consumer</i> must do before it starts consuming what the producer gave it.<p>I find that naming convention much more intuitive than release&#x2F;acquire, though release&#x2F;acquire is more general.</div><br/></div></div><div id="40329925" class="c"><input type="checkbox" id="c-40329925" checked=""/><div class="controls bullet"><span class="by">newpavlov</span><span>|</span><a href="#40332028">prev</a><span>|</span><a href="#40330541">next</a><span>|</span><label class="collapse" for="c-40329925">[-]</label><label class="expand" for="c-40329925">[1 more]</label></div><br/><div class="children"><div class="content">For a more in-depth understanding, I recommend reading &quot;Rust Atomics and Locks&quot;: <a href="https:&#x2F;&#x2F;marabos.nl&#x2F;atomics&#x2F;" rel="nofollow">https:&#x2F;&#x2F;marabos.nl&#x2F;atomics&#x2F;</a> It uses Rust for examples, but it more or less applicable to C&#x2F;C++ as well.</div><br/></div></div><div id="40330541" class="c"><input type="checkbox" id="c-40330541" checked=""/><div class="controls bullet"><span class="by">ajross</span><span>|</span><a href="#40329925">prev</a><span>|</span><a href="#40331828">next</a><span>|</span><label class="collapse" for="c-40330541">[-]</label><label class="expand" for="c-40330541">[9 more]</label></div><br/><div class="children"><div class="content">This bit isn&#x27;t quite correct:<p>&gt; <i>Acquire and release semantics don’t have any meaning on Intel- and AMD-brand processors. On x86 CPUs, which is to say, on just about any Intel- or AMD-brand CPU you can buy right now, memory operations on a single CPU core happen in program order.</i><p>In fact x86 CPUs do allow themselves to reorder reads around other reads[1].  The rule is that no memory access is allowed to cross a write operation[2].  The distinction isn&#x27;t important to traditional critical section analysis like the article is doing, but there are lockless algorithms out there that depend on fully-ordered reads.  Dekker&#x27;s famous (but mostly useless in practice) algorithm for mutual exclusion is one.<p>[1] Note here I&#x27;m using the more traditional and frankly much clearer terminology about actual hardware behavior and not the frustrating abstractions embraced by the language design community.<p>[2] Or one of a handful of &quot;serializing instructions&quot;, the most commonly relied on being LOCK CMPXCHG</div><br/><div id="40330699" class="c"><input type="checkbox" id="c-40330699" checked=""/><div class="controls bullet"><span class="by">moonchild</span><span>|</span><a href="#40330541">parent</a><span>|</span><a href="#40330799">next</a><span>|</span><label class="collapse" for="c-40330699">[-]</label><label class="expand" for="c-40330699">[2 more]</label></div><br/><div class="children"><div class="content">&gt; x86 CPUs do allow themselves to reorder reads around other reads. The rule is that no memory access is allowed to cross a write operation<p>That&#x27;s not correct.  Intel manual, vol 3, sec. 9.2.2:<p>&gt; Reads are not reordered with other reads<p>&gt; Writes are not reordered with older reads.<p>&gt; Writes to memory are not reordered with other writes<p>A read <i>may</i> be reordered w.r.t. an older write (and hence tfa is incorrect that po=ppo on x86), but reads are not ordered with other reads.  You can see in the c&#x2F;c++ processor mappings here <a href="https:&#x2F;&#x2F;www.cl.cam.ac.uk&#x2F;~pes20&#x2F;cpp&#x2F;cpp0xmappings.html" rel="nofollow">https:&#x2F;&#x2F;www.cl.cam.ac.uk&#x2F;~pes20&#x2F;cpp&#x2F;cpp0xmappings.html</a> that load acquire&#x2F;store release can be mapped to plain loads and stores on x86.</div><br/><div id="40330856" class="c"><input type="checkbox" id="c-40330856" checked=""/><div class="controls bullet"><span class="by">ajross</span><span>|</span><a href="#40330541">root</a><span>|</span><a href="#40330699">parent</a><span>|</span><a href="#40330799">next</a><span>|</span><label class="collapse" for="c-40330856">[-]</label><label class="expand" for="c-40330856">[1 more]</label></div><br/><div class="children"><div class="content">Oops, indeed.  Must be a bit flip error in my memory.</div><br/></div></div></div></div><div id="40330799" class="c"><input type="checkbox" id="c-40330799" checked=""/><div class="controls bullet"><span class="by">gpderetta</span><span>|</span><a href="#40330541">parent</a><span>|</span><a href="#40330699">prev</a><span>|</span><a href="#40330723">next</a><span>|</span><label class="collapse" for="c-40330799">[-]</label><label class="expand" for="c-40330799">[1 more]</label></div><br/><div class="children"><div class="content">Indeed, program ordering is too strong. x86 is TSO, which, as mentioned elsethread, allows for Store&#x2F;Load reordering (but not Load&#x2F;Load)<p>Dekker per-se is not terribly useful, but once you know that pattern (write to one variable and check a separate variable to make a decision) you start to recognise  it in many lock-free algorithms that try to be clever with plain stores and loads.</div><br/></div></div><div id="40330723" class="c"><input type="checkbox" id="c-40330723" checked=""/><div class="controls bullet"><span class="by">moonchild</span><span>|</span><a href="#40330541">parent</a><span>|</span><a href="#40330799">prev</a><span>|</span><a href="#40331828">next</a><span>|</span><label class="collapse" for="c-40330723">[-]</label><label class="expand" for="c-40330723">[5 more]</label></div><br/><div class="children"><div class="content">&gt; more traditional and frankly much clearer terminology about actual hardware behavior and not the frustrating abstractions embraced by the language design community<p>Axiomatic memory models were pushed as much from the hardware world as from the software world if not more so, and they exist for a reason.  Overfitting obligatorily abstract models to the behaviour of a particular microarchitecture benefits neither hardware nor software writers</div><br/><div id="40330851" class="c"><input type="checkbox" id="c-40330851" checked=""/><div class="controls bullet"><span class="by">ajross</span><span>|</span><a href="#40330541">root</a><span>|</span><a href="#40330723">parent</a><span>|</span><a href="#40331828">next</a><span>|</span><label class="collapse" for="c-40330851">[-]</label><label class="expand" for="c-40330851">[4 more]</label></div><br/><div class="children"><div class="content">&gt; Overfitting obligatorily abstract models to the behaviour of a particular microarchitecture benefits neither hardware nor software writers<p>I&#x27;m too dumb to know what the first clause means.  But the second is silly: understanding how to control the ordering of the actual memory operations (i.e. the mapping to actual behavior as seen on a bus&#x2F;interconnect somewhere) can <i>only</i> benefit hardware writers (because it tells them how to implement and explain what&#x27;s happening) and software writers (because it&#x27;s simple).<p>You don&#x27;t see articles like TFA about read and write barriers, because they&#x27;re obvious.  Acquire&#x2F;release is abstract egghead stuff, which means it&#x27;s almost certainly a bad API.</div><br/><div id="40331004" class="c"><input type="checkbox" id="c-40331004" checked=""/><div class="controls bullet"><span class="by">gary_0</span><span>|</span><a href="#40330541">root</a><span>|</span><a href="#40330851">parent</a><span>|</span><a href="#40331828">next</a><span>|</span><label class="collapse" for="c-40331004">[-]</label><label class="expand" for="c-40331004">[3 more]</label></div><br/><div class="children"><div class="content">What moonchild meant is that higher-level semantics are necessary because directly describing what the hardware is doing won&#x27;t work because almost every model of CPU does something slightly different.<p>Your argument that the higher-level terminology the industry settled on is confusing is valid (albeit subjective).<p>&gt; Acquire&#x2F;release is abstract egghead stuff<p>The article explains why this functionality is named that way, and why it&#x27;s necessary. It&#x27;s even kind of convenient, because in one line of standardized code you tell the compiler what you want, and it takes care of all the ugly platform-specific gunk, guaranteed!</div><br/><div id="40331120" class="c"><input type="checkbox" id="c-40331120" checked=""/><div class="controls bullet"><span class="by">ajross</span><span>|</span><a href="#40330541">root</a><span>|</span><a href="#40331004">parent</a><span>|</span><a href="#40331828">next</a><span>|</span><label class="collapse" for="c-40331120">[-]</label><label class="expand" for="c-40331120">[2 more]</label></div><br/><div class="children"><div class="content">&gt; What moonchild meant<p>To spell it out: I know very well what moonchild meant, and am no stranger to lockless algorithm design or memory ordering semantics.  It was a turn of phrase riffing on the point that &quot;memory ordering semantics are APIs&quot; and thus should have been designed with an eye toward clarity and comprehension for the working programmers who need to use them.<p>Acquire&#x2F;release was intended to make the job of a compiler author easier, by trying to home in on the differences between hardware that might be reasonably abstracted as a single API.  And I&#x27;m saying that&#x27;s a bad trade, because the compiler nerds are doing just fine and what the dumb jocks in the trenches want is read and write barriers.</div><br/><div id="40331456" class="c"><input type="checkbox" id="c-40331456" checked=""/><div class="controls bullet"><span class="by">gpderetta</span><span>|</span><a href="#40330541">root</a><span>|</span><a href="#40331120">parent</a><span>|</span><a href="#40331828">next</a><span>|</span><label class="collapse" for="c-40331456">[-]</label><label class="expand" for="c-40331456">[1 more]</label></div><br/><div class="children"><div class="content">I think it is just a generational difference. I learned lock-free programming during the standardization of the C++0x memory model and I do find acq&#x2F;rel a simpler model to understand and analyse algorithms, while thinking in term of reorderings never clicked for me.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="40331828" class="c"><input type="checkbox" id="c-40331828" checked=""/><div class="controls bullet"><span class="by">alfiedotwtf</span><span>|</span><a href="#40330541">prev</a><span>|</span><label class="collapse" for="c-40331828">[-]</label><label class="expand" for="c-40331828">[2 more]</label></div><br/><div class="children"><div class="content">I’ve read so much through the years on this, and I feel like it’s our Emperor’s Clothes - people pretend to understand, but does anyone actually understand this magic? Like not theoretically-superficially but in practice, or am I just too dumb to see the King’s new attire?</div><br/><div id="40332030" class="c"><input type="checkbox" id="c-40332030" checked=""/><div class="controls bullet"><span class="by">spacechild1</span><span>|</span><a href="#40331828">parent</a><span>|</span><label class="collapse" for="c-40332030">[-]</label><label class="expand" for="c-40332030">[1 more]</label></div><br/><div class="children"><div class="content">I do understand it to the extent that I can write correct lock-free data structures. For me that&#x27;s enough, I don&#x27;t need to know what happens exactly in the CPU for each architecture (altough I have <i>some</i> understanding).</div><br/></div></div></div></div></div></div></div></div></div></body></html>