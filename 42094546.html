<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1731229252712" as="style"/><link rel="stylesheet" href="styles.css?v=1731229252712"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://epochai.org/frontiermath/the-benchmark">FrontierMath: A benchmark for evaluating advanced mathematical reasoning in AI</a> <span class="domain">(<a href="https://epochai.org">epochai.org</a>)</span></div><div class="subtext"><span>sshroot</span> | <span>49 comments</span></div><br/><div><div id="42097240" class="c"><input type="checkbox" id="c-42097240" checked=""/><div class="controls bullet"><span class="by">agucova</span><span>|</span><a href="#42098150">next</a><span>|</span><label class="collapse" for="c-42097240">[-]</label><label class="expand" for="c-42097240">[38 more]</label></div><br/><div class="children"><div class="content">For some context on why this is important: this benchmark was designed to be extremely challenging for LLMs, with problems requiring several hours or days of work by expert mathematicians. Currently, LLMs solve 2% of problems in the set (which is kept private to prevent contamination).<p>They even provide a quote from Terence Tao, which helped create the benchmark (alongside other Field medalists and IMO question writers):<p>&gt; “These are extremely challenging. I think that in the near term basically the only way to solve them, short of having a real domain expert in the area, is by a combination of a semi-expert like a graduate student in a related field, maybe paired with some combination of a modern AI and lots of other algebra packages…”<p>Surprisingly, prediction markets [1] are putting 62% on AI achieving &gt; 85% performance on the benchmark before 2028.<p>[1]: <a href="https:&#x2F;&#x2F;manifold.markets&#x2F;MatthewBarnett&#x2F;will-an-ai-achieve-85-performance-o?play=true" rel="nofollow">https:&#x2F;&#x2F;manifold.markets&#x2F;MatthewBarnett&#x2F;will-an-ai-achieve-8...</a></div><br/><div id="42097567" class="c"><input type="checkbox" id="c-42097567" checked=""/><div class="controls bullet"><span class="by">sebzim4500</span><span>|</span><a href="#42097240">parent</a><span>|</span><a href="#42097936">next</a><span>|</span><label class="collapse" for="c-42097567">[-]</label><label class="expand" for="c-42097567">[4 more]</label></div><br/><div class="children"><div class="content">&gt;Surprisingly, prediction markets [1] are putting 62% on AI achieving &gt; 85% performance on the benchmark before 2028.<p>Or they know the ancient technique of training on the test set. I know most of the questions are kept secret, but they are being regularly sent over the API to every LLM provider.</div><br/><div id="42097783" class="c"><input type="checkbox" id="c-42097783" checked=""/><div class="controls bullet"><span class="by">tux3</span><span>|</span><a href="#42097240">root</a><span>|</span><a href="#42097567">parent</a><span>|</span><a href="#42097936">next</a><span>|</span><label class="collapse" for="c-42097783">[-]</label><label class="expand" for="c-42097783">[3 more]</label></div><br/><div class="children"><div class="content">Although the answer isn&#x27;t sent, so it would have to be a very deliberate effort to fish those out of the API chatter and find the right domain expert with 4-10 hours to spend on cracking it<p>Just letting the AI train on its own wrong output wouldn&#x27;t help. The benchmark already gives them lots of time for trial and error.</div><br/><div id="42098824" class="c"><input type="checkbox" id="c-42098824" checked=""/><div class="controls bullet"><span class="by">youoy</span><span>|</span><a href="#42097240">root</a><span>|</span><a href="#42097783">parent</a><span>|</span><a href="#42097936">next</a><span>|</span><label class="collapse" for="c-42098824">[-]</label><label class="expand" for="c-42098824">[2 more]</label></div><br/><div class="children"><div class="content">Why do people still insist that this is unlikely? Like assuming that the company that payed 15M for chat.com does not have some spare change to pay some graduate students&#x2F;postdocs to solve some math problems. The publicity of solving such benchmark would definitely raise the valuation so it would 100% be worth it for them...</div><br/><div id="42099066" class="c"><input type="checkbox" id="c-42099066" checked=""/><div class="controls bullet"><span class="by">llm_trw</span><span>|</span><a href="#42097240">root</a><span>|</span><a href="#42098824">parent</a><span>|</span><a href="#42097936">next</a><span>|</span><label class="collapse" for="c-42099066">[-]</label><label class="expand" for="c-42099066">[1 more]</label></div><br/><div class="children"><div class="content">Any benchmark which isn&#x27;t dynamically generated is useless for that very reason.</div><br/></div></div></div></div></div></div></div></div><div id="42097936" class="c"><input type="checkbox" id="c-42097936" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#42097240">parent</a><span>|</span><a href="#42097567">prev</a><span>|</span><a href="#42097804">next</a><span>|</span><label class="collapse" for="c-42097936">[-]</label><label class="expand" for="c-42097936">[6 more]</label></div><br/><div class="children"><div class="content">&gt; <i>Surprisingly, prediction markets [1] are putting 62% on AI achieving &gt; 85% performance on the benchmark before 2028.</i><p>Why surprisingly?<p>2028 is twice as long as capable LLMs existed to date. By &quot;capable&quot; here I mean capable enough to even remotely consider the idea of LLMs solving such tasks in the first place. ChatGPT&#x2F;GPT-3.5 <i>isn&#x27;t even 2 years old</i>!<p>4 years is a lot of time. It&#x27;s kind of silly to assume LLM capabilities have already bottomed out.</div><br/><div id="42098230" class="c"><input type="checkbox" id="c-42098230" checked=""/><div class="controls bullet"><span class="by">ekianjo</span><span>|</span><a href="#42097240">root</a><span>|</span><a href="#42097936">parent</a><span>|</span><a href="#42098768">next</a><span>|</span><label class="collapse" for="c-42098230">[-]</label><label class="expand" for="c-42098230">[1 more]</label></div><br/><div class="children"><div class="content">Sure but it is also reasonable to consider that the pace of progress is not always exponential or even linear at best. Diminishing returns are a thing and we already know that a 405b model is not 5 times better than a 70b model.</div><br/></div></div><div id="42098768" class="c"><input type="checkbox" id="c-42098768" checked=""/><div class="controls bullet"><span class="by">slashdave</span><span>|</span><a href="#42097240">root</a><span>|</span><a href="#42097936">parent</a><span>|</span><a href="#42098230">prev</a><span>|</span><a href="#42097804">next</a><span>|</span><label class="collapse" for="c-42098768">[-]</label><label class="expand" for="c-42098768">[4 more]</label></div><br/><div class="children"><div class="content">Except LLM capabilities have already peaked. Scaling has rapidly diminishing returns.</div><br/><div id="42098831" class="c"><input type="checkbox" id="c-42098831" checked=""/><div class="controls bullet"><span class="by">Workaccount2</span><span>|</span><a href="#42097240">root</a><span>|</span><a href="#42098768">parent</a><span>|</span><a href="#42097804">next</a><span>|</span><label class="collapse" for="c-42098831">[-]</label><label class="expand" for="c-42098831">[3 more]</label></div><br/><div class="children"><div class="content">I have yet to see any published evidence of that.</div><br/><div id="42098901" class="c"><input type="checkbox" id="c-42098901" checked=""/><div class="controls bullet"><span class="by">olivermuty</span><span>|</span><a href="#42097240">root</a><span>|</span><a href="#42098831">parent</a><span>|</span><a href="#42097804">next</a><span>|</span><label class="collapse" for="c-42098901">[-]</label><label class="expand" for="c-42098901">[2 more]</label></div><br/><div class="children"><div class="content">Since you go that route, do you have published evidence that shows they HAVENT entered the top of the S-curve?</div><br/><div id="42098958" class="c"><input type="checkbox" id="c-42098958" checked=""/><div class="controls bullet"><span class="by">edanm</span><span>|</span><a href="#42097240">root</a><span>|</span><a href="#42098901">parent</a><span>|</span><a href="#42097804">next</a><span>|</span><label class="collapse" for="c-42098958">[-]</label><label class="expand" for="c-42098958">[1 more]</label></div><br/><div class="children"><div class="content">What kind of evidence could convince you?</div><br/></div></div></div></div></div></div></div></div></div></div><div id="42097804" class="c"><input type="checkbox" id="c-42097804" checked=""/><div class="controls bullet"><span class="by">equestria</span><span>|</span><a href="#42097240">parent</a><span>|</span><a href="#42097936">prev</a><span>|</span><a href="#42097569">next</a><span>|</span><label class="collapse" for="c-42097804">[-]</label><label class="expand" for="c-42097804">[1 more]</label></div><br/><div class="children"><div class="content">Market size matters. There&#x27;s a whopping total of 71 bidders on that.</div><br/></div></div><div id="42097569" class="c"><input type="checkbox" id="c-42097569" checked=""/><div class="controls bullet"><span class="by">light_hue_1</span><span>|</span><a href="#42097240">parent</a><span>|</span><a href="#42097804">prev</a><span>|</span><a href="#42097390">next</a><span>|</span><label class="collapse" for="c-42097569">[-]</label><label class="expand" for="c-42097569">[4 more]</label></div><br/><div class="children"><div class="content">If I was going to bet, I would bet yes, they will reach above 85% performance.<p>The problem with all benchmarks, one that we just don&#x27;t how to solve, is leakage. Systematically, LLMs are much better at benchmarks created before they were trained than after. There are countless papers that show significant leakage between training and test sets for models.<p>This is in part why so many LLMs are so strong according to benchmarks, particularly older popular benchmarks, but then prove to be so weak in practice when you try them out.<p>In addition to leakage, people also over-tune their LLMs to specific datasets. They also go out and collect more data that looks like the dataset they want to perform well on.<p>There&#x27;s a lot of behind the scenes talk about unethical teams that collect data which doesn&#x27;t technically overlap test sets, but is extremely close. You can detect this if you look at the pattern of errors these models make. But no one wants to go out and accuse specific teams, at least not for now.</div><br/><div id="42098503" class="c"><input type="checkbox" id="c-42098503" checked=""/><div class="controls bullet"><span class="by">agucova</span><span>|</span><a href="#42097240">root</a><span>|</span><a href="#42097569">parent</a><span>|</span><a href="#42097592">next</a><span>|</span><label class="collapse" for="c-42098503">[-]</label><label class="expand" for="c-42098503">[2 more]</label></div><br/><div class="children"><div class="content">This benchmark’s questions and answers will be kept fully private, and the benchmark will only be run by Epoch. Short of the companies fishing out the questions from API logs (which seems quite unlikely), this shouldn’t be a problem.</div><br/><div id="42098902" class="c"><input type="checkbox" id="c-42098902" checked=""/><div class="controls bullet"><span class="by">benchmarkist</span><span>|</span><a href="#42097240">root</a><span>|</span><a href="#42098503">parent</a><span>|</span><a href="#42097592">next</a><span>|</span><label class="collapse" for="c-42098902">[-]</label><label class="expand" for="c-42098902">[1 more]</label></div><br/><div class="children"><div class="content">I looked at the sample questions and even if they get the questions there is no way they will figure out the answers without making significant breakthroughs in understanding mathematics and logic.</div><br/></div></div></div></div><div id="42097592" class="c"><input type="checkbox" id="c-42097592" checked=""/><div class="controls bullet"><span class="by">nerdponx</span><span>|</span><a href="#42097240">root</a><span>|</span><a href="#42097569">parent</a><span>|</span><a href="#42098503">prev</a><span>|</span><a href="#42097390">next</a><span>|</span><label class="collapse" for="c-42097592">[-]</label><label class="expand" for="c-42097592">[1 more]</label></div><br/><div class="children"><div class="content">Could you run the benchmark by bootstrapping (average of repeated subsampling), instead of a straight-across performance score, and regain some leakage resistance that way? As well as a better simulation of &quot;out of sample&quot; data, at least for a little while.</div><br/></div></div></div></div><div id="42097390" class="c"><input type="checkbox" id="c-42097390" checked=""/><div class="controls bullet"><span class="by">llm_trw</span><span>|</span><a href="#42097240">parent</a><span>|</span><a href="#42097569">prev</a><span>|</span><a href="#42098150">next</a><span>|</span><label class="collapse" for="c-42097390">[-]</label><label class="expand" for="c-42097390">[22 more]</label></div><br/><div class="children"><div class="content">These benchmarks are entirely pointless.<p>The people making them are specialists attempting to apply their skills to areas unrelated to LLM performance, a bit like a sprinter making a training regimen for a fighter jet.<p>What matters is the data structures that underlie the problem space - graph traversal. First, finding a path between two nodes; second, identifying the most efficient path; and third, deriving implicit nodes and edges based on a set of rules.<p>Currently, all LLMs are so limited that they struggle with journeys longer than four edges, even when given a full itinerary of all edges in the graph. Until they can consistently manage a number of steps greater than what is contained in any math proof in the validation data, they aren’t genuinely solving these problems; they’re merely regurgitating memorized information.</div><br/><div id="42098479" class="c"><input type="checkbox" id="c-42098479" checked=""/><div class="controls bullet"><span class="by">nopinsight</span><span>|</span><a href="#42097240">root</a><span>|</span><a href="#42097390">parent</a><span>|</span><a href="#42098839">next</a><span>|</span><label class="collapse" for="c-42098479">[-]</label><label class="expand" for="c-42098479">[4 more]</label></div><br/><div class="children"><div class="content">&gt; Currently, all LLMs are so limited that they struggle with journeys longer than four edges, even when given a full itinerary of all edges in the graph.<p>This is probably not the case for LLMs in the o1 series and possibly Claude 3.5 Sonnet. Have you tested them on this claim?</div><br/><div id="42098603" class="c"><input type="checkbox" id="c-42098603" checked=""/><div class="controls bullet"><span class="by">llm_trw</span><span>|</span><a href="#42097240">root</a><span>|</span><a href="#42098479">parent</a><span>|</span><a href="#42098839">next</a><span>|</span><label class="collapse" for="c-42098603">[-]</label><label class="expand" for="c-42098603">[3 more]</label></div><br/><div class="children"><div class="content">Yes, they also fail. I&#x27;ve found the original gpt4 to be the most consistent. One of these days I&#x27;ll spend the couple of thousands needed to benchmark all the top models and see how they actually perform on a task which can&#x27;t be gamed.</div><br/><div id="42098686" class="c"><input type="checkbox" id="c-42098686" checked=""/><div class="controls bullet"><span class="by">nopinsight</span><span>|</span><a href="#42097240">root</a><span>|</span><a href="#42098603">parent</a><span>|</span><a href="#42098839">next</a><span>|</span><label class="collapse" for="c-42098686">[-]</label><label class="expand" for="c-42098686">[2 more]</label></div><br/><div class="children"><div class="content">What kinds of problems in what domains did you test o1 models with?<p>I found that they are good at logic and math problems but still hallucinate. I didn’t try to stretch test them with hard problems though.</div><br/><div id="42098698" class="c"><input type="checkbox" id="c-42098698" checked=""/><div class="controls bullet"><span class="by">llm_trw</span><span>|</span><a href="#42097240">root</a><span>|</span><a href="#42098686">parent</a><span>|</span><a href="#42098839">next</a><span>|</span><label class="collapse" for="c-42098698">[-]</label><label class="expand" for="c-42098698">[1 more]</label></div><br/><div class="children"><div class="content">Finding a path between two vertices when given an itinerary of all the edges in a general graph, exactly what I said in the OP.</div><br/></div></div></div></div></div></div></div></div><div id="42098839" class="c"><input type="checkbox" id="c-42098839" checked=""/><div class="controls bullet"><span class="by">youoy</span><span>|</span><a href="#42097240">root</a><span>|</span><a href="#42097390">parent</a><span>|</span><a href="#42098479">prev</a><span>|</span><a href="#42097515">next</a><span>|</span><label class="collapse" for="c-42098839">[-]</label><label class="expand" for="c-42098839">[1 more]</label></div><br/><div class="children"><div class="content">Not to mention that math proofs are more than graph trasversals... (Although maybe simple math problems are not) There is the problem of extracting the semantics of math formalisms. This is easier in day to day language, I don&#x27;t know to what extent LLMs can also extract the semantics and relations of different mathematical abstractions.</div><br/></div></div><div id="42097515" class="c"><input type="checkbox" id="c-42097515" checked=""/><div class="controls bullet"><span class="by">benchmarkist</span><span>|</span><a href="#42097240">root</a><span>|</span><a href="#42097390">parent</a><span>|</span><a href="#42098839">prev</a><span>|</span><a href="#42097442">next</a><span>|</span><label class="collapse" for="c-42097515">[-]</label><label class="expand" for="c-42097515">[6 more]</label></div><br/><div class="children"><div class="content">It will be a useful benchmark to validate claims by people like Sam Altman about having achieved AGI.</div><br/><div id="42098796" class="c"><input type="checkbox" id="c-42098796" checked=""/><div class="controls bullet"><span class="by">campers</span><span>|</span><a href="#42097240">root</a><span>|</span><a href="#42097515">parent</a><span>|</span><a href="#42097613">next</a><span>|</span><label class="collapse" for="c-42098796">[-]</label><label class="expand" for="c-42098796">[1 more]</label></div><br/><div class="children"><div class="content">If an AI achieved 100% in this benchmark it would indicate super-intelligence in the field of mathematics. But depending on what else it could do it may fall short on general intelligence across all domains.</div><br/></div></div><div id="42097613" class="c"><input type="checkbox" id="c-42097613" checked=""/><div class="controls bullet"><span class="by">mkl</span><span>|</span><a href="#42097240">root</a><span>|</span><a href="#42097515">parent</a><span>|</span><a href="#42098796">prev</a><span>|</span><a href="#42097442">next</a><span>|</span><label class="collapse" for="c-42097613">[-]</label><label class="expand" for="c-42097613">[4 more]</label></div><br/><div class="children"><div class="content">Most humans can&#x27;t solve these problems, so it&#x27;s certainly possible to imagine a legitimate AGI that can&#x27;t either.</div><br/><div id="42098725" class="c"><input type="checkbox" id="c-42098725" checked=""/><div class="controls bullet"><span class="by">aurareturn</span><span>|</span><a href="#42097240">root</a><span>|</span><a href="#42097613">parent</a><span>|</span><a href="#42097442">next</a><span>|</span><label class="collapse" for="c-42098725">[-]</label><label class="expand" for="c-42098725">[3 more]</label></div><br/><div class="children"><div class="content">But humans can solve these problems given enough time and domain knowledge. An LLM would never be able to solve them unless they get smarter. Thats the point.<p>It’s not about whether a random human can solve them. It’s whether AI, in general, can. Humans, in general, have proven to be able to solve them already.</div><br/><div id="42099059" class="c"><input type="checkbox" id="c-42099059" checked=""/><div class="controls bullet"><span class="by">llm_trw</span><span>|</span><a href="#42097240">root</a><span>|</span><a href="#42098725">parent</a><span>|</span><a href="#42098909">next</a><span>|</span><label class="collapse" for="c-42099059">[-]</label><label class="expand" for="c-42099059">[1 more]</label></div><br/><div class="children"><div class="content">It is very much an open question just what an llm can solve when allowed to generate an indefinite number of intermediate tokens and allowed to sample an arbitrary amount of text to ground itself.<p>There are currently no tools that let llms do this and no one is building the tools for answering open ended questions.</div><br/></div></div><div id="42098909" class="c"><input type="checkbox" id="c-42098909" checked=""/><div class="controls bullet"><span class="by">benchmarkist</span><span>|</span><a href="#42097240">root</a><span>|</span><a href="#42098725">parent</a><span>|</span><a href="#42099059">prev</a><span>|</span><a href="#42097442">next</a><span>|</span><label class="collapse" for="c-42098909">[-]</label><label class="expand" for="c-42098909">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s correct. Thanks for clarifying for me because I have gotten tired with the comparison to &quot;99% of humans can&#x27;t do this&quot; as a counter-argument to AI hype criticism.</div><br/></div></div></div></div></div></div></div></div><div id="42097442" class="c"><input type="checkbox" id="c-42097442" checked=""/><div class="controls bullet"><span class="by">dr_dshiv</span><span>|</span><a href="#42097240">root</a><span>|</span><a href="#42097390">parent</a><span>|</span><a href="#42097515">prev</a><span>|</span><a href="#42098150">next</a><span>|</span><label class="collapse" for="c-42097442">[-]</label><label class="expand" for="c-42097442">[10 more]</label></div><br/><div class="children"><div class="content">&gt; they’re merely regurgitating memorized information<p>Source?</div><br/><div id="42097615" class="c"><input type="checkbox" id="c-42097615" checked=""/><div class="controls bullet"><span class="by">llm_trw</span><span>|</span><a href="#42097240">root</a><span>|</span><a href="#42097442">parent</a><span>|</span><a href="#42097489">next</a><span>|</span><label class="collapse" for="c-42097615">[-]</label><label class="expand" for="c-42097615">[3 more]</label></div><br/><div class="children"><div class="content">If a model can&#x27;t inately reason over 5 steps in a simple task but produces a flawless 500 step proof you either have divine intervention or memorisation.</div><br/><div id="42098671" class="c"><input type="checkbox" id="c-42098671" checked=""/><div class="controls bullet"><span class="by">NitpickLawyer</span><span>|</span><a href="#42097240">root</a><span>|</span><a href="#42097615">parent</a><span>|</span><a href="#42097489">next</a><span>|</span><label class="collapse" for="c-42098671">[-]</label><label class="expand" for="c-42098671">[2 more]</label></div><br/><div class="children"><div class="content">AlphaGeometry has entered the chat.<p>Also, AIMOv2 is doing stage 2 of their math challenge, they are now at &quot;national olympics&quot; level of difficulty. They have a new set of questions. Last year&#x27;s winner (27&#x2F;50 points) got 2&#x2F;50 on the new set. In the first 3 weeks of the competition the top score is 10&#x2F;50 on the new set, mostly with Qwen2.5-math. Given that this is a purposefully made new set of problems, and according to the organizers &quot;made to be AI hard&quot;, I&#x27;d say the regurgitation stuff is getting pretty stale.<p>Also also, the fact that claude3.5 can start coding in an invented language w&#x2F; ~20-30k tokens of &quot;documentation&quot; about the invented language is also some kind of proof that the stochastic parrots are the dismissers in this case.</div><br/><div id="42098677" class="c"><input type="checkbox" id="c-42098677" checked=""/><div class="controls bullet"><span class="by">llm_trw</span><span>|</span><a href="#42097240">root</a><span>|</span><a href="#42098671">parent</a><span>|</span><a href="#42097489">next</a><span>|</span><label class="collapse" for="c-42098677">[-]</label><label class="expand" for="c-42098677">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve not tested those models. Feel free to flick me through a couple of k in bitcoins if you&#x27;d like me to have a look for you.</div><br/></div></div></div></div></div></div><div id="42097489" class="c"><input type="checkbox" id="c-42097489" checked=""/><div class="controls bullet"><span class="by">exe34</span><span>|</span><a href="#42097240">root</a><span>|</span><a href="#42097442">parent</a><span>|</span><a href="#42097615">prev</a><span>|</span><a href="#42097505">next</a><span>|</span><label class="collapse" for="c-42097489">[-]</label><label class="expand" for="c-42097489">[1 more]</label></div><br/><div class="children"><div class="content">he just explained it to you.</div><br/></div></div><div id="42097505" class="c"><input type="checkbox" id="c-42097505" checked=""/><div class="controls bullet"><span class="by">firebaze</span><span>|</span><a href="#42097240">root</a><span>|</span><a href="#42097442">parent</a><span>|</span><a href="#42097489">prev</a><span>|</span><a href="#42098150">next</a><span>|</span><label class="collapse" for="c-42097505">[-]</label><label class="expand" for="c-42097505">[5 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not sure if it is feasible to provide all relevant sources to someone who doesn&#x27;t follow a field. It is quite common knowledge that LLMs in their current form have no ability to recurse directly over a prompt, which inherently limits their reasoning ability.</div><br/><div id="42097539" class="c"><input type="checkbox" id="c-42097539" checked=""/><div class="controls bullet"><span class="by">light_hue_1</span><span>|</span><a href="#42097240">root</a><span>|</span><a href="#42097505">parent</a><span>|</span><a href="#42098150">next</a><span>|</span><label class="collapse" for="c-42097539">[-]</label><label class="expand" for="c-42097539">[4 more]</label></div><br/><div class="children"><div class="content">This is just totally false.<p>That&#x27;s exactly what countless techniques related to chain of thought do.</div><br/><div id="42097594" class="c"><input type="checkbox" id="c-42097594" checked=""/><div class="controls bullet"><span class="by">llm_trw</span><span>|</span><a href="#42097240">root</a><span>|</span><a href="#42097539">parent</a><span>|</span><a href="#42097570">next</a><span>|</span><label class="collapse" for="c-42097594">[-]</label><label class="expand" for="c-42097594">[1 more]</label></div><br/><div class="children"><div class="content">The closest explanation to how chain of through works is suppressing the probability of a termination token.<p>People have found that even letting llms generate gibberish tokens produces better final outputs. Which isn&#x27;t a surprise when you realise that the only way a llm can do computation is by outputting tokens.</div><br/></div></div><div id="42097570" class="c"><input type="checkbox" id="c-42097570" checked=""/><div class="controls bullet"><span class="by">dr_dshiv</span><span>|</span><a href="#42097240">root</a><span>|</span><a href="#42097539">parent</a><span>|</span><a href="#42097594">prev</a><span>|</span><a href="#42098150">next</a><span>|</span><label class="collapse" for="c-42097570">[-]</label><label class="expand" for="c-42097570">[2 more]</label></div><br/><div class="children"><div class="content">It’s sometimes like, are these critics using the tools? It’s a strange schism at the moment.</div><br/><div id="42097600" class="c"><input type="checkbox" id="c-42097600" checked=""/><div class="controls bullet"><span class="by">llm_trw</span><span>|</span><a href="#42097240">root</a><span>|</span><a href="#42097570">parent</a><span>|</span><a href="#42098150">next</a><span>|</span><label class="collapse" for="c-42097600">[-]</label><label class="expand" for="c-42097600">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s my job to build these tools. I&#x27;m well aware of their strengths and shortcomings.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="42098150" class="c"><input type="checkbox" id="c-42098150" checked=""/><div class="controls bullet"><span class="by">bravura</span><span>|</span><a href="#42097240">prev</a><span>|</span><a href="#42097703">next</a><span>|</span><label class="collapse" for="c-42098150">[-]</label><label class="expand" for="c-42098150">[2 more]</label></div><br/><div class="children"><div class="content">Regarding keeping the test set private to avoid contamination, the comments about leakage are spot on. The real test set should always be <i>the future</i>.<p>We should evaluate LLMs on text from beyond their knowledge cutoff date, by computing their per-byte perplexity or per-byte compression ratio. There&#x27;s a deep theoretical connection between compression and learning.<p>The intuition here is that being able to predict the future of science (or any topic, really) is indicative of true understanding. Slightly more formally: When ICLR 2025 announces and publishes the accepted papers, Yoshua Bengio is less surprised&#x2F;perplexed by what&#x27;s new than a fresh PhD student. And Terence Tao is less surprised&#x2F;perplexed by what will be proven in math in the next 10 years than a graduate student in a related field.<p>This work has it right: <a href="https:&#x2F;&#x2F;ar5iv.labs.arxiv.org&#x2F;html&#x2F;&#x2F;2402.00861" rel="nofollow">https:&#x2F;&#x2F;ar5iv.labs.arxiv.org&#x2F;html&#x2F;&#x2F;2402.00861</a></div><br/><div id="42098244" class="c"><input type="checkbox" id="c-42098244" checked=""/><div class="controls bullet"><span class="by">3abiton</span><span>|</span><a href="#42098150">parent</a><span>|</span><a href="#42097703">next</a><span>|</span><label class="collapse" for="c-42098244">[-]</label><label class="expand" for="c-42098244">[1 more]</label></div><br/><div class="children"><div class="content">Interesting take sounds like MDL (Minimum description length) for LLMs!</div><br/></div></div></div></div><div id="42097524" class="c"><input type="checkbox" id="c-42097524" checked=""/><div class="controls bullet"><span class="by">benchmarkist</span><span>|</span><a href="#42097703">prev</a><span>|</span><a href="#42097683">next</a><span>|</span><label class="collapse" for="c-42097524">[-]</label><label class="expand" for="c-42097524">[5 more]</label></div><br/><div class="children"><div class="content">Very cool. It&#x27;ll be nice to have a benchmark that can be used to validate abstract reasoning capabilities because the hype is really starting to get out of hand.</div><br/><div id="42097596" class="c"><input type="checkbox" id="c-42097596" checked=""/><div class="controls bullet"><span class="by">nerdponx</span><span>|</span><a href="#42097524">parent</a><span>|</span><a href="#42097559">next</a><span>|</span><label class="collapse" for="c-42097596">[-]</label><label class="expand" for="c-42097596">[2 more]</label></div><br/><div class="children"><div class="content">I wonder if the best benchmark is a Prolog program that generates tests of logical reasoning. You could have a functionally infinite stream of test cases!</div><br/><div id="42098914" class="c"><input type="checkbox" id="c-42098914" checked=""/><div class="controls bullet"><span class="by">benchmarkist</span><span>|</span><a href="#42097524">root</a><span>|</span><a href="#42097596">parent</a><span>|</span><a href="#42097559">next</a><span>|</span><label class="collapse" for="c-42098914">[-]</label><label class="expand" for="c-42098914">[1 more]</label></div><br/><div class="children"><div class="content">You could but most LLMs can&#x27;t solve sudoku puzzles even though the training corpus already contains books on logic, constraint propagation, and state space exploration with backtracking.</div><br/></div></div></div></div><div id="42097559" class="c"><input type="checkbox" id="c-42097559" checked=""/><div class="controls bullet"><span class="by">sebzim4500</span><span>|</span><a href="#42097524">parent</a><span>|</span><a href="#42097596">prev</a><span>|</span><a href="#42097683">next</a><span>|</span><label class="collapse" for="c-42097559">[-]</label><label class="expand" for="c-42097559">[2 more]</label></div><br/><div class="children"><div class="content">I mean, this benchmark is really hard.<p>I don&#x27;t think it&#x27;s a requirement that a system claiming to be AGI should be able to solve these problems, 99.99% of humans can&#x27;t either.</div><br/><div id="42098920" class="c"><input type="checkbox" id="c-42098920" checked=""/><div class="controls bullet"><span class="by">benchmarkist</span><span>|</span><a href="#42097524">root</a><span>|</span><a href="#42097559">parent</a><span>|</span><a href="#42097683">next</a><span>|</span><label class="collapse" for="c-42098920">[-]</label><label class="expand" for="c-42098920">[1 more]</label></div><br/><div class="children"><div class="content">An AGI is often claimed to be a general purpose problem solver and these are exactly the types of problems that a general purpose problem solver would be able to solve if given access to a mathematical library. All existing LLMs have been trained on abstract mathematics and logic but it is obvious that they are incapable of abstract logical reasoning, e.g. solving sudoku puzzles.</div><br/></div></div></div></div></div></div><div id="42097683" class="c"><input type="checkbox" id="c-42097683" checked=""/><div class="controls bullet"><span class="by">westurner</span><span>|</span><a href="#42097524">prev</a><span>|</span><label class="collapse" for="c-42097683">[-]</label><label class="expand" for="c-42097683">[2 more]</label></div><br/><div class="children"><div class="content">ScholarlyArticle: &quot;FrontierMath: A Benchmark for Evaluating Advanced Mathematical Reasoning in AI&quot; (2024) <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2411.04872" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2411.04872</a> .. 
<a href="https:&#x2F;&#x2F;epochai.org&#x2F;frontiermath&#x2F;the-benchmark" rel="nofollow">https:&#x2F;&#x2F;epochai.org&#x2F;frontiermath&#x2F;the-benchmark</a> :<p>&gt; [Not even 2%]<p>&gt; Abstract: <i>We introduce FrontierMath, a benchmark of hundreds of original, exceptionally challenging mathematics problems crafted and vetted by expert mathematicians. The questions cover most major branches of modern mathematics -- from computationally intensive problems in number theory and real analysis to abstract questions in algebraic geometry and category theory. Solving a typical problem requires multiple hours of effort from a researcher in the relevant branch of mathematics, and for the upper end questions, multiple days. FrontierMath uses new, unpublished problems and automated verification to reliably evaluate models while minimizing risk of data contamination. Current state-of-the-art AI models solve under 2% of problems, revealing a vast gap between AI capabilities and the prowess of the mathematical community. As AI systems advance toward expert-level mathematical abilities, FrontierMath offers a rigorous testbed that quantifies their progress.</i></div><br/><div id="42097700" class="c"><input type="checkbox" id="c-42097700" checked=""/><div class="controls bullet"><span class="by">westurner</span><span>|</span><a href="#42097683">parent</a><span>|</span><label class="collapse" for="c-42097700">[-]</label><label class="expand" for="c-42097700">[1 more]</label></div><br/><div class="children"><div class="content">Additional AI math benchmarks:<p>- &quot;TheoremQA: A Theorem-driven [STEM] Question Answering dataset&quot; (2023) <a href="https:&#x2F;&#x2F;github.com&#x2F;TIGER-AI-Lab&#x2F;TheoremQA">https:&#x2F;&#x2F;github.com&#x2F;TIGER-AI-Lab&#x2F;TheoremQA</a></div><br/></div></div></div></div></div></div></div></div></div></body></html>