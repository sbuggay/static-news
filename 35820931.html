<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1683277251026" as="style"/><link rel="stylesheet" href="styles.css?v=1683277251026"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://blog.scottlogic.com/2023/05/04/langchain-mini.html">Re-implementing LangChain in 100 lines of code</a> <span class="domain">(<a href="https://blog.scottlogic.com">blog.scottlogic.com</a>)</span></div><div class="subtext"><span>ColinEberhardt</span> | <span>61 comments</span></div><br/><div><div id="35824313" class="c"><input type="checkbox" id="c-35824313" checked=""/><div class="controls bullet"><span class="by">fbrncci</span><span>|</span><a href="#35824411">next</a><span>|</span><label class="collapse" for="c-35824313">[-]</label><label class="expand" for="c-35824313">[9 more]</label></div><br/><div class="children"><div class="content">I work with Langchain on a daily basis now, and so often I find myself asking; do I really need a whole LLM framework for this? At this point, the assistant I am writing, will likely be more stable rewritten in pure Python. The deeper and more complex the application becomes, the more of a risk Langchain seems to become to keeping it maintainable. But even at less complex levels, if I want to do this:<p>1. Have a huge dataset of documents.<p>2. Want to ask questions and have an LLM chat conversation based on these documents.<p>3. Be able to implement tools like math, wiki or Google search on top of the retrieval.<p>4. Implement memory management for longer conversations.<p>Its still a lot more straightforward to maintain it in Python. The only thing where it becomes interesting is having agents execute async, which is not that easy replicate, but at the moment agents are not that helpful. Not trying to diss Langchain too much here, because its such an awesome framework, but I can&#x27;t help seeing past it other than just being a helpful tool to understand LLM&#x27;s and LLM programming for now.</div><br/><div id="35825824" class="c"><input type="checkbox" id="c-35825824" checked=""/><div class="controls bullet"><span class="by">danvass</span><span>|</span><a href="#35824313">parent</a><span>|</span><a href="#35824398">next</a><span>|</span><label class="collapse" for="c-35825824">[-]</label><label class="expand" for="c-35825824">[1 more]</label></div><br/><div class="children"><div class="content">We&#x27;ve been building LLM chains for over a year and found that whilst for simple use-cases it&#x27;s easy enough to grab a couple of APIs. However, having a Notebook experience built for iterating and collaborating whilst managing the complexity is something we&#x27;ve seen companies care deeply about.</div><br/></div></div><div id="35824398" class="c"><input type="checkbox" id="c-35824398" checked=""/><div class="controls bullet"><span class="by">theturtletalks</span><span>|</span><a href="#35824313">parent</a><span>|</span><a href="#35825824">prev</a><span>|</span><a href="#35824674">next</a><span>|</span><label class="collapse" for="c-35824398">[-]</label><label class="expand" for="c-35824398">[6 more]</label></div><br/><div class="children"><div class="content">Won’t ChatGPT eventually eat your lunch? Once ChatGPT allows uploading documents (embeddings), what good will your app be?<p>The tools you’re talking about like math, wiki, or search are already built as plugins on ChatGPT.<p>I see so many AI apps being built, but I think ChatGPT will be general enough to cover 85-90% of use-cases using the chat UI.</div><br/><div id="35825858" class="c"><input type="checkbox" id="c-35825858" checked=""/><div class="controls bullet"><span class="by">chaxor</span><span>|</span><a href="#35824313">root</a><span>|</span><a href="#35824398">parent</a><span>|</span><a href="#35824420">next</a><span>|</span><label class="collapse" for="c-35825858">[-]</label><label class="expand" for="c-35825858">[2 more]</label></div><br/><div class="children"><div class="content">The most important aspect of langchain is <i>NOT</i> using OpenAI for the LM.<p>The most useful aspect of using langchain is to use it with Galpaca (or vicuna&#x2F;koala&#x2F;etc) to spin up an assistant for your home.<p>This way, you can push <i>all</i> of your files through it - even petabytes or terabytes of files, at a fraction of the cost - and have it organize things for you.  No privacy problems, no extreme costs, just ease of use, low latency, offline, blazingly fast beauty.  That&#x27;s at least the trajectory.<p>Meta may soon release an improvement to Galactica similar to Galpaca (GeorgiaTech attempt) more officially (perhaps with more multimodal focus), which will likely improve upon the llama based models even further.<p>ChatGPT is just one model among many here, and it&#x27;s not even the first to use RLHF (Deepmind, as usual, was a bit earlier).<p>The simple task of downloading Redpamajas&#x2F;thePile&#x2F;etc and getting a vector db for it locally, and enhancing it with local files effectively brings a local Google to everyone, and it may only require a decent spinning disk HD for the DB storage with the typical langchain LLM setup to have a completely local &#x27;jarvis&#x27;-like assistant. (Sure, I know some people care about &#x27;news&#x27;-like info that requires connectivity, but <i>most</i> things don&#x27;t)</div><br/><div id="35826583" class="c"><input type="checkbox" id="c-35826583" checked=""/><div class="controls bullet"><span class="by">0xDEF</span><span>|</span><a href="#35824313">root</a><span>|</span><a href="#35825858">parent</a><span>|</span><a href="#35824420">next</a><span>|</span><label class="collapse" for="c-35826583">[-]</label><label class="expand" for="c-35826583">[1 more]</label></div><br/><div class="children"><div class="content">The vast majority of people building LM apps with (or without) LangChain are using OpenAI.<p>I sincerely hope local LM tech like Galpaca (or vicuna&#x2F;koala&#x2F;etc) succeed but I don&#x27;t understand why we are collectively pretending they are currently anywhere near gpt-3.5-turbo both in terms of speed and quality. Honestly the local models feel more like first generation BERT&#x2F;GPT-1 models that have been fine-tuned for QA using RLHF.</div><br/></div></div></div></div><div id="35824420" class="c"><input type="checkbox" id="c-35824420" checked=""/><div class="controls bullet"><span class="by">fbrncci</span><span>|</span><a href="#35824313">root</a><span>|</span><a href="#35824398">parent</a><span>|</span><a href="#35825858">prev</a><span>|</span><a href="#35824674">next</a><span>|</span><label class="collapse" for="c-35824420">[-]</label><label class="expand" for="c-35824420">[3 more]</label></div><br/><div class="children"><div class="content">It&#x27;s more or less an advanced personal project to stay on top of the LLM learning curve, rather than just being exposed to news and press releases. I also have an appetite for further wrapping my mind around all of this. I already work in the AI space as web-developer on the B2B &amp; enterprise side of things. My opinion here is that there are going to be loads of use-cases and necessary plugins, which for privacy, legal and security reasons need a proprietary solution and won&#x27;t be able to interface with any third party APIs, plugins or frameworks.</div><br/><div id="35824525" class="c"><input type="checkbox" id="c-35824525" checked=""/><div class="controls bullet"><span class="by">theturtletalks</span><span>|</span><a href="#35824313">root</a><span>|</span><a href="#35824420">parent</a><span>|</span><a href="#35824674">next</a><span>|</span><label class="collapse" for="c-35824525">[-]</label><label class="expand" for="c-35824525">[2 more]</label></div><br/><div class="children"><div class="content">I completely agree with you on AI being extensively integrated into existing apps and being leveraged that way.<p>But most of the AI apps I see are just like a “skin” on ChatGPT API.<p>I do think there is value in a universal chat UI that can connect to GPT-3 and other models.</div><br/><div id="35824659" class="c"><input type="checkbox" id="c-35824659" checked=""/><div class="controls bullet"><span class="by">fbrncci</span><span>|</span><a href="#35824313">root</a><span>|</span><a href="#35824525">parent</a><span>|</span><a href="#35824674">next</a><span>|</span><label class="collapse" for="c-35824659">[-]</label><label class="expand" for="c-35824659">[1 more]</label></div><br/><div class="children"><div class="content">I think that is a phase, which will come to pass, eventually most of the plugins and apps which are going to be popular, will likely run their own models or use open source models. Because the API calls for complex applications to OpenAI are currently far from economical. In the end you will have to charge the user, and that is going to be the crux. As a sole developer, doing loads of experiments on less than 50 documents, I am already crossing 50$ in API calls within a month. I can already run llama.cpp, but its just not good enough; but the cost would effectively be 0$ (not counting my hardware).</div><br/></div></div></div></div></div></div></div></div><div id="35824674" class="c"><input type="checkbox" id="c-35824674" checked=""/><div class="controls bullet"><span class="by">nbardy</span><span>|</span><a href="#35824313">parent</a><span>|</span><a href="#35824398">prev</a><span>|</span><a href="#35824411">next</a><span>|</span><label class="collapse" for="c-35824674">[-]</label><label class="expand" for="c-35824674">[1 more]</label></div><br/><div class="children"><div class="content">I’m not convinced yet, but if they can provide nice templating and reusability.<p>There is plenty room for code reuse in prompting.</div><br/></div></div></div></div><div id="35824411" class="c"><input type="checkbox" id="c-35824411" checked=""/><div class="controls bullet"><span class="by">rcme</span><span>|</span><a href="#35824313">prev</a><span>|</span><a href="#35823960">next</a><span>|</span><label class="collapse" for="c-35824411">[-]</label><label class="expand" for="c-35824411">[12 more]</label></div><br/><div class="children"><div class="content">LangChain has been so frequently discussed that I thought it must be this amazing piece of software. I was recently reading about vector databases and how they can be used to provide context to LLMs. I came across a LangChain class called RetrievalQA, which takes in a vector database and a question and produces and answer based on documents stored in the vector db. My curiosity was piqued! How did it work? Well... it works like this:<p><pre><code>    prompt_template = &quot;&quot;&quot;Use the following pieces of context to answer the question at the end. If you don&#x27;t know the answer, just say that you don&#x27;t know, don&#x27;t try to make up an answer.
    {context}
    Question: {question}
    Helpful Answer:&quot;&quot;&quot;
</code></pre>
My sense of wonder was instantly deflated. &quot;Helpful Answer:&quot;. Seriously? I think LLMs are cool, but this made me realize people are just throwing darts in the dark here.</div><br/><div id="35824428" class="c"><input type="checkbox" id="c-35824428" checked=""/><div class="controls bullet"><span class="by">nextworddev</span><span>|</span><a href="#35824411">parent</a><span>|</span><a href="#35825635">next</a><span>|</span><label class="collapse" for="c-35824428">[-]</label><label class="expand" for="c-35824428">[4 more]</label></div><br/><div class="children"><div class="content">It got a lot of traction on non-coders thinking it’s doing some magic, but if you read the source it boils down to some brittle prompts and lots of Python class boilerplate.<p>There’s some useful parts though</div><br/><div id="35824495" class="c"><input type="checkbox" id="c-35824495" checked=""/><div class="controls bullet"><span class="by">rcme</span><span>|</span><a href="#35824411">root</a><span>|</span><a href="#35824428">parent</a><span>|</span><a href="#35825635">next</a><span>|</span><label class="collapse" for="c-35824495">[-]</label><label class="expand" for="c-35824495">[3 more]</label></div><br/><div class="children"><div class="content">Just out of curiosity, what are the useful parts?</div><br/><div id="35824679" class="c"><input type="checkbox" id="c-35824679" checked=""/><div class="controls bullet"><span class="by">nextworddev</span><span>|</span><a href="#35824411">root</a><span>|</span><a href="#35824495">parent</a><span>|</span><a href="#35824851">next</a><span>|</span><label class="collapse" for="c-35824679">[-]</label><label class="expand" for="c-35824679">[1 more]</label></div><br/><div class="children"><div class="content">It’s good for building vector indices without worrying about writing adapters to milvus, pinecone, qdrant etc separately - in case you want to switch out later</div><br/></div></div><div id="35824851" class="c"><input type="checkbox" id="c-35824851" checked=""/><div class="controls bullet"><span class="by">19h</span><span>|</span><a href="#35824411">root</a><span>|</span><a href="#35824495">parent</a><span>|</span><a href="#35824679">prev</a><span>|</span><a href="#35825635">next</a><span>|</span><label class="collapse" for="c-35824851">[-]</label><label class="expand" for="c-35824851">[1 more]</label></div><br/><div class="children"><div class="content">The class structure provides a clean API for building on, even if the internals are basic. With some refinement, it could be a good starting point for more advanced models.</div><br/></div></div></div></div></div></div><div id="35825635" class="c"><input type="checkbox" id="c-35825635" checked=""/><div class="controls bullet"><span class="by">ryanjshaw</span><span>|</span><a href="#35824411">parent</a><span>|</span><a href="#35824428">prev</a><span>|</span><a href="#35824734">next</a><span>|</span><label class="collapse" for="c-35825635">[-]</label><label class="expand" for="c-35825635">[1 more]</label></div><br/><div class="children"><div class="content">I had the same experience and kept wondering if I was missing something important. I&#x27;m not a fan of Python, so I was anxious about not using the thing everybody recommended, but for my project I ultimately went with what I know well (C#). I&#x27;ve happily had zero issues.<p>LangChain docs and tutorials <i>were</i> useful for understanding the popular practices for approaching AI-driven development, but the biggest challenge by far has been getting a baseline prompt and measuring performance of alternative implementations against that in a sensible way that doesn&#x27;t break the bank. Mitchell Hashimotos&#x27;s Prompt Engineering article [1] was way more helpful in this regard than anything I saw in LangChain.<p>To that end I&#x27;ve also been working on a tool to save me money by caching requests and responses, blocking unexpectedly expensive requests, keeping a granular history of requests for prompt cost analysis, etc. Maybe I should open source it and get some VC bux too?<p>[1] <a href="https:&#x2F;&#x2F;mitchellh.com&#x2F;writing&#x2F;prompt-engineering-vs-blind-prompting" rel="nofollow">https:&#x2F;&#x2F;mitchellh.com&#x2F;writing&#x2F;prompt-engineering-vs-blind-pr...</a></div><br/></div></div><div id="35824734" class="c"><input type="checkbox" id="c-35824734" checked=""/><div class="controls bullet"><span class="by">fbrncci</span><span>|</span><a href="#35824411">parent</a><span>|</span><a href="#35825635">prev</a><span>|</span><a href="#35824498">next</a><span>|</span><label class="collapse" for="c-35824734">[-]</label><label class="expand" for="c-35824734">[1 more]</label></div><br/><div class="children"><div class="content">But wait, there is more! In Langchain you can build constitutional chains ontop of your chains, to validate if the answer was really helpful, by doing just one more API call, with a new prompt, asking if the answer answered the question based on the initial prompt, in an helpful way! And if it didn&#x27;t, revise the answer with another API call to be more helpful! And then you can chain these chains with even further API calls until you went through as much prompts you think are necessary to answer a single sentence question (What is the weather today on the moon?).</div><br/></div></div><div id="35824498" class="c"><input type="checkbox" id="c-35824498" checked=""/><div class="controls bullet"><span class="by">fzliu</span><span>|</span><a href="#35824411">parent</a><span>|</span><a href="#35824734">prev</a><span>|</span><a href="#35824996">next</a><span>|</span><label class="collapse" for="c-35824498">[-]</label><label class="expand" for="c-35824498">[1 more]</label></div><br/><div class="children"><div class="content">LangChain is meant to reduce&#x2F;remove the amount of boilerplate code needed to build a lot of applications with LLMs. I see your point, but I still think LangChain is useful for a particular segment of early stage developers.</div><br/></div></div><div id="35824996" class="c"><input type="checkbox" id="c-35824996" checked=""/><div class="controls bullet"><span class="by">m3kw9</span><span>|</span><a href="#35824411">parent</a><span>|</span><a href="#35824498">prev</a><span>|</span><a href="#35824837">next</a><span>|</span><label class="collapse" for="c-35824996">[-]</label><label class="expand" for="c-35824996">[1 more]</label></div><br/><div class="children"><div class="content">It basically gathers text that are similar to what you are asking and feed it into the prompt, yes.  No magic.  The worse part is that if you ask “please get me the summary to this doc” it will actually search the vector db using the entire question.  It’s not very smart. Depending on how you split the embedding you could end up with a bunch of crap</div><br/></div></div><div id="35824837" class="c"><input type="checkbox" id="c-35824837" checked=""/><div class="controls bullet"><span class="by">19h</span><span>|</span><a href="#35824411">parent</a><span>|</span><a href="#35824996">prev</a><span>|</span><a href="#35825053">next</a><span>|</span><label class="collapse" for="c-35824837">[-]</label><label class="expand" for="c-35824837">[2 more]</label></div><br/><div class="children"><div class="content">If it makes you feel any better, the researchers building these things don&#x27;t really know what they&#x27;re doing either.  They just throw data and compute at the problem and hope for the best.</div><br/><div id="35825052" class="c"><input type="checkbox" id="c-35825052" checked=""/><div class="controls bullet"><span class="by">esafak</span><span>|</span><a href="#35824411">root</a><span>|</span><a href="#35824837">parent</a><span>|</span><a href="#35825053">next</a><span>|</span><label class="collapse" for="c-35825052">[-]</label><label class="expand" for="c-35825052">[1 more]</label></div><br/><div class="children"><div class="content">I wouldn&#x27;t say that. If it was that simple, the credits of GPT-4 wouldn&#x27;t be this long: <a href="https:&#x2F;&#x2F;openai.com&#x2F;contributions&#x2F;gpt-4" rel="nofollow">https:&#x2F;&#x2F;openai.com&#x2F;contributions&#x2F;gpt-4</a></div><br/></div></div></div></div><div id="35825053" class="c"><input type="checkbox" id="c-35825053" checked=""/><div class="controls bullet"><span class="by">Karrot_Kream</span><span>|</span><a href="#35824411">parent</a><span>|</span><a href="#35824837">prev</a><span>|</span><a href="#35823960">next</a><span>|</span><label class="collapse" for="c-35825053">[-]</label><label class="expand" for="c-35825053">[1 more]</label></div><br/><div class="children"><div class="content">The default &quot;document splitter&quot; just splits along double newlines. It took me aback when I realized they made an entire class around this.</div><br/></div></div></div></div><div id="35823960" class="c"><input type="checkbox" id="c-35823960" checked=""/><div class="controls bullet"><span class="by">loveparade</span><span>|</span><a href="#35824411">prev</a><span>|</span><a href="#35823869">next</a><span>|</span><label class="collapse" for="c-35823960">[-]</label><label class="expand" for="c-35823960">[6 more]</label></div><br/><div class="children"><div class="content">Am I the only one who is not convinced by the value proposition of langchain? 99% of it are interface definitions and implementations for external tools, most of which are super straightforward. I can write integrations for what my app needs in less than an hour myself, why bring in a heavily opinionated external framework? It kind of feels like the npm &quot;left-pad&quot; to me. Everyone just uses it because it seems popular, not because they need it.</div><br/><div id="35824989" class="c"><input type="checkbox" id="c-35824989" checked=""/><div class="controls bullet"><span class="by">crazyedgar</span><span>|</span><a href="#35823960">parent</a><span>|</span><a href="#35824304">next</a><span>|</span><label class="collapse" for="c-35824989">[-]</label><label class="expand" for="c-35824989">[1 more]</label></div><br/><div class="children"><div class="content">For us LangChain actually caused more problems than it solved. We had a system in production which after working fine a few weeks suddenly started experiencing frequent failures (more than 30% of requests). On digging it seems that LangChain sets a default timeout of 60 seconds for every requests. And this behaviour isn&#x27;t documented! Such spurious decisions made by LangChain are everywhere, and will all eventually come back to bite. In the end we replaced everything with vanilla request clients. Definitely not recommended to build a system on a library that provides very limited value while hiding a huge amount of details and decisions from you.</div><br/></div></div><div id="35824304" class="c"><input type="checkbox" id="c-35824304" checked=""/><div class="controls bullet"><span class="by">newswasboring</span><span>|</span><a href="#35823960">parent</a><span>|</span><a href="#35824989">prev</a><span>|</span><a href="#35824126">next</a><span>|</span><label class="collapse" for="c-35824304">[-]</label><label class="expand" for="c-35824304">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s brilliant for experimentation and prototyping though. Granted I&#x27;ve not deployed anything llm related yet so I have not thought about it yet, but I don&#x27;t want to just start writing every integration I think I need by hand just to experiment with it.</div><br/></div></div><div id="35824126" class="c"><input type="checkbox" id="c-35824126" checked=""/><div class="controls bullet"><span class="by">Spivak</span><span>|</span><a href="#35823960">parent</a><span>|</span><a href="#35824304">prev</a><span>|</span><a href="#35824064">next</a><span>|</span><label class="collapse" for="c-35824126">[-]</label><label class="expand" for="c-35824126">[1 more]</label></div><br/><div class="children"><div class="content">Langchain is absolutely perfect though, it&#x27;s bad enough that you&#x27;ll be driven to write something better out of pure frustration but gives you enough good ideas and breadcrumbs to actually do it.<p>It&#x27;s probably the best on-ramp for &quot;practical uses of llms&quot; because it scratches just the right developer itch.</div><br/></div></div><div id="35824064" class="c"><input type="checkbox" id="c-35824064" checked=""/><div class="controls bullet"><span class="by">gumby</span><span>|</span><a href="#35823960">parent</a><span>|</span><a href="#35824126">prev</a><span>|</span><a href="#35823869">next</a><span>|</span><label class="collapse" for="c-35824064">[-]</label><label class="expand" for="c-35824064">[2 more]</label></div><br/><div class="children"><div class="content">&gt; I can write integrations for what my app needs in less than an hour myself,<p>Or just ask ChatGPT to do it...<p>Joking aside, I think &#x27;npm &quot;left-pad&quot;&#x27; describes it perfectly.</div><br/><div id="35825723" class="c"><input type="checkbox" id="c-35825723" checked=""/><div class="controls bullet"><span class="by">vidarh</span><span>|</span><a href="#35823960">root</a><span>|</span><a href="#35824064">parent</a><span>|</span><a href="#35823869">next</a><span>|</span><label class="collapse" for="c-35825723">[-]</label><label class="expand" for="c-35825723">[1 more]</label></div><br/><div class="children"><div class="content">Most of the code my OpenAI API experiments run on was written by ChatGPT.</div><br/></div></div></div></div></div></div><div id="35823869" class="c"><input type="checkbox" id="c-35823869" checked=""/><div class="controls bullet"><span class="by">cube2222</span><span>|</span><a href="#35823960">prev</a><span>|</span><a href="#35825117">next</a><span>|</span><label class="collapse" for="c-35823869">[-]</label><label class="expand" for="c-35823869">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, the basics of LangChain are fairly simple, and reimplementing a loop like that in Go, including tool usage, was very straightforward when I was writing Cuttlefish[0] (a toy desktop chat app for ChatGPT that can use stuff like your local terminal or Google).<p>The magic in LangChain,  though, is the ecosystem. I.e. they have integrations with tons of indexes, they have many tool implementations, etc. This is the real value of LangChain. The core ReAct loop is quite trivial (as this article demonstrates).<p>[0]: <a href="https:&#x2F;&#x2F;github.com&#x2F;cube2222&#x2F;cuttlefish">https:&#x2F;&#x2F;github.com&#x2F;cube2222&#x2F;cuttlefish</a></div><br/></div></div><div id="35825117" class="c"><input type="checkbox" id="c-35825117" checked=""/><div class="controls bullet"><span class="by">adityapurwa</span><span>|</span><a href="#35823869">prev</a><span>|</span><a href="#35824206">next</a><span>|</span><label class="collapse" for="c-35825117">[-]</label><label class="expand" for="c-35825117">[3 more]</label></div><br/><div class="children"><div class="content">I got the chance to try Langchain as part of a hiring process. I was already having my eye on it for a personal projects though.<p>The moment I tried it and went through the docs, the entire abstraction feels weird for me. I know a bit here and there about LLM, but Langchain make me feels like Im learning something entirely new.<p>How agent and tools work and how to write one wasnt straightforward from the docs, and the idea of having an AI attach itself to an eval or writing its own error&#x2F;hallucination-prone API request based on a docs doesnt give me a lot of confidence.<p>The hiring assignment specifically mentioned to use Langchain thought, so I did. But just as a glorified abstraction to call GPT and parses the NL output as JSON.<p>I did the actual API call, post-processing, etc. manually. Which I have granular control over it. Also cheaper in terms of token usages. You could say I ended writing my own agent&#x2F;tool that doesnt exactly match Langchain specifications but it works.<p>I guess Langchain had its use case. But it feels pretty weird to use for me.</div><br/><div id="35825620" class="c"><input type="checkbox" id="c-35825620" checked=""/><div class="controls bullet"><span class="by">minimaxir</span><span>|</span><a href="#35825117">parent</a><span>|</span><a href="#35825472">next</a><span>|</span><label class="collapse" for="c-35825620">[-]</label><label class="expand" for="c-35825620">[1 more]</label></div><br/><div class="children"><div class="content">LangChain and the ReAct paper that helped codify the implementation are both less than a year old.<p>A hiring assignment suggesting it is…weird.</div><br/></div></div><div id="35825472" class="c"><input type="checkbox" id="c-35825472" checked=""/><div class="controls bullet"><span class="by">triyambakam</span><span>|</span><a href="#35825117">parent</a><span>|</span><a href="#35825620">prev</a><span>|</span><a href="#35824206">next</a><span>|</span><label class="collapse" for="c-35825472">[-]</label><label class="expand" for="c-35825472">[1 more]</label></div><br/><div class="children"><div class="content">What type of position was the assessment for?</div><br/></div></div></div></div><div id="35824206" class="c"><input type="checkbox" id="c-35824206" checked=""/><div class="controls bullet"><span class="by">lxe</span><span>|</span><a href="#35825117">prev</a><span>|</span><a href="#35825436">next</a><span>|</span><label class="collapse" for="c-35824206">[-]</label><label class="expand" for="c-35824206">[4 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve been working with langchain and llamaindex and did notice that it&#x27;s a pretty hefty abstraction on top of pretty simple concepts and I also eventually ended up dropping both and simply write the underlying code without the framework on top.</div><br/><div id="35825036" class="c"><input type="checkbox" id="c-35825036" checked=""/><div class="controls bullet"><span class="by">zomglings</span><span>|</span><a href="#35824206">parent</a><span>|</span><a href="#35824214">next</a><span>|</span><label class="collapse" for="c-35825036">[-]</label><label class="expand" for="c-35825036">[1 more]</label></div><br/><div class="children"><div class="content">Ditto. But with faiss and openai api.</div><br/></div></div><div id="35824681" class="c"><input type="checkbox" id="c-35824681" checked=""/><div class="controls bullet"><span class="by">KevinBenSmith</span><span>|</span><a href="#35824206">parent</a><span>|</span><a href="#35824214">prev</a><span>|</span><a href="#35825436">next</a><span>|</span><label class="collapse" for="c-35824681">[-]</label><label class="expand" for="c-35824681">[1 more]</label></div><br/><div class="children"><div class="content">Pretty much sums up my experience as well.</div><br/></div></div></div></div><div id="35825436" class="c"><input type="checkbox" id="c-35825436" checked=""/><div class="controls bullet"><span class="by">saulpw</span><span>|</span><a href="#35824206">prev</a><span>|</span><a href="#35826216">next</a><span>|</span><label class="collapse" for="c-35825436">[-]</label><label class="expand" for="c-35825436">[1 more]</label></div><br/><div class="children"><div class="content">I also was underwhelmed by langchain, and started implementing my own &quot;AIPL&quot; (Array-Inspired Pipeline Language) which turns these &quot;chains&quot; into straightforward, linear scripts.  It&#x27;s very early days but already it feels like the right direction for experimenting with this stuff. (I&#x27;m looking for collaborators if anyone is interested!)<p><a href="https:&#x2F;&#x2F;github.com&#x2F;saulpw&#x2F;aipl">https:&#x2F;&#x2F;github.com&#x2F;saulpw&#x2F;aipl</a></div><br/></div></div><div id="35826216" class="c"><input type="checkbox" id="c-35826216" checked=""/><div class="controls bullet"><span class="by">havercosine</span><span>|</span><a href="#35825436">prev</a><span>|</span><a href="#35825383">next</a><span>|</span><label class="collapse" for="c-35826216">[-]</label><label class="expand" for="c-35826216">[1 more]</label></div><br/><div class="children"><div class="content">Personal experience: was using LangChain and its output parsers for getting structured data. It was having a very high error rates (probably prompt was becoming too long and confusing). But it is a just prompt + some parsing logic. Replaced it with straight asking openAI GPT for json that matches some Rust struct &#x2F; Python data-class. The errors went down and got one extra dependency out from the project. Tried to use its self hosted embeddings but the implementation (strangely) seemed tied to something called Run-house.<p>Not to belittle the library, but most of it is a very thin wrapper classes that reek of premature abstraction, couple with hit-n-miss docs. At this point, given the hype, it is primarily optimized for cooking up demoes quickly. But not sure if the valuations or production use is justified.</div><br/></div></div><div id="35825383" class="c"><input type="checkbox" id="c-35825383" checked=""/><div class="controls bullet"><span class="by">zyang</span><span>|</span><a href="#35826216">prev</a><span>|</span><a href="#35824777">next</a><span>|</span><label class="collapse" for="c-35825383">[-]</label><label class="expand" for="c-35825383">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m glad I wasn&#x27;t the only one that felt Langchain had a ton of redundant abstractions engineered to gain clout for vc money. Here is an example:<p>AnalyzeDocumentChain[1] just wraps RecursiveCharacterTextSplitter[2]. It serves no real purpose except padding the api doc.<p>[1] <a href="https:&#x2F;&#x2F;js.langchain.com&#x2F;docs&#x2F;modules&#x2F;chains&#x2F;other_chains&#x2F;analyze_document" rel="nofollow">https:&#x2F;&#x2F;js.langchain.com&#x2F;docs&#x2F;modules&#x2F;chains&#x2F;other_chains&#x2F;an...</a>
[2] <a href="https:&#x2F;&#x2F;js.langchain.com&#x2F;docs&#x2F;modules&#x2F;chains&#x2F;other_chains&#x2F;summarization" rel="nofollow">https:&#x2F;&#x2F;js.langchain.com&#x2F;docs&#x2F;modules&#x2F;chains&#x2F;other_chains&#x2F;su...</a></div><br/><div id="35825507" class="c"><input type="checkbox" id="c-35825507" checked=""/><div class="controls bullet"><span class="by">crazyedgar</span><span>|</span><a href="#35825383">parent</a><span>|</span><a href="#35824777">next</a><span>|</span><label class="collapse" for="c-35825507">[-]</label><label class="expand" for="c-35825507">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s worse than that. The documentation is a confusing mess that completely omits the explanation of key default parameters and details. And the abstractions are horrendously brittle. And difficult to fix, because there are too many layers.<p>The best use of LangChain is probably just looking at the included prompts in the source code for inspiration.</div><br/></div></div></div></div><div id="35824777" class="c"><input type="checkbox" id="c-35824777" checked=""/><div class="controls bullet"><span class="by">KevinBenSmith</span><span>|</span><a href="#35825383">prev</a><span>|</span><a href="#35824459">next</a><span>|</span><label class="collapse" for="c-35824777">[-]</label><label class="expand" for="c-35824777">[3 more]</label></div><br/><div class="children"><div class="content">As someone who has created several LLM-based applications running in production, my personal experience with langchain has been that it is too high of an abstraction for steps that in the end are actually fairly simple.<p>And as soon as you want to slightly modify something to better accomodate your use-case, you are trapped in layers &amp; layers of Python boiler plate code and unnecessary abstractions.<p>Maybe our llm applications haven’t been complex enough to warrent the use of langchain, but if that’s the case, then I wonder how many of such complex applications actually exist today.<p>-&gt; Anyways, I came away feeling quite let down by the hype.<p>For my own personal workflow, a more “hackable” architecture would be much more valuable. Totally fine if that means it’s less “general”.
As a comparison, I remember the early days of HugginfaceTransformers where they did not try to create a 100% high-level general abstraction on top of every conceivable Neural Network architecture. Instead, each model architecture was somewhat separate from one another, making it much easier to “hack” it.</div><br/><div id="35824811" class="c"><input type="checkbox" id="c-35824811" checked=""/><div class="controls bullet"><span class="by">19h</span><span>|</span><a href="#35824777">parent</a><span>|</span><a href="#35824459">next</a><span>|</span><label class="collapse" for="c-35824811">[-]</label><label class="expand" for="c-35824811">[2 more]</label></div><br/><div class="children"><div class="content">Comparing Langchain to Hugging Face Transformers is apples and oranges. One is for research, one is for production. Production ML requires more abstraction, not less.</div><br/><div id="35825446" class="c"><input type="checkbox" id="c-35825446" checked=""/><div class="controls bullet"><span class="by">crazyedgar</span><span>|</span><a href="#35824777">root</a><span>|</span><a href="#35824811">parent</a><span>|</span><a href="#35824459">next</a><span>|</span><label class="collapse" for="c-35825446">[-]</label><label class="expand" for="c-35825446">[1 more]</label></div><br/><div class="children"><div class="content">I disagree. Production systems don&#x27;t need to be full of AbstractSingletonProxyFactoryBeans which is basically what LangChain is. For example, Linux certainly isn&#x27;t.</div><br/></div></div></div></div></div></div><div id="35824459" class="c"><input type="checkbox" id="c-35824459" checked=""/><div class="controls bullet"><span class="by">okhat</span><span>|</span><a href="#35824777">prev</a><span>|</span><a href="#35825898">next</a><span>|</span><label class="collapse" for="c-35824459">[-]</label><label class="expand" for="c-35824459">[2 more]</label></div><br/><div class="children"><div class="content">There’s always DSP for those who need a lightweight but powerful programming model — not a library of predefined prompts and integrations.<p>It’s a very different experience from the hand-holding of LangChain, but it packs reusable magic in generic constructs like annotate, compile, etc that work with arbitrary programs.<p><a href="https:&#x2F;&#x2F;github.com&#x2F;stanfordnlp&#x2F;dsp&#x2F;">https:&#x2F;&#x2F;github.com&#x2F;stanfordnlp&#x2F;dsp&#x2F;</a></div><br/><div id="35824831" class="c"><input type="checkbox" id="c-35824831" checked=""/><div class="controls bullet"><span class="by">barking_biscuit</span><span>|</span><a href="#35824459">parent</a><span>|</span><a href="#35825898">next</a><span>|</span><label class="collapse" for="c-35824831">[-]</label><label class="expand" for="c-35824831">[1 more]</label></div><br/><div class="children"><div class="content">Didn&#x27;t know about this. Looks promising!</div><br/></div></div></div></div><div id="35825898" class="c"><input type="checkbox" id="c-35825898" checked=""/><div class="controls bullet"><span class="by">lynx23</span><span>|</span><a href="#35824459">prev</a><span>|</span><a href="#35825624">next</a><span>|</span><label class="collapse" for="c-35825898">[-]</label><label class="expand" for="c-35825898">[1 more]</label></div><br/><div class="children"><div class="content">Hmm, this is great food for thought!  I am working on a Haskell based REPL for GPT, called GPTi[1] which might benefit from this approach.<p>[1] <a href="https:&#x2F;&#x2F;github.com&#x2F;mlang&#x2F;gpti">https:&#x2F;&#x2F;github.com&#x2F;mlang&#x2F;gpti</a></div><br/></div></div><div id="35825624" class="c"><input type="checkbox" id="c-35825624" checked=""/><div class="controls bullet"><span class="by">nestorD</span><span>|</span><a href="#35825898">prev</a><span>|</span><a href="#35824705">next</a><span>|</span><label class="collapse" for="c-35825624">[-]</label><label class="expand" for="c-35825624">[2 more]</label></div><br/><div class="children"><div class="content">For me Langchain is glue code between a lot of commonly used LLM building blocks and prompts.<p>It is great to get a prototype 80% of the way there fast in order to validate an idea or run something short lived.<p>I suspect that, if you want to go further (simpler code, better control message length, reliability, etc), you will be better served by implementing the functionality you need yourself.</div><br/><div id="35825628" class="c"><input type="checkbox" id="c-35825628" checked=""/><div class="controls bullet"><span class="by">crazyedgar</span><span>|</span><a href="#35825624">parent</a><span>|</span><a href="#35824705">next</a><span>|</span><label class="collapse" for="c-35825628">[-]</label><label class="expand" for="c-35825628">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s no suspicion. Our experience shows that for the remaining 20% of work, LangChain actually gets in the way and must eventually be removed.</div><br/></div></div></div></div><div id="35824705" class="c"><input type="checkbox" id="c-35824705" checked=""/><div class="controls bullet"><span class="by">ukuina</span><span>|</span><a href="#35825624">prev</a><span>|</span><a href="#35823759">next</a><span>|</span><label class="collapse" for="c-35824705">[-]</label><label class="expand" for="c-35824705">[4 more]</label></div><br/><div class="children"><div class="content">I cannot praise Deepset Haystack enough for how simple they make things compared to LangChain, between the Preprocessor, the Reader&#x2F;Retriever, and the PromptNode - the APIs, docs, and tutorials are quite easy to modify to your use-case.<p>Not affiliated, just a happy defector from LangChain.</div><br/><div id="35825475" class="c"><input type="checkbox" id="c-35825475" checked=""/><div class="controls bullet"><span class="by">iamflimflam1</span><span>|</span><a href="#35824705">parent</a><span>|</span><a href="#35823759">next</a><span>|</span><label class="collapse" for="c-35825475">[-]</label><label class="expand" for="c-35825475">[3 more]</label></div><br/><div class="children"><div class="content">Is it open source? Wasn’t clear from the website.</div><br/><div id="35826068" class="c"><input type="checkbox" id="c-35826068" checked=""/><div class="controls bullet"><span class="by">aantti</span><span>|</span><a href="#35824705">root</a><span>|</span><a href="#35825475">parent</a><span>|</span><a href="#35825997">next</a><span>|</span><label class="collapse" for="c-35826068">[-]</label><label class="expand" for="c-35826068">[1 more]</label></div><br/><div class="children"><div class="content">Yes, Haystack is Apache 2.0 :) <a href="https:&#x2F;&#x2F;haystack.deepset.ai" rel="nofollow">https:&#x2F;&#x2F;haystack.deepset.ai</a></div><br/></div></div><div id="35825997" class="c"><input type="checkbox" id="c-35825997" checked=""/><div class="controls bullet"><span class="by">tholor</span><span>|</span><a href="#35824705">root</a><span>|</span><a href="#35825475">parent</a><span>|</span><a href="#35826068">prev</a><span>|</span><a href="#35823759">next</a><span>|</span><label class="collapse" for="c-35825997">[-]</label><label class="expand" for="c-35825997">[1 more]</label></div><br/><div class="children"><div class="content">Yes!
<a href="https:&#x2F;&#x2F;github.com&#x2F;deepset-ai&#x2F;haystack">https:&#x2F;&#x2F;github.com&#x2F;deepset-ai&#x2F;haystack</a></div><br/></div></div></div></div></div></div><div id="35823759" class="c"><input type="checkbox" id="c-35823759" checked=""/><div class="controls bullet"><span class="by">justanotheratom</span><span>|</span><a href="#35824705">prev</a><span>|</span><a href="#35823829">next</a><span>|</span><label class="collapse" for="c-35823759">[-]</label><label class="expand" for="c-35823759">[5 more]</label></div><br/><div class="children"><div class="content">Given that the company has $200 million valuation, that is $2 million per line of code! just kidding.<p>Still, I would like to understand $200 million valuation of langchain.ai.</div><br/><div id="35824225" class="c"><input type="checkbox" id="c-35824225" checked=""/><div class="controls bullet"><span class="by">nextworddev</span><span>|</span><a href="#35823759">parent</a><span>|</span><a href="#35823821">next</a><span>|</span><label class="collapse" for="c-35824225">[-]</label><label class="expand" for="c-35824225">[1 more]</label></div><br/><div class="children"><div class="content">Langchain is kinda like web3 in how it got memed on Twitter basically to adoption</div><br/></div></div><div id="35823821" class="c"><input type="checkbox" id="c-35823821" checked=""/><div class="controls bullet"><span class="by">throwaway888abc</span><span>|</span><a href="#35823759">parent</a><span>|</span><a href="#35824225">prev</a><span>|</span><a href="#35825389">next</a><span>|</span><label class="collapse" for="c-35823821">[-]</label><label class="expand" for="c-35823821">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a great momentum to dominate eco system. Heard about Docker (that was more than http fetch wrapper) ?</div><br/><div id="35824689" class="c"><input type="checkbox" id="c-35824689" checked=""/><div class="controls bullet"><span class="by">ukuina</span><span>|</span><a href="#35823759">root</a><span>|</span><a href="#35823821">parent</a><span>|</span><a href="#35825389">next</a><span>|</span><label class="collapse" for="c-35824689">[-]</label><label class="expand" for="c-35824689">[1 more]</label></div><br/><div class="children"><div class="content">I think we can safely say this did not end well for Docker.</div><br/></div></div></div></div><div id="35825389" class="c"><input type="checkbox" id="c-35825389" checked=""/><div class="controls bullet"><span class="by">reducesuffering</span><span>|</span><a href="#35823759">parent</a><span>|</span><a href="#35823821">prev</a><span>|</span><a href="#35823829">next</a><span>|</span><label class="collapse" for="c-35825389">[-]</label><label class="expand" for="c-35825389">[1 more]</label></div><br/><div class="children"><div class="content">VC&#x27;s are in full blown FOMO mode for things they barely understand. Even the engineering backgrounds are pretty lost; imagine the finance backgrounds that have barely wrote a lick of code.</div><br/></div></div></div></div><div id="35823829" class="c"><input type="checkbox" id="c-35823829" checked=""/><div class="controls bullet"><span class="by">rahimnathwani</span><span>|</span><a href="#35823759">prev</a><span>|</span><a href="#35823962">next</a><span>|</span><label class="collapse" for="c-35823829">[-]</label><label class="expand" for="c-35823829">[1 more]</label></div><br/><div class="children"><div class="content">Related comments about ReAct: <a href="https:&#x2F;&#x2F;hn.algolia.com&#x2F;?dateRange=all&amp;page=0&amp;prefix=true&amp;query=https%3A%2F%2Farxiv.org%2Fabs%2F2210.03629&amp;sort=byPopularity&amp;type=comment" rel="nofollow">https:&#x2F;&#x2F;hn.algolia.com&#x2F;?dateRange=all&amp;page=0&amp;prefix=true&amp;que...</a></div><br/></div></div><div id="35823962" class="c"><input type="checkbox" id="c-35823962" checked=""/><div class="controls bullet"><span class="by">fchief</span><span>|</span><a href="#35823829">prev</a><span>|</span><a href="#35826457">next</a><span>|</span><label class="collapse" for="c-35823962">[-]</label><label class="expand" for="c-35823962">[1 more]</label></div><br/><div class="children"><div class="content">We ported the core of LangChain to Ruby, and while it is way more that 100 lines, I would give similar feedback as the author. Here is the repo if anyone is interested <a href="https:&#x2F;&#x2F;github.com&#x2F;BoxcarsAI&#x2F;boxcars">https:&#x2F;&#x2F;github.com&#x2F;BoxcarsAI&#x2F;boxcars</a></div><br/></div></div><div id="35826457" class="c"><input type="checkbox" id="c-35826457" checked=""/><div class="controls bullet"><span class="by">shri_krishna</span><span>|</span><a href="#35823962">prev</a><span>|</span><a href="#35824780">next</a><span>|</span><label class="collapse" for="c-35826457">[-]</label><label class="expand" for="c-35826457">[1 more]</label></div><br/><div class="children"><div class="content">For the calculator tool I suggest instead to just generate Javascript as an output with temperature set to 0 (system prompt set to something along the lines of: &quot;Generate native Javascript code only. Don&#x27;t provide any explanations. Don&#x27;t import any extraneous libraries&quot;) and then eval that Javascript code in a VM. Deno is a good candidate for this as it has good security settings with access to filesystem and network turned off by default. You can use something like deno-vm [1] to execute it separate from your running process too. Setting GPT-4 as model works even better. I have seen it perform better than Wolfram Alpha in many cases so I am wondering why OpenAI chose to integrate with Wolfram Alpha for this. GPT-4 was able to solve some really complex math problems I threw at it.<p>[1]: <a href="https:&#x2F;&#x2F;www.npmjs.com&#x2F;package&#x2F;deno-vm" rel="nofollow">https:&#x2F;&#x2F;www.npmjs.com&#x2F;package&#x2F;deno-vm</a></div><br/></div></div><div id="35824780" class="c"><input type="checkbox" id="c-35824780" checked=""/><div class="controls bullet"><span class="by">valyagolev</span><span>|</span><a href="#35826457">prev</a><span>|</span><label class="collapse" for="c-35824780">[-]</label><label class="expand" for="c-35824780">[1 more]</label></div><br/><div class="children"><div class="content">we&#x27;re still in the stage of LLM adoption when we can have &quot;eye-opening&quot; simple discoveries weekly. Langchain has momentum because of this, as a library of simple ideas.  this period will end, and if they don&#x27;t figure out the next step they&#x27;re gone</div><br/></div></div></div></div></div></div></div></body></html>