<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1720861252406" as="style"/><link rel="stylesheet" href="styles.css?v=1720861252406"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.mattkeeter.com/blog/2024-07-12-interpreter/">Beating the Compiler</a> <span class="domain">(<a href="https://www.mattkeeter.com">www.mattkeeter.com</a>)</span></div><div class="subtext"><span>mkeeter</span> | <span>50 comments</span></div><br/><div><div id="40948735" class="c"><input type="checkbox" id="c-40948735" checked=""/><div class="controls bullet"><span class="by">gumby</span><span>|</span><a href="#40952404">next</a><span>|</span><label class="collapse" for="c-40948735">[-]</label><label class="expand" for="c-40948735">[15 more]</label></div><br/><div class="children"><div class="content">IMHO the best way to think of it (well, it&#x27;s how <i>I</i> have long thought of it) is two lemmas:<p>1 - The compiler has more &quot;fingers&quot; than a human does.  Back when I wrote programs in assembly I would use printout to keep track of what I was doing and for debugging, and so would often put a finger on the paper to mark where a jump was and then go to the destination to see if it matched up, etc.  This process isn&#x27;t at all scalable, so the compiler is inevitably going to do better than I ever could on anything more than something trivial.<p>2 - I know more about the program constraints than I could ever express (much less be bothered expressing) in a HLL.  &quot;All the values will be less than 16&quot; or &quot;I can use this memory location for something else after I&#x27;ve read from it&quot; or who knows what.  So sometimes I can chop stuff out or even rewrite the compiler output locally to speed it up.<p>Also I can only do this for a few architectures...and with modern x86 there are so many variants with all sorts of microoptimization affordances that I can rarely beat the compiler (this is a corollary of lemma 1)</div><br/><div id="40948945" class="c"><input type="checkbox" id="c-40948945" checked=""/><div class="controls bullet"><span class="by">almostgotcaught</span><span>|</span><a href="#40948735">parent</a><span>|</span><a href="#40951466">next</a><span>|</span><label class="collapse" for="c-40948945">[-]</label><label class="expand" for="c-40948945">[11 more]</label></div><br/><div class="children"><div class="content">A compiler is a combinatorial optimizer (think bin-packing). In general, optimizers&#x2F;solvers basically search for the best solution. Most production compilers don&#x27;t have solvers in them, they use heuristics instead, but even the best solvers use tons of heuristics. Naturally a computer will search&#x2F;try heuristics faster and more thoroughly than you but sometimes you can do better because performant searching is all about &quot;knowing where to look&quot;.</div><br/><div id="40950658" class="c"><input type="checkbox" id="c-40950658" checked=""/><div class="controls bullet"><span class="by">BeeOnRope</span><span>|</span><a href="#40948735">root</a><span>|</span><a href="#40948945">parent</a><span>|</span><a href="#40951466">next</a><span>|</span><label class="collapse" for="c-40950658">[-]</label><label class="expand" for="c-40950658">[10 more]</label></div><br/><div class="children"><div class="content">Modern compilers are not doing much searching in general. It&#x27;s mostly apply some feed-forward heuristic to determine whether to apply a transformation or not.<p>I think a slower, search based compiler could have a lot of potential for the hottest parts you&#x27;re willing to spend exorbitant time on a search.</div><br/><div id="40952149" class="c"><input type="checkbox" id="c-40952149" checked=""/><div class="controls bullet"><span class="by">gumby</span><span>|</span><a href="#40948735">root</a><span>|</span><a href="#40950658">parent</a><span>|</span><a href="#40950796">next</a><span>|</span><label class="collapse" for="c-40952149">[-]</label><label class="expand" for="c-40952149">[1 more]</label></div><br/><div class="children"><div class="content">I understand the compiler Microsoft uses to build release versions of Windows, Office etc is like this and can take days to run.</div><br/></div></div><div id="40950796" class="c"><input type="checkbox" id="c-40950796" checked=""/><div class="controls bullet"><span class="by">jonjojojon</span><span>|</span><a href="#40948735">root</a><span>|</span><a href="#40950658">parent</a><span>|</span><a href="#40952149">prev</a><span>|</span><a href="#40950997">next</a><span>|</span><label class="collapse" for="c-40950796">[-]</label><label class="expand" for="c-40950796">[2 more]</label></div><br/><div class="children"><div class="content">I have heard search based compiler optimization called &quot;superoptimization&quot;[1]. It seems interesting, but as far as I know has not seen much industrial use.<p>1. <a href="https:&#x2F;&#x2F;blog.regehr.org&#x2F;archives&#x2F;2578" rel="nofollow">https:&#x2F;&#x2F;blog.regehr.org&#x2F;archives&#x2F;2578</a></div><br/><div id="40952300" class="c"><input type="checkbox" id="c-40952300" checked=""/><div class="controls bullet"><span class="by">kaba0</span><span>|</span><a href="#40948735">root</a><span>|</span><a href="#40950796">parent</a><span>|</span><a href="#40950997">next</a><span>|</span><label class="collapse" for="c-40952300">[-]</label><label class="expand" for="c-40952300">[1 more]</label></div><br/><div class="children"><div class="content">It simply doesn’t scale. You can only superoptimize very short runs of code, nowhere anywhere close to even smaller code bases, let alone big ones.</div><br/></div></div></div></div><div id="40950997" class="c"><input type="checkbox" id="c-40950997" checked=""/><div class="controls bullet"><span class="by">almostgotcaught</span><span>|</span><a href="#40948735">root</a><span>|</span><a href="#40950658">parent</a><span>|</span><a href="#40950796">prev</a><span>|</span><a href="#40951466">next</a><span>|</span><label class="collapse" for="c-40950997">[-]</label><label class="expand" for="c-40950997">[6 more]</label></div><br/><div class="children"><div class="content">&gt; Modern compilers are not doing much searching in general.<p>This is false. Any compiler that does register allocation and instruction scheduling (all of them) is <i>searching</i> for an optimal (or just good enough) solution to an optimization problem.</div><br/><div id="40952050" class="c"><input type="checkbox" id="c-40952050" checked=""/><div class="controls bullet"><span class="by">WalterBright</span><span>|</span><a href="#40948735">root</a><span>|</span><a href="#40950997">parent</a><span>|</span><a href="#40951218">next</a><span>|</span><label class="collapse" for="c-40952050">[-]</label><label class="expand" for="c-40952050">[1 more]</label></div><br/><div class="children"><div class="content">Where things get fun is when two optimizations combine to make things worse. They never tell you about that in compiler class!<p>It&#x27;s like designing a house. If you want the master closet bigger, the master bath has to shrink. Everything is a tradeoff.</div><br/></div></div><div id="40951218" class="c"><input type="checkbox" id="c-40951218" checked=""/><div class="controls bullet"><span class="by">drpixie</span><span>|</span><a href="#40948735">root</a><span>|</span><a href="#40950997">parent</a><span>|</span><a href="#40952050">prev</a><span>|</span><a href="#40951466">next</a><span>|</span><label class="collapse" for="c-40951218">[-]</label><label class="expand" for="c-40951218">[4 more]</label></div><br/><div class="children"><div class="content">Can you give an example?<p>In general, searching any significant space is <i>very</i> slow, applying heuristics is much quicker.</div><br/><div id="40951457" class="c"><input type="checkbox" id="c-40951457" checked=""/><div class="controls bullet"><span class="by">azakai</span><span>|</span><a href="#40948735">root</a><span>|</span><a href="#40951218">parent</a><span>|</span><a href="#40951531">next</a><span>|</span><label class="collapse" for="c-40951457">[-]</label><label class="expand" for="c-40951457">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not sure there is a clear separation between applying heuristics and searching a space. Often in compilers you search a subset of a space using heuristics, and you can adjust those to control how much of the space you cover.<p>For example, here is a pass that reorders WebAssembly globals in the Binaryen optimizer:<p><a href="https:&#x2F;&#x2F;github.com&#x2F;WebAssembly&#x2F;binaryen&#x2F;blob&#x2F;main&#x2F;src&#x2F;passes&#x2F;ReorderGlobals.cpp">https:&#x2F;&#x2F;github.com&#x2F;WebAssembly&#x2F;binaryen&#x2F;blob&#x2F;main&#x2F;src&#x2F;passes...</a><p>We have a simple criteria for the quality of a solution - how big the binary size is with an order - but the space of possible orders is huge (every permutation that keeps every global after its dependencies). What we do is a targeted search of that space using some heuristics using parameters that work well enough and aren&#x27;t too slow in practice.</div><br/><div id="40951595" class="c"><input type="checkbox" id="c-40951595" checked=""/><div class="controls bullet"><span class="by">almostgotcaught</span><span>|</span><a href="#40948735">root</a><span>|</span><a href="#40951457">parent</a><span>|</span><a href="#40951531">next</a><span>|</span><label class="collapse" for="c-40951595">[-]</label><label class="expand" for="c-40951595">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I&#x27;m not sure there is a clear separation between applying heuristics<p>There is and it&#x27;s quite simple: if your heuristic reduces the size of your search space faster than it takes to perform the search (ie try solutions) then you have a real algo on your hands. Otherwise you&#x27;re just searching. This is basically the border between P and NP and it&#x27;s just that in compilers most of the problems are NP hard so none of the heuristics are really that good.</div><br/></div></div></div></div><div id="40951531" class="c"><input type="checkbox" id="c-40951531" checked=""/><div class="controls bullet"><span class="by">almostgotcaught</span><span>|</span><a href="#40948735">root</a><span>|</span><a href="#40951218">parent</a><span>|</span><a href="#40951457">prev</a><span>|</span><a href="#40951466">next</a><span>|</span><label class="collapse" for="c-40951531">[-]</label><label class="expand" for="c-40951531">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t know what you&#x27;re asking for - this isn&#x27;t some kind of controversial topic - any iterative algo that isn&#x27;t polynomial time (or is approximate) is search.<p>In the context of compilers there are many. Look at this block diagram for Chaitin&#x27;s register allocator:<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Register_allocation#Principle_2" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Register_allocation#Principle_...</a><p>That&#x27;s a search because it tries an allocation, possibly incurs a spill, tries again.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="40951466" class="c"><input type="checkbox" id="c-40951466" checked=""/><div class="controls bullet"><span class="by">ashton314</span><span>|</span><a href="#40948735">parent</a><span>|</span><a href="#40948945">prev</a><span>|</span><a href="#40949817">next</a><span>|</span><label class="collapse" for="c-40951466">[-]</label><label class="expand" for="c-40951466">[2 more]</label></div><br/><div class="children"><div class="content">I am going to be the token programming language researcher and say that what you really want is a dependently typed assembly language that your dependently typed higher level language lowers to. One school of thought that has yet to bear fruit in “mainstream“ programming, but gives tantalizing hints of what is possible, is expressing increasing amounts of your programs constraints in the type system, thereby informing the compiler precisely about your intent.</div><br/><div id="40951741" class="c"><input type="checkbox" id="c-40951741" checked=""/><div class="controls bullet"><span class="by">almostgotcaught</span><span>|</span><a href="#40948735">root</a><span>|</span><a href="#40951466">parent</a><span>|</span><a href="#40949817">next</a><span>|</span><label class="collapse" for="c-40951741">[-]</label><label class="expand" for="c-40951741">[1 more]</label></div><br/><div class="children"><div class="content">&gt; want is a dependently typed assembly language<p>Doesn&#x27;t make any sense. The &quot;type constraints&quot; on assembly operands (registers and numbers) is the ISA and thus those constraints are combinatorial not logical</div><br/></div></div></div></div><div id="40949817" class="c"><input type="checkbox" id="c-40949817" checked=""/><div class="controls bullet"><span class="by">albinahlback</span><span>|</span><a href="#40948735">parent</a><span>|</span><a href="#40951466">prev</a><span>|</span><a href="#40952404">next</a><span>|</span><label class="collapse" for="c-40949817">[-]</label><label class="expand" for="c-40949817">[1 more]</label></div><br/><div class="children"><div class="content">While I do think there are a lot of reasons to why one should not write in assembly, time-critical base routines can often benefit a lot from being written in assembly (take GMP&#x27;s mpn-module for instance). However, this puts some constraint on how the code should be formatted (in GMP&#x27;s case, this means that everything the mpz-module does is derived from the mpn-module), which cannot be said for all applications.</div><br/></div></div></div></div><div id="40952404" class="c"><input type="checkbox" id="c-40952404" checked=""/><div class="controls bullet"><span class="by">phire</span><span>|</span><a href="#40948735">prev</a><span>|</span><a href="#40952350">next</a><span>|</span><label class="collapse" for="c-40952404">[-]</label><label class="expand" for="c-40952404">[1 more]</label></div><br/><div class="children"><div class="content"><i>&gt; The dispatch loop takes a single indirect branch to the opcode-specific implementation. This means that the branch will be nigh unpredictable!</i><p>Modern branch predictors can actually predict indirect branches with multiple destinations, because they hash recent branch history into the prediction. The exact same indirect branch will end up with multiple BTB entries, based on previous control flow.<p>I was curious where the threaded code speedup is actually coming from. It&#x27;s possible much of the speedup is coming from eliminating the extra branch back to the dispatch loop. Or maybe the history tracking in the M1&#x27;s branch predictor doesn&#x27;t work well for this type of control flow.<p>So I checked out this code and modified the next macro, adding a dummy branch over a nop, to roughly isolate this factor.<p>On my M1, the extra unconditional branch benchmarks at 1.08 sec for fib, and 1.19 sec for Mandelbrot (all other times were the same).<p>Looks like the speedup is a mixture of the two. Eliminating that extra branch is responsible for about 20-30% of the speedup, and improving prediction on indirect branches is responsible for the other 70-80%</div><br/></div></div><div id="40952350" class="c"><input type="checkbox" id="c-40952350" checked=""/><div class="controls bullet"><span class="by">teo_zero</span><span>|</span><a href="#40952404">prev</a><span>|</span><a href="#40952183">next</a><span>|</span><label class="collapse" for="c-40952350">[-]</label><label class="expand" for="c-40952350">[1 more]</label></div><br/><div class="children"><div class="content">I was intrigued by this paragraph:<p>&gt; Making all of the opcode implementations the same size (padding to the size of the largest opcode implementation with .balign 256), then removing the jump table entirely. This was also slower, also probably because of cache friendliness: the opcode implementations go from 16.6 KiB total to 64 KiB.<p>Probably normalizing the opcode implementations length to the <i>maximum</i> length is not optimal. A possible experiment would be to normalize to the <i>modal</i> length. I would expect most opcodes to be arithmetic or logic operations and to share the same implementation length. The (hopefully few) more complex ones would need a trampoline.<p>Is this a crazy idea?</div><br/></div></div><div id="40952183" class="c"><input type="checkbox" id="c-40952183" checked=""/><div class="controls bullet"><span class="by">rerdavies</span><span>|</span><a href="#40952350">prev</a><span>|</span><a href="#40951412">next</a><span>|</span><label class="collapse" for="c-40952183">[-]</label><label class="expand" for="c-40952183">[1 more]</label></div><br/><div class="children"><div class="content">It would be interesting to see what happens if you turn on profile-guided optimization. This seems like a very good application for PGO.<p>The 518ms profile result for the branch-table load is very peculiar. To my eyes, it suggests that the branch-table load is is incurring cache misses at a furious rate. But I can&#x27;t honestly think of why that would be. On a Pi-4 everything should fit in L2 comfortably. Are you using a low-performance ARM processor like an A53?</div><br/></div></div><div id="40951412" class="c"><input type="checkbox" id="c-40951412" checked=""/><div class="controls bullet"><span class="by">interpunct</span><span>|</span><a href="#40952183">prev</a><span>|</span><a href="#40949453">next</a><span>|</span><label class="collapse" for="c-40951412">[-]</label><label class="expand" for="c-40951412">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I&#x27;ve proven to my satisfaction that writing an interpreter in assembly is both fun and performant!<p>Fun maybe&#x2F;maybe not, but define &quot;performant&quot;.  I might drop into assembly for 1 or 2 orders of magnitude faster for a non-toy project.  Even then, what are my requirements?  What is the bus factor of LuaJIT again?  Try getting support for s390x, or your patch accepted.<p>Look at the speedup of Lua v. LuaJIT (C language VM v. C&#x2F;Lua VM with JIT code gen):<p><a href="https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20180430211146&#x2F;https:&#x2F;&#x2F;luajit.org&#x2F;performance_x86.html" rel="nofollow">https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20180430211146&#x2F;https:&#x2F;&#x2F;luajit.or...</a></div><br/></div></div><div id="40949453" class="c"><input type="checkbox" id="c-40949453" checked=""/><div class="controls bullet"><span class="by">201984</span><span>|</span><a href="#40951412">prev</a><span>|</span><a href="#40950549">next</a><span>|</span><label class="collapse" for="c-40949453">[-]</label><label class="expand" for="c-40949453">[2 more]</label></div><br/><div class="children"><div class="content">Very cool! I enjoy seeing people writing asm, and letting us get the most out of our CPUs.<p>I see you already tried what I thought of, which is getting rid of the jump table and making each instruction handler the same size. Do you think that could still work if you limited each instruction handler to 64 or 32 bytes instead of 256, and then for longer handlers jumped to a larger body of code somewhere else?</div><br/><div id="40951630" class="c"><input type="checkbox" id="c-40951630" checked=""/><div class="controls bullet"><span class="by">abbeyj</span><span>|</span><a href="#40949453">parent</a><span>|</span><a href="#40950549">next</a><span>|</span><label class="collapse" for="c-40951630">[-]</label><label class="expand" for="c-40951630">[1 more]</label></div><br/><div class="children"><div class="content">This is how Dalvik (the old Android Java interpreter) worked, with 64 chosen as the size of an instruction handler.  See <a href="https:&#x2F;&#x2F;wladimir-tm4pda.github.io&#x2F;porting&#x2F;dalvik.html" rel="nofollow">https:&#x2F;&#x2F;wladimir-tm4pda.github.io&#x2F;porting&#x2F;dalvik.html</a> (search for &quot;computed goto&quot;).</div><br/></div></div></div></div><div id="40950549" class="c"><input type="checkbox" id="c-40950549" checked=""/><div class="controls bullet"><span class="by">o11c</span><span>|</span><a href="#40949453">prev</a><span>|</span><a href="#40949706">next</a><span>|</span><label class="collapse" for="c-40950549">[-]</label><label class="expand" for="c-40950549">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Making all of the opcode implementations the same size (padding to the size of the largest opcode implementation with .balign 256), then removing the jump table entirely.<p>Another idea would be to sort the opcodes by size (32-byte, 64-byte, 128-byte, 256-byte - or perhaps +1 to avoid the set-associativity problem below) rather than simply indexing.<p>&gt; This was also slower, also probably because of cache friendliness: the opcode implementations go from 16.6 KiB total to 64 KiB.<p>This is probably cache-unfriendly due to alignment too (associativity limits mean more conflict misses for highly-aligned memory), not just size. Most documentation only talks about this problem regarding the data cache though ...</div><br/></div></div><div id="40949706" class="c"><input type="checkbox" id="c-40949706" checked=""/><div class="controls bullet"><span class="by">JackYoustra</span><span>|</span><a href="#40950549">prev</a><span>|</span><a href="#40951135">next</a><span>|</span><label class="collapse" for="c-40949706">[-]</label><label class="expand" for="c-40949706">[2 more]</label></div><br/><div class="children"><div class="content">Did you try PGO? This post seems like the thing it was built for.</div><br/><div id="40950717" class="c"><input type="checkbox" id="c-40950717" checked=""/><div class="controls bullet"><span class="by">saagarjha</span><span>|</span><a href="#40949706">parent</a><span>|</span><a href="#40951135">next</a><span>|</span><label class="collapse" for="c-40950717">[-]</label><label class="expand" for="c-40950717">[1 more]</label></div><br/><div class="children"><div class="content">How would it help here?</div><br/></div></div></div></div><div id="40951135" class="c"><input type="checkbox" id="c-40951135" checked=""/><div class="controls bullet"><span class="by">256_</span><span>|</span><a href="#40949706">prev</a><span>|</span><a href="#40948808">next</a><span>|</span><label class="collapse" for="c-40951135">[-]</label><label class="expand" for="c-40951135">[3 more]</label></div><br/><div class="children"><div class="content">Why does making the FETCH part of the cycle a macro make it faster? Surely the branch predictor is fine with unconditional immediate branches. What am I missing here?<p>Also, it has jump-to-register immediately after the instruction that sets that register. Wouldn&#x27;t it be faster if it went like:<p><pre><code>  get jmp address
  execute VM opcode
  jmp to next instruction
</code></pre>
So the pipeline can fetch it ahead of time?</div><br/><div id="40952108" class="c"><input type="checkbox" id="c-40952108" checked=""/><div class="controls bullet"><span class="by">phire</span><span>|</span><a href="#40951135">parent</a><span>|</span><a href="#40948808">next</a><span>|</span><label class="collapse" for="c-40952108">[-]</label><label class="expand" for="c-40952108">[2 more]</label></div><br/><div class="children"><div class="content">Modern Out-of-order CPUs (like the M1), they can&#x27;t see branches until far too late.<p>The M1&#x27;s frontend at least 24 instruction past the unconditional branch before the early possible moment it can even see it.<p>So the branch predictor isn&#x27;t just responsible for predicting which way conditional branches go. It must remember where all branches are, and their target so that the front end can follow them with zero cycle delay. This means all branches, including call and return instructions too.<p>Which means that unconditional immediate branches cost about the same as a correctly predicted conditional branch.<p>But that&#x27;s not actually why the fetch has been moved.<p>The other thing to note is that the frontend and backend of a modern CPU are completely disconnected. The frontend doesn&#x27;t even try to get the correct address of an indirect jump from the backend. It always uses the branch predictor to predict the indirect branch.<p>And by inlining, each VM instruction has its own indirect jump, which means it gets different slot in the branch predictor allowing for better predictions.<p>At least that&#x27;s the theory behind threaded code. I&#x27;m unsure how much of this speedup is coming from eliminating the extra unconditional immediate branch and how much is from better prediction of indirect branches.</div><br/><div id="40952414" class="c"><input type="checkbox" id="c-40952414" checked=""/><div class="controls bullet"><span class="by">aengelke</span><span>|</span><a href="#40951135">root</a><span>|</span><a href="#40952108">parent</a><span>|</span><a href="#40948808">next</a><span>|</span><label class="collapse" for="c-40952414">[-]</label><label class="expand" for="c-40952414">[1 more]</label></div><br/><div class="children"><div class="content">Side note: Intel CPUs since Skylake and also recent AMD CPUs (since Zen 3 or so?) store a history for indirect branches. On such processors, using threaded jumps does not really improve performance anymore (I&#x27;ve even seen 1-2% slowdowns on some cores).</div><br/></div></div></div></div></div></div><div id="40948808" class="c"><input type="checkbox" id="c-40948808" checked=""/><div class="controls bullet"><span class="by">jll29</span><span>|</span><a href="#40951135">prev</a><span>|</span><a href="#40949262">next</a><span>|</span><label class="collapse" for="c-40948808">[-]</label><label class="expand" for="c-40948808">[6 more]</label></div><br/><div class="children"><div class="content">This was a good read, thanks.<p>Instead of using unsafe Rust to optimize the interpreter loop, I would prefer to write a transpiler that compiles the source UXN binaries to local CPU binaries, which would not require making code unsafe&#x2F;less readable and would permit further speed enhancements by getting rid of an interpreter loop altogether.</div><br/><div id="40948828" class="c"><input type="checkbox" id="c-40948828" checked=""/><div class="controls bullet"><span class="by">mkeeter</span><span>|</span><a href="#40948808">parent</a><span>|</span><a href="#40949262">next</a><span>|</span><label class="collapse" for="c-40948828">[-]</label><label class="expand" for="c-40948828">[5 more]</label></div><br/><div class="children"><div class="content">This is an interesting idea, but gets tricky if someone writes self-modifying code!<p>There are Uxn instructions which write to RAM; <i>normally</i>, this is used for storing data, but nothing prevents programs from editing their own code as they&#x27;re running.</div><br/><div id="40948983" class="c"><input type="checkbox" id="c-40948983" checked=""/><div class="controls bullet"><span class="by">duped</span><span>|</span><a href="#40948808">root</a><span>|</span><a href="#40948828">parent</a><span>|</span><a href="#40949262">next</a><span>|</span><label class="collapse" for="c-40948983">[-]</label><label class="expand" for="c-40948983">[4 more]</label></div><br/><div class="children"><div class="content">&gt;  but nothing prevents programs from editing their own code as they&#x27;re running<p>On some platforms writing to memory mapped in with PROT_EXEC will trigger a page fault and the process will be killed. In other words, self modifying executables are effectively forbidden by design (the workaround is to unmap the memory, map it as PROT_WRITE, modify, unmap, map it in as PROT_EXEC, and resume execution - which is what JITs do on MacOS, for example).</div><br/><div id="40949876" class="c"><input type="checkbox" id="c-40949876" checked=""/><div class="controls bullet"><span class="by">Hemospectrum</span><span>|</span><a href="#40948808">root</a><span>|</span><a href="#40948983">parent</a><span>|</span><a href="#40949408">next</a><span>|</span><label class="collapse" for="c-40949876">[-]</label><label class="expand" for="c-40949876">[1 more]</label></div><br/><div class="children"><div class="content">The parent comment was referring to programs running inside the UXN virtual machine, which explicitly supports and endorses self-modifying code. Many of the creators&#x27; own programs take advantage of this capability, so any conforming implementation has to find a way to make it work.</div><br/></div></div><div id="40949408" class="c"><input type="checkbox" id="c-40949408" checked=""/><div class="controls bullet"><span class="by">duskwuff</span><span>|</span><a href="#40948808">root</a><span>|</span><a href="#40948983">parent</a><span>|</span><a href="#40949876">prev</a><span>|</span><a href="#40949262">next</a><span>|</span><label class="collapse" for="c-40949408">[-]</label><label class="expand" for="c-40949408">[2 more]</label></div><br/><div class="children"><div class="content">There&#x27;s a better workaround, incidentally, which is to map the same memory to two different address ranges with different access permissions. This allows code in the JIT region to be updated while threads may be running in it.</div><br/><div id="40950726" class="c"><input type="checkbox" id="c-40950726" checked=""/><div class="controls bullet"><span class="by">saagarjha</span><span>|</span><a href="#40948808">root</a><span>|</span><a href="#40949408">parent</a><span>|</span><a href="#40949262">next</a><span>|</span><label class="collapse" for="c-40950726">[-]</label><label class="expand" for="c-40950726">[1 more]</label></div><br/><div class="children"><div class="content">An even better workaround is to make that switch faster.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="40949262" class="c"><input type="checkbox" id="c-40949262" checked=""/><div class="controls bullet"><span class="by">projektfu</span><span>|</span><a href="#40948808">prev</a><span>|</span><a href="#40949779">next</a><span>|</span><label class="collapse" for="c-40949262">[-]</label><label class="expand" for="c-40949262">[2 more]</label></div><br/><div class="children"><div class="content">Good article, brings the data to back it up.<p>Unfortunately, it was hard to read with the monokai.css theme because comments were nearly invisible, and a lot of your information was in comments.  Changing the color from #75715e to #95917e did the trick.  I guess Monokai is for programmers who never read comments.</div><br/><div id="40949419" class="c"><input type="checkbox" id="c-40949419" checked=""/><div class="controls bullet"><span class="by">mkeeter</span><span>|</span><a href="#40949262">parent</a><span>|</span><a href="#40949779">next</a><span>|</span><label class="collapse" for="c-40949419">[-]</label><label class="expand" for="c-40949419">[1 more]</label></div><br/><div class="children"><div class="content">Thanks for the feedback; I tweaked the brightness and pushed the change.</div><br/></div></div></div></div><div id="40949779" class="c"><input type="checkbox" id="c-40949779" checked=""/><div class="controls bullet"><span class="by">tempodox</span><span>|</span><a href="#40949262">prev</a><span>|</span><a href="#40952118">next</a><span>|</span><label class="collapse" for="c-40949779">[-]</label><label class="expand" for="c-40949779">[5 more]</label></div><br/><div class="children"><div class="content">I find this strange:<p><pre><code>  &amp;mut h as *mut _ as *mut _
</code></pre>
What is going on here?</div><br/><div id="40949924" class="c"><input type="checkbox" id="c-40949924" checked=""/><div class="controls bullet"><span class="by">mkeeter</span><span>|</span><a href="#40949779">parent</a><span>|</span><a href="#40949931">next</a><span>|</span><label class="collapse" for="c-40949924">[-]</label><label class="expand" for="c-40949924">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s doing the following cast:<p><pre><code>    &amp;mut DeviceHandle -&gt; *mut DeviceHandle -&gt; *mut c_void
</code></pre>
(with the pointer types being solved for automatically by the compiler)</div><br/></div></div><div id="40949931" class="c"><input type="checkbox" id="c-40949931" checked=""/><div class="controls bullet"><span class="by">dwattttt</span><span>|</span><a href="#40949779">parent</a><span>|</span><a href="#40949924">prev</a><span>|</span><a href="#40949845">next</a><span>|</span><label class="collapse" for="c-40949931">[-]</label><label class="expand" for="c-40949931">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a bit of a song and dance; you can turn a &amp;mut T into a *mut T, and you can cast a *mut T into a *mut anything, but you can&#x27;t do it in one step.</div><br/></div></div><div id="40949845" class="c"><input type="checkbox" id="c-40949845" checked=""/><div class="controls bullet"><span class="by">evrimoztamur</span><span>|</span><a href="#40949779">parent</a><span>|</span><a href="#40949931">prev</a><span>|</span><a href="#40952118">next</a><span>|</span><label class="collapse" for="c-40949845">[-]</label><label class="expand" for="c-40949845">[2 more]</label></div><br/><div class="children"><div class="content">It dereferences a mutable reference to h twice, ignoring its type with _s. I suppose this implies that h is a reference type itself.</div><br/><div id="40950137" class="c"><input type="checkbox" id="c-40950137" checked=""/><div class="controls bullet"><span class="by">muricula</span><span>|</span><a href="#40949779">root</a><span>|</span><a href="#40949845">parent</a><span>|</span><a href="#40952118">next</a><span>|</span><label class="collapse" for="c-40950137">[-]</label><label class="expand" for="c-40950137">[1 more]</label></div><br/><div class="children"><div class="content">No dereferences, just casts. It shouldn&#x27;t generate any loads&#x2F;reads from memory.</div><br/></div></div></div></div></div></div><div id="40952118" class="c"><input type="checkbox" id="c-40952118" checked=""/><div class="controls bullet"><span class="by">kosolam</span><span>|</span><a href="#40949779">prev</a><span>|</span><a href="#40951052">next</a><span>|</span><label class="collapse" for="c-40952118">[-]</label><label class="expand" for="c-40952118">[1 more]</label></div><br/><div class="children"><div class="content">I would love to understand better this uxn thing? Is it some academic experiment or it has real world applications? What’s the deal with the additional return stack?</div><br/></div></div><div id="40949283" class="c"><input type="checkbox" id="c-40949283" checked=""/><div class="controls bullet"><span class="by">lilyball</span><span>|</span><a href="#40951052">prev</a><span>|</span><a href="#40948685">next</a><span>|</span><label class="collapse" for="c-40949283">[-]</label><label class="expand" for="c-40949283">[1 more]</label></div><br/><div class="children"><div class="content">Does the compiler do anything differently if you stick to Rust but change the dispatch implementation to be an #[inline] fn next() that you put at the end of each opcode?</div><br/></div></div><div id="40948685" class="c"><input type="checkbox" id="c-40948685" checked=""/><div class="controls bullet"><span class="by">0x3444ac53</span><span>|</span><a href="#40949283">prev</a><span>|</span><a href="#40952239">next</a><span>|</span><label class="collapse" for="c-40948685">[-]</label><label class="expand" for="c-40948685">[1 more]</label></div><br/><div class="children"><div class="content">I was overjoyed to open this and find a reference to 100r and UXN</div><br/></div></div><div id="40952239" class="c"><input type="checkbox" id="c-40952239" checked=""/><div class="controls bullet"><span class="by">Validark</span><span>|</span><a href="#40948685">prev</a><span>|</span><a href="#40949364">next</a><span>|</span><label class="collapse" for="c-40952239">[-]</label><label class="expand" for="c-40952239">[2 more]</label></div><br/><div class="children"><div class="content">I wish you wouldn&#x27;t broadcast the sentiment contained in the first paragraph. Compilers lack the ability to consistently perform many basic optimizations to an embarrassing extent. Including even the ones you would think would be the first optimizations you&#x27;d implement when writing a compiler. Open up Godbolt and tell me if you still think the compiler knows best. I try to submit at least one issue to LLVM every time I look at the assembly it gives me. I say &quot;try to&quot; because sometimes it&#x27;s too much to deal with.<p>And by the way, probably the absolute worst things the compiler does are the &quot;smart&quot; things. I write my code knowing what the emit should look like, and the compiler sometimes thinks it has a better idea than how I wrote the code and makes the emit a lot more convoluted and slower than it would be if it just did what I said. Actually, I do know the machine decently well, thank you.<p>Saying &quot;centuries of engineering&quot; is misleading. A lot of those centuries are people arguing about theoretical optimizations of dubious value while we still haven&#x27;t even finished on the most basic optimizations that are obviously beneficial.<p>The second paragraph making it sound all mysterious that compilers are even more awful at interpreters than normal code really speaks to a complete lack of exposure to the subject matter. This stuff is only esoteric because you couldn&#x27;t be bothered to look at godbolt.org. Which is totally fine by the way, just don&#x27;t go telling me how high quality compilers are if you&#x27;ve never even looked.<p>That would be like me telling web developers that Dreamweaver produces phenomenal HTML and CSS, without ever looking at what it emits.<p>Sorry for the rant but it just bothers me how much praise is heaped upon compilers like they are some kind of gift from God, forged by monks, wizards, and unrivaled geniuses. A compiler is just a tool. There is no magic.</div><br/><div id="40952549" class="c"><input type="checkbox" id="c-40952549" checked=""/><div class="controls bullet"><span class="by">pjmlp</span><span>|</span><a href="#40952239">parent</a><span>|</span><a href="#40949364">next</a><span>|</span><label class="collapse" for="c-40952549">[-]</label><label class="expand" for="c-40952549">[1 more]</label></div><br/><div class="children"><div class="content">&quot;Any sufficiently advanced technology is indistinguishable from magic.&quot;<p>When people call themselves engineers, without placing their feets on an engineering school, with compiler development degrees, rather a six weeks bootcamp, their compilers feel like a sufficient advanced technology.</div><br/></div></div></div></div><div id="40949364" class="c"><input type="checkbox" id="c-40949364" checked=""/><div class="controls bullet"><span class="by">ajbt200128</span><span>|</span><a href="#40952239">prev</a><span>|</span><label class="collapse" for="c-40949364">[-]</label><label class="expand" for="c-40949364">[3 more]</label></div><br/><div class="children"><div class="content">&gt; &#x2F;&#x2F; SAFETY: do you trust me?<p>No.<p>Have you seen the safer-ffi crate? Then you won&#x27;t have to commit the deadly sin of writing unsafe Rust</div><br/><div id="40949513" class="c"><input type="checkbox" id="c-40949513" checked=""/><div class="controls bullet"><span class="by">Wowfunhappy</span><span>|</span><a href="#40949364">parent</a><span>|</span><a href="#40949715">next</a><span>|</span><label class="collapse" for="c-40949513">[-]</label><label class="expand" for="c-40949513">[1 more]</label></div><br/><div class="children"><div class="content">But this is an entry point to assembly code. It&#x27;s inherently unsafe.</div><br/></div></div><div id="40949715" class="c"><input type="checkbox" id="c-40949715" checked=""/><div class="controls bullet"><span class="by">gpm</span><span>|</span><a href="#40949364">parent</a><span>|</span><a href="#40949513">prev</a><span>|</span><label class="collapse" for="c-40949715">[-]</label><label class="expand" for="c-40949715">[1 more]</label></div><br/><div class="children"><div class="content">&gt; safer-ffi crate<p>It looks to me like that crate is supposed to help with exposing rust functions to C safely, not calling foreign functions in foreign code safely. Am I missing something?</div><br/></div></div></div></div></div></div></div></div></div></body></html>