<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1712307649518" as="style"/><link rel="stylesheet" href="styles.css?v=1712307649518"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://arxiv.org/abs/2404.02575">Language models as compilers: Simulating pseudocode execution</a> <span class="domain">(<a href="https://arxiv.org">arxiv.org</a>)</span></div><div class="subtext"><span>milliondreams</span> | <span>26 comments</span></div><br/><div><div id="39937161" class="c"><input type="checkbox" id="c-39937161" checked=""/><div class="controls bullet"><span class="by">pkoird</span><span>|</span><a href="#39939275">next</a><span>|</span><label class="collapse" for="c-39937161">[-]</label><label class="expand" for="c-39937161">[14 more]</label></div><br/><div class="children"><div class="content">Any sufficiently advanced LLM is indistinguishable from Prolog.<p>I half-jest but I envision the direction of LLM research to head towards a parser-oriented setup where LLMs merely extract the entities and relations and the actual logic is done by a logical engine such as Prolog.</div><br/><div id="39939193" class="c"><input type="checkbox" id="c-39939193" checked=""/><div class="controls bullet"><span class="by">thesz</span><span>|</span><a href="#39937161">parent</a><span>|</span><a href="#39938252">next</a><span>|</span><label class="collapse" for="c-39939193">[-]</label><label class="expand" for="c-39939193">[2 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Cyc#MathCraft" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Cyc#MathCraft</a><p>Quote:<p><pre><code>  One Cyc application aims to help students doing math at a 6th grade level, helping them much more deeply understand that subject matter... Unlike almost all other educational software, where the computer plays the role of the teacher, this application of Cyc, called MathCraft, has Cyc play the role of a fellow student who is always slightly more confused than you, the user, are about the subject.
</code></pre>
This is from 2017. I haven&#x27;t seen anything like this using LMs in 2017 and I suspect it is still hard for LLMs today.<p>Cyc is the huge reasoning engine. You can call it Prolog, if you want. I won&#x27;t.</div><br/><div id="39939874" class="c"><input type="checkbox" id="c-39939874" checked=""/><div class="controls bullet"><span class="by">ogogmad</span><span>|</span><a href="#39937161">root</a><span>|</span><a href="#39939193">parent</a><span>|</span><a href="#39938252">next</a><span>|</span><label class="collapse" for="c-39939874">[-]</label><label class="expand" for="c-39939874">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I suspect it is still hard for LLMs<p>I just gave it to Claude: <a href="https:&#x2F;&#x2F;imgur.com&#x2F;a&#x2F;fQQOy1d" rel="nofollow">https:&#x2F;&#x2F;imgur.com&#x2F;a&#x2F;fQQOy1d</a></div><br/></div></div></div></div><div id="39938252" class="c"><input type="checkbox" id="c-39938252" checked=""/><div class="controls bullet"><span class="by">lachlan_gray</span><span>|</span><a href="#39937161">parent</a><span>|</span><a href="#39939193">prev</a><span>|</span><a href="#39938802">next</a><span>|</span><label class="collapse" for="c-39938252">[-]</label><label class="expand" for="c-39938252">[1 more]</label></div><br/><div class="children"><div class="content">You might enjoy parts of this interview with Stephen Wolfram<p><a href="https:&#x2F;&#x2F;m.youtube.com&#x2F;watch?v=PdE-waSx-d8" rel="nofollow">https:&#x2F;&#x2F;m.youtube.com&#x2F;watch?v=PdE-waSx-d8</a><p>He’s very much on this kind of beat. In general I have a feeling that there are orders of magnitude to gain by successfully applying computer science to “language algorithms”.<p>Feels like we are exploring very narrow paths of computations that can be performed with language. Like we have an x86 cpu and we are building pocket calculators. So much untapped<p>Re prolog I had a similar intuition at some point and tried to make a stack based programming language that uses a language model as a kind of control&#x2F;logic unit<p><a href="https:&#x2F;&#x2F;github.com&#x2F;LachlanGray&#x2F;silas">https:&#x2F;&#x2F;github.com&#x2F;LachlanGray&#x2F;silas</a><p>I was missing a bunch of cs background at the time so I didn’t get very far, but I feel like there’s a lot to be done for this kind of thing</div><br/></div></div><div id="39938802" class="c"><input type="checkbox" id="c-39938802" checked=""/><div class="controls bullet"><span class="by">westoncb</span><span>|</span><a href="#39937161">parent</a><span>|</span><a href="#39938252">prev</a><span>|</span><a href="#39939471">next</a><span>|</span><label class="collapse" for="c-39938802">[-]</label><label class="expand" for="c-39938802">[1 more]</label></div><br/><div class="children"><div class="content">I think this is an important perspective. It helps clarify prompting as well because, used in a certain way, they are effectively natural language specification of constraints which have the effect of &#x27;partially configuring&#x27; the network so that its inference selects from the configuration space of its still free params<p>For example, if you tell it to reply in JSON (and it obeys), you&#x27;ve just constrained its search space in a particular way. There is space for very interesting informal programming that can be done from this perspective, setting up constraints and then allowing inference to solve within them. I&#x27;ve been using this heavily.<p>When I was first getting deep into LLM stuff a few months ago and contemplating latent space my main characterization was that much of its high level behavior can be usefully grappled with by viewing it as a kind of &#x27;learned geometric prolog&#x27;.<p>I did a bunch of illustrations and talked about some of these ideas here if anyone&#x27;s curious: <a href="https:&#x2F;&#x2F;x.com&#x2F;Westoncb&#x2F;status&#x2F;1757910205478703277" rel="nofollow">https:&#x2F;&#x2F;x.com&#x2F;Westoncb&#x2F;status&#x2F;1757910205478703277</a>  (I think I mostly dropped the prolog terminology in that presentation because not everyone knows about it)</div><br/></div></div><div id="39939471" class="c"><input type="checkbox" id="c-39939471" checked=""/><div class="controls bullet"><span class="by">pjmlp</span><span>|</span><a href="#39937161">parent</a><span>|</span><a href="#39938802">prev</a><span>|</span><a href="#39939572">next</a><span>|</span><label class="collapse" for="c-39939471">[-]</label><label class="expand" for="c-39939471">[1 more]</label></div><br/><div class="children"><div class="content">The moment they are fully there, just like an executable generated from a Prolog compiler, eventually it is time to realize programing is no more, except for the selected few ones from big corps that create LLM compilers.</div><br/></div></div><div id="39937857" class="c"><input type="checkbox" id="c-39937857" checked=""/><div class="controls bullet"><span class="by">gpm</span><span>|</span><a href="#39937161">parent</a><span>|</span><a href="#39939572">prev</a><span>|</span><a href="#39937439">next</a><span>|</span><label class="collapse" for="c-39937857">[-]</label><label class="expand" for="c-39937857">[4 more]</label></div><br/><div class="children"><div class="content">I envision a thread of research in the exact opposite direction. Take a logic program&#x2F;theorem&#x2F;database query&#x2F;... and use a LLM to guide a search for a solution&#x2F;proof&#x2F;query plan&#x2F;...</div><br/><div id="39939715" class="c"><input type="checkbox" id="c-39939715" checked=""/><div class="controls bullet"><span class="by">ithkuil</span><span>|</span><a href="#39937161">root</a><span>|</span><a href="#39937857">parent</a><span>|</span><a href="#39938091">next</a><span>|</span><label class="collapse" for="c-39939715">[-]</label><label class="expand" for="c-39939715">[1 more]</label></div><br/><div class="children"><div class="content">I wonder if the problem that LLMs solved was not the lack of &quot;intelligence&quot; of logic driven systems but the lack of a particular intelligence that is so crucial for is to make effective use of the interaction with such tools, namely the ability to actually understand our natural language.<p>That feature by itself is not enough, but can be a very effective glue to be used with other components of an intelligent system. The analogy with the human brain would be the broca area vs. the rest of the brain.<p>Now, there are open questions about whether the _architecture_ that underpins the LLMs is also good enough to be used as a substrate for other functions and what&#x27;s the most effective way for having these different components of the system communicate between each other.<p>The analogy with the human brain can guide us (as well as lead us astray), in that our brain, like biological systems often do, re-purposes the basic building blocks to create different subsystems.<p>It&#x27;s not clear to me at which level we&#x27;ll find the most effective re-purposable building blocks.<p>It&#x27;s easy to try (and people do) to use the top-level LLM system as such a building block and have it produce plans, connect it to external systems that feed information back and have it iterate again on it (ab)using it&#x27;s language processing as an API with the environment.<p>The human analogy of that is when we use external tools to extend our cognitive capacity, like when we do arithmetic using pencil and paper or when we scribble some notes to help us think.<p>I think this level is useful and real but I wonder if we also need to give more power to some lower levels too.<p>Granted, some of that &quot;power&quot; can already be emerging during the training of the LLMs but I wonder if some more specialized blocks might enhance the effectiveness</div><br/></div></div><div id="39938091" class="c"><input type="checkbox" id="c-39938091" checked=""/><div class="controls bullet"><span class="by">winwang</span><span>|</span><a href="#39937161">root</a><span>|</span><a href="#39937857">parent</a><span>|</span><a href="#39939715">prev</a><span>|</span><a href="#39937439">next</a><span>|</span><label class="collapse" for="c-39938091">[-]</label><label class="expand" for="c-39938091">[2 more]</label></div><br/><div class="children"><div class="content">LLM the Ultimate Heuristic?</div><br/><div id="39938176" class="c"><input type="checkbox" id="c-39938176" checked=""/><div class="controls bullet"><span class="by">kevindamm</span><span>|</span><a href="#39937161">root</a><span>|</span><a href="#39938091">parent</a><span>|</span><a href="#39937439">next</a><span>|</span><label class="collapse" for="c-39938176">[-]</label><label class="expand" for="c-39938176">[1 more]</label></div><br/><div class="children"><div class="content">It would be convenient if true.  I&#x27;m a little skeptical it will go that far, but at the same time humans seem to better understand a tricky problem after an internal monologue about it or a quick conversation with a rubber ducky.. so maybe?</div><br/></div></div></div></div></div></div><div id="39937439" class="c"><input type="checkbox" id="c-39937439" checked=""/><div class="controls bullet"><span class="by">pyinstallwoes</span><span>|</span><a href="#39937161">parent</a><span>|</span><a href="#39937857">prev</a><span>|</span><a href="#39937428">next</a><span>|</span><label class="collapse" for="c-39937439">[-]</label><label class="expand" for="c-39937439">[1 more]</label></div><br/><div class="children"><div class="content">Hehe, this was the exact thinking going across my mind in considering underlying architecture for a LLM OS&#x2F;Word processor that was self aware of the documents across a project for consistency.</div><br/></div></div><div id="39937428" class="c"><input type="checkbox" id="c-39937428" checked=""/><div class="controls bullet"><span class="by">nickpsecurity</span><span>|</span><a href="#39937161">parent</a><span>|</span><a href="#39937439">prev</a><span>|</span><a href="#39939739">next</a><span>|</span><label class="collapse" for="c-39937428">[-]</label><label class="expand" for="c-39937428">[1 more]</label></div><br/><div class="children"><div class="content">In truth, I thought it would be a great idea to train them on turning English and code into formal specs and logic language. Then, we could use all our tools in those areas work from there.<p>Combining LLM’s with rewriting logic, like Maude or K Framework, would be the most, powerful option. The rewriting tools plus LLM’s could probably rapidly develop static analyzers and code porting tools.</div><br/></div></div></div></div><div id="39939275" class="c"><input type="checkbox" id="c-39939275" checked=""/><div class="controls bullet"><span class="by">Voultapher</span><span>|</span><a href="#39937161">prev</a><span>|</span><a href="#39935753">next</a><span>|</span><label class="collapse" for="c-39939275">[-]</label><label class="expand" for="c-39939275">[1 more]</label></div><br/><div class="children"><div class="content">Non deterministic compilers, yay! Where do I sign up?<p>In more seriousness, miscompilations or in general unexpected behavior caused by layers below you are expensive to find and fix. I think LLMs have a long way to go before such use cases seem appealing to me.</div><br/></div></div><div id="39935753" class="c"><input type="checkbox" id="c-39935753" checked=""/><div class="controls bullet"><span class="by">Mathnerd314</span><span>|</span><a href="#39939275">prev</a><span>|</span><a href="#39937989">next</a><span>|</span><label class="collapse" for="c-39935753">[-]</label><label class="expand" for="c-39935753">[1 more]</label></div><br/><div class="children"><div class="content">The phase 2 prompt is complete, but the phase 3 prompt&#x27;s initial part ends in &quot;When constructing the main function, ...&quot;, and no mention of random seeds, so I guess this paper is not reproducible at all.</div><br/></div></div><div id="39937989" class="c"><input type="checkbox" id="c-39937989" checked=""/><div class="controls bullet"><span class="by">jumploops</span><span>|</span><a href="#39935753">prev</a><span>|</span><a href="#39935497">next</a><span>|</span><label class="collapse" for="c-39937989">[-]</label><label class="expand" for="c-39937989">[2 more]</label></div><br/><div class="children"><div class="content">English is terribly imprecise, so it makes sense to use pseudo instructions to improve the bounds&#x2F;outcome of a language model’s execution.<p>I do wonder how long hacks like this will be necessary; as it stands, many of these prompting techniques are essentially artificially expanding the input to enhance reasoning ability (increasing tokens, thus increasing chance of success).</div><br/><div id="39938763" class="c"><input type="checkbox" id="c-39938763" checked=""/><div class="controls bullet"><span class="by">nimbleal</span><span>|</span><a href="#39937989">parent</a><span>|</span><a href="#39935497">next</a><span>|</span><label class="collapse" for="c-39938763">[-]</label><label class="expand" for="c-39938763">[1 more]</label></div><br/><div class="children"><div class="content">I hope there are more models trained on more precise inputs going forward. I understand that natural language feels the most futuristic but while it has the lowest barrier to entry it’s not only imprecise but also slow. Visual approaches (for example control nets in stable diffusion, image as input in Chat GPT, though both of these are somewhat bolted on), 2D semi-natural languages all merit further inquiry.<p>Another (and perhaps the ultimate) possibility is to have some way —- perhaps through simulations —- to directly expose the model to the problem, rather than having a human&#x2F;natural language intermediary.</div><br/></div></div></div></div><div id="39935497" class="c"><input type="checkbox" id="c-39935497" checked=""/><div class="controls bullet"><span class="by">spxneo</span><span>|</span><a href="#39937989">prev</a><span>|</span><a href="#39939726">next</a><span>|</span><label class="collapse" for="c-39935497">[-]</label><label class="expand" for="c-39935497">[1 more]</label></div><br/><div class="children"><div class="content">This seems quite promising. Using pseudo-code as an intermediary step isn&#x27;t new but seems like this takes it a bit further. Will need to see some code and test it out.</div><br/></div></div><div id="39939726" class="c"><input type="checkbox" id="c-39939726" checked=""/><div class="controls bullet"><span class="by">lionkor</span><span>|</span><a href="#39935497">prev</a><span>|</span><a href="#39936679">next</a><span>|</span><label class="collapse" for="c-39939726">[-]</label><label class="expand" for="c-39939726">[1 more]</label></div><br/><div class="children"><div class="content">How is it better than a compiler written by people?</div><br/></div></div><div id="39936679" class="c"><input type="checkbox" id="c-39936679" checked=""/><div class="controls bullet"><span class="by">inciampati</span><span>|</span><a href="#39939726">prev</a><span>|</span><a href="#39937551">next</a><span>|</span><label class="collapse" for="c-39936679">[-]</label><label class="expand" for="c-39936679">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s going to be really fascinating to see this applied instead of chain of thought and other kinds of reasoning approaches, because it&#x27;s generic. It should in principle work on every kind of LLM.</div><br/></div></div><div id="39937551" class="c"><input type="checkbox" id="c-39937551" checked=""/><div class="controls bullet"><span class="by">skeledrew</span><span>|</span><a href="#39936679">prev</a><span>|</span><a href="#39937918">next</a><span>|</span><label class="collapse" for="c-39937551">[-]</label><label class="expand" for="c-39937551">[1 more]</label></div><br/><div class="children"><div class="content">Seeing this makes me want to reactivate an old project[0]. Been thinking more and more that LLMs could give it superpowers.<p>[0] <a href="https:&#x2F;&#x2F;pypi.org&#x2F;project&#x2F;neulang&#x2F;" rel="nofollow">https:&#x2F;&#x2F;pypi.org&#x2F;project&#x2F;neulang&#x2F;</a></div><br/></div></div><div id="39937918" class="c"><input type="checkbox" id="c-39937918" checked=""/><div class="controls bullet"><span class="by">m3kw9</span><span>|</span><a href="#39937551">prev</a><span>|</span><label class="collapse" for="c-39937918">[-]</label><label class="expand" for="c-39937918">[3 more]</label></div><br/><div class="children"><div class="content">If you train a LLM to compile, you probably also want to set the randomness to zero, if that is the case you’ve just “brute forced” an actual compiler</div><br/><div id="39938844" class="c"><input type="checkbox" id="c-39938844" checked=""/><div class="controls bullet"><span class="by">danielmarkbruce</span><span>|</span><a href="#39937918">parent</a><span>|</span><label class="collapse" for="c-39938844">[-]</label><label class="expand" for="c-39938844">[2 more]</label></div><br/><div class="children"><div class="content">you don&#x27;t want a creative compiler?</div><br/><div id="39939870" class="c"><input type="checkbox" id="c-39939870" checked=""/><div class="controls bullet"><span class="by">fxcao</span><span>|</span><a href="#39937918">root</a><span>|</span><a href="#39938844">parent</a><span>|</span><label class="collapse" for="c-39939870">[-]</label><label class="expand" for="c-39939870">[1 more]</label></div><br/><div class="children"><div class="content">In this specific use case I think we should avoid any creative aspect in the behavior of the LLM. Compiling might look like a &quot;word-for-word&quot; translation in a certain manner. Isn&#x27;t it ?</div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>