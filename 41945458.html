<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1730192458014" as="style"/><link rel="stylesheet" href="styles.css?v=1730192458014"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/FrigadeHQ/trench">Show HN: Trench – Open-source analytics infrastructure</a> <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>pancomplex</span> | <span>26 comments</span></div><br/><div><div id="41974755" class="c"><input type="checkbox" id="c-41974755" checked=""/><div class="controls bullet"><span class="by">bosky101</span><span>|</span><a href="#41975670">next</a><span>|</span><label class="collapse" for="c-41974755">[-]</label><label class="expand" for="c-41974755">[3 more]</label></div><br/><div class="children"><div class="content">1) Appreciate the single image to get started, but am particularly curious how you handle different events of a new user going to different nodes.<p>2) any admin interface or just the rest API?<p>3) a little bit on the clickhouse table and engine choices?<p>4) stats on Ingesting and querying tbe same time<p>5) node doesn&#x27;t support the clickhouse TCP interface. This was a major bottleneck even with batching of 50k events (or 30 secs whichever comes first)<p>6) CH indexes?<p>7) how are events partitioned to a Kafka partition? By userId? Any assumptions on minimum fields<p>Will try porting our in-house marketing automation backend (posthog frontend compatible) to this and see how it goes (150M+ events per day)<p>Kudos all around. Love all 3 of your technology choices.</div><br/><div id="41975168" class="c"><input type="checkbox" id="c-41975168" checked=""/><div class="controls bullet"><span class="by">pancomplex</span><span>|</span><a href="#41974755">parent</a><span>|</span><a href="#41975670">next</a><span>|</span><label class="collapse" for="c-41975168">[-]</label><label class="expand" for="c-41975168">[2 more]</label></div><br/><div class="children"><div class="content">Thank you!<p>1) All data is partitioned based on the &quot;instanceId&quot; of events (see `instanceId` here: <a href="https:&#x2F;&#x2F;docs.trench.dev&#x2F;api-reference&#x2F;events-create" rel="nofollow">https:&#x2F;&#x2F;docs.trench.dev&#x2F;api-reference&#x2F;events-create</a>). Instance IDs are typically a logically meaningful way of separating users (such as by company&#x2F;team&#x2F;etc.) that allows for sharding the data across nodes.<p>2) Yes, this the number 1 thing on our roadmap right now (if anyone is interested in helping build this, please reach out!)<p>3) We&#x27;re using the Kafka engine in ClickHouse for throttling the ingestion of events. It&#x27;s partitioned by instanceId (see #1) for scaling&#x2F;fast queries over similar events.<p>4) My benchmarks in production showed a single EC2 instance (16 cores &#x2F; 32 gb ram) barely working at 1000+ inserts &#x2F; second with roughly the same amount of queries per second. Load averages 0.91, 0.89 0.9. This was in stark contrast to our AWS Postgres cluster which continued to hit 90%+ CPU and low memory with 80 ACUs, before we finished the migration to Trench.<p>5) We seemed to solve this by running individual Node processes on every core (16 in parallel). Was the limit you saw caused by ClickHouse&#x27;s inbound HTTP interface?<p>6) Right now the system uses just a default MergeTree ordered by instanceId, useId, timestamp. This works really well for doing queries across the same user or instance, especially when generating timeseries graphs.<p>7) I am still trying to figure out the best Kafka partitioning scheme. userId seems to be the best for avoiding hot partitions. Curious if you have any experience with this?<p>Let us know how the migration goes and feel free to connect with me (christian@trench.dev).</div><br/><div id="41979096" class="c"><input type="checkbox" id="c-41979096" checked=""/><div class="controls bullet"><span class="by">bosky101</span><span>|</span><a href="#41974755">root</a><span>|</span><a href="#41975168">parent</a><span>|</span><a href="#41975670">next</a><span>|</span><label class="collapse" for="c-41979096">[-]</label><label class="expand" for="c-41979096">[1 more]</label></div><br/><div class="children"><div class="content">Not sure of the CH Kafka engine but generally I think you should partition by userId.<p>Because the next step would be trying to run some cron for a user or event based trigger based on the events.<p>And the only way to avoid multiple machines doing the same work &#x2F; sending the same comms - would be to push all users events to a partition. This way with multiple workers you don&#x27;t have the risk of duplicate processing.</div><br/></div></div></div></div></div></div><div id="41975670" class="c"><input type="checkbox" id="c-41975670" checked=""/><div class="controls bullet"><span class="by">hitradostava</span><span>|</span><a href="#41974755">prev</a><span>|</span><a href="#41974751">next</a><span>|</span><label class="collapse" for="c-41975670">[-]</label><label class="expand" for="c-41975670">[3 more]</label></div><br/><div class="children"><div class="content">Looks interesting, we solved this problem with Kinesis Firehose, S3 and Athena. Pricing is cheap, you can run any arbitrary SQL query and there is zero infrastructure to maintain.</div><br/><div id="41979061" class="c"><input type="checkbox" id="c-41979061" checked=""/><div class="controls bullet"><span class="by">bosky101</span><span>|</span><a href="#41975670">parent</a><span>|</span><a href="#41974751">next</a><span>|</span><label class="collapse" for="c-41979061">[-]</label><label class="expand" for="c-41979061">[2 more]</label></div><br/><div class="children"><div class="content">Storing small events in s3 can explode costs quickly.<p>At 1M events&#x2F;day that&#x27;s $7.5&#x2F;day. Decent<p>At 15M, $75&#x2F;day<p>Cost for 150 million S3 PUT requests per day of 25KB each would be $750&#x2F;day, assuming no extra data transfer charges.<p>With clickhouse you won&#x27;t get charged per read&#x2F;write</div><br/><div id="41980305" class="c"><input type="checkbox" id="c-41980305" checked=""/><div class="controls bullet"><span class="by">hitradostava</span><span>|</span><a href="#41975670">root</a><span>|</span><a href="#41979061">parent</a><span>|</span><a href="#41974751">next</a><span>|</span><label class="collapse" for="c-41980305">[-]</label><label class="expand" for="c-41980305">[1 more]</label></div><br/><div class="children"><div class="content">Kinesis supports buffering - up to 900 seconds or 128mb. So you are way out on your cost estimations. Over time queries can start costing more due to S3 Requests, but regular spark runs to combine small files solves that.</div><br/></div></div></div></div></div></div><div id="41974751" class="c"><input type="checkbox" id="c-41974751" checked=""/><div class="controls bullet"><span class="by">Attummm</span><span>|</span><a href="#41975670">prev</a><span>|</span><a href="#41976535">next</a><span>|</span><label class="collapse" for="c-41974751">[-]</label><label class="expand" for="c-41974751">[6 more]</label></div><br/><div class="children"><div class="content">Looks great, but what is missing for me are use cases.<p>Why should I use it?
What are the unique selling points of your project?</div><br/><div id="41974909" class="c"><input type="checkbox" id="c-41974909" checked=""/><div class="controls bullet"><span class="by">pancomplex</span><span>|</span><a href="#41974751">parent</a><span>|</span><a href="#41976535">next</a><span>|</span><label class="collapse" for="c-41974909">[-]</label><label class="expand" for="c-41974909">[5 more]</label></div><br/><div class="children"><div class="content">I looked around, but all the open source analytics projects I could find were bloated with all kinds of UI and unnecessary code paths. They also all seemed to use row-based RDMS as the data backbone (vs columnar stores like ClickHouse). I was looking for a backend-only solution that we could shape for our product use case that could scale.<p>So TLDR, if you&#x27;re at a smaller scale (&lt;1M MAUs), you probably will be fine just using a table in MySQL or Postgres. If you have a lot of traffic and users, you will need something like Trench that uses Kafka and ClickHouse.</div><br/><div id="41975786" class="c"><input type="checkbox" id="c-41975786" checked=""/><div class="controls bullet"><span class="by">Attummm</span><span>|</span><a href="#41974751">root</a><span>|</span><a href="#41974909">parent</a><span>|</span><a href="#41976535">next</a><span>|</span><label class="collapse" for="c-41975786">[-]</label><label class="expand" for="c-41975786">[4 more]</label></div><br/><div class="children"><div class="content">You are selling the underlying technologies(Kafka&#x2F;Clickhouse).<p>I&#x27;m interested in your project can do for me, my project(s), team&#x2F;company. There is a reason that most of the internet still uses PHP and old technologies. Because they focused not on the latest tech but on solving problems for others.<p>The project looks cool, but tell us the usecases.</div><br/><div id="41977886" class="c"><input type="checkbox" id="c-41977886" checked=""/><div class="controls bullet"><span class="by">mind-blight</span><span>|</span><a href="#41974751">root</a><span>|</span><a href="#41975786">parent</a><span>|</span><a href="#41976796">next</a><span>|</span><label class="collapse" for="c-41977886">[-]</label><label class="expand" for="c-41977886">[1 more]</label></div><br/><div class="children"><div class="content">It seems pretty clearly spelled out. If you have enough traffic that an events table is slowing down your postgres instance, you can easily set this up as a service to offload the events table. The author says &lt;1 million MAUs, and you probably don&#x27;t need this.<p>It&#x27;s built on tech known for handling very large amounts of traffic, which answers the how after the what.</div><br/></div></div><div id="41976796" class="c"><input type="checkbox" id="c-41976796" checked=""/><div class="controls bullet"><span class="by">dfltr</span><span>|</span><a href="#41974751">root</a><span>|</span><a href="#41975786">parent</a><span>|</span><a href="#41977886">prev</a><span>|</span><a href="#41976535">next</a><span>|</span><label class="collapse" for="c-41976796">[-]</label><label class="expand" for="c-41976796">[2 more]</label></div><br/><div class="children"><div class="content">Use case #1: You have a problem table (e.g. a high-volume events table) that grows non-linearly as your business starts to scale up. A queue + columnar store package like Trench moves the problem table out to a system better equipped to deal with it and lets your DB server handle its relational business in relative peace and quiet.</div><br/><div id="41978301" class="c"><input type="checkbox" id="c-41978301" checked=""/><div class="controls bullet"><span class="by">Attummm</span><span>|</span><a href="#41974751">root</a><span>|</span><a href="#41976796">parent</a><span>|</span><a href="#41976535">next</a><span>|</span><label class="collapse" for="c-41978301">[-]</label><label class="expand" for="c-41978301">[1 more]</label></div><br/><div class="children"><div class="content">Maybe I wasn&#x27;t clear enough but my questions have been rhetorical. They were not for me. If one starts stating technologies, it is akin to describing the individual ingredients of a sandwich.<p>The question remains: Why choose Trench over just using Kafka and Clickhouse or any other message queue and columnar database &#x2F; big data base?<p>If the goal of the post and the landing website is to entice people to use the tool, then answering these questions is important. If what is being discussed seems obvious, then who is the target demographic? Because they already know the space, use alternatives or have built their own.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="41976535" class="c"><input type="checkbox" id="c-41976535" checked=""/><div class="controls bullet"><span class="by">codegeek</span><span>|</span><a href="#41974751">prev</a><span>|</span><a href="#41976133">next</a><span>|</span><label class="collapse" for="c-41976535">[-]</label><label class="expand" for="c-41976535">[2 more]</label></div><br/><div class="children"><div class="content">Looks good. In market for something like this and I  just ran it locally. how do I visualize data ? Is Grafana not included by default.<p>Also, minor issue in your docs. There is an extra comma in the sample JSON under the sample event. The fragment below:<p><pre><code>        &quot;properties&quot;: {
            &quot;totalAccounts&quot;: 4,
            &quot;country&quot;: &quot;Denmark&quot;
        },
    }]
</code></pre>
I had to remove that comma at the end.</div><br/><div id="41976889" class="c"><input type="checkbox" id="c-41976889" checked=""/><div class="controls bullet"><span class="by">pancomplex</span><span>|</span><a href="#41976535">parent</a><span>|</span><a href="#41976133">next</a><span>|</span><label class="collapse" for="c-41976889">[-]</label><label class="expand" for="c-41976889">[1 more]</label></div><br/><div class="children"><div class="content">Thanks for flagging. Just fixed this.
Grafana is intentionally not included by default -- but it takes a few minutes to set it up. We&#x27;re still trying to figure out what to bundle by default in terms of UI -- for now it&#x27;s API only.</div><br/></div></div></div></div><div id="41976133" class="c"><input type="checkbox" id="c-41976133" checked=""/><div class="controls bullet"><span class="by">antman</span><span>|</span><a href="#41976535">prev</a><span>|</span><a href="#41977447">next</a><span>|</span><label class="collapse" for="c-41976133">[-]</label><label class="expand" for="c-41976133">[2 more]</label></div><br/><div class="children"><div class="content">How does it scale? Can you spin up multiple containers?
For upcoming features auto archiving to cloud storage old data would be great.</div><br/><div id="41976278" class="c"><input type="checkbox" id="c-41976278" checked=""/><div class="controls bullet"><span class="by">pancomplex</span><span>|</span><a href="#41976133">parent</a><span>|</span><a href="#41977447">next</a><span>|</span><label class="collapse" for="c-41976278">[-]</label><label class="expand" for="c-41976278">[1 more]</label></div><br/><div class="children"><div class="content">Once you&#x27;ve outgrown a single physical server, you can continue to scale the Trench cluster by spinning up more Trench application servers and switching to dedicated Kafka and ClickHouse (either self-hosted or via cloud offerings). You can also shard Trench itself depending on the structure of your data (e.g. 1 Trench instance per customer, use case, etc.)<p>Auto-archiving to cloud for Kafka (Confluent, AWS KMS, etc.) &#x2F; ClickHouse (ClickHouse Cloud, etc.) is definitely high on the roadmap.</div><br/></div></div></div></div><div id="41977447" class="c"><input type="checkbox" id="c-41977447" checked=""/><div class="controls bullet"><span class="by">oulipo</span><span>|</span><a href="#41976133">prev</a><span>|</span><a href="#41975034">next</a><span>|</span><label class="collapse" for="c-41977447">[-]</label><label class="expand" for="c-41977447">[2 more]</label></div><br/><div class="children"><div class="content">What is the advantage of this rather than using a postgres plugin for clickhouse and S3 storage of the data to build a kind of data-warehouse, which wouldn&#x27;t require the bloat of Kafka?</div><br/><div id="41977604" class="c"><input type="checkbox" id="c-41977604" checked=""/><div class="controls bullet"><span class="by">pancomplex</span><span>|</span><a href="#41977447">parent</a><span>|</span><a href="#41975034">next</a><span>|</span><label class="collapse" for="c-41977604">[-]</label><label class="expand" for="c-41977604">[1 more]</label></div><br/><div class="children"><div class="content">In my experience, at scale (~2-3k QPS), you&#x27;d run into a bottleneck ingesting so many events without Kafka. If you don&#x27;t have this level of throughput, you could totally do the above and still get the advantages of ClickHouse&#x27;s columnar datastore.</div><br/></div></div></div></div><div id="41975034" class="c"><input type="checkbox" id="c-41975034" checked=""/><div class="controls bullet"><span class="by">d_watt</span><span>|</span><a href="#41977447">prev</a><span>|</span><a href="#41977436">next</a><span>|</span><label class="collapse" for="c-41975034">[-]</label><label class="expand" for="c-41975034">[2 more]</label></div><br/><div class="children"><div class="content">Looks super interesting. Any positioning thoughts on this vs <a href="https:&#x2F;&#x2F;jitsu.com">https:&#x2F;&#x2F;jitsu.com</a> ?</div><br/><div id="41975259" class="c"><input type="checkbox" id="c-41975259" checked=""/><div class="controls bullet"><span class="by">pancomplex</span><span>|</span><a href="#41975034">parent</a><span>|</span><a href="#41977436">next</a><span>|</span><label class="collapse" for="c-41975259">[-]</label><label class="expand" for="c-41975259">[1 more]</label></div><br/><div class="children"><div class="content">I think a major difference is that Jitsu depends on you having a data warehouse whereas Trench can be spun up as a standalone system. The nature of Trench&#x27;s data is also to enable real-time querying a high scale which will be much slower when depending on ETL&#x27;ed data in a data warehouse.</div><br/></div></div></div></div><div id="41977436" class="c"><input type="checkbox" id="c-41977436" checked=""/><div class="controls bullet"><span class="by">oulipo</span><span>|</span><a href="#41975034">prev</a><span>|</span><a href="#41977487">next</a><span>|</span><label class="collapse" for="c-41977436">[-]</label><label class="expand" for="c-41977436">[2 more]</label></div><br/><div class="children"><div class="content">Could this be used to log IoT object events? or is it more for app analytics?</div><br/><div id="41977494" class="c"><input type="checkbox" id="c-41977494" checked=""/><div class="controls bullet"><span class="by">pancomplex</span><span>|</span><a href="#41977436">parent</a><span>|</span><a href="#41977487">next</a><span>|</span><label class="collapse" for="c-41977494">[-]</label><label class="expand" for="c-41977494">[1 more]</label></div><br/><div class="children"><div class="content">Yes for sure. We intentionally designed Trench to be very unopinionated when it comes to the application. So you can use it to stream and query anything from page views, log traces to IoT object events.</div><br/></div></div></div></div><div id="41977487" class="c"><input type="checkbox" id="c-41977487" checked=""/><div class="controls bullet"><span class="by">asdev</span><span>|</span><a href="#41977436">prev</a><span>|</span><label class="collapse" for="c-41977487">[-]</label><label class="expand" for="c-41977487">[3 more]</label></div><br/><div class="children"><div class="content">how is this different from Posthog?</div><br/><div id="41977572" class="c"><input type="checkbox" id="c-41977572" checked=""/><div class="controls bullet"><span class="by">pancomplex</span><span>|</span><a href="#41977487">parent</a><span>|</span><a href="#41979219">next</a><span>|</span><label class="collapse" for="c-41977572">[-]</label><label class="expand" for="c-41977572">[1 more]</label></div><br/><div class="children"><div class="content">The stack is indeed very similar to Posthog. The biggest difference is that we don&#x27;t come with all the feature bloat (Session Recordings, Feature Flags, Surveys, etc.) and instead provide a very minimal and easy to use backend + API that is applicable to a ton of use cases.<p>We (Frigade.com) actually use Posthog as well as Trench in production. Posthog powers all our website analytics. Trench powers our own SDK and tracking scripts we ship to our own customers.<p>I actually tried to spin up Posthog originally before building Trench, but there was just way too much overhead and &quot;junk&quot; we didn&#x27;t need. I would need to strip out so many features of their Python app, it would eventually be faster to build a clean solution in Typescript ourselves.</div><br/></div></div><div id="41979219" class="c"><input type="checkbox" id="c-41979219" checked=""/><div class="controls bullet"><span class="by">BohdanPetryshyn</span><span>|</span><a href="#41977487">parent</a><span>|</span><a href="#41977572">prev</a><span>|</span><label class="collapse" for="c-41979219">[-]</label><label class="expand" for="c-41979219">[1 more]</label></div><br/><div class="children"><div class="content">In addition to what pancomplex mentioned, Posthog is not fully open-source. Their free self-hosted version has limited functionality and the paid self-hosted version is no longer supported [1] which makes me feel like I&#x27;m pushed to use their cloud offering.<p>[1]: <a href="https:&#x2F;&#x2F;posthog.com&#x2F;docs&#x2F;self-host">https:&#x2F;&#x2F;posthog.com&#x2F;docs&#x2F;self-host</a></div><br/></div></div></div></div></div></div></div></div></div></body></html>