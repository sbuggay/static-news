<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1710320462169" as="style"/><link rel="stylesheet" href="styles.css?v=1710320462169"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://engineering.fb.com/2024/03/12/data-center-engineering/building-metas-genai-infrastructure/">Building Meta&#x27;s GenAI infrastructure</a> <span class="domain">(<a href="https://engineering.fb.com">engineering.fb.com</a>)</span></div><div class="subtext"><span>mootpt</span> | <span>238 comments</span></div><br/><div><div id="39682147" class="c"><input type="checkbox" id="c-39682147" checked=""/><div class="controls bullet"><span class="by">danielhanchen</span><span>|</span><a href="#39686210">next</a><span>|</span><label class="collapse" for="c-39682147">[-]</label><label class="expand" for="c-39682147">[20 more]</label></div><br/><div class="children"><div class="content">float8 got a mention! x2 more FLOPs! Also xformers has 2:4 sparsity support now so another x2? Is Llama3 gonna use like float8 + 2:4 sparsity for the MLP, so 4x H100 float16 FLOPs? Pytorch has fp8 experimental support, whilst attention is still complex to do in float8 due to precision issues, so maybe attention is in float16, and RoPE &#x2F; layernorms in float16 &#x2F; float32, whilst everything else is float8?</div><br/><div id="39682314" class="c"><input type="checkbox" id="c-39682314" checked=""/><div class="controls bullet"><span class="by">GamerAlias</span><span>|</span><a href="#39682147">parent</a><span>|</span><a href="#39683668">next</a><span>|</span><label class="collapse" for="c-39682314">[-]</label><label class="expand" for="c-39682314">[2 more]</label></div><br/><div class="children"><div class="content">I was thinking why is this one guy on HN so deeply interested and discussing technical details from a minor remark. Then I clocked the name. Great work on Gemma bugs</div><br/><div id="39682680" class="c"><input type="checkbox" id="c-39682680" checked=""/><div class="controls bullet"><span class="by">danielhanchen</span><span>|</span><a href="#39682147">root</a><span>|</span><a href="#39682314">parent</a><span>|</span><a href="#39683668">next</a><span>|</span><label class="collapse" for="c-39682680">[-]</label><label class="expand" for="c-39682680">[1 more]</label></div><br/><div class="children"><div class="content">Oh thanks :) I always like small details :)</div><br/></div></div></div></div><div id="39683668" class="c"><input type="checkbox" id="c-39683668" checked=""/><div class="controls bullet"><span class="by">andy99</span><span>|</span><a href="#39682147">parent</a><span>|</span><a href="#39682314">prev</a><span>|</span><a href="#39684040">next</a><span>|</span><label class="collapse" for="c-39683668">[-]</label><label class="expand" for="c-39683668">[8 more]</label></div><br/><div class="children"><div class="content">Is there float8 support in any common CPU intrinsics? It sounds interesting but curious what will be the impact if any on CPU inference.</div><br/><div id="39688409" class="c"><input type="checkbox" id="c-39688409" checked=""/><div class="controls bullet"><span class="by">teaearlgraycold</span><span>|</span><a href="#39682147">root</a><span>|</span><a href="#39683668">parent</a><span>|</span><a href="#39685361">next</a><span>|</span><label class="collapse" for="c-39688409">[-]</label><label class="expand" for="c-39688409">[3 more]</label></div><br/><div class="children"><div class="content">I’m curious if there’s a meaningful quality difference between float8 and some uint8 alternative (fixed precision or a look up table).</div><br/><div id="39688994" class="c"><input type="checkbox" id="c-39688994" checked=""/><div class="controls bullet"><span class="by">CraigJPerry</span><span>|</span><a href="#39682147">root</a><span>|</span><a href="#39688409">parent</a><span>|</span><a href="#39685361">next</a><span>|</span><label class="collapse" for="c-39688994">[-]</label><label class="expand" for="c-39688994">[2 more]</label></div><br/><div class="children"><div class="content">A LUT could be a significant performance penalty would it not? Instead of a float8 (potentially multiple in simd case) in a register, you’re now having to head out to at least L1 cache to dereference the value in the LUT.<p>Plain uint8 wouldn’t allow for the same accuracy range as float8 and it’s the accuracy not the precision (which uint would win for the largest values it can represent) that counts most.</div><br/><div id="39689046" class="c"><input type="checkbox" id="c-39689046" checked=""/><div class="controls bullet"><span class="by">danielhanchen</span><span>|</span><a href="#39682147">root</a><span>|</span><a href="#39688994">parent</a><span>|</span><a href="#39685361">next</a><span>|</span><label class="collapse" for="c-39689046">[-]</label><label class="expand" for="c-39689046">[1 more]</label></div><br/><div class="children"><div class="content">Oh oh was just gonna comment as well, but saw this! I think x86 has like pshufb for LUTs (used them like ages ago, but forgot now :() I think also some game (was it Spiderman) used loads of lookup tables.<p>The issue with LUTs is don&#x27;t you have to update the LUT itself? You can select which memory address to load up, but the LUT itself has to be differentiable maybe? TBH I&#x27;m not an expert on LUTs.<p>On fixed point - similarly ye you have to fix the precision ranges as well, so again I&#x27;m unsure on how one changes the fixed point numbers over time. I&#x27;ll have to read more on fixed point.<p>Maybe 1.58bit using (-1, 0, 1) which gets rid of multiplications and just additions might be more useful, although you&#x27;ll only get a 2x FLOP boost since you still need fp8 or fp16 addition.</div><br/></div></div></div></div></div></div><div id="39685765" class="c"><input type="checkbox" id="c-39685765" checked=""/><div class="controls bullet"><span class="by">ashvardanian</span><span>|</span><a href="#39682147">root</a><span>|</span><a href="#39683668">parent</a><span>|</span><a href="#39685361">prev</a><span>|</span><a href="#39684040">next</a><span>|</span><label class="collapse" for="c-39685765">[-]</label><label class="expand" for="c-39685765">[3 more]</label></div><br/><div class="children"><div class="content">Nope. Moreover, simulating it even with AVX-512 is quite an experience. Been postponing it for 2 years now... But first of all, you need to choose the version of float8 you want to implement, as the standards differ between GPU vendors.</div><br/><div id="39687319" class="c"><input type="checkbox" id="c-39687319" checked=""/><div class="controls bullet"><span class="by">janwas</span><span>|</span><a href="#39682147">root</a><span>|</span><a href="#39685765">parent</a><span>|</span><a href="#39684040">next</a><span>|</span><label class="collapse" for="c-39687319">[-]</label><label class="expand" for="c-39687319">[2 more]</label></div><br/><div class="children"><div class="content">We use it in gemma.cpp [1]. This hybrid of E5M2 and E4M3 decodes to bf16 in ~14 instructions, so we can do that on the fly during dot products.<p>[1]: github.com&#x2F;google&#x2F;gemma.cpp</div><br/><div id="39687535" class="c"><input type="checkbox" id="c-39687535" checked=""/><div class="controls bullet"><span class="by">danielhanchen</span><span>|</span><a href="#39682147">root</a><span>|</span><a href="#39687319">parent</a><span>|</span><a href="#39684040">next</a><span>|</span><label class="collapse" for="c-39687535">[-]</label><label class="expand" for="c-39687535">[1 more]</label></div><br/><div class="children"><div class="content">Congratulations on gemma.cpp!!</div><br/></div></div></div></div></div></div></div></div><div id="39684040" class="c"><input type="checkbox" id="c-39684040" checked=""/><div class="controls bullet"><span class="by">ipsum2</span><span>|</span><a href="#39682147">parent</a><span>|</span><a href="#39683668">prev</a><span>|</span><a href="#39686982">next</a><span>|</span><label class="collapse" for="c-39684040">[-]</label><label class="expand" for="c-39684040">[5 more]</label></div><br/><div class="children"><div class="content">You&#x27;re still bounded by memory bandwidth, so adding multiples to FLOPs is not going to give you a good representation of overall speedup.</div><br/><div id="39684106" class="c"><input type="checkbox" id="c-39684106" checked=""/><div class="controls bullet"><span class="by">jabl</span><span>|</span><a href="#39682147">root</a><span>|</span><a href="#39684040">parent</a><span>|</span><a href="#39687519">next</a><span>|</span><label class="collapse" for="c-39684106">[-]</label><label class="expand" for="c-39684106">[3 more]</label></div><br/><div class="children"><div class="content">Well, those smaller floats require less BW to transfer back and forth as well. Perhaps not a reduction linear in the size of the float, as maybe smaller floats require more iterations and&#x2F;or more nodes in the model graph to get an equivalent result.<p>But rest assured there&#x27;s an improvement, it&#x27;s not like people would be doing it if there wasn&#x27;t any benefit!</div><br/><div id="39684992" class="c"><input type="checkbox" id="c-39684992" checked=""/><div class="controls bullet"><span class="by">andy99</span><span>|</span><a href="#39682147">root</a><span>|</span><a href="#39684106">parent</a><span>|</span><a href="#39687519">next</a><span>|</span><label class="collapse" for="c-39684992">[-]</label><label class="expand" for="c-39684992">[2 more]</label></div><br/><div class="children"><div class="content">The impact on bandwidth is the main reason smaller is better I belive, certainly when it&#x27;s the bottleneck. I&#x27;m only really familiar with CPU but with say FP16 you might convert back to FP32 when you&#x27;re doing the actual multiplication (so conversion plus multiplication is actually slower) but because you&#x27;re moving half the data in and off you still get a huge speedup.</div><br/><div id="39687533" class="c"><input type="checkbox" id="c-39687533" checked=""/><div class="controls bullet"><span class="by">danielhanchen</span><span>|</span><a href="#39682147">root</a><span>|</span><a href="#39684992">parent</a><span>|</span><a href="#39687519">next</a><span>|</span><label class="collapse" for="c-39687533">[-]</label><label class="expand" for="c-39687533">[1 more]</label></div><br/><div class="children"><div class="content">I can&#x27;t remember some research paper somewhere even if you do float32 multiplications, but keep the data in bfloat16 by just simply truncating the lower mantissa bits, and doing packing, you still get speedups, since matrix multiplication is bound both by compute and cache access. If you can optimize on the cache side of things, speedups are definitely there.</div><br/></div></div></div></div></div></div><div id="39687519" class="c"><input type="checkbox" id="c-39687519" checked=""/><div class="controls bullet"><span class="by">danielhanchen</span><span>|</span><a href="#39682147">root</a><span>|</span><a href="#39684040">parent</a><span>|</span><a href="#39684106">prev</a><span>|</span><a href="#39686982">next</a><span>|</span><label class="collapse" for="c-39687519">[-]</label><label class="expand" for="c-39687519">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not sure exactly on how NVIDIA calculates FLOPs, but I do know for Intel&#x27;s FLOPs, it&#x27;s calculated from how many FMA units, how many loads can be done in tandem, and what the throughput is. And ye fp8 requires 2x less space. Sparse 2:4 might be less pronounced, since the matrix first needs to be constructed on the fly, and there is like a small matrix of indicator values.</div><br/></div></div></div></div><div id="39686982" class="c"><input type="checkbox" id="c-39686982" checked=""/><div class="controls bullet"><span class="by">boywitharupee</span><span>|</span><a href="#39682147">parent</a><span>|</span><a href="#39684040">prev</a><span>|</span><a href="#39685853">next</a><span>|</span><label class="collapse" for="c-39686982">[-]</label><label class="expand" for="c-39686982">[2 more]</label></div><br/><div class="children"><div class="content">care to explain why attention has precision issues with fp8?</div><br/><div id="39687161" class="c"><input type="checkbox" id="c-39687161" checked=""/><div class="controls bullet"><span class="by">danielhanchen</span><span>|</span><a href="#39682147">root</a><span>|</span><a href="#39686982">parent</a><span>|</span><a href="#39685853">next</a><span>|</span><label class="collapse" for="c-39687161">[-]</label><label class="expand" for="c-39687161">[1 more]</label></div><br/><div class="children"><div class="content">Oh so float8&#x27;s L2 Norm from float32 is around I think 1e-4, whilst float16 is 1e-6. Sadly attention is quite sensitive. There are some hybrid methods which just before the attention kernel which is done in fp8, upcasts the Q and K from the RoPE kernel to become float16, then also leaves V to be in float8. Everything is done in fp8 on the fly, and the output is fp8. This makes errors go to 1e-6.</div><br/></div></div></div></div><div id="39685853" class="c"><input type="checkbox" id="c-39685853" checked=""/><div class="controls bullet"><span class="by">j45</span><span>|</span><a href="#39682147">parent</a><span>|</span><a href="#39686982">prev</a><span>|</span><a href="#39686210">next</a><span>|</span><label class="collapse" for="c-39685853">[-]</label><label class="expand" for="c-39685853">[2 more]</label></div><br/><div class="children"><div class="content">Is it safe to assume this is the same float16 that exists in Apple m2 chips but not m1?</div><br/><div id="39686988" class="c"><input type="checkbox" id="c-39686988" checked=""/><div class="controls bullet"><span class="by">j45</span><span>|</span><a href="#39682147">root</a><span>|</span><a href="#39685853">parent</a><span>|</span><a href="#39686210">next</a><span>|</span><label class="collapse" for="c-39686988">[-]</label><label class="expand" for="c-39686988">[1 more]</label></div><br/><div class="children"><div class="content">Clarification: bfloat16<p>“bfloat16 data type and arithmetic instructions (AI and others)”<p><a href="https:&#x2F;&#x2F;eclecticlight.co&#x2F;2024&#x2F;01&#x2F;15&#x2F;why-the-m2-is-more-advanced-that-it-seemed&#x2F;" rel="nofollow">https:&#x2F;&#x2F;eclecticlight.co&#x2F;2024&#x2F;01&#x2F;15&#x2F;why-the-m2-is-more-advan...</a></div><br/></div></div></div></div></div></div><div id="39686210" class="c"><input type="checkbox" id="c-39686210" checked=""/><div class="controls bullet"><span class="by">dougdonohoe</span><span>|</span><a href="#39682147">prev</a><span>|</span><a href="#39681607">next</a><span>|</span><label class="collapse" for="c-39686210">[-]</label><label class="expand" for="c-39686210">[17 more]</label></div><br/><div class="children"><div class="content">Having lived through the dot-com era, I find the AI-era slightly dispiriting because of the sheer capital cost of training models.  At the start of the dot-com era, anyone could spin up an e-commerce site with relatively little infrastructure costs.  Now, it seems, only the hyper-scale companies can build these AI models.  Meta, Google, Microsoft, Open-AI, etc.</div><br/><div id="39687942" class="c"><input type="checkbox" id="c-39687942" checked=""/><div class="controls bullet"><span class="by">herval</span><span>|</span><a href="#39686210">parent</a><span>|</span><a href="#39686402">next</a><span>|</span><label class="collapse" for="c-39687942">[-]</label><label class="expand" for="c-39687942">[1 more]</label></div><br/><div class="children"><div class="content">I’m not sure we went through the same dot-com era, but in my experience, it was extremely expensive to spin up anything. You’d have to run your own servers, buy your own T1 lines, develop with rudimentary cgi… it was a very expensive mess - just like AI today<p>Which gives me hope that - like the web - hardware will catch up and stuff will become more and more accessible with time</div><br/></div></div><div id="39686402" class="c"><input type="checkbox" id="c-39686402" checked=""/><div class="controls bullet"><span class="by">renegade-otter</span><span>|</span><a href="#39686210">parent</a><span>|</span><a href="#39687942">prev</a><span>|</span><a href="#39688752">next</a><span>|</span><label class="collapse" for="c-39686402">[-]</label><label class="expand" for="c-39686402">[4 more]</label></div><br/><div class="children"><div class="content">Not everything has to be AI. You can run a small business infra for MUCH less than you did back then, especially if you adjust for inflation (!).<p>Training AI models costs a fortune, but so far it&#x27;s been just front-loading costs in hopes of a windfall. We&#x27;ll see what actually happens.</div><br/><div id="39687577" class="c"><input type="checkbox" id="c-39687577" checked=""/><div class="controls bullet"><span class="by">boringg</span><span>|</span><a href="#39686210">root</a><span>|</span><a href="#39686402">parent</a><span>|</span><a href="#39688752">next</a><span>|</span><label class="collapse" for="c-39687577">[-]</label><label class="expand" for="c-39687577">[3 more]</label></div><br/><div class="children"><div class="content">Front loading costs to eventually extract rents on usage with one hell of a capital wall protecting the assets.<p>Its easier to spin up a business for sure -- also easier to unwind it - there not as sticky as they used to be.</div><br/><div id="39687660" class="c"><input type="checkbox" id="c-39687660" checked=""/><div class="controls bullet"><span class="by">whatshisface</span><span>|</span><a href="#39686210">root</a><span>|</span><a href="#39687577">parent</a><span>|</span><a href="#39687766">next</a><span>|</span><label class="collapse" for="c-39687660">[-]</label><label class="expand" for="c-39687660">[1 more]</label></div><br/><div class="children"><div class="content">If the government can stay back far enough that more than one AI company can train their models, it will end up working like steel mills - barely enough profit to pay the massive cost of capital due to competition. If the government regulates the industry into a monopoly, all bets are off. Their investors are going to push hard for shutting the door behind them so watch out.<p>The only question is - what tactic? I don&#x27;t really know, but one  trick I am aware of is &quot;specifying to the vendor.&quot; In other words, the introduction of regulatory requirements that are at every step in the process a description of the most favored vendor&#x27;s product. As the favored players add more features, potentially safety features, those features are required in new regulations, using very specific descriptions that more or less mandate that you reproduce the existing technology, to use a software engineer&#x27;s term, bug-for-bug. If your product is better in some ways but worse in others, you might have a chance in the market - but to no avail, if the regulations demand exactly the advantages of the established suppliers.</div><br/></div></div><div id="39687766" class="c"><input type="checkbox" id="c-39687766" checked=""/><div class="controls bullet"><span class="by">brookst</span><span>|</span><a href="#39686210">root</a><span>|</span><a href="#39687577">parent</a><span>|</span><a href="#39687660">prev</a><span>|</span><a href="#39688752">next</a><span>|</span><label class="collapse" for="c-39687766">[-]</label><label class="expand" for="c-39687766">[1 more]</label></div><br/><div class="children"><div class="content">This is typically called a high fixed cost business, like airlines, hotels&#x2F;apartments, SpaceX, etc.<p>The dream may be barriers to entry that allow high margins (“rents” if you prefer the prejudicial), but all too often these huge capital costs bankrupt the company and lose money for investors (see: WeWork,  Magic Leap). It is high risk, high return. Which seems fair.</div><br/></div></div></div></div></div></div><div id="39688752" class="c"><input type="checkbox" id="c-39688752" checked=""/><div class="controls bullet"><span class="by">richardw</span><span>|</span><a href="#39686210">parent</a><span>|</span><a href="#39686402">prev</a><span>|</span><a href="#39686262">next</a><span>|</span><label class="collapse" for="c-39688752">[-]</label><label class="expand" for="c-39688752">[1 more]</label></div><br/><div class="children"><div class="content">I find the market way more open and competitive than dot-com. Everyone is throwing up a chatbot or RAG solution. There are tradesmen and secretaries and infinite 19 year olds who are now able to wire together a no-code app or low-code bot and add value to real businesses. The hyper scalars are making some money but absolutely don&#x27;t have this locked up. Any Groq or Mistral could wander in and eat their lunch, and we haven&#x27;t really started the race yet. The next decade will be ridiculous.</div><br/></div></div><div id="39686262" class="c"><input type="checkbox" id="c-39686262" checked=""/><div class="controls bullet"><span class="by">andy99</span><span>|</span><a href="#39686210">parent</a><span>|</span><a href="#39688752">prev</a><span>|</span><a href="#39688086">next</a><span>|</span><label class="collapse" for="c-39686262">[-]</label><label class="expand" for="c-39686262">[4 more]</label></div><br/><div class="children"><div class="content">So far it&#x27;s been pretty &quot;democratic&quot; - I feel in no way disadvantaged because I can&#x27;t train a foundation model myself. Actually the ecosystem is a lot better than 25 years ago - there are open source (or source available) versions of basically everything you&#x27;d want to participate in modern AI&#x2F;ML.</div><br/><div id="39686379" class="c"><input type="checkbox" id="c-39686379" checked=""/><div class="controls bullet"><span class="by">mewpmewp2</span><span>|</span><a href="#39686210">root</a><span>|</span><a href="#39686262">parent</a><span>|</span><a href="#39688086">next</a><span>|</span><label class="collapse" for="c-39686379">[-]</label><label class="expand" for="c-39686379">[3 more]</label></div><br/><div class="children"><div class="content">But none of those are remotely as good as GPT4 for example.</div><br/><div id="39686444" class="c"><input type="checkbox" id="c-39686444" checked=""/><div class="controls bullet"><span class="by">to11mtm</span><span>|</span><a href="#39686210">root</a><span>|</span><a href="#39686379">parent</a><span>|</span><a href="#39688086">next</a><span>|</span><label class="collapse" for="c-39686444">[-]</label><label class="expand" for="c-39686444">[2 more]</label></div><br/><div class="children"><div class="content">Mixtral?</div><br/><div id="39686885" class="c"><input type="checkbox" id="c-39686885" checked=""/><div class="controls bullet"><span class="by">ametrau</span><span>|</span><a href="#39686210">root</a><span>|</span><a href="#39686444">parent</a><span>|</span><a href="#39688086">next</a><span>|</span><label class="collapse" for="c-39686885">[-]</label><label class="expand" for="c-39686885">[1 more]</label></div><br/><div class="children"><div class="content">Obviously not even close</div><br/></div></div></div></div></div></div></div></div><div id="39688086" class="c"><input type="checkbox" id="c-39688086" checked=""/><div class="controls bullet"><span class="by">danielhanchen</span><span>|</span><a href="#39686210">parent</a><span>|</span><a href="#39686262">prev</a><span>|</span><a href="#39686245">next</a><span>|</span><label class="collapse" for="c-39688086">[-]</label><label class="expand" for="c-39688086">[2 more]</label></div><br/><div class="children"><div class="content">Another way to compete with the big tech incumbents is instead of hardware, try maths and software hacks to level the playing field! Training models is still black magic, so making it faster on the software side can solve the capital cost issue somewhat!</div><br/><div id="39688484" class="c"><input type="checkbox" id="c-39688484" checked=""/><div class="controls bullet"><span class="by">toxik</span><span>|</span><a href="#39686210">root</a><span>|</span><a href="#39688086">parent</a><span>|</span><a href="#39686245">next</a><span>|</span><label class="collapse" for="c-39688484">[-]</label><label class="expand" for="c-39688484">[1 more]</label></div><br/><div class="children"><div class="content">This kind of research is also incredibly capital intensive. You have to pay some of the smartest people around to work in it.</div><br/></div></div></div></div><div id="39686245" class="c"><input type="checkbox" id="c-39686245" checked=""/><div class="controls bullet"><span class="by">danielmarkbruce</span><span>|</span><a href="#39686210">parent</a><span>|</span><a href="#39688086">prev</a><span>|</span><a href="#39687328">next</a><span>|</span><label class="collapse" for="c-39686245">[-]</label><label class="expand" for="c-39686245">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not quite the same thing. A model is just one part of a product. You can spin up a product with zero infra and calling APIs hosting models.</div><br/></div></div><div id="39687328" class="c"><input type="checkbox" id="c-39687328" checked=""/><div class="controls bullet"><span class="by">mindwok</span><span>|</span><a href="#39686210">parent</a><span>|</span><a href="#39686245">prev</a><span>|</span><a href="#39688375">next</a><span>|</span><label class="collapse" for="c-39687328">[-]</label><label class="expand" for="c-39687328">[1 more]</label></div><br/><div class="children"><div class="content">We will probably get there, it&#x27;s just going to take time for hardware supply chains to catch up. I feel it&#x27;s more comparable to mainframe eras - it took time for general purpose computing to become commoditised.</div><br/></div></div><div id="39688375" class="c"><input type="checkbox" id="c-39688375" checked=""/><div class="controls bullet"><span class="by">hackerlight</span><span>|</span><a href="#39686210">parent</a><span>|</span><a href="#39687328">prev</a><span>|</span><a href="#39686521">next</a><span>|</span><label class="collapse" for="c-39688375">[-]</label><label class="expand" for="c-39688375">[1 more]</label></div><br/><div class="children"><div class="content">Foundation models != application layer. The question is whether the application layer&#x27;s lunch will be eaten by better foundation models.</div><br/></div></div></div></div><div id="39681607" class="c"><input type="checkbox" id="c-39681607" checked=""/><div class="controls bullet"><span class="by">islewis</span><span>|</span><a href="#39686210">prev</a><span>|</span><a href="#39683903">next</a><span>|</span><label class="collapse" for="c-39681607">[-]</label><label class="expand" for="c-39681607">[7 more]</label></div><br/><div class="children"><div class="content">I know we won&#x27;t get it this from FB, but I&#x27;d be really interested to see how the relationship of compute power to engineering hours scales.<p>They mention custom building as much as they can. If FB magically has the option to 10x the compute power, would they need to re-engineer the whole stack? What about 100x? Is each of these re-writes just a re-write, or is it a whole order of magnitude more complex?<p>My technical understanding of what&#x27;s under the hood of these clusters is pretty surface level- super curious if anyone with relevant experience has thoughts?</div><br/><div id="39681743" class="c"><input type="checkbox" id="c-39681743" checked=""/><div class="controls bullet"><span class="by">bilekas</span><span>|</span><a href="#39681607">parent</a><span>|</span><a href="#39686107">next</a><span>|</span><label class="collapse" for="c-39681743">[-]</label><label class="expand" for="c-39681743">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not 100% sure but I would.make an educated guess that that cluster in the first image for example is a sample of scalable clusters, so throwing more hardware at it could bring improvements but sooner or later the cost to improvements will call for an optimization or rewrite as you call it, so a bit of both usually. It seems a bit of a balancing act really!</div><br/></div></div><div id="39686107" class="c"><input type="checkbox" id="c-39686107" checked=""/><div class="controls bullet"><span class="by">jvalencia</span><span>|</span><a href="#39681607">parent</a><span>|</span><a href="#39681743">prev</a><span>|</span><a href="#39683128">next</a><span>|</span><label class="collapse" for="c-39686107">[-]</label><label class="expand" for="c-39686107">[2 more]</label></div><br/><div class="children"><div class="content">The cost of training quickly outpaces the cost of development as context length increases. So hardware is cheap until it isn&#x27;t anymore, by orders of magnitude.</div><br/><div id="39686149" class="c"><input type="checkbox" id="c-39686149" checked=""/><div class="controls bullet"><span class="by">samstave</span><span>|</span><a href="#39681607">root</a><span>|</span><a href="#39686107">parent</a><span>|</span><a href="#39683128">next</a><span>|</span><label class="collapse" for="c-39686149">[-]</label><label class="expand" for="c-39686149">[1 more]</label></div><br/><div class="children"><div class="content">But there is still significant cost in the physical buildouts of new pods&#x2F;DCs, whatever and the human engineering hours to physically build, even though its a mix of resources across the vendors and FB? - it still would be interesting to know man hours into the physical build of the HW.</div><br/></div></div></div></div><div id="39683128" class="c"><input type="checkbox" id="c-39683128" checked=""/><div class="controls bullet"><span class="by">tintor</span><span>|</span><a href="#39681607">parent</a><span>|</span><a href="#39686107">prev</a><span>|</span><a href="#39683903">next</a><span>|</span><label class="collapse" for="c-39683128">[-]</label><label class="expand" for="c-39683128">[3 more]</label></div><br/><div class="children"><div class="content">&quot;just a re-write&quot;</div><br/><div id="39683481" class="c"><input type="checkbox" id="c-39683481" checked=""/><div class="controls bullet"><span class="by">mirekrusin</span><span>|</span><a href="#39681607">root</a><span>|</span><a href="#39683128">parent</a><span>|</span><a href="#39683903">next</a><span>|</span><label class="collapse" for="c-39683481">[-]</label><label class="expand" for="c-39683481">[2 more]</label></div><br/><div class="children"><div class="content">...the idea is that at some point it &quot;just re-writes&quot; itself.</div><br/><div id="39686895" class="c"><input type="checkbox" id="c-39686895" checked=""/><div class="controls bullet"><span class="by">ametrau</span><span>|</span><a href="#39681607">root</a><span>|</span><a href="#39683481">parent</a><span>|</span><a href="#39683903">next</a><span>|</span><label class="collapse" for="c-39686895">[-]</label><label class="expand" for="c-39686895">[1 more]</label></div><br/><div class="children"><div class="content">The day after that, we have true AGI.</div><br/></div></div></div></div></div></div></div></div><div id="39683903" class="c"><input type="checkbox" id="c-39683903" checked=""/><div class="controls bullet"><span class="by">jvanderbot</span><span>|</span><a href="#39681607">prev</a><span>|</span><a href="#39682217">next</a><span>|</span><label class="collapse" for="c-39683903">[-]</label><label class="expand" for="c-39683903">[14 more]</label></div><br/><div class="children"><div class="content">So, I&#x27;d love to work on optimizing pipelines like this. How does one &quot;get into&quot; it? It seems a ML scientist with some C&#x2F;C++ and infra knowledge just dips down into the system when required? Or is it CUDA&#x2F;SIMD experts who move &quot;up&quot; into ML?</div><br/><div id="39686279" class="c"><input type="checkbox" id="c-39686279" checked=""/><div class="controls bullet"><span class="by">thegginthesky</span><span>|</span><a href="#39683903">parent</a><span>|</span><a href="#39684404">next</a><span>|</span><label class="collapse" for="c-39686279">[-]</label><label class="expand" for="c-39686279">[2 more]</label></div><br/><div class="children"><div class="content">I know someone who works on this in Meta. His resume is computer science heavy, with a masters in Machine Learning. On the previous experience side, before getting into Meta, he had about a decade working as a Software Engineer with Machine Learning system in multiple languages, such as Go, C++ and Python.<p>To get the job he applied for a spot I&#x27;m Software Engineer applied in Machine Learning, he went through the multiple step interview process, and then when he got the job he did a few weeks of training and interviewing teams. One of the teams in charge of optimizing ML code in Meta picked him up and now he works there.<p>Because of Meta&#x27;s scale, optimizing code that saves a few ms or watts is a huge impact in the bottom line.<p>In sum:<p>- Get a formal education in the area
- Get work experience somewhere
- Apply for a big tech job in Software Engineer applied with ML
- Hope they hire you and have a spot in one of the teams in charge of optimizing stuff</div><br/><div id="39686795" class="c"><input type="checkbox" id="c-39686795" checked=""/><div class="controls bullet"><span class="by">jvanderbot</span><span>|</span><a href="#39683903">root</a><span>|</span><a href="#39686279">parent</a><span>|</span><a href="#39684404">next</a><span>|</span><label class="collapse" for="c-39686795">[-]</label><label class="expand" for="c-39686795">[1 more]</label></div><br/><div class="children"><div class="content">This is helpful thank you. There&#x27;s always some luck.<p>I have a PhD in CS, and lots of experience in optimization and some in throughput&#x2F;speedups (in an amdahl sense) for planning problems. My biggest challenge is really getting something meaty with high constraints or large compute requirements.  By the time I get a pipeline set up it&#x27;s good enough and we move on. So it&#x27;s tough to build up that skillset to get in the door where the big problems are.</div><br/></div></div></div></div><div id="39684404" class="c"><input type="checkbox" id="c-39684404" checked=""/><div class="controls bullet"><span class="by">KaiserPro</span><span>|</span><a href="#39683903">parent</a><span>|</span><a href="#39686279">prev</a><span>|</span><a href="#39687218">next</a><span>|</span><label class="collapse" for="c-39684404">[-]</label><label class="expand" for="c-39684404">[7 more]</label></div><br/><div class="children"><div class="content">A lot of the optimisation at this level is getting data into the right place at the right time, without killing the network.<p>Its also a group effort to provide simple to use primitives that &quot;normal&quot; ML people can use, even if they&#x27;ve never used hyper scale clusters before.<p>So you need a good scheduler, that understand dependencies (no, the k8s scheduler(s) are shit for this, plus it wont scale past 1k nodes without eating all of your network bandwidth), then you need a dataloader that can provide the dataset access, then you need the IPC that allows sharing&#x2F;joining of GPUs together.<p>all of that needs to be wrapped up into a python interface that fairly simple to use.<p>Oh and it needs to be secure, pass an FCC audit (ie you need to prove that no user data is being used) have a high utilisation efficiency and uptime.<p>the model stuff is the cherry on the top</div><br/><div id="39686059" class="c"><input type="checkbox" id="c-39686059" checked=""/><div class="controls bullet"><span class="by">claytonjy</span><span>|</span><a href="#39683903">root</a><span>|</span><a href="#39684404">parent</a><span>|</span><a href="#39684998">next</a><span>|</span><label class="collapse" for="c-39686059">[-]</label><label class="expand" for="c-39686059">[1 more]</label></div><br/><div class="children"><div class="content">can you say more about the network issues with thousands of k8s nodes? I&#x27;m regularly running 2-3000 nodes in a GKE cluster, majority have GPUs, is this something I need to be worrying about?</div><br/></div></div><div id="39684998" class="c"><input type="checkbox" id="c-39684998" checked=""/><div class="controls bullet"><span class="by">jvanderbot</span><span>|</span><a href="#39683903">root</a><span>|</span><a href="#39684404">parent</a><span>|</span><a href="#39686059">prev</a><span>|</span><a href="#39687218">next</a><span>|</span><label class="collapse" for="c-39684998">[-]</label><label class="expand" for="c-39684998">[5 more]</label></div><br/><div class="children"><div class="content">Ok, but back to my main question, how do I get into this?</div><br/><div id="39685294" class="c"><input type="checkbox" id="c-39685294" checked=""/><div class="controls bullet"><span class="by">willsmith72</span><span>|</span><a href="#39683903">root</a><span>|</span><a href="#39684998">parent</a><span>|</span><a href="#39687218">next</a><span>|</span><label class="collapse" for="c-39685294">[-]</label><label class="expand" for="c-39685294">[4 more]</label></div><br/><div class="children"><div class="content">It looks more like an infra problem than ML. &quot;Software architect&quot;s mixed with devops&#x2F;infra&#x2F;sre people</div><br/><div id="39685384" class="c"><input type="checkbox" id="c-39685384" checked=""/><div class="controls bullet"><span class="by">jvanderbot</span><span>|</span><a href="#39683903">root</a><span>|</span><a href="#39685294">parent</a><span>|</span><a href="#39687218">next</a><span>|</span><label class="collapse" for="c-39685384">[-]</label><label class="expand" for="c-39685384">[3 more]</label></div><br/><div class="children"><div class="content">Well since I&#x27;m not a ML engineer of any kind - that&#x27;s good!</div><br/><div id="39685672" class="c"><input type="checkbox" id="c-39685672" checked=""/><div class="controls bullet"><span class="by">zooq_ai</span><span>|</span><a href="#39683903">root</a><span>|</span><a href="#39685384">parent</a><span>|</span><a href="#39687218">next</a><span>|</span><label class="collapse" for="c-39685672">[-]</label><label class="expand" for="c-39685672">[2 more]</label></div><br/><div class="children"><div class="content">at the end of the day, you are still moving, storing and manipulating 1&#x27;s and 0&#x27;s, whether you are a front end engineer or a backend engineer or systems engieer or an ML engineer or an infra engineer</div><br/><div id="39688686" class="c"><input type="checkbox" id="c-39688686" checked=""/><div class="controls bullet"><span class="by">elbear</span><span>|</span><a href="#39683903">root</a><span>|</span><a href="#39685672">parent</a><span>|</span><a href="#39687218">next</a><span>|</span><label class="collapse" for="c-39688686">[-]</label><label class="expand" for="c-39688686">[1 more]</label></div><br/><div class="children"><div class="content">yeah, but how do you get the hiring managers to see things in the same way? :)</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="39687218" class="c"><input type="checkbox" id="c-39687218" checked=""/><div class="controls bullet"><span class="by">chillee</span><span>|</span><a href="#39683903">parent</a><span>|</span><a href="#39684404">prev</a><span>|</span><a href="#39686438">next</a><span>|</span><label class="collapse" for="c-39687218">[-]</label><label class="expand" for="c-39687218">[1 more]</label></div><br/><div class="children"><div class="content">I work on PyTorch Compilers at Meta, and I think folks enter ML Systems from all directions :)<p>Some folks start with more familiarity in ML research and dip down as far as they need.<p>Other folks come from a traditional distributed systems&#x2F;compilers&#x2F;HPC background, and apply those skills to ML systems.</div><br/></div></div><div id="39686438" class="c"><input type="checkbox" id="c-39686438" checked=""/><div class="controls bullet"><span class="by">gajjanag</span><span>|</span><a href="#39683903">parent</a><span>|</span><a href="#39687218">prev</a><span>|</span><a href="#39686766">next</a><span>|</span><label class="collapse" for="c-39686438">[-]</label><label class="expand" for="c-39686438">[2 more]</label></div><br/><div class="children"><div class="content">Our group works on some of this stuff at Meta, and we have a pretty good diversity of backgrounds - high performance computing (the bulk), computer systems, compilers, ML engineers, etc. We are hiring.<p>Feel free to DM me to learn more.</div><br/><div id="39686813" class="c"><input type="checkbox" id="c-39686813" checked=""/><div class="controls bullet"><span class="by">jvanderbot</span><span>|</span><a href="#39683903">root</a><span>|</span><a href="#39686438">parent</a><span>|</span><a href="#39686766">next</a><span>|</span><label class="collapse" for="c-39686813">[-]</label><label class="expand" for="c-39686813">[1 more]</label></div><br/><div class="children"><div class="content">I will, thank you. Any info is very helpful.</div><br/></div></div></div></div><div id="39686766" class="c"><input type="checkbox" id="c-39686766" checked=""/><div class="controls bullet"><span class="by">yalok</span><span>|</span><a href="#39683903">parent</a><span>|</span><a href="#39686438">prev</a><span>|</span><a href="#39682217">next</a><span>|</span><label class="collapse" for="c-39686766">[-]</label><label class="expand" for="c-39686766">[1 more]</label></div><br/><div class="children"><div class="content">start with something small - take some kernel function in C, and try to optimize it for your laptops assembly SIMD instruction set.</div><br/></div></div></div></div><div id="39682217" class="c"><input type="checkbox" id="c-39682217" checked=""/><div class="controls bullet"><span class="by">fuddle</span><span>|</span><a href="#39683903">prev</a><span>|</span><a href="#39685337">next</a><span>|</span><label class="collapse" for="c-39682217">[-]</label><label class="expand" for="c-39682217">[31 more]</label></div><br/><div class="children"><div class="content">How much are they paying for H100&#x27;s? If they are paying $10k:
350,000 NVIDIA H100 x $10k = $3.5b</div><br/><div id="39682984" class="c"><input type="checkbox" id="c-39682984" checked=""/><div class="controls bullet"><span class="by">trsohmers</span><span>|</span><a href="#39682217">parent</a><span>|</span><a href="#39684419">next</a><span>|</span><label class="collapse" for="c-39682984">[-]</label><label class="expand" for="c-39682984">[11 more]</label></div><br/><div class="children"><div class="content">Significantly more than that; MFN pricing for NVIDIA DGX H100 (which has been getting priority supply allocation, so many have been suckered into buying them in order to get fast delivery) is ~$309k, while a basically equivalent HGX H100 system is ~$250k, coming to a price per GPU at the full server level being ~$31.5k. With Meta’s custom OCP systems integrating the SXM baseboards from NVIDIA, my guess is that their cost per GPU would be in the ~$23-$25k range.</div><br/><div id="39683638" class="c"><input type="checkbox" id="c-39683638" checked=""/><div class="controls bullet"><span class="by">fuddle</span><span>|</span><a href="#39682217">root</a><span>|</span><a href="#39682984">parent</a><span>|</span><a href="#39688026">next</a><span>|</span><label class="collapse" for="c-39683638">[-]</label><label class="expand" for="c-39683638">[9 more]</label></div><br/><div class="children"><div class="content">350,000 NVIDIA H100 x $23k = $8b :0</div><br/><div id="39683795" class="c"><input type="checkbox" id="c-39683795" checked=""/><div class="controls bullet"><span class="by">verticalscaler</span><span>|</span><a href="#39682217">root</a><span>|</span><a href="#39683638">parent</a><span>|</span><a href="#39688026">next</a><span>|</span><label class="collapse" for="c-39683795">[-]</label><label class="expand" for="c-39683795">[8 more]</label></div><br/><div class="children"><div class="content">Wait till you find out how much they spent on VR.<p>It is a real loophole in the economy. If you&#x27;re a trillion dollar company the market will insist you set such sums on fire just to be in the race for $current-hype. If they do it drives their market cap higher still and if they don&#x27;t they risk being considered un-innovative and therefore doomed to irrelevancy and the market cap will spiral downwards.<p>Sort of reminds me of The Producers.</div><br/><div id="39683871" class="c"><input type="checkbox" id="c-39683871" checked=""/><div class="controls bullet"><span class="by">oblio</span><span>|</span><a href="#39682217">root</a><span>|</span><a href="#39683795">parent</a><span>|</span><a href="#39685610">next</a><span>|</span><label class="collapse" for="c-39683871">[-]</label><label class="expand" for="c-39683871">[3 more]</label></div><br/><div class="children"><div class="content">The thing is, this could be considered basic research, right? Basic research IS setting money on fire until (and if) that basic research turns into TCP&#x2F;IP, Ethernet and the Internet.</div><br/><div id="39683956" class="c"><input type="checkbox" id="c-39683956" checked=""/><div class="controls bullet"><span class="by">verticalscaler</span><span>|</span><a href="#39682217">root</a><span>|</span><a href="#39683871">parent</a><span>|</span><a href="#39685610">next</a><span>|</span><label class="collapse" for="c-39683956">[-]</label><label class="expand" for="c-39683956">[2 more]</label></div><br/><div class="children"><div class="content">I wish.<p>Funnily enough Arpanet and all that Xerox stuff were like &lt;$50 million (inflation adjusted!) total. Some real forward thinkers were able to work the system by breaking off a tiny pittance of a much larger budget.<p>Where as I think this more appropriately can be considered the meta PR budget. They simply can&#x27;t not spend it, would look bad for Wall Street. Have to keep up with the herd.</div><br/><div id="39688438" class="c"><input type="checkbox" id="c-39688438" checked=""/><div class="controls bullet"><span class="by">throwaway2037</span><span>|</span><a href="#39682217">root</a><span>|</span><a href="#39683956">parent</a><span>|</span><a href="#39685610">next</a><span>|</span><label class="collapse" for="c-39688438">[-]</label><label class="expand" for="c-39688438">[1 more]</label></div><br/><div class="children"><div class="content"><p><pre><code>    &gt; Funnily enough Arpanet and all that Xerox stuff were like &lt;$50 million (inflation adjusted!) total.
</code></pre>
That doesn&#x27;t say much.  The industry was in utter infancy.  How much do you think it cost to move Ethernet from 100Mbit&#x2F;sec to 1GBbit&#x2F;sec to 10GB to 100GB to 400GB to 800GB?  At least one or two orders of magnitude.<p>How about the cost to build a fab for the Intel 8088 versus a fab that produces 5nm chips running @ 5GHz.  Again, at least one or two orders of magnitude.</div><br/></div></div></div></div></div></div><div id="39685610" class="c"><input type="checkbox" id="c-39685610" checked=""/><div class="controls bullet"><span class="by">lotsofpulp</span><span>|</span><a href="#39682217">root</a><span>|</span><a href="#39683795">parent</a><span>|</span><a href="#39683871">prev</a><span>|</span><a href="#39688026">next</a><span>|</span><label class="collapse" for="c-39685610">[-]</label><label class="expand" for="c-39685610">[4 more]</label></div><br/><div class="children"><div class="content">&gt; If you&#x27;re a trillion dollar company the market will insist you set such sums on fire just to be in the race for $current-hype. If they do it drives their market cap higher still and if they don&#x27;t they risk being considered un-innovative and therefore doomed to irrelevancy and the market cap will spiral downwards.<p>You don’t think earning increasing amounts of tens of billions of dollars in net income per year at some of the highest profit margins in the world at that size for 10+ years has anything to do with market cap?</div><br/><div id="39686490" class="c"><input type="checkbox" id="c-39686490" checked=""/><div class="controls bullet"><span class="by">verticalscaler</span><span>|</span><a href="#39682217">root</a><span>|</span><a href="#39685610">parent</a><span>|</span><a href="#39688026">next</a><span>|</span><label class="collapse" for="c-39686490">[-]</label><label class="expand" for="c-39686490">[3 more]</label></div><br/><div class="children"><div class="content">$1T Market Cap lets it be known it will invest $10B a year into $current-hype that will change <i>everything</i>. P&#x2F;E loosens speculatively on sudden new unbounded potential, Market Cap $1.1T. Hype funded. PR as innovator cemented.</div><br/><div id="39688448" class="c"><input type="checkbox" id="c-39688448" checked=""/><div class="controls bullet"><span class="by">throwaway2037</span><span>|</span><a href="#39682217">root</a><span>|</span><a href="#39686490">parent</a><span>|</span><a href="#39688657">next</a><span>|</span><label class="collapse" for="c-39688448">[-]</label><label class="expand" for="c-39688448">[1 more]</label></div><br/><div class="children"><div class="content">If you look at the R&amp;D expenditure of Apple, it is mindboggling.<p><a href="https:&#x2F;&#x2F;www.macrotrends.net&#x2F;stocks&#x2F;charts&#x2F;AAPL&#x2F;apple&#x2F;research-development-expenses" rel="nofollow">https:&#x2F;&#x2F;www.macrotrends.net&#x2F;stocks&#x2F;charts&#x2F;AAPL&#x2F;apple&#x2F;researc...</a><p>Roughly 30B USD per year.  And what are we getting?  Slightly slimmer phones and 3500USD AR&#x2F;VR headsets?</div><br/></div></div><div id="39688657" class="c"><input type="checkbox" id="c-39688657" checked=""/><div class="controls bullet"><span class="by">throwaway2037</span><span>|</span><a href="#39682217">root</a><span>|</span><a href="#39686490">parent</a><span>|</span><a href="#39688448">prev</a><span>|</span><a href="#39688026">next</a><span>|</span><label class="collapse" for="c-39688657">[-]</label><label class="expand" for="c-39688657">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Market Cap $1.1T. Hype funded.<p>I&#x27;m confused.  How does your stock price, which determines market cat, affect your cashflow to fund R&amp;D?  It does not.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="39688026" class="c"><input type="checkbox" id="c-39688026" checked=""/><div class="controls bullet"><span class="by">bigcat12345678</span><span>|</span><a href="#39682217">root</a><span>|</span><a href="#39682984">parent</a><span>|</span><a href="#39683638">prev</a><span>|</span><a href="#39684419">next</a><span>|</span><label class="collapse" for="c-39688026">[-]</label><label class="expand" for="c-39688026">[1 more]</label></div><br/><div class="children"><div class="content">Would you kindly provide sources to the numbers?
What is MFN?<p>Thanks!
(Your number is consistent with what I hear of, but I never managed to get solid sources to back them up)</div><br/></div></div></div></div><div id="39684419" class="c"><input type="checkbox" id="c-39684419" checked=""/><div class="controls bullet"><span class="by">vineyardmike</span><span>|</span><a href="#39682217">parent</a><span>|</span><a href="#39682984">prev</a><span>|</span><a href="#39683442">next</a><span>|</span><label class="collapse" for="c-39684419">[-]</label><label class="expand" for="c-39684419">[2 more]</label></div><br/><div class="children"><div class="content">It’s often forgotten now, but just a few years NVidia was cancelled production batches and writing down inventory when the GPU shortage cleared. No one needed more GPUs. It also happens to be when Meta first announced they were going to increase CapEx spending on compute.<p>I’m guessing that Meta got a sweetheart deal to help take a lot of inventory for NVidia and make commitments for future purchases.</div><br/><div id="39686235" class="c"><input type="checkbox" id="c-39686235" checked=""/><div class="controls bullet"><span class="by">transcriptase</span><span>|</span><a href="#39682217">root</a><span>|</span><a href="#39684419">parent</a><span>|</span><a href="#39683442">next</a><span>|</span><label class="collapse" for="c-39686235">[-]</label><label class="expand" for="c-39686235">[1 more]</label></div><br/><div class="children"><div class="content">I don’t think it was that nobody needed GPUs. It was that nvidia thought they could get scalper margins by restricting supply after the shortage showed people were willing to pay scalper prices.</div><br/></div></div></div></div><div id="39683442" class="c"><input type="checkbox" id="c-39683442" checked=""/><div class="controls bullet"><span class="by">dekhn</span><span>|</span><a href="#39682217">parent</a><span>|</span><a href="#39684419">prev</a><span>|</span><a href="#39682360">next</a><span>|</span><label class="collapse" for="c-39683442">[-]</label><label class="expand" for="c-39683442">[1 more]</label></div><br/><div class="children"><div class="content">That sounds like a reasonable budget for 3 years of hardware at a major AI company.</div><br/></div></div><div id="39682360" class="c"><input type="checkbox" id="c-39682360" checked=""/><div class="controls bullet"><span class="by">ZiiS</span><span>|</span><a href="#39682217">parent</a><span>|</span><a href="#39683442">prev</a><span>|</span><a href="#39682497">next</a><span>|</span><label class="collapse" for="c-39682360">[-]</label><label class="expand" for="c-39682360">[2 more]</label></div><br/><div class="children"><div class="content">They may have to pay a premium to secure ~¼ of the output; certainly unlikely to be that steep a discount.</div><br/><div id="39683673" class="c"><input type="checkbox" id="c-39683673" checked=""/><div class="controls bullet"><span class="by">theptip</span><span>|</span><a href="#39682217">root</a><span>|</span><a href="#39682360">parent</a><span>|</span><a href="#39682497">next</a><span>|</span><label class="collapse" for="c-39683673">[-]</label><label class="expand" for="c-39683673">[1 more]</label></div><br/><div class="children"><div class="content">Semi analysis posted recently noting that Meta locked in these purchases a while ago; something like a year or more. So they probably didn’t pay today’s spot rate.</div><br/></div></div></div></div><div id="39682497" class="c"><input type="checkbox" id="c-39682497" checked=""/><div class="controls bullet"><span class="by">YetAnotherNick</span><span>|</span><a href="#39682217">parent</a><span>|</span><a href="#39682360">prev</a><span>|</span><a href="#39684899">next</a><span>|</span><label class="collapse" for="c-39682497">[-]</label><label class="expand" for="c-39682497">[13 more]</label></div><br/><div class="children"><div class="content">&gt; $3.5b<p>Which is a fourth of what they spent in VR&#x2F;AR in a year. And Gen AI is something they could easily get more revenue as it has now become proven technology, and Meta could possibly leapfrog others because of the data moat.</div><br/><div id="39683188" class="c"><input type="checkbox" id="c-39683188" checked=""/><div class="controls bullet"><span class="by">dougb5</span><span>|</span><a href="#39682217">root</a><span>|</span><a href="#39682497">parent</a><span>|</span><a href="#39682637">next</a><span>|</span><label class="collapse" for="c-39683188">[-]</label><label class="expand" for="c-39683188">[5 more]</label></div><br/><div class="children"><div class="content">Proven technology, maybe, but proven product-market fit for the kinds of things Facebook is using it for?  Their linked blog about AI features gives examples &quot;AI stickers&quot; and image editing... cool, but are these potential multi-billion dollar lifts to their existing business?  I guess I&#x27;m skeptical it&#x27;s worthwhile unless they&#x27;re able to unseat ChatGPT with a market-leading general purpose assistant.</div><br/><div id="39683585" class="c"><input type="checkbox" id="c-39683585" checked=""/><div class="controls bullet"><span class="by">pests</span><span>|</span><a href="#39682217">root</a><span>|</span><a href="#39683188">parent</a><span>|</span><a href="#39684251">next</a><span>|</span><label class="collapse" for="c-39683585">[-]</label><label class="expand" for="c-39683585">[2 more]</label></div><br/><div class="children"><div class="content">I have a few group chats just that devolve into hours of sending stickers or image generation back and forth, lately we&#x27;ve been &quot;writing a book together&quot; with @Meta AI as the ghost writer, and while it utterly sucks, its been a hilarious shared experience.<p>I don&#x27;t think anyone else has gotten that group chat with AI thing so nailed.</div><br/><div id="39683920" class="c"><input type="checkbox" id="c-39683920" checked=""/><div class="controls bullet"><span class="by">TaylorAlexander</span><span>|</span><a href="#39682217">root</a><span>|</span><a href="#39683585">parent</a><span>|</span><a href="#39684251">next</a><span>|</span><label class="collapse" for="c-39683920">[-]</label><label class="expand" for="c-39683920">[1 more]</label></div><br/><div class="children"><div class="content">On the podcast TrashFuture, November Kelly recently described AI systems as “garbage dispensers” which is both a funny image (why would anyone make a garbage dispenser??) and an apt description. Certainly these tools have some utility, but there are a load of startups claiming to “democratize creativity” by allowing anyone to publish AI generated slop to major platforms. On the podcast this phrase was used during discussion of a website which lets you create AI generated music and push it to Spotify, a move which Spotify originally pushed back on but has now embraced. Garbage dispenser indeed.</div><br/></div></div></div></div><div id="39684251" class="c"><input type="checkbox" id="c-39684251" checked=""/><div class="controls bullet"><span class="by">YetAnotherNick</span><span>|</span><a href="#39682217">root</a><span>|</span><a href="#39683188">parent</a><span>|</span><a href="#39683585">prev</a><span>|</span><a href="#39682637">next</a><span>|</span><label class="collapse" for="c-39684251">[-]</label><label class="expand" for="c-39684251">[2 more]</label></div><br/><div class="children"><div class="content">&gt; unseat ChatGPT with a market-leading general purpose assistant.<p>It&#x27;s not impossible. The prediction from many(not that I believe it) is that over long run modelling tricks would become common knowledge and only thing that matters is compute and data, both of which Meta has.<p>Also there could be a trend of LLMs for ads or feed recommendation in the future as they has large completely unstructured dataset per user across multiple sites.</div><br/><div id="39685308" class="c"><input type="checkbox" id="c-39685308" checked=""/><div class="controls bullet"><span class="by">cj</span><span>|</span><a href="#39682217">root</a><span>|</span><a href="#39684251">parent</a><span>|</span><a href="#39682637">next</a><span>|</span><label class="collapse" for="c-39685308">[-]</label><label class="expand" for="c-39685308">[1 more]</label></div><br/><div class="children"><div class="content">Compute, data, and most importantly distribution&#x2F;users.<p>IMO standalone AI companies like OpenAI might be successful by providing infrastructure to other companies, but I can’t imagine ChatGPT remaining #1 many years from now.<p>The web is still trending towards being a walled garden. Maybe not right now, but long term I think people will use whatever AI is most convenient which probably will be AI built into a giant company with established user base (FB, GOOG, MSFT, and Apple if they ever get around to launching - would love Siri 2.0 if it meant not needing to open the ChatGPT iOS app)</div><br/></div></div></div></div></div></div><div id="39682637" class="c"><input type="checkbox" id="c-39682637" checked=""/><div class="controls bullet"><span class="by">NBJack</span><span>|</span><a href="#39682217">root</a><span>|</span><a href="#39682497">parent</a><span>|</span><a href="#39683188">prev</a><span>|</span><a href="#39684899">next</a><span>|</span><label class="collapse" for="c-39682637">[-]</label><label class="expand" for="c-39682637">[7 more]</label></div><br/><div class="children"><div class="content">What moat exactly? Much of the user data they have access to is drying up due to new regulations, some of which prohibit IIRC direct use on models as well. I&#x27;m not even sure they can use historical data.<p>Meta certainly has an edge in engineer count, undoubtedly. But I&#x27;d say they really, really want the metaverse to succeed more to have their on walled garden (i.e. equivalent power of Apple and Google stores, etc.). There&#x27;s a reason they gave a hard pass to a Google partnership.</div><br/><div id="39683071" class="c"><input type="checkbox" id="c-39683071" checked=""/><div class="controls bullet"><span class="by">Dr_Birdbrain</span><span>|</span><a href="#39682217">root</a><span>|</span><a href="#39682637">parent</a><span>|</span><a href="#39686628">next</a><span>|</span><label class="collapse" for="c-39683071">[-]</label><label class="expand" for="c-39683071">[4 more]</label></div><br/><div class="children"><div class="content">I think the raw text inside Facebook groups is at least as valuable as Reddit data. Even if demographics data is restricted under European law, the raw text of people interacting is quite valuable.</div><br/><div id="39683851" class="c"><input type="checkbox" id="c-39683851" checked=""/><div class="controls bullet"><span class="by">verticalscaler</span><span>|</span><a href="#39682217">root</a><span>|</span><a href="#39683071">parent</a><span>|</span><a href="#39683353">next</a><span>|</span><label class="collapse" for="c-39683851">[-]</label><label class="expand" for="c-39683851">[2 more]</label></div><br/><div class="children"><div class="content">Indeed, my deranged auntie posting on FB is approximately as valuable as my ADHD&#x2F;PTSD quaranteeny nephew redditing.</div><br/><div id="39688045" class="c"><input type="checkbox" id="c-39688045" checked=""/><div class="controls bullet"><span class="by">fragmede</span><span>|</span><a href="#39682217">root</a><span>|</span><a href="#39683851">parent</a><span>|</span><a href="#39683353">next</a><span>|</span><label class="collapse" for="c-39688045">[-]</label><label class="expand" for="c-39688045">[1 more]</label></div><br/><div class="children"><div class="content">That ignores all the user groups that are on Facebook. From apartment communities aka Nextdoor to grief support counseling to the mindfulness therapy groups, there’s a wealth of user comments a tad bit higher than Uncle John’s racist rants.</div><br/></div></div></div></div><div id="39683353" class="c"><input type="checkbox" id="c-39683353" checked=""/><div class="controls bullet"><span class="by">calvinmorrison</span><span>|</span><a href="#39682217">root</a><span>|</span><a href="#39683071">parent</a><span>|</span><a href="#39683851">prev</a><span>|</span><a href="#39686628">next</a><span>|</span><label class="collapse" for="c-39683353">[-]</label><label class="expand" for="c-39683353">[1 more]</label></div><br/><div class="children"><div class="content">facebooks downfall will be their lock in. every other social media platform lets you view a public profile, discussion groups etc. it&#x27;s all locked inside facebook.</div><br/></div></div></div></div><div id="39686628" class="c"><input type="checkbox" id="c-39686628" checked=""/><div class="controls bullet"><span class="by">agar</span><span>|</span><a href="#39682217">root</a><span>|</span><a href="#39682637">parent</a><span>|</span><a href="#39683071">prev</a><span>|</span><a href="#39684096">next</a><span>|</span><label class="collapse" for="c-39686628">[-]</label><label class="expand" for="c-39686628">[1 more]</label></div><br/><div class="children"><div class="content">&gt; There&#x27;s a reason they gave a hard pass to a Google partnership.<p>AIUI, Google required Meta to basically cede control of a partnered OS to them:<p>&quot;After years of not focusing on VR or doing anything to support our work in the space, Google has been pitching AndroidXR to partners and suggesting, incredibly, that WE are the ones threatening to fragment the ecosystem when they are the ones who plan to do exactly that.<p>&quot;We would love to partner with them. They could bring their apps to Quest today! They could bring the Play store (with its current economics for 2d apps) and add value to all their developers immediately, which is exactly the kind of open app ecosystem we want to see. We would be thrilled to have them. It would be a win for their developers and all consumers and we’ll keep pushing for it.<p>&quot;Instead, they want us to agree to restrictive terms that require us to give up our freedom to innovate and build better experiences for people and developers—we’ve seen this play out before and we think we can do better this time around.&quot;<p>-- From Mark Bosworth</div><br/></div></div><div id="39684096" class="c"><input type="checkbox" id="c-39684096" checked=""/><div class="controls bullet"><span class="by">YetAnotherNick</span><span>|</span><a href="#39682217">root</a><span>|</span><a href="#39682637">parent</a><span>|</span><a href="#39686628">prev</a><span>|</span><a href="#39684899">next</a><span>|</span><label class="collapse" for="c-39684096">[-]</label><label class="expand" for="c-39684096">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Much of the user data they have access to is drying up due to new regulations, some of which prohibit IIRC direct use on models as well.<p>Source would be appreciated, because this is opposite of obvious. Regulations against using public first party would be a big news and I haven&#x27;t heard of anything like that. They use my data for recommending feed so why not for answering my question?</div><br/></div></div></div></div></div></div><div id="39684899" class="c"><input type="checkbox" id="c-39684899" checked=""/><div class="controls bullet"><span class="by">loeg</span><span>|</span><a href="#39682217">parent</a><span>|</span><a href="#39682497">prev</a><span>|</span><a href="#39685337">next</a><span>|</span><label class="collapse" for="c-39684899">[-]</label><label class="expand" for="c-39684899">[1 more]</label></div><br/><div class="children"><div class="content">Yes, billions in GPU cap ex.</div><br/></div></div></div></div><div id="39685337" class="c"><input type="checkbox" id="c-39685337" checked=""/><div class="controls bullet"><span class="by">benreesman</span><span>|</span><a href="#39682217">prev</a><span>|</span><a href="#39682646">next</a><span>|</span><label class="collapse" for="c-39685337">[-]</label><label class="expand" for="c-39685337">[1 more]</label></div><br/><div class="children"><div class="content">I think it’s always useful to pay attention to the history on stuff like this and it’s a rare pleasure to be able to give some pointers in the literature along with some color to those interested from first-hand experience.<p>I’d point the interested at the DLRM paper [1]: that was just after I left and I’m sad I missed it. FB got into disagg racks and SDN and stuff fairly early, and we already had half-U dual-socket SKUs with the SSD and (increasingly) even DRAM elsewhere in the rack in 2018, but we were doing <i>huge</i> NNs for recommenders and rankers even for then. I don’t know if this is considered proprietary so I’ll play it safe and just say that a click-prediction model on IG Stories in 2018 was on the order of a modest but real LLM today (at FP32!).<p>The crazy part is they were HOGWILD trained on Intel AVX-2, which is just wild to think about. When I was screwing around with CUDA kernels we were time sharing NVIDIA dev boxes, typically 2-4 people doing CUDA were splitting up a single card as late as maybe 2016. I was managing what was called “IGML Infra” when I left and was on a first-name basis with the next-gen hardware people and any NVIDIA deal was still so closely guarded I didn’t hear more than rumors about GPUs for training let alone inference.<p>350k Hopper this year, Jesus. Say what you want about Meta but don’t say they can’t pour concrete and design SKUs on a dime: best damned infrastructure folks in the game pound-for-pound to this day.<p>The talk by Thomas “tnb” Bredillet in particular I’d recommend: one of the finest hackers, mathematicians, and humans I’ve ever had the pleasure to know.<p>[1] <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;1906.00091.pdf" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;1906.00091.pdf</a><p>[2] <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2108.09373.pdf" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2108.09373.pdf</a><p>[3] <a href="https:&#x2F;&#x2F;engineering.fb.com&#x2F;2022&#x2F;10&#x2F;18&#x2F;open-source&#x2F;ocp-summit-2022-grand-teton&#x2F;" rel="nofollow">https:&#x2F;&#x2F;engineering.fb.com&#x2F;2022&#x2F;10&#x2F;18&#x2F;open-source&#x2F;ocp-summit...</a><p>[4] <a href="https:&#x2F;&#x2F;youtu.be&#x2F;lQlIwWVlPGo?si=rRbRUAXX7aM0UcVO" rel="nofollow">https:&#x2F;&#x2F;youtu.be&#x2F;lQlIwWVlPGo?si=rRbRUAXX7aM0UcVO</a></div><br/></div></div><div id="39682646" class="c"><input type="checkbox" id="c-39682646" checked=""/><div class="controls bullet"><span class="by">zone411</span><span>|</span><a href="#39685337">prev</a><span>|</span><a href="#39681850">next</a><span>|</span><label class="collapse" for="c-39682646">[-]</label><label class="expand" for="c-39682646">[2 more]</label></div><br/><div class="children"><div class="content">Meta is still playing catch-up. Might be hard to believe but according to Reuters they&#x27;ve been trying to run AI workloads mostly on CPUs until 2022 and they had to pull the plug on the first iteration of their AI chip.<p><a href="https:&#x2F;&#x2F;www.reuters.com&#x2F;technology&#x2F;inside-metas-scramble-catch-up-ai-2023-04-25&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.reuters.com&#x2F;technology&#x2F;inside-metas-scramble-cat...</a></div><br/><div id="39685829" class="c"><input type="checkbox" id="c-39685829" checked=""/><div class="controls bullet"><span class="by">axpy906</span><span>|</span><a href="#39682646">parent</a><span>|</span><a href="#39681850">next</a><span>|</span><label class="collapse" for="c-39685829">[-]</label><label class="expand" for="c-39685829">[1 more]</label></div><br/><div class="children"><div class="content">Definitely has some pr buzz and flex in the article. Now I see why.</div><br/></div></div></div></div><div id="39681850" class="c"><input type="checkbox" id="c-39681850" checked=""/><div class="controls bullet"><span class="by">DEDLINE</span><span>|</span><a href="#39682646">prev</a><span>|</span><a href="#39682167">next</a><span>|</span><label class="collapse" for="c-39681850">[-]</label><label class="expand" for="c-39681850">[43 more]</label></div><br/><div class="children"><div class="content">I wonder if Meta would ever try to compete with AWS &#x2F; MSFT &#x2F; GOOG for AI workloads</div><br/><div id="39682648" class="c"><input type="checkbox" id="c-39682648" checked=""/><div class="controls bullet"><span class="by">lifeisstillgood</span><span>|</span><a href="#39681850">parent</a><span>|</span><a href="#39682690">next</a><span>|</span><label class="collapse" for="c-39682648">[-]</label><label class="expand" for="c-39682648">[28 more]</label></div><br/><div class="children"><div class="content">FB does not have the flywheel of running data centres - all three of those mentioned run hyper scale datacentres that they can then juice by “investing” billions in AI companies who then turn around and put those billions as revenue in the investors<p>OpenAI takes money from MSFT and buys Azure services<p>Anthropic takes Amazon money and buys AWS services (as do many robotics etc)<p>I am fairly sure it’s not illegal but it’s definitely low quality revenue</div><br/><div id="39685761" class="c"><input type="checkbox" id="c-39685761" checked=""/><div class="controls bullet"><span class="by">miohtama</span><span>|</span><a href="#39681850">root</a><span>|</span><a href="#39682648">parent</a><span>|</span><a href="#39682932">next</a><span>|</span><label class="collapse" for="c-39685761">[-]</label><label class="expand" for="c-39685761">[2 more]</label></div><br/><div class="children"><div class="content">Such barter deals were also popular during the 00s Internet Bubble.<p>Here more on the deals (2003):<p><a href="https:&#x2F;&#x2F;www.cnet.com&#x2F;tech&#x2F;services-and-software&#x2F;aol-saga-opens-old-dot-com-wounds&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.cnet.com&#x2F;tech&#x2F;services-and-software&#x2F;aol-saga-ope...</a><p>Popular names included AOL, Cisco, Yahoo, etc.<p>Not sure if Amazon’s term sheets driving high valuation are nothing but AWS credits (Amazon’s own license to print money).</div><br/></div></div><div id="39682932" class="c"><input type="checkbox" id="c-39682932" checked=""/><div class="controls bullet"><span class="by">woah</span><span>|</span><a href="#39681850">root</a><span>|</span><a href="#39682648">parent</a><span>|</span><a href="#39685761">prev</a><span>|</span><a href="#39684441">next</a><span>|</span><label class="collapse" for="c-39682932">[-]</label><label class="expand" for="c-39682932">[5 more]</label></div><br/><div class="children"><div class="content">Sounds like it&#x27;s free equity at the very least</div><br/><div id="39685653" class="c"><input type="checkbox" id="c-39685653" checked=""/><div class="controls bullet"><span class="by">lotsofpulp</span><span>|</span><a href="#39681850">root</a><span>|</span><a href="#39682932">parent</a><span>|</span><a href="#39684441">next</a><span>|</span><label class="collapse" for="c-39685653">[-]</label><label class="expand" for="c-39685653">[4 more]</label></div><br/><div class="children"><div class="content">How is it free equity?  Spending money to invest it somewhere involves risks.  You might recover some of it if the investment is valued by others, but there is no guarantee.</div><br/><div id="39685782" class="c"><input type="checkbox" id="c-39685782" checked=""/><div class="controls bullet"><span class="by">miohtama</span><span>|</span><a href="#39681850">root</a><span>|</span><a href="#39685653">parent</a><span>|</span><a href="#39684441">next</a><span>|</span><label class="collapse" for="c-39685782">[-]</label><label class="expand" for="c-39685782">[3 more]</label></div><br/><div class="children"><div class="content">You do not need cash in hands to invest. Instead, you print your own money (AWS credit) and use that to drive up the valuation, because this money costs you nothing today.<p>It might cost tomorrow though, when the company starts to use your services. However depending the deal structure they might not use all the credit, go belly up before credit is used or bought up by someone with real cash.</div><br/></div></div></div></div></div></div><div id="39684441" class="c"><input type="checkbox" id="c-39684441" checked=""/><div class="controls bullet"><span class="by">vineyardmike</span><span>|</span><a href="#39681850">root</a><span>|</span><a href="#39682648">parent</a><span>|</span><a href="#39682932">prev</a><span>|</span><a href="#39684756">next</a><span>|</span><label class="collapse" for="c-39684441">[-]</label><label class="expand" for="c-39684441">[2 more]</label></div><br/><div class="children"><div class="content">NVidia also invests in their AI customers.</div><br/><div id="39689050" class="c"><input type="checkbox" id="c-39689050" checked=""/><div class="controls bullet"><span class="by">fikama</span><span>|</span><a href="#39681850">root</a><span>|</span><a href="#39684441">parent</a><span>|</span><a href="#39684756">next</a><span>|</span><label class="collapse" for="c-39689050">[-]</label><label class="expand" for="c-39689050">[1 more]</label></div><br/><div class="children"><div class="content">What do you mean? Could you elaborate please? Enumerate some deals so I could read more about it?</div><br/></div></div></div></div><div id="39684756" class="c"><input type="checkbox" id="c-39684756" checked=""/><div class="controls bullet"><span class="by">itslennysfault</span><span>|</span><a href="#39681850">root</a><span>|</span><a href="#39682648">parent</a><span>|</span><a href="#39684441">prev</a><span>|</span><a href="#39684319">next</a><span>|</span><label class="collapse" for="c-39684756">[-]</label><label class="expand" for="c-39684756">[2 more]</label></div><br/><div class="children"><div class="content">Neither did AWS when they started. They were just building out data centers to run their little book website and decided to start selling the excess capacity. Meta could absolutely do the same, but in the short term, I think they find using that capacity more valuable than selling it.</div><br/><div id="39685335" class="c"><input type="checkbox" id="c-39685335" checked=""/><div class="controls bullet"><span class="by">otterley</span><span>|</span><a href="#39681850">root</a><span>|</span><a href="#39684756">parent</a><span>|</span><a href="#39684319">next</a><span>|</span><label class="collapse" for="c-39685335">[-]</label><label class="expand" for="c-39685335">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Neither did AWS when they started. They were just building out data centers to run their little book website and decided to start selling the excess capacity.<p>This is a myth. It simply isn&#x27;t true. AWS was conceived as a greenfield business by its first CEO. Besides, S3 and SQS were the first AWS services; EC2 didn&#x27;t appear till a few years later. And it wasn&#x27;t built from excess Amazon server capacity; it was totally separate.</div><br/></div></div></div></div><div id="39684319" class="c"><input type="checkbox" id="c-39684319" checked=""/><div class="controls bullet"><span class="by">virtuallynathan</span><span>|</span><a href="#39681850">root</a><span>|</span><a href="#39682648">parent</a><span>|</span><a href="#39684756">prev</a><span>|</span><a href="#39682690">next</a><span>|</span><label class="collapse" for="c-39684319">[-]</label><label class="expand" for="c-39684319">[16 more]</label></div><br/><div class="children"><div class="content">Facebook has more datacenter space and power than Amazon, Google, and Microsoft -- possibly more than Amazon and Microsoft combined...</div><br/><div id="39684729" class="c"><input type="checkbox" id="c-39684729" checked=""/><div class="controls bullet"><span class="by">jedberg</span><span>|</span><a href="#39681850">root</a><span>|</span><a href="#39684319">parent</a><span>|</span><a href="#39685924">next</a><span>|</span><label class="collapse" for="c-39684729">[-]</label><label class="expand" for="c-39684729">[4 more]</label></div><br/><div class="children"><div class="content">Unless you&#x27;ve worked at Amazon, Microsoft, Google, and Facebook, or a whole bunch of datacenter providers, I&#x27;m not sure how you could make that claim.  They don&#x27;t really share that information freely, even in their stock reports.<p>Heck I worked at Amazon and even then I couldn&#x27;t tell you the total datacenter space, they don&#x27;t even share it internally.</div><br/><div id="39685871" class="c"><input type="checkbox" id="c-39685871" checked=""/><div class="controls bullet"><span class="by">virtuallynathan</span><span>|</span><a href="#39681850">root</a><span>|</span><a href="#39684729">parent</a><span>|</span><a href="#39685924">next</a><span>|</span><label class="collapse" for="c-39685871">[-]</label><label class="expand" for="c-39685871">[3 more]</label></div><br/><div class="children"><div class="content">You can just map them all... I have. I also worked at AWS :)</div><br/><div id="39686666" class="c"><input type="checkbox" id="c-39686666" checked=""/><div class="controls bullet"><span class="by">chatmasta</span><span>|</span><a href="#39681850">root</a><span>|</span><a href="#39685871">parent</a><span>|</span><a href="#39687067">next</a><span>|</span><label class="collapse" for="c-39686666">[-]</label><label class="expand" for="c-39686666">[1 more]</label></div><br/><div class="children"><div class="content">This would be an interesting dataset to use for trading decisions (or sell to hedge funds).<p>But I wonder how much of their infrastructure is publicly mappable, compared to just the part of it that&#x27;s exposed to the edge. (Can you map some internal instances in a VPC?)<p>That said, I&#x27;m sure there are a lot of side channels in the provisioning APIs, certificate logs, and other metadata that could paint a decently accurate picture of cloud sizes. It might not cover everything but it&#x27;d be good enough to track and measure a gradual expansion of capacity.</div><br/></div></div><div id="39687067" class="c"><input type="checkbox" id="c-39687067" checked=""/><div class="controls bullet"><span class="by">the-rc</span><span>|</span><a href="#39681850">root</a><span>|</span><a href="#39685871">parent</a><span>|</span><a href="#39686666">prev</a><span>|</span><a href="#39685924">next</a><span>|</span><label class="collapse" for="c-39687067">[-]</label><label class="expand" for="c-39687067">[1 more]</label></div><br/><div class="children"><div class="content">Mapping as in.. drawing the outlines of buildings and computing the square footage yourself?</div><br/></div></div></div></div></div></div><div id="39685924" class="c"><input type="checkbox" id="c-39685924" checked=""/><div class="controls bullet"><span class="by">virtuallynathan</span><span>|</span><a href="#39681850">root</a><span>|</span><a href="#39684319">parent</a><span>|</span><a href="#39684729">prev</a><span>|</span><a href="#39684813">next</a><span>|</span><label class="collapse" for="c-39685924">[-]</label><label class="expand" for="c-39685924">[6 more]</label></div><br/><div class="children"><div class="content">To date, facebook has built, or is building, 47,100,000 sq ft of space, totaling nearly $24bn in investment. Based on available&#x2F;disclosed power numbers and extrapolating per sqft, I get something like 4770MW.<p>Last I updated my spreadsheet in 2019, Google had $17bn in investments across their datacenters, totaling 13,260,000 sq ft of datacenter space. Additional buildings have been built since then, but not to the scale of an additional 30mil sq ft.<p>Amazon operates ~80 datacenter buildings in Northern Virginia, each ~200,000 sq ft -- about 16,000,000sq ft total in that region, the other regions are much much smaller, perhaps another 4 mil sq ft. When I&#x27;m bored I&#x27;ll go update all my maps and spreadsheets.</div><br/><div id="39687046" class="c"><input type="checkbox" id="c-39687046" checked=""/><div class="controls bullet"><span class="by">the-rc</span><span>|</span><a href="#39681850">root</a><span>|</span><a href="#39685924">parent</a><span>|</span><a href="#39686271">next</a><span>|</span><label class="collapse" for="c-39687046">[-]</label><label class="expand" for="c-39687046">[1 more]</label></div><br/><div class="children"><div class="content">Does the square footage take into account multiple floors? What&#x27;s the source? It can be misleading, because you don&#x27;t know the compute density of what&#x27;s inside. Using just public data, power is a more accurate proxy. Until at least 5-6 years ago, Google was procuring more electricity than Amazon. Before that, it had a further advantage from lower PUE, but I bet the big names are all comparable on that front by now. Anyone that has worked at several of them can infer that FB is not the largest (but it&#x27;s still huge).<p>As for the dollars, were they just in 2019 or cumulative? The Google ones seem low compared to numbers from earnings.</div><br/></div></div><div id="39686271" class="c"><input type="checkbox" id="c-39686271" checked=""/><div class="controls bullet"><span class="by">samstave</span><span>|</span><a href="#39681850">root</a><span>|</span><a href="#39685924">parent</a><span>|</span><a href="#39687046">prev</a><span>|</span><a href="#39686156">next</a><span>|</span><label class="collapse" for="c-39686271">[-]</label><label class="expand" for="c-39686271">[1 more]</label></div><br/><div class="children"><div class="content">At this point <i>Power Companies</i> (ala PG&amp;E, etc) <i>should</i> be investing in AI companies in a big way. THen they make money off the AI companies to build out power infra - and vice versa.<p>I am surprised we havent heard about private electrical grid built out by such companies.<p>Surely they all have some owned power generation, but then if they do, the local areas where they DO build out power plants - they should have to build capacity for the local area, mayhaps in exchange for the normal tax subsidies they seek for all these large capital projects.<p>Cant wait until we pods&#x2F;clusters in orbit. With radioisotope batteries to power them along with the panels. (I wonder how close to a node a RI battery can be? Can each node have its own RI?) (sas they can produce upto &quot;several KW&quot; -- but I cant find a reliable source for max wattage of an RI...)<p>SpaceX should build an ISS module thats an AI DC cluster.<p>And have all the ISS technologies build its LLM there based on all the data they create?</div><br/></div></div><div id="39686156" class="c"><input type="checkbox" id="c-39686156" checked=""/><div class="controls bullet"><span class="by">VirusNewbie</span><span>|</span><a href="#39681850">root</a><span>|</span><a href="#39685924">parent</a><span>|</span><a href="#39686271">prev</a><span>|</span><a href="#39684813">next</a><span>|</span><label class="collapse" for="c-39686156">[-]</label><label class="expand" for="c-39686156">[3 more]</label></div><br/><div class="children"><div class="content">But Google built data centers aren&#x27;t the only data centers google is running their machine fleet in...</div><br/><div id="39686681" class="c"><input type="checkbox" id="c-39686681" checked=""/><div class="controls bullet"><span class="by">chatmasta</span><span>|</span><a href="#39681850">root</a><span>|</span><a href="#39686156">parent</a><span>|</span><a href="#39684813">next</a><span>|</span><label class="collapse" for="c-39686681">[-]</label><label class="expand" for="c-39686681">[2 more]</label></div><br/><div class="children"><div class="content">Yeah, Google buys servers in public datacenters like those from Equinix. One &quot;region&quot; needn&#x27;t be one datacenter, and sometimes AWS and GCP will even have computers in the same facility. It&#x27;s actually quite annoying that &quot;region&quot; is such an opaque construct and they don&#x27;t have any clear way to identify what physical building is hosting the hardware you rent from them.</div><br/><div id="39686946" class="c"><input type="checkbox" id="c-39686946" checked=""/><div class="controls bullet"><span class="by">the-rc</span><span>|</span><a href="#39681850">root</a><span>|</span><a href="#39686681">parent</a><span>|</span><a href="#39684813">next</a><span>|</span><label class="collapse" for="c-39686946">[-]</label><label class="expand" for="c-39686946">[1 more]</label></div><br/><div class="children"><div class="content">Those are almost lost in the noise,  compared to the big datacenters. (I&#x27;ve been inside two Atlanta facilities, one leased and one built from scratch, and the old Savvis one in Sunnyvale).</div><br/></div></div></div></div></div></div></div></div><div id="39684813" class="c"><input type="checkbox" id="c-39684813" checked=""/><div class="controls bullet"><span class="by">karmasimida</span><span>|</span><a href="#39681850">root</a><span>|</span><a href="#39684319">parent</a><span>|</span><a href="#39685924">prev</a><span>|</span><a href="#39685151">next</a><span>|</span><label class="collapse" for="c-39684813">[-]</label><label class="expand" for="c-39684813">[2 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think so, AWS hasn&#x27;t disclosed this numbers, like datacenter spaces occupied, so how do you know.</div><br/><div id="39685860" class="c"><input type="checkbox" id="c-39685860" checked=""/><div class="controls bullet"><span class="by">virtuallynathan</span><span>|</span><a href="#39681850">root</a><span>|</span><a href="#39684813">parent</a><span>|</span><a href="#39685151">next</a><span>|</span><label class="collapse" for="c-39685860">[-]</label><label class="expand" for="c-39685860">[1 more]</label></div><br/><div class="children"><div class="content">I have mapped every AWS data center globally, and I worked at AWS.<p>Facebook publishes this data.</div><br/></div></div></div></div><div id="39685151" class="c"><input type="checkbox" id="c-39685151" checked=""/><div class="controls bullet"><span class="by">pgwhalen</span><span>|</span><a href="#39681850">root</a><span>|</span><a href="#39684319">parent</a><span>|</span><a href="#39684813">prev</a><span>|</span><a href="#39684428">next</a><span>|</span><label class="collapse" for="c-39685151">[-]</label><label class="expand" for="c-39685151">[2 more]</label></div><br/><div class="children"><div class="content">I have zero evidence, but this seems extremely unlikely.  Do you have more than zero evidence?</div><br/><div id="39685810" class="c"><input type="checkbox" id="c-39685810" checked=""/><div class="controls bullet"><span class="by">meiraleal</span><span>|</span><a href="#39681850">root</a><span>|</span><a href="#39685151">parent</a><span>|</span><a href="#39684428">next</a><span>|</span><label class="collapse" for="c-39685810">[-]</label><label class="expand" for="c-39685810">[1 more]</label></div><br/><div class="children"><div class="content">Meta can use all their datacenter space while Amazon, Google, and Microsoft datacenter space is mostly rented.</div><br/></div></div></div></div><div id="39684428" class="c"><input type="checkbox" id="c-39684428" checked=""/><div class="controls bullet"><span class="by">dsp</span><span>|</span><a href="#39681850">root</a><span>|</span><a href="#39684319">parent</a><span>|</span><a href="#39685151">prev</a><span>|</span><a href="#39682690">next</a><span>|</span><label class="collapse" for="c-39684428">[-]</label><label class="expand" for="c-39684428">[1 more]</label></div><br/><div class="children"><div class="content">[citation needed]</div><br/></div></div></div></div></div></div><div id="39682690" class="c"><input type="checkbox" id="c-39682690" checked=""/><div class="controls bullet"><span class="by">rthnbgrredf</span><span>|</span><a href="#39681850">parent</a><span>|</span><a href="#39682648">prev</a><span>|</span><a href="#39684675">next</a><span>|</span><label class="collapse" for="c-39682690">[-]</label><label class="expand" for="c-39682690">[11 more]</label></div><br/><div class="children"><div class="content">Meta could build their own cloud offering. But it would take years to match the current existing offerings of AWS, Azure and GCP in terms of scale and wide range of cloud solutions.</div><br/><div id="39683978" class="c"><input type="checkbox" id="c-39683978" checked=""/><div class="controls bullet"><span class="by">Cthulhu_</span><span>|</span><a href="#39681850">root</a><span>|</span><a href="#39682690">parent</a><span>|</span><a href="#39683892">next</a><span>|</span><label class="collapse" for="c-39683978">[-]</label><label class="expand" for="c-39683978">[1 more]</label></div><br/><div class="children"><div class="content">And then there&#x27;s sales. All of those three - and more you haven&#x27;t considered, like the Chinese mega-IT companies - spend huge amounts on training, partnerships, consultancy, etc to get companies to use their services instead of their competitors. My current employer seems all-in on Azure, previous one was AWS.<p>There was one manager who worked at two large Dutch companies and sold AWS to them, as in, moving their entire IT, workloads and servers over to AWS. I wouldn&#x27;t be surprised if there was a deal made there somewhere.</div><br/></div></div><div id="39683892" class="c"><input type="checkbox" id="c-39683892" checked=""/><div class="controls bullet"><span class="by">oblio</span><span>|</span><a href="#39681850">root</a><span>|</span><a href="#39682690">parent</a><span>|</span><a href="#39683978">prev</a><span>|</span><a href="#39683072">next</a><span>|</span><label class="collapse" for="c-39683892">[-]</label><label class="expand" for="c-39683892">[8 more]</label></div><br/><div class="children"><div class="content">The real question is: why aren&#x27;t they? They had the infrastructure needed to seed a cloud offering 10 years ago. Heck, if Oracle managed to be in 5th (6th? 7th?) place, Facebook for sure could have been a top 5 contender, at least.</div><br/><div id="39688615" class="c"><input type="checkbox" id="c-39688615" checked=""/><div class="controls bullet"><span class="by">krschultz</span><span>|</span><a href="#39681850">root</a><span>|</span><a href="#39683892">parent</a><span>|</span><a href="#39686625">next</a><span>|</span><label class="collapse" for="c-39688615">[-]</label><label class="expand" for="c-39688615">[2 more]</label></div><br/><div class="children"><div class="content">Because they make more money using their servers for their own products than they would renting them to other people. Meta has an operating margin of 41% AFTER they burn a ton on Reality Labs, while AWS has a 21% margin with more disciplined spending. Social media is a more profitable business than infrastructure.</div><br/><div id="39688732" class="c"><input type="checkbox" id="c-39688732" checked=""/><div class="controls bullet"><span class="by">elbear</span><span>|</span><a href="#39681850">root</a><span>|</span><a href="#39688615">parent</a><span>|</span><a href="#39686625">next</a><span>|</span><label class="collapse" for="c-39688732">[-]</label><label class="expand" for="c-39688732">[1 more]</label></div><br/><div class="children"><div class="content">Does Meta make money from anything other than ads? It&#x27;s not a dismissive question. I&#x27;m curious if social media implies anything other than ads.</div><br/></div></div></div></div><div id="39686625" class="c"><input type="checkbox" id="c-39686625" checked=""/><div class="controls bullet"><span class="by">Thaxll</span><span>|</span><a href="#39681850">root</a><span>|</span><a href="#39683892">parent</a><span>|</span><a href="#39688615">prev</a><span>|</span><a href="#39684037">next</a><span>|</span><label class="collapse" for="c-39686625">[-]</label><label class="expand" for="c-39686625">[1 more]</label></div><br/><div class="children"><div class="content">Because it&#x27;s not their business, they&#x27;re not good at it and probably the ROI is not worth it.<p>Also how exactly they would do it, they don&#x27;t have enough infra for renting, they would need to x10 what they have now.</div><br/></div></div><div id="39684037" class="c"><input type="checkbox" id="c-39684037" checked=""/><div class="controls bullet"><span class="by">KaiserPro</span><span>|</span><a href="#39681850">root</a><span>|</span><a href="#39683892">parent</a><span>|</span><a href="#39686625">prev</a><span>|</span><a href="#39683072">next</a><span>|</span><label class="collapse" for="c-39684037">[-]</label><label class="expand" for="c-39684037">[4 more]</label></div><br/><div class="children"><div class="content">because meta sucks at software, documentation and making sure end user products work in a supported way.<p>Offering reliable IaaS is super hard and capital intensive. Its also not profitable if you are perceived as shit.</div><br/><div id="39684463" class="c"><input type="checkbox" id="c-39684463" checked=""/><div class="controls bullet"><span class="by">logicchains</span><span>|</span><a href="#39681850">root</a><span>|</span><a href="#39684037">parent</a><span>|</span><a href="#39683072">next</a><span>|</span><label class="collapse" for="c-39684463">[-]</label><label class="expand" for="c-39684463">[3 more]</label></div><br/><div class="children"><div class="content">&gt;because meta sucks at software<p>Google started a cloud and their user-facing software is atrocious. Compared e.g. Angular to React, Tensorflow to Pytorch.</div><br/><div id="39685981" class="c"><input type="checkbox" id="c-39685981" checked=""/><div class="controls bullet"><span class="by">negus</span><span>|</span><a href="#39681850">root</a><span>|</span><a href="#39684463">parent</a><span>|</span><a href="#39683072">next</a><span>|</span><label class="collapse" for="c-39685981">[-]</label><label class="expand" for="c-39685981">[2 more]</label></div><br/><div class="children"><div class="content">Why would you prefer Pytorch to Tensorflow&#x2F;Keras?</div><br/><div id="39686247" class="c"><input type="checkbox" id="c-39686247" checked=""/><div class="controls bullet"><span class="by">chessgecko</span><span>|</span><a href="#39681850">root</a><span>|</span><a href="#39685981">parent</a><span>|</span><a href="#39683072">next</a><span>|</span><label class="collapse" for="c-39686247">[-]</label><label class="expand" for="c-39686247">[1 more]</label></div><br/><div class="children"><div class="content">Tensorflow and keras have gotten better, but pytorch historically had better flexibility than keras and was much easier to debug&#x2F;develop in than tensorflow.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="39683072" class="c"><input type="checkbox" id="c-39683072" checked=""/><div class="controls bullet"><span class="by">bionhoward</span><span>|</span><a href="#39681850">root</a><span>|</span><a href="#39682690">parent</a><span>|</span><a href="#39683892">prev</a><span>|</span><a href="#39684675">next</a><span>|</span><label class="collapse" for="c-39683072">[-]</label><label class="expand" for="c-39683072">[1 more]</label></div><br/><div class="children"><div class="content">aww, those existing offerings are overcomplicated as hell, a fresh look could yield substantially simpler cloud developer experience and this would compete well against those other cloud offerings on simplicity alone</div><br/></div></div></div></div><div id="39684675" class="c"><input type="checkbox" id="c-39684675" checked=""/><div class="controls bullet"><span class="by">redleader55</span><span>|</span><a href="#39681850">parent</a><span>|</span><a href="#39682690">prev</a><span>|</span><a href="#39683430">next</a><span>|</span><label class="collapse" for="c-39684675">[-]</label><label class="expand" for="c-39684675">[1 more]</label></div><br/><div class="children"><div class="content">For consumers, AI could just be stateless &quot;micro service&quot;. Meta already has enough surfaces where customers can interact with AI.</div><br/></div></div><div id="39683430" class="c"><input type="checkbox" id="c-39683430" checked=""/><div class="controls bullet"><span class="by">crowcroft</span><span>|</span><a href="#39681850">parent</a><span>|</span><a href="#39684675">prev</a><span>|</span><a href="#39682167">next</a><span>|</span><label class="collapse" for="c-39683430">[-]</label><label class="expand" for="c-39683430">[2 more]</label></div><br/><div class="children"><div class="content">I think Meta have avoided doing this because it would complicate their business priorities. They don’t really do B2B.</div><br/><div id="39684717" class="c"><input type="checkbox" id="c-39684717" checked=""/><div class="controls bullet"><span class="by">carlossouza</span><span>|</span><a href="#39681850">root</a><span>|</span><a href="#39683430">parent</a><span>|</span><a href="#39682167">next</a><span>|</span><label class="collapse" for="c-39684717">[-]</label><label class="expand" for="c-39684717">[1 more]</label></div><br/><div class="children"><div class="content">What do you mean by “they don’t do B2B”? They sell ads to companies, don’t they?</div><br/></div></div></div></div></div></div><div id="39682167" class="c"><input type="checkbox" id="c-39682167" checked=""/><div class="controls bullet"><span class="by">elwell</span><span>|</span><a href="#39681850">prev</a><span>|</span><a href="#39687089">next</a><span>|</span><label class="collapse" for="c-39682167">[-]</label><label class="expand" for="c-39682167">[6 more]</label></div><br/><div class="children"><div class="content">&gt; Meta’s long-term vision is to build artificial general intelligence (AGI)</div><br/><div id="39686546" class="c"><input type="checkbox" id="c-39686546" checked=""/><div class="controls bullet"><span class="by">valzam</span><span>|</span><a href="#39682167">parent</a><span>|</span><a href="#39687089">next</a><span>|</span><label class="collapse" for="c-39686546">[-]</label><label class="expand" for="c-39686546">[5 more]</label></div><br/><div class="children"><div class="content">Don&#x27;t worry, this goal will change with the next hype cycle</div><br/><div id="39687249" class="c"><input type="checkbox" id="c-39687249" checked=""/><div class="controls bullet"><span class="by">latchkey</span><span>|</span><a href="#39682167">root</a><span>|</span><a href="#39686546">parent</a><span>|</span><a href="#39687089">next</a><span>|</span><label class="collapse" for="c-39687249">[-]</label><label class="expand" for="c-39687249">[4 more]</label></div><br/><div class="children"><div class="content">I pity the fools that think AI is just another internet hype cycle.</div><br/><div id="39687798" class="c"><input type="checkbox" id="c-39687798" checked=""/><div class="controls bullet"><span class="by">brookst</span><span>|</span><a href="#39682167">root</a><span>|</span><a href="#39687249">parent</a><span>|</span><a href="#39687089">next</a><span>|</span><label class="collapse" for="c-39687798">[-]</label><label class="expand" for="c-39687798">[3 more]</label></div><br/><div class="children"><div class="content">I’m old enough to remember the proud, defiant declarations that the <i>internet</i> was just a hype cycle.</div><br/><div id="39688606" class="c"><input type="checkbox" id="c-39688606" checked=""/><div class="controls bullet"><span class="by">bennyelv</span><span>|</span><a href="#39682167">root</a><span>|</span><a href="#39687798">parent</a><span>|</span><a href="#39687896">next</a><span>|</span><label class="collapse" for="c-39688606">[-]</label><label class="expand" for="c-39688606">[1 more]</label></div><br/><div class="children"><div class="content">Well it <i>was</i> wasn’t it?  There was a massive boom where loads of companies over promised what they would achieve, followed by a crash when everyone realised lots of them couldn’t, followed by stability for the smaller number that could.<p>It was the very definition of a hype cycle as far as I can see.  Hype cycle doesn’t mean “useless and will go away”, you have the second upward curve and then productivity.<p><a href="https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Gartner_hype_cycle" rel="nofollow">https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Gartner_hype_cycle</a></div><br/></div></div><div id="39687896" class="c"><input type="checkbox" id="c-39687896" checked=""/><div class="controls bullet"><span class="by">latchkey</span><span>|</span><a href="#39682167">root</a><span>|</span><a href="#39687798">parent</a><span>|</span><a href="#39688606">prev</a><span>|</span><a href="#39687089">next</a><span>|</span><label class="collapse" for="c-39687896">[-]</label><label class="expand" for="c-39687896">[1 more]</label></div><br/><div class="children"><div class="content">I got my first email in 1991 and started my first internet business in 1995 (a web dev shop). My entire life has been an endless hype cycle.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="39687089" class="c"><input type="checkbox" id="c-39687089" checked=""/><div class="controls bullet"><span class="by">spencerchubb</span><span>|</span><a href="#39682167">prev</a><span>|</span><a href="#39681605">next</a><span>|</span><label class="collapse" for="c-39687089">[-]</label><label class="expand" for="c-39687089">[6 more]</label></div><br/><div class="children"><div class="content">All this compute and my Instagram Reels feed still isn&#x27;t as good as my TikTok feed</div><br/><div id="39687325" class="c"><input type="checkbox" id="c-39687325" checked=""/><div class="controls bullet"><span class="by">zeroonetwothree</span><span>|</span><a href="#39687089">parent</a><span>|</span><a href="#39681605">next</a><span>|</span><label class="collapse" for="c-39687325">[-]</label><label class="expand" for="c-39687325">[5 more]</label></div><br/><div class="children"><div class="content">What does that have to do with Gen AI</div><br/><div id="39687791" class="c"><input type="checkbox" id="c-39687791" checked=""/><div class="controls bullet"><span class="by">lmm</span><span>|</span><a href="#39687089">root</a><span>|</span><a href="#39687325">parent</a><span>|</span><a href="#39687434">next</a><span>|</span><label class="collapse" for="c-39687791">[-]</label><label class="expand" for="c-39687791">[1 more]</label></div><br/><div class="children"><div class="content">If Gen AI <i>doesn&#x27;t</i> have anything to do with &quot;Meta&quot;&#x27;s actual business then WTF are they setting all this money on fire for?</div><br/></div></div><div id="39687434" class="c"><input type="checkbox" id="c-39687434" checked=""/><div class="controls bullet"><span class="by">spencerchubb</span><span>|</span><a href="#39687089">root</a><span>|</span><a href="#39687325">parent</a><span>|</span><a href="#39687791">prev</a><span>|</span><a href="#39681605">next</a><span>|</span><label class="collapse" for="c-39687434">[-]</label><label class="expand" for="c-39687434">[3 more]</label></div><br/><div class="children"><div class="content">GenAI infra is the same as regular AI infra. They used GenAI in the title because it&#x27;s a buzzword.</div><br/><div id="39687510" class="c"><input type="checkbox" id="c-39687510" checked=""/><div class="controls bullet"><span class="by">ipsum2</span><span>|</span><a href="#39687089">root</a><span>|</span><a href="#39687434">parent</a><span>|</span><a href="#39687558">next</a><span>|</span><label class="collapse" for="c-39687510">[-]</label><label class="expand" for="c-39687510">[1 more]</label></div><br/><div class="children"><div class="content">Not really. Ranking and recommendation models require different infrastructure than LLMs. The models are generally smaller and require more data processing before training.</div><br/></div></div><div id="39687558" class="c"><input type="checkbox" id="c-39687558" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#39687089">root</a><span>|</span><a href="#39687434">parent</a><span>|</span><a href="#39687510">prev</a><span>|</span><a href="#39681605">next</a><span>|</span><label class="collapse" for="c-39687558">[-]</label><label class="expand" for="c-39687558">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, no.</div><br/></div></div></div></div></div></div></div></div><div id="39681605" class="c"><input type="checkbox" id="c-39681605" checked=""/><div class="controls bullet"><span class="by">mjburgess</span><span>|</span><a href="#39687089">prev</a><span>|</span><a href="#39682068">next</a><span>|</span><label class="collapse" for="c-39681605">[-]</label><label class="expand" for="c-39681605">[21 more]</label></div><br/><div class="children"><div class="content">I&#x27;d be great if they could invest in an alternative to nvidia -- then, in one fell swoop, destroy the moats of everyone in the industry.</div><br/><div id="39681758" class="c"><input type="checkbox" id="c-39681758" checked=""/><div class="controls bullet"><span class="by">math_dandy</span><span>|</span><a href="#39681605">parent</a><span>|</span><a href="#39681896">next</a><span>|</span><label class="collapse" for="c-39681758">[-]</label><label class="expand" for="c-39681758">[6 more]</label></div><br/><div class="children"><div class="content">A company moving away from Nvidia&#x2F;CUDA while the field is developing so rapidly would result in that company falling behind. When (if) the rate of progress in the AI space slows, then perhaps the big players will have the breathing room to consider rethinking foundational components of their infrastructure. But even at that point, their massive investment in Nvidia will likely render this impractical. Nvidia decisively won the AI hardware lottery, and that&#x27;s why it&#x27;s worth trillions.</div><br/><div id="39682475" class="c"><input type="checkbox" id="c-39682475" checked=""/><div class="controls bullet"><span class="by">whiplash451</span><span>|</span><a href="#39681605">root</a><span>|</span><a href="#39681758">parent</a><span>|</span><a href="#39682288">next</a><span>|</span><label class="collapse" for="c-39682475">[-]</label><label class="expand" for="c-39682475">[3 more]</label></div><br/><div class="children"><div class="content">People said the same thing when tensorflow was all the rage and pytorch was a side project.<p>Granted, HW is much harder than SW, but I would not discount Meta&#x27;s ability to displace NVIDIA entirely.</div><br/><div id="39683998" class="c"><input type="checkbox" id="c-39683998" checked=""/><div class="controls bullet"><span class="by">Cthulhu_</span><span>|</span><a href="#39681605">root</a><span>|</span><a href="#39682475">parent</a><span>|</span><a href="#39682288">next</a><span>|</span><label class="collapse" for="c-39683998">[-]</label><label class="expand" for="c-39683998">[2 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think they could; nvidia has tons of talent, Meta would have to steal that. Meta doesn&#x27;t do anything in either consumer or datacenter hardware that isn&#x27;t for themselves either.<p>Meta is a services company, their hardware is secondary and for their own usage.</div><br/><div id="39685866" class="c"><input type="checkbox" id="c-39685866" checked=""/><div class="controls bullet"><span class="by">Wazako</span><span>|</span><a href="#39681605">root</a><span>|</span><a href="#39683998">parent</a><span>|</span><a href="#39682288">next</a><span>|</span><label class="collapse" for="c-39685866">[-]</label><label class="expand" for="c-39685866">[1 more]</label></div><br/><div class="children"><div class="content">meta has the Quest.
It&#x27;s not so bad that they&#x27;re looking to create an LPU for their headset to offer local play.</div><br/></div></div></div></div></div></div><div id="39682288" class="c"><input type="checkbox" id="c-39682288" checked=""/><div class="controls bullet"><span class="by">mjburgess</span><span>|</span><a href="#39681605">root</a><span>|</span><a href="#39681758">parent</a><span>|</span><a href="#39682475">prev</a><span>|</span><a href="#39681896">next</a><span>|</span><label class="collapse" for="c-39682288">[-]</label><label class="expand" for="c-39682288">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m more concerned to avoid nvidia (et al.) market domination, than chasing the top-edge of the genAI benefits sigmoid. This will prevent much broad-based innovation.</div><br/><div id="39682630" class="c"><input type="checkbox" id="c-39682630" checked=""/><div class="controls bullet"><span class="by">hx8</span><span>|</span><a href="#39681605">root</a><span>|</span><a href="#39682288">parent</a><span>|</span><a href="#39681896">next</a><span>|</span><label class="collapse" for="c-39682630">[-]</label><label class="expand" for="c-39682630">[1 more]</label></div><br/><div class="children"><div class="content">This space is so compeitive, even if Nvidia is asleep at the wheel a competitor will come and push them before too long.  AMD has a history of noticing when their competitors are going soft and rapidly being compeitive.</div><br/></div></div></div></div></div></div><div id="39681896" class="c"><input type="checkbox" id="c-39681896" checked=""/><div class="controls bullet"><span class="by">paxys</span><span>|</span><a href="#39681605">parent</a><span>|</span><a href="#39681758">prev</a><span>|</span><a href="#39682064">next</a><span>|</span><label class="collapse" for="c-39681896">[-]</label><label class="expand" for="c-39681896">[2 more]</label></div><br/><div class="children"><div class="content">Except that &quot;one fell swoop&quot; would realistically be 20+ years of research and development from the top minds in the semiconductor industry.</div><br/><div id="39684491" class="c"><input type="checkbox" id="c-39684491" checked=""/><div class="controls bullet"><span class="by">logicchains</span><span>|</span><a href="#39681605">root</a><span>|</span><a href="#39681896">parent</a><span>|</span><a href="#39682064">next</a><span>|</span><label class="collapse" for="c-39684491">[-]</label><label class="expand" for="c-39684491">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not the hardware keeping NVidia ahead, it&#x27;s the software. Hardware-wise AMD is competitive with NVidia, but their lack of a competitive CUDA alternative is hurting adoption.</div><br/></div></div></div></div><div id="39682064" class="c"><input type="checkbox" id="c-39682064" checked=""/><div class="controls bullet"><span class="by">brucethemoose2</span><span>|</span><a href="#39681605">parent</a><span>|</span><a href="#39681896">prev</a><span>|</span><a href="#39681818">next</a><span>|</span><label class="collapse" for="c-39682064">[-]</label><label class="expand" for="c-39682064">[1 more]</label></div><br/><div class="children"><div class="content">Facebook very specifically bought and customized Intel SKUs tailored for AI workloads for some time.</div><br/></div></div><div id="39681818" class="c"><input type="checkbox" id="c-39681818" checked=""/><div class="controls bullet"><span class="by">John23832</span><span>|</span><a href="#39681605">parent</a><span>|</span><a href="#39682064">prev</a><span>|</span><a href="#39681908">next</a><span>|</span><label class="collapse" for="c-39681818">[-]</label><label class="expand" for="c-39681818">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;engineering.fb.com&#x2F;2023&#x2F;10&#x2F;18&#x2F;ml-applications&#x2F;meta-ai-custom-silicon-olivia-wu&#x2F;" rel="nofollow">https:&#x2F;&#x2F;engineering.fb.com&#x2F;2023&#x2F;10&#x2F;18&#x2F;ml-applications&#x2F;meta-a...</a></div><br/></div></div><div id="39681908" class="c"><input type="checkbox" id="c-39681908" checked=""/><div class="controls bullet"><span class="by">aeyes</span><span>|</span><a href="#39681605">parent</a><span>|</span><a href="#39681818">prev</a><span>|</span><a href="#39682068">next</a><span>|</span><label class="collapse" for="c-39681908">[-]</label><label class="expand" for="c-39681908">[10 more]</label></div><br/><div class="children"><div class="content">Isn&#x27;t Google trying to do this with their TPUs?</div><br/><div id="39682315" class="c"><input type="checkbox" id="c-39682315" checked=""/><div class="controls bullet"><span class="by">crakenzak</span><span>|</span><a href="#39681605">root</a><span>|</span><a href="#39681908">parent</a><span>|</span><a href="#39682068">next</a><span>|</span><label class="collapse" for="c-39682315">[-]</label><label class="expand" for="c-39682315">[9 more]</label></div><br/><div class="children"><div class="content">I still, for the life of me, can&#x27;t understand why Google doesn&#x27;t just start selling their TPUs to everyone. Nvidia wouldn&#x27;t be anywhere near their size if they only made H100s available through their DGX cloud, which is what Google is doing only making TPUs available through Google Cloud.<p>Good hardware, good software support, and market is starving for performant competitors to the H100s (and soon B100s). Would sell like hotcakes.</div><br/><div id="39682914" class="c"><input type="checkbox" id="c-39682914" checked=""/><div class="controls bullet"><span class="by">aseipp</span><span>|</span><a href="#39681605">root</a><span>|</span><a href="#39682315">parent</a><span>|</span><a href="#39685284">next</a><span>|</span><label class="collapse" for="c-39682914">[-]</label><label class="expand" for="c-39682914">[1 more]</label></div><br/><div class="children"><div class="content">It is an absolutely massive amount of work to turn something designed for your custom software stack and data centers (custom rack designs, water cooling, etc) into a COTS product that is plug-and-play; not just technically but also things like sales, support, etc. You are introducing a massive amount of new problems to solve and pay for. And the in-house designs like TPUs (or Meta&#x27;s accelerators) are cost effective in part because they <i>don&#x27;t</i> do that stuff at all. They would not be as cheap per unit of work if they had to also pay off all that other stuff. They also have had a very strong demand for TPUs internally which takes priority over GCP.</div><br/></div></div><div id="39685284" class="c"><input type="checkbox" id="c-39685284" checked=""/><div class="controls bullet"><span class="by">dekhn</span><span>|</span><a href="#39681605">root</a><span>|</span><a href="#39682315">parent</a><span>|</span><a href="#39682914">prev</a><span>|</span><a href="#39682610">next</a><span>|</span><label class="collapse" for="c-39685284">[-]</label><label class="expand" for="c-39685284">[3 more]</label></div><br/><div class="children"><div class="content">Do you mean, sell TPU hardware to other companies that would run it in their data centers?  I can&#x27;t imagine that would ever really work.  The only reason TPUs work at Google is because they have huge teams across many different areas to keep them running (SRE, hardware repair, SWE, hardware infra) and it&#x27;s coupled to the design of the data centers.  To vend and externalize the software would require google to setup similar teams for external customers (well beyond what Google Cloud provides for TPUs today) just to eke out some margin of profit.  Plus, there is a whole proprietary stack running under the hood that google wouldn&#x27;t want to share with potential competitors.<p>Google used to sell a search appliance-in-a-box and eventually lost interest because hardware is so high-touch.</div><br/><div id="39685791" class="c"><input type="checkbox" id="c-39685791" checked=""/><div class="controls bullet"><span class="by">aeyes</span><span>|</span><a href="#39681605">root</a><span>|</span><a href="#39685284">parent</a><span>|</span><a href="#39682610">next</a><span>|</span><label class="collapse" for="c-39685791">[-]</label><label class="expand" for="c-39685791">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Google used to sell a search appliance-in-a-box and eventually lost interest because hardware is so high-touch.<p>We had a GSA for intranet search and other than the paint this was a standard Dell server. I remember not being impressed by what the GSA could do.<p>We also had Google Urchin for web analytics, it wasn&#x27;t a hardware appliance but the product wasn&#x27;t very impressive either. They then killed that and tried to get you onto Google Analytics.<p>They just didn&#x27;t commit to these on premise enterprise products.</div><br/><div id="39686012" class="c"><input type="checkbox" id="c-39686012" checked=""/><div class="controls bullet"><span class="by">dekhn</span><span>|</span><a href="#39681605">root</a><span>|</span><a href="#39685791">parent</a><span>|</span><a href="#39682610">next</a><span>|</span><label class="collapse" for="c-39686012">[-]</label><label class="expand" for="c-39686012">[1 more]</label></div><br/><div class="children"><div class="content">The server may have been dell, but it included a full stack of google3 software including chubby the lockserver.<p>We had one at my company and it was widely loved- far better intranet search and domain-specific search for biotech.</div><br/></div></div></div></div></div></div><div id="39682610" class="c"><input type="checkbox" id="c-39682610" checked=""/><div class="controls bullet"><span class="by">ajcp</span><span>|</span><a href="#39681605">root</a><span>|</span><a href="#39682315">parent</a><span>|</span><a href="#39685284">prev</a><span>|</span><a href="#39682441">next</a><span>|</span><label class="collapse" for="c-39682610">[-]</label><label class="expand" for="c-39682610">[2 more]</label></div><br/><div class="children"><div class="content">And undercut what they&#x27;d like to use as a huge motivator in people moving to GCP? Not likely. Even if they wanted to they can&#x27;t keep up with their own internal demand.<p>Beyond that they might not be as stable or resilient outside of the closely curated confines of their own data-centers. In that case selling them would be more of an embarrassment.</div><br/><div id="39682756" class="c"><input type="checkbox" id="c-39682756" checked=""/><div class="controls bullet"><span class="by">htrp</span><span>|</span><a href="#39681605">root</a><span>|</span><a href="#39682610">parent</a><span>|</span><a href="#39682441">next</a><span>|</span><label class="collapse" for="c-39682756">[-]</label><label class="expand" for="c-39682756">[1 more]</label></div><br/><div class="children"><div class="content">&gt;Beyond that they might not be as stable or resilient outside of the closely curated confines of their own data-centers. In that case selling them would be more of an embarrassment.<p>Once you go out of your heavily curated hardware stack, the headaches multiply exponentially.</div><br/></div></div></div></div><div id="39682441" class="c"><input type="checkbox" id="c-39682441" checked=""/><div class="controls bullet"><span class="by">qiine</span><span>|</span><a href="#39681605">root</a><span>|</span><a href="#39682315">parent</a><span>|</span><a href="#39682610">prev</a><span>|</span><a href="#39683012">next</a><span>|</span><label class="collapse" for="c-39682441">[-]</label><label class="expand" for="c-39682441">[1 more]</label></div><br/><div class="children"><div class="content">Maybe selling hardware to customers worldwide + support like Nvidia does is actually not trivial ?</div><br/></div></div><div id="39683012" class="c"><input type="checkbox" id="c-39683012" checked=""/><div class="controls bullet"><span class="by">neuronexmachina</span><span>|</span><a href="#39681605">root</a><span>|</span><a href="#39682315">parent</a><span>|</span><a href="#39682441">prev</a><span>|</span><a href="#39682068">next</a><span>|</span><label class="collapse" for="c-39683012">[-]</label><label class="expand" for="c-39683012">[1 more]</label></div><br/><div class="children"><div class="content">The impression I got from this thread yesterday is that Google&#x27;s having difficulty keeping up with the heavy internal demand for TPUs: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=39670121">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=39670121</a></div><br/></div></div></div></div></div></div></div></div><div id="39682068" class="c"><input type="checkbox" id="c-39682068" checked=""/><div class="controls bullet"><span class="by">gingergoat</span><span>|</span><a href="#39681605">prev</a><span>|</span><a href="#39683220">next</a><span>|</span><label class="collapse" for="c-39682068">[-]</label><label class="expand" for="c-39682068">[1 more]</label></div><br/><div class="children"><div class="content">The article doesn&#x27;t mention MTIA, meta&#x27;s custom ASIC for training &amp; inference acceleration.
<a href="https:&#x2F;&#x2F;ai.meta.com&#x2F;blog&#x2F;meta-training-inference-accelerator-AI-MTIA&#x2F;" rel="nofollow">https:&#x2F;&#x2F;ai.meta.com&#x2F;blog&#x2F;meta-training-inference-accelerator...</a><p>I wonder if they will use it in RSC.</div><br/></div></div><div id="39683220" class="c"><input type="checkbox" id="c-39683220" checked=""/><div class="controls bullet"><span class="by">wseqyrku</span><span>|</span><a href="#39682068">prev</a><span>|</span><a href="#39682196">next</a><span>|</span><label class="collapse" for="c-39683220">[-]</label><label class="expand" for="c-39683220">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Commitment to open AI innovation<p>I see what you did there, Meta.</div><br/><div id="39683736" class="c"><input type="checkbox" id="c-39683736" checked=""/><div class="controls bullet"><span class="by">owenpalmer</span><span>|</span><a href="#39683220">parent</a><span>|</span><a href="#39682196">next</a><span>|</span><label class="collapse" for="c-39683736">[-]</label><label class="expand" for="c-39683736">[1 more]</label></div><br/><div class="children"><div class="content">Haha, I noticed that too xD</div><br/></div></div></div></div><div id="39682196" class="c"><input type="checkbox" id="c-39682196" checked=""/><div class="controls bullet"><span class="by">latchkey</span><span>|</span><a href="#39683220">prev</a><span>|</span><a href="#39683913">next</a><span>|</span><label class="collapse" for="c-39682196">[-]</label><label class="expand" for="c-39682196">[4 more]</label></div><br/><div class="children"><div class="content">&gt; we have successfully used both RoCE and InfiniBand clusters for large, GenAI workloads (including our ongoing training of Llama 3 on our RoCE cluster) without any network bottlenecks.<p>Interesting dig on IB. RoCE is the right solution since it is open standards and more importantly, available without a 52+ week lead time.</div><br/><div id="39684919" class="c"><input type="checkbox" id="c-39684919" checked=""/><div class="controls bullet"><span class="by">loeg</span><span>|</span><a href="#39682196">parent</a><span>|</span><a href="#39683913">next</a><span>|</span><label class="collapse" for="c-39684919">[-]</label><label class="expand" for="c-39684919">[3 more]</label></div><br/><div class="children"><div class="content">Yeah, and RoCE isn&#x27;t single vendor.  I&#x27;m not sure IB scales to the relevant cluster sizes, either.</div><br/><div id="39685522" class="c"><input type="checkbox" id="c-39685522" checked=""/><div class="controls bullet"><span class="by">anonymousDan</span><span>|</span><a href="#39682196">root</a><span>|</span><a href="#39684919">parent</a><span>|</span><a href="#39683913">next</a><span>|</span><label class="collapse" for="c-39685522">[-]</label><label class="expand" for="c-39685522">[2 more]</label></div><br/><div class="children"><div class="content">Is NVLink just not scalable enough here?</div><br/><div id="39685884" class="c"><input type="checkbox" id="c-39685884" checked=""/><div class="controls bullet"><span class="by">loeg</span><span>|</span><a href="#39682196">root</a><span>|</span><a href="#39685522">parent</a><span>|</span><a href="#39683913">next</a><span>|</span><label class="collapse" for="c-39685884">[-]</label><label class="expand" for="c-39685884">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t know. I haven&#x27;t actually worked with IB in this specific space (or since before Nvidia acquired MLNX).  My experience with RoCE&#x2F;IB was for storage cluster backend in the late 2010s.</div><br/></div></div></div></div></div></div></div></div><div id="39683913" class="c"><input type="checkbox" id="c-39683913" checked=""/><div class="controls bullet"><span class="by">seydor</span><span>|</span><a href="#39682196">prev</a><span>|</span><a href="#39681454">next</a><span>|</span><label class="collapse" for="c-39683913">[-]</label><label class="expand" for="c-39683913">[2 more]</label></div><br/><div class="children"><div class="content">This is great news for Nvidia and their stock, but are they sure the LLMs and image models will scale indefinitely? nature and biology has a preference for sigmoids. What if we find out that AGI requries different kinds of cpu capabilities</div><br/><div id="39685806" class="c"><input type="checkbox" id="c-39685806" checked=""/><div class="controls bullet"><span class="by">jiggawatts</span><span>|</span><a href="#39683913">parent</a><span>|</span><a href="#39681454">next</a><span>|</span><label class="collapse" for="c-39685806">[-]</label><label class="expand" for="c-39685806">[1 more]</label></div><br/><div class="children"><div class="content">If anything, NVIDIA H100 GPUs are <i>too</i> general purpose! The optimal compute for AI training would be more specialised, but then would be efficient at only one NN architecture. Until we know what the best architecture is, the general purpose clusters remain a good strategy.</div><br/></div></div></div></div><div id="39681454" class="c"><input type="checkbox" id="c-39681454" checked=""/><div class="controls bullet"><span class="by">alexsereno</span><span>|</span><a href="#39683913">prev</a><span>|</span><a href="#39684185">next</a><span>|</span><label class="collapse" for="c-39681454">[-]</label><label class="expand" for="c-39681454">[4 more]</label></div><br/><div class="children"><div class="content">Honestly Meta is consistently one of the better companies at releasing tech stack info or just open sourcing, these kinds of articles are super fun</div><br/><div id="39681588" class="c"><input type="checkbox" id="c-39681588" checked=""/><div class="controls bullet"><span class="by">rshm</span><span>|</span><a href="#39681454">parent</a><span>|</span><a href="#39681507">next</a><span>|</span><label class="collapse" for="c-39681588">[-]</label><label class="expand" for="c-39681588">[1 more]</label></div><br/><div class="children"><div class="content">I think some elements of this stack might flow into the open compute.</div><br/></div></div><div id="39681507" class="c"><input type="checkbox" id="c-39681507" checked=""/><div class="controls bullet"><span class="by">adamnemecek</span><span>|</span><a href="#39681454">parent</a><span>|</span><a href="#39681588">prev</a><span>|</span><a href="#39684185">next</a><span>|</span><label class="collapse" for="c-39681507">[-]</label><label class="expand" for="c-39681507">[2 more]</label></div><br/><div class="children"><div class="content">Do you find this informative?</div><br/><div id="39682924" class="c"><input type="checkbox" id="c-39682924" checked=""/><div class="controls bullet"><span class="by">alexsereno</span><span>|</span><a href="#39681454">root</a><span>|</span><a href="#39681507">parent</a><span>|</span><a href="#39684185">next</a><span>|</span><label class="collapse" for="c-39682924">[-]</label><label class="expand" for="c-39682924">[1 more]</label></div><br/><div class="children"><div class="content">Yes of course - it depends on what lens though. If you mean &quot;I&#x27;m learning to build better from this&quot; then no, but its very informative on Meta&#x27;s own goals and mindset as well as real numbers that allow comparison to investment in other areas, etc. Also the point was mostly that Meta does publish a lot in the open - including actual open source tech stacks etc. They&#x27;re reasonably good actors in this specific domain.</div><br/></div></div></div></div></div></div><div id="39684185" class="c"><input type="checkbox" id="c-39684185" checked=""/><div class="controls bullet"><span class="by">pinko</span><span>|</span><a href="#39681454">prev</a><span>|</span><a href="#39683462">next</a><span>|</span><label class="collapse" for="c-39684185">[-]</label><label class="expand" for="c-39684185">[3 more]</label></div><br/><div class="children"><div class="content">The link mentions &quot;our internal job scheduler&quot; and how they had to optimize it for this work -- does anyone know what this job scheduler is called, or how it works?</div><br/><div id="39684431" class="c"><input type="checkbox" id="c-39684431" checked=""/><div class="controls bullet"><span class="by">KaiserPro</span><span>|</span><a href="#39684185">parent</a><span>|</span><a href="#39683462">next</a><span>|</span><label class="collapse" for="c-39684431">[-]</label><label class="expand" for="c-39684431">[2 more]</label></div><br/><div class="children"><div class="content">it might be twine: 
<a href="https:&#x2F;&#x2F;www.usenix.org&#x2F;system&#x2F;files&#x2F;osdi20-tang.pdf" rel="nofollow">https:&#x2F;&#x2F;www.usenix.org&#x2F;system&#x2F;files&#x2F;osdi20-tang.pdf</a><p>but I suspect its not that, because Twine is optimised for services rather than batch processing, and doesn&#x27;t really have the concept of priorities.</div><br/><div id="39685702" class="c"><input type="checkbox" id="c-39685702" checked=""/><div class="controls bullet"><span class="by">radicality</span><span>|</span><a href="#39684185">root</a><span>|</span><a href="#39684431">parent</a><span>|</span><a href="#39683462">next</a><span>|</span><label class="collapse" for="c-39685702">[-]</label><label class="expand" for="c-39685702">[1 more]</label></div><br/><div class="children"><div class="content">I would think it’s probably that. Also, has this been renamed to Twine from Tupperware?</div><br/></div></div></div></div></div></div><div id="39683462" class="c"><input type="checkbox" id="c-39683462" checked=""/><div class="controls bullet"><span class="by">mrkramer</span><span>|</span><a href="#39684185">prev</a><span>|</span><a href="#39687357">next</a><span>|</span><label class="collapse" for="c-39683462">[-]</label><label class="expand" for="c-39683462">[3 more]</label></div><br/><div class="children"><div class="content">&quot;Share this: Hacker News&quot; Noice</div><br/><div id="39683629" class="c"><input type="checkbox" id="c-39683629" checked=""/><div class="controls bullet"><span class="by">BonoboIO</span><span>|</span><a href="#39683462">parent</a><span>|</span><a href="#39687357">next</a><span>|</span><label class="collapse" for="c-39683629">[-]</label><label class="expand" for="c-39683629">[2 more]</label></div><br/><div class="children"><div class="content">I thought at first &quot;what are you talking about&quot;, when i check my uBlock filters. 
Was blocking the whole &quot;Share this&quot; content section.<p>Sharing on Hacker News ... they now their audience.</div><br/><div id="39684148" class="c"><input type="checkbox" id="c-39684148" checked=""/><div class="controls bullet"><span class="by">mrkramer</span><span>|</span><a href="#39683462">root</a><span>|</span><a href="#39683629">parent</a><span>|</span><a href="#39687357">next</a><span>|</span><label class="collapse" for="c-39684148">[-]</label><label class="expand" for="c-39684148">[1 more]</label></div><br/><div class="children"><div class="content">I also use uBlock but my filters are the default ones and I saw it without any problem but tbh this is the first time that I saw some post on the Web have HN as a share option or the first time that I was surprised seeing it. Maybe it has something to do with Google ranking &quot;trusted human information and knowledge&quot; higher than &quot;non-human&quot; information and knowledge[0] or simply some Meta software engineer loves and uses HN so s&#x2F;he decided to include HN as well, idk.<p>[0] <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=39423949">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=39423949</a></div><br/></div></div></div></div></div></div><div id="39687357" class="c"><input type="checkbox" id="c-39687357" checked=""/><div class="controls bullet"><span class="by">sashank_1509</span><span>|</span><a href="#39683462">prev</a><span>|</span><a href="#39682138">next</a><span>|</span><label class="collapse" for="c-39687357">[-]</label><label class="expand" for="c-39687357">[3 more]</label></div><br/><div class="children"><div class="content">Metas backing itself into a corner with its admirable commitment to open source. Unfortunately, at some point when they decide to monetize their billions spent and try to release a closed source model, the level of vitriol they will deal with will be an order of magnitude above what even OpenAI is experiencing. I don’t think they realize that!</div><br/><div id="39687414" class="c"><input type="checkbox" id="c-39687414" checked=""/><div class="controls bullet"><span class="by">bigcat12345678</span><span>|</span><a href="#39687357">parent</a><span>|</span><a href="#39687392">next</a><span>|</span><label class="collapse" for="c-39687414">[-]</label><label class="expand" for="c-39687414">[1 more]</label></div><br/><div class="children"><div class="content">No<p>Meta&#x27;s commitment to Open Source is well under calculation.<p>OCP is a way to rally lower-tier vendors to form a semi-alliance to keep up with super-gorilla like AWS &amp; Google.<p>LLaMA has already gained much more than its cost (look at the stock price, and the open source ecosystem built surrounding LLaMA, and Google&#x27;s open source Gemma models which is a proof of Meta&#x27;s success).<p>IMHO, Meta&#x27;s Open Source strategy already covered at least 5 years in prospect. That&#x27;s enough to finesse a 180 degree turn around if necessary (i.e., from open source to close source)</div><br/></div></div><div id="39687392" class="c"><input type="checkbox" id="c-39687392" checked=""/><div class="controls bullet"><span class="by">Horffupolde</span><span>|</span><a href="#39687357">parent</a><span>|</span><a href="#39687414">prev</a><span>|</span><a href="#39682138">next</a><span>|</span><label class="collapse" for="c-39687392">[-]</label><label class="expand" for="c-39687392">[1 more]</label></div><br/><div class="children"><div class="content">The general public doesn’t care. Only developers.</div><br/></div></div></div></div><div id="39682138" class="c"><input type="checkbox" id="c-39682138" checked=""/><div class="controls bullet"><span class="by">zerop</span><span>|</span><a href="#39687357">prev</a><span>|</span><a href="#39682002">next</a><span>|</span><label class="collapse" for="c-39682138">[-]</label><label class="expand" for="c-39682138">[5 more]</label></div><br/><div class="children"><div class="content">&gt; At Meta, we handle hundreds of trillions of AI model executions per day<p>Such a large number, makes sense?</div><br/><div id="39682487" class="c"><input type="checkbox" id="c-39682487" checked=""/><div class="controls bullet"><span class="by">GeneralMayhem</span><span>|</span><a href="#39682138">parent</a><span>|</span><a href="#39682856">next</a><span>|</span><label class="collapse" for="c-39682487">[-]</label><label class="expand" for="c-39682487">[1 more]</label></div><br/><div class="children"><div class="content">Sure. 100T&#x2F;day * 1day&#x2F;86400sec ~= 1B&#x2F;sec. They&#x27;re probably considering at least a few hundred candidates per impression, and every impression is going to go through _at least_ two models (relevance and pCTR&#x2F;revenue), so you could get there just with online serving at 5Mqps, which is plausible. But they&#x27;re also going to be doing a lot of stuff in batch - spam predictions, ad budget forecasts, etc - so that every candidate actually runs through four or five different models, and every actual impression could do more than that.</div><br/></div></div><div id="39682856" class="c"><input type="checkbox" id="c-39682856" checked=""/><div class="controls bullet"><span class="by">sangnoir</span><span>|</span><a href="#39682138">parent</a><span>|</span><a href="#39682487">prev</a><span>|</span><a href="#39682844">next</a><span>|</span><label class="collapse" for="c-39682856">[-]</label><label class="expand" for="c-39682856">[1 more]</label></div><br/><div class="children"><div class="content">How many ads does Meta serve a day, and how many AI model executions are done for each one? Repeat the same for stories, post and comment recommendations on Facebook and Instagram, and you have <i>very</i> big numbers. To that, Add VR, internal modeling and other backoffice&#x2F; offline analyses over billions of users and you&#x27;ll easily get into the trillions.</div><br/></div></div><div id="39682844" class="c"><input type="checkbox" id="c-39682844" checked=""/><div class="controls bullet"><span class="by">dakiol</span><span>|</span><a href="#39682138">parent</a><span>|</span><a href="#39682856">prev</a><span>|</span><a href="#39682170">next</a><span>|</span><label class="collapse" for="c-39682844">[-]</label><label class="expand" for="c-39682844">[1 more]</label></div><br/><div class="children"><div class="content">What&#x27;s an &quot;AI model execution&quot;? When I ask something to ChatGPT and it answers to me, does that count as 1 &quot;AI model execution&quot; for OpenAI?</div><br/></div></div><div id="39682170" class="c"><input type="checkbox" id="c-39682170" checked=""/><div class="controls bullet"><span class="by">pants2</span><span>|</span><a href="#39682138">parent</a><span>|</span><a href="#39682844">prev</a><span>|</span><a href="#39682002">next</a><span>|</span><label class="collapse" for="c-39682170">[-]</label><label class="expand" for="c-39682170">[1 more]</label></div><br/><div class="children"><div class="content">Perhaps there&#x27;s some combinatorics where every time an ad or post is displayed to the user, it runs through some hundreds&#x2F;thousands of candidates and computes their relevance.</div><br/></div></div></div></div><div id="39682002" class="c"><input type="checkbox" id="c-39682002" checked=""/><div class="controls bullet"><span class="by">hendersoon</span><span>|</span><a href="#39682138">prev</a><span>|</span><a href="#39682981">next</a><span>|</span><label class="collapse" for="c-39682002">[-]</label><label class="expand" for="c-39682002">[31 more]</label></div><br/><div class="children"><div class="content">350k H100 cards, around ten <i>billion</i> dollars just for the GPUs. Less if Nvidia gives a volume discount, which I imagine they do not.</div><br/><div id="39682118" class="c"><input type="checkbox" id="c-39682118" checked=""/><div class="controls bullet"><span class="by">renegade-otter</span><span>|</span><a href="#39682002">parent</a><span>|</span><a href="#39682981">next</a><span>|</span><label class="collapse" for="c-39682118">[-]</label><label class="expand" for="c-39682118">[30 more]</label></div><br/><div class="children"><div class="content">It will be ironic if Meta sinks all this money into the new trend and finds out later that it has been a huge boondoggle, just as publishers followed Facebook&#x27;s &quot;guidance&quot; on video being the future, subsequently gutting the talent pool and investing into video production and staff - only to find out it was all a total waste.</div><br/><div id="39682175" class="c"><input type="checkbox" id="c-39682175" checked=""/><div class="controls bullet"><span class="by">motoxpro</span><span>|</span><a href="#39682002">root</a><span>|</span><a href="#39682118">parent</a><span>|</span><a href="#39682536">next</a><span>|</span><label class="collapse" for="c-39682175">[-]</label><label class="expand" for="c-39682175">[2 more]</label></div><br/><div class="children"><div class="content">It already paid off. When the world moved from determinisic to probablistic ad modeling. That&#x27;s why their numbers are so good right now compared to every other advertiser</div><br/><div id="39685523" class="c"><input type="checkbox" id="c-39685523" checked=""/><div class="controls bullet"><span class="by">blitzar</span><span>|</span><a href="#39682002">root</a><span>|</span><a href="#39682175">parent</a><span>|</span><a href="#39682536">next</a><span>|</span><label class="collapse" for="c-39685523">[-]</label><label class="expand" for="c-39685523">[1 more]</label></div><br/><div class="children"><div class="content">It already paid off. FB stonk price is up lots.</div><br/></div></div></div></div><div id="39682536" class="c"><input type="checkbox" id="c-39682536" checked=""/><div class="controls bullet"><span class="by">foobarian</span><span>|</span><a href="#39682002">root</a><span>|</span><a href="#39682118">parent</a><span>|</span><a href="#39682175">prev</a><span>|</span><a href="#39682197">next</a><span>|</span><label class="collapse" for="c-39682536">[-]</label><label class="expand" for="c-39682536">[1 more]</label></div><br/><div class="children"><div class="content">There is still hope then for cheap gaming GPUs some day soon!  I have pretty much the last 10 years of flagship releases to catch up on...</div><br/></div></div><div id="39682197" class="c"><input type="checkbox" id="c-39682197" checked=""/><div class="controls bullet"><span class="by">tayo42</span><span>|</span><a href="#39682002">root</a><span>|</span><a href="#39682118">parent</a><span>|</span><a href="#39682536">prev</a><span>|</span><a href="#39682164">next</a><span>|</span><label class="collapse" for="c-39682197">[-]</label><label class="expand" for="c-39682197">[6 more]</label></div><br/><div class="children"><div class="content">What does video not be in the future mean? In social media tiktok and reels are everywhere?</div><br/><div id="39682481" class="c"><input type="checkbox" id="c-39682481" checked=""/><div class="controls bullet"><span class="by">michaelt</span><span>|</span><a href="#39682002">root</a><span>|</span><a href="#39682197">parent</a><span>|</span><a href="#39682495">next</a><span>|</span><label class="collapse" for="c-39682481">[-]</label><label class="expand" for="c-39682481">[2 more]</label></div><br/><div class="children"><div class="content">There are reports [1] that a bunch of companies like &quot;College Humor&quot; were convinced to switch to producing native video for facebook (instead of directing users to their own sites) on the basis of bullshit metrics from facebook, and had an extremely bad time as a result, with some companies going bankrupt.<p>Something like counting an autoplaying video that ran for 3 seconds as a &#x27;view&#x27; IIRC<p>[1] <a href="https:&#x2F;&#x2F;twitter.com&#x2F;adamconover&#x2F;status&#x2F;1183209875859333120" rel="nofollow">https:&#x2F;&#x2F;twitter.com&#x2F;adamconover&#x2F;status&#x2F;1183209875859333120</a></div><br/><div id="39682527" class="c"><input type="checkbox" id="c-39682527" checked=""/><div class="controls bullet"><span class="by">scubbo</span><span>|</span><a href="#39682002">root</a><span>|</span><a href="#39682481">parent</a><span>|</span><a href="#39682495">next</a><span>|</span><label class="collapse" for="c-39682527">[-]</label><label class="expand" for="c-39682527">[1 more]</label></div><br/><div class="children"><div class="content">Thankfully, Dropout (a spin-off of College Humor) is alive and well, and producing some of the best D&amp;D Actual Play series as well as other non-D&amp;D comedy shows. One of the entertainment services that I happily pay for because I want to support what they&#x27;re doing.</div><br/></div></div></div></div><div id="39682495" class="c"><input type="checkbox" id="c-39682495" checked=""/><div class="controls bullet"><span class="by">neon_electro</span><span>|</span><a href="#39682002">root</a><span>|</span><a href="#39682197">parent</a><span>|</span><a href="#39682481">prev</a><span>|</span><a href="#39682164">next</a><span>|</span><label class="collapse" for="c-39682495">[-]</label><label class="expand" for="c-39682495">[3 more]</label></div><br/><div class="children"><div class="content">They are referring to Facebook&#x2F;Meta’s 2015 “pivot to video”, speculating there may be a similar thing happening more recently with AI.<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Pivot_to_video" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Pivot_to_video</a></div><br/><div id="39683105" class="c"><input type="checkbox" id="c-39683105" checked=""/><div class="controls bullet"><span class="by">neuronexmachina</span><span>|</span><a href="#39682002">root</a><span>|</span><a href="#39682495">parent</a><span>|</span><a href="#39682735">next</a><span>|</span><label class="collapse" for="c-39683105">[-]</label><label class="expand" for="c-39683105">[1 more]</label></div><br/><div class="children"><div class="content">TIL. Reading up on it a little, I&#x27;m surprised the class-action settlement was just $40M: <a href="https:&#x2F;&#x2F;www.videoadvertisingsettlement.com&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.videoadvertisingsettlement.com&#x2F;</a></div><br/></div></div><div id="39682735" class="c"><input type="checkbox" id="c-39682735" checked=""/><div class="controls bullet"><span class="by">tayo42</span><span>|</span><a href="#39682002">root</a><span>|</span><a href="#39682495">parent</a><span>|</span><a href="#39683105">prev</a><span>|</span><a href="#39682164">next</a><span>|</span><label class="collapse" for="c-39682735">[-]</label><label class="expand" for="c-39682735">[1 more]</label></div><br/><div class="children"><div class="content">Interesting thanks!<p>Feels like in hind sight, maybe they were just to early to it.</div><br/></div></div></div></div></div></div><div id="39682191" class="c"><input type="checkbox" id="c-39682191" checked=""/><div class="controls bullet"><span class="by">echelon</span><span>|</span><a href="#39682002">root</a><span>|</span><a href="#39682118">parent</a><span>|</span><a href="#39682164">prev</a><span>|</span><a href="#39682981">next</a><span>|</span><label class="collapse" for="c-39682191">[-]</label><label class="expand" for="c-39682191">[19 more]</label></div><br/><div class="children"><div class="content">As a practitioner in the field, I can assure you this is not a boondoggle.<p>Those GPUs are going to subsume the entire music, film, and gaming industries. And that&#x27;s just to start.</div><br/><div id="39682579" class="c"><input type="checkbox" id="c-39682579" checked=""/><div class="controls bullet"><span class="by">__loam</span><span>|</span><a href="#39682002">root</a><span>|</span><a href="#39682191">parent</a><span>|</span><a href="#39682981">next</a><span>|</span><label class="collapse" for="c-39682579">[-]</label><label class="expand" for="c-39682579">[18 more]</label></div><br/><div class="children"><div class="content">&quot;My paycheck depends on this technology destroying every field producing cultural artifacts&quot;</div><br/><div id="39682772" class="c"><input type="checkbox" id="c-39682772" checked=""/><div class="controls bullet"><span class="by">echelon</span><span>|</span><a href="#39682002">root</a><span>|</span><a href="#39682579">parent</a><span>|</span><a href="#39682981">next</a><span>|</span><label class="collapse" for="c-39682772">[-]</label><label class="expand" for="c-39682772">[17 more]</label></div><br/><div class="children"><div class="content">Said the butter churner, cotton ginner, and petrol pumper.<p>I work in film. I&#x27;ve shot dozens of them the old fashioned way. I&#x27;ve always hated how labor, time, and cost intensive they are to make.<p>Despite instructions from the luminaries to &quot;just pick up a camera&quot;, the entire process is stone age. The field is extremely inequitable, full of nepotism and &quot;who you know&quot;. Almost every starry-eyed film student winds up doing drudge work for the rest of their lives. Most will never make a feature to match their ambition.<p>If the whole task was to simply convey my thoughts and dreams to others, why am I scrambling around to sign location rights, capture photons on expensive glass, and then smear and splice things together for months on end? This is ceremonial and soon to be anachronistic. I&#x27;m glad that whole mess is going to be replaced. It&#x27;s a farce.<p>To phrase it another way - would you like to be hand-writing assembly on punch cards? To only gain entrance into the field with your mathematics PhD?<p>To speak of the liberty and the economics, why should I have to sell the rights to my idea to a studio so I can get it off the ground? Why should I have to obey the studio&#x27;s rules and mind their interference?<p>This whole Gen AI thing is going to be the biggest liberating moment for filmmaking creatives. I know, because I am one.<p>And if you think any Jack or Jill can just come in and text prompt a whole movie, you&#x27;re crazy. It&#x27;s still hard work and a metric ton of good taste.<p>Art will never die. It&#x27;s the human soul. It&#x27;ll take more than some tech bros with GPUs to kill it.<p>AI is just another tool for the artist. A &quot;bicycle for the mind&quot; to quote Jobs, and a rocket ship for the imagination to convey my own direct experience.</div><br/><div id="39687919" class="c"><input type="checkbox" id="c-39687919" checked=""/><div class="controls bullet"><span class="by">lmm</span><span>|</span><a href="#39682002">root</a><span>|</span><a href="#39682772">parent</a><span>|</span><a href="#39683816">next</a><span>|</span><label class="collapse" for="c-39687919">[-]</label><label class="expand" for="c-39687919">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Said the butter churner, cotton ginner, and petrol pumper.<p>Said the bank teller, record producer, etc.. Plenty of cases where we&#x27;ve been told technology and automation would democratise the field and remove the middleman, and actually it&#x27;s the opposite.<p>Yes, it would be nice if AI made it easy for anyone who wanted to make a great movie. That doesn&#x27;t mean it&#x27;s going to happen.</div><br/></div></div><div id="39683816" class="c"><input type="checkbox" id="c-39683816" checked=""/><div class="controls bullet"><span class="by">munificent</span><span>|</span><a href="#39682002">root</a><span>|</span><a href="#39682772">parent</a><span>|</span><a href="#39687919">prev</a><span>|</span><a href="#39688056">next</a><span>|</span><label class="collapse" for="c-39683816">[-]</label><label class="expand" for="c-39683816">[1 more]</label></div><br/><div class="children"><div class="content">Call me crazy, but I don&#x27;t think churning butter and writing a novel are in the same category of human endeavor at all.</div><br/></div></div><div id="39683017" class="c"><input type="checkbox" id="c-39683017" checked=""/><div class="controls bullet"><span class="by">wizzwizz4</span><span>|</span><a href="#39682002">root</a><span>|</span><a href="#39682772">parent</a><span>|</span><a href="#39688056">prev</a><span>|</span><a href="#39685313">next</a><span>|</span><label class="collapse" for="c-39683017">[-]</label><label class="expand" for="c-39683017">[11 more]</label></div><br/><div class="children"><div class="content">&gt; <i>And if you think any Jack or Jill can just come in and text prompt a whole movie, you&#x27;re crazy. It&#x27;s still hard work and a metric ton of good taste.</i><p>If you want anything <i>good</i>, yes. If you just want <i>something</i>… I reckon it&#x27;d take a week to assemble an incomprehensible-nonsense-film pipeline, after which it&#x27;s just a matter of feeding the computer electricity.<p>Short-term, this is going to funnel resources <i>away</i> from the people with good taste. Long-term, it might help collapse the entire &quot;creative industry&quot;, after which we might get some of that artist liberation stuff you&#x27;re talking about – but we might just end up with new gatekeeping strategies from the wealthy and connected, and business as usual.</div><br/><div id="39683181" class="c"><input type="checkbox" id="c-39683181" checked=""/><div class="controls bullet"><span class="by">echelon</span><span>|</span><a href="#39682002">root</a><span>|</span><a href="#39683017">parent</a><span>|</span><a href="#39685313">next</a><span>|</span><label class="collapse" for="c-39683181">[-]</label><label class="expand" for="c-39683181">[10 more]</label></div><br/><div class="children"><div class="content">&gt; If you want anything good, yes. If you just want something ...<p>You don&#x27;t even need AI for that.<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;YouTube_poop" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;YouTube_poop</a><p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Skibidi_Toilet" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Skibidi_Toilet</a><p>The idea that AI isn&#x27;t going to be used as a creative tool too and that it won&#x27;t lead to more and better art is a defeatist, Luddite attitude.<p>Similarly shaped people thought that digital cameras would ruin cinema and photography.<p>&gt; Short-term, this is going to funnel resources away from the people with good taste.<p>On the contrary - every budding film student will soon [1] be able to execute on their entire visions straight out of the gates. No decades of clawing their way to a very limited, almost impossible to reach peak.<p>&gt; it might help collapse the entire &quot;creative industry&quot;<p>The studio system. Not the industry.<p>&gt; new gatekeeping strategies from the wealthy and connected, and business as usual.<p>Creatives have more ways of building brands and followings for themselves than ever before. It&#x27;s one of the largest growing sectors of the economy, and lots of people are earning livings off of it.<p>You&#x27;ll be able to follow that steampunk vampire creator that&#x27;s been missing from the world until now. Every long tail interest will be catered to. Even the most obscure and wild tastes, ideas, and designs. Stuff that would never get studio funding.<p>As a creative, I&#x27;m overjoyed by this. My friends and I are getting to create things we never could make before [2].<p>[1] This and next year.<p>[2] Just an inspiration &#x2F; aesthetic sample, but we&#x27;re making a full film: <a href="https:&#x2F;&#x2F;imgur.com&#x2F;a&#x2F;JNVnJIn" rel="nofollow">https:&#x2F;&#x2F;imgur.com&#x2F;a&#x2F;JNVnJIn</a></div><br/><div id="39684333" class="c"><input type="checkbox" id="c-39684333" checked=""/><div class="controls bullet"><span class="by">crmd</span><span>|</span><a href="#39682002">root</a><span>|</span><a href="#39683181">parent</a><span>|</span><a href="#39688880">next</a><span>|</span><label class="collapse" for="c-39684333">[-]</label><label class="expand" for="c-39684333">[5 more]</label></div><br/><div class="children"><div class="content">&gt;You&#x27;ll be able to follow that steampunk vampire creator that&#x27;s been missing from the world until now. Every long tail interest will be catered to. Even the most obscure and wild tastes, ideas, and designs. Stuff that would never get studio funding.<p>Your optimism reminds me of the optimism I had around the early internet. Power to the people, long tail, rise of the creative class, the fall of gatekeeping corporations, etc.<p>It was like that for a couple of years in the late 90s before power and control got vastly more centralized than before. Maybe this time it’ll be different.</div><br/><div id="39685019" class="c"><input type="checkbox" id="c-39685019" checked=""/><div class="controls bullet"><span class="by">munificent</span><span>|</span><a href="#39682002">root</a><span>|</span><a href="#39684333">parent</a><span>|</span><a href="#39688880">next</a><span>|</span><label class="collapse" for="c-39685019">[-]</label><label class="expand" for="c-39685019">[4 more]</label></div><br/><div class="children"><div class="content">The big difference is that back then, anyone with a consumer-level computer in their bedroom could turn it into a server and be a first-class citizen on the Internet.<p>With generative AI, models will be controlled by a handful of giant corporations who have the enormous corpuses (of dubious provenance) and compute ability to train them.<p>So it will be like last time, but even worse.</div><br/><div id="39685142" class="c"><input type="checkbox" id="c-39685142" checked=""/><div class="controls bullet"><span class="by">echelon</span><span>|</span><a href="#39682002">root</a><span>|</span><a href="#39685019">parent</a><span>|</span><a href="#39688880">next</a><span>|</span><label class="collapse" for="c-39685142">[-]</label><label class="expand" for="c-39685142">[3 more]</label></div><br/><div class="children"><div class="content">You can run ComfyUI and AnimateDiff on your PC. If you haven&#x27;t checked them out, please do.<p>And there are other angles to consider. Apple, for one, is expressly interested in not becoming a thin client to cloud AI. They&#x27;re baking a lot of inference power into their chips. If the creative class don&#x27;t need their devices, that doesn&#x27;t bode well for them...</div><br/><div id="39685412" class="c"><input type="checkbox" id="c-39685412" checked=""/><div class="controls bullet"><span class="by">munificent</span><span>|</span><a href="#39682002">root</a><span>|</span><a href="#39685142">parent</a><span>|</span><a href="#39688880">next</a><span>|</span><label class="collapse" for="c-39685412">[-]</label><label class="expand" for="c-39685412">[2 more]</label></div><br/><div class="children"><div class="content">Running local models isn&#x27;t the same as being able to train them from scratch yourself on a corpus of your own choosing.</div><br/><div id="39685518" class="c"><input type="checkbox" id="c-39685518" checked=""/><div class="controls bullet"><span class="by">echelon</span><span>|</span><a href="#39682002">root</a><span>|</span><a href="#39685412">parent</a><span>|</span><a href="#39688880">next</a><span>|</span><label class="collapse" for="c-39685518">[-]</label><label class="expand" for="c-39685518">[1 more]</label></div><br/><div class="children"><div class="content">There are so many ways to do exactly this too!<p>FakeYou, CivitAi, WeightsGg, Comflowy, ... -- there are tons of vibrant communities to teach you everything you need to know. The tools are open source, free to use, and accessible.<p>This isn&#x27;t hard at all once you dive in.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="39688880" class="c"><input type="checkbox" id="c-39688880" checked=""/><div class="controls bullet"><span class="by">MrScruff</span><span>|</span><a href="#39682002">root</a><span>|</span><a href="#39683181">parent</a><span>|</span><a href="#39684333">prev</a><span>|</span><a href="#39683967">next</a><span>|</span><label class="collapse" for="c-39688880">[-]</label><label class="expand" for="c-39688880">[1 more]</label></div><br/><div class="children"><div class="content">Are you talking about some as yet unseen research&#x2F;technology? The aesthetic sample looks like something we could have seen on the SD subreddit for the last year.</div><br/></div></div><div id="39683967" class="c"><input type="checkbox" id="c-39683967" checked=""/><div class="controls bullet"><span class="by">renegade-otter</span><span>|</span><a href="#39682002">root</a><span>|</span><a href="#39683181">parent</a><span>|</span><a href="#39688880">prev</a><span>|</span><a href="#39684435">next</a><span>|</span><label class="collapse" for="c-39683967">[-]</label><label class="expand" for="c-39683967">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Similarly shaped people thought that digital cameras would ruin cinema and photography.<p>Obviously, but you seem to be arguing that AI is just another evolution of productivity tools. You still need to have a photographer&#x27;s eye while using this technology.<p>If you couldn&#x27;t make a good composition on film, a digicam will not save you, and it definitely did not <i>replace</i> photographers. Perhaps lowered the barrier of entry for prosumers.<p><a href="https:&#x2F;&#x2F;www.nytimes.com&#x2F;2023&#x2F;12&#x2F;26&#x2F;opinion&#x2F;ai-future-photography.html?smid=nytcore-android-share" rel="nofollow">https:&#x2F;&#x2F;www.nytimes.com&#x2F;2023&#x2F;12&#x2F;26&#x2F;opinion&#x2F;ai-future-photogr...</a></div><br/><div id="39684168" class="c"><input type="checkbox" id="c-39684168" checked=""/><div class="controls bullet"><span class="by">echelon</span><span>|</span><a href="#39682002">root</a><span>|</span><a href="#39683967">parent</a><span>|</span><a href="#39684435">next</a><span>|</span><label class="collapse" for="c-39684168">[-]</label><label class="expand" for="c-39684168">[1 more]</label></div><br/><div class="children"><div class="content">We&#x27;re arguing the same point. :)</div><br/></div></div></div></div><div id="39684435" class="c"><input type="checkbox" id="c-39684435" checked=""/><div class="controls bullet"><span class="by">wizzwizz4</span><span>|</span><a href="#39682002">root</a><span>|</span><a href="#39683181">parent</a><span>|</span><a href="#39683967">prev</a><span>|</span><a href="#39685313">next</a><span>|</span><label class="collapse" for="c-39684435">[-]</label><label class="expand" for="c-39684435">[1 more]</label></div><br/><div class="children"><div class="content">Many YouTube Poops are artistic expression (e.g. <a href="https:&#x2F;&#x2F;redirect.invidious.io&#x2F;watch?v=dO4eIEvHjSw" rel="nofollow">https:&#x2F;&#x2F;redirect.invidious.io&#x2F;watch?v=dO4eIEvHjSw</a>). Skibidi Toilet is <i>definitely</i> artistic expression: it&#x27;s a full-on <i>epic</i>. (Reactions from one ≈50-year-old: “baffling” “how did they do that?” “why would anyone make this?”)<p>If you think the Luddites were defeatist, you don&#x27;t know much about the Luddites.<p>&gt; <i>On the contrary - every budding film student will soon [1] be able to execute on their entire visions straight out of the gates.</i> […] <i>Creatives have more ways of building brands and followings for themselves than ever before.</i><p>Yet, we have no shortage of starving artists. Will AI provide them food and shelter?<p>This is unequivocally a win for creative expression <i>for hobbyists</i>, but it stands to harm professionals – at least in the short term, perhaps longer-term. It&#x27;s not happening in a vacuum: the greedy are revoking livelihoods because they think AI can do it faster and cheaper (laundering appropriated hobbyist and increasingly-cheap professional labour).<p>&gt; <i>The studio system. Not the industry.</i><p>Huh, the word &#x27;industry&#x27; has a specialised meaning in economics. Didn&#x27;t know that.</div><br/></div></div></div></div></div></div><div id="39685313" class="c"><input type="checkbox" id="c-39685313" checked=""/><div class="controls bullet"><span class="by">dist-epoch</span><span>|</span><a href="#39682002">root</a><span>|</span><a href="#39682772">parent</a><span>|</span><a href="#39683017">prev</a><span>|</span><a href="#39682989">next</a><span>|</span><label class="collapse" for="c-39685313">[-]</label><label class="expand" for="c-39685313">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The field is extremely inequitable, full of nepotism and &quot;who you know&quot;<p>Maybe, but it&#x27;s never been cheaper to make a movie.<p>I know someone with no connections and (almost) no money which in 4 years made multiple no. 1 box-office films (obviously not in US, in a smaller country) and then got picked up by Netflix.</div><br/></div></div><div id="39682989" class="c"><input type="checkbox" id="c-39682989" checked=""/><div class="controls bullet"><span class="by">sangnoir</span><span>|</span><a href="#39682002">root</a><span>|</span><a href="#39682772">parent</a><span>|</span><a href="#39685313">prev</a><span>|</span><a href="#39682981">next</a><span>|</span><label class="collapse" for="c-39682989">[-]</label><label class="expand" for="c-39682989">[1 more]</label></div><br/><div class="children"><div class="content">&gt; And if you think any Jack or Jill can just come in and text prompt a whole movie, you&#x27;re crazy. It&#x27;s still hard work and a metric ton of good taste.<p>Yeah, I cant wait for ChuChuTV to get the best film Oscar &#x2F;s.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="39682981" class="c"><input type="checkbox" id="c-39682981" checked=""/><div class="controls bullet"><span class="by">ilaksh</span><span>|</span><a href="#39682002">prev</a><span>|</span><a href="#39683382">next</a><span>|</span><label class="collapse" for="c-39682981">[-]</label><label class="expand" for="c-39682981">[1 more]</label></div><br/><div class="children"><div class="content">&quot;Everything You Wanted to Know About GenAI at Meta, Except the One Thing You Honestly Care About&quot; (Llama 3).</div><br/></div></div><div id="39683382" class="c"><input type="checkbox" id="c-39683382" checked=""/><div class="controls bullet"><span class="by">dekhn</span><span>|</span><a href="#39682981">prev</a><span>|</span><a href="#39681570">next</a><span>|</span><label class="collapse" for="c-39683382">[-]</label><label class="expand" for="c-39683382">[1 more]</label></div><br/><div class="children"><div class="content">it&#x27;s really interesting just how similar these systems are to the designs adopted for HPC over the past few decades.  I&#x27;m salty because it took a while for the ML community to converge on this (20+K GPUs connected by a real fabric with low latency and high bandwidth).</div><br/></div></div><div id="39681570" class="c"><input type="checkbox" id="c-39681570" checked=""/><div class="controls bullet"><span class="by">marmaduke</span><span>|</span><a href="#39683382">prev</a><span>|</span><a href="#39683308">next</a><span>|</span><label class="collapse" for="c-39681570">[-]</label><label class="expand" for="c-39681570">[1 more]</label></div><br/><div class="children"><div class="content">Just for comparison, Swiss CSCS  new Alps system will get 5k GH200 nodes (each with a H100).</div><br/></div></div><div id="39683308" class="c"><input type="checkbox" id="c-39683308" checked=""/><div class="controls bullet"><span class="by">delanyoyoko</span><span>|</span><a href="#39681570">prev</a><span>|</span><a href="#39682086">next</a><span>|</span><label class="collapse" for="c-39683308">[-]</label><label class="expand" for="c-39683308">[2 more]</label></div><br/><div class="children"><div class="content">You&#x27;ve got to read &quot;open&quot; roughly 3x in a paragraph.</div><br/><div id="39684243" class="c"><input type="checkbox" id="c-39684243" checked=""/><div class="controls bullet"><span class="by">papichulo2023</span><span>|</span><a href="#39683308">parent</a><span>|</span><a href="#39682086">next</a><span>|</span><label class="collapse" for="c-39684243">[-]</label><label class="expand" for="c-39684243">[1 more]</label></div><br/><div class="children"><div class="content">If they release models I dont care honestly, they can brag about that as much as they want.</div><br/></div></div></div></div><div id="39682086" class="c"><input type="checkbox" id="c-39682086" checked=""/><div class="controls bullet"><span class="by">dazhbog</span><span>|</span><a href="#39683308">prev</a><span>|</span><a href="#39681741">next</a><span>|</span><label class="collapse" for="c-39682086">[-]</label><label class="expand" for="c-39682086">[2 more]</label></div><br/><div class="children"><div class="content">Searched H100 and an Amazon link popped up. Good reviews.<p><a href="https:&#x2F;&#x2F;www.amazon.com&#x2F;Tesla-NVIDIA-Learning-Compute-Graphics&#x2F;dp&#x2F;B0C3XH4QSJ#customerReviews" rel="nofollow">https:&#x2F;&#x2F;www.amazon.com&#x2F;Tesla-NVIDIA-Learning-Compute-Graphic...</a></div><br/><div id="39683241" class="c"><input type="checkbox" id="c-39683241" checked=""/><div class="controls bullet"><span class="by">mejutoco</span><span>|</span><a href="#39682086">parent</a><span>|</span><a href="#39681741">next</a><span>|</span><label class="collapse" for="c-39683241">[-]</label><label class="expand" for="c-39683241">[1 more]</label></div><br/><div class="children"><div class="content">Those reviews are hilarious</div><br/></div></div></div></div><div id="39681741" class="c"><input type="checkbox" id="c-39681741" checked=""/><div class="controls bullet"><span class="by">lvl102</span><span>|</span><a href="#39682086">prev</a><span>|</span><a href="#39687059">next</a><span>|</span><label class="collapse" for="c-39681741">[-]</label><label class="expand" for="c-39681741">[1 more]</label></div><br/><div class="children"><div class="content">This reads more like a flex for the investment community.</div><br/></div></div></div></div></div></div></div></body></html>