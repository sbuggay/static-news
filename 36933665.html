<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1690794075142" as="style"/><link rel="stylesheet" href="styles.css?v=1690794075142"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://resources.nvidia.com/en-us-dgx-gh200/technical-white-paper">Nvidia DGX GH200 Whitepaper</a> <span class="domain">(<a href="https://resources.nvidia.com">resources.nvidia.com</a>)</span></div><div class="subtext"><span>volta87</span> | <span>44 comments</span></div><br/><div><div id="36935662" class="c"><input type="checkbox" id="c-36935662" checked=""/><div class="controls bullet"><span class="by">tuetuopay</span><span>|</span><a href="#36936738">next</a><span>|</span><label class="collapse" for="c-36935662">[-]</label><label class="expand" for="c-36935662">[5 more]</label></div><br/><div class="children"><div class="content">Why is this called a whitepaper, as this is more of a documentation and architecture overview of the cluster? Wow a CLOS topology for networking, very innovative.<p>Details on NVLink would be great. For example, the needs and problems solved by their custom cables seemingly required by NVLink would be worth a whitepaper.<p>Don&#x27;t get me wrong, this is still great the general public can get a glimpse into Grace Hopper. And they do a good job of simplifying while throwing around mind-boggling numbers (the NVLink bandwidth is insane, though no words on latency, crucial for remote memory access).</div><br/><div id="36937270" class="c"><input type="checkbox" id="c-36937270" checked=""/><div class="controls bullet"><span class="by">mmaunder</span><span>|</span><a href="#36935662">parent</a><span>|</span><a href="#36938421">next</a><span>|</span><label class="collapse" for="c-36937270">[-]</label><label class="expand" for="c-36937270">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Why is this called a whitepaper, as this is more of a documentation and architecture overview of the cluster?<p>That’s what a marketing white paper is and does. It’s not an academic paper.</div><br/><div id="36937811" class="c"><input type="checkbox" id="c-36937811" checked=""/><div class="controls bullet"><span class="by">flakiness</span><span>|</span><a href="#36935662">root</a><span>|</span><a href="#36937270">parent</a><span>|</span><a href="#36938421">next</a><span>|</span><label class="collapse" for="c-36937811">[-]</label><label class="expand" for="c-36937811">[1 more]</label></div><br/><div class="children"><div class="content">To be fair NVIDIA used to publish more detailed &quot;white paper&quot; for their GPUs ex. [1] and CPU textbooks like H&amp;P [2] draws a lot of details from these. This less detailed &quot;whitepaper&quot; still has a scent of these old tradition.<p>[1] <a href="https:&#x2F;&#x2F;www.nvidia.com&#x2F;content&#x2F;PDF&#x2F;nvidia-ampere-ga-102-gpu-architecture-whitepaper-v2.pdf" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.nvidia.com&#x2F;content&#x2F;PDF&#x2F;nvidia-ampere-ga-102-gpu-...</a><p>[2] <a href="https:&#x2F;&#x2F;www.amazon.com&#x2F;Computer-Architecture-Quantitative-John-Hennessy&#x2F;dp&#x2F;012383872X" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.amazon.com&#x2F;Computer-Architecture-Quantitative-Jo...</a></div><br/></div></div></div></div><div id="36938421" class="c"><input type="checkbox" id="c-36938421" checked=""/><div class="controls bullet"><span class="by">callalex</span><span>|</span><a href="#36935662">parent</a><span>|</span><a href="#36937270">prev</a><span>|</span><a href="#36936587">next</a><span>|</span><label class="collapse" for="c-36938421">[-]</label><label class="expand" for="c-36938421">[1 more]</label></div><br/><div class="children"><div class="content">NVDA has spent too much time surrounded by cryptocurrency hacks that published “whitepapers” left and right with zero technical information or innovation. As they say, never get high on your own supply.</div><br/></div></div><div id="36936587" class="c"><input type="checkbox" id="c-36936587" checked=""/><div class="controls bullet"><span class="by">syntaxing</span><span>|</span><a href="#36935662">parent</a><span>|</span><a href="#36938421">prev</a><span>|</span><a href="#36936738">next</a><span>|</span><label class="collapse" for="c-36936587">[-]</label><label class="expand" for="c-36936587">[1 more]</label></div><br/><div class="children"><div class="content">Agreed, seems like an application note more than a white paper.</div><br/></div></div></div></div><div id="36936738" class="c"><input type="checkbox" id="c-36936738" checked=""/><div class="controls bullet"><span class="by">smodad</span><span>|</span><a href="#36935662">prev</a><span>|</span><a href="#36935944">next</a><span>|</span><label class="collapse" for="c-36936738">[-]</label><label class="expand" for="c-36936738">[17 more]</label></div><br/><div class="children"><div class="content">What&#x27;s funny is that even though the DGX GH200 is some of the most powerful hardware available, there&#x27;s such a voracious demand that it&#x27;s not gonna be enough to quench it. In fact, this is one of those cases where I think the demand will always outpace supply. Exciting stuff ahead.<p>I heard Elon say something interesting during the discussion&#x2F;launch of xAI: &quot;My prediction is that we will go from an extreme silicon shortage today, to probably a voltage-transformer shortage in about year, and then an electricity shortage in about a year, two years.&quot;<p>I&#x27;m not sure about the timeline, but it&#x27;s an intriguing idea that soon the rate limiting resource will be electricity. I wonder how true that is and if we&#x27;re prepared for that.</div><br/><div id="36936864" class="c"><input type="checkbox" id="c-36936864" checked=""/><div class="controls bullet"><span class="by">jiggawatts</span><span>|</span><a href="#36936738">parent</a><span>|</span><a href="#36936946">next</a><span>|</span><label class="collapse" for="c-36936864">[-]</label><label class="expand" for="c-36936864">[11 more]</label></div><br/><div class="children"><div class="content">He’s just plain wrong about the electricity usage going up because of AI compute.<p>To a first approximation, the amount of silicon wafers going through fabs globally is constant. We won’t suddenly increase chip manufacturing a hundredfold! There aren’t enough fabs or “tools” like the ASML EUV machines for that.<p>Electricity is used for lots of things, not just compute, and within compute the AI fraction is tiny. We’re ramping up a rounding error to a slightly larger rounding error.<p>What <i>will</i> increase is global energy demand for overall economic activity as manufacturing and industry is accelerated by AIs.<p>Anyone who’s played games like Factorio would know intuitively that the only two real inputs to the economy are raw materials and energy. Increases to manufacturing speed need matching increases to energy supply!</div><br/><div id="36937737" class="c"><input type="checkbox" id="c-36937737" checked=""/><div class="controls bullet"><span class="by">smodad</span><span>|</span><a href="#36936738">root</a><span>|</span><a href="#36936864">parent</a><span>|</span><a href="#36939729">next</a><span>|</span><label class="collapse" for="c-36937737">[-]</label><label class="expand" for="c-36937737">[1 more]</label></div><br/><div class="children"><div class="content">I bet you&#x27;re right. Even if you take into account that a data center is a monster consumer of energy, in the grand scheme of things it&#x27;s not that big. Some back of the envelope math:<p>Global electrical production in 2022 was ~30,000 TWh.[1]<p>If we over-estimate that a hyperscale data-center will consume about 100 MW of power, per year that would be around 876 GWh.[2]<p>Let&#x27;s overestimate again and say that 1,000 new data centers spring up in a year, every year they would consume 876 TWh.<p>Which, is 2.92% of total electricity production. Which given the fact that I overestimated the energy consumption by more than an order of magnitude, I would say the term &quot;rounding error&quot; is accurate.<p>I think the main limiting factor in the near term is going to be chip production capacity. The fabs take so long to spin up, it&#x27;s going to be a while before we can even consider &quot;electricity production&quot; being a limiting factor.<p>[1] <a href="https:&#x2F;&#x2F;yearbook.enerdata.net&#x2F;electricity&#x2F;world-electricity-production-statistics.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;yearbook.enerdata.net&#x2F;electricity&#x2F;world-electricity-...</a>
[2] <a href="https:&#x2F;&#x2F;cc-techgroup.com&#x2F;data-center-energy-consumption&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;cc-techgroup.com&#x2F;data-center-energy-consumption&#x2F;</a></div><br/></div></div><div id="36939729" class="c"><input type="checkbox" id="c-36939729" checked=""/><div class="controls bullet"><span class="by">paskjdfparwerwe</span><span>|</span><a href="#36936738">root</a><span>|</span><a href="#36936864">parent</a><span>|</span><a href="#36937737">prev</a><span>|</span><a href="#36936943">next</a><span>|</span><label class="collapse" for="c-36939729">[-]</label><label class="expand" for="c-36939729">[1 more]</label></div><br/><div class="children"><div class="content">Elon is speaking with all the Eliezur-esque &quot;foom&quot; in mind, where in AI will explode and either kill us or help us take over the Universe (and destroy everything in our way).</div><br/></div></div><div id="36936943" class="c"><input type="checkbox" id="c-36936943" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#36936738">root</a><span>|</span><a href="#36936864">parent</a><span>|</span><a href="#36939729">prev</a><span>|</span><a href="#36936946">next</a><span>|</span><label class="collapse" for="c-36936943">[-]</label><label class="expand" for="c-36936943">[8 more]</label></div><br/><div class="children"><div class="content">A wafer of H100s uses far more electricity than a wafer of [Apple] A16s though.</div><br/><div id="36937391" class="c"><input type="checkbox" id="c-36937391" checked=""/><div class="controls bullet"><span class="by">pclmulqdq</span><span>|</span><a href="#36936738">root</a><span>|</span><a href="#36936943">parent</a><span>|</span><a href="#36937354">next</a><span>|</span><label class="collapse" for="c-36937391">[-]</label><label class="expand" for="c-36937391">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;m pretty sure that&#x27;s actually wrong. Some math:<p>A16 is 200 sq mm of silicon while an H100 is about 800. That means you get about 100-120 A16&#x27;s on a wafer, while you only get ~30 H100&#x27;s (see <a href="https:&#x2F;&#x2F;www.silicon-edge.co.uk&#x2F;j&#x2F;index.php&#x2F;resources&#x2F;die-per-wafer" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.silicon-edge.co.uk&#x2F;j&#x2F;index.php&#x2F;resources&#x2F;die-per...</a>).<p>Let&#x27;s assume yield is 100% to make things easier. The rated max power of the A16 is about 250W, while the H100 is quoted at 700W. Thus, a wafer of A16&#x27;s is about 25-30 kW of power, while a wafer of H100&#x27;s is about 21 kW.<p>Edit: Just clarifying, this is not about the Apple A16, but the Nvidia A16. The mobile process used by the Apple chips is built for much lower performance and power, so I can&#x27;t imagine the two chips being anywhere near comparable - they fill two completely different roles.</div><br/><div id="36937510" class="c"><input type="checkbox" id="c-36937510" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#36936738">root</a><span>|</span><a href="#36937391">parent</a><span>|</span><a href="#36937354">next</a><span>|</span><label class="collapse" for="c-36937510">[-]</label><label class="expand" for="c-36937510">[2 more]</label></div><br/><div class="children"><div class="content">That&#x27;s my point; if silicon demand shits from mobile to AI data centers you can&#x27;t expect energy consumption to be the same.</div><br/><div id="36937928" class="c"><input type="checkbox" id="c-36937928" checked=""/><div class="controls bullet"><span class="by">pclmulqdq</span><span>|</span><a href="#36936738">root</a><span>|</span><a href="#36937510">parent</a><span>|</span><a href="#36937354">next</a><span>|</span><label class="collapse" for="c-36937928">[-]</label><label class="expand" for="c-36937928">[1 more]</label></div><br/><div class="children"><div class="content">Demand right now is not shifting from mobile to datacenter, demand is shifting from &quot;normal&quot; datacenter compute to AI datacenter compute.<p>I think if you had said &quot;AMD Epyc&quot; rather than a mobile chip, that would be a much more apt comparison.  The AI chips are somewhat more power intensive per box, but fairly similar on power&#x2F;area.  It turns out that these silicon processes are fairly uniform in terms of the power&#x2F;area that they can sustain for any kind of workload.<p>Mobile chips are designed for &lt;10% utilization and &quot;rush-to-idle&quot; workloads, and they are not remotely comparable to datacenter silicon (of any kind).</div><br/></div></div></div></div></div></div><div id="36937354" class="c"><input type="checkbox" id="c-36937354" checked=""/><div class="controls bullet"><span class="by">lwneal</span><span>|</span><a href="#36936738">root</a><span>|</span><a href="#36936943">parent</a><span>|</span><a href="#36937391">prev</a><span>|</span><a href="#36936946">next</a><span>|</span><label class="collapse" for="c-36937354">[-]</label><label class="expand" for="c-36937354">[4 more]</label></div><br/><div class="children"><div class="content">An H100 uses up to 350 Watts, while an A16 has a TDP of only 8 W. But, the A16 is a smaller chip (about 108mm vs. the H100&#x27;s 814mm) so you can fit more of them on a wafer. Since a wafer is 300mm in diameter, its area is 70685 mm^2, which would yield 86 H100&#x27;s or 654 A16&#x27;s. [1][2]<p>However, that discounts the waste on the edges of the circular wafer, as well as the chip yield, which will both likely be worse for the larger chip [3]. But, assuming a generous 70% yield by area [4], one wafer&#x27;s worth of H100s all packaged into GPUs and running full blast will use maybe 20 kilowatts, while the same wafer of A16s might use 3.6 kilowatts. Although in practice, the A16s will spend most of their time conserving battery power in your pocket, and even the H100s will spend some of their time idle.<p>TSMC is now producing over 14 million wafers per year. At most 1.2 million of those are on the 3nm node, and not all of that production goes to GPUs. But as an upper bound, if we imagine that all of TSMC&#x27;s wafers could be filled up with nothing but H100 chips, and if all of those H100 chips were immediately put to use running AI 24&#x2F;7, how much additional load could it put on the power grid every year?<p>The answer is, around 280 gigawatts, or if they were running 24&#x2F;7 for a year, about 2500 terawatt-hours. That&#x27;s about 10% of current world electricity consumption! So it&#x27;s not completely implausible to imagine that a huge ramp-up in AI usage might have an effect on the electric grid.<p>*edit: This assumes we&#x27;re talking about the Apple A16 (ie. the difference between phone chips and GPU chips). If we&#x27;re talking about the Nvidia A16 (ie. the difference between current GPU chips and last node&#x27;s GPU chips) see pclmulqdq&#x27;s comment.
⠀<p>[1] <a href="https:&#x2F;&#x2F;nanoreview.net&#x2F;en&#x2F;soc&#x2F;apple-a16-bionic" rel="nofollow noreferrer">https:&#x2F;&#x2F;nanoreview.net&#x2F;en&#x2F;soc&#x2F;apple-a16-bionic</a><p>[2] <a href="https:&#x2F;&#x2F;www.techpowerup.com&#x2F;gpu-specs&#x2F;h100-pcie-80-gb.c3899" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.techpowerup.com&#x2F;gpu-specs&#x2F;h100-pcie-80-gb.c3899</a><p>[3] <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=24185108">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=24185108</a><p>[4] <a href="https:&#x2F;&#x2F;www.extremetech.com&#x2F;computing&#x2F;analyst-tsmc-hitting-55-yields-on-3nm-node-for-apples-a17-bionic-m3-socs" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.extremetech.com&#x2F;computing&#x2F;analyst-tsmc-hitting-5...</a><p>[5] <a href="https:&#x2F;&#x2F;www.tsmc.com&#x2F;english&#x2F;dedicatedFoundry&#x2F;manufacturing&#x2F;fab_capacity" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.tsmc.com&#x2F;english&#x2F;dedicatedFoundry&#x2F;manufacturing&#x2F;...</a><p>[6] <a href="https:&#x2F;&#x2F;www.wolframalpha.com&#x2F;input?i=%2814+million%29+*+%2820+kilowatts%29\\" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.wolframalpha.com&#x2F;input?i=%2814+million%29+*+%282...</a>*</div><br/><div id="36939190" class="c"><input type="checkbox" id="c-36939190" checked=""/><div class="controls bullet"><span class="by">blackoil</span><span>|</span><a href="#36936738">root</a><span>|</span><a href="#36937354">parent</a><span>|</span><a href="#36937404">next</a><span>|</span><label class="collapse" for="c-36939190">[-]</label><label class="expand" for="c-36939190">[1 more]</label></div><br/><div class="children"><div class="content">&gt; At most 1.2 million of those are on the 3nm node<p>1.2 x 30 x 30000($&#x2F;board) ~ 1 trillion $$$. Time for NVDA call.</div><br/></div></div><div id="36937404" class="c"><input type="checkbox" id="c-36937404" checked=""/><div class="controls bullet"><span class="by">pclmulqdq</span><span>|</span><a href="#36936738">root</a><span>|</span><a href="#36937354">parent</a><span>|</span><a href="#36939190">prev</a><span>|</span><a href="#36936946">next</a><span>|</span><label class="collapse" for="c-36937404">[-]</label><label class="expand" for="c-36937404">[2 more]</label></div><br/><div class="children"><div class="content">8 watts for the A16&#x27;s TDP cannot be correct. Your phone CPU has a higher TDP. I saw 250 on Nvidia&#x27;s website as a maximum.<p>Edit: Oh, you are talking about the Apple A16. Those chips are completely different in function, so sure.</div><br/><div id="36939222" class="c"><input type="checkbox" id="c-36939222" checked=""/><div class="controls bullet"><span class="by">adrian_b</span><span>|</span><a href="#36936738">root</a><span>|</span><a href="#36937404">parent</a><span>|</span><a href="#36936946">next</a><span>|</span><label class="collapse" for="c-36939222">[-]</label><label class="expand" for="c-36939222">[1 more]</label></div><br/><div class="children"><div class="content">6 to 8 W is a typical TDP for a mobile phone SoC including the CPU.<p>A few mobile phone chips had a higher TDP, up to 10 W, but those were notorious for overheating and for low battery life.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="36936946" class="c"><input type="checkbox" id="c-36936946" checked=""/><div class="controls bullet"><span class="by">michaelt</span><span>|</span><a href="#36936738">parent</a><span>|</span><a href="#36936864">prev</a><span>|</span><a href="#36938432">next</a><span>|</span><label class="collapse" for="c-36936946">[-]</label><label class="expand" for="c-36936946">[1 more]</label></div><br/><div class="children"><div class="content"><i>&gt; I wonder how true that is</i><p>An Nvidia A100 costs $10000 and consumes 300W.<p>It seems unlikely that anyone could <i>afford</i> the number of A100s needed to create an electricity shortage.<p>If there is an electricity shortage, far more likely that ageing infrastructure and rising demand for air conditioning and electric car charging are to blame.</div><br/></div></div><div id="36938432" class="c"><input type="checkbox" id="c-36938432" checked=""/><div class="controls bullet"><span class="by">callalex</span><span>|</span><a href="#36936738">parent</a><span>|</span><a href="#36936946">prev</a><span>|</span><a href="#36938200">next</a><span>|</span><label class="collapse" for="c-36938432">[-]</label><label class="expand" for="c-36938432">[3 more]</label></div><br/><div class="children"><div class="content">Are there any examples at all about that guy being right about a technology prediction?</div><br/><div id="36938530" class="c"><input type="checkbox" id="c-36938530" checked=""/><div class="controls bullet"><span class="by">kanwisher</span><span>|</span><a href="#36936738">root</a><span>|</span><a href="#36938432">parent</a><span>|</span><a href="#36938200">next</a><span>|</span><label class="collapse" for="c-36938530">[-]</label><label class="expand" for="c-36938530">[2 more]</label></div><br/><div class="children"><div class="content">Electric cars, rocket ships …</div><br/><div id="36938870" class="c"><input type="checkbox" id="c-36938870" checked=""/><div class="controls bullet"><span class="by">losteric</span><span>|</span><a href="#36936738">root</a><span>|</span><a href="#36938530">parent</a><span>|</span><a href="#36938200">next</a><span>|</span><label class="collapse" for="c-36938870">[-]</label><label class="expand" for="c-36938870">[1 more]</label></div><br/><div class="children"><div class="content">Elon&#x27;s timeline predictions in both of those industries <i>for his own companies</i> have been consistently wrong for years. (FSD when??)<p>Given we&#x27;re talking about hardware for software, let&#x27;s at least look at his track record in the software industry... <i>glances at Twitter</i> ah, yeah, not great either.<p>Voltage regulator and electricity shortage from AI growth straight up doesn&#x27;t make sense, it&#x27;s dumber than the stuff he was spouting while &quot;deep-diving&quot; his Twitter misacquisition.</div><br/></div></div></div></div></div></div><div id="36938200" class="c"><input type="checkbox" id="c-36938200" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#36936738">parent</a><span>|</span><a href="#36938432">prev</a><span>|</span><a href="#36935944">next</a><span>|</span><label class="collapse" for="c-36938200">[-]</label><label class="expand" for="c-36938200">[1 more]</label></div><br/><div class="children"><div class="content">i mean he&#x27;s not the only one. sama&#x27;s other big bet is on nuclear fusion. <a href="https:&#x2F;&#x2F;blog.samaltman.com&#x2F;helion" rel="nofollow noreferrer">https:&#x2F;&#x2F;blog.samaltman.com&#x2F;helion</a></div><br/></div></div></div></div><div id="36935944" class="c"><input type="checkbox" id="c-36935944" checked=""/><div class="controls bullet"><span class="by">mmaunder</span><span>|</span><a href="#36936738">prev</a><span>|</span><a href="#36936392">next</a><span>|</span><label class="collapse" for="c-36935944">[-]</label><label class="expand" for="c-36935944">[5 more]</label></div><br/><div class="children"><div class="content">The memory and bandwidth numbers are mind blowing. Going to be very hard to catch Nvidia. It’s as if competitors are going through the motions for participation prizes.</div><br/><div id="36937558" class="c"><input type="checkbox" id="c-36937558" checked=""/><div class="controls bullet"><span class="by">jauntywundrkind</span><span>|</span><a href="#36935944">parent</a><span>|</span><a href="#36939747">next</a><span>|</span><label class="collapse" for="c-36937558">[-]</label><label class="expand" for="c-36937558">[2 more]</label></div><br/><div class="children"><div class="content">AMD has been shipping 128x lanes of PCIe 5.0 on chip. That&#x27;s 0.5TBps. Getting up to 0.9TBps isn&#x27;t that crazy, but having big enough fabric &amp; switches to attach to is a huge feat.<p>I have hope though. CXL switching is going to give the whole industry a very fresh look at interconnect fabrics, as a simpler to manage faster more direct alternative to PCIe. Should be good.<p>Personally I worry it&#x27;s flogging a dead horse, has too many constraints, but Ethernet could be rumbling into action again too maybe. The hyperscalers &amp; others created a new LinuxFoundation group &quot;Ultra Ethernet Scaling&quot; to scale up much faster. Still, even at 1Tbps, that&#x27;s a bunch of lanes (7x) of that ultra Ethernet you&#x27;d need to get to NVlink&#x27;s 0.9TBps GPU interconnect. More radical breaks with Ethernet are needed than line speed bumps, things that can make switches easier to scale out big, if this realm of tech is to be good systems fabric. <a href="https:&#x2F;&#x2F;www.linuxfoundation.org&#x2F;press&#x2F;announcing-ultra-ethernet-consortium-uec" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.linuxfoundation.org&#x2F;press&#x2F;announcing-ultra-ether...</a><p>One interesting note on the DGX GH200 architecture that is super interesting to me is that it&#x27;s inverted the connectivity relationship. Typically a system would have NIC &amp; GPU hanging off the processor bus, and interconnect would go over that bus (maybe optimizing with p2p-dma to skip going through main memory, if it&#x27;s fancy). But here? GPUs have a 0.9TBps connection to the NVswitch. If the CPU wants to talk to the cluster, it uses nvlink c2c to send the data to the gpu that then used it&#x27;s nvlink connection to the NVswitch to send it out. Interesting reversal, interesting flourish, and gee it sure makes sense to me; the GPU is the thing!<p>Also, past 256 GPUs, there are BlueField 3 devices for Ethernet or infiniband connectivity on DGX nodes. Which is a good but also pretty boring&#x2F;standard smartnic based scale out strategy.</div><br/><div id="36938502" class="c"><input type="checkbox" id="c-36938502" checked=""/><div class="controls bullet"><span class="by">mmaunder</span><span>|</span><a href="#36935944">root</a><span>|</span><a href="#36937558">parent</a><span>|</span><a href="#36939747">next</a><span>|</span><label class="collapse" for="c-36938502">[-]</label><label class="expand" for="c-36938502">[1 more]</label></div><br/><div class="children"><div class="content">Thanks for the data rich comment. Very interesting re the inversion you mentioned. Much appreciated.</div><br/></div></div></div></div><div id="36939747" class="c"><input type="checkbox" id="c-36939747" checked=""/><div class="controls bullet"><span class="by">paskjdfparwerwe</span><span>|</span><a href="#36935944">parent</a><span>|</span><a href="#36937558">prev</a><span>|</span><a href="#36936392">next</a><span>|</span><label class="collapse" for="c-36939747">[-]</label><label class="expand" for="c-36939747">[2 more]</label></div><br/><div class="children"><div class="content">NVDA has no real competitors in DL space.<p>The closest is Google with their TPUs.</div><br/><div id="36939962" class="c"><input type="checkbox" id="c-36939962" checked=""/><div class="controls bullet"><span class="by">haldujai</span><span>|</span><a href="#36935944">root</a><span>|</span><a href="#36939747">parent</a><span>|</span><a href="#36936392">next</a><span>|</span><label class="collapse" for="c-36939962">[-]</label><label class="expand" for="c-36939962">[1 more]</label></div><br/><div class="children"><div class="content">Gaudi2 was competitive with the A100 on paper but was borderline vaporware.<p>Agree for now, but long do we think this will last though.<p>There really hasn’t been that great of a financial incentive to compete on DL. Nvidia themselves only recently made this a major priority.<p>However, now that heaps of money are being thrown at massive training runs I expect we’ll see more competition popping up. Particularly if Intel pulls off IFS and catches up on the next node increasing availability.</div><br/></div></div></div></div></div></div><div id="36936392" class="c"><input type="checkbox" id="c-36936392" checked=""/><div class="controls bullet"><span class="by">jacquesm</span><span>|</span><a href="#36935944">prev</a><span>|</span><a href="#36936274">next</a><span>|</span><label class="collapse" for="c-36936392">[-]</label><label class="expand" for="c-36936392">[2 more]</label></div><br/><div class="children"><div class="content">I wonder how much this thing will cost, best I&#x27;ve been able to find so far is a &#x27;low 8 digits&#x27; estimate in Anandtech article but nothing more specific than that.<p><a href="https:&#x2F;&#x2F;www.anandtech.com&#x2F;show&#x2F;18877&#x2F;nvidia-grace-hopper-has-entered-full-production-announcing-dgx-gh200-ai-supercomputer" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.anandtech.com&#x2F;show&#x2F;18877&#x2F;nvidia-grace-hopper-has...</a></div><br/><div id="36937673" class="c"><input type="checkbox" id="c-36937673" checked=""/><div class="controls bullet"><span class="by">tikkun</span><span>|</span><a href="#36936392">parent</a><span>|</span><a href="#36936274">next</a><span>|</span><label class="collapse" for="c-36937673">[-]</label><label class="expand" for="c-36937673">[1 more]</label></div><br/><div class="children"><div class="content">Some private cloud execs I talked with ballparked it at $15-25mm [1].<p>[1]: (I wrote this) <a href="https:&#x2F;&#x2F;gpus.llm-utils.org&#x2F;nvidia-h100-gpus-supply-and-demand&#x2F;#how-much-do-these-gpus-cost" rel="nofollow noreferrer">https:&#x2F;&#x2F;gpus.llm-utils.org&#x2F;nvidia-h100-gpus-supply-and-deman...</a></div><br/></div></div></div></div><div id="36936274" class="c"><input type="checkbox" id="c-36936274" checked=""/><div class="controls bullet"><span class="by">tikkun</span><span>|</span><a href="#36936392">prev</a><span>|</span><a href="#36936393">next</a><span>|</span><label class="collapse" for="c-36936274">[-]</label><label class="expand" for="c-36936274">[6 more]</label></div><br/><div class="children"><div class="content">As context: 1x dgx gh200 has 256x gh200s which each have 1x h100 and 1x grace cpu</div><br/><div id="36936374" class="c"><input type="checkbox" id="c-36936374" checked=""/><div class="controls bullet"><span class="by">luc4sdreyer</span><span>|</span><a href="#36936274">parent</a><span>|</span><a href="#36936393">next</a><span>|</span><label class="collapse" for="c-36936374">[-]</label><label class="expand" for="c-36936374">[5 more]</label></div><br/><div class="children"><div class="content">Adding up to &quot;1 exaFLOPS&quot; (sparse FP8). For reference, the fastest FP64 supercomputer is the AMD-based Frontier supercomputer, at 1.1 exaFLOPS.</div><br/><div id="36939158" class="c"><input type="checkbox" id="c-36939158" checked=""/><div class="controls bullet"><span class="by">redox99</span><span>|</span><a href="#36936274">root</a><span>|</span><a href="#36936374">parent</a><span>|</span><a href="#36937529">next</a><span>|</span><label class="collapse" for="c-36939158">[-]</label><label class="expand" for="c-36939158">[1 more]</label></div><br/><div class="children"><div class="content">They quote sparse FP8 because it&#x27;s the biggest number. The most relevant number would be FP16 (non sparse) but they don&#x27;t mention that.</div><br/></div></div><div id="36937529" class="c"><input type="checkbox" id="c-36937529" checked=""/><div class="controls bullet"><span class="by">danbruc</span><span>|</span><a href="#36936274">root</a><span>|</span><a href="#36936374">parent</a><span>|</span><a href="#36939158">prev</a><span>|</span><a href="#36936393">next</a><span>|</span><label class="collapse" for="c-36937529">[-]</label><label class="expand" for="c-36937529">[3 more]</label></div><br/><div class="children"><div class="content">Does sparse mean anything other than we can not actually do as many FP8 operations per second as we just claimed? To me it sounds like they can do X matrix operations per second on sparse matrices using Y FP8 operations per second, but instead of just saying what Y is they tell us how many FP8 operations would be required if the matrices were not sparse. Is this pure marketing bullshit or is there some logic to this? How sparse do those matrices have to be? Or am I misunderstanding this claim?</div><br/><div id="36938671" class="c"><input type="checkbox" id="c-36938671" checked=""/><div class="controls bullet"><span class="by">buildbot</span><span>|</span><a href="#36936274">root</a><span>|</span><a href="#36937529">parent</a><span>|</span><a href="#36936393">next</a><span>|</span><label class="collapse" for="c-36938671">[-]</label><label class="expand" for="c-36938671">[2 more]</label></div><br/><div class="children"><div class="content">It means a very specific sparsity pattern - 2:4, so 2 out of 4 values are not 0. It&#x27;s not pure bullshit, because a matrix with 2:4 sparsity may represent more &quot;information&quot; than a matrix that is 50% smaller.</div><br/><div id="36939751" class="c"><input type="checkbox" id="c-36939751" checked=""/><div class="controls bullet"><span class="by">danbruc</span><span>|</span><a href="#36936274">root</a><span>|</span><a href="#36938671">parent</a><span>|</span><a href="#36936393">next</a><span>|</span><label class="collapse" for="c-36939751">[-]</label><label class="expand" for="c-36939751">[1 more]</label></div><br/><div class="children"><div class="content">Okay, yes, there is a bit more information than in a matrix with half the number of entries, namely the position of the zeros. But when it comes to the number of floating point operations, doubling that number seems at least somewhat questionable to me, they are not performing that many multiplications. On the other hand it would probably be hard if not impossible to achieve the same performance if one tried to manually exploit this sparsity and avoid the multiplications, so maybe under that angle it is not too unreasonable.<p>But this also made me wonder, how does one use this in practice? If the matrices are not tiny, then they will probably have to be incredible sparse in order to always have at least two out of four entries zero. So does this just set some entries to zero if there are not enough of them in each group of four? Does one have to ensure this on its own, reorder rows and columns and introduce zeros where required and acceptable?</div><br/></div></div></div></div></div></div></div></div></div></div><div id="36936393" class="c"><input type="checkbox" id="c-36936393" checked=""/><div class="controls bullet"><span class="by">LASR</span><span>|</span><a href="#36936274">prev</a><span>|</span><a href="#36937070">next</a><span>|</span><label class="collapse" for="c-36936393">[-]</label><label class="expand" for="c-36936393">[2 more]</label></div><br/><div class="children"><div class="content">I would be interesting to know what kind of next-gen models this can train.<p>On the LLM frontier, we’re starting to hit the limits of reasoning abilities in the current gen.</div><br/><div id="36939761" class="c"><input type="checkbox" id="c-36939761" checked=""/><div class="controls bullet"><span class="by">paskjdfparwerwe</span><span>|</span><a href="#36936393">parent</a><span>|</span><a href="#36937070">next</a><span>|</span><label class="collapse" for="c-36939761">[-]</label><label class="expand" for="c-36939761">[1 more]</label></div><br/><div class="children"><div class="content">... and the current generation is just an ensemble of the prev. generation.</div><br/></div></div></div></div><div id="36937070" class="c"><input type="checkbox" id="c-36937070" checked=""/><div class="controls bullet"><span class="by">moab</span><span>|</span><a href="#36936393">prev</a><span>|</span><a href="#36936005">next</a><span>|</span><label class="collapse" for="c-36937070">[-]</label><label class="expand" for="c-36937070">[1 more]</label></div><br/><div class="children"><div class="content">Unfortunate that they don&#x27;t mention the running times for any of the applications they benchmark (e.g., PageRank). Does anyone in the know have some idea how long this takes?</div><br/></div></div><div id="36936005" class="c"><input type="checkbox" id="c-36936005" checked=""/><div class="controls bullet"><span class="by">m3kw9</span><span>|</span><a href="#36937070">prev</a><span>|</span><label class="collapse" for="c-36936005">[-]</label><label class="expand" for="c-36936005">[5 more]</label></div><br/><div class="children"><div class="content">So basically 2x faster than H100</div><br/><div id="36936308" class="c"><input type="checkbox" id="c-36936308" checked=""/><div class="controls bullet"><span class="by">luc4sdreyer</span><span>|</span><a href="#36936005">parent</a><span>|</span><a href="#36936269">next</a><span>|</span><label class="collapse" for="c-36936308">[-]</label><label class="expand" for="c-36936308">[1 more]</label></div><br/><div class="children"><div class="content">They claim 1.1x to 7x, depending on what you&#x27;re doing. The 10% to 50% is for the ~10k GPU LLM training, where the main bottleneck tends to be networking:<p>&gt; DGX GH200 enables more efficient parallel mapping and alleviates the networking communication bottleneck. As a result, up to 1.5x faster training time can be achieved over a DGX H100-based solution for LLM training at scale.</div><br/></div></div><div id="36937285" class="c"><input type="checkbox" id="c-36937285" checked=""/><div class="controls bullet"><span class="by">kvetching</span><span>|</span><a href="#36936005">parent</a><span>|</span><a href="#36936269">prev</a><span>|</span><label class="collapse" for="c-36937285">[-]</label><label class="expand" for="c-36937285">[2 more]</label></div><br/><div class="children"><div class="content">Was this upgrade known or is this out of left field and people that stocked up on H100s going to feel a little regret</div><br/><div id="36937537" class="c"><input type="checkbox" id="c-36937537" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#36936005">root</a><span>|</span><a href="#36937285">parent</a><span>|</span><label class="collapse" for="c-36937537">[-]</label><label class="expand" for="c-36937537">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s been on the roadmap for a few years although there were no performance numbers. I assume GH200 is more expensive so the price&#x2F;performance advantage may not be overwhelming. Worst case you order GH200s and then scalp your H100s on the used market.</div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>