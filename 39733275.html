<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1710752451890" as="style"/><link rel="stylesheet" href="styles.css?v=1710752451890"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/albertan017/LLM4Decompile">LLM4Decompile: Decompiling Binary Code with LLM</a> <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>Davidbrcz</span> | <span>103 comments</span></div><br/><div><div id="39734385" class="c"><input type="checkbox" id="c-39734385" checked=""/><div class="controls bullet"><span class="by">klik99</span><span>|</span><a href="#39734317">next</a><span>|</span><label class="collapse" for="c-39734385">[-]</label><label class="expand" for="c-39734385">[53 more]</label></div><br/><div class="children"><div class="content">This is a fascinating idea, but (honest question, not a judgement) would the output be reliable? It would be hard to identify hallucinations since recompiling could produce different machine code. Particularly if there is some novel construct that could be a key part of the code. Are there ways of also reporting the LLMs confidence in sections like this when running generatively? It’s an amazing idea but I worry it would stumble invisibly on the parts that are most critical. I suppose it would just need human confirmation on the output</div><br/><div id="39741663" class="c"><input type="checkbox" id="c-39741663" checked=""/><div class="controls bullet"><span class="by">GoblinSlayer</span><span>|</span><a href="#39734385">parent</a><span>|</span><a href="#39734505">next</a><span>|</span><label class="collapse" for="c-39741663">[-]</label><label class="expand" for="c-39741663">[1 more]</label></div><br/><div class="children"><div class="content">Sounds like it should be able to split the code into functions with inferred API, then you should be able to fuzz these functions in binary and source versions.</div><br/></div></div><div id="39734505" class="c"><input type="checkbox" id="c-39734505" checked=""/><div class="controls bullet"><span class="by">Eager</span><span>|</span><a href="#39734385">parent</a><span>|</span><a href="#39741663">prev</a><span>|</span><a href="#39737569">next</a><span>|</span><label class="collapse" for="c-39734505">[-]</label><label class="expand" for="c-39734505">[28 more]</label></div><br/><div class="children"><div class="content">This is why round-tripping the code is important.<p>If you decompile the binary to source, then compile the source back to binary you should get the original binary.<p>You just need to do this enough times until the loss drops to some acceptable amount.<p>It&#x27;s a great task for reinforcement learning, which is known to be unreasonably effective for these types of problems.</div><br/><div id="39734687" class="c"><input type="checkbox" id="c-39734687" checked=""/><div class="controls bullet"><span class="by">thfuran</span><span>|</span><a href="#39734385">root</a><span>|</span><a href="#39734505">parent</a><span>|</span><a href="#39735195">next</a><span>|</span><label class="collapse" for="c-39734687">[-]</label><label class="expand" for="c-39734687">[24 more]</label></div><br/><div class="children"><div class="content">&gt;If you decompile the binary to source, then compile the source back to binary you should get the original binary.<p>You really can&#x27;t expect that if you&#x27;re not using exactly the same version of exactly the same compiler with exactly the same flags, and often not even then.</div><br/><div id="39740802" class="c"><input type="checkbox" id="c-39740802" checked=""/><div class="controls bullet"><span class="by">vasvir</span><span>|</span><a href="#39734385">root</a><span>|</span><a href="#39734687">parent</a><span>|</span><a href="#39734759">next</a><span>|</span><label class="collapse" for="c-39740802">[-]</label><label class="expand" for="c-39740802">[1 more]</label></div><br/><div class="children"><div class="content">Right.<p>A less formidable problem with higher chances of succeeding is from a given binary to figure out first compiler, compiler-version, compiler-flags.<p>From there you could have a model for every combination or at least a model for the compiler variant and use the other info (version, flags) as input to the model.</div><br/></div></div><div id="39734759" class="c"><input type="checkbox" id="c-39734759" checked=""/><div class="controls bullet"><span class="by">Eager</span><span>|</span><a href="#39734385">root</a><span>|</span><a href="#39734687">parent</a><span>|</span><a href="#39740802">prev</a><span>|</span><a href="#39736710">next</a><span>|</span><label class="collapse" for="c-39734759">[-]</label><label class="expand" for="c-39734759">[17 more]</label></div><br/><div class="children"><div class="content">You try your best, and if you provide enough examples, it will undoubtedly get figured out.</div><br/><div id="39734928" class="c"><input type="checkbox" id="c-39734928" checked=""/><div class="controls bullet"><span class="by">lolinder</span><span>|</span><a href="#39734385">root</a><span>|</span><a href="#39734759">parent</a><span>|</span><a href="#39734818">next</a><span>|</span><label class="collapse" for="c-39734928">[-]</label><label class="expand" for="c-39734928">[7 more]</label></div><br/><div class="children"><div class="content">I think you&#x27;re misunderstanding OP&#x27;s objection. It&#x27;s not simply a matter of going back and forth with the LLM until eventually (infinite monkeys on typewriters style) it gets the same binary as before: Even if you got the <i>exact same source code</i> as the original there&#x27;s still no automated way to tell that you&#x27;re done because the bits you get back out of the recompile step will almost certainly not be the same, even if your decompiled source were identical in every way. They might even vary quite substantially depending on a lot of different environmental factors.<p>Reproducible builds are hard to pull off cooperatively, when you control the pipeline that built the original binary and can work to eliminate all sources of variation. It&#x27;s simply not going to happen in a decompiler like this.</div><br/><div id="39735307" class="c"><input type="checkbox" id="c-39735307" checked=""/><div class="controls bullet"><span class="by">blagie</span><span>|</span><a href="#39734385">root</a><span>|</span><a href="#39734928">parent</a><span>|</span><a href="#39741405">next</a><span>|</span><label class="collapse" for="c-39735307">[-]</label><label class="expand" for="c-39735307">[5 more]</label></div><br/><div class="children"><div class="content">Well, no, but yes.<p>The critical piece is that this can be done in training. If I collect a large number of C programs from github, compile them (in a deterministic fashion), I can use that as a training, test, and validation set. The output of the ML ought to compile to the same way given the same environment.<p>Indeed, I can train over multiple deterministic build environments (e.g. different compilers, different compiler flags) to be even more robust.<p>The second critical piece is that for something like a GAN, it doesn&#x27;t need to be identical. You have two ML algorithms competing:<p>- One is trying to identify generated versus ground-truth source code<p>- One is trying to generate source code<p>Virtually all ML tasks are trained this way, and it doesn&#x27;t matter. I have images and descriptions, and all the ML needs to do is generate an indistinguishable description.<p>So if I give the poster a lot more benefit of the doubt on what they wanted to say, it can make sense.</div><br/><div id="39735387" class="c"><input type="checkbox" id="c-39735387" checked=""/><div class="controls bullet"><span class="by">lolinder</span><span>|</span><a href="#39734385">root</a><span>|</span><a href="#39735307">parent</a><span>|</span><a href="#39735593">next</a><span>|</span><label class="collapse" for="c-39735387">[-]</label><label class="expand" for="c-39735387">[2 more]</label></div><br/><div class="children"><div class="content">Oh, I was assuming that Eager was responding to klik99&#x27;s question about how we could identify hallucinations in the output—round tripping doesn&#x27;t help with that.<p>If what they&#x27;re actually saying is that it&#x27;s possible to train a model to low loss and then you just have to trust the results, yes, what you say makes sense.</div><br/><div id="39736784" class="c"><input type="checkbox" id="c-39736784" checked=""/><div class="controls bullet"><span class="by">blagie</span><span>|</span><a href="#39734385">root</a><span>|</span><a href="#39735387">parent</a><span>|</span><a href="#39735593">next</a><span>|</span><label class="collapse" for="c-39736784">[-]</label><label class="expand" for="c-39736784">[1 more]</label></div><br/><div class="children"><div class="content">I haven&#x27;t found many places where I trust the results of an ML algorithm. I&#x27;ve found many places where they work astonishingly well 30-95% of the time, which is to say, save me or others a bunch of time.<p>It&#x27;s been years, but I&#x27;m thinking back through things I&#x27;ve reverse-engineered before, and having something which kinda works most of the time would be super-useful still as a starting point.</div><br/></div></div></div></div><div id="39735593" class="c"><input type="checkbox" id="c-39735593" checked=""/><div class="controls bullet"><span class="by">incrudible</span><span>|</span><a href="#39734385">root</a><span>|</span><a href="#39735307">parent</a><span>|</span><a href="#39735387">prev</a><span>|</span><a href="#39741405">next</a><span>|</span><label class="collapse" for="c-39735593">[-]</label><label class="expand" for="c-39735593">[2 more]</label></div><br/><div class="children"><div class="content">Have you ever trained a GAN?</div><br/><div id="39736750" class="c"><input type="checkbox" id="c-39736750" checked=""/><div class="controls bullet"><span class="by">blagie</span><span>|</span><a href="#39734385">root</a><span>|</span><a href="#39735593">parent</a><span>|</span><a href="#39741405">next</a><span>|</span><label class="collapse" for="c-39736750">[-]</label><label class="expand" for="c-39736750">[1 more]</label></div><br/><div class="children"><div class="content">Technically, yes!<p>A more reasonable answer, though, is &quot;no.&quot;<p>I&#x27;ve technically gone through random tutorials and trained various toy networks, including a GAN at some point, but I don&#x27;t think that should really count. I also have a ton of experience with neural networks that&#x27;s decades out-of-date (HUNDREDS of nodes, doing things like OCR). And I&#x27;ve read a bunch of modern papers and used a bunch of Hugging Face models.<p>Which is to say, I&#x27;m not completely ignorant, but I do not have credible experience training GANs.</div><br/></div></div></div></div></div></div><div id="39741405" class="c"><input type="checkbox" id="c-39741405" checked=""/><div class="controls bullet"><span class="by">weinzierl</span><span>|</span><a href="#39734385">root</a><span>|</span><a href="#39734928">parent</a><span>|</span><a href="#39735307">prev</a><span>|</span><a href="#39734818">next</a><span>|</span><label class="collapse" for="c-39741405">[-]</label><label class="expand" for="c-39741405">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s true but a solvable problem. I once tried to reproduce the build of an uncooperative party and it was mainly tedious and boring.<p>The space of possible compiler arguments is huge, but ultimately what is actually used is mostly on a small surface.<p>Apart from that, I wrote a small tool to normalize the version string, timestamps and file path&#x27; in the binaries before I compared them. I know there are other sources of non-determinism, but these three things were enough in my case.<p>The hardest part were the numerous file path&#x27; from the build machine. I had not expected that. In hindsight, stripping both binaries before comparison might have helped, but I don&#x27;t remember why I didn&#x27;t do that.</div><br/></div></div></div></div><div id="39734818" class="c"><input type="checkbox" id="c-39734818" checked=""/><div class="controls bullet"><span class="by">thfuran</span><span>|</span><a href="#39734385">root</a><span>|</span><a href="#39734759">parent</a><span>|</span><a href="#39734928">prev</a><span>|</span><a href="#39734816">next</a><span>|</span><label class="collapse" for="c-39734818">[-]</label><label class="expand" for="c-39734818">[6 more]</label></div><br/><div class="children"><div class="content">What exactly are you suggesting will get figured out?</div><br/><div id="39734844" class="c"><input type="checkbox" id="c-39734844" checked=""/><div class="controls bullet"><span class="by">spqrr</span><span>|</span><a href="#39734385">root</a><span>|</span><a href="#39734818">parent</a><span>|</span><a href="#39734816">next</a><span>|</span><label class="collapse" for="c-39734844">[-]</label><label class="expand" for="c-39734844">[5 more]</label></div><br/><div class="children"><div class="content">The mapping from binary to source code.</div><br/><div id="39734931" class="c"><input type="checkbox" id="c-39734931" checked=""/><div class="controls bullet"><span class="by">thfuran</span><span>|</span><a href="#39734385">root</a><span>|</span><a href="#39734844">parent</a><span>|</span><a href="#39734927">next</a><span>|</span><label class="collapse" for="c-39734931">[-]</label><label class="expand" for="c-39734931">[3 more]</label></div><br/><div class="children"><div class="content">Even ignoring all sources of irreproducibility, there does not exist a bijection between source and binary artifact irrespective of tool chain. Two different toolchains could compile the same source to different binaries or different sources to the same binary. And you absolutely shouldn&#x27;t be ignoring sources of irreproducibility in this context, since they&#x27;ll cause even the same toolchain to keep producing different binaries given the same source.</div><br/><div id="39735056" class="c"><input type="checkbox" id="c-39735056" checked=""/><div class="controls bullet"><span class="by">achrono</span><span>|</span><a href="#39734385">root</a><span>|</span><a href="#39734931">parent</a><span>|</span><a href="#39734927">next</a><span>|</span><label class="collapse" for="c-39735056">[-]</label><label class="expand" for="c-39735056">[2 more]</label></div><br/><div class="children"><div class="content">Exactly, but neither the source nor the binary is what&#x27;s truly important here. The real question is: can the LLM generate the <i>functionally valid</i> source equivalent of the binary at hand? If I disassemble Microsoft Paint, can I get code that will result in a mostly functional version of Microsoft Paint, or will I just get 515 compile errors instead?</div><br/><div id="39736789" class="c"><input type="checkbox" id="c-39736789" checked=""/><div class="controls bullet"><span class="by">Brian_K_White</span><span>|</span><a href="#39734385">root</a><span>|</span><a href="#39735056">parent</a><span>|</span><a href="#39734927">next</a><span>|</span><label class="collapse" for="c-39736789">[-]</label><label class="expand" for="c-39736789">[1 more]</label></div><br/><div class="children"><div class="content">This is what I thought the question was really about.<p>I assume that an llm will simply see patterns that look similar to other patterns and make assosciations and assume ewuivalences on that level, meanwhile real code is full of things where the programmer, especially assembly programmers, modify something by a single instruction or offset value etc to get a very specific and functionally important result.<p>Often the result is code that not only isn&#x27;t obvious, it&#x27;s nominaly flatly wrong, violating standards, specs, intended function, datasheet docs, etc. If all you knew were the rules written in the docs, the code is broken and invalid.<p>Is the llm really going to see or understand the intent of that?<p>They find matching patterns in other existing stuff, and to the user who can not see the infinite body of that other stuff the llm pulled from, it looks like the llm understood the intent of a question, but I say it just found the prior work of some human who understood a similar intent somewhere else.<p>Maybe an llm or some other flavor of ai can operate some other way like actually playing out the binary like executing in a debugger and map out the results not just look at the code as fuzzy matching patterns. Can that take the place of understanding the intents the way a human would reading the decompiled assembly?<p>Guess we&#x27;ll be finding out sooner of later since of course it will all be tried.</div><br/></div></div></div></div></div></div><div id="39734927" class="c"><input type="checkbox" id="c-39734927" checked=""/><div class="controls bullet"><span class="by">layer8</span><span>|</span><a href="#39734385">root</a><span>|</span><a href="#39734844">parent</a><span>|</span><a href="#39734931">prev</a><span>|</span><a href="#39734816">next</a><span>|</span><label class="collapse" for="c-39734927">[-]</label><label class="expand" for="c-39734927">[1 more]</label></div><br/><div class="children"><div class="content">The question was about the reverse mapping.</div><br/></div></div></div></div></div></div><div id="39734910" class="c"><input type="checkbox" id="c-39734910" checked=""/><div class="controls bullet"><span class="by">fao_</span><span>|</span><a href="#39734385">root</a><span>|</span><a href="#39734759">parent</a><span>|</span><a href="#39734816">prev</a><span>|</span><a href="#39736710">next</a><span>|</span><label class="collapse" for="c-39734910">[-]</label><label class="expand" for="c-39734910">[2 more]</label></div><br/><div class="children"><div class="content">Except LLMs cannot reason.</div><br/><div id="39739134" class="c"><input type="checkbox" id="c-39739134" checked=""/><div class="controls bullet"><span class="by">LoganDark</span><span>|</span><a href="#39734385">root</a><span>|</span><a href="#39734910">parent</a><span>|</span><a href="#39736710">next</a><span>|</span><label class="collapse" for="c-39739134">[-]</label><label class="expand" for="c-39739134">[1 more]</label></div><br/><div class="children"><div class="content">LLMs can mimic past examples of reasoning from the dataset. So, it can re-use reasoning that it has already been trained on. If the network manages to generalize well enough across its training data, then it can get close to reproducing general reasoning. But it can&#x27;t yet fully get there, of course.</div><br/></div></div></div></div></div></div><div id="39736710" class="c"><input type="checkbox" id="c-39736710" checked=""/><div class="controls bullet"><span class="by">dheera</span><span>|</span><a href="#39734385">root</a><span>|</span><a href="#39734687">parent</a><span>|</span><a href="#39734759">prev</a><span>|</span><a href="#39735195">next</a><span>|</span><label class="collapse" for="c-39736710">[-]</label><label class="expand" for="c-39736710">[5 more]</label></div><br/><div class="children"><div class="content">Maybe we then need an LLM to tell us if two pieces of compiled code are equivalent in an input-output mapping sense (ignoring execution time).<p>I&#x27;m actually serious; it would be exceedingly easy to get training data for this just by running the same source code through a bunch of different compiler versions and optimization flags.</div><br/><div id="39739822" class="c"><input type="checkbox" id="c-39739822" checked=""/><div class="controls bullet"><span class="by">saagarjha</span><span>|</span><a href="#39734385">root</a><span>|</span><a href="#39736710">parent</a><span>|</span><a href="#39737416">next</a><span>|</span><label class="collapse" for="c-39739822">[-]</label><label class="expand" for="c-39739822">[2 more]</label></div><br/><div class="children"><div class="content">An LLM cannot do this. I don’t even mean this in a formal sense, because your problem is addressed by Rice’s Theorem, which places bounds on what any system (LLM or not) can do here; I mean it in the sense that an LLM isn’t even appropriate to use here because the best it can possibly do is provide you with its best guess at the answer. And while this might be a useful property for decompilation in general that’s not what was being discussed here.</div><br/><div id="39741315" class="c"><input type="checkbox" id="c-39741315" checked=""/><div class="controls bullet"><span class="by">dheera</span><span>|</span><a href="#39734385">root</a><span>|</span><a href="#39739822">parent</a><span>|</span><a href="#39737416">next</a><span>|</span><label class="collapse" for="c-39741315">[-]</label><label class="expand" for="c-39741315">[1 more]</label></div><br/><div class="children"><div class="content">Rice&#x27;s theorem does NOT prevent a program from giving correct answers to non-trivial properties of programs (including the halting problem or other undecidable problems) for 99.99% of inputs and &quot;I don&#x27;t know&quot; for 0.01% of inputs. It only states that you cannot write a program that provides a correct and definitive yes-or-no for 100% of inputs.<p>For a decompiler, being able to decompile even 90% of programs would be awesome. We&#x27;re not looking for theoretical perfectness.</div><br/></div></div></div></div><div id="39737416" class="c"><input type="checkbox" id="c-39737416" checked=""/><div class="controls bullet"><span class="by">thfuran</span><span>|</span><a href="#39734385">root</a><span>|</span><a href="#39736710">parent</a><span>|</span><a href="#39739822">prev</a><span>|</span><a href="#39735195">next</a><span>|</span><label class="collapse" for="c-39737416">[-]</label><label class="expand" for="c-39737416">[2 more]</label></div><br/><div class="children"><div class="content">Why would an llm be the tool for that job?</div><br/><div id="39738089" class="c"><input type="checkbox" id="c-39738089" checked=""/><div class="controls bullet"><span class="by">dheera</span><span>|</span><a href="#39734385">root</a><span>|</span><a href="#39737416">parent</a><span>|</span><a href="#39735195">next</a><span>|</span><label class="collapse" for="c-39738089">[-]</label><label class="expand" for="c-39738089">[1 more]</label></div><br/><div class="children"><div class="content">Without analytical thinking how else would you come to conviction that two functions are identical, for a computationally unfeasible number of possible inputs?</div><br/></div></div></div></div></div></div></div></div><div id="39735195" class="c"><input type="checkbox" id="c-39735195" checked=""/><div class="controls bullet"><span class="by">codethief</span><span>|</span><a href="#39734385">root</a><span>|</span><a href="#39734505">parent</a><span>|</span><a href="#39734687">prev</a><span>|</span><a href="#39735929">next</a><span>|</span><label class="collapse" for="c-39735195">[-]</label><label class="expand" for="c-39735195">[1 more]</label></div><br/><div class="children"><div class="content">&gt; you should get the original binary<p>According to the project&#x27;s README, they only seem to be checking mere &quot;re-compilability&quot; and &quot;re-executability&quot; of the decompiled code, though.</div><br/></div></div><div id="39735929" class="c"><input type="checkbox" id="c-39735929" checked=""/><div class="controls bullet"><span class="by">1024core</span><span>|</span><a href="#39734385">root</a><span>|</span><a href="#39734505">parent</a><span>|</span><a href="#39735195">prev</a><span>|</span><a href="#39737569">next</a><span>|</span><label class="collapse" for="c-39735929">[-]</label><label class="expand" for="c-39735929">[2 more]</label></div><br/><div class="children"><div class="content">&gt; If you decompile the binary to source, then compile the source back to binary you should get the original binary.<p>Doesn&#x27;t that depend on the compiler&#x27;s version though? Or, for that matter, even the sub-version. Every compiler does things differently.</div><br/><div id="39741159" class="c"><input type="checkbox" id="c-39741159" checked=""/><div class="controls bullet"><span class="by">fulafel</span><span>|</span><a href="#39734385">root</a><span>|</span><a href="#39735929">parent</a><span>|</span><a href="#39737569">next</a><span>|</span><label class="collapse" for="c-39741159">[-]</label><label class="expand" for="c-39741159">[1 more]</label></div><br/><div class="children"><div class="content">From the README:<p>&gt; By re-compiling the decompiled output and running the test cases, we assess if the decompilation preserved the program logic and behavior.<p>As this is in the metrics section, I guess fully automating this is not part of the research.</div><br/></div></div></div></div></div></div><div id="39737569" class="c"><input type="checkbox" id="c-39737569" checked=""/><div class="controls bullet"><span class="by">userbinator</span><span>|</span><a href="#39734385">parent</a><span>|</span><a href="#39734505">prev</a><span>|</span><a href="#39734976">next</a><span>|</span><label class="collapse" for="c-39737569">[-]</label><label class="expand" for="c-39737569">[2 more]</label></div><br/><div class="children"><div class="content">LLMs are by nature probabilistic, which is why they work reasonably well for &quot;imprecise&quot; domains like natural language processing. Expecting one to do decompilation, or disassembly for that matter, is IMHO very much a &quot;wrong tool for the job&quot; --- but perhaps it&#x27;s just an exploratory exercise for the &quot;just use an LLM&quot; meme that seems to be a common trend these days.<p>The bigger argument against the effectiveness of this approach is that existing decompilers can already do a much better job with far less processing power.</div><br/><div id="39738743" class="c"><input type="checkbox" id="c-39738743" checked=""/><div class="controls bullet"><span class="by">czl</span><span>|</span><a href="#39734385">root</a><span>|</span><a href="#39737569">parent</a><span>|</span><a href="#39734976">next</a><span>|</span><label class="collapse" for="c-39738743">[-]</label><label class="expand" for="c-39738743">[1 more]</label></div><br/><div class="children"><div class="content">In the future efficient rule based compilers and decompiler may be generated by AI systems trained on inputs and outputs of what we use today.<p>This effort is an exploration to find a radically different AI way that may give superior results.<p>Yes. For all the reasons you give above, AI for this job is not practical today.</div><br/></div></div></div></div><div id="39734976" class="c"><input type="checkbox" id="c-39734976" checked=""/><div class="controls bullet"><span class="by">layer8</span><span>|</span><a href="#39734385">parent</a><span>|</span><a href="#39737569">prev</a><span>|</span><a href="#39736537">next</a><span>|</span><label class="collapse" for="c-39734976">[-]</label><label class="expand" for="c-39734976">[13 more]</label></div><br/><div class="children"><div class="content">The way to do this is to have a formal verification tool that takes the input, the output, and a formal proof that the input matches the semantics of the output, and have the LLM create the formal proof alongside the output. Then you can run the verification tool to check if the LLM’s output is correct according to the proof that it also provided.<p>Of course, building and training an LLM that can provide such proofs will be the bigger challenge, but it would be a safe a way to detect hallucinations.</div><br/><div id="39735487" class="c"><input type="checkbox" id="c-39735487" checked=""/><div class="controls bullet"><span class="by">natsch</span><span>|</span><a href="#39734385">root</a><span>|</span><a href="#39734976">parent</a><span>|</span><a href="#39735027">next</a><span>|</span><label class="collapse" for="c-39735487">[-]</label><label class="expand" for="c-39735487">[5 more]</label></div><br/><div class="children"><div class="content">That would require the tool to prove the equivalence of the two programs, which is generally undecidable. Maybe this could be weakened to preserving some properties of the program.</div><br/><div id="39736169" class="c"><input type="checkbox" id="c-39736169" checked=""/><div class="controls bullet"><span class="by">layer8</span><span>|</span><a href="#39734385">root</a><span>|</span><a href="#39735487">parent</a><span>|</span><a href="#39735708">next</a><span>|</span><label class="collapse" for="c-39736169">[-]</label><label class="expand" for="c-39736169">[3 more]</label></div><br/><div class="children"><div class="content">No, it would not. It would require the LLM to provide a proof for the program that it outputs, which seems reasonable in the same way that a human decompiling a program would be able to provide a record of his&#x2F;her reasoning.<p>The formal verifier would then merely check the provided proof, which is a simple mechanical process.<p>This is analogous to a mathematician providing a detailed proof and a computer checking it.<p>What is impossible due to undecidability is for two <i>arbitrary</i> programs, to either prove or disprove their equivalence. However, the two programs we are talking about are highly correlated, and thus not arbitrary at all with respect to each other. If an LLM is able to provide a correct decompilation, then in principle it should also be able to provide a proof of the correctness of that decompilation.</div><br/><div id="39739834" class="c"><input type="checkbox" id="c-39739834" checked=""/><div class="controls bullet"><span class="by">saagarjha</span><span>|</span><a href="#39734385">root</a><span>|</span><a href="#39736169">parent</a><span>|</span><a href="#39735708">next</a><span>|</span><label class="collapse" for="c-39739834">[-]</label><label class="expand" for="c-39739834">[2 more]</label></div><br/><div class="children"><div class="content">Yes, and then someone needs to check that proof. It’s not particularly clear if that decompilation proof would be any more helpful than just doing the lifting by hand.</div><br/><div id="39741604" class="c"><input type="checkbox" id="c-39741604" checked=""/><div class="controls bullet"><span class="by">logicchains</span><span>|</span><a href="#39734385">root</a><span>|</span><a href="#39739834">parent</a><span>|</span><a href="#39735708">next</a><span>|</span><label class="collapse" for="c-39741604">[-]</label><label class="expand" for="c-39741604">[1 more]</label></div><br/><div class="children"><div class="content">No, nobody needs to check the proof; that&#x27;s the whole point of formal theorem proving, the machine checks it for you.</div><br/></div></div></div></div></div></div><div id="39735708" class="c"><input type="checkbox" id="c-39735708" checked=""/><div class="controls bullet"><span class="by">ngruhn</span><span>|</span><a href="#39734385">root</a><span>|</span><a href="#39735487">parent</a><span>|</span><a href="#39736169">prev</a><span>|</span><a href="#39735027">next</a><span>|</span><label class="collapse" for="c-39735708">[-]</label><label class="expand" for="c-39735708">[1 more]</label></div><br/><div class="children"><div class="content">That doesn’t mean that it’s impossible, right? Just that no tool is guaranteed to give an answer in any case. And those cases might be 90%, 10% or it-doesn’t-matter-in-practice %</div><br/></div></div></div></div><div id="39735027" class="c"><input type="checkbox" id="c-39735027" checked=""/><div class="controls bullet"><span class="by">djinnandtonic</span><span>|</span><a href="#39734385">root</a><span>|</span><a href="#39734976">parent</a><span>|</span><a href="#39735487">prev</a><span>|</span><a href="#39734994">next</a><span>|</span><label class="collapse" for="c-39735027">[-]</label><label class="expand" for="c-39735027">[5 more]</label></div><br/><div class="children"><div class="content">What if there are hallucinations in the verification tool?</div><br/><div id="39735071" class="c"><input type="checkbox" id="c-39735071" checked=""/><div class="controls bullet"><span class="by">thfuran</span><span>|</span><a href="#39734385">root</a><span>|</span><a href="#39735027">parent</a><span>|</span><a href="#39735078">next</a><span>|</span><label class="collapse" for="c-39735071">[-]</label><label class="expand" for="c-39735071">[1 more]</label></div><br/><div class="children"><div class="content">Then it&#x27;s not a formal verification tool. Generative models are profoundly unfit for that purpose.</div><br/></div></div><div id="39735078" class="c"><input type="checkbox" id="c-39735078" checked=""/><div class="controls bullet"><span class="by">layer8</span><span>|</span><a href="#39734385">root</a><span>|</span><a href="#39735027">parent</a><span>|</span><a href="#39735071">prev</a><span>|</span><a href="#39735224">next</a><span>|</span><label class="collapse" for="c-39735078">[-]</label><label class="expand" for="c-39735078">[1 more]</label></div><br/><div class="children"><div class="content">There may be bugs, but not hallucinations. Bugs are at least reproducible, and the source code of the verification tool is much, much smaller than an LLM, so has a much higher chance of its finite number of bugs to be found, whereas with an LLM it is probably impossible to remove all hallucinations.<p>To turn your question around: What if the compiler that compiles your LLM implementation “hallucinates”? That would be the closer parallel.</div><br/></div></div><div id="39735224" class="c"><input type="checkbox" id="c-39735224" checked=""/><div class="controls bullet"><span class="by">smellf</span><span>|</span><a href="#39734385">root</a><span>|</span><a href="#39735027">parent</a><span>|</span><a href="#39735078">prev</a><span>|</span><a href="#39734994">next</a><span>|</span><label class="collapse" for="c-39735224">[-]</label><label class="expand" for="c-39735224">[2 more]</label></div><br/><div class="children"><div class="content">I think the idea is that you&#x27;d have two independently-develooed systems, one LLM decompiling the binary and the other LLM formally verifying.  If the verifier disagrees with the decompiler you won&#x27;t know which tool is right and which is wrong, but if they agree then you&#x27;ll know the decompiled result is correct, since both tools are unlikely to hallucinate the same thing.</div><br/><div id="39735237" class="c"><input type="checkbox" id="c-39735237" checked=""/><div class="controls bullet"><span class="by">layer8</span><span>|</span><a href="#39734385">root</a><span>|</span><a href="#39735224">parent</a><span>|</span><a href="#39734994">next</a><span>|</span><label class="collapse" for="c-39735237">[-]</label><label class="expand" for="c-39735237">[1 more]</label></div><br/><div class="children"><div class="content">No, the idea is that the verifier is a human-written program, like the many formal-verification tools that already exist, not an LLM. There is zero reason to make this an LLM.<p>It makes sense to use LLMs for the decompilation and the proof generation, because both arguably require creativity, but a mere proof verifier requires zero creativity, only correctness.</div><br/></div></div></div></div></div></div><div id="39734994" class="c"><input type="checkbox" id="c-39734994" checked=""/><div class="controls bullet"><span class="by">thfuran</span><span>|</span><a href="#39734385">root</a><span>|</span><a href="#39734976">parent</a><span>|</span><a href="#39735027">prev</a><span>|</span><a href="#39736537">next</a><span>|</span><label class="collapse" for="c-39734994">[-]</label><label class="expand" for="c-39734994">[2 more]</label></div><br/><div class="children"><div class="content">Good luck formally proving Linux.</div><br/><div id="39735003" class="c"><input type="checkbox" id="c-39735003" checked=""/><div class="controls bullet"><span class="by">layer8</span><span>|</span><a href="#39734385">root</a><span>|</span><a href="#39734994">parent</a><span>|</span><a href="#39736537">next</a><span>|</span><label class="collapse" for="c-39735003">[-]</label><label class="expand" for="c-39735003">[1 more]</label></div><br/><div class="children"><div class="content">The goal is to prove that the source code matches the machine code, not to prove that the code implements some intended higher-level semantics. This has nothing to do with formally proving the correctness of the Linux kernel.</div><br/></div></div></div></div></div></div><div id="39736537" class="c"><input type="checkbox" id="c-39736537" checked=""/><div class="controls bullet"><span class="by">londons_explore</span><span>|</span><a href="#39734385">parent</a><span>|</span><a href="#39734976">prev</a><span>|</span><a href="#39736412">next</a><span>|</span><label class="collapse" for="c-39736537">[-]</label><label class="expand" for="c-39736537">[1 more]</label></div><br/><div class="children"><div class="content">Even if it isn&#x27;t fully reliable, often it&#x27;s only necessary to modify a few functions for most changes one wants to make to a binary.<p>You&#x27;d therefore only need to recompile those few functions.</div><br/></div></div><div id="39736412" class="c"><input type="checkbox" id="c-39736412" checked=""/><div class="controls bullet"><span class="by">afro88</span><span>|</span><a href="#39734385">parent</a><span>|</span><a href="#39736537">prev</a><span>|</span><a href="#39734754">next</a><span>|</span><label class="collapse" for="c-39736412">[-]</label><label class="expand" for="c-39736412">[1 more]</label></div><br/><div class="children"><div class="content">The detail how they measure this in the readme. This is directed at all the sibling comments as well!<p>TLDR they recompile and then re-execute (including test suites). From the results table it looks like GPT4 still &quot;outperforms&quot; their model in recompilation, but their recompiled code has a much better re-execution success rate (less hallucinations). But, that re-execution rate is still pretty lacking (around 14%), even if better than GPT4.</div><br/></div></div><div id="39734754" class="c"><input type="checkbox" id="c-39734754" checked=""/><div class="controls bullet"><span class="by">riedel</span><span>|</span><a href="#39734385">parent</a><span>|</span><a href="#39736412">prev</a><span>|</span><a href="#39734582">next</a><span>|</span><label class="collapse" for="c-39734754">[-]</label><label class="expand" for="c-39734754">[2 more]</label></div><br/><div class="children"><div class="content">One could as well use differential fuzzing.</div><br/><div id="39736691" class="c"><input type="checkbox" id="c-39736691" checked=""/><div class="controls bullet"><span class="by">klik99</span><span>|</span><a href="#39734385">root</a><span>|</span><a href="#39734754">parent</a><span>|</span><a href="#39734582">next</a><span>|</span><label class="collapse" for="c-39736691">[-]</label><label class="expand" for="c-39736691">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m amazed that there are so many good responses above only this mentions fuzzing. In the context of security, inputs might be non-linear things like adjacent memory, so I don&#x27;t see anyway to be confident about equilivancy without substantial fuzzing.<p>Honestly I just don&#x27;t see a way to formally verify this at all, it&#x27;s sounds like it could be a very useful tool but I don&#x27;t see a way for it to be fully confident. But, heck, just getting you 90% of the way towards understanding it with LLMs is still amazing and useful in real life.</div><br/></div></div></div></div><div id="39734582" class="c"><input type="checkbox" id="c-39734582" checked=""/><div class="controls bullet"><span class="by">sebastianconcpt</span><span>|</span><a href="#39734385">parent</a><span>|</span><a href="#39734754">prev</a><span>|</span><a href="#39735866">next</a><span>|</span><label class="collapse" for="c-39734582">[-]</label><label class="expand" for="c-39734582">[3 more]</label></div><br/><div class="children"><div class="content">Generators&#x27; nature is to hallucinate.</div><br/><div id="39735988" class="c"><input type="checkbox" id="c-39735988" checked=""/><div class="controls bullet"><span class="by">DougBTX</span><span>|</span><a href="#39734385">root</a><span>|</span><a href="#39734582">parent</a><span>|</span><a href="#39735866">next</a><span>|</span><label class="collapse" for="c-39735988">[-]</label><label class="expand" for="c-39735988">[2 more]</label></div><br/><div class="children"><div class="content">One man’s hallucination is another’s creativity.</div><br/><div id="39738608" class="c"><input type="checkbox" id="c-39738608" checked=""/><div class="controls bullet"><span class="by">sebastianconcpt</span><span>|</span><a href="#39734385">root</a><span>|</span><a href="#39735988">parent</a><span>|</span><a href="#39735866">next</a><span>|</span><label class="collapse" for="c-39738608">[-]</label><label class="expand" for="c-39738608">[1 more]</label></div><br/><div class="children"><div class="content">Well we need to remember that &quot;hallucination&quot; here is not a concept but a language figure for the output of a stochastic parroting machine. So what you mentinoed would be a digitally induced halluciation out of some dancing matrix multiplications &#x2F; electrons on silicon.</div><br/></div></div></div></div></div></div></div></div><div id="39734317" class="c"><input type="checkbox" id="c-39734317" checked=""/><div class="controls bullet"><span class="by">madisonmay</span><span>|</span><a href="#39734385">prev</a><span>|</span><a href="#39738304">next</a><span>|</span><label class="collapse" for="c-39734317">[-]</label><label class="expand" for="c-39734317">[2 more]</label></div><br/><div class="children"><div class="content">This is an excellent use case for LLM fine-tuning, purely because of the ease of generating a massive dataset of input &#x2F; output pairs from public C code</div><br/><div id="39737243" class="c"><input type="checkbox" id="c-39737243" checked=""/><div class="controls bullet"><span class="by">bt1a</span><span>|</span><a href="#39734317">parent</a><span>|</span><a href="#39738304">next</a><span>|</span><label class="collapse" for="c-39737243">[-]</label><label class="expand" for="c-39737243">[1 more]</label></div><br/><div class="children"><div class="content">I would also think that generating a very large amount of C code using coding LLMs (using deepseek, for example, + verifying that the output compiles) as synthetic training data would be quite beneficial in this situation. Generally the quality of synthetic training data is one of the main concerns, but in this case, the ability for the code to compile is the crux.</div><br/></div></div></div></div><div id="39738304" class="c"><input type="checkbox" id="c-39738304" checked=""/><div class="controls bullet"><span class="by">YeGoblynQueenne</span><span>|</span><a href="#39734317">prev</a><span>|</span><a href="#39733653">next</a><span>|</span><label class="collapse" for="c-39738304">[-]</label><label class="expand" for="c-39738304">[1 more]</label></div><br/><div class="children"><div class="content">If I read the &quot;re-executability&quot; results in the Results figure right then that&#x27;s a great idea but it doesn&#x27;t really work:<p><a href="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;albertan017&#x2F;LLM4Decompile&#x2F;main&#x2F;samples&#x2F;results_decompile.png" rel="nofollow">https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;albertan017&#x2F;LLM4Decompile&#x2F;...</a><p>To clarify:<p>&gt;&gt; Re-executability provides this critical measure of semantic correctness. By re-compiling the decompiled output and running the test cases, we assess if the decompilation preserved the program logic and behavior. Together, re-compilability and re-executability indicate syntax recovery and semantic preservation - both essential for usable and robust decompilation.</div><br/></div></div><div id="39733653" class="c"><input type="checkbox" id="c-39733653" checked=""/><div class="controls bullet"><span class="by">nebula8804</span><span>|</span><a href="#39738304">prev</a><span>|</span><a href="#39734160">next</a><span>|</span><label class="collapse" for="c-39733653">[-]</label><label class="expand" for="c-39733653">[5 more]</label></div><br/><div class="children"><div class="content">Will be interesting to see is there is some way to train a decompilation module based on who we know developed the application and use their previous code used as training. For example: Super Mario 64 and Zelda 64 were fully decompiled and a handful of other N64 games are in the process. I wonder if we could map which developers worked on these two games (maybe even guess who did what module) and then use that to more easily decompile any other game that had those developers working on it.<p>If this gets really good, maybe we can dream of having a fully de-obfuscated and open source life. All the layers of binary blobs in a PC can finally be decoded. All the drivers can be open. Why not do the OS as well! We don&#x27;t have to settle for Linux, we can bring back Windows XP and back port modern security and app compatibility into the OS and Microsoft can keep their Windows 11 junk...at least one can dream! :D</div><br/><div id="39737614" class="c"><input type="checkbox" id="c-39737614" checked=""/><div class="controls bullet"><span class="by">userbinator</span><span>|</span><a href="#39733653">parent</a><span>|</span><a href="#39735767">next</a><span>|</span><label class="collapse" for="c-39737614">[-]</label><label class="expand" for="c-39737614">[1 more]</label></div><br/><div class="children"><div class="content"><i>If this gets really good, maybe we can dream of having a fully de-obfuscated and open source life. All the layers of binary blobs in a PC can finally be decoded. All the drivers can be open. Why not do the OS as well!</i><p>Decompilers already exist and are really good. If an LLM can do the same as these existing compilers, you can bet the lawyers will consider it an equivalent process. The main problem is legal&#x2F;political, not technical.</div><br/></div></div><div id="39735767" class="c"><input type="checkbox" id="c-39735767" checked=""/><div class="controls bullet"><span class="by">coddle-hark</span><span>|</span><a href="#39733653">parent</a><span>|</span><a href="#39737614">prev</a><span>|</span><a href="#39734188">next</a><span>|</span><label class="collapse" for="c-39735767">[-]</label><label class="expand" for="c-39735767">[1 more]</label></div><br/><div class="children"><div class="content">I wrote my bachelor thesis on something tangential — basically, some researchers found that it was possible <i>in some very specific circumstances</i> to train a classifier to do author attribution (i.e. figure out who wrote the program) based just on the compiled binaries they produced. I don’t think the technique has been used for anything actually useful, but it’s cool to see that individual coding style survives the compilation process, so much so that you can tell one person’s compiled programs apart from another’s.</div><br/></div></div><div id="39734188" class="c"><input type="checkbox" id="c-39734188" checked=""/><div class="controls bullet"><span class="by">ZitchDog</span><span>|</span><a href="#39733653">parent</a><span>|</span><a href="#39735767">prev</a><span>|</span><a href="#39734160">next</a><span>|</span><label class="collapse" for="c-39734188">[-]</label><label class="expand" for="c-39734188">[2 more]</label></div><br/><div class="children"><div class="content">I doubt the code would be identifiable. It wouldn’t be the actual code written, but it would be very similar. But I assume many elements of code style would be lost, and any semblance of code style would be more or less hallucinated.</div><br/><div id="39734492" class="c"><input type="checkbox" id="c-39734492" checked=""/><div class="controls bullet"><span class="by">K0IN</span><span>|</span><a href="#39733653">root</a><span>|</span><a href="#39734188">parent</a><span>|</span><a href="#39734160">next</a><span>|</span><label class="collapse" for="c-39734492">[-]</label><label class="expand" for="c-39734492">[1 more]</label></div><br/><div class="children"><div class="content">if it can make test from the decompiled code, we could reimplement it with our code style. might be cool to have some bunch of llms working together with feedback loops.</div><br/></div></div></div></div></div></div><div id="39734160" class="c"><input type="checkbox" id="c-39734160" checked=""/><div class="controls bullet"><span class="by">a2code</span><span>|</span><a href="#39733653">prev</a><span>|</span><a href="#39733806">next</a><span>|</span><label class="collapse" for="c-39734160">[-]</label><label class="expand" for="c-39734160">[4 more]</label></div><br/><div class="children"><div class="content">The problem is interesting in at least two aspects. First, an ideal decompiler would eliminate proprietary source code. Second, the abundant publicly available C code allows you to simply make a dataset of paired ASM and source code. There is also a lot of variety with optimization level, compiler choice, and platform.<p>What is unclear to me is: why did the authors fine-tune the DeepSeek-Coder model? Can you train an LLM from zero with a similar dataset? How big does the LLM need to be? Can it run locally?</div><br/><div id="39736405" class="c"><input type="checkbox" id="c-39736405" checked=""/><div class="controls bullet"><span class="by">mike_hearn</span><span>|</span><a href="#39734160">parent</a><span>|</span><a href="#39739863">next</a><span>|</span><label class="collapse" for="c-39736405">[-]</label><label class="expand" for="c-39736405">[1 more]</label></div><br/><div class="children"><div class="content">Most proprietary code runs behind firewalls and won&#x27;t be affected by this one way or another.<p>It&#x27;s basically always better to start training with a pre-trained model rather than random, even if what you want isn&#x27;t that close to what you start with.</div><br/></div></div><div id="39739863" class="c"><input type="checkbox" id="c-39739863" checked=""/><div class="controls bullet"><span class="by">saagarjha</span><span>|</span><a href="#39734160">parent</a><span>|</span><a href="#39736405">prev</a><span>|</span><a href="#39734177">next</a><span>|</span><label class="collapse" for="c-39739863">[-]</label><label class="expand" for="c-39739863">[1 more]</label></div><br/><div class="children"><div class="content">Ideal decompilers do not exist. In some sense they can never exist as compilers are lossy, but even taking a liberal view of “high level understanding of the resulting code” this is essentially the AGI for computer security. Nobody has come close to it!</div><br/></div></div><div id="39734177" class="c"><input type="checkbox" id="c-39734177" checked=""/><div class="controls bullet"><span class="by">3abiton</span><span>|</span><a href="#39734160">parent</a><span>|</span><a href="#39739863">prev</a><span>|</span><a href="#39733806">next</a><span>|</span><label class="collapse" for="c-39734177">[-]</label><label class="expand" for="c-39734177">[1 more]</label></div><br/><div class="children"><div class="content">I assume it&#x27;s related to the cost of training vs fine-tuning. It could be also a starting point to validate an idea.</div><br/></div></div></div></div><div id="39733806" class="c"><input type="checkbox" id="c-39733806" checked=""/><div class="controls bullet"><span class="by">kukas</span><span>|</span><a href="#39734160">prev</a><span>|</span><a href="#39739934">next</a><span>|</span><label class="collapse" for="c-39733806">[-]</label><label class="expand" for="c-39733806">[5 more]</label></div><br/><div class="children"><div class="content">Hey, I am working on my own LLM-based decompiler for Python bytecode (<a href="https:&#x2F;&#x2F;github.com&#x2F;kukas&#x2F;deepcompyle">https:&#x2F;&#x2F;github.com&#x2F;kukas&#x2F;deepcompyle</a>). I feel there are not many people working on this research direction but I think it could be quite interesting, especially now that longer attention contexts are becoming feasible. If anyone knows a team that is working on this, I would be quite interested in cooperation.</div><br/><div id="39738413" class="c"><input type="checkbox" id="c-39738413" checked=""/><div class="controls bullet"><span class="by">a2code</span><span>|</span><a href="#39733806">parent</a><span>|</span><a href="#39735843">next</a><span>|</span><label class="collapse" for="c-39738413">[-]</label><label class="expand" for="c-39738413">[2 more]</label></div><br/><div class="children"><div class="content">Why Python? First, python is a language with a large open-source library. Second, I do not think it is used for software that is distributed as binaries?</div><br/><div id="39739757" class="c"><input type="checkbox" id="c-39739757" checked=""/><div class="controls bullet"><span class="by">Retr0id</span><span>|</span><a href="#39733806">root</a><span>|</span><a href="#39738413">parent</a><span>|</span><a href="#39735843">next</a><span>|</span><label class="collapse" for="c-39739757">[-]</label><label class="expand" for="c-39739757">[1 more]</label></div><br/><div class="children"><div class="content">Closed-source python exists, and it is frequently distributed in compiled binaries (especially in mediocre malware).<p>As a (supposedly) non-malicious example, the &quot;Nightshade&quot; watermarking tool is distributed as closed-source pre-compiled Python <a href="https:&#x2F;&#x2F;nightshade.cs.uchicago.edu&#x2F;downloads.html" rel="nofollow">https:&#x2F;&#x2F;nightshade.cs.uchicago.edu&#x2F;downloads.html</a></div><br/></div></div></div></div><div id="39735843" class="c"><input type="checkbox" id="c-39735843" checked=""/><div class="controls bullet"><span class="by">ok123456</span><span>|</span><a href="#39733806">parent</a><span>|</span><a href="#39738413">prev</a><span>|</span><a href="#39739934">next</a><span>|</span><label class="collapse" for="c-39735843">[-]</label><label class="expand" for="c-39735843">[2 more]</label></div><br/><div class="children"><div class="content">Is there a benefit from using an LLM for Python byte code? Python byte code is high enough level that it&#x27;s possible to translate it directly to source code from my experience.</div><br/><div id="39736229" class="c"><input type="checkbox" id="c-39736229" checked=""/><div class="controls bullet"><span class="by">kukas</span><span>|</span><a href="#39733806">root</a><span>|</span><a href="#39735843">parent</a><span>|</span><a href="#39739934">next</a><span>|</span><label class="collapse" for="c-39736229">[-]</label><label class="expand" for="c-39736229">[1 more]</label></div><br/><div class="children"><div class="content">My motivation is that the existing decompilers work only for Python versions till ~3.8. Having a model that could be finetuned with every new Python version release might overcome the need for highly specialized programmer that is able to update the decompiler to be compatible with the new version.<p>It is also a toy example for me to set up a working pipeline and then try to decompile more interesting targets.</div><br/></div></div></div></div></div></div><div id="39739934" class="c"><input type="checkbox" id="c-39739934" checked=""/><div class="controls bullet"><span class="by">saagarjha</span><span>|</span><a href="#39733806">prev</a><span>|</span><a href="#39733524">next</a><span>|</span><label class="collapse" for="c-39739934">[-]</label><label class="expand" for="c-39739934">[1 more]</label></div><br/><div class="children"><div class="content">The approach here is interesting in that it answers a question a lot of people have been asking: “what happens if we pipe a binary into a trained LLM and ask it to decompile it?” The answer is that it doesn’t really work at all right now! This is a surprising result because the design of the paper kind of doesn’t allow for any other conclusion to be drawn. Notably, if the LLM did a really good job in the evaluation they designed it would still be unclear whether it was actually useful, because the test “does it compile and pass a few test cases” is not actually a very good way to test a decompiler.<p>A couple people here have suggested that the generated decompilation should match the  source code exactly, which is a challenging thing to achieve and still hotly debated on whether it is a good metric or not. But the results here show that we’re starting to barely get past the “does it produce code” stage and move towards “does it produce code that looks vaguely correct” status but we’re definitely not there yet. Future steps of “is this a useful tool to drive decompilation” and “does this do better than state of the art” and “is this perfect at decompiling things” are still a long ways away. So it’s good to look at as a negative result as this area continues to attract new interest.</div><br/></div></div><div id="39733524" class="c"><input type="checkbox" id="c-39733524" checked=""/><div class="controls bullet"><span class="by">potatoman22</span><span>|</span><a href="#39739934">prev</a><span>|</span><a href="#39737583">next</a><span>|</span><label class="collapse" for="c-39733524">[-]</label><label class="expand" for="c-39733524">[3 more]</label></div><br/><div class="children"><div class="content">It&#x27;s interesting the 6b model outperforms the 33b model. I wonder if it means the 33b model needs more training data? It was pretrained on ~1 million C programs, compared to DeepSeek-Coder, which was trained on 2 trillion tokens, which is a few orders of magnitude more data.<p>I&#x27;m also curious about how this compares to non-LLM solutions.</div><br/><div id="39734977" class="c"><input type="checkbox" id="c-39734977" checked=""/><div class="controls bullet"><span class="by">mattashii</span><span>|</span><a href="#39733524">parent</a><span>|</span><a href="#39735156">next</a><span>|</span><label class="collapse" for="c-39734977">[-]</label><label class="expand" for="c-39734977">[1 more]</label></div><br/><div class="children"><div class="content">&gt; on ~1 million C programs, compared to [...] 2 trillion tokens, which is a few orders of magnitude more data.<p>Is that comparable like that? This would assume that the average C program of the set is orders (plural) of magnitude less than 2m tokens in size, which could indeed be true but sounds like an optimistic assumption.</div><br/></div></div><div id="39735156" class="c"><input type="checkbox" id="c-39735156" checked=""/><div class="controls bullet"><span class="by">Der_Einzige</span><span>|</span><a href="#39733524">parent</a><span>|</span><a href="#39734977">prev</a><span>|</span><a href="#39737583">next</a><span>|</span><label class="collapse" for="c-39735156">[-]</label><label class="expand" for="c-39735156">[1 more]</label></div><br/><div class="children"><div class="content">This has been the dynamics with LLMs for awhile. The majority of LLMs are massively <i>undertrained</i>. 7b models are the least &quot;undertrained&quot; mainstream models we have, hence why they have proliferated so much among the LLM fine-tuning community.</div><br/></div></div></div></div><div id="39737583" class="c"><input type="checkbox" id="c-39737583" checked=""/><div class="controls bullet"><span class="by">mahaloz</span><span>|</span><a href="#39733524">prev</a><span>|</span><a href="#39736664">next</a><span>|</span><label class="collapse" for="c-39737583">[-]</label><label class="expand" for="c-39737583">[1 more]</label></div><br/><div class="children"><div class="content">It’s always cool to see different approaches in this area, but I worry its benchmarks are meaningless without a comparison of non-AI based approaches (like IDA Pro). It would be interesting to see how this model holds up on metrics from previous papers in security.</div><br/></div></div><div id="39736664" class="c"><input type="checkbox" id="c-39736664" checked=""/><div class="controls bullet"><span class="by">sinuhe69</span><span>|</span><a href="#39737583">prev</a><span>|</span><a href="#39733590">next</a><span>|</span><label class="collapse" for="c-39736664">[-]</label><label class="expand" for="c-39736664">[2 more]</label></div><br/><div class="children"><div class="content">For me the huge difference between re-compilability and re-excuteability scores is very interesting. GTP4 achieved 8x% on re-compilability (syntactically correct) but abysmal 1x% in re-excutability (schematically correct) demonstrated once again its overgrown mimicry capacity.</div><br/><div id="39737023" class="c"><input type="checkbox" id="c-39737023" checked=""/><div class="controls bullet"><span class="by">sitkack</span><span>|</span><a href="#39736664">parent</a><span>|</span><a href="#39733590">next</a><span>|</span><label class="collapse" for="c-39737023">[-]</label><label class="expand" for="c-39737023">[1 more]</label></div><br/><div class="children"><div class="content">&gt; overgrown mimicry<p>I don&#x27;t think it shows that. GPT4 was not trained on decompiling binaries back into C. Amazing result for an untrained task.<p>We are soon going to have robust toolchain detection from binaries, and source recovery with variable and function names.</div><br/></div></div></div></div><div id="39733590" class="c"><input type="checkbox" id="c-39733590" checked=""/><div class="controls bullet"><span class="by">kken</span><span>|</span><a href="#39736664">prev</a><span>|</span><a href="#39733539">next</a><span>|</span><label class="collapse" for="c-39733590">[-]</label><label class="expand" for="c-39733590">[1 more]</label></div><br/><div class="children"><div class="content">Pretty wild how well GPT4 is still doing in comparison. It&#x27;s significantly better than their model at creating compilable code, but is less accurate at recreating functional code. Still quite impressive.</div><br/></div></div><div id="39733539" class="c"><input type="checkbox" id="c-39733539" checked=""/><div class="controls bullet"><span class="by">maCDzP</span><span>|</span><a href="#39733590">prev</a><span>|</span><a href="#39735343">next</a><span>|</span><label class="collapse" for="c-39733539">[-]</label><label class="expand" for="c-39733539">[4 more]</label></div><br/><div class="children"><div class="content">Can this be used for deobfuscation of code?
I really hadn’t thought about LLM being a tool during reverse engineering.</div><br/><div id="39734082" class="c"><input type="checkbox" id="c-39734082" checked=""/><div class="controls bullet"><span class="by">Tiberium</span><span>|</span><a href="#39733539">parent</a><span>|</span><a href="#39734750">next</a><span>|</span><label class="collapse" for="c-39734082">[-]</label><label class="expand" for="c-39734082">[1 more]</label></div><br/><div class="children"><div class="content">Big LLMs like GPT-4 (and even GPT 3.5 Turbo) can be directly used to beautify obfuscated&#x2F;minified JS, see e.g. <a href="https:&#x2F;&#x2F;thejunkland.com&#x2F;blog&#x2F;using-llms-to-reverse-javascript-minification.html" rel="nofollow">https:&#x2F;&#x2F;thejunkland.com&#x2F;blog&#x2F;using-llms-to-reverse-javascrip...</a> and <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=34503233">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=34503233</a></div><br/></div></div><div id="39734750" class="c"><input type="checkbox" id="c-39734750" checked=""/><div class="controls bullet"><span class="by">Eager</span><span>|</span><a href="#39733539">parent</a><span>|</span><a href="#39734082">prev</a><span>|</span><a href="#39735168">next</a><span>|</span><label class="collapse" for="c-39734750">[-]</label><label class="expand" for="c-39734750">[1 more]</label></div><br/><div class="children"><div class="content">I have tried feeding some of the foundation models obfuscated code from some of the competitions.<p>People might think that the answers would be in the training data already, but I didn&#x27;t find that to be the case. At least in my small experiments.<p>The model&#x27;s did try to guess what the code does.  They would say things like, &quot;It seems to be trying to print some message to the console&quot;.  I wasn&#x27;t able to get full solutions.<p>It&#x27;s definitely worth more research, not just as a curiosity, but these kinds of problems are good proxies for other tasks and also excellent benchmarks for LLMs particularly.</div><br/></div></div><div id="39735168" class="c"><input type="checkbox" id="c-39735168" checked=""/><div class="controls bullet"><span class="by">evmar</span><span>|</span><a href="#39733539">parent</a><span>|</span><a href="#39734750">prev</a><span>|</span><a href="#39735343">next</a><span>|</span><label class="collapse" for="c-39735168">[-]</label><label class="expand" for="c-39735168">[1 more]</label></div><br/><div class="children"><div class="content">I did a little experiment with this here:<p><a href="https:&#x2F;&#x2F;neugierig.org&#x2F;software&#x2F;blog&#x2F;2023&#x2F;01&#x2F;compiling-advent.html" rel="nofollow">https:&#x2F;&#x2F;neugierig.org&#x2F;software&#x2F;blog&#x2F;2023&#x2F;01&#x2F;compiling-advent...</a></div><br/></div></div></div></div><div id="39735343" class="c"><input type="checkbox" id="c-39735343" checked=""/><div class="controls bullet"><span class="by">AndrewKemendo</span><span>|</span><a href="#39733539">prev</a><span>|</span><a href="#39734044">next</a><span>|</span><label class="collapse" for="c-39735343">[-]</label><label class="expand" for="c-39735343">[1 more]</label></div><br/><div class="children"><div class="content">If successful wouldn’t you be replicating the compilers machine code 1:1?<p>In which case that means fully complete code can live in the “latent space” but is distributed as probabilities<p>Or perhaps more likely would it be replicating the logic only, which can then be translated into the target language<p>I would guess that any binary that requires a non-deterministic input (key, hash etc…) to compile would break this<p>Fascinating</div><br/></div></div><div id="39734044" class="c"><input type="checkbox" id="c-39734044" checked=""/><div class="controls bullet"><span class="by">jagrsw</span><span>|</span><a href="#39735343">prev</a><span>|</span><a href="#39736495">next</a><span>|</span><label class="collapse" for="c-39734044">[-]</label><label class="expand" for="c-39734044">[1 more]</label></div><br/><div class="children"><div class="content">Decompilation is somewhat a default choice for ML in the world of comp-sec.<p>Searching for vulns and producing patches in source code is a bit problematic, as the databases of vulnerable source code examples and their corresponding patches are neither well-structured nor comprehensive, and sometimes very, very specific to the analyzed code (for higher abstraction type of problems). So, it&#x27;s not easy to train something usable beyond standard mem safety problems and use of unsafe APIs.<p>The area of fuzzing is somewhat messy, with sporadic efforts undertaken here and there, but it also requires a lot of preparatory work, and the results might not be groundbreaking unless we reach a point where we can feed an ML model the entire source code of a project, allowing it to analyze and identify all bugs, producing fixes and providing offending inputs. i.e. not yet.<p>While decompilation is a fairly standard problem, it is possible to produce input-output pairs somewhat at will based on existing source code, using various compiler switches, CPU architectures, ABIs, obfuscations, syscall calling conventions. And train models on those input-output pairs (i.e. in reversed order).</div><br/></div></div><div id="39736495" class="c"><input type="checkbox" id="c-39736495" checked=""/><div class="controls bullet"><span class="by">mdaniel</span><span>|</span><a href="#39734044">prev</a><span>|</span><a href="#39740743">next</a><span>|</span><label class="collapse" for="c-39736495">[-]</label><label class="expand" for="c-39736495">[1 more]</label></div><br/><div class="children"><div class="content">relevant: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=34250872">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=34250872</a> (<i>G-3PO: A protocol droid for Ghidra, or GPT-3 for reverse-engineering</i> &lt;<a href="https:&#x2F;&#x2F;github.com&#x2F;tenable&#x2F;ghidra_tools&#x2F;blob&#x2F;main&#x2F;g3po&#x2F;g3po.py">https:&#x2F;&#x2F;github.com&#x2F;tenable&#x2F;ghidra_tools&#x2F;blob&#x2F;main&#x2F;g3po&#x2F;g3po....</a>&gt;; Jan, 2023; 44 comments)<p><i>ed</i>: seems they have this, too, which may value your submission: <a href="https:&#x2F;&#x2F;github.com&#x2F;tenable&#x2F;awesome-llm-cybersecurity-tools#awesome-large-language-model-tools-for-cybersecurity-research">https:&#x2F;&#x2F;github.com&#x2F;tenable&#x2F;awesome-llm-cybersecurity-tools#a...</a></div><br/></div></div><div id="39740743" class="c"><input type="checkbox" id="c-39740743" checked=""/><div class="controls bullet"><span class="by">xvilka</span><span>|</span><a href="#39736495">prev</a><span>|</span><a href="#39739050">next</a><span>|</span><label class="collapse" for="c-39740743">[-]</label><label class="expand" for="c-39740743">[1 more]</label></div><br/><div class="children"><div class="content">I think using higher-level input, e.g. the intermediate language like RzIL[1] could produce better results and is more scalable for making such decompliation multiplatform. As RzIL text form resemples SMT, it should make LLM easier to &quot;understand&quot; the meaning. Moreover, information from binary such as symbols, signatures, debug information (DWARF, PDB, etc) could enrich the result further. You can download Rizin[2] and try for yourself by calling `aaa` then `plf` for any chosen functions for architectures supported by RzIL. See the example excerpt for a function with this disassembly:<p><pre><code>  │       │   0x140007e51      movsd qword [rdi + 0x50], xmm2
  │       │   0x140007e56      mov   qword [rdi + 0x48], 0
  │       │   0x140007e5e      call  sym.rz_test.exe_ht_pp_free          ; sym.rz_test.exe_ht_pp_free
  │       │   0x140007e63      movaps xmm7, xmmword [var_38h]
  │       │   0x140007e68      movaps xmm6, xmmword [var_28h]
  │       │   0x140007e6d      mov   rbp, qword [var_10h]
  │       └─&gt; 0x140007e72      add   rsp, 0x48
  │           0x140007e76      pop   r15
  │           0x140007e78      pop   rdi
  └           0x140007e79      ret

  0x140007e6d (set rbp (loadw 0 64 (+ (var rsp) (bv 64 0x68))))
  0x140007e72 (seq (set op1 (var rsp)) (set op2 (bv 64 0x48)) (set sum (+ (var op1) (var op2))) (set rsp (var sum)) (set _result (var sum)) (set _popcnt (bv 8 0x0)) (set _val (cast 8 false (var _result))) (repeat (! (is_zero (var _val))) (seq (set _popcnt (+ (var _popcnt) (ite (lsb (var _val)) (bv 8 0x1) (bv 8 0x0)))) (set _val (&gt;&gt; (var _val) (bv 8 0x1) false)))) (set pf (is_zero (mod (var _popcnt) (bv 8 0x2)))) (set zf (is_zero (var _result))) (set sf (msb (var _result))) (set _result (var sum)) (set _x (var op1)) (set _y (var op2)) (set cf (|| (|| (&amp;&amp; (msb (var _x)) (msb (var _y))) (&amp;&amp; (! (msb (var _result))) (msb (var _y)))) (&amp;&amp; (msb (var _x)) (! (msb (var _result)))))) (set of (|| (&amp;&amp; (&amp;&amp; (! (msb (var _result))) (msb (var _x))) (msb (var _y))) (&amp;&amp; (&amp;&amp; (msb (var _result)) (! (msb (var _x)))) (! (msb (var _y)))))) (set af (|| (|| (&amp;&amp; (msb (cast 4 false (var _x))) (msb (cast 4 false (var _y)))) (&amp;&amp; (! (msb (cast 4 false (var _result)))) (msb (cast 4 false (var _y))))) (&amp;&amp; (msb (cast 4 false (var _x))) (! (msb (cast 4 false (var _result))))))))
  0x140007e76 (seq (set r15 (cast 64 false (loadw 0 64 (+ (var rsp) (bv 64 0x0))))) (set rsp (+ (var rsp) (bv 64 0x8))))
  0x140007e78 (seq (set rdi (loadw 0 64 (+ (var rsp) (bv 64 0x0)))) (set rsp (+ (var rsp) (bv 64 0x8))))
  0x140007e79 (seq (set tgt (loadw 0 64 (+ (var rsp) (bv 64 0x0)))) (set rsp (+ (var rsp) (bv 64 0x8))) (jmp (var tgt)))
</code></pre>
[1] <a href="https:&#x2F;&#x2F;github.com&#x2F;rizinorg&#x2F;rizin&#x2F;blob&#x2F;dev&#x2F;doc&#x2F;rzil.md">https:&#x2F;&#x2F;github.com&#x2F;rizinorg&#x2F;rizin&#x2F;blob&#x2F;dev&#x2F;doc&#x2F;rzil.md</a><p>[2] <a href="https:&#x2F;&#x2F;rizin.re" rel="nofollow">https:&#x2F;&#x2F;rizin.re</a></div><br/></div></div><div id="39739050" class="c"><input type="checkbox" id="c-39739050" checked=""/><div class="controls bullet"><span class="by">Nuzzerino</span><span>|</span><a href="#39740743">prev</a><span>|</span><a href="#39736935">next</a><span>|</span><label class="collapse" for="c-39739050">[-]</label><label class="expand" for="c-39739050">[1 more]</label></div><br/><div class="children"><div class="content">How does it actually compare to non-LLM decompilers IDA, Binja, etc? I only see comparisons with other LLMs.</div><br/></div></div><div id="39736935" class="c"><input type="checkbox" id="c-39736935" checked=""/><div class="controls bullet"><span class="by">speedylight</span><span>|</span><a href="#39739050">prev</a><span>|</span><a href="#39737470">next</a><span>|</span><label class="collapse" for="c-39736935">[-]</label><label class="expand" for="c-39736935">[1 more]</label></div><br/><div class="children"><div class="content">I have thought about doing something similar for heavily obfuscated JavaScript. Very useful for security research I imagine!</div><br/></div></div><div id="39737431" class="c"><input type="checkbox" id="c-39737431" checked=""/><div class="controls bullet"><span class="by">quantum_state</span><span>|</span><a href="#39733572">prev</a><span>|</span><a href="#39735257">next</a><span>|</span><label class="collapse" for="c-39737431">[-]</label><label class="expand" for="c-39737431">[1 more]</label></div><br/><div class="children"><div class="content">It seems the next logical step would be LLMAssistedHacking to turn things up side down…</div><br/></div></div><div id="39735257" class="c"><input type="checkbox" id="c-39735257" checked=""/><div class="controls bullet"><span class="by">ReptileMan</span><span>|</span><a href="#39737431">prev</a><span>|</span><a href="#39735381">next</a><span>|</span><label class="collapse" for="c-39735257">[-]</label><label class="expand" for="c-39735257">[2 more]</label></div><br/><div class="children"><div class="content">Let&#x27;s hope it kills Denuvo ...</div><br/><div id="39739777" class="c"><input type="checkbox" id="c-39739777" checked=""/><div class="controls bullet"><span class="by">Retr0id</span><span>|</span><a href="#39735257">parent</a><span>|</span><a href="#39735381">next</a><span>|</span><label class="collapse" for="c-39739777">[-]</label><label class="expand" for="c-39739777">[1 more]</label></div><br/><div class="children"><div class="content">Decompilation and deobfuscation are related but distinct tasks</div><br/></div></div></div></div><div id="39735381" class="c"><input type="checkbox" id="c-39735381" checked=""/><div class="controls bullet"><span class="by">m3kw9</span><span>|</span><a href="#39735257">prev</a><span>|</span><a href="#39736075">next</a><span>|</span><label class="collapse" for="c-39735381">[-]</label><label class="expand" for="c-39735381">[1 more]</label></div><br/><div class="children"><div class="content">Basically predicting code token by token except now you don’t even have a large enough context size and worse, you are using RAG</div><br/></div></div><div id="39736075" class="c"><input type="checkbox" id="c-39736075" checked=""/><div class="controls bullet"><span class="by">xorvoid</span><span>|</span><a href="#39735381">prev</a><span>|</span><a href="#39733808">next</a><span>|</span><label class="collapse" for="c-39736075">[-]</label><label class="expand" for="c-39736075">[4 more]</label></div><br/><div class="children"><div class="content">As someone who is actively developing a decompiler to reverse engineer old DOS 8086 video games, I&#x27;d have a hard time trusting an LLM to do this correctly. My standard is accurate semantics lifting from Machine Code to C. Reversing assembly to C is very delicate. There are many patterns that tend to <i>usually</i> map to obvious C constructs... except when they don&#x27;t. And that assumes the original source was C. Once you bump into routines that were hand-coded assembly and break every established rule in the calling conventions, all bets are off. I&#x27;m somewhat convinced that decompilation cannot be made fully-automatic. Instead a good decompiler is just a lever-arm on the manual work a reverser would otherwise be doing. Corollary: I&#x27;m also somewhat convinced that only the decompiler&#x27;s developers can really use it most effectively because they know where the &quot;bodies are buried&quot; and where different heuristics and assumptions were made. Decompilers are compilers with all the usual engineering challenges, plus a hard inference problem tacked on top.<p>All that said, I&#x27;m not a pessimist on this idea. I think it has pretty great promise as a technique for general reversing security analysis where the reversing is done mostly for &quot;discovery&quot; and &quot;understanding&quot; rather than for perfect semantic lifting to a high-level language. In that world, you can afford to develop &quot;hypotheses&quot; and then drill down to validate if you think you&#x27;ve discovered something big.<p>Compiling and testing the resulting decompilation is a great idea. I do that as well. The limitation here is TEST SUITE. Some random binary doesn&#x27;t typically come with a high-coverage test suite, so you have to develop your own acceptance criterion as you go along. In other words: write tests for a function whose computation you don&#x27;t understand (ha). I suppose a form of static-analysis &#x2F; symbolic-computation might be handy here (I haven&#x27;t explored that). Here you&#x27;re also beset with challenges of specifying which machine state changes are important and which are superfluous (e.g. is it okay if the x86 FLAGS register isn&#x27;t modified in the decompiled version, probably yes, but sometimes no).<p>In my case I don&#x27;t have access to the original compiler and even if I did, I&#x27;m not sure I could convince it to reproduce the same code. Maybe this is more feasible for more modern binaries where you can assume GCC, Clang, MSVC, or ICC.<p>At any rate: crazy hard, crazy fun problem. I&#x27;m sure LLMs have a role somewhere, but I&#x27;m not sure exactly where: the future will tell. My guess is some kind of &quot;copilot&quot; &#x2F; &quot;assistant&quot; type role rather than directly making the decisions.<p>(If this is your kind of thing... I&#x27;ll be writing more about it on my blog soonish...)</div><br/><div id="39738368" class="c"><input type="checkbox" id="c-39738368" checked=""/><div class="controls bullet"><span class="by">a2code</span><span>|</span><a href="#39736075">parent</a><span>|</span><a href="#39738988">next</a><span>|</span><label class="collapse" for="c-39738368">[-]</label><label class="expand" for="c-39738368">[2 more]</label></div><br/><div class="children"><div class="content">I would devise a somewhat loose metric. Consider you assign a percentage as to how much a binary is disassembled. As in, 0% means the binary is in assembly and 100% means the whole binary is now C code. The ideal decompiler would result in 100% for any binary.<p>My prediction is that this percentage will increase with time. It would be interesting to construct data for this metric.<p>It is important to define the limitations of using LLMs for this endeavor. I would like to emphasize your subtle point. The compiler used for the original binary may not be the same as the one you use. The probability of this increases with time, as compilers improve or the platform on which the binary runs becomes obsolete. This is a problem for validation, as in you cannot directly compare original assembly code with assembly after compiling C code (that came from decompiling).<p>Perhaps assembly routines could be given a likelihood, as in how sure the LLM is that some C code maps to assembly. Then, routines with hand-coded assembly would have a lower likelihood.</div><br/></div></div><div id="39738988" class="c"><input type="checkbox" id="c-39738988" checked=""/><div class="controls bullet"><span class="by">ouraf</span><span>|</span><a href="#39736075">parent</a><span>|</span><a href="#39738368">prev</a><span>|</span><a href="#39733808">next</a><span>|</span><label class="collapse" for="c-39738988">[-]</label><label class="expand" for="c-39738988">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m curious about the decompilation process.<p>I know compiling is a lossy process and optimization can make things even harder to remap, but if an LLM can recognize patterns correctly, chunk or classify each routine or even give a more palatable overview of what a part of the code is meant to do step by step, it becomes closer to what HexRays offer with their assembly to pseudo code translator. And from that point, it can make serviceable translations to real world languages.<p>LLMs won&#x27;t replace an engineer, but maybe they can help romhackers in identifying bugs or how some values are calculated by a game.</div><br/></div></div></div></div></div></div></div></div></div></body></html>