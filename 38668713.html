<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1702890066737" as="style"/><link rel="stylesheet" href="styles.css?v=1702890066737"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://spectrum.ieee.org/cfet-intel-samsung-tsmc">Intel, Samsung, and TSMC Demo 3D-Stacked Transistors</a> <span class="domain">(<a href="https://spectrum.ieee.org">spectrum.ieee.org</a>)</span></div><div class="subtext"><span>jnord</span> | <span>133 comments</span></div><br/><div><div id="38669879" class="c"><input type="checkbox" id="c-38669879" checked=""/><div class="controls bullet"><span class="by">tambourine_man</span><span>|</span><a href="#38669384">next</a><span>|</span><label class="collapse" for="c-38669879">[-]</label><label class="expand" for="c-38669879">[41 more]</label></div><br/><div class="children"><div class="content">It’s fun to be just a curious bystander for many years in this industry.<p>Every now and then Moore’s law hits a roadblock. Some experts see that as a clear sign that  it’s reaching its end. Others that it’s already dead, because actually, the price per transistor has increased. Others that it’s physics, we can approach Y but after X nm it can’t be done.<p>Then you read others that claim that Intel has just been lazy enjoying its almost monopoly for the past decade and was caught off guard by TSMC’s ultraviolet prowess. Or people who really know how the sausage is made, like Jim Keller, enthusiastically stating that we are nowhere near  any major fundamental limitation and can expect 1000X improvement in the years to come at least.<p>Anyway, it’s really fun to watch, like I said. Hard to think of a field with such rollercoaster-like forecasting while still delivering unparalleled growth in such a steady state for decades.</div><br/><div id="38669949" class="c"><input type="checkbox" id="c-38669949" checked=""/><div class="controls bullet"><span class="by">zozbot234</span><span>|</span><a href="#38669879">parent</a><span>|</span><a href="#38670909">next</a><span>|</span><label class="collapse" for="c-38669949">[-]</label><label class="expand" for="c-38669949">[25 more]</label></div><br/><div class="children"><div class="content">The limitations are very real. Dennard scaling has been dead since the mid-2000s (that is, power use per unit area has been increasing, even though energy use per logic operation <i>is</i> very much dropping at leading edge nodes) which means an increasing fraction of all silicon has to be &quot;dark&quot;, power-gated and only used for the rare accelerated workload.  Additionally, recent nodes have seen very little improvement in SRAM cell size which is used for register files and caches.  So perhaps we&#x27;ll be seeing relatively smaller caches per core in the future, and the addition of eDRAM (either on-die or on a separate chiplet) as a new, slower L4 level to partially cope with that.</div><br/><div id="38670947" class="c"><input type="checkbox" id="c-38670947" checked=""/><div class="controls bullet"><span class="by">projectileboy</span><span>|</span><a href="#38669879">root</a><span>|</span><a href="#38669949">parent</a><span>|</span><a href="#38670093">next</a><span>|</span><label class="collapse" for="c-38670947">[-]</label><label class="expand" for="c-38670947">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m ignorant of this space, but it seems like the obvious solution for heat dissipation is to layer lattices and not solid layers, in order to increase the overall surface area of the chip. I assume the manufacturing is too difficult...?</div><br/><div id="38671123" class="c"><input type="checkbox" id="c-38671123" checked=""/><div class="controls bullet"><span class="by">fooker</span><span>|</span><a href="#38669879">root</a><span>|</span><a href="#38670947">parent</a><span>|</span><a href="#38670093">next</a><span>|</span><label class="collapse" for="c-38671123">[-]</label><label class="expand" for="c-38671123">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s one of the promises of 3D stacked transistors, yes.</div><br/></div></div></div></div><div id="38670093" class="c"><input type="checkbox" id="c-38670093" checked=""/><div class="controls bullet"><span class="by">mikepurvis</span><span>|</span><a href="#38669879">root</a><span>|</span><a href="#38669949">parent</a><span>|</span><a href="#38670947">prev</a><span>|</span><a href="#38678838">next</a><span>|</span><label class="collapse" for="c-38670093">[-]</label><label class="expand" for="c-38670093">[16 more]</label></div><br/><div class="children"><div class="content">What if it went the other way and you got much larger die area dedicated to caches or even on-chip RAM, since that usage is relatively cheaper from a power&#x2F;heat point of view? Or is the process different enough between the two that it just doesn&#x27;t make sense to have them interwoven like that?</div><br/><div id="38670396" class="c"><input type="checkbox" id="c-38670396" checked=""/><div class="controls bullet"><span class="by">treesciencebot</span><span>|</span><a href="#38669879">root</a><span>|</span><a href="#38670093">parent</a><span>|</span><a href="#38670390">next</a><span>|</span><label class="collapse" for="c-38670396">[-]</label><label class="expand" for="c-38670396">[12 more]</label></div><br/><div class="children"><div class="content">The point of SRAM, especially at the L1&#x2F;L2 level is having an extremely high BW and extremely low latency (a few clock cycles). So it is not really an option to put them somewhere else (although L3 and as mentioned other lower level layers) can and are already being put into either separate chiplets in the same PCB w&#x2F;extremely fast ring OR directly on top of the die (3D stacking).</div><br/><div id="38670532" class="c"><input type="checkbox" id="c-38670532" checked=""/><div class="controls bullet"><span class="by">chongli</span><span>|</span><a href="#38669879">root</a><span>|</span><a href="#38670396">parent</a><span>|</span><a href="#38670593">next</a><span>|</span><label class="collapse" for="c-38670532">[-]</label><label class="expand" for="c-38670532">[4 more]</label></div><br/><div class="children"><div class="content">Yeah. The analogy for cache that I like to use is a table at the library. If you think about doing research (the old fashioned way) by looking through a library shelf by shelf and bringing books to your table to read through more closely. If you have a bigger table you can store more books which can speed your lookup times since you don’t need to get up and go back and forth to the shelves.<p>But at some point making your table larger just defeats the purpose of the library itself. Your table becomes the new library, and you have to walk around on it and look up things in these piles of books. So you make a smaller table in the middle of the big table.<p>Your fundamental limitation is how small you can make a memory cell, not how big you want to make a cache. That’s akin to making the books smaller print size so you can fit more on the same size table.</div><br/><div id="38673698" class="c"><input type="checkbox" id="c-38673698" checked=""/><div class="controls bullet"><span class="by">markhahn</span><span>|</span><a href="#38669879">root</a><span>|</span><a href="#38670532">parent</a><span>|</span><a href="#38672888">next</a><span>|</span><label class="collapse" for="c-38673698">[-]</label><label class="expand" for="c-38673698">[2 more]</label></div><br/><div class="children"><div class="content">well, sorta, since caches are just sram+tag logic.  you can parallelize tables, so that each remains fast, but it costs you power&#x2F;heat.  the decoder inherent to sram is what introduces the size-speed tradeoff.</div><br/><div id="38673986" class="c"><input type="checkbox" id="c-38673986" checked=""/><div class="controls bullet"><span class="by">chongli</span><span>|</span><a href="#38669879">root</a><span>|</span><a href="#38673698">parent</a><span>|</span><a href="#38672888">next</a><span>|</span><label class="collapse" for="c-38673986">[-]</label><label class="expand" for="c-38673986">[1 more]</label></div><br/><div class="children"><div class="content">I was ignoring the details on how SRAM works in favour of thinking about it physically. Most of those details just affect the average cell size at the end of the day.<p>The other physical aspect we’re dealing with is propagation delay and physical distance. That’s where the library analogy really shines: if there’s a minimum size to a book and a minimum size of you (the person doing the research) this corresponds roughly to minimum cell sizes and minimum wire pitch, so you’re ultimately limited in the density you can fit within a given volume.</div><br/></div></div></div></div><div id="38672888" class="c"><input type="checkbox" id="c-38672888" checked=""/><div class="controls bullet"><span class="by">randall</span><span>|</span><a href="#38669879">root</a><span>|</span><a href="#38670532">parent</a><span>|</span><a href="#38673698">prev</a><span>|</span><a href="#38670593">next</a><span>|</span><label class="collapse" for="c-38672888">[-]</label><label class="expand" for="c-38672888">[1 more]</label></div><br/><div class="children"><div class="content">Really good analogy!</div><br/></div></div></div></div><div id="38670593" class="c"><input type="checkbox" id="c-38670593" checked=""/><div class="controls bullet"><span class="by">DeathArrow</span><span>|</span><a href="#38669879">root</a><span>|</span><a href="#38670396">parent</a><span>|</span><a href="#38670532">prev</a><span>|</span><a href="#38670390">next</a><span>|</span><label class="collapse" for="c-38670593">[-]</label><label class="expand" for="c-38670593">[7 more]</label></div><br/><div class="children"><div class="content">Is it possible to use big and fat CPU registers instead of cache? There might be no wasted clock cycles and no delay.</div><br/><div id="38670919" class="c"><input type="checkbox" id="c-38670919" checked=""/><div class="controls bullet"><span class="by">Nevermark</span><span>|</span><a href="#38669879">root</a><span>|</span><a href="#38670593">parent</a><span>|</span><a href="#38670898">next</a><span>|</span><label class="collapse" for="c-38670919">[-]</label><label class="expand" for="c-38670919">[3 more]</label></div><br/><div class="children"><div class="content">A compiler AND processor design amateur here. (Latter in school.)<p>Once you have enough registers, having more mean lowers active utilization for any given instruction (bad use of space, vs. fast pipelined access to cached stack) or higher levels of parallel instruction dispatch (much greater complexity, and even greater inefficiency for branching misses).<p>Then you have to update instruction sets, which could be impossible given how tightly they fit in current instruction sizes.<p>Ergo, increasing register banks is a major architecture &amp; platform change from hardware to software redesign, with heavy end user impact, and a fair chance of decreasing performance.<p>In contrast, anything that improves caching performance is a big non-disruptive win.</div><br/><div id="38671578" class="c"><input type="checkbox" id="c-38671578" checked=""/><div class="controls bullet"><span class="by">als0</span><span>|</span><a href="#38669879">root</a><span>|</span><a href="#38670919">parent</a><span>|</span><a href="#38670898">next</a><span>|</span><label class="collapse" for="c-38671578">[-]</label><label class="expand" for="c-38671578">[2 more]</label></div><br/><div class="children"><div class="content">What about if you use register windows or special renaming of architectural registers to internal ones? <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Register_window" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Register_window</a></div><br/><div id="38679390" class="c"><input type="checkbox" id="c-38679390" checked=""/><div class="controls bullet"><span class="by">Nevermark</span><span>|</span><a href="#38669879">root</a><span>|</span><a href="#38671578">parent</a><span>|</span><a href="#38670898">next</a><span>|</span><label class="collapse" for="c-38679390">[-]</label><label class="expand" for="c-38679390">[1 more]</label></div><br/><div class="children"><div class="content">The amount of stack in the L1 cache is essentially that. A shifting fast access working memory area.<p>Then think of registers as just part of the fetch &amp; store pipelines for staging operations on stack values.<p>Forth goes all in with this approach.</div><br/></div></div></div></div></div></div><div id="38670898" class="c"><input type="checkbox" id="c-38670898" checked=""/><div class="controls bullet"><span class="by">Dylan16807</span><span>|</span><a href="#38669879">root</a><span>|</span><a href="#38670593">parent</a><span>|</span><a href="#38670919">prev</a><span>|</span><a href="#38672423">next</a><span>|</span><label class="collapse" for="c-38670898">[-]</label><label class="expand" for="c-38670898">[2 more]</label></div><br/><div class="children"><div class="content">Registers are quite expensive in space and power, because multiple at once have to be accessible in many places.<p>If you add more registers, the cost per register increases rapidly, and you very quickly hit your limits.<p>If you make registers wider, that&#x27;s still very expensive, <i>and</i> you introduce extra steps to get to your data most of the time.<p>So no, you can&#x27;t do that in a reasonable way.</div><br/><div id="38670945" class="c"><input type="checkbox" id="c-38670945" checked=""/><div class="controls bullet"><span class="by">DeathArrow</span><span>|</span><a href="#38669879">root</a><span>|</span><a href="#38670898">parent</a><span>|</span><a href="#38672423">next</a><span>|</span><label class="collapse" for="c-38670945">[-]</label><label class="expand" for="c-38670945">[1 more]</label></div><br/><div class="children"><div class="content">Thank you!</div><br/></div></div></div></div><div id="38672423" class="c"><input type="checkbox" id="c-38672423" checked=""/><div class="controls bullet"><span class="by">saati</span><span>|</span><a href="#38669879">root</a><span>|</span><a href="#38670593">parent</a><span>|</span><a href="#38670898">prev</a><span>|</span><a href="#38670390">next</a><span>|</span><label class="collapse" for="c-38672423">[-]</label><label class="expand" for="c-38672423">[1 more]</label></div><br/><div class="children"><div class="content">CPU registers are either SRAM or even larger flip-flops, they have the same problem.</div><br/></div></div></div></div></div></div><div id="38670390" class="c"><input type="checkbox" id="c-38670390" checked=""/><div class="controls bullet"><span class="by">adgjlsfhk1</span><span>|</span><a href="#38669879">root</a><span>|</span><a href="#38670093">parent</a><span>|</span><a href="#38670396">prev</a><span>|</span><a href="#38678838">next</a><span>|</span><label class="collapse" for="c-38670390">[-]</label><label class="expand" for="c-38670390">[3 more]</label></div><br/><div class="children"><div class="content">the caches are already ~75% of the space. you can&#x27;t significantly increase that. On die ram is also relatively unlikely due to process differences. my best guess is more 3d cache chips. if we can get the interconnects small enough and fast enough, I could see a future where the logic is stacked on top of a dozen (physical) layers of stacked cache</div><br/><div id="38670761" class="c"><input type="checkbox" id="c-38670761" checked=""/><div class="controls bullet"><span class="by">iopq</span><span>|</span><a href="#38669879">root</a><span>|</span><a href="#38670390">parent</a><span>|</span><a href="#38673664">next</a><span>|</span><label class="collapse" for="c-38670761">[-]</label><label class="expand" for="c-38670761">[1 more]</label></div><br/><div class="children"><div class="content">AMD stacked cache is a significant increase and gives a huge boost in certain gaming scenarios, to the point that it&#x27;s a 100% increase in certain games that rely on huge caches</div><br/></div></div><div id="38673664" class="c"><input type="checkbox" id="c-38673664" checked=""/><div class="controls bullet"><span class="by">markhahn</span><span>|</span><a href="#38669879">root</a><span>|</span><a href="#38670390">parent</a><span>|</span><a href="#38670761">prev</a><span>|</span><a href="#38678838">next</a><span>|</span><label class="collapse" for="c-38673664">[-]</label><label class="expand" for="c-38673664">[1 more]</label></div><br/><div class="children"><div class="content">stacking is a heat problem, and heat has been the PRIMARY system limit for over a decade.<p>2.5d is just too easy and effective - we&#x27;re going to have lots more chiplets, and only the cool ones will get stacked.</div><br/></div></div></div></div></div></div><div id="38678838" class="c"><input type="checkbox" id="c-38678838" checked=""/><div class="controls bullet"><span class="by">mvkel</span><span>|</span><a href="#38669879">root</a><span>|</span><a href="#38669949">parent</a><span>|</span><a href="#38670093">prev</a><span>|</span><a href="#38671852">next</a><span>|</span><label class="collapse" for="c-38678838">[-]</label><label class="expand" for="c-38678838">[2 more]</label></div><br/><div class="children"><div class="content">Limitations in existing processes, sure. But not limitations in physics. If E=mc^2, we&#x27;ve got a lot of efficiencies still to find.</div><br/><div id="38680418" class="c"><input type="checkbox" id="c-38680418" checked=""/><div class="controls bullet"><span class="by">oblio</span><span>|</span><a href="#38669879">root</a><span>|</span><a href="#38678838">parent</a><span>|</span><a href="#38671852">next</a><span>|</span><label class="collapse" for="c-38680418">[-]</label><label class="expand" for="c-38680418">[1 more]</label></div><br/><div class="children"><div class="content">Fusion-based computing FTW!</div><br/></div></div></div></div><div id="38671852" class="c"><input type="checkbox" id="c-38671852" checked=""/><div class="controls bullet"><span class="by">hinkley</span><span>|</span><a href="#38669879">root</a><span>|</span><a href="#38669949">parent</a><span>|</span><a href="#38678838">prev</a><span>|</span><a href="#38670909">next</a><span>|</span><label class="collapse" for="c-38671852">[-]</label><label class="expand" for="c-38671852">[4 more]</label></div><br/><div class="children"><div class="content">I wonder if we’ll see compressed data transmission at some point.</div><br/><div id="38672073" class="c"><input type="checkbox" id="c-38672073" checked=""/><div class="controls bullet"><span class="by">mazurnification</span><span>|</span><a href="#38669879">root</a><span>|</span><a href="#38671852">parent</a><span>|</span><a href="#38673648">next</a><span>|</span><label class="collapse" for="c-38672073">[-]</label><label class="expand" for="c-38672073">[1 more]</label></div><br/><div class="children"><div class="content">Good question - but it would have to be a one of the kind that decrease latency not the one that decrease bandwidth. Maybe there is a way to achieve such.</div><br/></div></div><div id="38673648" class="c"><input type="checkbox" id="c-38673648" checked=""/><div class="controls bullet"><span class="by">markhahn</span><span>|</span><a href="#38669879">root</a><span>|</span><a href="#38671852">parent</a><span>|</span><a href="#38672073">prev</a><span>|</span><a href="#38670909">next</a><span>|</span><label class="collapse" for="c-38673648">[-]</label><label class="expand" for="c-38673648">[2 more]</label></div><br/><div class="children"><div class="content">fast compression is way too slow.<p>remember, we&#x27;re talking TB&#x2F;s these days.</div><br/><div id="38677435" class="c"><input type="checkbox" id="c-38677435" checked=""/><div class="controls bullet"><span class="by">hinkley</span><span>|</span><a href="#38669879">root</a><span>|</span><a href="#38673648">parent</a><span>|</span><a href="#38670909">next</a><span>|</span><label class="collapse" for="c-38677435">[-]</label><label class="expand" for="c-38677435">[1 more]</label></div><br/><div class="children"><div class="content">Could be useful for sparse data structures.</div><br/></div></div></div></div></div></div></div></div><div id="38670909" class="c"><input type="checkbox" id="c-38670909" checked=""/><div class="controls bullet"><span class="by">ksec</span><span>|</span><a href="#38669879">parent</a><span>|</span><a href="#38669949">prev</a><span>|</span><a href="#38672205">next</a><span>|</span><label class="collapse" for="c-38670909">[-]</label><label class="expand" for="c-38670909">[11 more]</label></div><br/><div class="children"><div class="content">&gt;It’s fun to be just a curious bystander for many years in this industry.
Every now and then Moore’s law hits a roadblock. Some experts see that as a clear sign that it’s reaching its end......<p>That is just mainstream reporting.<p>If one actually went and read the paper referred or what the context was. It was always the same thing. It was all about the economics, all the way back from early 90s. We cant do x node because it would be too expensive to sustain it at a node every two years.<p>Smartphone era ( Referring to Post iPhone launch ) essentially meant we ship an additional ~2 <i>Billions</i> Pocket computer every year including Tablet. That is 5x the most optimistic projection to traditional PC model at 400M &#x2F; year. ( Which we never reached ). And that is ignoring the Server market, Network Market, GPU market, AI Market etc. In terms of transistor and revenue or profits the whole TAM ( Total Addressable Market ) went up at least 10x more than those projection. Which is essentially what scale us from 22nm to now 3nm, and all the way to 2nm and 1.4nm. And my projection of 1nm by 2030 as well. I even wrote on HN in ~2015 I have a hard time to see how we could sustain this post 3nm. At the time when trillion dollar company was thought to be impossible.<p>On the other side of things, the cost projection  to next node ( e.g 2nm ), and next next node (e.g 1.4nm ) was always higher than what its turns out. As with any large project management it is was better to ask and project more in case shit hits the fan. ( Intel 10nm ) But every time TSMC has executed so well.<p>So as you can see there is a projection mismatch at both ends. Which is why the clear sign of progress coming to end keeps being wrong.<p>&gt; and can expect 1000X improvement in the years to come at least.<p>I just want to state that this figure keeps being throw around. It was Jim Keller comparing at the time Intel 14nm ( Which is somewhere close to TSMC N10 ) to hypothetical physics limit. At 3nm we are at least 4x pass that. Depending on how you want to measure it we could reach less than 100x by 2030.<p>AI trend could carries us forward to may be 2035. But we dont have another product category like iPhone. Server at hyperscaler are already at a scale growth is slowing. We will again need to substantially lower the development cost of leading node ( My bet is on the AI &#x2F; Software side ) and some product that continues to grow the TAM. May be Autonomous Vehicles will finally be a thing by 2030s ? ( I doubt it but just throwing in some ides ).</div><br/><div id="38677652" class="c"><input type="checkbox" id="c-38677652" checked=""/><div class="controls bullet"><span class="by">tambourine_man</span><span>|</span><a href="#38669879">root</a><span>|</span><a href="#38670909">parent</a><span>|</span><a href="#38671310">next</a><span>|</span><label class="collapse" for="c-38677652">[-]</label><label class="expand" for="c-38677652">[1 more]</label></div><br/><div class="children"><div class="content">I remember reading around the 300nm transition that Moore’s law was all over because wavelengths and physics. No one was talking about multiple masking patterns, probably because it was prohibitively expensive. Inconceivable, much like trillion dollar companies in the early 2000s.<p>I remember a quote from Von Braun where he learned to use the word &#x27;impossible&#x27; with the greatest caution.<p>When you have a significant fraction of the GDP of a super power dedicated to achieving some crazy engineering task, it almost certainly can be done. And I wouldn’t bet against our hanger for better chips.</div><br/></div></div><div id="38671310" class="c"><input type="checkbox" id="c-38671310" checked=""/><div class="controls bullet"><span class="by">pjmlp</span><span>|</span><a href="#38669879">root</a><span>|</span><a href="#38670909">parent</a><span>|</span><a href="#38677652">prev</a><span>|</span><a href="#38671127">next</a><span>|</span><label class="collapse" for="c-38671310">[-]</label><label class="expand" for="c-38671310">[4 more]</label></div><br/><div class="children"><div class="content">However there is a big difference between those &quot;~2 Billions Pocket computer every year including Tablet&quot; and regular computers, so to speak.<p>They are mostly programmed in managed languages, where the respective runtimes and OS collaborate, in order to distribute the computing across all available cores in the best way possible, with little intervention required from the developers side.<p>Additionally, the OS frameworks and language runtimes collaborate in the best way to take advantage of each specific set of CPU capabilities in an almost transparent way.<p>Quite different from the regular POSIX and Win32 applications coded in C and C++, where everything needs to be explicitly taken care of, which is what kind of prevents most of the cool CPU approaches to take off, sitting there idle most of the time.</div><br/><div id="38671694" class="c"><input type="checkbox" id="c-38671694" checked=""/><div class="controls bullet"><span class="by">fl7305</span><span>|</span><a href="#38669879">root</a><span>|</span><a href="#38671310">parent</a><span>|</span><a href="#38671127">next</a><span>|</span><label class="collapse" for="c-38671694">[-]</label><label class="expand" for="c-38671694">[3 more]</label></div><br/><div class="children"><div class="content">&gt; They are mostly programmed in managed languages, where the respective runtimes and OS collaborate, in order to distribute the computing across all available cores in the best way possible, with little intervention required from the developers side.<p>I was under the impression that distributing workloads across many CPU cores (or HW threads) is done at the process and thread level by the OS? That gives managed and unmanaged languages the same benefits.<p>Managed languages provide higher level primitives that makes it easier to create a multi-threaded application. But isn&#x27;t that still manually coded in the mainstream managed languages?<p>I&#x27;m thinking of inherently CPU-intensive custom workloads. UI rendering and IO operations become automatically distributed with little intervention.<p>Or am I missing something, where there is &quot;little intervention required from the developers side&quot; to create multi-threaded apps?</div><br/><div id="38671827" class="c"><input type="checkbox" id="c-38671827" checked=""/><div class="controls bullet"><span class="by">pjmlp</span><span>|</span><a href="#38669879">root</a><span>|</span><a href="#38671694">parent</a><span>|</span><a href="#38671127">next</a><span>|</span><label class="collapse" for="c-38671827">[-]</label><label class="expand" for="c-38671827">[2 more]</label></div><br/><div class="children"><div class="content">You are missing the part that ART, Swift&#x2F;Objective-C runtime, and stuff like Gran Central Dispatch also take part in the decision process.<p>So the schedulers can decide in a more transparent way what runs where, specially on Android side, where the on-device JIT&#x2F;AOT compilers are part of the loop.<p>Additionally, there is more effort on having the toolchains explore SIMD capabilities, where on C and C++ level one is expected to write that code explicilty.<p>Yes, auto-vectorization isn&#x27;t as good as writing the code explicitly, however the latter implies that only a niche set of developers actually care to write any of it.<p>Hence why frameworks like Accelerate exist, even if a JIT isn&#x27;t part of the picture, the framework takes the best path depending on available hardware.<p>Likewise higher level managed frameworks offer a better distribution between the parallel processing taking part across CPU, GPU or NPU, which again on classical UNIX&#x2F;Win32 in C and C++, have to be explicility programmed for.<p>Such higher level frameworks can of course also be provided in such languages, e.g. CUDA and SYCL, howver then we start discussing about programmer culture to adopt such kind of tooling in classical LOB applications.</div><br/><div id="38672244" class="c"><input type="checkbox" id="c-38672244" checked=""/><div class="controls bullet"><span class="by">fl7305</span><span>|</span><a href="#38669879">root</a><span>|</span><a href="#38671827">parent</a><span>|</span><a href="#38671127">next</a><span>|</span><label class="collapse" for="c-38672244">[-]</label><label class="expand" for="c-38672244">[1 more]</label></div><br/><div class="children"><div class="content">&gt; ART, Swift&#x2F;Objective-C runtime, and stuff like Grand Central Dispatch<p>I don&#x27;t know these, but from a quick googling it still looks like explicit multi-threading? Albeit with higher level primitives than in older languages, but still explicit?<p>&gt; auto-vectorization<p>I&#x27;m not sure I see a hard dividing line between older languages and managed ones as far as auto-vectorization? Sure, a higher-level language might make it easier for the compiler since it knows more about potential side effects, but simple and local C code doesn&#x27;t have any side effects either.<p>&gt; with little intervention required from the developers side<p>&gt; Hence why frameworks like Accelerate exist, even if a JIT isn&#x27;t part of the picture<p>Accelerate looks nice, but it still looks like it has to be called explicitly in the user code?<p>&gt; Likewise higher level managed frameworks offer a better distribution between the parallel processing taking part across CPU, GPU or NPU, which again on classical UNIX&#x2F;Win32 in C and C++, have to be explicility programmed for.<p>I&#x27;m not sure I understand, can you give more explicit examples?<p>My point here isn&#x27;t that managed languages don&#x27;t give big benefits over C. I prefer Python and C# when those can be used.<p>It&#x27;s more that I don&#x27;t see &quot;automatic parallel processing&quot; as a solved problem?<p>Sure, we get better and better primitives for multi-threading, and there are more and more high-level parallel libraries like you mentioned. But for most cases, the programmer still has to explicitly design the application to take advantage of multiple cores.</div><br/></div></div></div></div></div></div></div></div><div id="38671127" class="c"><input type="checkbox" id="c-38671127" checked=""/><div class="controls bullet"><span class="by">oldesthacker</span><span>|</span><a href="#38669879">root</a><span>|</span><a href="#38670909">parent</a><span>|</span><a href="#38671310">prev</a><span>|</span><a href="#38672217">next</a><span>|</span><label class="collapse" for="c-38671127">[-]</label><label class="expand" for="c-38671127">[1 more]</label></div><br/><div class="children"><div class="content">&gt; It was all about the economics, all the way back from early 90s. We cant do x node because it would be too expensive to sustain it at a node every two years.<p>Totally agree.<p>&gt; AI trend could carries us forward to may be 2035. But we dont have another product category like iPhone.<p>There will be fancier iPhones with on board offline Large Language Models and other Foundation Models to talk to, solving all kinds of tasks for you that would require a human assistant today.</div><br/></div></div><div id="38672217" class="c"><input type="checkbox" id="c-38672217" checked=""/><div class="controls bullet"><span class="by">prof-dr-ir</span><span>|</span><a href="#38669879">root</a><span>|</span><a href="#38670909">parent</a><span>|</span><a href="#38671127">prev</a><span>|</span><a href="#38672205">next</a><span>|</span><label class="collapse" for="c-38672217">[-]</label><label class="expand" for="c-38672217">[4 more]</label></div><br/><div class="children"><div class="content">&gt; But every time TSMC has executed so well.<p>TSMC or ASML? Or both? I am not trying to be dismissive, just curious about who deserves the credits here.</div><br/><div id="38672798" class="c"><input type="checkbox" id="c-38672798" checked=""/><div class="controls bullet"><span class="by">xbmcuser</span><span>|</span><a href="#38669879">root</a><span>|</span><a href="#38672217">parent</a><span>|</span><a href="#38672810">next</a><span>|</span><label class="collapse" for="c-38672798">[-]</label><label class="expand" for="c-38672798">[1 more]</label></div><br/><div class="children"><div class="content">TSMC otherwise intel and samsung would not be chasing TSMC</div><br/></div></div><div id="38672810" class="c"><input type="checkbox" id="c-38672810" checked=""/><div class="controls bullet"><span class="by">bwhitty</span><span>|</span><a href="#38669879">root</a><span>|</span><a href="#38672217">parent</a><span>|</span><a href="#38672798">prev</a><span>|</span><a href="#38673717">next</a><span>|</span><label class="collapse" for="c-38672810">[-]</label><label class="expand" for="c-38672810">[1 more]</label></div><br/><div class="children"><div class="content">It’s a massive supply chain, so, yes, both. But also a hundred other companies. TSMC and other foundries bring together many technologies from many companies (and no doubt a lot of their own) to ship a full foundry solution (design-technology-cooptimization, masks, lithography, packaging, etc).</div><br/></div></div><div id="38673717" class="c"><input type="checkbox" id="c-38673717" checked=""/><div class="controls bullet"><span class="by">markhahn</span><span>|</span><a href="#38669879">root</a><span>|</span><a href="#38672217">parent</a><span>|</span><a href="#38672810">prev</a><span>|</span><a href="#38672205">next</a><span>|</span><label class="collapse" for="c-38673717">[-]</label><label class="expand" for="c-38673717">[1 more]</label></div><br/><div class="children"><div class="content">arguably, the current race is down to TSMC making the right decision on hi-NA EUV (ie, to run with low-NA).  it&#x27;s not as if Intel couldn&#x27;t have acquired EUV, they just chose not to.</div><br/></div></div></div></div></div></div><div id="38672205" class="c"><input type="checkbox" id="c-38672205" checked=""/><div class="controls bullet"><span class="by">bootloop</span><span>|</span><a href="#38669879">parent</a><span>|</span><a href="#38670909">prev</a><span>|</span><a href="#38672890">next</a><span>|</span><label class="collapse" for="c-38672205">[-]</label><label class="expand" for="c-38672205">[1 more]</label></div><br/><div class="children"><div class="content">Aren&#x27;t Intel, TSMC and Samsung all customers (and investors) of ASML, which is actually the manufacturer and developer of the EUV (ultraviolet) machines this  refers to? Basically, if at all, they might have a slight exclusivity deal, but given the owner structure you can imagine that this will not really affect anything in the long run. With the willingness of spending the money on new nodes they will have the technology too.</div><br/></div></div><div id="38672890" class="c"><input type="checkbox" id="c-38672890" checked=""/><div class="controls bullet"><span class="by">limaoscarjuliet</span><span>|</span><a href="#38669879">parent</a><span>|</span><a href="#38672205">prev</a><span>|</span><a href="#38675340">next</a><span>|</span><label class="collapse" for="c-38672890">[-]</label><label class="expand" for="c-38672890">[1 more]</label></div><br/><div class="children"><div class="content">As Jim Keller himself famously put, Moore&#x27;s law is still fine. Furthermore, the number of people predicting end of Moore&#x27;s law doubles every 18 months, thus following the Moore&#x27;s law itself.</div><br/></div></div><div id="38675340" class="c"><input type="checkbox" id="c-38675340" checked=""/><div class="controls bullet"><span class="by">creer</span><span>|</span><a href="#38669879">parent</a><span>|</span><a href="#38672890">prev</a><span>|</span><a href="#38670494">next</a><span>|</span><label class="collapse" for="c-38675340">[-]</label><label class="expand" for="c-38675340">[1 more]</label></div><br/><div class="children"><div class="content">It is fun to watch and keep track of - And keeping in mind it&#x27;s also been an insane amount of work by an insane number of people with an insane amount of budget thrown at the problems. You can do quite a bit in software &quot;as a hobby&quot; - and this field is not it.</div><br/></div></div></div></div><div id="38669384" class="c"><input type="checkbox" id="c-38669384" checked=""/><div class="controls bullet"><span class="by">ChuckMcM</span><span>|</span><a href="#38669879">prev</a><span>|</span><a href="#38669808">next</a><span>|</span><label class="collapse" for="c-38669384">[-]</label><label class="expand" for="c-38669384">[2 more]</label></div><br/><div class="children"><div class="content">Fun times.<p>I think one of the interesting takeaways here should be that they have a 48 - 50nm &quot;device pitch&quot; which is to say the transistors are small in the XY plane there are pitch widths much larger than &quot;5nm&quot; or &quot;3nm&quot; (people familiar with chip production realize this but too often people who don&#x27;t have a very deep understanding of chip production are mislead into thinking you can put down transistors 5nm apart from each other)<p>So from a density perspective, a perhaps 30 - 40% gain in overall number of transistors in the same space.<p>Looking at the Intel inverter design, it looks like if they were willing to double the depth they could come up with a really compact DRAM cell. A chiplet with 8 GB of ECC DDR memory on it would be a useful thing both for their processors and their high end FPGA architectures.</div><br/><div id="38673753" class="c"><input type="checkbox" id="c-38673753" checked=""/><div class="controls bullet"><span class="by">markhahn</span><span>|</span><a href="#38669384">parent</a><span>|</span><a href="#38669808">next</a><span>|</span><label class="collapse" for="c-38673753">[-]</label><label class="expand" for="c-38673753">[1 more]</label></div><br/><div class="children"><div class="content">really compact DRAM?  have you seen DRAM?  the aspect ratio is already huge, though afaik no one stacks the pass transistor.<p>high-end systems already have stacked DRAM chiplets, though admittedly this hasn&#x27;t made much of an appearance outside GPUs until now (MI300a).</div><br/></div></div></div></div><div id="38669808" class="c"><input type="checkbox" id="c-38669808" checked=""/><div class="controls bullet"><span class="by">bogtog</span><span>|</span><a href="#38669384">prev</a><span>|</span><a href="#38670103">next</a><span>|</span><label class="collapse" for="c-38669808">[-]</label><label class="expand" for="c-38669808">[35 more]</label></div><br/><div class="children"><div class="content">General question about semiconductors: Why is there so much emphasis on the density of transistors rather than purely on the costs of production (compute&#x2F;$)? CPUs aren&#x27;t particularly large. My computer&#x27;s CPU may be just a few tablespoons in volume. Hence, is compute less useful if it&#x27;s spread out (e.g., due to communication speeds)?</div><br/><div id="38670001" class="c"><input type="checkbox" id="c-38670001" checked=""/><div class="controls bullet"><span class="by">sabbey</span><span>|</span><a href="#38669808">parent</a><span>|</span><a href="#38670738">next</a><span>|</span><label class="collapse" for="c-38670001">[-]</label><label class="expand" for="c-38670001">[12 more]</label></div><br/><div class="children"><div class="content">Light travels at one foot per nanosecond.  So a processor one foot wide you&#x27;d expect to run at 1 GHz max.</div><br/><div id="38671546" class="c"><input type="checkbox" id="c-38671546" checked=""/><div class="controls bullet"><span class="by">smolder</span><span>|</span><a href="#38669808">root</a><span>|</span><a href="#38670001">parent</a><span>|</span><a href="#38670638">next</a><span>|</span><label class="collapse" for="c-38671546">[-]</label><label class="expand" for="c-38671546">[4 more]</label></div><br/><div class="children"><div class="content">That&#x27;s only if you needed a signal to cross the whole chip in one cycle. There&#x27;s no such limitation preventing a 1 foot wide chip from being filled with 5ghz cores on an appropriate ring bus.</div><br/><div id="38671975" class="c"><input type="checkbox" id="c-38671975" checked=""/><div class="controls bullet"><span class="by">Jensson</span><span>|</span><a href="#38669808">root</a><span>|</span><a href="#38671546">parent</a><span>|</span><a href="#38675987">next</a><span>|</span><label class="collapse" for="c-38671975">[-]</label><label class="expand" for="c-38671975">[1 more]</label></div><br/><div class="children"><div class="content">But then you have many cores. With 3d scaling you could make a bigger core and still have high hz.</div><br/></div></div><div id="38671892" class="c"><input type="checkbox" id="c-38671892" checked=""/><div class="controls bullet"><span class="by">winwang</span><span>|</span><a href="#38669808">root</a><span>|</span><a href="#38671546">parent</a><span>|</span><a href="#38675987">prev</a><span>|</span><a href="#38670638">next</a><span>|</span><label class="collapse" for="c-38671892">[-]</label><label class="expand" for="c-38671892">[1 more]</label></div><br/><div class="children"><div class="content">something something quantum tunnelling for probabilistic FTL signalling (&#x2F;s)</div><br/></div></div></div></div><div id="38670638" class="c"><input type="checkbox" id="c-38670638" checked=""/><div class="controls bullet"><span class="by">DeathArrow</span><span>|</span><a href="#38669808">root</a><span>|</span><a href="#38670001">parent</a><span>|</span><a href="#38671546">prev</a><span>|</span><a href="#38670085">next</a><span>|</span><label class="collapse" for="c-38670638">[-]</label><label class="expand" for="c-38670638">[1 more]</label></div><br/><div class="children"><div class="content">Isn&#x27;t Apple M3 larger in size than other Arm CPUs? Still, they don&#x27;t run slower.</div><br/></div></div><div id="38670085" class="c"><input type="checkbox" id="c-38670085" checked=""/><div class="controls bullet"><span class="by">badrabbit</span><span>|</span><a href="#38669808">root</a><span>|</span><a href="#38670001">parent</a><span>|</span><a href="#38670638">prev</a><span>|</span><a href="#38670738">next</a><span>|</span><label class="collapse" for="c-38670085">[-]</label><label class="expand" for="c-38670085">[6 more]</label></div><br/><div class="children"><div class="content">Only if it is so badly designed that data needs to cross the entire dye&#x27;s cross section.</div><br/><div id="38670205" class="c"><input type="checkbox" id="c-38670205" checked=""/><div class="controls bullet"><span class="by">cma</span><span>|</span><a href="#38669808">root</a><span>|</span><a href="#38670085">parent</a><span>|</span><a href="#38670738">next</a><span>|</span><label class="collapse" for="c-38670205">[-]</label><label class="expand" for="c-38670205">[5 more]</label></div><br/><div class="children"><div class="content">Look at how much space cache uses on a die.</div><br/><div id="38670253" class="c"><input type="checkbox" id="c-38670253" checked=""/><div class="controls bullet"><span class="by">badrabbit</span><span>|</span><a href="#38669808">root</a><span>|</span><a href="#38670205">parent</a><span>|</span><a href="#38670738">next</a><span>|</span><label class="collapse" for="c-38670253">[-]</label><label class="expand" for="c-38670253">[4 more]</label></div><br/><div class="children"><div class="content">The core would use cache near it? Memory access delay such as caches is not considered part of cpu frequency either afaik.</div><br/><div id="38670404" class="c"><input type="checkbox" id="c-38670404" checked=""/><div class="controls bullet"><span class="by">tux3</span><span>|</span><a href="#38669808">root</a><span>|</span><a href="#38670253">parent</a><span>|</span><a href="#38673804">next</a><span>|</span><label class="collapse" for="c-38670404">[-]</label><label class="expand" for="c-38670404">[1 more]</label></div><br/><div class="children"><div class="content">Cache takes X number of cycles to return a result<p>You can make X lower by reducing the frequency (= having each cycle be longer)<p>But apart for that, the main reason big chips would clock slower is power, not timing. If you have a lot of transistors all switching on a high voltage so that the frequency is high, you get molten metal and the magic smoke leaves.<p>Big chips aren&#x27;t one big stage where light travels from one side to the other. But they are giant weaves of heating elements that can&#x27;t all run fast all of the time</div><br/></div></div><div id="38673804" class="c"><input type="checkbox" id="c-38673804" checked=""/><div class="controls bullet"><span class="by">markhahn</span><span>|</span><a href="#38669808">root</a><span>|</span><a href="#38670253">parent</a><span>|</span><a href="#38670404">prev</a><span>|</span><a href="#38670738">next</a><span>|</span><label class="collapse" for="c-38673804">[-]</label><label class="expand" for="c-38673804">[2 more]</label></div><br/><div class="children"><div class="content">cache latency is definitely part of what limits core clock.  you&#x27;re not going to have a good time if your L1 latency is, say 10 clocks.  not to mention the fact that register files are not much different than SRAM (therefore cache-like).</div><br/><div id="38676014" class="c"><input type="checkbox" id="c-38676014" checked=""/><div class="controls bullet"><span class="by">badrabbit</span><span>|</span><a href="#38669808">root</a><span>|</span><a href="#38673804">parent</a><span>|</span><a href="#38670738">next</a><span>|</span><label class="collapse" for="c-38676014">[-]</label><label class="expand" for="c-38676014">[1 more]</label></div><br/><div class="children"><div class="content">Fair enough, to measure real world performance you&#x27;re right anf that&#x27;s all that should matter anyways.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="38670738" class="c"><input type="checkbox" id="c-38670738" checked=""/><div class="controls bullet"><span class="by">brennanpeterson</span><span>|</span><a href="#38669808">parent</a><span>|</span><a href="#38670001">prev</a><span>|</span><a href="#38669827">next</a><span>|</span><label class="collapse" for="c-38670738">[-]</label><label class="expand" for="c-38670738">[1 more]</label></div><br/><div class="children"><div class="content">It is?<p>A factory makes transistors ,and if you increase a &#x27;node&#x27;, you make twice as much. If you do an amazing job, you might reduce cost 10%.<p>So by far the best way to maximize value in semiconductors is to enable shrink.<p>But you also just don&#x27;t hear it in the popular or even engineering press. Most manufacturers and designers look at a PPAC curve (power, performance, area, cost) and find optimal design points.<p>As for spreading it out: the unit of production isn&#x27;t a wafer, it is a lithographic field, which is roughly 25*35mm. You cant practically &#x27;speead out&#x27; much more (ok, you sort of can with field stitching, but that is really expensive).</div><br/></div></div><div id="38669827" class="c"><input type="checkbox" id="c-38669827" checked=""/><div class="controls bullet"><span class="by">xhrpost</span><span>|</span><a href="#38669808">parent</a><span>|</span><a href="#38670738">prev</a><span>|</span><a href="#38670776">next</a><span>|</span><label class="collapse" for="c-38669827">[-]</label><label class="expand" for="c-38669827">[2 more]</label></div><br/><div class="children"><div class="content">You could always purchase a multi CPU system (effectively what you&#x27;re suggesting) from several years ago for much cheaper than modern hardware. If you&#x27;re using it regularly though, the electrical cost will eventually eat away any money savings vs the same computational power in a modern single CPU.</div><br/><div id="38672898" class="c"><input type="checkbox" id="c-38672898" checked=""/><div class="controls bullet"><span class="by">xbmcuser</span><span>|</span><a href="#38669808">root</a><span>|</span><a href="#38669827">parent</a><span>|</span><a href="#38670776">next</a><span>|</span><label class="collapse" for="c-38672898">[-]</label><label class="expand" for="c-38672898">[1 more]</label></div><br/><div class="children"><div class="content">With the way Solar&#x2F;wind + batteries are bringing electricity prices down the cost per compute will still come down even as moore laws slows down. Looking at current trends running today processors 10 years from now could just cost in electricity just 10-12% what it costs now.</div><br/></div></div></div></div><div id="38670776" class="c"><input type="checkbox" id="c-38670776" checked=""/><div class="controls bullet"><span class="by">iopq</span><span>|</span><a href="#38669808">parent</a><span>|</span><a href="#38669827">prev</a><span>|</span><a href="#38670426">next</a><span>|</span><label class="collapse" for="c-38670776">[-]</label><label class="expand" for="c-38670776">[4 more]</label></div><br/><div class="children"><div class="content">Because when you make it denser, you can cut the CPU into smaller parts, which decreases costs<p>when you make it less dense, it can clock up higher, but you will have fewer cores per mm^2<p>AMD went with both approaches, where their hybrid CPU will have densely packed low speed Zen 4C cores and some high speed Zen 4 cores to boost at the highest frequency</div><br/><div id="38671238" class="c"><input type="checkbox" id="c-38671238" checked=""/><div class="controls bullet"><span class="by">cubefox</span><span>|</span><a href="#38669808">root</a><span>|</span><a href="#38670776">parent</a><span>|</span><a href="#38670426">next</a><span>|</span><label class="collapse" for="c-38671238">[-]</label><label class="expand" for="c-38671238">[3 more]</label></div><br/><div class="children"><div class="content">Increasing density has caused chip cost per FLOP&#x2F;s to decrease exponentially over the last decades. But nowadays the price per transistor doesn&#x27;t go down as fast with increased density like it used to.<p>E.g. new Nvidia GPUs are getting smaller for the same price, which means they are getting more expensive for the same size. At some point, the price per transistor will actually increase. Then Moore&#x27;s Law (the exponential increase in transistor density) will probably stop, simply because it&#x27;s not economical to produce slower chips for the same price. (Maybe the increased power efficiency will still make density scaling worth it for a little while longer, but probably not a lot longer.)</div><br/><div id="38671557" class="c"><input type="checkbox" id="c-38671557" checked=""/><div class="controls bullet"><span class="by">jpgvm</span><span>|</span><a href="#38669808">root</a><span>|</span><a href="#38671238">parent</a><span>|</span><a href="#38670426">next</a><span>|</span><label class="collapse" for="c-38671557">[-]</label><label class="expand" for="c-38671557">[2 more]</label></div><br/><div class="children"><div class="content">This isn&#x27;t due to fundamental cost increasing per transistor though, this is because NVidia changed their pricing strategy to decouple it from that.<p>They are simply making greater % profit&#x2F;transitor.</div><br/><div id="38674838" class="c"><input type="checkbox" id="c-38674838" checked=""/><div class="controls bullet"><span class="by">FirmwareBurner</span><span>|</span><a href="#38669808">root</a><span>|</span><a href="#38671557">parent</a><span>|</span><a href="#38670426">next</a><span>|</span><label class="collapse" for="c-38674838">[-]</label><label class="expand" for="c-38674838">[1 more]</label></div><br/><div class="children"><div class="content"><i>&gt; this is because NVidia changed their pricing strategy to decouple it from that</i><p>Because neither AMD nor Intel can come withing striking distance of Nvidia&#x27;s flagships, and seeing how their silicone flies off the shelves, they have also adjusted their pricing to match their relative performance to Nvidia.</div><br/></div></div></div></div></div></div></div></div><div id="38670426" class="c"><input type="checkbox" id="c-38670426" checked=""/><div class="controls bullet"><span class="by">noam_k</span><span>|</span><a href="#38669808">parent</a><span>|</span><a href="#38670776">prev</a><span>|</span><a href="#38670037">next</a><span>|</span><label class="collapse" for="c-38670426">[-]</label><label class="expand" for="c-38670426">[1 more]</label></div><br/><div class="children"><div class="content">In addition to the answers already given, there are defects during the process that are more likely to render your chip useless the larger your chip is. This is true for smaller chips as well, and often the design handles a defunct component, but you prefer minimizing defects per chip.</div><br/></div></div><div id="38670037" class="c"><input type="checkbox" id="c-38670037" checked=""/><div class="controls bullet"><span class="by">uluyol</span><span>|</span><a href="#38669808">parent</a><span>|</span><a href="#38670426">prev</a><span>|</span><a href="#38670166">next</a><span>|</span><label class="collapse" for="c-38670037">[-]</label><label class="expand" for="c-38670037">[1 more]</label></div><br/><div class="children"><div class="content">Density is one of the main ways to get cost savings. But there are others too, and there&#x27;s also a lot of hype around them. Chiplets for example. Or CXL for memory.</div><br/></div></div><div id="38670166" class="c"><input type="checkbox" id="c-38670166" checked=""/><div class="controls bullet"><span class="by">Salgat</span><span>|</span><a href="#38669808">parent</a><span>|</span><a href="#38670037">prev</a><span>|</span><a href="#38670616">next</a><span>|</span><label class="collapse" for="c-38670166">[-]</label><label class="expand" for="c-38670166">[1 more]</label></div><br/><div class="children"><div class="content">Personal usage still relies on fast single threaded performance. As far as business usage, the cost is primarily energy which requires smaller node size for the same performance.</div><br/></div></div><div id="38670616" class="c"><input type="checkbox" id="c-38670616" checked=""/><div class="controls bullet"><span class="by">DeathArrow</span><span>|</span><a href="#38669808">parent</a><span>|</span><a href="#38670166">prev</a><span>|</span><a href="#38673772">next</a><span>|</span><label class="collapse" for="c-38670616">[-]</label><label class="expand" for="c-38670616">[1 more]</label></div><br/><div class="children"><div class="content">What do you mean by spread? Multi socketed mainboards?<p>That would help only for parallelizable workloads. For many workloads is the single threaded performance that matters most.</div><br/></div></div><div id="38673772" class="c"><input type="checkbox" id="c-38673772" checked=""/><div class="controls bullet"><span class="by">markhahn</span><span>|</span><a href="#38669808">parent</a><span>|</span><a href="#38670616">prev</a><span>|</span><a href="#38669831">next</a><span>|</span><label class="collapse" for="c-38673772">[-]</label><label class="expand" for="c-38673772">[1 more]</label></div><br/><div class="children"><div class="content">cost is area, because defects.<p>TOF latency isn&#x27;t that much of a big deal, though driving a signal for distance consumes a lot of power, and power has been the primary design-limiter for at least a decade.</div><br/></div></div><div id="38669831" class="c"><input type="checkbox" id="c-38669831" checked=""/><div class="controls bullet"><span class="by">foolfoolz</span><span>|</span><a href="#38669808">parent</a><span>|</span><a href="#38673772">prev</a><span>|</span><a href="#38669865">next</a><span>|</span><label class="collapse" for="c-38669831">[-]</label><label class="expand" for="c-38669831">[1 more]</label></div><br/><div class="children"><div class="content">reducing costs is nice for consumer… making cpu higher cost that goes brrrrt is better for business</div><br/></div></div><div id="38669865" class="c"><input type="checkbox" id="c-38669865" checked=""/><div class="controls bullet"><span class="by">twobitshifter</span><span>|</span><a href="#38669808">parent</a><span>|</span><a href="#38669831">prev</a><span>|</span><a href="#38671986">next</a><span>|</span><label class="collapse" for="c-38669865">[-]</label><label class="expand" for="c-38669865">[1 more]</label></div><br/><div class="children"><div class="content">I believe this was some of the advantage of the AMD Zen series of chips which moved to a larger die size from Athlon.</div><br/></div></div><div id="38671986" class="c"><input type="checkbox" id="c-38671986" checked=""/><div class="controls bullet"><span class="by">imtringued</span><span>|</span><a href="#38669808">parent</a><span>|</span><a href="#38669865">prev</a><span>|</span><a href="#38669826">next</a><span>|</span><label class="collapse" for="c-38671986">[-]</label><label class="expand" for="c-38671986">[1 more]</label></div><br/><div class="children"><div class="content">Because you are assuming there is an objectively optimal processor design for a specific manufacturing process.<p>If you don&#x27;t constrain the chip to a specific design then what is going to count as compute? The number of adders or multipliers? That is just a different way of talking about transistor density.</div><br/></div></div><div id="38669826" class="c"><input type="checkbox" id="c-38669826" checked=""/><div class="controls bullet"><span class="by">wahnfrieden</span><span>|</span><a href="#38669808">parent</a><span>|</span><a href="#38671986">prev</a><span>|</span><a href="#38669862">next</a><span>|</span><label class="collapse" for="c-38669826">[-]</label><label class="expand" for="c-38669826">[1 more]</label></div><br/><div class="children"><div class="content">Yes, electricity doesn’t move instantly</div><br/></div></div><div id="38669862" class="c"><input type="checkbox" id="c-38669862" checked=""/><div class="controls bullet"><span class="by">nsonha</span><span>|</span><a href="#38669808">parent</a><span>|</span><a href="#38669826">prev</a><span>|</span><a href="#38670103">next</a><span>|</span><label class="collapse" for="c-38669862">[-]</label><label class="expand" for="c-38669862">[6 more]</label></div><br/><div class="children"><div class="content">the physical limitation of more CPUs: heat, which in turn downgrades performance</div><br/><div id="38670130" class="c"><input type="checkbox" id="c-38670130" checked=""/><div class="controls bullet"><span class="by">mikepurvis</span><span>|</span><a href="#38669808">root</a><span>|</span><a href="#38669862">parent</a><span>|</span><a href="#38670103">next</a><span>|</span><label class="collapse" for="c-38670130">[-]</label><label class="expand" for="c-38670130">[5 more]</label></div><br/><div class="children"><div class="content">But I think the GP&#x27;s point is that heat is far easier managed when spread out over a larger area, so why all the emphasis on ultra tiny transistors vs just making a chip that&#x27;s two inches by two inches or something?<p>And I think the main answer to that comes when you look at some of the discourse around Apple&#x27;s M-series chips, that doing a larger-die design is just way riskier: there are huge implications on cost, yield, flexibility, etc, so it was really something that Apple was uniquely positioned to move aggressively on vs a player like Qualcomm who needs to be way more conservative in what they try to sell to their main customers (phone OEMs like Samsung).</div><br/><div id="38672135" class="c"><input type="checkbox" id="c-38672135" checked=""/><div class="controls bullet"><span class="by">dist-epoch</span><span>|</span><a href="#38669808">root</a><span>|</span><a href="#38670130">parent</a><span>|</span><a href="#38670103">next</a><span>|</span><label class="collapse" for="c-38672135">[-]</label><label class="expand" for="c-38672135">[4 more]</label></div><br/><div class="children"><div class="content">&gt; making a chip that&#x27;s two inches by two inches<p>These already exist. Lookup images of AMD Ryzen Threadripper PRO 7995WX - 96 cores:<p><a href="https:&#x2F;&#x2F;www.techpowerup.com&#x2F;img&#x2F;fp51OPD4JRS7wvTK.jpg" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.techpowerup.com&#x2F;img&#x2F;fp51OPD4JRS7wvTK.jpg</a></div><br/><div id="38672445" class="c"><input type="checkbox" id="c-38672445" checked=""/><div class="controls bullet"><span class="by">dontlaugh</span><span>|</span><a href="#38669808">root</a><span>|</span><a href="#38672135">parent</a><span>|</span><a href="#38670103">next</a><span>|</span><label class="collapse" for="c-38672445">[-]</label><label class="expand" for="c-38672445">[3 more]</label></div><br/><div class="children"><div class="content">Those are made up of much smaller chiplets. No individual die is all that big</div><br/><div id="38678450" class="c"><input type="checkbox" id="c-38678450" checked=""/><div class="controls bullet"><span class="by">ls612</span><span>|</span><a href="#38669808">root</a><span>|</span><a href="#38672445">parent</a><span>|</span><a href="#38670103">next</a><span>|</span><label class="collapse" for="c-38678450">[-]</label><label class="expand" for="c-38678450">[2 more]</label></div><br/><div class="children"><div class="content">Oh the reason they don’t make dies that big is the probably of a defect balloons and your yields would be shit.</div><br/><div id="38678879" class="c"><input type="checkbox" id="c-38678879" checked=""/><div class="controls bullet"><span class="by">mikepurvis</span><span>|</span><a href="#38669808">root</a><span>|</span><a href="#38678450">parent</a><span>|</span><a href="#38670103">next</a><span>|</span><label class="collapse" for="c-38678879">[-]</label><label class="expand" for="c-38678879">[1 more]</label></div><br/><div class="children"><div class="content">Apple handles that in part by fusing off the broken subcomponents of the huge die, though, which is how they end up with stuff like a 7-core GPU.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="38670103" class="c"><input type="checkbox" id="c-38670103" checked=""/><div class="controls bullet"><span class="by">sh1mmer</span><span>|</span><a href="#38669808">prev</a><span>|</span><a href="#38671965">next</a><span>|</span><label class="collapse" for="c-38670103">[-]</label><label class="expand" for="c-38670103">[6 more]</label></div><br/><div class="children"><div class="content">Maybe I’m missing something here, but wouldn’t heat become a bigger issue? Right now we have pretty intense cooling solutions to get heat off the surface of a comparatively thinner chip. If chips become more cubic how would we cool the inside?</div><br/><div id="38670407" class="c"><input type="checkbox" id="c-38670407" checked=""/><div class="controls bullet"><span class="by">TOMDM</span><span>|</span><a href="#38670103">parent</a><span>|</span><a href="#38671965">next</a><span>|</span><label class="collapse" for="c-38670407">[-]</label><label class="expand" for="c-38670407">[5 more]</label></div><br/><div class="children"><div class="content">If we keep going down this route I have to wonder if we&#x27;ll see something drastic in the cooling space.<p>CPU dies are optimised towards being cooled from one side. I wonder if we&#x27;ll eventually see sockets, motherboards and heat spreaders shift towards cooling both sides of the CPU.<p>Probably not, can&#x27;t imagine what a halfway feasible solution to integrating pin out and a heat spreader would be.</div><br/><div id="38671535" class="c"><input type="checkbox" id="c-38671535" checked=""/><div class="controls bullet"><span class="by">mook</span><span>|</span><a href="#38670103">root</a><span>|</span><a href="#38670407">parent</a><span>|</span><a href="#38672791">next</a><span>|</span><label class="collapse" for="c-38671535">[-]</label><label class="expand" for="c-38671535">[1 more]</label></div><br/><div class="children"><div class="content">A couple years back they noted that they were looking at having essentially cooling pipes _inside_ the chips. There hasn&#x27;t been much noise in terms of commercialization, but that&#x27;s the kind of extreme they were looking at.<p><a href="https:&#x2F;&#x2F;www.tomshardware.com&#x2F;news&#x2F;tsmc-exploring-on-chip-semiconductor-integrated-watercooling" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.tomshardware.com&#x2F;news&#x2F;tsmc-exploring-on-chip-sem...</a></div><br/></div></div><div id="38672791" class="c"><input type="checkbox" id="c-38672791" checked=""/><div class="controls bullet"><span class="by">chainingsolid</span><span>|</span><a href="#38670103">root</a><span>|</span><a href="#38670407">parent</a><span>|</span><a href="#38671535">prev</a><span>|</span><a href="#38672180">next</a><span>|</span><label class="collapse" for="c-38672791">[-]</label><label class="expand" for="c-38672791">[1 more]</label></div><br/><div class="children"><div class="content">Heres my first thought on how you might be able to do pin out on a &#x27;sandwich a cpu between 2 heatsinks design&#x27;.<p>1) DRAM gets integrated with the cpu. Slight thickness increase, probably quite a bit of added width. We get a bigger area to cool, closer ram and no need for any memory pins.<p>2) Add power connections to the 2 cooling sides. Running power wires through the coolers shouldn&#x27;t be an issue.<p>3) Run as many of the fastest PCIe lanes as you can out the 4 thin sides of the package. These end up handling ALL of the IO.<p>Some downsides I can think of off the bat are cooking the ram chips and with so much density and heat not sure how well signal integrity would work out.</div><br/></div></div><div id="38672180" class="c"><input type="checkbox" id="c-38672180" checked=""/><div class="controls bullet"><span class="by">dist-epoch</span><span>|</span><a href="#38670103">root</a><span>|</span><a href="#38670407">parent</a><span>|</span><a href="#38672791">prev</a><span>|</span><a href="#38670861">next</a><span>|</span><label class="collapse" for="c-38672180">[-]</label><label class="expand" for="c-38672180">[1 more]</label></div><br/><div class="children"><div class="content">&gt; cooling both sides of the CPU<p>That would only double cooling capacity, and has costs - completely invalidates current motherboard designs.</div><br/></div></div><div id="38670861" class="c"><input type="checkbox" id="c-38670861" checked=""/><div class="controls bullet"><span class="by">teaearlgraycold</span><span>|</span><a href="#38670103">root</a><span>|</span><a href="#38670407">parent</a><span>|</span><a href="#38672180">prev</a><span>|</span><a href="#38671965">next</a><span>|</span><label class="collapse" for="c-38670861">[-]</label><label class="expand" for="c-38670861">[1 more]</label></div><br/><div class="children"><div class="content">A relatively easy win here is to have a “stock” set of fins built into the motherboard behind the CPU socket. The CPU could get attached to it with a pad or paste on the back.</div><br/></div></div></div></div></div></div><div id="38671965" class="c"><input type="checkbox" id="c-38671965" checked=""/><div class="controls bullet"><span class="by">drtgh</span><span>|</span><a href="#38670103">prev</a><span>|</span><a href="#38672202">next</a><span>|</span><label class="collapse" for="c-38671965">[-]</label><label class="expand" for="c-38671965">[13 more]</label></div><br/><div class="children"><div class="content">In storage, moving away from 2D MLC and TLC NAND towards 3D TLC stacking (and horrendous higher bits) has introduced disturbances that literally shorten the memory life cycle. When a cell is read, the voltage alters the state of adjacent cells, which must be forced to be rewritten to preserve their state, thus shortening the life cycle of the disk just by reading data. they are selling us crap.<p>From the little I understand about the problem, this would be solved by occupying more surface area to separate the tracks that run through the vertical stacks ? what would be like a 2D design surface area but with bigger complications. Although I have read papers[1] that propose adding latency in an attempt to mitigate (not solve) the problem.<p>So now, reading this news about processors and stacking, I wonder about what inconveniences the end users are going to suffer with processors built under these techniques. Whether in computational reliability, vulnerabilities and so on.<p>I wrote vulnerabilities (pure imagination and speculation of my own, I&#x27;m imagining a prefetch problem at the transistor level) because if it turns to be real at future I can see the manufacturer introducing a fix for randomly increase latencies or any other thing, and sending the computing power back ten years with an &quot;oh, we didn&#x27;t expect it such thing were possible when we designed it&quot;.<p>And of course the computational reliability.<p>is being taken care of to avoid all of this?.. if not, I leave my comment here for courts in the future.<p>[1] [2021] doi.org&#x2F;10.1145&#x2F;3445814.3446733 (use sci-hub)<p>[2] [2018] doi.org&#x2F;10.1145&#x2F;3224432 <a href="https:&#x2F;&#x2F;people.inf.ethz.ch&#x2F;omutlu&#x2F;pub&#x2F;3D-NAND-flash-lifetime-early-retention-loss-and-process-variation_sigmetrics18_pomacs18-twocolumn.pdf" rel="nofollow noreferrer">https:&#x2F;&#x2F;people.inf.ethz.ch&#x2F;omutlu&#x2F;pub&#x2F;3D-NAND-flash-lifetime...</a></div><br/><div id="38672003" class="c"><input type="checkbox" id="c-38672003" checked=""/><div class="controls bullet"><span class="by">FirmwareBurner</span><span>|</span><a href="#38671965">parent</a><span>|</span><a href="#38672147">next</a><span>|</span><label class="collapse" for="c-38672003">[-]</label><label class="expand" for="c-38672003">[1 more]</label></div><br/><div class="children"><div class="content"><i>&gt;So now, reading this news about processors and stacking, I wonder about what inconveniences the end users are going to suffer with processors built under these techniques. Whether in computational reliability, vulnerabilities and so on.</i><p>Denser logic hasn&#x27;t got the same issues as dense non-volatile storage as logic doesn&#x27;t need to have any persistence.<p>It&#x27;s what the likes of Micron and Samsung are good at fixing and working around when they launch and scale their Xnm processes for a specific storage technology, and what makes them better than competitors.<p>Intel, TSMC, GloFo, etc they all can buy the latest gen EUV machines from ASML if they want, but yet TSMC is always one node ahead on logic and Micron and Samsung win at storage, because they&#x27;re good at ironing out the kinks and challenges that come from shrinking down those specific designs closer and closer to sub-nm level while the others can not (so easily).<p>If fabbing cutting edge silicone was as easy as just having the latest gen ASML machines, then ASML would just hoard the cutting edge machines for themselves and become vertically integrated in fabbing their own cutting chips as a side hustle before everyone else.</div><br/></div></div><div id="38672147" class="c"><input type="checkbox" id="c-38672147" checked=""/><div class="controls bullet"><span class="by">dist-epoch</span><span>|</span><a href="#38671965">parent</a><span>|</span><a href="#38672003">prev</a><span>|</span><a href="#38672202">next</a><span>|</span><label class="collapse" for="c-38672147">[-]</label><label class="expand" for="c-38672147">[11 more]</label></div><br/><div class="children"><div class="content">&gt; they are selling us crap.<p>You can completely rewrite a modern 4TB 3D TLC NAND every day for 3 years (3000 TBW). How is that crap? Who even has such needs?<p>You are talking about some arbitrary &quot;quality&quot; - I want to be able to rewrite it a zillion times - which make no sense for 99.9% of use cases.<p>I&#x27;d much rather have a 4 TB drive which can be rewritten 1000 times versus a same price 256 GB one which can be rewritten 1 million times.</div><br/><div id="38672206" class="c"><input type="checkbox" id="c-38672206" checked=""/><div class="controls bullet"><span class="by">drtgh</span><span>|</span><a href="#38671965">root</a><span>|</span><a href="#38672147">parent</a><span>|</span><a href="#38673861">next</a><span>|</span><label class="collapse" for="c-38672206">[-]</label><label class="expand" for="c-38672206">[5 more]</label></div><br/><div class="children"><div class="content">&gt;You can completely rewrite a modern [..]<p>3D NAND has introduced degradation when is read data from the disk. You need to calculate then how many times the disk is read, the unwritten free space that will be consumed for to maintain the data when the disk is read, and so on.</div><br/><div id="38676377" class="c"><input type="checkbox" id="c-38676377" checked=""/><div class="controls bullet"><span class="by">_zoltan_</span><span>|</span><a href="#38671965">root</a><span>|</span><a href="#38672206">parent</a><span>|</span><a href="#38673861">next</a><span>|</span><label class="collapse" for="c-38676377">[-]</label><label class="expand" for="c-38676377">[4 more]</label></div><br/><div class="children"><div class="content">and? the TBW guarantees are known in advance.</div><br/><div id="38676923" class="c"><input type="checkbox" id="c-38676923" checked=""/><div class="controls bullet"><span class="by">drtgh</span><span>|</span><a href="#38671965">root</a><span>|</span><a href="#38676377">parent</a><span>|</span><a href="#38673861">next</a><span>|</span><label class="collapse" for="c-38676923">[-]</label><label class="expand" for="c-38676923">[3 more]</label></div><br/><div class="children"><div class="content">The TBW of the disk shown in the specifications is the estimated write limit of each cell multiplied by the number of cells. They don&#x27;t take into account that in order to read the data of each cell, the adjacent cells will be written and will consume little by little these estimated write limits.<p>Therefore, if you fill the disk and only read data, it will sooner or later go into protection mode or lose data because of it.<p>They could only guarantee the TBW if more memory were added for to cover the writes consumption by the reads usage of the current 3D NAND design. I no longer know how to explain that it is programmed obsolescence, self-destructing disks by read data.<p>We stopped seeing 10 years guaranties when 3D NAND was introduced, so they know well what they are doing.</div><br/><div id="38678686" class="c"><input type="checkbox" id="c-38678686" checked=""/><div class="controls bullet"><span class="by">fomine3</span><span>|</span><a href="#38671965">root</a><span>|</span><a href="#38676923">parent</a><span>|</span><a href="#38673861">next</a><span>|</span><label class="collapse" for="c-38678686">[-]</label><label class="expand" for="c-38678686">[2 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think so <a href="https:&#x2F;&#x2F;www.jedec.org&#x2F;standards-documents&#x2F;focus&#x2F;flash&#x2F;solid-state-drives" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.jedec.org&#x2F;standards-documents&#x2F;focus&#x2F;flash&#x2F;solid-...</a></div><br/><div id="38679158" class="c"><input type="checkbox" id="c-38679158" checked=""/><div class="controls bullet"><span class="by">drtgh</span><span>|</span><a href="#38671965">root</a><span>|</span><a href="#38678686">parent</a><span>|</span><a href="#38673861">next</a><span>|</span><label class="collapse" for="c-38679158">[-]</label><label class="expand" for="c-38679158">[1 more]</label></div><br/><div class="children"><div class="content">Why do you link an Industrial SSD Storage standard with write test? It only shows the cells have the corresponding write limits at beginning.<p>My last comment, I&#x27;m sorry but I can&#x27;t spend any more time with this.<p>To read data consume writes,<p><a href="https:&#x2F;&#x2F;dl.acm.org&#x2F;doi&#x2F;10.1145&#x2F;3445814.3446733" rel="nofollow noreferrer">https:&#x2F;&#x2F;dl.acm.org&#x2F;doi&#x2F;10.1145&#x2F;3445814.3446733</a><p>&quot; Figure 1a plots the average SSD lifetime consumed by the read-only workloads across 200 days on three SSDs (the detailed parameters of these SSDs can be found from SSD-A&#x2F;-B&#x2F;-C in Table 1). As shown in the figure, the lifetime consumed by the read (disturbance) induced writes increases significantly as the SSD density increases.  In addition, increasing the read throughput (from 17MBps to 56&#x2F;68MBps) can greatly accelerate the lifetime consumption. Even more problematically, as the density increases, the SSD lifetime (plotted in Figure 1b) decreases.
In addition, SSD-aware write-reduction-oriented system software is no longer sufficient for high-density 3D SSDs, to reduce lifetime consumption. This is because the SSDs entered an era where one can wear out an SSD by simply reading it.&quot;<p>Data retention consume writes,<p><a href="https:&#x2F;&#x2F;ghose.cs.illinois.edu&#x2F;papers&#x2F;18sigmetrics_3dflash.pdf" rel="nofollow noreferrer">https:&#x2F;&#x2F;ghose.cs.illinois.edu&#x2F;papers&#x2F;18sigmetrics_3dflash.pd...</a><p>&quot; 3D NAND flash memory exhibits three new error sources that were not previously observed in planar NAND flash memory:<p>(1) layer-to-layer process variation, a new phenomenon specific to the 3D nature of the device, where the average error rate of each 3D-stacked layer in a chip is significantly different;<p>(2) early retention loss, a new phenomenon where the number of errors due to charge leakage increases quickly within
several hours after programming; and<p>(3) retention interference, a new phenomenon where the rate at which charge leaks from a flash cell is dependent on the data value stored in the neighboring cell. &quot;<p>Free way.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="38673861" class="c"><input type="checkbox" id="c-38673861" checked=""/><div class="controls bullet"><span class="by">markhahn</span><span>|</span><a href="#38671965">root</a><span>|</span><a href="#38672147">parent</a><span>|</span><a href="#38672206">prev</a><span>|</span><a href="#38672202">next</a><span>|</span><label class="collapse" for="c-38673861">[-]</label><label class="expand" for="c-38673861">[5 more]</label></div><br/><div class="children"><div class="content">TLC is a decent spot, which is why it&#x27;s still being produced.<p>QLC is less so, since its endurance is only ~300 cycles.  there&#x27;s plenty of tension in the storage industry about this, with vendors saying &quot;don&#x27;t worry be happy&quot;, and purchasers saying &quot;wait, what read:write ratio are you assuming, and how much dedupe?&quot;<p>PLC (probably &lt;100 cycles) is very dubious, IMO, simply because it would only be suitable for very cold data - and at that point you&#x27;re competing with magnetic media (which has been scaling quite nicely).</div><br/><div id="38678702" class="c"><input type="checkbox" id="c-38678702" checked=""/><div class="controls bullet"><span class="by">fomine3</span><span>|</span><a href="#38671965">root</a><span>|</span><a href="#38673861">parent</a><span>|</span><a href="#38675208">next</a><span>|</span><label class="collapse" for="c-38678702">[-]</label><label class="expand" for="c-38678702">[1 more]</label></div><br/><div class="children"><div class="content">2D TLC wasn&#x27;t quite decent, but 3D TLC is decent. I think some bad reputation about TLC is come from 2D TLC.</div><br/></div></div><div id="38675208" class="c"><input type="checkbox" id="c-38675208" checked=""/><div class="controls bullet"><span class="by">dist-epoch</span><span>|</span><a href="#38671965">root</a><span>|</span><a href="#38673861">parent</a><span>|</span><a href="#38678702">prev</a><span>|</span><a href="#38672202">next</a><span>|</span><label class="collapse" for="c-38675208">[-]</label><label class="expand" for="c-38675208">[3 more]</label></div><br/><div class="children"><div class="content">I have hard drives which I only write to once - long term archive. I will gladly change them fro QLC&#x2F;PLC storage if price is reasonable.<p>There is a market for any cycle count, it just needs to be reliable and respect the spec.</div><br/><div id="38675602" class="c"><input type="checkbox" id="c-38675602" checked=""/><div class="controls bullet"><span class="by">markhahn</span><span>|</span><a href="#38671965">root</a><span>|</span><a href="#38675208">parent</a><span>|</span><a href="#38672202">next</a><span>|</span><label class="collapse" for="c-38675602">[-]</label><label class="expand" for="c-38675602">[2 more]</label></div><br/><div class="children"><div class="content">that&#x27;s the tape market I mentioned.  agreed, tape doesn&#x27;t fit the personal market, but it totally dominates anywhere that has scale.<p>the question is: what counts as reliable?  if PLC is good for 50 erasures, are you really comfortable with that?  it&#x27;s going to cost more than half of QLC, I assure you...<p>the interesting thing about flash is that people want to use the speed.  which means they put in places that have a high content-mutation rate.  if it&#x27;s just personal stuff - mostly cold, little mutation - that&#x27;s fine but not the main market.</div><br/><div id="38675769" class="c"><input type="checkbox" id="c-38675769" checked=""/><div class="controls bullet"><span class="by">dist-epoch</span><span>|</span><a href="#38671965">root</a><span>|</span><a href="#38675602">parent</a><span>|</span><a href="#38672202">next</a><span>|</span><label class="collapse" for="c-38675769">[-]</label><label class="expand" for="c-38675769">[1 more]</label></div><br/><div class="children"><div class="content">There is a market for high speed read only data - S3 serving, and all kinds of mostly read database scenarios (OLAP). You can have tiered storage, data is first consolidated&#x2F;updated on TLC drives, and as it ages is moved to PLC storage. RocksDB already supports something like this.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="38672202" class="c"><input type="checkbox" id="c-38672202" checked=""/><div class="controls bullet"><span class="by">CalChris</span><span>|</span><a href="#38671965">prev</a><span>|</span><a href="#38669554">next</a><span>|</span><label class="collapse" for="c-38672202">[-]</label><label class="expand" for="c-38672202">[3 more]</label></div><br/><div class="children"><div class="content">A minor startup isn&#x27;t Intel, Samsung and TSMC but www.thruchip.com did 3d stacking 10 years ago.<p><a href="https:&#x2F;&#x2F;web.stanford.edu&#x2F;class&#x2F;ee380&#x2F;Abstracts&#x2F;141022-slides.pdf" rel="nofollow noreferrer">https:&#x2F;&#x2F;web.stanford.edu&#x2F;class&#x2F;ee380&#x2F;Abstracts&#x2F;141022-slides...</a><p><a href="https:&#x2F;&#x2F;www.theregister.com&#x2F;2014&#x2F;02&#x2F;21&#x2F;thruchip_communications_comes_up_with_alternative_to_through_silicon_vias&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.theregister.com&#x2F;2014&#x2F;02&#x2F;21&#x2F;thruchip_communicatio...</a></div><br/><div id="38675468" class="c"><input type="checkbox" id="c-38675468" checked=""/><div class="controls bullet"><span class="by">markhahn</span><span>|</span><a href="#38672202">parent</a><span>|</span><a href="#38672261">next</a><span>|</span><label class="collapse" for="c-38675468">[-]</label><label class="expand" for="c-38675468">[1 more]</label></div><br/><div class="children"><div class="content">the case for inductive stacked chips is pretty compelling, if those slides are right!<p>I wonder if you can also couple adjacent chips that way, since 2.5D is, if anything, more important than stacking...</div><br/></div></div></div></div><div id="38669554" class="c"><input type="checkbox" id="c-38669554" checked=""/><div class="controls bullet"><span class="by">andrewstuart</span><span>|</span><a href="#38672202">prev</a><span>|</span><a href="#38669662">next</a><span>|</span><label class="collapse" for="c-38669554">[-]</label><label class="expand" for="c-38669554">[8 more]</label></div><br/><div class="children"><div class="content">What real world outcomes might we expect from this technology?<p>Anyone know?</div><br/><div id="38669591" class="c"><input type="checkbox" id="c-38669591" checked=""/><div class="controls bullet"><span class="by">thunderbird120</span><span>|</span><a href="#38669554">parent</a><span>|</span><a href="#38669800">next</a><span>|</span><label class="collapse" for="c-38669591">[-]</label><label class="expand" for="c-38669591">[1 more]</label></div><br/><div class="children"><div class="content">Faster chips which use less power to do the same amount of computation, same as ever.<p>CFETs are very much real world technology which are on the roadmaps for all leading edge fabs. They&#x27;re the same as current gen FinFets and GAAFets a year or two from now in that they essentially just do the same thing as previous generations of chip tech except they do it better.</div><br/></div></div><div id="38669800" class="c"><input type="checkbox" id="c-38669800" checked=""/><div class="controls bullet"><span class="by">WaxProlix</span><span>|</span><a href="#38669554">parent</a><span>|</span><a href="#38669591">prev</a><span>|</span><a href="#38672804">next</a><span>|</span><label class="collapse" for="c-38669800">[-]</label><label class="expand" for="c-38669800">[4 more]</label></div><br/><div class="children"><div class="content">Novel cooling solutions, among others, one suspects.</div><br/><div id="38673410" class="c"><input type="checkbox" id="c-38673410" checked=""/><div class="controls bullet"><span class="by">CyberDildonics</span><span>|</span><a href="#38669554">root</a><span>|</span><a href="#38669800">parent</a><span>|</span><a href="#38672804">next</a><span>|</span><label class="collapse" for="c-38673410">[-]</label><label class="expand" for="c-38673410">[3 more]</label></div><br/><div class="children"><div class="content">What do you mean by that and what are you basing that on?</div><br/><div id="38676207" class="c"><input type="checkbox" id="c-38676207" checked=""/><div class="controls bullet"><span class="by">WaxProlix</span><span>|</span><a href="#38669554">root</a><span>|</span><a href="#38673410">parent</a><span>|</span><a href="#38672804">next</a><span>|</span><label class="collapse" for="c-38676207">[-]</label><label class="expand" for="c-38676207">[2 more]</label></div><br/><div class="children"><div class="content">Running watts through transistors produces heat. Flat transistors are cooled by various heat dispersal mechanisms today. Thicker 3D stacked transistors will possibly provide impetus for a different cooling paradigm.</div><br/><div id="38676290" class="c"><input type="checkbox" id="c-38676290" checked=""/><div class="controls bullet"><span class="by">CyberDildonics</span><span>|</span><a href="#38669554">root</a><span>|</span><a href="#38676207">parent</a><span>|</span><a href="#38672804">next</a><span>|</span><label class="collapse" for="c-38676290">[-]</label><label class="expand" for="c-38676290">[1 more]</label></div><br/><div class="children"><div class="content">This is just the same thing you said before worded differently.<p>What different cooling paradigm and what information leads you to think that it&#x27;s a reality?</div><br/></div></div></div></div></div></div></div></div><div id="38672804" class="c"><input type="checkbox" id="c-38672804" checked=""/><div class="controls bullet"><span class="by">amelius</span><span>|</span><a href="#38669554">parent</a><span>|</span><a href="#38669800">prev</a><span>|</span><a href="#38669662">next</a><span>|</span><label class="collapse" for="c-38672804">[-]</label><label class="expand" for="c-38672804">[2 more]</label></div><br/><div class="children"><div class="content">Thicker phones.</div><br/><div id="38675599" class="c"><input type="checkbox" id="c-38675599" checked=""/><div class="controls bullet"><span class="by">Narishma</span><span>|</span><a href="#38669554">root</a><span>|</span><a href="#38672804">parent</a><span>|</span><a href="#38669662">next</a><span>|</span><label class="collapse" for="c-38675599">[-]</label><label class="expand" for="c-38675599">[1 more]</label></div><br/><div class="children"><div class="content">One can dream.</div><br/></div></div></div></div></div></div><div id="38669662" class="c"><input type="checkbox" id="c-38669662" checked=""/><div class="controls bullet"><span class="by">dcreater</span><span>|</span><a href="#38669554">prev</a><span>|</span><a href="#38675702">next</a><span>|</span><label class="collapse" for="c-38669662">[-]</label><label class="expand" for="c-38669662">[1 more]</label></div><br/><div class="children"><div class="content">Since it&#x27;s still a GAA channel, are the channel lengths sthr same as the latest 3nm node?</div><br/></div></div><div id="38675702" class="c"><input type="checkbox" id="c-38675702" checked=""/><div class="controls bullet"><span class="by">kosasbest</span><span>|</span><a href="#38669662">prev</a><span>|</span><a href="#38670086">next</a><span>|</span><label class="collapse" for="c-38675702">[-]</label><label class="expand" for="c-38675702">[1 more]</label></div><br/><div class="children"><div class="content">Interesting that when we can&#x27;t make chips bigger laterally, we go vertical and stack transistors. It&#x27;s like we discovered high-rise buildings all over again.</div><br/></div></div><div id="38670086" class="c"><input type="checkbox" id="c-38670086" checked=""/><div class="controls bullet"><span class="by">0x1ceb00da</span><span>|</span><a href="#38675702">prev</a><span>|</span><a href="#38669802">next</a><span>|</span><label class="collapse" for="c-38670086">[-]</label><label class="expand" for="c-38670086">[11 more]</label></div><br/><div class="children"><div class="content">Is that going to increase the GHz as well or just the number of cores.</div><br/><div id="38670100" class="c"><input type="checkbox" id="c-38670100" checked=""/><div class="controls bullet"><span class="by">rishav_sharan</span><span>|</span><a href="#38670086">parent</a><span>|</span><a href="#38670101">next</a><span>|</span><label class="collapse" for="c-38670100">[-]</label><label class="expand" for="c-38670100">[8 more]</label></div><br/><div class="children"><div class="content">Doubt that. Frequency will be tied to heat dissipation. And in a 3d stack, the heat dissipation of the inner transistors is going to be very difficult</div><br/><div id="38670529" class="c"><input type="checkbox" id="c-38670529" checked=""/><div class="controls bullet"><span class="by">Dylan16807</span><span>|</span><a href="#38670086">root</a><span>|</span><a href="#38670100">parent</a><span>|</span><a href="#38670377">next</a><span>|</span><label class="collapse" for="c-38670529">[-]</label><label class="expand" for="c-38670529">[1 more]</label></div><br/><div class="children"><div class="content">These two layers are touching, nanometers apart. The heat dissipation will be the same for both layers.  It&#x27;s still a simple problem of density, not a more complicated problem similar to trying to cool multiple dies.<p>Edit: To throw math at it, silicon conducts at 2-4 Watts per centimeter-Kelvin.  If we need the heat to travel an extra 100nm, and we&#x27;re looking at a 1cm by 1cm area of chip, then it takes 20 to 40 kilowatts flowing through that slice before the top and bottom will differ by more than 0.1 degrees.</div><br/></div></div><div id="38670377" class="c"><input type="checkbox" id="c-38670377" checked=""/><div class="controls bullet"><span class="by">sundvor</span><span>|</span><a href="#38670086">root</a><span>|</span><a href="#38670100">parent</a><span>|</span><a href="#38670529">prev</a><span>|</span><a href="#38670383">next</a><span>|</span><label class="collapse" for="c-38670377">[-]</label><label class="expand" for="c-38670377">[4 more]</label></div><br/><div class="children"><div class="content">In gaming, especially simulators: The 5800x3d and then the 7800x3d has proved how exemplary performance benefits can be gained in certain use cases, in some cases outperforming Intel with less than half the power usage (if not a third).<p>Limiting overclocking is a price to pay for that, but you kind of get it back with the monthly power bills - and still going toe to toe with Intel in general.</div><br/><div id="38670667" class="c"><input type="checkbox" id="c-38670667" checked=""/><div class="controls bullet"><span class="by">DeathArrow</span><span>|</span><a href="#38670086">root</a><span>|</span><a href="#38670377">parent</a><span>|</span><a href="#38670383">next</a><span>|</span><label class="collapse" for="c-38670667">[-]</label><label class="expand" for="c-38670667">[3 more]</label></div><br/><div class="children"><div class="content">I doubt that for one user using one CPU the power bill is going to matter. People still use AC, washing machines and electrical heating consuming thousands of kw.</div><br/><div id="38671323" class="c"><input type="checkbox" id="c-38671323" checked=""/><div class="controls bullet"><span class="by">sundvor</span><span>|</span><a href="#38670086">root</a><span>|</span><a href="#38670667">parent</a><span>|</span><a href="#38670383">next</a><span>|</span><label class="collapse" for="c-38671323">[-]</label><label class="expand" for="c-38671323">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a 100-150w difference. It all adds up.<p>This also means you don&#x27;t need to run the fans in your system as high.</div><br/><div id="38675546" class="c"><input type="checkbox" id="c-38675546" checked=""/><div class="controls bullet"><span class="by">markhahn</span><span>|</span><a href="#38670086">root</a><span>|</span><a href="#38671323">parent</a><span>|</span><a href="#38670383">next</a><span>|</span><label class="collapse" for="c-38675546">[-]</label><label class="expand" for="c-38675546">[1 more]</label></div><br/><div class="children"><div class="content">Look at the numbers.<p>Power&#x2F;heat matters for datacenters, but not for people.  Yes, you can built a kw desktop, but you know you&#x27;re doing something weird.  For most people, their computer&#x27;s peak dissipation has been falling for a decade.  90W cpus used to be common, but mainstream is currently going from 65 to 40W categories in desktops.  And normal people do not have GPUs.  Even more normal people depend primarily on mobile devices, where 15W laptops are routine, and lots of people use devices &lt;4W.</div><br/></div></div></div></div></div></div></div></div><div id="38670383" class="c"><input type="checkbox" id="c-38670383" checked=""/><div class="controls bullet"><span class="by">georgeburdell</span><span>|</span><a href="#38670086">root</a><span>|</span><a href="#38670100">parent</a><span>|</span><a href="#38670377">prev</a><span>|</span><a href="#38670101">next</a><span>|</span><label class="collapse" for="c-38670383">[-]</label><label class="expand" for="c-38670383">[2 more]</label></div><br/><div class="children"><div class="content">Look at the specs for the Core series since 2007.  The clocks have doubled.  It’s not a fast increase, to be sure, but it’s happening</div><br/></div></div></div></div><div id="38670101" class="c"><input type="checkbox" id="c-38670101" checked=""/><div class="controls bullet"><span class="by">rishav_sharan</span><span>|</span><a href="#38670086">parent</a><span>|</span><a href="#38670100">prev</a><span>|</span><a href="#38670657">next</a><span>|</span><label class="collapse" for="c-38670101">[-]</label><label class="expand" for="c-38670101">[1 more]</label></div><br/><div class="children"><div class="content">Doubt that. Frequency will be tied to heat dissipation. And in a 3d stack, the heat dissipation of the inner transistors is going to be very difficult</div><br/></div></div><div id="38670657" class="c"><input type="checkbox" id="c-38670657" checked=""/><div class="controls bullet"><span class="by">DeathArrow</span><span>|</span><a href="#38670086">parent</a><span>|</span><a href="#38670101">prev</a><span>|</span><a href="#38669802">next</a><span>|</span><label class="collapse" for="c-38670657">[-]</label><label class="expand" for="c-38670657">[1 more]</label></div><br/><div class="children"><div class="content">GHz might not increase but maybe they can do more IPC by having a wider architecture.</div><br/></div></div></div></div><div id="38669802" class="c"><input type="checkbox" id="c-38669802" checked=""/><div class="controls bullet"><span class="by">29athrowaway</span><span>|</span><a href="#38670086">prev</a><span>|</span><a href="#38671306">next</a><span>|</span><label class="collapse" for="c-38669802">[-]</label><label class="expand" for="c-38669802">[2 more]</label></div><br/><div class="children"><div class="content">What does heat do in these chips? How does it not melt?</div><br/><div id="38675502" class="c"><input type="checkbox" id="c-38675502" checked=""/><div class="controls bullet"><span class="by">markhahn</span><span>|</span><a href="#38669802">parent</a><span>|</span><a href="#38671306">next</a><span>|</span><label class="collapse" for="c-38675502">[-]</label><label class="expand" for="c-38675502">[1 more]</label></div><br/><div class="children"><div class="content">heat density is heat density.  this technique isn&#x27;t the same as stacking two logic dies (which would have a heat problem).<p>backside power is actually a pretty important power improvement - both delivery and cooling.</div><br/></div></div></div></div><div id="38671306" class="c"><input type="checkbox" id="c-38671306" checked=""/><div class="controls bullet"><span class="by">anthk</span><span>|</span><a href="#38669802">prev</a><span>|</span><a href="#38671083">next</a><span>|</span><label class="collapse" for="c-38671306">[-]</label><label class="expand" for="c-38671306">[1 more]</label></div><br/><div class="children"><div class="content">Any EE member here? How&#x27;s photonics&#x27; computing going?</div><br/></div></div><div id="38671083" class="c"><input type="checkbox" id="c-38671083" checked=""/><div class="controls bullet"><span class="by">oldesthacker</span><span>|</span><a href="#38671306">prev</a><span>|</span><a href="#38671037">next</a><span>|</span><label class="collapse" for="c-38671083">[-]</label><label class="expand" for="c-38671083">[2 more]</label></div><br/><div class="children"><div class="content">Interesting bit about Samsung’s secret sauce:<p>Samsung went even smaller than Intel, showing results for 48-nm and 45-nm contacted poly pitch (CPP), compared to Intel’s 60 nm, though these were for individual devices, not complete inverters. Although there was some performance degradation in the smaller of Samsung’s two prototype CFETs, it wasn’t much, and the company’s researchers believe manufacturing process optimization will take care of it. Crucial to Samsung’s success was the ability to electrically isolate the sources and drains of the stacked pFET and nFET devices. Without adequate isolation, the device, which Samsung calls a 3D stacked FET (3DSFET), will leak current. A key step to achieving that isolation was swapping an etching step involving wet chemicals with a new kind of dry etch. That led to an 80 percent boost in the yield of good devices. Like Intel, Samsung contacted the bottom of the device from beneath the silicon to save space. However, the Korean chipmaker differed from the American one by using a single nanosheet in each of the paired devices, instead of Intel’s three. According to its researchers, increasing the number of nanosheets will enhance the CFET’s performance.</div><br/></div></div><div id="38671037" class="c"><input type="checkbox" id="c-38671037" checked=""/><div class="controls bullet"><span class="by">cubefox</span><span>|</span><a href="#38671083">prev</a><span>|</span><a href="#38671256">next</a><span>|</span><label class="collapse" for="c-38671037">[-]</label><label class="expand" for="c-38671037">[5 more]</label></div><br/><div class="children"><div class="content">&gt; Experts estimate CFETs to roll out commercially seven to ten years from now, but there is still a lot of work before they are ready.<p>So the technology is still very much science fiction at this point.</div><br/><div id="38671687" class="c"><input type="checkbox" id="c-38671687" checked=""/><div class="controls bullet"><span class="by">smolder</span><span>|</span><a href="#38671037">parent</a><span>|</span><a href="#38671043">next</a><span>|</span><label class="collapse" for="c-38671687">[-]</label><label class="expand" for="c-38671687">[3 more]</label></div><br/><div class="children"><div class="content">No, they&#x27;ve been made, just not via scaled-up commercial production process.</div><br/><div id="38672236" class="c"><input type="checkbox" id="c-38672236" checked=""/><div class="controls bullet"><span class="by">cubefox</span><span>|</span><a href="#38671037">root</a><span>|</span><a href="#38671687">parent</a><span>|</span><a href="#38671043">next</a><span>|</span><label class="collapse" for="c-38672236">[-]</label><label class="expand" for="c-38672236">[2 more]</label></div><br/><div class="children"><div class="content">The fact that they are predicted to be &quot;seven to ten years&quot; away suggests there are still many unsolved problems that are preventing scaling-up from becoming a reality.</div><br/><div id="38679914" class="c"><input type="checkbox" id="c-38679914" checked=""/><div class="controls bullet"><span class="by">smolder</span><span>|</span><a href="#38671037">root</a><span>|</span><a href="#38672236">parent</a><span>|</span><a href="#38671043">next</a><span>|</span><label class="collapse" for="c-38679914">[-]</label><label class="expand" for="c-38679914">[1 more]</label></div><br/><div class="children"><div class="content">Fair point. I think for comparison it&#x27;s interesting that Intel spent most of a decade on a single process.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></body></html>