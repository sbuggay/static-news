<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1708765281071" as="style"/><link rel="stylesheet" href="styles.css?v=1708765281071"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://intrinsic-lora.github.io/">Generative Models: What do they know? Do they know things? Let&#x27;s find out</a> <span class="domain">(<a href="https://intrinsic-lora.github.io">intrinsic-lora.github.io</a>)</span></div><div class="subtext"><span>corysama</span> | <span>70 comments</span></div><br/><div><div id="39487554" class="c"><input type="checkbox" id="c-39487554" checked=""/><div class="controls bullet"><span class="by">ukuina</span><span>|</span><a href="#39487524">next</a><span>|</span><label class="collapse" for="c-39487554">[-]</label><label class="expand" for="c-39487554">[13 more]</label></div><br/><div class="children"><div class="content">The name is a reference to a fictional gameshow in Bojack Horseman called &quot;Hollywoo Stars and Celebrities: What Do They Know? Do They Know Things?? Let&#x27;s Find Out!&quot;<p><a href="https:&#x2F;&#x2F;bojackhorseman.fandom.com&#x2F;wiki&#x2F;Hollywoo_Stars_and_Celebrities:_What_Do_They_Know%3F_Do_They_Know_Things%3F%3F_Let%27s_Find_Out" rel="nofollow">https:&#x2F;&#x2F;bojackhorseman.fandom.com&#x2F;wiki&#x2F;Hollywoo_Stars_and_Ce...</a>!</div><br/><div id="39488094" class="c"><input type="checkbox" id="c-39488094" checked=""/><div class="controls bullet"><span class="by">reso</span><span>|</span><a href="#39487554">parent</a><span>|</span><a href="#39488945">next</a><span>|</span><label class="collapse" for="c-39488094">[-]</label><label class="expand" for="c-39488094">[1 more]</label></div><br/><div class="children"><div class="content">Not gonna lie I upvoted this post based only on the title.</div><br/></div></div><div id="39488945" class="c"><input type="checkbox" id="c-39488945" checked=""/><div class="controls bullet"><span class="by">_____-___</span><span>|</span><a href="#39487554">parent</a><span>|</span><a href="#39488094">prev</a><span>|</span><a href="#39487897">next</a><span>|</span><label class="collapse" for="c-39488945">[-]</label><label class="expand" for="c-39488945">[1 more]</label></div><br/><div class="children"><div class="content">I reference this specific game show title quite a bit, but I don&#x27;t think that many people get it sadly, so I just seem weird haha</div><br/></div></div><div id="39487897" class="c"><input type="checkbox" id="c-39487897" checked=""/><div class="controls bullet"><span class="by">echelon</span><span>|</span><a href="#39487554">parent</a><span>|</span><a href="#39488945">prev</a><span>|</span><a href="#39487524">next</a><span>|</span><label class="collapse" for="c-39487897">[-]</label><label class="expand" for="c-39487897">[10 more]</label></div><br/><div class="children"><div class="content">I adore that show so much. I have this sticker on my laptop.<p>If you haven&#x27;t seen Bojack Horseman, it&#x27;s funny and heartfelt. Palpably existential. If that kind of thing speaks to you, you owe yourself a watch.<p>In terms of a complete animation package, I think it easy outdoes Futurama. There&#x27;s so much relatable depth to it. It hits hard, but it stays lighthearted enough to make you feel good about it.<p>As it turns out, I&#x27;m now working on filmtech, so that &quot;Hollywoo&quot; sticker fits me even better now.</div><br/><div id="39488449" class="c"><input type="checkbox" id="c-39488449" checked=""/><div class="controls bullet"><span class="by">the_af</span><span>|</span><a href="#39487554">root</a><span>|</span><a href="#39487897">parent</a><span>|</span><a href="#39489528">next</a><span>|</span><label class="collapse" for="c-39488449">[-]</label><label class="expand" for="c-39488449">[5 more]</label></div><br/><div class="children"><div class="content">I want to like Bojack and I know it has drama and heartfelt moments (watched all of season 1 I think), but <i>in my opinion</i> it&#x27;s undone by its moments of &quot;wacky&quot; humor. I don&#x27;t even mean that there are humanoid animals and humans living together, no explanation -- I can embrace that. I mean the Simpsons&#x2F;Family Guy kind of humor... I could do without it and I think it would make the show better.<p>Or maybe it does get better after season 1? Since everyone seems to love it.</div><br/><div id="39490169" class="c"><input type="checkbox" id="c-39490169" checked=""/><div class="controls bullet"><span class="by">karmakurtisaani</span><span>|</span><a href="#39487554">root</a><span>|</span><a href="#39488449">parent</a><span>|</span><a href="#39488466">next</a><span>|</span><label class="collapse" for="c-39490169">[-]</label><label class="expand" for="c-39490169">[1 more]</label></div><br/><div class="children"><div class="content">I remember reading they had to make season 1 &quot;wacky&quot; to sell the show. What the show becomes later would have been ... hard to describe to studio executives.</div><br/></div></div><div id="39488466" class="c"><input type="checkbox" id="c-39488466" checked=""/><div class="controls bullet"><span class="by">yosame</span><span>|</span><a href="#39487554">root</a><span>|</span><a href="#39488449">parent</a><span>|</span><a href="#39490169">prev</a><span>|</span><a href="#39489146">next</a><span>|</span><label class="collapse" for="c-39488466">[-]</label><label class="expand" for="c-39488466">[1 more]</label></div><br/><div class="children"><div class="content">Season 1 is definitely the weakest season, especially at the start. There&#x27;s definitely still wacky humour in the rest of the show, but it loses the family guy cutaway gags.<p>I&#x27;d personally recommend giving season 2 a shot, if you still don&#x27;t like it then the shows probably not for you.</div><br/></div></div><div id="39489146" class="c"><input type="checkbox" id="c-39489146" checked=""/><div class="controls bullet"><span class="by">KerrAvon</span><span>|</span><a href="#39487554">root</a><span>|</span><a href="#39488449">parent</a><span>|</span><a href="#39488466">prev</a><span>|</span><a href="#39488812">next</a><span>|</span><label class="collapse" for="c-39489146">[-]</label><label class="expand" for="c-39489146">[1 more]</label></div><br/><div class="children"><div class="content">It’s very Los Angeles nihilist in tone. If that doesn’t make you happy, maybe skip it.</div><br/></div></div><div id="39488812" class="c"><input type="checkbox" id="c-39488812" checked=""/><div class="controls bullet"><span class="by">reducesuffering</span><span>|</span><a href="#39487554">root</a><span>|</span><a href="#39488449">parent</a><span>|</span><a href="#39489146">prev</a><span>|</span><a href="#39489528">next</a><span>|</span><label class="collapse" for="c-39488812">[-]</label><label class="expand" for="c-39488812">[1 more]</label></div><br/><div class="children"><div class="content">Season 1 is definitely weakest; very common in great TV series. Just start from season 2 right now and I&#x27;m pretty sure you&#x27;ll love it. It will always have &quot;wacky&quot; moments with a character like Todd in it though.</div><br/></div></div></div></div><div id="39489528" class="c"><input type="checkbox" id="c-39489528" checked=""/><div class="controls bullet"><span class="by">khedoros1</span><span>|</span><a href="#39487554">root</a><span>|</span><a href="#39487897">parent</a><span>|</span><a href="#39488449">prev</a><span>|</span><a href="#39488926">next</a><span>|</span><label class="collapse" for="c-39489528">[-]</label><label class="expand" for="c-39489528">[1 more]</label></div><br/><div class="children"><div class="content">&gt; but it stays lighthearted enough to make you feel good about it.<p>There were plenty of parts that were dark enough to make it difficult to watch. There were lighthearted parts, but that&#x27;s not a description I would&#x27;ve applied to the show as a whole.</div><br/></div></div><div id="39488926" class="c"><input type="checkbox" id="c-39488926" checked=""/><div class="controls bullet"><span class="by">jeffparsons</span><span>|</span><a href="#39487554">root</a><span>|</span><a href="#39487897">parent</a><span>|</span><a href="#39489528">prev</a><span>|</span><a href="#39487967">next</a><span>|</span><label class="collapse" for="c-39488926">[-]</label><label class="expand" for="c-39488926">[2 more]</label></div><br/><div class="children"><div class="content">&gt; It hits hard, but it stays lighthearted enough to make you feel good about it.<p>That wasn&#x27;t my experience of it. It&#x27;s a brilliant show, to be sure, but at some point I felt the bleakness, particularly around Bojack&#x27;s inability to help himself, became too much for me. Maybe different parts of the show resonate in different people.</div><br/><div id="39490164" class="c"><input type="checkbox" id="c-39490164" checked=""/><div class="controls bullet"><span class="by">rocketbop</span><span>|</span><a href="#39487554">root</a><span>|</span><a href="#39488926">parent</a><span>|</span><a href="#39487967">next</a><span>|</span><label class="collapse" for="c-39490164">[-]</label><label class="expand" for="c-39490164">[1 more]</label></div><br/><div class="children"><div class="content">I agree it wasn’t light at all in the later parts. Very bleak. If it was ever supposed to be a comedy it didn’t end as one but I can’t think of other animated series you could class as a drama.<p>I think it is one of only about three animated shows that are genuinely outstanding as TV and not just animation or comedy. The other two being Simpsons and Futurama.</div><br/></div></div></div></div></div></div></div></div><div id="39487524" class="c"><input type="checkbox" id="c-39487524" checked=""/><div class="controls bullet"><span class="by">dougmwne</span><span>|</span><a href="#39487554">prev</a><span>|</span><a href="#39488158">next</a><span>|</span><label class="collapse" for="c-39487524">[-]</label><label class="expand" for="c-39487524">[9 more]</label></div><br/><div class="children"><div class="content">This is awesome!<p>So one of the big reasons there was hype about Sora is that it felt very likely from watching a few videos that there was an internal physical simulation of the world happening and the video was more like a camera recording that physical and 3D scene simulation. It was just a sort of naïve sense that there HAD to be more going on behind the scenes than gluing bits of other videos together.<p>This is evidence, and it’s appearing even in still image generators. The models essentially learn how to render a 3D scene and take a picture of it. That’s incredible considering that we weren’t trying to create a 3D engine, we just threw a bunch of images at some linear algebra and optimized. Out popped a world simulator.</div><br/><div id="39489626" class="c"><input type="checkbox" id="c-39489626" checked=""/><div class="controls bullet"><span class="by">whimsicalism</span><span>|</span><a href="#39487524">parent</a><span>|</span><a href="#39489604">next</a><span>|</span><label class="collapse" for="c-39489626">[-]</label><label class="expand" for="c-39489626">[2 more]</label></div><br/><div class="children"><div class="content">&gt; just a sort of naïve sense that there HAD to be more going on behind the scenes than gluing bits of other videos together<p>People really still think that&#x27;s all thats happening?</div><br/><div id="39489771" class="c"><input type="checkbox" id="c-39489771" checked=""/><div class="controls bullet"><span class="by">0_____0</span><span>|</span><a href="#39487524">root</a><span>|</span><a href="#39489626">parent</a><span>|</span><a href="#39489604">next</a><span>|</span><label class="collapse" for="c-39489771">[-]</label><label class="expand" for="c-39489771">[1 more]</label></div><br/><div class="children"><div class="content">Who is people? Most folks only vaguely know about generative AI if they know about it at all. I&#x27;m technical but not in software specifically and usually ignore most AI news, so GP&#x27;s comment is in fact news to me!</div><br/></div></div></div></div><div id="39489604" class="c"><input type="checkbox" id="c-39489604" checked=""/><div class="controls bullet"><span class="by">patcon</span><span>|</span><a href="#39487524">parent</a><span>|</span><a href="#39489626">prev</a><span>|</span><a href="#39489902">next</a><span>|</span><label class="collapse" for="c-39489604">[-]</label><label class="expand" for="c-39489604">[1 more]</label></div><br/><div class="children"><div class="content">&gt; we weren’t trying to create a 3D engine, we just threw a bunch of images at some linear algebra and optimized. Out popped a world simulator.<p>Heh. Sounds like what a personified evolution might say about a mind ;)</div><br/></div></div><div id="39488413" class="c"><input type="checkbox" id="c-39488413" checked=""/><div class="controls bullet"><span class="by">ClumsyPilot</span><span>|</span><a href="#39487524">parent</a><span>|</span><a href="#39489902">prev</a><span>|</span><a href="#39490097">next</a><span>|</span><label class="collapse" for="c-39488413">[-]</label><label class="expand" for="c-39488413">[3 more]</label></div><br/><div class="children"><div class="content">Well we do have game engines for a while now.
Maybe a game engine with a chat interface would do a better job</div><br/><div id="39489495" class="c"><input type="checkbox" id="c-39489495" checked=""/><div class="controls bullet"><span class="by">3abiton</span><span>|</span><a href="#39487524">root</a><span>|</span><a href="#39488413">parent</a><span>|</span><a href="#39489256">next</a><span>|</span><label class="collapse" for="c-39489495">[-]</label><label class="expand" for="c-39489495">[1 more]</label></div><br/><div class="children"><div class="content">I think is the key, most likely it was a big part of their training dataset.</div><br/></div></div><div id="39489256" class="c"><input type="checkbox" id="c-39489256" checked=""/><div class="controls bullet"><span class="by">TheDudeMan</span><span>|</span><a href="#39487524">root</a><span>|</span><a href="#39488413">parent</a><span>|</span><a href="#39489495">prev</a><span>|</span><a href="#39490097">next</a><span>|</span><label class="collapse" for="c-39489256">[-]</label><label class="expand" for="c-39489256">[1 more]</label></div><br/><div class="children"><div class="content">Depends on whether your goal is to render a scene or push the envelope in generative AI.</div><br/></div></div></div></div><div id="39490097" class="c"><input type="checkbox" id="c-39490097" checked=""/><div class="controls bullet"><span class="by">asadotzler</span><span>|</span><a href="#39487524">parent</a><span>|</span><a href="#39488413">prev</a><span>|</span><a href="#39488158">next</a><span>|</span><label class="collapse" for="c-39490097">[-]</label><label class="expand" for="c-39490097">[1 more]</label></div><br/><div class="children"><div class="content">Like the cat springing a 5th leg and then losing it just as quick, in a cherry-picked video from the software makers? How does that fit your wishful narrative?</div><br/></div></div></div></div><div id="39488158" class="c"><input type="checkbox" id="c-39488158" checked=""/><div class="controls bullet"><span class="by">LarsDu88</span><span>|</span><a href="#39487524">prev</a><span>|</span><a href="#39487363">next</a><span>|</span><label class="collapse" for="c-39488158">[-]</label><label class="expand" for="c-39488158">[4 more]</label></div><br/><div class="children"><div class="content">Reminds me of when I tried to extract G-buffers from my Unity High Definition Rendering Pipeline test project: <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=Fwtc694qNUM" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=Fwtc694qNUM</a><p>I&#x27;m not sure if this paper is really proving anything though. There&#x27;s a giant-ass UNET Lora model that&#x27;s being trained here, so is it really &quot;extracting&quot; something from an existing model, or simply creating a new model that can create channels that look like something you&#x27;d get out of a deferred rendering pipeline.<p>After all, taking normals, albedo, and depth and combining them (deferred rendering) is just one of several techniques to create a 3d scene. Wasn&#x27;t even used in videogames until the early 2000s (in a Shrek videogame for the Xbox! (<a href="https:&#x2F;&#x2F;sites.google.com&#x2F;site&#x2F;richgel99&#x2F;the-early-history-of-deferred-shading-and-lighting" rel="nofollow">https:&#x2F;&#x2F;sites.google.com&#x2F;site&#x2F;richgel99&#x2F;the-early-history-of...</a>)<p>What would really be awesome is to get a LORA model that can extract the &quot;camera&quot; rotation and translation matrix for these image generation models. That would really demonstrate something (and be quite useful at the same time).</div><br/><div id="39488539" class="c"><input type="checkbox" id="c-39488539" checked=""/><div class="controls bullet"><span class="by">joefourier</span><span>|</span><a href="#39488158">parent</a><span>|</span><a href="#39488570">next</a><span>|</span><label class="collapse" for="c-39488539">[-]</label><label class="expand" for="c-39488539">[1 more]</label></div><br/><div class="children"><div class="content">If you look at the supplementary material, they do a test where they train the Lora with a randomly initialised Unet and it is largely incapable of extracting any surface normals as opposed to using the pretrained Stable Diffusion Unet - clearly showing the features of the model are relevant to its performance.</div><br/></div></div><div id="39488570" class="c"><input type="checkbox" id="c-39488570" checked=""/><div class="controls bullet"><span class="by">sfink</span><span>|</span><a href="#39488158">parent</a><span>|</span><a href="#39488539">prev</a><span>|</span><a href="#39487363">next</a><span>|</span><label class="collapse" for="c-39488570">[-]</label><label class="expand" for="c-39488570">[2 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t really know what I&#x27;m talking about, but doesn&#x27;t this address that?<p>&gt;  with newly learned parameters that make up less than 0.6% of the total parameters in the generative model<p>0.6% sounds like a small number. Is it measuring the right thing?<p>Certainly, I wouldn&#x27;t expect the model to necessarily be encoding exactly the set of things that they&#x27;re extracting, but it still seems very significant to me even if it is &quot;just&quot; encoding some set of things that can be cheaply (in terms of model size) and reliably mapped to normals, albedo, and depth.<p>(I don&#x27;t care what basis vectors it&#x27;s using, as long as I know how to map them to mine.)</div><br/><div id="39489018" class="c"><input type="checkbox" id="c-39489018" checked=""/><div class="controls bullet"><span class="by">LarsDu88</span><span>|</span><a href="#39488158">root</a><span>|</span><a href="#39488570">parent</a><span>|</span><a href="#39487363">next</a><span>|</span><label class="collapse" for="c-39489018">[-]</label><label class="expand" for="c-39489018">[1 more]</label></div><br/><div class="children"><div class="content">0.6 percent of a model with 890 million parameters is still 5.34 million parameters.<p>That&#x27;s still pretty big. Maybe big enough to fake normals, learn some albedo smoothing functions, and learn a depth estimator perhaps??</div><br/></div></div></div></div></div></div><div id="39487363" class="c"><input type="checkbox" id="c-39487363" checked=""/><div class="controls bullet"><span class="by">dkarras</span><span>|</span><a href="#39488158">prev</a><span>|</span><a href="#39488360">next</a><span>|</span><label class="collapse" for="c-39487363">[-]</label><label class="expand" for="c-39487363">[17 more]</label></div><br/><div class="children"><div class="content">This is pretty remarkable. So these really do learn humanly interpretable representations and not only doing some magic in the billion dimensional hyperplane that we can&#x27;t hope of deciphering.</div><br/><div id="39487453" class="c"><input type="checkbox" id="c-39487453" checked=""/><div class="controls bullet"><span class="by">corysama</span><span>|</span><a href="#39487363">parent</a><span>|</span><a href="#39488294">next</a><span>|</span><label class="collapse" for="c-39487453">[-]</label><label class="expand" for="c-39487453">[2 more]</label></div><br/><div class="children"><div class="content">As an old 3D graphics engineer, the fact that albedo is in there is as just striking as it should be expected.<p>The core components of physically based rendering are position (derivable from image XY and depth), surface normal, incoming light, and at least albedo + one of a few variations on surface material properties such as specularity and roughness.<p>That the AI is modeling depth is pretty expected. Modeling surface normal is a nice local convolution of depth. But, modeling albedo separated from incoming light is great. I wonder if specularity is hiding in there too.</div><br/><div id="39487480" class="c"><input type="checkbox" id="c-39487480" checked=""/><div class="controls bullet"><span class="by">hackerlight</span><span>|</span><a href="#39487363">root</a><span>|</span><a href="#39487453">parent</a><span>|</span><a href="#39488294">next</a><span>|</span><label class="collapse" for="c-39487480">[-]</label><label class="expand" for="c-39487480">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a <i>good</i> depth map, too. Better than other tools I&#x27;ve seen which require fiddling with lots of knobs to get a good result. Might be useful for textures for parallax mapping.</div><br/></div></div></div></div><div id="39488294" class="c"><input type="checkbox" id="c-39488294" checked=""/><div class="controls bullet"><span class="by">int_19h</span><span>|</span><a href="#39487363">parent</a><span>|</span><a href="#39487453">prev</a><span>|</span><a href="#39487694">next</a><span>|</span><label class="collapse" for="c-39488294">[-]</label><label class="expand" for="c-39488294">[13 more]</label></div><br/><div class="children"><div class="content">I find it amazing that, for all the evidence we have of generative models having some fairly complex internal model of the world, people still insist that they are mere &quot;stochastic parrots&quot; who &quot;don&#x27;t really understand anything&quot;.</div><br/><div id="39488541" class="c"><input type="checkbox" id="c-39488541" checked=""/><div class="controls bullet"><span class="by">mewpmewp2</span><span>|</span><a href="#39487363">root</a><span>|</span><a href="#39488294">parent</a><span>|</span><a href="#39490105">next</a><span>|</span><label class="collapse" for="c-39488541">[-]</label><label class="expand" for="c-39488541">[3 more]</label></div><br/><div class="children"><div class="content">From the other side however if you really think about it, our understanding of everything must be stochastic as well. So perhaps this sort of thing yields in many complexities that we are not aware of. How would I know I am not a stochaistic parrot of some sort. I am just neural nets traine on current envrionment while the base model that is dependent on DNA, through evolution and natural selection of the fittest. Same as currently competing LLMs where the best one will win out.</div><br/><div id="39489255" class="c"><input type="checkbox" id="c-39489255" checked=""/><div class="controls bullet"><span class="by">int_19h</span><span>|</span><a href="#39487363">root</a><span>|</span><a href="#39488541">parent</a><span>|</span><a href="#39490105">next</a><span>|</span><label class="collapse" for="c-39489255">[-]</label><label class="expand" for="c-39489255">[2 more]</label></div><br/><div class="children"><div class="content">You&#x27;re not wrong, but the &quot;stochastic parrot&quot; claim always comes with another, implicit one that <i>we</i> are not like that; that there&#x27;s some fundamental difference, somehow, even if it is not externally observable. Chinese room etc.<p>In short, it&#x27;s the good old religious debate about souls, just wrapped in techno-philosophical trappings.</div><br/><div id="39489550" class="c"><input type="checkbox" id="c-39489550" checked=""/><div class="controls bullet"><span class="by">cthalupa</span><span>|</span><a href="#39487363">root</a><span>|</span><a href="#39489255">parent</a><span>|</span><a href="#39490105">next</a><span>|</span><label class="collapse" for="c-39489550">[-]</label><label class="expand" for="c-39489550">[1 more]</label></div><br/><div class="children"><div class="content">You could leverage the exact same accusation against the other side - we know fundamentally how the math works on these things, yet somehow throw enough parameters at them and eventually there&#x27;s some undefined emergent behavior that results in something more.<p>What that something more is is even less defined with even fewer theories as to what it is than there are around the woo and mysticism of human intelligence. And as LarsDu88 points out in a separate thread, there are alternative explanations for what we&#x27;re seeing here besides &quot;We&#x27;ve created some sort of weird internal 3D engine that the diffusion models use for generating stuff,&quot; which also meshes closely with the fact that generations routinely have multiple perspectives and other errors that wouldn&#x27;t exist if they modeled the world some people are suggesting.<p>If there&#x27;s something more going on here, we&#x27;re going to need some real explanations instead of things that can be explained multiple other ways before I&#x27;m going to take it seriously, at least.</div><br/></div></div></div></div></div></div><div id="39490105" class="c"><input type="checkbox" id="c-39490105" checked=""/><div class="controls bullet"><span class="by">asadotzler</span><span>|</span><a href="#39487363">root</a><span>|</span><a href="#39488294">parent</a><span>|</span><a href="#39488541">prev</a><span>|</span><a href="#39488815">next</a><span>|</span><label class="collapse" for="c-39490105">[-]</label><label class="expand" for="c-39490105">[1 more]</label></div><br/><div class="children"><div class="content">Well, when the cherry picked videos from OpenAI have a cat springing a fifth leg for no reason, people are right to be skeptical.</div><br/></div></div><div id="39488815" class="c"><input type="checkbox" id="c-39488815" checked=""/><div class="controls bullet"><span class="by">wredue</span><span>|</span><a href="#39487363">root</a><span>|</span><a href="#39488294">parent</a><span>|</span><a href="#39490105">prev</a><span>|</span><a href="#39487694">next</a><span>|</span><label class="collapse" for="c-39488815">[-]</label><label class="expand" for="c-39488815">[8 more]</label></div><br/><div class="children"><div class="content">We have zero evidence that these models have any “understanding” of anything.<p>“Understanding” would mean that they be able to train themselves, which they are as yet unable to do.<p>We are tuning weights and biases to statistically regurgitate training data. That is all they are.</div><br/><div id="39489174" class="c"><input type="checkbox" id="c-39489174" checked=""/><div class="controls bullet"><span class="by">esafak</span><span>|</span><a href="#39487363">root</a><span>|</span><a href="#39488815">parent</a><span>|</span><a href="#39489086">next</a><span>|</span><label class="collapse" for="c-39489174">[-]</label><label class="expand" for="c-39489174">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t buy that definition of understanding. Yours is closer to learning. If you had an accident and lost the ability to learn new things, you would still be able to understand based on what you have learnt so far. And that&#x27;s what these models are like. They don&#x27;t retrain themselves because we haven&#x27;t told them to.</div><br/></div></div><div id="39489086" class="c"><input type="checkbox" id="c-39489086" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#39487363">root</a><span>|</span><a href="#39488815">parent</a><span>|</span><a href="#39489174">prev</a><span>|</span><a href="#39489040">next</a><span>|</span><label class="collapse" for="c-39489086">[-]</label><label class="expand" for="c-39489086">[5 more]</label></div><br/><div class="children"><div class="content">So, in order for a kid to understand multiplication means they must be able to train themselves and not regurgitate the multiplication table?</div><br/><div id="39489194" class="c"><input type="checkbox" id="c-39489194" checked=""/><div class="controls bullet"><span class="by">ipaddr</span><span>|</span><a href="#39487363">root</a><span>|</span><a href="#39489086">parent</a><span>|</span><a href="#39489223">next</a><span>|</span><label class="collapse" for="c-39489194">[-]</label><label class="expand" for="c-39489194">[3 more]</label></div><br/><div class="children"><div class="content">Yes I think so.  Understanding would involve understanding that it&#x27;s a short form for adding.  Remembering multiplication tables allows you to use math but it doesn&#x27;t infer understanding.<p>Training themselves is necessary.  All learning is self learning.  Teachers can present material in different ways but learning is personal.  No one can force you to learn either.</div><br/><div id="39489219" class="c"><input type="checkbox" id="c-39489219" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#39487363">root</a><span>|</span><a href="#39489194">parent</a><span>|</span><a href="#39489223">next</a><span>|</span><label class="collapse" for="c-39489219">[-]</label><label class="expand" for="c-39489219">[2 more]</label></div><br/><div class="children"><div class="content">You can check if a model (or a kid) understands multiplication by simply probing them with questions, to explain the concept in their own words, or on concrete examples. If their answers are robust they understand, if their answers are fragile and very input dependent, they don&#x27;t.<p>&quot;To understand&quot; is one of those poorly defined concepts, like &quot;consciousness&quot;, it is thrown a lot in the face when talking about AI. But what does it mean actually? It means to have a working model of the thing you are understanding, a causal model that adapts to any new configuration of the inputs reliably. Or in other words it means to generalize well around that topic.<p>The opposite would be to &quot;learn to the test&quot; or &quot;overfit the problem&quot; and only be able to solve very limited cases that follow the training pattern closely. That would make for brittle learning, at surface level, based on shortcuts.</div><br/><div id="39489272" class="c"><input type="checkbox" id="c-39489272" checked=""/><div class="controls bullet"><span class="by">int_19h</span><span>|</span><a href="#39487363">root</a><span>|</span><a href="#39489219">parent</a><span>|</span><a href="#39489223">next</a><span>|</span><label class="collapse" for="c-39489272">[-]</label><label class="expand" for="c-39489272">[1 more]</label></div><br/><div class="children"><div class="content">&gt; It means to have a working model of the thing you are understanding, a causal model that adapts to any new configuration of the inputs reliably<p>The weasel word here is &quot;reliably&quot;. What does this actually mean? It obviously cannot be reliable in a sense of always giving the correct result, because this would make understanding something a strict binary, and we definitely don&#x27;t treat it like that for humans - we say things like &quot;they understand it better than me&quot; all the time, which when you  boil it down has to mean &quot;their model of it is more predictive than mine&quot;.<p>But then if that is a quantifiable measure, then we&#x27;re really talking about &quot;reliable enough&quot;. And then the questions are: 1) where do you draw that line, exactly, and 2) even more importantly, <i>why</i> do you draw the line there and not somewhere else.<p>For me, the only sensible answer to this is to refuse to draw the line at all, and just embrace the fact that understanding is a spectrum. But then it doesn&#x27;t even make sense to ask questions like &quot;does the model <i>really</i> understands?&quot; - they are meaningless.<p>(The same goes for concepts like &quot;consciousness&quot; or &quot;intelligence&quot;, by the way.)<p>The reason why I think this isn&#x27;t universally accepted is because it makes us not special, and humans really, <i>really</i> like to think of themselves as special (just look at our religions).</div><br/></div></div></div></div></div></div><div id="39489223" class="c"><input type="checkbox" id="c-39489223" checked=""/><div class="controls bullet"><span class="by">mardef</span><span>|</span><a href="#39487363">root</a><span>|</span><a href="#39489086">parent</a><span>|</span><a href="#39489194">prev</a><span>|</span><a href="#39489040">next</a><span>|</span><label class="collapse" for="c-39489223">[-]</label><label class="expand" for="c-39489223">[1 more]</label></div><br/><div class="children"><div class="content">I wouldn&#x27;t call someone reciting a French-English dictionary a French speaker that understands the language.<p>Other way around. If a kid understood the concepts of multiplation, they could train themselves on the next logical steps like exponents.<p>The consequences of this in the terms of AI would mean they build on a series of concepts and would quickly dwarf us in intelligence.</div><br/></div></div></div></div><div id="39489040" class="c"><input type="checkbox" id="c-39489040" checked=""/><div class="controls bullet"><span class="by">huytersd</span><span>|</span><a href="#39487363">root</a><span>|</span><a href="#39488815">parent</a><span>|</span><a href="#39489086">prev</a><span>|</span><a href="#39487694">next</a><span>|</span><label class="collapse" for="c-39489040">[-]</label><label class="expand" for="c-39489040">[1 more]</label></div><br/><div class="children"><div class="content">No, you can have abstract representations of a concept which would fit understanding in a certain sense of the word. You can have “understanding” of a concept without an overarching self aware hypervisor. It’s like isolating a set of neurons in your brain that represent an idea.</div><br/></div></div></div></div></div></div></div></div><div id="39488360" class="c"><input type="checkbox" id="c-39488360" checked=""/><div class="controls bullet"><span class="by">hn_throwaway_99</span><span>|</span><a href="#39487363">prev</a><span>|</span><a href="#39488536">next</a><span>|</span><label class="collapse" for="c-39488360">[-]</label><label class="expand" for="c-39488360">[2 more]</label></div><br/><div class="children"><div class="content">I skimmed the paper, but a lot of it was over my head. As someone not very versed in image generation AI, can anyone help me understand? This sentence (which another commenter highlighted) appears to be the key part:<p>&gt; I-LoRA modulates key feature maps to extract intrinsic scene properties such as normals, depth, albedo, and shading, using the models&#x27; existing decoders without additional layers, revealing their deep understanding of scene intrinsics.<p>What exactly does &quot;modulates key feature maps to extract intrinsic scene properties&quot; mean? How were these scene property images generated if no additional decoding layers were added?</div><br/><div id="39489068" class="c"><input type="checkbox" id="c-39489068" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#39488360">parent</a><span>|</span><a href="#39488536">next</a><span>|</span><label class="collapse" for="c-39489068">[-]</label><label class="expand" for="c-39489068">[1 more]</label></div><br/><div class="children"><div class="content">Say you have a neural network with 1B parameters, you add 5M more parameters spread around (LoRA), and continue training for a while but only the newly added parameters, not the base network. The result is a &quot;modulated&quot; network that would predict scene properties.<p>The interesting thing is that it only takes a few more parameters so it must be that the original network was pretty close already.</div><br/></div></div></div></div><div id="39488536" class="c"><input type="checkbox" id="c-39488536" checked=""/><div class="controls bullet"><span class="by">educaysean</span><span>|</span><a href="#39488360">prev</a><span>|</span><a href="#39489642">next</a><span>|</span><label class="collapse" for="c-39488536">[-]</label><label class="expand" for="c-39488536">[1 more]</label></div><br/><div class="children"><div class="content">This is good news for VR (or spatial computing). If the models understand the physical world as well as the paper shows, generating two projections of a scene does not sound like a difficult ask. Really excited for what&#x27;s to come.</div><br/></div></div><div id="39489642" class="c"><input type="checkbox" id="c-39489642" checked=""/><div class="controls bullet"><span class="by">modeless</span><span>|</span><a href="#39488536">prev</a><span>|</span><a href="#39487908">next</a><span>|</span><label class="collapse" for="c-39489642">[-]</label><label class="expand" for="c-39489642">[1 more]</label></div><br/><div class="children"><div class="content">Ooh, so this can take real images and predict albedo and lighting! Please, someone use this to make relightable gaussian splatting scenes. Dynamic lighting would really expand the usefulness of 3D scans made from photos, and I haven&#x27;t seen anyone get anything close to what I would call &quot;good&quot; results in that area yet.</div><br/></div></div><div id="39487908" class="c"><input type="checkbox" id="c-39487908" checked=""/><div class="controls bullet"><span class="by">vslira</span><span>|</span><a href="#39489642">prev</a><span>|</span><a href="#39489910">next</a><span>|</span><label class="collapse" for="c-39487908">[-]</label><label class="expand" for="c-39487908">[3 more]</label></div><br/><div class="children"><div class="content">Not to be a skeptic or anything, but how do we know normal maps etc weren’t enriched into the datasets by the image gen companies?<p>I understand this paper links to open source model where that can be verified, but maybe this is one secret sauce of these more advanced models?</div><br/><div id="39488061" class="c"><input type="checkbox" id="c-39488061" checked=""/><div class="controls bullet"><span class="by">dougmwne</span><span>|</span><a href="#39487908">parent</a><span>|</span><a href="#39489910">next</a><span>|</span><label class="collapse" for="c-39488061">[-]</label><label class="expand" for="c-39488061">[2 more]</label></div><br/><div class="children"><div class="content">You would need to train on pairings of normal map images to source images. To my knowledge, that’s not a common training technique and this ability seems to bridge across several open models.</div><br/><div id="39488186" class="c"><input type="checkbox" id="c-39488186" checked=""/><div class="controls bullet"><span class="by">coffeebeqn</span><span>|</span><a href="#39487908">root</a><span>|</span><a href="#39488061">parent</a><span>|</span><a href="#39489910">next</a><span>|</span><label class="collapse" for="c-39488186">[-]</label><label class="expand" for="c-39488186">[1 more]</label></div><br/><div class="children"><div class="content">It’s also kind of cool if it “understands” a normal map and that it maps to specific 3D geometry. People generally use 3D tools like Zbrush to sculpt the details to normals. Probably some people can draw them too</div><br/></div></div></div></div></div></div><div id="39489910" class="c"><input type="checkbox" id="c-39489910" checked=""/><div class="controls bullet"><span class="by">dvh</span><span>|</span><a href="#39487908">prev</a><span>|</span><a href="#39487954">next</a><span>|</span><label class="collapse" for="c-39489910">[-]</label><label class="expand" for="c-39489910">[1 more]</label></div><br/><div class="children"><div class="content">I asked ai that was posted here yesterday to draw common european chub and virtually every single one had adipose fin.</div><br/></div></div><div id="39487954" class="c"><input type="checkbox" id="c-39487954" checked=""/><div class="controls bullet"><span class="by">auggierose</span><span>|</span><a href="#39489910">prev</a><span>|</span><a href="#39487387">next</a><span>|</span><label class="collapse" for="c-39487954">[-]</label><label class="expand" for="c-39487954">[6 more]</label></div><br/><div class="children"><div class="content">So how do they get the normals, for example? Are they generated by the AI <i>before</i> the image is generated in order to generate the image, and they are just reading them off some internal state?</div><br/><div id="39488206" class="c"><input type="checkbox" id="c-39488206" checked=""/><div class="controls bullet"><span class="by">dougmwne</span><span>|</span><a href="#39487954">parent</a><span>|</span><a href="#39487989">next</a><span>|</span><label class="collapse" for="c-39488206">[-]</label><label class="expand" for="c-39488206">[3 more]</label></div><br/><div class="children"><div class="content">Yes, there’s rudimentary evidence that there’s essentially a 3D engine within the model that participates in generating the image. If we could inspect and interpret the whole process it would likely be bizarre and byzantine, like a sort of convergent evolution that independently recreates a tangled spaghetti mess of unreal engine, adobe lightroom, and a physical simulation of a Canon D5.</div><br/><div id="39488495" class="c"><input type="checkbox" id="c-39488495" checked=""/><div class="controls bullet"><span class="by">qingcharles</span><span>|</span><a href="#39487954">root</a><span>|</span><a href="#39488206">parent</a><span>|</span><a href="#39487989">next</a><span>|</span><label class="collapse" for="c-39488495">[-]</label><label class="expand" for="c-39488495">[2 more]</label></div><br/><div class="children"><div class="content">Essentially similar perhaps to the 3D engine that a human brain runs that generates a single &quot;3D&quot; image from two 2D cameras (eyes) and fills in missing objects in blind spots, etc.</div><br/><div id="39489386" class="c"><input type="checkbox" id="c-39489386" checked=""/><div class="controls bullet"><span class="by">tsimionescu</span><span>|</span><a href="#39487954">root</a><span>|</span><a href="#39488495">parent</a><span>|</span><a href="#39487989">next</a><span>|</span><label class="collapse" for="c-39489386">[-]</label><label class="expand" for="c-39489386">[1 more]</label></div><br/><div class="children"><div class="content">Note that while having two eyes helps build a more accurate 3D image, people with one eye still see in 3D. Eye movement is at least as important a part of 3D vision as stereoscopy.</div><br/></div></div></div></div></div></div><div id="39487989" class="c"><input type="checkbox" id="c-39487989" checked=""/><div class="controls bullet"><span class="by">corysama</span><span>|</span><a href="#39487954">parent</a><span>|</span><a href="#39488206">prev</a><span>|</span><a href="#39487387">next</a><span>|</span><label class="collapse" for="c-39487989">[-]</label><label class="expand" for="c-39487989">[2 more]</label></div><br/><div class="children"><div class="content">The training data is just billions of {RGB image, text description} pairs. So, it appears the model figured out how to make the normals as part of the process of making the images.<p>Or, are you asking how the researchers extracted it?<p>&gt;  I-LoRA modulates key feature maps to extract intrinsic scene properties such as normals, depth, albedo, and shading, using the models&#x27; existing decoders without additional layers, revealing their deep understanding of scene intrinsics.</div><br/><div id="39489678" class="c"><input type="checkbox" id="c-39489678" checked=""/><div class="controls bullet"><span class="by">auggierose</span><span>|</span><a href="#39487954">root</a><span>|</span><a href="#39487989">parent</a><span>|</span><a href="#39487387">next</a><span>|</span><label class="collapse" for="c-39489678">[-]</label><label class="expand" for="c-39489678">[1 more]</label></div><br/><div class="children"><div class="content">Yes, that sentence &quot;modulates key feature maps&quot; doesn&#x27;t tell me anything. What do they mean when saying they extract the normals?</div><br/></div></div></div></div></div></div><div id="39487387" class="c"><input type="checkbox" id="c-39487387" checked=""/><div class="controls bullet"><span class="by">bbor</span><span>|</span><a href="#39487954">prev</a><span>|</span><a href="#39487856">next</a><span>|</span><label class="collapse" for="c-39487387">[-]</label><label class="expand" for="c-39487387">[6 more]</label></div><br/><div class="children"><div class="content">I have no idea what Toyota or adobe are up to and why they’re funding research with a name like this, but I fucking love it. It’s science, let’s get some whimsy back in here!!<p>More materially:<p><pre><code>  Optimized with a small set of labeled images, our model-agnostic approach adapts to various generative architectures, including Diffusion models, GANs, and Autoregressive models.
</code></pre>
Am I correct in understanding that this is purely a visuospatial tool, and the examples aren’t just visual by coincidence? Like, there’s no way to stretch this to text models? Very new to this interpretability approach, very impressive.</div><br/><div id="39487646" class="c"><input type="checkbox" id="c-39487646" checked=""/><div class="controls bullet"><span class="by">sp332</span><span>|</span><a href="#39487387">parent</a><span>|</span><a href="#39489381">next</a><span>|</span><label class="collapse" for="c-39487646">[-]</label><label class="expand" for="c-39487646">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s research into editing facts in language models. <a href="https:&#x2F;&#x2F;rome.baulab.info&#x2F;" rel="nofollow">https:&#x2F;&#x2F;rome.baulab.info&#x2F;</a></div><br/></div></div><div id="39489381" class="c"><input type="checkbox" id="c-39489381" checked=""/><div class="controls bullet"><span class="by">blovescoffee</span><span>|</span><a href="#39487387">parent</a><span>|</span><a href="#39487646">prev</a><span>|</span><a href="#39487533">next</a><span>|</span><label class="collapse" for="c-39489381">[-]</label><label class="expand" for="c-39489381">[1 more]</label></div><br/><div class="children"><div class="content">You have no idea why Toyota or Adobe are funding computer vision research?</div><br/></div></div><div id="39487533" class="c"><input type="checkbox" id="c-39487533" checked=""/><div class="controls bullet"><span class="by">raincole</span><span>|</span><a href="#39487387">parent</a><span>|</span><a href="#39489381">prev</a><span>|</span><a href="#39488504">next</a><span>|</span><label class="collapse" for="c-39487533">[-]</label><label class="expand" for="c-39487533">[2 more]</label></div><br/><div class="children"><div class="content">Bojack Horseman reference that we didn&#x27;t know we need.</div><br/><div id="39489185" class="c"><input type="checkbox" id="c-39489185" checked=""/><div class="controls bullet"><span class="by">seattle_spring</span><span>|</span><a href="#39487387">root</a><span>|</span><a href="#39487533">parent</a><span>|</span><a href="#39488504">next</a><span>|</span><label class="collapse" for="c-39489185">[-]</label><label class="expand" for="c-39489185">[1 more]</label></div><br/><div class="children"><div class="content">What is this, a crossover episode?</div><br/></div></div></div></div><div id="39488504" class="c"><input type="checkbox" id="c-39488504" checked=""/><div class="controls bullet"><span class="by">frri</span><span>|</span><a href="#39487387">parent</a><span>|</span><a href="#39487533">prev</a><span>|</span><a href="#39487856">next</a><span>|</span><label class="collapse" for="c-39488504">[-]</label><label class="expand" for="c-39488504">[1 more]</label></div><br/><div class="children"><div class="content">Si hzux</div><br/></div></div></div></div><div id="39487856" class="c"><input type="checkbox" id="c-39487856" checked=""/><div class="controls bullet"><span class="by">mindcrime</span><span>|</span><a href="#39487387">prev</a><span>|</span><a href="#39487152">next</a><span>|</span><label class="collapse" for="c-39487856">[-]</label><label class="expand" for="c-39487856">[1 more]</label></div><br/><div class="children"><div class="content">Damn, now I&#x27;m suddenly finding myself wanting to go back and re-watch Bojack Horseman. Not that that would be a bad thing.</div><br/></div></div><div id="39487152" class="c"><input type="checkbox" id="c-39487152" checked=""/><div class="controls bullet"><span class="by">goryramsy</span><span>|</span><a href="#39487856">prev</a><span>|</span><a href="#39489973">next</a><span>|</span><label class="collapse" for="c-39487152">[-]</label><label class="expand" for="c-39487152">[3 more]</label></div><br/><div class="children"><div class="content">SSL error? Just me?</div><br/><div id="39487340" class="c"><input type="checkbox" id="c-39487340" checked=""/><div class="controls bullet"><span class="by">corysama</span><span>|</span><a href="#39487152">parent</a><span>|</span><a href="#39487415">next</a><span>|</span><label class="collapse" for="c-39487340">[-]</label><label class="expand" for="c-39487340">[1 more]</label></div><br/><div class="children"><div class="content">Works on my machine.
Alternative link: <a href="https:&#x2F;&#x2F;github.com&#x2F;duxiaodan&#x2F;intrinsic-lora">https:&#x2F;&#x2F;github.com&#x2F;duxiaodan&#x2F;intrinsic-lora</a></div><br/></div></div><div id="39487415" class="c"><input type="checkbox" id="c-39487415" checked=""/><div class="controls bullet"><span class="by">01HNNWZ0MV43FF</span><span>|</span><a href="#39487152">parent</a><span>|</span><a href="#39487340">prev</a><span>|</span><a href="#39489973">next</a><span>|</span><label class="collapse" for="c-39487415">[-]</label><label class="expand" for="c-39487415">[1 more]</label></div><br/><div class="children"><div class="content">Works here. &quot;Verified by DigiCert&quot;. SHA-256 fingerprint of 38:2C:D4:2D:33:C0:2B:C6:67:8E:65:7C:E1:7B:84:6D:04:73:A7:E7:91:CD:B3:5B:8E:AD:90:1A:F1:E1:1A:08</div><br/></div></div></div></div></div></div></div></div></div></body></html>