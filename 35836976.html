<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1683363668492" as="style"/><link rel="stylesheet" href="styles.css?v=1683363668492"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/openai/shap-e">Shap-E: Generate 3D objects conditioned on text or images</a>Â <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>tim_sw</span> | <span>38 comments</span></div><br/><div><div id="35837489" class="c"><input type="checkbox" id="c-35837489" checked=""/><div class="controls bullet"><span class="by">krisoft</span><span>|</span><a href="#35838276">next</a><span>|</span><label class="collapse" for="c-35837489">[-]</label><label class="expand" for="c-35837489">[3 more]</label></div><br/><div class="children"><div class="content">Tangentially related: A hobby I found immensely rewarding as of late is to ask a generative model to draw something pretty and then try to make the object in real life.<p>I have previously asked dall-e to draw me steampunk watch-like gizmos, selected the prettiest and then I went and carved it out of wax. And right now I&#x27;m 3d modelling a copper owl jewellery design dreamed up by Midjourney.<p>It is a really exciting exercise because it makes me think about what do I like about the image, what is the &quot;essence of it&quot;. It is also stretches my maker muscles because when I design things for myself from scratch I always keep in mind the constraints of my tools and techniques. But of course the AI has no such compunctions. It just draws something pretty, manufacturability be damned.</div><br/><div id="35838998" class="c"><input type="checkbox" id="c-35838998" checked=""/><div class="controls bullet"><span class="by">vertis</span><span>|</span><a href="#35837489">parent</a><span>|</span><a href="#35837944">next</a><span>|</span><label class="collapse" for="c-35838998">[-]</label><label class="expand" for="c-35838998">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve found it very rewarding as a source of fantastical ideas. I like that generating items in mid-journey can break me out of one line of thinking even if that&#x27;s because it&#x27;s result is absurd.</div><br/></div></div><div id="35837944" class="c"><input type="checkbox" id="c-35837944" checked=""/><div class="controls bullet"><span class="by">samstave</span><span>|</span><a href="#35837489">parent</a><span>|</span><a href="#35838998">prev</a><span>|</span><a href="#35838276">next</a><span>|</span><label class="collapse" for="c-35837944">[-]</label><label class="expand" for="c-35837944">[1 more]</label></div><br/><div class="children"><div class="content">please share!</div><br/></div></div></div></div><div id="35838276" class="c"><input type="checkbox" id="c-35838276" checked=""/><div class="controls bullet"><span class="by">cl42</span><span>|</span><a href="#35837489">prev</a><span>|</span><a href="#35838642">next</a><span>|</span><label class="collapse" for="c-35838276">[-]</label><label class="expand" for="c-35838276">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve been playing with this a bit. Sharing some examples that aren&#x27;t from their repo, in case people are curious.<p>Simple objects are surprisingly good. Examples of a viking helmet below:<p>-- <a href="https:&#x2F;&#x2F;phasellm.com&#x2F;static&#x2F;img&#x2F;helmet-01.png" rel="nofollow">https:&#x2F;&#x2F;phasellm.com&#x2F;static&#x2F;img&#x2F;helmet-01.png</a><p>-- <a href="https:&#x2F;&#x2F;phasellm.com&#x2F;static&#x2F;img&#x2F;helmet-02.png" rel="nofollow">https:&#x2F;&#x2F;phasellm.com&#x2F;static&#x2F;img&#x2F;helmet-02.png</a><p>More complex objects, e.g., &quot;a viking&quot; are harder though you can clearly see what the model is trying to do (cape, sword, person, etc.)...<p>-- <a href="https:&#x2F;&#x2F;phasellm.com&#x2F;static&#x2F;img&#x2F;viking-01.png" rel="nofollow">https:&#x2F;&#x2F;phasellm.com&#x2F;static&#x2F;img&#x2F;viking-01.png</a><p>Maybe more iterations of the model could work. I&#x27;m sure it&#x27;s only a matter of time before this gets much better, more details, etc.</div><br/></div></div><div id="35838642" class="c"><input type="checkbox" id="c-35838642" checked=""/><div class="controls bullet"><span class="by">joeld42</span><span>|</span><a href="#35838276">prev</a><span>|</span><a href="#35837594">next</a><span>|</span><label class="collapse" for="c-35838642">[-]</label><label class="expand" for="c-35838642">[1 more]</label></div><br/><div class="children"><div class="content">Tip: If you&#x27;re loading these .glbs in blender, add an &quot;Attribute&quot; node in the shader editor, put &quot;Col&quot; in the name field, and connect &quot;Color&quot; to &quot;Base Color&quot; in the material to see the colors.</div><br/></div></div><div id="35837594" class="c"><input type="checkbox" id="c-35837594" checked=""/><div class="controls bullet"><span class="by">startupsfail</span><span>|</span><a href="#35838642">prev</a><span>|</span><a href="#35838569">next</a><span>|</span><label class="collapse" for="c-35837594">[-]</label><label class="expand" for="c-35837594">[5 more]</label></div><br/><div class="children"><div class="content">There was something like that, but seemingly (comparing demo videos) much higher quality released a few months ago from NVIDIA - <a href="https:&#x2F;&#x2F;research.nvidia.com&#x2F;labs&#x2F;dir&#x2F;magic3d&#x2F;" rel="nofollow">https:&#x2F;&#x2F;research.nvidia.com&#x2F;labs&#x2F;dir&#x2F;magic3d&#x2F;</a></div><br/><div id="35837690" class="c"><input type="checkbox" id="c-35837690" checked=""/><div class="controls bullet"><span class="by">ehsankia</span><span>|</span><a href="#35837594">parent</a><span>|</span><a href="#35838470">next</a><span>|</span><label class="collapse" for="c-35837690">[-]</label><label class="expand" for="c-35837690">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t understand, if you have a 3d model, why do these gifs need to be so low res and aliased? The AI isn&#x27;t generated gifs, why can&#x27;t they properly render the previews in higher quality? The magic3d models don&#x27;t look that much more detailed, they&#x27;re just rendered properly...</div><br/></div></div><div id="35838470" class="c"><input type="checkbox" id="c-35838470" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#35837594">parent</a><span>|</span><a href="#35837690">prev</a><span>|</span><a href="#35838505">next</a><span>|</span><label class="collapse" for="c-35838470">[-]</label><label class="expand" for="c-35838470">[1 more]</label></div><br/><div class="children"><div class="content">The colors on those are strange and unpleasant. I wonder if they forgot something basic like gamma correction.</div><br/></div></div><div id="35838505" class="c"><input type="checkbox" id="c-35838505" checked=""/><div class="controls bullet"><span class="by">Racing0461</span><span>|</span><a href="#35837594">parent</a><span>|</span><a href="#35838470">prev</a><span>|</span><a href="#35838569">next</a><span>|</span><label class="collapse" for="c-35838505">[-]</label><label class="expand" for="c-35838505">[2 more]</label></div><br/><div class="children"><div class="content">maybe thats why they released at on github instead of adding it as a feature on openai.com, it sucks.</div><br/><div id="35839382" class="c"><input type="checkbox" id="c-35839382" checked=""/><div class="controls bullet"><span class="by">orliesaurus</span><span>|</span><a href="#35837594">root</a><span>|</span><a href="#35838505">parent</a><span>|</span><a href="#35838569">next</a><span>|</span><label class="collapse" for="c-35839382">[-]</label><label class="expand" for="c-35839382">[1 more]</label></div><br/><div class="children"><div class="content">I actually thought this initially, but I also believe that given the nature of where we are going (in the 3d space at least) it makes sense to open source something that isn&#x27;t commercially resellable (thinking all the people who just repackage openai APIs) and let the community iterate over it and make it better perhaps?</div><br/></div></div></div></div></div></div><div id="35838569" class="c"><input type="checkbox" id="c-35838569" checked=""/><div class="controls bullet"><span class="by">georyb</span><span>|</span><a href="#35837594">prev</a><span>|</span><a href="#35837323">next</a><span>|</span><label class="collapse" for="c-35838569">[-]</label><label class="expand" for="c-35838569">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m curios how much more difficult is generative 3D?<p>We are barely able to generate 2D 1080p images, without artefacts using diffusion methods. How much more complex is the jump to production grade 3D?<p>As someone creating re-usable 3D product models on Polymock @ <a href="https:&#x2F;&#x2F;polymock.com" rel="nofollow">https:&#x2F;&#x2F;polymock.com</a> the bigest issue for me, is that you want your models to be editable. 3D modellers want to post-process and add tweaks to existing 3D models. Current AI generators lack this layering structures.<p>What I actually want, is a 3D generator for textures &#x2F; materials. It should be a much simpler task for current AI.<p>At the moment, the state of 3D generators is slowly ripening for indie game developers. I&#x27;m sure that in the near future, the models will be high-enough quality to generate a basic character set.<p>Others have mentioned it, but I think NVIDIA has an edge in 3D synthesis 
 &amp; rendering. OpenAI is arguable the leader in consumer text-transformers - I wonder the goal for releasing this POC (I don&#x27;t think they will allocate any serious resource here)</div><br/><div id="35838615" class="c"><input type="checkbox" id="c-35838615" checked=""/><div class="controls bullet"><span class="by">prox</span><span>|</span><a href="#35838569">parent</a><span>|</span><a href="#35837323">next</a><span>|</span><label class="collapse" for="c-35838615">[-]</label><label class="expand" for="c-35838615">[1 more]</label></div><br/><div class="children"><div class="content">Someone made a SD&#x2F;blender hybrid add-on where texturing will be based on a prompt.</div><br/></div></div></div></div><div id="35837323" class="c"><input type="checkbox" id="c-35837323" checked=""/><div class="controls bullet"><span class="by">alexmolas</span><span>|</span><a href="#35838569">prev</a><span>|</span><a href="#35837458">next</a><span>|</span><label class="collapse" for="c-35837323">[-]</label><label class="expand" for="c-35837323">[5 more]</label></div><br/><div class="children"><div class="content">Finally some open AI from OpenAI</div><br/><div id="35837593" class="c"><input type="checkbox" id="c-35837593" checked=""/><div class="controls bullet"><span class="by">juunpp</span><span>|</span><a href="#35837323">parent</a><span>|</span><a href="#35838417">next</a><span>|</span><label class="collapse" for="c-35837593">[-]</label><label class="expand" for="c-35837593">[3 more]</label></div><br/><div class="children"><div class="content">Is it? The code in the repository is MIT, but the models are downloaded from Azure:<p><a href="https:&#x2F;&#x2F;github.com&#x2F;openai&#x2F;shap-e&#x2F;blob&#x2F;main&#x2F;shap_e&#x2F;models&#x2F;download.py">https:&#x2F;&#x2F;github.com&#x2F;openai&#x2F;shap-e&#x2F;blob&#x2F;main&#x2F;shap_e&#x2F;models&#x2F;dow...</a><p>The code license in such cases would not extend to binary blobs downloaded from the Internet. And the code is basically useless without the blob.</div><br/><div id="35838430" class="c"><input type="checkbox" id="c-35838430" checked=""/><div class="controls bullet"><span class="by">pabs3</span><span>|</span><a href="#35837323">root</a><span>|</span><a href="#35837593">parent</a><span>|</span><a href="#35838634">next</a><span>|</span><label class="collapse" for="c-35838430">[-]</label><label class="expand" for="c-35838430">[1 more]</label></div><br/><div class="children"><div class="content">It definitely wouldn&#x27;t pass Debian&#x27;s machine learning policy:<p><a href="https:&#x2F;&#x2F;salsa.debian.org&#x2F;deeplearning-team&#x2F;ml-policy&#x2F;" rel="nofollow">https:&#x2F;&#x2F;salsa.debian.org&#x2F;deeplearning-team&#x2F;ml-policy&#x2F;</a>
<a href="https:&#x2F;&#x2F;deepdive.opensource.org&#x2F;podcast&#x2F;why-debian-wont-distribute-ai-models-any-time-soon&#x2F;" rel="nofollow">https:&#x2F;&#x2F;deepdive.opensource.org&#x2F;podcast&#x2F;why-debian-wont-dist...</a></div><br/></div></div><div id="35838634" class="c"><input type="checkbox" id="c-35838634" checked=""/><div class="controls bullet"><span class="by">newswasboring</span><span>|</span><a href="#35837323">root</a><span>|</span><a href="#35837593">parent</a><span>|</span><a href="#35838430">prev</a><span>|</span><a href="#35838417">next</a><span>|</span><label class="collapse" for="c-35838634">[-]</label><label class="expand" for="c-35838634">[1 more]</label></div><br/><div class="children"><div class="content">I can&#x27;t figure it out, what&#x27;s the license on the blob?</div><br/></div></div></div></div><div id="35838417" class="c"><input type="checkbox" id="c-35838417" checked=""/><div class="controls bullet"><span class="by">speedgoose</span><span>|</span><a href="#35837323">parent</a><span>|</span><a href="#35837593">prev</a><span>|</span><a href="#35837458">next</a><span>|</span><label class="collapse" for="c-35838417">[-]</label><label class="expand" for="c-35838417">[1 more]</label></div><br/><div class="children"><div class="content">OpenAi also released Whisper in September. They do open stuff once in a while.</div><br/></div></div></div></div><div id="35837458" class="c"><input type="checkbox" id="c-35837458" checked=""/><div class="controls bullet"><span class="by">chaxor</span><span>|</span><a href="#35837323">prev</a><span>|</span><a href="#35838661">next</a><span>|</span><label class="collapse" for="c-35837458">[-]</label><label class="expand" for="c-35837458">[2 more]</label></div><br/><div class="children"><div class="content">Seems extremely similar to the Point-e work done a few months ago.
I would imagine that just doing Veitoris Rips on the point-e would get close to this solution as well, although that would be a bit too logic based for the ML world we live in now.</div><br/><div id="35837663" class="c"><input type="checkbox" id="c-35837663" checked=""/><div class="controls bullet"><span class="by">jahewson</span><span>|</span><a href="#35837458">parent</a><span>|</span><a href="#35838661">next</a><span>|</span><label class="collapse" for="c-35837663">[-]</label><label class="expand" for="c-35837663">[1 more]</label></div><br/><div class="children"><div class="content">That would get you a mesh but not a NeRF.</div><br/></div></div></div></div><div id="35838661" class="c"><input type="checkbox" id="c-35838661" checked=""/><div class="controls bullet"><span class="by">EamonnMR</span><span>|</span><a href="#35837458">prev</a><span>|</span><a href="#35838241">next</a><span>|</span><label class="collapse" for="c-35838661">[-]</label><label class="expand" for="c-35838661">[1 more]</label></div><br/><div class="children"><div class="content">The next super Scribblenauts game is going to be wild.</div><br/></div></div><div id="35838241" class="c"><input type="checkbox" id="c-35838241" checked=""/><div class="controls bullet"><span class="by">personjerry</span><span>|</span><a href="#35838661">prev</a><span>|</span><a href="#35838063">next</a><span>|</span><label class="collapse" for="c-35838241">[-]</label><label class="expand" for="c-35838241">[2 more]</label></div><br/><div class="children"><div class="content">Every time I click Samples.md and then click back, GitHub tells me &quot;Access to this site has been restricted.&quot; and times me out for a while. Anybody have the same thing or know why?</div><br/><div id="35839358" class="c"><input type="checkbox" id="c-35839358" checked=""/><div class="controls bullet"><span class="by">knobhandle</span><span>|</span><a href="#35838241">parent</a><span>|</span><a href="#35838063">next</a><span>|</span><label class="collapse" for="c-35839358">[-]</label><label class="expand" for="c-35839358">[1 more]</label></div><br/><div class="children"><div class="content">Had the same issue. On other browser I was able to browse the site. Just clear recent history and cookies.</div><br/></div></div></div></div><div id="35838063" class="c"><input type="checkbox" id="c-35838063" checked=""/><div class="controls bullet"><span class="by">bemmu</span><span>|</span><a href="#35838241">prev</a><span>|</span><a href="#35837193">next</a><span>|</span><label class="collapse" for="c-35838063">[-]</label><label class="expand" for="c-35838063">[2 more]</label></div><br/><div class="children"><div class="content">HuggingFace space: <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;hysts&#x2F;Shap-E" rel="nofollow">https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;hysts&#x2F;Shap-E</a></div><br/><div id="35838638" class="c"><input type="checkbox" id="c-35838638" checked=""/><div class="controls bullet"><span class="by">newswasboring</span><span>|</span><a href="#35838063">parent</a><span>|</span><a href="#35837193">next</a><span>|</span><label class="collapse" for="c-35838638">[-]</label><label class="expand" for="c-35838638">[1 more]</label></div><br/><div class="children"><div class="content">Did it get hugged to death? I only see a runtime error.</div><br/></div></div></div></div><div id="35837193" class="c"><input type="checkbox" id="c-35837193" checked=""/><div class="controls bullet"><span class="by">qup</span><span>|</span><a href="#35838063">prev</a><span>|</span><a href="#35837917">next</a><span>|</span><label class="collapse" for="c-35837193">[-]</label><label class="expand" for="c-35837193">[7 more]</label></div><br/><div class="children"><div class="content">I just got a 3D printer but I&#x27;m a total noob.<p>How many more steps have to occur between these models and me printing them?</div><br/><div id="35837386" class="c"><input type="checkbox" id="c-35837386" checked=""/><div class="controls bullet"><span class="by">krisoft</span><span>|</span><a href="#35837193">parent</a><span>|</span><a href="#35837324">next</a><span>|</span><label class="collapse" for="c-35837386">[-]</label><label class="expand" for="c-35837386">[4 more]</label></div><br/><div class="children"><div class="content">&gt; How many more steps have to occur between these models and me printing them?<p>Shouldn&#x27;t be too hard. Based on the code of the examples it seems it can output polygonal meshes in ply format. Either your slicer natively supports that, or you can use something (for example blender) to convert the ply to a format your slicer supports.<p>What can go wrong if the model &quot;looks okay&quot; but have some subtle geometric issue (like if it has a missing face, which makes it non-manifold or non-watertight) Nowadays many slicers have tools to heal such problems, but there can be dragons that way.<p>I looked for an example object in their repo and found this one: <a href="https:&#x2F;&#x2F;github.com&#x2F;openai&#x2F;shap-e&#x2F;blob&#x2F;main&#x2F;shap_e&#x2F;examples&#x2F;example_data&#x2F;cactus&#x2F;object.obj">https:&#x2F;&#x2F;github.com&#x2F;openai&#x2F;shap-e&#x2F;blob&#x2F;main&#x2F;shap_e&#x2F;examples&#x2F;e...</a><p>If that is representative it is a very nice clean geometry. I have sliced it with prusa slicer no problem and I could be printing it within a minute of downloading it if I would need a 3d printed cactus in my life.<p>&gt; I just got a 3D printer but I&#x27;m a total noob.<p>How noob you mean? If this would be literally your first print I would recommend printing first a sample file which came with your printer. (just to make sure everything is okay with the printer itself) But as a second print you can totally try to print one of these of course.  Just don&#x27;t give up the hobby if something goes wrong :) Something always goes wrong.</div><br/><div id="35837674" class="c"><input type="checkbox" id="c-35837674" checked=""/><div class="controls bullet"><span class="by">qup</span><span>|</span><a href="#35837193">root</a><span>|</span><a href="#35837386">parent</a><span>|</span><a href="#35837324">next</a><span>|</span><label class="collapse" for="c-35837674">[-]</label><label class="expand" for="c-35837674">[3 more]</label></div><br/><div class="children"><div class="content">&gt; How noob you mean?<p>I successfully printed a hollow cube yesterday, my first ever print, and failed on about 6 attempts at a &quot;mario ring&quot; file. It&#x27;s PETG and I&#x27;m just fiddling with settings, getting a lot of stringing etc.<p>Anyway, very new, but I&#x27;m prepared for the learning curve. I&#x27;m a good debugger, and I don&#x27;t give up easily, so hopefully that&#x27;ll carry through to the printing.</div><br/><div id="35837730" class="c"><input type="checkbox" id="c-35837730" checked=""/><div class="controls bullet"><span class="by">filoleg</span><span>|</span><a href="#35837193">root</a><span>|</span><a href="#35837674">parent</a><span>|</span><a href="#35837742">next</a><span>|</span><label class="collapse" for="c-35837730">[-]</label><label class="expand" for="c-35837730">[1 more]</label></div><br/><div class="children"><div class="content">I got into 3D printing from zero knowledge a couple of months ago, and i found PETG an absolute nightmare to deal with compared to PLA.<p>Mind you, i only bought filament from Prusa and AtomicFilament, two very respectable manufacturers. Had zero issues with their PLA, and it looked beautiful. With PETG, no matter how much i tried adjusting live-z levels or playing in PrusaSlicer with print speed levels, temperature, layer height, etc., it all would mess up at some point. Out of 5 prints of the same object, I finally managed to get one great print out of PETG. But when I tried printing another one, I would start having various issues again and would have to adjust things again in hopes of eventually getting it right. I just went back to PLA and had zero issues at all since then.<p>Even though I am aware of PLA disadvantages compared to PETG, I simply realized that for my purposes, they didn&#x27;t matter nearly as much as consistency and ease of good prints.</div><br/></div></div><div id="35837742" class="c"><input type="checkbox" id="c-35837742" checked=""/><div class="controls bullet"><span class="by">ehsankia</span><span>|</span><a href="#35837193">root</a><span>|</span><a href="#35837674">parent</a><span>|</span><a href="#35837730">prev</a><span>|</span><a href="#35837324">next</a><span>|</span><label class="collapse" for="c-35837742">[-]</label><label class="expand" for="c-35837742">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m also pretty new, and in my experience, when it gets tricky is support. Quality models for 3d printers are made to print without supports, but a lot of these normal models have a lot of weird details and geometries that require supports. And then you gotta fiddle with a bunch of settings to find the right parameters for it.</div><br/></div></div></div></div></div></div><div id="35837324" class="c"><input type="checkbox" id="c-35837324" checked=""/><div class="controls bullet"><span class="by">dceddia</span><span>|</span><a href="#35837193">parent</a><span>|</span><a href="#35837386">prev</a><span>|</span><a href="#35837917">next</a><span>|</span><label class="collapse" for="c-35837324">[-]</label><label class="expand" for="c-35837324">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not sure what format it&#x27;s generating these models in, but if they&#x27;re SDL, you should be able to drop them into a slicer program (like PrusaSlicer, Cura, etc) and generate the gcode there (the 3D printer movement instructions). Then load that gcode into your printer (via SD card, wifi, whatever it supports) and go!<p>If these aren&#x27;t in SDL, but are some format Blender can open, then Blender can turn them into SDL. It looks from the description like it&#x27;s compatible with Blender.</div><br/><div id="35837357" class="c"><input type="checkbox" id="c-35837357" checked=""/><div class="controls bullet"><span class="by">kuida0r3</span><span>|</span><a href="#35837193">root</a><span>|</span><a href="#35837324">parent</a><span>|</span><a href="#35837917">next</a><span>|</span><label class="collapse" for="c-35837357">[-]</label><label class="expand" for="c-35837357">[1 more]</label></div><br/><div class="children"><div class="content">From the jupyter notebook in the repo [0], the output is in .ply or polygon file format which is used by some 3D scanners and can be converted to STL supported by most 3D printers.<p>0-<a href="https:&#x2F;&#x2F;github.com&#x2F;openai&#x2F;shap-e&#x2F;blob&#x2F;main&#x2F;shap_e&#x2F;examples&#x2F;sample_text_to_3d.ipynb">https:&#x2F;&#x2F;github.com&#x2F;openai&#x2F;shap-e&#x2F;blob&#x2F;main&#x2F;shap_e&#x2F;examples&#x2F;s...</a></div><br/></div></div></div></div></div></div><div id="35837318" class="c"><input type="checkbox" id="c-35837318" checked=""/><div class="controls bullet"><span class="by">babuloseo</span><span>|</span><a href="#35837246">prev</a><span>|</span><a href="#35837206">next</a><span>|</span><label class="collapse" for="c-35837318">[-]</label><label class="expand" for="c-35837318">[3 more]</label></div><br/><div class="children"><div class="content">TIL what a Ube ice cream cone is</div><br/><div id="35838486" class="c"><input type="checkbox" id="c-35838486" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#35837318">parent</a><span>|</span><a href="#35837206">next</a><span>|</span><label class="collapse" for="c-35838486">[-]</label><label class="expand" for="c-35838486">[2 more]</label></div><br/><div class="children"><div class="content">it&#x27;s popular in the Philippines and it&#x27;s an impressive purple color. Taro and pandan are good in desserts too.<p>And then there&#x27;s durian.</div><br/><div id="35839126" class="c"><input type="checkbox" id="c-35839126" checked=""/><div class="controls bullet"><span class="by">uhhyeahdude</span><span>|</span><a href="#35837318">root</a><span>|</span><a href="#35838486">parent</a><span>|</span><a href="#35837206">next</a><span>|</span><label class="collapse" for="c-35839126">[-]</label><label class="expand" for="c-35839126">[1 more]</label></div><br/><div class="children"><div class="content">Ube has been an increasingly trendy&#x2F;popular flavor for all sorts of dessert food in America; this is perhaps most evident if you visit Hawaii, but it can also be found in pretty much any bubble tea shop as a flavor option.  ubaehawaii makes an ube crinkle cookie that is as delicious as it is purple. Iâm not affiliated or anything, just a fan of good cookies (and ube!)</div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>