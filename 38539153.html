<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1701853256376" as="style"/><link rel="stylesheet" href="styles.css?v=1701853256376"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/ml-explore/mlx">MLX: An array framework for Apple Silicon</a> <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>jacobkahn</span> | <span>19 comments</span></div><br/><div><div id="38541402" class="c"><input type="checkbox" id="c-38541402" checked=""/><div class="controls bullet"><span class="by">babl-yc</span><span>|</span><a href="#38541154">next</a><span>|</span><label class="collapse" for="c-38541402">[-]</label><label class="expand" for="c-38541402">[5 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve found the process of porting custom ML models to iOS extremely difficult.<p>AFAIK the only way to leverage Apple Neural Engine (and get the best performance) is to use CoreML. The only documented way to use CoreML is via coremltools, which takes a trace of a PyTorch  model and attempts to translate it into a protobuf graph understood by CoreML.<p>This process often fails and requires model changes, or worse &quot;succeeds&quot; but gives you the wrong output when you run the model. Additionally, you have to play detective to figure out why some operations run on the CPU, or GPU instead of ANE.<p>It&#x27;s exciting to see more tools like this for working with tensor-like objects, but I really wish Apple would make porting custom models in a high performance manner easier.</div><br/><div id="38541591" class="c"><input type="checkbox" id="c-38541591" checked=""/><div class="controls bullet"><span class="by">sgu999</span><span>|</span><a href="#38541402">parent</a><span>|</span><a href="#38541442">next</a><span>|</span><label class="collapse" for="c-38541591">[-]</label><label class="expand" for="c-38541591">[2 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t understand why Apple isn&#x27;t trying to integrate better with the standard tools for that field. I guess it makes sense to lock in app devs, but ML eng.?<p>That said I&#x27;ve had good success with onnxruntime recently [0].<p>[0] <a href="https:&#x2F;&#x2F;onnxruntime.ai&#x2F;docs&#x2F;execution-providers&#x2F;CoreML-ExecutionProvider.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;onnxruntime.ai&#x2F;docs&#x2F;execution-providers&#x2F;CoreML-Execu...</a></div><br/><div id="38541644" class="c"><input type="checkbox" id="c-38541644" checked=""/><div class="controls bullet"><span class="by">domschl</span><span>|</span><a href="#38541402">root</a><span>|</span><a href="#38541591">parent</a><span>|</span><a href="#38541442">next</a><span>|</span><label class="collapse" for="c-38541644">[-]</label><label class="expand" for="c-38541644">[1 more]</label></div><br/><div class="children"><div class="content">The project probably at least partially serves as documentation for other platforms to integrate Silicon acceleration. It basically demonstrates how to use macOS Accelerate and Metal MPS (metal performance shaders) using C++ for Machine Learning and training optimization.<p>Thus other platforms can simply take this backend-code and integrate it. (Pytorch basically did that already with Apple&#x27;s help).</div><br/></div></div></div></div><div id="38541442" class="c"><input type="checkbox" id="c-38541442" checked=""/><div class="controls bullet"><span class="by">m00x</span><span>|</span><a href="#38541402">parent</a><span>|</span><a href="#38541591">prev</a><span>|</span><a href="#38541154">next</a><span>|</span><label class="collapse" for="c-38541442">[-]</label><label class="expand" for="c-38541442">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not sure why there aren&#x27;t more companies supporting ONNX. It&#x27;s so nice to use if it&#x27;s supported by the platform&#x2F;model.</div><br/><div id="38541517" class="c"><input type="checkbox" id="c-38541517" checked=""/><div class="controls bullet"><span class="by">lifthrasiir</span><span>|</span><a href="#38541402">root</a><span>|</span><a href="#38541442">parent</a><span>|</span><a href="#38541154">next</a><span>|</span><label class="collapse" for="c-38541517">[-]</label><label class="expand" for="c-38541517">[1 more]</label></div><br/><div class="children"><div class="content">Not every model can be easily converted to ONNX though, especially with PyTorch.</div><br/></div></div></div></div></div></div><div id="38541154" class="c"><input type="checkbox" id="c-38541154" checked=""/><div class="controls bullet"><span class="by">kiratp</span><span>|</span><a href="#38541402">prev</a><span>|</span><a href="#38541617">next</a><span>|</span><label class="collapse" for="c-38541154">[-]</label><label class="expand" for="c-38541154">[4 more]</label></div><br/><div class="children"><div class="content">I wish there was more information as to how this differs from or improves on Jax.<p>Flax+Jax+OpenXLA seems to finally be building some momentum so when a big player launches yet another competitor, the justification for it would be a good thing to see.<p>What was “not good enough” with Jax? Why did it make sense to put this human time and energy there instead of doubling down on Flax&#x2F;Jax&#x2F;OpenXLA? How will this move the needle at all against Nvidia?<p>I guess the fact that Google is pushing OpenXLA is making the other giants not want to truly lean in?<p>I don’t want 10 competing “choices”. I want one clear, open, competitor to Cuda that works on all the competing hardware.</div><br/><div id="38541448" class="c"><input type="checkbox" id="c-38541448" checked=""/><div class="controls bullet"><span class="by">jphoward</span><span>|</span><a href="#38541154">parent</a><span>|</span><a href="#38541617">next</a><span>|</span><label class="collapse" for="c-38541448">[-]</label><label class="expand" for="c-38541448">[3 more]</label></div><br/><div class="children"><div class="content">I was excited about JAX, but I think the developers missed a trick when they decided it should be entirely immutable. It sounds silly, but I think if I have an array `x` and want to set index 0 to 10, it&#x27;s a big mistake if I can&#x27;t do:<p><pre><code>  x[0] = 10
</code></pre>
And instead I have to do:<p><pre><code>  y = x.at[0].set(10)
</code></pre>
Of course this has advantages, and I know it sounds lame, but as someone whose brain works in numpy, this is really offputting.</div><br/><div id="38541670" class="c"><input type="checkbox" id="c-38541670" checked=""/><div class="controls bullet"><span class="by">leewlving</span><span>|</span><a href="#38541154">root</a><span>|</span><a href="#38541448">parent</a><span>|</span><a href="#38541617">next</a><span>|</span><label class="collapse" for="c-38541670">[-]</label><label class="expand" for="c-38541670">[2 more]</label></div><br/><div class="children"><div class="content">I think it is a feature from functional programming. In some level, I more agree with jax style.</div><br/><div id="38541765" class="c"><input type="checkbox" id="c-38541765" checked=""/><div class="controls bullet"><span class="by">lifthrasiir</span><span>|</span><a href="#38541154">root</a><span>|</span><a href="#38541670">parent</a><span>|</span><a href="#38541617">next</a><span>|</span><label class="collapse" for="c-38541765">[-]</label><label class="expand" for="c-38541765">[1 more]</label></div><br/><div class="children"><div class="content">But you can convert automatically a mutable code into a functional code if that makes things easier. That&#x27;s what Haskell&#x27;s `do` notation does, and PyTorch even has `torch.func.functionalize` for that. Immutable should be default, but not compulsory.</div><br/></div></div></div></div></div></div></div></div><div id="38541617" class="c"><input type="checkbox" id="c-38541617" checked=""/><div class="controls bullet"><span class="by">salimmadjd</span><span>|</span><a href="#38541154">prev</a><span>|</span><a href="#38541024">next</a><span>|</span><label class="collapse" for="c-38541617">[-]</label><label class="expand" for="c-38541617">[1 more]</label></div><br/><div class="children"><div class="content">Awni Hannun of Apple AI research team has a deep dive thread on X [0] with some additional info and answers some of the questions<p>[0] <a href="https:&#x2F;&#x2F;x.com&#x2F;awnihannun&#x2F;status&#x2F;1732184443451019431?s=46&amp;t=OMN5agtP4INL78CWEdABRw" rel="nofollow noreferrer">https:&#x2F;&#x2F;x.com&#x2F;awnihannun&#x2F;status&#x2F;1732184443451019431?s=46&amp;t=O...</a></div><br/></div></div><div id="38541024" class="c"><input type="checkbox" id="c-38541024" checked=""/><div class="controls bullet"><span class="by">amilios</span><span>|</span><a href="#38541617">prev</a><span>|</span><a href="#38541177">next</a><span>|</span><label class="collapse" for="c-38541024">[-]</label><label class="expand" for="c-38541024">[3 more]</label></div><br/><div class="children"><div class="content">It seems like it&#x27;s matching PyTorch&#x27;s API very closely, which is great. Part of me wishes they took it a step further and just made it completely API-compatible, such that code written for PyTorch could run out-of-the-box with MLX, that would be killer.</div><br/><div id="38541613" class="c"><input type="checkbox" id="c-38541613" checked=""/><div class="controls bullet"><span class="by">sgu999</span><span>|</span><a href="#38541024">parent</a><span>|</span><a href="#38541500">next</a><span>|</span><label class="collapse" for="c-38541613">[-]</label><label class="expand" for="c-38541613">[1 more]</label></div><br/><div class="children"><div class="content">Note that there is a Metal backend for PyTorch [0]. Sadly it doesn&#x27;t work well with codebases that didn&#x27;t account for it from the start...<p>[0] <a href="https:&#x2F;&#x2F;developer.apple.com&#x2F;metal&#x2F;pytorch&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;developer.apple.com&#x2F;metal&#x2F;pytorch&#x2F;</a></div><br/></div></div><div id="38541500" class="c"><input type="checkbox" id="c-38541500" checked=""/><div class="controls bullet"><span class="by">nikhil896</span><span>|</span><a href="#38541024">parent</a><span>|</span><a href="#38541613">prev</a><span>|</span><a href="#38541177">next</a><span>|</span><label class="collapse" for="c-38541500">[-]</label><label class="expand" for="c-38541500">[1 more]</label></div><br/><div class="children"><div class="content">&quot;import mlx as torch&quot;</div><br/></div></div></div></div><div id="38541177" class="c"><input type="checkbox" id="c-38541177" checked=""/><div class="controls bullet"><span class="by">skavi</span><span>|</span><a href="#38541024">prev</a><span>|</span><a href="#38540996">next</a><span>|</span><label class="collapse" for="c-38541177">[-]</label><label class="expand" for="c-38541177">[1 more]</label></div><br/><div class="children"><div class="content">Given the API is similar to existing libraries, I’m curious as to whether the performance is better with this one. And if so, what’s stopping existing libraries from being as fast. IIRC, PyTorch at least has a Metal backend.<p>The README mentions unified memory, but what stops other frameworks from modeling copies as no-ops? I wonder if MLX makes larger architectural decisions based on GPU CPU communication being cheap.</div><br/></div></div><div id="38540996" class="c"><input type="checkbox" id="c-38540996" checked=""/><div class="controls bullet"><span class="by">timeimp</span><span>|</span><a href="#38541177">prev</a><span>|</span><a href="#38540903">next</a><span>|</span><label class="collapse" for="c-38540996">[-]</label><label class="expand" for="c-38540996">[2 more]</label></div><br/><div class="children"><div class="content">&gt;MLX is an array framework for machine learning on Apple silicon, brought to you by Apple machine learning research.<p>Does this mean its from Apple directly (as part of the machine-learning engineering team)?</div><br/><div id="38541020" class="c"><input type="checkbox" id="c-38541020" checked=""/><div class="controls bullet"><span class="by">amilios</span><span>|</span><a href="#38540996">parent</a><span>|</span><a href="#38540903">next</a><span>|</span><label class="collapse" for="c-38541020">[-]</label><label class="expand" for="c-38541020">[1 more]</label></div><br/><div class="children"><div class="content">Yes, I believe so.</div><br/></div></div></div></div><div id="38540903" class="c"><input type="checkbox" id="c-38540903" checked=""/><div class="controls bullet"><span class="by">janalsncm</span><span>|</span><a href="#38540996">prev</a><span>|</span><a href="#38540630">next</a><span>|</span><label class="collapse" for="c-38540903">[-]</label><label class="expand" for="c-38540903">[1 more]</label></div><br/><div class="children"><div class="content">Going in I was really worried there would be a bunch of wonkiness with unique apis different from torch or tf. But it seems pretty close to torch, which is a pleasant surprise. No need to reinvent the wheel.</div><br/></div></div><div id="38540630" class="c"><input type="checkbox" id="c-38540630" checked=""/><div class="controls bullet"><span class="by">apstats</span><span>|</span><a href="#38540903">prev</a><span>|</span><label class="collapse" for="c-38540630">[-]</label><label class="expand" for="c-38540630">[1 more]</label></div><br/><div class="children"><div class="content">This is really cool. I wonder how long it will be till we have GPT-4 quality models that run locally (if we ever will). Would open up a lot of possibilities.</div><br/></div></div></div></div></div></div></div></body></html>