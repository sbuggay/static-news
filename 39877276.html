<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1711875653635" as="style"/><link rel="stylesheet" href="styles.css?v=1711875653635"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://smunshi.net/kolmogorov-complexity-and-compression-distance.html">Kolmogorov Complexity and Compression Distance</a> <span class="domain">(<a href="https://smunshi.net">smunshi.net</a>)</span></div><div class="subtext"><span>rgbimbochamp</span> | <span>85 comments</span></div><br/><div><div id="39877848" class="c"><input type="checkbox" id="c-39877848" checked=""/><div class="controls bullet"><span class="by">tromp</span><span>|</span><a href="#39877660">next</a><span>|</span><label class="collapse" for="c-39877848">[-]</label><label class="expand" for="c-39877848">[21 more]</label></div><br/><div class="children"><div class="content">&gt; let’s assume that there exists a universal language U<p>Why not specify it?<p>&gt; That gives us the true language-agnostic definition of Kolmogorov Complexity as follows:<p>Choosing the language of Turing Machines does not make the definition language agnostic.<p>Aiming for the simplest definition of description complexity, I instead based my definitions on the older computational model of lambda calculus in [1].<p>Unlike the assumed UTM above, the universal lambda machine is easy to describe in detail:<p><pre><code>    (λ 1 1) (λ λ λ 1 (λ λ λ λ 3 (λ 5 (3 (λ 2 (3 (λ λ 3 (λ 1 2 3))) (4 (λ 4 (λ 3 1 (2 1)))))) (1 (2 (λ 1 2)) (λ 4 (λ 4 (λ 2 (1 4))) 5)))) (3 3) 2) (λ 1 ((λ 1 1) (λ 1 1)))
</code></pre>
Furthermore, it allows almost identical definitions of various variations of descriptional complexity, namely<p>1) plain complexity<p>2) prefix complexity<p>3) monotone complexity<p>all of which have their application in Algorithmic Information Theory [2].<p>[1] <a href="https:&#x2F;&#x2F;gist.github.com&#x2F;tromp&#x2F;86b3184f852f65bfb814e3ab0987d861" rel="nofollow">https:&#x2F;&#x2F;gist.github.com&#x2F;tromp&#x2F;86b3184f852f65bfb814e3ab0987d8...</a><p>[2] <a href="https:&#x2F;&#x2F;homepages.cwi.nl&#x2F;~paulv&#x2F;kolmogorov.html" rel="nofollow">https:&#x2F;&#x2F;homepages.cwi.nl&#x2F;~paulv&#x2F;kolmogorov.html</a></div><br/><div id="39881793" class="c"><input type="checkbox" id="c-39881793" checked=""/><div class="controls bullet"><span class="by">asplake</span><span>|</span><a href="#39877848">parent</a><span>|</span><a href="#39879157">next</a><span>|</span><label class="collapse" for="c-39881793">[-]</label><label class="expand" for="c-39881793">[1 more]</label></div><br/><div class="children"><div class="content">&gt; let’s assume that there exists a universal language U such that it always gives us the shortest description length for all strings.<p>Read on a bit and it looks like proof by contradiction:<p>&gt; However, let’s bring back the paradox we discussed above. According to that paradox, U cannot exist or U cannot provide shorter descriptions than every arbitrary L.</div><br/></div></div><div id="39879157" class="c"><input type="checkbox" id="c-39879157" checked=""/><div class="controls bullet"><span class="by">canjobear</span><span>|</span><a href="#39877848">parent</a><span>|</span><a href="#39881793">prev</a><span>|</span><a href="#39877916">next</a><span>|</span><label class="collapse" for="c-39879157">[-]</label><label class="expand" for="c-39879157">[2 more]</label></div><br/><div class="children"><div class="content">The whole point of Kolmogorov complexity is that description lengths under different Turing-complete description languages (such as UTM and lambda calculus) are only different up to a constant that depends on the languages and not on the thing being described.</div><br/><div id="39880571" class="c"><input type="checkbox" id="c-39880571" checked=""/><div class="controls bullet"><span class="by">uoaei</span><span>|</span><a href="#39877848">root</a><span>|</span><a href="#39879157">parent</a><span>|</span><a href="#39877916">next</a><span>|</span><label class="collapse" for="c-39880571">[-]</label><label class="expand" for="c-39880571">[1 more]</label></div><br/><div class="children"><div class="content">The whole point of Kolmogorov complexity is that there exists some language for minimal description length of an arbitrary program and you compare optimal descriptions across languages. In other words, the point is to explicitly consider the choice of language as part of the encoding scheme that needs describing. That choice is included as part of the description whose length is being measured.</div><br/></div></div></div></div><div id="39877916" class="c"><input type="checkbox" id="c-39877916" checked=""/><div class="controls bullet"><span class="by">rhelz</span><span>|</span><a href="#39877848">parent</a><span>|</span><a href="#39879157">prev</a><span>|</span><a href="#39877660">next</a><span>|</span><label class="collapse" for="c-39877916">[-]</label><label class="expand" for="c-39877916">[17 more]</label></div><br/><div class="children"><div class="content">There is another, more insidious, problem with trying to give a language agnostic definition:  Different languages will have different symbols which are outputable.<p>If you have a Turing machine which can only print out binary digits, then it can&#x27;t print out a chinese character, no matter how long the input program is.<p>Yeah, you can do something like unicode, and associate a binary string with each chinese character--but printing out that binary string is not printing out the chinese character.  It&#x27;s printing out a binary string.<p>In particular, your lambda-calculus based turing machine cannot print out chinese characters.  It therefore cannot be used to define a <i>universal</i> complexity for any string.</div><br/><div id="39879649" class="c"><input type="checkbox" id="c-39879649" checked=""/><div class="controls bullet"><span class="by">AnotherGoodName</span><span>|</span><a href="#39877848">root</a><span>|</span><a href="#39877916">parent</a><span>|</span><a href="#39879189">next</a><span>|</span><label class="collapse" for="c-39879649">[-]</label><label class="expand" for="c-39879649">[7 more]</label></div><br/><div class="children"><div class="content">This is quite misguided as you seem to think the alphabet for Shannon entropy or Kolmogorov complexity is in any way what we think of as an alphabet.<p>Did you know the best compression methods out all have a variable length (measured in bits) alphabet? eg. Dynamic Markov Coding will start with just &#x27;0&#x27; and &#x27;1&#x27; and then predict the next bit but as it see&#x27;s more symbols it will extend this to single characters (so see &#x27;a&#x27; or &#x27;b&#x27; and predict the next bit). They&#x27;ll then continue as they learn more of the file and their alphabet will essentially include common pairwise letters, then words and entire common phrases.<p>This is actually a commonly missed aspect of Shannon entropy. A file of 0111101110111 repeated will give you a different result if you consider a 1 bit alphabet of 25% &#x27;0&#x27; and 75% &#x27;1&#x27; than a 4 bit alphabet of 100% &#x27;0111&#x27;. No one in the real world is using the character frequencies of english characters as a measure of Shannon entropy or Kolmogorov complexity. No algorithm expects that. They all work at the binary level and they will try to adjust the symbol lengths of the alphabet to common sequences to achieve the best result.<p>This is in fact the reason Kolmogorov complexity is used rather than Shannon entropy. Shannon entropy doesn&#x27;t tell you how to define an optimal alphabet. That part is actually undefinable. It just tells you what to do if you have that already. Kolmogorov complexity says more completely &#x27;find the optimal alphabet and the symbol probabilities and make a minimal sequence from that&#x27;.<p>Different human languages don&#x27;t figure into this at all and are completely irrelevant.</div><br/><div id="39879822" class="c"><input type="checkbox" id="c-39879822" checked=""/><div class="controls bullet"><span class="by">rhelz</span><span>|</span><a href="#39877848">root</a><span>|</span><a href="#39879649">parent</a><span>|</span><a href="#39879189">next</a><span>|</span><label class="collapse" for="c-39879822">[-]</label><label class="expand" for="c-39879822">[6 more]</label></div><br/><div class="children"><div class="content">&gt; Different human languages don&#x27;t figure into this at all and are completely irrelevant.<p>Back to basics:  A Turing machine is specified by a set of symbols it can read&#x2F;write to a tape, and a state machine matching current state and read symbol to next state and actions.<p>If that set of symbols is just {1,0}, then it absolutely, positively, cannot print out the string &quot;ABC&quot;.<p>&gt; the best compression methods out all have a variable length (measured in bits) alphabet.<p>This is a category error....if the compression algorithm reads and writes binary data, its alphabet is &quot;zero&quot; and &quot;one.&quot;  The symbols read and written by a Turing machine are atomic--they are not composed of any simpler parts.<p>Sure, external to the turning machine, you can adopt some conventions which map bit patterns to letters in a different alphabet.  But a binary Turing machine cannot print out those letters--it can only print out a string of 1&#x27;s and 0&#x27;s.<p>The mapping from strings in the binary language to letters in the target language <i>cannot</i> participate in the calculations for the complexity of a string in another language.  Because if it did, again, you could make the Kolmogorov complexity of any arbitrary string S you choose to be 0, because you could just say the null output maps to S.<p>This is a subtle problem, often glossed over or just missed entirely.  We are so used to encoding things in binary that it might not occur to us unless we think about it deeply.<p>Nevertheless, it is a real, genuine problem.</div><br/><div id="39882346" class="c"><input type="checkbox" id="c-39882346" checked=""/><div class="controls bullet"><span class="by">tromp</span><span>|</span><a href="#39877848">root</a><span>|</span><a href="#39879822">parent</a><span>|</span><a href="#39879927">next</a><span>|</span><label class="collapse" for="c-39882346">[-]</label><label class="expand" for="c-39882346">[1 more]</label></div><br/><div class="children"><div class="content">&gt; cannot print out the string &quot;ABC&quot;<p>When you write a program in any modern programming language to print &quot;ABC&quot;,
that program merely outputs the 3 bytes 01000001 01000010 01000011,
ASCII codes which your console window (not the program you wrote) decides to display graphically as those characters.<p>So any machine outputting bits can be said to print out &quot;ABC&quot; just as well.<p>Furthermore, your comment above was transmitted by your browser to Hacker News not as English characters but as those very bits, and everyone reading your comment was receiving those bits. The way that the browser decides to display those bits does not change their character.</div><br/></div></div><div id="39879927" class="c"><input type="checkbox" id="c-39879927" checked=""/><div class="controls bullet"><span class="by">AnotherGoodName</span><span>|</span><a href="#39877848">root</a><span>|</span><a href="#39879822">parent</a><span>|</span><a href="#39882346">prev</a><span>|</span><a href="#39879189">next</a><span>|</span><label class="collapse" for="c-39879927">[-]</label><label class="expand" for="c-39879927">[4 more]</label></div><br/><div class="children"><div class="content">Just because a turing machine prints out 0 and 1 at each step doesn&#x27;t mean the sequences to factor into the calculation of what to print out next can&#x27;t be longer binary sequences.<p>Pretty much all the best compression methods are language agnostic and work on bit wise sequences. They also pretty much all predict the next bit and feed that into an alogithmic encoder.<p>Eg. look up dynamic markov coding which is commonly used by Hutter prize winners. The paper is short and readable. They dynamically create a binary tree and binary sequences are seen so if the pattern &#x27;01101000 01100101&#x27; comes in it walks down the binary tree. It&#x27;ll probably predict the next bit as &#x27;0&#x27; as &#x27;0110100001100101&#x27; just so happened to be a common sequence in English that will likely have a next bit of &#x27;0&#x27; but the Dynamic Markov coding model has no idea of that. It just has binary sequences of bits and a prediction of the next bit given that.<p>Likewise it can continue reading the bits of the file in and walking down its binary tree where history of the next bit are stored in every node and it see&#x27;s &#x27;111001001011110110100000&#x27;. It makes the prediction of the next bit as a likely &#x27;1&#x27; that it feeds into an arithmetic coder that takes predictions and forms an optimally minimal bitsequence from that. That second binary sequence forms part of 你好.<p>In both cases the turing machine doesn&#x27;t care about that. It&#x27;s also just writing 1&#x27;s and 0&#x27;s as per a turing machine. Eventually those 1&#x27;s and 0&#x27;s form sequences that happen to map to characters in various languages but it doesn&#x27;t care about that.<p>&gt;The mapping from strings in the binary language to letters in the target language cannot participate in the calculations for the complexity of a string in another language. Because if it did, again, you could make the Kolmogorov complexity of any arbitrary string S you choose to be 0, because you could just say the null output maps to S.<p>One other thing to address here is that Kolmogorov complexity explicitly includes any dictionary you use in it&#x27;s calculation. A dictionary of the file you wish to compress would just blow out your Kolmogorov complexity to that size exactly. That&#x27;s why Kolmogorov complexity is an excellent tool. You explicitly cannot cheat in this way.</div><br/><div id="39880891" class="c"><input type="checkbox" id="c-39880891" checked=""/><div class="controls bullet"><span class="by">rhelz</span><span>|</span><a href="#39877848">root</a><span>|</span><a href="#39879927">parent</a><span>|</span><a href="#39879189">next</a><span>|</span><label class="collapse" for="c-39880891">[-]</label><label class="expand" for="c-39880891">[3 more]</label></div><br/><div class="children"><div class="content">&gt; the turing machine doesn&#x27;t care about that. It&#x27;s also just writing 1&#x27;s and 0&#x27;s as per a turing machine.<p>But a Turing machine does not have to be restricted to just printing out zeros and ones.  It can be any finite set of symbols. For example, he Soviets built a computer which used base 3--its symbol set was {-1, 0, 1}.  It didn&#x27;t have bits which could just store &quot;1&quot; or &quot;0&quot;, it had trits which could store &quot;-1&quot;, &quot;0&quot;, or &quot;1&quot;.<p>And <i>why</i> the soviets built such a computer is germane to Kolmogorov complexity <i>just because</i> you can make shorter strings in base 3 than you can in base 2.   The choice of symbol set absolutely impacts the length of strings and programs, and therefore impacts the Kolmogorov complexity of strings relative to the computer.<p>With this in mind, please consider three Turing Machines:  A, B, and C<p>The symbols A prints out on its tape are {&quot;A&quot;, &quot;B&quot;, &quot;C&quot;}<p>The symbols B prints out on its tape are {&quot;0&quot;, &quot;1&quot;}<p>The symbols C prints out on its tape are {&quot;0&quot;, &quot;1&quot;, &quot;A&quot;, &quot;B&quot;, &quot;C&quot;}<p>Now consider two strings:   &quot;1000001&quot; and &quot;A&quot;.  Turing machine B could print out &quot;1000001&quot;.  Turing machine A could print out &quot;A&quot;.<p>You might be tempted to equate &quot;1000001&quot; and &quot;A&quot;.  But consider the same two strings printed out by machine C:<p>&quot;1000001&quot; and &quot;A&quot;<p>Clearly, these are different strings.  If C printed out &quot;A&quot;, it did not print out &quot;1000001&quot;, and vice versa.<p>&gt; Kolmogorov complexity explicitly includes any dictionary you use in it&#x27;s calculation.<p>Sure, but on a binary turing machine, like Machine B above, that dictionary is not going to be matching between binary strings and, say Roman letters.  Its going to be mapping from one binary string to another binary string.<p>Using Machine C, you certainly could write a program which inputed &quot;1000001&quot; and output &quot;A&quot;.   But you absolutely, positively, cannot write such a program in either machines A or B. Machine A cannot print the string &quot;1000001&quot;.  And B cannot print the string &quot;A&quot;.<p>Different strings, different things.</div><br/><div id="39880987" class="c"><input type="checkbox" id="c-39880987" checked=""/><div class="controls bullet"><span class="by">AnotherGoodName</span><span>|</span><a href="#39877848">root</a><span>|</span><a href="#39880891">parent</a><span>|</span><a href="#39881992">next</a><span>|</span><label class="collapse" for="c-39880987">[-]</label><label class="expand" for="c-39880987">[1 more]</label></div><br/><div class="children"><div class="content">All of those examples are exactly equivalent and convertable but where you are confusing yourself is that you&#x27;re thinking of the differing states of a given n-ary system as having explicit symbols. It&#x27;s best to think of it as simply numeric. Binary 010 is 2 if i were to write in decimal. Ternary 020 is the number 6 if i were to write it in decimal. Etc.<p>Any actual symbol mapping to the numbers from an n-ary system to actual symbols like you are showing here is actually arbitrary and part of the calculation of space when measuring an algorithms Kolmogov complexity. The program size in kolmogorov complexity includes the dictionary of numerical to symbolic lookup which is what you are getting at here.</div><br/></div></div><div id="39881992" class="c"><input type="checkbox" id="c-39881992" checked=""/><div class="controls bullet"><span class="by">kaba0</span><span>|</span><a href="#39877848">root</a><span>|</span><a href="#39880891">parent</a><span>|</span><a href="#39880987">prev</a><span>|</span><a href="#39879189">next</a><span>|</span><label class="collapse" for="c-39881992">[-]</label><label class="expand" for="c-39881992">[1 more]</label></div><br/><div class="children"><div class="content">You can trivially convert any such Turing machine to another simply by adding n new states to it, that map a letter of the previous alphabet to the new’s.<p>With all due respect, you are misunderstanding something&#x2F;bring something up with no relevance to complexity.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="39879189" class="c"><input type="checkbox" id="c-39879189" checked=""/><div class="controls bullet"><span class="by">canjobear</span><span>|</span><a href="#39877848">root</a><span>|</span><a href="#39877916">parent</a><span>|</span><a href="#39879649">prev</a><span>|</span><a href="#39878820">next</a><span>|</span><label class="collapse" for="c-39879189">[-]</label><label class="expand" for="c-39879189">[2 more]</label></div><br/><div class="children"><div class="content">Why is this a problem? No information is lost when characters (or graphics) are encoded in binary.</div><br/><div id="39880006" class="c"><input type="checkbox" id="c-39880006" checked=""/><div class="controls bullet"><span class="by">rhelz</span><span>|</span><a href="#39877848">root</a><span>|</span><a href="#39879189">parent</a><span>|</span><a href="#39878820">next</a><span>|</span><label class="collapse" for="c-39880006">[-]</label><label class="expand" for="c-39880006">[1 more]</label></div><br/><div class="children"><div class="content">A turing machine is defined as a set of symbols which it can read&#x2F;write to the tape, and a state machine which maps the current symbol read to the next state and some actions.<p>The symbols of the Turing machine are <i>atomic</i>.  They are not composed of any simpler parts.  If one of the Turing machine&#x27;s symbol is the letter &quot;A&quot;, it&#x27;s the letter &quot;A&quot;.  It is not, say, the ascii code (1000001)<p>1000001 could be the Goedel number for &quot;A&quot;, but its not the symbol &quot;A&quot;.   The two strings &quot;A&quot; and &quot;1000001&quot; are two different strings.<p>Its a map-vs-territory kind of thing.  If you are really good at programming--which is to say, you are really good at Goedel mapping your problem to integers--you might, by years of long familiarity, just start thinking of them as one and the same, but they are not.<p>It might make it vivid to consider a turing machine whose symbols were {1, 0, A}.  Clearly, the string &quot;1000001&quot; and the string &quot;A&quot; are two different outputs for this turing machine.  The lengths  of the strings &quot;1000001&quot; and &quot;A&quot; are different.  They are composed of different symbols.  They are absolutely, positively, not the same string, so they are not the same thing.</div><br/></div></div></div></div><div id="39878820" class="c"><input type="checkbox" id="c-39878820" checked=""/><div class="controls bullet"><span class="by">mxkopy</span><span>|</span><a href="#39877848">root</a><span>|</span><a href="#39877916">parent</a><span>|</span><a href="#39879189">prev</a><span>|</span><a href="#39879445">next</a><span>|</span><label class="collapse" for="c-39878820">[-]</label><label class="expand" for="c-39878820">[5 more]</label></div><br/><div class="children"><div class="content">I feel like a conversion from binary strings to Unicode&#x2F;Chinese characters would be in PTIME, so adding a conversion machine would be a nonfactor for languages in most complexity classes.</div><br/><div id="39878954" class="c"><input type="checkbox" id="c-39878954" checked=""/><div class="controls bullet"><span class="by">smallnamespace</span><span>|</span><a href="#39877848">root</a><span>|</span><a href="#39878820">parent</a><span>|</span><a href="#39879445">next</a><span>|</span><label class="collapse" for="c-39878954">[-]</label><label class="expand" for="c-39878954">[4 more]</label></div><br/><div class="children"><div class="content">The stronger result here is that any sort of conversion you can explicitly specify can be turned into a program.<p>Since Kolmogorov Complexity is specified in terms of lengths of programs, that means the KC between two different pairs of encodings can differ at most by a constant amount (the size of the program that converts back and forth).<p>The above is a bit handwavey, there are details you can tighten up (Is it the program size or something smaller? The program length in <i>which</i> encoding?), but heuristically that&#x27;s why theorists can talk about &quot;the&quot; Kolmogorov complexity without getting bogged down in with pesky encoding details.<p>It&#x27;s also why we usually don&#x27;t worry too much about the fine details of Turing Machines (alphabet, etc.), since you can generally emulate one sort of Turing Machine pretty easily with a short program written on another.</div><br/><div id="39880080" class="c"><input type="checkbox" id="c-39880080" checked=""/><div class="controls bullet"><span class="by">rhelz</span><span>|</span><a href="#39877848">root</a><span>|</span><a href="#39878954">parent</a><span>|</span><a href="#39879445">next</a><span>|</span><label class="collapse" for="c-39880080">[-]</label><label class="expand" for="c-39880080">[3 more]</label></div><br/><div class="children"><div class="content">&gt; any sort of conversion you can explicitly specify can be turned into a program.<p>If your Turing machine can only print out zeros and ones, there&#x27;s no program which can get it to print out &quot;ABC&quot;.   So it <i>cannot</i> specify a conversion between a language whose symbols are {0,1} and a language whose symbols are {&quot;A&quot;,B&quot;,&quot;C&quot;}.<p>It could specify a mapping between one binary string and another binary string, but it can&#x27;t even print out &quot;ABC&quot; so how could it possibly specify a conversion?<p>This is elementary guys.</div><br/><div id="39880659" class="c"><input type="checkbox" id="c-39880659" checked=""/><div class="controls bullet"><span class="by">smallnamespace</span><span>|</span><a href="#39877848">root</a><span>|</span><a href="#39880080">parent</a><span>|</span><a href="#39880682">next</a><span>|</span><label class="collapse" for="c-39880659">[-]</label><label class="expand" for="c-39880659">[1 more]</label></div><br/><div class="children"><div class="content">You pick an obvious encoding (such as binary) yourself, in the same way your computer is not outputting some platonic ideal &quot;A&quot; but a series of electrical impulses that your monitor plus your eyes and brain interprets as &quot;A&quot;.<p>Sure, you can object that the encoding is &quot;outside&quot; the TM, but for the purposes of discussing complexity these objections are pretty trivial, again for the same reasons (whatever encoding you pick the conversion process is a program you can write down, and once you write it down it means the Kolmogorov Complexity is the same between different TMs up to the length of whatever encoding&#x2F;decoding program you come up with).<p>Put another way, a TM with alphabet is {0, 1} is technically not the same as the TM with alphabet {A, B}. But it&#x27;s obvious to <i>us</i> that the TMs are equivalent.</div><br/></div></div><div id="39880682" class="c"><input type="checkbox" id="c-39880682" checked=""/><div class="controls bullet"><span class="by">cscurmudgeon</span><span>|</span><a href="#39877848">root</a><span>|</span><a href="#39880080">parent</a><span>|</span><a href="#39880659">prev</a><span>|</span><a href="#39879445">next</a><span>|</span><label class="collapse" for="c-39880682">[-]</label><label class="expand" for="c-39880682">[1 more]</label></div><br/><div class="children"><div class="content">It is not an intractable problem as you believe it is.<p>E.g., make the machine print out pixel values for a large screen. The screen can display Chinese characters in canonical ways.</div><br/></div></div></div></div></div></div></div></div><div id="39879445" class="c"><input type="checkbox" id="c-39879445" checked=""/><div class="controls bullet"><span class="by">SimplyUnknown</span><span>|</span><a href="#39877848">root</a><span>|</span><a href="#39877916">parent</a><span>|</span><a href="#39878820">prev</a><span>|</span><a href="#39877660">next</a><span>|</span><label class="collapse" for="c-39879445">[-]</label><label class="expand" for="c-39879445">[2 more]</label></div><br/><div class="children"><div class="content">But Chinese (or mandarin) is not a context-free grammar whereas I believe that encoding a language on a turing machine implies a context-free grammar so this example doesn&#x27;t hold.</div><br/><div id="39880043" class="c"><input type="checkbox" id="c-39880043" checked=""/><div class="controls bullet"><span class="by">rhelz</span><span>|</span><a href="#39877848">root</a><span>|</span><a href="#39879445">parent</a><span>|</span><a href="#39877660">next</a><span>|</span><label class="collapse" for="c-39880043">[-]</label><label class="expand" for="c-39880043">[1 more]</label></div><br/><div class="children"><div class="content">Well, a couple of points:  its not obvious that Chinese doesn&#x27;t have a context-free grammar:  see the talk by David Branner:  &quot;The Grammar of Classical Chinese is Very Close to Being a Context-Free Grammar&quot;.<p>And a properly programmed turing machine can parse languages which are way more complex than context-free languages are.</div><br/></div></div></div></div></div></div></div></div><div id="39877660" class="c"><input type="checkbox" id="c-39877660" checked=""/><div class="controls bullet"><span class="by">arketyp</span><span>|</span><a href="#39877848">prev</a><span>|</span><a href="#39878452">next</a><span>|</span><label class="collapse" for="c-39877660">[-]</label><label class="expand" for="c-39877660">[12 more]</label></div><br/><div class="children"><div class="content">Richard von Mises (brother of the economist) formulated a definition of randomness as a sequence of data that, were you a gambler, you cannot by any strategy make money on betting on the outcomes. This was before computational calculus and was later developed by Kolmogorov and others in algorithmic complexity. The modern variation would be (Wiki) &quot;considering a finite sequence random (with respect to a class of computing systems) if any program that can generate the sequence is at least as long as the sequence itself&quot;.</div><br/><div id="39878135" class="c"><input type="checkbox" id="c-39878135" checked=""/><div class="controls bullet"><span class="by">n4r9</span><span>|</span><a href="#39877660">parent</a><span>|</span><a href="#39878485">next</a><span>|</span><label class="collapse" for="c-39878135">[-]</label><label class="expand" for="c-39878135">[4 more]</label></div><br/><div class="children"><div class="content">&gt; you cannot by any strategy make money on betting on the outcomes<p>What does &quot;strategy&quot; mean here? I might just happen to have a strategy which involves betting on the exact sequence of heads and tails in a given sequence. The analogy in terms of languages is that my language might just happen to have a short keyword that represents a given sequence of heads and tails.<p>I don&#x27;t know much about Kolmogorow complexity so I&#x27;m certainly missing something here. Potentially there is a subtle clause in the technical definition that doesn&#x27;t make it through to these articles.</div><br/><div id="39880931" class="c"><input type="checkbox" id="c-39880931" checked=""/><div class="controls bullet"><span class="by">inimino</span><span>|</span><a href="#39877660">root</a><span>|</span><a href="#39878135">parent</a><span>|</span><a href="#39879202">next</a><span>|</span><label class="collapse" for="c-39880931">[-]</label><label class="expand" for="c-39880931">[1 more]</label></div><br/><div class="children"><div class="content">The idea is that you bet before the sequence is known. Nowadays we would say it is the distribution (or the process producing the random sequences) that can be truly random or not, and we recognize that saying &quot;sequence [...] is random&quot; is incoherent, same as the joke of the random int set to 4 with a comment in the source code that it was chosen by fair dice roll.<p>If you know everything about the process and still can&#x27;t beat chance at predicting it, that&#x27;s the quality we are after. In this definition &quot;random&quot; just means unpredictable, which is another way to explain why it can only be a meaningful distinction when you don&#x27;t yet know the result.</div><br/></div></div><div id="39879202" class="c"><input type="checkbox" id="c-39879202" checked=""/><div class="controls bullet"><span class="by">canjobear</span><span>|</span><a href="#39877660">root</a><span>|</span><a href="#39878135">parent</a><span>|</span><a href="#39880931">prev</a><span>|</span><a href="#39878245">next</a><span>|</span><label class="collapse" for="c-39879202">[-]</label><label class="expand" for="c-39879202">[1 more]</label></div><br/><div class="children"><div class="content">&gt; What does &quot;strategy&quot; mean here?<p>Any function that outputs bets.</div><br/></div></div><div id="39878245" class="c"><input type="checkbox" id="c-39878245" checked=""/><div class="controls bullet"><span class="by">PartiallyTyped</span><span>|</span><a href="#39877660">root</a><span>|</span><a href="#39878135">parent</a><span>|</span><a href="#39879202">prev</a><span>|</span><a href="#39878485">next</a><span>|</span><label class="collapse" for="c-39878245">[-]</label><label class="expand" for="c-39878245">[1 more]</label></div><br/><div class="children"><div class="content">&gt; What does &quot;strategy&quot; mean here? I might just happen to have a strategy which involves betting on the exact sequence of heads and tails in a given sequence.<p>That&#x27;s a very narrow program.<p>&gt; The analogy in terms of languages is that my language might just happen to have a short keyword that represents a given sequence of heads and tails.<p>The sequence still needs to be generated &quot;somehow&quot;. Either by executing the program and producing the sequence, or by explicitly stating it. Even if you have it &quot;cached&quot; and &quot;represented&quot; in your language, you still need to generate the sequence. The resources spent here is the Kolmogorov complexity.<p>The easiest way to expand your little program is to say that you have a seed s.t. any consecutive generation results in a consecutive sequence that matches up to the period of the generator. Now it is more generic, but has a period. You can then expand this to accept multiple seeds and once it has reached a period, to simply take the next seed.<p>Should this sequence be finite, you are in luck. Your program can have length O(generator + N&#x2F;P) where N is length of sequence, and P is the period of your RNG.<p>All this is is just compression which plays into the whole Kolmogorov complexity.</div><br/></div></div></div></div><div id="39878485" class="c"><input type="checkbox" id="c-39878485" checked=""/><div class="controls bullet"><span class="by">a_wild_dandan</span><span>|</span><a href="#39877660">parent</a><span>|</span><a href="#39878135">prev</a><span>|</span><a href="#39879246">next</a><span>|</span><label class="collapse" for="c-39878485">[-]</label><label class="expand" for="c-39878485">[3 more]</label></div><br/><div class="children"><div class="content">Doesn&#x27;t the modern variation break for programs with lossless encoding&#x2F;decoding? At least, for sufficiently long sequences? A Huffman&#x2F;byte-pair encoding would shred any trillion-bit+ sequence, for instance. But I intuitively expect many random trillion-bit sequences exist.</div><br/><div id="39878597" class="c"><input type="checkbox" id="c-39878597" checked=""/><div class="controls bullet"><span class="by">chaboud</span><span>|</span><a href="#39877660">root</a><span>|</span><a href="#39878485">parent</a><span>|</span><a href="#39878861">next</a><span>|</span><label class="collapse" for="c-39878597">[-]</label><label class="expand" for="c-39878597">[1 more]</label></div><br/><div class="children"><div class="content">There is no encoding that would shred &quot;any&quot; (read: every) trillion bit sequence.  If that were true, some fundamentals of information theory and compressibility would break down.<p>Lossless encoding works by taking advantage of the more commonly observed sequences of data having lower information entropy.  For things like audio encoding, where discontinuous sequences aren&#x27;t naturally observed (or pleasing to listen to), lossless encoding has a lot to work with.</div><br/></div></div><div id="39878861" class="c"><input type="checkbox" id="c-39878861" checked=""/><div class="controls bullet"><span class="by">mxkopy</span><span>|</span><a href="#39877660">root</a><span>|</span><a href="#39878485">parent</a><span>|</span><a href="#39878597">prev</a><span>|</span><a href="#39879246">next</a><span>|</span><label class="collapse" for="c-39878861">[-]</label><label class="expand" for="c-39878861">[1 more]</label></div><br/><div class="children"><div class="content">For any fixed compression scheme, there is an input string that is actually lengthened by it rather than shortened.<p>However Huffman isn’t a fixed compression scheme since it makes a different frequency tree for different corpora.</div><br/></div></div></div></div><div id="39879246" class="c"><input type="checkbox" id="c-39879246" checked=""/><div class="controls bullet"><span class="by">canjobear</span><span>|</span><a href="#39877660">parent</a><span>|</span><a href="#39878485">prev</a><span>|</span><a href="#39880022">next</a><span>|</span><label class="collapse" for="c-39879246">[-]</label><label class="expand" for="c-39879246">[2 more]</label></div><br/><div class="children"><div class="content">Do you have a citation? I didn’t know the idea went back that far.</div><br/><div id="39881729" class="c"><input type="checkbox" id="c-39881729" checked=""/><div class="controls bullet"><span class="by">arketyp</span><span>|</span><a href="#39877660">root</a><span>|</span><a href="#39879246">parent</a><span>|</span><a href="#39880022">next</a><span>|</span><label class="collapse" for="c-39881729">[-]</label><label class="expand" for="c-39881729">[1 more]</label></div><br/><div class="children"><div class="content">Thanks, I had to dig. I read about it in [1]. Mises was concerned about the formalization of probability theory. It seems the idea appears at least as early as in his 1919 paper [2].<p>[1] An Introduction to Kolmogorov Complexity and Its Applications, M. Li &amp; P. Vitnányi<p>[2] Grundlagen der Wahrscheinlichkeitsrechnung, R. von Mises</div><br/></div></div></div></div><div id="39880022" class="c"><input type="checkbox" id="c-39880022" checked=""/><div class="controls bullet"><span class="by">Ar-Curunir</span><span>|</span><a href="#39877660">parent</a><span>|</span><a href="#39879246">prev</a><span>|</span><a href="#39878452">next</a><span>|</span><label class="collapse" for="c-39880022">[-]</label><label class="expand" for="c-39880022">[2 more]</label></div><br/><div class="children"><div class="content">The two definitions say different things. What von Mises said is closer to cryptographic definitions of pseudorandomness, and in particular to next-bit unpredictability.</div><br/><div id="39881755" class="c"><input type="checkbox" id="c-39881755" checked=""/><div class="controls bullet"><span class="by">arketyp</span><span>|</span><a href="#39877660">root</a><span>|</span><a href="#39880022">parent</a><span>|</span><a href="#39878452">next</a><span>|</span><label class="collapse" for="c-39881755">[-]</label><label class="expand" for="c-39881755">[1 more]</label></div><br/><div class="children"><div class="content">Yes, I agree. But I talked about an idea development and said variation, not necessarily addressing the same thing. The headline would be algorithmically random sequence.<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Algorithmically_random_sequence" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Algorithmically_random_sequenc...</a></div><br/></div></div></div></div></div></div><div id="39878452" class="c"><input type="checkbox" id="c-39878452" checked=""/><div class="controls bullet"><span class="by">anonzzzies</span><span>|</span><a href="#39877660">prev</a><span>|</span><a href="#39877627">next</a><span>|</span><label class="collapse" for="c-39878452">[-]</label><label class="expand" for="c-39878452">[2 more]</label></div><br/><div class="children"><div class="content">Kolmogorov complexity is a lovely subject and one of the more influential ones in my life.<p>THE book <a href="https:&#x2F;&#x2F;link.springer.com&#x2F;book&#x2F;10.1007&#x2F;978-0-387-49820-1" rel="nofollow">https:&#x2F;&#x2F;link.springer.com&#x2F;book&#x2F;10.1007&#x2F;978-0-387-49820-1</a> is absolutely a thing to read. It was for me 30 years ago and it aged well.</div><br/><div id="39878657" class="c"><input type="checkbox" id="c-39878657" checked=""/><div class="controls bullet"><span class="by">derbOac</span><span>|</span><a href="#39878452">parent</a><span>|</span><a href="#39877627">next</a><span>|</span><label class="collapse" for="c-39878657">[-]</label><label class="expand" for="c-39878657">[1 more]</label></div><br/><div class="children"><div class="content">That is a great book on the subject — the authors have published some important work in this area in papers as well.</div><br/></div></div></div></div><div id="39877627" class="c"><input type="checkbox" id="c-39877627" checked=""/><div class="controls bullet"><span class="by">wood_spirit</span><span>|</span><a href="#39878452">prev</a><span>|</span><a href="#39881783">next</a><span>|</span><label class="collapse" for="c-39877627">[-]</label><label class="expand" for="c-39877627">[3 more]</label></div><br/><div class="children"><div class="content">An excellent rabbit hole to dive into is the equivalence of compression and general AI.  Every programmer should make a compressor (and, separately, a ray tracer)!<p>See <a href="http:&#x2F;&#x2F;prize.hutter1.net&#x2F;" rel="nofollow">http:&#x2F;&#x2F;prize.hutter1.net&#x2F;</a></div><br/><div id="39877831" class="c"><input type="checkbox" id="c-39877831" checked=""/><div class="controls bullet"><span class="by">avmich</span><span>|</span><a href="#39877627">parent</a><span>|</span><a href="#39881070">next</a><span>|</span><label class="collapse" for="c-39877831">[-]</label><label class="expand" for="c-39877831">[1 more]</label></div><br/><div class="children"><div class="content">Some examples for a particular algorithm: <a href="https:&#x2F;&#x2F;rosettacode.org&#x2F;wiki&#x2F;LZW_compression" rel="nofollow">https:&#x2F;&#x2F;rosettacode.org&#x2F;wiki&#x2F;LZW_compression</a></div><br/></div></div><div id="39881070" class="c"><input type="checkbox" id="c-39881070" checked=""/><div class="controls bullet"><span class="by">pixelpoet</span><span>|</span><a href="#39877627">parent</a><span>|</span><a href="#39877831">prev</a><span>|</span><a href="#39881783">next</a><span>|</span><label class="collapse" for="c-39881070">[-]</label><label class="expand" for="c-39881070">[1 more]</label></div><br/><div class="children"><div class="content">Definitely with you on the ray&#x2F;path tracer :)</div><br/></div></div></div></div><div id="39878155" class="c"><input type="checkbox" id="c-39878155" checked=""/><div class="controls bullet"><span class="by">alfanick</span><span>|</span><a href="#39881783">prev</a><span>|</span><a href="#39878433">next</a><span>|</span><label class="collapse" for="c-39878155">[-]</label><label class="expand" for="c-39878155">[3 more]</label></div><br/><div class="children"><div class="content">A side question: is this taught in CS curriculum you know? It was at my uni (fairly good one, in a minor European country), and this experience biases me because I assume every CS knows Kolmogorov complexity.</div><br/><div id="39879967" class="c"><input type="checkbox" id="c-39879967" checked=""/><div class="controls bullet"><span class="by">sunshowers</span><span>|</span><a href="#39878155">parent</a><span>|</span><a href="#39879447">next</a><span>|</span><label class="collapse" for="c-39879967">[-]</label><label class="expand" for="c-39879967">[1 more]</label></div><br/><div class="children"><div class="content">At my university (IIT, top school in India and well-known around the world) this was covered in an elective you could take, not part of the core CS curriculum.</div><br/></div></div><div id="39879447" class="c"><input type="checkbox" id="c-39879447" checked=""/><div class="controls bullet"><span class="by">quibono</span><span>|</span><a href="#39878155">parent</a><span>|</span><a href="#39879967">prev</a><span>|</span><a href="#39878433">next</a><span>|</span><label class="collapse" for="c-39879447">[-]</label><label class="expand" for="c-39879447">[1 more]</label></div><br/><div class="children"><div class="content">Yes, at least in the UK. From working through some US university curricula - it&#x27;s also present there as well.</div><br/></div></div></div></div><div id="39878433" class="c"><input type="checkbox" id="c-39878433" checked=""/><div class="controls bullet"><span class="by">davesque</span><span>|</span><a href="#39878155">prev</a><span>|</span><a href="#39877480">next</a><span>|</span><label class="collapse" for="c-39878433">[-]</label><label class="expand" for="c-39878433">[4 more]</label></div><br/><div class="children"><div class="content">Something I&#x27;ve always noticed with the notion of Kolmogorov complexity is that the question of determining the lowest level of computation is problematic.<p>For example, in the article, the author first defines the basic idea of KC. But then they correctly point out that the basic idea depends very much on the exact language that is chosen. So they describe how theorists have defined the notion of universal computation. But even this adjustment doesn&#x27;t seem to escape the fact the we still depend on a system of mathematical symbols to describe the theory. And the notion of a Turing machine itself depends on other abstract concepts such as time and space, each with their own inherent, conceptual complexity. What sorts of minds (i.e. brains) are required to make sense out of the theory and what physical system is required for them to operate correctly? If the definition of KC includes a notion of how complex the Turing machine is that is required to compute a string, then the further down you go, the less the difference in complexity should be between any one string and another. After all, they all exist in the same universe!<p>I guess it just goes to show how much the idea of KC lives in the realm of theory. As soon as you pose the question of complexity so abstractly, you invite in all kinds of theoretical considerations that make the meaning more slippery. That&#x27;s why KC really doesn&#x27;t deserve to be compared to Shannon entropy as it often is.<p>But let me draw a comparison anyway like I said you shouldn&#x27;t! Because Alice from the article could also have made a strong argument against Bob by just pointing out that the Shannon entropy of his string was lower, which is very relevant in terms of the number of heads or tails and the likelihood of seeing a particular count of them.</div><br/><div id="39878776" class="c"><input type="checkbox" id="c-39878776" checked=""/><div class="controls bullet"><span class="by">veerd</span><span>|</span><a href="#39878433">parent</a><span>|</span><a href="#39879518">next</a><span>|</span><label class="collapse" for="c-39878776">[-]</label><label class="expand" for="c-39878776">[1 more]</label></div><br/><div class="children"><div class="content">1. Choice of language only matters up to an additive constant (e.g. you could just write a simulator so language A can run language B).<p>2. If you want something with less physical grounding, you could use lambda calculus instead of Turing machines.<p>3. Kolmogorov Complexity and Shannon Entropy are compared with one another because they both are talking about the same thing: optimal compression. Kolmogorov Complexity talks about the compressibility of individual objects and Shannon Entropy talks about compressibility of streams of i.i.d. random variables.</div><br/></div></div><div id="39879518" class="c"><input type="checkbox" id="c-39879518" checked=""/><div class="controls bullet"><span class="by">AnotherGoodName</span><span>|</span><a href="#39878433">parent</a><span>|</span><a href="#39878776">prev</a><span>|</span><a href="#39882062">next</a><span>|</span><label class="collapse" for="c-39879518">[-]</label><label class="expand" for="c-39879518">[1 more]</label></div><br/><div class="children"><div class="content">Shannon entropy and Kolmogorov complexity are absolutely literally the same thing though! They are both purely theoretical and you cannot calculate the minimum Shannon entropy any better than you can calculate the Kolmogorov complexity. In fact if you could calculate one you could calculate the other trivially but we don&#x27;t have a way to do that.<p>For those now thinking about how to calculate Shannon entropy using the defined formula what are you using for the symbols? If you used one bit symbols of &#x27;1&#x27; and &#x27;0&#x27; and a probability of each appearing a file that was just 11101110... repeating would you would find a different Shannon entropy to someone using 4 bit symbols. Shannon entropy is literally uncomputable  in the real world. You can only compute it if you are given a fixed alphabet and frequencies but in the real world the optimal alphabet for a given file to calculate the minimum Shannon entropy is actually unknowable.<p>That&#x27;s where Kolmogorov complexity comes in. It states that &quot;well we don&#x27;t actually have a way to define the alphabet in Shannon entropy in the real world but if we pretend we have a system (the universal computation) we could calculate it&quot;. They then add in the size of the program length that does the calculation as well to prevent cheating by having a language that has a dictionary specific to the thing to encode and call that Kolmogorov complexity. But that&#x27;s it. They are literally the same thing in essence.<p>Kolmogorov complexity is in fact better than Shannon entropy for real world usage. It&#x27;s every bit as computable in the real world (ie. not at all but at the very least you can do the best compression you can and make a guess!) but it at least states that upfront.<p>For anyone wanting to claim that they had a CS assignment to calculate Shannon entropy and it&#x27;s totally computable your teacher should probably have explained that the symbol frequencies for the alphabet given aren&#x27;t actually computable like that in the real world as the optimal symbol lengths themselves aren&#x27;t actually computable. You cannot in the real world just say &quot;compute the Shannon entropy of an alphabet with two symbols - B 30% and A 70%&quot; because you don&#x27;t actually know if B and A are the optimal alphabet to define to minimize Shannon entropy. BBBAAAAAAA repeated has no entropy but it fits the definition of the question given and would give you a different result.</div><br/></div></div></div></div><div id="39877480" class="c"><input type="checkbox" id="c-39877480" checked=""/><div class="controls bullet"><span class="by">causal</span><span>|</span><a href="#39878433">prev</a><span>|</span><a href="#39877635">next</a><span>|</span><label class="collapse" for="c-39877480">[-]</label><label class="expand" for="c-39877480">[11 more]</label></div><br/><div class="children"><div class="content">Confused how the interesting number paradox proves KC cannot be computed.</div><br/><div id="39877707" class="c"><input type="checkbox" id="c-39877707" checked=""/><div class="controls bullet"><span class="by">Opocio</span><span>|</span><a href="#39877480">parent</a><span>|</span><a href="#39877584">next</a><span>|</span><label class="collapse" for="c-39877707">[-]</label><label class="expand" for="c-39877707">[2 more]</label></div><br/><div class="children"><div class="content">Me neither.<p>But how I see it is that for solving KC in full generality you&#x27;ll have to:<p>- Start with the program that explicitly returns the original string. Let&#x27;s say it has length N
- run all possible programs that are shorter than N (just try all combinations of characters)
- look at the results and pick the shortest program that compiles and outputs the original string<p>The problem there is that you have to wait for all programs to end, and you don&#x27;t know if they will end or not. So you have a problem that&#x27;s equivalent to the halting problem (and that&#x27;s not solvable) (and the halting problem is loosely related to the interesting number problem).<p>(This is not a proof and I don&#x27;t have a background in the field btw)</div><br/><div id="39878619" class="c"><input type="checkbox" id="c-39878619" checked=""/><div class="controls bullet"><span class="by">causal</span><span>|</span><a href="#39877480">root</a><span>|</span><a href="#39877707">parent</a><span>|</span><a href="#39877584">next</a><span>|</span><label class="collapse" for="c-39878619">[-]</label><label class="expand" for="c-39878619">[1 more]</label></div><br/><div class="children"><div class="content">That intuitively makes sense to me.</div><br/></div></div></div></div><div id="39877584" class="c"><input type="checkbox" id="c-39877584" checked=""/><div class="controls bullet"><span class="by">srcreigh</span><span>|</span><a href="#39877480">parent</a><span>|</span><a href="#39877707">prev</a><span>|</span><a href="#39877741">next</a><span>|</span><label class="collapse" for="c-39877584">[-]</label><label class="expand" for="c-39877584">[4 more]</label></div><br/><div class="children"><div class="content">The author is referring to something called Chaitin incompleteness.<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Kolmogorov_complexity#Chaitin&#x27;s_incompleteness_theorem" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Kolmogorov_complexity#Chaitin&#x27;...</a><p>Of course trivially some KC can be proven, ex a language with 1 or 0 characters that is interpreted to a specific string. Or to prove KC(x) where the compressed value has length N and you can list out all the results for all strings of length less than N, and they don&#x27;t equal x, proves KC(x)=N.<p>The interesting number paradox (Berry&#x27;s paradox) is more related to Chaitin incompleteness.<p>Basically, given a language there’s some code which enumerates proofs that KC of a string is more than some constant L, and returns the first one it finds.<p>If the constant L is large enough, it becomes larger than the entire proof generating code. So the proof generating code will never find a proof of any KC larger than L.<p>It&#x27;s interesting to think about that the language gets more complex, proofs for larger strings become possible. And what it would mean for the languages to keep getting more complex indefinitely.<p>it&#x27;s a similar train of thought to busy beaver numbers and how systems of logic (PA,ZFC) become independent to values like BB(745), and what it could mean to have more and more advanced types of logic which don&#x27;t become independent until some high target n.</div><br/><div id="39878599" class="c"><input type="checkbox" id="c-39878599" checked=""/><div class="controls bullet"><span class="by">causal</span><span>|</span><a href="#39877480">root</a><span>|</span><a href="#39877584">parent</a><span>|</span><a href="#39877741">next</a><span>|</span><label class="collapse" for="c-39878599">[-]</label><label class="expand" for="c-39878599">[3 more]</label></div><br/><div class="children"><div class="content">This seems to assume that KC can be infinite. That must have been proven at some point? Otherwise it may be that there is some upper-bound for L which happens to also be the KC for a KC-computer.</div><br/><div id="39882420" class="c"><input type="checkbox" id="c-39882420" checked=""/><div class="controls bullet"><span class="by">tromp</span><span>|</span><a href="#39877480">root</a><span>|</span><a href="#39878599">parent</a><span>|</span><a href="#39879276">next</a><span>|</span><label class="collapse" for="c-39882420">[-]</label><label class="expand" for="c-39882420">[1 more]</label></div><br/><div class="children"><div class="content">KC(x) is always finite for any finite x. What we can say instead is that KC is unbounded. I.e. there is no finite bound on the value of KC(x).</div><br/></div></div><div id="39879276" class="c"><input type="checkbox" id="c-39879276" checked=""/><div class="controls bullet"><span class="by">srcreigh</span><span>|</span><a href="#39877480">root</a><span>|</span><a href="#39878599">parent</a><span>|</span><a href="#39882420">prev</a><span>|</span><a href="#39877741">next</a><span>|</span><label class="collapse" for="c-39879276">[-]</label><label class="expand" for="c-39879276">[1 more]</label></div><br/><div class="children"><div class="content">yes, it’s a pigeonhole principle argument. A bit tricky to actually enumerate everything. Imagine KC had a limit k. Then there’s a fixed number of strings that can be compressed to k characters. so considering how there’s an infinite number of strings of length greater than k, they can’t all be compressed to be at most k. Therefore KC has no limit</div><br/></div></div></div></div></div></div><div id="39877741" class="c"><input type="checkbox" id="c-39877741" checked=""/><div class="controls bullet"><span class="by">nyrikki</span><span>|</span><a href="#39877480">parent</a><span>|</span><a href="#39877584">prev</a><span>|</span><a href="#39877768">next</a><span>|</span><label class="collapse" for="c-39877741">[-]</label><label class="expand" for="c-39877741">[1 more]</label></div><br/><div class="children"><div class="content">Impredicativity is the property you may want to dig into for formal proofs on why self references can be problematic.<p>There is an important difference between semantically complete and syntactically complete that may cause some barriers.<p>Gödels completeness theorem is about semantic completeness while his incompleteness theorems are about syntactic completeness.<p>From Wikipedia:
&gt; A formal system is syntactically complete if and only if no unprovable sentence can be added to it without introducing an inconsistency.<p>&#x27;This statement is false&#x27;, which Gödel mapped to natural numbers is an example of that inconsistency.<p>If KC was computable, there would be an infinity of paradoxes like the interesting number paradox.<p>The Berry paradox that is linked to  in the INP link in the page has a subheading that relates it to KC computability.<p><a href="https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Berry_paradox" rel="nofollow">https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Berry_paradox</a></div><br/></div></div><div id="39877768" class="c"><input type="checkbox" id="c-39877768" checked=""/><div class="controls bullet"><span class="by">explaininjs</span><span>|</span><a href="#39877480">parent</a><span>|</span><a href="#39877741">prev</a><span>|</span><a href="#39877635">next</a><span>|</span><label class="collapse" for="c-39877768">[-]</label><label class="expand" for="c-39877768">[3 more]</label></div><br/><div class="children"><div class="content">Similar to how the interesting number paradox relies on a &quot;shortcut statement&quot; to force-up the number of non-interest, If Kolmogorov complexity were computable you could create a &quot;shortcut program&quot; to force-down the shortest length of the program:<p>Given: TM length of a JS runtime is 1,000,000 cells.<p>Assume: KC is computable, and TM length of a `function KolmoglorovComplexity(string s)` is 4,000,000 cells.<p>Known: KC&#x27;s of values grow infinitely large - only 2^n-1 possible values can ever be encoded by n bits.<p>Take: function Shortcut() { for (const s in generateEveryStringFromShortestUp()) { if ( KolomoglorovComplexity(s &gt; 10,000,000) ) return s } }<p>You see that the Shortcut function is encoded in 5,000,135 cells (plus that string generator, but that&#x27;s small&#x2F;constant), but it computes a value of arbitrarily large complexity (rather, one cell increase in the program length causes 10x increase in the complexity). A contradiction.</div><br/><div id="39878504" class="c"><input type="checkbox" id="c-39878504" checked=""/><div class="controls bullet"><span class="by">causal</span><span>|</span><a href="#39877480">root</a><span>|</span><a href="#39877768">parent</a><span>|</span><a href="#39877635">next</a><span>|</span><label class="collapse" for="c-39878504">[-]</label><label class="expand" for="c-39878504">[2 more]</label></div><br/><div class="children"><div class="content">Still confused. What is contradictory about a simple program computing a more complex program? Randomly generating a more complex program does not make the complex program reducible to a random string generator.</div><br/><div id="39879629" class="c"><input type="checkbox" id="c-39879629" checked=""/><div class="controls bullet"><span class="by">basil-rash</span><span>|</span><a href="#39877480">root</a><span>|</span><a href="#39878504">parent</a><span>|</span><a href="#39877635">next</a><span>|</span><label class="collapse" for="c-39879629">[-]</label><label class="expand" for="c-39879629">[1 more]</label></div><br/><div class="children"><div class="content">The complexity cannot be over 10,000,000 if that simple program generated it. That is the precise definition of complexity.<p>I don’t understand what you mean by reducibility to random strings, randomness has precisely nothing to do with complexity, even if they do tend to go together.</div><br/></div></div></div></div></div></div></div></div><div id="39877635" class="c"><input type="checkbox" id="c-39877635" checked=""/><div class="controls bullet"><span class="by">JDEW</span><span>|</span><a href="#39877480">prev</a><span>|</span><a href="#39877836">next</a><span>|</span><label class="collapse" for="c-39877635">[-]</label><label class="expand" for="c-39877635">[1 more]</label></div><br/><div class="children"><div class="content">&gt; It has been demonstrated that KC(x), can be reasonably estimated by the number of bits required to encode x using a compressor C (such as gzip)<p>Talk about a cliffhanger :)<p>Using [0] you get 32B for Alice and 40B for Bob.<p>[0] It has been demonstrated that KC(x), can be reasonably estimated by the number of bits required to encode x using a compressor C (such as gzip)</div><br/></div></div><div id="39877836" class="c"><input type="checkbox" id="c-39877836" checked=""/><div class="controls bullet"><span class="by">mojomark</span><span>|</span><a href="#39877635">prev</a><span>|</span><a href="#39877644">next</a><span>|</span><label class="collapse" for="c-39877836">[-]</label><label class="expand" for="c-39877836">[4 more]</label></div><br/><div class="children"><div class="content">I&#x27;m going to keep reading (because I love the KC topic), but I&#x27;d appreciate anyone confirming if the following are errors in this article:<p>1.) Conflating usage of the term &quot;random&quot; and &quot;complexity&quot;. After all, a set of &quot;randomly&quot; drawn sample permutations from an alphabet are all equally likely. However, their &quot;complexity&quot; may differ, which is basically the point of the article, but the term more or less &quot;random&quot; keeps being used to refer to permutations with more or less &quot;complexity&quot;, which I think is probably going to perpetuate confusion on this topic.<p>2.) From the article: &quot;Moreover, a string cannot be compressed if its KC(x)≥|x|&quot;. Shouldn&#x27;t the expression accompanying this statement be KC(x)=|x| ?</div><br/><div id="39877944" class="c"><input type="checkbox" id="c-39877944" checked=""/><div class="controls bullet"><span class="by">tromp</span><span>|</span><a href="#39877836">parent</a><span>|</span><a href="#39877940">next</a><span>|</span><label class="collapse" for="c-39877944">[-]</label><label class="expand" for="c-39877944">[1 more]</label></div><br/><div class="children"><div class="content">Regarding point 1), one can easily show that with probability &gt;= 1 - 2^{-k}, a randomly chosen bitstring x of length n must satisfy KC(x) &gt;= n-k. After all, there are only 1+2+... 2^{n-k-1} = 2^{n-k}-1 shorter descriptions.
So highly compressible strings are highly unlikely.<p>Regarding 2), No, most strings x do not satisfy KC(x) = |x|, since you need to use some bits to specify that you&#x27;re giving x literally. See the first theorem of [1].<p>[1] <a href="https:&#x2F;&#x2F;gist.github.com&#x2F;tromp&#x2F;86b3184f852f65bfb814e3ab0987d861#theorems-concretely" rel="nofollow">https:&#x2F;&#x2F;gist.github.com&#x2F;tromp&#x2F;86b3184f852f65bfb814e3ab0987d8...</a></div><br/></div></div><div id="39877975" class="c"><input type="checkbox" id="c-39877975" checked=""/><div class="controls bullet"><span class="by">rhelz</span><span>|</span><a href="#39877836">parent</a><span>|</span><a href="#39877940">prev</a><span>|</span><a href="#39877644">next</a><span>|</span><label class="collapse" for="c-39877975">[-]</label><label class="expand" for="c-39877975">[1 more]</label></div><br/><div class="children"><div class="content">re #1:  the conflation is justified, but you couldn&#x27;t guess that just from what was presented in the OP.  There are some cool theorems which justify it tho---if you like Kolmogorov complexity you are in for a fun ride.<p>re #2:  No.  Basically the &gt; part of it handles the case when the smallest program which prints out the string is actually LARGER than the length of the string.  In that case, the string is still incompressible.   Compression means mapping from larger strings to smaller strings.</div><br/></div></div></div></div><div id="39877644" class="c"><input type="checkbox" id="c-39877644" checked=""/><div class="controls bullet"><span class="by">pizza</span><span>|</span><a href="#39877836">prev</a><span>|</span><a href="#39877586">next</a><span>|</span><label class="collapse" for="c-39877644">[-]</label><label class="expand" for="c-39877644">[1 more]</label></div><br/><div class="children"><div class="content">I think maybe another way to put this is that Alice&#x27;s number is in a typical set [0] of the distribution of bitstrings whereas Bob&#x27;s might not be. Depending on the tolerance, the typical set can have near-total coverage of the distribution. Another way of making this about compression is that a random code that could encode typical set strings well probably will suffer some overhead when encoding Bob&#x27;s, but most strings it will encode close to optimally.<p>[0] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Typical_set" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Typical_set</a></div><br/></div></div><div id="39877586" class="c"><input type="checkbox" id="c-39877586" checked=""/><div class="controls bullet"><span class="by">yamrzou</span><span>|</span><a href="#39877644">prev</a><span>|</span><a href="#39877782">next</a><span>|</span><label class="collapse" for="c-39877586">[-]</label><label class="expand" for="c-39877586">[2 more]</label></div><br/><div class="children"><div class="content">Well, I reached the end of the article (interesting btw), and still not convinced why bob can&#x27;t claim that there was no foul-play involved and that his got his result due to excellent luck.</div><br/><div id="39877819" class="c"><input type="checkbox" id="c-39877819" checked=""/><div class="controls bullet"><span class="by">ComplexSystems</span><span>|</span><a href="#39877586">parent</a><span>|</span><a href="#39877782">next</a><span>|</span><label class="collapse" for="c-39877819">[-]</label><label class="expand" for="c-39877819">[1 more]</label></div><br/><div class="children"><div class="content">You don&#x27;t need Kolmogorov complexity for this; simple hypothesis testing will do. The null hypothesis is that the coin is fair and the alternative is that it&#x27;s biased. If Bob was correct, then there would simply <i>never</i> be any way to refute the null hypothesis of a fair coin, no matter what, since it can simply output anything at all with equal probability as anything else. In reality, that isn&#x27;t how hypothesis testing works, and pretty much any standard technique (computing p-values, likelihood ratios, etc) will agree that 20 tails in a row is extremely unlikely given the null hypothesis in a way that 10 tails and 10 heads is not.</div><br/></div></div></div></div><div id="39877782" class="c"><input type="checkbox" id="c-39877782" checked=""/><div class="controls bullet"><span class="by">copx</span><span>|</span><a href="#39877586">prev</a><span>|</span><a href="#39880138">next</a><span>|</span><label class="collapse" for="c-39877782">[-]</label><label class="expand" for="c-39877782">[5 more]</label></div><br/><div class="children"><div class="content">&gt;Bob claims that since the probability of getting both his and Alice’s sequence is the same (2−20
), it proves that there was no foul-play involved.<p>..and Bob is 100% right.<p>&gt;Bob credits his excellent luck. Alice is smart and cannot be easily convinced. She get’s back at Bob by claiming that probability cannot be used in this context as it reveals no information regarding the randomness of the obtained sequences. One can take a quick glance at the obtained sequences and easily point out that Alice’s sequence is more random than Bob’s sequence.<p>No, it is not. Given a perfectly random coin toss Bob&#x27;s sequence is indeed just as likely as Alice&#x27;s sequence and in no way &quot;less random&quot; because both sequences result from the same randomness with equal probability.<p>A nice example of human intuition being at odds with probability math, though. Bob&#x27;s result seems less likely but it really is not.
Which reminds me that I actually had to write my own computer simulation of the Monty Hall Problem before I was willing to believe the correct answer.
I think (most?) human brains have a bug in the &quot;understanding probability&quot; subroutine.</div><br/><div id="39877886" class="c"><input type="checkbox" id="c-39877886" checked=""/><div class="controls bullet"><span class="by">ptero</span><span>|</span><a href="#39877782">parent</a><span>|</span><a href="#39877965">next</a><span>|</span><label class="collapse" for="c-39877886">[-]</label><label class="expand" for="c-39877886">[1 more]</label></div><br/><div class="children"><div class="content">Not quite. Specifically, <i>assuming independent random tosses</i> A and B sequences are equally likely. No objection here.<p>But the question posed is different: given a specific sequence, how likely it to have come from independent coin tosses? That is, how likely is it that Bob is cheating and his sequence was in fact <i>not</i> a sequence of a fair coin tosses.<p>And for this KC is a reasonable measure. My 2c.</div><br/></div></div><div id="39877965" class="c"><input type="checkbox" id="c-39877965" checked=""/><div class="controls bullet"><span class="by">Hunpeter</span><span>|</span><a href="#39877782">parent</a><span>|</span><a href="#39877886">prev</a><span>|</span><a href="#39877955">next</a><span>|</span><label class="collapse" for="c-39877965">[-]</label><label class="expand" for="c-39877965">[2 more]</label></div><br/><div class="children"><div class="content">The &quot;bug&quot; in this case imo, is that we interpret A&#x27;s sequence as &quot;random garbage&quot; without regard to the actual contents, whereas we interpret B&#x27;s as &quot;all Ts&quot;. The question our brain asks then is &quot;is it more likely to get random garbage or all Ts?&quot;</div><br/><div id="39878818" class="c"><input type="checkbox" id="c-39878818" checked=""/><div class="controls bullet"><span class="by">nerdponx</span><span>|</span><a href="#39877782">root</a><span>|</span><a href="#39877965">parent</a><span>|</span><a href="#39877955">next</a><span>|</span><label class="collapse" for="c-39878818">[-]</label><label class="expand" for="c-39878818">[1 more]</label></div><br/><div class="children"><div class="content">Right. It might be more interesting to consider the count of Ts and Hs instead of considering exact sequences.</div><br/></div></div></div></div><div id="39877955" class="c"><input type="checkbox" id="c-39877955" checked=""/><div class="controls bullet"><span class="by">Gimpei</span><span>|</span><a href="#39877782">parent</a><span>|</span><a href="#39877965">prev</a><span>|</span><a href="#39880138">next</a><span>|</span><label class="collapse" for="c-39877955">[-]</label><label class="expand" for="c-39877955">[1 more]</label></div><br/><div class="children"><div class="content">Couldn’t you say that the distribution of tosses is less likely in the case of Bob?</div><br/></div></div></div></div><div id="39880138" class="c"><input type="checkbox" id="c-39880138" checked=""/><div class="controls bullet"><span class="by">Ono-Sendai</span><span>|</span><a href="#39877782">prev</a><span>|</span><a href="#39877852">next</a><span>|</span><label class="collapse" for="c-39880138">[-]</label><label class="expand" for="c-39880138">[3 more]</label></div><br/><div class="children"><div class="content">Kolmogorov Complexity does not help with giving a universal measure of complexity or randomness:
<a href="https:&#x2F;&#x2F;forwardscattering.org&#x2F;page&#x2F;0" rel="nofollow">https:&#x2F;&#x2F;forwardscattering.org&#x2F;page&#x2F;0</a></div><br/><div id="39881207" class="c"><input type="checkbox" id="c-39881207" checked=""/><div class="controls bullet"><span class="by">AnotherGoodName</span><span>|</span><a href="#39880138">parent</a><span>|</span><a href="#39877852">next</a><span>|</span><label class="collapse" for="c-39881207">[-]</label><label class="expand" for="c-39881207">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a lot better than the alternatives. Particularly the misused Shannon entropy.<p>The top rated answer for &quot;how do i measure Shannon entropy&quot; on stack overflow for example has an accepted answer of &quot;count the probabilities of all 8bit sequences and then multiply the log of those probabilities together as per the equation&quot;. Which is a problematic answer. A file of all 8bit characters in sequence repeated many times over won&#x27;t have any entropy but will have high entropy by this particular arbitrary measure. The problem with Shannon Entropy is that you have no way to define the optimal symbol lengths and frequencies for any given file.<p>Kolmogorov Complexity on the other hand at least gives some way for us to get a rough estimate. It&#x27;s just as incalculable as Shannon entropy but at least by essentially explicitly stating &quot;compress it using the best tool you have at hand and see how small it gets and also include the size of the compression program in the calculation to prevent cheating by using a dictionary&quot; you can get some rough estimate.<p>Basically Kolmogorov Complexity is the best tool we have. It&#x27;s not perfect because just like Shannon Entropy it&#x27;s incalculable in reality but unlike Shannon Entropy we do have a good way to measure if one tool of calculating Kolmogorov Complexity is better than another tool. That measure is simply &quot;does it compress better?&quot;.<p>It&#x27;s literally the best way to measure randomness of an arbitrary file. Any other way is pretty game-able. If someone uses Shannon entropy to measure randomness just look at the alphabet they use for that measurement and repeat that alphabet sequentially over and over again and you&#x27;ll have a high shannon entropy for a clearly non-random file. Likewise other measurements might be game-able with large dictionaries to lookup. Kolmogorov complexity includes the entire program so that game doesn&#x27;t work here.</div><br/><div id="39882053" class="c"><input type="checkbox" id="c-39882053" checked=""/><div class="controls bullet"><span class="by">Ono-Sendai</span><span>|</span><a href="#39880138">root</a><span>|</span><a href="#39881207">parent</a><span>|</span><a href="#39877852">next</a><span>|</span><label class="collapse" for="c-39882053">[-]</label><label class="expand" for="c-39882053">[1 more]</label></div><br/><div class="children"><div class="content">Practically speaking, trying to compress a file is a nice way of measuring... something.  
I was more talking about the theoretical notion of complexity.</div><br/></div></div></div></div></div></div><div id="39877852" class="c"><input type="checkbox" id="c-39877852" checked=""/><div class="controls bullet"><span class="by">avmich</span><span>|</span><a href="#39880138">prev</a><span>|</span><a href="#39877678">next</a><span>|</span><label class="collapse" for="c-39877852">[-]</label><label class="expand" for="c-39877852">[5 more]</label></div><br/><div class="children"><div class="content">&gt; Another thing to note is that Kolmogorov complexity of a string cannot be computed. There cannot exist a computer that will always guarantee the Kolmogorov complexity for all the strings.<p>Sounds a bit puzzling. Surely for a particular programming language we can enumerate all programs, ordered by length etc. and check which is the shortest one giving the given string. So what&#x27;s uncomputable here? For long strings that could take long time, but - ?</div><br/><div id="39877887" class="c"><input type="checkbox" id="c-39877887" checked=""/><div class="controls bullet"><span class="by">floobertoober</span><span>|</span><a href="#39877852">parent</a><span>|</span><a href="#39878177">next</a><span>|</span><label class="collapse" for="c-39877887">[-]</label><label class="expand" for="c-39877887">[1 more]</label></div><br/><div class="children"><div class="content">With a Turing complete language, you can&#x27;t know whether a given program eventually yields the string, or continues indefinitely</div><br/></div></div><div id="39877992" class="c"><input type="checkbox" id="c-39877992" checked=""/><div class="controls bullet"><span class="by">tromp</span><span>|</span><a href="#39877852">parent</a><span>|</span><a href="#39878177">prev</a><span>|</span><a href="#39877876">next</a><span>|</span><label class="collapse" for="c-39877992">[-]</label><label class="expand" for="c-39877992">[1 more]</label></div><br/><div class="children"><div class="content">&gt; So what&#x27;s uncomputable here?<p>Deciding whether the universal machine will <i>ever</i> halt on a particular input. I.e. the good old halting problem.</div><br/></div></div><div id="39877876" class="c"><input type="checkbox" id="c-39877876" checked=""/><div class="controls bullet"><span class="by">MutualMisinfo</span><span>|</span><a href="#39877852">parent</a><span>|</span><a href="#39877992">prev</a><span>|</span><a href="#39877678">next</a><span>|</span><label class="collapse" for="c-39877876">[-]</label><label class="expand" for="c-39877876">[1 more]</label></div><br/><div class="children"><div class="content">The programs we check might not halt.</div><br/></div></div></div></div><div id="39877678" class="c"><input type="checkbox" id="c-39877678" checked=""/><div class="controls bullet"><span class="by">marius_k</span><span>|</span><a href="#39877852">prev</a><span>|</span><a href="#39877871">next</a><span>|</span><label class="collapse" for="c-39877678">[-]</label><label class="expand" for="c-39877678">[4 more]</label></div><br/><div class="children"><div class="content">Sometimes I wonder what would be the smallest program to generate humans DNA. How many operations would it take and how would it compare to real world iterations of total evolution.</div><br/><div id="39877748" class="c"><input type="checkbox" id="c-39877748" checked=""/><div class="controls bullet"><span class="by">wood_spirit</span><span>|</span><a href="#39877678">parent</a><span>|</span><a href="#39877767">next</a><span>|</span><label class="collapse" for="c-39877748">[-]</label><label class="expand" for="c-39877748">[1 more]</label></div><br/><div class="children"><div class="content">Interestingly, dna programs are quite compressible<p><a href="https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Compression_of_genomic_sequencing_data" rel="nofollow">https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Compression_of_genomic_seque...</a></div><br/></div></div><div id="39877767" class="c"><input type="checkbox" id="c-39877767" checked=""/><div class="controls bullet"><span class="by">arketyp</span><span>|</span><a href="#39877678">parent</a><span>|</span><a href="#39877748">prev</a><span>|</span><a href="#39879142">next</a><span>|</span><label class="collapse" for="c-39877767">[-]</label><label class="expand" for="c-39877767">[1 more]</label></div><br/><div class="children"><div class="content">Not sure what kinds of selection pressures there has been for shorter DNA strings, but presumably you could compress it a great deal putting it in a .zip file. Now imagine the havoc caused by random mutations on that format though.</div><br/></div></div><div id="39879142" class="c"><input type="checkbox" id="c-39879142" checked=""/><div class="controls bullet"><span class="by">amelius</span><span>|</span><a href="#39877678">parent</a><span>|</span><a href="#39877767">prev</a><span>|</span><a href="#39877871">next</a><span>|</span><label class="collapse" for="c-39879142">[-]</label><label class="expand" for="c-39879142">[1 more]</label></div><br/><div class="children"><div class="content">If we ever find a perfect theory of physics, then that might be the smallest program to generate human DNA.</div><br/></div></div></div></div><div id="39877871" class="c"><input type="checkbox" id="c-39877871" checked=""/><div class="controls bullet"><span class="by">rhelz</span><span>|</span><a href="#39877678">prev</a><span>|</span><a href="#39877424">next</a><span>|</span><label class="collapse" for="c-39877871">[-]</label><label class="expand" for="c-39877871">[1 more]</label></div><br/><div class="children"><div class="content">I think its bootless to try to define the &quot;minimum possible&quot; Kolmogorov complexity.     Here&#x27;s why:<p>1.  Note, kolmogorov complexity is defined by the length of the shortest <i>program</i> which prints out the string.  What counts is the <i>number</i> of instructions, and not the <i>complexity of those instructions</i>.<p>2.  So say S is a very complex spring.  We can always construct a turing machine which could print out S using a zero length program:  it could just start in a state which prints out S when you turn it on, and then halts.<p>3.  So there is no such thing as a turing machine which prints out <i>every</i> string shorter than <i>any</i> other turing machine prints it out, QED.<p>That&#x27;s the bad news.  The good news is we don&#x27;t even need to do that.  For any string S, say that M and N are any two universal turing machines.  Without loss of generality, specify that KM(S) &lt;= KN(S).   Then there is always some C for which KM(S) &lt;= KN(S) + C.   The constant C being the length of the program required to <i>emulate</i> machine M on machine N.<p>We are used to abstracting out constant sums and constant factors like this.  The strings we are dealing with (as a species) are growing in length exponentially--that&#x27;s why we went from 8-bit, to 16bit, etc computers.  So as the length of S goes to infinity, the difference between the its complexity for any two machines becomes negligible.</div><br/></div></div></div></div></div></div></div></body></html>