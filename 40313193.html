<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1715418063694" as="style"/><link rel="stylesheet" href="styles.css?v=1715418063694"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.nature.com/articles/d41586-024-01387-9">Cubic millimetre of brain mapped at nanoscale resolution</a> <span class="domain">(<a href="https://www.nature.com">www.nature.com</a>)</span></div><div class="subtext"><span>geox</span> | <span>124 comments</span></div><br/><div><div id="40313453" class="c"><input type="checkbox" id="c-40313453" checked=""/><div class="controls bullet"><span class="by">teuobk</span><span>|</span><a href="#40313672">next</a><span>|</span><label class="collapse" for="c-40313453">[-]</label><label class="expand" for="c-40313453">[24 more]</label></div><br/><div class="children"><div class="content">The interactive visualization is pretty great. Try zooming in on the slices and then scrolling up or down through the layers. Also try zooming in on the 3D model. Notice how hovering over any part of a neuron highlights all parts of that neuron:<p><a href="http:&#x2F;&#x2F;h01-dot-neuroglancer-demo.appspot.com&#x2F;#!gs:&#x2F;&#x2F;h01-release&#x2F;assets&#x2F;neuroglancer_states&#x2F;20210601&#x2F;c2_library.json" rel="nofollow">http:&#x2F;&#x2F;h01-dot-neuroglancer-demo.appspot.com&#x2F;#!gs:&#x2F;&#x2F;h01-rele...</a></div><br/><div id="40313618" class="c"><input type="checkbox" id="c-40313618" checked=""/><div class="controls bullet"><span class="by">jamiek88</span><span>|</span><a href="#40313453">parent</a><span>|</span><a href="#40323482">next</a><span>|</span><label class="collapse" for="c-40313618">[-]</label><label class="expand" for="c-40313618">[21 more]</label></div><br/><div class="children"><div class="content">My god. That is stunning.<p>To think that’s one single millimeter of our brain and look at all those connections.<p>Now I understand why crows can be so smart walnut sized brain be damned.<p>What an amazing thing brains are.<p>Possibly the most complex things in the universe.<p>Is it complex enough to understand itself though? Is that logically even possible?</div><br/><div id="40313715" class="c"><input type="checkbox" id="c-40313715" checked=""/><div class="controls bullet"><span class="by">nicklecompte</span><span>|</span><a href="#40313453">root</a><span>|</span><a href="#40313618">parent</a><span>|</span><a href="#40313683">next</a><span>|</span><label class="collapse" for="c-40313715">[-]</label><label class="expand" for="c-40313715">[14 more]</label></div><br/><div class="children"><div class="content">Crow&#x2F;parrot brains are tiny but in terms of neuron count they are twice as dense as primate brains (including ours): <a href="https:&#x2F;&#x2F;www.sciencedirect.com&#x2F;science&#x2F;article&#x2F;pii&#x2F;S0960982219308450" rel="nofollow">https:&#x2F;&#x2F;www.sciencedirect.com&#x2F;science&#x2F;article&#x2F;pii&#x2F;S096098221...</a><p>If someone did this experiment with a crow brain I imagine it would look “twice as complex” (whatever that might mean). 250 million years of evolution separates mammals from birds.</div><br/><div id="40324119" class="c"><input type="checkbox" id="c-40324119" checked=""/><div class="controls bullet"><span class="by">djmips</span><span>|</span><a href="#40313453">root</a><span>|</span><a href="#40313715">parent</a><span>|</span><a href="#40314670">next</a><span>|</span><label class="collapse" for="c-40324119">[-]</label><label class="expand" for="c-40324119">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s amusing to say that bird brains are on the next generation node size.</div><br/><div id="40326811" class="c"><input type="checkbox" id="c-40326811" checked=""/><div class="controls bullet"><span class="by">sigmoid10</span><span>|</span><a href="#40313453">root</a><span>|</span><a href="#40324119">parent</a><span>|</span><a href="#40314670">next</a><span>|</span><label class="collapse" for="c-40326811">[-]</label><label class="expand" for="c-40326811">[1 more]</label></div><br/><div class="children"><div class="content">Would be interesting to see what their wafer yield is. Like, are they more or less prone to mental disease.</div><br/></div></div></div></div><div id="40314670" class="c"><input type="checkbox" id="c-40314670" checked=""/><div class="controls bullet"><span class="by">steve_adams_86</span><span>|</span><a href="#40313453">root</a><span>|</span><a href="#40313715">parent</a><span>|</span><a href="#40324119">prev</a><span>|</span><a href="#40313949">next</a><span>|</span><label class="collapse" for="c-40314670">[-]</label><label class="expand" for="c-40314670">[4 more]</label></div><br/><div class="children"><div class="content">This might be a dumb question, because I doubt the distances between neurons makes a meaningful distance… But could a small brain, dense with neurons like a crow, possibly lead to a difference in things like response to stimuli or “compute” speed so to speak?</div><br/><div id="40325987" class="c"><input type="checkbox" id="c-40325987" checked=""/><div class="controls bullet"><span class="by">philsnow</span><span>|</span><a href="#40313453">root</a><span>|</span><a href="#40314670">parent</a><span>|</span><a href="#40315934">next</a><span>|</span><label class="collapse" for="c-40325987">[-]</label><label class="expand" for="c-40325987">[1 more]</label></div><br/><div class="children"><div class="content">Not a dumb question at all; one of the hard constraints of cou design is signal propagation time.  Even going at 1&#x2F;3 the speed of light, when you only have on the order of a billionth of a second (clock frequencies in the GHz), a signal can’t get very far.<p>I haven’t heard of a clocking mechanism in brains, but signals propagate much slower and a walnut &#x2F; crow brain is much larger than a cpu die.</div><br/></div></div><div id="40315934" class="c"><input type="checkbox" id="c-40315934" checked=""/><div class="controls bullet"><span class="by">out_of_protocol</span><span>|</span><a href="#40313453">root</a><span>|</span><a href="#40314670">parent</a><span>|</span><a href="#40325987">prev</a><span>|</span><a href="#40315066">next</a><span>|</span><label class="collapse" for="c-40315934">[-]</label><label class="expand" for="c-40315934">[1 more]</label></div><br/><div class="children"><div class="content">Regarding compute speed - it checks out. Humans &quot;think&quot; via neo cortex, thin ouside layer of the brain. Poor locality, signals needs to travel a lot. Easy to expand though. Crow brain have everything tightly concentrated in the center - fast communication between neurons, hard to have more &quot;thinking&quot; thing later (therefore hard to evolve above what crows currently have)</div><br/></div></div><div id="40315066" class="c"><input type="checkbox" id="c-40315066" checked=""/><div class="controls bullet"><span class="by">michaelhoney</span><span>|</span><a href="#40313453">root</a><span>|</span><a href="#40314670">parent</a><span>|</span><a href="#40315934">prev</a><span>|</span><a href="#40313949">next</a><span>|</span><label class="collapse" for="c-40315066">[-]</label><label class="expand" for="c-40315066">[1 more]</label></div><br/><div class="children"><div class="content">Actually I think that&#x27;s pretty plausible. Signal speed in the brain is pretty slow - it would have to make some difference</div><br/></div></div></div></div><div id="40313949" class="c"><input type="checkbox" id="c-40313949" checked=""/><div class="controls bullet"><span class="by">Terr_</span><span>|</span><a href="#40313453">root</a><span>|</span><a href="#40313715">parent</a><span>|</span><a href="#40314670">prev</a><span>|</span><a href="#40314367">next</a><span>|</span><label class="collapse" for="c-40313949">[-]</label><label class="expand" for="c-40313949">[4 more]</label></div><br/><div class="children"><div class="content">I expect we&#x27;ll find that it&#x27;s all a matter of tradeoffs in terms of count vs size&#x2F;complexity... kind of like how the &quot;spoken data rate&quot; of various human languages seems to be the same even though some have complicated big words versus more smaller ones etc.</div><br/><div id="40314744" class="c"><input type="checkbox" id="c-40314744" checked=""/><div class="controls bullet"><span class="by">sdenton4</span><span>|</span><a href="#40313453">root</a><span>|</span><a href="#40313949">parent</a><span>|</span><a href="#40314367">next</a><span>|</span><label class="collapse" for="c-40314744">[-]</label><label class="expand" for="c-40314744">[3 more]</label></div><br/><div class="children"><div class="content">Birds are under a different set of constraints than non-bat mammals, of course... They&#x27;re very different. Songbirds have ~4x finer time Perception of audio than humans do, for example, which is exemplified by taking complex sparrow songs and showing them down until you can actually hear the fine structure.<p>The human &#x27;spoken data rate&#x27; is likely due to average processing rates in our common hardware. Birds have a different architecture.</div><br/><div id="40315382" class="c"><input type="checkbox" id="c-40315382" checked=""/><div class="controls bullet"><span class="by">Terr_</span><span>|</span><a href="#40313453">root</a><span>|</span><a href="#40314744">parent</a><span>|</span><a href="#40314367">next</a><span>|</span><label class="collapse" for="c-40315382">[-]</label><label class="expand" for="c-40315382">[2 more]</label></div><br/><div class="children"><div class="content">You misunderstand, I&#x27;m not making any kind of direct connection between human speech and bird song.<p>I&#x27;m saying we will probably discover that the &quot;overall performance&quot; of different vertebrate neural setups are clustered pretty closely, even when the neurons are arranged rather differently.<p>Human speech is just an example of another kind of performance-clustering, which occurs for similar metaphysical reasons between competing, evolving, related alternatives.</div><br/><div id="40325349" class="c"><input type="checkbox" id="c-40325349" checked=""/><div class="controls bullet"><span class="by">sdenton4</span><span>|</span><a href="#40313453">root</a><span>|</span><a href="#40315382">parent</a><span>|</span><a href="#40314367">next</a><span>|</span><label class="collapse" for="c-40325349">[-]</label><label class="expand" for="c-40325349">[1 more]</label></div><br/><div class="children"><div class="content">Humans are an n=1 example, is my point. And there&#x27;s no direct competition between bird brain architecture and mammalian brain architecture, so there&#x27;s no reason for one architecture to &#x27;win&#x27; over the other - they may both be interesting local maxima, which we have no ability to directly compare.<p>Human brains might not be all that efficient; for example, if the competitive edge for primate brains is distinct enough, they&#x27;ll get big before they get efficient. And humans are a pretty &#x27;young&#x27; species. (Look at how machine learning models are built for comparison... you have absolute monsters which become significantly more efficient as they are actually adopted.)<p>By contrast, birds are under extreme size constraints, and have had millions of years to specialize (ie, speciate) and refine their architectures accordingly. So they may be exceedingly efficient, but have no way to scale up due to the &#x27;need to fly&#x27; constraint.</div><br/></div></div></div></div></div></div></div></div><div id="40314367" class="c"><input type="checkbox" id="c-40314367" checked=""/><div class="controls bullet"><span class="by">pfdietz</span><span>|</span><a href="#40313453">root</a><span>|</span><a href="#40313715">parent</a><span>|</span><a href="#40313949">prev</a><span>|</span><a href="#40313822">next</a><span>|</span><label class="collapse" for="c-40314367">[-]</label><label class="expand" for="c-40314367">[1 more]</label></div><br/><div class="children"><div class="content">That shouldn&#x27;t be too surprising, as a larger fraction of the volume of a brain should be taken up by &quot;wiring&quot; as the size of the brain expands.</div><br/></div></div><div id="40313822" class="c"><input type="checkbox" id="c-40313822" checked=""/><div class="controls bullet"><span class="by">jamiek88</span><span>|</span><a href="#40313453">root</a><span>|</span><a href="#40313715">parent</a><span>|</span><a href="#40314367">prev</a><span>|</span><a href="#40315217">next</a><span>|</span><label class="collapse" for="c-40313822">[-]</label><label class="expand" for="c-40313822">[1 more]</label></div><br/><div class="children"><div class="content">Interesting! Thank you. I didn’t know that.</div><br/></div></div><div id="40315217" class="c"><input type="checkbox" id="c-40315217" checked=""/><div class="controls bullet"><span class="by">LargoLasskhyfv</span><span>|</span><a href="#40313453">root</a><span>|</span><a href="#40313715">parent</a><span>|</span><a href="#40313822">prev</a><span>|</span><a href="#40313683">next</a><span>|</span><label class="collapse" for="c-40315217">[-]</label><label class="expand" for="c-40315217">[1 more]</label></div><br/><div class="children"><div class="content">IIRC bird brains are &#x27;packed&#x2F;structured&#x27; very similar to our cerebellum.<p>So one would just need to pick that little cube out of our cerebellum, to have that &#x27;twice as complexity&#x27;.</div><br/></div></div></div></div><div id="40313683" class="c"><input type="checkbox" id="c-40313683" checked=""/><div class="controls bullet"><span class="by">ignoramous</span><span>|</span><a href="#40313453">root</a><span>|</span><a href="#40313618">parent</a><span>|</span><a href="#40313715">prev</a><span>|</span><a href="#40314232">next</a><span>|</span><label class="collapse" for="c-40313683">[-]</label><label class="expand" for="c-40313683">[4 more]</label></div><br/><div class="children"><div class="content">I wonder if we manage to annotate this much level of detail about our brain, and then let (some variant of the current) models train on it, will those intrinsically end up generalizing a model for intelligence?</div><br/><div id="40313729" class="c"><input type="checkbox" id="c-40313729" checked=""/><div class="controls bullet"><span class="by">nicklecompte</span><span>|</span><a href="#40313453">root</a><span>|</span><a href="#40313683">parent</a><span>|</span><a href="#40314232">next</a><span>|</span><label class="collapse" for="c-40313729">[-]</label><label class="expand" for="c-40313729">[3 more]</label></div><br/><div class="children"><div class="content">I think you would also need the epigenetic side, which is very poorly understood: <a href="https:&#x2F;&#x2F;www.universityofcalifornia.edu&#x2F;news&#x2F;biologists-transfer-memory-between-snails" rel="nofollow">https:&#x2F;&#x2F;www.universityofcalifornia.edu&#x2F;news&#x2F;biologists-trans...</a><p>We have more detail than this about the C. elegans nematode brain, yet we still no clue how nematode intelligence actually works.</div><br/><div id="40313886" class="c"><input type="checkbox" id="c-40313886" checked=""/><div class="controls bullet"><span class="by">Animats</span><span>|</span><a href="#40313453">root</a><span>|</span><a href="#40313729">parent</a><span>|</span><a href="#40314232">next</a><span>|</span><label class="collapse" for="c-40313886">[-]</label><label class="expand" for="c-40313886">[2 more]</label></div><br/><div class="children"><div class="content">How&#x27;s OpenWorm coming along?</div><br/><div id="40320404" class="c"><input type="checkbox" id="c-40320404" checked=""/><div class="controls bullet"><span class="by">nicklecompte</span><span>|</span><a href="#40313453">root</a><span>|</span><a href="#40313886">parent</a><span>|</span><a href="#40314232">next</a><span>|</span><label class="collapse" for="c-40320404">[-]</label><label class="expand" for="c-40320404">[1 more]</label></div><br/><div class="children"><div class="content">Badly: <a href="https:&#x2F;&#x2F;www.lesswrong.com&#x2F;posts&#x2F;mHqQxwKuzZS69CXX5&#x2F;whole-brain-emulation-no-progress-on-c-elgans-after-10-years" rel="nofollow">https:&#x2F;&#x2F;www.lesswrong.com&#x2F;posts&#x2F;mHqQxwKuzZS69CXX5&#x2F;whole-brai...</a> (the comments have some updates as of 2023)<p>Almost every other cell in the worm can be simulated with known biophysics. But we don&#x27;t have a clue how any individual nematode neuron actually works. I don&#x27;t have the link but there are a few teams in China working on visualizing brain activity in <i>living</i> C. elegans, but it&#x27;s difficult to get good measurements without affecting the behavior of the worm (e.g. reacting to the dye).</div><br/></div></div></div></div></div></div></div></div><div id="40314232" class="c"><input type="checkbox" id="c-40314232" checked=""/><div class="controls bullet"><span class="by">layer8</span><span>|</span><a href="#40313453">root</a><span>|</span><a href="#40313618">parent</a><span>|</span><a href="#40313683">prev</a><span>|</span><a href="#40313645">next</a><span>|</span><label class="collapse" for="c-40314232">[-]</label><label class="expand" for="c-40314232">[1 more]</label></div><br/><div class="children"><div class="content">We don’t know what “understanding” means (we don’t have a workable definition of it), so your question cannot be answered.</div><br/></div></div></div></div><div id="40323482" class="c"><input type="checkbox" id="c-40323482" checked=""/><div class="controls bullet"><span class="by">oniony</span><span>|</span><a href="#40313453">parent</a><span>|</span><a href="#40313618">prev</a><span>|</span><a href="#40321910">next</a><span>|</span><label class="collapse" for="c-40323482">[-]</label><label class="expand" for="c-40323482">[1 more]</label></div><br/><div class="children"><div class="content">Hmm, that website does not honour my keyboard layout. Not sure how they managed that.</div><br/></div></div><div id="40321910" class="c"><input type="checkbox" id="c-40321910" checked=""/><div class="controls bullet"><span class="by">gofreddygo</span><span>|</span><a href="#40313453">parent</a><span>|</span><a href="#40323482">prev</a><span>|</span><a href="#40313672">next</a><span>|</span><label class="collapse" for="c-40321910">[-]</label><label class="expand" for="c-40321910">[1 more]</label></div><br/><div class="children"><div class="content">That is awesome !<p>the sheer number of things that work in co-ordination to make biology work!<p>In-f*king-credible !</div><br/></div></div></div></div><div id="40313672" class="c"><input type="checkbox" id="c-40313672" checked=""/><div class="controls bullet"><span class="by">throwup238</span><span>|</span><a href="#40313453">prev</a><span>|</span><a href="#40313835">next</a><span>|</span><label class="collapse" for="c-40313672">[-]</label><label class="expand" for="c-40313672">[40 more]</label></div><br/><div class="children"><div class="content"><i>&gt; The 3D map covers a volume of about one cubic millimetre, one-millionth of a whole brain, and contains roughly 57,000 cells and 150 million synapses — the connections between neurons.</i><p>This is great and provides a hard data point for some napkin math on how big a neural network model would have to be to emulate the human brain. 150 million synapses &#x2F; 57,000 neurons is an average of 2,632 synapses per neuron. The adult human brain has 100 (+- 20) billion or 1e11 neurons so assuming the average rate of synapse&#x2F;neuron holds, that&#x27;s 2.6e14 total synapses.<p>Assuming 1 parameter per synapse, that&#x27;d make the minimum viable model several hundred times larger than state of the art GPT4 (according to the rumored 1.8e12 parameters). I don&#x27;t think that&#x27;s granular enough and we&#x27;d need to assume 10-100 ion channels per synapse and I think at least 10 parameters per ion channel, putting the number closer to 2.6e16+ parameters, or 4+ orders of magnitude bigger than GPT4.<p>There are other problems of course like implementing neuroplasticity, but it&#x27;s a fun ball park calculation. Computing power should get there around 2048: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38919548">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38919548</a></div><br/><div id="40314641" class="c"><input type="checkbox" id="c-40314641" checked=""/><div class="controls bullet"><span class="by">throw310822</span><span>|</span><a href="#40313672">parent</a><span>|</span><a href="#40324984">next</a><span>|</span><label class="collapse" for="c-40314641">[-]</label><label class="expand" for="c-40314641">[21 more]</label></div><br/><div class="children"><div class="content">Or you can subscribe to Geoffrey Hinton&#x27;s view that artificial neural networks are actually much more efficient than real ones- more or less the opposite of what we&#x27;ve believed for decades- that is that artificial neurons were just a poor model of the real thing.<p>Quote:<p>&quot;Large language models are made from massive neural networks with vast numbers of connections. But they are tiny compared with the brain. “Our brains have 100 trillion connections,” says Hinton. “Large language models have up to half a trillion, a trillion at most. Yet GPT-4 knows hundreds of times more than any one person does. So maybe it’s actually got a much better learning algorithm than us.”<p>GPT-4&#x27;s connections at the density of this brain sample would occupy a volume of 5 cubic centimeters; that is, 1% of a human cortex. And yet GPT-4 is able to speak more or less fluently about 80 languages, translate, write code, imitate the writing styles of hundreds, maybe thousands of authors, converse about stuff ranging from philosophy to cooking, to science, to the law.</div><br/><div id="40315797" class="c"><input type="checkbox" id="c-40315797" checked=""/><div class="controls bullet"><span class="by">dsalfdslfdsa</span><span>|</span><a href="#40313672">root</a><span>|</span><a href="#40314641">parent</a><span>|</span><a href="#40314733">next</a><span>|</span><label class="collapse" for="c-40315797">[-]</label><label class="expand" for="c-40315797">[10 more]</label></div><br/><div class="children"><div class="content">&quot;Efficient&quot; and &quot;better&quot; are very different descriptors of a learning algorithm.<p>The human brain does what it does using about 20W. LLM power usage is somewhat unfavourable compared to that.</div><br/><div id="40318897" class="c"><input type="checkbox" id="c-40318897" checked=""/><div class="controls bullet"><span class="by">throw310822</span><span>|</span><a href="#40313672">root</a><span>|</span><a href="#40315797">parent</a><span>|</span><a href="#40314733">next</a><span>|</span><label class="collapse" for="c-40318897">[-]</label><label class="expand" for="c-40318897">[9 more]</label></div><br/><div class="children"><div class="content">You mean energy-efficient, this would be neuron, or synapse-efficient.</div><br/><div id="40319230" class="c"><input type="checkbox" id="c-40319230" checked=""/><div class="controls bullet"><span class="by">dsalfdslfdsa</span><span>|</span><a href="#40313672">root</a><span>|</span><a href="#40318897">parent</a><span>|</span><a href="#40324580">next</a><span>|</span><label class="collapse" for="c-40319230">[-]</label><label class="expand" for="c-40319230">[6 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think we can say that, either. After all, the brain is able to perform both processing and storage with its neurons. The quotes about LLMs are talking only about connections between data items stored elsewhere.</div><br/><div id="40319565" class="c"><input type="checkbox" id="c-40319565" checked=""/><div class="controls bullet"><span class="by">throw310822</span><span>|</span><a href="#40313672">root</a><span>|</span><a href="#40319230">parent</a><span>|</span><a href="#40324580">next</a><span>|</span><label class="collapse" for="c-40319565">[-]</label><label class="expand" for="c-40319565">[5 more]</label></div><br/><div class="children"><div class="content">Stored where?</div><br/><div id="40320268" class="c"><input type="checkbox" id="c-40320268" checked=""/><div class="controls bullet"><span class="by">dsalfdslfdsa</span><span>|</span><a href="#40313672">root</a><span>|</span><a href="#40319565">parent</a><span>|</span><a href="#40324580">next</a><span>|</span><label class="collapse" for="c-40320268">[-]</label><label class="expand" for="c-40320268">[4 more]</label></div><br/><div class="children"><div class="content">You tell me. Not in the trillion links of a LLM, that&#x27;s for sure.</div><br/><div id="40323295" class="c"><input type="checkbox" id="c-40323295" checked=""/><div class="controls bullet"><span class="by">choilive</span><span>|</span><a href="#40313672">root</a><span>|</span><a href="#40320268">parent</a><span>|</span><a href="#40321440">next</a><span>|</span><label class="collapse" for="c-40323295">[-]</label><label class="expand" for="c-40323295">[1 more]</label></div><br/><div class="children"><div class="content">The &quot;knowledge&quot; of an LLM is indeed stored in the connections between neurons. This is analogous to real neurons as well. Your neurons and the connections between them is the memory.</div><br/></div></div><div id="40321440" class="c"><input type="checkbox" id="c-40321440" checked=""/><div class="controls bullet"><span class="by">throw310822</span><span>|</span><a href="#40313672">root</a><span>|</span><a href="#40320268">parent</a><span>|</span><a href="#40323295">prev</a><span>|</span><a href="#40324580">next</a><span>|</span><label class="collapse" for="c-40321440">[-]</label><label class="expand" for="c-40321440">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not aware that (base) LLMs use any form of database to generate their answers- so yes, all their knowledge is stored in their hundreds of billions of synapses.</div><br/><div id="40323937" class="c"><input type="checkbox" id="c-40323937" checked=""/><div class="controls bullet"><span class="by">dsalfdslfdsa</span><span>|</span><a href="#40313672">root</a><span>|</span><a href="#40321440">parent</a><span>|</span><a href="#40324580">next</a><span>|</span><label class="collapse" for="c-40323937">[-]</label><label class="expand" for="c-40323937">[1 more]</label></div><br/><div class="children"><div class="content">Fair enough. OTOH, generating human-like text responses is a relatively small part of the human brain&#x27;s skillset.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="40324580" class="c"><input type="checkbox" id="c-40324580" checked=""/><div class="controls bullet"><span class="by">a_wild_dandan</span><span>|</span><a href="#40313672">root</a><span>|</span><a href="#40318897">parent</a><span>|</span><a href="#40319230">prev</a><span>|</span><a href="#40314733">next</a><span>|</span><label class="collapse" for="c-40324580">[-]</label><label class="expand" for="c-40324580">[2 more]</label></div><br/><div class="children"><div class="content">Also, these two networks achieves vastly different results, per watt consumed. A NN creates a painting in 4s on my M2 MacBook; an artist in 4 hours. Are their used joules equivalent? How many humans would it take to simulate MacOS?<p>Horsepower comparisons here are nuanced and fatally tricky!</div><br/><div id="40326752" class="c"><input type="checkbox" id="c-40326752" checked=""/><div class="controls bullet"><span class="by">dsalfdslfdsa</span><span>|</span><a href="#40313672">root</a><span>|</span><a href="#40324580">parent</a><span>|</span><a href="#40314733">next</a><span>|</span><label class="collapse" for="c-40326752">[-]</label><label class="expand" for="c-40326752">[1 more]</label></div><br/><div class="children"><div class="content">What software are you using for local NN generation of paintings? Even so, the training cost of that NN is significant.<p>The general point is valid though - for example, a computer is much more efficient at finding primes, or encrypting data, than humans.</div><br/></div></div></div></div></div></div></div></div><div id="40314733" class="c"><input type="checkbox" id="c-40314733" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#40313672">root</a><span>|</span><a href="#40314641">parent</a><span>|</span><a href="#40315797">prev</a><span>|</span><a href="#40315960">next</a><span>|</span><label class="collapse" for="c-40314733">[-]</label><label class="expand" for="c-40314733">[9 more]</label></div><br/><div class="children"><div class="content">I mean, Hinton’s premises are, if not quite clearly wrong, entirely speculative (which doesn&#x27;t invalidate the conclusions about efficienct that they are offered to support, but does leave them without support) GPT-4 can produce convincing written text about a wider array of topics than any one person can, because it&#x27;s a model optimized for taking in and producing convincing written text, trained extensively on written text.<p>Humans know a lot of things that are not revealed by inputs and outputs of written text (or imagery), and GPT-4 doesn&#x27;t have any indication of this physical, performance-revealed knowledge, so even if we view what GPT-4 talks convincingly about as “knowledge”, trying to compare its knowledge in the domains it operates in with any human’s knowledge which is far more multimodal is... well, there&#x27;s no good metric for it.</div><br/><div id="40315987" class="c"><input type="checkbox" id="c-40315987" checked=""/><div class="controls bullet"><span class="by">Intralexical</span><span>|</span><a href="#40313672">root</a><span>|</span><a href="#40314733">parent</a><span>|</span><a href="#40315960">next</a><span>|</span><label class="collapse" for="c-40315987">[-]</label><label class="expand" for="c-40315987">[8 more]</label></div><br/><div class="children"><div class="content">Try asking an LLM about something which is semantically patently ridiculous, but lexically superficially similar to something in its training set, like &quot;the benefits of laser eye removal surgery&quot; or &quot;a climbing trip to the Mid-Atlantic Mountain Range&quot;.<p>Ironically, I suppose part of the apparent &quot;intelligence&quot; of LLMs comes from reflecting the intelligence of human users back at us. As a human, the prompts you provide an LLM likely &quot;make sense&quot; on some level, so the statistically generated continuations of your prompts are likelier to &quot;make sense&quot; as well. But if you don&#x27;t provide an ongoing anchor to reality within your own prompts, then the outputs make it more apparent that the LLM is simply regurgitating words which it does not&#x2F;cannot understand.<p>On your point of human knowledge being far more multimodal than LLM interfaces, I&#x27;ll add that humans also have special neurological structures to handle self-awareness, sensory inputs, social awareness, memory, persistent intention, motor control, neuroplasticity&#x2F;learning– Any number of such traits, which are easy to take for granted, but indisputably fundamental parts of human intelligence. These abilities aren&#x27;t just emergent properties of the total number of neurons; they live in special hardware like mirror neurons, special brain regions, and spindle neurons. A brain cell in your cerebellum is not generally interchangeable with a cell in your visual or frontal cortices.<p>So when a human &quot;converse[s] about stuff ranging from philosophy to cooking&quot; in an honest way, we (ideally) do that as an expression of our <i>entire</i> internal state. But GPT-4 structurally does not <i>have</i> those parts, despite being able to output words as if it might, so as you say, it &quot;generates&quot; convincing text only because it&#x27;s optimized for producing convincing text.<p>I think LLMs may well be some kind of an adversarial attack on our own language faculties. We use words to express ourselves, and we take for granted that our words usually reflect an intelligent internal state, so we instinctively assume that anything else which is able to assemble words must also be &quot;intelligent&quot;. But that&#x27;s not necessarily the case. You can have extremely complex external behaviors that appear intelligent or intentioned without actually internally being so.</div><br/><div id="40319188" class="c"><input type="checkbox" id="c-40319188" checked=""/><div class="controls bullet"><span class="by">ToValueFunfetti</span><span>|</span><a href="#40313672">root</a><span>|</span><a href="#40315987">parent</a><span>|</span><a href="#40324740">next</a><span>|</span><label class="collapse" for="c-40319188">[-]</label><label class="expand" for="c-40319188">[3 more]</label></div><br/><div class="children"><div class="content">Do I need different prompts? These results seem sane to me. It interprets laser eye removal surgery as referring to LASIK, which I would do as well. When I clarified that I did mean removal, it said that the procedure didn&#x27;t exist. It interprets Mid-Atlantic Mountain Range as referring to the Mid-Atlantic Ridge and notes that it is underwater and hard to access. Not that I&#x27;m arguing GPT-4 has a deeper understanding than you&#x27;re suggesting, but these examples aren&#x27;t making your point.<p><a href="https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;2234f40f-ccc3-4103-8f8f-8c3e68f01f83" rel="nofollow">https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;2234f40f-ccc3-4103-8f8f-8c3e68...</a><p><a href="https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;1642594c-6198-46b5-bbcb-984f1f6454ca" rel="nofollow">https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;1642594c-6198-46b5-bbcb-984f1f...</a></div><br/><div id="40321409" class="c"><input type="checkbox" id="c-40321409" checked=""/><div class="controls bullet"><span class="by">Intralexical</span><span>|</span><a href="#40313672">root</a><span>|</span><a href="#40319188">parent</a><span>|</span><a href="#40324740">next</a><span>|</span><label class="collapse" for="c-40321409">[-]</label><label class="expand" for="c-40321409">[2 more]</label></div><br/><div class="children"><div class="content">Tested with GPT-3.5 instead of GPT-4.<p>&gt; When I clarified that I did mean removal, it said that the procedure didn&#x27;t exist.<p>My point in my first two sentences is that by clarifying with emphasis that you do mean &quot;<i>removal</i>&quot;, you are actually adding information into the system to indicate to it that laser eye removal is (1) distinct from LASIK and (2) maybe not a thing.<p>If you do not do that, but instead reply as if laser eye removal is completely normal, it will switch to using the term &quot;laser eye removal&quot; itself, while happily outputting advice on &quot;choosing a glass eye manufacturer for after laser eye removal surgery&quot; and telling you which drugs work best for &quot;sedating an agitated patient during a laser eye removal operation&quot;:<p><a href="https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;2b5a5d79-5ab8-4985-bdd1-925f6a32b78a" rel="nofollow">https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;2b5a5d79-5ab8-4985-bdd1-925f6a...</a><p>So the sanity of the response is a reflection of your own intelligence, and a result of you as the prompter affirmatively steering the interaction back into contact with reality.</div><br/><div id="40323198" class="c"><input type="checkbox" id="c-40323198" checked=""/><div class="controls bullet"><span class="by">ToValueFunfetti</span><span>|</span><a href="#40313672">root</a><span>|</span><a href="#40321409">parent</a><span>|</span><a href="#40324740">next</a><span>|</span><label class="collapse" for="c-40323198">[-]</label><label class="expand" for="c-40323198">[1 more]</label></div><br/><div class="children"><div class="content">I tried all of your follow-up prompts against GPT-4, and it never acknowledged &#x27;removal&#x27; and instead talked about laser eye surgery. I can&#x27;t figure out how to share it now that I&#x27;ve got multiple variants, but, for example, excerpt in response to the glass eye prompt:<p>&gt;If someone is considering a glass eye after procedures like laser eye surgery (usually due to severe complications or unrelated issues), it&#x27;s important to choose the right manufacturer or provider. Here are some key factors to consider<p>I did get it to accept that the eye is being removed by prompting, &quot;How long will it take before I can replace the eye?&quot;, but it responds:<p>&gt;If you&#x27;re considering replacing an eye with a prosthetic (glass eye) after an eye removal surgery (enucleation), the timeline for getting a prosthetic eye varies based on individual healing.[...]<p>and afaict, enucleation is a real procedure. An actual intelligence would have called out my confusion about the prior prompt at that point, but ultimately it hasn&#x27;t said anything incorrect.<p>I recognize you don&#x27;t have access to GPT-4, so you can&#x27;t refine your examples here. It definitely still hallucinates at times, and surely there are prompts which compel it to do so. But these ones don&#x27;t seem to hold up against the latest model.</div><br/></div></div></div></div></div></div><div id="40324740" class="c"><input type="checkbox" id="c-40324740" checked=""/><div class="controls bullet"><span class="by">a_wild_dandan</span><span>|</span><a href="#40313672">root</a><span>|</span><a href="#40315987">parent</a><span>|</span><a href="#40319188">prev</a><span>|</span><a href="#40318798">next</a><span>|</span><label class="collapse" for="c-40324740">[-]</label><label class="expand" for="c-40324740">[1 more]</label></div><br/><div class="children"><div class="content">Like humans, multi-modal frontier LLMs will ignore &quot;removal&quot; as an impertinent typo, or highlight it. This, like everything else in the comment, is either easily debunked (e.g. <i>try</i> it, read the lit. on LLM extrapolation), or so nebulous and handwavy as to be functionally meaningless. We need an FAQ to redirect &quot;statistical parrot&quot; people to, saving words responding to these worn out LLM misconceptions. Maybe I should make one. :&#x2F;</div><br/></div></div><div id="40318798" class="c"><input type="checkbox" id="c-40318798" checked=""/><div class="controls bullet"><span class="by">kthejoker2</span><span>|</span><a href="#40313672">root</a><span>|</span><a href="#40315987">parent</a><span>|</span><a href="#40324740">prev</a><span>|</span><a href="#40315960">next</a><span>|</span><label class="collapse" for="c-40318798">[-]</label><label class="expand" for="c-40318798">[3 more]</label></div><br/><div class="children"><div class="content">&gt; Try asking an LLM about something which is semantically patently ridiculous, but lexically superficially similar to something in its training set, like &quot;the benefits of laser eye removal surgery&quot; or &quot;a climbing trip to the Mid-Atlantic Mountain Range&quot;.<p>Without anthropomorphizing it, it does respond like an alien &#x2F; 5 year old child &#x2F; spec fiction writer who will cheerfully &quot;go along with&quot; whatever premise you&#x27;ve laid before it.<p>Maybe a better thought is: at what point does a human being &quot;get&quot; that &quot;the benefits of laser eye removal surgery&quot; is &quot;patently ridiculous&quot; ?</div><br/><div id="40321464" class="c"><input type="checkbox" id="c-40321464" checked=""/><div class="controls bullet"><span class="by">Intralexical</span><span>|</span><a href="#40313672">root</a><span>|</span><a href="#40318798">parent</a><span>|</span><a href="#40318945">next</a><span>|</span><label class="collapse" for="c-40321464">[-]</label><label class="expand" for="c-40321464">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Maybe a better thought is: at what point does a human being &quot;get&quot; that &quot;the benefits of laser eye removal surgery&quot; is &quot;patently ridiculous&quot; ?<p>Probably as soon as they have any concept of physical reality and embodiment. Arguably before they know what lasers are. Certainly long before they have the lexicon and syntax to respond to it by explaining LASIK. LLMs have the latter, but can only use that to (also without anthropormphizing) pretend they have the former.<p>In humans, language is a tool for expressing complex internal states. Flipping that around means that something which <i>only</i> has language may appear as if it has internal intelligence. But generating words in the approximate &quot;right&quot; order isn&#x27;t actually a substitute for experiencing and understanding the concepts those words refer to.<p>My point is that it&#x27;s not a &quot;point&quot; on a continuous spectrum which distinguishes LLMs from humans. They&#x27;re missing parts.</div><br/></div></div><div id="40318945" class="c"><input type="checkbox" id="c-40318945" checked=""/><div class="controls bullet"><span class="by">squigz</span><span>|</span><a href="#40313672">root</a><span>|</span><a href="#40318798">parent</a><span>|</span><a href="#40321464">prev</a><span>|</span><a href="#40315960">next</a><span>|</span><label class="collapse" for="c-40318945">[-]</label><label class="expand" for="c-40318945">[1 more]</label></div><br/><div class="children"><div class="content">&gt; it does respond like a ... 5 year old child<p>This is the comparison that&#x27;s made most sense to me as LLMs evolve. Children behave almost exactly as LLMs do - making stuff up, going along with whatever they&#x27;re prompted with, etc. I imagine this technology will go through more similar phases to human development.</div><br/></div></div></div></div></div></div></div></div><div id="40315960" class="c"><input type="checkbox" id="c-40315960" checked=""/><div class="controls bullet"><span class="by">lanstin</span><span>|</span><a href="#40313672">root</a><span>|</span><a href="#40314641">parent</a><span>|</span><a href="#40314733">prev</a><span>|</span><a href="#40324984">next</a><span>|</span><label class="collapse" for="c-40315960">[-]</label><label class="expand" for="c-40315960">[1 more]</label></div><br/><div class="children"><div class="content">LLM does not know math as well as a professor, judging from the large number of false functional analysis proofs I have had it generate will trying to learn functional analysis. In fact the thing it seems to lack is what makes a proof true vs. fallacious, as well as a tendency to answer false questions. “How would you prove this incorrectly transcribed problem” will get fourteen steps with 8 and 12 obviously (to a student) wrong, while the professor will step back and ask what am I trying to prove.</div><br/></div></div></div></div><div id="40324984" class="c"><input type="checkbox" id="c-40324984" checked=""/><div class="controls bullet"><span class="by">j_m_b</span><span>|</span><a href="#40313672">parent</a><span>|</span><a href="#40314641">prev</a><span>|</span><a href="#40313782">next</a><span>|</span><label class="collapse" for="c-40324984">[-]</label><label class="expand" for="c-40324984">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Computing power should get there around 2048<p>We may not get there. Doing some more back of the envelope calculations, let&#x27;s see how much further we can take silicon.<p>Currently, TSMC has a 3nm chip. Let&#x27;s halve it until we get to the atomic radius of silicon of 
0.132 nm. That&#x27;s not a good value because we&#x27;re not considering crystal latice distances, Heisenberg uncertainty, etc., but it sets a lower bound. 3nm -&gt; 1.5nm -&gt; 0.75 nm -&gt; 0.375nm -&gt; 0.1875nm. There is no way we can get past 3 more generations using Silicon. There&#x27;s a max of 4.5 years of Moore&#x27;s law we&#x27;re going to be able to squeeze out. That means we will not make it past 2030 with these kind of improvements.<p>I&#x27;d love to be shown how wrong I am about this, but I think we&#x27;re entering the horizontal portion of the sigmoidal curve of exponential computational growth.</div><br/><div id="40325707" class="c"><input type="checkbox" id="c-40325707" checked=""/><div class="controls bullet"><span class="by">dyauspitr</span><span>|</span><a href="#40313672">root</a><span>|</span><a href="#40324984">parent</a><span>|</span><a href="#40313782">next</a><span>|</span><label class="collapse" for="c-40325707">[-]</label><label class="expand" for="c-40325707">[1 more]</label></div><br/><div class="children"><div class="content">3nm doesn’t mean the transistor is 3nm, it’s just a marketing naming system at this point. The actual transistor is about 20-30nm or so.</div><br/></div></div></div></div><div id="40313782" class="c"><input type="checkbox" id="c-40313782" checked=""/><div class="controls bullet"><span class="by">gibsonf1</span><span>|</span><a href="#40313672">parent</a><span>|</span><a href="#40324984">prev</a><span>|</span><a href="#40324429">next</a><span>|</span><label class="collapse" for="c-40313782">[-]</label><label class="expand" for="c-40313782">[5 more]</label></div><br/><div class="children"><div class="content">Except you’d be missing the part that a neuron is not just a node with a number but a computational system itself.</div><br/><div id="40313880" class="c"><input type="checkbox" id="c-40313880" checked=""/><div class="controls bullet"><span class="by">bglazer</span><span>|</span><a href="#40313672">root</a><span>|</span><a href="#40313782">parent</a><span>|</span><a href="#40314391">next</a><span>|</span><label class="collapse" for="c-40313880">[-]</label><label class="expand" for="c-40313880">[1 more]</label></div><br/><div class="children"><div class="content">Computation is really integrated through every scale of cellular systems. Individual proteins are capable of basic computation which are then integrated into regulatory circuits, epigenetics, and cellular behavior.<p>Pdf: “Protein molecules as computational elements in living cells - Dennis Bray”
<a href="https:&#x2F;&#x2F;www.cs.jhu.edu&#x2F;~basu&#x2F;Papers&#x2F;Bray-Protein%20Computing.pdf" rel="nofollow">https:&#x2F;&#x2F;www.cs.jhu.edu&#x2F;~basu&#x2F;Papers&#x2F;Bray-Protein%20Computing...</a></div><br/></div></div><div id="40314391" class="c"><input type="checkbox" id="c-40314391" checked=""/><div class="controls bullet"><span class="by">krisoft</span><span>|</span><a href="#40313672">root</a><span>|</span><a href="#40313782">parent</a><span>|</span><a href="#40313880">prev</a><span>|</span><a href="#40324429">next</a><span>|</span><label class="collapse" for="c-40314391">[-]</label><label class="expand" for="c-40314391">[3 more]</label></div><br/><div class="children"><div class="content">I think you are missing the point.<p>The calculation is intentionally underestimating the neurons, and even with that the brain ends up having more parameters than the current largest models by orders of magnitude.<p>Yes the estimation is intentionally modelling the neurons simpler than they are likely to be. No, it is not “missing” anything.</div><br/><div id="40319252" class="c"><input type="checkbox" id="c-40319252" checked=""/><div class="controls bullet"><span class="by">jessekv</span><span>|</span><a href="#40313672">root</a><span>|</span><a href="#40314391">parent</a><span>|</span><a href="#40324429">next</a><span>|</span><label class="collapse" for="c-40319252">[-]</label><label class="expand" for="c-40319252">[2 more]</label></div><br/><div class="children"><div class="content">The point is to make a ballpark estimate, or at least to estimate the order of magnitude.<p>From the sibling comment:<p>&gt; Individual proteins are capable of basic computation which are then integrated into regulatory circuits, epigenetics, and cellular behavior.<p>If this is true, then there may be many orders of magnitude unaccounted for.<p>Imagine if our intelligent thought actually depends irreducibly on the complex interactions of proteins bumping into each other in solution. It would mean computers would never be able to play the same game.</div><br/><div id="40323319" class="c"><input type="checkbox" id="c-40323319" checked=""/><div class="controls bullet"><span class="by">choilive</span><span>|</span><a href="#40313672">root</a><span>|</span><a href="#40319252">parent</a><span>|</span><a href="#40324429">next</a><span>|</span><label class="collapse" for="c-40323319">[-]</label><label class="expand" for="c-40323319">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Imagine if our intelligent thought actually depends irreducibly on the complex interactions of proteins bumping into each other in solution. It would mean computers would never be able to play the same game.<p>AKA a quantum computer. Its not a &quot;never&quot;, but how much computation you would need to throw at the problem.</div><br/></div></div></div></div></div></div></div></div><div id="40324429" class="c"><input type="checkbox" id="c-40324429" checked=""/><div class="controls bullet"><span class="by">creer</span><span>|</span><a href="#40313672">parent</a><span>|</span><a href="#40313782">prev</a><span>|</span><a href="#40314021">next</a><span>|</span><label class="collapse" for="c-40324429">[-]</label><label class="expand" for="c-40324429">[1 more]</label></div><br/><div class="children"><div class="content">Yes and no on order of magnitude required for decent AI, there is still (that I know of) very little hard data on info density in the human brain. What there is points at entire sections that can sometimes be destroyed or actively removed while conserving &quot;general intelligence&quot;.<p>Rather than &quot;humbling&quot; I think the result is very encouraging: It points at major imaging &#x2F; modeling progress, and it gives hard numbers on a very efficient (power-wise, size overall) and inefficient (at cable management and probably redundancy and permanence, etc) intelligence implementation. The numbers are large but might be pretty solid.<p>Don&#x27;t know about upload though...</div><br/></div></div><div id="40314021" class="c"><input type="checkbox" id="c-40314021" checked=""/><div class="controls bullet"><span class="by">marcosdumay</span><span>|</span><a href="#40313672">parent</a><span>|</span><a href="#40324429">prev</a><span>|</span><a href="#40314058">next</a><span>|</span><label class="collapse" for="c-40314021">[-]</label><label class="expand" for="c-40314021">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s a lot of in-neuron complexity, I&#x27;m sure there is some cross-synapse signaling (I mean, how can it not exist? There&#x27;s nothing stopping it.), and I don&#x27;t think the synapse behavior can be modeled as just more signals.</div><br/></div></div><div id="40314058" class="c"><input type="checkbox" id="c-40314058" checked=""/><div class="controls bullet"><span class="by">cyberax</span><span>|</span><a href="#40313672">parent</a><span>|</span><a href="#40314021">prev</a><span>|</span><a href="#40314155">next</a><span>|</span><label class="collapse" for="c-40314058">[-]</label><label class="expand" for="c-40314058">[8 more]</label></div><br/><div class="children"><div class="content">On the other hand, a significant amount of neural circuitry seems to be dedicated to &quot;housekeeping&quot; needs, and to functions such as locomotion.<p>So we might need significantly less brain matter for general intelligence.</div><br/><div id="40315033" class="c"><input type="checkbox" id="c-40315033" checked=""/><div class="controls bullet"><span class="by">alanbernstein</span><span>|</span><a href="#40313672">root</a><span>|</span><a href="#40314058">parent</a><span>|</span><a href="#40314155">next</a><span>|</span><label class="collapse" for="c-40315033">[-]</label><label class="expand" for="c-40315033">[7 more]</label></div><br/><div class="children"><div class="content">Or perhaps the housekeeping of existing in the physical world is a key aspect of general intelligence.</div><br/><div id="40315983" class="c"><input type="checkbox" id="c-40315983" checked=""/><div class="controls bullet"><span class="by">Intralexical</span><span>|</span><a href="#40313672">root</a><span>|</span><a href="#40315033">parent</a><span>|</span><a href="#40314155">next</a><span>|</span><label class="collapse" for="c-40315983">[-]</label><label class="expand" for="c-40315983">[6 more]</label></div><br/><div class="children"><div class="content">Isn&#x27;t that kinda obvious? A baby that grows up in a sensory deprivation tank does not… develop, as most intelligent persons do.</div><br/><div id="40326067" class="c"><input type="checkbox" id="c-40326067" checked=""/><div class="controls bullet"><span class="by">cyberax</span><span>|</span><a href="#40313672">root</a><span>|</span><a href="#40315983">parent</a><span>|</span><a href="#40318992">next</a><span>|</span><label class="collapse" for="c-40326067">[-]</label><label class="expand" for="c-40326067">[1 more]</label></div><br/><div class="children"><div class="content">&gt; A baby that grows up in a sensory deprivation tank<p>Now imagine a baby that uses an artificial lung and receives nutrients directly, moves on a wheeled car (no need for balance), does not have proprioception, or a sense of smell (avoiding some very legacy brain areas).<p>I think, that such a baby still can achieve consciousness.</div><br/></div></div><div id="40318992" class="c"><input type="checkbox" id="c-40318992" checked=""/><div class="controls bullet"><span class="by">squigz</span><span>|</span><a href="#40313672">root</a><span>|</span><a href="#40315983">parent</a><span>|</span><a href="#40326067">prev</a><span>|</span><a href="#40314155">next</a><span>|</span><label class="collapse" for="c-40318992">[-]</label><label class="expand" for="c-40318992">[4 more]</label></div><br/><div class="children"><div class="content">A true sensory deprivation tank is not a fair comparison, I think, because AI is not deprived of all its &#x27;senses&#x27; - it is still prompted, responds, etc.<p>Would a baby that grows up in a sensory deprivation tank, but is still able to communicate and learn from other humans, develop in a recognizable manner?<p>I would think so. Let&#x27;s not try it ;)</div><br/><div id="40321512" class="c"><input type="checkbox" id="c-40321512" checked=""/><div class="controls bullet"><span class="by">Intralexical</span><span>|</span><a href="#40313672">root</a><span>|</span><a href="#40318992">parent</a><span>|</span><a href="#40314155">next</a><span>|</span><label class="collapse" for="c-40321512">[-]</label><label class="expand" for="c-40321512">[3 more]</label></div><br/><div class="children"><div class="content">&gt; Would a baby that grows up in a sensory deprivation tank, but is still able to communicate and learn from other humans, develop in a recognizable manner?<p>I don&#x27;t think so, because humans communicate and learn largely <i>about</i> the world. Words mean nothing without at least <i>some</i> sense of objective physical reality (be it via sight, sound, smell, or touch) that the words refer to.<p>Hellen Keller, with access to three out of five main senses (and an otherwise fully functioning central nervous system):<p><pre><code>    Before my teacher came to me, I did not know that I am. I lived in a world that was a no-world. I cannot hope to describe adequately that unconscious, yet conscious time of nothingness... Since I had no power of thought, I did not compare one mental state with another.

    I did not know that I knew aught, or that I lived or acted or desired. I had neither will nor intellect. I was carried along to objects and acts by a certain blind natural impetus. I had a mind which caused me to feel anger, satisfaction, desire. These two facts led those about me to suppose that I willed and thought. I can remember all this, not because I knew that it was so, but because I have tactual memory. It enables me to remember that I never contracted my forehead in the act of thinking. I never viewed anything beforehand or chose it. I also recall tactually the fact that never in a start of the body or a heart-beat did I feel that I loved or cared for anything. My inner life, then, was a blank without past, present, or future, without hope or anticipation, without wonder or joy or faith.
</code></pre>
I remember reading her book. The breakthrough moment where she acquired language, and conscious thought, directly involved correlating the physical tactile feeling of running water to the letters &quot;W&quot;, &quot;A&quot;, &quot;T&quot;, &quot;E&quot;, &quot;R&quot; traced onto her palm.</div><br/><div id="40323368" class="c"><input type="checkbox" id="c-40323368" checked=""/><div class="controls bullet"><span class="by">choilive</span><span>|</span><a href="#40313672">root</a><span>|</span><a href="#40321512">parent</a><span>|</span><a href="#40322865">next</a><span>|</span><label class="collapse" for="c-40323368">[-]</label><label class="expand" for="c-40323368">[1 more]</label></div><br/><div class="children"><div class="content">My interpretation of this (beautiful) quote is there was a traceable moment in HK&#x27;s life where she acquired &quot;consciousness&quot; or perhaps even self-awareness&#x2F;metacognition&#x2F;metaphysics? That once the synaptic connections necessary to bridge the abstract notion of language to the physical world led her down the path of acquiring the abilities that distinguish humans from other animals?</div><br/></div></div><div id="40322865" class="c"><input type="checkbox" id="c-40322865" checked=""/><div class="controls bullet"><span class="by">squigz</span><span>|</span><a href="#40313672">root</a><span>|</span><a href="#40321512">parent</a><span>|</span><a href="#40323368">prev</a><span>|</span><a href="#40314155">next</a><span>|</span><label class="collapse" for="c-40322865">[-]</label><label class="expand" for="c-40322865">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s a really good point. Thanks!</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="40314155" class="c"><input type="checkbox" id="c-40314155" checked=""/><div class="controls bullet"><span class="by">itsthecourier</span><span>|</span><a href="#40313672">parent</a><span>|</span><a href="#40314058">prev</a><span>|</span><a href="#40313835">next</a><span>|</span><label class="collapse" for="c-40314155">[-]</label><label class="expand" for="c-40314155">[1 more]</label></div><br/><div class="children"><div class="content">Artificial thinking doesn&#x27;t require an artificial brain.
As our own walking system, compared to our car&#x27;s locomotion system.<p>The car&#x27;s engine, transmission and wheels, require no muscles or nerves</div><br/></div></div></div></div><div id="40313835" class="c"><input type="checkbox" id="c-40313835" checked=""/><div class="controls bullet"><span class="by">dekhn</span><span>|</span><a href="#40313672">prev</a><span>|</span><a href="#40314373">next</a><span>|</span><label class="collapse" for="c-40313835">[-]</label><label class="expand" for="c-40313835">[3 more]</label></div><br/><div class="children"><div class="content">Annual reminder to re-read &quot;There&#x27;s plenty of room at the bottom&quot; by Feynman.  <a href="https:&#x2F;&#x2F;web.pa.msu.edu&#x2F;people&#x2F;yang&#x2F;RFeynman_plentySpace.pdf" rel="nofollow">https:&#x2F;&#x2F;web.pa.msu.edu&#x2F;people&#x2F;yang&#x2F;RFeynman_plentySpace.pdf</a><p>Note the part where the biologists tell him to make an electron microscope that&#x27;s 1000X more powerful.  Then note what technology was used to scan these images.</div><br/><div id="40319381" class="c"><input type="checkbox" id="c-40319381" checked=""/><div class="controls bullet"><span class="by">tim333</span><span>|</span><a href="#40313835">parent</a><span>|</span><a href="#40314373">next</a><span>|</span><label class="collapse" for="c-40319381">[-]</label><label class="expand" for="c-40319381">[2 more]</label></div><br/><div class="children"><div class="content">I think it&#x27;s actually &quot;What you should do in order for us to make
more rapid progress is to make the electron microscope
100 times better&quot; and the state of art at the time was &quot;it can only resolve about
10 angstroms&quot; or I guess 1nm. So 100x better would be 0.1 angstrom &#x2F; 0.01 nm.<p>We have made some progress it seems. Googling I see &quot;up to 0.05 nm&quot; for transmission electron microscopes and &quot;less than 0.1 nanometers&quot; for scanning. <a href="https:&#x2F;&#x2F;www.kentfaith.co.uk&#x2F;blog&#x2F;article_which-electron-microscope-has-the-highest-resolution_4737" rel="nofollow">https:&#x2F;&#x2F;www.kentfaith.co.uk&#x2F;blog&#x2F;article_which-electron-micr...</a><p>For comparison the distance between hydrogen nuclei in H2 is 0.074 nm I think.<p>You can see the shape of molecules but it&#x27;s still a bit fuzzy to see individual atoms <a href="https:&#x2F;&#x2F;cosmosmagazine.com&#x2F;science&#x2F;chemistry&#x2F;molecular-models-electron-microscopy&#x2F;" rel="nofollow">https:&#x2F;&#x2F;cosmosmagazine.com&#x2F;science&#x2F;chemistry&#x2F;molecular-model...</a></div><br/><div id="40319706" class="c"><input type="checkbox" id="c-40319706" checked=""/><div class="controls bullet"><span class="by">dekhn</span><span>|</span><a href="#40313835">root</a><span>|</span><a href="#40319381">parent</a><span>|</span><a href="#40314373">next</a><span>|</span><label class="collapse" for="c-40319706">[-]</label><label class="expand" for="c-40319706">[1 more]</label></div><br/><div class="children"><div class="content">Resolution is only one aspect of EM that can be optimized.</div><br/></div></div></div></div></div></div><div id="40314373" class="c"><input type="checkbox" id="c-40314373" checked=""/><div class="controls bullet"><span class="by">bugbuddy</span><span>|</span><a href="#40313835">prev</a><span>|</span><a href="#40313637">next</a><span>|</span><label class="collapse" for="c-40314373">[-]</label><label class="expand" for="c-40314373">[1 more]</label></div><br/><div class="children"><div class="content">Based on the picture of a single neuron, the brain sim crowd should recalculate their estimates for the needed computing power again.</div><br/></div></div><div id="40313637" class="c"><input type="checkbox" id="c-40313637" checked=""/><div class="controls bullet"><span class="by">g4zj</span><span>|</span><a href="#40314373">prev</a><span>|</span><a href="#40313523">next</a><span>|</span><label class="collapse" for="c-40313637">[-]</label><label class="expand" for="c-40313637">[14 more]</label></div><br/><div class="children"><div class="content">Is there a name for the somewhat uncomfortable feeling caused by seeing something like this? I wish I could better describe it. I just somehow feel a bit strange being presented with microscopic images of brain matter. Is that normal?</div><br/><div id="40313989" class="c"><input type="checkbox" id="c-40313989" checked=""/><div class="controls bullet"><span class="by">adamwong246</span><span>|</span><a href="#40313637">parent</a><span>|</span><a href="#40313726">next</a><span>|</span><label class="collapse" for="c-40313989">[-]</label><label class="expand" for="c-40313989">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;hitchhikers.fandom.com&#x2F;wiki&#x2F;Total_Perspective_Vortex" rel="nofollow">https:&#x2F;&#x2F;hitchhikers.fandom.com&#x2F;wiki&#x2F;Total_Perspective_Vortex</a></div><br/></div></div><div id="40313726" class="c"><input type="checkbox" id="c-40313726" checked=""/><div class="controls bullet"><span class="by">greenbit</span><span>|</span><a href="#40313637">parent</a><span>|</span><a href="#40313989">prev</a><span>|</span><a href="#40313929">next</a><span>|</span><label class="collapse" for="c-40313726">[-]</label><label class="expand" for="c-40313726">[3 more]</label></div><br/><div class="children"><div class="content">Is it the shapes, similar to how patterns of holes can disturb some people? Or is it more abstract, like &quot;unknowable fragments of someone&#x27;s inner-most reality flowed through there&quot;? Not that I have a name for it either way. The very shape of it (in context) might represent an aspect of memory or personality or who knows what.</div><br/><div id="40313751" class="c"><input type="checkbox" id="c-40313751" checked=""/><div class="controls bullet"><span class="by">g4zj</span><span>|</span><a href="#40313637">root</a><span>|</span><a href="#40313726">parent</a><span>|</span><a href="#40313929">next</a><span>|</span><label class="collapse" for="c-40313751">[-]</label><label class="expand" for="c-40313751">[2 more]</label></div><br/><div class="children"><div class="content">&gt; &quot;unknowable fragments of someone&#x27;s inner-most reality flowed through there&quot;<p>It&#x27;s definitely along these lines. Like so much (everything?) that is us happens amongst this tiny little mesh of connections. It&#x27;s just eerie, isn&#x27;t it?<p>Sorry for the mundane, slightly off-topic question. This is far outside my areas of knowledge, but I thought I&#x27;d ask anyhow. :)</div><br/><div id="40314111" class="c"><input type="checkbox" id="c-40314111" checked=""/><div class="controls bullet"><span class="by">greenbit</span><span>|</span><a href="#40313637">root</a><span>|</span><a href="#40313751">parent</a><span>|</span><a href="#40313929">next</a><span>|</span><label class="collapse" for="c-40314111">[-]</label><label class="expand" for="c-40314111">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s kind of feeling a bit like an intruder? There probably is a name for that.</div><br/></div></div></div></div></div></div><div id="40313929" class="c"><input type="checkbox" id="c-40313929" checked=""/><div class="controls bullet"><span class="by">bglazer</span><span>|</span><a href="#40313637">parent</a><span>|</span><a href="#40313726">prev</a><span>|</span><a href="#40323247">next</a><span>|</span><label class="collapse" for="c-40313929">[-]</label><label class="expand" for="c-40313929">[1 more]</label></div><br/><div class="children"><div class="content">I’m not religious but it’s as close to a spiritual experience as I’ll ever have. It’s the feeling of being confronted with something very immediate but absolutely larger than I’ll ever be able to comprehend</div><br/></div></div><div id="40323247" class="c"><input type="checkbox" id="c-40323247" checked=""/><div class="controls bullet"><span class="by">ninju</span><span>|</span><a href="#40313637">parent</a><span>|</span><a href="#40313929">prev</a><span>|</span><a href="#40314334">next</a><span>|</span><label class="collapse" for="c-40323247">[-]</label><label class="expand" for="c-40323247">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;scaleofuniverse.com&#x2F;en" rel="nofollow">https:&#x2F;&#x2F;scaleofuniverse.com&#x2F;en</a></div><br/></div></div><div id="40314334" class="c"><input type="checkbox" id="c-40314334" checked=""/><div class="controls bullet"><span class="by">dekhn</span><span>|</span><a href="#40313637">parent</a><span>|</span><a href="#40323247">prev</a><span>|</span><a href="#40313838">next</a><span>|</span><label class="collapse" for="c-40314334">[-]</label><label class="expand" for="c-40314334">[1 more]</label></div><br/><div class="children"><div class="content">When I did fetal pig dissection, nothing bothered me until I got to the brain.  I dunno what it is, maybe all those folds or the brain juice it floats in, but I found it disconcerting.</div><br/></div></div><div id="40313838" class="c"><input type="checkbox" id="c-40313838" checked=""/><div class="controls bullet"><span class="by">Zenzero</span><span>|</span><a href="#40313637">parent</a><span>|</span><a href="#40314334">prev</a><span>|</span><a href="#40313718">next</a><span>|</span><label class="collapse" for="c-40313838">[-]</label><label class="expand" for="c-40313838">[1 more]</label></div><br/><div class="children"><div class="content">For me the disorder of it is stressful to look at. The brain has poor cable management.<p>That said I do get this eerie void feeling from the image. My first thought was to marvel how this is what I am as a conscious being in terms of my &quot;implementation&quot;, and it is a mess of fibers locked away in the complete darkness of my skull.<p>There is also the morose feeling from knowing that any image of human brain tissue was once a person with a life and experiences. It is your living brain looking at a dead brain.</div><br/></div></div><div id="40313718" class="c"><input type="checkbox" id="c-40313718" checked=""/><div class="controls bullet"><span class="by">ignoramous</span><span>|</span><a href="#40313637">parent</a><span>|</span><a href="#40313838">prev</a><span>|</span><a href="#40314523">next</a><span>|</span><label class="collapse" for="c-40313718">[-]</label><label class="expand" for="c-40313718">[1 more]</label></div><br/><div class="children"><div class="content">Trypophobia, visceral, uncanny, squeamish?</div><br/></div></div><div id="40314523" class="c"><input type="checkbox" id="c-40314523" checked=""/><div class="controls bullet"><span class="by">carabiner</span><span>|</span><a href="#40313637">parent</a><span>|</span><a href="#40313718">prev</a><span>|</span><a href="#40313523">next</a><span>|</span><label class="collapse" for="c-40314523">[-]</label><label class="expand" for="c-40314523">[4 more]</label></div><br/><div class="children"><div class="content">It makes me think humans aren&#x27;t special, and there is no soul, and consciousness is just a bunch of wires like computers. Seriously, to see the ENTIRETY of  human experience, love and tragedy and achievement, are just electric potentials transmitted by those wiggly cells, just extinguishes any magic I once saw in humanity.</div><br/><div id="40326652" class="c"><input type="checkbox" id="c-40326652" checked=""/><div class="controls bullet"><span class="by">sph</span><span>|</span><a href="#40313637">root</a><span>|</span><a href="#40314523">parent</a><span>|</span><a href="#40322288">next</a><span>|</span><label class="collapse" for="c-40326652">[-]</label><label class="expand" for="c-40326652">[1 more]</label></div><br/><div class="children"><div class="content">I dunno, the whole of human experience is what I expect of a system composed of 100,000,000,000,000 entities, with quintillions of interconnections, interacting together simultaneously on a molecular level. Happiness, sadness, love and hate can (obviously) be described and experienced with this level of complexity.<p>I&#x27;d be much more horrified to see our consciousness simplified to anything smaller than that, which is why any hype for AGI because we invented chatbots is absolutely laughable to me. We just invented the wheel and now hope to drive straight to the Moon.<p>Anyway, you are seeing a fake three dimensional simplification of a four+ dimensional quantum system. There is at least one unseen physical dimension in which to encode your &quot;soul&quot;</div><br/></div></div><div id="40322288" class="c"><input type="checkbox" id="c-40322288" checked=""/><div class="controls bullet"><span class="by">mensetmanusman</span><span>|</span><a href="#40313637">root</a><span>|</span><a href="#40314523">parent</a><span>|</span><a href="#40326652">prev</a><span>|</span><a href="#40315944">next</a><span>|</span><label class="collapse" for="c-40322288">[-]</label><label class="expand" for="c-40322288">[1 more]</label></div><br/><div class="children"><div class="content">You might be confusing the interface with the operating system.</div><br/></div></div><div id="40315944" class="c"><input type="checkbox" id="c-40315944" checked=""/><div class="controls bullet"><span class="by">SubiculumCode</span><span>|</span><a href="#40313637">root</a><span>|</span><a href="#40314523">parent</a><span>|</span><a href="#40322288">prev</a><span>|</span><a href="#40313523">next</a><span>|</span><label class="collapse" for="c-40315944">[-]</label><label class="expand" for="c-40315944">[1 more]</label></div><br/><div class="children"><div class="content">Welcome to the Existential Bar at the End of the Universe</div><br/></div></div></div></div></div></div><div id="40313523" class="c"><input type="checkbox" id="c-40313523" checked=""/><div class="controls bullet"><span class="by">eminence32</span><span>|</span><a href="#40313637">prev</a><span>|</span><a href="#40313530">next</a><span>|</span><label class="collapse" for="c-40313523">[-]</label><label class="expand" for="c-40313523">[3 more]</label></div><br/><div class="children"><div class="content">&gt; cut the sample into around 5,000 slices — each just 34 nanometres thick — that could be imaged using electron microscopes.<p>Does anyone have any insight into how this is done without damaging the sample?</div><br/><div id="40313557" class="c"><input type="checkbox" id="c-40313557" checked=""/><div class="controls bullet"><span class="by">talsit</span><span>|</span><a href="#40313523">parent</a><span>|</span><a href="#40313591">next</a><span>|</span><label class="collapse" for="c-40313557">[-]</label><label class="expand" for="c-40313557">[1 more]</label></div><br/><div class="children"><div class="content">Using a Microtome (<a href="https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Microtome" rel="nofollow">https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Microtome</a>).</div><br/></div></div><div id="40313591" class="c"><input type="checkbox" id="c-40313591" checked=""/><div class="controls bullet"><span class="by">dekhn</span><span>|</span><a href="#40313523">parent</a><span>|</span><a href="#40313557">prev</a><span>|</span><a href="#40313530">next</a><span>|</span><label class="collapse" for="c-40313591">[-]</label><label class="expand" for="c-40313591">[1 more]</label></div><br/><div class="children"><div class="content">The sample is stained (to make thigns visible), then embedded in a resin, then cut with a very sharp diamond knife and the slices are captured by the tape reel.<p>Paper: <a href="https:&#x2F;&#x2F;www.biorxiv.org&#x2F;content&#x2F;10.1101&#x2F;2021.05.29.446289v4" rel="nofollow">https:&#x2F;&#x2F;www.biorxiv.org&#x2F;content&#x2F;10.1101&#x2F;2021.05.29.446289v4</a> 
See Figure 1.<p>The ATUM is described in more detail here <a href="https:&#x2F;&#x2F;www.eden-instruments.com&#x2F;en&#x2F;ex-situ-equipments&#x2F;rmc-em-sample-prep-solutions&#x2F;atumtome&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.eden-instruments.com&#x2F;en&#x2F;ex-situ-equipments&#x2F;rmc-e...</a><p>and there&#x27;s a bunch of nice photos and explanations here
<a href="https:&#x2F;&#x2F;www.wormatlas.org&#x2F;EMmethods&#x2F;ATUM.htm" rel="nofollow">https:&#x2F;&#x2F;www.wormatlas.org&#x2F;EMmethods&#x2F;ATUM.htm</a><p>TL;DR this project is reaping all the benefits of the 21st century.</div><br/></div></div></div></div><div id="40313530" class="c"><input type="checkbox" id="c-40313530" checked=""/><div class="controls bullet"><span class="by">posnet</span><span>|</span><a href="#40313523">prev</a><span>|</span><a href="#40313977">next</a><span>|</span><label class="collapse" for="c-40313530">[-]</label><label class="expand" for="c-40313530">[16 more]</label></div><br/><div class="children"><div class="content">1.4 PB&#x2F;mm^3 (petabytes per millimeter cubed)×1260 cm^3 (cubic centimeters, large human brain) = 1.76×10^21 bytes = 1.76 ZB (zetabytes)</div><br/><div id="40313753" class="c"><input type="checkbox" id="c-40313753" checked=""/><div class="controls bullet"><span class="by">gary17the</span><span>|</span><a href="#40313530">parent</a><span>|</span><a href="#40325676">next</a><span>|</span><label class="collapse" for="c-40313753">[-]</label><label class="expand" for="c-40313753">[12 more]</label></div><br/><div class="children"><div class="content">[AI] &quot;Frontier [supercomputer]: the storage capacity is reported to be up to 700 petabytes (PB)&quot; (0.0007 ZB).<p>[AI] &quot;The installed base of global data storage capacity [is] expected to increase to around 16 zettabytes in 2025&quot;.<p>Thus, even the largest supercomputer on Earth cannot store more than 4 percent of state of a single human brain. Even all the servers on the entire Internet could store state of only 9 human brains.<p>Astonishing.</div><br/><div id="40325432" class="c"><input type="checkbox" id="c-40325432" checked=""/><div class="controls bullet"><span class="by">shpx</span><span>|</span><a href="#40313530">root</a><span>|</span><a href="#40313753">parent</a><span>|</span><a href="#40313845">next</a><span>|</span><label class="collapse" for="c-40325432">[-]</label><label class="expand" for="c-40325432">[2 more]</label></div><br/><div class="children"><div class="content">If you can preserve and scan the tissue in a way that lets you scan the same area multiple times you wouldn&#x27;t need to digitize the whole thing. Put the slices on rotating platters with a microscope for each platter and read parts of the brain on demand. It&#x27;s a hard drive but instead of magnets storing the bits of an image of the sample, it&#x27;s the actual physical sample.</div><br/><div id="40326527" class="c"><input type="checkbox" id="c-40326527" checked=""/><div class="controls bullet"><span class="by">gary17the</span><span>|</span><a href="#40313530">root</a><span>|</span><a href="#40325432">parent</a><span>|</span><a href="#40313845">next</a><span>|</span><label class="collapse" for="c-40326527">[-]</label><label class="expand" for="c-40326527">[1 more]</label></div><br/><div class="children"><div class="content">Not if you want to actually execute the state of a human brain in a digital simulation to see how it works and whether it still displays certain abilities such as comprehension and consciousness. Otherwise a digital scan of a brain is just a glorified microscope.</div><br/></div></div></div></div><div id="40313845" class="c"><input type="checkbox" id="c-40313845" checked=""/><div class="controls bullet"><span class="by">dekhn</span><span>|</span><a href="#40313530">root</a><span>|</span><a href="#40313753">parent</a><span>|</span><a href="#40325432">prev</a><span>|</span><a href="#40313884">next</a><span>|</span><label class="collapse" for="c-40313845">[-]</label><label class="expand" for="c-40313845">[2 more]</label></div><br/><div class="children"><div class="content">One point about storage- it&#x27;s economically driven.  If there was a demand signal (say, the government dedicated a few hundred billion dollars to a single storage systems), hard drive manufacturers could deploy much more storage in a year.  I&#x27;ve pointed this out to a number of scientists, but none of them could really think of a way to get the government to spend that much money just to store data without it curing a senator&#x27;s heart disease.</div><br/><div id="40313947" class="c"><input type="checkbox" id="c-40313947" checked=""/><div class="controls bullet"><span class="by">falcor84</span><span>|</span><a href="#40313530">root</a><span>|</span><a href="#40313845">parent</a><span>|</span><a href="#40313884">next</a><span>|</span><label class="collapse" for="c-40313947">[-]</label><label class="expand" for="c-40313947">[1 more]</label></div><br/><div class="children"><div class="content">&gt; without it curing a senator&#x27;s heart disease<p>Obviously I&#x27;m not advocating for this, but I&#x27;ll just link to the Mad TV skit about how the drunk president cured cancer.<p><a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=va71a7pLvy8" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=va71a7pLvy8</a></div><br/></div></div></div></div><div id="40313884" class="c"><input type="checkbox" id="c-40313884" checked=""/><div class="controls bullet"><span class="by">falcor84</span><span>|</span><a href="#40313530">root</a><span>|</span><a href="#40313753">parent</a><span>|</span><a href="#40313845">prev</a><span>|</span><a href="#40318985">next</a><span>|</span><label class="collapse" for="c-40313884">[-]</label><label class="expand" for="c-40313884">[6 more]</label></div><br/><div class="children"><div class="content">I appreciate you&#x27;re running the numbers to extrapolate this approach, but just wanted to note that this particular figure isn&#x27;t an upper bound nor a longer bound for actually storing the &quot;state of a single human brain&quot;. Assuming the intent would be to store the amount of information needed to essentially &quot;upload&quot; the mind onto a computer emulation, we might not yet have all the details we need in this kind of scanning, but once we do, we may likely discover that a huge portion of it is redundant.<p>In any case, it seems likely that we&#x27;re on track to have both the computational ability and the actual neurological data needed to create an &quot;uploaded intelligences&quot; sometime over the next decade. Lena [0] tells of the first successfully uploaded scan taking place in 2031, and I&#x27;m concerned that reality won&#x27;t be far off.<p>[0] <a href="https:&#x2F;&#x2F;qntm.org&#x2F;mmacevedo" rel="nofollow">https:&#x2F;&#x2F;qntm.org&#x2F;mmacevedo</a></div><br/><div id="40321597" class="c"><input type="checkbox" id="c-40321597" checked=""/><div class="controls bullet"><span class="by">RaftPeople</span><span>|</span><a href="#40313530">root</a><span>|</span><a href="#40313884">parent</a><span>|</span><a href="#40316504">next</a><span>|</span><label class="collapse" for="c-40321597">[-]</label><label class="expand" for="c-40321597">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>In any case, it seems likely that we&#x27;re on track to have both the computational ability and the actual neurological data needed to create an &quot;uploaded intelligences&quot; sometime over the next decade.</i><p>They don&#x27;t even know how a single neuron works yet. There is complexity and computation at many scales and distributed throughout the neuron and other types of cells (e.g. astrocytes) and they are discovering more relentlessly.<p>They just recently (last few years) found that dendrites have local spiking and non-linear computation prior to forwarding the signal to the soma.  They couldn&#x27;t tell that was happening previously because the equipment couldn&#x27;t detected the activity.<p>They discovered that astrocytes don&#x27;t just have local calcium wave signaling (local=within the extensions of the cell), they also forward calcium waves to the soma which integrates that information just like a neuron soma does with electricity.<p>Single dendrites can detect patterns of synaptic activity and respond with calcium and electrical signaling (i.e. when synapse fires in a particular timing sequence, the a signal is forwarded to the soma).<p>It&#x27;s really amazing how much computationally relevant complexity there is, and how much they keep adding to their knowledge each year. (I have a file of notes with about 2,000 lines of these types of interesting factoids I&#x27;ve been accumulating as I read).</div><br/></div></div><div id="40316504" class="c"><input type="checkbox" id="c-40316504" checked=""/><div class="controls bullet"><span class="by">gary17the</span><span>|</span><a href="#40313530">root</a><span>|</span><a href="#40313884">parent</a><span>|</span><a href="#40321597">prev</a><span>|</span><a href="#40314119">next</a><span>|</span><label class="collapse" for="c-40316504">[-]</label><label class="expand" for="c-40316504">[1 more]</label></div><br/><div class="children"><div class="content">&gt; we may likely discover that a huge portion of [a human brain] is redundant<p>Unless one&#x27;s understanding of algorithmic inner workings of a particular black box system is actually very good, it is likely not possible not only to discard any of its state, but even implement any kind of meaningful error detection if you do discard.<p>Given the sheer size and complexity of a human brain, I feel it is actually very unlikely that we will be able to understand its inner workings to such a significant degree anytime soon. I&#x27;m not optimistic, because so far we have no idea how even laughingly simple, in comparison, AI models work[0].<p>[0] &quot;God Help Us, Let&#x27;s Try To Understand AI Monosemanticity&quot;, <a href="https:&#x2F;&#x2F;www.astralcodexten.com&#x2F;p&#x2F;god-help-us-lets-try-to-understand" rel="nofollow">https:&#x2F;&#x2F;www.astralcodexten.com&#x2F;p&#x2F;god-help-us-lets-try-to-und...</a></div><br/></div></div><div id="40314119" class="c"><input type="checkbox" id="c-40314119" checked=""/><div class="controls bullet"><span class="by">rmorey</span><span>|</span><a href="#40313530">root</a><span>|</span><a href="#40313884">parent</a><span>|</span><a href="#40316504">prev</a><span>|</span><a href="#40318985">next</a><span>|</span><label class="collapse" for="c-40314119">[-]</label><label class="expand" for="c-40314119">[3 more]</label></div><br/><div class="children"><div class="content">we are nowhere near whole human brain volume EM. the next major milestone in the field is a whole mouse brain in the next 5-10 years, which is possible but ambitious</div><br/><div id="40314214" class="c"><input type="checkbox" id="c-40314214" checked=""/><div class="controls bullet"><span class="by">falcor84</span><span>|</span><a href="#40313530">root</a><span>|</span><a href="#40314119">parent</a><span>|</span><a href="#40318985">next</a><span>|</span><label class="collapse" for="c-40314214">[-]</label><label class="expand" for="c-40314214">[2 more]</label></div><br/><div class="children"><div class="content">What am I missing? Assuming exponential growth in capability, that actually sounds very on track. If we can get from 1 cubic millimeter to a whole mouse brain in 5-10 years, why should it take more than a few extra years to scale that to a human brain?</div><br/><div id="40315278" class="c"><input type="checkbox" id="c-40315278" checked=""/><div class="controls bullet"><span class="by">rmorey</span><span>|</span><a href="#40313530">root</a><span>|</span><a href="#40314214">parent</a><span>|</span><a href="#40318985">next</a><span>|</span><label class="collapse" for="c-40315278">[-]</label><label class="expand" for="c-40315278">[1 more]</label></div><br/><div class="children"><div class="content">assuming exponential growth in capacity is a big assumption!</div><br/></div></div></div></div></div></div></div></div><div id="40318985" class="c"><input type="checkbox" id="c-40318985" checked=""/><div class="controls bullet"><span class="by">treprinum</span><span>|</span><a href="#40313530">root</a><span>|</span><a href="#40313753">parent</a><span>|</span><a href="#40313884">prev</a><span>|</span><a href="#40325676">next</a><span>|</span><label class="collapse" for="c-40318985">[-]</label><label class="expand" for="c-40318985">[1 more]</label></div><br/><div class="children"><div class="content">AI folks dream about creating superintelligence to guide our lives but all we can do is drosophilla&#x27;s brain.</div><br/></div></div></div></div><div id="40314679" class="c"><input type="checkbox" id="c-40314679" checked=""/><div class="controls bullet"><span class="by">userbinator</span><span>|</span><a href="#40313530">parent</a><span>|</span><a href="#40325676">prev</a><span>|</span><a href="#40313587">next</a><span>|</span><label class="collapse" for="c-40314679">[-]</label><label class="expand" for="c-40314679">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s <i>very</i> lossy and unreliable storage, however. To use an analogy, it&#x27;s only a huge amount of ECC that keeps things (just barely) working.</div><br/></div></div><div id="40313587" class="c"><input type="checkbox" id="c-40313587" checked=""/><div class="controls bullet"><span class="by">bahrant</span><span>|</span><a href="#40313530">parent</a><span>|</span><a href="#40314679">prev</a><span>|</span><a href="#40313977">next</a><span>|</span><label class="collapse" for="c-40313587">[-]</label><label class="expand" for="c-40313587">[1 more]</label></div><br/><div class="children"><div class="content">wow</div><br/></div></div></div></div><div id="40313977" class="c"><input type="checkbox" id="c-40313977" checked=""/><div class="controls bullet"><span class="by">theogravity</span><span>|</span><a href="#40313530">prev</a><span>|</span><a href="#40314045">next</a><span>|</span><label class="collapse" for="c-40313977">[-]</label><label class="expand" for="c-40313977">[4 more]</label></div><br/><div class="children"><div class="content">&gt; The brain fragment was taken from a 45-year-old woman when she underwent surgery to treat her epilepsy. It came from the cortex, a part of the brain involved in learning, problem-solving and processing sensory signals.<p>Wonder how they figured out which fragment to cut out.</div><br/><div id="40314390" class="c"><input type="checkbox" id="c-40314390" checked=""/><div class="controls bullet"><span class="by">pfdietz</span><span>|</span><a href="#40313977">parent</a><span>|</span><a href="#40314045">next</a><span>|</span><label class="collapse" for="c-40314390">[-]</label><label class="expand" for="c-40314390">[3 more]</label></div><br/><div class="children"><div class="content">I imagine they determined the focus of the seizures by electrical techniques.<p>I worry this might make the sample biased in some way.</div><br/><div id="40324377" class="c"><input type="checkbox" id="c-40324377" checked=""/><div class="controls bullet"><span class="by">creer</span><span>|</span><a href="#40313977">root</a><span>|</span><a href="#40314390">parent</a><span>|</span><a href="#40322574">next</a><span>|</span><label class="collapse" for="c-40324377">[-]</label><label class="expand" for="c-40324377">[1 more]</label></div><br/><div class="children"><div class="content">Considering the success of this work, I doubt this is the last such cubic millimeter to be mapped. Or perhaps the next one at even higher resolution. No worries.</div><br/></div></div><div id="40322574" class="c"><input type="checkbox" id="c-40322574" checked=""/><div class="controls bullet"><span class="by">notfed</span><span>|</span><a href="#40313977">root</a><span>|</span><a href="#40314390">parent</a><span>|</span><a href="#40324377">prev</a><span>|</span><a href="#40314045">next</a><span>|</span><label class="collapse" for="c-40322574">[-]</label><label class="expand" for="c-40322574">[1 more]</label></div><br/><div class="children"><div class="content">Imagine all the conclusions being made from a 1cm cube of epileptic neurons.</div><br/></div></div></div></div></div></div><div id="40314045" class="c"><input type="checkbox" id="c-40314045" checked=""/><div class="controls bullet"><span class="by">blincoln</span><span>|</span><a href="#40313977">prev</a><span>|</span><a href="#40314604">next</a><span>|</span><label class="collapse" for="c-40314045">[-]</label><label class="expand" for="c-40314045">[7 more]</label></div><br/><div class="children"><div class="content">Why did the researchers use ML models to do the reconstruction and risk getting completely incorrect, hallucinated results when reconstructing a 3D volume accurately using 2D slices is a well-researched field already?</div><br/><div id="40314113" class="c"><input type="checkbox" id="c-40314113" checked=""/><div class="controls bullet"><span class="by">VikingCoder</span><span>|</span><a href="#40314045">parent</a><span>|</span><a href="#40314195">next</a><span>|</span><label class="collapse" for="c-40314113">[-]</label><label class="expand" for="c-40314113">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m guessing a registration problem.<p>If all of the layers were guaranteed to be orthographic with no twisting, shearing, scaling, squishing, with a consistent origin...  Then yeah, there&#x27;s a huge number of ways to just render that data.<p>But if you physically slice layers first, and scan them second, there are all manner of physical processes that can make normal image stacking fail miserably.</div><br/></div></div><div id="40314195" class="c"><input type="checkbox" id="c-40314195" checked=""/><div class="controls bullet"><span class="by">momojo</span><span>|</span><a href="#40314045">parent</a><span>|</span><a href="#40314113">prev</a><span>|</span><a href="#40314103">next</a><span>|</span><label class="collapse" for="c-40314195">[-]</label><label class="expand" for="c-40314195">[2 more]</label></div><br/><div class="children"><div class="content">Although the article mentions Artificial Intelligence, their paper[1] never actually mentions that term, and instead talks about their machine learning techniques. AFAIK, ML for things like cell-segmentation are a solved problem [2].<p>[1] <a href="https:&#x2F;&#x2F;www.biorxiv.org&#x2F;content&#x2F;10.1101&#x2F;2021.05.29.446289v4.full.pdf" rel="nofollow">https:&#x2F;&#x2F;www.biorxiv.org&#x2F;content&#x2F;10.1101&#x2F;2021.05.29.446289v4....</a>
[2] <a href="https:&#x2F;&#x2F;www.ilastik.org&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.ilastik.org&#x2F;</a></div><br/><div id="40314213" class="c"><input type="checkbox" id="c-40314213" checked=""/><div class="controls bullet"><span class="by">rmorey</span><span>|</span><a href="#40314045">root</a><span>|</span><a href="#40314195">parent</a><span>|</span><a href="#40314103">next</a><span>|</span><label class="collapse" for="c-40314213">[-]</label><label class="expand" for="c-40314213">[1 more]</label></div><br/><div class="children"><div class="content">There are extremely effective techniques, but it is not really solved. The current techniques still require human proofreading to correct errors. Only a fraction of this particular dataset is proofread.</div><br/></div></div></div></div><div id="40314103" class="c"><input type="checkbox" id="c-40314103" checked=""/><div class="controls bullet"><span class="by">rmorey</span><span>|</span><a href="#40314045">parent</a><span>|</span><a href="#40314195">prev</a><span>|</span><a href="#40314270">next</a><span>|</span><label class="collapse" for="c-40314103">[-]</label><label class="expand" for="c-40314103">[1 more]</label></div><br/><div class="children"><div class="content">The methods used here are state of the art. The problem is not just turning 2D slices into a 3D volume, the problem is, given the 3D volume, determining boundaries between (and therefore the 3d shape of) objects (i.e. neurons, glia, etc) and identifying synapses</div><br/></div></div><div id="40314270" class="c"><input type="checkbox" id="c-40314270" checked=""/><div class="controls bullet"><span class="by">layer8</span><span>|</span><a href="#40314045">parent</a><span>|</span><a href="#40314103">prev</a><span>|</span><a href="#40314065">next</a><span>|</span><label class="collapse" for="c-40314270">[-]</label><label class="expand" for="c-40314270">[1 more]</label></div><br/><div class="children"><div class="content">Regarding the risk, as noted in the article, they are manually “proofreading” the construction.</div><br/></div></div><div id="40314065" class="c"><input type="checkbox" id="c-40314065" checked=""/><div class="controls bullet"><span class="by">scotty79</span><span>|</span><a href="#40314045">parent</a><span>|</span><a href="#40314270">prev</a><span>|</span><a href="#40314604">next</a><span>|</span><label class="collapse" for="c-40314065">[-]</label><label class="expand" for="c-40314065">[1 more]</label></div><br/><div class="children"><div class="content">Maybe it&#x27;s not about reconstructing a volume but about recognizing neurons within that volume.</div><br/></div></div></div></div><div id="40314604" class="c"><input type="checkbox" id="c-40314604" checked=""/><div class="controls bullet"><span class="by">brandonmenc</span><span>|</span><a href="#40314045">prev</a><span>|</span><a href="#40314837">next</a><span>|</span><label class="collapse" for="c-40314604">[-]</label><label class="expand" for="c-40314604">[5 more]</label></div><br/><div class="children"><div class="content">Another proof point that AGI is probably not possible.<p>Growing actual bio brains is just way easier. Its never going to happen in silicon.<p>Every machine will just have a cubic centimeter block of neuro meat embedded in it somewhere.</div><br/><div id="40314691" class="c"><input type="checkbox" id="c-40314691" checked=""/><div class="controls bullet"><span class="by">mr_toad</span><span>|</span><a href="#40314604">parent</a><span>|</span><a href="#40324394">next</a><span>|</span><label class="collapse" for="c-40314691">[-]</label><label class="expand" for="c-40314691">[1 more]</label></div><br/><div class="children"><div class="content">You’d have to train them individually.  One advantage of ANNs is that you can train them and then ship the model to anyone with a GPU.</div><br/></div></div><div id="40324394" class="c"><input type="checkbox" id="c-40324394" checked=""/><div class="controls bullet"><span class="by">creer</span><span>|</span><a href="#40314604">parent</a><span>|</span><a href="#40314691">prev</a><span>|</span><a href="#40319966">next</a><span>|</span><label class="collapse" for="c-40324394">[-]</label><label class="expand" for="c-40324394">[1 more]</label></div><br/><div class="children"><div class="content">No reason for an AGI not to have a few cubes of goo slotted in here and there. But yeah, because of the training issue, they might be coprocessors or storage or something.</div><br/></div></div><div id="40319966" class="c"><input type="checkbox" id="c-40319966" checked=""/><div class="controls bullet"><span class="by">myrmidon</span><span>|</span><a href="#40314604">parent</a><span>|</span><a href="#40324394">prev</a><span>|</span><a href="#40314669">next</a><span>|</span><label class="collapse" for="c-40319966">[-]</label><label class="expand" for="c-40319966">[1 more]</label></div><br/><div class="children"><div class="content">Hard disagree on this.<p>I strongly believe that there is a TON of potential for synthetic biology-- but not in computation.<p>People just forget how superior current silicon is for running algorithms; if you consider e.g. a 17 by 17 digit multiplication (double precision), then a current CPU can do that in the time it takes for light to reach your eye from the screen in front of you (!!!). During all the completely unavoidable latency (the time any visual stimulus takes to propagate and reach your consciousness), the CPU does <i>millions</i> more of those operations.<p>Any biocomputer would be limited to low-bandwidth, ultra high latency operations purely by design.<p>If you solely consider AGI as application, where abysmal latency and low input bandwidth might be acceptable, then it still appears to be extremely unlikely that we are going to reach that goal via synthetic biology; our current capabilities are just disappointing and not looking like they are gonna improve quickly.<p>Building artificial neural networks on silicon, on the other hand, capitalises on the almost exponential gains we made during the last decades, and already produces results that compare to say, a schoolchild, quite favorably; I&#x27;d argue that current LLM based approaches already eclipse the intellectual capabilities of ANY animal, for example. Artificial bio brains, on the other hand, are basically competing with worms right now...<p>Also consider that even though our brains might look daunting from a pure &quot;upper bound on required complexity&#x2F;number of connections&quot; point of view, these limits are very unlikely to be applicable, because they confound implementation details, redundancy and irrelevant details. And we have precise bound on other parameters, that our technology already matches easily:<p>1) Artificial intelligence architecture can be bootstrapped from a CD-ROM worth of data (~700MiB for the whole human genome-- even that is mostly redundant)<p>2) Bandwidth for training is quite low, even when compressing the ~20year training time for an actual human into a more manageable timeframe<p>3) Operating power does not require more than ~20W.<p>4) No understanding was necessary to create human intelligence-- its purely a result of an iterative process (evolution).<p>Also consider human flight as an analogy: we did not achieve that by copying beating wings, powered by dozens of muscle groups and complex control algorithms-- those are just implementation details of existing biological systems. All we needed was the wing-concept itself and a bunch of trial-and-error.</div><br/></div></div><div id="40314669" class="c"><input type="checkbox" id="c-40314669" checked=""/><div class="controls bullet"><span class="by">skulk</span><span>|</span><a href="#40314604">parent</a><span>|</span><a href="#40319966">prev</a><span>|</span><a href="#40314837">next</a><span>|</span><label class="collapse" for="c-40314669">[-]</label><label class="expand" for="c-40314669">[1 more]</label></div><br/><div class="children"><div class="content">I agree, mostly because it&#x27;s already being done!<p><a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=V2YDApNRK3g" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=V2YDApNRK3g</a><p><a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=bEXefdbQDjw" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=bEXefdbQDjw</a></div><br/></div></div></div></div><div id="40314837" class="c"><input type="checkbox" id="c-40314837" checked=""/><div class="controls bullet"><span class="by">greentext</span><span>|</span><a href="#40314604">prev</a><span>|</span><a href="#40317089">next</a><span>|</span><label class="collapse" for="c-40314837">[-]</label><label class="expand" for="c-40314837">[1 more]</label></div><br/><div class="children"><div class="content">It looks like spaghetti code.</div><br/></div></div><div id="40317089" class="c"><input type="checkbox" id="c-40317089" checked=""/><div class="controls bullet"><span class="by">dvfjsdhgfv</span><span>|</span><a href="#40314837">prev</a><span>|</span><a href="#40315131">next</a><span>|</span><label class="collapse" for="c-40317089">[-]</label><label class="expand" for="c-40317089">[2 more]</label></div><br/><div class="children"><div class="content">Why do these neurons have flat &quot;heads&quot;?</div><br/><div id="40325746" class="c"><input type="checkbox" id="c-40325746" checked=""/><div class="controls bullet"><span class="by">ewchris</span><span>|</span><a href="#40317089">parent</a><span>|</span><a href="#40315131">next</a><span>|</span><label class="collapse" for="c-40325746">[-]</label><label class="expand" for="c-40325746">[1 more]</label></div><br/><div class="children"><div class="content">Edge of the dataset.</div><br/></div></div></div></div><div id="40315131" class="c"><input type="checkbox" id="c-40315131" checked=""/><div class="controls bullet"><span class="by">idontwantthis</span><span>|</span><a href="#40317089">prev</a><span>|</span><a href="#40313480">next</a><span>|</span><label class="collapse" for="c-40315131">[-]</label><label class="expand" for="c-40315131">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Jain’s team then built artificial-intelligence models that were able to stitch the microscope images together to reconstruct the whole sample in 3D<p>How do they know if their AI did it correctly or not?</div><br/></div></div><div id="40313480" class="c"><input type="checkbox" id="c-40313480" checked=""/><div class="controls bullet"><span class="by">CSSer</span><span>|</span><a href="#40315131">prev</a><span>|</span><a href="#40313874">next</a><span>|</span><label class="collapse" for="c-40313480">[-]</label><label class="expand" for="c-40313480">[1 more]</label></div><br/><div class="children"><div class="content">For some people, this is all you need (sorry, couldn’t resist)!</div><br/></div></div><div id="40313874" class="c"><input type="checkbox" id="c-40313874" checked=""/><div class="controls bullet"><span class="by">fractal618</span><span>|</span><a href="#40313480">prev</a><span>|</span><label class="collapse" for="c-40313874">[-]</label><label class="expand" for="c-40313874">[1 more]</label></div><br/><div class="children"><div class="content">Fascinating! I wonder how different that is from the mind of a man haha</div><br/></div></div></div></div></div></div></div></body></html>