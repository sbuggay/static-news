<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1683190851271" as="style"/><link rel="stylesheet" href="styles.css?v=1683190851271"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.latent.space/p/reza-shabani#details">Replit&#x27;s new Code LLM: Open Source, 77% smaller than Codex, trained in 1 week</a> <span class="domain">(<a href="https://www.latent.space">www.latent.space</a>)</span></div><div class="subtext"><span>swyx</span> | <span>208 comments</span></div><br/><div><div id="35803714" class="c"><input type="checkbox" id="c-35803714" checked=""/><div class="controls bullet"><span class="by">amasad</span><span>|</span><a href="#35806045">next</a><span>|</span><label class="collapse" for="c-35803714">[-]</label><label class="expand" for="c-35803714">[39 more]</label></div><br/><div class="children"><div class="content">Some links:<p>- Repo: <a href="https:&#x2F;&#x2F;github.com&#x2F;replit&#x2F;ReplitLM&#x2F;tree&#x2F;main&#x2F;replit-code-v1-3b">https:&#x2F;&#x2F;github.com&#x2F;replit&#x2F;ReplitLM&#x2F;tree&#x2F;main&#x2F;replit-code-v1-...</a><p>- HuggingFace: <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;replit&#x2F;replit-code-v1-3b" rel="nofollow">https:&#x2F;&#x2F;huggingface.co&#x2F;replit&#x2F;replit-code-v1-3b</a><p>- Demo: <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;replit&#x2F;replit-code-v1-3b-demo" rel="nofollow">https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;replit&#x2F;replit-code-v1-3b-demo</a><p>- Early benchmark results: <a href="https:&#x2F;&#x2F;twitter.com&#x2F;amasad&#x2F;status&#x2F;1651019556423598081" rel="nofollow">https:&#x2F;&#x2F;twitter.com&#x2F;amasad&#x2F;status&#x2F;1651019556423598081</a><p>A lot about this project was surprising. We knew it was going to be good, but didn&#x27;t expect to be this good -- especially surprising was the finetuned performance boost, and the fact that the model is decent at language tasks and reasoning (in some cases much better than much larger general-purpose models).<p>It feels like there is a lot more to do with this model, and I have a suspicion you can even make a half-decent chatbot (at least one focused on code) by finetuning it on conversation (and&#x2F;or instruction) datasets.<p>Will follow up with a more comprehensive technical report and the UL2R version (fill-in-the-middle support).</div><br/><div id="35804612" class="c"><input type="checkbox" id="c-35804612" checked=""/><div class="controls bullet"><span class="by">newhouseb</span><span>|</span><a href="#35803714">parent</a><span>|</span><a href="#35806920">next</a><span>|</span><label class="collapse" for="c-35804612">[-]</label><label class="expand" for="c-35804612">[4 more]</label></div><br/><div class="children"><div class="content">First - thank you for open sourcing this! It&#x27;s a real gift to the community to have a model intended for &quot;commercial use&quot; that&#x27;s actually licensed as such.<p>I&#x27;d be very interested to hear about the choice&#x2F;evaluation of the ALiBi approach for positional embedding (perhaps in the technical report).<p>My intuition suggests that while this allows for better generalizability for longer sequence lengths, it penalizes scenarios where an LLM might need to check for things like a function signature far away from where the next token is generated. My initial testing of this model tracks with this intuition but that&#x27;s by no means a rigorous evaluation.</div><br/><div id="35807172" class="c"><input type="checkbox" id="c-35807172" checked=""/><div class="controls bullet"><span class="by">ofirpress</span><span>|</span><a href="#35803714">root</a><span>|</span><a href="#35804612">parent</a><span>|</span><a href="#35806920">next</a><span>|</span><label class="collapse" for="c-35807172">[-]</label><label class="expand" for="c-35807172">[3 more]</label></div><br/><div class="children"><div class="content">(I wrote ALiBi)
You can read the paper here <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2108.12409" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2108.12409</a><p>While intuitively it does seem like ALiBi would make it hard for the model to attend to things that are far away, in many scenarios we&#x27;ve tested with different models trained on different datasets, ALiBi <i>always</i> performs better than sinusoidal, rotary, and other embedding types, even when we&#x27;re not using it to extrapolate to longer sequence lengths.<p>These findings have been confirmed by others, including by the BLOOM open source LM project.</div><br/><div id="35808034" class="c"><input type="checkbox" id="c-35808034" checked=""/><div class="controls bullet"><span class="by">newhouseb</span><span>|</span><a href="#35803714">root</a><span>|</span><a href="#35807172">parent</a><span>|</span><a href="#35806920">next</a><span>|</span><label class="collapse" for="c-35808034">[-]</label><label class="expand" for="c-35808034">[2 more]</label></div><br/><div class="children"><div class="content">Small world!<p>Thanks for the link (which I&#x27;ve now skimmed beyond the abstract). What wasn&#x27;t obvious to me from the abstract is that different attention heads have different penalty strengths, so if some prediction task requires long range dependencies you might expect one of the less-penalized heads to end up specializing. I wonder what would happen if the penalty for one head is zero? (The paper suggests this might&#x27;ve been tried and just made things worse, but unclear)<p>I must admit that this is a wonderfully elegant (and interpretable) way to do this... much more intuitive (to me at least, a wannabe practitioner) than all of the trig-based embeddings.</div><br/><div id="35810786" class="c"><input type="checkbox" id="c-35810786" checked=""/><div class="controls bullet"><span class="by">ofirpress</span><span>|</span><a href="#35803714">root</a><span>|</span><a href="#35808034">parent</a><span>|</span><a href="#35806920">next</a><span>|</span><label class="collapse" for="c-35810786">[-]</label><label class="expand" for="c-35810786">[1 more]</label></div><br/><div class="children"><div class="content">&gt; so if some prediction task requires long range dependencies you might expect one of the less-penalized heads to end up specializing
Exactly. You have heads that focus on content nearby and ones that focus on stuff that is far away.<p>&gt;  I wonder what would happen if the penalty for one head is zero? (The paper suggests this might&#x27;ve been tried and just made things worse, but unclear)
Yup, this is something we tried. Making one of the heads zero doesn&#x27;t improve or degrade performance.<p>&gt;I must admit that this is a wonderfully elegant (and interpretable) way to do this... much more intuitive (to me at least, a wannabe practitioner) than all of the trig-based embeddings.<p>Thanks so much!!</div><br/></div></div></div></div></div></div></div></div><div id="35806920" class="c"><input type="checkbox" id="c-35806920" checked=""/><div class="controls bullet"><span class="by">kir-gadjello</span><span>|</span><a href="#35803714">parent</a><span>|</span><a href="#35804612">prev</a><span>|</span><a href="#35805103">next</a><span>|</span><label class="collapse" for="c-35806920">[-]</label><label class="expand" for="c-35806920">[9 more]</label></div><br/><div class="children"><div class="content">Impressive model, thank you for releasing it under a business-friendly license!<p>Have you considered using Google&#x27;s sparse &quot;scaling transformer&quot; architecture as the base? Even at 3B scale it can generate 3-4x more tokens per FLOP while being competitive at perplexity with a dense transformer. I think OpenAI uses a variant of it in their ChatGPT-3.5-Turbo product.<p>Here is the paper <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2111.12763" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2111.12763</a>
and the implementation <a href="https:&#x2F;&#x2F;github.com&#x2F;google&#x2F;trax&#x2F;blob&#x2F;master&#x2F;trax&#x2F;models&#x2F;research&#x2F;terraformer.py">https:&#x2F;&#x2F;github.com&#x2F;google&#x2F;trax&#x2F;blob&#x2F;master&#x2F;trax&#x2F;models&#x2F;resea...</a> if you are interested.<p>Hope you get to look into this!</div><br/><div id="35807044" class="c"><input type="checkbox" id="c-35807044" checked=""/><div class="controls bullet"><span class="by">b33j0r</span><span>|</span><a href="#35803714">root</a><span>|</span><a href="#35806920">parent</a><span>|</span><a href="#35810079">next</a><span>|</span><label class="collapse" for="c-35807044">[-]</label><label class="expand" for="c-35807044">[1 more]</label></div><br/><div class="children"><div class="content">Thank you for releasing the weights along with the announcement. The posts that made great headlines, but “weights are on their way!”<p>Like why did we even get excited? This? Great work.</div><br/></div></div><div id="35810079" class="c"><input type="checkbox" id="c-35810079" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#35803714">root</a><span>|</span><a href="#35806920">parent</a><span>|</span><a href="#35807044">prev</a><span>|</span><a href="#35807457">next</a><span>|</span><label class="collapse" for="c-35810079">[-]</label><label class="expand" for="c-35810079">[4 more]</label></div><br/><div class="children"><div class="content">&gt; I think OpenAI uses a variant of it in their ChatGPT-3.5-Turbo product.<p>is that a guess or is there a source? im curious to read more</div><br/><div id="35810253" class="c"><input type="checkbox" id="c-35810253" checked=""/><div class="controls bullet"><span class="by">kir-gadjello</span><span>|</span><a href="#35803714">root</a><span>|</span><a href="#35810079">parent</a><span>|</span><a href="#35807457">next</a><span>|</span><label class="collapse" for="c-35810253">[-]</label><label class="expand" for="c-35810253">[3 more]</label></div><br/><div class="children"><div class="content">It is a guess informed by some familiarity with the literature and by going over the papers authored by researchers credited in the OpenAI&#x27;s &quot;GPT-4 contributors&quot; web page.<p>I have an expanded list of foundational research that is likely to serve as basis for gpt4 here in my blog: <a href="https:&#x2F;&#x2F;kir-gadjello.github.io&#x2F;posts&#x2F;gpt4-some-technical-hypotheses&#x2F;" rel="nofollow">https:&#x2F;&#x2F;kir-gadjello.github.io&#x2F;posts&#x2F;gpt4-some-technical-hyp...</a><p>Hope it helps!</div><br/><div id="35811043" class="c"><input type="checkbox" id="c-35811043" checked=""/><div class="controls bullet"><span class="by">blueblimp</span><span>|</span><a href="#35803714">root</a><span>|</span><a href="#35810253">parent</a><span>|</span><a href="#35812194">next</a><span>|</span><label class="collapse" for="c-35811043">[-]</label><label class="expand" for="c-35811043">[1 more]</label></div><br/><div class="children"><div class="content">Interesting resource. I had been wondering whether anyone had tried to compile such a list.</div><br/></div></div><div id="35812194" class="c"><input type="checkbox" id="c-35812194" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#35803714">root</a><span>|</span><a href="#35810253">parent</a><span>|</span><a href="#35811043">prev</a><span>|</span><a href="#35807457">next</a><span>|</span><label class="collapse" for="c-35812194">[-]</label><label class="expand" for="c-35812194">[1 more]</label></div><br/><div class="children"><div class="content">thank you! glad i asked</div><br/></div></div></div></div></div></div><div id="35807457" class="c"><input type="checkbox" id="c-35807457" checked=""/><div class="controls bullet"><span class="by">chaxor</span><span>|</span><a href="#35803714">root</a><span>|</span><a href="#35806920">parent</a><span>|</span><a href="#35810079">prev</a><span>|</span><a href="#35805103">next</a><span>|</span><label class="collapse" for="c-35807457">[-]</label><label class="expand" for="c-35807457">[3 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think it&#x27;s a business friendly license?</div><br/><div id="35809327" class="c"><input type="checkbox" id="c-35809327" checked=""/><div class="controls bullet"><span class="by">kir-gadjello</span><span>|</span><a href="#35803714">root</a><span>|</span><a href="#35807457">parent</a><span>|</span><a href="#35805103">next</a><span>|</span><label class="collapse" for="c-35809327">[-]</label><label class="expand" for="c-35809327">[2 more]</label></div><br/><div class="children"><div class="content">It allows for modifications and commercial use: <a href="https:&#x2F;&#x2F;creativecommons.org&#x2F;licenses&#x2F;by-sa&#x2F;4.0&#x2F;" rel="nofollow">https:&#x2F;&#x2F;creativecommons.org&#x2F;licenses&#x2F;by-sa&#x2F;4.0&#x2F;</a><p>&gt;You are free to:<p>&gt;Share — copy and redistribute the material in any medium or format<p>&gt;Adapt — remix, transform, and build upon the material<p>&gt;for any purpose, even commercially.<p>Compare this to the latest release from StabilityAI lab DeepFloyd, &quot;IF&quot;, which in addition to various restrictive clauses strictly prohibits commercial use: <a href="https:&#x2F;&#x2F;github.com&#x2F;deep-floyd&#x2F;IF&#x2F;blob&#x2F;develop&#x2F;LICENSE-MODEL">https:&#x2F;&#x2F;github.com&#x2F;deep-floyd&#x2F;IF&#x2F;blob&#x2F;develop&#x2F;LICENSE-MODEL</a><p>Repl.it&#x27;s release is as open as it gets these days, in my book.</div><br/><div id="35811766" class="c"><input type="checkbox" id="c-35811766" checked=""/><div class="controls bullet"><span class="by">LukeShu</span><span>|</span><a href="#35803714">root</a><span>|</span><a href="#35809327">parent</a><span>|</span><a href="#35805103">next</a><span>|</span><label class="collapse" for="c-35811766">[-]</label><label class="expand" for="c-35811766">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a copyleft license; and lots of folks on HN seem to think that copyleft, while being open, isn&#x27;t business friendly.</div><br/></div></div></div></div></div></div></div></div><div id="35805103" class="c"><input type="checkbox" id="c-35805103" checked=""/><div class="controls bullet"><span class="by">sputknick</span><span>|</span><a href="#35803714">parent</a><span>|</span><a href="#35806920">prev</a><span>|</span><a href="#35805317">next</a><span>|</span><label class="collapse" for="c-35805103">[-]</label><label class="expand" for="c-35805103">[11 more]</label></div><br/><div class="children"><div class="content">What does &quot;fine tuning&quot; mean in this context? Does it mean you fine-tuned it on a specific code repository, or collection of code repositories and then had it do work in those repositories?</div><br/><div id="35805232" class="c"><input type="checkbox" id="c-35805232" checked=""/><div class="controls bullet"><span class="by">amasad</span><span>|</span><a href="#35803714">root</a><span>|</span><a href="#35805103">parent</a><span>|</span><a href="#35805364">next</a><span>|</span><label class="collapse" for="c-35805232">[-]</label><label class="expand" for="c-35805232">[9 more]</label></div><br/><div class="children"><div class="content">Broadly finetuning is any post pretraining training. Most of the time it is used in the context of fitting a more narrow task. In our case, it was the same training objective as the pretraining but meant to be more representative of what Replit users like to code. However, we were surprised by how well it boosted overall performance. Best guess: it&#x27;s a) novel data and b) the model could take even more training!!</div><br/><div id="35805348" class="c"><input type="checkbox" id="c-35805348" checked=""/><div class="controls bullet"><span class="by">spenczar5</span><span>|</span><a href="#35803714">root</a><span>|</span><a href="#35805232">parent</a><span>|</span><a href="#35807851">next</a><span>|</span><label class="collapse" for="c-35805348">[-]</label><label class="expand" for="c-35805348">[4 more]</label></div><br/><div class="children"><div class="content">How feasible and effective would it be to fine-tune a model against an organization&#x27;s private source code, resulting in an &quot;internal&quot; model that knows how to work with that org&#x27;s stuff?<p>Could you, say, fine-tune the model every week with the latest merges? Every hour?</div><br/><div id="35805694" class="c"><input type="checkbox" id="c-35805694" checked=""/><div class="controls bullet"><span class="by">pyth0</span><span>|</span><a href="#35803714">root</a><span>|</span><a href="#35805348">parent</a><span>|</span><a href="#35806145">next</a><span>|</span><label class="collapse" for="c-35805694">[-]</label><label class="expand" for="c-35805694">[2 more]</label></div><br/><div class="children"><div class="content">Finetuning is a relatively quick process. Training the base model is the expensive part (can take weeks and huge amounts of compute), whereas finetuning usually is only on the last few layers and can be done with much less resources. You could definitely have a &quot;nightly&quot; finetune model that is retrained every day or so.</div><br/><div id="35809235" class="c"><input type="checkbox" id="c-35809235" checked=""/><div class="controls bullet"><span class="by">rattray</span><span>|</span><a href="#35803714">root</a><span>|</span><a href="#35805694">parent</a><span>|</span><a href="#35806145">next</a><span>|</span><label class="collapse" for="c-35809235">[-]</label><label class="expand" for="c-35809235">[1 more]</label></div><br/><div class="children"><div class="content">Interesting - how would that work for a company that wanted to run their own codex model, on-prem, trained on their own code? Perhaps also trained on their dependencies?</div><br/></div></div></div></div><div id="35806145" class="c"><input type="checkbox" id="c-35806145" checked=""/><div class="controls bullet"><span class="by">naderkhalil</span><span>|</span><a href="#35803714">root</a><span>|</span><a href="#35805348">parent</a><span>|</span><a href="#35805694">prev</a><span>|</span><a href="#35807851">next</a><span>|</span><label class="collapse" for="c-35806145">[-]</label><label class="expand" for="c-35806145">[1 more]</label></div><br/><div class="children"><div class="content">Finetuning a smaller model leading to better performance seems like a significant finding that&#x27;ll lead to a lot of companies fine-tuning their own internal &quot;ChatGPT&quot;s</div><br/></div></div></div></div><div id="35807851" class="c"><input type="checkbox" id="c-35807851" checked=""/><div class="controls bullet"><span class="by">sanderjd</span><span>|</span><a href="#35803714">root</a><span>|</span><a href="#35805232">parent</a><span>|</span><a href="#35805348">prev</a><span>|</span><a href="#35807674">next</a><span>|</span><label class="collapse" for="c-35807851">[-]</label><label class="expand" for="c-35807851">[3 more]</label></div><br/><div class="children"><div class="content">You seem to know your stuff some, so I&#x27;ll ask you a question on this: Are there any good books on all the different approaches in this space, or is it all too new and fast moving for such a thing?</div><br/><div id="35810299" class="c"><input type="checkbox" id="c-35810299" checked=""/><div class="controls bullet"><span class="by">nl</span><span>|</span><a href="#35803714">root</a><span>|</span><a href="#35807851">parent</a><span>|</span><a href="#35811671">next</a><span>|</span><label class="collapse" for="c-35810299">[-]</label><label class="expand" for="c-35810299">[1 more]</label></div><br/><div class="children"><div class="content">There are no books on <i>Large</i> LMs but almost any resource about neural networks covers fine tuning. I like the FastAI courses, and these do cover language models.</div><br/></div></div><div id="35811671" class="c"><input type="checkbox" id="c-35811671" checked=""/><div class="controls bullet"><span class="by">osanseviero</span><span>|</span><a href="#35803714">root</a><span>|</span><a href="#35807851">parent</a><span>|</span><a href="#35810299">prev</a><span>|</span><a href="#35807674">next</a><span>|</span><label class="collapse" for="c-35811671">[-]</label><label class="expand" for="c-35811671">[1 more]</label></div><br/><div class="children"><div class="content">You can also check the NLP with transformers book</div><br/></div></div></div></div><div id="35807674" class="c"><input type="checkbox" id="c-35807674" checked=""/><div class="controls bullet"><span class="by">titaniczero</span><span>|</span><a href="#35803714">root</a><span>|</span><a href="#35805232">parent</a><span>|</span><a href="#35807851">prev</a><span>|</span><a href="#35805364">next</a><span>|</span><label class="collapse" for="c-35807674">[-]</label><label class="expand" for="c-35807674">[1 more]</label></div><br/><div class="children"><div class="content">When you fine-tune it, do you train just the head&#x2F;last few layers or do you also unfreeze the model afterwards and retrain the whole model with a very small LR for a few epochs?</div><br/></div></div></div></div><div id="35805364" class="c"><input type="checkbox" id="c-35805364" checked=""/><div class="controls bullet"><span class="by">WinLychee</span><span>|</span><a href="#35803714">root</a><span>|</span><a href="#35805103">parent</a><span>|</span><a href="#35805232">prev</a><span>|</span><a href="#35805317">next</a><span>|</span><label class="collapse" for="c-35805364">[-]</label><label class="expand" for="c-35805364">[1 more]</label></div><br/><div class="children"><div class="content">You can take a network and its weights that someone else trained, and use that pretrained network to train on your own data, which is likely to be a better starting point than random weights.</div><br/></div></div></div></div><div id="35805317" class="c"><input type="checkbox" id="c-35805317" checked=""/><div class="controls bullet"><span class="by">spenczar5</span><span>|</span><a href="#35803714">parent</a><span>|</span><a href="#35805103">prev</a><span>|</span><a href="#35804428">next</a><span>|</span><label class="collapse" for="c-35805317">[-]</label><label class="expand" for="c-35805317">[2 more]</label></div><br/><div class="children"><div class="content">How is this code licensed? I didn&#x27;t see a license in the repo. It looks interesting!</div><br/><div id="35805517" class="c"><input type="checkbox" id="c-35805517" checked=""/><div class="controls bullet"><span class="by">dgacmu</span><span>|</span><a href="#35803714">root</a><span>|</span><a href="#35805317">parent</a><span>|</span><a href="#35804428">next</a><span>|</span><label class="collapse" for="c-35805517">[-]</label><label class="expand" for="c-35805517">[1 more]</label></div><br/><div class="children"><div class="content">The README indicates:<p>The base model checkpoint is licensed under the Creative Commons license (CC BY-SA-4.0). Under the license, you must give credit to Replit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests that Replit endorses you or your use.</div><br/></div></div></div></div><div id="35804428" class="c"><input type="checkbox" id="c-35804428" checked=""/><div class="controls bullet"><span class="by">letitgo12345</span><span>|</span><a href="#35803714">parent</a><span>|</span><a href="#35805317">prev</a><span>|</span><a href="#35804101">next</a><span>|</span><label class="collapse" for="c-35804428">[-]</label><label class="expand" for="c-35804428">[5 more]</label></div><br/><div class="children"><div class="content">Doesn&#x27;t the Stack contain HumanEval? So you&#x27;re basically comparing numbers on the pretraining data.</div><br/><div id="35804634" class="c"><input type="checkbox" id="c-35804634" checked=""/><div class="controls bullet"><span class="by">amasad</span><span>|</span><a href="#35803714">root</a><span>|</span><a href="#35804428">parent</a><span>|</span><a href="#35806152">next</a><span>|</span><label class="collapse" for="c-35804634">[-]</label><label class="expand" for="c-35804634">[2 more]</label></div><br/><div class="children"><div class="content">Can&#x27;t find it now but pretty sure BigCode said somewhere they explicitly looked for it and removed it. Also subjective measure does match up to the benchmark. Our finetuned model performed +50% on HumanEval and then when using it felt at least that much improved.</div><br/><div id="35808533" class="c"><input type="checkbox" id="c-35808533" checked=""/><div class="controls bullet"><span class="by">godelski</span><span>|</span><a href="#35803714">root</a><span>|</span><a href="#35804634">parent</a><span>|</span><a href="#35806152">next</a><span>|</span><label class="collapse" for="c-35808533">[-]</label><label class="expand" for="c-35808533">[1 more]</label></div><br/><div class="children"><div class="content">You can view the prompts, solutions, and checks here[0]. See my sibling comment (to yours) where I quote the Human Eval paper and do some more analysis. But I think if you look at [0] you&#x27;ll see that these aren&#x27;t really unique problems and are likely to have large repetitions in the dataset. I should add to that comment to include the dataset[1] (too late to edit) where they mention that they just scrape all of GitHub (Jan 1 2015 - Mar 31 2022). They do exact and near de-duplicate but near de-duplication is messy.<p>&gt; We implement near-deduplication in our pre-processing pipeline on top of exact
deduplication. We first split the files into words&#x2F;tokens based on non-alphanumeric characters and remove files with fewer than 10 tokens. Next, we compute the MinHash  with 256 permutations of all documents, and use Locality Sensitive Hashing to find clusters of duplicates. We further reduce these clusters by ensuring that each file in the original cluster is similar to at least one other file in the reduced cluster. We consider two files similar when their Jaccard similarity exceeds 0.85.<p>Near-duplicates are still difficult to measure. So we should expect duplication, and it should be proportional to the number of samples we have (even if the same variance, but I&#x27;d wager higher variance with larger duplications).<p>[0] <a href="https:&#x2F;&#x2F;github.com&#x2F;openai&#x2F;code-align-evals-data&#x2F;tree&#x2F;97446d992c3785d6605f1500b2c9b95d042e7b9c&#x2F;human_eval">https:&#x2F;&#x2F;github.com&#x2F;openai&#x2F;code-align-evals-data&#x2F;tree&#x2F;97446d9...</a><p>[1] <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2211.15533" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2211.15533</a></div><br/></div></div></div></div><div id="35806152" class="c"><input type="checkbox" id="c-35806152" checked=""/><div class="controls bullet"><span class="by">godelski</span><span>|</span><a href="#35803714">root</a><span>|</span><a href="#35804428">parent</a><span>|</span><a href="#35804634">prev</a><span>|</span><a href="#35804101">next</a><span>|</span><label class="collapse" for="c-35806152">[-]</label><label class="expand" for="c-35806152">[2 more]</label></div><br/><div class="children"><div class="content">My favorite line from the HumanEval paper[0]<p>&gt; It is important for these tasks to be hand-written, since our models are trained on a large fraction of GitHub, which already contains solutions to problems from a variety of sources.<p>So to answer your question, yes, the evaluation dataset is spoiled. You can find such unique and never before seen docstrings like<p>&gt; For a given list of input numbers calculate the Mean Absolute Deviation around the mean of this dataset. Mean Absolute Deviation is the absolute difference between each element and a centerpoint (mean in this case)[1]<p>And here&#x27;s a repo I found that is 8 years old[2]. But how about a more recent one that is even closer?[3] There&#x27;s plenty more examples[4] (does anyone know how actually limit the date to prior to 2021? `pushed:&lt;2021` doesn&#x27;t work nor does using the `created` keyword. Date searching doesn&#x27;t seem to work well).<p>In essence, we can still use this evaluation method to determine how good our model is at doing fuzzy searching. Which, mind you, is still a useful thing. But I would be careful in concluding that this means the model is good at generalizing arbitrary descriptions of code or novel pieces of code. That said, one may be able to argue that not many lines of code are actually that novel. Still, we need to be careful about our conclusions and understand the limitations of our metrics (something I am currently deeply troubled by)<p>[0] <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2107.03374" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2107.03374</a><p>[1] <a href="https:&#x2F;&#x2F;github.com&#x2F;openai&#x2F;code-align-evals-data&#x2F;blob&#x2F;97446d992c3785d6605f1500b2c9b95d042e7b9c&#x2F;human_eval&#x2F;floats_mean_absolute_deviation.py#L6">https:&#x2F;&#x2F;github.com&#x2F;openai&#x2F;code-align-evals-data&#x2F;blob&#x2F;97446d9...</a><p>[2] <a href="https:&#x2F;&#x2F;github.com&#x2F;bertomartin&#x2F;stat4701&#x2F;blob&#x2F;ec2b64f629cbbf6267169302265f73a98edef67d&#x2F;stck.py#L175">https:&#x2F;&#x2F;github.com&#x2F;bertomartin&#x2F;stat4701&#x2F;blob&#x2F;ec2b64f629cbbf6...</a><p>[3] <a href="https:&#x2F;&#x2F;github.com&#x2F;danielwatson6&#x2F;hate-speech-project&#x2F;blob&#x2F;64a2eecce5218373ef5c449eeb1dfb397532eda5&#x2F;scripts&#x2F;wordnet_mf.py#L61">https:&#x2F;&#x2F;github.com&#x2F;danielwatson6&#x2F;hate-speech-project&#x2F;blob&#x2F;64...</a><p>[4] <a href="https:&#x2F;&#x2F;github.com&#x2F;search?q=abs%28x+-+mean%29+for+language%3APython&amp;type=code">https:&#x2F;&#x2F;github.com&#x2F;search?q=abs%28x+-+mean%29+for+language%3...</a></div><br/><div id="35808140" class="c"><input type="checkbox" id="c-35808140" checked=""/><div class="controls bullet"><span class="by">godelski</span><span>|</span><a href="#35803714">root</a><span>|</span><a href="#35806152">parent</a><span>|</span><a href="#35804101">next</a><span>|</span><label class="collapse" for="c-35808140">[-]</label><label class="expand" for="c-35808140">[1 more]</label></div><br/><div class="children"><div class="content">(follow-up: Figured this should be a different comment)<p>I wanted to demonstrate what I said above so I came up with some examples of things I think a human would have an easy time implementing but might be hard to implement. BUT a key part is that I expect these to be in the dataset! I just don&#x27;t expect these to be in hundreds or thousands of githubs because they will be uncommon (but not rare). Also, we&#x27;ll pretty much ask for few-liners to give the model the biggest advantage we can (errors will compound).<p>Prompt:<p>from torch import nn<p>class LipSwish(nn.Module):<p>&quot;&quot;&quot;&quot;<p>The Swish activation function is defined by a gated linear unit,<p>where the gate is defined by a sigmoid function and multiplies the input with<p>a learnable parameter, beta. Beta is initialized as 0.5.<p>The Lipswish function normalizes the output by the upper bound of 1.1.<p>&quot;&quot;&quot;&quot;<p><pre><code>    def __init__(self:

        super().__init__()
</code></pre>
Result: Mostly correct but missing the division by 1.1. The forward is `return x * F.sigmoid(self.beta * x)`, which is Swish (it also assumes we had &quot;import torch&quot; and applied type hinting). It did properly set the parameter (this is just a 3 liner)<p>Discussion: The Swish function should be in the dataset and is a well known activation function (though beta is not in the pytorch version). Despite LipSwish being in the dataset (introduced in 2019 from Residual Flows[0]) it is not common. I could get the code to generate the swish function (initializing beta, and performing the gate) but could not get the code to divide the output by 1.1. I would not expect a human to have difficulties with this.<p>Okay, so let&#x27;s try something else that might be a bit more common and older. The same paper uses a concatenated activation function, and those aren&#x27;t &quot;uncommon&quot;. CReLU was introduced in 2016[1] and there&#x27;s plenty of concatenated activations around since then. The pytorch documentation even uses it as an example[2]. There&#x27;s far more examples of CReLU (3k python results for &quot;class CReLU&quot; vs 58 for &quot;class LipSwish. Use these numbers as weak hints because search sucks and isn&#x27;t always accurate).<p>Prompt:<p>from torch import nn<p>from torch.nn import functional as F<p>class CReLU(nn.Module):<p>&quot;&quot;&quot;&quot;<p>Concatenated version of ReLU. The activation is applied to both the positive and<p>negative of our input and the result is concatenated.<p>&quot;&quot;&quot;&quot;<p><pre><code>    def __init__(self):

        super().__init__()

    def forward(self, x):
</code></pre>
Result: `return torch.cat([x.clamp(min=0), -x.clamp(min=0)], 1)`. This is correct but not the expected one-liner result.<p>Discussion: This was a bit surprising, it didn&#x27;t use functional as we might expect (or hinted). But interestingly it will if we change the class name to &quot;ConcatenatedReLU&quot;. I found exact copies on GitHub with the full name (memorization) but the fist page of instances for CReLU I found used functional (I did find one that was exactly the above code, when adding &quot;clamp&quot; to the search, but missing the minus sign. There were plenty of errors in CReLU implementations). Interesting side note: CReLU continues and defines a function CReLU6 with uses the same docstring but clamps with a max of 6 on the positive input whereas Concatenated starts to define a convolutional block (Conv + BatchNorm + ReLU) called Conv2d.<p>So we have kinda mixed results, and in both cases these are rather odd and probably not what we wanted. We can clearly see that there are issues where a human would not have too much trouble. There&#x27;s a big issue in these types of problems: we need to memorize a lot of information (otherwise we can&#x27;t even write code or know library calls) but too much memorization prevents creativity. There is a lot of gray area between the _pure_ &quot;Stochastic Parrot&quot;&#x2F;&quot;Fancy copy machine&quot; vs a generalized intelligence (with a broad and flexible definition of intelligence). I&#x27;d still call them stochastic parrots because to me the evidence suggests that we&#x27;re closer to the memorization side than the creation side. But that doesn&#x27;t mean these frameworks aren&#x27;t useful. We all know a lot of code is boiler plate (otherwise we wouldn&#x27;t have the joke &quot;copy paste from SO&quot;) and these tools can be very useful for that. But I think the utility is highly going to depend on what you are coding for and how you code. If you&#x27;re doing standard stuff, this probably has high utility to you and can save you a lot of time. The same way writing macros does, but this is FAR more powerful. It can also help novices a lot. Also, if your main errors are reading mistakes (e.g. you&#x27;re dyslexic) -- this is my largest problem -- then this might make things difficult as you have a tendency to gloss over text and miss minor errors. I also don&#x27;t think these tools would help if you&#x27;re a researcher or writing optimized or specialized code. These differences are probably why we see such differences in people&#x27;s reactions. But it may also be a hint into what people do and how they work when we see who raves and who rants about these.<p>[0] <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1906.02735" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1906.02735</a><p>[1] <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1603.05201" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1603.05201</a><p>[2] <a href="https:&#x2F;&#x2F;pytorch.org&#x2F;docs&#x2F;stable&#x2F;generated&#x2F;torch.nn.ReLU.html" rel="nofollow">https:&#x2F;&#x2F;pytorch.org&#x2F;docs&#x2F;stable&#x2F;generated&#x2F;torch.nn.ReLU.html</a><p>Edit: We can also check if code is in the stack[3]. We see that [0] is indeed in the dataset so we know there is information leakage. Interestingly the exact copy I found in the previous comment[4] isn&#x27;t! (The repo, though the user is)<p>[3] <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;bigcode&#x2F;in-the-stack" rel="nofollow">https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;bigcode&#x2F;in-the-stack</a><p>[4] <a href="https:&#x2F;&#x2F;github.com&#x2F;bertomartin&#x2F;stat4701&#x2F;blob&#x2F;ec2b64f629cbbf6267169302265f73a98edef67d&#x2F;stck.py#L175">https:&#x2F;&#x2F;github.com&#x2F;bertomartin&#x2F;stat4701&#x2F;blob&#x2F;ec2b64f629cbbf6...</a></div><br/></div></div></div></div></div></div><div id="35804101" class="c"><input type="checkbox" id="c-35804101" checked=""/><div class="controls bullet"><span class="by">pera</span><span>|</span><a href="#35803714">parent</a><span>|</span><a href="#35804428">prev</a><span>|</span><a href="#35811728">next</a><span>|</span><label class="collapse" for="c-35804101">[-]</label><label class="expand" for="c-35804101">[4 more]</label></div><br/><div class="children"><div class="content">Hi there, I have two question:<p>1 - Why did you choose Markdown? It seems an odd choice for training a model like this.<p>2 - Have you tried to train only one single PL and then benchmark it against this more general version?</div><br/><div id="35804244" class="c"><input type="checkbox" id="c-35804244" checked=""/><div class="controls bullet"><span class="by">amasad</span><span>|</span><a href="#35803714">root</a><span>|</span><a href="#35804101">parent</a><span>|</span><a href="#35805490">next</a><span>|</span><label class="collapse" for="c-35804244">[-]</label><label class="expand" for="c-35804244">[2 more]</label></div><br/><div class="children"><div class="content">1- We trained on languages that are most popular on Replit. Markdown is important because you need some amount of natural language in the data, and it will act as a sort of &quot;natural language label&quot; for code.<p>2- I like how portable it is being a single small model doing a lot of languages. Single code models are an approach that models like Salesforce&#x2F;Codegen did that, but I believe we beat (or get very close) to their mono models on benchmarks.</div><br/><div id="35804722" class="c"><input type="checkbox" id="c-35804722" checked=""/><div class="controls bullet"><span class="by">fuzzythinker</span><span>|</span><a href="#35803714">root</a><span>|</span><a href="#35804244">parent</a><span>|</span><a href="#35805490">next</a><span>|</span><label class="collapse" for="c-35804722">[-]</label><label class="expand" for="c-35804722">[1 more]</label></div><br/><div class="children"><div class="content">Have you thought of finding or creating something like this [0]?<p>I created this as the basis for my origami folding descriptive language. I tried to find something similar, requirements being both well structured and English-like but couldn&#x27;t find any, so I created it.<p>The origami folding app will hopefully be out in 2 weeks, so you can see how it&#x27;s used.<p>[0] <a href="https:&#x2F;&#x2F;github.com&#x2F;fuzzthink&#x2F;mation-spec">https:&#x2F;&#x2F;github.com&#x2F;fuzzthink&#x2F;mation-spec</a></div><br/></div></div></div></div><div id="35805490" class="c"><input type="checkbox" id="c-35805490" checked=""/><div class="controls bullet"><span class="by">runnerup</span><span>|</span><a href="#35803714">root</a><span>|</span><a href="#35804101">parent</a><span>|</span><a href="#35804244">prev</a><span>|</span><a href="#35811728">next</a><span>|</span><label class="collapse" for="c-35805490">[-]</label><label class="expand" for="c-35805490">[1 more]</label></div><br/><div class="children"><div class="content">They trained on <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;datasets&#x2F;bigcode&#x2F;the-stack-dedup" rel="nofollow">https:&#x2F;&#x2F;huggingface.co&#x2F;datasets&#x2F;bigcode&#x2F;the-stack-dedup</a> which is a massive curated dataset accumulated from GitHub. Details are here: <a href="https:&#x2F;&#x2F;www.bigcode-project.org&#x2F;docs&#x2F;about&#x2F;the-stack&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.bigcode-project.org&#x2F;docs&#x2F;about&#x2F;the-stack&#x2F;</a><p>Many of the most-represented &quot;languages&quot; on GitHub are actually things like JSON, XML, HTML, CSV, text, markdown, YAML, and SVG.<p>More details from them here: <a href="https:&#x2F;&#x2F;blog.replit.com&#x2F;llm-training">https:&#x2F;&#x2F;blog.replit.com&#x2F;llm-training</a></div><br/></div></div></div></div><div id="35811728" class="c"><input type="checkbox" id="c-35811728" checked=""/><div class="controls bullet"><span class="by">curiousgal</span><span>|</span><a href="#35803714">parent</a><span>|</span><a href="#35804101">prev</a><span>|</span><a href="#35804393">next</a><span>|</span><label class="collapse" for="c-35811728">[-]</label><label class="expand" for="c-35811728">[2 more]</label></div><br/><div class="children"><div class="content">Did any interns help in developing this? If so are you planning on intimidating them as usual? :)<p>Reference: <i>How Replit used legal threats to kill my open-source project</i> <a href="https:&#x2F;&#x2F;intuitiveexplanations.com&#x2F;tech&#x2F;replit&#x2F;" rel="nofollow">https:&#x2F;&#x2F;intuitiveexplanations.com&#x2F;tech&#x2F;replit&#x2F;</a></div><br/><div id="35812869" class="c"><input type="checkbox" id="c-35812869" checked=""/><div class="controls bullet"><span class="by">robertlagrant</span><span>|</span><a href="#35803714">root</a><span>|</span><a href="#35811728">parent</a><span>|</span><a href="#35804393">next</a><span>|</span><label class="collapse" for="c-35812869">[-]</label><label class="expand" for="c-35812869">[1 more]</label></div><br/><div class="children"><div class="content">Wow. That&#x27;s extremely poor behaviour if the account is accurate.</div><br/></div></div></div></div><div id="35804393" class="c"><input type="checkbox" id="c-35804393" checked=""/><div class="controls bullet"><span class="by">gbasin</span><span>|</span><a href="#35803714">parent</a><span>|</span><a href="#35811728">prev</a><span>|</span><a href="#35806045">next</a><span>|</span><label class="collapse" for="c-35804393">[-]</label><label class="expand" for="c-35804393">[1 more]</label></div><br/><div class="children"><div class="content">Very exciting, thanks for sharing all this</div><br/></div></div></div></div><div id="35806045" class="c"><input type="checkbox" id="c-35806045" checked=""/><div class="controls bullet"><span class="by">doodlesdev</span><span>|</span><a href="#35803714">prev</a><span>|</span><a href="#35803731">next</a><span>|</span><label class="collapse" for="c-35806045">[-]</label><label class="expand" for="c-35806045">[19 more]</label></div><br/><div class="children"><div class="content">The model is way too small, comparing it to Codex feels disingenous. Sure it&#x27;s 77% smaller, it&#x27;s also 77% worse. Although, it&#x27;s a cool project nonetheless.<p>For instance, even this simple snippet generates wrong inline completions:<p><pre><code>   &#x2F;&#x2F; Only return even numbers bigger than 10 from the array
   const arrayFilter = (array) =&gt;
</code></pre>
Replit-code-v1:<p><pre><code>   &#x2F;&#x2F; Only return even numbers bigger than 10 from the array
   const arrayFilter = (array) =&gt; {
     return array.filter((item) =&gt; item &gt; 10);
   };
</code></pre>
Gets it wrong, returns odd numbers.<p>Codeium:<p><pre><code>   &#x2F;&#x2F; Only return even numbers bigger than 10 from the array
   const arrayFilter = (array) =&gt; {
     return array.filter((num) =&gt; num &gt; 10 &amp;&amp; num % 2 === 0);
   };
</code></pre>
ChatGPT (GPT-3.5 Turbo) - Code-only, without the rest of the completion since it&#x27;s instruction-tuned:<p><pre><code>   const arrayFilter = (array) =&gt; {
     return array.filter(num =&gt; num % 2 === 0 &amp;&amp; num &gt; 10);
   }
</code></pre>
Not comparable at all. For reference if anyone wants to test I ran this through the HuggingFace space using the default parameters, ChatGPT through chat.openai.com, and Codeium through the VSCodium extension on an empty JavaScript file.</div><br/><div id="35806247" class="c"><input type="checkbox" id="c-35806247" checked=""/><div class="controls bullet"><span class="by">amasad</span><span>|</span><a href="#35806045">parent</a><span>|</span><a href="#35806374">next</a><span>|</span><label class="collapse" for="c-35806247">[-]</label><label class="expand" for="c-35806247">[6 more]</label></div><br/><div class="children"><div class="content">Interesting. This seems like a weakness of natural language understanding. If you rephrase your prompt slightly it would get it right. Try:<p><pre><code>  &#x2F;&#x2F; return even numbers that are also more than 10
  const arrayFilter = (array) =&gt;
</code></pre>
It would do the right thing. The fine-tuned version gets your prompt right so maybe it benefited from natural language data. Will look more into it.</div><br/><div id="35806811" class="c"><input type="checkbox" id="c-35806811" checked=""/><div class="controls bullet"><span class="by">doodlesdev</span><span>|</span><a href="#35806045">root</a><span>|</span><a href="#35806247">parent</a><span>|</span><a href="#35807393">next</a><span>|</span><label class="collapse" for="c-35806811">[-]</label><label class="expand" for="c-35806811">[4 more]</label></div><br/><div class="children"><div class="content">That&#x27;s really interesting, indeed I can reproduce this by changing the comment. I also managed to get correct output for this sample by renaming the function.</div><br/><div id="35807608" class="c"><input type="checkbox" id="c-35807608" checked=""/><div class="controls bullet"><span class="by">eevilspock</span><span>|</span><a href="#35806045">root</a><span>|</span><a href="#35806811">parent</a><span>|</span><a href="#35807393">next</a><span>|</span><label class="collapse" for="c-35807608">[-]</label><label class="expand" for="c-35807608">[3 more]</label></div><br/><div class="children"><div class="content">clearly your original comment was unfair.</div><br/><div id="35809368" class="c"><input type="checkbox" id="c-35809368" checked=""/><div class="controls bullet"><span class="by">int_19h</span><span>|</span><a href="#35806045">root</a><span>|</span><a href="#35807608">parent</a><span>|</span><a href="#35810032">next</a><span>|</span><label class="collapse" for="c-35809368">[-]</label><label class="expand" for="c-35809368">[1 more]</label></div><br/><div class="children"><div class="content">Is it, though? The major selling point of coding LLMs is that you can use natural language to describe what you want. If minor changes to wording - the ones that would not make any difference with a human - can result in drastically worse results, that feels problematic for real-world scenarios.</div><br/></div></div><div id="35810032" class="c"><input type="checkbox" id="c-35810032" checked=""/><div class="controls bullet"><span class="by">throwaway675309</span><span>|</span><a href="#35806045">root</a><span>|</span><a href="#35807608">parent</a><span>|</span><a href="#35809368">prev</a><span>|</span><a href="#35807393">next</a><span>|</span><label class="collapse" for="c-35810032">[-]</label><label class="expand" for="c-35810032">[1 more]</label></div><br/><div class="children"><div class="content">The criticism stands if you have to continue to rewrite your &quot;prompt&quot; until you can coax out the correct desired output.</div><br/></div></div></div></div></div></div><div id="35807393" class="c"><input type="checkbox" id="c-35807393" checked=""/><div class="controls bullet"><span class="by">SCLeo</span><span>|</span><a href="#35806045">root</a><span>|</span><a href="#35806247">parent</a><span>|</span><a href="#35806811">prev</a><span>|</span><a href="#35806374">next</a><span>|</span><label class="collapse" for="c-35807393">[-]</label><label class="expand" for="c-35807393">[1 more]</label></div><br/><div class="children"><div class="content">I agree. Maybe it interpreted it as return the numbers that are more than 10 in the given array of even numbers.<p>For example, if the instruction says &quot;return person objects that are at least 20 years old&quot;, it might be more reasonable to generate:<p>array.filter(item =&gt; item.age &gt;= 20)<p>as oppose to<p>array.filter(item =&gt; (item instanceof Person) &amp;&amp; (item.age &gt;= 20))</div><br/></div></div></div></div><div id="35806374" class="c"><input type="checkbox" id="c-35806374" checked=""/><div class="controls bullet"><span class="by">SheinhardtWigCo</span><span>|</span><a href="#35806045">parent</a><span>|</span><a href="#35806247">prev</a><span>|</span><a href="#35806661">next</a><span>|</span><label class="collapse" for="c-35806374">[-]</label><label class="expand" for="c-35806374">[2 more]</label></div><br/><div class="children"><div class="content">It seems like every week someone comes out with some version of &quot;we can get results similar to OpenAI&#x27;s API with our model that you can run on a Commodore 64!&quot;<p>And then you dig in, and it&#x27;s always far behind in some important way.<p>Not hating here, I love the pace of iteration, just not the hyperbole.</div><br/><div id="35808677" class="c"><input type="checkbox" id="c-35808677" checked=""/><div class="controls bullet"><span class="by">barking_biscuit</span><span>|</span><a href="#35806045">root</a><span>|</span><a href="#35806374">parent</a><span>|</span><a href="#35806661">next</a><span>|</span><label class="collapse" for="c-35808677">[-]</label><label class="expand" for="c-35808677">[1 more]</label></div><br/><div class="children"><div class="content">&gt;&quot;we can get results similar to OpenAI&#x27;s API with our model that you can run on a Commodore 64!&quot;<p>I have felt similar frustrations with statements that feel disingenuous too. Thanks for articulating this with such a beautifully hilarious metaphor.</div><br/></div></div></div></div><div id="35806661" class="c"><input type="checkbox" id="c-35806661" checked=""/><div class="controls bullet"><span class="by">thewataccount</span><span>|</span><a href="#35806045">parent</a><span>|</span><a href="#35806374">prev</a><span>|</span><a href="#35808360">next</a><span>|</span><label class="collapse" for="c-35806661">[-]</label><label class="expand" for="c-35806661">[1 more]</label></div><br/><div class="children"><div class="content">I need more time to compare it, the short 128 tokens in the demo is a bit rough but -<p>On first look this seems to blow the current llama based models out of the water including the 30B ones.<p>Pasting what you want + url + example json with no other context and it &quot;knows&quot; what the url and the json is for, without even telling it.<p>I&#x27;m not even saying it&#x27;s as good as chatGPT, but this is a tenth the size of the best llama models I&#x27;ve seen.</div><br/></div></div><div id="35808360" class="c"><input type="checkbox" id="c-35808360" checked=""/><div class="controls bullet"><span class="by">moffkalast</span><span>|</span><a href="#35806045">parent</a><span>|</span><a href="#35806661">prev</a><span>|</span><a href="#35806768">next</a><span>|</span><label class="collapse" for="c-35808360">[-]</label><label class="expand" for="c-35808360">[2 more]</label></div><br/><div class="children"><div class="content">Yeah I tried the demo, it wrote some wrong code with comments in Chinese. I think I&#x27;ll pass.<p>It&#x27;s a pretty well accepted fact now that bigger LLM = moar better without exceptions. I&#x27;m not sure why there&#x27;s a race to the bottom of who&#x27;ll make the most useless model that can run everywhere.</div><br/><div id="35810215" class="c"><input type="checkbox" id="c-35810215" checked=""/><div class="controls bullet"><span class="by">thewataccount</span><span>|</span><a href="#35806045">root</a><span>|</span><a href="#35808360">parent</a><span>|</span><a href="#35806768">next</a><span>|</span><label class="collapse" for="c-35810215">[-]</label><label class="expand" for="c-35810215">[1 more]</label></div><br/><div class="children"><div class="content">&gt; It&#x27;s a pretty well accepted fact now that bigger LLM = moar better without exceptions.<p>That&#x27;s not true, the amount of training is a MAJOR factor.<p>See the Chinchilla paper - <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2203.15556" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2203.15556</a><p>tl;dr - a &quot;fully&quot; trained small model can outperform a &quot;undertrained&quot; larger model. If you have a fixed amount of compute (budget), then you need to optimize for the largest model that you can fully train, and not simply up the parameter count.<p>EDIT: Also you can&#x27;t necessarily compare the parameter count across model architectures*<p>This thing seems to outperform the finetuned 30B llama models I&#x27;ve seen.</div><br/></div></div></div></div><div id="35806768" class="c"><input type="checkbox" id="c-35806768" checked=""/><div class="controls bullet"><span class="by">johnfn</span><span>|</span><a href="#35806045">parent</a><span>|</span><a href="#35808360">prev</a><span>|</span><a href="#35803731">next</a><span>|</span><label class="collapse" for="c-35806768">[-]</label><label class="expand" for="c-35806768">[7 more]</label></div><br/><div class="children"><div class="content">&gt; Sure it&#x27;s 77% smaller, it&#x27;s also 77% worse.<p>Hehe, yeah, imagine saying you made a new programming language with 77% less lines of code than Python.</div><br/><div id="35807082" class="c"><input type="checkbox" id="c-35807082" checked=""/><div class="controls bullet"><span class="by">Zababa</span><span>|</span><a href="#35806045">root</a><span>|</span><a href="#35806768">parent</a><span>|</span><a href="#35803731">next</a><span>|</span><label class="collapse" for="c-35807082">[-]</label><label class="expand" for="c-35807082">[6 more]</label></div><br/><div class="children"><div class="content">Finally, an opportunity to share this <a href="https:&#x2F;&#x2F;nsl.com&#x2F;papers&#x2F;denial.html" rel="nofollow">https:&#x2F;&#x2F;nsl.com&#x2F;papers&#x2F;denial.html</a></div><br/><div id="35808742" class="c"><input type="checkbox" id="c-35808742" checked=""/><div class="controls bullet"><span class="by">johnfn</span><span>|</span><a href="#35806045">root</a><span>|</span><a href="#35807082">parent</a><span>|</span><a href="#35808775">next</a><span>|</span><label class="collapse" for="c-35808742">[-]</label><label class="expand" for="c-35808742">[3 more]</label></div><br/><div class="children"><div class="content">I’m curious about the downvotes because I thought I was just agreeing with OP. Obviously lines of code in a programming language repo is no correlate at all to quality. It’s like the old adage about measuring aircraft quality by weight.</div><br/><div id="35810861" class="c"><input type="checkbox" id="c-35810861" checked=""/><div class="controls bullet"><span class="by">riwsky</span><span>|</span><a href="#35806045">root</a><span>|</span><a href="#35808742">parent</a><span>|</span><a href="#35808775">next</a><span>|</span><label class="collapse" for="c-35810861">[-]</label><label class="expand" for="c-35810861">[2 more]</label></div><br/><div class="children"><div class="content">That’s an inverse correlate, not no correlate</div><br/><div id="35812499" class="c"><input type="checkbox" id="c-35812499" checked=""/><div class="controls bullet"><span class="by">johnfn</span><span>|</span><a href="#35806045">root</a><span>|</span><a href="#35810861">parent</a><span>|</span><a href="#35808775">next</a><span>|</span><label class="collapse" for="c-35812499">[-]</label><label class="expand" for="c-35812499">[1 more]</label></div><br/><div class="children"><div class="content">No, a PL could have millions of lines of code and still not be very good. Consider any enterprise language that no one likes :)</div><br/></div></div></div></div></div></div><div id="35808775" class="c"><input type="checkbox" id="c-35808775" checked=""/><div class="controls bullet"><span class="by">barking_biscuit</span><span>|</span><a href="#35806045">root</a><span>|</span><a href="#35807082">parent</a><span>|</span><a href="#35808742">prev</a><span>|</span><a href="#35807535">next</a><span>|</span><label class="collapse" for="c-35808775">[-]</label><label class="expand" for="c-35808775">[1 more]</label></div><br/><div class="children"><div class="content">I didn&#x27;t get the punchline of this, so I asked GPT-4 to explain the punchline. Actually quite amusing.</div><br/></div></div></div></div></div></div></div></div><div id="35803731" class="c"><input type="checkbox" id="c-35803731" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#35806045">prev</a><span>|</span><a href="#35804959">next</a><span>|</span><label class="collapse" for="c-35803731">[-]</label><label class="expand" for="c-35803731">[36 more]</label></div><br/><div class="children"><div class="content">hi HN! back again with an exclusive deep dive with Replit’s head of AI. I attended their developer day last week (<a href="https:&#x2F;&#x2F;twitter.com&#x2F;swyx&#x2F;status&#x2F;1650989632413401089" rel="nofollow">https:&#x2F;&#x2F;twitter.com&#x2F;swyx&#x2F;status&#x2F;1650989632413401089</a>) just expecting a regular fundraise announcement and was totally shocked when they annoucned their own LLM and also said they would open source it. so immediately asked them for a podcast interview and this is the result.<p>my favorite learning is how they are pushing the state of the art - openai’s HumanEval is the industry standard benchmark for code LLMs, but Reza kindly went above and beyond to show how they use “AmjadEval” - using coder intuition to capture human preference on what output is more helpful to coders (see screenshots <a href="https:&#x2F;&#x2F;twitter.com&#x2F;swyx&#x2F;status&#x2F;1653791019421569024?s=20" rel="nofollow">https:&#x2F;&#x2F;twitter.com&#x2F;swyx&#x2F;status&#x2F;1653791019421569024?s=20</a>)<p>please AMA!</div><br/><div id="35803783" class="c"><input type="checkbox" id="c-35803783" checked=""/><div class="controls bullet"><span class="by">marcodiego</span><span>|</span><a href="#35803731">parent</a><span>|</span><a href="#35804264">next</a><span>|</span><label class="collapse" for="c-35803783">[-]</label><label class="expand" for="c-35803783">[32 more]</label></div><br/><div class="children"><div class="content">Sorry, I have to ask this: how does this compare to ChatGPT?</div><br/><div id="35804015" class="c"><input type="checkbox" id="c-35804015" checked=""/><div class="controls bullet"><span class="by">runnerup</span><span>|</span><a href="#35803731">root</a><span>|</span><a href="#35803783">parent</a><span>|</span><a href="#35803995">next</a><span>|</span><label class="collapse" for="c-35804015">[-]</label><label class="expand" for="c-35804015">[26 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not crucial that it beat ChatGPT this year. That&#x27;s a pretty unattainable goal for a group like Replit. From the users POV, none of the current copilots compare favorably against ChatGPT, even Microsoft&#x27;s OpenAI-powered GitHub Copilot.<p>What&#x27;s important is that they&#x27;re preparing for the future by building all the tooling&#x2F;UI&#x2F;UX around coding copilots. This way, when costs and feasibility of building ChatGPT-quality LLM&#x27;s drop and multiple open-source models are available, Replit has the ability to immediately drop them into their production environment. They&#x27;ll also have the skills and systems to finetune any new models and wring extra performance out of them.<p>This is more important to users than it seems at first because current UX of things like GitHub Copilot don&#x27;t allow me to use their AI against my codebase the way that I want to (the way I use ChatGPT). Right now GitHub Copilot is a glorified auto-complete, but I want it to do widespread scaffolding, refactoring, and analysis across my whole codebase. Microsoft has access to LLM&#x27;s that can do this through their control of OpenAI -- but Microsoft lacks the tooling&#x2F;UI&#x2F;UX to bring the power of ChatGPT to me as a user of VSCode&#x2F;IntelliJ&#x2F;PyCharm&#x2F;Visual Studio.<p>So if Replit can find more innovative, boundary-pushing ways of integrating LLM&#x27;s, they won&#x27;t necessarily need the highest quality LLM&#x27;s to produce a superior user experience. It&#x27;s a strong signal that Replit is well-positioned for the future, when ChatGPT-like models are democratized.<p>Hopefully JetBrains is paying attention. They definitely have time to wait a bit more (1-2 years?), but not a lot of time. JetBrains shouldn&#x27;t solely rely on Github Copilot plug-in to provide their users with LLM&#x27;s, because it&#x27;s not clear that the user experience of that plug-in will stay competitive with the user experience that GitHub Copilot will offer directly in VSCode. The IntelliJ&#x2F;PyCharm plugin may remain &quot;just a fancy auto-complete&quot; while VSCode gets more interactive workflows.<p>Future IDE&#x27;s with LLM integration require novel, smart, clever UX typically invented only by very creative people.<p>It&#x27;s also worth noting that Replit is not just trying to be an IDE -- they&#x27;re also building a marketplace to buy&#x2F;sell coding work, and establishing a small foothold as a niche cloud computing provider.</div><br/><div id="35805114" class="c"><input type="checkbox" id="c-35805114" checked=""/><div class="controls bullet"><span class="by">earthboundkid</span><span>|</span><a href="#35803731">root</a><span>|</span><a href="#35804015">parent</a><span>|</span><a href="#35807027">next</a><span>|</span><label class="collapse" for="c-35805114">[-]</label><label class="expand" for="c-35805114">[9 more]</label></div><br/><div class="children"><div class="content">I keep saying that it&#x27;s obvious that local execution is the future of LLMs. Remote execution makes a ton of sense for databases, and most web apps are on some level just CRUD over a remote DB, so we&#x27;ve all gotten used to the idea that in the 21st century a software business should be running remote servers… But LLMs don&#x27;t need to run remotely, and they don&#x27;t especially benefit from running remotely either (okay, more training data, but you can batch that and send it back asynchronously). The future is local.</div><br/><div id="35805959" class="c"><input type="checkbox" id="c-35805959" checked=""/><div class="controls bullet"><span class="by">blueboo</span><span>|</span><a href="#35803731">root</a><span>|</span><a href="#35805114">parent</a><span>|</span><a href="#35807027">next</a><span>|</span><label class="collapse" for="c-35805959">[-]</label><label class="expand" for="c-35805959">[8 more]</label></div><br/><div class="children"><div class="content">The future is using the best possible tool to drive your work. Won’t local models be systematically inferior to bigger commercial offerings for the next few years at least?</div><br/><div id="35808302" class="c"><input type="checkbox" id="c-35808302" checked=""/><div class="controls bullet"><span class="by">pmoriarty</span><span>|</span><a href="#35803731">root</a><span>|</span><a href="#35805959">parent</a><span>|</span><a href="#35806912">next</a><span>|</span><label class="collapse" for="c-35808302">[-]</label><label class="expand" for="c-35808302">[2 more]</label></div><br/><div class="children"><div class="content"><i>&quot;The future is using the best possible tool to drive your work&quot;</i><p>Not if that tool is censored, and you need an uncensored version to do your work.  Or maybe you have privacy considerations, or your company policies forbid using something hosted remotely or owned by another company, etc...</div><br/><div id="35810867" class="c"><input type="checkbox" id="c-35810867" checked=""/><div class="controls bullet"><span class="by">riwsky</span><span>|</span><a href="#35803731">root</a><span>|</span><a href="#35808302">parent</a><span>|</span><a href="#35806912">next</a><span>|</span><label class="collapse" for="c-35810867">[-]</label><label class="expand" for="c-35810867">[1 more]</label></div><br/><div class="children"><div class="content"><i>cries in HIPAA</i></div><br/></div></div></div></div><div id="35806912" class="c"><input type="checkbox" id="c-35806912" checked=""/><div class="controls bullet"><span class="by">steve_adams_86</span><span>|</span><a href="#35803731">root</a><span>|</span><a href="#35805959">parent</a><span>|</span><a href="#35808302">prev</a><span>|</span><a href="#35806784">next</a><span>|</span><label class="collapse" for="c-35806912">[-]</label><label class="expand" for="c-35806912">[3 more]</label></div><br/><div class="children"><div class="content">Maybe. I wonder if very narrow, multi-model systems might eventually deliver better performance and utility than monolithic models like GPT. Rather than pay for access to that, you might be better off investing in resources that can train and learn on exactly what you&#x27;re doing, rather than something general that is good at a lot of things but not incredible at your specific task.</div><br/><div id="35810767" class="c"><input type="checkbox" id="c-35810767" checked=""/><div class="controls bullet"><span class="by">runnerup</span><span>|</span><a href="#35803731">root</a><span>|</span><a href="#35806912">parent</a><span>|</span><a href="#35806784">next</a><span>|</span><label class="collapse" for="c-35810767">[-]</label><label class="expand" for="c-35810767">[2 more]</label></div><br/><div class="children"><div class="content"><a href="http:&#x2F;&#x2F;www.incompleteideas.net&#x2F;IncIdeas&#x2F;BitterLesson.html" rel="nofollow">http:&#x2F;&#x2F;www.incompleteideas.net&#x2F;IncIdeas&#x2F;BitterLesson.html</a><p>Generally we have continued finding that the more &quot;other&quot;&#x2F;general stuff an AI model is trained on, the better it performs on specific tasks. As in, an AI model trained to identify photos of all animals will perform better than an AI model that is only trained to identify breeds of dogs. Even at identifying breeds of dogs.<p>Taken to the extreme, we&#x27;ve found that training image models with &quot;multi-modal&quot; LLM capabilities improves their ability to identify dogs&#x2F;etc. A lot of people don&#x27;t realize that GPT-4 is actually multi-modal...while OpenAI has only allowed API access to use text input, the model itself can also accept image input.<p>Note that we&#x27;ve moved on from ImageNet-style tests &quot;Choose the most appropriate label for this image from 200 possible labels&quot; to much more advanced &quot;Reasoning&quot; tests[0]. PaLI[1] is potentially the SoTA here but BeIT-3[2] may be better example for my thesis. Notice that BeIT-3 is trained on not just images, but also trained like an LLM. Yet it outperforms purely image-trained models on pure-image tasks like Object Detection and Semantic Segmentation.<p>More importantly, it can understand human questioning like &quot;What type of flowers are in the blue buckets of this image?&quot; and respond intelligently.<p>0: <a href="https:&#x2F;&#x2F;paperswithcode.com&#x2F;area&#x2F;reasoning" rel="nofollow">https:&#x2F;&#x2F;paperswithcode.com&#x2F;area&#x2F;reasoning</a><p>1: <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2209.06794v2.pdf" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2209.06794v2.pdf</a><p>2: <a href="https:&#x2F;&#x2F;paperswithcode.com&#x2F;paper&#x2F;image-as-a-foreign-language-beit-pretraining" rel="nofollow">https:&#x2F;&#x2F;paperswithcode.com&#x2F;paper&#x2F;image-as-a-foreign-language...</a><p>3: <a href="http:&#x2F;&#x2F;www.incompleteideas.net&#x2F;IncIdeas&#x2F;BitterLesson.html" rel="nofollow">http:&#x2F;&#x2F;www.incompleteideas.net&#x2F;IncIdeas&#x2F;BitterLesson.html</a></div><br/><div id="35810830" class="c"><input type="checkbox" id="c-35810830" checked=""/><div class="controls bullet"><span class="by">steve_adams_86</span><span>|</span><a href="#35803731">root</a><span>|</span><a href="#35810767">parent</a><span>|</span><a href="#35806784">next</a><span>|</span><label class="collapse" for="c-35810830">[-]</label><label class="expand" for="c-35810830">[1 more]</label></div><br/><div class="children"><div class="content">Very interesting. I’d hoped it was going to go a different direction, but the evidence clearly suggests that what you linked here is correct so far.</div><br/></div></div></div></div></div></div><div id="35806784" class="c"><input type="checkbox" id="c-35806784" checked=""/><div class="controls bullet"><span class="by">imoverclocked</span><span>|</span><a href="#35803731">root</a><span>|</span><a href="#35805959">parent</a><span>|</span><a href="#35806912">prev</a><span>|</span><a href="#35808676">next</a><span>|</span><label class="collapse" for="c-35806784">[-]</label><label class="expand" for="c-35806784">[1 more]</label></div><br/><div class="children"><div class="content">For shops that want to ensure their own codebase stays local, definitely no.</div><br/></div></div><div id="35808676" class="c"><input type="checkbox" id="c-35808676" checked=""/><div class="controls bullet"><span class="by">theaiquestion</span><span>|</span><a href="#35803731">root</a><span>|</span><a href="#35805959">parent</a><span>|</span><a href="#35806784">prev</a><span>|</span><a href="#35807027">next</a><span>|</span><label class="collapse" for="c-35808676">[-]</label><label class="expand" for="c-35808676">[1 more]</label></div><br/><div class="children"><div class="content">I think that we&#x27;ll reach &quot;good enough&quot; - and that the commercial offerings won&#x27;t have much tangible benefit for at least simply being &quot;fancy autocomplete&quot;.<p>Currently you don&#x27;t really use LLMs for designing the structure, just completing the implementation, and I think that will be very doable locally.</div><br/></div></div></div></div></div></div><div id="35807027" class="c"><input type="checkbox" id="c-35807027" checked=""/><div class="controls bullet"><span class="by">furyofantares</span><span>|</span><a href="#35803731">root</a><span>|</span><a href="#35804015">parent</a><span>|</span><a href="#35805114">prev</a><span>|</span><a href="#35808818">next</a><span>|</span><label class="collapse" for="c-35807027">[-]</label><label class="expand" for="c-35807027">[2 more]</label></div><br/><div class="children"><div class="content">Whether it beats ChatGPT right now is important to me, right now.<p>I&#x27;m very excited about everyone doing work even when they&#x27;re not beating ChatGPT right now, of course.<p>But how it compares to ChatGPT right now is extremely relevant to lots of people.<p>It&#x27;s also become very common to vaguely reference OpenAI&#x27;s offerings when announcing new models without saying how they actually compare, or only mentioning some small way in which it compares favorably.<p>(Though it seems to often be that some comment from the article comparing to OpenAI gets promoted to the title when posted on HN, like here.)</div><br/><div id="35808224" class="c"><input type="checkbox" id="c-35808224" checked=""/><div class="controls bullet"><span class="by">jeron</span><span>|</span><a href="#35803731">root</a><span>|</span><a href="#35807027">parent</a><span>|</span><a href="#35808818">next</a><span>|</span><label class="collapse" for="c-35808224">[-]</label><label class="expand" for="c-35808224">[1 more]</label></div><br/><div class="children"><div class="content">I think this is somewhat of a naive way to look at this. Yes, ChatGPT is really good, but they&#x27;re basically completely closed source. A lot of the power of LLMs can and will come from open sourced models that anyone can dig into the weights and tune it for their use case, as well as train and run on their own platform.</div><br/></div></div></div></div><div id="35808818" class="c"><input type="checkbox" id="c-35808818" checked=""/><div class="controls bullet"><span class="by">worldsayshi</span><span>|</span><a href="#35803731">root</a><span>|</span><a href="#35804015">parent</a><span>|</span><a href="#35807027">prev</a><span>|</span><a href="#35804838">next</a><span>|</span><label class="collapse" for="c-35808818">[-]</label><label class="expand" for="c-35808818">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;m a bit surprised that IP and infosec isn&#x27;t a much bigger part of this discussion.<p>ChatGPT ought to be a non starter for many use cases where data cannot be shared with OpenAI or where the copyright situation of the generated output could become too vague.<p>Having the option of open source models that potentially could be self hosted could make those use cases viable.</div><br/><div id="35809067" class="c"><input type="checkbox" id="c-35809067" checked=""/><div class="controls bullet"><span class="by">runnerup</span><span>|</span><a href="#35803731">root</a><span>|</span><a href="#35808818">parent</a><span>|</span><a href="#35804838">next</a><span>|</span><label class="collapse" for="c-35809067">[-]</label><label class="expand" for="c-35809067">[2 more]</label></div><br/><div class="children"><div class="content">ChatGPT now has an option to turn off both historical logging of conversations and use of your interactions to train the model. There&#x27;s still concern, but for any company which is already using GitHub&#x2F;BitBucket to host their code or Azure&#x2F;GCP&#x2F;AWS for their build&#x2F;CI&#x2F;CD servers...it&#x27;s not like they&#x27;re hermetically sealed in the first place.<p>OpenAI probably hasn&#x27;t gone through all the SOC2&#x2F;etc&#x2F;etc&#x2F;etc&#x2F;etc audit certification that AWS&#x2F;GCP&#x2F;Azure have, but if you&#x27;re using those, then this decision is just a matter of degree. Plus OpenAI is clearly aware of the concerns and beginning to address them in order to expand their addressable market.<p>For defense companies, yeah, this is a non-starter. But they often don&#x27;t even have access to StackOverflow and cell signals are physically, purposefully blocked by the building construction materials. And they only recently even started using cloud computing and use a purpose-built cloud at Azure&#x2F;GCP&#x2F;AWS that&#x27;s specifically walled off for DoD partners.</div><br/><div id="35812803" class="c"><input type="checkbox" id="c-35812803" checked=""/><div class="controls bullet"><span class="by">krageon</span><span>|</span><a href="#35803731">root</a><span>|</span><a href="#35809067">parent</a><span>|</span><a href="#35804838">next</a><span>|</span><label class="collapse" for="c-35812803">[-]</label><label class="expand" for="c-35812803">[1 more]</label></div><br/><div class="children"><div class="content">It says it has those things, but it changes absolutely nothing for corporate use - you&#x27;re still exfiltrating important information. To say nothing of sending personal information there, that is an even worse idea (because you have less money and are therefore less important to keep in mind for a large corporation).<p>Saying that they&#x27;re &quot;working on it&quot; is not useful IMO - at the end of the day, they&#x27;ll be exactly as unethical as they can get away with. We live in a time where we can comfortably say that that is &quot;very unethical&quot;.</div><br/></div></div></div></div></div></div><div id="35804838" class="c"><input type="checkbox" id="c-35804838" checked=""/><div class="controls bullet"><span class="by">valedan</span><span>|</span><a href="#35803731">root</a><span>|</span><a href="#35804015">parent</a><span>|</span><a href="#35808818">prev</a><span>|</span><a href="#35805696">next</a><span>|</span><label class="collapse" for="c-35804838">[-]</label><label class="expand" for="c-35804838">[10 more]</label></div><br/><div class="children"><div class="content">What does this mean for the future of editors like emacs and (neo)vim? Right now the Copilot plugin for Neovim works pretty much the same as the one for VSCode, but as LLMs get integrated more into IDEs and new workflows are built around them, will the old-school editors be able to keep up? I&#x27;m a little worried because I just switched from VSCode to Neovim a few months ago!</div><br/><div id="35812513" class="c"><input type="checkbox" id="c-35812513" checked=""/><div class="controls bullet"><span class="by">tmtvl</span><span>|</span><a href="#35803731">root</a><span>|</span><a href="#35804838">parent</a><span>|</span><a href="#35806623">next</a><span>|</span><label class="collapse" for="c-35812513">[-]</label><label class="expand" for="c-35812513">[1 more]</label></div><br/><div class="children"><div class="content">There is a ChatGPT shell for Emacs: <a href="https:&#x2F;&#x2F;xenodium.com&#x2F;chatgpt-shell-available-on-melpa&#x2F;" rel="nofollow">https:&#x2F;&#x2F;xenodium.com&#x2F;chatgpt-shell-available-on-melpa&#x2F;</a></div><br/></div></div><div id="35806623" class="c"><input type="checkbox" id="c-35806623" checked=""/><div class="controls bullet"><span class="by">SheinhardtWigCo</span><span>|</span><a href="#35803731">root</a><span>|</span><a href="#35804838">parent</a><span>|</span><a href="#35812513">prev</a><span>|</span><a href="#35811755">next</a><span>|</span><label class="collapse" for="c-35806623">[-]</label><label class="expand" for="c-35806623">[3 more]</label></div><br/><div class="children"><div class="content">This could be the dawn of a new day for the old-school editors. Not to start any wars here, but I could never get the hang of Vim, and that&#x27;s hardly an unusual complaint. But now, free high-quality personalized &quot;tuition&quot; just became economically viable.</div><br/><div id="35807215" class="c"><input type="checkbox" id="c-35807215" checked=""/><div class="controls bullet"><span class="by">runnerup</span><span>|</span><a href="#35803731">root</a><span>|</span><a href="#35806623">parent</a><span>|</span><a href="#35811755">next</a><span>|</span><label class="collapse" for="c-35807215">[-]</label><label class="expand" for="c-35807215">[2 more]</label></div><br/><div class="children"><div class="content">Side note, potentially check out vimtutor, or also <a href="https:&#x2F;&#x2F;vim-adventures.com&#x2F;" rel="nofollow">https:&#x2F;&#x2F;vim-adventures.com&#x2F;</a></div><br/><div id="35809070" class="c"><input type="checkbox" id="c-35809070" checked=""/><div class="controls bullet"><span class="by">pmoriarty</span><span>|</span><a href="#35803731">root</a><span>|</span><a href="#35807215">parent</a><span>|</span><a href="#35811755">next</a><span>|</span><label class="collapse" for="c-35809070">[-]</label><label class="expand" for="c-35809070">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;d second the advice to go through vimtutor.<p>Highly recommended.</div><br/></div></div></div></div></div></div><div id="35811755" class="c"><input type="checkbox" id="c-35811755" checked=""/><div class="controls bullet"><span class="by">llarsson</span><span>|</span><a href="#35803731">root</a><span>|</span><a href="#35804838">parent</a><span>|</span><a href="#35806623">prev</a><span>|</span><a href="#35805023">next</a><span>|</span><label class="collapse" for="c-35811755">[-]</label><label class="expand" for="c-35811755">[1 more]</label></div><br/><div class="children"><div class="content">Stuff like the Language Server shows that people are interested in making new stuff work well with our old beloved editors. I have faith.</div><br/></div></div><div id="35805023" class="c"><input type="checkbox" id="c-35805023" checked=""/><div class="controls bullet"><span class="by">davidkunz</span><span>|</span><a href="#35803731">root</a><span>|</span><a href="#35804838">parent</a><span>|</span><a href="#35811755">prev</a><span>|</span><a href="#35805882">next</a><span>|</span><label class="collapse" for="c-35805023">[-]</label><label class="expand" for="c-35805023">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;ll be great if they&#x27;d build language servers via the language server protocol, that would be editor agnostic.</div><br/><div id="35805374" class="c"><input type="checkbox" id="c-35805374" checked=""/><div class="controls bullet"><span class="by">spenczar5</span><span>|</span><a href="#35803731">root</a><span>|</span><a href="#35805023">parent</a><span>|</span><a href="#35805882">next</a><span>|</span><label class="collapse" for="c-35805374">[-]</label><label class="expand" for="c-35805374">[1 more]</label></div><br/><div class="children"><div class="content">Github Copilot actually works through the language server protocol already. Document contents are sent to it and it responds with code completions.</div><br/></div></div></div></div><div id="35805882" class="c"><input type="checkbox" id="c-35805882" checked=""/><div class="controls bullet"><span class="by">mzz80</span><span>|</span><a href="#35803731">root</a><span>|</span><a href="#35804838">parent</a><span>|</span><a href="#35805023">prev</a><span>|</span><a href="#35805696">next</a><span>|</span><label class="collapse" for="c-35805882">[-]</label><label class="expand" for="c-35805882">[2 more]</label></div><br/><div class="children"><div class="content">Neovim already can’t keep up by itself. The future of vim won’t be as a standalone application, but as a plugin into other IDEs. The support for Neovim and VSCodeVim within VSCode greatly reduces the utility of a standalone app for anything other than edits to very small projects.</div><br/><div id="35807275" class="c"><input type="checkbox" id="c-35807275" checked=""/><div class="controls bullet"><span class="by">soulofmischief</span><span>|</span><a href="#35803731">root</a><span>|</span><a href="#35805882">parent</a><span>|</span><a href="#35805696">next</a><span>|</span><label class="collapse" for="c-35807275">[-]</label><label class="expand" for="c-35807275">[1 more]</label></div><br/><div class="children"><div class="content">vim is a text editor.</div><br/></div></div></div></div></div></div></div></div><div id="35803995" class="c"><input type="checkbox" id="c-35803995" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#35803731">root</a><span>|</span><a href="#35803783">parent</a><span>|</span><a href="#35804015">prev</a><span>|</span><a href="#35805658">next</a><span>|</span><label class="collapse" for="c-35803995">[-]</label><label class="expand" for="c-35803995">[4 more]</label></div><br/><div class="children"><div class="content">it doesn&#x27;t. replit-code-v1-3b is a code LLM, ChatGPT is an app on top of LLMs. it compares to OpenAI Codex, a small version of which is behind GitHub Copilot.</div><br/><div id="35805409" class="c"><input type="checkbox" id="c-35805409" checked=""/><div class="controls bullet"><span class="by">mritchie712</span><span>|</span><a href="#35803731">root</a><span>|</span><a href="#35803995">parent</a><span>|</span><a href="#35805768">next</a><span>|</span><label class="collapse" for="c-35805409">[-]</label><label class="expand" for="c-35805409">[1 more]</label></div><br/><div class="children"><div class="content">It (replit-code-v1-3b) is already quite good at explaining code:<p>Input:<p><pre><code>    below is a SQL statement:

    SELECT
      CAST(DATE_TRUNC(&#x27;week&#x27;, &quot;t1&quot;.&quot;TIMESTAMP&quot;) AS DATE) AS &quot;WEEK_START&quot;,
      COUNT(\*) AS &quot;EVENT_COUNT&quot;
    FROM &quot;ANALYTICS&quot;.&quot;POSTHOG&quot;.&quot;POSTHOG_EVENTS&quot; AS &quot;t1&quot;
    GROUP BY
      &quot;WEEK_START&quot;
    ORDER BY
      &quot;WEEK_START&quot;
    LIMIT 2000

    Explain this SQL. Respond in JSON format with the following keys: 
    TITLE, DESCRIPTION, TABLES
    JSON response:
</code></pre>
output:<p><pre><code>    {
        &quot;title&quot;: &quot;Weekly Events Count&quot;,
        &quot;description&quot;: &quot;Count of weekly events&quot;,
        &quot;tables&quot;: [
            {
                &quot;name&quot;: &quot;POSTHOG_EVENTS&quot;,
                &quot;columns&quot;: [
                    &quot;WEEK_START&quot;,
                    &quot;EVENT_COUNT&quot;
                ]
            }
        ]
    }</code></pre></div><br/></div></div><div id="35805768" class="c"><input type="checkbox" id="c-35805768" checked=""/><div class="controls bullet"><span class="by">cubefox</span><span>|</span><a href="#35803731">root</a><span>|</span><a href="#35803995">parent</a><span>|</span><a href="#35805409">prev</a><span>|</span><a href="#35809197">next</a><span>|</span><label class="collapse" for="c-35805768">[-]</label><label class="expand" for="c-35805768">[1 more]</label></div><br/><div class="children"><div class="content">Free ChatGPT is based on code-davinci-002 (GPT-3.5), which is used in OpenAI Codex. See<p><a href="https:&#x2F;&#x2F;platform.openai.com&#x2F;docs&#x2F;model-index-for-researchers" rel="nofollow">https:&#x2F;&#x2F;platform.openai.com&#x2F;docs&#x2F;model-index-for-researchers</a><p><a href="https:&#x2F;&#x2F;help.openai.com&#x2F;en&#x2F;articles&#x2F;6195637-getting-started-with-codex" rel="nofollow">https:&#x2F;&#x2F;help.openai.com&#x2F;en&#x2F;articles&#x2F;6195637-getting-started-...</a></div><br/></div></div><div id="35809197" class="c"><input type="checkbox" id="c-35809197" checked=""/><div class="controls bullet"><span class="by">pottertheotter</span><span>|</span><a href="#35803731">root</a><span>|</span><a href="#35803995">parent</a><span>|</span><a href="#35805768">prev</a><span>|</span><a href="#35805658">next</a><span>|</span><label class="collapse" for="c-35809197">[-]</label><label class="expand" for="c-35809197">[1 more]</label></div><br/><div class="children"><div class="content">Sorry, but this is wrong. OpenAI&#x27;s gpt-3.5-turbo and gpt-4 models (aka ChatGPT) are what it should be compared against. Codex has been deprecated since March, something that has been widely discussed in the LLM world and is prominently noted on the main Codex page: &quot;As of March 2023, the Codex models are now deprecated. Please check out our newer Chat models which are able to do many coding tasks with similar capability&quot;<p>See: <a href="https:&#x2F;&#x2F;platform.openai.com&#x2F;docs&#x2F;guides&#x2F;code" rel="nofollow">https:&#x2F;&#x2F;platform.openai.com&#x2F;docs&#x2F;guides&#x2F;code</a></div><br/></div></div></div></div><div id="35805658" class="c"><input type="checkbox" id="c-35805658" checked=""/><div class="controls bullet"><span class="by">heliophobicdude</span><span>|</span><a href="#35803731">root</a><span>|</span><a href="#35803783">parent</a><span>|</span><a href="#35803995">prev</a><span>|</span><a href="#35804264">next</a><span>|</span><label class="collapse" for="c-35805658">[-]</label><label class="expand" for="c-35805658">[1 more]</label></div><br/><div class="children"><div class="content">Hard to compare them actually. The thing about ChatGPT is the chat part. It was trained to interact and respond with human conversation. This is more like CodePilot, with code complete based off of actual code</div><br/></div></div></div></div><div id="35804264" class="c"><input type="checkbox" id="c-35804264" checked=""/><div class="controls bullet"><span class="by">FanaHOVA</span><span>|</span><a href="#35803731">parent</a><span>|</span><a href="#35803783">prev</a><span>|</span><a href="#35805640">next</a><span>|</span><label class="collapse" for="c-35804264">[-]</label><label class="expand" for="c-35804264">[2 more]</label></div><br/><div class="children"><div class="content">This was a lot of fun to record, and second episode where I get an eval question wrong, I&#x27;m going to be demoted to bot soon lol</div><br/><div id="35807435" class="c"><input type="checkbox" id="c-35807435" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#35803731">root</a><span>|</span><a href="#35804264">parent</a><span>|</span><a href="#35805640">next</a><span>|</span><label class="collapse" for="c-35807435">[-]</label><label class="expand" for="c-35807435">[1 more]</label></div><br/><div class="children"><div class="content">means you are human! like the rest of us</div><br/></div></div></div></div><div id="35805640" class="c"><input type="checkbox" id="c-35805640" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#35803731">parent</a><span>|</span><a href="#35804264">prev</a><span>|</span><a href="#35804959">next</a><span>|</span><label class="collapse" for="c-35805640">[-]</label><label class="expand" for="c-35805640">[1 more]</label></div><br/><div class="children"><div class="content">we also did an interview with Varun Mohan of Codeium, which is another competing code model trained from complete scratch: <a href="https:&#x2F;&#x2F;lspace.swyx.io&#x2F;p&#x2F;varun-mohan#details" rel="nofollow">https:&#x2F;&#x2F;lspace.swyx.io&#x2F;p&#x2F;varun-mohan#details</a></div><br/></div></div></div></div><div id="35804959" class="c"><input type="checkbox" id="c-35804959" checked=""/><div class="controls bullet"><span class="by">sashank_1509</span><span>|</span><a href="#35803731">prev</a><span>|</span><a href="#35803830">next</a><span>|</span><label class="collapse" for="c-35804959">[-]</label><label class="expand" for="c-35804959">[6 more]</label></div><br/><div class="children"><div class="content">Replit: I tried to write HMM Forward function code:<p>```<p># Write a function that performs the forward algorithm of an HMM. Ideally it uses numpy vectorization,<p># But if you cannot do that it is fine too. Just perform forward inference, given HMM parameters and Observations.<p># 
def HMM_forward() :<p><pre><code>    # Write your code here

    # Hint: 

    # - Remember that HMMs are stochastic, so you will need to multiply transition matrices by observation probabilities

    # - Remember that HMMs are stochastic, so you will need to multiply emission matrices by observation probabilities

    # - Remember that HMMs are stochastic, so you will need to multiply emission matrices by transition matrices

    # - Remember that HMMs are stochastic, so you will need to multiply emission matrices by transition matrices

    # - Remember that HMMs are stochastic, so</code></pre>
```
It gets stuck in an infinite loop. 
ChatGPT gets it write, first shot:<p>```<p>import numpy as np<p>def forward_algorithm(A, B, pi, obs):<p><pre><code>    &quot;&quot;&quot;
    Performs the forward algorithm for an HMM.

    Parameters:
        A: numpy.ndarray, shape (N, N)
            Transition matrix of the HMM, where N is the number of states.
        B: numpy.ndarray, shape (N, M)
            Emission matrix of the HMM, where M is the number of possible observations.
        pi: numpy.ndarray, shape (N,)
            Initial probability distribution over states.
        obs: numpy.ndarray, shape (T,)
            Sequence of T observations.
    
    Returns:
        alpha: numpy.ndarray, shape (T, N)
            Forward probabilities for each state at each time step.
    &quot;&quot;&quot;

    T = obs.shape[0]
    N = A.shape[0]

    alpha = np.zeros((T, N))
    alpha[0] = pi * B[:, obs[0]]

    for t in range(1, T):
        alpha[t] = np.dot(alpha[t-1], A) * B[:, obs[t]]

    return alpha</code></pre>
```
OpenAI managed to do the important but extremely hard, they moved out of the DL benchmark frame and made something that is general purpose useful. Great effort and congrats to Replit team though, hopefully they can keep iterating on this and reach ChatGPT capabilities someday</div><br/><div id="35805066" class="c"><input type="checkbox" id="c-35805066" checked=""/><div class="controls bullet"><span class="by">amasad</span><span>|</span><a href="#35804959">parent</a><span>|</span><a href="#35809945">next</a><span>|</span><label class="collapse" for="c-35805066">[-]</label><label class="expand" for="c-35805066">[2 more]</label></div><br/><div class="children"><div class="content">The model is not RLHF&#x27;d or instructed. It&#x27;s an inline autocomplete model so it will get confused if you talk it like you&#x27;re talking to a person. Altho it is possible to finetune it this way. To get better full function completion try giving it the function definition and a descriptive docstring as a prompt.</div><br/></div></div><div id="35809945" class="c"><input type="checkbox" id="c-35809945" checked=""/><div class="controls bullet"><span class="by">fauxpause_</span><span>|</span><a href="#35804959">parent</a><span>|</span><a href="#35805066">prev</a><span>|</span><a href="#35803830">next</a><span>|</span><label class="collapse" for="c-35809945">[-]</label><label class="expand" for="c-35809945">[3 more]</label></div><br/><div class="children"><div class="content">&gt; But if you cannot do that it is fine too. Just perform forward inference, given HMM parameters and Observations.<p>Stuff like this will make your outcomes worse for any model.</div><br/><div id="35810274" class="c"><input type="checkbox" id="c-35810274" checked=""/><div class="controls bullet"><span class="by">sashank_1509</span><span>|</span><a href="#35804959">root</a><span>|</span><a href="#35809945">parent</a><span>|</span><a href="#35803830">next</a><span>|</span><label class="collapse" for="c-35810274">[-]</label><label class="expand" for="c-35810274">[2 more]</label></div><br/><div class="children"><div class="content">Really? My experience with GPT is more the description I add the better the results. I presume this is because it has a longer prompt to attend upon, I think the whole idea of focusing on keywords&#x2F; concise sentences is a very “search engine” paradigm and language models do better the more you describe your question</div><br/><div id="35810890" class="c"><input type="checkbox" id="c-35810890" checked=""/><div class="controls bullet"><span class="by">fauxpause_</span><span>|</span><a href="#35804959">root</a><span>|</span><a href="#35810274">parent</a><span>|</span><a href="#35803830">next</a><span>|</span><label class="collapse" for="c-35810890">[-]</label><label class="expand" for="c-35810890">[1 more]</label></div><br/><div class="children"><div class="content">Details are fine. But think about how this thing works. It does not think about your request. It comes up with the most probable answer. There is some tuning to imply self reflection, but that’s mostly fake. When you say “Do X, but if you can’t do X, do Y”, you may very well encourage the model to do Y without any qualitative assessment over whether it could actually do X.<p>Same for questions where you ask “is X good or bad? And why?”. It answers good or bad before it comes up with the reasons. That’s very plausibly ok, but it’s different from how people imagine it works and thinks.</div><br/></div></div></div></div></div></div></div></div><div id="35803830" class="c"><input type="checkbox" id="c-35803830" checked=""/><div class="controls bullet"><span class="by">tyingq</span><span>|</span><a href="#35804959">prev</a><span>|</span><a href="#35804035">next</a><span>|</span><label class="collapse" for="c-35803830">[-]</label><label class="expand" for="c-35803830">[12 more]</label></div><br/><div class="children"><div class="content">More tools in the field is great! I tried a few things, and it&#x27;s reasonable, but it does have some quirks that seem to repeat, like:<p>I tried a prompt of:<p><pre><code>  # python function that returns a random integer between min and max
</code></pre>
And it produced:<p><pre><code>  def random_int(min, max):
      return random.randint(min, max)

  # define the size of the grid
  n = 5
</code></pre>
It doesn&#x27;t add the needed import statement, and I&#x27;m unclear why it&#x27;s &quot;defining the size of the grid&quot;.</div><br/><div id="35803903" class="c"><input type="checkbox" id="c-35803903" checked=""/><div class="controls bullet"><span class="by">amasad</span><span>|</span><a href="#35803830">parent</a><span>|</span><a href="#35803902">next</a><span>|</span><label class="collapse" for="c-35803903">[-]</label><label class="expand" for="c-35803903">[1 more]</label></div><br/><div class="children"><div class="content">LLMs generally but more so small models will keep going and generate seemingly unrelated things. On the frontend tools like Copilot and Ghostwriter do a lot of things like use stopwords or simply not show completions outside a single block.<p>As for your prompt, it&#x27;s following your prompt a little too closely and generating just the function. You can however condition it that this is the start of the program it will do the import, e.g.<p><pre><code>   # python function that returns a random integer between min and max
   import
</code></pre>
This is in fact a suggestion from OpenAI on best practices for prompting called &quot;leading words&quot; <a href="https:&#x2F;&#x2F;help.openai.com&#x2F;en&#x2F;articles&#x2F;6654000-best-practices-for-prompt-engineering-with-openai-api" rel="nofollow">https:&#x2F;&#x2F;help.openai.com&#x2F;en&#x2F;articles&#x2F;6654000-best-practices-f...</a></div><br/></div></div><div id="35803902" class="c"><input type="checkbox" id="c-35803902" checked=""/><div class="controls bullet"><span class="by">circuit10</span><span>|</span><a href="#35803830">parent</a><span>|</span><a href="#35803903">prev</a><span>|</span><a href="#35807217">next</a><span>|</span><label class="collapse" for="c-35803902">[-]</label><label class="expand" for="c-35803902">[7 more]</label></div><br/><div class="children"><div class="content">That&#x27;s because it&#x27;s not following instructions like ChatGPT, it&#x27;s just trying to guess that could plausibly come after what you put, like Copilot or the old GPT-3 models</div><br/><div id="35804519" class="c"><input type="checkbox" id="c-35804519" checked=""/><div class="controls bullet"><span class="by">jeremyjh</span><span>|</span><a href="#35803830">root</a><span>|</span><a href="#35803902">parent</a><span>|</span><a href="#35804198">next</a><span>|</span><label class="collapse" for="c-35804519">[-]</label><label class="expand" for="c-35804519">[4 more]</label></div><br/><div class="children"><div class="content">Isn’t ChatGPT also just generating plausible text that could be a response to an instruction?</div><br/><div id="35804601" class="c"><input type="checkbox" id="c-35804601" checked=""/><div class="controls bullet"><span class="by">whimsicalism</span><span>|</span><a href="#35803830">root</a><span>|</span><a href="#35804519">parent</a><span>|</span><a href="#35804954">next</a><span>|</span><label class="collapse" for="c-35804601">[-]</label><label class="expand" for="c-35804601">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not generating the most likely next word in the &#x27;meta-corpora&#x27; of all possible discussions similar to the ones it has been trained on, it is trying to generate plausible text that would be scored well as a helpful assistant - and in the process has transferred knowledge acquired from its pre-training task.</div><br/></div></div><div id="35804954" class="c"><input type="checkbox" id="c-35804954" checked=""/><div class="controls bullet"><span class="by">circuit10</span><span>|</span><a href="#35803830">root</a><span>|</span><a href="#35804519">parent</a><span>|</span><a href="#35804601">prev</a><span>|</span><a href="#35804830">next</a><span>|</span><label class="collapse" for="c-35804954">[-]</label><label class="expand" for="c-35804954">[1 more]</label></div><br/><div class="children"><div class="content">&quot;that could be a response to an instruction&quot; is the critical part here</div><br/></div></div><div id="35804830" class="c"><input type="checkbox" id="c-35804830" checked=""/><div class="controls bullet"><span class="by">travisjungroth</span><span>|</span><a href="#35803830">root</a><span>|</span><a href="#35804519">parent</a><span>|</span><a href="#35804954">prev</a><span>|</span><a href="#35804198">next</a><span>|</span><label class="collapse" for="c-35804830">[-]</label><label class="expand" for="c-35804830">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, at their core they’re both trying to guess&#x2F;generate what comes next. Differences: Being trained towards conversations versus code. Hyperparameters set to stop differently. “Wrappers” that form the prompt.</div><br/></div></div></div></div><div id="35804198" class="c"><input type="checkbox" id="c-35804198" checked=""/><div class="controls bullet"><span class="by">minkzilla</span><span>|</span><a href="#35803830">root</a><span>|</span><a href="#35803902">parent</a><span>|</span><a href="#35804519">prev</a><span>|</span><a href="#35807217">next</a><span>|</span><label class="collapse" for="c-35804198">[-]</label><label class="expand" for="c-35804198">[2 more]</label></div><br/><div class="children"><div class="content">and imports are (almost) always at the top of your file not with this function</div><br/><div id="35804283" class="c"><input type="checkbox" id="c-35804283" checked=""/><div class="controls bullet"><span class="by">vharuck</span><span>|</span><a href="#35803830">root</a><span>|</span><a href="#35804198">parent</a><span>|</span><a href="#35807217">next</a><span>|</span><label class="collapse" for="c-35804283">[-]</label><label class="expand" for="c-35804283">[1 more]</label></div><br/><div class="children"><div class="content">I tried the same input, except wrapping it in triple-quotes instead of commenting it.  So that it would match the standard practice for module doc strings.  Here&#x27;s the result:<p><pre><code>    &quot;&quot;&quot;python function that returns a random integer between min and max&quot;&quot;&quot;
        return random.randint(min, max)


    def gen_random_float(min, max):
        &quot;&quot;&quot;python function that returns a random float between min and max&quot;&quot;&quot;
        return random.uniform(
</code></pre>
So, it assumed the triple-quote was a function&#x27;s doc string, despite it not being indented.  It then assumes I&#x27;ll want a similar function for floats (I assume it was cut off by a token limit).</div><br/></div></div></div></div></div></div><div id="35807217" class="c"><input type="checkbox" id="c-35807217" checked=""/><div class="controls bullet"><span class="by">tyingq</span><span>|</span><a href="#35803830">parent</a><span>|</span><a href="#35803902">prev</a><span>|</span><a href="#35803918">next</a><span>|</span><label class="collapse" for="c-35807217">[-]</label><label class="expand" for="c-35807217">[1 more]</label></div><br/><div class="children"><div class="content">Based on the the replies, I tried a different prompt:<p><pre><code>  # python script that prints out an integer between min and max
</code></pre>
And it did better.  Included the import, didn&#x27;t add unrelated code, but did still put the code inside a function.</div><br/></div></div><div id="35803918" class="c"><input type="checkbox" id="c-35803918" checked=""/><div class="controls bullet"><span class="by">radq</span><span>|</span><a href="#35803830">parent</a><span>|</span><a href="#35807217">prev</a><span>|</span><a href="#35805931">next</a><span>|</span><label class="collapse" for="c-35803918">[-]</label><label class="expand" for="c-35803918">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve had the issue of generating random code after the completion with other models as well; it&#x27;s due to how the models are trained. You need to stop generating when you encounter token(s) that indicate you&#x27;re done - see <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;replit&#x2F;replit-code-v1-3b#post-processing" rel="nofollow">https:&#x2F;&#x2F;huggingface.co&#x2F;replit&#x2F;replit-code-v1-3b#post-process...</a></div><br/></div></div><div id="35805931" class="c"><input type="checkbox" id="c-35805931" checked=""/><div class="controls bullet"><span class="by">agilob</span><span>|</span><a href="#35803830">parent</a><span>|</span><a href="#35803918">prev</a><span>|</span><a href="#35804035">next</a><span>|</span><label class="collapse" for="c-35805931">[-]</label><label class="expand" for="c-35805931">[1 more]</label></div><br/><div class="children"><div class="content">I get such unrelated statements from copilot too, not often, but a few I remember.</div><br/></div></div></div></div><div id="35804035" class="c"><input type="checkbox" id="c-35804035" checked=""/><div class="controls bullet"><span class="by">GreedClarifies</span><span>|</span><a href="#35803830">prev</a><span>|</span><a href="#35810953">next</a><span>|</span><label class="collapse" for="c-35804035">[-]</label><label class="expand" for="c-35804035">[8 more]</label></div><br/><div class="children"><div class="content">This is amazing work and bravo on to the people working on redpajama.<p>This is fantastic for the world, this means LLMs will not be controlled by a couple of companies with the associated rents.<p>Yes, private LLMs will likely be a couple of years ahead of &#x27;free&#x27; alternatives, but that&#x27;s <i>OK</i>, we want to incentivize for profit research so long as the services are low priced in time (and in this case in short order).<p>AMAZING WORK.</div><br/><div id="35807179" class="c"><input type="checkbox" id="c-35807179" checked=""/><div class="controls bullet"><span class="by">laweijfmvo</span><span>|</span><a href="#35804035">parent</a><span>|</span><a href="#35805225">next</a><span>|</span><label class="collapse" for="c-35807179">[-]</label><label class="expand" for="c-35807179">[2 more]</label></div><br/><div class="children"><div class="content">My first reaction was, &quot;why is replit building LLMs,&quot; but I guess it fits their needs to have one optimized for their use. But I wonder, is this the beginning of another wave of &quot;every company is an AI company?&quot; Are we going to see a spike in tech hiring around AI&#x2F;LLM, money starting to flow again, etc? And how many years until it all blows up and the layoffs start?</div><br/><div id="35808471" class="c"><input type="checkbox" id="c-35808471" checked=""/><div class="controls bullet"><span class="by">dpflan</span><span>|</span><a href="#35804035">root</a><span>|</span><a href="#35807179">parent</a><span>|</span><a href="#35805225">next</a><span>|</span><label class="collapse" for="c-35808471">[-]</label><label class="expand" for="c-35808471">[1 more]</label></div><br/><div class="children"><div class="content">Finetuning models and LLMs (and any model) is going to a be common practice . Each company is its own domain, which domain knowledge and data to specialize open sourced models or used other models to distill&#x2F;teach their own proprietary model (home grown or modify someone else&#x27;s).</div><br/></div></div></div></div><div id="35805225" class="c"><input type="checkbox" id="c-35805225" checked=""/><div class="controls bullet"><span class="by">m3kw9</span><span>|</span><a href="#35804035">parent</a><span>|</span><a href="#35807179">prev</a><span>|</span><a href="#35804158">next</a><span>|</span><label class="collapse" for="c-35805225">[-]</label><label class="expand" for="c-35805225">[2 more]</label></div><br/><div class="children"><div class="content">Have you even tried it? It’s pretty bad</div><br/><div id="35805604" class="c"><input type="checkbox" id="c-35805604" checked=""/><div class="controls bullet"><span class="by">GreedClarifies</span><span>|</span><a href="#35804035">root</a><span>|</span><a href="#35805225">parent</a><span>|</span><a href="#35804158">next</a><span>|</span><label class="collapse" for="c-35805604">[-]</label><label class="expand" for="c-35805604">[1 more]</label></div><br/><div class="children"><div class="content">But that&#x27;s <i>fine</i> it can be a year or two behind the state of the art. That&#x27;s not the point.<p>The point is that there will be alternatives and that will reduce the price in time further increasing the impact of the technology.<p>There was a possible future where only MSFT and maybe GOOG and maybe one or two other companies had this technology and extracted massive rents.</div><br/></div></div></div></div><div id="35804158" class="c"><input type="checkbox" id="c-35804158" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#35804035">parent</a><span>|</span><a href="#35805225">prev</a><span>|</span><a href="#35810953">next</a><span>|</span><label class="collapse" for="c-35804158">[-]</label><label class="expand" for="c-35804158">[3 more]</label></div><br/><div class="children"><div class="content">to be clear this work is not based on redpajama - though we did discuss that in the previous episode <a href="https:&#x2F;&#x2F;twitter.com&#x2F;swyx&#x2F;status&#x2F;1648080532734087168?s=46&amp;t=90xQ8sGy63D2OtiaoGJuww" rel="nofollow">https:&#x2F;&#x2F;twitter.com&#x2F;swyx&#x2F;status&#x2F;1648080532734087168?s=46&amp;t=9...</a></div><br/><div id="35804281" class="c"><input type="checkbox" id="c-35804281" checked=""/><div class="controls bullet"><span class="by">GreedClarifies</span><span>|</span><a href="#35804035">root</a><span>|</span><a href="#35804158">parent</a><span>|</span><a href="#35810953">next</a><span>|</span><label class="collapse" for="c-35804281">[-]</label><label class="expand" for="c-35804281">[2 more]</label></div><br/><div class="children"><div class="content">Oh my bad!<p>I thought I read that, is it based upon:<p><a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2211.15533" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2211.15533</a> (The Stack) ?</div><br/><div id="35805121" class="c"><input type="checkbox" id="c-35805121" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#35804035">root</a><span>|</span><a href="#35804281">parent</a><span>|</span><a href="#35810953">next</a><span>|</span><label class="collapse" for="c-35805121">[-]</label><label class="expand" for="c-35805121">[1 more]</label></div><br/><div class="children"><div class="content">partially. Reza discussed their data pipeline in the blogpost that we reference in the show notes</div><br/></div></div></div></div></div></div></div></div><div id="35810953" class="c"><input type="checkbox" id="c-35810953" checked=""/><div class="controls bullet"><span class="by">dvt</span><span>|</span><a href="#35804035">prev</a><span>|</span><a href="#35803856">next</a><span>|</span><label class="collapse" for="c-35810953">[-]</label><label class="expand" for="c-35810953">[2 more]</label></div><br/><div class="children"><div class="content">I genuinely don&#x27;t understand how anyone can use something like this and seriously think &quot;oh yeah, this is revolutionary.&quot; It&#x27;s almost complete garbage and can&#x27;t do anything <i>remotely</i> interesting.<p><pre><code>    # a method that approximates the hyperbolic tangent (clamped tanh)

    def rational_tanh(x):
        return (x + 1) &#x2F; (x - 1)
</code></pre>
Even gave it the BIG hint of a &quot;clamped&quot; and &quot;rational&quot; tanh, but that ain&#x27;t it, chief. Forget GPT-4, I would be embarrassed to even show this as a tech demo.</div><br/><div id="35812798" class="c"><input type="checkbox" id="c-35812798" checked=""/><div class="controls bullet"><span class="by">afro88</span><span>|</span><a href="#35810953">parent</a><span>|</span><a href="#35803856">next</a><span>|</span><label class="collapse" for="c-35812798">[-]</label><label class="expand" for="c-35812798">[1 more]</label></div><br/><div class="children"><div class="content">I use &quot;something like this&quot; (GPT4) all the time. Use a good model. Can&#x27;t wait till proper open source models catch up, but they&#x27;re not there yet.<p>Here&#x27;s GPT4&#x27;s response:<p>```<p>import math<p>def clamped_tanh(x, n_terms=10):
    &quot;&quot;&quot;
    Approximate the hyperbolic tangent (tanh) function using a Maclaurin series expansion.<p><pre><code>    Args:
        x (float): The input value for which to compute the tanh.
        n_terms (int, optional): The number of terms to use in the Maclaurin series. Default is 10.

    Returns:
        float: The approximated tanh value.
    &quot;&quot;&quot;
    tanh_approx = 0

    for n in range(n_terms):
        coef = ((-1) ** n) * (2 * n + 1)
        term = coef * (x ** (2 * n + 1)) &#x2F; math.factorial(2 * n + 1)
        tanh_approx += term

    # Clamping the tanh approximation to the range [-1, 1]
    tanh_approx = max(-1, min(tanh_approx, 1))

    return tanh_approx
</code></pre>
# Example usage
x = 0.5
result = clamped_tanh(x)
print(f&quot;clamped_tanh({x}) = {result}&quot;)<p>```</div><br/></div></div></div></div><div id="35803856" class="c"><input type="checkbox" id="c-35803856" checked=""/><div class="controls bullet"><span class="by">waffletower</span><span>|</span><a href="#35810953">prev</a><span>|</span><a href="#35807437">next</a><span>|</span><label class="collapse" for="c-35803856">[-]</label><label class="expand" for="c-35803856">[9 more]</label></div><br/><div class="children"><div class="content">No Clojure.  No Julia.  No Haskell.  No Racket.  No Scheme. No Common Lisp.  No OCaml. And, as much as I despise Microsoft, No C#.  No F#.  No Swift.  No Objective-C. No Perl. No Datalog. A glaringly lacking choice of languages.</div><br/><div id="35805101" class="c"><input type="checkbox" id="c-35805101" checked=""/><div class="controls bullet"><span class="by">ubertaco</span><span>|</span><a href="#35803856">parent</a><span>|</span><a href="#35811526">next</a><span>|</span><label class="collapse" for="c-35805101">[-]</label><label class="expand" for="c-35805101">[1 more]</label></div><br/><div class="children"><div class="content">I fed it some OCaml and it worked, though the example was trivial:<p><pre><code>    type point = { x: int; y : int }
    let manhattan_distance (a: point) (b: point) : int =
</code></pre>
which it completed to<p><pre><code>    type point = { x: int; y : int }
    let manhattan_distance (a: point) (b: point) : int =
        abs (a.x - b.x) + abs (a.y - b.y)
</code></pre>
...which is a valid and correct OCaml definition of this method:<p><a href="https:&#x2F;&#x2F;try.ocamlpro.com&#x2F;#code&#x2F;type&#x27;point&#x27;=&#x27;$4&#x27;x:&#x27;int;&#x27;y&#x27;:&#x27;int&#x27;$6!let&#x27;manhattan_distance&#x27;(a:&#x27;point)&#x27;(b:&#x27;point)&#x27;:&#x27;int&#x27;=!abs&#x27;(a.x&#x27;-&#x27;b.x)&#x27;+&#x27;abs&#x27;(a.y&#x27;-&#x27;b.y)!;;!!let&#x27;origin&#x27;=&#x27;$4x&#x27;=&#x27;0;&#x27;y&#x27;=&#x27;0$6&#x27;in!let&#x27;dest&#x27;=&#x27;$4x&#x27;=&#x27;2;&#x27;y&#x27;=&#x27;3$6&#x27;in!Printf.printf&#x27;$($+d$(&#x27;(manhattan_distance&#x27;origin&#x27;dest)" rel="nofollow">https:&#x2F;&#x2F;try.ocamlpro.com&#x2F;#code&#x2F;type&#x27;point&#x27;=&#x27;$4&#x27;x:&#x27;int;&#x27;y&#x27;:&#x27;i...</a></div><br/></div></div><div id="35811526" class="c"><input type="checkbox" id="c-35811526" checked=""/><div class="controls bullet"><span class="by">esjeon</span><span>|</span><a href="#35803856">parent</a><span>|</span><a href="#35805101">prev</a><span>|</span><a href="#35804478">next</a><span>|</span><label class="collapse" for="c-35811526">[-]</label><label class="expand" for="c-35811526">[1 more]</label></div><br/><div class="children"><div class="content">I hate to admit, but Python, C, Java, and JS cover most of the modern programming. But not supporting C# sounds like a bad idea.</div><br/></div></div><div id="35804478" class="c"><input type="checkbox" id="c-35804478" checked=""/><div class="controls bullet"><span class="by">Dayshine</span><span>|</span><a href="#35803856">parent</a><span>|</span><a href="#35811526">prev</a><span>|</span><a href="#35805728">next</a><span>|</span><label class="collapse" for="c-35804478">[-]</label><label class="expand" for="c-35804478">[1 more]</label></div><br/><div class="children"><div class="content">C# was available in the dataset they link, and is the most glaring ommission by global usage...</div><br/></div></div><div id="35805728" class="c"><input type="checkbox" id="c-35805728" checked=""/><div class="controls bullet"><span class="by">mclide</span><span>|</span><a href="#35803856">parent</a><span>|</span><a href="#35804478">prev</a><span>|</span><a href="#35804083">next</a><span>|</span><label class="collapse" for="c-35805728">[-]</label><label class="expand" for="c-35805728">[1 more]</label></div><br/><div class="children"><div class="content">Despite the lack of examples, it still completes trivial clojure like &quot;(defn connect [&quot; and other lisp syntax like &quot;(define (hello&quot; which is promising for further refinement training on Lisp languages.</div><br/></div></div><div id="35804083" class="c"><input type="checkbox" id="c-35804083" checked=""/><div class="controls bullet"><span class="by">ebiester</span><span>|</span><a href="#35803856">parent</a><span>|</span><a href="#35805728">prev</a><span>|</span><a href="#35806923">next</a><span>|</span><label class="collapse" for="c-35804083">[-]</label><label class="expand" for="c-35804083">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m sure that has to do with the dataset available to them.</div><br/><div id="35804614" class="c"><input type="checkbox" id="c-35804614" checked=""/><div class="controls bullet"><span class="by">runnerup</span><span>|</span><a href="#35803856">root</a><span>|</span><a href="#35804083">parent</a><span>|</span><a href="#35806923">next</a><span>|</span><label class="collapse" for="c-35804614">[-]</label><label class="expand" for="c-35804614">[1 more]</label></div><br/><div class="children"><div class="content">Which is a deduplicated version of this: <a href="https:&#x2F;&#x2F;www.bigcode-project.org&#x2F;docs&#x2F;about&#x2F;the-stack&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.bigcode-project.org&#x2F;docs&#x2F;about&#x2F;the-stack&#x2F;</a><p>And probably, yes. While it contains 358 programming languages, obviously there&#x27;s a long tail after the 20 most-represented languages. Some people might not expect without thinking about it for a bit that many of the most-represented &quot;languages&quot; are actually things like JSON, XML, HTML, CSV, text, markdown, YAML, SVG.<p>Also note that it won&#x27;t be able to parse natural language nearly as well without additionally being trained on something like the LAION dataset, so this version will be more of an autocomplete like Copilot rather than something which can manifest high level business logic from whole cloth like ChatGPT.</div><br/></div></div></div></div><div id="35806923" class="c"><input type="checkbox" id="c-35806923" checked=""/><div class="controls bullet"><span class="by">sitkack</span><span>|</span><a href="#35803856">parent</a><span>|</span><a href="#35804083">prev</a><span>|</span><a href="#35807437">next</a><span>|</span><label class="collapse" for="c-35806923">[-]</label><label class="expand" for="c-35806923">[2 more]</label></div><br/><div class="children"><div class="content">You could take it and finetune it on a bunch of Lisps, probably cost on the order of 50-500 to do that.</div><br/><div id="35807288" class="c"><input type="checkbox" id="c-35807288" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#35803856">root</a><span>|</span><a href="#35806923">parent</a><span>|</span><a href="#35807437">next</a><span>|</span><label class="collapse" for="c-35807288">[-]</label><label class="expand" for="c-35807288">[1 more]</label></div><br/><div class="children"><div class="content">if anyone from MosaicML is reading this, i’d love a guide on how to do exactly this!</div><br/></div></div></div></div></div></div><div id="35807437" class="c"><input type="checkbox" id="c-35807437" checked=""/><div class="controls bullet"><span class="by">chaxor</span><span>|</span><a href="#35803856">prev</a><span>|</span><a href="#35811808">next</a><span>|</span><label class="collapse" for="c-35807437">[-]</label><label class="expand" for="c-35807437">[7 more]</label></div><br/><div class="children"><div class="content">This is a bit hard to believe that the system is decent at producing code which captures complex ideas and higher level structure when the tokens&#x2F;param value is &gt;30 (it&#x27;s ~200 here? ) The &#x27;good&#x27; models (meaning having lots of &#x27;knowledge&#x27; or &#x27;memorization&#x27; about the dataset) typically tend to be around 2 tokens&#x2F;param and models with decent generation of language with less knowledge&#x2F;memorization are around 30 tokens&#x2F;param.
Perhaps the domain allows for this, but due to the fact that the linguistic interface on the input is still needed... It&#x27;s hard to believe.</div><br/><div id="35807880" class="c"><input type="checkbox" id="c-35807880" checked=""/><div class="controls bullet"><span class="by">gnramires</span><span>|</span><a href="#35807437">parent</a><span>|</span><a href="#35807488">next</a><span>|</span><label class="collapse" for="c-35807880">[-]</label><label class="expand" for="c-35807880">[1 more]</label></div><br/><div class="children"><div class="content">Tokens&#x2F;param shouldn&#x27;t matter more than the total training FLOPs, I believe. Clearly if we train a your claimed &#x27;ideal&#x27; 2 tokens&#x2F;param a very small dataset (not many tokens in the first place), it wouldn&#x27;t have enough data to properly learn the relevant languages. Once there is enough data, then it becomes a question of model capacity (does it have enough degrees of freedom to support the computational structures needed?).<p>I believe the overparametrization largely helps with generalization and reducing overfitting, at 2 tokens&#x2F;param there&#x27;s much more degrees of freedom than structures that can be learned from what I can tell (the extra capacity just provides good breathing room for internal structures). But if your model has enough capacity, and you can find a good enough training method (and you have enough data to learn the task), then you should be able to succeed in arbitrary low tokens&#x2F;param, which is good to keep in mind to make efficient models.</div><br/></div></div><div id="35807488" class="c"><input type="checkbox" id="c-35807488" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#35807437">parent</a><span>|</span><a href="#35807880">prev</a><span>|</span><a href="#35807764">next</a><span>|</span><label class="collapse" for="c-35807488">[-]</label><label class="expand" for="c-35807488">[2 more]</label></div><br/><div class="children"><div class="content">this kind of critical thinking is exactly what replit is going to need for their stated goal of doing whole-app generation. right now they only test it on AmjadEval. you… might wanna consider joining them to work on it?</div><br/><div id="35811457" class="c"><input type="checkbox" id="c-35811457" checked=""/><div class="controls bullet"><span class="by">chaxor</span><span>|</span><a href="#35807437">root</a><span>|</span><a href="#35807488">parent</a><span>|</span><a href="#35807764">next</a><span>|</span><label class="collapse" for="c-35811457">[-]</label><label class="expand" for="c-35811457">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not sure noticing tokens&#x2F;params or simplicial modeling properties occur requires much critical thought - perhaps it&#x27;s just a standard first thought for anyone given an LM now.  
I&#x27;ve worked tangentially to NLP for about 7 years in academia, but most of my work has been focused on a less known field of mathematics applied to either to outputs or to the NNs, as well as bioinformatics.  As such, my expertise may not be as refined as the real players in the field such as Glaese, Finn, Velockovic, etc. but I try typically keep up with the actual key advancements in the field (usually the stuff few people notice).  This area takes far too much compute capability for many people to actually become experts in it, so much of my interests have been less on <i>large</i> LMs and more towards algorithms.
But I suppose I agree that it is frustrating to see how little knowledge many of the hype-filled crowds possess that are piling into this area. (Not calling anyone specifically out in this thread, just in general across the internet)</div><br/></div></div></div></div><div id="35807764" class="c"><input type="checkbox" id="c-35807764" checked=""/><div class="controls bullet"><span class="by">EvgeniyZh</span><span>|</span><a href="#35807437">parent</a><span>|</span><a href="#35807488">prev</a><span>|</span><a href="#35811808">next</a><span>|</span><label class="collapse" for="c-35807764">[-]</label><label class="expand" for="c-35807764">[3 more]</label></div><br/><div class="children"><div class="content">Are you saying the less you train the model the better it is? I&#x27;m confused</div><br/><div id="35809930" class="c"><input type="checkbox" id="c-35809930" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#35807437">root</a><span>|</span><a href="#35807764">parent</a><span>|</span><a href="#35811808">next</a><span>|</span><label class="collapse" for="c-35809930">[-]</label><label class="expand" for="c-35809930">[2 more]</label></div><br/><div class="children"><div class="content">i believe GP is referencing the Kaplan and Chinchilla scaling laws. we reference those in the podcast but i’m not sure if some deeper insight is being hinted at here where different scaling laws apply for different domains&#x2F;purposes</div><br/><div id="35812752" class="c"><input type="checkbox" id="c-35812752" checked=""/><div class="controls bullet"><span class="by">EvgeniyZh</span><span>|</span><a href="#35807437">root</a><span>|</span><a href="#35809930">parent</a><span>|</span><a href="#35811808">next</a><span>|</span><label class="collapse" for="c-35812752">[-]</label><label class="expand" for="c-35812752">[1 more]</label></div><br/><div class="children"><div class="content">But these say exactly the opposite, the more tok&#x2F;param the better. There is some optimum after which you need more training FLOPS to improve than if you add parameters but it is definitely not the other way around</div><br/></div></div></div></div></div></div></div></div><div id="35811808" class="c"><input type="checkbox" id="c-35811808" checked=""/><div class="controls bullet"><span class="by">markeibes</span><span>|</span><a href="#35807437">prev</a><span>|</span><a href="#35804793">next</a><span>|</span><label class="collapse" for="c-35811808">[-]</label><label class="expand" for="c-35811808">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m always sad to see these things being trained on a tiny number of programming languages. Makes it harder still for the good languages to compete.</div><br/></div></div><div id="35804793" class="c"><input type="checkbox" id="c-35804793" checked=""/><div class="controls bullet"><span class="by">Imnimo</span><span>|</span><a href="#35811808">prev</a><span>|</span><a href="#35811997">next</a><span>|</span><label class="collapse" for="c-35804793">[-]</label><label class="expand" for="c-35804793">[1 more]</label></div><br/><div class="children"><div class="content">Tried it out on the HuggingFace demo, with default settings.<p>Prompt:<p>&gt;def nth_prime(n):<p>Completion:<p>&gt;    if n == 1:<p>&gt;        return 2<p>&gt;    if n == 2:<p>&gt;        return 3<p>&gt;    if n == 3:<p>&gt;        return 5<p>&gt;    if n == 4</div><br/></div></div><div id="35811997" class="c"><input type="checkbox" id="c-35811997" checked=""/><div class="controls bullet"><span class="by">abdellah123</span><span>|</span><a href="#35804793">prev</a><span>|</span><a href="#35805270">next</a><span>|</span><label class="collapse" for="c-35811997">[-]</label><label class="expand" for="c-35811997">[1 more]</label></div><br/><div class="children"><div class="content">&quot;1M concurrent containers&quot;
curious about replit containers. Do they run on firecracker?</div><br/></div></div><div id="35805270" class="c"><input type="checkbox" id="c-35805270" checked=""/><div class="controls bullet"><span class="by">robby_w_g</span><span>|</span><a href="#35811997">prev</a><span>|</span><a href="#35807220">next</a><span>|</span><label class="collapse" for="c-35805270">[-]</label><label class="expand" for="c-35805270">[12 more]</label></div><br/><div class="children"><div class="content">I recognized the name Replit and couldn&#x27;t remember why. A quick search reminded me: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=27424195" rel="nofollow">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=27424195</a></div><br/><div id="35808823" class="c"><input type="checkbox" id="c-35808823" checked=""/><div class="controls bullet"><span class="by">ec109685</span><span>|</span><a href="#35805270">parent</a><span>|</span><a href="#35805825">next</a><span>|</span><label class="collapse" for="c-35808823">[-]</label><label class="expand" for="c-35808823">[2 more]</label></div><br/><div class="children"><div class="content">This founder has extreme views and full of hyperbole: <a href="https:&#x2F;&#x2F;twitter.com&#x2F;amasad&#x2F;status&#x2F;1504092244168478728?s=20" rel="nofollow">https:&#x2F;&#x2F;twitter.com&#x2F;amasad&#x2F;status&#x2F;1504092244168478728?s=20</a></div><br/><div id="35808974" class="c"><input type="checkbox" id="c-35808974" checked=""/><div class="controls bullet"><span class="by">amasad</span><span>|</span><a href="#35805270">root</a><span>|</span><a href="#35808823">parent</a><span>|</span><a href="#35805825">next</a><span>|</span><label class="collapse" for="c-35808974">[-]</label><label class="expand" for="c-35808974">[1 more]</label></div><br/><div class="children"><div class="content">Is this the best you can find? not even top 10 bangers.</div><br/></div></div></div></div><div id="35805825" class="c"><input type="checkbox" id="c-35805825" checked=""/><div class="controls bullet"><span class="by">stephenjayakar</span><span>|</span><a href="#35805270">parent</a><span>|</span><a href="#35808823">prev</a><span>|</span><a href="#35806329">next</a><span>|</span><label class="collapse" for="c-35805825">[-]</label><label class="expand" for="c-35805825">[6 more]</label></div><br/><div class="children"><div class="content">this feels like an attempt to hive mind against anything cool from this company</div><br/><div id="35806058" class="c"><input type="checkbox" id="c-35806058" checked=""/><div class="controls bullet"><span class="by">robby_w_g</span><span>|</span><a href="#35805270">root</a><span>|</span><a href="#35805825">parent</a><span>|</span><a href="#35806043">next</a><span>|</span><label class="collapse" for="c-35806058">[-]</label><label class="expand" for="c-35806058">[1 more]</label></div><br/><div class="children"><div class="content">I think it&#x27;s fair to evaluate a company&#x27;s behavior before engaging in business with them. And I personally dislike persons in power abusing their position, which is why I remembered the company name almost two years later.<p>I haven&#x27;t heard of any similar behavior since then, which is a good sign. But a reputation can be a hard thing to shake. The CEO should have considered that before doing what he did.</div><br/></div></div><div id="35806043" class="c"><input type="checkbox" id="c-35806043" checked=""/><div class="controls bullet"><span class="by">naillo</span><span>|</span><a href="#35805270">root</a><span>|</span><a href="#35805825">parent</a><span>|</span><a href="#35806058">prev</a><span>|</span><a href="#35806028">next</a><span>|</span><label class="collapse" for="c-35806043">[-]</label><label class="expand" for="c-35806043">[1 more]</label></div><br/><div class="children"><div class="content">Threatening a guy for making an open source version of replit sounds pretty crummy in my eyes.</div><br/></div></div><div id="35806028" class="c"><input type="checkbox" id="c-35806028" checked=""/><div class="controls bullet"><span class="by">ibrarmalik</span><span>|</span><a href="#35805270">root</a><span>|</span><a href="#35805825">parent</a><span>|</span><a href="#35806043">prev</a><span>|</span><a href="#35805957">next</a><span>|</span><label class="collapse" for="c-35806028">[-]</label><label class="expand" for="c-35806028">[1 more]</label></div><br/><div class="children"><div class="content">I think people are smart enough to receive extra information and do whatever they want with that.</div><br/></div></div><div id="35805957" class="c"><input type="checkbox" id="c-35805957" checked=""/><div class="controls bullet"><span class="by">dimgl</span><span>|</span><a href="#35805270">root</a><span>|</span><a href="#35805825">parent</a><span>|</span><a href="#35806028">prev</a><span>|</span><a href="#35806329">next</a><span>|</span><label class="collapse" for="c-35805957">[-]</label><label class="expand" for="c-35805957">[2 more]</label></div><br/><div class="children"><div class="content">+1, this is unnecessary.</div><br/><div id="35806074" class="c"><input type="checkbox" id="c-35806074" checked=""/><div class="controls bullet"><span class="by">aardshark</span><span>|</span><a href="#35805270">root</a><span>|</span><a href="#35805957">parent</a><span>|</span><a href="#35806329">next</a><span>|</span><label class="collapse" for="c-35806074">[-]</label><label class="expand" for="c-35806074">[1 more]</label></div><br/><div class="children"><div class="content">Alternatively, it&#x27;s called consequences of your actions. Don&#x27;t be surprised if shitty behaviour comes back to bite you.</div><br/></div></div></div></div></div></div></div></div><div id="35807220" class="c"><input type="checkbox" id="c-35807220" checked=""/><div class="controls bullet"><span class="by">davidy123</span><span>|</span><a href="#35805270">prev</a><span>|</span><a href="#35804432">next</a><span>|</span><label class="collapse" for="c-35807220">[-]</label><label class="expand" for="c-35807220">[2 more]</label></div><br/><div class="children"><div class="content">I keep thinking there should be a way to train a copilot against just one set of code libraries. I know LLMs require training against a lot of text to get their smarts, but is there a way to set this up so a model can be created for a specific library by anyone, so it could provide open source support via a transformer + model? Maybe this would be a better approach than a jack of all trades, master of none.</div><br/><div id="35811055" class="c"><input type="checkbox" id="c-35811055" checked=""/><div class="controls bullet"><span class="by">nl</span><span>|</span><a href="#35807220">parent</a><span>|</span><a href="#35804432">next</a><span>|</span><label class="collapse" for="c-35811055">[-]</label><label class="expand" for="c-35811055">[1 more]</label></div><br/><div class="children"><div class="content">Yes, this is what fine tuning is for.<p>It&#x27;s pretty obvious that lots of people will want to take a strong code completion model, then fine tune it on their docs + libraries and then make it available inside their docs&#x2F;discord&#x2F;slack as a support thing.</div><br/></div></div></div></div><div id="35804432" class="c"><input type="checkbox" id="c-35804432" checked=""/><div class="controls bullet"><span class="by">LightMachine</span><span>|</span><a href="#35807220">prev</a><span>|</span><a href="#35803927">next</a><span>|</span><label class="collapse" for="c-35804432">[-]</label><label class="expand" for="c-35804432">[1 more]</label></div><br/><div class="children"><div class="content">Any idea how much it cost to train it and how it was trained?</div><br/></div></div><div id="35803927" class="c"><input type="checkbox" id="c-35803927" checked=""/><div class="controls bullet"><span class="by">circuit10</span><span>|</span><a href="#35804432">prev</a><span>|</span><a href="#35804164">next</a><span>|</span><label class="collapse" for="c-35803927">[-]</label><label class="expand" for="c-35803927">[2 more]</label></div><br/><div class="children"><div class="content">This probably makes a self-hosted and&#x2F;or local Copilot a lot more feasible</div><br/><div id="35804224" class="c"><input type="checkbox" id="c-35804224" checked=""/><div class="controls bullet"><span class="by">FanaHOVA</span><span>|</span><a href="#35803927">parent</a><span>|</span><a href="#35804164">next</a><span>|</span><label class="collapse" for="c-35804224">[-]</label><label class="expand" for="c-35804224">[1 more]</label></div><br/><div class="children"><div class="content">Yes, something like FauxPilot[0] should be able to use it instead of CodeGen<p>[0] <a href="https:&#x2F;&#x2F;github.com&#x2F;fauxpilot&#x2F;fauxpilot">https:&#x2F;&#x2F;github.com&#x2F;fauxpilot&#x2F;fauxpilot</a></div><br/></div></div></div></div><div id="35804164" class="c"><input type="checkbox" id="c-35804164" checked=""/><div class="controls bullet"><span class="by">protonbob</span><span>|</span><a href="#35803927">prev</a><span>|</span><a href="#35806963">next</a><span>|</span><label class="collapse" for="c-35804164">[-]</label><label class="expand" for="c-35804164">[1 more]</label></div><br/><div class="children"><div class="content">Darn it doesn&#x27;t look like it has c sharp.</div><br/></div></div><div id="35806963" class="c"><input type="checkbox" id="c-35806963" checked=""/><div class="controls bullet"><span class="by">user3939382</span><span>|</span><a href="#35804164">prev</a><span>|</span><a href="#35803837">next</a><span>|</span><label class="collapse" for="c-35806963">[-]</label><label class="expand" for="c-35806963">[1 more]</label></div><br/><div class="children"><div class="content">Unfortunately I&#x27;m someone who sometimes can&#x27;t separate the art from the artist. Replit is the company where the founder sent these nasty pompous threats to their ex-employee for their innocent side project and then tried to double talk his way out of it with a bs non-apology when it got exposed in public. I won&#x27;t support Replit or anything they make.</div><br/></div></div><div id="35803837" class="c"><input type="checkbox" id="c-35803837" checked=""/><div class="controls bullet"><span class="by">fswd</span><span>|</span><a href="#35806963">prev</a><span>|</span><a href="#35807911">next</a><span>|</span><label class="collapse" for="c-35803837">[-]</label><label class="expand" for="c-35803837">[9 more]</label></div><br/><div class="children"><div class="content">I can barely keep up with this stuff, but quick question.  Is there a way to simply change the URL setting of copilot to point to this model?  Obviously it needs an endpoint, I could hack something up, but asking if somebody has already done this? Would be nice to cancel my copilot.</div><br/><div id="35804117" class="c"><input type="checkbox" id="c-35804117" checked=""/><div class="controls bullet"><span class="by">execveat</span><span>|</span><a href="#35803837">parent</a><span>|</span><a href="#35803984">next</a><span>|</span><label class="collapse" for="c-35804117">[-]</label><label class="expand" for="c-35804117">[5 more]</label></div><br/><div class="children"><div class="content">It&#x27;s nowhere close to Codex&#x2F;Copilot. Try the demo: <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;replit&#x2F;replit-code-v1-3b-demo" rel="nofollow">https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;replit&#x2F;replit-code-v1-3b-demo</a></div><br/><div id="35805445" class="c"><input type="checkbox" id="c-35805445" checked=""/><div class="controls bullet"><span class="by">tarruda</span><span>|</span><a href="#35803837">root</a><span>|</span><a href="#35804117">parent</a><span>|</span><a href="#35803984">next</a><span>|</span><label class="collapse" for="c-35805445">[-]</label><label class="expand" for="c-35805445">[4 more]</label></div><br/><div class="children"><div class="content">So they are lying on this tweet? <a href="https:&#x2F;&#x2F;twitter.com&#x2F;Replit&#x2F;status&#x2F;1651344186715803648" rel="nofollow">https:&#x2F;&#x2F;twitter.com&#x2F;Replit&#x2F;status&#x2F;1651344186715803648</a></div><br/><div id="35811448" class="c"><input type="checkbox" id="c-35811448" checked=""/><div class="controls bullet"><span class="by">sanxiyn</span><span>|</span><a href="#35803837">root</a><span>|</span><a href="#35805445">parent</a><span>|</span><a href="#35805549">next</a><span>|</span><label class="collapse" for="c-35811448">[-]</label><label class="expand" for="c-35811448">[1 more]</label></div><br/><div class="children"><div class="content">They are probably not lying, but good performance on benchmarks does not imply good performance on your use cases.</div><br/></div></div><div id="35805549" class="c"><input type="checkbox" id="c-35805549" checked=""/><div class="controls bullet"><span class="by">naillo</span><span>|</span><a href="#35803837">root</a><span>|</span><a href="#35805445">parent</a><span>|</span><a href="#35811448">prev</a><span>|</span><a href="#35803984">next</a><span>|</span><label class="collapse" for="c-35805549">[-]</label><label class="expand" for="c-35805549">[2 more]</label></div><br/><div class="children"><div class="content">Yep</div><br/></div></div></div></div></div></div><div id="35803984" class="c"><input type="checkbox" id="c-35803984" checked=""/><div class="controls bullet"><span class="by">circuit10</span><span>|</span><a href="#35803837">parent</a><span>|</span><a href="#35804117">prev</a><span>|</span><a href="#35803949">next</a><span>|</span><label class="collapse" for="c-35803984">[-]</label><label class="expand" for="c-35803984">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s <a href="https:&#x2F;&#x2F;github.com&#x2F;fauxpilot&#x2F;fauxpilot">https:&#x2F;&#x2F;github.com&#x2F;fauxpilot&#x2F;fauxpilot</a> but it doesn&#x27;t use this model</div><br/></div></div><div id="35803949" class="c"><input type="checkbox" id="c-35803949" checked=""/><div class="controls bullet"><span class="by">jacobrussell</span><span>|</span><a href="#35803837">parent</a><span>|</span><a href="#35803984">prev</a><span>|</span><a href="#35807911">next</a><span>|</span><label class="collapse" for="c-35803949">[-]</label><label class="expand" for="c-35803949">[2 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think it&#x27;s possible to point Copilot to other models. I don&#x27;t think Microsoft would benefit much from that feature. You could use existing tools [0] to host your own model which in theory could be used by an extension your IDE uses. But I&#x27;m not sure if an extension like that exists.<p>[0] <a href="https:&#x2F;&#x2F;github.com&#x2F;oobabooga&#x2F;text-generation-webui">https:&#x2F;&#x2F;github.com&#x2F;oobabooga&#x2F;text-generation-webui</a></div><br/><div id="35803991" class="c"><input type="checkbox" id="c-35803991" checked=""/><div class="controls bullet"><span class="by">circuit10</span><span>|</span><a href="#35803837">root</a><span>|</span><a href="#35803949">parent</a><span>|</span><a href="#35807911">next</a><span>|</span><label class="collapse" for="c-35803991">[-]</label><label class="expand" for="c-35803991">[1 more]</label></div><br/><div class="children"><div class="content">Of course it&#x27;s possible, just not officially<p>See <a href="https:&#x2F;&#x2F;github.com&#x2F;fauxpilot&#x2F;fauxpilot&#x2F;blob&#x2F;main&#x2F;documentation&#x2F;client.md#copilot-plugin">https:&#x2F;&#x2F;github.com&#x2F;fauxpilot&#x2F;fauxpilot&#x2F;blob&#x2F;main&#x2F;documentati...</a></div><br/></div></div></div></div></div></div><div id="35807911" class="c"><input type="checkbox" id="c-35807911" checked=""/><div class="controls bullet"><span class="by">hinkley</span><span>|</span><a href="#35803837">prev</a><span>|</span><a href="#35805194">next</a><span>|</span><label class="collapse" for="c-35807911">[-]</label><label class="expand" for="c-35807911">[9 more]</label></div><br/><div class="children"><div class="content">I think that 20 years from now, we&#x27;ll all be sitting around wondering 1) where the fuck are my flying cars, and 2) what were they thinking using computers to write code?<p>And the reason I say this is because these tools are answering a question that we haven&#x27;t asked yet: what common problems need to be solved in this programming language, and where do I get code to solve that problem?<p>These LLM modules are basically telling us how to duplicate code, and what we need is the opposite: how to stop reinventing the wheel for the 100th time.<p>Instead of writing code for me, tell me if I already have it. If I&#x27;m writing it, tell me there&#x27;s a library for that. If I&#x27;m a library writer, give me suggestions for what libraries are missing from the toolkit.<p>All we&#x27;ve done so far is begun the process of automating the production of duplicate code. With absolutely no way to go back in time and correct bugs introduced in earlier iterations. We are likely, for instance, to see 0 day attacks that affect hundreds of applications, but with no simple way to describe which applications are affected. That&#x27;s going to be a first rate trainwreck.</div><br/><div id="35808276" class="c"><input type="checkbox" id="c-35808276" checked=""/><div class="controls bullet"><span class="by">moffkalast</span><span>|</span><a href="#35807911">parent</a><span>|</span><a href="#35808252">next</a><span>|</span><label class="collapse" for="c-35808276">[-]</label><label class="expand" for="c-35808276">[1 more]</label></div><br/><div class="children"><div class="content">Well fwiw, working with GPT 4 it often suggests which libraries to use assuming the question allows for it, so it&#x27;s not like everyone&#x27;s writing everything from scratch.<p>But libraries and especially frameworks as they are these days are also a giant liability more often than not. APIs change for no reason, they can be removed from the package manager at any moment without warning, people may slip malicious code into them past LGTM reviews, have recursive dependencies upon dependencies that bloat and slow down your build process, etc.<p>Sometimes you don&#x27;t need the to install the entire damn car manufacturing plant and dealership it comes with just to get that one wheel you needed. And an LLM can just write you the code for a very nicely customized wheel in a few seconds anyway.</div><br/></div></div><div id="35808252" class="c"><input type="checkbox" id="c-35808252" checked=""/><div class="controls bullet"><span class="by">seydor</span><span>|</span><a href="#35807911">parent</a><span>|</span><a href="#35808276">prev</a><span>|</span><a href="#35808797">next</a><span>|</span><label class="collapse" for="c-35808252">[-]</label><label class="expand" for="c-35808252">[6 more]</label></div><br/><div class="children"><div class="content">&gt; how to stop reinventing the wheel for the 100th time.<p>The idea of libraries may not have been a good one. It saved human time but no library is perfect because no abstraction is perfect and this causes unnecessary bloat. It seems tha Nature does not use libraries, it uses replication instead, and we can now have that too.</div><br/><div id="35808659" class="c"><input type="checkbox" id="c-35808659" checked=""/><div class="controls bullet"><span class="by">hinkley</span><span>|</span><a href="#35807911">root</a><span>|</span><a href="#35808252">parent</a><span>|</span><a href="#35808907">next</a><span>|</span><label class="collapse" for="c-35808659">[-]</label><label class="expand" for="c-35808659">[1 more]</label></div><br/><div class="children"><div class="content">So instead everyone who has to solve a problem has to be an expert on that problem, rather than just an informed consumer.</div><br/></div></div><div id="35808907" class="c"><input type="checkbox" id="c-35808907" checked=""/><div class="controls bullet"><span class="by">webnrrd2k</span><span>|</span><a href="#35807911">root</a><span>|</span><a href="#35808252">parent</a><span>|</span><a href="#35808659">prev</a><span>|</span><a href="#35808457">next</a><span>|</span><label class="collapse" for="c-35808907">[-]</label><label class="expand" for="c-35808907">[2 more]</label></div><br/><div class="children"><div class="content">You have a point, but I think there are some big trade-offs...<p>Nature uses replication, but it&#x27;s also horrifically complex and we have no real idea about the specifics of how it all works, or what to do when many, many things go wrong.<p>Also, I think nature uses cloning, which I kind of think would be called a &#x27;library&#x27; in this case, for single-celled organisms (archaea and bacteria). In addition many eukaryotic organisms can reproduce via cloning under special situations.<p>I don&#x27;t know, I&#x27;m not really trying to argue one way or the other. I&#x27;m kinda&#x27; thinking out loud here... but I&#x27;d like to see LLMs used to create really great libraries, or some other abstractions, that are easy to use and also understandable. It might not happen soon, but I think that there is a lot of value in moving things that way.</div><br/><div id="35809039" class="c"><input type="checkbox" id="c-35809039" checked=""/><div class="controls bullet"><span class="by">seydor</span><span>|</span><a href="#35807911">root</a><span>|</span><a href="#35808907">parent</a><span>|</span><a href="#35808457">next</a><span>|</span><label class="collapse" for="c-35809039">[-]</label><label class="expand" for="c-35809039">[1 more]</label></div><br/><div class="children"><div class="content">&gt; but it&#x27;s also horrifically complex and we have no real idea about the specifics of how it all works, or what to do when many, many things go wrong.<p>Sounds a lot like neural networks.<p>I think libraries are a result of the human brain&#x27;s limited working memory capacity , while organisms or neural networks aren&#x27;t so limited in what they can focus on. Perhaps the transformer became successful in syntactic abstraction because it <i>is</i> limited on how many things it can focus on.<p>Computer libraries are equally a result of limited memory and disk. Javascript is a counterexample of what happens when computing is free (because it runs on someone else&#x27;s computer)</div><br/></div></div></div></div><div id="35808457" class="c"><input type="checkbox" id="c-35808457" checked=""/><div class="controls bullet"><span class="by">sicariusnoctis</span><span>|</span><a href="#35807911">root</a><span>|</span><a href="#35808252">parent</a><span>|</span><a href="#35808907">prev</a><span>|</span><a href="#35808623">next</a><span>|</span><label class="collapse" for="c-35808457">[-]</label><label class="expand" for="c-35808457">[1 more]</label></div><br/><div class="children"><div class="content">Replication does not help in managing completely. That&#x27;s why we use abstractions, even with the problems they have.</div><br/></div></div><div id="35808623" class="c"><input type="checkbox" id="c-35808623" checked=""/><div class="controls bullet"><span class="by">x-shadowban</span><span>|</span><a href="#35807911">root</a><span>|</span><a href="#35808252">parent</a><span>|</span><a href="#35808457">prev</a><span>|</span><a href="#35808797">next</a><span>|</span><label class="collapse" for="c-35808623">[-]</label><label class="expand" for="c-35808623">[1 more]</label></div><br/><div class="children"><div class="content">Ha I never wondered what the physical&#x2F;life version of a shared library is until I read your post so thanks for that.</div><br/></div></div></div></div><div id="35808797" class="c"><input type="checkbox" id="c-35808797" checked=""/><div class="controls bullet"><span class="by">webnrrd2k</span><span>|</span><a href="#35807911">parent</a><span>|</span><a href="#35808252">prev</a><span>|</span><a href="#35805194">next</a><span>|</span><label class="collapse" for="c-35808797">[-]</label><label class="expand" for="c-35808797">[1 more]</label></div><br/><div class="children"><div class="content">I agree -- maybe someday LLMs will give me a the code for a set of simple abstractions that are well-matched for the problems I currently face. Something like a Pattern Language that was all the rage, but, um, better? More objective and pragmatically useful. Not galaxy-brain theory.<p>That&#x27;s what I really want. But that would also put me out of a job.</div><br/></div></div></div></div><div id="35805194" class="c"><input type="checkbox" id="c-35805194" checked=""/><div class="controls bullet"><span class="by">m3kw9</span><span>|</span><a href="#35807911">prev</a><span>|</span><a href="#35805717">next</a><span>|</span><label class="collapse" for="c-35805194">[-]</label><label class="expand" for="c-35805194">[3 more]</label></div><br/><div class="children"><div class="content">It just gave me prototypes lol<p>def sieve_eratosthenes(n):<p>##a function to sort 10 numbers<p><pre><code>    def bubble_sort(a):
</code></pre>
##a function to sort 10 numbers<p><pre><code>    def insertion_sort(a):
</code></pre>
##a function to sort 10 numbers<p><pre><code>    def quick_sort(a):</code></pre></div><br/><div id="35805670" class="c"><input type="checkbox" id="c-35805670" checked=""/><div class="controls bullet"><span class="by">ImprobableTruth</span><span>|</span><a href="#35805194">parent</a><span>|</span><a href="#35805992">next</a><span>|</span><label class="collapse" for="c-35805670">[-]</label><label class="expand" for="c-35805670">[1 more]</label></div><br/><div class="children"><div class="content">Did you mess around with the settings? I&#x27;m getting a correct implementation and since it&#x27;s deterministic (with default settings) it should be the same for you.</div><br/></div></div><div id="35805992" class="c"><input type="checkbox" id="c-35805992" checked=""/><div class="controls bullet"><span class="by">m3kw9</span><span>|</span><a href="#35805194">parent</a><span>|</span><a href="#35805670">prev</a><span>|</span><a href="#35805717">next</a><span>|</span><label class="collapse" for="c-35805992">[-]</label><label class="expand" for="c-35805992">[1 more]</label></div><br/><div class="children"><div class="content">I left the settings. All I added was ##a function to sort 10 numbers.  Assuming it would complete it like copilot</div><br/></div></div></div></div><div id="35805717" class="c"><input type="checkbox" id="c-35805717" checked=""/><div class="controls bullet"><span class="by">eikenberry</span><span>|</span><a href="#35805194">prev</a><span>|</span><a href="#35804824">next</a><span>|</span><label class="collapse" for="c-35805717">[-]</label><label class="expand" for="c-35805717">[2 more]</label></div><br/><div class="children"><div class="content">Is this a Co-pilot like assistant or something more? Co-pilot is neat but is basically not much more than an automated snippet system. The actual writing of the code is not the part that I want help with, I want an AI system that helps me design better software systems. Something more akin to program mind mapping than some fancy auto-completion system.</div><br/><div id="35807903" class="c"><input type="checkbox" id="c-35807903" checked=""/><div class="controls bullet"><span class="by">qrio2</span><span>|</span><a href="#35805717">parent</a><span>|</span><a href="#35804824">next</a><span>|</span><label class="collapse" for="c-35807903">[-]</label><label class="expand" for="c-35807903">[1 more]</label></div><br/><div class="children"><div class="content">I wonder if LLM with something like plantUML would generate anything useful</div><br/></div></div></div></div><div id="35804824" class="c"><input type="checkbox" id="c-35804824" checked=""/><div class="controls bullet"><span class="by">robertlucas</span><span>|</span><a href="#35805717">prev</a><span>|</span><a href="#35805938">next</a><span>|</span><label class="collapse" for="c-35804824">[-]</label><label class="expand" for="c-35804824">[1 more]</label></div><br/><div class="children"><div class="content">Is there any way to connect these new code focused LLMs into VS Code in order to replace Github Copilot?</div><br/></div></div><div id="35805938" class="c"><input type="checkbox" id="c-35805938" checked=""/><div class="controls bullet"><span class="by">SXX</span><span>|</span><a href="#35804824">prev</a><span>|</span><a href="#35803851">next</a><span>|</span><label class="collapse" for="c-35805938">[-]</label><label class="expand" for="c-35805938">[1 more]</label></div><br/><div class="children"><div class="content">Weak spot which I guess similar to other LLMs. If you mention recursion somewhere in comments model sometimes start to recursively generate the same lines over and over again.</div><br/></div></div><div id="35803851" class="c"><input type="checkbox" id="c-35803851" checked=""/><div class="controls bullet"><span class="by">tarruda</span><span>|</span><a href="#35805938">prev</a><span>|</span><a href="#35804770">next</a><span>|</span><label class="collapse" for="c-35803851">[-]</label><label class="expand" for="c-35803851">[11 more]</label></div><br/><div class="children"><div class="content">3 billion parameters. Does that mean I will be able to run on a 8gb consumer GPU?</div><br/><div id="35804940" class="c"><input type="checkbox" id="c-35804940" checked=""/><div class="controls bullet"><span class="by">dontwearitout</span><span>|</span><a href="#35803851">parent</a><span>|</span><a href="#35803915">next</a><span>|</span><label class="collapse" for="c-35804940">[-]</label><label class="expand" for="c-35804940">[1 more]</label></div><br/><div class="children"><div class="content">Probably not out of the box but if some of the local deep learning wizards get a quantized version working well and optimize it a bit, definitely.</div><br/></div></div><div id="35803915" class="c"><input type="checkbox" id="c-35803915" checked=""/><div class="controls bullet"><span class="by">generalizations</span><span>|</span><a href="#35803851">parent</a><span>|</span><a href="#35804940">prev</a><span>|</span><a href="#35803920">next</a><span>|</span><label class="collapse" for="c-35803915">[-]</label><label class="expand" for="c-35803915">[2 more]</label></div><br/><div class="children"><div class="content">Means that once it&#x27;s incorporated into llama.cpp, you can run it on your laptop.</div><br/><div id="35803982" class="c"><input type="checkbox" id="c-35803982" checked=""/><div class="controls bullet"><span class="by">amasad</span><span>|</span><a href="#35803851">root</a><span>|</span><a href="#35803915">parent</a><span>|</span><a href="#35803920">next</a><span>|</span><label class="collapse" for="c-35803982">[-]</label><label class="expand" for="c-35803982">[1 more]</label></div><br/><div class="children"><div class="content">Hopefully on phones too</div><br/></div></div></div></div><div id="35803920" class="c"><input type="checkbox" id="c-35803920" checked=""/><div class="controls bullet"><span class="by">RHab</span><span>|</span><a href="#35803851">parent</a><span>|</span><a href="#35803915">prev</a><span>|</span><a href="#35803926">next</a><span>|</span><label class="collapse" for="c-35803920">[-]</label><label class="expand" for="c-35803920">[3 more]</label></div><br/><div class="children"><div class="content">No, I could only get 2.7B to run on 8GB VRam unfortunatly.</div><br/><div id="35803976" class="c"><input type="checkbox" id="c-35803976" checked=""/><div class="controls bullet"><span class="by">amasad</span><span>|</span><a href="#35803851">root</a><span>|</span><a href="#35803920">parent</a><span>|</span><a href="#35803926">next</a><span>|</span><label class="collapse" for="c-35803976">[-]</label><label class="expand" for="c-35803976">[2 more]</label></div><br/><div class="children"><div class="content">it is 2.7B</div><br/><div id="35804781" class="c"><input type="checkbox" id="c-35804781" checked=""/><div class="controls bullet"><span class="by">tarruda</span><span>|</span><a href="#35803851">root</a><span>|</span><a href="#35803976">parent</a><span>|</span><a href="#35803926">next</a><span>|</span><label class="collapse" for="c-35804781">[-]</label><label class="expand" for="c-35804781">[1 more]</label></div><br/><div class="children"><div class="content">Loading seems to have worked on my laptop&#x27;s RTX 3070, `nvidia-smi` shows `5188MiB &#x2F;  8192MiB` in memory usage.</div><br/></div></div></div></div></div></div><div id="35803926" class="c"><input type="checkbox" id="c-35803926" checked=""/><div class="controls bullet"><span class="by">pera</span><span>|</span><a href="#35803851">parent</a><span>|</span><a href="#35803920">prev</a><span>|</span><a href="#35804770">next</a><span>|</span><label class="collapse" for="c-35803926">[-]</label><label class="expand" for="c-35803926">[4 more]</label></div><br/><div class="children"><div class="content">their pytorch_model.bin is 10.4GB</div><br/><div id="35804772" class="c"><input type="checkbox" id="c-35804772" checked=""/><div class="controls bullet"><span class="by">tarruda</span><span>|</span><a href="#35803851">root</a><span>|</span><a href="#35803926">parent</a><span>|</span><a href="#35804770">next</a><span>|</span><label class="collapse" for="c-35804772">[-]</label><label class="expand" for="c-35804772">[3 more]</label></div><br/><div class="children"><div class="content">I just loaded this on my laptop&#x27;s RTX 3070 GPU by following the instructions here: <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;replit&#x2F;replit-code-v1-3b" rel="nofollow">https:&#x2F;&#x2F;huggingface.co&#x2F;replit&#x2F;replit-code-v1-3b</a><p>I don&#x27;t know how I can test the model, but it seem loading worked. When I run `nvidia-smi` on another terminal, I see `5188MiB &#x2F;  8192MiB` in the memory-usage column.</div><br/><div id="35805137" class="c"><input type="checkbox" id="c-35805137" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#35803851">root</a><span>|</span><a href="#35804772">parent</a><span>|</span><a href="#35804770">next</a><span>|</span><label class="collapse" for="c-35805137">[-]</label><label class="expand" for="c-35805137">[2 more]</label></div><br/><div class="children"><div class="content">you can load it but you cant run inference? whats the issue?</div><br/><div id="35805357" class="c"><input type="checkbox" id="c-35805357" checked=""/><div class="controls bullet"><span class="by">tarruda</span><span>|</span><a href="#35803851">root</a><span>|</span><a href="#35805137">parent</a><span>|</span><a href="#35804770">next</a><span>|</span><label class="collapse" for="c-35805357">[-]</label><label class="expand" for="c-35805357">[1 more]</label></div><br/><div class="children"><div class="content">No issue, I&#x27;m simply unfamiliar with python machine learning APIs.<p>I managed to run inference locally by installing the requirements and running app.py from the demo: <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;replit&#x2F;replit-code-v1-3b-demo&#x2F;tree&#x2F;main" rel="nofollow">https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;replit&#x2F;replit-code-v1-3b-demo&#x2F;...</a><p>It is very fast on my RTX 3070, VRAM usage goes to ~= 6.3GB during inference.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="35804770" class="c"><input type="checkbox" id="c-35804770" checked=""/><div class="controls bullet"><span class="by">jeremypress</span><span>|</span><a href="#35803851">prev</a><span>|</span><a href="#35804136">next</a><span>|</span><label class="collapse" for="c-35804770">[-]</label><label class="expand" for="c-35804770">[2 more]</label></div><br/><div class="children"><div class="content">Interesting how this guy has a finance background but knows how to code, especially for emerging technologies like LLMs</div><br/><div id="35806348" class="c"><input type="checkbox" id="c-35806348" checked=""/><div class="controls bullet"><span class="by">ipsum2</span><span>|</span><a href="#35804770">parent</a><span>|</span><a href="#35804136">next</a><span>|</span><label class="collapse" for="c-35806348">[-]</label><label class="expand" for="c-35806348">[1 more]</label></div><br/><div class="children"><div class="content">Didn&#x27;t MosaicML do the training for them?</div><br/></div></div></div></div><div id="35804136" class="c"><input type="checkbox" id="c-35804136" checked=""/><div class="controls bullet"><span class="by">love2read</span><span>|</span><a href="#35804770">prev</a><span>|</span><a href="#35805299">next</a><span>|</span><label class="collapse" for="c-35804136">[-]</label><label class="expand" for="c-35804136">[1 more]</label></div><br/><div class="children"><div class="content">Can this be used with the copilot plugins for every ide?</div><br/></div></div><div id="35805299" class="c"><input type="checkbox" id="c-35805299" checked=""/><div class="controls bullet"><span class="by">youssefabdelm</span><span>|</span><a href="#35804136">prev</a><span>|</span><a href="#35805733">next</a><span>|</span><label class="collapse" for="c-35805299">[-]</label><label class="expand" for="c-35805299">[3 more]</label></div><br/><div class="children"><div class="content">title is missing: &quot;trained in 1 week, and like most open source LLMs so far... it sucks compared to the closed source alternatives&quot;<p>Great effort of course bla bla bla...<p>Open source really needs some benchmarking, and up their game quality-wise.<p>And yes I know they&#x27;re expensive as shit to train... let&#x27;s not keep wasting our money and actually work together, pool our resources, to make a GOOD model.<p>But oh no, everyone wants to put their stamp on it. &quot;Replit did this! Look at us!&quot;</div><br/><div id="35806435" class="c"><input type="checkbox" id="c-35806435" checked=""/><div class="controls bullet"><span class="by">ImprobableTruth</span><span>|</span><a href="#35805299">parent</a><span>|</span><a href="#35805733">next</a><span>|</span><label class="collapse" for="c-35806435">[-]</label><label class="expand" for="c-35806435">[2 more]</label></div><br/><div class="children"><div class="content">This is easy to say, but I think the issue is that getting an LLM right isn&#x27;t easy, so it&#x27;s not clear who should steward such a project. Something like BLOOM shows that even if you have the necessary compute, you can still get a model that isn&#x27;t good.<p>I think it will take some time for it to be clear who is a leader in training open source models (maybe it will be the red pajama folks?) and I think they&#x27;ll get more support after that.</div><br/><div id="35808340" class="c"><input type="checkbox" id="c-35808340" checked=""/><div class="controls bullet"><span class="by">youssefabdelm</span><span>|</span><a href="#35805299">root</a><span>|</span><a href="#35806435">parent</a><span>|</span><a href="#35805733">next</a><span>|</span><label class="collapse" for="c-35808340">[-]</label><label class="expand" for="c-35808340">[1 more]</label></div><br/><div class="children"><div class="content">Fair point</div><br/></div></div></div></div></div></div><div id="35805733" class="c"><input type="checkbox" id="c-35805733" checked=""/><div class="controls bullet"><span class="by">gowld</span><span>|</span><a href="#35805299">prev</a><span>|</span><a href="#35811422">next</a><span>|</span><label class="collapse" for="c-35805733">[-]</label><label class="expand" for="c-35805733">[4 more]</label></div><br/><div class="children"><div class="content">Can I use repl.it with an external Code LLM, with or without paying repl.it for Ghostwriter ?</div><br/><div id="35805960" class="c"><input type="checkbox" id="c-35805960" checked=""/><div class="controls bullet"><span class="by">amasad</span><span>|</span><a href="#35805733">parent</a><span>|</span><a href="#35811422">next</a><span>|</span><label class="collapse" for="c-35805960">[-]</label><label class="expand" for="c-35805960">[3 more]</label></div><br/><div class="children"><div class="content">Yes we have a robust extension system and some are already building alternatives.</div><br/><div id="35806538" class="c"><input type="checkbox" id="c-35806538" checked=""/><div class="controls bullet"><span class="by">varunkmohan</span><span>|</span><a href="#35805733">root</a><span>|</span><a href="#35805960">parent</a><span>|</span><a href="#35811422">next</a><span>|</span><label class="collapse" for="c-35806538">[-]</label><label class="expand" for="c-35806538">[2 more]</label></div><br/><div class="children"><div class="content">Hi from the Codeium team. It&#x27;s awesome to hear you are allowing other code LLMs to be used on the Replit platform (we&#x27;re big fans)! We&#x27;d love to enable our free chrome extension on Replit.</div><br/><div id="35807506" class="c"><input type="checkbox" id="c-35807506" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#35805733">root</a><span>|</span><a href="#35806538">parent</a><span>|</span><a href="#35811422">next</a><span>|</span><label class="collapse" for="c-35807506">[-]</label><label class="expand" for="c-35807506">[1 more]</label></div><br/><div class="children"><div class="content">would love to be able to compare codeium vs ghostwriter inside replit! (or toggle between them based on known strengths or preferences, perhaps by project or by filetype)</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></body></html>