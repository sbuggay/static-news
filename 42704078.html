<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1736931675383" as="style"/><link rel="stylesheet" href="styles.css?v=1736931675383"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://p.migdal.pl/blog/2025/01/dont-use-cosine-similarity/">Don&#x27;t use cosine similarity carelessly</a> <span class="domain">(<a href="https://p.migdal.pl">p.migdal.pl</a>)</span></div><div class="subtext"><span>stared</span> | <span>45 comments</span></div><br/><div><div id="42708269" class="c"><input type="checkbox" id="c-42708269" checked=""/><div class="controls bullet"><span class="by">bambax</span><span>|</span><a href="#42705300">next</a><span>|</span><label class="collapse" for="c-42708269">[-]</label><label class="expand" for="c-42708269">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>In the US, word2vec might tell you espresso and cappuccino are practically identical. It is not a claim you would make in Italy.</i><p>True, and quite funny. This is an excellent, well-written and very informative article, but this part is wrongly worded:<p>&gt; <i>Let&#x27;s have a task that looks simple, a simple quest from our everyday life: &quot;What did I do with my keys?&quot; [and compare it to other notes using cosine similarity]: &quot;Where did I put my wallet&quot; [=&gt; 0.6], &quot;I left them in my pocket&quot; [=&gt; 0.5]</i><p>&gt; <i>The best approach is to directly use LLM query to compare two entries, [along the lines of]: &quot;Is {sentence_a} similar to {sentence_b}?&quot;</i><p>(bits in brackets paraphrased for quoting convenience)<p>This will result in the same, or &quot;worse&quot; result, as any LLM will respond that &quot;Where did I put my wallet&quot; is very similar to &quot;What did I do with my keys?&quot;, while &quot;I left them in my pocket&quot; is completely dissimilar.<p>I&#x27;m actually not sure what the author was trying to get at here? You could ask an LLM &#x27;is that sentence a plausible answer to the question&#x27; and then it would work; but if you ask for pure &#x27;likeness&#x27;, it seems that in many cases, LLMs&#x27; responses will be close to cosine similarity.</div><br/></div></div><div id="42705300" class="c"><input type="checkbox" id="c-42705300" checked=""/><div class="controls bullet"><span class="by">pamelafox</span><span>|</span><a href="#42708269">prev</a><span>|</span><a href="#42706617">next</a><span>|</span><label class="collapse" for="c-42705300">[-]</label><label class="expand" for="c-42705300">[11 more]</label></div><br/><div class="children"><div class="content">If you&#x27;re using cosine similarity when retrieving for a RAG application, a good approach is to then use a &quot;semantic re-ranker&quot; or &quot;L2 re-ranking model&quot; to re-rank the results to better match the user query.<p>There&#x27;s an example in the pgvector-python that uses a cross-encoder model for re-ranking: <a href="https:&#x2F;&#x2F;github.com&#x2F;pgvector&#x2F;pgvector-python&#x2F;blob&#x2F;master&#x2F;examples&#x2F;hybrid_search&#x2F;cross_encoder.py#L57">https:&#x2F;&#x2F;github.com&#x2F;pgvector&#x2F;pgvector-python&#x2F;blob&#x2F;master&#x2F;exam...</a><p>You can even use a language model for re-ranking, though it may not be as good as a model trained specifically for re-ranking purposes.<p>In our Azure RAG approaches, we use the AI Search semantic ranker, which uses the same model that Bing uses for re-ranking search results.</div><br/><div id="42705326" class="c"><input type="checkbox" id="c-42705326" checked=""/><div class="controls bullet"><span class="by">pamelafox</span><span>|</span><a href="#42705300">parent</a><span>|</span><a href="#42708643">next</a><span>|</span><label class="collapse" for="c-42705326">[-]</label><label class="expand" for="c-42705326">[8 more]</label></div><br/><div class="children"><div class="content">Another tip: do NOT store vector embeddings of nothingness, mostly whitespace, a solid image, etc. We&#x27;ve had a few situations with RAG data stores which accidentally ingested mostly-empty content (either text or image), and those dang vectors matched EVERYTHING. WAs I like to think of it, there&#x27;s a bit of nothing in everything.. so make sure that if you are storing a vector embedding, there is some amount of signal in that embedding.</div><br/><div id="42705772" class="c"><input type="checkbox" id="c-42705772" checked=""/><div class="controls bullet"><span class="by">variaga</span><span>|</span><a href="#42705300">root</a><span>|</span><a href="#42705326">parent</a><span>|</span><a href="#42708406">next</a><span>|</span><label class="collapse" for="c-42705772">[-]</label><label class="expand" for="c-42705772">[1 more]</label></div><br/><div class="children"><div class="content">Interesting. A project I worked on (audio recognition for a voice-command system) we ended up going the other way and explicitly adding an encoding of &quot;nothingness&quot; (actually 2, one for &quot;silence&quot; and another for &quot;white noise&quot;) and special casing them (&quot;if either &#x27;silence&#x27; or &#x27;noise&#x27; is in the top 3 matches, ignore the input entirely&quot;).<p>This was to avoid the problem where, when we only had vectors for &quot;valid&quot; sounds and there was an input that didn&#x27;t match anything in the training set (a foreign language, garbage truck backing up, a dog barking, ...) the model would still return <i>some</i> word as the closest match (there&#x27;s always <i>a</i> vector that has the highest similarity) and frequently do so with high confidence i.e. even though the actual input didn&#x27;t actually match anything in the training set, it would be &quot;enough&quot; more like one known vector than any of the others that it would pass most threshold tests, leading to a lot of false positives.</div><br/></div></div><div id="42708406" class="c"><input type="checkbox" id="c-42708406" checked=""/><div class="controls bullet"><span class="by">jhy</span><span>|</span><a href="#42705300">root</a><span>|</span><a href="#42705326">parent</a><span>|</span><a href="#42705772">prev</a><span>|</span><a href="#42705499">next</a><span>|</span><label class="collapse" for="c-42708406">[-]</label><label class="expand" for="c-42708406">[1 more]</label></div><br/><div class="children"><div class="content">We used to have this problem in AWS Rekognition; a poorly detected face -- e.g. a blurry face in the background -- would hit with high confidence with every other blurry face. We fixed that largely by adding specific tests against this [effectively] null vector. The same will work for text or other image vectors.</div><br/></div></div><div id="42705499" class="c"><input type="checkbox" id="c-42705499" checked=""/><div class="controls bullet"><span class="by">pbhjpbhj</span><span>|</span><a href="#42705300">root</a><span>|</span><a href="#42705326">parent</a><span>|</span><a href="#42708406">prev</a><span>|</span><a href="#42706529">next</a><span>|</span><label class="collapse" for="c-42705499">[-]</label><label class="expand" for="c-42705499">[4 more]</label></div><br/><div class="children"><div class="content">That sounds like a problem for the embedding, would you need to renormalise so that low signal inputs could be well represented. A white square and a red square shouldn&#x27;t be different levels of details. Depending on the purpose of the vector embedding, there should be a difference between images of mostly white pixels and partial images.<p>Disclaimer, I don&#x27;t know shit.</div><br/><div id="42705514" class="c"><input type="checkbox" id="c-42705514" checked=""/><div class="controls bullet"><span class="by">pamelafox</span><span>|</span><a href="#42705300">root</a><span>|</span><a href="#42705499">parent</a><span>|</span><a href="#42706529">next</a><span>|</span><label class="collapse" for="c-42705514">[-]</label><label class="expand" for="c-42705514">[3 more]</label></div><br/><div class="children"><div class="content">I should clarify that I experienced these issues with text-embedding-ada-002 and the Azure AI vision model (based on Florence). I have not tested many other embedding models to see if they&#x27;d have the same issue.</div><br/><div id="42707731" class="c"><input type="checkbox" id="c-42707731" checked=""/><div class="controls bullet"><span class="by">mattvr</span><span>|</span><a href="#42705300">root</a><span>|</span><a href="#42705514">parent</a><span>|</span><a href="#42705690">next</a><span>|</span><label class="collapse" for="c-42707731">[-]</label><label class="expand" for="c-42707731">[1 more]</label></div><br/><div class="children"><div class="content">You could also work around this by adding a scaling transformation that normalizes and centers (e.g. sklearn StandardScaler) in between the raw embeddings — based on some example data points from your data set. Might introduce some bias, but I’ve found this helpful in some cases with off the shelf embeddings.</div><br/></div></div><div id="42705690" class="c"><input type="checkbox" id="c-42705690" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#42705300">root</a><span>|</span><a href="#42705514">parent</a><span>|</span><a href="#42707731">prev</a><span>|</span><a href="#42706529">next</a><span>|</span><label class="collapse" for="c-42705690">[-]</label><label class="expand" for="c-42705690">[1 more]</label></div><br/><div class="children"><div class="content">FWIW I think you&#x27;re right, we have very different stacks, and I&#x27;ve observed the same thing, with a much clunkier description thank your elegant way of putting it.<p>I do embeddings on arbitrary websites at runtime, and had a persistent problem with the last chunk of a web page matching more things. In retrospect, its obvious that the smaller the chunk was, the more it was matching everything<p>Full details: MSMARCO MiniLM L6V3 inferenced using ONNX on iOS&#x2F;web&#x2F;android&#x2F;macos&#x2F;windows&#x2F;linux</div><br/></div></div></div></div></div></div><div id="42706529" class="c"><input type="checkbox" id="c-42706529" checked=""/><div class="controls bullet"><span class="by">jsenn</span><span>|</span><a href="#42705300">root</a><span>|</span><a href="#42705326">parent</a><span>|</span><a href="#42705499">prev</a><span>|</span><a href="#42708643">next</a><span>|</span><label class="collapse" for="c-42706529">[-]</label><label class="expand" for="c-42706529">[1 more]</label></div><br/><div class="children"><div class="content">Same experience embedding random alphanumeric strings or strings of digits with smaller embedding models—very important to filter those out.</div><br/></div></div></div></div><div id="42708643" class="c"><input type="checkbox" id="c-42708643" checked=""/><div class="controls bullet"><span class="by">antirez</span><span>|</span><a href="#42705300">parent</a><span>|</span><a href="#42705326">prev</a><span>|</span><a href="#42708296">next</a><span>|</span><label class="collapse" for="c-42708643">[-]</label><label class="expand" for="c-42708643">[1 more]</label></div><br/><div class="children"><div class="content">I propose a different technique:<p>- Use a large context LLM.<p>- Segment documents to 25% of context or alike.<p>- With RAG, retrieve fragments from all the documents, they do a first pass semantic re-ranking like this, sending to the LLM:<p>I have a set of documents I can show you to reply the user question &quot;$QUESTION&quot;. Please tell me from the title and best matching fragments what document IDs you want to see to better reply:<p>[Document ID 0]: &quot;Some title &#x2F; synopsis. From page 100 to 200&quot;<p>... best matching fragment of document 0...<p>... second best fragment ...<p>[Document ID 1]: &quot;Some title &#x2F; synopsis. From page 200 to 300&quot;<p>... fragmnets ...<p>LLM output: show me 3, 5, 13.<p>New query, with attached the full documents for 75% of context window.<p>&quot;Based on the attached documents in this chat, reply to $QUESTION&quot;.</div><br/></div></div><div id="42708296" class="c"><input type="checkbox" id="c-42708296" checked=""/><div class="controls bullet"><span class="by">pilooch</span><span>|</span><a href="#42705300">parent</a><span>|</span><a href="#42708643">prev</a><span>|</span><a href="#42706617">next</a><span>|</span><label class="collapse" for="c-42708296">[-]</label><label class="expand" for="c-42708296">[1 more]</label></div><br/><div class="children"><div class="content">Statistically you want the retriever to be trained for cosine similarity. Vision LLM retriever such as DSE do this correctly. No need for reranker once done.</div><br/></div></div></div></div><div id="42706617" class="c"><input type="checkbox" id="c-42706617" checked=""/><div class="controls bullet"><span class="by">bjourne</span><span>|</span><a href="#42705300">prev</a><span>|</span><a href="#42708548">next</a><span>|</span><label class="collapse" for="c-42706617">[-]</label><label class="expand" for="c-42706617">[3 more]</label></div><br/><div class="children"><div class="content">So word vectors solve the problem that two words may never appear in the same context, yet can be strongly correlated. &quot;Python&quot; may never be found close to &quot;Ruby&quot;, yet &quot;scripting&quot; is likely to be found in both their contexts so the embedding algorithm will ensure that they are close in some vector space. Except it rarely works well because of the curse of dimensionality.<p>Perhaps one could represent word embeddings as vertices, rather than vectors? Suppose you find &quot;Python&quot; and &quot;scripting&quot; in the same context. You draw a weighted edge between them. If you find the same words again you reduce the weight of the edge. Then to compute the similarity between two words, just compute the weighted shortest path between their vertices. You could extend it to pair-wise sentence similarity using Steiner trees. Of course it would be much slower than cosine similarity, but probably also much more useful.</div><br/><div id="42708655" class="c"><input type="checkbox" id="c-42708655" checked=""/><div class="controls bullet"><span class="by">yobbo</span><span>|</span><a href="#42706617">parent</a><span>|</span><a href="#42706700">next</a><span>|</span><label class="collapse" for="c-42708655">[-]</label><label class="expand" for="c-42708655">[1 more]</label></div><br/><div class="children"><div class="content">Embeddings represent more than P(&quot;found in the same context&quot;).<p>It is true that cosine similarity is unhelpful if you expect it to be a distance measure.<p>[0,0,1] and [0,1,0] are orthogonal (cosine 0) but have euclidean distance √2, and 1&#x2F;3 of vector elements are identical.<p>It is better if embeddings encode also angles, absolute and relative distances in some meaningful way. Testing only cosine ignores all distances.</div><br/></div></div><div id="42706700" class="c"><input type="checkbox" id="c-42706700" checked=""/><div class="controls bullet"><span class="by">jsenn</span><span>|</span><a href="#42706617">parent</a><span>|</span><a href="#42708655">prev</a><span>|</span><a href="#42708548">next</a><span>|</span><label class="collapse" for="c-42706700">[-]</label><label class="expand" for="c-42706700">[1 more]</label></div><br/><div class="children"><div class="content">You might be interested in HippoRAG [1] which takes a graph-based approach similar to what you’re suggesting here.<p>[1]: <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2405.14831" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2405.14831</a></div><br/></div></div></div></div><div id="42708548" class="c"><input type="checkbox" id="c-42708548" checked=""/><div class="controls bullet"><span class="by">romanhn</span><span>|</span><a href="#42706617">prev</a><span>|</span><a href="#42706105">next</a><span>|</span><label class="collapse" for="c-42708548">[-]</label><label class="expand" for="c-42708548">[2 more]</label></div><br/><div class="children"><div class="content">Say I generate embeddings for a bunch of articles. Given the query &quot;articles about San Francisco that don&#x27;t mention cars&quot; would cosine similarity uprank or downrank the car mentions? Assuming exclusions aren&#x27;t handled well, what techniques might I use to support them?</div><br/><div id="42708573" class="c"><input type="checkbox" id="c-42708573" checked=""/><div class="controls bullet"><span class="by">mirekrusin</span><span>|</span><a href="#42708548">parent</a><span>|</span><a href="#42706105">next</a><span>|</span><label class="collapse" for="c-42708573">[-]</label><label class="expand" for="c-42708573">[1 more]</label></div><br/><div class="children"><div class="content">I think you have to separate it into negative query and run (negative) rank and combine results yourself.</div><br/></div></div></div></div><div id="42706105" class="c"><input type="checkbox" id="c-42706105" checked=""/><div class="controls bullet"><span class="by">deepsquirrelnet</span><span>|</span><a href="#42708548">prev</a><span>|</span><a href="#42708165">next</a><span>|</span><label class="collapse" for="c-42706105">[-]</label><label class="expand" for="c-42706105">[5 more]</label></div><br/><div class="children"><div class="content">&gt; So, what can we use instead?<p>&gt; The most powerful approach<p>&gt; The best approach is to directly use LLM query to compare two entries.<p>Cross encoders are a solution I’m quite fond of, high performing and much faster. I recently put an STS cross encoder up on huggingface based on ModernBERT that performs very well.</div><br/><div id="42707187" class="c"><input type="checkbox" id="c-42707187" checked=""/><div class="controls bullet"><span class="by">sroussey</span><span>|</span><a href="#42706105">parent</a><span>|</span><a href="#42706484">next</a><span>|</span><label class="collapse" for="c-42707187">[-]</label><label class="expand" for="c-42707187">[1 more]</label></div><br/><div class="children"><div class="content">I had to look that up… for others:<p>An STS cross encoder is a model that uses the CrossEncoder class to predict the semantic similarity between two sentences. STS stands for Semantic Textual Similarity.</div><br/></div></div><div id="42706484" class="c"><input type="checkbox" id="c-42706484" checked=""/><div class="controls bullet"><span class="by">staticautomatic</span><span>|</span><a href="#42706105">parent</a><span>|</span><a href="#42707187">prev</a><span>|</span><a href="#42706782">next</a><span>|</span><label class="collapse" for="c-42706484">[-]</label><label class="expand" for="c-42706484">[2 more]</label></div><br/><div class="children"><div class="content">Link please?</div><br/><div id="42706508" class="c"><input type="checkbox" id="c-42706508" checked=""/><div class="controls bullet"><span class="by">deepsquirrelnet</span><span>|</span><a href="#42706105">root</a><span>|</span><a href="#42706484">parent</a><span>|</span><a href="#42706782">next</a><span>|</span><label class="collapse" for="c-42706508">[-]</label><label class="expand" for="c-42706508">[1 more]</label></div><br/><div class="children"><div class="content">Here you go!<p><a href="https:&#x2F;&#x2F;huggingface.co&#x2F;dleemiller&#x2F;ModernCE-base-sts" rel="nofollow">https:&#x2F;&#x2F;huggingface.co&#x2F;dleemiller&#x2F;ModernCE-base-sts</a><p>There’s also the large model, which performs a bit better.</div><br/></div></div></div></div><div id="42706782" class="c"><input type="checkbox" id="c-42706782" checked=""/><div class="controls bullet"><span class="by">janalsncm</span><span>|</span><a href="#42706105">parent</a><span>|</span><a href="#42706484">prev</a><span>|</span><a href="#42708165">next</a><span>|</span><label class="collapse" for="c-42706782">[-]</label><label class="expand" for="c-42706782">[1 more]</label></div><br/><div class="children"><div class="content">Cross encoders still don’t solve the fundamental problem of defining similarity that the author is referring to.<p>Frankly, the LLM approach the author talks about in the end doesn’t either. What does “similar” mean here?<p>Given inputs A, B, and C, you have to decide whether A and B are more similar or A and C are more similar. The algorithm (or architecture, depending on how you look at it) can’t do that for you. Dual encoder, cross encoder, bag of words, it doesn’t matter.</div><br/></div></div></div></div><div id="42708165" class="c"><input type="checkbox" id="c-42708165" checked=""/><div class="controls bullet"><span class="by">cranium</span><span>|</span><a href="#42706105">prev</a><span>|</span><a href="#42707385">next</a><span>|</span><label class="collapse" for="c-42708165">[-]</label><label class="expand" for="c-42708165">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s also why HyDE (Hypothetical Document Embeddings) can work better when the context isn&#x27;t clear. Instead of embedding the user question directly – and risk retrieving chunks that look like the question – you ask a LLM to hallucinate an answer and use that to retrieve relevant chunks. Obviously, the hallucinated bits are never used afterwards.</div><br/></div></div><div id="42707385" class="c"><input type="checkbox" id="c-42707385" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#42708165">prev</a><span>|</span><a href="#42705713">next</a><span>|</span><label class="collapse" for="c-42707385">[-]</label><label class="expand" for="c-42707385">[6 more]</label></div><br/><div class="children"><div class="content">My chunk rewriting method is to use a LLM to generate a title, summary, keyword list, topic, parent topic, and gp topic. Then I embed the concatenation of all of them instead of just the original chunk. This helps a lot.<p>One fundamental problem of cosine similarity is that it works on surface level. For example, &quot;5+5&quot; won&#x27;t embed close to &quot;10&quot;. Or &quot;The 5th word of this phrase&quot; won&#x27;t be similar to &quot;this&quot;.<p>If there is any implicit knowledge it won&#x27;t be captured by simple cosine similarity, that is why we need to draw out those inplicit deductions before embedding. Hence my approach of pre-embedding expansion of chunk semantic information.<p>I basically treat text like code, and have to &quot;run the code&quot; to get its meaning unpacked.</div><br/><div id="42707566" class="c"><input type="checkbox" id="c-42707566" checked=""/><div class="controls bullet"><span class="by">gavmor</span><span>|</span><a href="#42707385">parent</a><span>|</span><a href="#42705713">next</a><span>|</span><label class="collapse" for="c-42707566">[-]</label><label class="expand" for="c-42707566">[5 more]</label></div><br/><div class="children"><div class="content">How do you contextualize the chunk at re-write time?</div><br/><div id="42707651" class="c"><input type="checkbox" id="c-42707651" checked=""/><div class="controls bullet"><span class="by">ewild</span><span>|</span><a href="#42707385">root</a><span>|</span><a href="#42707566">parent</a><span>|</span><a href="#42705713">next</a><span>|</span><label class="collapse" for="c-42707651">[-]</label><label class="expand" for="c-42707651">[4 more]</label></div><br/><div class="children"><div class="content">the original chunk is most likely stored with it in referential format such as an id in the metadata to pull from a DB or something along those lines. I do exactly what he does aswell and i have an Id metadata value that does exactly that pointing to an id in a DB which holds the text chunks and their respective metadata</div><br/><div id="42707971" class="c"><input type="checkbox" id="c-42707971" checked=""/><div class="controls bullet"><span class="by">gavmor</span><span>|</span><a href="#42707385">root</a><span>|</span><a href="#42707651">parent</a><span>|</span><a href="#42705713">next</a><span>|</span><label class="collapse" for="c-42707971">[-]</label><label class="expand" for="c-42707971">[3 more]</label></div><br/><div class="children"><div class="content">The original chunk, sure, but what if the original chunk is full of eg pronouns? This is a problem I haven&#x27;t heard an elegant solution for, although I&#x27;ve seen it done OK.<p>What I mean is, how can you derive topics from a chunk that refers to them only obliquely?</div><br/><div id="42708226" class="c"><input type="checkbox" id="c-42708226" checked=""/><div class="controls bullet"><span class="by">gearhart</span><span>|</span><a href="#42707385">root</a><span>|</span><a href="#42707971">parent</a><span>|</span><a href="#42705713">next</a><span>|</span><label class="collapse" for="c-42708226">[-]</label><label class="expand" for="c-42708226">[2 more]</label></div><br/><div class="children"><div class="content">Before chunking, run coreference resolution to get rid of all of your pronouns and replace them with explicit references. You need to be a bit of careful to ensure you chunk both processed and unprocessed versions in the same places but it’s very doable.<p>If you haven’t seen it, there’s a lovely overview of the idea in one of the SpaCy blog posts: <a href="https:&#x2F;&#x2F;explosion.ai&#x2F;blog&#x2F;coref" rel="nofollow">https:&#x2F;&#x2F;explosion.ai&#x2F;blog&#x2F;coref</a></div><br/><div id="42708367" class="c"><input type="checkbox" id="c-42708367" checked=""/><div class="controls bullet"><span class="by">gavmor</span><span>|</span><a href="#42707385">root</a><span>|</span><a href="#42708226">parent</a><span>|</span><a href="#42705713">next</a><span>|</span><label class="collapse" for="c-42708367">[-]</label><label class="expand" for="c-42708367">[1 more]</label></div><br/><div class="children"><div class="content">Oh wow, yes, this is clever!</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="42705713" class="c"><input type="checkbox" id="c-42705713" checked=""/><div class="controls bullet"><span class="by">weitendorf</span><span>|</span><a href="#42707385">prev</a><span>|</span><a href="#42706756">next</a><span>|</span><label class="collapse" for="c-42705713">[-]</label><label class="expand" for="c-42705713">[1 more]</label></div><br/><div class="children"><div class="content">Cosine similarity and top-k RAG feel so primitive to me, like we are still in the semantic dark ages.<p>The article is right to point out that cosine similarity is more of an accidental property of data than anything in most cases (but IIUC there are newer embedding models that are deliberately trained for cosine similarity as a similarity measure). The author&#x27;s bootstrapping approach is interesting especially because of it&#x27;s ability to map relations other than the identity, but it seems like more of a computational optimization or shortcut (you could just run inference on the input) than a way to correlate unstructured data.<p>After trying out some RAG approaches and becoming disillusioned pretty quickly I think we need to solve the problem much deeper by structuring models so that they can perform RAG during training. Prompting typical LLMs with RAG gives them input that is dissimilar from their training data and relies on heuristics (like the data format) and thresholds (like topK) that live outside the model itself. We could probably greatly improve this by having models define the embeddings, formats, and retrieval processes (ie learn its own multi-step or &quot;agentic&quot; RAG while it learns everything else) that best help them model their training data.<p>I&#x27;m not an AI researcher though and I assume the real problem is that getting the right structure to train properly&#x2F;efficiently is rather difficult.</div><br/></div></div><div id="42706756" class="c"><input type="checkbox" id="c-42706756" checked=""/><div class="controls bullet"><span class="by">nomilk</span><span>|</span><a href="#42705713">prev</a><span>|</span><a href="#42707475">next</a><span>|</span><label class="collapse" for="c-42706756">[-]</label><label class="expand" for="c-42706756">[2 more]</label></div><br/><div class="children"><div class="content">Occasionally I&#x27;ll forget a famous quote [0] so I&#x27;ll describe it to an LLM but the LLM is rarely able to find it. I think it&#x27;s because the description of the quote uses &#x27;like&#x27; words, but not the <i>exact</i> words in the quote, so the LLM gets confused and can&#x27;t find it.<p>Interestingly, the opposite conclusion is drawn in the TFA (the article says LLMs are quite <i>good</i> at identifying &#x27;like&#x27; words, or, at least, better than the cosine method, which admittedly isn&#x27;t a high bar).<p>[0] Admittedly, some are a little obscure, but they&#x27;re in famous publications by famous authors, so I&#x27;d have expected an LLM to have &#x27;seen&#x27; them before.</div><br/><div id="42708544" class="c"><input type="checkbox" id="c-42708544" checked=""/><div class="controls bullet"><span class="by">seanhunter</span><span>|</span><a href="#42706756">parent</a><span>|</span><a href="#42707475">next</a><span>|</span><label class="collapse" for="c-42708544">[-]</label><label class="expand" for="c-42708544">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s not how llm training and recall works at all so I&#x27;m not surprised you are not getting good results in this way. You would be much better using a conventional search engine or if you want to use an llm, use one with a search tool so it will use the search engine for you.<p>The problem you&#x27;re encountering is not the model being unable to determine whether a quote it knows is responsive to your prompt but instead is a problem to do with recall in the model (which is not generally a task it&#x27;s trained for). So it&#x27;s not a similarity problem it&#x27;s a recall problem.<p>When LLMs are trained on a particular document, they don&#x27;t save a perfect copy somehow that they can fish out later. They use it to update their weights via backpropogation and are evaluated on their &quot;sentence completion&quot; task during the main phase of training or on a prompt response eval set during instruction fine tuning. Unless your quote is in that set or is part of the eval for the sentence completion task during the main training, there&#x27;s no reason to suppose the LLM will particularly be able to recall it as it&#x27;s not being trained to do that.<p>So what happens instead is the results of training on your quote update the weights in the model and that maybe somehow in some way that is quite mysterious results in some ability to recall it later but it&#x27;s not a task it&#x27;s evaluated on or trained for, so it&#x27;s not surprising it&#x27;s not great at it and in fact it&#x27;s a wonder it can do it at all.<p>p.s. If you want to evaluate whether it is struggling with similarity, look up a quote and ask a model whether or not it&#x27;s responsive to a given question.  I.e. give it a prompt like this<p><pre><code>   I want a quote about someone living the highlife during  the 1960s.  Do you think this quote by George Best does the job? “I spent a lot of money on booze, birds, and fast cars. The rest I just squandered.”</code></pre></div><br/></div></div></div></div><div id="42707475" class="c"><input type="checkbox" id="c-42707475" checked=""/><div class="controls bullet"><span class="by">mlepath</span><span>|</span><a href="#42706756">prev</a><span>|</span><a href="#42705469">next</a><span>|</span><label class="collapse" for="c-42707475">[-]</label><label class="expand" for="c-42707475">[2 more]</label></div><br/><div class="children"><div class="content">In ML everything is a tradeoff. The article strongly suggests using dot product similarity and it&#x27;s a great metric in some situations, but dot product similarity has some issues too:
- not normalized (unlike cosine simularity)
- heavily favors large vectors
- unbounded output
- ...<p>Basically, do not carelessly use any similarity metric.</div><br/><div id="42708114" class="c"><input type="checkbox" id="c-42708114" checked=""/><div class="controls bullet"><span class="by">danieldk</span><span>|</span><a href="#42707475">parent</a><span>|</span><a href="#42705469">next</a><span>|</span><label class="collapse" for="c-42708114">[-]</label><label class="expand" for="c-42708114">[1 more]</label></div><br/><div class="children"><div class="content">Traditional word embeddings (like word2vec) were trained using logistic regression. So probably the closest would be <i>σ(u.v)</i>, which is of course nicely bounded.<p>(The catch is that during training logistic regression is done on the word and context vectors, but they have a high degree of similarity. People would even sum the context vectors and word vectors or train with word and context vectors being the same vectors without much loss.)</div><br/></div></div></div></div><div id="42705469" class="c"><input type="checkbox" id="c-42705469" checked=""/><div class="controls bullet"><span class="by">abstractbill</span><span>|</span><a href="#42707475">prev</a><span>|</span><a href="#42706922">next</a><span>|</span><label class="collapse" for="c-42705469">[-]</label><label class="expand" for="c-42705469">[2 more]</label></div><br/><div class="children"><div class="content">Typo: &quot;When we with vectors&quot; should be &quot;When we <i>work</i> with vectors&quot; I think.</div><br/><div id="42708798" class="c"><input type="checkbox" id="c-42708798" checked=""/><div class="controls bullet"><span class="by">stared</span><span>|</span><a href="#42705469">parent</a><span>|</span><a href="#42706922">next</a><span>|</span><label class="collapse" for="c-42708798">[-]</label><label class="expand" for="c-42708798">[1 more]</label></div><br/><div class="children"><div class="content">Thx, fixed!</div><br/></div></div></div></div><div id="42706922" class="c"><input type="checkbox" id="c-42706922" checked=""/><div class="controls bullet"><span class="by">anArbitraryOne</span><span>|</span><a href="#42705469">prev</a><span>|</span><a href="#42706959">next</a><span>|</span><label class="collapse" for="c-42706922">[-]</label><label class="expand" for="c-42706922">[1 more]</label></div><br/><div class="children"><div class="content">Just want to say how great I am for calling this out a few months ago <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;context?id=41470605">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;context?id=41470605</a></div><br/></div></div><div id="42706959" class="c"><input type="checkbox" id="c-42706959" checked=""/><div class="controls bullet"><span class="by">Nataliaaaa</span><span>|</span><a href="#42706922">prev</a><span>|</span><a href="#42705455">next</a><span>|</span><label class="collapse" for="c-42706959">[-]</label><label class="expand" for="c-42706959">[1 more]</label></div><br/><div class="children"><div class="content">By the way, I just wanted to say I really like your post! It’s well-reasoned, clear, and the use of images makes it super easy and enjoyable to read. So visually pleasing!</div><br/></div></div><div id="42705455" class="c"><input type="checkbox" id="c-42705455" checked=""/><div class="controls bullet"><span class="by">pooyak</span><span>|</span><a href="#42706959">prev</a><span>|</span><a href="#42706207">next</a><span>|</span><label class="collapse" for="c-42705455">[-]</label><label class="expand" for="c-42705455">[3 more]</label></div><br/><div class="children"><div class="content">Very interesting article. Is there any model that can generate embeddings given a system prompt? This can be useful not only for similarity searching but also for clustering use cases without having to do too much custom work. Essentially, a zero shot embedding model.</div><br/><div id="42705788" class="c"><input type="checkbox" id="c-42705788" checked=""/><div class="controls bullet"><span class="by">Loranubi</span><span>|</span><a href="#42705455">parent</a><span>|</span><a href="#42705770">next</a><span>|</span><label class="collapse" for="c-42705788">[-]</label><label class="expand" for="c-42705788">[1 more]</label></div><br/><div class="children"><div class="content">There are many embedding models supporting instructions. <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;mteb&#x2F;leaderboard" rel="nofollow">https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;mteb&#x2F;leaderboard</a></div><br/></div></div><div id="42705770" class="c"><input type="checkbox" id="c-42705770" checked=""/><div class="controls bullet"><span class="by">petesergeant</span><span>|</span><a href="#42705455">parent</a><span>|</span><a href="#42705788">prev</a><span>|</span><a href="#42706207">next</a><span>|</span><label class="collapse" for="c-42705770">[-]</label><label class="expand" for="c-42705770">[1 more]</label></div><br/><div class="children"><div class="content">I may have missed the point of your question, but there are many generators of embeddings:<p><a href="https:&#x2F;&#x2F;openai.com&#x2F;index&#x2F;new-embedding-models-and-api-updates&#x2F;" rel="nofollow">https:&#x2F;&#x2F;openai.com&#x2F;index&#x2F;new-embedding-models-and-api-update...</a></div><br/></div></div></div></div><div id="42706207" class="c"><input type="checkbox" id="c-42706207" checked=""/><div class="controls bullet"><span class="by">nikolayasdf123</span><span>|</span><a href="#42705455">prev</a><span>|</span><a href="#42706481">next</a><span>|</span><label class="collapse" for="c-42706207">[-]</label><label class="expand" for="c-42706207">[1 more]</label></div><br/><div class="children"><div class="content">&gt; &quot;Is {sentence_a} similar to {sentence_b}?&quot;<p>I also find this methods powerful. I see more and more software is getting outsourced into LLM judgements&#x2F;prompts.</div><br/></div></div><div id="42706481" class="c"><input type="checkbox" id="c-42706481" checked=""/><div class="controls bullet"><span class="by">SubiculumCode</span><span>|</span><a href="#42706207">prev</a><span>|</span><label class="collapse" for="c-42706481">[-]</label><label class="expand" for="c-42706481">[2 more]</label></div><br/><div class="children"><div class="content">The article is basically saying: if the feature vectors are crypticly encoded, then cosine similarity tells you little.<p>Cosin similarity of two encrypted images would be useless, unencrypt them, a bit more useful.<p>The &#x27;strings are not the territory&#x27; in other words, the territory is the semantic constructs cryptically encoded into those strings. You want the similarity of constructs, not strings.</div><br/><div id="42707487" class="c"><input type="checkbox" id="c-42707487" checked=""/><div class="controls bullet"><span class="by">j16sdiz</span><span>|</span><a href="#42706481">parent</a><span>|</span><label class="collapse" for="c-42707487">[-]</label><label class="expand" for="c-42707487">[1 more]</label></div><br/><div class="children"><div class="content">I can&#x27;t see these in this article, at all.<p>I think what it say is under &quot;Is it the right kind of similarity?&quot; :<p>&gt; Consider books.
&gt; For a literary critic, similarity might mean sharing thematic elements. For a librarian, it&#x27;s about genre classification.
&gt; For a reader, it&#x27;s about emotions it evokes. For a typesetter, it&#x27;s page count and format.
&gt; Each perspective is valid, yet cosine similarity smashes all these nuanced views into a single number — with confidence and an illusion of objectivity.</div><br/></div></div></div></div></div></div></div></div></div></body></html>