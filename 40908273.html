<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1720515672650" as="style"/><link rel="stylesheet" href="styles.css?v=1720515672650"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://arxiv.org/abs/2309.04259">C++ patterns for low-latency applications including high-frequency trading</a> <span class="domain">(<a href="https://arxiv.org">arxiv.org</a>)</span></div><div class="subtext"><span>chris_overseas</span> | <span>151 comments</span></div><br/><div><div id="40911715" class="c"><input type="checkbox" id="c-40911715" checked=""/><div class="controls bullet"><span class="by">nickelpro</span><span>|</span><a href="#40910923">next</a><span>|</span><label class="collapse" for="c-40911715">[-]</label><label class="expand" for="c-40911715">[24 more]</label></div><br/><div class="children"><div class="content">Fairly trivial base introduction to the subject.<p>In my experience teaching undergrads they mostly get this stuff already. Their CompArch class has taught them the basics of branch prediction, cache coherence, and instruction caches; the trivial elements of performance.<p>I&#x27;m somewhat surprised the piece doesn&#x27;t deal at all with a classic performance killer, false sharing, although it seems mostly concerned with single-threaded latency. The total lack of &quot;free&quot; optimization tricks like fat LTO, PGO, or even the standardized hinting attributes ([[likely]], [[unlikely]]) for optimizing icache layout was also surprising.<p>Neither this piece, nor my undergraduates, deal with the more nitty-gritty elements of performance. These mostly get into the usage specifics of particular IO APIs, synchronization primitives, IPC mechanisms, and some of the more esoteric compiler builtins.<p>Besides all that, what the nascent low-latency programmer almost always lacks, and the hardest thing to instill in them, is a certain paranoia. A genuine fear, hate, and anger, towards unnecessary allocations, copies, and other performance killers. A creeping feeling that causes them to compulsively run the benchmarks through callgrind looking for calls into the object cache that miss and go to an allocator in the middle of the hot loop.<p>I think a formative moment for me was when I was writing a low-latency server and I realized that constructing a vector I&#x2F;O operation ended up being overall slower than just copying the small objects I was dealing with into a contiguous buffer and performing a single write. There&#x27;s no such thing as a free copy, and that includes fat pointers.</div><br/><div id="40911758" class="c"><input type="checkbox" id="c-40911758" checked=""/><div class="controls bullet"><span class="by">mbo</span><span>|</span><a href="#40911715">parent</a><span>|</span><a href="#40912535">next</a><span>|</span><label class="collapse" for="c-40911758">[-]</label><label class="expand" for="c-40911758">[21 more]</label></div><br/><div class="children"><div class="content">Out of interest, do you have any literature that you&#x27;d recommend instead?</div><br/><div id="40911822" class="c"><input type="checkbox" id="c-40911822" checked=""/><div class="controls bullet"><span class="by">nickelpro</span><span>|</span><a href="#40911715">root</a><span>|</span><a href="#40911758">parent</a><span>|</span><a href="#40912156">next</a><span>|</span><label class="collapse" for="c-40911822">[-]</label><label class="expand" for="c-40911822">[16 more]</label></div><br/><div class="children"><div class="content">On the software side I don&#x27;t think HFT is as special a space as this paper makes it out to be.[1] Each year at cppcon there&#x27;s another half-dozen talks going in depth on different elements of performance that cover more ground collectively than any single paper will.<p>Similarly, there&#x27;s an immense amount of formal literature and textbooks out of the game development space that can be very useful to newcomers looking for structural approaches to high performance compute and IO loops. Games care a lot about local and network latency, the problem spaces aren&#x27;t that far apart (and writing games is a very fun way to learn).<p>I don&#x27;t have specific recommendations for holistic introductions to the field. I learn new techniques primarily through building things, watching conference talks, reading source code of other low latency projects, and discussion with coworkers.<p>[1]: HFT is quite special on the hardware side, which is discussed in the paper. The NICs, network stacks, and extensive integration of FPGAs do heavily differentiate the industry and I don&#x27;t want to insinuate otherwise.<p>You will not find a lot of SystemVerilog programmers at a typical video game studio.</div><br/><div id="40912086" class="c"><input type="checkbox" id="c-40912086" checked=""/><div class="controls bullet"><span class="by">Maxatar</span><span>|</span><a href="#40911715">root</a><span>|</span><a href="#40911822">parent</a><span>|</span><a href="#40913628">next</a><span>|</span><label class="collapse" for="c-40912086">[-]</label><label class="expand" for="c-40912086">[12 more]</label></div><br/><div class="children"><div class="content">As someone who does quant trading professionally and game development as a hobby, they both are performance sensitive, but they emphasize different kinds of performance. Trading is about minimizing latency while video games are about maximizing bandwidth.<p>Video games try to cram as much work as possible within about 16 milliseconds whereas for most trading algorithms 16 milliseconds is too slow to do anything, you want to process and produce a response to input within the span of microseconds, which is 3 orders of magnitude faster than a single frame in a video game.<p>The problem spaces really are quite distinct in this respect and a lot of techniques from one space don&#x27;t really carry over to the other.</div><br/><div id="40912332" class="c"><input type="checkbox" id="c-40912332" checked=""/><div class="controls bullet"><span class="by">ssfrr</span><span>|</span><a href="#40911715">root</a><span>|</span><a href="#40912086">parent</a><span>|</span><a href="#40912197">next</a><span>|</span><label class="collapse" for="c-40912332">[-]</label><label class="expand" for="c-40912332">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;m curious how HFT relates to pro audio programming. The timescale is close to gaming (usually &lt;10ms for desktop PC work), but you really care about the tail of the distribution. All the audio processing happens in a high-priority callback that&#x27;s called for every audio frame and needs complete within the time budget, so you typically never allocate, do IO, or use any blocking synchronization primitives [1].<p>It&#x27;s not hard real-time like you&#x27;re going to crash your car, but if you miss your deadline it causes an unacceptable and audible glitch.<p>I&#x27;ve always been a bit surprised that Jane Street uses OCaml. I know they&#x27;ve put a lot of attention into the GC, but it still seems fundamentally indeterminate in a way that would make most audio devs nervous.<p>[1]: <a href="http:&#x2F;&#x2F;www.rossbencina.com&#x2F;code&#x2F;real-time-audio-programming-101-time-waits-for-nothing" rel="nofollow">http:&#x2F;&#x2F;www.rossbencina.com&#x2F;code&#x2F;real-time-audio-programming-...</a></div><br/><div id="40912605" class="c"><input type="checkbox" id="c-40912605" checked=""/><div class="controls bullet"><span class="by">steve1977</span><span>|</span><a href="#40911715">root</a><span>|</span><a href="#40912332">parent</a><span>|</span><a href="#40912956">next</a><span>|</span><label class="collapse" for="c-40912605">[-]</label><label class="expand" for="c-40912605">[1 more]</label></div><br/><div class="children"><div class="content">In audio, you can usually tolerate a few milliseconds of latency (more when mixing, less when recording). This means you can buffer your audio stream, for example in blocks of 64 or 128 samples.<p>As far as I know, these millisecond latencies are orders of magnitude higher than what would be tolerable in HFT. There the  units are microseconds and nanoseconds.</div><br/></div></div></div></div><div id="40912197" class="c"><input type="checkbox" id="c-40912197" checked=""/><div class="controls bullet"><span class="by">nickelpro</span><span>|</span><a href="#40911715">root</a><span>|</span><a href="#40912086">parent</a><span>|</span><a href="#40912332">prev</a><span>|</span><a href="#40912961">next</a><span>|</span><label class="collapse" for="c-40912197">[-]</label><label class="expand" for="c-40912197">[2 more]</label></div><br/><div class="children"><div class="content">Of course, time spans are different. But read the paper, it&#x27;s dealing with incredibly basic techniques. When we&#x27;re speaking on the level of &quot;data should be in cache&quot; and &quot;cold code should be far away from the hot path&quot; the fields are practically identical.<p>You&#x27;re entirely correct that quant work is dealing with pure latency in situations where game engines might amortize throughput over multiple frames. But a question about &quot;how do I get started in performance&#x2F;latency work?&quot; isn&#x27;t usefully answered by &quot;get a Hudson River Trading internship&quot;.</div><br/><div id="40912220" class="c"><input type="checkbox" id="c-40912220" checked=""/><div class="controls bullet"><span class="by">Maxatar</span><span>|</span><a href="#40911715">root</a><span>|</span><a href="#40912197">parent</a><span>|</span><a href="#40912961">next</a><span>|</span><label class="collapse" for="c-40912220">[-]</label><label class="expand" for="c-40912220">[1 more]</label></div><br/><div class="children"><div class="content">On that point we certainly agree.</div><br/></div></div></div></div><div id="40912961" class="c"><input type="checkbox" id="c-40912961" checked=""/><div class="controls bullet"><span class="by">atomicnumber3</span><span>|</span><a href="#40911715">root</a><span>|</span><a href="#40912086">parent</a><span>|</span><a href="#40912197">prev</a><span>|</span><a href="#40913628">next</a><span>|</span><label class="collapse" for="c-40912961">[-]</label><label class="expand" for="c-40912961">[6 more]</label></div><br/><div class="children"><div class="content">&quot;which is 3 orders of magnitude faster than a single frame in a video game.&quot;<p>You&#x27;re right on the money. I worked in HFT for half a decade.<p>Back in the late 2000s you were on the cutting edge if you were writing really good C++ and had overclocked some CPUs to hell and back and then shoved them in a rack in a datacenter in new jersey. &quot;To hell and back&quot; means &quot;they only crash every hour or two&quot; (because while they&#x27;re up, they&#x27;re faster than your competition).<p>Around the mid 2010&#x27;s it had moved entirely to FPGAs. Do something smart in software, then give the FPGA something dumb to wait for (e.g. use software to produce a model and wait for some kind of alpha to develop, then tell the FPGA &quot;ok wait for X &gt; Y and fire the order&quot; was basically the name of the game. And it was often better to be faster than it was to be smarter, so really you just kept the FPGA as simple and fast as possible.<p>At that point, your hard realtime constraints for the language doing the smart stuff really dissolve. Compared to an FPGA getting an order out the door in some fraction of a mic, a CPU doing anything is slow. So you might as well use python, yknow?<p>People also play all kinds of different speed games. There&#x27;s latency races around NJ and chicago where microseconds matter around price movements and C++ isn&#x27;t really part of the picture in a competitive way anymore, but that&#x27;s not to say someone isn&#x27;t ekeing out a niche where they&#x27;re doing something vaguely smarter faster than opponents. But these things, at scale, tend to be questions of - either your alpha is very short-lived (microseconds, and if it isn&#x27;t organically microseconds, it will be competed until it is), or it is fundamentally longer-lived (seconds to minutes?) and you might as well use python and develop 100x faster.<p>The silly thing is, the really good trades that focus on short-term alphas (ms&#x27;s and less) are generally obviously good trades and so you don&#x27;t have to be super smart to realize it&#x27;s a really fucking good trade, you had better be fast and go get it. So there&#x27;s also this kind of built-in bias for being fast because if a trade is so marginally good that you needed a crazy smart and slow model to tell it apart from a bad trade, it&#x27;s probably still a relatively crummy trade and all your smarts let you do is pick up a few extra pennies for your trouble.<p>I&#x27;ll close by saying don&#x27;t take my words as representative of the industry - the trades my firm specialized in was literally a dying breed and my understanding is that most of the big crazy-crazy-fast-microwave-network people have moved to doing order execution anyway, because most of the money in the crazy-crazy-fast game dried up as more firms switched to either DIYing the order execution or paying a former-HFT to do it for them.</div><br/><div id="40913735" class="c"><input type="checkbox" id="c-40913735" checked=""/><div class="controls bullet"><span class="by">mgaunard</span><span>|</span><a href="#40911715">root</a><span>|</span><a href="#40912961">parent</a><span>|</span><a href="#40913366">next</a><span>|</span><label class="collapse" for="c-40913735">[-]</label><label class="expand" for="c-40913735">[1 more]</label></div><br/><div class="children"><div class="content">Even if the low-latency logic moves to the FPGA, you still need your slow path to be reasonably fast, say about 100us, and absolutely never more than 1ms.<p>To my knowledge Python is not suitable, though I know some players embed scripting languages that are.</div><br/></div></div><div id="40913366" class="c"><input type="checkbox" id="c-40913366" checked=""/><div class="controls bullet"><span class="by">doovd</span><span>|</span><a href="#40911715">root</a><span>|</span><a href="#40912961">parent</a><span>|</span><a href="#40913735">prev</a><span>|</span><a href="#40913628">next</a><span>|</span><label class="collapse" for="c-40913366">[-]</label><label class="expand" for="c-40913366">[4 more]</label></div><br/><div class="children"><div class="content">&gt; obviously good trades<p>Are you able to expand with any examples of this?</div><br/><div id="40913819" class="c"><input type="checkbox" id="c-40913819" checked=""/><div class="controls bullet"><span class="by">mgaunard</span><span>|</span><a href="#40911715">root</a><span>|</span><a href="#40913366">parent</a><span>|</span><a href="#40913737">next</a><span>|</span><label class="collapse" for="c-40913819">[-]</label><label class="expand" for="c-40913819">[1 more]</label></div><br/><div class="children"><div class="content">The idea for aggressive orders in HFT is to buy before the market goes up, and sell before the market goes down.<p>HFT signals are about detecting those patterns right before they occur, but as early as the information is available globally. For example someone just bought huge amounts of X, driving the price up, and you know Y is positively correlated to X, so Y will go up as well, so you buy it before it does.<p>X and Y might be fungible, correlated mechanically or statistically.<p>You can also do it on Y=X as well; then what you need is the ability to statistically tell whether a trade will initiate&#x2F;continue a trend or revert. You only need to be right most of the time.</div><br/></div></div><div id="40913737" class="c"><input type="checkbox" id="c-40913737" checked=""/><div class="controls bullet"><span class="by">au8er</span><span>|</span><a href="#40911715">root</a><span>|</span><a href="#40913366">parent</a><span>|</span><a href="#40913819">prev</a><span>|</span><a href="#40913628">next</a><span>|</span><label class="collapse" for="c-40913737">[-]</label><label class="expand" for="c-40913737">[2 more]</label></div><br/><div class="children"><div class="content">If every other exchange is selling $AAPL at $100 and suddenly the top level of one exchange drops to $99, then if you just take out that order you basically gain a free dollar. Do this very fast and have pricing the product accurately and you will print tons of money.</div><br/><div id="40913878" class="c"><input type="checkbox" id="c-40913878" checked=""/><div class="controls bullet"><span class="by">mgaunard</span><span>|</span><a href="#40911715">root</a><span>|</span><a href="#40913737">parent</a><span>|</span><a href="#40913628">next</a><span>|</span><label class="collapse" for="c-40913878">[-]</label><label class="expand" for="c-40913878">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not that simple. It could just be that exchange is the first one to drop to 99 but all others will as well.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="40913628" class="c"><input type="checkbox" id="c-40913628" checked=""/><div class="controls bullet"><span class="by">mgaunard</span><span>|</span><a href="#40911715">root</a><span>|</span><a href="#40911822">parent</a><span>|</span><a href="#40912086">prev</a><span>|</span><a href="#40913209">next</a><span>|</span><label class="collapse" for="c-40913628">[-]</label><label class="expand" for="c-40913628">[1 more]</label></div><br/><div class="children"><div class="content">Latency isn&#x27;t even as important in HFT as people claim. What&#x27;s most important is deterministically staying into a reasonable enveloppe (even at the 99.9 percentile) to satisfy real-time requirements and not fall behind.<p>When it&#x27;s really important, it&#x27;s implemented in FPGA or with an ASIC.</div><br/></div></div><div id="40913209" class="c"><input type="checkbox" id="c-40913209" checked=""/><div class="controls bullet"><span class="by">hawk_</span><span>|</span><a href="#40911715">root</a><span>|</span><a href="#40911822">parent</a><span>|</span><a href="#40913628">prev</a><span>|</span><a href="#40912156">next</a><span>|</span><label class="collapse" for="c-40913209">[-]</label><label class="expand" for="c-40913209">[2 more]</label></div><br/><div class="children"><div class="content">What other low latency projects in public domain are worth learning from?</div><br/><div id="40913369" class="c"><input type="checkbox" id="c-40913369" checked=""/><div class="controls bullet"><span class="by">nickelpro</span><span>|</span><a href="#40911715">root</a><span>|</span><a href="#40913209">parent</a><span>|</span><a href="#40912156">next</a><span>|</span><label class="collapse" for="c-40913369">[-]</label><label class="expand" for="c-40913369">[1 more]</label></div><br/><div class="children"><div class="content">Whatever is relevant to the domain you&#x27;re tackling. How you structurally approach latency in a web server is different than a 3D renderer, which is different than an audio stack, etc. All of those domains have great open source or source available code to learn from, but it wouldn&#x27;t be useful for me to say &quot;go read HAProxy&quot; if you&#x27;re never going to touch an HTTP packet. When I&#x27;m tackling a problem the first thing I do is research everything everyone else has done on the problem and read their code, benchmark it if possible, and steal all the good ideas.<p>The basic principles never change. Avoid copies, never allocate, keep the hot path local, and really, <i>good</i> codebases should be doing these things anyway. I don&#x27;t code any differently when I&#x27;m writing a command line argument parser vs low-latency RPC servers. It&#x27;s just a matter of how long I spend tweaking and trying to improve a specific section of code, how willing I am to throw out an entire abstraction I&#x27;ve been working on for perf.<p>In the domain of web stuff, effectively all the major load balancers are good to study. HAProxy, nginx, Envoy. Also anything antirez has ever touched.<p>Application servers are also interesting to study because there&#x27;s many tricks to learn from a piece of software that needs to interface with something very slow but otherwise wants to be completely transparent in the call graph. FastWSGI is a good example.</div><br/></div></div></div></div></div></div><div id="40912156" class="c"><input type="checkbox" id="c-40912156" checked=""/><div class="controls bullet"><span class="by">_aavaa_</span><span>|</span><a href="#40911715">root</a><span>|</span><a href="#40911758">parent</a><span>|</span><a href="#40911822">prev</a><span>|</span><a href="#40912535">next</a><span>|</span><label class="collapse" for="c-40912156">[-]</label><label class="expand" for="c-40912156">[4 more]</label></div><br/><div class="children"><div class="content">I&#x27;d recommend: <a href="https:&#x2F;&#x2F;www.computerenhance.com" rel="nofollow">https:&#x2F;&#x2F;www.computerenhance.com</a><p>The author has a strong game development (engine and tooling) background and I have found it incredibly useful.<p>It also satisfies the requirement for &quot;A genuine fear, hate, and anger, towards unnecessary allocations, copies, and other performance killers.&quot;</div><br/><div id="40912244" class="c"><input type="checkbox" id="c-40912244" checked=""/><div class="controls bullet"><span class="by">hi_dang_</span><span>|</span><a href="#40911715">root</a><span>|</span><a href="#40912156">parent</a><span>|</span><a href="#40912535">next</a><span>|</span><label class="collapse" for="c-40912244">[-]</label><label class="expand" for="c-40912244">[3 more]</label></div><br/><div class="children"><div class="content">Very anecdotal but of the people I know in game studios who are tasked with engine work, and people who make a killing doing FPGA work for HFT firms, both camps shook their head at Casey’s HMH thing. Uniformly I do not know of a single professional developer of this sort of caliber who looked at HMH and thought it looks great. Quite the opposite. I think they found his approach and justifications unsound as it would instil awful practices of premature unfounded optimization and a disdain for normal library code in favour of hand-rolling your own half-baked implementations based on outdated trivia. I agree with them on the basis that HMH exposed an unprepared and inexperienced audience to something that has to be regarded with utmost care. For this, I refer to Jonathan Blow’s presentation of “a list is probably good enough” as an antidote. I think JB’s recommendations are more in line with actual practices, whereas Casey just raised red flags uniformly from here-and-now engine devs shipping multi platform games.</div><br/><div id="40912335" class="c"><input type="checkbox" id="c-40912335" checked=""/><div class="controls bullet"><span class="by">_aavaa_</span><span>|</span><a href="#40911715">root</a><span>|</span><a href="#40912244">parent</a><span>|</span><a href="#40912315">next</a><span>|</span><label class="collapse" for="c-40912335">[-]</label><label class="expand" for="c-40912335">[1 more]</label></div><br/><div class="children"><div class="content">I have not watched Handmade Hero, so I can&#x27;t offer any comments any their comments based on factual claims about the software. A few things though:<p>I am not linking to handmade hero, I&#x27;m linking to a separate project of his (his performance aware programming course) that is actually aimed at being an educational piece.<p>I lied, I will comment on one factual piece. &quot;normal library code in favour of hand-rolling your own half-baked implementations based on outdated trivia.&quot; Yes, that is the whole point of the series (not the characterization as half-based and outdated trivia). The point was to show how to build a game (and its engine) from scratch to as big of a degree as possible. The avowing of library code is the point, to show what it takes to build engines rather than call a library so that the industry has more people who would even attempt doing such a thing.<p>Equally anecdotally, based on available online information, he worked for a long time on core technologies at RAD Game tools, a company which essentially every gamer, expect maybe pure mobile gamers, has purchased a game that used their technology. It may be possible that he acts (or acted in HMH) based on outdated trivia and favoured premature unfounded optimization, but I find it hard to believe based on the content of his I&#x27;ve engaged with and his track record.</div><br/></div></div><div id="40912315" class="c"><input type="checkbox" id="c-40912315" checked=""/><div class="controls bullet"><span class="by">nickelpro</span><span>|</span><a href="#40911715">root</a><span>|</span><a href="#40912244">parent</a><span>|</span><a href="#40912335">prev</a><span>|</span><a href="#40912535">next</a><span>|</span><label class="collapse" for="c-40912315">[-]</label><label class="expand" for="c-40912315">[1 more]</label></div><br/><div class="children"><div class="content">Casey&#x27;s a fundamentalist, in the religious extremist sense. Just as a theologian might have something to learn from the most extremely devout, so it is that there is valuable information in Casey&#x27;s proselytizing.<p>But you should no more follow Casey in form and function than you would any other fundamentalist.</div><br/></div></div></div></div></div></div></div></div><div id="40912535" class="c"><input type="checkbox" id="c-40912535" checked=""/><div class="controls bullet"><span class="by">contingencies</span><span>|</span><a href="#40911715">parent</a><span>|</span><a href="#40911758">prev</a><span>|</span><a href="#40910923">next</a><span>|</span><label class="collapse" for="c-40912535">[-]</label><label class="expand" for="c-40912535">[2 more]</label></div><br/><div class="children"><div class="content">How I might approach it. Interested in feedback from people closer to the space.<p>First, split the load in to simple asset-specific data streams with a front-end FPGA for raw speed. Resist the temptation to actually execute here as the friction is too high for iteration, people, supply chain, etc. Input may be a FIX stream or similar, output is a series of asset-specific binary event streams along low-latency buses, split in to asset-specific segments of a scalable cluster of low-end MCUs. Second, get rid of the general purpose operating system assumption on your asset-specific MCU-based execution platform to enable faster turnaround using low-level code you can actually find people to write on hardware you can actually purchase. Third, profit? In such a setup you&#x27;d need to monitor the overall state with a general purpose OS based governor which could pause or change strategies by reprogramming the individual elements as required.<p>Just how low are the latencies involved? At a certain point you&#x27;re better off paying to get the hardware closer to the core than bothering with engineering, right? I guess that heavily depends on the rules and available DCs &#x2F; link infrastructure offered by the exchanges or pools in question. I would guess a number of profitable operations probably don&#x27;t disclose which pools they connect to and make a business of front-running, regulations or terms of service be damned. In such cases, the relative network geographic latency between two points of execution is more powerful than the absolute latency to one.</div><br/><div id="40913123" class="c"><input type="checkbox" id="c-40913123" checked=""/><div class="controls bullet"><span class="by">nickelpro</span><span>|</span><a href="#40911715">root</a><span>|</span><a href="#40912535">parent</a><span>|</span><a href="#40910923">next</a><span>|</span><label class="collapse" for="c-40913123">[-]</label><label class="expand" for="c-40913123">[1 more]</label></div><br/><div class="children"><div class="content">The work I do is all in the single-to-low-double-digit microsecond range to give you an idea of timing constraints. I&#x27;m peripheral to HFT as a field though.<p>&gt; First, split the load in to simple asset-specific data streams with a front-end FPGA for raw speed. Resist the temptation to actually execute here as the friction is too high for iteration, people, supply chain, etc.<p>This is largely incorrect, or more generously <i>out-of-date</i>, and it influences everything downstream of your explanation. Think of FPGAs as far more flexible GPUs and you&#x27;re in the right arena. Input parsing and filtering are the obvious applications, but this is by no means the end state.<p>A wide variety of sanity checks and monitoring features are pushed to the FPGAs, fixed calculation tasks, and output generation. It is possible for the entire stack for some (or most, or all) transactions to be implemented at the FPGA layer. For such transactions the time magnitudes are mid-to-high triple digit nanoseconds. The stacks I&#x27;ve seen with my own two eyeballs talked to supervision algorithms over PCIe (which themselves must be not-slow, but not in the same realm as &lt;10us work), but otherwise nothing crazy fancy. This is well covered in the older academic work on the subject [1], which is why I&#x27;m fairly certain its long out of date by now.<p>HRT has some public information on the pipeline they use for testing and verifying trading components implemented in HDL.[2] With the modern tooling, namely Verilator, development isn&#x27;t significantly different than modern software development. If anything, SystemVerilog components are much easier to unit test than typical C++ code.<p>Beyond that it gets way too firm-specific to really comment on anything, and I&#x27;m certainly not the one to comment. There&#x27;s maybe three dozen HFT firms in the entire United States? It&#x27;s not a huge field with widely acknowledged industry norms.<p>[1]: <a href="https:&#x2F;&#x2F;ieeexplore.ieee.org&#x2F;document&#x2F;6299067" rel="nofollow">https:&#x2F;&#x2F;ieeexplore.ieee.org&#x2F;document&#x2F;6299067</a><p>[2]: <a href="https:&#x2F;&#x2F;www.hudsonrivertrading.com&#x2F;hrtbeat&#x2F;verify-custom-hardware&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.hudsonrivertrading.com&#x2F;hrtbeat&#x2F;verify-custom-har...</a></div><br/></div></div></div></div></div></div><div id="40910923" class="c"><input type="checkbox" id="c-40910923" checked=""/><div class="controls bullet"><span class="by">twic</span><span>|</span><a href="#40911715">prev</a><span>|</span><a href="#40909602">next</a><span>|</span><label class="collapse" for="c-40910923">[-]</label><label class="expand" for="c-40910923">[1 more]</label></div><br/><div class="children"><div class="content">My emphasis:<p>&gt; The output of this test is a test statistic (t-statistic) and an associated p-value. The t-statistic, also known as the score, is the result of the unit-root test on the residuals. A more negative t-statistic suggests that the residuals are more likely to be stationary. The p-value provides a measure of the probability that the null hypothesis of the test (no cointegration) is true. <i>The results of your test</i> yielded a p-value of approximately 0.0149 and a t-statistic of -3.7684.<p>I think they used an LLM to write this bit.<p>It&#x27;s also a really weird example. They look at correlation of once-a-day close prices over five years, and then write code to calculate the spread with 65 microsecond latency. That doesn&#x27;t actually make any sense as something to do. And you wouldn&#x27;t be calculating statistics on the spread in your inner loop. And 65 microseconds is far too slow for an inner loop. I suppose the point is just to exercise some optimisation techniques - but this is a rather unrepresentative thing to optimise!</div><br/></div></div><div id="40909602" class="c"><input type="checkbox" id="c-40909602" checked=""/><div class="controls bullet"><span class="by">sneilan1</span><span>|</span><a href="#40910923">prev</a><span>|</span><a href="#40913454">next</a><span>|</span><label class="collapse" for="c-40909602">[-]</label><label class="expand" for="c-40909602">[54 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve got an implementation of a stock exchange that uses the LMAX disruptor pattern in C++
<a href="https:&#x2F;&#x2F;github.com&#x2F;sneilan&#x2F;stock-exchange">https:&#x2F;&#x2F;github.com&#x2F;sneilan&#x2F;stock-exchange</a><p>And a basic implementation of the LMAX disruptor as a couple C++ files
<a href="https:&#x2F;&#x2F;github.com&#x2F;sneilan&#x2F;lmax-disruptor-tutorial">https:&#x2F;&#x2F;github.com&#x2F;sneilan&#x2F;lmax-disruptor-tutorial</a><p>I&#x27;ve been looking to rebuild this in rust however. I reached the point where I implemented my own websocket protocol, authentication system, SSL etc. Then I realized that memory management and dependencies are a lot easier in rust. Especially for a one man software project.</div><br/><div id="40910420" class="c"><input type="checkbox" id="c-40910420" checked=""/><div class="controls bullet"><span class="by">JedMartin</span><span>|</span><a href="#40909602">parent</a><span>|</span><a href="#40910861">next</a><span>|</span><label class="collapse" for="c-40910420">[-]</label><label class="expand" for="c-40910420">[3 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not easy to get data structures like this right in C++. There are a couple of problems with your implementation of the queue.
Memory accesses can be reordered by both the compiler and the CPU, so you should use std::atomic for your producer and consumer positions to get the barriers described in the original LMAX Disruptor paper.
In the get method, you&#x27;re returning a pointer to the element within the queue after bumping the consumer position (which frees the slot for the producer), so it can get overwritten while the user is accessing it.
And then your producer and consumer positions will most likely end up in the same cache line, leading to false sharing.</div><br/><div id="40910490" class="c"><input type="checkbox" id="c-40910490" checked=""/><div class="controls bullet"><span class="by">sneilan1</span><span>|</span><a href="#40909602">root</a><span>|</span><a href="#40910420">parent</a><span>|</span><a href="#40910861">next</a><span>|</span><label class="collapse" for="c-40910490">[-]</label><label class="expand" for="c-40910490">[2 more]</label></div><br/><div class="children"><div class="content">&gt;&gt; In the get method, you&#x27;re returning a pointer to the element within the queue after bumping the consumer position (which frees the slot for the producer), so it can get overwritten while the user is accessing it. And then your producer and consumer positions will most likely end up in the same cache line, leading to false sharing.<p>I did not realize this. Thank you so much for pointing this out. I&#x27;m going to take a look.<p>&gt;&gt; use std::atomic for your producer<p>Yes, it is hard to get these data structures right. I used Martin Fowler&#x27;s description of the LMAX algorithm which did not mention atomic. <a href="https:&#x2F;&#x2F;martinfowler.com&#x2F;articles&#x2F;lmax.html" rel="nofollow">https:&#x2F;&#x2F;martinfowler.com&#x2F;articles&#x2F;lmax.html</a>
I&#x27;ll check out the paper.</div><br/><div id="40910811" class="c"><input type="checkbox" id="c-40910811" checked=""/><div class="controls bullet"><span class="by">hi_dang_</span><span>|</span><a href="#40909602">root</a><span>|</span><a href="#40910490">parent</a><span>|</span><a href="#40910861">next</a><span>|</span><label class="collapse" for="c-40910811">[-]</label><label class="expand" for="c-40910811">[1 more]</label></div><br/><div class="children"><div class="content">I sincerely doubt the big HFT firms use anything of Fowler’s. Their optimizations are down to making their own hardware. LL is very context dependent and Amdahl’s law applies here.</div><br/></div></div></div></div></div></div><div id="40910861" class="c"><input type="checkbox" id="c-40910861" checked=""/><div class="controls bullet"><span class="by">worstspotgain</span><span>|</span><a href="#40909602">parent</a><span>|</span><a href="#40910420">prev</a><span>|</span><a href="#40911548">next</a><span>|</span><label class="collapse" for="c-40910861">[-]</label><label class="expand" for="c-40910861">[29 more]</label></div><br/><div class="children"><div class="content">I briefly looked over your stock exchange code:<p>- For memory management, consider switching to std::shared_ptr. It won&#x27;t slow anything down and will put that concern to rest entirely.<p>- For sockets, there are FOSS libraries that will outperform your code and save you a ton of headaches dealing with caveats and annoyances. For example, your looping through FD_ISSET is slower than e.g. epoll or kqueue.<p>- For dependencies, C++ is definitely wilder than other languages. Dependencies are even harder to find than they are to manage. There&#x27;s a lot of prospective library code, some of it hidden in little forgotten folds of the Internet. Finding it is basically a skill unto itself, one that can pay off handsomely.</div><br/><div id="40911224" class="c"><input type="checkbox" id="c-40911224" checked=""/><div class="controls bullet"><span class="by">zxcvbn4038</span><span>|</span><a href="#40909602">root</a><span>|</span><a href="#40910861">parent</a><span>|</span><a href="#40911181">next</a><span>|</span><label class="collapse" for="c-40911224">[-]</label><label class="expand" for="c-40911224">[9 more]</label></div><br/><div class="children"><div class="content">When I did low latency everyone was offloading TCP to dedicated hardware.<p>They would shut down every single process on the server and bind the trading trading app to the CPUs during trading hours to ensure nothing interrupted.<p>Electrons travel slower than light so they would rent server space at the exchange  so they had direct access to the exchange network and didn&#x27;t have to transverse miles of cables to send their orders.<p>They would multicast their traffic and there were separate systems to receive the multicast, log packets, and write orders to to databases. There were redundant trading servers that would monitor the multicast traffic so that if they had to take over they would know all of the open positions and orders.<p>They did all of their testing against simulators - never against live data or even the exchange test systems. They had a petabyte of exchange data they could play back to verify their code worked and to see if tweaks to the algorithm yielding better or worse trading decisions over time.<p>A solid understanding of the underlying hardware was required, you would make sure network interfaces were arranged in a way they wouldn&#x27;t cause contention on the PCI bus. You usually had separate interfaces for market data and orders.<p>All changes were done after exchange hours once trades had been submitted to the back office. The IT department was responsible for reimbursing traders for any losses caused by IT activity - there were shady traders who would look for IT problems and bank them up so they could blame a bad trade on them at some future time.</div><br/><div id="40912626" class="c"><input type="checkbox" id="c-40912626" checked=""/><div class="controls bullet"><span class="by">shaklee3</span><span>|</span><a href="#40909602">root</a><span>|</span><a href="#40911224">parent</a><span>|</span><a href="#40911284">next</a><span>|</span><label class="collapse" for="c-40912626">[-]</label><label class="expand" for="c-40912626">[3 more]</label></div><br/><div class="children"><div class="content">You don&#x27;t need to shut down processes on the server. All you have to do is isolate CPU cores and move your workloads onto those cores. That&#x27;s been a common practice in low latency networking for decades.</div><br/><div id="40912955" class="c"><input type="checkbox" id="c-40912955" checked=""/><div class="controls bullet"><span class="by">bluGill</span><span>|</span><a href="#40909602">root</a><span>|</span><a href="#40912626">parent</a><span>|</span><a href="#40911284">next</a><span>|</span><label class="collapse" for="c-40912955">[-]</label><label class="expand" for="c-40912955">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not in HFT, but I wouldn&#x27;t expect that to be enough.<p>Not only do you want to isolate cores, you want to isolate any shared cache between cores. You do not want your critical data ejected from the cache because a different core sharing the cache has decided it needs that cache. Which of course starts with knowing exactly what CPU you are using since different ones have different cache layouts.<p>You also don&#x27;t want those other cores using up precious main memory or IO bandwidth at the moment you need it.</div><br/><div id="40912995" class="c"><input type="checkbox" id="c-40912995" checked=""/><div class="controls bullet"><span class="by">worstspotgain</span><span>|</span><a href="#40909602">root</a><span>|</span><a href="#40912955">parent</a><span>|</span><a href="#40911284">next</a><span>|</span><label class="collapse" for="c-40912995">[-]</label><label class="expand" for="c-40912995">[1 more]</label></div><br/><div class="children"><div class="content">Just to add to your good points: since there&#x27;s always a faster cache for your working set to not fit in, you can use memory streaming instructions to reduce cache pollution. Depending on the algorithm, increasing cache hit rates can give ridiculous speed-ups.</div><br/></div></div></div></div></div></div><div id="40911284" class="c"><input type="checkbox" id="c-40911284" checked=""/><div class="controls bullet"><span class="by">gohwell</span><span>|</span><a href="#40909602">root</a><span>|</span><a href="#40911224">parent</a><span>|</span><a href="#40912626">prev</a><span>|</span><a href="#40912257">next</a><span>|</span><label class="collapse" for="c-40911284">[-]</label><label class="expand" for="c-40911284">[3 more]</label></div><br/><div class="children"><div class="content">I’ve worked at a few firms and never heard of an IT budget for f-ups. Sounds like a toxic work environment.</div><br/><div id="40913278" class="c"><input type="checkbox" id="c-40913278" checked=""/><div class="controls bullet"><span class="by">hawk_</span><span>|</span><a href="#40909602">root</a><span>|</span><a href="#40911284">parent</a><span>|</span><a href="#40911493">next</a><span>|</span><label class="collapse" for="c-40913278">[-]</label><label class="expand" for="c-40913278">[1 more]</label></div><br/><div class="children"><div class="content">Depends on how it&#x27;s set up. You take a chunk of profits as well if things go well.</div><br/></div></div></div></div><div id="40912257" class="c"><input type="checkbox" id="c-40912257" checked=""/><div class="controls bullet"><span class="by">rramadass</span><span>|</span><a href="#40909602">root</a><span>|</span><a href="#40911224">parent</a><span>|</span><a href="#40911284">prev</a><span>|</span><a href="#40911526">next</a><span>|</span><label class="collapse" for="c-40912257">[-]</label><label class="expand" for="c-40912257">[1 more]</label></div><br/><div class="children"><div class="content">Any good books&#x2F;resources you can recommend to learn about the above architectures&#x2F;techniques?</div><br/></div></div><div id="40911526" class="c"><input type="checkbox" id="c-40911526" checked=""/><div class="controls bullet"><span class="by">ra0x3</span><span>|</span><a href="#40909602">root</a><span>|</span><a href="#40911224">parent</a><span>|</span><a href="#40912257">prev</a><span>|</span><a href="#40911181">next</a><span>|</span><label class="collapse" for="c-40911526">[-]</label><label class="expand" for="c-40911526">[1 more]</label></div><br/><div class="children"><div class="content">A great insightful comment, thank you!</div><br/></div></div></div></div><div id="40911181" class="c"><input type="checkbox" id="c-40911181" checked=""/><div class="controls bullet"><span class="by">sneilan1</span><span>|</span><a href="#40909602">root</a><span>|</span><a href="#40910861">parent</a><span>|</span><a href="#40911224">prev</a><span>|</span><a href="#40911548">next</a><span>|</span><label class="collapse" for="c-40911181">[-]</label><label class="expand" for="c-40911181">[19 more]</label></div><br/><div class="children"><div class="content">I did not know std::shared_ptr would not slow things down. I&#x27;ve learned something new today! :)<p>Yes, I agree, epoll is a lot better than FD_ISSET.<p>Maybe I can keep moving with my C++ code but do people still trust C++ projects anymore? My ideal use case is a hobbyist who wants a toy stock exchange to run directly in AWS. I felt that C++ has a lot of bad publicity and if I want anyone to trust&#x2F;try my code I would have to rebuild it in rust.</div><br/><div id="40911337" class="c"><input type="checkbox" id="c-40911337" checked=""/><div class="controls bullet"><span class="by">worstspotgain</span><span>|</span><a href="#40909602">root</a><span>|</span><a href="#40911181">parent</a><span>|</span><a href="#40911882">next</a><span>|</span><label class="collapse" for="c-40911337">[-]</label><label class="expand" for="c-40911337">[16 more]</label></div><br/><div class="children"><div class="content">Here&#x27;s how to maximize shared_ptr performance:<p>- In function signatures, use const references: foo(const std::shared_ptr&lt;bar&gt; &amp;p). This will prevent unnecessary bumps of the refcount.<p>- If you have an inner loop copying a lot of pointers around, you can dereference the shared_ptr&#x27;s to raw pointers. This is 100% safe provided that the shared_ptr continues to exist in the meantime. I would consider this an optimization and an edge case, though.<p>I would say people trust C++ projects at least as much as any other professional language - more so if you prove that you know what you&#x27;re doing.</div><br/><div id="40911423" class="c"><input type="checkbox" id="c-40911423" checked=""/><div class="controls bullet"><span class="by">Maxatar</span><span>|</span><a href="#40909602">root</a><span>|</span><a href="#40911337">parent</a><span>|</span><a href="#40911882">next</a><span>|</span><label class="collapse" for="c-40911423">[-]</label><label class="expand" for="c-40911423">[15 more]</label></div><br/><div class="children"><div class="content">&gt; In function signatures, use const references: foo(const std::shared_ptr&lt;bar&gt; &amp;p). This will prevent unnecessary bumps of the refcount.<p>This advice doesn&#x27;t seem quite right to me, and in my codebases I strictly forbid passing shared_ptr by const reference. If you don&#x27;t need to share ownership of bar, then you do the following:<p><pre><code>    foo(const bar&amp;);
</code></pre>
If you do need to share ownership of bar, then you do the following:<p><pre><code>    foo(std::shared_ptr&lt;bar&gt;);
</code></pre>
Why do we pass by value when sharing ownership? Because it allows for move semantics, so that you give the caller to option to make a copy, which bumps up the reference count, or to entirely avoid any copy whatsoever, which allows transfering ownership without bumping the reference count.<p>Having said that, shared_ptrs do have their uses but they are very very rare and almost all of our use cases do not expose shared_ptr&#x27;s in the public API but rather use them as an implementation detail. We use them almost exclusively for things like immutable data structures, or copy-on-write semantics, or as a part of a lock-free data structure.</div><br/><div id="40913767" class="c"><input type="checkbox" id="c-40913767" checked=""/><div class="controls bullet"><span class="by">spacechild1</span><span>|</span><a href="#40909602">root</a><span>|</span><a href="#40911423">parent</a><span>|</span><a href="#40911606">next</a><span>|</span><label class="collapse" for="c-40913767">[-]</label><label class="expand" for="c-40913767">[1 more]</label></div><br/><div class="children"><div class="content">&gt; If you don&#x27;t need to share ownership of bar, then you do the following:
&gt;
&gt;     foo(const bar&amp;);<p>Exactly!<p>&gt; This advice doesn&#x27;t seem quite right to me, and in my codebases I strictly forbid passing shared_ptr by const reference<p>There is at least one use case I can think of: the function <i>may</i> copy the shared_ptr, but you want to avoid touching the reference count for the (frequent) case where it doesn&#x27;t. This is an edge case, though, and personally I almost never do it.</div><br/></div></div><div id="40911606" class="c"><input type="checkbox" id="c-40911606" checked=""/><div class="controls bullet"><span class="by">worstspotgain</span><span>|</span><a href="#40909602">root</a><span>|</span><a href="#40911423">parent</a><span>|</span><a href="#40913767">prev</a><span>|</span><a href="#40911486">next</a><span>|</span><label class="collapse" for="c-40911606">[-]</label><label class="expand" for="c-40911606">[8 more]</label></div><br/><div class="children"><div class="content">foo(const bar&amp;) is ideal if you precisely wish to <i>bar</i> ownership. If (and in many kinds of projects, invariably it&#x27;s more like when) you later decide to share ownership, or if nullptr is an option, then it&#x27;s no good.<p>foo(std::shared_ptr&lt;bar&gt;) is copy-constructed as part of your function call (bumping the refcount) unless copy elision is both available and allowed. It&#x27;s only ideal if you almost always pass newly instantiated objects.<p>Pass by const reference is the sweet spot. If you absolutely must minimize the refcount bumps, overload by const reference and by rvalue.<p>As for shared_ptrs being very rare, uh, no. We use them by the truckload. To each their own!</div><br/><div id="40911929" class="c"><input type="checkbox" id="c-40911929" checked=""/><div class="controls bullet"><span class="by">CyberDildonics</span><span>|</span><a href="#40909602">root</a><span>|</span><a href="#40911606">parent</a><span>|</span><a href="#40911486">next</a><span>|</span><label class="collapse" for="c-40911929">[-]</label><label class="expand" for="c-40911929">[7 more]</label></div><br/><div class="children"><div class="content"><i>foo(const bar&amp;) is ideal if you precisely wish to bar ownership.</i><p>What?<p><i>invariably it&#x27;s more like when) you later decide to share ownership,</i><p>shared_ptr shouldn&#x27;t even be necessary for keeping track of single threaded scope based ownership.<p><i>As for shared_ptrs being very rare, uh, no. We use them by the truckload. To each their own!</i><p>You might want to look into that, you shouldn&#x27;t need to count references in single threaded scope based ownership. If you need something to last longer, make it&#x27;s ownership higher scoped.<p>If something already works it works, but this is not necessary and is avoiding understanding the actual scope of variables.</div><br/><div id="40912005" class="c"><input type="checkbox" id="c-40912005" checked=""/><div class="controls bullet"><span class="by">worstspotgain</span><span>|</span><a href="#40909602">root</a><span>|</span><a href="#40911929">parent</a><span>|</span><a href="#40911486">next</a><span>|</span><label class="collapse" for="c-40912005">[-]</label><label class="expand" for="c-40912005">[6 more]</label></div><br/><div class="children"><div class="content">&gt; What?<p>The context you&#x27;re missing is in your post&#x27;s GP. That poster holds a std::shared_ptr&lt;bar&gt; (for whatever perfectly valid reason) and wishes to pass it to foo(). However, he declares it as foo(const bar &amp;) because the callee does not need to share in the ownership of the shared_ptr. That means it gets called as foo(*p.get()).<p>&gt; scope based ownership<p>That&#x27;s the incorrect assumption that you came to. Obviously if bar is only used for stack-based scope variables, no shared_ptr is needed.</div><br/><div id="40912225" class="c"><input type="checkbox" id="c-40912225" checked=""/><div class="controls bullet"><span class="by">CyberDildonics</span><span>|</span><a href="#40909602">root</a><span>|</span><a href="#40912005">parent</a><span>|</span><a href="#40911486">next</a><span>|</span><label class="collapse" for="c-40912225">[-]</label><label class="expand" for="c-40912225">[5 more]</label></div><br/><div class="children"><div class="content"><i>The context you&#x27;re missing is in your post&#x27;s GP.</i><p>I didn&#x27;t miss any of that, that exactly what I thought it meant. I just don&#x27;t know what you mean by <i>precisely wish to bar ownership</i><p><i>That&#x27;s the incorrect assumption that you came to.</i><p>Prove it. In a single threaded program with scope based ownership, that shared_ptr is going to be freed somewhere, so why not just have it exist in that scope as a unique_ptr so the ownership scope is clear?<p><i>Obviously if bar is only used for stack-based scope variables, no shared_ptr is needed.</i><p>Are you saying I&#x27;m wrong then saying the exact thing I just said?</div><br/><div id="40912404" class="c"><input type="checkbox" id="c-40912404" checked=""/><div class="controls bullet"><span class="by">a_t48</span><span>|</span><a href="#40909602">root</a><span>|</span><a href="#40912225">parent</a><span>|</span><a href="#40912383">next</a><span>|</span><label class="collapse" for="c-40912404">[-]</label><label class="expand" for="c-40912404">[2 more]</label></div><br/><div class="children"><div class="content">Not sure if this is what GP was getting at, but in games a shared pointer (or similar custom resource handle) to something like a texture can be very useful - you want to share resources between objects in the scene so that you don&#x27;t load a thing from disk when it&#x27;s already in memory, but don&#x27;t want to hold onto it forever to save RAM.</div><br/><div id="40912529" class="c"><input type="checkbox" id="c-40912529" checked=""/><div class="controls bullet"><span class="by">CyberDildonics</span><span>|</span><a href="#40909602">root</a><span>|</span><a href="#40912404">parent</a><span>|</span><a href="#40912383">next</a><span>|</span><label class="collapse" for="c-40912529">[-]</label><label class="expand" for="c-40912529">[1 more]</label></div><br/><div class="children"><div class="content">Very true, and in between threads and in other areas too, but this isn&#x27;t scope based ownership, it&#x27;s completely separate from the scope hierarchy of the program.<p>Scope based ownership would be a unique_ptr that frees the heap memory when it goes out of scope (if it isn&#x27;t moved).</div><br/></div></div></div></div><div id="40912383" class="c"><input type="checkbox" id="c-40912383" checked=""/><div class="controls bullet"><span class="by">worstspotgain</span><span>|</span><a href="#40909602">root</a><span>|</span><a href="#40912225">parent</a><span>|</span><a href="#40912404">prev</a><span>|</span><a href="#40911486">next</a><span>|</span><label class="collapse" for="c-40912383">[-]</label><label class="expand" for="c-40912383">[2 more]</label></div><br/><div class="children"><div class="content">&gt; I just don&#x27;t know what you mean by precisely wish to bar ownership<p>If foo() doesn&#x27;t need to share ownership now but may need to later, declaring it as foo(const std::shared_ptr&lt;bar&gt; &amp;) instead of foo(const bar &amp;) allows this change without revising any prototypes. However, if we precisely wish to prohibit shared ownership by foo(), we can do so by declaring it as foo(const bar &amp;).<p>&gt; Prove it. In a single threaded program with scope based ownership<p>The incorrect assumption that you came to is that we were talking about stack variables. But anyways, here&#x27;s an example that&#x27;s both scope-based and single threaded:<p><pre><code>   std::vector&lt;std::shared_ptr&lt;bar&gt; &gt; v;
</code></pre>
with an algorithm that selectively adds our pointer to the vector one or more times, and another that duplicates and removes elements according to some ongoing criteria. The object gets deleted when no pointer instances are left in the vector.<p>In practice most code is multithreaded (not that it matters) and most shared_ptrs are held inside other objects (not that it makes a difference either.)<p>&gt; Are you saying I&#x27;m wrong then saying the exact thing I just said?<p>I&#x27;m saying you misunderstood and now I clarified again. I&#x27;m at the troll-detection threshold, so this is my last clarification. Take care!</div><br/><div id="40912562" class="c"><input type="checkbox" id="c-40912562" checked=""/><div class="controls bullet"><span class="by">CyberDildonics</span><span>|</span><a href="#40909602">root</a><span>|</span><a href="#40912383">parent</a><span>|</span><a href="#40911486">next</a><span>|</span><label class="collapse" for="c-40912562">[-]</label><label class="expand" for="c-40912562">[1 more]</label></div><br/><div class="children"><div class="content"><i>If foo() doesn&#x27;t need to share ownership now but may need to later,</i><p>This doesn&#x27;t make sense. Why would a function in a more narrow scope need to take or share ownership? The variable passed will persist before and after the function call.<p><i>The incorrect assumption that you came to is that we were talking about stack variables.</i><p>I don&#x27;t know what this means here. I said scope, you are saying stack. If lifetime is being dictated purely by scope, you don&#x27;t need shared_ptr, you can just use a unique_ptr at the correct scope.<p><i>But anyways, here&#x27;s an example that&#x27;s both scope-based and single threaded: std::vector&lt;std::shared_ptr&lt;bar&gt; &gt; v;</i><p>This isn&#x27;t scope based lifetime, this is lifetime based on some other criteria than going out of scope. I will show you with what you wrote:<p><i>and another that duplicates and removes elements according to some ongoing criteria.</i></div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="40911486" class="c"><input type="checkbox" id="c-40911486" checked=""/><div class="controls bullet"><span class="by">a_t48</span><span>|</span><a href="#40909602">root</a><span>|</span><a href="#40911423">parent</a><span>|</span><a href="#40911606">prev</a><span>|</span><a href="#40913298">next</a><span>|</span><label class="collapse" for="c-40911486">[-]</label><label class="expand" for="c-40911486">[4 more]</label></div><br/><div class="children"><div class="content">If you _maybe_ need to share ownership, the second is a little pessimistic - you always increase the ref count.</div><br/><div id="40912237" class="c"><input type="checkbox" id="c-40912237" checked=""/><div class="controls bullet"><span class="by">Maxatar</span><span>|</span><a href="#40909602">root</a><span>|</span><a href="#40911486">parent</a><span>|</span><a href="#40913298">next</a><span>|</span><label class="collapse" for="c-40912237">[-]</label><label class="expand" for="c-40912237">[3 more]</label></div><br/><div class="children"><div class="content">That is correct and I can see that being a justification for passing a const&amp;, in fact the C++ Core Guidelines agree with you that such a scenario is the only acceptable reason for passing a shared_ptr by const&amp;, although they encourage passing by value, or just passing a const T&amp;.</div><br/><div id="40912389" class="c"><input type="checkbox" id="c-40912389" checked=""/><div class="controls bullet"><span class="by">a_t48</span><span>|</span><a href="#40909602">root</a><span>|</span><a href="#40912237">parent</a><span>|</span><a href="#40913298">next</a><span>|</span><label class="collapse" for="c-40912389">[-]</label><label class="expand" for="c-40912389">[2 more]</label></div><br/><div class="children"><div class="content">Obviously the correct way is to accept a templated type and use perfect forwarding. &#x2F;s &#x2F;s &#x2F;s &#x2F;s &#x2F;s</div><br/><div id="40912488" class="c"><input type="checkbox" id="c-40912488" checked=""/><div class="controls bullet"><span class="by">worstspotgain</span><span>|</span><a href="#40909602">root</a><span>|</span><a href="#40912389">parent</a><span>|</span><a href="#40913298">next</a><span>|</span><label class="collapse" for="c-40912488">[-]</label><label class="expand" for="c-40912488">[1 more]</label></div><br/><div class="children"><div class="content">Bonus points for using static_cast&lt;T &amp;&amp;&gt;(p) instead of std::forward&lt;T&gt;(p) ;)</div><br/></div></div></div></div></div></div></div></div><div id="40913298" class="c"><input type="checkbox" id="c-40913298" checked=""/><div class="controls bullet"><span class="by">quotemstr</span><span>|</span><a href="#40909602">root</a><span>|</span><a href="#40911423">parent</a><span>|</span><a href="#40911486">prev</a><span>|</span><a href="#40911882">next</a><span>|</span><label class="collapse" for="c-40913298">[-]</label><label class="expand" for="c-40913298">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Why do we pass by value when sharing ownership? Because it allows for move semantics, so that you give the caller to option to make a copy, which bumps up the reference count, or to entirely avoid any copy whatsoever, which allows transfering ownership without bumping the reference count.<p>What if the callee sometimes wants to get a reference count and sometimes doesn&#x27;t? In the latter case, your proposed signature forces an unnecessary pair of atomic reference count operations. But if you use<p><pre><code>    foo(bar const&amp;)
</code></pre>
instead, then foo can&#x27;t acquire a reference even when it wants to.<p>You could stick std::enable_shared_from_this` under `bar`. But `std::enable_shared_from_this` adds a machine word of memory, so you might not want to do that.<p>If you pass<p><pre><code>    foo(shared_ptr&lt;bar&gt; const&amp;)
</code></pre>
you incur an extra pointer chase in the callee. Sure, you could write<p><pre><code>    foo(bar const&amp;, shared_ptr&lt;bar&gt; const&amp;)
</code></pre>
but then you burn an extra argument register. You can&#x27;t win, can you?<p>You can win actually. Just use <a href="https:&#x2F;&#x2F;www.boost.org&#x2F;doc&#x2F;libs&#x2F;1_85_0&#x2F;libs&#x2F;smart_ptr&#x2F;doc&#x2F;html&#x2F;smart_ptr.html#intrusive_ptr" rel="nofollow">https:&#x2F;&#x2F;www.boost.org&#x2F;doc&#x2F;libs&#x2F;1_85_0&#x2F;libs&#x2F;smart_ptr&#x2F;doc&#x2F;htm...</a> or your favorite intrusive reference-counted smart pointer, not `std::shared_ptr`. If you do, you get the same capabilities that `std::enable_shared_from_this` grants but without any of the downsides.</div><br/></div></div></div></div></div></div><div id="40911882" class="c"><input type="checkbox" id="c-40911882" checked=""/><div class="controls bullet"><span class="by">fooker</span><span>|</span><a href="#40909602">root</a><span>|</span><a href="#40911181">parent</a><span>|</span><a href="#40911337">prev</a><span>|</span><a href="#40912632">next</a><span>|</span><label class="collapse" for="c-40911882">[-]</label><label class="expand" for="c-40911882">[1 more]</label></div><br/><div class="children"><div class="content">Reference counting definitely slows down tight loops if you are not careful.<p>The way to avoid that in low latency code is to break the abstraction and operate with the raw pointer in the few areas where this could be a bottleneck.<p>It is usually not a bottleneck if your code is decently exploiting ipc, an extra addition or subtraction easily gets executed while some other operation is waiting a cycle for some cpu resource.</div><br/></div></div><div id="40912632" class="c"><input type="checkbox" id="c-40912632" checked=""/><div class="controls bullet"><span class="by">shaklee3</span><span>|</span><a href="#40909602">root</a><span>|</span><a href="#40911181">parent</a><span>|</span><a href="#40911882">prev</a><span>|</span><a href="#40911548">next</a><span>|</span><label class="collapse" for="c-40912632">[-]</label><label class="expand" for="c-40912632">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s not true. It does slow things down because it has an atomic access. How slow depends on the platform.<p>unique_ptr does not slow things down.</div><br/></div></div></div></div></div></div><div id="40911548" class="c"><input type="checkbox" id="c-40911548" checked=""/><div class="controls bullet"><span class="by">pclmulqdq</span><span>|</span><a href="#40909602">parent</a><span>|</span><a href="#40910861">prev</a><span>|</span><a href="#40910572">next</a><span>|</span><label class="collapse" for="c-40911548">[-]</label><label class="expand" for="c-40911548">[1 more]</label></div><br/><div class="children"><div class="content">The LMAX disruptor is a great data structure when you have threads bound to cores and most&#x2F;all of them are uncontended. It has some terrible pathologies at the tails if you aren&#x27;t using this pattern. Threads getting descheduled at bad times can really hurt.<p>SPSC ring buffers are going to be hard to beat for the system you are thinking of, and you can likely also implement work stealing using good old locks if you need it.</div><br/></div></div><div id="40910572" class="c"><input type="checkbox" id="c-40910572" checked=""/><div class="controls bullet"><span class="by">temporarely</span><span>|</span><a href="#40909602">parent</a><span>|</span><a href="#40911548">prev</a><span>|</span><a href="#40910520">next</a><span>|</span><label class="collapse" for="c-40910572">[-]</label><label class="expand" for="c-40910572">[13 more]</label></div><br/><div class="children"><div class="content">fun fact: the original LMAX was designed for and written in Java.<p><a href="https:&#x2F;&#x2F;martinfowler.com&#x2F;articles&#x2F;lmax.html" rel="nofollow">https:&#x2F;&#x2F;martinfowler.com&#x2F;articles&#x2F;lmax.html</a></div><br/><div id="40910619" class="c"><input type="checkbox" id="c-40910619" checked=""/><div class="controls bullet"><span class="by">sneilan1</span><span>|</span><a href="#40909602">root</a><span>|</span><a href="#40910572">parent</a><span>|</span><a href="#40910520">next</a><span>|</span><label class="collapse" for="c-40910619">[-]</label><label class="expand" for="c-40910619">[12 more]</label></div><br/><div class="children"><div class="content">I think it made sense at the time. From what I understand, you can make Java run as fast as C++ if you&#x27;re careful with it and use JIT. However, I have never tried such a thing and my source is hearsay from friends who have worked in financial institutions. Then you get added benefit of the Java ecosystem.</div><br/><div id="40910691" class="c"><input type="checkbox" id="c-40910691" checked=""/><div class="controls bullet"><span class="by">nine_k</span><span>|</span><a href="#40909602">root</a><span>|</span><a href="#40910619">parent</a><span>|</span><a href="#40911546">next</a><span>|</span><label class="collapse" for="c-40910691">[-]</label><label class="expand" for="c-40910691">[6 more]</label></div><br/><div class="children"><div class="content">From my hearsay, you absolutely can, given two things: fewer pointer-chasing data structures, and, most crucially, fewer or no allocations. Pre-allocate arrays of things you need, run ring buffers on them if you have to use a varying number of things.<p>A fun but practical approach which I again heard (second-hand) to be used, is just drowning your code in physical RAM, and switch the GC completely off. Have enough RAM to run a trading day, then reboot. The cost is trivial, compared to spending engineering hours on different approaches.</div><br/><div id="40912847" class="c"><input type="checkbox" id="c-40912847" checked=""/><div class="controls bullet"><span class="by">bostik</span><span>|</span><a href="#40909602">root</a><span>|</span><a href="#40910691">parent</a><span>|</span><a href="#40911327">next</a><span>|</span><label class="collapse" for="c-40912847">[-]</label><label class="expand" for="c-40912847">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>fewer or no allocations</i><p>Quite fitting in a thread about HFT that has already referenced game development as a parallel universe of similar techniques.<p>In the feature phone era, mobile phone games were written in Java (well, a subset: Java EE). Practically <i>all</i> games followed the same memory management strategy. They allocated the memory they needed during the early initialisation, and then never again during the actual runtime of the game. That was the only way to retain even a semblance of performance.</div><br/></div></div><div id="40911327" class="c"><input type="checkbox" id="c-40911327" checked=""/><div class="controls bullet"><span class="by">ramchip</span><span>|</span><a href="#40909602">root</a><span>|</span><a href="#40910691">parent</a><span>|</span><a href="#40912847">prev</a><span>|</span><a href="#40911201">next</a><span>|</span><label class="collapse" for="c-40911327">[-]</label><label class="expand" for="c-40911327">[3 more]</label></div><br/><div class="children"><div class="content">I worked in trading and we did the first one, in C++. We&#x27;d load all the instruments (stocks etc.) on startup to preallocate the &quot;universe&quot;, and use ring buffers as queues. Instruments don&#x27;t change during trading hours so restarting daily to pick up the new data is enough.<p>I saw a Java team do the second one in an order router (a system that connects to various exchanges and routes+translates orders for each exchange&#x27;s requirements), and they wrote an interesting retrospective doc where they basically said it wasn&#x27;t worth it - it caused a lot of trouble without giving a significant edge in performance. YMMV! That was around 2012.</div><br/><div id="40911562" class="c"><input type="checkbox" id="c-40911562" checked=""/><div class="controls bullet"><span class="by">bb88</span><span>|</span><a href="#40909602">root</a><span>|</span><a href="#40911327">parent</a><span>|</span><a href="#40911201">next</a><span>|</span><label class="collapse" for="c-40911562">[-]</label><label class="expand" for="c-40911562">[2 more]</label></div><br/><div class="children"><div class="content">I honestly don&#x27;t know why the real time trading devs don&#x27;t make their own OS&#x2F;programming language for this.  It&#x27;s not like they don&#x27;t have the money.</div><br/><div id="40913126" class="c"><input type="checkbox" id="c-40913126" checked=""/><div class="controls bullet"><span class="by">nine_k</span><span>|</span><a href="#40909602">root</a><span>|</span><a href="#40911562">parent</a><span>|</span><a href="#40911201">next</a><span>|</span><label class="collapse" for="c-40913126">[-]</label><label class="expand" for="c-40913126">[1 more]</label></div><br/><div class="children"><div class="content">Making your own OS or language is <i>hard</i>, if you care about both performance and correctness.<p>But HFT people do a lot of OS-level hacking, squeezing the last bits of performance from the kernel where the kernel is needed, and&#x2F;or running parts of the kernel stack (like networking) in userspace, avoiding context switches. CPU core pinning, offloading of everything possible to the network cards, etc, goes without saying.</div><br/></div></div></div></div></div></div><div id="40911201" class="c"><input type="checkbox" id="c-40911201" checked=""/><div class="controls bullet"><span class="by">sneilan1</span><span>|</span><a href="#40909602">root</a><span>|</span><a href="#40910691">parent</a><span>|</span><a href="#40911327">prev</a><span>|</span><a href="#40911546">next</a><span>|</span><label class="collapse" for="c-40911201">[-]</label><label class="expand" for="c-40911201">[1 more]</label></div><br/><div class="children"><div class="content">So literally remove as much allocation as possible and then reboot each day. That makes a lot of sense to me!</div><br/></div></div></div></div><div id="40911546" class="c"><input type="checkbox" id="c-40911546" checked=""/><div class="controls bullet"><span class="by">bb88</span><span>|</span><a href="#40909602">root</a><span>|</span><a href="#40910619">parent</a><span>|</span><a href="#40910691">prev</a><span>|</span><a href="#40910520">next</a><span>|</span><label class="collapse" for="c-40911546">[-]</label><label class="expand" for="c-40911546">[5 more]</label></div><br/><div class="children"><div class="content">All the java libs that you use can never do an allocation -- ever!.  So you don&#x27;t really get that much benefit to the java ecosystem (other than IDE&#x27;s).  You have to audit the code you use to make sure allocations never happen during the critical path.<p>Fifteen years ago, the USN&#x27;s DDX software program learned this the hard way when they needed a hard real time requirement in the milliseconds.</div><br/><div id="40911692" class="c"><input type="checkbox" id="c-40911692" checked=""/><div class="controls bullet"><span class="by">throwaway2037</span><span>|</span><a href="#40909602">root</a><span>|</span><a href="#40911546">parent</a><span>|</span><a href="#40910520">next</a><span>|</span><label class="collapse" for="c-40911692">[-]</label><label class="expand" for="c-40911692">[4 more]</label></div><br/><div class="children"><div class="content">In my experience: Allocation is OK, but garbage collection is bad.</div><br/><div id="40912012" class="c"><input type="checkbox" id="c-40912012" checked=""/><div class="controls bullet"><span class="by">bb88</span><span>|</span><a href="#40909602">root</a><span>|</span><a href="#40911692">parent</a><span>|</span><a href="#40910520">next</a><span>|</span><label class="collapse" for="c-40912012">[-]</label><label class="expand" for="c-40912012">[3 more]</label></div><br/><div class="children"><div class="content">I think back then GC defaulted running potentially at allocation.<p>shared_ptr is a much better solution for garbage collection.  One I wish that java had implemented.</div><br/><div id="40913686" class="c"><input type="checkbox" id="c-40913686" checked=""/><div class="controls bullet"><span class="by">throwaway2037</span><span>|</span><a href="#40909602">root</a><span>|</span><a href="#40912012">parent</a><span>|</span><a href="#40912793">next</a><span>|</span><label class="collapse" for="c-40913686">[-]</label><label class="expand" for="c-40913686">[1 more]</label></div><br/><div class="children"><div class="content"><p><pre><code>    &gt; shared_ptr is a much better solution for garbage collection. One I wish that java had implemented.
</code></pre>
I&#x27;m pretty sure there is a large body of (computer science) research work around the topic of deterministic (reference-counted) vs non-deterministic (non-reference counted) garbage collection.  There are lots of pros and cons for both sides.  Also, I find it interesting that Java, C#, and GoLang all chose non-deterministic GC, but Perl and Python use deterministic GC.  (I&#x27;m not sure what Ruby does.)</div><br/></div></div><div id="40912793" class="c"><input type="checkbox" id="c-40912793" checked=""/><div class="controls bullet"><span class="by">josefx</span><span>|</span><a href="#40909602">root</a><span>|</span><a href="#40912012">parent</a><span>|</span><a href="#40913686">prev</a><span>|</span><a href="#40910520">next</a><span>|</span><label class="collapse" for="c-40912793">[-]</label><label class="expand" for="c-40912793">[1 more]</label></div><br/><div class="children"><div class="content">I think CPython does reference counting for its memory management, it still has to run a GC since reference counting does not handle reference cycles.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="40910520" class="c"><input type="checkbox" id="c-40910520" checked=""/><div class="controls bullet"><span class="by">fooker</span><span>|</span><a href="#40909602">parent</a><span>|</span><a href="#40910572">prev</a><span>|</span><a href="#40913454">next</a><span>|</span><label class="collapse" for="c-40910520">[-]</label><label class="expand" for="c-40910520">[7 more]</label></div><br/><div class="children"><div class="content">You say it&#x27;s easier in Rust, but you still have a complete C++ implementation and not a Rust one. :)</div><br/><div id="40910577" class="c"><input type="checkbox" id="c-40910577" checked=""/><div class="controls bullet"><span class="by">sneilan1</span><span>|</span><a href="#40909602">root</a><span>|</span><a href="#40910520">parent</a><span>|</span><a href="#40910556">next</a><span>|</span><label class="collapse" for="c-40910577">[-]</label><label class="expand" for="c-40910577">[5 more]</label></div><br/><div class="children"><div class="content">It took me about a year to build all of this stuff in C++. So I imagine since I&#x27;ve had to learn rust, it will probably take me the same amount of time if I can save time with dependencies.</div><br/><div id="40910814" class="c"><input type="checkbox" id="c-40910814" checked=""/><div class="controls bullet"><span class="by">fooker</span><span>|</span><a href="#40909602">root</a><span>|</span><a href="#40910577">parent</a><span>|</span><a href="#40910556">next</a><span>|</span><label class="collapse" for="c-40910814">[-]</label><label class="expand" for="c-40910814">[4 more]</label></div><br/><div class="children"><div class="content">In my experience, once you know the problem really well, yes you&#x27;re right.<p>If you are building a complex prototype from scratch, you&#x27;ll usually spend more time fighting the Rust compiler than trying out alternate design decisions.</div><br/><div id="40911193" class="c"><input type="checkbox" id="c-40911193" checked=""/><div class="controls bullet"><span class="by">sneilan1</span><span>|</span><a href="#40909602">root</a><span>|</span><a href="#40910814">parent</a><span>|</span><a href="#40910556">next</a><span>|</span><label class="collapse" for="c-40911193">[-]</label><label class="expand" for="c-40911193">[3 more]</label></div><br/><div class="children"><div class="content">I do know the problem domain well. My second iteration in rust already almost has an order book implemented.<p>Writing code in rust however is very fun! (At least so far lol)</div><br/><div id="40911565" class="c"><input type="checkbox" id="c-40911565" checked=""/><div class="controls bullet"><span class="by">bb88</span><span>|</span><a href="#40909602">root</a><span>|</span><a href="#40911193">parent</a><span>|</span><a href="#40911817">next</a><span>|</span><label class="collapse" for="c-40911565">[-]</label><label class="expand" for="c-40911565">[1 more]</label></div><br/><div class="children"><div class="content">Better than C++?  Have you experienced any problems in Rust that C++ instantly solved?  Not because I&#x27;m pro&#x2F;anti rust&#x2F;C++ here, just curious.</div><br/></div></div><div id="40911817" class="c"><input type="checkbox" id="c-40911817" checked=""/><div class="controls bullet"><span class="by">fooker</span><span>|</span><a href="#40909602">root</a><span>|</span><a href="#40911193">parent</a><span>|</span><a href="#40911565">prev</a><span>|</span><a href="#40910556">next</a><span>|</span><label class="collapse" for="c-40911817">[-]</label><label class="expand" for="c-40911817">[1 more]</label></div><br/><div class="children"><div class="content">Writing Rust is fun in the sense that solving a puzzle is fun.<p>Great when that&#x27;s what you set out to do (rewrite it in Rust^TM) can get annoying otherwise (solving&#x2F;researching a problem).</div><br/></div></div></div></div></div></div></div></div><div id="40910556" class="c"><input type="checkbox" id="c-40910556" checked=""/><div class="controls bullet"><span class="by">deepsun</span><span>|</span><a href="#40909602">root</a><span>|</span><a href="#40910520">parent</a><span>|</span><a href="#40910577">prev</a><span>|</span><a href="#40913454">next</a><span>|</span><label class="collapse" for="c-40910556">[-]</label><label class="expand" for="c-40910556">[1 more]</label></div><br/><div class="children"><div class="content">Linus said he wouldn&#x27;t start Linux if Unix was ready at that time.</div><br/></div></div></div></div></div></div><div id="40913454" class="c"><input type="checkbox" id="c-40913454" checked=""/><div class="controls bullet"><span class="by">winternewt</span><span>|</span><a href="#40909602">prev</a><span>|</span><a href="#40910101">next</a><span>|</span><label class="collapse" for="c-40913454">[-]</label><label class="expand" for="c-40913454">[1 more]</label></div><br/><div class="children"><div class="content">I made a C++ logging library [1] that has many similarities to the LMAX disruptor. It appears to have found some use among the HFT community.<p>The original intent was to enable highly detailed logging without performance degradation for &quot;post-mortem&quot; debugging in production environments. I had coworkers who would refuse to include logging of certain important information for troubleshooting, because they were scared that it would impact performance. This put an end to that argument.<p>[1] <a href="https:&#x2F;&#x2F;github.com&#x2F;mattiasflodin&#x2F;reckless">https:&#x2F;&#x2F;github.com&#x2F;mattiasflodin&#x2F;reckless</a></div><br/></div></div><div id="40910101" class="c"><input type="checkbox" id="c-40910101" checked=""/><div class="controls bullet"><span class="by">munificent</span><span>|</span><a href="#40913454">prev</a><span>|</span><a href="#40909567">next</a><span>|</span><label class="collapse" for="c-40910101">[-]</label><label class="expand" for="c-40910101">[7 more]</label></div><br/><div class="children"><div class="content"><i>&gt; The noted efficiency in compile-time dispatch is due to decisions about function calls being made during
the compilation phase. By bypassing the decision-making overhead present in runtime dispatch, programs
can execute more swiftly, thus boosting performance.</i><p>The other benefit with compile-time dispatch is that when the compiler can statically determine which function is being called, it may be able to inline the called function&#x27;s code directly at the callsite. That eliminates <i>all</i> of the function call overhead and may also enable further optimizations (dead code elimination, constant propagation, etc.).</div><br/><div id="40911982" class="c"><input type="checkbox" id="c-40911982" checked=""/><div class="controls bullet"><span class="by">foobazgt</span><span>|</span><a href="#40910101">parent</a><span>|</span><a href="#40910449">next</a><span>|</span><label class="collapse" for="c-40911982">[-]</label><label class="expand" for="c-40911982">[1 more]</label></div><br/><div class="children"><div class="content">&gt; That eliminates all of the function call overhead and may also enable further optimizations (dead code elimination, constant propagation, etc.).<p>AFAIK, the speedup is almost never function call overhead. As you mention at the tail end, it&#x27;s all about the compiler optimizations being able to see past the dynamic branch. Good JITs support polymorphic inlining. My (somewhat dated) experience for C++ is that PGO is the solve for this, but it&#x27;s not widely used. Instead people tend to avoid dynamic dispatch altogether in performance sensitive code.<p>I think the more general moral of the story is to avoid all kinds of unnecessary dynamic branching in hot sections of code in any language unless you have strong&#x2F;confidence your compiler&#x2F;JIT is seeing through it.</div><br/></div></div><div id="40910449" class="c"><input type="checkbox" id="c-40910449" checked=""/><div class="controls bullet"><span class="by">binary132</span><span>|</span><a href="#40910101">parent</a><span>|</span><a href="#40911982">prev</a><span>|</span><a href="#40910204">next</a><span>|</span><label class="collapse" for="c-40910449">[-]</label><label class="expand" for="c-40910449">[1 more]</label></div><br/><div class="children"><div class="content">The real performance depends on the runtime behavior of the machine as well as compiler optimizations.  I thought this talk was very interesting on this subject.<p><a href="https:&#x2F;&#x2F;youtu.be&#x2F;i5MAXAxp_Tw" rel="nofollow">https:&#x2F;&#x2F;youtu.be&#x2F;i5MAXAxp_Tw</a></div><br/></div></div><div id="40910204" class="c"><input type="checkbox" id="c-40910204" checked=""/><div class="controls bullet"><span class="by">xxpor</span><span>|</span><a href="#40910101">parent</a><span>|</span><a href="#40910449">prev</a><span>|</span><a href="#40909567">next</a><span>|</span><label class="collapse" for="c-40910204">[-]</label><label class="expand" for="c-40910204">[4 more]</label></div><br/><div class="children"><div class="content">OTOH, it might be a net negative in latency if you&#x27;re icache limited. Depends on the access pattern among other things, of course.</div><br/><div id="40910240" class="c"><input type="checkbox" id="c-40910240" checked=""/><div class="controls bullet"><span class="by">munificent</span><span>|</span><a href="#40910101">root</a><span>|</span><a href="#40910204">parent</a><span>|</span><a href="#40909567">next</a><span>|</span><label class="collapse" for="c-40910240">[-]</label><label class="expand" for="c-40910240">[3 more]</label></div><br/><div class="children"><div class="content">Yup, you always have to measure.<p>Though my impression is that compilers tend to be fairly conservative about inlining so that don&#x27;t risk the inlining being a pessimization.</div><br/><div id="40912023" class="c"><input type="checkbox" id="c-40912023" checked=""/><div class="controls bullet"><span class="by">foobazgt</span><span>|</span><a href="#40910101">root</a><span>|</span><a href="#40910240">parent</a><span>|</span><a href="#40911802">next</a><span>|</span><label class="collapse" for="c-40912023">[-]</label><label class="expand" for="c-40912023">[1 more]</label></div><br/><div class="children"><div class="content">My experience has been that it&#x27;s rather heuristic based. It&#x27;s a clear win when you can immediately see far enough in advance to know that it&#x27;ll also decrease the amount of generated code. You can spot trivial cases where this is true at the point of inlining. However, if you stopped there, you&#x27;d leave a ton of optimizations on the table. Further optimization (e.g. DCE) will often drastically reduce code size from the inlining, but it&#x27;s hard to predict in relationship to a specific inlining decision.<p>So, statistics and heuristics.</div><br/></div></div><div id="40911802" class="c"><input type="checkbox" id="c-40911802" checked=""/><div class="controls bullet"><span class="by">rasalas</span><span>|</span><a href="#40910101">root</a><span>|</span><a href="#40910240">parent</a><span>|</span><a href="#40912023">prev</a><span>|</span><a href="#40909567">next</a><span>|</span><label class="collapse" for="c-40911802">[-]</label><label class="expand" for="c-40911802">[1 more]</label></div><br/><div class="children"><div class="content">In my experience it&#x27;s the &quot;force inline&quot; directives that can make this terrible.<p>I had a coworker who loved &quot;force inline&quot;. A symptom was stupidly long codegen times on MSVC.</div><br/></div></div></div></div></div></div></div></div><div id="40909567" class="c"><input type="checkbox" id="c-40909567" checked=""/><div class="controls bullet"><span class="by">jeffreygoesto</span><span>|</span><a href="#40910101">prev</a><span>|</span><a href="#40910331">next</a><span>|</span><label class="collapse" for="c-40909567">[-]</label><label class="expand" for="c-40909567">[7 more]</label></div><br/><div class="children"><div class="content">Reminds me of <a href="https:&#x2F;&#x2F;github.com&#x2F;CppCon&#x2F;CppCon2017&#x2F;blob&#x2F;master&#x2F;Presentations&#x2F;When%20a%20Microsecond%20Is%20an%20Eternity&#x2F;When%20a%20Microsecond%20Is%20an%20Eternity%20-%20Carl%20Cook%20-%20CppCon%202017.pdf">https:&#x2F;&#x2F;github.com&#x2F;CppCon&#x2F;CppCon2017&#x2F;blob&#x2F;master&#x2F;Presentatio...</a></div><br/><div id="40910251" class="c"><input type="checkbox" id="c-40910251" checked=""/><div class="controls bullet"><span class="by">munificent</span><span>|</span><a href="#40909567">parent</a><span>|</span><a href="#40910331">next</a><span>|</span><label class="collapse" for="c-40910251">[-]</label><label class="expand" for="c-40910251">[6 more]</label></div><br/><div class="children"><div class="content">This is an excellent slideshow.<p>The slide on measuring by having a fake server replaying order data, a second server calculating runtimes, the server under test, and a hardware switch to let you measure packet times is so delightfully hardcore.<p>I don&#x27;t have any interest in working in finance, but it must be fun working on something so performance critical that buying a rack of hardware just for benchmarking is economically feasible.</div><br/><div id="40910720" class="c"><input type="checkbox" id="c-40910720" checked=""/><div class="controls bullet"><span class="by">nine_k</span><span>|</span><a href="#40909567">root</a><span>|</span><a href="#40910251">parent</a><span>|</span><a href="#40910727">next</a><span>|</span><label class="collapse" for="c-40910720">[-]</label><label class="expand" for="c-40910720">[4 more]</label></div><br/><div class="children"><div class="content">Delightfully hardcore indeed!<p>But of course you don&#x27;t have to buy a rack of servers for testing, you can rent it. Servers are a quickly depreciating asset, why invest in them?</div><br/><div id="40910732" class="c"><input type="checkbox" id="c-40910732" checked=""/><div class="controls bullet"><span class="by">a_t48</span><span>|</span><a href="#40909567">root</a><span>|</span><a href="#40910720">parent</a><span>|</span><a href="#40910985">next</a><span>|</span><label class="collapse" for="c-40910732">[-]</label><label class="expand" for="c-40910732">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;d want it to be the exact same hardware as in production, for one.</div><br/></div></div><div id="40910985" class="c"><input type="checkbox" id="c-40910985" checked=""/><div class="controls bullet"><span class="by">CyberDildonics</span><span>|</span><a href="#40909567">root</a><span>|</span><a href="#40910720">parent</a><span>|</span><a href="#40910732">prev</a><span>|</span><a href="#40910727">next</a><span>|</span><label class="collapse" for="c-40910985">[-]</label><label class="expand" for="c-40910985">[2 more]</label></div><br/><div class="children"><div class="content">Why would replaying data for testing be &quot;Delightfully hardcore indeed!&quot;.  That&#x27;s how people program in general, they run the same data through their program.<p><i>Servers are a quickly depreciating asset, why invest in them?</i><p>I don&#x27;t think they are a quickly depreciating asset compared to the price of renting, but you would want total control over them in this scenario anyway.</div><br/><div id="40911135" class="c"><input type="checkbox" id="c-40911135" checked=""/><div class="controls bullet"><span class="by">nine_k</span><span>|</span><a href="#40909567">root</a><span>|</span><a href="#40910985">parent</a><span>|</span><a href="#40910727">next</a><span>|</span><label class="collapse" for="c-40911135">[-]</label><label class="expand" for="c-40911135">[1 more]</label></div><br/><div class="children"><div class="content">I thought that the hardcore part is taking the data from the switch to account for the network latency.</div><br/></div></div></div></div></div></div><div id="40910727" class="c"><input type="checkbox" id="c-40910727" checked=""/><div class="controls bullet"><span class="by">a_t48</span><span>|</span><a href="#40909567">root</a><span>|</span><a href="#40910251">parent</a><span>|</span><a href="#40910720">prev</a><span>|</span><a href="#40910331">next</a><span>|</span><label class="collapse" for="c-40910727">[-]</label><label class="expand" for="c-40910727">[1 more]</label></div><br/><div class="children"><div class="content">The self driving space does this :)</div><br/></div></div></div></div></div></div><div id="40910331" class="c"><input type="checkbox" id="c-40910331" checked=""/><div class="controls bullet"><span class="by">astromaniak</span><span>|</span><a href="#40909567">prev</a><span>|</span><a href="#40909944">next</a><span>|</span><label class="collapse" for="c-40910331">[-]</label><label class="expand" for="c-40910331">[1 more]</label></div><br/><div class="children"><div class="content">Just in case you are a pro developer, the whole thing is worth looking at:<p><a href="https:&#x2F;&#x2F;github.com&#x2F;CppCon&#x2F;CppCon2017&#x2F;tree&#x2F;master&#x2F;Presentations">https:&#x2F;&#x2F;github.com&#x2F;CppCon&#x2F;CppCon2017&#x2F;tree&#x2F;master&#x2F;Presentatio...</a><p>and up</div><br/></div></div><div id="40909944" class="c"><input type="checkbox" id="c-40909944" checked=""/><div class="controls bullet"><span class="by">globular-toast</span><span>|</span><a href="#40910331">prev</a><span>|</span><a href="#40909882">next</a><span>|</span><label class="collapse" for="c-40909944">[-]</label><label class="expand" for="c-40909944">[54 more]</label></div><br/><div class="children"><div class="content">Is there any good reason for high-frequency trading to exist? People often complain about bitcoin wasting energy, but oddly this gets a free pass despite this being a definite net negative to society as far as I can tell.</div><br/><div id="40910275" class="c"><input type="checkbox" id="c-40910275" checked=""/><div class="controls bullet"><span class="by">jeffreyrogers</span><span>|</span><a href="#40909944">parent</a><span>|</span><a href="#40911582">next</a><span>|</span><label class="collapse" for="c-40910275">[-]</label><label class="expand" for="c-40910275">[7 more]</label></div><br/><div class="children"><div class="content">Bid&#x2F;ask spreads are far narrower than they were previously. If you look at the profits of the HFT industry as a whole they aren&#x27;t that large (low billions) and their dollar volume is in the trillions. Hard to argue that the industry is wildly prosocial but making spreads narrower does mean less money goes to middlemen.</div><br/><div id="40911935" class="c"><input type="checkbox" id="c-40911935" checked=""/><div class="controls bullet"><span class="by">akira2501</span><span>|</span><a href="#40909944">root</a><span>|</span><a href="#40910275">parent</a><span>|</span><a href="#40910335">next</a><span>|</span><label class="collapse" for="c-40911935">[-]</label><label class="expand" for="c-40911935">[1 more]</label></div><br/><div class="children"><div class="content">&gt; but making spreads narrower does mean less money goes to middlemen.<p>On individual trades.  I would think you&#x27;d have to also argue that their high overall trading volume is somehow also a benefit to the broader market or at the very least that it does not outcompete the benefits of narrowing.</div><br/></div></div><div id="40910335" class="c"><input type="checkbox" id="c-40910335" checked=""/><div class="controls bullet"><span class="by">sesuximo</span><span>|</span><a href="#40909944">root</a><span>|</span><a href="#40910275">parent</a><span>|</span><a href="#40911935">prev</a><span>|</span><a href="#40911582">next</a><span>|</span><label class="collapse" for="c-40910335">[-]</label><label class="expand" for="c-40910335">[5 more]</label></div><br/><div class="children"><div class="content">Why do high spreads mean more money for middlemen?</div><br/><div id="40910366" class="c"><input type="checkbox" id="c-40910366" checked=""/><div class="controls bullet"><span class="by">Arnt</span><span>|</span><a href="#40909944">root</a><span>|</span><a href="#40910335">parent</a><span>|</span><a href="#40911582">next</a><span>|</span><label class="collapse" for="c-40910366">[-]</label><label class="expand" for="c-40910366">[4 more]</label></div><br/><div class="children"><div class="content">When you buy stock, you generally by it from a &quot;market maker&quot;, which is a middleman. When you sell, you sell to a market maker. Their business is to let you buy and sell when you want instead of waiting for a buyer&#x2F;seller to show up. The spread is their profit source.</div><br/><div id="40910390" class="c"><input type="checkbox" id="c-40910390" checked=""/><div class="controls bullet"><span class="by">sesuximo</span><span>|</span><a href="#40909944">root</a><span>|</span><a href="#40910366">parent</a><span>|</span><a href="#40911582">next</a><span>|</span><label class="collapse" for="c-40910390">[-]</label><label class="expand" for="c-40910390">[3 more]</label></div><br/><div class="children"><div class="content">Wouldn’t the price movement overwhelm the spread if you sell more than a few days after you buy?  I guess if spreads were huge it would matter more</div><br/><div id="40910416" class="c"><input type="checkbox" id="c-40910416" checked=""/><div class="controls bullet"><span class="by">Arnt</span><span>|</span><a href="#40909944">root</a><span>|</span><a href="#40910390">parent</a><span>|</span><a href="#40911582">next</a><span>|</span><label class="collapse" for="c-40910416">[-]</label><label class="expand" for="c-40910416">[2 more]</label></div><br/><div class="children"><div class="content">The price movement does indeed overwhelm the spread. Half the time it goes up, half the time down.</div><br/><div id="40911472" class="c"><input type="checkbox" id="c-40911472" checked=""/><div class="controls bullet"><span class="by">Maxatar</span><span>|</span><a href="#40909944">root</a><span>|</span><a href="#40910416">parent</a><span>|</span><a href="#40911582">next</a><span>|</span><label class="collapse" for="c-40911472">[-]</label><label class="expand" for="c-40911472">[1 more]</label></div><br/><div class="children"><div class="content">&gt;Half the time it goes up, half the time down.<p>This is not true and in fact when I hire quants or developers, I have to spend a surprising amount of time even teaching people with PhD&#x27;s in statistics that the random nature of the stock market does not mean that it&#x27;s a coin toss. It&#x27;s surprising the number of people who should know better think trading is just about being right 51% of the time, or that typically stocks have a 50&#x2F;50 chance of going up or down at any given moment...<p>What&#x27;s closer to the truth is that stocks are actually quite predictable the overwhelming majority of the time, but a single mistake can end up costing you dearly. You can be right 95% of the time, and then lose everything you ever made in the remaining 5% of the time. A stock might go up 10 times in a row, and then on the 11th trial, it wipes out everything it made and then some.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="40911582" class="c"><input type="checkbox" id="c-40911582" checked=""/><div class="controls bullet"><span class="by">TheAlchemist</span><span>|</span><a href="#40909944">parent</a><span>|</span><a href="#40910275">prev</a><span>|</span><a href="#40909995">next</a><span>|</span><label class="collapse" for="c-40911582">[-]</label><label class="expand" for="c-40911582">[1 more]</label></div><br/><div class="children"><div class="content">Because it&#x27;s not explicitly forbidden ?<p>I would argue that HFT is a rather small space, albeit pretty concentrated. It&#x27;s several orders of magnitude smaller in terms of energy wasting than Bitcoin.<p>The only positive from HFT is liquidity and tighter spreads, but it also depends what people put into HFT definition. For example, Robinhood and free trading, probably wouldn&#x27;t exist without it.<p>They are taking a part of the cake that previously went to brokers and banks. HFT is not in a business of screwing &#x27;the little guy&#x27;.<p>From my perspective there is little to none negative to the society. If somebody is investing long term in the stock market, he couldn&#x27;t care less about HFT.</div><br/></div></div><div id="40909995" class="c"><input type="checkbox" id="c-40909995" checked=""/><div class="controls bullet"><span class="by">FredPret</span><span>|</span><a href="#40909944">parent</a><span>|</span><a href="#40911582">prev</a><span>|</span><a href="#40910146">next</a><span>|</span><label class="collapse" for="c-40909995">[-]</label><label class="expand" for="c-40909995">[18 more]</label></div><br/><div class="children"><div class="content">Non-bitcoin transactions are just a couple of entries in various databases. Mining bitcoin is intense number crunching.<p>HFT makes the financial markets a tiny bit more accurate by resolving inconsistencies (for example three pairs of currencies can get out of whack with one another) and obvious mispricings (for various definitions of &quot;obvious&quot;)</div><br/><div id="40910270" class="c"><input type="checkbox" id="c-40910270" checked=""/><div class="controls bullet"><span class="by">jeffbee</span><span>|</span><a href="#40909944">root</a><span>|</span><a href="#40909995">parent</a><span>|</span><a href="#40910146">next</a><span>|</span><label class="collapse" for="c-40910270">[-]</label><label class="expand" for="c-40910270">[17 more]</label></div><br/><div class="children"><div class="content">That&#x27;s a nice fairy tale that they probably tell their kids when asked, but what the profitable firms are doing at the cutting edge is inducing responses in the other guys&#x27; robots, in a phase that the antagonist controls, then trading against what they know is about to happen. It is literally market manipulation. A way to kill off this entire field of endeavor is to charge a tax on cancelled orders.</div><br/><div id="40910453" class="c"><input type="checkbox" id="c-40910453" checked=""/><div class="controls bullet"><span class="by">blakers95</span><span>|</span><a href="#40909944">root</a><span>|</span><a href="#40910270">parent</a><span>|</span><a href="#40910677">next</a><span>|</span><label class="collapse" for="c-40910453">[-]</label><label class="expand" for="c-40910453">[9 more]</label></div><br/><div class="children"><div class="content">Yep and what&#x27;s worse is many hft firms aren&#x27;t in the market-making business at all but actually REMOVE liquidity.</div><br/><div id="40910470" class="c"><input type="checkbox" id="c-40910470" checked=""/><div class="controls bullet"><span class="by">FredPret</span><span>|</span><a href="#40909944">root</a><span>|</span><a href="#40910453">parent</a><span>|</span><a href="#40911975">next</a><span>|</span><label class="collapse" for="c-40910470">[-]</label><label class="expand" for="c-40910470">[7 more]</label></div><br/><div class="children"><div class="content">What&#x27;s the mechanism for removing liquidity?</div><br/><div id="40911161" class="c"><input type="checkbox" id="c-40911161" checked=""/><div class="controls bullet"><span class="by">itchyouch</span><span>|</span><a href="#40909944">root</a><span>|</span><a href="#40910470">parent</a><span>|</span><a href="#40910483">next</a><span>|</span><label class="collapse" for="c-40911161">[-]</label><label class="expand" for="c-40911161">[2 more]</label></div><br/><div class="children"><div class="content">Adding liquidity means to place an order that sits on the book while removing liquidity means to execute against an order that&#x27;s already resting on the book.</div><br/></div></div><div id="40911598" class="c"><input type="checkbox" id="c-40911598" checked=""/><div class="controls bullet"><span class="by">cheonic730</span><span>|</span><a href="#40909944">root</a><span>|</span><a href="#40910470">parent</a><span>|</span><a href="#40910483">prev</a><span>|</span><a href="#40910908">next</a><span>|</span><label class="collapse" for="c-40911598">[-]</label><label class="expand" for="c-40911598">[2 more]</label></div><br/><div class="children"><div class="content">&gt; What&#x27;s the mechanism for removing liquidity?<p>Liquidity removal = market order<p>Liquidity providing = limit order (not immediately executable)</div><br/><div id="40912173" class="c"><input type="checkbox" id="c-40912173" checked=""/><div class="controls bullet"><span class="by">usefulcat</span><span>|</span><a href="#40909944">root</a><span>|</span><a href="#40911598">parent</a><span>|</span><a href="#40910908">next</a><span>|</span><label class="collapse" for="c-40912173">[-]</label><label class="expand" for="c-40912173">[1 more]</label></div><br/><div class="children"><div class="content">The order type is a red herring (you can take liquidity with a limit order).<p>The only difference between an order that removes liquidity and an order that adds liquidity is whether it executes upon arrival (removing liquidity) or rests on the order book on arrival (adding liquidity).</div><br/></div></div></div></div></div></div><div id="40911975" class="c"><input type="checkbox" id="c-40911975" checked=""/><div class="controls bullet"><span class="by">alchemist1e9</span><span>|</span><a href="#40909944">root</a><span>|</span><a href="#40910453">parent</a><span>|</span><a href="#40910470">prev</a><span>|</span><a href="#40910677">next</a><span>|</span><label class="collapse" for="c-40911975">[-]</label><label class="expand" for="c-40911975">[1 more]</label></div><br/><div class="children"><div class="content">This comment is how to tell me you completely misunderstood CLOB market structure without telling me.</div><br/></div></div></div></div><div id="40910677" class="c"><input type="checkbox" id="c-40910677" checked=""/><div class="controls bullet"><span class="by">FredPret</span><span>|</span><a href="#40909944">root</a><span>|</span><a href="#40910270">parent</a><span>|</span><a href="#40910453">prev</a><span>|</span><a href="#40911968">next</a><span>|</span><label class="collapse" for="c-40910677">[-]</label><label class="expand" for="c-40910677">[5 more]</label></div><br/><div class="children"><div class="content">If one outlawed &#x2F; disincentivized hostile the bot behavior you described, there would still be the opportunity to do the good and profitable things I described.</div><br/><div id="40912002" class="c"><input type="checkbox" id="c-40912002" checked=""/><div class="controls bullet"><span class="by">alchemist1e9</span><span>|</span><a href="#40909944">root</a><span>|</span><a href="#40910677">parent</a><span>|</span><a href="#40911968">next</a><span>|</span><label class="collapse" for="c-40912002">[-]</label><label class="expand" for="c-40912002">[4 more]</label></div><br/><div class="children"><div class="content">These commenters have no clue what they are talking about. You don’t need to worry about hostile behaviors in the way they claim. These HN individuals are not domain educated and are spouting highly uninformed nonsense. Silly ideas like market orders take liquidity and limit orders provide it show an extremely rudimentary familiarity with only basic terminology of the field and with no understanding of the extremely dynamic and complex nature of modern capital markets. For instance they don’t realize that most longer term managers execute as much as 80% of their orders as passive limit orders, yet they are the ones that are actually liquidity demanders not suppliers.</div><br/><div id="40912228" class="c"><input type="checkbox" id="c-40912228" checked=""/><div class="controls bullet"><span class="by">rramadass</span><span>|</span><a href="#40909944">root</a><span>|</span><a href="#40912002">parent</a><span>|</span><a href="#40912283">next</a><span>|</span><label class="collapse" for="c-40912228">[-]</label><label class="expand" for="c-40912228">[2 more]</label></div><br/><div class="children"><div class="content">&gt; These HN individuals are not domain educated and are spouting highly uninformed nonsense.<p>Yeah, this is highly frustrating particularly for people like me who don&#x27;t know anything about the domain i.e. HFT&#x2F;Trading and would like to know more.<p>Can you recommend some good introductory books&#x2F;resources ?</div><br/><div id="40912358" class="c"><input type="checkbox" id="c-40912358" checked=""/><div class="controls bullet"><span class="by">alchemist1e9</span><span>|</span><a href="#40909944">root</a><span>|</span><a href="#40912228">parent</a><span>|</span><a href="#40912283">next</a><span>|</span><label class="collapse" for="c-40912358">[-]</label><label class="expand" for="c-40912358">[1 more]</label></div><br/><div class="children"><div class="content">I might be biased for some almost personal reasons, however I think there is one book that anyone serious about the field should just read, period.<p>“Trades, Quotes and Prices”<p>Authors:<p>Jean-Philippe Bouchaud, Capital Fund Management, Paris, Julius Bonart, University College London, Jonathan Donier, Capital Fund Management, Martin Gould, CFM - Imperial Institute of Quantitative Finance.<p>I’m a practitioner and this book is foundational.</div><br/></div></div></div></div></div></div></div></div><div id="40911968" class="c"><input type="checkbox" id="c-40911968" checked=""/><div class="controls bullet"><span class="by">alchemist1e9</span><span>|</span><a href="#40909944">root</a><span>|</span><a href="#40910270">parent</a><span>|</span><a href="#40910677">prev</a><span>|</span><a href="#40910146">next</a><span>|</span><label class="collapse" for="c-40911968">[-]</label><label class="expand" for="c-40911968">[2 more]</label></div><br/><div class="children"><div class="content">Exchanges put limits on cancellation rates as measured by a multiple of filled orders.<p>You have to allow strategies that can induce other strategies as by definition those also increase liquidity. It’s a difficult problem to explain to anyone except the very few people who can understand the extremely complicated feedback loops that result from bots fighting bots, however the regulators actually have access to counterparty tagged exchange event data and what is found when this is analyzed is that the net cost for liquidity that is extracted by market makers and short term traders from longer term participants is continuously decreasing not increasing. The system is becoming more and more efficient and not less. This is good for markets and the economy. There are also less people working in financial markets per capita than ever before, granted those who are might include a higher percentage of highly skilled and specialized and educated individuals than previously, which some might argue might be better used in some other industry, but that is rightfully not what the market wants.<p>There is absolutely no logical reason to “kill off this entire field” those sentiments are purely envy based reactions from those who don’t understand what is happening.</div><br/><div id="40912539" class="c"><input type="checkbox" id="c-40912539" checked=""/><div class="controls bullet"><span class="by">FredPret</span><span>|</span><a href="#40909944">root</a><span>|</span><a href="#40911968">parent</a><span>|</span><a href="#40910146">next</a><span>|</span><label class="collapse" for="c-40912539">[-]</label><label class="expand" for="c-40912539">[1 more]</label></div><br/><div class="children"><div class="content">The other fundamental thing is that if you can’t sell something, you don’t really own it.<p>So wether pairs of people want to buy-and-hold or HFT their assets is really neither here nor there for uninvolved third parties.</div><br/></div></div></div></div></div></div></div></div><div id="40910146" class="c"><input type="checkbox" id="c-40910146" checked=""/><div class="controls bullet"><span class="by">bravura</span><span>|</span><a href="#40909944">parent</a><span>|</span><a href="#40909995">prev</a><span>|</span><a href="#40910149">next</a><span>|</span><label class="collapse" for="c-40910146">[-]</label><label class="expand" for="c-40910146">[8 more]</label></div><br/><div class="children"><div class="content">Warren Buffett proposed that the stock market should be open less frequently, like once a quarter or similar. This would encourage long-term investing rather than reacting to speculation.<p>Regardless, there are no natural events that necessitate high-frequency trading. The underlying value of things rarely changes very quickly, and if it does it&#x27;s not volatile, rather it&#x27;s a firm transiton.</div><br/><div id="40910241" class="c"><input type="checkbox" id="c-40910241" checked=""/><div class="controls bullet"><span class="by">astromaniak</span><span>|</span><a href="#40909944">root</a><span>|</span><a href="#40910146">parent</a><span>|</span><a href="#40910398">next</a><span>|</span><label class="collapse" for="c-40910241">[-]</label><label class="expand" for="c-40910241">[4 more]</label></div><br/><div class="children"><div class="content">&gt; Warren Buffett proposed that the stock market should be open less frequently<p>This will result in another market where deals will be made and then finalized on that &#x27;official&#x27; when it opens. It&#x27;s like with employee stock. You can sell it before you can...</div><br/><div id="40910602" class="c"><input type="checkbox" id="c-40910602" checked=""/><div class="controls bullet"><span class="by">munk-a</span><span>|</span><a href="#40909944">root</a><span>|</span><a href="#40910241">parent</a><span>|</span><a href="#40910398">next</a><span>|</span><label class="collapse" for="c-40910602">[-]</label><label class="expand" for="c-40910602">[3 more]</label></div><br/><div class="children"><div class="content">Not if we disallow it.  We have laws in place to try and prevent a lot of natural actions of markets.</div><br/><div id="40911126" class="c"><input type="checkbox" id="c-40911126" checked=""/><div class="controls bullet"><span class="by">FredPret</span><span>|</span><a href="#40909944">root</a><span>|</span><a href="#40910602">parent</a><span>|</span><a href="#40910398">next</a><span>|</span><label class="collapse" for="c-40911126">[-]</label><label class="expand" for="c-40911126">[2 more]</label></div><br/><div class="children"><div class="content">Instant biggest black market of all time, corruption skyrockets, only the richest people get fair deals on investments.</div><br/><div id="40911947" class="c"><input type="checkbox" id="c-40911947" checked=""/><div class="controls bullet"><span class="by">akira2501</span><span>|</span><a href="#40909944">root</a><span>|</span><a href="#40911126">parent</a><span>|</span><a href="#40910398">next</a><span>|</span><label class="collapse" for="c-40911947">[-]</label><label class="expand" for="c-40911947">[1 more]</label></div><br/><div class="children"><div class="content">They&#x27;ll get better than fair deals.  They will almost exclusively own all the available pricing information.</div><br/></div></div></div></div></div></div></div></div><div id="40910398" class="c"><input type="checkbox" id="c-40910398" checked=""/><div class="controls bullet"><span class="by">Arnt</span><span>|</span><a href="#40909944">root</a><span>|</span><a href="#40910146">parent</a><span>|</span><a href="#40910241">prev</a><span>|</span><a href="#40910247">next</a><span>|</span><label class="collapse" for="c-40910398">[-]</label><label class="expand" for="c-40910398">[1 more]</label></div><br/><div class="children"><div class="content">AIUI the point of HFT isn&#x27;t to trade frequently, but rather to change offer&#x2F;bid prices in the smallest possible steps (small along both axes) while waiting for someone to accept the offer&#x2F;bid.</div><br/></div></div><div id="40910247" class="c"><input type="checkbox" id="c-40910247" checked=""/><div class="controls bullet"><span class="by">htrp</span><span>|</span><a href="#40909944">root</a><span>|</span><a href="#40910146">parent</a><span>|</span><a href="#40910398">prev</a><span>|</span><a href="#40910497">next</a><span>|</span><label class="collapse" for="c-40910247">[-]</label><label class="expand" for="c-40910247">[1 more]</label></div><br/><div class="children"><div class="content">most trading volume already happens at open or before close.</div><br/></div></div><div id="40910497" class="c"><input type="checkbox" id="c-40910497" checked=""/><div class="controls bullet"><span class="by">kolbe</span><span>|</span><a href="#40909944">root</a><span>|</span><a href="#40910146">parent</a><span>|</span><a href="#40910247">prev</a><span>|</span><a href="#40910149">next</a><span>|</span><label class="collapse" for="c-40910497">[-]</label><label class="expand" for="c-40910497">[1 more]</label></div><br/><div class="children"><div class="content">Seems like a testable hypothesis. Choose the four times a year that the stock is at a fair price, and buy when it goes below it and sell when it goes above it?</div><br/></div></div></div></div><div id="40910149" class="c"><input type="checkbox" id="c-40910149" checked=""/><div class="controls bullet"><span class="by">idohft</span><span>|</span><a href="#40909944">parent</a><span>|</span><a href="#40910146">prev</a><span>|</span><a href="#40910764">next</a><span>|</span><label class="collapse" for="c-40910149">[-]</label><label class="expand" for="c-40910149">[1 more]</label></div><br/><div class="children"><div class="content">How far have you tried to tell, and do you buy&#x2F;sell stocks?<p>There&#x27;s someone on the other side of your trade when you want to trade something. You&#x27;re more likely than not choosing to interact with an HFT player at your price. If you&#x27;re getting a better price, that&#x27;s money that you get to keep.<p>*I&#x27;m going to disagree on &quot;free pass&quot; also. HFT is pretty often criticized here.</div><br/></div></div><div id="40910764" class="c"><input type="checkbox" id="c-40910764" checked=""/><div class="controls bullet"><span class="by">rcxdude</span><span>|</span><a href="#40909944">parent</a><span>|</span><a href="#40910149">prev</a><span>|</span><a href="#40910373">next</a><span>|</span><label class="collapse" for="c-40910764">[-]</label><label class="expand" for="c-40910764">[2 more]</label></div><br/><div class="children"><div class="content">Yes: it put a much larger, more expensive, and less efficient part of wall street out of business. Before it was done with computers, it was done with lots of people doing the same job. What was that job? Well, if you want to go to a market and sell something, you generally would like for there to be someone there who&#x27;s buying it. But it&#x27;s not always the case that there&#x27;s a buyer there right at the time who actually wants the item for their own use. The inverse is also true for a prospective buyer. Enter middle-men or market makers who just hang around the marketplace, learning roughly how much people will buy or sell a given good for, and buy it for slightly less than they can sell it later for. This is actually generally useful if you just want to buy or sell something.<p>Now, does this need to get towards milli-seconds or nano-seconds? No, this is just the equivalent of many of these middle-men racing to give you an offer. But it&#x27;s (part of) how they compete with each other, and as they do so they squeeze the margins of the industry as a whole: In fact the profits of HFT firms have decreased as a percentage of the overall market and in absolute terms after the initial peak as they displaced the day traders doing the same thing.</div><br/><div id="40912944" class="c"><input type="checkbox" id="c-40912944" checked=""/><div class="controls bullet"><span class="by">bostik</span><span>|</span><a href="#40909944">root</a><span>|</span><a href="#40910764">parent</a><span>|</span><a href="#40910373">next</a><span>|</span><label class="collapse" for="c-40912944">[-]</label><label class="expand" for="c-40912944">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>it&#x27;s not always the case that there&#x27;s a buyer there right at the time</i><p>This hits the nail on the head. For a trade to happen, counterparties need to meet in price <i>and</i> in time. A market place is useless if there is nobody around to buy or sell at the same time you do.<p>The core service market makers provide is not liquidity. It&#x27;s immediacy: they offer (put up) liquidity in order to capture trades, but the value proposition for other traders - and the exchanges! - is that there is someone to take the other side of a trade when a non-MM entity wants to buy or sell instruments.<p>It took me a long time to understand what the difference is. And in order to make sure that there is sufficient liquidity in place, exchanges set up both contractual requirements and incentive structures for their market makers.</div><br/></div></div></div></div><div id="40910373" class="c"><input type="checkbox" id="c-40910373" checked=""/><div class="controls bullet"><span class="by">pi-rat</span><span>|</span><a href="#40909944">parent</a><span>|</span><a href="#40910764">prev</a><span>|</span><a href="#40910026">next</a><span>|</span><label class="collapse" for="c-40910373">[-]</label><label class="expand" for="c-40910373">[3 more]</label></div><br/><div class="children"><div class="content">Generally gets attributed with:<p>- Increased liquidity. Ensures there&#x27;s actually something to be traded available globally, and swiftly moves it to places where it&#x27;s lacking.<p>- Tighter spreads, the difference between you buying and then selling again is lower. Which often is good for the &quot;actual users&quot; of the market.<p>- Global prices &#x2F; less geographical differences in prices. Generally you can trust you get the right price no matter what venue you trade at, as any arbitrage opportunity has likely already been executed on.<p>- etc..</div><br/><div id="40910624" class="c"><input type="checkbox" id="c-40910624" checked=""/><div class="controls bullet"><span class="by">munk-a</span><span>|</span><a href="#40909944">root</a><span>|</span><a href="#40910373">parent</a><span>|</span><a href="#40910026">next</a><span>|</span><label class="collapse" for="c-40910624">[-]</label><label class="expand" for="c-40910624">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Tighter spreads, the difference between you buying and then selling again is lower. Which often is good for the &quot;actual users&quot; of the market.<p>I just wanted to highlight this one in particular - the spread is tighter because HFTs eat the spread and reduce the error that market players can benefit from.  The spread is disappearing because of rent-seeking from the HFTs.</div><br/><div id="40911250" class="c"><input type="checkbox" id="c-40911250" checked=""/><div class="controls bullet"><span class="by">yxhuvud</span><span>|</span><a href="#40909944">root</a><span>|</span><a href="#40910624">parent</a><span>|</span><a href="#40910026">next</a><span>|</span><label class="collapse" for="c-40911250">[-]</label><label class="expand" for="c-40911250">[1 more]</label></div><br/><div class="children"><div class="content">What needs to be pointed out is that the rent and spread is the same thing in this equation. Before the rise of HFT actual people performed these functions, and then the spread&#x2F;rent-seeking was a lot higher.</div><br/></div></div></div></div></div></div><div id="40910026" class="c"><input type="checkbox" id="c-40910026" checked=""/><div class="controls bullet"><span class="by">torlok</span><span>|</span><a href="#40909944">parent</a><span>|</span><a href="#40910373">prev</a><span>|</span><a href="#40909973">next</a><span>|</span><label class="collapse" for="c-40910026">[-]</label><label class="expand" for="c-40910026">[4 more]</label></div><br/><div class="children"><div class="content">To go a step further, I don&#x27;t think you should be required to talk to middlemen when buying stocks, yet here we are. The house wants its cut.</div><br/><div id="40912667" class="c"><input type="checkbox" id="c-40912667" checked=""/><div class="controls bullet"><span class="by">mrbald</span><span>|</span><a href="#40909944">root</a><span>|</span><a href="#40910026">parent</a><span>|</span><a href="#40911293">next</a><span>|</span><label class="collapse" for="c-40912667">[-]</label><label class="expand" for="c-40912667">[1 more]</label></div><br/><div class="children"><div class="content">Central counterparty concept implemented by most exchanges is a valid service, as otherwise counterparty risk management would be a nightmare - an example of a useful “middleman”.</div><br/></div></div><div id="40911293" class="c"><input type="checkbox" id="c-40911293" checked=""/><div class="controls bullet"><span class="by">smabie</span><span>|</span><a href="#40909944">root</a><span>|</span><a href="#40910026">parent</a><span>|</span><a href="#40912667">prev</a><span>|</span><a href="#40910277">next</a><span>|</span><label class="collapse" for="c-40911293">[-]</label><label class="expand" for="c-40911293">[1 more]</label></div><br/><div class="children"><div class="content">So who would sell it to you then? At any given time there&#x27;s not very many actual natural buyer and sellers for a single security.</div><br/></div></div><div id="40910277" class="c"><input type="checkbox" id="c-40910277" checked=""/><div class="controls bullet"><span class="by">astromaniak</span><span>|</span><a href="#40909944">root</a><span>|</span><a href="#40910026">parent</a><span>|</span><a href="#40911293">prev</a><span>|</span><a href="#40909973">next</a><span>|</span><label class="collapse" for="c-40910277">[-]</label><label class="expand" for="c-40910277">[1 more]</label></div><br/><div class="children"><div class="content">Under the carpet deals would make it less transparent. It would be hard to detect that top manager sold all his stock to competitors and now is making decisions in their favor.</div><br/></div></div></div></div><div id="40909973" class="c"><input type="checkbox" id="c-40909973" checked=""/><div class="controls bullet"><span class="by">arcimpulse</span><span>|</span><a href="#40909944">parent</a><span>|</span><a href="#40910026">prev</a><span>|</span><a href="#40912318">next</a><span>|</span><label class="collapse" for="c-40909973">[-]</label><label class="expand" for="c-40909973">[3 more]</label></div><br/><div class="children"><div class="content">It would be trivial (and vastly more equitable) to quantize trade times.</div><br/><div id="40911144" class="c"><input type="checkbox" id="c-40911144" checked=""/><div class="controls bullet"><span class="by">FredPret</span><span>|</span><a href="#40909944">root</a><span>|</span><a href="#40909973">parent</a><span>|</span><a href="#40912318">next</a><span>|</span><label class="collapse" for="c-40911144">[-]</label><label class="expand" for="c-40911144">[2 more]</label></div><br/><div class="children"><div class="content">You mean like settling trades every 0.25 seconds or something like that? Wouldn&#x27;t there be a queue of trades piling up every 0.25 seconds, incentivizing maximum speed anyway?</div><br/><div id="40912680" class="c"><input type="checkbox" id="c-40912680" checked=""/><div class="controls bullet"><span class="by">foobazgt</span><span>|</span><a href="#40909944">root</a><span>|</span><a href="#40911144">parent</a><span>|</span><a href="#40912318">next</a><span>|</span><label class="collapse" for="c-40912680">[-]</label><label class="expand" for="c-40912680">[1 more]</label></div><br/><div class="children"><div class="content">Usually the proposal is to randomize the processing of the queue. So, as long as your trades get in during the window, there&#x27;s no advantage to getting in any earlier. In theory the window is so small as to not have any impact on liquidity but wide enough to basically shut down all HFT.</div><br/></div></div></div></div></div></div><div id="40912318" class="c"><input type="checkbox" id="c-40912318" checked=""/><div class="controls bullet"><span class="by">lifeformed</span><span>|</span><a href="#40909944">parent</a><span>|</span><a href="#40909973">prev</a><span>|</span><a href="#40912083">next</a><span>|</span><label class="collapse" for="c-40912318">[-]</label><label class="expand" for="c-40912318">[1 more]</label></div><br/><div class="children"><div class="content">Just from an energy perspective, I&#x27;m pretty sure HFT uses many orders of magnitude less energy than bitcoin mining.</div><br/></div></div><div id="40911566" class="c"><input type="checkbox" id="c-40911566" checked=""/><div class="controls bullet"><span class="by">lmm</span><span>|</span><a href="#40909944">parent</a><span>|</span><a href="#40912083">prev</a><span>|</span><a href="#40911077">next</a><span>|</span><label class="collapse" for="c-40911566">[-]</label><label class="expand" for="c-40911566">[1 more]</label></div><br/><div class="children"><div class="content">&gt; a definite net negative to society as far as I can tell.<p>What did you examine to reach that conclusion? If high-frequency trading were positive for society, what would you expect to be different?<p>The reason for high-frequency trading to exist is that the sub-penny rule makes it illegal to compete on price so you have to compete on speed instead. Abolishing the sub-penny rule would mean high-frequency trading profits got competed-away to nothing, although frankly they&#x27;re already pretty close. The whole industry is basically an irrelevant piece of plumbing anyway.</div><br/></div></div><div id="40911077" class="c"><input type="checkbox" id="c-40911077" checked=""/><div class="controls bullet"><span class="by">calibas</span><span>|</span><a href="#40909944">parent</a><span>|</span><a href="#40911566">prev</a><span>|</span><a href="#40910597">next</a><span>|</span><label class="collapse" for="c-40911077">[-]</label><label class="expand" for="c-40911077">[2 more]</label></div><br/><div class="children"><div class="content">A net negative to society, but a positive for the wealthiest.</div><br/><div id="40912055" class="c"><input type="checkbox" id="c-40912055" checked=""/><div class="controls bullet"><span class="by">cheonic730</span><span>|</span><a href="#40909944">root</a><span>|</span><a href="#40911077">parent</a><span>|</span><a href="#40910597">next</a><span>|</span><label class="collapse" for="c-40912055">[-]</label><label class="expand" for="c-40912055">[1 more]</label></div><br/><div class="children"><div class="content">&gt; A net negative to society, but a positive for the wealthiest.<p>No.<p>When your passive index fund manager rebalances every month because “NVDA is now overweighted in VTI, QQQ” the manager does not care about the bid&#x2F;ask spread.<p>When VTI is $1.6 trillion, even a $0.01 difference in  price translates to a loss $60 million for the passive 401k, IRA, investors.<p>HFT reduces the bid&#x2F;ask spread, and “gives this $60 million back” to the passive investors for every $0.01 price difference, every month. Note that VTI mid price at time of writing is $272.49.</div><br/></div></div></div></div><div id="40910597" class="c"><input type="checkbox" id="c-40910597" checked=""/><div class="controls bullet"><span class="by">mkoubaa</span><span>|</span><a href="#40909944">parent</a><span>|</span><a href="#40911077">prev</a><span>|</span><a href="#40909882">next</a><span>|</span><label class="collapse" for="c-40910597">[-]</label><label class="expand" for="c-40910597">[1 more]</label></div><br/><div class="children"><div class="content">Why does it exist?<p>Because it&#x27;s legal and profitable.<p>If you don&#x27;t like it, try to convince regulators that it shouldn&#x27;t be legal and provide a framework for criminalizing&#x2F;fining it without unintended consequences, and then find a way to pay regulators more in bribes than the HFT shops do, even though their pockets are deeper than yours, and then things may change.<p>If that sounds impossible, that&#x27;s another answer to your question</div><br/></div></div></div></div><div id="40909882" class="c"><input type="checkbox" id="c-40909882" checked=""/><div class="controls bullet"><span class="by">gedanziger</span><span>|</span><a href="#40909944">prev</a><span>|</span><label class="collapse" for="c-40909882">[-]</label><label class="expand" for="c-40909882">[1 more]</label></div><br/><div class="children"><div class="content">Very cool intro to the subject!</div><br/></div></div></div></div></div></div></div></body></html>