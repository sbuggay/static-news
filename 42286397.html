<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1733043654022" as="style"/><link rel="stylesheet" href="styles.css?v=1733043654022"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://arxiv.org/abs/2411.01747">DynaSaur: Large Language Agents Beyond Predefined Actions</a>Â <span class="domain">(<a href="https://arxiv.org">arxiv.org</a>)</span></div><div class="subtext"><span>surprisetalk</span> | <span>5 comments</span></div><br/><div><div id="42287094" class="c"><input type="checkbox" id="c-42287094" checked=""/><div class="controls bullet"><span class="by">throwup238</span><span>|</span><a href="#42287020">next</a><span>|</span><label class="collapse" for="c-42287094">[-]</label><label class="expand" for="c-42287094">[3 more]</label></div><br/><div class="children"><div class="content">It looks like the key insight here is to have the LLM generate its own tools (as in GPT&#x2F;Claude tool calling) via Python code generation and apply cosine similarity RAG to select which tools are available at each step using the tool description and the problem&#x2F;step while using recent history to error correct.<p>The agent starts with some human created tooling like a tool to read the file system or create another tool using python code, then starts accumulating custom Python functions it wrote itself with tool calling metadata like descriptions and input&#x2F;output types. Every time it reaches a step, if it doesn&#x27;t find a relevant tool, it creates a new one. Apparently this improves performance on complex tasks (via GAIA benchmark) with diminishing returns on simpler tasks.</div><br/><div id="42287129" class="c"><input type="checkbox" id="c-42287129" checked=""/><div class="controls bullet"><span class="by">IanCal</span><span>|</span><a href="#42287094">parent</a><span>|</span><a href="#42287020">next</a><span>|</span><label class="collapse" for="c-42287129">[-]</label><label class="expand" for="c-42287129">[2 more]</label></div><br/><div class="children"><div class="content">I played around making these things before, it&#x27;s a fun exercise. Interesting to see that&#x27;s where things may be heading.<p>My example was asking for a poem about the headlines (good example of info they don&#x27;t have, and something that&#x27;s very hard to do mechanically).<p><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37015591">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37015591</a></div><br/></div></div></div></div><div id="42287020" class="c"><input type="checkbox" id="c-42287020" checked=""/><div class="controls bullet"><span class="by">golol</span><span>|</span><a href="#42287094">prev</a><span>|</span><label class="collapse" for="c-42287020">[-]</label><label class="expand" for="c-42287020">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t like the way LLM papers are written. LLMs receive inputs and produce outputs that are best represented as plaintext with some special characters. Simply showing a few examples of the agent&#x27;s core LLM text continuation job would explain the architecture much better than figures. I can&#x27;t help but feel that the authors which do this are intentionally obfuscating things.</div><br/></div></div></div></div></div></div></div></body></html>