<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1712826053866" as="style"/><link rel="stylesheet" href="styles.css?v=1712826053866"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/bennyschmidt/next-token-prediction">Show HN: Next-token prediction in JavaScript – build fast LLMs from scratch</a> <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>bschmidt1</span> | <span>25 comments</span></div><br/><div><div id="39998678" class="c"><input type="checkbox" id="c-39998678" checked=""/><div class="controls bullet"><span class="by">selcuka</span><span>|</span><a href="#39999922">next</a><span>|</span><label class="collapse" for="c-39998678">[-]</label><label class="expand" for="c-39998678">[5 more]</label></div><br/><div class="children"><div class="content">I might be misinterpreting the blurb above, but isn&#x27;t this a JavaScript implementation of a Markov Chain [1]?<p>[1] <a href="https:&#x2F;&#x2F;towardsdatascience.com&#x2F;text-generation-with-markov-chains-an-introduction-to-using-markovify-742e6680dc33" rel="nofollow">https:&#x2F;&#x2F;towardsdatascience.com&#x2F;text-generation-with-markov-c...</a></div><br/><div id="39998722" class="c"><input type="checkbox" id="c-39998722" checked=""/><div class="controls bullet"><span class="by">mpeg</span><span>|</span><a href="#39998678">parent</a><span>|</span><a href="#39999922">next</a><span>|</span><label class="collapse" for="c-39998722">[-]</label><label class="expand" for="c-39998722">[4 more]</label></div><br/><div class="children"><div class="content">Exactly my thoughts, this isn’t really an LLM. I understand it’s just a personal project but it’s probably good to know LLMs are not just lookup tables.<p>Also, I’m not sure I understand the explanation of why js objects are so great for this, you could do the same thing with a python dict for example or equivalent mapping types in any programming language.<p>This is also missing an attention mechanism which is very important to understand even for a toy LLM as it’s part of what makes the responses so accurate to the context, rather than it just predicting what word usually comes next to another word (or sequence of words)</div><br/><div id="39998818" class="c"><input type="checkbox" id="c-39998818" checked=""/><div class="controls bullet"><span class="by">selcuka</span><span>|</span><a href="#39998678">root</a><span>|</span><a href="#39998722">parent</a><span>|</span><a href="#39999014">next</a><span>|</span><label class="collapse" for="c-39998818">[-]</label><label class="expand" for="c-39998818">[1 more]</label></div><br/><div class="children"><div class="content">&gt; you could do the same thing with a python dict for example or equivalent mapping types in any programming language.<p>Yes, any language with a hashmap of sorts with O(1) lookups should be equivalent.</div><br/></div></div><div id="39999014" class="c"><input type="checkbox" id="c-39999014" checked=""/><div class="controls bullet"><span class="by">littlestymaar</span><span>|</span><a href="#39998678">root</a><span>|</span><a href="#39998722">parent</a><span>|</span><a href="#39998818">prev</a><span>|</span><a href="#39999922">next</a><span>|</span><label class="collapse" for="c-39999014">[-]</label><label class="expand" for="c-39999014">[2 more]</label></div><br/><div class="children"><div class="content">&gt; but it’s probably good to know LLMs are not just lookup tables.<p>But there are almost literally lookup tables actually!<p>The thing is they don&#x27;t perform the lookup on a single word as a key, but on the entire context, which is what makes them special. But besides that it&#x27;s “just” a lookup table.</div><br/><div id="39999065" class="c"><input type="checkbox" id="c-39999065" checked=""/><div class="controls bullet"><span class="by">kibibu</span><span>|</span><a href="#39998678">root</a><span>|</span><a href="#39999014">parent</a><span>|</span><a href="#39999922">next</a><span>|</span><label class="collapse" for="c-39999065">[-]</label><label class="expand" for="c-39999065">[1 more]</label></div><br/><div class="children"><div class="content">A deep attention network is absolutely not a lookup table</div><br/></div></div></div></div></div></div></div></div><div id="39999922" class="c"><input type="checkbox" id="c-39999922" checked=""/><div class="controls bullet"><span class="by">machiaweliczny</span><span>|</span><a href="#39998678">prev</a><span>|</span><a href="#39998886">next</a><span>|</span><label class="collapse" for="c-39999922">[-]</label><label class="expand" for="c-39999922">[1 more]</label></div><br/><div class="children"><div class="content">Man watch video from Karpathy and learn about prefix trees (tries)</div><br/></div></div><div id="39998886" class="c"><input type="checkbox" id="c-39998886" checked=""/><div class="controls bullet"><span class="by">fredwu</span><span>|</span><a href="#39999922">prev</a><span>|</span><a href="#39998812">next</a><span>|</span><label class="collapse" for="c-39998886">[-]</label><label class="expand" for="c-39998886">[3 more]</label></div><br/><div class="children"><div class="content">Calling this an LLM and claiming:<p>&gt; With enough training data and a good chat interface, this can be used instead of well-known decoder-only models like GPT, Mistral, etc.<p>Seems to be very misleading...</div><br/><div id="39999345" class="c"><input type="checkbox" id="c-39999345" checked=""/><div class="controls bullet"><span class="by">bschmidt1</span><span>|</span><a href="#39998886">parent</a><span>|</span><a href="#39998812">next</a><span>|</span><label class="collapse" for="c-39999345">[-]</label><label class="expand" for="c-39999345">[2 more]</label></div><br/><div class="children"><div class="content">&gt; enough training data
&gt; good chat interface<p>I&#x27;m going to try to do that here: <a href="https:&#x2F;&#x2F;github.com&#x2F;bennyschmidt&#x2F;llimo">https:&#x2F;&#x2F;github.com&#x2F;bennyschmidt&#x2F;llimo</a><p>I totally understand your skepticism, and am also surprised it works so well as a sentence-finisher, even with hardly any data (a handful of books). Think about it like this:<p>If you had a file with billions of sentences:<p>&quot;Paris is in France&quot;
&quot;Apples grow on trees&quot;
&quot;Gold is worth more than silver&quot;
&quot;I know where to go!&quot;
etc...<p>Then you can complete virtually any sentence. Say the user enters &quot;Paris&quot; - you can easily find and return &quot;is in France&quot; by simply searching for &quot;Paris&quot; in the text then slicing out the rest of the sentence, &quot;is in France&quot; -- or just give the next word &quot;is&quot; for more of an auto-suggest feel.<p>But if there were 4 sentences starting with &quot;Paris&quot;, it gets slightly more complex, now I have to rank them to know which one is the best suggestion:<p>&quot;Paris is in France.&quot;
&quot;Paris is nice this time of year.&quot; 
&quot;Paris Hilton liked my post!&quot;
&quot;Paris was my favorite city overall.&quot;<p>In this case, &quot;is&quot; is still the best because it scores higher than &quot;Hilton&quot; and &quot;was&quot; - because it follows &quot;Paris&quot; more frequently. So in addition to the text file of billions of sentences, I need to make a ranking system to give a point score to every possible word in the file at every possible position it might be in.<p>To make it all faster (because a super massive text file is not feasible), the billions of sentences are not actually represented in a single text file, but as a deeply nested JavaScript object our computers are more optimized to traverse and lookup, along with the point values for each word.<p>At this point, _with enough sentences on file_ with ranked suggestions and fast lookups, you can complete almost anything a user could input. This is what I shared today.<p>&gt; good chat interface<p>To put the sentence-finisher to use as a chat bot, all you need to do is convert the user&#x27;s question or &quot;prompt&quot; into the beginning of a sentence. For example:<p>&quot;Where is Paris?&quot; -&gt; &quot;Paris is&quot; and let the completer give you &quot;in France&quot;. So the answer is: &quot;Paris is in France.&quot;<p>Does this make sense?</div><br/><div id="39999627" class="c"><input type="checkbox" id="c-39999627" checked=""/><div class="controls bullet"><span class="by">cess11</span><span>|</span><a href="#39998886">root</a><span>|</span><a href="#39999345">parent</a><span>|</span><a href="#39998812">next</a><span>|</span><label class="collapse" for="c-39999627">[-]</label><label class="expand" for="c-39999627">[1 more]</label></div><br/><div class="children"><div class="content">Stick with it and eventually you&#x27;ll invent your own subset of Prolog.</div><br/></div></div></div></div></div></div><div id="39998935" class="c"><input type="checkbox" id="c-39998935" checked=""/><div class="controls bullet"><span class="by">gattilorenz</span><span>|</span><a href="#39998812">prev</a><span>|</span><a href="#39999143">next</a><span>|</span><label class="collapse" for="c-39998935">[-]</label><label class="expand" for="c-39998935">[3 more]</label></div><br/><div class="children"><div class="content">Nice that the topic gets you enthusiastic! If you want to learn about LLMs, I suggest you try educational material that doesn’t simplify it too much (i.e. not videos), before implementing something.<p>Personal recommendation: <a href="https:&#x2F;&#x2F;web.stanford.edu&#x2F;~jurafsky&#x2F;slp3&#x2F;" rel="nofollow">https:&#x2F;&#x2F;web.stanford.edu&#x2F;~jurafsky&#x2F;slp3&#x2F;</a>
Chapters 6-10 should give you a good understanding of these concepts, also from the mathematical point of view!</div><br/><div id="39999008" class="c"><input type="checkbox" id="c-39999008" checked=""/><div class="controls bullet"><span class="by">bschmidt1</span><span>|</span><a href="#39998935">parent</a><span>|</span><a href="#39999145">next</a><span>|</span><label class="collapse" for="c-39999008">[-]</label><label class="expand" for="c-39999008">[1 more]</label></div><br/><div class="children"><div class="content">Amazing resource thank you!<p>Agree regarding videos for learning technical concepts - strangely when things are over-simplified they can become harder to understand on a technical level, I guess just being so abstracted. Example: The embeddings in the video I mentioned were always visualized spatially, where I simply think about it in terms of numerical point values. Like in the movie Hackers where they&#x27;re traveling through 3D &quot;cities&quot; of &quot;data&quot; or whatever is going on. On one hand it simplifies the domain for a wider audience, yet it turns it into something else entirely!<p>Appreciate you sharing these.</div><br/></div></div><div id="39999145" class="c"><input type="checkbox" id="c-39999145" checked=""/><div class="controls bullet"><span class="by">pushreply</span><span>|</span><a href="#39998935">parent</a><span>|</span><a href="#39999008">prev</a><span>|</span><a href="#39999143">next</a><span>|</span><label class="collapse" for="c-39999145">[-]</label><label class="expand" for="c-39999145">[1 more]</label></div><br/><div class="children"><div class="content">wow Thanks!</div><br/></div></div></div></div><div id="39999143" class="c"><input type="checkbox" id="c-39999143" checked=""/><div class="controls bullet"><span class="by">anonzzzies</span><span>|</span><a href="#39998935">prev</a><span>|</span><a href="#39998933">next</a><span>|</span><label class="collapse" for="c-39999143">[-]</label><label class="expand" for="c-39999143">[2 more]</label></div><br/><div class="children"><div class="content">The language is not really related to this; people have been doing this type of thing in Prolog and Lisp since before the 90s. Actually, with predicates to represent facts that you learn in your first Prolog class, you can do what you did but in any order, so not just following the hashmap from start to end but create any sentence starting from any point without effort. (Note also there the language doesn’t matter, you can do this in any language, just for Prolog this is the first thing you will learn as it’s a fundament and strength of the language).<p>I recommend a read of symbolic ai, or better, just a generic ai book:  I was raised on Norvig (90s) but no idea how up to date that is kept&#x2F;still is.</div><br/><div id="39999375" class="c"><input type="checkbox" id="c-39999375" checked=""/><div class="controls bullet"><span class="by">bschmidt1</span><span>|</span><a href="#39999143">parent</a><span>|</span><a href="#39998933">next</a><span>|</span><label class="collapse" for="c-39999375">[-]</label><label class="expand" for="c-39999375">[1 more]</label></div><br/><div class="children"><div class="content">Yep it can work for &quot;next-pixel prediction&quot; too where the token is a pixel. If I have enough samples of arrangements of pixels, it&#x27;s not fundamentally different than samples of arrangements of words. I&#x27;ll check out that book - thanks!</div><br/></div></div></div></div><div id="39998933" class="c"><input type="checkbox" id="c-39998933" checked=""/><div class="controls bullet"><span class="by">davely</span><span>|</span><a href="#39999143">prev</a><span>|</span><a href="#39998905">next</a><span>|</span><label class="collapse" for="c-39998933">[-]</label><label class="expand" for="c-39998933">[2 more]</label></div><br/><div class="children"><div class="content">Nice work! I did something in a similar vein, using JavaScript and Markov chains back in 2015 or so and ended up giving a fun talk about it at a coding bootcamp. [1]<p>I based it off a Ruby module called “Twitter Ebooks”, which I believe was based on a Python module called “horsey books”, which could create a bot that would make posts using Markov chains, given a corpus of text. [2]<p>(I’m not dropping the date to be a jerk, more to point out that Markov chains &#x2F; n-grams are an interesting concept for experimenting with language models and have been around for a while.)<p>In my case, I fed a corpus of data (my Twitter history at the point, which was something like 20K tweets) and tried to create a Twitter bot to make intelligent sounding posts.<p>It worked out, sometimes. But, it was a lot of fun to figure out!<p>[1] “Building intelligent robots using Node.js that can conquer Twitter” - <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=rMmXdiUGsr4" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=rMmXdiUGsr4</a><p>[2] <a href="https:&#x2F;&#x2F;github.com&#x2F;longears&#x2F;horsey-books">https:&#x2F;&#x2F;github.com&#x2F;longears&#x2F;horsey-books</a></div><br/><div id="39998982" class="c"><input type="checkbox" id="c-39998982" checked=""/><div class="controls bullet"><span class="by">bschmidt1</span><span>|</span><a href="#39998933">parent</a><span>|</span><a href="#39998905">next</a><span>|</span><label class="collapse" for="c-39998982">[-]</label><label class="expand" for="c-39998982">[1 more]</label></div><br/><div class="children"><div class="content">Awesome video, and really cool. I loved the ATTCares convo haha. I first heard about Markov chains from a philosopher named Donald Hoffman, but this demo makes it more clear! Thanks for sharing</div><br/></div></div></div></div><div id="39998905" class="c"><input type="checkbox" id="c-39998905" checked=""/><div class="controls bullet"><span class="by">willwade</span><span>|</span><a href="#39998933">prev</a><span>|</span><a href="#39998665">next</a><span>|</span><label class="collapse" for="c-39998905">[-]</label><label class="expand" for="c-39998905">[2 more]</label></div><br/><div class="children"><div class="content">Have a read about PPM - Prediction by Partial Matching<p><a href="http:&#x2F;&#x2F;cotty.16x16.com&#x2F;compress&#x2F;peppm.htm" rel="nofollow">http:&#x2F;&#x2F;cotty.16x16.com&#x2F;compress&#x2F;peppm.htm</a><p><a href="https:&#x2F;&#x2F;compressions.sourceforge.net&#x2F;PPM.html" rel="nofollow">https:&#x2F;&#x2F;compressions.sourceforge.net&#x2F;PPM.html</a><p><a href="https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Prediction_by_partial_matching" rel="nofollow">https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Prediction_by_partial_matchi...</a><p>In swift <a href="https:&#x2F;&#x2F;github.com&#x2F;kdv123&#x2F;PPMLM">https:&#x2F;&#x2F;github.com&#x2F;kdv123&#x2F;PPMLM</a><p>In C <a href="https:&#x2F;&#x2F;github.com&#x2F;money6g&#x2F;ppm">https:&#x2F;&#x2F;github.com&#x2F;money6g&#x2F;ppm</a><p>Someone’s done a JS version but I can’t find it right now</div><br/><div id="39999046" class="c"><input type="checkbox" id="c-39999046" checked=""/><div class="controls bullet"><span class="by">bschmidt1</span><span>|</span><a href="#39998905">parent</a><span>|</span><a href="#39998665">next</a><span>|</span><label class="collapse" for="c-39999046">[-]</label><label class="expand" for="c-39999046">[1 more]</label></div><br/><div class="children"><div class="content">This is awesome, thanks. I&#x27;ve been messing with wink&#x27;s NLP library (<a href="https:&#x2F;&#x2F;winkjs.org&#x2F;wink-nlp&#x2F;" rel="nofollow">https:&#x2F;&#x2F;winkjs.org&#x2F;wink-nlp&#x2F;</a>) to transform user queries and format responses so I can make a proper chat bot - will see what I can learn from these!</div><br/></div></div></div></div><div id="39998665" class="c"><input type="checkbox" id="c-39998665" checked=""/><div class="controls bullet"><span class="by">kylegalbraith</span><span>|</span><a href="#39998905">prev</a><span>|</span><a href="#39998976">next</a><span>|</span><label class="collapse" for="c-39998665">[-]</label><label class="expand" for="c-39998665">[2 more]</label></div><br/><div class="children"><div class="content">This is what HN is all about. This probably isn&#x27;t your next big LLM project but its a wonderfully simple example that shows what is happening underneath the hood. Do you plan on writing up something like a blog post to go with it?</div><br/><div id="39999116" class="c"><input type="checkbox" id="c-39999116" checked=""/><div class="controls bullet"><span class="by">bschmidt1</span><span>|</span><a href="#39998665">parent</a><span>|</span><a href="#39998976">next</a><span>|</span><label class="collapse" for="c-39999116">[-]</label><label class="expand" for="c-39999116">[1 more]</label></div><br/><div class="children"><div class="content">Hell yeah :) At first I thought a simple Show HN titled &quot;Next token prediction in 100 lines of JavaScript&quot; would be cool, but the project grew and now it&#x27;s a few different modules and things going on.<p>A couple people have basically said &quot;but what does it do?&quot;, &quot;what value does it add?&quot;<p>So I am planning a series of examples with videos for use cases like: Auto-completion, auto-correct, spell checking, search&#x2F;lookup, and if I can get around to making an ImageDecoder, could get into &quot;next-pixel prediction&quot;.<p>Beyond prediction, I want to make a YouTube video when I can show a working example of a really good chatbot than anyone can just npm install and use, would be funny to give some of the open models a run for their money - but you&#x27;re right, it&#x27;s just a hobby project for now. Working on that in a separate project: <a href="https:&#x2F;&#x2F;github.com&#x2F;bennyschmidt&#x2F;llimo">https:&#x2F;&#x2F;github.com&#x2F;bennyschmidt&#x2F;llimo</a><p>Thanks for the comment and motivation to write about it!</div><br/></div></div></div></div><div id="39998976" class="c"><input type="checkbox" id="c-39998976" checked=""/><div class="controls bullet"><span class="by">mirekrusin</span><span>|</span><a href="#39998665">prev</a><span>|</span><a href="#39996261">next</a><span>|</span><label class="collapse" for="c-39998976">[-]</label><label class="expand" for="c-39998976">[2 more]</label></div><br/><div class="children"><div class="content">The only thing it shows is that the author has a lot to learn.</div><br/><div id="39999407" class="c"><input type="checkbox" id="c-39999407" checked=""/><div class="controls bullet"><span class="by">bschmidt1</span><span>|</span><a href="#39998976">parent</a><span>|</span><a href="#39996261">next</a><span>|</span><label class="collapse" for="c-39999407">[-]</label><label class="expand" for="c-39999407">[1 more]</label></div><br/><div class="children"><div class="content">Of course I do, who doesn&#x27;t? Can you pick 1 thing I need to focus on most so I can get some value out of this comment? :D</div><br/></div></div></div></div></div></div></div></div></div></body></html>