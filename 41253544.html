<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1723712457157" as="style"/><link rel="stylesheet" href="styles.css?v=1723712457157"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://news.mit.edu/2024/researchers-use-large-language-models-to-flag-problems-0814">MIT researchers use large language models to flag problems in complex systems</a> <span class="domain">(<a href="https://news.mit.edu">news.mit.edu</a>)</span></div><div class="subtext"><span>fluxify</span> | <span>13 comments</span></div><br/><div><div id="41253963" class="c"><input type="checkbox" id="c-41253963" checked=""/><div class="controls bullet"><span class="by">mdp2021</span><span>|</span><a href="#41253986">next</a><span>|</span><label class="collapse" for="c-41253963">[-]</label><label class="expand" for="c-41253963">[1 more]</label></div><br/><div class="children"><div class="content">This exercise seems like highlighting the need for a cheap (under use), all-purpose framework for an efficient function approximator (as bare ML is too costly).<p>They are trying LLMs for this purpose, but maybe the structure of an optimal architecture should be studied.</div><br/></div></div><div id="41253986" class="c"><input type="checkbox" id="c-41253986" checked=""/><div class="controls bullet"><span class="by">glutamate</span><span>|</span><a href="#41253963">prev</a><span>|</span><a href="#41253767">next</a><span>|</span><label class="collapse" for="c-41253986">[-]</label><label class="expand" for="c-41253986">[5 more]</label></div><br/><div class="children"><div class="content">Some people, when confronted with a complex system, think &quot;I know, I&#x27;ll use a large language model.&quot; Now they have two complex systems interacting.</div><br/><div id="41254048" class="c"><input type="checkbox" id="c-41254048" checked=""/><div class="controls bullet"><span class="by">cqqxo4zV46cp</span><span>|</span><a href="#41253986">parent</a><span>|</span><a href="#41254076">next</a><span>|</span><label class="collapse" for="c-41254048">[-]</label><label class="expand" for="c-41254048">[3 more]</label></div><br/><div class="children"><div class="content">Some people trivialise things in bad faith to score internet points on Hacker News, I guess.
 The status quo, per the article, was already using “deep learning” models to perform anomaly detection. We are already talking about complex, black-box systems.<p>The stated advantage was that they didn’t require deployment-specific training. You can just throw a pre-trained LLM at it. There is also a stated benefit: early-stage detection, without needing to pay for, or wait for, training a custom ML model.
The article is quite open about the fact that the LLM approach doesn’t beat the state of the art in terms of accuracy.<p>It’s like you didn’t click the link.</div><br/><div id="41254198" class="c"><input type="checkbox" id="c-41254198" checked=""/><div class="controls bullet"><span class="by">glutamate</span><span>|</span><a href="#41253986">root</a><span>|</span><a href="#41254048">parent</a><span>|</span><a href="#41254152">next</a><span>|</span><label class="collapse" for="c-41254198">[-]</label><label class="expand" for="c-41254198">[1 more]</label></div><br/><div class="children"><div class="content">Colour me old-fashioned, but i am really sceptical about a zero-shot general-purpose LLM-based anomaly detector being able to outperform a trivial, not-obviously-wrong ML&#x2F;statistical model calibrated on a small subset of the data that makes training extremely fast, in entirely new domains. And in anomaly detection, false negatives (and even false positives) can be very expensive.<p>The most promising role for LLMs in timeseries prediction is in extracting covariates from unstructured data, in the wind example, weather reports and geographically proximal social media posts.</div><br/></div></div><div id="41254152" class="c"><input type="checkbox" id="c-41254152" checked=""/><div class="controls bullet"><span class="by">mdp2021</span><span>|</span><a href="#41253986">root</a><span>|</span><a href="#41254048">parent</a><span>|</span><a href="#41254198">prev</a><span>|</span><a href="#41254076">next</a><span>|</span><label class="collapse" for="c-41254152">[-]</label><label class="expand" for="c-41254152">[1 more]</label></div><br/><div class="children"><div class="content">The metrics OP suggest increase with the transition from DL to LLMs (and OP had no immediate duty to discuss other metrics).</div><br/></div></div></div></div><div id="41254076" class="c"><input type="checkbox" id="c-41254076" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#41253986">parent</a><span>|</span><a href="#41254048">prev</a><span>|</span><a href="#41253767">next</a><span>|</span><label class="collapse" for="c-41254076">[-]</label><label class="expand" for="c-41254076">[1 more]</label></div><br/><div class="children"><div class="content">&gt;  Now they have two complex systems interacting.<p>As opposed to sending crowds of people to interact with the system? We are even more complex and less benchmarked&#x2F;tested than LLMs. At least the LLM is a known thing, we know its limitations, we can evaluate and compensate for their lacks.</div><br/></div></div></div></div><div id="41253767" class="c"><input type="checkbox" id="c-41253767" checked=""/><div class="controls bullet"><span class="by">qtwhat</span><span>|</span><a href="#41253986">prev</a><span>|</span><a href="#41253837">next</a><span>|</span><label class="collapse" for="c-41253767">[-]</label><label class="expand" for="c-41253767">[4 more]</label></div><br/><div class="children"><div class="content">Is this saying, we can use LLM to understand non-language signal?
Sounds fun!</div><br/><div id="41253982" class="c"><input type="checkbox" id="c-41253982" checked=""/><div class="controls bullet"><span class="by">lmpdev</span><span>|</span><a href="#41253767">parent</a><span>|</span><a href="#41253781">next</a><span>|</span><label class="collapse" for="c-41253982">[-]</label><label class="expand" for="c-41253982">[2 more]</label></div><br/><div class="children"><div class="content">Why not?<p>Whether through analogy or an actual underlying isomorphism between the mechanisms underpinning language and other domains, I don’t see a reason LLMs can’t occasionally have insights into non-language problems<p>Is it better than other methods? No. Is it efficient? Absolutely not.<p>I don’t work with LLMs but I think a lot of the HN’s users are prematurely skeptical of the potential low-hanging fruit across many domains that can be explored with these new, convenient but invariably suboptimal tools</div><br/><div id="41254058" class="c"><input type="checkbox" id="c-41254058" checked=""/><div class="controls bullet"><span class="by">cqqxo4zV46cp</span><span>|</span><a href="#41253767">root</a><span>|</span><a href="#41253982">parent</a><span>|</span><a href="#41253781">next</a><span>|</span><label class="collapse" for="c-41254058">[-]</label><label class="expand" for="c-41254058">[1 more]</label></div><br/><div class="children"><div class="content">Prematurely skeptical because there’s a large contingent of people that have conflated being loudly dismissive with being actually intelligent, which I find quite enjoyable since the dismissiveness usually manifests as armchair Dunning Kruger philosophising about what “intelligence” is.
 Software engineering, as an industry, has a massive NIH problem when it comes to literally any other field of study.</div><br/></div></div></div></div><div id="41253781" class="c"><input type="checkbox" id="c-41253781" checked=""/><div class="controls bullet"><span class="by">viraptor</span><span>|</span><a href="#41253767">parent</a><span>|</span><a href="#41253982">prev</a><span>|</span><a href="#41253837">next</a><span>|</span><label class="collapse" for="c-41253781">[-]</label><label class="expand" for="c-41253781">[1 more]</label></div><br/><div class="children"><div class="content">Yes, those systems can understand a bit of math. But it&#x27;s weird that they would seriously try that given <a href="https:&#x2F;&#x2F;github.com&#x2F;NX-AI&#x2F;xlstm">https:&#x2F;&#x2F;github.com&#x2F;NX-AI&#x2F;xlstm</a> already exists.<p>I mean, it&#x27;s cool to know that it works, but I don&#x27;t get why would they invest any more time trying to improve the results.</div><br/></div></div></div></div><div id="41253837" class="c"><input type="checkbox" id="c-41253837" checked=""/><div class="controls bullet"><span class="by">beardyw</span><span>|</span><a href="#41253767">prev</a><span>|</span><label class="collapse" for="c-41253837">[-]</label><label class="expand" for="c-41253837">[2 more]</label></div><br/><div class="children"><div class="content">&gt; converts time-series data into text-based inputs an LLM can process.<p>What? Which the model then tokenizes? I am struggling to make sense of this.</div><br/><div id="41253847" class="c"><input type="checkbox" id="c-41253847" checked=""/><div class="controls bullet"><span class="by">ubercore</span><span>|</span><a href="#41253837">parent</a><span>|</span><label class="collapse" for="c-41253847">[-]</label><label class="expand" for="c-41253847">[1 more]</label></div><br/><div class="children"><div class="content">I read this as basically finding a language representation of timeseries data that would be understood by LLMs better than feeding raw records. I&#x27;m guessing it tokenizes very similarly to any other LLM. Perhaps I misread, though.</div><br/></div></div></div></div></div></div></div></div></div></body></html>