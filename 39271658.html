<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1707382873907" as="style"/><link rel="stylesheet" href="styles.css?v=1707382873907"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://helixml.substack.com/p/how-we-got-fine-tuning-mistral-7b">How we got fine-tuning Mistral-7B to not suck</a> <span class="domain">(<a href="https://helixml.substack.com">helixml.substack.com</a>)</span></div><div class="subtext"><span>lewq</span> | <span>15 comments</span></div><br/><div><div id="39299722" class="c"><input type="checkbox" id="c-39299722" checked=""/><div class="controls bullet"><span class="by">isaacfrond</span><span>|</span><a href="#39299389">next</a><span>|</span><label class="collapse" for="c-39299722">[-]</label><label class="expand" for="c-39299722">[1 more]</label></div><br/><div class="children"><div class="content">If you look at the source [1] you can see how they solved their what are the doctors going to do problem. It is literally included in one of the prompts now :-)<p><i>Users tend to ask broad, vague questions of the document in order to test that the system is working. We want those queries to work well. For example, a user would ask &quot;what are the doctors going to do?&quot; of a document that is about a junior doctors&#x27; strike. Take this into account when generating the questions - in particular, refer to noun phrases by less specific descriptions, so for example instead of &quot;junior doctors&quot;, say &quot;doctors&quot; in your questions.</i><p>[1]: <a href="https:&#x2F;&#x2F;github.com&#x2F;helixml&#x2F;helix&#x2F;blob&#x2F;main&#x2F;api&#x2F;pkg&#x2F;dataprep&#x2F;qapairs&#x2F;qapair_config.yaml">https:&#x2F;&#x2F;github.com&#x2F;helixml&#x2F;helix&#x2F;blob&#x2F;main&#x2F;api&#x2F;pkg&#x2F;dataprep&#x2F;...</a></div><br/></div></div><div id="39299389" class="c"><input type="checkbox" id="c-39299389" checked=""/><div class="controls bullet"><span class="by">joshka</span><span>|</span><a href="#39299722">prev</a><span>|</span><a href="#39298136">next</a><span>|</span><label class="collapse" for="c-39299389">[-]</label><label class="expand" for="c-39299389">[1 more]</label></div><br/><div class="children"><div class="content">For helix, I notice that GitHub is listed as a data source, but there&#x27;s nothing in the docs about this. I&#x27;d really love to see what a model trained on my commonly used git repos (which generally are newer than The Stack etc), and in particular their commit history. Ideally these would make it easier for code completion to have the historical context as well as the current code to play with in determining what to write next.<p>I often wonder how you&#x27;d go about organizing training data for a full historic github repo in a way that makes sense for training (or RAG)? The vast majority of the data is previous changes to the repo. I think this would generally mean that it would outweigh the current information and cause problems (i.e. old method names before refactoring etc.)<p>Also, perhaps being able to expand that out to doing the same thing for a bunch of consumers of the library that I&#x27;m maintaining would be neat.<p>Sprinkle in the PR and Issue history, docs website, API docs, and discord history and I think you&#x27;d have a helluva model.</div><br/></div></div><div id="39298136" class="c"><input type="checkbox" id="c-39298136" checked=""/><div class="controls bullet"><span class="by">cuuupid</span><span>|</span><a href="#39299389">prev</a><span>|</span><a href="#39296806">next</a><span>|</span><label class="collapse" for="c-39298136">[-]</label><label class="expand" for="c-39298136">[1 more]</label></div><br/><div class="children"><div class="content">Not in love with axolotl but appreciate the advantages. This is an interesting approach, but you can also finetune easily on providers who wrap axolotl like Replicate [1], Modal [2], or if you want to run the infra, LLM Engine [3].<p>My only gripe with Helix would be that it&#x27;s smaller than the above and my org would be peeved about data security. The ability to self host is cool, but too much can go wrong too quickly with plain Docker ML. Would love to see, for example, a `cog` version of the images that we can deploy distributed with more confidence&#x2F;bravado.<p>[1] <a href="https:&#x2F;&#x2F;replicate.com&#x2F;mistralai&#x2F;mistral-7b-instruct-v0.2">https:&#x2F;&#x2F;replicate.com&#x2F;mistralai&#x2F;mistral-7b-instruct-v0.2</a>
[2] <a href="https:&#x2F;&#x2F;modal.com" rel="nofollow">https:&#x2F;&#x2F;modal.com</a>
[3] <a href="https:&#x2F;&#x2F;llm-engine.scale.com&#x2F;" rel="nofollow">https:&#x2F;&#x2F;llm-engine.scale.com&#x2F;</a></div><br/></div></div><div id="39296806" class="c"><input type="checkbox" id="c-39296806" checked=""/><div class="controls bullet"><span class="by">bugglebeetle</span><span>|</span><a href="#39298136">prev</a><span>|</span><a href="#39298382">next</a><span>|</span><label class="collapse" for="c-39296806">[-]</label><label class="expand" for="c-39296806">[2 more]</label></div><br/><div class="children"><div class="content">Unsloth’s colab notebooks for fine-tuning Mistral-7B are super easy to use and run fine in just about any colab instance:<p><a href="https:&#x2F;&#x2F;github.com&#x2F;unslothai&#x2F;unsloth">https:&#x2F;&#x2F;github.com&#x2F;unslothai&#x2F;unsloth</a><p>It’s my default now for experimenting and basic training. If I want to get into the weeds, I use axolotl, but 9&#x2F;10, it’s not really necessary.</div><br/><div id="39299685" class="c"><input type="checkbox" id="c-39299685" checked=""/><div class="controls bullet"><span class="by">3abiton</span><span>|</span><a href="#39296806">parent</a><span>|</span><a href="#39298382">next</a><span>|</span><label class="collapse" for="c-39299685">[-]</label><label class="expand" for="c-39299685">[1 more]</label></div><br/><div class="children"><div class="content">How much improvement do you get by finetuning?</div><br/></div></div></div></div><div id="39298382" class="c"><input type="checkbox" id="c-39298382" checked=""/><div class="controls bullet"><span class="by">nicolezhu</span><span>|</span><a href="#39296806">prev</a><span>|</span><a href="#39284786">next</a><span>|</span><label class="collapse" for="c-39298382">[-]</label><label class="expand" for="c-39298382">[1 more]</label></div><br/><div class="children"><div class="content">What are some os &#x2F; hardware specific challenges you guys faced?</div><br/></div></div><div id="39284786" class="c"><input type="checkbox" id="c-39284786" checked=""/><div class="controls bullet"><span class="by">HanClinto</span><span>|</span><a href="#39298382">prev</a><span>|</span><a href="#39272245">next</a><span>|</span><label class="collapse" for="c-39284786">[-]</label><label class="expand" for="c-39284786">[1 more]</label></div><br/><div class="children"><div class="content">Fantastic writeup -- thank you so much for sharing your lessons learned along the way! Very valuable resource, and I&#x27;ll be checking out your product!</div><br/></div></div><div id="39272245" class="c"><input type="checkbox" id="c-39272245" checked=""/><div class="controls bullet"><span class="by">deforciant</span><span>|</span><a href="#39284786">prev</a><span>|</span><label class="collapse" for="c-39272245">[-]</label><label class="expand" for="c-39272245">[7 more]</label></div><br/><div class="children"><div class="content">I always thought that fine tuning is more like getting a style rather than memorizing information word to word or at least the facts. What are the next steps to ensure that it doesn&#x27;t start pulling info from the base knowledge and reference the docs instead? 
How long does it usually take to train? 10-15 minutes on what doc size?</div><br/><div id="39277909" class="c"><input type="checkbox" id="c-39277909" checked=""/><div class="controls bullet"><span class="by">lewq</span><span>|</span><a href="#39272245">parent</a><span>|</span><a href="#39272558">next</a><span>|</span><label class="collapse" for="c-39277909">[-]</label><label class="expand" for="c-39277909">[5 more]</label></div><br/><div class="children"><div class="content">Fine tuning is just more training -- so it&#x27;s definitely possible to teach the model facts this way too.<p>In practice we&#x27;ve found that it&#x27;s a bit of a balancing act to teach the model the new knowledge without destroying existing knowledge, but it&#x27;s just a matter of tuning the parameters carefully. We&#x27;re also researching whether we can fine-tune a brand new expert in a MoE model like Mixtral, I&#x27;ve also seen work on fine-tuning just a fixed set of weights. I&#x27;m sure there will be more developments in this space soon.<p>In terms of how you refer to new knowledge and not base knowledge, like many things in LLMs, you just ask the LLM :-) For example, if you look at this session <a href="https:&#x2F;&#x2F;app.tryhelix.ai&#x2F;session&#x2F;62905598-b1b7-4d93-bc39-5a935492ac5a" rel="nofollow">https:&#x2F;&#x2F;app.tryhelix.ai&#x2F;session&#x2F;62905598-b1b7-4d93-bc39-5a93...</a> and click &quot;Show Info&quot; at the top, you can see the system prompt is:<p>&quot;You are an intelligent chatbot named Helix that has been fine-tuned on document(s) e1ef2e896c in document group 62905598b1. The document group contains 1 document(s). The user will ask you questions about these documents: you must ONLY answer with context from the documents listed. Do NOT refer to background knowledge.&quot;<p>It does a pretty good job at this, although I&#x27;m sure there are ways to improve it further.<p>Referencing the specific document IDs in the fine-tuning was an innovation that has really helped us.<p>In terms of training time, yeah - 5 minutes on a news article, 10 minutes on a typical length paper. Pretty usable. We&#x27;re experimenting with reducing the number of epochs and increasing the learning rate to make it faster at that too.</div><br/><div id="39299262" class="c"><input type="checkbox" id="c-39299262" checked=""/><div class="controls bullet"><span class="by">gbickford</span><span>|</span><a href="#39272245">root</a><span>|</span><a href="#39277909">parent</a><span>|</span><a href="#39298020">next</a><span>|</span><label class="collapse" for="c-39299262">[-]</label><label class="expand" for="c-39299262">[1 more]</label></div><br/><div class="children"><div class="content">Have you tried generating two sets of qapairs, one with bad answers, and using DPO?</div><br/></div></div><div id="39298020" class="c"><input type="checkbox" id="c-39298020" checked=""/><div class="controls bullet"><span class="by">aCoreyJ</span><span>|</span><a href="#39272245">root</a><span>|</span><a href="#39277909">parent</a><span>|</span><a href="#39299262">prev</a><span>|</span><a href="#39272558">next</a><span>|</span><label class="collapse" for="c-39298020">[-]</label><label class="expand" for="c-39298020">[3 more]</label></div><br/><div class="children"><div class="content">What is the advantage over using Retrieval Augmented Generation ?</div><br/><div id="39298126" class="c"><input type="checkbox" id="c-39298126" checked=""/><div class="controls bullet"><span class="by">aCoreyJ</span><span>|</span><a href="#39272245">root</a><span>|</span><a href="#39298020">parent</a><span>|</span><a href="#39298122">next</a><span>|</span><label class="collapse" for="c-39298126">[-]</label><label class="expand" for="c-39298126">[1 more]</label></div><br/><div class="children"><div class="content">Actually missed this was covered in the post, thanks</div><br/></div></div><div id="39298122" class="c"><input type="checkbox" id="c-39298122" checked=""/><div class="controls bullet"><span class="by">aCoreyJ</span><span>|</span><a href="#39272245">root</a><span>|</span><a href="#39298020">parent</a><span>|</span><a href="#39298126">prev</a><span>|</span><a href="#39272558">next</a><span>|</span><label class="collapse" for="c-39298122">[-]</label><label class="expand" for="c-39298122">[1 more]</label></div><br/><div class="children"><div class="content">Actually missed this is answered in the article!</div><br/></div></div></div></div></div></div><div id="39272558" class="c"><input type="checkbox" id="c-39272558" checked=""/><div class="controls bullet"><span class="by">drphilwinder</span><span>|</span><a href="#39272245">parent</a><span>|</span><a href="#39277909">prev</a><span>|</span><label class="collapse" for="c-39272558">[-]</label><label class="expand" for="c-39272558">[1 more]</label></div><br/><div class="children"><div class="content">Your sentiment is correct, but it&#x27;s more of a spectrum. Fine tuning can learn facts (otherwise how would the foundation models learn facts?). But it needs those facts in the training dataset. If you have an infinite amount of facts, then you can memorise all of them.<p>The challenge arises when it becomes hard to generate that training data. If you just have the raw text and pop that in the context (i.e. RAG), then the LLM can be just as factual without any of that hassle.<p>Q2: identifiers in the prompt to say &quot;you&#x27;ve been trained on this, only answer questions about this&quot;.<p>Q3: Depends on the size of the training data&#x2F;docs. For the average PDF, about 30 minutes.<p>Give it a try!</div><br/></div></div></div></div></div></div></div></div></div></body></html>