<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1692262859981" as="style"/><link rel="stylesheet" href="styles.css?v=1692262859981"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://community.intel.com/t5/Blogs/Tech-Innovation/Artificial-Intelligence-AI/Intel-QuickAssist-Technology-Zstandard-Plugin-an-External/post/1509818">Intel QuickAssist Technology Zstandard Plugin for Zstandard</a> <span class="domain">(<a href="https://community.intel.com">community.intel.com</a>)</span></div><div class="subtext"><span>ot</span> | <span>44 comments</span></div><br/><div><div id="37155986" class="c"><input type="checkbox" id="c-37155986" checked=""/><div class="controls bullet"><span class="by">berbec</span><span>|</span><a href="#37155541">next</a><span>|</span><label class="collapse" for="c-37155986">[-]</label><label class="expand" for="c-37155986">[4 more]</label></div><br/><div class="children"><div class="content">A massive power and CPU load decrease in Zstandard is a big win for Intel. AMD has been racking up major pluses in the enterprise space, with RAM, PCIE and core count advantage. Showing that <i>any</i> Intel is faster at such a major CPU load task is a big deal.<p>That&#x27;s not to detract from everything AMD has done, but hardware is only the first step. Software that properly uses the features your hardware provides is just, if not more, important.<p>I love the fact AMD is pushing Intel so much. Pre-C2D days were amazing because we had two vibrant, innovative companies pushing to the edge of possible; trying to out-do each other. Pre-Ryzen was a horrible time. Do you want to spend $500 to upgrade from a 4-core intel 4000-cpu to an intel 5000-cpu? You&#x27;ll get DDR4 and 1% IPC.<p>Now we get massive IPC, clock speed, ram and PCIE improvements on a regular basis. Competition is great, especially for the consumer.</div><br/><div id="37158278" class="c"><input type="checkbox" id="c-37158278" checked=""/><div class="controls bullet"><span class="by">jiggawatts</span><span>|</span><a href="#37155986">parent</a><span>|</span><a href="#37155541">next</a><span>|</span><label class="collapse" for="c-37158278">[-]</label><label class="expand" for="c-37158278">[3 more]</label></div><br/><div class="children"><div class="content">From the benchmarks I’ve seen, QAT is a desperate attempt to gain <i>some</i> competitive advantage over AMD. It’s not clear if there is any actual advantage for real workloads.<p>Sure, benchmarks of pure compression will come out ahead for Intel, but a typical sever running something like a database engine with compressed disk storage is likely a win for AMD.<p>The new EPYC 9004 chips are much cheaper than the Intel CPUs with QAT, and they have more cores, and much higher clock speeds.<p>It’s hard to believe there’s any scenario where the Xeon CPUs provide better overall value…</div><br/><div id="37158601" class="c"><input type="checkbox" id="c-37158601" checked=""/><div class="controls bullet"><span class="by">nvm0n2</span><span>|</span><a href="#37155986">root</a><span>|</span><a href="#37158278">parent</a><span>|</span><a href="#37155541">next</a><span>|</span><label class="collapse" for="c-37158601">[-]</label><label class="expand" for="c-37158601">[2 more]</label></div><br/><div class="children"><div class="content">How is compression not a real workload? Zstd is an excellent codec that&#x27;s rapidly proliferating - for example Chrome is integrating it at the moment.<p><a href="https:&#x2F;&#x2F;bugs.chromium.org&#x2F;p&#x2F;chromium&#x2F;issues&#x2F;detail?id=1246971" rel="nofollow noreferrer">https:&#x2F;&#x2F;bugs.chromium.org&#x2F;p&#x2F;chromium&#x2F;issues&#x2F;detail?id=124697...</a><p>Relatively few servers run databases. Many more are running web servers and given the huge efforts web devs go to in order to optimize response sizes, much faster, lower power <i>and</i> lower latency compression seems like an instant win. All that&#x27;s required is for web servers to integrate the zstd library and this QAT thing, and that can be enough to tip the balance especially for IO bound servers that are mostly just doing string interpolation and waiting for backends.<p>And you mention a DB with compressed disk storage. How is better compression <i>not</i> a huge win for that use case? Databases are usually disk IOP, latency and CPU power constrained, and this is a win for all of those cases.<p>Finally, clearly this tech can be applied to other algorithms not just zstd. Presumably they highlight zstd because the library is actively maintained and was willing to add this (probably single use) &quot;plugin&quot; API. Really they should have just integrated it directly instead of complicating things for every zstd user, but I guess it adds extra dependencies or increases code size or something. The wins are big enough that other codec libraries will probably use the same approach and eventually it&#x27;ll be abstracted by APIs that are less code size sensitive.<p>Yes, AMD is doing great right now, but Intel have had an edge when it comes to specialized CPU features for a long time. For example AMD are only just now catching up to where Intel were with SGX 8 years ago.</div><br/><div id="37158846" class="c"><input type="checkbox" id="c-37158846" checked=""/><div class="controls bullet"><span class="by">saagarjha</span><span>|</span><a href="#37155986">root</a><span>|</span><a href="#37158601">parent</a><span>|</span><a href="#37155541">next</a><span>|</span><label class="collapse" for="c-37158846">[-]</label><label class="expand" for="c-37158846">[1 more]</label></div><br/><div class="children"><div class="content">&gt; For example AMD are only just now catching up to where Intel were with SGX 8 years ago.<p>Ah yes, being hopelessly broken?</div><br/></div></div></div></div></div></div></div></div><div id="37155541" class="c"><input type="checkbox" id="c-37155541" checked=""/><div class="controls bullet"><span class="by">jeffbee</span><span>|</span><a href="#37155986">prev</a><span>|</span><a href="#37157824">next</a><span>|</span><label class="collapse" for="c-37155541">[-]</label><label class="expand" for="c-37155541">[14 more]</label></div><br/><div class="children"><div class="content">I love the QAT libraries and I feel their abilities are overlooked. Intel also has the igzip library that does not even require QAT and it radically faster than zlib, which is handy in older applications where gzip is unavoidable despite its obsolescence.<p>The major downside of course is it is quite tricky to use this stuff in practice. In the cloud, you need a bare metal instance that exposes the QAT peripheral, and they are relatively scarce. And this whole generation of hardware is only just beginning to land in public clouds. For machines you own, you will need to scrutinize Intel&#x27;s somewhat ridiculous product matrix in order to acquire a Xeon that has QAT.</div><br/><div id="37156870" class="c"><input type="checkbox" id="c-37156870" checked=""/><div class="controls bullet"><span class="by">brirec</span><span>|</span><a href="#37155541">parent</a><span>|</span><a href="#37156230">next</a><span>|</span><label class="collapse" for="c-37156870">[-]</label><label class="expand" for="c-37156870">[1 more]</label></div><br/><div class="children"><div class="content">QAT does support SR-IOV on platforms with IOMMU support, so you can at least delegate access to QAT across multiple VMs. I don’t think any public cloud providers offer this, though.</div><br/></div></div><div id="37156230" class="c"><input type="checkbox" id="c-37156230" checked=""/><div class="controls bullet"><span class="by">andrius4669</span><span>|</span><a href="#37155541">parent</a><span>|</span><a href="#37156870">prev</a><span>|</span><a href="#37156282">next</a><span>|</span><label class="collapse" for="c-37156230">[-]</label><label class="expand" for="c-37156230">[3 more]</label></div><br/><div class="children"><div class="content">any idea how igzip&#x27;s non-QAT path compares to zlib-ng[1]?<p>[1] <a href="https:&#x2F;&#x2F;github.com&#x2F;zlib-ng&#x2F;zlib-ng">https:&#x2F;&#x2F;github.com&#x2F;zlib-ng&#x2F;zlib-ng</a></div><br/><div id="37158636" class="c"><input type="checkbox" id="c-37158636" checked=""/><div class="controls bullet"><span class="by">powturbo</span><span>|</span><a href="#37155541">root</a><span>|</span><a href="#37156230">parent</a><span>|</span><a href="#37156413">next</a><span>|</span><label class="collapse" for="c-37158636">[-]</label><label class="expand" for="c-37158636">[1 more]</label></div><br/><div class="children"><div class="content">You can use TurboBench [1] to benchmark igzip, zlib-ng and others.<p>Download TurbBench from Releases [2]<p>Here Some Benchmarks:<p>- <a href="https:&#x2F;&#x2F;github.com&#x2F;zlib-ng&#x2F;zlib-ng&#x2F;issues&#x2F;1486">https:&#x2F;&#x2F;github.com&#x2F;zlib-ng&#x2F;zlib-ng&#x2F;issues&#x2F;1486</a><p>- <a href="https:&#x2F;&#x2F;github.com&#x2F;powturbo&#x2F;TurboBench&#x2F;issues&#x2F;43">https:&#x2F;&#x2F;github.com&#x2F;powturbo&#x2F;TurboBench&#x2F;issues&#x2F;43</a><p>[1] <a href="https:&#x2F;&#x2F;github.com&#x2F;powturbo&#x2F;TurboBench">https:&#x2F;&#x2F;github.com&#x2F;powturbo&#x2F;TurboBench</a><p>[2] <a href="https:&#x2F;&#x2F;github.com&#x2F;powturbo&#x2F;TurboBench&#x2F;releases">https:&#x2F;&#x2F;github.com&#x2F;powturbo&#x2F;TurboBench&#x2F;releases</a></div><br/></div></div><div id="37156413" class="c"><input type="checkbox" id="c-37156413" checked=""/><div class="controls bullet"><span class="by">jeffbee</span><span>|</span><a href="#37155541">root</a><span>|</span><a href="#37156230">parent</a><span>|</span><a href="#37158636">prev</a><span>|</span><a href="#37156282">next</a><span>|</span><label class="collapse" for="c-37156413">[-]</label><label class="expand" for="c-37156413">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s fairly easy to check for yourself, but with local builds on a desktop CPU without QAT, compressing a 150MB JSON input, with igzip and minigzip (from zlib-ng) both producing a smaller output than gzip, gzip needs 1.187s, minigzip needs 0.665s, and igzip needs 0.313s.</div><br/></div></div></div></div><div id="37156282" class="c"><input type="checkbox" id="c-37156282" checked=""/><div class="controls bullet"><span class="by">pizza</span><span>|</span><a href="#37155541">parent</a><span>|</span><a href="#37156230">prev</a><span>|</span><a href="#37155679">next</a><span>|</span><label class="collapse" for="c-37156282">[-]</label><label class="expand" for="c-37156282">[1 more]</label></div><br/><div class="children"><div class="content">This is great, I can think of several places where zlib is the bottleneck and would love to speed them up</div><br/></div></div><div id="37155679" class="c"><input type="checkbox" id="c-37155679" checked=""/><div class="controls bullet"><span class="by">VWWHFSfQ</span><span>|</span><a href="#37155541">parent</a><span>|</span><a href="#37156282">prev</a><span>|</span><a href="#37156500">next</a><span>|</span><label class="collapse" for="c-37155679">[-]</label><label class="expand" for="c-37155679">[7 more]</label></div><br/><div class="children"><div class="content">&gt; older applications where gzip is unavoidable despite its obsolescence<p>Is gzip actually obsolete or are there just newer alternatives?  gzip is still everywhere</div><br/><div id="37155709" class="c"><input type="checkbox" id="c-37155709" checked=""/><div class="controls bullet"><span class="by">jeffbee</span><span>|</span><a href="#37155541">root</a><span>|</span><a href="#37155679">parent</a><span>|</span><a href="#37156500">next</a><span>|</span><label class="collapse" for="c-37155709">[-]</label><label class="expand" for="c-37155709">[6 more]</label></div><br/><div class="children"><div class="content">The zlib implementation is not optimal in any way that I am aware of. You can get better compression with the same compute time, and you can get the same compression with less time, in every application I have seen, by using some other thing. I usually want to look at zstd, lz4, and brotli in addition to zlib.<p>That said, the igzip re-implementation is really good. If you can use it, igzip moves gzip closer to the optimal frontier.</div><br/><div id="37156718" class="c"><input type="checkbox" id="c-37156718" checked=""/><div class="controls bullet"><span class="by">jandrese</span><span>|</span><a href="#37155541">root</a><span>|</span><a href="#37155709">parent</a><span>|</span><a href="#37155923">next</a><span>|</span><label class="collapse" for="c-37156718">[-]</label><label class="expand" for="c-37156718">[1 more]</label></div><br/><div class="children"><div class="content">The only place gzip wins is in compatibility.  <i>Everything</i> supports gzip.  zstd, lz4, brotli, and others aren&#x27;t included by default in most places yet, although the situation is starting to improve.<p>Plus, if you want super compatibility there is older-than-dirt pkzip&#x2F;infozip.</div><br/></div></div><div id="37155923" class="c"><input type="checkbox" id="c-37155923" checked=""/><div class="controls bullet"><span class="by">rincebrain</span><span>|</span><a href="#37155541">root</a><span>|</span><a href="#37155709">parent</a><span>|</span><a href="#37156718">prev</a><span>|</span><a href="#37158267">next</a><span>|</span><label class="collapse" for="c-37155923">[-]</label><label class="expand" for="c-37155923">[2 more]</label></div><br/><div class="children"><div class="content">There&#x27;s also the various zlib forks by cloudflare et al, if you want to go down that road.<p>But yes, lz4 and zstd would be what I&#x27;d recommend people use.</div><br/><div id="37157293" class="c"><input type="checkbox" id="c-37157293" checked=""/><div class="controls bullet"><span class="by">dralley</span><span>|</span><a href="#37155541">root</a><span>|</span><a href="#37155923">parent</a><span>|</span><a href="#37158267">next</a><span>|</span><label class="collapse" for="c-37157293">[-]</label><label class="expand" for="c-37157293">[1 more]</label></div><br/><div class="children"><div class="content">The code quality of some of the cloudflare changes is questionable. Optimizations aren&#x27;t cleanly separated by commits, some of the licensing is dicey, etc.<p>zlib-ng tried to merge as much as they could from the cloudflare fork without getting into licensing issues.</div><br/></div></div></div></div><div id="37158267" class="c"><input type="checkbox" id="c-37158267" checked=""/><div class="controls bullet"><span class="by">benatkin</span><span>|</span><a href="#37155541">root</a><span>|</span><a href="#37155709">parent</a><span>|</span><a href="#37155923">prev</a><span>|</span><a href="#37156500">next</a><span>|</span><label class="collapse" for="c-37158267">[-]</label><label class="expand" for="c-37158267">[2 more]</label></div><br/><div class="children"><div class="content">it&#x27;s optimal in that it&#x27;s a community project and not an extremely unethical BigCorp project</div><br/><div id="37158413" class="c"><input type="checkbox" id="c-37158413" checked=""/><div class="controls bullet"><span class="by">jeffbee</span><span>|</span><a href="#37155541">root</a><span>|</span><a href="#37158267">parent</a><span>|</span><a href="#37156500">next</a><span>|</span><label class="collapse" for="c-37158413">[-]</label><label class="expand" for="c-37158413">[1 more]</label></div><br/><div class="children"><div class="content">Are you suggesting that lz4 is unethical?</div><br/></div></div></div></div></div></div></div></div><div id="37156500" class="c"><input type="checkbox" id="c-37156500" checked=""/><div class="controls bullet"><span class="by">selectodude</span><span>|</span><a href="#37155541">parent</a><span>|</span><a href="#37155679">prev</a><span>|</span><a href="#37157824">next</a><span>|</span><label class="collapse" for="c-37156500">[-]</label><label class="expand" for="c-37156500">[1 more]</label></div><br/><div class="children"><div class="content">Intel’s software is simply best in class (n=2).</div><br/></div></div></div></div><div id="37157824" class="c"><input type="checkbox" id="c-37157824" checked=""/><div class="controls bullet"><span class="by">sanqui</span><span>|</span><a href="#37155541">prev</a><span>|</span><a href="#37158479">next</a><span>|</span><label class="collapse" for="c-37157824">[-]</label><label class="expand" for="c-37157824">[1 more]</label></div><br/><div class="children"><div class="content">Btrfs, the file system I use, utilizes zstd for transparent compression. That&#x27;s using a lot of CPU all the time on laptop. So more efficient compressing is great news! Is this for future CPUs?</div><br/></div></div><div id="37158479" class="c"><input type="checkbox" id="c-37158479" checked=""/><div class="controls bullet"><span class="by">SilverBirch</span><span>|</span><a href="#37157824">prev</a><span>|</span><a href="#37157984">next</a><span>|</span><label class="collapse" for="c-37158479">[-]</label><label class="expand" for="c-37158479">[3 more]</label></div><br/><div class="children"><div class="content">This may be a really dumb question... but: Is this transparent? Like, can I compress some data using QAT to create a zstd file, email it to my friend and have them decompress it without QAT? From the way that this is described it sounds like they&#x27;re replacing the sequence producer, but presumably that doesn&#x27;t matter as long as the format you encode those sequences adhere to some standard format?</div><br/><div id="37158582" class="c"><input type="checkbox" id="c-37158582" checked=""/><div class="controls bullet"><span class="by">nvm0n2</span><span>|</span><a href="#37158479">parent</a><span>|</span><a href="#37158684">next</a><span>|</span><label class="collapse" for="c-37158582">[-]</label><label class="expand" for="c-37158582">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s right. The decoder doesn&#x27;t know.</div><br/></div></div><div id="37158684" class="c"><input type="checkbox" id="c-37158684" checked=""/><div class="controls bullet"><span class="by">ur-whale</span><span>|</span><a href="#37158479">parent</a><span>|</span><a href="#37158582">prev</a><span>|</span><a href="#37157984">next</a><span>|</span><label class="collapse" for="c-37158684">[-]</label><label class="expand" for="c-37158684">[1 more]</label></div><br/><div class="children"><div class="content">More importantly, how easy is this to deploy in a real world production situation?</div><br/></div></div></div></div><div id="37157984" class="c"><input type="checkbox" id="c-37157984" checked=""/><div class="controls bullet"><span class="by">loeg</span><span>|</span><a href="#37158479">prev</a><span>|</span><a href="#37158571">next</a><span>|</span><label class="collapse" for="c-37157984">[-]</label><label class="expand" for="c-37157984">[1 more]</label></div><br/><div class="children"><div class="content">Good to see more in the compression offload space.  Several years ago we ended up running a custom gzip softcore on an FPGA (I believe) co-located on a NIC to get somewhat better gzip compression performance than software.  (We were pretty short on PCIe physical capacity in that model.)<p>Dealing with the gzip core vendor and the FPGA vendor (both in wildly different timezones) was a little unpleasant.</div><br/></div></div><div id="37158571" class="c"><input type="checkbox" id="c-37158571" checked=""/><div class="controls bullet"><span class="by">ahofmann</span><span>|</span><a href="#37157984">prev</a><span>|</span><a href="#37157564">next</a><span>|</span><label class="collapse" for="c-37158571">[-]</label><label class="expand" for="c-37158571">[1 more]</label></div><br/><div class="children"><div class="content">Why do they show different compression levels in their graphs? That seems kind of fishy to me.</div><br/></div></div><div id="37157564" class="c"><input type="checkbox" id="c-37157564" checked=""/><div class="controls bullet"><span class="by">metta2uall</span><span>|</span><a href="#37158571">prev</a><span>|</span><a href="#37156527">next</a><span>|</span><label class="collapse" for="c-37157564">[-]</label><label class="expand" for="c-37157564">[3 more]</label></div><br/><div class="children"><div class="content">Interesting that Intel&#x27;s code for this includes numerous references to LZ4, as if that&#x27;s the actual algorithm the hardware originally aimed to accelerate.. So seems like LZ4 and ZSTD are quite similar?<p><a href="https:&#x2F;&#x2F;github.com&#x2F;intel&#x2F;QAT-ZSTD-Plugin&#x2F;blob&#x2F;main&#x2F;src&#x2F;qatseqprod.c">https:&#x2F;&#x2F;github.com&#x2F;intel&#x2F;QAT-ZSTD-Plugin&#x2F;blob&#x2F;main&#x2F;src&#x2F;qatse...</a></div><br/><div id="37157912" class="c"><input type="checkbox" id="c-37157912" checked=""/><div class="controls bullet"><span class="by">lifthrasiir</span><span>|</span><a href="#37157564">parent</a><span>|</span><a href="#37158193">next</a><span>|</span><label class="collapse" for="c-37157912">[-]</label><label class="expand" for="c-37157912">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s actually LZ4<i>S</i>, which is an intermediate format very similar to LZ4. LZ4 can be regarded as an LZSS-only compression format with no further coding, so any format that uses LZSS as its core modelling scheme will benefit from LZ4S acceleration. (QAT also has specific support for DEFLATE and Huffman coding, but that&#x27;s all.)</div><br/></div></div><div id="37158193" class="c"><input type="checkbox" id="c-37158193" checked=""/><div class="controls bullet"><span class="by">xxs</span><span>|</span><a href="#37157564">parent</a><span>|</span><a href="#37157912">prev</a><span>|</span><a href="#37156527">next</a><span>|</span><label class="collapse" for="c-37158193">[-]</label><label class="expand" for="c-37158193">[1 more]</label></div><br/><div class="children"><div class="content">Pretty much all LZ77 class of algorithms try finding longest matches in a dictionary. (both zstd, lz4... and deflate [(g)zip] are all lz77)</div><br/></div></div></div></div><div id="37156527" class="c"><input type="checkbox" id="c-37156527" checked=""/><div class="controls bullet"><span class="by">bitbckt</span><span>|</span><a href="#37157564">prev</a><span>|</span><a href="#37157385">next</a><span>|</span><label class="collapse" for="c-37156527">[-]</label><label class="expand" for="c-37156527">[1 more]</label></div><br/><div class="children"><div class="content">Finally. I’m tired of seeing zlib in QAT reviews alone - it’s largely irrelevant to situations where I might want to choose Intel (for QAT) over AMD.<p>I don’t fault Intel for choosing web frontend acceleration over storage first, but this has been a long time coming.</div><br/></div></div><div id="37157385" class="c"><input type="checkbox" id="c-37157385" checked=""/><div class="controls bullet"><span class="by">estebarb</span><span>|</span><a href="#37156527">prev</a><span>|</span><a href="#37156540">next</a><span>|</span><label class="collapse" for="c-37157385">[-]</label><label class="expand" for="c-37157385">[3 more]</label></div><br/><div class="children"><div class="content">Is there an easy way to use these accelerators from the CLI? Sometimes I have to decompress several TBs of gzip files, but I don&#x27;t want to rollout my own decompressor in C. I know that Graviton 2 includes a compression accelerator as well, but no idea how to use it (easily).</div><br/><div id="37158412" class="c"><input type="checkbox" id="c-37158412" checked=""/><div class="controls bullet"><span class="by">mxmlnkn</span><span>|</span><a href="#37157385">parent</a><span>|</span><a href="#37158201">next</a><span>|</span><label class="collapse" for="c-37158412">[-]</label><label class="expand" for="c-37158412">[1 more]</label></div><br/><div class="children"><div class="content">If you have large gzip files to decompress, I can recommend igzip[1] for fastest single-core decompression or my pet project rapidgzip[2] for effective multi-core decompression, both have simple CLI tools.
For using accelerators (QAT, I assume, because the article is about this) from the CLI, then QATzip[3] comes with a command line tool qatzip which can be used as described in the project ReadMe. I didn&#x27;t test it, though, as I have no QAT-enabled device.<p>[1] <a href="https:&#x2F;&#x2F;github.com&#x2F;intel&#x2F;isa-l&#x2F;tree&#x2F;master&#x2F;igzip">https:&#x2F;&#x2F;github.com&#x2F;intel&#x2F;isa-l&#x2F;tree&#x2F;master&#x2F;igzip</a>
[2] <a href="https:&#x2F;&#x2F;github.com&#x2F;mxmlnkn&#x2F;rapidgzip">https:&#x2F;&#x2F;github.com&#x2F;mxmlnkn&#x2F;rapidgzip</a>
[3] <a href="https:&#x2F;&#x2F;github.com&#x2F;intel&#x2F;QATzip#test-qatzip">https:&#x2F;&#x2F;github.com&#x2F;intel&#x2F;QATzip#test-qatzip</a></div><br/></div></div><div id="37158201" class="c"><input type="checkbox" id="c-37158201" checked=""/><div class="controls bullet"><span class="by">xxs</span><span>|</span><a href="#37157385">parent</a><span>|</span><a href="#37158412">prev</a><span>|</span><a href="#37156540">next</a><span>|</span><label class="collapse" for="c-37158201">[-]</label><label class="expand" for="c-37158201">[1 more]</label></div><br/><div class="children"><div class="content">The accelerator (at least this particular use) won&#x27;t help decompression.</div><br/></div></div></div></div><div id="37156540" class="c"><input type="checkbox" id="c-37156540" checked=""/><div class="controls bullet"><span class="by">pclmulqdq</span><span>|</span><a href="#37157385">prev</a><span>|</span><a href="#37156276">next</a><span>|</span><label class="collapse" for="c-37156540">[-]</label><label class="expand" for="c-37156540">[6 more]</label></div><br/><div class="children"><div class="content">QAT is awesome, and flips the script on the notion of core count primacy.  In many servers, QAT when properly used will save several CPU cores, since cores spend a lot of time compressing and encrypting stuff.  However, the software layer has always been Intel&#x27;s weakness, and I&#x27;m not entirely sure they got this one right.</div><br/><div id="37158655" class="c"><input type="checkbox" id="c-37158655" checked=""/><div class="controls bullet"><span class="by">nvm0n2</span><span>|</span><a href="#37156540">parent</a><span>|</span><a href="#37157062">next</a><span>|</span><label class="collapse" for="c-37158655">[-]</label><label class="expand" for="c-37158655">[1 more]</label></div><br/><div class="children"><div class="content">Intel&#x27;s software has always been pretty good for me. You&#x27;re complaining about the need for a driver, right? That seems reasonable, more like a weakness of cloud computing that it takes so long for clouds to expose the real capabilities of the hardware. It&#x27;s a win for those who can (re)master dedicated machines and attendant Linux sysadmin issues.</div><br/></div></div><div id="37157062" class="c"><input type="checkbox" id="c-37157062" checked=""/><div class="controls bullet"><span class="by">c_o_n_v_e_x</span><span>|</span><a href="#37156540">parent</a><span>|</span><a href="#37158655">prev</a><span>|</span><a href="#37156771">next</a><span>|</span><label class="collapse" for="c-37157062">[-]</label><label class="expand" for="c-37157062">[2 more]</label></div><br/><div class="children"><div class="content">Out of curiosity, what are some use cases?  The only one I&#x27;m even remotely familiar with is https encryption offloading.</div><br/><div id="37157301" class="c"><input type="checkbox" id="c-37157301" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#37156540">root</a><span>|</span><a href="#37157062">parent</a><span>|</span><a href="#37156771">next</a><span>|</span><label class="collapse" for="c-37157301">[-]</label><label class="expand" for="c-37157301">[1 more]</label></div><br/><div class="children"><div class="content">This sounds like it would be great for filesystem compression (e.g. ZFS).</div><br/></div></div></div></div><div id="37156771" class="c"><input type="checkbox" id="c-37156771" checked=""/><div class="controls bullet"><span class="by">bluedevilzn</span><span>|</span><a href="#37156540">parent</a><span>|</span><a href="#37157062">prev</a><span>|</span><a href="#37156276">next</a><span>|</span><label class="collapse" for="c-37156771">[-]</label><label class="expand" for="c-37156771">[2 more]</label></div><br/><div class="children"><div class="content">Is this available in any public cloud?</div><br/><div id="37156812" class="c"><input type="checkbox" id="c-37156812" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#37156540">root</a><span>|</span><a href="#37156771">parent</a><span>|</span><a href="#37156276">next</a><span>|</span><label class="collapse" for="c-37156812">[-]</label><label class="expand" for="c-37156812">[1 more]</label></div><br/><div class="children"><div class="content">AWS has it.</div><br/></div></div></div></div></div></div><div id="37156276" class="c"><input type="checkbox" id="c-37156276" checked=""/><div class="controls bullet"><span class="by">scrubs</span><span>|</span><a href="#37156540">prev</a><span>|</span><label class="collapse" for="c-37156276">[-]</label><label class="expand" for="c-37156276">[6 more]</label></div><br/><div class="children"><div class="content">Checking this out tomorrow. Side work project is better compressing 10s of TBs of files.</div><br/><div id="37156375" class="c"><input type="checkbox" id="c-37156375" checked=""/><div class="controls bullet"><span class="by">soulbadguy</span><span>|</span><a href="#37156276">parent</a><span>|</span><label class="collapse" for="c-37156375">[-]</label><label class="expand" for="c-37156375">[5 more]</label></div><br/><div class="children"><div class="content">Please report back your findings, I am sure I am not the only one wanting to see some real world results</div><br/><div id="37156679" class="c"><input type="checkbox" id="c-37156679" checked=""/><div class="controls bullet"><span class="by">throwaway81523</span><span>|</span><a href="#37156276">root</a><span>|</span><a href="#37156375">parent</a><span>|</span><label class="collapse" for="c-37156679">[-]</label><label class="expand" for="c-37156679">[4 more]</label></div><br/><div class="children"><div class="content">I&#x27;d like to know what QAT actually is?  Some kind of special purpose hardware extension for LZ and crypto?  I used to compress a lot of files using xz and it is slow, but not THAT slow.  I have a now-ancient 4 core i7 server and it takes a day or so hours to compress a TB of text.  I haven&#x27;t looked at it in a while and don&#x27;t remember actual numbers, but the point is that if you don&#x27;t need realtime response, the cpu usage of these algorithms is tolerable without special hardware.</div><br/><div id="37156783" class="c"><input type="checkbox" id="c-37156783" checked=""/><div class="controls bullet"><span class="by">jeffbee</span><span>|</span><a href="#37156276">root</a><span>|</span><a href="#37156679">parent</a><span>|</span><label class="collapse" for="c-37156783">[-]</label><label class="expand" for="c-37156783">[3 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a PCIe device that is either on a stick (earliest generation), integrated into the platform chipset, or integrated into the CPU (latest generation). Nobody outside Intel really knows what&#x27;s in it, but you submit requests to it and it encrypts, decrypts, checksums, or compresses something. If this sounds familiar it is because we had stuff like that in the 90s.</div><br/><div id="37157017" class="c"><input type="checkbox" id="c-37157017" checked=""/><div class="controls bullet"><span class="by">jevinskie</span><span>|</span><a href="#37156276">root</a><span>|</span><a href="#37156783">parent</a><span>|</span><label class="collapse" for="c-37157017">[-]</label><label class="expand" for="c-37157017">[2 more]</label></div><br/><div class="children"><div class="content">There is some enum or #define in a header I found recently that suggested there was once QAT acceleration of something XML related! I can’t find any documentation about it though.<p>edit: CPA_ACC_SVC_TYPE_XML <a href="https:&#x2F;&#x2F;github.com&#x2F;ravynsoft&#x2F;ravynos&#x2F;blob&#x2F;ee81203faa28ab3e6a987b1e2c4f3b759d02ebfa&#x2F;sys&#x2F;dev&#x2F;qat&#x2F;qat_api&#x2F;include&#x2F;cpa.h#L419">https:&#x2F;&#x2F;github.com&#x2F;ravynsoft&#x2F;ravynos&#x2F;blob&#x2F;ee81203faa28ab3e6a...</a></div><br/><div id="37157085" class="c"><input type="checkbox" id="c-37157085" checked=""/><div class="controls bullet"><span class="by">jeffbee</span><span>|</span><a href="#37156276">root</a><span>|</span><a href="#37157017">parent</a><span>|</span><label class="collapse" for="c-37157085">[-]</label><label class="expand" for="c-37157085">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;github.com&#x2F;intel&#x2F;qatlib&#x2F;blob&#x2F;main&#x2F;quickassist&#x2F;include&#x2F;cpa.h#L445">https:&#x2F;&#x2F;github.com&#x2F;intel&#x2F;qatlib&#x2F;blob&#x2F;main&#x2F;quickassist&#x2F;includ...</a><p>It also seems to suggest that it could accelerate hyperscan, but considering the hardware and software are both from Intel and they don&#x27;t integrate them, maybe it doesn&#x27;t work or is theoretical.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></body></html>