<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1698742865399" as="style"/><link rel="stylesheet" href="styles.css?v=1698742865399"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://knowingmachines.org/knowing-legal-machines/legal-explainer/questions/can-i-remove-my-personal-data-from-genai-training-datasets">Can I remove my personal data from GenAI training datasets?</a> <span class="domain">(<a href="https://knowingmachines.org">knowingmachines.org</a>)</span></div><div class="subtext"><span>randomlogin</span> | <span>73 comments</span></div><br/><div><div id="38079203" class="c"><input type="checkbox" id="c-38079203" checked=""/><div class="controls bullet"><span class="by">valianteffort</span><span>|</span><a href="#38077794">next</a><span>|</span><label class="collapse" for="c-38079203">[-]</label><label class="expand" for="c-38079203">[37 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t get it, you put that information on the internet, you have no expectation to privacy. But now maybe you learned a lesson, and you won&#x27;t publicly share things you don&#x27;t want people to see?</div><br/><div id="38080743" class="c"><input type="checkbox" id="c-38080743" checked=""/><div class="controls bullet"><span class="by">jjav</span><span>|</span><a href="#38079203">parent</a><span>|</span><a href="#38081389">next</a><span>|</span><label class="collapse" for="c-38080743">[-]</label><label class="expand" for="c-38080743">[3 more]</label></div><br/><div class="children"><div class="content">&gt; I don&#x27;t get it, you put that information on the internet, you have no expectation to privacy.<p>While that is somewhat true, there are multiple angles to it. The big one is expectations. It used to be that if you shared something on an obscure forum that had like 100 readers, most of those people expected that only 100 would see their posting. And it was true, so it reinforced the expectation for nontechnical people, which is basically everyone within a rounding error.<p>Then everything gets indexes and now fed to AI and suddenly billions of people have easy access to what they felt was very limited in distribution.<p>You could file this under &quot;People don&#x27;t threat model correctly&quot;, but also (more importantly) under the fact that technology should consider human nature before breaking expectations.</div><br/><div id="38081872" class="c"><input type="checkbox" id="c-38081872" checked=""/><div class="controls bullet"><span class="by">fsckboy</span><span>|</span><a href="#38079203">root</a><span>|</span><a href="#38080743">parent</a><span>|</span><a href="#38081059">next</a><span>|</span><label class="collapse" for="c-38081872">[-]</label><label class="expand" for="c-38081872">[1 more]</label></div><br/><div class="children"><div class="content">do you ever save things you see on the internet that have some &quot;scandal&quot; merit, say for example you don&#x27;t like Donald Trump and you come across a variety of material that&#x27;s embarrassing to him. Or your school bully, or your gf&#x27;s ex, or Macron in France, Trudeau in Canada, etc. Would you feel that other people should get to tell you to delete it because you&#x27;re not allowed to use any aids to help you remember or prove why they are bad people (in your estimation)? Freedom to remember is part and parcel of free speech.</div><br/></div></div><div id="38081059" class="c"><input type="checkbox" id="c-38081059" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#38079203">root</a><span>|</span><a href="#38080743">parent</a><span>|</span><a href="#38081872">prev</a><span>|</span><a href="#38081389">next</a><span>|</span><label class="collapse" for="c-38081059">[-]</label><label class="expand" for="c-38081059">[1 more]</label></div><br/><div class="children"><div class="content">You should consider the size of the training set as well. A blog post in a 30T dataset like RedPajama has less impact than one in a fine-tuning dataset of 1000 examples. The gradients from all tokens are added up, they stack on top of each other and their influence is diluted in larger datasets.</div><br/></div></div></div></div><div id="38081389" class="c"><input type="checkbox" id="c-38081389" checked=""/><div class="controls bullet"><span class="by">thefz</span><span>|</span><a href="#38079203">parent</a><span>|</span><a href="#38080743">prev</a><span>|</span><a href="#38079355">next</a><span>|</span><label class="collapse" for="c-38081389">[-]</label><label class="expand" for="c-38081389">[3 more]</label></div><br/><div class="children"><div class="content">This is similar to saying that if girls don&#x27;t want to be molested, they should not wear a mini skirt in public.<p>One may not have been aware of the future existence of AI when writing on a public platform.<p>Or one simply may want his blog&#x2F;thoughts to be intended for human consumption and not to train the latest commercial product which will reap from his content and not share any profit.</div><br/><div id="38081912" class="c"><input type="checkbox" id="c-38081912" checked=""/><div class="controls bullet"><span class="by">fsckboy</span><span>|</span><a href="#38079203">root</a><span>|</span><a href="#38081389">parent</a><span>|</span><a href="#38081909">next</a><span>|</span><label class="collapse" for="c-38081912">[-]</label><label class="expand" for="c-38081912">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>saying that if girls don&#x27;t want to be molested, they should not wear a mini skirt in public</i><p>such a ridiculous example if you are trying to convince me that you care about these girls&#x27; safety as opposed to some abstract egg-headed right.</div><br/></div></div><div id="38081909" class="c"><input type="checkbox" id="c-38081909" checked=""/><div class="controls bullet"><span class="by">scrollaway</span><span>|</span><a href="#38079203">root</a><span>|</span><a href="#38081389">parent</a><span>|</span><a href="#38081912">prev</a><span>|</span><a href="#38079355">next</a><span>|</span><label class="collapse" for="c-38081909">[-]</label><label class="expand" for="c-38081909">[1 more]</label></div><br/><div class="children"><div class="content">How is it similar to that strawman?<p>There is no expectation of privacy in public. That is pretty much the definition. It’s not victim blaming.</div><br/></div></div></div></div><div id="38079355" class="c"><input type="checkbox" id="c-38079355" checked=""/><div class="controls bullet"><span class="by">stingraycharles</span><span>|</span><a href="#38079203">parent</a><span>|</span><a href="#38081389">prev</a><span>|</span><a href="#38080027">next</a><span>|</span><label class="collapse" for="c-38079355">[-]</label><label class="expand" for="c-38079355">[11 more]</label></div><br/><div class="children"><div class="content">The “right to be forgotten” is an explicit right in the EU, which I think applies here.</div><br/><div id="38079455" class="c"><input type="checkbox" id="c-38079455" checked=""/><div class="controls bullet"><span class="by">qweqwe14</span><span>|</span><a href="#38079203">root</a><span>|</span><a href="#38079355">parent</a><span>|</span><a href="#38079413">next</a><span>|</span><label class="collapse" for="c-38079455">[-]</label><label class="expand" for="c-38079455">[7 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not saying that this right is a bad thing, but the reality is that it&#x27;s rarely enforceable. As soon as you put something on the internet, you have every &quot;right&quot; to expect that it&#x27;s there forever.<p>No amount of legislation can outweigh the technical reality.</div><br/><div id="38079521" class="c"><input type="checkbox" id="c-38079521" checked=""/><div class="controls bullet"><span class="by">esafak</span><span>|</span><a href="#38079203">root</a><span>|</span><a href="#38079455">parent</a><span>|</span><a href="#38079413">next</a><span>|</span><label class="collapse" for="c-38079521">[-]</label><label class="expand" for="c-38079521">[6 more]</label></div><br/><div class="children"><div class="content">The government has no problem getting rid of CSAM and terrorist material, for practical purposes. It&#x27;s not a technical problem.</div><br/><div id="38079966" class="c"><input type="checkbox" id="c-38079966" checked=""/><div class="controls bullet"><span class="by">627467</span><span>|</span><a href="#38079203">root</a><span>|</span><a href="#38079521">parent</a><span>|</span><a href="#38079639">next</a><span>|</span><label class="collapse" for="c-38079966">[-]</label><label class="expand" for="c-38079966">[3 more]</label></div><br/><div class="children"><div class="content">It is obviously a technical challenge. Image yourself trying to facing 3 pictures, one of CSAM, another of terrorist material and just some random photo of random guy eating ice scream: what steps would you do to determine if this last photo is &quot;legal&quot; or not?<p>YouTube have decades of attempt at determining if uploaded content violates copyright, normally through fingerprinting content submitted by right holders. YouTube still fails at catching all copyright infringement. That&#x27;s why they are generally protected from prosecution while they demonstrate reasonable attempt that preventing their services from being misused.<p>Imagine ALL IMAGES IN THE WORLD being submitted for fingerprinting. How about malicious or erroneous submitions that taint datasets?<p>Also: right to be forgotten is a horrible misleading name. At most you have right to request data to be removed from datasets. And only if you have some legal basis that demonstrate that your data is in that dataset. It is not a right to be &quot;forgotten&quot;. Imagine you yourself being told to &quot;forget an image, sound, etc&quot;, how is this enforced? You may even ask for proof that you know the content you are being told to forget. How do you do this?</div><br/><div id="38081530" class="c"><input type="checkbox" id="c-38081530" checked=""/><div class="controls bullet"><span class="by">fullspectrumdev</span><span>|</span><a href="#38079203">root</a><span>|</span><a href="#38079966">parent</a><span>|</span><a href="#38079995">next</a><span>|</span><label class="collapse" for="c-38081530">[-]</label><label class="expand" for="c-38081530">[1 more]</label></div><br/><div class="children"><div class="content">The “right to be forgotten” works nicely in tandem with the “right to know” - where you get to ask companies to tell you what they have on you.</div><br/></div></div><div id="38079995" class="c"><input type="checkbox" id="c-38079995" checked=""/><div class="controls bullet"><span class="by">edgyquant</span><span>|</span><a href="#38079203">root</a><span>|</span><a href="#38079966">parent</a><span>|</span><a href="#38081530">prev</a><span>|</span><a href="#38079639">next</a><span>|</span><label class="collapse" for="c-38079995">[-]</label><label class="expand" for="c-38079995">[1 more]</label></div><br/><div class="children"><div class="content">If you have the image and the person reaches out saying it’s them and they want it removed, you have a pretty good idea of the legality.  As stated, this isn’t a technical problem it’s a bureaucratic one.  Most companies didn’t think they had to remove it so didn’t have steps in place to do so.  Now a lot of them do, with GenAI just being the latest group of companies who feel they have an argument in favor of not having to do so.</div><br/></div></div></div></div><div id="38079639" class="c"><input type="checkbox" id="c-38079639" checked=""/><div class="controls bullet"><span class="by">qweqwe14</span><span>|</span><a href="#38079203">root</a><span>|</span><a href="#38079521">parent</a><span>|</span><a href="#38079966">prev</a><span>|</span><a href="#38080232">next</a><span>|</span><label class="collapse" for="c-38079639">[-]</label><label class="expand" for="c-38079639">[1 more]</label></div><br/><div class="children"><div class="content">They only get rid of those materials that they can seize. I doubt they will be able to seize a properly hosted onion domain. It&#x27;s just that most of the actors aren&#x27;t good enough with technology.<p>That&#x27;s the reason you mostly see the pretty dumb guys getting caught. As long as you are smarter and more tech-savvy than 80% of the criminals, you are pretty much out of reach for the feds.</div><br/></div></div><div id="38080232" class="c"><input type="checkbox" id="c-38080232" checked=""/><div class="controls bullet"><span class="by">XorNot</span><span>|</span><a href="#38079203">root</a><span>|</span><a href="#38079521">parent</a><span>|</span><a href="#38079639">prev</a><span>|</span><a href="#38079413">next</a><span>|</span><label class="collapse" for="c-38080232">[-]</label><label class="expand" for="c-38080232">[1 more]</label></div><br/><div class="children"><div class="content">The government has enormous trouble getting rid of CSAM. The FBI had databases of content that is <i>decades</i> old - basically images recognised as &quot;classics&quot; that are still shared amongst the consumers of such things.<p>It is illegal to possess, but despite the most aggressive enforcement on the planet it is still out there.</div><br/></div></div></div></div></div></div><div id="38079413" class="c"><input type="checkbox" id="c-38079413" checked=""/><div class="controls bullet"><span class="by">constantly</span><span>|</span><a href="#38079203">root</a><span>|</span><a href="#38079355">parent</a><span>|</span><a href="#38079455">prev</a><span>|</span><a href="#38080027">next</a><span>|</span><label class="collapse" for="c-38079413">[-]</label><label class="expand" for="c-38079413">[3 more]</label></div><br/><div class="children"><div class="content">EU rights do not apply in the US.</div><br/><div id="38081627" class="c"><input type="checkbox" id="c-38081627" checked=""/><div class="controls bullet"><span class="by">niemandhier</span><span>|</span><a href="#38079203">root</a><span>|</span><a href="#38079413">parent</a><span>|</span><a href="#38079900">next</a><span>|</span><label class="collapse" for="c-38081627">[-]</label><label class="expand" for="c-38081627">[1 more]</label></div><br/><div class="children"><div class="content">True but globally operating corps are subjects to all kind of national laws and as soon as you have any presence in the EU those regulations apply.<p>An online shop in Germany once removed Cuban cigars because of US trade sanctions.<p>ClearView just declared to ignore the right to be forgotten, even for EU citizens. It will be interesting to se how this plays out. I guess it will take a few years…</div><br/></div></div><div id="38079900" class="c"><input type="checkbox" id="c-38079900" checked=""/><div class="controls bullet"><span class="by">dantheman</span><span>|</span><a href="#38079203">root</a><span>|</span><a href="#38079413">parent</a><span>|</span><a href="#38081627">prev</a><span>|</span><a href="#38080027">next</a><span>|</span><label class="collapse" for="c-38079900">[-]</label><label class="expand" for="c-38079900">[1 more]</label></div><br/><div class="children"><div class="content">The &#x27;right to be forgotten&#x27; isn&#x27;t a right.</div><br/></div></div></div></div></div></div><div id="38080027" class="c"><input type="checkbox" id="c-38080027" checked=""/><div class="controls bullet"><span class="by">exabrial</span><span>|</span><a href="#38079203">parent</a><span>|</span><a href="#38079355">prev</a><span>|</span><a href="#38080884">next</a><span>|</span><label class="collapse" for="c-38080027">[-]</label><label class="expand" for="c-38080027">[12 more]</label></div><br/><div class="children"><div class="content">&gt; you put that information on the internet, you have no expectation to privacy<p>That was the expectation until Zuckerberg came along. People were putting tons of stuff on BBSs, intranets, and other stuff 20+ years beforehand because people had the idea of &quot;consent&quot; back then existed: using someones information for a purpose they didn&#x27;t intend was (and still is) wrong.</div><br/><div id="38080132" class="c"><input type="checkbox" id="c-38080132" checked=""/><div class="controls bullet"><span class="by">FeepingCreature</span><span>|</span><a href="#38079203">root</a><span>|</span><a href="#38080027">parent</a><span>|</span><a href="#38081088">next</a><span>|</span><label class="collapse" for="c-38080132">[-]</label><label class="expand" for="c-38080132">[7 more]</label></div><br/><div class="children"><div class="content">Using someone&#x27;s information for a purpose they didn&#x27;t intend is wrong? What? This just seems obviously mistaken. I don&#x27;t agree with that at all. I&#x27;m not even sure how to argue about that.<p>Lots of art, science and technology can be considered as &quot;using someone&#x27;s information for a purpose they didn&#x27;t intend.&quot; It is extremely normal for people to find new uses for things; information is not exempt from this.</div><br/><div id="38081052" class="c"><input type="checkbox" id="c-38081052" checked=""/><div class="controls bullet"><span class="by">pzs</span><span>|</span><a href="#38079203">root</a><span>|</span><a href="#38080132">parent</a><span>|</span><a href="#38081104">next</a><span>|</span><label class="collapse" for="c-38081052">[-]</label><label class="expand" for="c-38081052">[5 more]</label></div><br/><div class="children"><div class="content">Consider the thought experiment that you give your postal address to some business, because you want to subscribe to regular grocery deliveries. Then you notice that each delivered package contains a small transparent bag with some with powder in it.<p>Whoever treats others&#x27; information can only do so with a clear purpose and for a defined time period according to current EU laws.<p>If, however, you were referring to information that you published on the Internet for everyone&#x27;s benefit then you would still need to consider intellectual property rights. In the open source software world we have the licenses that deal with this, and then there are copyright laws protecting content providers (not making a case here whether they are good or not).<p>I guess what makes a difference is if there is some business involved either in the production or in the consumption side of the equation and if we accept that &quot;machine learning&quot; is the same as &quot;human learning&quot;.<p>EDIT: separated paragraphs, typo</div><br/><div id="38081085" class="c"><input type="checkbox" id="c-38081085" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#38079203">root</a><span>|</span><a href="#38081052">parent</a><span>|</span><a href="#38081104">next</a><span>|</span><label class="collapse" for="c-38081085">[-]</label><label class="expand" for="c-38081085">[4 more]</label></div><br/><div class="children"><div class="content">Copyrights protect the copying of the original text, but models take gradients. Are gradients protected as well? Even when data is copyrighted it still has legitimate value for training, pure ideas don&#x27;t get copyright protection, only expression.</div><br/><div id="38081535" class="c"><input type="checkbox" id="c-38081535" checked=""/><div class="controls bullet"><span class="by">RandomLensman</span><span>|</span><a href="#38079203">root</a><span>|</span><a href="#38081085">parent</a><span>|</span><a href="#38081104">next</a><span>|</span><label class="collapse" for="c-38081535">[-]</label><label class="expand" for="c-38081535">[3 more]</label></div><br/><div class="children"><div class="content">Can the model use the text without making a copy (in memory) to process it?</div><br/><div id="38081811" class="c"><input type="checkbox" id="c-38081811" checked=""/><div class="controls bullet"><span class="by">PeterStuer</span><span>|</span><a href="#38079203">root</a><span>|</span><a href="#38081535">parent</a><span>|</span><a href="#38081104">next</a><span>|</span><label class="collapse" for="c-38081811">[-]</label><label class="expand" for="c-38081811">[2 more]</label></div><br/><div class="children"><div class="content">Can a human?</div><br/><div id="38081861" class="c"><input type="checkbox" id="c-38081861" checked=""/><div class="controls bullet"><span class="by">RandomLensman</span><span>|</span><a href="#38079203">root</a><span>|</span><a href="#38081811">parent</a><span>|</span><a href="#38081104">next</a><span>|</span><label class="collapse" for="c-38081861">[-]</label><label class="expand" for="c-38081861">[1 more]</label></div><br/><div class="children"><div class="content">Not relevant. What humans do isn&#x27;t necessarily viewed the same way as what machines do.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="38081104" class="c"><input type="checkbox" id="c-38081104" checked=""/><div class="controls bullet"><span class="by">tuyiown</span><span>|</span><a href="#38079203">root</a><span>|</span><a href="#38080132">parent</a><span>|</span><a href="#38081052">prev</a><span>|</span><a href="#38081088">next</a><span>|</span><label class="collapse" for="c-38081104">[-]</label><label class="expand" for="c-38081104">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Using someone&#x27;s information for a purpose they didn&#x27;t intend is wrong? What? This just seems obviously mistaken.<p>Yet you would expect that people won&#x27;t record your private conversations, and even less play it back to third parties.<p>Exchanges, of whatever information, whether it is personal stories or administrative data occurs in some kind of trust on what kind use you consent to. Respecting this consent is a social obligation on the receiver end.</div><br/></div></div></div></div><div id="38081088" class="c"><input type="checkbox" id="c-38081088" checked=""/><div class="controls bullet"><span class="by">icelancer</span><span>|</span><a href="#38079203">root</a><span>|</span><a href="#38080027">parent</a><span>|</span><a href="#38080132">prev</a><span>|</span><a href="#38080200">next</a><span>|</span><label class="collapse" for="c-38081088">[-]</label><label class="expand" for="c-38081088">[2 more]</label></div><br/><div class="children"><div class="content">&gt; That was the expectation until Zuckerberg came along.<p>The early days of the Internet were full of &quot;information should be free&quot; hackers, many of whom roam this very forum in their 40s, 50s, and 60s.<p>Well, information is free now. And this is what it looks like - consumed by LLMs. We got what we asked for.</div><br/><div id="38081947" class="c"><input type="checkbox" id="c-38081947" checked=""/><div class="controls bullet"><span class="by">scrollaway</span><span>|</span><a href="#38079203">root</a><span>|</span><a href="#38081088">parent</a><span>|</span><a href="#38080200">next</a><span>|</span><label class="collapse" for="c-38081947">[-]</label><label class="expand" for="c-38081947">[1 more]</label></div><br/><div class="children"><div class="content">Indeed. There was no expectation of privacy on the internet at the time and THAT is exactly why it was standard to not communicate personal information you didn’t want to share. Pseudonymity carried onto the internet until the Facebook days.<p>I am still firmly in the Information wants to be free camp, and I agree with you that LLMs scanning it is a logical continuation of it all.</div><br/></div></div></div></div><div id="38080200" class="c"><input type="checkbox" id="c-38080200" checked=""/><div class="controls bullet"><span class="by">caturopath</span><span>|</span><a href="#38079203">root</a><span>|</span><a href="#38080027">parent</a><span>|</span><a href="#38081088">prev</a><span>|</span><a href="#38080229">next</a><span>|</span><label class="collapse" for="c-38080200">[-]</label><label class="expand" for="c-38080200">[1 more]</label></div><br/><div class="children"><div class="content">&gt; That was the expectation until Zuckerberg came along.<p>This isn&#x27;t my recollection of a pre-facebook internet</div><br/></div></div><div id="38080229" class="c"><input type="checkbox" id="c-38080229" checked=""/><div class="controls bullet"><span class="by">vasco</span><span>|</span><a href="#38079203">root</a><span>|</span><a href="#38080027">parent</a><span>|</span><a href="#38080200">prev</a><span>|</span><a href="#38080884">next</a><span>|</span><label class="collapse" for="c-38080229">[-]</label><label class="expand" for="c-38080229">[1 more]</label></div><br/><div class="children"><div class="content">This seems like a fantasy. Anything could end up in 4chan with a photoshoped penis on it since a long time before Zuck came along.</div><br/></div></div></div></div><div id="38080884" class="c"><input type="checkbox" id="c-38080884" checked=""/><div class="controls bullet"><span class="by">devjab</span><span>|</span><a href="#38079203">parent</a><span>|</span><a href="#38080027">prev</a><span>|</span><a href="#38080417">next</a><span>|</span><label class="collapse" for="c-38080884">[-]</label><label class="expand" for="c-38080884">[1 more]</label></div><br/><div class="children"><div class="content">There are a lot of aspects to this though. We write code for solar power plants, some of it is open source or at least publicly available. What if we wrote something that turned out to be bad and it was used by someone else through the AI and it broke their plant… would we be responsible?<p>Now, you’re probably thinking about this from a reasoning or technical perspective in which case it’ll appear to be a ridiculous concern… because it is a ridiculous concern. That’s not how our legal department sees it though. They see it as risk mitigation, and they actually take it rather serious.</div><br/></div></div><div id="38080417" class="c"><input type="checkbox" id="c-38080417" checked=""/><div class="controls bullet"><span class="by">Sparkyte</span><span>|</span><a href="#38079203">parent</a><span>|</span><a href="#38080884">prev</a><span>|</span><a href="#38080859">next</a><span>|</span><label class="collapse" for="c-38080417">[-]</label><label class="expand" for="c-38080417">[1 more]</label></div><br/><div class="children"><div class="content">GPDR and many data rights exist today, it is still applicable to AI.</div><br/></div></div><div id="38080859" class="c"><input type="checkbox" id="c-38080859" checked=""/><div class="controls bullet"><span class="by">thayne</span><span>|</span><a href="#38079203">parent</a><span>|</span><a href="#38080417">prev</a><span>|</span><a href="#38079420">next</a><span>|</span><label class="collapse" for="c-38080859">[-]</label><label class="expand" for="c-38080859">[1 more]</label></div><br/><div class="children"><div class="content">&gt; you put that information on the internet<p>That isn&#x27;t necessarily true. Someone else might have put the information on the Internet. That could be someone else uploading a photo of you, or records of your home purchase on a city&#x27;s public records, or an obituary or wedding announcement that listed you as family, etc.etc.</div><br/></div></div><div id="38079420" class="c"><input type="checkbox" id="c-38079420" checked=""/><div class="controls bullet"><span class="by">cratermoon</span><span>|</span><a href="#38079203">parent</a><span>|</span><a href="#38080859">prev</a><span>|</span><a href="#38081057">next</a><span>|</span><label class="collapse" for="c-38079420">[-]</label><label class="expand" for="c-38079420">[1 more]</label></div><br/><div class="children"><div class="content">People didn&#x27;t put their private medical records on the open internet. They may have uploaded them to a service they <i>thought</i> was respecting privacy but was either selling their data without disclosure or was just straight up incompetent and uploaded private-user-data.zip to a public Dropbox share.</div><br/></div></div><div id="38079489" class="c"><input type="checkbox" id="c-38079489" checked=""/><div class="controls bullet"><span class="by">esafak</span><span>|</span><a href="#38079203">parent</a><span>|</span><a href="#38081054">prev</a><span>|</span><a href="#38077794">next</a><span>|</span><label class="collapse" for="c-38079489">[-]</label><label class="expand" for="c-38079489">[1 more]</label></div><br/><div class="children"><div class="content">I do have an expectation to privacy. It is possible to secure information if so desired.<p>Do you expect your online bank to secure your data? Your email provider? Your healthcare provider? So you do expect some privacy. I just expect some more. I believe that companies should not own my data just because they provide me with services off it. From that, consequences follow.<p>I have a better proposition: let&#x27;s slap companies that don&#x27;t respect privacy with fines until they too learn a lesson.</div><br/></div></div></div></div><div id="38077794" class="c"><input type="checkbox" id="c-38077794" checked=""/><div class="controls bullet"><span class="by">ilamont</span><span>|</span><a href="#38079203">prev</a><span>|</span><a href="#38078666">next</a><span>|</span><label class="collapse" for="c-38077794">[-]</label><label class="expand" for="c-38077794">[1 more]</label></div><br/><div class="children"><div class="content">Not just personal information. Blogs, commercial content, news articles and more. Check out the Allen Institute for Artificial Intelligence&#x27;s C4 dataset to see if anything you wrote was ingested:<p><a href="https:&#x2F;&#x2F;c4-search.apps.allenai.org" rel="nofollow noreferrer">https:&#x2F;&#x2F;c4-search.apps.allenai.org</a><p>Love the disclaimer: &quot;The dataset is released under the terms of ODC-BY. By using this, you are also bound by the Common Crawl Terms of Use in respect of the content contained in the dataset.&quot;</div><br/></div></div><div id="38078666" class="c"><input type="checkbox" id="c-38078666" checked=""/><div class="controls bullet"><span class="by">jprete</span><span>|</span><a href="#38077794">prev</a><span>|</span><a href="#38077594">next</a><span>|</span><label class="collapse" for="c-38078666">[-]</label><label class="expand" for="c-38078666">[9 more]</label></div><br/><div class="children"><div class="content">The article weasels out at the end by claiming that companies “may be unable to comply” with requirements to delete personal data. It’s easy to comply - if there’s no other choice then you delete the model and all backups and derivative data that was trained in flagrant violation of the law.</div><br/><div id="38079295" class="c"><input type="checkbox" id="c-38079295" checked=""/><div class="controls bullet"><span class="by">ivalm</span><span>|</span><a href="#38078666">parent</a><span>|</span><a href="#38079207">next</a><span>|</span><label class="collapse" for="c-38079295">[-]</label><label class="expand" for="c-38079295">[4 more]</label></div><br/><div class="children"><div class="content">For most companies “deleting the model” is equivalent to dissolving the company so that is equivalent to not being able
to comply. More realistically what they would need to do is exit the market of the country that has such stupid laws.</div><br/><div id="38079759" class="c"><input type="checkbox" id="c-38079759" checked=""/><div class="controls bullet"><span class="by">dylan604</span><span>|</span><a href="#38078666">root</a><span>|</span><a href="#38079295">parent</a><span>|</span><a href="#38079774">prev</a><span>|</span><a href="#38079207">next</a><span>|</span><label class="collapse" for="c-38079759">[-]</label><label class="expand" for="c-38079759">[2 more]</label></div><br/><div class="children"><div class="content">&gt;For most companies “deleting the model” is equivalent to dissolving the company<p>I&#x27;m okay with that. It&#x27;s sad that you&#x27;re not. If you&#x27;re willing to start a business on such shady foundations, there&#x27;s a really good chance your business will continue to make shady decisions in the future. It&#x27;s better to find and remove the cancer early</div><br/><div id="38080997" class="c"><input type="checkbox" id="c-38080997" checked=""/><div class="controls bullet"><span class="by">ivalm</span><span>|</span><a href="#38078666">root</a><span>|</span><a href="#38079759">parent</a><span>|</span><a href="#38079207">next</a><span>|</span><label class="collapse" for="c-38080997">[-]</label><label class="expand" for="c-38080997">[1 more]</label></div><br/><div class="children"><div class="content">I just disagree that it&#x27;s shady. If you put your personal info into public circulation I think it&#x27;s absolutely morally fine to have a model train on it.</div><br/></div></div></div></div></div></div><div id="38079207" class="c"><input type="checkbox" id="c-38079207" checked=""/><div class="controls bullet"><span class="by">batch12</span><span>|</span><a href="#38078666">parent</a><span>|</span><a href="#38079295">prev</a><span>|</span><a href="#38078854">next</a><span>|</span><label class="collapse" for="c-38079207">[-]</label><label class="expand" for="c-38079207">[1 more]</label></div><br/><div class="children"><div class="content">I was daydreaming about other possible ways to comply, but I don&#x27;t know if they&#x27;d really work in practice. Ideas like:<p>- Supply copywritten keywords and approved responses to try and retrain the model.<p>- Train the copywritten content again with inverse weighting. I imagine this one wouldn&#x27;t really work well and still keep the model performance up...</div><br/></div></div><div id="38078854" class="c"><input type="checkbox" id="c-38078854" checked=""/><div class="controls bullet"><span class="by">soulofmischief</span><span>|</span><a href="#38078666">parent</a><span>|</span><a href="#38079207">prev</a><span>|</span><a href="#38077594">next</a><span>|</span><label class="collapse" for="c-38078854">[-]</label><label class="expand" for="c-38078854">[3 more]</label></div><br/><div class="children"><div class="content">Which law is that?</div><br/><div id="38078924" class="c"><input type="checkbox" id="c-38078924" checked=""/><div class="controls bullet"><span class="by">john-radio</span><span>|</span><a href="#38078666">root</a><span>|</span><a href="#38078854">parent</a><span>|</span><a href="#38077594">next</a><span>|</span><label class="collapse" for="c-38078924">[-]</label><label class="expand" for="c-38078924">[2 more]</label></div><br/><div class="children"><div class="content">The post that you&#x27;re responding to doesn&#x27;t make any claim about the law; it expresses that the defense that an AI company might be &quot;unable to comply&quot; with a command to remove user data is not an honest one.</div><br/><div id="38078944" class="c"><input type="checkbox" id="c-38078944" checked=""/><div class="controls bullet"><span class="by">soulofmischief</span><span>|</span><a href="#38078666">root</a><span>|</span><a href="#38078924">parent</a><span>|</span><a href="#38077594">next</a><span>|</span><label class="collapse" for="c-38078944">[-]</label><label class="expand" for="c-38078944">[1 more]</label></div><br/><div class="children"><div class="content">&quot;<i>flagrant</i> violation of the law&quot; heavily implies that OP has some strong feelings around this, and I want to know what law they think is potentially being flagrantly violated.</div><br/></div></div></div></div></div></div></div></div><div id="38077594" class="c"><input type="checkbox" id="c-38077594" checked=""/><div class="controls bullet"><span class="by">bmitc</span><span>|</span><a href="#38078666">prev</a><span>|</span><a href="#38080427">next</a><span>|</span><label class="collapse" for="c-38077594">[-]</label><label class="expand" for="c-38077594">[23 more]</label></div><br/><div class="children"><div class="content">In general, we need a data bill of rights. Corporations are enslaving us digitally, and I feel it&#x27;s reaching a boiling point.</div><br/><div id="38077657" class="c"><input type="checkbox" id="c-38077657" checked=""/><div class="controls bullet"><span class="by">graphe</span><span>|</span><a href="#38077594">parent</a><span>|</span><a href="#38077620">next</a><span>|</span><label class="collapse" for="c-38077657">[-]</label><label class="expand" for="c-38077657">[7 more]</label></div><br/><div class="children"><div class="content">There are zero incentives for them to comply and zero ways a person can make them accountable. If your SSN can be leaked and nothing will happen why would they care about scrappable pictures?<p>The only times they care are when it can cost them money. SD didn&#x27;t care about visual artists but could not do the same for generative music since the rights are managed by deep pockets.</div><br/><div id="38078897" class="c"><input type="checkbox" id="c-38078897" checked=""/><div class="controls bullet"><span class="by">happytiger</span><span>|</span><a href="#38077594">root</a><span>|</span><a href="#38077657">parent</a><span>|</span><a href="#38078158">next</a><span>|</span><label class="collapse" for="c-38078897">[-]</label><label class="expand" for="c-38078897">[3 more]</label></div><br/><div class="children"><div class="content">Frankly, and not directed personally, but that’s not really true.<p>Government can make the incentive — and has. Legislation can put the teeth in societal goods like this even if financial incentives don’t.<p>California has done exactly this with their right to be deleted law.<p><a href="https:&#x2F;&#x2F;www.foley.com&#x2F;en&#x2F;insights&#x2F;publications&#x2F;2023&#x2F;10&#x2F;california-expands-data-deletion-rights-brokers#:~:text=By%20January%201%2C%202026%2C%20the,associated%20service%20provider%20or%20contractor" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.foley.com&#x2F;en&#x2F;insights&#x2F;publications&#x2F;2023&#x2F;10&#x2F;calif...</a>.</div><br/><div id="38079854" class="c"><input type="checkbox" id="c-38079854" checked=""/><div class="controls bullet"><span class="by">graphe</span><span>|</span><a href="#38077594">root</a><span>|</span><a href="#38078897">parent</a><span>|</span><a href="#38078158">next</a><span>|</span><label class="collapse" for="c-38079854">[-]</label><label class="expand" for="c-38079854">[2 more]</label></div><br/><div class="children"><div class="content">The two parties are the state and the data brokers. The individual has no way to do this on their own. But you&#x27;re right, it doesn&#x27;t have to be true. Maybe someone will have precedence and sue a company. Until then I am convinced it is true.</div><br/><div id="38080537" class="c"><input type="checkbox" id="c-38080537" checked=""/><div class="controls bullet"><span class="by">happytiger</span><span>|</span><a href="#38077594">root</a><span>|</span><a href="#38079854">parent</a><span>|</span><a href="#38078158">next</a><span>|</span><label class="collapse" for="c-38080537">[-]</label><label class="expand" for="c-38080537">[1 more]</label></div><br/><div class="children"><div class="content">Fair enough. I respect your logic.</div><br/></div></div></div></div></div></div><div id="38078158" class="c"><input type="checkbox" id="c-38078158" checked=""/><div class="controls bullet"><span class="by">thelittleone</span><span>|</span><a href="#38077594">root</a><span>|</span><a href="#38077657">parent</a><span>|</span><a href="#38078897">prev</a><span>|</span><a href="#38077620">next</a><span>|</span><label class="collapse" for="c-38078158">[-]</label><label class="expand" for="c-38078158">[3 more]</label></div><br/><div class="children"><div class="content">AI might lead to more paywalled sites which would suck.</div><br/><div id="38078684" class="c"><input type="checkbox" id="c-38078684" checked=""/><div class="controls bullet"><span class="by">pixl97</span><span>|</span><a href="#38077594">root</a><span>|</span><a href="#38078158">parent</a><span>|</span><a href="#38077620">next</a><span>|</span><label class="collapse" for="c-38078684">[-]</label><label class="expand" for="c-38078684">[2 more]</label></div><br/><div class="children"><div class="content">Depends, will it reduce the number of ad driven sites? Could be a good thing.</div><br/><div id="38081297" class="c"><input type="checkbox" id="c-38081297" checked=""/><div class="controls bullet"><span class="by">thih9</span><span>|</span><a href="#38077594">root</a><span>|</span><a href="#38078684">parent</a><span>|</span><a href="#38077620">next</a><span>|</span><label class="collapse" for="c-38081297">[-]</label><label class="expand" for="c-38081297">[1 more]</label></div><br/><div class="children"><div class="content">Your favorite forum&#x2F;blog&#x2F;app might be ad driven.<p>And it’s not like ads will disappear; if anything, we’ll get AI ads.</div><br/></div></div></div></div></div></div></div></div><div id="38077620" class="c"><input type="checkbox" id="c-38077620" checked=""/><div class="controls bullet"><span class="by">andybak</span><span>|</span><a href="#38077594">parent</a><span>|</span><a href="#38077657">prev</a><span>|</span><a href="#38077706">next</a><span>|</span><label class="collapse" for="c-38077620">[-]</label><label class="expand" for="c-38077620">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s plenty of AI being trained by hobbyists, artists and enthusiasts too.</div><br/></div></div><div id="38077706" class="c"><input type="checkbox" id="c-38077706" checked=""/><div class="controls bullet"><span class="by">dr_dshiv</span><span>|</span><a href="#38077594">parent</a><span>|</span><a href="#38077620">prev</a><span>|</span><a href="#38078868">next</a><span>|</span><label class="collapse" for="c-38077706">[-]</label><label class="expand" for="c-38077706">[13 more]</label></div><br/><div class="children"><div class="content">This is like the plight of a slave, how?</div><br/><div id="38078848" class="c"><input type="checkbox" id="c-38078848" checked=""/><div class="controls bullet"><span class="by">bmitc</span><span>|</span><a href="#38077594">root</a><span>|</span><a href="#38077706">parent</a><span>|</span><a href="#38078528">next</a><span>|</span><label class="collapse" for="c-38078848">[-]</label><label class="expand" for="c-38078848">[2 more]</label></div><br/><div class="children"><div class="content">I didn&#x27;t say anything remotely close to what you&#x27;re implying. What a ridiculous statement. I used the word enslave and used it correctly in this context.<p><a href="https:&#x2F;&#x2F;www.merriam-webster.com&#x2F;dictionary&#x2F;enslave" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.merriam-webster.com&#x2F;dictionary&#x2F;enslave</a><p><a href="https:&#x2F;&#x2F;www.merriam-webster.com&#x2F;dictionary&#x2F;slavery" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.merriam-webster.com&#x2F;dictionary&#x2F;slavery</a><p><i>a situation or practice in which people are entrapped (as by debt) and exploited</i>; <i>submission to a dominating influence</i><p>From Oxford Dictionary: <i>cause (someone) to lose their freedom of choice or action</i></div><br/><div id="38081716" class="c"><input type="checkbox" id="c-38081716" checked=""/><div class="controls bullet"><span class="by">Last5Digits</span><span>|</span><a href="#38077594">root</a><span>|</span><a href="#38078848">parent</a><span>|</span><a href="#38078528">next</a><span>|</span><label class="collapse" for="c-38081716">[-]</label><label class="expand" for="c-38081716">[1 more]</label></div><br/><div class="children"><div class="content">Is this elementary school, where we ignore the usage and context of words and simply recite the dictionary definition? You were clearly aware of the emotional weight of the term and tried to exploit it to make your argument more impactful.<p>Can I call my mom a slave-driver now, because she made me clean my room when I was a child? I clearly had no choice but to submit to her demands, since I relied on her for food and shelter!</div><br/></div></div></div></div><div id="38078528" class="c"><input type="checkbox" id="c-38078528" checked=""/><div class="controls bullet"><span class="by">Retric</span><span>|</span><a href="#38077594">root</a><span>|</span><a href="#38077706">parent</a><span>|</span><a href="#38078848">prev</a><span>|</span><a href="#38078868">next</a><span>|</span><label class="collapse" for="c-38078528">[-]</label><label class="expand" for="c-38078528">[10 more]</label></div><br/><div class="children"><div class="content">The complete lack of power or ownership of your work.<p>Do you think anyone consented to have AI companies scrap GitHub etc?</div><br/><div id="38078709" class="c"><input type="checkbox" id="c-38078709" checked=""/><div class="controls bullet"><span class="by">pixl97</span><span>|</span><a href="#38077594">root</a><span>|</span><a href="#38078528">parent</a><span>|</span><a href="#38078889">next</a><span>|</span><label class="collapse" for="c-38078709">[-]</label><label class="expand" for="c-38078709">[4 more]</label></div><br/><div class="children"><div class="content">Eh, you borrowed from society to create &#x27;your work&#x27; and now you want to lock it up like you&#x27;ve created it wholly.</div><br/><div id="38079471" class="c"><input type="checkbox" id="c-38079471" checked=""/><div class="controls bullet"><span class="by">Retric</span><span>|</span><a href="#38077594">root</a><span>|</span><a href="#38078709">parent</a><span>|</span><a href="#38079347">next</a><span>|</span><label class="collapse" for="c-38079471">[-]</label><label class="expand" for="c-38079471">[1 more]</label></div><br/><div class="children"><div class="content">By that standard no copyrighted works have any protection, except clearly that isn’t the world we live in.</div><br/></div></div><div id="38079438" class="c"><input type="checkbox" id="c-38079438" checked=""/><div class="controls bullet"><span class="by">cratermoon</span><span>|</span><a href="#38077594">root</a><span>|</span><a href="#38078709">parent</a><span>|</span><a href="#38079347">prev</a><span>|</span><a href="#38078889">next</a><span>|</span><label class="collapse" for="c-38079438">[-]</label><label class="expand" for="c-38079438">[1 more]</label></div><br/><div class="children"><div class="content">No, it&#x27;s the generative AI companies that are taking from society all the data and locking it up in their opaque models and selling that as if they created it wholly.</div><br/></div></div></div></div><div id="38078889" class="c"><input type="checkbox" id="c-38078889" checked=""/><div class="controls bullet"><span class="by">soulofmischief</span><span>|</span><a href="#38077594">root</a><span>|</span><a href="#38078528">parent</a><span>|</span><a href="#38078709">prev</a><span>|</span><a href="#38078868">next</a><span>|</span><label class="collapse" for="c-38078889">[-]</label><label class="expand" for="c-38078889">[5 more]</label></div><br/><div class="children"><div class="content">They consented if the data was public. Opt-out scanning practices is a whole other beast.<p>But unfortunately, unless you challenge the ToS in court, you consented the moment you didn&#x27;t delete all of your data after the policy update. Is that fucked? Sure, and maybe we need regulation around that, but in the face of current legislation, consent was granted.</div><br/><div id="38079452" class="c"><input type="checkbox" id="c-38079452" checked=""/><div class="controls bullet"><span class="by">Retric</span><span>|</span><a href="#38077594">root</a><span>|</span><a href="#38078889">parent</a><span>|</span><a href="#38078960">next</a><span>|</span><label class="collapse" for="c-38079452">[-]</label><label class="expand" for="c-38079452">[3 more]</label></div><br/><div class="children"><div class="content">That’s factually incorrect. GitHub’s ToS don’t give them any rights to use your information in this way.<p>Their argument is they don’t need any such permission, but they can profit from this data by selectively allowing  large scale scrapping by 3rd parties thus breaking their TOS by selling your data.</div><br/><div id="38079765" class="c"><input type="checkbox" id="c-38079765" checked=""/><div class="controls bullet"><span class="by">soulofmischief</span><span>|</span><a href="#38077594">root</a><span>|</span><a href="#38079452">parent</a><span>|</span><a href="#38078960">next</a><span>|</span><label class="collapse" for="c-38079765">[-]</label><label class="expand" for="c-38079765">[2 more]</label></div><br/><div class="children"><div class="content">GitHub&#x27;s ToS expressly allows them to change the terms of their service at will, and they do indeed publish these changes, and your continued use of their website is considered consent.<p>Furthermore, as [0] states:<p>&gt; We may use your information to provide, administer, analyze, manage, and operate our Service. For example, we use your information for the following purposes:<p>&gt; ...Improve and develop our products and services including to develop new services or features, and conduct research...<p>[0] <a href="https:&#x2F;&#x2F;docs.github.com&#x2F;en&#x2F;site-policy&#x2F;privacy-policies&#x2F;github-privacy-statement#how-github-uses-your-information" rel="nofollow noreferrer">https:&#x2F;&#x2F;docs.github.com&#x2F;en&#x2F;site-policy&#x2F;privacy-policies&#x2F;gith...</a></div><br/><div id="38080390" class="c"><input type="checkbox" id="c-38080390" checked=""/><div class="controls bullet"><span class="by">Retric</span><span>|</span><a href="#38077594">root</a><span>|</span><a href="#38079765">parent</a><span>|</span><a href="#38078960">next</a><span>|</span><label class="collapse" for="c-38080390">[-]</label><label class="expand" for="c-38080390">[1 more]</label></div><br/><div class="children"><div class="content">They didn’t limit copilot to active users who therefore have implied consent to ToS changes.<p>“Improving and developing products and services” doesn’t cover what they did.  Which is why that line isn’t being brought up in the ongoing litigation.<p>Further, at scale they are well aware users didn’t own the copyright to all uploaded data making their ToS insufficient shielding for this use.  Which is why they aren’t even trying to suggest the ToS enabled this kind of use as that suggests it would be required and opens themselves to massive amounts of liability.</div><br/></div></div></div></div></div></div><div id="38078960" class="c"><input type="checkbox" id="c-38078960" checked=""/><div class="controls bullet"><span class="by">jprete</span><span>|</span><a href="#38077594">root</a><span>|</span><a href="#38078889">parent</a><span>|</span><a href="#38079452">prev</a><span>|</span><a href="#38078868">next</a><span>|</span><label class="collapse" for="c-38078960">[-]</label><label class="expand" for="c-38078960">[1 more]</label></div><br/><div class="children"><div class="content">Failing to actively say &quot;no&quot; is not the same thing as saying &quot;yes&quot;. If your point is that the law means nothing unless someone is willing to file lawsuits, your point is taken.</div><br/></div></div></div></div></div></div></div></div><div id="38078868" class="c"><input type="checkbox" id="c-38078868" checked=""/><div class="controls bullet"><span class="by">happytiger</span><span>|</span><a href="#38077594">parent</a><span>|</span><a href="#38077706">prev</a><span>|</span><a href="#38080427">next</a><span>|</span><label class="collapse" for="c-38078868">[-]</label><label class="expand" for="c-38078868">[1 more]</label></div><br/><div class="children"><div class="content">I just finished getting downvoted in another thread for writing these very words. Couldn’t agree more.</div><br/></div></div></div></div><div id="38080427" class="c"><input type="checkbox" id="c-38080427" checked=""/><div class="controls bullet"><span class="by">Sparkyte</span><span>|</span><a href="#38077594">prev</a><span>|</span><a href="#38078403">next</a><span>|</span><label class="collapse" for="c-38080427">[-]</label><label class="expand" for="c-38080427">[1 more]</label></div><br/><div class="children"><div class="content">Legally they can&#x27;t use your data without your consent and that data must be able to be deleted by your demand. So for GenAI to use personal information is bad and they should change its design. I advise they obfuscate the data to not contain sensitive information if they are intending to create AI around such data. Identifiable information is not a good thing.<p>GDPR and many other laws are still applicable to what GenAI is.</div><br/></div></div><div id="38078403" class="c"><input type="checkbox" id="c-38078403" checked=""/><div class="controls bullet"><span class="by">moose4400</span><span>|</span><a href="#38080427">prev</a><span>|</span><label class="collapse" for="c-38078403">[-]</label><label class="expand" for="c-38078403">[1 more]</label></div><br/><div class="children"><div class="content">Now&#x27;s a good time to scrub your online identity before things get worse.</div><br/></div></div></div></div></div></div></div></body></html>