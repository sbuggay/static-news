<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1729242071367" as="style"/><link rel="stylesheet" href="styles.css?v=1729242071367"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.crunchydata.com/blog/pg_parquet-an-extension-to-connect-postgres-and-parquet">Pg_parquet: An extension to connect Postgres and parquet</a>Â <span class="domain">(<a href="https://www.crunchydata.com">www.crunchydata.com</a>)</span></div><div class="subtext"><span>craigkerstiens</span> | <span>18 comments</span></div><br/><div><div id="41876178" class="c"><input type="checkbox" id="c-41876178" checked=""/><div class="controls bullet"><span class="by">RMarcus</span><span>|</span><a href="#41873697">next</a><span>|</span><label class="collapse" for="c-41876178">[-]</label><label class="expand" for="c-41876178">[1 more]</label></div><br/><div class="children"><div class="content">This is awesome, thanks for creating this. I&#x27;ve had to write some absolutely wonky scripts to dump a PostgreSQL database into Parquet, or read a Parquet file into PostgreSQL. Normally some terrible combination of psycopg and pyarrow, which worked, but it was ad-hoc and slightly different every time.<p>A lot of other commenters are talking about `pg_duckdb` which maybe also could&#x27;ve solved my problem, but this looks quite simple and clean.<p>I hope for some kind of near-term future where there&#x27;s <i>some</i> standardish analytics-friendly data archival format. I think Parquet is the closest thing we have now.</div><br/></div></div><div id="41873697" class="c"><input type="checkbox" id="c-41873697" checked=""/><div class="controls bullet"><span class="by">linuxhansl</span><span>|</span><a href="#41876178">prev</a><span>|</span><a href="#41873813">next</a><span>|</span><label class="collapse" for="c-41873697">[-]</label><label class="expand" for="c-41873697">[7 more]</label></div><br/><div class="children"><div class="content">Parquet itself is actually not that interesting. It should be able to read (and even write) Iceberg tables.<p>Also, how does it compare to pg_duckdb (which adds DuckDB execution to Postgres including reading parquet and Iceberg), or duck_fdw (which wraps a DuckDB database, which can be in memory and only pass-through Iceberg&#x2F;Parquet tables)?</div><br/><div id="41874177" class="c"><input type="checkbox" id="c-41874177" checked=""/><div class="controls bullet"><span class="by">mslot</span><span>|</span><a href="#41873697">parent</a><span>|</span><a href="#41876793">next</a><span>|</span><label class="collapse" for="c-41874177">[-]</label><label class="expand" for="c-41874177">[1 more]</label></div><br/><div class="children"><div class="content">(Marco from Crunchy Data)<p>With PostgreSQL extensions, we find it&#x27;s most effective to have single-purpose modular extensions.<p>For instance, I created pg_cron a few years ago, and it&#x27;s on basically every PostgreSQL service because it does one thing and does it well.<p>We wanted to create a light-weight implementation of Parquet that does not pull a multi-threaded library into every postgres process.<p>When you get to more complex features, a lot of questions around trade-offs, user experience, and deployment model start appearing. For instance, when querying an Iceberg table, caching becomes quite important, but that raises lots of other questions around cache management. Also, how do you deal with that memory hungry, multi-threaded query engine running in every process without things constantly falling over?<p>It&#x27;s easier to answer those questions in the context of a managed service where you control the environment, so we have a  product that can query Iceberg&#x2F;Parquet&#x2F;CSV&#x2F;etc. in S3, does automatic caching, figures out the region of your bucket, can create tables directly from files, and uses DuckDB to accelerate queries in a reliable manner. This is partially powered by a set of custom extensions, partially by other things running on the managed service.
<a href="https:&#x2F;&#x2F;docs.crunchybridge.com&#x2F;analytics" rel="nofollow">https:&#x2F;&#x2F;docs.crunchybridge.com&#x2F;analytics</a><p>However, some components can be neatly extracted and shared broadly like COPY TO&#x2F;FROM Parquet. We find it very useful for archiving old partitions, importing public and private data sets, preparing data for analytics, and moving data between PostgreSQL servers.</div><br/></div></div><div id="41876793" class="c"><input type="checkbox" id="c-41876793" checked=""/><div class="controls bullet"><span class="by">fulafel</span><span>|</span><a href="#41873697">parent</a><span>|</span><a href="#41874177">prev</a><span>|</span><a href="#41874044">next</a><span>|</span><label class="collapse" for="c-41876793">[-]</label><label class="expand" for="c-41876793">[2 more]</label></div><br/><div class="children"><div class="content">Having the famously crashy DuckDB share a process and memory with PostgreSQL  doesn&#x27;t seem like the most robust setup.</div><br/><div id="41876976" class="c"><input type="checkbox" id="c-41876976" checked=""/><div class="controls bullet"><span class="by">skeptrune</span><span>|</span><a href="#41873697">root</a><span>|</span><a href="#41876793">parent</a><span>|</span><a href="#41874044">next</a><span>|</span><label class="collapse" for="c-41876976">[-]</label><label class="expand" for="c-41876976">[1 more]</label></div><br/><div class="children"><div class="content">I had the exact same reaction</div><br/></div></div></div></div><div id="41874044" class="c"><input type="checkbox" id="c-41874044" checked=""/><div class="controls bullet"><span class="by">AdamProut</span><span>|</span><a href="#41873697">parent</a><span>|</span><a href="#41876793">prev</a><span>|</span><a href="#41873813">next</a><span>|</span><label class="collapse" for="c-41874044">[-]</label><label class="expand" for="c-41874044">[3 more]</label></div><br/><div class="children"><div class="content">Had a similar thought.  Azure Postgres has something similar to pg_parquet (pg_azure_storage), but we&#x27;re looking into replacing it with pg_duckdb assuming the extension continues to mature.<p>It would be great if the Postgres community could get behind one good opensource extension for the various columnstore data use cases (querying data stored in an open columnstore format - delta, iceberg, etc. being one of them).  pg_duckdb seems to have the best chance at being the goto extension for this.</div><br/><div id="41874183" class="c"><input type="checkbox" id="c-41874183" checked=""/><div class="controls bullet"><span class="by">mslot</span><span>|</span><a href="#41873697">root</a><span>|</span><a href="#41874044">parent</a><span>|</span><a href="#41873813">next</a><span>|</span><label class="collapse" for="c-41874183">[-]</label><label class="expand" for="c-41874183">[2 more]</label></div><br/><div class="children"><div class="content">Fun fact, I created pg_azure_storage :)</div><br/><div id="41877261" class="c"><input type="checkbox" id="c-41877261" checked=""/><div class="controls bullet"><span class="by">brinox</span><span>|</span><a href="#41873697">root</a><span>|</span><a href="#41874183">parent</a><span>|</span><a href="#41873813">next</a><span>|</span><label class="collapse" for="c-41877261">[-]</label><label class="expand" for="c-41877261">[1 more]</label></div><br/><div class="children"><div class="content">I was just wondering if pg_parquet could be combined with pg_azure_storage to write Parquet files to Azure Storage.<p>I had problems with pg_azure_storage in the past, because the roles pg_read_server_files and pg_write_server_files are unassignable on Azure PostgreSQL databases which makes the use of `COPY {FROM,TO}` impossible.</div><br/></div></div></div></div></div></div></div></div><div id="41873813" class="c"><input type="checkbox" id="c-41873813" checked=""/><div class="controls bullet"><span class="by">oulipo</span><span>|</span><a href="#41873697">prev</a><span>|</span><a href="#41873978">next</a><span>|</span><label class="collapse" for="c-41873813">[-]</label><label class="expand" for="c-41873813">[2 more]</label></div><br/><div class="children"><div class="content">Cool, would this be better than using a clickhouse &#x2F; duckdb extension that reads postgres and saves to Parquet?<p>What would be recommended to output regularly old data to S3 as parquet file? To use a cron job which launches a second Postgres process connecting to the database and extracting the data, or using the regular database instance? doesn&#x27;t that slow down the instance too much?</div><br/><div id="41874097" class="c"><input type="checkbox" id="c-41874097" checked=""/><div class="controls bullet"><span class="by">craigkerstiens</span><span>|</span><a href="#41873813">parent</a><span>|</span><a href="#41873978">next</a><span>|</span><label class="collapse" for="c-41874097">[-]</label><label class="expand" for="c-41874097">[1 more]</label></div><br/><div class="children"><div class="content">This alone wouldn&#x27;t be a full replacement. We do have a full product that does that with customers seeing great performance in production. Crunchy Bridge for Analytics does similar by embedding DuckDB inside Postgres, though for users is largely an implementation detail. We support iceberg as well and have a lot more coming basically to allow for seamless analytics on Postgres building on what Postgres is good at, iceberg for storage, and duckdb for vectorized execution.<p>That isn&#x27;t fully open source at this time but has been production grade for some time. This was one piece that makes getting to that easier for folks and felt a good standalone bit to open source and share with the broader community. We can also see where this by itself for certain use cases makes sense, as you sort of point out if you had time series partitioned data, leveraged partman for new partitions and pg_cron which this same set of people authored you could automatically archive old partitions to parquet but still have thing for analysis if needed.</div><br/></div></div></div></div><div id="41873978" class="c"><input type="checkbox" id="c-41873978" checked=""/><div class="controls bullet"><span class="by">whalesalad</span><span>|</span><a href="#41873813">prev</a><span>|</span><a href="#41871295">next</a><span>|</span><label class="collapse" for="c-41873978">[-]</label><label class="expand" for="c-41873978">[3 more]</label></div><br/><div class="children"><div class="content">I wish RDS made it easy to add custom extensions like this.</div><br/><div id="41874650" class="c"><input type="checkbox" id="c-41874650" checked=""/><div class="controls bullet"><span class="by">wdb</span><span>|</span><a href="#41873978">parent</a><span>|</span><a href="#41875299">next</a><span>|</span><label class="collapse" for="c-41874650">[-]</label><label class="expand" for="c-41874650">[1 more]</label></div><br/><div class="children"><div class="content">or Google Cloud</div><br/></div></div><div id="41875299" class="c"><input type="checkbox" id="c-41875299" checked=""/><div class="controls bullet"><span class="by">treefarmer</span><span>|</span><a href="#41873978">parent</a><span>|</span><a href="#41874650">prev</a><span>|</span><a href="#41871295">next</a><span>|</span><label class="collapse" for="c-41875299">[-]</label><label class="expand" for="c-41875299">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, I&#x27;m still surprised they haven&#x27;t added a list of unsupported extensions (that you can add but they&#x27;re not responsible for the performance of).</div><br/></div></div></div></div><div id="41871295" class="c"><input type="checkbox" id="c-41871295" checked=""/><div class="controls bullet"><span class="by">aamederen</span><span>|</span><a href="#41873978">prev</a><span>|</span><a href="#41875366">next</a><span>|</span><label class="collapse" for="c-41871295">[-]</label><label class="expand" for="c-41871295">[1 more]</label></div><br/><div class="children"><div class="content">Congratulations! I&#x27;m happy to see the PostgreSQL license.</div><br/></div></div><div id="41875366" class="c"><input type="checkbox" id="c-41875366" checked=""/><div class="controls bullet"><span class="by">jeadie</span><span>|</span><a href="#41871295">prev</a><span>|</span><a href="#41872476">next</a><span>|</span><label class="collapse" for="c-41875366">[-]</label><label class="expand" for="c-41875366">[1 more]</label></div><br/><div class="children"><div class="content">Why not just federate Postgres and parquet files? That way the query planner can push down as much of the query and reduce how much data has to move about?</div><br/></div></div></div></div></div></div></div></body></html>