<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1697446867915" as="style"/><link rel="stylesheet" href="styles.css?v=1697446867915"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://arxiv.org/abs/2310.08560">MemGPT: Towards LLMs as Operating Systems</a> <span class="domain">(<a href="https://arxiv.org">arxiv.org</a>)</span></div><div class="subtext"><span>belter</span> | <span>82 comments</span></div><br/><div><div id="37895618" class="c"><input type="checkbox" id="c-37895618" checked=""/><div class="controls bullet"><span class="by">pacjam</span><span>|</span><a href="#37895685">next</a><span>|</span><label class="collapse" for="c-37895618">[-]</label><label class="expand" for="c-37895618">[4 more]</label></div><br/><div class="children"><div class="content">Hey all, I’m the lead author on this work. Thanks to the OP for posting, and for all the interest and feedback. To clarify a few points: the goal of this work is to investigate the extent to which an LLM can manage memory and different memory hierarchies, applying lessons from operating systems to extend effective context lengths. All of our code is open sourced at <a href="https:&#x2F;&#x2F;github.com&#x2F;cpacker&#x2F;MemGPT">https:&#x2F;&#x2F;github.com&#x2F;cpacker&#x2F;MemGPT</a> so you can try it out yourselves!</div><br/><div id="37897120" class="c"><input type="checkbox" id="c-37897120" checked=""/><div class="controls bullet"><span class="by">pacjam</span><span>|</span><a href="#37895618">parent</a><span>|</span><a href="#37895912">next</a><span>|</span><label class="collapse" for="c-37897120">[-]</label><label class="expand" for="c-37897120">[1 more]</label></div><br/><div class="children"><div class="content">Update - we just released a Discord perpetual chatbot implemented on top of MemGPT, you can try it here: <a href="https:&#x2F;&#x2F;discord.gg&#x2F;9GEQrxmVyE" rel="nofollow noreferrer">https:&#x2F;&#x2F;discord.gg&#x2F;9GEQrxmVyE</a><p>You can also run the chatbot demo + a doc QA bot demo (where you can ask MemGPT about API docs) locally with the code on GitHub.</div><br/></div></div><div id="37895912" class="c"><input type="checkbox" id="c-37895912" checked=""/><div class="controls bullet"><span class="by">a1j9o94</span><span>|</span><a href="#37895618">parent</a><span>|</span><a href="#37897120">prev</a><span>|</span><a href="#37895685">next</a><span>|</span><label class="collapse" for="c-37895912">[-]</label><label class="expand" for="c-37895912">[2 more]</label></div><br/><div class="children"><div class="content">This is a fascinating approach! I posted this as a separate comment but would be curious about your response directly.<p>What do you think about the tradeoff of having an agent manage its own memory as opposed to having a separate agent whose job it is to manage the memory and the other agent just focuses on the conversation?</div><br/><div id="37895916" class="c"><input type="checkbox" id="c-37895916" checked=""/><div class="controls bullet"><span class="by">pacjam</span><span>|</span><a href="#37895618">root</a><span>|</span><a href="#37895912">parent</a><span>|</span><a href="#37895685">next</a><span>|</span><label class="collapse" for="c-37895916">[-]</label><label class="expand" for="c-37895916">[1 more]</label></div><br/><div class="children"><div class="content">Thanks for your interest! Left a comment on the other thread</div><br/></div></div></div></div></div></div><div id="37895685" class="c"><input type="checkbox" id="c-37895685" checked=""/><div class="controls bullet"><span class="by">o11c</span><span>|</span><a href="#37895618">prev</a><span>|</span><a href="#37895861">next</a><span>|</span><label class="collapse" for="c-37895685">[-]</label><label class="expand" for="c-37895685">[3 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t remember the name, but there&#x27;s already an Esolang that executes its commands unreliably. Through careful program design, you can ensure that a <i>sequence</i> of commands will execute with 99%, 99.9%, etc. reliability.</div><br/><div id="37896892" class="c"><input type="checkbox" id="c-37896892" checked=""/><div class="controls bullet"><span class="by">Aeolos</span><span>|</span><a href="#37895685">parent</a><span>|</span><a href="#37895861">next</a><span>|</span><label class="collapse" for="c-37896892">[-]</label><label class="expand" for="c-37896892">[2 more]</label></div><br/><div class="children"><div class="content">Java2000 iirc.<p>2 decades later, the same approach was unironically popularized for infrastructure as “chaos engineering”.</div><br/><div id="37897052" class="c"><input type="checkbox" id="c-37897052" checked=""/><div class="controls bullet"><span class="by">majewsky</span><span>|</span><a href="#37895685">root</a><span>|</span><a href="#37896892">parent</a><span>|</span><a href="#37895861">next</a><span>|</span><label class="collapse" for="c-37897052">[-]</label><label class="expand" for="c-37897052">[1 more]</label></div><br/><div class="children"><div class="content">Not sure if that was &#x2F;s or not, but it is indeed an important insight to realize that no IT system can have 100% reliability once you factor in hardware failures and power outages. And that&#x27;s before we talk about bugs.</div><br/></div></div></div></div></div></div><div id="37895861" class="c"><input type="checkbox" id="c-37895861" checked=""/><div class="controls bullet"><span class="by">a1j9o94</span><span>|</span><a href="#37895685">prev</a><span>|</span><a href="#37895247">next</a><span>|</span><label class="collapse" for="c-37895861">[-]</label><label class="expand" for="c-37895861">[2 more]</label></div><br/><div class="children"><div class="content">This is super interesting! I was thinking about how to approach a similar problem for a project I&#x27;m working on, and my approach is similar.<p>I am curious about the benefit of having the agent interact with the user (or doing the task) and managing its memory instead of having an observer agent that modifies the memory separately. The thought process is to let the agent use all of its tokens to focus on the task and not memory management.</div><br/><div id="37895910" class="c"><input type="checkbox" id="c-37895910" checked=""/><div class="controls bullet"><span class="by">pacjam</span><span>|</span><a href="#37895861">parent</a><span>|</span><a href="#37895247">next</a><span>|</span><label class="collapse" for="c-37895910">[-]</label><label class="expand" for="c-37895910">[1 more]</label></div><br/><div class="children"><div class="content">Explicit memory management (MemGPT-style) vs implicit&#x2F;external memory management is an interesting tradeoff. Like you said, adding all the instructions on how to manage memory consumes ~1k tokens (using the default prompts on our MemGPT GitHub release), which is a lot when your context window is 8k. Additionally, it requires the base LLM to be very good at instruction following; gpt-4 can do it well, but it&#x27;s much more difficult to get explicit memory management to work with gpt-3.5-turbo or llama2 70b finetunes (so to build a robust system, you may have to end up having to &quot;split&quot; the thinking out of necessity).<p>One of the main benefits of explicit memory management is simplicity - e.g., you don&#x27;t have to manage logic between a &quot;memory creation&quot; thread and a &quot;dialogue thread&quot;. The explicit approach also integrates well with the iterative paging&#x2F;retrieval for document analysis we demo in the paper&#x2F;on GitHub.</div><br/></div></div></div></div><div id="37896241" class="c"><input type="checkbox" id="c-37896241" checked=""/><div class="controls bullet"><span class="by">skrebbel</span><span>|</span><a href="#37895247">prev</a><span>|</span><a href="#37894980">next</a><span>|</span><label class="collapse" for="c-37896241">[-]</label><label class="expand" for="c-37896241">[11 more]</label></div><br/><div class="children"><div class="content">Sorry if this is a bit meta but why is it so popular and accepted to Just Say Stuff in AI land? Sometimes it seems to me that AI people have begun hallucinating as much as the models they’re training.<p>This article seems pretty cool but in no way has it anything to do with its title. “Operating system” has a clearly defined meaning and it’s not “a thing that has memory”. To me these kinds of grandiose claims with no substance undermine the credibility of the authors.<p>I mean what’s wrong with “Tiered memory layers to provide extended AI context windows”?</div><br/><div id="37896831" class="c"><input type="checkbox" id="c-37896831" checked=""/><div class="controls bullet"><span class="by">lgessler</span><span>|</span><a href="#37896241">parent</a><span>|</span><a href="#37896295">next</a><span>|</span><label class="collapse" for="c-37896831">[-]</label><label class="expand" for="c-37896831">[1 more]</label></div><br/><div class="children"><div class="content">IMO, as an NLP researcher, it&#x27;s a product of the &quot;fast science&quot; culture of AI where there are more papers than anyone could possibly read even in a given subfield at a particular conference, and an &quot;old&quot; paper is anything that was published over two years ago. (Who knew Bollywood movies and AI publications would have so much in common?) Maybe there are good reasons why publications should move so much more quickly in AI as opposed to, say, scholastic philosophy, but it&#x27;s undeniable that it has become a struggle to get others to even read an abstract of your work, and as such we should not be surprised when sensationalization verges on becoming a requirement for your work to get engagement.<p>So to answer your question--perhaps cynically--“Tiered memory layers to provide extended AI context windows” is not the best title you could have for an AI paper because it has all the rizz of a shipping manifest. If you want to maximize citations, you need to market more.<p>I also considered whether to blame the field&#x27;s very young reviewer population for not having the proper disdain for sensationalization that I&#x27;d expect from an older researcher who would surely have more restraint than to speak so much more of the sizzle than of the steak, but then I remembered that the paper which introduced the Transformer model was titled &quot;Attention Is All You Need&quot;.</div><br/></div></div><div id="37896295" class="c"><input type="checkbox" id="c-37896295" checked=""/><div class="controls bullet"><span class="by">isoprophlex</span><span>|</span><a href="#37896241">parent</a><span>|</span><a href="#37896831">prev</a><span>|</span><a href="#37896486">next</a><span>|</span><label class="collapse" for="c-37896295">[-]</label><label class="expand" for="c-37896295">[2 more]</label></div><br/><div class="children"><div class="content">The NFT&#x2F;web3&#x2F;shitcoin grifters had their bubble burst, so now they&#x27;re gravitating towards AI.</div><br/><div id="37896668" class="c"><input type="checkbox" id="c-37896668" checked=""/><div class="controls bullet"><span class="by">kalium-xyz</span><span>|</span><a href="#37896241">root</a><span>|</span><a href="#37896295">parent</a><span>|</span><a href="#37896486">next</a><span>|</span><label class="collapse" for="c-37896668">[-]</label><label class="expand" for="c-37896668">[1 more]</label></div><br/><div class="children"><div class="content">They already owned the video cards. Might as Well</div><br/></div></div></div></div><div id="37896486" class="c"><input type="checkbox" id="c-37896486" checked=""/><div class="controls bullet"><span class="by">pacjam</span><span>|</span><a href="#37896241">parent</a><span>|</span><a href="#37896295">prev</a><span>|</span><a href="#37896414">next</a><span>|</span><label class="collapse" for="c-37896486">[-]</label><label class="expand" for="c-37896486">[5 more]</label></div><br/><div class="children"><div class="content">Thanks for your feedback @skrebbel. We called it MemGPT - in reference to teaching LLMs how to manage their own memory hierarchy. The idea and title evolved when we realized we were teaching the LLM to read&#x2F;write, and this enabled perpetual chatbots, doc QA, etc. Various capabilities by a few simple abstractions, inspired by the original unix paper&#x27;s 4 key abstractions - read&#x2F;write&#x2F;open&#x2F;close. Further, in the title we say &quot;Towards&quot;, indicating a qualified step in that direction.</div><br/><div id="37896558" class="c"><input type="checkbox" id="c-37896558" checked=""/><div class="controls bullet"><span class="by">skrebbel</span><span>|</span><a href="#37896241">root</a><span>|</span><a href="#37896486">parent</a><span>|</span><a href="#37896617">next</a><span>|</span><label class="collapse" for="c-37896558">[-]</label><label class="expand" for="c-37896558">[1 more]</label></div><br/><div class="children"><div class="content">Perpetual chatbots are a super cool achievement but I fail to see how that resembles an OS, a thing that handles files and lets you run programs, in any way. If MemGPT is as spectacular as you suggest then I think an honest, down to earth title would have gotten you a lot more attention. It seems to me that limited context windows are one of the key roadblocks to wider real-world LLM applicability, beyond demos that do well on Twitter I mean.</div><br/></div></div><div id="37896617" class="c"><input type="checkbox" id="c-37896617" checked=""/><div class="controls bullet"><span class="by">ludwik</span><span>|</span><a href="#37896241">root</a><span>|</span><a href="#37896486">parent</a><span>|</span><a href="#37896558">prev</a><span>|</span><a href="#37896553">next</a><span>|</span><label class="collapse" for="c-37896617">[-]</label><label class="expand" for="c-37896617">[1 more]</label></div><br/><div class="children"><div class="content">I think a title like &quot;MemGPT: Operating System inspired memory management for LLMs&quot; would be okay. The current title makes it seem as if you are building an OS based on the LLM technology, which is quite misleading.</div><br/></div></div><div id="37896553" class="c"><input type="checkbox" id="c-37896553" checked=""/><div class="controls bullet"><span class="by">__void</span><span>|</span><a href="#37896241">root</a><span>|</span><a href="#37896486">parent</a><span>|</span><a href="#37896617">prev</a><span>|</span><a href="#37896612">next</a><span>|</span><label class="collapse" for="c-37896553">[-]</label><label class="expand" for="c-37896553">[1 more]</label></div><br/><div class="children"><div class="content">still this is not an &quot;operating system&quot; nor does it in any way related to them;<p>please use the right words when you have to communicate, otherwise you just sound like scammers who want to sell pots with holes by passing them off as colanders</div><br/></div></div><div id="37896612" class="c"><input type="checkbox" id="c-37896612" checked=""/><div class="controls bullet"><span class="by">abdellah123</span><span>|</span><a href="#37896241">root</a><span>|</span><a href="#37896486">parent</a><span>|</span><a href="#37896553">prev</a><span>|</span><a href="#37896414">next</a><span>|</span><label class="collapse" for="c-37896612">[-]</label><label class="expand" for="c-37896612">[1 more]</label></div><br/><div class="children"><div class="content">&gt; we were teaching the LLM to read&#x2F;write<p>Very interesting.</div><br/></div></div></div></div><div id="37896414" class="c"><input type="checkbox" id="c-37896414" checked=""/><div class="controls bullet"><span class="by">xamde</span><span>|</span><a href="#37896241">parent</a><span>|</span><a href="#37896486">prev</a><span>|</span><a href="#37896683">next</a><span>|</span><label class="collapse" for="c-37896414">[-]</label><label class="expand" for="c-37896414">[1 more]</label></div><br/><div class="children"><div class="content">This ist really a succint description: &quot;Sometimes it seems to me that AI people have begun hallucinating as much as the models they’re training.&quot;</div><br/></div></div></div></div><div id="37894980" class="c"><input type="checkbox" id="c-37894980" checked=""/><div class="controls bullet"><span class="by">behnamoh</span><span>|</span><a href="#37896241">prev</a><span>|</span><a href="#37895836">next</a><span>|</span><label class="collapse" for="c-37894980">[-]</label><label class="expand" for="c-37894980">[42 more]</label></div><br/><div class="children"><div class="content">People have to stop treating LLMs and transformer models like they&#x27;re the solution to everything. Never before had I seen so much jump on a hype by academics (I&#x27;m an academic too). Honestly it feels like mostly clout seeking and a way to improve citation numbers.</div><br/><div id="37895400" class="c"><input type="checkbox" id="c-37895400" checked=""/><div class="controls bullet"><span class="by">gmerc</span><span>|</span><a href="#37894980">parent</a><span>|</span><a href="#37895248">next</a><span>|</span><label class="collapse" for="c-37895400">[-]</label><label class="expand" for="c-37895400">[7 more]</label></div><br/><div class="children"><div class="content">Transformers are a primitive we have not fully figured out yet. So it’s perfectly fine to see where this primitive fits.<p>For example, this week several papers on time series forecasts indicate they may have use there.<p>For example they seem to do better job on translation than previous approaches.<p>For example they seem to do a better job at transcription than previous approaches.<p>Probably will do better on OCR than previous approaches.<p>Probably has flaws that limits scenarios requiring high precision we may or may not overcome<p>Possibly will better on autonomous decision making (Does x include  a privacy leak should be investigated?) than previous approaches (keyword scanning).<p>We are in a technological wave of discovery and experimentation, calls for restraint of curiosity and research betray fears</div><br/><div id="37895487" class="c"><input type="checkbox" id="c-37895487" checked=""/><div class="controls bullet"><span class="by">sigmoid10</span><span>|</span><a href="#37894980">root</a><span>|</span><a href="#37895400">parent</a><span>|</span><a href="#37895248">next</a><span>|</span><label class="collapse" for="c-37895487">[-]</label><label class="expand" for="c-37895487">[6 more]</label></div><br/><div class="children"><div class="content">It goes way beyond that. Transformers are the first practical, scalable, general-purpose differentiable (i.e. trainable with gradient descent) algorithm. We haven&#x27;t come close to seeing the limits of what they can do, because everything so far points to the fact that their only limit is our current hardware. And hardware is improving at a much faster and steadier rate than algorithms in computer science these days.</div><br/><div id="37895669" class="c"><input type="checkbox" id="c-37895669" checked=""/><div class="controls bullet"><span class="by">sterlind</span><span>|</span><a href="#37894980">root</a><span>|</span><a href="#37895487">parent</a><span>|</span><a href="#37895649">next</a><span>|</span><label class="collapse" for="c-37895669">[-]</label><label class="expand" for="c-37895669">[2 more]</label></div><br/><div class="children"><div class="content">everything? they&#x27;ve solved reinforcement learning? they can handle continuous domains, like robot motion? that&#x27;s funny, I thought they could only handle sequences of tokens.*<p>yes, they&#x27;re exciting, and they are the most general architecture we&#x27;ve found so far, but there are important problems in AI (like anything continuous), that they&#x27;re really not suited for.<p>I think there&#x27;s better architectures out there for many tasks, and I&#x27;m a little dismayed that everyone seems to be cargo-culting the GPT architecture rather than taking the lessons for transformers and experimenting with more specialized algorithms.<p>*btw they don&#x27;t <i>need</i> quantized tokens, there&#x27;s no reason they can&#x27;t just work on continuous vectors directly, and they don&#x27;t have to be causal or limited to one sequence, but &quot;transformer&quot; seems to mean GPT in everyone&#x27;s mind, and even though the original transformer was an encoder-decoder model we rarely seem to see those these days for some reason.</div><br/><div id="37895693" class="c"><input type="checkbox" id="c-37895693" checked=""/><div class="controls bullet"><span class="by">og_kalu</span><span>|</span><a href="#37894980">root</a><span>|</span><a href="#37895669">parent</a><span>|</span><a href="#37895649">next</a><span>|</span><label class="collapse" for="c-37895693">[-]</label><label class="expand" for="c-37895693">[1 more]</label></div><br/><div class="children"><div class="content">&gt;they&#x27;ve solved reinforcement learning?<p>Transformers can do Reinforcement Learning yes.<p><a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2106.01345" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2106.01345</a><p><a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2205.14953" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2205.14953</a><p>&gt;they can handle continuous domains, like robot motion?<p>Yes they can handle it just fine. Excellently in fact.<p><a href="https:&#x2F;&#x2F;www.deepmind.com&#x2F;blog&#x2F;scaling-up-learning-across-many-different-robot-types" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.deepmind.com&#x2F;blog&#x2F;scaling-up-learning-across-man...</a><p><a href="https:&#x2F;&#x2F;tidybot.cs.princeton.edu&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;tidybot.cs.princeton.edu&#x2F;</a><p><a href="https:&#x2F;&#x2F;general-pattern-machines.github.io&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;general-pattern-machines.github.io&#x2F;</a><p><a href="https:&#x2F;&#x2F;wayve.ai&#x2F;thinking&#x2F;lingo-natural-language-autonomous-driving&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;wayve.ai&#x2F;thinking&#x2F;lingo-natural-language-autonomous-...</a><p>I don&#x27;t know if anyone is saying they&#x27;re the best at or have &quot;solved&quot; everything but they can damn near do anything.</div><br/></div></div></div></div><div id="37895649" class="c"><input type="checkbox" id="c-37895649" checked=""/><div class="controls bullet"><span class="by">esafak</span><span>|</span><a href="#37894980">root</a><span>|</span><a href="#37895487">parent</a><span>|</span><a href="#37895669">prev</a><span>|</span><a href="#37895248">next</a><span>|</span><label class="collapse" for="c-37895649">[-]</label><label class="expand" for="c-37895649">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not sure about the last assertion. How would you even compare them? It is easier to deploy newer algorithms (software) than hardware.</div><br/><div id="37895928" class="c"><input type="checkbox" id="c-37895928" checked=""/><div class="controls bullet"><span class="by">sigmoid10</span><span>|</span><a href="#37894980">root</a><span>|</span><a href="#37895649">parent</a><span>|</span><a href="#37895248">next</a><span>|</span><label class="collapse" for="c-37895928">[-]</label><label class="expand" for="c-37895928">[2 more]</label></div><br/><div class="children"><div class="content">There&#x27;s two ways you can solve currently intractable problems: Find better algorithms or improve the hardware. It&#x27;s actually insanely hard to come up with new algorithms, that is why machine learning and AI were lagging behind most of computer science for decades.</div><br/></div></div></div></div></div></div></div></div><div id="37895248" class="c"><input type="checkbox" id="c-37895248" checked=""/><div class="controls bullet"><span class="by">cle</span><span>|</span><a href="#37894980">parent</a><span>|</span><a href="#37895400">prev</a><span>|</span><a href="#37895070">next</a><span>|</span><label class="collapse" for="c-37895248">[-]</label><label class="expand" for="c-37895248">[8 more]</label></div><br/><div class="children"><div class="content">I&#x27;m struggling to find where these authors are treating LLMs and transformers like they&#x27;re the solution to everything, or where they are just following hype around? These are long-time AI researchers at Berkeley who&#x27;ve developed a framework for dealing with limited context windows, drawing inspiration from operating systems.</div><br/><div id="37895360" class="c"><input type="checkbox" id="c-37895360" checked=""/><div class="controls bullet"><span class="by">behnamoh</span><span>|</span><a href="#37894980">root</a><span>|</span><a href="#37895248">parent</a><span>|</span><a href="#37895070">next</a><span>|</span><label class="collapse" for="c-37895360">[-]</label><label class="expand" for="c-37895360">[7 more]</label></div><br/><div class="children"><div class="content">&quot;LLMs as Operating Systems&quot;... —long-time AI researchers at Berkeley</div><br/><div id="37895385" class="c"><input type="checkbox" id="c-37895385" checked=""/><div class="controls bullet"><span class="by">danenania</span><span>|</span><a href="#37894980">root</a><span>|</span><a href="#37895360">parent</a><span>|</span><a href="#37895070">next</a><span>|</span><label class="collapse" for="c-37895385">[-]</label><label class="expand" for="c-37895385">[6 more]</label></div><br/><div class="children"><div class="content">In the paper, they&#x27;re talking about managing LLM context windows the way operating systems manage memory and files. They&#x27;re not saying LLMs should be used as operating systems.</div><br/><div id="37895813" class="c"><input type="checkbox" id="c-37895813" checked=""/><div class="controls bullet"><span class="by">dstanko</span><span>|</span><a href="#37894980">root</a><span>|</span><a href="#37895385">parent</a><span>|</span><a href="#37895070">next</a><span>|</span><label class="collapse" for="c-37895813">[-]</label><label class="expand" for="c-37895813">[5 more]</label></div><br/><div class="children"><div class="content">they should work on their communication skills.</div><br/><div id="37895986" class="c"><input type="checkbox" id="c-37895986" checked=""/><div class="controls bullet"><span class="by">another_story</span><span>|</span><a href="#37894980">root</a><span>|</span><a href="#37895813">parent</a><span>|</span><a href="#37895070">next</a><span>|</span><label class="collapse" for="c-37895986">[-]</label><label class="expand" for="c-37895986">[4 more]</label></div><br/><div class="children"><div class="content">This is unhelpful. People should be expected to read past headlines. The paper&#x27;s abstract takes 30 seconds to read.</div><br/><div id="37896328" class="c"><input type="checkbox" id="c-37896328" checked=""/><div class="controls bullet"><span class="by">dstanko</span><span>|</span><a href="#37894980">root</a><span>|</span><a href="#37895986">parent</a><span>|</span><a href="#37895070">next</a><span>|</span><label class="collapse" for="c-37896328">[-]</label><label class="expand" for="c-37896328">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;m sorry it&#x27;s unhelpful, but it is how I feel about the article and click-baity title. downwote all you want.</div><br/><div id="37896498" class="c"><input type="checkbox" id="c-37896498" checked=""/><div class="controls bullet"><span class="by">xcv123</span><span>|</span><a href="#37894980">root</a><span>|</span><a href="#37896328">parent</a><span>|</span><a href="#37896479">next</a><span>|</span><label class="collapse" for="c-37896498">[-]</label><label class="expand" for="c-37896498">[1 more]</label></div><br/><div class="children"><div class="content">Always cringeworthy when the average bum coder on HN with zero attention span or intellectual curiosity criticizes papers way out of their intellectual depth without reading further than the title. They are describing a new concept using &quot;operating system&quot; almost as a metaphor. This is a way to describe novel concepts. The article abstract makes the point clear and only takes a few seconds to read.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="37895070" class="c"><input type="checkbox" id="c-37895070" checked=""/><div class="controls bullet"><span class="by">Scipio_Afri</span><span>|</span><a href="#37894980">parent</a><span>|</span><a href="#37895248">prev</a><span>|</span><a href="#37895502">next</a><span>|</span><label class="collapse" for="c-37895070">[-]</label><label class="expand" for="c-37895070">[13 more]</label></div><br/><div class="children"><div class="content">The branding on this is a bit much, it’s not an operating system. However LLMs are the real deal, some papers claim they are achieving SOTA or significant breakthroughs in various domains. Surely they’re computationally intensive, but if you have read the most of the papers out of Berkeley, Microsoft, Meta, Google&#x2F;DeepMind&#x2F;Waymo… I think you’d have an change in opinion.</div><br/><div id="37895189" class="c"><input type="checkbox" id="c-37895189" checked=""/><div class="controls bullet"><span class="by">TerrifiedMouse</span><span>|</span><a href="#37894980">root</a><span>|</span><a href="#37895070">parent</a><span>|</span><a href="#37895100">next</a><span>|</span><label class="collapse" for="c-37895189">[-]</label><label class="expand" for="c-37895189">[10 more]</label></div><br/><div class="children"><div class="content">&gt; However LLMs are the real deal<p>Weird thing is it was designed to model language. It’s surprising that it returns sound answers as often as it does. But that’s also kind of the problem, it’s “surprising”, i.e. we don’t really know what happened.<p>You wouldn’t fly on a jetliner that’s “surprising it flies without disintegrating midair”.</div><br/><div id="37895277" class="c"><input type="checkbox" id="c-37895277" checked=""/><div class="controls bullet"><span class="by">s17n</span><span>|</span><a href="#37894980">root</a><span>|</span><a href="#37895189">parent</a><span>|</span><a href="#37895853">next</a><span>|</span><label class="collapse" for="c-37895277">[-]</label><label class="expand" for="c-37895277">[2 more]</label></div><br/><div class="children"><div class="content">People were pretty surprised by the Wright flyer.  Confidence is built by experience, not theoretical understanding.</div><br/><div id="37896228" class="c"><input type="checkbox" id="c-37896228" checked=""/><div class="controls bullet"><span class="by">ravetcofx</span><span>|</span><a href="#37894980">root</a><span>|</span><a href="#37895277">parent</a><span>|</span><a href="#37895853">next</a><span>|</span><label class="collapse" for="c-37896228">[-]</label><label class="expand" for="c-37896228">[1 more]</label></div><br/><div class="children"><div class="content">Science being iterative, they definitely weren&#x27;t the first to fly, and not even in a heavier than aircraft, what they did acheive was the first time the pilot had 3-axis control, and was the first powered heavier than air manned flight.</div><br/></div></div></div></div><div id="37895853" class="c"><input type="checkbox" id="c-37895853" checked=""/><div class="controls bullet"><span class="by">unblough</span><span>|</span><a href="#37894980">root</a><span>|</span><a href="#37895189">parent</a><span>|</span><a href="#37895277">prev</a><span>|</span><a href="#37895218">next</a><span>|</span><label class="collapse" for="c-37895853">[-]</label><label class="expand" for="c-37895853">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Weird thing is it was designed to model language. It’s surprising that it returns sound answers as often as it does.<p>Is this surprising? Can you point to researchers in the field being “surprised” by LLMs returning sound answers?<p>&gt; “surprising”, i.e. we don’t really know what happened.<p>This ie reads like a sort of popsci conclusion.<p>We know exactly what happened. We programmed it to perform these calculations. It’s actually rather straightforward elementary mathematics.<p>But, what happens is so many interdependent calculations grow the complexity of the problem until we are unable to hold it in it our minds, and to analyze its decisions computationally necessitates similar levels of computation for each decision being made as what was used to compute the weights.<p>As for its effectiveness, familiarity with the field of computational complexity points to high dimensional polynomial optimization problems being broadly universal solvers.</div><br/></div></div><div id="37895218" class="c"><input type="checkbox" id="c-37895218" checked=""/><div class="controls bullet"><span class="by">beoberha</span><span>|</span><a href="#37894980">root</a><span>|</span><a href="#37895189">parent</a><span>|</span><a href="#37895853">prev</a><span>|</span><a href="#37895100">next</a><span>|</span><label class="collapse" for="c-37895218">[-]</label><label class="expand" for="c-37895218">[6 more]</label></div><br/><div class="children"><div class="content">Unless you’re using an LLM to fly a plane, your analogy is a woefully bad comparison.</div><br/><div id="37895225" class="c"><input type="checkbox" id="c-37895225" checked=""/><div class="controls bullet"><span class="by">TerrifiedMouse</span><span>|</span><a href="#37894980">root</a><span>|</span><a href="#37895218">parent</a><span>|</span><a href="#37895100">next</a><span>|</span><label class="collapse" for="c-37895225">[-]</label><label class="expand" for="c-37895225">[5 more]</label></div><br/><div class="children"><div class="content">I guess my point is, if we don’t understand it, we don’t know its failure scenarios.</div><br/><div id="37895373" class="c"><input type="checkbox" id="c-37895373" checked=""/><div class="controls bullet"><span class="by">jackgolding</span><span>|</span><a href="#37894980">root</a><span>|</span><a href="#37895225">parent</a><span>|</span><a href="#37895396">next</a><span>|</span><label class="collapse" for="c-37895373">[-]</label><label class="expand" for="c-37895373">[1 more]</label></div><br/><div class="children"><div class="content">This is the case with all neural nets&#x2F;black box AI models and a lot are used in various industries.</div><br/></div></div><div id="37895396" class="c"><input type="checkbox" id="c-37895396" checked=""/><div class="controls bullet"><span class="by">tayo42</span><span>|</span><a href="#37894980">root</a><span>|</span><a href="#37895225">parent</a><span>|</span><a href="#37895373">prev</a><span>|</span><a href="#37895260">next</a><span>|</span><label class="collapse" for="c-37895396">[-]</label><label class="expand" for="c-37895396">[2 more]</label></div><br/><div class="children"><div class="content">What things are not understood about transformers?</div><br/><div id="37895525" class="c"><input type="checkbox" id="c-37895525" checked=""/><div class="controls bullet"><span class="by">aik</span><span>|</span><a href="#37894980">root</a><span>|</span><a href="#37895396">parent</a><span>|</span><a href="#37895260">next</a><span>|</span><label class="collapse" for="c-37895525">[-]</label><label class="expand" for="c-37895525">[1 more]</label></div><br/><div class="children"><div class="content">All the uses</div><br/></div></div></div></div><div id="37895260" class="c"><input type="checkbox" id="c-37895260" checked=""/><div class="controls bullet"><span class="by">omarfarooq</span><span>|</span><a href="#37894980">root</a><span>|</span><a href="#37895225">parent</a><span>|</span><a href="#37895396">prev</a><span>|</span><a href="#37895100">next</a><span>|</span><label class="collapse" for="c-37895260">[-]</label><label class="expand" for="c-37895260">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s an LLM for that.</div><br/></div></div></div></div></div></div></div></div><div id="37895253" class="c"><input type="checkbox" id="c-37895253" checked=""/><div class="controls bullet"><span class="by">mistermann</span><span>|</span><a href="#37894980">root</a><span>|</span><a href="#37895070">parent</a><span>|</span><a href="#37895100">prev</a><span>|</span><a href="#37895502">next</a><span>|</span><label class="collapse" for="c-37895253">[-]</label><label class="expand" for="c-37895253">[1 more]</label></div><br/><div class="children"><div class="content">Depends what &quot;operating system&quot; means.  I&#x27;d say things like democracy, marketing&#x2F;journalism&#x2F;propaganda, etc are operating systems of some sort, in that they perform orchestration of humans, modify reality, etc.   Lack of memory is a big handicap for LLM&#x27;s if they want to play in that league.</div><br/></div></div></div></div><div id="37895502" class="c"><input type="checkbox" id="c-37895502" checked=""/><div class="controls bullet"><span class="by">hlfshell</span><span>|</span><a href="#37894980">parent</a><span>|</span><a href="#37895070">prev</a><span>|</span><a href="#37895072">next</a><span>|</span><label class="collapse" for="c-37895502">[-]</label><label class="expand" for="c-37895502">[1 more]</label></div><br/><div class="children"><div class="content">We have found a new hammer and everything very much looks like a nail.<p>It&#x27;s perfectly natural and allows us to figure out what does and doesn&#x27;t work, even if it means sometimes we have to deal with empty hype projects.</div><br/></div></div><div id="37895072" class="c"><input type="checkbox" id="c-37895072" checked=""/><div class="controls bullet"><span class="by">avmich</span><span>|</span><a href="#37894980">parent</a><span>|</span><a href="#37895502">prev</a><span>|</span><a href="#37895043">next</a><span>|</span><label class="collapse" for="c-37895072">[-]</label><label class="expand" for="c-37895072">[1 more]</label></div><br/><div class="children"><div class="content">Judge it by its merits.<p>If the object of hype adds useful novelty, the interest could be justified. If, as it&#x27;s often the case, it is not quite known - it&#x27;s a question to figure out.<p>Granted, intuition is worth something, but it&#x27;s still not a certainty, so somebody having a different opinion still could see something useful here.</div><br/></div></div><div id="37895043" class="c"><input type="checkbox" id="c-37895043" checked=""/><div class="controls bullet"><span class="by">infecto</span><span>|</span><a href="#37894980">parent</a><span>|</span><a href="#37895072">prev</a><span>|</span><a href="#37895126">next</a><span>|</span><label class="collapse" for="c-37895043">[-]</label><label class="expand" for="c-37895043">[1 more]</label></div><br/><div class="children"><div class="content">I agree they are probably being over-applied but I for one am fascinated and excited for the future and all the possibilities. It’s amazing how much effort is being applied across the board and failures to me just progress other research.</div><br/></div></div><div id="37895126" class="c"><input type="checkbox" id="c-37895126" checked=""/><div class="controls bullet"><span class="by">pylua</span><span>|</span><a href="#37894980">parent</a><span>|</span><a href="#37895043">prev</a><span>|</span><a href="#37895136">next</a><span>|</span><label class="collapse" for="c-37895126">[-]</label><label class="expand" for="c-37895126">[1 more]</label></div><br/><div class="children"><div class="content">It deserves to be explored. A lot of research is just applying existing techniques to problems with a few tweaks and documenting the results.<p>I did not read the paper, but it could be that the authors find it is not effective.</div><br/></div></div><div id="37895136" class="c"><input type="checkbox" id="c-37895136" checked=""/><div class="controls bullet"><span class="by">keyle</span><span>|</span><a href="#37894980">parent</a><span>|</span><a href="#37895126">prev</a><span>|</span><a href="#37895371">next</a><span>|</span><label class="collapse" for="c-37895136">[-]</label><label class="expand" for="c-37895136">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m a software developer, I live in the concrete world.<p>To put it in layman&#x27;s terms, LLMs are to software developers what power tools were for tradesmen.<p>Sure you can still use your old screw driver, and for some work, it&#x27;s not worth getting your electric drill out; but it&#x27;s a game changer.<p>Sometimes, the hype is justified. I believe at the OS layers, LLM support would make sense. It&#x27;s full of old mental constructs and &quot;I have to remember how to do this&quot;.</div><br/></div></div><div id="37895371" class="c"><input type="checkbox" id="c-37895371" checked=""/><div class="controls bullet"><span class="by">IOT_Apprentice</span><span>|</span><a href="#37894980">parent</a><span>|</span><a href="#37895136">prev</a><span>|</span><a href="#37895376">next</a><span>|</span><label class="collapse" for="c-37895371">[-]</label><label class="expand" for="c-37895371">[2 more]</label></div><br/><div class="children"><div class="content">Sure if the initial blockchain hype  I remember people wanted to build a OS.</div><br/><div id="37895378" class="c"><input type="checkbox" id="c-37895378" checked=""/><div class="controls bullet"><span class="by">yieldcrv</span><span>|</span><a href="#37894980">root</a><span>|</span><a href="#37895371">parent</a><span>|</span><a href="#37895376">next</a><span>|</span><label class="collapse" for="c-37895378">[-]</label><label class="expand" for="c-37895378">[1 more]</label></div><br/><div class="children"><div class="content">Some of those “OS”es did launch, but theyve been rebranded to SDKs</div><br/></div></div></div></div><div id="37895376" class="c"><input type="checkbox" id="c-37895376" checked=""/><div class="controls bullet"><span class="by">greatpostman</span><span>|</span><a href="#37894980">parent</a><span>|</span><a href="#37895371">prev</a><span>|</span><a href="#37895424">next</a><span>|</span><label class="collapse" for="c-37895376">[-]</label><label class="expand" for="c-37895376">[1 more]</label></div><br/><div class="children"><div class="content">LLMs are a step function change in computers</div><br/></div></div><div id="37895424" class="c"><input type="checkbox" id="c-37895424" checked=""/><div class="controls bullet"><span class="by">nyolfen</span><span>|</span><a href="#37894980">parent</a><span>|</span><a href="#37895376">prev</a><span>|</span><a href="#37895039">next</a><span>|</span><label class="collapse" for="c-37895424">[-]</label><label class="expand" for="c-37895424">[1 more]</label></div><br/><div class="children"><div class="content">they are very clearly the most powerful technological innovation i&#x27;ve witnessed in my adult life. we don&#x27;t even know what they&#x27;re capable of yet, we&#x27;re like one year into discovering practical usecases and they are improving at a constant dizzying rate. this is the time for exploration and experimentation.</div><br/></div></div><div id="37895039" class="c"><input type="checkbox" id="c-37895039" checked=""/><div class="controls bullet"><span class="by">anon291</span><span>|</span><a href="#37894980">parent</a><span>|</span><a href="#37895424">prev</a><span>|</span><a href="#37895413">next</a><span>|</span><label class="collapse" for="c-37895039">[-]</label><label class="expand" for="c-37895039">[1 more]</label></div><br/><div class="children"><div class="content">I would agree, but on the other hand, Transformer (or attention really) based models seem to be the first time that computers are generating ad hoc human text on a variety of topics, so I do believe the hype is justified. I mean... people have spent entire careers in pursuit of this goal, and it&#x27;s here... as long as what you want to talk about is less than 4096 &#x2F; some K tokens.<p>Given how little progress (relatively) was made until transformers, it seems totally reasonable to pursue att ention models.</div><br/></div></div><div id="37895413" class="c"><input type="checkbox" id="c-37895413" checked=""/><div class="controls bullet"><span class="by">rvz</span><span>|</span><a href="#37894980">parent</a><span>|</span><a href="#37895039">prev</a><span>|</span><a href="#37895243">next</a><span>|</span><label class="collapse" for="c-37895413">[-]</label><label class="expand" for="c-37895413">[2 more]</label></div><br/><div class="children"><div class="content">Precisely this. This doesn&#x27;t solve anything and appears to be absurd techno-solutionism at this point.<p>Every single problem does not need to be solved using an LLM, which this paper tells us the amount of desperation in this hype cycle.<p>Those reading this paper and giving it credibility have fallen for this nonsense and are probably gullible enough to believe in this non use-case.</div><br/><div id="37896774" class="c"><input type="checkbox" id="c-37896774" checked=""/><div class="controls bullet"><span class="by">Philpax</span><span>|</span><a href="#37894980">root</a><span>|</span><a href="#37895413">parent</a><span>|</span><a href="#37895243">next</a><span>|</span><label class="collapse" for="c-37896774">[-]</label><label class="expand" for="c-37896774">[1 more]</label></div><br/><div class="children"><div class="content">Did you read the paper? What exactly do you think it does?</div><br/></div></div></div></div></div></div><div id="37895836" class="c"><input type="checkbox" id="c-37895836" checked=""/><div class="controls bullet"><span class="by">hereforcomments</span><span>|</span><a href="#37894980">prev</a><span>|</span><a href="#37895684">next</a><span>|</span><label class="collapse" for="c-37895836">[-]</label><label class="expand" for="c-37895836">[5 more]</label></div><br/><div class="children"><div class="content">There will be a Hackathon at work and with my team mate we are preparing with some kind of hierarchical memory&#x2F;knowledge solution.<p>Briefly: we tell ChatGPT what API based tools we have, explaines them in 1 sentence and where it can reach their documentation. We added documentations as endpoint. example.com&#x2F;docs&#x2F;main is always the starting point that returns high level overview of the app and all available endpoints to call. Every endpoint has its own documentation as well. E.g.: &#x2F;geocoder has &#x2F;docs&#x2F;geocoder documentation endpoint that describes what it does, what input it expects and what it will return.<p>We also provieded ChatGPT with actions like read_docs, call_endpoint and end_conversation. An action is a structured JSON object with a set of parameters. If ChatGPT wants to interact with the mentioned resources, it emits an action, it gets executed and the answer fed back to it.<p>With this I can do a task like: &quot;Get a 30 minutes drivetime polygon around 15 Bond Street, London and send it to Foster.&quot;<p>It plans and executes the following all alone. First it calls the geocoder to get the coordinates for the isochrone endpoint, then gets the isochrone by calling the isochrone 
endpoint and saves it, calls Microsoft Graph API and queries my top 50 connections to find out who Foster is and calls the MS Graph API&#x27;s send mail endpoint to send the email with attachment to Foster.<p>It can hierarchically explore the available resources so we don&#x27;t need a huge context window and we don&#x27;t have to train the model either. Also we could implement multiple agents. 1 would be a manager and there could me multiple agents to perform each task and return the results to the manager. It would furthet reduce reduce the required context window.<p>Very likely some BS app will win the Hackathon like always like a market price predictor using Weka&#x27;s multilayer perceptron with default settings but we believe our solution could be extremely powerful.</div><br/><div id="37895898" class="c"><input type="checkbox" id="c-37895898" checked=""/><div class="controls bullet"><span class="by">a1j9o94</span><span>|</span><a href="#37895836">parent</a><span>|</span><a href="#37896684">next</a><span>|</span><label class="collapse" for="c-37895898">[-]</label><label class="expand" for="c-37895898">[3 more]</label></div><br/><div class="children"><div class="content">This is interesting. Can you expand on how this gets around the context window problem? Are you thinking the agent does a one-off task rather than continuing back and forth with the user?<p>I do think this will be way less than having all of the functions listed to begin with though. I think the discoverability is a novel approach. Honestly, I&#x27;m surprised ChatGPT with plugins doesn&#x27;t do something like this by default rather than making you pick which plugins you want at the beginning of the conversation.</div><br/><div id="37895969" class="c"><input type="checkbox" id="c-37895969" checked=""/><div class="controls bullet"><span class="by">hereforcomments</span><span>|</span><a href="#37895836">root</a><span>|</span><a href="#37895898">parent</a><span>|</span><a href="#37896684">next</a><span>|</span><label class="collapse" for="c-37895969">[-]</label><label class="expand" for="c-37895969">[2 more]</label></div><br/><div class="children"><div class="content">First, the discoverability reduces the required context window. We don&#x27;t have to explain every app we have, it&#x27;s enough to tell ChatGPT one sentence about them and it will go deeper if it thinks that would help it to perform the task.<p>Also, we have not implemented it, we can have one or multiple level of managers just like at a company and each would delegate a task to a worker (who could also be a manager) and they would report back the result. Just like in real life, a manager doesn&#x27;t have to know how something is done, it should only know it&#x27;s done and the get the results.<p>We work for a large company and very likely have 100s of apps. We could build wrappers around them e.g. using selenium and we could interact with even old apps.<p>We could also do the same approach with databases. The db itself would have docs, each table and each field as well. So we could ask ChatGPT to query data from the db and it could fully understand the data before writing the sql query.</div><br/><div id="37896174" class="c"><input type="checkbox" id="c-37896174" checked=""/><div class="controls bullet"><span class="by">novax81</span><span>|</span><a href="#37895836">root</a><span>|</span><a href="#37895969">parent</a><span>|</span><a href="#37896684">next</a><span>|</span><label class="collapse" for="c-37896174">[-]</label><label class="expand" for="c-37896174">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve written about some hierarchical manager system with some friends when exploring how to use AI for larger set tasks.  While the easy answer is simply using something with much larger context - `Claude` is amazing with an API key if you&#x27;re on the waitlist - we definitely followed the same idea of splitting up the context into individual groups.<p>We had some success actually with layering another AI into the mix - having one AI look at a <i>summary</i> version of the context as a whole, and decide which pieces of context to assign to each manager.  This of course requires a sidestep into another database of some kind to store the &quot;master context&quot; (AKA the full conversation, so you likely already have it in some form of storage), and of course a lot more calls to the AI which overall increases latency quite a bit.<p>1. Use an AI to provide a short summary of each piece of logical context and map it by access ID
2. Use another AI to determine which pieces contain the most useful additional context to the piece of the task being evaluated
3. Build the context from the generated ID list and pass to individual task manager AI</div><br/></div></div></div></div></div></div></div></div><div id="37895684" class="c"><input type="checkbox" id="c-37895684" checked=""/><div class="controls bullet"><span class="by">danielmarkbruce</span><span>|</span><a href="#37895836">prev</a><span>|</span><a href="#37896988">next</a><span>|</span><label class="collapse" for="c-37895684">[-]</label><label class="expand" for="c-37895684">[2 more]</label></div><br/><div class="children"><div class="content">This paper could be interesting but the title and analogy are so absurd sounding that most people won&#x27;t read it.</div><br/></div></div><div id="37896988" class="c"><input type="checkbox" id="c-37896988" checked=""/><div class="controls bullet"><span class="by">mgaunard</span><span>|</span><a href="#37895684">prev</a><span>|</span><a href="#37895462">next</a><span>|</span><label class="collapse" for="c-37896988">[-]</label><label class="expand" for="c-37896988">[2 more]</label></div><br/><div class="children"><div class="content">As a software engineer, the last thing I need from my operating system is to be a LLM.<p>Thankfully, this paper is not that; the name is just misleading.</div><br/></div></div><div id="37895462" class="c"><input type="checkbox" id="c-37895462" checked=""/><div class="controls bullet"><span class="by">lyapunova</span><span>|</span><a href="#37896988">prev</a><span>|</span><a href="#37895639">next</a><span>|</span><label class="collapse" for="c-37895462">[-]</label><label class="expand" for="c-37895462">[6 more]</label></div><br/><div class="children"><div class="content">I think the problem with stuff like this is that in many cases the authors have an idea like &quot;LLMS + ???? = Operating System !&quot;<p>which is not that hard of an idea to come up with. Generally in each instance of LLM + ???? = &quot;thing&quot;, the first papers that come out to fill the ???? with an answer do that in a rush to get on arxiv and so naturally the work is lackluster (since they have barely had time to think about an actual good solution for the ????).</div><br/><div id="37895663" class="c"><input type="checkbox" id="c-37895663" checked=""/><div class="controls bullet"><span class="by">BasilPH</span><span>|</span><a href="#37895462">parent</a><span>|</span><a href="#37895737">next</a><span>|</span><label class="collapse" for="c-37895663">[-]</label><label class="expand" for="c-37895663">[1 more]</label></div><br/><div class="children"><div class="content">My initial reaction when reading the title was the same. Their abstract does a better job at explaining what they actually do, and where the connection with an OS comes in:<p>&gt; To enable using context beyond limited context windows, we propose virtual context management, a technique drawing inspiration from hierarchical memory systems in traditional operating systems that provide the appearance of large memory resources through data movement between fast and slow memory.</div><br/></div></div><div id="37895737" class="c"><input type="checkbox" id="c-37895737" checked=""/><div class="controls bullet"><span class="by">pacjam</span><span>|</span><a href="#37895462">parent</a><span>|</span><a href="#37895663">prev</a><span>|</span><a href="#37895585">next</a><span>|</span><label class="collapse" for="c-37895737">[-]</label><label class="expand" for="c-37895737">[1 more]</label></div><br/><div class="children"><div class="content">Hey OP, thank you for the post. In this work, we are looking at one particular functionality of an OS - memory management. The project started off motivated by trying to extend context length for a project we were working on. The analogy to OSes came naturally as the project progressed and there was growing similarity to the caching and memory hierarchy relation.</div><br/></div></div><div id="37895585" class="c"><input type="checkbox" id="c-37895585" checked=""/><div class="controls bullet"><span class="by">SV_BubbleTime</span><span>|</span><a href="#37895462">parent</a><span>|</span><a href="#37895737">prev</a><span>|</span><a href="#37896685">next</a><span>|</span><label class="collapse" for="c-37895585">[-]</label><label class="expand" for="c-37895585">[2 more]</label></div><br/><div class="children"><div class="content">Did you think these people just stopped existing when crypto took a dump? Blockchain all the things… LLM all the things!<p>At least LLMs have a very obvious use from day1… but an OS is not one of them.</div><br/><div id="37895692" class="c"><input type="checkbox" id="c-37895692" checked=""/><div class="controls bullet"><span class="by">lacrimacida</span><span>|</span><a href="#37895462">root</a><span>|</span><a href="#37895585">parent</a><span>|</span><a href="#37896685">next</a><span>|</span><label class="collapse" for="c-37895692">[-]</label><label class="expand" for="c-37895692">[1 more]</label></div><br/><div class="children"><div class="content">You’re probably thinking of a traditional OS. This could be an interesting project though.</div><br/></div></div></div></div></div></div><div id="37895639" class="c"><input type="checkbox" id="c-37895639" checked=""/><div class="controls bullet"><span class="by">tayo42</span><span>|</span><a href="#37895462">prev</a><span>|</span><label class="collapse" for="c-37895639">[-]</label><label class="expand" for="c-37895639">[3 more]</label></div><br/><div class="children"><div class="content">This comment section is wild right now btw, no one is responding to the content, just the, i guess, misleading title.<p>The OS in the title is making a comparison to how page caches work. Relevant data is moved into the context the llm needs to answer chat questions. When it runs out of memory it moves a condensed, searchable version of the content to another data store. Its trying to solve the problem of relatively low max token limits.<p>I wonder if this makes it easier to run on small devices?</div><br/><div id="37895696" class="c"><input type="checkbox" id="c-37895696" checked=""/><div class="controls bullet"><span class="by">pacjam</span><span>|</span><a href="#37895639">parent</a><span>|</span><a href="#37896691">next</a><span>|</span><label class="collapse" for="c-37895696">[-]</label><label class="expand" for="c-37895696">[1 more]</label></div><br/><div class="children"><div class="content">Thanks for checking out our work! Yeah, great point, this is even more critical in those scenarios when you have very limited memory. You can play around with different context sizes using the code on GitHub: <a href="https:&#x2F;&#x2F;github.com&#x2F;cpacker&#x2F;MemGPT&#x2F;blob&#x2F;main&#x2F;memgpt&#x2F;constants.py#L16">https:&#x2F;&#x2F;github.com&#x2F;cpacker&#x2F;MemGPT&#x2F;blob&#x2F;main&#x2F;memgpt&#x2F;constants...</a></div><br/></div></div></div></div></div></div></div></div></div></body></html>