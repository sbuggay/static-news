<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1737277254133" as="style"/><link rel="stylesheet" href="styles.css?v=1737277254133"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://chipsandcheese.com/p/inside-the-amd-radeon-instinct-mi300as">The AMD Radeon Instinct MI300A&#x27;s Giant Memory Subsystem</a> <span class="domain">(<a href="https://chipsandcheese.com">chipsandcheese.com</a>)</span></div><div class="subtext"><span>pella</span> | <span>83 comments</span></div><br/><div><div id="42748940" class="c"><input type="checkbox" id="c-42748940" checked=""/><div class="controls bullet"><span class="by">btown</span><span>|</span><a href="#42749299">next</a><span>|</span><label class="collapse" for="c-42748940">[-]</label><label class="expand" for="c-42748940">[44 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve often thought that one of the places AMD could distinguish itself from NVIDIA is bringing significantly higher amounts of VRAM (or memory systems that are as performant as what we currently know as VRAM) to the consumer space.<p>A card with a fraction of the FLOPS of cutting-edge graphics cards (and ideally proportionally less power consumption), but with 64-128GB VRAM-equivalent, would be a gamechanger for letting people experiment with large multi-modal models, and seriously incentivize researchers to build the next generation of tensor abstraction libraries for both CUDA and ROCm&#x2F;HIP. And for gaming, you could break new grounds on high-resolution textures. AMD would be back in the game.<p>Of course, if it&#x27;s not real VRAM, it needs to be at least somewhat close on the latency and bandwidth front, so let&#x27;s pop on over and see what&#x27;s happening in this article...<p>&gt; An Infinity Cache hit has a load-to-use latency of over 140 ns. Even DRAM on the AMD Ryzen 9 7950X3D shows less latency. Missing Infinity Cache of course drives latency up even higher, to a staggering 227 ns. HBM stands for High Bandwidth Memory, not low latency memory, and it shows.<p>Welp. Guess my wish isn&#x27;t coming true today.</div><br/><div id="42749201" class="c"><input type="checkbox" id="c-42749201" checked=""/><div class="controls bullet"><span class="by">enragedcacti</span><span>|</span><a href="#42748940">parent</a><span>|</span><a href="#42749096">next</a><span>|</span><label class="collapse" for="c-42749201">[-]</label><label class="expand" for="c-42749201">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Of course, if it&#x27;s not real VRAM, it needs to be at least somewhat close on the latency and bandwidth front<p>It is close to <i>VRAM</i>*, just not close to DRAM on a conventionally designed CPU. This thing is effectively just a GPU that fits in a CPU slot and has CPU cores bolted to the side. This approach has the downside of worse CPU performance and the upsides of orders of magnitude faster CPU&lt;-&gt;GPU communication, simpler programming since coherency is handled for you, and access to substantial amounts of high bandwidth memory (up to 512GB with 4 MI300As).<p>* <a href="https:&#x2F;&#x2F;chipsandcheese.com&#x2F;p&#x2F;microbenchmarking-nvidias-rtx-4090" rel="nofollow">https:&#x2F;&#x2F;chipsandcheese.com&#x2F;p&#x2F;microbenchmarking-nvidias-rtx-4...</a></div><br/><div id="42751139" class="c"><input type="checkbox" id="c-42751139" checked=""/><div class="controls bullet"><span class="by">rbanffy</span><span>|</span><a href="#42748940">root</a><span>|</span><a href="#42749201">parent</a><span>|</span><a href="#42749096">next</a><span>|</span><label class="collapse" for="c-42751139">[-]</label><label class="expand" for="c-42751139">[1 more]</label></div><br/><div class="children"><div class="content">I was curious because given the latencies between the CCXs, the number of NUMA domains seems small.</div><br/></div></div></div></div><div id="42749096" class="c"><input type="checkbox" id="c-42749096" checked=""/><div class="controls bullet"><span class="by">Fade_Dance</span><span>|</span><a href="#42748940">parent</a><span>|</span><a href="#42749201">prev</a><span>|</span><a href="#42749048">next</a><span>|</span><label class="collapse" for="c-42749096">[-]</label><label class="expand" for="c-42749096">[6 more]</label></div><br/><div class="children"><div class="content">Assuming we are comparing chips that are using the latest generation&#x2F;high density memory modules, a wider bus width is required for larger memory counts, which is expensive when it comes to silicon area. Therefore, if AMD is willing to boost up memory count as a competitive advantage, they may as well also consider using that die space for more logic gates as well. It&#x27;s a set of trade-offs and an optimization problem to some degree.<p>That said, when an incumbent has a leadership advantage, one of the obvious ways to boost profit is to slash the memory bus width, and then a competitor can come in and bring it up a bit and have a competitive offering. The industry has certainly seen this pattern many times. But as far as AMD coming in and using gigantic memory counts as a competitive advantage? You have to keep in mind the die space constraints.<p>Well over a decade ago - I think it was R600 - AMD did take this approach, and it was fairly disastrous because the logic performance of the chip wasn&#x27;t good enough while the die was too big and hot and yields were too low. They didn&#x27;t strike the right balance and sacrificed too much for a 512-bit memory bus.<p>AMD has also tried to sidestep some of these limitations with HBM back when it was new technology, but that didn&#x27;t work out for them either. They actually would have been better off just increasing bus width and continuing to use the most optimized and cost efficient commodity memory chips in that case.<p>Data center and such may have a bit more freedom for innovation but the consumer space is definitely stuck on the paradigm of GPU plus nearby mem chips, and going outside of that fence is a huge latency hit.</div><br/><div id="42752086" class="c"><input type="checkbox" id="c-42752086" checked=""/><div class="controls bullet"><span class="by">Dylan16807</span><span>|</span><a href="#42748940">root</a><span>|</span><a href="#42749096">parent</a><span>|</span><a href="#42749451">next</a><span>|</span><label class="collapse" for="c-42752086">[-]</label><label class="expand" for="c-42752086">[1 more]</label></div><br/><div class="children"><div class="content">&gt; a wider bus width is required for larger memory counts<p>Most video cards wire up 32 data pins to each memory chip.  But GDDR chips already have full support for running 16 pins to each chip.  And DDR commonly goes down to <i>4</i> data pins per chip.<p>The latest GDDR7 chips are 24Gbit, and at 16 bits each you could fit 48GB onto a nice easy 256 bit bus, with a speed of at least 1TB&#x2F;s.  If you use 384 bits and&#x2F;or send 8 to each chip, you can cram in so many chips it becomes a matter of <i>fitting</i> everything.</div><br/></div></div><div id="42749451" class="c"><input type="checkbox" id="c-42749451" checked=""/><div class="controls bullet"><span class="by">amluto</span><span>|</span><a href="#42748940">root</a><span>|</span><a href="#42749096">parent</a><span>|</span><a href="#42752086">prev</a><span>|</span><a href="#42749048">next</a><span>|</span><label class="collapse" for="c-42749451">[-]</label><label class="expand" for="c-42749451">[4 more]</label></div><br/><div class="children"><div class="content">&gt; a wider bus width is required for larger memory counts, which is expensive when it comes to silicon area<p>I find this constraint to be rather odd. An extra, say, three address bits would add very little space (or latency in a serial protocol) to a memory bus, and the actual problem seems to be that the current generation of memory chips are intended for point-to-point connection.<p>It seems to me that, if the memory vendors aren’t building physically larger, higher capacity chips, then any of the major players (AMD, Nvidia, Intel, whoever else is in this field right now) could kludge around it with a multiplexer.  A multiplexer would need to be somewhat large, but its job would be simple enough that it should be doable with an older, cheaper process and without using entirely unreasonable amounts of power.<p>So my assumption is this is mostly an economic issue.  The vendors don’t think it’s worthwhile to do this.</div><br/><div id="42749962" class="c"><input type="checkbox" id="c-42749962" checked=""/><div class="controls bullet"><span class="by">sroussey</span><span>|</span><a href="#42748940">root</a><span>|</span><a href="#42749451">parent</a><span>|</span><a href="#42751635">next</a><span>|</span><label class="collapse" for="c-42749962">[-]</label><label class="expand" for="c-42749962">[1 more]</label></div><br/><div class="children"><div class="content">Bus width they are talking about are multiples of 128. I think Apple m series chips are good examples. They go from 128 to 256 to 512 bits which just happens to be roughly about the megabytes per second bandwidth.</div><br/></div></div><div id="42751635" class="c"><input type="checkbox" id="c-42751635" checked=""/><div class="controls bullet"><span class="by">formerly_proven</span><span>|</span><a href="#42748940">root</a><span>|</span><a href="#42749451">parent</a><span>|</span><a href="#42749962">prev</a><span>|</span><a href="#42749048">next</a><span>|</span><label class="collapse" for="c-42751635">[-]</label><label class="expand" for="c-42751635">[2 more]</label></div><br/><div class="children"><div class="content">GDDR has been point-to-point since... I dunno, probably 2000? Because cet par you can&#x27;t really have an actual <i>bus</i> when you chase maximum bandwidth. Even the double-sided layouts (like T-layout, with &lt;2mm stubs) typically incur a reduction in data rate. These also dissipate a fair amount of heat, you&#x27;re looking at around 5-8 W per chip (~6 pJ&#x2F;bit), it&#x27;s not like you can just stack a bunch of those dies.<p>&gt; A multiplexer would need to be somewhat large, but its job would be simple enough that it should be doable with an older, cheaper process and without using entirely unreasonable amounts of power.<p>I don&#x27;t know what you&#x27;re basing that on. We&#x27;re talking about 32 Gbps serdes here. Yes, there&#x27;s multiplexers even for that. But what good is deciding which memory chip you want to use on boot-up?</div><br/><div id="42752242" class="c"><input type="checkbox" id="c-42752242" checked=""/><div class="controls bullet"><span class="by">amluto</span><span>|</span><a href="#42748940">root</a><span>|</span><a href="#42751635">parent</a><span>|</span><a href="#42749048">next</a><span>|</span><label class="collapse" for="c-42752242">[-]</label><label class="expand" for="c-42752242">[1 more]</label></div><br/><div class="children"><div class="content">Not multiplexed on boot — multiplexed at run time. Build a chip that speaks the GDDR protocol to the host GPU and has 2-4 GDDR channels coming out the other end and aggregates the attached memory at the cost of an extra chip, some latency, some power, and an extra chip. As far as the GPU is concerned, it’s an extra large GDDR chip, and it would allow a GPU vendor to squeeze in more RAM without adding more pins to the GPU or needing to route more memory channels directly to it.<p>(Compare to something like Apple’s designs or “Project Digits”. Current- and next-gen GPUs have considerably higher memory bandwidth but considerably less memory capacity.  Mostly my point is that I think Nvidia or AMD could make a desktop-style GPU with 2-4x the RAM, somewhat worse latency, but otherwise equivalent performance without needing Samsung or another vendor to build higher capacity GDDR chips than currently exist.)</div><br/></div></div></div></div></div></div></div></div><div id="42749048" class="c"><input type="checkbox" id="c-42749048" checked=""/><div class="controls bullet"><span class="by">mpercival531</span><span>|</span><a href="#42748940">parent</a><span>|</span><a href="#42749096">prev</a><span>|</span><a href="#42749785">next</a><span>|</span><label class="collapse" for="c-42749048">[-]</label><label class="expand" for="c-42749048">[11 more]</label></div><br/><div class="children"><div class="content">They are. Strix Halo is going after that same space of Apple M4 Pro&#x2F;Max where it is currently unchallenged. Pairing it with two 64GB LPCAMM2 modules will get you there.<p>Edit: The problem with AMD is less the hardware offerings, but more that their compute software stack historically tends to handwave or be very slow with consumer GPU support — even more so with their APUs. Maybe the advent of MI300A will change the equation, maybe not.</div><br/><div id="42749929" class="c"><input type="checkbox" id="c-42749929" checked=""/><div class="controls bullet"><span class="by">lhl</span><span>|</span><a href="#42748940">root</a><span>|</span><a href="#42749048">parent</a><span>|</span><a href="#42752317">next</a><span>|</span><label class="collapse" for="c-42749929">[-]</label><label class="expand" for="c-42749929">[9 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t know of any non-soldered memory Strix Halo devices, but both HP and Asus have announced 128GB SKUs (availability unknown).<p>For LLM inference, basically everything works w&#x2F; ROCm on RDNA3 now (well, Flash Attention is via Triton and doesn&#x27;t have support for SWA and some other stuff; also I mostly test on Linux, although I did check that the new WSL2 support works). I&#x27;ve tested some older APUs w&#x2F; basic benchmarking as well. Notes here for those interested: <a href="https:&#x2F;&#x2F;llm-tracker.info&#x2F;howto&#x2F;AMD-GPUs" rel="nofollow">https:&#x2F;&#x2F;llm-tracker.info&#x2F;howto&#x2F;AMD-GPUs</a></div><br/><div id="42750062" class="c"><input type="checkbox" id="c-42750062" checked=""/><div class="controls bullet"><span class="by">UncleOxidant</span><span>|</span><a href="#42748940">root</a><span>|</span><a href="#42749929">parent</a><span>|</span><a href="#42752317">next</a><span>|</span><label class="collapse" for="c-42750062">[-]</label><label class="expand" for="c-42750062">[8 more]</label></div><br/><div class="children"><div class="content">Thanks for that link. I&#x27;m interested in either getting the HP Mini Z1 G1a or an NVidia Digits for LLM experimentation. The obvious advantage for the Digits is the CUDA ecosystem is much more tried &amp; true for that kind of thing. But the disadvantage is trying to use it as a replacement for my current PC as well as the fact that it&#x27;s going to run an already old version of Ubuntu (22.04) and you&#x27;re dependent on Nvidia for updates.</div><br/><div id="42750176" class="c"><input type="checkbox" id="c-42750176" checked=""/><div class="controls bullet"><span class="by">lhl</span><span>|</span><a href="#42748940">root</a><span>|</span><a href="#42750062">parent</a><span>|</span><a href="#42750988">next</a><span>|</span><label class="collapse" for="c-42750176">[-]</label><label class="expand" for="c-42750176">[4 more]</label></div><br/><div class="children"><div class="content">Yeah, I think anyone w&#x2F; old Jetsons knows what it&#x27;s like to be left high and dry by Nvidia&#x27;s embedded software support. Older models are basically just ewaste. Since the Digits won&#x27;t be out until May, I guess there&#x27;s enough time to wait and see - at least to get a sense of what the actual specs are. I have a feeling the FP16 TFLOPS and the MBW are going to be much lower than what people have been hyping themselves up for.<p>Sadly, my feeling is that the big Strix Halo SKUs (which have no scheduled release dates) aren&#x27;t going to be competitively priced (they&#x27;re likely to be at a big FLOPS&#x2F;real-world performance disadvantage, and there&#x27;s still the PITA factor), but there is something appealing about about the do-it-all aspect of it.</div><br/><div id="42751178" class="c"><input type="checkbox" id="c-42751178" checked=""/><div class="controls bullet"><span class="by">rbanffy</span><span>|</span><a href="#42748940">root</a><span>|</span><a href="#42750176">parent</a><span>|</span><a href="#42750988">next</a><span>|</span><label class="collapse" for="c-42751178">[-]</label><label class="expand" for="c-42751178">[3 more]</label></div><br/><div class="children"><div class="content">DIGITS looks like a serious attempt, but they don’t have too much of an incentive to have people developing for older hardware. I wouldn’t expect them to supor it for more than five years. At least the underlying Ubuntu will last more than that and provide a viable work environment far beyond the time it gets really boring.</div><br/><div id="42751801" class="c"><input type="checkbox" id="c-42751801" checked=""/><div class="controls bullet"><span class="by">UncleOxidant</span><span>|</span><a href="#42748940">root</a><span>|</span><a href="#42751178">parent</a><span>|</span><a href="#42750988">next</a><span>|</span><label class="collapse" for="c-42751801">[-]</label><label class="expand" for="c-42751801">[2 more]</label></div><br/><div class="children"><div class="content">If only they could get their changes upstreamed to Ubuntu (and possible kernel mods upstreamed), then we wouldn&#x27;t have to worry about it.</div><br/><div id="42751874" class="c"><input type="checkbox" id="c-42751874" checked=""/><div class="controls bullet"><span class="by">rbanffy</span><span>|</span><a href="#42748940">root</a><span>|</span><a href="#42751801">parent</a><span>|</span><a href="#42750988">next</a><span>|</span><label class="collapse" for="c-42751874">[-]</label><label class="expand" for="c-42751874">[1 more]</label></div><br/><div class="children"><div class="content">Getting their kernel mods upstreamed is very unlikely, but they might provide just enough you can build a new kernel with the same major version number.</div><br/></div></div></div></div></div></div></div></div><div id="42750988" class="c"><input type="checkbox" id="c-42750988" checked=""/><div class="controls bullet"><span class="by">KeplerBoy</span><span>|</span><a href="#42748940">root</a><span>|</span><a href="#42750062">parent</a><span>|</span><a href="#42750176">prev</a><span>|</span><a href="#42752317">next</a><span>|</span><label class="collapse" for="c-42750988">[-]</label><label class="expand" for="c-42750988">[3 more]</label></div><br/><div class="children"><div class="content">Who said anything about Ubuntu 22.04? I mean sure that&#x27;s the newest release current jetpack comes with, but I&#x27;d be surprised if they shipped digits with that.</div><br/><div id="42751155" class="c"><input type="checkbox" id="c-42751155" checked=""/><div class="controls bullet"><span class="by">rbanffy</span><span>|</span><a href="#42748940">root</a><span>|</span><a href="#42750988">parent</a><span>|</span><a href="#42752317">next</a><span>|</span><label class="collapse" for="c-42751155">[-]</label><label class="expand" for="c-42751155">[2 more]</label></div><br/><div class="children"><div class="content">Doesn’t DGX OS use the latest LTS version? Current should be 24.04.</div><br/><div id="42751395" class="c"><input type="checkbox" id="c-42751395" checked=""/><div class="controls bullet"><span class="by">KeplerBoy</span><span>|</span><a href="#42748940">root</a><span>|</span><a href="#42751155">parent</a><span>|</span><a href="#42752317">next</a><span>|</span><label class="collapse" for="c-42751395">[-]</label><label class="expand" for="c-42751395">[1 more]</label></div><br/><div class="children"><div class="content">I wouldn&#x27;t know. I only work with workstation or jetson stuff.<p>The DGX documentation and downloads aren&#x27;t public afaik.<p>Edit: Nevermind, some information about DGX is public and they really are on 22.04, but oh well, the deep learning stack is guaranteed to run.<p><a href="https:&#x2F;&#x2F;docs.nvidia.com&#x2F;base-os&#x2F;too" rel="nofollow">https:&#x2F;&#x2F;docs.nvidia.com&#x2F;base-os&#x2F;too</a></div><br/></div></div></div></div></div></div></div></div></div></div><div id="42752317" class="c"><input type="checkbox" id="c-42752317" checked=""/><div class="controls bullet"><span class="by">Dylan16807</span><span>|</span><a href="#42748940">root</a><span>|</span><a href="#42749048">parent</a><span>|</span><a href="#42749929">prev</a><span>|</span><a href="#42749785">next</a><span>|</span><label class="collapse" for="c-42752317">[-]</label><label class="expand" for="c-42752317">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Pairing it with two 64GB LPCAMM2 modules will get you there.<p>It gets you closer for sure.  But while ~250GB&#x2F;s is a whole lot better than SO-DIMMs at ~100GB&#x2F;s, the new mid-tier GPUs are probably more like 640-900GB&#x2F;s.</div><br/></div></div></div></div><div id="42749785" class="c"><input type="checkbox" id="c-42749785" checked=""/><div class="controls bullet"><span class="by">therealpygon</span><span>|</span><a href="#42748940">parent</a><span>|</span><a href="#42749048">prev</a><span>|</span><a href="#42752432">next</a><span>|</span><label class="collapse" for="c-42749785">[-]</label><label class="expand" for="c-42749785">[4 more]</label></div><br/><div class="children"><div class="content">I wholeheartedly agree. Nvidia is intentionally suppressing the amount of memory on their consumer GPUs to prevent data centers from using consumer cards rather than their far more expensive counterparts. The fact that they used to offer the 3060 with 12GB, but have now pushed the pricing higher and limited many cards to 8GB is a testament to the fact they are. I don’t need giga-TOPS with 8-16gb of memory, I’d be perfectly happy with half that speed but with 64gb of memory or more. Even slower memory would be fine. I don’t need 1000t&#x2F;s, but being able to load a reasonable intelligent model even at 50t&#x2F;s would be great.</div><br/><div id="42749897" class="c"><input type="checkbox" id="c-42749897" checked=""/><div class="controls bullet"><span class="by">lhl</span><span>|</span><a href="#42748940">root</a><span>|</span><a href="#42749785">parent</a><span>|</span><a href="#42752432">next</a><span>|</span><label class="collapse" for="c-42749897">[-]</label><label class="expand" for="c-42749897">[3 more]</label></div><br/><div class="children"><div class="content">Getting to 50 tok&#x2F;s for a big model requires not just memory, but also memory bandwidth. Currently, 1TB&#x2F;s of MBW will get a 70B Q4 (~40GB) model to about 20-25 tok&#x2F;s. The good thing is models continue to get smarter - today&#x27;s 20-30B models beat out last years 70B models on most tasks and the biggest open models like DeepSeek-v3 might have lots of weights, but actually a relatively reasonable # of activations&#x2F;pass.<p>You can test out your half the speed but w&#x2F; 64GB or more of memory w&#x2F; the latest Macs, AMD Strix Halo, or the upcoming Nvidia Digits, though. I suspect by the middle of the year there will be a bunch of options in the ~$3K range. Personally, I think I&#x27;d rather go for 2 x 5090s for 64GB of memory at 1.7TB&#x2F;s than 96 or 128GB w&#x2F; only 250GB&#x2F;s of MBW.</div><br/><div id="42749979" class="c"><input type="checkbox" id="c-42749979" checked=""/><div class="controls bullet"><span class="by">sroussey</span><span>|</span><a href="#42748940">root</a><span>|</span><a href="#42749897">parent</a><span>|</span><a href="#42752432">next</a><span>|</span><label class="collapse" for="c-42749979">[-]</label><label class="expand" for="c-42749979">[2 more]</label></div><br/><div class="children"><div class="content">A Mac with that memory will have closer to 500GB&#x2F;s but your point still stands.<p>That said, if you just want to play around, having more memory will let you do more interesting things. I’d rather have that option over speed since I won’t be doing production inference serving on my laptop.</div><br/><div id="42750021" class="c"><input type="checkbox" id="c-42750021" checked=""/><div class="controls bullet"><span class="by">lhl</span><span>|</span><a href="#42748940">root</a><span>|</span><a href="#42749979">parent</a><span>|</span><a href="#42752432">next</a><span>|</span><label class="collapse" for="c-42750021">[-]</label><label class="expand" for="c-42750021">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, the M4 Max actually has pretty decent MBW - 546 GB&#x2F;s (cheapest config is $4.7K on a 14&quot; MBP atm, but maybe there will be a Mac Studio at some point). The big weakness for the Mac is actually the lack of TFLOPS on the GPU - the beefiest maxes out at ~34 FP16 TFLOPS. It makes a lot of use cases super painful, since prefill&#x2F;prompt processing can take <i>minutes</i> before token generation starts.</div><br/></div></div></div></div></div></div></div></div><div id="42752432" class="c"><input type="checkbox" id="c-42752432" checked=""/><div class="controls bullet"><span class="by">Aurornis</span><span>|</span><a href="#42748940">parent</a><span>|</span><a href="#42749785">prev</a><span>|</span><a href="#42749039">next</a><span>|</span><label class="collapse" for="c-42752432">[-]</label><label class="expand" for="c-42752432">[5 more]</label></div><br/><div class="children"><div class="content">&gt; AMD would be back in the game.<p>The market for prosumer cards with high VRAM and low FLOPS would be negligibly small. The data center market is massive on one end and the gaming market is big on the other. Casual consumers who just want a lot of VRAM are such a small minority of people that it doesn’t matter to the bottom line.<p>It also wouldn’t be financially advantageous to divert RAM chips away from data center production. We don’t have a surplus of chips waiting to be installed, so building out high VRAM but affordable cards would only take away from higher margin products in the datacenter space.</div><br/><div id="42753803" class="c"><input type="checkbox" id="c-42753803" checked=""/><div class="controls bullet"><span class="by">kouteiheika</span><span>|</span><a href="#42748940">root</a><span>|</span><a href="#42752432">parent</a><span>|</span><a href="#42752564">next</a><span>|</span><label class="collapse" for="c-42753803">[-]</label><label class="expand" for="c-42753803">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The market for prosumer cards with high VRAM and low FLOPS would be negligibly small. The data center market is massive on one end and the gaming market is big on the other. Casual consumers who just want a lot of VRAM are such a small minority of people that it doesn’t matter to the bottom line.<p>I&#x27;m sure this is also what AMD is thinking, and it&#x27;s also why they will never catch up to NVidia in ecosystem and software support.<p>It&#x27;s not for the casual consumers, and it&#x27;s not supposed to make money directly! You want these high VRAM SKUs to attract enthusiast and researchers. I have read a staggering amount of research papers where the authors used some random <i>consumer</i> NVidia GPU. Do you know how many I&#x27;ve read which used AMD GPUs? Big fat ZERO! You want to incentivize these people to use your hardware? You want to get devs to support your platform? Give them a unique value proposition that the competition won&#x27;t.<p>I&#x27;m currently waiting for the 5090 to be available, and I&#x27;m going to buy two of them. If AMD would have released a GPU at a fair price, with reasonable performance and double the VRAM that NVidia offers, do you know what would I do? I would buy two AMD cards instead, port my software to it, and contribute PRs to any upstream software that I use so that it works with these cards. But alas, here we are.</div><br/></div></div><div id="42752564" class="c"><input type="checkbox" id="c-42752564" checked=""/><div class="controls bullet"><span class="by">albertzeyer</span><span>|</span><a href="#42748940">root</a><span>|</span><a href="#42752432">parent</a><span>|</span><a href="#42753803">prev</a><span>|</span><a href="#42752667">next</a><span>|</span><label class="collapse" for="c-42752564">[-]</label><label class="expand" for="c-42752564">[1 more]</label></div><br/><div class="children"><div class="content">You might be true for the market.<p>However, that target audience, those hobby enthusiasts, hobby developers, also university labs with low budget, those are the people who will develop the future open source frameworks, and ultimately&#x2F;implicitly those are the people who can have a quite big impact on the future development of brand recognition and the open source ecosystem around the hardware. Those people can shape the future trends.<p>So, only looking at the market, how much units you would sell here, that totally ignores the impact this might have indirectly in the future.</div><br/></div></div><div id="42752667" class="c"><input type="checkbox" id="c-42752667" checked=""/><div class="controls bullet"><span class="by">jph00</span><span>|</span><a href="#42748940">root</a><span>|</span><a href="#42752432">parent</a><span>|</span><a href="#42752564">prev</a><span>|</span><a href="#42753047">next</a><span>|</span><label class="collapse" for="c-42752667">[-]</label><label class="expand" for="c-42752667">[1 more]</label></div><br/><div class="children"><div class="content">Actually there&#x27;s a <i>lot</i> of demand in the AI data center space for such a card, such as for running large mixture of experts (MoE) models -- e.g. DeepSeek v3, which is one of the best LLMs in the world today.<p>Although AMD would need to greatly improve their entire software stack to make running AI models on AMD an attractive proposition.</div><br/></div></div><div id="42753047" class="c"><input type="checkbox" id="c-42753047" checked=""/><div class="controls bullet"><span class="by">bsder</span><span>|</span><a href="#42748940">root</a><span>|</span><a href="#42752432">parent</a><span>|</span><a href="#42752667">prev</a><span>|</span><a href="#42749039">next</a><span>|</span><label class="collapse" for="c-42753047">[-]</label><label class="expand" for="c-42753047">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The market for prosumer cards with high VRAM and low FLOPS would be negligibly small.<p>I don&#x27;t agree.  I regularly get VSCode crashing because it ran out of VRAM.<p>8GB VRAM starts to feel cramped when you have to composite multiple web browsers (aka Electron apps) onto your 4K monitor screen.<p>nVidia not offering 16GB on consumer level cards is purely a market segmentation strategy and AMD should make them pay for it.</div><br/></div></div></div></div><div id="42749039" class="c"><input type="checkbox" id="c-42749039" checked=""/><div class="controls bullet"><span class="by">pkroll</span><span>|</span><a href="#42748940">parent</a><span>|</span><a href="#42752432">prev</a><span>|</span><a href="#42749016">next</a><span>|</span><label class="collapse" for="c-42749039">[-]</label><label class="expand" for="c-42749039">[6 more]</label></div><br/><div class="children"><div class="content">You&#x27;re not the only one thinking that: <a href="https:&#x2F;&#x2F;www.nvidia.com&#x2F;en-us&#x2F;project-digits&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.nvidia.com&#x2F;en-us&#x2F;project-digits&#x2F;</a><p>128G of unified memory. $3K. Throw ollama and ComfyUI on that sucker and things could get interesting. The question is how much slower than a 5090, is this gonna be? The memory bandwidth isn&#x27;t going to match a 512 bit bus.</div><br/><div id="42750999" class="c"><input type="checkbox" id="c-42750999" checked=""/><div class="controls bullet"><span class="by">KeplerBoy</span><span>|</span><a href="#42748940">root</a><span>|</span><a href="#42749039">parent</a><span>|</span><a href="#42749113">next</a><span>|</span><label class="collapse" for="c-42750999">[-]</label><label class="expand" for="c-42750999">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s going to be waaay slower than a 5090. We&#x27;re looking at something like 60W TDP for the entire system vs 600W for a 5090 GPU.<p>It&#x27;s going to be very energy efficient, it will get plenty of flops, but they won&#x27;t be able to cheat physics.</div><br/></div></div><div id="42749113" class="c"><input type="checkbox" id="c-42749113" checked=""/><div class="controls bullet"><span class="by">lostmsu</span><span>|</span><a href="#42748940">root</a><span>|</span><a href="#42749039">parent</a><span>|</span><a href="#42750999">prev</a><span>|</span><a href="#42750477">next</a><span>|</span><label class="collapse" for="c-42749113">[-]</label><label class="expand" for="c-42749113">[2 more]</label></div><br/><div class="children"><div class="content">AFAIK this uses even slower memory.</div><br/><div id="42749985" class="c"><input type="checkbox" id="c-42749985" checked=""/><div class="controls bullet"><span class="by">sroussey</span><span>|</span><a href="#42748940">root</a><span>|</span><a href="#42749113">parent</a><span>|</span><a href="#42750477">next</a><span>|</span><label class="collapse" for="c-42749985">[-]</label><label class="expand" for="c-42749985">[1 more]</label></div><br/><div class="children"><div class="content">And a fraction of the 5090 cores.</div><br/></div></div></div></div><div id="42750477" class="c"><input type="checkbox" id="c-42750477" checked=""/><div class="controls bullet"><span class="by">manojlds</span><span>|</span><a href="#42748940">root</a><span>|</span><a href="#42749039">parent</a><span>|</span><a href="#42749113">prev</a><span>|</span><a href="#42749016">next</a><span>|</span><label class="collapse" for="c-42750477">[-]</label><label class="expand" for="c-42750477">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s LPDDR5.</div><br/><div id="42752524" class="c"><input type="checkbox" id="c-42752524" checked=""/><div class="controls bullet"><span class="by">ein0p</span><span>|</span><a href="#42748940">root</a><span>|</span><a href="#42750477">parent</a><span>|</span><a href="#42749016">next</a><span>|</span><label class="collapse" for="c-42752524">[-]</label><label class="expand" for="c-42752524">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s actually a good thing. That&#x27;s how you get a ton of DRAM without it costing a fortune. M2 Ultra is able to get GPU-like 800GB&#x2F;sec with DDR4. From that it follows that if you can design a specialized chip, you can get a respectable 1 TB&#x2F;sec quite easily with LPDDR5, provided that you&#x27;re willing to design a chip to support a ton of memory channels (and potentially also a wider memory bus). In fact, I&#x27;m baffled that such devices don&#x27;t already exist outside Apple&#x27;s product line. Seems like a rather obvious thing to do, and Apple has a &quot;proof of concept&quot; already. I can think of at least four companies off the top of my head that could do it quite easily, besides Apple.</div><br/></div></div></div></div></div></div><div id="42749016" class="c"><input type="checkbox" id="c-42749016" checked=""/><div class="controls bullet"><span class="by">formerly_proven</span><span>|</span><a href="#42748940">parent</a><span>|</span><a href="#42749039">prev</a><span>|</span><a href="#42749629">next</a><span>|</span><label class="collapse" for="c-42749016">[-]</label><label class="expand" for="c-42749016">[1 more]</label></div><br/><div class="children"><div class="content">Totally normal latencies for a GPU though.</div><br/></div></div><div id="42749629" class="c"><input type="checkbox" id="c-42749629" checked=""/><div class="controls bullet"><span class="by">0934u934y9g</span><span>|</span><a href="#42748940">parent</a><span>|</span><a href="#42749016">prev</a><span>|</span><a href="#42749805">next</a><span>|</span><label class="collapse" for="c-42749629">[-]</label><label class="expand" for="c-42749629">[1 more]</label></div><br/><div class="children"><div class="content">The problem with only providing VRAM is that some AI things like real time audio processing under preform significantly because it does not have the equivalent of tensor cores to keep up. There are LLM&#x27;s that won&#x27;t run for the same reason. You will have more than enough VRAM but not enough tensor cores. AMD isn&#x27;t able to compete.</div><br/></div></div><div id="42749805" class="c"><input type="checkbox" id="c-42749805" checked=""/><div class="controls bullet"><span class="by">SecretDreams</span><span>|</span><a href="#42748940">parent</a><span>|</span><a href="#42749629">prev</a><span>|</span><a href="#42752946">next</a><span>|</span><label class="collapse" for="c-42749805">[-]</label><label class="expand" for="c-42749805">[6 more]</label></div><br/><div class="children"><div class="content">If, by the grace of tech Jesus, amd gave us such systems at volumes Nvidia would notice, Nvidia would simply then do the same but with a better ecosystem.<p>The biggest problem for AMD is not that the majority of people want to use AMD. It is that the majority of people want AMD to be more competitive so that Nvidia will be forced to drop prices so that people can afford Nvidia products.<p>Until this pattern changes, AMD has a big uphill battle. Same for Intel, except Intel is at least seemingly doing great gen&#x2F;gen improvements in mid&#x2F;low range consumer GPUs and bringing healthy vram along for the ride.</div><br/><div id="42751410" class="c"><input type="checkbox" id="c-42751410" checked=""/><div class="controls bullet"><span class="by">llm_trw</span><span>|</span><a href="#42748940">root</a><span>|</span><a href="#42749805">parent</a><span>|</span><a href="#42752404">next</a><span>|</span><label class="collapse" for="c-42751410">[-]</label><label class="expand" for="c-42751410">[3 more]</label></div><br/><div class="children"><div class="content">The same could ba said for CPUs from Intel and AMD 5 years ago. Now people, myself included, buy AMD because it is simply the better choice.</div><br/><div id="42752517" class="c"><input type="checkbox" id="c-42752517" checked=""/><div class="controls bullet"><span class="by">MindSpunk</span><span>|</span><a href="#42748940">root</a><span>|</span><a href="#42751410">parent</a><span>|</span><a href="#42752404">next</a><span>|</span><label class="collapse" for="c-42752517">[-]</label><label class="expand" for="c-42752517">[2 more]</label></div><br/><div class="children"><div class="content">The difference with AMD and Intel when zen launched is that AMD launched a product that utterly destroyed Intel’s line up in productivity workloads. Zen 1 launched with <i>double</i> the cores of the competing intel chip at the same price point. The benchmarks were a bloodbath and intel struggled to respond with a competitive product for 4 years. Arguably they still haven’t caught up. AMD just brutally out executed Intel.<p>Doing that to nvidia would be a tall order</div><br/><div id="42753844" class="c"><input type="checkbox" id="c-42753844" checked=""/><div class="controls bullet"><span class="by">llm_trw</span><span>|</span><a href="#42748940">root</a><span>|</span><a href="#42752517">parent</a><span>|</span><a href="#42752404">next</a><span>|</span><label class="collapse" for="c-42753844">[-]</label><label class="expand" for="c-42753844">[1 more]</label></div><br/><div class="children"><div class="content">Core wise Intel had the advantage until the last generation or two. The same can be true for gpus, just add a ton more memory and watch them fly off the shelves.</div><br/></div></div></div></div></div></div><div id="42752404" class="c"><input type="checkbox" id="c-42752404" checked=""/><div class="controls bullet"><span class="by">AnthonyMouse</span><span>|</span><a href="#42748940">root</a><span>|</span><a href="#42749805">parent</a><span>|</span><a href="#42751410">prev</a><span>|</span><a href="#42751294">next</a><span>|</span><label class="collapse" for="c-42752404">[-]</label><label class="expand" for="c-42752404">[1 more]</label></div><br/><div class="children"><div class="content">&gt; If, by the grace of tech Jesus, amd gave us such systems at volumes Nvidia would notice, Nvidia would simply then do the same but with a better ecosystem.<p>Not if they have &quot;a better ecosystem&quot; -- they would continue to charge a premium for that.<p>Which creates a dilemma for Nvidia. If they would match AMD&#x27;s pricing, they&#x27;d be losing all the money they could get by charging more, which is a ton. Whereas if they charge more, they get more <i>today</i> from the people who pay the premium, but some people are more price sensitive than others, so there are still a lot of people who would buy &quot;lots of VRAM for less money&quot; from AMD. And soon AMD has a lot of users, improves their software support and the difference disappears entirely.<p>Forcing the larger competitor into that dilemma is very much to the advantage of the smaller competitor.</div><br/></div></div><div id="42751294" class="c"><input type="checkbox" id="c-42751294" checked=""/><div class="controls bullet"><span class="by">holoduke</span><span>|</span><a href="#42748940">root</a><span>|</span><a href="#42749805">parent</a><span>|</span><a href="#42752404">prev</a><span>|</span><a href="#42752946">next</a><span>|</span><label class="collapse" for="c-42751294">[-]</label><label class="expand" for="c-42751294">[1 more]</label></div><br/><div class="children"><div class="content">It can change quickly. Great example is the short domination of the ati 9700 that crushed nvidia for a short while.</div><br/></div></div></div></div><div id="42752946" class="c"><input type="checkbox" id="c-42752946" checked=""/><div class="controls bullet"><span class="by">treesciencebot</span><span>|</span><a href="#42748940">parent</a><span>|</span><a href="#42749805">prev</a><span>|</span><a href="#42749299">next</a><span>|</span><label class="collapse" for="c-42752946">[-]</label><label class="expand" for="c-42752946">[1 more]</label></div><br/><div class="children"><div class="content">For traditional LLMs this might be true (especially large MoEs at bs=1) but I highly disagree with &quot;multi-modal models&quot; phrase since most of the models that <i>output</i> in other modalities are generally compute bound. Which means less flops will make the experience so much worse (imagine waiting a couple minutes for an image and hours for videos).</div><br/></div></div></div></div><div id="42749299" class="c"><input type="checkbox" id="c-42749299" checked=""/><div class="controls bullet"><span class="by">mk_stjames</span><span>|</span><a href="#42748940">prev</a><span>|</span><a href="#42752051">next</a><span>|</span><label class="collapse" for="c-42749299">[-]</label><label class="expand" for="c-42749299">[10 more]</label></div><br/><div class="children"><div class="content">So the 300A is an accelerator coupled with a full 24-core EPYC and 128GB of HBM all on a single chip (or, packaged chiplets, whatever).<p>Why is it I can&#x27;t buy a single one of these, on a motherboard, in a workstation format case, to use as an insane workstation?  Assuming you could program for the accelerator part, there is an entire world of x86-fixed CAD, engineering, and entertainment industry (rendering, etc) where people want a single, desktop machine with 128GB + of fast ram to number crunch.<p>There are Blender artists out there that build dual and quad RTX4090 machines with Threadrippers for $20k+ in components all day, because their render jobs pay for it.<p>There are engineering companies that would not bat an eye at dropping $30k on a workstation if it mean they could spin around 80 gigabyte CATIA models of cars or aircraft loaded in RAM quicker. I know this at least because I sure as hell did with with several HP Z-series machines costing whole-Toyota-Corolla prices over the years...<p>But these combined APU chips are relegated to these server units.  In the end is this a driver problem?  Just a software problem?  A chicken and egg problem where no one is developing the support because there isn&#x27;t the hardware on the market, and there isn&#x27;t the hardware on the market because AMD thinks there is no use case?<p>Edit: and note my use cases mentioned don&#x27;t rely on latency, really, like videogamers need to hit framerates.  The cache miss latency mentioned in the article doesn&#x27;t matter as much for these type of compute applications where the main problems are just loading and unloading the massive amount of data.  Things like offline renders and post-processing CFD simulations.  Not necessarily a video output framerate.</div><br/><div id="42749843" class="c"><input type="checkbox" id="c-42749843" checked=""/><div class="controls bullet"><span class="by">latchkey</span><span>|</span><a href="#42749299">parent</a><span>|</span><a href="#42752447">next</a><span>|</span><label class="collapse" for="c-42749843">[-]</label><label class="expand" for="c-42749843">[8 more]</label></div><br/><div class="children"><div class="content">(I run a company that buys MI300x.)<p>&gt; <i>Why is it I can&#x27;t buy a single one of these, on a motherboard, in a workstation format case, to use as an insane workstation?</i><p>AMD doesn&#x27;t have the resources to support end users for something like this. They are a public company, look at their spend. They are pouring everything they&#x27;ve got into trying to keep up with the Nvidia release cycle for AI chips.<p>These chips are cutting edge, they are not perfect. They are still working through the hardware and software issues. It is hard enough to deal with all the public opinion on things as it is. Why would they add another layer of potential abuse?</div><br/><div id="42752446" class="c"><input type="checkbox" id="c-42752446" checked=""/><div class="controls bullet"><span class="by">AnthonyMouse</span><span>|</span><a href="#42749299">root</a><span>|</span><a href="#42749843">parent</a><span>|</span><a href="#42752447">next</a><span>|</span><label class="collapse" for="c-42752446">[-]</label><label class="expand" for="c-42752446">[7 more]</label></div><br/><div class="children"><div class="content">The people who buy stuff like that are professionals. They often know something about the tools they&#x27;re using and if there are any problems, provide bug reports that actually describe what&#x27;s happening instead of some non-descriptive mush like &quot;I have your GPU and Windows crashes sometimes&quot;. That is extremely helpful if you&#x27;re trying to get rid of those bugs.<p>This is the same reason software shops have found it useful to support Linux, even if not many people use it. The people who do will make your product suck less, which in turn makes it easier to sell to the mass market, which will get upset and think unfavorably of you if they have the same problem but not be as good at telling you about it.</div><br/><div id="42752538" class="c"><input type="checkbox" id="c-42752538" checked=""/><div class="controls bullet"><span class="by">latchkey</span><span>|</span><a href="#42749299">root</a><span>|</span><a href="#42752446">parent</a><span>|</span><a href="#42752455">next</a><span>|</span><label class="collapse" for="c-42752538">[-]</label><label class="expand" for="c-42752538">[4 more]</label></div><br/><div class="children"><div class="content">Groq is a good example here:<p><a href="https:&#x2F;&#x2F;www.eetimes.com&#x2F;groq-ceo-we-no-longer-sell-hardware&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.eetimes.com&#x2F;groq-ceo-we-no-longer-sell-hardware&#x2F;</a><p>Our users give them plenty of feedback. They just RMA&#x27;d whole bunch of our GPUs over this issue so that they could take them back to the mothership and figure out what&#x27;s up...<p><a href="https:&#x2F;&#x2F;github.com&#x2F;ROCm&#x2F;ROCm&#x2F;issues&#x2F;4021">https:&#x2F;&#x2F;github.com&#x2F;ROCm&#x2F;ROCm&#x2F;issues&#x2F;4021</a><p>It takes a lot of coordination, across ourselves (with customers), our DC, AMD and Dell to make that happen.</div><br/><div id="42752706" class="c"><input type="checkbox" id="c-42752706" checked=""/><div class="controls bullet"><span class="by">AnthonyMouse</span><span>|</span><a href="#42749299">root</a><span>|</span><a href="#42752538">parent</a><span>|</span><a href="#42752455">next</a><span>|</span><label class="collapse" for="c-42752706">[-]</label><label class="expand" for="c-42752706">[3 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not that you don&#x27;t get bug reports from data center customers, it&#x27;s that data center customers have scale in a bad way. They buy thousands of GPUs, they do whatever they&#x27;re going to do with them, they have a problem, they report the bug. One bug report across thousands of GPUs, because they&#x27;re all being used for the same thing by that customer so they only have the problems you have when you try to do that. Another data center buys thousands of GPUs and they&#x27;re doing something else which is extremely common and well supported, so they don&#x27;t have any issues and you get <i>zero</i> bug reports from them.<p>Compare this to, you sell a thousand GPUs to a thousand professionals and 10% of them have some problem, but each a different one. You get 100 bug reports, you fix 100 bugs instead of just one, things improve much faster.</div><br/><div id="42753127" class="c"><input type="checkbox" id="c-42753127" checked=""/><div class="controls bullet"><span class="by">latchkey</span><span>|</span><a href="#42749299">root</a><span>|</span><a href="#42752706">parent</a><span>|</span><a href="#42752455">next</a><span>|</span><label class="collapse" for="c-42753127">[-]</label><label class="expand" for="c-42753127">[2 more]</label></div><br/><div class="children"><div class="content">We have 136 of these things. Not thousands. AMD is intentionally keeping their number of providers limited [0](bottom of page).<p>No two providers has the same customers, meaning the workloads vary quite a lot, and a lot of the &quot;professional&quot; developers you&#x27;re talking about all have jobs that rent this compute.<p>These GPUs are enterprise, they only come in one form factor. It is a 350lbs box that takes 10kW of power and some pretty serious cooling. It costs as much as an expensive Ferrari.<p>If you&#x27;re now also suggesting that AMD also release another product that is easier for developers to get their hands on and deploy, then now you&#x27;ve totally lost me. You&#x27;re exponentially trying to increase the amount of work and money they spend, for what? Some feedback?<p>[0] <a href="https:&#x2F;&#x2F;www.amd.com&#x2F;en&#x2F;products&#x2F;accelerators&#x2F;instinct.html" rel="nofollow">https:&#x2F;&#x2F;www.amd.com&#x2F;en&#x2F;products&#x2F;accelerators&#x2F;instinct.html</a></div><br/><div id="42755030" class="c"><input type="checkbox" id="c-42755030" checked=""/><div class="controls bullet"><span class="by">AnthonyMouse</span><span>|</span><a href="#42749299">root</a><span>|</span><a href="#42753127">parent</a><span>|</span><a href="#42752455">next</a><span>|</span><label class="collapse" for="c-42755030">[-]</label><label class="expand" for="c-42755030">[1 more]</label></div><br/><div class="children"><div class="content">&gt; We have 136 of these things. Not thousands.<p>That&#x27;s a number within an order of magnitude, and you&#x27;re presumably not the largest provider.<p>&gt; No two providers has the same customers, meaning the workloads vary quite a lot, and a lot of the &quot;professional&quot; developers you&#x27;re talking about all have jobs that rent this compute.<p>If you own something and you&#x27;ve having problems with it, you&#x27;re more inclined to try to solve them. If you&#x27;re renting something and you have problems with it, you&#x27;re more inclined to rent something else instead.<p>&gt; These GPUs are enterprise, they only come in one form factor. It is a 350lbs box that takes 10kW of power and some pretty serious cooling. It costs as much as an expensive Ferrari.<p>Making only 4-socket systems was a choice.<p>You&#x27;re also acting like multiple SKUs are something weird. Start offering Ryzen APUs with some on-package GDDR or HBM. Make something that fits in the Threadripper socket and uses PCIe power connectors for extra power. People would buy these things.<p>The point is to create lots of systems in the hands of lots of people that use the same general hardware architecture so that you&#x27;re improving its software support.</div><br/></div></div></div></div></div></div></div></div><div id="42752455" class="c"><input type="checkbox" id="c-42752455" checked=""/><div class="controls bullet"><span class="by">Aurornis</span><span>|</span><a href="#42749299">root</a><span>|</span><a href="#42752446">parent</a><span>|</span><a href="#42752538">prev</a><span>|</span><a href="#42752447">next</a><span>|</span><label class="collapse" for="c-42752455">[-]</label><label class="expand" for="c-42752455">[2 more]</label></div><br/><div class="children"><div class="content">&gt; provide bug reports that actually describe what&#x27;s happening<p>Doesn’t matter if the bug reports are good or bad. Supporting low volume applications is a bad business move when the alternative is 9-figure data center contracts.<p>The data center business is orders of magnitude larger. Trying to support individual developers would be a huge business mistake when they already can’t keep up with data center.</div><br/><div id="42752502" class="c"><input type="checkbox" id="c-42752502" checked=""/><div class="controls bullet"><span class="by">AnthonyMouse</span><span>|</span><a href="#42749299">root</a><span>|</span><a href="#42752455">parent</a><span>|</span><a href="#42752447">next</a><span>|</span><label class="collapse" for="c-42752502">[-]</label><label class="expand" for="c-42752502">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s the same hardware running the same software. You want the bug reports so you can fix them and then your data center customers don&#x27;t encounter them when they&#x27;re evaluating your product.<p>What they can keep up with is basically a matter of how much capacity they order from TSMC. If they underestimated demand for some generation, that&#x27;s the sort of thing you fix with the next contract or you&#x27;re just throwing money away.</div><br/></div></div></div></div></div></div></div></div><div id="42752447" class="c"><input type="checkbox" id="c-42752447" checked=""/><div class="controls bullet"><span class="by">Aurornis</span><span>|</span><a href="#42749299">parent</a><span>|</span><a href="#42749843">prev</a><span>|</span><a href="#42752051">next</a><span>|</span><label class="collapse" for="c-42752447">[-]</label><label class="expand" for="c-42752447">[1 more]</label></div><br/><div class="children"><div class="content">Data center orders are high volume and allow long lead times. You can collect orders, collect money, and then agree when to deliver huge batches of product.<p>Selling one off chips isn’t attractive at all in this context. Selling a couple parts to the rare Blender artist is nothing relative to the data center buildouts with billion dollar budgets.<p>Every one-off part you sell takes resources and inventory away from landing those big contracts.</div><br/></div></div></div></div><div id="42752051" class="c"><input type="checkbox" id="c-42752051" checked=""/><div class="controls bullet"><span class="by">erulabs</span><span>|</span><a href="#42749299">prev</a><span>|</span><a href="#42751599">next</a><span>|</span><label class="collapse" for="c-42752051">[-]</label><label class="expand" for="c-42752051">[1 more]</label></div><br/><div class="children"><div class="content">its interesting that two simultaneous and contradictory views are held by AI engineers:<p>- Software is over<p>- An impenetrable software moat protects Nvidia&#x27;s market capitalization</div><br/></div></div><div id="42751599" class="c"><input type="checkbox" id="c-42751599" checked=""/><div class="controls bullet"><span class="by">ChuckMcM</span><span>|</span><a href="#42752051">prev</a><span>|</span><a href="#42748716">next</a><span>|</span><label class="collapse" for="c-42751599">[-]</label><label class="expand" for="c-42751599">[1 more]</label></div><br/><div class="children"><div class="content">That is quite a thing. I&#x27;ve been out of the &#x27;design loop&#x27; for chips like this for a while so I don&#x27;t know if they still do full chip simulations prior to tapeout but woah trying to simulate that thing would take quite the compute complex in itself. Hat&#x27;s off to AMD for getting it out the door.</div><br/></div></div><div id="42748716" class="c"><input type="checkbox" id="c-42748716" checked=""/><div class="controls bullet"><span class="by">amelius</span><span>|</span><a href="#42751599">prev</a><span>|</span><a href="#42749032">next</a><span>|</span><label class="collapse" for="c-42748716">[-]</label><label class="expand" for="c-42748716">[9 more]</label></div><br/><div class="children"><div class="content">I&#x27;m curious why this space hasn&#x27;t been patented to death.</div><br/><div id="42748756" class="c"><input type="checkbox" id="c-42748756" checked=""/><div class="controls bullet"><span class="by">hedora</span><span>|</span><a href="#42748716">parent</a><span>|</span><a href="#42749032">next</a><span>|</span><label class="collapse" for="c-42748756">[-]</label><label class="expand" for="c-42748756">[8 more]</label></div><br/><div class="children"><div class="content">It has been.  All sides have a pile of patents.  All sides violate all the other sides’ patents.  If anyone sues, everyone goes out of business.<p>This is the system working as currently intended.  No matter what happens, the lawyers get will rich.<p>If a small company comes in and doesn’t pay the lawyers, it’ll get sued for violating the patents.</div><br/><div id="42749109" class="c"><input type="checkbox" id="c-42749109" checked=""/><div class="controls bullet"><span class="by">yvdriess</span><span>|</span><a href="#42748716">root</a><span>|</span><a href="#42748756">parent</a><span>|</span><a href="#42750516">next</a><span>|</span><label class="collapse" for="c-42749109">[-]</label><label class="expand" for="c-42749109">[3 more]</label></div><br/><div class="children"><div class="content">Yep, it&#x27;s an area denial weapon.<p>You basically cannot do anything worthwhile in this space without violating someone&#x27;s patents. It&#x27;s beneficial patent and corporate lawyers, but it&#x27;s detrimental to innovation. As an engineer you are asked to not look up existing techniques or designs as this will taint you legally.</div><br/><div id="42749781" class="c"><input type="checkbox" id="c-42749781" checked=""/><div class="controls bullet"><span class="by">kmeisthax</span><span>|</span><a href="#42748716">root</a><span>|</span><a href="#42749109">parent</a><span>|</span><a href="#42750516">next</a><span>|</span><label class="collapse" for="c-42749781">[-]</label><label class="expand" for="c-42749781">[2 more]</label></div><br/><div class="children"><div class="content">&quot;Tainting&quot; isn&#x27;t a thing in patent law. All engineers worldwide are tainted the moment the patent is published; that&#x27;s why parallel reinvention is not a defense to patent infringement.</div><br/><div id="42750076" class="c"><input type="checkbox" id="c-42750076" checked=""/><div class="controls bullet"><span class="by">lhl</span><span>|</span><a href="#42748716">root</a><span>|</span><a href="#42749781">parent</a><span>|</span><a href="#42750516">next</a><span>|</span><label class="collapse" for="c-42750076">[-]</label><label class="expand" for="c-42750076">[1 more]</label></div><br/><div class="children"><div class="content">But you pay triple damages if you knowingly vs unknowingly violate a patent (35 U.S.C. § 284). Of course, everything is patented, so, engineers are just told to not read patents.</div><br/></div></div></div></div></div></div><div id="42750516" class="c"><input type="checkbox" id="c-42750516" checked=""/><div class="controls bullet"><span class="by">WithinReason</span><span>|</span><a href="#42748716">root</a><span>|</span><a href="#42748756">parent</a><span>|</span><a href="#42749109">prev</a><span>|</span><a href="#42749726">next</a><span>|</span><label class="collapse" for="c-42750516">[-]</label><label class="expand" for="c-42750516">[3 more]</label></div><br/><div class="children"><div class="content">Mutually assured destruction</div><br/><div id="42750549" class="c"><input type="checkbox" id="c-42750549" checked=""/><div class="controls bullet"><span class="by">amelius</span><span>|</span><a href="#42748716">root</a><span>|</span><a href="#42750516">parent</a><span>|</span><a href="#42749726">next</a><span>|</span><label class="collapse" for="c-42750549">[-]</label><label class="expand" for="c-42750549">[2 more]</label></div><br/><div class="children"><div class="content">Where do patent-trolls fit in this analogy?</div><br/><div id="42752426" class="c"><input type="checkbox" id="c-42752426" checked=""/><div class="controls bullet"><span class="by">twasold</span><span>|</span><a href="#42748716">root</a><span>|</span><a href="#42750549">parent</a><span>|</span><a href="#42749726">next</a><span>|</span><label class="collapse" for="c-42752426">[-]</label><label class="expand" for="c-42752426">[1 more]</label></div><br/><div class="children"><div class="content">They’re the backstreet gangs that rob single missile silos from failing states and ransom you.</div><br/></div></div></div></div></div></div><div id="42749726" class="c"><input type="checkbox" id="c-42749726" checked=""/><div class="controls bullet"><span class="by">amelius</span><span>|</span><a href="#42748716">root</a><span>|</span><a href="#42748756">parent</a><span>|</span><a href="#42750516">prev</a><span>|</span><a href="#42749032">next</a><span>|</span><label class="collapse" for="c-42749726">[-]</label><label class="expand" for="c-42749726">[1 more]</label></div><br/><div class="children"><div class="content">&gt; If a small company comes in and doesn’t pay the lawyers, it’ll get sued for violating the patents.<p>This assumes the small company isn&#x27;t just in it for the patents.</div><br/></div></div></div></div></div></div><div id="42749032" class="c"><input type="checkbox" id="c-42749032" checked=""/><div class="controls bullet"><span class="by">neuroelectron</span><span>|</span><a href="#42748716">prev</a><span>|</span><a href="#42752507">next</a><span>|</span><label class="collapse" for="c-42749032">[-]</label><label class="expand" for="c-42749032">[11 more]</label></div><br/><div class="children"><div class="content">&gt;Still, core to core transfers are very rare in practice. I consider core to core latency test results to be just about irrelevant to application performance. I’m only showing test results here to explain the system topology.<p>How exactly are &quot;applications&quot; developed for this? Or is that all proprietary knowledge? TinyBox has resorted to writing their own drivers for 7900 XTX</div><br/><div id="42749868" class="c"><input type="checkbox" id="c-42749868" checked=""/><div class="controls bullet"><span class="by">latchkey</span><span>|</span><a href="#42749032">parent</a><span>|</span><a href="#42752507">next</a><span>|</span><label class="collapse" for="c-42749868">[-]</label><label class="expand" for="c-42749868">[10 more]</label></div><br/><div class="children"><div class="content">ROCm is the stack that people write code against to talk to AMD hardware.<p>George wrote some incomplete non-perfomant drivers for a consumer grade product. Certainly not an easy task, but it also isn&#x27;t something that most people would use. George just makes loud noises to get attention, but few in the HPC industry pay any attention to him.</div><br/><div id="42750974" class="c"><input type="checkbox" id="c-42750974" checked=""/><div class="controls bullet"><span class="by">neuroelectron</span><span>|</span><a href="#42749032">root</a><span>|</span><a href="#42749868">parent</a><span>|</span><a href="#42750277">next</a><span>|</span><label class="collapse" for="c-42750974">[-]</label><label class="expand" for="c-42750974">[3 more]</label></div><br/><div class="children"><div class="content">Yes ROCm is for the GPU, but the MI300A also includes 4 clusters of cpus connected by an infinity fabric. Generally this kind of thing is handled by the OS but there is no OS for this product.</div><br/><div id="42751202" class="c"><input type="checkbox" id="c-42751202" checked=""/><div class="controls bullet"><span class="by">latchkey</span><span>|</span><a href="#42749032">root</a><span>|</span><a href="#42750974">parent</a><span>|</span><a href="#42752910">next</a><span>|</span><label class="collapse" for="c-42751202">[-]</label><label class="expand" for="c-42751202">[1 more]</label></div><br/><div class="children"><div class="content">AMD has had APU&#x27;s for years, the PS5 chip is an APU.<p>I did a quick google search and found this presentation which details the programming model...<p><a href="https:&#x2F;&#x2F;nowlab.cse.ohio-state.edu&#x2F;static&#x2F;media&#x2F;workshops&#x2F;presentations&#x2F;espm2_23&#x2F;PublicSC23ESPM2ProgrammingAMDInstinctMI300A.pdf" rel="nofollow">https:&#x2F;&#x2F;nowlab.cse.ohio-state.edu&#x2F;static&#x2F;media&#x2F;workshops&#x2F;pre...</a></div><br/></div></div><div id="42752910" class="c"><input type="checkbox" id="c-42752910" checked=""/><div class="controls bullet"><span class="by">alienthrowaway</span><span>|</span><a href="#42749032">root</a><span>|</span><a href="#42750974">parent</a><span>|</span><a href="#42751202">prev</a><span>|</span><a href="#42750277">next</a><span>|</span><label class="collapse" for="c-42752910">[-]</label><label class="expand" for="c-42752910">[1 more]</label></div><br/><div class="children"><div class="content">AMD has been doing IF-connected CCDs&#x2F;chiplets for a while now - since Zen 1, released in 2017. All the x86 OSes work fine on each iteration.<p>Application authors who care about wringing out the last drop of performance need to be mindful about how they manage processes and cache lines on this hardware - as they would on any other architecture</div><br/></div></div></div></div><div id="42750277" class="c"><input type="checkbox" id="c-42750277" checked=""/><div class="controls bullet"><span class="by">tucnak</span><span>|</span><a href="#42749032">root</a><span>|</span><a href="#42749868">parent</a><span>|</span><a href="#42750974">prev</a><span>|</span><a href="#42752507">next</a><span>|</span><label class="collapse" for="c-42750277">[-]</label><label class="expand" for="c-42750277">[6 more]</label></div><br/><div class="children"><div class="content">Nobody cares what HPC industry has to say; until recently, they have happily been jerking off Monte-Carlo simulations on overpriced nation-grade supercomputer NUMA clusters and didn&#x27;t know what a &quot;GPU&quot; was anyway! Also please stop spreading &quot;consumer grade product&quot; propaganda. I had used AMD Instinct MI50&#x27;s—supposedly datacenter-grade hardware, and have faced the <i>exact</i> same problems as George. Except in my case there was no call-line at Lisa&#x27;s.<p>Guess what, the AI industry has spoken: hyper-scalers would buy NVIDIA, or rather design their own silicon. Any thing, any how, but nothing to do with AMD.<p>Also: if your business is doing so great, how come you&#x27;re constantly in all these Hacker News threads talking and talking and talking but not actually releasing products of any kind, of any bread, that any of the hackers on here could use?</div><br/><div id="42750491" class="c"><input type="checkbox" id="c-42750491" checked=""/><div class="controls bullet"><span class="by">latchkey</span><span>|</span><a href="#42749032">root</a><span>|</span><a href="#42750277">parent</a><span>|</span><a href="#42752507">next</a><span>|</span><label class="collapse" for="c-42750491">[-]</label><label class="expand" for="c-42750491">[5 more]</label></div><br/><div class="children"><div class="content">&gt; but not actually releasing products of any kind, of any bread, that any of the hackers on here could use?<p>Our &quot;product&quot; is open access to a very specific type of HPC compute that previously was locked up and only available to a short list of researchers.<p>Thanks for asking, we just added 1 GPU &#x2F; 1 minute docker container access through our excellent partners: <a href="https:&#x2F;&#x2F;shadeform.ai">https:&#x2F;&#x2F;shadeform.ai</a><p>1 GPU &#x2F; 1 VM &#x2F; 1 minute is coming soon.</div><br/><div id="42750521" class="c"><input type="checkbox" id="c-42750521" checked=""/><div class="controls bullet"><span class="by">tucnak</span><span>|</span><a href="#42749032">root</a><span>|</span><a href="#42750491">parent</a><span>|</span><a href="#42752507">next</a><span>|</span><label class="collapse" for="c-42750521">[-]</label><label class="expand" for="c-42750521">[4 more]</label></div><br/><div class="children"><div class="content">From the looks of it, YOU ARE the product. That is, manufacturing optics of a &quot;partner&quot; and &quot;distributer&quot; ecosystem for AMD. And on borrowed time, too.</div><br/><div id="42750589" class="c"><input type="checkbox" id="c-42750589" checked=""/><div class="controls bullet"><span class="by">latchkey</span><span>|</span><a href="#42749032">root</a><span>|</span><a href="#42750521">parent</a><span>|</span><a href="#42752507">next</a><span>|</span><label class="collapse" for="c-42750589">[-]</label><label class="expand" for="c-42750589">[3 more]</label></div><br/><div class="children"><div class="content">&gt; From the looks of it, YOU ARE the product.<p>Sweet, thanks! That&#x27;s at least part of what a CEO is supposed to be.</div><br/><div id="42751461" class="c"><input type="checkbox" id="c-42751461" checked=""/><div class="controls bullet"><span class="by">tucnak</span><span>|</span><a href="#42749032">root</a><span>|</span><a href="#42750589">parent</a><span>|</span><a href="#42752507">next</a><span>|</span><label class="collapse" for="c-42751461">[-]</label><label class="expand" for="c-42751461">[2 more]</label></div><br/><div class="children"><div class="content">Please don&#x27;t be salty; the only person here who may embarrass you is yourself. I&#x27;m happy that you like to think about yourself as CEO, but perhaps it&#x27;s worth reflecting you may be doing a better job if you had spent less time on Hacker News, and more time figuring out how to get Hacker News excited about your product? So far you have pledged allegiance to AMD every chance you got, and spun tall tales of great capability, with not much to show for it besides &quot;partners.&quot; You know nobody has trained a thing with your GPU&#x27;s yet? That would be a great place to start for a CEO. To make something people would use. To justify it to us; as AMD themselves have clearly justified your existence there&#x27;s no work there!<p>It&#x27;s just tough words from a nobody, don&#x27;t worry you&#x27;ll be fine!</div><br/><div id="42751551" class="c"><input type="checkbox" id="c-42751551" checked=""/><div class="controls bullet"><span class="by">latchkey</span><span>|</span><a href="#42749032">root</a><span>|</span><a href="#42751461">parent</a><span>|</span><a href="#42752507">next</a><span>|</span><label class="collapse" for="c-42751551">[-]</label><label class="expand" for="c-42751551">[1 more]</label></div><br/><div class="children"><div class="content">&gt; You know nobody has trained a thing with your GPU&#x27;s yet?<p><a href="https:&#x2F;&#x2F;x.com&#x2F;zealandic1&#x2F;status&#x2F;1877005338324427014" rel="nofollow">https:&#x2F;&#x2F;x.com&#x2F;zealandic1&#x2F;status&#x2F;1877005338324427014</a></div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="42750215" class="c"><input type="checkbox" id="c-42750215" checked=""/><div class="controls bullet"><span class="by">behnamoh</span><span>|</span><a href="#42752507">prev</a><span>|</span><label class="collapse" for="c-42750215">[-]</label><label class="expand" for="c-42750215">[5 more]</label></div><br/><div class="children"><div class="content">AMD is done, no one uses their GPUs for AI because AMD were too dumb to understand the value of software lock-in like Nvidia did with CUDA.</div><br/><div id="42753721" class="c"><input type="checkbox" id="c-42753721" checked=""/><div class="controls bullet"><span class="by">DiabloD3</span><span>|</span><a href="#42750215">parent</a><span>|</span><a href="#42750458">next</a><span>|</span><label class="collapse" for="c-42753721">[-]</label><label class="expand" for="c-42753721">[2 more]</label></div><br/><div class="children"><div class="content">Funny you say that, because nobody serious about AI is actually using Nvidia unless they&#x27;re already locked in with CUDA.<p>Highest performing inference engines all use Vulkan, and are either faster per dollarwatt on the CDNA3 cards or (surprisingly) the RDNA3 cards, not Lovelace.</div><br/><div id="42753978" class="c"><input type="checkbox" id="c-42753978" checked=""/><div class="controls bullet"><span class="by">behnamoh</span><span>|</span><a href="#42750215">root</a><span>|</span><a href="#42753721">parent</a><span>|</span><a href="#42750458">next</a><span>|</span><label class="collapse" for="c-42753978">[-]</label><label class="expand" for="c-42753978">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Funny you say that, because nobody serious about AI is actually using Nvidia unless they&#x27;re already locked in with CUDA.<p>Yeah right, so Meta and XAI buying hundreds of Nvidia&#x27;s H100&#x27;s was because they were not serious in AI. wtf</div><br/></div></div></div></div><div id="42750458" class="c"><input type="checkbox" id="c-42750458" checked=""/><div class="controls bullet"><span class="by">guywhocodes</span><span>|</span><a href="#42750215">parent</a><span>|</span><a href="#42753721">prev</a><span>|</span><label class="collapse" for="c-42750458">[-]</label><label class="expand" for="c-42750458">[2 more]</label></div><br/><div class="children"><div class="content">More like the value of drivers that doesn&#x27;t require one in-house team per customer to &quot;fix&quot; driver crashes in the customers&#x27; particular workloads.</div><br/><div id="42751175" class="c"><input type="checkbox" id="c-42751175" checked=""/><div class="controls bullet"><span class="by">numpy-thagoras</span><span>|</span><a href="#42750215">root</a><span>|</span><a href="#42750458">parent</a><span>|</span><label class="collapse" for="c-42751175">[-]</label><label class="expand" for="c-42751175">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, the labour involved in running non Nvidia equipment is the elephant in the room.<p>Nvidia GPU: spin up OS, run your sims or load your LLM, gather results.<p>AMD GPU: spin up OS, grok driver fixes, try and run your sims, grok more driver fixes, can&#x27;t even gather results until you can verify software correctness of your fixes. Yeah, sometimes you need someone with specialized knowledge of numerical methods to help tune your fixes.<p>... What kind of maddening workflows are these? It&#x27;s literally negative work: you are busy, you barely get anywhere, and you end up having to do more.<p>In light of that, the Nvidia tax doesn&#x27;t look so bad.</div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>