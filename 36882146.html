<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1690448460743" as="style"/><link rel="stylesheet" href="styles.css?v=1690448460743"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/continuedev/continue">Show HN: Continue – Open-source coding autopilot</a> <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>sestinj</span> | <span>74 comments</span></div><br/><div><div id="36890819" class="c"><input type="checkbox" id="c-36890819" checked=""/><div class="controls bullet"><span class="by">pax</span><span>|</span><a href="#36886291">next</a><span>|</span><label class="collapse" for="c-36890819">[-]</label><label class="expand" for="c-36890819">[1 more]</label></div><br/><div class="children"><div class="content">Is there any LLM based coding assistant than can read from terminal, thus catching error output?</div><br/></div></div><div id="36886291" class="c"><input type="checkbox" id="c-36886291" checked=""/><div class="controls bullet"><span class="by">milani</span><span>|</span><a href="#36890819">prev</a><span>|</span><a href="#36887435">next</a><span>|</span><label class="collapse" for="c-36886291">[-]</label><label class="expand" for="c-36886291">[6 more]</label></div><br/><div class="children"><div class="content">In my experience working with GPT4, if I give enough context on types, other functions definitions and the libraries I use, I get very accurate results. But it is a tedious task to copy paste from multiple places (type definitions, function definitions, packages, etc.).<p>In addition to the selected lines, does Continue support getting related definitions from the language server and inject them in the prompt? That would be huge.</div><br/><div id="36889138" class="c"><input type="checkbox" id="c-36889138" checked=""/><div class="controls bullet"><span class="by">Aperocky</span><span>|</span><a href="#36886291">parent</a><span>|</span><a href="#36888614">next</a><span>|</span><label class="collapse" for="c-36889138">[-]</label><label class="expand" for="c-36889138">[1 more]</label></div><br/><div class="children"><div class="content">&gt; if I give enough context on types, other functions definitions and the libraries I use, I get very accurate results.<p>It&#x27;s almost like .. coding it yourself!</div><br/></div></div><div id="36888614" class="c"><input type="checkbox" id="c-36888614" checked=""/><div class="controls bullet"><span class="by">lalwanivikas</span><span>|</span><a href="#36886291">parent</a><span>|</span><a href="#36889138">prev</a><span>|</span><a href="#36886378">next</a><span>|</span><label class="collapse" for="c-36888614">[-]</label><label class="expand" for="c-36888614">[2 more]</label></div><br/><div class="children"><div class="content">I have been experimenting a lot lately, and I would much rather copy paste high quality output(via providing context) than playing guessing games.<p>It&#x27;s not like you have to be coding all the time.<p>Things will of course change as tools evolve.</div><br/><div id="36888682" class="c"><input type="checkbox" id="c-36888682" checked=""/><div class="controls bullet"><span class="by">sestinj</span><span>|</span><a href="#36886291">root</a><span>|</span><a href="#36888614">parent</a><span>|</span><a href="#36886378">next</a><span>|</span><label class="collapse" for="c-36888682">[-]</label><label class="expand" for="c-36888682">[1 more]</label></div><br/><div class="children"><div class="content">Couldn&#x27;t agree more—it&#x27;s worth the extra effort to know <i>exactly</i> what enters the prompt. But control isn&#x27;t mutually exclusive with removing the need to copy&#x2F;paste. Continue lets you highlight code with perfect precision, and this is much lower effort.</div><br/></div></div></div></div><div id="36886378" class="c"><input type="checkbox" id="c-36886378" checked=""/><div class="controls bullet"><span class="by">sestinj</span><span>|</span><a href="#36886291">parent</a><span>|</span><a href="#36888614">prev</a><span>|</span><a href="#36889292">next</a><span>|</span><label class="collapse" for="c-36886378">[-]</label><label class="expand" for="c-36886378">[1 more]</label></div><br/><div class="children"><div class="content">This is very near on the roadmap, and we agree it will be awesome!<p>As of now, if there are collections of definitions that you frequently reference, you could save them in the system message, or write custom slash commands that let you prefix your prompt with these definitions.</div><br/></div></div><div id="36889292" class="c"><input type="checkbox" id="c-36889292" checked=""/><div class="controls bullet"><span class="by">bvm</span><span>|</span><a href="#36886291">parent</a><span>|</span><a href="#36886378">prev</a><span>|</span><a href="#36887435">next</a><span>|</span><label class="collapse" for="c-36889292">[-]</label><label class="expand" for="c-36889292">[1 more]</label></div><br/><div class="children"><div class="content">I also found this tedious and made a tiny vscode extension to make it less tedious<p><a href="https:&#x2F;&#x2F;marketplace.visualstudio.com&#x2F;items?itemName=TomJennings.copy-selected-file-contents" rel="nofollow noreferrer">https:&#x2F;&#x2F;marketplace.visualstudio.com&#x2F;items?itemName=TomJenni...</a></div><br/></div></div></div></div><div id="36887435" class="c"><input type="checkbox" id="c-36887435" checked=""/><div class="controls bullet"><span class="by">eikenberry</span><span>|</span><a href="#36886291">prev</a><span>|</span><a href="#36886863">next</a><span>|</span><label class="collapse" for="c-36887435">[-]</label><label class="expand" for="c-36887435">[5 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not sure about your plans but you should consider implementing this based on the language server protocol model. Having it run as a local service that editors and other applications can interact with. LSP was a huge success and seems like a good model to follow.</div><br/><div id="36887580" class="c"><input type="checkbox" id="c-36887580" checked=""/><div class="controls bullet"><span class="by">sestinj</span><span>|</span><a href="#36887435">parent</a><span>|</span><a href="#36886863">next</a><span>|</span><label class="collapse" for="c-36887580">[-]</label><label class="expand" for="c-36887580">[4 more]</label></div><br/><div class="children"><div class="content">We have something similar in our plans. While the LSP doesn&#x27;t directly offer all of the APIs we need, we want to be an &quot;extended LSP&quot;, and integrate an LSP as part of the Continue server.</div><br/><div id="36888832" class="c"><input type="checkbox" id="c-36888832" checked=""/><div class="controls bullet"><span class="by">FloatArtifact</span><span>|</span><a href="#36887435">root</a><span>|</span><a href="#36887580">parent</a><span>|</span><a href="#36889009">next</a><span>|</span><label class="collapse" for="c-36888832">[-]</label><label class="expand" for="c-36888832">[1 more]</label></div><br/><div class="children"><div class="content">An alternative to in LSP is tree sitter <a href="https:&#x2F;&#x2F;github.com&#x2F;tree-sitter?type=source">https:&#x2F;&#x2F;github.com&#x2F;tree-sitter?type=source</a></div><br/></div></div><div id="36889009" class="c"><input type="checkbox" id="c-36889009" checked=""/><div class="controls bullet"><span class="by">jenadine</span><span>|</span><a href="#36887435">root</a><span>|</span><a href="#36887580">parent</a><span>|</span><a href="#36888832">prev</a><span>|</span><a href="#36886863">next</a><span>|</span><label class="collapse" for="c-36889009">[-]</label><label class="expand" for="c-36889009">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m curious to know what API is missing on the LSP.<p>With the LSP you have access to to whole source code and can do edits in the whole workspace.</div><br/><div id="36889650" class="c"><input type="checkbox" id="c-36889650" checked=""/><div class="controls bullet"><span class="by">sestinj</span><span>|</span><a href="#36887435">root</a><span>|</span><a href="#36889009">parent</a><span>|</span><a href="#36886863">next</a><span>|</span><label class="collapse" for="c-36889650">[-]</label><label class="expand" for="c-36889650">[1 more]</label></div><br/><div class="children"><div class="content">One example is displaying a side-by-side diff as we stream an edit</div><br/></div></div></div></div></div></div></div></div><div id="36886863" class="c"><input type="checkbox" id="c-36886863" checked=""/><div class="controls bullet"><span class="by">cassianoleal</span><span>|</span><a href="#36887435">prev</a><span>|</span><a href="#36886937">next</a><span>|</span><label class="collapse" for="c-36886863">[-]</label><label class="expand" for="c-36886863">[7 more]</label></div><br/><div class="children"><div class="content">This looks great.<p>A few observations:<p>- As soon as I sent it the first prompt, it tried to connect to windows.net. Why is that? Is this call safe to block?<p>- When opening a new window, macOS asks me to give access to VS Code for a lot of folders: Desktop, Downloads, Documents... The only new thing is the Continue plugin. Why would it ask that?<p>- It looks like it needs to redownload &quot;Python packages&quot; every time I open a new window. I wonder if this could be optimised for a quicker startup.<p>- It tries to connect to meilisearch.com . What information is being sent over? What is this used for?</div><br/><div id="36886983" class="c"><input type="checkbox" id="c-36886983" checked=""/><div class="controls bullet"><span class="by">sestinj</span><span>|</span><a href="#36886863">parent</a><span>|</span><a href="#36886937">next</a><span>|</span><label class="collapse" for="c-36886983">[-]</label><label class="expand" for="c-36886983">[6 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not aware of any reason we would be connecting to windows.net. I would be surprised if VS Code did not already have access to Desktop &#x2F; Documents &#x2F; etc. but if this is the case, then Continue reads the currently open files as context for the LLM. It would be very useful to hear more about the details of these two cases so we can try to better reproduce and solve the problem. Would you be interested in opening a new issue? (<a href="https:&#x2F;&#x2F;github.com&#x2F;continuedev&#x2F;continue&#x2F;issues&#x2F;new">https:&#x2F;&#x2F;github.com&#x2F;continuedev&#x2F;continue&#x2F;issues&#x2F;new</a>)<p>Continue will cache Python packages in ~&#x2F;.continue&#x2F;server&#x2F;env after the first download, but there might be something else causing slower startup. Will look into this as well!<p>Meilisearch is an open-source search library. We connect to meilisearch.com only in order to download the software, which then runs completely locally to power search in the dropdown as you type. The line of code where we do this is here: <a href="https:&#x2F;&#x2F;github.com&#x2F;continuedev&#x2F;continue&#x2F;blob&#x2F;ce76e391775034c1faec3198f59b2d5f90f61150&#x2F;continuedev&#x2F;src&#x2F;continuedev&#x2F;server&#x2F;meilisearch_server.py#L44">https:&#x2F;&#x2F;github.com&#x2F;continuedev&#x2F;continue&#x2F;blob&#x2F;ce76e391775034c...</a></div><br/><div id="36887777" class="c"><input type="checkbox" id="c-36887777" checked=""/><div class="controls bullet"><span class="by">Galanwe</span><span>|</span><a href="#36886863">root</a><span>|</span><a href="#36886983">parent</a><span>|</span><a href="#36886937">next</a><span>|</span><label class="collapse" for="c-36887777">[-]</label><label class="expand" for="c-36887777">[5 more]</label></div><br/><div class="children"><div class="content"><p><pre><code>    subprocess.run(f&quot;curl -L https:&#x2F;&#x2F;install.meilisearch.com | sh&quot;, shell=True)
</code></pre>
Just went from &quot;cool project, might try it&quot; to &quot;nope&quot;.</div><br/><div id="36888086" class="c"><input type="checkbox" id="c-36888086" checked=""/><div class="controls bullet"><span class="by">sestinj</span><span>|</span><a href="#36886863">root</a><span>|</span><a href="#36887777">parent</a><span>|</span><a href="#36886937">next</a><span>|</span><label class="collapse" for="c-36888086">[-]</label><label class="expand" for="c-36888086">[4 more]</label></div><br/><div class="children"><div class="content">This is fair feedback. We will move to packaging it with our extension to avoid running arbitrary code.</div><br/><div id="36888337" class="c"><input type="checkbox" id="c-36888337" checked=""/><div class="controls bullet"><span class="by">Galanwe</span><span>|</span><a href="#36886863">root</a><span>|</span><a href="#36888086">parent</a><span>|</span><a href="#36886937">next</a><span>|</span><label class="collapse" for="c-36888337">[-]</label><label class="expand" for="c-36888337">[3 more]</label></div><br/><div class="children"><div class="content">Note that you&#x27;re also not opting out of &quot;meilisearch telemetry&quot;.<p>You are sending full laptop specs of your users to meilisearch. Which in turn sends them to Twilio apparently.</div><br/><div id="36888376" class="c"><input type="checkbox" id="c-36888376" checked=""/><div class="controls bullet"><span class="by">sestinj</span><span>|</span><a href="#36886863">root</a><span>|</span><a href="#36888337">parent</a><span>|</span><a href="#36886937">next</a><span>|</span><label class="collapse" for="c-36888376">[-]</label><label class="expand" for="c-36888376">[2 more]</label></div><br/><div class="children"><div class="content">This is a good catch, thank you</div><br/><div id="36890126" class="c"><input type="checkbox" id="c-36890126" checked=""/><div class="controls bullet"><span class="by">Galanwe</span><span>|</span><a href="#36886863">root</a><span>|</span><a href="#36888376">parent</a><span>|</span><a href="#36886937">next</a><span>|</span><label class="collapse" for="c-36890126">[-]</label><label class="expand" for="c-36890126">[1 more]</label></div><br/><div class="children"><div class="content">I see you&#x27;ve fixed it already, kudos for your reactivity!</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="36886937" class="c"><input type="checkbox" id="c-36886937" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#36886863">prev</a><span>|</span><a href="#36887135">next</a><span>|</span><label class="collapse" for="c-36886937">[-]</label><label class="expand" for="c-36886937">[2 more]</label></div><br/><div class="children"><div class="content">&quot;Continue works with any LLM, including local models using ggml&quot;<p>Which of the local models have you seen the best results with?<p>UPDATE: Found a note here <a href="https:&#x2F;&#x2F;github.com&#x2F;continuedev&#x2F;continue&#x2F;blob&#x2F;ce76e391775034c1faec3198f59b2d5f90f61150&#x2F;docs&#x2F;docs&#x2F;customization.md#local-models-with-ggml">https:&#x2F;&#x2F;github.com&#x2F;continuedev&#x2F;continue&#x2F;blob&#x2F;ce76e391775034c...</a> that says &quot;While these models don&#x27;t yet perform as well, they are free, entirely private, and run offline.&quot; and points to the documentation here for how to run one, but doesn&#x27;t really recommend a specific model: <a href="https:&#x2F;&#x2F;github.com&#x2F;continuedev&#x2F;ggml-server-example">https:&#x2F;&#x2F;github.com&#x2F;continuedev&#x2F;ggml-server-example</a></div><br/><div id="36887082" class="c"><input type="checkbox" id="c-36887082" checked=""/><div class="controls bullet"><span class="by">sestinj</span><span>|</span><a href="#36886937">parent</a><span>|</span><a href="#36887135">next</a><span>|</span><label class="collapse" for="c-36887082">[-]</label><label class="expand" for="c-36887082">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve had the best luck with WizardLM-7B. It runs at ~4 tokens&#x2F;sec on my M1 and has decent outputs for simple situations. While it can&#x27;t handle complex refactors like gpt4, I believe there&#x27;s room to improve both via prompting and codebase-specific fine-tuning.<p>And good point! I&#x27;ve just added this as the recommendation in the README.</div><br/></div></div></div></div><div id="36887135" class="c"><input type="checkbox" id="c-36887135" checked=""/><div class="controls bullet"><span class="by">whoisjuan</span><span>|</span><a href="#36886937">prev</a><span>|</span><a href="#36886021">next</a><span>|</span><label class="collapse" for="c-36887135">[-]</label><label class="expand" for="c-36887135">[9 more]</label></div><br/><div class="children"><div class="content">Why is nobody in this space making good gains on UX?<p>I have tried almost every co-pilot solution, including GitHub Co-Pilot with Chat and Labs, Cody, and a few random extensions.<p>And for some reason, I still default to using ChatGPT, even with the massive drawback of copying and pasting.<p>I haven’t seen any breakthroughs with these developer experiences. Every still feels suboptimal.</div><br/><div id="36890625" class="c"><input type="checkbox" id="c-36890625" checked=""/><div class="controls bullet"><span class="by">sqs</span><span>|</span><a href="#36887135">parent</a><span>|</span><a href="#36887234">next</a><span>|</span><label class="collapse" for="c-36890625">[-]</label><label class="expand" for="c-36890625">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m one of the people building Cody (<a href="https:&#x2F;&#x2F;cody.dev" rel="nofollow noreferrer">https:&#x2F;&#x2F;cody.dev</a>), which you mentioned. Re: suboptimal, yeah, these are all very early and there is so much room for improvement. Do you have a sense at least of what would be less suboptimal&#x2F;more optimal for you?</div><br/></div></div><div id="36887234" class="c"><input type="checkbox" id="c-36887234" checked=""/><div class="controls bullet"><span class="by">extr</span><span>|</span><a href="#36887135">parent</a><span>|</span><a href="#36890625">prev</a><span>|</span><a href="#36887238">next</a><span>|</span><label class="collapse" for="c-36887234">[-]</label><label class="expand" for="c-36887234">[3 more]</label></div><br/><div class="children"><div class="content">Check out the Rubberduck Extension [1] for VS Code. It&#x27;s not super well publicized but I&#x27;ve actually found it basically hits a perfect middle ground between copilot and copy&#x2F;pasting into ChatGPT. You can give it a prompt to edit code and it will stream the answer from GPT-4 into VS Code and show you a live diff with your current code. It&#x27;s actually pretty well done, I use it dozens of times a day for even super minor things (I&#x27;m lazy).<p>Actually, it looks like this project is fairly similar in some ways. A little more full featured.<p>[1] <a href="https:&#x2F;&#x2F;marketplace.visualstudio.com&#x2F;items?itemName=Rubberduck.rubberduck-vscode" rel="nofollow noreferrer">https:&#x2F;&#x2F;marketplace.visualstudio.com&#x2F;items?itemName=Rubberdu...</a></div><br/><div id="36890696" class="c"><input type="checkbox" id="c-36890696" checked=""/><div class="controls bullet"><span class="by">lgrammel</span><span>|</span><a href="#36887135">root</a><span>|</span><a href="#36887234">parent</a><span>|</span><a href="#36887722">next</a><span>|</span><label class="collapse" for="c-36890696">[-]</label><label class="expand" for="c-36890696">[1 more]</label></div><br/><div class="children"><div class="content">Author here - thanks for the mention! Re publicizing: I can never get any attention for my projects, no matter where I post them. Sites like this one (where I tried posting the project multiple times) feel very gamed to me at this point.</div><br/></div></div><div id="36887722" class="c"><input type="checkbox" id="c-36887722" checked=""/><div class="controls bullet"><span class="by">whoisjuan</span><span>|</span><a href="#36887135">root</a><span>|</span><a href="#36887234">parent</a><span>|</span><a href="#36890696">prev</a><span>|</span><a href="#36887238">next</a><span>|</span><label class="collapse" for="c-36887722">[-]</label><label class="expand" for="c-36887722">[1 more]</label></div><br/><div class="children"><div class="content">Thanks! I’ll give this a try for sure.</div><br/></div></div></div></div><div id="36887238" class="c"><input type="checkbox" id="c-36887238" checked=""/><div class="controls bullet"><span class="by">sestinj</span><span>|</span><a href="#36887135">parent</a><span>|</span><a href="#36887234">prev</a><span>|</span><a href="#36887717">next</a><span>|</span><label class="collapse" for="c-36887238">[-]</label><label class="expand" for="c-36887238">[2 more]</label></div><br/><div class="children"><div class="content">We very much agree, and are aiming to tackle exactly this problem with Continue. Curious to know more about what you&#x27;ve tried and learned. What are the limitations that cause you to return to ChatGPT?<p>On another note: we purposefully refer to ourselves as an &quot;autopilot&quot; rather than &quot;co-pilot&quot;. While at first glance pedantic, we think there is real value behind the idea that developers should be in control. We want to get out of their way, rather than injecting AI everywhere. An autopilot should feel like less of a separate entity (a pair-programmer) and more of an extension of yourself, a part of your own brain that you can call on to more easily complete particular tasks.</div><br/><div id="36890022" class="c"><input type="checkbox" id="c-36890022" checked=""/><div class="controls bullet"><span class="by">ldhough</span><span>|</span><a href="#36887135">root</a><span>|</span><a href="#36887238">parent</a><span>|</span><a href="#36887717">next</a><span>|</span><label class="collapse" for="c-36890022">[-]</label><label class="expand" for="c-36890022">[1 more]</label></div><br/><div class="children"><div class="content">&gt; more of an extension of yourself, a part of your own brain that you can call on to more easily complete particular tasks.<p>I like this idea but I gotta say when I think &quot;autopilot&quot; I think &quot;does it for you&quot; and imagine ceding control rather than retaining it. I definitely assumed after reading the name that it was going to be a tool to minimize developer involvement as much as possible, similar to how AutoGPT is supposed to require less supervision.</div><br/></div></div></div></div><div id="36887717" class="c"><input type="checkbox" id="c-36887717" checked=""/><div class="controls bullet"><span class="by">estebarb</span><span>|</span><a href="#36887135">parent</a><span>|</span><a href="#36887238">prev</a><span>|</span><a href="#36886021">next</a><span>|</span><label class="collapse" for="c-36887717">[-]</label><label class="expand" for="c-36887717">[2 more]</label></div><br/><div class="children"><div class="content">You have tried Control+I (Cmd+I in Mac) with Visual Studio Code + GitHub Copilot? I didn&#x27;t knew of it until yesterday and it is much better than the chat or wait for autocomplete approach.</div><br/><div id="36888481" class="c"><input type="checkbox" id="c-36888481" checked=""/><div class="controls bullet"><span class="by">whoisjuan</span><span>|</span><a href="#36887135">root</a><span>|</span><a href="#36887717">parent</a><span>|</span><a href="#36886021">next</a><span>|</span><label class="collapse" for="c-36888481">[-]</label><label class="expand" for="c-36888481">[1 more]</label></div><br/><div class="children"><div class="content">Nice! I didn&#x27;t know about this! Thanks.</div><br/></div></div></div></div></div></div><div id="36886021" class="c"><input type="checkbox" id="c-36886021" checked=""/><div class="controls bullet"><span class="by">satvikpendem</span><span>|</span><a href="#36887135">prev</a><span>|</span><a href="#36885645">next</a><span>|</span><label class="collapse" for="c-36886021">[-]</label><label class="expand" for="c-36886021">[4 more]</label></div><br/><div class="children"><div class="content">Looks like this is similar to GitHub Copilot Chat [0], just open source right? I like that you&#x27;re supporting open models as well rather than just ChatGPT. Is there a way for your extension to read the file you&#x27;re in as input before you ask any questions, so that it has the context of what you want to do?<p>[0] <a href="https:&#x2F;&#x2F;github.blog&#x2F;2023-07-20-github-copilot-chat-beta-now-available-for-every-organization&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;github.blog&#x2F;2023-07-20-github-copilot-chat-beta-now-...</a></div><br/><div id="36889359" class="c"><input type="checkbox" id="c-36889359" checked=""/><div class="controls bullet"><span class="by">specproc</span><span>|</span><a href="#36886021">parent</a><span>|</span><a href="#36886098">next</a><span>|</span><label class="collapse" for="c-36889359">[-]</label><label class="expand" for="c-36889359">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve been using Copilot and Copilot chat for a while now, and I really struggle to see why I should use any of these ChatGPT wrappers over it. I know some support local inference with open models, but they&#x27;re just not that good in July 2023.<p>Sure, it&#x27;s M$, sure it&#x27;s not open source (IIRC), but all you get with these alternatives is a wrapper around the ChatGPT API, or in some cases a lesser model. No one&#x27;s solved the whole directory context problem yet, no one seems to be doing much the Copilot suite can&#x27;t.<p>Copilot is <i>currently</i> reasonably priced, and pretty much guaranteed support and  development going forward. There&#x27;s pull requests and cli in the pipeline [0].<p>I&#x27;d need directory context inference on a quality open model to be convinced to use anything else, and we&#x27;re just not there yet.<p>[0] <a href="https:&#x2F;&#x2F;github.com&#x2F;features&#x2F;preview&#x2F;copilot-x">https:&#x2F;&#x2F;github.com&#x2F;features&#x2F;preview&#x2F;copilot-x</a></div><br/><div id="36889386" class="c"><input type="checkbox" id="c-36889386" checked=""/><div class="controls bullet"><span class="by">satvikpendem</span><span>|</span><a href="#36886021">root</a><span>|</span><a href="#36889359">parent</a><span>|</span><a href="#36886098">next</a><span>|</span><label class="collapse" for="c-36889386">[-]</label><label class="expand" for="c-36889386">[1 more]</label></div><br/><div class="children"><div class="content">I use both Copilot and ChatGPT, they&#x27;re entirely different things. Copilot works best for one line autocomplete, ChatGPT works for writing entire functions, if needed. This is to be expected as Copilot currently uses a much older LLM, and it is due to be upgraded to GPT 4 soon.</div><br/></div></div></div></div><div id="36886098" class="c"><input type="checkbox" id="c-36886098" checked=""/><div class="controls bullet"><span class="by">sestinj</span><span>|</span><a href="#36886021">parent</a><span>|</span><a href="#36889359">prev</a><span>|</span><a href="#36885645">next</a><span>|</span><label class="collapse" for="c-36886098">[-]</label><label class="expand" for="c-36886098">[1 more]</label></div><br/><div class="children"><div class="content">Right now we are similar, but the open-source part is really key. We think that the ability to write custom plugins will make for a completely different kind of product.<p>And yes, by default Continue sees your open file, but you can also highlight multiple code snippets or type &#x27;@&#x27; to include context from outside your codebase, like GitHub issues.</div><br/></div></div></div></div><div id="36885645" class="c"><input type="checkbox" id="c-36885645" checked=""/><div class="controls bullet"><span class="by">weekay</span><span>|</span><a href="#36886021">prev</a><span>|</span><a href="#36890695">next</a><span>|</span><label class="collapse" for="c-36885645">[-]</label><label class="expand" for="c-36885645">[2 more]</label></div><br/><div class="children"><div class="content">Seems interesting will definitely give it a try.
Few observations&#x2F; questions from reading the documentation-
&gt; Continue will only be as helpful as the LLM you are using to power the edits and explanations<p>Are there any others apart from gpt4 suitable for programming copilot tasks ?<p>&gt; If files get too large, it can be difficult for Continue to fit them into the limited LLM context windows. Try to highlight the section of code that include the relevant context. It&#x27;s rare that you need the entire file.<p>Most of the value and real world use case benefits come from usage in a brownfield development where a legacy code isn’t well understood and is large (exceed current LLM context ?)<p>&gt; telemetry through posthog 
Can organisations setup their own telemetry and development data collection to further analyse how and where the Copilot is being used ?<p>&gt; Finops 
How does one get visibility of token &#x2F; api usage and track api spends ?</div><br/><div id="36885898" class="c"><input type="checkbox" id="c-36885898" checked=""/><div class="controls bullet"><span class="by">sestinj</span><span>|</span><a href="#36885645">parent</a><span>|</span><a href="#36890695">next</a><span>|</span><label class="collapse" for="c-36885898">[-]</label><label class="expand" for="c-36885898">[1 more]</label></div><br/><div class="children"><div class="content">Appreciate the deep read into the docs!<p>&gt; We&#x27;ve found claude-2 very capable, especially for chat functionality, and especially in situations where you&#x27;re looking for the equivalent of a faster Google search, even smaller models will do. For inline edits, gpt4 well outperforms others, but we&#x27;ve only optimized the prompt for gpt4. There&#x27;s a LOT of tinkering to be done here, and it seems clear that OSS models will be capable soon.<p>&gt; Definitely value there. We have an embeddings search plugin heading out the door soon, but we very consciously avoided this for a while - it obstructs understanding of what code enters the context window, and we think transparency is underrated.<p>&gt; Yes! You could have your own PostHog telemetry by simply switching out the key, but we also deposit higher quality development data on your machine (we never see it). Benefits being both 1) understanding ROI of the tool, and 2) being able to train custom models.<p>&gt; This is a reasonable request! We&#x27;ll add a feature for this. Right now, you can use the usage dashboard of whichever provider&#x27;s key you use.</div><br/></div></div></div></div><div id="36890695" class="c"><input type="checkbox" id="c-36890695" checked=""/><div class="controls bullet"><span class="by">AstraZenecat</span><span>|</span><a href="#36885645">prev</a><span>|</span><a href="#36887009">next</a><span>|</span><label class="collapse" for="c-36890695">[-]</label><label class="expand" for="c-36890695">[1 more]</label></div><br/><div class="children"><div class="content">does this require gpt-4? I can&#x27;t afford such a luxury sadly.</div><br/></div></div><div id="36887009" class="c"><input type="checkbox" id="c-36887009" checked=""/><div class="controls bullet"><span class="by">anotherpaulg</span><span>|</span><a href="#36890695">prev</a><span>|</span><a href="#36889889">next</a><span>|</span><label class="collapse" for="c-36887009">[-]</label><label class="expand" for="c-36887009">[2 more]</label></div><br/><div class="children"><div class="content">This looks really interesting. Have you spent much time investigating how to provide code context to the LLM without needing to manually highlight all the relevant code?<p>That’s been a major focus of my open source AI coding assistant project [0]. It seems super promising to exploit the semantic structure of code to help LLMs understand complex codebases [1].<p>Also, there’s a small discord [2] where a few of us are sharing learnings about building these coding assistants. Please join if you’d like to compare notes.<p>[0] <a href="https:&#x2F;&#x2F;github.com&#x2F;paul-gauthier&#x2F;aider">https:&#x2F;&#x2F;github.com&#x2F;paul-gauthier&#x2F;aider</a><p>[1] <a href="https:&#x2F;&#x2F;aider.chat&#x2F;docs&#x2F;ctags.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;aider.chat&#x2F;docs&#x2F;ctags.html</a><p>[2] <a href="https:&#x2F;&#x2F;discord.gg&#x2F;FTYDTRKZ" rel="nofollow noreferrer">https:&#x2F;&#x2F;discord.gg&#x2F;FTYDTRKZ</a></div><br/><div id="36887154" class="c"><input type="checkbox" id="c-36887154" checked=""/><div class="controls bullet"><span class="by">sestinj</span><span>|</span><a href="#36887009">parent</a><span>|</span><a href="#36889889">next</a><span>|</span><label class="collapse" for="c-36887154">[-]</label><label class="expand" for="c-36887154">[1 more]</label></div><br/><div class="children"><div class="content">We&#x27;ve tried embedding search multiple times, and are also looking into the LSP. We actually removed the former for the time being because it reduces control&#x2F;transparency when files are automatically being selected. Soon however we plan to release a Continue add-on that lets you type &#x27;@magic&#x27; or &#x27;@search&#x27; or &#x27;@embed&#x27; or something to deliberately include the results of a vector search in your context.<p>Looks like cool work you&#x27;re doing, would love to learn more—thanks for the invite!</div><br/></div></div></div></div><div id="36889889" class="c"><input type="checkbox" id="c-36889889" checked=""/><div class="controls bullet"><span class="by">jossclimb</span><span>|</span><a href="#36887009">prev</a><span>|</span><a href="#36889078">next</a><span>|</span><label class="collapse" for="c-36889889">[-]</label><label class="expand" for="c-36889889">[1 more]</label></div><br/><div class="children"><div class="content">How are you going to monetize this? I would be very nervous building a business around an extension calling someone elses API. You only have to look at the drama that played out at reddit a few weeks ago, to see how risky it is.</div><br/></div></div><div id="36889078" class="c"><input type="checkbox" id="c-36889078" checked=""/><div class="controls bullet"><span class="by">jenadine</span><span>|</span><a href="#36889889">prev</a><span>|</span><a href="#36885661">next</a><span>|</span><label class="collapse" for="c-36889078">[-]</label><label class="expand" for="c-36889078">[2 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t find this clear in the website what LLM it is really using.
Is it sending my code and queries over the internet? Or can it use a local language model?</div><br/><div id="36889139" class="c"><input type="checkbox" id="c-36889139" checked=""/><div class="controls bullet"><span class="by">sestinj</span><span>|</span><a href="#36889078">parent</a><span>|</span><a href="#36885661">next</a><span>|</span><label class="collapse" for="c-36889139">[-]</label><label class="expand" for="c-36889139">[1 more]</label></div><br/><div class="children"><div class="content">By default it uses the gpt4 API, but you can optionally use any language model you&#x27;d like, including a local model. Can read more here: <a href="https:&#x2F;&#x2F;continue.dev&#x2F;docs&#x2F;customization#change-the-default-llm">https:&#x2F;&#x2F;continue.dev&#x2F;docs&#x2F;customization#change-the-default-l...</a></div><br/></div></div></div></div><div id="36885661" class="c"><input type="checkbox" id="c-36885661" checked=""/><div class="controls bullet"><span class="by">jierlich</span><span>|</span><a href="#36889078">prev</a><span>|</span><a href="#36889195">next</a><span>|</span><label class="collapse" for="c-36885661">[-]</label><label class="expand" for="c-36885661">[3 more]</label></div><br/><div class="children"><div class="content">Been using Continue for a few weeks in combination with GH co-pilot. Overall it&#x27;s been a solid experience. After a few days of adjusting, it&#x27;s become my go to because I don&#x27;t feel like I need to leave VSCode to get questions answered. Although there are constraints, the edit functionality works ~80% of the time after figuring out how to prompt it.<p>It&#x27;s clear the team is shipping a ton too since almost every day I see VSCode popup about restarting my editor for the new version of Continue.<p>Excited to see where things go with this!</div><br/><div id="36885736" class="c"><input type="checkbox" id="c-36885736" checked=""/><div class="controls bullet"><span class="by">mritchie712</span><span>|</span><a href="#36885661">parent</a><span>|</span><a href="#36889195">next</a><span>|</span><label class="collapse" for="c-36885736">[-]</label><label class="expand" for="c-36885736">[2 more]</label></div><br/><div class="children"><div class="content">What LLM are you using it with?</div><br/><div id="36885873" class="c"><input type="checkbox" id="c-36885873" checked=""/><div class="controls bullet"><span class="by">jierlich</span><span>|</span><a href="#36885661">root</a><span>|</span><a href="#36885736">parent</a><span>|</span><a href="#36889195">next</a><span>|</span><label class="collapse" for="c-36885873">[-]</label><label class="expand" for="c-36885873">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m using the default, which is GPT4 iirc</div><br/></div></div></div></div></div></div><div id="36889195" class="c"><input type="checkbox" id="c-36889195" checked=""/><div class="controls bullet"><span class="by">smcleod</span><span>|</span><a href="#36885661">prev</a><span>|</span><a href="#36886209">next</a><span>|</span><label class="collapse" for="c-36889195">[-]</label><label class="expand" for="c-36889195">[5 more]</label></div><br/><div class="children"><div class="content">Looks like it&#x27;s trying to send my data to &quot;meilisearch&quot; without asking me :&#x2F;</div><br/><div id="36889429" class="c"><input type="checkbox" id="c-36889429" checked=""/><div class="controls bullet"><span class="by">sestinj</span><span>|</span><a href="#36889195">parent</a><span>|</span><a href="#36886209">next</a><span>|</span><label class="collapse" for="c-36889429">[-]</label><label class="expand" for="c-36889429">[4 more]</label></div><br/><div class="children"><div class="content">No longer: <a href="https:&#x2F;&#x2F;github.com&#x2F;continuedev&#x2F;continue&#x2F;commit&#x2F;8db5b39170229ba93b83f526e7fd80056e461c6a">https:&#x2F;&#x2F;github.com&#x2F;continuedev&#x2F;continue&#x2F;commit&#x2F;8db5b39170229...</a><p>Definitely not intending this type of behavior. We want to do everything to keep Continue completely private.</div><br/><div id="36889489" class="c"><input type="checkbox" id="c-36889489" checked=""/><div class="controls bullet"><span class="by">smcleod</span><span>|</span><a href="#36889195">root</a><span>|</span><a href="#36889429">parent</a><span>|</span><a href="#36889519">next</a><span>|</span><label class="collapse" for="c-36889489">[-]</label><label class="expand" for="c-36889489">[1 more]</label></div><br/><div class="children"><div class="content">Ah, good to see, easy mistake to make. Thanks.</div><br/></div></div><div id="36889519" class="c"><input type="checkbox" id="c-36889519" checked=""/><div class="controls bullet"><span class="by">deanc</span><span>|</span><a href="#36889195">root</a><span>|</span><a href="#36889429">parent</a><span>|</span><a href="#36889489">prev</a><span>|</span><a href="#36886209">next</a><span>|</span><label class="collapse" for="c-36889519">[-]</label><label class="expand" for="c-36889519">[2 more]</label></div><br/><div class="children"><div class="content">Why is it there in the first place?</div><br/><div id="36889626" class="c"><input type="checkbox" id="c-36889626" checked=""/><div class="controls bullet"><span class="by">sestinj</span><span>|</span><a href="#36889195">root</a><span>|</span><a href="#36889519">parent</a><span>|</span><a href="#36886209">next</a><span>|</span><label class="collapse" for="c-36889626">[-]</label><label class="expand" for="c-36889626">[1 more]</label></div><br/><div class="children"><div class="content">If you mean Meilisearch, we use it to provide a snappy dropdown search experience, like here: <a href="https:&#x2F;&#x2F;youtu.be&#x2F;3Ocrc-WX4iQ?t=86" rel="nofollow noreferrer">https:&#x2F;&#x2F;youtu.be&#x2F;3Ocrc-WX4iQ?t=86</a><p>We chose Meilisearch because it works entirely on your machine (now that analytics are turned off ;) )</div><br/></div></div></div></div></div></div></div></div><div id="36886209" class="c"><input type="checkbox" id="c-36886209" checked=""/><div class="controls bullet"><span class="by">rodrigodlu</span><span>|</span><a href="#36889195">prev</a><span>|</span><a href="#36889141">next</a><span>|</span><label class="collapse" for="c-36886209">[-]</label><label class="expand" for="c-36886209">[4 more]</label></div><br/><div class="children"><div class="content">Hey! Thanks for this tool. I was testing and paying copilot, including the new chat integrated tool, but I feel your work flow proposal is more compelling.<p>That said, I&#x27;m not sure what&#x27;s the difference between providing my own openapi key or not. The &quot;Customization&quot; doc is not entirely clear on what using my own key enables me to do.<p>For instance, is this required for gpt4?
What are the limits of the free trial key?<p>I don&#x27;t want to evaluate this not knowing which model is really using, and it&#x27;s not clear what difference the key makes.<p>Edit: Also when I asked the Continue chat how to change my key and the model being used, it said that this is not possible since the key is yours, instead of pointing me to the &quot;Extension Settings&quot; inside the extension tab using the cog wheel.</div><br/><div id="36886324" class="c"><input type="checkbox" id="c-36886324" checked=""/><div class="controls bullet"><span class="by">sestinj</span><span>|</span><a href="#36886209">parent</a><span>|</span><a href="#36889141">next</a><span>|</span><label class="collapse" for="c-36886324">[-]</label><label class="expand" for="c-36886324">[3 more]</label></div><br/><div class="children"><div class="content">We wanted to make it as easy as possible for people to try Continue, so we allow 250 free requests. These use gpt4. If you plug in your own API key in VS Code settings, it will also use gpt4 by default.<p>We&#x27;ll update the &#x2F;help messaging so it knows this, and you can read more about choosing a model here: <a href="https:&#x2F;&#x2F;continue.dev&#x2F;docs&#x2F;customization">https:&#x2F;&#x2F;continue.dev&#x2F;docs&#x2F;customization</a></div><br/><div id="36888891" class="c"><input type="checkbox" id="c-36888891" checked=""/><div class="controls bullet"><span class="by">FloatArtifact</span><span>|</span><a href="#36886209">root</a><span>|</span><a href="#36886324">parent</a><span>|</span><a href="#36889141">next</a><span>|</span><label class="collapse" for="c-36888891">[-]</label><label class="expand" for="c-36888891">[2 more]</label></div><br/><div class="children"><div class="content">LocalAI seems like a interesting project that allows self-hosted can be easily called over the network.  Open AI compatible interface <a href="https:&#x2F;&#x2F;github.com&#x2F;go-skynet&#x2F;LocalAI">https:&#x2F;&#x2F;github.com&#x2F;go-skynet&#x2F;LocalAI</a></div><br/><div id="36889186" class="c"><input type="checkbox" id="c-36889186" checked=""/><div class="controls bullet"><span class="by">sestinj</span><span>|</span><a href="#36886209">root</a><span>|</span><a href="#36888891">parent</a><span>|</span><a href="#36889141">next</a><span>|</span><label class="collapse" for="c-36889186">[-]</label><label class="expand" for="c-36889186">[1 more]</label></div><br/><div class="children"><div class="content">Thanks for sharing! We&#x27;ve been recommending something similar with these llama-cpp-python bindings <a href="https:&#x2F;&#x2F;github.com&#x2F;abetlen&#x2F;llama-cpp-python#web-server">https:&#x2F;&#x2F;github.com&#x2F;abetlen&#x2F;llama-cpp-python#web-server</a>, but I&#x27;ll have to check that out</div><br/></div></div></div></div></div></div></div></div><div id="36889141" class="c"><input type="checkbox" id="c-36889141" checked=""/><div class="controls bullet"><span class="by">jenadine</span><span>|</span><a href="#36886209">prev</a><span>|</span><a href="#36886121">next</a><span>|</span><label class="collapse" for="c-36889141">[-]</label><label class="expand" for="c-36889141">[2 more]</label></div><br/><div class="children"><div class="content">The extension is not available on <a href="https:&#x2F;&#x2F;open-vsx.org&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;open-vsx.org&#x2F;</a> ? (The market place for VSCodium)</div><br/><div id="36889236" class="c"><input type="checkbox" id="c-36889236" checked=""/><div class="controls bullet"><span class="by">sestinj</span><span>|</span><a href="#36889141">parent</a><span>|</span><a href="#36886121">next</a><span>|</span><label class="collapse" for="c-36889236">[-]</label><label class="expand" for="c-36889236">[1 more]</label></div><br/><div class="children"><div class="content">It is now :) <a href="https:&#x2F;&#x2F;open-vsx.org&#x2F;extension&#x2F;Continue&#x2F;continue" rel="nofollow noreferrer">https:&#x2F;&#x2F;open-vsx.org&#x2F;extension&#x2F;Continue&#x2F;continue</a></div><br/></div></div></div></div><div id="36886121" class="c"><input type="checkbox" id="c-36886121" checked=""/><div class="controls bullet"><span class="by">krono</span><span>|</span><a href="#36889141">prev</a><span>|</span><a href="#36887991">next</a><span>|</span><label class="collapse" for="c-36886121">[-]</label><label class="expand" for="c-36886121">[3 more]</label></div><br/><div class="children"><div class="content">A cursory look through the source reveals the presence of three different telemetry suites of which only Posthog looks to be properly documented. I could have overlooked it, but do you have any more information on what Segment and Sentry are doing there?</div><br/><div id="36886197" class="c"><input type="checkbox" id="c-36886197" checked=""/><div class="controls bullet"><span class="by">sestinj</span><span>|</span><a href="#36886121">parent</a><span>|</span><a href="#36887991">next</a><span>|</span><label class="collapse" for="c-36886197">[-]</label><label class="expand" for="c-36886197">[2 more]</label></div><br/><div class="children"><div class="content">Just deleted: <a href="https:&#x2F;&#x2F;github.com&#x2F;continuedev&#x2F;continue&#x2F;commit&#x2F;eba2f57a6462f691000544aa4d274de2e8a5cc37">https:&#x2F;&#x2F;github.com&#x2F;continuedev&#x2F;continue&#x2F;commit&#x2F;eba2f57a6462f...</a><p>Neither were doing anything, we simply forgot to `npm uninstall` after (a while ago) playing around to decide which service to use. Thanks for pointing it out.</div><br/><div id="36886284" class="c"><input type="checkbox" id="c-36886284" checked=""/><div class="controls bullet"><span class="by">krono</span><span>|</span><a href="#36886121">root</a><span>|</span><a href="#36886197">parent</a><span>|</span><a href="#36887991">next</a><span>|</span><label class="collapse" for="c-36886284">[-]</label><label class="expand" for="c-36886284">[1 more]</label></div><br/><div class="children"><div class="content">That clears it up, cheers and all the best with this project!</div><br/></div></div></div></div></div></div><div id="36887991" class="c"><input type="checkbox" id="c-36887991" checked=""/><div class="controls bullet"><span class="by">FloatArtifact</span><span>|</span><a href="#36886121">prev</a><span>|</span><a href="#36885948">next</a><span>|</span><label class="collapse" for="c-36887991">[-]</label><label class="expand" for="c-36887991">[5 more]</label></div><br/><div class="children"><div class="content">Thank you for supporting an open source ecosystem.<p>A couple of thoughts.<p>1. It would be nice if we could ingest external resources like web pages.<p>2. Deep integration with the debugger (Limitation mentioned in your docs). Code pilot seems to be very superficial here.<p>I know the issues above are limited by the token context. However, there&#x27;s not a lot of innovation in these two aspects for code generation.</div><br/><div id="36888079" class="c"><input type="checkbox" id="c-36888079" checked=""/><div class="controls bullet"><span class="by">sestinj</span><span>|</span><a href="#36887991">parent</a><span>|</span><a href="#36885948">next</a><span>|</span><label class="collapse" for="c-36888079">[-]</label><label class="expand" for="c-36888079">[4 more]</label></div><br/><div class="children"><div class="content">The first is already possible today! Using &quot;ContextProviders&quot;, you can specify external resources to use as context. For example, we have a GitHub Issues ContextProvider that lets you type &#x27;@issue&#x27; and then search through open issues in your repo. We haven&#x27;t yet built a ContextProvider for web pages, but this is a great idea. Theoretically, just type &#x27;@&lt;URL&gt;&#x27;, then the LLM will know about the page.<p>The second sounds quite interesting. I&#x27;m curious whether you envision as far as the language model stepping through a program on its own? We had considered working on this at one point in time.</div><br/><div id="36888781" class="c"><input type="checkbox" id="c-36888781" checked=""/><div class="controls bullet"><span class="by">FloatArtifact</span><span>|</span><a href="#36887991">root</a><span>|</span><a href="#36888079">parent</a><span>|</span><a href="#36885948">next</a><span>|</span><label class="collapse" for="c-36888781">[-]</label><label class="expand" for="c-36888781">[3 more]</label></div><br/><div class="children"><div class="content">All right.<p>Honestly I could see it both ways depending on the needs of the developer. The language model could step through autonomously or with the developer.<p>Thinking of how this could look like abstractly through a UI. Picture sequential timeline which consists each step the developer or the model has made through the code. A timeline that the developer could fast forward or rewind which has some implications for the LLM.<p>There are three main areas the developer could give LLM inputs.<p>1. Before debugging<p>The user could give input (Trace back, a question, ingested context (URL) before initializing debugging, instruction steps, autonomously or guided.<p>Autonomously given the context of before debugging, it could even optionally set its own breakpoints.<p>2. At any step during debugging<p>LLM might influence how the developers steps through the code.<p>3. Post debugging<p>Now imagine each step through the debugger being logged to which the user could ask questions within the context of the history of the debugger. LLM could have different scoped contexts relative to the timeline of the steps of interest.<p>Imagine the developer steps through 15 points in the code. Developer could ask about step 7 or a range of steps post debugging. LLM could be limited scope to only the previous steps including 7 or a range. Alternatively it could have knowledge of the entire step history. The underline assumption there is limiting context in some cases improves output of LLM.</div><br/><div id="36889180" class="c"><input type="checkbox" id="c-36889180" checked=""/><div class="controls bullet"><span class="by">sestinj</span><span>|</span><a href="#36887991">root</a><span>|</span><a href="#36888781">parent</a><span>|</span><a href="#36888938">next</a><span>|</span><label class="collapse" for="c-36889180">[-]</label><label class="expand" for="c-36889180">[1 more]</label></div><br/><div class="children"><div class="content">This is fantastic thinking. Actually I&#x27;m quite excited about the combination of fault-localization techniques and LLMs; taking a traceback, pruning the call-graph, and seeking out bugs. There&#x27;s a real future in all of this</div><br/></div></div><div id="36888938" class="c"><input type="checkbox" id="c-36888938" checked=""/><div class="controls bullet"><span class="by">FloatArtifact</span><span>|</span><a href="#36887991">root</a><span>|</span><a href="#36888781">parent</a><span>|</span><a href="#36889180">prev</a><span>|</span><a href="#36885948">next</a><span>|</span><label class="collapse" for="c-36888938">[-]</label><label class="expand" for="c-36888938">[1 more]</label></div><br/><div class="children"><div class="content">Profiling code then optimizing autonomously would be interesting to see as it edits the code.</div><br/></div></div></div></div></div></div></div></div><div id="36885948" class="c"><input type="checkbox" id="c-36885948" checked=""/><div class="controls bullet"><span class="by">nraf</span><span>|</span><a href="#36887991">prev</a><span>|</span><a href="#36885989">next</a><span>|</span><label class="collapse" for="c-36885948">[-]</label><label class="expand" for="c-36885948">[3 more]</label></div><br/><div class="children"><div class="content">Any plans for supporting Jetbrains IDEs?</div><br/><div id="36885991" class="c"><input type="checkbox" id="c-36885991" checked=""/><div class="controls bullet"><span class="by">sestinj</span><span>|</span><a href="#36885948">parent</a><span>|</span><a href="#36886544">next</a><span>|</span><label class="collapse" for="c-36885991">[-]</label><label class="expand" for="c-36885991">[1 more]</label></div><br/><div class="children"><div class="content">Focusing on VS Code for at least the next few weeks, but we&#x27;ve planned from the start! You can read more here (<a href="https:&#x2F;&#x2F;continue.dev&#x2F;docs&#x2F;how-continue-works">https:&#x2F;&#x2F;continue.dev&#x2F;docs&#x2F;how-continue-works</a>), but the Continue server abstracts over the IDE APIs, so it will be easier to support any IDE, even letting you run Continue in &quot;headless mode&quot; from the a Python script, the CLI, or in CI&#x2F;CD.</div><br/></div></div><div id="36886544" class="c"><input type="checkbox" id="c-36886544" checked=""/><div class="controls bullet"><span class="by">vunderba</span><span>|</span><a href="#36885948">parent</a><span>|</span><a href="#36885991">prev</a><span>|</span><a href="#36885989">next</a><span>|</span><label class="collapse" for="c-36886544">[-]</label><label class="expand" for="c-36886544">[1 more]</label></div><br/><div class="children"><div class="content">I use both pycharm and Webstorm, so an extension would be great! On the plus side, since they are all basically reskins of IntelliJ, one plug-in should work for all of the jetbrains suite.</div><br/></div></div></div></div><div id="36885989" class="c"><input type="checkbox" id="c-36885989" checked=""/><div class="controls bullet"><span class="by">dimal</span><span>|</span><a href="#36885948">prev</a><span>|</span><a href="#36885861">next</a><span>|</span><label class="collapse" for="c-36885989">[-]</label><label class="expand" for="c-36885989">[2 more]</label></div><br/><div class="children"><div class="content">This looks great! I’ve been pretty underwhelmed with the UX of the other VS Code extensions, for just the reasons you list. This looks a lot like how I imagined an AI extension should work. Gonna try it out.</div><br/><div id="36886022" class="c"><input type="checkbox" id="c-36886022" checked=""/><div class="controls bullet"><span class="by">sestinj</span><span>|</span><a href="#36885989">parent</a><span>|</span><a href="#36885861">next</a><span>|</span><label class="collapse" for="c-36886022">[-]</label><label class="expand" for="c-36886022">[1 more]</label></div><br/><div class="children"><div class="content">Really appreciate this! Would love to hear feedback once you try</div><br/></div></div></div></div><div id="36885861" class="c"><input type="checkbox" id="c-36885861" checked=""/><div class="controls bullet"><span class="by">johnfn</span><span>|</span><a href="#36885989">prev</a><span>|</span><a href="#36886629">next</a><span>|</span><label class="collapse" for="c-36885861">[-]</label><label class="expand" for="c-36885861">[2 more]</label></div><br/><div class="children"><div class="content">When I installed it, I immediately get this error:<p>&gt; You are using an out-of-date version of the Continue extension. Please update to the latest version.</div><br/><div id="36885943" class="c"><input type="checkbox" id="c-36885943" checked=""/><div class="controls bullet"><span class="by">sestinj</span><span>|</span><a href="#36885861">parent</a><span>|</span><a href="#36886629">next</a><span>|</span><label class="collapse" for="c-36885943">[-]</label><label class="expand" for="c-36885943">[1 more]</label></div><br/><div class="children"><div class="content">Just fixed, thanks for the heads up. Latest version should be v0.0.207.</div><br/></div></div></div></div><div id="36886629" class="c"><input type="checkbox" id="c-36886629" checked=""/><div class="controls bullet"><span class="by">mr_o47</span><span>|</span><a href="#36885861">prev</a><span>|</span><label class="collapse" for="c-36886629">[-]</label><label class="expand" for="c-36886629">[2 more]</label></div><br/><div class="children"><div class="content">What do you think about starcoder</div><br/><div id="36886715" class="c"><input type="checkbox" id="c-36886715" checked=""/><div class="controls bullet"><span class="by">sestinj</span><span>|</span><a href="#36886629">parent</a><span>|</span><label class="collapse" for="c-36886715">[-]</label><label class="expand" for="c-36886715">[1 more]</label></div><br/><div class="children"><div class="content">We&#x27;ve experimented with it quite a bit, and at one point used it as our default model for inline edits. As they discuss in section 5.1 of the paper (<a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2305.06161.pdf" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2305.06161.pdf</a>), they&#x27;ve trained on data formatted as &quot;&lt;commit_before&gt;code&lt;commit_msg&gt;text&lt;commit_after&gt;code&lt;eos&gt;&quot;, which was convenient for our use case. Unfortunately, it tended to repeat itself and for more complex edits it doesn&#x27;t match the raw ability of gpt4. I&#x27;m optimistic about open-source models though, and the data Continue lets users collect for themselves will help the open-source community get the data they need to compete.</div><br/></div></div></div></div></div></div></div></div></div></body></html>