<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1685350863662" as="style"/><link rel="stylesheet" href="styles.css?v=1685350863662"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://blog.archive.org/2023/05/29/let-us-serve-you-but-dont-bring-us-down/">Let us serve you, but don&#x27;t bring us down</a>Â <span class="domain">(<a href="https://blog.archive.org">blog.archive.org</a>)</span></div><div class="subtext"><span>_delirium</span> | <span>124 comments</span></div><br/><div><div id="36112095" class="c"><input type="checkbox" id="c-36112095" checked=""/><div class="controls bullet"><span class="by">isoos</span><span>|</span><a href="#36110689">next</a><span>|</span><label class="collapse" for="c-36112095">[-]</label><label class="expand" for="c-36112095">[1 more]</label></div><br/><div class="children"><div class="content">Proposal for web-scrapers to self-coordinate: monitor the response latencies and rate limit yourself based on that.<p>(1) Limit your load &#x2F; parallelism: do not use more than 4 threads, and if the site takes more than a few seconds to respond, use fewer.<p>(2) Limit aggregate load: after each request, sleep&#x2F;wait at least the amount that the previous request took to get served.<p>(3) If you need more than that, ask the site owners for direct channel.<p>This way if multiple crawler happen to crawl the same resource-limited site, the site may have a fighting chance.</div><br/></div></div><div id="36110689" class="c"><input type="checkbox" id="c-36110689" checked=""/><div class="controls bullet"><span class="by">pfooti</span><span>|</span><a href="#36112095">prev</a><span>|</span><a href="#36110899">next</a><span>|</span><label class="collapse" for="c-36110689">[-]</label><label class="expand" for="c-36110689">[57 more]</label></div><br/><div class="children"><div class="content">I run a system at my employer that occasionally gets scraped by malicious users. It can be used to infer the purchasability of a specific domain, which is a moderately-interesting API endpoint, since that requires talking to domain registries. For a while, nobody cared enough about it to abuse the endpoint. But then we started getting about 40 QPS of traffic. We normally get less than 1.<p>I was keeping an eye on it, because we are hard-capped at 100 QPS to our provider, beyond that and they start dropping our traffic (and it is an outside provider, bundling domain registries like verisign and stuff), which makes regular users break if their traffic gets unlucky.<p>Anyway, after a week of 40qps, they start spiking to 200+, and we pull the plug on the whole thing: now each request to our endpoint requires a recaptcha token. This is not great (more friction for legit users = more churn) but it is successful. IF they had only kept their QPS low, nobody would have cared. I wanted to send some kind of response code like, &quot;nearing quota&quot;.<p>FTR before people ask: it was quite difficult to stop this particular attack, since it worked like a DDOS, smeared across a _large_ number of ipv4 and ipv6 requesters. 50 QPS just isn&#x27;t enough quota to do stuff like reactively banning IP numbers if the attacker has millions of IPs available.</div><br/><div id="36110952" class="c"><input type="checkbox" id="c-36110952" checked=""/><div class="controls bullet"><span class="by">rapnie</span><span>|</span><a href="#36110689">parent</a><span>|</span><a href="#36111141">next</a><span>|</span><label class="collapse" for="c-36110952">[-]</label><label class="expand" for="c-36110952">[31 more]</label></div><br/><div class="children"><div class="content">Maybe mCaptcha [0] is worth a look. It applies a Proof-of-Work like algorithm (not blockchain-related) which makes it very expensive for scrapers to get data in bulk, but poses least amount of friction to individual users. The project is implemented in Rust and received NGI.eu&#x2F;NLnet funding. I don&#x27;t know its state of production-readiness, but Codeberg.org is considering using it (this choice is informed by higher respect for privacy and improved a11y compared to hCaptcha).<p>[0] <a href="https:&#x2F;&#x2F;mcaptcha.org&#x2F;" rel="nofollow">https:&#x2F;&#x2F;mcaptcha.org&#x2F;</a></div><br/><div id="36111156" class="c"><input type="checkbox" id="c-36111156" checked=""/><div class="controls bullet"><span class="by">emporas</span><span>|</span><a href="#36110689">root</a><span>|</span><a href="#36110952">parent</a><span>|</span><a href="#36111062">next</a><span>|</span><label class="collapse" for="c-36111156">[-]</label><label class="expand" for="c-36111156">[5 more]</label></div><br/><div class="children"><div class="content">In my opinion, PoW is the only reliable way, to avoid DDoS attacks. Scraping too much, too quickly is a light form of DDoS, although not intentional. PoW was invented in 2006 exactly for that purpose.<p>The genius of bitcoin (not BTC) is that it provides an organized and practical way, for PoW to be used by everyone on the planet. Some people find it strange, because there is an imaginary token created out of pure nothing which represents the PoW. It would work fine, without that imaginary token i.e. bitcoin, just by dollars of euros, but it wouldn&#x27;t be internet native. The point is always to just send a minimal PoW with every http or tcp&#x2F;ip request.</div><br/><div id="36112052" class="c"><input type="checkbox" id="c-36112052" checked=""/><div class="controls bullet"><span class="by">riedel</span><span>|</span><a href="#36110689">root</a><span>|</span><a href="#36111156">parent</a><span>|</span><a href="#36111817">next</a><span>|</span><label class="collapse" for="c-36112052">[-]</label><label class="expand" for="c-36112052">[1 more]</label></div><br/><div class="children"><div class="content">The problem to me seems that it needs to scale with the number of requests. So PoW effectively burns energy.<p>As the problem with captchas, is rather who profits from them and who could track users, it seems that with an OCR system to be protected, it is most reasonable to actually give OCR tasks to humans. IMHO this is far more sustainable and people would understand the value:  there is nothing bad in improving ML in general. Maybe someone could even define a sensible PoW task for OCR but I doubt it...</div><br/></div></div><div id="36111817" class="c"><input type="checkbox" id="c-36111817" checked=""/><div class="controls bullet"><span class="by">sph</span><span>|</span><a href="#36110689">root</a><span>|</span><a href="#36111156">parent</a><span>|</span><a href="#36112052">prev</a><span>|</span><a href="#36111964">next</a><span>|</span><label class="collapse" for="c-36111817">[-]</label><label class="expand" for="c-36111817">[2 more]</label></div><br/><div class="children"><div class="content">Proof-of-work was originally introduced by Adam Back&#x27;s hashcash, to fight email spam.<p>Bitcoin is an evolution of that idea applied to digital cash.<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;&#x2F;wiki&#x2F;Hashcash" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;&#x2F;wiki&#x2F;Hashcash</a></div><br/><div id="36111867" class="c"><input type="checkbox" id="c-36111867" checked=""/><div class="controls bullet"><span class="by">emporas</span><span>|</span><a href="#36110689">root</a><span>|</span><a href="#36111817">parent</a><span>|</span><a href="#36111964">next</a><span>|</span><label class="collapse" for="c-36111867">[-]</label><label class="expand" for="c-36111867">[1 more]</label></div><br/><div class="children"><div class="content">Yes, DDoS attacks are spam over the http protocol. Spam is spam over the imap protocol. Overwhelming a server with too many download requests, is not spam but it has the same effect. Calling the police every ten minutes because the door sounds like someone tries to break in, is spam.</div><br/></div></div></div></div><div id="36111964" class="c"><input type="checkbox" id="c-36111964" checked=""/><div class="controls bullet"><span class="by">RugnirViking</span><span>|</span><a href="#36110689">root</a><span>|</span><a href="#36111156">parent</a><span>|</span><a href="#36111817">prev</a><span>|</span><a href="#36111062">next</a><span>|</span><label class="collapse" for="c-36111964">[-]</label><label class="expand" for="c-36111964">[1 more]</label></div><br/><div class="children"><div class="content">I hate to be a pedant but I see it used wrong a lot. &quot;DDOS&quot; stands for <i>Distributed</i> denial of service, specifically indicating the traffic is coming from many sources (wide range of ip), which is what makes it so hard to defend against. Someone scraping too fast would be performing an unintentional DOS, because they probably arent scraping using a botnet (and if they were they probably do in fact intend to attack)</div><br/></div></div></div></div><div id="36111062" class="c"><input type="checkbox" id="c-36111062" checked=""/><div class="controls bullet"><span class="by">toastal</span><span>|</span><a href="#36110689">root</a><span>|</span><a href="#36110952">parent</a><span>|</span><a href="#36111156">prev</a><span>|</span><a href="#36111978">next</a><span>|</span><label class="collapse" for="c-36111062">[-]</label><label class="expand" for="c-36111062">[1 more]</label></div><br/><div class="children"><div class="content">If it doesnât involve my free labor training machine learning models like reCAPTCHA and hCAPTCHA and I can still visit sites from a non-Western IP, then itâs already an improvement.</div><br/></div></div><div id="36111978" class="c"><input type="checkbox" id="c-36111978" checked=""/><div class="controls bullet"><span class="by">RobotToaster</span><span>|</span><a href="#36110689">root</a><span>|</span><a href="#36110952">parent</a><span>|</span><a href="#36111062">prev</a><span>|</span><a href="#36111053">next</a><span>|</span><label class="collapse" for="c-36111978">[-]</label><label class="expand" for="c-36111978">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s also (the imaginatively named) powcaptcha <a href="https:&#x2F;&#x2F;git.sequentialread.com&#x2F;forest&#x2F;pow-captcha" rel="nofollow">https:&#x2F;&#x2F;git.sequentialread.com&#x2F;forest&#x2F;pow-captcha</a></div><br/></div></div><div id="36111053" class="c"><input type="checkbox" id="c-36111053" checked=""/><div class="controls bullet"><span class="by">8organicbits</span><span>|</span><a href="#36110689">root</a><span>|</span><a href="#36110952">parent</a><span>|</span><a href="#36111978">prev</a><span>|</span><a href="#36111766">next</a><span>|</span><label class="collapse" for="c-36111053">[-]</label><label class="expand" for="c-36111053">[18 more]</label></div><br/><div class="children"><div class="content">Really interesting! How efficiently does a web browser compute the PoW? I&#x27;m concerned that a bot would use an efficient GPU implementation while real users would run an inefficient JS&#x2F;webcrypto version.</div><br/><div id="36111133" class="c"><input type="checkbox" id="c-36111133" checked=""/><div class="controls bullet"><span class="by">jchw</span><span>|</span><a href="#36110689">root</a><span>|</span><a href="#36111053">parent</a><span>|</span><a href="#36111186">next</a><span>|</span><label class="collapse" for="c-36111133">[-]</label><label class="expand" for="c-36111133">[1 more]</label></div><br/><div class="children"><div class="content">I tried to implement PoW in browser for the same concept. I think it&#x27;s probably at least marginally useful, but practically you&#x27;re limited by WebCrypto I think, which outperformed anything I could find in pure JS or WASM. The disadvantage of WebCrypto is that there&#x27;s a limited set of algorithms you can use and also, understandably, calculating hashes is async, so if you want a lot of rounds, you&#x27;ll spend a lot of time jumping in and out of the event loop. It&#x27;s still probably a useful speed bump or price increase for expensive operations: what might cost a few seconds on a typical phone or desktop is probably at least enough to act as a speed bump for attackers to perform it quickly (especially combined with other measures like throttling and progressively increasing PoW difficulty for an IP.) Maybe WebGPU could change this, but I&#x27;m weary of relying on all users having a fast GPU enabled in their browser just for this use case.<p>Though thinking about it, I wonder if there is a hybrid: start with a difficulty that&#x27;s just a few seconds for CPU&#x2F;WebCrypto and ramp up quickly, but also support WebGPU where possible so that web users on abusive connections may still succeed? I am not sure though, I guess this depends on the feasibility of using WebGPU and etc.</div><br/></div></div><div id="36111186" class="c"><input type="checkbox" id="c-36111186" checked=""/><div class="controls bullet"><span class="by">emporas</span><span>|</span><a href="#36110689">root</a><span>|</span><a href="#36111053">parent</a><span>|</span><a href="#36111133">prev</a><span>|</span><a href="#36111766">next</a><span>|</span><label class="collapse" for="c-36111186">[-]</label><label class="expand" for="c-36111186">[16 more]</label></div><br/><div class="children"><div class="content">Requiring every user to compute it&#x27;s own PoW is a terrible idea. It defeats the whole purpose. One&#x27;s person expensive computation is another person&#x27;s almost free computation.<p>I commented in the past about it:<p>&quot;At first glance, yes, we can create intentionally expensive computations without relying on a blockchain, that would serve the same purpose. In reality we cannot. Special computer hardware (ASICs) could generate much cheaper PoW annotations than general purpose computers, and sell it to spammers. Blockchain economic incentives ensure that ASICs will be used by the miners first and foremost.&quot;<p><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=33533389" rel="nofollow">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=33533389</a></div><br/><div id="36112101" class="c"><input type="checkbox" id="c-36112101" checked=""/><div class="controls bullet"><span class="by">yyyk</span><span>|</span><a href="#36110689">root</a><span>|</span><a href="#36111186">parent</a><span>|</span><a href="#36111524">next</a><span>|</span><label class="collapse" for="c-36112101">[-]</label><label class="expand" for="c-36112101">[1 more]</label></div><br/><div class="children"><div class="content">&gt;One&#x27;s person expensive computation is another person&#x27;s almost free computation<p>We have pretty good guides to what&#x27;s an expensive computation to everyone. That&#x27;s how password-hashing algorithms work, much better than BitCoin does. Besides, the existence of specialized methods of compute is hardly determinative. We&#x27;re not trying to stop TLAs. It just needs to be expensive enough, and at most we&#x27;ll later update again.</div><br/></div></div><div id="36111524" class="c"><input type="checkbox" id="c-36111524" checked=""/><div class="controls bullet"><span class="by">8organicbits</span><span>|</span><a href="#36110689">root</a><span>|</span><a href="#36111186">parent</a><span>|</span><a href="#36112101">prev</a><span>|</span><a href="#36111661">next</a><span>|</span><label class="collapse" for="c-36111524">[-]</label><label class="expand" for="c-36111524">[2 more]</label></div><br/><div class="children"><div class="content">Looking cross-comment I think you&#x27;re advocating for micro-payments or micro-proof-of-burn. This is better than having every user compute their own PoW as they&#x27;d purchase a small amount of cryptocurrency from an ASIC farm, which should be cheaper&#x2F;faster&#x2F;more efficient than using their local hardware. I mostly agree with the concept, but I don&#x27;t think any such API exists yet with enough adoption to consider this a real option any time soon.<p>Right now, if I was to ask my users to do a proof of burn for $0.0001 of BTC most of them would just close my site as they don&#x27;t have any BTC. The process of setting up an account on an exchange, waiting several hours&#x2F;days for KYC checks to clear, adding a credit card, buying BTC, sending it to a browser extension, and then trying the signup again is a *significant* initial hurdle. If we were in a world where I could assume all my users already owned BTC, that&#x27;s a different story, but we haven&#x27;t seen adoption of cryptocurrency anywhere near that level. I don&#x27;t expect PoW schemes to drive that adoption either, so this seems like a poor solution today.<p>Do you happen to know if a hCaptcha&#x2F;mCaptcha-like micro-proof-of-burn tool exists already? I&#x27;d be happy to be proven wrong.<p>That brings us back to options that exist today, which includes every user computing their own PoW. Looking at mCaptcha some more, it uses a SHA256 derivative so it&#x27;s compute-hard and vulnerable to GPUs&#x2F;ASICs. The author mentions some of those concerns in an earlier thread [1]. I wonder if a different proof-of-work algorithm would be better, like a memory-hard PoW, proof-of-space, and&#x2F;or proof-of-wait. I&#x27;m skeptical of those too, unfortunately.<p>[1] <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=32341446" rel="nofollow">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=32341446</a></div><br/><div id="36111639" class="c"><input type="checkbox" id="c-36111639" checked=""/><div class="controls bullet"><span class="by">emporas</span><span>|</span><a href="#36110689">root</a><span>|</span><a href="#36111524">parent</a><span>|</span><a href="#36111661">next</a><span>|</span><label class="collapse" for="c-36111639">[-]</label><label class="expand" for="c-36111639">[1 more]</label></div><br/><div class="children"><div class="content">You are right in most of your points. Today it doesn&#x27;t exist an API for micro_proof_of_burn. Economic incentives however require a little patience because they need to work their way through the system. 0.0001 BTC is hugely expensive. A blockchain with millionth of a cent transaction, is certainly possible, and it will exist in 2-3 years approximately.<p>In my calculations, with millionth of a cent per transaction, even paying for torrent blocks (64 KB), not torrent pieces (16KB) will soon become profitable.</div><br/></div></div></div></div><div id="36111661" class="c"><input type="checkbox" id="c-36111661" checked=""/><div class="controls bullet"><span class="by">entropyie</span><span>|</span><a href="#36110689">root</a><span>|</span><a href="#36111186">parent</a><span>|</span><a href="#36111524">prev</a><span>|</span><a href="#36111519">next</a><span>|</span><label class="collapse" for="c-36111661">[-]</label><label class="expand" for="c-36111661">[3 more]</label></div><br/><div class="children"><div class="content">Security is not all or nothing.
There are many applications where adding a small bit of friction in the form of compute will stop 99.9% of abusive traffic.
Visual captchas are a plague on the internet, but so is Blockchain mania.<p>I added FriendlyCaptcha to some of my sites, and stopped 100% of abusive traffic. Open source, user friendly, accessible to people with disabilities.<p><a href="https:&#x2F;&#x2F;friendlycaptcha.com&#x2F;" rel="nofollow">https:&#x2F;&#x2F;friendlycaptcha.com&#x2F;</a><p>Most of us are not running amazon.com here.</div><br/><div id="36111763" class="c"><input type="checkbox" id="c-36111763" checked=""/><div class="controls bullet"><span class="by">emporas</span><span>|</span><a href="#36110689">root</a><span>|</span><a href="#36111661">parent</a><span>|</span><a href="#36111928">next</a><span>|</span><label class="collapse" for="c-36111763">[-]</label><label class="expand" for="c-36111763">[1 more]</label></div><br/><div class="children"><div class="content">Nice solution, if that works for your site, perfect.<p>If i may add, in case someone desires a little bit of revenue from a website, one very popular solution is to put advertisements in some places. Well some people consider that a security hole, including me. So i guess the definition of security varies, but the security mania goes on for many decades. I am one of those security maniacs, and any tool to enhance security is important, blockchain is one of them.</div><br/></div></div><div id="36111928" class="c"><input type="checkbox" id="c-36111928" checked=""/><div class="controls bullet"><span class="by">RobotToaster</span><span>|</span><a href="#36110689">root</a><span>|</span><a href="#36111661">parent</a><span>|</span><a href="#36111763">prev</a><span>|</span><a href="#36111519">next</a><span>|</span><label class="collapse" for="c-36111928">[-]</label><label class="expand" for="c-36111928">[1 more]</label></div><br/><div class="children"><div class="content">Friendlycaptcha isn&#x27;t open source, only the widget&#x2F;client is. The sever seems to be closed source.</div><br/></div></div></div></div><div id="36111519" class="c"><input type="checkbox" id="c-36111519" checked=""/><div class="controls bullet"><span class="by">Leo_Germond</span><span>|</span><a href="#36110689">root</a><span>|</span><a href="#36111186">parent</a><span>|</span><a href="#36111661">prev</a><span>|</span><a href="#36111544">next</a><span>|</span><label class="collapse" for="c-36111519">[-]</label><label class="expand" for="c-36111519">[2 more]</label></div><br/><div class="children"><div class="content">Specialized ASICs are not easy to come up with, what&#x27;s more if it&#x27;s in a tug of war you can expect those to suddenly become obsolete, rendering this approach too costly for a scrapper. Also you may have missed the part in the original link where they were using AWS to do the scrapping, so no ASICs there, and you pay by the minute, two things that would make PoW a valid countermeasure, no &quot;free computation&quot; in that setup.</div><br/><div id="36111571" class="c"><input type="checkbox" id="c-36111571" checked=""/><div class="controls bullet"><span class="by">emporas</span><span>|</span><a href="#36110689">root</a><span>|</span><a href="#36111519">parent</a><span>|</span><a href="#36111544">next</a><span>|</span><label class="collapse" for="c-36111571">[-]</label><label class="expand" for="c-36111571">[1 more]</label></div><br/><div class="children"><div class="content">As far as i know, btc and ethereum actively fight the ASICs, because they will diminish the profits of amateur miners, and will bring great centralization to the network. Which is true, and it is no problem.</div><br/></div></div></div></div><div id="36111544" class="c"><input type="checkbox" id="c-36111544" checked=""/><div class="controls bullet"><span class="by">tornato7</span><span>|</span><a href="#36110689">root</a><span>|</span><a href="#36111186">parent</a><span>|</span><a href="#36111519">prev</a><span>|</span><a href="#36111216">next</a><span>|</span><label class="collapse" for="c-36111544">[-]</label><label class="expand" for="c-36111544">[1 more]</label></div><br/><div class="children"><div class="content">Ethereum was pretty successfully ASIC-resistant. Other PoW algorithms are GPU-resistant. Even so, I doubt most spammers are sophisticated enough to create ASICs just to make cheaper requests to this guy&#x27;s service.</div><br/></div></div><div id="36111216" class="c"><input type="checkbox" id="c-36111216" checked=""/><div class="controls bullet"><span class="by">comex</span><span>|</span><a href="#36110689">root</a><span>|</span><a href="#36111186">parent</a><span>|</span><a href="#36111544">prev</a><span>|</span><a href="#36111766">next</a><span>|</span><label class="collapse" for="c-36111216">[-]</label><label class="expand" for="c-36111216">[6 more]</label></div><br/><div class="children"><div class="content">&gt; Blockchain economic incentives ensure that ASICs will be used by the miners first and foremost.<p>So instead, what, you want people to buy BTC and send small amounts of it to websites?<p>Problem is, given varying income levels across society and across the world, one person&#x27;s expensive micropayment is another person&#x27;s almost free micropayment.</div><br/><div id="36111275" class="c"><input type="checkbox" id="c-36111275" checked=""/><div class="controls bullet"><span class="by">emporas</span><span>|</span><a href="#36110689">root</a><span>|</span><a href="#36111216">parent</a><span>|</span><a href="#36111766">next</a><span>|</span><label class="collapse" for="c-36111275">[-]</label><label class="expand" for="c-36111275">[5 more]</label></div><br/><div class="children"><div class="content">In a comment down below, i made it clear i was not referring to BTC. In the internet there is no centralized registry of naming projects. There are currently three projects in which the communities call themselves bitcoin. Any one of the other two bitcoins support much smaller microtransactions than BTC.<p>Very true, that micropayments could vary on their relative cheapness across the global population. Let&#x27;s put a number, is 0.01 cent affordable by most people on the planet, for every http request?</div><br/><div id="36111381" class="c"><input type="checkbox" id="c-36111381" checked=""/><div class="controls bullet"><span class="by">elcomet</span><span>|</span><a href="#36110689">root</a><span>|</span><a href="#36111275">parent</a><span>|</span><a href="#36111766">next</a><span>|</span><label class="collapse" for="c-36111381">[-]</label><label class="expand" for="c-36111381">[4 more]</label></div><br/><div class="children"><div class="content">So maybe you should link to the one you are referring to, if there are three projects with the same name.</div><br/><div id="36111463" class="c"><input type="checkbox" id="c-36111463" checked=""/><div class="controls bullet"><span class="by">emporas</span><span>|</span><a href="#36110689">root</a><span>|</span><a href="#36111381">parent</a><span>|</span><a href="#36111766">next</a><span>|</span><label class="collapse" for="c-36111463">[-]</label><label class="expand" for="c-36111463">[3 more]</label></div><br/><div class="children"><div class="content">I am talking about Bitcoin BSV. If the purpose of blockchain was solely to provide 
PoW, then there could exist a lot of blockchains, a thousand maybe. Economic incentives ensure that the most inefficient of blockchains will be put out of the market. So some of them, like btc will soon be put out of the market, because speed and microtransactions is the two factors every blockchain competes on.<p><a href="https:&#x2F;&#x2F;www.binance.com&#x2F;en&#x2F;price&#x2F;bitcoin-sv" rel="nofollow">https:&#x2F;&#x2F;www.binance.com&#x2F;en&#x2F;price&#x2F;bitcoin-sv</a></div><br/><div id="36111545" class="c"><input type="checkbox" id="c-36111545" checked=""/><div class="controls bullet"><span class="by">8organicbits</span><span>|</span><a href="#36110689">root</a><span>|</span><a href="#36111463">parent</a><span>|</span><a href="#36111766">next</a><span>|</span><label class="collapse" for="c-36111545">[-]</label><label class="expand" for="c-36111545">[2 more]</label></div><br/><div class="children"><div class="content">&gt; This coin is not listed on Binance for trade and service.<p>An obscure coin my users cannot purchase through major exchanges is a really poor solution. Sorry, that makes no sense.</div><br/><div id="36111694" class="c"><input type="checkbox" id="c-36111694" checked=""/><div class="controls bullet"><span class="by">emporas</span><span>|</span><a href="#36110689">root</a><span>|</span><a href="#36111545">parent</a><span>|</span><a href="#36111766">next</a><span>|</span><label class="collapse" for="c-36111694">[-]</label><label class="expand" for="c-36111694">[1 more]</label></div><br/><div class="children"><div class="content">I answered on the other comment, but at that point, in case there is a blockchain, which supports a millionth of a cent transaction, then exchanges (Binance, Coinbase etc) are not so useful. If every person just needs one cent for a million http requests, then one guy in your neighbourhood or your town, or your city might  have some of it, you message him and he will send you a cent for free. You buy him a coffee, and he will give you in return, billions of http requests.<p>But again, economic incentives need to work their way into the system.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="36111766" class="c"><input type="checkbox" id="c-36111766" checked=""/><div class="controls bullet"><span class="by">ranger_danger</span><span>|</span><a href="#36110689">root</a><span>|</span><a href="#36110952">parent</a><span>|</span><a href="#36111053">prev</a><span>|</span><a href="#36111075">next</a><span>|</span><label class="collapse" for="c-36111766">[-]</label><label class="expand" for="c-36111766">[1 more]</label></div><br/><div class="children"><div class="content">There is also this proof-of-work solution <a href="https:&#x2F;&#x2F;gitgud.io&#x2F;fatchan&#x2F;haproxy-protection&#x2F;" rel="nofollow">https:&#x2F;&#x2F;gitgud.io&#x2F;fatchan&#x2F;haproxy-protection&#x2F;</a></div><br/></div></div><div id="36111075" class="c"><input type="checkbox" id="c-36111075" checked=""/><div class="controls bullet"><span class="by">hackernewds</span><span>|</span><a href="#36110689">root</a><span>|</span><a href="#36110952">parent</a><span>|</span><a href="#36111766">prev</a><span>|</span><a href="#36111665">next</a><span>|</span><label class="collapse" for="c-36111075">[-]</label><label class="expand" for="c-36111075">[2 more]</label></div><br/><div class="children"><div class="content">how does it work? perhaps it&#x27;s proprietary that the authors wouldn&#x27;t want to disclose, but I did not see anything referenced in the site. I wouldn&#x27;t plug it into mine without knowing g</div><br/><div id="36111124" class="c"><input type="checkbox" id="c-36111124" checked=""/><div class="controls bullet"><span class="by">rapnie</span><span>|</span><a href="#36110689">root</a><span>|</span><a href="#36111075">parent</a><span>|</span><a href="#36111665">next</a><span>|</span><label class="collapse" for="c-36111124">[-]</label><label class="expand" for="c-36111124">[1 more]</label></div><br/><div class="children"><div class="content">It isn&#x27;t proprietary [0]. There is a matrix channel [1] for the project to ask questions.<p>[0] <a href="https:&#x2F;&#x2F;github.com&#x2F;mCaptcha&#x2F;mCaptcha">https:&#x2F;&#x2F;github.com&#x2F;mCaptcha&#x2F;mCaptcha</a><p>[1] <a href="https:&#x2F;&#x2F;matrix.to&#x2F;#&#x2F;#mCaptcha:matrix.batsense.net" rel="nofollow">https:&#x2F;&#x2F;matrix.to&#x2F;#&#x2F;#mCaptcha:matrix.batsense.net</a></div><br/></div></div></div></div><div id="36111665" class="c"><input type="checkbox" id="c-36111665" checked=""/><div class="controls bullet"><span class="by">RockRobotRock</span><span>|</span><a href="#36110689">root</a><span>|</span><a href="#36110952">parent</a><span>|</span><a href="#36111075">prev</a><span>|</span><a href="#36111141">next</a><span>|</span><label class="collapse" for="c-36111665">[-]</label><label class="expand" for="c-36111665">[2 more]</label></div><br/><div class="children"><div class="content">hCaptcha&#x27;s accessibility model seems quite good to me: <a href="https:&#x2F;&#x2F;www.hcaptcha.com&#x2F;accessibility" rel="nofollow">https:&#x2F;&#x2F;www.hcaptcha.com&#x2F;accessibility</a></div><br/><div id="36111724" class="c"><input type="checkbox" id="c-36111724" checked=""/><div class="controls bullet"><span class="by">fsckboy</span><span>|</span><a href="#36110689">root</a><span>|</span><a href="#36111665">parent</a><span>|</span><a href="#36111141">next</a><span>|</span><label class="collapse" for="c-36111724">[-]</label><label class="expand" for="c-36111724">[1 more]</label></div><br/><div class="children"><div class="content">proof of work sounds accessible to me</div><br/></div></div></div></div></div></div><div id="36111141" class="c"><input type="checkbox" id="c-36111141" checked=""/><div class="controls bullet"><span class="by">Szpadel</span><span>|</span><a href="#36110689">parent</a><span>|</span><a href="#36110952">prev</a><span>|</span><a href="#36110697">next</a><span>|</span><label class="collapse" for="c-36111141">[-]</label><label class="expand" for="c-36111141">[2 more]</label></div><br/><div class="children"><div class="content">I had similar issue for one of our clients.
My strategy to not affect legit users was to enable mitigations if global traffic crossed some threshold.<p>eg. in your case this could mean if traffic is above eg. 75QPS then captcha is enabled, and if it&#x27;s below that it&#x27;s disabled.<p>I don&#x27;t know what tech stack you are using, but nice trick that i figured out was to abuse rate limiting to detect global traffic (doing if branch with rate limit with const as client id)</div><br/><div id="36111202" class="c"><input type="checkbox" id="c-36111202" checked=""/><div class="controls bullet"><span class="by">pfooti</span><span>|</span><a href="#36110689">root</a><span>|</span><a href="#36111141">parent</a><span>|</span><a href="#36110697">next</a><span>|</span><label class="collapse" for="c-36111202">[-]</label><label class="expand" for="c-36111202">[1 more]</label></div><br/><div class="children"><div class="content">That is more or less what I landed on myself. (Not quite, but similar reactive configs based on traffic thresholds).<p>For a while, we had to just set off pagers when global traffic exceeded a threshold and manually toggle the extra hardening, but eventually it became a lot more reactive.</div><br/></div></div></div></div><div id="36110697" class="c"><input type="checkbox" id="c-36110697" checked=""/><div class="controls bullet"><span class="by">pierat</span><span>|</span><a href="#36110689">parent</a><span>|</span><a href="#36111141">prev</a><span>|</span><a href="#36110705">next</a><span>|</span><label class="collapse" for="c-36110697">[-]</label><label class="expand" for="c-36110697">[2 more]</label></div><br/><div class="children"><div class="content">QPS seems to be &quot;queries per second&quot;.<p>I first thought it was something like &quot;quadrillion bytes per second&quot; or some newer over-the-top data measurement :)</div><br/><div id="36111298" class="c"><input type="checkbox" id="c-36111298" checked=""/><div class="controls bullet"><span class="by">vaylian</span><span>|</span><a href="#36110689">root</a><span>|</span><a href="#36110697">parent</a><span>|</span><a href="#36110705">next</a><span>|</span><label class="collapse" for="c-36111298">[-]</label><label class="expand" for="c-36111298">[1 more]</label></div><br/><div class="children"><div class="content">I haven&#x27;t heard of that abbreviation before. But there is a stub on Wikipedia if anyone cares about improving that article: <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Queries_per_second" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Queries_per_second</a></div><br/></div></div></div></div><div id="36110705" class="c"><input type="checkbox" id="c-36110705" checked=""/><div class="controls bullet"><span class="by">sbierwagen</span><span>|</span><a href="#36110689">parent</a><span>|</span><a href="#36110697">prev</a><span>|</span><a href="#36111651">next</a><span>|</span><label class="collapse" for="c-36110705">[-]</label><label class="expand" for="c-36110705">[9 more]</label></div><br/><div class="children"><div class="content">Temporarily add 500ms of latency to all ipv6 users, backoff timers for ipv4 addresses. Since there&#x27;s only 4 billion v4 addresses, it&#x27;s easy enough to just track them all in a sqlite db.</div><br/><div id="36111005" class="c"><input type="checkbox" id="c-36111005" checked=""/><div class="controls bullet"><span class="by">pfooti</span><span>|</span><a href="#36110689">root</a><span>|</span><a href="#36110705">parent</a><span>|</span><a href="#36110764">next</a><span>|</span><label class="collapse" for="c-36111005">[-]</label><label class="expand" for="c-36111005">[1 more]</label></div><br/><div class="children"><div class="content">Mostly works, but there do exist a couple of botnets that contain 1 million compromised machines. If each makes one request before hitting backoff, spread evenly throughout the day, that&#x27;s about 10 QPS alone before they use an IP number twice. But they tend to not actually level out their usage (which is a bummer - if they did they could have kept using it). Instead they hit with a lot of parallel queries all at once.<p>There&#x27;s only so much you can really do when your underlying resource is so limited. Luckily the value of the query is lower than the cost of a recaptcha solve, so the attackers moved on to some other target.<p>Ironically I could now turn off the endpoint protection (or have it responsive to traffic load), until the attackers return. I shall not go into too many details, no need to give people a map.</div><br/></div></div><div id="36110764" class="c"><input type="checkbox" id="c-36110764" checked=""/><div class="controls bullet"><span class="by">Taek</span><span>|</span><a href="#36110689">root</a><span>|</span><a href="#36110705">parent</a><span>|</span><a href="#36111005">prev</a><span>|</span><a href="#36111651">next</a><span>|</span><label class="collapse" for="c-36110764">[-]</label><label class="expand" for="c-36110764">[7 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think that works if your attacker has millions of IPs and is only using 200 per second.</div><br/><div id="36110832" class="c"><input type="checkbox" id="c-36110832" checked=""/><div class="controls bullet"><span class="by">akiselev</span><span>|</span><a href="#36110689">root</a><span>|</span><a href="#36110764">parent</a><span>|</span><a href="#36111651">next</a><span>|</span><label class="collapse" for="c-36110832">[-]</label><label class="expand" for="c-36110832">[6 more]</label></div><br/><div class="children"><div class="content">How are they getting millions of ipv4 addresses? IIUC thatâs at least the equivalent of a &#x2F;12 block. Do those shady residential proxies really operate at that scale?<p>If theyâre ipv6 address wouldnât they be safe to block across large ranges?</div><br/><div id="36110864" class="c"><input type="checkbox" id="c-36110864" checked=""/><div class="controls bullet"><span class="by">slivanes</span><span>|</span><a href="#36110689">root</a><span>|</span><a href="#36110832">parent</a><span>|</span><a href="#36110901">next</a><span>|</span><label class="collapse" for="c-36110864">[-]</label><label class="expand" for="c-36110864">[1 more]</label></div><br/><div class="children"><div class="content">My guess through compromised boxes (or some apps) that act as proxies.</div><br/></div></div><div id="36110901" class="c"><input type="checkbox" id="c-36110901" checked=""/><div class="controls bullet"><span class="by">reaperman</span><span>|</span><a href="#36110689">root</a><span>|</span><a href="#36110832">parent</a><span>|</span><a href="#36110864">prev</a><span>|</span><a href="#36111651">next</a><span>|</span><label class="collapse" for="c-36110901">[-]</label><label class="expand" for="c-36110901">[4 more]</label></div><br/><div class="children"><div class="content">It is trivially easy to get millions of IPv6âs, even spread out across a thousand ranges.<p>It is also trivially âeasyâ to get past reCAPTCHA, but it costs more. My guess is that a domain name checker tool isnât worth the cost per request to bypass reCAPTCHA (approximate 0.02 cents per session)</div><br/><div id="36110943" class="c"><input type="checkbox" id="c-36110943" checked=""/><div class="controls bullet"><span class="by">jszymborski</span><span>|</span><a href="#36110689">root</a><span>|</span><a href="#36110901">parent</a><span>|</span><a href="#36111651">next</a><span>|</span><label class="collapse" for="c-36110943">[-]</label><label class="expand" for="c-36110943">[3 more]</label></div><br/><div class="children"><div class="content">Right, but this is why the GGP&#x27;s post suggested throttling IPV6. Or at least that was my understanding.</div><br/><div id="36110980" class="c"><input type="checkbox" id="c-36110980" checked=""/><div class="controls bullet"><span class="by">reaperman</span><span>|</span><a href="#36110689">root</a><span>|</span><a href="#36110943">parent</a><span>|</span><a href="#36111651">next</a><span>|</span><label class="collapse" for="c-36110980">[-]</label><label class="expand" for="c-36110980">[2 more]</label></div><br/><div class="children"><div class="content">The 500ms latency will help a lot if tons of requests are coming in serial. But most likely they are coming in parallel.<p>Itâs hard to âthrottleâ a single isolated request from a lone IP.</div><br/><div id="36111272" class="c"><input type="checkbox" id="c-36111272" checked=""/><div class="controls bullet"><span class="by">wtallis</span><span>|</span><a href="#36110689">root</a><span>|</span><a href="#36110980">parent</a><span>|</span><a href="#36111651">next</a><span>|</span><label class="collapse" for="c-36111272">[-]</label><label class="expand" for="c-36111272">[1 more]</label></div><br/><div class="children"><div class="content">So.. <i>make</i> the requests serial. Just dump all the requests coming in over IPv6 into a queue, service that queue at a rate that&#x27;s higher than the non-bot traffic requires but still low enough to be a problem for bots that can&#x27;t self-limit to a reasonable rate. And of course, manage that queue intelligently so that you start dropping requests before you run out of RAM.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="36111651" class="c"><input type="checkbox" id="c-36111651" checked=""/><div class="controls bullet"><span class="by">Pmop</span><span>|</span><a href="#36110689">parent</a><span>|</span><a href="#36110705">prev</a><span>|</span><a href="#36110860">next</a><span>|</span><label class="collapse" for="c-36111651">[-]</label><label class="expand" for="c-36111651">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s a demand, why not supply it, and make money while you are at it?<p>This reminds me of the RMT driven botting problem in WoW (World of Warcraft). Instead of fighting the neverending game of cat and mouse against botters, Blizzard just decided to supply the long reprimanded demand for in-game currency by creating the WoW token, and they make money while they&#x27;re at.</div><br/></div></div><div id="36110860" class="c"><input type="checkbox" id="c-36110860" checked=""/><div class="controls bullet"><span class="by">jb_gericke</span><span>|</span><a href="#36110689">parent</a><span>|</span><a href="#36111651">prev</a><span>|</span><a href="#36111537">next</a><span>|</span><label class="collapse" for="c-36110860">[-]</label><label class="expand" for="c-36110860">[2 more]</label></div><br/><div class="children"><div class="content">Why not put auth on the endpoint and enforce quotas and rate limiting (an api gateway like kong could handle this for you).</div><br/><div id="36110942" class="c"><input type="checkbox" id="c-36110942" checked=""/><div class="controls bullet"><span class="by">pfooti</span><span>|</span><a href="#36110689">root</a><span>|</span><a href="#36110860">parent</a><span>|</span><a href="#36111537">next</a><span>|</span><label class="collapse" for="c-36110942">[-]</label><label class="expand" for="c-36110942">[1 more]</label></div><br/><div class="children"><div class="content">Endpoint was invoked in our signup funnel, so there was a bootstrapping problem for quota enforcement, the attackers weren&#x27;t making a whole signup, just getting to the point where the domain search ran.</div><br/></div></div></div></div><div id="36111537" class="c"><input type="checkbox" id="c-36111537" checked=""/><div class="controls bullet"><span class="by">WA</span><span>|</span><a href="#36110689">parent</a><span>|</span><a href="#36110860">prev</a><span>|</span><a href="#36111279">next</a><span>|</span><label class="collapse" for="c-36111537">[-]</label><label class="expand" for="c-36111537">[2 more]</label></div><br/><div class="children"><div class="content">I usually make it a two step process:<p><pre><code>  host example.com
</code></pre>
If this returns with an IP address, no need to talk to a registrar. Only if there is no IP address, I go with<p><pre><code>  whois example.com</code></pre></div><br/><div id="36111653" class="c"><input type="checkbox" id="c-36111653" checked=""/><div class="controls bullet"><span class="by">schoen</span><span>|</span><a href="#36110689">root</a><span>|</span><a href="#36111537">parent</a><span>|</span><a href="#36111279">next</a><span>|</span><label class="collapse" for="c-36111653">[-]</label><label class="expand" for="c-36111653">[1 more]</label></div><br/><div class="children"><div class="content">You could also do an in-between step of<p><pre><code>  host -t soa example.com
</code></pre>
which should give you domains that have any DNS record at all, not just an A record.</div><br/></div></div></div></div><div id="36111279" class="c"><input type="checkbox" id="c-36111279" checked=""/><div class="controls bullet"><span class="by">ricardo81</span><span>|</span><a href="#36110689">parent</a><span>|</span><a href="#36111537">prev</a><span>|</span><a href="#36110791">next</a><span>|</span><label class="collapse" for="c-36111279">[-]</label><label class="expand" for="c-36111279">[1 more]</label></div><br/><div class="children"><div class="content">Understandable. I&#x27;ve seen services that offer residential IP address proxies for as low as $1&#x2F;GB. FWIW the particular service in mind actually pays the IP owners who opt into it.<p>I guess your tool is asking the registries if domains are registered.</div><br/></div></div><div id="36110791" class="c"><input type="checkbox" id="c-36110791" checked=""/><div class="controls bullet"><span class="by">fragmede</span><span>|</span><a href="#36110689">parent</a><span>|</span><a href="#36111279">prev</a><span>|</span><a href="#36110905">next</a><span>|</span><label class="collapse" for="c-36110791">[-]</label><label class="expand" for="c-36110791">[1 more]</label></div><br/><div class="children"><div class="content">did you ever look inside those queries? were they the same, just repeated ad nauseam just polling in case their status had changed?</div><br/></div></div><div id="36110905" class="c"><input type="checkbox" id="c-36110905" checked=""/><div class="controls bullet"><span class="by">boulos</span><span>|</span><a href="#36110689">parent</a><span>|</span><a href="#36110791">prev</a><span>|</span><a href="#36110763">next</a><span>|</span><label class="collapse" for="c-36110905">[-]</label><label class="expand" for="c-36110905">[2 more]</label></div><br/><div class="children"><div class="content">Rate limit and return a 429?</div><br/><div id="36110955" class="c"><input type="checkbox" id="c-36110955" checked=""/><div class="controls bullet"><span class="by">pfooti</span><span>|</span><a href="#36110689">root</a><span>|</span><a href="#36110905">parent</a><span>|</span><a href="#36110763">next</a><span>|</span><label class="collapse" for="c-36110955">[-]</label><label class="expand" for="c-36110955">[1 more]</label></div><br/><div class="children"><div class="content">See sibling, but the endpoint was part of a signup funnel, so short of rearchitecting it completely to put that check after customer creation, there&#x27;s no real persistent key to rate limit on. Any one IP ended up getting rate limited to 5 requests per hour on that API, but the attack was incoming from what looked like a botnet, so it was tricky.</div><br/></div></div></div></div><div id="36110763" class="c"><input type="checkbox" id="c-36110763" checked=""/><div class="controls bullet"><span class="by">hattmall</span><span>|</span><a href="#36110689">parent</a><span>|</span><a href="#36110905">prev</a><span>|</span><a href="#36110899">next</a><span>|</span><label class="collapse" for="c-36110763">[-]</label><label class="expand" for="c-36110763">[3 more]</label></div><br/><div class="children"><div class="content">Captcha seems like overkill. Were you not able to implement a JS fingerprinting &#x2F; bot check before captcha.</div><br/><div id="36110904" class="c"><input type="checkbox" id="c-36110904" checked=""/><div class="controls bullet"><span class="by">reaperman</span><span>|</span><a href="#36110689">root</a><span>|</span><a href="#36110763">parent</a><span>|</span><a href="#36111024">next</a><span>|</span><label class="collapse" for="c-36110904">[-]</label><label class="expand" for="c-36110904">[1 more]</label></div><br/><div class="children"><div class="content">Most of the time, the new CAPTCHAs do that and then never show an actual interactive element. The interactive gimmicks are a fallback in cases of high uncertainty.<p>The webmaster doesnât need to worry about it, the anti-bot services handle who gets what difficulty of challenge. But the webmaster can specify whether theyâd like to be more or less strict&#x2F;difficult than usual.</div><br/></div></div><div id="36111024" class="c"><input type="checkbox" id="c-36111024" checked=""/><div class="controls bullet"><span class="by">pfooti</span><span>|</span><a href="#36110689">root</a><span>|</span><a href="#36110763">parent</a><span>|</span><a href="#36110904">prev</a><span>|</span><a href="#36110899">next</a><span>|</span><label class="collapse" for="c-36111024">[-]</label><label class="expand" for="c-36111024">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, &quot;recaptcha&quot; in this case is shorthand for a lot of stuff we did to harden the endpoint that ultimately represents a minor shift in balance from no friction to some friction for otherwise legitimate users, but a pretty significant drop in illegitimate traffic.<p>The main idea here is that at some point just leaving the scrape running in a way that didn&#x27;t overwhelm my backend would have resulted in me not caring enough to do that. But now they get nothing. Even if you&#x27;re borrowing bandwidth and not paying, you should be a good neighbor is all.</div><br/></div></div></div></div></div></div><div id="36110899" class="c"><input type="checkbox" id="c-36110899" checked=""/><div class="controls bullet"><span class="by">x-complexity</span><span>|</span><a href="#36110689">prev</a><span>|</span><a href="#36110948">next</a><span>|</span><label class="collapse" for="c-36110899">[-]</label><label class="expand" for="c-36110899">[14 more]</label></div><br/><div class="children"><div class="content">Unpopular opinion: Severely rate limit retrieving the files from the website &#x2F; HTTP endpoint, and loudly point towards downloading the files via torrents.<p>The torrent protocol was meant to relieve this level of server load in mind.</div><br/><div id="36110914" class="c"><input type="checkbox" id="c-36110914" checked=""/><div class="controls bullet"><span class="by">userbinator</span><span>|</span><a href="#36110899">parent</a><span>|</span><a href="#36111377">next</a><span>|</span><label class="collapse" for="c-36110914">[-]</label><label class="expand" for="c-36110914">[2 more]</label></div><br/><div class="children"><div class="content"><i>and loudly point towards downloading the files via torrents.</i><p>By &quot;loudly&quot;, perhaps actually redirect to the .torrent instead, for those who trip the rate limit?</div><br/><div id="36111003" class="c"><input type="checkbox" id="c-36111003" checked=""/><div class="controls bullet"><span class="by">x-complexity</span><span>|</span><a href="#36110899">root</a><span>|</span><a href="#36110914">parent</a><span>|</span><a href="#36111377">next</a><span>|</span><label class="collapse" for="c-36111003">[-]</label><label class="expand" for="c-36111003">[1 more]</label></div><br/><div class="children"><div class="content">...that can work.</div><br/></div></div></div></div><div id="36111377" class="c"><input type="checkbox" id="c-36111377" checked=""/><div class="controls bullet"><span class="by">maksimur</span><span>|</span><a href="#36110899">parent</a><span>|</span><a href="#36110914">prev</a><span>|</span><a href="#36111739">next</a><span>|</span><label class="collapse" for="c-36111377">[-]</label><label class="expand" for="c-36111377">[7 more]</label></div><br/><div class="children"><div class="content">Torrents have the habit of disappearing when no users keep them alive. It happened to me enough times to be wary of such solution. If there&#x27;s a way to keep them alive regardless of interest I&#x27;m all for it.</div><br/><div id="36111436" class="c"><input type="checkbox" id="c-36111436" checked=""/><div class="controls bullet"><span class="by">5e92cb50239222b</span><span>|</span><a href="#36110899">root</a><span>|</span><a href="#36111377">parent</a><span>|</span><a href="#36111527">next</a><span>|</span><label class="collapse" for="c-36111436">[-]</label><label class="expand" for="c-36111436">[1 more]</label></div><br/><div class="children"><div class="content">How is that worse than serving files via HTTP? With HTTP archive.org is the only peer that can serve files to you, with BitTorrent it will be one of the (hopefully) many peers, and will degrade to the same level of redundancy as HTTP if all other peers leave.<p>BitTorrent also supports web seeds and they don&#x27;t even really have to keep a full client running, just embed an HTTP link into the .torrent file.</div><br/></div></div><div id="36111527" class="c"><input type="checkbox" id="c-36111527" checked=""/><div class="controls bullet"><span class="by">chronogram</span><span>|</span><a href="#36110899">root</a><span>|</span><a href="#36111377">parent</a><span>|</span><a href="#36111436">prev</a><span>|</span><a href="#36111907">next</a><span>|</span><label class="collapse" for="c-36111527">[-]</label><label class="expand" for="c-36111527">[1 more]</label></div><br/><div class="children"><div class="content">Have you tried an Archive.org torrent yet? It&#x27;s backed by the servers, but has the advantages of selecting which parts of the archive you want and being verifiable and being able to have more bandwidth on popular archives. The Archive.org servers show up on the &quot;HTTP sources&quot; tab next to the &quot;Peers&quot; tab for me.</div><br/></div></div><div id="36111907" class="c"><input type="checkbox" id="c-36111907" checked=""/><div class="controls bullet"><span class="by">maksimur</span><span>|</span><a href="#36110899">root</a><span>|</span><a href="#36111377">parent</a><span>|</span><a href="#36111527">prev</a><span>|</span><a href="#36111832">next</a><span>|</span><label class="collapse" for="c-36111907">[-]</label><label class="expand" for="c-36111907">[1 more]</label></div><br/><div class="children"><div class="content">Thanks everyone for your reply. It made me reconsider my opinion. Though the downvotes are unnecessary. Use them when they&#x27;re actually necessary. Not as gate keeping or as a &quot;don&#x27;t agree&quot; button or whatever frivolous thing is passing through your mind.</div><br/></div></div><div id="36111832" class="c"><input type="checkbox" id="c-36111832" checked=""/><div class="controls bullet"><span class="by">nextaccountic</span><span>|</span><a href="#36110899">root</a><span>|</span><a href="#36111377">parent</a><span>|</span><a href="#36111907">prev</a><span>|</span><a href="#36111893">next</a><span>|</span><label class="collapse" for="c-36111832">[-]</label><label class="expand" for="c-36111832">[1 more]</label></div><br/><div class="children"><div class="content">The very same machines that serve http can also seed torrents. If those machines go offline, they also take down the http endpoint</div><br/></div></div><div id="36111893" class="c"><input type="checkbox" id="c-36111893" checked=""/><div class="controls bullet"><span class="by">shepherdjerred</span><span>|</span><a href="#36110899">root</a><span>|</span><a href="#36111377">parent</a><span>|</span><a href="#36111832">prev</a><span>|</span><a href="#36111539">next</a><span>|</span><label class="collapse" for="c-36111893">[-]</label><label class="expand" for="c-36111893">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s no worse than just relying on Arhcive.org to be sole provider</div><br/></div></div><div id="36111539" class="c"><input type="checkbox" id="c-36111539" checked=""/><div class="controls bullet"><span class="by">happywolf</span><span>|</span><a href="#36110899">root</a><span>|</span><a href="#36111377">parent</a><span>|</span><a href="#36111893">prev</a><span>|</span><a href="#36111739">next</a><span>|</span><label class="collapse" for="c-36111539">[-]</label><label class="expand" for="c-36111539">[1 more]</label></div><br/><div class="children"><div class="content">Seeding peers or machines are meant to mitigate this issue.</div><br/></div></div></div></div><div id="36111739" class="c"><input type="checkbox" id="c-36111739" checked=""/><div class="controls bullet"><span class="by">ranger_danger</span><span>|</span><a href="#36110899">parent</a><span>|</span><a href="#36111377">prev</a><span>|</span><a href="#36111032">next</a><span>|</span><label class="collapse" for="c-36111739">[-]</label><label class="expand" for="c-36111739">[1 more]</label></div><br/><div class="children"><div class="content">Depending on the type of content you download, the chances of anyone else already seeding that might actually be zero.</div><br/></div></div></div></div><div id="36110948" class="c"><input type="checkbox" id="c-36110948" checked=""/><div class="controls bullet"><span class="by">tastysandwich</span><span>|</span><a href="#36110899">prev</a><span>|</span><a href="#36111764">next</a><span>|</span><label class="collapse" for="c-36110948">[-]</label><label class="expand" for="c-36110948">[3 more]</label></div><br/><div class="children"><div class="content">I have a side project that scrapes thousands and thousands of pages of a single website.<p>So as not to piss them off (and so they don&#x27;t try to block me), my script will take about 6 hours. Between each page fetch it sleeps for a small, random amount of time. It&#x27;s been working like that for years.</div><br/><div id="36111999" class="c"><input type="checkbox" id="c-36111999" checked=""/><div class="controls bullet"><span class="by">bazmattaz</span><span>|</span><a href="#36110948">parent</a><span>|</span><a href="#36111611">next</a><span>|</span><label class="collapse" for="c-36111999">[-]</label><label class="expand" for="c-36111999">[1 more]</label></div><br/><div class="children"><div class="content">Yes, this is the way. When I was purchasing a car last year I scraped a popular used car website for cars I liked to keep track of deals. I added a random sleep in between each page so the entire script took a few hours to run.</div><br/></div></div><div id="36111611" class="c"><input type="checkbox" id="c-36111611" checked=""/><div class="controls bullet"><span class="by">Alifatisk</span><span>|</span><a href="#36110948">parent</a><span>|</span><a href="#36111999">prev</a><span>|</span><a href="#36111764">next</a><span>|</span><label class="collapse" for="c-36111611">[-]</label><label class="expand" for="c-36111611">[1 more]</label></div><br/><div class="children"><div class="content">Wish more people did like you!</div><br/></div></div></div></div><div id="36111764" class="c"><input type="checkbox" id="c-36111764" checked=""/><div class="controls bullet"><span class="by">alentred</span><span>|</span><a href="#36110948">prev</a><span>|</span><a href="#36111229">next</a><span>|</span><label class="collapse" for="c-36111764">[-]</label><label class="expand" for="c-36111764">[3 more]</label></div><br/><div class="children"><div class="content">Just yesterday there was a comment here on HN [1] about <a href="https:&#x2F;&#x2F;jsonip.com" rel="nofollow">https:&#x2F;&#x2F;jsonip.com</a>, which is essentially supported by a single person (all operational costs included) and gets abused in a somewhat similar manner. I am not even sure what to think: do the folks not understand what they do, or are they just bluntly ignorant of it?<p>[1] <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36092417" rel="nofollow">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36092417</a></div><br/><div id="36112037" class="c"><input type="checkbox" id="c-36112037" checked=""/><div class="controls bullet"><span class="by">marginalia_nu</span><span>|</span><a href="#36111764">parent</a><span>|</span><a href="#36111808">next</a><span>|</span><label class="collapse" for="c-36112037">[-]</label><label class="expand" for="c-36112037">[1 more]</label></div><br/><div class="children"><div class="content">Yeah I&#x27;m getting this shit too with Marginalia Search. I&#x27;m getting about 2-2.5M queries per day that are definitely from bots that would 100% sink my server if they somehow go through the bot mitigation. It peaks at hundreds of search queries per second. To be clear these are search queries, and search queries typically trigger disk reads of about ~10-20 Mb.<p>I get about 20,000 queries per day that may be human.</div><br/></div></div><div id="36111808" class="c"><input type="checkbox" id="c-36111808" checked=""/><div class="controls bullet"><span class="by">raverbashing</span><span>|</span><a href="#36111764">parent</a><span>|</span><a href="#36112037">prev</a><span>|</span><a href="#36111229">next</a><span>|</span><label class="collapse" for="c-36111808">[-]</label><label class="expand" for="c-36111808">[1 more]</label></div><br/><div class="children"><div class="content">&gt; o the folks not understand what they do, or are they just bluntly ignorant of it?<p>They don&#x27;t care. And yes I&#x27;ve heard stories of people &quot;finding a service&quot; that does something basic and just dumping their whole traffic onto it<p>(of course they play the victim once they&#x27;re found out)</div><br/></div></div></div></div><div id="36111229" class="c"><input type="checkbox" id="c-36111229" checked=""/><div class="controls bullet"><span class="by">yyyk</span><span>|</span><a href="#36111764">prev</a><span>|</span><a href="#36110664">next</a><span>|</span><label class="collapse" for="c-36111229">[-]</label><label class="expand" for="c-36111229">[4 more]</label></div><br/><div class="children"><div class="content">Archive.org is a bit of a special case, you need to call them repeatedly to archive a website. They do have a rate limit there, it&#x27;s pretty aggressive* to the point you could trip it by manually using the site. They must have forgotten to limit the OCR files download.<p>* If they had a better API (a simple non-synchronous API would be enough, one where we could send a list of URLs would be even better), one could have made a lot less calls.</div><br/><div id="36111675" class="c"><input type="checkbox" id="c-36111675" checked=""/><div class="controls bullet"><span class="by">Retr0id</span><span>|</span><a href="#36111229">parent</a><span>|</span><a href="#36111709">next</a><span>|</span><label class="collapse" for="c-36111675">[-]</label><label class="expand" for="c-36111675">[1 more]</label></div><br/><div class="children"><div class="content">Last time I wanted to bulk-archive a bunch of urls, I asked about it, and sent a txt file full of URLs to someone and they put it in the archival queue.</div><br/></div></div><div id="36111709" class="c"><input type="checkbox" id="c-36111709" checked=""/><div class="controls bullet"><span class="by">llui85</span><span>|</span><a href="#36111229">parent</a><span>|</span><a href="#36111675">prev</a><span>|</span><a href="#36110664">next</a><span>|</span><label class="collapse" for="c-36111709">[-]</label><label class="expand" for="c-36111709">[2 more]</label></div><br/><div class="children"><div class="content">They have a Google Sheets &quot;API&quot; which I&#x27;ve used and works reasonably well:<p><a href="https:&#x2F;&#x2F;archive.org&#x2F;services&#x2F;wayback-gsheets&#x2F;" rel="nofollow">https:&#x2F;&#x2F;archive.org&#x2F;services&#x2F;wayback-gsheets&#x2F;</a></div><br/><div id="36112040" class="c"><input type="checkbox" id="c-36112040" checked=""/><div class="controls bullet"><span class="by">krackers</span><span>|</span><a href="#36111229">root</a><span>|</span><a href="#36111709">parent</a><span>|</span><a href="#36110664">next</a><span>|</span><label class="collapse" for="c-36112040">[-]</label><label class="expand" for="c-36112040">[1 more]</label></div><br/><div class="children"><div class="content">This has been broken for the past month (just stuck on waiting for workers for several days), did they fix it?</div><br/></div></div></div></div></div></div><div id="36110664" class="c"><input type="checkbox" id="c-36110664" checked=""/><div class="controls bullet"><span class="by">radq</span><span>|</span><a href="#36111229">prev</a><span>|</span><a href="#36111244">next</a><span>|</span><label class="collapse" for="c-36110664">[-]</label><label class="expand" for="c-36110664">[8 more]</label></div><br/><div class="children"><div class="content">Sounds like they don&#x27;t have rate limiting implemented? That seems odd, and it&#x27;s also surprising it isn&#x27;t talked about in the post.</div><br/><div id="36110699" class="c"><input type="checkbox" id="c-36110699" checked=""/><div class="controls bullet"><span class="by">p-e-w</span><span>|</span><a href="#36110664">parent</a><span>|</span><a href="#36111091">next</a><span>|</span><label class="collapse" for="c-36110699">[-]</label><label class="expand" for="c-36110699">[5 more]</label></div><br/><div class="children"><div class="content">Indeed. <i>Tens of thousands of requests per second</i> from just 64 hosts? So they allow individual hosts to make hundreds of requests per second, sustained? That sounds crazy. Even for a burst limit hundreds per second would be extremely high.</div><br/><div id="36110898" class="c"><input type="checkbox" id="c-36110898" checked=""/><div class="controls bullet"><span class="by">akiselev</span><span>|</span><a href="#36110664">root</a><span>|</span><a href="#36110699">parent</a><span>|</span><a href="#36111091">next</a><span>|</span><label class="collapse" for="c-36110898">[-]</label><label class="expand" for="c-36110898">[4 more]</label></div><br/><div class="children"><div class="content">Archive.org is a core utility for the web to the point where Wikipedia and many other sites would collapse without it in the sense that many if not most of their outbound links would be dead forever. Iâm pretty sure it would even impact the US justice system [1].<p>Obviously judges arenât going to have to worry about reasonable rate limits but if these DDoSes are rare, Iâd much rather they dealt with them on a case by case basis. Without some complex dynamic rate limit that scales based on available compute and demand, rate limiting would be a blunt solution that will necessarily generate false positives.<p>[1] <a href="https:&#x2F;&#x2F;www.theregister.com&#x2F;2018&#x2F;09&#x2F;04&#x2F;wayback_machine_legit&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.theregister.com&#x2F;2018&#x2F;09&#x2F;04&#x2F;wayback_machine_legit...</a></div><br/><div id="36111131" class="c"><input type="checkbox" id="c-36111131" checked=""/><div class="controls bullet"><span class="by">p-e-w</span><span>|</span><a href="#36110664">root</a><span>|</span><a href="#36110898">parent</a><span>|</span><a href="#36110961">next</a><span>|</span><label class="collapse" for="c-36111131">[-]</label><label class="expand" for="c-36111131">[2 more]</label></div><br/><div class="children"><div class="content">Rate limiting is (usually) done on a <i>per-host</i> basis. The only users who would be adversely affected are those who perform hundreds of requests per second <i>from a single system.</i><p>Virtually every major website has per-host inbound request limits. This is completely standard practice and Archive.org is the odd one here.<p>And DDoS isn&#x27;t the only concern. Legitimate users that run poorly written Python scripts that make insane numbers of requests can hog server resources, and rate limits with appropriate error messages linking to resources documenting efficient access patterns can improve the experience for everyone, and drastically cut costs for the service operators.</div><br/><div id="36111285" class="c"><input type="checkbox" id="c-36111285" checked=""/><div class="controls bullet"><span class="by">phkx</span><span>|</span><a href="#36110664">root</a><span>|</span><a href="#36111131">parent</a><span>|</span><a href="#36110961">next</a><span>|</span><label class="collapse" for="c-36111285">[-]</label><label class="expand" for="c-36111285">[1 more]</label></div><br/><div class="children"><div class="content">Itâs rather per public IP, such that e.g. behind a corporate proxy you may experience rate limiting even for regular use, just because youâre sharing a few IP addresses with a large number of users. Better hope that you get an increased quota for your external IPs in that case.</div><br/></div></div></div></div><div id="36110961" class="c"><input type="checkbox" id="c-36110961" checked=""/><div class="controls bullet"><span class="by">Defletter</span><span>|</span><a href="#36110664">root</a><span>|</span><a href="#36110898">parent</a><span>|</span><a href="#36111131">prev</a><span>|</span><a href="#36111091">next</a><span>|</span><label class="collapse" for="c-36110961">[-]</label><label class="expand" for="c-36110961">[1 more]</label></div><br/><div class="children"><div class="content">Probably not just the US justice system. I also guess that academia would take a hit too. Not every citation is of a published paper.</div><br/></div></div></div></div></div></div><div id="36111088" class="c"><input type="checkbox" id="c-36111088" checked=""/><div class="controls bullet"><span class="by">hackernewds</span><span>|</span><a href="#36110664">parent</a><span>|</span><a href="#36111091">prev</a><span>|</span><a href="#36111244">next</a><span>|</span><label class="collapse" for="c-36111088">[-]</label><label class="expand" for="c-36111088">[1 more]</label></div><br/><div class="children"><div class="content">Precisely. What kinds of legitimate processes would require this kind of utility from Archive.org?</div><br/></div></div></div></div><div id="36111244" class="c"><input type="checkbox" id="c-36111244" checked=""/><div class="controls bullet"><span class="by">Roark66</span><span>|</span><a href="#36110664">prev</a><span>|</span><a href="#36111818">next</a><span>|</span><label class="collapse" for="c-36111244">[-]</label><label class="expand" for="c-36111244">[4 more]</label></div><br/><div class="children"><div class="content">I just wonder, is archive.org getting any government grant money? If they aren&#x27;t they should. And I&#x27;m not even talking about just the US. All sorts of countries (US, UK, Germany - to name the few) and international organisations like EU pour hundreds of millions into &quot;cultural projects&quot; of very questionable value.<p>How about they actually fund something really worthy of preservation? Of course it is archive.org role to reach out first. For example EU could fund an archive.org mirror in the EU (with certain throughout etc).<p>Of course opponents of public&#x2F;government funding have a very good point in that many organisations when they get public money, they find a way to burn through all of it in a lot less efficient way. This can be mitigated by attaching concrete conditions to the grants. One example is a mirror in a specific location.</div><br/><div id="36111352" class="c"><input type="checkbox" id="c-36111352" checked=""/><div class="controls bullet"><span class="by">brylie</span><span>|</span><a href="#36111244">parent</a><span>|</span><a href="#36111824">next</a><span>|</span><label class="collapse" for="c-36111352">[-]</label><label class="expand" for="c-36111352">[2 more]</label></div><br/><div class="children"><div class="content">The Internet Archive lists some of their major donors on the About IA page:<p><a href="https:&#x2F;&#x2F;archive.org&#x2F;about&#x2F;" rel="nofollow">https:&#x2F;&#x2F;archive.org&#x2F;about&#x2F;</a><p>Since they are a U.S. 501(c)(3), they also publish annual reports, which can be downloaded e.g., at the ProPublica Nonprofit Explorer<p><a href="https:&#x2F;&#x2F;projects.propublica.org&#x2F;nonprofits&#x2F;organizations&#x2F;943242767" rel="nofollow">https:&#x2F;&#x2F;projects.propublica.org&#x2F;nonprofits&#x2F;organizations&#x2F;943...</a></div><br/><div id="36111503" class="c"><input type="checkbox" id="c-36111503" checked=""/><div class="controls bullet"><span class="by">tkgally</span><span>|</span><a href="#36111244">root</a><span>|</span><a href="#36111352">parent</a><span>|</span><a href="#36111824">next</a><span>|</span><label class="collapse" for="c-36111503">[-]</label><label class="expand" for="c-36111503">[1 more]</label></div><br/><div class="children"><div class="content">The Internet Archive has many smaller donors, too. I use the Archive frequently for a variety of purposes and derive immense value from it, so I donate to it every year.</div><br/></div></div></div></div><div id="36111824" class="c"><input type="checkbox" id="c-36111824" checked=""/><div class="controls bullet"><span class="by">mellosouls</span><span>|</span><a href="#36111244">parent</a><span>|</span><a href="#36111352">prev</a><span>|</span><a href="#36111818">next</a><span>|</span><label class="collapse" for="c-36111824">[-]</label><label class="expand" for="c-36111824">[1 more]</label></div><br/><div class="children"><div class="content">There are various underfunded digital archives in the EU and elsewhere that have legal duties to preserve online content relating to their specific countries.<p>They may be &quot;of very questionable value&quot; to you but your solution to remove funding from them to channel it to a much wealthier organisation in a wealthier country is neither ethical, legal or practical.</div><br/></div></div></div></div><div id="36111818" class="c"><input type="checkbox" id="c-36111818" checked=""/><div class="controls bullet"><span class="by">MeteorMarc</span><span>|</span><a href="#36111244">prev</a><span>|</span><a href="#36111673">next</a><span>|</span><label class="collapse" for="c-36111818">[-]</label><label class="expand" for="c-36111818">[1 more]</label></div><br/><div class="children"><div class="content">What an incredibly well versed notice from archive.org! Clear, no assumptions, no irony, no accusations, but only reaching out as they request from us.</div><br/></div></div><div id="36111673" class="c"><input type="checkbox" id="c-36111673" checked=""/><div class="controls bullet"><span class="by">buro9</span><span>|</span><a href="#36111818">prev</a><span>|</span><a href="#36111056">next</a><span>|</span><label class="collapse" for="c-36111673">[-]</label><label class="expand" for="c-36111673">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m waiting for Cloudflare to open source their web server as promised.<p>But failing that I&#x27;m likely to implement a web proxy that utilizes the wirefilter library that is already open sourced by Cloudflare (but no longer updated).<p>The tools to stop these attacks are reasonably trivial.<p>Most of the art of stopping them is observability.<p>When you can see every dimension of a TCP&#x2F;UDP connection, the TLS handshake, the HTTP communication... Then the dimension by which an attack is being conducted is glaringly obvious.<p>Once you have the very obvious correlation, then you only need a blunt instrument of a tool that can block&#x2F;deny&#x2F;nullroute the attack.<p>What&#x27;s hard isn&#x27;t the block rules, What&#x27;s hard is instrumenting enough observability to see the obvious correlation of an attack.<p>Even on my personal nginx a single request logs about 20 things. But there are literally hundreds of properties one can log if you have access to the entirety of the stack, and if you have access to log on it, then you have the ability to carry that context to a point in the code where you can block it.<p>Also, 10k qps really isn&#x27;t a lot. So this should be treated as a warning sign, this attack was low volume even for amateur booter services.</div><br/></div></div><div id="36111056" class="c"><input type="checkbox" id="c-36111056" checked=""/><div class="controls bullet"><span class="by">porbelm</span><span>|</span><a href="#36111673">prev</a><span>|</span><a href="#36111892">next</a><span>|</span><label class="collapse" for="c-36111056">[-]</label><label class="expand" for="c-36111056">[2 more]</label></div><br/><div class="children"><div class="content">OCRs of PD material? Is someone about to train a new AI model, perhaps? I&#x27;d think the Archive would be happy to arrange for receiving hard drives, filling them up, and sending them back. They seem like a very helpful bunch.</div><br/><div id="36111113" class="c"><input type="checkbox" id="c-36111113" checked=""/><div class="controls bullet"><span class="by">wly_cdgr</span><span>|</span><a href="#36111056">parent</a><span>|</span><a href="#36111892">next</a><span>|</span><label class="collapse" for="c-36111113">[-]</label><label class="expand" for="c-36111113">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s ChatGPT itself....learning....evolving...:)</div><br/></div></div></div></div><div id="36111892" class="c"><input type="checkbox" id="c-36111892" checked=""/><div class="controls bullet"><span class="by">mellosouls</span><span>|</span><a href="#36111056">prev</a><span>|</span><a href="#36110799">next</a><span>|</span><label class="collapse" for="c-36111892">[-]</label><label class="expand" for="c-36111892">[1 more]</label></div><br/><div class="children"><div class="content">We&#x27;ve had various web-crawling businesses promoting their crawl-etiquette-busting technologies to approval and acclaim on HN; undermining of services for the public good like this is exactly the end result we are supporting when we do that.</div><br/></div></div><div id="36110799" class="c"><input type="checkbox" id="c-36110799" checked=""/><div class="controls bullet"><span class="by">copperx</span><span>|</span><a href="#36111892">prev</a><span>|</span><a href="#36110997">next</a><span>|</span><label class="collapse" for="c-36110799">[-]</label><label class="expand" for="c-36110799">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not an expert in networking, but isn&#x27;t this scenario Cloudflare&#x27;s bread and butter? Is there any reason to not outsource this problem?</div><br/><div id="36110985" class="c"><input type="checkbox" id="c-36110985" checked=""/><div class="controls bullet"><span class="by">crote</span><span>|</span><a href="#36110799">parent</a><span>|</span><a href="#36110997">next</a><span>|</span><label class="collapse" for="c-36110985">[-]</label><label class="expand" for="c-36110985">[1 more]</label></div><br/><div class="children"><div class="content">It depends. A CDN-like approach wouldn&#x27;t really work because all requests are different and legit, so plain old caching isn&#x27;t going to cut it.<p>On the other hand, Cloudflare has quite some experience with DDoS protection, so they definitely have the right infrastructure in place to stop this kind of abuse. What is the bill going to be, though?</div><br/></div></div></div></div><div id="36110997" class="c"><input type="checkbox" id="c-36110997" checked=""/><div class="controls bullet"><span class="by">markus_zhang</span><span>|</span><a href="#36110799">prev</a><span>|</span><a href="#36111813">next</a><span>|</span><label class="collapse" for="c-36110997">[-]</label><label class="expand" for="c-36110997">[1 more]</label></div><br/><div class="children"><div class="content">Has anyone&#x2F;any company asked you to buy their anti-DdoS service recent days&#x2F;weeks?</div><br/></div></div><div id="36111813" class="c"><input type="checkbox" id="c-36111813" checked=""/><div class="controls bullet"><span class="by">netfortius</span><span>|</span><a href="#36110997">prev</a><span>|</span><a href="#36110972">next</a><span>|</span><label class="collapse" for="c-36111813">[-]</label><label class="expand" for="c-36111813">[1 more]</label></div><br/><div class="children"><div class="content">I would [have] reach[ed] to AWS techies. The services of archive.org are known and important enough for the AWS folks to chase down the sources and&#x2F;or initiate some action against the perpetrators, malicious or not as they might be.</div><br/></div></div><div id="36110972" class="c"><input type="checkbox" id="c-36110972" checked=""/><div class="controls bullet"><span class="by">blitzar</span><span>|</span><a href="#36111813">prev</a><span>|</span><a href="#36111153">next</a><span>|</span><label class="collapse" for="c-36110972">[-]</label><label class="expand" for="c-36110972">[1 more]</label></div><br/><div class="children"><div class="content">Someone somewhere must be training a new &quot;Open&quot; Ai</div><br/></div></div><div id="36110756" class="c"><input type="checkbox" id="c-36110756" checked=""/><div class="controls bullet"><span class="by">behnamoh</span><span>|</span><a href="#36111153">prev</a><span>|</span><a href="#36110849">next</a><span>|</span><label class="collapse" for="c-36110756">[-]</label><label class="expand" for="c-36110756">[1 more]</label></div><br/><div class="children"><div class="content">Pretty sure it was an attack, not legitimate bulk use of the website.</div><br/></div></div><div id="36110849" class="c"><input type="checkbox" id="c-36110849" checked=""/><div class="controls bullet"><span class="by">fbdab103</span><span>|</span><a href="#36110756">prev</a><span>|</span><a href="#36110718">next</a><span>|</span><label class="collapse" for="c-36110849">[-]</label><label class="expand" for="c-36110849">[1 more]</label></div><br/><div class="children"><div class="content">Huh, meanwhile, I recently wanted to grab ~200 pages from the archive where I put a 1-2 minute delay between the requests and had a bunch of repeated failures.</div><br/></div></div><div id="36110718" class="c"><input type="checkbox" id="c-36110718" checked=""/><div class="controls bullet"><span class="by">mholt</span><span>|</span><a href="#36110849">prev</a><span>|</span><a href="#36110874">next</a><span>|</span><label class="collapse" for="c-36110718">[-]</label><label class="expand" for="c-36110718">[1 more]</label></div><br/><div class="children"><div class="content">&gt; &quot;Error establishing database connection&quot;<p>Well, that&#x27;s ironic.<p>... Anyone have an archive.org link of the page?</div><br/></div></div><div id="36110874" class="c"><input type="checkbox" id="c-36110874" checked=""/><div class="controls bullet"><span class="by">fragmede</span><span>|</span><a href="#36110718">prev</a><span>|</span><a href="#36111419">next</a><span>|</span><label class="collapse" for="c-36110874">[-]</label><label class="expand" for="c-36110874">[3 more]</label></div><br/><div class="children"><div class="content">This is a job for HTTP 429!</div><br/><div id="36111238" class="c"><input type="checkbox" id="c-36111238" checked=""/><div class="controls bullet"><span class="by">toyg</span><span>|</span><a href="#36110874">parent</a><span>|</span><a href="#36110958">next</a><span>|</span><label class="collapse" for="c-36111238">[-]</label><label class="expand" for="c-36111238">[1 more]</label></div><br/><div class="children"><div class="content">I recently fought and won 429... On a website ran by the very company I work for. They use a vendor for certain services, and such vendor sells a (terrible) API access for bulk operations, so I whipped out Selenium instead; which meant I, the site &quot;admin&quot;, was being throttled with 429. A few pauses here and there, and all was well.</div><br/></div></div><div id="36110958" class="c"><input type="checkbox" id="c-36110958" checked=""/><div class="controls bullet"><span class="by">jszymborski</span><span>|</span><a href="#36110874">parent</a><span>|</span><a href="#36111238">prev</a><span>|</span><a href="#36111419">next</a><span>|</span><label class="collapse" for="c-36110958">[-]</label><label class="expand" for="c-36110958">[1 more]</label></div><br/><div class="children"><div class="content">Or 420 :P</div><br/></div></div></div></div><div id="36111419" class="c"><input type="checkbox" id="c-36111419" checked=""/><div class="controls bullet"><span class="by">simonmales</span><span>|</span><a href="#36110874">prev</a><span>|</span><a href="#36111227">next</a><span>|</span><label class="collapse" for="c-36111419">[-]</label><label class="expand" for="c-36111419">[1 more]</label></div><br/><div class="children"><div class="content">We have a service that was often crawled by bots on cloud providers, luckily we can block AWS IPs without to much hassle.</div><br/></div></div><div id="36111227" class="c"><input type="checkbox" id="c-36111227" checked=""/><div class="controls bullet"><span class="by">Jamie9912</span><span>|</span><a href="#36111419">prev</a><span>|</span><a href="#36110841">next</a><span>|</span><label class="collapse" for="c-36111227">[-]</label><label class="expand" for="c-36111227">[1 more]</label></div><br/><div class="children"><div class="content">How could they not have rate limiting?</div><br/></div></div><div id="36110665" class="c"><input type="checkbox" id="c-36110665" checked=""/><div class="controls bullet"><span class="by">TekMol</span><span>|</span><a href="#36110841">prev</a><span>|</span><label class="collapse" for="c-36110665">[-]</label><label class="expand" for="c-36110665">[9 more]</label></div><br/><div class="children"><div class="content">What is the legal ground for archive.org to copy websites? Shouldn&#x27;t copyright forbid that?<p>They don&#x27;t even respect robots.txt. So content creators can&#x27;t even opt out of that. Not that copyright would have copyright holders having to opt out of copying in the first place.<p>How have they not been sued out of existance yet?</div><br/><div id="36111950" class="c"><input type="checkbox" id="c-36111950" checked=""/><div class="controls bullet"><span class="by">tannhaeuser</span><span>|</span><a href="#36110665">parent</a><span>|</span><a href="#36110837">next</a><span>|</span><label class="collapse" for="c-36111950">[-]</label><label class="expand" for="c-36111950">[1 more]</label></div><br/><div class="children"><div class="content">A question indeed that has to be answered before everything else. We can&#x27;t criticize eg search engines for &quot;previewing&quot; content on search result pages and for sending you to copycat sites with the most ads and ignore gross content copying at the same time. We also have these &quot;helpful&quot; insertions of links to archive.ph copies here when the original story is paywalled and sometimes even just ad-ridden - to copied content on archive.ph with third-party ads which I find at least unethical.<p>That said, personally I <i>do</i> use  Wayback machine about once a month for genuine search of historic content.</div><br/></div></div><div id="36110837" class="c"><input type="checkbox" id="c-36110837" checked=""/><div class="controls bullet"><span class="by">crazydoggers</span><span>|</span><a href="#36110665">parent</a><span>|</span><a href="#36111950">prev</a><span>|</span><a href="#36110674">next</a><span>|</span><label class="collapse" for="c-36110837">[-]</label><label class="expand" for="c-36110837">[2 more]</label></div><br/><div class="children"><div class="content">Same way a library does. The information is made available to anyone who wants it, the copyrights are maintained intact, and they donât attempt to profit from the material.<p>Copyright law specifically allows for libraries and archives to make copies of copyrighted material.<p>Without such laws, without libraries, knowledge could not be guaranteed to be shared freely among the public, resulting in ever growing knowledge and education gaps between those with means and those without.<p>Edit: Since you asked for the legal ground, here it is specifically:<p><a href="https:&#x2F;&#x2F;www.law.cornell.edu&#x2F;uscode&#x2F;text&#x2F;17&#x2F;108" rel="nofollow">https:&#x2F;&#x2F;www.law.cornell.edu&#x2F;uscode&#x2F;text&#x2F;17&#x2F;108</a><p>And hereâs is further discussion by the copyright office itself:<p><a href="https:&#x2F;&#x2F;www.copyright.gov&#x2F;policy&#x2F;section108&#x2F;discussion-document.pdf" rel="nofollow">https:&#x2F;&#x2F;www.copyright.gov&#x2F;policy&#x2F;section108&#x2F;discussion-docum...</a><p>Congress and the copyright office have made it an important part of copyright law to protect archival, library and fair use doctrine.</div><br/><div id="36111649" class="c"><input type="checkbox" id="c-36111649" checked=""/><div class="controls bullet"><span class="by">crazydoggers</span><span>|</span><a href="#36110665">root</a><span>|</span><a href="#36110837">parent</a><span>|</span><a href="#36110674">next</a><span>|</span><label class="collapse" for="c-36111649">[-]</label><label class="expand" for="c-36111649">[1 more]</label></div><br/><div class="children"><div class="content">I just wanted to add, while I donât agree with the assessment that copyright holders need to be protected from something like archive.org, i donât think the parent comment deserved to be flagged, so I vouched for it. I think the question was raised in sincerity, and I think it offers a point of discussion for those not familiar with the issues.<p>I donât think itâs helpful to flag things people disagree with, as long as they donât attempt to spread misinformation, or trolling etc. The parent phrased the topic as a question, meaning I believe they were open to understanding.<p>I also think itâs relative to the topic posted, as weâre talking about either an attack on archive.org, or a massive recopying of archive data by an unknown.<p>Talking to people with opposing views is important. Letâs not just shut people down if we donât agree with something, especially when someone is asking a question.</div><br/></div></div></div></div><div id="36110674" class="c"><input type="checkbox" id="c-36110674" checked=""/><div class="controls bullet"><span class="by">ddtaylor</span><span>|</span><a href="#36110665">parent</a><span>|</span><a href="#36110837">prev</a><span>|</span><a href="#36110999">next</a><span>|</span><label class="collapse" for="c-36110674">[-]</label><label class="expand" for="c-36110674">[3 more]</label></div><br/><div class="children"><div class="content">Details?</div><br/><div id="36110696" class="c"><input type="checkbox" id="c-36110696" checked=""/><div class="controls bullet"><span class="by">shlant</span><span>|</span><a href="#36110665">root</a><span>|</span><a href="#36110674">parent</a><span>|</span><a href="#36110999">next</a><span>|</span><label class="collapse" for="c-36110696">[-]</label><label class="expand" for="c-36110696">[2 more]</label></div><br/><div class="children"><div class="content">found this: <a href="https:&#x2F;&#x2F;blog.archive.org&#x2F;2017&#x2F;04&#x2F;17&#x2F;robots-txt-meant-for-search-engines-dont-work-well-for-web-archives&#x2F;" rel="nofollow">https:&#x2F;&#x2F;blog.archive.org&#x2F;2017&#x2F;04&#x2F;17&#x2F;robots-txt-meant-for-sea...</a></div><br/><div id="36110740" class="c"><input type="checkbox" id="c-36110740" checked=""/><div class="controls bullet"><span class="by">avarun</span><span>|</span><a href="#36110665">root</a><span>|</span><a href="#36110696">parent</a><span>|</span><a href="#36110999">next</a><span>|</span><label class="collapse" for="c-36110740">[-]</label><label class="expand" for="c-36110740">[1 more]</label></div><br/><div class="children"><div class="content">Seems reasonable</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></body></html>