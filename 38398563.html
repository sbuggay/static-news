<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1700816457832" as="style"/><link rel="stylesheet" href="styles.css?v=1700816457832"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/socketteer/loom">Experimental tree-based writing interface for GPT-3</a>Â <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>pyinstallwoes</span> | <span>31 comments</span></div><br/><div><div id="38400959" class="c"><input type="checkbox" id="c-38400959" checked=""/><div class="controls bullet"><span class="by">parafactual</span><span>|</span><a href="#38401723">next</a><span>|</span><label class="collapse" for="c-38400959">[-]</label><label class="expand" for="c-38400959">[4 more]</label></div><br/><div class="children"><div class="content">I maintain a less featureful but easier to use and less janky Loom implementation as an Obsidian plugin: <a href="https:&#x2F;&#x2F;github.com&#x2F;cosmicoptima&#x2F;loom">https:&#x2F;&#x2F;github.com&#x2F;cosmicoptima&#x2F;loom</a><p>(Why Obsidian? Because then I don&#x27;t have to write a text editor from scratch, and because one can then combine it with other plugins. Also because I intended for this implementation to work on mobile, but getting the UX right for that is annoying so it isn&#x27;t supported right now.)<p>davinci-002 is a good publicly available model to start with. Weaving takes practice if you want something very specific.</div><br/><div id="38400982" class="c"><input type="checkbox" id="c-38400982" checked=""/><div class="controls bullet"><span class="by">pyinstallwoes</span><span>|</span><a href="#38400959">parent</a><span>|</span><a href="#38401723">next</a><span>|</span><label class="collapse" for="c-38400982">[-]</label><label class="expand" for="c-38400982">[3 more]</label></div><br/><div class="children"><div class="content">How do you use it in your workflow?</div><br/><div id="38401010" class="c"><input type="checkbox" id="c-38401010" checked=""/><div class="controls bullet"><span class="by">parafactual</span><span>|</span><a href="#38400959">root</a><span>|</span><a href="#38400982">parent</a><span>|</span><a href="#38401723">next</a><span>|</span><label class="collapse" for="c-38401010">[-]</label><label class="expand" for="c-38401010">[2 more]</label></div><br/><div class="children"><div class="content">i create new notes, put interesting and shiny texts in them, and weave from them for fun and intellectual or aesthetic inspiration</div><br/><div id="38401138" class="c"><input type="checkbox" id="c-38401138" checked=""/><div class="controls bullet"><span class="by">pyinstallwoes</span><span>|</span><a href="#38400959">root</a><span>|</span><a href="#38401010">parent</a><span>|</span><a href="#38401723">next</a><span>|</span><label class="collapse" for="c-38401138">[-]</label><label class="expand" for="c-38401138">[1 more]</label></div><br/><div class="children"><div class="content">How do you handle the branches, variations? Like the leaf nodes? Do you use it to compare possible paths then when you decide you prune them?</div><br/></div></div></div></div></div></div></div></div><div id="38401723" class="c"><input type="checkbox" id="c-38401723" checked=""/><div class="controls bullet"><span class="by">imhoguy</span><span>|</span><a href="#38400959">prev</a><span>|</span><a href="#38398815">next</a><span>|</span><label class="collapse" for="c-38401723">[-]</label><label class="expand" for="c-38401723">[1 more]</label></div><br/><div class="children"><div class="content">Does it do or anyone knows some writing tool where the text can be anonymized before it is sent to GPT? I don&#x27;t want to share sensitive data, like PII etc.<p>I could just manually specify words to be send to GPT as placeholders, &quot;John Doe&quot; -&gt; &quot;JD&quot;. Then on every response the placeholders would be resolved  with the original text just for visual purposes &quot;JD&quot; -&gt; &quot;John Doe&quot;.<p>I know it can be made with a little programming and OpenAI API, but maybe no need to reinvent.</div><br/></div></div><div id="38398815" class="c"><input type="checkbox" id="c-38398815" checked=""/><div class="controls bullet"><span class="by">photoGrant</span><span>|</span><a href="#38401723">prev</a><span>|</span><a href="#38401180">next</a><span>|</span><label class="collapse" for="c-38398815">[-]</label><label class="expand" for="c-38398815">[10 more]</label></div><br/><div class="children"><div class="content">The multiverse visualisation was really cool! This whole tool feels like it&#x27;s designed for a writer from the future.<p>link for curious: <a href="https:&#x2F;&#x2F;generative.ink&#x2F;meta&#x2F;block-multiverse&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;generative.ink&#x2F;meta&#x2F;block-multiverse&#x2F;</a></div><br/><div id="38399854" class="c"><input type="checkbox" id="c-38399854" checked=""/><div class="controls bullet"><span class="by">mathiasgredal</span><span>|</span><a href="#38398815">parent</a><span>|</span><a href="#38398942">next</a><span>|</span><label class="collapse" for="c-38399854">[-]</label><label class="expand" for="c-38399854">[8 more]</label></div><br/><div class="children"><div class="content">I have always been bothered with the multinomial layer that picks the next token. It seems like you should be able to stick a classifier in there to detect if the probabilities align with a satisfactory answer and whether the model is unsure of the response. If that is the case, then it should branch out to a bigger model which would compute that single token that it is unsure about, and from that the rest of the response is obvious for the smaller model.<p>This way you could combine e.g. a 7B parameter model with a 70B parameter model, and get the quality of the larger model while most of the time you are only running the small model.<p>Edit: You could also store the full probabilities for each token, and then the classifier could detect if it had gone down a bad path, and then unwind the tokens and pick a different path.</div><br/><div id="38399868" class="c"><input type="checkbox" id="c-38399868" checked=""/><div class="controls bullet"><span class="by">jacquesm</span><span>|</span><a href="#38398815">root</a><span>|</span><a href="#38399854">parent</a><span>|</span><a href="#38400978">next</a><span>|</span><label class="collapse" for="c-38399868">[-]</label><label class="expand" for="c-38399868">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s reminiscent of a caching scheme, you could probably layer that down to even smaller and up to even larger models for increased performance and accuracy.<p>Better yet: have many smaller models that can when confused call upon larger models and the larger models could then pick the most appropriate smaller &#x27;expert&#x27; model or, alternatively themselves escalate. Sort of a supervisor tree for language models.</div><br/></div></div><div id="38400978" class="c"><input type="checkbox" id="c-38400978" checked=""/><div class="controls bullet"><span class="by">soulofmischief</span><span>|</span><a href="#38398815">root</a><span>|</span><a href="#38399854">parent</a><span>|</span><a href="#38399868">prev</a><span>|</span><a href="#38400047">next</a><span>|</span><label class="collapse" for="c-38400978">[-]</label><label class="expand" for="c-38400978">[1 more]</label></div><br/><div class="children"><div class="content">Contextual loading of a bigger model would incur a lot of latency. In this case it might be a good idea to farm out the request to a non-local model. Could be a good avenue for a hybrid local &amp; remote completion system.</div><br/></div></div><div id="38400047" class="c"><input type="checkbox" id="c-38400047" checked=""/><div class="controls bullet"><span class="by">briancleland</span><span>|</span><a href="#38398815">root</a><span>|</span><a href="#38399854">parent</a><span>|</span><a href="#38400978">prev</a><span>|</span><a href="#38399946">next</a><span>|</span><label class="collapse" for="c-38400047">[-]</label><label class="expand" for="c-38400047">[1 more]</label></div><br/><div class="children"><div class="content">Sounds like speculative decoding.<p><a href="https:&#x2F;&#x2F;huggingface.co&#x2F;blog&#x2F;vivien&#x2F;optimal-lossy-variant-of-speculative-decoding" rel="nofollow noreferrer">https:&#x2F;&#x2F;huggingface.co&#x2F;blog&#x2F;vivien&#x2F;optimal-lossy-variant-of-...</a></div><br/></div></div><div id="38399946" class="c"><input type="checkbox" id="c-38399946" checked=""/><div class="controls bullet"><span class="by">photoGrant</span><span>|</span><a href="#38398815">root</a><span>|</span><a href="#38399854">parent</a><span>|</span><a href="#38400047">prev</a><span>|</span><a href="#38400980">next</a><span>|</span><label class="collapse" for="c-38399946">[-]</label><label class="expand" for="c-38399946">[1 more]</label></div><br/><div class="children"><div class="content">I want to say this is where the progress is being made currently. Not only having &#x27;experts per domain&#x27; but &#x27;experts per pairing&#x27;</div><br/></div></div><div id="38400980" class="c"><input type="checkbox" id="c-38400980" checked=""/><div class="controls bullet"><span class="by">pyinstallwoes</span><span>|</span><a href="#38398815">root</a><span>|</span><a href="#38399854">parent</a><span>|</span><a href="#38399946">prev</a><span>|</span><a href="#38398942">next</a><span>|</span><label class="collapse" for="c-38400980">[-]</label><label class="expand" for="c-38400980">[3 more]</label></div><br/><div class="children"><div class="content">Is there anything experimenting with that?</div><br/><div id="38401254" class="c"><input type="checkbox" id="c-38401254" checked=""/><div class="controls bullet"><span class="by">Roark66</span><span>|</span><a href="#38398815">root</a><span>|</span><a href="#38400980">parent</a><span>|</span><a href="#38398942">next</a><span>|</span><label class="collapse" for="c-38401254">[-]</label><label class="expand" for="c-38401254">[2 more]</label></div><br/><div class="children"><div class="content">I would be very surprised if (not at all)OpenAI didn&#x27;t. I&#x27;ve noticed it with both gpt 3.5 and Gpt4 that if you ask it a difficult question the latency increases a lot, especially at the beginning of the answer. I wouldn&#x27;t ve surprised if they did exactly what was described.</div><br/><div id="38401346" class="c"><input type="checkbox" id="c-38401346" checked=""/><div class="controls bullet"><span class="by">pyinstallwoes</span><span>|</span><a href="#38398815">root</a><span>|</span><a href="#38401254">parent</a><span>|</span><a href="#38398942">next</a><span>|</span><label class="collapse" for="c-38401346">[-]</label><label class="expand" for="c-38401346">[1 more]</label></div><br/><div class="children"><div class="content">Right Iâve noticed that too. Itâs like it takes a pause and reevals. Definitely feels like a cache or memoization of token paths. Interesting.</div><br/></div></div></div></div></div></div></div></div><div id="38398942" class="c"><input type="checkbox" id="c-38398942" checked=""/><div class="controls bullet"><span class="by">DonHopkins</span><span>|</span><a href="#38398815">parent</a><span>|</span><a href="#38399854">prev</a><span>|</span><a href="#38401180">next</a><span>|</span><label class="collapse" for="c-38398942">[-]</label><label class="expand" for="c-38398942">[1 more]</label></div><br/><div class="children"><div class="content">...from the futures!</div><br/></div></div></div></div><div id="38401180" class="c"><input type="checkbox" id="c-38401180" checked=""/><div class="controls bullet"><span class="by">adfm</span><span>|</span><a href="#38398815">prev</a><span>|</span><a href="#38401142">next</a><span>|</span><label class="collapse" for="c-38401180">[-]</label><label class="expand" for="c-38401180">[1 more]</label></div><br/><div class="children"><div class="content">SimpleMind does something similar with OPML and it works well across desktop and mobile. Definitely worth checking out on a tablet.<p><a href="https:&#x2F;&#x2F;simplemind.eu&#x2F;blog&#x2F;mapping-your-thoughts-with-chatgpt&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;simplemind.eu&#x2F;blog&#x2F;mapping-your-thoughts-with-chatgp...</a></div><br/></div></div><div id="38401142" class="c"><input type="checkbox" id="c-38401142" checked=""/><div class="controls bullet"><span class="by">saberience</span><span>|</span><a href="#38401180">prev</a><span>|</span><a href="#38401516">next</a><span>|</span><label class="collapse" for="c-38401142">[-]</label><label class="expand" for="c-38401142">[3 more]</label></div><br/><div class="children"><div class="content">Can someone explain the primary use-case for this tool? Is it literally intended for writing a novel? Or just as sort of a plaything for exploring possibilities for generating text?<p>Wouldn&#x27;t the limited context window constrain any attempt to write long form text with this model?</div><br/><div id="38401351" class="c"><input type="checkbox" id="c-38401351" checked=""/><div class="controls bullet"><span class="by">pyinstallwoes</span><span>|</span><a href="#38401142">parent</a><span>|</span><a href="#38401516">next</a><span>|</span><label class="collapse" for="c-38401351">[-]</label><label class="expand" for="c-38401351">[2 more]</label></div><br/><div class="children"><div class="content">How is it limited? If anything itâs unlimited.</div><br/><div id="38401519" class="c"><input type="checkbox" id="c-38401519" checked=""/><div class="controls bullet"><span class="by">saberience</span><span>|</span><a href="#38401142">root</a><span>|</span><a href="#38401351">parent</a><span>|</span><a href="#38401516">next</a><span>|</span><label class="collapse" for="c-38401519">[-]</label><label class="expand" for="c-38401519">[1 more]</label></div><br/><div class="children"><div class="content">There is a 16k context window for GPT3.5. So for example, if you tried to put in a chapter of a novel then you would exceed the context window and the model would &quot;forget&quot; events from the start of the chapter.</div><br/></div></div></div></div></div></div><div id="38401516" class="c"><input type="checkbox" id="c-38401516" checked=""/><div class="controls bullet"><span class="by">siva7</span><span>|</span><a href="#38401142">prev</a><span>|</span><a href="#38399683">next</a><span>|</span><label class="collapse" for="c-38401516">[-]</label><label class="expand" for="c-38401516">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t grasp what this is. Not from reading that page and i&#x27;m not alone on that. Is someone able to tell what the practical real-world use cases are?</div><br/></div></div><div id="38399683" class="c"><input type="checkbox" id="c-38399683" checked=""/><div class="controls bullet"><span class="by">shoo</span><span>|</span><a href="#38401516">prev</a><span>|</span><a href="#38399728">next</a><span>|</span><label class="collapse" for="c-38399683">[-]</label><label class="expand" for="c-38399683">[1 more]</label></div><br/><div class="children"><div class="content">see also - an experimental tree-based thinking interface for software design:<p>- <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=1962051">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=1962051</a> HN discussion 2010<p>- <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=f84n5oFoZBc" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=f84n5oFoZBc</a> (working video link of presentation)</div><br/></div></div><div id="38399728" class="c"><input type="checkbox" id="c-38399728" checked=""/><div class="controls bullet"><span class="by">summitsummit</span><span>|</span><a href="#38399683">prev</a><span>|</span><a href="#38399704">next</a><span>|</span><label class="collapse" for="c-38399728">[-]</label><label class="expand" for="c-38399728">[2 more]</label></div><br/><div class="children"><div class="content">i (biasedly) thought this was going to be a reddit-like infinitely nested threaded interface to chat with GPT (as opposed to the serial chat-like dialogue based one.</div><br/><div id="38400170" class="c"><input type="checkbox" id="c-38400170" checked=""/><div class="controls bullet"><span class="by">ahmedfromtunis</span><span>|</span><a href="#38399728">parent</a><span>|</span><a href="#38399704">next</a><span>|</span><label class="collapse" for="c-38400170">[-]</label><label class="expand" for="c-38400170">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s what I thought, too. Such an interface would be awesome to explore multiple trains of thought simultaneously and efficiently.<p>With the ability to seemlessly merge branches together using smart conflict resolution algorithms, this can be an invaluable tool for better decision-making.</div><br/></div></div></div></div><div id="38399704" class="c"><input type="checkbox" id="c-38399704" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#38399728">prev</a><span>|</span><a href="#38399095">next</a><span>|</span><label class="collapse" for="c-38399704">[-]</label><label class="expand" for="c-38399704">[1 more]</label></div><br/><div class="children"><div class="content">This is the work of @repligate, I can&#x27;t recommend them highly enough. A true creative in every sense of the word, a rare spirit with a fundamental grounding and understanding of the spirit of LLMs. I highly, highly recommended pursuing every inch of their writing that interests you.<p><a href="https:&#x2F;&#x2F;twitter.com&#x2F;repligate" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;repligate</a></div><br/></div></div><div id="38399095" class="c"><input type="checkbox" id="c-38399095" checked=""/><div class="controls bullet"><span class="by">mickelsen</span><span>|</span><a href="#38399704">prev</a><span>|</span><a href="#38399831">next</a><span>|</span><label class="collapse" for="c-38399095">[-]</label><label class="expand" for="c-38399095">[1 more]</label></div><br/><div class="children"><div class="content">Related:
<a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36002817">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36002817</a></div><br/></div></div><div id="38399831" class="c"><input type="checkbox" id="c-38399831" checked=""/><div class="controls bullet"><span class="by">ampdot</span><span>|</span><a href="#38399095">prev</a><span>|</span><a href="#38399535">next</a><span>|</span><label class="collapse" for="c-38399831">[-]</label><label class="expand" for="c-38399831">[1 more]</label></div><br/><div class="children"><div class="content">This is a tool intended for exploring base language models. The best publicly available base model on the OpenAI API is &quot;davinci-002&quot;. Not davinci, but davinci-002.</div><br/></div></div><div id="38399535" class="c"><input type="checkbox" id="c-38399535" checked=""/><div class="controls bullet"><span class="by">xchip</span><span>|</span><a href="#38399831">prev</a><span>|</span><a href="#38399030">next</a><span>|</span><label class="collapse" for="c-38399535">[-]</label><label class="expand" for="c-38399535">[2 more]</label></div><br/><div class="children"><div class="content">Could anybody elaborate on what this does?</div><br/><div id="38399568" class="c"><input type="checkbox" id="c-38399568" checked=""/><div class="controls bullet"><span class="by">andai</span><span>|</span><a href="#38399535">parent</a><span>|</span><a href="#38399030">next</a><span>|</span><label class="collapse" for="c-38399568">[-]</label><label class="expand" for="c-38399568">[1 more]</label></div><br/><div class="children"><div class="content">&gt;Read this[0] for a conceptual explanation of block multiverse interface and demo video<p>[0] <a href="https:&#x2F;&#x2F;generative.ink&#x2F;meta&#x2F;block-multiverse&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;generative.ink&#x2F;meta&#x2F;block-multiverse&#x2F;</a></div><br/></div></div></div></div><div id="38399030" class="c"><input type="checkbox" id="c-38399030" checked=""/><div class="controls bullet"><span class="by">Der_Einzige</span><span>|</span><a href="#38399535">prev</a><span>|</span><a href="#38399818">next</a><span>|</span><label class="collapse" for="c-38399030">[-]</label><label class="expand" for="c-38399030">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ll shamelessly plug my somewhat related but even less polished take on a text generation studio.<p>I was fascinated by the idea of constraining an LLMs vocabulary and it ended up as a publication and this: <a href="https:&#x2F;&#x2F;github.com&#x2F;Hellisotherpeople&#x2F;Constrained-Text-Generation-Studio&#x2F;tree&#x2F;main">https:&#x2F;&#x2F;github.com&#x2F;Hellisotherpeople&#x2F;Constrained-Text-Genera...</a></div><br/></div></div></div></div></div></div></div></body></html>