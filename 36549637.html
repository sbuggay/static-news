<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1688288449529" as="style"/><link rel="stylesheet" href="styles.css?v=1688288449529"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/jgbit/vuda">VUDA: A Vulkan Implementation of CUDA</a> <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>tormeh</span> | <span>77 comments</span></div><br/><div><div id="36550042" class="c"><input type="checkbox" id="c-36550042" checked=""/><div class="controls bullet"><span class="by">fancyfredbot</span><span>|</span><a href="#36549764">next</a><span>|</span><label class="collapse" for="c-36550042">[-]</label><label class="expand" for="c-36550042">[20 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not an implementation of CUDA, it&#x27;s an implementation of the CUDA runtime API. The API is used to configure the card, allocate and copy memory, and run kernels. Importantly you cannot use this to write the actual kernels which run on the GPU!</div><br/><div id="36550139" class="c"><input type="checkbox" id="c-36550139" checked=""/><div class="controls bullet"><span class="by">sheepscreek</span><span>|</span><a href="#36550042">parent</a><span>|</span><a href="#36552255">next</a><span>|</span><label class="collapse" for="c-36550139">[-]</label><label class="expand" for="c-36550139">[17 more]</label></div><br/><div class="children"><div class="content">I was half hoping this meant running CUDA code on AMD GPUs. Thanks for clarifying.</div><br/><div id="36550412" class="c"><input type="checkbox" id="c-36550412" checked=""/><div class="controls bullet"><span class="by">empyrrhicist</span><span>|</span><a href="#36550042">root</a><span>|</span><a href="#36550139">parent</a><span>|</span><a href="#36553375">next</a><span>|</span><label class="collapse" for="c-36550412">[-]</label><label class="expand" for="c-36550412">[14 more]</label></div><br/><div class="children"><div class="content">I know AMD has a whole bunch of (related?) projects for GPU compute, but man - if they could just provide an interop layer that Just Works they&#x27;d get immediate access to so much more market share.</div><br/><div id="36550824" class="c"><input type="checkbox" id="c-36550824" checked=""/><div class="controls bullet"><span class="by">sanxiyn</span><span>|</span><a href="#36550042">root</a><span>|</span><a href="#36550412">parent</a><span>|</span><a href="#36550972">next</a><span>|</span><label class="collapse" for="c-36550824">[-]</label><label class="expand" for="c-36550824">[9 more]</label></div><br/><div class="children"><div class="content">Eh well, it is very close to just working. From &quot;Training LLMs with AMD MI250 GPUs and MosaicML&quot;:<p>&gt; It all just works. No code changes were needed.<p><a href="https:&#x2F;&#x2F;www.mosaicml.com&#x2F;blog&#x2F;amd-mi250" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.mosaicml.com&#x2F;blog&#x2F;amd-mi250</a></div><br/><div id="36553508" class="c"><input type="checkbox" id="c-36553508" checked=""/><div class="controls bullet"><span class="by">paulmd</span><span>|</span><a href="#36550042">root</a><span>|</span><a href="#36550824">parent</a><span>|</span><a href="#36550972">next</a><span>|</span><label class="collapse" for="c-36553508">[-]</label><label class="expand" for="c-36553508">[8 more]</label></div><br/><div class="children"><div class="content">“Just works” in this context means executing the compiled CUDA or the PTX bytecode without recompiling. Nobody is ever going to utilize ROCm if it requires distributing as source and recompiling.<p>To make it even more insulting, even simply installing ROCm itself is a massive burden, even on an ostensibly-supported (as geohot discovered) and even just “it works out of the box if you distribute and compile it locally” is ignoring that whole massive “draw the rest of the owl” stage of getting ROCm installed and building properly in your environment.</div><br/><div id="36557170" class="c"><input type="checkbox" id="c-36557170" checked=""/><div class="controls bullet"><span class="by">JoshTriplett</span><span>|</span><a href="#36550042">root</a><span>|</span><a href="#36553508">parent</a><span>|</span><a href="#36554430">next</a><span>|</span><label class="collapse" for="c-36557170">[-]</label><label class="expand" for="c-36557170">[1 more]</label></div><br/><div class="children"><div class="content">&gt; “Just works” in this context means executing the compiled CUDA or the PTX bytecode without recompiling. Nobody is ever going to utilize ROCm if it requires distributing as source and recompiling.<p>Even a source-compatible layer that let you <i>just</i> recompile CUDA code for an AMD GPU would be a huge improvement. That alone would eliminate the CUDA lock-in.</div><br/></div></div><div id="36554430" class="c"><input type="checkbox" id="c-36554430" checked=""/><div class="controls bullet"><span class="by">causality0</span><span>|</span><a href="#36550042">root</a><span>|</span><a href="#36553508">parent</a><span>|</span><a href="#36557170">prev</a><span>|</span><a href="#36550972">next</a><span>|</span><label class="collapse" for="c-36554430">[-]</label><label class="expand" for="c-36554430">[6 more]</label></div><br/><div class="children"><div class="content">Don&#x27;t forget AMD doesn&#x27;t seem to even care about ROCm themselves. Six months in and RDNA3 cards still don&#x27;t support it. Can you imagine if Nvidia launched RTX40- cards with no DLSS even though 30- cards already had it, and six months started boasting about how DLSS support was &quot;coming this fall&quot;?</div><br/><div id="36554879" class="c"><input type="checkbox" id="c-36554879" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#36550042">root</a><span>|</span><a href="#36554430">parent</a><span>|</span><a href="#36555112">next</a><span>|</span><label class="collapse" for="c-36554879">[-]</label><label class="expand" for="c-36554879">[1 more]</label></div><br/><div class="children"><div class="content">ROCm is for CDNA not RDNA. It has limited, best-effort RDNA support for a few cards.</div><br/></div></div><div id="36555112" class="c"><input type="checkbox" id="c-36555112" checked=""/><div class="controls bullet"><span class="by">i80and</span><span>|</span><a href="#36550042">root</a><span>|</span><a href="#36554430">parent</a><span>|</span><a href="#36554879">prev</a><span>|</span><a href="#36550972">next</a><span>|</span><label class="collapse" for="c-36555112">[-]</label><label class="expand" for="c-36555112">[4 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve been running PyTorch on my Radeon 7900 XT using ROCm. Is that not supposed to work?</div><br/><div id="36555373" class="c"><input type="checkbox" id="c-36555373" checked=""/><div class="controls bullet"><span class="by">graphe</span><span>|</span><a href="#36550042">root</a><span>|</span><a href="#36555112">parent</a><span>|</span><a href="#36550972">next</a><span>|</span><label class="collapse" for="c-36555373">[-]</label><label class="expand" for="c-36555373">[3 more]</label></div><br/><div class="children"><div class="content">No, it actually isn&#x27;t supposed to work, it&#x27;s not officially supported. <a href="https:&#x2F;&#x2F;sep5.readthedocs.io&#x2F;en&#x2F;latest&#x2F;Installation_Guide&#x2F;Installation-Guide.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;sep5.readthedocs.io&#x2F;en&#x2F;latest&#x2F;Installation_Guide&#x2F;Ins...</a></div><br/><div id="36556219" class="c"><input type="checkbox" id="c-36556219" checked=""/><div class="controls bullet"><span class="by">slavik81</span><span>|</span><a href="#36550042">root</a><span>|</span><a href="#36555373">parent</a><span>|</span><a href="#36555559">next</a><span>|</span><label class="collapse" for="c-36556219">[-]</label><label class="expand" for="c-36556219">[1 more]</label></div><br/><div class="children"><div class="content">The hardware that is officially supported is a subset of the hardware that works. You are correct that the RX 7900 XT is not officially supported, but I must point out that you are linking to a fork of the documentation from 2019. This is the official ROCm documentation: <a href="https:&#x2F;&#x2F;rocm.docs.amd.com&#x2F;en&#x2F;latest&#x2F;release&#x2F;gpu_os_support.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;rocm.docs.amd.com&#x2F;en&#x2F;latest&#x2F;release&#x2F;gpu_os_support.h...</a></div><br/></div></div><div id="36555559" class="c"><input type="checkbox" id="c-36555559" checked=""/><div class="controls bullet"><span class="by">i80and</span><span>|</span><a href="#36550042">root</a><span>|</span><a href="#36555373">parent</a><span>|</span><a href="#36556219">prev</a><span>|</span><a href="#36550972">next</a><span>|</span><label class="collapse" for="c-36555559">[-]</label><label class="expand" for="c-36555559">[1 more]</label></div><br/><div class="children"><div class="content">Fascinating. And yet.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="36550972" class="c"><input type="checkbox" id="c-36550972" checked=""/><div class="controls bullet"><span class="by">collsni</span><span>|</span><a href="#36550042">root</a><span>|</span><a href="#36550412">parent</a><span>|</span><a href="#36550824">prev</a><span>|</span><a href="#36550648">next</a><span>|</span><label class="collapse" for="c-36550972">[-]</label><label class="expand" for="c-36550972">[2 more]</label></div><br/><div class="children"><div class="content">It is coming from what I can tell</div><br/><div id="36553544" class="c"><input type="checkbox" id="c-36553544" checked=""/><div class="controls bullet"><span class="by">meragrin_</span><span>|</span><a href="#36550042">root</a><span>|</span><a href="#36550972">parent</a><span>|</span><a href="#36550648">next</a><span>|</span><label class="collapse" for="c-36553544">[-]</label><label class="expand" for="c-36553544">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s been coming for years now.  I will probably be years before it really is here.</div><br/></div></div></div></div><div id="36550648" class="c"><input type="checkbox" id="c-36550648" checked=""/><div class="controls bullet"><span class="by">heyoni</span><span>|</span><a href="#36550042">root</a><span>|</span><a href="#36550412">parent</a><span>|</span><a href="#36550972">prev</a><span>|</span><a href="#36553375">next</a><span>|</span><label class="collapse" for="c-36550648">[-]</label><label class="expand" for="c-36550648">[2 more]</label></div><br/><div class="children"><div class="content">Then they too could call themselves an AI company!</div><br/><div id="36550816" class="c"><input type="checkbox" id="c-36550816" checked=""/><div class="controls bullet"><span class="by">empyrrhicist</span><span>|</span><a href="#36550042">root</a><span>|</span><a href="#36550648">parent</a><span>|</span><a href="#36553375">next</a><span>|</span><label class="collapse" for="c-36550816">[-]</label><label class="expand" for="c-36550816">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve been hoping for it for so long - I wonder if there&#x27;s enough interest that someone could do a GoFundMe to hire at least one full time dev lol.</div><br/></div></div></div></div></div></div><div id="36553375" class="c"><input type="checkbox" id="c-36553375" checked=""/><div class="controls bullet"><span class="by">jdoerfert</span><span>|</span><a href="#36550042">root</a><span>|</span><a href="#36550139">parent</a><span>|</span><a href="#36550412">prev</a><span>|</span><a href="#36557520">next</a><span>|</span><label class="collapse" for="c-36553375">[-]</label><label class="expand" for="c-36553375">[1 more]</label></div><br/><div class="children"><div class="content">Shameless plug: <a href="https:&#x2F;&#x2F;www.osti.gov&#x2F;servlets&#x2F;purl&#x2F;1892137" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.osti.gov&#x2F;servlets&#x2F;purl&#x2F;1892137</a><p>TLDR; If you provide even more functions through the overloaded headers, incl. &quot;hidden ones&quot;, e.g., `__cudaPushCallConfiguration`, you can use LLVM&#x2F;Clang as a CUDA compiler and target AMD GPUs, the host, and soon GPUs of two other manufacturers.</div><br/></div></div><div id="36557520" class="c"><input type="checkbox" id="c-36557520" checked=""/><div class="controls bullet"><span class="by">causality0</span><span>|</span><a href="#36550042">root</a><span>|</span><a href="#36550139">parent</a><span>|</span><a href="#36553375">prev</a><span>|</span><a href="#36552255">next</a><span>|</span><label class="collapse" for="c-36557520">[-]</label><label class="expand" for="c-36557520">[1 more]</label></div><br/><div class="children"><div class="content">Vulkan doesn&#x27;t exactly work great on AMD either. I&#x27;m in the process of returning a 7900XTX right now because of AMD&#x27;s busted Vulkan drivers.</div><br/></div></div></div></div><div id="36552255" class="c"><input type="checkbox" id="c-36552255" checked=""/><div class="controls bullet"><span class="by">RicoElectrico</span><span>|</span><a href="#36550042">parent</a><span>|</span><a href="#36550139">prev</a><span>|</span><a href="#36552994">next</a><span>|</span><label class="collapse" for="c-36552255">[-]</label><label class="expand" for="c-36552255">[1 more]</label></div><br/><div class="children"><div class="content">So what is this useful for, then?</div><br/></div></div><div id="36552994" class="c"><input type="checkbox" id="c-36552994" checked=""/><div class="controls bullet"><span class="by">pjmlp</span><span>|</span><a href="#36550042">parent</a><span>|</span><a href="#36552255">prev</a><span>|</span><a href="#36549764">next</a><span>|</span><label class="collapse" for="c-36552994">[-]</label><label class="expand" for="c-36552994">[1 more]</label></div><br/><div class="children"><div class="content">Additionally, any wannabe CUDA replacement needs to support PTX and polyglot development, or is a non starter for lots of workloads.</div><br/></div></div></div></div><div id="36549764" class="c"><input type="checkbox" id="c-36549764" checked=""/><div class="controls bullet"><span class="by">nightowl_games</span><span>|</span><a href="#36550042">prev</a><span>|</span><a href="#36550677">next</a><span>|</span><label class="collapse" for="c-36549764">[-]</label><label class="expand" for="c-36549764">[20 more]</label></div><br/><div class="children"><div class="content">How does this relate to the goals outlined by George Hotz to bring ML to AMD chips and break the Nvidia dominance?<p>I&#x27;m not an expert here but this approach seems powerful and important. But this system seems complex enough to doubt the ability of an individual to build. It seems like this would need a corporate sponsor to get off the ground. Perhaps AMD itself would be interested in paying engineers to iterate on this?</div><br/><div id="36549953" class="c"><input type="checkbox" id="c-36549953" checked=""/><div class="controls bullet"><span class="by">jitl</span><span>|</span><a href="#36549764">parent</a><span>|</span><a href="#36550525">next</a><span>|</span><label class="collapse" for="c-36549953">[-]</label><label class="expand" for="c-36549953">[18 more]</label></div><br/><div class="children"><div class="content">Holtz is talking about drivers too, not just user space libraries.<p>&gt; The software is terrible! There’s kernel panics in the driver. You have to run a newer kernel than the Ubuntu default to make it remotely stable. I’m still not sure if the driver supports putting two cards in one machine, or if there’s some poorly written global state. When I put the second card in and run an OpenCL program, half the time it kernel panics and you have to reboot.<p>He also talks about user space stuff but clearly he thinks the whole stack, above and below this kind of library also needs a lot of work.</div><br/><div id="36550544" class="c"><input type="checkbox" id="c-36550544" checked=""/><div class="controls bullet"><span class="by">iforgotpassword</span><span>|</span><a href="#36549764">root</a><span>|</span><a href="#36549953">parent</a><span>|</span><a href="#36550165">next</a><span>|</span><label class="collapse" for="c-36550544">[-]</label><label class="expand" for="c-36550544">[13 more]</label></div><br/><div class="children"><div class="content">This is still so mind-boggling to me. AMD should be in a good financial position now that Zen was such a success, and that their GPUs are catching up too. Why are their drivers still a Clusterfuck across the board after all these years? Why not throw more manpower at the problem?<p>I&#x27;m sure even if their GPUs were twice as fast as Nvidia&#x27;s, everybody would still buy team green because it&#x27;s better to have a card that works than a broken piece of garbage. We tried to get an MI50 to work reliably at work with KVM, but that thing was a complete dumpster fire. A colleague just bought a 7900XTX for gaming and spent days getting it to work. This included three Windows reinstalls. And that use case is gaming on Windows, which supposedly is the best supported case. It only gets worse from there. Compute on Linux? Lol.<p>Now last time this topic came up, someone claimed that AMD is pretty much at their limits production wise, and there are a few unnamed large companies buying loads of their cards for compute and cloud gaming, and AMD basically has engineers dedicated to making sure things work exactly for their use case, so they don&#x27;t have to really care about the rest. Sounds pretty wild, but not completely unrealistic...</div><br/><div id="36550624" class="c"><input type="checkbox" id="c-36550624" checked=""/><div class="controls bullet"><span class="by">hedora</span><span>|</span><a href="#36549764">root</a><span>|</span><a href="#36550544">parent</a><span>|</span><a href="#36550705">next</a><span>|</span><label class="collapse" for="c-36550624">[-]</label><label class="expand" for="c-36550624">[8 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve had the opposite experience under Linux.<p>My old nvidia 570&#x27;s drivers went into severe bitrot.  Basic stuff like screensavers and desktops broke badly, and games were flaky.  The card is still more than powerful enough for what I used it for.<p>I switched to AMD, with open source drivers.  I get windows-level performance on AAA (and indie) games in steam, and zero compatibility issues with the rest of the Linux ecosystem.</div><br/><div id="36552018" class="c"><input type="checkbox" id="c-36552018" checked=""/><div class="controls bullet"><span class="by">amlib</span><span>|</span><a href="#36549764">root</a><span>|</span><a href="#36550624">parent</a><span>|</span><a href="#36552326">next</a><span>|</span><label class="collapse" for="c-36552018">[-]</label><label class="expand" for="c-36552018">[3 more]</label></div><br/><div class="children"><div class="content">AMD GPU support in linux is a bit of a flip flop. Some generations seem to get a lot of love and work really damn well (sometimes with better and broader support than the windows drivers) like RDNA2 and most Polaris cards. Others such as Vega and specially now RDNA3 are a shitshow with a lot of things just broken.</div><br/><div id="36554856" class="c"><input type="checkbox" id="c-36554856" checked=""/><div class="controls bullet"><span class="by">gcoakes</span><span>|</span><a href="#36549764">root</a><span>|</span><a href="#36552018">parent</a><span>|</span><a href="#36553019">next</a><span>|</span><label class="collapse" for="c-36554856">[-]</label><label class="expand" for="c-36554856">[1 more]</label></div><br/><div class="children"><div class="content">I used a Vega64 for years and just bought a 6000 series. Both work great on my machines. I&#x27;m typically running the bleeding edge kernels though, so that might explain it a bit. I would think Ubuntu is probably the most supported if you opt for the OEM kernel.</div><br/></div></div><div id="36553019" class="c"><input type="checkbox" id="c-36553019" checked=""/><div class="controls bullet"><span class="by">tyfon</span><span>|</span><a href="#36549764">root</a><span>|</span><a href="#36552018">parent</a><span>|</span><a href="#36554856">prev</a><span>|</span><a href="#36552326">next</a><span>|</span><label class="collapse" for="c-36553019">[-]</label><label class="expand" for="c-36553019">[1 more]</label></div><br/><div class="children"><div class="content">I ran vega 64 in linux for 3-4 years, it was really nice. It also worked without bugs with proton, the 3060 I have now gives me a lot of artifacts like incorrect lightning and even X crashes once in a while.<p>I&#x27;m considering switching back to an AMD card due to this.</div><br/></div></div></div></div><div id="36552326" class="c"><input type="checkbox" id="c-36552326" checked=""/><div class="controls bullet"><span class="by">aseipp</span><span>|</span><a href="#36549764">root</a><span>|</span><a href="#36550624">parent</a><span>|</span><a href="#36552018">prev</a><span>|</span><a href="#36551883">next</a><span>|</span><label class="collapse" for="c-36552326">[-]</label><label class="expand" for="c-36552326">[1 more]</label></div><br/><div class="children"><div class="content">It really depends on the card. I have an old RDNA workstation card in my server and the driver was a real crapshoot. I eventually started delaying updates to newer kernel releases (which would fix other bugs!) because there would be regressions of various kinds. Graphics under Linux is still a bit painful after all these years.<p>At least Nvidia finally open sourced their driver too, I guess. And Intel is still open source. But it still sucks a bit I think unless you do research.</div><br/></div></div><div id="36551883" class="c"><input type="checkbox" id="c-36551883" checked=""/><div class="controls bullet"><span class="by">fiddlerwoaroof</span><span>|</span><a href="#36549764">root</a><span>|</span><a href="#36550624">parent</a><span>|</span><a href="#36552326">prev</a><span>|</span><a href="#36552889">next</a><span>|</span><label class="collapse" for="c-36551883">[-]</label><label class="expand" for="c-36551883">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, I’ve always bought AMD for this reason since some really bad experiences with Nvidia cards.</div><br/></div></div><div id="36552889" class="c"><input type="checkbox" id="c-36552889" checked=""/><div class="controls bullet"><span class="by">izacus</span><span>|</span><a href="#36549764">root</a><span>|</span><a href="#36550624">parent</a><span>|</span><a href="#36551883">prev</a><span>|</span><a href="#36550705">next</a><span>|</span><label class="collapse" for="c-36552889">[-]</label><label class="expand" for="c-36552889">[2 more]</label></div><br/><div class="children"><div class="content">Why are you talking about screensavers in a CUDA thread though? You can&#x27;t compute on a fancy screensaver animation, you need a working CUDA driver that nVidia provides for that.</div><br/><div id="36553029" class="c"><input type="checkbox" id="c-36553029" checked=""/><div class="controls bullet"><span class="by">kbenson</span><span>|</span><a href="#36549764">root</a><span>|</span><a href="#36552889">parent</a><span>|</span><a href="#36550705">next</a><span>|</span><label class="collapse" for="c-36553029">[-]</label><label class="expand" for="c-36553029">[1 more]</label></div><br/><div class="children"><div class="content">Likely because this subsection of the thread seems more focused on drivers in general and less on CUDA, if the other replies are anything to go by.</div><br/></div></div></div></div></div></div><div id="36550705" class="c"><input type="checkbox" id="c-36550705" checked=""/><div class="controls bullet"><span class="by">derstander</span><span>|</span><a href="#36549764">root</a><span>|</span><a href="#36550544">parent</a><span>|</span><a href="#36550624">prev</a><span>|</span><a href="#36551613">next</a><span>|</span><label class="collapse" for="c-36550705">[-]</label><label class="expand" for="c-36550705">[2 more]</label></div><br/><div class="children"><div class="content">&gt; And that use case is gaming on Windows, which supposedly is the best supported case.<p>I’m being a little tongue-in-cheek here, but the best supported case for AMD is gaming via console: AMD provides CPU&#x2F;GPU for the current generation of both the XBox <i>and</i> PlayStation consoles.<p>Which suggests to me that they shouldn’t have too much problem supporting their hardware on Windows or Linux.  But that’s outside of my area of expertise. Maybe they need to spend too much engineer effort and time supporting the consoles at what’s probably a pretty thin profit margin?</div><br/><div id="36551870" class="c"><input type="checkbox" id="c-36551870" checked=""/><div class="controls bullet"><span class="by">Narishma</span><span>|</span><a href="#36549764">root</a><span>|</span><a href="#36550705">parent</a><span>|</span><a href="#36551613">next</a><span>|</span><label class="collapse" for="c-36551870">[-]</label><label class="expand" for="c-36551870">[1 more]</label></div><br/><div class="children"><div class="content">The previous generation as well, and the one before for Xbox 360 and Wii, and the one before for Gamecube.</div><br/></div></div></div></div><div id="36551613" class="c"><input type="checkbox" id="c-36551613" checked=""/><div class="controls bullet"><span class="by">roadbuster</span><span>|</span><a href="#36549764">root</a><span>|</span><a href="#36550544">parent</a><span>|</span><a href="#36550705">prev</a><span>|</span><a href="#36550165">next</a><span>|</span><label class="collapse" for="c-36551613">[-]</label><label class="expand" for="c-36551613">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Why not throw more manpower at the problem?<p>Oh, of course.</div><br/><div id="36551724" class="c"><input type="checkbox" id="c-36551724" checked=""/><div class="controls bullet"><span class="by">iforgotpassword</span><span>|</span><a href="#36549764">root</a><span>|</span><a href="#36551613">parent</a><span>|</span><a href="#36550165">next</a><span>|</span><label class="collapse" for="c-36551724">[-]</label><label class="expand" for="c-36551724">[1 more]</label></div><br/><div class="children"><div class="content">No, really. We&#x27;ve worked with Intel, Nvidia and AMD... Well for the latter, at least tried. We&#x27;re not a big fish, but response time and quality of responses were stellar with Intel and Nvidia. AMD took weeks and even when asking very precise questions with lots of technical background, there was a lot of &quot;hmm dunno have to find someone who&#x27;d know&quot; kind of answers, and it would often take one to two weeks for a single reply. And that&#x27;s not even dev work, it&#x27;s just tech support for your own damn stuff you&#x27;re trying to sell.<p>You can&#x27;t seriously tell me that&#x27;s not something they could fix.</div><br/></div></div></div></div></div></div><div id="36550165" class="c"><input type="checkbox" id="c-36550165" checked=""/><div class="controls bullet"><span class="by">cwillu</span><span>|</span><a href="#36549764">root</a><span>|</span><a href="#36549953">parent</a><span>|</span><a href="#36550544">prev</a><span>|</span><a href="#36553129">next</a><span>|</span><label class="collapse" for="c-36550165">[-]</label><label class="expand" for="c-36550165">[2 more]</label></div><br/><div class="children"><div class="content">Par for the course with new kernel things: it&#x27;s unusual for something new in the kernel to be stable in the distro kernels unless they&#x27;ve devoted a great deal of effort to backport things.</div><br/><div id="36550640" class="c"><input type="checkbox" id="c-36550640" checked=""/><div class="controls bullet"><span class="by">arthur2e5</span><span>|</span><a href="#36549764">root</a><span>|</span><a href="#36550165">parent</a><span>|</span><a href="#36553129">next</a><span>|</span><label class="collapse" for="c-36550640">[-]</label><label class="expand" for="c-36550640">[1 more]</label></div><br/><div class="children"><div class="content">The way conservative distros define &quot;stable&quot; is part of the problem. For things less than 3 years old, going for stale versions often runs counter to &quot;stable&quot;.</div><br/></div></div></div></div><div id="36553129" class="c"><input type="checkbox" id="c-36553129" checked=""/><div class="controls bullet"><span class="by">imtringued</span><span>|</span><a href="#36549764">root</a><span>|</span><a href="#36549953">parent</a><span>|</span><a href="#36550165">prev</a><span>|</span><a href="#36551827">next</a><span>|</span><label class="collapse" for="c-36553129">[-]</label><label class="expand" for="c-36553129">[1 more]</label></div><br/><div class="children"><div class="content">The only hope is rusticl and it happens inspite of AMD.</div><br/></div></div></div></div><div id="36550525" class="c"><input type="checkbox" id="c-36550525" checked=""/><div class="controls bullet"><span class="by">roenxi</span><span>|</span><a href="#36549764">parent</a><span>|</span><a href="#36549953">prev</a><span>|</span><a href="#36550677">next</a><span>|</span><label class="collapse" for="c-36550525">[-]</label><label class="expand" for="c-36550525">[1 more]</label></div><br/><div class="children"><div class="content">Hmm. I found<p><a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=Mr0rWJhv9jU">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=Mr0rWJhv9jU</a><p>and<p><a href="https:&#x2F;&#x2F;geohot.github.io&#x2F;blog&#x2F;jekyll&#x2F;update&#x2F;2023&#x2F;06&#x2F;07&#x2F;a-dive-into-amds-drivers.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;geohot.github.io&#x2F;blog&#x2F;jekyll&#x2F;update&#x2F;2023&#x2F;06&#x2F;07&#x2F;a-div...</a><p>I feel a lot better about my journey with AMD now; there seemed to be some major issues with their GPU drivers. Now I know it wasn&#x27;t just me.</div><br/></div></div></div></div><div id="36550677" class="c"><input type="checkbox" id="c-36550677" checked=""/><div class="controls bullet"><span class="by">netheril96</span><span>|</span><a href="#36549764">prev</a><span>|</span><a href="#36549937">next</a><span>|</span><label class="collapse" for="c-36550677">[-]</label><label class="expand" for="c-36550677">[6 more]</label></div><br/><div class="children"><div class="content">Just in case other people who have AMD GPU and run Windows have the same needs as I have, that is, to train or run machine learning models, please checkout torch-directml and tensorflow-directml.</div><br/><div id="36555263" class="c"><input type="checkbox" id="c-36555263" checked=""/><div class="controls bullet"><span class="by">HarHarVeryFunny</span><span>|</span><a href="#36550677">parent</a><span>|</span><a href="#36553139">next</a><span>|</span><label class="collapse" for="c-36555263">[-]</label><label class="expand" for="c-36555263">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not sure this really makes any more sense than AMD chasing CUDA compatibility with ROCm&#x2F;MiOpen&#x2F;HIP. CUDA and DirectX seem too low level to be used as a compatibility API over widely divergent hardware (AMD vs NVidia) without giving up a lot of performance.<p>cuDNN being higher level offers more opportunity for compatibility without losing performance (i.e different implementations of kernels fine-tuned for optimal performance on AMD vs NVidia hardware), but the trouble is that so much of what frameworks like PyTorch do is based on custom kernels, not just cuDNN.<p>It seems the best bet for AMD would be a rock solid low level API (not a moving target) and support of high level optimizing ML compilers to reduce the level of
effort for the framework (PyTorch, TensorFlow, JAX ...) vendors to provide framework-level support on top of that. Ultimately they&#x27;d need to work very closely with the framework vendors to provide this support, since they are the ones who would be benefiting from it.<p>It&#x27;s odd how much of an afterthought ML support has seemed to be for AMD over the years... maybe the relative size of the consumer ML market vs graphics&#x2F;gaming market didn&#x27;t seem to make it worth their effort, but as NVidia has shown this is a path to gaining much more lucrative data center wins.</div><br/></div></div><div id="36553139" class="c"><input type="checkbox" id="c-36553139" checked=""/><div class="controls bullet"><span class="by">skocznymroczny</span><span>|</span><a href="#36550677">parent</a><span>|</span><a href="#36555263">prev</a><span>|</span><a href="#36552985">next</a><span>|</span><label class="collapse" for="c-36553139">[-]</label><label class="expand" for="c-36553139">[2 more]</label></div><br/><div class="children"><div class="content">How does it work? Last time I tried DirectML it wasn&#x27;t well supposed and there was little software which supported it. Also the performance seemed to be not too great. I am currently using a Linux install because with ROCm I can use popular tools like Automatic111 webui and oobabooga.</div><br/><div id="36557218" class="c"><input type="checkbox" id="c-36557218" checked=""/><div class="controls bullet"><span class="by">netheril96</span><span>|</span><a href="#36550677">root</a><span>|</span><a href="#36553139">parent</a><span>|</span><a href="#36552985">next</a><span>|</span><label class="collapse" for="c-36557218">[-]</label><label class="expand" for="c-36557218">[1 more]</label></div><br/><div class="children"><div class="content">I trained a WGAN on torch-directml with no issues so the software seems quite supported. But I can’t speak of performance because I have nothing to compare against.</div><br/></div></div></div></div><div id="36552985" class="c"><input type="checkbox" id="c-36552985" checked=""/><div class="controls bullet"><span class="by">bornfreddy</span><span>|</span><a href="#36550677">parent</a><span>|</span><a href="#36553139">prev</a><span>|</span><a href="#36549937">next</a><span>|</span><label class="collapse" for="c-36552985">[-]</label><label class="expand" for="c-36552985">[2 more]</label></div><br/><div class="children"><div class="content">Does that work? I might be in market for a new GPU if AMD had something that beats NVidia for ML (for sane price)... I can&#x27;t really justify buying NVidia GPU, anything decent is too expensive.</div><br/><div id="36557203" class="c"><input type="checkbox" id="c-36557203" checked=""/><div class="controls bullet"><span class="by">netheril96</span><span>|</span><a href="#36550677">root</a><span>|</span><a href="#36552985">parent</a><span>|</span><a href="#36549937">next</a><span>|</span><label class="collapse" for="c-36557203">[-]</label><label class="expand" for="c-36557203">[1 more]</label></div><br/><div class="children"><div class="content">It works for me. I have no issues training a WGAN with it. But I don’t know how much slower it is compared to CUDA on a similar priced NVIDIA card.</div><br/></div></div></div></div></div></div><div id="36549937" class="c"><input type="checkbox" id="c-36549937" checked=""/><div class="controls bullet"><span class="by">wtcactus</span><span>|</span><a href="#36550677">prev</a><span>|</span><a href="#36552029">next</a><span>|</span><label class="collapse" for="c-36549937">[-]</label><label class="expand" for="c-36549937">[2 more]</label></div><br/><div class="children"><div class="content">Seems dead. Last commit was February 2022.</div><br/><div id="36550479" class="c"><input type="checkbox" id="c-36550479" checked=""/><div class="controls bullet"><span class="by">qwertox</span><span>|</span><a href="#36549937">parent</a><span>|</span><a href="#36552029">next</a><span>|</span><label class="collapse" for="c-36550479">[-]</label><label class="expand" for="c-36550479">[1 more]</label></div><br/><div class="children"><div class="content">And that was only one line added. Most of the code is 3 and 5 years old.</div><br/></div></div></div></div><div id="36552029" class="c"><input type="checkbox" id="c-36552029" checked=""/><div class="controls bullet"><span class="by">panzi</span><span>|</span><a href="#36549937">prev</a><span>|</span><a href="#36549756">next</a><span>|</span><label class="collapse" for="c-36552029">[-]</label><label class="expand" for="c-36552029">[1 more]</label></div><br/><div class="children"><div class="content">There needs to be a 3rd implementation called SHUDA.</div><br/></div></div><div id="36549756" class="c"><input type="checkbox" id="c-36549756" checked=""/><div class="controls bullet"><span class="by">josalhor</span><span>|</span><a href="#36552029">prev</a><span>|</span><a href="#36549911">next</a><span>|</span><label class="collapse" for="c-36549756">[-]</label><label class="expand" for="c-36549756">[2 more]</label></div><br/><div class="children"><div class="content">As someone who has never programmed directly for a GPU, how does this compare to HIP? Can this be an efficient abstraction over Nvidia and AMD GPUs?</div><br/><div id="36549999" class="c"><input type="checkbox" id="c-36549999" checked=""/><div class="controls bullet"><span class="by">westurner</span><span>|</span><a href="#36549756">parent</a><span>|</span><a href="#36549911">next</a><span>|</span><label class="collapse" for="c-36549999">[-]</label><label class="expand" for="c-36549999">[1 more]</label></div><br/><div class="children"><div class="content">From <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=34399633">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=34399633</a> :<p>&gt;&gt;&gt; <i>hipify-clang is a clang-based tool for translating CUDA sources into HIP sources. It translates CUDA source into an abstract syntax tree, which is traversed by transformation matchers. After applying all the matchers, the output HIP source is produced. [...]</i><p>(Edit) CUDA APIs supported by hipify-clang: <a href="https:&#x2F;&#x2F;rocm.docs.amd.com&#x2F;projects&#x2F;HIPIFY&#x2F;en&#x2F;latest&#x2F;supported_apis.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;rocm.docs.amd.com&#x2F;projects&#x2F;HIPIFY&#x2F;en&#x2F;latest&#x2F;supporte...</a></div><br/></div></div></div></div><div id="36549911" class="c"><input type="checkbox" id="c-36549911" checked=""/><div class="controls bullet"><span class="by">gymbeaux</span><span>|</span><a href="#36549756">prev</a><span>|</span><a href="#36549743">next</a><span>|</span><label class="collapse" for="c-36549911">[-]</label><label class="expand" for="c-36549911">[1 more]</label></div><br/><div class="children"><div class="content">Things like this pop up relatively often but they never pick up steam and I am still using Nvidia GPUs. I would imagine this is no different.</div><br/></div></div><div id="36549743" class="c"><input type="checkbox" id="c-36549743" checked=""/><div class="controls bullet"><span class="by">saboot</span><span>|</span><a href="#36549911">prev</a><span>|</span><a href="#36551073">next</a><span>|</span><label class="collapse" for="c-36549743">[-]</label><label class="expand" for="c-36549743">[1 more]</label></div><br/><div class="children"><div class="content">That is quite interesting .. so I should be able to run my cuda accelerated programs on AMD and Intel devices then, correct?</div><br/></div></div><div id="36551073" class="c"><input type="checkbox" id="c-36551073" checked=""/><div class="controls bullet"><span class="by">einpoklum</span><span>|</span><a href="#36549743">prev</a><span>|</span><a href="#36549827">next</a><span>|</span><label class="collapse" for="c-36551073">[-]</label><label class="expand" for="c-36551073">[3 more]</label></div><br/><div class="children"><div class="content">1. This implements the clunky C-ish API; there&#x27;s also the Modern-C++ API wrappers, with automatic error checking, RAII resource control etc.; see: <a href="https:&#x2F;&#x2F;github.com&#x2F;eyalroz&#x2F;cuda-api-wrappers">https:&#x2F;&#x2F;github.com&#x2F;eyalroz&#x2F;cuda-api-wrappers</a> (due disclosure: I&#x27;m the author)<p>2. Implementing the _runtime_ API is not the right choice; it&#x27;s important to implement the _driver_ API, otherwise you can&#x27;t isolate contexts, dynamically add newly-compiled JIT kernels via modules etc.<p>3. This is less than 3000 lines of code. Wrapping all of the core CUDA APIs (driver, runtime, NVTX, JIT compilation of CUDA-C++ and of PTX) took me &gt; 14,000 LoC.</div><br/><div id="36553575" class="c"><input type="checkbox" id="c-36553575" checked=""/><div class="controls bullet"><span class="by">rootw0rm</span><span>|</span><a href="#36551073">parent</a><span>|</span><a href="#36549827">next</a><span>|</span><label class="collapse" for="c-36553575">[-]</label><label class="expand" for="c-36553575">[2 more]</label></div><br/><div class="children"><div class="content">nice project.  this is why HN kicks ass</div><br/><div id="36555474" class="c"><input type="checkbox" id="c-36555474" checked=""/><div class="controls bullet"><span class="by">einpoklum</span><span>|</span><a href="#36551073">root</a><span>|</span><a href="#36553575">parent</a><span>|</span><a href="#36549827">next</a><span>|</span><label class="collapse" for="c-36555474">[-]</label><label class="expand" for="c-36555474">[1 more]</label></div><br/><div class="children"><div class="content">Thanks for the compliment :-)<p>What I _really_ like to receive, though, is feedback from using the wrappers, ideas for changes&#x2F;improvements, and of course messages volunteering to QA new versions before their release :-P</div><br/></div></div></div></div></div></div><div id="36549827" class="c"><input type="checkbox" id="c-36549827" checked=""/><div class="controls bullet"><span class="by">AndrewKemendo</span><span>|</span><a href="#36551073">prev</a><span>|</span><a href="#36551483">next</a><span>|</span><label class="collapse" for="c-36549827">[-]</label><label class="expand" for="c-36549827">[11 more]</label></div><br/><div class="children"><div class="content">This could be a big deal if we have an actual alternative to CUDA<p>I can’t see NVIDIA letting this just exist</div><br/><div id="36549894" class="c"><input type="checkbox" id="c-36549894" checked=""/><div class="controls bullet"><span class="by">Ballas</span><span>|</span><a href="#36549827">parent</a><span>|</span><a href="#36550031">next</a><span>|</span><label class="collapse" for="c-36549894">[-]</label><label class="expand" for="c-36549894">[6 more]</label></div><br/><div class="children"><div class="content">My opinion is that CUDA is not the mote keeping the others out - it&#x27;s the CUDNN (and CUBLAS), more specifically the level to which they are optimized.</div><br/><div id="36549986" class="c"><input type="checkbox" id="c-36549986" checked=""/><div class="controls bullet"><span class="by">roenxi</span><span>|</span><a href="#36549827">root</a><span>|</span><a href="#36549894">parent</a><span>|</span><a href="#36550020">next</a><span>|</span><label class="collapse" for="c-36549986">[-]</label><label class="expand" for="c-36549986">[4 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not even certain optimisation matters. I can crash my machine (AMD graphics) with a stock Debian install by letting something attempt BLAS on the GPU.<p>The situation is starting to improve though. Installed a bunch of libraries from <a href="https:&#x2F;&#x2F;repo.radeon.com&#x2F;rocm&#x2F;apt&#x2F;5.4" rel="nofollow noreferrer">https:&#x2F;&#x2F;repo.radeon.com&#x2F;rocm&#x2F;apt&#x2F;5.4</a> jammy main and the crashes got less frequent. I don&#x27;t have a lot of faith in AMD to deliver reliable BLAS libraries at this point, but it could happen. The hardware is there, I just don&#x27;t think they&#x27;re prioritising supporting the right places in the distribution chain or supporting consumer-level graphics.</div><br/><div id="36559561" class="c"><input type="checkbox" id="c-36559561" checked=""/><div class="controls bullet"><span class="by">Ballas</span><span>|</span><a href="#36549827">root</a><span>|</span><a href="#36549986">parent</a><span>|</span><a href="#36551240">next</a><span>|</span><label class="collapse" for="c-36559561">[-]</label><label class="expand" for="c-36559561">[1 more]</label></div><br/><div class="children"><div class="content">I do find it strange that AMD is not allocating more resources to ROCM, given that that seems to be where the money is, at least from my viewpoint. I guess they have been able to sell more cards than they could manufacture, but that seems to be changing.</div><br/></div></div><div id="36551240" class="c"><input type="checkbox" id="c-36551240" checked=""/><div class="controls bullet"><span class="by">metal_am</span><span>|</span><a href="#36549827">root</a><span>|</span><a href="#36549986">parent</a><span>|</span><a href="#36559561">prev</a><span>|</span><a href="#36550020">next</a><span>|</span><label class="collapse" for="c-36551240">[-]</label><label class="expand" for="c-36551240">[2 more]</label></div><br/><div class="children"><div class="content">How about something like MAGMA?</div><br/><div id="36557942" class="c"><input type="checkbox" id="c-36557942" checked=""/><div class="controls bullet"><span class="by">roenxi</span><span>|</span><a href="#36549827">root</a><span>|</span><a href="#36551240">parent</a><span>|</span><a href="#36550020">next</a><span>|</span><label class="collapse" for="c-36557942">[-]</label><label class="expand" for="c-36557942">[1 more]</label></div><br/><div class="children"><div class="content">No idea. But if it goes through OpenCl it will likely expose the same bugs.</div><br/></div></div></div></div></div></div></div></div><div id="36550031" class="c"><input type="checkbox" id="c-36550031" checked=""/><div class="controls bullet"><span class="by">flykespice</span><span>|</span><a href="#36549827">parent</a><span>|</span><a href="#36549894">prev</a><span>|</span><a href="#36551483">next</a><span>|</span><label class="collapse" for="c-36550031">[-]</label><label class="expand" for="c-36550031">[4 more]</label></div><br/><div class="children"><div class="content">And on what legal ground would NVIDIA have to take this down?</div><br/><div id="36550528" class="c"><input type="checkbox" id="c-36550528" checked=""/><div class="controls bullet"><span class="by">themoonisachees</span><span>|</span><a href="#36549827">root</a><span>|</span><a href="#36550031">parent</a><span>|</span><a href="#36551483">next</a><span>|</span><label class="collapse" for="c-36550528">[-]</label><label class="expand" for="c-36550528">[3 more]</label></div><br/><div class="children"><div class="content">When you have Nvidia money you don&#x27;t need grounds to sue, the lawyers will think of something and drag any open-source devs through years-long suits.<p>The only saving grace would be Oracle v Google which established the de jure that an API isn&#x27;t copyrightable.</div><br/><div id="36550709" class="c"><input type="checkbox" id="c-36550709" checked=""/><div class="controls bullet"><span class="by">hedora</span><span>|</span><a href="#36549827">root</a><span>|</span><a href="#36550528">parent</a><span>|</span><a href="#36557752">next</a><span>|</span><label class="collapse" for="c-36550709">[-]</label><label class="expand" for="c-36550709">[1 more]</label></div><br/><div class="children"><div class="content">APIs weren&#x27;t copyrightable before Oracle v Google.  There was plenty of precedent saying that.  For example, before they were called Oracle, they built a clone of IBM SEQUEL.<p>The main concern with Oracle v Google was that the court would ignore or misinterpret the existing precedent.<p>A secondary concern was that a Google employee formerly worked on Java at Sun (and&#x2F;or Oracle), and copy-pasted some implementation source code from oracle to google&#x27;s code bases.  There was a real possibility the &quot;APIs aren&#x27;t copyrightable&quot; precedent would stand, but the courts would rule that Google couldn&#x27;t continue distributing Dalvik.</div><br/></div></div><div id="36557752" class="c"><input type="checkbox" id="c-36557752" checked=""/><div class="controls bullet"><span class="by">aidenn0</span><span>|</span><a href="#36549827">root</a><span>|</span><a href="#36550528">parent</a><span>|</span><a href="#36550709">prev</a><span>|</span><a href="#36551483">next</a><span>|</span><label class="collapse" for="c-36557752">[-]</label><label class="expand" for="c-36557752">[1 more]</label></div><br/><div class="children"><div class="content">I thought that Oracle v Google established that APIs <i>are</i> copyrightable, but Google&#x27;s copying met the terms for fair use?</div><br/></div></div></div></div></div></div></div></div><div id="36551483" class="c"><input type="checkbox" id="c-36551483" checked=""/><div class="controls bullet"><span class="by">xeonmc</span><span>|</span><a href="#36549827">prev</a><span>|</span><a href="#36549769">next</a><span>|</span><label class="collapse" for="c-36551483">[-]</label><label class="expand" for="c-36551483">[3 more]</label></div><br/><div class="children"><div class="content">Huge missed opportunity to call it &quot;Vuudoo&quot;</div><br/><div id="36556787" class="c"><input type="checkbox" id="c-36556787" checked=""/><div class="controls bullet"><span class="by">Conscat</span><span>|</span><a href="#36551483">parent</a><span>|</span><a href="#36549769">next</a><span>|</span><label class="collapse" for="c-36556787">[-]</label><label class="expand" for="c-36556787">[2 more]</label></div><br/><div class="children"><div class="content">Might be confusing with Voodoo<p><a href="https:&#x2F;&#x2F;github.com&#x2F;cogciprocate&#x2F;voodoo">https:&#x2F;&#x2F;github.com&#x2F;cogciprocate&#x2F;voodoo</a></div><br/><div id="36558106" class="c"><input type="checkbox" id="c-36558106" checked=""/><div class="controls bullet"><span class="by">userbinator</span><span>|</span><a href="#36551483">root</a><span>|</span><a href="#36556787">parent</a><span>|</span><a href="#36549769">next</a><span>|</span><label class="collapse" for="c-36558106">[-]</label><label class="expand" for="c-36558106">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s already confusing enough with the 3dfx GPUs of the same name:<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;3dfx_Interactive#Product_development_history" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;3dfx_Interactive#Product_devel...</a></div><br/></div></div></div></div></div></div><div id="36549769" class="c"><input type="checkbox" id="c-36549769" checked=""/><div class="controls bullet"><span class="by">DrNosferatu</span><span>|</span><a href="#36551483">prev</a><span>|</span><a href="#36556131">next</a><span>|</span><label class="collapse" for="c-36549769">[-]</label><label class="expand" for="c-36549769">[4 more]</label></div><br/><div class="children"><div class="content">Sounds great!<p>How far is it actually compatible right now?<p>Are there any tests &#x2F; benchmarks?<p>Can this be used to run CUDA-accelerated LLMs?</div><br/><div id="36550253" class="c"><input type="checkbox" id="c-36550253" checked=""/><div class="controls bullet"><span class="by">syntaxers</span><span>|</span><a href="#36549769">parent</a><span>|</span><a href="#36550019">next</a><span>|</span><label class="collapse" for="c-36550253">[-]</label><label class="expand" for="c-36550253">[1 more]</label></div><br/><div class="children"><div class="content">&gt; &gt; VUDA only takes kernels in SPIR-V format. VUDA does not provide any support for compiling CUDA C kernels directly to SPIR-V (yet). However, it does not know or care how the SPIR-V source was created - may it be GLSL, HLSL, OpenCL.<p>So the answer is no, it can&#x27;t be used with kernels that use cublas or cudnn, which excludes almost all ML use-cases.</div><br/></div></div><div id="36550019" class="c"><input type="checkbox" id="c-36550019" checked=""/><div class="controls bullet"><span class="by">johndough</span><span>|</span><a href="#36549769">parent</a><span>|</span><a href="#36550253">prev</a><span>|</span><a href="#36556131">next</a><span>|</span><label class="collapse" for="c-36550019">[-]</label><label class="expand" for="c-36550019">[2 more]</label></div><br/><div class="children"><div class="content">The Vulkan spec does not enforce strict IEEE 754 floating point semantics, so perfect compatibility with CUDA is impossible.<p><a href="https:&#x2F;&#x2F;registry.khronos.org&#x2F;vulkan&#x2F;specs&#x2F;1.3-khr-extensions&#x2F;html&#x2F;chap43.html#spirvenv-op-prec" rel="nofollow noreferrer">https:&#x2F;&#x2F;registry.khronos.org&#x2F;vulkan&#x2F;specs&#x2F;1.3-khr-extensions...</a><p>However, the deep learning field does currently not pay much attention to reproducibility, so this might not be a big issue.</div><br/><div id="36550053" class="c"><input type="checkbox" id="c-36550053" checked=""/><div class="controls bullet"><span class="by">my123</span><span>|</span><a href="#36549769">root</a><span>|</span><a href="#36550019">parent</a><span>|</span><a href="#36556131">next</a><span>|</span><label class="collapse" for="c-36550053">[-]</label><label class="expand" for="c-36550053">[1 more]</label></div><br/><div class="children"><div class="content">Memory management in Vulkan is _very_ restricted. Nothing remotely like UVM. CUDA on Vulkan for these reasons will always stay a pet project at best, with no shot at usable quality whatsoever.</div><br/></div></div></div></div></div></div><div id="36556131" class="c"><input type="checkbox" id="c-36556131" checked=""/><div class="controls bullet"><span class="by">jaimex2</span><span>|</span><a href="#36549769">prev</a><span>|</span><a href="#36549772">next</a><span>|</span><label class="collapse" for="c-36556131">[-]</label><label class="expand" for="c-36556131">[1 more]</label></div><br/><div class="children"><div class="content">I have no hope for AMD. They should have made compatibility tools yesterday.</div><br/></div></div><div id="36549772" class="c"><input type="checkbox" id="c-36549772" checked=""/><div class="controls bullet"><span class="by">empyrrhicist</span><span>|</span><a href="#36556131">prev</a><span>|</span><label class="collapse" for="c-36549772">[-]</label><label class="expand" for="c-36549772">[1 more]</label></div><br/><div class="children"><div class="content">Doesn&#x27;t look very active, does it still work?</div><br/></div></div></div></div></div></div></div></body></html>