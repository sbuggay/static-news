<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1687942852557" as="style"/><link rel="stylesheet" href="styles.css?v=1687942852557"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://blogs.nvidia.com/blog/2023/06/27/generative-ai-debut-mlperf/">H100 GPUs Set Standard for Gen AI in Debut MLPerf Benchmark</a> <span class="domain">(<a href="https://blogs.nvidia.com">blogs.nvidia.com</a>)</span></div><div class="subtext"><span>Anon84</span> | <span>59 comments</span></div><br/><div><div id="36499926" class="c"><input type="checkbox" id="c-36499926" checked=""/><div class="controls bullet"><span class="by">ed</span><span>|</span><a href="#36500033">next</a><span>|</span><label class="collapse" for="c-36499926">[-]</label><label class="expand" for="c-36499926">[25 more]</label></div><br/><div class="children"><div class="content">These could train GPT-3 in 46 hours. (Edited from &quot;11 mins&quot; per <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36500154">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36500154</a> )<p>An equivalent number of V100&#x27;s (GPT-3&#x27;s original GPU) would&#x27;ve taken about 36 days [0].<p>0 – <a href="https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;GPT3&#x2F;comments&#x2F;p1xf10&#x2F;comment&#x2F;h8h3sl4&#x2F;?utm_source=reddit&amp;utm_medium=web2x&amp;context=3" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;GPT3&#x2F;comments&#x2F;p1xf10&#x2F;comment&#x2F;h8h3sl...</a></div><br/><div id="36500023" class="c"><input type="checkbox" id="c-36500023" checked=""/><div class="controls bullet"><span class="by">april7</span><span>|</span><a href="#36499926">parent</a><span>|</span><a href="#36500825">next</a><span>|</span><label class="collapse" for="c-36500023">[-]</label><label class="expand" for="c-36500023">[7 more]</label></div><br/><div class="children"><div class="content">Kind of. This tweet better explains what they did:<p><a href="https:&#x2F;&#x2F;twitter.com&#x2F;abhi_venigalla&#x2F;status&#x2F;1673813863186452480?s=20" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;abhi_venigalla&#x2F;status&#x2F;167381386318645248...</a></div><br/><div id="36500154" class="c"><input type="checkbox" id="c-36500154" checked=""/><div class="controls bullet"><span class="by">smaddox</span><span>|</span><a href="#36499926">root</a><span>|</span><a href="#36500023">parent</a><span>|</span><a href="#36500825">next</a><span>|</span><label class="collapse" for="c-36500154">[-]</label><label class="expand" for="c-36500154">[6 more]</label></div><br/><div class="children"><div class="content">So it would be more like 46 hours to train GPT-3 from scratch.<p><pre><code>    (300BT &#x2F; 1.2BT) * 11 min * (1 hr &#x2F; 60 min) = 45.8 hr
</code></pre>
Still pretty incredible. That&#x27;s an 18.8x speedup over 36 days.</div><br/><div id="36501760" class="c"><input type="checkbox" id="c-36501760" checked=""/><div class="controls bullet"><span class="by">lumost</span><span>|</span><a href="#36499926">root</a><span>|</span><a href="#36500154">parent</a><span>|</span><a href="#36500215">next</a><span>|</span><label class="collapse" for="c-36501760">[-]</label><label class="expand" for="c-36501760">[3 more]</label></div><br/><div class="children"><div class="content">This points to an interesting future for foundation models. This is an 18x cost reduction in only 2 years. Either foundation models are going to get much bigger, or variations will become common.</div><br/><div id="36503214" class="c"><input type="checkbox" id="c-36503214" checked=""/><div class="controls bullet"><span class="by">rerx</span><span>|</span><a href="#36499926">root</a><span>|</span><a href="#36501760">parent</a><span>|</span><a href="#36503670">next</a><span>|</span><label class="collapse" for="c-36503214">[-]</label><label class="expand" for="c-36503214">[1 more]</label></div><br/><div class="children"><div class="content">V100 GPUs are from 2017, so it&#x27;s more than two years. A100 already appeared there years ago, btw.<p>An eight GPU DGX-1 server cost ~149k$ back then (googled news postings). A current gen DGX H100 is 520k$ with 5 years of support. Of course it holds 5x the memory, plus GPUs and interconnect are much faster. But when comparing costs, take price hikes into account.</div><br/></div></div><div id="36503670" class="c"><input type="checkbox" id="c-36503670" checked=""/><div class="controls bullet"><span class="by">raverbashing</span><span>|</span><a href="#36499926">root</a><span>|</span><a href="#36501760">parent</a><span>|</span><a href="#36503214">prev</a><span>|</span><a href="#36500215">next</a><span>|</span><label class="collapse" for="c-36503670">[-]</label><label class="expand" for="c-36503670">[1 more]</label></div><br/><div class="children"><div class="content">Variations of specializations I guess<p>For writing code you don&#x27;t care about feeding world history to your model. So a smaller model might be better at a specialized task<p>Sure, having a big multi-modal-model is great, but by having specialized models you can spread tasks better</div><br/></div></div></div></div></div></div></div></div><div id="36500825" class="c"><input type="checkbox" id="c-36500825" checked=""/><div class="controls bullet"><span class="by">usaar333</span><span>|</span><a href="#36499926">parent</a><span>|</span><a href="#36500023">prev</a><span>|</span><a href="#36501278">next</a><span>|</span><label class="collapse" for="c-36500825">[-]</label><label class="expand" for="c-36500825">[6 more]</label></div><br/><div class="children"><div class="content">Your citation is for 1k A100s, not 3.5k V100s.  I think it&#x27;s actually ~51 days on 3.5k V100s.<p>Just to compare the GPUs, TF32 Tensor processing went from ~125 TFlops to ~990.  It then looks like they also dropped the precision to FP8, which gives you another 4x win.<p>What&#x27;s interesting is to look at how we&#x27;re progressing in performance over time.  In some sense, a bit slow?<p>A V100 costs $10k at release; an H100 seems to be $40k.<p>So we&#x27;ve only managed to halve the cost of a flop in 5 years.  That seems.. much slower than what Moore&#x27;s Law would have suggested.</div><br/><div id="36502402" class="c"><input type="checkbox" id="c-36502402" checked=""/><div class="controls bullet"><span class="by">ac29</span><span>|</span><a href="#36499926">root</a><span>|</span><a href="#36500825">parent</a><span>|</span><a href="#36500894">next</a><span>|</span><label class="collapse" for="c-36502402">[-]</label><label class="expand" for="c-36502402">[2 more]</label></div><br/><div class="children"><div class="content">&gt; So we&#x27;ve only managed to halve the cost of a flop in 5 years. That seems.. much slower than what Moore&#x27;s Law would have suggested.<p>Moore&#x27;s law says nothing about price or performance.<p>H100 has about 4x as many transistors as V100, which is pretty close to what Moore&#x27;s law would predict.</div><br/><div id="36503076" class="c"><input type="checkbox" id="c-36503076" checked=""/><div class="controls bullet"><span class="by">esperent</span><span>|</span><a href="#36499926">root</a><span>|</span><a href="#36502402">parent</a><span>|</span><a href="#36500894">next</a><span>|</span><label class="collapse" for="c-36503076">[-]</label><label class="expand" for="c-36503076">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Moore&#x27;s law says nothing about price or performance.<p>Moore&#x27;s law is about doubling of transistor count for the same price. At least that&#x27;s always been my understanding.<p>EDIT: I decided to look it up. Heres the original 1975 statement from him that led to the law:<p><i>&quot;The complexity for minimum component costs has increased at a rate of roughly a factor of two per year. Certainly over the short term this rate can be expected to continue, if not to increase. Over the longer term, the rate of increase is a bit more uncertain, although there is no reason to believe it will not remain nearly constant for at least 10 years.&quot;</i><p>So yup, it&#x27;s about transistor density vs price.</div><br/></div></div></div></div><div id="36500894" class="c"><input type="checkbox" id="c-36500894" checked=""/><div class="controls bullet"><span class="by">winwang</span><span>|</span><a href="#36499926">root</a><span>|</span><a href="#36500825">parent</a><span>|</span><a href="#36502402">prev</a><span>|</span><a href="#36501278">next</a><span>|</span><label class="collapse" for="c-36500894">[-]</label><label class="expand" for="c-36500894">[3 more]</label></div><br/><div class="children"><div class="content">What about power draw? Quick google says V100 is max 300W while H100 is max 700W TDP, which makes the cost more favorable than 4x, so more like 7x less per flop. *assuming* the same electricity cost, which actually seems to have increased significantly.<p>On a (minor) side note, it seems that $1.00 from 2018 is worth ~$1.20 in 2023. I wish more cost comparisons included inflation, because the past few years have had a lot of it.</div><br/><div id="36500986" class="c"><input type="checkbox" id="c-36500986" checked=""/><div class="controls bullet"><span class="by">usaar333</span><span>|</span><a href="#36499926">root</a><span>|</span><a href="#36500894">parent</a><span>|</span><a href="#36501278">next</a><span>|</span><label class="collapse" for="c-36500986">[-]</label><label class="expand" for="c-36500986">[2 more]</label></div><br/><div class="children"><div class="content">Good call on power draw, but it seems dwarfed by capital cost.  Assuming 3 year life (this tech gets outdated..), 300W constant consumption costs under $1k at $0.3&#x2F;kwh.<p>You need to be an order of magnitude higher in power usage before it really starts mattering.  e.g. a Tesla3 consumes around 15 KW (20x the H100) while driving.<p>That said it looks like flops&#x2F;watt dropped by only 3.4x, which is also sub Moore&#x27;s Law (3 years to halve power consumption)</div><br/><div id="36501227" class="c"><input type="checkbox" id="c-36501227" checked=""/><div class="controls bullet"><span class="by">TOMDM</span><span>|</span><a href="#36499926">root</a><span>|</span><a href="#36500986">parent</a><span>|</span><a href="#36501278">next</a><span>|</span><label class="collapse" for="c-36501227">[-]</label><label class="expand" for="c-36501227">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think flops&#x2F;$ is enough to really capture the difference here.<p>You couldn&#x27;t replicate the scale of compute this allows no matter how many V100&#x27;s you had.<p>A huge amount of cost here is embodied in networking and memory.<p>If one were to design a chip that cared only for flop&#x2F;$ without caring for all of the interconnect and memory, then the 4090 is a much fairer comparison, and even then that card isn&#x27;t designed for a flop&#x2F;$ optimisation.</div><br/></div></div></div></div></div></div></div></div><div id="36501278" class="c"><input type="checkbox" id="c-36501278" checked=""/><div class="controls bullet"><span class="by">godelski</span><span>|</span><a href="#36499926">parent</a><span>|</span><a href="#36500825">prev</a><span>|</span><a href="#36499975">next</a><span>|</span><label class="collapse" for="c-36501278">[-]</label><label class="expand" for="c-36501278">[2 more]</label></div><br/><div class="children"><div class="content">With 3,584 GPUs, or 448 Nodes w&#x2F; 8GPUs&#x2F;node. At 5 nodes&#x2F;rack, that&#x27;s 90 racks. I looked and found and old listing for Lambda&#x27;s Echelon racks about $650k. So the infra cost is a little under $6 million.<p>If you bought the $2&#x2F;hr H100 instance they offer, that would cost ~$330k. Pricey, but not too bad.<p>My bigger hope is that with cheaper compute we can see more architecture search and designs. A lot of different architectures are relatively unexplored due to computational constraints and are typically performed by smaller labs so they don&#x27;t scale and it is kinda hard to compare models when we&#x27;re just looking at performance benchmarks and not considering other factors. We definitely don&#x27;t want big labs to railroad our research directions. Feels weird that a huge amount of NLP is based on using pretrained models and tuning them. Vision is going this way too. You basically can&#x27;t get published without being SOTA so you basically have to modify an existing model or have a multi-million dollar lab and train from scratch. Really weird to expect academia to compete with big labs and really weird to not let academia take &quot;bigger risks&quot; and explore less popular areas. It is vital to our research path that we don&#x27;t force everything onto a single track.</div><br/><div id="36502866" class="c"><input type="checkbox" id="c-36502866" checked=""/><div class="controls bullet"><span class="by">m00x</span><span>|</span><a href="#36499926">root</a><span>|</span><a href="#36501278">parent</a><span>|</span><a href="#36499975">next</a><span>|</span><label class="collapse" for="c-36502866">[-]</label><label class="expand" for="c-36502866">[1 more]</label></div><br/><div class="children"><div class="content">H100s are now around 30k USD if you&#x27;re lucky, going up to 40k on Ebay&#x2F;Amazon.<p>3,584 GPUs at $30,000 is $104,550,000 USD only in GPUs.</div><br/></div></div></div></div><div id="36499975" class="c"><input type="checkbox" id="c-36499975" checked=""/><div class="controls bullet"><span class="by">messe</span><span>|</span><a href="#36499926">parent</a><span>|</span><a href="#36501278">prev</a><span>|</span><a href="#36499997">next</a><span>|</span><label class="collapse" for="c-36499975">[-]</label><label class="expand" for="c-36499975">[7 more]</label></div><br/><div class="children"><div class="content">3500 of them trained GPT-3 in 11 minutes. That number is still worth remarking.</div><br/><div id="36500739" class="c"><input type="checkbox" id="c-36500739" checked=""/><div class="controls bullet"><span class="by">layoric</span><span>|</span><a href="#36499926">root</a><span>|</span><a href="#36499975">parent</a><span>|</span><a href="#36500013">next</a><span>|</span><label class="collapse" for="c-36500739">[-]</label><label class="expand" for="c-36500739">[1 more]</label></div><br/><div class="children"><div class="content">GPT3 benchmark, as others have said this means it would be ~46 hours to train GPT, still impressive! Also, going by other comments here, ~3500 of these or 13-14 DGX GH200s at ~$10m each means we are talking about ~$135m worth of compute here. Still very impressive but holy hell that is a lot of money worth of compute hardware.</div><br/></div></div><div id="36500013" class="c"><input type="checkbox" id="c-36500013" checked=""/><div class="controls bullet"><span class="by">reaperman</span><span>|</span><a href="#36499926">root</a><span>|</span><a href="#36499975">parent</a><span>|</span><a href="#36500739">prev</a><span>|</span><a href="#36500581">next</a><span>|</span><label class="collapse" for="c-36500013">[-]</label><label class="expand" for="c-36500013">[4 more]</label></div><br/><div class="children"><div class="content">It’s remarkable that one of these could train GPT-3 in under a month. However, good to note that its the price is that of twenty 4090’s.</div><br/><div id="36500658" class="c"><input type="checkbox" id="c-36500658" checked=""/><div class="controls bullet"><span class="by">cavisne</span><span>|</span><a href="#36499926">root</a><span>|</span><a href="#36500013">parent</a><span>|</span><a href="#36500550">next</a><span>|</span><label class="collapse" for="c-36500658">[-]</label><label class="expand" for="c-36500658">[1 more]</label></div><br/><div class="children"><div class="content">One interesting thing is if the model can’t fit into GPU memory (sharded across multiple chips) it would be much slower. So one chip would take more than a month.<p>That’s why these clusters are so valuable, even with Nvidias margins they are still cheaper than using less compute for longer.</div><br/></div></div><div id="36500550" class="c"><input type="checkbox" id="c-36500550" checked=""/><div class="controls bullet"><span class="by">ClassyJacket</span><span>|</span><a href="#36499926">root</a><span>|</span><a href="#36500013">parent</a><span>|</span><a href="#36500658">prev</a><span>|</span><a href="#36500581">next</a><span>|</span><label class="collapse" for="c-36500550">[-]</label><label class="expand" for="c-36500550">[2 more]</label></div><br/><div class="children"><div class="content">Could it actually? Or do you need the memory size of thousands of them running in parallel?</div><br/><div id="36501249" class="c"><input type="checkbox" id="c-36501249" checked=""/><div class="controls bullet"><span class="by">reaperman</span><span>|</span><a href="#36499926">root</a><span>|</span><a href="#36500550">parent</a><span>|</span><a href="#36500581">next</a><span>|</span><label class="collapse" for="c-36501249">[-]</label><label class="expand" for="c-36501249">[1 more]</label></div><br/><div class="children"><div class="content">Yes I worded that <i>extremely</i> poorly.</div><br/></div></div></div></div></div></div><div id="36500581" class="c"><input type="checkbox" id="c-36500581" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#36499926">root</a><span>|</span><a href="#36499975">parent</a><span>|</span><a href="#36500013">prev</a><span>|</span><a href="#36499997">next</a><span>|</span><label class="collapse" for="c-36500581">[-]</label><label class="expand" for="c-36500581">[1 more]</label></div><br/><div class="children"><div class="content">title says: &quot;a massive GPT-3-based benchmark&quot;<p>that means they might pass a few batches through a GPT-3 sized random init network and time it</div><br/></div></div></div></div><div id="36499997" class="c"><input type="checkbox" id="c-36499997" checked=""/><div class="controls bullet"><span class="by">zetazzed</span><span>|</span><a href="#36499926">parent</a><span>|</span><a href="#36499975">prev</a><span>|</span><a href="#36501876">next</a><span>|</span><label class="collapse" for="c-36499997">[-]</label><label class="expand" for="c-36499997">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, it&#x27;s wild - feels like we see &quot;software is so slow now! nobody optimizes software anymore, they just run Python and burn cycles!&quot; posts all the time, but man, when a company REALLY wants to optimize something -- it&#x27;s a thing of beauty.</div><br/></div></div></div></div><div id="36500033" class="c"><input type="checkbox" id="c-36500033" checked=""/><div class="controls bullet"><span class="by">hinkley</span><span>|</span><a href="#36499926">prev</a><span>|</span><a href="#36499418">next</a><span>|</span><label class="collapse" for="c-36500033">[-]</label><label class="expand" for="c-36500033">[5 more]</label></div><br/><div class="children"><div class="content">I am keeping my fingers crossed that there will be a &#x27;Bloom Filter&#x27; moment for AI where we create an algorithm that can eliminate an expensive calculation in 99% of interactions and give us a 10x speedup in some larger problem domain.<p>Or some other &#x27;trust but verify&#x27; situation where the suggested action is still validated against business rules that have some notion of consumer protection.</div><br/><div id="36501247" class="c"><input type="checkbox" id="c-36501247" checked=""/><div class="controls bullet"><span class="by">usaar333</span><span>|</span><a href="#36500033">parent</a><span>|</span><a href="#36499418">next</a><span>|</span><label class="collapse" for="c-36501247">[-]</label><label class="expand" for="c-36501247">[4 more]</label></div><br/><div class="children"><div class="content">Dropping numerical precision seems to have done that to some degree?</div><br/><div id="36503541" class="c"><input type="checkbox" id="c-36503541" checked=""/><div class="controls bullet"><span class="by">dsign</span><span>|</span><a href="#36500033">root</a><span>|</span><a href="#36501247">parent</a><span>|</span><a href="#36502383">next</a><span>|</span><label class="collapse" for="c-36503541">[-]</label><label class="expand" for="c-36503541">[2 more]</label></div><br/><div class="children"><div class="content">I think the parent is referring to the fact that LLMs and generative models are, for the time being, “creating new markets” and “creating new problems”, but not really solving any of the hard problems we already have. I see it this way: you have this incredible piece of technology. You can use it to take the scraps away from a bunch of starving artists, and convert that survival income in wealth for some entrepreneur. Or you can use it to cure cancer or aging or make fossil-free airplanes. At the moment, the first application seems to be the one moving the market, and that’s really sad.<p>On the side of hope, if somebody were to demonstrate how to use a bunch of GPUs to make the e-coli bacteria live for a little longer using an approach that has a semblance of generality, I guarantee that a lot of old people would be willing to part with their fortunes in exchange for a sliver of hope for them or future generations.</div><br/><div id="36503583" class="c"><input type="checkbox" id="c-36503583" checked=""/><div class="controls bullet"><span class="by">soultrees</span><span>|</span><a href="#36500033">root</a><span>|</span><a href="#36503541">parent</a><span>|</span><a href="#36502383">next</a><span>|</span><label class="collapse" for="c-36503583">[-]</label><label class="expand" for="c-36503583">[1 more]</label></div><br/><div class="children"><div class="content">That’s only because the companies with marketing budgets and marketing teams are the ones you are implying.<p>There is serious research going down right now, but you don’t see you typical medical research department at your university buying ads on Instagram.</div><br/></div></div></div></div><div id="36502383" class="c"><input type="checkbox" id="c-36502383" checked=""/><div class="controls bullet"><span class="by">hinkley</span><span>|</span><a href="#36500033">root</a><span>|</span><a href="#36501247">parent</a><span>|</span><a href="#36503541">prev</a><span>|</span><a href="#36499418">next</a><span>|</span><label class="collapse" for="c-36502383">[-]</label><label class="expand" for="c-36502383">[1 more]</label></div><br/><div class="children"><div class="content">You have a deterministic AI program to show me?</div><br/></div></div></div></div></div></div><div id="36499418" class="c"><input type="checkbox" id="c-36499418" checked=""/><div class="controls bullet"><span class="by">tikkun</span><span>|</span><a href="#36500033">prev</a><span>|</span><a href="#36501553">next</a><span>|</span><label class="collapse" for="c-36499418">[-]</label><label class="expand" for="c-36499418">[3 more]</label></div><br/><div class="children"><div class="content">If you want to try one, some good options are:<p>FluidStack or Lambda Labs<p>If you need to rent a supercluster and you’re not tied to one of the big 3 clouds, then talk with FluidStack, Lambda, Oracle, maybe CoreWeave.</div><br/><div id="36501160" class="c"><input type="checkbox" id="c-36501160" checked=""/><div class="controls bullet"><span class="by">rch</span><span>|</span><a href="#36499418">parent</a><span>|</span><a href="#36501553">next</a><span>|</span><label class="collapse" for="c-36501160">[-]</label><label class="expand" for="c-36501160">[2 more]</label></div><br/><div class="children"><div class="content">Lambda seems like the easiest to work with at present.</div><br/><div id="36501729" class="c"><input type="checkbox" id="c-36501729" checked=""/><div class="controls bullet"><span class="by">tikkun</span><span>|</span><a href="#36499418">root</a><span>|</span><a href="#36501160">parent</a><span>|</span><a href="#36501553">next</a><span>|</span><label class="collapse" for="c-36501729">[-]</label><label class="expand" for="c-36501729">[1 more]</label></div><br/><div class="children"><div class="content">I’ve used both and found both to work well for me. There are a variety of other gpu cloud options that aren’t good, though. I listed a bunch here, some are good, some seem to be worse on all dimensions (price, capacity, and UX) - <a href="https:&#x2F;&#x2F;gpus.llm-utils.org&#x2F;alternative-gpu-clouds&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;gpus.llm-utils.org&#x2F;alternative-gpu-clouds&#x2F;</a><p>Tl;dr of the good ones: FluidStack and Lambda for H100s (1x instances), Runpod for A100s.</div><br/></div></div></div></div></div></div><div id="36501553" class="c"><input type="checkbox" id="c-36501553" checked=""/><div class="controls bullet"><span class="by">Karupan</span><span>|</span><a href="#36499418">prev</a><span>|</span><a href="#36500312">next</a><span>|</span><label class="collapse" for="c-36501553">[-]</label><label class="expand" for="c-36501553">[9 more]</label></div><br/><div class="children"><div class="content">Has AMD completely missed the ML&#x2F;AI train? I’m quite surprised that even for inference, there doesn’t seem to be a viable competitor to nvidia. Is there anything in AMD’s roadmap to suggest they are planning to even compete?</div><br/><div id="36503041" class="c"><input type="checkbox" id="c-36503041" checked=""/><div class="controls bullet"><span class="by">singhrac</span><span>|</span><a href="#36501553">parent</a><span>|</span><a href="#36502177">next</a><span>|</span><label class="collapse" for="c-36503041">[-]</label><label class="expand" for="c-36503041">[3 more]</label></div><br/><div class="children"><div class="content">Intel is much closer with Habana Gaudi2. Sometimes I’m unsure whether they even recognize it.<p>They also published MLPerf results today: <a href="https:&#x2F;&#x2F;habana.ai&#x2F;blog&#x2F;gaudi2-demonstrates-competitive-llm-performance-on-industry-benchmark-mlperf" rel="nofollow noreferrer">https:&#x2F;&#x2F;habana.ai&#x2F;blog&#x2F;gaudi2-demonstrates-competitive-llm-p...</a><p>With 384 Gaudi2s they did the LLM task in 312 minutes, compared to 46 minutes for 768 H100s. It’ll come down to cost, but given the H100 is a process node or two ahead (and much more expensive I imagine?), Intel is actually much closer than I had realized. They’re the only other to submit an MLPerf result for the LLM task, I think. All credit of course to Habana Labs which was acquired by Intel.</div><br/><div id="36503312" class="c"><input type="checkbox" id="c-36503312" checked=""/><div class="controls bullet"><span class="by">Karupan</span><span>|</span><a href="#36501553">root</a><span>|</span><a href="#36503041">parent</a><span>|</span><a href="#36502177">next</a><span>|</span><label class="collapse" for="c-36503312">[-]</label><label class="expand" for="c-36503312">[2 more]</label></div><br/><div class="children"><div class="content">As a ML outsider, this was the first I’ve ever heard of it. Obviously I’m not the target audience, but I’m just shocked that I didn’t even know Intel was in the game.</div><br/><div id="36503957" class="c"><input type="checkbox" id="c-36503957" checked=""/><div class="controls bullet"><span class="by">Dalewyn</span><span>|</span><a href="#36501553">root</a><span>|</span><a href="#36503312">parent</a><span>|</span><a href="#36502177">next</a><span>|</span><label class="collapse" for="c-36503957">[-]</label><label class="expand" for="c-36503957">[1 more]</label></div><br/><div class="children"><div class="content">Intel&#x27;s going big in their own way by putting &quot;AI&quot; accelerators and the like in their latest and future processors, kind of need to be living under a rock to just miss it in these kinds of tech circles.<p>But that said, Intel suffers from the same fundamental problem as AMD: They aren&#x27;t Nvidia and they can&#x27;t CUDA.</div><br/></div></div></div></div></div></div><div id="36502177" class="c"><input type="checkbox" id="c-36502177" checked=""/><div class="controls bullet"><span class="by">jiggawatts</span><span>|</span><a href="#36501553">parent</a><span>|</span><a href="#36503041">prev</a><span>|</span><a href="#36502121">next</a><span>|</span><label class="collapse" for="c-36502177">[-]</label><label class="expand" for="c-36502177">[1 more]</label></div><br/><div class="children"><div class="content">Their upcoming AMD MI300 APU looks very competitive with NVIDIA&#x27;s GH200.<p>The problem remains the lack of software support.</div><br/></div></div><div id="36502121" class="c"><input type="checkbox" id="c-36502121" checked=""/><div class="controls bullet"><span class="by">cavisne</span><span>|</span><a href="#36501553">parent</a><span>|</span><a href="#36502177">prev</a><span>|</span><a href="#36502869">next</a><span>|</span><label class="collapse" for="c-36502121">[-]</label><label class="expand" for="c-36502121">[1 more]</label></div><br/><div class="children"><div class="content">The &quot;even for inference&quot; thing has turned into a bit of a trap imo.<p>Data parallel models scaled up for training and then could run on individual chips, but these massive model parallel models require a couple of chips directly linked together even to do inference.<p>So the idea that a competitor could come in with a simple, cheap inference chip doesn&#x27;t really work.</div><br/></div></div><div id="36502869" class="c"><input type="checkbox" id="c-36502869" checked=""/><div class="controls bullet"><span class="by">rapsey</span><span>|</span><a href="#36501553">parent</a><span>|</span><a href="#36502121">prev</a><span>|</span><a href="#36500312">next</a><span>|</span><label class="collapse" for="c-36502869">[-]</label><label class="expand" for="c-36502869">[3 more]</label></div><br/><div class="children"><div class="content">AMD is bad at software and that is not changing so they will always be behind.</div><br/><div id="36503463" class="c"><input type="checkbox" id="c-36503463" checked=""/><div class="controls bullet"><span class="by">dsign</span><span>|</span><a href="#36501553">root</a><span>|</span><a href="#36502869">parent</a><span>|</span><a href="#36500312">next</a><span>|</span><label class="collapse" for="c-36503463">[-]</label><label class="expand" for="c-36503463">[2 more]</label></div><br/><div class="children"><div class="content">I agree with this. Even their GPU drivers for gaming are bad, they get stuck at “basic” things like MPEG encoding.<p>But I don’t understand why software is a problem for them with their deep pockets. It can’t possibly be dearth of talent, or that it is expensive. Here in Europe a good software engineer earns half of what a mediocre software engineer earns in USA, to say nothing of India or China. They could just hire a bunch of teams and up their software game.</div><br/><div id="36503704" class="c"><input type="checkbox" id="c-36503704" checked=""/><div class="controls bullet"><span class="by">rapsey</span><span>|</span><a href="#36501553">root</a><span>|</span><a href="#36503463">parent</a><span>|</span><a href="#36500312">next</a><span>|</span><label class="collapse" for="c-36503704">[-]</label><label class="expand" for="c-36503704">[1 more]</label></div><br/><div class="children"><div class="content">Hardware development is very different to software development. AMD is a hardware company and they probably run their software development badly.</div><br/></div></div></div></div></div></div></div></div><div id="36500312" class="c"><input type="checkbox" id="c-36500312" checked=""/><div class="controls bullet"><span class="by">SushiHippie</span><span>|</span><a href="#36501553">prev</a><span>|</span><a href="#36499898">next</a><span>|</span><label class="collapse" for="c-36500312">[-]</label><label class="expand" for="c-36500312">[8 more]</label></div><br/><div class="children"><div class="content">Does anyone know how much kWh was used (or could have probably been used) in these 11 minutes?</div><br/><div id="36500390" class="c"><input type="checkbox" id="c-36500390" checked=""/><div class="controls bullet"><span class="by">aiappreciator</span><span>|</span><a href="#36500312">parent</a><span>|</span><a href="#36499898">next</a><span>|</span><label class="collapse" for="c-36500390">[-]</label><label class="expand" for="c-36500390">[7 more]</label></div><br/><div class="children"><div class="content">H100s consume like 350W.
3000 H100s = 350kW
350*0.2h = 70kWh, about $20 at $0.3&#x2F;kWh (lets assume data centers have expensive electrical costs).</div><br/><div id="36502497" class="c"><input type="checkbox" id="c-36502497" checked=""/><div class="controls bullet"><span class="by">shaklee3</span><span>|</span><a href="#36500312">root</a><span>|</span><a href="#36500390">parent</a><span>|</span><a href="#36500485">next</a><span>|</span><label class="collapse" for="c-36502497">[-]</label><label class="expand" for="c-36502497">[2 more]</label></div><br/><div class="children"><div class="content">You can&#x27;t really use 350W. It&#x27;s very rare for a workload to consume the full TDP.</div><br/><div id="36503405" class="c"><input type="checkbox" id="c-36503405" checked=""/><div class="controls bullet"><span class="by">pinkcan</span><span>|</span><a href="#36500312">root</a><span>|</span><a href="#36502497">parent</a><span>|</span><a href="#36500485">next</a><span>|</span><label class="collapse" for="c-36503405">[-]</label><label class="expand" for="c-36503405">[1 more]</label></div><br/><div class="children"><div class="content">this is napkin math, for sure there are other components in the system that do not directly contribute to the computation – cooling systems, DC lights</div><br/></div></div></div></div><div id="36500485" class="c"><input type="checkbox" id="c-36500485" checked=""/><div class="controls bullet"><span class="by">SushiHippie</span><span>|</span><a href="#36500312">root</a><span>|</span><a href="#36500390">parent</a><span>|</span><a href="#36502497">prev</a><span>|</span><a href="#36499898">next</a><span>|</span><label class="collapse" for="c-36500485">[-]</label><label class="expand" for="c-36500485">[4 more]</label></div><br/><div class="children"><div class="content">Ah Thanks! Taking the data from here[0] for the USA, this would be about 25,69kg of CO2.<p>[0] <a href="https:&#x2F;&#x2F;ourworldindata.org&#x2F;grapher&#x2F;carbon-intensity-electricity">https:&#x2F;&#x2F;ourworldindata.org&#x2F;grapher&#x2F;carbon-intensity-electric...</a></div><br/><div id="36500978" class="c"><input type="checkbox" id="c-36500978" checked=""/><div class="controls bullet"><span class="by">alwa</span><span>|</span><a href="#36500312">root</a><span>|</span><a href="#36500485">parent</a><span>|</span><a href="#36500858">next</a><span>|</span><label class="collapse" for="c-36500978">[-]</label><label class="expand" for="c-36500978">[2 more]</label></div><br/><div class="children"><div class="content">Which, per the EPA [0], is roughly the tailpipe CO2 you’d emit by burning a little under 3 gallons of gas in your car, right? Which is to say, driving 65ish miles in the US [1]?<p>It amazes me that computational feats of this magnitude can be so energy efficient in the scheme of things.<p>[0] <a href="https:&#x2F;&#x2F;www.epa.gov&#x2F;greenvehicles&#x2F;tailpipe-greenhouse-gas-emissions-typical-passenger-vehicle#burning" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.epa.gov&#x2F;greenvehicles&#x2F;tailpipe-greenhouse-gas-em...</a><p>[1] <a href="https:&#x2F;&#x2F;www.epa.gov&#x2F;greenvehicles&#x2F;tailpipe-greenhouse-gas-emissions-typical-passenger-vehicle#:~:text=This%20assumes%20the%20average%20gasoline,around%2011%2C500%20miles%20per%20year" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.epa.gov&#x2F;greenvehicles&#x2F;tailpipe-greenhouse-gas-em...</a>.</div><br/><div id="36501369" class="c"><input type="checkbox" id="c-36501369" checked=""/><div class="controls bullet"><span class="by">NhanH</span><span>|</span><a href="#36500312">root</a><span>|</span><a href="#36500978">parent</a><span>|</span><a href="#36500858">next</a><span>|</span><label class="collapse" for="c-36501369">[-]</label><label class="expand" for="c-36501369">[1 more]</label></div><br/><div class="children"><div class="content">It’s not that surprising actually, computation moves nothing and all energy has to turn into heat. If computation would use as much energy as moving physical objects, the heat would burn everything down</div><br/></div></div></div></div><div id="36500858" class="c"><input type="checkbox" id="c-36500858" checked=""/><div class="controls bullet"><span class="by">nl</span><span>|</span><a href="#36500312">root</a><span>|</span><a href="#36500485">parent</a><span>|</span><a href="#36500978">prev</a><span>|</span><a href="#36499898">next</a><span>|</span><label class="collapse" for="c-36500858">[-]</label><label class="expand" for="c-36500858">[1 more]</label></div><br/><div class="children"><div class="content">If you are on GCP you can choose low carbon data centers: <a href="https:&#x2F;&#x2F;cloud.google.com&#x2F;sustainability&#x2F;region-carbon" rel="nofollow noreferrer">https:&#x2F;&#x2F;cloud.google.com&#x2F;sustainability&#x2F;region-carbon</a></div><br/></div></div></div></div></div></div></div></div><div id="36499898" class="c"><input type="checkbox" id="c-36499898" checked=""/><div class="controls bullet"><span class="by">tiernano</span><span>|</span><a href="#36500312">prev</a><span>|</span><a href="#36500467">next</a><span>|</span><label class="collapse" for="c-36499898">[-]</label><label class="expand" for="c-36499898">[5 more]</label></div><br/><div class="children"><div class="content">I have heard these are 100k each... anyone know if that&#x27;s correct? Guessing that&#x27;s list, and no one pays list, but still...</div><br/><div id="36499964" class="c"><input type="checkbox" id="c-36499964" checked=""/><div class="controls bullet"><span class="by">tikkun</span><span>|</span><a href="#36499898">parent</a><span>|</span><a href="#36500957">next</a><span>|</span><label class="collapse" for="c-36499964">[-]</label><label class="expand" for="c-36499964">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m writing a cool mega post on this at the moment – not published yet but here&#x27;s the excerpt on pricing:<p>How much do these GPUs cost?<p>H100s are around $30-33k at the IT hardware resellers CDW and SHI (<a href="https:&#x2F;&#x2F;www.cdw.com&#x2F;product&#x2F;nvidia-h100-gpu-computing-processor-nvidia-h100-tensor-core-80-gb&#x2F;7367181" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.cdw.com&#x2F;product&#x2F;nvidia-h100-gpu-computing-proces...</a>, <a href="https:&#x2F;&#x2F;www.shi.com&#x2F;product&#x2F;45671009&#x2F;NVIDIA-H100-GPU-computing-processor" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.shi.com&#x2F;product&#x2F;45671009&#x2F;NVIDIA-H100-GPU-computi...</a>)<p>Supermicro’s HGX H100 8x GPU server is $297k at the reseller Dihuni (<a href="https:&#x2F;&#x2F;www.dihuni.com&#x2F;product&#x2F;supermicro-8125gs-tnhr-server&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.dihuni.com&#x2F;product&#x2F;supermicro-8125gs-tnhr-server...</a>)<p>DGX H100 is $521k at the reseller Insight (<a href="https:&#x2F;&#x2F;www.insight.com&#x2F;en_US&#x2F;shop&#x2F;product&#x2F;DGXH-G640F+P2CMI60&#x2F;NVIDIA&#x2F;DGXH-G640F+P2CMI60&#x2F;NVIDIA-DGX-H100-P4387-SYSTEM-640GB-FULL-STD-SUPPORT-5-YRS&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.insight.com&#x2F;en_US&#x2F;shop&#x2F;product&#x2F;DGXH-G640F+P2CMI6...</a>)<p>The DGX GH200 might cost in the range of $10mm-20mm or more (A guesstimate ballpark from an exec at a cloud company I talked with)<p>If anyone wants to pre-review the post and can offer thoughtful comments, my email&#x27;s in my profile.<p>And to clarify the difference between all of these product names, I put together this diagram - <a href="https:&#x2F;&#x2F;gpus.llm-utils.org&#x2F;dgx-gh200-vs-gh200-vs-h100&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;gpus.llm-utils.org&#x2F;dgx-gh200-vs-gh200-vs-h100&#x2F;</a>. I don&#x27;t have the HGX H100 or the DGX H100 on there though - but the HGX H100 is a reference platform for OEMs to design and make H100 based servers with either 4x H100s or 8x H100s (<a href="https:&#x2F;&#x2F;nvdam.widen.net&#x2F;s&#x2F;5kgbjq2v2t&#x2F;hpc-hgx-h100-datasheet-nvidia-web" rel="nofollow noreferrer">https:&#x2F;&#x2F;nvdam.widen.net&#x2F;s&#x2F;5kgbjq2v2t&#x2F;hpc-hgx-h100-datasheet-...</a>) and the DGX H100 is the official Nvidia server with 8x H100s (<a href="https:&#x2F;&#x2F;resources.nvidia.com&#x2F;en-us-dgx-systems&#x2F;ai-enterprise-dgx" rel="nofollow noreferrer">https:&#x2F;&#x2F;resources.nvidia.com&#x2F;en-us-dgx-systems&#x2F;ai-enterprise...</a>).</div><br/></div></div><div id="36500957" class="c"><input type="checkbox" id="c-36500957" checked=""/><div class="controls bullet"><span class="by">huac</span><span>|</span><a href="#36499898">parent</a><span>|</span><a href="#36499964">prev</a><span>|</span><a href="#36499939">next</a><span>|</span><label class="collapse" for="c-36500957">[-]</label><label class="expand" for="c-36500957">[1 more]</label></div><br/><div class="children"><div class="content">from somebody who bought 2500 of them: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36313960">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36313960</a></div><br/></div></div><div id="36499939" class="c"><input type="checkbox" id="c-36499939" checked=""/><div class="controls bullet"><span class="by">finexplained</span><span>|</span><a href="#36499898">parent</a><span>|</span><a href="#36500957">prev</a><span>|</span><a href="#36500467">next</a><span>|</span><label class="collapse" for="c-36499939">[-]</label><label class="expand" for="c-36499939">[2 more]</label></div><br/><div class="children"><div class="content">I thought the H100s were ~30-40k each. But they&#x27;re not widely available and you usually buy multiple boxes from vendors that also come with expensive CPUs&#x2F;RAM etc.</div><br/><div id="36500280" class="c"><input type="checkbox" id="c-36500280" checked=""/><div class="controls bullet"><span class="by">aiappreciator</span><span>|</span><a href="#36499898">root</a><span>|</span><a href="#36499939">parent</a><span>|</span><a href="#36500467">next</a><span>|</span><label class="collapse" for="c-36500280">[-]</label><label class="expand" for="c-36500280">[1 more]</label></div><br/><div class="children"><div class="content">H100s are intended to be retailed piecemeal. The big enterprise model is DGX GH200, at $10 mil each.<p>Its just that current supply is extremely short, so the H100s end up only available to big buyers. But that will be resolved in time. Nvidia wants every university lab to have a H100 so no competitor sneaks in there.</div><br/></div></div></div></div></div></div><div id="36500467" class="c"><input type="checkbox" id="c-36500467" checked=""/><div class="controls bullet"><span class="by">deviantbit</span><span>|</span><a href="#36499898">prev</a><span>|</span><label class="collapse" for="c-36500467">[-]</label><label class="expand" for="c-36500467">[3 more]</label></div><br/><div class="children"><div class="content">SkyNet awakens... then says, &quot;I&#x27;ll be back.&quot; Goes to sleep to be trained again. (ominous music follows)... Across the screen it says, &quot;Sarah Connor is now in grade school.&quot; Then blinks away. A moment later, &quot;John Connor has yet to be conceived.&quot; (More ominous music) Image of Jensen Huang in a terminator leather jacket standing hold the next generation GPU is shown. (More ominous music that peaks to a finale)<p>Will you join the resistance?<p>LOL, I welcome our new overload.</div><br/><div id="36500777" class="c"><input type="checkbox" id="c-36500777" checked=""/><div class="controls bullet"><span class="by">Electricniko</span><span>|</span><a href="#36500467">parent</a><span>|</span><label class="collapse" for="c-36500777">[-]</label><label class="expand" for="c-36500777">[2 more]</label></div><br/><div class="children"><div class="content">Is our new overlord Jensen Huang or Skynet? I prefer one over the other.</div><br/><div id="36500989" class="c"><input type="checkbox" id="c-36500989" checked=""/><div class="controls bullet"><span class="by">deviantbit</span><span>|</span><a href="#36500467">root</a><span>|</span><a href="#36500777">parent</a><span>|</span><label class="collapse" for="c-36500989">[-]</label><label class="expand" for="c-36500989">[1 more]</label></div><br/><div class="children"><div class="content">Yes.</div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>