<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1738400470282" as="style"/><link rel="stylesheet" href="styles.css?v=1738400470282"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://simonwillison.net/2025/Jan/31/o3-mini/">Notes on OpenAI o3-mini</a> <span class="domain">(<a href="https://simonwillison.net">simonwillison.net</a>)</span></div><div class="subtext"><span>dtquad</span> | <span>54 comments</span></div><br/><div><div id="42895610" class="c"><input type="checkbox" id="c-42895610" checked=""/><div class="controls bullet"><span class="by">tkgally</span><span>|</span><a href="#42894532">next</a><span>|</span><label class="collapse" for="c-42895610">[-]</label><label class="expand" for="c-42895610">[11 more]</label></div><br/><div class="children"><div class="content">At the end of his post, Simon mentions translation between human languages. While maybe not directly related to token limits, I just did a test in which both R1 and o3-mini got worse at translation in the latter half of a long text.<p>I ran the test on Perplexity Pro, which hosts DeepSeek R1 in the U.S. and which has just added o3-mini as well. The text was a speech I translated a month ago from Japanese to English, preceded by a long prompt specifying the speech’s purpose and audience and the sort of style I wanted. (I am a professional Japanese-English translator with nearly four decades of experience. I have been testing and using LLMs for translation since early 2023.)<p>An initial comparison of the output suggested that, while R1 didn’t seem bad, o3-mini produced a writing style closer to what I asked for in the prompt—smoother and more natural English.<p>But then I noticed that the output length was 5,855 characters for R1, 9,052 characters for o3-mini, and 11,021 characters for my own polished version. Comparing the three translations side-by-side with the original Japanese, I discovered that R1 had omitted entire paragraphs toward the end of the speech, and that o3-mini had switched to a strange abbreviated style (using slashes instead of “and” between noun phrases, for example) toward the end as well. The vanilla versions of ChatGPT, Claude, and Gemini that I ran the same prompt and text through a month ago had had none of those problems.</div><br/><div id="42896222" class="c"><input type="checkbox" id="c-42896222" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#42895610">parent</a><span>|</span><a href="#42895821">next</a><span>|</span><label class="collapse" for="c-42896222">[-]</label><label class="expand" for="c-42896222">[1 more]</label></div><br/><div class="children"><div class="content">Yikes! Sounds to me like reliable longer form translation is very much not something you can trust to these models. Thanks for sharing.</div><br/></div></div><div id="42895821" class="c"><input type="checkbox" id="c-42895821" checked=""/><div class="controls bullet"><span class="by">nycdatasci</span><span>|</span><a href="#42895610">parent</a><span>|</span><a href="#42896222">prev</a><span>|</span><a href="#42896413">next</a><span>|</span><label class="collapse" for="c-42895821">[-]</label><label class="expand" for="c-42895821">[5 more]</label></div><br/><div class="children"><div class="content">This is a great anecdote and I hope others can learn from it.  R1, o1, and o3-mini work best on problems that have a “correct” answer (as in code that passes unit tests, or math problems).  If multiple professional translators are given the same document to translate, is there a single correct translation?</div><br/><div id="42895943" class="c"><input type="checkbox" id="c-42895943" checked=""/><div class="controls bullet"><span class="by">tkgally</span><span>|</span><a href="#42895610">root</a><span>|</span><a href="#42895821">parent</a><span>|</span><a href="#42895842">next</a><span>|</span><label class="collapse" for="c-42895943">[-]</label><label class="expand" for="c-42895943">[1 more]</label></div><br/><div class="children"><div class="content">No. People’s tastes and judgments vary too much.<p>One fundamental area of disagreement is how closely a translation should reflect the content and structure of the original text versus how smooth and natural it should sound in the target language. With languages like Japanese or Chinese translated into English, for example, the vocabulary, grammar, and rhetoric can be very different between the languages. A close literal translation will usually seem awkward or even strange in English. To make the English seem natural, often you have to depart from what the original text says.<p>Most translators will agree that where to aim on that spectrum should be based on the type of text and the reason for translating it, but they will still disagree about specific word choices. And there are genres for which there is no consensus at all about which approach is best. I have heard heated exchanges between literary scholars about whether or not translations of novels should reflect the original as closely as possible out of respect for the author and the author’s cultural context, even if that means the translation seems awkward and difficult to understand to a casual reader.<p>The ideal, of course, would be translations that are both accurate and natural, but it can be very hard to strike that balance. One way LLMs have been helping me is to suggest multiple rewordings of sentences and paragraphs. Many of their suggestions are no good, but often enough they include wordings that I recognize are better in both fidelity and naturalness compared to what I can come up with on my own.</div><br/></div></div><div id="42895842" class="c"><input type="checkbox" id="c-42895842" checked=""/><div class="controls bullet"><span class="by">jakevoytko</span><span>|</span><a href="#42895610">root</a><span>|</span><a href="#42895821">parent</a><span>|</span><a href="#42895943">prev</a><span>|</span><a href="#42895948">next</a><span>|</span><label class="collapse" for="c-42895842">[-]</label><label class="expand" for="c-42895842">[1 more]</label></div><br/><div class="children"><div class="content">My wife is a professional translator and both revises others&#x27; work and gets revised. Based on numerous anecdotes from her, I can promise you that &quot;single correct translation&quot; does not exist.</div><br/></div></div><div id="42895948" class="c"><input type="checkbox" id="c-42895948" checked=""/><div class="controls bullet"><span class="by">ec109685</span><span>|</span><a href="#42895610">root</a><span>|</span><a href="#42895821">parent</a><span>|</span><a href="#42895842">prev</a><span>|</span><a href="#42896549">next</a><span>|</span><label class="collapse" for="c-42895948">[-]</label><label class="expand" for="c-42895948">[1 more]</label></div><br/><div class="children"><div class="content">Well, the post said o3-mini did great in the beginning, so it’s likely something other than reasoning causing the poor performance towards the end.</div><br/></div></div><div id="42896549" class="c"><input type="checkbox" id="c-42896549" checked=""/><div class="controls bullet"><span class="by">aprilthird2021</span><span>|</span><a href="#42895610">root</a><span>|</span><a href="#42895821">parent</a><span>|</span><a href="#42895948">prev</a><span>|</span><a href="#42896413">next</a><span>|</span><label class="collapse" for="c-42896549">[-]</label><label class="expand" for="c-42896549">[1 more]</label></div><br/><div class="children"><div class="content">For almost any classic piece of literature there are competing translations, so no</div><br/></div></div></div></div><div id="42896413" class="c"><input type="checkbox" id="c-42896413" checked=""/><div class="controls bullet"><span class="by">EVa5I7bHFq9mnYK</span><span>|</span><a href="#42895610">parent</a><span>|</span><a href="#42895821">prev</a><span>|</span><a href="#42896113">next</a><span>|</span><label class="collapse" for="c-42896413">[-]</label><label class="expand" for="c-42896413">[1 more]</label></div><br/><div class="children"><div class="content">Could it be fixed by splitting the text into smaller parts? Looks easy to implement.</div><br/></div></div><div id="42896113" class="c"><input type="checkbox" id="c-42896113" checked=""/><div class="controls bullet"><span class="by">WhitneyLand</span><span>|</span><a href="#42895610">parent</a><span>|</span><a href="#42896413">prev</a><span>|</span><a href="#42894532">next</a><span>|</span><label class="collapse" for="c-42896113">[-]</label><label class="expand" for="c-42896113">[3 more]</label></div><br/><div class="children"><div class="content">How far off was o3 from the level of a professional translator (before it started to go off track)?</div><br/><div id="42896543" class="c"><input type="checkbox" id="c-42896543" checked=""/><div class="controls bullet"><span class="by">tkgally</span><span>|</span><a href="#42895610">root</a><span>|</span><a href="#42896113">parent</a><span>|</span><a href="#42894532">next</a><span>|</span><label class="collapse" for="c-42896543">[-]</label><label class="expand" for="c-42896543">[2 more]</label></div><br/><div class="children"><div class="content">As I explained in a sister comment, it is not possible to rate translation quality objectively, as opinions and positions about what constitutes a good translation vary. But in my tests of reasoning models since the release of o1-preview, they have not seemed as reliable as the straight nonreasoning versions of ChatGPT, Claude, or Gemini. The translation process itself usually doesn’t seem to require the kind of multistep thinking those reasoning models can be good at.<p>For more than a year, regular LLMs, when properly prompted, have been able to produce translations that would be indistinguishable from those of <i>some</i> professional translators for <i>some</i> types of translation.<p>General-purpose LLMs are best for translating straight expository prose without much technical or organization-specific vocabulary. Results are mixed for texts containing slang, dialogue, poetry, archaic language, etc.—partly because people’s tastes differ for how such texts should be translated.<p>Because most translators are freelancers, it’s hard to get a handle on what impact LLMs have been having on their workloads overall. I have heard reports from experienced translators who have seen work drop off precipitously and have had to change careers, while others report an increase in their workloads over the past two years.<p>Many translation jobs involve confidential material, and some translators may be hanging onto their jobs because their clients or employers do not allow the use of cloud-based LLMs. That safety net won’t be in place forever, though.<p>I suspect that those who work directly with translation clients and who are personally known and trusted by their clients will be able to keep working, using LLMs as appropriate to speed up and improve the quality of their work. That’s the position I am fortunate to be in now.<p>But translators who do piecework through translation agencies or online referrers like Fiverr will have a hard time competing with the much faster and cheaper—and often equally good—LLMs.<p>I made a few videos about LLMs and translation a couple of years ago. Parts of them are out of date, but my basic thinking hasn’t changed too much since then. If you’re interested:<p>“Translating with ChatGPT”<p><a href="https:&#x2F;&#x2F;youtu.be&#x2F;najKN2bXqCo" rel="nofollow">https:&#x2F;&#x2F;youtu.be&#x2F;najKN2bXqCo</a><p>“Can GPT-4 translate literature?”<p><a href="https:&#x2F;&#x2F;youtu.be&#x2F;5KKDCp3OaMo" rel="nofollow">https:&#x2F;&#x2F;youtu.be&#x2F;5KKDCp3OaMo</a><p>“What do translators think about GPT?”<p><a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=8JUepj7wIl0" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=8JUepj7wIl0</a><p>I’m planning to make a few more videos on the topic soon, this time focusing on how I use LLMs in my own translation work.</div><br/><div id="42896906" class="c"><input type="checkbox" id="c-42896906" checked=""/><div class="controls bullet"><span class="by">cma</span><span>|</span><a href="#42895610">root</a><span>|</span><a href="#42896543">parent</a><span>|</span><a href="#42894532">next</a><span>|</span><label class="collapse" for="c-42896906">[-]</label><label class="expand" for="c-42896906">[1 more]</label></div><br/><div class="children"><div class="content">Not that you&#x27;d want to have to do more steps, but how do they do if you split it up in separate parts and translate them individually, then feed it back in interleaved in parts&#x2F;translated parts and ask it to keep the style but fix any errors due to it originally not having full context?<p>Or another approach, feed it all into context but tell it to wait and not translate, and then feed it in an additionalt time part by part asking it to translate each part and with the translation style instructions repeated.</div><br/></div></div></div></div></div></div></div></div><div id="42894532" class="c"><input type="checkbox" id="c-42894532" checked=""/><div class="controls bullet"><span class="by">kamikazeturtles</span><span>|</span><a href="#42895610">prev</a><span>|</span><a href="#42895630">next</a><span>|</span><label class="collapse" for="c-42894532">[-]</label><label class="expand" for="c-42894532">[4 more]</label></div><br/><div class="children"><div class="content">There&#x27;s a huge price difference between o3-mini and o1 ($4.40 vs $60 per million output tokens), what trade-offs in performance would justify such a large price gap?<p>Are there specific use cases where o1&#x27;s higher cost is justified anymore?</div><br/><div id="42895875" class="c"><input type="checkbox" id="c-42895875" checked=""/><div class="controls bullet"><span class="by">arthurcolle</span><span>|</span><a href="#42894532">parent</a><span>|</span><a href="#42895038">next</a><span>|</span><label class="collapse" for="c-42895875">[-]</label><label class="expand" for="c-42895875">[1 more]</label></div><br/><div class="children"><div class="content">its the same thing as:<p>gpt-3.5 -&gt; gpt-4 (gpt-4-32k premium)<p>&quot;omni&quot; announced (multimodal fusion, initial promise of gpt-4o, but cost effectively distilled down with additional multimodal aspects)<p>gpt-4o-mini -&gt; gpt-4o (multimodal, realtime)<p>gpt-4o + &quot;reasoning&quot; exposed via tools in ChatGPT (you can see it in export formats) -&gt; &quot;o&quot; series<p>o1 -&gt; o1 premium &#x2F; o1-mini (equivalent of gpt-4 &quot;god model&quot; becoming basis for lots of other stuff)<p>o1-pro-mode, o1-premium, o1-mini, somewhere in that is the &quot;o1-2024-12-17&quot; model with not streaming, function calling, and structured outputs and vision<p>now, distilled o1-pro-mode probably is o3-mini and o3-mini-high-mode (the naming is becoming just as bad as android)<p>its the repeat, take model, scale it up, run evals, detect innefficiencies, retrain, scale, distill, see what&#x27;s not working. when you find a good little zone in the efficiency frontier, release it with a cool name</div><br/></div></div><div id="42895038" class="c"><input type="checkbox" id="c-42895038" checked=""/><div class="controls bullet"><span class="by">benatkin</span><span>|</span><a href="#42894532">parent</a><span>|</span><a href="#42895875">prev</a><span>|</span><a href="#42894912">next</a><span>|</span><label class="collapse" for="c-42895038">[-]</label><label class="expand" for="c-42895038">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Are there specific use cases where o1&#x27;s higher cost is justified anymore?<p>Long tail stuff perhaps. Most stuff doesn&#x27;t resemble a programming benchmark. A newer model thrives despite being small when there is a lot of training data, and with programming benchmarks, like with chess, there is a lot of training data, in part because high quality training data can be synthesized.</div><br/></div></div><div id="42894912" class="c"><input type="checkbox" id="c-42894912" checked=""/><div class="controls bullet"><span class="by">zamadatix</span><span>|</span><a href="#42894532">parent</a><span>|</span><a href="#42895038">prev</a><span>|</span><a href="#42895630">next</a><span>|</span><label class="collapse" for="c-42894912">[-]</label><label class="expand" for="c-42894912">[1 more]</label></div><br/><div class="children"><div class="content">Not really, it&#x27;ll also be replaced by a newer o3 series model in short order.</div><br/></div></div></div></div><div id="42895630" class="c"><input type="checkbox" id="c-42895630" checked=""/><div class="controls bullet"><span class="by">johngalt2600</span><span>|</span><a href="#42894532">prev</a><span>|</span><a href="#42896181">next</a><span>|</span><label class="collapse" for="c-42895630">[-]</label><label class="expand" for="c-42895630">[1 more]</label></div><br/><div class="children"><div class="content">So far ive been impressed.. seems to be in the same ballpark as r1 and claude for coding. I will have to gather more samples.. in this past week ive changed from using 100% claude exclusively (since 3.5) to hitting all the big boys: claude, r1, 4o (o3 now), and gemini flash. Then ill do a new chat that includes all of their generated solutions for additional context for a refactored
final solution.<p>R1 has upped the ante so Im hoping we continue to get more updates rapidly... they are getting quite good</div><br/></div></div><div id="42896181" class="c"><input type="checkbox" id="c-42896181" checked=""/><div class="controls bullet"><span class="by">submeta</span><span>|</span><a href="#42895630">prev</a><span>|</span><a href="#42894775">next</a><span>|</span><label class="collapse" for="c-42896181">[-]</label><label class="expand" for="c-42896181">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The model accepts up to 200,000 tokens of input, an improvement on GPT-4o’s 128,000.<p>So finally ChatGPT catches up with Claude which has a 200,000 token input limit ever since.<p>Claude with its projects feature is my go to tool for working on projects that I have to work on for weeks and months. Now I see a possible alternative.</div><br/></div></div><div id="42894775" class="c"><input type="checkbox" id="c-42894775" checked=""/><div class="controls bullet"><span class="by">xnx</span><span>|</span><a href="#42896181">prev</a><span>|</span><a href="#42894482">next</a><span>|</span><label class="collapse" for="c-42894775">[-]</label><label class="expand" for="c-42894775">[10 more]</label></div><br/><div class="children"><div class="content">Hasn&#x27;t Gemini pricing been lower than this (or even free) for awhile? <a href="https:&#x2F;&#x2F;ai.google.dev&#x2F;pricing" rel="nofollow">https:&#x2F;&#x2F;ai.google.dev&#x2F;pricing</a></div><br/><div id="42894872" class="c"><input type="checkbox" id="c-42894872" checked=""/><div class="controls bullet"><span class="by">BinRoo</span><span>|</span><a href="#42894775">parent</a><span>|</span><a href="#42894482">next</a><span>|</span><label class="collapse" for="c-42894872">[-]</label><label class="expand" for="c-42894872">[9 more]</label></div><br/><div class="children"><div class="content">Are you insinuating Gemini is similar in performance to o3-mini?</div><br/><div id="42895178" class="c"><input type="checkbox" id="c-42895178" checked=""/><div class="controls bullet"><span class="by">panarky</span><span>|</span><a href="#42894775">root</a><span>|</span><a href="#42894872">parent</a><span>|</span><a href="#42895113">next</a><span>|</span><label class="collapse" for="c-42895178">[-]</label><label class="expand" for="c-42895178">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve only had o3-mini for a day, but Gemini 2.0 Flash Thinking is still clearly better for my use cases.<p>And it&#x27;s currently free in aistudio.google.com and in the API.<p>And it handles a million tokens.</div><br/></div></div><div id="42895113" class="c"><input type="checkbox" id="c-42895113" checked=""/><div class="controls bullet"><span class="by">xnx</span><span>|</span><a href="#42894775">root</a><span>|</span><a href="#42894872">parent</a><span>|</span><a href="#42895178">prev</a><span>|</span><a href="#42895016">next</a><span>|</span><label class="collapse" for="c-42895113">[-]</label><label class="expand" for="c-42895113">[3 more]</label></div><br/><div class="children"><div class="content">Definitely varies by application, but the blind &quot;taste test&quot; vibes are very good for Gemini: <a href="https:&#x2F;&#x2F;lmarena.ai&#x2F;?leaderboard" rel="nofollow">https:&#x2F;&#x2F;lmarena.ai&#x2F;?leaderboard</a></div><br/><div id="42895314" class="c"><input type="checkbox" id="c-42895314" checked=""/><div class="controls bullet"><span class="by">anabab</span><span>|</span><a href="#42894775">root</a><span>|</span><a href="#42895113">parent</a><span>|</span><a href="#42895016">next</a><span>|</span><label class="collapse" for="c-42895314">[-]</label><label class="expand" for="c-42895314">[2 more]</label></div><br/><div class="children"><div class="content">that reminds me that a week ago there was a (now deleted but has a copy of the content available in the comments) post on Reddit where the author claimed they have attempted manipulating&#x2F;manipulated voting on lmarena in favor of Gemini to tip the scale on Polymarket where on a question like &quot;which AI model will be the best one by $date&quot; (with the outcome decided based on the scoring on lmarena) they have supposedly made O(USD10k).<p>Original deleted post: <a href="https:&#x2F;&#x2F;old.reddit.com&#x2F;r&#x2F;MachineLearning&#x2F;comments&#x2F;1i83mhj&#x2F;lm_arena_public_voting_is_not_objective_for_llm&#x2F;" rel="nofollow">https:&#x2F;&#x2F;old.reddit.com&#x2F;r&#x2F;MachineLearning&#x2F;comments&#x2F;1i83mhj&#x2F;lm...</a><p>A copy of the content: <a href="https:&#x2F;&#x2F;old.reddit.com&#x2F;r&#x2F;MachineLearning&#x2F;comments&#x2F;1i83mhj&#x2F;lm_arena_public_voting_is_not_objective_for_llm&#x2F;m9029so&#x2F;" rel="nofollow">https:&#x2F;&#x2F;old.reddit.com&#x2F;r&#x2F;MachineLearning&#x2F;comments&#x2F;1i83mhj&#x2F;lm...</a></div><br/></div></div></div></div><div id="42895016" class="c"><input type="checkbox" id="c-42895016" checked=""/><div class="controls bullet"><span class="by">gerdesj</span><span>|</span><a href="#42894775">root</a><span>|</span><a href="#42894872">parent</a><span>|</span><a href="#42895113">prev</a><span>|</span><a href="#42894482">next</a><span>|</span><label class="collapse" for="c-42895016">[-]</label><label class="expand" for="c-42895016">[4 more]</label></div><br/><div class="children"><div class="content">Are you implying it isn&#x27;t?<p>(evidence please, everyone)</div><br/><div id="42895412" class="c"><input type="checkbox" id="c-42895412" checked=""/><div class="controls bullet"><span class="by">BinRoo</span><span>|</span><a href="#42894775">root</a><span>|</span><a href="#42895016">parent</a><span>|</span><a href="#42894482">next</a><span>|</span><label class="collapse" for="c-42895412">[-]</label><label class="expand" for="c-42895412">[3 more]</label></div><br/><div class="children"><div class="content">Simple example: o3-mini-high gets this [1] right, whereas Gemini 2.0 Flash 01-21 gets it wrong.<p>[1] <a href="https:&#x2F;&#x2F;chatgpt.com&#x2F;share&#x2F;679d9579-5bb8-8008-ac4a-38cef65b45b5" rel="nofollow">https:&#x2F;&#x2F;chatgpt.com&#x2F;share&#x2F;679d9579-5bb8-8008-ac4a-38cef65b45...</a></div><br/><div id="42896588" class="c"><input type="checkbox" id="c-42896588" checked=""/><div class="controls bullet"><span class="by">maeil</span><span>|</span><a href="#42894775">root</a><span>|</span><a href="#42895412">parent</a><span>|</span><a href="#42895707">next</a><span>|</span><label class="collapse" for="c-42896588">[-]</label><label class="expand" for="c-42896588">[1 more]</label></div><br/><div class="children"><div class="content">This agrees with my limited testing so far, but in a different way: o3 being better at coding and  objective tasks, with the most recent Flash 2.0-thinking stronger at subjective tasks. Similarly, o3 seems better at shorter output sizes, but drops off, tending to be lazy.</div><br/></div></div><div id="42895707" class="c"><input type="checkbox" id="c-42895707" checked=""/><div class="controls bullet"><span class="by">xnx</span><span>|</span><a href="#42894775">root</a><span>|</span><a href="#42895412">parent</a><span>|</span><a href="#42896588">prev</a><span>|</span><a href="#42894482">next</a><span>|</span><label class="collapse" for="c-42895707">[-]</label><label class="expand" for="c-42895707">[1 more]</label></div><br/><div class="children"><div class="content">Great example. Thank you. Can confirm that none of the Gemini models warned about the exception without prompting.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="42894482" class="c"><input type="checkbox" id="c-42894482" checked=""/><div class="controls bullet"><span class="by">maxdo</span><span>|</span><a href="#42894775">prev</a><span>|</span><a href="#42894629">next</a><span>|</span><label class="collapse" for="c-42894482">[-]</label><label class="expand" for="c-42894482">[5 more]</label></div><br/><div class="children"><div class="content">How would you rate it against  Claude ? Didn’t test it yet, but o1 pro didn’t perform as good</div><br/><div id="42894757" class="c"><input type="checkbox" id="c-42894757" checked=""/><div class="controls bullet"><span class="by">pants2</span><span>|</span><a href="#42894482">parent</a><span>|</span><a href="#42894629">next</a><span>|</span><label class="collapse" for="c-42894757">[-]</label><label class="expand" for="c-42894757">[4 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve been trying out o3 mini in Cursor today, it seems &quot;smarter&quot; but overall tends to overthink things and if it&#x27;s not provided with perfect context it&#x27;s prone to hallucinate. Overall I prefer Sonnet still. It has a certain magic of always making reasonable assumptions and finding simple solutions.</div><br/><div id="42896603" class="c"><input type="checkbox" id="c-42896603" checked=""/><div class="controls bullet"><span class="by">maeil</span><span>|</span><a href="#42894482">root</a><span>|</span><a href="#42894757">parent</a><span>|</span><a href="#42894847">next</a><span>|</span><label class="collapse" for="c-42896603">[-]</label><label class="expand" for="c-42896603">[1 more]</label></div><br/><div class="children"><div class="content">Agreed that Sonnet still feels like the best all-round model. The new ones are at least on par with it for pure coding, or exceed it (r1, o1 both do IME) but don&#x27;t generalize as well, especially to tasks with subjective answers. I find the latest Gemini 2.0-Flash-thinking to be closest to Sonnet on those.</div><br/></div></div><div id="42894847" class="c"><input type="checkbox" id="c-42894847" checked=""/><div class="controls bullet"><span class="by">firecall</span><span>|</span><a href="#42894482">root</a><span>|</span><a href="#42894757">parent</a><span>|</span><a href="#42896603">prev</a><span>|</span><a href="#42894629">next</a><span>|</span><label class="collapse" for="c-42894847">[-]</label><label class="expand" for="c-42894847">[2 more]</label></div><br/><div class="children"><div class="content">As n occasions user and fan of Cursor, it would be good if they could explain what the models are and why the different models exist.<p>There’s no obvious answer of why one should switch to any of them!</div><br/><div id="42895463" class="c"><input type="checkbox" id="c-42895463" checked=""/><div class="controls bullet"><span class="by">conception</span><span>|</span><a href="#42894482">root</a><span>|</span><a href="#42894847">parent</a><span>|</span><a href="#42894629">next</a><span>|</span><label class="collapse" for="c-42895463">[-]</label><label class="expand" for="c-42895463">[1 more]</label></div><br/><div class="children"><div class="content">I don’t think there’s an obvious answer. Try them out and see which works better for your use case.</div><br/></div></div></div></div></div></div></div></div><div id="42894629" class="c"><input type="checkbox" id="c-42894629" checked=""/><div class="controls bullet"><span class="by">brianbest101</span><span>|</span><a href="#42894482">prev</a><span>|</span><a href="#42894835">next</a><span>|</span><label class="collapse" for="c-42894629">[-]</label><label class="expand" for="c-42894629">[2 more]</label></div><br/><div class="children"><div class="content">Open AI really needs to work on their naming conventions for these things.</div><br/><div id="42895159" class="c"><input type="checkbox" id="c-42895159" checked=""/><div class="controls bullet"><span class="by">benatkin</span><span>|</span><a href="#42894629">parent</a><span>|</span><a href="#42894835">next</a><span>|</span><label class="collapse" for="c-42895159">[-]</label><label class="expand" for="c-42895159">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s all based on <i>omni</i> which to me has weird religious connotations. It just occurred to me to put it together with sama&#x27;s other project, scanning everyone&#x27;s eyes. That&#x27;s one aspect of omniscience - keeping track of every soul.<p>Another thing it seems similar to is how Jeff Bezos registered relentless.com. There seems to be a gap between the ideal branding from the perspective of the creators and branding that makes sense to consumers.</div><br/></div></div></div></div></div></div></div></div></div></body></html>