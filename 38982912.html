<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1705222856642" as="style"/><link rel="stylesheet" href="styles.css?v=1705222856642"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://lemire.me/blog/2008/08/21/peer-review-is-an-honor-based-system/">Peer review is an honor-based system (2008)</a> <span class="domain">(<a href="https://lemire.me">lemire.me</a>)</span></div><div class="subtext"><span>ibobev</span> | <span>95 comments</span></div><br/><div><div id="38983668" class="c"><input type="checkbox" id="c-38983668" checked=""/><div class="controls bullet"><span class="by">2cynykyl</span><span>|</span><a href="#38984711">next</a><span>|</span><label class="collapse" for="c-38983668">[-]</label><label class="expand" for="c-38983668">[14 more]</label></div><br/><div class="children"><div class="content">The statements made in the original post are so foreign to me. It sounds like the author is digging really deep to try and say something nice about the peer review process.  To be fair, it <i>might</i> be true for CS where they are stuck in the weird trap of publishing in conferences, but in other circles everything goes into journals, and in this case the peer-review processes is definitely not there to &quot;help the authors&quot;.<p>The peer review is there to help the journal maintain its reputation by preventing the publication of sub-standard stuff.  Period.   Sub-standard can mean uninteresting, incomplete, poorly written, or whatever the journal is aiming for.  It is <i>not</i> there to safe guard the integrity of the literature against erroneous results...it&#x27;s purely self-interest on the part of the journal.<p>In reality, a rejected paper will just be submitted elsewhere until it is eventually accepted.  The authors cannot afford to spend 1-2 years worth of work on a project then have nothing to show for it, just because a reviewer didn&#x27;t &quot;get it&quot;.  So authors will keep submitting it (hopefully with some improvements based on past reviewer comments, but maybe not) until it &quot;gets through&quot; somewhere, and eventually nearly everything gets the seal of &quot;peer review&quot;.<p>&gt; There is SO much more I could write on this subject, but I&#x27;m trying to stay on point (-:</div><br/><div id="38988191" class="c"><input type="checkbox" id="c-38988191" checked=""/><div class="controls bullet"><span class="by">jballer</span><span>|</span><a href="#38983668">parent</a><span>|</span><a href="#38984689">next</a><span>|</span><label class="collapse" for="c-38988191">[-]</label><label class="expand" for="c-38988191">[2 more]</label></div><br/><div class="children"><div class="content">This was what a few academics hypothesized and set out to prove in what is now known as the Grievance Studies Affair [1]. Not only did they get multiple hoax papers published, they got recognized for “excellent scholarship” [2].<p>[1] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Grievance_studies_affair" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Grievance_studies_affair</a><p>[2] <a href="https:&#x2F;&#x2F;youtu.be&#x2F;kVk9a5Jcd1k?t=3m49s" rel="nofollow">https:&#x2F;&#x2F;youtu.be&#x2F;kVk9a5Jcd1k?t=3m49s</a></div><br/><div id="38988613" class="c"><input type="checkbox" id="c-38988613" checked=""/><div class="controls bullet"><span class="by">fenomas</span><span>|</span><a href="#38983668">root</a><span>|</span><a href="#38988191">parent</a><span>|</span><a href="#38984689">next</a><span>|</span><label class="collapse" for="c-38988613">[-]</label><label class="expand" for="c-38988613">[1 more]</label></div><br/><div class="children"><div class="content">That grievance studies thing was idiotic, and really ought to be dismissed and forgotten. Reasons:<p>1. The hoax authors didn&#x27;t submit gibberish or anything, like with Sokal - they submitted coherent papers that <i>they</i> considered absurd, but which they expected the journals to find reasonable. As such, they only thing they can even pretend to have proven is that they and the journals disagree about what&#x27;s reasonable.<p>2. IIRC, every one of the initial hoax papers was flat-out rejected! If the authors had any backbone they could have stopped right there, and published a paper called &quot;These grievance journals aren&#x27;t as bad as we expected.&quot; :D But they didn&#x27;t - they set out to iterate on each paper until a journal accepted it. And if your experimental methodology is &quot;keep trying different things until X happens&quot;, you can hardly pretend to have proved something when X happens.<p>I mean, I <i>agree</i> with the premise the hoax authors were trying to prove. But their &quot;experiment&quot; was silly, and I think it&#x27;s dishonest of them to pretend it proved something. Meh. Meh!</div><br/></div></div></div></div><div id="38984689" class="c"><input type="checkbox" id="c-38984689" checked=""/><div class="controls bullet"><span class="by">tptacek</span><span>|</span><a href="#38983668">parent</a><span>|</span><a href="#38988191">prev</a><span>|</span><a href="#38988314">next</a><span>|</span><label class="collapse" for="c-38984689">[-]</label><label class="expand" for="c-38984689">[6 more]</label></div><br/><div class="children"><div class="content">Right, it&#x27;s a low bar, and it&#x27;s meant to be a low bar, and that&#x27;s fine.<p>It&#x27;s not <i>no</i> bar. Peer review adds <i>some</i> credibility to a paper. And the venue does as well. It&#x27;s just less credibility than the popular imagination assumes.</div><br/><div id="38985657" class="c"><input type="checkbox" id="c-38985657" checked=""/><div class="controls bullet"><span class="by">AlbertCory</span><span>|</span><a href="#38983668">root</a><span>|</span><a href="#38984689">parent</a><span>|</span><a href="#38988314">next</a><span>|</span><label class="collapse" for="c-38985657">[-]</label><label class="expand" for="c-38985657">[5 more]</label></div><br/><div class="children"><div class="content">This had a refreshing degree of realism. Naturally, any perfection-minded person will be offended by that.<p>A decent journal will stop using reviewers who do a lousy job, and complaints by authors about their paper&#x27;s reviewers ought to be listened to and not dismissed as sour grapes.</div><br/><div id="38986829" class="c"><input type="checkbox" id="c-38986829" checked=""/><div class="controls bullet"><span class="by">godelski</span><span>|</span><a href="#38983668">root</a><span>|</span><a href="#38985657">parent</a><span>|</span><a href="#38988314">next</a><span>|</span><label class="collapse" for="c-38986829">[-]</label><label class="expand" for="c-38986829">[4 more]</label></div><br/><div class="children"><div class="content">&gt; A decent journal will stop using reviewers who do a lousy job, and complaints by authors about their paper&#x27;s reviewers ought to be listened to and not dismissed as sour grapes.<p>As a data point in ML conferences, I had a reviewer give me a strong reject with only a few sentences. First was a generic &quot;not novel&quot; with no further explanation. The rest was a complaint that my paper had serious flaws and pointed to an intentionally redacted link and a broken cross-reference. We reported them to the AC and the other two reviewers were borderline and weak accept, but both had low confidence (of course the inane reviewer was high confidence). The result was that the reviewer&#x27;s rebuttal was much more angry and the weak accept said &quot;authors addressed my concerns, but I&#x27;ve decided to lower my score.&quot;<p>I tell this story because at a certain point it is not a problem with bad reviewers, it is a problem with bad management. The most important thing that a system can have is self correcting behavior. A system that gives a bad faith actor a slap on the wrist and allows them to then escalate their bad behavior and influence others is not a well functioning system. Granted, this is just one example, but I&#x27;ve seen many others (such as a theory paper being rejected for lack of experiments). I&#x27;ve started collecting author tweets I find about these kinds of situations, but I think there&#x27;s a lot more that aren&#x27;t easily conveyed on social media.<p>I do really want to promote discussion of these things because I think we should always be improving our systems. You&#x27;re right that nothing is every perfect, but we can still recognize flaws without being consumed with the impossible goal of perfectionism.</div><br/><div id="38986959" class="c"><input type="checkbox" id="c-38986959" checked=""/><div class="controls bullet"><span class="by">AlbertCory</span><span>|</span><a href="#38983668">root</a><span>|</span><a href="#38986829">parent</a><span>|</span><a href="#38988314">next</a><span>|</span><label class="collapse" for="c-38986959">[-]</label><label class="expand" for="c-38986959">[3 more]</label></div><br/><div class="children"><div class="content">Indeed, my paper to CACM based on this:<p><a href="https:&#x2F;&#x2F;papers.ssrn.com&#x2F;sol3&#x2F;papers.cfm?abstract_id=2399580" rel="nofollow">https:&#x2F;&#x2F;papers.ssrn.com&#x2F;sol3&#x2F;papers.cfm?abstract_id=2399580</a><p>was shitcanned by a Microsoft reviewer (if you&#x27;re the one and you&#x27;re reading this: GFY)<p>First of all, he ignored it for six months, and it wasn&#x27;t until I begged the editor that he got it moving. Then he gave one round of critique, and when I addressed it, he said, &quot;the patent law changed&quot; and closed the process. He knew nothing about patents.<p>As I said, the editors should not defer to these douchebags. Fortunately I don&#x27;t need pubs for my career, but some people do.</div><br/><div id="38987283" class="c"><input type="checkbox" id="c-38987283" checked=""/><div class="controls bullet"><span class="by">godelski</span><span>|</span><a href="#38983668">root</a><span>|</span><a href="#38986959">parent</a><span>|</span><a href="#38988101">next</a><span>|</span><label class="collapse" for="c-38987283">[-]</label><label class="expand" for="c-38987283">[1 more]</label></div><br/><div class="children"><div class="content">Funny enough, none of my first author works have been &quot;published&quot; but since they are on arxiv I have a competitive citation count and h-index (most cites are from my first author works). Only group upset at me is my grad school. It&#x27;s extremely frustrating because I have all indications of doing good work and clearly the community agrees. I think the funniest part of it all is that I&#x27;ve offered to show them my reviews and so we can discuss if I am doing something wrong or &quot;just having bad luck.&quot; But no one wants to even entertain the idea that the system is dysfunctional.<p>I will never understand why in CS we use a conference system as our indicator of merit. It is an antagonistic zero sum game. There is no recourse for giving a bad faith review and you are incentivized to reject works. It&#x27;s easier to reject and thus less time consuming -- every paper has flaws and limitations, just point at them and ignore context--, you marginally increase the chance of your own paper getting in, and venues use acceptance rates as the main measure to indicate their level of prestige (if I cared enough I&#x27;d just get LLMs to spam papers to abuse this). Every part of the system that does something good and beneficial to the scientific community relies entirely on people acting in good faith and against other incentives they have, favoring the purity of science. That clearly doesn&#x27;t scale and clearly sets a stage for bad actors to overwhelm. I think we only continue this because they&#x27;ve successfully convinced good faith actors that there is no other way and that it isn&#x27;t as bad as it is. I just wonder how much money and time is lost due to all of this (before we even account for the ridiculousness of charging for what arxiv does for free. The paper is given to them for free as well as the reviewing is done for free, and much of the organizing committee and all that is also free labor. Something this important shouldn&#x27;t have so many similarities to a scam that seeks to extract money from the government and universities).</div><br/></div></div><div id="38988101" class="c"><input type="checkbox" id="c-38988101" checked=""/><div class="controls bullet"><span class="by">dmoy</span><span>|</span><a href="#38983668">root</a><span>|</span><a href="#38986959">parent</a><span>|</span><a href="#38987283">prev</a><span>|</span><a href="#38988314">next</a><span>|</span><label class="collapse" for="c-38988101">[-]</label><label class="expand" for="c-38988101">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Then he gave one round of critique, and when I addressed it, he said, &quot;the patent law changed&quot; and closed the process.<p>Was this back in 2014, or more recently?</div><br/></div></div></div></div></div></div></div></div></div></div><div id="38988314" class="c"><input type="checkbox" id="c-38988314" checked=""/><div class="controls bullet"><span class="by">chmike</span><span>|</span><a href="#38983668">parent</a><span>|</span><a href="#38984689">prev</a><span>|</span><a href="#38984500">next</a><span>|</span><label class="collapse" for="c-38988314">[-]</label><label class="expand" for="c-38988314">[1 more]</label></div><br/><div class="children"><div class="content">The peer review system is definitely biased. It&#x27;s ok for many articles, but there are outliers. For instance really original theories or experimental data. The publication may be stopped to avoid putting the journal&#x27;s reputation at risk or because the reviewers have personal reasons to not support the article (it would shade their own pet theory, invalidate their research project, they didn&#x27;t understood it, etc.).<p>The problem with publishing elsewhere is that many people unable to objectively evaluate the validity of the theory juge its value by the reputation of the journal. Also the other journal will most probably have less visibility. There is thus a higher chance that the other theory will not be reported in reviews.<p>There are many assumptions in the above comment that I can&#x27;t agree with. But my experience is with physics, not computer science.</div><br/></div></div><div id="38984500" class="c"><input type="checkbox" id="c-38984500" checked=""/><div class="controls bullet"><span class="by">slimsag</span><span>|</span><a href="#38983668">parent</a><span>|</span><a href="#38988314">prev</a><span>|</span><a href="#38984568">next</a><span>|</span><label class="collapse" for="c-38984500">[-]</label><label class="expand" for="c-38984500">[2 more]</label></div><br/><div class="children"><div class="content">Isn&#x27;t this almost identical to the general admissions process, too?<p>It seems strange to me that we built institutions on the idea of filtering in&#x2F;out applicants based on relatively arbitrary criteria, and then express shock&#x2F;surprise when the reward systems inside that institution are.. basically the same?<p>There are parallels everywhere, e.g. scientists feeling they must get positive &#x27;groundbreaking discovery!&#x27; news reporting about their publications, not just actually doing impactful work, in the same way good grades aren&#x27;t enough and you need some other impactful story to tell in order to be accepted to many schools.<p>All of it can be traced back to money, money, money.</div><br/><div id="38986876" class="c"><input type="checkbox" id="c-38986876" checked=""/><div class="controls bullet"><span class="by">godelski</span><span>|</span><a href="#38983668">root</a><span>|</span><a href="#38984500">parent</a><span>|</span><a href="#38984568">next</a><span>|</span><label class="collapse" for="c-38986876">[-]</label><label class="expand" for="c-38986876">[1 more]</label></div><br/><div class="children"><div class="content">&gt; It seems strange to me that we built institutions on the idea of filtering in&#x2F;out applicants based on relatively arbitrary criteria, and then express shock&#x2F;surprise when the reward systems inside that institution are.. basically the same?<p>I think it is impossible to use anything other than noisy signals in many of these processes. I&#x27;m not bothered by the noise. But what I am bothered by is pretending the noise doesn&#x27;t exist or trying to convince people it is a feature and not a bug. Why not just admit the process is noisy and that we&#x27;re just doing our best? These processes may still be frustrating, but they will be less so and it leaves the door open to fixing issues if they are actually fixable.<p>With the way we publish science, I find it very odd. We are doing essentially the same thing we have done for centuries with only a few minor tweaks. But unlike the past we don&#x27;t have many of the same constraints; such as, printing, lack of color, distribution&#x2F;storage, communication (which is arguably the main purpose of papers), video, and so on. Why are we stuck in the 18th century with a sprinkling of 21st century (plots&#x2F;graphics and arxiv)? We can track data, reproduction efforts, failures, challenges, and all that stuff. Is not the point of science the pursuit of knowledge? If so, it seems like we&#x27;re being pretty inefficient. I think there&#x27;s just something funny about how we publish papers on things like computer graphics and video but constrain our communication methods to a piece of paper.</div><br/></div></div></div></div><div id="38984568" class="c"><input type="checkbox" id="c-38984568" checked=""/><div class="controls bullet"><span class="by">Blahah</span><span>|</span><a href="#38983668">parent</a><span>|</span><a href="#38984500">prev</a><span>|</span><a href="#38986517">next</a><span>|</span><label class="collapse" for="c-38984568">[-]</label><label class="expand" for="c-38984568">[1 more]</label></div><br/><div class="children"><div class="content">True for a particular dominant but antiquated and rapidly aging out model of peer review. Peer review as practiced at PeerJ, eLife, F1000, etc. is collaborative, productive, and maintains integrity in a visible way.<p>Peer review is not inherently terrible. Exploitative rent seeking publishers that commoditize academic careers and outputs, and hold knowledge to ransom, are the problem.<p>Please, everyone, stop publishing in journals that do harm. Think about what the impact of where you publish a paper is and align your choices with your values.</div><br/></div></div><div id="38986517" class="c"><input type="checkbox" id="c-38986517" checked=""/><div class="controls bullet"><span class="by">whatever1</span><span>|</span><a href="#38983668">parent</a><span>|</span><a href="#38984568">prev</a><span>|</span><a href="#38984711">next</a><span>|</span><label class="collapse" for="c-38986517">[-]</label><label class="expand" for="c-38986517">[1 more]</label></div><br/><div class="children"><div class="content">System works as intended. There are filler papers and seminal papers. They both need to pass the sniff test of the peer review process.<p>For the filler papers nobody cares after they get published, they might cite them for the sake of completeness.<p>The seminal papers though will be replicated and any hint of BS will be revealed.</div><br/></div></div></div></div><div id="38984711" class="c"><input type="checkbox" id="c-38984711" checked=""/><div class="controls bullet"><span class="by">currymj</span><span>|</span><a href="#38983668">prev</a><span>|</span><a href="#38984773">next</a><span>|</span><label class="collapse" for="c-38984711">[-]</label><label class="expand" for="c-38984711">[5 more]</label></div><br/><div class="children"><div class="content">where things seem to really go wrong with peer review is when entities outside a scientific community want to use published research to set public policy, decide where to invest, or make high-stakes hiring decisions.<p>doing this actually requires a costly investment in deep understanding of the research and the literature around it, to know if it is sound and high-impact. but nobody wants to make this investment, and they&#x27;ve mostly convinced themselves that just free-riding off peer review is good enough.<p>of course it is not, flawed papers make it through peer review all the time. also this outside use of peer review introduces extremely strong distorting incentives -- an even hugely greater desire to be published in specific prestigious outlets -- in the face of which peer review is not really adequate to catch misconduct.<p>I think the ideal form of peer-reviewed journal is unfortunately logically impossible: its contents would be completely open access, costing nothing for scientists who want to build on the results. But it would require an extremely expensive subscription to find out who has published in it, the money going to fund extremely thorough peer review, so that outside decision-makers can&#x27;t try to free ride and distort the incentives.</div><br/><div id="38984883" class="c"><input type="checkbox" id="c-38984883" checked=""/><div class="controls bullet"><span class="by">bee_rider</span><span>|</span><a href="#38984711">parent</a><span>|</span><a href="#38985816">next</a><span>|</span><label class="collapse" for="c-38984883">[-]</label><label class="expand" for="c-38984883">[2 more]</label></div><br/><div class="children"><div class="content">I think this is not even really a problem with the peer review system, but a problem with the (mostly, nonexistence of) an in depth science journalism field. Peer review just means it is ok to stick in a scientific journal and have peers read it… people with advanced bullshit detectors and nuance parsers in a particular domain.<p>A paper is a brick. A policy is a building. It is not a problem in the brick manufacturing field, if people keep trying to build houses without any mortar.<p>(Just to be explicit, I think you are right on the money and just wanted to elaborate&#x2F;rant).</div><br/><div id="38986723" class="c"><input type="checkbox" id="c-38986723" checked=""/><div class="controls bullet"><span class="by">thaumasiotes</span><span>|</span><a href="#38984711">root</a><span>|</span><a href="#38984883">parent</a><span>|</span><a href="#38985816">next</a><span>|</span><label class="collapse" for="c-38986723">[-]</label><label class="expand" for="c-38986723">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Peer review just means it is ok to stick in a scientific journal and have peers read it… people with advanced bullshit detectors and nuance parsers in a particular domain.<p>That&#x27;s not what peer review means. If that were what it meant, it would have no purpose - the people you describe don&#x27;t benefit from the paper they&#x27;re reading having been through peer review. They already understand the domain.<p>Compare <a href="https:&#x2F;&#x2F;genomesunzipped.org&#x2F;2012&#x2F;08&#x2F;the-first-steps-towards-a-modern-system-of-scientific-publication.php" rel="nofollow">https:&#x2F;&#x2F;genomesunzipped.org&#x2F;2012&#x2F;08&#x2F;the-first-steps-towards-...</a> :<p>&gt; The solution to this problem relies on a simple observation – in my field, I am completely indifferent to whether a paper has been “peer-reviewed” for the basic reason that I consider myself a “peer”. I do not think it extremely hubristic to say that I am reasonably capable of evaluating whether a paper in my field is worth reading, and then if so, of judging its merits. The opinions of other people in the field are of course important, but in no way does the fact that two or three nameless people thought a paper worth publishing influence my opinion of it.<p>The only goal that peer review serves is letting people who <i>aren&#x27;t</i> peers and <i>don&#x27;t</i> understand what the paper is saying believe that they can tell whether the paper is good or not. They still can&#x27;t, but because of the peer review system, they feel that they can.</div><br/></div></div></div></div><div id="38985816" class="c"><input type="checkbox" id="c-38985816" checked=""/><div class="controls bullet"><span class="by">pdonis</span><span>|</span><a href="#38984711">parent</a><span>|</span><a href="#38984883">prev</a><span>|</span><a href="#38986523">next</a><span>|</span><label class="collapse" for="c-38985816">[-]</label><label class="expand" for="c-38985816">[1 more]</label></div><br/><div class="children"><div class="content"><i>&gt; entities outside a scientific community want to use published research to set public policy</i><p>I don&#x27;t think it&#x27;s limited to entities outside a scientific community, because many of the people who want to use published research to set public policy are themselves scientists (often the same scientists who published the research).</div><br/></div></div><div id="38986523" class="c"><input type="checkbox" id="c-38986523" checked=""/><div class="controls bullet"><span class="by">thaumasiotes</span><span>|</span><a href="#38984711">parent</a><span>|</span><a href="#38985816">prev</a><span>|</span><a href="#38984773">next</a><span>|</span><label class="collapse" for="c-38986523">[-]</label><label class="expand" for="c-38986523">[1 more]</label></div><br/><div class="children"><div class="content">&gt; where things seem to really go wrong with peer review is when entities outside a scientific community want to use published research to set public policy, decide where to invest, or make high-stakes hiring decisions<p>OK, but those are the only use cases for peer review.</div><br/></div></div></div></div><div id="38984773" class="c"><input type="checkbox" id="c-38984773" checked=""/><div class="controls bullet"><span class="by">cs702</span><span>|</span><a href="#38984711">prev</a><span>|</span><a href="#38983168">next</a><span>|</span><label class="collapse" for="c-38984773">[-]</label><label class="expand" for="c-38984773">[4 more]</label></div><br/><div class="children"><div class="content">In fields such as Math, Physics, EE, CS, and AI, &quot;peer review&quot; is already being replaced by open debate online. Cutting-edge research in those fields is now routinely posted <i>first</i> on repositories like arXiv, with supporting code and data made public <i>first</i> on sites like Github. The work is reviewed <i>first</i> online, in the open, in a variety of forums, including X.com (formerly Twitter). Anyone with something to contribute can participate, regardless of pedigree. It&#x27;s <i>so much better</i> than the outdated system of &quot;peer review,&quot; which actually isn&#x27;t that old.[a]<p>The question is: <i>Who</i> benefits the most from preserving the dying &quot;peer review&quot; system? <i>Who</i> loses the most from the transition to open debate? Short answer: Publishing houses and conference organizations. Neither wants the status quo to change.<p>[a] <a href="https:&#x2F;&#x2F;michaelnielsen.org&#x2F;blog&#x2F;three-myths-about-scientific-peer-review&#x2F;" rel="nofollow">https:&#x2F;&#x2F;michaelnielsen.org&#x2F;blog&#x2F;three-myths-about-scientific...</a></div><br/><div id="38985020" class="c"><input type="checkbox" id="c-38985020" checked=""/><div class="controls bullet"><span class="by">jltsiren</span><span>|</span><a href="#38984773">parent</a><span>|</span><a href="#38986316">next</a><span>|</span><label class="collapse" for="c-38985020">[-]</label><label class="expand" for="c-38985020">[2 more]</label></div><br/><div class="children"><div class="content">If you are well known in your field, you don&#x27;t need peer review. People will read your preprints, invite you to conferences, and follow you on your preferred platforms anyway. If you are in a well-known project, people will pay attention to your work, even if you are not famous yourself.<p>For everyone else, there is peer review. Attention economy is unforgiving and benefits the elite. With peer review, everyone&#x27;s work gets at least a minimum level of attention. Which may then lead to more attention if the work is worth it.<p>Every serious proposal for replacing the current peer review practices must have the same feature. When someone submits new work, there must be people who have to review it. Fully voluntary reviews don&#x27;t work.</div><br/><div id="38986089" class="c"><input type="checkbox" id="c-38986089" checked=""/><div class="controls bullet"><span class="by">Retric</span><span>|</span><a href="#38984773">root</a><span>|</span><a href="#38985020">parent</a><span>|</span><a href="#38986316">next</a><span>|</span><label class="collapse" for="c-38986089">[-]</label><label class="expand" for="c-38986089">[1 more]</label></div><br/><div class="children"><div class="content">Peer review still occurs outside of journals, it’s simply less formalistic.<p>One of the biggest advantage of peer review is it allows obvious corrections from a 3rd party to occur without wasting everyone in the fields time.  Gatekeeping isn’t the point, increasing the signal to noise ratio is.</div><br/></div></div></div></div><div id="38986316" class="c"><input type="checkbox" id="c-38986316" checked=""/><div class="controls bullet"><span class="by">maleldil</span><span>|</span><a href="#38984773">parent</a><span>|</span><a href="#38985020">prev</a><span>|</span><a href="#38983168">next</a><span>|</span><label class="collapse" for="c-38986316">[-]</label><label class="expand" for="c-38986316">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The work is reviewed first online, in the open<p>Some places require an anonymity period, so you have to wait until that ends to submit your paper to arXiv.</div><br/></div></div></div></div><div id="38983168" class="c"><input type="checkbox" id="c-38983168" checked=""/><div class="controls bullet"><span class="by">tptacek</span><span>|</span><a href="#38984773">prev</a><span>|</span><a href="#38983319">next</a><span>|</span><label class="collapse" for="c-38983168">[-]</label><label class="expand" for="c-38983168">[20 more]</label></div><br/><div class="children"><div class="content">Stefan Savage put it best, I think: a paper accepted in a journal is part of a conversation that science is having; it&#x27;s the start of a debate, not the conclusion. What&#x27;s important about a paper is whether the ideas in it are validated and get built on by other scientists. Peer review is just a sanity check before that process starts, nothing more.</div><br/><div id="38984146" class="c"><input type="checkbox" id="c-38984146" checked=""/><div class="controls bullet"><span class="by">Almondsetat</span><span>|</span><a href="#38983168">parent</a><span>|</span><a href="#38983247">next</a><span>|</span><label class="collapse" for="c-38984146">[-]</label><label class="expand" for="c-38984146">[5 more]</label></div><br/><div class="children"><div class="content">We should start framing 
some journals as &quot;here&#x27;s what the authors have found convincing from bleeding edge submissions, please take a look and try to confirm these findings&quot; for other researchers and others as &quot;here&#x27;s a conservative and comprehensive
list of results which have been solidly reproduced&quot; for professionals in the field who want dependable stuff</div><br/><div id="38984332" class="c"><input type="checkbox" id="c-38984332" checked=""/><div class="controls bullet"><span class="by">zamfi</span><span>|</span><a href="#38983168">root</a><span>|</span><a href="#38984146">parent</a><span>|</span><a href="#38983247">next</a><span>|</span><label class="collapse" for="c-38984332">[-]</label><label class="expand" for="c-38984332">[4 more]</label></div><br/><div class="children"><div class="content">&gt; here&#x27;s a conservative and comprehensive list of results which have been solidly reproduced<p>This sounds more like textbooks.<p>Journals are usually intended to be venues for experts to talk to <i>each other</i>, not even &quot;professionals in the field&quot;.<p>There are some journals (sometimes called &quot;translational&quot;) that try to bring scientific results into practice, though these are often limited to fields where &quot;practice&quot; is its own huge body of knowledge that doesn&#x27;t always overlap with &quot;research&quot; in that field (e.g., Medicine).</div><br/><div id="38986487" class="c"><input type="checkbox" id="c-38986487" checked=""/><div class="controls bullet"><span class="by">treyd</span><span>|</span><a href="#38983168">root</a><span>|</span><a href="#38984332">parent</a><span>|</span><a href="#38983247">next</a><span>|</span><label class="collapse" for="c-38986487">[-]</label><label class="expand" for="c-38986487">[3 more]</label></div><br/><div class="children"><div class="content">&gt; Journals are usually intended to be venues for experts to talk to each other, not even &quot;professionals in the field&quot;.<p>This made sense when communication was slow and the back and forth of discourse could take weeks to months.  But publishing your work in a way that thousands of other readers can consume it is easier now that it&#x27;s been ever, so it stands to reason that sharing the results of scientific works may yield better outcomes if it takes on a different form.</div><br/><div id="38986853" class="c"><input type="checkbox" id="c-38986853" checked=""/><div class="controls bullet"><span class="by">tptacek</span><span>|</span><a href="#38983168">root</a><span>|</span><a href="#38986487">parent</a><span>|</span><a href="#38983247">next</a><span>|</span><label class="collapse" for="c-38986853">[-]</label><label class="expand" for="c-38986853">[2 more]</label></div><br/><div class="children"><div class="content">There&#x27;s a whole Internet to post important results on without waiting for peer review. If you&#x27;re an established practitioner in your field making claims that are straightforward to follow, other practitioners will probably read you.</div><br/><div id="38988279" class="c"><input type="checkbox" id="c-38988279" checked=""/><div class="controls bullet"><span class="by">Almondsetat</span><span>|</span><a href="#38983168">root</a><span>|</span><a href="#38986853">parent</a><span>|</span><a href="#38983247">next</a><span>|</span><label class="collapse" for="c-38988279">[-]</label><label class="expand" for="c-38988279">[1 more]</label></div><br/><div class="children"><div class="content">How can it be an important result if nobody has peer reviewed it let alone reproduce it?<p>It&#x27;s a potentially important claim</div><br/></div></div></div></div></div></div></div></div></div></div><div id="38983247" class="c"><input type="checkbox" id="c-38983247" checked=""/><div class="controls bullet"><span class="by">j7ake</span><span>|</span><a href="#38983168">parent</a><span>|</span><a href="#38984146">prev</a><span>|</span><a href="#38983633">next</a><span>|</span><label class="collapse" for="c-38983247">[-]</label><label class="expand" for="c-38983247">[1 more]</label></div><br/><div class="children"><div class="content">The value of a paper depends on much it influences the thinking of other scientists multiplied by the number of scientists it influences.<p>Therefore the recent super conductivity papers may well end up being very important, if only to stir up the community to action.</div><br/></div></div><div id="38983633" class="c"><input type="checkbox" id="c-38983633" checked=""/><div class="controls bullet"><span class="by">photochemsyn</span><span>|</span><a href="#38983168">parent</a><span>|</span><a href="#38983247">prev</a><span>|</span><a href="#38983860">next</a><span>|</span><label class="collapse" for="c-38983633">[-]</label><label class="expand" for="c-38983633">[4 more]</label></div><br/><div class="children"><div class="content">A funny story from academia is about the cohort of peer reviewers whose primary standard for acceptance is that their own work is cited in the bibliography of the submitted paper.<p>Peer review often fails to catch cheaters, too, as the infamous Jan Hendrik Schön  case demonstrated (from 2000-2001 the Bell Labs researcher published 9 papers in Science and 7 in Nature, all of which made it through peer review, all of which were later retracted on grounds of fraudulent data manipulation).  In the long run, the scandal did improve the field, as all publications on microelectronic graphite etc. devices now require electron microscopy proof that the claimed devices actually exist.  Note current AI technology allows for data fraud and image manipulation that&#x27;s much harder to detect than in the past, though.</div><br/><div id="38985383" class="c"><input type="checkbox" id="c-38985383" checked=""/><div class="controls bullet"><span class="by">neilv</span><span>|</span><a href="#38983168">root</a><span>|</span><a href="#38983633">parent</a><span>|</span><a href="#38985070">next</a><span>|</span><label class="collapse" for="c-38985383">[-]</label><label class="expand" for="c-38985383">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>A funny story from academia is about the cohort of peer reviewers whose primary standard for acceptance is that their own work is cited in the bibliography of the submitted paper.</i><p>In some circles, the two first pieces of feedback on a paper draft, from a nominal co-author:<p>1. Cite [my people&#x27;s various loosely related work].<p>2. Cite [particular researcher in this niche], who&#x27;ll probably be a reviewer.</div><br/></div></div><div id="38985070" class="c"><input type="checkbox" id="c-38985070" checked=""/><div class="controls bullet"><span class="by">spookie</span><span>|</span><a href="#38983168">root</a><span>|</span><a href="#38983633">parent</a><span>|</span><a href="#38985383">prev</a><span>|</span><a href="#38983860">next</a><span>|</span><label class="collapse" for="c-38985070">[-]</label><label class="expand" for="c-38985070">[2 more]</label></div><br/><div class="children"><div class="content">Yes, this is indeed a big problem. If anything, more eyes are needed. Therefore, less walls.</div><br/><div id="38986866" class="c"><input type="checkbox" id="c-38986866" checked=""/><div class="controls bullet"><span class="by">tptacek</span><span>|</span><a href="#38983168">root</a><span>|</span><a href="#38985070">parent</a><span>|</span><a href="#38983860">next</a><span>|</span><label class="collapse" for="c-38986866">[-]</label><label class="expand" for="c-38986866">[1 more]</label></div><br/><div class="children"><div class="content">In a lot of fields, more eyes aren&#x27;t going to create fewer walls, because (a) the important venues are selecting K winners out of N submissions, and that K is the bottleneck, and (b) in most fields, any real (and some unreal) results will get published <i>somewhere</i>.</div><br/></div></div></div></div></div></div><div id="38983860" class="c"><input type="checkbox" id="c-38983860" checked=""/><div class="controls bullet"><span class="by">RcouF1uZ4gsC</span><span>|</span><a href="#38983168">parent</a><span>|</span><a href="#38983633">prev</a><span>|</span><a href="#38983329">next</a><span>|</span><label class="collapse" for="c-38983860">[-]</label><label class="expand" for="c-38983860">[4 more]</label></div><br/><div class="children"><div class="content">Then devalue published papers.<p>Don’t use them as the basis for rewards.<p>Don’t use them as the basis for policy<p>If they are nothing more than the the starting conversation of scientists then we should not put much value in them.<p>Let’s not play the have it both ways game where scientific papers are given deference and then when there is cheating just say li g that scientific papers are just a conversation starter.</div><br/><div id="38984094" class="c"><input type="checkbox" id="c-38984094" checked=""/><div class="controls bullet"><span class="by">tptacek</span><span>|</span><a href="#38983168">root</a><span>|</span><a href="#38983860">parent</a><span>|</span><a href="#38985570">next</a><span>|</span><label class="collapse" for="c-38984094">[-]</label><label class="expand" for="c-38984094">[1 more]</label></div><br/><div class="children"><div class="content">People doing science professionally already understand the value of a paper.</div><br/></div></div><div id="38985570" class="c"><input type="checkbox" id="c-38985570" checked=""/><div class="controls bullet"><span class="by">neilv</span><span>|</span><a href="#38983168">root</a><span>|</span><a href="#38983860">parent</a><span>|</span><a href="#38984094">prev</a><span>|</span><a href="#38984634">next</a><span>|</span><label class="collapse" for="c-38985570">[-]</label><label class="expand" for="c-38985570">[1 more]</label></div><br/><div class="children"><div class="content">&gt; * Then devalue published papers.  Don’t use them as the basis for rewards.*<p>What about the use of papers as metrics for advancing in academic careers?<p>Career advancement could be based on market forces (e.g., productive researcher on something valued, if they&#x27;re not given a sweet enough deal by one university, another university can snap them up).  But how do buyers in the market get the information about how valuable a given researcher is?  (Word of mouth?  CV summary without pubs list?  Job talks?  Interviews?  Twitter?)</div><br/></div></div><div id="38984634" class="c"><input type="checkbox" id="c-38984634" checked=""/><div class="controls bullet"><span class="by">concordDance</span><span>|</span><a href="#38983168">root</a><span>|</span><a href="#38983860">parent</a><span>|</span><a href="#38985570">prev</a><span>|</span><a href="#38983329">next</a><span>|</span><label class="collapse" for="c-38984634">[-]</label><label class="expand" for="c-38984634">[1 more]</label></div><br/><div class="children"><div class="content">If not using papers as a basis for policy then what? Making a committee of academics from a selection of prestigious institutions every time you have a question that needs answering?</div><br/></div></div></div></div><div id="38983329" class="c"><input type="checkbox" id="c-38983329" checked=""/><div class="controls bullet"><span class="by">loceng</span><span>|</span><a href="#38983168">parent</a><span>|</span><a href="#38983860">prev</a><span>|</span><a href="#38983227">next</a><span>|</span><label class="collapse" for="c-38983329">[-]</label><label class="expand" for="c-38983329">[2 more]</label></div><br/><div class="children"><div class="content">I think us humans are flawed enough where we need a reminder of timescale, e.g. how time tested is a theory, how long did a different belief exist before a new understanding arose?<p>Einstein for example had public resistance to his theory of relativity in the beginning.</div><br/><div id="38985163" class="c"><input type="checkbox" id="c-38985163" checked=""/><div class="controls bullet"><span class="by">dctoedt</span><span>|</span><a href="#38983168">root</a><span>|</span><a href="#38983329">parent</a><span>|</span><a href="#38983227">next</a><span>|</span><label class="collapse" for="c-38985163">[-]</label><label class="expand" for="c-38985163">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>Einstein for example had public resistance to his theory of relativity in the beginning.</i><p>More recently, it took <i>years</i> for the medical community to get over its opposition to the evidence that common peptic ulcers are caused by bacteria (which earned two Aussie physicians the 2005 Nobel Prize in Medicine). [0]  A NY Times correspondent (and physician) wrote in 2002, &quot;I’ve never seen the medical community more defensive or more critical of a story.&quot;<p>(Much of the opposition was interest-based, e.g., surgeons who didn&#x27;t want to lose lucrative fees for operating on ulcer patients who could instead be treated with inexpensive antibiotics without the pain and recovery time of major surgery.)<p>[0] <a href="https:&#x2F;&#x2F;www.nobelprize.org&#x2F;prizes&#x2F;medicine&#x2F;2005&#x2F;7693-the-nobel-prize-in-physiology-or-medicine-2005-2005-6&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.nobelprize.org&#x2F;prizes&#x2F;medicine&#x2F;2005&#x2F;7693-the-nob...</a><p>[1] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Timeline_of_peptic_ulcer_disease_and_Helicobacter_pylori#1970%E2%80%9321st_century" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Timeline_of_peptic_ulcer_disea...</a></div><br/></div></div></div></div><div id="38983227" class="c"><input type="checkbox" id="c-38983227" checked=""/><div class="controls bullet"><span class="by">HarryHirsch</span><span>|</span><a href="#38983168">parent</a><span>|</span><a href="#38983329">prev</a><span>|</span><a href="#38983319">next</a><span>|</span><label class="collapse" for="c-38983227">[-]</label><label class="expand" for="c-38983227">[3 more]</label></div><br/><div class="children"><div class="content">Well, yes. But what&#x27;s worrying is that so many people who have seen a university from inside and even have advanced degrees do not know this. Every time some one comes up with grants for reproducing published stuff the silly idea finds enthusiastic support. How come? People should know about the practice of science but don&#x27;t.</div><br/><div id="38983416" class="c"><input type="checkbox" id="c-38983416" checked=""/><div class="controls bullet"><span class="by">BalinKing</span><span>|</span><a href="#38983168">root</a><span>|</span><a href="#38983227">parent</a><span>|</span><a href="#38983319">next</a><span>|</span><label class="collapse" for="c-38983416">[-]</label><label class="expand" for="c-38983416">[2 more]</label></div><br/><div class="children"><div class="content">It seems like you&#x27;re agreeing with the parent, but then the sentence<p>&gt; Every time some one comes up with grants for reproducing published stuff the silly idea finds enthusiastic support.<p>suggests that you think replication isn&#x27;t useful. Or, am I misunderstanding what &quot;the silly idea&quot; refers to?</div><br/><div id="38983502" class="c"><input type="checkbox" id="c-38983502" checked=""/><div class="controls bullet"><span class="by">wizzwizz4</span><span>|</span><a href="#38983168">root</a><span>|</span><a href="#38983416">parent</a><span>|</span><a href="#38983319">next</a><span>|</span><label class="collapse" for="c-38983502">[-]</label><label class="expand" for="c-38983502">[1 more]</label></div><br/><div class="children"><div class="content">The silly idea is the thing they&#x27;re trying to replicate (likely out of suspicion that it&#x27;s a <i>false</i> silly idea).</div><br/></div></div></div></div></div></div></div></div><div id="38983319" class="c"><input type="checkbox" id="c-38983319" checked=""/><div class="controls bullet"><span class="by">TheAceOfHearts</span><span>|</span><a href="#38983168">prev</a><span>|</span><a href="#38983802">next</a><span>|</span><label class="collapse" for="c-38983319">[-]</label><label class="expand" for="c-38983319">[6 more]</label></div><br/><div class="children"><div class="content">Peer reviews should be done in public and considered an ongoing process rather than a one-time thing. If an expert thinks some questions are worth asking, then the resulting discussion should be available for younger generations to learn from it as well. I think the open source ecosystem has shown the effectiveness of such a system. As more data is made public it becomes easier and more effective to sniff out bad actors as well.<p>We could also take steps towards helping establish high reputation for certain papers by introducing a mechanism other than citation count. Maybe some kind of stamp of approval.</div><br/><div id="38983954" class="c"><input type="checkbox" id="c-38983954" checked=""/><div class="controls bullet"><span class="by">adtac</span><span>|</span><a href="#38983319">parent</a><span>|</span><a href="#38983410">next</a><span>|</span><label class="collapse" for="c-38983954">[-]</label><label class="expand" for="c-38983954">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;d take it even further: make peer review public <i>and open</i> to all members of that community. Imagine a forum-like discussion anybody can anonymously review any submission and all reviews are public.<p>Becoming a reviewer should still be invite-only and the system should keep track of the reviewer&#x27;s identity behind the scenes to monitor for abuse, of course. The review can include coarse-grained reputation signals like &quot;has reviewed 100+ papers in the last 5 years&quot;.<p>It might be worth embargoing reviews with a fixed time delay before making them public to prevent bandwagon effects and disincentivise review plagiarism tho. The reviewer&#x27;s identity should be deanonymised too after something along the same time scale as when the paper author&#x27;s identity is revealed.</div><br/><div id="38984441" class="c"><input type="checkbox" id="c-38984441" checked=""/><div class="controls bullet"><span class="by">blackbear_</span><span>|</span><a href="#38983319">root</a><span>|</span><a href="#38983954">parent</a><span>|</span><a href="#38983410">next</a><span>|</span><label class="collapse" for="c-38984441">[-]</label><label class="expand" for="c-38984441">[1 more]</label></div><br/><div class="children"><div class="content">Fortunately this is already happening in some fields such as machine learning. Check this out: <a href="https:&#x2F;&#x2F;openreview.net&#x2F;group?id=ICLR.cc&#x2F;2024&#x2F;Conference#tab-active-submissions" rel="nofollow">https:&#x2F;&#x2F;openreview.net&#x2F;group?id=ICLR.cc&#x2F;2024&#x2F;Conference#tab-...</a></div><br/></div></div></div></div><div id="38983410" class="c"><input type="checkbox" id="c-38983410" checked=""/><div class="controls bullet"><span class="by">nextos</span><span>|</span><a href="#38983319">parent</a><span>|</span><a href="#38983954">prev</a><span>|</span><a href="#38983411">next</a><span>|</span><label class="collapse" for="c-38983410">[-]</label><label class="expand" for="c-38983410">[2 more]</label></div><br/><div class="children"><div class="content">Yes, this is more or less how the non-profit journal <a href="https:&#x2F;&#x2F;elifesciences.org" rel="nofollow">https:&#x2F;&#x2F;elifesciences.org</a> (funded by HHMI, Wellcome, Max Planck, and Wallenberg Foundation) works.<p>A problematic aspect of non-public peer reviews is waste and political battles. I have witnessed first-hand how big names in a particular field reject articles from incumbents that are perfectly sound just to delay their publication and&#x2F;or to copy them.<p>A public review introduces some skin in the game and avoids this kind of behavior, as well as rejections or requests to make changes because of reviewer incompetence. It also avoids the opposite thing, blind acceptance of flawed studies.</div><br/><div id="38984747" class="c"><input type="checkbox" id="c-38984747" checked=""/><div class="controls bullet"><span class="by">sampo</span><span>|</span><a href="#38983319">root</a><span>|</span><a href="#38983410">parent</a><span>|</span><a href="#38983411">next</a><span>|</span><label class="collapse" for="c-38984747">[-]</label><label class="expand" for="c-38984747">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Yes, this is more or less how the non-profit journal <a href="https:&#x2F;&#x2F;elifesciences.org" rel="nofollow">https:&#x2F;&#x2F;elifesciences.org</a> (funded by HHMI, Wellcome, Max Planck, and Wallenberg Foundation) works.<p>Also, all 19 journals published by EGU (European Geophysical Union)<p><a href="https:&#x2F;&#x2F;www.egu.eu&#x2F;publications&#x2F;open-access-journals&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.egu.eu&#x2F;publications&#x2F;open-access-journals&#x2F;</a></div><br/></div></div></div></div><div id="38983411" class="c"><input type="checkbox" id="c-38983411" checked=""/><div class="controls bullet"><span class="by">taeric</span><span>|</span><a href="#38983319">parent</a><span>|</span><a href="#38983410">prev</a><span>|</span><a href="#38983802">next</a><span>|</span><label class="collapse" for="c-38983411">[-]</label><label class="expand" for="c-38983411">[1 more]</label></div><br/><div class="children"><div class="content">I think that was a view on peer review that was lost.  Used to, the citations and continued exploration of a topic was a vital part of the peer review.</div><br/></div></div></div></div><div id="38983802" class="c"><input type="checkbox" id="c-38983802" checked=""/><div class="controls bullet"><span class="by">pacbard</span><span>|</span><a href="#38983319">prev</a><span>|</span><a href="#38986219">next</a><span>|</span><label class="collapse" for="c-38983802">[-]</label><label class="expand" for="c-38983802">[3 more]</label></div><br/><div class="children"><div class="content">Maybe a better descriptor would be that peer review is a reputation-based system.<p>The peers that will review your work likely know about the paper you submitted already, because they work on related work themselves and sat through your conference presentations. Most of them want you to publish your work and will provide a good&#x2F;non-adversarial review of a paper.<p>Sometimes though, your paper hits too close to home for them, then they will try not to get it published or will slow walk the review so that their own work can come out before yours or at the same time.<p>On top of that, you have journal editors who can see everything about the process and can decide to ignore a good&#x2F;bad review to fit their ideas about the paper itself and to fit the overall vision they have for the journal for the coming publication schedule.</div><br/><div id="38984649" class="c"><input type="checkbox" id="c-38984649" checked=""/><div class="controls bullet"><span class="by">concordDance</span><span>|</span><a href="#38983802">parent</a><span>|</span><a href="#38986219">next</a><span>|</span><label class="collapse" for="c-38984649">[-]</label><label class="expand" for="c-38984649">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Sometimes though, your paper hits too close to home for them, then they will try not to get it published or will slow walk the review so that their own work can come out before yours or at the same time.<p>How often does this actually happen? Can&#x27;t say I&#x27;ve heard of people doing this.</div><br/><div id="38985474" class="c"><input type="checkbox" id="c-38985474" checked=""/><div class="controls bullet"><span class="by">tovej</span><span>|</span><a href="#38983802">root</a><span>|</span><a href="#38984649">parent</a><span>|</span><a href="#38986219">next</a><span>|</span><label class="collapse" for="c-38985474">[-]</label><label class="expand" for="c-38985474">[1 more]</label></div><br/><div class="children"><div class="content">I have heard from colleagues that this has happened to them.</div><br/></div></div></div></div></div></div><div id="38986219" class="c"><input type="checkbox" id="c-38986219" checked=""/><div class="controls bullet"><span class="by">thejoneser</span><span>|</span><a href="#38983802">prev</a><span>|</span><a href="#38984601">next</a><span>|</span><label class="collapse" for="c-38986219">[-]</label><label class="expand" for="c-38986219">[5 more]</label></div><br/><div class="children"><div class="content">What is the alternative?  Channeling Chuchill, peer review is the worst form of journal review except for all those other forms that have been tried from time to time.<p>As an associate editor and frequent reviewer, I can say with confidence that peer review filters out at least 90% of the garbage that journals receive as submissions.  It also provides useful feedback to researchers who cannot otherwise get it.  People submit papers knowing they will get rejected because they want to read the referee reports.<p>In my field, academics simply do not trust a result until it has been replicated and scrutinized by other researchers.  If that doesn&#x27;t happen, it&#x27;s usually because the result was not interesting enough for anyone to care.  If the scrutiny reveals problems, that undermines the credibility of the authors, which is ultimately more important than whether they get the pub.<p>A final comment: Peer-reviewed journals differ dramatically in their quality.  If you don&#x27;t know what the good journals are, you should expect that your reading will include a bunch of crap that no serious person in the field would pay attention to.  Why these crap journals even exist is a mystery to me.</div><br/><div id="38986253" class="c"><input type="checkbox" id="c-38986253" checked=""/><div class="controls bullet"><span class="by">baseline-shift</span><span>|</span><a href="#38986219">parent</a><span>|</span><a href="#38984601">next</a><span>|</span><label class="collapse" for="c-38986253">[-]</label><label class="expand" for="c-38986253">[4 more]</label></div><br/><div class="children"><div class="content">Re &#x27;Why these crap journals even exist is a mystery to me.&#x27;
Don&#x27;t journals make money by charging academics to read the whole paper?</div><br/><div id="38986308" class="c"><input type="checkbox" id="c-38986308" checked=""/><div class="controls bullet"><span class="by">maleldil</span><span>|</span><a href="#38986219">root</a><span>|</span><a href="#38986253">parent</a><span>|</span><a href="#38986341">next</a><span>|</span><label class="collapse" for="c-38986308">[-]</label><label class="expand" for="c-38986308">[1 more]</label></div><br/><div class="children"><div class="content">And by charging the authors to publish the paper in the first place. Although I think a lot of the money both ways comes from universities and other organisations that pay for publication costs and have deals with publishers.<p>Thank god for CS&#x27;s culture of pre-prints on arXiv.</div><br/></div></div><div id="38986341" class="c"><input type="checkbox" id="c-38986341" checked=""/><div class="controls bullet"><span class="by">thejoneser</span><span>|</span><a href="#38986219">root</a><span>|</span><a href="#38986253">parent</a><span>|</span><a href="#38986308">prev</a><span>|</span><a href="#38984601">next</a><span>|</span><label class="collapse" for="c-38986341">[-]</label><label class="expand" for="c-38986341">[2 more]</label></div><br/><div class="children"><div class="content">Yes, that&#x27;s got to be part of the explanation.  What&#x27;s not clear to me is why anyone gets professional credit (e.g., tenure) for publishing in a journal that is obviously bad.</div><br/><div id="38987077" class="c"><input type="checkbox" id="c-38987077" checked=""/><div class="controls bullet"><span class="by">buzzergfxkjkl</span><span>|</span><a href="#38986219">root</a><span>|</span><a href="#38986341">parent</a><span>|</span><a href="#38984601">next</a><span>|</span><label class="collapse" for="c-38987077">[-]</label><label class="expand" for="c-38987077">[1 more]</label></div><br/><div class="children"><div class="content">The answer to your question is just part of the whole sad story...<p>Promotion committees (hopefully!) know which journals or publications are low quality. If they are unfamiliar, they generally don&#x27;t have time (or inclination) to verify the paper(s) or publication itself. Especially true when it&#x27;s a slightly different sub-field than their own. So it often comes down to a simple count of pubs. That&#x27;s usually all the credit they need!</div><br/></div></div></div></div></div></div></div></div><div id="38984601" class="c"><input type="checkbox" id="c-38984601" checked=""/><div class="controls bullet"><span class="by">Whoppertime</span><span>|</span><a href="#38986219">prev</a><span>|</span><a href="#38984488">next</a><span>|</span><label class="collapse" for="c-38984601">[-]</label><label class="expand" for="c-38984601">[6 more]</label></div><br/><div class="children"><div class="content">Peer Review seems like a system designed to encourage group think.
The findings of Copernicus that the Earth rotated around the sun instead of vice versa would not pass peer review. Nor would Louis Pasteur&#x27;s Germ Theory.</div><br/><div id="38984728" class="c"><input type="checkbox" id="c-38984728" checked=""/><div class="controls bullet"><span class="by">fasterik</span><span>|</span><a href="#38984601">parent</a><span>|</span><a href="#38984660">next</a><span>|</span><label class="collapse" for="c-38984728">[-]</label><label class="expand" for="c-38984728">[3 more]</label></div><br/><div class="children"><div class="content">Physicists have been using preprint servers for decades, which means anyone can put a paper on the internet for everyone in the field to read and evaluate. So this idea that Copernicus would be suppressed under the current system is absurd. Einstein and Bohr&#x27;s ideas passed peer review, as radical as they were. Every physicist is <i>hoping</i> for data that contradict our current theories. It was a huge disappointment when the only result of the LHC was to confirm the standard model.<p>For all the flaws of academic publishing, we are still in a much better place than when church dogma was the gatekeeper of knowledge.</div><br/><div id="38985050" class="c"><input type="checkbox" id="c-38985050" checked=""/><div class="controls bullet"><span class="by">puzzledobserver</span><span>|</span><a href="#38984601">root</a><span>|</span><a href="#38984728">parent</a><span>|</span><a href="#38984660">next</a><span>|</span><label class="collapse" for="c-38985050">[-]</label><label class="expand" for="c-38985050">[2 more]</label></div><br/><div class="children"><div class="content">If I understand correctly, only one of Einstein&#x27;s papers was ever subjected to peer review. He didn&#x27;t like it. [0]<p>There are some situations where peer review has led to groupthink. The one that comes to mind is the amyloid hypothesis. [1]<p>[0] <a href="https:&#x2F;&#x2F;theconversation.com&#x2F;hate-the-peer-review-process-einstein-did-too-27405" rel="nofollow">https:&#x2F;&#x2F;theconversation.com&#x2F;hate-the-peer-review-process-ein...</a><p>[1] <a href="https:&#x2F;&#x2F;www.science.org&#x2F;content&#x2F;article&#x2F;potential-fabrication-research-images-threatens-key-theory-alzheimers-disease" rel="nofollow">https:&#x2F;&#x2F;www.science.org&#x2F;content&#x2F;article&#x2F;potential-fabricatio...</a></div><br/><div id="38985644" class="c"><input type="checkbox" id="c-38985644" checked=""/><div class="controls bullet"><span class="by">fasterik</span><span>|</span><a href="#38984601">root</a><span>|</span><a href="#38985050">parent</a><span>|</span><a href="#38984660">next</a><span>|</span><label class="collapse" for="c-38985644">[-]</label><label class="expand" for="c-38985644">[1 more]</label></div><br/><div class="children"><div class="content">Thanks, I wasn&#x27;t aware of the level of peer review of physics journals in the early 20th century. Note that Annalen der Physik was publishing 90-95% of submissions, so there was still some review process. I also wonder how much of that had to do with the average quality of a researcher working in physics back then, since physics was still a specialized pursuit of a very small number of people. We have orders of magnitude more people working in science today, so it might not be feasible for journals to publish 90-95% of submissions without a significant drop in quality. I think the solution is for more fields to adopt the model that most of math&#x2F;CS&#x2F;physics already follows. Put everything up on preprint servers and allow people to cite preprints. That way the community can accept ideas and build on them regardless of whether a specific paper makes it into published journals.</div><br/></div></div></div></div></div></div><div id="38984660" class="c"><input type="checkbox" id="c-38984660" checked=""/><div class="controls bullet"><span class="by">frozenport</span><span>|</span><a href="#38984601">parent</a><span>|</span><a href="#38984728">prev</a><span>|</span><a href="#38984488">next</a><span>|</span><label class="collapse" for="c-38984660">[-]</label><label class="expand" for="c-38984660">[2 more]</label></div><br/><div class="children"><div class="content">Yeah I agree. The only good system is one where I judge the validity of the work. Especially if its something I don&#x27;t know about because then I have no baises.</div><br/><div id="38985434" class="c"><input type="checkbox" id="c-38985434" checked=""/><div class="controls bullet"><span class="by">bjornsing</span><span>|</span><a href="#38984601">root</a><span>|</span><a href="#38984660">parent</a><span>|</span><a href="#38984488">next</a><span>|</span><label class="collapse" for="c-38985434">[-]</label><label class="expand" for="c-38985434">[1 more]</label></div><br/><div class="children"><div class="content">You may think it’s a joke. But it’s pretty much the core idea of the Enlightenment (that everyone can think for themselves and don’t need priests to tell them what to think). The motto of the Royal Society is “Nullius in verba”, “take nobody’s word for it”.</div><br/></div></div></div></div></div></div><div id="38984488" class="c"><input type="checkbox" id="c-38984488" checked=""/><div class="controls bullet"><span class="by">johnchristopher</span><span>|</span><a href="#38984601">prev</a><span>|</span><a href="#38984707">next</a><span>|</span><label class="collapse" for="c-38984488">[-]</label><label class="expand" for="c-38984488">[3 more]</label></div><br/><div class="children"><div class="content">Meanwhile:<p>&gt; It has come to my attention that academics are now using generative AI (Chat GPT or whatever) to conduct their peer reviews.<p>&gt; [..]<p>&gt;  If ever there were a compelling argument to totally abandon the intellectually dishonest notion of “blind” peer review – a system everyone knows is broken, rarely fully “blind” and frequently not “blind” at all, but allowing unscrupulous or mediocre yet established scholars to sabotage promising work – then this finally is it: accountability and transparency in the face of the robot takeover. Every person who reviews another person’s scholarship must be willing to sign their name to their own evaluation, to stand by it and assert it was not the work of the machines.<p>Unethical academics, AI, and peer review <a href="https:&#x2F;&#x2F;nicospage.eu&#x2F;blog" rel="nofollow">https:&#x2F;&#x2F;nicospage.eu&#x2F;blog</a></div><br/><div id="38985804" class="c"><input type="checkbox" id="c-38985804" checked=""/><div class="controls bullet"><span class="by">hashtag-til</span><span>|</span><a href="#38984488">parent</a><span>|</span><a href="#38984731">next</a><span>|</span><label class="collapse" for="c-38985804">[-]</label><label class="expand" for="c-38985804">[1 more]</label></div><br/><div class="children"><div class="content">Soon: AI generated paper evaluated by AI reviewer - nobody learns anything.</div><br/></div></div><div id="38984731" class="c"><input type="checkbox" id="c-38984731" checked=""/><div class="controls bullet"><span class="by">bee_rider</span><span>|</span><a href="#38984488">parent</a><span>|</span><a href="#38985804">prev</a><span>|</span><a href="#38984707">next</a><span>|</span><label class="collapse" for="c-38984731">[-]</label><label class="expand" for="c-38984731">[1 more]</label></div><br/><div class="children"><div class="content">It is far too early to say there’s some ethics convention for not using ML models to write peer reviews.<p>If you used a machine to write your peer review, you’ve staked your reputation on its output being correct (in the same way that you stake your reputation on not producing bullshit peer reviews, which is to say… eh, probably not a make-or-break thing but it is in the mix). So you need to check the output. That’s the skill we as a society value.<p>We don’t employ scientists for their literature skills, but for their ability to build and evaluate theories and data, that sort of thing. And hey, less brainpower remembering grammar rules means more for the study of science. This is good.<p>Some people will torpedo their careers by putting too much faith in the ML model, but the way to avoid being them is to apply the same level of diligence to the model’s output as any other tool.<p>I’m more worried that ML models will enable some continued silliness. There’s something odd going on if people type their actual arguments into an ML model, then it produces extra necessary filler text to get into a journal, then we use ML models to review that text and hope to distill it to the actual arguments, and then the general public again uses ML models to do the same. It seems like we’d just be better off sharing the prompts or something, hahaha.</div><br/></div></div></div></div><div id="38984707" class="c"><input type="checkbox" id="c-38984707" checked=""/><div class="controls bullet"><span class="by">dataangel</span><span>|</span><a href="#38984488">prev</a><span>|</span><a href="#38984588">next</a><span>|</span><label class="collapse" for="c-38984707">[-]</label><label class="expand" for="c-38984707">[2 more]</label></div><br/><div class="children"><div class="content">He says peer review is for the authors, but I think science being peer reviewed is one of the key points used to convince the public to trust scientific results.</div><br/><div id="38984976" class="c"><input type="checkbox" id="c-38984976" checked=""/><div class="controls bullet"><span class="by">fasterik</span><span>|</span><a href="#38984707">parent</a><span>|</span><a href="#38984588">next</a><span>|</span><label class="collapse" for="c-38984976">[-]</label><label class="expand" for="c-38984976">[1 more]</label></div><br/><div class="children"><div class="content">If someone thinks that a scientific paper is true because it passed peer review, they need to change their mental model of how science works. Peer review ensures that a given paper meets a minimum standard of quality. Trust of scientific results emerges gradually as the broader field forms a consensus based on dozens or hundreds of papers.</div><br/></div></div></div></div><div id="38984588" class="c"><input type="checkbox" id="c-38984588" checked=""/><div class="controls bullet"><span class="by">omeze</span><span>|</span><a href="#38984707">prev</a><span>|</span><a href="#38983662">next</a><span>|</span><label class="collapse" for="c-38984588">[-]</label><label class="expand" for="c-38984588">[1 more]</label></div><br/><div class="children"><div class="content">This is a great characterization of why peer review is great - it makes honest scientists better. A lot of progress is driven by &quot;jumps&quot; from influential papers, and we want those to be as good as they can. It may not stop frauds, but the frauds weren&#x27;t going to help us anyway. I think fraudulent research mostly hurts by distracting honest scientists and new scientists, not by convincing them of something untrue.</div><br/></div></div><div id="38983662" class="c"><input type="checkbox" id="c-38983662" checked=""/><div class="controls bullet"><span class="by">timkam</span><span>|</span><a href="#38984588">prev</a><span>|</span><a href="#38984541">next</a><span>|</span><label class="collapse" for="c-38983662">[-]</label><label class="expand" for="c-38983662">[1 more]</label></div><br/><div class="children"><div class="content">What I disagree with in the article is the _I never make mistakes_ attitude; it could be worse, but I still think it&#x27;s good to discuss. The author writes that because they are &quot;serious&quot;, they can essentially rebut all criticism &quot;easily&quot;. We are all human and even excellent scientists make honest mistakes. Strong theorists can sometimes make &quot;hard&quot; math mistakes. In the best cases, peer review gives us some assurance that we at least did not make obvious mistakes that can be relatively easily spotted by other specialized researchers.
I think the _never make mistakes_ attitude is dangerous, because it means that researchers need to be very cautious when admitting honest mistakes and their own intellectual fallibility in order to not lose face.</div><br/></div></div><div id="38984541" class="c"><input type="checkbox" id="c-38984541" checked=""/><div class="controls bullet"><span class="by">shermantanktop</span><span>|</span><a href="#38983662">prev</a><span>|</span><a href="#38985132">next</a><span>|</span><label class="collapse" for="c-38984541">[-]</label><label class="expand" for="c-38984541">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m outside this world but what always strikes me is the risk&#x2F;reward gamble that cheaters are taking.<p>By the time they are caught cheating, they have invested dozens of years if not decades into a career that is now pretty much dead.  Is there a life-after-cheating story in the relevant field?  I can&#x27;t imagine much of one.  Part-time lecturer&#x2F;tutor in a fourth rate school, perhaps.<p>Of course, that presumes a moment in time where they begin cheating, risking it all.  If they were cheating all along, from age 12 onward, maybe stopping is the problem.</div><br/></div></div><div id="38985132" class="c"><input type="checkbox" id="c-38985132" checked=""/><div class="controls bullet"><span class="by">donatj</span><span>|</span><a href="#38984541">prev</a><span>|</span><a href="#38983589">next</a><span>|</span><label class="collapse" for="c-38985132">[-]</label><label class="expand" for="c-38985132">[1 more]</label></div><br/><div class="children"><div class="content">This is what I was trying to say a couple weeks ago and kept getting down voted into oblivion. History had shown anything that depends on human actors will  be manipulated.</div><br/></div></div><div id="38983589" class="c"><input type="checkbox" id="c-38983589" checked=""/><div class="controls bullet"><span class="by">T-A</span><span>|</span><a href="#38985132">prev</a><span>|</span><a href="#38983545">next</a><span>|</span><label class="collapse" for="c-38983589">[-]</label><label class="expand" for="c-38983589">[1 more]</label></div><br/><div class="children"><div class="content">This seems topical:<p><a href="https:&#x2F;&#x2F;tvtropes.org&#x2F;pmwiki&#x2F;pmwiki.php&#x2F;Main&#x2F;NoHonorAmongThieves" rel="nofollow">https:&#x2F;&#x2F;tvtropes.org&#x2F;pmwiki&#x2F;pmwiki.php&#x2F;Main&#x2F;NoHonorAmongThie...</a></div><br/></div></div><div id="38983545" class="c"><input type="checkbox" id="c-38983545" checked=""/><div class="controls bullet"><span class="by">sfryxell</span><span>|</span><a href="#38983589">prev</a><span>|</span><a href="#38986246">next</a><span>|</span><label class="collapse" for="c-38983545">[-]</label><label class="expand" for="c-38983545">[2 more]</label></div><br/><div class="children"><div class="content">This applies to code review, another honor based system.</div><br/><div id="38983829" class="c"><input type="checkbox" id="c-38983829" checked=""/><div class="controls bullet"><span class="by">orm</span><span>|</span><a href="#38983545">parent</a><span>|</span><a href="#38986246">next</a><span>|</span><label class="collapse" for="c-38983829">[-]</label><label class="expand" for="c-38983829">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve done both, and been on the receiving end of both, but hadn&#x27;t thought of this similarity. I think it&#x27;s a good analogy.</div><br/></div></div></div></div><div id="38986246" class="c"><input type="checkbox" id="c-38986246" checked=""/><div class="controls bullet"><span class="by">baseline-shift</span><span>|</span><a href="#38983545">prev</a><span>|</span><a href="#38987637">next</a><span>|</span><label class="collapse" for="c-38986246">[-]</label><label class="expand" for="c-38986246">[1 more]</label></div><br/><div class="children"><div class="content">His use of &quot;he&quot; or &quot;his&quot; research was a bit dated looking... More natural to say &quot;they&quot; presented a paper and &quot;their&quot; paper didn&#x27;t pass muster or whatever</div><br/></div></div><div id="38987637" class="c"><input type="checkbox" id="c-38987637" checked=""/><div class="controls bullet"><span class="by">yigalirani</span><span>|</span><a href="#38986246">prev</a><span>|</span><a href="#38983532">next</a><span>|</span><label class="collapse" for="c-38987637">[-]</label><label class="expand" for="c-38987637">[1 more]</label></div><br/><div class="children"><div class="content">&gt; peer review may perpetuate some biases and prevent researchers from putting into question some fundamental questions (“we decided that this is the right way, if you question it, you are a loony”).<p>sounds like the definiton of an echo chamber</div><br/></div></div><div id="38983532" class="c"><input type="checkbox" id="c-38983532" checked=""/><div class="controls bullet"><span class="by">apwheele</span><span>|</span><a href="#38987637">prev</a><span>|</span><a href="#38983483">next</a><span>|</span><label class="collapse" for="c-38983532">[-]</label><label class="expand" for="c-38983532">[3 more]</label></div><br/><div class="children"><div class="content">Based on personal experience, I have a very different opinion than Daniel.<p>I do not think peer review adds much value over self-publishing. Consumers still need to read and verify the work themselves. Bad stuff gets published in peer review so often you still need to verify the integrity of everything yourself. For a simple hypothetical, say peer review is &quot;good quality&quot; 80% of the time, and self-published is good quality 50% of the time. These are made up numbers, but I am saying &quot;80% is too low for the pain of peer review to provide much value&quot;. As a consumer I find 0 value in peer review (I can use google and read what I want, being published in peer review is an annoying paywall if anything).<p>I believe the majority of comments in peer review are not based on technical accuracy (what an outsider may think peer review is about, verifying if something is right or wrong), but tend to be more clearly opinions. So from a writer standpoint for people who say &quot;peer review improves my work&quot;, that does not jive with my experience.<p>There are so many other negatives with peer review in academia (people bean counting pubs, paywalled, the club issue Daniel mentions), I just don&#x27;t think it adds much of any value. If everyone decided tomorrow &quot;I am just going to publish stuff on ArXiv&quot; (or whatever preprint server), the world would not be worse off. I think we would be better off actually.</div><br/><div id="38983721" class="c"><input type="checkbox" id="c-38983721" checked=""/><div class="controls bullet"><span class="by">matthewdgreen</span><span>|</span><a href="#38983532">parent</a><span>|</span><a href="#38987862">next</a><span>|</span><label class="collapse" for="c-38983721">[-]</label><label class="expand" for="c-38983721">[1 more]</label></div><br/><div class="children"><div class="content">Right now in my field (cryptography and security) the number of papers is exploding. The real battle at this point is not only finding time to read the papers, it&#x27;s even finding time to learn about them. Unfortunately self-publishing (AKA preprints) just means we&#x27;re producing a lot of papers nobody has time to read, many of them with obvious flaws and bad presentation that could easily be fixed. Peer-review is <i>one</i> rating system that helps to filter some signal from the noise.</div><br/></div></div><div id="38987862" class="c"><input type="checkbox" id="c-38987862" checked=""/><div class="controls bullet"><span class="by">Ar-Curunir</span><span>|</span><a href="#38983532">parent</a><span>|</span><a href="#38983721">prev</a><span>|</span><a href="#38983483">next</a><span>|</span><label class="collapse" for="c-38987862">[-]</label><label class="expand" for="c-38987862">[1 more]</label></div><br/><div class="children"><div class="content">Good luck keeping up with and filtering through that deluge of mostly shit research. The ArXiV feeds of even semi-popular fields like computer security is mostly full of garbage that you would never see in a good conference.</div><br/></div></div></div></div><div id="38983483" class="c"><input type="checkbox" id="c-38983483" checked=""/><div class="controls bullet"><span class="by">niceice</span><span>|</span><a href="#38983532">prev</a><span>|</span><a href="#38985678">next</a><span>|</span><label class="collapse" for="c-38983483">[-]</label><label class="expand" for="c-38983483">[1 more]</label></div><br/><div class="children"><div class="content">Consensus review is on the way out. I don&#x27;t know what replaces it, perhaps a Github-like system? Whatever it is, hopefully it includes a focus on replication.</div><br/></div></div><div id="38985678" class="c"><input type="checkbox" id="c-38985678" checked=""/><div class="controls bullet"><span class="by">ARandomerDude</span><span>|</span><a href="#38983483">prev</a><span>|</span><a href="#38983493">next</a><span>|</span><label class="collapse" for="c-38985678">[-]</label><label class="expand" for="c-38985678">[1 more]</label></div><br/><div class="children"><div class="content">I would be amazed if it weren’t.  Ultimately, every system is an honor-based based system.</div><br/></div></div><div id="38983493" class="c"><input type="checkbox" id="c-38983493" checked=""/><div class="controls bullet"><span class="by">photochemsyn</span><span>|</span><a href="#38985678">prev</a><span>|</span><a href="#38984182">next</a><span>|</span><label class="collapse" for="c-38983493">[-]</label><label class="expand" for="c-38983493">[1 more]</label></div><br/><div class="children"><div class="content">There are two kinds of peer review in academic science - at the point of publication, and the point of funding.  While quantities of ink have been spilled on the former, the latter gets far less attention - though as you might guess, this is a much more contentious issue because millions of dollars of funding may be on the line.  A good discussion is here:<p>&quot;Is there hard evidence that the grant peer review system performs significantly better than random?&quot;<p><a href="https:&#x2F;&#x2F;academia.stackexchange.com&#x2F;a&#x2F;128343" rel="nofollow">https:&#x2F;&#x2F;academia.stackexchange.com&#x2F;a&#x2F;128343</a><p>In short, &#x27;freedom of research direction&#x27;, aka &#x27;blue skies research&#x27;[1] is steadily becoming a thing of the past, as grant managers and politicians and academic administration teams increasingly take the view that they&#x27;re the ones who should be directing what kinds of research are done, rather than the academic researchers themselves.  This is enforced by a grant system that narrowly defines how the funds can be spent, meaning that your average academic researcher has been transformed into a corporate drone following orders from the executive floor.<p>[1] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Blue_skies_research" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Blue_skies_research</a><p>This transformation of academic research began around the same time Bayh-Dole legislation granted exclusive licensing of university patents developed with taxpayer funds to private interests (1980).</div><br/></div></div><div id="38984182" class="c"><input type="checkbox" id="c-38984182" checked=""/><div class="controls bullet"><span class="by">chrchang523</span><span>|</span><a href="#38983493">prev</a><span>|</span><a href="#38983743">next</a><span>|</span><label class="collapse" for="c-38984182">[-]</label><label class="expand" for="c-38984182">[2 more]</label></div><br/><div class="children"><div class="content">(2008)</div><br/><div id="38985717" class="c"><input type="checkbox" id="c-38985717" checked=""/><div class="controls bullet"><span class="by">dang</span><span>|</span><a href="#38984182">parent</a><span>|</span><a href="#38983743">next</a><span>|</span><label class="collapse" for="c-38985717">[-]</label><label class="expand" for="c-38985717">[1 more]</label></div><br/><div class="children"><div class="content">Added. Thanks!</div><br/></div></div></div></div><div id="38983743" class="c"><input type="checkbox" id="c-38983743" checked=""/><div class="controls bullet"><span class="by">thsksbd</span><span>|</span><a href="#38984182">prev</a><span>|</span><a href="#38984211">next</a><span>|</span><label class="collapse" for="c-38983743">[-]</label><label class="expand" for="c-38983743">[1 more]</label></div><br/><div class="children"><div class="content">&quot;Peer review is an honor-based system&quot;<p>But we are not an honor society anymore</div><br/></div></div><div id="38984211" class="c"><input type="checkbox" id="c-38984211" checked=""/><div class="controls bullet"><span class="by">bsdpufferfish</span><span>|</span><a href="#38983743">prev</a><span>|</span><a href="#38984658">next</a><span>|</span><label class="collapse" for="c-38984211">[-]</label><label class="expand" for="c-38984211">[1 more]</label></div><br/><div class="children"><div class="content">Reminder that &quot;peer review&quot; used to mean sending a letter to your friend to see what they think of your work.<p>The formalized system of opaque and unaccountable criticism that gatekeeps science had to have been invented in the 20th century.</div><br/></div></div><div id="38984658" class="c"><input type="checkbox" id="c-38984658" checked=""/><div class="controls bullet"><span class="by">alpineidyll3</span><span>|</span><a href="#38984211">prev</a><span>|</span><a href="#38983287">next</a><span>|</span><label class="collapse" for="c-38984658">[-]</label><label class="expand" for="c-38984658">[1 more]</label></div><br/><div class="children"><div class="content">If people would actually _measure_ the outcomes of peer review instead of talking about it, I think it would meet a swift end.<p>Empirically, I find no improvement in reproducibility between arxiv and journals. The costs are incredibly high too.<p>Like many things in our world peer review is a short lived extrapolation which doesn&#x27;t resemble it&#x27;s origins but is regarded as immutable gospel. It matters most if what you need is the respect of academics.</div><br/></div></div><div id="38983287" class="c"><input type="checkbox" id="c-38983287" checked=""/><div class="controls bullet"><span class="by">loceng</span><span>|</span><a href="#38984658">prev</a><span>|</span><a href="#38987520">next</a><span>|</span><label class="collapse" for="c-38983287">[-]</label><label class="expand" for="c-38983287">[4 more]</label></div><br/><div class="children"><div class="content">Dr. Christopher Essex in a recent interview [<a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=jpjpBWxvamA" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=jpjpBWxvamA</a>] highlighted that it&#x27;s called &quot;peer review&quot; and not &quot;expert review&quot; - which I think is an often most important detail that should not put anyone on a pedestal; of course the &quot;peer review&quot; system has been hijacked-corrupted to some degree, where there are gatekeepers to getting published in the &quot;most reputable&quot; journals.</div><br/><div id="38983332" class="c"><input type="checkbox" id="c-38983332" checked=""/><div class="controls bullet"><span class="by">hinkley</span><span>|</span><a href="#38983287">parent</a><span>|</span><a href="#38987520">next</a><span>|</span><label class="collapse" for="c-38983332">[-]</label><label class="expand" for="c-38983332">[3 more]</label></div><br/><div class="children"><div class="content">I think the layman assumes that the authors <i>are</i> experts and thus so too would the peers.<p>Journalists are a huge problem here. I blame about half of the anti science backlash on breathless journalism writing checks science can’t cash.</div><br/><div id="38984319" class="c"><input type="checkbox" id="c-38984319" checked=""/><div class="controls bullet"><span class="by">logifail</span><span>|</span><a href="#38983287">root</a><span>|</span><a href="#38983332">parent</a><span>|</span><a href="#38987520">next</a><span>|</span><label class="collapse" for="c-38984319">[-]</label><label class="expand" for="c-38984319">[2 more]</label></div><br/><div class="children"><div class="content">&gt; I blame about half of the anti science backlash on breathless journalism [..]<p>This isn&#x27;t a science-specific problem.   Journalism has <i>serious</i> issues with incentives.</div><br/><div id="38988462" class="c"><input type="checkbox" id="c-38988462" checked=""/><div class="controls bullet"><span class="by">hinkley</span><span>|</span><a href="#38983287">root</a><span>|</span><a href="#38984319">parent</a><span>|</span><a href="#38987520">next</a><span>|</span><label class="collapse" for="c-38988462">[-]</label><label class="expand" for="c-38988462">[1 more]</label></div><br/><div class="children"><div class="content">I took one journalism class, taught by a crotchety old man, who seemed to be of the opinion that they were all liars and cheats pretty much as far back as you can go. Hearst just weaponized a rot that was always there.<p>But what do you do without news?</div><br/></div></div></div></div></div></div></div></div><div id="38987520" class="c"><input type="checkbox" id="c-38987520" checked=""/><div class="controls bullet"><span class="by">apapapa</span><span>|</span><a href="#38983287">prev</a><span>|</span><a href="#38983561">next</a><span>|</span><label class="collapse" for="c-38987520">[-]</label><label class="expand" for="c-38987520">[1 more]</label></div><br/><div class="children"><div class="content">Well... No shit.</div><br/></div></div></div></div></div></div></div></body></html>