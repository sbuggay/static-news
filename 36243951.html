<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1686301251749" as="style"/><link rel="stylesheet" href="styles.css?v=1686301251749"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.kolide.com/blog/ai-browser-extensions-are-a-security-nightmare">AI browser extensions are a security nightmare</a> <span class="domain">(<a href="https://www.kolide.com">www.kolide.com</a>)</span></div><div class="subtext"><span>terracatta</span> | <span>112 comments</span></div><br/><div><div id="36254211" class="c"><input type="checkbox" id="c-36254211" checked=""/><div class="controls bullet"><span class="by">Roark66</span><span>|</span><a href="#36247164">next</a><span>|</span><label class="collapse" for="c-36254211">[-]</label><label class="expand" for="c-36254211">[2 more]</label></div><br/><div class="children"><div class="content">&gt;Actually, the current AI situation may be even more perilous than Jurassic Park. In that film, the misguided science that brought dinosaurs back to life was at least confined to a single island and controlled by a single corporation. In our current reality, the dinosaurs are loose, and anyone who wants to can play with one.<p>I&#x27;m really tired of reading stuff like this above. Seriously, AI is a disruptive tech and some people will oppose any change, but this is too much. All of the &quot;security issues&quot; mentioned in the article are true for browser extensions,and perhaps even software in general.<p>Then the author talks about &quot;copyright mess&quot; just before describing how it is pretty much resolved in their company (copilot banned).<p>The only real &quot;problem with AI&quot; is really a &quot;problem with cloud&quot; or more precisely &quot;problem with people&#x27;s lack of understanding of it&quot;. Average people should be interested in finding software alternatives that don&#x27;t undermine their privacy.<p>For example look at AI image up scaling. Every single android app other than mine sends user&#x27;s images to a server somewhere. Are those images retained? Are they scanned for whatever &quot;legal purposes&quot; the maker deems adequate? No one knows. No one cares. Well specifically in the entire world about 90 people seem to care.<p>Why 90 people? Because that&#x27;s how many users my android app has 6 months after release. (the app does all processing locally, free version is ad supported, paid version can be used 100% offline).</div><br/></div></div><div id="36247164" class="c"><input type="checkbox" id="c-36247164" checked=""/><div class="controls bullet"><span class="by">amelius</span><span>|</span><a href="#36254211">prev</a><span>|</span><a href="#36244679">next</a><span>|</span><label class="collapse" for="c-36247164">[-]</label><label class="expand" for="c-36247164">[22 more]</label></div><br/><div class="children"><div class="content">Actually, aren&#x27;t <i>all</i> browser extensions a security nightmare?<p>Or has something changed recently?</div><br/><div id="36249994" class="c"><input type="checkbox" id="c-36249994" checked=""/><div class="controls bullet"><span class="by">kpw94</span><span>|</span><a href="#36247164">parent</a><span>|</span><a href="#36248148">next</a><span>|</span><label class="collapse" for="c-36249994">[-]</label><label class="expand" for="c-36249994">[2 more]</label></div><br/><div class="children"><div class="content">Yeah parts of the article would still be as valid if this was about regular extensions.<p>The main difference is that AI extension, by design, send the content of the pages you browse to a server.<p>A malicious &quot;calculator&quot; extension could also send all the content to a server, and extension users don&#x27;t really have an idea of what each extension is actually doing.<p>So skip the &quot;Malware posing as AI browser extension&quot; section, it&#x27;s same kind of security issues as a malware calculator extension.<p>The legitimate AI extension&#x27;s problems are more interesting.<p>Article wastes a bit more time on other security issues you get from using AI LLM in general. Those apply whether you&#x27;re using a browser extension or chat.openai.com directly.<p>The valid point that applies to narrowly AI browser extension are:<p>1) it could send sensitive data you wouldn&#x27;t have sent otherwise. Most people would know what they&#x27;re doing when they explicitly paste the stuff on chat.openai.com. But when it&#x27;s now automated via the extension DOM scraping, it&#x27;s a bit harder to realize how much you&#x27;re giving away.<p>2) And the hidden text prompt injection. That&#x27;s interesting as now your attacker could be the website you browse, if you have configured too many plugins (Zapier plugin giving access to your email)<p>These 2 parts of TFA are imo novel security issues that only exist with AI browser extension, and are interesting.</div><br/><div id="36250506" class="c"><input type="checkbox" id="c-36250506" checked=""/><div class="controls bullet"><span class="by">mattigames</span><span>|</span><a href="#36247164">root</a><span>|</span><a href="#36249994">parent</a><span>|</span><a href="#36248148">next</a><span>|</span><label class="collapse" for="c-36250506">[-]</label><label class="expand" for="c-36250506">[1 more]</label></div><br/><div class="children"><div class="content">If a calculator extension is caught sending any data at all over the network they immediately would be suspicious, but evey AI extension has plausible deniability when making any requests, most can send all the webpage including form inputs and still have such deniability.</div><br/></div></div></div></div><div id="36248148" class="c"><input type="checkbox" id="c-36248148" checked=""/><div class="controls bullet"><span class="by">madeofpalk</span><span>|</span><a href="#36247164">parent</a><span>|</span><a href="#36249994">prev</a><span>|</span><a href="#36250002">next</a><span>|</span><label class="collapse" for="c-36248148">[-]</label><label class="expand" for="c-36248148">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s actually what I thought the title was until reading your comment, and I agreed vehemently.</div><br/></div></div><div id="36250002" class="c"><input type="checkbox" id="c-36250002" checked=""/><div class="controls bullet"><span class="by">moritzwarhier</span><span>|</span><a href="#36247164">parent</a><span>|</span><a href="#36248148">prev</a><span>|</span><a href="#36247339">next</a><span>|</span><label class="collapse" for="c-36250002">[-]</label><label class="expand" for="c-36250002">[7 more]</label></div><br/><div class="children"><div class="content">Already commented something similar in another thread:<p>Why is the security policy for extensions still not architected like other web permissions?<p>There has been a shift on mobile already from &quot;take it or leave it&quot;-style permissions on install towards more fine grained control not overidable by the app manifest.<p>I think Browser extensions should behave similarly. Especially when it comes to which origins an extensions is allowed to act on.<p>The user should be able to restrict this regardless of the manifest, even forced to do.<p>Extensions that need to act on all or an unknown set of origins should require a big and scary prompt after installation, regardless of what the user agrees to during installation.<p>I say this as a happy user of uBlock origin and React DevTools.<p>But for the common user the default should be to deny permissions and require user interaction.</div><br/><div id="36251091" class="c"><input type="checkbox" id="c-36251091" checked=""/><div class="controls bullet"><span class="by">dylan604</span><span>|</span><a href="#36247164">root</a><span>|</span><a href="#36250002">parent</a><span>|</span><a href="#36250042">next</a><span>|</span><label class="collapse" for="c-36251091">[-]</label><label class="expand" for="c-36251091">[4 more]</label></div><br/><div class="children"><div class="content">you can make a warning as big and scary as you can, and people will just blindly hit accept&#x2F;agree&#x2F;ok. the look&#x2F;design of the banner is not what will stop people from hitting ok, as at this point, i don&#x27;t think anything will</div><br/><div id="36251372" class="c"><input type="checkbox" id="c-36251372" checked=""/><div class="controls bullet"><span class="by">hsbauauvhabzb</span><span>|</span><a href="#36247164">root</a><span>|</span><a href="#36251091">parent</a><span>|</span><a href="#36251814">next</a><span>|</span><label class="collapse" for="c-36251372">[-]</label><label class="expand" for="c-36251372">[2 more]</label></div><br/><div class="children"><div class="content">While this is historically true, if the text is human readable - ‘may be able to read and transmit to a third party any data you input, including credit card numbers and passwords’ - is fairly likely to raise awareness. It’s not effect, but it’s better than nothing.<p>It’s worth contrasting clear communication such as the above to a EULA designed by scummy companies to <i>not</i> be read, browsers presumably have nothing to gain by exposing malicious plugins, so they’re a good candidate for the former.<p>If only we could get Mozilla executive to implement something actually useful instead of whatever meme tech they’ve lost their nut over this week, that’d be nice.</div><br/><div id="36254391" class="c"><input type="checkbox" id="c-36254391" checked=""/><div class="controls bullet"><span class="by">tweetle_beetle</span><span>|</span><a href="#36247164">root</a><span>|</span><a href="#36251372">parent</a><span>|</span><a href="#36251814">next</a><span>|</span><label class="collapse" for="c-36254391">[-]</label><label class="expand" for="c-36254391">[1 more]</label></div><br/><div class="children"><div class="content">In isolation this is true, but for most people they just want the product the extension is offering - skipping past boring warnings is a means to an end. There is also the issue of warning fatigue when extension authors normalise asking for more permissions - more warnings leads to less engagement.<p>One way to avoid this would be to have an extension market which highlights alternative extensions and how they differ in permissions. But it would be hard to maintain those relationships, create a new oppportunity to game trust, push responsibility onto the market owners, etc. And ultimately, many interact with proprietary products without a direct competitor e.g. if FAANGs made them. So I can&#x27;t see it happening.</div><br/></div></div></div></div><div id="36251814" class="c"><input type="checkbox" id="c-36251814" checked=""/><div class="controls bullet"><span class="by">klyrs</span><span>|</span><a href="#36247164">root</a><span>|</span><a href="#36251091">parent</a><span>|</span><a href="#36251372">prev</a><span>|</span><a href="#36250042">next</a><span>|</span><label class="collapse" for="c-36251814">[-]</label><label class="expand" for="c-36251814">[1 more]</label></div><br/><div class="children"><div class="content"><i>Click &#x27;agree&#x27; on the next 3 prompts within 15 seconds to see a monkey throwing an ice cream cone at King Charles</i></div><br/></div></div></div></div><div id="36250042" class="c"><input type="checkbox" id="c-36250042" checked=""/><div class="controls bullet"><span class="by">hgsgm</span><span>|</span><a href="#36247164">root</a><span>|</span><a href="#36250002">parent</a><span>|</span><a href="#36251091">prev</a><span>|</span><a href="#36247339">next</a><span>|</span><label class="collapse" for="c-36250042">[-]</label><label class="expand" for="c-36250042">[2 more]</label></div><br/><div class="children"><div class="content">Mobile doesn&#x27;t give you control over which origins it contacts.</div><br/><div id="36250152" class="c"><input type="checkbox" id="c-36250152" checked=""/><div class="controls bullet"><span class="by">moritzwarhier</span><span>|</span><a href="#36247164">root</a><span>|</span><a href="#36250042">parent</a><span>|</span><a href="#36247339">next</a><span>|</span><label class="collapse" for="c-36250152">[-]</label><label class="expand" for="c-36250152">[1 more]</label></div><br/><div class="children"><div class="content">Yes you are right, that came down to me after I hit the submit button. But consider my train of thought more an associative one.<p>I&#x27;d like an UI similar to the mobile one.
I brought up the origin thing because for lots of extensions I would like that kind of UI for origin control. Origin control is part of WebExtension API, but it&#x27;s during installation, which forces even well-meaning developers to request overly broad permissions for some kinds of extensions.</div><br/></div></div></div></div></div></div><div id="36247339" class="c"><input type="checkbox" id="c-36247339" checked=""/><div class="controls bullet"><span class="by">jprete</span><span>|</span><a href="#36247164">parent</a><span>|</span><a href="#36250002">prev</a><span>|</span><a href="#36247280">next</a><span>|</span><label class="collapse" for="c-36247339">[-]</label><label class="expand" for="c-36247339">[8 more]</label></div><br/><div class="children"><div class="content">No, because a typical safe-to-run browser extension is written in such a way that it can be examined to see what it does. AI-based tools can’t be analyzed based on their code, so the only way to make them safe is by limiting their capabilities. Any such capability limit is likely to be either too constraining, not constraining enough, or require as much planning ability as the AI itself.</div><br/><div id="36249634" class="c"><input type="checkbox" id="c-36249634" checked=""/><div class="controls bullet"><span class="by">majormajor</span><span>|</span><a href="#36247164">root</a><span>|</span><a href="#36247339">parent</a><span>|</span><a href="#36247571">next</a><span>|</span><label class="collapse" for="c-36249634">[-]</label><label class="expand" for="c-36249634">[1 more]</label></div><br/><div class="children"><div class="content">When you talk about not being able to analyze these based on their code do you mean because today they&#x27;re all just calling out to OpenAI or whoever?<p>The risks listed in the article itself mostly seem to fall under the same, non-AI-extension, core problem of &quot;you&#x27;re given them all your data.&quot; And that&#x27;s a risk for non-AI-based extensions too, but if you look at the code of an AI one, it&#x27;s gonna be obvious that it&#x27;s shipping it off to a third party server, right? And once that happens... you can&#x27;t un-close that door.<p>(The risks about copyright and such of content you generate by using AI tools are interesting and different, but I don&#x27;t know that I&#x27;d call them security ones.)<p>The prompt injection one is pretty interesting, but still seems to fall under &quot;traditional&quot; plugin security issues: if you authorize a plugin to read everything on your screen, AND have full integration with your email, or whatever, then... that&#x27;s a huge risk. The AI&#x2F;injection part makes it triggerable by a third-party, which certainly raises the alarm level a lot, but also: bad idea, period, IMO.</div><br/></div></div><div id="36247571" class="c"><input type="checkbox" id="c-36247571" checked=""/><div class="controls bullet"><span class="by">amelius</span><span>|</span><a href="#36247164">root</a><span>|</span><a href="#36247339">parent</a><span>|</span><a href="#36249634">prev</a><span>|</span><a href="#36247280">next</a><span>|</span><label class="collapse" for="c-36247571">[-]</label><label class="expand" for="c-36247571">[6 more]</label></div><br/><div class="children"><div class="content">The problem is the permission system. Like apps, extensions have an all-or-nothing attitude to permissions. Browsers should allow the user to be more specific about permissions, and let extensions think the user gave more permissions than they actually did. E.g. if extension insists that they need &quot;access to entire filesystem&quot;, the browser should make the extension believe they have access to the entire filesystem, but of course the entire thing is sandboxed and the user can restrict the access behind the scenes.<p>Without this feature, extensions will keep insisting they need access, and the user will eventually fall for it.</div><br/><div id="36247746" class="c"><input type="checkbox" id="c-36247746" checked=""/><div class="controls bullet"><span class="by">josteink</span><span>|</span><a href="#36247164">root</a><span>|</span><a href="#36247571">parent</a><span>|</span><a href="#36247280">next</a><span>|</span><label class="collapse" for="c-36247746">[-]</label><label class="expand" for="c-36247746">[5 more]</label></div><br/><div class="children"><div class="content">&gt; Like apps, extensions have an all-or-nothing attitude to permissions<p>Browser extensions needs to declare their permissions. With Manifest V3 we’re seeing even more need to declare permissions.<p>Any extension cannot do anything not explicitly granted to it by the user upon installation.</div><br/><div id="36249380" class="c"><input type="checkbox" id="c-36249380" checked=""/><div class="controls bullet"><span class="by">actionablefiber</span><span>|</span><a href="#36247164">root</a><span>|</span><a href="#36247746">parent</a><span>|</span><a href="#36247280">next</a><span>|</span><label class="collapse" for="c-36249380">[-]</label><label class="expand" for="c-36249380">[4 more]</label></div><br/><div class="children"><div class="content">The issue is those extensions can withhold valuable functionality needlessly.<p>If I download $usefulWikipediaCompanionExtension whose functionality only depends on access to *.wikipedia.org but whose manifest <i>demands</i> permission on all sites, I&#x27;d like to be able to tell my browser &quot;if I&#x27;m not really on Wikipedia, only show the extension a blank page.&quot;</div><br/><div id="36250062" class="c"><input type="checkbox" id="c-36250062" checked=""/><div class="controls bullet"><span class="by">hgsgm</span><span>|</span><a href="#36247164">root</a><span>|</span><a href="#36249380">parent</a><span>|</span><a href="#36247280">next</a><span>|</span><label class="collapse" for="c-36250062">[-]</label><label class="expand" for="c-36250062">[3 more]</label></div><br/><div class="children"><div class="content">That&#x27;s a lot more work than saying &quot;No&quot; to using the malware.</div><br/><div id="36250280" class="c"><input type="checkbox" id="c-36250280" checked=""/><div class="controls bullet"><span class="by">actionablefiber</span><span>|</span><a href="#36247164">root</a><span>|</span><a href="#36250062">parent</a><span>|</span><a href="#36247280">next</a><span>|</span><label class="collapse" for="c-36250280">[-]</label><label class="expand" for="c-36250280">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s common for various counterparties, including software, to ask for much more information than they need and possibly be doing untrustworthy things with it while also providing legitimate value to the end user.<p>I&#x27;ve lied about my birthday while signing up for websites before. I&#x27;ve also made ad-hoc email addresses with forwarding to conceal my main email address. I&#x27;ve given fictitious phone numbers and I&#x27;ve used the names of fictional characters. I do this because I benefit from the service but I don&#x27;t trust the provider to use my information responsibly.<p>Not a logical leap to go from there to feeding fake data to extensions when they request data that the user deems unnecessary for their functionality.</div><br/><div id="36250422" class="c"><input type="checkbox" id="c-36250422" checked=""/><div class="controls bullet"><span class="by">saurik</span><span>|</span><a href="#36247164">root</a><span>|</span><a href="#36250280">parent</a><span>|</span><a href="#36247280">next</a><span>|</span><label class="collapse" for="c-36250422">[-]</label><label class="expand" for="c-36250422">[1 more]</label></div><br/><div class="children"><div class="content">Yeah: while declaring permissions sounds cool and tries to fit into the narrative of helping protect end users who don&#x27;t know how to manage anything themselves, <i>at the end of the day</i> it first requires an extremely opinionated central entity in charge of listings which takes a role in attempting to mediate the incentive incompatibilities (something which should raise serious ethical red flags and begs the question of conflicts of interest with respect to that player and the market that they get to fully control) but then still not only <i>doesn&#x27;t work</i> to prevent users from getting abused, it <i>will never work</i>: &quot;this app has requested access to your birthday&quot; might be easy for end users, but (if this must be an API; but like, to the extent to which birthday is a bad example, this generalizes to every other thing that people currently must grant as &quot;permissions&quot;) the only actually-correct solution is to <i>always</i> provide a concrete random date to every app by default and then allow the user to go out of their way--and this <i>must not</i>, under any circumstance, be something the app is allowed to prompt for or have any visibility into: this must be something the user has to initiate through external UI--to say &quot;I grant this app access to my real birthday&quot; (which, to the app, would have to look like the user merely changed the setting on their birthday to some other random date, as opposed to &quot;the user finally gave us permission to see the same date that they can share to every other app&quot;).</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="36247280" class="c"><input type="checkbox" id="c-36247280" checked=""/><div class="controls bullet"><span class="by">LapsangGuzzler</span><span>|</span><a href="#36247164">parent</a><span>|</span><a href="#36247339">prev</a><span>|</span><a href="#36250057">next</a><span>|</span><label class="collapse" for="c-36247280">[-]</label><label class="expand" for="c-36247280">[2 more]</label></div><br/><div class="children"><div class="content">shout out to the Arc browser, which has it&#x27;s own browser sandbox and WYSIWYG tools to build JS snippets that run in your browser. I&#x27;m not affiliated with them in any way, but they&#x27;re really changing the way I look at browsing online.</div><br/><div id="36247830" class="c"><input type="checkbox" id="c-36247830" checked=""/><div class="controls bullet"><span class="by">moffkalast</span><span>|</span><a href="#36247164">root</a><span>|</span><a href="#36247280">parent</a><span>|</span><a href="#36250057">next</a><span>|</span><label class="collapse" for="c-36247830">[-]</label><label class="expand" for="c-36247830">[1 more]</label></div><br/><div class="children"><div class="content">Does that come on a CD along with Intel Arc GPUs? :D</div><br/></div></div></div></div><div id="36250057" class="c"><input type="checkbox" id="c-36250057" checked=""/><div class="controls bullet"><span class="by">notatoad</span><span>|</span><a href="#36247164">parent</a><span>|</span><a href="#36247280">prev</a><span>|</span><a href="#36244679">next</a><span>|</span><label class="collapse" for="c-36250057">[-]</label><label class="expand" for="c-36250057">[1 more]</label></div><br/><div class="children"><div class="content">an extension developer can scope their extension to only run on certain URLs, and if that list changes then chrome will automatically disable it until the user re-authorizes for the new set of URLs.<p>so they&#x27;re not a <i>total</i> security nightmare if they&#x27;re only authorized to run on sites where you don&#x27;t enter any private data.  for example, looking through my extensions list, the py3redirect that autmatically redirects python2 documentation pages to python3 pages doesn&#x27;t request access to anything other than python.org.<p>but otherwise, yeah, you&#x27;re giving permission to execute arbitrary code on any website you visit, which is about as compromised as your browser can get.</div><br/></div></div></div></div><div id="36244679" class="c"><input type="checkbox" id="c-36244679" checked=""/><div class="controls bullet"><span class="by">kypro</span><span>|</span><a href="#36247164">prev</a><span>|</span><a href="#36246605">next</a><span>|</span><label class="collapse" for="c-36244679">[-]</label><label class="expand" for="c-36244679">[56 more]</label></div><br/><div class="children"><div class="content">&gt; <i>Yes, large language models (LLMs) are not actually AI in that they are not actually intelligent, but we’re going to use the common nomenclature here.<p>I&#x27;m sorry for the off-topic comment, but why do I keep seeing this? What am I missing here – is it that some people define intelligence as &gt;= human, or that LLM are not intelligence because they&#x27;re *just* statistical models?</i></div><br/><div id="36246249" class="c"><input type="checkbox" id="c-36246249" checked=""/><div class="controls bullet"><span class="by">VoodooJuJu</span><span>|</span><a href="#36244679">parent</a><span>|</span><a href="#36245080">next</a><span>|</span><label class="collapse" for="c-36246249">[-]</label><label class="expand" for="c-36246249">[10 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a way for the author to distinguish himself as one who is neither a purveyor of, nor fooled by, the magic, grift, and cringy sci-fi fantasizing that currently comprises the majority of AI discussion.<p>Currently, most mentions of AI, outside of a proper technical discussion, are coming from crypto-tier grifters and starry-eyed suckers. Even further, a lot of discussions from otherwise technical people are sci-fi-tier fearmongering about some ostensible Skynet, or something, it&#x27;s not quite clear, but it&#x27;s clearly quite cringe. The latter is one of the many calibers of ammunition being used by AI incumbents to dig regulatory moats for themselves.<p>Anyway, I understand why the author is distinguishing himself with his LLM...AI disclaimer, given the above.</div><br/><div id="36246751" class="c"><input type="checkbox" id="c-36246751" checked=""/><div class="controls bullet"><span class="by">dguest</span><span>|</span><a href="#36244679">root</a><span>|</span><a href="#36246249">parent</a><span>|</span><a href="#36245080">next</a><span>|</span><label class="collapse" for="c-36246751">[-]</label><label class="expand" for="c-36246751">[9 more]</label></div><br/><div class="children"><div class="content">In my field it&#x27;s accepted (by some) that you write &quot;AI&quot; for your grant proposal and say &quot;ML&quot; when you talk to colleagues and want to be taken seriously.<p>It feels a bit wrong to me, because as you say it&#x27;s arguably a grift, in this case on the taxpayer who funds science grants. More charitably it might just be the applicant admitting that they have no idea what they are doing, and the funding agency seeing this as a good chance to explore the unknown. 
Still, unless the field is AI research (mine isn&#x27;t) it seems like funding agencies should giving money to people who understand their tools.</div><br/><div id="36246829" class="c"><input type="checkbox" id="c-36246829" checked=""/><div class="controls bullet"><span class="by">sebzim4500</span><span>|</span><a href="#36244679">root</a><span>|</span><a href="#36246751">parent</a><span>|</span><a href="#36245080">next</a><span>|</span><label class="collapse" for="c-36246829">[-]</label><label class="expand" for="c-36246829">[8 more]</label></div><br/><div class="children"><div class="content">Most people outside of academia understand AI to include way more than just ML. People refer to the bots in video games as AI and they are probably a few hundred lines of straightforward code.<p>I don&#x27;t think there is anything wrong with using the colloquial definition of the term when communicating with funding agencies&#x2F;the public.</div><br/><div id="36246969" class="c"><input type="checkbox" id="c-36246969" checked=""/><div class="controls bullet"><span class="by">shagie</span><span>|</span><a href="#36244679">root</a><span>|</span><a href="#36246829">parent</a><span>|</span><a href="#36250662">next</a><span>|</span><label class="collapse" for="c-36246969">[-]</label><label class="expand" for="c-36246969">[3 more]</label></div><br/><div class="children"><div class="content">Would those topics that &quot;outside academia understands AI to include&quot; be covered in <a href="http:&#x2F;&#x2F;aima.cs.berkeley.edu" rel="nofollow">http:&#x2F;&#x2F;aima.cs.berkeley.edu</a> ?<p>When you say &quot;bots in video games as AI&quot; that&#x27;s covered in the book titled Artificial Intelligence: A Modern Approach, 4th US ed. :<p><pre><code>    II Problem-solving 
        3 Solving Problems by Searching    ...  63 
        4 Search in Complex Environments   ... 110 
        5 Adversarial Search and Games     ... 146 
        6 Constraint Satisfaction Problems ... 180 
</code></pre>
Those topics would be in chapter 5.<p>Sure, it may be a few hundred lines of code, but it&#x27;s still something that a Berkley written AI textbook covers.<p>Spelled out more for that section:<p><pre><code>    Chapter 5   Adversarial Search and Games ... 146

    5.1   Game Theory ... 146 
        5.1.1   Two-player zero-sum games ... 147 
    5.2   Optimal Decisions in Games ... 148 
        5.2.1   The minimax search algorithm ... 149 
        5.2.2   Optimal decisions in multiplayer games ... 151 
        5.2.3   Alpha--Beta Pruning ... 152 
        5.2.4   Move ordering ... 153 
    5.3   Heuristic Alpha--Beta Tree Search ... 156 
        5.3.1   Evaluation functions ... 156 
        5.3.2   Cutting off search ... 158 
        5.3.3   Forward pruning ... 159 
        5.3.4   Search versus lookup ... 160 
    5.4   Monte Carlo Tree Search ... 161 
    5.5   Stochastic Games ... 164 
        5.5.1   Evaluation functions for games of chance ... 166 
    5.6   Partially Observable Games ... 168 
        5.6.1   Kriegspiel: Partially observable chess ... 168 
        5.6.2   Card games ... 171 
    5.7   Limitations of Game Search Algorithms ... 173</code></pre></div><br/><div id="36248159" class="c"><input type="checkbox" id="c-36248159" checked=""/><div class="controls bullet"><span class="by">Animats</span><span>|</span><a href="#36244679">root</a><span>|</span><a href="#36246969">parent</a><span>|</span><a href="#36250662">next</a><span>|</span><label class="collapse" for="c-36248159">[-]</label><label class="expand" for="c-36248159">[2 more]</label></div><br/><div class="children"><div class="content">I think I have an original edition of that book somewhere. Good Old Fashioned AI.</div><br/><div id="36249606" class="c"><input type="checkbox" id="c-36249606" checked=""/><div class="controls bullet"><span class="by">shagie</span><span>|</span><a href="#36244679">root</a><span>|</span><a href="#36248159">parent</a><span>|</span><a href="#36250662">next</a><span>|</span><label class="collapse" for="c-36249606">[-]</label><label class="expand" for="c-36249606">[1 more]</label></div><br/><div class="children"><div class="content">My assignments (different book) for Intro to AI class were:<p>Boolean algebra simplifier.  Given a LISP expression - for example (AND A (OR C D)) write a function to return the variables needed to make the entire expression TRUE.  Return NIL if the expression is a paradox such as (AND A (NOT A)).  The expressions that we were to resolve had on the order of 100-200 operators and were deeply nested.  I recall that I wrote a function as part of it that I called HAMLET-P that identified terms of the form (OR 2B (NOT 2B)) and rapidly simplified them to TRUE.<p>Not-brute-force job scheduler.  The job-shop scheduling problem ( <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Job-shop_scheduling" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Job-shop_scheduling</a> ) with in order processing of multiple tasks that had dependencies.  Any worker could do any task but could only do one task at a time.<p>The third one I don&#x27;t remember what it was.  I know it was there since the class had four assignments... (digging... must have been something with Prolog)<p>The last assignment was written in any language (I did it in C++ having had enough of LISP and I had a good model for how to do it in my head in C++).  A 19,19,5 game ( <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;M,n,k-game" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;M,n,k-game</a> ).  Similar to go-maku or pente.  This didn&#x27;t have any constraints that go-maku has or captures that pente has.  It was to use a two ply min-max tree with alpha beta pruning.  It would beat me 7 out of 10 times.  I could get a draw 2 out of 10 and win 1 out of 10.  For fun I also learned ncurses and made it so that I could play the game with the arrow keys rather than as &#x27;10,9... oh crap, I meant 9,10&#x27;.<p>And I still consider all of those problems and homework assignments as &quot;AI&quot;.<p>From the digging, I found a later year of the class that I took.  They added a bit of neural nets in it, but other topics were still there.<p>By way of <a href="https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;19970214064228&#x2F;http:&#x2F;&#x2F;www.cs.wisc.edu&#x2F;~pubs&#x2F;faculty-info&#x2F;" rel="nofollow">https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;19970214064228&#x2F;http:&#x2F;&#x2F;www.cs.wis...</a> to the professors&#x27;s home page and classes taught - 
<a href="https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;19970224221107&#x2F;http:&#x2F;&#x2F;www.cs.wisc.edu&#x2F;~kunen&#x2F;cs540.html" rel="nofollow">https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;19970224221107&#x2F;http:&#x2F;&#x2F;www.cs.wis...</a><p>Professor Dryer taught a different section <a href="https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;19970508190550&#x2F;http:&#x2F;&#x2F;www.cs.wisc.edu&#x2F;~dyer&#x2F;cs540.html" rel="nofollow">https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;19970508190550&#x2F;http:&#x2F;&#x2F;www.cs.wis...</a><p>The domain of the AI research group at that time: <a href="https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;19970508113626&#x2F;http:&#x2F;&#x2F;www.cs.wisc.edu&#x2F;~shavlik&#x2F;uwai.html" rel="nofollow">https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;19970508113626&#x2F;http:&#x2F;&#x2F;www.cs.wis...</a></div><br/></div></div></div></div></div></div><div id="36250662" class="c"><input type="checkbox" id="c-36250662" checked=""/><div class="controls bullet"><span class="by">sh34r</span><span>|</span><a href="#36244679">root</a><span>|</span><a href="#36246829">parent</a><span>|</span><a href="#36246969">prev</a><span>|</span><a href="#36246927">next</a><span>|</span><label class="collapse" for="c-36250662">[-]</label><label class="expand" for="c-36250662">[1 more]</label></div><br/><div class="children"><div class="content">I think there’s nuance to be had here. Terms have been overloaded, and individuals aren’t necessarily acting in bad faith. ML can be considered to be a subset of AI.<p>That being said, ML is extremely boring to me, and I really do think a lot of the research is an enormous grift. Hop on the bandwagon, read a stats book, flagrantly plagiarize it, submit to CS journal that no statisticians read, publish and don’t perish, rinse, repeat.<p>It feels like society  has spent billions of dollars on bad academics continuously reinventing applied statistics over and over again, but now with Big Data and a brand refresh! It’s like a whole generation of academics watched one too many  terrible Hollywood remakes. It broke their brains, and now they’re only doing remakes too.<p>They ran out of statistics content to steal, so now the latest and greatest thing is plagiarizing classical AI works from the late 20th century and calling it “reinforcement learning.”<p>It’s all very frustrating. We could’ve funded a Manhattan project for fusion power, but instead thousands of our most brilliant people are wasting their time and humanity’s  carbon budget to create the most powerful spambot ever.</div><br/></div></div><div id="36246927" class="c"><input type="checkbox" id="c-36246927" checked=""/><div class="controls bullet"><span class="by">dguest</span><span>|</span><a href="#36244679">root</a><span>|</span><a href="#36246829">parent</a><span>|</span><a href="#36250662">prev</a><span>|</span><a href="#36247979">next</a><span>|</span><label class="collapse" for="c-36246927">[-]</label><label class="expand" for="c-36246927">[1 more]</label></div><br/><div class="children"><div class="content">I agree that using a colloquial definition is fine. And I don&#x27;t mean to be too harsh on people who use buzzwords in their grant proposal: it&#x27;s just sort of the sea you swim in.<p>But I only wish we could say that a few hundred lines of code was &quot;AI&quot;: that would mean funding for a lot of desperately needed software infrastructure. Instead AI is taken as synonymous with ML, and more specifically deep neural networks, for the most part.</div><br/></div></div><div id="36247979" class="c"><input type="checkbox" id="c-36247979" checked=""/><div class="controls bullet"><span class="by">dsr_</span><span>|</span><a href="#36244679">root</a><span>|</span><a href="#36246829">parent</a><span>|</span><a href="#36246927">prev</a><span>|</span><a href="#36245080">next</a><span>|</span><label class="collapse" for="c-36247979">[-]</label><label class="expand" for="c-36247979">[2 more]</label></div><br/><div class="children"><div class="content">I think you&#x27;re entirely wrong about this. Using the term AI or artificial intelligence directly invokes several centuries of cultural baggage about golems, robots, Terminators, androids and cyborgs and Matrix-squid.<p>Saying &quot;large language models&quot; does not. Saying &quot;giant correlation networks&quot; does not. Not to be too Sapir-Whorfian, but the terminology we use influences our conversations: terrorists, guerillas, rebels, revolutionaries, freedom-fighters.</div><br/><div id="36248820" class="c"><input type="checkbox" id="c-36248820" checked=""/><div class="controls bullet"><span class="by">sebzim4500</span><span>|</span><a href="#36244679">root</a><span>|</span><a href="#36247979">parent</a><span>|</span><a href="#36245080">next</a><span>|</span><label class="collapse" for="c-36248820">[-]</label><label class="expand" for="c-36248820">[1 more]</label></div><br/><div class="children"><div class="content">Should a nuclear power station rebrand itself to avoid being associated with Hiroshima? I really don&#x27;t get what you are trying to say.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="36245080" class="c"><input type="checkbox" id="c-36245080" checked=""/><div class="controls bullet"><span class="by">shagie</span><span>|</span><a href="#36244679">parent</a><span>|</span><a href="#36246249">prev</a><span>|</span><a href="#36245686">next</a><span>|</span><label class="collapse" for="c-36245080">[-]</label><label class="expand" for="c-36245080">[1 more]</label></div><br/><div class="children"><div class="content">I think its the &quot;just&quot; statistical models part.<p>If you pull up the TOC for an AI textbook, you&#x27;ll find lots of things that aren&#x27;t &quot;intelligent&quot;.  Machine learning is just a subset of it.  I recall a professor in the AI department back in the 90s working on describing the shape of an object from a photograph (image to text) based on a number of tools (edge detection was one paper I recall).<p>Also in AI is writing a deductive first order logic solver is covered in there as are min-max trees and constraint satisfaction problems.<p><a href="http:&#x2F;&#x2F;aima.cs.berkeley.edu" rel="nofollow">http:&#x2F;&#x2F;aima.cs.berkeley.edu</a><p><a href="https:&#x2F;&#x2F;www.cs.ubc.ca&#x2F;~poole&#x2F;ci&#x2F;contents.html" rel="nofollow">https:&#x2F;&#x2F;www.cs.ubc.ca&#x2F;~poole&#x2F;ci&#x2F;contents.html</a> (note chapter 4)<p><a href="https:&#x2F;&#x2F;www.wiley.com&#x2F;en-us&#x2F;Mathematical+Methods+in+Artificial+Intelligence-p-9780818672002" rel="nofollow">https:&#x2F;&#x2F;www.wiley.com&#x2F;en-us&#x2F;Mathematical+Methods+in+Artifici...</a><p>People are trying to put a box around &quot;AI&quot; to mean a particular thing - maybe they want AI to mean &quot;artificial general intelligence&quot; rather than all the things that are covered in the intro to AI class in college.<p>I ultimately believe that trying to use a term that has been very broad for decades to apply to only a small subset of the domain is going to end up being a fruitless Scotsman tilting at windmills.<p>... And you know what, I think it does a pretty good job at being intelligent.  <a href="https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;01d760b3-4171-4e28-a23b-0b6565a9646c" rel="nofollow">https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;01d760b3-4171-4e28-a23b-0b6565...</a></div><br/></div></div><div id="36245686" class="c"><input type="checkbox" id="c-36245686" checked=""/><div class="controls bullet"><span class="by">bee_rider</span><span>|</span><a href="#36244679">parent</a><span>|</span><a href="#36245080">prev</a><span>|</span><a href="#36244890">next</a><span>|</span><label class="collapse" for="c-36245686">[-]</label><label class="expand" for="c-36245686">[9 more]</label></div><br/><div class="children"><div class="content">Very clever people have located true intelligence in the gaps between what an machine can do and what a human can. Therefore, to show that you aren’t a starry-eyed rube you put a disclaimer that you aren’t really talking about intelligence, but something that just looks and acts like it.<p>True intelligence is, of course, definitionally the ability to do things like art or… err, wait, sorry, I haven’t checked recently, where have we put the goalposts nowadays?</div><br/><div id="36246199" class="c"><input type="checkbox" id="c-36246199" checked=""/><div class="controls bullet"><span class="by">ethanbond</span><span>|</span><a href="#36244679">root</a><span>|</span><a href="#36245686">parent</a><span>|</span><a href="#36249732">next</a><span>|</span><label class="collapse" for="c-36246199">[-]</label><label class="expand" for="c-36246199">[5 more]</label></div><br/><div class="children"><div class="content">I’m hesitant to even call this moving the goal posts. Intelligence has never been solidly defined even within humans (see: IQ debate; book smart vs street smart; idiot savants).<p>It’s unsurprising that creating machines that seem to do some stuff very intelligently and some other things not very intelligently at all is causing some discontent with regard to our language.<p>I see a whole lot more gnashing of teeth about goalposts moving than I do about people proposing actual solid goalposts.<p>So what’s your definition?</div><br/><div id="36246493" class="c"><input type="checkbox" id="c-36246493" checked=""/><div class="controls bullet"><span class="by">bee_rider</span><span>|</span><a href="#36244679">root</a><span>|</span><a href="#36246199">parent</a><span>|</span><a href="#36249840">next</a><span>|</span><label class="collapse" for="c-36246493">[-]</label><label class="expand" for="c-36246493">[3 more]</label></div><br/><div class="children"><div class="content">&gt; I’m hesitant to even call this moving the goal posts. Intelligence has never been solidly defined even within humans (see: IQ debate; book smart vs street smart; idiot savants).<p>&gt; It’s unsurprising that creating machines that seem to do some stuff very intelligently and some other things not very intelligently at all is causing some discontent with regard to our language.<p>I think I agree about the language.<p>I don’t have a definition of intelligence. I don’t work in one of those fields that would need to define it, so my first attempt probably wouldn’t be very good, but I’d say intelligence isn’t a single thing, but a label we’ve arbitrarily applied to a bunch of behaviors that are loosely related at best. So, trying to say this thing is intelligent, this thing is not, is basically hopeless, especially when things that we don’t believe are intelligent are being made to exhibit those behaviors, one behavior at a time.<p>&gt; I see a whole lot more gnashing of teeth about goalposts moving than I do about people proposing actual solid goalposts.<p>I might not see a ton of explicit “here are the goalpost” type statements. But, every time someone says “I’m using the term AI, but actually of course this isn’t intelligence,” the seem to me at least to be referencing some implicit goalposts. If there isn’t a way of classifying what is or isn’t intelligent, how can they say something isn’t it? I think the people making the distinction have the responsibility to tell us where they’ve made the cutoff.<p>Maybe I’m just quibbling. Now that I’ve written all that out, I’m beginning to wonder if I just don’t like the wording of the disclaimer. I’d probably be satisfied if instead of “this isn’t intelligence, but I’m going to call it AI,” people would say “Intelligence is too hard to define, so I’m going to call this AI, because why not?”</div><br/><div id="36246622" class="c"><input type="checkbox" id="c-36246622" checked=""/><div class="controls bullet"><span class="by">oszai</span><span>|</span><a href="#36244679">root</a><span>|</span><a href="#36246493">parent</a><span>|</span><a href="#36249840">next</a><span>|</span><label class="collapse" for="c-36246622">[-]</label><label class="expand" for="c-36246622">[2 more]</label></div><br/><div class="children"><div class="content">Conceptually Speaking you can reduce it down to Intelligence and strip out the Artificial Label.<p>So know the question is what is Intelligence. Our standardized testing Model tells us passing tests that Humans cannot would be considered intelligent.<p>Then add back in artificial to complete the equation.<p>Commercially the Term Ai Means nothing thanks to years of Machine Learning being labeled such. It&#x27;s arbitrary and relays more to Group Think to avoid approaching that Intelligence is a Scalar Value and not a Binary Construct.</div><br/></div></div></div></div><div id="36249840" class="c"><input type="checkbox" id="c-36249840" checked=""/><div class="controls bullet"><span class="by">pixl97</span><span>|</span><a href="#36244679">root</a><span>|</span><a href="#36246199">parent</a><span>|</span><a href="#36246493">prev</a><span>|</span><a href="#36249732">next</a><span>|</span><label class="collapse" for="c-36249840">[-]</label><label class="expand" for="c-36249840">[1 more]</label></div><br/><div class="children"><div class="content">&gt;So what’s your definition?<p>I say we take the word intelligence and throw it out the window. It&#x27;s a bit like talking about the either before we discovered more about physics. We chose a word with an ethereal definition that may or may not apply depending on the context.<p>So what do we do instead? We define sets of capability and context and devise tests around that. If it turns out a test actually sucked or was not expansive enough, we don&#x27;t get rid of that particular test. Instead we make a new more advanced test with better coverage. Under this domain no human would pass all the tests either. We could each individual sub test with ratings like &#x27;far below human capability&#x27;, &#x27;average human capability&#x27;, &#x27;far beyond human capabilities&#x27;. These tests could be everywhere from emotional understanding and comprehension, to reasoning and logical ability, and even include embodiment tests.<p>Of course even then I see a day where some embodied robot beats the vast majority of emotional, intellectual, and physical tests and some human supremacist still comes back with &quot;iTs n0t InTeLLigeNt&quot;</div><br/></div></div></div></div><div id="36249732" class="c"><input type="checkbox" id="c-36249732" checked=""/><div class="controls bullet"><span class="by">pixl97</span><span>|</span><a href="#36244679">root</a><span>|</span><a href="#36245686">parent</a><span>|</span><a href="#36246199">prev</a><span>|</span><a href="#36245772">next</a><span>|</span><label class="collapse" for="c-36249732">[-]</label><label class="expand" for="c-36249732">[1 more]</label></div><br/><div class="children"><div class="content">Heh, Computers will never be intelligent, we will just moving the bar until humans can no longer be classified as intelligent.</div><br/></div></div><div id="36245772" class="c"><input type="checkbox" id="c-36245772" checked=""/><div class="controls bullet"><span class="by">hospitalJail</span><span>|</span><a href="#36244679">root</a><span>|</span><a href="#36245686">parent</a><span>|</span><a href="#36249732">prev</a><span>|</span><a href="#36244890">next</a><span>|</span><label class="collapse" for="c-36245772">[-]</label><label class="expand" for="c-36245772">[2 more]</label></div><br/><div class="children"><div class="content">Stable Diffusion doesnt make art, it makes photos. We can deem them art.<p>Its denoising software.</div><br/><div id="36249884" class="c"><input type="checkbox" id="c-36249884" checked=""/><div class="controls bullet"><span class="by">lucubratory</span><span>|</span><a href="#36244679">root</a><span>|</span><a href="#36245772">parent</a><span>|</span><a href="#36244890">next</a><span>|</span><label class="collapse" for="c-36249884">[-]</label><label class="expand" for="c-36249884">[1 more]</label></div><br/><div class="children"><div class="content">Ooh, this is a rare one! A comment directly noting the similarities between AI art with photography, but insisting both aren&#x27;t art. You&#x27;re in very historical company: <a href="https:&#x2F;&#x2F;daily.jstor.org&#x2F;when-photography-was-not-art&#x2F;" rel="nofollow">https:&#x2F;&#x2F;daily.jstor.org&#x2F;when-photography-was-not-art&#x2F;</a></div><br/></div></div></div></div></div></div><div id="36244890" class="c"><input type="checkbox" id="c-36244890" checked=""/><div class="controls bullet"><span class="by">wongarsu</span><span>|</span><a href="#36244679">parent</a><span>|</span><a href="#36245686">prev</a><span>|</span><a href="#36245067">next</a><span>|</span><label class="collapse" for="c-36244890">[-]</label><label class="expand" for="c-36244890">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s long been a divide between what people call hard vs soft AI, or strong vs weak AI, or narrow vs general. The definitions are a bit fuzzy, but generally a hard AI or strong AI would be able to think for itself, develop strategies and skills, maybe have a sense of self. Soft AI in contrast is a mere tool where you put something in and get something out.<p>Now some people don&#x27;t like using the term AI for soft&#x2F;weak&#x2F;narrow AI, because it&#x27;s a fleeting definition, mostly applied to things that are novel and that we didn&#x27;t think computers were able to do. Playing chess used to be considered AI, but a short time after AI beat the human chess world master it was no longer considered AI. If you buy a chess computer capable of beating Magnus Carlsen today that&#x27;s considered a clever algorithm, no longer AI. You see the same thing playing out in real time right now with LLMs, where they go from AI to &quot;just algorithms&quot; in record time.</div><br/></div></div><div id="36245067" class="c"><input type="checkbox" id="c-36245067" checked=""/><div class="controls bullet"><span class="by">JohnFen</span><span>|</span><a href="#36244679">parent</a><span>|</span><a href="#36244890">prev</a><span>|</span><a href="#36245012">next</a><span>|</span><label class="collapse" for="c-36245067">[-]</label><label class="expand" for="c-36245067">[2 more]</label></div><br/><div class="children"><div class="content">Because we don&#x27;t have a real handle on what &quot;intelligence&quot; actually is, any use of the word without defining it is essentially just noise.</div><br/><div id="36246245" class="c"><input type="checkbox" id="c-36246245" checked=""/><div class="controls bullet"><span class="by">ethanbond</span><span>|</span><a href="#36244679">root</a><span>|</span><a href="#36245067">parent</a><span>|</span><a href="#36245012">next</a><span>|</span><label class="collapse" for="c-36246245">[-]</label><label class="expand" for="c-36246245">[1 more]</label></div><br/><div class="children"><div class="content">Yeah this is exactly it. It’s interesting seeing a precision-oriented discipline (engineering) running into the inherently very, very muddy world of semantics.<p>“What do you mean it’s not intelligent?! It passed Test X!”<p>“Yes and now that tells us Test X was not a good test for whatever it is we refer to as ‘intelligence’”</div><br/></div></div></div></div><div id="36245012" class="c"><input type="checkbox" id="c-36245012" checked=""/><div class="controls bullet"><span class="by">sublinear</span><span>|</span><a href="#36244679">parent</a><span>|</span><a href="#36245067">prev</a><span>|</span><a href="#36253157">next</a><span>|</span><label class="collapse" for="c-36245012">[-]</label><label class="expand" for="c-36245012">[16 more]</label></div><br/><div class="children"><div class="content">&gt; LLM are not intelligence because they&#x27;re <i>just</i> statistical models<p>This is exactly it for me.</div><br/><div id="36245473" class="c"><input type="checkbox" id="c-36245473" checked=""/><div class="controls bullet"><span class="by">xigency</span><span>|</span><a href="#36244679">root</a><span>|</span><a href="#36245012">parent</a><span>|</span><a href="#36245699">next</a><span>|</span><label class="collapse" for="c-36245473">[-]</label><label class="expand" for="c-36245473">[2 more]</label></div><br/><div class="children"><div class="content">Are you intelligent or just a bunch of cells? Given that I can query it for all sorts of information that I don’t know, I would consider LLMs to, at the very least, contain and present intelligence…artificially.</div><br/><div id="36246718" class="c"><input type="checkbox" id="c-36246718" checked=""/><div class="controls bullet"><span class="by">vel0city</span><span>|</span><a href="#36244679">root</a><span>|</span><a href="#36245473">parent</a><span>|</span><a href="#36245699">next</a><span>|</span><label class="collapse" for="c-36246718">[-]</label><label class="expand" for="c-36246718">[1 more]</label></div><br/><div class="children"><div class="content">I can query Wikipedia or IMDB for all sorts of information I don&#x27;t know. I wouldn&#x27;t consider the search box of either site to be &quot;intelligent&quot;, so I don&#x27;t know &quot;query it for all sorts of information&quot; is a generally good rubric for intelligence.</div><br/></div></div></div></div><div id="36245699" class="c"><input type="checkbox" id="c-36245699" checked=""/><div class="controls bullet"><span class="by">ericd</span><span>|</span><a href="#36244679">root</a><span>|</span><a href="#36245012">parent</a><span>|</span><a href="#36245473">prev</a><span>|</span><a href="#36245848">next</a><span>|</span><label class="collapse" for="c-36245699">[-]</label><label class="expand" for="c-36245699">[7 more]</label></div><br/><div class="children"><div class="content">And if your brain is mostly a statistical model of the world, with action probabilities based on what parts of it happen to be excited at the moment?</div><br/><div id="36246051" class="c"><input type="checkbox" id="c-36246051" checked=""/><div class="controls bullet"><span class="by">jmopp</span><span>|</span><a href="#36244679">root</a><span>|</span><a href="#36245699">parent</a><span>|</span><a href="#36254243">next</a><span>|</span><label class="collapse" for="c-36246051">[-]</label><label class="expand" for="c-36246051">[5 more]</label></div><br/><div class="children"><div class="content">How do we know that the brain is a statistical model of the world? It sounds like explaining an unknown phenomenon using the technology du jour - just 10&#x2F;20 years ago, the brain was a computer.</div><br/><div id="36246358" class="c"><input type="checkbox" id="c-36246358" checked=""/><div class="controls bullet"><span class="by">JohnFen</span><span>|</span><a href="#36244679">root</a><span>|</span><a href="#36246051">parent</a><span>|</span><a href="#36249902">next</a><span>|</span><label class="collapse" for="c-36246358">[-]</label><label class="expand" for="c-36246358">[2 more]</label></div><br/><div class="children"><div class="content">This touches on a dichotomy that has fascinated me for decades, from the very beginning of my interest in AI.<p>One side of the dichotomy asserts that &quot;if it walks like a duck...&quot; that is, if a computer appears to be intelligent to us, then it must be intelligent. This is basically the Turing Test crowd (even though Turing himself didn&#x27;t approve of the Turing Test as an actual test of AI).<p>On the other side, you have people who assert that the human mind is really just a super-complicated version of &quot;X&quot;, where &quot;X&quot; is whatever the cool new tech of the day is.<p>I have no conclusions to draw from this sort of thing, aside from highlighting that we don&#x27;t know what intelligence or consciousness actually are. I&#x27;m just fascinated by it.</div><br/><div id="36252111" class="c"><input type="checkbox" id="c-36252111" checked=""/><div class="controls bullet"><span class="by">sublinear</span><span>|</span><a href="#36244679">root</a><span>|</span><a href="#36246358">parent</a><span>|</span><a href="#36249902">next</a><span>|</span><label class="collapse" for="c-36252111">[-]</label><label class="expand" for="c-36252111">[1 more]</label></div><br/><div class="children"><div class="content">The general notion is called &quot;lumpers&quot; and &quot;splitters&quot;.<p>From the perspective of software, the lumpers are pretty much always wrong except for when they get a lucky guess. Think of a pointy-haired boss who weaponizes his wishful thinking with a brutal dismissal of all implementation details and imposes ignorantly firm deadlines, or an architecture astronaut who writes and forces upon everyone cruel interfaces and classes that are thoroughly out of touch with reality.<p>As they say: &quot;it&#x27;s more easy to lump splits than split lumps&quot;. The people who insist the statistical models have emergent behavior, or even worse, equate them with human brains are &quot;lumpers&quot; who lack imagination and have no desire to truly understand and model these things. They naively seek out oversimplifications and falsely believe they&#x27;re applying Occam&#x27;s Razor, but they&#x27;re actually just morons. &quot;Splitters&quot; are by their very definition always technically correct, but create complex distinctions that either represent much deeper knowledge than necessary, or hallucination. Either way, both types are needed, and of course, society values the lumpers far more for essentially playing the lottery with their reputations by telling people what they want to hear.<p><a href="https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Lumpers_and_splitters" rel="nofollow">https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Lumpers_and_splitters</a></div><br/></div></div></div></div><div id="36249902" class="c"><input type="checkbox" id="c-36249902" checked=""/><div class="controls bullet"><span class="by">pixl97</span><span>|</span><a href="#36244679">root</a><span>|</span><a href="#36246051">parent</a><span>|</span><a href="#36246358">prev</a><span>|</span><a href="#36254243">next</a><span>|</span><label class="collapse" for="c-36249902">[-]</label><label class="expand" for="c-36249902">[2 more]</label></div><br/><div class="children"><div class="content">So conversely, is the brain magic? And if so, if we look at the evolutionary lineage of neural networks, at which point did it become so?</div><br/><div id="36253635" class="c"><input type="checkbox" id="c-36253635" checked=""/><div class="controls bullet"><span class="by">jmopp</span><span>|</span><a href="#36244679">root</a><span>|</span><a href="#36249902">parent</a><span>|</span><a href="#36254243">next</a><span>|</span><label class="collapse" for="c-36253635">[-]</label><label class="expand" for="c-36253635">[1 more]</label></div><br/><div class="children"><div class="content">I wouldn&#x27;t say the brain is magic, just that we still don&#x27;t know what consciousness and intelligence is. Could the complex emergent behaviour we call intelligence emerge from a statistical model? Maybe. Can we gain more insights on what intelligence is by studying these models? Definitely. On the other hand — Are there limits to large language models&#x27; capabilities that we haven&#x27;t reached yet?</div><br/></div></div></div></div></div></div><div id="36254243" class="c"><input type="checkbox" id="c-36254243" checked=""/><div class="controls bullet"><span class="by">layer8</span><span>|</span><a href="#36244679">root</a><span>|</span><a href="#36245699">parent</a><span>|</span><a href="#36246051">prev</a><span>|</span><a href="#36245848">next</a><span>|</span><label class="collapse" for="c-36254243">[-]</label><label class="expand" for="c-36254243">[1 more]</label></div><br/><div class="children"><div class="content">The brain carries state and is self-modifying, which is something that can‘t be said about mere statistical models.</div><br/></div></div></div></div><div id="36245848" class="c"><input type="checkbox" id="c-36245848" checked=""/><div class="controls bullet"><span class="by">hospitalJail</span><span>|</span><a href="#36244679">root</a><span>|</span><a href="#36245012">parent</a><span>|</span><a href="#36245699">prev</a><span>|</span><a href="#36253157">next</a><span>|</span><label class="collapse" for="c-36245848">[-]</label><label class="expand" for="c-36245848">[6 more]</label></div><br/><div class="children"><div class="content">Its interesting to see what it thinks about some ideas, like I ask, what 5 companies are best at marketing. My goal here is to be hypercritical of the companies it says because they are masters at manipulation. GPT3.5 was awful and confused advertising and marketing. GPT4 was perfect (Apple, Nike, Coke, Amazon, P&amp;G)<p>As much as chatgpt doesnt want to give you answers because the fuzziness, it has the ability to make judgements on things like &quot;This is the best&quot; or &quot;This is the worst&quot;.<p>Ofc with bias.</div><br/><div id="36246680" class="c"><input type="checkbox" id="c-36246680" checked=""/><div class="controls bullet"><span class="by">nathan_compton</span><span>|</span><a href="#36244679">root</a><span>|</span><a href="#36245848">parent</a><span>|</span><a href="#36253157">next</a><span>|</span><label class="collapse" for="c-36246680">[-]</label><label class="expand" for="c-36246680">[5 more]</label></div><br/><div class="children"><div class="content">Does it have the ability or is it just generating text similar to what it has seen before? The two things are very different.</div><br/><div id="36246883" class="c"><input type="checkbox" id="c-36246883" checked=""/><div class="controls bullet"><span class="by">hospitalJail</span><span>|</span><a href="#36244679">root</a><span>|</span><a href="#36246680">parent</a><span>|</span><a href="#36253157">next</a><span>|</span><label class="collapse" for="c-36246883">[-]</label><label class="expand" for="c-36246883">[4 more]</label></div><br/><div class="children"><div class="content">In this examples, it likely took that those companies are often praised about their marketing in the same sentence marketing is mentioned.<p>LLMs don&#x27;t repeat text its seen before, it links words&#x2F;tokens&#x2F;phrases that are related. Its prediction, but the prediction isnt just copypasting a previous webpage.<p>Have you use chatgpt yet? I wouldn&#x27;t delay. Heck you are here on HN, you basically have a responsibility to test it.</div><br/><div id="36247209" class="c"><input type="checkbox" id="c-36247209" checked=""/><div class="controls bullet"><span class="by">nathan_compton</span><span>|</span><a href="#36244679">root</a><span>|</span><a href="#36246883">parent</a><span>|</span><a href="#36253157">next</a><span>|</span><label class="collapse" for="c-36247209">[-]</label><label class="expand" for="c-36247209">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve used it <i>extensively</i>. GPT4 is great, but it is not intelligent. I think its really weird and also totally understandable that people think it is.</div><br/><div id="36249332" class="c"><input type="checkbox" id="c-36249332" checked=""/><div class="controls bullet"><span class="by">girvo</span><span>|</span><a href="#36244679">root</a><span>|</span><a href="#36247209">parent</a><span>|</span><a href="#36249908">next</a><span>|</span><label class="collapse" for="c-36249332">[-]</label><label class="expand" for="c-36249332">[1 more]</label></div><br/><div class="children"><div class="content">It’s something so new and foreign that I’m deeply unsurprised that some feel it’s intelligent.<p>I personally don’t care one way or the other, whether it is or isn’t. What I care about is whether it’s useful.</div><br/></div></div><div id="36249908" class="c"><input type="checkbox" id="c-36249908" checked=""/><div class="controls bullet"><span class="by">pixl97</span><span>|</span><a href="#36244679">root</a><span>|</span><a href="#36247209">parent</a><span>|</span><a href="#36249332">prev</a><span>|</span><a href="#36253157">next</a><span>|</span><label class="collapse" for="c-36249908">[-]</label><label class="expand" for="c-36249908">[1 more]</label></div><br/><div class="children"><div class="content">Eh, please comprehensively define intelligent... I have a feeling that this may explain a lot about your answer.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="36253157" class="c"><input type="checkbox" id="c-36253157" checked=""/><div class="controls bullet"><span class="by">LudwigNagasena</span><span>|</span><a href="#36244679">parent</a><span>|</span><a href="#36245012">prev</a><span>|</span><a href="#36245330">next</a><span>|</span><label class="collapse" for="c-36253157">[-]</label><label class="expand" for="c-36253157">[1 more]</label></div><br/><div class="children"><div class="content">&gt; is it that some people define intelligence as &gt;= human<p>Just like some people define stupid as &lt;= them. Aptitude is a multivariate spectra. It is already hard to come up with a cutoff on a single measure, way harder to do so for a bunch of different skills that for some reason happen to correlate in humans (and sometimes they diverge wildly as in the case of savant syndrome).</div><br/></div></div><div id="36245330" class="c"><input type="checkbox" id="c-36245330" checked=""/><div class="controls bullet"><span class="by">ravenstine</span><span>|</span><a href="#36244679">parent</a><span>|</span><a href="#36253157">prev</a><span>|</span><a href="#36246232">next</a><span>|</span><label class="collapse" for="c-36245330">[-]</label><label class="expand" for="c-36245330">[4 more]</label></div><br/><div class="children"><div class="content">&gt;  is it that some people define intelligence as &gt;= human<p>I just want to say that this seems to be how many, if not most people define intelligence internally.  If an LLM gets something wrong or doesn&#x27;t know something, then it must be completely unintelligent. (as if humans never get anything wrong!)</div><br/><div id="36245511" class="c"><input type="checkbox" id="c-36245511" checked=""/><div class="controls bullet"><span class="by">xigency</span><span>|</span><a href="#36244679">root</a><span>|</span><a href="#36245330">parent</a><span>|</span><a href="#36246279">next</a><span>|</span><label class="collapse" for="c-36245511">[-]</label><label class="expand" for="c-36245511">[1 more]</label></div><br/><div class="children"><div class="content">Clearly the test isn’t &gt;= as ChatGPT is already more coherent than large swaths of the population. The AI test for some is that its intelligence &gt;&gt;&gt; human intelligence. Which is funny because by that point in time, their opinion will be more than worthless.</div><br/></div></div><div id="36246279" class="c"><input type="checkbox" id="c-36246279" checked=""/><div class="controls bullet"><span class="by">ethanbond</span><span>|</span><a href="#36244679">root</a><span>|</span><a href="#36245330">parent</a><span>|</span><a href="#36245511">prev</a><span>|</span><a href="#36246232">next</a><span>|</span><label class="collapse" for="c-36246279">[-]</label><label class="expand" for="c-36246279">[2 more]</label></div><br/><div class="children"><div class="content">Like with humans, there are intelligent ways to be wrong and unintelligent ways to be wrong.<p>LLMs do a whole lot of “wrong in a way that indicates it is not ‘thinking’ the way an intelligent human would.”</div><br/><div id="36247802" class="c"><input type="checkbox" id="c-36247802" checked=""/><div class="controls bullet"><span class="by">ravenstine</span><span>|</span><a href="#36244679">root</a><span>|</span><a href="#36246279">parent</a><span>|</span><a href="#36246232">next</a><span>|</span><label class="collapse" for="c-36247802">[-]</label><label class="expand" for="c-36247802">[1 more]</label></div><br/><div class="children"><div class="content">What&#x27;s concerning about this is we are evaluating AI on a basis that humans are not subject to.  LLMs in their current form are built on the knowledge of the internet, while humans have both the internet and realtime feedback from their own lives in the physical world.  If a human brain could be trained the same way as an LLM, might it also connect seemingly unconnected ideas in a way that would appear as non-thought?  Maybe, maybe not.  LLMs seem to be biased heavily towards making best effort guesses on things it doesn&#x27;t know about, whilst humans are far more modest in doing so.  I just don&#x27;t know if we&#x27;re really at a point where we can conclusively decide that something isn&#x27;t thinking just because it doesn&#x27;t appear to be thinking by the standards we place upon ourselves.</div><br/></div></div></div></div></div></div><div id="36246232" class="c"><input type="checkbox" id="c-36246232" checked=""/><div class="controls bullet"><span class="by">majormajor</span><span>|</span><a href="#36244679">parent</a><span>|</span><a href="#36245330">prev</a><span>|</span><a href="#36246654">next</a><span>|</span><label class="collapse" for="c-36246232">[-]</label><label class="expand" for="c-36246232">[1 more]</label></div><br/><div class="children"><div class="content">AI&#x27;s a very soft term, and there&#x27;s long been a technical vs &quot;casual&quot; split in what it means. Five or ten years ago you&#x27;d say your photo was retouched with AI dust removal, say, and we&#x27;d all know what that means. And that there was a big gulf between that and the sci-fi &quot;AI&quot; of Blade Runner or Her or Star Wars, etc.<p>The user interface to Chat GPT and similar tools, though, has made a lot of people think that gap is gone, and that instead of thinking they are using an AI tool in the technical sense, they now think they&#x27;re talking to a full-fledged other being in the sci-fi sense; that that idea has now come true.<p>So a lot of people are careful to distinguish the one from the other in their writing.</div><br/></div></div><div id="36246654" class="c"><input type="checkbox" id="c-36246654" checked=""/><div class="controls bullet"><span class="by">nathan_compton</span><span>|</span><a href="#36244679">parent</a><span>|</span><a href="#36246232">prev</a><span>|</span><a href="#36245444">next</a><span>|</span><label class="collapse" for="c-36246654">[-]</label><label class="expand" for="c-36246654">[4 more]</label></div><br/><div class="children"><div class="content">I say that large language models are not intelligent because of the way they fail to do things. In particular, they fail in such a way as to indicate they have no mental model of the things they parrot. If you give them a simple, but very unusual, coding problem, they will confidently give you an incorrect solution even though they <i>seem</i> to understand programming when dealing with things similar to their training data.<p>An intelligent thing should easily generalize in these situations but LLMs fail to. I use GPT4 every day and I frequently encounter this kind of thing.</div><br/><div id="36247006" class="c"><input type="checkbox" id="c-36247006" checked=""/><div class="controls bullet"><span class="by">NumberWangMan</span><span>|</span><a href="#36244679">root</a><span>|</span><a href="#36246654">parent</a><span>|</span><a href="#36245444">next</a><span>|</span><label class="collapse" for="c-36247006">[-]</label><label class="expand" for="c-36247006">[3 more]</label></div><br/><div class="children"><div class="content">Is there a definition of intelligence that rules out large language models, but that does not also rule out large portions of humanity?  A lot of people would readily admit that they don&#x27;t have programming aptitude and would probably end up just memorizing things.  Do we say those people are not intelligent?<p>It seems to me that the perceived difference is mostly in being able to admit that you don&#x27;t know something, rather than make up an answer -- but making up an answer is still something that humans do sometimes.</div><br/><div id="36247427" class="c"><input type="checkbox" id="c-36247427" checked=""/><div class="controls bullet"><span class="by">nathan_compton</span><span>|</span><a href="#36244679">root</a><span>|</span><a href="#36247006">parent</a><span>|</span><a href="#36245444">next</a><span>|</span><label class="collapse" for="c-36247427">[-]</label><label class="expand" for="c-36247427">[2 more]</label></div><br/><div class="children"><div class="content">I have to admit this is a genuinely interesting question. Language models demonstrably do have some models of the world inside of them. And, I admit, what I say that they aren&#x27;t intelligent, I mostly mean they are very stupid, rather than like a machine or algorithm. Artificial stupidity is progress.</div><br/><div id="36250614" class="c"><input type="checkbox" id="c-36250614" checked=""/><div class="controls bullet"><span class="by">pixl97</span><span>|</span><a href="#36244679">root</a><span>|</span><a href="#36247427">parent</a><span>|</span><a href="#36245444">next</a><span>|</span><label class="collapse" for="c-36250614">[-]</label><label class="expand" for="c-36250614">[1 more]</label></div><br/><div class="children"><div class="content">Ok, so from your other comment, I think this is where our definition of intelligence is breaking down...<p>Biological agents have a consistent world model based on their capabilities because an inconsistent model would lead to lack of reproduction or death. We could call this environmental intelligence.<p>Meanwhile we have LLMs that have appear to have what I would consider &#x27;micro&#x27; world models for some things, but not a large consistent world model. I&#x27;m guessing this is due to a few things, but for example not being culled for bad world models would be one, and another is they are only grounded  in text and we&#x27;ve not really explored multi-modal grounding in models very far.<p>I guess what&#x27;s going to be interesting is to see how multi-modal and embodied models do as they are trained in the environment and create a more consistent world model.</div><br/></div></div></div></div></div></div></div></div><div id="36245444" class="c"><input type="checkbox" id="c-36245444" checked=""/><div class="controls bullet"><span class="by">russdill</span><span>|</span><a href="#36244679">parent</a><span>|</span><a href="#36246654">prev</a><span>|</span><a href="#36245795">next</a><span>|</span><label class="collapse" for="c-36245444">[-]</label><label class="expand" for="c-36245444">[4 more]</label></div><br/><div class="children"><div class="content">It&#x27;s statistical models all the way down.</div><br/><div id="36245741" class="c"><input type="checkbox" id="c-36245741" checked=""/><div class="controls bullet"><span class="by">ryanklee</span><span>|</span><a href="#36244679">root</a><span>|</span><a href="#36245444">parent</a><span>|</span><a href="#36245795">next</a><span>|</span><label class="collapse" for="c-36245741">[-]</label><label class="expand" for="c-36245741">[3 more]</label></div><br/><div class="children"><div class="content">That is not a very good reason to call an entity unintelligent. There are uncontroversial models of human intelligence that are Bayesian.</div><br/><div id="36246256" class="c"><input type="checkbox" id="c-36246256" checked=""/><div class="controls bullet"><span class="by">russdill</span><span>|</span><a href="#36244679">root</a><span>|</span><a href="#36245741">parent</a><span>|</span><a href="#36245795">next</a><span>|</span><label class="collapse" for="c-36246256">[-]</label><label class="expand" for="c-36246256">[2 more]</label></div><br/><div class="children"><div class="content">That&#x27;s what I&#x27;m alluding to.</div><br/><div id="36249093" class="c"><input type="checkbox" id="c-36249093" checked=""/><div class="controls bullet"><span class="by">ryanklee</span><span>|</span><a href="#36244679">root</a><span>|</span><a href="#36246256">parent</a><span>|</span><a href="#36245795">next</a><span>|</span><label class="collapse" for="c-36249093">[-]</label><label class="expand" for="c-36249093">[1 more]</label></div><br/><div class="children"><div class="content">Ah, apologies, I read your comment as alluding to statistics as a reason to dismiss intelligence in machines</div><br/></div></div></div></div></div></div></div></div><div id="36244822" class="c"><input type="checkbox" id="c-36244822" checked=""/><div class="controls bullet"><span class="by">guy98238710</span><span>|</span><a href="#36244679">parent</a><span>|</span><a href="#36245795">prev</a><span>|</span><a href="#36246605">next</a><span>|</span><label class="collapse" for="c-36244822">[-]</label><label class="expand" for="c-36244822">[1 more]</label></div><br/><div class="children"><div class="content">More like intelligence == human. ChatGPT is superhuman in many ways.</div><br/></div></div></div></div><div id="36246605" class="c"><input type="checkbox" id="c-36246605" checked=""/><div class="controls bullet"><span class="by">ricardo81</span><span>|</span><a href="#36244679">prev</a><span>|</span><a href="#36246169">next</a><span>|</span><label class="collapse" for="c-36246605">[-]</label><label class="expand" for="c-36246605">[2 more]</label></div><br/><div class="children"><div class="content">Only skimmed through the article, it seems -AI from the title would be an old story?<p>Also, that huge 4.7MB image in the head of the article...</div><br/><div id="36247586" class="c"><input type="checkbox" id="c-36247586" checked=""/><div class="controls bullet"><span class="by">SCUSKU</span><span>|</span><a href="#36246605">parent</a><span>|</span><a href="#36246169">next</a><span>|</span><label class="collapse" for="c-36247586">[-]</label><label class="expand" for="c-36247586">[1 more]</label></div><br/><div class="children"><div class="content">SEO, who needs it!</div><br/></div></div></div></div><div id="36246169" class="c"><input type="checkbox" id="c-36246169" checked=""/><div class="controls bullet"><span class="by">Tycho</span><span>|</span><a href="#36246605">prev</a><span>|</span><a href="#36244686">next</a><span>|</span><label class="collapse" for="c-36246169">[-]</label><label class="expand" for="c-36246169">[2 more]</label></div><br/><div class="children"><div class="content">I wonder when we’ll start seeing computer viruses that communicate with a remote LLM in order to get help circumventing barriers.<p>Alternatively, maybe anti-virus software can phone home to get on-the-fly advice.</div><br/><div id="36252497" class="c"><input type="checkbox" id="c-36252497" checked=""/><div class="controls bullet"><span class="by">ronsor</span><span>|</span><a href="#36246169">parent</a><span>|</span><a href="#36244686">next</a><span>|</span><label class="collapse" for="c-36252497">[-]</label><label class="expand" for="c-36252497">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Alternatively, maybe anti-virus software can phone home to get on-the-fly advice.<p>Modern antivirus software already does this, more or less. It&#x27;s usually called something like &quot;cloud scanning.&quot;</div><br/></div></div></div></div><div id="36244686" class="c"><input type="checkbox" id="c-36244686" checked=""/><div class="controls bullet"><span class="by">CyberDildonics</span><span>|</span><a href="#36246169">prev</a><span>|</span><a href="#36245858">next</a><span>|</span><label class="collapse" for="c-36244686">[-]</label><label class="expand" for="c-36244686">[15 more]</label></div><br/><div class="children"><div class="content">Browser Extensions Are a Security Nightmare - I guess you can add AI in front to make it seem new.</div><br/><div id="36244828" class="c"><input type="checkbox" id="c-36244828" checked=""/><div class="controls bullet"><span class="by">mahogany</span><span>|</span><a href="#36244686">parent</a><span>|</span><a href="#36244873">next</a><span>|</span><label class="collapse" for="c-36244828">[-]</label><label class="expand" for="c-36244828">[13 more]</label></div><br/><div class="children"><div class="content">Exactly - it blows my mind how normalized the permission <i>Access your data for all websites</i> is (I think it&#x27;s <i>Read and Change all your data on all websites for Chrome</i>). I use only one or two extensions because of this. Why does a procrastination tool need such an insanely broad permission?</div><br/><div id="36245128" class="c"><input type="checkbox" id="c-36245128" checked=""/><div class="controls bullet"><span class="by">hoosieree</span><span>|</span><a href="#36244686">root</a><span>|</span><a href="#36244828">parent</a><span>|</span><a href="#36245830">next</a><span>|</span><label class="collapse" for="c-36245128">[-]</label><label class="expand" for="c-36245128">[9 more]</label></div><br/><div class="children"><div class="content">I wrote a Chrome extension[1] that reads no data but places a colored translucent div over the page. It requires that same &quot;change all your data&quot; permission.<p>My takeaway lesson is that the permissions model for extensions is confusing and nearly useless.<p>[1] <a href="https:&#x2F;&#x2F;chrome.google.com&#x2F;webstore&#x2F;detail&#x2F;obscura&#x2F;nhlkgnilpmpddehjcegjpofpiiaomnen" rel="nofollow">https:&#x2F;&#x2F;chrome.google.com&#x2F;webstore&#x2F;detail&#x2F;obscura&#x2F;nhlkgnilpm...</a></div><br/><div id="36245544" class="c"><input type="checkbox" id="c-36245544" checked=""/><div class="controls bullet"><span class="by">thfuran</span><span>|</span><a href="#36244686">root</a><span>|</span><a href="#36245128">parent</a><span>|</span><a href="#36245525">next</a><span>|</span><label class="collapse" for="c-36245544">[-]</label><label class="expand" for="c-36245544">[4 more]</label></div><br/><div class="children"><div class="content">How would you allow changing page contents with a narrow permission?</div><br/><div id="36245691" class="c"><input type="checkbox" id="c-36245691" checked=""/><div class="controls bullet"><span class="by">gnicholas</span><span>|</span><a href="#36244686">root</a><span>|</span><a href="#36245544">parent</a><span>|</span><a href="#36245525">next</a><span>|</span><label class="collapse" for="c-36245691">[-]</label><label class="expand" for="c-36245691">[3 more]</label></div><br/><div class="children"><div class="content">I also have a Chrome extension that needs access to page content on all pages, for the purpose of making text easier to read.<p>I could see distinguishing between extensions that in any way exfiltrate data from the pages you view, versus extensions that process the DOM and do something locally, but never send the data anywhere.<p>This requires a bit closer vetting than Google currently does, I think. To demonstrate that all processing happens locally, we encourage our users to load various websites with our extension toggled off, then go into airplane mode, and then turn our extension on. This doesn&#x27;t strictly guarantee that we&#x27;re not separately exfiltrating data (we aren&#x27;t), but it does prove that our core process happens locally.</div><br/><div id="36246783" class="c"><input type="checkbox" id="c-36246783" checked=""/><div class="controls bullet"><span class="by">sebzim4500</span><span>|</span><a href="#36244686">root</a><span>|</span><a href="#36245691">parent</a><span>|</span><a href="#36245525">next</a><span>|</span><label class="collapse" for="c-36246783">[-]</label><label class="expand" for="c-36246783">[2 more]</label></div><br/><div class="children"><div class="content">There are hundreds of thousands of extensions, and none of them make Google any money. Hard to see how they could justify any serious manual review.</div><br/><div id="36248708" class="c"><input type="checkbox" id="c-36248708" checked=""/><div class="controls bullet"><span class="by">gnicholas</span><span>|</span><a href="#36244686">root</a><span>|</span><a href="#36246783">parent</a><span>|</span><a href="#36245525">next</a><span>|</span><label class="collapse" for="c-36248708">[-]</label><label class="expand" for="c-36248708">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, it could make sense for them to structure their extension framework so that developers could work with website data in a sandbox, if their use case allows for it. That would enable developers who don&#x27;t need to send data to a server for processing to prove that the data never leaves the user&#x27;s machine.</div><br/></div></div></div></div></div></div></div></div><div id="36245525" class="c"><input type="checkbox" id="c-36245525" checked=""/><div class="controls bullet"><span class="by">youreincorrect</span><span>|</span><a href="#36244686">root</a><span>|</span><a href="#36245128">parent</a><span>|</span><a href="#36245544">prev</a><span>|</span><a href="#36245574">next</a><span>|</span><label class="collapse" for="c-36245525">[-]</label><label class="expand" for="c-36245525">[3 more]</label></div><br/><div class="children"><div class="content">Do you suppose it&#x27;s possible that accessing the DOM to add a div implicitly requires access to page data?</div><br/><div id="36247304" class="c"><input type="checkbox" id="c-36247304" checked=""/><div class="controls bullet"><span class="by">hoosieree</span><span>|</span><a href="#36244686">root</a><span>|</span><a href="#36245525">parent</a><span>|</span><a href="#36245574">next</a><span>|</span><label class="collapse" for="c-36247304">[-]</label><label class="expand" for="c-36247304">[2 more]</label></div><br/><div class="children"><div class="content">I can see how many applications might want to read the page, but in my case it&#x27;s not necessary. My extension tries to add a &lt;div&gt; under the &lt;body&gt; element, regardless of what&#x27;s going on in the page. If there&#x27;s no &lt;body&gt;, my extension stops working but the browser keeps going.<p>In short, if there were separate &quot;read&quot; and &quot;write&quot; permissions, I would only need &quot;write&quot;. For privacy-concerned people, that&#x27;s a very important distinction.</div><br/><div id="36247822" class="c"><input type="checkbox" id="c-36247822" checked=""/><div class="controls bullet"><span class="by">jabradoodle</span><span>|</span><a href="#36244686">root</a><span>|</span><a href="#36247304">parent</a><span>|</span><a href="#36245574">next</a><span>|</span><label class="collapse" for="c-36247822">[-]</label><label class="expand" for="c-36247822">[1 more]</label></div><br/><div class="children"><div class="content">It would be more complex than that given you can write arbitrary JavaScript that can read anything it likes and send it anywhere.</div><br/></div></div></div></div></div></div></div></div><div id="36245830" class="c"><input type="checkbox" id="c-36245830" checked=""/><div class="controls bullet"><span class="by">waboremo</span><span>|</span><a href="#36244686">root</a><span>|</span><a href="#36244828">parent</a><span>|</span><a href="#36245128">prev</a><span>|</span><a href="#36245869">next</a><span>|</span><label class="collapse" for="c-36245830">[-]</label><label class="expand" for="c-36245830">[1 more]</label></div><br/><div class="children"><div class="content">If it operates on more than one domain, it needs those permissions to function based on how the permissions system works. You can limit those yourself in the settings page for the extension, but everything else is basically workarounds applied to avoid that permission.<p>For example, a web clipper operates on multiple domains, but it can avoid it by using activetab permission instead and then offering optional permissions if it wants when you click on the clipper extension icon.<p>If you want something to be done automatically on multiple domains, this is not possible without that permission. Not unless you want to annoy users with prompts.</div><br/></div></div><div id="36245869" class="c"><input type="checkbox" id="c-36245869" checked=""/><div class="controls bullet"><span class="by">hospitalJail</span><span>|</span><a href="#36244686">root</a><span>|</span><a href="#36244828">parent</a><span>|</span><a href="#36245830">prev</a><span>|</span><a href="#36244873">next</a><span>|</span><label class="collapse" for="c-36245869">[-]</label><label class="expand" for="c-36245869">[2 more]</label></div><br/><div class="children"><div class="content">Just because an extension can do that, doesnt mean they are sending your info to a server.</div><br/><div id="36246128" class="c"><input type="checkbox" id="c-36246128" checked=""/><div class="controls bullet"><span class="by">mahogany</span><span>|</span><a href="#36244686">root</a><span>|</span><a href="#36245869">parent</a><span>|</span><a href="#36244873">next</a><span>|</span><label class="collapse" for="c-36246128">[-]</label><label class="expand" for="c-36246128">[1 more]</label></div><br/><div class="children"><div class="content">No, but (1) you are trusting the extension to not do that, and (2) even if you vet the extension now, it could change in the future. Or am I mistaken? My understanding is that by default, extensions update automatically. If you accept these permissions initially, then you implicitly accept them for any future update. The alternative is keeping track of and updating every extension manually, re-vetting each one every time.</div><br/></div></div></div></div></div></div><div id="36244873" class="c"><input type="checkbox" id="c-36244873" checked=""/><div class="controls bullet"><span class="by">croes</span><span>|</span><a href="#36244686">parent</a><span>|</span><a href="#36244828">prev</a><span>|</span><a href="#36245858">next</a><span>|</span><label class="collapse" for="c-36244873">[-]</label><label class="expand" for="c-36244873">[1 more]</label></div><br/><div class="children"><div class="content">Exactly.<p>But I think at the moment it&#x27;s easier to get someone to install an extension as long it mentions GPT or AI.</div><br/></div></div></div></div><div id="36245858" class="c"><input type="checkbox" id="c-36245858" checked=""/><div class="controls bullet"><span class="by">FL33TW00D</span><span>|</span><a href="#36244686">prev</a><span>|</span><a href="#36248584">next</a><span>|</span><label class="collapse" for="c-36245858">[-]</label><label class="expand" for="c-36245858">[2 more]</label></div><br/><div class="children"><div class="content">But what is the &quot;AI&quot; ran entirely locally? 
<a href="https:&#x2F;&#x2F;pagevau.lt&#x2F;" rel="nofollow">https:&#x2F;&#x2F;pagevau.lt&#x2F;</a></div><br/><div id="36246282" class="c"><input type="checkbox" id="c-36246282" checked=""/><div class="controls bullet"><span class="by">williamstein</span><span>|</span><a href="#36245858">parent</a><span>|</span><a href="#36248584">next</a><span>|</span><label class="collapse" for="c-36246282">[-]</label><label class="expand" for="c-36246282">[1 more]</label></div><br/><div class="children"><div class="content">The &quot;Download for Chrome&quot; link on that page is broken.  &quot;404. That’s an error. The requested URL was not found on this server. That’s all we know.&quot;</div><br/></div></div></div></div><div id="36248584" class="c"><input type="checkbox" id="c-36248584" checked=""/><div class="controls bullet"><span class="by">Garcia98</span><span>|</span><a href="#36245858">prev</a><span>|</span><a href="#36247319">next</a><span>|</span><label class="collapse" for="c-36248584">[-]</label><label class="expand" for="c-36248584">[1 more]</label></div><br/><div class="children"><div class="content">The issue is not AI, nor browser extensions per se, the issue is the lackluster permission system that Chrome extensions have, it&#x27;s pretty similar to what Android had 7 (?) years ago, which should not be acceptable in 2023.</div><br/></div></div><div id="36247319" class="c"><input type="checkbox" id="c-36247319" checked=""/><div class="controls bullet"><span class="by">matheusmoreira</span><span>|</span><a href="#36248584">prev</a><span>|</span><a href="#36249610">next</a><span>|</span><label class="collapse" for="c-36247319">[-]</label><label class="expand" for="c-36247319">[8 more]</label></div><br/><div class="children"><div class="content">Pretty much every single extension that isn&#x27;t uBlock Origin is a security nightmare.</div><br/><div id="36247609" class="c"><input type="checkbox" id="c-36247609" checked=""/><div class="controls bullet"><span class="by">vorticalbox</span><span>|</span><a href="#36247319">parent</a><span>|</span><a href="#36247623">next</a><span>|</span><label class="collapse" for="c-36247609">[-]</label><label class="expand" for="c-36247609">[1 more]</label></div><br/><div class="children"><div class="content">Even unblock is, only takes the repository owners login to be taken an update pushed.</div><br/></div></div><div id="36247623" class="c"><input type="checkbox" id="c-36247623" checked=""/><div class="controls bullet"><span class="by">hxugufjfjf</span><span>|</span><a href="#36247319">parent</a><span>|</span><a href="#36247609">prev</a><span>|</span><a href="#36249610">next</a><span>|</span><label class="collapse" for="c-36247623">[-]</label><label class="expand" for="c-36247623">[6 more]</label></div><br/><div class="children"><div class="content">No. There are many good, secure browser extensions.</div><br/><div id="36248182" class="c"><input type="checkbox" id="c-36248182" checked=""/><div class="controls bullet"><span class="by">madeofpalk</span><span>|</span><a href="#36247319">root</a><span>|</span><a href="#36247623">parent</a><span>|</span><a href="#36249610">next</a><span>|</span><label class="collapse" for="c-36248182">[-]</label><label class="expand" for="c-36248182">[5 more]</label></div><br/><div class="children"><div class="content">Such as?</div><br/><div id="36248250" class="c"><input type="checkbox" id="c-36248250" checked=""/><div class="controls bullet"><span class="by">hxugufjfjf</span><span>|</span><a href="#36247319">root</a><span>|</span><a href="#36248182">parent</a><span>|</span><a href="#36249610">next</a><span>|</span><label class="collapse" for="c-36248250">[-]</label><label class="expand" for="c-36248250">[4 more]</label></div><br/><div class="children"><div class="content">Privacy Badger, 1Password, HTTPS Everywhere, Dark Reader, to name a few.</div><br/><div id="36248699" class="c"><input type="checkbox" id="c-36248699" checked=""/><div class="controls bullet"><span class="by">madeofpalk</span><span>|</span><a href="#36247319">root</a><span>|</span><a href="#36248250">parent</a><span>|</span><a href="#36249610">next</a><span>|</span><label class="collapse" for="c-36248699">[-]</label><label class="expand" for="c-36248699">[3 more]</label></div><br/><div class="children"><div class="content">&gt; Add &quot;Dark Reader&quot;?<p>&gt; It can: Read and change all data on all your websites<p>It already has the broadest permissions available. Dark Reader injects arbitary code into every page you visit. It&#x27;s one silent update away from stealing all your sessions. This is a security nightmare.<p>All browser extensions are a security nightmare.</div><br/><div id="36252737" class="c"><input type="checkbox" id="c-36252737" checked=""/><div class="controls bullet"><span class="by">dustyharddrive</span><span>|</span><a href="#36247319">root</a><span>|</span><a href="#36248699">parent</a><span>|</span><a href="#36251822">next</a><span>|</span><label class="collapse" for="c-36252737">[-]</label><label class="expand" for="c-36252737">[1 more]</label></div><br/><div class="children"><div class="content">If you have the time, will, and ability, audit the latest release and turn off auto update. That’s counter productive when the extension has its own attack surface of course.<p>I also haven’t read anything concerning about Mozilla’s Recommended review system yet.</div><br/></div></div><div id="36251822" class="c"><input type="checkbox" id="c-36251822" checked=""/><div class="controls bullet"><span class="by">hxugufjfjf</span><span>|</span><a href="#36247319">root</a><span>|</span><a href="#36248699">parent</a><span>|</span><a href="#36252737">prev</a><span>|</span><a href="#36249610">next</a><span>|</span><label class="collapse" for="c-36251822">[-]</label><label class="expand" for="c-36251822">[1 more]</label></div><br/><div class="children"><div class="content">Interesting!</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="36249610" class="c"><input type="checkbox" id="c-36249610" checked=""/><div class="controls bullet"><span class="by">activiation</span><span>|</span><a href="#36247319">prev</a><span>|</span><label class="collapse" for="c-36249610">[-]</label><label class="expand" for="c-36249610">[1 more]</label></div><br/><div class="children"><div class="content">Automatic updates should be disabled by default...</div><br/></div></div></div></div></div></div></div></body></html>