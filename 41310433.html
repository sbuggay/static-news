<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1724317256078" as="style"/><link rel="stylesheet" href="styles.css?v=1724317256078"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://francisbach.com/jensen-inequality/">Revisiting the Classics: Jensen&#x27;s Inequality (2023)</a> <span class="domain">(<a href="https://francisbach.com">francisbach.com</a>)</span></div><div class="subtext"><span>cpp_frog</span> | <span>6 comments</span></div><br/><div><div id="41317578" class="c"><input type="checkbox" id="c-41317578" checked=""/><div class="controls bullet"><span class="by">maxmininflect</span><span>|</span><a href="#41313409">next</a><span>|</span><label class="collapse" for="c-41317578">[-]</label><label class="expand" for="c-41317578">[1 more]</label></div><br/><div class="children"><div class="content">A very natural explanation of &quot;wikipedia proof 2&quot; for differentiable functions seems to be missing:<p>By linearity of expectation, both sides are linear in f, and for linear f we have equality. Let&#x27;s subtract the linear function whose graph is the tangent hyperplane to f at E(X). By above, this does not change the validity of the inequality. But now the left hand side is 0, and right hand side is non-negative by convexity, so we are done.<p>It&#x27;s also now clear what the difference of the two sides is -- it&#x27;s the expectation of the gap between f(X) an and the value of the tangent plane at X.<p>Now in general replace tangent hyperplane with graph of a subderivative, to recover what wiki says.</div><br/></div></div><div id="41313409" class="c"><input type="checkbox" id="c-41313409" checked=""/><div class="controls bullet"><span class="by">thehappyfellow</span><span>|</span><a href="#41317578">prev</a><span>|</span><label class="collapse" for="c-41313409">[-]</label><label class="expand" for="c-41313409">[4 more]</label></div><br/><div class="children"><div class="content">The proof of Young’s inequality is pretty neat but has the „magically think of taking a log of an arbitrary expression which happens to work” step. But it clarifies why the reciprocals of exponents have to sum up to 1: they are interpreted as probabilities when calculating expected value.<p>Here’s how I like to conceptualise it: bounding mixed variable product by sum of single variable terms is useful. Logarithms change multiplication to addition. Jensen’s inequality lifts addition from the argument of a convex function outside. Compose.</div><br/><div id="41314704" class="c"><input type="checkbox" id="c-41314704" checked=""/><div class="controls bullet"><span class="by">contravariant</span><span>|</span><a href="#41313409">parent</a><span>|</span><label class="collapse" for="c-41314704">[-]</label><label class="expand" for="c-41314704">[3 more]</label></div><br/><div class="children"><div class="content">You&#x27;ve got a product on one side and what looks like a convex combination on the other, taking the log and applying Jensen&#x27;s inequality isn&#x27;t as big a leap as it may sound.</div><br/><div id="41314803" class="c"><input type="checkbox" id="c-41314803" checked=""/><div class="controls bullet"><span class="by">thehappyfellow</span><span>|</span><a href="#41313409">root</a><span>|</span><a href="#41314704">parent</a><span>|</span><label class="collapse" for="c-41314803">[-]</label><label class="expand" for="c-41314803">[2 more]</label></div><br/><div class="children"><div class="content">Agreed, provided you have both sides of the inequality. Coming up with that particular convex combination is a bit of a leap that’s not super intuitive to me.</div><br/><div id="41314819" class="c"><input type="checkbox" id="c-41314819" checked=""/><div class="controls bullet"><span class="by">SpaceManNabs</span><span>|</span><a href="#41313409">root</a><span>|</span><a href="#41314803">parent</a><span>|</span><label class="collapse" for="c-41314819">[-]</label><label class="expand" for="c-41314819">[1 more]</label></div><br/><div class="children"><div class="content">if you work with a lot of convex optimization, it comes up pretty often. for example, if you learn fenchel conjugates, the lead up and motivation to learning them will often necessitate proving young&#x27;s inequality with jensen&#x27;s inequality. that is why learning different maths is cool. you intuit some ways to reshape the problem in order to make these &quot;not super intuitive&quot; connections.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></body></html>