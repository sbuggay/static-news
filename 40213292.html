<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1714554069589" as="style"/><link rel="stylesheet" href="styles.css?v=1714554069589"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.sscardapane.it/alice-book">Alice&#x27;s adventures in a differentiable wonderland</a> <span class="domain">(<a href="https://www.sscardapane.it">www.sscardapane.it</a>)</span></div><div class="subtext"><span>tosh</span> | <span>77 comments</span></div><br/><div><div id="40214349" class="c"><input type="checkbox" id="c-40214349" checked=""/><div class="controls bullet"><span class="by">xanderlewis</span><span>|</span><a href="#40215053">next</a><span>|</span><label class="collapse" for="c-40214349">[-]</label><label class="expand" for="c-40214349">[65 more]</label></div><br/><div class="children"><div class="content">&gt; Stripped of anything else, neural networks are compositions of differentiable primitives<p>I’m a sucker for statements like this. It almost feels philosophical, and makes the whole subject so much more comprehensible in only a single sentence.<p>I think François Chollet says something similar in his book on deep learning: one shouldn’t fall into the trap of anthropomorphising and mysticising models based on the ‘neural’ name; deep learning is simply the application of sequences of operations that are nonlinear (and hence capable of encoding arbitrary complexity) but nonetheless differentiable and so efficiently optimisable.</div><br/><div id="40219489" class="c"><input type="checkbox" id="c-40219489" checked=""/><div class="controls bullet"><span class="by">jonas21</span><span>|</span><a href="#40214349">parent</a><span>|</span><a href="#40214829">next</a><span>|</span><label class="collapse" for="c-40219489">[-]</label><label class="expand" for="c-40219489">[1 more]</label></div><br/><div class="children"><div class="content">I feel like this statement is both obvious after spending a few minutes working with neural networks and completely useless in helping you build better neural networks.<p>It&#x27;s kind of like saying, &quot;Stripped of anything else, works of literature are compositions of words&quot;</div><br/></div></div><div id="40214829" class="c"><input type="checkbox" id="c-40214829" checked=""/><div class="controls bullet"><span class="by">captainclam</span><span>|</span><a href="#40214349">parent</a><span>|</span><a href="#40219489">prev</a><span>|</span><a href="#40216719">next</a><span>|</span><label class="collapse" for="c-40214829">[-]</label><label class="expand" for="c-40214829">[10 more]</label></div><br/><div class="children"><div class="content">Ugh, exactly, it&#x27;s so cool. I&#x27;ve been a deep learning practitioner for ~3 years now, and I feel like this notion has really been impressed upon me only recently.<p>I&#x27;ve spent an awful lot of mental energy trying to conceive of how these things work, when really it comes down to &quot;does increasing this parameter improve the performance on this task? Yes? Move the dial up a bit. No? Down a bit...&quot; x 1e9.<p>And the cool part is that this yields such rich, interesting, sometimes even useful, structures!<p>I like to think of this cognitive primitive as the analogue to the idea that thermodynamics is just the sum of particles bumping into each other. At the end of the day, that really is just it, but the collective behavior is something else entirely.</div><br/><div id="40214973" class="c"><input type="checkbox" id="c-40214973" checked=""/><div class="controls bullet"><span class="by">xanderlewis</span><span>|</span><a href="#40214349">root</a><span>|</span><a href="#40214829">parent</a><span>|</span><a href="#40215025">next</a><span>|</span><label class="collapse" for="c-40214973">[-]</label><label class="expand" for="c-40214973">[1 more]</label></div><br/><div class="children"><div class="content">&gt; At the end of the day, that really is just it, but the collective behavior is something else entirely.<p>Exactly. It’s not to say that neat descriptions like this are the end of the story (or even the beginning of it). If they were, there would be no need for this entire field of study.<p>But they are cool, and can give you a really clear conceptualisation of something that can appear more like a sum of disjoint observations and ad hoc tricks than a discipline based on a few deep principles.</div><br/></div></div><div id="40215025" class="c"><input type="checkbox" id="c-40215025" checked=""/><div class="controls bullet"><span class="by">JackFr</span><span>|</span><a href="#40214349">root</a><span>|</span><a href="#40214829">parent</a><span>|</span><a href="#40214973">prev</a><span>|</span><a href="#40218156">next</a><span>|</span><label class="collapse" for="c-40215025">[-]</label><label class="expand" for="c-40215025">[1 more]</label></div><br/><div class="children"><div class="content">NAND gates by themselves are kind of dull, but it&#x27;s pretty cool what you can do with a billion of them.</div><br/></div></div><div id="40218156" class="c"><input type="checkbox" id="c-40218156" checked=""/><div class="controls bullet"><span class="by">kadushka</span><span>|</span><a href="#40214349">root</a><span>|</span><a href="#40214829">parent</a><span>|</span><a href="#40215025">prev</a><span>|</span><a href="#40216719">next</a><span>|</span><label class="collapse" for="c-40218156">[-]</label><label class="expand" for="c-40218156">[7 more]</label></div><br/><div class="children"><div class="content"><i>it comes down to &quot;does increasing this parameter improve the performance on this task? Yes? Move the dial up a bit. No? Down a bit...&quot; x 1e9</i><p>This is not how gradient based NN optimization works. What you described is called &quot;random weight perturbation&quot;, a variant of evolutionary algorithms. It does not scale to networks larger than a few thousand parameters for obvious reasons.<p>NNs are optimized by directly computing a gradient which tells us the direction to go to to reduce the loss on the current batch of training data. There&#x27;s no trying up or down and seeing if it worked - we always know which direction to go.<p>SGD and RWP are two completely different approaches to learning optimal NN weights.</div><br/><div id="40219050" class="c"><input type="checkbox" id="c-40219050" checked=""/><div class="controls bullet"><span class="by">captainclam</span><span>|</span><a href="#40214349">root</a><span>|</span><a href="#40218156">parent</a><span>|</span><a href="#40218281">next</a><span>|</span><label class="collapse" for="c-40219050">[-]</label><label class="expand" for="c-40219050">[2 more]</label></div><br/><div class="children"><div class="content">I guess you could say I don&#x27;t know RWP from Adam! :D<p>My og comment wasn&#x27;t to accurately explain gradient optimization, I was just expressing a sentiment not especially aimed at experts and not especially requiring details.<p>Though I&#x27;m afraid I subjected you to the same &quot;cringe&quot; I experience when I read pop sci&#x2F;tech articles describe deep learning optimization as &quot;the algorithm&quot; being &quot;rewarded&quot; or &quot;punished,&quot; haha.</div><br/><div id="40219538" class="c"><input type="checkbox" id="c-40219538" checked=""/><div class="controls bullet"><span class="by">kadushka</span><span>|</span><a href="#40214349">root</a><span>|</span><a href="#40219050">parent</a><span>|</span><a href="#40218281">next</a><span>|</span><label class="collapse" for="c-40219538">[-]</label><label class="expand" for="c-40219538">[1 more]</label></div><br/><div class="children"><div class="content">No worries, we&#x27;re all friends here!<p>it&#x27;s just you happened to accidentally describe the idea behind RWP, which is a gradient-free optimization method, so I thought I should point it out.</div><br/></div></div></div></div><div id="40218281" class="c"><input type="checkbox" id="c-40218281" checked=""/><div class="controls bullet"><span class="by">xanderlewis</span><span>|</span><a href="#40214349">root</a><span>|</span><a href="#40218156">parent</a><span>|</span><a href="#40219050">prev</a><span>|</span><a href="#40216719">next</a><span>|</span><label class="collapse" for="c-40218281">[-]</label><label class="expand" for="c-40218281">[4 more]</label></div><br/><div class="children"><div class="content">I don’t think the author <i>literally</i> meant tweaking the parameters and seeing what happens; it’s probably an analogy meant to give a sense of how the gradient indicates what direction and to what degree the parameters should be tweaked. Basically, substitute ‘the gradient is positive’ for ‘increasing this parameter decreases performance’ and vice versa and it becomes correct.</div><br/><div id="40218390" class="c"><input type="checkbox" id="c-40218390" checked=""/><div class="controls bullet"><span class="by">p1esk</span><span>|</span><a href="#40214349">root</a><span>|</span><a href="#40218281">parent</a><span>|</span><a href="#40216719">next</a><span>|</span><label class="collapse" for="c-40218390">[-]</label><label class="expand" for="c-40218390">[3 more]</label></div><br/><div class="children"><div class="content">That substitution is the main difference between SGD and RWP.<p>It’s like describing bubble sort when you meant to describe quick sort. Would not fly on an ML 101 exam, or in an ML job interview.</div><br/><div id="40218743" class="c"><input type="checkbox" id="c-40218743" checked=""/><div class="controls bullet"><span class="by">xanderlewis</span><span>|</span><a href="#40214349">root</a><span>|</span><a href="#40218390">parent</a><span>|</span><a href="#40219369">next</a><span>|</span><label class="collapse" for="c-40218743">[-]</label><label class="expand" for="c-40218743">[1 more]</label></div><br/><div class="children"><div class="content">It’s not like that at all. You couldn’t accidentally sound like you’re describing quick sort when describing bubble sort, or vice versa. I can’t think of any substitution of a few words that would do that.<p>The <i>meaning</i> of the gradient is perfectly adequately described by the author. They weren’t describing an algorithm for <i>computing</i> it.</div><br/></div></div><div id="40219369" class="c"><input type="checkbox" id="c-40219369" checked=""/><div class="controls bullet"><span class="by">a_random_canuck</span><span>|</span><a href="#40214349">root</a><span>|</span><a href="#40218390">parent</a><span>|</span><a href="#40218743">prev</a><span>|</span><a href="#40216719">next</a><span>|</span><label class="collapse" for="c-40219369">[-]</label><label class="expand" for="c-40219369">[1 more]</label></div><br/><div class="children"><div class="content">I don’t think anyone is trying to pass an exam here, but just give an understandable overview to a general audience.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="40216719" class="c"><input type="checkbox" id="c-40216719" checked=""/><div class="controls bullet"><span class="by">naasking</span><span>|</span><a href="#40214349">parent</a><span>|</span><a href="#40214829">prev</a><span>|</span><a href="#40216975">next</a><span>|</span><label class="collapse" for="c-40216719">[-]</label><label class="expand" for="c-40216719">[1 more]</label></div><br/><div class="children"><div class="content">&gt; one shouldn’t fall into the trap of anthropomorphising and mysticising models based on the ‘neural’ name<p>One also shouldn&#x27;t fall into the dual trap of assuming that just because one understands how a model works, it cannot have any bearing on the ever-mysterious operation of the brain.</div><br/></div></div><div id="40216975" class="c"><input type="checkbox" id="c-40216975" checked=""/><div class="controls bullet"><span class="by">sideshowb</span><span>|</span><a href="#40214349">parent</a><span>|</span><a href="#40216719">prev</a><span>|</span><a href="#40216343">next</a><span>|</span><label class="collapse" for="c-40216975">[-]</label><label class="expand" for="c-40216975">[1 more]</label></div><br/><div class="children"><div class="content">&gt; deep learning is simply the application of sequences of operations that are nonlinear  but nonetheless differentiable<p>Though other things fit this description which are not deep learning. Like (shameless plug) my recent paper here <a href="https:&#x2F;&#x2F;ieeexplore.ieee.org&#x2F;document&#x2F;10497907" rel="nofollow">https:&#x2F;&#x2F;ieeexplore.ieee.org&#x2F;document&#x2F;10497907</a></div><br/></div></div><div id="40216343" class="c"><input type="checkbox" id="c-40216343" checked=""/><div class="controls bullet"><span class="by">jimbokun</span><span>|</span><a href="#40214349">parent</a><span>|</span><a href="#40216975">prev</a><span>|</span><a href="#40215198">next</a><span>|</span><label class="collapse" for="c-40216343">[-]</label><label class="expand" for="c-40216343">[1 more]</label></div><br/><div class="children"><div class="content">I always get the impression even the proponents of these algorithms when they didn&#x27;t seem so promising, are shocked at the capabilities demonstrated by models built with such a relatively simple procedure.</div><br/></div></div><div id="40215198" class="c"><input type="checkbox" id="c-40215198" checked=""/><div class="controls bullet"><span class="by">gessha</span><span>|</span><a href="#40214349">parent</a><span>|</span><a href="#40216343">prev</a><span>|</span><a href="#40215628">next</a><span>|</span><label class="collapse" for="c-40215198">[-]</label><label class="expand" for="c-40215198">[5 more]</label></div><br/><div class="children"><div class="content">It is soothing to the mind because it conveys that it’s understandable but it doesn’t take away from the complexity. You still have to read through math and pytorch code and debug nonsensical CUDA errors, comb through the data, etc etc</div><br/><div id="40215394" class="c"><input type="checkbox" id="c-40215394" checked=""/><div class="controls bullet"><span class="by">whimsicalism</span><span>|</span><a href="#40214349">root</a><span>|</span><a href="#40215198">parent</a><span>|</span><a href="#40215628">next</a><span>|</span><label class="collapse" for="c-40215394">[-]</label><label class="expand" for="c-40215394">[4 more]</label></div><br/><div class="children"><div class="content">the complexity is in the values learned from the optimization. even the pytorch code for a simple transformer is not that complex, attention is a simple mechanism, etc.</div><br/><div id="40215998" class="c"><input type="checkbox" id="c-40215998" checked=""/><div class="controls bullet"><span class="by">gessha</span><span>|</span><a href="#40214349">root</a><span>|</span><a href="#40215394">parent</a><span>|</span><a href="#40215628">next</a><span>|</span><label class="collapse" for="c-40215998">[-]</label><label class="expand" for="c-40215998">[3 more]</label></div><br/><div class="children"><div class="content">Complexity also comes from the number of papers that work out how different elements of network work and how to intuitively change them.<p>Why do we use conv operators, why do we use attention operators, when do we use one over the other? What augmentations do you use, how big of a dataset do you need, how do you collect the dataset, etc etc etc</div><br/><div id="40216078" class="c"><input type="checkbox" id="c-40216078" checked=""/><div class="controls bullet"><span class="by">whimsicalism</span><span>|</span><a href="#40214349">root</a><span>|</span><a href="#40215998">parent</a><span>|</span><a href="#40215628">next</a><span>|</span><label class="collapse" for="c-40216078">[-]</label><label class="expand" for="c-40216078">[2 more]</label></div><br/><div class="children"><div class="content">idk, just using attention and massive web crawls gets you pretty far. a lot of the rest is more product-style decisions about what personality you want your LM to take.<p>I fundamentally don&#x27;t think this technology is that complex.</div><br/><div id="40219323" class="c"><input type="checkbox" id="c-40219323" checked=""/><div class="controls bullet"><span class="by">gessha</span><span>|</span><a href="#40214349">root</a><span>|</span><a href="#40216078">parent</a><span>|</span><a href="#40215628">next</a><span>|</span><label class="collapse" for="c-40219323">[-]</label><label class="expand" for="c-40219323">[1 more]</label></div><br/><div class="children"><div class="content">No? In his recent tutorial, Karpathy showed just how much complexity there is in the tokenizer.<p>This technology has been years in the making with many small advances pushing the performance ever so slightly. There’s been theoretical and engineering advances that contributed to where we are today. And we need many more to get the technology to an actually usable level instead of the current word spaghetti that we get.<p>Also, the post is generally about neural networks and not just LMs.<p>When making design decisions about an ML system you shouldn’t just choose the attention hammer and hammer away. There’s a lot of design constraints you need to consider which is why I made the original reply.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="40215628" class="c"><input type="checkbox" id="c-40215628" checked=""/><div class="controls bullet"><span class="by">phkahler</span><span>|</span><a href="#40214349">parent</a><span>|</span><a href="#40215198">prev</a><span>|</span><a href="#40215592">next</a><span>|</span><label class="collapse" for="c-40215628">[-]</label><label class="expand" for="c-40215628">[12 more]</label></div><br/><div class="children"><div class="content">&gt;&gt; one shouldn’t fall into the trap of anthropomorphising and mysticising models based on the ‘neural’ name<p>And yet, artificial neural networks ARE an approximation of how biological neurons work. It is worth noting that they came out of neurobiology and not some math department - well at least in the forward direction, I&#x27;m not sure who came up with the training algorithms (probably the math folks). Should they be considered mystical? No.  I would also posit that biological neurons are more efficient and probably have better learning algorithms than artificial ones today.<p>I&#x27;m confused as to why some people seem to shun the biological equivalence of these things. In a recent thread here I learned that physical synaptic weights (in our brains) are at least partly stored in DNA or its methylation. If that isn&#x27;t fascinating I&#x27;m not sure what is. Or is it more along the lines of intelligence can be reduced to a large number of simple things, and biology has given us an interesting physical implementation?</div><br/><div id="40216482" class="c"><input type="checkbox" id="c-40216482" checked=""/><div class="controls bullet"><span class="by">xanderlewis</span><span>|</span><a href="#40214349">root</a><span>|</span><a href="#40215628">parent</a><span>|</span><a href="#40215780">next</a><span>|</span><label class="collapse" for="c-40216482">[-]</label><label class="expand" for="c-40216482">[10 more]</label></div><br/><div class="children"><div class="content">As the commenter below mentions, the biological version of a neuron (i.e. a neuron) is <i>much</i> more complicated than the neural network version. The neural network version is essentially just a weighted sum, with an extra layer of shaping applied afterwards to make it nonlinear. As far as I know, we still don’t understand all of the complexity about how biological neurons work. Even skimming the Wikipedia page for ‘neuron’ will give you some idea.<p>The original idea of approximating something like a neuron using a weighted sum (which is a fairly obvious idea, given the initial discovery that neurons become ‘activated’ and they do so in proportion to how much the neurons they are connected to are) did come from thinking about biological brains, but the mathematical building blocks are incredibly simple and are hundreds of years old, if not thousands.</div><br/><div id="40216693" class="c"><input type="checkbox" id="c-40216693" checked=""/><div class="controls bullet"><span class="by">naasking</span><span>|</span><a href="#40214349">root</a><span>|</span><a href="#40216482">parent</a><span>|</span><a href="#40215780">next</a><span>|</span><label class="collapse" for="c-40216693">[-]</label><label class="expand" for="c-40216693">[9 more]</label></div><br/><div class="children"><div class="content">&gt;  the biological version of a neuron (i.e. a neuron) is much more complicated than the neural network version<p>This is a difference of degree not of kind, because neural networks are Turning complete. Whatever additional complexity the neuron has can itself be modelled as a neural network.<p>Edit: meaning, that if the greater complexity of a biological neuron is relevant to its information processing component, then that just increases the number of artificial neural network neurons needed to describe it, it does not need any computation of a different kind.</div><br/><div id="40218071" class="c"><input type="checkbox" id="c-40218071" checked=""/><div class="controls bullet"><span class="by">andoando</span><span>|</span><a href="#40214349">root</a><span>|</span><a href="#40216693">parent</a><span>|</span><a href="#40217202">next</a><span>|</span><label class="collapse" for="c-40218071">[-]</label><label class="expand" for="c-40218071">[3 more]</label></div><br/><div class="children"><div class="content">And assembly is also turing complete, so if two models being both Turing completeness means they are equivalent, there would be no need for coding neural networks at all. Would you consider LLMs a different kind of computation than writing assembly code?<p>Perhaps fundamentally they are not, but its also true that just writing more and more random assembly code isn&#x27;t going to lead to an LLM.</div><br/><div id="40218394" class="c"><input type="checkbox" id="c-40218394" checked=""/><div class="controls bullet"><span class="by">naasking</span><span>|</span><a href="#40214349">root</a><span>|</span><a href="#40218071">parent</a><span>|</span><a href="#40217202">next</a><span>|</span><label class="collapse" for="c-40218394">[-]</label><label class="expand" for="c-40218394">[2 more]</label></div><br/><div class="children"><div class="content">LLMs aren&#x27;t randomly generated though, they are shaped by training data. This means there would, in principle, be a comparable way to synthesize an equivalent assembly program from that same training data.<p>The difference here is that it&#x27;s just more obvious how to do this in one case than the other.<p>My point was only that 1) neural networks are sufficient, even if real neurons have additional complexity, and 2) whatever that additional complexity, artificial neural networks can learn to reproduce it.</div><br/><div id="40218505" class="c"><input type="checkbox" id="c-40218505" checked=""/><div class="controls bullet"><span class="by">andoando</span><span>|</span><a href="#40214349">root</a><span>|</span><a href="#40218394">parent</a><span>|</span><a href="#40217202">next</a><span>|</span><label class="collapse" for="c-40218505">[-]</label><label class="expand" for="c-40218505">[1 more]</label></div><br/><div class="children"><div class="content">I understand that, what I am saying though is the fact that they can doesn&#x27;t mean that they will by simply scaling their number. It still entirely depends on how they are trained&#x2F;arranged, meaning it may take a completely different way of composing&#x2F;glueing neurons together to stimulate any additional complexity. Its like saying a nand gate is turing complete, I put 1000000000 of them in a series, but its not doing anything, what gives, do I need to add a billion more?<p>Just as a modeling and running a single neuron takes x amount of transistors configured in a very specific way for example, it may take y amount of neurons arranged in some very specific, unknown to model something that has extra properties.<p>And its not clear either whether neurons are fundamentally the correct approach to reach this higher level construction than some other kind of node.</div><br/></div></div></div></div></div></div><div id="40217202" class="c"><input type="checkbox" id="c-40217202" checked=""/><div class="controls bullet"><span class="by">xanderlewis</span><span>|</span><a href="#40214349">root</a><span>|</span><a href="#40216693">parent</a><span>|</span><a href="#40218071">prev</a><span>|</span><a href="#40215780">next</a><span>|</span><label class="collapse" for="c-40217202">[-]</label><label class="expand" for="c-40217202">[5 more]</label></div><br/><div class="children"><div class="content">PowerPoint is Turing complete. Does that mean PowerPoint should be regarded as being biological or at least neuroscience-inspired?</div><br/><div id="40217352" class="c"><input type="checkbox" id="c-40217352" checked=""/><div class="controls bullet"><span class="by">naasking</span><span>|</span><a href="#40214349">root</a><span>|</span><a href="#40217202">parent</a><span>|</span><a href="#40215780">next</a><span>|</span><label class="collapse" for="c-40217352">[-]</label><label class="expand" for="c-40217352">[4 more]</label></div><br/><div class="children"><div class="content">No, but neural networks literally were inspired by biology so I&#x27;m not sure what your point is.</div><br/><div id="40217999" class="c"><input type="checkbox" id="c-40217999" checked=""/><div class="controls bullet"><span class="by">xanderlewis</span><span>|</span><a href="#40214349">root</a><span>|</span><a href="#40217352">parent</a><span>|</span><a href="#40215780">next</a><span>|</span><label class="collapse" for="c-40217999">[-]</label><label class="expand" for="c-40217999">[3 more]</label></div><br/><div class="children"><div class="content">My point is that you seem to think neurons in the sense of artificial neural networks and neurons in the human brain are equivalent because:<p>(1) Neural networks are Turing complete, and hence can do anything brains can. [debatable anyway; We don’t know this to be the case since brains might be doing more than computation. Ask a philosopher or a cognitive scientist. Or Roger Penrose.]<p>(2) Neural networks were very loosely inspired by the idea that the human brain is made up of interconnected nodes that ‘activate’ in proportion to how other related nodes do.<p>I don’t think that’s nearly enough to say that they’re equivalent. For (1), we don’t yet know (and we’re not even close), and anyway: if you consider all Turing complete systems to be equivalent to the point of it being a waste of time to talk about their differences then you can say goodbye to quite a lot of work in theoretical computer science. For (2): so what? Lots of things are inspired by other things. It doesn’t make them in any sense equivalent, especially if the analogy is as weak as it is in this case. No neuroscientist thinks that a weighted sum is an adequate (or even remotely accurate) model of a real biological neuron. They operate on completely different principles, as we now know much better than when such things were first dreamed up.</div><br/><div id="40218254" class="c"><input type="checkbox" id="c-40218254" checked=""/><div class="controls bullet"><span class="by">naasking</span><span>|</span><a href="#40214349">root</a><span>|</span><a href="#40217999">parent</a><span>|</span><a href="#40215780">next</a><span>|</span><label class="collapse" for="c-40218254">[-]</label><label class="expand" for="c-40218254">[2 more]</label></div><br/><div class="children"><div class="content">The brain certainly could be doing super-Turing computation, but that would overturn quite a bit of physics seeing as how not even quantum computers are more powerful than Turing machines (they&#x27;re just faster on some problems). Extraordinary claims and all that.<p>As for equivalency, that depends on how that&#x27;s defined. Real neurons would not feature any more computational power than Turing machines or artificial neural networks, but I never said it would be a waste of time to talk about their differences. I merely pointed out that the artificial neural network model is <i>still sufficient</i>, even if real neurons have more complexity.<p>&gt; No neuroscientist thinks that a weighted sum is an adequate (or even remotely accurate) model of a real biological neuron<p>Fortunately that&#x27;s not what I said. If the neuron indeed has more relevant complexity, then it wouldn&#x27;t be one weighted sum = one biological neuron, but one biological neuron = a network of weighted sums, since such a network can model any function.</div><br/><div id="40218343" class="c"><input type="checkbox" id="c-40218343" checked=""/><div class="controls bullet"><span class="by">xanderlewis</span><span>|</span><a href="#40214349">root</a><span>|</span><a href="#40218254">parent</a><span>|</span><a href="#40215780">next</a><span>|</span><label class="collapse" for="c-40218343">[-]</label><label class="expand" for="c-40218343">[1 more]</label></div><br/><div class="children"><div class="content">The original comment you were in defence of was suggesting that artificial neurons were somehow very close to biological ones, since supposedly that’s where their inspiration came from.<p>If you’re interested in pure computational ‘power’, then if the brain is nothing more than a Turing machine (which, as you agree, it might not be), fine. You can call them ‘equivalent’. It’s just not very meaningful.<p>What’s interesting about neural nets has nothing to do with <i>what</i> they can compute; indeed they can compute anything any other Turing machine can, and nothing more. What’s interesting is <i>how</i> they do it, since they can ‘learn’ and hence allow us to produce solutions to hard problems without any explicit programming or traditional analysis of the problem.<p>&gt; that would overturn quite a bit of physics<p>Our physics is currently woefully incomplete, so… yes. That would be welcome.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="40215780" class="c"><input type="checkbox" id="c-40215780" checked=""/><div class="controls bullet"><span class="by">kragen</span><span>|</span><a href="#40214349">root</a><span>|</span><a href="#40215628">parent</a><span>|</span><a href="#40216482">prev</a><span>|</span><a href="#40215592">next</a><span>|</span><label class="collapse" for="c-40215780">[-]</label><label class="expand" for="c-40215780">[1 more]</label></div><br/><div class="children"><div class="content">anns originated in hypotheses about how neurobiology might work in the 01940s but diverged completely from neurobiology in the 01960s; they contain nothing we&#x27;ve learned about neurons in the last 50 years, and not much from before that either (they don&#x27;t, for example, do hebbian learning).  current anns use training methods like gradient descent with momentum and activation functions like relu which have no plausible biological realization<p>artificial neural networks are an approximation of biological neural networks in the same way that a submarine is an approximation of a fish</div><br/></div></div></div></div><div id="40215592" class="c"><input type="checkbox" id="c-40215592" checked=""/><div class="controls bullet"><span class="by">zackmorris</span><span>|</span><a href="#40214349">parent</a><span>|</span><a href="#40215628">prev</a><span>|</span><a href="#40215245">next</a><span>|</span><label class="collapse" for="c-40215592">[-]</label><label class="expand" for="c-40215592">[1 more]</label></div><br/><div class="children"><div class="content">Ya so far this is the best introduction to neural networks from first principles that I&#x27;ve seen.<p>Quickly skimming the draft pdf at <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2404.17625" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2404.17625</a> I can grok it instantly, because it&#x27;s written in familiar academic language instead of gobbledygook. Anyone with an undergrad math education in engineering, computer science, etc or a self-taught equivalent understanding of differential equations should be able to read it easily. It does a really good job of connecting esoteric terms like tensors with arrays, gradients with partial derivatives, Jacobians with gradients and backpropagation with gradient descent in forward&#x2F;reverse mode automatic differentiation. Which helps the reader to grasp the fundamentals instead of being distracted by the implementation details of TensorFlow, CUDA, etc. Some notable excerpts:<p>Introduction (page 4):<p><pre><code>  By viewing neural networks as simply compositions of differentiable primitives we can ask two basic questions (Figure F.1.3): first, what data types can we handle as inputs or outputs? And second, what sort of primitives can we use? Differentiability is a strong requirement that does not allow us to work directly with many standard data types, such as characters or integers, which are fundamentally discrete and hence discontinuous. By contrast, we will see that differentiable models can work easily with more complex data represented as large arrays (what we will call tensors) of numbers, such as images, which can be manipulated algebraically by basic compositions of linear and nonlinear transformations.
</code></pre>
Chapter 2.2 Gradients and Jacobians (page 23):<p><pre><code>  [just read this section - it connects partial derivatives, gradients, Jacobians and Taylor’s theorem - wow!]
</code></pre>
Chapter 4.1.5 Some computational considerations (page 59):<p><pre><code>  In general, we will always prefer algorithms that scale linearly both in the feature dimension c and in the batch size n, since super-linear algorithms will become quickly impractical (e.g., a batch of 32 RGB images of size 1024×1024 has c ≈ 1e7). We can avoid a quadratic complexity in the equation of the gradient by computing the multiplications in the correct order, i.e., computing the matrix-vector product Xw first. Hence, pure gradient descent is linear in both c and n, but only if proper care is taken in the implementation: generalizing this idea is the fundamental insight for the development of reverse-mode automatic differentiation, a.k.a. back-propagation (Section 6.3).
</code></pre>
Chapter 6 Automatic differentiation (page 87):<p><pre><code>  We consider the problem of efficiently computing gradients of generic computational graphs, such as those induced by optimizing a scalar loss function on a fully-connected neural network, a task called automatic differentiation (AD) [BPRS18]. You can think of a computational graph as the set of atomic operations (which we call primitives) obtained by running the program itself. We will consider sequential graphs for brevity, but everything can be easily extended to more sophisticated, acyclic computational graphs.
  
  The problem may seem trivial, since the chain rule of Jacobians (Section 2.2, (E.2.22)) tells us that the gradient of function composition is simply the matrix product of the corresponding Jacobian matrices. However, efficiently implementing this is the key challenge, and the resulting algorithm (reverse-mode AD or backpropagation) is a cornerstone of neural networks and differentiable programming in general [GW08, BR24]. Understanding it is also key to understanding the design (and the differences) of most frameworks for implementing and training such programs (such as TensorFlow or PyTorch or JAX). A brief history of the algorithm can be found in [Gri12].
</code></pre>
Edit: I changed Chapter 2.2.3 Jacobians (page 27) to Chapter 2.2 Gradients and Jacobians (page 23) for better context.</div><br/></div></div><div id="40215245" class="c"><input type="checkbox" id="c-40215245" checked=""/><div class="controls bullet"><span class="by">jxy</span><span>|</span><a href="#40214349">parent</a><span>|</span><a href="#40215592">prev</a><span>|</span><a href="#40219752">next</a><span>|</span><label class="collapse" for="c-40215245">[-]</label><label class="expand" for="c-40215245">[13 more]</label></div><br/><div class="children"><div class="content">&gt; &gt; Stripped of anything else, neural networks are compositions of differentiable primitives<p>&gt; I’m a sucker for statements like this. It almost feels philosophical, and makes the whole subject so much more comprehensible in only a single sentence.<p>And I hate inaccurate statements like this. It pretends to be rigorous mathematical, but really just propagates erroneous information, and makes the whole article so much more amateur in only a single sentence.<p>The simple relu is continuous but not differentiable at 0, and its derivative is discontinuous at 0.</div><br/><div id="40215358" class="c"><input type="checkbox" id="c-40215358" checked=""/><div class="controls bullet"><span class="by">xanderlewis</span><span>|</span><a href="#40214349">root</a><span>|</span><a href="#40215245">parent</a><span>|</span><a href="#40215380">next</a><span>|</span><label class="collapse" for="c-40215358">[-]</label><label class="expand" for="c-40215358">[11 more]</label></div><br/><div class="children"><div class="content">It’s not ‘inaccurate’. The mark of true mastery is an ability to make terse statements that convey a huge amount without involving excessive formality or discussion of by-the-by technical details. If ever you’ve spoken to world-renowned experts in pure mathematics or other highly technical and pendantic fields, you’ll find they’ll say all sorts of ‘inaccurate’ things in conversation (or even in written documents). It doesn’t make them worthless; far from it.<p>If you want to have a war of petty pedantry, let’s go: the derivative of ReLU can’t be <i>discontinuous at zero</i>, as you say, because continuity (or indeed discontinuity) of a function at x requires the function to have a value at x (which is the negation of what your first statement correctly claims).</div><br/><div id="40218402" class="c"><input type="checkbox" id="c-40218402" checked=""/><div class="controls bullet"><span class="by">newrotik</span><span>|</span><a href="#40214349">root</a><span>|</span><a href="#40215358">parent</a><span>|</span><a href="#40216643">next</a><span>|</span><label class="collapse" for="c-40218402">[-]</label><label class="expand" for="c-40218402">[1 more]</label></div><br/><div class="children"><div class="content">Lack of differentiability is actually a very important feature of the underlying optimization problem.<p>You might think that it doesn&#x27;t matter because ReLU is, e.g., non-differentiable &quot;only at one point&quot;.<p>Gradient based methods (what you find in pytorch) generally rely on the idea that gradients should taper to 0 in the proximity of a local optimum. This is not the case for non-differentiable functions, and in fact gradients can be made to be arbitrarily large even very close to the optimum.<p>As you may imagine, it is not hard to construct examples where simple gradient methods that do not properly take these facts into account fail to converge. These examples are not exotic.</div><br/></div></div><div id="40216643" class="c"><input type="checkbox" id="c-40216643" checked=""/><div class="controls bullet"><span class="by">makerdiety</span><span>|</span><a href="#40214349">root</a><span>|</span><a href="#40215358">parent</a><span>|</span><a href="#40218402">prev</a><span>|</span><a href="#40215704">next</a><span>|</span><label class="collapse" for="c-40216643">[-]</label><label class="expand" for="c-40216643">[3 more]</label></div><br/><div class="children"><div class="content">Invoking excessive formality and discussions of minute technical details leads to a cathedral of knowledge built on autistic pedantry. The chosen rabbit hole to get lost in needs to be the correct one. And human science is riddled with the paths that have naive or childish fundamentals.</div><br/><div id="40219467" class="c"><input type="checkbox" id="c-40219467" checked=""/><div class="controls bullet"><span class="by">kragen</span><span>|</span><a href="#40214349">root</a><span>|</span><a href="#40216643">parent</a><span>|</span><a href="#40217277">next</a><span>|</span><label class="collapse" for="c-40219467">[-]</label><label class="expand" for="c-40219467">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>a cathedral of knowledge built on autistic pedantry</i><p>this is certainly true, but more often we use its short name, &#x27;math&#x27;.  it turns out to be far more effective than so-called common sense</div><br/></div></div><div id="40217277" class="c"><input type="checkbox" id="c-40217277" checked=""/><div class="controls bullet"><span class="by">mistermann</span><span>|</span><a href="#40214349">root</a><span>|</span><a href="#40216643">parent</a><span>|</span><a href="#40219467">prev</a><span>|</span><a href="#40215704">next</a><span>|</span><label class="collapse" for="c-40217277">[-]</label><label class="expand" for="c-40217277">[1 more]</label></div><br/><div class="children"><div class="content">This comment makes me want to both upvote and downvote with extreme enthusiasm&#x2F;fury!<p>The sign of a truly good conversation?</div><br/></div></div></div></div><div id="40215704" class="c"><input type="checkbox" id="c-40215704" checked=""/><div class="controls bullet"><span class="by">kragen</span><span>|</span><a href="#40214349">root</a><span>|</span><a href="#40215358">parent</a><span>|</span><a href="#40216643">prev</a><span>|</span><a href="#40215380">next</a><span>|</span><label class="collapse" for="c-40215704">[-]</label><label class="expand" for="c-40215704">[6 more]</label></div><br/><div class="children"><div class="content">my experience with world-renowned experts in pure mathematics is that they are much more careful than the average bear to explicitly qualify inaccurate things as inaccurate, because their discipline requires them to be very clear about precisely what they are saying<p>discontinuity of a function at <i>x</i> does not, according to the usual definition of &#x27;continuity&#x27;, require the function to have a value at <i>x</i>; indeed, functions that fail to have a value at <i>x</i> are necessarily discontinuous there, precisely because (as you say) they are not continuous there.  <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Continuous_function#Definition_in_terms_of_limits_of_functions" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Continuous_function#Definition...</a><p>there are other definitions of &#x27;discontinuous&#x27; in use, but i can&#x27;t think of one that would give the result you claim</div><br/><div id="40216360" class="c"><input type="checkbox" id="c-40216360" checked=""/><div class="controls bullet"><span class="by">xanderlewis</span><span>|</span><a href="#40214349">root</a><span>|</span><a href="#40215704">parent</a><span>|</span><a href="#40215380">next</a><span>|</span><label class="collapse" for="c-40216360">[-]</label><label class="expand" for="c-40216360">[5 more]</label></div><br/><div class="children"><div class="content">&gt; they are much more careful than the average bear to explicitly qualify inaccurate things as inaccurate<p>Sure. But what part of this <i>entirely worded in natural language, and very short</i> statement made you think it was a technical, formal statement? I think you’re just taking an opportunity to flex your knowledge of basic calculus, and deliberately attributing intent to the author that isn’t there in order to look clever.<p>Regarding a function being discontinuous at a point outside its domain: if you take a completely naive view of what ‘discontinuous’ means, then I suppose you can say so. But discontinuity is just the logical negation of continuity. Observe:<p>To say that <i>f: X —&gt; Y (in this context, a real-valued function of real numbers) is continuous</i> means precisely<p>∀x∈X ∀ε&gt;0 ∃δ&gt;0 |x - p| &lt; δ ⇒ |f(x) - f(p)| &lt; ε<p>and so its negation looks like<p>∃x∈X ⌐ …<p>that is, there is a point <i>in X, the domain of f</i> where continuity fails.<p>For example, you wouldn’t talk about a function defined on the integers being <i>discontinuous at pi</i>, would you? That would just be weird.<p>To prove the point further, observe that the set of discontinuities (according to your definition) of any given function would actually include <i>every</i> number… in fact every mathematical object in the universe — which would make it not even a set in ZFC. So it’s absurd.<p>Even more reasons to believe functions can only be discontinuous at points of their domain: a function is said to be discontinuous if it has at least one discontinuity. By your definition, <i>every</i> function is discontinuous.<p>…anyway, I said we were going to be petty. I’m trying to demonstrate this is a waste of time by wasting my own time.</div><br/><div id="40219519" class="c"><input type="checkbox" id="c-40219519" checked=""/><div class="controls bullet"><span class="by">kragen</span><span>|</span><a href="#40214349">root</a><span>|</span><a href="#40216360">parent</a><span>|</span><a href="#40216448">next</a><span>|</span><label class="collapse" for="c-40219519">[-]</label><label class="expand" for="c-40219519">[2 more]</label></div><br/><div class="children"><div class="content">you have an interesting point of view, and some of the things you have said are correct, but if you try to use gradient descent on a function from, say, ℤ → ℝ, you are going to be a very sad xanda.  i would indeed describe such a function as being discontinuous not just at <i>π</i> but everywhere, at least with the usual definition of continuity (though there is a sense in which such a function could be, for example, scott-continuous)<p>even in the case of a single discontinuity in the derivative, like in relu&#x27;, you lose the intermediate value theorem and everything that follows from it; it&#x27;s not an inconsequential or marginally relevant fact</div><br/><div id="40220344" class="c"><input type="checkbox" id="c-40220344" checked=""/><div class="controls bullet"><span class="by">jj3</span><span>|</span><a href="#40214349">root</a><span>|</span><a href="#40219519">parent</a><span>|</span><a href="#40216448">next</a><span>|</span><label class="collapse" for="c-40220344">[-]</label><label class="expand" for="c-40220344">[1 more]</label></div><br/><div class="children"><div class="content">Note that any function ℤ → ℝ is continuous on its domain but nowhere differentiable.<p>A Scott-continuous function ℤ → ℝ must be monontonous. So not every such function is Scott-continuous.</div><br/></div></div></div></div><div id="40216448" class="c"><input type="checkbox" id="c-40216448" checked=""/><div class="controls bullet"><span class="by">laingc</span><span>|</span><a href="#40214349">root</a><span>|</span><a href="#40216360">parent</a><span>|</span><a href="#40219519">prev</a><span>|</span><a href="#40215380">next</a><span>|</span><label class="collapse" for="c-40216448">[-]</label><label class="expand" for="c-40216448">[2 more]</label></div><br/><div class="children"><div class="content">Because memes aren&#x27;t allowed on HN, you&#x27;re not allowed to reply with the &quot;akssshuallllyyy&quot; meme, so you had to go to these lengths.<p>¯\_(ツ)_&#x2F;¯</div><br/><div id="40216492" class="c"><input type="checkbox" id="c-40216492" checked=""/><div class="controls bullet"><span class="by">xanderlewis</span><span>|</span><a href="#40214349">root</a><span>|</span><a href="#40216448">parent</a><span>|</span><a href="#40215380">next</a><span>|</span><label class="collapse" for="c-40216492">[-]</label><label class="expand" for="c-40216492">[1 more]</label></div><br/><div class="children"><div class="content">You’re actually not far off. I’m somewhat embarrassed by the above, but I think it makes the point.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="40215380" class="c"><input type="checkbox" id="c-40215380" checked=""/><div class="controls bullet"><span class="by">whimsicalism</span><span>|</span><a href="#40214349">root</a><span>|</span><a href="#40215245">parent</a><span>|</span><a href="#40215358">prev</a><span>|</span><a href="#40219752">next</a><span>|</span><label class="collapse" for="c-40215380">[-]</label><label class="expand" for="c-40215380">[1 more]</label></div><br/><div class="children"><div class="content">it&#x27;s pretty close to accurate, the lack of differentiability at 0 for relu doesn&#x27;t really come into play in practice</div><br/></div></div></div></div><div id="40219752" class="c"><input type="checkbox" id="c-40219752" checked=""/><div class="controls bullet"><span class="by">m463</span><span>|</span><a href="#40214349">parent</a><span>|</span><a href="#40215245">prev</a><span>|</span><a href="#40214569">next</a><span>|</span><label class="collapse" for="c-40219752">[-]</label><label class="expand" for="c-40219752">[1 more]</label></div><br/><div class="children"><div class="content">chess is pattern matching.</div><br/></div></div><div id="40214569" class="c"><input type="checkbox" id="c-40214569" checked=""/><div class="controls bullet"><span class="by">andoando</span><span>|</span><a href="#40214349">parent</a><span>|</span><a href="#40219752">prev</a><span>|</span><a href="#40215168">next</a><span>|</span><label class="collapse" for="c-40214569">[-]</label><label class="expand" for="c-40214569">[15 more]</label></div><br/><div class="children"><div class="content">What does &quot;differentiable primitives&quot; mean here?</div><br/><div id="40214658" class="c"><input type="checkbox" id="c-40214658" checked=""/><div class="controls bullet"><span class="by">xanderlewis</span><span>|</span><a href="#40214349">root</a><span>|</span><a href="#40214569">parent</a><span>|</span><a href="#40215221">next</a><span>|</span><label class="collapse" for="c-40214658">[-]</label><label class="expand" for="c-40214658">[9 more]</label></div><br/><div class="children"><div class="content">I think it’s referring to ‘primitive functions’ in the sense that they’re the building blocks of more complicated functions. If f and g are differentiable, f+g, fg, f&#x2F;g (as long as g is never zero)… and so on are differentiable too. Importantly, f <i>composed with</i> g is also differentiable, and so since the output of the whole network as a function of its input is a composition of these ‘primitives’ it’s differentiable too.<p>The actual primitive functions in this case would be things like the weighted sums of activations in the previous layer to get the activation of a given layer, and the actual ‘activation functions’ (traditionally something like a sigmoid function; these days a ReLU) associated with each layer.<p>‘Primitives’ is also sometimes used as a synonym for <i>antiderivatives</i>, but I don’t think that’s what it means here.<p>Edit: it just occurred to me from a comment below that you might have meant to ask what the ‘differentiable’ part means. See <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Differentiable_function" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Differentiable_function</a>.</div><br/><div id="40215568" class="c"><input type="checkbox" id="c-40215568" checked=""/><div class="controls bullet"><span class="by">andoando</span><span>|</span><a href="#40214349">root</a><span>|</span><a href="#40214658">parent</a><span>|</span><a href="#40215221">next</a><span>|</span><label class="collapse" for="c-40215568">[-]</label><label class="expand" for="c-40215568">[8 more]</label></div><br/><div class="children"><div class="content">Is this function composition essentially lambda calculus then?</div><br/><div id="40216613" class="c"><input type="checkbox" id="c-40216613" checked=""/><div class="controls bullet"><span class="by">xanderlewis</span><span>|</span><a href="#40214349">root</a><span>|</span><a href="#40215568">parent</a><span>|</span><a href="#40216384">next</a><span>|</span><label class="collapse" for="c-40216613">[-]</label><label class="expand" for="c-40216613">[6 more]</label></div><br/><div class="children"><div class="content">Composition here just means what it does for any two functions: the value of the ‘composition’ of <i>f</i> and <i>g</i> at <i>x</i> is defined to be <i>f</i> applied to <i>g</i> applied to <i>x</i>. In symbols, its: <i>f∘g := f(g(x))</i> for each <i>x</i> in the domain of <i>f</i>. It  may seem obvious, but the fact that this new thing is also a function (that is, its value is well-defined for every input) is actually a very useful thing indeed and leads to… well, most of mathematics.<p>You can certainly <i>do</i> function composition in lambda calculus: in fact, the act of composition itself is a higher order function (takes functions and returns a function) and you can certainly express it formally with lambda terms and such. It’s not really got anything to do with any particular language or model of computation though.</div><br/><div id="40217050" class="c"><input type="checkbox" id="c-40217050" checked=""/><div class="controls bullet"><span class="by">andoando</span><span>|</span><a href="#40214349">root</a><span>|</span><a href="#40216613">parent</a><span>|</span><a href="#40216384">next</a><span>|</span><label class="collapse" for="c-40217050">[-]</label><label class="expand" for="c-40217050">[5 more]</label></div><br/><div class="children"><div class="content">I didn&#x27;t form my question too well. I understand all that. What I am asking is, are these function compositions equivalent to equivalent&#x2F;similar to functions in lambda calculus?<p>I guess my question, is what are the primitive functions here doing?</div><br/><div id="40217296" class="c"><input type="checkbox" id="c-40217296" checked=""/><div class="controls bullet"><span class="by">xanderlewis</span><span>|</span><a href="#40214349">root</a><span>|</span><a href="#40217050">parent</a><span>|</span><a href="#40216384">next</a><span>|</span><label class="collapse" for="c-40217296">[-]</label><label class="expand" for="c-40217296">[4 more]</label></div><br/><div class="children"><div class="content">Well, yes, to the extent that functions are functions are functions (they’re just associations or mappings or whatever you want to call them).<p>Maybe your question boils down to asking something more general like: what’s the difference between functions <i>to a computer scientist</i> (or a programmer) and functions <i>to a mathematician</i>? That is, are ‘functions’ in C (or lambda calculus), say, the same ‘functions’ we talk about in calculus?<p>The answer to that is: in this case, because these are quite simple functions (sums and products and compositions thereof) they’re the same. In general, they’re a bit different. The difference is basically the difference between functional programming and ‘traditional’ programming. If you have state&#x2F;‘side effects’ of functions, then your function won’t be a function <i>in the sense of mathematics</i>; if the return value of your function depends entirely on the input and doesn’t return different values depending on whatever else is happening in the program, then it will be.<p>Since you’re asking about lambda calculus in particular, the answer is that they’re the same because lambda calculus doesn’t have state. It’s ‘purely functional’ in that sense.<p>&gt;I guess my question, is what are the primitive functions here doing?<p>I’m not really sure what you mean. They’re doing what functions always do. Every computer program is abstractly a (partial) function.<p>Does that help, or have I misunderstood?</div><br/><div id="40217668" class="c"><input type="checkbox" id="c-40217668" checked=""/><div class="controls bullet"><span class="by">andoando</span><span>|</span><a href="#40214349">root</a><span>|</span><a href="#40217296">parent</a><span>|</span><a href="#40216384">next</a><span>|</span><label class="collapse" for="c-40217668">[-]</label><label class="expand" for="c-40217668">[3 more]</label></div><br/><div class="children"><div class="content">So when I think of functions in lambda calculus, I think of the I,S,K functions which when composed can produce functions like &quot;copy&quot;, &quot;add&quot;, &quot;remove&quot;, &quot;if&quot;, etc which then can do different computations like &quot;copy every other symbol if the symbol is true&quot;, &quot;multiply 5 times then add 2&quot;. Since lambda calculus is complete, any computation&#x2F;program can be composed.<p>When I think of functions in a traditional mathematical sense, I think about transformations of numbers. x-&gt;2x, x-&gt;2x^2, etc. I completely understand composition of functions here, ex x-&gt;2(x-&gt;2x)^2, but its unclear how these transformations relate to computation. For a regression problem, I can totally understand how finding the right compositions of functions can lead to a better approximations. So I am wondering, in an LLM architecture, what computations do these functions actually represent? I assume, it has something to do with what path to take through the neural layers. 
I probably just need to take the time to study it deeper.<p>&gt;If you have state&#x2F;‘side effects’ of functions, then your function won’t be a function in the sense of mathematics; if the return value of your function depends entirely on the input and doesn’t return different values depending on whatever else is happening in the program, then it will be.<p>Totally understood from the perspective of functions in say, Java. Though fundamentally I don&#x27;t think there is distinction between functions in computer science and mathematics. The program as a whole is effectively a function. The &quot;global&quot; state is from another reference, just local variables of the encompassing function. If a function is modifying variables outside of the &quot;function block&quot; (in say Java), the &quot;input&quot; to the function isn&#x27;t just the parameters of the function. Imo, this is more of an artifact of implementation of some languages rather than a fundamental difference. Python for example requires declaring global args in the function block. Go one step further and require putting global args into the parameters list and you&#x27;re pretty close to satisfying this.</div><br/><div id="40217897" class="c"><input type="checkbox" id="c-40217897" checked=""/><div class="controls bullet"><span class="by">xanderlewis</span><span>|</span><a href="#40214349">root</a><span>|</span><a href="#40217668">parent</a><span>|</span><a href="#40216384">next</a><span>|</span><label class="collapse" for="c-40217897">[-]</label><label class="expand" for="c-40217897">[2 more]</label></div><br/><div class="children"><div class="content">I think you’re actually massively overthinking it.<p>The state of a neural network is described entirely by its parameters, which usually consist of a long array (well, a matrix, or a tensor, or whatever…) of floating point numbers. What is being optimised when a network is trained is <i>these parameters</i> and nothing else. When you evaluate a neural network on some input (often called performing ‘inference’), that is when the functions we’re talking about are used. You start with the input vector, and you apply all of those functions in order and you get the output vector of the network. The training process also uses these functions, because to train a network you have to perform evaluation repeatedly in between tweaking those parameters to make it better approximate the desired output for each input. Importantly, the functions do not change. They are constant; it’s the parameters that change. The functions are the architecture — not the thing being learned. Essentially what the parameters represent is how likely each neuron is to be activated (have a high value) if others in the previous layer are. So you can think of the parameters as encoding strengths of connections between each pair of neurons in consecutive layers. Thinking about ‘what path to take through the neural layers’ is way too sophisticated — it’s not doing anything like that.<p>&gt; Though fundamentally I don&#x27;t think there is distinction between functions in computer science and mathematics. The program as a whole is effectively a function.<p>You’re pretty much right about that, but there are two important problems&#x2F;nitpicks:<p>(1) We can’t prove (in general) that a given program will halt and evaluate to something (rather than just looping forever) on a given input, so the ‘entire program’ is instead what’s called a <i>partial function</i>. This means that it’s still a function on its domain — but we can’t know what its precise domain is. Given an input, it may or may not produce an output. If it does, though, it’s well defined because it’s a deterministic process.<p>(2) You’re right to qualify that it’s the <i>whole program</i> that is (possibly) a function. If you take a function from some program that depends on some state in that same program, then clearly that function won’t be a proper ‘mathematical’ function. Sure, if you incorporate that extra state as one of your inputs, it might be, but that’s a <i>different function</i>. You have to remember that in mathematics, unlike in programming, a function consists essentially of three pieces of data: a domain, a codomain, and a ‘rule’. If you want to be set-theoretic and formal about it, this rule is just a subset of the cartesian product of its domain and codomain (it’s a set of pairs of the form (x, f(x))). If you change either of these sets, it’s technically a different function and there are good reasons for distinguishing between these. So it’s not right to say that mathematical functions and functions in a computer program are <i>exactly</i> the same.</div><br/><div id="40218456" class="c"><input type="checkbox" id="c-40218456" checked=""/><div class="controls bullet"><span class="by">andoando</span><span>|</span><a href="#40214349">root</a><span>|</span><a href="#40217897">parent</a><span>|</span><a href="#40216384">next</a><span>|</span><label class="collapse" for="c-40218456">[-]</label><label class="expand" for="c-40218456">[1 more]</label></div><br/><div class="children"><div class="content">I appreciate your responses, sorry I hope I don&#x27;t seem like Im arguing for the sake of arguing.<p>&gt;Essentially what the parameters represent is how likely each neuron is to be activated (have a high value) if others in the previous layer are. So you can think of the parameters as encoding strengths of connections between each pair of neurons in consecutive layers. Thinking about ‘what path to take through the neural layers’ is way too sophisticated — it’s not doing anything like that.<p>Im a little confused. The discussion thus far about how neural networks are essentially just compositions of functions, but you are now saying that the function is static, and only the parameters change.<p>But that aside, if these parameters change which neurons are activated, and this activation affects which neurons are activated in the next layer, are these parameters effectively not changing the path taken through the layers?<p>&gt;Sure, if you incorporate that extra state as one of your inputs, it might be, but that’s a different function.<p>So say we have this program
&quot;
let c = 2;
function 3sum (a,b) { 
return a+b + c;
}
let d = 3sum(3,4)&quot;<p>I believe you are saying, if we had constructed this instead as<p>&quot;function(a,b,c) {
return a+b+c
}
let d = 3sum(3,4,2)
&quot;<p>then, this is a different function.<p>Certainly, these are different in a sense, but at a fundamental level, when you compile this all down and run it, there is an equivalency in the <i>transformation</i> that is happening. That is, the two functions equivalently take some input state A (composed of a,b,c) and return the same output state B, while applying the same intermediary steps (add a to b, add c to result of (add to b)). Really, in the first case where c is defined outside the scope of the function block, the interpreter is effectively producing the function 3sum(x,y,c) as it has to at some point, one way or another, inject c into a+b+c.<p>Similarly, I am won&#x27;t argue that the current, formal definitions of functions in mathematics are exactly that of functions as they&#x27;re generally defined in programming.<p>Rather, what I saying is that there is an equivalent way to think and study functions that equally apply to both fields. That is, a function is simply a transformation from A to B, where A and B can be anything, whether that is bits, numbers, or any other construction in any system. The only primitive distinction to make here is whether A and B are the same thing or different.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="40216384" class="c"><input type="checkbox" id="c-40216384" checked=""/><div class="controls bullet"><span class="by">OJFord</span><span>|</span><a href="#40214349">root</a><span>|</span><a href="#40215568">parent</a><span>|</span><a href="#40216613">prev</a><span>|</span><a href="#40215221">next</a><span>|</span><label class="collapse" for="c-40216384">[-]</label><label class="expand" for="c-40216384">[1 more]</label></div><br/><div class="children"><div class="content">Function composition is just f(g(x)), considered as a single function that&#x27;s the composition of f and g; it has the domain of f and the range of g.<p>In lambda calculus terminology it&#x27;s an &#x27;application&#x27; (with a function argument).</div><br/></div></div></div></div></div></div><div id="40215221" class="c"><input type="checkbox" id="c-40215221" checked=""/><div class="controls bullet"><span class="by">esafak</span><span>|</span><a href="#40214349">root</a><span>|</span><a href="#40214569">parent</a><span>|</span><a href="#40214658">prev</a><span>|</span><a href="#40214623">next</a><span>|</span><label class="collapse" for="c-40215221">[-]</label><label class="expand" for="c-40215221">[1 more]</label></div><br/><div class="children"><div class="content">functions, which you can compose to increase their expressiveness, and run gradient descent on to train.<p>The success of deep learning is basically attributable to composable (expressive), differentiable (learnable) functions. The &quot;deep&quot; moniker alludes to the compositionality.</div><br/></div></div><div id="40214623" class="c"><input type="checkbox" id="c-40214623" checked=""/><div class="controls bullet"><span class="by">CobrastanJorji</span><span>|</span><a href="#40214349">root</a><span>|</span><a href="#40214569">parent</a><span>|</span><a href="#40215221">prev</a><span>|</span><a href="#40215206">next</a><span>|</span><label class="collapse" for="c-40214623">[-]</label><label class="expand" for="c-40214623">[3 more]</label></div><br/><div class="children"><div class="content">Continuous mathematical functions which have derivatives.</div><br/></div></div><div id="40215206" class="c"><input type="checkbox" id="c-40215206" checked=""/><div class="controls bullet"><span class="by">dirkc</span><span>|</span><a href="#40214349">root</a><span>|</span><a href="#40214569">parent</a><span>|</span><a href="#40214623">prev</a><span>|</span><a href="#40215168">next</a><span>|</span><label class="collapse" for="c-40215206">[-]</label><label class="expand" for="c-40215206">[1 more]</label></div><br/><div class="children"><div class="content">When I did &quot;AI&quot; it would have meant the sigmoid function, these days it&#x27;s something like ReLU.</div><br/></div></div></div></div><div id="40215168" class="c"><input type="checkbox" id="c-40215168" checked=""/><div class="controls bullet"><span class="by">SkyBelow</span><span>|</span><a href="#40214349">parent</a><span>|</span><a href="#40214569">prev</a><span>|</span><a href="#40215053">next</a><span>|</span><label class="collapse" for="c-40215168">[-]</label><label class="expand" for="c-40215168">[3 more]</label></div><br/><div class="children"><div class="content">Before the recent AI boom, I was mystified by the possibility of AI and emulating humans (in no small part thanks to works of fiction showing AI powered androids).  Then I created and trained some neural networks.  Smaller ones, doing much of nothing special.  That was enough to break the mysticism.  To realize it was just multiplying matrices.  Training them was a bit more advanced, but still applied mathematics.<p>Only recently have I begun to appreciate that the simplicity of the operation, applied to a large enough matrices, may still capture enough of the nature of intelligence and sentience.  In the end we can be broken down into (relatively) simple chemical reactions, and it is the massive scale of these reactions that create real intelligence and sentience.</div><br/><div id="40217287" class="c"><input type="checkbox" id="c-40217287" checked=""/><div class="controls bullet"><span class="by">naasking</span><span>|</span><a href="#40214349">root</a><span>|</span><a href="#40215168">parent</a><span>|</span><a href="#40217327">next</a><span>|</span><label class="collapse" for="c-40217287">[-]</label><label class="expand" for="c-40217287">[1 more]</label></div><br/><div class="children"><div class="content">Exactly, the people who are derisive of those who consider ML models to exhibit glimmers of true intelligence because it&#x27;s only matrix multiplications always amuse me. It&#x27;s like they don&#x27;t even realize the contradiction in holding the position that seemingly complex and  intelligent outward behaviour should not be used as an indication of actual complexity and intelligence.</div><br/></div></div><div id="40217327" class="c"><input type="checkbox" id="c-40217327" checked=""/><div class="controls bullet"><span class="by">mistermann</span><span>|</span><a href="#40214349">root</a><span>|</span><a href="#40215168">parent</a><span>|</span><a href="#40217287">prev</a><span>|</span><a href="#40215053">next</a><span>|</span><label class="collapse" for="c-40217327">[-]</label><label class="expand" for="c-40217327">[1 more]</label></div><br/><div class="children"><div class="content">Next step, in case you get bored: <i>why</i> (in fact, <i>not a minor distinction</i>) does such a simple approach work so well?</div><br/></div></div></div></div></div></div><div id="40215053" class="c"><input type="checkbox" id="c-40215053" checked=""/><div class="controls bullet"><span class="by">p1esk</span><span>|</span><a href="#40214349">prev</a><span>|</span><a href="#40215080">next</a><span>|</span><label class="collapse" for="c-40215053">[-]</label><label class="expand" for="c-40215053">[3 more]</label></div><br/><div class="children"><div class="content">And then you learn about binary or ternary networks where gradients don’t really exist anywhere, and you start to wonder about the importance of this differentiability.</div><br/><div id="40216262" class="c"><input type="checkbox" id="c-40216262" checked=""/><div class="controls bullet"><span class="by">ubj</span><span>|</span><a href="#40215053">parent</a><span>|</span><a href="#40215343">next</a><span>|</span><label class="collapse" for="c-40216262">[-]</label><label class="expand" for="c-40216262">[1 more]</label></div><br/><div class="children"><div class="content">...And then you start learning about generalizations of the notion of &quot;gradient&quot; to scenarios where the classical gradient doesn&#x27;t exist :)</div><br/></div></div><div id="40215343" class="c"><input type="checkbox" id="c-40215343" checked=""/><div class="controls bullet"><span class="by">whimsicalism</span><span>|</span><a href="#40215053">parent</a><span>|</span><a href="#40216262">prev</a><span>|</span><a href="#40215080">next</a><span>|</span><label class="collapse" for="c-40215343">[-]</label><label class="expand" for="c-40215343">[1 more]</label></div><br/><div class="children"><div class="content">binary networks don&#x27;t really work well unless you do a relaxation first</div><br/></div></div></div></div><div id="40215080" class="c"><input type="checkbox" id="c-40215080" checked=""/><div class="controls bullet"><span class="by">gfaure</span><span>|</span><a href="#40215053">prev</a><span>|</span><a href="#40213790">next</a><span>|</span><label class="collapse" for="c-40215080">[-]</label><label class="expand" for="c-40215080">[1 more]</label></div><br/><div class="children"><div class="content">In the literature, they&#x27;re usually called convolutional layers (I think you can pretty much search and replace all uses of &quot;convolutive&quot; in the text).</div><br/></div></div><div id="40213790" class="c"><input type="checkbox" id="c-40213790" checked=""/><div class="controls bullet"><span class="by">glonq</span><span>|</span><a href="#40215080">prev</a><span>|</span><a href="#40214712">next</a><span>|</span><label class="collapse" for="c-40213790">[-]</label><label class="expand" for="c-40213790">[4 more]</label></div><br/><div class="children"><div class="content">I wonder if the usage of Alice &amp; Wonderland takes inspiration from Douglas Hofstadter&#x27;s &quot;Gödel, Escher, Bach: an Eternal Golden Braid&quot; ?</div><br/><div id="40214991" class="c"><input type="checkbox" id="c-40214991" checked=""/><div class="controls bullet"><span class="by">abdullahkhalids</span><span>|</span><a href="#40213790">parent</a><span>|</span><a href="#40214471">next</a><span>|</span><label class="collapse" for="c-40214991">[-]</label><label class="expand" for="c-40214991">[1 more]</label></div><br/><div class="children"><div class="content">Lewis Carrol&#x27;s Alice in Wonderland features a number of logical and mathematical puzzles [1]<p>He also wrote What the Tortoise Said to Achilles (1895) in which the paradoxes of Zeno are discussed.<p>So it&#x27;s more correct to say that GEB and this article are originally inspired by Lewis Carrol&#x27;s work.<p>[1] I wrote a short article for my university magazine a long time ago. Some interesting references at the end <a href="https:&#x2F;&#x2F;abd.tiddlyspot.com&#x2F;#%5B%5BMathematical%20Adventures%20in%20Wonderland%5D%5D" rel="nofollow">https:&#x2F;&#x2F;abd.tiddlyspot.com&#x2F;#%5B%5BMathematical%20Adventures%...</a></div><br/></div></div><div id="40214471" class="c"><input type="checkbox" id="c-40214471" checked=""/><div class="controls bullet"><span class="by">iainmerrick</span><span>|</span><a href="#40213790">parent</a><span>|</span><a href="#40214991">prev</a><span>|</span><a href="#40214647">next</a><span>|</span><label class="collapse" for="c-40214471">[-]</label><label class="expand" for="c-40214471">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a pretty common trope, especially for math-related books, e.g. Alex Bellos&#x27; &quot;Alex&#x27;s Adventures in Numberland&quot;.</div><br/></div></div><div id="40214647" class="c"><input type="checkbox" id="c-40214647" checked=""/><div class="controls bullet"><span class="by">devnonymous</span><span>|</span><a href="#40213790">parent</a><span>|</span><a href="#40214471">prev</a><span>|</span><a href="#40214712">next</a><span>|</span><label class="collapse" for="c-40214647">[-]</label><label class="expand" for="c-40214647">[1 more]</label></div><br/><div class="children"><div class="content">No, I think the inspiration is more direct <a href="https:&#x2F;&#x2F;duckduckgo.com&#x2F;?q=lewis+carroll+alice+in+wonderland+math" rel="nofollow">https:&#x2F;&#x2F;duckduckgo.com&#x2F;?q=lewis+carroll+alice+in+wonderland+...</a></div><br/></div></div></div></div><div id="40214712" class="c"><input type="checkbox" id="c-40214712" checked=""/><div class="controls bullet"><span class="by">Eduard</span><span>|</span><a href="#40213790">prev</a><span>|</span><a href="#40213461">next</a><span>|</span><label class="collapse" for="c-40214712">[-]</label><label class="expand" for="c-40214712">[2 more]</label></div><br/><div class="children"><div class="content">better remove all the Disney-based Alice in Wonderland character intellectual property from the book.</div><br/><div id="40217683" class="c"><input type="checkbox" id="c-40217683" checked=""/><div class="controls bullet"><span class="by">astrodust</span><span>|</span><a href="#40214712">parent</a><span>|</span><a href="#40213461">next</a><span>|</span><label class="collapse" for="c-40217683">[-]</label><label class="expand" for="c-40217683">[1 more]</label></div><br/><div class="children"><div class="content">I was just thinking that&#x27;s &quot;cease and desist&quot; bait right there.</div><br/></div></div></div></div></div></div></div></div></div></body></html>