<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1723626078522" as="style"/><link rel="stylesheet" href="styles.css?v=1723626078522"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a>Launch HN: Trellis (YC W24) – AI-powered workflows for unstructured data</a> </div><div class="subtext"><span>macklinkachorn</span> | <span>77 comments</span></div><br/><div><div id="41244088" class="c"><input type="checkbox" id="c-41244088" checked=""/><div class="controls bullet"><span class="by">blotterfyi</span><span>|</span><a href="#41241137">next</a><span>|</span><label class="collapse" for="c-41244088">[-]</label><label class="expand" for="c-41244088">[1 more]</label></div><br/><div class="children"><div class="content">Just want to say, this is pretty cool.</div><br/></div></div><div id="41241137" class="c"><input type="checkbox" id="c-41241137" checked=""/><div class="controls bullet"><span class="by">john_horton</span><span>|</span><a href="#41244088">prev</a><span>|</span><a href="#41240447">next</a><span>|</span><label class="collapse" for="c-41241137">[-]</label><label class="expand" for="c-41241137">[1 more]</label></div><br/><div class="children"><div class="content">Very cool - I&#x27;ve been working on an open source python package that lets you do some similar things (<a href="https:&#x2F;&#x2F;github.com&#x2F;expectedparrot&#x2F;edsl">https:&#x2F;&#x2F;github.com&#x2F;expectedparrot&#x2F;edsl</a>).<p>Here&#x27;s an example of the Enron email demo using the edsl syntax&#x2F;package &amp; a few different LLMs: 
<a href="https:&#x2F;&#x2F;www.expectedparrot.com&#x2F;content&#x2F;6607caa1-efc5-439f-8530-8fcc5625fdd7" rel="nofollow">https:&#x2F;&#x2F;www.expectedparrot.com&#x2F;content&#x2F;6607caa1-efc5-439f-85...</a></div><br/></div></div><div id="41240447" class="c"><input type="checkbox" id="c-41240447" checked=""/><div class="controls bullet"><span class="by">makk</span><span>|</span><a href="#41241137">prev</a><span>|</span><a href="#41243239">next</a><span>|</span><label class="collapse" for="c-41240447">[-]</label><label class="expand" for="c-41240447">[4 more]</label></div><br/><div class="children"><div class="content">&gt; a major commercial bank I work with couldn’t improve credit risk models because critical data was stuck in PDFs and emails.<p>Great use case! Worked on exactly this a decade ago. It was Hard™ then. Could only make so much progress. Getting this right is a huge value unlock. Congrats!</div><br/><div id="41243978" class="c"><input type="checkbox" id="c-41243978" checked=""/><div class="controls bullet"><span class="by">ace32229</span><span>|</span><a href="#41240447">parent</a><span>|</span><a href="#41243143">next</a><span>|</span><label class="collapse" for="c-41243978">[-]</label><label class="expand" for="c-41243978">[1 more]</label></div><br/><div class="children"><div class="content">I have just been working through the same problem (though just PDFs). Google DocAI helped enormously after a bit of initial input.</div><br/></div></div><div id="41243143" class="c"><input type="checkbox" id="c-41243143" checked=""/><div class="controls bullet"><span class="by">harryf</span><span>|</span><a href="#41240447">parent</a><span>|</span><a href="#41243978">prev</a><span>|</span><a href="#41240846">next</a><span>|</span><label class="collapse" for="c-41243143">[-]</label><label class="expand" for="c-41243143">[1 more]</label></div><br/><div class="children"><div class="content">Make sure you have an on-premise option for this type of customer. I&#x27;ve worked at two software companies in Europe with tangentially similar products related to document analysis. On premise is a key requirement.<p>Even though it&#x27;s 2024, banks, financial institutions like insurance companies etc. tend to be _very_ cautious with valuable documents involving customers. There are also regional regulations that prevent things like patient data being shared with _any_ 3rd parties. Even one of the big 4 oil companies that I&#x27;ve dealt with as prospective customer - very strict rules requiring on premise solutions.<p>The good news is many are using things like Kubernetes and OpenShift internally, so it should be possible to port what you do on AWS to on-premise.</div><br/></div></div><div id="41240846" class="c"><input type="checkbox" id="c-41240846" checked=""/><div class="controls bullet"><span class="by">macklinkachorn</span><span>|</span><a href="#41240447">parent</a><span>|</span><a href="#41243143">prev</a><span>|</span><a href="#41243239">next</a><span>|</span><label class="collapse" for="c-41240846">[-]</label><label class="expand" for="c-41240846">[1 more]</label></div><br/><div class="children"><div class="content">Great to hear that you worked saw similar use cases. Doing this before LLMs seem like a big challenge.</div><br/></div></div></div></div><div id="41243239" class="c"><input type="checkbox" id="c-41243239" checked=""/><div class="controls bullet"><span class="by">iudexgundyr</span><span>|</span><a href="#41240447">prev</a><span>|</span><a href="#41236767">next</a><span>|</span><label class="collapse" for="c-41243239">[-]</label><label class="expand" for="c-41243239">[1 more]</label></div><br/><div class="children"><div class="content">Interesting! One quick question, how did you validate your data and ensure its correctness, since the ground truth is unstructured?</div><br/></div></div><div id="41236767" class="c"><input type="checkbox" id="c-41236767" checked=""/><div class="controls bullet"><span class="by">icey</span><span>|</span><a href="#41243239">prev</a><span>|</span><a href="#41240023">next</a><span>|</span><label class="collapse" for="c-41236767">[-]</label><label class="expand" for="c-41236767">[2 more]</label></div><br/><div class="children"><div class="content">Great idea. I used to work at Instabase, which you probably compete with. The better you are at dealing with dodgy PDFs and document scans, the more valuable this will be to big banks, shipping companies, etc.</div><br/><div id="41237405" class="c"><input type="checkbox" id="c-41237405" checked=""/><div class="controls bullet"><span class="by">macklinkachorn</span><span>|</span><a href="#41236767">parent</a><span>|</span><a href="#41240023">next</a><span>|</span><label class="collapse" for="c-41237405">[-]</label><label class="expand" for="c-41237405">[1 more]</label></div><br/><div class="children"><div class="content">Thanks! Always surprised to see how many dodgy PDFs and scans there is in enterprises.</div><br/></div></div></div></div><div id="41240023" class="c"><input type="checkbox" id="c-41240023" checked=""/><div class="controls bullet"><span class="by">bustodisgusto</span><span>|</span><a href="#41236767">prev</a><span>|</span><a href="#41237490">next</a><span>|</span><label class="collapse" for="c-41240023">[-]</label><label class="expand" for="c-41240023">[2 more]</label></div><br/><div class="children"><div class="content">We built something tangentially related at SoundTrace.<p>Basically when we onboard a new client they dump all their audiograms on us as PDFs.<p>The data needs extraction needs to be perfect because the tables values are used to detect hearing loss over time.<p>We settled on a pipeline that looks roughly like<p>PDF -&gt; gpto pre filter phase -&gt; OCR to extract text tables and forms -&gt; things branch out here<p>We do a direct parse of forms and text through an LLM<p>Extract audiogram graphs and send them to a foundation convnet<p>Attempt to parse tables programmatically<p>-&gt; an audiogram might have 3 separate places where the values are so we pass the results of all three of these routes through Claude sonnet and if they match they get auto approved. If they don’t, they get flagged for manual review.<p>All in all it’s been a journey but the accuracy is near 100 percent. These tools are incredible</div><br/><div id="41240878" class="c"><input type="checkbox" id="c-41240878" checked=""/><div class="controls bullet"><span class="by">macklinkachorn</span><span>|</span><a href="#41240023">parent</a><span>|</span><a href="#41237490">next</a><span>|</span><label class="collapse" for="c-41240878">[-]</label><label class="expand" for="c-41240878">[1 more]</label></div><br/><div class="children"><div class="content">Super cool! This aligns with our experiences. These tools are great and can get to near 100% of accuracy but it&#x27;s quite a lot of work on the Eng side to get it there reliably.</div><br/></div></div></div></div><div id="41237490" class="c"><input type="checkbox" id="c-41237490" checked=""/><div class="controls bullet"><span class="by">rahimnathwani</span><span>|</span><a href="#41240023">prev</a><span>|</span><a href="#41236694">next</a><span>|</span><label class="collapse" for="c-41237490">[-]</label><label class="expand" for="c-41237490">[7 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve had do some of this recently, as a one-off, to extract the same fields from thousands of scanned documents.<p>I used OpenAI&#x27;s function calling (via Langchain&#x27;s <a href="https:&#x2F;&#x2F;python.langchain.com&#x2F;v0.1&#x2F;docs&#x2F;modules&#x2F;model_io&#x2F;chat&#x2F;structured_output&#x2F;" rel="nofollow">https:&#x2F;&#x2F;python.langchain.com&#x2F;v0.1&#x2F;docs&#x2F;modules&#x2F;model_io&#x2F;chat...</a> API).<p>Some of the challenges I had:<p>1. poor recall for some fields, even with a wide variety of input document formats<p>2. needing to experiment with the json schema (particularly field descriptions) to get the best info out, and ignore superfluous information<p>3. for each long document, deciding whether to send the whole document in the context, or only the most relevant chunks (using traditional text search and semantic vector search)<p>4. poor quality OCR<p>From the demo video, it seems like your main innovation is allowing a non-technical user to do #2 in an iterative fashion. Have I understood correctly?</div><br/><div id="41237672" class="c"><input type="checkbox" id="c-41237672" checked=""/><div class="controls bullet"><span class="by">macklinkachorn</span><span>|</span><a href="#41237490">parent</a><span>|</span><a href="#41239045">next</a><span>|</span><label class="collapse" for="c-41237672">[-]</label><label class="expand" for="c-41237672">[1 more]</label></div><br/><div class="children"><div class="content">We face similar challenges you listed and handle all of the above.
1. Out of the box OCR doesn&#x27;t perform as well for complex documents (with tables, images, etc.). We use vision model to help process that documents. 
2. Recall (for longer documents) and accuracy are also a major problem. We built in validation systems and references to help users validate the results. 
3. Maintain this systems in production, integrate with the data sources and refresh when new data comes in are quite annoying. We manage that for the end users. 
4. For non-technical users, we allow them to iterate through different business logic and have a one unify place to manage data workflows.</div><br/></div></div><div id="41239045" class="c"><input type="checkbox" id="c-41239045" checked=""/><div class="controls bullet"><span class="by">efriis</span><span>|</span><a href="#41237490">parent</a><span>|</span><a href="#41237672">prev</a><span>|</span><a href="#41237818">next</a><span>|</span><label class="collapse" for="c-41239045">[-]</label><label class="expand" for="c-41239045">[3 more]</label></div><br/><div class="children"><div class="content">Would recommend using the updated guide here! That link is from the v0.1 docs. <a href="https:&#x2F;&#x2F;python.langchain.com&#x2F;v0.2&#x2F;docs&#x2F;how_to&#x2F;structured_output&#x2F;" rel="nofollow">https:&#x2F;&#x2F;python.langchain.com&#x2F;v0.2&#x2F;docs&#x2F;how_to&#x2F;structured_out...</a><p>OOC which openai model were you using? Would recommend trying 4o as well as Anthropic claude 3.5 sonnet if ya haven&#x27;t played around with those yet</div><br/><div id="41239169" class="c"><input type="checkbox" id="c-41239169" checked=""/><div class="controls bullet"><span class="by">rahimnathwani</span><span>|</span><a href="#41237490">root</a><span>|</span><a href="#41239045">parent</a><span>|</span><a href="#41237818">next</a><span>|</span><label class="collapse" for="c-41239169">[-]</label><label class="expand" for="c-41239169">[2 more]</label></div><br/><div class="children"><div class="content">Thanks.<p>I was using gpt-3.5-turbo-0125. It was before the recent pricing change.<p>But I have a bunch of updates to make to the json schema, so will re-run everything with gpt-4o-mini.<p>Sonnet seems a lot more expensive, but I&#x27;ll &#x27;upgrade&#x27; if the schema changes don&#x27;t get sufficiently good results.</div><br/><div id="41239223" class="c"><input type="checkbox" id="c-41239223" checked=""/><div class="controls bullet"><span class="by">efriis</span><span>|</span><a href="#41237490">root</a><span>|</span><a href="#41239169">parent</a><span>|</span><a href="#41237818">next</a><span>|</span><label class="collapse" for="c-41239223">[-]</label><label class="expand" for="c-41239223">[1 more]</label></div><br/><div class="children"><div class="content">Nice. Could also give haiku a try!</div><br/></div></div></div></div></div></div><div id="41237818" class="c"><input type="checkbox" id="c-41237818" checked=""/><div class="controls bullet"><span class="by">mistursinistur</span><span>|</span><a href="#41237490">parent</a><span>|</span><a href="#41239045">prev</a><span>|</span><a href="#41236694">next</a><span>|</span><label class="collapse" for="c-41237818">[-]</label><label class="expand" for="c-41237818">[2 more]</label></div><br/><div class="children"><div class="content">FWIW I&#x27;ve seen noticeably better results on (1) and (4) extracting JSON from images via Claude, although (2) and (3) still take effort.</div><br/><div id="41237913" class="c"><input type="checkbox" id="c-41237913" checked=""/><div class="controls bullet"><span class="by">rahimnathwani</span><span>|</span><a href="#41237490">root</a><span>|</span><a href="#41237818">parent</a><span>|</span><a href="#41236694">next</a><span>|</span><label class="collapse" for="c-41237913">[-]</label><label class="expand" for="c-41237913">[1 more]</label></div><br/><div class="children"><div class="content">Thanks for sharing.<p>I&#x27;m curious about what types of source documents you tried, and whether you ever suffer from hallucinations?</div><br/></div></div></div></div></div></div><div id="41236694" class="c"><input type="checkbox" id="c-41236694" checked=""/><div class="controls bullet"><span class="by">cs702</span><span>|</span><a href="#41237490">prev</a><span>|</span><a href="#41237398">next</a><span>|</span><label class="collapse" for="c-41236694">[-]</label><label class="expand" for="c-41236694">[3 more]</label></div><br/><div class="children"><div class="content">Congratulations on launching!<p>Trellis looks <i>amazing</i>... but only if it works well enough, i.e., if the rate of edge cases that trip up the service consistently remains close to 0%.<p>Every organization in the world needs and wants this, like, right now.<p>If you make it work well enough, you&#x27;ll have customers knocking on your door around the clock.<p>I&#x27;m going to take a look. Like others here, I&#x27;m rooting for you guys to succeed.</div><br/><div id="41236726" class="c"><input type="checkbox" id="c-41236726" checked=""/><div class="controls bullet"><span class="by">macklinkachorn</span><span>|</span><a href="#41236694">parent</a><span>|</span><a href="#41237398">next</a><span>|</span><label class="collapse" for="c-41236726">[-]</label><label class="expand" for="c-41236726">[2 more]</label></div><br/><div class="children"><div class="content">Maintaining the right level of accuracy across different domain is quite hard and something we spend a lot of time on. The accuracy bar tends to be quite high for financial services so we&#x27;re adding some validation steps and checking to make sure any errors get caught beforehand.</div><br/><div id="41236787" class="c"><input type="checkbox" id="c-41236787" checked=""/><div class="controls bullet"><span class="by">cs702</span><span>|</span><a href="#41236694">root</a><span>|</span><a href="#41236726">parent</a><span>|</span><a href="#41237398">next</a><span>|</span><label class="collapse" for="c-41236787">[-]</label><label class="expand" for="c-41236787">[1 more]</label></div><br/><div class="children"><div class="content">Thank you. Yes, I&#x27;m not at all surprised to hear that.<p>The biggest challenge I see for you guys is that your best customer prospects, i.e., those organizations which need this most urgently and are willing to pay the most for it are the ones already spending gobs of money to do it with human labor because mistakes are too costly, so they need at least human-level performance.<p>As you know, current-generation LLMs&#x2F;LMMs are not yet reliable enough to do it on their own. They need all the help they can get -- sanity data checks, post-processing logic, ensembles of models, organization into teams of agents, etc., etc. -- I&#x27;m sure you&#x27;re looking at all options.<p>Absent human beings in the loop, you&#x27;re at the frontier of LLM&#x2F;LMM research.<p>If you pull it off, you&#x27;ll make megabucks.</div><br/></div></div></div></div></div></div><div id="41237398" class="c"><input type="checkbox" id="c-41237398" checked=""/><div class="controls bullet"><span class="by">shcheklein</span><span>|</span><a href="#41236694">prev</a><span>|</span><a href="#41236508">next</a><span>|</span><label class="collapse" for="c-41237398">[-]</label><label class="expand" for="c-41237398">[2 more]</label></div><br/><div class="children"><div class="content">Hey, congrats! Are you competing &#x2F; is there some overlap &#x2F; what are the key differences with Roe AI (YC W24) - roe.ai (just launched recently on HN <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=41202694">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=41202694</a> as well).</div><br/><div id="41238159" class="c"><input type="checkbox" id="c-41238159" checked=""/><div class="controls bullet"><span class="by">jackylin</span><span>|</span><a href="#41237398">parent</a><span>|</span><a href="#41236508">next</a><span>|</span><label class="collapse" for="c-41238159">[-]</label><label class="expand" for="c-41238159">[1 more]</label></div><br/><div class="children"><div class="content">Jason and Richard from Roe AI are amazing people! We were in the same YC batch and section. Excited for what Roe AI is building and their focus on building a new type of data warehouse.<p>At Trellis, we&#x27;re focused on building the AI tool that supports document-heavy workflows (this includes building the dashboard for teams to review, update, and approved results that were flagged, reading and writing directly to your system of record like Salesforce, and allowing customers to create their own validations around the documents).</div><br/></div></div></div></div><div id="41236508" class="c"><input type="checkbox" id="c-41236508" checked=""/><div class="controls bullet"><span class="by">atak1</span><span>|</span><a href="#41237398">prev</a><span>|</span><a href="#41237225">next</a><span>|</span><label class="collapse" for="c-41236508">[-]</label><label class="expand" for="c-41236508">[2 more]</label></div><br/><div class="children"><div class="content">Congrats on launching! Wish we had this years ago at Flexport for our ops &#x2F; science teams. Traditional ML approaches are expensive, and the idea of defining your final shape of data and automating the ETL process is the best abstraction out there.<p>Rooting for you guys!</div><br/><div id="41236581" class="c"><input type="checkbox" id="c-41236581" checked=""/><div class="controls bullet"><span class="by">macklinkachorn</span><span>|</span><a href="#41236508">parent</a><span>|</span><a href="#41237225">next</a><span>|</span><label class="collapse" for="c-41236581">[-]</label><label class="expand" for="c-41236581">[1 more]</label></div><br/><div class="children"><div class="content">Glad to see people experiencing similar problems! We previously spend way too much time building and maintaining document processing pipeline that doesn&#x27;t really scale.</div><br/></div></div></div></div><div id="41237225" class="c"><input type="checkbox" id="c-41237225" checked=""/><div class="controls bullet"><span class="by">artembugara</span><span>|</span><a href="#41236508">prev</a><span>|</span><a href="#41237428">next</a><span>|</span><label class="collapse" for="c-41237225">[-]</label><label class="expand" for="c-41237225">[5 more]</label></div><br/><div class="children"><div class="content">Hey folks. Congrats on the launch.<p>Everyone here knows that it&#x27;s a really big problem that no one has nailed yet.<p>My 2 cents:<p>1. It took us (newscatcherapi.com) three years to realize that customers with the biggest problems and with the biggest budgets are the most underserved. The reason is that everyone is building an infinitely scalable AI&#x2F;LLM&#x2F;whatever to gain insights from news.<p>In reality, this NLP&#x2F;AI works quite OK out of the box but is not ideal for everyone at the same time. So we decided to do Palantir-like onboarding&#x2F;integration for each customer. We charge 25x more, but customers have a perfect tailor-made solution and a high ROI.<p>I see you already do the same! &quot;99%+ accuracy with fine-tuning and human-in-the-loop&quot; is what worked great for us. This way, your competitor is a human on payroll (very expensive) and not AWS Tesseract.<p>Going from 95% to 99% is just a fractional improvement, but it can be &quot;not good enough&quot; to a &quot;great solution&quot; change that can be charged differently.<p>2. &quot;AI-powered workflow for unstructured data&quot; what does it even mean? Why don&#x27;t you say &quot;99%+ accuracy extraction&quot;? It&#x27;s 2024, everyone is using AI, and everyone knows you need 2 hours to start applying AI from 0. So don&#x27;t lower my expectations.</div><br/><div id="41237378" class="c"><input type="checkbox" id="c-41237378" checked=""/><div class="controls bullet"><span class="by">macklinkachorn</span><span>|</span><a href="#41237225">parent</a><span>|</span><a href="#41237973">next</a><span>|</span><label class="collapse" for="c-41237378">[-]</label><label class="expand" for="c-41237378">[2 more]</label></div><br/><div class="children"><div class="content">Appreciate the note.<p>1. I completely agree. Last-mile accuracy is crucial for enterprise buyers, and the challenge isn&#x27;t just the AI. It&#x27;s about mapping their business logic and workflows to the product in a way that demonstrates fast time to value.<p>2. Thanks for the feedback. We&#x27;re still refining the messaging and don&#x27;t want to be overly focused on just the extraction aspect. Do you think positioning it as ETL for unstructured data or high-accuracy extraction for enterprises might work better?&quot;</div><br/><div id="41237474" class="c"><input type="checkbox" id="c-41237474" checked=""/><div class="controls bullet"><span class="by">artembugara</span><span>|</span><a href="#41237225">root</a><span>|</span><a href="#41237378">parent</a><span>|</span><a href="#41237973">next</a><span>|</span><label class="collapse" for="c-41237474">[-]</label><label class="expand" for="c-41237474">[1 more]</label></div><br/><div class="children"><div class="content">2. I think that &quot;AI&quot; and &quot;unstructured data&quot; sounded &quot;cool&quot; 5 years ago :)<p>I&#x27;d be mindblown if you said, &quot;We turn PDFs into structured data with 99.99% accuracy. Here is how:&quot;<p>And then tell me about fine-tuning human-in-the-loop stuff.</div><br/></div></div></div></div><div id="41237973" class="c"><input type="checkbox" id="c-41237973" checked=""/><div class="controls bullet"><span class="by">EarlyOom</span><span>|</span><a href="#41237225">parent</a><span>|</span><a href="#41237378">prev</a><span>|</span><a href="#41237366">next</a><span>|</span><label class="collapse" for="c-41237973">[-]</label><label class="expand" for="c-41237973">[1 more]</label></div><br/><div class="children"><div class="content">We&#x27;ve been building something similar with <a href="https:&#x2F;&#x2F;vlm.run&#x2F;" rel="nofollow">https:&#x2F;&#x2F;vlm.run&#x2F;</a>: we&#x27;re starting out with documents, but feel like the real killer app will involve agentic workflows grounded in visual inputs like websites. The challenge is that even the best foundation models still struggle a lot with hallucination and rate limits, which means that you have to chain together both OCR and LLMs to get a good result. Platforms like Tesseract work fine for simple, dense documents, but don&#x27;t help with more complex visual media like charts and graphs. LLMs are great, but even the release of JSON schemas by OpenAI hasn&#x27;t really fixed &#x27;making things up&#x27; or &#x27;giving up halfway through&#x27;.</div><br/></div></div></div></div><div id="41237428" class="c"><input type="checkbox" id="c-41237428" checked=""/><div class="controls bullet"><span class="by">skeptrune</span><span>|</span><a href="#41237225">prev</a><span>|</span><a href="#41238002">next</a><span>|</span><label class="collapse" for="c-41237428">[-]</label><label class="expand" for="c-41237428">[2 more]</label></div><br/><div class="children"><div class="content">Both fulltext (BM25 or SPLADE) and dense vector search have issues with documents of different lengths. Part of what makes recursive sentence splitting work so well are its length normalization properties.<p>Filters are a really important feature downstream of that which this system can provide.<p>We have also worked with the Enron corpus for demos and fast, reliable ETL for a set of documents that large is more difficult than it seems and a commendable problem to solve.<p>Exciting stuff!</div><br/><div id="41237738" class="c"><input type="checkbox" id="c-41237738" checked=""/><div class="controls bullet"><span class="by">macklinkachorn</span><span>|</span><a href="#41237428">parent</a><span>|</span><a href="#41238002">next</a><span>|</span><label class="collapse" for="c-41237738">[-]</label><label class="expand" for="c-41237738">[1 more]</label></div><br/><div class="children"><div class="content">Thanks! We also start to see the patterns where search systems are being improved with filters and hierarchy level metadata. Another use case that people use Trellis for is ingesting data into their downstream LLMs applications.</div><br/></div></div></div></div><div id="41238002" class="c"><input type="checkbox" id="c-41238002" checked=""/><div class="controls bullet"><span class="by">macklinkachorn</span><span>|</span><a href="#41237428">prev</a><span>|</span><a href="#41242209">next</a><span>|</span><label class="collapse" for="c-41238002">[-]</label><label class="expand" for="c-41238002">[1 more]</label></div><br/><div class="children"><div class="content">Getting a lot of love from HN so the demo site and data processing might slow down by quite a bit. We&#x27;re fixing it right now!</div><br/></div></div><div id="41242209" class="c"><input type="checkbox" id="c-41242209" checked=""/><div class="controls bullet"><span class="by">xkq</span><span>|</span><a href="#41238002">prev</a><span>|</span><a href="#41237794">next</a><span>|</span><label class="collapse" for="c-41242209">[-]</label><label class="expand" for="c-41242209">[2 more]</label></div><br/><div class="children"><div class="content">Super sick. I’m building this at work rn. Definitely a cool technical problem. Good luck!</div><br/><div id="41242290" class="c"><input type="checkbox" id="c-41242290" checked=""/><div class="controls bullet"><span class="by">macklinkachorn</span><span>|</span><a href="#41242209">parent</a><span>|</span><a href="#41237794">next</a><span>|</span><label class="collapse" for="c-41242290">[-]</label><label class="expand" for="c-41242290">[1 more]</label></div><br/><div class="children"><div class="content">That’s awesome. Curious to hear your use cases and also happy to share notes on what we see work well. Feel free to ping me (email in Bio)</div><br/></div></div></div></div><div id="41237794" class="c"><input type="checkbox" id="c-41237794" checked=""/><div class="controls bullet"><span class="by">aiden3</span><span>|</span><a href="#41242209">prev</a><span>|</span><a href="#41240335">next</a><span>|</span><label class="collapse" for="c-41237794">[-]</label><label class="expand" for="c-41237794">[3 more]</label></div><br/><div class="children"><div class="content">What about a pdf with many separate datapoints on it?<p>For instance, I have 100 pdfs, each with 10-100 individual products listed (in different formats).<p>I want to create a single table with one row per product appearing in any of the PDFs, with various details like price, product description, etc.,<p>From what I can tell from the demo, it seems like 1 file = 1 row in Trellis?</div><br/><div id="41237865" class="c"><input type="checkbox" id="c-41237865" checked=""/><div class="controls bullet"><span class="by">macklinkachorn</span><span>|</span><a href="#41237794">parent</a><span>|</span><a href="#41238395">next</a><span>|</span><label class="collapse" for="c-41237865">[-]</label><label class="expand" for="c-41237865">[1 more]</label></div><br/><div class="children"><div class="content">Good question and we have seen this extraction workflow a lot in financial services. We just added table mode to the product (select table in transformation parameters) where we extract table structure in the documents that match that schema. So 1 file map to N rows where N is all the row in the table.</div><br/></div></div><div id="41238395" class="c"><input type="checkbox" id="c-41238395" checked=""/><div class="controls bullet"><span class="by">atak1</span><span>|</span><a href="#41237794">parent</a><span>|</span><a href="#41237865">prev</a><span>|</span><a href="#41240335">next</a><span>|</span><label class="collapse" for="c-41238395">[-]</label><label class="expand" for="c-41238395">[1 more]</label></div><br/><div class="children"><div class="content">Just did an extraction and table mode targets this rly well :)</div><br/></div></div></div></div><div id="41240335" class="c"><input type="checkbox" id="c-41240335" checked=""/><div class="controls bullet"><span class="by">usehexus</span><span>|</span><a href="#41237794">prev</a><span>|</span><a href="#41237219">next</a><span>|</span><label class="collapse" for="c-41240335">[-]</label><label class="expand" for="c-41240335">[1 more]</label></div><br/><div class="children"><div class="content">Congrats on the launch! This is a great idea! Many usecases.</div><br/></div></div><div id="41237219" class="c"><input type="checkbox" id="c-41237219" checked=""/><div class="controls bullet"><span class="by">serjester</span><span>|</span><a href="#41240335">prev</a><span>|</span><a href="#41237563">next</a><span>|</span><label class="collapse" for="c-41237219">[-]</label><label class="expand" for="c-41237219">[3 more]</label></div><br/><div class="children"><div class="content">It seems like your business strategy is contingent on foundational model providers not improving their product on a couple dimensions: price, grounding accuracy and file handling. This is a risky strategy, especially in such a competitive market. Wishing you the best of luck.</div><br/><div id="41237330" class="c"><input type="checkbox" id="c-41237330" checked=""/><div class="controls bullet"><span class="by">hamsterbooster</span><span>|</span><a href="#41237219">parent</a><span>|</span><a href="#41237563">next</a><span>|</span><label class="collapse" for="c-41237330">[-]</label><label class="expand" for="c-41237330">[2 more]</label></div><br/><div class="children"><div class="content">I would say the opposite. We want to make sure that we build our systems in a way that it get better as foundational model becomes better.<p>Our thesis is that foundational models will become good and affordable enough to be used in almost all data processing pipelines. We build systems on top of that to manage workflows, integrations, and data applications that people may want to develop.</div><br/><div id="41237392" class="c"><input type="checkbox" id="c-41237392" checked=""/><div class="controls bullet"><span class="by">CuriouslyC</span><span>|</span><a href="#41237219">root</a><span>|</span><a href="#41237330">parent</a><span>|</span><a href="#41237563">next</a><span>|</span><label class="collapse" for="c-41237392">[-]</label><label class="expand" for="c-41237392">[1 more]</label></div><br/><div class="children"><div class="content">Seems like you want foundational models to become better at doing what you want when you give it your &quot;magic&quot; prompt, while not becoming smart enough to not need your magic prompt at all.<p>I&#x27;d need to actually dig into your product to make an informed statement but my guess is that if you build your business around AI secret sauce you&#x27;re going to get your business eaten and pivot or fail, and if you build your business around a UI and specific integrations&#x2F;tools real customers you&#x27;re already in contact with want right now, you&#x27;ll be ok.</div><br/></div></div></div></div></div></div><div id="41237563" class="c"><input type="checkbox" id="c-41237563" checked=""/><div class="controls bullet"><span class="by">purplepatrick</span><span>|</span><a href="#41237219">prev</a><span>|</span><a href="#41237784">next</a><span>|</span><label class="collapse" for="c-41237563">[-]</label><label class="expand" for="c-41237563">[2 more]</label></div><br/><div class="children"><div class="content">Two quick questions: any plans on being hipaa compliant? Probably one of the biggest use cases for this is in health insurance, etc.<p>How do your capabilities compare to Google Document AI or Watson SDU? Also what about standalone competitors such as Indico Data or DocuPanda?</div><br/><div id="41238050" class="c"><input type="checkbox" id="c-41238050" checked=""/><div class="controls bullet"><span class="by">macklinkachorn</span><span>|</span><a href="#41237563">parent</a><span>|</span><a href="#41237784">next</a><span>|</span><label class="collapse" for="c-41238050">[-]</label><label class="expand" for="c-41238050">[1 more]</label></div><br/><div class="children"><div class="content">Yes, HIPAA compliance is on the roadmap and should be out in a few weeks. We spent a lot of time on healthcare&#x2F;sensitive data use cases.<p>Google Document AI and Watson SDU seem to be an afterthought for IBM&#x2F;Google. The accuracy and configurability often fall short when you want to use them in a production setting.<p>Comparing to other legacy document processing companies, I think there are a few areas where we differentiate:<p>1. We handle end-to-end workflows from integrating with data sources, defining the transformation, and automatically triggering new runs when there’s an update to the data.
2. We built our entire stack on LLM and Vision transformers and use OCR&#x2F;parser to check the results. This allows the mapping and tasks to be a lot more robust and flexible.
3. We have validations, reference checking, and confidence score metrics that enable fast human-in-the-loop iteration.</div><br/></div></div></div></div><div id="41237784" class="c"><input type="checkbox" id="c-41237784" checked=""/><div class="controls bullet"><span class="by">MoritzWall</span><span>|</span><a href="#41237563">prev</a><span>|</span><a href="#41237481">next</a><span>|</span><label class="collapse" for="c-41237784">[-]</label><label class="expand" for="c-41237784">[1 more]</label></div><br/><div class="children"><div class="content">&gt; And many companies today want data preprocessing in ETL pipelines and data ingestion for RAG.<p>I&#x27;m curious, have you (or your customers) deployed this in a RAG use case already, and what have been the results like?</div><br/></div></div><div id="41237481" class="c"><input type="checkbox" id="c-41237481" checked=""/><div class="controls bullet"><span class="by">dmahanta</span><span>|</span><a href="#41237784">prev</a><span>|</span><a href="#41238450">next</a><span>|</span><label class="collapse" for="c-41237481">[-]</label><label class="expand" for="c-41237481">[2 more]</label></div><br/><div class="children"><div class="content">Didnt work for me as expected</div><br/><div id="41237546" class="c"><input type="checkbox" id="c-41237546" checked=""/><div class="controls bullet"><span class="by">macklinkachorn</span><span>|</span><a href="#41237481">parent</a><span>|</span><a href="#41238450">next</a><span>|</span><label class="collapse" for="c-41237546">[-]</label><label class="expand" for="c-41237546">[1 more]</label></div><br/><div class="children"><div class="content">Please let me know the issues and happy to get it set up correctly for you. I&#x27;m at mac@runtrellis.com</div><br/></div></div></div></div><div id="41238450" class="c"><input type="checkbox" id="c-41238450" checked=""/><div class="controls bullet"><span class="by">hubraumhugo</span><span>|</span><a href="#41237481">prev</a><span>|</span><a href="#41237383">next</a><span>|</span><label class="collapse" for="c-41238450">[-]</label><label class="expand" for="c-41238450">[2 more]</label></div><br/><div class="children"><div class="content">You mention validation and schema guarantees as key features for high accuracy. Are you using an LLM-as-a-judge combined with traditional checks for this?</div><br/><div id="41238678" class="c"><input type="checkbox" id="c-41238678" checked=""/><div class="controls bullet"><span class="by">macklinkachorn</span><span>|</span><a href="#41238450">parent</a><span>|</span><a href="#41237383">next</a><span>|</span><label class="collapse" for="c-41238678">[-]</label><label class="expand" for="c-41238678">[1 more]</label></div><br/><div class="children"><div class="content">Yes, we combine LLMs as a judge with traditional checks like reverse search in original data sources, defining your own post-processing logic, and simple classifier for confidence score.</div><br/></div></div></div></div><div id="41237383" class="c"><input type="checkbox" id="c-41237383" checked=""/><div class="controls bullet"><span class="by">chrisweekly</span><span>|</span><a href="#41238450">prev</a><span>|</span><a href="#41238066">next</a><span>|</span><label class="collapse" for="c-41237383">[-]</label><label class="expand" for="c-41237383">[3 more]</label></div><br/><div class="children"><div class="content">disclaimer: I&#x27;m a barely-informed layperson, not any kind of AI expert<p>non-snarky genuine question: is &quot;generate structured data from unstructured data using AI&quot; intended to be a moat or differentiator?<p>catalyst for my question: I just read about this capability becoming available from other AI vendors, e.g.<p><a href="https:&#x2F;&#x2F;openai.com&#x2F;index&#x2F;introducing-structured-outputs-in-the-api" rel="nofollow">https:&#x2F;&#x2F;openai.com&#x2F;index&#x2F;introducing-structured-outputs-in-t...</a></div><br/><div id="41237708" class="c"><input type="checkbox" id="c-41237708" checked=""/><div class="controls bullet"><span class="by">constantinum</span><span>|</span><a href="#41237383">parent</a><span>|</span><a href="#41238066">next</a><span>|</span><label class="collapse" for="c-41237708">[-]</label><label class="expand" for="c-41237708">[2 more]</label></div><br/><div class="children"><div class="content">That is only part of the problem; the others include:<p>1. writing connectors for various sources<p>2. writing connectors for destination<p>3. supporting multiple models, embeddings, vector database, text extractors<p>3. workflow automation engine(cron jobs)<p>4. performance tuning for speed and costs<p>5. security and compliance</div><br/><div id="41237779" class="c"><input type="checkbox" id="c-41237779" checked=""/><div class="controls bullet"><span class="by">macklinkachorn</span><span>|</span><a href="#41237383">root</a><span>|</span><a href="#41237708">parent</a><span>|</span><a href="#41238066">next</a><span>|</span><label class="collapse" for="c-41237779">[-]</label><label class="expand" for="c-41237779">[1 more]</label></div><br/><div class="children"><div class="content">Totally! The structured extraction from AI is only a small part in the product. 
Beyond the list above we also built
1. Custom validation that allows end users to validate outputs with their own logic
2. Manage different workflows (monitoring, scaling) and keep track of business logic in processing different data sources.</div><br/></div></div></div></div></div></div><div id="41238066" class="c"><input type="checkbox" id="c-41238066" checked=""/><div class="controls bullet"><span class="by">EarlyOom</span><span>|</span><a href="#41237383">prev</a><span>|</span><a href="#41236799">next</a><span>|</span><label class="collapse" for="c-41238066">[-]</label><label class="expand" for="c-41238066">[2 more]</label></div><br/><div class="children"><div class="content">Curious how this compares to platforms like <a href="https:&#x2F;&#x2F;unstructured.io&#x2F;" rel="nofollow">https:&#x2F;&#x2F;unstructured.io&#x2F;</a></div><br/><div id="41238288" class="c"><input type="checkbox" id="c-41238288" checked=""/><div class="controls bullet"><span class="by">macklinkachorn</span><span>|</span><a href="#41238066">parent</a><span>|</span><a href="#41236799">next</a><span>|</span><label class="collapse" for="c-41238288">[-]</label><label class="expand" for="c-41238288">[1 more]</label></div><br/><div class="children"><div class="content">Unstructured seems to be focusing a lot on the document chunking and data ingestion into RAGs part.  Trellis handles the process end-to-end from extraction to transforming the data into the schema that you need for downstream applications.<p>The way unstructured built their parsing and extraction are mostly based on traditional OCR and rule based extraction. We built all preprocessing pipeline in an LLM and vision model first way that allows us to be flexible when the data is quite complex (like tables and images within documents).</div><br/></div></div></div></div><div id="41236799" class="c"><input type="checkbox" id="c-41236799" checked=""/><div class="controls bullet"><span class="by">bitshaker</span><span>|</span><a href="#41238066">prev</a><span>|</span><a href="#41237893">next</a><span>|</span><label class="collapse" for="c-41236799">[-]</label><label class="expand" for="c-41236799">[2 more]</label></div><br/><div class="children"><div class="content">Digitizing and organizing old document scans for birth, marriage, and death records would be a huge win for genealogy research. The Mormon church would be a great customer for you.</div><br/><div id="41237465" class="c"><input type="checkbox" id="c-41237465" checked=""/><div class="controls bullet"><span class="by">meiraleal</span><span>|</span><a href="#41236799">parent</a><span>|</span><a href="#41237893">next</a><span>|</span><label class="collapse" for="c-41237465">[-]</label><label class="expand" for="c-41237465">[1 more]</label></div><br/><div class="children"><div class="content">For them and all other 50 AI PDF scanning wrappers that were featured on Show HN in the past month.</div><br/></div></div></div></div><div id="41237893" class="c"><input type="checkbox" id="c-41237893" checked=""/><div class="controls bullet"><span class="by">inglor</span><span>|</span><a href="#41236799">prev</a><span>|</span><a href="#41237006">next</a><span>|</span><label class="collapse" for="c-41237893">[-]</label><label class="expand" for="c-41237893">[3 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t understand why you need an LLM for this, wouldn&#x27;t a simple NER + entity normalization do this at a fraction of the cost?<p>(congrats on the launch!)</div><br/><div id="41238136" class="c"><input type="checkbox" id="c-41238136" checked=""/><div class="controls bullet"><span class="by">macklinkachorn</span><span>|</span><a href="#41237893">parent</a><span>|</span><a href="#41238064">next</a><span>|</span><label class="collapse" for="c-41238136">[-]</label><label class="expand" for="c-41238136">[1 more]</label></div><br/><div class="children"><div class="content">NER is good for really simple things (like getting names, addresses, etc.).<p>A lot of the use cases that we see, like extracting data from nested tables in 100-page-long private credit documents or flagging transactions and emails that contain a specific compliance violation, are impossible to do with NER.<p>NER is good for really simple things (like getting names, addresses, etc.).<p>A lot of the use cases that we see, like extracting data from nested tables in 100-page-long private credit documents or flagging transactions and emails that contain a specific compliance violation, are impossible to do with NER.<p>With Trellis, the idea is taht you can write any mappings and transformations (no matter how complex the tasks or the source data are).</div><br/></div></div><div id="41238064" class="c"><input type="checkbox" id="c-41238064" checked=""/><div class="controls bullet"><span class="by">jackylin</span><span>|</span><a href="#41237893">parent</a><span>|</span><a href="#41238136">prev</a><span>|</span><a href="#41237006">next</a><span>|</span><label class="collapse" for="c-41238064">[-]</label><label class="expand" for="c-41238064">[1 more]</label></div><br/><div class="children"><div class="content">Good question—NER and entity normalization work well for documents that have been standardized (e.g., IRS 1040a tax forms). However, the moment something slightly changes about the form, such as the structure of the table, the accuracy of NER drops dramatically.<p>This is why logistics companies, financial services, and insurance firms have in-house teams to process these documents (e.g., insurance claims adjusters) or outsource them to BPOs. These documents can vary significantly from one to another.<p>With LLMs fine-tuned on your data, the accuracy is much higher, more robust, and more generalizable. We have a human in the loop for flagged results to ensure we maintain the highest accuracy standards in critical settings like financial services.</div><br/></div></div></div></div><div id="41237006" class="c"><input type="checkbox" id="c-41237006" checked=""/><div class="controls bullet"><span class="by">doctorpangloss</span><span>|</span><a href="#41237893">prev</a><span>|</span><a href="#41238112">next</a><span>|</span><label class="collapse" for="c-41237006">[-]</label><label class="expand" for="c-41237006">[11 more]</label></div><br/><div class="children"><div class="content">&gt; At the Stanford AI lab where we met... 80% of enterprise data is unstructured, and traditional platforms can’t handle it<p>You guys came out of an academic lab, so you must know that hypothesis fishing expeditions are not viable.<p>&gt; ... a major commercial bank... couldn’t improve credit risk models because critical data was stuck in PDFs and emails.<p>In this example there will be no improvement to the risk model or whatever, because 19&#x2F;20 times there will be no improvement. In an academic setting this is seen as normal, but in a business setting with no executive champions, only product managers, this will be seen as a failure, and it will be associated with you and your technology, which is bad.<p>Unfortunately these people are not willing to pay more money for less risk. What they want is a base consulting cost (i.e., a non-venture business) to identify the lowest risk, promotion worthy endeavor, and then they want to pay as little as possible to achieve that. In a sense, the kind of customers who need unstructured data ETLs are poorly positioned to use such a technology, because they don&#x27;t value technology generally, they aren&#x27;t forward looking.<p>Assembling attractive websites that are really features on top of Dagster? There&#x27;s a lot of value in that. Question is, are people willing to pay for that? Anyone can make attractive Dagster UIs, anyone can do Python glue. It&#x27;s very challenging to differentiate yourselves, even when you feel like you have some customers, because eventually, one of those middlemen at BankCo are going to punch your USP into Google, and find the pre-existing services with huge account management teams (i.e., the hand holding consulting business people really pay for) that outpace you.</div><br/><div id="41237088" class="c"><input type="checkbox" id="c-41237088" checked=""/><div class="controls bullet"><span class="by">mritchie712</span><span>|</span><a href="#41237006">parent</a><span>|</span><a href="#41237096">next</a><span>|</span><label class="collapse" for="c-41237088">[-]</label><label class="expand" for="c-41237088">[7 more]</label></div><br/><div class="children"><div class="content">&gt; 80% of enterprise data is unstructured<p>I&#x27;ve seen quotes like this many times. It&#x27;s silly. I worked at a big bank for over a decade. 95% of the data we cared about was already in a SQL database. Maybe ~80% of our data was &quot;unstructured&quot;, but it wasn&#x27;t stuff we cared about for risk management or other critical functions.<p>&gt; people are not willing to pay more money for less risk<p>I&#x27;d disagree here. Banks are willing to pay money to reduce risk, it&#x27;s just unlikely to come from scraping data out of PDFs with an LLM because they&#x27;ve already done this if it&#x27;s worth it.</div><br/><div id="41237886" class="c"><input type="checkbox" id="c-41237886" checked=""/><div class="controls bullet"><span class="by">wjnc</span><span>|</span><a href="#41237006">root</a><span>|</span><a href="#41237088">parent</a><span>|</span><a href="#41237425">next</a><span>|</span><label class="collapse" for="c-41237886">[-]</label><label class="expand" for="c-41237886">[3 more]</label></div><br/><div class="children"><div class="content">Who, in your example, put the customers financial data in the SQL database? Because in my part of finance that’s either the customer, or an employee.<p>Our customers are asking for integration with a lot of their systems (say HR &#x2F; patrolling), but never ever offer to hook up their accounting system. If we want financial data, we either get a PDF with their audited financial statement or in exceptional cases a custom audited statement (you know, the one where a print of a part of the ledger gets a signature from the CPA for a not insignificant bill).<p>So I am enthusiastic from a data science point of view. Financial data processing of customer data is &#x2F; was scarce since limited to what was feasible to manually process. That is nearly in the past.</div><br/><div id="41243404" class="c"><input type="checkbox" id="c-41243404" checked=""/><div class="controls bullet"><span class="by">PeterStuer</span><span>|</span><a href="#41237006">root</a><span>|</span><a href="#41237886">parent</a><span>|</span><a href="#41237425">next</a><span>|</span><label class="collapse" for="c-41243404">[-]</label><label class="expand" for="c-41243404">[2 more]</label></div><br/><div class="children"><div class="content">I created automated descision suppport systems in asset based finance. For daily needs you get customer financials and other risk data from both official national sources and the likes of Dunn and Bradstreet, Graydon etc. The choice of providers depends on both the customer and deal risk&#x2F;size. While the &quot;api&quot;&#x27;s to these providers might be clunky (putting structured request file on an ftp server and polling for a response), the data is structured (enough) to process.<p>Deals that are exceptional enough get assigned to a risk officer that deals with it as a case (sidenote: they use a lott of selfmade Excel, VB and low-code tools as they never get IT priority for these cases). There is not enough uniformity as well as a decreased tolerance for inaccuracy in those to warrant extensive automation.</div><br/><div id="41243562" class="c"><input type="checkbox" id="c-41243562" checked=""/><div class="controls bullet"><span class="by">wjnc</span><span>|</span><a href="#41237006">root</a><span>|</span><a href="#41243404">parent</a><span>|</span><a href="#41237425">next</a><span>|</span><label class="collapse" for="c-41243562">[-]</label><label class="expand" for="c-41243562">[1 more]</label></div><br/><div class="children"><div class="content">Thanks. I see the context now. Our asset managers are indeed lucky to have Bloomberg and such, which are easily integratable (and indeed, have been &quot;SQL&quot; for more than a decade now). I&#x27;m aware of the third party providers of customer financial information. Lucky to operate in a niche that is not served by them. Graydon (the only one I&#x27;ve been in contact with) is facing a massive disruption though. Their higher tiers are perhaps not enterprise expensive, but Trellis and the likes are probably more integratable and more affordable.<p>But still, the one building the LLM-integration is 4x as expensive as the one manually entering the data. It&#x27;s all about TOC, scale and risk perception. I also love that &quot;risk people&quot; (in the banking context, I&#x27;d say: model people) think their data quality should be exceptional and then use end user computing MacGyver style models. Spit and popsicle sticks.</div><br/></div></div></div></div></div></div><div id="41237425" class="c"><input type="checkbox" id="c-41237425" checked=""/><div class="controls bullet"><span class="by">lmeyerov</span><span>|</span><a href="#41237006">root</a><span>|</span><a href="#41237088">parent</a><span>|</span><a href="#41237886">prev</a><span>|</span><a href="#41237096">next</a><span>|</span><label class="collapse" for="c-41237425">[-]</label><label class="expand" for="c-41237425">[3 more]</label></div><br/><div class="children"><div class="content">Yep, and nowadays, banks are already deploying this stuff internally via their own IT teams. They have 1-2 decades of having built up ETL&#x2F;orchestration talent + infra, and have been growing deals with openai&#x2F;azure&#x2F;google&#x2F;aws&#x2F;databricks for the LLM bits. Internally, big banks are rolling out hundreds of LLM apps each, and generally have freezes on new external AI vendors due to &#x27;AI compliance risk&#x27;. NLP commoditized so it&#x27;s a different world.<p>It makes sense on paper from a VC perspective as a big bet.. but good luck to smaller VC-funded founders competing with massive BD teams fronting top AI dev teams. We compete in adjacent spaces where we can differentiate, and intentionally decided against going in head-on. For those who can, again, good luck!</div><br/><div id="41237918" class="c"><input type="checkbox" id="c-41237918" checked=""/><div class="controls bullet"><span class="by">wjnc</span><span>|</span><a href="#41237006">root</a><span>|</span><a href="#41237425">parent</a><span>|</span><a href="#41237096">next</a><span>|</span><label class="collapse" for="c-41237918">[-]</label><label class="expand" for="c-41237918">[2 more]</label></div><br/><div class="children"><div class="content">Am I in another world? (See my response above.) Most of the ‘hundreds of LLM apps’ I see are, well, not very fancy and struggling to keep up on accuracy in comparison to the meatspace solutions they promised to massively outperform.<p>I agree with your assessment that the IT risk barrier is very high in big corp so that entry might be hard for Trellis. Plus a continuous push afterwards to go back to traditional cloud once their offerings catch up.</div><br/><div id="41239326" class="c"><input type="checkbox" id="c-41239326" checked=""/><div class="controls bullet"><span class="by">lmeyerov</span><span>|</span><a href="#41237006">root</a><span>|</span><a href="#41237918">parent</a><span>|</span><a href="#41237096">next</a><span>|</span><label class="collapse" for="c-41239326">[-]</label><label class="expand" for="c-41239326">[1 more]</label></div><br/><div class="children"><div class="content">I totally agree, and it&#x27;s useful to play out the shrinking quality gap over time:<p>- Today: Financial companies are willing to pay cloud providers for DB, LLM, &amp; AI services, and want to paper over the rest with internal teams + OSS, and maybe some already-trusted contractors for stopgaps. Institutional immune system largely rejects innovators not in the above categories.<p>- Next 6-18mo: Projects continue, and they hit today&#x27;s typical quality issues. It&#x27;s easiest to continue to solve these with the current team, maybe pull on a consultant or neighboring team due to good-money-after-bad, and likely, the cloud&#x2F;AI provider solves more and more for them (GPT5, ..., new Google Vertex APIs, ..)<p>- Next year or year after: Either the above solved it, or they make a new decision around contractors + new software vendors. But how much is still needed here?<p>It&#x27;s a scary question for non-vertical startups to still make sense with the assumption that horizontal data incumbents and core AI infra providers don&#x27;t continue to eat into the territory here. Data extraction, vector indexing, RAG as a service, data quality, talk to your data, etc. Throw in the pressure of VC funding and even more fun. I think there&#x27;s opportunity here, but when I think about who is positioned wrt distribution &amp; engineering resources to get at that... I do not envy founders without those advantages.</div><br/></div></div></div></div></div></div></div></div><div id="41237096" class="c"><input type="checkbox" id="c-41237096" checked=""/><div class="controls bullet"><span class="by">hamsterbooster</span><span>|</span><a href="#41237006">parent</a><span>|</span><a href="#41237088">prev</a><span>|</span><a href="#41238112">next</a><span>|</span><label class="collapse" for="c-41237096">[-]</label><label class="expand" for="c-41237096">[3 more]</label></div><br/><div class="children"><div class="content">Thanks for the feedback. We built Trellis based on our experience with ingesting and analyzing unstructured customer calls and chats in a reliable way. We couldn’t find a good solution apart from developing a dedicated ML pipeline, which is quite difficult to maintain.<p>There are some elements that might resemble Dagster, but I believe the challenging part is constructing validation systems that ensure high accuracy and correct schemas while processing all kinds of complex PDFs and document edge cases. Over the past few weeks, our engineering team has spent a lot of time developing a vision model robust enough to extract nested tables from documents</div><br/><div id="41237237" class="c"><input type="checkbox" id="c-41237237" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#41237006">root</a><span>|</span><a href="#41237096">parent</a><span>|</span><a href="#41238112">next</a><span>|</span><label class="collapse" for="c-41237237">[-]</label><label class="expand" for="c-41237237">[2 more]</label></div><br/><div class="children"><div class="content">What is your metric and score? Maybe you have reached perfect reliability, but in my experience information extraction is about 90% accurate for real life scenarios, and you can&#x27;t reliably know which 90%.<p>In critical scenarios companies won&#x27;t risk using 100% automation, the human is still in the loop, so the cost doesn&#x27;t go down much.<p>I work on LLM based information extraction and use my own evaluation sets. That&#x27;s how I obtained the 90% score. I tested on many document types. It looks like it&#x27;s magic when you try an invoice in GPT-4o and skim the outputs, but if you spend 15 minutes you find issues.<p>Can you risk an OCR error confusing a dot for a comma to send 1000x more money in a bank transfer, or to get the medical data extraction wrong and someone could suffer because there was no human in the document ingestion pipeline to see what is happening?</div><br/></div></div></div></div></div></div><div id="41238112" class="c"><input type="checkbox" id="c-41238112" checked=""/><div class="controls bullet"><span class="by">aviguptakonda</span><span>|</span><a href="#41237006">prev</a><span>|</span><a href="#41236812">next</a><span>|</span><label class="collapse" for="c-41238112">[-]</label><label class="expand" for="c-41238112">[1 more]</label></div><br/><div class="children"><div class="content">Wow, this is game changing!
With your inventions, interestingly we might also be discovering reverse ETL use cases, where the insights&#x2F;analytics obtained from the troves of unstructured data can be fed back into ERP&#x2F;CRM&#x2F;HCM systems, closing the complete loop and amplifying more business value!!
Congratulations to the Trellis team :)
Regards, Avinash</div><br/></div></div><div id="41236812" class="c"><input type="checkbox" id="c-41236812" checked=""/><div class="controls bullet"><span class="by">natural1</span><span>|</span><a href="#41238112">prev</a><span>|</span><a href="#41237307">next</a><span>|</span><label class="collapse" for="c-41236812">[-]</label><label class="expand" for="c-41236812">[1 more]</label></div><br/><div class="children"><div class="content">Has Trellis explored partnerships or integrations with major ERP systems or existing ETL pipelines? The ability to seamlessly fit into existing enterprise architectures could be a significant competitive advantage and a compelling value proposition for large enterprises looking to modernize their data infrastructure.</div><br/></div></div><div id="41237307" class="c"><input type="checkbox" id="c-41237307" checked=""/><div class="controls bullet"><span class="by">mehulashah</span><span>|</span><a href="#41236812">prev</a><span>|</span><a href="#41237341">next</a><span>|</span><label class="collapse" for="c-41237307">[-]</label><label class="expand" for="c-41237307">[1 more]</label></div><br/><div class="children"><div class="content">Congratulations on the launch! This is the right way to think about LLMs and document processing.</div><br/></div></div><div id="41237341" class="c"><input type="checkbox" id="c-41237341" checked=""/><div class="controls bullet"><span class="by">rmbyrro</span><span>|</span><a href="#41237307">prev</a><span>|</span><label class="collapse" for="c-41237341">[-]</label><label class="expand" for="c-41237341">[3 more]</label></div><br/><div class="children"><div class="content">Domains should start with your company name. Like trellishq.com<p>Because browsers have an autocomplete feature.</div><br/><div id="41237396" class="c"><input type="checkbox" id="c-41237396" checked=""/><div class="controls bullet"><span class="by">shafyy</span><span>|</span><a href="#41237341">parent</a><span>|</span><label class="collapse" for="c-41237396">[-]</label><label class="expand" for="c-41237396">[2 more]</label></div><br/><div class="children"><div class="content">...which also autocompletes if the domain does not start with the company name :-)</div><br/><div id="41237421" class="c"><input type="checkbox" id="c-41237421" checked=""/><div class="controls bullet"><span class="by">rmbyrro</span><span>|</span><a href="#41237341">root</a><span>|</span><a href="#41237396">parent</a><span>|</span><label class="collapse" for="c-41237421">[-]</label><label class="expand" for="c-41237421">[1 more]</label></div><br/><div class="children"><div class="content">Yes, but brains are not good at remembering which word they decided to prepend Trellis</div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>