<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1687338073373" as="style"/><link rel="stylesheet" href="styles.css?v=1687338073373"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://arxiv.org/abs/2306.11644">Textbooks are all you need</a> <span class="domain">(<a href="https://arxiv.org">arxiv.org</a>)</span></div><div class="subtext"><span>foobarqux</span> | <span>44 comments</span></div><br/><div><div id="36413829" class="c"><input type="checkbox" id="c-36413829" checked=""/><div class="controls bullet"><span class="by">og_kalu</span><span>|</span><a href="#36416019">next</a><span>|</span><label class="collapse" for="c-36413829">[-]</label><label class="expand" for="c-36413829">[5 more]</label></div><br/><div class="children"><div class="content">8 passes so 50B tokens seen. Still, any other &gt;50% HumanEval model is much much bigger <a href="https:&#x2F;&#x2F;twitter.com&#x2F;SebastienBubeck&#x2F;status&#x2F;1671326369626853376" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;SebastienBubeck&#x2F;status&#x2F;16713263696268533...</a><p>Now this wouldn&#x27;t be possible without the high quality synthetic dataset produced by GPT(1B tokens) but this is more evidence in line with Tiny Stories (<a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2305.07759" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2305.07759</a>). That is, LLMs only need to be so big (both data and parameters) to learn the total sum of human knowledge (and deal with trash data).</div><br/><div id="36414179" class="c"><input type="checkbox" id="c-36414179" checked=""/><div class="controls bullet"><span class="by">skepticATX</span><span>|</span><a href="#36413829">parent</a><span>|</span><a href="#36416019">next</a><span>|</span><label class="collapse" for="c-36414179">[-]</label><label class="expand" for="c-36414179">[4 more]</label></div><br/><div class="children"><div class="content">This result puts more emphasis on data quality, which might actually be problematic long term though? The vast majority of human knowledge is not represented in high quality textbooks.<p>It’s not clear from these results but the paper seems to at least imply that the importance of the synthetic data is to “unlock” the pre-training data.<p>My takeaway as a non-expert is that this is a good result for small and efficient models focused on well-defined domains, but a neutral or maybe even a bad result for a model that displays general intelligence.</div><br/><div id="36414616" class="c"><input type="checkbox" id="c-36414616" checked=""/><div class="controls bullet"><span class="by">airgapstopgap</span><span>|</span><a href="#36413829">root</a><span>|</span><a href="#36414179">parent</a><span>|</span><a href="#36416019">next</a><span>|</span><label class="collapse" for="c-36414616">[-]</label><label class="expand" for="c-36414616">[3 more]</label></div><br/><div class="children"><div class="content">The vast majority of human data can be refined into something approximating high quality textbooks, which is what happened here too.</div><br/><div id="36416030" class="c"><input type="checkbox" id="c-36416030" checked=""/><div class="controls bullet"><span class="by">WJW</span><span>|</span><a href="#36413829">root</a><span>|</span><a href="#36414616">parent</a><span>|</span><a href="#36415467">next</a><span>|</span><label class="collapse" for="c-36416030">[-]</label><label class="expand" for="c-36416030">[1 more]</label></div><br/><div class="children"><div class="content">I wonder if that is true. Intuitively it seems to me that there are probably many areas of knowledge that cannot be reliably summarized into a textbook. Most subjective experiences, for example. Qualia have been notoriously difficult to describe too, even if the might be absolute.<p>Even for fields that lend themselves well to being converted to textbook format there is often a tradeoff between accuracy and conciseness. The more you refine, the more nuance you throw away. It seems like a Very Hard Problem (tm) to know which data are superfluous and which are not, especially at scale.</div><br/></div></div><div id="36415467" class="c"><input type="checkbox" id="c-36415467" checked=""/><div class="controls bullet"><span class="by">skepticATX</span><span>|</span><a href="#36413829">root</a><span>|</span><a href="#36414616">parent</a><span>|</span><a href="#36416030">prev</a><span>|</span><a href="#36416019">next</a><span>|</span><label class="collapse" for="c-36415467">[-]</label><label class="expand" for="c-36415467">[1 more]</label></div><br/><div class="children"><div class="content">Only 1&#x2F;7 of the data they are using is synthetic though. The other 6&#x2F;7 was just filtered from a larger dataset, not refined in any way.</div><br/></div></div></div></div></div></div></div></div><div id="36416019" class="c"><input type="checkbox" id="c-36416019" checked=""/><div class="controls bullet"><span class="by">cafaxo</span><span>|</span><a href="#36413829">prev</a><span>|</span><a href="#36413975">next</a><span>|</span><label class="collapse" for="c-36416019">[-]</label><label class="expand" for="c-36416019">[2 more]</label></div><br/><div class="children"><div class="content">From page 6, when they describe their synthetic textbook dataset:<p>&quot;Consider the matrix A = np.array([[1, 2], [2, 4]]). We can check if this matrix is singular or nonsingular using the determinant function. [...]&quot;<p>No. The determinant is not a suitable way to do that. A proper way to numerically measure singularity would be to compute the condition number of the matrix (the ratio of its largest to smallest singular value).</div><br/><div id="36416066" class="c"><input type="checkbox" id="c-36416066" checked=""/><div class="controls bullet"><span class="by">aix1</span><span>|</span><a href="#36416019">parent</a><span>|</span><a href="#36413975">next</a><span>|</span><label class="collapse" for="c-36416066">[-]</label><label class="expand" for="c-36416066">[1 more]</label></div><br/><div class="children"><div class="content">Am I misreading this, or is it really about a 2x2 matrix? (In which case computing the determinant involves just two multiplications and one subtraction.)</div><br/></div></div></div></div><div id="36413975" class="c"><input type="checkbox" id="c-36413975" checked=""/><div class="controls bullet"><span class="by">eightysixfour</span><span>|</span><a href="#36416019">prev</a><span>|</span><a href="#36414047">next</a><span>|</span><label class="collapse" for="c-36413975">[-]</label><label class="expand" for="c-36413975">[1 more]</label></div><br/><div class="children"><div class="content">The next step change for ML will be some kind of broad model (like the the LLM equivalent of JEPA) outlining the answer from a “big picture view” and then using an ensemble of small, precise models like this one filling in the details.</div><br/></div></div><div id="36414047" class="c"><input type="checkbox" id="c-36414047" checked=""/><div class="controls bullet"><span class="by">bongobingo1</span><span>|</span><a href="#36413975">prev</a><span>|</span><a href="#36415409">next</a><span>|</span><label class="collapse" for="c-36414047">[-]</label><label class="expand" for="c-36414047">[6 more]</label></div><br/><div class="children"><div class="content">&gt; using a selection of ``textbook quality&quot; data from the web ... and synthetically generated textbooks and exercises with GPT-3.5<p>Is this common, training a LLM from another LLMs generated output? How do you avoid &quot;bad code&quot; from GPT, if not out right hallucinations?</div><br/><div id="36414128" class="c"><input type="checkbox" id="c-36414128" checked=""/><div class="controls bullet"><span class="by">og_kalu</span><span>|</span><a href="#36414047">parent</a><span>|</span><a href="#36414850">next</a><span>|</span><label class="collapse" for="c-36414128">[-]</label><label class="expand" for="c-36414128">[2 more]</label></div><br/><div class="children"><div class="content">&gt;Is this common, training a LLM from another LLMs generated output?<p>It&#x27;s not uncommon. And the level the SOTA LLMs are now, it&#x27;ll only become more common.<p>It happens because we&#x27;re at the stage where GPT-3.5&#x2F;4 can generate much better data (or hit more encompassing or general distributions with the right instructions) than what the majority of LLMs will be typically trained on.<p>Also 4 can recheck output for bugs, mistakes, errors etc<p>It may not be perfect but neither would &quot;natural data&quot; and depending on exactly what kind of data, it might be as close to perfect as you&#x27;ll get - <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2305.07759" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2305.07759</a></div><br/><div id="36414278" class="c"><input type="checkbox" id="c-36414278" checked=""/><div class="controls bullet"><span class="by">zarzavat</span><span>|</span><a href="#36414047">root</a><span>|</span><a href="#36414128">parent</a><span>|</span><a href="#36414850">next</a><span>|</span><label class="collapse" for="c-36414278">[-]</label><label class="expand" for="c-36414278">[1 more]</label></div><br/><div class="children"><div class="content">When humans <i>think</i> this is what they are doing: retraining themselves on their own learned data. In other words, knowledge is not a conserved quantity. Of course the extent of the extra knowledge you can produce without access to the environment is limited.</div><br/></div></div></div></div><div id="36414850" class="c"><input type="checkbox" id="c-36414850" checked=""/><div class="controls bullet"><span class="by">kramerger</span><span>|</span><a href="#36414047">parent</a><span>|</span><a href="#36414128">prev</a><span>|</span><a href="#36414734">next</a><span>|</span><label class="collapse" for="c-36414850">[-]</label><label class="expand" for="c-36414850">[1 more]</label></div><br/><div class="children"><div class="content">If you think about it, how do humans learn things?<p>A child gets alot of his knowledge by randomly copying what grownups do.</div><br/></div></div><div id="36414734" class="c"><input type="checkbox" id="c-36414734" checked=""/><div class="controls bullet"><span class="by">adt</span><span>|</span><a href="#36414047">parent</a><span>|</span><a href="#36414850">prev</a><span>|</span><a href="#36414204">next</a><span>|</span><label class="collapse" for="c-36414734">[-]</label><label class="expand" for="c-36414734">[1 more]</label></div><br/><div class="children"><div class="content">Exactly.<p>The False Promise of Imitating Proprietary LLMs (UC Berkeley, 25&#x2F;May&#x2F;2023)<p><a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2305.15717" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2305.15717</a></div><br/></div></div><div id="36414204" class="c"><input type="checkbox" id="c-36414204" checked=""/><div class="controls bullet"><span class="by">kleton</span><span>|</span><a href="#36414047">parent</a><span>|</span><a href="#36414734">prev</a><span>|</span><a href="#36415409">next</a><span>|</span><label class="collapse" for="c-36414204">[-]</label><label class="expand" for="c-36414204">[1 more]</label></div><br/><div class="children"><div class="content">This is probably why openai sets the knowledge cutoff when it does.</div><br/></div></div></div></div><div id="36415409" class="c"><input type="checkbox" id="c-36415409" checked=""/><div class="controls bullet"><span class="by">regularfry</span><span>|</span><a href="#36414047">prev</a><span>|</span><a href="#36415736">next</a><span>|</span><label class="collapse" for="c-36415409">[-]</label><label class="expand" for="c-36415409">[1 more]</label></div><br/><div class="children"><div class="content">Looking at the `Educational values deemed by the filter` table on page 5, I can&#x27;t help wondering whether compressibility might not be a usable proxy for educational value.  High compressibility would imply low information content.  High marginal compressibility when added to a large dataset would imply the information is already in there.  This is basically Normalised Compression Distance all over again - it&#x27;s only a rough proxy, but I guess the question is whether it could work at all, rather than is it as good as this result.<p>If that worked as a proxy value, you could sidestep needing GPT-4 at all.</div><br/></div></div><div id="36415736" class="c"><input type="checkbox" id="c-36415736" checked=""/><div class="controls bullet"><span class="by">hcks</span><span>|</span><a href="#36415409">prev</a><span>|</span><a href="#36415194">next</a><span>|</span><label class="collapse" for="c-36415736">[-]</label><label class="expand" for="c-36415736">[1 more]</label></div><br/><div class="children"><div class="content">´all you need’ is going to become an anti-signal very quick</div><br/></div></div><div id="36415194" class="c"><input type="checkbox" id="c-36415194" checked=""/><div class="controls bullet"><span class="by">rjb7731</span><span>|</span><a href="#36415736">prev</a><span>|</span><a href="#36414225">next</a><span>|</span><label class="collapse" for="c-36415194">[-]</label><label class="expand" for="c-36415194">[1 more]</label></div><br/><div class="children"><div class="content">Its interesting this paper &amp; the Orca LLM paper from Microsoft are using GPT3&#x2F;4 model outputs to train &#x27;powerful&#x27; models. Big question is will they allow your average joes&#x2F;businesses to do the same on their own data? Doubt it, considering it breaks OAIs terms of use at present. Will opensource lead the way on this? Bring on Llama-v2</div><br/></div></div><div id="36414225" class="c"><input type="checkbox" id="c-36414225" checked=""/><div class="controls bullet"><span class="by">waynecochran</span><span>|</span><a href="#36415194">prev</a><span>|</span><a href="#36415060">next</a><span>|</span><label class="collapse" for="c-36414225">[-]</label><label class="expand" for="c-36414225">[2 more]</label></div><br/><div class="children"><div class="content"><p><pre><code>   &quot;displays surprising emergent properties&quot;
</code></pre>
Section 3 states &quot;includes managing intricate algorithmic tasks.&quot; I take this as meaning it can write new code (not regurgitation). It is impressive that is can write code as described in the prompt, but I didn&#x27;t think this was considered &quot;emergent&quot; but &quot;generalization.&quot; What is the difference?</div><br/><div id="36415307" class="c"><input type="checkbox" id="c-36415307" checked=""/><div class="controls bullet"><span class="by">mjburgess</span><span>|</span><a href="#36414225">parent</a><span>|</span><a href="#36415060">next</a><span>|</span><label class="collapse" for="c-36415307">[-]</label><label class="expand" for="c-36415307">[1 more]</label></div><br/><div class="children"><div class="content">There is no difference, &quot;emergent&quot; is another hype term used in place of &quot;discontinuous generalisation&quot;.<p>ie., with 1MB data you dont get generalisation, with 1TB you do. So they call that emergence.<p>I&#x27;m almost at the point where I can let these things go; but each new bit of mystifying hype, another stone falls in my shoe.</div><br/></div></div></div></div><div id="36415060" class="c"><input type="checkbox" id="c-36415060" checked=""/><div class="controls bullet"><span class="by">gtsnexp</span><span>|</span><a href="#36414225">prev</a><span>|</span><a href="#36415656">next</a><span>|</span><label class="collapse" for="c-36415060">[-]</label><label class="expand" for="c-36415060">[1 more]</label></div><br/><div class="children"><div class="content">Is it possible to test or access this model through a web interface or any other means?</div><br/></div></div><div id="36415656" class="c"><input type="checkbox" id="c-36415656" checked=""/><div class="controls bullet"><span class="by">jackphilson</span><span>|</span><a href="#36415060">prev</a><span>|</span><a href="#36414193">next</a><span>|</span><label class="collapse" for="c-36415656">[-]</label><label class="expand" for="c-36415656">[2 more]</label></div><br/><div class="children"><div class="content">The words &quot;are all you need&quot; are all you need</div><br/><div id="36415744" class="c"><input type="checkbox" id="c-36415744" checked=""/><div class="controls bullet"><span class="by">eimrine</span><span>|</span><a href="#36415656">parent</a><span>|</span><a href="#36414193">next</a><span>|</span><label class="collapse" for="c-36415744">[-]</label><label class="expand" for="c-36415744">[1 more]</label></div><br/><div class="children"><div class="content">All you need is weed, weed, weed is all you need.</div><br/></div></div></div></div><div id="36414193" class="c"><input type="checkbox" id="c-36414193" checked=""/><div class="controls bullet"><span class="by">ilaksh</span><span>|</span><a href="#36415656">prev</a><span>|</span><a href="#36414988">next</a><span>|</span><label class="collapse" for="c-36414193">[-]</label><label class="expand" for="c-36414193">[1 more]</label></div><br/><div class="children"><div class="content">But it&#x27;s still only 50 something percent on HumanEval right? So to really prove this out you still need to try to make a much larger model.<p>I wish someone would do something like that but not use OpenAI&#x27;s models to create the training data because then supposedly it can&#x27;t be used for commercial purposes.<p>Not that it&#x27;s easy to create a lot of high quality training data.</div><br/></div></div><div id="36414988" class="c"><input type="checkbox" id="c-36414988" checked=""/><div class="controls bullet"><span class="by">haliskerbas</span><span>|</span><a href="#36414193">prev</a><span>|</span><a href="#36414005">next</a><span>|</span><label class="collapse" for="c-36414988">[-]</label><label class="expand" for="c-36414988">[1 more]</label></div><br/><div class="children"><div class="content">It’s interesting to me how a lot of these new models use GPT for the synthetic data generation to then train a better or more focused model</div><br/></div></div><div id="36414005" class="c"><input type="checkbox" id="c-36414005" checked=""/><div class="controls bullet"><span class="by">tehsauce</span><span>|</span><a href="#36414988">prev</a><span>|</span><a href="#36414302">next</a><span>|</span><label class="collapse" for="c-36414005">[-]</label><label class="expand" for="c-36414005">[1 more]</label></div><br/><div class="children"><div class="content">Overall a very interesting result.<p>I’m not sure why they compare to a list of results for the MBPP benchmark but don’t seem to include these results which are much better:<p><a href="https:&#x2F;&#x2F;paperswithcode.com&#x2F;sota&#x2F;code-generation-on-mbpp" rel="nofollow noreferrer">https:&#x2F;&#x2F;paperswithcode.com&#x2F;sota&#x2F;code-generation-on-mbpp</a></div><br/></div></div><div id="36414302" class="c"><input type="checkbox" id="c-36414302" checked=""/><div class="controls bullet"><span class="by">ototot</span><span>|</span><a href="#36414005">prev</a><span>|</span><a href="#36414197">next</a><span>|</span><label class="collapse" for="c-36414302">[-]</label><label class="expand" for="c-36414302">[2 more]</label></div><br/><div class="children"><div class="content">why don&#x27;t they use a real textbook?</div><br/><div id="36414339" class="c"><input type="checkbox" id="c-36414339" checked=""/><div class="controls bullet"><span class="by">elefanten</span><span>|</span><a href="#36414302">parent</a><span>|</span><a href="#36414197">next</a><span>|</span><label class="collapse" for="c-36414339">[-]</label><label class="expand" for="c-36414339">[1 more]</label></div><br/><div class="children"><div class="content">Because it’d either be expensive or illegal, and all content owners are paying attention now</div><br/></div></div></div></div><div id="36414197" class="c"><input type="checkbox" id="c-36414197" checked=""/><div class="controls bullet"><span class="by">light_hue_1</span><span>|</span><a href="#36414302">prev</a><span>|</span><a href="#36414270">next</a><span>|</span><label class="collapse" for="c-36414197">[-]</label><label class="expand" for="c-36414197">[1 more]</label></div><br/><div class="children"><div class="content">This is a misleading title. GPT-3.5 is all you need!<p>Their whole method relies on getting GPT-3.5 to produce examples and then training a network on those examples. This is a run-of-the-mill method called distillation.<p>There&#x27;s nothing new or special here.</div><br/></div></div><div id="36414270" class="c"><input type="checkbox" id="c-36414270" checked=""/><div class="controls bullet"><span class="by">lisasays</span><span>|</span><a href="#36414197">prev</a><span>|</span><a href="#36414043">next</a><span>|</span><label class="collapse" for="c-36414270">[-]</label><label class="expand" for="c-36414270">[2 more]</label></div><br/><div class="children"><div class="content"><i>Suriya Gunasekar, Yi Zhang, Jyoti Aneja, Caio César Teodoro Mendes, Allie Del Giorno, Sivakanth Gopi, Mojan Javaheripi, Piero Kauffmann, Gustavo de Rosa, Olli Saarikivi, Adil Salim, Shital Shah, Harkirat Singh Behl, Xin Wang, Sébastien Bubeck, Ronen Eldan, Adam Tauman Kalai, Yin Tat Lee, Yuanzhi Li</i><p>Actually, it turns out that impact factor is all you need.</div><br/><div id="36414314" class="c"><input type="checkbox" id="c-36414314" checked=""/><div class="controls bullet"><span class="by">behnamoh</span><span>|</span><a href="#36414270">parent</a><span>|</span><a href="#36414043">next</a><span>|</span><label class="collapse" for="c-36414314">[-]</label><label class="expand" for="c-36414314">[1 more]</label></div><br/><div class="children"><div class="content">Turns out, all you need is, indeed, all you need.</div><br/></div></div></div></div><div id="36414043" class="c"><input type="checkbox" id="c-36414043" checked=""/><div class="controls bullet"><span class="by">onos</span><span>|</span><a href="#36414270">prev</a><span>|</span><a href="#36414273">next</a><span>|</span><label class="collapse" for="c-36414043">[-]</label><label class="expand" for="c-36414043">[11 more]</label></div><br/><div class="children"><div class="content">I vote the title meme “… is all you need” end now.</div><br/><div id="36414104" class="c"><input type="checkbox" id="c-36414104" checked=""/><div class="controls bullet"><span class="by">jrflowers</span><span>|</span><a href="#36414043">parent</a><span>|</span><a href="#36414102">next</a><span>|</span><label class="collapse" for="c-36414104">[-]</label><label class="expand" for="c-36414104">[1 more]</label></div><br/><div class="children"><div class="content">I like the reasoning here. If you think about it, to end this madness a vote is all you need.</div><br/></div></div><div id="36414102" class="c"><input type="checkbox" id="c-36414102" checked=""/><div class="controls bullet"><span class="by">sn41</span><span>|</span><a href="#36414043">parent</a><span>|</span><a href="#36414104">prev</a><span>|</span><a href="#36414072">next</a><span>|</span><label class="collapse" for="c-36414102">[-]</label><label class="expand" for="c-36414102">[5 more]</label></div><br/><div class="children"><div class="content">Suggested title: &quot;Is all you need considered harmful&quot;</div><br/><div id="36414210" class="c"><input type="checkbox" id="c-36414210" checked=""/><div class="controls bullet"><span class="by">ninepoints</span><span>|</span><a href="#36414043">root</a><span>|</span><a href="#36414102">parent</a><span>|</span><a href="#36414242">next</a><span>|</span><label class="collapse" for="c-36414210">[-]</label><label class="expand" for="c-36414210">[3 more]</label></div><br/><div class="children"><div class="content">Myths data scientists believe about &quot;is all you need considered harmful&quot;</div><br/><div id="36414277" class="c"><input type="checkbox" id="c-36414277" checked=""/><div class="controls bullet"><span class="by">xeonmc</span><span>|</span><a href="#36414043">root</a><span>|</span><a href="#36414210">parent</a><span>|</span><a href="#36414242">next</a><span>|</span><label class="collapse" for="c-36414277">[-]</label><label class="expand" for="c-36414277">[2 more]</label></div><br/><div class="children"><div class="content">The unreasonable effectiveness of considered harmful essays is all you need</div><br/><div id="36414423" class="c"><input type="checkbox" id="c-36414423" checked=""/><div class="controls bullet"><span class="by">ph0rque</span><span>|</span><a href="#36414043">root</a><span>|</span><a href="#36414277">parent</a><span>|</span><a href="#36414242">next</a><span>|</span><label class="collapse" for="c-36414423">[-]</label><label class="expand" for="c-36414423">[1 more]</label></div><br/><div class="children"><div class="content">All you need hate him!</div><br/></div></div></div></div></div></div><div id="36414242" class="c"><input type="checkbox" id="c-36414242" checked=""/><div class="controls bullet"><span class="by">mdonahoe</span><span>|</span><a href="#36414043">root</a><span>|</span><a href="#36414102">parent</a><span>|</span><a href="#36414210">prev</a><span>|</span><a href="#36414072">next</a><span>|</span><label class="collapse" for="c-36414242">[-]</label><label class="expand" for="c-36414242">[1 more]</label></div><br/><div class="children"><div class="content">Harm is all you need</div><br/></div></div></div></div><div id="36414072" class="c"><input type="checkbox" id="c-36414072" checked=""/><div class="controls bullet"><span class="by">behnamoh</span><span>|</span><a href="#36414043">parent</a><span>|</span><a href="#36414102">prev</a><span>|</span><a href="#36414238">next</a><span>|</span><label class="collapse" for="c-36414072">[-]</label><label class="expand" for="c-36414072">[3 more]</label></div><br/><div class="children"><div class="content">The whole NLP field is full of memes. Just look at the model names: Llama, Gorilla, Jarvis, Falcon, Vicuña, Alpaca, etc.</div><br/><div id="36414200" class="c"><input type="checkbox" id="c-36414200" checked=""/><div class="controls bullet"><span class="by">littlestymaar</span><span>|</span><a href="#36414043">root</a><span>|</span><a href="#36414072">parent</a><span>|</span><a href="#36414238">next</a><span>|</span><label class="collapse" for="c-36414200">[-]</label><label class="expand" for="c-36414200">[2 more]</label></div><br/><div class="children"><div class="content">Not just NLP the whole IA field, see YOLO and NeRF.</div><br/><div id="36414313" class="c"><input type="checkbox" id="c-36414313" checked=""/><div class="controls bullet"><span class="by">SheepHerdr</span><span>|</span><a href="#36414043">root</a><span>|</span><a href="#36414200">parent</a><span>|</span><a href="#36414238">next</a><span>|</span><label class="collapse" for="c-36414313">[-]</label><label class="expand" for="c-36414313">[1 more]</label></div><br/><div class="children"><div class="content">Then there&#x27;s all the sesame street names for NLP models. <a href="https:&#x2F;&#x2F;i.redd.it&#x2F;048rybz0yuv81.png" rel="nofollow noreferrer">https:&#x2F;&#x2F;i.redd.it&#x2F;048rybz0yuv81.png</a></div><br/></div></div></div></div></div></div><div id="36414238" class="c"><input type="checkbox" id="c-36414238" checked=""/><div class="controls bullet"><span class="by">y-curious</span><span>|</span><a href="#36414043">parent</a><span>|</span><a href="#36414072">prev</a><span>|</span><a href="#36414273">next</a><span>|</span><label class="collapse" for="c-36414238">[-]</label><label class="expand" for="c-36414238">[1 more]</label></div><br/><div class="children"><div class="content">Over-simplified requirements for complex topics is all you need</div><br/></div></div></div></div><div id="36414273" class="c"><input type="checkbox" id="c-36414273" checked=""/><div class="controls bullet"><span class="by">elif</span><span>|</span><a href="#36414043">prev</a><span>|</span><label class="collapse" for="c-36414273">[-]</label><label class="expand" for="c-36414273">[2 more]</label></div><br/><div class="children"><div class="content">I bet it still gaslights invented facts.</div><br/></div></div></div></div></div></div></div></body></html>