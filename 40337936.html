<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1715590866519" as="style"/><link rel="stylesheet" href="styles.css?v=1715590866519"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://hazyresearch.stanford.edu/blog/2024-05-12-tk">GPUs Go Brrr</a> <span class="domain">(<a href="https://hazyresearch.stanford.edu">hazyresearch.stanford.edu</a>)</span></div><div class="subtext"><span>nmstoker</span> | <span>104 comments</span></div><br/><div><div id="40338385" class="c"><input type="checkbox" id="c-40338385" checked=""/><div class="controls bullet"><span class="by">Animats</span><span>|</span><a href="#40338794">next</a><span>|</span><label class="collapse" for="c-40338385">[-]</label><label class="expand" for="c-40338385">[27 more]</label></div><br/><div class="children"><div class="content">&quot;<i>And we ask: if your matrix multiply is smaller than 16x16, are you sure what you’re doing is AI?</i><p><i>From a philosophical point of view, we think a frame shift is in order. A “register” certainly shouldn’t be a 32-bit word like on the CPUs of old. And a 1024-bit wide vector register, as CUDA uses, is certainly a step in the right direction. But to us a “register” is a 16x16 tile of data. We think AI wants this.&quot;</i><p>The hardware needs of AI are starting to focus. GPUs, after all, were designed for an entirely different job. They&#x27;re used for AI because they have good matrix multiply hardware. &quot;AI GPUs&quot; get to leave out some of the stuff in a real GPU (does an H100 even have texture fill units?). Then there&#x27;s a trend towards much shorter numbers. 16 bit floating point? 8 bit? 2 bit? 1 bit? That will settle out at some point. This paper indicates that hardware that likes 16x16 tiles makes a lot of sense. It&#x27;s certainly possible to build such hardware. Someone reading this is probably writing it in VHDL right now, or will be soon.<p>Then we&#x27;ll see somewhat simpler, less general, and cheaper devices that do &quot;AI&quot; operations with as little excess hardware baggage as possible. Nice.</div><br/><div id="40339470" class="c"><input type="checkbox" id="c-40339470" checked=""/><div class="controls bullet"><span class="by">bcatanzaro</span><span>|</span><a href="#40338385">parent</a><span>|</span><a href="#40338564">next</a><span>|</span><label class="collapse" for="c-40339470">[-]</label><label class="expand" for="c-40339470">[2 more]</label></div><br/><div class="children"><div class="content">GPUs have evolved to be AI machines with as little baggage as possible. People have been arguing GPUs were old technology and therefore unsuited for AI since at least 2014 (when Nervana was founded), but what they perhaps didn’t expect is that the GPU would evolve so quickly to be an AI machine.</div><br/><div id="40340910" class="c"><input type="checkbox" id="c-40340910" checked=""/><div class="controls bullet"><span class="by">celrod</span><span>|</span><a href="#40338385">root</a><span>|</span><a href="#40339470">parent</a><span>|</span><a href="#40338564">next</a><span>|</span><label class="collapse" for="c-40340910">[-]</label><label class="expand" for="c-40340910">[1 more]</label></div><br/><div class="children"><div class="content">Bill Dally from Nvidia argues that there is &quot;no gain in building a specialized accelerator&quot;, in part because current overhead on top of the arithmetic is in the ballpark of 20% (16% of IMMA and 22% for HMMA units)
<a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=gofI47kfD28" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=gofI47kfD28</a></div><br/></div></div></div></div><div id="40338564" class="c"><input type="checkbox" id="c-40338564" checked=""/><div class="controls bullet"><span class="by">dvt</span><span>|</span><a href="#40338385">parent</a><span>|</span><a href="#40339470">prev</a><span>|</span><a href="#40340626">next</a><span>|</span><label class="collapse" for="c-40338564">[-]</label><label class="expand" for="c-40338564">[6 more]</label></div><br/><div class="children"><div class="content">&gt; Then we&#x27;ll see somewhat simpler, less general, and cheaper devices that do &quot;AI&quot; operations with as little excess hardware baggage as possible. Nice.<p>Apple has already been doing this for a few years now. The NPU is totally different from the GPU or CPU on the die itself[1]. Nvidia is likely working on this as well, but I think a device that&#x27;s a gaming&#x2F;entertainment&#x2F;crypto&#x2F;AI bundle (i.e. sticking with the video card) is probably a better business move.<p>[1] <a href="https:&#x2F;&#x2F;github.com&#x2F;hollance&#x2F;neural-engine&#x2F;blob&#x2F;master&#x2F;docs&#x2F;ane-vs-gpu.md">https:&#x2F;&#x2F;github.com&#x2F;hollance&#x2F;neural-engine&#x2F;blob&#x2F;master&#x2F;docs&#x2F;a...</a></div><br/><div id="40339004" class="c"><input type="checkbox" id="c-40339004" checked=""/><div class="controls bullet"><span class="by">talldayo</span><span>|</span><a href="#40338385">root</a><span>|</span><a href="#40338564">parent</a><span>|</span><a href="#40339696">next</a><span>|</span><label class="collapse" for="c-40339004">[-]</label><label class="expand" for="c-40339004">[3 more]</label></div><br/><div class="children"><div class="content">The NPUs on a lot of different systems occupy an awkward spot. For extremely small models, they&#x27;re the way to go for low-power inference. But once you reach LLM or vision transformer size, it makes a lot more sense to switch to GPU shaders for that extra bit of large-model performance. For stuff like Llama and Stable Diffusion, those Neural Engines are practically wasted silicon. The biggest saving grace is projects like ONNX attempting to sew them into a unified non-15-competing-standards API, but even that won&#x27;t change how underpowered they are.<p>Nvidia escapes this by designing their GPU architecture to incorporate NPU concepts at a fundamental level. It&#x27;s less redundant silicon and enables you to scale a single architecture instead of flip-flopping to whichever one is most convenient.</div><br/><div id="40340306" class="c"><input type="checkbox" id="c-40340306" checked=""/><div class="controls bullet"><span class="by">nxobject</span><span>|</span><a href="#40338385">root</a><span>|</span><a href="#40339004">parent</a><span>|</span><a href="#40339696">next</a><span>|</span><label class="collapse" for="c-40340306">[-]</label><label class="expand" for="c-40340306">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s currently doable for Apple – I think their strategy is to slowly enhance iPhones, bit by bit, with special-purpose models for dealing with media like photo subject identification, OCR (in every language!), voice transcription, etc. Apple&#x27;s currently learning from Microsoft&#x27;s attempts to make AI stick everywhere.</div><br/><div id="40340367" class="c"><input type="checkbox" id="c-40340367" checked=""/><div class="controls bullet"><span class="by">joquarky</span><span>|</span><a href="#40338385">root</a><span>|</span><a href="#40340306">parent</a><span>|</span><a href="#40339696">next</a><span>|</span><label class="collapse" for="c-40340367">[-]</label><label class="expand" for="c-40340367">[1 more]</label></div><br/><div class="children"><div class="content">Soon our phones will dream beside us every night (integrating new data into our personal model while on the charger)</div><br/></div></div></div></div></div></div><div id="40339696" class="c"><input type="checkbox" id="c-40339696" checked=""/><div class="controls bullet"><span class="by">yosefk</span><span>|</span><a href="#40338385">root</a><span>|</span><a href="#40338564">parent</a><span>|</span><a href="#40339004">prev</a><span>|</span><a href="#40339315">next</a><span>|</span><label class="collapse" for="c-40339696">[-]</label><label class="expand" for="c-40339696">[1 more]</label></div><br/><div class="children"><div class="content">For inference, Nvidia has DLA since 2017-ish if I remember correctly, which is completely separate from the GPU.</div><br/></div></div><div id="40339315" class="c"><input type="checkbox" id="c-40339315" checked=""/><div class="controls bullet"><span class="by">eru</span><span>|</span><a href="#40338385">root</a><span>|</span><a href="#40338564">parent</a><span>|</span><a href="#40339696">prev</a><span>|</span><a href="#40340626">next</a><span>|</span><label class="collapse" for="c-40339315">[-]</label><label class="expand" for="c-40339315">[1 more]</label></div><br/><div class="children"><div class="content">And Google has their TPUs.</div><br/></div></div></div></div><div id="40340626" class="c"><input type="checkbox" id="c-40340626" checked=""/><div class="controls bullet"><span class="by">muyuu</span><span>|</span><a href="#40338385">parent</a><span>|</span><a href="#40338564">prev</a><span>|</span><a href="#40338490">next</a><span>|</span><label class="collapse" for="c-40340626">[-]</label><label class="expand" for="c-40340626">[2 more]</label></div><br/><div class="children"><div class="content">it&#x27;s going to be awkward in consumer hardware either way<p>if you segregate AI units from the GPU, the thing is both AI and GPUs will continue  to need massive amounts of matrix multiplication and as little memory latency as possible<p>the move to have more of it wrapped in the GPU makes sense but at least in the short and medium term, most devices won&#x27;t be able to justify the gargantuan silicon wafer space&#x2F;die growth that this would entail - also currently Nvidia&#x27;s tech is ahead and they don&#x27;t make state of the art x86 or ARM CPUs<p>for the time being I think the current paradigm makes the most sense, with small compute devices making inroads in the consumer markets as non-generalist computers - note that more AI-oriented pseudo-GPUs already exist and are successful since the earlier Nvidia Tesla lineup and then the so-called &quot;Nvidia Data Center GPUs&quot;</div><br/><div id="40340994" class="c"><input type="checkbox" id="c-40340994" checked=""/><div class="controls bullet"><span class="by">rfoo</span><span>|</span><a href="#40338385">root</a><span>|</span><a href="#40340626">parent</a><span>|</span><a href="#40338490">next</a><span>|</span><label class="collapse" for="c-40340994">[-]</label><label class="expand" for="c-40340994">[1 more]</label></div><br/><div class="children"><div class="content">&gt; as little memory latency as possible<p>Should be &quot;as much memory bandwidth as possible&quot;. GPUs are designed to be (relatively) more insensitive to memory latency than CPU.</div><br/></div></div></div></div><div id="40338490" class="c"><input type="checkbox" id="c-40338490" checked=""/><div class="controls bullet"><span class="by">mvkel</span><span>|</span><a href="#40338385">parent</a><span>|</span><a href="#40340626">prev</a><span>|</span><a href="#40339278">next</a><span>|</span><label class="collapse" for="c-40338490">[-]</label><label class="expand" for="c-40338490">[5 more]</label></div><br/><div class="children"><div class="content">Would you say this is ultimately &quot;ASICs for AI&quot;?</div><br/><div id="40338562" class="c"><input type="checkbox" id="c-40338562" checked=""/><div class="controls bullet"><span class="by">dartos</span><span>|</span><a href="#40338385">root</a><span>|</span><a href="#40338490">parent</a><span>|</span><a href="#40339278">next</a><span>|</span><label class="collapse" for="c-40338562">[-]</label><label class="expand" for="c-40338562">[4 more]</label></div><br/><div class="children"><div class="content">In the same way that CPUs are ASICs for integer operations, that makes sense to me.</div><br/><div id="40340215" class="c"><input type="checkbox" id="c-40340215" checked=""/><div class="controls bullet"><span class="by">saagarjha</span><span>|</span><a href="#40338385">root</a><span>|</span><a href="#40338562">parent</a><span>|</span><a href="#40339558">next</a><span>|</span><label class="collapse" for="c-40340215">[-]</label><label class="expand" for="c-40340215">[2 more]</label></div><br/><div class="children"><div class="content">Most CPUs do just fine on floating point too.</div><br/><div id="40340606" class="c"><input type="checkbox" id="c-40340606" checked=""/><div class="controls bullet"><span class="by">actionfromafar</span><span>|</span><a href="#40338385">root</a><span>|</span><a href="#40340215">parent</a><span>|</span><a href="#40339558">next</a><span>|</span><label class="collapse" for="c-40340606">[-]</label><label class="expand" for="c-40340606">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m still getting used to that.</div><br/></div></div></div></div></div></div></div></div><div id="40338568" class="c"><input type="checkbox" id="c-40338568" checked=""/><div class="controls bullet"><span class="by">WanderPanda</span><span>|</span><a href="#40338385">parent</a><span>|</span><a href="#40339278">prev</a><span>|</span><a href="#40338963">next</a><span>|</span><label class="collapse" for="c-40338568">[-]</label><label class="expand" for="c-40338568">[5 more]</label></div><br/><div class="children"><div class="content">Wait but nvidia tensor-cores are exactly the hardware that likes 16x16 tiles, no? I thought that was the whole point? The hardware is already here and I&#x27;m sceptical if there is another order of magnitude in performance to be gained from even more specialized designs.</div><br/><div id="40338961" class="c"><input type="checkbox" id="c-40338961" checked=""/><div class="controls bullet"><span class="by">wtallis</span><span>|</span><a href="#40338385">root</a><span>|</span><a href="#40338568">parent</a><span>|</span><a href="#40338963">next</a><span>|</span><label class="collapse" for="c-40338961">[-]</label><label class="expand" for="c-40338961">[4 more]</label></div><br/><div class="children"><div class="content">What&#x27;s the ratio of tensor cores to regular SIMD compute (&quot;CUDA cores&quot;) on NVIDIA&#x27;s current chips?</div><br/><div id="40339844" class="c"><input type="checkbox" id="c-40339844" checked=""/><div class="controls bullet"><span class="by">creato</span><span>|</span><a href="#40338385">root</a><span>|</span><a href="#40338961">parent</a><span>|</span><a href="#40338963">next</a><span>|</span><label class="collapse" for="c-40339844">[-]</label><label class="expand" for="c-40339844">[3 more]</label></div><br/><div class="children"><div class="content">This is in the article: if you aren&#x27;t using the tensor cores, you aren&#x27;t utilizing ~94% of the FLOPs available.</div><br/><div id="40340508" class="c"><input type="checkbox" id="c-40340508" checked=""/><div class="controls bullet"><span class="by">wtallis</span><span>|</span><a href="#40338385">root</a><span>|</span><a href="#40339844">parent</a><span>|</span><a href="#40340923">next</a><span>|</span><label class="collapse" for="c-40340508">[-]</label><label class="expand" for="c-40340508">[1 more]</label></div><br/><div class="children"><div class="content">Knowing what portion of the FLOPs are in the tensor cores isn&#x27;t quite the right thing to be looking at. The key question is how much more tensor core performance can be gained by reducing or eliminating the dies area devoted to non-tensor compute and higher precision arithmetic. Most of NVIDIA&#x27;s GPUs are still designed primarily for graphics: they have some fixed function units that can be deleted in an AI-only chip, and a lot of die space devoted to non-tensor compute because the tensor cores don&#x27;t naturally lend themselves to graphics work (though NVIDIA has spent years coming up with ways to not leave the tensor cores dark during graphics work, most notably DLSS).<p>So the claims that NVIDIA&#x27;s GPUs are already thoroughly optimized for AI and that there&#x27;s no low-hanging fruit for further specialization don&#x27;t seem too plausible, unless you&#x27;re only talking about the part of the datacenter lineup that has already had nearly all fixed-function graphics hardware excised. And even for Hopper and Blackwell, there&#x27;s some fat to be trimmed if you can narrow your requirements.</div><br/></div></div><div id="40340923" class="c"><input type="checkbox" id="c-40340923" checked=""/><div class="controls bullet"><span class="by">Sharlin</span><span>|</span><a href="#40338385">root</a><span>|</span><a href="#40339844">parent</a><span>|</span><a href="#40340508">prev</a><span>|</span><a href="#40338963">next</a><span>|</span><label class="collapse" for="c-40340923">[-]</label><label class="expand" for="c-40340923">[1 more]</label></div><br/><div class="children"><div class="content">On the H100 specifically. The figure is likely different on consumer cards.</div><br/></div></div></div></div></div></div></div></div><div id="40338963" class="c"><input type="checkbox" id="c-40338963" checked=""/><div class="controls bullet"><span class="by">choppaface</span><span>|</span><a href="#40338385">parent</a><span>|</span><a href="#40338568">prev</a><span>|</span><a href="#40339443">next</a><span>|</span><label class="collapse" for="c-40338963">[-]</label><label class="expand" for="c-40338963">[3 more]</label></div><br/><div class="children"><div class="content">“NVidia’s LIES..<p>On kernels such as flash attention, TMA and the L2 cache are both fast enough so as to hide these problems reasonably well. But to make the full use of the hardware, memory request must be coalesced and bank conflicts avoided
”<p>The depth of the competition is also starting to become apparent.  There’s no way the documentation error was totally an accident.  Diagrams are the easiest to steal &#x2F; copy and there must have been some utility for nvidia to have left this in place.  Remember when Naveen Rao’s Nervana was writing NVidia Maxwell drivers that out-performed NVidia’s own? Not every documentation mishap in a high-growth product is a competition counter-measure, but given that the researchers spent so long reverse-engineering wgmma and given the China-US political situation of the H100 in particular, it seems NVidia is up to its old tricks to protect its moat.<p>So don’t over-study the H100 peculiarities, as “what hardware does AI want?” really encompasses the commercial situation as well.</div><br/><div id="40340477" class="c"><input type="checkbox" id="c-40340477" checked=""/><div class="controls bullet"><span class="by">wiz21c</span><span>|</span><a href="#40338385">root</a><span>|</span><a href="#40338963">parent</a><span>|</span><a href="#40339443">next</a><span>|</span><label class="collapse" for="c-40340477">[-]</label><label class="expand" for="c-40340477">[2 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t understand. If they document their stuff with errors, it will hurt users, be they chinese or US ? Or is it expected that US users will call Nvidia&#x27;s to ask for the correct documentation ?</div><br/><div id="40341058" class="c"><input type="checkbox" id="c-40341058" checked=""/><div class="controls bullet"><span class="by">acka</span><span>|</span><a href="#40338385">root</a><span>|</span><a href="#40340477">parent</a><span>|</span><a href="#40339443">next</a><span>|</span><label class="collapse" for="c-40341058">[-]</label><label class="expand" for="c-40341058">[1 more]</label></div><br/><div class="children"><div class="content">It could be a case of classic market segmentation. The lower tier customers get the incomplete or error ridden documentation, and the upper tier trusted customers^W&#x27;partners&#x27; get access to the juicy stuff: complete and mostly correct documentation, including stuff intentionally left out of the lower tier package like essential application notes. All under strict NDA of course.</div><br/></div></div></div></div></div></div><div id="40339443" class="c"><input type="checkbox" id="c-40339443" checked=""/><div class="controls bullet"><span class="by">jiveturkey</span><span>|</span><a href="#40338385">parent</a><span>|</span><a href="#40338963">prev</a><span>|</span><a href="#40338794">next</a><span>|</span><label class="collapse" for="c-40339443">[-]</label><label class="expand" for="c-40339443">[2 more]</label></div><br/><div class="children"><div class="content">hasn&#x27;t google been building such devices for a decade now?</div><br/><div id="40340714" class="c"><input type="checkbox" id="c-40340714" checked=""/><div class="controls bullet"><span class="by">yayr</span><span>|</span><a href="#40338385">root</a><span>|</span><a href="#40339443">parent</a><span>|</span><a href="#40338794">next</a><span>|</span><label class="collapse" for="c-40340714">[-]</label><label class="expand" for="c-40340714">[1 more]</label></div><br/><div class="children"><div class="content">yep, and the main engineers have founded groq.com with an architecture that among others precisely solved the memory management issues</div><br/></div></div></div></div></div></div><div id="40338794" class="c"><input type="checkbox" id="c-40338794" checked=""/><div class="controls bullet"><span class="by">renonce</span><span>|</span><a href="#40338385">prev</a><span>|</span><a href="#40340436">next</a><span>|</span><label class="collapse" for="c-40338794">[-]</label><label class="expand" for="c-40338794">[4 more]</label></div><br/><div class="children"><div class="content">&gt; NVIDIA’s lies. This is an extraordinarily misleading representation of the actual 128b swizzled wgmma layout. This diagram cost us three weeks of life that we will not get back, hence the public shaming.<p>Wondering if anyone would be surprised that a huge amount of progress in AI is on the engineering side (optimizing matmuls), and that a huge portion of the engineering is about reverse engineering NVIDIA chips</div><br/><div id="40340549" class="c"><input type="checkbox" id="c-40340549" checked=""/><div class="controls bullet"><span class="by">DeathArrow</span><span>|</span><a href="#40338794">parent</a><span>|</span><a href="#40340436">next</a><span>|</span><label class="collapse" for="c-40340549">[-]</label><label class="expand" for="c-40340549">[3 more]</label></div><br/><div class="children"><div class="content">Architecture doesn&#x27;t make a difference. Big enough models trained with big enough data tend to give the same results regardless of architecture. So yes, most advances in AI are mostly due to the fact we can now multiply matrices very fast.</div><br/><div id="40340719" class="c"><input type="checkbox" id="c-40340719" checked=""/><div class="controls bullet"><span class="by">elcomet</span><span>|</span><a href="#40338794">root</a><span>|</span><a href="#40340549">parent</a><span>|</span><a href="#40340436">next</a><span>|</span><label class="collapse" for="c-40340719">[-]</label><label class="expand" for="c-40340719">[2 more]</label></div><br/><div class="children"><div class="content">That&#x27;s not completely true. The architecture must behave well for scaling, which is not trivial. Basic multi-layer perceptrons do not scale well for example, the gradient will vanish or explode deeper in the network.</div><br/><div id="40340884" class="c"><input type="checkbox" id="c-40340884" checked=""/><div class="controls bullet"><span class="by">3abiton</span><span>|</span><a href="#40338794">root</a><span>|</span><a href="#40340719">parent</a><span>|</span><a href="#40340436">next</a><span>|</span><label class="collapse" for="c-40340884">[-]</label><label class="expand" for="c-40340884">[1 more]</label></div><br/><div class="children"><div class="content">And data quality. Ensuring the sourcing and quality is very important to get a good model.</div><br/></div></div></div></div></div></div></div></div><div id="40340436" class="c"><input type="checkbox" id="c-40340436" checked=""/><div class="controls bullet"><span class="by">diginova</span><span>|</span><a href="#40338794">prev</a><span>|</span><a href="#40338283">next</a><span>|</span><label class="collapse" for="c-40340436">[-]</label><label class="expand" for="c-40340436">[2 more]</label></div><br/><div class="children"><div class="content">What should I do if I want to understand such articles in complete? where to start on the roadmap?</div><br/><div id="40340546" class="c"><input type="checkbox" id="c-40340546" checked=""/><div class="controls bullet"><span class="by">kolinko</span><span>|</span><a href="#40340436">parent</a><span>|</span><a href="#40338283">next</a><span>|</span><label class="collapse" for="c-40340546">[-]</label><label class="expand" for="c-40340546">[1 more]</label></div><br/><div class="children"><div class="content">This is a good course on gpu programming. Around 4.0 lesson you’ll get the required basics: <a href="https:&#x2F;&#x2F;youtube.com&#x2F;playlist?list=PLzn6LN6WhlN06hIOA_ge6SrgdeSiuf9Tb&amp;si=CE4C7wrkz55YCUqG" rel="nofollow">https:&#x2F;&#x2F;youtube.com&#x2F;playlist?list=PLzn6LN6WhlN06hIOA_ge6Srgd...</a><p>Also, write your own cuda kernel to do vector-matrix multiplication (if you use pycuda, you can focus on the kernel, and write everything else with python). Just tell chatgpt that you want to write your own implementation that multiplies a 4000-element vector by 4000x12000 matrix, and to guide you through the whole process.<p>For renting gpus, runpods is great - right now they have everything from lower tier gpus to h100s. You can start with a lesser gpu at the beginning.</div><br/></div></div></div></div><div id="40338283" class="c"><input type="checkbox" id="c-40338283" checked=""/><div class="controls bullet"><span class="by">perfmode</span><span>|</span><a href="#40340436">prev</a><span>|</span><a href="#40339279">next</a><span>|</span><label class="collapse" for="c-40338283">[-]</label><label class="expand" for="c-40338283">[2 more]</label></div><br/><div class="children"><div class="content">This article rekindles the joy I experienced during CS 149 Parallel Programming.</div><br/><div id="40340118" class="c"><input type="checkbox" id="c-40340118" checked=""/><div class="controls bullet"><span class="by">figbert</span><span>|</span><a href="#40338283">parent</a><span>|</span><a href="#40339279">next</a><span>|</span><label class="collapse" for="c-40340118">[-]</label><label class="expand" for="c-40340118">[1 more]</label></div><br/><div class="children"><div class="content">Appreciate the recommendation, will check out the course!</div><br/></div></div></div></div><div id="40339279" class="c"><input type="checkbox" id="c-40339279" checked=""/><div class="controls bullet"><span class="by">latchkey</span><span>|</span><a href="#40338283">prev</a><span>|</span><a href="#40340761">next</a><span>|</span><label class="collapse" for="c-40339279">[-]</label><label class="expand" for="c-40339279">[5 more]</label></div><br/><div class="children"><div class="content">Really impressed by the writing style of this post and very much looking forward to this on AMD MI300x. Let me know if you want some time on mine.</div><br/><div id="40340736" class="c"><input type="checkbox" id="c-40340736" checked=""/><div class="controls bullet"><span class="by">globular-toast</span><span>|</span><a href="#40339279">parent</a><span>|</span><a href="#40339924">next</a><span>|</span><label class="collapse" for="c-40340736">[-]</label><label class="expand" for="c-40340736">[1 more]</label></div><br/><div class="children"><div class="content">Good writing is clear and unambiguous. With speech there is an opportunity to interrupt and ask for clarification. Writing has one chance to get the message across. A reader shouldn&#x27;t have to consult knowyourmeme.com to figure out what the heck the authors are trying to say. I don&#x27;t even know what the title means here. That&#x27;s how far they&#x27;ve missed the mark.</div><br/></div></div><div id="40339924" class="c"><input type="checkbox" id="c-40339924" checked=""/><div class="controls bullet"><span class="by">jsemrau</span><span>|</span><a href="#40339279">parent</a><span>|</span><a href="#40340736">prev</a><span>|</span><a href="#40340761">next</a><span>|</span><label class="collapse" for="c-40339924">[-]</label><label class="expand" for="c-40339924">[3 more]</label></div><br/><div class="children"><div class="content">Really? It gives me PTSD from the Wallstreetbets days.</div><br/><div id="40340036" class="c"><input type="checkbox" id="c-40340036" checked=""/><div class="controls bullet"><span class="by">forrestthewoods</span><span>|</span><a href="#40339279">root</a><span>|</span><a href="#40339924">parent</a><span>|</span><a href="#40340761">next</a><span>|</span><label class="collapse" for="c-40340036">[-]</label><label class="expand" for="c-40340036">[2 more]</label></div><br/><div class="children"><div class="content">I also enjoyed the article&#x27;s style. I utterly despise &quot;academic paper speak&quot;. It is, imho, not the most effective style to communicate complex ideas. I find it so much easier to learn from a more casual &quot;blog post&quot; or in-person presentation over stiff, rigid academic speak.</div><br/><div id="40340144" class="c"><input type="checkbox" id="c-40340144" checked=""/><div class="controls bullet"><span class="by">kaycey2022</span><span>|</span><a href="#40339279">root</a><span>|</span><a href="#40340036">parent</a><span>|</span><a href="#40340761">next</a><span>|</span><label class="collapse" for="c-40340144">[-]</label><label class="expand" for="c-40340144">[1 more]</label></div><br/><div class="children"><div class="content">I find both to be useful in different stages. The casual style is very helpful when starting out. But once I have put in a few weeks or months of study in, then the rigor and preciseness of academic style is good as well.<p>I agree with you in the sense that something has &quot;died&quot; in writings the follow academic paper speak these days. Just yesterday I saw an ancient article surfaced by Scientific American and Peter Norvig on System Analysis by Strachey. It uses quite a bit of formal language but is super approachable at the same time. That kind of skill is rarely seen these days.</div><br/></div></div></div></div></div></div></div></div><div id="40340761" class="c"><input type="checkbox" id="c-40340761" checked=""/><div class="controls bullet"><span class="by">imiric</span><span>|</span><a href="#40339279">prev</a><span>|</span><a href="#40338624">next</a><span>|</span><label class="collapse" for="c-40340761">[-]</label><label class="expand" for="c-40340761">[1 more]</label></div><br/><div class="children"><div class="content">Hasn&#x27;t this research been done by teams building NPUs today? E.g. chips built by Groq use an architecture built specifically for AI, which is why they&#x27;re able to deliver the performance they do. On the consumer side, Apple silicon is also quite capable.<p>I&#x27;m not in this field at all, but it seems to me that using general purpose processors that communicate over (relatively) slow lanes can only get us so far. Rethinking the design at the hardware level, and eventually bringing the price down for the consumer market seems like a better long-term strategy.</div><br/></div></div><div id="40338624" class="c"><input type="checkbox" id="c-40338624" checked=""/><div class="controls bullet"><span class="by">phinnaeus</span><span>|</span><a href="#40340761">prev</a><span>|</span><a href="#40338596">next</a><span>|</span><label class="collapse" for="c-40338624">[-]</label><label class="expand" for="c-40338624">[15 more]</label></div><br/><div class="children"><div class="content">FYI the caption of the &quot;spirit animals&quot; image says &quot;canadian goose&quot; instead of &quot;Canada Goose&quot;.</div><br/><div id="40340738" class="c"><input type="checkbox" id="c-40340738" checked=""/><div class="controls bullet"><span class="by">silisili</span><span>|</span><a href="#40338624">parent</a><span>|</span><a href="#40340057">next</a><span>|</span><label class="collapse" for="c-40340738">[-]</label><label class="expand" for="c-40340738">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve only heard people in my entire lifetime call them Canadian Geese.<p>The only time I&#x27;ve ever even seen or heard of Canada Goose&#x2F;Geese are people on the internet telling others they are wrong.<p>I think it&#x27;s time to just accept it as correct.</div><br/><div id="40341090" class="c"><input type="checkbox" id="c-40341090" checked=""/><div class="controls bullet"><span class="by">FearNotDaniel</span><span>|</span><a href="#40338624">root</a><span>|</span><a href="#40340738">parent</a><span>|</span><a href="#40340057">next</a><span>|</span><label class="collapse" for="c-40341090">[-]</label><label class="expand" for="c-40341090">[1 more]</label></div><br/><div class="children"><div class="content">Absolutely, it&#x27;s like living in London and eventually having to accept that tourists will always say &quot;Big Ben&quot; when they mean the clock tower of the Palace of Westminster, which encloses the bell whose actual name is Big Ben. The name of the tower is, de facto, Big Ben, and life gets so much easier when you drop the urge to tell people they are wrong all the time...<p>Edit: TIL the tower was properly renamed &quot;Elizabeth Tower&quot; in 2012 [0] but I seriously doubt a single person in the last 12 years has ever used that name...<p>[0] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Big_Ben" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Big_Ben</a></div><br/></div></div></div></div><div id="40340057" class="c"><input type="checkbox" id="c-40340057" checked=""/><div class="controls bullet"><span class="by">xarope</span><span>|</span><a href="#40338624">parent</a><span>|</span><a href="#40340738">prev</a><span>|</span><a href="#40338966">next</a><span>|</span><label class="collapse" for="c-40340057">[-]</label><label class="expand" for="c-40340057">[1 more]</label></div><br/><div class="children"><div class="content">I am missing the reference to the canadian goose and the retriever puppy as spirit animals.  Is that to say the H100 is an ornery thing, but the RTX4090 is friendly?</div><br/></div></div><div id="40338966" class="c"><input type="checkbox" id="c-40338966" checked=""/><div class="controls bullet"><span class="by">adzm</span><span>|</span><a href="#40338624">parent</a><span>|</span><a href="#40340057">prev</a><span>|</span><a href="#40338924">next</a><span>|</span><label class="collapse" for="c-40338966">[-]</label><label class="expand" for="c-40338966">[1 more]</label></div><br/><div class="children"><div class="content">Likely a regional thing; they are consistently called Canadian Geese where I grew up and where I currently live.</div><br/></div></div><div id="40338924" class="c"><input type="checkbox" id="c-40338924" checked=""/><div class="controls bullet"><span class="by">downrightmike</span><span>|</span><a href="#40338624">parent</a><span>|</span><a href="#40338966">prev</a><span>|</span><a href="#40339729">next</a><span>|</span><label class="collapse" for="c-40338924">[-]</label><label class="expand" for="c-40338924">[1 more]</label></div><br/><div class="children"><div class="content">Don&#x27;t worry, the Geese are en route to location, resolution incoming. Stand by.</div><br/></div></div><div id="40339729" class="c"><input type="checkbox" id="c-40339729" checked=""/><div class="controls bullet"><span class="by">bombcar</span><span>|</span><a href="#40338624">parent</a><span>|</span><a href="#40338924">prev</a><span>|</span><a href="#40340581">next</a><span>|</span><label class="collapse" for="c-40339729">[-]</label><label class="expand" for="c-40339729">[2 more]</label></div><br/><div class="children"><div class="content">It’s a Canada Goose from Canada. A Canadian Canada Goose, or Canadian Goose.</div><br/><div id="40339953" class="c"><input type="checkbox" id="c-40339953" checked=""/><div class="controls bullet"><span class="by">gosub100</span><span>|</span><a href="#40338624">root</a><span>|</span><a href="#40339729">parent</a><span>|</span><a href="#40340581">next</a><span>|</span><label class="collapse" for="c-40339953">[-]</label><label class="expand" for="c-40339953">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Buffalo_buffalo_Buffalo_buffalo_buffalo_buffalo_Buffalo_buffalo" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Buffalo_buffalo_Buffalo_buffal...</a></div><br/></div></div></div></div><div id="40340581" class="c"><input type="checkbox" id="c-40340581" checked=""/><div class="controls bullet"><span class="by">bn-l</span><span>|</span><a href="#40338624">parent</a><span>|</span><a href="#40339729">prev</a><span>|</span><a href="#40338901">next</a><span>|</span><label class="collapse" for="c-40340581">[-]</label><label class="expand" for="c-40340581">[1 more]</label></div><br/><div class="children"><div class="content">Who cares</div><br/></div></div><div id="40338901" class="c"><input type="checkbox" id="c-40338901" checked=""/><div class="controls bullet"><span class="by">wglb</span><span>|</span><a href="#40338624">parent</a><span>|</span><a href="#40340581">prev</a><span>|</span><a href="#40338703">next</a><span>|</span><label class="collapse" for="c-40338901">[-]</label><label class="expand" for="c-40338901">[1 more]</label></div><br/><div class="children"><div class="content">An error too often made.</div><br/></div></div><div id="40338703" class="c"><input type="checkbox" id="c-40338703" checked=""/><div class="controls bullet"><span class="by">fastball</span><span>|</span><a href="#40338624">parent</a><span>|</span><a href="#40338901">prev</a><span>|</span><a href="#40340545">next</a><span>|</span><label class="collapse" for="c-40338703">[-]</label><label class="expand" for="c-40338703">[1 more]</label></div><br/><div class="children"><div class="content">Canadian goose seems better in [current year], to avoid confusion with the clothing brand.</div><br/></div></div><div id="40340545" class="c"><input type="checkbox" id="c-40340545" checked=""/><div class="controls bullet"><span class="by">adrian_b</span><span>|</span><a href="#40338624">parent</a><span>|</span><a href="#40338703">prev</a><span>|</span><a href="#40338596">next</a><span>|</span><label class="collapse" for="c-40340545">[-]</label><label class="expand" for="c-40340545">[4 more]</label></div><br/><div class="children"><div class="content">I consider bad the habit of English to use nouns also as adjectives, because it causes many ambiguities, some of which can be very annoying, even if they are a rich source of jokes and word plays.<p>In most languages the use of a noun as an adjective is marked, by a particle or by an affix or at least by a different stress pattern (like moving the stress to the last syllable), which removes the ambiguities.<p>So for most non-native speakers &quot;Canadian goose&quot; makes much more sense than &quot;Canada goose&quot; (which may feel like &quot;Canada and a goose&quot; or &quot;a goose that is also Canada&quot; and not like &quot;a goose from Canada&quot;).</div><br/><div id="40340671" class="c"><input type="checkbox" id="c-40340671" checked=""/><div class="controls bullet"><span class="by">p0w3n3d</span><span>|</span><a href="#40338624">root</a><span>|</span><a href="#40340545">parent</a><span>|</span><a href="#40340632">next</a><span>|</span><label class="collapse" for="c-40340671">[-]</label><label class="expand" for="c-40340671">[1 more]</label></div><br/><div class="children"><div class="content">always the former noun is describing the latter. Butter fly is not a flying butter (as my children&#x27;s teacher told them to make a joke about butterfly) but a fly made of butter instead.</div><br/></div></div><div id="40340632" class="c"><input type="checkbox" id="c-40340632" checked=""/><div class="controls bullet"><span class="by">kitd</span><span>|</span><a href="#40338624">root</a><span>|</span><a href="#40340545">parent</a><span>|</span><a href="#40340671">prev</a><span>|</span><a href="#40340631">next</a><span>|</span><label class="collapse" for="c-40340632">[-]</label><label class="expand" for="c-40340632">[1 more]</label></div><br/><div class="children"><div class="content">&quot;Canada&quot; isn&#x27;t being used as an adjective though. The name of the species is &quot;Canada Goose&quot;, like &quot;Long Island Shellfish&quot; or &quot;Dublin Bay Prawns&quot;.</div><br/></div></div><div id="40340631" class="c"><input type="checkbox" id="c-40340631" checked=""/><div class="controls bullet"><span class="by">actionfromafar</span><span>|</span><a href="#40338624">root</a><span>|</span><a href="#40340545">parent</a><span>|</span><a href="#40340632">prev</a><span>|</span><a href="#40338596">next</a><span>|</span><label class="collapse" for="c-40340631">[-]</label><label class="expand" for="c-40340631">[1 more]</label></div><br/><div class="children"><div class="content">Now you made me think of ways to English Adjective my text for word play... make it stop.</div><br/></div></div></div></div></div></div><div id="40338596" class="c"><input type="checkbox" id="c-40338596" checked=""/><div class="controls bullet"><span class="by">WanderPanda</span><span>|</span><a href="#40338624">prev</a><span>|</span><a href="#40340558">next</a><span>|</span><label class="collapse" for="c-40338596">[-]</label><label class="expand" for="c-40338596">[1 more]</label></div><br/><div class="children"><div class="content">Is this &quot;just&quot; CUTLASS in user friendly?</div><br/></div></div><div id="40340558" class="c"><input type="checkbox" id="c-40340558" checked=""/><div class="controls bullet"><span class="by">DeathArrow</span><span>|</span><a href="#40338596">prev</a><span>|</span><a href="#40337950">next</a><span>|</span><label class="collapse" for="c-40340558">[-]</label><label class="expand" for="c-40340558">[1 more]</label></div><br/><div class="children"><div class="content">So do their kernels and library also speed up RTX 4090?</div><br/></div></div><div id="40337950" class="c"><input type="checkbox" id="c-40337950" checked=""/><div class="controls bullet"><span class="by">nmstoker</span><span>|</span><a href="#40340558">prev</a><span>|</span><a href="#40338713">next</a><span>|</span><label class="collapse" for="c-40337950">[-]</label><label class="expand" for="c-40337950">[1 more]</label></div><br/><div class="children"><div class="content">Some related material here too:<p><a href="https:&#x2F;&#x2F;twitter.com&#x2F;bfspector&#x2F;status&#x2F;1789749117104894179?t=kruiIMW5J9cDq_RNrHHINg&amp;s=19" rel="nofollow">https:&#x2F;&#x2F;twitter.com&#x2F;bfspector&#x2F;status&#x2F;1789749117104894179?t=k...</a></div><br/></div></div><div id="40338713" class="c"><input type="checkbox" id="c-40338713" checked=""/><div class="controls bullet"><span class="by">apsec112</span><span>|</span><a href="#40337950">prev</a><span>|</span><a href="#40338235">next</a><span>|</span><label class="collapse" for="c-40338713">[-]</label><label class="expand" for="c-40338713">[1 more]</label></div><br/><div class="children"><div class="content">Interesting! Would this support fp8? Does anyone know how it would compare to Triton?</div><br/></div></div><div id="40338235" class="c"><input type="checkbox" id="c-40338235" checked=""/><div class="controls bullet"><span class="by">jauntywundrkind</span><span>|</span><a href="#40338713">prev</a><span>|</span><a href="#40339633">next</a><span>|</span><label class="collapse" for="c-40338235">[-]</label><label class="expand" for="c-40338235">[4 more]</label></div><br/><div class="children"><div class="content">The ThunderKittens mascot has great kitten&#x2F;Sony-Aibo vibes. Nicely generated, AI (I presume). <a href="https:&#x2F;&#x2F;github.com&#x2F;HazyResearch&#x2F;ThunderKittens">https:&#x2F;&#x2F;github.com&#x2F;HazyResearch&#x2F;ThunderKittens</a></div><br/><div id="40338370" class="c"><input type="checkbox" id="c-40338370" checked=""/><div class="controls bullet"><span class="by">layer8</span><span>|</span><a href="#40338235">parent</a><span>|</span><a href="#40339633">next</a><span>|</span><label class="collapse" for="c-40338370">[-]</label><label class="expand" for="c-40338370">[3 more]</label></div><br/><div class="children"><div class="content">It looks off because the head isn’t centered on the neck.</div><br/><div id="40340120" class="c"><input type="checkbox" id="c-40340120" checked=""/><div class="controls bullet"><span class="by">Satam</span><span>|</span><a href="#40338235">root</a><span>|</span><a href="#40338370">parent</a><span>|</span><a href="#40339761">next</a><span>|</span><label class="collapse" for="c-40340120">[-]</label><label class="expand" for="c-40340120">[1 more]</label></div><br/><div class="children"><div class="content">Easy fix: <a href="https:&#x2F;&#x2F;imgur.com&#x2F;a&#x2F;Ahwt6tr" rel="nofollow">https:&#x2F;&#x2F;imgur.com&#x2F;a&#x2F;Ahwt6tr</a> (although not sure which one is actually better)</div><br/></div></div><div id="40339761" class="c"><input type="checkbox" id="c-40339761" checked=""/><div class="controls bullet"><span class="by">john_minsk</span><span>|</span><a href="#40338235">root</a><span>|</span><a href="#40338370">parent</a><span>|</span><a href="#40340120">prev</a><span>|</span><a href="#40339633">next</a><span>|</span><label class="collapse" for="c-40339761">[-]</label><label class="expand" for="c-40339761">[1 more]</label></div><br/><div class="children"><div class="content">Great attention to detail! I, like the parent, was surprised by the quality as well. However now I can&#x27;t unsee it:-)</div><br/></div></div></div></div></div></div><div id="40339633" class="c"><input type="checkbox" id="c-40339633" checked=""/><div class="controls bullet"><span class="by">brcmthrowaway</span><span>|</span><a href="#40338235">prev</a><span>|</span><a href="#40340570">next</a><span>|</span><label class="collapse" for="c-40339633">[-]</label><label class="expand" for="c-40339633">[11 more]</label></div><br/><div class="children"><div class="content">NVIDIA needs to be broken up</div><br/><div id="40340749" class="c"><input type="checkbox" id="c-40340749" checked=""/><div class="controls bullet"><span class="by">silveraxe93</span><span>|</span><a href="#40339633">parent</a><span>|</span><a href="#40339837">next</a><span>|</span><label class="collapse" for="c-40340749">[-]</label><label class="expand" for="c-40340749">[1 more]</label></div><br/><div class="children"><div class="content">NVIDIA is so damn good at its job that it took over the market.
There&#x27;s no regulatory or similar barriers to entry. It&#x27;s literally that they do a damn good job and the competition can&#x27;t be as good.<p>You look at that and want to take a sledgehammer to a golden goose? I don&#x27;t get these people</div><br/></div></div><div id="40339837" class="c"><input type="checkbox" id="c-40339837" checked=""/><div class="controls bullet"><span class="by">latchkey</span><span>|</span><a href="#40339633">parent</a><span>|</span><a href="#40340749">prev</a><span>|</span><a href="#40339741">next</a><span>|</span><label class="collapse" for="c-40339837">[-]</label><label class="expand" for="c-40339837">[7 more]</label></div><br/><div class="children"><div class="content">The better alternative is to root for AMD and others to develop their own products so that regardless of breaking NV up or not, there are alternative solutions for people to use. They all leapfrog each other with new releases now any way. Why put all your eggs into one basket.</div><br/><div id="40339969" class="c"><input type="checkbox" id="c-40339969" checked=""/><div class="controls bullet"><span class="by">simondotau</span><span>|</span><a href="#40339633">root</a><span>|</span><a href="#40339837">parent</a><span>|</span><a href="#40339741">next</a><span>|</span><label class="collapse" for="c-40339969">[-]</label><label class="expand" for="c-40339969">[6 more]</label></div><br/><div class="children"><div class="content">George Hotz went down the AMD rabbit hole for a while and concluded that the driver software — more precisely the firmware which runs on the cards themselves — is so badly written that there&#x27;s no hope of them becoming serious contenders in AI without some major changes in AMD&#x27;s priorities.</div><br/><div id="40340355" class="c"><input type="checkbox" id="c-40340355" checked=""/><div class="controls bullet"><span class="by">callalex</span><span>|</span><a href="#40339633">root</a><span>|</span><a href="#40339969">parent</a><span>|</span><a href="#40340100">next</a><span>|</span><label class="collapse" for="c-40340355">[-]</label><label class="expand" for="c-40340355">[1 more]</label></div><br/><div class="children"><div class="content">Egohotz is brilliant in many ways, but taking him at his word when it comes to working with others has been a mistake since at least around 2010. This is well documented.</div><br/></div></div><div id="40340100" class="c"><input type="checkbox" id="c-40340100" checked=""/><div class="controls bullet"><span class="by">latchkey</span><span>|</span><a href="#40339633">root</a><span>|</span><a href="#40339969">parent</a><span>|</span><a href="#40340355">prev</a><span>|</span><a href="#40339741">next</a><span>|</span><label class="collapse" for="c-40340100">[-]</label><label class="expand" for="c-40340100">[4 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not defending their software. It does honestly have a ton of issues.<p>George Hotz tried to get a consumer card to work. He also refused my public invitations to have free time on my enterprise cards, calling me an AMD shill.<p>AMD listened and responded to him and gave him even the difficult things that he was demanding. He has the tools to make it work now and if he needs more, AMD already seems willing to give it. That is progress.<p>To simply throw out George as the be-all and end-all of a $245B company... frankly absurd.</div><br/><div id="40340347" class="c"><input type="checkbox" id="c-40340347" checked=""/><div class="controls bullet"><span class="by">creato</span><span>|</span><a href="#40339633">root</a><span>|</span><a href="#40340100">parent</a><span>|</span><a href="#40340324">next</a><span>|</span><label class="collapse" for="c-40340347">[-]</label><label class="expand" for="c-40340347">[2 more]</label></div><br/><div class="children"><div class="content">The fact that consumer and &quot;pro&quot;(?) GPUs don&#x27;t use (mostly) the same software is not confidence inspiring. It means that AMD&#x27;s already apparently limited capacity for software development is stretched thinner than it otherwise would be.<p>Also, if the consumer GPUs are hopelessly broken but the enterprise GPUs are fine, that greatly limits the number of people that can contribute to making the AMD AI software ecosystem better. How much of the utility of the NVIDIA software ecosystem comes from gaming GPU owners tinkering in their free time? Or grad students doing small scale research?<p>I think these kinds of things are a big part of why NVIDIA&#x27;s software is so much better than AMD right now.</div><br/><div id="40340523" class="c"><input type="checkbox" id="c-40340523" checked=""/><div class="controls bullet"><span class="by">wruza</span><span>|</span><a href="#40339633">root</a><span>|</span><a href="#40340347">parent</a><span>|</span><a href="#40340324">next</a><span>|</span><label class="collapse" for="c-40340523">[-]</label><label class="expand" for="c-40340523">[1 more]</label></div><br/><div class="children"><div class="content"><i>that greatly limits the number of people that can contribute to making the AMD AI software ecosystem better</i><p>I’d say it simply dials it down to zero. No one’s gonna buy an enterprise AMD card for playing with AI, so no one’s gonna contribute to that either. As a local AI enthusiast, this “but he used consumer card” complaint makes no sense to me.</div><br/></div></div></div></div><div id="40340324" class="c"><input type="checkbox" id="c-40340324" checked=""/><div class="controls bullet"><span class="by">shmerl</span><span>|</span><a href="#40339633">root</a><span>|</span><a href="#40340100">parent</a><span>|</span><a href="#40340347">prev</a><span>|</span><a href="#40339741">next</a><span>|</span><label class="collapse" for="c-40340324">[-]</label><label class="expand" for="c-40340324">[1 more]</label></div><br/><div class="children"><div class="content">Indeed, AMD willing to open firmware is something Nvidia never has done.</div><br/></div></div></div></div></div></div></div></div><div id="40339741" class="c"><input type="checkbox" id="c-40339741" checked=""/><div class="controls bullet"><span class="by">huhlig</span><span>|</span><a href="#40339633">parent</a><span>|</span><a href="#40339837">prev</a><span>|</span><a href="#40340570">next</a><span>|</span><label class="collapse" for="c-40339741">[-]</label><label class="expand" for="c-40339741">[2 more]</label></div><br/><div class="children"><div class="content">Into what? Where would you draw such lines?</div><br/><div id="40340001" class="c"><input type="checkbox" id="c-40340001" checked=""/><div class="controls bullet"><span class="by">robocat</span><span>|</span><a href="#40339633">root</a><span>|</span><a href="#40339741">parent</a><span>|</span><a href="#40340570">next</a><span>|</span><label class="collapse" for="c-40340001">[-]</label><label class="expand" for="c-40340001">[1 more]</label></div><br/><div class="children"><div class="content">Into tiles ;-p<p>GPU compute is already broken up - there is a supply chain of other cooperating players that work together to deliver GPU compute to end users:<p>TSMC, SK hynix, Synopsys, cloud providers (Azure&#x2F;Amazon etcetera), model providers (OpenAI&#x2F;Anthropic etcetera).<p>Why single out NVidia in the chain? Plus the different critical parts of the chain are in different jurisdictions. Split up NVidia and somebody else will take over that spot in the ecosystem.
This interview with Synopsys is rather enlightening: <a href="https:&#x2F;&#x2F;www.acquired.fm&#x2F;episodes&#x2F;the-software-behind-silicon-with-synopsys-founder-aart-de-geus-and-ceo-sassine-ghazi" rel="nofollow">https:&#x2F;&#x2F;www.acquired.fm&#x2F;episodes&#x2F;the-software-behind-silicon...</a><p>How does the profit currently get split between the different links? Profit is the forcing variable for market cap and profit is the indicator of advantage. Break up NVidia and where does the profit move?</div><br/></div></div></div></div></div></div><div id="40340570" class="c"><input type="checkbox" id="c-40340570" checked=""/><div class="controls bullet"><span class="by">cl3misch</span><span>|</span><a href="#40339633">prev</a><span>|</span><a href="#40338383">next</a><span>|</span><label class="collapse" for="c-40340570">[-]</label><label class="expand" for="c-40340570">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The unswizzled shared memory layouts suffer from very poor coalescing<p>If I didn&#x27;t know any better I&#x27;d consider it technobabble</div><br/></div></div><div id="40338383" class="c"><input type="checkbox" id="c-40338383" checked=""/><div class="controls bullet"><span class="by">behnamoh</span><span>|</span><a href="#40340570">prev</a><span>|</span><a href="#40338451">next</a><span>|</span><label class="collapse" for="c-40338383">[-]</label><label class="expand" for="c-40338383">[8 more]</label></div><br/><div class="children"><div class="content">tangential: When @sama talks about &quot;Universal Basic Compute&quot; (UBC) as a substitute for Universal Basic Income, obviously he means GPU, right? Who&#x27;s going to benefit from such policies? Only nvidia? It just seems such a dystopian future to live in: imagine you can sell your UBC to others who know better how to use it, or you can use it to mine bitcoin or whatever. But all the compute is actually created by one company.<p>There are many reasons to hate nvidia, but honestly if this UBC policy is even remotely being considered in some circles, I&#x27;d join Linus Torvalds and say &quot;nvidia, fuck you&quot;.</div><br/><div id="40338470" class="c"><input type="checkbox" id="c-40338470" checked=""/><div class="controls bullet"><span class="by">jra101</span><span>|</span><a href="#40338383">parent</a><span>|</span><a href="#40340343">next</a><span>|</span><label class="collapse" for="c-40338470">[-]</label><label class="expand" for="c-40338470">[6 more]</label></div><br/><div class="children"><div class="content">You&#x27;re blaming NVIDIA for Sam Altman&#x27;s dumb idea?</div><br/><div id="40338579" class="c"><input type="checkbox" id="c-40338579" checked=""/><div class="controls bullet"><span class="by">WanderPanda</span><span>|</span><a href="#40338383">root</a><span>|</span><a href="#40338470">parent</a><span>|</span><a href="#40338506">next</a><span>|</span><label class="collapse" for="c-40338579">[-]</label><label class="expand" for="c-40338579">[1 more]</label></div><br/><div class="children"><div class="content">One&#x27;s &quot;dumb idea&quot; is another marketers &quot;genius stroke&quot;. Seems like he is playing the media puppets while he can</div><br/></div></div><div id="40338506" class="c"><input type="checkbox" id="c-40338506" checked=""/><div class="controls bullet"><span class="by">behnamoh</span><span>|</span><a href="#40338383">root</a><span>|</span><a href="#40338470">parent</a><span>|</span><a href="#40338579">prev</a><span>|</span><a href="#40340343">next</a><span>|</span><label class="collapse" for="c-40338506">[-]</label><label class="expand" for="c-40338506">[4 more]</label></div><br/><div class="children"><div class="content">nvidia&#x27;s CEO literally keeps saying &quot;the more you buy GPUs, the more you save&quot;—it&#x27;s hard to believe nvidia has nothing to do with such ideas.</div><br/><div id="40338601" class="c"><input type="checkbox" id="c-40338601" checked=""/><div class="controls bullet"><span class="by">coffeebeqn</span><span>|</span><a href="#40338383">root</a><span>|</span><a href="#40338506">parent</a><span>|</span><a href="#40338592">next</a><span>|</span><label class="collapse" for="c-40338601">[-]</label><label class="expand" for="c-40338601">[1 more]</label></div><br/><div class="children"><div class="content">GPU CEO wants to sell more GPUs? What on earth</div><br/></div></div><div id="40338592" class="c"><input type="checkbox" id="c-40338592" checked=""/><div class="controls bullet"><span class="by">WanderPanda</span><span>|</span><a href="#40338383">root</a><span>|</span><a href="#40338506">parent</a><span>|</span><a href="#40338601">prev</a><span>|</span><a href="#40340343">next</a><span>|</span><label class="collapse" for="c-40338592">[-]</label><label class="expand" for="c-40338592">[2 more]</label></div><br/><div class="children"><div class="content">Him saying this always puts me off. Gives hard old sales-guy vibes. I really wonder who&#x2F;which demographic is influenced in nvidias favor by this rethoric.</div><br/></div></div></div></div></div></div><div id="40340343" class="c"><input type="checkbox" id="c-40340343" checked=""/><div class="controls bullet"><span class="by">callalex</span><span>|</span><a href="#40338383">parent</a><span>|</span><a href="#40338470">prev</a><span>|</span><a href="#40338451">next</a><span>|</span><label class="collapse" for="c-40340343">[-]</label><label class="expand" for="c-40340343">[1 more]</label></div><br/><div class="children"><div class="content">You’re looking for logic. The only logic is “when a sucker buys WorldCoin, sama bank account go brrrr”.<p>That’s the whole logic.</div><br/></div></div></div></div><div id="40338451" class="c"><input type="checkbox" id="c-40338451" checked=""/><div class="controls bullet"><span class="by">uyzstvqs</span><span>|</span><a href="#40338383">prev</a><span>|</span><a href="#40338520">next</a><span>|</span><label class="collapse" for="c-40338451">[-]</label><label class="expand" for="c-40338451">[5 more]</label></div><br/><div class="children"><div class="content">What is needed are true NPUs as dedicated co-processors, especially for prosumer desktop systems (devs, other professionals, gamers). GPUs work in the enterprise, but they&#x27;re a hassle to use for AI on the personal computing side of the market. Especially VRAM limitations, but also the lack of a standard open API other than Vulkan (again, using video stuff for AI).</div><br/><div id="40338572" class="c"><input type="checkbox" id="c-40338572" checked=""/><div class="controls bullet"><span class="by">dartos</span><span>|</span><a href="#40338451">parent</a><span>|</span><a href="#40338520">next</a><span>|</span><label class="collapse" for="c-40338572">[-]</label><label class="expand" for="c-40338572">[4 more]</label></div><br/><div class="children"><div class="content">Fwiw, Vulkan isn’t specifically a graphics api and has had compute specific features for a while now. (Potentially since its inception)</div><br/><div id="40339040" class="c"><input type="checkbox" id="c-40339040" checked=""/><div class="controls bullet"><span class="by">the__alchemist</span><span>|</span><a href="#40338451">root</a><span>|</span><a href="#40338572">parent</a><span>|</span><a href="#40338520">next</a><span>|</span><label class="collapse" for="c-40339040">[-]</label><label class="expand" for="c-40339040">[3 more]</label></div><br/><div class="children"><div class="content">Compared to CUDA, Vulkan is... not fun to code compute in! The serialization bridge and duplicating data structures and functions between CPU and GPU is tedious.</div><br/><div id="40339728" class="c"><input type="checkbox" id="c-40339728" checked=""/><div class="controls bullet"><span class="by">dartos</span><span>|</span><a href="#40338451">root</a><span>|</span><a href="#40339040">parent</a><span>|</span><a href="#40338520">next</a><span>|</span><label class="collapse" for="c-40339728">[-]</label><label class="expand" for="c-40339728">[2 more]</label></div><br/><div class="children"><div class="content">I hear both CUDA and Vulkan are not fun to code in.<p>But yeah Vulkan is famously verbose. It takes about 1000 LoC to draw a triangle</div><br/><div id="40340540" class="c"><input type="checkbox" id="c-40340540" checked=""/><div class="controls bullet"><span class="by">KeplerBoy</span><span>|</span><a href="#40338451">root</a><span>|</span><a href="#40339728">parent</a><span>|</span><a href="#40338520">next</a><span>|</span><label class="collapse" for="c-40340540">[-]</label><label class="expand" for="c-40340540">[1 more]</label></div><br/><div class="children"><div class="content">CUDA is very much fun to code in!<p>Nvidia provides devs with great tools (Nsight Systems and Nsight Compute), so you know where you have to optimize.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="40338520" class="c"><input type="checkbox" id="c-40338520" checked=""/><div class="controls bullet"><span class="by">jokoon</span><span>|</span><a href="#40338451">prev</a><span>|</span><a href="#40339769">next</a><span>|</span><label class="collapse" for="c-40338520">[-]</label><label class="expand" for="c-40338520">[11 more]</label></div><br/><div class="children"><div class="content">this is why people should better study neuroscience, psychology if they want to advance research in AI.<p>also things related to graph topology in neural networks maybe, but probably not related to artificial NN.<p>I was given this video, which I found was pretty interesting: <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=nkdZRBFtqSs" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=nkdZRBFtqSs</a> (How Developers might stop worrying about AI taking software jobs and Learn to Profit from LLMs - YouTube)</div><br/><div id="40338593" class="c"><input type="checkbox" id="c-40338593" checked=""/><div class="controls bullet"><span class="by">dartos</span><span>|</span><a href="#40338520">parent</a><span>|</span><a href="#40339276">next</a><span>|</span><label class="collapse" for="c-40338593">[-]</label><label class="expand" for="c-40338593">[8 more]</label></div><br/><div class="children"><div class="content">I don’t think psychology will have any bearing on AI.<p>I doubt neuroscience will either, but I’m not as sure on that.<p>The more impressive AI systems we have moved further away from the neuron analogy that came from perceptions.<p>The whole “intelligence” and “neural” part of AI is a red herring imo. Really poor ambiguous word choice for a specific, technical idea.</div><br/><div id="40338682" class="c"><input type="checkbox" id="c-40338682" checked=""/><div class="controls bullet"><span class="by">sva_</span><span>|</span><a href="#40338520">root</a><span>|</span><a href="#40338593">parent</a><span>|</span><a href="#40338798">next</a><span>|</span><label class="collapse" for="c-40338682">[-]</label><label class="expand" for="c-40338682">[2 more]</label></div><br/><div class="children"><div class="content">&gt; I doubt neuroscience will either, but I’m not as sure on that<p>The stuff on spiking networks and neuromorphic computing is definitely interesting and inspired by neuroscience, but it currently seems mostly like vaporware</div><br/><div id="40339701" class="c"><input type="checkbox" id="c-40339701" checked=""/><div class="controls bullet"><span class="by">dartos</span><span>|</span><a href="#40338520">root</a><span>|</span><a href="#40338682">parent</a><span>|</span><a href="#40338798">next</a><span>|</span><label class="collapse" for="c-40339701">[-]</label><label class="expand" for="c-40339701">[1 more]</label></div><br/><div class="children"><div class="content">Yep, I’ve heard about spiking networks, but haven’t read into them much yet.</div><br/></div></div></div></div><div id="40338798" class="c"><input type="checkbox" id="c-40338798" checked=""/><div class="controls bullet"><span class="by">nradov</span><span>|</span><a href="#40338520">root</a><span>|</span><a href="#40338593">parent</a><span>|</span><a href="#40338682">prev</a><span>|</span><a href="#40338716">next</a><span>|</span><label class="collapse" for="c-40338798">[-]</label><label class="expand" for="c-40338798">[2 more]</label></div><br/><div class="children"><div class="content">The question is whether current AI technologies represent any progress towards a true human equivalent artificial <i>general</i> intelligence. Most likely not, but no one knows for sure. If the answer turns out to be no then real progress will likely require theoretical insights from psychology, neuroscience, and other fields.</div><br/><div id="40339710" class="c"><input type="checkbox" id="c-40339710" checked=""/><div class="controls bullet"><span class="by">dartos</span><span>|</span><a href="#40338520">root</a><span>|</span><a href="#40338798">parent</a><span>|</span><a href="#40338716">next</a><span>|</span><label class="collapse" for="c-40339710">[-]</label><label class="expand" for="c-40339710">[1 more]</label></div><br/><div class="children"><div class="content">Fwiw, I don’t think we’re any closer to general intelligence then we were 5 years ago.<p>Other than that, I agree, especially since you added “and other fields.”
Psychology might eventually give us a useful definition of “intelligence,” so that’d be something.<p>Obviously all research can influence other areas of research.</div><br/></div></div></div></div><div id="40338716" class="c"><input type="checkbox" id="c-40338716" checked=""/><div class="controls bullet"><span class="by">fastball</span><span>|</span><a href="#40338520">root</a><span>|</span><a href="#40338593">parent</a><span>|</span><a href="#40338798">prev</a><span>|</span><a href="#40339276">next</a><span>|</span><label class="collapse" for="c-40338716">[-]</label><label class="expand" for="c-40338716">[3 more]</label></div><br/><div class="children"><div class="content">*perceptrons</div><br/><div id="40339703" class="c"><input type="checkbox" id="c-40339703" checked=""/><div class="controls bullet"><span class="by">dartos</span><span>|</span><a href="#40338520">root</a><span>|</span><a href="#40338716">parent</a><span>|</span><a href="#40339276">next</a><span>|</span><label class="collapse" for="c-40339703">[-]</label><label class="expand" for="c-40339703">[2 more]</label></div><br/><div class="children"><div class="content">Darn autocorrect. Thank you.</div><br/><div id="40340668" class="c"><input type="checkbox" id="c-40340668" checked=""/><div class="controls bullet"><span class="by">actionfromafar</span><span>|</span><a href="#40338520">root</a><span>|</span><a href="#40339703">parent</a><span>|</span><a href="#40339276">next</a><span>|</span><label class="collapse" for="c-40340668">[-]</label><label class="expand" for="c-40340668">[1 more]</label></div><br/><div class="children"><div class="content">Haha, I didn&#x27;t get it when I read &quot;perceptions&quot;. Thought ... of what? :-D</div><br/></div></div></div></div></div></div></div></div><div id="40339276" class="c"><input type="checkbox" id="c-40339276" checked=""/><div class="controls bullet"><span class="by">chmod775</span><span>|</span><a href="#40338520">parent</a><span>|</span><a href="#40338593">prev</a><span>|</span><a href="#40338959">next</a><span>|</span><label class="collapse" for="c-40339276">[-]</label><label class="expand" for="c-40339276">[1 more]</label></div><br/><div class="children"><div class="content">I can&#x27;t seem to figure out the connection between this comment and the article at hand, except that they&#x27;re both about AI.</div><br/></div></div><div id="40338959" class="c"><input type="checkbox" id="c-40338959" checked=""/><div class="controls bullet"><span class="by">renewiltord</span><span>|</span><a href="#40338520">parent</a><span>|</span><a href="#40339276">prev</a><span>|</span><a href="#40339769">next</a><span>|</span><label class="collapse" for="c-40338959">[-]</label><label class="expand" for="c-40338959">[1 more]</label></div><br/><div class="children"><div class="content">There are loads of psychologists and neuroscientists today. Has any of them in the last few years produced anything advancing AI? The proof of the pudding is in the eating so if they have at a higher rate than just straight CS&#x2F;Mathematics and related then there’s probably some truth to it.</div><br/></div></div></div></div><div id="40339769" class="c"><input type="checkbox" id="c-40339769" checked=""/><div class="controls bullet"><span class="by">benreesman</span><span>|</span><a href="#40338520">prev</a><span>|</span><label class="collapse" for="c-40339769">[-]</label><label class="expand" for="c-40339769">[3 more]</label></div><br/><div class="children"><div class="content">It’s stupid, we can get a credible foundation model on a billion weights.<p>If you don’t know this you’re a novice in the field.</div><br/><div id="40339779" class="c"><input type="checkbox" id="c-40339779" checked=""/><div class="controls bullet"><span class="by">spullara</span><span>|</span><a href="#40339769">parent</a><span>|</span><label class="collapse" for="c-40339779">[-]</label><label class="expand" for="c-40339779">[2 more]</label></div><br/><div class="children"><div class="content">please publish it!</div><br/></div></div></div></div></div></div></div></div></div></body></html>