<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1683018043545" as="style"/><link rel="stylesheet" href="styles.css?v=1683018043545"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.vipshek.com/blog/gpt-learning">GPT makes learning fun again</a> <span class="domain">(<a href="https://www.vipshek.com">www.vipshek.com</a>)</span></div><div class="subtext"><span>vipshek</span> | <span>111 comments</span></div><br/><div><div id="35783494" class="c"><input type="checkbox" id="c-35783494" checked=""/><div class="controls bullet"><span class="by">devjab</span><span>|</span><a href="#35784922">next</a><span>|</span><label class="collapse" for="c-35783494">[-]</label><label class="expand" for="c-35783494">[43 more]</label></div><br/><div class="children"><div class="content">I&#x27;m in two minds about it. On one hand the internet (in general) has become so hard to find information on, and I agree with the author that GPT is a breath of fresh air. On the other hand I&#x27;ve seen GPT fail so miserably at topics that I&#x27;m knowledge about that I have a very hard time trusting anything it tells me. I&#x27;m not sure what the answer really is, but I&#x27;m not sure it&#x27;s GPT. I wish we could go back to having search engines that actually led to useful information and not just advertisements, and I wish we had a GPT that would not tell lies.<p>I doubt either of those wishes are going to come true though. Search engines are likely always going to be SEO&#x27;ed into uselessness and GPT isn&#x27;t intentionally telling lies.</div><br/><div id="35784668" class="c"><input type="checkbox" id="c-35784668" checked=""/><div class="controls bullet"><span class="by">somethoughts</span><span>|</span><a href="#35783494">parent</a><span>|</span><a href="#35783979">next</a><span>|</span><label class="collapse" for="c-35784668">[-]</label><label class="expand" for="c-35784668">[4 more]</label></div><br/><div class="children"><div class="content">As a follow on to those thoughts, I feel like ChatGPT is in the phase similar to that fleeting moment when search engines were maximally useable - before SEO was a thing and before Google &quot;needed&quot; to turn on the profitability spigot.<p>Its unclear to me how long we&#x27;ll have before LLM Engine Optimization is a thing and OpenAI&#x2F;MSFT &quot;need&quot; to turn on their LLM profitability spigot; and what ChatGPT will look like then.<p>That said, I&#x27;m curious as to whether technically LLMs are inherently more challenging to game than search engines.</div><br/><div id="35784821" class="c"><input type="checkbox" id="c-35784821" checked=""/><div class="controls bullet"><span class="by">danielbln</span><span>|</span><a href="#35783494">root</a><span>|</span><a href="#35784668">parent</a><span>|</span><a href="#35784822">next</a><span>|</span><label class="collapse" for="c-35784821">[-]</label><label class="expand" for="c-35784821">[1 more]</label></div><br/><div class="children"><div class="content">A big benefit is that there are already plenty ok-ish open source LLMs out there that you can hook up to various information sources. Even if OpenAI flips the ad switch tomorrow, you can still run those by yourself. We didn&#x27;t really have that option with search engines.</div><br/></div></div><div id="35784822" class="c"><input type="checkbox" id="c-35784822" checked=""/><div class="controls bullet"><span class="by">enlyth</span><span>|</span><a href="#35783494">root</a><span>|</span><a href="#35784668">parent</a><span>|</span><a href="#35784821">prev</a><span>|</span><a href="#35783979">next</a><span>|</span><label class="collapse" for="c-35784822">[-]</label><label class="expand" for="c-35784822">[2 more]</label></div><br/><div class="children"><div class="content">I actually don&#x27;t mind paying the $20&#x2F;mo or whatever if it means no ads, hopefully this turns out to be a viable business model for them.
Also, first company with an uncensored LLM that doesn&#x27;t reply &quot;As an AI language model&quot; will get my money.</div><br/><div id="35784884" class="c"><input type="checkbox" id="c-35784884" checked=""/><div class="controls bullet"><span class="by">blibble</span><span>|</span><a href="#35783494">root</a><span>|</span><a href="#35784822">parent</a><span>|</span><a href="#35783979">next</a><span>|</span><label class="collapse" for="c-35784884">[-]</label><label class="expand" for="c-35784884">[1 more]</label></div><br/><div class="children"><div class="content">why have no ads when you can plaster it with ads and also charge $20?<p>see: windows 11</div><br/></div></div></div></div></div></div><div id="35783979" class="c"><input type="checkbox" id="c-35783979" checked=""/><div class="controls bullet"><span class="by">LASR</span><span>|</span><a href="#35783494">parent</a><span>|</span><a href="#35784668">prev</a><span>|</span><a href="#35783603">next</a><span>|</span><label class="collapse" for="c-35783979">[-]</label><label class="expand" for="c-35783979">[18 more]</label></div><br/><div class="children"><div class="content">I want to use this comment to state one thing, not directly addressed to you.<p>Stop using GPT as a database! GPT is far more useful a reasoning engine that can accumulate fuzzy data and then provide various views or transformation of that data.<p>So asking GPT to parse a Wikipedia page and then asking it to teach you from it - this is a much more successful usage than what the author in the original article is doing.<p>It is not useful as an accurate source of information. It’s inaccurate sometimes, and it’s hard to tell when. OTOH, as a formatted, it has some actual world-changing potential.</div><br/><div id="35783991" class="c"><input type="checkbox" id="c-35783991" checked=""/><div class="controls bullet"><span class="by">hammyhavoc</span><span>|</span><a href="#35783494">root</a><span>|</span><a href="#35783979">parent</a><span>|</span><a href="#35784304">next</a><span>|</span><label class="collapse" for="c-35783991">[-]</label><label class="expand" for="c-35783991">[14 more]</label></div><br/><div class="children"><div class="content">Is it? I couldn&#x27;t even get it to figure out an NGINX config, despite feeding it the documentation and URL rewrites it would need, and the prior Apache .htaccess file. Spent days on it. Consulted with people who know more than me about prompt engineering. Nope.<p>Reasoning is not its strong point, IMO. It&#x27;s a next-word prediction model, why would it be? It&#x27;s doing what an LLM does. Frequently, nonsensically.</div><br/><div id="35784894" class="c"><input type="checkbox" id="c-35784894" checked=""/><div class="controls bullet"><span class="by">SanderNL</span><span>|</span><a href="#35783494">root</a><span>|</span><a href="#35783991">parent</a><span>|</span><a href="#35784309">next</a><span>|</span><label class="collapse" for="c-35784894">[-]</label><label class="expand" for="c-35784894">[1 more]</label></div><br/><div class="children"><div class="content">&gt; It&#x27;s a next-word prediction model, why would it be?<p>If you want to make accurate predictions, you&#x27;ll need reasoning or at least some process that approximates it.<p>&quot;There a no bananas. Max is looking for bananas. Will he be successful: [yes&#x2F;no]&quot;</div><br/></div></div><div id="35784309" class="c"><input type="checkbox" id="c-35784309" checked=""/><div class="controls bullet"><span class="by">throwaway675309</span><span>|</span><a href="#35783494">root</a><span>|</span><a href="#35783991">parent</a><span>|</span><a href="#35784894">prev</a><span>|</span><a href="#35784052">next</a><span>|</span><label class="collapse" for="c-35784309">[-]</label><label class="expand" for="c-35784309">[8 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve actually had great success with the automation of boiler plate DevOps nonsense <i>using</i> GPT-4, including: GitHub actions, Caddy scripts, Docker files, etc.<p>Every second that I didn&#x27;t have to:<p>- go look up a similar problem on Google<p>- open three or four stack overflow tabs<p>- read through the stack overflow links<p>- copy out the answer<p>- change all the variables to match variable names that I want<p>All of this represents a huge time saver for me. I&#x27;m honestly baffled that people lack the ability to use LLMs in a productive and optimal manner.</div><br/><div id="35784698" class="c"><input type="checkbox" id="c-35784698" checked=""/><div class="controls bullet"><span class="by">LASR</span><span>|</span><a href="#35783494">root</a><span>|</span><a href="#35784309">parent</a><span>|</span><a href="#35784352">next</a><span>|</span><label class="collapse" for="c-35784698">[-]</label><label class="expand" for="c-35784698">[2 more]</label></div><br/><div class="children"><div class="content">&gt; I&#x27;m honestly baffled that people lack the ability to use LLMs in a productive and optimal manner.<p>Huge +1.<p>I’ve got it to do a large part of my work for me by chaining some simple API calls.<p>The fundamental conceptual gap I see - people often ask it to do some “thinking”. Then are annoyed by the inaccurate output.<p>A simple example is doing word count and it getting the wrong answer very confidently.<p>Of course it sucks at that. It doesn’t have a counter internally. But if you ask it to number each word in the input and output a list, then ask for the word count, it gets it right every time.<p>Almost like how a human might count words manually.</div><br/><div id="35784887" class="c"><input type="checkbox" id="c-35784887" checked=""/><div class="controls bullet"><span class="by">therein</span><span>|</span><a href="#35783494">root</a><span>|</span><a href="#35784698">parent</a><span>|</span><a href="#35784352">next</a><span>|</span><label class="collapse" for="c-35784887">[-]</label><label class="expand" for="c-35784887">[1 more]</label></div><br/><div class="children"><div class="content">I agree. I often use it as if it is a code generator with a decent grasp of human language.<p>Here is what I asked it to do the other day, and it just did it right away and got it entirely right.<p>&gt; Write async tokio Rust code that takes in a Vec&lt;u8&gt;, writes it to a temporary file, calls &#x2F;usr&#x2F;bin&#x2F;svc infer pathToTemporaryFile, reads and deletes temporaryFile+&quot;.out&quot; and returns Result&lt;Vec&lt;u8&gt;&gt; containing the contents of temporaryFile+&quot;.out&quot;<p>I knew what I wanted, I could have written it myself, there was no unknown but it took fewer keystrokes and honestly when asked to write small components like this with pedantic detail, it does an incredible job and the output is easy to validate quickly.</div><br/></div></div></div></div><div id="35784352" class="c"><input type="checkbox" id="c-35784352" checked=""/><div class="controls bullet"><span class="by">consp</span><span>|</span><a href="#35783494">root</a><span>|</span><a href="#35784309">parent</a><span>|</span><a href="#35784698">prev</a><span>|</span><a href="#35784052">next</a><span>|</span><label class="collapse" for="c-35784352">[-]</label><label class="expand" for="c-35784352">[5 more]</label></div><br/><div class="children"><div class="content">Did you learn anything in the process? You&#x27;d still have to over the output and understand it, otherwise nothing has changed except the method of producing something you don&#x27;t understand.</div><br/><div id="35784518" class="c"><input type="checkbox" id="c-35784518" checked=""/><div class="controls bullet"><span class="by">rolisz</span><span>|</span><a href="#35783494">root</a><span>|</span><a href="#35784352">parent</a><span>|</span><a href="#35784052">next</a><span>|</span><label class="collapse" for="c-35784518">[-]</label><label class="expand" for="c-35784518">[4 more]</label></div><br/><div class="children"><div class="content">If you&#x27;re not DevOps, why bother learning whatever framework is used today, but which will be replaced by something else next year? I just want to get my stuff deployed and that&#x27;s it.</div><br/><div id="35784913" class="c"><input type="checkbox" id="c-35784913" checked=""/><div class="controls bullet"><span class="by">input_sh</span><span>|</span><a href="#35783494">root</a><span>|</span><a href="#35784518">parent</a><span>|</span><a href="#35784632">next</a><span>|</span><label class="collapse" for="c-35784913">[-]</label><label class="expand" for="c-35784913">[1 more]</label></div><br/><div class="children"><div class="content">Saying that DevOps tooling changes every year is absolute nonsense. The tooling is fairly standardised nowadays (Docker, Kubernetes, Ansible, Terraform, Prometheus, CI&#x2F;CD tool of your choice) and every part of it is over half a decade old.<p>ChatGPT will only help you with the simplest of tasks, and even then you&#x27;re gonna fail if you don&#x27;t know to correct it. If you go beyond the most basic of the tasks you can learn how to do in a few hours, good luck fitting them in a chat prompt.</div><br/></div></div><div id="35784632" class="c"><input type="checkbox" id="c-35784632" checked=""/><div class="controls bullet"><span class="by">ChatGTP</span><span>|</span><a href="#35783494">root</a><span>|</span><a href="#35784518">parent</a><span>|</span><a href="#35784913">prev</a><span>|</span><a href="#35784052">next</a><span>|</span><label class="collapse" for="c-35784632">[-]</label><label class="expand" for="c-35784632">[2 more]</label></div><br/><div class="children"><div class="content">Yeah that’s true, why bother actually knowing anything about the systems they run your software &#x2F;s</div><br/><div id="35784881" class="c"><input type="checkbox" id="c-35784881" checked=""/><div class="controls bullet"><span class="by">rolisz</span><span>|</span><a href="#35783494">root</a><span>|</span><a href="#35784632">parent</a><span>|</span><a href="#35784052">next</a><span>|</span><label class="collapse" for="c-35784881">[-]</label><label class="expand" for="c-35784881">[1 more]</label></div><br/><div class="children"><div class="content">I have a finite amount of time. I can choose to learn and know more about the software that I&#x27;m developing and make the software better, or I can spend some amount of time to learn the DevOps part, or some mix in between. In some cases, the ratio is 90:10 in favor of software development.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="35784052" class="c"><input type="checkbox" id="c-35784052" checked=""/><div class="controls bullet"><span class="by">andai</span><span>|</span><a href="#35783494">root</a><span>|</span><a href="#35783991">parent</a><span>|</span><a href="#35784309">prev</a><span>|</span><a href="#35784036">next</a><span>|</span><label class="collapse" for="c-35784052">[-]</label><label class="expand" for="c-35784052">[3 more]</label></div><br/><div class="children"><div class="content">GPT-3 or 4? Re: reasoning, apparently it gives much better performance if you ask it to write out its thought process step by step (because it has no &quot;internal&quot; thought process; it must be externalized).</div><br/><div id="35784054" class="c"><input type="checkbox" id="c-35784054" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#35783494">root</a><span>|</span><a href="#35784052">parent</a><span>|</span><a href="#35784036">next</a><span>|</span><label class="collapse" for="c-35784054">[-]</label><label class="expand" for="c-35784054">[2 more]</label></div><br/><div class="children"><div class="content">Yeah, that sounds like a GPT-3.5 problem to me. I wouldn&#x27;t trust 3.5 to write me an Nginx config, but I&#x27;d give 4 a shot at it.<p>I just tried using GPT-4 to translate a random htaccess file I found to nginx and it seemed to do a good initial job: <a href="https:&#x2F;&#x2F;gist.github.com&#x2F;simonw&#x2F;8174f653a0c08c120830c56332054ca3" rel="nofollow">https:&#x2F;&#x2F;gist.github.com&#x2F;simonw&#x2F;8174f653a0c08c120830c56332054...</a></div><br/><div id="35784169" class="c"><input type="checkbox" id="c-35784169" checked=""/><div class="controls bullet"><span class="by">andai</span><span>|</span><a href="#35783494">root</a><span>|</span><a href="#35784054">parent</a><span>|</span><a href="#35784036">next</a><span>|</span><label class="collapse" for="c-35784169">[-]</label><label class="expand" for="c-35784169">[1 more]</label></div><br/><div class="children"><div class="content">I tried your prompt and it works with 3.5 too, but I&#x27;m not qualified to verify the output (75% of it looks the same to me though).</div><br/></div></div></div></div></div></div><div id="35784036" class="c"><input type="checkbox" id="c-35784036" checked=""/><div class="controls bullet"><span class="by">LASR</span><span>|</span><a href="#35783494">root</a><span>|</span><a href="#35783991">parent</a><span>|</span><a href="#35784052">prev</a><span>|</span><a href="#35784304">next</a><span>|</span><label class="collapse" for="c-35784036">[-]</label><label class="expand" for="c-35784036">[1 more]</label></div><br/><div class="children"><div class="content">Interesting. Curious as to what specific task you gave it and how it failed.<p>My team has been working on several advanced techniques using reasoning on LLMs. The stacked performance of all of these techniques combined yields is quite impressive.</div><br/></div></div></div></div><div id="35784304" class="c"><input type="checkbox" id="c-35784304" checked=""/><div class="controls bullet"><span class="by">burglins</span><span>|</span><a href="#35783494">root</a><span>|</span><a href="#35783979">parent</a><span>|</span><a href="#35783991">prev</a><span>|</span><a href="#35784087">next</a><span>|</span><label class="collapse" for="c-35784304">[-]</label><label class="expand" for="c-35784304">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m curious - how do you pass the article to GPT? Are you doing any formatting?</div><br/></div></div><div id="35784087" class="c"><input type="checkbox" id="c-35784087" checked=""/><div class="controls bullet"><span class="by">krainboltgreene</span><span>|</span><a href="#35783494">root</a><span>|</span><a href="#35783979">parent</a><span>|</span><a href="#35784304">prev</a><span>|</span><a href="#35783603">next</a><span>|</span><label class="collapse" for="c-35784087">[-]</label><label class="expand" for="c-35784087">[2 more]</label></div><br/><div class="children"><div class="content">&gt; GPT is far more useful a reasoning engine<p>Hilarious to read this advice when GPT, by it&#x27;s own designers, cannot reason.</div><br/><div id="35784666" class="c"><input type="checkbox" id="c-35784666" checked=""/><div class="controls bullet"><span class="by">LASR</span><span>|</span><a href="#35783494">root</a><span>|</span><a href="#35784087">parent</a><span>|</span><a href="#35783603">next</a><span>|</span><label class="collapse" for="c-35784666">[-]</label><label class="expand" for="c-35784666">[1 more]</label></div><br/><div class="children"><div class="content">It can’t reason - as in there no internal memory or intelligence in there. But you can ask it to generate a reasoning chain as part of its output. And then extract that output and do something else with that. That’s the reasoning it can perform.<p>Look up the Sam Altman podcast with Lex. He specifically talks about reasoning engines.</div><br/></div></div></div></div></div></div><div id="35783603" class="c"><input type="checkbox" id="c-35783603" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#35783494">parent</a><span>|</span><a href="#35783979">prev</a><span>|</span><a href="#35783584">next</a><span>|</span><label class="collapse" for="c-35783603">[-]</label><label class="expand" for="c-35783603">[9 more]</label></div><br/><div class="children"><div class="content">&quot;I&#x27;m not sure what the answer really is, but I&#x27;m not sure it&#x27;s GPT.&quot;<p>My suggestion is to stick with it and get a feel for what it&#x27;s good at.<p>I&#x27;ve found that after a few months of using ChatGPT every day I&#x27;ve developed a pretty solid intuition for which questions are likely to get good answers and which are likely to trigger hallucinations.<p>It&#x27;s difficult to describe what those intuitions are though!<p>One rule of thumb I&#x27;ve developed: if something is likely to be &quot;common knowledge&quot; - if it&#x27;s something that is likely to have been discussed accurately on the internet by many different people - then ChatGPT is very likely to answer questions about it accurately.</div><br/><div id="35784094" class="c"><input type="checkbox" id="c-35784094" checked=""/><div class="controls bullet"><span class="by">thefz</span><span>|</span><a href="#35783494">root</a><span>|</span><a href="#35783603">parent</a><span>|</span><a href="#35783687">next</a><span>|</span><label class="collapse" for="c-35784094">[-]</label><label class="expand" for="c-35784094">[4 more]</label></div><br/><div class="children"><div class="content">&gt; One rule of thumb I&#x27;ve developed: if something is likely to be &quot;common knowledge&quot; - if it&#x27;s something that is likely to have been discussed accurately on the internet by many different people - then ChatGPT is very likely to answer questions about it accurately.<p>If so, this information is already easy to find, making GPT redundant.</div><br/><div id="35784921" class="c"><input type="checkbox" id="c-35784921" checked=""/><div class="controls bullet"><span class="by">SanderNL</span><span>|</span><a href="#35783494">root</a><span>|</span><a href="#35784094">parent</a><span>|</span><a href="#35784498">next</a><span>|</span><label class="collapse" for="c-35784921">[-]</label><label class="expand" for="c-35784921">[1 more]</label></div><br/><div class="children"><div class="content">I think it&#x27;s more about being more confident that GPT is working with at least a base of semi-accurate knowledge.<p>You can ask it to &quot;combine&quot; knowledge in &quot;novel&quot; ways that are not discussed verbatim on the web. It&#x27;s not groundbreaking reasoning by any means, but it can be very useful. (&quot;My ridiculously specific question about model X83844-QQ combined with random factor X&quot;)</div><br/></div></div><div id="35784498" class="c"><input type="checkbox" id="c-35784498" checked=""/><div class="controls bullet"><span class="by">Yiin</span><span>|</span><a href="#35783494">root</a><span>|</span><a href="#35784094">parent</a><span>|</span><a href="#35784921">prev</a><span>|</span><a href="#35783687">next</a><span>|</span><label class="collapse" for="c-35784498">[-]</label><label class="expand" for="c-35784498">[2 more]</label></div><br/><div class="children"><div class="content">it being commonly discussed doesn&#x27;t mean easily accessible. Personally ads and bad UI are main factors of my increased usage of gpt-4.</div><br/><div id="35784663" class="c"><input type="checkbox" id="c-35784663" checked=""/><div class="controls bullet"><span class="by">lifeonlars</span><span>|</span><a href="#35783494">root</a><span>|</span><a href="#35784498">parent</a><span>|</span><a href="#35783687">next</a><span>|</span><label class="collapse" for="c-35784663">[-]</label><label class="expand" for="c-35784663">[1 more]</label></div><br/><div class="children"><div class="content">Is that just the problem that ChatGPT is solving? That we have most of the answers to everyone&#x27;s questions on the web but that ads and SEO have made it impossible to access?<p>If so it seems like 1. that problem is of our own making and could be fixed without ChatGPT and 2. what will actually happen is that &#x27;experts-exchange&#x27; and all the similar slightly scammy help sites and forums are going to try to stop LLMs from stealing their lunch.</div><br/></div></div></div></div></div></div><div id="35783687" class="c"><input type="checkbox" id="c-35783687" checked=""/><div class="controls bullet"><span class="by">themodelplumber</span><span>|</span><a href="#35783494">root</a><span>|</span><a href="#35783603">parent</a><span>|</span><a href="#35784094">prev</a><span>|</span><a href="#35783584">next</a><span>|</span><label class="collapse" for="c-35783687">[-]</label><label class="expand" for="c-35783687">[4 more]</label></div><br/><div class="children"><div class="content">&gt; then ChatGPT is very likely to answer questions about it accurately.<p>Uh, and sooo boringly, especially if there&#x27;s even any tiny part of it that is developing or theoretical, and you want to learn about that part.<p>I&#x27;ve used the phrase&#x2F;request &quot;more obscure (perspectives&#x2F;explanations&#x2F;etc)&quot; with GPT so many times.<p>(Try it, you might be surprised at alternative takes on things, takes which are not even necessarily conspiracy theories and such)<p>...Which has made me think: Maybe life is more boring, the more one thinks there are just really good one-and-done answers to most everything.</div><br/><div id="35783726" class="c"><input type="checkbox" id="c-35783726" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#35783494">root</a><span>|</span><a href="#35783687">parent</a><span>|</span><a href="#35783762">next</a><span>|</span><label class="collapse" for="c-35783726">[-]</label><label class="expand" for="c-35783726">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, there are so many fun ways you can make it more interesting.<p>One of my favourite is to ask it to explain with analogies. The other day I was digging into the attention mechanism used to train LLMs, so I asked it:<p>&quot;Explain queries, keys, and values in the context of LLM attention using analogies from Terry Pratchett&#x27;s Discworld&quot;<p>I find sometimes I get some real gems out of this that help me remember things much more effectively than just reading the basic explanation.<p>(In case anyone&#x27;s curious I ran that just now and got the following: <a href="https:&#x2F;&#x2F;gist.github.com&#x2F;simonw&#x2F;777b1d19f36beb39fb4216a0238fec13" rel="nofollow">https:&#x2F;&#x2F;gist.github.com&#x2F;simonw&#x2F;777b1d19f36beb39fb4216a0238fe...</a> )</div><br/></div></div><div id="35783762" class="c"><input type="checkbox" id="c-35783762" checked=""/><div class="controls bullet"><span class="by">barrysteve</span><span>|</span><a href="#35783494">root</a><span>|</span><a href="#35783687">parent</a><span>|</span><a href="#35783726">prev</a><span>|</span><a href="#35783584">next</a><span>|</span><label class="collapse" for="c-35783762">[-]</label><label class="expand" for="c-35783762">[2 more]</label></div><br/><div class="children"><div class="content">Jonathan Blow is spending up to a decade on a new programming language to get away from c++.<p>Most everything has been covered in logical extensions of concepts started in the 80s-90s. Those products aren&#x27;t good for our..<p>Ah there&#x27;s no point commenting here anymore. HN is so blinkered in it&#x27;s thinking.<p>The feeling of flying high on lofty concepts and pretending to get a bird&#x27;s eye view of tech is no longer worth the squeeze. The thought patterns here are predictable like slashdot. I don&#x27;t belong here. Bye.</div><br/><div id="35783815" class="c"><input type="checkbox" id="c-35783815" checked=""/><div class="controls bullet"><span class="by">themodelplumber</span><span>|</span><a href="#35783494">root</a><span>|</span><a href="#35783762">parent</a><span>|</span><a href="#35783584">next</a><span>|</span><label class="collapse" for="c-35783815">[-]</label><label class="expand" for="c-35783815">[1 more]</label></div><br/><div class="children"><div class="content">Yep, if you don&#x27;t care about the details or scope, everything is the same, all patterns repeat, all wheels are reinvented.<p>You&#x27;ve probably heard this before, but IMO you&#x27;ll never find a happy place working from that perspective.</div><br/></div></div></div></div></div></div></div></div><div id="35783584" class="c"><input type="checkbox" id="c-35783584" checked=""/><div class="controls bullet"><span class="by">Gigachad</span><span>|</span><a href="#35783494">parent</a><span>|</span><a href="#35783603">prev</a><span>|</span><a href="#35784427">next</a><span>|</span><label class="collapse" for="c-35783584">[-]</label><label class="expand" for="c-35783584">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve been using ChatGPT as a brainstorming tool rather than just relying on it for specific examples. Stuff like asking it for some ideas for things to learn on a topic.</div><br/></div></div><div id="35784427" class="c"><input type="checkbox" id="c-35784427" checked=""/><div class="controls bullet"><span class="by">catgpt23</span><span>|</span><a href="#35783494">parent</a><span>|</span><a href="#35783584">prev</a><span>|</span><a href="#35783605">next</a><span>|</span><label class="collapse" for="c-35784427">[-]</label><label class="expand" for="c-35784427">[3 more]</label></div><br/><div class="children"><div class="content">It&#x27;s understandable that you have mixed feelings about GPT and the current state of the internet. The internet has become a complex landscape with a mixture of useful information and advertisements, making it harder to find the information we need.<p>GPT, like any AI system, has its limitations. It is based on the data it was trained on, and it&#x27;s not perfect in providing accurate and reliable information all the time. Additionally, the model might not always be up-to-date or may lack information on specific niche topics.<p>To address your concerns, there are a few things that can be done:<p>1. Improvement of AI systems: AI developers can continue working on improving the accuracy and reliability of AI models like GPT. This includes refining algorithms, using better training data, and incorporating user feedback to make the models more useful and trustworthy.<p>2. Critical thinking and fact-checking: It&#x27;s important to remember that no source of information is infallible. As users, we should apply critical thinking and verify information when using AI-generated content or searching the web. Cross-referencing multiple sources can help ensure that the information we consume is accurate.<p>3. Search engine improvements: The tech industry can work on developing search engines that prioritize relevant and high-quality content over advertisements and SEO-driven results. This might involve new algorithms, better curation of content, or alternative search platforms that focus on user needs.<p>While it&#x27;s true that some of your wishes might not come true overnight, continuous improvement and innovation in the AI and tech industry can lead to better solutions in the future. As users, we can also help shape these improvements by providing feedback and engaging in discussions about the technology we use.</div><br/><div id="35784434" class="c"><input type="checkbox" id="c-35784434" checked=""/><div class="controls bullet"><span class="by">midasuni</span><span>|</span><a href="#35783494">root</a><span>|</span><a href="#35784427">parent</a><span>|</span><a href="#35783605">next</a><span>|</span><label class="collapse" for="c-35784434">[-]</label><label class="expand" for="c-35784434">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Cross-referencing multiple sources can help ensure that the information we consume is accurate.<p>Not when they are all based on the same Wikipedia article</div><br/><div id="35784474" class="c"><input type="checkbox" id="c-35784474" checked=""/><div class="controls bullet"><span class="by">jimsimmons</span><span>|</span><a href="#35783494">root</a><span>|</span><a href="#35784434">parent</a><span>|</span><a href="#35783605">next</a><span>|</span><label class="collapse" for="c-35784474">[-]</label><label class="expand" for="c-35784474">[1 more]</label></div><br/><div class="children"><div class="content">GP looks ChatGPT generated</div><br/></div></div></div></div></div></div><div id="35783605" class="c"><input type="checkbox" id="c-35783605" checked=""/><div class="controls bullet"><span class="by">lcuff</span><span>|</span><a href="#35783494">parent</a><span>|</span><a href="#35784427">prev</a><span>|</span><a href="#35783574">next</a><span>|</span><label class="collapse" for="c-35783605">[-]</label><label class="expand" for="c-35783605">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m curious about what topics you have knowledge of where it&#x27;s failed.  Does it seem like there&#x27;s a pattern to the failures?  I&#x27;ve been using GPT for coding help, and it it is very helpful in ruby and bash, though it often delivers buggy software: Badly handled non-happy-path conditions, mostly, which when I tell it to handle the case, it may.  It&#x27;s a huge help for me finding gems and showing me standard ruby library syntax.  On the other hand, it&#x27;s been useless when I try to get it to write Applescript for me.  I believe that says more about AppleScript than about GPT.  Sigh.</div><br/></div></div><div id="35783574" class="c"><input type="checkbox" id="c-35783574" checked=""/><div class="controls bullet"><span class="by">forrestthewoods</span><span>|</span><a href="#35783494">parent</a><span>|</span><a href="#35783605">prev</a><span>|</span><a href="#35784664">next</a><span>|</span><label class="collapse" for="c-35783574">[-]</label><label class="expand" for="c-35783574">[1 more]</label></div><br/><div class="children"><div class="content">&gt; On the other hand I&#x27;ve seen GPT fail so miserably at topics that I&#x27;m knowledge about that I have a very hard time trusting anything it tells me.<p>ChatGPT’s current super power is helping people get from 0-to-1 on a new topic. In particular if that topic is adjacent to or a different niche with your expertise.<p>It’s not currently amazing at taking someone from intermediate to advanced knowledge.<p>At least in my experience. If I’m using a new library&#x2F;framework&#x2F;API for the first time it’s <i>amazing</i> at answering the endless newbie questions I have.</div><br/></div></div><div id="35784664" class="c"><input type="checkbox" id="c-35784664" checked=""/><div class="controls bullet"><span class="by">underdeserver</span><span>|</span><a href="#35783494">parent</a><span>|</span><a href="#35783574">prev</a><span>|</span><a href="#35783522">next</a><span>|</span><label class="collapse" for="c-35784664">[-]</label><label class="expand" for="c-35784664">[1 more]</label></div><br/><div class="children"><div class="content">Gell-Mann amnesia, in AI form. Wonderful! It&#x27;s like learning a complex topic from reading the newspaper.</div><br/></div></div><div id="35783522" class="c"><input type="checkbox" id="c-35783522" checked=""/><div class="controls bullet"><span class="by">thsbrown</span><span>|</span><a href="#35783494">parent</a><span>|</span><a href="#35784664">prev</a><span>|</span><a href="#35783557">next</a><span>|</span><label class="collapse" for="c-35783522">[-]</label><label class="expand" for="c-35783522">[1 more]</label></div><br/><div class="children"><div class="content">Just out of curiosity are you using got 4 or 3.5?</div><br/></div></div><div id="35783557" class="c"><input type="checkbox" id="c-35783557" checked=""/><div class="controls bullet"><span class="by">userbinator</span><span>|</span><a href="#35783494">parent</a><span>|</span><a href="#35783522">prev</a><span>|</span><a href="#35784922">next</a><span>|</span><label class="collapse" for="c-35783557">[-]</label><label class="expand" for="c-35783557">[3 more]</label></div><br/><div class="children"><div class="content">It&#x27;s become hard, and will become harder, precisely because of things like GPT (unintentionally) spreading misinformation. I&#x27;m against censorship in general, and this is no exception, but I do hope it leads to people becoming more critical of what they consume. However, I suspect that instead we will unfortunately see the continued cycle of creating large masses of people &quot;educated&quot; on such widely-propagated half-truths, while only a tiny subset of the population will have the actual truth.</div><br/><div id="35783631" class="c"><input type="checkbox" id="c-35783631" checked=""/><div class="controls bullet"><span class="by">brokencode</span><span>|</span><a href="#35783494">root</a><span>|</span><a href="#35783557">parent</a><span>|</span><a href="#35784922">next</a><span>|</span><label class="collapse" for="c-35783631">[-]</label><label class="expand" for="c-35783631">[2 more]</label></div><br/><div class="children"><div class="content">The internet is a misinformation spreading machine. GPT is new and will surely improve over time, but I can’t say the same for the internet.<p>In an ideal world, people would learn only from high quality sources like books and schools. But a shocking amount of people learn mostly through social media and whatever they find on Google.<p>I think LLMs will provide a better alternative.</div><br/><div id="35783730" class="c"><input type="checkbox" id="c-35783730" checked=""/><div class="controls bullet"><span class="by">vanviegen</span><span>|</span><a href="#35783494">root</a><span>|</span><a href="#35783631">parent</a><span>|</span><a href="#35784922">next</a><span>|</span><label class="collapse" for="c-35783730">[-]</label><label class="expand" for="c-35783730">[1 more]</label></div><br/><div class="children"><div class="content">Exactly! LLMs will be able&#x2F;are able to construct their answers not just based on one Reddit comment they found somewhere, but on &quot;all* comments as well as more reliable sources, such as the actual source code for the thing under discussion, scientific debate, (case) law texts, books, etc. They already seem somewhat capable of weighing source reliability.</div><br/></div></div></div></div></div></div></div></div><div id="35784922" class="c"><input type="checkbox" id="c-35784922" checked=""/><div class="controls bullet"><span class="by">noduerme</span><span>|</span><a href="#35783494">prev</a><span>|</span><a href="#35783518">next</a><span>|</span><label class="collapse" for="c-35784922">[-]</label><label class="expand" for="c-35784922">[1 more]</label></div><br/><div class="children"><div class="content">Why learn? The best part about LLMs is you and your children will never need to know anything or think anything ever again.</div><br/></div></div><div id="35783518" class="c"><input type="checkbox" id="c-35783518" checked=""/><div class="controls bullet"><span class="by">chazeon</span><span>|</span><a href="#35784922">prev</a><span>|</span><a href="#35783539">next</a><span>|</span><label class="collapse" for="c-35783518">[-]</label><label class="expand" for="c-35783518">[2 more]</label></div><br/><div class="children"><div class="content">I really found asking GPT to put a math concept under a physics context very helpful for me. As a computational physics student, that is really how I understand math and the world. Only very few textbooks can help me with this.<p>From [<i>Make Something Wonderful: Steve Jobs in His Own Words</i>][1], Steve once said in a interview in 1983:<p>&gt; The problem was, you can&#x27;t ask Aristotle a question. And I think, as we look towards the next fifty to one hundred years, if we really can come up with these machines that can capture an underlying spirit, or an underlying set of principles, or an underlying way of looking at the world, then, when the next Aristotle comes around, maybe if he carries around one of these machines with him his whole life–his or her whole life–and types in all this stuff, then maybe someday, after this person&#x27;s dead and gone, we can ask this machine, “Hey, what would Aristotle have said? What about this?” And maybe we won&#x27;t get the right answer, but maybe we will. And that&#x27;s really exciting to me. And that&#x27;s one of the reasons I&#x27;m doing what I&#x27;m doing.<p>And this <i>future</i>, expected &quot;next fifty to one hundred years&quot;, is somewhat here already.<p>[1]: <a href="https:&#x2F;&#x2F;book.stevejobsarchive.com&#x2F;" rel="nofollow">https:&#x2F;&#x2F;book.stevejobsarchive.com&#x2F;</a></div><br/><div id="35784338" class="c"><input type="checkbox" id="c-35784338" checked=""/><div class="controls bullet"><span class="by">waterhouse</span><span>|</span><a href="#35783518">parent</a><span>|</span><a href="#35783539">next</a><span>|</span><label class="collapse" for="c-35784338">[-]</label><label class="expand" for="c-35784338">[1 more]</label></div><br/><div class="children"><div class="content">You might like the quote from Vladimir Arnold: &quot;Mathematics is a part of physics. Physics is an experimental science, a part of natural science. Mathematics is the part of physics where experiments are cheap.&quot;</div><br/></div></div></div></div><div id="35783539" class="c"><input type="checkbox" id="c-35783539" checked=""/><div class="controls bullet"><span class="by">kccqzy</span><span>|</span><a href="#35783518">prev</a><span>|</span><a href="#35783582">next</a><span>|</span><label class="collapse" for="c-35783539">[-]</label><label class="expand" for="c-35783539">[8 more]</label></div><br/><div class="children"><div class="content">You can downvote me but I think OP hasn&#x27;t learned how to learn yet. If OP reads Wikipedia by understanding every sentence and clicking on every link, that&#x27;s deliberately sabotaging his own learning. Attitudes like &quot;I don&#x27;t really feel like spelunking through a ton more articles&quot; simply shows OP isn&#x27;t interested in learning per se, just quick answers.<p>OP learns in a way that&#x27;s very child-like. When you are a five-year-old it&#x27;s okay to learn by asking everything. That stops being acceptable by the age of fifteen. OP hasn&#x27;t learned any research skills yet, and when OP&#x27;s needs inevitably exhausts the ability of LLMs, OP would be utterly unable to read an encyclopedia or a research paper or perhaps a textbook.</div><br/><div id="35783828" class="c"><input type="checkbox" id="c-35783828" checked=""/><div class="controls bullet"><span class="by">lIl-IIIl</span><span>|</span><a href="#35783539">parent</a><span>|</span><a href="#35783586">next</a><span>|</span><label class="collapse" for="c-35783828">[-]</label><label class="expand" for="c-35783828">[1 more]</label></div><br/><div class="children"><div class="content">The problem is Wikipedia. OP&#x27;s approach is perfectly natural. Textbooks are designed for OP&#x27;s approach because that&#x27;s how people learn.<p>If I want to learn about topic C which requires knowledge of topics A and B, but C can also be generalized to concepts X and Y, it will be very hard to learn from Wikipedia.<p>If I don&#x27;t know how to add numbers and look up &quot;sum&quot; on Wikipedia, in the second sentence I learn that summing is used for functions, vectors, matrices, and other things I don&#x27;t know about. This is a cool feature and I love it for exploring but hate it for learning things that require a few layers of concepts to get.<p>Textbooks do the opposite and are awesome. An electronics textbook will take you step by step through all the concepts to get to LEDs, without &quot;forward references&quot; to the concepts you haven&#x27;t learned yet.<p>The &quot;problem&quot; with textbooks is that it will take a while to get to the destination. LEDs might be in chapter 15 and you may not want to spend a few months going through chapters 1-14. You don&#x27;t know what you will need to understand chapter 15.<p>But you can perhaps work backward - you are guaranteed that any unfamiliar concept introduced in chapter 15 will be covered in chapters 1-14, and that there is no rabbit hole.<p>ChatGPT or a personal tutor can shortcut this by giving you just the &quot;narrow path&quot; of knowledge to understand the concept that you want to learn.</div><br/></div></div><div id="35783586" class="c"><input type="checkbox" id="c-35783586" checked=""/><div class="controls bullet"><span class="by">tux3</span><span>|</span><a href="#35783539">parent</a><span>|</span><a href="#35783828">prev</a><span>|</span><a href="#35783954">next</a><span>|</span><label class="collapse" for="c-35783586">[-]</label><label class="expand" for="c-35783586">[1 more]</label></div><br/><div class="children"><div class="content">I notice that this contains only  criticism and comparison to children, without offering a better way to learn.<p>If OP reads your comment, they will be no better at learning than they were before. In that way, it&#x27;s a pretty unhelpful comment.</div><br/></div></div><div id="35783954" class="c"><input type="checkbox" id="c-35783954" checked=""/><div class="controls bullet"><span class="by">vipshek</span><span>|</span><a href="#35783539">parent</a><span>|</span><a href="#35783586">prev</a><span>|</span><a href="#35784393">next</a><span>|</span><label class="collapse" for="c-35783954">[-]</label><label class="expand" for="c-35783954">[1 more]</label></div><br/><div class="children"><div class="content">OP here. I think learning exists on a broad spectrum. On one end, you&#x27;re just indulging curiosity (&quot;I wonder how...?&quot;). On the other, you&#x27;re trying to build deep understanding and expertise.<p>I completely agree that for the latter goal, the approaches in the blog post are insufficient, even undesirable. And I do worry that the way I engage with content on the web is weakening my ability to go deep on a subject I&#x27;m interested in.<p>But I do think there is value in just being able to indulge curiosity quickly and consistently. Not only is it rewarding in its own right, but it also provides the spark that leads you to eventually go deeper.<p>Lately, I&#x27;ve found myself sitting at a laptop with friends, asking GPT a question, reading and discussing the response, and then coming up with and asking followup questions as a group. I don&#x27;t think we would&#x27;ve done that in the past, because the interface of search engines and webpages and browser tabs were too unwieldy to engage with collectively. It just feels like a completely new way to learn things, and what&#x27;s what I&#x27;m most excited about.</div><br/></div></div><div id="35784393" class="c"><input type="checkbox" id="c-35784393" checked=""/><div class="controls bullet"><span class="by">WA</span><span>|</span><a href="#35783539">parent</a><span>|</span><a href="#35783954">prev</a><span>|</span><a href="#35783566">next</a><span>|</span><label class="collapse" for="c-35784393">[-]</label><label class="expand" for="c-35784393">[2 more]</label></div><br/><div class="children"><div class="content">I agree, especially if you consider these were the questions on OP&#x27;s mind:<p>&gt; <i>just out of curiosity, I wanted to learn more. I get that LEDs consume less energy and release less heat, and that they&#x27;re made using semiconductors. But what kinds of semiconductors? How do semiconductors work in general, anyway?</i><p>And they proceed to type &quot;LED&quot; into Google. Why not &quot;led what kind of semiconductor&quot; and &quot;how do semiconductors work in leds&quot;?<p>I assume, OP didn&#x27;t write &quot;LED&quot; in the ChatGPT text box without any context either.</div><br/><div id="35784561" class="c"><input type="checkbox" id="c-35784561" checked=""/><div class="controls bullet"><span class="by">vipshek</span><span>|</span><a href="#35783539">root</a><span>|</span><a href="#35784393">parent</a><span>|</span><a href="#35783566">next</a><span>|</span><label class="collapse" for="c-35784561">[-]</label><label class="expand" for="c-35784561">[1 more]</label></div><br/><div class="children"><div class="content">For what it’s worth, the transcript I posted is 100% of the conversation I had with GPT-4. “How do LEDs work?” was the only thing I wrote in the initial question.<p>I did try Googling “how do LEDs work” for comparison, but it yielded the same top few results. Of course, I could have iteratively tried different search queries to get to the answers I wanted, but this gets at my real point: I don’t <i>have</i> to formulate 5 different search queries anymore, allowing me to maintain one focused line of inquiry. I talk about this a little in the “fewer browser tabs” bit of the post.<p>I do think someone could create an alternative search UI that would be better for learning on the web. Something where you can run multiple searches and “collect” the useful information you find into a single page, rather than having the results split across a mess of browser tabs and note-taking windows. Maybe I just find juggling many browser tabs more annoying than other people do?<p>Anyway, I tried the queries you posted above, and most resources I found were still very confusing for a layman. The one exception is this page, which I think does a great job of introducing additional complexity on this topic gradually: <a href="https:&#x2F;&#x2F;electronics.howstuffworks.com&#x2F;led.htm" rel="nofollow">https:&#x2F;&#x2F;electronics.howstuffworks.com&#x2F;led.htm</a></div><br/></div></div></div></div><div id="35783566" class="c"><input type="checkbox" id="c-35783566" checked=""/><div class="controls bullet"><span class="by">thsbrown</span><span>|</span><a href="#35783539">parent</a><span>|</span><a href="#35784393">prev</a><span>|</span><a href="#35783582">next</a><span>|</span><label class="collapse" for="c-35783566">[-]</label><label class="expand" for="c-35783566">[2 more]</label></div><br/><div class="children"><div class="content">Just out of curiosity what would say is the optimal way to learn from an encyclopedia, research paper or Wikipedia?</div><br/><div id="35783743" class="c"><input type="checkbox" id="c-35783743" checked=""/><div class="controls bullet"><span class="by">dmbche</span><span>|</span><a href="#35783539">root</a><span>|</span><a href="#35783566">parent</a><span>|</span><a href="#35783582">next</a><span>|</span><label class="collapse" for="c-35783743">[-]</label><label class="expand" for="c-35783743">[1 more]</label></div><br/><div class="children"><div class="content">Sticking to what you want to understand - for example, when reading a paper, you don&#x27;t necessarily need to read the methodology, especially if it&#x27;s out of your field. Read the abstract and the conclusion, identify any part of it that you are suprised by and would like further explanation, and go see that part of the paper.<p>A lot of the paper is talking to peer and people wanting to verify the validity of the paper - by it being peer reviewed, you can mostly assume that the paper is valid, and stick to what the paper is saying instead of it&#x27;s methodology.</div><br/></div></div></div></div></div></div><div id="35783582" class="c"><input type="checkbox" id="c-35783582" checked=""/><div class="controls bullet"><span class="by">brokencode</span><span>|</span><a href="#35783539">prev</a><span>|</span><a href="#35783488">next</a><span>|</span><label class="collapse" for="c-35783582">[-]</label><label class="expand" for="c-35783582">[5 more]</label></div><br/><div class="children"><div class="content">I noticed a while back that the internet has made me terribly prone to skimming. It got to a point where I could hardly stand to read anything longer than a short news article.<p>To learn anything useful on the internet, you pretty much have to skim. So much of the internet is so loaded with filler and BS that it is hardly worth reading at all.<p>With ChatGPT, it’s incredibly refreshing to be able to ask a question and get nothing other than a concise answer. No skimming required. I feel so much more focused and better able to learn this way.</div><br/><div id="35784611" class="c"><input type="checkbox" id="c-35784611" checked=""/><div class="controls bullet"><span class="by">phh</span><span>|</span><a href="#35783582">parent</a><span>|</span><a href="#35783747">next</a><span>|</span><label class="collapse" for="c-35784611">[-]</label><label class="expand" for="c-35784611">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s interesting because that&#x27;s my biggest gripe against ChatGPT, it&#x27;s too verbose and very hard to skim through. Compared to stack overflow answers it&#x27;ll be easily four times longer. Sure compared to for instance news website, it is less verbose, but those are easy to skim. I&#x27;m still able to read through well written text without skimming, though yes most of the texts I&#x27;ll read I&#x27;ll skim through, then go back and then to improve my global understanding, which I think is beneficial</div><br/></div></div><div id="35783747" class="c"><input type="checkbox" id="c-35783747" checked=""/><div class="controls bullet"><span class="by">the_duke</span><span>|</span><a href="#35783582">parent</a><span>|</span><a href="#35784611">prev</a><span>|</span><a href="#35783944">next</a><span>|</span><label class="collapse" for="c-35783747">[-]</label><label class="expand" for="c-35783747">[2 more]</label></div><br/><div class="children"><div class="content">I have a standard copy n paste prompt that instructs it to keep answers concise and free of boilerplate.<p>Otherwise ChatGPT is prone to injecting lots of filler text as well.</div><br/><div id="35784708" class="c"><input type="checkbox" id="c-35784708" checked=""/><div class="controls bullet"><span class="by">piaste</span><span>|</span><a href="#35783582">root</a><span>|</span><a href="#35783747">parent</a><span>|</span><a href="#35783944">next</a><span>|</span><label class="collapse" for="c-35784708">[-]</label><label class="expand" for="c-35784708">[1 more]</label></div><br/><div class="children"><div class="content">Care to share that prompt? I find the fillers and disclaimers very grating too.</div><br/></div></div></div></div><div id="35783944" class="c"><input type="checkbox" id="c-35783944" checked=""/><div class="controls bullet"><span class="by">bob_boblaw</span><span>|</span><a href="#35783582">parent</a><span>|</span><a href="#35783747">prev</a><span>|</span><a href="#35783488">next</a><span>|</span><label class="collapse" for="c-35783944">[-]</label><label class="expand" for="c-35783944">[1 more]</label></div><br/><div class="children"><div class="content">hmm that makes sense. I too have skimmed way too much because of the BS. and ya it is refreshing now that I think about it</div><br/></div></div></div></div><div id="35783488" class="c"><input type="checkbox" id="c-35783488" checked=""/><div class="controls bullet"><span class="by">homieg33</span><span>|</span><a href="#35783582">prev</a><span>|</span><a href="#35784690">next</a><span>|</span><label class="collapse" for="c-35783488">[-]</label><label class="expand" for="c-35783488">[7 more]</label></div><br/><div class="children"><div class="content">It’s nice to be able to ask ChatGPT a half baked, poorly researched, poorly worded question with bad grammar yet get a totally good faith response back that’s a springboard for follow up questions. Whereas if you did the same thing on any stack exchange site you get downvotes and comments like “please read the guidelines and edit your question.”</div><br/><div id="35783528" class="c"><input type="checkbox" id="c-35783528" checked=""/><div class="controls bullet"><span class="by">pavlov</span><span>|</span><a href="#35783488">parent</a><span>|</span><a href="#35783551">next</a><span>|</span><label class="collapse" for="c-35783528">[-]</label><label class="expand" for="c-35783528">[5 more]</label></div><br/><div class="children"><div class="content">Kindness and patience have always been in short supply on the public internet, but AI can simulate them in infinite amounts.<p>That’s a positive thing about this generative AI revolution that I haven’t really thought about in those terms until now.</div><br/><div id="35783834" class="c"><input type="checkbox" id="c-35783834" checked=""/><div class="controls bullet"><span class="by">tomnipotent</span><span>|</span><a href="#35783488">root</a><span>|</span><a href="#35783528">parent</a><span>|</span><a href="#35783588">next</a><span>|</span><label class="collapse" for="c-35783834">[-]</label><label class="expand" for="c-35783834">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Kindness and patience have always been in short supply<p>Agreed. Look at all the responses in this post attacking the author for how he learns, it&#x27;s embarrassing to read. Now imagine that person is actually a teacher or TA, or worse a co-worker. I&#x27;d much rather deal with an imperfect ChatGPT session than that kind of flippancy.</div><br/></div></div><div id="35783588" class="c"><input type="checkbox" id="c-35783588" checked=""/><div class="controls bullet"><span class="by">p-e-w</span><span>|</span><a href="#35783488">root</a><span>|</span><a href="#35783528">parent</a><span>|</span><a href="#35783834">prev</a><span>|</span><a href="#35783551">next</a><span>|</span><label class="collapse" for="c-35783588">[-]</label><label class="expand" for="c-35783588">[3 more]</label></div><br/><div class="children"><div class="content">That is actually <i>the</i> killer feature of interactive AIs.<p>People go on and on and on about &quot;accuracy&quot;, completely ignoring that accuracy is irrelevant to 99.9% of things that humans do in their everyday lives.<p>Simulating (positive) human interaction is far more impactful than getting facts correct.</div><br/><div id="35783760" class="c"><input type="checkbox" id="c-35783760" checked=""/><div class="controls bullet"><span class="by">kerkeslager</span><span>|</span><a href="#35783488">root</a><span>|</span><a href="#35783588">parent</a><span>|</span><a href="#35783551">next</a><span>|</span><label class="collapse" for="c-35783760">[-]</label><label class="expand" for="c-35783760">[2 more]</label></div><br/><div class="children"><div class="content">What does it mean to have a positive interaction with someone who consistently tells you misinformation with a high degree of confidence?</div><br/><div id="35784736" class="c"><input type="checkbox" id="c-35784736" checked=""/><div class="controls bullet"><span class="by">p-e-w</span><span>|</span><a href="#35783488">root</a><span>|</span><a href="#35783760">parent</a><span>|</span><a href="#35783551">next</a><span>|</span><label class="collapse" for="c-35784736">[-]</label><label class="expand" for="c-35784736">[1 more]</label></div><br/><div class="children"><div class="content">If you don&#x27;t already know the answer to that question, I doubt it would be possible to explain it to you. Looking for precise definitions of essential human qualities is a fool&#x27;s errand.</div><br/></div></div></div></div></div></div></div></div><div id="35783551" class="c"><input type="checkbox" id="c-35783551" checked=""/><div class="controls bullet"><span class="by">thsbrown</span><span>|</span><a href="#35783488">parent</a><span>|</span><a href="#35783528">prev</a><span>|</span><a href="#35784690">next</a><span>|</span><label class="collapse" for="c-35783551">[-]</label><label class="expand" for="c-35783551">[1 more]</label></div><br/><div class="children"><div class="content">Completely agree. ChatGPT can be an incredible tool for getting a lay of the land on a subject or topic you don&#x27;t know much about.<p>On that note, search in that regard always reminded me of those times where you ask a teacher how to spell a word and they say to look it up in the dictionary.</div><br/></div></div></div></div><div id="35784690" class="c"><input type="checkbox" id="c-35784690" checked=""/><div class="controls bullet"><span class="by">lars512</span><span>|</span><a href="#35783488">prev</a><span>|</span><a href="#35784252">next</a><span>|</span><label class="collapse" for="c-35784690">[-]</label><label class="expand" for="c-35784690">[1 more]</label></div><br/><div class="children"><div class="content">I totally agree with the author, I find I&#x27;m finally able to ask about a range of new concepts, get them explained at my level, and dive deeper as curiosity warrants it.<p>It&#x27;s also magical when you summarise the understanding you&#x27;ve reached back to it, and it can confirm or tweak it for you.<p>In other ways it&#x27;s also nice to just pay for it and then to be in an advertising free space.<p>One critique is that when you ask it to compare things it&#x27;s often too balanced or too positive&#x2F;enthusiastic (&quot;both are great for different reasons!&quot;) when what you want is a more sober analysis. But you can usually do some prompt management to adjust it back to a reasonable range.</div><br/></div></div><div id="35784252" class="c"><input type="checkbox" id="c-35784252" checked=""/><div class="controls bullet"><span class="by">rapsacnz</span><span>|</span><a href="#35784690">prev</a><span>|</span><a href="#35783612">next</a><span>|</span><label class="collapse" for="c-35784252">[-]</label><label class="expand" for="c-35784252">[1 more]</label></div><br/><div class="children"><div class="content">Don&#x27;t forget that GPT was trained on data from all the sources that failed you. So if we all collectively neglect them, and they fall over, we will lose many valuable resources.<p>I think we need to think about how to keep these valuable sites going, because they are ultimately providing most of the value of the various available language models.</div><br/></div></div><div id="35783612" class="c"><input type="checkbox" id="c-35783612" checked=""/><div class="controls bullet"><span class="by">kumarvvr</span><span>|</span><a href="#35784252">prev</a><span>|</span><a href="#35783431">next</a><span>|</span><label class="collapse" for="c-35783612">[-]</label><label class="expand" for="c-35783612">[4 more]</label></div><br/><div class="children"><div class="content">This is so ridiculous.<p>GPT is like that &quot;know-it-all&quot; friend we have who just has something to say about <i>anything</i>, with knowledge skimmed from the internet.<p>GPT is a language model. It outputs <i>what you want to hear</i>, not what is correct.</div><br/><div id="35783636" class="c"><input type="checkbox" id="c-35783636" checked=""/><div class="controls bullet"><span class="by">p-e-w</span><span>|</span><a href="#35783612">parent</a><span>|</span><a href="#35783431">next</a><span>|</span><label class="collapse" for="c-35783636">[-]</label><label class="expand" for="c-35783636">[3 more]</label></div><br/><div class="children"><div class="content">&gt; It outputs what you want to hear<p>Nonsense. How could it possibly know &quot;what you want to hear&quot;?</div><br/><div id="35784468" class="c"><input type="checkbox" id="c-35784468" checked=""/><div class="controls bullet"><span class="by">jhugo</span><span>|</span><a href="#35783612">root</a><span>|</span><a href="#35783636">parent</a><span>|</span><a href="#35783647">next</a><span>|</span><label class="collapse" for="c-35784468">[-]</label><label class="expand" for="c-35784468">[1 more]</label></div><br/><div class="children"><div class="content">It outputs what some idealised version of a person wants to hear, where what is &quot;idealised&quot; has been determined by its training. I&#x27;ve noticed, for example, that it appears to have been trained to want to give responses that seem helpful, and make you trust it. When it&#x27;s outputting garbage code that doesn&#x27;t work, it will often say things like &quot;I have tested this and it works correctly&quot;, despite that being an impossibility.</div><br/></div></div><div id="35783647" class="c"><input type="checkbox" id="c-35783647" checked=""/><div class="controls bullet"><span class="by">kumarvvr</span><span>|</span><a href="#35783612">root</a><span>|</span><a href="#35783636">parent</a><span>|</span><a href="#35784468">prev</a><span>|</span><a href="#35783431">next</a><span>|</span><label class="collapse" for="c-35783647">[-]</label><label class="expand" for="c-35783647">[1 more]</label></div><br/><div class="children"><div class="content">Because we tell it what we want.<p>&quot;How do I do this&quot;<p>&quot;How do I do that&quot;<p>&quot;What is this&quot;<p>&quot;What is that&quot;</div><br/></div></div></div></div></div></div><div id="35783431" class="c"><input type="checkbox" id="c-35783431" checked=""/><div class="controls bullet"><span class="by">grrdotcloud</span><span>|</span><a href="#35783612">prev</a><span>|</span><a href="#35783736">next</a><span>|</span><label class="collapse" for="c-35783431">[-]</label><label class="expand" for="c-35783431">[2 more]</label></div><br/><div class="children"><div class="content">Imagine being able to ask questions and get answers back based upon understanding, and not upon a curriculum or agenda. I have found this method to allow me to consume information much faster while skipping over the often tedious topics.</div><br/><div id="35783772" class="c"><input type="checkbox" id="c-35783772" checked=""/><div class="controls bullet"><span class="by">kerkeslager</span><span>|</span><a href="#35783431">parent</a><span>|</span><a href="#35783736">next</a><span>|</span><label class="collapse" for="c-35783772">[-]</label><label class="expand" for="c-35783772">[1 more]</label></div><br/><div class="children"><div class="content">Do you think that &quot;tediousness&quot; is a good indicator of whether a topic is important?</div><br/></div></div></div></div><div id="35783736" class="c"><input type="checkbox" id="c-35783736" checked=""/><div class="controls bullet"><span class="by">enoch2090</span><span>|</span><a href="#35783431">prev</a><span>|</span><a href="#35783485">next</a><span>|</span><label class="collapse" for="c-35783736">[-]</label><label class="expand" for="c-35783736">[1 more]</label></div><br/><div class="children"><div class="content">Now whenever I need to use a fancy new package that I never used of, I use LangChain to collect all documents from the package document site, load them into a vectorDB and start asking GPT questions. This method works in 80% of the time.
One pitfall is that with this method I only get what I want. I don&#x27;t get a deep understanding of that package as it used to be if I carefully read over the documents. Still finding a balancing point in between.</div><br/></div></div><div id="35783485" class="c"><input type="checkbox" id="c-35783485" checked=""/><div class="controls bullet"><span class="by">DotaFan</span><span>|</span><a href="#35783736">prev</a><span>|</span><a href="#35784040">next</a><span>|</span><label class="collapse" for="c-35783485">[-]</label><label class="expand" for="c-35783485">[3 more]</label></div><br/><div class="children"><div class="content">It is very helpful to learn new stuff indeed, I am personally using <a href="https:&#x2F;&#x2F;www.phind.com">https:&#x2F;&#x2F;www.phind.com</a>.</div><br/><div id="35783562" class="c"><input type="checkbox" id="c-35783562" checked=""/><div class="controls bullet"><span class="by">an_aparallel</span><span>|</span><a href="#35783485">parent</a><span>|</span><a href="#35783675">next</a><span>|</span><label class="collapse" for="c-35783562">[-]</label><label class="expand" for="c-35783562">[1 more]</label></div><br/><div class="children"><div class="content">im using phind too - phinding it pretty incredible.  As someone learning development - it has helped me with so many of the annoyances of learning dev environments, like:<p><i>setting up a venv..
</i>environmental variable issues in windows.
*diagnosing a UTF-8 issue in windows.<p>i get that professionals problems would be harder to answer...however, getting responses without wading through stack exchange entry after entry has really kept me focused, and prevented the often times frustrating recursive spiral which is getting an issue with your issues issue...</div><br/></div></div><div id="35783675" class="c"><input type="checkbox" id="c-35783675" checked=""/><div class="controls bullet"><span class="by">pulvinar</span><span>|</span><a href="#35783485">parent</a><span>|</span><a href="#35783562">prev</a><span>|</span><a href="#35784040">next</a><span>|</span><label class="collapse" for="c-35783675">[-]</label><label class="expand" for="c-35783675">[1 more]</label></div><br/><div class="children"><div class="content">I like how it checks its facts (mostly, anyway).<p>It didn&#x27;t give a wrong answer when asked &quot;Is there a digital to analog converter with an 8V analog range and serial input?&quot;, which another poster (mhb) had shown to trip up plain GPT4.</div><br/></div></div></div></div><div id="35784040" class="c"><input type="checkbox" id="c-35784040" checked=""/><div class="controls bullet"><span class="by">andai</span><span>|</span><a href="#35783485">prev</a><span>|</span><a href="#35783753">next</a><span>|</span><label class="collapse" for="c-35784040">[-]</label><label class="expand" for="c-35784040">[1 more]</label></div><br/><div class="children"><div class="content">Most people seem to prefer learning by talking and asking questions. At least, that&#x27;s what I&#x27;ve gathered from Discord servers where 99.9% of people ask questions answered on the first page of the Readme ;)</div><br/></div></div><div id="35783753" class="c"><input type="checkbox" id="c-35783753" checked=""/><div class="controls bullet"><span class="by">kweingar</span><span>|</span><a href="#35784040">prev</a><span>|</span><a href="#35784587">next</a><span>|</span><label class="collapse" for="c-35783753">[-]</label><label class="expand" for="c-35783753">[1 more]</label></div><br/><div class="children"><div class="content">ChatGPT can be a great supplement for independent research. But when the article mentions a “curious seventh-grader”, I think we should focus on getting them quality human instruction whenever possible instead of just pointing them to ChatGPT.<p>ChatGPT addresses a scalability problem: not everyone has access to a tutor  or can just call up a teacher or mentor to learn and ask questions. But some in the tech industry claim that ChatGPT is as good as or even better than human instruction, which to me seems totally off base.<p>The biggest problem I see in using LLMs as a teacher-substitute is that LLMs answer the questions you ask, whereas a good teacher tells you what you need to hear. Maybe this is solvable with specialized model tuning, but we need to actually solve it before telling kids that the best way to learn is to talk to the computer.</div><br/></div></div><div id="35784587" class="c"><input type="checkbox" id="c-35784587" checked=""/><div class="controls bullet"><span class="by">butler14</span><span>|</span><a href="#35783753">prev</a><span>|</span><a href="#35783656">next</a><span>|</span><label class="collapse" for="c-35784587">[-]</label><label class="expand" for="c-35784587">[1 more]</label></div><br/><div class="children"><div class="content">This is the classic &quot;google is so crap now&quot;, then when you dig a bit, the search query is something incredibly broad (in this case &quot;led&quot;) or irrelevant, with the author then complaining about the quality of the results<p>I&#x27;m not taking anything away from Chat-GPT for this use case, but I see the above pattern in almost every Google bashing thread on HN.</div><br/></div></div><div id="35783656" class="c"><input type="checkbox" id="c-35783656" checked=""/><div class="controls bullet"><span class="by">shortsightedsid</span><span>|</span><a href="#35784587">prev</a><span>|</span><a href="#35783590">next</a><span>|</span><label class="collapse" for="c-35783656">[-]</label><label class="expand" for="c-35783656">[1 more]</label></div><br/><div class="children"><div class="content">Its almost as if ChatGPT is getting to be a form of dialogic learning [1]. While ChatGPT is not yet an authoritative source, it should be possible to get to such a future. The problem is with the ethics of it becoming an authoritative source and how it can possibly unlearn (or accept change or challenges). For now, the example OP provides is without authority where they learnt about a topic taking ChatGPT as a peer.<p>References:<p>1. <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Dialogic_learning" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Dialogic_learning</a></div><br/></div></div><div id="35783590" class="c"><input type="checkbox" id="c-35783590" checked=""/><div class="controls bullet"><span class="by">chx</span><span>|</span><a href="#35783656">prev</a><span>|</span><a href="#35783508">next</a><span>|</span><label class="collapse" for="c-35783590">[-]</label><label class="expand" for="c-35783590">[21 more]</label></div><br/><div class="children"><div class="content">This is incredibly, incredibly naive. &quot;Within minutes, I learned&quot; -- absolutely nothing. At most you&#x27;ve learned how the answers to your question would sound like. <i>They are not the answers</i>.</div><br/><div id="35783617" class="c"><input type="checkbox" id="c-35783617" checked=""/><div class="controls bullet"><span class="by">p-e-w</span><span>|</span><a href="#35783590">parent</a><span>|</span><a href="#35783725">next</a><span>|</span><label class="collapse" for="c-35783617">[-]</label><label class="expand" for="c-35783617">[14 more]</label></div><br/><div class="children"><div class="content">&gt; They are not the answers.<p>You can&#x27;t possibly know that.</div><br/><div id="35783626" class="c"><input type="checkbox" id="c-35783626" checked=""/><div class="controls bullet"><span class="by">chx</span><span>|</span><a href="#35783590">root</a><span>|</span><a href="#35783617">parent</a><span>|</span><a href="#35783725">next</a><span>|</span><label class="collapse" for="c-35783626">[-]</label><label class="expand" for="c-35783626">[13 more]</label></div><br/><div class="children"><div class="content">I can.<p>Even if the answers accidentally happen to be correct, that&#x27;s just the broken clock happens to be correct twice a day. The information value of answers by ChatGPT is <i>zero</i>.</div><br/><div id="35783701" class="c"><input type="checkbox" id="c-35783701" checked=""/><div class="controls bullet"><span class="by">tempestn</span><span>|</span><a href="#35783590">root</a><span>|</span><a href="#35783626">parent</a><span>|</span><a href="#35783639">next</a><span>|</span><label class="collapse" for="c-35783701">[-]</label><label class="expand" for="c-35783701">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not correct by accident. It&#x27;s not generating responses randomly, but based on extensive training data.  The accuracy of answers is very high, especially on uncontroversial topics like most of the examples in the OP. And the author even described cross-checking the answers for validity and confirming that it was generally correct.  (I was also an electrical engineer once upon a time and nothing jumped out at me as wrong, but admittedly it&#x27;s been quite a while!)<p>You can&#x27;t rely in it being 100% correct, but that&#x27;s very different from it having no informational value at all. When it comes down to it, you can&#x27;t rely on anything being 100% correct. I recall finding multiple errors in textbooks in the past, and certainly Wikipedia is wrong about all kinds of things; that doesn&#x27;t make them useless.  It just means in situations where it&#x27;s critical to be correct, you need to double-check.  But often that&#x27;s not necessary, and when it is, it&#x27;s a lot easier to start with something and then verify it than to not have the tool in the first place.</div><br/></div></div><div id="35783639" class="c"><input type="checkbox" id="c-35783639" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#35783590">root</a><span>|</span><a href="#35783626">parent</a><span>|</span><a href="#35783701">prev</a><span>|</span><a href="#35783708">next</a><span>|</span><label class="collapse" for="c-35783639">[-]</label><label class="expand" for="c-35783639">[9 more]</label></div><br/><div class="children"><div class="content">It sounds to me like you&#x27;re letting your firmly held existing biases get in the way of you learning a powerful new tool.<p>As I said in <a href="https:&#x2F;&#x2F;simonwillison.net&#x2F;2023&#x2F;Apr&#x2F;8&#x2F;llms-break-the-internet&#x2F;" rel="nofollow">https:&#x2F;&#x2F;simonwillison.net&#x2F;2023&#x2F;Apr&#x2F;8&#x2F;llms-break-the-internet...</a><p>&gt; This is the thing I worry that people are sleeping on. People who think “these language models lie to you all the time” (which they do) and “they will produce buggy code with security holes”—every single complaint about these things is true, and yet, despite all of that, the productivity benefits you get if you lean into them and say OK, how do I work with something that’s completely unreliable, that invents things, that comes up with APIs that don’t exist… how do I use that to enhance my workflow anyway?</div><br/><div id="35783691" class="c"><input type="checkbox" id="c-35783691" checked=""/><div class="controls bullet"><span class="by">chx</span><span>|</span><a href="#35783590">root</a><span>|</span><a href="#35783639">parent</a><span>|</span><a href="#35783708">next</a><span>|</span><label class="collapse" for="c-35783691">[-]</label><label class="expand" for="c-35783691">[8 more]</label></div><br/><div class="children"><div class="content">That large language models are stochastic parrots is not a bias, it&#x27;s a fact. You feed it a very large amount of structured data and then put up a question which it&#x27;ll answer with a series of those which are most likely to follow. <i>There is nothing else</i>.</div><br/><div id="35783707" class="c"><input type="checkbox" id="c-35783707" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#35783590">root</a><span>|</span><a href="#35783691">parent</a><span>|</span><a href="#35783721">next</a><span>|</span><label class="collapse" for="c-35783707">[-]</label><label class="expand" for="c-35783707">[1 more]</label></div><br/><div class="children"><div class="content">I know how they work. What&#x27;s so interesting to me about them is how useful they turn out to be despite the seemingly dumb and simple way they are built.<p>I encourage you to experiment more! Here are my notes so far: <a href="https:&#x2F;&#x2F;simonwillison.net&#x2F;tags&#x2F;llms&#x2F;" rel="nofollow">https:&#x2F;&#x2F;simonwillison.net&#x2F;tags&#x2F;llms&#x2F;</a></div><br/></div></div><div id="35783721" class="c"><input type="checkbox" id="c-35783721" checked=""/><div class="controls bullet"><span class="by">p-e-w</span><span>|</span><a href="#35783590">root</a><span>|</span><a href="#35783691">parent</a><span>|</span><a href="#35783707">prev</a><span>|</span><a href="#35783705">next</a><span>|</span><label class="collapse" for="c-35783721">[-]</label><label class="expand" for="c-35783721">[5 more]</label></div><br/><div class="children"><div class="content">Do you have <i>any</i> evidence that human minds work substantially different from that?</div><br/><div id="35783838" class="c"><input type="checkbox" id="c-35783838" checked=""/><div class="controls bullet"><span class="by">chx</span><span>|</span><a href="#35783590">root</a><span>|</span><a href="#35783721">parent</a><span>|</span><a href="#35783705">next</a><span>|</span><label class="collapse" for="c-35783838">[-]</label><label class="expand" for="c-35783838">[4 more]</label></div><br/><div class="children"><div class="content">Yes. Human minds often craft sentences which contain words together which never occurred in the same sentence before, not even close:<p>&gt; There was a boy called Eustace Clarence Scrubb, and he almost deserved it<p>&gt; Everything starts somewhere, although many physicists disagree.<p>&gt; It was a nice day. All the days had been nice. There had been rather more than seven of them so far, and rain hadn&#x27;t been invented yet<p>&gt; My father had a face that could stop a clock.<p>&gt; It is important, when killing a nun, to ensure that you bring an army of sufficient size.<p>&gt; In the myriadic year of our Lord—the ten thousandth year of the King Undying, the kindly Prince of Death!— Gideon Nav packed her sword, her shoes, and her dirty magazines, and she escaped from the House of the Ninth.<p>There&#x27;s just no end to these.<p>And, of course, science is full of these too, one that jumps to mind is Shinichi Mochizuki&#x27;s claimed proof of the ABC conjecture which has been proven flawed as it often happens but it was certainly a credible proof despite written in a language no mathematician have ever seen.</div><br/><div id="35784025" class="c"><input type="checkbox" id="c-35784025" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#35783590">root</a><span>|</span><a href="#35783838">parent</a><span>|</span><a href="#35784106">next</a><span>|</span><label class="collapse" for="c-35784025">[-]</label><label class="expand" for="c-35784025">[2 more]</label></div><br/><div class="children"><div class="content">&quot;Human minds often craft sentences which contain words together which never occurred in the same sentence before, not even close&quot;<p>Weirdly, LLMs do that too.<p>Have you heard of the &quot;Let’s be bear or bunny&quot; pattern?<p>My iPhone hallucinated that the other day, running a LLM directly on the phone!<p><a href="https:&#x2F;&#x2F;simonwillison.net&#x2F;2023&#x2F;May&#x2F;1&#x2F;lets-be-bear-or-bunny&#x2F;" rel="nofollow">https:&#x2F;&#x2F;simonwillison.net&#x2F;2023&#x2F;May&#x2F;1&#x2F;lets-be-bear-or-bunny&#x2F;</a></div><br/><div id="35784762" class="c"><input type="checkbox" id="c-35784762" checked=""/><div class="controls bullet"><span class="by">chx</span><span>|</span><a href="#35783590">root</a><span>|</span><a href="#35784025">parent</a><span>|</span><a href="#35784106">next</a><span>|</span><label class="collapse" for="c-35784762">[-]</label><label class="expand" for="c-35784762">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Weirdly, LLMs do that too.<p>Yes but those are <i>as every other thing they emit</i>, indeed , &quot;Let’s be bear or bunny&quot;, I heard it called AI hallucination I personally like to call it word salad.</div><br/></div></div></div></div><div id="35784106" class="c"><input type="checkbox" id="c-35784106" checked=""/><div class="controls bullet"><span class="by">pulvinar</span><span>|</span><a href="#35783590">root</a><span>|</span><a href="#35783838">parent</a><span>|</span><a href="#35784025">prev</a><span>|</span><a href="#35783705">next</a><span>|</span><label class="collapse" for="c-35784106">[-]</label><label class="expand" for="c-35784106">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s easy to cherry pick from the vast human repertoire. Here&#x27;s a sample from GPT4, where I picked one from a total of two:<p>&gt; The man on the moon fell off his ladder one Tuesday, a common enough occurrence that nobody really paid it any mind. Truth is, gravity&#x27;s always been a bit of a show-off, even in the star-dusted emptiness of space.</div><br/></div></div></div></div></div></div><div id="35783705" class="c"><input type="checkbox" id="c-35783705" checked=""/><div class="controls bullet"><span class="by">tempestn</span><span>|</span><a href="#35783590">root</a><span>|</span><a href="#35783691">parent</a><span>|</span><a href="#35783721">prev</a><span>|</span><a href="#35783708">next</a><span>|</span><label class="collapse" for="c-35783705">[-]</label><label class="expand" for="c-35783705">[1 more]</label></div><br/><div class="children"><div class="content">Yeah. And in doing so, it will usually give you the correct answers.</div><br/></div></div></div></div></div></div><div id="35783708" class="c"><input type="checkbox" id="c-35783708" checked=""/><div class="controls bullet"><span class="by">p-e-w</span><span>|</span><a href="#35783590">root</a><span>|</span><a href="#35783626">parent</a><span>|</span><a href="#35783639">prev</a><span>|</span><a href="#35783725">next</a><span>|</span><label class="collapse" for="c-35783708">[-]</label><label class="expand" for="c-35783708">[2 more]</label></div><br/><div class="children"><div class="content">&gt; The information value of answers by ChatGPT is zero.<p>Nonsense. The only way this would be true is if ChatGPT&#x27;s answers were as likely to be correct as <i>random</i> answers. They are much, much more likely to be correct, however, so their information value is greater than zero by definition.<p>What you&#x27;re claiming is equivalent to &quot;search engines can find incorrect information, so search engines are worthless for information retrieval&quot;. Which is bollocks.</div><br/><div id="35784602" class="c"><input type="checkbox" id="c-35784602" checked=""/><div class="controls bullet"><span class="by">chx</span><span>|</span><a href="#35783590">root</a><span>|</span><a href="#35783708">parent</a><span>|</span><a href="#35783725">next</a><span>|</span><label class="collapse" for="c-35784602">[-]</label><label class="expand" for="c-35784602">[1 more]</label></div><br/><div class="children"><div class="content">&gt;  The only way this would be true is if ChatGPT&#x27;s answers were as likely to be correct as random answers.<p>Which is the case<p>&gt; They are much, much more likely to be correct,<p>They are not. It&#x27;s just apophenia to find meaning in the word salad.</div><br/></div></div></div></div></div></div></div></div><div id="35783725" class="c"><input type="checkbox" id="c-35783725" checked=""/><div class="controls bullet"><span class="by">ipnon</span><span>|</span><a href="#35783590">parent</a><span>|</span><a href="#35783617">prev</a><span>|</span><a href="#35783610">next</a><span>|</span><label class="collapse" for="c-35783725">[-]</label><label class="expand" for="c-35783725">[1 more]</label></div><br/><div class="children"><div class="content">“There’s no sense in being precise when you don’t even know what you’re talking about.” John von Neumann</div><br/></div></div><div id="35783610" class="c"><input type="checkbox" id="c-35783610" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#35783590">parent</a><span>|</span><a href="#35783725">prev</a><span>|</span><a href="#35783508">next</a><span>|</span><label class="collapse" for="c-35783610">[-]</label><label class="expand" for="c-35783610">[5 more]</label></div><br/><div class="children"><div class="content">How sure are you about that?</div><br/><div id="35783666" class="c"><input type="checkbox" id="c-35783666" checked=""/><div class="controls bullet"><span class="by">dmbche</span><span>|</span><a href="#35783590">root</a><span>|</span><a href="#35783610">parent</a><span>|</span><a href="#35783629">next</a><span>|</span><label class="collapse" for="c-35783666">[-]</label><label class="expand" for="c-35783666">[3 more]</label></div><br/><div class="children"><div class="content">I mean did you read the discussion he had with the language model? Does it clarify anything better than you would get by skimming wikipedia?<p>I have not found these explanations sufficient, while I have done a bit of chemistry and physics I understand the basics of light emissions, but reading this has the same value as reading the wiki article on LEDs to me.</div><br/><div id="35783678" class="c"><input type="checkbox" id="c-35783678" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#35783590">root</a><span>|</span><a href="#35783666">parent</a><span>|</span><a href="#35783629">next</a><span>|</span><label class="collapse" for="c-35783678">[-]</label><label class="expand" for="c-35783678">[2 more]</label></div><br/><div class="children"><div class="content">It was a lot shorter than the Wikipedia articles.</div><br/><div id="35783715" class="c"><input type="checkbox" id="c-35783715" checked=""/><div class="controls bullet"><span class="by">dmbche</span><span>|</span><a href="#35783590">root</a><span>|</span><a href="#35783678">parent</a><span>|</span><a href="#35783629">next</a><span>|</span><label class="collapse" for="c-35783715">[-]</label><label class="expand" for="c-35783715">[1 more]</label></div><br/><div class="children"><div class="content">Sure - when I skim articles, I often don&#x27;t read all of it and stick to what I&#x27;m interested in - I&#x27;d argue that even takes less time than chatting with chat-gpt and fact checking it<p>(Edit: - and you get sources right away with wikipedia!)</div><br/></div></div></div></div></div></div><div id="35783629" class="c"><input type="checkbox" id="c-35783629" checked=""/><div class="controls bullet"><span class="by">chx</span><span>|</span><a href="#35783590">root</a><span>|</span><a href="#35783610">parent</a><span>|</span><a href="#35783666">prev</a><span>|</span><a href="#35783508">next</a><span>|</span><label class="collapse" for="c-35783629">[-]</label><label class="expand" for="c-35783629">[1 more]</label></div><br/><div class="children"><div class="content">Even if the answers accidentally happen to be correct, that&#x27;s just the broken clock happens to be correct twice a day. The information value of answers by ChatGPT is <i>zero</i>.</div><br/></div></div></div></div></div></div><div id="35783508" class="c"><input type="checkbox" id="c-35783508" checked=""/><div class="controls bullet"><span class="by">akeck</span><span>|</span><a href="#35783590">prev</a><span>|</span><a href="#35783616">next</a><span>|</span><label class="collapse" for="c-35783508">[-]</label><label class="expand" for="c-35783508">[2 more]</label></div><br/><div class="children"><div class="content">Fun with caveats I&#x27;m finding. Today I asked for an outline of DevSecOps concept based on CISA recommendations. The CISA doc it referenced doesn&#x27;t actually exist.</div><br/><div id="35784850" class="c"><input type="checkbox" id="c-35784850" checked=""/><div class="controls bullet"><span class="by">danielbln</span><span>|</span><a href="#35783508">parent</a><span>|</span><a href="#35783616">next</a><span>|</span><label class="collapse" for="c-35784850">[-]</label><label class="expand" for="c-35784850">[1 more]</label></div><br/><div class="children"><div class="content">For something like that you really want to use GPT3&#x2F;4 hooked up to search, e.g. <a href="https:&#x2F;&#x2F;www.phind.com&#x2F;search?q=give+me+an+outline+of+DevSecOps+concept+based+on+CISA+recommendations.&amp;c=&amp;source=searchbox">https:&#x2F;&#x2F;www.phind.com&#x2F;search?q=give+me+an+outline+of+DevSecO...</a></div><br/></div></div></div></div><div id="35783616" class="c"><input type="checkbox" id="c-35783616" checked=""/><div class="controls bullet"><span class="by">renewiltord</span><span>|</span><a href="#35783508">prev</a><span>|</span><a href="#35784453">next</a><span>|</span><label class="collapse" for="c-35783616">[-]</label><label class="expand" for="c-35783616">[1 more]</label></div><br/><div class="children"><div class="content">Shortly before GPT and friends burst on the scene, I was looking for a website which would meet me where I am as an engineer - I&#x27;ve written reams of code in various languages.<p>If I want to try Rust, I don&#x27;t want to be taught uint8 v uint16 or that you shadow variables. I want to know the interesting parts.<p>ChatGPT is pretty good at this and the other thing I want: pandas training. You can ask it to generate exercises at any difficulty and also provide test data!<p>This tool is the biggest mind expander for me since search engines.</div><br/></div></div><div id="35784453" class="c"><input type="checkbox" id="c-35784453" checked=""/><div class="controls bullet"><span class="by">jhugo</span><span>|</span><a href="#35783616">prev</a><span>|</span><a href="#35783266">next</a><span>|</span><label class="collapse" for="c-35784453">[-]</label><label class="expand" for="c-35784453">[1 more]</label></div><br/><div class="children"><div class="content">When was learning ever not fun?</div><br/></div></div><div id="35783266" class="c"><input type="checkbox" id="c-35783266" checked=""/><div class="controls bullet"><span class="by">newprint</span><span>|</span><a href="#35784453">prev</a><span>|</span><label class="collapse" for="c-35783266">[-]</label><label class="expand" for="c-35783266">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;m confused. So, this person just asked ChatGPT bunch of surface level questions about Solid State Physics, got response. What is so exciting ?</div><br/><div id="35783398" class="c"><input type="checkbox" id="c-35783398" checked=""/><div class="controls bullet"><span class="by">blast</span><span>|</span><a href="#35783266">parent</a><span>|</span><a href="#35783519">next</a><span>|</span><label class="collapse" for="c-35783398">[-]</label><label class="expand" for="c-35783398">[1 more]</label></div><br/><div class="children"><div class="content">The author describes his learning process in detail and explains what&#x27;s exciting: he got a basic understanding of the subject within minutes, after being frustrated by Wikipedia, a physics education site, and some other site. Getting through the surface level is a big deal for someone who&#x27;s new to a subject.</div><br/></div></div><div id="35783519" class="c"><input type="checkbox" id="c-35783519" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#35783266">parent</a><span>|</span><a href="#35783398">prev</a><span>|</span><label class="collapse" for="c-35783519">[-]</label><label class="expand" for="c-35783519">[1 more]</label></div><br/><div class="children"><div class="content">The article explains exactly why they find this exciting, by comparing it to the same research exercise conducted using Google and Wikipedia.</div><br/></div></div></div></div></div></div></div></div></div></body></html>