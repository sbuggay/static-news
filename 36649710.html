<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1688893260983" as="style"/><link rel="stylesheet" href="styles.css?v=1688893260983"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://ai.googleblog.com/2023/06/announcing-first-machine-unlearning.html">Machine Unlearning Challenge</a> <span class="domain">(<a href="https://ai.googleblog.com">ai.googleblog.com</a>)</span></div><div class="subtext"><span>Anon84</span> | <span>23 comments</span></div><br/><div><div id="36650699" class="c"><input type="checkbox" id="c-36650699" checked=""/><div class="controls bullet"><span class="by">gojomo</span><span>|</span><a href="#36649992">next</a><span>|</span><label class="collapse" for="c-36650699">[-]</label><label class="expand" for="c-36650699">[4 more]</label></div><br/><div class="children"><div class="content">Joel: &quot;Is there any risk of brain damage?&quot;<p>Dr. Mierzwiak: &quot;Well, technically speaking, the operation is brain damage, but it&#x27;s on a par with a night of heavy drinking. Nothing you&#x27;ll miss.&quot;<p>- <i>Eternal Sunshine of the Spotless Mind</i> (2004)</div><br/><div id="36651140" class="c"><input type="checkbox" id="c-36651140" checked=""/><div class="controls bullet"><span class="by">twbarr</span><span>|</span><a href="#36650699">parent</a><span>|</span><a href="#36651476">next</a><span>|</span><label class="collapse" for="c-36651140">[-]</label><label class="expand" for="c-36651140">[2 more]</label></div><br/><div class="children"><div class="content">Lord Mayor of Cologne: &quot;You&#x27;ve damaged your brain, Universe, but no more than a week of binge drinking or five minutes on a cell phone.&quot;<p>- Futurama, Parasites Lost (2001)</div><br/><div id="36651375" class="c"><input type="checkbox" id="c-36651375" checked=""/><div class="controls bullet"><span class="by">goodbyesf</span><span>|</span><a href="#36650699">root</a><span>|</span><a href="#36651140">parent</a><span>|</span><a href="#36651476">next</a><span>|</span><label class="collapse" for="c-36651375">[-]</label><label class="expand" for="c-36651375">[1 more]</label></div><br/><div class="children"><div class="content">Homer Simpson: Alright brain, you don&#x27;t like me and I don&#x27;t like you. But let&#x27;s just do this and I can get back to killing you with beer.<p>- Simpsons, The Front (1992)</div><br/></div></div></div></div><div id="36651476" class="c"><input type="checkbox" id="c-36651476" checked=""/><div class="controls bullet"><span class="by">ChatGTP</span><span>|</span><a href="#36650699">parent</a><span>|</span><a href="#36651140">prev</a><span>|</span><a href="#36649992">next</a><span>|</span><label class="collapse" for="c-36651476">[-]</label><label class="expand" for="c-36651476">[1 more]</label></div><br/><div class="children"><div class="content">None of this is true for those who abstain from Alcohol :)</div><br/></div></div></div></div><div id="36649992" class="c"><input type="checkbox" id="c-36649992" checked=""/><div class="controls bullet"><span class="by">buildbot</span><span>|</span><a href="#36650699">prev</a><span>|</span><a href="#36650131">next</a><span>|</span><label class="collapse" for="c-36649992">[-]</label><label class="expand" for="c-36649992">[7 more]</label></div><br/><div class="children"><div class="content">While this post seems aimed more at compliance or sensitive data issues, “unlearning” aka forgetting itself may be essential for better or more human like AI agents. You are as much defined by what you have forgotten as what you have learned.</div><br/><div id="36650092" class="c"><input type="checkbox" id="c-36650092" checked=""/><div class="controls bullet"><span class="by">version_five</span><span>|</span><a href="#36649992">parent</a><span>|</span><a href="#36650216">next</a><span>|</span><label class="collapse" for="c-36650092">[-]</label><label class="expand" for="c-36650092">[5 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve heard than some mental illness (maybe schizophrenia) is theorized to be in part due to an inability to forget things. Certainly normal human existence involves preferential remembering and forgetting. For example not dwelling on pain or failure etc.<p>Gradient descent obviously has none of that, it has not feelings or goals, and so there would be no preferential remembering or forgetting other than to do better next word prediction or rlhf or whatever. So it would be interesting to think about what a model should remember or forget in order to align it with our goals (because it doesn&#x27;t have any of it&#x27;s own).<p><i>Also, don&#x27;t volunteer for Google. They have lots of money, they can pay for this stuff and if you know how to do it you have lots of options.</i></div><br/><div id="36650767" class="c"><input type="checkbox" id="c-36650767" checked=""/><div class="controls bullet"><span class="by">pessimizer</span><span>|</span><a href="#36649992">root</a><span>|</span><a href="#36650092">parent</a><span>|</span><a href="#36650959">next</a><span>|</span><label class="collapse" for="c-36650767">[-]</label><label class="expand" for="c-36650767">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, the prize for doing the best on this challenge should be a piece of the company.</div><br/></div></div><div id="36650959" class="c"><input type="checkbox" id="c-36650959" checked=""/><div class="controls bullet"><span class="by">B1FF_PSUVM</span><span>|</span><a href="#36649992">root</a><span>|</span><a href="#36650092">parent</a><span>|</span><a href="#36650767">prev</a><span>|</span><a href="#36650216">next</a><span>|</span><label class="collapse" for="c-36650959">[-]</label><label class="expand" for="c-36650959">[3 more]</label></div><br/><div class="children"><div class="content">&gt; I&#x27;ve heard than some mental illness (maybe schizophrenia) is theorized to be in part due to an inability to forget things.<p>My totally amateur pet theory is that paranoia is threat pattern recognition gone bonkers.<p>Actually, most of what we do with brains is pattern recognition, and if there isn&#x27;t enough good input they will make shit up.</div><br/><div id="36650983" class="c"><input type="checkbox" id="c-36650983" checked=""/><div class="controls bullet"><span class="by">bitcurious</span><span>|</span><a href="#36649992">root</a><span>|</span><a href="#36650959">parent</a><span>|</span><a href="#36650216">next</a><span>|</span><label class="collapse" for="c-36650983">[-]</label><label class="expand" for="c-36650983">[2 more]</label></div><br/><div class="children"><div class="content">&gt; My totally amateur pet theory is that paranoia is threat pattern recognition gone bonkers.<p>Supposedly OCD is your brain’s cause-effect loop being too potent. As in, you have a random fear I.e. “stove is on, fire will burn down house,” you go to check the stove, and the act of checking (regardless of its being on) creates the feeling that you saved your house from burning down, so now you feel compelled to check every time. Paraphrased from the Huberman podcast.</div><br/><div id="36651956" class="c"><input type="checkbox" id="c-36651956" checked=""/><div class="controls bullet"><span class="by">__loam</span><span>|</span><a href="#36649992">root</a><span>|</span><a href="#36650983">parent</a><span>|</span><a href="#36650216">next</a><span>|</span><label class="collapse" for="c-36651956">[-]</label><label class="expand" for="c-36651956">[1 more]</label></div><br/><div class="children"><div class="content">I have OCD. This is basically accurate in that it&#x27;s an anxiety disorder that affects your ability to judge whether a worst case scenario is likely or not, but the thoughts are more like &quot;What if I drive across the median and kill a family of 5 in a minivan&quot; or &quot;What if I pull my genitals out in this meeting and try to fuck my boss&quot;. The compulsions are usually not as logically coherent as needing to check if the stove is on or the house will burn down (though there are people who experience ocd like this). Usually my compulsions happen as a way to try and stop thinking those thoughts, like pulling over and playing internet chess for half an hour. The problem is that the compulsions steal a lot of time and don&#x27;t typically address the underlying obsessive thought.</div><br/></div></div></div></div></div></div></div></div><div id="36650216" class="c"><input type="checkbox" id="c-36650216" checked=""/><div class="controls bullet"><span class="by">Barrin92</span><span>|</span><a href="#36649992">parent</a><span>|</span><a href="#36650092">prev</a><span>|</span><a href="#36650131">next</a><span>|</span><label class="collapse" for="c-36650216">[-]</label><label class="expand" for="c-36650216">[1 more]</label></div><br/><div class="children"><div class="content">it is certainly better for all AI agents, not just human like systems, because it is almost the definition of intelligence. Forgetting the irrelevant stuff and having a system that does as much as possible with as little information as possible is what learning is, compression in other terms.</div><br/></div></div></div></div><div id="36650131" class="c"><input type="checkbox" id="c-36650131" checked=""/><div class="controls bullet"><span class="by">tnecniv</span><span>|</span><a href="#36649992">prev</a><span>|</span><a href="#36650446">next</a><span>|</span><label class="collapse" for="c-36650131">[-]</label><label class="expand" for="c-36650131">[1 more]</label></div><br/><div class="children"><div class="content">An interesting idea. My first thought was to say “just use a differentially private learning algorithm,” but DP requires a notion of closeness, and that’s not trivial for, e.g., image data. Images close in an abstract sense, like Euclidean distance, may not be close in a task-relevant sense. You may not know what a good, task-relevant metric for employing DP without performing some kind of learning in the first place.</div><br/></div></div><div id="36650446" class="c"><input type="checkbox" id="c-36650446" checked=""/><div class="controls bullet"><span class="by">quickthrower2</span><span>|</span><a href="#36650131">prev</a><span>|</span><a href="#36651602">next</a><span>|</span><label class="collapse" for="c-36650446">[-]</label><label class="expand" for="c-36650446">[1 more]</label></div><br/><div class="children"><div class="content">Who knows… unlearning might turn out be good as a “sleep” phase while learning too. Sort of a regularisation. Could be done after each epoch.</div><br/></div></div><div id="36651602" class="c"><input type="checkbox" id="c-36651602" checked=""/><div class="controls bullet"><span class="by">dleeftink</span><span>|</span><a href="#36650446">prev</a><span>|</span><a href="#36652319">next</a><span>|</span><label class="collapse" for="c-36651602">[-]</label><label class="expand" for="c-36651602">[3 more]</label></div><br/><div class="children"><div class="content">As with many ML-phrases, the use of &#x27;unlearning&#x27; frames  data modelling as a false dichotomy between &#x27;learnable&#x27; and &#x27;forgettable&#x27; data. Whereas humans are able to forget over time, it would be quite disturbing to block some memories from access entirely, how traumatic they might be (and quite apparent among people suffering memory loss).<p>While from a privacy perspective, not all &#x27;data points&#x27; (i.e. memories) need be shared with the populace at large, to the individual they do constitute affective buildings blocks to deal with previous experiences. Similarly, the threshold for sharing (private) experiences depends on the communicative context one&#x27;s in and how comfortable one feels sharing them.<p>Might similar mechanisms provide large models the ability to retain an internal recollection of &#x27;traumatic&#x27; or &#x27;problematic&#x27; data and become more attuned to the context its communicating in instead? Leaving blank spots or blocking out experience completely sets the stage for &#x27;disturbing&#x27; a model&#x27;s memory after the fact. While I don&#x27;t want to draw a comparison between current NN architectures and organic ones, it is worth questioning our framing of currently emerging methods, as the incipient terminology can imbue how later practioners implement and think about these mechanisms.</div><br/><div id="36651910" class="c"><input type="checkbox" id="c-36651910" checked=""/><div class="controls bullet"><span class="by">__loam</span><span>|</span><a href="#36651602">parent</a><span>|</span><a href="#36652319">next</a><span>|</span><label class="collapse" for="c-36651910">[-]</label><label class="expand" for="c-36651910">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s just statistics guys. You either put the data in the training set or you don&#x27;t.</div><br/><div id="36652172" class="c"><input type="checkbox" id="c-36652172" checked=""/><div class="controls bullet"><span class="by">kxcrossing</span><span>|</span><a href="#36651602">root</a><span>|</span><a href="#36651910">parent</a><span>|</span><a href="#36652319">next</a><span>|</span><label class="collapse" for="c-36652172">[-]</label><label class="expand" for="c-36652172">[1 more]</label></div><br/><div class="children"><div class="content">Well, isn&#x27;t this challenge about altering a model after-the-fact? I.e. we are stuck with this data in the training set and must figure out a way to clean up the model</div><br/></div></div></div></div></div></div><div id="36652319" class="c"><input type="checkbox" id="c-36652319" checked=""/><div class="controls bullet"><span class="by">aforty</span><span>|</span><a href="#36651602">prev</a><span>|</span><a href="#36651348">next</a><span>|</span><label class="collapse" for="c-36652319">[-]</label><label class="expand" for="c-36652319">[1 more]</label></div><br/><div class="children"><div class="content">Please don’t do free work for google. If you have a solution for this then you have lots of options.</div><br/></div></div><div id="36651348" class="c"><input type="checkbox" id="c-36651348" checked=""/><div class="controls bullet"><span class="by">victor9000</span><span>|</span><a href="#36652319">prev</a><span>|</span><a href="#36651945">next</a><span>|</span><label class="collapse" for="c-36651348">[-]</label><label class="expand" for="c-36651348">[1 more]</label></div><br/><div class="children"><div class="content">They say privacy, but this sounds like a request to make censorship more censor friendly.<p>Edit: People seem to disagree, but is this not a tool for wiping ideas from your training data?  Meaning they want to train on Wikipedia and remove concepts (per locale probably) easy as pie.  This is Google outsourcing compliance with jurisdictions that require thought policing.</div><br/></div></div><div id="36650617" class="c"><input type="checkbox" id="c-36650617" checked=""/><div class="controls bullet"><span class="by">CGamesPlay</span><span>|</span><a href="#36651945">prev</a><span>|</span><a href="#36650977">next</a><span>|</span><label class="collapse" for="c-36650617">[-]</label><label class="expand" for="c-36650617">[2 more]</label></div><br/><div class="children"><div class="content">This is an interesting concept. Is there something like an MNIST for this, to make it more concrete?</div><br/><div id="36651027" class="c"><input type="checkbox" id="c-36651027" checked=""/><div class="controls bullet"><span class="by">sudosysgen</span><span>|</span><a href="#36650617">parent</a><span>|</span><a href="#36650977">next</a><span>|</span><label class="collapse" for="c-36651027">[-]</label><label class="expand" for="c-36651027">[1 more]</label></div><br/><div class="children"><div class="content">Yes. Like all NeurIPS competition challenges, there is a starting kit which provides a dataset and metrics, there is also a grader on Kaggle.</div><br/></div></div></div></div><div id="36650977" class="c"><input type="checkbox" id="c-36650977" checked=""/><div class="controls bullet"><span class="by">JimmyRuska</span><span>|</span><a href="#36650617">prev</a><span>|</span><label class="collapse" for="c-36650977">[-]</label><label class="expand" for="c-36650977">[1 more]</label></div><br/><div class="children"><div class="content">Deep forgetting</div><br/></div></div></div></div></div></div></div></body></html>