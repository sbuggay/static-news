<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1717318872462" as="style"/><link rel="stylesheet" href="styles.css?v=1717318872462"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://eugeneyan.com/writing/llm-lessons/">What we&#x27;ve learned from a year of building with LLMs</a> <span class="domain">(<a href="https://eugeneyan.com">eugeneyan.com</a>)</span></div><div class="subtext"><span>ViktorasJucikas</span> | <span>79 comments</span></div><br/><div><div id="40551413" class="c"><input type="checkbox" id="c-40551413" checked=""/><div class="controls bullet"><span class="by">mloncode</span><span>|</span><a href="#40549233">next</a><span>|</span><label class="collapse" for="c-40551413">[-]</label><label class="expand" for="c-40551413">[1 more]</label></div><br/><div class="children"><div class="content">This is Hamel, one of the authors of the article.  We published the article with OReilly here:<p>Part 1: <a href="https:&#x2F;&#x2F;www.oreilly.com&#x2F;radar&#x2F;what-we-learned-from-a-year-of-building-with-llms-part-i&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.oreilly.com&#x2F;radar&#x2F;what-we-learned-from-a-year-of...</a>
Part 2: <a href="https:&#x2F;&#x2F;www.oreilly.com&#x2F;radar&#x2F;what-we-learned-from-a-year-of-building-with-llms-part-ii&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.oreilly.com&#x2F;radar&#x2F;what-we-learned-from-a-year-of...</a><p>We were working on this webpage to collect the entire three part article in one place (the third part isn&#x27;t published yet).  We didn&#x27;t expect anyone to notice the site!  Either way, part 3 should be out in a week or so.</div><br/></div></div><div id="40549233" class="c"><input type="checkbox" id="c-40549233" checked=""/><div class="controls bullet"><span class="by">dbs</span><span>|</span><a href="#40551413">prev</a><span>|</span><a href="#40552576">next</a><span>|</span><label class="collapse" for="c-40549233">[-]</label><label class="expand" for="c-40549233">[34 more]</label></div><br/><div class="children"><div class="content">Show me the use cases you have supported in production. Then I might read all the 30 pages praising the dozens (soon to be hundreds?) of “best practices” to build LLMs.</div><br/><div id="40551594" class="c"><input type="checkbox" id="c-40551594" checked=""/><div class="controls bullet"><span class="by">mloncode</span><span>|</span><a href="#40549233">parent</a><span>|</span><a href="#40550413">next</a><span>|</span><label class="collapse" for="c-40551594">[-]</label><label class="expand" for="c-40551594">[1 more]</label></div><br/><div class="children"><div class="content">Hi, Hamel here.  I&#x27;m one of the co-authors.  I&#x27;m an independent consultant and not all clients allow me to talk about their work.<p>However, I have two that do, which I&#x27;ve discussed in the article.  These are two production use cases that I have supported (which again, are explicitly mentioned in the article):<p>1. <a href="https:&#x2F;&#x2F;www.honeycomb.io&#x2F;blog&#x2F;introducing-query-assistant" rel="nofollow">https:&#x2F;&#x2F;www.honeycomb.io&#x2F;blog&#x2F;introducing-query-assistant</a><p>2. <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=B_DMMlDuJB0" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=B_DMMlDuJB0</a><p>Other co-authors have worked on significant bodies of work:<p>Bryan Bischoff lead the creation of Magic in Hex: <a href="https:&#x2F;&#x2F;www.latent.space&#x2F;p&#x2F;bryan-bischof" rel="nofollow">https:&#x2F;&#x2F;www.latent.space&#x2F;p&#x2F;bryan-bischof</a><p>Jason Liu created the most popular OSS libraries for structured data called instructor <a href="https:&#x2F;&#x2F;github.com&#x2F;jxnl&#x2F;instructor">https:&#x2F;&#x2F;github.com&#x2F;jxnl&#x2F;instructor</a>, and works with some of the leading companies in the space like Limitless and Raycast (<a href="https:&#x2F;&#x2F;jxnl.co&#x2F;services&#x2F;#current-and-past-clients" rel="nofollow">https:&#x2F;&#x2F;jxnl.co&#x2F;services&#x2F;#current-and-past-clients</a>)<p>Eugene Yan works with LLMs extensively at Amazon and uses that to inform his writing: <a href="https:&#x2F;&#x2F;eugeneyan.com&#x2F;writing&#x2F;" rel="nofollow">https:&#x2F;&#x2F;eugeneyan.com&#x2F;writing&#x2F;</a> (However he isn&#x27;t allowed to share specifics about Amazon)<p>I believe you might find these worth looking at.</div><br/></div></div><div id="40550413" class="c"><input type="checkbox" id="c-40550413" checked=""/><div class="controls bullet"><span class="by">fnordpiglet</span><span>|</span><a href="#40549233">parent</a><span>|</span><a href="#40551594">prev</a><span>|</span><a href="#40549570">next</a><span>|</span><label class="collapse" for="c-40550413">[-]</label><label class="expand" for="c-40550413">[9 more]</label></div><br/><div class="children"><div class="content">We use LLMs in dozens of different production applications for critical business flows. They allow for a lot of dynamism in our flows that aren’t amenable to direct quantitative reasoning or structured workflows. Double digit percents of our growth in the last year are entirely due to them. The biggest challenge is tool chain, limits on inference capacity, and developer understanding of the abilities, limits, and techniques for using LLMs effectively.<p>I often see these messages from the community doubting the reality, but LLMs are a powerful tool in the tool chest. But I think most companies are not staffed with skilled enough engineers with a creative enough bent to really take advantage of them yet or be willing to fund basic research and from first principles toolchain creation. That’s ok. But it’s foolish to assume this is all hype like crypto was. The parallels are obvious but the foundations are different.</div><br/><div id="40550775" class="c"><input type="checkbox" id="c-40550775" checked=""/><div class="controls bullet"><span class="by">threeseed</span><span>|</span><a href="#40549233">root</a><span>|</span><a href="#40550413">parent</a><span>|</span><a href="#40551574">next</a><span>|</span><label class="collapse" for="c-40550775">[-]</label><label class="expand" for="c-40550775">[3 more]</label></div><br/><div class="children"><div class="content">No one is saying that all of AI is hype. It clearly isn&#x27;t.<p>But the facts are that today LLMs are not suitable for use cases that need accurate results. And there is no evidence or research that suggests this is changing anytime soon. Maybe for ever.<p>There are very strong parallels to crypto in that (a) people are starting with the technology and trying to find problems and (b) there is a cult like atmosphere where non-believers are seen as being anti-progress and anti-technology.</div><br/><div id="40550792" class="c"><input type="checkbox" id="c-40550792" checked=""/><div class="controls bullet"><span class="by">fnordpiglet</span><span>|</span><a href="#40549233">root</a><span>|</span><a href="#40550775">parent</a><span>|</span><a href="#40551574">next</a><span>|</span><label class="collapse" for="c-40550792">[-]</label><label class="expand" for="c-40550792">[2 more]</label></div><br/><div class="children"><div class="content">Yeah I think a key is LLMs in business are not generally useful alone. They require classical computing techniques to really be powerful. Accurate computation is a generally well established field and you don’t need an LLM to do optimization or math or even deductive logical reasoning. That’s a waste of their power which is typically abstract semantic abductive “reasoning” and natural language processing. Overlaying this with constraints, structure, and augmenting with optimizers, solvers, etc, you get a form of computing that was impossible more than 5 years prior and is only practical in the last 9 months.<p>On the crypto stuff yeah I get it - especially if you’re not in the weeds of its use. A lot of people formed opinions from GPT3.5, Gemini, copilot, and other crappy experiences and haven’t kept up with the state of the art.  The rate of change in AI is breathtaking and I think hard to comprehend for most people. Also the recent mess of crypto and the fact grifters grift etc also hurts. But people who doubt -are- stuck in the past. That’s not necessarily their fault and it might not even apply to their career or lives in the present and the flaws are enormous as you point out. But it’s such a remarkably powerful new mode of compute that it in combination with all the other powerful modes of compute is changing everything and will continue too, especially if next generation models keep improving as they seem to be likely to.</div><br/><div id="40552405" class="c"><input type="checkbox" id="c-40552405" checked=""/><div class="controls bullet"><span class="by">jeffreygoesto</span><span>|</span><a href="#40549233">root</a><span>|</span><a href="#40550792">parent</a><span>|</span><a href="#40551574">next</a><span>|</span><label class="collapse" for="c-40552405">[-]</label><label class="expand" for="c-40552405">[1 more]</label></div><br/><div class="children"><div class="content">That text applies to basically every new technology. Point is that you can&#x27;t predict it&#x27;s usefulness in 20 years from that.<p>To me it still looks like a hammer made completely from rubber. You can practice to get some good hits, but it is pretty hard to get something reliable. And a beginner will basically just bounce it around. But it is sold as rescue for beginners.</div><br/></div></div></div></div></div></div><div id="40551574" class="c"><input type="checkbox" id="c-40551574" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#40549233">root</a><span>|</span><a href="#40550413">parent</a><span>|</span><a href="#40550775">prev</a><span>|</span><a href="#40550460">next</a><span>|</span><label class="collapse" for="c-40551574">[-]</label><label class="expand" for="c-40551574">[2 more]</label></div><br/><div class="children"><div class="content">&gt; <i>We use LLMs in dozens of different production applications for critical business flows. They allow for a lot of dynamism in our flows that aren’t amenable to direct quantitative reasoning or structured workflows. Double digit percents of our growth in the last year are entirely due to them. The biggest challenge is tool chain, limits on inference capacity, and developer understanding of the abilities, limits, and techniques for using LLMs effectively.</i><p>That sounds like corporate buzzword salad. It doesn&#x27;t tell much as it stands, not without at least one specific example to ground all those relative statements.</div><br/><div id="40551597" class="c"><input type="checkbox" id="c-40551597" checked=""/><div class="controls bullet"><span class="by">mloncode</span><span>|</span><a href="#40549233">root</a><span>|</span><a href="#40551574">parent</a><span>|</span><a href="#40550460">next</a><span>|</span><label class="collapse" for="c-40551597">[-]</label><label class="expand" for="c-40551597">[1 more]</label></div><br/><div class="children"><div class="content">Hi, Hamel here.  I&#x27;m one of the co-authors.  I&#x27;m an independent consultant and not all clients allow me to talk about their work.<p>However, I have two that do, which I&#x27;ve discussed in the article.  These are two production use cases that I have supported (which again, are explicitly mentioned in the article):<p>1. <a href="https:&#x2F;&#x2F;www.honeycomb.io&#x2F;blog&#x2F;introducing-query-assistant" rel="nofollow">https:&#x2F;&#x2F;www.honeycomb.io&#x2F;blog&#x2F;introducing-query-assistant</a><p>2. <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=B_DMMlDuJB0" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=B_DMMlDuJB0</a><p>Other co-authors have worked on significant bodies of work:<p>Bryan Bischoff lead the creation of Magic in Hex: <a href="https:&#x2F;&#x2F;www.latent.space&#x2F;p&#x2F;bryan-bischof" rel="nofollow">https:&#x2F;&#x2F;www.latent.space&#x2F;p&#x2F;bryan-bischof</a><p>Jason Liu created the most popular OSS libraries for structured data called instructor <a href="https:&#x2F;&#x2F;github.com&#x2F;jxnl&#x2F;instructor">https:&#x2F;&#x2F;github.com&#x2F;jxnl&#x2F;instructor</a>, and works with some of the leading companies in the space like Limitless and Raycast (<a href="https:&#x2F;&#x2F;jxnl.co&#x2F;services&#x2F;#current-and-past-clients" rel="nofollow">https:&#x2F;&#x2F;jxnl.co&#x2F;services&#x2F;#current-and-past-clients</a>)<p>Eugene Yan works with LLMs extensively at Amazon and uses that to inform his writing: <a href="https:&#x2F;&#x2F;eugeneyan.com&#x2F;writing&#x2F;" rel="nofollow">https:&#x2F;&#x2F;eugeneyan.com&#x2F;writing&#x2F;</a> (However he isn&#x27;t allowed to share specifics about Amazon)<p>I believe you might find these worth looking at.</div><br/></div></div></div></div><div id="40550460" class="c"><input type="checkbox" id="c-40550460" checked=""/><div class="controls bullet"><span class="by">mvdtnz</span><span>|</span><a href="#40549233">root</a><span>|</span><a href="#40550413">parent</a><span>|</span><a href="#40551574">prev</a><span>|</span><a href="#40549570">next</a><span>|</span><label class="collapse" for="c-40550460">[-]</label><label class="expand" for="c-40550460">[3 more]</label></div><br/><div class="children"><div class="content">Yet another post claiming &quot;dozens&quot; of production use cases without listing a single one.</div><br/><div id="40550618" class="c"><input type="checkbox" id="c-40550618" checked=""/><div class="controls bullet"><span class="by">fnordpiglet</span><span>|</span><a href="#40549233">root</a><span>|</span><a href="#40550460">parent</a><span>|</span><a href="#40549570">next</a><span>|</span><label class="collapse" for="c-40550618">[-]</label><label class="expand" for="c-40550618">[2 more]</label></div><br/><div class="children"><div class="content">I’ve listed plenty in my comment history. I don’t generally feel compelled to trot them all out all the time - I don’t need to “prove” anything and if you think I’m lying that’s your choice. Finally, many of our uses are trade secrets and a significant competitive advantage so I don’t feel the need to disclose them to the world if our competitors don’t believe in the tech. We can keep eating their lunch.</div><br/></div></div></div></div></div></div><div id="40549570" class="c"><input type="checkbox" id="c-40549570" checked=""/><div class="controls bullet"><span class="by">robbiemitchell</span><span>|</span><a href="#40549233">parent</a><span>|</span><a href="#40550413">prev</a><span>|</span><a href="#40549552">next</a><span>|</span><label class="collapse" for="c-40549570">[-]</label><label class="expand" for="c-40549570">[16 more]</label></div><br/><div class="children"><div class="content">Processing high volumes of unstructured data (text)… we’re using a STAG architecture.<p>- Generate targeted LLM micro summaries of every record (ticket, call, etc.) continually<p>- Use layers of regex, semantic embeddings, and scoring enrichments to identify report rows (pivots on aggregates) worth attention, running on a schedule<p>- Proactively explain each report row by identifying what’s unusual about it and LLM summarizing a subset of the microsummaries.<p>- Push the result to webhook<p>Lack of JSON schema restriction is a significant barrier to entry on hooking LLMs up to a multi step process.<p>Another is preventing LLMs from adding intro or conclusion text.</div><br/><div id="40551694" class="c"><input type="checkbox" id="c-40551694" checked=""/><div class="controls bullet"><span class="by">joatmon-snoo</span><span>|</span><a href="#40549233">root</a><span>|</span><a href="#40549570">parent</a><span>|</span><a href="#40550563">next</a><span>|</span><label class="collapse" for="c-40551694">[-]</label><label class="expand" for="c-40551694">[1 more]</label></div><br/><div class="children"><div class="content">We actually built an error-tolerant JSON parser to handle this. Our customers were reporting exactly the same issue- trying a bunch of different techniques to get more usefully structured data out.<p>You can check it out over at <a href="https:&#x2F;&#x2F;github.com&#x2F;BoundaryML&#x2F;baml">https:&#x2F;&#x2F;github.com&#x2F;BoundaryML&#x2F;baml</a>. Would love to talk if this is something that seems interesting!</div><br/></div></div><div id="40550563" class="c"><input type="checkbox" id="c-40550563" checked=""/><div class="controls bullet"><span class="by">adamsbriscoe</span><span>|</span><a href="#40549233">root</a><span>|</span><a href="#40549570">parent</a><span>|</span><a href="#40551694">prev</a><span>|</span><a href="#40552274">next</a><span>|</span><label class="collapse" for="c-40550563">[-]</label><label class="expand" for="c-40550563">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Lack of JSON schema restriction is a significant barrier to entry on hooking LLMs up to a multi step process.<p>(Plug) I shipped a dedicated OpenAI-compatible API for this, jsonmode.com a couple weeks ago and just integrated Groq (they were nice enough to bump up the rate limits) so it&#x27;s crazy fast. It&#x27;s a WIP but so far very comparable to JSON output from frontier models, with some bonus features (web crawling etc).</div><br/><div id="40552429" class="c"><input type="checkbox" id="c-40552429" checked=""/><div class="controls bullet"><span class="by">tarasglek</span><span>|</span><a href="#40549233">root</a><span>|</span><a href="#40550563">parent</a><span>|</span><a href="#40552274">next</a><span>|</span><label class="collapse" for="c-40552429">[-]</label><label class="expand" for="c-40552429">[1 more]</label></div><br/><div class="children"><div class="content">The metallica-esque lightning logo is cool</div><br/></div></div></div></div><div id="40552274" class="c"><input type="checkbox" id="c-40552274" checked=""/><div class="controls bullet"><span class="by">lastdong</span><span>|</span><a href="#40549233">root</a><span>|</span><a href="#40549570">parent</a><span>|</span><a href="#40550563">prev</a><span>|</span><a href="#40549946">next</a><span>|</span><label class="collapse" for="c-40552274">[-]</label><label class="expand" for="c-40552274">[1 more]</label></div><br/><div class="children"><div class="content">“Use layers of regex, semantic embeddings, and scoring enrichments to identify report rows (pivots on aggregates) worth attention, running on a schedule”<p>This is really interesting, is there any architecture documentation&#x2F;articles that you can recommend?</div><br/></div></div><div id="40549946" class="c"><input type="checkbox" id="c-40549946" checked=""/><div class="controls bullet"><span class="by">benreesman</span><span>|</span><a href="#40549233">root</a><span>|</span><a href="#40549570">parent</a><span>|</span><a href="#40552274">prev</a><span>|</span><a href="#40549731">next</a><span>|</span><label class="collapse" for="c-40549946">[-]</label><label class="expand" for="c-40549946">[1 more]</label></div><br/><div class="children"><div class="content">I only became aware of it recently and therefore haven’t done more than play with in a fairly cursory way, but unstructured.io seems to have a lot of traction and certainly in my little toy tests their open-source stuff seems pretty clearly better than the status quo.<p>Might be worth checking out.</div><br/></div></div><div id="40549731" class="c"><input type="checkbox" id="c-40549731" checked=""/><div class="controls bullet"><span class="by">BoorishBears</span><span>|</span><a href="#40549233">root</a><span>|</span><a href="#40549570">parent</a><span>|</span><a href="#40549946">prev</a><span>|</span><a href="#40549552">next</a><span>|</span><label class="collapse" for="c-40549731">[-]</label><label class="expand" for="c-40549731">[10 more]</label></div><br/><div class="children"><div class="content">&gt; Lack of JSON schema restriction is a significant barrier to entry on hooking LLMs up to a multi step process.<p>How are you struggling with this, let alone as a significant barrier? JSON adherence with a well thought out schema hasn&#x27;t been a worry between improved model performance and various grammar based constraint systems in a while.<p>&gt; Another is preventing LLMs from adding intro or conclusion text.<p>Also trivial to work around by pre-filling and stop tokens, or just extremely basic text parsing.<p>Also would recommend writing out Stream-Triggered Augmented Generation since the term is so barely used it might as well be made up from the POV of someone trying to understand the comment</div><br/><div id="40549804" class="c"><input type="checkbox" id="c-40549804" checked=""/><div class="controls bullet"><span class="by">robbiemitchell</span><span>|</span><a href="#40549233">root</a><span>|</span><a href="#40549731">parent</a><span>|</span><a href="#40549552">next</a><span>|</span><label class="collapse" for="c-40549804">[-]</label><label class="expand" for="c-40549804">[9 more]</label></div><br/><div class="children"><div class="content">Asking even a top-notch LLM to output well formed JSON simply fails sometimes. And when you’re running LLMs at high volume in the background, you can’t use the best available until the last mile.<p>You work around it with post-processing and retries. But it’s still a bit brittle given how much stuff happens downstream without supervision.</div><br/><div id="40550228" class="c"><input type="checkbox" id="c-40550228" checked=""/><div class="controls bullet"><span class="by">fancy_pantser</span><span>|</span><a href="#40549233">root</a><span>|</span><a href="#40549804">parent</a><span>|</span><a href="#40550327">next</a><span>|</span><label class="collapse" for="c-40550228">[-]</label><label class="expand" for="c-40550228">[3 more]</label></div><br/><div class="children"><div class="content">Constrained output with GBNF or JSON is much more efficient and less error-prone. I hope nobody outside of hobby projects is still using error&#x2F;retry loops.</div><br/><div id="40551707" class="c"><input type="checkbox" id="c-40551707" checked=""/><div class="controls bullet"><span class="by">joatmon-snoo</span><span>|</span><a href="#40549233">root</a><span>|</span><a href="#40550228">parent</a><span>|</span><a href="#40550327">next</a><span>|</span><label class="collapse" for="c-40551707">[-]</label><label class="expand" for="c-40551707">[2 more]</label></div><br/><div class="children"><div class="content">Constraining output means you don’t get to use ChatGPT or Claude though, and now you have to run your own stuff. Maybe for some folks that’s OK, but really annoying for others.</div><br/><div id="40551819" class="c"><input type="checkbox" id="c-40551819" checked=""/><div class="controls bullet"><span class="by">fancy_pantser</span><span>|</span><a href="#40549233">root</a><span>|</span><a href="#40551707">parent</a><span>|</span><a href="#40550327">next</a><span>|</span><label class="collapse" for="c-40551819">[-]</label><label class="expand" for="c-40551819">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;re totally right, I&#x27;m in my own HPC bubble. The organizations I work with create their own models and it&#x27;s easy for me to forget that&#x27;s the exception more than the rule. I apologize for making too many assumptions in my previous comment.</div><br/></div></div></div></div></div></div><div id="40550327" class="c"><input type="checkbox" id="c-40550327" checked=""/><div class="controls bullet"><span class="by">jncfhnb</span><span>|</span><a href="#40549233">root</a><span>|</span><a href="#40549804">parent</a><span>|</span><a href="#40550228">prev</a><span>|</span><a href="#40550676">next</a><span>|</span><label class="collapse" for="c-40550327">[-]</label><label class="expand" for="c-40550327">[3 more]</label></div><br/><div class="children"><div class="content">… why would you have the LLM spit out a json rather than define the json yourself and have the LLM supply values?</div><br/><div id="40552190" class="c"><input type="checkbox" id="c-40552190" checked=""/><div class="controls bullet"><span class="by">esafak</span><span>|</span><a href="#40549233">root</a><span>|</span><a href="#40550327">parent</a><span>|</span><a href="#40551378">next</a><span>|</span><label class="collapse" for="c-40552190">[-]</label><label class="expand" for="c-40552190">[1 more]</label></div><br/><div class="children"><div class="content">If the LLM doesn&#x27;t output data that conforms to a schema, you can&#x27;t reliably parse it, so you&#x27;re back to square one.</div><br/></div></div><div id="40551378" class="c"><input type="checkbox" id="c-40551378" checked=""/><div class="controls bullet"><span class="by">janpieterz</span><span>|</span><a href="#40549233">root</a><span>|</span><a href="#40550327">parent</a><span>|</span><a href="#40552190">prev</a><span>|</span><a href="#40550676">next</a><span>|</span><label class="collapse" for="c-40551378">[-]</label><label class="expand" for="c-40551378">[1 more]</label></div><br/><div class="children"><div class="content">How would I do this reliably? Eg give me 10 different values, all in one prompt for performance reasons?<p>Might not need JSON but whatever format it outputs, it needs to be reliable.</div><br/></div></div></div></div><div id="40550676" class="c"><input type="checkbox" id="c-40550676" checked=""/><div class="controls bullet"><span class="by">yeahwhatever10</span><span>|</span><a href="#40549233">root</a><span>|</span><a href="#40549804">parent</a><span>|</span><a href="#40550327">prev</a><span>|</span><a href="#40550799">next</a><span>|</span><label class="collapse" for="c-40550676">[-]</label><label class="expand" for="c-40550676">[1 more]</label></div><br/><div class="children"><div class="content">The phrase you want to search is &quot;constrained decoding&quot;.</div><br/></div></div><div id="40550799" class="c"><input type="checkbox" id="c-40550799" checked=""/><div class="controls bullet"><span class="by">BoorishBears</span><span>|</span><a href="#40549233">root</a><span>|</span><a href="#40549804">parent</a><span>|</span><a href="#40550676">prev</a><span>|</span><a href="#40549552">next</a><span>|</span><label class="collapse" for="c-40550799">[-]</label><label class="expand" for="c-40550799">[1 more]</label></div><br/><div class="children"><div class="content">The best available actually have the <i>fewest</i> knobs for JSON schema enforcement (ie. OpenAI&#x27;s JSON mode, which technically can still produce incorrect JSON)<p>If you&#x27;re using anything less you should have a grammar that enforces exactly what tokens are allowed to be output. Fine Tuning can help too in case you&#x27;re worried about the effects of constraining the generation, but in my experience it&#x27;s not really a thing</div><br/></div></div></div></div></div></div></div></div><div id="40549552" class="c"><input type="checkbox" id="c-40549552" checked=""/><div class="controls bullet"><span class="by">thallium205</span><span>|</span><a href="#40549233">parent</a><span>|</span><a href="#40549570">prev</a><span>|</span><a href="#40549485">next</a><span>|</span><label class="collapse" for="c-40549552">[-]</label><label class="expand" for="c-40549552">[1 more]</label></div><br/><div class="children"><div class="content">We have a company mail, fax, and phone room that receives thousands of pages a day that now sorts, categorizes, and extracts useful information from them all in a completely automated way by LLMs.  Several FTEs have been reassigned elsewhere as a result.</div><br/></div></div><div id="40549485" class="c"><input type="checkbox" id="c-40549485" checked=""/><div class="controls bullet"><span class="by">harrisoned</span><span>|</span><a href="#40549233">parent</a><span>|</span><a href="#40549552">prev</a><span>|</span><a href="#40551622">next</a><span>|</span><label class="collapse" for="c-40549485">[-]</label><label class="expand" for="c-40549485">[1 more]</label></div><br/><div class="children"><div class="content">It certainly has use cases, just not as many as the hype lead people to believe.
For me:<p>-Regex expressions: ChatGPT is the best multi-million regex parser to date.<p>-Grammar and semantic check: It&#x27;s a very good revision tool, helped me a lot of times, specially when writing in non-native languages.<p>-Artwork inspiration: Not only for visual inspiration, in the case of image generators, but descriptive as well. The verbosity of some LLMs can help describe things in more detail than a person would.<p>-General coding: While your mileage may vary on that one, it has helped me a lot at work building stuff on languages i&#x27;m not very familiar with. Just snippets, nothing big.</div><br/></div></div><div id="40551622" class="c"><input type="checkbox" id="c-40551622" checked=""/><div class="controls bullet"><span class="by">hubraumhugo</span><span>|</span><a href="#40549233">parent</a><span>|</span><a href="#40549485">prev</a><span>|</span><a href="#40550766">next</a><span>|</span><label class="collapse" for="c-40551622">[-]</label><label class="expand" for="c-40551622">[1 more]</label></div><br/><div class="children"><div class="content">I think it comes down to relatively unexciting use cases that have a high business impact (process automation, RPA, data analysis), not fancy chatbots or generative art.<p>For example, we focused on the boring and hard task of web data extraction.<p>Traditional web scraping is labor-intensive, error-prone, and requires constant updates to handle website changes. It&#x27;s repetitive and tedious, but couldn&#x27;t be automated due to the high data diversity and many edge cases. This required a combination of rule-based tools, developers, and constant maintenance.<p>We&#x27;re now using LLMs to generate web scrapers and data transformation steps on the fly that adapt to website changes, automating the full process end-to-end.</div><br/></div></div><div id="40550766" class="c"><input type="checkbox" id="c-40550766" checked=""/><div class="controls bullet"><span class="by">obiefernandez</span><span>|</span><a href="#40549233">parent</a><span>|</span><a href="#40551622">prev</a><span>|</span><a href="#40551635">next</a><span>|</span><label class="collapse" for="c-40550766">[-]</label><label class="expand" for="c-40550766">[1 more]</label></div><br/><div class="children"><div class="content">The book I&#x27;m writing is almost finished and is based almost entirely on production use cases: <a href="https:&#x2F;&#x2F;leanpub.com&#x2F;patterns-of-application-development-using-ai" rel="nofollow">https:&#x2F;&#x2F;leanpub.com&#x2F;patterns-of-application-development-usin...</a></div><br/></div></div><div id="40551635" class="c"><input type="checkbox" id="c-40551635" checked=""/><div class="controls bullet"><span class="by">bbischof</span><span>|</span><a href="#40549233">parent</a><span>|</span><a href="#40550766">prev</a><span>|</span><a href="#40549313">next</a><span>|</span><label class="collapse" for="c-40551635">[-]</label><label class="expand" for="c-40551635">[1 more]</label></div><br/><div class="children"><div class="content">Hello, it’s Bryan, an author on this piece.<p>I’d you’re interested in using one of the LLM-applications I have in prod, check out <a href="https:&#x2F;&#x2F;hex.tech&#x2F;product&#x2F;magic-ai&#x2F;" rel="nofollow">https:&#x2F;&#x2F;hex.tech&#x2F;product&#x2F;magic-ai&#x2F;</a> It has a free limit every month to give it a try and see how you like it. If you have feedback after using it, we’re always very interested to hear from users.</div><br/></div></div><div id="40549313" class="c"><input type="checkbox" id="c-40549313" checked=""/><div class="controls bullet"><span class="by">joe_the_user</span><span>|</span><a href="#40549233">parent</a><span>|</span><a href="#40551635">prev</a><span>|</span><a href="#40551538">next</a><span>|</span><label class="collapse" for="c-40549313">[-]</label><label class="expand" for="c-40549313">[1 more]</label></div><br/><div class="children"><div class="content">I have a friend who uses ChatGPT for writing quick policy statement for her clients (mostly schools). I have a friend who uses it to create images and descriptions for DnD adventures. LLMs have uses.<p>The problem I see is, who can an &quot;application&quot; be anything but a little window onto the base abilities of ChatGPT and so effectively offers nothing <i>more</i> to an end-user. The final result still have to be checked and regular end-users have to do their own prompt.<p>Edit: Also, I should also say that anyone who&#x27;s designing LLM apps that, rather than being end-user tools, are effectively gate keepers to getting action or &quot;a human&quot; from a company deserves a big &quot;f* you&quot; &#x27;cause that approach is evil.</div><br/></div></div><div id="40551538" class="c"><input type="checkbox" id="c-40551538" checked=""/><div class="controls bullet"><span class="by">cqqxo4zV46cp</span><span>|</span><a href="#40549233">parent</a><span>|</span><a href="#40549313">prev</a><span>|</span><a href="#40552576">next</a><span>|</span><label class="collapse" for="c-40551538">[-]</label><label class="expand" for="c-40551538">[1 more]</label></div><br/><div class="children"><div class="content">Or maybe they could choose to focus their attention on people that aren’t needlessly aggressive and adversarial.</div><br/></div></div></div></div><div id="40552576" class="c"><input type="checkbox" id="c-40552576" checked=""/><div class="controls bullet"><span class="by">blumomo</span><span>|</span><a href="#40549233">prev</a><span>|</span><a href="#40550092">next</a><span>|</span><label class="collapse" for="c-40552576">[-]</label><label class="expand" for="c-40552576">[1 more]</label></div><br/><div class="children"><div class="content">&gt; PUBLISHED<p>&gt; June 8, 2024<p>Is this an article from the future?</div><br/></div></div><div id="40550092" class="c"><input type="checkbox" id="c-40550092" checked=""/><div class="controls bullet"><span class="by">threeseed</span><span>|</span><a href="#40552576">prev</a><span>|</span><a href="#40548988">next</a><span>|</span><label class="collapse" for="c-40550092">[-]</label><label class="expand" for="c-40550092">[1 more]</label></div><br/><div class="children"><div class="content">RAGs do not prevent hallucinations nor does it guarantee that the quality of your output is contingent solely on the quality of your input. Using LLMs for legal use cases for example has shown it to be poor for anything other than initial research as it is accurate at best 65%:<p><a href="https:&#x2F;&#x2F;dho.stanford.edu&#x2F;wp-content&#x2F;uploads&#x2F;Legal_RAG_Hallucinations.pdf" rel="nofollow">https:&#x2F;&#x2F;dho.stanford.edu&#x2F;wp-content&#x2F;uploads&#x2F;Legal_RAG_Halluc...</a><p>So would strongly disagree that <i>LLMs have become “good enough” for real-world applications&quot;</i> based on what was promised.</div><br/></div></div><div id="40548988" class="c"><input type="checkbox" id="c-40548988" checked=""/><div class="controls bullet"><span class="by">Multicomp</span><span>|</span><a href="#40550092">prev</a><span>|</span><a href="#40548891">next</a><span>|</span><label class="collapse" for="c-40548988">[-]</label><label class="expand" for="c-40548988">[8 more]</label></div><br/><div class="children"><div class="content">Anyone have a convenience solution for doing multi-step workflows? For example, I&#x27;m filling out the basics of an NPC character sheet on my game prep. I&#x27;m using a certain rule system, give the enemy certain tactics, certain stats, certain types of weapons, right now I have a &#x27;god prompt&#x27; trying to walk the LLM through creating the basic character sheet, but the responses get squeezed down into what one or two prompt responses can be.<p>If I can do node-red or a function chain for prompts and outputs, that would be sweet.</div><br/><div id="40549158" class="c"><input type="checkbox" id="c-40549158" checked=""/><div class="controls bullet"><span class="by">hugocbp</span><span>|</span><a href="#40548988">parent</a><span>|</span><a href="#40549191">next</a><span>|</span><label class="collapse" for="c-40549158">[-]</label><label class="expand" for="c-40549158">[1 more]</label></div><br/><div class="children"><div class="content">For me, a very simple &quot;breakdown tasks into a queue and store in a DB&quot; solution has help tremendously with most requests.<p>Instead of trying to do everything into a single chat or chain, add steps to ask the LLM to break down the next tasks, with context, and store that into SQLite or something. Then start new chats&#x2F;chains on each of those tasks.<p>Then just loop them back into LLM.<p>I find that long chats or chains just confuse most models and we start seeing gibberish.<p>Right now I&#x27;m favoring something like:<p>&quot;We&#x27;re going to do task {task}. The current situation and context is {context}.<p>Break down what individual steps we need to perform to achieve {goal} and output these steps with their necessary context as {standard_task_json}. If the output is already enough to satisfy {goal}, just output the result as text.&quot;<p>I find that leaving everything to LLM in a sequence is not as effective as using LLM to break things down and having a DB and code logic to support the development of more complex outcomes.</div><br/></div></div><div id="40549191" class="c"><input type="checkbox" id="c-40549191" checked=""/><div class="controls bullet"><span class="by">gpsx</span><span>|</span><a href="#40548988">parent</a><span>|</span><a href="#40549158">prev</a><span>|</span><a href="#40549249">next</a><span>|</span><label class="collapse" for="c-40549191">[-]</label><label class="expand" for="c-40549191">[1 more]</label></div><br/><div class="children"><div class="content">One option for doing this is to incrementally build up the &quot;document&quot; using isolated prompts for each section. I say document because I am not exactly sure what the character sheet looks like, but I am assuming it can be constructed one section at a time. You create a prompt to create the first section. Then, you create a second prompt that gives the agent your existing document and prompts it to create the next section. You continue until all the sections are finished. In some cases this works better than doing a single conversation.</div><br/></div></div><div id="40549249" class="c"><input type="checkbox" id="c-40549249" checked=""/><div class="controls bullet"><span class="by">proc0</span><span>|</span><a href="#40548988">parent</a><span>|</span><a href="#40549191">prev</a><span>|</span><a href="#40550287">next</a><span>|</span><label class="collapse" for="c-40549249">[-]</label><label class="expand" for="c-40549249">[1 more]</label></div><br/><div class="children"><div class="content">Sounds like you need an agent system, some libs are mentioned here: <a href="https:&#x2F;&#x2F;lilianweng.github.io&#x2F;posts&#x2F;2023-06-23-agent&#x2F;" rel="nofollow">https:&#x2F;&#x2F;lilianweng.github.io&#x2F;posts&#x2F;2023-06-23-agent&#x2F;</a></div><br/></div></div><div id="40550287" class="c"><input type="checkbox" id="c-40550287" checked=""/><div class="controls bullet"><span class="by">127</span><span>|</span><a href="#40548988">parent</a><span>|</span><a href="#40549249">prev</a><span>|</span><a href="#40549065">next</a><span>|</span><label class="collapse" for="c-40550287">[-]</label><label class="expand" for="c-40550287">[1 more]</label></div><br/><div class="children"><div class="content">Did you force it into a parser? You can define a simple language in llama.cpp for the LLM to obey.</div><br/></div></div><div id="40549065" class="c"><input type="checkbox" id="c-40549065" checked=""/><div class="controls bullet"><span class="by">CuriouslyC</span><span>|</span><a href="#40548988">parent</a><span>|</span><a href="#40550287">prev</a><span>|</span><a href="#40549157">next</a><span>|</span><label class="collapse" for="c-40549065">[-]</label><label class="expand" for="c-40549065">[2 more]</label></div><br/><div class="children"><div class="content">You can do multi shot workflows pretty easy, I like to have the model produce markdown, then add code blocks (```json&#x2F;yaml```) to extract the interim results.  You can lay out multiple &quot;phases&quot; in your prompt and have it perform each one in turn, and have each one reference prior phases.  Then at the end you just pull out the code blocks for each phase and you have your structured result.</div><br/></div></div><div id="40549157" class="c"><input type="checkbox" id="c-40549157" checked=""/><div class="controls bullet"><span class="by">mentos</span><span>|</span><a href="#40548988">parent</a><span>|</span><a href="#40549065">prev</a><span>|</span><a href="#40548891">next</a><span>|</span><label class="collapse" for="c-40549157">[-]</label><label class="expand" for="c-40549157">[1 more]</label></div><br/><div class="children"><div class="content">I still haven’t played with using one LLM to oversee another.<p>“You are in charge of game prep and must work with an LLM over many prompts to…”</div><br/></div></div></div></div><div id="40548891" class="c"><input type="checkbox" id="c-40548891" checked=""/><div class="controls bullet"><span class="by">DylanSp</span><span>|</span><a href="#40548988">prev</a><span>|</span><a href="#40550318">next</a><span>|</span><label class="collapse" for="c-40548891">[-]</label><label class="expand" for="c-40548891">[1 more]</label></div><br/><div class="children"><div class="content">Looks like the same content that was posted on oreilly.com a couple days ago, just on a separate site. That has some existing discussion: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=40508390">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=40508390</a>.</div><br/></div></div><div id="40550318" class="c"><input type="checkbox" id="c-40550318" checked=""/><div class="controls bullet"><span class="by">sheepscreek</span><span>|</span><a href="#40548891">prev</a><span>|</span><a href="#40548785">next</a><span>|</span><label class="collapse" for="c-40550318">[-]</label><label class="expand" for="c-40550318">[4 more]</label></div><br/><div class="children"><div class="content">I’m sure this has some decent insights but it’s from almost 1 year ago! A lot has changed in this space since then.</div><br/><div id="40550896" class="c"><input type="checkbox" id="c-40550896" checked=""/><div class="controls bullet"><span class="by">bgrainger</span><span>|</span><a href="#40550318">parent</a><span>|</span><a href="#40548785">next</a><span>|</span><label class="collapse" for="c-40550896">[-]</label><label class="expand" for="c-40550896">[3 more]</label></div><br/><div class="children"><div class="content">Are you sure? The article says &quot;cite this as Yan et al. (May 2024)&quot; and published-time in the metadata is 2024-05-12.<p>Weird: I just refreshed the page and it now redirects to a different domain (than the originally-submitted URL) and has a date of June 8, 2023. It still cites articles and blog posts from 2024, though.</div><br/><div id="40551162" class="c"><input type="checkbox" id="c-40551162" checked=""/><div class="controls bullet"><span class="by">jph00</span><span>|</span><a href="#40550318">root</a><span>|</span><a href="#40550896">parent</a><span>|</span><a href="#40548785">next</a><span>|</span><label class="collapse" for="c-40551162">[-]</label><label class="expand" for="c-40551162">[2 more]</label></div><br/><div class="children"><div class="content">Looks like they made a mistake in the article metadata - they definitely just released this article.</div><br/><div id="40551376" class="c"><input type="checkbox" id="c-40551376" checked=""/><div class="controls bullet"><span class="by">jph00</span><span>|</span><a href="#40550318">root</a><span>|</span><a href="#40551162">parent</a><span>|</span><a href="#40548785">next</a><span>|</span><label class="collapse" for="c-40551376">[-]</label><label class="expand" for="c-40551376">[1 more]</label></div><br/><div class="children"><div class="content">OK I let them know, and they&#x27;ve fixed it now.</div><br/></div></div></div></div></div></div></div></div><div id="40548785" class="c"><input type="checkbox" id="c-40548785" checked=""/><div class="controls bullet"><span class="by">OutOfHere</span><span>|</span><a href="#40550318">prev</a><span>|</span><a href="#40548833">next</a><span>|</span><label class="collapse" for="c-40548785">[-]</label><label class="expand" for="c-40548785">[1 more]</label></div><br/><div class="children"><div class="content">Almost all of this should flow from common-sense. I would use what makes sense for your application, and not worry about the rest. It&#x27;s a toolbox, not a rulebook. The one point that comes more from experience than from common-sense is to always pin your model versions. As a final tip, if despite trying everything, you still don&#x27;t like the LLM&#x27;s output, just run it again!<p>Here is a summary of all points:<p>1. Focus on Prompting Techniques:<p><pre><code>   1.1. Start with n-shot prompts to provide examples demonstrating tasks.
   1.2. Use Chain-of-Thought (CoT) prompting for complex tasks, making instructions specific.
   1.3. Incorporate relevant resources via Retrieval Augmented Generation (RAG).
</code></pre>
2. Structure Inputs and Outputs:<p><pre><code>   2.1. Format inputs using serialization methods like XML, JSON, or Markdown.
   2.2. Ensure outputs are structured to integrate seamlessly with downstream systems.
</code></pre>
3. Simplify Prompts:<p><pre><code>   3.1. Break down complex prompts into smaller, focused ones.
   3.2. Iterate and evaluate each prompt individually for better performance.
</code></pre>
4. Optimize Context Tokens:<p><pre><code>   4.1. Minimize redundant or irrelevant context in prompts.
   4.2. Structure the context clearly to emphasize relationships between parts.
</code></pre>
5. Leverage Information Retrieval&#x2F;RAG:<p><pre><code>   5.1. Use RAG to provide the LLM with knowledge to improve output.
   5.2. Ensure retrieved documents are relevant, dense, and detailed.
   5.3. Utilize hybrid search methods combining keyword and embedding-based retrieval.
</code></pre>
6. Workflow Optimization:<p><pre><code>   6.1. Decompose tasks into multi-step workflows for better accuracy.
   6.2. Prioritize deterministic execution for reliability and predictability.
   6.3. Use caching to save costs and reduce latency.
</code></pre>
7. Evaluation and Monitoring:<p><pre><code>   7.1. Create assertion-based unit tests using real input&#x2F;output samples.
   7.2. Use LLM-as-Judge for pairwise comparisons to evaluate outputs.
   7.3. Regularly review LLM inputs and outputs for new patterns or issues.
</code></pre>
8. Address Hallucinations and Guardrails:<p><pre><code>   8.1. Combine prompt engineering with factual inconsistency guardrails.
   8.2. Use content moderation APIs and PII detection packages to filter outputs.
</code></pre>
9. Operational Practices:<p><pre><code>   9.1. Regularly check for development-prod data skew.
   9.2. Ensure data logging and review input&#x2F;output samples daily.
   9.3. Pin specific model versions to maintain consistency and avoid unexpected changes.
</code></pre>
10. Team and Roles:<p><pre><code>    10.1. Educate and empower all team members to use AI technology.
    10.2. Include designers early in the process to improve user experience and reframe user needs.
    10.3. Ensure the right progression of roles and hire based on the specific phase of the project.
</code></pre>
11. Risk Management:<p><pre><code>    11.1. Calibrate risk tolerance based on the use case and audience.
    11.2. Focus on internal applications first to manage risk and gain confidence before expanding to customer-facing use cases.</code></pre></div><br/></div></div><div id="40548833" class="c"><input type="checkbox" id="c-40548833" checked=""/><div class="controls bullet"><span class="by">felixbraun</span><span>|</span><a href="#40548785">prev</a><span>|</span><a href="#40548773">next</a><span>|</span><label class="collapse" for="c-40548833">[-]</label><label class="expand" for="c-40548833">[1 more]</label></div><br/><div class="children"><div class="content">related discussion (3 days ago): <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=40508390">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=40508390</a></div><br/></div></div><div id="40548773" class="c"><input type="checkbox" id="c-40548773" checked=""/><div class="controls bullet"><span class="by">solidasparagus</span><span>|</span><a href="#40548833">prev</a><span>|</span><a href="#40548778">next</a><span>|</span><label class="collapse" for="c-40548773">[-]</label><label class="expand" for="c-40548773">[25 more]</label></div><br/><div class="children"><div class="content">No offense, but I&#x27;d love to see what they&#x27;ve successfully built using LLMs before taking their advice too seriously. The idea that fine-tuning isn&#x27;t even a consideration (perhaps even something they think is absolutely incorrect if the section titles of the unfinished section is anything to go by) is very strange to me and suggests a pretty narrow perspective IMO</div><br/><div id="40551400" class="c"><input type="checkbox" id="c-40551400" checked=""/><div class="controls bullet"><span class="by">jph00</span><span>|</span><a href="#40548773">parent</a><span>|</span><a href="#40551668">next</a><span>|</span><label class="collapse" for="c-40551400">[-]</label><label class="expand" for="c-40551400">[3 more]</label></div><br/><div class="children"><div class="content">&gt; <i>The idea that fine-tuning isn&#x27;t even a consideration (perhaps even something they think is absolutely incorrect if the section titles of the unfinished section is anything to go by) is very strange to me and suggests a pretty narrow perspective IMO</i><p>The article has a section called &quot;When to finetune&quot;, along with links to separate pages describing how to do so. They absolutely don&#x27;t say that &quot;fine-tuning isn&#x27;t even a consideration&quot;. Instead, they describe the situations in which fine-tuning is likely to be helpful.</div><br/><div id="40552147" class="c"><input type="checkbox" id="c-40552147" checked=""/><div class="controls bullet"><span class="by">solidasparagus</span><span>|</span><a href="#40548773">root</a><span>|</span><a href="#40551400">parent</a><span>|</span><a href="#40552064">prev</a><span>|</span><a href="#40551668">next</a><span>|</span><label class="collapse" for="c-40552147">[-]</label><label class="expand" for="c-40552147">[1 more]</label></div><br/><div class="children"><div class="content">Huh. Well that&#x27;s embarrassing. I guess I missed it when I lost interest in the caching section and jumped straight to Evaluation and Monitoring.</div><br/></div></div></div></div><div id="40551668" class="c"><input type="checkbox" id="c-40551668" checked=""/><div class="controls bullet"><span class="by">bbischof</span><span>|</span><a href="#40548773">parent</a><span>|</span><a href="#40551400">prev</a><span>|</span><a href="#40549391">next</a><span>|</span><label class="collapse" for="c-40551668">[-]</label><label class="expand" for="c-40551668">[2 more]</label></div><br/><div class="children"><div class="content">Hello, it’s Bryan, an author on this piece.<p>I’d you’re interested in using one of the LLM-applications I have in prod, check out <a href="https:&#x2F;&#x2F;hex.tech&#x2F;product&#x2F;magic-ai&#x2F;" rel="nofollow">https:&#x2F;&#x2F;hex.tech&#x2F;product&#x2F;magic-ai&#x2F;</a> It has a free limit every month to give it a try and see how you like it. If you have feedback after using it, we’re always very interested to hear from users.<p>As far as fine-tuning in particular, our consensus is that there are easier options first. I personally have fine-tuned gpt models since 2022; here’s a silly post I wrote about it on gpt 2: <a href="https:&#x2F;&#x2F;wandb.ai&#x2F;wandb&#x2F;fc-bot&#x2F;reports&#x2F;Accelerating-ML-Content-Creation-with-ML---VmlldzoxNzQ0MDAw" rel="nofollow">https:&#x2F;&#x2F;wandb.ai&#x2F;wandb&#x2F;fc-bot&#x2F;reports&#x2F;Accelerating-ML-Conten...</a></div><br/><div id="40552008" class="c"><input type="checkbox" id="c-40552008" checked=""/><div class="controls bullet"><span class="by">solidasparagus</span><span>|</span><a href="#40548773">root</a><span>|</span><a href="#40551668">parent</a><span>|</span><a href="#40549391">next</a><span>|</span><label class="collapse" for="c-40552008">[-]</label><label class="expand" for="c-40552008">[1 more]</label></div><br/><div class="children"><div class="content">I took at look at Magic earlier today and it didn&#x27;t work at all for me, sorry to say. After the example prompt, I tried to learn about a table and it generated bad SQL (correct query to pull a row, but with limit 0). I asked it to show me the DDL and it generated invalid SQL. Then I tried to ask it to do some population statistics on the customer table and ended up confused about why there appears to be two windows in the cell, with the previously generated SQL on the left and the newly generated SQL on the right. The new SQL wouldn&#x27;t run when I hit run cell, the error showed the originally generated SQL. I gave up and bounced.<p>I went back while writing this comment and realized it might be showing me a diff (better use of color would have helped, I have been trained by github). But I was at a loss for what to do with that. I just now figured out the Keep button exists and it accepted the diff and now it sort of makes sense, but the SQL still doesn&#x27;t return any results.<p>My honest feedback is that there is way too much stuff I don&#x27;t understand on the screen and it makes me confused and a little stressed. Ease me into it please, I&#x27;m dumb. There seems to be cells that are linked together and cells that aren&#x27;t(? separated by purplish background) and I don&#x27;t understand it. I am a jupyter user and I feel like this should be intuitive to me, but it isn&#x27;t. I am not a designer, but I suspect the structural markings like cell boundaries are too faint compared to the content of the cells and&#x2F;or the exterior of a cell having the same color as the interior is making it hard for me. I feel lost in a sea of white.<p>But the core issue is that, excluding the prompt I copy-pasted word for word which worked like a charm, I am 0 out of 4 on actually leveraging AI to solve the problems I asked of Magic. I like the concept of natural language BI (I worked on in the early days when Alexa came out) so I probably gave it more chances than I would have for a different product.<p>For me, it doesn&#x27;t fit my criteria for good problems to solve with AI in 2024 - the conversational interface and binary right&#x2F;wrong nature of querying&#x2F;presenting data accurately make the cost of failure too high, which is a death sentence for AI products IMO (compare to proactive, non-blocking products like copilot or shades-of-wrong problems like image generation or conversations with imaginary characters). But text-to-SQL and data presentation make sense as AI capabilities in 2024 so I can see why that could be a good product to pursue. If it worked, I would definitely use it.</div><br/></div></div></div></div><div id="40549391" class="c"><input type="checkbox" id="c-40549391" checked=""/><div class="controls bullet"><span class="by">lmeyerov</span><span>|</span><a href="#40548773">parent</a><span>|</span><a href="#40551668">prev</a><span>|</span><a href="#40548901">next</a><span>|</span><label class="collapse" for="c-40549391">[-]</label><label class="expand" for="c-40549391">[5 more]</label></div><br/><div class="children"><div class="content">We work in some pretty serious domains and try to stay away from fine tuning:<p>- Most of our accuracy ROI is from agentic loops over top models, and dynamic RAG example injection goes far here that the relative lift of adding fine-tuning isn&#x27;t worth the many costs<p>- A lot of fine-tuning is for OSS models that do worse than agentic loops over the proprietary GPT4&#x2F;Opus3<p>- For distribution, it&#x27;s a lot easier to deploy for pluggable top APIs without requiring fine-tuning, e.g., &quot;connect to your gpt4&#x2F;opus3 + for dumber-but-bigger tasks, groq&quot;<p>- The resources we could put into fine-tuning are better spent on RAG, agentic loops, prompts&#x2F;evals, etc<p>We do use tuned smaller dumber models, such as part of a coarse relevancy filter in a firehose pipeline... but these are outliers. Likewise, we expect to be using them more... but again, for rarer cases and only after we&#x27;ve exhausted other stuff. I&#x27;m guessing as we do more fine-tuning, it&#x27;ll be more on embeddings than LLMs, at least until OSS models get a lot better.</div><br/><div id="40549566" class="c"><input type="checkbox" id="c-40549566" checked=""/><div class="controls bullet"><span class="by">solidasparagus</span><span>|</span><a href="#40548773">root</a><span>|</span><a href="#40549391">parent</a><span>|</span><a href="#40548901">next</a><span>|</span><label class="collapse" for="c-40549566">[-]</label><label class="expand" for="c-40549566">[4 more]</label></div><br/><div class="children"><div class="content">See if the article said this, I would have agreed - fine-tuning is a tool and it should be used thoughtfully. Although I personally believe that in this funding climate it makes sense to make data collection and model training a core capability of any AI product. However that will only be available and wise for some founders.</div><br/><div id="40550178" class="c"><input type="checkbox" id="c-40550178" checked=""/><div class="controls bullet"><span class="by">lmeyerov</span><span>|</span><a href="#40548773">root</a><span>|</span><a href="#40549566">parent</a><span>|</span><a href="#40548901">next</a><span>|</span><label class="collapse" for="c-40550178">[-]</label><label class="expand" for="c-40550178">[3 more]</label></div><br/><div class="children"><div class="content">Agreed, model training and data collection are great!<p>The subtle bit is just doesn&#x27;t have to be for LLMs, as these are typically part of a system-of-models. E.g., we &lt;3 RAG, and GNNs for improving your KG is fascinating. Likewise, dspy&#x27;s explorations in optimizing prompts, vs LLMs, is very cool.</div><br/><div id="40552312" class="c"><input type="checkbox" id="c-40552312" checked=""/><div class="controls bullet"><span class="by">tarasglek</span><span>|</span><a href="#40548773">root</a><span>|</span><a href="#40550178">parent</a><span>|</span><a href="#40550255">next</a><span>|</span><label class="collapse" for="c-40552312">[-]</label><label class="expand" for="c-40552312">[1 more]</label></div><br/><div class="children"><div class="content">Can you give a concrete example of GNNs helping?</div><br/></div></div><div id="40550255" class="c"><input type="checkbox" id="c-40550255" checked=""/><div class="controls bullet"><span class="by">solidasparagus</span><span>|</span><a href="#40548773">root</a><span>|</span><a href="#40550178">parent</a><span>|</span><a href="#40552312">prev</a><span>|</span><a href="#40548901">next</a><span>|</span><label class="collapse" for="c-40550255">[-]</label><label class="expand" for="c-40550255">[1 more]</label></div><br/><div class="children"><div class="content">&gt; we &lt;3 RAG, and GNNs for improving your KG is fascinating<p>Oh man I am so torn between this being a fantastic idea and this being &quot;building a better slide-rule in the age of the computer&quot;.<p>dspy is definitely a project I want to dig into more</div><br/></div></div></div></div></div></div></div></div><div id="40548901" class="c"><input type="checkbox" id="c-40548901" checked=""/><div class="controls bullet"><span class="by">gandalfgeek</span><span>|</span><a href="#40548773">parent</a><span>|</span><a href="#40549391">prev</a><span>|</span><a href="#40549178">next</a><span>|</span><label class="collapse" for="c-40548901">[-]</label><label class="expand" for="c-40548901">[3 more]</label></div><br/><div class="children"><div class="content">This was kind of conventional wisdom (&quot;fine tune only when absolutely necessary for your domain&quot;, &quot;fine-tuning hurts factuality&quot;), but some recent research (some of which they cite) has actually quantitatively shown that RAG is much preferable to FT for adding domain-specific knowledge to an LLM:<p>- &quot;Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?&quot; <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;&#x2F;2405.05904" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;&#x2F;2405.05904</a><p>- &quot;Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs&quot; <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2312.05934" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2312.05934</a></div><br/><div id="40549068" class="c"><input type="checkbox" id="c-40549068" checked=""/><div class="controls bullet"><span class="by">solidasparagus</span><span>|</span><a href="#40548773">root</a><span>|</span><a href="#40548901">parent</a><span>|</span><a href="#40549178">next</a><span>|</span><label class="collapse" for="c-40549068">[-]</label><label class="expand" for="c-40549068">[2 more]</label></div><br/><div class="children"><div class="content">Thanks, I&#x27;ll read those more fully.<p>But &quot;knowledge injection&quot; is still pretty narrow to me. Here&#x27;s an example of a very simple but extremely valuable usecase - taking a model that was trained on language+code and finetuning it on a text-to-DSL task, where the DSL is a custom one you created (and thus isn&#x27;t in the training data). I would consider that close to infeasible if your only tool is a RAG hammer, but it&#x27;s a very powerful way to leverage LLMs.</div><br/><div id="40550777" class="c"><input type="checkbox" id="c-40550777" checked=""/><div class="controls bullet"><span class="by">gandalfgeek</span><span>|</span><a href="#40548773">root</a><span>|</span><a href="#40549068">parent</a><span>|</span><a href="#40549178">next</a><span>|</span><label class="collapse" for="c-40550777">[-]</label><label class="expand" for="c-40550777">[1 more]</label></div><br/><div class="children"><div class="content">Agree that your use-case is different. The papers above are dealing mostly with adding a domain-specific <i>textual</i> corpus, still answering questions in prose.<p>&quot;Teaching&quot; the LLM an entirely new language (like a DSL) might actually need fine-tuning, but you can probably build a pretty decent first-cut of your system with n-shot prompts, then fine-tune to get the accuracy higher.</div><br/></div></div></div></div></div></div><div id="40549178" class="c"><input type="checkbox" id="c-40549178" checked=""/><div class="controls bullet"><span class="by">OutOfHere</span><span>|</span><a href="#40548773">parent</a><span>|</span><a href="#40548901">prev</a><span>|</span><a href="#40549100">next</a><span>|</span><label class="collapse" for="c-40549178">[-]</label><label class="expand" for="c-40549178">[7 more]</label></div><br/><div class="children"><div class="content">Fine-tuning is an absolutely necessary for true AI, and even if it&#x27;s desirable, it&#x27;s unfeasible to do for now for any large model considering how expensive GPUs are. If I had infinite money, I&#x27;d throw it at continuous fine-tuning and would throw away the RAG. Fine-tuning also requires appropriate measures to prevent forgetting of older concepts.</div><br/><div id="40549242" class="c"><input type="checkbox" id="c-40549242" checked=""/><div class="controls bullet"><span class="by">solidasparagus</span><span>|</span><a href="#40548773">root</a><span>|</span><a href="#40549178">parent</a><span>|</span><a href="#40549100">next</a><span>|</span><label class="collapse" for="c-40549242">[-]</label><label class="expand" for="c-40549242">[6 more]</label></div><br/><div class="children"><div class="content">It is not unfeasible. It is absolutely realistic to do distributed finetuning of an 8B text model on previous generation hardware. You can add finetuning to your set of options for about the cost of one FTE - up to you whether that tradeoff is worth it, but in many places it is. The expertise to pull it off is expensive, but to get a mid-level AI SME capable of helping a company adopt finetuning, you are only going to pay about the equivalent of 1-3 senior engineers.<p>Expensive? Sure, all of AI is crazy expensive. Unfeasible? No</div><br/><div id="40549281" class="c"><input type="checkbox" id="c-40549281" checked=""/><div class="controls bullet"><span class="by">OutOfHere</span><span>|</span><a href="#40548773">root</a><span>|</span><a href="#40549242">parent</a><span>|</span><a href="#40549100">next</a><span>|</span><label class="collapse" for="c-40549281">[-]</label><label class="expand" for="c-40549281">[5 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t consider a small 8B model to be worth fine-tuning. Fine-tuning is worthwhile when you have a larger model with capacity to add data, perhaps one that can even grow its layers with the data. In contrast, fine-tuning a small saturated model will easily cause it to forget older information.<p>All things considered, in relative terms, as much as I think fine-tuning would be nice, it will remain significantly more expensive than just making RAG or search calls. I say this while being a fan of fine-tuning.</div><br/><div id="40549298" class="c"><input type="checkbox" id="c-40549298" checked=""/><div class="controls bullet"><span class="by">solidasparagus</span><span>|</span><a href="#40548773">root</a><span>|</span><a href="#40549281">parent</a><span>|</span><a href="#40549100">next</a><span>|</span><label class="collapse" for="c-40549298">[-]</label><label class="expand" for="c-40549298">[4 more]</label></div><br/><div class="children"><div class="content">&gt; I don&#x27;t consider a small 8B model to be worth fine-tuning.<p>Going to have to disagree with you on that one. A modern 8B model that has been trained on enough tokens is ridiculously powerful.</div><br/><div id="40549354" class="c"><input type="checkbox" id="c-40549354" checked=""/><div class="controls bullet"><span class="by">OutOfHere</span><span>|</span><a href="#40548773">root</a><span>|</span><a href="#40549298">parent</a><span>|</span><a href="#40549100">next</a><span>|</span><label class="collapse" for="c-40549354">[-]</label><label class="expand" for="c-40549354">[3 more]</label></div><br/><div class="children"><div class="content">A well-trained 8B model will already be over-saturated with information from the start. It will therefore easily forget much old information when fine-tuning it with new materials. It just doesn&#x27;t have the capacity to take in too much information.<p>Don&#x27;t get me wrong. I think an 70B or larger model would be worth fine-tuning, especially if it can be grown further with more layers.</div><br/><div id="40549535" class="c"><input type="checkbox" id="c-40549535" checked=""/><div class="controls bullet"><span class="by">solidasparagus</span><span>|</span><a href="#40548773">root</a><span>|</span><a href="#40549354">parent</a><span>|</span><a href="#40549100">next</a><span>|</span><label class="collapse" for="c-40549535">[-]</label><label class="expand" for="c-40549535">[2 more]</label></div><br/><div class="children"><div class="content">&gt; A well-trained 8B model will already be over-saturated with information from the start<p>Any evidence of that that I can look at? This doesn&#x27;t match what I&#x27;ve seen nor have I heard this from the world-class researchers I have worked with. Would be interested to learn more.</div><br/><div id="40550692" class="c"><input type="checkbox" id="c-40550692" checked=""/><div class="controls bullet"><span class="by">OutOfHere</span><span>|</span><a href="#40548773">root</a><span>|</span><a href="#40549535">parent</a><span>|</span><a href="#40549100">next</a><span>|</span><label class="collapse" for="c-40550692">[-]</label><label class="expand" for="c-40550692">[1 more]</label></div><br/><div class="children"><div class="content">Upon further thought, if fine-tuning involves adding layers, then the initial saturation should not matter. Let&#x27;s say if an 8B model adds 0.8*2 = 1.6B of new layers for fine-tuning, then with some assumptions, a ballpark is that this could be good for 16 million articles for fine-tuning.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="40549100" class="c"><input type="checkbox" id="c-40549100" checked=""/><div class="controls bullet"><span class="by">CuriouslyC</span><span>|</span><a href="#40548773">parent</a><span>|</span><a href="#40549178">prev</a><span>|</span><a href="#40548778">next</a><span>|</span><label class="collapse" for="c-40549100">[-]</label><label class="expand" for="c-40549100">[4 more]</label></div><br/><div class="children"><div class="content">Fine tuning has been on the way out for a while.  It&#x27;s hard to do right and costly.  LoRAs are better for influencing output style as they don&#x27;t dumb down the model, and they&#x27;re easier to create. This is on top of RAG just being better for new facts like the other reply mentioned.</div><br/><div id="40549280" class="c"><input type="checkbox" id="c-40549280" checked=""/><div class="controls bullet"><span class="by">solidasparagus</span><span>|</span><a href="#40548773">root</a><span>|</span><a href="#40549100">parent</a><span>|</span><a href="#40548778">next</a><span>|</span><label class="collapse" for="c-40549280">[-]</label><label class="expand" for="c-40549280">[3 more]</label></div><br/><div class="children"><div class="content">How much of that is just the flood of traditional engineers into the space and the fact that collecting data and then fine-tuning models is orders of magnitude more complex than just throwing in RAG? I suspect a huge amount of RAG&#x27;s popularity is just that any engineer can do a version of it + ChatGPT API calls in a day.<p>As for lora - in the context of my comment, that&#x27;s just splitting hairs IMO. It falls in the category of finetuning for me, although I understand why you might disagree. But it&#x27;s not like the article mentions lora either, nor am I aware of people doing lora without GPUs which the article is against (No GPUs before PMF)</div><br/><div id="40551243" class="c"><input type="checkbox" id="c-40551243" checked=""/><div class="controls bullet"><span class="by">altdataseller</span><span>|</span><a href="#40548773">root</a><span>|</span><a href="#40549280">parent</a><span>|</span><a href="#40548778">next</a><span>|</span><label class="collapse" for="c-40551243">[-]</label><label class="expand" for="c-40551243">[2 more]</label></div><br/><div class="children"><div class="content">I disagree. No amount of fine tuning will ever give the LLM the relevant context with which to answer my question. Maybe if your context is a static Wikipedia or something that will never change, you can fine tune it. But if your data and docs keep changing, how is fine tuning going to be better than RAG?</div><br/><div id="40551325" class="c"><input type="checkbox" id="c-40551325" checked=""/><div class="controls bullet"><span class="by">solidasparagus</span><span>|</span><a href="#40548773">root</a><span>|</span><a href="#40551243">parent</a><span>|</span><a href="#40548778">next</a><span>|</span><label class="collapse" for="c-40551325">[-]</label><label class="expand" for="c-40551325">[1 more]</label></div><br/><div class="children"><div class="content">Continuous retraining and deployment maybe? But I&#x27;m actually not anti-RAG (although I think it is overrated because the retrieval problem is still handled extremely naively), I just think that fine-tuning should <i>also</i> be in your toolkit.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></body></html>