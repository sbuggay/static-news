<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1723971667778" as="style"/><link rel="stylesheet" href="styles.css?v=1723971667778"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://joel.tools/smarter/">Are you better than a language model at predicting the next word?</a> <span class="domain">(<a href="https://joel.tools">joel.tools</a>)</span></div><div class="subtext"><span>JoelEinbinder</span> | <span>66 comments</span></div><br/><div><div id="41281018" class="c"><input type="checkbox" id="c-41281018" checked=""/><div class="controls bullet"><span class="by">modeless</span><span>|</span><a href="#41277363">next</a><span>|</span><label class="collapse" for="c-41281018">[-]</label><label class="expand" for="c-41281018">[1 more]</label></div><br/><div class="children"><div class="content">&gt; You scored 11&#x2F;15. The best language model, llama-2-7b, scored 10&#x2F;15.<p>I see that you get a random quiz every time, so results aren&#x27;t comparable between people. I think I got an easy one. Neat game! If you could find a corpus that makes it easy for average humans to beat the LLMs, and add some nice design, maybe Wordle-style daily challenge plus social sharing etc, I could see it going viral just as a way for people to &quot;prove&quot; that they are &quot;smarter&quot; than AI.</div><br/></div></div><div id="41277363" class="c"><input type="checkbox" id="c-41277363" checked=""/><div class="controls bullet"><span class="by">jsnell</span><span>|</span><a href="#41281018">prev</a><span>|</span><a href="#41277195">next</a><span>|</span><label class="collapse" for="c-41277363">[-]</label><label class="expand" for="c-41277363">[8 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a neat idea, though not what I expected from the title talking about &quot;smart&quot; :)<p>You might want to replace the single page format with showing just one question at a time, and giving instant feedback on after each answer.<p>First, it&#x27;d be more engaging. Even the small version of the quiz is a bit long for something where you don&#x27;t know what the payoff will be. Second, you&#x27;d get to see the correct answer while still having the context on why you replied the way you did.</div><br/><div id="41278496" class="c"><input type="checkbox" id="c-41278496" checked=""/><div class="controls bullet"><span class="by">codetrotter</span><span>|</span><a href="#41277363">parent</a><span>|</span><a href="#41277466">next</a><span>|</span><label class="collapse" for="c-41278496">[-]</label><label class="expand" for="c-41278496">[1 more]</label></div><br/><div class="children"><div class="content">&gt; not what I expected from the title talking about &quot;smart&quot;<p>I think the title is mainly a reference to the TV show “Are you smarter than a fifth grader?”<p>Fittingly then, is the fact that a lot of types of questions that they were asking in that TV show was mostly trivia. Which I also don’t think of as being a particularly important characteristic of being “smart”.<p>When I think of “smart” people, I think of people who can take limited amount of information and connect dots in ways that others can’t. Of course it also builds on knowledge. You need to have specific knowledge in the first place to make connections. But knowing facts like “the battle of so and so happened on August 18th 1924, one hundred years ago today” alone is not “smart”. A smart person is someone who uses knowledge in a surprising way. Or in a way that others would not have been able to. After the smart person made the connection others might also go like “oh that’s so obvious why didn’t I think about that” or even “yeah that’s really obvious, I could’ve thought of that too”. And yet the first person to actually make, and properly communicate that connection was the smart one. Smart exactly because they did.</div><br/></div></div><div id="41277466" class="c"><input type="checkbox" id="c-41277466" checked=""/><div class="controls bullet"><span class="by">JoelEinbinder</span><span>|</span><a href="#41277363">parent</a><span>|</span><a href="#41278496">prev</a><span>|</span><a href="#41277499">next</a><span>|</span><label class="collapse" for="c-41277466">[-]</label><label class="expand" for="c-41277466">[3 more]</label></div><br/><div class="children"><div class="content">If you want to practice it one question at at time, you set the question count to 1.
<a href="https:&#x2F;&#x2F;joel.tools&#x2F;smarter&#x2F;?questions=1" rel="nofollow">https:&#x2F;&#x2F;joel.tools&#x2F;smarter&#x2F;?questions=1</a><p>When I tested it this way it resulted in less of an emotional reaction.</div><br/><div id="41278827" class="c"><input type="checkbox" id="c-41278827" checked=""/><div class="controls bullet"><span class="by">lupire</span><span>|</span><a href="#41277363">root</a><span>|</span><a href="#41277466">parent</a><span>|</span><a href="#41277499">next</a><span>|</span><label class="collapse" for="c-41278827">[-]</label><label class="expand" for="c-41278827">[2 more]</label></div><br/><div class="children"><div class="content">I retired as worldwide champion (tied) of text prediction.<p><pre><code>  you: 0&#x2F;1
  gpt-4o: 0&#x2F;1
  gpt-4: 0&#x2F;1
  gpt-4o-mini: 0&#x2F;1
  llama-2-7b: 0&#x2F;1
  llama-3-8b: 0&#x2F;1
  mistral-7b: 0&#x2F;1
  unigram: 0&#x2F;1</code></pre></div><br/><div id="41280068" class="c"><input type="checkbox" id="c-41280068" checked=""/><div class="controls bullet"><span class="by">SushiHippie</span><span>|</span><a href="#41277363">root</a><span>|</span><a href="#41278827">parent</a><span>|</span><a href="#41277499">next</a><span>|</span><label class="collapse" for="c-41280068">[-]</label><label class="expand" for="c-41280068">[1 more]</label></div><br/><div class="children"><div class="content">Uhm I was just wondering if all models could get a question correct at the same time and except this &quot;you&quot; model all got it correct.<p>you: 0&#x2F;1<p>gpt-4o: 1&#x2F;1<p>gpt-4: 1&#x2F;1<p>gpt-4o-mini: 1&#x2F;1<p>llama-2-7b: 1&#x2F;1<p>llama-3-8b: 1&#x2F;1<p>mistral-7b: 1&#x2F;1<p>unigram: 1&#x2F;1</div><br/></div></div></div></div></div></div><div id="41277499" class="c"><input type="checkbox" id="c-41277499" checked=""/><div class="controls bullet"><span class="by">KTibow</span><span>|</span><a href="#41277363">parent</a><span>|</span><a href="#41277466">prev</a><span>|</span><a href="#41279521">next</a><span>|</span><label class="collapse" for="c-41277499">[-]</label><label class="expand" for="c-41277499">[2 more]</label></div><br/><div class="children"><div class="content">If you&#x27;re looking for &quot;knowledge&quot; try <a href="https:&#x2F;&#x2F;d.erenrich.net&#x2F;are-you-smarter-than-an-llm&#x2F;index.html" rel="nofollow">https:&#x2F;&#x2F;d.erenrich.net&#x2F;are-you-smarter-than-an-llm&#x2F;index.htm...</a></div><br/><div id="41280173" class="c"><input type="checkbox" id="c-41280173" checked=""/><div class="controls bullet"><span class="by">j_bum</span><span>|</span><a href="#41277363">root</a><span>|</span><a href="#41277499">parent</a><span>|</span><a href="#41279521">next</a><span>|</span><label class="collapse" for="c-41280173">[-]</label><label class="expand" for="c-41280173">[1 more]</label></div><br/><div class="children"><div class="content">This is fun!<p>I bet this could be a unique testing resource for aspiring Jeapordy contestants.</div><br/></div></div></div></div><div id="41279521" class="c"><input type="checkbox" id="c-41279521" checked=""/><div class="controls bullet"><span class="by">dang</span><span>|</span><a href="#41277363">parent</a><span>|</span><a href="#41277499">prev</a><span>|</span><a href="#41277195">next</a><span>|</span><label class="collapse" for="c-41279521">[-]</label><label class="expand" for="c-41279521">[1 more]</label></div><br/><div class="children"><div class="content">Thanks - we&#x27;ve LLMified the title.</div><br/></div></div></div></div><div id="41277195" class="c"><input type="checkbox" id="c-41277195" checked=""/><div class="controls bullet"><span class="by">JoelEinbinder</span><span>|</span><a href="#41277363">prev</a><span>|</span><a href="#41281080">next</a><span>|</span><label class="collapse" for="c-41277195">[-]</label><label class="expand" for="c-41277195">[3 more]</label></div><br/><div class="children"><div class="content">I made a little game&#x2F;quiz where you try to guess the next word in a bunch of Hacker News comments and compete against various language models. I used llama2 to generate three alternative completions for each comment creating a multiple choice question. For the local language models that you are competing against, I consider them having picked the answer with the lowest total perplexity of prompt + answer. I am able to replicate this behavior with the OpenAI models by setting a logit_bias that limits the llm to pick only one of the allowed answers. I tried just giving the full multiple choice question as a prompt and having it pick an answer, but that led to really poor results. So I&#x27;m not able to compare with Claude or any online LLMs that don&#x27;t have logit_bias.<p>I wouldn&#x27;t call the quiz fun exactly. After playing with it a lot I think I&#x27;ve been able to consistently get above 50% of questions right. I have slowed down a lot answering each question, which I think LLMs have trouble doing.</div><br/><div id="41278238" class="c"><input type="checkbox" id="c-41278238" checked=""/><div class="controls bullet"><span class="by">jonahx</span><span>|</span><a href="#41277195">parent</a><span>|</span><a href="#41278603">next</a><span>|</span><label class="collapse" for="c-41278238">[-]</label><label class="expand" for="c-41278238">[1 more]</label></div><br/><div class="children"><div class="content">&quot;This exercise helped me to understand how language models work on a much deeper level.&quot;<p>I&#x27;d like to hear more on this.</div><br/></div></div><div id="41278603" class="c"><input type="checkbox" id="c-41278603" checked=""/><div class="controls bullet"><span class="by">0xDEADFED5</span><span>|</span><a href="#41277195">parent</a><span>|</span><a href="#41278238">prev</a><span>|</span><a href="#41281080">next</a><span>|</span><label class="collapse" for="c-41278603">[-]</label><label class="expand" for="c-41278603">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s an interesting test, pretty cool idea.  Thanks for sharing</div><br/></div></div></div></div><div id="41281080" class="c"><input type="checkbox" id="c-41281080" checked=""/><div class="controls bullet"><span class="by">blitzar</span><span>|</span><a href="#41277195">prev</a><span>|</span><a href="#41279973">next</a><span>|</span><label class="collapse" for="c-41281080">[-]</label><label class="expand" for="c-41281080">[1 more]</label></div><br/><div class="children"><div class="content">I took some mushrooms and hallucinated the answers.</div><br/></div></div><div id="41279973" class="c"><input type="checkbox" id="c-41279973" checked=""/><div class="controls bullet"><span class="by">nojs</span><span>|</span><a href="#41281080">prev</a><span>|</span><a href="#41277443">next</a><span>|</span><label class="collapse" for="c-41279973">[-]</label><label class="expand" for="c-41279973">[2 more]</label></div><br/><div class="children"><div class="content">Nice. I found you can beat this by picking the word least likely to be selected by a language model, because it seems like the alternative choices are generated by an LLM. “Pick the outlier” is the best strategy.<p>This is presumably also a simply strategy for detecting AI content in general - see how many “high temperature” choices it makes.</div><br/><div id="41280041" class="c"><input type="checkbox" id="c-41280041" checked=""/><div class="controls bullet"><span class="by">JoelEinbinder</span><span>|</span><a href="#41279973">parent</a><span>|</span><a href="#41277443">next</a><span>|</span><label class="collapse" for="c-41280041">[-]</label><label class="expand" for="c-41280041">[1 more]</label></div><br/><div class="children"><div class="content">What scores are you getting using this technique?</div><br/></div></div></div></div><div id="41277443" class="c"><input type="checkbox" id="c-41277443" checked=""/><div class="controls bullet"><span class="by">layer8</span><span>|</span><a href="#41279973">prev</a><span>|</span><a href="#41280184">next</a><span>|</span><label class="collapse" for="c-41277443">[-]</label><label class="expand" for="c-41277443">[1 more]</label></div><br/><div class="children"><div class="content">This is also a good test for noticing that you spend too much time reading HN comments.</div><br/></div></div><div id="41280184" class="c"><input type="checkbox" id="c-41280184" checked=""/><div class="controls bullet"><span class="by">chmod775</span><span>|</span><a href="#41277443">prev</a><span>|</span><a href="#41280787">next</a><span>|</span><label class="collapse" for="c-41280184">[-]</label><label class="expand" for="c-41280184">[2 more]</label></div><br/><div class="children"><div class="content"><p><pre><code>    you: 4&#x2F;15
    gpt-4o: 0&#x2F;15
    gpt-4: 1&#x2F;15
    gpt-4o-mini: 2&#x2F;15
    llama-2-7b: 2&#x2F;15
    llama-3-8b: 3&#x2F;15
    mistral-7b: 4&#x2F;15
    unigram: 1&#x2F;15
</code></pre>
Seems like none of us is really better than flipping a coin, so I&#x27;d wager that you cannot accurately predict the next word with the given information.<p>If one could instead sort the answers by likelihood and got scored based on how high one ranked the correct answer, things would probably look better than random.<p>Also I wonder how these LLMs were prompted. Were they just used to complete the text, or where they put in a &quot;mood&quot; where they would try to complete the text in the original author&#x27;s voice?<p>Obviously as as human I&#x27;d try to put myself in the author&#x27;s head and emulate their way of speaking, whereas an LLM might just complete things in its default voice.</div><br/><div id="41280314" class="c"><input type="checkbox" id="c-41280314" checked=""/><div class="controls bullet"><span class="by">JoelEinbinder</span><span>|</span><a href="#41280184">parent</a><span>|</span><a href="#41280787">next</a><span>|</span><label class="collapse" for="c-41280314">[-]</label><label class="expand" for="c-41280314">[1 more]</label></div><br/><div class="children"><div class="content">On the full set of 1000 questions, the language models are getting 30-35% correct.  With patience, humans can do 40-50%.<p>The language models were prompted with the text + each candidate answer, and the one with the lowest perplexity was picked. I tried to avoid instruction tuned models wherever possible to avoid the &quot;voice&quot; problem.</div><br/></div></div></div></div><div id="41280787" class="c"><input type="checkbox" id="c-41280787" checked=""/><div class="controls bullet"><span class="by">pizza</span><span>|</span><a href="#41280184">prev</a><span>|</span><a href="#41278263">next</a><span>|</span><label class="collapse" for="c-41280787">[-]</label><label class="expand" for="c-41280787">[1 more]</label></div><br/><div class="children"><div class="content">If the samples came from HN, I wonder how likely it is that the text is already a part of a dataset (ie common crawl snapshot) so that the LLMs have already seen them?<p>edit: judging from the comments I saw, they were all quite recent, so I guess this isn&#x27;t happening. Though I do know that ChatGPT can sometimes use a Bing search tool during chats, which can actually link to recently indexed text, but I highly doubt that the gpt4o-mini API model is doing that.</div><br/></div></div><div id="41278263" class="c"><input type="checkbox" id="c-41278263" checked=""/><div class="controls bullet"><span class="by">anikan_vader</span><span>|</span><a href="#41280787">prev</a><span>|</span><a href="#41278003">next</a><span>|</span><label class="collapse" for="c-41278263">[-]</label><label class="expand" for="c-41278263">[2 more]</label></div><br/><div class="children"><div class="content">Got 8&#x2F;15, best AI model got 7&#x2F;15, and unigram got 1&#x2F;15.<p>Finally a use for all the wasted hours I’ve spent on HN — my next word prediction is marginally better than that of the AI.</div><br/><div id="41278611" class="c"><input type="checkbox" id="c-41278611" checked=""/><div class="controls bullet"><span class="by">sethammons</span><span>|</span><a href="#41278263">parent</a><span>|</span><a href="#41278003">next</a><span>|</span><label class="collapse" for="c-41278611">[-]</label><label class="expand" for="c-41278611">[1 more]</label></div><br/><div class="children"><div class="content">I have wasted an inordinate amount of time hn. i scored 2&#x2F;15</div><br/></div></div></div></div><div id="41278003" class="c"><input type="checkbox" id="c-41278003" checked=""/><div class="controls bullet"><span class="by">moritzwarhier</span><span>|</span><a href="#41278263">prev</a><span>|</span><a href="#41280245">next</a><span>|</span><label class="collapse" for="c-41278003">[-]</label><label class="expand" for="c-41278003">[1 more]</label></div><br/><div class="children"><div class="content">This is the best interactive website about LLMs at a meta level (so excluding prompt interfaces for actual AIs) that I&#x27;ve seen so far.<p>Quizzes can be magical.<p>Haven&#x27;t seen any cooler new 
language-related interactive fun-project on the web since:<p><a href="https:&#x2F;&#x2F;wikispeedruns.com&#x2F;" rel="nofollow">https:&#x2F;&#x2F;wikispeedruns.com&#x2F;</a><p>It would be great if the quiz included an intro or note about the training data, but as-is it also succeeds because it&#x27;s obvious from the quiz prompts&#x2F;questions that they&#x27;re related to HN comments.<p>Sharing this with a general audience could spark funny discussions about bubbles and biases :)</div><br/></div></div><div id="41280245" class="c"><input type="checkbox" id="c-41280245" checked=""/><div class="controls bullet"><span class="by">dataflow</span><span>|</span><a href="#41278003">prev</a><span>|</span><a href="#41277544">next</a><span>|</span><label class="collapse" for="c-41280245">[-]</label><label class="expand" for="c-41280245">[1 more]</label></div><br/><div class="children"><div class="content">I got 9&#x2F;15, vs. 4&#x2F;15 for an LLM. I assume these are lifted from HN? Seems like an indication I should spend less time here...</div><br/></div></div><div id="41277544" class="c"><input type="checkbox" id="c-41277544" checked=""/><div class="controls bullet"><span class="by">Garlef</span><span>|</span><a href="#41280245">prev</a><span>|</span><a href="#41280958">next</a><span>|</span><label class="collapse" for="c-41277544">[-]</label><label class="expand" for="c-41277544">[1 more]</label></div><br/><div class="children"><div class="content">I like it. It&#x27;s a humorous reversal of the usual articles that boil down to &quot;Look! I made the AI fail at something!&quot;</div><br/></div></div><div id="41280958" class="c"><input type="checkbox" id="c-41280958" checked=""/><div class="controls bullet"><span class="by">lelanthran</span><span>|</span><a href="#41277544">prev</a><span>|</span><a href="#41280065">next</a><span>|</span><label class="collapse" for="c-41280958">[-]</label><label class="expand" for="c-41280958">[1 more]</label></div><br/><div class="children"><div class="content">This is a nonsense test. There is no context, so the &#x27;next&#x27; word after the single word &#x27;The&#x27; is effectively random.<p>I&#x27;m pretty certain that LLMs are unable to work at all without context.</div><br/></div></div><div id="41280065" class="c"><input type="checkbox" id="c-41280065" checked=""/><div class="controls bullet"><span class="by">RheingoldRiver</span><span>|</span><a href="#41280958">prev</a><span>|</span><a href="#41277903">next</a><span>|</span><label class="collapse" for="c-41280065">[-]</label><label class="expand" for="c-41280065">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t quite understand, what makes &quot;Okay I&#x27;ve&quot; more correct than &quot;Okay so&quot;? No meaningful context was provided here, how do we know &quot;Okay I&#x27;ve&quot; was at all meaningfully correct?<p>For the longer comments I understand, but for the ones where it&#x27;s 1 or 2 words and many of the options are correct English phrases, I don&#x27;t understand why there&#x27;s bias towards one? Wouldn&#x27;t we need a prompt here?<p>Also, I got bored halfway through and selected &quot;D&quot; for all of them</div><br/></div></div><div id="41277903" class="c"><input type="checkbox" id="c-41277903" checked=""/><div class="controls bullet"><span class="by">Kiro</span><span>|</span><a href="#41280065">prev</a><span>|</span><a href="#41280384">next</a><span>|</span><label class="collapse" for="c-41277903">[-]</label><label class="expand" for="c-41277903">[4 more]</label></div><br/><div class="children"><div class="content">Where do the incorrect options come from?</div><br/><div id="41279951" class="c"><input type="checkbox" id="c-41279951" checked=""/><div class="controls bullet"><span class="by">manuelmoreale</span><span>|</span><a href="#41277903">parent</a><span>|</span><a href="#41278879">next</a><span>|</span><label class="collapse" for="c-41279951">[-]</label><label class="expand" for="c-41279951">[2 more]</label></div><br/><div class="children"><div class="content">In another comment the author wrote<p>&gt; I made a little game&#x2F;quiz where you try to guess the next word in a bunch of Hacker News comments<p>So I guess the correct answer comes from the HN user who wrote the comment?</div><br/><div id="41281016" class="c"><input type="checkbox" id="c-41281016" checked=""/><div class="controls bullet"><span class="by">Kiro</span><span>|</span><a href="#41277903">root</a><span>|</span><a href="#41279951">parent</a><span>|</span><a href="#41278879">next</a><span>|</span><label class="collapse" for="c-41281016">[-]</label><label class="expand" for="c-41281016">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, but I was wondering about the incorrect options.</div><br/></div></div></div></div><div id="41278879" class="c"><input type="checkbox" id="c-41278879" checked=""/><div class="controls bullet"><span class="by">lupire</span><span>|</span><a href="#41277903">parent</a><span>|</span><a href="#41279951">prev</a><span>|</span><a href="#41280384">next</a><span>|</span><label class="collapse" for="c-41278879">[-]</label><label class="expand" for="c-41278879">[1 more]</label></div><br/><div class="children"><div class="content">I suspect they come from the LLMs.</div><br/></div></div></div></div><div id="41280384" class="c"><input type="checkbox" id="c-41280384" checked=""/><div class="controls bullet"><span class="by">card_zero</span><span>|</span><a href="#41277903">prev</a><span>|</span><a href="#41278094">next</a><span>|</span><label class="collapse" for="c-41280384">[-]</label><label class="expand" for="c-41280384">[1 more]</label></div><br/><div class="children"><div class="content">The LLMs are better than me at knowing the finer probabilities of next words, and worse than me at guessing the points being made and reasoning about that.</div><br/></div></div><div id="41278094" class="c"><input type="checkbox" id="c-41278094" checked=""/><div class="controls bullet"><span class="by">ChrisArchitect</span><span>|</span><a href="#41280384">prev</a><span>|</span><a href="#41277654">next</a><span>|</span><label class="collapse" for="c-41278094">[-]</label><label class="expand" for="c-41278094">[1 more]</label></div><br/><div class="children"><div class="content">Related:<p><i>Who&#x27;s Smarter: AI or a 5-Year-Old?</i><p><a href="https:&#x2F;&#x2F;nautil.us&#x2F;whos-smarter-ai-or-a-5-year-old-776799&#x2F;" rel="nofollow">https:&#x2F;&#x2F;nautil.us&#x2F;whos-smarter-ai-or-a-5-year-old-776799&#x2F;</a><p>(<a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=41263363">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=41263363</a>)</div><br/></div></div><div id="41277654" class="c"><input type="checkbox" id="c-41277654" checked=""/><div class="controls bullet"><span class="by">stackghost</span><span>|</span><a href="#41278094">prev</a><span>|</span><a href="#41277533">next</a><span>|</span><label class="collapse" for="c-41277654">[-]</label><label class="expand" for="c-41277654">[11 more]</label></div><br/><div class="children"><div class="content">This is just a test of how likely you are to generate the same word <i>as the LLM</i>.  The LLM does not produce the &quot;correct&quot; next word as there are multiple correct words that fit grammatically and can be used to continue the sentence while maintaining context.<p>I don&#x27;t see what this has to do with being &quot;smarter&quot; than anything.  Example:<p>1. I see a business decision here.
Arm cores have licensing fees attached to them.
Arm is becoming ____<p>a) ether<p>b) a<p>c) the<p>d) more<p>But who&#x27;s to say which is &quot;correct&quot;?  Arm is becoming a household name.  Arm is becoming the premier choice for new CPU architectures.  Arm is becoming more valuable by the day.  Any of b), c), or d) are equally good choices.  What is there to be gained in divining which one the LLM would pick?</div><br/><div id="41277668" class="c"><input type="checkbox" id="c-41277668" checked=""/><div class="controls bullet"><span class="by">JoelEinbinder</span><span>|</span><a href="#41277654">parent</a><span>|</span><a href="#41277533">next</a><span>|</span><label class="collapse" for="c-41277668">[-]</label><label class="expand" for="c-41277668">[10 more]</label></div><br/><div class="children"><div class="content">The LLM didn’t generate the next word. Hacker News commenters did. You can see the source of the comment on the results screen.</div><br/><div id="41278041" class="c"><input type="checkbox" id="c-41278041" checked=""/><div class="controls bullet"><span class="by">sigbottle</span><span>|</span><a href="#41277654">root</a><span>|</span><a href="#41277668">parent</a><span>|</span><a href="#41278057">next</a><span>|</span><label class="collapse" for="c-41278041">[-]</label><label class="expand" for="c-41278041">[3 more]</label></div><br/><div class="children"><div class="content">Do LLM&#x27;s generate words on the fly or can they sort of &quot;go back&quot; and correct themselves? stackghost brought up a good point I didn&#x27;t think about before</div><br/><div id="41280438" class="c"><input type="checkbox" id="c-41280438" checked=""/><div class="controls bullet"><span class="by">benlivengood</span><span>|</span><a href="#41277654">root</a><span>|</span><a href="#41278041">parent</a><span>|</span><a href="#41279862">next</a><span>|</span><label class="collapse" for="c-41280438">[-]</label><label class="expand" for="c-41280438">[1 more]</label></div><br/><div class="children"><div class="content">Beam search generates multiple potential completions and scores multiple tokens by likelihood, the picks the most likely after some threshold or length, which is close to a &quot;go back and try again&quot;.</div><br/></div></div><div id="41279862" class="c"><input type="checkbox" id="c-41279862" checked=""/><div class="controls bullet"><span class="by">YZF</span><span>|</span><a href="#41277654">root</a><span>|</span><a href="#41278041">parent</a><span>|</span><a href="#41280438">prev</a><span>|</span><a href="#41278057">next</a><span>|</span><label class="collapse" for="c-41279862">[-]</label><label class="expand" for="c-41279862">[1 more]</label></div><br/><div class="children"><div class="content">afaik they do not go back. keep in mind there is a context in which they are generating the response, e.g. the system prompt and the actual question.</div><br/></div></div></div></div><div id="41278057" class="c"><input type="checkbox" id="c-41278057" checked=""/><div class="controls bullet"><span class="by">DiscourseFan</span><span>|</span><a href="#41277654">root</a><span>|</span><a href="#41277668">parent</a><span>|</span><a href="#41278041">prev</a><span>|</span><a href="#41277533">next</a><span>|</span><label class="collapse" for="c-41278057">[-]</label><label class="expand" for="c-41278057">[6 more]</label></div><br/><div class="children"><div class="content">At this point, we&#x27;ve all gotten quite used to the &quot;style&quot; of LLM outputs, and personally I doubt this is the case, <i>however</i>, it is possible that there is some, shall we say, <i>corruption</i> of the data here, since it was not possible to measure the ability of LLMs to predict the next word <i>before there were LLMs</i>.<p>I propose you do the same things, but only include HN content from before the existence of LLMs. That should ensure there is no bias towards any of the models.</div><br/><div id="41278090" class="c"><input type="checkbox" id="c-41278090" checked=""/><div class="controls bullet"><span class="by">JoelEinbinder</span><span>|</span><a href="#41277654">root</a><span>|</span><a href="#41278057">parent</a><span>|</span><a href="#41278553">next</a><span>|</span><label class="collapse" for="c-41278090">[-]</label><label class="expand" for="c-41278090">[1 more]</label></div><br/><div class="children"><div class="content">If I used old comments then it&#x27;s likely that the models will have trained on them. I haven&#x27;t tested if that makes a difference though.</div><br/></div></div><div id="41278553" class="c"><input type="checkbox" id="c-41278553" checked=""/><div class="controls bullet"><span class="by">raggi</span><span>|</span><a href="#41277654">root</a><span>|</span><a href="#41278057">parent</a><span>|</span><a href="#41278090">prev</a><span>|</span><a href="#41277533">next</a><span>|</span><label class="collapse" for="c-41278553">[-]</label><label class="expand" for="c-41278553">[4 more]</label></div><br/><div class="children"><div class="content">an unbiased llm shouldn&#x27;t be producing &quot;style&quot;, it should be generating outputs that closely match the training set, as such their introduction should constitute only some biasing toward the average, which also happens in language usage in humans over time. the outcome is likely indistinguishable for large general data sets and large models. i am interested to see how chatbot outputs produce human output bias in generations growing up with them though, that seems likely and will probably be substantial</div><br/><div id="41278940" class="c"><input type="checkbox" id="c-41278940" checked=""/><div class="controls bullet"><span class="by">DiscourseFan</span><span>|</span><a href="#41277654">root</a><span>|</span><a href="#41278553">parent</a><span>|</span><a href="#41277533">next</a><span>|</span><label class="collapse" for="c-41278940">[-]</label><label class="expand" for="c-41278940">[3 more]</label></div><br/><div class="children"><div class="content">But that&#x27;s clearly not the case. There was a post the other day about how GPT used certain words at a rate remarkably higher than average. Also the paragraph breaks, the politesse. No, I don&#x27;t have much to back it up, but generally I can tell very quickly if a chunk of text is from ChatGPT, for instance, or if an image is generated by DALL-E.</div><br/><div id="41279284" class="c"><input type="checkbox" id="c-41279284" checked=""/><div class="controls bullet"><span class="by">raggi</span><span>|</span><a href="#41277654">root</a><span>|</span><a href="#41278940">parent</a><span>|</span><a href="#41277533">next</a><span>|</span><label class="collapse" for="c-41279284">[-]</label><label class="expand" for="c-41279284">[2 more]</label></div><br/><div class="children"><div class="content">in the above, when i say llm, i mean the base models, when i say chatbot, i mean things like chatgpt, they&#x27;re not the same. chatgpt is not just a frontend for the base model, studies on chatgpt covering output biasing that it has from the fine tuning, prompts and contexts and other things they do are largely not applicable to the raw model generation in this quiz, and they are also largely not applicable to llms as a whole</div><br/><div id="41279336" class="c"><input type="checkbox" id="c-41279336" checked=""/><div class="controls bullet"><span class="by">DiscourseFan</span><span>|</span><a href="#41277654">root</a><span>|</span><a href="#41279284">parent</a><span>|</span><a href="#41277533">next</a><span>|</span><label class="collapse" for="c-41279336">[-]</label><label class="expand" for="c-41279336">[1 more]</label></div><br/><div class="children"><div class="content">An LLM takes a slice of data from the world, by nature it has to organize it in some such way, depending on how its trained, and the method of organizing it is hard-coded into the model. Therefore, all models will develop some sort of style, no matter what, since somebody, or a team of people, had to figure out a way to portion out a selection of data, and this problem is intractable.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="41277533" class="c"><input type="checkbox" id="c-41277533" checked=""/><div class="controls bullet"><span class="by">akira2501</span><span>|</span><a href="#41277654">prev</a><span>|</span><a href="#41277338">next</a><span>|</span><label class="collapse" for="c-41277533">[-]</label><label class="expand" for="c-41277533">[4 more]</label></div><br/><div class="children"><div class="content">Yes.  I can tell you about things that happened this morning.  Your language model cannot.</div><br/><div id="41279969" class="c"><input type="checkbox" id="c-41279969" checked=""/><div class="controls bullet"><span class="by">manuelmoreale</span><span>|</span><a href="#41277533">parent</a><span>|</span><a href="#41277338">next</a><span>|</span><label class="collapse" for="c-41279969">[-]</label><label class="expand" for="c-41279969">[3 more]</label></div><br/><div class="children"><div class="content">I can also invite you out for a coffee and your LLM can’t do that either–yet.</div><br/><div id="41280659" class="c"><input type="checkbox" id="c-41280659" checked=""/><div class="controls bullet"><span class="by">Squeeze2664</span><span>|</span><a href="#41277533">root</a><span>|</span><a href="#41279969">parent</a><span>|</span><a href="#41277338">next</a><span>|</span><label class="collapse" for="c-41280659">[-]</label><label class="expand" for="c-41280659">[2 more]</label></div><br/><div class="children"><div class="content">They&#x27;re perfectly capable of inviting you out for coffee. They just can&#x27;t show up yet.</div><br/><div id="41280679" class="c"><input type="checkbox" id="c-41280679" checked=""/><div class="controls bullet"><span class="by">fragmede</span><span>|</span><a href="#41277533">root</a><span>|</span><a href="#41280659">parent</a><span>|</span><a href="#41277338">next</a><span>|</span><label class="collapse" for="c-41280679">[-]</label><label class="expand" for="c-41280679">[1 more]</label></div><br/><div class="children"><div class="content">though, with web access and a credit card and the right information, you could probably get one to order a pizza to your house though.</div><br/></div></div></div></div></div></div></div></div><div id="41277338" class="c"><input type="checkbox" id="c-41277338" checked=""/><div class="controls bullet"><span class="by">silisili</span><span>|</span><a href="#41277533">prev</a><span>|</span><a href="#41280934">next</a><span>|</span><label class="collapse" for="c-41277338">[-]</label><label class="expand" for="c-41277338">[3 more]</label></div><br/><div class="children"><div class="content">Was mine broken?  One of my prompts was just &#x27;&gt;&#x27;.  So of course I guessed a random word.  The answer key showed I got it wrong, but showed the right answer inserted into a longer prompt.  Or is that how it&#x27;s supposed to work?</div><br/><div id="41277369" class="c"><input type="checkbox" id="c-41277369" checked=""/><div class="controls bullet"><span class="by">JoelEinbinder</span><span>|</span><a href="#41277338">parent</a><span>|</span><a href="#41280934">next</a><span>|</span><label class="collapse" for="c-41277369">[-]</label><label class="expand" for="c-41277369">[2 more]</label></div><br/><div class="children"><div class="content">That isn&#x27;t how it&#x27;s supposed to work. I mean sometimes you get a supper annoying prompt like &quot;&gt;&quot;, but if you guess the right answer it should give you the point. I just checked the two prompts like that, and they seem to work for me.</div><br/><div id="41277400" class="c"><input type="checkbox" id="c-41277400" checked=""/><div class="controls bullet"><span class="by">silisili</span><span>|</span><a href="#41277338">root</a><span>|</span><a href="#41277369">parent</a><span>|</span><a href="#41280934">next</a><span>|</span><label class="collapse" for="c-41277400">[-]</label><label class="expand" for="c-41277400">[1 more]</label></div><br/><div class="children"><div class="content">Right, I got the answer incorrect, so that part worked right.  I just wasn&#x27;t sure if the question was intentionally clipped and missing that context, but it does sound intentional.  I guess I make a poor LLM!</div><br/></div></div></div></div></div></div><div id="41280934" class="c"><input type="checkbox" id="c-41280934" checked=""/><div class="controls bullet"><span class="by">globular-toast</span><span>|</span><a href="#41277338">prev</a><span>|</span><a href="#41277827">next</a><span>|</span><label class="collapse" for="c-41280934">[-]</label><label class="expand" for="c-41280934">[2 more]</label></div><br/><div class="children"><div class="content">Everything I picked was grammatically correct, so I don&#x27;t see the point. Is the point of a &quot;language model&quot; just to recall people&#x27;s comments from the internet now?</div><br/><div id="41280988" class="c"><input type="checkbox" id="c-41280988" checked=""/><div class="controls bullet"><span class="by">tmalsburg2</span><span>|</span><a href="#41280934">parent</a><span>|</span><a href="#41277827">next</a><span>|</span><label class="collapse" for="c-41280988">[-]</label><label class="expand" for="c-41280988">[1 more]</label></div><br/><div class="children"><div class="content">Always has been.</div><br/></div></div></div></div><div id="41277827" class="c"><input type="checkbox" id="c-41277827" checked=""/><div class="controls bullet"><span class="by">shakna</span><span>|</span><a href="#41280934">prev</a><span>|</span><a href="#41279675">next</a><span>|</span><label class="collapse" for="c-41277827">[-]</label><label class="expand" for="c-41277827">[1 more]</label></div><br/><div class="children"><div class="content">So... If I picked the same results, in the same timeframe... And I don&#x27;t think glue should go on pizza... Does that mean LLMs are completely useless to me?</div><br/></div></div><div id="41279675" class="c"><input type="checkbox" id="c-41279675" checked=""/><div class="controls bullet"><span class="by">rlt</span><span>|</span><a href="#41277827">prev</a><span>|</span><a href="#41277374">next</a><span>|</span><label class="collapse" for="c-41279675">[-]</label><label class="expand" for="c-41279675">[2 more]</label></div><br/><div class="children"><div class="content">Is this with the “temperature” parameter set to 0? Most LLM chatbots set it to something higher.<p>It would be interesting to try varying it, as well as the seed.</div><br/><div id="41279896" class="c"><input type="checkbox" id="c-41279896" checked=""/><div class="controls bullet"><span class="by">JoelEinbinder</span><span>|</span><a href="#41279675">parent</a><span>|</span><a href="#41277374">next</a><span>|</span><label class="collapse" for="c-41279896">[-]</label><label class="expand" for="c-41279896">[1 more]</label></div><br/><div class="children"><div class="content">Temperature doesn&#x27;t play a role here, because the LLM is not being sampled (other than to generate the candidate answers). Instead the answer the llm picks is decided by computing the complexity for the full prompt + answer string.</div><br/></div></div></div></div><div id="41277374" class="c"><input type="checkbox" id="c-41277374" checked=""/><div class="controls bullet"><span class="by">wesselbindt</span><span>|</span><a href="#41279675">prev</a><span>|</span><a href="#41278874">next</a><span>|</span><label class="collapse" for="c-41277374">[-]</label><label class="expand" for="c-41277374">[1 more]</label></div><br/><div class="children"><div class="content">I like the website, but it could be a bit more explicit about the point it&#x27;s trying to make. Given that a lot of people tend to think of LLM as somehow a thinking entity rather than a statistical model for guessing the most likely next word, most will probably look at these questions and think the website is broken.</div><br/></div></div><div id="41278874" class="c"><input type="checkbox" id="c-41278874" checked=""/><div class="controls bullet"><span class="by">nick3443</span><span>|</span><a href="#41277374">prev</a><span>|</span><a href="#41277725">next</a><span>|</span><label class="collapse" for="c-41278874">[-]</label><label class="expand" for="c-41278874">[1 more]</label></div><br/><div class="children"><div class="content">This isn&#x27;t really the challenge (loss function) that language models are trained on. It&#x27;s not a simple next-word challenge, they get more context, see how BERT was trained as a reference.</div><br/></div></div><div id="41277725" class="c"><input type="checkbox" id="c-41277725" checked=""/><div class="controls bullet"><span class="by">xanderlewis</span><span>|</span><a href="#41278874">prev</a><span>|</span><a href="#41277465">next</a><span>|</span><label class="collapse" for="c-41277725">[-]</label><label class="expand" for="c-41277725">[1 more]</label></div><br/><div class="children"><div class="content">I feel like I recognise the comment about tensors from HN a few days ago, haha.</div><br/></div></div><div id="41277465" class="c"><input type="checkbox" id="c-41277465" checked=""/><div class="controls bullet"><span class="by">TacticalCoder</span><span>|</span><a href="#41277725">prev</a><span>|</span><a href="#41277344">next</a><span>|</span><label class="collapse" for="c-41277465">[-]</label><label class="expand" for="c-41277465">[1 more]</label></div><br/><div class="children"><div class="content">My computer can compute 573034897183834790x3019487439184798 in less than a millisecond. Doesn&#x27;t make it smarter than me.</div><br/></div></div><div id="41277344" class="c"><input type="checkbox" id="c-41277344" checked=""/><div class="controls bullet"><span class="by">mjcurl</span><span>|</span><a href="#41277465">prev</a><span>|</span><a href="#41277507">next</a><span>|</span><label class="collapse" for="c-41277344">[-]</label><label class="expand" for="c-41277344">[3 more]</label></div><br/><div class="children"><div class="content">5&#x2F;15, so the same as choosing the most common word.<p>I think I did worse when the prompt is shorter. It just becomes a guessing game then and I find myself thinking more like a language model.</div><br/><div id="41277990" class="c"><input type="checkbox" id="c-41277990" checked=""/><div class="controls bullet"><span class="by">dalton01</span><span>|</span><a href="#41277344">parent</a><span>|</span><a href="#41277504">next</a><span>|</span><label class="collapse" for="c-41277990">[-]</label><label class="expand" for="c-41277990">[1 more]</label></div><br/><div class="children"><div class="content">It says choosing the most common word was just 1&#x2F;5 (and their best LLM was 4&#x2F;15)</div><br/></div></div><div id="41277504" class="c"><input type="checkbox" id="c-41277504" checked=""/><div class="controls bullet"><span class="by">toxik</span><span>|</span><a href="#41277344">parent</a><span>|</span><a href="#41277990">prev</a><span>|</span><a href="#41277507">next</a><span>|</span><label class="collapse" for="c-41277504">[-]</label><label class="expand" for="c-41277504">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, it should be sentences that have low next token distribution entropy. Where an LLM is sure what the next word is. I bet people do real well on those too. By the way, I also had 5&#x2F;15.</div><br/></div></div></div></div><div id="41277507" class="c"><input type="checkbox" id="c-41277507" checked=""/><div class="controls bullet"><span class="by">nyrikki</span><span>|</span><a href="#41277344">prev</a><span>|</span><a href="#41277693">next</a><span>|</span><label class="collapse" for="c-41277507">[-]</label><label class="expand" for="c-41277507">[1 more]</label></div><br/><div class="children"><div class="content">7&#x2F;10 This is more about set shattering than &#x27;smarts&#x27;<p>LLMs are effectively DAGs, they literally have to unroll infinite possibilities in the absence of larger context into finite options.<p>You can unroll and cyclic graph into a dag, but you constrict the solution space.<p>Take the &#x27;spoken&#x27;: sentence:<p>&quot;I never said she stole my money&quot;<p>And say it multiple times with emphasis on each word and notice how the meaning changes.<p>That is text being a forgetful functor.<p>As you can describe PAC learning, or as compression, which is exactly equivalent to the finite set shattering above, you can assign probabilities to next tokans.<p>But that is existential quantification, limited based on your corpus based on pattern matching and finding.<p>I guess if &quot;Smart&quot; is defined as pattern matching and finding it would apply.<p>But this is exactly why there was a split between symbolic AI, which targeted universal quantification and statistical learning, which targets existential quantification.<p>Even if ML had never been invented, I would assume that there were mechanical methods to stack rank next tokens from a corpus.<p>This isn&#x27;t a case of &#x27;smarter&#x27;, but just different.  If that difference is meaningful depends on context.</div><br/></div></div><div id="41277693" class="c"><input type="checkbox" id="c-41277693" checked=""/><div class="controls bullet"><span class="by">zoklet-enjoyer</span><span>|</span><a href="#41277507">prev</a><span>|</span><label class="collapse" for="c-41277693">[-]</label><label class="expand" for="c-41277693">[2 more]</label></div><br/><div class="children"><div class="content">You scored 6&#x2F;15. The best language model, gpt-4o, scored 6&#x2F;15. The unigram model, which just picks the most common word without reading the prompt, scored 2&#x2F;15.<p>Keep in mind that you took 204 seconds to answer the questions, whereas the slowest language model was llama-3-8b taking only 10 seconds!</div><br/><div id="41278272" class="c"><input type="checkbox" id="c-41278272" checked=""/><div class="controls bullet"><span class="by">e12e</span><span>|</span><a href="#41277693">parent</a><span>|</span><label class="collapse" for="c-41278272">[-]</label><label class="expand" for="c-41278272">[1 more]</label></div><br/><div class="children"><div class="content"><p><pre><code>    you: 8&#x2F;15
    gpt-4o: 2&#x2F;15
    gpt-4: 4&#x2F;15
    gpt-4o-mini: 4&#x2F;15
    llama-2-7b: 5&#x2F;15
    llama-3-8b: 5&#x2F;15
    mistral-7b: 6&#x2F;15
    unigram: 5&#x2F;15
</code></pre>
&gt; You scored 8&#x2F;15. The best language model, mistral-7b, scored 6&#x2F;15. The unigram model, which just picks the most common word without reading the prompt, scored 5&#x2F;15.<p>(In I think 120 seconds - didn&#x27;t copy that part).<p>Interesting that results differ this much between runs (for the LLMs).<p>Surely someone did better than me on their first run?<p>Ed: I wonder if the human scores correlate with age of hn account?</div><br/></div></div></div></div></div></div></div></div></div></body></html>