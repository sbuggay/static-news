<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1713089488691" as="style"/><link rel="stylesheet" href="styles.css?v=1713089488691"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.quantamagazine.org/how-do-machines-grok-data-20240412/">How do machines ‘grok’ data?</a> <span class="domain">(<a href="https://www.quantamagazine.org">www.quantamagazine.org</a>)</span></div><div class="subtext"><span>nsoonhui</span> | <span>3 comments</span></div><br/><div><div id="40029841" class="c"><input type="checkbox" id="c-40029841" checked=""/><div class="controls bullet"><span class="by">mjburgess</span><span>|</span><a href="#40029045">next</a><span>|</span><label class="collapse" for="c-40029841">[-]</label><label class="expand" for="c-40029841">[1 more]</label></div><br/><div class="children"><div class="content">NNs (indeed, all statistical fitting algs) have no relevant properties here: properties derive just from the structure of the dataset. Here (<a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2201.02177" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2201.02177</a>) NNs are trained on a &#x27;complete world&#x27; problem, ie., modulo arithmetic where the whole outcome space is trivial in size and abstract with complete information.<p>Why should NNs eventually find a representation of this tiny, abstract, full-representable outcome space after an arbitrary amount of training time? Well it will do so, eventually, if this outcome space can be fully represented by sequences of conditional probabilities.<p>There is nothing more to this &#x27;discovery&#x27; than some trivial abstract mathematical spaces can be represented as conditional probability structures. Is this even a discovery?<p>One has to imagine this deception is perpetrated because the peddlers of such systems want to impart the problem structure to properties of NNs in general, and thereby say, &quot;well, if you train NNs on face shapes, phrenology becomes possible!&quot;. ie., as a way of whitewashing their broken half-baked generative AI systems where the problem domain isnt arithmetic mod 97</div><br/></div></div><div id="40029045" class="c"><input type="checkbox" id="c-40029045" checked=""/><div class="controls bullet"><span class="by">verisimi</span><span>|</span><a href="#40029841">prev</a><span>|</span><label class="collapse" for="c-40029045">[-]</label><label class="expand" for="c-40029045">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Automatic testing revealed this unexpected accuracy to the rest of the team, and they soon realized that the network had found clever ways of arranging the numbers a and b. Internally, the network represents the numbers in some high-dimensional space, but when the researchers projected these numbers down to 2D space and mapped them, the numbers formed a circle.</div><br/></div></div></div></div></div></div></div></body></html>