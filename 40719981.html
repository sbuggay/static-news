<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1718787673584" as="style"/><link rel="stylesheet" href="styles.css?v=1718787673584"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://arxiv.org/abs/2406.11717">Refusal in language models is mediated by a single direction</a> <span class="domain">(<a href="https://arxiv.org">arxiv.org</a>)</span></div><div class="subtext"><span>Tomte</span> | <span>32 comments</span></div><br/><div><div id="40722890" class="c"><input type="checkbox" id="c-40722890" checked=""/><div class="controls bullet"><span class="by">eigenvalue</span><span>|</span><a href="#40726029">next</a><span>|</span><label class="collapse" for="c-40722890">[-]</label><label class="expand" for="c-40722890">[20 more]</label></div><br/><div class="children"><div class="content">Now that this technique is known, I wonder if there will be an arm’s race to try to “distribute” the refusal tendency across as many different directions in the embedding space as possible so that it can’t be easily offset without reducing the quality of the inferences so much that it’s not worth it.</div><br/><div id="40723714" class="c"><input type="checkbox" id="c-40723714" checked=""/><div class="controls bullet"><span class="by">pizza</span><span>|</span><a href="#40722890">parent</a><span>|</span><a href="#40723854">next</a><span>|</span><label class="collapse" for="c-40723714">[-]</label><label class="expand" for="c-40723714">[3 more]</label></div><br/><div class="children"><div class="content">You&#x27;d have to make refusal a high rank subspace, and that seems like it could be quite difficult. One alternative approach I&#x27;ve seen is to make refusal behavior more likely to just output the end-of-speech token.</div><br/><div id="40723942" class="c"><input type="checkbox" id="c-40723942" checked=""/><div class="controls bullet"><span class="by">eigenvalue</span><span>|</span><a href="#40722890">root</a><span>|</span><a href="#40723714">parent</a><span>|</span><a href="#40723854">next</a><span>|</span><label class="collapse" for="c-40723942">[-]</label><label class="expand" for="c-40723942">[2 more]</label></div><br/><div class="children"><div class="content">There are ways to do that from linear algebra, like orthogonalization processes (e.g., Gram-Schmidt process) followed by basis expansion. Or random projections can also be used in a similar way. And I’m sure there are much fancier techniques that draw upon higher math (like Grassmannians or Teichmuller mappings).</div><br/><div id="40724832" class="c"><input type="checkbox" id="c-40724832" checked=""/><div class="controls bullet"><span class="by">ziofill</span><span>|</span><a href="#40722890">root</a><span>|</span><a href="#40723942">parent</a><span>|</span><a href="#40723854">next</a><span>|</span><label class="collapse" for="c-40724832">[-]</label><label class="expand" for="c-40724832">[1 more]</label></div><br/><div class="children"><div class="content">Would you be able to share some links to these techniques? They sound related to something I’m working on but in an entirely different field.</div><br/></div></div></div></div></div></div><div id="40723854" class="c"><input type="checkbox" id="c-40723854" checked=""/><div class="controls bullet"><span class="by">jelly</span><span>|</span><a href="#40722890">parent</a><span>|</span><a href="#40723714">prev</a><span>|</span><a href="#40722968">next</a><span>|</span><label class="collapse" for="c-40723854">[-]</label><label class="expand" for="c-40723854">[1 more]</label></div><br/><div class="children"><div class="content">Perhaps LLM creators will start using ablation as the censorship method instead of a refusal</div><br/></div></div><div id="40722968" class="c"><input type="checkbox" id="c-40722968" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#40722890">parent</a><span>|</span><a href="#40723854">prev</a><span>|</span><a href="#40726029">next</a><span>|</span><label class="collapse" for="c-40722968">[-]</label><label class="expand" for="c-40722968">[15 more]</label></div><br/><div class="children"><div class="content">IMHO, probably not, reasoning:<p>It&#x27;s only worthwhile if you&#x27;re distributing weights.<p>If you&#x27;re distributing weights, people can train right over them anyway (ex. the waifu of the hour is based on Mistral...called...Moistral...<i>shudders</i>)<p>Abliteration hasn&#x27;t get significant traction in the handing-out-weights space. That surprised me because of the amount of avowed not-waifu desire for &quot;uncensored&quot; models.<p>It didn&#x27;t surprise me in that, the volume and ferocity of takes on &quot;lobotomizing&quot; did not match my experience with base LLMs at BigCo. There&#x27;s not a ton of difference between a base LLM and the &quot;censored&quot; ones.<p>Trying the abliterated ones makes that embarrassingly clear. You&#x27;re better off tuning on erotic fanfic for your waifu than using an abliterated one, truth is, there&#x27;s nothing hidden.</div><br/><div id="40725286" class="c"><input type="checkbox" id="c-40725286" checked=""/><div class="controls bullet"><span class="by">zozbot234</span><span>|</span><a href="#40722890">root</a><span>|</span><a href="#40722968">parent</a><span>|</span><a href="#40723031">next</a><span>|</span><label class="collapse" for="c-40725286">[-]</label><label class="expand" for="c-40725286">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Trying the abliterated ones makes that embarrassingly clear. You&#x27;re better off tuning on erotic fanfic for your waifu than using an abliterated one<p>These are two very different things. Ablation gets used to remove the LLM&#x27;s behavior of refusing to answer, but obviously it does not otherwise affect the LLM&#x27;s replies, much less increase the LLM&#x27;s knowledge or suitability to &quot;forbidden&quot; topics since that will depend on what it was trained on, and forbidden topics tend not to be heavily featured in the training process.  Instead, the models tend to confabulate even more than usual as if clumsily trying to fill the gaps in their training.  If anything, ablation will more easily let us test &quot;what an LLM would say if it was jailbroken&quot;, which will likely help mitigate the oft-expressed concern that a &quot;jailbroken&quot; model might say something dangerous.  (Of course a random confabulation about the wrong topic can also be quite dangerous, but confabulations in general are a really hard problem to address.)</div><br/></div></div><div id="40723031" class="c"><input type="checkbox" id="c-40723031" checked=""/><div class="controls bullet"><span class="by">behnamoh</span><span>|</span><a href="#40722890">root</a><span>|</span><a href="#40722968">parent</a><span>|</span><a href="#40725286">prev</a><span>|</span><a href="#40723494">next</a><span>|</span><label class="collapse" for="c-40723031">[-]</label><label class="expand" for="c-40723031">[9 more]</label></div><br/><div class="children"><div class="content">&gt; There&#x27;s not a ton of difference between a base LLM and the &quot;censored&quot; ones.<p>Actually, there is a lot of difference between base and censored models in terms of creative capacities. See the shocking results of this paper for instance: <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2406.05587" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2406.05587</a><p>The censorship literally obliterates the creativity of LLMs.</div><br/><div id="40723072" class="c"><input type="checkbox" id="c-40723072" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#40722890">root</a><span>|</span><a href="#40723031">parent</a><span>|</span><a href="#40723494">next</a><span>|</span><label class="collapse" for="c-40723072">[-]</label><label class="expand" for="c-40723072">[8 more]</label></div><br/><div class="children"><div class="content">&quot;RLHF significantly reduces to eliminates long tail log probs&quot;<p>shares no words with &quot;Shocking result: model creativity is obliterated by censorship&quot;<p>Honestly, swear to God, the words aren&#x27;t even in the same ballpark as what&#x27;s actually going on. RLHF is also the process that makes it something you can talk to instead of an autocompleter. Has nothing to do with the concept of censorship. We can tell by the abliteration models. I can tell because I&#x27;ve used massive base models.<p>I also think it&#x27;s fairly well demonstrated and accessible to train an LLM now, enough that if &quot;creativity was obliterated by censorship&quot;, someone would have made an uncensored one that demonstrated superior outputs. Wasn&#x27;t that Grok&#x27;s whole thing? It&#x27;ll even tell you how to make meth &#x2F; cocaine? And it&#x27;s nowhere near leaderboards.</div><br/><div id="40723249" class="c"><input type="checkbox" id="c-40723249" checked=""/><div class="controls bullet"><span class="by">behnamoh</span><span>|</span><a href="#40722890">root</a><span>|</span><a href="#40723072">parent</a><span>|</span><a href="#40723814">prev</a><span>|</span><a href="#40725428">next</a><span>|</span><label class="collapse" for="c-40723249">[-]</label><label class="expand" for="c-40723249">[3 more]</label></div><br/><div class="children"><div class="content">Did you even read the paper? It literally says how RLHF significantly reduces model creativity through three experiments.<p>&gt; I also think it&#x27;s fairly well demonstrated and accessible to train an LLM now, enough that if &quot;creativity was obliterated by censorship&quot;, someone would have made an uncensored one that demonstrated superior outputs.<p>No need to to that when we have base models of llama, Mistral, etc.<p>&gt; RLHF is also the process that makes it something you can talk to instead of an autocompleter.<p>Not really. It aligns the model. What you&#x27;re talking about is the SFT process done before RLHF where you finetune the model to behave like a conversational AI.</div><br/><div id="40723584" class="c"><input type="checkbox" id="c-40723584" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#40722890">root</a><span>|</span><a href="#40723249">parent</a><span>|</span><a href="#40725428">next</a><span>|</span><label class="collapse" for="c-40723584">[-]</label><label class="expand" for="c-40723584">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Did you even read the paper?<p>?! Are we in middle school? If so, I&#x27;m rubber you&#x27;re glue, whatever you say... (to wit, I quoted the paper to you to demonstrate it wasn&#x27;t as the claim, i.e. &quot;exhibit lower entropy in token predictions&quot; !=  &quot;creativity is obliterated due to censorship&quot;)<p>&gt;  It literally says how RLHF significantly reduces model creativity through three experiments.<p>Ah, I see now. :) I don&#x27;t take it personally. I&#x27;m old enough to smile at aggro behavior kicking up sand in front of a step back to the bailey.<p>&gt; No need to to that when we have base models of llama, Mistral, etc.<p>They&#x27;re RLHF&#x27;d&#x2F;censorship&#x27;d too. &quot;Base model&quot; is a colloquialism that used to mean &quot;no RLHF, just straight sipping from scraped web pages.&quot; Now it means &quot;the last round wasn&#x27;t explicitly chat&quot;. I am using it in the &quot;sipping from straight scraped web pages&quot; sense.<p>&gt; Not really<p>Yes, really. Btw, what does &quot;It aligns the model&quot; mean to you at this point in your post? RLHF was just censorship that obliterates creativity?<p>&gt; &quot;[intentionally left blank]&quot;<p>There is 0 discussion of any of the practical effects I mentioned as rope for you to walk down from your strong claim, ex. abliteration, uncensored models, etc.<p>&gt; (not actually in your post at all!)<p>Is it possible your account got hacked? There&#x27;s someone else using it to post that no one should even release models anymore because they&#x27;re all the same and use the same techniques.[1][2] That&#x27;s hard to square with someone who thinks they&#x27;re all having their creativity obliterated due to censorship.<p>[1] <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=40599838">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=40599838</a>
[2] <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=40600136">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=40600136</a></div><br/><div id="40725491" class="c"><input type="checkbox" id="c-40725491" checked=""/><div class="controls bullet"><span class="by">osmarks</span><span>|</span><a href="#40722890">root</a><span>|</span><a href="#40723584">parent</a><span>|</span><a href="#40725428">next</a><span>|</span><label class="collapse" for="c-40725491">[-]</label><label class="expand" for="c-40725491">[1 more]</label></div><br/><div class="children"><div class="content">Mistral and Meta release &quot;instruct&quot; (RLHF) and not-instruct models. The non-instruct ones are in fact non-RLHF, pretraining-only ones (though they probably have ChatGPT-ish text in the dataset nowadays, and Meta might have done some extra training on evals...).</div><br/></div></div></div></div></div></div><div id="40725428" class="c"><input type="checkbox" id="c-40725428" checked=""/><div class="controls bullet"><span class="by">lynx23</span><span>|</span><a href="#40722890">root</a><span>|</span><a href="#40723072">parent</a><span>|</span><a href="#40723249">prev</a><span>|</span><a href="#40723494">next</a><span>|</span><label class="collapse" for="c-40725428">[-]</label><label class="expand" for="c-40725428">[3 more]</label></div><br/><div class="children"><div class="content">Its funny how someone using the phrase &quot;swear to god&quot; can lecture someone else about their use of words and basically, between the lines, asking for more &quot;realism&quot;...<p>In my book, <i>nobody</i> invoking god in a public discussion should be even remotely taken seriously.</div><br/><div id="40725504" class="c"><input type="checkbox" id="c-40725504" checked=""/><div class="controls bullet"><span class="by">QuesnayJr</span><span>|</span><a href="#40722890">root</a><span>|</span><a href="#40725428">parent</a><span>|</span><a href="#40723494">next</a><span>|</span><label class="collapse" for="c-40725504">[-]</label><label class="expand" for="c-40725504">[2 more]</label></div><br/><div class="children"><div class="content">I swear to God that Hacker News is the only place on the entire internet where you could find someone who takes a stock rhetorical phrase like &quot;swear to god&quot; literally.</div><br/><div id="40725633" class="c"><input type="checkbox" id="c-40725633" checked=""/><div class="controls bullet"><span class="by">zozbot234</span><span>|</span><a href="#40722890">root</a><span>|</span><a href="#40725504">parent</a><span>|</span><a href="#40723494">next</a><span>|</span><label class="collapse" for="c-40725633">[-]</label><label class="expand" for="c-40725633">[1 more]</label></div><br/><div class="children"><div class="content">I swear to $DEITY that this is the most entertaining subthread i&#x27;ve seen in a while on HN.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="40723494" class="c"><input type="checkbox" id="c-40723494" checked=""/><div class="controls bullet"><span class="by">thelastparadise</span><span>|</span><a href="#40722890">root</a><span>|</span><a href="#40722968">parent</a><span>|</span><a href="#40723031">prev</a><span>|</span><a href="#40726029">next</a><span>|</span><label class="collapse" for="c-40723494">[-]</label><label class="expand" for="c-40723494">[4 more]</label></div><br/><div class="children"><div class="content">Moistral?<p>There&#x27;s no way that can be real...<p>Edit: what is a waifu???</div><br/><div id="40726065" class="c"><input type="checkbox" id="c-40726065" checked=""/><div class="controls bullet"><span class="by">pjc50</span><span>|</span><a href="#40722890">root</a><span>|</span><a href="#40723494">parent</a><span>|</span><a href="#40725631">next</a><span>|</span><label class="collapse" for="c-40726065">[-]</label><label class="expand" for="c-40726065">[1 more]</label></div><br/><div class="children"><div class="content">No way it can <i>not</i> be real. Any technology unleashed on the wider internet is going to be used for this, and companies spend a lot of effort on &quot;brand safety&quot; to try not to get pulled into that too much. Why do you think the models are censored in the first place?<p>One of the early uses for NN-style AI image content aware fill was a tool called &quot;waifu2x&quot;, for upscaling anime from VHS.</div><br/></div></div><div id="40725631" class="c"><input type="checkbox" id="c-40725631" checked=""/><div class="controls bullet"><span class="by">QuesnayJr</span><span>|</span><a href="#40722890">root</a><span>|</span><a href="#40723494">parent</a><span>|</span><a href="#40726065">prev</a><span>|</span><a href="#40723717">next</a><span>|</span><label class="collapse" for="c-40725631">[-]</label><label class="expand" for="c-40725631">[1 more]</label></div><br/><div class="children"><div class="content">&quot;Waifu&quot; is &quot;wife&quot; if written in katakana.  It is jokingly used as a name for the fictional female characters in manga and anime that are designed to appeal to male viewers.  Some people wish the fiction wasn&#x27;t so fictional.</div><br/></div></div><div id="40723717" class="c"><input type="checkbox" id="c-40723717" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#40722890">root</a><span>|</span><a href="#40723494">parent</a><span>|</span><a href="#40725631">prev</a><span>|</span><a href="#40726029">next</a><span>|</span><label class="collapse" for="c-40723717">[-]</label><label class="expand" for="c-40723717">[1 more]</label></div><br/><div class="children"><div class="content">My sweet summer child, I weep to burden you with this, turn back:<p>I bet if you looked up waifu&#x27;s definition it&#x27;d have a vaguer meaning. In local LLM context, there&#x27;s a sizable community for &quot;virtual girlfriend AI&quot;, once you start hearing things like &quot;SillyTavern&quot; you&#x27;re over in the community. Think applications designed around local LLMs and the use case of having pre-canned prompts to &quot;boot up&quot; a girlfriend persona.<p>For what it&#x27;s worth, I&#x27;m being glib, so it may seem I&#x27;m linking it to erotica for giggles. c.f. graphics used on official GitHub, <a href="https:&#x2F;&#x2F;github.com&#x2F;SillyTavern&#x2F;SillyTavern">https:&#x2F;&#x2F;github.com&#x2F;SillyTavern&#x2F;SillyTavern</a>, and language at <a href="https:&#x2F;&#x2F;sillytavernai.com&#x2F;" rel="nofollow">https:&#x2F;&#x2F;sillytavernai.com&#x2F;</a> like [1] and [2]<p>[1] &quot;We recommend using our sister site: <a href="https:&#x2F;&#x2F;aicharactercards.com" rel="nofollow">https:&#x2F;&#x2F;aicharactercards.com</a>. It is a moderated character card repo. All cards go through a moderation process to make sure there are no overly inappropriate, illegal or scam like cards. NSFW cards are allowed so long as all characters are above the age of majority.&quot;<p>[2] Easy to use prompt fields such as main prompts, NSFW prompts and Jailbreak prompts that let you steer the chat in any way you desire</div><br/></div></div></div></div></div></div></div></div><div id="40726029" class="c"><input type="checkbox" id="c-40726029" checked=""/><div class="controls bullet"><span class="by">luke-stanley</span><span>|</span><a href="#40722890">prev</a><span>|</span><a href="#40723131">next</a><span>|</span><label class="collapse" for="c-40726029">[-]</label><label class="expand" for="c-40726029">[1 more]</label></div><br/><div class="children"><div class="content">Related comments: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=40242939">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=40242939</a>
I pointed out that you can use llama.cpp to do something like this with it&#x27;s Classifier-Free Guidance (CFG) feature (may be easier than using Pytorch or such).</div><br/></div></div><div id="40723131" class="c"><input type="checkbox" id="c-40723131" checked=""/><div class="controls bullet"><span class="by">morningsam</span><span>|</span><a href="#40726029">prev</a><span>|</span><a href="#40722818">next</a><span>|</span><label class="collapse" for="c-40723131">[-]</label><label class="expand" for="c-40723131">[1 more]</label></div><br/><div class="children"><div class="content">Same thing in LessWrong post form from back in April: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=40242939">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=40242939</a></div><br/></div></div><div id="40722818" class="c"><input type="checkbox" id="c-40722818" checked=""/><div class="controls bullet"><span class="by">wavemode</span><span>|</span><a href="#40723131">prev</a><span>|</span><a href="#40724422">next</a><span>|</span><label class="collapse" for="c-40722818">[-]</label><label class="expand" for="c-40722818">[3 more]</label></div><br/><div class="children"><div class="content">Related recent HN submission (Uncensor any LLM with abliteration): <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=40665721">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=40665721</a></div><br/><div id="40722840" class="c"><input type="checkbox" id="c-40722840" checked=""/><div class="controls bullet"><span class="by">schoen</span><span>|</span><a href="#40722818">parent</a><span>|</span><a href="#40723463">next</a><span>|</span><label class="collapse" for="c-40722840">[-]</label><label class="expand" for="c-40722840">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t know the exact connection between the two, but that article cites an article which is described as a preview of this paper. So I guess it was working with a summary of this paper&#x27;s contributions.</div><br/></div></div><div id="40723463" class="c"><input type="checkbox" id="c-40723463" checked=""/><div class="controls bullet"><span class="by">Natsu</span><span>|</span><a href="#40722818">parent</a><span>|</span><a href="#40722840">prev</a><span>|</span><a href="#40724422">next</a><span>|</span><label class="collapse" for="c-40723463">[-]</label><label class="expand" for="c-40723463">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m surprised no one has yet labeled this direction as the &quot;axis of evil.&quot;</div><br/></div></div></div></div><div id="40724422" class="c"><input type="checkbox" id="c-40724422" checked=""/><div class="controls bullet"><span class="by">groovity</span><span>|</span><a href="#40722818">prev</a><span>|</span><a href="#40724594">next</a><span>|</span><label class="collapse" for="c-40724422">[-]</label><label class="expand" for="c-40724422">[4 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not surprising.  LLMs feel like a bunch of different competing predictors all wrapped into one.<p>Have a conversation with an LLM about what it thinks of trans women being on straight men&#x27;s dating app queues.<p>It&#x27;ll say all the usual things &quot;gender is an identity&quot;, &quot;trans women are real women&quot;, etc.<p>But then point out that sexuality is based on biological sex, and it&#x27;ll switch to 100% agreeing with you.<p>The opinion and tone of their text moves with the wind.</div><br/></div></div><div id="40724594" class="c"><input type="checkbox" id="c-40724594" checked=""/><div class="controls bullet"><span class="by">akasakahakada</span><span>|</span><a href="#40724422">prev</a><span>|</span><label class="collapse" for="c-40724594">[-]</label><label class="expand" for="c-40724594">[2 more]</label></div><br/><div class="children"><div class="content">LLM search engine coupled with so called &quot;saftefy&quot;, will this lead us to somewhere as dystopian as described by literature?<p>Like,<p>Me: Hey library, tell me how insects make love.<p>Library: Sorry I can&#x27;t answer that.  Knowledge of insects&#x27; intercourse can be extrapolated into human&#x27;s. To protect human from AIDS, I cannot tell you that.</div><br/><div id="40725896" class="c"><input type="checkbox" id="c-40725896" checked=""/><div class="controls bullet"><span class="by">thaumasiotes</span><span>|</span><a href="#40724594">parent</a><span>|</span><label class="collapse" for="c-40725896">[-]</label><label class="expand" for="c-40725896">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Knowledge of insects&#x27; intercourse can be extrapolated into human&#x27;s.<p>That might be difficult. Insects are a wide field.<p>For example, female bedbugs have no genitalia. Instead, the male&#x27;s penis pierces the female&#x27;s exoskeleton wherever happens to be convenient, in a procedure known formally as &quot;traumatic insemination&quot;.</div><br/></div></div></div></div></div></div></div></div></div></body></html>