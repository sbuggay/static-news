<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1694250058644" as="style"/><link rel="stylesheet" href="styles.css?v=1694250058644"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://course.spacy.io/en/">Advanced NLP with SpaCy</a> <span class="domain">(<a href="https://course.spacy.io">course.spacy.io</a>)</span></div><div class="subtext"><span>auraham</span> | <span>12 comments</span></div><br/><div><div id="37442956" class="c"><input type="checkbox" id="c-37442956" checked=""/><div class="controls bullet"><span class="by">tomohelix</span><span>|</span><a href="#37442933">next</a><span>|</span><label class="collapse" for="c-37442956">[-]</label><label class="expand" for="c-37442956">[10 more]</label></div><br/><div class="children"><div class="content">No offense, but isn&#x27;t the NLP field effectively solved with the creation of LLMs, or at least for the majority of the tasks you would expect from an NLP application?<p>I am sure you can find some special areas or niches where traditional NLP approaches would outcompete a black box like LLMs. But with the LLMs becoming much more efficient now after quantization to the point you can run them locally, I think there is a good argument in saying simple NLP is basically solved.</div><br/><div id="37443313" class="c"><input type="checkbox" id="c-37443313" checked=""/><div class="controls bullet"><span class="by">roenxi</span><span>|</span><a href="#37442956">parent</a><span>|</span><a href="#37443462">next</a><span>|</span><label class="collapse" for="c-37443313">[-]</label><label class="expand" for="c-37443313">[2 more]</label></div><br/><div class="children"><div class="content">1) It is extremely rare for a field to ever &#x27;be solved&#x27;. There is still active research into how to multiply 2 numbers together. NLP is not anywhere close to solved.<p>2) LLMs have different trade-offs to fundamental techniques. Linear regression still gets lots of use despite there usually being a theoretically better method for any specific application. There will be parallels to that in NLP.<p>3) Isn&#x27;t the article talking about training things like LLM? It is right there - &quot;Chapter 4: Training a neural network model&quot;.</div><br/><div id="37443450" class="c"><input type="checkbox" id="c-37443450" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#37442956">root</a><span>|</span><a href="#37443313">parent</a><span>|</span><a href="#37443462">next</a><span>|</span><label class="collapse" for="c-37443450">[-]</label><label class="expand" for="c-37443450">[1 more]</label></div><br/><div class="children"><div class="content">Funny thing, you can get LLM+Code Interpreter to do your linear regression with sklearn, all orchestrated by the LLM. So LLM+toys &quot;can do&quot; linear regression, or any other library algorithm.<p>And I think I read in some paper that pure LLMs can do regression tasks in few shot mode. Maybe not as good as sklearn, but a decent result.</div><br/></div></div></div></div><div id="37443462" class="c"><input type="checkbox" id="c-37443462" checked=""/><div class="controls bullet"><span class="by">pharmakom</span><span>|</span><a href="#37442956">parent</a><span>|</span><a href="#37443313">prev</a><span>|</span><a href="#37443080">next</a><span>|</span><label class="collapse" for="c-37443462">[-]</label><label class="expand" for="c-37443462">[1 more]</label></div><br/><div class="children"><div class="content">We still use regex despite there being LLMs that can approximate this functionality<p>They have different trade offs  in the solution space.<p>I have no doubt that prompt engineering will eat into a bunch of work that was previously done using NLP though - particularly for prototyping.</div><br/></div></div><div id="37443080" class="c"><input type="checkbox" id="c-37443080" checked=""/><div class="controls bullet"><span class="by">cantdutchthis</span><span>|</span><a href="#37442956">parent</a><span>|</span><a href="#37443462">prev</a><span>|</span><a href="#37443339">next</a><span>|</span><label class="collapse" for="c-37443080">[-]</label><label class="expand" for="c-37443080">[2 more]</label></div><br/><div class="children"><div class="content">&gt; I think there is a good argument in saying simple NLP is basically solved<p>In my experience LLMs can get about 70-80% accuracy on a bunch of NER and text classification tasks if you give it a reasonable prompt. That&#x27;s not nothing and it&#x27;s something that you can get started with super quickly. But you&#x27;ll have slow responses and typically a 3rd party running the inference.<p>Annotating data yourself to about 2000-3000 examples, on the datasets that I ran my benchmarks on, may get you closer to 80-90%. You&#x27;ll typically also get fast inference that you can run on your own hardware no problem. By annotating the data myself I also like to think that I understand the problem much better as a consequence.<p>Don&#x27;t get me wrong. LLMs are cool and interesting ... but they don&#x27;t seem to replace old-school methods just yet.</div><br/><div id="37443264" class="c"><input type="checkbox" id="c-37443264" checked=""/><div class="controls bullet"><span class="by">mxkopy</span><span>|</span><a href="#37442956">root</a><span>|</span><a href="#37443080">parent</a><span>|</span><a href="#37443339">next</a><span>|</span><label class="collapse" for="c-37443264">[-]</label><label class="expand" for="c-37443264">[1 more]</label></div><br/><div class="children"><div class="content">I doubt LLMs will ever replace old-school methods precisely for this reason:<p>&gt; By annotating the data myself I also like to think that I understand the problem much better as a consequence.<p>I’m sure that once we peer into the black box, we’ll find just more refined old-school methods.</div><br/></div></div></div></div><div id="37443339" class="c"><input type="checkbox" id="c-37443339" checked=""/><div class="controls bullet"><span class="by">gattilorenz</span><span>|</span><a href="#37442956">parent</a><span>|</span><a href="#37443080">prev</a><span>|</span><a href="#37443094">next</a><span>|</span><label class="collapse" for="c-37443339">[-]</label><label class="expand" for="c-37443339">[1 more]</label></div><br/><div class="children"><div class="content">I don’t understand what it means to be “solved”. It’s like saying that “architecture is now solved”, “physics is solved”, or “programming is solved”.<p>It’s a field of science and&#x2F;or engineering, it’s not like we will ever run out of things to try&#x2F;build&#x2F;investigate. LLMs work… to a certain extent, with limitations and tradeoffs, and for some things. Would you spend days, money and Co2 to split a huge text corpus in sentences with a LLM, if a simpler program can do that just as well, there’s no need to find “the perfect prompt” (and hope that the LLM doesn’t forget one sentence, adds something inbetween, etc etc) and it gets done in three hours?</div><br/></div></div><div id="37443094" class="c"><input type="checkbox" id="c-37443094" checked=""/><div class="controls bullet"><span class="by">hnhg</span><span>|</span><a href="#37442956">parent</a><span>|</span><a href="#37443339">prev</a><span>|</span><a href="#37443371">next</a><span>|</span><label class="collapse" for="c-37443094">[-]</label><label class="expand" for="c-37443094">[1 more]</label></div><br/><div class="children"><div class="content">I have wondered this but Spacy seem to be about delivering additional value on top of the LLMs. Take a look here: <a href="https:&#x2F;&#x2F;spacy.io&#x2F;usage&#x2F;large-language-models" rel="nofollow noreferrer">https:&#x2F;&#x2F;spacy.io&#x2F;usage&#x2F;large-language-models</a></div><br/></div></div><div id="37443371" class="c"><input type="checkbox" id="c-37443371" checked=""/><div class="controls bullet"><span class="by">globular-toast</span><span>|</span><a href="#37442956">parent</a><span>|</span><a href="#37443094">prev</a><span>|</span><a href="#37443019">next</a><span>|</span><label class="collapse" for="c-37443371">[-]</label><label class="expand" for="c-37443371">[1 more]</label></div><br/><div class="children"><div class="content">Remember when neural nets were invented then forgotten about for decades because machine learning was solved by support vector machines etc?</div><br/></div></div><div id="37443019" class="c"><input type="checkbox" id="c-37443019" checked=""/><div class="controls bullet"><span class="by">politelemon</span><span>|</span><a href="#37442956">parent</a><span>|</span><a href="#37443371">prev</a><span>|</span><a href="#37442933">next</a><span>|</span><label class="collapse" for="c-37443019">[-]</label><label class="expand" for="c-37443019">[1 more]</label></div><br/><div class="children"><div class="content">At least for those of us unfamiliar with the field, LLMs are an easy way of getting the task done. The only thing worth noting I suppose is that the most effective ones are behind paywalls.<p>In some cases though you may want the NLP task to be run locally - you want it to be free, and should not require excessive resources - for those cases libraries like Spacy and NLTK make sense. Yes there are projects like llama.cpp and friends, but it&#x27;s a fast moving field and they aren&#x27;t suited for production applications yet, and even then require high end hardware setups which not everyone will necessarily be running in.</div><br/></div></div></div></div><div id="37442933" class="c"><input type="checkbox" id="c-37442933" checked=""/><div class="controls bullet"><span class="by">dchia</span><span>|</span><a href="#37442956">prev</a><span>|</span><label class="collapse" for="c-37442933">[-]</label><label class="expand" for="c-37442933">[1 more]</label></div><br/><div class="children"><div class="content">old but gold</div><br/></div></div></div></div></div></div></div></body></html>