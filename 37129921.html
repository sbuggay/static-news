<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1692176461062" as="style"/><link rel="stylesheet" href="styles.css?v=1692176461062"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.cs.utexas.edu/~eunsol/courses/data/bitter_lesson.pdf">The Bitter Lesson [pdf]</a> <span class="domain">(<a href="https://www.cs.utexas.edu">www.cs.utexas.edu</a>)</span></div><div class="subtext"><span>jdkee</span> | <span>13 comments</span></div><br/><div><div id="37144361" class="c"><input type="checkbox" id="c-37144361" checked=""/><div class="controls bullet"><span class="by">Xcelerate</span><span>|</span><a href="#37143904">next</a><span>|</span><label class="collapse" for="c-37144361">[-]</label><label class="expand" for="c-37144361">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The second general point to be learned from the bitter lesson is that the actual contents of minds are tremendously, irredeemably complex; we should stop trying to find simple ways to think about the contents of minds, such as simple ways to think about space, objects, multiple agents, or symmetries.<p>I agree and think “ML explainability” efforts are doomed to fail as ML becomes increasingly more effective. There is no a priori reason that the human brain should be capable of intuitively grokking sufficiently advanced general learners. We can invent them and improve them, but saying that we will be able to understand what the myriad matrix multiplications are “doing” will be like saying we understand the human brain because we can model the physics of its constituent atoms. The emergent complexity is too high for us to make any sense of it.</div><br/></div></div><div id="37143904" class="c"><input type="checkbox" id="c-37143904" checked=""/><div class="controls bullet"><span class="by">isaacfrond</span><span>|</span><a href="#37144361">prev</a><span>|</span><a href="#37142918">next</a><span>|</span><label class="collapse" for="c-37143904">[-]</label><label class="expand" for="c-37143904">[3 more]</label></div><br/><div class="children"><div class="content">I think the Go example is facetious. For the longest time, Go simply was not amenable to search. It is only because of breakthrough in theory that Go became amendable to search. And, it is hardly a straightforward search mind you. Two self learning networks are involved. A first to guide the expansion of a Monte Carlo based tree search, a second to evaluate the nodes in the tree. You can hardly blame a researcher in the 70s, 80s, 90s, 00s for not focusing on computer power, when you have 19^2 expansion factor for each move.</div><br/><div id="37144453" class="c"><input type="checkbox" id="c-37144453" checked=""/><div class="controls bullet"><span class="by">reacweb</span><span>|</span><a href="#37143904">parent</a><span>|</span><a href="#37144269">next</a><span>|</span><label class="collapse" for="c-37144453">[-]</label><label class="expand" for="c-37144453">[1 more]</label></div><br/><div class="children"><div class="content">Go has been described as the drosophila of AI. Once a program will know how to play go, we&#x27;ll be able to make more general artificial intelligences. This is exactly what has happened with alphago and chatgpt. We&#x27;re not repeating the same thing that happened with chess, but we are past the singularity. Recent advances in AI are lighting up the very nature of intelligence. Our memory and our brain are a machine for predicting the future. It&#x27;s very similar to what recent models do. Alphagozero has rediscovered the history of chess openings in the same order as humans. We are no longer discovering simple new algorithms supported by machine advances, but architecting predictive systems based on guided learning. When we developed the algorithm for playing chess, the possibilities for generalization were limited. With these new architectures, new possibilities are appearing every day. IMHO, the predictions were true: since alphago, we&#x27;ve entered a new world.</div><br/></div></div><div id="37144269" class="c"><input type="checkbox" id="c-37144269" checked=""/><div class="controls bullet"><span class="by">PoignardAzur</span><span>|</span><a href="#37143904">parent</a><span>|</span><a href="#37144453">prev</a><span>|</span><a href="#37142918">next</a><span>|</span><label class="collapse" for="c-37144269">[-]</label><label class="expand" for="c-37144269">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not called &quot;the bitter lesson&quot; for being optimistic.<p>One of the points, I think, is that there is very little a researcher in the 70s could have done to make progress on these problems, because the computing power just wasn&#x27;t there yet; and once the computing power was here, almost all of that 70s researcher&#x27;s work became obsolete.</div><br/></div></div></div></div><div id="37142918" class="c"><input type="checkbox" id="c-37142918" checked=""/><div class="controls bullet"><span class="by">fnbr</span><span>|</span><a href="#37143904">prev</a><span>|</span><a href="#37143273">next</a><span>|</span><label class="collapse" for="c-37142918">[-]</label><label class="expand" for="c-37142918">[1 more]</label></div><br/><div class="children"><div class="content">This is the original page, I’d link to this:<p><a href="http:&#x2F;&#x2F;www.incompleteideas.net&#x2F;IncIdeas&#x2F;BitterLesson.html" rel="nofollow noreferrer">http:&#x2F;&#x2F;www.incompleteideas.net&#x2F;IncIdeas&#x2F;BitterLesson.html</a><p>u&#x2F;dang, swap links if you see this?</div><br/></div></div><div id="37143273" class="c"><input type="checkbox" id="c-37143273" checked=""/><div class="controls bullet"><span class="by">hyperthesis</span><span>|</span><a href="#37142918">prev</a><span>|</span><a href="#37143670">next</a><span>|</span><label class="collapse" for="c-37143273">[-]</label><label class="expand" for="c-37143273">[2 more]</label></div><br/><div class="children"><div class="content">Just adding an obvious corollary regarding parallelization, to &quot;leverage computation&quot; and &quot;massive computation became available and a means was found to put it to good use&quot;:<p><pre><code>  Parallelizable methods win (e.g. DL), by using the computation available
</code></pre>
Further: progress will occur on real-world problems that can be solved by those methods, making those applications dominant throughout society. (i.e. everything looks like a nail to someone with a hammer... but if it&#x27;s a <i>really good</i> hammer, that may be the best approach)</div><br/><div id="37143476" class="c"><input type="checkbox" id="c-37143476" checked=""/><div class="controls bullet"><span class="by">seanhunter</span><span>|</span><a href="#37143273">parent</a><span>|</span><a href="#37143670">next</a><span>|</span><label class="collapse" for="c-37143476">[-]</label><label class="expand" for="c-37143476">[1 more]</label></div><br/><div class="children"><div class="content">Yes.  Prior to this though in the AI community there was a lot of debate about the pros and cons of &quot;weak search&quot; (ie generalized methods) and &quot;strong search&quot; (ie methods which make use of domain knowledge). The bitter lesson is more or less that in the long run weak search always wins and the only real judgement call is whether strong search can give you a transient benefit in a particular case before weak search surpasses it and whether that is worth it.<p>In my head this always parallelled the &quot;premature optimization&quot; conversation in programming.  Most programmers would say that inlining etc was only justified when you&#x27;ve benchmarked so you know how the benchmarks are performing but the experience of whole program optimization in things like hotspot jvm and llvm seems to suggest that even benchmarked optimizations can be premature because only a vm can do optimizations on the real world use case.</div><br/></div></div></div></div><div id="37143670" class="c"><input type="checkbox" id="c-37143670" checked=""/><div class="controls bullet"><span class="by">v9v</span><span>|</span><a href="#37143273">prev</a><span>|</span><a href="#37143980">next</a><span>|</span><label class="collapse" for="c-37143670">[-]</label><label class="expand" for="c-37143670">[2 more]</label></div><br/><div class="children"><div class="content">Also see A Better Lesson:
<a href="https:&#x2F;&#x2F;rodneybrooks.com&#x2F;a-better-lesson&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;rodneybrooks.com&#x2F;a-better-lesson&#x2F;</a></div><br/><div id="37144343" class="c"><input type="checkbox" id="c-37144343" checked=""/><div class="controls bullet"><span class="by">PoignardAzur</span><span>|</span><a href="#37143670">parent</a><span>|</span><a href="#37143980">next</a><span>|</span><label class="collapse" for="c-37144343">[-]</label><label class="expand" for="c-37144343">[1 more]</label></div><br/><div class="children"><div class="content">Ehh, I&#x27;m more on Sutton&#x27;s side so far.<p>Brook&#x27;s post goes over the classics (Moore&#x27;s law is ending, curating a dataset requires human intervention, etc) and posits that making a huge model won&#x27;t be a competitive strategy for long because it gets to expensive to train and use.<p>It&#x27;s a bit early to tell, but so far that hasn&#x27;t materialized. OpenAI got state-of-the-art results with GPT-4, AFAIK by sticking for very-super-big models together. Open source experiments with LLAMA show you can still get good results with heavy quantization. Distillation hasn&#x27;t be too explored by mainstream projects, but I bet there&#x27;s lots of potential there too.<p>Right now the winning strategy looks to be &quot;go really big, then figure out how to go small&quot;.</div><br/></div></div></div></div><div id="37143980" class="c"><input type="checkbox" id="c-37143980" checked=""/><div class="controls bullet"><span class="by">niemandhier</span><span>|</span><a href="#37143670">prev</a><span>|</span><a href="#37142968">next</a><span>|</span><label class="collapse" for="c-37143980">[-]</label><label class="expand" for="c-37143980">[2 more]</label></div><br/><div class="children"><div class="content">I think the Bitter Lessons do not consider two important points with regards to neural nets :<p>1. Not all nets work for all problems, those that work tend to have the right inductive biases. We discovered the architectures partially by trial an error, nevertheless they work because of encoded prior information.<p>2. Data and computation are bounded. GPT4 was basically trained on all text, further advancements probably need more insight not more data.</div><br/><div id="37144033" class="c"><input type="checkbox" id="c-37144033" checked=""/><div class="controls bullet"><span class="by">psychoslave</span><span>|</span><a href="#37143980">parent</a><span>|</span><a href="#37142968">next</a><span>|</span><label class="collapse" for="c-37144033">[-]</label><label class="expand" for="c-37144033">[1 more]</label></div><br/><div class="children"><div class="content">What do you mean with more insights? If they are not represented as some data, how could they ever influence any computational model?</div><br/></div></div></div></div><div id="37142968" class="c"><input type="checkbox" id="c-37142968" checked=""/><div class="controls bullet"><span class="by">Animats</span><span>|</span><a href="#37143980">prev</a><span>|</span><label class="collapse" for="c-37142968">[-]</label><label class="expand" for="c-37142968">[1 more]</label></div><br/><div class="children"><div class="content">On HN before, at least once.[1]<p>[1] <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36017857">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36017857</a></div><br/></div></div></div></div></div></div></div></body></html>