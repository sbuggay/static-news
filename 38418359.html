<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1700989258610" as="style"/><link rel="stylesheet" href="styles.css?v=1700989258610"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://computer.rip/2023-11-25-the-curse-of-docker.html">The Curse of Docker</a> <span class="domain">(<a href="https://computer.rip">computer.rip</a>)</span></div><div class="subtext"><span>sklargh</span> | <span>70 comments</span></div><br/><div><div id="38419530" class="c"><input type="checkbox" id="c-38419530" checked=""/><div class="controls bullet"><span class="by">zaptheimpaler</span><span>|</span><a href="#38419790">next</a><span>|</span><label class="collapse" for="c-38419530">[-]</label><label class="expand" for="c-38419530">[12 more]</label></div><br/><div class="children"><div class="content">Nah docker is excellent and far far preferable to the standard way of doing things for most people.<p>All the traditional distribution methods have barely even figured out how to uninstall a piece of software. `apt remove` will often leave other things lying around.<p>He complains about configuration being more complex because its not a file? Except it is, and its so much simpler to just have a compose file that tells you EXACTLY which files are used for configuration and where they are. This is still not easy in normal linux packages. You have to google or dig through a list of 10-15 places that may be used for config..<p>The other brilliant opinion is that docker makes the barrier to entry for packaging <i>too low</i>.. but the alternative is not those things being packaged well in apt or whatever, its them not being packaged at all.. this is not a win.<p>Whats the alternative to running a big project like say Sourcegraph through a docker compose instance? You have to get set up ~10 services yourself including Redis, Postgres, some logging thing blah blah. I do not believe this is ever easier than `docker compose up -d`.<p>And if you want to run it without docker, the docker images are basically a self-documenting system for how to do that. This is strictly a win over previous systems, where there generally just is no documentation for that.<p>Personally docker lowers the activation energy to deploy something that I can now try&#x2F;run so many complex pieces of software so easily. I run sourcegraph, nginx, postgres, redis on my machine easily.  A week ago I wanted to learn more about data engineering - got a whole Apache Airflow cluster setup with a single compose file, took a few minutes. That would have been at least an hour of following some half-outdated deploy guide before so I just wouldn&#x27;t have done it.<p>---<p>The beginning of the post is most revealing though:<p>&gt; The fact that I have multiple times had to unpack flatpaks and modify them to fix dependencies reveals ... Still, these systems work reasonably well, well enough that they continue to proliferate...<p>Basically you are okay with opening up flatpaks to modify them but not opening up docker images.. it just comes down to familiarity.</div><br/><div id="38419865" class="c"><input type="checkbox" id="c-38419865" checked=""/><div class="controls bullet"><span class="by">kbenson</span><span>|</span><a href="#38419530">parent</a><span>|</span><a href="#38420109">next</a><span>|</span><label class="collapse" for="c-38419865">[-]</label><label class="expand" for="c-38419865">[5 more]</label></div><br/><div class="children"><div class="content">The thing I&#x27;m always interested in finding out is how people using lots of containers deal with security updates.<p>Do they go into every image and run the updates for the base image it&#x27;s based on? Does that just mean you&#x27;re now subject to multiple OS security and patching and best practices?<p>Do they think it doesn&#x27;t matter and just get new images then they&#x27;re published, which from what I can see is just when the overplayed software has an update and not the system anduvraries it relies on?<p>When glibc or zlib have a security update, what do you do? For RHEL and derivatives it looks line quay.io tries to help with that, but what&#x27;s the best practice for the rest of the community?<p>We haven&#x27;t really adopted containers at all at work yet, and to be honest this is at least part of the reason. It feels like we&#x27;d be doing all the patching we currently are, and then a bunch more. Sure, there are some gains, but if also feels like there&#x27;s a lot more work involved there too?</div><br/><div id="38420024" class="c"><input type="checkbox" id="c-38420024" checked=""/><div class="controls bullet"><span class="by">zaptheimpaler</span><span>|</span><a href="#38419530">root</a><span>|</span><a href="#38419865">parent</a><span>|</span><a href="#38420018">next</a><span>|</span><label class="collapse" for="c-38420024">[-]</label><label class="expand" for="c-38420024">[1 more]</label></div><br/><div class="children"><div class="content">So i primarily use containers on my local machine walled off from the internet, so it&#x27;s not a big concern for me. Watchtower [1] is popular among home server users too which automatically updates containers to the latest image.<p>For production uses I think companies generally build their own containers. They would have a common base linux container and build the other containers based off that with a typical CI&#x2F;CD pipeline. So if glibc is patched, it&#x27;s probably patched in the base container and the others are then rebuilt. You don&#x27;t have to patch each container individually, just the base. Once the whole build pipeline is automated its not too hard to add checks for security updates and rebuild when needed. Production also minimizes the scope of containers with nothing installed except what&#x27;s necessary so they have few dependencies.<p>[1] <a href="https:&#x2F;&#x2F;github.com&#x2F;containrrr&#x2F;watchtower">https:&#x2F;&#x2F;github.com&#x2F;containrrr&#x2F;watchtower</a></div><br/></div></div><div id="38420018" class="c"><input type="checkbox" id="c-38420018" checked=""/><div class="controls bullet"><span class="by">slekker</span><span>|</span><a href="#38419530">root</a><span>|</span><a href="#38419865">parent</a><span>|</span><a href="#38420024">prev</a><span>|</span><a href="#38420103">next</a><span>|</span><label class="collapse" for="c-38420018">[-]</label><label class="expand" for="c-38420018">[2 more]</label></div><br/><div class="children"><div class="content">You can use tools like Snyk to scan images for vulnerabilities (even the Docker(tm) cli tool has one now), you can do things like failing your CI pipeline if there are critica vulnerabilities.<p>You can also use Dependabot (and others) to update your images on a cronjob-like schedule.<p>This is a solved problem</div><br/><div id="38420040" class="c"><input type="checkbox" id="c-38420040" checked=""/><div class="controls bullet"><span class="by">SkiFire13</span><span>|</span><a href="#38419530">root</a><span>|</span><a href="#38420018">parent</a><span>|</span><a href="#38420103">next</a><span>|</span><label class="collapse" for="c-38420040">[-]</label><label class="expand" for="c-38420040">[1 more]</label></div><br/><div class="children"><div class="content">This is a solution for the app developer, not for the users that might have to deal with older and unsupported apps.</div><br/></div></div></div></div><div id="38420103" class="c"><input type="checkbox" id="c-38420103" checked=""/><div class="controls bullet"><span class="by">chillfox</span><span>|</span><a href="#38419530">root</a><span>|</span><a href="#38419865">parent</a><span>|</span><a href="#38420018">prev</a><span>|</span><a href="#38420109">next</a><span>|</span><label class="collapse" for="c-38420103">[-]</label><label class="expand" for="c-38420103">[1 more]</label></div><br/><div class="children"><div class="content">Don’t use glibc…<p>I am of course partially joking.<p>But seriously, use musl libc, build static binaries, build the images from scratch, and have a CI server handle it for you to keep it updated.<p>Alternatively use a small image like Alpine as base if you want some tools in the image for debugging.</div><br/></div></div></div></div><div id="38420109" class="c"><input type="checkbox" id="c-38420109" checked=""/><div class="controls bullet"><span class="by">progval</span><span>|</span><a href="#38419530">parent</a><span>|</span><a href="#38419865">prev</a><span>|</span><a href="#38420079">next</a><span>|</span><label class="collapse" for="c-38420109">[-]</label><label class="expand" for="c-38420109">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Whats the alternative to running a big project like say Sourcegraph through a docker compose instance? You have to get set up ~10 services yourself including Redis, Postgres, some logging thing blah blah. I do not believe this is ever easier than `docker compose up -d`.<p>Even with Docker, it&#x27;s not as easy as `docker compose up -d`.<p>You need to setup backups too. How do you backup all these containers? Do they even support it? Meanwhile I already have Postgres and Redis tuned, running, and backuped. I&#x27;d even have a warm Postgres replica if I could figure how to make that work.<p>Then you need to monitor them for security updates. How are you notified your Sourcegraph container and its dependencies&#x27; containers need to be updated and restarted? If they used system packages, I&#x27;d already have this solved with Munin&#x27;s APT plugin and&#x2F;or Debian&#x27;s unattended-upgrades. So you need to install Watchtower or equivalent. Which can&#x27;t tell the difference between a security update and other updates, so you might have your software updated with breaking changes at any point.<p>Alternatively, you can locate and subscribe to the RSS feed for the repository of every Dockerfile involved (or use one of these third-party services providing RSS feeds for Dockerhub) and hope they contain a changelog. If I installed from Debian I wouldn&#x27;t need that because I&#x27;m already subscribed to debian-security-announce@lists.debian.org</div><br/></div></div><div id="38420079" class="c"><input type="checkbox" id="c-38420079" checked=""/><div class="controls bullet"><span class="by">chillfox</span><span>|</span><a href="#38419530">parent</a><span>|</span><a href="#38420109">prev</a><span>|</span><a href="#38419705">next</a><span>|</span><label class="collapse" for="c-38420079">[-]</label><label class="expand" for="c-38420079">[1 more]</label></div><br/><div class="children"><div class="content">Exactly, Docker + Compose is the best way of running server software these days.<p>I keep my compose files in source control and I have got a CI server building images for anything that doesn’t have first party images available.<p>Updates are super easy as well, just update the pinned version at the top of the compose file (if not using latest), then ’docker-compose pull’ followed by ’docker-compose up -d’<p>The entire thing is so much more stable and easier to manage than the RedHat&#x2F;Ubuntu&#x2F;FreeBSD systems I used to manage.<p>(I use Alpine Linux + ZFS for the host OS)</div><br/></div></div><div id="38419705" class="c"><input type="checkbox" id="c-38419705" checked=""/><div class="controls bullet"><span class="by">angarg12</span><span>|</span><a href="#38419530">parent</a><span>|</span><a href="#38420079">prev</a><span>|</span><a href="#38419825">next</a><span>|</span><label class="collapse" for="c-38419705">[-]</label><label class="expand" for="c-38419705">[1 more]</label></div><br/><div class="children"><div class="content">I spent the last couple of days trying to set up some software waddling though open source repositories, fixing broken deps, pinning minor versions, browsing SO for obscure errors... I wish I had a Docker container instead.</div><br/></div></div><div id="38419825" class="c"><input type="checkbox" id="c-38419825" checked=""/><div class="controls bullet"><span class="by">ofrzeta</span><span>|</span><a href="#38419530">parent</a><span>|</span><a href="#38419705">prev</a><span>|</span><a href="#38419790">next</a><span>|</span><label class="collapse" for="c-38419825">[-]</label><label class="expand" for="c-38419825">[3 more]</label></div><br/><div class="children"><div class="content">&gt; figured out how to uninstall a piece of software. `apt remove` will often leave other things lying around.<p>What&#x27;s the Docker way of uninstall? In most cases Docker packaged software uses some kind of volume or local mount to save data. Is there a way to remove these when you remove the container? What about networks? (besides running prune on all available entities)</div><br/><div id="38419867" class="c"><input type="checkbox" id="c-38419867" checked=""/><div class="controls bullet"><span class="by">zaptheimpaler</span><span>|</span><a href="#38419530">root</a><span>|</span><a href="#38419825">parent</a><span>|</span><a href="#38419790">next</a><span>|</span><label class="collapse" for="c-38419867">[-]</label><label class="expand" for="c-38419867">[2 more]</label></div><br/><div class="children"><div class="content">You can `docker rm -v &lt;container&gt;` to remove a ccontainer + its volumes. For larger stuff typically I just read the docker-compose file with all of that listed in one place, so its pretty easy to just `docker rm` the volumes and networks. With apt I have no idea what files were added or modified and there&#x27;s no simple &quot;undo&quot;.</div><br/><div id="38420077" class="c"><input type="checkbox" id="c-38420077" checked=""/><div class="controls bullet"><span class="by">ofrzeta</span><span>|</span><a href="#38419530">root</a><span>|</span><a href="#38419867">parent</a><span>|</span><a href="#38419790">next</a><span>|</span><label class="collapse" for="c-38420077">[-]</label><label class="expand" for="c-38420077">[1 more]</label></div><br/><div class="children"><div class="content">I wasn&#x27;t aware of &#x27;-v&#x27; so thanks for that.<p>You can list package content with &#x27;dpkg -L&#x27;, although, granted, it doesn&#x27;t cover files that were somehow created by the install script. Also &#x27;apt purge&#x27; removes all files including config.</div><br/></div></div></div></div></div></div></div></div><div id="38419790" class="c"><input type="checkbox" id="c-38419790" checked=""/><div class="controls bullet"><span class="by">rkagerer</span><span>|</span><a href="#38419530">prev</a><span>|</span><a href="#38418919">next</a><span>|</span><label class="collapse" for="c-38419790">[-]</label><label class="expand" for="c-38419790">[2 more]</label></div><br/><div class="children"><div class="content">You know who really knows how to package software? Mark Russinovich, Nir Sofer, and all the others who gave us beautiful utililies in standalone EXE&#x27;s that don&#x27;t require any dependencies.<p>For the longest time I stayed on older versions of .NET so any version of Windows since 2003 could run my software out of the box.  Made use of ILMerge or a custom AssemblyResolve handler to bundle support DLL&#x27;s right into my single-file tools - it wasn&#x27;t hard.<p>I have no complaints about Docker, but I do find where I used to be able to download simple zip files and place their contents into my project I now just get a black box Docker link with zero documentation and that makes me sad.</div><br/></div></div><div id="38418919" class="c"><input type="checkbox" id="c-38418919" checked=""/><div class="controls bullet"><span class="by">leonheld</span><span>|</span><a href="#38419790">prev</a><span>|</span><a href="#38419247">next</a><span>|</span><label class="collapse" for="c-38418919">[-]</label><label class="expand" for="c-38418919">[11 more]</label></div><br/><div class="children"><div class="content">&gt; Anyway, what I really wanted to complain a bit about is the realm of software intended to be run on servers.<p>Okay.<p>&gt; I&#x27;m not sure that Docker has saved me more hours than it&#x27;s cost<p>I&#x27;m not sure what&#x27;s the alternative for servers here. Containers have certainly saved me of a lot of headache and created very little overhead. N=1 (as it seems to be the OP).<p>&gt; The problem is the use of Docker as a lowest common denominator [...] approach to distributing software to end users.<p>Isn&#x27;t the issue specific for server use? Are you running random images from the internet on your servers?<p>&gt; In the worst case, some Docker images provide no documentation at all<p>Well, in the same vein as my last comment, Docker is not a silver bullet for everything. You still have to take care of what you&#x27;re actually running.<p>Honestly the discussion is valid, but I think the OP aimed at &quot;the current state of things&quot; and hit a very valuable tool that doesn&#x27;t deserve some of the targeted cristicism I read here.<p>edit: my two cents for those who cannot bother and expect just because it&#x27;s a container, everything will magically be solved: use official images and those from Bitnami. There, you&#x27;re set.</div><br/><div id="38419018" class="c"><input type="checkbox" id="c-38419018" checked=""/><div class="controls bullet"><span class="by">viraptor</span><span>|</span><a href="#38418919">parent</a><span>|</span><a href="#38419600">next</a><span>|</span><label class="collapse" for="c-38419018">[-]</label><label class="expand" for="c-38419018">[9 more]</label></div><br/><div class="children"><div class="content">&gt; I&#x27;m not sure what&#x27;s the alternative for servers here.<p>Nixos&#x2F;nixpkgs: isolated dependencies &#x2F; services, easy to override if needed, configs follow relatively consistent pattern (main options exposed, others can be passed as text), service files can do isolation by whitelisting paths without going full-blown self-contained-os container.<p>&gt; Are you running random images from the internet on your servers?<p>Many home server users do this. In business use, unless you invest lots of time into this, a part of your services is still effectively a random image from the internet.<p>&gt; and those from Bitnami<p>Yes, that&#x27;s a random image from the internet.</div><br/><div id="38419114" class="c"><input type="checkbox" id="c-38419114" checked=""/><div class="controls bullet"><span class="by">blackoil</span><span>|</span><a href="#38418919">root</a><span>|</span><a href="#38419018">parent</a><span>|</span><a href="#38419407">next</a><span>|</span><label class="collapse" for="c-38419114">[-]</label><label class="expand" for="c-38419114">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Yes, that&#x27;s a random image from the internet.<p>By that definition, you are running it on a random OS, random processor with some random network infra.</div><br/><div id="38419166" class="c"><input type="checkbox" id="c-38419166" checked=""/><div class="controls bullet"><span class="by">viraptor</span><span>|</span><a href="#38418919">root</a><span>|</span><a href="#38419114">parent</a><span>|</span><a href="#38419407">next</a><span>|</span><label class="collapse" for="c-38419166">[-]</label><label class="expand" for="c-38419166">[1 more]</label></div><br/><div class="children"><div class="content">Kinda. It depends what your risk tolerance is.<p>But seriously, what&#x27;s your business relationship to bitnami? What are the guarantees about keeping those images up to date? What are the guarantees about the feature set provided? How long will the specific image be available publicly&#x2F;free? Is the base system guaranteed to stay the same? What about architecture support?</div><br/></div></div></div></div><div id="38419407" class="c"><input type="checkbox" id="c-38419407" checked=""/><div class="controls bullet"><span class="by">patrick451</span><span>|</span><a href="#38418919">root</a><span>|</span><a href="#38419018">parent</a><span>|</span><a href="#38419114">prev</a><span>|</span><a href="#38419600">next</a><span>|</span><label class="collapse" for="c-38419407">[-]</label><label class="expand" for="c-38419407">[6 more]</label></div><br/><div class="children"><div class="content">It&#x27;s always been surprising to me how little people seem to care about the provenance of their images. It&#x27;s even more surprising that infosec isn&#x27;t forcing developing to start their images `FROM scratch`.</div><br/><div id="38419529" class="c"><input type="checkbox" id="c-38419529" checked=""/><div class="controls bullet"><span class="by">w-ll</span><span>|</span><a href="#38418919">root</a><span>|</span><a href="#38419407">parent</a><span>|</span><a href="#38419548">next</a><span>|</span><label class="collapse" for="c-38419529">[-]</label><label class="expand" for="c-38419529">[4 more]</label></div><br/><div class="children"><div class="content">Are you compiling you os distro&#x27;s `FROM scratch`?<p>Ther&#x27;s always a certin level of trust, and for many, docker containers are just as trusty as distros from trusty orgs or volunteers.</div><br/><div id="38419725" class="c"><input type="checkbox" id="c-38419725" checked=""/><div class="controls bullet"><span class="by">rnimmer</span><span>|</span><a href="#38418919">root</a><span>|</span><a href="#38419529">parent</a><span>|</span><a href="#38419548">next</a><span>|</span><label class="collapse" for="c-38419725">[-]</label><label class="expand" for="c-38419725">[3 more]</label></div><br/><div class="children"><div class="content">There once was a man named Terry Davis...</div><br/><div id="38419808" class="c"><input type="checkbox" id="c-38419808" checked=""/><div class="controls bullet"><span class="by">w-ll</span><span>|</span><a href="#38418919">root</a><span>|</span><a href="#38419725">parent</a><span>|</span><a href="#38419548">next</a><span>|</span><label class="collapse" for="c-38419808">[-]</label><label class="expand" for="c-38419808">[2 more]</label></div><br/><div class="children"><div class="content">I imagine anyone with a BA in CS has wrote a OS from scratch.<p>How many systems on chips are in a moderen computer, not the main system and cpu, but every little chip and controller, the boot system, every board seems to have a little OS.<p>In regards to security, its all about analysing risk and trade-offs.<p>For me using containers from known vendors is a risk im willing to take.</div><br/><div id="38419963" class="c"><input type="checkbox" id="c-38419963" checked=""/><div class="controls bullet"><span class="by">viraptor</span><span>|</span><a href="#38418919">root</a><span>|</span><a href="#38419808">parent</a><span>|</span><a href="#38419548">next</a><span>|</span><label class="collapse" for="c-38419963">[-]</label><label class="expand" for="c-38419963">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I imagine anyone with a BA in CS has wrote a OS from scratch.<p>Not even close. Very few courses require anything that advanced and only some of those are non-optional.</div><br/></div></div></div></div></div></div></div></div><div id="38419548" class="c"><input type="checkbox" id="c-38419548" checked=""/><div class="controls bullet"><span class="by">skipnup</span><span>|</span><a href="#38418919">root</a><span>|</span><a href="#38419407">parent</a><span>|</span><a href="#38419529">prev</a><span>|</span><a href="#38419600">next</a><span>|</span><label class="collapse" for="c-38419548">[-]</label><label class="expand" for="c-38419548">[1 more]</label></div><br/><div class="children"><div class="content">But that could be said about each an any dependency.<p>And some (very rare) companies do enforce that, everyone else has to build up a bit of trust.</div><br/></div></div></div></div></div></div><div id="38419600" class="c"><input type="checkbox" id="c-38419600" checked=""/><div class="controls bullet"><span class="by">alexey-salmin</span><span>|</span><a href="#38418919">parent</a><span>|</span><a href="#38419018">prev</a><span>|</span><a href="#38419247">next</a><span>|</span><label class="collapse" for="c-38419600">[-]</label><label class="expand" for="c-38419600">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Isn&#x27;t the issue specific for server use? Are you running random images from the internet on your servers?<p>Well exactly, there&#x27;s what the author is writing about.<p>The whole article is dedicated to the problem of Docker being used as a distribution method, that is as a replacement for say Debian package.<p>So in order to use that software you need to run a Docker image from the internet which is open poorly made and incompatible with your infrastructure. Had a package been available you&#x27;d simply do &quot;apt-get install&quot; inside your own image built with your infrastructure in mind.</div><br/></div></div></div></div><div id="38419247" class="c"><input type="checkbox" id="c-38419247" checked=""/><div class="controls bullet"><span class="by">theden</span><span>|</span><a href="#38418919">prev</a><span>|</span><a href="#38419868">next</a><span>|</span><label class="collapse" for="c-38419247">[-]</label><label class="expand" for="c-38419247">[2 more]</label></div><br/><div class="children"><div class="content">&gt;One of the great sins of Docker is having normalized running software as root. Yes, Docker provides a degree of isolation, but from a perspective of defense in depth running anything with user exposure as root continues to be a poor practice.<p>&gt;Perhaps one of the problems with Docker is that it&#x27;s too easy to use<p>If you&#x27;ve ever had to make a nonroot docker image (or an image that runs properly with the `--read-only` flag), it&#x27;s not as trivial and fast to get things going—if it was default, perhaps docker wouldn&#x27;t have been so successful in getting engineers of all types and levels to adopt it?<p>It&#x27;s rare to find tooling in the DevOps&#x2F;SRE world that&#x27;s easy to just get started with productively, so docker&#x27;s low barrier to entry is an exception IMO. Yes, the downside is you get a lot of poorly-made `Dockerfiles` in the wild, but it&#x27;s also easy to iterate and improve them, given that there&#x27;s a common ground. It&#x27;s a curse I suppose, but I&#x27;d rather have a well-understood curse than the alternative being an arbitrary amount of bespoke curses.</div><br/><div id="38419697" class="c"><input type="checkbox" id="c-38419697" checked=""/><div class="controls bullet"><span class="by">numbsafari</span><span>|</span><a href="#38419247">parent</a><span>|</span><a href="#38419868">next</a><span>|</span><label class="collapse" for="c-38419697">[-]</label><label class="expand" for="c-38419697">[1 more]</label></div><br/><div class="children"><div class="content">Running all your software as root is the IT equivalent of sales guys slapping themselves on the back for selling something for free.<p>It’s all fun and games until the bills come due.</div><br/></div></div></div></div><div id="38419868" class="c"><input type="checkbox" id="c-38419868" checked=""/><div class="controls bullet"><span class="by">jillesvangurp</span><span>|</span><a href="#38419247">prev</a><span>|</span><a href="#38419026">next</a><span>|</span><label class="collapse" for="c-38419868">[-]</label><label class="expand" for="c-38419868">[1 more]</label></div><br/><div class="children"><div class="content">I remember how things were before docker. Better is not a word I&#x27;d use for that.<p>It sucked. Deploying software meant dealing with lots of operating system and distribution specific configuration, issues, bugs, etc. All of that had to be orchestrated with complicated scripts. First those were hand written, and later we got things like chef and puppet. Docker wiped most of that out and replaced it with simple build time tools that eliminate the need for having a lot of deploy time tools that take ages to run, are very complex to maintain, etc.<p>I also love to use it for development a lot. It allows me to use lots of different things that I need without having to bother installing those things. Saves a lot of time.<p>Docker gives us a nice standard way to run and configure whatever. Mostly configuration only gets hard when the underlying software is hard to configure. That&#x27;s usually a problem with the software, not with docker. These days if you are building something that requires fiddling with some configuration file, it kind of is broken by design. You should design your configuration with docker in mind and not force people to have to mount volumes just so they can set some properties.<p>The reason docker is so widespread is that it is so obviously a good idea and there hasn&#x27;t been anyone that came along with something better that actually managed to get any traction worth talking about. Most of the docker alternatives tend to be compatible with docker to the point that the differences are mostly in how they run dockerized software.<p>And while I like docker, I think Kubernetes is a hopelessly over engineered and convoluted mess.</div><br/></div></div><div id="38419026" class="c"><input type="checkbox" id="c-38419026" checked=""/><div class="controls bullet"><span class="by">owyn</span><span>|</span><a href="#38419868">prev</a><span>|</span><a href="#38419079">next</a><span>|</span><label class="collapse" for="c-38419026">[-]</label><label class="expand" for="c-38419026">[3 more]</label></div><br/><div class="children"><div class="content">There are a lot of use cases for docker, I think this is complaining about a few specific things in more complex applications that probably shouldn&#x27;t be deployed that way because you&#x27;re not just exposing port 80, it&#x27;s a whole tool deployed to end users, like an appliance. But that&#x27;s not my primary use case for Docker.<p>For me, the best thing about Docker is that it&#x27;s brought the average developer experience from &quot;oh, I think I have an install.sh for that around somewhere&quot; to mostly repeatable builds that are mostly self documenting. Any time a tool is self documenting it&#x27;s a win. If you want the cake, you have to write down the recipe. That&#x27;s huge. It&#x27;s forcing lazy devs (which we all are) to just write it down. At this point the amount of &quot;weird bearded guy tribal knowledge&quot; that is now documented in a Dockerfile somewhere is a treasure trove.<p>Things still break all the time for a million dumb reasons but as a least common denominator it&#x27;s a great place to start.  It&#x27;s not a solution for everything and it sounds like that&#x27;s what this article is about. Docker+Compose is not great for everything, so don&#x27;t use it for those situations. But it&#x27;s so much better than what was before.</div><br/><div id="38419085" class="c"><input type="checkbox" id="c-38419085" checked=""/><div class="controls bullet"><span class="by">Onawa</span><span>|</span><a href="#38419026">parent</a><span>|</span><a href="#38419830">next</a><span>|</span><label class="collapse" for="c-38419085">[-]</label><label class="expand" for="c-38419085">[1 more]</label></div><br/><div class="children"><div class="content">Without reading the article, I would also agree that Docker has made things better for me rather than worse. If someone else spent the effort to create a Dockerfile for their app, it will reduce the amount of issues I have trying to deploy it greatly. At least at that point they have figured out the majority of dependencies required to run their app, then I only have to troubleshoot the details rather than starting from scratch for whatever server distribution that I&#x27;m running it on.</div><br/></div></div><div id="38419830" class="c"><input type="checkbox" id="c-38419830" checked=""/><div class="controls bullet"><span class="by">__MatrixMan__</span><span>|</span><a href="#38419026">parent</a><span>|</span><a href="#38419085">prev</a><span>|</span><a href="#38419079">next</a><span>|</span><label class="collapse" for="c-38419830">[-]</label><label class="expand" for="c-38419830">[1 more]</label></div><br/><div class="children"><div class="content">&gt; mostly repeatable builds that are mostly self documenting<p>&quot;Mostly&quot; is going a bit far there.<p>If you want those things you should use nix to build your docker images, but you&#x27;re going to have to want them pretty badly.</div><br/></div></div></div></div><div id="38419079" class="c"><input type="checkbox" id="c-38419079" checked=""/><div class="controls bullet"><span class="by">ycombinatrix</span><span>|</span><a href="#38419026">prev</a><span>|</span><a href="#38420083">next</a><span>|</span><label class="collapse" for="c-38419079">[-]</label><label class="expand" for="c-38419079">[4 more]</label></div><br/><div class="children"><div class="content">&gt;Doing anything non-default with networks in Docker Compose will often create stacks that don&#x27;t work correctly on machines with complex network setups.<p>I run into this often. Docker networking is a mess.</div><br/><div id="38419105" class="c"><input type="checkbox" id="c-38419105" checked=""/><div class="controls bullet"><span class="by">j45</span><span>|</span><a href="#38419079">parent</a><span>|</span><a href="#38420083">next</a><span>|</span><label class="collapse" for="c-38419105">[-]</label><label class="expand" for="c-38419105">[3 more]</label></div><br/><div class="children"><div class="content">Depending on the load and use case, encapsulating docker itself in an lxc container or a standalone vm can be a semi maintainable and separated solution.</div><br/><div id="38419676" class="c"><input type="checkbox" id="c-38419676" checked=""/><div class="controls bullet"><span class="by">NorwegianDude</span><span>|</span><a href="#38419079">root</a><span>|</span><a href="#38419105">parent</a><span>|</span><a href="#38419190">next</a><span>|</span><label class="collapse" for="c-38419676">[-]</label><label class="expand" for="c-38419676">[1 more]</label></div><br/><div class="children"><div class="content">Docker in lxc is also a huge mess when it comes to storage drivers with some backends...</div><br/></div></div><div id="38419190" class="c"><input type="checkbox" id="c-38419190" checked=""/><div class="controls bullet"><span class="by">heatmiser</span><span>|</span><a href="#38419079">root</a><span>|</span><a href="#38419105">parent</a><span>|</span><a href="#38419676">prev</a><span>|</span><a href="#38420083">next</a><span>|</span><label class="collapse" for="c-38419190">[-]</label><label class="expand" for="c-38419190">[1 more]</label></div><br/><div class="children"><div class="content">I like this approach for running multiple services on customer servers&#x2F;clouds. for my own cloud though, i&#x27;ll use some orchestrator that makes sense</div><br/></div></div></div></div></div></div><div id="38420083" class="c"><input type="checkbox" id="c-38420083" checked=""/><div class="controls bullet"><span class="by">wg0</span><span>|</span><a href="#38419079">prev</a><span>|</span><a href="#38419666">next</a><span>|</span><label class="collapse" for="c-38420083">[-]</label><label class="expand" for="c-38420083">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s no merit to this complaint about Docker that it complicates configuration. Actually it simplifies a great deal.<p>Author should consider how configuration is at different locations and sometimes even further split differently in different distributions for the same software package (apache, PostgreSQL etc) while a docker Image has it all at a very well known location within image and it doesn&#x27;t matter where you use that image.</div><br/></div></div><div id="38419666" class="c"><input type="checkbox" id="c-38419666" checked=""/><div class="controls bullet"><span class="by">what-the-grump</span><span>|</span><a href="#38420083">prev</a><span>|</span><a href="#38419223">next</a><span>|</span><label class="collapse" for="c-38419666">[-]</label><label class="expand" for="c-38419666">[1 more]</label></div><br/><div class="children"><div class="content">These sorts of things usually take longer to get working than equivalent software distributed as a conventional Linux package or to be built from source.<p>Yes, but they are done once, and forced to ship the docker image. The stupid amount of time we&#x27;ve spent looking for that one package dependency because someone forgot that they installed something to make a project work... Or the classic we setup SSL, no one knows how they setup SSL once they are done, etc.<p>Docker forces a lot of the infrastructure decisions that devs make in their sandbox to be actually well defined. Not that it makes their choices any more sane, safer, secure. At least someone can take a look at the mess and replicate it, as many time as they want, quickly, break it, fix it, upgrade it, without ever requesting a dev VM build, having sysops install preqs, etc.<p>Is docker work? Everything is work. Do I think docker should be the default go to? No I&#x27;d like for people to use app services and simply perform the build on the app node, but that magic is even harder to debug and troubleshoot.</div><br/></div></div><div id="38419223" class="c"><input type="checkbox" id="c-38419223" checked=""/><div class="controls bullet"><span class="by">chasil</span><span>|</span><a href="#38419666">prev</a><span>|</span><a href="#38419198">next</a><span>|</span><label class="collapse" for="c-38419223">[-]</label><label class="expand" for="c-38419223">[2 more]</label></div><br/><div class="children"><div class="content">The original method to distribute library- independent software was &quot;cc --static&quot; née &quot;cc -s&quot;...<p>The world was a much simpler place so long ago.</div><br/><div id="38419905" class="c"><input type="checkbox" id="c-38419905" checked=""/><div class="controls bullet"><span class="by">mianos</span><span>|</span><a href="#38419223">parent</a><span>|</span><a href="#38419198">next</a><span>|</span><label class="collapse" for="c-38419905">[-]</label><label class="expand" for="c-38419905">[1 more]</label></div><br/><div class="children"><div class="content">Or use applications in golang. Not a user myself, but all the stuff like vault and such are just an executable. What is even funnier is go apps tend to have the simplest containers, for example kaniko seems to be a go app kaniko as init and nothing else.<p>One could also argue that apps that mandate running in docker probably have some ridiculous dependency issues or too clever by half runtime.</div><br/></div></div></div></div><div id="38419198" class="c"><input type="checkbox" id="c-38419198" checked=""/><div class="controls bullet"><span class="by">cyrnel</span><span>|</span><a href="#38419223">prev</a><span>|</span><a href="#38419655">next</a><span>|</span><label class="collapse" for="c-38419198">[-]</label><label class="expand" for="c-38419198">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Making things worse, a lot of Docker images try to make configuration less painful by providing some sort of entry-point shell script that generates the full configuration from some simpler document provided to the container.<p>I see this as the container world reinventing the wheel of reasonable defaults for software that has long since lost sight of that. Nginx and Apache are two of the worst offenders, which won&#x27;t just serve files out of a directory without a few dozens lines of config.</div><br/></div></div><div id="38419655" class="c"><input type="checkbox" id="c-38419655" checked=""/><div class="controls bullet"><span class="by">alexey-salmin</span><span>|</span><a href="#38419198">prev</a><span>|</span><a href="#38419389">next</a><span>|</span><label class="collapse" for="c-38419655">[-]</label><label class="expand" for="c-38419655">[3 more]</label></div><br/><div class="children"><div class="content">I think most of the comments here largely miss the point of the article. The guy doesn&#x27;t complain about docker as a whole and doesn&#x27;t criticise it&#x27;s usage for software deployment which normally is the main application.<p>He complains about Docker being used as a software distribution method, that is as a replacement for say Debian package, pip package, npm package etc.<p>So in order to use that software you need to run a Docker image from the internet which is often poorly made and is incompatible with your infrastructure. Had a package been available you&#x27;d simply do &quot;install&quot; inside your own image built with your infrastructure in mind.<p>With that I agree completely. Docker and worse even docker-compose are terrible ways of software distribution and should never be used except for demos and for rare cases where software is not distributed to the customer in the normal sense but rather directly deployed into his system.<p>Docker and docker-compose are still very good methods of software deployment.</div><br/><div id="38419782" class="c"><input type="checkbox" id="c-38419782" checked=""/><div class="controls bullet"><span class="by">solatic</span><span>|</span><a href="#38419655">parent</a><span>|</span><a href="#38419689">next</a><span>|</span><label class="collapse" for="c-38419782">[-]</label><label class="expand" for="c-38419782">[1 more]</label></div><br/><div class="children"><div class="content">This, but I want to add, I think the root cause is less due to the ease of writing a Dockerfile vs writing a deb, rpm, etc. and more due to the low cost of hosting. Whatever low-quality Dockerfile you write, you can sign up on Docker Hub, build and push there, and you&#x27;re done. GitHub Packages doesn&#x27;t support deb or rpm, and anyway for better or for worse, packages are tightly coupled to the distribution they&#x27;re packaged for. That means either getting your package into the package repository of each distribution you want to target, or hosting your own package repository, which is non-trivial in both financial and labor cost.<p>Docker has a lot more crap, but it <i>did</i> dramatically lower the barrier of entry, which is a good thing. The proper response isn&#x27;t to bemoan the lower barrier of entry, but to attempt to lower the barrier of entry of traditional packaging.</div><br/></div></div><div id="38419689" class="c"><input type="checkbox" id="c-38419689" checked=""/><div class="controls bullet"><span class="by">turtlebits</span><span>|</span><a href="#38419655">parent</a><span>|</span><a href="#38419782">prev</a><span>|</span><a href="#38419389">next</a><span>|</span><label class="collapse" for="c-38419689">[-]</label><label class="expand" for="c-38419689">[1 more]</label></div><br/><div class="children"><div class="content">I have rarely seen end user software being distributed as a docker image, only server applications.   Occasionally I see CLI tools that are hard to package available as docker images, but those are generally done because the maintainer hasn&#x27;t provided precompiled binaries.</div><br/></div></div></div></div><div id="38419389" class="c"><input type="checkbox" id="c-38419389" checked=""/><div class="controls bullet"><span class="by">notatoad</span><span>|</span><a href="#38419655">prev</a><span>|</span><a href="#38419564">next</a><span>|</span><label class="collapse" for="c-38419389">[-]</label><label class="expand" for="c-38419389">[1 more]</label></div><br/><div class="children"><div class="content">Dockerfiles are really really simple.  they do essentially three things: set a base image, set environment variables, and run scripts.  and then as sort of a meta-thing, they prove that the steps in the dockerfile actually work, when you start the docker container and see that it works.<p>if you don&#x27;t want to run in docker, a dockerfile is still a perfect setup script. open it up and see what it does, and use that as install instructions.</div><br/></div></div><div id="38419564" class="c"><input type="checkbox" id="c-38419564" checked=""/><div class="controls bullet"><span class="by">zubairq</span><span>|</span><a href="#38419389">prev</a><span>|</span><a href="#38419764">next</a><span>|</span><label class="collapse" for="c-38419564">[-]</label><label class="expand" for="c-38419564">[1 more]</label></div><br/><div class="children"><div class="content">Having worked at Red Hat and worked on many Docker &#x2F; Kubernetes systems I agree with some parts of the article, but my view is that the wrold is going through a transition phase right now of moving to containerised systems.<p>Take for example running something like 3Scale (an internet gateway) in Docker or Kubernete. It can be a nightmare to configure and run 3Scale using containers with the multiple memory limits and other container specific issues. Far easier to get 3Scale running without containers.<p>So many software systems were not designed in the Docker era, and going forward many container applications will be designed to be easier to configure&#x2F;use in the Container world due to a &quot;Container&#x2F;Docker native&quot; mindset when designing the system in the first place</div><br/></div></div><div id="38419764" class="c"><input type="checkbox" id="c-38419764" checked=""/><div class="controls bullet"><span class="by">GabeIsko</span><span>|</span><a href="#38419564">prev</a><span>|</span><a href="#38419940">next</a><span>|</span><label class="collapse" for="c-38419764">[-]</label><label class="expand" for="c-38419764">[1 more]</label></div><br/><div class="children"><div class="content">I can&#x27;t believe what I am reading. It took you more time to set up nextcloud with docker compose? What? For my hobby stuff, I can usually try something out really quickly by giving a compose a quick read and pasting it into portainer for a test.<p>I have my gripes with docker - especially for my professional work, and I am not a fan about how much it obscures images, nor its shibboleth approach to using a CLI-daemon interface (should be a `dockerctl` command in my mind) but I really can&#x27;t believe that you would want to manually set up multi process platforms manually. When you want to connect to a data base, and have it be ephemeral? I have rooted around in enough application servers to understand that docker-compose and dockerfiles is a very sane approach.<p>The real issue I am seeing in the comments are that people are complaining that they would prefer getting a maintained package for software. Would rather use `apt install` or `dnf install` than mess with containers. That has been discussed to death and we get the same answer is the same every time - yes that would be a nice world to live in, but it is a fantasy to imagine anyone doing that much maintenance work for packages.</div><br/></div></div><div id="38419940" class="c"><input type="checkbox" id="c-38419940" checked=""/><div class="controls bullet"><span class="by">devjab</span><span>|</span><a href="#38419764">prev</a><span>|</span><a href="#38419621">next</a><span>|</span><label class="collapse" for="c-38419940">[-]</label><label class="expand" for="c-38419940">[1 more]</label></div><br/><div class="children"><div class="content">I think a lot of your comments here are very true. I don’t think docker made my world worse and I certainly don’t think it cost me more time, but I also sort of agree with the author. I came into Typescript late, and to “tame” the wildness of the ecosystem I set up a lot of opinionated systems for our developers. I didn’t dictate them, it was a collaborative process where we worked long and hard go agree on how we would utilise the Node ecosystem as well as the 10ish rules that we’ve changed as opposed to the “global” strict eslint rules. Rules which have themselves been born out of a decade of different rulesets like the Airbnb ones most people in the JS community will have heard of. My approach to containers has been similar.<p>We don’t use docker-compose and never have as an example, we went with Terraform, though today we’re using Bicep, and we make heavy use of dapr side cars. Which makes working with infrastructure sort of easy. Easy to lock down and opinionate at least. You can get most templates directly from Azures GitHub, but you can obviously also build your own, and then it’s simply a matter of having some decent template projects so that your developers can be up and running in a few minutes whenever they need to start a new project. Obviously there is a cost when you’re moving legacy projects into this sort of infrastructure, but it’s not like it’s really that resource consuming if it was already containerised, and it’s not too bad even if it wasn’t.<p>Now, that’s how we do it. It’s also how I think everyone should do it, but it’s not how you “have” to do it. In many ways, you’re as free to utilize the container ecosystems as freely as you can with the Node ecosystem. Well maybe not as free as that, but still free enough to create a lot of horror stories. Which is exactly what has happened with containers in many organisations. As such I think the author has a valid point. I’m not sure where we would go without the freedom though. Our exact setup works for us, you might not agree with our choices and neither of us would be wrong. So while some opinionated processes might be compatible with container infrastructure, others will need to remain “free”. I’m certainly with a lot of you in that it was worse before containers. I’ve also done work with organisations where container deployments worked so poorly that it was clearly not better, however, and I suspect those pipelines are far more common than given credit in this comment section.</div><br/></div></div><div id="38419621" class="c"><input type="checkbox" id="c-38419621" checked=""/><div class="controls bullet"><span class="by">defanor</span><span>|</span><a href="#38419940">prev</a><span>|</span><a href="#38419484">next</a><span>|</span><label class="collapse" for="c-38419621">[-]</label><label class="expand" for="c-38419621">[2 more]</label></div><br/><div class="children"><div class="content">Docker keeps reminding me of people in the past shipping VM images, or sometimes physical machines, often with rather inappropriate desktop hardware and software. So do these points:<p>&gt; The problem is the use of Docker as a lowest common denominator, or perhaps more accurately lowest common effort, approach to distributing software to end users.<p>Shipping physical machines probably is even lower than that though. Or even the VMs.<p>&gt; One of the great sins of Docker is having normalized running software as root.<p>I am not as familiar with Docker practices, but unfortunately, AFAICT, people did that frequently on regular systems as well, just to not bother with permissions. (Edit: now I recalled people also not following the FHS and storing things in the root directory inside Docker images, but sometimes it was&#x2F;is similar without containers as well, and inside a container it does not clutter the host system, at least).<p>&gt; Having &quot;pi&quot; in the name of a software product is a big red flag in my mind, it immediately makes me think &quot;they will not have documented how to run this on a shared device.&quot;<p>This approach is similar to shipping physical machines. Or at least maintaining odd legacy software on a dedicated machine.<p>I think a rather pessimistic view is that proper packaging switched to Docker or single-purpose machines, but an optimistic one is that those are the unnecessary VMs and larger single-purpose machines that were replaced by Docker and RPi. Maybe there is a little of both going on.</div><br/><div id="38419744" class="c"><input type="checkbox" id="c-38419744" checked=""/><div class="controls bullet"><span class="by">ungamedplayer</span><span>|</span><a href="#38419621">parent</a><span>|</span><a href="#38419484">next</a><span>|</span><label class="collapse" for="c-38419744">[-]</label><label class="expand" for="c-38419744">[1 more]</label></div><br/><div class="children"><div class="content">&gt;AFAICT, people did that frequently on regular systems as well, just to not bother with permissions.<p>This was an easy way to tell if you were dealing with a Muppet.  If you saw this you would know that the software was going to be a problem.</div><br/></div></div></div></div><div id="38419484" class="c"><input type="checkbox" id="c-38419484" checked=""/><div class="controls bullet"><span class="by">eviks</span><span>|</span><a href="#38419621">prev</a><span>|</span><a href="#38419270">next</a><span>|</span><label class="collapse" for="c-38419484">[-]</label><label class="expand" for="c-38419484">[2 more]</label></div><br/><div class="children"><div class="content">Has any great design been invented that isn&#x27;t tied to hardcoded paths preventing multiple versions of the same library and would allow easy linking to any version? Nix? Anything else?</div><br/><div id="38420027" class="c"><input type="checkbox" id="c-38420027" checked=""/><div class="controls bullet"><span class="by">colordrops</span><span>|</span><a href="#38419484">parent</a><span>|</span><a href="#38419270">next</a><span>|</span><label class="collapse" for="c-38420027">[-]</label><label class="expand" for="c-38420027">[1 more]</label></div><br/><div class="children"><div class="content">Yes, Nix. And it works great.</div><br/></div></div></div></div><div id="38419270" class="c"><input type="checkbox" id="c-38419270" checked=""/><div class="controls bullet"><span class="by">linuxrebe1</span><span>|</span><a href="#38419484">prev</a><span>|</span><a href="#38419332">next</a><span>|</span><label class="collapse" for="c-38419270">[-]</label><label class="expand" for="c-38419270">[2 more]</label></div><br/><div class="children"><div class="content">99.9% of the problems you spoke to, which are very real. Could be solved if people building the software would just understand one thing. A container is not a mini VM. It is not in any way shape or form a virtual machine. If what you need is a lightweight virtual machine. Build that. Do not build a container because it&#x27;s the latest and greatest buzzword. But instead I see large monolithic applications, shoved into a container, and then I hear a multitude of complaints about performance issues ETC. You may be able to drive a nail with a screwdriver but it&#x27;s not a good idea.</div><br/><div id="38419341" class="c"><input type="checkbox" id="c-38419341" checked=""/><div class="controls bullet"><span class="by">v3ss0n</span><span>|</span><a href="#38419270">parent</a><span>|</span><a href="#38419332">next</a><span>|</span><label class="collapse" for="c-38419341">[-]</label><label class="expand" for="c-38419341">[1 more]</label></div><br/><div class="children"><div class="content">Only applies to docker.<p>LXC for example designed container like a VM</div><br/></div></div></div></div><div id="38419332" class="c"><input type="checkbox" id="c-38419332" checked=""/><div class="controls bullet"><span class="by">Xeamek</span><span>|</span><a href="#38419270">prev</a><span>|</span><a href="#38420088">next</a><span>|</span><label class="collapse" for="c-38419332">[-]</label><label class="expand" for="c-38419332">[1 more]</label></div><br/><div class="children"><div class="content">The curse of docker is that it allows devs to be lazy and rather then making sure their configuration and deployment are straightforward, they get to keep all their mess working (longer).<p>Ofcourse, if you have really complex setup docker is invaluable.
But if all you are using it is to make the depreciation warnings go away on your single executable app, that&#x27;s just abuse of the tool for the wrong reasons</div><br/></div></div><div id="38420088" class="c"><input type="checkbox" id="c-38420088" checked=""/><div class="controls bullet"><span class="by">PreInternet01</span><span>|</span><a href="#38419332">prev</a><span>|</span><a href="#38419204">next</a><span>|</span><label class="collapse" for="c-38420088">[-]</label><label class="expand" for="c-38420088">[1 more]</label></div><br/><div class="children"><div class="content">&gt; distributing an application only as a Docker image is often evidence of a relatively immature project<p>Or, you know, a contractual requirement. And, as far as those go, I actually kind of like it: you ship a well-tested container, and the only thing the infra dept at the customer site has to configure-via-the-environment is the URL for (or path to, via any kind of supported file system mounted into the container, which most IT shops can still <i>just about</i> manage) the instance configuration file.<p>This reduces most initial troubleshooting to &quot;well, what does the instance log say about retrieving and parsing the configuration file?&quot;, which, trust me, is <i>way</i> preferable over what you get with most other deployment methods I&#x27;ve been involved with...</div><br/></div></div><div id="38419204" class="c"><input type="checkbox" id="c-38419204" checked=""/><div class="controls bullet"><span class="by">teddyh</span><span>|</span><a href="#38420088">prev</a><span>|</span><a href="#38419515">next</a><span>|</span><label class="collapse" for="c-38419204">[-]</label><label class="expand" for="c-38419204">[3 more]</label></div><br/><div class="children"><div class="content">In the old days, the age-old cry of the beleaguered developer was “My code isn’t buggy, it works on my machine!”, to which the response was “We’re not shipping your machine to the customer!”.  Well, science marches on, and we’ve invented a way to do exactly that.  Instead of, you know, writing actually robust and simple-to-deploy software.<p>See also: &lt;<a href="https:&#x2F;&#x2F;blog.brixit.nl&#x2F;developers-are-lazy-thus-flatpak&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;blog.brixit.nl&#x2F;developers-are-lazy-thus-flatpak&#x2F;</a>&gt;</div><br/><div id="38419497" class="c"><input type="checkbox" id="c-38419497" checked=""/><div class="controls bullet"><span class="by">viraptor</span><span>|</span><a href="#38419204">parent</a><span>|</span><a href="#38419515">next</a><span>|</span><label class="collapse" for="c-38419497">[-]</label><label class="expand" for="c-38419497">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Instead of, you know, writing actually robust and simple-to-deploy software.<p>This is unfortunately much harder to do than doing docker images. If you&#x27;re trying to ship a robust and simple to deploy app, you will fail at some point - you just haven&#x27;t seen a system where that happens yet. You can&#x27;t be robust vs unknown unknowns and what a system will look like in a couple of years (next LTS) can be very surprising.</div><br/><div id="38419550" class="c"><input type="checkbox" id="c-38419550" checked=""/><div class="controls bullet"><span class="by">teddyh</span><span>|</span><a href="#38419204">root</a><span>|</span><a href="#38419497">parent</a><span>|</span><a href="#38419515">next</a><span>|</span><label class="collapse" for="c-38419550">[-]</label><label class="expand" for="c-38419550">[1 more]</label></div><br/><div class="children"><div class="content">Hacking on some code and making random changes until it works (”It works!  Ship it!”) is much easier (or at least feels easier) than designing the code carefully and using tests to verify the correctness of our code.  Yet for good reasons we do it the harder way.  For mostly the same reasons, I’m very wary of a system image of some pre-installed software instead of packaged software which is meant to run in a variety of environments, and to be easily configured to do so.<p>Note also that a system which is robust and adaptive to different environments today is <i>also</i> robust to different <i>future</i> environments.  And nobody can escape the march of time.  Everybody needs updates.  TLS updates.  Time zone updates.  Security fixes.  I’d rather have a system designed with robustness against differences as a primary concern than a system where it’s <i>assumed</i> that it will run in an unchanging static universe.</div><br/></div></div></div></div></div></div><div id="38419515" class="c"><input type="checkbox" id="c-38419515" checked=""/><div class="controls bullet"><span class="by">eviks</span><span>|</span><a href="#38419204">prev</a><span>|</span><a href="#38419700">next</a><span>|</span><label class="collapse" for="c-38419515">[-]</label><label class="expand" for="c-38419515">[3 more]</label></div><br/><div class="children"><div class="content">Has any great design been invented that isn&#x27;t tied to hardcoded paths preventing multiple versions of the same library etc and would allow easy linking to any version? Nix? Anything else?</div><br/><div id="38419587" class="c"><input type="checkbox" id="c-38419587" checked=""/><div class="controls bullet"><span class="by">nusmella</span><span>|</span><a href="#38419515">parent</a><span>|</span><a href="#38420020">next</a><span>|</span><label class="collapse" for="c-38419587">[-]</label><label class="expand" for="c-38419587">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t know if this is normal or if anyone else does it but I usually either download binaries or compile from source and move the executable to &#x2F;usr&#x2F;local&#x2F;bin&#x2F; and create a symlink. Lets me easily switch between versions. I avoid using a package manager for anything where I want control over the version and installation.<p>- curl -fSLJO $RELEASE<p>- tar xvf $DOWNLOAD.tar.gz &amp;&amp; cd $DOWNLOAD`<p>- make .<p>- mv $EXECUTABLE &#x2F;usr&#x2F;local&#x2F;bin&#x2F;$EXECUTABLE-$VERSION`<p>- ln -s &#x2F;usr&#x2F;local&#x2F;bin&#x2F;$EXECUTABLE-$VERSION &#x2F;usr&#x2F;local&#x2F;bin&#x2F;$EXECUTABLE<p>- # chmod 750, chown root:$appuser, etc<p>Works great for everything I&#x27;ve tried thus far. Redis, HAproy, Prometheus exporters, and many more.</div><br/></div></div><div id="38420020" class="c"><input type="checkbox" id="c-38420020" checked=""/><div class="controls bullet"><span class="by">oddmiral</span><span>|</span><a href="#38419515">parent</a><span>|</span><a href="#38419587">prev</a><span>|</span><a href="#38419700">next</a><span>|</span><label class="collapse" for="c-38420020">[-]</label><label class="expand" for="c-38420020">[1 more]</label></div><br/><div class="children"><div class="content">Yes, these &quot;great designs&quot; are invented at a constant rate. I saw about 30 of them, or 1 per year at average. For example, Fedora invented and then abandoned modular design recently.</div><br/></div></div></div></div><div id="38419700" class="c"><input type="checkbox" id="c-38419700" checked=""/><div class="controls bullet"><span class="by">steve1977</span><span>|</span><a href="#38419515">prev</a><span>|</span><a href="#38419888">next</a><span>|</span><label class="collapse" for="c-38419700">[-]</label><label class="expand" for="c-38419700">[2 more]</label></div><br/><div class="children"><div class="content">It seems to me that many of the points in the article are not really problems with Docker, but problems with Linux.<p>I.e. the way Linux handles multiple versions of libraries and of course the fragmentation hell that is Linux distributions.<p>Docker then is just a bandaid for these problems.</div><br/><div id="38420180" class="c"><input type="checkbox" id="c-38420180" checked=""/><div class="controls bullet"><span class="by">oddmiral</span><span>|</span><a href="#38419700">parent</a><span>|</span><a href="#38419888">next</a><span>|</span><label class="collapse" for="c-38420180">[-]</label><label class="expand" for="c-38420180">[1 more]</label></div><br/><div class="children"><div class="content">Linux (kernel) can run any libraries in any combination. You are talking about distributions. Support for multiple versions of a library is not a goal for a typical distribution. Typically, this is necessary for commercial software vendors, which have money to throw at the problem. If commercial software vendors needs this so badly, they can sign a support contract with distributor, so a dedicated team of maintainers will care about this problem with libraries for them.<p>In the open-source world, it&#x27;s an order of magnitude easier to patch the source, than introduce two versions of a same library. In rare cases, a -compat package is created, which then abandoned as soon as possible.</div><br/></div></div></div></div><div id="38419888" class="c"><input type="checkbox" id="c-38419888" checked=""/><div class="controls bullet"><span class="by">INTPenis</span><span>|</span><a href="#38419700">prev</a><span>|</span><a href="#38419267">next</a><span>|</span><label class="collapse" for="c-38419888">[-]</label><label class="expand" for="c-38419888">[1 more]</label></div><br/><div class="children"><div class="content">The curse of that website, it made me dizzy just scrolling.<p>Containers are amazing, they&#x27;re bigger than docker, end of story.</div><br/></div></div><div id="38419267" class="c"><input type="checkbox" id="c-38419267" checked=""/><div class="controls bullet"><span class="by">jrm4</span><span>|</span><a href="#38419888">prev</a><span>|</span><a href="#38419285">next</a><span>|</span><label class="collapse" for="c-38419267">[-]</label><label class="expand" for="c-38419267">[1 more]</label></div><br/><div class="children"><div class="content">Did the author say anything actually negative about Docker? All I saw was &quot;Docker can be suboptimal&quot; but nothing to suggest that it has been anything other than at least a partial improvement?</div><br/></div></div><div id="38419285" class="c"><input type="checkbox" id="c-38419285" checked=""/><div class="controls bullet"><span class="by">kapitanjakc</span><span>|</span><a href="#38419267">prev</a><span>|</span><a href="#38420053">next</a><span>|</span><label class="collapse" for="c-38419285">[-]</label><label class="expand" for="c-38419285">[1 more]</label></div><br/><div class="children"><div class="content">Docker containers and images have saved me a lot of shipping pain in web part.<p>I haven&#x27;t come across them being used as package manager or distributors yet.</div><br/></div></div><div id="38420053" class="c"><input type="checkbox" id="c-38420053" checked=""/><div class="controls bullet"><span class="by">smitty1e</span><span>|</span><a href="#38419285">prev</a><span>|</span><a href="#38420139">next</a><span>|</span><label class="collapse" for="c-38420053">[-]</label><label class="expand" for="c-38420053">[1 more]</label></div><br/><div class="children"><div class="content">Great read. If I had to quibble, it would be with<p>&gt; Even if 90-day ephemeral TLS certificates and a general atmosphere of laziness have deteriorated our discipline in this regard, private key material should be closely guarded. It should be stored in only one place and accessible to only one principal. You don&#x27;t even have to get into these types of lofty security concerns, though. TLS is also sort of complicated to configure.<p>Any time there is complexity and only the One True Priest can manage it, there will be tears.<p>There had better be a break glass solution backed by Righteous Documentation (a hypothetical substance I heard about this one time) if we are boxed in to a One True Priest situation.</div><br/></div></div><div id="38420139" class="c"><input type="checkbox" id="c-38420139" checked=""/><div class="controls bullet"><span class="by">saidinesh5</span><span>|</span><a href="#38420053">prev</a><span>|</span><a href="#38419487">next</a><span>|</span><label class="collapse" for="c-38420139">[-]</label><label class="expand" for="c-38420139">[1 more]</label></div><br/><div class="children"><div class="content">Obligatory Hitler uses Docker post: <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=PivpCKEiQOQ" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=PivpCKEiQOQ</a><p>Lol @  &quot;I&#x27;m moving everyone to Windows! Don&#x27;t cry, you can run bash on Windows 10 now.&quot;</div><br/></div></div></div></div></div></div></div></body></html>