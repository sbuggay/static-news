<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1689757254306" as="style"/><link rel="stylesheet" href="styles.css?v=1689757254306"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://arxiv.org/abs/2307.09009">How is ChatGPT&#x27;s behavior changing over time?</a> <span class="domain">(<a href="https://arxiv.org">arxiv.org</a>)</span></div><div class="subtext"><span>tim_sw</span> | <span>95 comments</span></div><br/><div><div id="36781559" class="c"><input type="checkbox" id="c-36781559" checked=""/><div class="controls bullet"><span class="by">dudeinhawaii</span><span>|</span><a href="#36781968">next</a><span>|</span><label class="collapse" for="c-36781559">[-]</label><label class="expand" for="c-36781559">[25 more]</label></div><br/><div class="children"><div class="content">I think we should stop trying to quiz LLMs on mathematics, something for which they are explicitly not designed to do with their tokenized view of the world. Ask GPT-4 to use its Wolfram plugin and it returns the answers quickly and correctly.<p>Second, I think the code generation bit of this paper is blown out of proportion. The code can&#x27;t be immediately injected into a codebase due to a formatting change (triple quotes). I&#x27;d be more interested in changes to the quality and performance of the code generated, not whether it can be easily copy&#x2F;pasted from the page.<p>I could not replicate that result (but could replicate the other math issues). I&#x27;ve also never seen the triple quotes in results so it&#x27;s unclear if there was a temporary presentation bug.</div><br/><div id="36782244" class="c"><input type="checkbox" id="c-36782244" checked=""/><div class="controls bullet"><span class="by">xp84</span><span>|</span><a href="#36781559">parent</a><span>|</span><a href="#36783048">next</a><span>|</span><label class="collapse" for="c-36782244">[-]</label><label class="expand" for="c-36782244">[11 more]</label></div><br/><div class="children"><div class="content">Seriously. GPT doing math is like using a 737 to drive around on the ground, or if you had the phone number of a prominent astrophysicist and you call him to do long division for you. Wtf is the point. We have computer things to do every math problem. It’s a waste of energy to use LLMs for it in my opinion.</div><br/><div id="36783654" class="c"><input type="checkbox" id="c-36783654" checked=""/><div class="controls bullet"><span class="by">reportgunner</span><span>|</span><a href="#36781559">root</a><span>|</span><a href="#36782244">parent</a><span>|</span><a href="#36783406">next</a><span>|</span><label class="collapse" for="c-36783654">[-]</label><label class="expand" for="c-36783654">[1 more]</label></div><br/><div class="children"><div class="content">What is the point of doing anything if you can&#x27;t use flashy technologies ? Leave that to the old people. &#x2F;s</div><br/></div></div><div id="36783406" class="c"><input type="checkbox" id="c-36783406" checked=""/><div class="controls bullet"><span class="by">theelous3</span><span>|</span><a href="#36781559">root</a><span>|</span><a href="#36782244">parent</a><span>|</span><a href="#36783654">prev</a><span>|</span><a href="#36782306">next</a><span>|</span><label class="collapse" for="c-36783406">[-]</label><label class="expand" for="c-36783406">[1 more]</label></div><br/><div class="children"><div class="content">The point of doing $non-llm-optimal-thing on an llm is the hope that it let&#x27;s you skip on formal syntaxes, which are mentally taxing.<p>It&#x27;s far easier even for an expert to communicate what they want in natural language than it is in a formal syntax for all but the most trivial things.<p>It should be a goal of these tools to do this correctly.</div><br/></div></div><div id="36782306" class="c"><input type="checkbox" id="c-36782306" checked=""/><div class="controls bullet"><span class="by">sheepscreek</span><span>|</span><a href="#36781559">root</a><span>|</span><a href="#36782244">parent</a><span>|</span><a href="#36783406">prev</a><span>|</span><a href="#36782446">next</a><span>|</span><label class="collapse" for="c-36782306">[-]</label><label class="expand" for="c-36782306">[2 more]</label></div><br/><div class="children"><div class="content">A better example would be - calling your guitar lessons teacher for help on a statistics problem.</div><br/><div id="36783262" class="c"><input type="checkbox" id="c-36783262" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#36781559">root</a><span>|</span><a href="#36782306">parent</a><span>|</span><a href="#36782446">next</a><span>|</span><label class="collapse" for="c-36783262">[-]</label><label class="expand" for="c-36783262">[1 more]</label></div><br/><div class="children"><div class="content">Possibly more like instantiating the statistics problem by getting, say, every 3 members of an orchestra to represent a triplet of doors in the Monty Hall problem and then making a ball-park guess what the results are from a seat in the middle of the back row.</div><br/></div></div></div></div><div id="36782446" class="c"><input type="checkbox" id="c-36782446" checked=""/><div class="controls bullet"><span class="by">lumost</span><span>|</span><a href="#36781559">root</a><span>|</span><a href="#36782244">parent</a><span>|</span><a href="#36782306">prev</a><span>|</span><a href="#36783048">next</a><span>|</span><label class="collapse" for="c-36782446">[-]</label><label class="expand" for="c-36782446">[6 more]</label></div><br/><div class="children"><div class="content">I used GPT-4 to generate a non-cryptographic random 64 character string. It was faster to ask GPT-4 for the string than ask GPT-4 for the instructions to generate the string from my terminal. GPT-4 was faster than google.</div><br/><div id="36783663" class="c"><input type="checkbox" id="c-36783663" checked=""/><div class="controls bullet"><span class="by">reportgunner</span><span>|</span><a href="#36781559">root</a><span>|</span><a href="#36782446">parent</a><span>|</span><a href="#36783156">next</a><span>|</span><label class="collapse" for="c-36783663">[-]</label><label class="expand" for="c-36783663">[1 more]</label></div><br/><div class="children"><div class="content">Were you in a room that had it&#x27;s walls slowly caving in like in indiana jones or why does it matter that it was faster ?</div><br/></div></div><div id="36783156" class="c"><input type="checkbox" id="c-36783156" checked=""/><div class="controls bullet"><span class="by">oefnak</span><span>|</span><a href="#36781559">root</a><span>|</span><a href="#36782446">parent</a><span>|</span><a href="#36783663">prev</a><span>|</span><a href="#36783309">next</a><span>|</span><label class="collapse" for="c-36783156">[-]</label><label class="expand" for="c-36783156">[1 more]</label></div><br/><div class="children"><div class="content">That definitely won&#x27;t be random.</div><br/></div></div><div id="36783309" class="c"><input type="checkbox" id="c-36783309" checked=""/><div class="controls bullet"><span class="by">deafpolygon</span><span>|</span><a href="#36781559">root</a><span>|</span><a href="#36782446">parent</a><span>|</span><a href="#36783156">prev</a><span>|</span><a href="#36783268">next</a><span>|</span><label class="collapse" for="c-36783309">[-]</label><label class="expand" for="c-36783309">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think this will be a truly random string.</div><br/></div></div><div id="36783268" class="c"><input type="checkbox" id="c-36783268" checked=""/><div class="controls bullet"><span class="by">dgb23</span><span>|</span><a href="#36781559">root</a><span>|</span><a href="#36782446">parent</a><span>|</span><a href="#36783309">prev</a><span>|</span><a href="#36783141">next</a><span>|</span><label class="collapse" for="c-36783268">[-]</label><label class="expand" for="c-36783268">[1 more]</label></div><br/><div class="children"><div class="content">That’s likely a very good example of the limitations of LLMs.</div><br/></div></div><div id="36783141" class="c"><input type="checkbox" id="c-36783141" checked=""/><div class="controls bullet"><span class="by">ThrowawayTestr</span><span>|</span><a href="#36781559">root</a><span>|</span><a href="#36782446">parent</a><span>|</span><a href="#36783268">prev</a><span>|</span><a href="#36783048">next</a><span>|</span><label class="collapse" for="c-36783141">[-]</label><label class="expand" for="c-36783141">[1 more]</label></div><br/><div class="children"><div class="content">Surely navigating to random.org is faster than typing a prompt.</div><br/></div></div></div></div></div></div><div id="36783048" class="c"><input type="checkbox" id="c-36783048" checked=""/><div class="controls bullet"><span class="by">deelly</span><span>|</span><a href="#36781559">parent</a><span>|</span><a href="#36782244">prev</a><span>|</span><a href="#36781922">next</a><span>|</span><label class="collapse" for="c-36783048">[-]</label><label class="expand" for="c-36783048">[1 more]</label></div><br/><div class="children"><div class="content">No, we definitely should continue to quiz LLMs on mathematics and absolutely any other topics. Otherwise how do we know and understand limitation of the system?</div><br/></div></div><div id="36781922" class="c"><input type="checkbox" id="c-36781922" checked=""/><div class="controls bullet"><span class="by">ehnto</span><span>|</span><a href="#36781559">parent</a><span>|</span><a href="#36783048">prev</a><span>|</span><a href="#36783410">next</a><span>|</span><label class="collapse" for="c-36781922">[-]</label><label class="expand" for="c-36781922">[2 more]</label></div><br/><div class="children"><div class="content">I think knowing if the code can be used verbatim is actually the more important part practically speaking. That is the actually useful part.<p>Quality is important to humans, because humans have to read it, but correctness is what people using ChatGPT for code actually need. So long as the quality and performance is good enough, then it will be useful.<p>Performance is such a nuanced topic that you need very context aware devs anyway, and I think a general purpose LLM is never going to have that kind of awareness.</div><br/><div id="36782720" class="c"><input type="checkbox" id="c-36782720" checked=""/><div class="controls bullet"><span class="by">staunton</span><span>|</span><a href="#36781559">root</a><span>|</span><a href="#36781922">parent</a><span>|</span><a href="#36783410">next</a><span>|</span><label class="collapse" for="c-36782720">[-]</label><label class="expand" for="c-36782720">[1 more]</label></div><br/><div class="children"><div class="content">&gt; never going to have that kind of awareness<p>Be careful with that goalpost, it might make sudden movements.</div><br/></div></div></div></div><div id="36783410" class="c"><input type="checkbox" id="c-36783410" checked=""/><div class="controls bullet"><span class="by">dr_dshiv</span><span>|</span><a href="#36781559">parent</a><span>|</span><a href="#36781922">prev</a><span>|</span><a href="#36783169">next</a><span>|</span><label class="collapse" for="c-36783410">[-]</label><label class="expand" for="c-36783410">[1 more]</label></div><br/><div class="children"><div class="content">They should stop teaching math to kids for the same reason. Just give them a calculator! Or show us the evidence that math education improves cognitive abilities in other domains.</div><br/></div></div><div id="36783169" class="c"><input type="checkbox" id="c-36783169" checked=""/><div class="controls bullet"><span class="by">dontupvoteme</span><span>|</span><a href="#36781559">parent</a><span>|</span><a href="#36783410">prev</a><span>|</span><a href="#36781708">next</a><span>|</span><label class="collapse" for="c-36783169">[-]</label><label class="expand" for="c-36783169">[4 more]</label></div><br/><div class="children"><div class="content">Could not agree more. It doesn&#x27;t understand what a number is, why is everyone trying to quiz it on maths instead of, perhaps, seeing how good it is at language tasks, or even foreign languages?  I suspect it has gotten a lot worse in non-english since launch.</div><br/><div id="36783634" class="c"><input type="checkbox" id="c-36783634" checked=""/><div class="controls bullet"><span class="by">gwd</span><span>|</span><a href="#36781559">root</a><span>|</span><a href="#36783169">parent</a><span>|</span><a href="#36783189">next</a><span>|</span><label class="collapse" for="c-36783634">[-]</label><label class="expand" for="c-36783634">[1 more]</label></div><br/><div class="children"><div class="content">Why do you think this?<p>FWIW I use GPT-4 regularly to explain Koine Greek from the New Testament to me; its ability there certainly hasn&#x27;t diminished in the last two months.</div><br/></div></div><div id="36783189" class="c"><input type="checkbox" id="c-36783189" checked=""/><div class="controls bullet"><span class="by">delusional</span><span>|</span><a href="#36781559">root</a><span>|</span><a href="#36783169">parent</a><span>|</span><a href="#36783634">prev</a><span>|</span><a href="#36781708">next</a><span>|</span><label class="collapse" for="c-36783189">[-]</label><label class="expand" for="c-36783189">[2 more]</label></div><br/><div class="children"><div class="content">it &quot;understands&quot; numbers the exact same amount that it understands words.</div><br/><div id="36783208" class="c"><input type="checkbox" id="c-36783208" checked=""/><div class="controls bullet"><span class="by">vermilingua</span><span>|</span><a href="#36781559">root</a><span>|</span><a href="#36783189">parent</a><span>|</span><a href="#36781708">next</a><span>|</span><label class="collapse" for="c-36783208">[-]</label><label class="expand" for="c-36783208">[1 more]</label></div><br/><div class="children"><div class="content">Well, no, because numbers are “words” that represent something that behaves in a very different way to words in a sentance.</div><br/></div></div></div></div></div></div><div id="36781708" class="c"><input type="checkbox" id="c-36781708" checked=""/><div class="controls bullet"><span class="by">sanxiyn</span><span>|</span><a href="#36781559">parent</a><span>|</span><a href="#36783169">prev</a><span>|</span><a href="#36783546">next</a><span>|</span><label class="collapse" for="c-36781708">[-]</label><label class="expand" for="c-36781708">[4 more]</label></div><br/><div class="children"><div class="content">Or OpenAI can stop being stupid and adopt LLaMA-like tokenization, which special cases numbers and tokenize them into individual digits.</div><br/><div id="36781768" class="c"><input type="checkbox" id="c-36781768" checked=""/><div class="controls bullet"><span class="by">jinay</span><span>|</span><a href="#36781559">root</a><span>|</span><a href="#36781708">parent</a><span>|</span><a href="#36781776">next</a><span>|</span><label class="collapse" for="c-36781768">[-]</label><label class="expand" for="c-36781768">[1 more]</label></div><br/><div class="children"><div class="content">Are LLaMA-based models better at math because of this digit-based tokenization?</div><br/></div></div><div id="36781776" class="c"><input type="checkbox" id="c-36781776" checked=""/><div class="controls bullet"><span class="by">bugglebeetle</span><span>|</span><a href="#36781559">root</a><span>|</span><a href="#36781708">parent</a><span>|</span><a href="#36781768">prev</a><span>|</span><a href="#36783546">next</a><span>|</span><label class="collapse" for="c-36781776">[-]</label><label class="expand" for="c-36781776">[2 more]</label></div><br/><div class="children"><div class="content">Isn’t the tokenization tied to the training of the model?</div><br/><div id="36782360" class="c"><input type="checkbox" id="c-36782360" checked=""/><div class="controls bullet"><span class="by">colobas</span><span>|</span><a href="#36781559">root</a><span>|</span><a href="#36781776">parent</a><span>|</span><a href="#36783546">next</a><span>|</span><label class="collapse" for="c-36782360">[-]</label><label class="expand" for="c-36782360">[1 more]</label></div><br/><div class="children"><div class="content">The model learns an embedding table, where (roughly) each row is used as the model’s internal representation of each token. The numbers in that table are learned. What isn’t learned is the map from token (i.e. combination of characters&#x2F;byte-pairs) to row-index in the embedding table. That is given by tokenization<p>EDIT: removed redundant bit</div><br/></div></div></div></div></div></div><div id="36783546" class="c"><input type="checkbox" id="c-36783546" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#36781559">parent</a><span>|</span><a href="#36781708">prev</a><span>|</span><a href="#36781968">next</a><span>|</span><label class="collapse" for="c-36783546">[-]</label><label class="expand" for="c-36783546">[1 more]</label></div><br/><div class="children"><div class="content">In terms of evaluating LLMs, I&#x27;d argue quizzing them on maths is still better than the other thing people keep doing - quizzing them on facts and self-contradicting scenarios, hoping to get them to only either recall information perfectly, or answer with &quot;I don&#x27;t know&quot;.<p>I&#x27;m not an AI&#x2F;ML scientist, so I may be way off mark here, but everything I&#x27;ve read so far, and all my experience playing with GPT-3.5 and GPT-4, tell me that comparing performance of an LLM to that of a human is a category error, because the LLM isn&#x27;t a good analogue of a <i>whole</i> human mind - but it&#x27;s a very good analogue to human <i>inner voice</i>. The stream of consciousness. The whatever-it-is that surfaces your unconscious&#x2F;subconscious thought process in form of words and sentences.<p>The inner voice is fast, it&#x27;s reactive. It generates thoughts that match the situation, whether they&#x27;re correct or factually accurate or not. It&#x27;s up to the conscious part of your mind to stop, refine, or recycle those thoughts. If you let it keep going, it&#x27;ll give you thoughts based on what <i>feels like</i> should follow the thoughts that came before. And, unless you habituated responding to anything new with &quot;I don&#x27;t know&quot; followed by ignoring the topic, the inner voice will start blurting answers to what looks like a question&#x2F;problem statement; whether or not they&#x27;ll make any sense, depends on your familiarity with the topic in question.<p>Pretty much 1:1 what LLMs do.<p>Now, this could all be noise, but I don&#x27;t think so. I know not everyone has a distinct inner narrative (much like not everyone can visualize things in their mind - I can&#x27;t), but many (most?) people do. The description of the &quot;inner voice experience&quot; I gave above is something I figured out over a decade ago - before LLMs or even deep learning were a thing, before I knew anything about the NLP beyond recognizing the term &quot;Markov chain&quot; is somehow related. Could my inner narration style be unique? Possibly, but given how advice to avoid connecting your inner voice directly with your vocal apparatus is deeply infused in culture and literature, I strongly suspect this is just how it works.<p>All this to say: it is my hypothesis, so far corroborated by experience, that when you start feeding absurd amount of unlabeled text to a transformer model, letting it pick up on the structures encoded within, what you get is a close equivalent to our own inner voice - the part that deals with associations, not logic or data storage. You can&#x27;t expect it to get good at performing arbitrary computation or recalling data with perfect fidelity, because it&#x27;s structurally not what it&#x27;s suited for. For humans, performing arbitrary calculations or perfect recall requires engaging a slower, more algorithmic thinking process (and&#x2F;or external memory). That part is currently missing in the LLM-based AI systems we&#x27;re playing with.</div><br/></div></div></div></div><div id="36781968" class="c"><input type="checkbox" id="c-36781968" checked=""/><div class="controls bullet"><span class="by">randomwalker</span><span>|</span><a href="#36781559">prev</a><span>|</span><a href="#36783661">next</a><span>|</span><label class="collapse" for="c-36781968">[-]</label><label class="expand" for="c-36781968">[1 more]</label></div><br/><div class="children"><div class="content">This paper is being misinterpreted. The degradations reported are somewhat peculiar to the authors&#x27; task selection and evaluation method and can easily result from fine tuning rather than intentionally degrading GPT-4&#x27;s performance for cost saving reasons.<p>They report 2 degradations: code generation &amp; math problems. In both cases, they report a <i>behavior change</i> (likely fine tuning) rather than a <i>capability decrease</i> (possibly intentional degradation). The paper confuses these a bit: they mostly say behavior, including in the title, but the intro says capability in a couple of places.<p>Code generation: the change they report is that the newer GPT-4 adds non-code text to its output. They don&#x27;t evaluate the correctness of the code. They merely check if the code is directly executable. So the newer model&#x27;s attempt to be more helpful counted against it.<p>Math problems (primality checking): to solve this the model needs to do chain of thought. For some weird reason, the newer model doesn&#x27;t seem to do so when asked to think step by step (but the current ChatGPT-4 does, as you can easily check). The paper doesn&#x27;t say that the accuracy is worse <i>conditional on doing CoT</i>.<p>The other two tasks are visual reasoning and answering sensitive questions. On the former, they report a slight improvement. On the latter, they report that the filters are much more effective — unsurprising since we know that OpenAI has been heavily tweaking these.<p>In short, everything in the paper is consistent with fine tuning. It is possible that OpenAI is gaslighting everyone by denying that they degraded performance for cost saving purposes — but if so, this paper doesn&#x27;t provide evidence of it. Still, it&#x27;s a fascinating study of the unintended consequences of model updates.</div><br/></div></div><div id="36783661" class="c"><input type="checkbox" id="c-36783661" checked=""/><div class="controls bullet"><span class="by">ChemSpider</span><span>|</span><a href="#36781968">prev</a><span>|</span><a href="#36782665">next</a><span>|</span><label class="collapse" for="c-36783661">[-]</label><label class="expand" for="c-36783661">[1 more]</label></div><br/><div class="children"><div class="content">For _medical_ questions, the public version of ChatGPT has become useless. Even a simple question such as &quot;What are the typical side effects of XYZ&quot; is answered with a gigantic disclaimer and then often a fancy version of &quot;I am not sure&quot;. Yeah, that much I knew already.<p>It used to be better in the past.</div><br/></div></div><div id="36782665" class="c"><input type="checkbox" id="c-36782665" checked=""/><div class="controls bullet"><span class="by">spiritplumber</span><span>|</span><a href="#36783661">prev</a><span>|</span><a href="#36782403">next</a><span>|</span><label class="collapse" for="c-36782665">[-]</label><label class="expand" for="c-36782665">[1 more]</label></div><br/><div class="children"><div class="content">And even the lecturers acquiesced when they found that a lecture on the sea was none the less stimulating when compiled out of other lectures that had already been delivered on the same subject. “Beware of first-hand ideas!” exclaimed one of the most advanced of them. “First-hand ideas do not really exist. They are but the physical impressions produced by love and fear, and on this gross foundation who could erect a philosophy? Let your ideas be second-hand, and if possible tenth-hand, for then they will be far removed from that disturbing element — direct observation. Do not learn anything about this subject of mine — the French Revolution. Learn instead what I think
that Enicharmon thought Urizen thought Gutch thought Ho-Yung thought Chi-Bo-Sing thought Lafcadio Hearn thought Carlyle thought Mirabeau said about the French Revolution. Through the medium of these ten great minds, the blood that was shed at Paris and the windows that were broken at Versailles will be clarified to an idea which you may employ most profitably in your daily lives. But be sure that the intermediates are many and varied, for in history one authority exists to counteract another. Urizen must counteract the scepticism of Ho-Yung and Enicharmon, I must myself counteract the impetuosity of Gutch. You who listen to me are in a better position to judge about the French Revolution than I am. Your descendants will be even in a better position than you, for they will learn what you think I think, and yet another intermediate will be added to the chain. And in time” — his voice rose — “there will come a generation that had got beyond facts, beyond impressions, a generation absolutely colourless, a generation ‘seraphically free From taint of personality,’ which will see the French Revolution not as it happened, nor as they would like it to have happened, but as it would have happened, had it taken place in the days of the Machine.”<p>E M Forster, &quot;The Machine Stops&quot;, 1909</div><br/></div></div><div id="36782403" class="c"><input type="checkbox" id="c-36782403" checked=""/><div class="controls bullet"><span class="by">barrkel</span><span>|</span><a href="#36782665">prev</a><span>|</span><a href="#36781788">next</a><span>|</span><label class="collapse" for="c-36782403">[-]</label><label class="expand" for="c-36782403">[8 more]</label></div><br/><div class="children"><div class="content">Irritatingly, OpenAI reps deny any change in model capabilities over time. It&#x27;s more likely that as the models are optimized for cost and performance, their in-house evaluation metrics don&#x27;t cover everything customers are interested in. Meanwhile, the probabilistic nature of LLM output means there is plausible deniability.</div><br/><div id="36783274" class="c"><input type="checkbox" id="c-36783274" checked=""/><div class="controls bullet"><span class="by">JanSt</span><span>|</span><a href="#36782403">parent</a><span>|</span><a href="#36782508">next</a><span>|</span><label class="collapse" for="c-36783274">[-]</label><label class="expand" for="c-36783274">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m now sometimes using GPT3.5 because it produces better results than GPT4. GPT4 was amazing when it first came out for me. Either it has deteriorated or I was lucky in the beginning and am now lucky with GPT3.5 from time to time.</div><br/></div></div><div id="36782508" class="c"><input type="checkbox" id="c-36782508" checked=""/><div class="controls bullet"><span class="by">NLPaep</span><span>|</span><a href="#36782403">parent</a><span>|</span><a href="#36783274">prev</a><span>|</span><a href="#36781788">next</a><span>|</span><label class="collapse" for="c-36782508">[-]</label><label class="expand" for="c-36782508">[6 more]</label></div><br/><div class="children"><div class="content">Source? They’ve only denied the API model changing. Not the website.</div><br/><div id="36782546" class="c"><input type="checkbox" id="c-36782546" checked=""/><div class="controls bullet"><span class="by">barrkel</span><span>|</span><a href="#36782403">root</a><span>|</span><a href="#36782508">parent</a><span>|</span><a href="#36781788">next</a><span>|</span><label class="collapse" for="c-36782546">[-]</label><label class="expand" for="c-36782546">[5 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;twitter.com&#x2F;npew&#x2F;status&#x2F;1679538687854661637?t=3CLXlTzccRu-NthzF9ZXOw&amp;s=19" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;npew&#x2F;status&#x2F;1679538687854661637?t=3CLXlT...</a></div><br/><div id="36782633" class="c"><input type="checkbox" id="c-36782633" checked=""/><div class="controls bullet"><span class="by">blowski</span><span>|</span><a href="#36782403">root</a><span>|</span><a href="#36782546">parent</a><span>|</span><a href="#36781788">next</a><span>|</span><label class="collapse" for="c-36782633">[-]</label><label class="expand" for="c-36782633">[4 more]</label></div><br/><div class="children"><div class="content">(Tweet contents)<p>&gt; No, we haven&#x27;t made GPT-4 dumber. Quite the opposite: we make each new version smarter than the previous one.
&gt; Current hypothesis: When you use it more heavily, you start noticing issues you didn&#x27;t see before.<p>I don’t see how it supports your argument. Your comment says “they deny making changes to GPT-4”, and the tweet says “we are making incremental improvements to GPT-4”.</div><br/><div id="36782872" class="c"><input type="checkbox" id="c-36782872" checked=""/><div class="controls bullet"><span class="by">esperent</span><span>|</span><a href="#36782403">root</a><span>|</span><a href="#36782633">parent</a><span>|</span><a href="#36781788">next</a><span>|</span><label class="collapse" for="c-36782872">[-]</label><label class="expand" for="c-36782872">[3 more]</label></div><br/><div class="children"><div class="content">It&#x27;s important to read company marketing statements as if you were a lawyer. We haven&#x27;t made <i>GPT-4</i> dumber != We haven&#x27;t made <i>ChatGPT(4)</i> dumber.<p>Personal hypothesis is that they have made a few changes to ChatGPT recently - possibly quantization, and almost certainly some tweaks to make it give shorter&#x2F;less detailed answers.<p>But by the nature of a probibalistic tool being run by a secretive company, it&#x27;s hard to say for sure. Maybe I and everyone else complaining have just started to get unlucky answers.</div><br/><div id="36783179" class="c"><input type="checkbox" id="c-36783179" checked=""/><div class="controls bullet"><span class="by">dontupvoteme</span><span>|</span><a href="#36782403">root</a><span>|</span><a href="#36782872">parent</a><span>|</span><a href="#36783279">next</a><span>|</span><label class="collapse" for="c-36783179">[-]</label><label class="expand" for="c-36783179">[1 more]</label></div><br/><div class="children"><div class="content">They&#x27;re also going to claim &quot;that&#x27;s alignment, we&#x27;re making it less evil, not dumber&quot;</div><br/></div></div><div id="36783279" class="c"><input type="checkbox" id="c-36783279" checked=""/><div class="controls bullet"><span class="by">JanSt</span><span>|</span><a href="#36782403">root</a><span>|</span><a href="#36782872">parent</a><span>|</span><a href="#36783179">prev</a><span>|</span><a href="#36781788">next</a><span>|</span><label class="collapse" for="c-36783279">[-]</label><label class="expand" for="c-36783279">[1 more]</label></div><br/><div class="children"><div class="content">Same experience for me. Very unlucky answers now.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="36781788" class="c"><input type="checkbox" id="c-36781788" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#36782403">prev</a><span>|</span><a href="#36781506">next</a><span>|</span><label class="collapse" for="c-36781788">[-]</label><label class="expand" for="c-36781788">[11 more]</label></div><br/><div class="children"><div class="content">Previous commentary I know of from OpenAI staff:<p>Logan: The API does not just change without us telling you. The models are static there. <a href="https:&#x2F;&#x2F;twitter.com&#x2F;OfficialLoganK&#x2F;status&#x2F;1663934947931897857" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;OfficialLoganK&#x2F;status&#x2F;166393494793189785...</a> may 31<p>Peter: No, we haven&#x27;t made GPT-4 dumber. Quite the opposite: we make each new version smarter than the previous one. <a href="https:&#x2F;&#x2F;twitter.com&#x2F;jlowin&#x2F;status&#x2F;1679660938415177731" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;jlowin&#x2F;status&#x2F;1679660938415177731</a> july 14<p>either the models are static, or they are being improved continuously and there have been unforeseen regressions. only one can be true at any point in time. was this policy changed in the last 1.5 months?</div><br/><div id="36781875" class="c"><input type="checkbox" id="c-36781875" checked=""/><div class="controls bullet"><span class="by">airgapstopgap</span><span>|</span><a href="#36781788">parent</a><span>|</span><a href="#36781833">next</a><span>|</span><label class="collapse" for="c-36781875">[-]</label><label class="expand" for="c-36781875">[9 more]</label></div><br/><div class="children"><div class="content">Not really. They have a way of squaring this circle, by changing their inference code. Speculative sampling [1] would still make their first claim a lie – sure, there&#x27;d still be the original GPT-4 model, <i>plus</i> a smaller draft worker. But early exit decoding [2] allows you to get <i>almost as good</i> results for much cheaper from exactly the same checkpoint. We know that this line of research for large-scale inference is going strong [3] so it stands to reason that OpenAI, with their wealth of talent focused on GPT-4 throughput&amp;inference [4], large contexts and aggressive pricing policy, would also develop something like that. And of course it&#x27;s &quot;smarter&quot; that way – in a very deceptive sense of the word.<p>1. <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2302.01318" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2302.01318</a><p>2. <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2207.07061" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2207.07061</a><p>3. <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2307.02628" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2307.02628</a><p>4. <a href="https:&#x2F;&#x2F;openai.com&#x2F;contributions&#x2F;gpt-4" rel="nofollow noreferrer">https:&#x2F;&#x2F;openai.com&#x2F;contributions&#x2F;gpt-4</a></div><br/><div id="36781981" class="c"><input type="checkbox" id="c-36781981" checked=""/><div class="controls bullet"><span class="by">BoorishBears</span><span>|</span><a href="#36781788">root</a><span>|</span><a href="#36781875">parent</a><span>|</span><a href="#36781833">next</a><span>|</span><label class="collapse" for="c-36781981">[-]</label><label class="expand" for="c-36781981">[8 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t get why you&#x27;re jumping to cloak and daggers style operations: OpenAI would not kneecap their commercial offering by randomly changing how it works.<p>At the end of the day 99% of the confusion comes from people using the web interface, which undoubtedly does change much more often than the API versions they share.<p>The web app they host isn&#x27;t a simple API wrapper, it does summarization, has some sort of system prompt, and calls the moderation API. That&#x27;s undoubtedly being updated all the time.</div><br/><div id="36782257" class="c"><input type="checkbox" id="c-36782257" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#36781788">root</a><span>|</span><a href="#36781981">parent</a><span>|</span><a href="#36782199">next</a><span>|</span><label class="collapse" for="c-36782257">[-]</label><label class="expand" for="c-36782257">[3 more]</label></div><br/><div class="children"><div class="content">&gt; OpenAI would not kneecap their commercial offering by randomly changing how it works.<p>Have you seen the 25 messages&#x2F;3 hours limitation for GPT-4? Why do you think they did that? Of course they would make more money scaling up the volume, but how to do that when compute is so limited? Of course, by using some kind of approximation - quantised model or speculative sampling come to mind. It&#x27;s hard to pinpoint model regressions, but scaling up volume is great, one more incentive to do it.</div><br/><div id="36782302" class="c"><input type="checkbox" id="c-36782302" checked=""/><div class="controls bullet"><span class="by">BoorishBears</span><span>|</span><a href="#36781788">root</a><span>|</span><a href="#36782257">parent</a><span>|</span><a href="#36782199">next</a><span>|</span><label class="collapse" for="c-36782302">[-]</label><label class="expand" for="c-36782302">[2 more]</label></div><br/><div class="children"><div class="content">You realize that&#x27;s a limitation in the web application right?<p>The web app is a consumer app (B2C) the api is commercial (B2B). They tinker with the B2C app because it&#x27;s already a lossy approximation of using the model between the summarization and system prompt.<p>They <i>cannot</i> mess with the commercial offering willy-nilly: People are building businesses predicated on it behaving a certain way. That&#x27;s why there are dated version that you can pin to with the API. The web app changes whenever they feel like it.</div><br/><div id="36783267" class="c"><input type="checkbox" id="c-36783267" checked=""/><div class="controls bullet"><span class="by">zo1</span><span>|</span><a href="#36781788">root</a><span>|</span><a href="#36782302">parent</a><span>|</span><a href="#36782199">next</a><span>|</span><label class="collapse" for="c-36783267">[-]</label><label class="expand" for="c-36783267">[1 more]</label></div><br/><div class="children"><div class="content">You keep repeating that. You don&#x27;t even know if the people commenting to you use the API or the &quot;web app&quot;. I use the API and I noticed the same stuff others have.</div><br/></div></div></div></div></div></div><div id="36782199" class="c"><input type="checkbox" id="c-36782199" checked=""/><div class="controls bullet"><span class="by">airgapstopgap</span><span>|</span><a href="#36781788">root</a><span>|</span><a href="#36781981">parent</a><span>|</span><a href="#36782257">prev</a><span>|</span><a href="#36782033">next</a><span>|</span><label class="collapse" for="c-36782199">[-]</label><label class="expand" for="c-36782199">[2 more]</label></div><br/><div class="children"><div class="content">No, it makes sense to secure engagement with the most expensive implementation and then cut costs, this kind of stuff is pervasive in the industry. Besides, we have Brockman on record saying that they do &quot;a lot of quantization&quot;[1][2] so it&#x27;s not paranoia to suspect other optimization schemes when there&#x27;s a clear performance drop, which they have also denied a few times.<p>1. <a href="https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;44a0c5b6-c629-470a-992f-8cdbbecd64a2" rel="nofollow noreferrer">https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;44a0c5b6-c629-470a-992f-8cdbbe...</a><p>2. <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=_hpuPi7YZX8">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=_hpuPi7YZX8</a></div><br/><div id="36782322" class="c"><input type="checkbox" id="c-36782322" checked=""/><div class="controls bullet"><span class="by">BoorishBears</span><span>|</span><a href="#36781788">root</a><span>|</span><a href="#36782199">parent</a><span>|</span><a href="#36782033">next</a><span>|</span><label class="collapse" for="c-36782322">[-]</label><label class="expand" for="c-36782322">[1 more]</label></div><br/><div class="children"><div class="content">Paranoia would be charitable: it&#x27;s FUD.<p>If you intentionally smear the line between their web app which is chock full of optimizations to even let it function as it does (the web app&#x27;s max conversation length exceeds the context window) and the API which is versioned and iterated on in the open... it&#x27;s either a lack of understanding or FUD.</div><br/></div></div></div></div><div id="36782033" class="c"><input type="checkbox" id="c-36782033" checked=""/><div class="controls bullet"><span class="by">Shank</span><span>|</span><a href="#36781788">root</a><span>|</span><a href="#36781981">parent</a><span>|</span><a href="#36782199">prev</a><span>|</span><a href="#36781833">next</a><span>|</span><label class="collapse" for="c-36782033">[-]</label><label class="expand" for="c-36782033">[2 more]</label></div><br/><div class="children"><div class="content">&gt; OpenAI would not kneecap their commercial offering by randomly changing how it works.<p>&gt; As of July 3, 2023, we’ve disabled the Browse with Bing beta feature out of an abundance of caution while we fix this in order to do right by content owners. We are working to bring the beta back as quickly as possible, and appreciate your understanding!<p><a href="https:&#x2F;&#x2F;help.openai.com&#x2F;en&#x2F;articles&#x2F;8077698-how-do-i-use-chatgpt-browse-with-bing-to-search-the-web" rel="nofollow noreferrer">https:&#x2F;&#x2F;help.openai.com&#x2F;en&#x2F;articles&#x2F;8077698-how-do-i-use-cha...</a></div><br/><div id="36782079" class="c"><input type="checkbox" id="c-36782079" checked=""/><div class="controls bullet"><span class="by">BoorishBears</span><span>|</span><a href="#36781788">root</a><span>|</span><a href="#36782033">parent</a><span>|</span><a href="#36781833">next</a><span>|</span><label class="collapse" for="c-36782079">[-]</label><label class="expand" for="c-36782079">[1 more]</label></div><br/><div class="children"><div class="content">Thank you for confirming my point?<p>&gt; At the end of the day 99% of the confusion comes from people using the web interface, which undoubtedly does change much more often than the API versions they share.<p>The API does not offer any browsing features, that&#x27;s the web app.</div><br/></div></div></div></div></div></div></div></div><div id="36781833" class="c"><input type="checkbox" id="c-36781833" checked=""/><div class="controls bullet"><span class="by">flangola7</span><span>|</span><a href="#36781788">parent</a><span>|</span><a href="#36781875">prev</a><span>|</span><a href="#36781506">next</a><span>|</span><label class="collapse" for="c-36781833">[-]</label><label class="expand" for="c-36781833">[1 more]</label></div><br/><div class="children"><div class="content">You can call a specific version of the model. It&#x27;s ones of the API values. The latter person is referring to the &quot;gpt-4&quot; which the documentation states will update and change without warning.</div><br/></div></div></div></div><div id="36781506" class="c"><input type="checkbox" id="c-36781506" checked=""/><div class="controls bullet"><span class="by">svaha1728</span><span>|</span><a href="#36781788">prev</a><span>|</span><a href="#36782903">next</a><span>|</span><label class="collapse" for="c-36781506">[-]</label><label class="expand" for="c-36781506">[2 more]</label></div><br/><div class="children"><div class="content">&gt;June version added “‘python and “‘ before and after the code snippet. Second, it also generated a few more comments. While a small change, the extra triple quotes render the code not executable.<p>These are to represent markdown code blocks, which probably helped their front end developers, but hinders copy-pasta</div><br/><div id="36781655" class="c"><input type="checkbox" id="c-36781655" checked=""/><div class="controls bullet"><span class="by">QuantumG</span><span>|</span><a href="#36781506">parent</a><span>|</span><a href="#36782903">next</a><span>|</span><label class="collapse" for="c-36781655">[-]</label><label class="expand" for="c-36781655">[1 more]</label></div><br/><div class="children"><div class="content">Outputting that on the API is kinda dumb, but yeah, hardly something worth publishing.</div><br/></div></div></div></div><div id="36782903" class="c"><input type="checkbox" id="c-36782903" checked=""/><div class="controls bullet"><span class="by">Aulig</span><span>|</span><a href="#36781506">prev</a><span>|</span><a href="#36781924">next</a><span>|</span><label class="collapse" for="c-36782903">[-]</label><label class="expand" for="c-36782903">[1 more]</label></div><br/><div class="children"><div class="content">Just yesterday I gave ChatGPT a summarization task and it performed horribly. I even tried multiple times and got the identical answer. Then I gave the identical prompt to gpt-3.5-turbo via the API and I immediately got the expected good answer.</div><br/></div></div><div id="36781924" class="c"><input type="checkbox" id="c-36781924" checked=""/><div class="controls bullet"><span class="by">JimmyRuska</span><span>|</span><a href="#36782903">prev</a><span>|</span><a href="#36782634">next</a><span>|</span><label class="collapse" for="c-36781924">[-]</label><label class="expand" for="c-36781924">[1 more]</label></div><br/><div class="children"><div class="content">The pre-prompting length will grow more and more as more liabilities in the responses are uncovered. I would imagine the more the pre-prompting grows the more attention is diverted to the rules rather than the user prompt, and the less reasoning available.<p>I wonder if they&#x27;ll start using LLMs while ingesting new data. eg asking the LLM if the content is helpful, cites sources, respectful, positive, not-thin content, common or often duplicated content, etc etc, before each content import.</div><br/></div></div><div id="36782634" class="c"><input type="checkbox" id="c-36782634" checked=""/><div class="controls bullet"><span class="by">metanonsense</span><span>|</span><a href="#36781924">prev</a><span>|</span><a href="#36782234">next</a><span>|</span><label class="collapse" for="c-36782634">[-]</label><label class="expand" for="c-36782634">[2 more]</label></div><br/><div class="children"><div class="content">With those GPT4 architecture infos leaked a few weeks ago, my personal theory is that they use mixture-of-experts routing for scaling the system. For instance, they could say: from 0 to 50% system load use a mixture of top-6 models for inference, from 60 to 80% use top-4 models, above 80% use top-2 models. This could make ChatGPT look dumber or smarter depending on the time of the day and system usage. Naturally, the variance of inference quality would spread and people would experience regressions in quality with some probability.<p>They could also use these parameters over time to become more cost efficient, in general, or reserve GPUs (i.e. allocating more expert networks) for some higher-margin use-cases.</div><br/><div id="36782713" class="c"><input type="checkbox" id="c-36782713" checked=""/><div class="controls bullet"><span class="by">metanonsense</span><span>|</span><a href="#36782634">parent</a><span>|</span><a href="#36782234">next</a><span>|</span><label class="collapse" for="c-36782713">[-]</label><label class="expand" for="c-36782713">[1 more]</label></div><br/><div class="children"><div class="content">They could even persist the inference parameterization, e.g. &quot;use top-8 for &#x27;compute the sum of 42 and 17&#x27;&quot;, for every prompt ever seen and reuse it later to prevent people doing &quot;poor man&#x27;s regression testing&quot; and make the model look more stable.</div><br/></div></div></div></div><div id="36782234" class="c"><input type="checkbox" id="c-36782234" checked=""/><div class="controls bullet"><span class="by">s3p</span><span>|</span><a href="#36782634">prev</a><span>|</span><a href="#36782894">next</a><span>|</span><label class="collapse" for="c-36782234">[-]</label><label class="expand" for="c-36782234">[1 more]</label></div><br/><div class="children"><div class="content">Commented this on a submission that was a duplicate of this one, but:<p>When GPT&#x27;s details were allegedly leaked [0] I read about the mixture of experts and wondered if this explains my recent distaste for GPT. Lately I have been using Anthropic&#x27;s offering (mainly since it is free and has a 100k context window) and I&#x27;ve been surprised at just how well it reasons and understands what I&#x27;m asking. It responds like GPT 4 used to, and speaks to me with nuance I haven&#x27;t seen since Bing released their original chatbot. I still find GPT 4 better if I want to fine-tune the model and make it adopt a persona-- Claude will almost always refuse.<p>Either way, I&#x27;m a bit confused with the way GPT 4 has been changing over time. It seems the team made significant changes to the model quality in favor of performance. Whether accuracy or performance is more important is up for debate, but something is clearly changing.<p>[0] <a href="https:&#x2F;&#x2F;archive.ph&#x2F;2RQ8X" rel="nofollow noreferrer">https:&#x2F;&#x2F;archive.ph&#x2F;2RQ8X</a></div><br/></div></div><div id="36782894" class="c"><input type="checkbox" id="c-36782894" checked=""/><div class="controls bullet"><span class="by">high_5</span><span>|</span><a href="#36782234">prev</a><span>|</span><a href="#36781743">next</a><span>|</span><label class="collapse" for="c-36782894">[-]</label><label class="expand" for="c-36782894">[1 more]</label></div><br/><div class="children"><div class="content">Since the system appears to be dynamic to certain extent (beyond training) this will be a permanent problem. The feedback that large&#x2F;public GPT systems are given and retrained upon will cause ups and downs, depending on the mood of the society. But I believe this entanglement of people dependent on LLMs and vice versa will go pear shaped until full Idiocracy scenario is reached. As George Carlin supposedly said &quot;never underestimate the power of stupid people in large groups&quot;.</div><br/></div></div><div id="36781743" class="c"><input type="checkbox" id="c-36781743" checked=""/><div class="controls bullet"><span class="by">blobbers</span><span>|</span><a href="#36782894">prev</a><span>|</span><a href="#36783167">next</a><span>|</span><label class="collapse" for="c-36781743">[-]</label><label class="expand" for="c-36781743">[7 more]</label></div><br/><div class="children"><div class="content">A little surprised this sort of thing passes for a publish-able paper.<p>Isn&#x27;t it the equivalent to saying &quot;Here&#x27;s the top 10 results for google searching golden retrievers March 2023, and here&#x27;s the top 10 results from June 2023. We see that google is returning even cuter animals today. Unfortunately though, one of the results linked to a page full of cats.&quot;<p>I&#x27;m sure openai has a list of standard questions that it tracks the responses it is getting over a period of time with perfect knowledge &#x2F; version timing of their own releases.<p>This does not seem like valid research &#x2F; publication.</div><br/><div id="36782856" class="c"><input type="checkbox" id="c-36782856" checked=""/><div class="controls bullet"><span class="by">danybittel</span><span>|</span><a href="#36781743">parent</a><span>|</span><a href="#36781878">next</a><span>|</span><label class="collapse" for="c-36782856">[-]</label><label class="expand" for="c-36782856">[1 more]</label></div><br/><div class="children"><div class="content">If it&#x27;s not deterministic, it&#x27;s not going to be useful in professional settings!<p>Example: you get a bunch of data from your boss, need to find something out, you prompt engineer the results. Your boss get&#x27;s back to you (five weeks later), likes the result, just want&#x27;s you to fix a minor thing. It&#x27;s now giving you completely different results. It&#x27;s like building on sand.</div><br/></div></div><div id="36781878" class="c"><input type="checkbox" id="c-36781878" checked=""/><div class="controls bullet"><span class="by">gyrovagueGeist</span><span>|</span><a href="#36781743">parent</a><span>|</span><a href="#36782856">prev</a><span>|</span><a href="#36781850">next</a><span>|</span><label class="collapse" for="c-36781878">[-]</label><label class="expand" for="c-36781878">[1 more]</label></div><br/><div class="children"><div class="content">Its arxiv its not a published paper. Until it&#x27;s reprinted by a journal or proceedings, its basically a blog post that people feel more comfortable citing. 
It&#x27;s main purpose is to introduce&#x2F;increase caution about other methods using these services:  &quot;our findings shows
that the behavior of the “same” LLM service can change substantially in a relatively short amount
of time, highlighting the need for continuous monitoring of LLM quality&quot;<p>Which seems valuable for other research using OpenAI GPT directly.</div><br/></div></div><div id="36781850" class="c"><input type="checkbox" id="c-36781850" checked=""/><div class="controls bullet"><span class="by">ineedasername</span><span>|</span><a href="#36781743">parent</a><span>|</span><a href="#36781878">prev</a><span>|</span><a href="#36783167">next</a><span>|</span><label class="collapse" for="c-36781850">[-]</label><label class="expand" for="c-36781850">[4 more]</label></div><br/><div class="children"><div class="content">No, the methodology listed in the paper shows their efforts were significantly more extensive than you represent here. As one example, their test of prime numbers went through 500 randomly selected primes, also evaluating the chain of thought in responses along with the success rate of this classification task. I’m not sure how you arrived at your impression, but it does not match the contents of the paper that I saw with a quick scan of each section.</div><br/><div id="36781866" class="c"><input type="checkbox" id="c-36781866" checked=""/><div class="controls bullet"><span class="by">blobbers</span><span>|</span><a href="#36781743">root</a><span>|</span><a href="#36781850">parent</a><span>|</span><a href="#36783167">next</a><span>|</span><label class="collapse" for="c-36781866">[-]</label><label class="expand" for="c-36781866">[3 more]</label></div><br/><div class="children"><div class="content">Not to seem sarcastic, but 500 randomly selected primes doesn&#x27;t change my mind. I read the paper, and dumbed it down to dogs and cats.<p>Do you really feel like the efforts were significant or meaningful?</div><br/><div id="36782000" class="c"><input type="checkbox" id="c-36782000" checked=""/><div class="controls bullet"><span class="by">ineedasername</span><span>|</span><a href="#36781743">root</a><span>|</span><a href="#36781866">parent</a><span>|</span><a href="#36783167">next</a><span>|</span><label class="collapse" for="c-36782000">[-]</label><label class="expand" for="c-36782000">[2 more]</label></div><br/><div class="children"><div class="content">&gt;I read the paper, and dumbed it down to dogs and cats.<p>I could read the Pricicipia, or anything, and dumb it down to dogs and cats, but that reduction to the dumb would be a failing all my own.<p>As for the test-- a classification task benchmarked with 500 examples is a fairly decent test of a system&#x27;s capabilities, be it LLM or a traditional machine learning model. And again, this was only one of a variety of tasks. While it&#x27;s certainly no Principia, I don&#x27;t know how you get from there to dogs and cats, nor have you explained your reasoning on how you found the path between the two.</div><br/><div id="36783203" class="c"><input type="checkbox" id="c-36783203" checked=""/><div class="controls bullet"><span class="by">blobbers</span><span>|</span><a href="#36781743">root</a><span>|</span><a href="#36782000">parent</a><span>|</span><a href="#36783167">next</a><span>|</span><label class="collapse" for="c-36783203">[-]</label><label class="expand" for="c-36783203">[1 more]</label></div><br/><div class="children"><div class="content">Well, for starters, you take a model with 100 trillion parameters, and then you test it with... 500 examples. WAIT did you say hundred? 500 hundred? Not 500 hundred thousand right?<p>Okay okay hold on back to the drawing board.<p>...dumbed down to cats and dogs.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="36783167" class="c"><input type="checkbox" id="c-36783167" checked=""/><div class="controls bullet"><span class="by">dontupvoteme</span><span>|</span><a href="#36781743">prev</a><span>|</span><a href="#36783562">next</a><span>|</span><label class="collapse" for="c-36783167">[-]</label><label class="expand" for="c-36783167">[1 more]</label></div><br/><div class="children"><div class="content">one things for sure, it really does not want to output entire code blocks now, opting heavily to just give the delta.</div><br/></div></div><div id="36783562" class="c"><input type="checkbox" id="c-36783562" checked=""/><div class="controls bullet"><span class="by">courseofaction</span><span>|</span><a href="#36783167">prev</a><span>|</span><a href="#36782600">next</a><span>|</span><label class="collapse" for="c-36783562">[-]</label><label class="expand" for="c-36783562">[1 more]</label></div><br/><div class="children"><div class="content">OpenAI just lie through their teeth lol.</div><br/></div></div><div id="36781577" class="c"><input type="checkbox" id="c-36781577" checked=""/><div class="controls bullet"><span class="by">ramesh31</span><span>|</span><a href="#36781452">prev</a><span>|</span><a href="#36781393">next</a><span>|</span><label class="collapse" for="c-36781577">[-]</label><label class="expand" for="c-36781577">[15 more]</label></div><br/><div class="children"><div class="content">OpenAI is going to be left in the dust by (actual) open models. Llama 2 is already reaching GPT-3 levels, and can run inference on consumer hardware. Crazy how fast that flipped.</div><br/><div id="36781682" class="c"><input type="checkbox" id="c-36781682" checked=""/><div class="controls bullet"><span class="by">nomel</span><span>|</span><a href="#36781577">parent</a><span>|</span><a href="#36781816">next</a><span>|</span><label class="collapse" for="c-36781682">[-]</label><label class="expand" for="c-36781682">[6 more]</label></div><br/><div class="children"><div class="content">What enables this?<p>There&#x27;s a <i>huge</i> gap between GPT-3.5 and 4, put there by a massive amount of money, from my understanding.<p>To compete, with open source projects being less well funded, I would assume that orders of magnitude improvements in training cost would be required. What do you see driving this, and who do you see paying for it?<p>If Meta, or anyone else, gets something that beats GPT-4, I would naively assume they would monetize it. If someopen source effort manages to beat GPT-4, then I assume some well funded, profit seeking, entity will dump orders of magnitude more money into whatever enabled the open source offerings to compete.<p>I don&#x27;t think GPT-4 is the pinnacle of OpenAI, or that their funding will run dry, so they shouldn&#x27;t be viewed as a static entity.</div><br/><div id="36781723" class="c"><input type="checkbox" id="c-36781723" checked=""/><div class="controls bullet"><span class="by">ramesh31</span><span>|</span><a href="#36781577">root</a><span>|</span><a href="#36781682">parent</a><span>|</span><a href="#36781816">next</a><span>|</span><label class="collapse" for="c-36781723">[-]</label><label class="expand" for="c-36781723">[5 more]</label></div><br/><div class="children"><div class="content">&gt;Or, are you suggesting that GPT-4 is the pinnacle of OpenAI, or that their funding will run dry?<p>My bet is that Meta has pivoted almost entirely to this space with their R&amp;D in the last six months. Llama 2 is spectacular. And with its&#x27; success, there will undoubtedly be more. They also happen to have access to limitless amounts of compute, cash, and engineering that puts OpenAI to shame. This could finally be their chance to create a platform for real. And the open source community and startups will benefit off of that.</div><br/><div id="36782077" class="c"><input type="checkbox" id="c-36782077" checked=""/><div class="controls bullet"><span class="by">nomel</span><span>|</span><a href="#36781577">root</a><span>|</span><a href="#36781723">parent</a><span>|</span><a href="#36781802">next</a><span>|</span><label class="collapse" for="c-36782077">[-]</label><label class="expand" for="c-36782077">[3 more]</label></div><br/><div class="children"><div class="content">What motive do you see for them releasing these models for free, especially with the massive increase in cost associated with catching up?</div><br/><div id="36782363" class="c"><input type="checkbox" id="c-36782363" checked=""/><div class="controls bullet"><span class="by">ramesh31</span><span>|</span><a href="#36781577">root</a><span>|</span><a href="#36782077">parent</a><span>|</span><a href="#36782414">next</a><span>|</span><label class="collapse" for="c-36782363">[-]</label><label class="expand" for="c-36782363">[1 more]</label></div><br/><div class="children"><div class="content">&gt; What motive do you see for them releasing these models for free, especially with the massive increase in cost associated with catching up?<p>Owning a platform. Zuck&#x27;s dream.<p>They put tons of money into these models, nurture an ecosystem of companies built around them, and then start gradually figuring out a licensing model for the ones that take off.</div><br/></div></div><div id="36782414" class="c"><input type="checkbox" id="c-36782414" checked=""/><div class="controls bullet"><span class="by">littlestymaar</span><span>|</span><a href="#36781577">root</a><span>|</span><a href="#36782077">parent</a><span>|</span><a href="#36782363">prev</a><span>|</span><a href="#36781802">next</a><span>|</span><label class="collapse" for="c-36782414">[-]</label><label class="expand" for="c-36782414">[1 more]</label></div><br/><div class="children"><div class="content">Kill Op*nAI, for starter. If they see it as a threat, commoditizing the tech is a great way to get rid of them at a reasonable cost.</div><br/></div></div></div></div></div></div></div></div><div id="36781816" class="c"><input type="checkbox" id="c-36781816" checked=""/><div class="controls bullet"><span class="by">flangola7</span><span>|</span><a href="#36781577">parent</a><span>|</span><a href="#36781682">prev</a><span>|</span><a href="#36781393">next</a><span>|</span><label class="collapse" for="c-36781816">[-]</label><label class="expand" for="c-36781816">[8 more]</label></div><br/><div class="children"><div class="content">Llama really isn&#x27;t open source, at least not in the sense of FOSS licenses like GPL or MIT. It comes with a number of use-case conditions and gives Meta many avenues to revoke a license if they feel like it. They also have a hard cap on the number of allowed users you may have using your Llama-based product above which you must seek further Meta approval.<p>Furthermore, Llama remains well below GPT-3 on human rated tests such as programming, and GPT-3 is already over three years old. It is also misleading to suggest Llama 2 can be ran on consumer hardware - the smaller and quantized models can but those are even more lacking in capability. Full power Llama 2 still requires multiple kilowatts of electricity and $10,000+ of compute hardware per inference session.<p>OpenAI does not have a moat, but they do have a very high wall.</div><br/><div id="36782336" class="c"><input type="checkbox" id="c-36782336" checked=""/><div class="controls bullet"><span class="by">pedrosorio</span><span>|</span><a href="#36781577">root</a><span>|</span><a href="#36781816">parent</a><span>|</span><a href="#36782058">next</a><span>|</span><label class="collapse" for="c-36782336">[-]</label><label class="expand" for="c-36782336">[1 more]</label></div><br/><div class="children"><div class="content">&gt; They also have a hard cap on the number of allowed users you may have using your Llama-based product above which you must seek further Meta approval.<p>This is not what the Llama 2 license says [0]. There is a cap on the number of active users of products (any products, not just ones that may make use of Llama) by the company who plans to use Llama 2 <i>as of Llama 2 release date</i>.<p>Not a “future cap on number of users of your Llama2-based product”. Also, the cap is 700 million users.<p>&gt; If, on the Llama 2 version release date, the 
monthly active users of the products or services made available by or for Licensee, 
or Licensee&#x27;s affiliates, is greater than 700 million monthly active users in the 
preceding calendar month, you must request a license from Meta<p>[0] <a href="https:&#x2F;&#x2F;github.com&#x2F;facebookresearch&#x2F;llama&#x2F;blob&#x2F;main&#x2F;LICENSE">https:&#x2F;&#x2F;github.com&#x2F;facebookresearch&#x2F;llama&#x2F;blob&#x2F;main&#x2F;LICENSE</a></div><br/></div></div><div id="36782058" class="c"><input type="checkbox" id="c-36782058" checked=""/><div class="controls bullet"><span class="by">Sosh101</span><span>|</span><a href="#36781577">root</a><span>|</span><a href="#36781816">parent</a><span>|</span><a href="#36782336">prev</a><span>|</span><a href="#36782470">next</a><span>|</span><label class="collapse" for="c-36782058">[-]</label><label class="expand" for="c-36782058">[2 more]</label></div><br/><div class="children"><div class="content">&gt; and $10,000+ of compute hardware per inference session.<p>What hardware would you need to run it at home?</div><br/><div id="36783611" class="c"><input type="checkbox" id="c-36783611" checked=""/><div class="controls bullet"><span class="by">ramesh31</span><span>|</span><a href="#36781577">root</a><span>|</span><a href="#36782058">parent</a><span>|</span><a href="#36782470">next</a><span>|</span><label class="collapse" for="c-36783611">[-]</label><label class="expand" for="c-36783611">[1 more]</label></div><br/><div class="children"><div class="content">&gt;What hardware would you need to run it at home?<p>Step 1: <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;TheBloke&#x2F;Llama-2-7B-Chat-GGML&#x2F;blob&#x2F;main&#x2F;llama-2-7b-chat.ggmlv3.q4_0.bin" rel="nofollow noreferrer">https:&#x2F;&#x2F;huggingface.co&#x2F;TheBloke&#x2F;Llama-2-7B-Chat-GGML&#x2F;blob&#x2F;ma...</a><p>Step 2: <a href="https:&#x2F;&#x2F;github.com&#x2F;ggerganov&#x2F;llama.cpp">https:&#x2F;&#x2F;github.com&#x2F;ggerganov&#x2F;llama.cpp</a><p>Step 3: you&#x27;re welcome</div><br/></div></div></div></div><div id="36782470" class="c"><input type="checkbox" id="c-36782470" checked=""/><div class="controls bullet"><span class="by">littlestymaar</span><span>|</span><a href="#36781577">root</a><span>|</span><a href="#36781816">parent</a><span>|</span><a href="#36782058">prev</a><span>|</span><a href="#36782312">next</a><span>|</span><label class="collapse" for="c-36782470">[-]</label><label class="expand" for="c-36782470">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Furthermore, Llama remains well below GPT-3 on human rated tests such as programming, and GPT-3 is already over three years old.<p>It&#x27;s just not part of the entended use-case, and hasn&#x27;t been trained to do so. It&#x27;s almost like complaining that StableDiffusion isn&#x27;t good at text generation…<p>&gt; It is also misleading to suggest Llama 2 can be ran on consumer hardware - the smaller and quantized models can but those are even more lacking in capability<p>The biggest models will be abble to run on the CPU just fine with llama.cpp as long as you have enough (cheap) RAM. Sure it&#x27;s slow, but you <i>can</i> run it.<p>&gt; Full power Llama 2 still requires multiple kilowatts of electricity and $10,000+ of compute hardware per inference session.<p>What is that “per inference session” doing here? You pay the hardware only once you know… (and the number of kilowatt isn&#x27;t per inference session either, the number of Watt•hour is)</div><br/><div id="36783047" class="c"><input type="checkbox" id="c-36783047" checked=""/><div class="controls bullet"><span class="by">flangola7</span><span>|</span><a href="#36781577">root</a><span>|</span><a href="#36782470">parent</a><span>|</span><a href="#36782312">next</a><span>|</span><label class="collapse" for="c-36783047">[-]</label><label class="expand" for="c-36783047">[1 more]</label></div><br/><div class="children"><div class="content">&gt;It&#x27;s just not part of the entended use-case, and hasn&#x27;t been trained to do so. It&#x27;s almost like complaining that StableDiffusion isn&#x27;t good at text generation…<p>For the most part none of these systems were trained to do anything. The capabilities are emergent. My statement about the benchmarks remains unfazed.<p>&gt;The biggest models will be abble to run on the CPU just fine with llama.cpp as long as you have enough (cheap) RAM. Sure it&#x27;s slow, but you <i>can</i> run it.<p>Yes, but what products&#x2F;clients are you pitching where that kind of wait will be acceptable? Time is money. Standing up racks of maxed out RAM server slots is still far from inexpensive too.<p>&gt;What is that “per inference session” doing here? You pay the hardware only once you know… (and the number of kilowatt isn&#x27;t per inference session either, the number of Watt•hour is)<p>Good job at completely missing the point. I know what a kilowatt is and it is the unit I meant, not kilowatt-hour. I&#x27;m referring to the hardware necessary to run one user session of inference. While user 1&#x27;s tokens are generating, users 2 and up are in the queue waiting. If you want to serve multiple users simultaneously you will need to invest in multiple $xx,xxx units of hardware each requiring a multi-kW electrical circuit.<p>There is a reason ChatGPT incurs electrical bills on the order of a million dollars per day.</div><br/></div></div></div></div><div id="36782312" class="c"><input type="checkbox" id="c-36782312" checked=""/><div class="controls bullet"><span class="by">ramesh31</span><span>|</span><a href="#36781577">root</a><span>|</span><a href="#36781816">parent</a><span>|</span><a href="#36782470">prev</a><span>|</span><a href="#36781393">next</a><span>|</span><label class="collapse" for="c-36782312">[-]</label><label class="expand" for="c-36782312">[2 more]</label></div><br/><div class="children"><div class="content">&gt;Llama really isn&#x27;t open source, at least not in the sense of FOSS licenses like GPL or MIT.<p>Note that I never said &quot;open source&quot; just &quot;open models&quot;. As in, I can now actually build things with GPT3 capability that run locally. I couldn&#x27;t care less about the model code.<p>&gt;Llama 2 still requires multiple kilowatts of electricity and $10,000+ of compute hardware per inference session.<p>I&#x27;m running llama-2-7b-chat on my 8GB M1 Mac right now with llama.cpp. Completions are instant, and essentially at GPT3 levels of accuracy.<p>The higher param models require up to 64GB RAM, but it&#x27;s all CPU based.</div><br/><div id="36782486" class="c"><input type="checkbox" id="c-36782486" checked=""/><div class="controls bullet"><span class="by">gyrovagueGeist</span><span>|</span><a href="#36781577">root</a><span>|</span><a href="#36782312">parent</a><span>|</span><a href="#36781393">next</a><span>|</span><label class="collapse" for="c-36782486">[-]</label><label class="expand" for="c-36782486">[1 more]</label></div><br/><div class="children"><div class="content">If you compiled llama.cpp with Metal I wouldn’t say its ~all CPU based. But it is still incredible! I need to set this up myself this weekend :)</div><br/></div></div></div></div></div></div></div></div><div id="36781393" class="c"><input type="checkbox" id="c-36781393" checked=""/><div class="controls bullet"><span class="by">Der_Einzige</span><span>|</span><a href="#36781577">prev</a><span>|</span><a href="#36781734">next</a><span>|</span><label class="collapse" for="c-36781393">[-]</label><label class="expand" for="c-36781393">[5 more]</label></div><br/><div class="children"><div class="content">Never let OpenAI or Google employees (in regards to search) gaslight you into believing that things aren&#x27;t being &quot;enshittified&quot;. Glad to see scholarly evidence of this coming out.</div><br/><div id="36781667" class="c"><input type="checkbox" id="c-36781667" checked=""/><div class="controls bullet"><span class="by">quickthrower2</span><span>|</span><a href="#36781393">parent</a><span>|</span><a href="#36781493">next</a><span>|</span><label class="collapse" for="c-36781667">[-]</label><label class="expand" for="c-36781667">[3 more]</label></div><br/><div class="children"><div class="content">Honest enshittification is good but rare. Like a cloud telling you what specific CPU SKU is in the hardware (not just 1 vcore).<p>They should say what you are paying for in terms of technicals, either spill the beans on the architecture or have some SLAs on how good the thing is.</div><br/><div id="36781859" class="c"><input type="checkbox" id="c-36781859" checked=""/><div class="controls bullet"><span class="by">opportune</span><span>|</span><a href="#36781393">root</a><span>|</span><a href="#36781667">parent</a><span>|</span><a href="#36781493">next</a><span>|</span><label class="collapse" for="c-36781859">[-]</label><label class="expand" for="c-36781859">[2 more]</label></div><br/><div class="children"><div class="content">I work in cloud-land, the problem with exposing every little technical detail is that 1. part of the point of purchasing a cloud product is to abstract that away 2. coding to the implementation instead of the API creates huge headaches for everybody because there are often good reasons (make things more efficient) to change the implementation 3. sadly, there are “features” such as overcommit which you don’t want to know about as a customer.<p>While some of those are anti-customer on their face, the “we shouldn’t commit to implementation details and instead just to our API&#x2F;feature surface” may seem anti-customer while actually making things much better for customers. When implementations are supported in perpetuity development grinds to a standstill. Even overcommit ends up helping customers - cloud companies can offer lower sticker prices.<p>In the case of both regular Public cloud and OpenAI - if you need stability beyond publicly supported APIs you are probably not a good fit as a customer and should instead find a company willing to commit to lower level implementations (eg bare metal, truly major&#x2F;minor versioned software) or roll-your-own.</div><br/><div id="36782034" class="c"><input type="checkbox" id="c-36782034" checked=""/><div class="controls bullet"><span class="by">quickthrower2</span><span>|</span><a href="#36781393">root</a><span>|</span><a href="#36781859">parent</a><span>|</span><a href="#36781493">next</a><span>|</span><label class="collapse" for="c-36782034">[-]</label><label class="expand" for="c-36782034">[1 more]</label></div><br/><div class="children"><div class="content">That is fine, then you need some kinds of comparable metric that stays the same over time. FLOPS maybe?<p>Ideally the same across clouds, or more likely cloud-specific.<p>Or even re pin it every 5 years. E.g. a 2020-CPU, 2025-CPU etc.<p>We need a &quot;horse power&quot; for the cloud I guess!</div><br/></div></div></div></div></div></div><div id="36781493" class="c"><input type="checkbox" id="c-36781493" checked=""/><div class="controls bullet"><span class="by">EGreg</span><span>|</span><a href="#36781393">parent</a><span>|</span><a href="#36781667">prev</a><span>|</span><a href="#36781734">next</a><span>|</span><label class="collapse" for="c-36781493">[-]</label><label class="expand" for="c-36781493">[1 more]</label></div><br/><div class="children"><div class="content">Profit motive corrupts
Absolute profit motive corrupts absolutely</div><br/></div></div></div></div><div id="36781734" class="c"><input type="checkbox" id="c-36781734" checked=""/><div class="controls bullet"><span class="by">ttul</span><span>|</span><a href="#36781393">prev</a><span>|</span><label class="collapse" for="c-36781734">[-]</label><label class="expand" for="c-36781734">[7 more]</label></div><br/><div class="children"><div class="content">I tried the prime number problem and GPT-4 nailed it. I’m not sure whether they are testing things correctly…<p>“ Sure, let&#x27;s go step by step.<p>A prime number is a number greater than 1 that has no positive divisors other than 1 and itself. This means if we can find any other number (excluding 1 and the number itself) that divides 17077, then it is not a prime number.<p>Let&#x27;s start by checking divisibility by 2. Since 17077 is an odd number (its last digit is 7), it is not divisible by 2.<p>For the next step, we can look at divisibility by 3. We add up the digits: 1+7+0+7+7 = 22. Because 22 is not divisible by 3, 17077 is also not divisible by 3.<p>The smallest prime number greater than 3 is 5. Checking divisibility by 5, we see that 17077 does not end in 0 or 5, so it is not divisible by 5.<p>The smallest prime number greater than 5 is 7. To check divisibility by 7, there is no simple rule like with 2, 3, and 5, so we would perform the actual division. But we can stop here because I just recalled a rule that we can only check up to the square root of the number and the square root of 17077 is approximately 130.68. So if there were factors other than 1 and 17077, we would have found them by now.<p>Therefore, 17077 is a prime number.”</div><br/><div id="36781863" class="c"><input type="checkbox" id="c-36781863" checked=""/><div class="controls bullet"><span class="by">moonchild</span><span>|</span><a href="#36781734">parent</a><span>|</span><a href="#36782157">next</a><span>|</span><label class="collapse" for="c-36781863">[-]</label><label class="expand" for="c-36781863">[4 more]</label></div><br/><div class="children"><div class="content">&gt; GPT-4 nailed it<p>Did it?  Did you read what it wrote?</div><br/><div id="36782140" class="c"><input type="checkbox" id="c-36782140" checked=""/><div class="controls bullet"><span class="by">pedrosorio</span><span>|</span><a href="#36781734">root</a><span>|</span><a href="#36781863">parent</a><span>|</span><a href="#36781884">next</a><span>|</span><label class="collapse" for="c-36782140">[-]</label><label class="expand" for="c-36782140">[1 more]</label></div><br/><div class="children"><div class="content">I’ve seen so many of these on Twitter since chat GPT came out.<p>&gt; Look at this amazing capability, it gets it perfectly! (screenshot of interaction with clear flaws&#x2F;outright wrong answer)</div><br/></div></div><div id="36781884" class="c"><input type="checkbox" id="c-36781884" checked=""/><div class="controls bullet"><span class="by">kevinventullo</span><span>|</span><a href="#36781734">root</a><span>|</span><a href="#36781863">parent</a><span>|</span><a href="#36782140">prev</a><span>|</span><a href="#36782157">next</a><span>|</span><label class="collapse" for="c-36781884">[-]</label><label class="expand" for="c-36781884">[2 more]</label></div><br/><div class="children"><div class="content">It certainly nails the cadence of a rigorous proof. It just needs to learn to append “the rest is left as an exercise to the reader” to the end of its output.</div><br/></div></div></div></div><div id="36782157" class="c"><input type="checkbox" id="c-36782157" checked=""/><div class="controls bullet"><span class="by">YZF</span><span>|</span><a href="#36781734">parent</a><span>|</span><a href="#36781863">prev</a><span>|</span><label class="collapse" for="c-36782157">[-]</label><label class="expand" for="c-36782157">[2 more]</label></div><br/><div class="children"><div class="content">Aren&#x27;t there more potential primes between 130 and 7?</div><br/><div id="36782382" class="c"><input type="checkbox" id="c-36782382" checked=""/><div class="controls bullet"><span class="by">littlestymaar</span><span>|</span><a href="#36781734">root</a><span>|</span><a href="#36782157">parent</a><span>|</span><label class="collapse" for="c-36782382">[-]</label><label class="expand" for="c-36782382">[1 more]</label></div><br/><div class="children"><div class="content">Between 5 and 130 actually, it didn&#x27;t even checked 7!</div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>