<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1705568482567" as="style"/><link rel="stylesheet" href="styles.css?v=1705568482567"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://deepmind.google/discover/blog/alphageometry-an-olympiad-level-ai-system-for-geometry/">AlphaGeometry: An Olympiad-level AI system for geometry</a> <span class="domain">(<a href="https://deepmind.google">deepmind.google</a>)</span></div><div class="subtext"><span>FlawedReformer</span> | <span>120 comments</span></div><br/><div><div id="39031351" class="c"><input type="checkbox" id="c-39031351" checked=""/><div class="controls bullet"><span class="by">dang</span><span>|</span><a href="#39039546">next</a><span>|</span><label class="collapse" for="c-39031351">[-]</label><label class="expand" for="c-39031351">[3 more]</label></div><br/><div class="children"><div class="content">See also <a href="https:&#x2F;&#x2F;www.nytimes.com&#x2F;2024&#x2F;01&#x2F;17&#x2F;science&#x2F;ai-computers-mathematics-olympiad.html" rel="nofollow">https:&#x2F;&#x2F;www.nytimes.com&#x2F;2024&#x2F;01&#x2F;17&#x2F;science&#x2F;ai-computers-math...</a><p>(via <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=39030186">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=39030186</a>, but we&#x27;ll merge that thread hither)</div><br/><div id="39030969" class="c"><input type="checkbox" id="c-39030969" checked=""/><div class="controls bullet"><span class="by">empath-nirvana</span><span>|</span><a href="#39031351">parent</a><span>|</span><a href="#39039546">next</a><span>|</span><label class="collapse" for="c-39030969">[-]</label><label class="expand" for="c-39030969">[2 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;archive.is&#x2F;https:&#x2F;&#x2F;www.nytimes.com&#x2F;2024&#x2F;01&#x2F;17&#x2F;science&#x2F;ai-computers-mathematics-olympiad.html" rel="nofollow">https:&#x2F;&#x2F;archive.is&#x2F;https:&#x2F;&#x2F;www.nytimes.com&#x2F;2024&#x2F;01&#x2F;17&#x2F;scienc...</a></div><br/><div id="39031324" class="c"><input type="checkbox" id="c-39031324" checked=""/><div class="controls bullet"><span class="by">neonate</span><span>|</span><a href="#39031351">root</a><span>|</span><a href="#39030969">parent</a><span>|</span><a href="#39039546">next</a><span>|</span><label class="collapse" for="c-39031324">[-]</label><label class="expand" for="c-39031324">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20240117162133&#x2F;https:&#x2F;&#x2F;www.nytimes.com&#x2F;2024&#x2F;01&#x2F;17&#x2F;science&#x2F;ai-computers-mathematics-olympiad.html" rel="nofollow">https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20240117162133&#x2F;https:&#x2F;&#x2F;www.nytim...</a></div><br/></div></div></div></div></div></div><div id="39039546" class="c"><input type="checkbox" id="c-39039546" checked=""/><div class="controls bullet"><span class="by">aldousd666</span><span>|</span><a href="#39031351">prev</a><span>|</span><a href="#39037222">next</a><span>|</span><label class="collapse" for="c-39039546">[-]</label><label class="expand" for="c-39039546">[1 more]</label></div><br/><div class="children"><div class="content">This is fascinating and inspiring progress! What&#x27;s crazy to me is how many people are looking to put stakes in the ground in front of this, claiming breathlessly before anyone can speak, that this isn&#x27;t real AI progress or this isn&#x27;t actually doing it how humans supposedly do, and implying that therefore it&#x27;s not a big deal. I&#x27;m sorry to break to you folks, this is just another sign post moment. One more event to mark our place in history as we sail on. And when we look back on it, there isn&#x27;t going to be all the disclaimers people are trying to throw down now. We had imagenet and deep blue, we had alphazero, alphago, GPT4, alphafold, and now we have AlphaGeometry.As DJ Khaled likes to point out, this is.. Another one</div><br/></div></div><div id="39037222" class="c"><input type="checkbox" id="c-39037222" checked=""/><div class="controls bullet"><span class="by">szmerdi</span><span>|</span><a href="#39039546">prev</a><span>|</span><a href="#39032275">next</a><span>|</span><label class="collapse" for="c-39037222">[-]</label><label class="expand" for="c-39037222">[3 more]</label></div><br/><div class="children"><div class="content">As a former problem designer for IMO and similar contests, I deeply enjoyed reading this paper. At the same time, I&#x27;d like to point out that it was clear Geometry had to be the first topic to give up against AI (i.e., smart knowledge and inference-method indexing)
Among math olympiad topics, Geometry problems are often the most &quot;mechanical.&quot; Once you can express the problem in terms of coordinates (think XY or complex plane) you&#x27;re looking at a finite set of steps a computer can use to find a solution. Of course, time limits and human error get in the way of this being practical during the IMO itself. Back in the day, I&#x27;d use WolframAlpha to verify geometry proofs for problems I designed (+conjectures) using this approach.<p>Algebra (especially inequalities) can be similar – pull off some intense calculations and you often have your answer.<p>Where I&#x27;m really excited to see intelligent systems make progress is with Number Theory and Combinatorics problems. The search spaces are far more complex and they often require proving that something is <i>impossible.</i> These are the problems that would be difficult to solve with brute force computation.</div><br/><div id="39037512" class="c"><input type="checkbox" id="c-39037512" checked=""/><div class="controls bullet"><span class="by">fovc</span><span>|</span><a href="#39037222">parent</a><span>|</span><a href="#39038782">next</a><span>|</span><label class="collapse" for="c-39037512">[-]</label><label class="expand" for="c-39037512">[1 more]</label></div><br/><div class="children"><div class="content">As a consumer of those problems, first of all, thank you! Even decades on from high school I occasionally enjoy working on them.<p>But agree that geometry was obviously going to be first. From what I’ve gathered here, it’s not “brute forcing” in terms of relying on algebraic geometry, vectors, or complex number solutions, but it is brute force in that it’s exhaustively looking for “interesting” constructions.<p>Geometry was always my worst subject, but even so I felt like if given the right construction the problem was much easier. Unfortunately I never developed the intuition to hit on those constructions quickly. It seems this AI doesn’t either, but it can churn through them much faster   — There are only so many perpendiculars and parallels and bisectors you can construct which you can more or less mechanically evaluate (map out all angles and ratios, try power of a point, etc.)<p>While this is incredibly impressive, it seems like Deep Mind:Kasparov::AlphaGeo:Terry Tao in the “engine vs AI” sense.<p>I agree Algebra is likely next. Like geometry, more often than not you “just” need a clever substitution or 3, of which there are only so many options to choose from.<p>Some combinatorics problems I think would also be amenable to this search strategy (e.g., finding things to count 2 ways), but that seems like a bridge further away, and only gets you a subset of problems.<p>Number theory would be my guess for the final frontier before a perfect 42.</div><br/></div></div><div id="39038782" class="c"><input type="checkbox" id="c-39038782" checked=""/><div class="controls bullet"><span class="by">Dracophoenix</span><span>|</span><a href="#39037222">parent</a><span>|</span><a href="#39037512">prev</a><span>|</span><a href="#39032275">next</a><span>|</span><label class="collapse" for="c-39038782">[-]</label><label class="expand" for="c-39038782">[1 more]</label></div><br/><div class="children"><div class="content">How did you get into such a position? Is there an application process of some sort?<p>After verifying solvability, what is the process for selecting the specific problems that will show up in the finished set? Is it by vote or some other evaluation?</div><br/></div></div></div></div><div id="39032275" class="c"><input type="checkbox" id="c-39032275" checked=""/><div class="controls bullet"><span class="by">nybsjytm</span><span>|</span><a href="#39037222">prev</a><span>|</span><a href="#39030396">next</a><span>|</span><label class="collapse" for="c-39032275">[-]</label><label class="expand" for="c-39032275">[22 more]</label></div><br/><div class="children"><div class="content">If I read their paper right, this is legit work (much more legit than DeepMind&#x27;s AI math paper last month falsely advertised as solving an open math research problem) but it&#x27;s still pretty striking how far away the structure of it is from the usual idea of automated reasoning&#x2F;intelligence.<p>A transformer is trained on millions of elementary geometry theorems and used as brute search for a proof, which because of the elementary geometry context has both a necessarily elementary structure and can be easily symbolically judged as true or false. When the brute search fails, an extra geometric construction is randomly added (like adding a midpoint of a certain line) to see if brute search using that extra raw material might work. [edit: as corrected by Imnimo, I got this backwards - the brute search is just pure brute search, the transformer is used to predict which extra geometric construction to add]<p>Also (not mentioned in the blog post) the actual problem statements had to be modified&#x2F;adapted, e.g. the actual problem statement &quot;Let AH1, BH2 and CH3 be the altitudes of a triangle ABC. The incircle W of triangle ABC touches the sides BC, CA and AB at T1, T2 and T3, respectively. Consider the symmetric images of the lines H1H2, H2H3, and H3H1 with respect to the lines T1T2, T2T3, and T3T1. Prove that these images form a triangle whose vertices lie on W.&quot; had to be changed to &quot;Let ABC be a triangle. Define point I such that AI is the bisector of angle BAC and CI is the bisector of angle ACB. Define point T1 as the foot of I on line BC. Define T2 as the foot of I on line AC. Define point T3 as the foot of I on line AB. Define point H1 as the foot of A on line BC. Define point H2 as the foot of B on line AC. Define point H3 as the foot of C on line AB. Define point X1 as the intersection of circles (T1,H1) and (T2,H1). Define point X2 as the intersection of circles (T1,H2) and (T2,H2). Define point Y2 as the intersection of circles (T2,H2) and (T3,H2). Define point Y3 as the intersection of circles (T2,H3) and (T3,H3). Define point Z as the intersection of lines X1X2 and Y2Y3. Prove that T1I=IZ.&quot;</div><br/><div id="39032487" class="c"><input type="checkbox" id="c-39032487" checked=""/><div class="controls bullet"><span class="by">Imnimo</span><span>|</span><a href="#39032275">parent</a><span>|</span><a href="#39032938">next</a><span>|</span><label class="collapse" for="c-39032487">[-]</label><label class="expand" for="c-39032487">[2 more]</label></div><br/><div class="children"><div class="content">&gt;A transformer is trained on millions of elementary geometry theorems and used as brute search for a proof, which because of the elementary geometry context has both a necessarily elementary structure and can be easily symbolically judged as true or false. When the brute search fails, an extra geometric construction is randomly added (like adding a midpoint of a certain line) to see if brute search using that extra raw material might work.<p>I don&#x27;t think this is quite right. The brute force search is performed by a symbolic solver, not the transformer. When it runs out of new deductions, the transformer is asked to suggest possible extra constructions (not randomly added).</div><br/><div id="39032596" class="c"><input type="checkbox" id="c-39032596" checked=""/><div class="controls bullet"><span class="by">nybsjytm</span><span>|</span><a href="#39032275">root</a><span>|</span><a href="#39032487">parent</a><span>|</span><a href="#39032938">next</a><span>|</span><label class="collapse" for="c-39032596">[-]</label><label class="expand" for="c-39032596">[1 more]</label></div><br/><div class="children"><div class="content">Thanks for the correction, it looks like you&#x27;re right.</div><br/></div></div></div></div><div id="39032938" class="c"><input type="checkbox" id="c-39032938" checked=""/><div class="controls bullet"><span class="by">killerstorm</span><span>|</span><a href="#39032275">parent</a><span>|</span><a href="#39032487">prev</a><span>|</span><a href="#39035065">next</a><span>|</span><label class="collapse" for="c-39032938">[-]</label><label class="expand" for="c-39032938">[16 more]</label></div><br/><div class="children"><div class="content">&gt; it&#x27;s still pretty striking how far away the structure of it is from the usual idea of automated reasoning&#x2F;intelligence.<p>How so? Reasoning is fundamentally a search problem.<p>The process you described is exactly the process humans use: i.e. make a guess about what&#x27;s useful, try to work out details mechanically. If get stuck, make another guess, etc. So the process is like searching through a tree.<p>People figured out this process back in 1955 (and made a working prototype which can prove theorems): <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Logic_Theorist" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Logic_Theorist</a> but it all hinges on using good &#x27;heuristics&#x27;. Neural networks are relevant here as they can extract heuristics from data.<p>What do you think is &quot;the usual idea of automated reasoning&quot;? Some magic device which can solve any problem using a single linear pass?</div><br/><div id="39034174" class="c"><input type="checkbox" id="c-39034174" checked=""/><div class="controls bullet"><span class="by">jhrmnn</span><span>|</span><a href="#39032275">root</a><span>|</span><a href="#39032938">parent</a><span>|</span><a href="#39034291">next</a><span>|</span><label class="collapse" for="c-39034174">[-]</label><label class="expand" for="c-39034174">[4 more]</label></div><br/><div class="children"><div class="content">I think the intuition here is that an “intelligent” system would lean much more heavily on the heuristics than on the search, like humans. It’s hard to quantify in this case, but certainly in the case of chess, when engines were about as good as best human players, they were doing orders of magnitude larger search than humans. Which made them feel more like chess _engines_ than chess AI. AlphaZero certainly made a step in the right direction, but it’s still far from how humans play.</div><br/><div id="39034437" class="c"><input type="checkbox" id="c-39034437" checked=""/><div class="controls bullet"><span class="by">killerstorm</span><span>|</span><a href="#39032275">root</a><span>|</span><a href="#39034174">parent</a><span>|</span><a href="#39034291">next</a><span>|</span><label class="collapse" for="c-39034437">[-]</label><label class="expand" for="c-39034437">[3 more]</label></div><br/><div class="children"><div class="content">The comment above mentions &quot;brute force&quot; incorrectly. It&#x27;s fundamentally impossible to brute force googol combinations...</div><br/><div id="39038930" class="c"><input type="checkbox" id="c-39038930" checked=""/><div class="controls bullet"><span class="by">tsimionescu</span><span>|</span><a href="#39032275">root</a><span>|</span><a href="#39034437">parent</a><span>|</span><a href="#39036320">next</a><span>|</span><label class="collapse" for="c-39038930">[-]</label><label class="expand" for="c-39038930">[1 more]</label></div><br/><div class="children"><div class="content">The key insight is this whole thread is that this Alpha Geometry only works <i>because</i> the search field is not a googol combinations. So, it doesn&#x27;t really generalize to many other fields of math. We shouldn&#x27;t expect an AlphaCategoryTheory or AlphaNumberTheory anytime soon.</div><br/></div></div><div id="39036320" class="c"><input type="checkbox" id="c-39036320" checked=""/><div class="controls bullet"><span class="by">nybsjytm</span><span>|</span><a href="#39032275">root</a><span>|</span><a href="#39034437">parent</a><span>|</span><a href="#39038930">prev</a><span>|</span><a href="#39034291">next</a><span>|</span><label class="collapse" for="c-39036320">[-]</label><label class="expand" for="c-39036320">[1 more]</label></div><br/><div class="children"><div class="content">The search space here is not so large. Read this paper, a key part of the present work: <a href="https:&#x2F;&#x2F;doi.org&#x2F;10.1023&#x2F;A:1006171315513" rel="nofollow">https:&#x2F;&#x2F;doi.org&#x2F;10.1023&#x2F;A:1006171315513</a></div><br/></div></div></div></div></div></div><div id="39034291" class="c"><input type="checkbox" id="c-39034291" checked=""/><div class="controls bullet"><span class="by">amelius</span><span>|</span><a href="#39032275">root</a><span>|</span><a href="#39032938">parent</a><span>|</span><a href="#39034174">prev</a><span>|</span><a href="#39033184">next</a><span>|</span><label class="collapse" for="c-39034291">[-]</label><label class="expand" for="c-39034291">[8 more]</label></div><br/><div class="children"><div class="content">Well, what&#x27;s different is that humans invent new abstractions along the way such as complex numbers and Fourier transforms.</div><br/><div id="39034333" class="c"><input type="checkbox" id="c-39034333" checked=""/><div class="controls bullet"><span class="by">MrPatan</span><span>|</span><a href="#39032275">root</a><span>|</span><a href="#39034291">parent</a><span>|</span><a href="#39034321">next</a><span>|</span><label class="collapse" for="c-39034333">[-]</label><label class="expand" for="c-39034333">[6 more]</label></div><br/><div class="children"><div class="content">Not a lot of humans do</div><br/><div id="39035908" class="c"><input type="checkbox" id="c-39035908" checked=""/><div class="controls bullet"><span class="by">skepticATX</span><span>|</span><a href="#39032275">root</a><span>|</span><a href="#39034333">parent</a><span>|</span><a href="#39034395">next</a><span>|</span><label class="collapse" for="c-39035908">[-]</label><label class="expand" for="c-39035908">[1 more]</label></div><br/><div class="children"><div class="content">Every single human has abstractions that are unique to them. Your world model isn’t the same as mine.<p>It’s just that usually these abstractions are fuzzy and hard to formalize, so they aren’t shared. It doesn’t mean that they don’t exist.</div><br/></div></div><div id="39034395" class="c"><input type="checkbox" id="c-39034395" checked=""/><div class="controls bullet"><span class="by">amelius</span><span>|</span><a href="#39032275">root</a><span>|</span><a href="#39034333">parent</a><span>|</span><a href="#39035908">prev</a><span>|</span><a href="#39034548">next</a><span>|</span><label class="collapse" for="c-39034395">[-]</label><label class="expand" for="c-39034395">[3 more]</label></div><br/><div class="children"><div class="content">When a human has done the same thing many times they tend to try to generalize and take shortcuts. And make tools. Perhaps I missed something but I haven&#x27;t seen a neural net do that.</div><br/><div id="39035939" class="c"><input type="checkbox" id="c-39035939" checked=""/><div class="controls bullet"><span class="by">mitthrowaway2</span><span>|</span><a href="#39032275">root</a><span>|</span><a href="#39034395">parent</a><span>|</span><a href="#39034548">next</a><span>|</span><label class="collapse" for="c-39035939">[-]</label><label class="expand" for="c-39035939">[2 more]</label></div><br/><div class="children"><div class="content">Is that very different than the distillation and amplification process that happens during training? Where the neural net learns to predict in one step what initially required several steps of iterated execution.</div><br/><div id="39036244" class="c"><input type="checkbox" id="c-39036244" checked=""/><div class="controls bullet"><span class="by">WalterSear</span><span>|</span><a href="#39032275">root</a><span>|</span><a href="#39035939">parent</a><span>|</span><a href="#39034548">next</a><span>|</span><label class="collapse" for="c-39036244">[-]</label><label class="expand" for="c-39036244">[1 more]</label></div><br/><div class="children"><div class="content">IMHO, yes. It&#x27;s not an (internal) invention occurring as a result of insight into the process - it&#x27;s an (external) human training one model on the output of another model.</div><br/></div></div></div></div></div></div><div id="39034548" class="c"><input type="checkbox" id="c-39034548" checked=""/><div class="controls bullet"><span class="by">littlestymaar</span><span>|</span><a href="#39032275">root</a><span>|</span><a href="#39034333">parent</a><span>|</span><a href="#39034395">prev</a><span>|</span><a href="#39034321">next</a><span>|</span><label class="collapse" for="c-39034548">[-]</label><label class="expand" for="c-39034548">[1 more]</label></div><br/><div class="children"><div class="content">True, but we&#x27;re talking about Olympiad level math skills here.</div><br/></div></div></div></div><div id="39034321" class="c"><input type="checkbox" id="c-39034321" checked=""/><div class="controls bullet"><span class="by">gowld</span><span>|</span><a href="#39032275">root</a><span>|</span><a href="#39034291">parent</a><span>|</span><a href="#39034333">prev</a><span>|</span><a href="#39033184">next</a><span>|</span><label class="collapse" for="c-39034321">[-]</label><label class="expand" for="c-39034321">[1 more]</label></div><br/><div class="children"><div class="content">A neural network is nothing but a heap of new abstractions from data.</div><br/></div></div></div></div><div id="39034105" class="c"><input type="checkbox" id="c-39034105" checked=""/><div class="controls bullet"><span class="by">somewhereoutth</span><span>|</span><a href="#39032275">root</a><span>|</span><a href="#39032938">parent</a><span>|</span><a href="#39033184">prev</a><span>|</span><a href="#39035065">next</a><span>|</span><label class="collapse" for="c-39034105">[-]</label><label class="expand" for="c-39034105">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Some magic device which can solve any problem using a single linear pass?<p>You mean like a calculator?</div><br/><div id="39034328" class="c"><input type="checkbox" id="c-39034328" checked=""/><div class="controls bullet"><span class="by">gowld</span><span>|</span><a href="#39032275">root</a><span>|</span><a href="#39034105">parent</a><span>|</span><a href="#39035065">next</a><span>|</span><label class="collapse" for="c-39034328">[-]</label><label class="expand" for="c-39034328">[1 more]</label></div><br/><div class="children"><div class="content">A calculator that can solve any problem human could, and more? Sure.</div><br/></div></div></div></div></div></div><div id="39035065" class="c"><input type="checkbox" id="c-39035065" checked=""/><div class="controls bullet"><span class="by">alexey-salmin</span><span>|</span><a href="#39032275">parent</a><span>|</span><a href="#39032938">prev</a><span>|</span><a href="#39038183">next</a><span>|</span><label class="collapse" for="c-39035065">[-]</label><label class="expand" for="c-39035065">[1 more]</label></div><br/><div class="children"><div class="content">&gt; When the brute search fails, an extra geometric construction is randomly added (like adding a midpoint of a certain line) to see if brute search using that extra raw material might work<p>That&#x27;s exactly how I was taught geometry in school and I hated it with my all guts. Only after making it into the math department of the university I learned to do it properly and to enjoy it.</div><br/></div></div><div id="39038183" class="c"><input type="checkbox" id="c-39038183" checked=""/><div class="controls bullet"><span class="by">NooneAtAll3</span><span>|</span><a href="#39032275">parent</a><span>|</span><a href="#39035065">prev</a><span>|</span><a href="#39030396">next</a><span>|</span><label class="collapse" for="c-39038183">[-]</label><label class="expand" for="c-39038183">[2 more]</label></div><br/><div class="children"><div class="content">how did you edit your comment after it got visible to others?</div><br/><div id="39038855" class="c"><input type="checkbox" id="c-39038855" checked=""/><div class="controls bullet"><span class="by">tsimionescu</span><span>|</span><a href="#39032275">root</a><span>|</span><a href="#39038183">parent</a><span>|</span><a href="#39030396">next</a><span>|</span><label class="collapse" for="c-39038855">[-]</label><label class="expand" for="c-39038855">[1 more]</label></div><br/><div class="children"><div class="content">You can edit a comment for about an hour if I remember correctly, regardless of it being visible. You can&#x27;t delete it after someone responds to it though.</div><br/></div></div></div></div></div></div><div id="39030396" class="c"><input type="checkbox" id="c-39030396" checked=""/><div class="controls bullet"><span class="by">marojejian</span><span>|</span><a href="#39032275">prev</a><span>|</span><a href="#39032313">next</a><span>|</span><label class="collapse" for="c-39030396">[-]</label><label class="expand" for="c-39030396">[8 more]</label></div><br/><div class="children"><div class="content">Though this particular model doesn&#x27;t sound generalizable, the neuro-symbolic approach seems very promising to me:<p>- linking the (increasingly powerful) &quot;system 1&quot; tools that are most of current ML with more structured &quot;system 2&quot; tools, like logical proof generation, which can plan and and check the veracity &#x2F; value of output.  
- System 2 chugs along &#x27;till it gets stuck, then system 1 jumps in to provide an intuitive guess on what part of state space to check next. 
- Here they leveraged the ability to generate proofs by computer to create a data set of 100m proofs, enabling scalable self-supervised learning. Seem to me the symbolic domains are well formed to allow such generation of data, which while low value in each instance, might allow valuable pre-training in aggregate.<p>Putting these elements together is an approach that could get us quite far.<p>The key milestone will be moving away from the need to use specific formal &#x2F; symbolic domains, and to generate a pretrained system that can generalize the skills learned from those domains.</div><br/><div id="39031209" class="c"><input type="checkbox" id="c-39031209" checked=""/><div class="controls bullet"><span class="by">gizmo686</span><span>|</span><a href="#39030396">parent</a><span>|</span><a href="#39037326">next</a><span>|</span><label class="collapse" for="c-39031209">[-]</label><label class="expand" for="c-39031209">[6 more]</label></div><br/><div class="children"><div class="content">&gt; The key milestone will be moving away from the need to use specific formal &#x2F; symbolic domains, and to generate a pretrained system that can generalize the skills learned from those domains.<p>You do not need to solve everything at once. This approach has the potential to revolution both math and programming by moving formal verification from being a niche tool into a regular part of every practitioners toolbox.<p>It also completely solves (within the domain it applies) one of the most fundamental problems of AI that the current round is calling &quot;hallucinations&quot;; however that solution only works because we have a non AI system to prove correctness.<p>At a high level, this approach is not really that new. Biochem has been using AI to help find candidate molecules, which are then verified by physical experimentation.<p>Combinatorical game AI has been using the AI as an input to old fasion monte carlo searches</div><br/><div id="39034084" class="c"><input type="checkbox" id="c-39034084" checked=""/><div class="controls bullet"><span class="by">initplus</span><span>|</span><a href="#39030396">root</a><span>|</span><a href="#39031209">parent</a><span>|</span><a href="#39034543">next</a><span>|</span><label class="collapse" for="c-39034084">[-]</label><label class="expand" for="c-39034084">[1 more]</label></div><br/><div class="children"><div class="content">&gt;however that solution only works because we have a non AI system to prove correctness<p>But this is actually a really common scenario. Checking a solution for correctness is often much easier than actually finding a correct solution in the first place.</div><br/></div></div><div id="39034543" class="c"><input type="checkbox" id="c-39034543" checked=""/><div class="controls bullet"><span class="by">empath-nirvana</span><span>|</span><a href="#39030396">root</a><span>|</span><a href="#39031209">parent</a><span>|</span><a href="#39034084">prev</a><span>|</span><a href="#39031270">next</a><span>|</span><label class="collapse" for="c-39034543">[-]</label><label class="expand" for="c-39034543">[3 more]</label></div><br/><div class="children"><div class="content">&gt; however that solution only works because we have a non AI system to prove correctness.<p>I&#x27;m not sure why you are calling it non-AI.  There&#x27;s no reason why some AI system has to be some single neural network like GPT and not a hacked together conglomeration of a bunch of neural networks and symbolic logic systems.  Like is it cheating to use a SAT solver?  Is a SAT solver itself not artificial intelligence of a kind?</div><br/><div id="39034833" class="c"><input type="checkbox" id="c-39034833" checked=""/><div class="controls bullet"><span class="by">cubefox</span><span>|</span><a href="#39030396">root</a><span>|</span><a href="#39034543">parent</a><span>|</span><a href="#39031270">next</a><span>|</span><label class="collapse" for="c-39034833">[-]</label><label class="expand" for="c-39034833">[2 more]</label></div><br/><div class="children"><div class="content">In modern terminology, AI = machine learning model. The hand coded GOFAI from the past is just called software.</div><br/><div id="39035983" class="c"><input type="checkbox" id="c-39035983" checked=""/><div class="controls bullet"><span class="by">lucubratory</span><span>|</span><a href="#39030396">root</a><span>|</span><a href="#39034833">parent</a><span>|</span><a href="#39031270">next</a><span>|</span><label class="collapse" for="c-39035983">[-]</label><label class="expand" for="c-39035983">[1 more]</label></div><br/><div class="children"><div class="content">No, you can&#x27;t just declare a word redefined when it is still in common usage in its correct meaning, which includes both GOFAI and deep learning&#x2F;neural network approaches. AI is effect defined, not architecture defined.</div><br/></div></div></div></div></div></div><div id="39031270" class="c"><input type="checkbox" id="c-39031270" checked=""/><div class="controls bullet"><span class="by">jvanderbot</span><span>|</span><a href="#39030396">root</a><span>|</span><a href="#39031209">parent</a><span>|</span><a href="#39034543">prev</a><span>|</span><a href="#39037326">next</a><span>|</span><label class="collapse" for="c-39031270">[-]</label><label class="expand" for="c-39031270">[1 more]</label></div><br/><div class="children"><div class="content">Moreover, it&#x27;s not so recently that people began training networks to help make guesses for branch and bound type solvers.</div><br/></div></div></div></div><div id="39037326" class="c"><input type="checkbox" id="c-39037326" checked=""/><div class="controls bullet"><span class="by">uptownfunk</span><span>|</span><a href="#39030396">parent</a><span>|</span><a href="#39031209">prev</a><span>|</span><a href="#39032313">next</a><span>|</span><label class="collapse" for="c-39037326">[-]</label><label class="expand" for="c-39037326">[1 more]</label></div><br/><div class="children"><div class="content">This I suspect is the closest chance to reaching some flavor of AGI</div><br/></div></div></div></div><div id="39032313" class="c"><input type="checkbox" id="c-39032313" checked=""/><div class="controls bullet"><span class="by">bnprks</span><span>|</span><a href="#39030396">prev</a><span>|</span><a href="#39031259">next</a><span>|</span><label class="collapse" for="c-39032313">[-]</label><label class="expand" for="c-39032313">[4 more]</label></div><br/><div class="children"><div class="content">I appreciate that the authors released code and weights with their paper! This is the first high-profile DeepMind paper I can recall that has runnable inference code + checkpoints released. (Though I&#x27;m happy to be corrected by earlier examples I&#x27;ve missed)<p>I don&#x27;t yet see a public copy of the training set &#x2F; example training code, but still this is a good step towards providing something other researchers can build on -- which is after all the whole point of academic papers!</div><br/><div id="39034262" class="c"><input type="checkbox" id="c-39034262" checked=""/><div class="controls bullet"><span class="by">pk-protect-ai</span><span>|</span><a href="#39032313">parent</a><span>|</span><a href="#39031259">next</a><span>|</span><label class="collapse" for="c-39034262">[-]</label><label class="expand" for="c-39034262">[3 more]</label></div><br/><div class="children"><div class="content">Yeap. I&#x27;m missing the datasets as well. They have generated 100M synthetic examples ... Were these examples generated with AlphaGeometry? Where is the filtering code and initial input to generate these synthetics?<p>Im I&#x27;m wrong that they are using t5 model? At least they are using the sentencepiece t5 vocabulary.<p>How many GPU hours have they spend training this model? Which training parameters were used?<p>Don&#x27;t get me wrong, I find this system fascinating it is what applied engineering should look like. But I&#x27;d like to know more about the training details and the initial data they have used as well as the methods of synthetic data generation.</div><br/><div id="39035284" class="c"><input type="checkbox" id="c-39035284" checked=""/><div class="controls bullet"><span class="by">jsenn</span><span>|</span><a href="#39032313">root</a><span>|</span><a href="#39034262">parent</a><span>|</span><a href="#39031259">next</a><span>|</span><label class="collapse" for="c-39035284">[-]</label><label class="expand" for="c-39035284">[2 more]</label></div><br/><div class="children"><div class="content">The methods section of the paper describes the training data generation as well as the model settings: <a href="https:&#x2F;&#x2F;www.nature.com&#x2F;articles&#x2F;s41586-023-06747-5#Sec16" rel="nofollow">https:&#x2F;&#x2F;www.nature.com&#x2F;articles&#x2F;s41586-023-06747-5#Sec16</a></div><br/><div id="39035303" class="c"><input type="checkbox" id="c-39035303" checked=""/><div class="controls bullet"><span class="by">pk-protect-ai</span><span>|</span><a href="#39032313">root</a><span>|</span><a href="#39035284">parent</a><span>|</span><a href="#39031259">next</a><span>|</span><label class="collapse" for="c-39035303">[-]</label><label class="expand" for="c-39035303">[1 more]</label></div><br/><div class="children"><div class="content">ty for pointing that out!</div><br/></div></div></div></div></div></div></div></div><div id="39031259" class="c"><input type="checkbox" id="c-39031259" checked=""/><div class="controls bullet"><span class="by">Imnimo</span><span>|</span><a href="#39032313">prev</a><span>|</span><a href="#39030661">next</a><span>|</span><label class="collapse" for="c-39031259">[-]</label><label class="expand" for="c-39031259">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;m very curious how often the LM produces a helpful construction. Surely it must be doing better than random chance, but is it throwing out thousands of constructions before it finds a good one, or is it able to generate useful proposals at a rate similar to human experts?<p>They say in the paper, &quot;Because the language model decoding
process returns k different sequences describing k alternative auxiliary
constructions, we perform a beam search over these k options, using
the score of each beam as its value function. This set-up is highly parallelizable across beams, allowing substantial speed-up when there are
parallel computational resources. In our experiments, we use a beam
size of k = 512, the maximum number of iterations is 16 and the branching factor for each node, that is, the decoding batch size, is 32.&quot;<p>But I don&#x27;t totally understand how 512 and 16 translate into total number of constructions proposed. They also note that ablating beam size and max iterations seems to only somewhat degrade performance. Does this imply that the model is actually pretty good at putting helpful constructions near the top, and only for the hardest problems does it need to produce thousands?</div><br/><div id="39031863" class="c"><input type="checkbox" id="c-39031863" checked=""/><div class="controls bullet"><span class="by">kingkongjaffa</span><span>|</span><a href="#39031259">parent</a><span>|</span><a href="#39032246">next</a><span>|</span><label class="collapse" for="c-39031863">[-]</label><label class="expand" for="c-39031863">[1 more]</label></div><br/><div class="children"><div class="content">thanks TIL what Beam search is <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Beam_search" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Beam_search</a></div><br/></div></div><div id="39032246" class="c"><input type="checkbox" id="c-39032246" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#39031259">parent</a><span>|</span><a href="#39031863">prev</a><span>|</span><a href="#39030661">next</a><span>|</span><label class="collapse" for="c-39032246">[-]</label><label class="expand" for="c-39032246">[1 more]</label></div><br/><div class="children"><div class="content">IMHO: this bumps, hard, against limitations of language &#x2F; human-machine analogies.<p>But let&#x27;s try -- TL;DR 262,144, but don&#x27;t take it literally:<p>- The output of a decoding function is a token. ~3&#x2F;4 of a word. Let&#x27;s just say 1 word.<p>- <i>Tokens considered per token output = 262,144</i> Total number of token considerations for 1 output token = beam_size * branching_factor * max_iterations = 512 * 32 * 16 = 262,144.<p>- Let&#x27;s take their sample solution and get a word count. <a href="https:&#x2F;&#x2F;storage.googleapis.com&#x2F;deepmind-media&#x2F;DeepMind.com&#x2F;Blog&#x2F;alphageometry-an-olympiad-level-ai-system-for-geometry%20&#x2F;AlphaGeometry%20solution.pdf" rel="nofollow">https:&#x2F;&#x2F;storage.googleapis.com&#x2F;deepmind-media&#x2F;DeepMind.com&#x2F;B...</a><p>- <i>Total tokens for solution = 2289</i><p>- <i>Total # of tokens considered = 600,047,616</i> = 262,144 * 2289<p>- Hack: &quot;&quot;number of solutions considered&quot;&quot; = total tokens considered &#x2F; total tokens in solution<p>- <i>262,144</i> (same # as number of tokens we viewed at each iteration step, which makes sense)</div><br/></div></div></div></div><div id="39030661" class="c"><input type="checkbox" id="c-39030661" checked=""/><div class="controls bullet"><span class="by">apsec112</span><span>|</span><a href="#39031259">prev</a><span>|</span><a href="#39031779">next</a><span>|</span><label class="collapse" for="c-39030661">[-]</label><label class="expand" for="c-39030661">[6 more]</label></div><br/><div class="children"><div class="content">Interesting that the transformer used is tiny. From the paper:<p>&quot;We use the Meliad library for transformer training with its base settings. The transformer has 12 layers, embedding dimension of 1,024, eight heads of attention and an inter-attention dense layer of dimension 4,096 with ReLU activation. Overall, the transformer has 151 million parameters, excluding embedding layers at its input and output heads. Our customized tokenizer is trained with ‘word’ mode using SentencePiece and has a vocabulary size of 757. We limit the maximum context length to 1,024 tokens and use T5-style relative position embedding. Sequence packing is also used because more than 90% of our sequences are under 200 in length.&quot;</div><br/><div id="39031119" class="c"><input type="checkbox" id="c-39031119" checked=""/><div class="controls bullet"><span class="by">albertzeyer</span><span>|</span><a href="#39030661">parent</a><span>|</span><a href="#39030901">next</a><span>|</span><label class="collapse" for="c-39031119">[-]</label><label class="expand" for="c-39031119">[4 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not tiny, this is a quite normal size outside the field of LLMs, e.g. normal-sized language models, or also translation models, or acoustic models. Some people even would call this large.</div><br/><div id="39031284" class="c"><input type="checkbox" id="c-39031284" checked=""/><div class="controls bullet"><span class="by">apsec112</span><span>|</span><a href="#39030661">root</a><span>|</span><a href="#39031119">parent</a><span>|</span><a href="#39030901">next</a><span>|</span><label class="collapse" for="c-39031284">[-]</label><label class="expand" for="c-39031284">[3 more]</label></div><br/><div class="children"><div class="content">It&#x27;s tiny by the standards of transformers, pretty sure most transformers trained (across all domains) are larger than this</div><br/><div id="39031616" class="c"><input type="checkbox" id="c-39031616" checked=""/><div class="controls bullet"><span class="by">albertzeyer</span><span>|</span><a href="#39030661">root</a><span>|</span><a href="#39031284">parent</a><span>|</span><a href="#39032365">next</a><span>|</span><label class="collapse" for="c-39031616">[-]</label><label class="expand" for="c-39031616">[1 more]</label></div><br/><div class="children"><div class="content">No. Where do you have this from?<p>Looking at NeurIPS 2023:<p><a href="https:&#x2F;&#x2F;openreview.net&#x2F;group?id=NeurIPS.cc&#x2F;2023&#x2F;Conference#tab-accept-spotlight" rel="nofollow">https:&#x2F;&#x2F;openreview.net&#x2F;group?id=NeurIPS.cc&#x2F;2023&#x2F;Conference#t...</a><p>Some random spotlight papers:<p>- <a href="https:&#x2F;&#x2F;openreview.net&#x2F;pdf?id=YkBDJWerKg" rel="nofollow">https:&#x2F;&#x2F;openreview.net&#x2F;pdf?id=YkBDJWerKg</a>: Transformer (VPT) with 248M parameters<p>- <a href="https:&#x2F;&#x2F;openreview.net&#x2F;pdf?id=CAF4CnUblx" rel="nofollow">https:&#x2F;&#x2F;openreview.net&#x2F;pdf?id=CAF4CnUblx</a>: Vit-B&#x2F;16 with 86M parameters<p>- <a href="https:&#x2F;&#x2F;openreview.net&#x2F;pdf?id=3PjCt4kmRx" rel="nofollow">https:&#x2F;&#x2F;openreview.net&#x2F;pdf?id=3PjCt4kmRx</a>: Transformer with 282M parameters<p>Also, in my field (speech recognition, machine translation, language modeling), all using Transformer variants, this is a pretty normal model size.</div><br/></div></div><div id="39032365" class="c"><input type="checkbox" id="c-39032365" checked=""/><div class="controls bullet"><span class="by">kristjansson</span><span>|</span><a href="#39030661">root</a><span>|</span><a href="#39031284">parent</a><span>|</span><a href="#39031616">prev</a><span>|</span><a href="#39030901">next</a><span>|</span><label class="collapse" for="c-39032365">[-]</label><label class="expand" for="c-39032365">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s tiny by the standards of LLMs; _L_LM might give you some indication as to where they fit in the overall landscape.</div><br/></div></div></div></div></div></div><div id="39030901" class="c"><input type="checkbox" id="c-39030901" checked=""/><div class="controls bullet"><span class="by">ipnon</span><span>|</span><a href="#39030661">parent</a><span>|</span><a href="#39031119">prev</a><span>|</span><a href="#39031779">next</a><span>|</span><label class="collapse" for="c-39030901">[-]</label><label class="expand" for="c-39030901">[1 more]</label></div><br/><div class="children"><div class="content">This suggests there may be some more low hanging fruit in the hard sciences for transformers to bite at, so long as they can be properly formulated. This was not a problem of scaling it seems.</div><br/></div></div></div></div><div id="39031779" class="c"><input type="checkbox" id="c-39031779" checked=""/><div class="controls bullet"><span class="by">zodiac</span><span>|</span><a href="#39030661">prev</a><span>|</span><a href="#39035190">next</a><span>|</span><label class="collapse" for="c-39031779">[-]</label><label class="expand" for="c-39031779">[1 more]</label></div><br/><div class="children"><div class="content">The real TIL (to me) is that the previous state-of-the-art could solve 10 of these! I&#x27;d heard there was a decision algorithm for plane geometry problems but I didn&#x27;t know it was a practical one. Some searching turned up <a href="http:&#x2F;&#x2F;www.mmrc.iss.ac.cn&#x2F;~xgao&#x2F;paper&#x2F;book-area.pdf" rel="nofollow">http:&#x2F;&#x2F;www.mmrc.iss.ac.cn&#x2F;~xgao&#x2F;paper&#x2F;book-area.pdf</a> as a reference.</div><br/></div></div><div id="39035190" class="c"><input type="checkbox" id="c-39035190" checked=""/><div class="controls bullet"><span class="by">qrian</span><span>|</span><a href="#39031779">prev</a><span>|</span><a href="#39033814">next</a><span>|</span><label class="collapse" for="c-39035190">[-]</label><label class="expand" for="c-39035190">[5 more]</label></div><br/><div class="children"><div class="content">I was all ready to be skeptical for most of these kind of works its outputs are &#x27;not like human proofs&#x27; but then I saw Evan Chen&#x27;s quote that it is indeed clean human-readable proof. Evan Chen is a prominent member of Olympiad math community and an author of famous Olympiad geometry book[1] so this time I will have to concede that machines indeed have conquered part of the IMO problems.<p>[1]: <a href="https:&#x2F;&#x2F;web.evanchen.cc&#x2F;geombook.html" rel="nofollow">https:&#x2F;&#x2F;web.evanchen.cc&#x2F;geombook.html</a></div><br/><div id="39035557" class="c"><input type="checkbox" id="c-39035557" checked=""/><div class="controls bullet"><span class="by">qrian</span><span>|</span><a href="#39035190">parent</a><span>|</span><a href="#39033814">next</a><span>|</span><label class="collapse" for="c-39035557">[-]</label><label class="expand" for="c-39035557">[4 more]</label></div><br/><div class="children"><div class="content">But then again, there&#x27;s an error in the proof of IMO P3, in Fig1.f and Step 26. of the full proof in supplimentary material[1], which it states that ∠GMD = ∠GO2D, which is incorrect. It should be ∠GMD + ∠GO2D = π. I am trying to follow its logic but I cannot parse Step 25. Did it hallucinate this step?<p>It has the right idea of O2 being on the nine point circle though.<p>edit: I retract my statement. It looks like it is using directed angles[2] which then the statement becomes correct.<p>[1]: <a href="https:&#x2F;&#x2F;storage.googleapis.com&#x2F;deepmind-media&#x2F;DeepMind.com&#x2F;Blog&#x2F;alphageometry-an-olympiad-level-ai-system-for-geometry%20&#x2F;AlphaGeometry%20solution.pdf" rel="nofollow">https:&#x2F;&#x2F;storage.googleapis.com&#x2F;deepmind-media&#x2F;DeepMind.com&#x2F;B...</a><p>[2]: <a href="https:&#x2F;&#x2F;web.evanchen.cc&#x2F;handouts&#x2F;Directed-Angles&#x2F;Directed-Angles.pdf" rel="nofollow">https:&#x2F;&#x2F;web.evanchen.cc&#x2F;handouts&#x2F;Directed-Angles&#x2F;Directed-An...</a></div><br/><div id="39035628" class="c"><input type="checkbox" id="c-39035628" checked=""/><div class="controls bullet"><span class="by">polygamous_bat</span><span>|</span><a href="#39035190">root</a><span>|</span><a href="#39035557">parent</a><span>|</span><a href="#39035649">next</a><span>|</span><label class="collapse" for="c-39035628">[-]</label><label class="expand" for="c-39035628">[2 more]</label></div><br/><div class="children"><div class="content">I haven’t checked the proof yet, but could it be possible that it’s using directed angles? Threw me off initially when I first learned it as well, but it can be handy for different configurations.</div><br/><div id="39035672" class="c"><input type="checkbox" id="c-39035672" checked=""/><div class="controls bullet"><span class="by">qrian</span><span>|</span><a href="#39035190">root</a><span>|</span><a href="#39035628">parent</a><span>|</span><a href="#39035649">next</a><span>|</span><label class="collapse" for="c-39035672">[-]</label><label class="expand" for="c-39035672">[1 more]</label></div><br/><div class="children"><div class="content">Looks like you are correct. I did not know about directed angles. Thanks.</div><br/></div></div></div></div></div></div></div></div><div id="39033814" class="c"><input type="checkbox" id="c-39033814" checked=""/><div class="controls bullet"><span class="by">FranchuFranchu</span><span>|</span><a href="#39035190">prev</a><span>|</span><a href="#39032446">next</a><span>|</span><label class="collapse" for="c-39033814">[-]</label><label class="expand" for="c-39033814">[5 more]</label></div><br/><div class="children"><div class="content">As soon as ChatGPT got released, I tried to make it solve IMO-style problems. It failed.<p>If this is legit, this is huge. Finding geometric proofs means proving things, and proving propositions is what an intelligence does. In my opinion, this is the closest we have gotten so far to AGI. Really excited to see what the future holds.</div><br/><div id="39034308" class="c"><input type="checkbox" id="c-39034308" checked=""/><div class="controls bullet"><span class="by">1024core</span><span>|</span><a href="#39033814">parent</a><span>|</span><a href="#39034365">next</a><span>|</span><label class="collapse" for="c-39034308">[-]</label><label class="expand" for="c-39034308">[1 more]</label></div><br/><div class="children"><div class="content">From the paper:<p>&gt; When producing full natural-language proofs on IMO-AG-30, however, GPT-4 has a success rate of 0% ...</div><br/></div></div><div id="39034365" class="c"><input type="checkbox" id="c-39034365" checked=""/><div class="controls bullet"><span class="by">gowld</span><span>|</span><a href="#39033814">parent</a><span>|</span><a href="#39034308">prev</a><span>|</span><a href="#39038697">next</a><span>|</span><label class="collapse" for="c-39034365">[-]</label><label class="expand" for="c-39034365">[2 more]</label></div><br/><div class="children"><div class="content">Proving propositions has been computer work for several decades.<p>This is not a pure LLM. Search algorithms are obviously incredibly powerful at solving search problems. The LLM contribution is an &quot;intuitive&quot; way to optimize the search.</div><br/><div id="39037795" class="c"><input type="checkbox" id="c-39037795" checked=""/><div class="controls bullet"><span class="by">extractionmech</span><span>|</span><a href="#39033814">root</a><span>|</span><a href="#39034365">parent</a><span>|</span><a href="#39038697">next</a><span>|</span><label class="collapse" for="c-39037795">[-]</label><label class="expand" for="c-39037795">[1 more]</label></div><br/><div class="children"><div class="content">This is basically semantic pruning.</div><br/></div></div></div></div><div id="39038697" class="c"><input type="checkbox" id="c-39038697" checked=""/><div class="controls bullet"><span class="by">CamperBob2</span><span>|</span><a href="#39033814">parent</a><span>|</span><a href="#39034365">prev</a><span>|</span><a href="#39032446">next</a><span>|</span><label class="collapse" for="c-39038697">[-]</label><label class="expand" for="c-39038697">[1 more]</label></div><br/><div class="children"><div class="content"><i>As soon as ChatGPT got released, I tried to make it solve IMO-style problems. It failed.</i><p>Have you tried the same questions with ChatGPT 4?  It is a transformational change (no pun intended) over the earlier releases, and over all open-source models.<p>Just today, I needed to interpret some awkwardly-timestamped log data.  I asked it a few questions along the lines of &quot;What time it was 10,000 seconds before xx:yy:zz?&quot;  It didn&#x27;t give me the answer, <i>but it wrote and executed a Python program that did.</i></div><br/></div></div></div></div><div id="39032446" class="c"><input type="checkbox" id="c-39032446" checked=""/><div class="controls bullet"><span class="by">qwertox</span><span>|</span><a href="#39033814">prev</a><span>|</span><a href="#39030882">next</a><span>|</span><label class="collapse" for="c-39032446">[-]</label><label class="expand" for="c-39032446">[11 more]</label></div><br/><div class="children"><div class="content">Google DeepMind keeps publishing these things while having missed the AI-for-the-people train, that I&#x27;m getting more and more the feeling that they have such a huge arsenal of AI-tech piling up in their secret rooms, as if they&#x27;re already simulating entire AI-based societies.<p>As if they&#x27;re stuck in a loop of &quot;let&#x27;s improve this a bit more until it is even better&quot;, while AGI is already a solved problem for them.<p>Or they&#x27;re just an uncoordinated, chaotic bunch of AI teams without a leader who unifies them. With leader I don&#x27;t mean Demis Hassabis, but rather someone like Sundar Pichai.</div><br/><div id="39036240" class="c"><input type="checkbox" id="c-39036240" checked=""/><div class="controls bullet"><span class="by">ks2048</span><span>|</span><a href="#39032446">parent</a><span>|</span><a href="#39035909">next</a><span>|</span><label class="collapse" for="c-39036240">[-]</label><label class="expand" for="c-39036240">[1 more]</label></div><br/><div class="children"><div class="content">I don’t get the criticism. It seems like basic research and the kind of thing that would lead the way to “AGI” (combining llm-style prediction with logical reasoning). Unless you’re talking about what’s the point of publishing Nature papers - then it’s probably that the people involved want some concrete recognition in their work up to this point. And I supposed tech&#x2F;investor press until they get something useful out from it.</div><br/></div></div><div id="39035909" class="c"><input type="checkbox" id="c-39035909" checked=""/><div class="controls bullet"><span class="by">hacketthfk</span><span>|</span><a href="#39032446">parent</a><span>|</span><a href="#39036240">prev</a><span>|</span><a href="#39033444">next</a><span>|</span><label class="collapse" for="c-39035909">[-]</label><label class="expand" for="c-39035909">[2 more]</label></div><br/><div class="children"><div class="content">They are optimizing for Nature papers, not general usability.<p>Not even one thing they did was without an associated Nature paper, and the paper was always first.</div><br/><div id="39037769" class="c"><input type="checkbox" id="c-39037769" checked=""/><div class="controls bullet"><span class="by">extractionmech</span><span>|</span><a href="#39032446">root</a><span>|</span><a href="#39035909">parent</a><span>|</span><a href="#39033444">next</a><span>|</span><label class="collapse" for="c-39037769">[-]</label><label class="expand" for="c-39037769">[1 more]</label></div><br/><div class="children"><div class="content">Maybe they have a secret client. I mean someone must be doing this for our side. If not them then who?</div><br/></div></div></div></div><div id="39033444" class="c"><input type="checkbox" id="c-39033444" checked=""/><div class="controls bullet"><span class="by">achierius</span><span>|</span><a href="#39032446">parent</a><span>|</span><a href="#39035909">prev</a><span>|</span><a href="#39034885">next</a><span>|</span><label class="collapse" for="c-39033444">[-]</label><label class="expand" for="c-39033444">[1 more]</label></div><br/><div class="children"><div class="content">I think Occam&#x27;s razor would have something to say about the relative likelihood of those two options.</div><br/></div></div><div id="39034885" class="c"><input type="checkbox" id="c-39034885" checked=""/><div class="controls bullet"><span class="by">generationP</span><span>|</span><a href="#39032446">parent</a><span>|</span><a href="#39033444">prev</a><span>|</span><a href="#39032612">next</a><span>|</span><label class="collapse" for="c-39034885">[-]</label><label class="expand" for="c-39034885">[1 more]</label></div><br/><div class="children"><div class="content">What they did here is one of the first steps towards an AI that generates nontrivial and correct mathematical proofs. (An alternative benchmark would be IMO-level inequalities. Other topics such as algebra, combinatorics and number theory are probably no easier than the rest of mathematics, thus less useful as stepping stones.)<p>And an AI that generates nontrivial and correct mathematical proofs would, in turn, be a good first step towards an AI that can &quot;think logically&quot; in the common-sense meaning of the word (i.e., not just mess around with words and sentences but actually have some logical theory behind what it is saying). It might be a dead end, but it might not be. Even if it is, it will be a boon to mathematics.</div><br/></div></div><div id="39032612" class="c"><input type="checkbox" id="c-39032612" checked=""/><div class="controls bullet"><span class="by">nybsjytm</span><span>|</span><a href="#39032446">parent</a><span>|</span><a href="#39034885">prev</a><span>|</span><a href="#39034535">next</a><span>|</span><label class="collapse" for="c-39032612">[-]</label><label class="expand" for="c-39032612">[4 more]</label></div><br/><div class="children"><div class="content">This is at almost the polar opposite end of the spectrum from &quot;AGI,&quot; it&#x27;s centered on brute search.</div><br/><div id="39035610" class="c"><input type="checkbox" id="c-39035610" checked=""/><div class="controls bullet"><span class="by">margorczynski</span><span>|</span><a href="#39032446">root</a><span>|</span><a href="#39032612">parent</a><span>|</span><a href="#39033307">next</a><span>|</span><label class="collapse" for="c-39035610">[-]</label><label class="expand" for="c-39035610">[2 more]</label></div><br/><div class="children"><div class="content">Brute searching all possible mathematical constructs, theorems, etc. to see which one fits the problem would probably take you practiacally an infinite amount of time.<p>This works tbh, how I see it, very closely to how a human does - via &quot;instinct&quot; it gathers relevant knowledge based on the problem and then &quot;brute searches&quot; some combinations to see which one holds. But this &quot;intuition&quot; is the crucial part where brute search completely fails and you need very aggressive compression of the knowledge space.</div><br/><div id="39036332" class="c"><input type="checkbox" id="c-39036332" checked=""/><div class="controls bullet"><span class="by">nybsjytm</span><span>|</span><a href="#39032446">root</a><span>|</span><a href="#39035610">parent</a><span>|</span><a href="#39033307">next</a><span>|</span><label class="collapse" for="c-39036332">[-]</label><label class="expand" for="c-39036332">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Brute searching all possible mathematical constructs, theorems, etc. to see which one fits the problem would probably take you practiacally an infinite amount of time.<p>That&#x27;s not the kind of search which is being done. Read this paper: <a href="https:&#x2F;&#x2F;doi.org&#x2F;10.1023&#x2F;A:1006171315513" rel="nofollow">https:&#x2F;&#x2F;doi.org&#x2F;10.1023&#x2F;A:1006171315513</a></div><br/></div></div></div></div><div id="39033307" class="c"><input type="checkbox" id="c-39033307" checked=""/><div class="controls bullet"><span class="by">danielmarkbruce</span><span>|</span><a href="#39032446">root</a><span>|</span><a href="#39032612">parent</a><span>|</span><a href="#39035610">prev</a><span>|</span><a href="#39034535">next</a><span>|</span><label class="collapse" for="c-39033307">[-]</label><label class="expand" for="c-39033307">[1 more]</label></div><br/><div class="children"><div class="content">They are not polar opposites.</div><br/></div></div></div></div><div id="39034535" class="c"><input type="checkbox" id="c-39034535" checked=""/><div class="controls bullet"><span class="by">senseiV</span><span>|</span><a href="#39032446">parent</a><span>|</span><a href="#39032612">prev</a><span>|</span><a href="#39030882">next</a><span>|</span><label class="collapse" for="c-39034535">[-]</label><label class="expand" for="c-39034535">[1 more]</label></div><br/><div class="children"><div class="content">&gt; simulating entire AI-based societies.<p>Didnt they already have scaled down simulations of this?</div><br/></div></div></div></div><div id="39030882" class="c"><input type="checkbox" id="c-39030882" checked=""/><div class="controls bullet"><span class="by">hcarlens</span><span>|</span><a href="#39032446">prev</a><span>|</span><a href="#39036425">next</a><span>|</span><label class="collapse" for="c-39030882">[-]</label><label class="expand" for="c-39030882">[1 more]</label></div><br/><div class="children"><div class="content">Also relevant: <a href="https:&#x2F;&#x2F;aimoprize.com&#x2F;" rel="nofollow">https:&#x2F;&#x2F;aimoprize.com&#x2F;</a><p>($10m prize for models that can perform well at IMO)</div><br/></div></div><div id="39036425" class="c"><input type="checkbox" id="c-39036425" checked=""/><div class="controls bullet"><span class="by">gisearkr</span><span>|</span><a href="#39030882">prev</a><span>|</span><a href="#39036074">next</a><span>|</span><label class="collapse" for="c-39036425">[-]</label><label class="expand" for="c-39036425">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s a worked example near the article&#x27;s start proving that an isoceles triangle has equal angles: the so-called <i>pons asinorum</i>. The caption concludes with &quot;In this example, just one construct is required.&quot;<p>That strikes me as odd, because I&#x27;d expect the symbolic engine to require <i>zero</i> such constructs to find a proof. Although dropping a bisector is the standard grade-school proof strategy, there&#x27;s a well-known proof that defines no additional entities: since AB = AC, we have (by side-side-side) that △ABC ≅ △ACB, and therefore that ∠ABC = ∠ACB.<p>It&#x27;s funny because what that proof is most famous for is having been rediscovered by an automated theorem prover in the 1950s-1960s. (Wikipedia states that this is a myth, and that it was only rediscovered by Marvin Minsky pretending to be an automated theorem prover... which is true; but then Herbert Gelernter later wrote such a theorem prover! [1])<p>[1] <a href="https:&#x2F;&#x2F;www.qedcat.com&#x2F;function&#x2F;27.3.pdf#page=18" rel="nofollow">https:&#x2F;&#x2F;www.qedcat.com&#x2F;function&#x2F;27.3.pdf#page=18</a></div><br/></div></div><div id="39036074" class="c"><input type="checkbox" id="c-39036074" checked=""/><div class="controls bullet"><span class="by">topsycatt</span><span>|</span><a href="#39036425">prev</a><span>|</span><a href="#39031398">next</a><span>|</span><label class="collapse" for="c-39036074">[-]</label><label class="expand" for="c-39036074">[2 more]</label></div><br/><div class="children"><div class="content">Oh hey! I ghost-wrote an earlier article that references the same idea (<a href="https:&#x2F;&#x2F;blog.google&#x2F;technology&#x2F;ai&#x2F;bard-improved-reasoning-google-sheets-export&#x2F;amp&#x2F;" rel="nofollow">https:&#x2F;&#x2F;blog.google&#x2F;technology&#x2F;ai&#x2F;bard-improved-reasoning-go...</a>). I wonder if they came to it independently or if they read mine and it planted some seeds? Either way, super cool work.</div><br/><div id="39036138" class="c"><input type="checkbox" id="c-39036138" checked=""/><div class="controls bullet"><span class="by">j2kun</span><span>|</span><a href="#39036074">parent</a><span>|</span><a href="#39031398">next</a><span>|</span><label class="collapse" for="c-39036138">[-]</label><label class="expand" for="c-39036138">[1 more]</label></div><br/><div class="children"><div class="content">They have been working on these ideas since like 2021 they said, so I don&#x27;t think it&#x27;s that recent.</div><br/></div></div></div></div><div id="39031398" class="c"><input type="checkbox" id="c-39031398" checked=""/><div class="controls bullet"><span class="by">TFortunato</span><span>|</span><a href="#39036074">prev</a><span>|</span><a href="#39031432">next</a><span>|</span><label class="collapse" for="c-39031398">[-]</label><label class="expand" for="c-39031398">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m a big fan of approaches like this, that combine deep learning &#x2F; newer techniques w&#x2F; &quot;GOFAI&quot; approaches.</div><br/></div></div><div id="39031432" class="c"><input type="checkbox" id="c-39031432" checked=""/><div class="controls bullet"><span class="by">summerlight</span><span>|</span><a href="#39031398">prev</a><span>|</span><a href="#39032760">next</a><span>|</span><label class="collapse" for="c-39031432">[-]</label><label class="expand" for="c-39031432">[2 more]</label></div><br/><div class="children"><div class="content">It looks like there&#x27;s some interesting works to connect ML with symbolic reasoning (or searching). I&#x27;m closer to layman in this area but IIUC the latter is known to be rife with yet-to-be-understood heuristics to prune out the solution space and ML models are pretty good at this area.
I&#x27;m not in a position to suggest what needs to happen to further push the boundary, but in my impression it looks like the current significant blocker is that we don&#x27;t really have a way to construct a self-feedback loop structure that consistently iterates and improves the model from its own output. If this can be done properly, we may see something incredible in a few years.</div><br/><div id="39032399" class="c"><input type="checkbox" id="c-39032399" checked=""/><div class="controls bullet"><span class="by">rafaelero</span><span>|</span><a href="#39031432">parent</a><span>|</span><a href="#39032760">next</a><span>|</span><label class="collapse" for="c-39032399">[-]</label><label class="expand" for="c-39032399">[1 more]</label></div><br/><div class="children"><div class="content">I didn&#x27;t look further into their method, but it seems to me that symbolic reasoning is only important insofar as it makes the solution verifiable. That still is a glorious capability, but a very narrow one.</div><br/></div></div></div></div><div id="39032760" class="c"><input type="checkbox" id="c-39032760" checked=""/><div class="controls bullet"><span class="by">artninja1988</span><span>|</span><a href="#39031432">prev</a><span>|</span><a href="#39032734">next</a><span>|</span><label class="collapse" for="c-39032760">[-]</label><label class="expand" for="c-39032760">[6 more]</label></div><br/><div class="children"><div class="content">&gt;To train AlphaGeometry&#x27;s language model, the researchers had to create their own training data to compensate for the scarcity of existing geometric data. They generated nearly half a billion random geometric diagrams and fed them to the symbolic engine. This engine analyzed each diagram and produced statements about their properties. These statements were organized into 100 million synthetic proofs to train the language model.<p>With all the bickering about copyright, could something similar be used for coding llms? Would kill the ip issues, at least for coding</div><br/><div id="39034894" class="c"><input type="checkbox" id="c-39034894" checked=""/><div class="controls bullet"><span class="by">cubefox</span><span>|</span><a href="#39032760">parent</a><span>|</span><a href="#39033870">next</a><span>|</span><label class="collapse" for="c-39034894">[-]</label><label class="expand" for="c-39034894">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s the topic of this fascinating paper:<p><a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2207.14502" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2207.14502</a></div><br/><div id="39035818" class="c"><input type="checkbox" id="c-39035818" checked=""/><div class="controls bullet"><span class="by">artninja1988</span><span>|</span><a href="#39032760">root</a><span>|</span><a href="#39034894">parent</a><span>|</span><a href="#39033870">next</a><span>|</span><label class="collapse" for="c-39035818">[-]</label><label class="expand" for="c-39035818">[1 more]</label></div><br/><div class="children"><div class="content">Hey, thanks! I&#x27;ll add it to my reading list</div><br/></div></div></div></div><div id="39033870" class="c"><input type="checkbox" id="c-39033870" checked=""/><div class="controls bullet"><span class="by">sangnoir</span><span>|</span><a href="#39032760">parent</a><span>|</span><a href="#39034894">prev</a><span>|</span><a href="#39033243">next</a><span>|</span><label class="collapse" for="c-39033870">[-]</label><label class="expand" for="c-39033870">[1 more]</label></div><br/><div class="children"><div class="content">For language, the symbolic engine itself would likely be trained on copyrighted input, unlike the geometry engine, since math &amp; math facts are not covered by copyright.<p>If you couple random text genrsrion and such an engine for language, you&#x27;d be laundering your training using the extra step (and the quality will likely be worse due to multiplicative errors)</div><br/></div></div><div id="39033243" class="c"><input type="checkbox" id="c-39033243" checked=""/><div class="controls bullet"><span class="by">nodogoto</span><span>|</span><a href="#39032760">parent</a><span>|</span><a href="#39033870">prev</a><span>|</span><a href="#39032734">next</a><span>|</span><label class="collapse" for="c-39033243">[-]</label><label class="expand" for="c-39033243">[2 more]</label></div><br/><div class="children"><div class="content">What statements about properties of randomly generated code snippets would be useful for coding LLMs? You would need to generate text explaining what each snippet does, but that would require an existing coding LLM, so any IP concerns would persist.</div><br/><div id="39033377" class="c"><input type="checkbox" id="c-39033377" checked=""/><div class="controls bullet"><span class="by">artninja1988</span><span>|</span><a href="#39032760">root</a><span>|</span><a href="#39033243">parent</a><span>|</span><a href="#39032734">next</a><span>|</span><label class="collapse" for="c-39033377">[-]</label><label class="expand" for="c-39033377">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, but couldn&#x27;t some system be built that understands what the differnt code snippets do by compiling them or whatever?</div><br/></div></div></div></div></div></div><div id="39032734" class="c"><input type="checkbox" id="c-39032734" checked=""/><div class="controls bullet"><span class="by">zbyforgotp</span><span>|</span><a href="#39032760">prev</a><span>|</span><a href="#39036080">next</a><span>|</span><label class="collapse" for="c-39032734">[-]</label><label class="expand" for="c-39032734">[1 more]</label></div><br/><div class="children"><div class="content">This sounds like the famous system 1 and system 2 thinking with the prover doing the systematic system 2 thinking and the llm doing the intuitive system 1 thinking.</div><br/></div></div><div id="39036080" class="c"><input type="checkbox" id="c-39036080" checked=""/><div class="controls bullet"><span class="by">hyh1048576</span><span>|</span><a href="#39032734">prev</a><span>|</span><a href="#39030607">next</a><span>|</span><label class="collapse" for="c-39036080">[-]</label><label class="expand" for="c-39036080">[1 more]</label></div><br/><div class="children"><div class="content">Maybe it&#x27;s mentioned somewhere but I missed it, could someone provide a list of the five problems that AlphaGeometry failed to solve? The paper mentioned IMO 2008p6 and IMO 2019p2. What are the other three?</div><br/></div></div><div id="39030607" class="c"><input type="checkbox" id="c-39030607" checked=""/><div class="controls bullet"><span class="by">apsec112</span><span>|</span><a href="#39036080">prev</a><span>|</span><a href="#39031971">next</a><span>|</span><label class="collapse" for="c-39030607">[-]</label><label class="expand" for="c-39030607">[1 more]</label></div><br/><div class="children"><div class="content">Links to the paper appear broken, but here is a link:<p><a href="https:&#x2F;&#x2F;www.nature.com&#x2F;articles&#x2F;s41586-023-06747-5" rel="nofollow">https:&#x2F;&#x2F;www.nature.com&#x2F;articles&#x2F;s41586-023-06747-5</a></div><br/></div></div><div id="39031971" class="c"><input type="checkbox" id="c-39031971" checked=""/><div class="controls bullet"><span class="by">ackfoobar</span><span>|</span><a href="#39030607">prev</a><span>|</span><a href="#39034635">next</a><span>|</span><label class="collapse" for="c-39031971">[-]</label><label class="expand" for="c-39031971">[1 more]</label></div><br/><div class="children"><div class="content">Euclidean geometry is decidable. Does that make it easier for computers, compared to other IMO problems?</div><br/></div></div><div id="39034635" class="c"><input type="checkbox" id="c-39034635" checked=""/><div class="controls bullet"><span class="by">compthink</span><span>|</span><a href="#39031971">prev</a><span>|</span><a href="#39034849">next</a><span>|</span><label class="collapse" for="c-39034635">[-]</label><label class="expand" for="c-39034635">[1 more]</label></div><br/><div class="children"><div class="content">Very interesting. I was suspicious they could get an LLM to do this alone, and reading the description they don&#x27;t. It&#x27;s still AI I would say, maybe even more so since it alternates between a generative machine learning model to come up with hypothesis points. But then it uses a optimizer to solve for those pointa and simplify the problem. So it really is a mathematical reasoning system. Also good to note that is tuned specificially to these types of geometry problems.</div><br/></div></div><div id="39034849" class="c"><input type="checkbox" id="c-39034849" checked=""/><div class="controls bullet"><span class="by">generationP</span><span>|</span><a href="#39034635">prev</a><span>|</span><a href="#39030598">next</a><span>|</span><label class="collapse" for="c-39034849">[-]</label><label class="expand" for="c-39034849">[1 more]</label></div><br/><div class="children"><div class="content">What deductive system are they using to verify the proofs? I&#x27;m asking because the conventions of olympiad geometry are slightly different from those of the rest of mathematics (you can make informal &quot;general position&quot; arguments; you can pooh-pooh issues of sign and betweenness; you can apply theorems to unstated limiting cases; etc.), and it is far from obvious to me how this logic can be formalized without causing contradictions.</div><br/></div></div><div id="39030598" class="c"><input type="checkbox" id="c-39030598" checked=""/><div class="controls bullet"><span class="by">sega_sai</span><span>|</span><a href="#39034849">prev</a><span>|</span><a href="#39032713">next</a><span>|</span><label class="collapse" for="c-39030598">[-]</label><label class="expand" for="c-39030598">[1 more]</label></div><br/><div class="children"><div class="content">Just in case the DOI link from the press-release doesn&#x27;t work for you -- <a href="https:&#x2F;&#x2F;www.nature.com&#x2F;articles&#x2F;s41586-023-06747-5" rel="nofollow">https:&#x2F;&#x2F;www.nature.com&#x2F;articles&#x2F;s41586-023-06747-5</a> here&#x27;s the paper.</div><br/></div></div><div id="39032713" class="c"><input type="checkbox" id="c-39032713" checked=""/><div class="controls bullet"><span class="by">sidcool</span><span>|</span><a href="#39030598">prev</a><span>|</span><a href="#39033749">next</a><span>|</span><label class="collapse" for="c-39032713">[-]</label><label class="expand" for="c-39032713">[1 more]</label></div><br/><div class="children"><div class="content">And it&#x27;s been open sourced.  The code and model both!</div><br/></div></div><div id="39033749" class="c"><input type="checkbox" id="c-39033749" checked=""/><div class="controls bullet"><span class="by">ipsum2</span><span>|</span><a href="#39032713">prev</a><span>|</span><a href="#39030188">next</a><span>|</span><label class="collapse" for="c-39033749">[-]</label><label class="expand" for="c-39033749">[2 more]</label></div><br/><div class="children"><div class="content">Do normal proofs for Olympiad level geometry questions require 150+ steps like the one that was generated here? It seems inelegant.</div><br/><div id="39033846" class="c"><input type="checkbox" id="c-39033846" checked=""/><div class="controls bullet"><span class="by">lacker</span><span>|</span><a href="#39033749">parent</a><span>|</span><a href="#39030188">next</a><span>|</span><label class="collapse" for="c-39033846">[-]</label><label class="expand" for="c-39033846">[1 more]</label></div><br/><div class="children"><div class="content">When a human solves these problems, you might state a &quot;step&quot; in natural language. Like, &quot;apply a polar transformation to this diagram&quot;. But that same single step, if you translate into a low-level DSL, could be dozens of different steps.<p>For an example, check out this formalization of a solution to a non-geometry IMO problem:<p><a href="https:&#x2F;&#x2F;gist.github.com&#x2F;mlyean&#x2F;b4cc46cf6b0705c1226511a2b404deff" rel="nofollow">https:&#x2F;&#x2F;gist.github.com&#x2F;mlyean&#x2F;b4cc46cf6b0705c1226511a2b404d...</a><p>Roughly the same solution is written here in human language:<p><a href="https:&#x2F;&#x2F;artofproblemsolving.com&#x2F;wiki&#x2F;index.php&#x2F;1972_IMO_Problems&#x2F;Problem_5" rel="nofollow">https:&#x2F;&#x2F;artofproblemsolving.com&#x2F;wiki&#x2F;index.php&#x2F;1972_IMO_Prob...</a><p>It&#x27;s not precisely clear what counts as a &quot;step&quot; but to me this seems like roughly 50 steps in the low-level formalized proof, and 5 steps in the human-language proof.<p>So, my conclusion is just that I wouldn&#x27;t necessarily say that a 150-step automated proof was inelegant. It can also be that the language used to express these proofs fills in more of the details.<p>It&#x27;s like the difference between counting lines of code in compiled code and a high-level language, counting the steps is really dependent on the level at which you express it.</div><br/></div></div></div></div><div id="39030188" class="c"><input type="checkbox" id="c-39030188" checked=""/><div class="controls bullet"><span class="by">marojejian</span><span>|</span><a href="#39033749">prev</a><span>|</span><a href="#39032244">next</a><span>|</span><label class="collapse" for="c-39030188">[-]</label><label class="expand" for="c-39030188">[1 more]</label></div><br/><div class="children"><div class="content">AlphaGeometry paper:
<a href="https:&#x2F;&#x2F;www.nature.com&#x2F;articles&#x2F;s41586-023-06747-5" rel="nofollow">https:&#x2F;&#x2F;www.nature.com&#x2F;articles&#x2F;s41586-023-06747-5</a></div><br/></div></div><div id="39032244" class="c"><input type="checkbox" id="c-39032244" checked=""/><div class="controls bullet"><span class="by">treprinum</span><span>|</span><a href="#39030188">prev</a><span>|</span><a href="#39031933">next</a><span>|</span><label class="collapse" for="c-39032244">[-]</label><label class="expand" for="c-39032244">[20 more]</label></div><br/><div class="children"><div class="content">What happens to science when the most talented kids won&#x27;t be able to compete in ~2 years tops? Would our civilization reach plateau or start downward trajectory as there will be no incentive to torture oneself to become the best in the world? Will it all fade away like chess once computers started beating grandmasters?</div><br/><div id="39034636" class="c"><input type="checkbox" id="c-39034636" checked=""/><div class="controls bullet"><span class="by">hiAndrewQuinn</span><span>|</span><a href="#39032244">parent</a><span>|</span><a href="#39032280">next</a><span>|</span><label class="collapse" for="c-39034636">[-]</label><label class="expand" for="c-39034636">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve accepted that the human form, with its ~3 pounds of not especially optimized brainpower, is basically going to be relegated to the same status as demoscene hardware for anything that matters after this century.<p>That&#x27;s cool by me, though. This bit of demoscene hardware experiences qualia, and that combination is weird and cool enough to make me want to push myself in new and weird directions. That&#x27;s what play is in a way.</div><br/></div></div><div id="39032280" class="c"><input type="checkbox" id="c-39032280" checked=""/><div class="controls bullet"><span class="by">ironlake</span><span>|</span><a href="#39032244">parent</a><span>|</span><a href="#39034636">prev</a><span>|</span><a href="#39033872">next</a><span>|</span><label class="collapse" for="c-39032280">[-]</label><label class="expand" for="c-39032280">[3 more]</label></div><br/><div class="children"><div class="content">Chess is immensely more popular since Deep Blue beat Kasparov.</div><br/><div id="39035302" class="c"><input type="checkbox" id="c-39035302" checked=""/><div class="controls bullet"><span class="by">treprinum</span><span>|</span><a href="#39032244">root</a><span>|</span><a href="#39032280">parent</a><span>|</span><a href="#39032414">next</a><span>|</span><label class="collapse" for="c-39035302">[-]</label><label class="expand" for="c-39035302">[1 more]</label></div><br/><div class="children"><div class="content">Chess was the drosophila of AI - something one could study in detail and invent newer and newer approaches to solving it. It&#x27;s no longer having that function, was surpassed by Go for a brief moment until that one got solved as well. A whole generation that was raised on this drosophila is slowly fading away, for the new entrants its no longer the game to beat, more like brain stimulating fun exercise&#x2F;hobby and not something capturing imagination, telling us something about the very base of our intelligence anymore.</div><br/></div></div><div id="39032414" class="c"><input type="checkbox" id="c-39032414" checked=""/><div class="controls bullet"><span class="by">jstummbillig</span><span>|</span><a href="#39032244">root</a><span>|</span><a href="#39032280">parent</a><span>|</span><a href="#39035302">prev</a><span>|</span><a href="#39033872">next</a><span>|</span><label class="collapse" for="c-39032414">[-]</label><label class="expand" for="c-39032414">[1 more]</label></div><br/><div class="children"><div class="content">True, but the fun is currently derived from humans going up against humans as a sport. Machines are tools (for learning or cheating) but we are not interested in competition with them.<p>How will it work for math, where humans do useful work right now? I can not see battle math becoming a big thing, but maybe when some of the tedious stuff goes away math will be philosophy and poking the smarter system is where entertainment can be had?</div><br/></div></div></div></div><div id="39033872" class="c"><input type="checkbox" id="c-39033872" checked=""/><div class="controls bullet"><span class="by">lacker</span><span>|</span><a href="#39032244">parent</a><span>|</span><a href="#39032280">prev</a><span>|</span><a href="#39034102">next</a><span>|</span><label class="collapse" for="c-39033872">[-]</label><label class="expand" for="c-39033872">[4 more]</label></div><br/><div class="children"><div class="content">The incentive to compete in the IMO is that it&#x27;s fun to do math contests, it&#x27;s fun to win math contests, and (if you think that far ahead as a high schooler) it looks good on your resume. None of that incentive will go away if the computers get better at math contests.</div><br/><div id="39034647" class="c"><input type="checkbox" id="c-39034647" checked=""/><div class="controls bullet"><span class="by">jhbadger</span><span>|</span><a href="#39032244">root</a><span>|</span><a href="#39033872">parent</a><span>|</span><a href="#39033912">next</a><span>|</span><label class="collapse" for="c-39034647">[-]</label><label class="expand" for="c-39034647">[1 more]</label></div><br/><div class="children"><div class="content">People still compete in foot races even though cars can go faster. People still play chess and Go even though computers can beat them.</div><br/></div></div><div id="39033912" class="c"><input type="checkbox" id="c-39033912" checked=""/><div class="controls bullet"><span class="by">treprinum</span><span>|</span><a href="#39032244">root</a><span>|</span><a href="#39033872">parent</a><span>|</span><a href="#39034647">prev</a><span>|</span><a href="#39034102">next</a><span>|</span><label class="collapse" for="c-39033912">[-]</label><label class="expand" for="c-39033912">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;d be super demoralized if anything I could do a future pocket machine could do much better and faster. Like my very best is not enough to even tread water.</div><br/><div id="39037266" class="c"><input type="checkbox" id="c-39037266" checked=""/><div class="controls bullet"><span class="by">gowld</span><span>|</span><a href="#39032244">root</a><span>|</span><a href="#39033912">parent</a><span>|</span><a href="#39034102">next</a><span>|</span><label class="collapse" for="c-39037266">[-]</label><label class="expand" for="c-39037266">[1 more]</label></div><br/><div class="children"><div class="content">That applies to most things humans so for fun.<p>No one needs these contest math problems solved -- by requirement, they are solved before any student attempts them.</div><br/></div></div></div></div></div></div><div id="39034102" class="c"><input type="checkbox" id="c-39034102" checked=""/><div class="controls bullet"><span class="by">sdenton4</span><span>|</span><a href="#39032244">parent</a><span>|</span><a href="#39033872">prev</a><span>|</span><a href="#39032272">next</a><span>|</span><label class="collapse" for="c-39034102">[-]</label><label class="expand" for="c-39034102">[1 more]</label></div><br/><div class="children"><div class="content">We just need a Netflix series about a geometry prodigy with excellent fashion sense.</div><br/></div></div><div id="39032272" class="c"><input type="checkbox" id="c-39032272" checked=""/><div class="controls bullet"><span class="by">Agingcoder</span><span>|</span><a href="#39032244">parent</a><span>|</span><a href="#39034102">prev</a><span>|</span><a href="#39032491">next</a><span>|</span><label class="collapse" for="c-39032272">[-]</label><label class="expand" for="c-39032272">[2 more]</label></div><br/><div class="children"><div class="content">I never studied math to become the best in the world !</div><br/><div id="39033869" class="c"><input type="checkbox" id="c-39033869" checked=""/><div class="controls bullet"><span class="by">treprinum</span><span>|</span><a href="#39032244">root</a><span>|</span><a href="#39032272">parent</a><span>|</span><a href="#39032491">next</a><span>|</span><label class="collapse" for="c-39033869">[-]</label><label class="expand" for="c-39033869">[1 more]</label></div><br/><div class="children"><div class="content">Are you an Olympiad Gold Medalist? Did you move the field of math significantly (beyond a basic PhD)?</div><br/></div></div></div></div><div id="39032491" class="c"><input type="checkbox" id="c-39032491" checked=""/><div class="controls bullet"><span class="by">jeanloolz</span><span>|</span><a href="#39032244">parent</a><span>|</span><a href="#39032272">prev</a><span>|</span><a href="#39036318">next</a><span>|</span><label class="collapse" for="c-39032491">[-]</label><label class="expand" for="c-39032491">[4 more]</label></div><br/><div class="children"><div class="content">Chess never faded away. It actually has never been as big as it is today.</div><br/><div id="39033933" class="c"><input type="checkbox" id="c-39033933" checked=""/><div class="controls bullet"><span class="by">treprinum</span><span>|</span><a href="#39032244">root</a><span>|</span><a href="#39032491">parent</a><span>|</span><a href="#39036318">next</a><span>|</span><label class="collapse" for="c-39033933">[-]</label><label class="expand" for="c-39033933">[3 more]</label></div><br/><div class="children"><div class="content">That might be true in the number of active chess players, but it&#x27;s no longer viewed as a peak intellectual game and the magic is long gone, just another intense hobby some people do, but basic machines can do better.</div><br/><div id="39038430" class="c"><input type="checkbox" id="c-39038430" checked=""/><div class="controls bullet"><span class="by">mewpmewp2</span><span>|</span><a href="#39032244">root</a><span>|</span><a href="#39033933">parent</a><span>|</span><a href="#39034284">next</a><span>|</span><label class="collapse" for="c-39038430">[-]</label><label class="expand" for="c-39038430">[1 more]</label></div><br/><div class="children"><div class="content">Maybe not the peak intellectual game, because there are overall so many other games, digital as well, but it is unaffected from the fact that computers have beat humans.</div><br/></div></div><div id="39034284" class="c"><input type="checkbox" id="c-39034284" checked=""/><div class="controls bullet"><span class="by">westcoast49</span><span>|</span><a href="#39032244">root</a><span>|</span><a href="#39033933">parent</a><span>|</span><a href="#39038430">prev</a><span>|</span><a href="#39036318">next</a><span>|</span><label class="collapse" for="c-39034284">[-]</label><label class="expand" for="c-39034284">[1 more]</label></div><br/><div class="children"><div class="content">It’a still viewed as a peak intellectual game. And the magic is still there, just watch or listen to the fans of Magnus Carlsen when they’re viewing, discussing or analyzing his games.</div><br/></div></div></div></div></div></div><div id="39036318" class="c"><input type="checkbox" id="c-39036318" checked=""/><div class="controls bullet"><span class="by">WalterSear</span><span>|</span><a href="#39032244">parent</a><span>|</span><a href="#39032491">prev</a><span>|</span><a href="#39035795">next</a><span>|</span><label class="collapse" for="c-39036318">[-]</label><label class="expand" for="c-39036318">[1 more]</label></div><br/><div class="children"><div class="content">The same thing that happened when they allowed calculators in the classroom.</div><br/></div></div><div id="39035795" class="c"><input type="checkbox" id="c-39035795" checked=""/><div class="controls bullet"><span class="by">imranq</span><span>|</span><a href="#39032244">parent</a><span>|</span><a href="#39036318">prev</a><span>|</span><a href="#39034050">next</a><span>|</span><label class="collapse" for="c-39035795">[-]</label><label class="expand" for="c-39035795">[1 more]</label></div><br/><div class="children"><div class="content">Unless you can figure out AI that is available everywhere, all the time (even in the most remote jungle with no power), there will always be value in making humans smarter</div><br/></div></div><div id="39032345" class="c"><input type="checkbox" id="c-39032345" checked=""/><div class="controls bullet"><span class="by">EvgeniyZh</span><span>|</span><a href="#39032244">parent</a><span>|</span><a href="#39034050">prev</a><span>|</span><a href="#39031933">next</a><span>|</span><label class="collapse" for="c-39032345">[-]</label><label class="expand" for="c-39032345">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think chess faded away</div><br/></div></div></div></div><div id="39031933" class="c"><input type="checkbox" id="c-39031933" checked=""/><div class="controls bullet"><span class="by">WhitneyLand</span><span>|</span><a href="#39032244">prev</a><span>|</span><label class="collapse" for="c-39031933">[-]</label><label class="expand" for="c-39031933">[3 more]</label></div><br/><div class="children"><div class="content">It was interesting. One of the reviewers noted that one of the generated proofs didn’t seem that elegant in his opinion.<p>Given enough compute, I wonder how much this would be improved by having it find as many solutions as possible within the allotted time and proposing the simplest one.</div><br/><div id="39032575" class="c"><input type="checkbox" id="c-39032575" checked=""/><div class="controls bullet"><span class="by">jacobolus</span><span>|</span><a href="#39031933">parent</a><span>|</span><a href="#39032190">next</a><span>|</span><label class="collapse" for="c-39032575">[-]</label><label class="expand" for="c-39032575">[1 more]</label></div><br/><div class="children"><div class="content">The issue is that the computer-generated proofs operate at a very low level, step by step, like writing a program in assembly language without the use of coherent structure.<p>The human proof style instead chunks the parts of a solution into human-meaningful &quot;lemmas&quot; (helper theorems) and builds bodies of theory into well-defined and widely used abstractions like complex numbers or derivatives, with a corpus of accepted results.<p>Some human proofs of theorems also have a bit of this flavor of inscrutable lists of highly technical steps, especially the first time something is proven. Over time, the most important theorems are often recast in terms of a more suitable grounding theory, in which they can be proven with a few obvious statements or sometimes a clever trick or two.</div><br/></div></div><div id="39032190" class="c"><input type="checkbox" id="c-39032190" checked=""/><div class="controls bullet"><span class="by">spookie</span><span>|</span><a href="#39031933">parent</a><span>|</span><a href="#39032575">prev</a><span>|</span><label class="collapse" for="c-39032190">[-]</label><label class="expand" for="c-39032190">[1 more]</label></div><br/><div class="children"><div class="content">Elegance would require more than this. Reasoning, for one.</div><br/></div></div></div></div></div></div></div></div></div></body></html>