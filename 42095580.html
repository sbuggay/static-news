<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1731229252712" as="style"/><link rel="stylesheet" href="styles.css?v=1731229252712"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://opencoder-llm.github.io/">OpenCoder: Open Cookbook for Top-Tier Code Large Language Models</a> <span class="domain">(<a href="https://opencoder-llm.github.io">opencoder-llm.github.io</a>)</span></div><div class="subtext"><span>pil0u</span> | <span>55 comments</span></div><br/><div><div id="42096191" class="c"><input type="checkbox" id="c-42096191" checked=""/><div class="controls bullet"><span class="by">marmaduke</span><span>|</span><a href="#42099138">next</a><span>|</span><label class="collapse" for="c-42096191">[-]</label><label class="expand" for="c-42096191">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Unlike most prior efforts, we release not only model weights and inference code, but also the reproducible training data, complete data processing pipeline, rigorous experimental ablation results, and detailed training protocols for open scientific research.<p>Regardless of the specific performance of this model versus another model, I think it’s good to keep in mind that everyone benefits from this kind of work</div><br/><div id="42098558" class="c"><input type="checkbox" id="c-42098558" checked=""/><div class="controls bullet"><span class="by">WiSaGaN</span><span>|</span><a href="#42096191">parent</a><span>|</span><a href="#42099138">next</a><span>|</span><label class="collapse" for="c-42098558">[-]</label><label class="expand" for="c-42098558">[1 more]</label></div><br/><div class="children"><div class="content">This is probably the closest you can get as an &quot;open source&quot; model.</div><br/></div></div></div></div><div id="42099138" class="c"><input type="checkbox" id="c-42099138" checked=""/><div class="controls bullet"><span class="by">chvid</span><span>|</span><a href="#42096191">prev</a><span>|</span><a href="#42098929">next</a><span>|</span><label class="collapse" for="c-42099138">[-]</label><label class="expand" for="c-42099138">[1 more]</label></div><br/><div class="children"><div class="content">Great to see some actual open source!<p>Looking at the training data. For example a  prompt &#x2F; response like this:<p>Prompt:<p>I want to create a Python program that takes a sentence as input and sorts all the words in the sentence in descending order based on their length. How can I achieve this?<p>Response:<p>Certainly! You can create a Python program to sort the words in a sentence by their length in descending order. Here’s a step-by-step guide to achieve this: 1. *Split the sentence into words*: Use the `split()` method to break the sentence into a list of words. 2. *Sort the words by length*: Use the `sorted()` function with a custom key to sort the words by their length in descending order. 3. *Join the sorted words*: Use the `join()` method to combine the sorted words back into a single string. Here&#x27;s a complete Python program that demonstrates this: ```python def sort_words_by_length(sentence): # Step 1: Split the sentence into words words = sentence.split() # Step 2: Sort the words by length in descending order sorted_words = sorted(words, key=len, reverse=True) # Step 3: Join the sorted words back into a single string sorted_sentence = &#x27; &#x27;.join(sorted_words) return sorted_sentence # Example usage sentence = &quot;I want to create a Python program&quot; sorted_sentence = sort_words_by_length(sentence) print(sorted_sentence) ``` ### Explanation: - *`sentence.split()`*: This method splits the input sentence into a list of words based on whitespace. - *`sorted(words, key=len, reverse=True)`*: This sorts the list of words based on their length. The `key=len` argument specifies that the length of each word should be used for sorting, and `reverse=True` ensures the sorting is in descending order. - *`&#x27; &#x27;.join(sorted_words)`*: This joins the sorted list of words back into a single string, with each word separated by a space. ### Example Output: For the input sentence `&quot;I want to create a Python program&quot;`, the output will be: ``` create program Python want ``` This output shows the words sorted by length in descending order.<p>It strikes me that it would easier to train a NN (or another mechanism) if the training that was more structured and the actual question&#x2F;answer was stripped from the plesentaries &#x2F; additional explanations.<p>Also keep the training data to one language (say english &#x2F; python).<p>Ie.:<p>Prompt:<p>sort the words in a sentence by their length in descending order<p>Response:<p>sorted(sentence.split(), key=len, reverse=True)<p>Alternative one could use snippets like above and the synthesize &quot;realistic&quot; prompt &#x2F; responses.</div><br/></div></div><div id="42098929" class="c"><input type="checkbox" id="c-42098929" checked=""/><div class="controls bullet"><span class="by">sysmax</span><span>|</span><a href="#42099138">prev</a><span>|</span><a href="#42096053">next</a><span>|</span><label class="collapse" for="c-42098929">[-]</label><label class="expand" for="c-42098929">[1 more]</label></div><br/><div class="children"><div class="content">I was just messing around with LLMs all day, so had a few test cases open. Asked it to change a few things in a ~6KB C# snippet in a somewhat ambiguous, but reasonable way.<p>GPT-4 did this job perfectly. Qwen:72b did half of the job, completely missed the other one, and renamed 1 variable that had nothing to do with the question. Llama3.1:70b behaved very similar to Qwen, which is interesting.<p>OpenCoder:8b started reasonably well, then randomly replaced &quot;Split(&#x27;\n&#x27;)&quot; with &quot;Split(n)&quot; in unrelated code, and then went completely berserk, hallucinating non-existent StackOverflow pages and answers.<p>For posterity, I saved it here: <a href="https:&#x2F;&#x2F;pastebin.com&#x2F;VRXYFpzr" rel="nofollow">https:&#x2F;&#x2F;pastebin.com&#x2F;VRXYFpzr</a><p>My best guess is that you shouldn&#x27;t train it on mostly code. Natural language conversations used to train other models let them &quot;figure out&quot; human-like reasoning. If your training set is mostly code, it can produce output that looks like code, but it will have little value to humans.<p>Edit: to be fair, llama3.2:3b also botched the code. But it did not hallucinate complete nonsense at least.</div><br/></div></div><div id="42096053" class="c"><input type="checkbox" id="c-42096053" checked=""/><div class="controls bullet"><span class="by">johndough</span><span>|</span><a href="#42098929">prev</a><span>|</span><a href="#42095953">next</a><span>|</span><label class="collapse" for="c-42096053">[-]</label><label class="expand" for="c-42096053">[1 more]</label></div><br/><div class="children"><div class="content">I was wondering why Figure 1 showed a HumanEval score of 61.6 for Qwen2.5-Coder-7B, but Table 1 shows a score of 88.4, i. e. better than this new model with a score of 66.5.<p>The reason is that those are actually two different models (Qwen2.5-Coder-7B-Base with 61.6, Qwen2.5-Coder-7B-Instruct with 88.4).</div><br/></div></div><div id="42095953" class="c"><input type="checkbox" id="c-42095953" checked=""/><div class="controls bullet"><span class="by">atilimcetin</span><span>|</span><a href="#42096053">prev</a><span>|</span><a href="#42097546">next</a><span>|</span><label class="collapse" for="c-42095953">[-]</label><label class="expand" for="c-42095953">[2 more]</label></div><br/><div class="children"><div class="content">Home page of that arxiv paper: <a href="https:&#x2F;&#x2F;opencoder-llm.github.io&#x2F;" rel="nofollow">https:&#x2F;&#x2F;opencoder-llm.github.io&#x2F;</a></div><br/><div id="42096816" class="c"><input type="checkbox" id="c-42096816" checked=""/><div class="controls bullet"><span class="by">dang</span><span>|</span><a href="#42095953">parent</a><span>|</span><a href="#42097546">next</a><span>|</span><label class="collapse" for="c-42096816">[-]</label><label class="expand" for="c-42096816">[1 more]</label></div><br/><div class="children"><div class="content">Thanks! We&#x27;ve changed to that from <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2411.04905" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2411.04905</a>, which is also linked there.</div><br/></div></div></div></div><div id="42097546" class="c"><input type="checkbox" id="c-42097546" checked=""/><div class="controls bullet"><span class="by">rustcleaner</span><span>|</span><a href="#42095953">prev</a><span>|</span><a href="#42096853">next</a><span>|</span><label class="collapse" for="c-42097546">[-]</label><label class="expand" for="c-42097546">[1 more]</label></div><br/><div class="children"><div class="content">Anyone doing training where the metadata of the compilation and execution (like profiling data) is included?  Maybe such inclusion could help nudge models in more code-efficient directions?  I don&#x27;t know, I&#x27;m only a laygenius at this stuff.</div><br/></div></div><div id="42096853" class="c"><input type="checkbox" id="c-42096853" checked=""/><div class="controls bullet"><span class="by">smilebot</span><span>|</span><a href="#42097546">prev</a><span>|</span><a href="#42096012">next</a><span>|</span><label class="collapse" for="c-42096853">[-]</label><label class="expand" for="c-42096853">[2 more]</label></div><br/><div class="children"><div class="content">&gt;Due to the prevalence of forking and copy-pasting within the codebase, nearly
75% of files are completely duplicated.<p>This is surprisingly high. Does the include imported libraries and packages? Since you are hashing at the file level, I am not fully convinced that this is due to people copying entire files over without modification.</div><br/></div></div><div id="42096012" class="c"><input type="checkbox" id="c-42096012" checked=""/><div class="controls bullet"><span class="by">tontoncyber</span><span>|</span><a href="#42096853">prev</a><span>|</span><a href="#42096731">next</a><span>|</span><label class="collapse" for="c-42096012">[-]</label><label class="expand" for="c-42096012">[3 more]</label></div><br/><div class="children"><div class="content">Interesting paper and work but the model doesn&#x27;t seems to be better than Qwen2.5-Coder in some languages including Ruby.</div><br/><div id="42096295" class="c"><input type="checkbox" id="c-42096295" checked=""/><div class="controls bullet"><span class="by">deepsquirrelnet</span><span>|</span><a href="#42096012">parent</a><span>|</span><a href="#42096469">next</a><span>|</span><label class="collapse" for="c-42096295">[-]</label><label class="expand" for="c-42096295">[1 more]</label></div><br/><div class="children"><div class="content">I’ve tried a bunch of different models that are essentially different instruction tuning on base models, and that seems to be generally true in my experience. I don’t think you can fine tune your way into a significantly better code model. At best, one that can follow instructions better, but not one that can usually write noticeably better code or solve harder problems.</div><br/></div></div><div id="42096469" class="c"><input type="checkbox" id="c-42096469" checked=""/><div class="controls bullet"><span class="by">tontoncyber</span><span>|</span><a href="#42096012">parent</a><span>|</span><a href="#42096295">prev</a><span>|</span><a href="#42096731">next</a><span>|</span><label class="collapse" for="c-42096469">[-]</label><label class="expand" for="c-42096469">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m waiting for the 32B! <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=42096027">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=42096027</a></div><br/></div></div></div></div><div id="42096731" class="c"><input type="checkbox" id="c-42096731" checked=""/><div class="controls bullet"><span class="by">IshKebab</span><span>|</span><a href="#42096012">prev</a><span>|</span><a href="#42096368">next</a><span>|</span><label class="collapse" for="c-42096731">[-]</label><label class="expand" for="c-42096731">[1 more]</label></div><br/><div class="children"><div class="content">What kind of hardware do you need to run this?</div><br/></div></div><div id="42096368" class="c"><input type="checkbox" id="c-42096368" checked=""/><div class="controls bullet"><span class="by">4b11b4</span><span>|</span><a href="#42096731">prev</a><span>|</span><a href="#42098443">next</a><span>|</span><label class="collapse" for="c-42096368">[-]</label><label class="expand" for="c-42096368">[1 more]</label></div><br/><div class="children"><div class="content">plumbing is important</div><br/></div></div><div id="42098443" class="c"><input type="checkbox" id="c-42098443" checked=""/><div class="controls bullet"><span class="by">telcal</span><span>|</span><a href="#42096368">prev</a><span>|</span><a href="#42096569">next</a><span>|</span><label class="collapse" for="c-42098443">[-]</label><label class="expand" for="c-42098443">[1 more]</label></div><br/><div class="children"><div class="content">Honestly thought from the title that this was some kind of food recipe cookbook using LLMs.</div><br/></div></div><div id="42096569" class="c"><input type="checkbox" id="c-42096569" checked=""/><div class="controls bullet"><span class="by">hasnain99</span><span>|</span><a href="#42098443">prev</a><span>|</span><a href="#42096727">next</a><span>|</span><label class="collapse" for="c-42096569">[-]</label><label class="expand" for="c-42096569">[1 more]</label></div><br/><div class="children"><div class="content">nice</div><br/></div></div><div id="42096727" class="c"><input type="checkbox" id="c-42096727" checked=""/><div class="controls bullet"><span class="by">v3ss0n</span><span>|</span><a href="#42096569">prev</a><span>|</span><a href="#42095857">next</a><span>|</span><label class="collapse" for="c-42096727">[-]</label><label class="expand" for="c-42096727">[21 more]</label></div><br/><div class="children"><div class="content">Tested , so much hallucination , cannot hold a candle against Qwen 2.5 or even General Purpose model Mistral-Nemo.</div><br/><div id="42098017" class="c"><input type="checkbox" id="c-42098017" checked=""/><div class="controls bullet"><span class="by">UncleOxidant</span><span>|</span><a href="#42096727">parent</a><span>|</span><a href="#42096866">next</a><span>|</span><label class="collapse" for="c-42098017">[-]</label><label class="expand" for="c-42098017">[1 more]</label></div><br/><div class="children"><div class="content">You can try Quen 2.5 here: <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;Qwen&#x2F;Qwen2.5" rel="nofollow">https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;Qwen&#x2F;Qwen2.5</a></div><br/></div></div><div id="42096866" class="c"><input type="checkbox" id="c-42096866" checked=""/><div class="controls bullet"><span class="by">bt1a</span><span>|</span><a href="#42096727">parent</a><span>|</span><a href="#42098017">prev</a><span>|</span><a href="#42098817">next</a><span>|</span><label class="collapse" for="c-42096866">[-]</label><label class="expand" for="c-42096866">[18 more]</label></div><br/><div class="children"><div class="content">To be fair, nothing comes close to Qwen2.5 atm</div><br/><div id="42096950" class="c"><input type="checkbox" id="c-42096950" checked=""/><div class="controls bullet"><span class="by">littlestymaar</span><span>|</span><a href="#42096727">root</a><span>|</span><a href="#42096866">parent</a><span>|</span><a href="#42098898">next</a><span>|</span><label class="collapse" for="c-42096950">[-]</label><label class="expand" for="c-42096950">[12 more]</label></div><br/><div class="children"><div class="content">This is something that&#x27;s obvious to anyone playing with local LLMs but that doesn&#x27;t seem to be that much well-known even among tech enthusiast.<p>Qwen is really ahead of the pack right now when it comes to weight-available models.</div><br/><div id="42097034" class="c"><input type="checkbox" id="c-42097034" checked=""/><div class="controls bullet"><span class="by">tomr75</span><span>|</span><a href="#42096727">root</a><span>|</span><a href="#42096950">parent</a><span>|</span><a href="#42096959">next</a><span>|</span><label class="collapse" for="c-42097034">[-]</label><label class="expand" for="c-42097034">[6 more]</label></div><br/><div class="children"><div class="content">which size are you using?<p>I don&#x27;t see why you would use it over claude and 4o-mini with cursor unless you are working on a top secret repo</div><br/><div id="42097778" class="c"><input type="checkbox" id="c-42097778" checked=""/><div class="controls bullet"><span class="by">underlines</span><span>|</span><a href="#42096727">root</a><span>|</span><a href="#42097034">parent</a><span>|</span><a href="#42097935">next</a><span>|</span><label class="collapse" for="c-42097778">[-]</label><label class="expand" for="c-42097778">[2 more]</label></div><br/><div class="children"><div class="content">the company i work for and actually most Swiss IT contractors have harsh rules, and more than half of our projects, we aren&#x27;t allowed to use Github Copilot or pasting stuff to any LLM API.<p>For that matter I built a vLLM based local GPU machine for our dev squads as a trial. Currently using a 4070Ti Super with 16GB Vram and upgrading to 4x 4070Ti Super to support 70b models.<p>The difficulties we face IMHO:<p>- Cursor doesn&#x27;t support WSL Devcontainers<p>- Small Tab-Complete models are more important, and there&#x27;s less going on for those<p>- There&#x27;s a huge gap between 7-14b and 120b models, not a lot of 70b models available<p>In reality, on 7-14b nothing beats Qwen2.5 for interactive coding and something around 2b for tab-completion</div><br/><div id="42098642" class="c"><input type="checkbox" id="c-42098642" checked=""/><div class="controls bullet"><span class="by">NitpickLawyer</span><span>|</span><a href="#42096727">root</a><span>|</span><a href="#42097778">parent</a><span>|</span><a href="#42097935">next</a><span>|</span><label class="collapse" for="c-42098642">[-]</label><label class="expand" for="c-42098642">[1 more]</label></div><br/><div class="children"><div class="content">&gt; - Cursor doesn&#x27;t support WSL Devcontainers<p>If it works for you, devcontainers now work under Linux w&#x2F; docker.</div><br/></div></div></div></div><div id="42097935" class="c"><input type="checkbox" id="c-42097935" checked=""/><div class="controls bullet"><span class="by">girvo</span><span>|</span><a href="#42096727">root</a><span>|</span><a href="#42097034">parent</a><span>|</span><a href="#42097778">prev</a><span>|</span><a href="#42098320">next</a><span>|</span><label class="collapse" for="c-42097935">[-]</label><label class="expand" for="c-42097935">[2 more]</label></div><br/><div class="children"><div class="content">&gt; I don&#x27;t see why you would use it over claude and 4o-mini with cursor unless you are working on a top secret repo<p>Plenty of companies won&#x27;t let you use those products with our internal code.</div><br/></div></div></div></div><div id="42096959" class="c"><input type="checkbox" id="c-42096959" checked=""/><div class="controls bullet"><span class="by">drawnwren</span><span>|</span><a href="#42096727">root</a><span>|</span><a href="#42096950">parent</a><span>|</span><a href="#42097034">prev</a><span>|</span><a href="#42098898">next</a><span>|</span><label class="collapse" for="c-42096959">[-]</label><label class="expand" for="c-42096959">[5 more]</label></div><br/><div class="children"><div class="content">How does it compare to Claude?</div><br/><div id="42098123" class="c"><input type="checkbox" id="c-42098123" checked=""/><div class="controls bullet"><span class="by">sourcecodeplz</span><span>|</span><a href="#42096727">root</a><span>|</span><a href="#42096959">parent</a><span>|</span><a href="#42097475">next</a><span>|</span><label class="collapse" for="c-42098123">[-]</label><label class="expand" for="c-42098123">[3 more]</label></div><br/><div class="children"><div class="content">Claude is the best at coding but the limits are the problem. You only get like a handful of messages.</div><br/><div id="42098546" class="c"><input type="checkbox" id="c-42098546" checked=""/><div class="controls bullet"><span class="by">yumraj</span><span>|</span><a href="#42096727">root</a><span>|</span><a href="#42098123">parent</a><span>|</span><a href="#42097475">next</a><span>|</span><label class="collapse" for="c-42098546">[-]</label><label class="expand" for="c-42098546">[2 more]</label></div><br/><div class="children"><div class="content">With free or with paid too?</div><br/><div id="42099127" class="c"><input type="checkbox" id="c-42099127" checked=""/><div class="controls bullet"><span class="by">girvo</span><span>|</span><a href="#42096727">root</a><span>|</span><a href="#42098546">parent</a><span>|</span><a href="#42097475">next</a><span>|</span><label class="collapse" for="c-42099127">[-]</label><label class="expand" for="c-42099127">[1 more]</label></div><br/><div class="children"><div class="content">You can pay for Claude API access (not normal Claude Pro) and wire in something like Cline via your API key, but it gets expensive <i>fast</i> in my experience.</div><br/></div></div></div></div></div></div><div id="42097475" class="c"><input type="checkbox" id="c-42097475" checked=""/><div class="controls bullet"><span class="by">behnamoh</span><span>|</span><a href="#42096727">root</a><span>|</span><a href="#42096959">parent</a><span>|</span><a href="#42098123">prev</a><span>|</span><a href="#42098898">next</a><span>|</span><label class="collapse" for="c-42097475">[-]</label><label class="expand" for="c-42097475">[1 more]</label></div><br/><div class="children"><div class="content">nothing compares to claude, not even gpt-4.</div><br/></div></div></div></div></div></div><div id="42098898" class="c"><input type="checkbox" id="c-42098898" checked=""/><div class="controls bullet"><span class="by">guerrilla</span><span>|</span><a href="#42096727">root</a><span>|</span><a href="#42096866">parent</a><span>|</span><a href="#42096950">prev</a><span>|</span><a href="#42096941">next</a><span>|</span><label class="collapse" for="c-42098898">[-]</label><label class="expand" for="c-42098898">[2 more]</label></div><br/><div class="children"><div class="content">Question for those using it. Can the 7B really be used locally on a card with only 16GB VRAM? LLM Explorer says[1] it requires 15.4GB. That seems like cutting it close.<p>1. <a href="https:&#x2F;&#x2F;llm.extractum.io&#x2F;model&#x2F;Qwen%2FQwen2.5-7B,58qKLCI6aniiqWi9q1tMUj" rel="nofollow">https:&#x2F;&#x2F;llm.extractum.io&#x2F;model&#x2F;Qwen%2FQwen2.5-7B,58qKLCI6ani...</a></div><br/><div id="42098952" class="c"><input type="checkbox" id="c-42098952" checked=""/><div class="controls bullet"><span class="by">johndough</span><span>|</span><a href="#42096727">root</a><span>|</span><a href="#42098898">parent</a><span>|</span><a href="#42096941">next</a><span>|</span><label class="collapse" for="c-42098952">[-]</label><label class="expand" for="c-42098952">[1 more]</label></div><br/><div class="children"><div class="content">I am happily using qwen2.5-coder-7b-instruct-q3_k_m.gguf with a context size of 32768 on an RTX 3060 Mobile with 6GB VRAM using llama.cpp [2]. With 16GB VRAM, you could use qwen2.5-7b-instruct-q8_0.gguf which is basically indistinguishable from the fp16 variant.<p>[1] <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;Qwen&#x2F;Qwen2.5-7B-Instruct-GGUF" rel="nofollow">https:&#x2F;&#x2F;huggingface.co&#x2F;Qwen&#x2F;Qwen2.5-7B-Instruct-GGUF</a><p>[2] <a href="https:&#x2F;&#x2F;github.com&#x2F;ggerganov&#x2F;llama.cpp">https:&#x2F;&#x2F;github.com&#x2F;ggerganov&#x2F;llama.cpp</a></div><br/></div></div></div></div><div id="42096941" class="c"><input type="checkbox" id="c-42096941" checked=""/><div class="controls bullet"><span class="by">v3ss0n</span><span>|</span><a href="#42096727">root</a><span>|</span><a href="#42096866">parent</a><span>|</span><a href="#42098898">prev</a><span>|</span><a href="#42097120">next</a><span>|</span><label class="collapse" for="c-42096941">[-]</label><label class="expand" for="c-42096941">[1 more]</label></div><br/><div class="children"><div class="content">don&#x27;t know how they are getting top of Qwen at very poor quality via humaneval bench.</div><br/></div></div><div id="42097120" class="c"><input type="checkbox" id="c-42097120" checked=""/><div class="controls bullet"><span class="by">rnewme</span><span>|</span><a href="#42096727">root</a><span>|</span><a href="#42096866">parent</a><span>|</span><a href="#42096941">prev</a><span>|</span><a href="#42098817">next</a><span>|</span><label class="collapse" for="c-42097120">[-]</label><label class="expand" for="c-42097120">[2 more]</label></div><br/><div class="children"><div class="content">Not even deepseek coder 2.5?</div><br/><div id="42097294" class="c"><input type="checkbox" id="c-42097294" checked=""/><div class="controls bullet"><span class="by">viraptor</span><span>|</span><a href="#42096727">root</a><span>|</span><a href="#42097120">parent</a><span>|</span><a href="#42098817">next</a><span>|</span><label class="collapse" for="c-42097294">[-]</label><label class="expand" for="c-42097294">[1 more]</label></div><br/><div class="children"><div class="content">Not according to the scores here <a href="https:&#x2F;&#x2F;github.com&#x2F;QwenLM&#x2F;Qwen2.5-Coder">https:&#x2F;&#x2F;github.com&#x2F;QwenLM&#x2F;Qwen2.5-Coder</a></div><br/></div></div></div></div></div></div></div></div><div id="42095857" class="c"><input type="checkbox" id="c-42095857" checked=""/><div class="controls bullet"><span class="by">TZubiri</span><span>|</span><a href="#42096727">prev</a><span>|</span><a href="#42095998">next</a><span>|</span><label class="collapse" for="c-42095857">[-]</label><label class="expand" for="c-42095857">[8 more]</label></div><br/><div class="children"><div class="content">What is that &quot;this http URL&quot; thing in the first sentence of the abstract?<p>Is this slob?</div><br/><div id="42095890" class="c"><input type="checkbox" id="c-42095890" checked=""/><div class="controls bullet"><span class="by">Retr0id</span><span>|</span><a href="#42095857">parent</a><span>|</span><a href="#42095889">next</a><span>|</span><label class="collapse" for="c-42095890">[-]</label><label class="expand" for="c-42095890">[2 more]</label></div><br/><div class="children"><div class="content">Bad auto-URL-extraction, presumably. The PDF reads:<p>&gt; Large language models (LLMs) for code have become indispensable in various domains, including code generation, reasoning tasks and agent systems. While open-access code LLMs are increasingly approaching the performance levels of proprietary models,<p>&quot;systems.while&quot; is obviously not a valid domain.</div><br/><div id="42096365" class="c"><input type="checkbox" id="c-42096365" checked=""/><div class="controls bullet"><span class="by">4b11b4</span><span>|</span><a href="#42095857">root</a><span>|</span><a href="#42095890">parent</a><span>|</span><a href="#42095889">next</a><span>|</span><label class="collapse" for="c-42096365">[-]</label><label class="expand" for="c-42096365">[1 more]</label></div><br/><div class="children"><div class="content">while.systems</div><br/></div></div></div></div><div id="42095889" class="c"><input type="checkbox" id="c-42095889" checked=""/><div class="controls bullet"><span class="by">HerrMonnezza</span><span>|</span><a href="#42095857">parent</a><span>|</span><a href="#42095890">prev</a><span>|</span><a href="#42095920">next</a><span>|</span><label class="collapse" for="c-42095889">[-]</label><label class="expand" for="c-42095889">[4 more]</label></div><br/><div class="children"><div class="content">arXiv replaces any URL in the text of the abstract with a link with text &quot;this http url&quot;; it seems the authors did not know this and just embedded a bare URL in their abstract.</div><br/><div id="42095939" class="c"><input type="checkbox" id="c-42095939" checked=""/><div class="controls bullet"><span class="by">vasco</span><span>|</span><a href="#42095857">root</a><span>|</span><a href="#42095889">parent</a><span>|</span><a href="#42095920">next</a><span>|</span><label class="collapse" for="c-42095939">[-]</label><label class="expand" for="c-42095939">[3 more]</label></div><br/><div class="children"><div class="content">I think it mistook a typo that didn&#x27;t add a space after a sentence.</div><br/><div id="42096149" class="c"><input type="checkbox" id="c-42096149" checked=""/><div class="controls bullet"><span class="by">johndough</span><span>|</span><a href="#42095857">root</a><span>|</span><a href="#42095939">parent</a><span>|</span><a href="#42095920">next</a><span>|</span><label class="collapse" for="c-42096149">[-]</label><label class="expand" for="c-42096149">[2 more]</label></div><br/><div class="children"><div class="content">I think this is the relevant code:<p><pre><code>    TLDS = &quot;[a-z][a-z]+&quot; 
</code></pre>
<a href="https:&#x2F;&#x2F;github.com&#x2F;arXiv&#x2F;arxiv-base&#x2F;blob&#x2F;develop&#x2F;arxiv&#x2F;base&#x2F;urls&#x2F;links.py#L116-L123">https:&#x2F;&#x2F;github.com&#x2F;arXiv&#x2F;arxiv-base&#x2F;blob&#x2F;develop&#x2F;arxiv&#x2F;base&#x2F;...</a><p>A more restrictive TLD list would have prevented this, but I certainly don&#x27;t want to be the one to add new TLDs all the time, so I can see why the code looks like it does.</div><br/><div id="42096409" class="c"><input type="checkbox" id="c-42096409" checked=""/><div class="controls bullet"><span class="by">Mathnerd314</span><span>|</span><a href="#42095857">root</a><span>|</span><a href="#42096149">parent</a><span>|</span><a href="#42095920">next</a><span>|</span><label class="collapse" for="c-42096409">[-]</label><label class="expand" for="c-42096409">[1 more]</label></div><br/><div class="children"><div class="content">Mozilla has a list, <a href="https:&#x2F;&#x2F;publicsuffix.org&#x2F;list&#x2F;" rel="nofollow">https:&#x2F;&#x2F;publicsuffix.org&#x2F;list&#x2F;</a>, relatively easy to update. I&#x27;m sure there is some Python wrapper library they could use.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="42095998" class="c"><input type="checkbox" id="c-42095998" checked=""/><div class="controls bullet"><span class="by">mistrial9</span><span>|</span><a href="#42095857">prev</a><span>|</span><label class="collapse" for="c-42095998">[-]</label><label class="expand" for="c-42095998">[8 more]</label></div><br/><div class="children"><div class="content">making a wild guess on the nationality of every author of this paper (1), and observing the number of authors, and observing the velocity and volume of similar papers.. it seems a pattern of &quot;English language as a service to automated programming environments&quot; appears to be very useful and relevant for people (nations?) that are wholly and firmly not English speaking..<p>(1) is M-A-P or INFtech dot ai a well-known institutional affiliation?</div><br/><div id="42096245" class="c"><input type="checkbox" id="c-42096245" checked=""/><div class="controls bullet"><span class="by">jstanley</span><span>|</span><a href="#42095998">parent</a><span>|</span><a href="#42096260">next</a><span>|</span><label class="collapse" for="c-42096245">[-]</label><label class="expand" for="c-42096245">[3 more]</label></div><br/><div class="children"><div class="content">What are you trying to say here?<p>I gave it a few tries but couldn&#x27;t figure it out.</div><br/><div id="42096721" class="c"><input type="checkbox" id="c-42096721" checked=""/><div class="controls bullet"><span class="by">jannyfer</span><span>|</span><a href="#42095998">root</a><span>|</span><a href="#42096245">parent</a><span>|</span><a href="#42097136">next</a><span>|</span><label class="collapse" for="c-42096721">[-]</label><label class="expand" for="c-42096721">[1 more]</label></div><br/><div class="children"><div class="content">It seems proofreading-as-a-service would be very useful for mistrial9.</div><br/></div></div></div></div><div id="42096260" class="c"><input type="checkbox" id="c-42096260" checked=""/><div class="controls bullet"><span class="by">bbor</span><span>|</span><a href="#42095998">parent</a><span>|</span><a href="#42096245">prev</a><span>|</span><a href="#42096551">next</a><span>|</span><label class="collapse" for="c-42096260">[-]</label><label class="expand" for="c-42096260">[1 more]</label></div><br/><div class="children"><div class="content">To be clear: INFTech is a for-profit (I think…?) firm out of Shanghai, and MAP is an international FOSS collective (<a href="https:&#x2F;&#x2F;m-a-p.ai&#x2F;about" rel="nofollow">https:&#x2F;&#x2F;m-a-p.ai&#x2F;about</a>).<p>Speaking generally, a <i>lot</i> of software engineering worldwide is done in English, so it makes sense that they’re training models in English even if some&#x2F;most of the researchers also speak a Chinese language. Plus, HuggingFace is English-native, and working on FOSS models (FOSLMs?) without targeting that community would be like making a command line accounting tool and not immediately posting it to the HackerNews community.<p>Your comment seems to imply some sort of hidden motivation, but idk, seems pretty straightforwardly benign to me! Plus it’s hard to say how many papers are published in other languages about LLMs, considering we wouldn’t read them.</div><br/></div></div><div id="42096551" class="c"><input type="checkbox" id="c-42096551" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#42095998">parent</a><span>|</span><a href="#42096260">prev</a><span>|</span><a href="#42096130">next</a><span>|</span><label class="collapse" for="c-42096551">[-]</label><label class="expand" for="c-42096551">[2 more]</label></div><br/><div class="children"><div class="content">someone on twitter once referred to these as &quot;wechat papers&quot; and i cant get it out of my head</div><br/></div></div></div></div></div></div></div></div></div></body></html>