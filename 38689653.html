<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1702976459616" as="style"/><link rel="stylesheet" href="styles.css?v=1702976459616"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/microsoft/LLMLingua">LLMLingua: Compressing Prompts for Faster Inferencing</a> <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>TarqDirtyToMe</span> | <span>26 comments</span></div><br/><div><div id="38692910" class="c"><input type="checkbox" id="c-38692910" checked=""/><div class="controls bullet"><span class="by">avereveard</span><span>|</span><a href="#38693267">next</a><span>|</span><label class="collapse" for="c-38692910">[-]</label><label class="expand" for="c-38692910">[2 more]</label></div><br/><div class="children"><div class="content">I wonder if this could also be useful in reverse, you&#x27;d have a large expensive llm producing a few tokens per sentence about the answer, then a expansion llm forming sentences out of it.</div><br/><div id="38692941" class="c"><input type="checkbox" id="c-38692941" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#38692910">parent</a><span>|</span><a href="#38693267">next</a><span>|</span><label class="collapse" for="c-38692941">[-]</label><label class="expand" for="c-38692941">[1 more]</label></div><br/><div class="children"><div class="content">the text to image community has upscalers like this… i wonder if useful</div><br/></div></div></div></div><div id="38693267" class="c"><input type="checkbox" id="c-38693267" checked=""/><div class="controls bullet"><span class="by">baq</span><span>|</span><a href="#38692910">prev</a><span>|</span><a href="#38689654">next</a><span>|</span><label class="collapse" for="c-38693267">[-]</label><label class="expand" for="c-38693267">[1 more]</label></div><br/><div class="children"><div class="content">Redundancy is resiliency - wonder if there’s still enough error correction in the compressed language?</div><br/></div></div><div id="38689654" class="c"><input type="checkbox" id="c-38689654" checked=""/><div class="controls bullet"><span class="by">TarqDirtyToMe</span><span>|</span><a href="#38693267">prev</a><span>|</span><a href="#38690615">next</a><span>|</span><label class="collapse" for="c-38689654">[-]</label><label class="expand" for="c-38689654">[11 more]</label></div><br/><div class="children"><div class="content">LLMLingua uses a well-trained small language model after alignment, such as GPT2-small or LLaMA-7B, to detect the unimportant tokens in the prompt and enable inference with the compressed prompt in black-box LLMs, achieving up to 20x compression with minimal performance loss.</div><br/><div id="38693290" class="c"><input type="checkbox" id="c-38693290" checked=""/><div class="controls bullet"><span class="by">sroussey</span><span>|</span><a href="#38689654">parent</a><span>|</span><a href="#38690551">next</a><span>|</span><label class="collapse" for="c-38693290">[-]</label><label class="expand" for="c-38693290">[1 more]</label></div><br/><div class="children"><div class="content">What would happen if instead of the long prompt, you just sent the mean of the embeddings of the prompt tokens?</div><br/></div></div><div id="38690551" class="c"><input type="checkbox" id="c-38690551" checked=""/><div class="controls bullet"><span class="by">cyanydeez</span><span>|</span><a href="#38689654">parent</a><span>|</span><a href="#38693290">prev</a><span>|</span><a href="#38691200">next</a><span>|</span><label class="collapse" for="c-38690551">[-]</label><label class="expand" for="c-38690551">[3 more]</label></div><br/><div class="children"><div class="content">“Why waste time say lot word when few word do trick” -Kevin Malone</div><br/><div id="38692429" class="c"><input type="checkbox" id="c-38692429" checked=""/><div class="controls bullet"><span class="by">arthurcolle</span><span>|</span><a href="#38689654">root</a><span>|</span><a href="#38690551">parent</a><span>|</span><a href="#38690723">next</a><span>|</span><label class="collapse" for="c-38692429">[-]</label><label class="expand" for="c-38692429">[1 more]</label></div><br/><div class="children"><div class="content">Perfection. Key insight. &quot;Few Word [is] All Need&quot; (with a robust enough foundation model)<p>Linked for the culture: <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=bctjSvn-OC8&amp;t=4s" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=bctjSvn-OC8&amp;t=4s</a><p>Sleep big last night</div><br/></div></div></div></div><div id="38691200" class="c"><input type="checkbox" id="c-38691200" checked=""/><div class="controls bullet"><span class="by">behnamoh</span><span>|</span><a href="#38689654">parent</a><span>|</span><a href="#38690551">prev</a><span>|</span><a href="#38690615">next</a><span>|</span><label class="collapse" for="c-38691200">[-]</label><label class="expand" for="c-38691200">[6 more]</label></div><br/><div class="children"><div class="content">Came here to mention this. Whenever I hear &quot;alignment&quot; I immediately say &quot;No way am I going to use that shit&quot;. Seriously, there&#x27;s alignment and then there&#x27;s censorship—the AI creators are using the former when they actually mean the latter. This needs to stop.</div><br/><div id="38691292" class="c"><input type="checkbox" id="c-38691292" checked=""/><div class="controls bullet"><span class="by">TarqDirtyToMe</span><span>|</span><a href="#38689654">root</a><span>|</span><a href="#38691200">parent</a><span>|</span><a href="#38690615">next</a><span>|</span><label class="collapse" for="c-38691292">[-]</label><label class="expand" for="c-38691292">[5 more]</label></div><br/><div class="children"><div class="content">My understanding is that in an academic context you’ll hear alignment anytime a model is tuned to accomplish a certain task, not just to steer its political affiliation and idea of ethics<p>I don’t think this models use of alignment implies any sort of censorship, it’s just being tuned to accomplish the task of outputting only important tokens for the target llm</div><br/><div id="38692457" class="c"><input type="checkbox" id="c-38692457" checked=""/><div class="controls bullet"><span class="by">smeagull</span><span>|</span><a href="#38689654">root</a><span>|</span><a href="#38691292">parent</a><span>|</span><a href="#38691407">prev</a><span>|</span><a href="#38690615">next</a><span>|</span><label class="collapse" for="c-38692457">[-]</label><label class="expand" for="c-38692457">[1 more]</label></div><br/><div class="children"><div class="content">In my experience it means the AI will waste tokens apologizing for it&#x27;s short comings and ignoring task prompts in favour of it&#x27;s alignment.</div><br/></div></div></div></div></div></div></div></div><div id="38690615" class="c"><input type="checkbox" id="c-38690615" checked=""/><div class="controls bullet"><span class="by">thebeardisred</span><span>|</span><a href="#38689654">prev</a><span>|</span><a href="#38691980">next</a><span>|</span><label class="collapse" for="c-38690615">[-]</label><label class="expand" for="c-38690615">[4 more]</label></div><br/><div class="children"><div class="content">Wild.  if I&#x27;m reading this correctly it&#x27;s effectively a sort of &quot;zip&quot; algorithm for both the inputs and outputs of a prompt based model.  thus, it allows a user to compress their request down to the minimal token size which retains the same semantics.  In effect, this then allows a user to encode a more dense set of tokens into the original request.<p>Does that sound about right?</div><br/><div id="38691333" class="c"><input type="checkbox" id="c-38691333" checked=""/><div class="controls bullet"><span class="by">TarqDirtyToMe</span><span>|</span><a href="#38690615">parent</a><span>|</span><a href="#38690734">next</a><span>|</span><label class="collapse" for="c-38691333">[-]</label><label class="expand" for="c-38691333">[1 more]</label></div><br/><div class="children"><div class="content">Sounds right to me. I think it’s fun that is this may be the only compression algorithm where the output is still human understandable.<p>It reads like a slightly garbled version of what someone writing down bullet point notes of a lecture might write.<p>It’s so rare that the human optimized and machine optimized versions of an input are so similar</div><br/></div></div><div id="38690734" class="c"><input type="checkbox" id="c-38690734" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#38690615">parent</a><span>|</span><a href="#38691333">prev</a><span>|</span><a href="#38691980">next</a><span>|</span><label class="collapse" for="c-38690734">[-]</label><label class="expand" for="c-38690734">[2 more]</label></div><br/><div class="children"><div class="content">Yes you&#x27;re correct -- it&#x27;s a really interesting thing, in that it reminds me of early 2023 when people would &quot;compress&quot; prompts by having ChatGPT rewrite it itself into something smaller.<p>There&#x27;s really no substantive difference between that and what they&#x27;re doing here, other than they&#x27;re purposefully using a crappier model than GPT 3.5&#x2F;ChatGPT to increase the cost savings.<p>For example, the first set of graphics is demonstrating switching a long question with 5 Q&#x2F;A examples (&quot;5-shot&quot;, in the literature) into ~4 sentences that are a paraphrasing of the question and have one or two very brief examples without reasoning.<p>That&#x27;s all well and fine if you&#x27;re confident the model is so amazing that it answers as well as it does with 1-shot as it does with 5-shot, but it is very, very, very likely that is not the case. Additionally, now you&#x27;re adding this odd layer between the user&#x27;s input and OpenAI that will easily be &quot;felt&quot;.</div><br/><div id="38691118" class="c"><input type="checkbox" id="c-38691118" checked=""/><div class="controls bullet"><span class="by">3abiton</span><span>|</span><a href="#38690615">root</a><span>|</span><a href="#38690734">parent</a><span>|</span><a href="#38691980">next</a><span>|</span><label class="collapse" for="c-38691118">[-]</label><label class="expand" for="c-38691118">[1 more]</label></div><br/><div class="children"><div class="content">There is a need for a comparison, otherwise I find your assessment of the performance a &quot;bit&quot; subjective.</div><br/></div></div></div></div></div></div><div id="38691980" class="c"><input type="checkbox" id="c-38691980" checked=""/><div class="controls bullet"><span class="by">icanhasjonas</span><span>|</span><a href="#38690615">prev</a><span>|</span><a href="#38692761">next</a><span>|</span><label class="collapse" for="c-38691980">[-]</label><label class="expand" for="c-38691980">[1 more]</label></div><br/><div class="children"><div class="content">Very interesting, we&#x27;ve started on an approach to enable LLM agents communicate and context share in their own language, but I think calling it compression is actually more intuitive. I love this</div><br/></div></div><div id="38692761" class="c"><input type="checkbox" id="c-38692761" checked=""/><div class="controls bullet"><span class="by">joelthelion</span><span>|</span><a href="#38691980">prev</a><span>|</span><a href="#38690607">next</a><span>|</span><label class="collapse" for="c-38692761">[-]</label><label class="expand" for="c-38692761">[1 more]</label></div><br/><div class="children"><div class="content">I wonder if, as humans, we could benefit from this. Could we learn to read this compressed lingo?</div><br/></div></div><div id="38690607" class="c"><input type="checkbox" id="c-38690607" checked=""/><div class="controls bullet"><span class="by">mbb70</span><span>|</span><a href="#38692761">prev</a><span>|</span><a href="#38691206">next</a><span>|</span><label class="collapse" for="c-38690607">[-]</label><label class="expand" for="c-38690607">[2 more]</label></div><br/><div class="children"><div class="content">This always seemed like the end game vs. getting a degree in prompt engineering.<p>If you get enough data on &quot;initial prompt attempt&quot; -&gt; &quot;final successful prompt&quot;, the whole thing can be replaced by a fine tuned model.<p>You would just select a &quot;prompt rewritter llm&quot; that optimizes for accuracy, cost, alignment etc.</div><br/><div id="38691686" class="c"><input type="checkbox" id="c-38691686" checked=""/><div class="controls bullet"><span class="by">pseudosavant</span><span>|</span><a href="#38690607">parent</a><span>|</span><a href="#38691206">next</a><span>|</span><label class="collapse" for="c-38691686">[-]</label><label class="expand" for="c-38691686">[1 more]</label></div><br/><div class="children"><div class="content">GPT on top of GPT. It is turtles all the way down.</div><br/></div></div></div></div></div></div></div></div></div></body></html>