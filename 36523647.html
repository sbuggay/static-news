<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1688115646420" as="style"/><link rel="stylesheet" href="styles.css?v=1688115646420"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://cleanlab.ai/blog/prompt-selection/">Beware of Unreliable Data in Model Evaluation: A LLM Prompt Selection Case Study</a> <span class="domain">(<a href="https://cleanlab.ai">cleanlab.ai</a>)</span></div><div class="subtext"><span>cmauck10</span> | <span>7 comments</span></div><br/><div><div id="36523657" class="c"><input type="checkbox" id="c-36523657" checked=""/><div class="controls bullet"><span class="by">cmauck10</span><span>|</span><a href="#36524653">next</a><span>|</span><label class="collapse" for="c-36523657">[-]</label><label class="expand" for="c-36523657">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s pretty common now for data scientists and ML engineers to validate the quality of their training data being fed into these LLMs, but what about their test data used to evaluate them?<p>I spent some time playing around with the FLAN-T5 open-source LLM from Google Research and I discovered that noisy test&#x2F;evaluation data can actually cause you to choose sub-optimal prompts.<p>Given two prompts A and B, I found multiple cases where prompt A performed better on the observed (noisy) test data, yet worse on the high-quality test data. In reality, this means that you would choose A as the &quot;best prompt&quot; when prompt B is actually the better one. I also proved the accuracy difference to be significant via McNemar’s Test.<p>This article explains my methodology and how I used data-centric AI to automatically clean the noisy test data in order to ensure optimal prompt selection.</div><br/></div></div><div id="36524653" class="c"><input type="checkbox" id="c-36524653" checked=""/><div class="controls bullet"><span class="by">neeleshs</span><span>|</span><a href="#36523657">prev</a><span>|</span><label class="collapse" for="c-36524653">[-]</label><label class="expand" for="c-36524653">[5 more]</label></div><br/><div class="children"><div class="content">Given that LLMs fail to give consistent answers to the same questions, how does that factor into these studies?</div><br/><div id="36525212" class="c"><input type="checkbox" id="c-36525212" checked=""/><div class="controls bullet"><span class="by">cmauck10</span><span>|</span><a href="#36524653">parent</a><span>|</span><a href="#36529553">next</a><span>|</span><label class="collapse" for="c-36525212">[-]</label><label class="expand" for="c-36525212">[1 more]</label></div><br/><div class="children"><div class="content">Most LLMs allow you to specify the temperature parameter that governs the randomness and thus the creativity of the responses. For this experiment I used a very low temperature to ensure consistency for a given prompt.</div><br/></div></div><div id="36529553" class="c"><input type="checkbox" id="c-36529553" checked=""/><div class="controls bullet"><span class="by">Tostino</span><span>|</span><a href="#36524653">parent</a><span>|</span><a href="#36525212">prev</a><span>|</span><label class="collapse" for="c-36529553">[-]</label><label class="expand" for="c-36529553">[3 more]</label></div><br/><div class="children"><div class="content">You can have an LLM be entirely deterministic. This is by design how they work. Having the randomness added to their response is a choice.</div><br/><div id="36529677" class="c"><input type="checkbox" id="c-36529677" checked=""/><div class="controls bullet"><span class="by">svaha1728</span><span>|</span><a href="#36524653">root</a><span>|</span><a href="#36529553">parent</a><span>|</span><label class="collapse" for="c-36529677">[-]</label><label class="expand" for="c-36529677">[2 more]</label></div><br/><div class="children"><div class="content">They can be deterministic, but that doesn’t mean the information they are regurgitating is correct.</div><br/><div id="36529759" class="c"><input type="checkbox" id="c-36529759" checked=""/><div class="controls bullet"><span class="by">Tostino</span><span>|</span><a href="#36524653">root</a><span>|</span><a href="#36529677">parent</a><span>|</span><label class="collapse" for="c-36529759">[-]</label><label class="expand" for="c-36529759">[1 more]</label></div><br/><div class="children"><div class="content">That isn&#x27;t what I was replying to though. Factuality is different than determinism. They are not trained to retain facts. They are trained to predict the next word.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></body></html>