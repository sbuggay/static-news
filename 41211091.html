<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1723539678927" as="style"/><link rel="stylesheet" href="styles.css?v=1723539678927"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.nature.com/articles/s44260-024-00014-y">Antifragility in complex dynamical systems</a> <span class="domain">(<a href="https://www.nature.com">www.nature.com</a>)</span></div><div class="subtext"><span>RafelMri</span> | <span>39 comments</span></div><br/><div><div id="41231644" class="c"><input type="checkbox" id="c-41231644" checked=""/><div class="controls bullet"><span class="by">bob1029</span><span>|</span><a href="#41233128">next</a><span>|</span><label class="collapse" for="c-41231644">[-]</label><label class="expand" for="c-41231644">[6 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve found that intentionally causing abrupt (but reasonable) changes to hyperparameters in evolutionary spiking neural network simulations (I.e between each generation) results in far more robust simulations that will meet fitness criteria with less likelihood of getting stuck somewhere. The tradeoff being that simulating will take longer, but this may be worth things like reducing the chances of your resource requirements going asymptotic half way through.<p>My current method of perturbation is to cap the total # of activations per candidate globally. When at least 3 improvements in the best global fitness score have been achieved, I cut the global activation limit in <i>half</i>. Obviously, this is fairly catastrophic for the current population. Each generation can increase the limit by 1% if no improvements made. This provides aggressive selection pressure for more efficient networks and forces a different kind of partial restart of the training process (I.e. do what you just did with 50% resources now). Very often this does result in optimization of the network. It also seems to make the networks rebound faster after restarts. At first, a restart can take 10-20 generations to recover. By generation 1000, this is closer to 1-2.</div><br/><div id="41232130" class="c"><input type="checkbox" id="c-41232130" checked=""/><div class="controls bullet"><span class="by">UniverseHacker</span><span>|</span><a href="#41231644">parent</a><span>|</span><a href="#41232129">next</a><span>|</span><label class="collapse" for="c-41232130">[-]</label><label class="expand" for="c-41232130">[3 more]</label></div><br/><div class="children"><div class="content">Very cool, but I&#x27;m surprised you&#x27;re sharing this on here and not in a job interview with a deep learning startup and&#x2F;or an arXiv paper.</div><br/><div id="41232191" class="c"><input type="checkbox" id="c-41232191" checked=""/><div class="controls bullet"><span class="by">bob1029</span><span>|</span><a href="#41231644">root</a><span>|</span><a href="#41232130">parent</a><span>|</span><a href="#41232129">next</a><span>|</span><label class="collapse" for="c-41232191">[-]</label><label class="expand" for="c-41232191">[2 more]</label></div><br/><div class="children"><div class="content">&gt; a job interview with a deep learning startup<p>I am not aware of any DL startups that are interested in techniques which are incompatible with GPUs and back propagation. I think this is a solo journey through the dark forest for now.</div><br/><div id="41232342" class="c"><input type="checkbox" id="c-41232342" checked=""/><div class="controls bullet"><span class="by">inciampati</span><span>|</span><a href="#41231644">root</a><span>|</span><a href="#41232191">parent</a><span>|</span><a href="#41232129">next</a><span>|</span><label class="collapse" for="c-41232342">[-]</label><label class="expand" for="c-41232342">[1 more]</label></div><br/><div class="children"><div class="content">Eloquent, realistic, and sad. I&#x27;m living my own version of this (in biotech). The journey is the wonder.</div><br/></div></div></div></div></div></div><div id="41232129" class="c"><input type="checkbox" id="c-41232129" checked=""/><div class="controls bullet"><span class="by">JackeJR</span><span>|</span><a href="#41231644">parent</a><span>|</span><a href="#41232130">prev</a><span>|</span><a href="#41233128">next</a><span>|</span><label class="collapse" for="c-41232129">[-]</label><label class="expand" for="c-41232129">[2 more]</label></div><br/><div class="children"><div class="content">I am quite curious about your approach, Do you have an example code somewhere?</div><br/><div id="41232256" class="c"><input type="checkbox" id="c-41232256" checked=""/><div class="controls bullet"><span class="by">bob1029</span><span>|</span><a href="#41231644">root</a><span>|</span><a href="#41232129">parent</a><span>|</span><a href="#41233128">next</a><span>|</span><label class="collapse" for="c-41232256">[-]</label><label class="expand" for="c-41232256">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;d start here: <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2406.12552" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2406.12552</a><p>I will say that less is more and &quot;The Bitter Lesson&quot; applies here. Chasing biologically-inspired rabbits, such as STDP and LIF (see paper above&#x2F;wikipedia), does seem to be a waste of time, especially when we have this thing entirely outside of biology that can arbitrarily replicate, serialize, mutate and simulate billions of instances of the same parent candidate in minutes-hours.<p>Leaky charge carriers and inability to persist learned weights between candidate instantiations are limitations, not features to emulate. Imagine if you could be reincarnated with all of the exact knowledge you have today. Then clone that 1000 times and apply subtle mutations to it. Then, put these clones in an FFA arena and see who wins based upon a very well crafted fitness function. Then, do all of that over and over thousands of times per hour.</div><br/></div></div></div></div></div></div><div id="41233128" class="c"><input type="checkbox" id="c-41233128" checked=""/><div class="controls bullet"><span class="by">fasteo</span><span>|</span><a href="#41231644">prev</a><span>|</span><a href="#41231811">next</a><span>|</span><label class="collapse" for="c-41233128">[-]</label><label class="expand" for="c-41233128">[4 more]</label></div><br/><div class="children"><div class="content">Random note: Antifragility is called hormesis in living organisms, a concept that existed since the 1950s when the wrong dose - too low - of herbicides made the plants stronger.</div><br/><div id="41233610" class="c"><input type="checkbox" id="c-41233610" checked=""/><div class="controls bullet"><span class="by">0134340</span><span>|</span><a href="#41233128">parent</a><span>|</span><a href="#41233385">next</a><span>|</span><label class="collapse" for="c-41233610">[-]</label><label class="expand" for="c-41233610">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s what immediately came to mind when reading OP&#x27;s comment. He&#x27;s basically describing the action of perturbing a system just enough with a weak force that it &#x27;innoculates&#x27;, for lack of a better word, itself against similar but stronger forces.</div><br/></div></div><div id="41233385" class="c"><input type="checkbox" id="c-41233385" checked=""/><div class="controls bullet"><span class="by">Beretta_Vexee</span><span>|</span><a href="#41233128">parent</a><span>|</span><a href="#41233610">prev</a><span>|</span><a href="#41231811">next</a><span>|</span><label class="collapse" for="c-41233385">[-]</label><label class="expand" for="c-41233385">[2 more]</label></div><br/><div class="children"><div class="content">Mechanical engineering uses the term system resilience. I must admit I don&#x27;t like antifragility, which sounds like a novlang and is poorly defined.</div><br/><div id="41233470" class="c"><input type="checkbox" id="c-41233470" checked=""/><div class="controls bullet"><span class="by">dmichulke</span><span>|</span><a href="#41233128">root</a><span>|</span><a href="#41233385">parent</a><span>|</span><a href="#41231811">next</a><span>|</span><label class="collapse" for="c-41233470">[-]</label><label class="expand" for="c-41233470">[1 more]</label></div><br/><div class="children"><div class="content">Resilience is not the same, a system is anti-fragile if it gets stronger under stress.<p>Resilience is just &quot;not getting weaker&quot;.</div><br/></div></div></div></div></div></div><div id="41231811" class="c"><input type="checkbox" id="c-41231811" checked=""/><div class="controls bullet"><span class="by">delichon</span><span>|</span><a href="#41233128">prev</a><span>|</span><a href="#41232494">next</a><span>|</span><label class="collapse" for="c-41231811">[-]</label><label class="expand" for="c-41231811">[7 more]</label></div><br/><div class="children"><div class="content"><p><pre><code>  Systems or organisms can be defined as antifragile if they derive benefit from systemic variability, volatility, randomness, or disorder.
</code></pre>
If that&#x27;s a riddle, death fits. Those things are characteristic of the pestilence, famine, war, etc. that feed death. The decay surrounding death is complex and dynamical. And death is more sustainable than any living system.</div><br/><div id="41232058" class="c"><input type="checkbox" id="c-41232058" checked=""/><div class="controls bullet"><span class="by">UniverseHacker</span><span>|</span><a href="#41231811">parent</a><span>|</span><a href="#41232066">next</a><span>|</span><label class="collapse" for="c-41232058">[-]</label><label class="expand" for="c-41232058">[4 more]</label></div><br/><div class="children"><div class="content">but death isn&#x27;t a system or organism...</div><br/><div id="41232721" class="c"><input type="checkbox" id="c-41232721" checked=""/><div class="controls bullet"><span class="by">tinix</span><span>|</span><a href="#41231811">root</a><span>|</span><a href="#41232058">parent</a><span>|</span><a href="#41232125">next</a><span>|</span><label class="collapse" for="c-41232721">[-]</label><label class="expand" for="c-41232721">[1 more]</label></div><br/><div class="children"><div class="content">you are an organism that is continually dying.<p><a href="https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Autophagy" rel="nofollow">https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Autophagy</a><p><a href="https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Secondary_succession" rel="nofollow">https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Secondary_succession</a><p><a href="https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Restructuring" rel="nofollow">https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Restructuring</a><p><a href="https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Code_refactoring" rel="nofollow">https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Code_refactoring</a><p><a href="https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Shiva" rel="nofollow">https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Shiva</a><p><a href="https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Tandava" rel="nofollow">https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Tandava</a><p>it&#x27;s all the same shit</div><br/></div></div><div id="41232125" class="c"><input type="checkbox" id="c-41232125" checked=""/><div class="controls bullet"><span class="by">fsckboy</span><span>|</span><a href="#41231811">root</a><span>|</span><a href="#41232058">parent</a><span>|</span><a href="#41232721">prev</a><span>|</span><a href="#41232066">next</a><span>|</span><label class="collapse" for="c-41232125">[-]</label><label class="expand" for="c-41232125">[2 more]</label></div><br/><div class="children"><div class="content">&gt;<i>but death isn&#x27;t a system</i><p>death is entropy. do you know of a system without entropy?<p>&gt;<i>or organism...</i><p>boy are you going to be surprised when you answer that knock on the door, eh?</div><br/><div id="41233515" class="c"><input type="checkbox" id="c-41233515" checked=""/><div class="controls bullet"><span class="by">BriggyDwiggs42</span><span>|</span><a href="#41231811">root</a><span>|</span><a href="#41232125">parent</a><span>|</span><a href="#41232066">next</a><span>|</span><label class="collapse" for="c-41233515">[-]</label><label class="expand" for="c-41233515">[1 more]</label></div><br/><div class="children"><div class="content">Isn’t it definitely not an organism? If death is the inevitable process from order to disorder, isn’t it deeply a-systemic at its core? If it were a system, it would also eventually have to end.</div><br/></div></div></div></div></div></div><div id="41232066" class="c"><input type="checkbox" id="c-41232066" checked=""/><div class="controls bullet"><span class="by">jrsdav</span><span>|</span><a href="#41231811">parent</a><span>|</span><a href="#41232058">prev</a><span>|</span><a href="#41232147">next</a><span>|</span><label class="collapse" for="c-41232066">[-]</label><label class="expand" for="c-41232066">[1 more]</label></div><br/><div class="children"><div class="content">So life as a system benefits from the randomness — but inevitableness — of death, is how I interpret that. Benefits as in, key to its continual perpetuation.</div><br/></div></div><div id="41232147" class="c"><input type="checkbox" id="c-41232147" checked=""/><div class="controls bullet"><span class="by">diab0lic</span><span>|</span><a href="#41231811">parent</a><span>|</span><a href="#41232066">prev</a><span>|</span><a href="#41232494">next</a><span>|</span><label class="collapse" for="c-41232147">[-]</label><label class="expand" for="c-41232147">[1 more]</label></div><br/><div class="children"><div class="content">The whole conversation is very scope dependent. A species can be antifragile specifically because the constituent organisms are fragile. The species evolves not in spite of death and mutation (variation) of the organisms but because of it.<p>At the same time organisms themselves can be antifragile at a different scope. My body gets stronger when I stress the muscles, and gets weaker when I do not.<p>Edit to add… it is also very dose dependent. Zero muscle stress and I get weaker. Some and I get strong. Too much and I get rhabdomyolysis — an absorbing barrier.<p>Same goes for the species. No death means no evolution. Some means evolution. Extinction level deaths are an absorbing barrier.</div><br/></div></div></div></div><div id="41232494" class="c"><input type="checkbox" id="c-41232494" checked=""/><div class="controls bullet"><span class="by">mo_42</span><span>|</span><a href="#41231811">prev</a><span>|</span><a href="#41231816">next</a><span>|</span><label class="collapse" for="c-41232494">[-]</label><label class="expand" for="c-41232494">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;d like to point out that Norbert Wiener was the first to discover the concept of antifragility (under a different term though).<p>It&#x27;s also worth checking out more of his works as he initiated the field of cybernetics.</div><br/><div id="41232546" class="c"><input type="checkbox" id="c-41232546" checked=""/><div class="controls bullet"><span class="by">agumonkey</span><span>|</span><a href="#41232494">parent</a><span>|</span><a href="#41231816">next</a><span>|</span><label class="collapse" for="c-41232546">[-]</label><label class="expand" for="c-41232546">[2 more]</label></div><br/><div class="children"><div class="content">Where did he described this? (Honest question)</div><br/><div id="41233155" class="c"><input type="checkbox" id="c-41233155" checked=""/><div class="controls bullet"><span class="by">mo_42</span><span>|</span><a href="#41232494">root</a><span>|</span><a href="#41232546">parent</a><span>|</span><a href="#41231816">next</a><span>|</span><label class="collapse" for="c-41233155">[-]</label><label class="expand" for="c-41233155">[1 more]</label></div><br/><div class="children"><div class="content">To be correct, he maybe didn&#x27;t coin the term. At least I didn&#x27;t find it on quick search in his book Cybernetics. Seems like the term ultrastable actually comes from Ashby [1].<p>[1] <a href="https:&#x2F;&#x2F;users.sussex.ac.uk&#x2F;~ezequiel&#x2F;AS&#x2F;lectures&#x2F;AdaptiveSystems3.pdf" rel="nofollow">https:&#x2F;&#x2F;users.sussex.ac.uk&#x2F;~ezequiel&#x2F;AS&#x2F;lectures&#x2F;AdaptiveSys...</a></div><br/></div></div></div></div></div></div><div id="41231816" class="c"><input type="checkbox" id="c-41231816" checked=""/><div class="controls bullet"><span class="by">AgentOrange1234</span><span>|</span><a href="#41232494">prev</a><span>|</span><a href="#41232098">next</a><span>|</span><label class="collapse" for="c-41231816">[-]</label><label class="expand" for="c-41231816">[9 more]</label></div><br/><div class="children"><div class="content">I wish folks would write more plainly. “Antifragility characterizes the benefit of a dynamical system derived from the variability in environmental perturbations.” Geish.</div><br/><div id="41232141" class="c"><input type="checkbox" id="c-41232141" checked=""/><div class="controls bullet"><span class="by">theOGognf</span><span>|</span><a href="#41231816">parent</a><span>|</span><a href="#41232078">next</a><span>|</span><label class="collapse" for="c-41232141">[-]</label><label class="expand" for="c-41232141">[1 more]</label></div><br/><div class="children"><div class="content">Ironically, that sentence is pretty plain for a dynamics and control paper lol</div><br/></div></div><div id="41232078" class="c"><input type="checkbox" id="c-41232078" checked=""/><div class="controls bullet"><span class="by">UniverseHacker</span><span>|</span><a href="#41231816">parent</a><span>|</span><a href="#41232141">prev</a><span>|</span><a href="#41232098">next</a><span>|</span><label class="collapse" for="c-41232078">[-]</label><label class="expand" for="c-41232078">[7 more]</label></div><br/><div class="children"><div class="content">Well it is in a journal called &quot;complexity.&quot; But I agree, that sentence is awful, I&#x27;m surprised they decided to lead with it, and nobody proof reading the paper objected.</div><br/><div id="41232140" class="c"><input type="checkbox" id="c-41232140" checked=""/><div class="controls bullet"><span class="by">defrost</span><span>|</span><a href="#41231816">root</a><span>|</span><a href="#41232078">parent</a><span>|</span><a href="#41232098">next</a><span>|</span><label class="collapse" for="c-41232140">[-]</label><label class="expand" for="c-41232140">[6 more]</label></div><br/><div class="children"><div class="content">The leading three authors are from Germany, Mexico, and Switzerland resptfully.<p>The sentence they want should capture the notion of being robust when poked with a stick.<p>A pencil on it&#x27;s tip is a fragile system, one burp and it falls to the table, far from the intial state. Marbles in fruit bowls are anti-fragile, given a good shake (up to a threshold) and they remain in the bowl and return to the low centre.<p>Reading further, they want more; that repeated perturbations should deliver <i>benefit</i>, that systems in an warped egg carton configuration can be annealed to reveal an optimal point by vigorous shaking slowly reduced in degree.<p>Having now read the whole paper it doesn&#x27;t seem novel wrt to the state of dynamic system discussions in the mid 1980s other than the insertion of &quot;antifragility&quot; as nomenclature into the mix.</div><br/><div id="41232214" class="c"><input type="checkbox" id="c-41232214" checked=""/><div class="controls bullet"><span class="by">wenc</span><span>|</span><a href="#41231816">root</a><span>|</span><a href="#41232140">parent</a><span>|</span><a href="#41232098">next</a><span>|</span><label class="collapse" for="c-41232214">[-]</label><label class="expand" for="c-41232214">[5 more]</label></div><br/><div class="children"><div class="content">&gt; A pencil on it&#x27;s tip is a fragile system, one burp and it falls to the table, far from the intial state. Marbles in fruit bowls are anti-fragile, given a good shake (up to a threshold) and they remain in the bowl and return to the low centre.<p>I believe what you&#x27;re describing is a stable vs unstable system, not fragile vs antifragile.<p>You can perturb a bowl with a marble, and the marble will still end up in the middle because it will return to stable equilibrium point (an &quot;attractor&quot;). Yours is an illustration of a stable system. Whereas a marble placed in an upside down bowl (with no ridges, just a half sphere), when perturbed, will fall off. This is an unstable system. These are classic examples used in (Lyapunov) stability theory.<p>Fragility and antifragility aren&#x27;t about stability (returning to equilibria), but gains or losses after perturbation, which is related to convexity&#x2F;concavity.<p>When you perturb an anti-fragile (or convex) system, it doesn&#x27;t return to equilibrium but in fact improves. Conversely, when you perturb a fragile system, it degrades. The analysis is usually done with Jensen&#x27;s inequality rather than Lyapunov.<p>EDIT: not sure why the downvotes. I&#x27;m pointing out a fact. The examples do not demonstrate antifragility, but stability, which is not the same concept.</div><br/><div id="41232280" class="c"><input type="checkbox" id="c-41232280" checked=""/><div class="controls bullet"><span class="by">defrost</span><span>|</span><a href="#41231816">root</a><span>|</span><a href="#41232214">parent</a><span>|</span><a href="#41232098">next</a><span>|</span><label class="collapse" for="c-41232280">[-]</label><label class="expand" for="c-41232280">[4 more]</label></div><br/><div class="children"><div class="content">You appear to have replied the first draft of my comment as I was expanding it. Thank you for the response.</div><br/><div id="41232312" class="c"><input type="checkbox" id="c-41232312" checked=""/><div class="controls bullet"><span class="by">wenc</span><span>|</span><a href="#41231816">root</a><span>|</span><a href="#41232280">parent</a><span>|</span><a href="#41232098">next</a><span>|</span><label class="collapse" for="c-41232312">[-]</label><label class="expand" for="c-41232312">[3 more]</label></div><br/><div class="children"><div class="content">No, I replied to your full post. Just wanted to point out that your examples showed stability, not antifragility.</div><br/><div id="41232470" class="c"><input type="checkbox" id="c-41232470" checked=""/><div class="controls bullet"><span class="by">defrost</span><span>|</span><a href="#41231816">root</a><span>|</span><a href="#41232312">parent</a><span>|</span><a href="#41232098">next</a><span>|</span><label class="collapse" for="c-41232470">[-]</label><label class="expand" for="c-41232470">[2 more]</label></div><br/><div class="children"><div class="content">My initial motivation was to point out the authors likely weren&#x27;t native in English.<p>I meandered onwards to waffle about the nature of what they were describing, which to my mind at least <i>begins</i> with a notion of stability, in pursuit of a better succint opening line (which I don&#x27;t have).<p>You&#x27;ve said:<p><pre><code>    Fragility and antifragility aren&#x27;t about stability (returning to equilibria), but gains or losses after perturbation, which is related to convexity&#x2F;concavity.
</code></pre>
I&#x27;ve said:<p><pre><code>    Reading further, they want more; that repeated perturbations should deliver benefit, that systems in an warped egg carton configuration can be annealed to reveal an optimal point by vigorous shaking slowly reduced in degree.
</code></pre>
We likely both agree that an anti-fragile system should not spiral out of control. I assume when you refer to &quot;convexity&#x2F;concavity&quot; you mean at a scale greater than local, at the scale of the warp in an egg carton as I made reference.<p>My principal gripe with such discussion, as I said, was I don&#x27;t see much that is new other than language over what was discussed in the mid 1980s .. but perhaps I&#x27;ve not read enough.<p>The downvoting of your comment is poor form.</div><br/><div id="41232692" class="c"><input type="checkbox" id="c-41232692" checked=""/><div class="controls bullet"><span class="by">wenc</span><span>|</span><a href="#41231816">root</a><span>|</span><a href="#41232470">parent</a><span>|</span><a href="#41232098">next</a><span>|</span><label class="collapse" for="c-41232692">[-]</label><label class="expand" for="c-41232692">[1 more]</label></div><br/><div class="children"><div class="content">Thanks for engaging. You&#x27;re right in that the ideas are not new, but I feel the language and the framing somewhat is.<p>I&#x27;m not sure if you&#x27;ve come across N. N. Taleb&#x27;s work -- he&#x27;s the guy who coined the term &quot;antifragility&quot; = things things that benefit from perturbation. In it he argues that the antifragility is a property of systems that satisfy Jensen&#x27;s inequality [1]. If the system&#x27;s function f is convex, then:<p><pre><code>  E[f(X)] &gt; f(E[X])
</code></pre>
X is a random variable representing perturbations to the system, and f(.) is the system&#x27;s response. If Jensen&#x27;s inequality is satisfied (which is only true if f is convex), the inequality tells us that the average response to variable inputs (E[f(X)]) is greater than the response to the average input f(E[X]). This means that the system benefits more from variability in the input than it would from a constant, average input.<p>Antifragile systems, in that sense, are not conventionally &quot;stable&quot;. Taleb describes a spectrum: Fragile -&gt; Robust -&gt; Antifragile<p>Stable systems often fall into the robust category -- they can withstand stress without breaking, but they don&#x27;t necessarily improve from it.<p>It&#x27;s a really subtle nuance.<p>An example from life: the young person who takes no risks, has a stable job, does well enough but isn&#x27;t really interested in moving or taking on new opportunities. They&#x27;ll never make it big. This is stability.<p>But the young person who starts a startup and keeps taking risks, iterating and pivoting. If they win, they win big. If they lose, they only lose a few years of their early life. This is antifragility, and it is actually a departure from stability.<p>[1] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Jensen%27s_inequality" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Jensen%27s_inequality</a></div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="41232098" class="c"><input type="checkbox" id="c-41232098" checked=""/><div class="controls bullet"><span class="by">UniverseHacker</span><span>|</span><a href="#41231816">prev</a><span>|</span><a href="#41232415">next</a><span>|</span><label class="collapse" for="c-41232098">[-]</label><label class="expand" for="c-41232098">[2 more]</label></div><br/><div class="children"><div class="content">I love how Taleb managed to translate an ideal from stoic philosophy into a precisely defined mathematical concept</div><br/><div id="41232671" class="c"><input type="checkbox" id="c-41232671" checked=""/><div class="controls bullet"><span class="by">Animats</span><span>|</span><a href="#41232098">parent</a><span>|</span><a href="#41232415">next</a><span>|</span><label class="collapse" for="c-41232671">[-]</label><label class="expand" for="c-41232671">[1 more]</label></div><br/><div class="children"><div class="content">Some of this reads like rediscovering control theory, which is all about stability and robustness within defined limits.
It&#x27;s more popularization than innovation.<p>The person who first translated this idea into math was James Clerk Maxwell, in his paper, &quot;On Governors&quot;, in 1868.[1]
Maxwell was the first to get a mathematical handle on stability of feedback systems. He wrote: <i>&quot;If, by altering the
adjustments of the machine, its governing power is continually increased,
there is generally a lin1it at which the disturbance, instead of subsiding
more rapidly, becomes an oscillating and jerking motion, increasing in violence till it reaches the limit of action of the governor. This takes place when the possible part of one of the impossible roots becomes positive. ... I have pointed out that, under certain conditions, the sudden disturbances
of the machine do not act through the differential system on the governor,
or vice versa. When these conditions are fulfilled, the equations of motion are not only simple, but the motion itself is not liable to disturbances
depending on the mutual action of the machine and the governor.&quot;</i> That, right there, is the beginning of the mathematics of antifragility. Today, we call this turning up the P term of a PID controller too high and getting outside the stable region. Maxwell was the first to formalize the role of delay and damping (he calls it &quot;viscosity&quot;) in this.<p>There&#x27;s &quot;robust control&quot;, a useful theory of &quot;antifragility&quot; in industrial use for decades. Here&#x27;s an excellent video on how this is done.[2] That&#x27;s worth a watch. Note the emphasis on how the combination of delay and noise can cause instability in a system resistant to both delay and noise separately. This can be dealt with by moving the areas of instability around in the frequency domain.<p>(Modern control theory has become insanely complicated over the last few years. Until recent years, control theory was mostly linear control theory plus some self tuning.
Now, control theorists are trying to figure out how to get the benefits of machine learning while still having predictable error bounds. This means getting into the innards of what neural nets are really doing. I still get IEEE Trans. on Control Systems Technology,
but don&#x27;t understand it any more. So I&#x27;m not sure how that&#x27;s coming along.)<p>[1] <a href="https:&#x2F;&#x2F;archive.org&#x2F;details&#x2F;jstor-112510&#x2F;mode&#x2F;2up?view=theater" rel="nofollow">https:&#x2F;&#x2F;archive.org&#x2F;details&#x2F;jstor-112510&#x2F;mode&#x2F;2up?view=theat...</a><p>[2] <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=A7wHSr6GRnc" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=A7wHSr6GRnc</a></div><br/></div></div></div></div><div id="41232415" class="c"><input type="checkbox" id="c-41232415" checked=""/><div class="controls bullet"><span class="by">krick</span><span>|</span><a href="#41232098">prev</a><span>|</span><a href="#41231793">next</a><span>|</span><label class="collapse" for="c-41232415">[-]</label><label class="expand" for="c-41232415">[3 more]</label></div><br/><div class="children"><div class="content">There are now so many bullshit-terms derived from Taleb&#x27;s bullshit books. Like how people still keep mentioning &quot;black swans&quot; as if it actually means something other (or something more) than &quot;unexpected event&quot;. And for some unfathomable reason it keeps traction. Similarly how Mandelbrot &quot;redefined&quot; (i.e. distorted) the meaning of &quot;Lindy effect&quot;, and it stuck (however, I didn&#x27;t notice if it became popular to call a millenia-old banality by than name after Mandelbrot, or Taleb again). It probably should serve as an another example of that if you are arrogant enough, people will follow you just because of that.<p>However, I guess &quot;antifragility&quot; isn&#x27;t the worst of these.</div><br/><div id="41233092" class="c"><input type="checkbox" id="c-41233092" checked=""/><div class="controls bullet"><span class="by">nottorp</span><span>|</span><a href="#41232415">parent</a><span>|</span><a href="#41232713">next</a><span>|</span><label class="collapse" for="c-41233092">[-]</label><label class="expand" for="c-41233092">[1 more]</label></div><br/><div class="children"><div class="content">When I saw the title I thought it came out of one of those online bullshit generators...</div><br/></div></div></div></div><div id="41231793" class="c"><input type="checkbox" id="c-41231793" checked=""/><div class="controls bullet"><span class="by">adiM</span><span>|</span><a href="#41232415">prev</a><span>|</span><label class="collapse" for="c-41231793">[-]</label><label class="expand" for="c-41231793">[4 more]</label></div><br/><div class="children"><div class="content">Is this just risk seeking behavior (in contrast to risk sensitive)</div><br/><div id="41232089" class="c"><input type="checkbox" id="c-41232089" checked=""/><div class="controls bullet"><span class="by">marci</span><span>|</span><a href="#41231793">parent</a><span>|</span><label class="collapse" for="c-41232089">[-]</label><label class="expand" for="c-41232089">[3 more]</label></div><br/><div class="children"><div class="content">Now I wonder what a machine learning model with risk seeking behaviour would look like.</div><br/><div id="41233099" class="c"><input type="checkbox" id="c-41233099" checked=""/><div class="controls bullet"><span class="by">nottorp</span><span>|</span><a href="#41231793">root</a><span>|</span><a href="#41232089">parent</a><span>|</span><a href="#41232249">next</a><span>|</span><label class="collapse" for="c-41233099">[-]</label><label class="expand" for="c-41233099">[1 more]</label></div><br/><div class="children"><div class="content">From the little I know about ML in general, you always want to introduce randomness so you don&#x27;t get stuck in a local minimum&#x2F;maximum. So they&#x27;re all risk seeking?</div><br/></div></div><div id="41232249" class="c"><input type="checkbox" id="c-41232249" checked=""/><div class="controls bullet"><span class="by">mike_ivanov</span><span>|</span><a href="#41231793">root</a><span>|</span><a href="#41232089">parent</a><span>|</span><a href="#41233099">prev</a><span>|</span><label class="collapse" for="c-41232249">[-]</label><label class="expand" for="c-41232249">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=41231644">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=41231644</a></div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>