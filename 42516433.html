<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1735290050552" as="style"/><link rel="stylesheet" href="styles.css?v=1735290050552"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/lisyarus/webgpu-raytracer">Show HN: I&#x27;ve made a Monte-Carlo raytracer for glTF scenes in WebGPU</a>Â <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>lisyarus</span> | <span>37 comments</span></div><br/><div><div id="42516709" class="c"><input type="checkbox" id="c-42516709" checked=""/><div class="controls bullet"><span class="by">omolobo</span><span>|</span><a href="#42519050">next</a><span>|</span><label class="collapse" for="c-42516709">[-]</label><label class="expand" for="c-42516709">[4 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a mega-kernel, so you&#x27;ll get poor occupancy past the first bounce. A better strategy is to shoot, sort, and repeat, which then also allows you to squeeze in an adaptive sampler in the middle.<p>&gt; &#x2F;&#x2F; No idea where negative values come from :(<p>I don&#x27;t know, but:<p>&gt; newRay.origin += sign(dot(newRay.direction, geometryNormal)) * geometryNormal * 1e-4;<p>The new origin should be along the reflected ray, not along the direction of the normal. This line basically adds the normal (with a sign) to the origin (intersection point), which seems odd.<p>Poor&#x27;s man way to find where the negatives come from is to max(0,...) stuff until you find it.</div><br/><div id="42516727" class="c"><input type="checkbox" id="c-42516727" checked=""/><div class="controls bullet"><span class="by">lisyarus</span><span>|</span><a href="#42516709">parent</a><span>|</span><a href="#42517689">next</a><span>|</span><label class="collapse" for="c-42516727">[-]</label><label class="expand" for="c-42516727">[2 more]</label></div><br/><div class="children"><div class="content">&gt; It&#x27;s a mega-kernel, so you&#x27;ll get poor occupancy past the first bounce<p>Sure! If you look into the to-do list, there&#x27;s a &quot;wavefront path tracer&quot; entry :)<p>&gt; new origin should be along the reflected ray<p>I&#x27;ve found that doing it the way I&#x27;m doing it works better for preventing self-intersections. Might be worth investigating, though.</div><br/><div id="42516760" class="c"><input type="checkbox" id="c-42516760" checked=""/><div class="controls bullet"><span class="by">omolobo</span><span>|</span><a href="#42516709">root</a><span>|</span><a href="#42516727">parent</a><span>|</span><a href="#42517689">next</a><span>|</span><label class="collapse" for="c-42516760">[-]</label><label class="expand" for="c-42516760">[1 more]</label></div><br/><div class="children"><div class="content">It probably works better when the reflected ray is almost tangent to the surface. But that should be an epsilon case.</div><br/></div></div></div></div><div id="42517689" class="c"><input type="checkbox" id="c-42517689" checked=""/><div class="controls bullet"><span class="by">TomClabault</span><span>|</span><a href="#42516709">parent</a><span>|</span><a href="#42516727">prev</a><span>|</span><a href="#42519050">next</a><span>|</span><label class="collapse" for="c-42517689">[-]</label><label class="expand" for="c-42517689">[1 more]</label></div><br/><div class="children"><div class="content">&gt; A better strategy is to shoot, sort, and repeat<p>Do we have good sorting strategy whose costs are amortized yet? Meister 2020 (<a href="https:&#x2F;&#x2F;meistdan.github.io&#x2F;publications&#x2F;raysorting&#x2F;paper.pdf" rel="nofollow">https:&#x2F;&#x2F;meistdan.github.io&#x2F;publications&#x2F;raysorting&#x2F;paper.pdf</a>) shows that the hard part is actually to hide the cost of the sorting.<p>&gt;  squeeze in an adaptive sampler in the middle.
Can you expand on that? How does that work? I only know of adaptive sampling in screen space where you shoot more or less rays to certain pixels based on their estimated variance so far.</div><br/></div></div></div></div><div id="42519050" class="c"><input type="checkbox" id="c-42519050" checked=""/><div class="controls bullet"><span class="by">bezdomniy</span><span>|</span><a href="#42516709">prev</a><span>|</span><a href="#42517403">next</a><span>|</span><label class="collapse" for="c-42519050">[-]</label><label class="expand" for="c-42519050">[1 more]</label></div><br/><div class="children"><div class="content">Very cool. I did a similar project with wgpu in Rust - <a href="https:&#x2F;&#x2F;github.com&#x2F;bezdomniy&#x2F;Rengin">https:&#x2F;&#x2F;github.com&#x2F;bezdomniy&#x2F;Rengin</a>
nice to find your projects to see where I can improve!</div><br/></div></div><div id="42517403" class="c"><input type="checkbox" id="c-42517403" checked=""/><div class="controls bullet"><span class="by">artemonster</span><span>|</span><a href="#42519050">prev</a><span>|</span><a href="#42516678">next</a><span>|</span><label class="collapse" for="c-42517403">[-]</label><label class="expand" for="c-42517403">[3 more]</label></div><br/><div class="children"><div class="content">&gt; &quot;GPU &quot;software&quot; raytracer&quot;<p>&gt; WebGPU<p>&gt; this project is desktop-only<p>Boss, I am confused, boss.</div><br/><div id="42517570" class="c"><input type="checkbox" id="c-42517570" checked=""/><div class="controls bullet"><span class="by">lisyarus</span><span>|</span><a href="#42517403">parent</a><span>|</span><a href="#42516678">next</a><span>|</span><label class="collapse" for="c-42517570">[-]</label><label class="expand" for="c-42517570">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m using WebGPU as a nice modern graphics API that is at the same time much more user-friendly and easier to use compared to e.g. Vulkan. I&#x27;m using a desktop implementation of WebGPU called wgpu, via it&#x27;s C bindings called wgpu-native.<p>My browser doesn&#x27;t support WebGPU properly yet, so I don&#x27;t really care about running this thing in browser.</div><br/><div id="42518923" class="c"><input type="checkbox" id="c-42518923" checked=""/><div class="controls bullet"><span class="by">firtoz</span><span>|</span><a href="#42517403">root</a><span>|</span><a href="#42517570">parent</a><span>|</span><a href="#42516678">next</a><span>|</span><label class="collapse" for="c-42518923">[-]</label><label class="expand" for="c-42518923">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s a fascinating approach.<p>And it gets me a bit sad about the state of WebGPU, however hopefully that&#x27;ll be resolved soon... I also on Linux am impatiently waiting for WebGPU to be supported on my browser.</div><br/></div></div></div></div></div></div><div id="42516678" class="c"><input type="checkbox" id="c-42516678" checked=""/><div class="controls bullet"><span class="by">modeless</span><span>|</span><a href="#42517403">prev</a><span>|</span><a href="#42516434">next</a><span>|</span><label class="collapse" for="c-42516678">[-]</label><label class="expand" for="c-42516678">[4 more]</label></div><br/><div class="children"><div class="content">Do you have a link that runs in the browser?</div><br/><div id="42516715" class="c"><input type="checkbox" id="c-42516715" checked=""/><div class="controls bullet"><span class="by">lisyarus</span><span>|</span><a href="#42516678">parent</a><span>|</span><a href="#42516434">next</a><span>|</span><label class="collapse" for="c-42516715">[-]</label><label class="expand" for="c-42516715">[3 more]</label></div><br/><div class="children"><div class="content">Nope, this project is desktop-only</div><br/><div id="42517099" class="c"><input type="checkbox" id="c-42517099" checked=""/><div class="controls bullet"><span class="by">modeless</span><span>|</span><a href="#42516678">root</a><span>|</span><a href="#42516715">parent</a><span>|</span><a href="#42516949">next</a><span>|</span><label class="collapse" for="c-42517099">[-]</label><label class="expand" for="c-42517099">[1 more]</label></div><br/><div class="children"><div class="content">You should try building it with Emscripten. SDL2 is supported.</div><br/></div></div></div></div></div></div><div id="42516691" class="c"><input type="checkbox" id="c-42516691" checked=""/><div class="controls bullet"><span class="by">crazygringo</span><span>|</span><a href="#42516434">prev</a><span>|</span><a href="#42516985">next</a><span>|</span><label class="collapse" for="c-42516691">[-]</label><label class="expand" for="c-42516691">[19 more]</label></div><br/><div class="children"><div class="content">This is a completely side question, but just because it always astonishes me how &quot;real&quot; raytraced scenes can look in terms of lighting, but it&#x27;s too complex&#x2F;slow for video games.<p>How far have we gotten in terms of training AI models on raytraced lighting, to simulate it but fast enough for video games? Training an AI not on rendered scenes from any particular viewpoint, but rather on how light and shadows would be &quot;baked into&quot; textures?<p>Because what raytracing excels at is the overall realism of diffuse light. And it seems like the kind of thing AI would be good at learning?<p>I&#x27;ve always though, e.g. when looking at the shadows trees cast, I couldn&#x27;t care less if the each leaf shape in the shadow is accurate or entirely hallucinated. The important things seem to be a combination of the overall light diffusion, combined with correct nearby shadow shapes for objects. Which is seems AI would excel at?</div><br/><div id="42517816" class="c"><input type="checkbox" id="c-42517816" checked=""/><div class="controls bullet"><span class="by">jms55</span><span>|</span><a href="#42516691">parent</a><span>|</span><a href="#42517104">next</a><span>|</span><label class="collapse" for="c-42517816">[-]</label><label class="expand" for="c-42517816">[1 more]</label></div><br/><div class="children"><div class="content">This was a recent presentation from SIGGRAPH 2024 that covered using neural nets to store baked (not dynamic!) lighting <a href="https:&#x2F;&#x2F;advances.realtimerendering.com&#x2F;s2024&#x2F;#neural_light_grid" rel="nofollow">https:&#x2F;&#x2F;advances.realtimerendering.com&#x2F;s2024&#x2F;#neural_light_g...</a>.<p>Even with the fact that it&#x27;s static lighting, you can already see a ton of the challenges that they faced. In the end they did get a fairly usable solution that improved on their existing baking tools, but it took what seems like months of experimenting without clear linear progress. They could have just as easily stalled out and been stuck with models that didn&#x27;t work.<p>And that was just for static lighting, not every realtime dynamic lighting. ML is going to need a lot of advancements before it can predict lighting whole-sale, faster and easier than tracing rays.<p>On the other hand ML is really really good at replacing all the mediocre handwritten heuristics 3d rendering has. For lighting, denoising low-signal (0.5-1 rays per pixel) lighting is a big area of research[0] since handwritten heuristics tend to struggle with such little amount of data available, along with lighting caches[1] which have to adapt to a wide variety of situations that again make handwritten heuristics struggle.<p>[0]: <a href="https:&#x2F;&#x2F;gpuopen.com&#x2F;learn&#x2F;neural_supersampling_and_denoising_for_real-time_path_tracing" rel="nofollow">https:&#x2F;&#x2F;gpuopen.com&#x2F;learn&#x2F;neural_supersampling_and_denoising...</a>, and the references it lists<p>[1]:<a href="https:&#x2F;&#x2F;research.nvidia.com&#x2F;publication&#x2F;2021-06_real-time-neural-radiance-caching-path-tracing" rel="nofollow">https:&#x2F;&#x2F;research.nvidia.com&#x2F;publication&#x2F;2021-06_real-time-ne...</a></div><br/></div></div><div id="42517104" class="c"><input type="checkbox" id="c-42517104" checked=""/><div class="controls bullet"><span class="by">nuclearsugar</span><span>|</span><a href="#42516691">parent</a><span>|</span><a href="#42517816">prev</a><span>|</span><a href="#42516736">next</a><span>|</span><label class="collapse" for="c-42517104">[-]</label><label class="expand" for="c-42517104">[1 more]</label></div><br/><div class="children"><div class="content">I think there will certainly be an AI 3D render engine at some point. But currently AI is used in 3D render engines to assist with denoising.
<a href="https:&#x2F;&#x2F;docs.blender.org&#x2F;manual&#x2F;en&#x2F;2.92&#x2F;render&#x2F;layers&#x2F;denoising.html" rel="nofollow">https:&#x2F;&#x2F;docs.blender.org&#x2F;manual&#x2F;en&#x2F;2.92&#x2F;render&#x2F;layers&#x2F;denois...</a></div><br/></div></div><div id="42516736" class="c"><input type="checkbox" id="c-42516736" checked=""/><div class="controls bullet"><span class="by">Etheryte</span><span>|</span><a href="#42516691">parent</a><span>|</span><a href="#42517104">prev</a><span>|</span><a href="#42516744">next</a><span>|</span><label class="collapse" for="c-42516736">[-]</label><label class="expand" for="c-42516736">[10 more]</label></div><br/><div class="children"><div class="content">At any reasonable quality, AI is even more expensive than raytracing. A simple intuition for this is the fact that you can easily run a raytracer on consumer hardware, even if at low FPS, meanwhile you need a beefy setup to run most AI models and they still take a while.</div><br/><div id="42516809" class="c"><input type="checkbox" id="c-42516809" checked=""/><div class="controls bullet"><span class="by">toshinoriyagi</span><span>|</span><a href="#42516691">root</a><span>|</span><a href="#42516736">parent</a><span>|</span><a href="#42516839">next</a><span>|</span><label class="collapse" for="c-42516809">[-]</label><label class="expand" for="c-42516809">[4 more]</label></div><br/><div class="children"><div class="content">While some very large models may need beefy hardware, there are multiple forms of deep learning used for similar purposes:<p>Nvidia&#x27;s DLSS is a neural network that upscales images so that games may be rendered quickly at lower resolutions, and than upscaled to the display resolution in less total time than rendering natively at the display resolution.<p>Nvidia&#x27;s DLDSR downscales a greater-than-native resolution image faster than typical downscaling algorithms used in DSR.<p>Nvidia&#x27;s RTX HDR is a post-processing filter that takes an sRGB image and converts it to HDR.<p>So, it is very likely that a model that converts rasterized images to raytraced versions is possible, and fast. The most likely road block is the lack of a quality dataset for training such a model. Not all games have ray tracing, and even fewer have quality implementations.</div><br/><div id="42517463" class="c"><input type="checkbox" id="c-42517463" checked=""/><div class="controls bullet"><span class="by">jsheard</span><span>|</span><a href="#42516691">root</a><span>|</span><a href="#42516809">parent</a><span>|</span><a href="#42517460">next</a><span>|</span><label class="collapse" for="c-42517463">[-]</label><label class="expand" for="c-42517463">[2 more]</label></div><br/><div class="children"><div class="content">To be clear DLSS is a very different beast than your typical AI upscaler, it uses the principle of temporal reuse where <i>real</i> samples from previous frames are combined with samples from the current frame in order to converge towards a higher resolution over time. It&#x27;s not guessing new samples out of thin air, just guessing whether old samples are still usable, which is why DLSS is so fast and accurate compared to general purpose AI upscalers and why you can&#x27;t use DLSS on images or videos.</div><br/><div id="42517717" class="c"><input type="checkbox" id="c-42517717" checked=""/><div class="controls bullet"><span class="by">jms55</span><span>|</span><a href="#42516691">root</a><span>|</span><a href="#42517463">parent</a><span>|</span><a href="#42517460">next</a><span>|</span><label class="collapse" for="c-42517717">[-]</label><label class="expand" for="c-42517717">[1 more]</label></div><br/><div class="children"><div class="content">To add to this, DLSS 2 functions exactly the same as a non-ML temporal upscaler does: it blends pixels from the previous frame with pixels from the current frame.<p>The ML part of DLSS is that the blend weights are determined by a neural net, rather than handwritten heuristics.<p>DLSS 1 _did_ try and and use neural networks to predict the new (upscaled) pixels outright, which went really poorly for a variety of reasons I don&#x27;t feel like getting into, hence why they abandoned that approach.</div><br/></div></div></div></div><div id="42517460" class="c"><input type="checkbox" id="c-42517460" checked=""/><div class="controls bullet"><span class="by">mywittyname</span><span>|</span><a href="#42516691">root</a><span>|</span><a href="#42516809">parent</a><span>|</span><a href="#42517463">prev</a><span>|</span><a href="#42516839">next</a><span>|</span><label class="collapse" for="c-42517460">[-]</label><label class="expand" for="c-42517460">[1 more]</label></div><br/><div class="children"><div class="content">&gt; So, it is very likely that a model that converts rasterized images to raytraced versions is possible, and fast.<p>How would this even work and not just be a DLSS derivative?<p>The magic of ray tracing is the ability to render light sources and reflections that are not in the scene.  So where is the information coming from that the algorithm would use to place and draw the lights, shadows, reflections, etc?<p>I&#x27;m not asking to be snarky.  I can usually &quot;get there from here&quot; when it comes to theoretical technology, but I can&#x27;t work out how a raster image would contain enough data to allow for accurate ray tracing to be applied for objects whose effects are only included due to ray tracing.</div><br/></div></div></div></div><div id="42516839" class="c"><input type="checkbox" id="c-42516839" checked=""/><div class="controls bullet"><span class="by">8n4vidtmkvmk</span><span>|</span><a href="#42516691">root</a><span>|</span><a href="#42516736">parent</a><span>|</span><a href="#42516809">prev</a><span>|</span><a href="#42516815">next</a><span>|</span><label class="collapse" for="c-42516839">[-]</label><label class="expand" for="c-42516839">[4 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not convinced. We have &quot;hyper&quot; and &quot;lightning&quot; diffusion models that run 1-4 steps and are pretty quick on consumer hardware. I really have no idea which would be quicker with some optimizations and hardware tailored for the use-case.</div><br/><div id="42516876" class="c"><input type="checkbox" id="c-42516876" checked=""/><div class="controls bullet"><span class="by">jsheard</span><span>|</span><a href="#42516691">root</a><span>|</span><a href="#42516839">parent</a><span>|</span><a href="#42516815">next</a><span>|</span><label class="collapse" for="c-42516876">[-]</label><label class="expand" for="c-42516876">[3 more]</label></div><br/><div class="children"><div class="content">The hard part is keeping everything coherent over time in a dynamic scene with a dynamic camera. Hallucinating vaguely plausible lighting may be adequate for a still image, but not so much in a game if you hallucinate shadows or reflections of off-screen objects that aren&#x27;t really there, or &quot;forget&quot; that off-screen objects exist, or invent light sources that make no sense in context.<p>The main benefit of raytracing in games is that it has accurate global knowledge of the scene beyond what&#x27;s directly in front of the camera, as opposed to earlier approximations which tried to work with only what the camera sees. Img2img diffusion is the ultimate form of the latter approach in that it tries to infer <i>everything</i> from what the camera sees, and guesses the rest.</div><br/><div id="42518052" class="c"><input type="checkbox" id="c-42518052" checked=""/><div class="controls bullet"><span class="by">8n4vidtmkvmk</span><span>|</span><a href="#42516691">root</a><span>|</span><a href="#42516876">parent</a><span>|</span><a href="#42516815">next</a><span>|</span><label class="collapse" for="c-42518052">[-]</label><label class="expand" for="c-42518052">[2 more]</label></div><br/><div class="children"><div class="content">Right, but I&#x27;m not actually suggesting we use diffusion. At least, not the same models we&#x27;re using now. We need to incorporate a few sample rays at least so that it &#x27;knows&#x27; what&#x27;s <i>actually</i> off-screen, and then we just give it lots of training data of partially rendered images and fully rendered images so that it learns how to fill in the gaps. It shouldn&#x27;t hallucinate very much if we do that. I don&#x27;t know how to solve for temporal coherence though -- I guess we might want to train on videos instead of still images.<p>Also, that new Google paper where it generates entire games from a single image has up to 60 seconds of &#x27;memory&#x27; I think they said, so I don&#x27;t think the &quot;forgetting&quot; is actually that big of a problem since we can refresh the memory with a properly rendered image at least every that often.<p>I&#x27;m just spitballing here though, I think all of Unreal 5.4 or 5.5 has put this into practice already with their new lighting system.</div><br/><div id="42518107" class="c"><input type="checkbox" id="c-42518107" checked=""/><div class="controls bullet"><span class="by">jsheard</span><span>|</span><a href="#42516691">root</a><span>|</span><a href="#42518052">parent</a><span>|</span><a href="#42516815">next</a><span>|</span><label class="collapse" for="c-42518107">[-]</label><label class="expand" for="c-42518107">[1 more]</label></div><br/><div class="children"><div class="content">&gt; We need to incorporate a few sample rays at least so that it &#x27;knows&#x27; what&#x27;s actually off-screen, and then we just give it lots of training data of partially rendered images and fully rendered images so that it learns how to fill in the gaps.<p>That&#x27;s already a thing, there&#x27;s ML-driven denoisers which take a rough raytraced image and do their best to infer what the fully converged image would look like based on their training data. For example in the offline rendering world there&#x27;s Nvidia&#x27;s OptiX denoiser and Intel&#x27;s OIDN, and in the realtime world there&#x27;s Nvidia&#x27;s DLSS Ray Reconstruction which uses an ML model to do both upscaling and denoising at the same time.<p><a href="https:&#x2F;&#x2F;developer.nvidia.com&#x2F;optix-denoiser" rel="nofollow">https:&#x2F;&#x2F;developer.nvidia.com&#x2F;optix-denoiser</a><p><a href="https:&#x2F;&#x2F;www.openimagedenoise.org" rel="nofollow">https:&#x2F;&#x2F;www.openimagedenoise.org</a></div><br/></div></div></div></div></div></div></div></div><div id="42516815" class="c"><input type="checkbox" id="c-42516815" checked=""/><div class="controls bullet"><span class="by">TuringTest</span><span>|</span><a href="#42516691">root</a><span>|</span><a href="#42516736">parent</a><span>|</span><a href="#42516839">prev</a><span>|</span><a href="#42516744">next</a><span>|</span><label class="collapse" for="c-42516815">[-]</label><label class="expand" for="c-42516815">[1 more]</label></div><br/><div class="children"><div class="content">Yeah but that has something to do with<p>1) commercial hardware pipelinea being improved for decades in handling 3D polygons, and<p>2) graphical AI models are trained on understanding natural language in addition to rendering.<p>I can imagine a new breed of specialized generative graphical AI that entirely skips language and is trained on stock 3D objects as input, which could potentially perform much better.</div><br/></div></div></div></div><div id="42516744" class="c"><input type="checkbox" id="c-42516744" checked=""/><div class="controls bullet"><span class="by">omolobo</span><span>|</span><a href="#42516691">parent</a><span>|</span><a href="#42516736">prev</a><span>|</span><a href="#42516741">next</a><span>|</span><label class="collapse" for="c-42516744">[-]</label><label class="expand" for="c-42516744">[1 more]</label></div><br/><div class="children"><div class="content">See: <a href="https:&#x2F;&#x2F;research.nvidia.com&#x2F;labs&#x2F;rtr&#x2F;tag&#x2F;neural-rendering&#x2F;" rel="nofollow">https:&#x2F;&#x2F;research.nvidia.com&#x2F;labs&#x2F;rtr&#x2F;tag&#x2F;neural-rendering&#x2F;</a><p>Specifically this one, which seems to tackle what you mentioned: <a href="https:&#x2F;&#x2F;research.nvidia.com&#x2F;labs&#x2F;rtr&#x2F;publication&#x2F;hadadan2023radiometric&#x2F;" rel="nofollow">https:&#x2F;&#x2F;research.nvidia.com&#x2F;labs&#x2F;rtr&#x2F;publication&#x2F;hadadan2023...</a></div><br/></div></div><div id="42516741" class="c"><input type="checkbox" id="c-42516741" checked=""/><div class="controls bullet"><span class="by">jampekka</span><span>|</span><a href="#42516691">parent</a><span>|</span><a href="#42516744">prev</a><span>|</span><a href="#42518582">next</a><span>|</span><label class="collapse" for="c-42516741">[-]</label><label class="expand" for="c-42516741">[1 more]</label></div><br/><div class="children"><div class="content">The current approach seems to be ray tracing limited&#x2F;feasible number of samples and upsampling&#x2F;denoising the result using neural networks.</div><br/></div></div><div id="42518582" class="c"><input type="checkbox" id="c-42518582" checked=""/><div class="controls bullet"><span class="by">holoduke</span><span>|</span><a href="#42516691">parent</a><span>|</span><a href="#42516741">prev</a><span>|</span><a href="#42516753">next</a><span>|</span><label class="collapse" for="c-42518582">[-]</label><label class="expand" for="c-42518582">[1 more]</label></div><br/><div class="children"><div class="content">Its still hard to do realtime.  You need so much gpu memory that a second GPU must be used at least today. The question is what gets achieved quicker. Hard calculated simulation or AI post processing. Or maybe a combination?</div><br/></div></div><div id="42516753" class="c"><input type="checkbox" id="c-42516753" checked=""/><div class="controls bullet"><span class="by">lispisok</span><span>|</span><a href="#42516691">parent</a><span>|</span><a href="#42518582">prev</a><span>|</span><a href="#42516739">next</a><span>|</span><label class="collapse" for="c-42516753">[-]</label><label class="expand" for="c-42516753">[2 more]</label></div><br/><div class="children"><div class="content">This is an interesting idea but please no more AI graphics generation in video games please. Games dont get optimized anymore because devs rely on AI upscaling and frame generation to get playable framerates and it makes the games look bad and play bad.</div><br/><div id="42518608" class="c"><input type="checkbox" id="c-42518608" checked=""/><div class="controls bullet"><span class="by">holoduke</span><span>|</span><a href="#42516691">root</a><span>|</span><a href="#42516753">parent</a><span>|</span><a href="#42516739">next</a><span>|</span><label class="collapse" for="c-42518608">[-]</label><label class="expand" for="c-42518608">[1 more]</label></div><br/><div class="children"><div class="content">No its because hardware is not fast enough. Performance optimization is a large part of engine development. It happens at Epic as well.</div><br/></div></div></div></div></div></div><div id="42517389" class="c"><input type="checkbox" id="c-42517389" checked=""/><div class="controls bullet"><span class="by">pjmlp</span><span>|</span><a href="#42516985">prev</a><span>|</span><label class="collapse" for="c-42517389">[-]</label><label class="expand" for="c-42517389">[3 more]</label></div><br/><div class="children"><div class="content">WebGPU projects that don&#x27;t provide browser examples are kind of strange, then better use Vulkan or whatever.</div><br/><div id="42520545" class="c"><input type="checkbox" id="c-42520545" checked=""/><div class="controls bullet"><span class="by">sspiff</span><span>|</span><a href="#42517389">parent</a><span>|</span><a href="#42517576">next</a><span>|</span><label class="collapse" for="c-42520545">[-]</label><label class="expand" for="c-42520545">[1 more]</label></div><br/><div class="children"><div class="content">WegGPU is a way nicer HAL if you&#x27;re not an experienced graphics engineer. So even if you only target desktops, it&#x27;s a valid choice.<p>On the web, WebGPU is only supported by Chrome-based browser engines at this point, and a lot of software developers us Firefox (and don&#x27;t really like encouraging a browser monoculture), so it doesn&#x27;t make a ton of sense to target browser based WebGPU for some people at this point.</div><br/></div></div><div id="42517576" class="c"><input type="checkbox" id="c-42517576" checked=""/><div class="controls bullet"><span class="by">lisyarus</span><span>|</span><a href="#42517389">parent</a><span>|</span><a href="#42520545">prev</a><span>|</span><label class="collapse" for="c-42517576">[-]</label><label class="expand" for="c-42517576">[1 more]</label></div><br/><div class="children"><div class="content">See my answer to artemonster above.</div><br/></div></div></div></div></div></div></div></div></div></body></html>