<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1731920460311" as="style"/><link rel="stylesheet" href="styles.css?v=1731920460311"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://eli.thegreenplace.net/2024/ml-in-go-with-a-python-sidecar/">ML in Go with a Python Sidecar</a> <span class="domain">(<a href="https://eli.thegreenplace.net">eli.thegreenplace.net</a>)</span></div><div class="subtext"><span>zdw</span> | <span>13 comments</span></div><br/><div><div id="42168035" class="c"><input type="checkbox" id="c-42168035" checked=""/><div class="controls bullet"><span class="by">mountainriver</span><span>|</span><a href="#42169470">next</a><span>|</span><label class="collapse" for="c-42168035">[-]</label><label class="expand" for="c-42168035">[2 more]</label></div><br/><div class="children"><div class="content">I wrote <a href="https:&#x2F;&#x2F;github.com&#x2F;aunum&#x2F;gold">https:&#x2F;&#x2F;github.com&#x2F;aunum&#x2F;gold</a> as an attempt to try ML with Go.<p>I came to the opinion that it’s just not worth it. This isn’t what Go was designed for and it will likely never be a good language to interface with ML.<p>The Go to C FFI is too slow for native Cuda ops and Go doesn’t have a good bridge to Python.<p>Rust is a much much better option in these scenarios</div><br/><div id="42170124" class="c"><input type="checkbox" id="c-42170124" checked=""/><div class="controls bullet"><span class="by">pjmlp</span><span>|</span><a href="#42168035">parent</a><span>|</span><a href="#42169470">next</a><span>|</span><label class="collapse" for="c-42170124">[-]</label><label class="expand" for="c-42170124">[1 more]</label></div><br/><div class="children"><div class="content">Additionally Google seems to be fine with only providing a wrapper around Gemini endpoints and such.<p>Not like other ecosystems which are developing the infrastructure to develop ML stuff on the respective language, including targeting the GPU if one so wishes.<p>Go is the main language for the CNCF project landscape ecosystem and that is about it. And even then, newer projects are more likely to pick Rust.</div><br/></div></div></div></div><div id="42169470" class="c"><input type="checkbox" id="c-42169470" checked=""/><div class="controls bullet"><span class="by">neomantra</span><span>|</span><a href="#42168035">prev</a><span>|</span><a href="#42166754">next</a><span>|</span><label class="collapse" for="c-42169470">[-]</label><label class="expand" for="c-42169470">[1 more]</label></div><br/><div class="children"><div class="content">Last week I started this OllamaTea [1] BubbleTea component library which tries to leverage this idea of an Ollama sidecar.<p>I&#x27;ve really appreciated Ollama as a simple local inferencing service.   I&#x27;ll now sometimes ask Ollama something using its CLI, rather than going to a URL bar.  Once Llama 3.2 Vision became available on Ollama this month [2], I got excited to try them with visual UI elements.  I&#x27;ve also wanted to explore some kid-friendly TUIs, which need to be cheap and private.<p>OllamaTea is not intended to be a full-feature Chat program, but rather as scaffolding for adding Ollama to custom TUI apps.<p>Once I had the base OllamaTea library, I was able write the POC that inspired the whole thing.;  I made a TUI that plots a terminal chart of some market data, converts that to an image, then prompts Ollama about it.   Easy to achieve once all the pieces were in place. [3]<p>The direct Ollama Golang API [4] is very easy to use.  OllamaTea just makes it easier to make TUIs.  While most of the research action is in Python, I think there&#x27;s room for ML applications&#x2F;services&#x2F;orchestrators written in Golang and working with the Ollama API surface [5].<p>[1] <a href="https:&#x2F;&#x2F;github.com&#x2F;nimblemarkets&#x2F;ollamatea">https:&#x2F;&#x2F;github.com&#x2F;nimblemarkets&#x2F;ollamatea</a><p>[2] <a href="https:&#x2F;&#x2F;ollama.com&#x2F;blog&#x2F;llama3.2-vision">https:&#x2F;&#x2F;ollama.com&#x2F;blog&#x2F;llama3.2-vision</a><p>[3] <a href="https:&#x2F;&#x2F;github.com&#x2F;NimbleMarkets&#x2F;ollamatea&#x2F;blob&#x2F;main&#x2F;cmd&#x2F;ot-timechart&#x2F;README.md#databento-data-example">https:&#x2F;&#x2F;github.com&#x2F;NimbleMarkets&#x2F;ollamatea&#x2F;blob&#x2F;main&#x2F;cmd&#x2F;ot-...</a><p>[4] <a href="https:&#x2F;&#x2F;pkg.go.dev&#x2F;github.com&#x2F;ollama&#x2F;ollama&#x2F;api" rel="nofollow">https:&#x2F;&#x2F;pkg.go.dev&#x2F;github.com&#x2F;ollama&#x2F;ollama&#x2F;api</a><p>[5] <a href="https:&#x2F;&#x2F;github.com&#x2F;ollama&#x2F;ollama&#x2F;blob&#x2F;main&#x2F;docs&#x2F;api.md">https:&#x2F;&#x2F;github.com&#x2F;ollama&#x2F;ollama&#x2F;blob&#x2F;main&#x2F;docs&#x2F;api.md</a></div><br/></div></div><div id="42166754" class="c"><input type="checkbox" id="c-42166754" checked=""/><div class="controls bullet"><span class="by">daniel-thompson</span><span>|</span><a href="#42169470">prev</a><span>|</span><a href="#42166391">next</a><span>|</span><label class="collapse" for="c-42166754">[-]</label><label class="expand" for="c-42166754">[7 more]</label></div><br/><div class="children"><div class="content">&gt; Completely bespoke models are typically trained in Python using tools like TensorFlow, JAX or PyTorch that don&#x27;t have real non-Python alternatives<p>The article outlines some interesting ways to evade this problem. What&#x27;s the latest thinking on robustly addressing it, e.g. are there any approaches for executing inference on a tf or pytorch model from within a golang process, no sidecar required?</div><br/><div id="42166865" class="c"><input type="checkbox" id="c-42166865" checked=""/><div class="controls bullet"><span class="by">kevmo314</span><span>|</span><a href="#42166754">parent</a><span>|</span><a href="#42167877">next</a><span>|</span><label class="collapse" for="c-42166865">[-]</label><label class="expand" for="c-42166865">[1 more]</label></div><br/><div class="children"><div class="content">For Go specifically, there are some libraries like Gorgonia (<a href="https:&#x2F;&#x2F;github.com&#x2F;gorgonia&#x2F;gorgonia">https:&#x2F;&#x2F;github.com&#x2F;gorgonia&#x2F;gorgonia</a>) that can do inference.<p>Practically speaking though, the rate at which models change is so fast that if you opt to go this route, you&#x27;ll perpetually be lagging behind the state of the art by just a bit. Either you&#x27;ll be the one implementing the latest improvements or be waiting for the framework to catch up. This is the real value of the sidecar approach: when a new technique comes out (like speculative decoding, for example) you don&#x27;t need to reimplement it in Go but instead can use the implementation that most other python users will use.</div><br/></div></div><div id="42167877" class="c"><input type="checkbox" id="c-42167877" checked=""/><div class="controls bullet"><span class="by">neomantra</span><span>|</span><a href="#42166754">parent</a><span>|</span><a href="#42166865">prev</a><span>|</span><a href="#42170132">next</a><span>|</span><label class="collapse" for="c-42167877">[-]</label><label class="expand" for="c-42167877">[2 more]</label></div><br/><div class="children"><div class="content">Perhaps check out GoMLX (&quot;an Accelerated ML and Math Framework&quot;, there&#x27;s a lot of scaffolding and it JITs to various backends.  Related to that project, I sometimes use GoNB in VSCode, which is Golang notebooks [2].<p>[1] <a href="https:&#x2F;&#x2F;github.com&#x2F;gomlx&#x2F;gomlx">https:&#x2F;&#x2F;github.com&#x2F;gomlx&#x2F;gomlx</a><p>[2] <a href="https:&#x2F;&#x2F;github.com&#x2F;janpfeifer&#x2F;gonb">https:&#x2F;&#x2F;github.com&#x2F;janpfeifer&#x2F;gonb</a></div><br/><div id="42168320" class="c"><input type="checkbox" id="c-42168320" checked=""/><div class="controls bullet"><span class="by">eliben</span><span>|</span><a href="#42166754">root</a><span>|</span><a href="#42167877">parent</a><span>|</span><a href="#42170132">next</a><span>|</span><label class="collapse" for="c-42168320">[-]</label><label class="expand" for="c-42168320">[1 more]</label></div><br/><div class="children"><div class="content">Indeed, I have a plan to publish a follow-up using GoMLX - I already have the code working and just need to clean it all up and write a post</div><br/></div></div></div></div><div id="42170132" class="c"><input type="checkbox" id="c-42170132" checked=""/><div class="controls bullet"><span class="by">pjmlp</span><span>|</span><a href="#42166754">parent</a><span>|</span><a href="#42167877">prev</a><span>|</span><a href="#42167069">next</a><span>|</span><label class="collapse" for="c-42170132">[-]</label><label class="expand" for="c-42170132">[1 more]</label></div><br/><div class="children"><div class="content">Pytorch and Tensorflow have first class support for C++ (naturally), and Java.</div><br/></div></div><div id="42167069" class="c"><input type="checkbox" id="c-42167069" checked=""/><div class="controls bullet"><span class="by">richardjennings</span><span>|</span><a href="#42166754">parent</a><span>|</span><a href="#42170132">prev</a><span>|</span><a href="#42167338">next</a><span>|</span><label class="collapse" for="c-42167069">[-]</label><label class="expand" for="c-42167069">[1 more]</label></div><br/><div class="children"><div class="content">It is possible to include CPython in a CGO program - allowing Python to be executed from within the CGO process directly. This comes with some complexities - GIL and thread safety in Go routines, complexity of cross-compiling between architectures, overhead in copying values across the FFI, limitations of integrating as a Go module. I am hoping to see a CGO GIL&#x27;less Python integration show up here at some point that has all the answers.</div><br/></div></div><div id="42167338" class="c"><input type="checkbox" id="c-42167338" checked=""/><div class="controls bullet"><span class="by">uriah</span><span>|</span><a href="#42166754">parent</a><span>|</span><a href="#42167069">prev</a><span>|</span><a href="#42166391">next</a><span>|</span><label class="collapse" for="c-42167338">[-]</label><label class="expand" for="c-42167338">[1 more]</label></div><br/><div class="children"><div class="content">These frameworks are C++ under the hood. A far as I know (not too experienced with go) you can use cgo to call any C++ code. So you should be able to serialize the model (torchscript) then run it with libtorch. Tensorflow also similarly has a C++ api</div><br/></div></div></div></div><div id="42166391" class="c"><input type="checkbox" id="c-42166391" checked=""/><div class="controls bullet"><span class="by">calderwoodra</span><span>|</span><a href="#42166754">prev</a><span>|</span><label class="collapse" for="c-42166391">[-]</label><label class="expand" for="c-42166391">[2 more]</label></div><br/><div class="children"><div class="content">I was surprised you chose http for your IPC - I was expecting there to be a more handy tool that Python could expose and Go could leverage without needing to keep a second process constantly running.</div><br/><div id="42166529" class="c"><input type="checkbox" id="c-42166529" checked=""/><div class="controls bullet"><span class="by">herval</span><span>|</span><a href="#42166391">parent</a><span>|</span><label class="collapse" for="c-42166529">[-]</label><label class="expand" for="c-42166529">[1 more]</label></div><br/><div class="children"><div class="content">Keeping models in memory is more efficient than constantly loading&#x2F;unloading them, so a process that keeps running is the way to go</div><br/></div></div></div></div></div></div></div></div></div></body></html>