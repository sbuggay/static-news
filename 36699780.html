<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1689238853539" as="style"/><link rel="stylesheet" href="styles.css?v=1689238853539"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/a16z-infra/companion-app">Show HN: AI companions stack – create and host your own AI companions</a> <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>ykhli</span> | <span>39 comments</span></div><br/><div><div id="36702052" class="c"><input type="checkbox" id="c-36702052" checked=""/><div class="controls bullet"><span class="by">yonixw</span><span>|</span><a href="#36705420">next</a><span>|</span><label class="collapse" for="c-36702052">[-]</label><label class="expand" for="c-36702052">[19 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not host your own AI at all! You need like 5 saas api-keys to operate this app. But sure, you can host this UI on your own.</div><br/><div id="36705151" class="c"><input type="checkbox" id="c-36705151" checked=""/><div class="controls bullet"><span class="by">eob</span><span>|</span><a href="#36702052">parent</a><span>|</span><a href="#36703779">next</a><span>|</span><label class="collapse" for="c-36705151">[-]</label><label class="expand" for="c-36705151">[1 more]</label></div><br/><div class="children"><div class="content">I think we’re in platform reliance mode for quite a while. I think of all of these SaaS companies as different icons on an abstract AWS console that doesn’t exist yet.<p>We wouldn’t bat an eye at using S3, EC2, and RDS as a host your own setup. The only difference here is that startups are moving faster than incumbents.<p>FWIW that’s one reason why Steamship (disclaimer: I’m the founder) aggregates all AI services under a single API key and interface. It’s to deal with the insane glue-code hassle of running this stuff on your own.</div><br/></div></div><div id="36703779" class="c"><input type="checkbox" id="c-36703779" checked=""/><div class="controls bullet"><span class="by">roseway4</span><span>|</span><a href="#36702052">parent</a><span>|</span><a href="#36705151">prev</a><span>|</span><a href="#36703160">next</a><span>|</span><label class="collapse" for="c-36703779">[-]</label><label class="expand" for="c-36703779">[2 more]</label></div><br/><div class="children"><div class="content">Well, it is a round-up of their venture investments in the space ;-)<p>If you&#x27;re looking to self-host chat memory rather than go all in on Supabase, there&#x27;s Zep: <a href="https:&#x2F;&#x2F;github.com&#x2F;getzep&#x2F;zep">https:&#x2F;&#x2F;github.com&#x2F;getzep&#x2F;zep</a><p>Full disclosure: I&#x27;m a co-author.</div><br/><div id="36705884" class="c"><input type="checkbox" id="c-36705884" checked=""/><div class="controls bullet"><span class="by">kaliqt</span><span>|</span><a href="#36702052">root</a><span>|</span><a href="#36703779">parent</a><span>|</span><a href="#36703160">next</a><span>|</span><label class="collapse" for="c-36705884">[-]</label><label class="expand" for="c-36705884">[1 more]</label></div><br/><div class="children"><div class="content">Supabase is also self-hostable though.</div><br/></div></div></div></div><div id="36703160" class="c"><input type="checkbox" id="c-36703160" checked=""/><div class="controls bullet"><span class="by">layoric</span><span>|</span><a href="#36702052">parent</a><span>|</span><a href="#36703779">prev</a><span>|</span><a href="#36702182">next</a><span>|</span><label class="collapse" for="c-36703160">[-]</label><label class="expand" for="c-36703160">[1 more]</label></div><br/><div class="children"><div class="content">It doesn&#x27;t seem to be a major barrier for most (it absolutely is for me). Is there enough of a want&#x2F;market for tools that integrate with common OSS LLM APIs like oobabooga&#x2F;Kobold&#x2F;Novel&#x2F;vLLM etc? One idea I&#x27;ve been toying with is a BYO model with support for these APIs, eg for IDE integration, brain storming etc. Seems like a good approach to me but how many people would actually bother standing up these LLM engines with APIs to use it?</div><br/></div></div><div id="36702182" class="c"><input type="checkbox" id="c-36702182" checked=""/><div class="controls bullet"><span class="by">causality0</span><span>|</span><a href="#36702052">parent</a><span>|</span><a href="#36703160">prev</a><span>|</span><a href="#36704345">next</a><span>|</span><label class="collapse" for="c-36702182">[-]</label><label class="expand" for="c-36702182">[13 more]</label></div><br/><div class="children"><div class="content">It makes me wonder how long it will be until open-source locally-run AI chatbots reach the GPT-4 level. Five years? Ten?</div><br/><div id="36703113" class="c"><input type="checkbox" id="c-36703113" checked=""/><div class="controls bullet"><span class="by">crooked-v</span><span>|</span><a href="#36702052">root</a><span>|</span><a href="#36702182">parent</a><span>|</span><a href="#36705154">next</a><span>|</span><label class="collapse" for="c-36703113">[-]</label><label class="expand" for="c-36703113">[4 more]</label></div><br/><div class="children"><div class="content">The real limiter is having enough GPU RAM to train and run a usefully large model. Everything else is just fiddly details.</div><br/><div id="36703223" class="c"><input type="checkbox" id="c-36703223" checked=""/><div class="controls bullet"><span class="by">brucethemoose2</span><span>|</span><a href="#36702052">root</a><span>|</span><a href="#36703113">parent</a><span>|</span><a href="#36705154">next</a><span>|</span><label class="collapse" for="c-36703223">[-]</label><label class="expand" for="c-36703223">[3 more]</label></div><br/><div class="children"><div class="content">Not anymore. Llama.cpp and kobold.cpp run well with low vram and non Nvidia GPUs.<p>Huggingface is full of finetunes now, and I believe a 33b model can be finetuned on a single 3090.<p>Llama.cpp is developing some kind of training, but I have no idea what the requirements will be.</div><br/><div id="36704284" class="c"><input type="checkbox" id="c-36704284" checked=""/><div class="controls bullet"><span class="by">causality0</span><span>|</span><a href="#36702052">root</a><span>|</span><a href="#36703223">parent</a><span>|</span><a href="#36705154">next</a><span>|</span><label class="collapse" for="c-36704284">[-]</label><label class="expand" for="c-36704284">[2 more]</label></div><br/><div class="children"><div class="content">To me, GPT&#x27;s real &quot;secret sauce&quot; is how it primes the model for interactive prompting instead of just text completion.</div><br/><div id="36704439" class="c"><input type="checkbox" id="c-36704439" checked=""/><div class="controls bullet"><span class="by">ynniv</span><span>|</span><a href="#36702052">root</a><span>|</span><a href="#36704284">parent</a><span>|</span><a href="#36705154">next</a><span>|</span><label class="collapse" for="c-36704439">[-]</label><label class="expand" for="c-36704439">[1 more]</label></div><br/><div class="children"><div class="content">There are &quot;chat&quot; and &quot;instruct&quot; variants of most models now.</div><br/></div></div></div></div></div></div></div></div><div id="36705154" class="c"><input type="checkbox" id="c-36705154" checked=""/><div class="controls bullet"><span class="by">eob</span><span>|</span><a href="#36702052">root</a><span>|</span><a href="#36702182">parent</a><span>|</span><a href="#36703113">prev</a><span>|</span><a href="#36702225">next</a><span>|</span><label class="collapse" for="c-36705154">[-]</label><label class="expand" for="c-36705154">[2 more]</label></div><br/><div class="children"><div class="content">When it happens, I think it’ll happen on our phones first.</div><br/><div id="36706160" class="c"><input type="checkbox" id="c-36706160" checked=""/><div class="controls bullet"><span class="by">koheripbal</span><span>|</span><a href="#36702052">root</a><span>|</span><a href="#36705154">parent</a><span>|</span><a href="#36702225">next</a><span>|</span><label class="collapse" for="c-36706160">[-]</label><label class="expand" for="c-36706160">[1 more]</label></div><br/><div class="children"><div class="content">Given the fundamental hardware matrix operations, that seems unlikely, unless it&#x27;s something very scaled down.</div><br/></div></div></div></div><div id="36702225" class="c"><input type="checkbox" id="c-36702225" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#36702052">root</a><span>|</span><a href="#36702182">parent</a><span>|</span><a href="#36705154">prev</a><span>|</span><a href="#36704371">next</a><span>|</span><label class="collapse" for="c-36702225">[-]</label><label class="expand" for="c-36702225">[1 more]</label></div><br/><div class="children"><div class="content">its more a question of hardware progress than software probably. theres a minimum level for these behaviors to emerge</div><br/></div></div><div id="36703721" class="c"><input type="checkbox" id="c-36703721" checked=""/><div class="controls bullet"><span class="by">vorpalhex</span><span>|</span><a href="#36702052">root</a><span>|</span><a href="#36702182">parent</a><span>|</span><a href="#36704371">prev</a><span>|</span><a href="#36702696">next</a><span>|</span><label class="collapse" for="c-36703721">[-]</label><label class="expand" for="c-36703721">[1 more]</label></div><br/><div class="children"><div class="content">The open source bot I played with last week (Wizard Vicuna uncensored) was 85% of gpt 3.5 on a VERY hard use case (fiction stories).<p>Maybe a year before we are the level of stablediffusion?</div><br/></div></div><div id="36702696" class="c"><input type="checkbox" id="c-36702696" checked=""/><div class="controls bullet"><span class="by">lettergram</span><span>|</span><a href="#36702052">root</a><span>|</span><a href="#36702182">parent</a><span>|</span><a href="#36703721">prev</a><span>|</span><a href="#36704345">next</a><span>|</span><label class="collapse" for="c-36702696">[-]</label><label class="expand" for="c-36702696">[3 more]</label></div><br/><div class="children"><div class="content">It depends on the tasks, I’d argue some of the open source alternatives are at the gpt-4 level already, particularly for code generation.<p>That said, I suspect summarization, translation, etc will take time. I’d suspect under 1 year.</div><br/><div id="36702743" class="c"><input type="checkbox" id="c-36702743" checked=""/><div class="controls bullet"><span class="by">worldsayshi</span><span>|</span><a href="#36702052">root</a><span>|</span><a href="#36702696">parent</a><span>|</span><a href="#36704345">next</a><span>|</span><label class="collapse" for="c-36702743">[-]</label><label class="expand" for="c-36702743">[2 more]</label></div><br/><div class="children"><div class="content">&gt;I’d argue some of the open source alternatives are at the gpt-4 level already, particularly for code generation.<p>Like which one?</div><br/><div id="36703121" class="c"><input type="checkbox" id="c-36703121" checked=""/><div class="controls bullet"><span class="by">brucethemoose2</span><span>|</span><a href="#36702052">root</a><span>|</span><a href="#36702743">parent</a><span>|</span><a href="#36704345">next</a><span>|</span><label class="collapse" for="c-36703121">[-]</label><label class="expand" for="c-36703121">[1 more]</label></div><br/><div class="children"><div class="content">Large context Chronos 33b (and some mixes) for roleplaying type chat.<p>And there are some very new 65b finetunes I have not tried.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="36705420" class="c"><input type="checkbox" id="c-36705420" checked=""/><div class="controls bullet"><span class="by">asynchronous</span><span>|</span><a href="#36702052">prev</a><span>|</span><a href="#36702235">next</a><span>|</span><label class="collapse" for="c-36705420">[-]</label><label class="expand" for="c-36705420">[3 more]</label></div><br/><div class="children"><div class="content">Tangentially related, how much would you guys be willing to pay for a company that could deliver a local model implementation that could run on high tier consumer grade hardware at a reduced ability?
I feel like even if there was some severe restrictions (model wasn&#x27;t open source, DRM, etc.) I’d still be willing to fork out for it.</div><br/><div id="36705920" class="c"><input type="checkbox" id="c-36705920" checked=""/><div class="controls bullet"><span class="by">FanaHOVA</span><span>|</span><a href="#36705420">parent</a><span>|</span><a href="#36705905">next</a><span>|</span><label class="collapse" for="c-36705920">[-]</label><label class="expand" for="c-36705920">[1 more]</label></div><br/><div class="children"><div class="content">MLC Chat lets you run RedPajama 3B on an iPhone. It&#x27;s free. You&#x27;d need to specify what type of model you&#x27;re thinking about I guess?</div><br/></div></div><div id="36705905" class="c"><input type="checkbox" id="c-36705905" checked=""/><div class="controls bullet"><span class="by">fallingmeat</span><span>|</span><a href="#36705420">parent</a><span>|</span><a href="#36705920">prev</a><span>|</span><a href="#36702235">next</a><span>|</span><label class="collapse" for="c-36705905">[-]</label><label class="expand" for="c-36705905">[1 more]</label></div><br/><div class="children"><div class="content">Is this the promise of Amazon Sagemaker?</div><br/></div></div></div></div><div id="36702235" class="c"><input type="checkbox" id="c-36702235" checked=""/><div class="controls bullet"><span class="by">mcbuilder</span><span>|</span><a href="#36705420">prev</a><span>|</span><a href="#36701907">next</a><span>|</span><label class="collapse" for="c-36702235">[-]</label><label class="expand" for="c-36702235">[2 more]</label></div><br/><div class="children"><div class="content">I hosted my own AI using SillyTavern + text-generation backend (e.g. oogabooga &#x2F; KoboldAI), just need the power needed to crank the LLM.</div><br/><div id="36703071" class="c"><input type="checkbox" id="c-36703071" checked=""/><div class="controls bullet"><span class="by">brucethemoose2</span><span>|</span><a href="#36702235">parent</a><span>|</span><a href="#36701907">next</a><span>|</span><label class="collapse" for="c-36703071">[-]</label><label class="expand" for="c-36703071">[1 more]</label></div><br/><div class="children"><div class="content">Koboldcpp (with ngrok if you need it) is another excellent self hosting solution.<p>13b will work on 16GB RAM, and 33b on 32GB RAM, with pretty much any dGPU for a little acceleration and RAM offloading.<p>Doubly so if you host it as an AI Horde node (so you have priority access to many models through the web browser).</div><br/></div></div></div></div><div id="36701907" class="c"><input type="checkbox" id="c-36701907" checked=""/><div class="controls bullet"><span class="by">arisAlexis</span><span>|</span><a href="#36702235">prev</a><span>|</span><a href="#36704857">next</a><span>|</span><label class="collapse" for="c-36701907">[-]</label><label class="expand" for="c-36701907">[7 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t get why I wouldn&#x27;t just keep an open tab with chatgpt on specific topics. They will very soon have big enough context windows. Why build another UI, deployment pipes and all that jazz ?<p>P.s nobody will *sms the companion</div><br/><div id="36705178" class="c"><input type="checkbox" id="c-36705178" checked=""/><div class="controls bullet"><span class="by">eob</span><span>|</span><a href="#36701907">parent</a><span>|</span><a href="#36702050">next</a><span>|</span><label class="collapse" for="c-36705178">[-]</label><label class="expand" for="c-36705178">[2 more]</label></div><br/><div class="children"><div class="content">ChatGPT is amazing but ultimately unwieldy for directed, long running relationships more nuanced than general themed chit chat.<p>We’re in the nascent stages but I think there will probably always be a community of folks who want to add more nuance to the communication, whether it’s reveries that enact a mood or goal, tie-ins to other services, etc.<p>Eg imagine wanting to have your ChatGPT DnD master also keep some kind of score. It may be ultimately easiest to put a wrapper around a themed GPT window that imposes a predictable way to do that rather than require everyone to figure out how to prompt it correctly.</div><br/><div id="36706090" class="c"><input type="checkbox" id="c-36706090" checked=""/><div class="controls bullet"><span class="by">arisAlexis</span><span>|</span><a href="#36701907">root</a><span>|</span><a href="#36705178">parent</a><span>|</span><a href="#36702050">next</a><span>|</span><label class="collapse" for="c-36706090">[-]</label><label class="expand" for="c-36706090">[1 more]</label></div><br/><div class="children"><div class="content">But they created a wrapper web page for a web page here</div><br/></div></div></div></div><div id="36702050" class="c"><input type="checkbox" id="c-36702050" checked=""/><div class="controls bullet"><span class="by">rootusrootus</span><span>|</span><a href="#36701907">parent</a><span>|</span><a href="#36705178">prev</a><span>|</span><a href="#36702375">next</a><span>|</span><label class="collapse" for="c-36702050">[-]</label><label class="expand" for="c-36702050">[1 more]</label></div><br/><div class="children"><div class="content">For me, it would be cost and alignment.  If I own the software, I can choose whatever alignment suits me, or none at all.  And ChatGPT is $20&#x2F;month (assuming you want GPT4, and I do).<p>But there&#x27;s still a good argument for a hybrid solution.  Buy GPT4 access through the API and get a native UI to query it.  Much cheaper to pay as you go, and someone else is still handling the heavy lifting.  But if you want an uncensored model, you&#x27;re out of luck.</div><br/></div></div><div id="36702375" class="c"><input type="checkbox" id="c-36702375" checked=""/><div class="controls bullet"><span class="by">babyshake</span><span>|</span><a href="#36701907">parent</a><span>|</span><a href="#36702050">prev</a><span>|</span><a href="#36703675">next</a><span>|</span><label class="collapse" for="c-36702375">[-]</label><label class="expand" for="c-36702375">[2 more]</label></div><br/><div class="children"><div class="content">Its roughly comparable to how you can use a spreadsheet to do a lot of different things, but it improves the UX (with some trade-offs) to have more custom designed UIs instead of directly using a spreadsheet.</div><br/><div id="36704937" class="c"><input type="checkbox" id="c-36704937" checked=""/><div class="controls bullet"><span class="by">kimburgess</span><span>|</span><a href="#36701907">root</a><span>|</span><a href="#36702375">parent</a><span>|</span><a href="#36703675">next</a><span>|</span><label class="collapse" for="c-36704937">[-]</label><label class="expand" for="c-36704937">[1 more]</label></div><br/><div class="children"><div class="content">As someone working in a large non-software org, that statement does not hold. Spreadsheets are the underlying infrastructure to a mildly terrifying amount of modern civilization.</div><br/></div></div></div></div><div id="36703675" class="c"><input type="checkbox" id="c-36703675" checked=""/><div class="controls bullet"><span class="by">Karunamon</span><span>|</span><a href="#36701907">parent</a><span>|</span><a href="#36702375">prev</a><span>|</span><a href="#36704857">next</a><span>|</span><label class="collapse" for="c-36703675">[-]</label><label class="expand" for="c-36703675">[1 more]</label></div><br/><div class="children"><div class="content">Privacy is a big one. ChatGPT (the website) gives Openai the right to use your conversations for model training (unless you turn conversation history off but that feature is rather important to the UX).<p>Anything going through the API on the other hand has a commitment to not do this and to purge the history after a month.</div><br/></div></div></div></div><div id="36704857" class="c"><input type="checkbox" id="c-36704857" checked=""/><div class="controls bullet"><span class="by">nl</span><span>|</span><a href="#36701907">prev</a><span>|</span><a href="#36705380">next</a><span>|</span><label class="collapse" for="c-36704857">[-]</label><label class="expand" for="c-36704857">[1 more]</label></div><br/><div class="children"><div class="content">I love how honest the README is:<p>&gt; Shortcomings<p>&gt; Oh, there are so many.</div><br/></div></div><div id="36705380" class="c"><input type="checkbox" id="c-36705380" checked=""/><div class="controls bullet"><span class="by">veaxvoid</span><span>|</span><a href="#36704857">prev</a><span>|</span><a href="#36703403">next</a><span>|</span><label class="collapse" for="c-36705380">[-]</label><label class="expand" for="c-36705380">[1 more]</label></div><br/><div class="children"><div class="content">you mean kaggle? don’t you?</div><br/></div></div><div id="36703403" class="c"><input type="checkbox" id="c-36703403" checked=""/><div class="controls bullet"><span class="by">yding</span><span>|</span><a href="#36705380">prev</a><span>|</span><a href="#36701823">next</a><span>|</span><label class="collapse" for="c-36703403">[-]</label><label class="expand" for="c-36703403">[1 more]</label></div><br/><div class="children"><div class="content">Good job Yoko!</div><br/></div></div><div id="36701823" class="c"><input type="checkbox" id="c-36701823" checked=""/><div class="controls bullet"><span class="by">Havoc</span><span>|</span><a href="#36703403">prev</a><span>|</span><a href="#36702413">next</a><span>|</span><label class="collapse" for="c-36701823">[-]</label><label class="expand" for="c-36701823">[3 more]</label></div><br/><div class="children"><div class="content">Is this a16z associate with the vc a16z?</div><br/><div id="36702231" class="c"><input type="checkbox" id="c-36702231" checked=""/><div class="controls bullet"><span class="by">dmarcos</span><span>|</span><a href="#36701823">parent</a><span>|</span><a href="#36702413">next</a><span>|</span><label class="collapse" for="c-36702231">[-]</label><label class="expand" for="c-36702231">[2 more]</label></div><br/><div class="children"><div class="content">Yeah. <a href="https:&#x2F;&#x2F;twitter.com&#x2F;stuffyokodraws&#x2F;status&#x2F;1678799439471972352?s=46&amp;t=2HptW4-5P7ffTQpwDgInRQ" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;stuffyokodraws&#x2F;status&#x2F;167879943947197235...</a><p>Smart. A VC firm that heavily invests in software platforms will make much better decisions if they have first hand experience using the products.</div><br/></div></div></div></div></div></div></div></div></div></body></html>