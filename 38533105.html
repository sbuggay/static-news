<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1701853256376" as="style"/><link rel="stylesheet" href="styles.css?v=1701853256376"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://generallyintelligent.substack.com/p/fine-tuning-mistral-7b-on-magic-the">Fine-tuning Mistral 7B on Magic the Gathering Draft</a> <span class="domain">(<a href="https://generallyintelligent.substack.com">generallyintelligent.substack.com</a>)</span></div><div class="subtext"><span>dmakian</span> | <span>87 comments</span></div><br/><div><div id="38535465" class="c"><input type="checkbox" id="c-38535465" checked=""/><div class="controls bullet"><span class="by">zoogeny</span><span>|</span><a href="#38535558">next</a><span>|</span><label class="collapse" for="c-38535465">[-]</label><label class="expand" for="c-38535465">[8 more]</label></div><br/><div class="children"><div class="content">I like that this shows how hard even conceptually simple ideas are to achieve in fine-tuning LLMs. Even given a pretty good starting dataset, a decent starting model, etc. this appears to have been a challenge.<p>One thing it did make me think about was that these models are suitable for things that don&#x27;t have a natural definitive answer. That is, picking the perfect card given a set of picks is probably combinatorially impossible to solve. But picking a <i>good</i> card given a set is possible and LLMs can approach human level performance.<p>I think this leads to a set of problems that current LLMs may be fine-tuned to solve.</div><br/><div id="38536531" class="c"><input type="checkbox" id="c-38536531" checked=""/><div class="controls bullet"><span class="by">dharmab</span><span>|</span><a href="#38535465">parent</a><span>|</span><a href="#38536559">next</a><span>|</span><label class="collapse" for="c-38536531">[-]</label><label class="expand" for="c-38536531">[6 more]</label></div><br/><div class="children"><div class="content">That lines up with my experience- for high-stakes decisions, they rarely give me a great answer. But for low stakes decisions, they do well at giving me a good enough answer. For example, I&#x27;ve been using them to help find gifts for friends and children this month. I don&#x27;t need the best choice to solve the problem, just a good one.</div><br/><div id="38536813" class="c"><input type="checkbox" id="c-38536813" checked=""/><div class="controls bullet"><span class="by">pixl97</span><span>|</span><a href="#38535465">root</a><span>|</span><a href="#38536531">parent</a><span>|</span><a href="#38538204">next</a><span>|</span><label class="collapse" for="c-38536813">[-]</label><label class="expand" for="c-38536813">[2 more]</label></div><br/><div class="children"><div class="content">How much additional calculation occurs in high-stakes decisions by individuals. Also what is the variability in quality of high stakes decisions in humans?<p>I&#x27;m guessing LLM decision is rather average, but that the LLM has no easy way of spending the extra time to gather information around said high stakes decisions like a human would.</div><br/><div id="38538843" class="c"><input type="checkbox" id="c-38538843" checked=""/><div class="controls bullet"><span class="by">s1artibartfast</span><span>|</span><a href="#38535465">root</a><span>|</span><a href="#38536813">parent</a><span>|</span><a href="#38538204">next</a><span>|</span><label class="collapse" for="c-38538843">[-]</label><label class="expand" for="c-38538843">[1 more]</label></div><br/><div class="children"><div class="content">I dont think additional calculation is the difference. It makes more sense to think of individual humans as models which are highly tuned.<p>Just like like LLMs, some humans are better tuned than others for specific tasks, as well as in general.</div><br/></div></div></div></div><div id="38538204" class="c"><input type="checkbox" id="c-38538204" checked=""/><div class="controls bullet"><span class="by">nothrowaways</span><span>|</span><a href="#38535465">root</a><span>|</span><a href="#38536531">parent</a><span>|</span><a href="#38536813">prev</a><span>|</span><a href="#38536559">next</a><span>|</span><label class="collapse" for="c-38538204">[-]</label><label class="expand" for="c-38538204">[3 more]</label></div><br/><div class="children"><div class="content">What are examples of low stakes</div><br/><div id="38538652" class="c"><input type="checkbox" id="c-38538652" checked=""/><div class="controls bullet"><span class="by">rictic</span><span>|</span><a href="#38535465">root</a><span>|</span><a href="#38538204">parent</a><span>|</span><a href="#38539336">next</a><span>|</span><label class="collapse" for="c-38538652">[-]</label><label class="expand" for="c-38538652">[1 more]</label></div><br/><div class="children"><div class="content">A random sampling of things GPT-4 has helped me with lately:<p>Where are the dates in whole foods? (A: with nuts, not fruits and veggies)<p>How can I steam bao without a steamer basket? (A: saucepan, 1&quot; water, balled up aluminum foil, plate, baos, lid)<p>Any guess as to when this photo was taken? It looks like anywhere from the 70s to the 90s. (A: the photo paper has a logo that postdates a 2003 company merger)</div><br/></div></div><div id="38539336" class="c"><input type="checkbox" id="c-38539336" checked=""/><div class="controls bullet"><span class="by">dharmab</span><span>|</span><a href="#38535465">root</a><span>|</span><a href="#38538204">parent</a><span>|</span><a href="#38538652">prev</a><span>|</span><a href="#38536559">next</a><span>|</span><label class="collapse" for="c-38539336">[-]</label><label class="expand" for="c-38539336">[1 more]</label></div><br/><div class="children"><div class="content">Generating content for tabletop gaming with my friends (especially wacky ideas, like character names themed after items on the Taco Bell menu)<p>I had to buy some spare tools where I cared more about price than quality and it helped me choose some suitable brands<p>As mentioned, you can tell it a bit about a person (and feed in their wishlist if they have one) and it&#x27;ll help you pick something they&#x27;ll probably like<p>Finding something to do to spend an afternoon in a city while traveling<p>In general, anything where there is no objective best answer (meaning I can ask it to generate multiple possibilities and filter out the bad ideas) and where I value speed over correctness.</div><br/></div></div></div></div></div></div><div id="38536559" class="c"><input type="checkbox" id="c-38536559" checked=""/><div class="controls bullet"><span class="by">falcor84</span><span>|</span><a href="#38535465">parent</a><span>|</span><a href="#38536531">prev</a><span>|</span><a href="#38535558">next</a><span>|</span><label class="collapse" for="c-38536559">[-]</label><label class="expand" for="c-38536559">[1 more]</label></div><br/><div class="children"><div class="content">I wonder if you could define a specific complexity class of problems that LLMs are good at</div><br/></div></div></div></div><div id="38535558" class="c"><input type="checkbox" id="c-38535558" checked=""/><div class="controls bullet"><span class="by">doctorpangloss</span><span>|</span><a href="#38535465">prev</a><span>|</span><a href="#38534449">next</a><span>|</span><label class="collapse" for="c-38535558">[-]</label><label class="expand" for="c-38535558">[8 more]</label></div><br/><div class="children"><div class="content">&gt; With that data, you can extract “ground truth” by looking at the draft picks made by the best players on the service (sorted by win rate).<p>Do you mean that you are looking at the draft picks from <a href="https:&#x2F;&#x2F;www.17lands.com&#x2F;leaderboard" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.17lands.com&#x2F;leaderboard</a> and then sorting by Win Rate? Didn&#x27;t you mean to choose Match Wins or Trophies? Otherwise, you&#x27;re not measuring the best players on the service. You&#x27;re training on draft choices where most choices were very good - i.e., win rate sort will show you the luckiest players, not the best ones. That will naturally show up in any validation or testing you do too.<p>Shouldn&#x27;t this be compared not to an LLM baseline, but to a baseline where an &quot;Elo&quot; style score is computed for each card compared to others from the 17lands data; then, until you have two colors, suggest the best scoring card, or when you do have color(s), suggest the best scoring card within that color or a land?<p>I think it is possible for the LLM to have some semblance of rules knowledge, but it is more likely that it is picking up on card rarity, costs and &quot;Big&quot; more than anything else for unseen cards.<p>Your &quot;accuracy&quot; on the draft seems poor. I&#x27;m not sure it means what you think it means. Are you saying that when looking at the high win rate choices, where all the choices were mostly good, you happened to pick the choice that isn&#x27;t the same as the player who originated the data? It actually seems harder to make a choice among all good choices.<p>Anyway, there is quite a bit going on here.</div><br/><div id="38535585" class="c"><input type="checkbox" id="c-38535585" checked=""/><div class="controls bullet"><span class="by">dmakian</span><span>|</span><a href="#38535558">parent</a><span>|</span><a href="#38534449">next</a><span>|</span><label class="collapse" for="c-38535585">[-]</label><label class="expand" for="c-38535585">[7 more]</label></div><br/><div class="children"><div class="content">&gt; Do you mean that you are looking at the draft picks from <a href="https:&#x2F;&#x2F;www.17lands.com&#x2F;leaderboard" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.17lands.com&#x2F;leaderboard</a> and then sorting by Win Rate? Didn&#x27;t you mean to choose Match Wins or Trophies? Otherwise, you&#x27;re not measuring the best players on the service. You&#x27;re training on draft choices where most choices were very good - i.e., win rate sort will show you the luckiest players, not the best ones. That will naturally show up in any validation or testing you do too.<p>Ahh no just unclear in the post, I&#x27;m filtering to players in 17lands with a &gt; 62% match win rate who are drafting at a high ranking (&gt;=diamond rank). I look at all of those players&#x27; drafts though, even the ones where they do poorly.<p>&gt; Your &quot;accuracy&quot; on the draft seems poor. I&#x27;m not sure it means what you think it means. Are you saying that when looking at the high win rate choices, where all the choices were mostly good, you happened to pick the choice that isn&#x27;t the same as the player who originated the data? It actually seems harder to make a choice among all good choices.<p>Accuracy here is making the same choice from a given pack as one of the good players. Obviously subjective so not a perfect metric, but a decent check on ability to emulate a high-quality drafter.</div><br/><div id="38536312" class="c"><input type="checkbox" id="c-38536312" checked=""/><div class="controls bullet"><span class="by">Palmik</span><span>|</span><a href="#38535558">root</a><span>|</span><a href="#38535585">parent</a><span>|</span><a href="#38535746">next</a><span>|</span><label class="collapse" for="c-38536312">[-]</label><label class="expand" for="c-38536312">[2 more]</label></div><br/><div class="children"><div class="content">In ELO like match-making, you typically pair together people such that they are likely to have 50% chance to win. Therefore as the OP says, filtering down to people with high (60+%) life-time win-rate creates some sort of (interesting) bias.<p>I would select from all games played on sufficiently high level.</div><br/><div id="38538532" class="c"><input type="checkbox" id="c-38538532" checked=""/><div class="controls bullet"><span class="by">pclmulqdq</span><span>|</span><a href="#38535558">root</a><span>|</span><a href="#38536312">parent</a><span>|</span><a href="#38535746">next</a><span>|</span><label class="collapse" for="c-38538532">[-]</label><label class="expand" for="c-38538532">[1 more]</label></div><br/><div class="children"><div class="content">They don&#x27;t fully use Elo for matchmaking.  There&#x27;s a league system, and you get matched with players in your league.  The ranks reset frequently, too.<p>Edit - I did the math.  From the data on the MTG Elo Project, top Magic players have about a 70-75% game win percentage over an average tournament player.  They have the top player at ~2300 Elo with the average being around 1500 (in matches), and have scaled the Elo system so that a 200 point gap is a 60% chance to win a best-of-three match (this is NOT the same as Chess Elo scoring).</div><br/></div></div></div></div><div id="38535746" class="c"><input type="checkbox" id="c-38535746" checked=""/><div class="controls bullet"><span class="by">doctorpangloss</span><span>|</span><a href="#38535558">root</a><span>|</span><a href="#38535585">parent</a><span>|</span><a href="#38536312">prev</a><span>|</span><a href="#38534449">next</a><span>|</span><label class="collapse" for="c-38535746">[-]</label><label class="expand" for="c-38535746">[4 more]</label></div><br/><div class="children"><div class="content">Hmm, but that will filter out more than half the players on the Match Wins and Trophies based leaderboards, many of them Diamond and Mythic. So I think your choice of 62% match win rate is almost certainly disproportionately selecting for people who received very good draft choices, even if it includes some actually very good players in the data set.<p>I mean 62% might feel like a good number, but it&#x27;s arbitrary, you&#x27;d have to justify how you chose it, and just eyeballing it, it is filtering out a lot of very good players with many, many more match wins.<p>Perhaps you can sort by Latest Rank, and filter out people with 2 or fewer trophies. Or you will have to validate with known bad draft choices in the prompt, to see what it does. Suffice it to say, I still don&#x27;t think the 17Lands data represents what you think it does.<p>Like without a direct discussion about measuring and accounting for luck in the draft... for all I know the data is seriously flawed. It probably isn&#x27;t, but it&#x27;s maybe one of many, many issues to address when dealing with strategy card game AI problems.</div><br/><div id="38535886" class="c"><input type="checkbox" id="c-38535886" checked=""/><div class="controls bullet"><span class="by">dmakian</span><span>|</span><a href="#38535558">root</a><span>|</span><a href="#38535746">parent</a><span>|</span><a href="#38534449">next</a><span>|</span><label class="collapse" for="c-38535886">[-]</label><label class="expand" for="c-38535886">[3 more]</label></div><br/><div class="children"><div class="content">Still not clear maybe, I&#x27;m selecting players with a 62% lifetime win rate so mostly players who have been good over a larger number of drafts!<p>Definitely not perfect data though, and agree that defining good in this context is hard -- a lot of the variance of &quot;good&quot; depends on how you play the cards either way. All good points!</div><br/><div id="38536107" class="c"><input type="checkbox" id="c-38536107" checked=""/><div class="controls bullet"><span class="by">doctorpangloss</span><span>|</span><a href="#38535558">root</a><span>|</span><a href="#38535886">parent</a><span>|</span><a href="#38538753">next</a><span>|</span><label class="collapse" for="c-38536107">[-]</label><label class="expand" for="c-38536107">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I&#x27;m selecting players with a 62% lifetime win rate so mostly players who have been good over a larger number of drafts!<p>Hmm, but there are a lot of players with greater than a 62% lifetime win rate with very few drafts, but there may be many of those players... do you see? The win rate isn&#x27;t a good filter. You chose it, you are trying to justify it, and I&#x27;m not convinced, not without the hard numbers.<p>I&#x27;m not confused about what filter you chose. I just think it&#x27;s a bad filter, and you haven&#x27;t thought very deeply about how it affects the data, which includes presumably your test and validation data - however you&#x27;re choosing to test and validate, apparently by hand, by some eyeballed examples.<p>Anyway I think you have to compare with a non-LLM, non-random baseline to have any sense if this stuff is working at all. I could be dead wrong. I would maybe compare with a community draft picker.</div><br/></div></div><div id="38538753" class="c"><input type="checkbox" id="c-38538753" checked=""/><div class="controls bullet"><span class="by">donpark</span><span>|</span><a href="#38535558">root</a><span>|</span><a href="#38535886">parent</a><span>|</span><a href="#38536107">prev</a><span>|</span><a href="#38534449">next</a><span>|</span><label class="collapse" for="c-38538753">[-]</label><label class="expand" for="c-38538753">[1 more]</label></div><br/><div class="children"><div class="content">Data selection depends the use-case. Two contrasting use-cases I see are:<p>- Emulation<p>- Advisor<p>In case of MTG player emulation for example, I think it makes sense to group data by some rankable criteria like winrate to train rank-specific models that can mimic players of each rank.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="38534449" class="c"><input type="checkbox" id="c-38534449" checked=""/><div class="controls bullet"><span class="by">dwrodri</span><span>|</span><a href="#38535558">prev</a><span>|</span><a href="#38536475">next</a><span>|</span><label class="collapse" for="c-38534449">[-]</label><label class="expand" for="c-38534449">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not the most revolutionary change to our daily lives, but I do genuinely look forward to playing against bots that have interesting play styles for games like Magic: the Gathering. I think this is a clear case where it could drastically improve the ability for the R&amp;D team to come up with and test new mechanics at different levels of play.</div><br/><div id="38540054" class="c"><input type="checkbox" id="c-38540054" checked=""/><div class="controls bullet"><span class="by">Mengkudulangsat</span><span>|</span><a href="#38534449">parent</a><span>|</span><a href="#38536475">next</a><span>|</span><label class="collapse" for="c-38540054">[-]</label><label class="expand" for="c-38540054">[1 more]</label></div><br/><div class="children"><div class="content">The OpenAI Dota2 experiment produced many interesting behaviours, even the pros are impressed.</div><br/></div></div></div></div><div id="38536475" class="c"><input type="checkbox" id="c-38536475" checked=""/><div class="controls bullet"><span class="by">float-trip</span><span>|</span><a href="#38534449">prev</a><span>|</span><a href="#38540569">next</a><span>|</span><label class="collapse" for="c-38536475">[-]</label><label class="expand" for="c-38536475">[3 more]</label></div><br/><div class="children"><div class="content">Thanks for writing up. Rather than zeroing out the loss for the prompt, did you also try using weighted loss with Axolotl? At one point, Microsoft&#x27;s GPT 3 docs suggested this was beneficial when the responses are short (like you have with &quot;Cut in.&quot;) Domain adaptation over subreddits&#x2F;forums before finetuning may help as well.</div><br/><div id="38536526" class="c"><input type="checkbox" id="c-38536526" checked=""/><div class="controls bullet"><span class="by">dmakian</span><span>|</span><a href="#38536475">parent</a><span>|</span><a href="#38540569">next</a><span>|</span><label class="collapse" for="c-38536526">[-]</label><label class="expand" for="c-38536526">[2 more]</label></div><br/><div class="children"><div class="content">&gt; did you also try using weighted loss with Axolotl<p>This is really smart, I didn&#x27;t think about this! Will add it to my list of things to try, great idea!<p>&gt; Domain adaptation over subreddits&#x2F;forums before finetuning may help as well.<p>I was thinking about this too (along with transcribing draft youtube videos), I&#x27;d definitely be curious how much this helps.</div><br/><div id="38539323" class="c"><input type="checkbox" id="c-38539323" checked=""/><div class="controls bullet"><span class="by">float-trip</span><span>|</span><a href="#38536475">root</a><span>|</span><a href="#38536526">parent</a><span>|</span><a href="#38540569">next</a><span>|</span><label class="collapse" for="c-38539323">[-]</label><label class="expand" for="c-38539323">[1 more]</label></div><br/><div class="children"><div class="content">Related comment from gwern: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38438859">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38438859</a>. Can&#x27;t find the docs now - I think they were the old GPT 3 ones - but they suggested a low value somewhere around 0.01 and 0.1.<p>Also - why qlora rather than a full finetune? Using LambdaLabs, it&#x27;d cost roughly the same as your quote. Cheaper I think if you&#x27;re willing to gamble with fp8: <a href="https:&#x2F;&#x2F;github.com&#x2F;mosaicml&#x2F;llm-foundry&#x2F;tree&#x2F;main&#x2F;scripts&#x2F;train&#x2F;benchmarking">https:&#x2F;&#x2F;github.com&#x2F;mosaicml&#x2F;llm-foundry&#x2F;tree&#x2F;main&#x2F;scripts&#x2F;tr...</a>. And fewer hyperparameters to tune as well</div><br/></div></div></div></div></div></div><div id="38540569" class="c"><input type="checkbox" id="c-38540569" checked=""/><div class="controls bullet"><span class="by">HanClinto</span><span>|</span><a href="#38536475">prev</a><span>|</span><a href="#38535364">next</a><span>|</span><label class="collapse" for="c-38540569">[-]</label><label class="expand" for="c-38540569">[1 more]</label></div><br/><div class="children"><div class="content">Excellent, thank you for posting this!<p>I was actually just looking into fine-tuning an LLM for Magic: The Gathering this week -- I&#x27;ve been building a small card-similarity browser using semantic embeddings of cards to find functionally or flavorfully similar cards.<p>I&#x27;ve just been using InstructorXL, but either Instructor doesn&#x27;t have enough innate knowledge of the game, or else I need to work on better prompts, but so far I&#x27;ve tried 9 different prompts, and none of them seem to perform very well for generating embeddings:<p><a href="https:&#x2F;&#x2F;github.com&#x2F;HanClinto&#x2F;MtgMatrix&#x2F;blob&#x2F;main&#x2F;data&#x2F;create_db.py#L20">https:&#x2F;&#x2F;github.com&#x2F;HanClinto&#x2F;MtgMatrix&#x2F;blob&#x2F;main&#x2F;data&#x2F;create...</a><p>So my next step was to try and download a dataset of similar cards (I have some ideas on this), and I was trying to see if I could use this to do triplet-loss training of a large embedding model or something.<p>Aaaaand, that&#x27;s as far as I&#x27;ve gotten.  I haven&#x27;t actually figured out _how_ to hook all of that up, but your post is extremely inspirational for me.  Thank you for posting this!!</div><br/></div></div><div id="38535364" class="c"><input type="checkbox" id="c-38535364" checked=""/><div class="controls bullet"><span class="by">apetresc</span><span>|</span><a href="#38540569">prev</a><span>|</span><a href="#38535213">next</a><span>|</span><label class="collapse" for="c-38535364">[-]</label><label class="expand" for="c-38535364">[7 more]</label></div><br/><div class="children"><div class="content">If I&#x27;m reading the author&#x27;s writeup correctly, the prompt he&#x27;s giving the agent at each pick contains only the <i>names</i> of the cards in its pool so far, and only gives the full text for the cards in the pack it&#x27;s being passed. It doesn&#x27;t look like context is being maintained between picks, presumably for context window size reasons.<p>If so, and if he&#x27;s correct in his assumption that these sets are out of the bot&#x27;s training cutoff window, then surely it&#x27;s purely coincidence if it ends up being a good drafter? The bot would have literally no way to know what cards work well with its previous picks, what signals have been sent and received in the draft so far, etc. Not even the best human player could take (for example, from the sample prompt) &quot;Gadwick&#x27;s First Duel -- {1}{U} (uncommon)&quot; and figure out what works well with that (if they&#x27;ve never seen the card before).<p>It would just end up picking generically good draft cards that share a color with its previous picks. Which is already what pick-order-based heuristics have always done.</div><br/><div id="38535415" class="c"><input type="checkbox" id="c-38535415" checked=""/><div class="controls bullet"><span class="by">dmakian</span><span>|</span><a href="#38535364">parent</a><span>|</span><a href="#38535213">next</a><span>|</span><label class="collapse" for="c-38535415">[-]</label><label class="expand" for="c-38535415">[6 more]</label></div><br/><div class="children"><div class="content">&gt; If I&#x27;m reading the author&#x27;s writeup correctly, the prompt he&#x27;s giving the agent at each pick contains only the names of the cards in its pool so far, and only gives the full text for the cards in the pack it&#x27;s being passed. It doesn&#x27;t look like context is being maintained between picks, presumably for context window size reasons.<p>Not quite -- there&#x27;s a few ways the model learns the full card text:<p>* The models are trained on card trivia completions as well, where they&#x27;re asked to complete the full text of the card as well as information about it (type, CMC, etc.)<p>* The models do still have to learn next token completion on the cards in packs, meaning they learn to predict the full text of the cards while making draft picks as well.<p>Net net, the bots learn the text of the new cards pretty comprehensively.</div><br/><div id="38535434" class="c"><input type="checkbox" id="c-38535434" checked=""/><div class="controls bullet"><span class="by">apetresc</span><span>|</span><a href="#38535364">root</a><span>|</span><a href="#38535415">parent</a><span>|</span><a href="#38536286">next</a><span>|</span><label class="collapse" for="c-38535434">[-]</label><label class="expand" for="c-38535434">[4 more]</label></div><br/><div class="children"><div class="content">Ooh I see! You do that with Mistral7B, I&#x27;m guessing? But not with the small GPT-3.5 trial you did?</div><br/><div id="38535491" class="c"><input type="checkbox" id="c-38535491" checked=""/><div class="controls bullet"><span class="by">dmakian</span><span>|</span><a href="#38535364">root</a><span>|</span><a href="#38535434">parent</a><span>|</span><a href="#38536286">next</a><span>|</span><label class="collapse" for="c-38535491">[-]</label><label class="expand" for="c-38535491">[3 more]</label></div><br/><div class="children"><div class="content">The two larger GPT-3.5 trials also got the card trivia examples, but like a bad scientist I don&#x27;t have a great control group for those</div><br/><div id="38535529" class="c"><input type="checkbox" id="c-38535529" checked=""/><div class="controls bullet"><span class="by">apetresc</span><span>|</span><a href="#38535364">root</a><span>|</span><a href="#38535491">parent</a><span>|</span><a href="#38536286">next</a><span>|</span><label class="collapse" for="c-38535529">[-]</label><label class="expand" for="c-38535529">[2 more]</label></div><br/><div class="children"><div class="content">And also, since it seems you&#x27;re the author, can you also clarify if your methodology allowed for the bot to track signals outside of the color-identity-count summary statistic you pass in the prompt? Something like allowing it to notice that a card has wheeled, or that a certain synergy piece was passed a few picks ago.</div><br/><div id="38535624" class="c"><input type="checkbox" id="c-38535624" checked=""/><div class="controls bullet"><span class="by">dmakian</span><span>|</span><a href="#38535364">root</a><span>|</span><a href="#38535529">parent</a><span>|</span><a href="#38536286">next</a><span>|</span><label class="collapse" for="c-38535624">[-]</label><label class="expand" for="c-38535624">[1 more]</label></div><br/><div class="children"><div class="content">Only the statistics you see in the prompt (which are clearly limited). I have a lot of ideas about how you could improve that context (most likely letting the AI record and track notes throughout a draft), but this one was relatively simple to implement.  Definitely room for improvement!</div><br/></div></div></div></div></div></div></div></div><div id="38536286" class="c"><input type="checkbox" id="c-38536286" checked=""/><div class="controls bullet"><span class="by">chc4</span><span>|</span><a href="#38535364">root</a><span>|</span><a href="#38535415">parent</a><span>|</span><a href="#38535434">prev</a><span>|</span><a href="#38535213">next</a><span>|</span><label class="collapse" for="c-38536286">[-]</label><label class="expand" for="c-38536286">[1 more]</label></div><br/><div class="children"><div class="content">Haha, I don&#x27;t know anything about AI training but that&#x27;s a really cute trick.</div><br/></div></div></div></div></div></div><div id="38535213" class="c"><input type="checkbox" id="c-38535213" checked=""/><div class="controls bullet"><span class="by">mdaniel</span><span>|</span><a href="#38535364">prev</a><span>|</span><a href="#38535349">next</a><span>|</span><label class="collapse" for="c-38535213">[-]</label><label class="expand" for="c-38535213">[4 more]</label></div><br/><div class="children"><div class="content">In case you didn&#x27;t see it, <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38525978">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38525978</a> (I hacked Magic the Gathering: Arena for a 100% win rate) may interest this audience if for no other reason that the investigator discovered that Sparky, the pseudo-AI in MTGA, doesn&#x27;t appear to be as stupid complicated as one may have suspected from the outside</div><br/><div id="38536271" class="c"><input type="checkbox" id="c-38536271" checked=""/><div class="controls bullet"><span class="by">chc4</span><span>|</span><a href="#38535213">parent</a><span>|</span><a href="#38535349">next</a><span>|</span><label class="collapse" for="c-38536271">[-]</label><label class="expand" for="c-38536271">[3 more]</label></div><br/><div class="children"><div class="content">Sparky is the Arena AI, but no one ever accused it of being a <i>good</i> Arena AI - it is very much only there for the new player experience of playing against a dumb computer when you&#x27;re first exposed to the game and don&#x27;t know the rules, or for the computer equivalent of &quot;playing against a goldfish&quot; a deck you made to see how it draws or combos. It&#x27;s not a Chess CPU.</div><br/><div id="38536930" class="c"><input type="checkbox" id="c-38536930" checked=""/><div class="controls bullet"><span class="by">mdaniel</span><span>|</span><a href="#38535213">root</a><span>|</span><a href="#38536271">parent</a><span>|</span><a href="#38535349">next</a><span>|</span><label class="collapse" for="c-38536930">[-]</label><label class="expand" for="c-38536930">[2 more]</label></div><br/><div class="children"><div class="content">I hope I also did not accuse it of being good, but the observation I was trying to make is that -- according to the article, I have not myself confirmed the claim -- they run the card evaluation logic <i>and gameplanning</i> locally, not in a data center full of H100s, which I consider to be quite a feat given the free-text-y self-modifying rules of M:TG</div><br/><div id="38538286" class="c"><input type="checkbox" id="c-38538286" checked=""/><div class="controls bullet"><span class="by">sciolist</span><span>|</span><a href="#38535213">root</a><span>|</span><a href="#38536930">parent</a><span>|</span><a href="#38535349">next</a><span>|</span><label class="collapse" for="c-38538286">[-]</label><label class="expand" for="c-38538286">[1 more]</label></div><br/><div class="children"><div class="content">One of the big things to note is that Sparky plays very basic decks, with few complicated cards and combos. Rules-based AI could definitely play at a basic level using a beatdown strategy, but give it some sort of control&#x2F;combo deck and it would struggle.</div><br/></div></div></div></div></div></div></div></div><div id="38535349" class="c"><input type="checkbox" id="c-38535349" checked=""/><div class="controls bullet"><span class="by">greysphere</span><span>|</span><a href="#38535213">prev</a><span>|</span><a href="#38536467">next</a><span>|</span><label class="collapse" for="c-38535349">[-]</label><label class="expand" for="c-38535349">[4 more]</label></div><br/><div class="children"><div class="content">It would be interesting to compare to training a NN to draft w&#x2F;o the Mistral starting point (both by epoch and by $). It&#x27;s not obvious to me why the LLM component would be relevant.  Maybe there are enough deck lists or mock drafts on the internet to have an influence I suppose. Or maybe &#x27;fine tune an llm&#x27; just has more infrastructure than &#x27;create a nn&#x27;. Maybe we need a nnfiddle to make that easier.</div><br/><div id="38536091" class="c"><input type="checkbox" id="c-38536091" checked=""/><div class="controls bullet"><span class="by">filterfiber</span><span>|</span><a href="#38535349">parent</a><span>|</span><a href="#38535592">next</a><span>|</span><label class="collapse" for="c-38536091">[-]</label><label class="expand" for="c-38536091">[1 more]</label></div><br/><div class="children"><div class="content">The benefit of the LLMs is that the checkpoint already &quot;understands&quot; a lot by default. Finetuning is relatively cheap and makes many tasks such as this one perform decently well simply by shoving some data into it.<p>The base checkpoint takes a lot of compute to make, but that&#x27;s what holds most of it&#x27;s &quot;knowledge&quot; so to speak.<p>Making a NN from scratch means you&#x27;ll have to somehow map the cards into inputs. I have limited knowledge of how MTG works, but most TGG have text descriptions and complex effects. Mapping text to logic is what LLMs are really good at, otherwise you&#x27;re starting from scratch and will also need a relatively large amount of compute before it starts displaying any type of decent behaviour.<p>It&#x27;s also easy for most software devs to do this - finetuning mostly consists of collecting text and feeding it into a finetuning script. You don&#x27;t need to know linear algebra, what a &quot;convolution&quot; is, etc. to do finetuning.</div><br/></div></div><div id="38535592" class="c"><input type="checkbox" id="c-38535592" checked=""/><div class="controls bullet"><span class="by">apetresc</span><span>|</span><a href="#38535349">parent</a><span>|</span><a href="#38536091">prev</a><span>|</span><a href="#38536467">next</a><span>|</span><label class="collapse" for="c-38535592">[-]</label><label class="expand" for="c-38535592">[2 more]</label></div><br/><div class="children"><div class="content">Without Mistral, how would you get it to generalize to cards it hasn&#x27;t seen before? I assume by &quot;training a NN to draft without Mistral&quot; you mean where the input layer is just a bitmapped vector of the cards in the pack, right? The killer feature of this experiment is that it works on sets the model has never seen before and has 0 training data on, using just the text of the card. I don&#x27;t think you can do that without an LLM.</div><br/><div id="38535920" class="c"><input type="checkbox" id="c-38535920" checked=""/><div class="controls bullet"><span class="by">greysphere</span><span>|</span><a href="#38535349">root</a><span>|</span><a href="#38535592">parent</a><span>|</span><a href="#38536467">next</a><span>|</span><label class="collapse" for="c-38535920">[-]</label><label class="expand" for="c-38535920">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s a good point. It looks like the article hints at some success on that front. It&#x27;d be interesting to see what that means quantitatively. Interesting that this delta could even be used as a measure of the llm&#x27;s value.<p>I&#x27;d be curious about the difference in success w&#x2F; drafts on a new 2&#x2F;2 bear with a different name, and cards with a new keyword &#x27;fizzbangitude 7&#x27; as well.</div><br/></div></div></div></div></div></div><div id="38536467" class="c"><input type="checkbox" id="c-38536467" checked=""/><div class="controls bullet"><span class="by">8f2ab37a-ed6c</span><span>|</span><a href="#38535349">prev</a><span>|</span><a href="#38534746">next</a><span>|</span><label class="collapse" for="c-38536467">[-]</label><label class="expand" for="c-38536467">[6 more]</label></div><br/><div class="children"><div class="content">Thanks for sharing this, I found it helpful as an addition to my homebrew curriculum for learning how to fine-tune open source LLMs.</div><br/><div id="38536538" class="c"><input type="checkbox" id="c-38536538" checked=""/><div class="controls bullet"><span class="by">objektif</span><span>|</span><a href="#38536467">parent</a><span>|</span><a href="#38534746">next</a><span>|</span><label class="collapse" for="c-38536538">[-]</label><label class="expand" for="c-38536538">[5 more]</label></div><br/><div class="children"><div class="content">Can you please point me to good resources on fine tuning? Thanks.</div><br/><div id="38536747" class="c"><input type="checkbox" id="c-38536747" checked=""/><div class="controls bullet"><span class="by">amrrs</span><span>|</span><a href="#38536467">root</a><span>|</span><a href="#38536538">parent</a><span>|</span><a href="#38537277">next</a><span>|</span><label class="collapse" for="c-38536747">[-]</label><label class="expand" for="c-38536747">[1 more]</label></div><br/><div class="children"><div class="content">Check out <a href="https:&#x2F;&#x2F;github.com&#x2F;OpenAccess-AI-Collective&#x2F;axolotl">https:&#x2F;&#x2F;github.com&#x2F;OpenAccess-AI-Collective&#x2F;axolotl</a></div><br/></div></div><div id="38537277" class="c"><input type="checkbox" id="c-38537277" checked=""/><div class="controls bullet"><span class="by">8f2ab37a-ed6c</span><span>|</span><a href="#38536467">root</a><span>|</span><a href="#38536538">parent</a><span>|</span><a href="#38536747">prev</a><span>|</span><a href="#38534746">next</a><span>|</span><label class="collapse" for="c-38537277">[-]</label><label class="expand" for="c-38537277">[3 more]</label></div><br/><div class="children"><div class="content">Search for articles showing you code for fine-tuning Llama 2, ideally including a colab notebook that you can run and modify yourself so that you have real code to work with. You can try to modify their working example to suit your own toy project as a first step.</div><br/><div id="38538181" class="c"><input type="checkbox" id="c-38538181" checked=""/><div class="controls bullet"><span class="by">objektif</span><span>|</span><a href="#38536467">root</a><span>|</span><a href="#38537277">parent</a><span>|</span><a href="#38534746">next</a><span>|</span><label class="collapse" for="c-38538181">[-]</label><label class="expand" for="c-38538181">[2 more]</label></div><br/><div class="children"><div class="content">This has not been very useful as everyone is trying to market their tool in a way.</div><br/><div id="38538439" class="c"><input type="checkbox" id="c-38538439" checked=""/><div class="controls bullet"><span class="by">nlpfromscratch</span><span>|</span><a href="#38536467">root</a><span>|</span><a href="#38538181">parent</a><span>|</span><a href="#38534746">next</a><span>|</span><label class="collapse" for="c-38538439">[-]</label><label class="expand" for="c-38538439">[1 more]</label></div><br/><div class="children"><div class="content">Assuming you are using Transformers, the official notebooks are a logical place to start: <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;docs&#x2F;transformers&#x2F;notebooks" rel="nofollow noreferrer">https:&#x2F;&#x2F;huggingface.co&#x2F;docs&#x2F;transformers&#x2F;notebooks</a></div><br/></div></div></div></div></div></div></div></div></div></div><div id="38534746" class="c"><input type="checkbox" id="c-38534746" checked=""/><div class="controls bullet"><span class="by">danbrooks</span><span>|</span><a href="#38536467">prev</a><span>|</span><a href="#38538734">next</a><span>|</span><label class="collapse" for="c-38534746">[-]</label><label class="expand" for="c-38534746">[2 more]</label></div><br/><div class="children"><div class="content">Super interesting that drafts can be represented with LLMs.<p>The best performing draft AI&#x27;s I&#x27;ve seen leverage representation learning in some form.<p>See: <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2107.04438.pdf" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2107.04438.pdf</a></div><br/><div id="38534858" class="c"><input type="checkbox" id="c-38534858" checked=""/><div class="controls bullet"><span class="by">dmakian</span><span>|</span><a href="#38534746">parent</a><span>|</span><a href="#38538734">next</a><span>|</span><label class="collapse" for="c-38534858">[-]</label><label class="expand" for="c-38534858">[1 more]</label></div><br/><div class="children"><div class="content">I hadn&#x27;t seen this, this is awesome! You&#x27;d think given the volume of data available that this type of method would outperform an LLM, cool results.<p>Still some fun things about LLM representations -- you can do fun things like give the bots preferences &#x2F; personality in a system prompt which is entertaining!</div><br/></div></div></div></div><div id="38538734" class="c"><input type="checkbox" id="c-38538734" checked=""/><div class="controls bullet"><span class="by">qrian</span><span>|</span><a href="#38534746">prev</a><span>|</span><a href="#38534860">next</a><span>|</span><label class="collapse" for="c-38538734">[-]</label><label class="expand" for="c-38538734">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve seen models learn heuristics that are harmful in real performance, and I wonder how much is accuracy directly transferrable to actually good drafting.<p>A question, when GPT-4 contradicts in explanation, how much of them were in fact correct?</div><br/><div id="38539223" class="c"><input type="checkbox" id="c-38539223" checked=""/><div class="controls bullet"><span class="by">dmakian</span><span>|</span><a href="#38538734">parent</a><span>|</span><a href="#38534860">next</a><span>|</span><label class="collapse" for="c-38539223">[-]</label><label class="expand" for="c-38539223">[1 more]</label></div><br/><div class="children"><div class="content">&gt; A question, when GPT-4 contradicts in explanation, how much of them were in fact correct?<p>It was mostly when a card is good in a vacuum but not as good in a specific set. WOE (which this was trained on) skewed pretty aggressive, so GPT-4 was tended to overvalue strong expensive cards (compared to what good players thought at least).</div><br/></div></div></div></div><div id="38534860" class="c"><input type="checkbox" id="c-38534860" checked=""/><div class="controls bullet"><span class="by">reactordev</span><span>|</span><a href="#38538734">prev</a><span>|</span><a href="#38537316">next</a><span>|</span><label class="collapse" for="c-38534860">[-]</label><label class="expand" for="c-38534860">[2 more]</label></div><br/><div class="children"><div class="content">I like how it identified that you haven&#x27;t committed to either white or blue yet. It was aware of deck <i>composition</i> and not just going for the jugular. Keep tuning. It could also be Human-bias because you also <i>played</i> the hand. Have someone else draft against your LLM and then you play it and see if it&#x27;s the same. Statistically it should match given enough games.</div><br/><div id="38541158" class="c"><input type="checkbox" id="c-38541158" checked=""/><div class="controls bullet"><span class="by">beacon294</span><span>|</span><a href="#38534860">parent</a><span>|</span><a href="#38537316">next</a><span>|</span><label class="collapse" for="c-38541158">[-]</label><label class="expand" for="c-38541158">[1 more]</label></div><br/><div class="children"><div class="content">draft data exists, might be a fast alternative</div><br/></div></div></div></div><div id="38537316" class="c"><input type="checkbox" id="c-38537316" checked=""/><div class="controls bullet"><span class="by">rgbrgb</span><span>|</span><a href="#38534860">prev</a><span>|</span><a href="#38539827">next</a><span>|</span><label class="collapse" for="c-38537316">[-]</label><label class="expand" for="c-38537316">[2 more]</label></div><br/><div class="children"><div class="content">&gt; I ended up renting an hourly GPU from Runpod (an RTX 4090 w&#x2F; 24GB of VRAM) for ~$0.7&#x2F;hr.<p>Sorry if I missed this, but how much did it cost total to do the fine-tune? Is that the 40 hour number (~$27)?<p>Also, very cool writeup. Thanks for sharing!</div><br/><div id="38537377" class="c"><input type="checkbox" id="c-38537377" checked=""/><div class="controls bullet"><span class="by">dmakian</span><span>|</span><a href="#38537316">parent</a><span>|</span><a href="#38539827">next</a><span>|</span><label class="collapse" for="c-38537377">[-]</label><label class="expand" for="c-38537377">[1 more]</label></div><br/><div class="children"><div class="content">The longest running fine tuning job took about 8 hours, so ~$5.<p>I think if you add up all of the learning and testing I did, probably closer to ~$50 total</div><br/></div></div></div></div><div id="38539827" class="c"><input type="checkbox" id="c-38539827" checked=""/><div class="controls bullet"><span class="by">mtnGoat</span><span>|</span><a href="#38537316">prev</a><span>|</span><a href="#38535813">next</a><span>|</span><label class="collapse" for="c-38539827">[-]</label><label class="expand" for="c-38539827">[2 more]</label></div><br/><div class="children"><div class="content">I think Yahoo fantasy sports and others in the space are doing amazing work on this idea. I wonder if an LLM is even necessary for this, it’s mostly maths. Analyze past winning decks and made decisions based on performance.</div><br/><div id="38540644" class="c"><input type="checkbox" id="c-38540644" checked=""/><div class="controls bullet"><span class="by">FanaHOVA</span><span>|</span><a href="#38539827">parent</a><span>|</span><a href="#38535813">next</a><span>|</span><label class="collapse" for="c-38540644">[-]</label><label class="expand" for="c-38540644">[1 more]</label></div><br/><div class="children"><div class="content">17Lands data would definitely help, but humans don&#x27;t have that data in their head when sitting at a draft table.</div><br/></div></div></div></div><div id="38535813" class="c"><input type="checkbox" id="c-38535813" checked=""/><div class="controls bullet"><span class="by">iEchoic</span><span>|</span><a href="#38539827">prev</a><span>|</span><a href="#38537565">next</a><span>|</span><label class="collapse" for="c-38535813">[-]</label><label class="expand" for="c-38535813">[1 more]</label></div><br/><div class="children"><div class="content">Really interesting, thanks for writing this up. I&#x27;d love to see this applied to actually playing the game, provided that you could fit a (long) game state in the context window.</div><br/></div></div><div id="38537565" class="c"><input type="checkbox" id="c-38537565" checked=""/><div class="controls bullet"><span class="by">sva_</span><span>|</span><a href="#38535813">prev</a><span>|</span><a href="#38535114">next</a><span>|</span><label class="collapse" for="c-38537565">[-]</label><label class="expand" for="c-38537565">[1 more]</label></div><br/><div class="children"><div class="content">Hmm, is &quot;Generally Intelligent&quot; related to the company that previously had that name, but renamed itself to &quot;Imbue&quot;? Sort of confused.<p><a href="https:&#x2F;&#x2F;www.ycombinator.com&#x2F;companies&#x2F;imbue">https:&#x2F;&#x2F;www.ycombinator.com&#x2F;companies&#x2F;imbue</a></div><br/></div></div><div id="38535114" class="c"><input type="checkbox" id="c-38535114" checked=""/><div class="controls bullet"><span class="by">freediver</span><span>|</span><a href="#38537565">prev</a><span>|</span><a href="#38534778">next</a><span>|</span><label class="collapse" for="c-38535114">[-]</label><label class="expand" for="c-38535114">[4 more]</label></div><br/><div class="children"><div class="content">Super interesting work. Do you have thoughts how to leverage this to create a deck builder AI that would also simulate games? The major problem here is that the search space for MTG is amazingly vast.<p>I&#x27;ve seen this effort previously, pretty exciting stuff:<p><a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=Xq4T44EvPvo" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=Xq4T44EvPvo</a></div><br/><div id="38538390" class="c"><input type="checkbox" id="c-38538390" checked=""/><div class="controls bullet"><span class="by">algo_trader</span><span>|</span><a href="#38535114">parent</a><span>|</span><a href="#38535333">next</a><span>|</span><label class="collapse" for="c-38538390">[-]</label><label class="expand" for="c-38538390">[2 more]</label></div><br/><div class="children"><div class="content">&gt; <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=Xq4T44EvPvo" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=Xq4T44EvPvo</a><p>Why would he need to write a game simulator from scratch?<p>Surely there are OSS versions which are &quot;good enough&quot; ?<p>(disclosure: not a MtG expert)</div><br/><div id="38539620" class="c"><input type="checkbox" id="c-38539620" checked=""/><div class="controls bullet"><span class="by">gdown</span><span>|</span><a href="#38535114">root</a><span>|</span><a href="#38538390">parent</a><span>|</span><a href="#38535333">next</a><span>|</span><label class="collapse" for="c-38539620">[-]</label><label class="expand" for="c-38539620">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, that surprised me too, given that <a href="https:&#x2F;&#x2F;github.com&#x2F;magefree&#x2F;mage">https:&#x2F;&#x2F;github.com&#x2F;magefree&#x2F;mage</a> is open source and pretty actively developed.
But watching the rest of the video it looks like his implementation only needed to support &lt;20 different cards that he picked, so the limited rule set he needed might have been easy enough to write.</div><br/></div></div></div></div><div id="38535333" class="c"><input type="checkbox" id="c-38535333" checked=""/><div class="controls bullet"><span class="by">dmakian</span><span>|</span><a href="#38535114">parent</a><span>|</span><a href="#38538390">prev</a><span>|</span><a href="#38534778">next</a><span>|</span><label class="collapse" for="c-38535333">[-]</label><label class="expand" for="c-38535333">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve definitely thought about this problem and think it&#x27;s in the range of &#x27;feasible&#x27;, but it would be pretty slow and expensive given how much context you need to provide a model for it to be able to reason about the game state. Worth trying though!</div><br/></div></div></div></div><div id="38534778" class="c"><input type="checkbox" id="c-38534778" checked=""/><div class="controls bullet"><span class="by">rkwz</span><span>|</span><a href="#38535114">prev</a><span>|</span><a href="#38538309">next</a><span>|</span><label class="collapse" for="c-38534778">[-]</label><label class="expand" for="c-38534778">[7 more]</label></div><br/><div class="children"><div class="content">&gt; I was particularly interested in testing models’ ability to reason (i.e., perform a somewhat complex task that requires high context understanding) about out-of-distribution (i.e., unseen) data.<p>I was under the assumption that finetuneing LLMs was useful only when you need to change the model&#x27;s tone (speak like a pirate, voldemort etc).<p>Are there other examples where LLMs were trained to reason a particular way?</div><br/><div id="38535026" class="c"><input type="checkbox" id="c-38535026" checked=""/><div class="controls bullet"><span class="by">selfhoster11</span><span>|</span><a href="#38534778">parent</a><span>|</span><a href="#38534850">next</a><span>|</span><label class="collapse" for="c-38535026">[-]</label><label class="expand" for="c-38535026">[1 more]</label></div><br/><div class="children"><div class="content">Check our Orca. IIRC, it&#x27;s a technique that aims to encode additional logical capabilities into smaller models by having larger models generate step-by-step solutions to various problems. This doesn&#x27;t just make them speak more like GPT-4&#x2F;3.5, but is supposedly making them think more like it as well.</div><br/></div></div><div id="38534850" class="c"><input type="checkbox" id="c-38534850" checked=""/><div class="controls bullet"><span class="by">minimaxir</span><span>|</span><a href="#38534778">parent</a><span>|</span><a href="#38535026">prev</a><span>|</span><a href="#38535030">next</a><span>|</span><label class="collapse" for="c-38534850">[-]</label><label class="expand" for="c-38534850">[1 more]</label></div><br/><div class="children"><div class="content">You can get a standard LLM to change tone just by giving it a system prompt&#x2F;instruction to follow a certain tone.<p>The only issue there is that sometimes the RLHF seeps through, which can be solved by system prompting even harder.</div><br/></div></div><div id="38535030" class="c"><input type="checkbox" id="c-38535030" checked=""/><div class="controls bullet"><span class="by">dmakian</span><span>|</span><a href="#38534778">parent</a><span>|</span><a href="#38534850">prev</a><span>|</span><a href="#38535049">next</a><span>|</span><label class="collapse" for="c-38535030">[-]</label><label class="expand" for="c-38535030">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I was under the assumption that finetuneing LLMs was useful only when you need to change the model&#x27;s tone (speak like a pirate, voldemort etc).<p>A lot of why I tried this out was to test the limits of this belief, you see a lot of talk like this out there and it sounded like nonsense to me.<p>Finetuning is fundamentally not much different than continued pretraining; if you feed the model high-quality and high-volume data I think it&#x27;s reasonable to expect it to acquire new skills</div><br/></div></div><div id="38535049" class="c"><input type="checkbox" id="c-38535049" checked=""/><div class="controls bullet"><span class="by">oceanplexian</span><span>|</span><a href="#38534778">parent</a><span>|</span><a href="#38535030">prev</a><span>|</span><a href="#38535161">next</a><span>|</span><label class="collapse" for="c-38535049">[-]</label><label class="expand" for="c-38535049">[1 more]</label></div><br/><div class="children"><div class="content">In order to speak like a pirate, it has to be able to reason :) I&#x27;ve done some fine tunes as well similar to the MTG example, in mine I was fine tuning it to speak JSON and reason about some input- and yes, you can indeed get these models to perform on novel tasks.</div><br/></div></div><div id="38535161" class="c"><input type="checkbox" id="c-38535161" checked=""/><div class="controls bullet"><span class="by">samus</span><span>|</span><a href="#38534778">parent</a><span>|</span><a href="#38535049">prev</a><span>|</span><a href="#38534927">next</a><span>|</span><label class="collapse" for="c-38535161">[-]</label><label class="expand" for="c-38535161">[1 more]</label></div><br/><div class="children"><div class="content">Finetuning is a useful workaround for cases when the context size is unsuitable for the task at hand. Anybody knows whether it was ever considered to finetune an LLM   on the Linux kernel sources&#x27; history and its associated mailing lists?</div><br/></div></div><div id="38534927" class="c"><input type="checkbox" id="c-38534927" checked=""/><div class="controls bullet"><span class="by">skerit</span><span>|</span><a href="#38534778">parent</a><span>|</span><a href="#38535161">prev</a><span>|</span><a href="#38538309">next</a><span>|</span><label class="collapse" for="c-38534927">[-]</label><label class="expand" for="c-38534927">[1 more]</label></div><br/><div class="children"><div class="content">Aren&#x27;t a lot of base models fine-tuned with (Q)Lora on instruct-based datasets with good results? I thought this was a very common practice?</div><br/></div></div></div></div><div id="38538309" class="c"><input type="checkbox" id="c-38538309" checked=""/><div class="controls bullet"><span class="by">g2e</span><span>|</span><a href="#38534778">prev</a><span>|</span><a href="#38537918">next</a><span>|</span><label class="collapse" for="c-38538309">[-]</label><label class="expand" for="c-38538309">[1 more]</label></div><br/><div class="children"><div class="content">Any good pointers on the specifics on how one would do this themselves with axolot? Did you find that the documentation was adequate?</div><br/></div></div><div id="38537918" class="c"><input type="checkbox" id="c-38537918" checked=""/><div class="controls bullet"><span class="by">lubutu</span><span>|</span><a href="#38538309">prev</a><span>|</span><a href="#38536254">next</a><span>|</span><label class="collapse" for="c-38537918">[-]</label><label class="expand" for="c-38537918">[1 more]</label></div><br/><div class="children"><div class="content">Lurrus into Dead Weight — that&#x27;s a nice start.</div><br/></div></div><div id="38536254" class="c"><input type="checkbox" id="c-38536254" checked=""/><div class="controls bullet"><span class="by">tayo42</span><span>|</span><a href="#38537918">prev</a><span>|</span><a href="#38534826">next</a><span>|</span><label class="collapse" for="c-38536254">[-]</label><label class="expand" for="c-38536254">[6 more]</label></div><br/><div class="children"><div class="content">I wonder if you could use a smaller model or get better results if you treated each card as a token, gave the state of the draft as an input and the predicted token would be the card to pick. You woukd have to train from scratch with a custom tokenizer.</div><br/><div id="38538231" class="c"><input type="checkbox" id="c-38538231" checked=""/><div class="controls bullet"><span class="by">cjf101</span><span>|</span><a href="#38536254">parent</a><span>|</span><a href="#38536534">next</a><span>|</span><label class="collapse" for="c-38538231">[-]</label><label class="expand" for="c-38538231">[1 more]</label></div><br/><div class="children"><div class="content">I was thinking something fairly similar.  You could probably do pretty well with a basic NN setup this way, no need for an LLM.  It wouldn&#x27;t work on &quot;never seen before cards&quot; and would probably make some absurd picks when it&#x27;s wrong, but I&#x27;d bet you could get to 90% accuracy.</div><br/></div></div><div id="38536534" class="c"><input type="checkbox" id="c-38536534" checked=""/><div class="controls bullet"><span class="by">float-trip</span><span>|</span><a href="#38536254">parent</a><span>|</span><a href="#38538231">prev</a><span>|</span><a href="#38534826">next</a><span>|</span><label class="collapse" for="c-38536534">[-]</label><label class="expand" for="c-38536534">[4 more]</label></div><br/><div class="children"><div class="content">I tried adding special tokens for a reddit-style dataset once. The format was: `&lt;|post_author|&gt;username&lt;|post_title|&gt;title here...`<p>The resulting model was so much worse than just formatting everything plaintext. This was with MPT-30B, 15 special tokens, 300M training tokens, and a full finetune.<p>I may have made a mistake, but I haven&#x27;t seen any open source finetunes successfully add a large number of tokens yet either.</div><br/><div id="38537293" class="c"><input type="checkbox" id="c-38537293" checked=""/><div class="controls bullet"><span class="by">Tostino</span><span>|</span><a href="#38536254">root</a><span>|</span><a href="#38536534">parent</a><span>|</span><a href="#38537433">next</a><span>|</span><label class="collapse" for="c-38537293">[-]</label><label class="expand" for="c-38537293">[2 more]</label></div><br/><div class="children"><div class="content">Try doing the same thing in your dataset, but don&#x27;t actually add them as &quot;special tokens&quot;, and just let them just be multiple tokens.<p>Adding new tokens needs a ton of data to train what the token means. Reusing existing tokens, will allow you to easily teach that a sequence of tokens now has a new meaning after fine tuning.</div><br/><div id="38537540" class="c"><input type="checkbox" id="c-38537540" checked=""/><div class="controls bullet"><span class="by">float-trip</span><span>|</span><a href="#38536254">root</a><span>|</span><a href="#38537293">parent</a><span>|</span><a href="#38537433">next</a><span>|</span><label class="collapse" for="c-38537540">[-]</label><label class="expand" for="c-38537540">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s what I ended up doing (`[Author] username [Title] post title...`)<p>&gt; Adding new tokens needs a ton of data to train what the token means.<p>But how much? 300M tokens is fine for a simple version of ChatML with ~4 tokens. Not for 15, at least in my case. How&#x27;s this relationship scale?<p>Just trying to offer one datapoint for what doesn&#x27;t work, with the hedge that I might have just had a bug</div><br/></div></div></div></div><div id="38537433" class="c"><input type="checkbox" id="c-38537433" checked=""/><div class="controls bullet"><span class="by">tayo42</span><span>|</span><a href="#38536254">root</a><span>|</span><a href="#38536534">parent</a><span>|</span><a href="#38537293">prev</a><span>|</span><a href="#38534826">next</a><span>|</span><label class="collapse" for="c-38537433">[-]</label><label class="expand" for="c-38537433">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t mean add special tokens, but make the vocab only the set of possible cards. each card is a token.<p>a simple input might be &lt;cards you hold&gt; 1 14 56&lt;&#x2F;end&gt;&lt;cards to pick&gt; 5 64 2&lt;&#x2F;end&gt; -&gt; predicted token is the draft pick.<p>Then train a transformer based network from scratch.</div><br/></div></div></div></div></div></div><div id="38534826" class="c"><input type="checkbox" id="c-38534826" checked=""/><div class="controls bullet"><span class="by">dacox</span><span>|</span><a href="#38536254">prev</a><span>|</span><a href="#38535205">next</a><span>|</span><label class="collapse" for="c-38534826">[-]</label><label class="expand" for="c-38534826">[2 more]</label></div><br/><div class="children"><div class="content">Wow, I have exactly the same side project in progress, minus the fine tuning part. We even chose the same names and phrasing for parts of the project.</div><br/><div id="38534892" class="c"><input type="checkbox" id="c-38534892" checked=""/><div class="controls bullet"><span class="by">dmakian</span><span>|</span><a href="#38534826">parent</a><span>|</span><a href="#38535205">next</a><span>|</span><label class="collapse" for="c-38534892">[-]</label><label class="expand" for="c-38534892">[1 more]</label></div><br/><div class="children"><div class="content">Would love to compare notes, drop me a email at dshersh at umich dot edu if you&#x27;d be interested!</div><br/></div></div></div></div><div id="38535205" class="c"><input type="checkbox" id="c-38535205" checked=""/><div class="controls bullet"><span class="by">matsemann</span><span>|</span><a href="#38534826">prev</a><span>|</span><a href="#38535183">next</a><span>|</span><label class="collapse" for="c-38535205">[-]</label><label class="expand" for="c-38535205">[3 more]</label></div><br/><div class="children"><div class="content">How is the fine tuning actually performed? They have the data of drafts, and a prompt. But what does one do with it, more concretely?</div><br/><div id="38535293" class="c"><input type="checkbox" id="c-38535293" checked=""/><div class="controls bullet"><span class="by">dmakian</span><span>|</span><a href="#38535205">parent</a><span>|</span><a href="#38535183">next</a><span>|</span><label class="collapse" for="c-38535293">[-]</label><label class="expand" for="c-38535293">[2 more]</label></div><br/><div class="children"><div class="content">High level it&#x27;s basically:
1. Generate a lot of text examples that look like this: <a href="https:&#x2F;&#x2F;gist.githubusercontent.com&#x2F;davidhershey&#x2F;f57d0b19563fef86b117751dcbe6de20&#x2F;raw&#x2F;7bba77a61f6b698563157efe2a772954456cfe5e&#x2F;full_draft_prompt_chatml.txt" rel="nofollow noreferrer">https:&#x2F;&#x2F;gist.githubusercontent.com&#x2F;davidhershey&#x2F;f57d0b19563f...</a><p>2. The model is effectively trained to predict the next token based on the previous tokens in each of these examples, which has the side effect here of teaching it to make a draft pick based on the contents of a pack.<p>Nothing too fancy, just next word prediction more or less</div><br/><div id="38540588" class="c"><input type="checkbox" id="c-38540588" checked=""/><div class="controls bullet"><span class="by">sdenton4</span><span>|</span><a href="#38535205">root</a><span>|</span><a href="#38535293">parent</a><span>|</span><a href="#38535183">next</a><span>|</span><label class="collapse" for="c-38540588">[-]</label><label class="expand" for="c-38540588">[1 more]</label></div><br/><div class="children"><div class="content">Curious how different the performance would be if instead of a &#x27;Hall of Famer&#x27; we tell the bot that it is decently-good, but will be deactivated if it can&#x27;t achieve human-level performance...</div><br/></div></div></div></div></div></div><div id="38535183" class="c"><input type="checkbox" id="c-38535183" checked=""/><div class="controls bullet"><span class="by">imjonse</span><span>|</span><a href="#38535205">prev</a><span>|</span><a href="#38535642">next</a><span>|</span><label class="collapse" for="c-38535183">[-]</label><label class="expand" for="c-38535183">[1 more]</label></div><br/><div class="children"><div class="content">Confusing name for the domain (Generally Intelligent) since it&#x27;s the former name  of a company in the AI&#x2F;LLM area but does not seem to be related.</div><br/></div></div><div id="38535642" class="c"><input type="checkbox" id="c-38535642" checked=""/><div class="controls bullet"><span class="by">gigel82</span><span>|</span><a href="#38535183">prev</a><span>|</span><a href="#38534839">next</a><span>|</span><label class="collapse" for="c-38535642">[-]</label><label class="expand" for="c-38535642">[5 more]</label></div><br/><div class="children"><div class="content">For some reason I thought fine tuning is not possible without specialized hardware (A100 &#x2F; H100). Where can I learn more about hardware requirements for fine tuning on consumer GPUs?</div><br/><div id="38535681" class="c"><input type="checkbox" id="c-38535681" checked=""/><div class="controls bullet"><span class="by">dmakian</span><span>|</span><a href="#38535642">parent</a><span>|</span><a href="#38536316">next</a><span>|</span><label class="collapse" for="c-38535681">[-]</label><label class="expand" for="c-38535681">[1 more]</label></div><br/><div class="children"><div class="content">There is not a lot of great content out there making this clear, but basically all that matters for basic fine tuning is how much VRAM you have -- since the 3090 &#x2F; 4090 have 24GB VRAM they&#x27;re both pretty decent fine tuning chips. I think you could probably fine-tune a model up to ~13B parameters on one of them with PEFT (<a href="https:&#x2F;&#x2F;github.com&#x2F;huggingface&#x2F;peft">https:&#x2F;&#x2F;github.com&#x2F;huggingface&#x2F;peft</a>)</div><br/></div></div><div id="38536316" class="c"><input type="checkbox" id="c-38536316" checked=""/><div class="controls bullet"><span class="by">mmcwilliams</span><span>|</span><a href="#38535642">parent</a><span>|</span><a href="#38535681">prev</a><span>|</span><a href="#38534839">next</a><span>|</span><label class="collapse" for="c-38536316">[-]</label><label class="expand" for="c-38536316">[3 more]</label></div><br/><div class="children"><div class="content">Definitely possible on even older off-the-shelf hardware. I use 24GB 4090s for 13b-sized models and have even used 12GB Titans for 7b models, admittedly at much slower rates.</div><br/><div id="38536935" class="c"><input type="checkbox" id="c-38536935" checked=""/><div class="controls bullet"><span class="by">viraptor</span><span>|</span><a href="#38535642">root</a><span>|</span><a href="#38536316">parent</a><span>|</span><a href="#38537347">next</a><span>|</span><label class="collapse" for="c-38536935">[-]</label><label class="expand" for="c-38536935">[1 more]</label></div><br/><div class="children"><div class="content">You can also use Apple silicon for this: <a href="https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;LocalLLaMA&#x2F;comments&#x2F;15y9m64&#x2F;fine_tuningggml_quantiziation_on_apple_silicon&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;LocalLLaMA&#x2F;comments&#x2F;15y9m64&#x2F;fine_tu...</a></div><br/></div></div><div id="38537347" class="c"><input type="checkbox" id="c-38537347" checked=""/><div class="controls bullet"><span class="by">gigel82</span><span>|</span><a href="#38535642">root</a><span>|</span><a href="#38536316">parent</a><span>|</span><a href="#38536935">prev</a><span>|</span><a href="#38534839">next</a><span>|</span><label class="collapse" for="c-38537347">[-]</label><label class="expand" for="c-38537347">[1 more]</label></div><br/><div class="children"><div class="content">I have a 3080Ti with 12Gb VRAM and would like to try fine tuning the same Mistral 7B model (which I found incredibly potent). Any tips on how to get started?</div><br/></div></div></div></div></div></div><div id="38534839" class="c"><input type="checkbox" id="c-38534839" checked=""/><div class="controls bullet"><span class="by">throwaway743</span><span>|</span><a href="#38535642">prev</a><span>|</span><label class="collapse" for="c-38534839">[-]</label><label class="expand" for="c-38534839">[1 more]</label></div><br/><div class="children"><div class="content">Would like to know, how many matches were won per draft token? If it&#x27;s less than 2, I&#x27;ll stick to my shitty hand picks :&#x2F;</div><br/></div></div></div></div></div></div></div></body></html>