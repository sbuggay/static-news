<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1721638876449" as="style"/><link rel="stylesheet" href="styles.css?v=1721638876449"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://pypy.org/posts/2024/07/mining-jit-traces-missing-optimizations-z3.html">Mining JIT traces for missing optimizations with Z3</a> <span class="domain">(<a href="https://pypy.org">pypy.org</a>)</span></div><div class="subtext"><span>matt_d</span> | <span>39 comments</span></div><br/><div><div id="41025924" class="c"><input type="checkbox" id="c-41025924" checked=""/><div class="controls bullet"><span class="by">adsharma</span><span>|</span><a href="#41029503">next</a><span>|</span><label class="collapse" for="c-41025924">[-]</label><label class="expand" for="c-41025924">[3 more]</label></div><br/><div class="children"><div class="content">Why not do this at a higher level on the python source itself?<p>I ask because z3 has been used for type inference (Typpete) and for solving equations written in Python.</div><br/><div id="41026314" class="c"><input type="checkbox" id="c-41026314" checked=""/><div class="controls bullet"><span class="by">ainoobler</span><span>|</span><a href="#41025924">parent</a><span>|</span><a href="#41028922">next</a><span>|</span><label class="collapse" for="c-41026314">[-]</label><label class="expand" for="c-41026314">[1 more]</label></div><br/><div class="children"><div class="content">There is more runtime information in the traces and more opportunities for optimization.</div><br/></div></div></div></div><div id="41029503" class="c"><input type="checkbox" id="c-41029503" checked=""/><div class="controls bullet"><span class="by">gus_massa</span><span>|</span><a href="#41025924">prev</a><span>|</span><a href="#41027795">next</a><span>|</span><label class="collapse" for="c-41029503">[-]</label><label class="expand" for="c-41029503">[2 more]</label></div><br/><div class="children"><div class="content">From the article:<p>&gt; <i>(x &amp; c1) | (x &amp; c1) ==
  x &amp; (c1 | c2)</i><p>Is this a typo? Shoud the second <i>c1</i> be <i>c2</i> instead?</div><br/><div id="41030228" class="c"><input type="checkbox" id="c-41030228" checked=""/><div class="controls bullet"><span class="by">lock_enthusiast</span><span>|</span><a href="#41029503">parent</a><span>|</span><a href="#41027795">next</a><span>|</span><label class="collapse" for="c-41030228">[-]</label><label class="expand" for="c-41030228">[1 more]</label></div><br/><div class="children"><div class="content">I think it&#x27;s a typo, and it should be (x &amp; c1) | (x &amp; c2).</div><br/></div></div></div></div><div id="41027795" class="c"><input type="checkbox" id="c-41027795" checked=""/><div class="controls bullet"><span class="by">puzzledobserver</span><span>|</span><a href="#41029503">prev</a><span>|</span><a href="#41026257">next</a><span>|</span><label class="collapse" for="c-41027795">[-]</label><label class="expand" for="c-41027795">[4 more]</label></div><br/><div class="children"><div class="content">How does the PyPy JIT compare to the JIT in the upcoming CPython 3.13?</div><br/><div id="41028892" class="c"><input type="checkbox" id="c-41028892" checked=""/><div class="controls bullet"><span class="by">i80and</span><span>|</span><a href="#41027795">parent</a><span>|</span><a href="#41026257">next</a><span>|</span><label class="collapse" for="c-41028892">[-]</label><label class="expand" for="c-41028892">[3 more]</label></div><br/><div class="children"><div class="content">Very different technologies. The PyPy JIT is a tracing JIT where hot paths of execution are identified, then that specific path is compiled and optimized. Same as LuaJIT.<p>The CPython JIT is a newer and less invasive technique called copy-and-patch[1]. It&#x27;s a lot less powerful, but a lot easier to plug into an existing language implementation: known sequences of python bytecode are mapped to templates of machine code<p>[1] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Copy-and-patch" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Copy-and-patch</a></div><br/><div id="41029783" class="c"><input type="checkbox" id="c-41029783" checked=""/><div class="controls bullet"><span class="by">AlotOfReading</span><span>|</span><a href="#41027795">root</a><span>|</span><a href="#41028892">parent</a><span>|</span><a href="#41026257">next</a><span>|</span><label class="collapse" for="c-41029783">[-]</label><label class="expand" for="c-41029783">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m a bit surprised that copy-and-patch is &quot;new&quot;. I remember writing a JIT framework that did something similar back in the aughts and I got the idea from reading docs that were already old then.<p>I understand people at IBM  were doing it industrially for Java bytecode in the late 90s under the name quasi-static compilation, and the DyC&#x2F;Tempo folks were doing similar things over in C land under different names. There were some minor differences due to the technology of the day, but it was broadly similar. For example, explicitly building to IR was uncommon outside Java land and register scheduling didn&#x27;t have a lot of choices to make. The Java stuff even allowed the template specializations to exist on other computers and be dynamically loaded and validated over the network, for thin-client reasons. Very cool for the early 2000s.</div><br/><div id="41030905" class="c"><input type="checkbox" id="c-41030905" checked=""/><div class="controls bullet"><span class="by">chc4</span><span>|</span><a href="#41027795">root</a><span>|</span><a href="#41029783">parent</a><span>|</span><a href="#41026257">next</a><span>|</span><label class="collapse" for="c-41030905">[-]</label><label class="expand" for="c-41030905">[1 more]</label></div><br/><div class="children"><div class="content">Template JITs aren&#x27;t new. Copy and patch is a specific scheme for automatically creating a template JIT by using relocations in order to generate templates from normal C++ code. That wikipedia page is just very bad.</div><br/></div></div></div></div></div></div></div></div><div id="41026257" class="c"><input type="checkbox" id="c-41026257" checked=""/><div class="controls bullet"><span class="by">aantix</span><span>|</span><a href="#41027795">prev</a><span>|</span><label class="collapse" for="c-41026257">[-]</label><label class="expand" for="c-41026257">[29 more]</label></div><br/><div class="children"><div class="content">Compile enough traces with the accompanying optimizations and you have solid training data for an LLM that can suggest optimizations based on JIT traces.</div><br/><div id="41026750" class="c"><input type="checkbox" id="c-41026750" checked=""/><div class="controls bullet"><span class="by">cfbolztereick</span><span>|</span><a href="#41026257">parent</a><span>|</span><a href="#41029470">next</a><span>|</span><label class="collapse" for="c-41026750">[-]</label><label class="expand" for="c-41026750">[3 more]</label></div><br/><div class="children"><div class="content">All the minimized inefficiencies that are found by my script are already optimizations. They just happen to be rather specific patterns, so they need to be suitably generalized. There&#x27;s another Regehr etal paper about how to do that automatically:
<a href="https:&#x2F;&#x2F;dl.acm.org&#x2F;doi&#x2F;10.1145&#x2F;3649837" rel="nofollow">https:&#x2F;&#x2F;dl.acm.org&#x2F;doi&#x2F;10.1145&#x2F;3649837</a><p>(llm&#x27;s aren&#x27;t involved, it&#x27;s all based on z3)<p>I don&#x27;t plan on implementing something like this for now, I&#x27;d rather take the inefficiencies and manually extract optimizations out of them and implement them in PyPy&#x27;s jit.</div><br/><div id="41027331" class="c"><input type="checkbox" id="c-41027331" checked=""/><div class="controls bullet"><span class="by">algo_trader</span><span>|</span><a href="#41026257">root</a><span>|</span><a href="#41026750">parent</a><span>|</span><a href="#41029470">next</a><span>|</span><label class="collapse" for="c-41027331">[-]</label><label class="expand" for="c-41027331">[2 more]</label></div><br/><div class="children"><div class="content">You are not wrong<p>AlphaZero-type systems were unable to significantly improve over near-optimal solvers such as z3.</div><br/><div id="41027696" class="c"><input type="checkbox" id="c-41027696" checked=""/><div class="controls bullet"><span class="by">Zacharias030</span><span>|</span><a href="#41026257">root</a><span>|</span><a href="#41027331">parent</a><span>|</span><a href="#41029470">next</a><span>|</span><label class="collapse" for="c-41027696">[-]</label><label class="expand" for="c-41027696">[1 more]</label></div><br/><div class="children"><div class="content">Could you point me to some references to learn about his?</div><br/></div></div></div></div></div></div><div id="41029470" class="c"><input type="checkbox" id="c-41029470" checked=""/><div class="controls bullet"><span class="by">bastawhiz</span><span>|</span><a href="#41026257">parent</a><span>|</span><a href="#41026750">prev</a><span>|</span><a href="#41026317">next</a><span>|</span><label class="collapse" for="c-41029470">[-]</label><label class="expand" for="c-41029470">[1 more]</label></div><br/><div class="children"><div class="content">If you already know what the optimizations are, you don&#x27;t need AI to optimize them. Just write optimizations in the compiler. That&#x27;s literally one of the biggest jobs of the compiler already.</div><br/></div></div><div id="41026317" class="c"><input type="checkbox" id="c-41026317" checked=""/><div class="controls bullet"><span class="by">ainoobler</span><span>|</span><a href="#41026257">parent</a><span>|</span><a href="#41029470">prev</a><span>|</span><label class="collapse" for="c-41026317">[-]</label><label class="expand" for="c-41026317">[24 more]</label></div><br/><div class="children"><div class="content">How would you verify semantic correctness of the optimizations?</div><br/><div id="41026345" class="c"><input type="checkbox" id="c-41026345" checked=""/><div class="controls bullet"><span class="by">aantix</span><span>|</span><a href="#41026257">root</a><span>|</span><a href="#41026317">parent</a><span>|</span><label class="collapse" for="c-41026345">[-]</label><label class="expand" for="c-41026345">[23 more]</label></div><br/><div class="children"><div class="content">I think I envisioned traces being extracted from a series of open source projects and their automated test suites.<p>Run the test suite, identify optimizations. One by one, make the the optimization change to the implementation as suggested by the LLM.<p>Instrument the changed methods on the second test run and see if runtime performance has changed. Verify that the test still passes.</div><br/><div id="41026369" class="c"><input type="checkbox" id="c-41026369" checked=""/><div class="controls bullet"><span class="by">ainoobler</span><span>|</span><a href="#41026257">root</a><span>|</span><a href="#41026345">parent</a><span>|</span><label class="collapse" for="c-41026369">[-]</label><label class="expand" for="c-41026369">[22 more]</label></div><br/><div class="children"><div class="content">I meant how do you make sure the optimization suggested by the AI is actually valid. If you&#x27;re using AI to modify bytecode for faster execution then you have to make sure the optimized and unoptimized code are semantically equivalent. Neural networks can&#x27;t do logic so how would you know the suggestions were not bogus?</div><br/><div id="41026455" class="c"><input type="checkbox" id="c-41026455" checked=""/><div class="controls bullet"><span class="by">weebull</span><span>|</span><a href="#41026257">root</a><span>|</span><a href="#41026369">parent</a><span>|</span><a href="#41026465">next</a><span>|</span><label class="collapse" for="c-41026455">[-]</label><label class="expand" for="c-41026455">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;ve asked the right question, and for those that think validation is as simpLe as &quot;run it and see if it gets the right result&quot;, good start but instruction ordering can be critical around multi thread aware data structures. Taking a fence out, or an atomic operation might give a big performance gain. Trouble is the structure may now go wrong 1% of the time.</div><br/></div></div><div id="41026465" class="c"><input type="checkbox" id="c-41026465" checked=""/><div class="controls bullet"><span class="by">aantix</span><span>|</span><a href="#41026257">root</a><span>|</span><a href="#41026369">parent</a><span>|</span><a href="#41026455">prev</a><span>|</span><a href="#41026913">next</a><span>|</span><label class="collapse" for="c-41026465">[-]</label><label class="expand" for="c-41026465">[18 more]</label></div><br/><div class="children"><div class="content">A valid accompanying test would ensure this?<p>You’d be extracting optimization candidates by running the test suite.<p>You re-run the test suite after changes to ensure they still pass.</div><br/><div id="41026505" class="c"><input type="checkbox" id="c-41026505" checked=""/><div class="controls bullet"><span class="by">ainoobler</span><span>|</span><a href="#41026257">root</a><span>|</span><a href="#41026465">parent</a><span>|</span><a href="#41026753">next</a><span>|</span><label class="collapse" for="c-41026505">[-]</label><label class="expand" for="c-41026505">[10 more]</label></div><br/><div class="children"><div class="content">JIT optimizers operate at runtime, there are no test suites to verify before&#x2F;after. It&#x27;s happening live as the code is running so if you use AI then you won&#x27;t know if the optimization is actually valid or not. This is why the article is using Z3 instead of neural networks. Z3 can validate semantic equivalence, neural networks can&#x27;t.</div><br/><div id="41026611" class="c"><input type="checkbox" id="c-41026611" checked=""/><div class="controls bullet"><span class="by">fwip</span><span>|</span><a href="#41026257">root</a><span>|</span><a href="#41026505">parent</a><span>|</span><a href="#41026753">next</a><span>|</span><label class="collapse" for="c-41026611">[-]</label><label class="expand" for="c-41026611">[9 more]</label></div><br/><div class="children"><div class="content">Yes, but this Z3 analysis is not done at runtime. It&#x27;s done offline, based on JIT traces. A neural network could, in principal, suggest optimizations in the same way, which an expert would then review for possible inclusion into the Pypy JIT.</div><br/><div id="41026652" class="c"><input type="checkbox" id="c-41026652" checked=""/><div class="controls bullet"><span class="by">ainoobler</span><span>|</span><a href="#41026257">root</a><span>|</span><a href="#41026611">parent</a><span>|</span><a href="#41026753">next</a><span>|</span><label class="collapse" for="c-41026652">[-]</label><label class="expand" for="c-41026652">[8 more]</label></div><br/><div class="children"><div class="content">You&#x27;d still have to write a proof for verifying semantic equivalence before implementing the optimization so I don&#x27;t see what the neural network gains you here unless it is actually supplying the proof of correctness along with the optimization.</div><br/><div id="41026946" class="c"><input type="checkbox" id="c-41026946" checked=""/><div class="controls bullet"><span class="by">screcth</span><span>|</span><a href="#41026257">root</a><span>|</span><a href="#41026652">parent</a><span>|</span><a href="#41027125">next</a><span>|</span><label class="collapse" for="c-41026946">[-]</label><label class="expand" for="c-41026946">[1 more]</label></div><br/><div class="children"><div class="content">The idea is that the LLM would provide &quot;intuition&quot; to guide the optimizer to find better optimizations, but a formal proof would be necessary to ensure that those optimizations are actually valid.</div><br/></div></div><div id="41027125" class="c"><input type="checkbox" id="c-41027125" checked=""/><div class="controls bullet"><span class="by">fwip</span><span>|</span><a href="#41026257">root</a><span>|</span><a href="#41026652">parent</a><span>|</span><a href="#41026946">prev</a><span>|</span><a href="#41026753">next</a><span>|</span><label class="collapse" for="c-41027125">[-]</label><label class="expand" for="c-41027125">[6 more]</label></div><br/><div class="children"><div class="content">I might be incorrect, but I don&#x27;t believe that most compiler optimizations have formal proofs written out before implementation. Does Pypy do this?</div><br/><div id="41027352" class="c"><input type="checkbox" id="c-41027352" checked=""/><div class="controls bullet"><span class="by">derdi</span><span>|</span><a href="#41026257">root</a><span>|</span><a href="#41027125">parent</a><span>|</span><a href="#41030892">next</a><span>|</span><label class="collapse" for="c-41027352">[-]</label><label class="expand" for="c-41027352">[4 more]</label></div><br/><div class="children"><div class="content">Pypy doesn&#x27;t do this in general. The same Z3 model that is used to find these missing optimizations is also used to verify some integer optimizations.<p>But the point is that as long as optimization rules are hand-written, a human has thought about them and convinced themselves (maybe incorrectly) that the rules are correct. If a machine generates them without a human in the loop, some other sort of correctness argument is needed. Hence the reasonable suggestion that they should be formally verified.</div><br/><div id="41028161" class="c"><input type="checkbox" id="c-41028161" checked=""/><div class="controls bullet"><span class="by">cfbolztereick</span><span>|</span><a href="#41026257">root</a><span>|</span><a href="#41027352">parent</a><span>|</span><a href="#41027725">next</a><span>|</span><label class="collapse" for="c-41028161">[-]</label><label class="expand" for="c-41028161">[1 more]</label></div><br/><div class="children"><div class="content">PyPy has formally verified the integer abstract domain using Z3, a quite important part of our jit optimizer (will write about that in the coming weeks).<p>We also run a fuzzer regularly to find optimization bugs, using Z3 as a correctness check:<p><a href="https:&#x2F;&#x2F;pypy.org&#x2F;posts&#x2F;2022&#x2F;12&#x2F;jit-bug-finding-smt-fuzzing.html" rel="nofollow">https:&#x2F;&#x2F;pypy.org&#x2F;posts&#x2F;2022&#x2F;12&#x2F;jit-bug-finding-smt-fuzzing.h...</a><p>The peephole optimizations aren&#x27;t themselves formally verified completely yet. We&#x27;ve verified the very simplest rules, and some of the newer complicated ones, but not systematically all of them. I plan to work on fully and automatically verifying all integer optimizations in the next year or so. But we&#x27;ll see, I&#x27;ll need to find students and&#x2F;or money.</div><br/></div></div><div id="41027725" class="c"><input type="checkbox" id="c-41027725" checked=""/><div class="controls bullet"><span class="by">fwip</span><span>|</span><a href="#41026257">root</a><span>|</span><a href="#41027352">parent</a><span>|</span><a href="#41028161">prev</a><span>|</span><a href="#41030892">next</a><span>|</span><label class="collapse" for="c-41027725">[-]</label><label class="expand" for="c-41027725">[2 more]</label></div><br/><div class="children"><div class="content">Ah, yes, I meant that the LLM could output suggestions, which a human would then think about and convince themselves, and only then, implement in Pypy.</div><br/><div id="41028703" class="c"><input type="checkbox" id="c-41028703" checked=""/><div class="controls bullet"><span class="by">derdi</span><span>|</span><a href="#41026257">root</a><span>|</span><a href="#41027725">parent</a><span>|</span><a href="#41030892">next</a><span>|</span><label class="collapse" for="c-41028703">[-]</label><label class="expand" for="c-41028703">[1 more]</label></div><br/><div class="children"><div class="content">Presumably the LLM would generate a lot of proposed rules for humans to wade through. Reviewing lots of proposed rewrites while catching all possible errors would be tedious and error-prone. We have computers to take care of this kind of work.</div><br/></div></div></div></div></div></div><div id="41030892" class="c"><input type="checkbox" id="c-41030892" checked=""/><div class="controls bullet"><span class="by">dkersten</span><span>|</span><a href="#41026257">root</a><span>|</span><a href="#41027125">parent</a><span>|</span><a href="#41027352">prev</a><span>|</span><a href="#41026753">next</a><span>|</span><label class="collapse" for="c-41030892">[-]</label><label class="expand" for="c-41030892">[1 more]</label></div><br/><div class="children"><div class="content">Perhaps not, but they’re based on heuristics and checks that are known, checked and understood by humans, and aren’t prone to hallucination like LLM’s are. An LLM suggests something that looks plausible, but there’s no guarantee that it’s suggestions actually work as intended, hence the need for a proof.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="41026753" class="c"><input type="checkbox" id="c-41026753" checked=""/><div class="controls bullet"><span class="by">SkiFire13</span><span>|</span><a href="#41026257">root</a><span>|</span><a href="#41026465">parent</a><span>|</span><a href="#41026505">prev</a><span>|</span><a href="#41026534">next</a><span>|</span><label class="collapse" for="c-41026753">[-]</label><label class="expand" for="c-41026753">[6 more]</label></div><br/><div class="children"><div class="content">Tests can&#x27;t ensure the correctness of an algorithm, only that it gives the correct output on a specific input.</div><br/><div id="41026927" class="c"><input type="checkbox" id="c-41026927" checked=""/><div class="controls bullet"><span class="by">aantix</span><span>|</span><a href="#41026257">root</a><span>|</span><a href="#41026753">parent</a><span>|</span><a href="#41026534">next</a><span>|</span><label class="collapse" for="c-41026927">[-]</label><label class="expand" for="c-41026927">[5 more]</label></div><br/><div class="children"><div class="content">Depends on the comprehensiveness of the test.</div><br/><div id="41030294" class="c"><input type="checkbox" id="c-41030294" checked=""/><div class="controls bullet"><span class="by">petschge</span><span>|</span><a href="#41026257">root</a><span>|</span><a href="#41026927">parent</a><span>|</span><a href="#41027114">next</a><span>|</span><label class="collapse" for="c-41030294">[-]</label><label class="expand" for="c-41030294">[1 more]</label></div><br/><div class="children"><div class="content">Sure, for booleans you can just test all combinations of input arguments. In some cases you can do the same for all possible 32 bit float or int values that you have as input. But for 64 bit integers (let alone several of them) that&#x27;s not feasible.</div><br/></div></div><div id="41027114" class="c"><input type="checkbox" id="c-41027114" checked=""/><div class="controls bullet"><span class="by">SkiFire13</span><span>|</span><a href="#41026257">root</a><span>|</span><a href="#41026927">parent</a><span>|</span><a href="#41030294">prev</a><span>|</span><a href="#41026534">next</a><span>|</span><label class="collapse" for="c-41027114">[-]</label><label class="expand" for="c-41027114">[3 more]</label></div><br/><div class="children"><div class="content">For any practical input no test is gonna be comprehensive enough. Especially for something that has infinite possible inputs like programs.</div><br/><div id="41028113" class="c"><input type="checkbox" id="c-41028113" checked=""/><div class="controls bullet"><span class="by">aantix</span><span>|</span><a href="#41026257">root</a><span>|</span><a href="#41027114">parent</a><span>|</span><a href="#41026534">next</a><span>|</span><label class="collapse" for="c-41028113">[-]</label><label class="expand" for="c-41028113">[2 more]</label></div><br/><div class="children"><div class="content">Is the scope a whole program or a specific algorithm?</div><br/><div id="41031554" class="c"><input type="checkbox" id="c-41031554" checked=""/><div class="controls bullet"><span class="by">SkiFire13</span><span>|</span><a href="#41026257">root</a><span>|</span><a href="#41028113">parent</a><span>|</span><a href="#41026534">next</a><span>|</span><label class="collapse" for="c-41031554">[-]</label><label class="expand" for="c-41031554">[1 more]</label></div><br/><div class="children"><div class="content">Even most algorithms would allow too many inputs. Even a simple algorithm computing the addition between two 64 bit numbers allow 2^128 possible input combinations, which would take billions of years to exhaustively check in the best case.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="41026534" class="c"><input type="checkbox" id="c-41026534" checked=""/><div class="controls bullet"><span class="by">lmeyerov</span><span>|</span><a href="#41026257">root</a><span>|</span><a href="#41026465">parent</a><span>|</span><a href="#41026753">prev</a><span>|</span><a href="#41026913">next</a><span>|</span><label class="collapse" for="c-41026534">[-]</label><label class="expand" for="c-41026534">[1 more]</label></div><br/><div class="children"><div class="content">Close!<p>Generate the z3 too - as the need is to verify, not test. It can be a direct translation. For all inputs, is the optimization output equivalent. (Bootstrapping a compiler prototype via LLMs is nice though.)<p>One place LLMs get fun here is where the direct translation to z3 times out, such as bigger or more complicated programs, and so the LLM can provide intuition for pushing the solver ahead.</div><br/></div></div></div></div><div id="41026913" class="c"><input type="checkbox" id="c-41026913" checked=""/><div class="controls bullet"><span class="by">wolf550e</span><span>|</span><a href="#41026257">root</a><span>|</span><a href="#41026369">parent</a><span>|</span><a href="#41026465">prev</a><span>|</span><a href="#41027397">next</a><span>|</span><label class="collapse" for="c-41026913">[-]</label><label class="expand" for="c-41026913">[1 more]</label></div><br/><div class="children"><div class="content">regehr et al use alive2 which uses z3</div><br/></div></div><div id="41027397" class="c"><input type="checkbox" id="c-41027397" checked=""/><div class="controls bullet"><span class="by">Twirrim</span><span>|</span><a href="#41026257">root</a><span>|</span><a href="#41026369">parent</a><span>|</span><a href="#41026913">prev</a><span>|</span><label class="collapse" for="c-41027397">[-]</label><label class="expand" for="c-41027397">[1 more]</label></div><br/><div class="children"><div class="content">But.. But.. But.... This is HN.  You must use AI &#x2F; LLMs for everything!   &#x2F;s</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></body></html>