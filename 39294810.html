<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1707382873907" as="style"/><link rel="stylesheet" href="styles.css?v=1707382873907"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://cloud.google.com/blog/products/application-development/new-localllm-lets-you-develop-gen-ai-apps-locally-without-gpus">Localllm lets you develop gen AI apps on local CPUs</a> <span class="domain">(<a href="https://cloud.google.com">cloud.google.com</a>)</span></div><div class="subtext"><span>srameshc</span> | <span>55 comments</span></div><br/><div><div id="39296567" class="c"><input type="checkbox" id="c-39296567" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#39294838">next</a><span>|</span><label class="collapse" for="c-39296567">[-]</label><label class="expand" for="c-39296567">[15 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not thrilled about <a href="https:&#x2F;&#x2F;github.com&#x2F;GoogleCloudPlatform&#x2F;localllm&#x2F;blob&#x2F;main&#x2F;llm-tool&#x2F;setup.py">https:&#x2F;&#x2F;github.com&#x2F;GoogleCloudPlatform&#x2F;localllm&#x2F;blob&#x2F;main&#x2F;ll...</a> calling their Python package &quot;llm&quot; and installing &quot;llm&quot; as a CLI command, when my similar <a href="https:&#x2F;&#x2F;llm.datasette.io&#x2F;" rel="nofollow">https:&#x2F;&#x2F;llm.datasette.io&#x2F;</a> project has that namespace reserved on PyPI already: <a href="https:&#x2F;&#x2F;pypi.org&#x2F;project&#x2F;llm&#x2F;" rel="nofollow">https:&#x2F;&#x2F;pypi.org&#x2F;project&#x2F;llm&#x2F;</a></div><br/><div id="39298169" class="c"><input type="checkbox" id="c-39298169" checked=""/><div class="controls bullet"><span class="by">behnamoh</span><span>|</span><a href="#39296567">parent</a><span>|</span><a href="#39296688">next</a><span>|</span><label class="collapse" for="c-39298169">[-]</label><label class="expand" for="c-39298169">[4 more]</label></div><br/><div class="children"><div class="content">I&#x27;m really pissed off at Google for doing this:<p>- First, they &quot;steal&quot; @simonw&#x27;s &#x27;llm&#x27; keyword for their own CLI tool (<a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=39296567">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=39296567</a>)<p>- Then they create a wrapper around llama-cpp-python which is a wrapper around llama-cpp, a project they don&#x27;t even credit nor support.<p>- Then they steal @mcapodici&#x27;s article title to publish it on their blog (<a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=39297563">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=39297563</a>).<p>- And the ironic part is that their Gemini models are closed-source, so no gguf for those.</div><br/><div id="39299773" class="c"><input type="checkbox" id="c-39299773" checked=""/><div class="controls bullet"><span class="by">3abiton</span><span>|</span><a href="#39296567">root</a><span>|</span><a href="#39298169">parent</a><span>|</span><a href="#39299363">next</a><span>|</span><label class="collapse" for="c-39299773">[-]</label><label class="expand" for="c-39299773">[1 more]</label></div><br/><div class="children"><div class="content">Google trying to ride the open source hype that  Meta is blessed by, except google is a mean girl who regrets opening up the transformer without taxing it, so they&#x27;re really sour about it and doing these tricks now to pretend to still support open-source.</div><br/></div></div><div id="39299363" class="c"><input type="checkbox" id="c-39299363" checked=""/><div class="controls bullet"><span class="by">vasco</span><span>|</span><a href="#39296567">root</a><span>|</span><a href="#39298169">parent</a><span>|</span><a href="#39299773">prev</a><span>|</span><a href="#39299020">next</a><span>|</span><label class="collapse" for="c-39299363">[-]</label><label class="expand" for="c-39299363">[1 more]</label></div><br/><div class="children"><div class="content">&quot;No GPU? No Problem.&quot; Isn&#x27;t exactly a complex phrase they&#x27;d have to steal, seems much more likely they came up with it independently.</div><br/></div></div><div id="39299020" class="c"><input type="checkbox" id="c-39299020" checked=""/><div class="controls bullet"><span class="by">pests</span><span>|</span><a href="#39296567">root</a><span>|</span><a href="#39298169">parent</a><span>|</span><a href="#39299363">prev</a><span>|</span><a href="#39296688">next</a><span>|</span><label class="collapse" for="c-39299020">[-]</label><label class="expand" for="c-39299020">[1 more]</label></div><br/><div class="children"><div class="content">May I ask why you linked to your parents comment as a source? Just seems.. odd</div><br/></div></div></div></div><div id="39296688" class="c"><input type="checkbox" id="c-39296688" checked=""/><div class="controls bullet"><span class="by">triyambakam</span><span>|</span><a href="#39296567">parent</a><span>|</span><a href="#39298169">prev</a><span>|</span><a href="#39298442">next</a><span>|</span><label class="collapse" for="c-39296688">[-]</label><label class="expand" for="c-39296688">[7 more]</label></div><br/><div class="children"><div class="content">I actually wish that no one took the llm namespace. It&#x27;s annoyingly vague.</div><br/><div id="39296735" class="c"><input type="checkbox" id="c-39296735" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#39296567">root</a><span>|</span><a href="#39296688">parent</a><span>|</span><a href="#39299633">next</a><span>|</span><label class="collapse" for="c-39296735">[-]</label><label class="expand" for="c-39296735">[3 more]</label></div><br/><div class="children"><div class="content">I think it&#x27;s a pretty great name for my tool, given that it lets you interact with dozens of different LLMs via plugins.<p>Plus I like that it&#x27;s three letters, since it&#x27;s designed for CLI usage.</div><br/><div id="39299729" class="c"><input type="checkbox" id="c-39299729" checked=""/><div class="controls bullet"><span class="by">thih9</span><span>|</span><a href="#39296567">root</a><span>|</span><a href="#39296735">parent</a><span>|</span><a href="#39299113">next</a><span>|</span><label class="collapse" for="c-39299729">[-]</label><label class="expand" for="c-39299729">[1 more]</label></div><br/><div class="children"><div class="content">Yes - at the same time it would similarly fit other tools where some form of working with LLMs is the main feature. And with time we might get more of these.<p>At least it’s not called “ai”, we have that already, e.g. <a href="https:&#x2F;&#x2F;github.com&#x2F;yufeikang&#x2F;ai-cli">https:&#x2F;&#x2F;github.com&#x2F;yufeikang&#x2F;ai-cli</a></div><br/></div></div><div id="39299113" class="c"><input type="checkbox" id="c-39299113" checked=""/><div class="controls bullet"><span class="by">triyambakam</span><span>|</span><a href="#39296567">root</a><span>|</span><a href="#39296735">parent</a><span>|</span><a href="#39299729">prev</a><span>|</span><a href="#39299633">next</a><span>|</span><label class="collapse" for="c-39299113">[-]</label><label class="expand" for="c-39299113">[1 more]</label></div><br/><div class="children"><div class="content">But your tool isn&#x27;t an llm. llmt for e.g. llm tool could be better</div><br/></div></div></div></div><div id="39299633" class="c"><input type="checkbox" id="c-39299633" checked=""/><div class="controls bullet"><span class="by">rollcat</span><span>|</span><a href="#39296567">root</a><span>|</span><a href="#39296688">parent</a><span>|</span><a href="#39296735">prev</a><span>|</span><a href="#39297569">next</a><span>|</span><label class="collapse" for="c-39299633">[-]</label><label class="expand" for="c-39299633">[1 more]</label></div><br/><div class="children"><div class="content">I like what Go does (I know, the irony). Buy a domain name, that&#x27;s your namespace.</div><br/></div></div><div id="39297569" class="c"><input type="checkbox" id="c-39297569" checked=""/><div class="controls bullet"><span class="by">arcanemachiner</span><span>|</span><a href="#39296567">root</a><span>|</span><a href="#39296688">parent</a><span>|</span><a href="#39299633">prev</a><span>|</span><a href="#39299567">next</a><span>|</span><label class="collapse" for="c-39297569">[-]</label><label class="expand" for="c-39297569">[1 more]</label></div><br/><div class="children"><div class="content">This is kinda how I feel about HTTPie taking using &#x27;http&#x27; in the CLI.</div><br/></div></div><div id="39299567" class="c"><input type="checkbox" id="c-39299567" checked=""/><div class="controls bullet"><span class="by">coding123</span><span>|</span><a href="#39296567">root</a><span>|</span><a href="#39296688">parent</a><span>|</span><a href="#39297569">prev</a><span>|</span><a href="#39298442">next</a><span>|</span><label class="collapse" for="c-39299567">[-]</label><label class="expand" for="c-39299567">[1 more]</label></div><br/><div class="children"><div class="content">Almost every package is vague if you&#x27;re just going off names of packages. Is &#x27;pandas&#x27; some kind of screensaver showcasing the cute animals?</div><br/></div></div></div></div><div id="39298442" class="c"><input type="checkbox" id="c-39298442" checked=""/><div class="controls bullet"><span class="by">nicolezhu</span><span>|</span><a href="#39296567">parent</a><span>|</span><a href="#39296688">prev</a><span>|</span><a href="#39296613">next</a><span>|</span><label class="collapse" for="c-39298442">[-]</label><label class="expand" for="c-39298442">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, this feels super reactive. Like someone pitched an idea for how to convert AI enthusiasts to paid google AI suite...<p>I want to know: are they contributing back to llamacpp? Are they paying GG?</div><br/></div></div><div id="39296613" class="c"><input type="checkbox" id="c-39296613" checked=""/><div class="controls bullet"><span class="by">rmorey</span><span>|</span><a href="#39296567">parent</a><span>|</span><a href="#39298442">prev</a><span>|</span><a href="#39298542">next</a><span>|</span><label class="collapse" for="c-39296613">[-]</label><label class="expand" for="c-39296613">[1 more]</label></div><br/><div class="children"><div class="content">I thought exactly the same - it actually drives me nuts that Python packages have this confusing dual-name nature. You were there first!</div><br/></div></div><div id="39298542" class="c"><input type="checkbox" id="c-39298542" checked=""/><div class="controls bullet"><span class="by">sitkack</span><span>|</span><a href="#39296567">parent</a><span>|</span><a href="#39296613">prev</a><span>|</span><a href="#39294838">next</a><span>|</span><label class="collapse" for="c-39298542">[-]</label><label class="expand" for="c-39298542">[1 more]</label></div><br/><div class="children"><div class="content">You should rename your project.</div><br/></div></div></div></div><div id="39294838" class="c"><input type="checkbox" id="c-39294838" checked=""/><div class="controls bullet"><span class="by">brucethemoose2</span><span>|</span><a href="#39296567">prev</a><span>|</span><a href="#39295563">next</a><span>|</span><label class="collapse" for="c-39294838">[-]</label><label class="expand" for="c-39294838">[10 more]</label></div><br/><div class="children"><div class="content">Even Google is making a llama.cpp wrapper.<p>Technically a wrapper of a wrapper, though llama-cpp-python is quite excellent... TBH I would just recommend using that and all its under-the-radar features (like grammar, and built in function calling support with Functionary).</div><br/><div id="39296376" class="c"><input type="checkbox" id="c-39296376" checked=""/><div class="controls bullet"><span class="by">depingus</span><span>|</span><a href="#39294838">parent</a><span>|</span><a href="#39295587">next</a><span>|</span><label class="collapse" for="c-39296376">[-]</label><label class="expand" for="c-39296376">[2 more]</label></div><br/><div class="children"><div class="content">Slightly off topic, here is the best local llama.cpp wrapper I&#x27;ve run into:<p><a href="https:&#x2F;&#x2F;github.com&#x2F;Mozilla-Ocho&#x2F;llamafile">https:&#x2F;&#x2F;github.com&#x2F;Mozilla-Ocho&#x2F;llamafile</a><p>You can download any .gguf model (not just the ones in their examples) and run it locally (as long as you have the ram for it). I was running 7B models with ease on an old FX8350 and now 13B models on a 5600X (32GB RAM on both machines).<p>This wrapper spins up a local web server that runs a simple web frontend to use immediately with no code, but also exposes an OpenAI compatible API for dev work and alt frontends (like SillyTavern).</div><br/><div id="39299795" class="c"><input type="checkbox" id="c-39299795" checked=""/><div class="controls bullet"><span class="by">3abiton</span><span>|</span><a href="#39294838">root</a><span>|</span><a href="#39296376">parent</a><span>|</span><a href="#39295587">next</a><span>|</span><label class="collapse" for="c-39299795">[-]</label><label class="expand" for="c-39299795">[1 more]</label></div><br/><div class="children"><div class="content">What&#x27;s the speed? I heard of llamafile before.</div><br/></div></div></div></div><div id="39295587" class="c"><input type="checkbox" id="c-39295587" checked=""/><div class="controls bullet"><span class="by">andy99</span><span>|</span><a href="#39294838">parent</a><span>|</span><a href="#39296376">prev</a><span>|</span><a href="#39297294">next</a><span>|</span><label class="collapse" for="c-39295587">[-]</label><label class="expand" for="c-39295587">[3 more]</label></div><br/><div class="children"><div class="content">Oh it&#x27;s a wrapper? I just skimmed and thought they reinvented llama.cpp for some reason, which would have been mildly interesting.</div><br/><div id="39295610" class="c"><input type="checkbox" id="c-39295610" checked=""/><div class="controls bullet"><span class="by">williamstein</span><span>|</span><a href="#39294838">root</a><span>|</span><a href="#39295587">parent</a><span>|</span><a href="#39297294">next</a><span>|</span><label class="collapse" for="c-39295610">[-]</label><label class="expand" for="c-39295610">[2 more]</label></div><br/><div class="children"><div class="content">(edit: this is completely irrelevant remark. sorry)  It&#x27;s (1) written in Python, and (2) ollama appears nowhere in their Docker repo [1], and (3) it gets the models only from huggingface instead of the ollama repos.  Thus maybe it is NOT a wrapper of ollama?<p>[1] <a href="https:&#x2F;&#x2F;github.com&#x2F;googlecloudplatform&#x2F;localllm">https:&#x2F;&#x2F;github.com&#x2F;googlecloudplatform&#x2F;localllm</a></div><br/><div id="39295685" class="c"><input type="checkbox" id="c-39295685" checked=""/><div class="controls bullet"><span class="by">andy99</span><span>|</span><a href="#39294838">root</a><span>|</span><a href="#39295610">parent</a><span>|</span><a href="#39297294">next</a><span>|</span><label class="collapse" for="c-39295685">[-]</label><label class="expand" for="c-39295685">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;github.com&#x2F;GoogleCloudPlatform&#x2F;localllm&#x2F;blob&#x2F;main&#x2F;llm-tool&#x2F;setup.py#L30">https:&#x2F;&#x2F;github.com&#x2F;GoogleCloudPlatform&#x2F;localllm&#x2F;blob&#x2F;main&#x2F;ll...</a><p>I see llama.cpp in there, but I didn&#x27;t go deeper than that. Ollama is not the same thing.</div><br/></div></div></div></div></div></div><div id="39297294" class="c"><input type="checkbox" id="c-39297294" checked=""/><div class="controls bullet"><span class="by">m00x</span><span>|</span><a href="#39294838">parent</a><span>|</span><a href="#39295587">prev</a><span>|</span><a href="#39296418">next</a><span>|</span><label class="collapse" for="c-39297294">[-]</label><label class="expand" for="c-39297294">[2 more]</label></div><br/><div class="children"><div class="content">I wonder what need they&#x27;re fulfilling here. It&#x27;s not really more useful than using llamacpp-python. This is not something old Google would even release.</div><br/><div id="39298540" class="c"><input type="checkbox" id="c-39298540" checked=""/><div class="controls bullet"><span class="by">bigiain</span><span>|</span><a href="#39294838">root</a><span>|</span><a href="#39297294">parent</a><span>|</span><a href="#39296418">next</a><span>|</span><label class="collapse" for="c-39298540">[-]</label><label class="expand" for="c-39298540">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I wonder what need they&#x27;re fulfilling here.<p>The need to fill more seats on the AI hype train.<p>(Someone&#x27;s probably got &quot;release AI software as Google open source&quot; as an OKR)</div><br/></div></div></div></div><div id="39296418" class="c"><input type="checkbox" id="c-39296418" checked=""/><div class="controls bullet"><span class="by">thund</span><span>|</span><a href="#39294838">parent</a><span>|</span><a href="#39297294">prev</a><span>|</span><a href="#39295563">next</a><span>|</span><label class="collapse" for="c-39296418">[-]</label><label class="expand" for="c-39296418">[2 more]</label></div><br/><div class="children"><div class="content">does Functionary work with generic models like llama.cpp? had the impression you could only use Functionary GGUFs</div><br/><div id="39299309" class="c"><input type="checkbox" id="c-39299309" checked=""/><div class="controls bullet"><span class="by">gbickford</span><span>|</span><a href="#39294838">root</a><span>|</span><a href="#39296418">parent</a><span>|</span><a href="#39295563">next</a><span>|</span><label class="collapse" for="c-39299309">[-]</label><label class="expand" for="c-39299309">[1 more]</label></div><br/><div class="children"><div class="content">Llama.cpp is an inference engine. The author of llama.cpp designed gguf. Funcionary is a model that does function calling. You can download functionary weights in the gguf format and then run it using llama.cpp on low-end machines using CPU or GPU or a mix of both.</div><br/></div></div></div></div></div></div><div id="39295563" class="c"><input type="checkbox" id="c-39295563" checked=""/><div class="controls bullet"><span class="by">pmontra</span><span>|</span><a href="#39294838">prev</a><span>|</span><a href="#39295751">next</a><span>|</span><label class="collapse" for="c-39295563">[-]</label><label class="expand" for="c-39295563">[6 more]</label></div><br/><div class="children"><div class="content">&gt; We suggest using a machine type of e2-standard-32 (32 vCPU, 16 core and 128 GB memory), an admittedly beefy machine.<p>Average price per month $966.56<p><a href="https:&#x2F;&#x2F;gcloud-compute.com&#x2F;e2-standard-32.html" rel="nofollow">https:&#x2F;&#x2F;gcloud-compute.com&#x2F;e2-standard-32.html</a></div><br/><div id="39295590" class="c"><input type="checkbox" id="c-39295590" checked=""/><div class="controls bullet"><span class="by">williamstein</span><span>|</span><a href="#39295563">parent</a><span>|</span><a href="#39295622">next</a><span>|</span><label class="collapse" for="c-39295590">[-]</label><label class="expand" for="c-39295590">[1 more]</label></div><br/><div class="children"><div class="content">You can also get exactly that same VM as a spot instance with a 10GB disk and external ip address in the us-west4 region for $142.04&#x2F;month.   (Spot instance prices vary dramatically from one region to another, but that one is very discounted in us-west4.)<p>Also, is this localllm kind of like a Google competitor to some aspects of ollama?</div><br/></div></div><div id="39295622" class="c"><input type="checkbox" id="c-39295622" checked=""/><div class="controls bullet"><span class="by">api</span><span>|</span><a href="#39295563">parent</a><span>|</span><a href="#39295590">prev</a><span>|</span><a href="#39295751">next</a><span>|</span><label class="collapse" for="c-39295622">[-]</label><label class="expand" for="c-39295622">[4 more]</label></div><br/><div class="children"><div class="content">You could buy 4-6 machines like that per year at that price. Gives you a taste of cloud mark-up. Bandwidth markup is far more insane.</div><br/><div id="39296789" class="c"><input type="checkbox" id="c-39296789" checked=""/><div class="controls bullet"><span class="by">eyegor</span><span>|</span><a href="#39295563">root</a><span>|</span><a href="#39295622">parent</a><span>|</span><a href="#39296821">next</a><span>|</span><label class="collapse" for="c-39296789">[-]</label><label class="expand" for="c-39296789">[2 more]</label></div><br/><div class="children"><div class="content">For $1000 you could basically build one today. 5950x (16c cpu) is $400, 128gb kit of ddr4 is $250-300, maybe enough budget left for mobo, ssd, psu, case, cooler if you bought used bits (may also need cheapest gpu on Craigslist depending on your needs). All new ~$1200. Aws&#x2F;gcp prices are nuts compared to on prem, although hetzner and co would be much cheaper.</div><br/><div id="39298556" class="c"><input type="checkbox" id="c-39298556" checked=""/><div class="controls bullet"><span class="by">omgwtfbyobbq</span><span>|</span><a href="#39295563">root</a><span>|</span><a href="#39296789">parent</a><span>|</span><a href="#39296821">next</a><span>|</span><label class="collapse" for="c-39298556">[-]</label><label class="expand" for="c-39298556">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, Cloud is definitely a money maker.<p>If someone has a microcenter nearby, they could build an 8 core ddr4 system with 128gb of ram for maybe $800.<p>$3200+ could build a 64 core&#x2F;128gb ddr5 rig.<p><a href="https:&#x2F;&#x2F;www.newegg.com&#x2F;tyan-s8050gm2ne-9534-amd-epyc-9534-2-45ghz-installed&#x2F;p&#x2F;N82E16813151352" rel="nofollow">https:&#x2F;&#x2F;www.newegg.com&#x2F;tyan-s8050gm2ne-9534-amd-epyc-9534-2-...</a></div><br/></div></div></div></div><div id="39296821" class="c"><input type="checkbox" id="c-39296821" checked=""/><div class="controls bullet"><span class="by">mkatx</span><span>|</span><a href="#39295563">root</a><span>|</span><a href="#39295622">parent</a><span>|</span><a href="#39296789">prev</a><span>|</span><a href="#39295751">next</a><span>|</span><label class="collapse" for="c-39296821">[-]</label><label class="expand" for="c-39296821">[1 more]</label></div><br/><div class="children"><div class="content">Yep, I built gaming PCs for years, and I have a few laying around.. Add some ram and they a great servers (without memory safety though).</div><br/></div></div></div></div></div></div><div id="39295751" class="c"><input type="checkbox" id="c-39295751" checked=""/><div class="controls bullet"><span class="by">andy99</span><span>|</span><a href="#39295563">prev</a><span>|</span><a href="#39298760">next</a><span>|</span><label class="collapse" for="c-39295751">[-]</label><label class="expand" for="c-39295751">[3 more]</label></div><br/><div class="children"><div class="content">One thing I&#x27;m happy about is that the gguf file format is getting widely used, here endorsed by Google. I vastly prefer working with gguf and have adopted it for my project, hopefully it gets the critical mass to become a &quot;native&quot; format and we can stop with pytorch checkpoints.</div><br/><div id="39296379" class="c"><input type="checkbox" id="c-39296379" checked=""/><div class="controls bullet"><span class="by">brucethemoose2</span><span>|</span><a href="#39295751">parent</a><span>|</span><a href="#39298760">next</a><span>|</span><label class="collapse" for="c-39296379">[-]</label><label class="expand" for="c-39296379">[2 more]</label></div><br/><div class="children"><div class="content">On the contrary, it&#x27;s not one-size-fits-all.<p>It doesn&#x27;t support everything other backends need (like certain quantization schemes). If it somehow does, then its not universally compatible and that&#x27;s just going to create more confusion.</div><br/><div id="39298143" class="c"><input type="checkbox" id="c-39298143" checked=""/><div class="controls bullet"><span class="by">behnamoh</span><span>|</span><a href="#39295751">root</a><span>|</span><a href="#39296379">parent</a><span>|</span><a href="#39298760">next</a><span>|</span><label class="collapse" for="c-39298143">[-]</label><label class="expand" for="c-39298143">[1 more]</label></div><br/><div class="children"><div class="content">It supports grammar and that&#x27;s more than enough in practice.</div><br/></div></div></div></div></div></div><div id="39298760" class="c"><input type="checkbox" id="c-39298760" checked=""/><div class="controls bullet"><span class="by">geuis</span><span>|</span><a href="#39295751">prev</a><span>|</span><a href="#39297563">next</a><span>|</span><label class="collapse" for="c-39298760">[-]</label><label class="expand" for="c-39298760">[1 more]</label></div><br/><div class="children"><div class="content">For the interested, I&#x27;ve been having fun with llama.cpp. I&#x27;ve got it running well, if a bit slowly, on my 2019 intel MacBook Pro. There&#x27;s configs you can tweak that get it to run faster, mainly dealing with memory mapping. I&#x27;ve been working on documenting my findings but haven&#x27;t published yet.<p>I say all that to encourage people to try it out with different models. It&#x27;s not production quality but totally usable for testing things out even on older machines.</div><br/></div></div><div id="39297563" class="c"><input type="checkbox" id="c-39297563" checked=""/><div class="controls bullet"><span class="by">mcapodici</span><span>|</span><a href="#39298760">prev</a><span>|</span><a href="#39296777">next</a><span>|</span><label class="collapse" for="c-39297563">[-]</label><label class="expand" for="c-39297563">[2 more]</label></div><br/><div class="children"><div class="content">Hey that&#x27;s my title ... almost :-) <a href="https:&#x2F;&#x2F;martincapodici.com&#x2F;2023&#x2F;07&#x2F;15&#x2F;no-local-gpu-no-problem-running-andrej-karpathys-nanogpt-on-modal-com&#x2F;" rel="nofollow">https:&#x2F;&#x2F;martincapodici.com&#x2F;2023&#x2F;07&#x2F;15&#x2F;no-local-gpu-no-proble...</a></div><br/><div id="39298917" class="c"><input type="checkbox" id="c-39298917" checked=""/><div class="controls bullet"><span class="by">hongweiyap5</span><span>|</span><a href="#39297563">parent</a><span>|</span><a href="#39296777">next</a><span>|</span><label class="collapse" for="c-39298917">[-]</label><label class="expand" for="c-39298917">[1 more]</label></div><br/><div class="children"><div class="content">hvjvhcgxgxggcgcgcgcgcywww.@aliyun.com</div><br/></div></div></div></div><div id="39296777" class="c"><input type="checkbox" id="c-39296777" checked=""/><div class="controls bullet"><span class="by">smcleod</span><span>|</span><a href="#39297563">prev</a><span>|</span><a href="#39298370">next</a><span>|</span><label class="collapse" for="c-39296777">[-]</label><label class="expand" for="c-39296777">[2 more]</label></div><br/><div class="children"><div class="content">How can you call something “local”LLM and have it rely on Google cloud?!<p>&gt; “…within the Google Cloud Workstation”</div><br/><div id="39299615" class="c"><input type="checkbox" id="c-39299615" checked=""/><div class="controls bullet"><span class="by">seu</span><span>|</span><a href="#39296777">parent</a><span>|</span><a href="#39298370">next</a><span>|</span><label class="collapse" for="c-39299615">[-]</label><label class="expand" for="c-39299615">[1 more]</label></div><br/><div class="children"><div class="content">Exactly my thought.</div><br/></div></div></div></div><div id="39298370" class="c"><input type="checkbox" id="c-39298370" checked=""/><div class="controls bullet"><span class="by">reissbaker</span><span>|</span><a href="#39296777">prev</a><span>|</span><a href="#39298617">next</a><span>|</span><label class="collapse" for="c-39298370">[-]</label><label class="expand" for="c-39298370">[2 more]</label></div><br/><div class="children"><div class="content">This blog post has a distinct &quot;written by an LLM&quot; feel to it that I can&#x27;t quite put my finger on.</div><br/><div id="39298858" class="c"><input type="checkbox" id="c-39298858" checked=""/><div class="controls bullet"><span class="by">mirekrusin</span><span>|</span><a href="#39298370">parent</a><span>|</span><a href="#39298617">next</a><span>|</span><label class="collapse" for="c-39298858">[-]</label><label class="expand" for="c-39298858">[1 more]</label></div><br/><div class="children"><div class="content">Bullet points starting with bolded text, longer, objective, soulless sentences devoided of &quot;I&quot;.</div><br/></div></div></div></div><div id="39298617" class="c"><input type="checkbox" id="c-39298617" checked=""/><div class="controls bullet"><span class="by">iAkashPaul</span><span>|</span><a href="#39298370">prev</a><span>|</span><a href="#39298431">next</a><span>|</span><label class="collapse" for="c-39298617">[-]</label><label class="expand" for="c-39298617">[1 more]</label></div><br/><div class="children"><div class="content">The amount of obfuscation &amp; head-in the-ground was nauseating to read</div><br/></div></div><div id="39298431" class="c"><input type="checkbox" id="c-39298431" checked=""/><div class="controls bullet"><span class="by">nicolezhu</span><span>|</span><a href="#39298617">prev</a><span>|</span><a href="#39296301">next</a><span>|</span><label class="collapse" for="c-39298431">[-]</label><label class="expand" for="c-39298431">[1 more]</label></div><br/><div class="children"><div class="content">As a former Google employee working on their OSS stack, this feels a bit off brand.<p>Here&#x27;s a whole list of indie, OSS AI frameworks you can use: <a href="https:&#x2F;&#x2F;github.com&#x2F;janhq&#x2F;awesome-local-ai">https:&#x2F;&#x2F;github.com&#x2F;janhq&#x2F;awesome-local-ai</a><p>Disclaimer: I&#x27;m one of the core devs on Jan.</div><br/></div></div><div id="39296301" class="c"><input type="checkbox" id="c-39296301" checked=""/><div class="controls bullet"><span class="by">UncleOxidant</span><span>|</span><a href="#39298431">prev</a><span>|</span><a href="#39296980">next</a><span>|</span><label class="collapse" for="c-39296301">[-]</label><label class="expand" for="c-39296301">[7 more]</label></div><br/><div class="children"><div class="content">&gt; pip3 install openai<p>Why is that required?</div><br/><div id="39296359" class="c"><input type="checkbox" id="c-39296359" checked=""/><div class="controls bullet"><span class="by">brucethemoose2</span><span>|</span><a href="#39296301">parent</a><span>|</span><a href="#39296373">next</a><span>|</span><label class="collapse" for="c-39296359">[-]</label><label class="expand" for="c-39296359">[3 more]</label></div><br/><div class="children"><div class="content">Everyone uses that for openai compatible api requests.<p>Its actually great. Most backends and frontends &quot;just work&quot; with each other because they all talk with openai (albeit with some caveats).</div><br/><div id="39296788" class="c"><input type="checkbox" id="c-39296788" checked=""/><div class="controls bullet"><span class="by">smcleod</span><span>|</span><a href="#39296301">root</a><span>|</span><a href="#39296359">parent</a><span>|</span><a href="#39296373">next</a><span>|</span><label class="collapse" for="c-39296788">[-]</label><label class="expand" for="c-39296788">[2 more]</label></div><br/><div class="children"><div class="content">I think you might be thinking of litellm? OpenAI is for OpenAI.com (although you can override the base URL it’s far from ideal).</div><br/><div id="39297262" class="c"><input type="checkbox" id="c-39297262" checked=""/><div class="controls bullet"><span class="by">Tostino</span><span>|</span><a href="#39296301">root</a><span>|</span><a href="#39296788">parent</a><span>|</span><a href="#39296373">next</a><span>|</span><label class="collapse" for="c-39297262">[-]</label><label class="expand" for="c-39297262">[1 more]</label></div><br/><div class="children"><div class="content">What do you mean &quot;far from ideal&quot;? It&#x27;s literally just passing in your services URL rather than using the default when instantiating the client. Something you will need to do with any client you use.</div><br/></div></div></div></div></div></div><div id="39296373" class="c"><input type="checkbox" id="c-39296373" checked=""/><div class="controls bullet"><span class="by">spacecadet</span><span>|</span><a href="#39296301">parent</a><span>|</span><a href="#39296359">prev</a><span>|</span><a href="#39296364">next</a><span>|</span><label class="collapse" for="c-39296373">[-]</label><label class="expand" for="c-39296373">[2 more]</label></div><br/><div class="children"><div class="content">I wondered that too. I see a comment, but I still wonder why its &quot;required&quot; here.</div><br/></div></div></div></div><div id="39296980" class="c"><input type="checkbox" id="c-39296980" checked=""/><div class="controls bullet"><span class="by">tracerbulletx</span><span>|</span><a href="#39296301">prev</a><span>|</span><a href="#39299195">next</a><span>|</span><label class="collapse" for="c-39296980">[-]</label><label class="expand" for="c-39296980">[3 more]</label></div><br/><div class="children"><div class="content">They&#x27;ve really jumped the shark. Creating a wrapper for llama.cpp (a project they don&#x27;t even credit here) and acting like that&#x27;s even interesting, then somehow implying this is a feature or benefit of using Google Cloud Workstations? This is the most technically bankrupt product page I&#x27;ve ever seen in my life and for a company that used to mean something to people to do it is pathetic.</div><br/><div id="39296997" class="c"><input type="checkbox" id="c-39296997" checked=""/><div class="controls bullet"><span class="by">segmondy</span><span>|</span><a href="#39296980">parent</a><span>|</span><a href="#39299195">next</a><span>|</span><label class="collapse" for="c-39296997">[-]</label><label class="expand" for="c-39296997">[2 more]</label></div><br/><div class="children"><div class="content">it&#x27;s actually a wrapper around llama-cpp-python.  they ought to be embarrassed.</div><br/><div id="39297266" class="c"><input type="checkbox" id="c-39297266" checked=""/><div class="controls bullet"><span class="by">m00x</span><span>|</span><a href="#39296980">root</a><span>|</span><a href="#39296997">parent</a><span>|</span><a href="#39299195">next</a><span>|</span><label class="collapse" for="c-39297266">[-]</label><label class="expand" for="c-39297266">[1 more]</label></div><br/><div class="children"><div class="content">Google really has fallen off. This is intern level stuff.</div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>