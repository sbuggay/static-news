<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1716022854490" as="style"/><link rel="stylesheet" href="styles.css?v=1716022854490"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/metaskills/experts">Multi AI agent systems using OpenAI&#x27;s assistants API</a> <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>metaskills</span> | <span>60 comments</span></div><br/><div><div id="40395968" class="c"><input type="checkbox" id="c-40395968" checked=""/><div class="controls bullet"><span class="by">yatz</span><span>|</span><a href="#40395311">next</a><span>|</span><label class="collapse" for="c-40395968">[-]</label><label class="expand" for="c-40395968">[4 more]</label></div><br/><div class="children"><div class="content">Assistants API is promising, but earlier versions have many issues, especially with how it calculates the costs. As per OpenAI docs, you pay for data storage, a fixed price per API call, + token usage. It sounds straightforward until you start using it.<p>Here is how it works. When you upload attachments, in my case a very large PDF, it chunks that PDF into small parts and stores them in a vector database. It seems like the chunking part is not that great, as every time you make a call, the system loads a large chunk or many chunks and sends them to the model along with your prompt, which inflates your per request costs to 10 times more than the prompt + response tokens combined. So, be mindful of the hidden costs and monitor your usage.</div><br/><div id="40396478" class="c"><input type="checkbox" id="c-40396478" checked=""/><div class="controls bullet"><span class="by">iamflimflam1</span><span>|</span><a href="#40395968">parent</a><span>|</span><a href="#40396901">next</a><span>|</span><label class="collapse" for="c-40396478">[-]</label><label class="expand" for="c-40396478">[1 more]</label></div><br/><div class="children"><div class="content">There isn’t really any other way for this to work. The only way for the model to answer questions on your pdf is for the information to be somewhere in the prompt.</div><br/></div></div><div id="40396901" class="c"><input type="checkbox" id="c-40396901" checked=""/><div class="controls bullet"><span class="by">hnuser123456</span><span>|</span><a href="#40395968">parent</a><span>|</span><a href="#40396478">prev</a><span>|</span><a href="#40396078">next</a><span>|</span><label class="collapse" for="c-40396901">[-]</label><label class="expand" for="c-40396901">[1 more]</label></div><br/><div class="children"><div class="content">How large is a very large PDF?</div><br/></div></div></div></div><div id="40395311" class="c"><input type="checkbox" id="c-40395311" checked=""/><div class="controls bullet"><span class="by">xrendan</span><span>|</span><a href="#40395968">prev</a><span>|</span><a href="#40395427">next</a><span>|</span><label class="collapse" for="c-40395311">[-]</label><label class="expand" for="c-40395311">[15 more]</label></div><br/><div class="children"><div class="content">I&#x27;d be interested in knowing if anyone is seriously using the assistants API, it feels like such a lock in to OpenAIs platform when your can alternatively just use completions that are much more easily interchanged.</div><br/><div id="40395906" class="c"><input type="checkbox" id="c-40395906" checked=""/><div class="controls bullet"><span class="by">Nedomas</span><span>|</span><a href="#40395311">parent</a><span>|</span><a href="#40396225">next</a><span>|</span><label class="collapse" for="c-40395906">[-]</label><label class="expand" for="c-40395906">[3 more]</label></div><br/><div class="children"><div class="content">I do and built Assistants API compat layer for Groq and Anthropic: <a href="https:&#x2F;&#x2F;github.com&#x2F;supercorp-ai&#x2F;supercompat">https:&#x2F;&#x2F;github.com&#x2F;supercorp-ai&#x2F;supercompat</a> 
I’d argue that Assistants API DX &gt; manual completions API.</div><br/><div id="40395976" class="c"><input type="checkbox" id="c-40395976" checked=""/><div class="controls bullet"><span class="by">tomrod</span><span>|</span><a href="#40395311">root</a><span>|</span><a href="#40395906">parent</a><span>|</span><a href="#40396225">next</a><span>|</span><label class="collapse" for="c-40395976">[-]</label><label class="expand" for="c-40395976">[2 more]</label></div><br/><div class="children"><div class="content">Aye, but your FinOps will be comolaining even with simple use.</div><br/><div id="40396045" class="c"><input type="checkbox" id="c-40396045" checked=""/><div class="controls bullet"><span class="by">Nedomas</span><span>|</span><a href="#40395311">root</a><span>|</span><a href="#40395976">parent</a><span>|</span><a href="#40396225">next</a><span>|</span><label class="collapse" for="c-40396045">[-]</label><label class="expand" for="c-40396045">[1 more]</label></div><br/><div class="children"><div class="content">Assistants API use in prod used to suck because it would send full convo on each message. But last month they added an option to send truncted history so its no longer 2$ a pop thankfully. Also Grok, Haiku and Mistral is cheap</div><br/></div></div></div></div></div></div><div id="40396225" class="c"><input type="checkbox" id="c-40396225" checked=""/><div class="controls bullet"><span class="by">oddthink</span><span>|</span><a href="#40395311">parent</a><span>|</span><a href="#40395906">prev</a><span>|</span><a href="#40395488">next</a><span>|</span><label class="collapse" for="c-40396225">[-]</label><label class="expand" for="c-40396225">[1 more]</label></div><br/><div class="children"><div class="content">I know at least one team is at work is using the Assistants API, and I&#x27;m talking with another team that is leaning pretty heavily towards using it over building a custom RAG solution themselves, or even over other in-house frameworks.</div><br/></div></div><div id="40395488" class="c"><input type="checkbox" id="c-40395488" checked=""/><div class="controls bullet"><span class="by">phh</span><span>|</span><a href="#40395311">parent</a><span>|</span><a href="#40396225">prev</a><span>|</span><a href="#40396516">next</a><span>|</span><label class="collapse" for="c-40395488">[-]</label><label class="expand" for="c-40395488">[9 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve indeed refused to work with some providers giving only a chat interface and not a completion interface because it made the communication &quot;less natural&quot; to the model (like adding new system messages in between for function calling on models which don&#x27;t officially does it, or adding other categories than system&#x2F;user&#x2F;assistant)</div><br/><div id="40395510" class="c"><input type="checkbox" id="c-40395510" checked=""/><div class="controls bullet"><span class="by">metaskills</span><span>|</span><a href="#40395311">root</a><span>|</span><a href="#40395488">parent</a><span>|</span><a href="#40395515">next</a><span>|</span><label class="collapse" for="c-40395510">[-]</label><label class="expand" for="c-40395510">[7 more]</label></div><br/><div class="children"><div class="content">Great points. Dont even get me started about how function calling in other LLMs costs me tokens. Something OpenAI provides OOTB. I&#x27;m also not a big fan of OpenAI&#x27;s lock in. Right now I&#x27;m on a huge Claude 3 Haiku kick. That said, OpenAI does seem to get the APIs right and my hunch is the new Assistants API is going to potentially disrupt things again. Time will tell.</div><br/><div id="40395616" class="c"><input type="checkbox" id="c-40395616" checked=""/><div class="controls bullet"><span class="by">heggy</span><span>|</span><a href="#40395311">root</a><span>|</span><a href="#40395510">parent</a><span>|</span><a href="#40395703">next</a><span>|</span><label class="collapse" for="c-40395616">[-]</label><label class="expand" for="c-40395616">[4 more]</label></div><br/><div class="children"><div class="content">I would love to be using Claude, but you can&#x27;t get API access (beyond an initial trial period) in the EU without providing a European VAT number. They don&#x27;t want personal users or people to even learn and experiment I guess.</div><br/><div id="40395789" class="c"><input type="checkbox" id="c-40395789" checked=""/><div class="controls bullet"><span class="by">metaskills</span><span>|</span><a href="#40395311">root</a><span>|</span><a href="#40395616">parent</a><span>|</span><a href="#40395750">next</a><span>|</span><label class="collapse" for="c-40395789">[-]</label><label class="expand" for="c-40395789">[1 more]</label></div><br/><div class="children"><div class="content">Interesting, would Amazon Bedrock be an alternative? That&#x27;s how I use Claude.</div><br/></div></div><div id="40395750" class="c"><input type="checkbox" id="c-40395750" checked=""/><div class="controls bullet"><span class="by">bjterry</span><span>|</span><a href="#40395311">root</a><span>|</span><a href="#40395616">parent</a><span>|</span><a href="#40395789">prev</a><span>|</span><a href="#40395938">next</a><span>|</span><label class="collapse" for="c-40395750">[-]</label><label class="expand" for="c-40395750">[1 more]</label></div><br/><div class="children"><div class="content">You can use the Claude APIs via OpenRouter with a pre-paid account.</div><br/></div></div><div id="40395938" class="c"><input type="checkbox" id="c-40395938" checked=""/><div class="controls bullet"><span class="by">Jimmc414</span><span>|</span><a href="#40395311">root</a><span>|</span><a href="#40395616">parent</a><span>|</span><a href="#40395750">prev</a><span>|</span><a href="#40395703">next</a><span>|</span><label class="collapse" for="c-40395938">[-]</label><label class="expand" for="c-40395938">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;d guess it&#x27;s more likely about the additional programming needed to meet GDPR compliance requirements.</div><br/></div></div></div></div><div id="40395703" class="c"><input type="checkbox" id="c-40395703" checked=""/><div class="controls bullet"><span class="by">msp26</span><span>|</span><a href="#40395311">root</a><span>|</span><a href="#40395510">parent</a><span>|</span><a href="#40395616">prev</a><span>|</span><a href="#40395515">next</a><span>|</span><label class="collapse" for="c-40395703">[-]</label><label class="expand" for="c-40395703">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Dont even get me started about how function calling in other LLMs costs me tokens. Something OpenAI provides out of the box.<p>Not sure what you mean by this.</div><br/><div id="40396017" class="c"><input type="checkbox" id="c-40396017" checked=""/><div class="controls bullet"><span class="by">metaskills</span><span>|</span><a href="#40395311">root</a><span>|</span><a href="#40395703">parent</a><span>|</span><a href="#40395515">next</a><span>|</span><label class="collapse" for="c-40396017">[-]</label><label class="expand" for="c-40396017">[1 more]</label></div><br/><div class="children"><div class="content">I have some assumptions&#x2F;guesses on how billing works. Gonna do a post on this on my unremarkable.ai blog, please do signup for posts there, no spam. I could be right or wrong but need to do some experiments and publish later.</div><br/></div></div></div></div></div></div><div id="40395515" class="c"><input type="checkbox" id="c-40395515" checked=""/><div class="controls bullet"><span class="by">BoorishBears</span><span>|</span><a href="#40395311">root</a><span>|</span><a href="#40395488">parent</a><span>|</span><a href="#40395510">prev</a><span>|</span><a href="#40396516">next</a><span>|</span><label class="collapse" for="c-40395515">[-]</label><label class="expand" for="c-40395515">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not sure you&#x27;re talking about the same thing: OpenAI specifically has a &quot;Assistants API&quot; that manages long term memory and tool usage for the consumer: <a href="https:&#x2F;&#x2F;platform.openai.com&#x2F;assistants" rel="nofollow">https:&#x2F;&#x2F;platform.openai.com&#x2F;assistants</a><p>I&#x27;d guestimate 99% of people using LLMs are using instruct-based message interfaces that have a variation of system&#x2F;user&#x2F;assistant. The top models mostly only come as a completion models, and even Anthropic has switched to a message based API</div><br/></div></div></div></div><div id="40396516" class="c"><input type="checkbox" id="c-40396516" checked=""/><div class="controls bullet"><span class="by">j45</span><span>|</span><a href="#40395311">parent</a><span>|</span><a href="#40395488">prev</a><span>|</span><a href="#40395427">next</a><span>|</span><label class="collapse" for="c-40396516">[-]</label><label class="expand" for="c-40396516">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve used it and in some cases it&#x27;s taking days and weeks of development away to get to testing the market.<p>In some cases the lock in is what it is for now because a particular model in reality is so far ahead, or staying ahead.<p>It doesn&#x27;t mean other options won&#x27;t become available, but it does matter to relate your need to your actions.<p>Getting something working consistently for example might be the first goal, and then learning to implement it with multiple models might be secondary.  The chances of that increase the later other models are explored in some cases.<p>It should be possible to tell pretty quickly if something works in a particular model that&#x27;s the leader, how others compare to it and how to track the rate of change between them.</div><br/></div></div></div></div><div id="40395427" class="c"><input type="checkbox" id="c-40395427" checked=""/><div class="controls bullet"><span class="by">csouzaf</span><span>|</span><a href="#40395311">prev</a><span>|</span><a href="#40396219">next</a><span>|</span><label class="collapse" for="c-40395427">[-]</label><label class="expand" for="c-40395427">[6 more]</label></div><br/><div class="children"><div class="content">What&#x27;s the use cases people are using Multi AI Agents to solve problems that deliver real value? Someone has something with your hands on right now?</div><br/><div id="40396947" class="c"><input type="checkbox" id="c-40396947" checked=""/><div class="controls bullet"><span class="by">avereveard</span><span>|</span><a href="#40395427">parent</a><span>|</span><a href="#40395518">next</a><span>|</span><label class="collapse" for="c-40396947">[-]</label><label class="expand" for="c-40396947">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve encountered two viable cases: instructions are too complex, too many tools, or wildly different processing steps, in which case it semplify a lot the processing to have a few well defined steps each doing their thing, and a coordinator on top, either sequential, or intelligent, that is only focuesed on next step routing.<p>the other is memory for conversational retrieval. ai memory is still quite limited, especially if there needs to be a lot of token in context, and context too long impede the ability of llm of focus on the task itself, especially if the context is itself a conversation or a request, so spreading the context along a few agents, and propagating the user request among agent, and having those produce answer fragment for another llm to formulate an answer allows to not lose the conversational context without swamping the llm with noise.<p>the problem tho remains latency as son as you nest them latency explodes as you can only stream the last layer of llm output</div><br/></div></div><div id="40395518" class="c"><input type="checkbox" id="c-40395518" checked=""/><div class="controls bullet"><span class="by">ww520</span><span>|</span><a href="#40395427">parent</a><span>|</span><a href="#40396947">prev</a><span>|</span><a href="#40396835">next</a><span>|</span><label class="collapse" for="c-40395518">[-]</label><label class="expand" for="c-40395518">[2 more]</label></div><br/><div class="children"><div class="content">I imagine having an agent set up with specific RAG context to solve a specific problem and having another with a different RAG context to solve a different problem can be useful.</div><br/><div id="40395594" class="c"><input type="checkbox" id="c-40395594" checked=""/><div class="controls bullet"><span class="by">csouzaf</span><span>|</span><a href="#40395427">root</a><span>|</span><a href="#40395518">parent</a><span>|</span><a href="#40396835">next</a><span>|</span><label class="collapse" for="c-40395594">[-]</label><label class="expand" for="c-40395594">[1 more]</label></div><br/><div class="children"><div class="content">I see customer support as a very talked subject to solve this. But these system really manage to solve the issue removing the human feedback dramatically?</div><br/></div></div></div></div><div id="40396835" class="c"><input type="checkbox" id="c-40396835" checked=""/><div class="controls bullet"><span class="by">LASR</span><span>|</span><a href="#40395427">parent</a><span>|</span><a href="#40395518">prev</a><span>|</span><a href="#40395440">next</a><span>|</span><label class="collapse" for="c-40396835">[-]</label><label class="expand" for="c-40396835">[1 more]</label></div><br/><div class="children"><div class="content">We’ve tried. A lot. Custom frameworks and all.<p>There is really no way to make the ensemble behave with an acceptable level of consistency.<p>Where we ended up is now having a frontier model generate a whole tree of possible execution plans, and then have the user select one of those path, and then we just run whatever the user chose in a plain sequence until the next decision point that needs user approval.</div><br/></div></div><div id="40395440" class="c"><input type="checkbox" id="c-40395440" checked=""/><div class="controls bullet"><span class="by">coffeebeqn</span><span>|</span><a href="#40395427">parent</a><span>|</span><a href="#40396835">prev</a><span>|</span><a href="#40396219">next</a><span>|</span><label class="collapse" for="c-40395440">[-]</label><label class="expand" for="c-40395440">[1 more]</label></div><br/><div class="children"><div class="content">I tried the last crop. Interesting idea but the success rate of any real multi step task always approached 0% the longer it went</div><br/></div></div></div></div><div id="40396219" class="c"><input type="checkbox" id="c-40396219" checked=""/><div class="controls bullet"><span class="by">mentos</span><span>|</span><a href="#40395427">prev</a><span>|</span><a href="#40395358">next</a><span>|</span><label class="collapse" for="c-40396219">[-]</label><label class="expand" for="c-40396219">[3 more]</label></div><br/><div class="children"><div class="content">Anyone recommend the best way to use AI to search all of my documents for a project. I&#x27;ve got specifications, blueprints, emails, forms, etc.<p>Would be great to be able to ask it, &#x27;have we completed the X process with contractor Y yet?&#x27;</div><br/><div id="40397443" class="c"><input type="checkbox" id="c-40397443" checked=""/><div class="controls bullet"><span class="by">squirrel</span><span>|</span><a href="#40396219">parent</a><span>|</span><a href="#40396241">next</a><span>|</span><label class="collapse" for="c-40397443">[-]</label><label class="expand" for="c-40397443">[1 more]</label></div><br/><div class="children"><div class="content">Zenfetch</div><br/></div></div><div id="40396241" class="c"><input type="checkbox" id="c-40396241" checked=""/><div class="controls bullet"><span class="by">valiant-comma</span><span>|</span><a href="#40396219">parent</a><span>|</span><a href="#40397443">prev</a><span>|</span><a href="#40395358">next</a><span>|</span><label class="collapse" for="c-40396241">[-]</label><label class="expand" for="c-40396241">[1 more]</label></div><br/><div class="children"><div class="content">Try h2ogpt:<p><a href="https:&#x2F;&#x2F;github.com&#x2F;h2oai&#x2F;h2ogpt">https:&#x2F;&#x2F;github.com&#x2F;h2oai&#x2F;h2ogpt</a></div><br/></div></div></div></div><div id="40395358" class="c"><input type="checkbox" id="c-40395358" checked=""/><div class="controls bullet"><span class="by">beoberha</span><span>|</span><a href="#40396219">prev</a><span>|</span><a href="#40396298">next</a><span>|</span><label class="collapse" for="c-40395358">[-]</label><label class="expand" for="c-40395358">[11 more]</label></div><br/><div class="children"><div class="content">From the website linked in the readme:<p>“A lot of research has been doing in this are and we can expect a lot more in 2024 in this space. I promise to share some clarity around where I think this industry is headed. In personal talks I have warned that multi-agent systems are complex and hard to get right. I&#x27;ve seen little evidence of real-world use cases too”<p>These assistant systems fascinate me, but I just don’t have the time and energy to set something up. I was going to ask if anyone had a good experience with it, but the above makes it sound like there’s not much hope at the moment. Curious what other people’s experience are.</div><br/><div id="40395550" class="c"><input type="checkbox" id="c-40395550" checked=""/><div class="controls bullet"><span class="by">dongobread</span><span>|</span><a href="#40395358">parent</a><span>|</span><a href="#40395495">next</a><span>|</span><label class="collapse" for="c-40395550">[-]</label><label class="expand" for="c-40395550">[4 more]</label></div><br/><div class="children"><div class="content">We tried using a multi-agent system for a complex NLP-type task and we found:<p>- Too many errors that just propogate on top of each other, if a single agent in the chain generates something even a little bit off then the whole system goes off the rails.<p>- You often end up having to pass a massive amount of shared context to every agent which just increases the cost dramatically.<p>Curiously enough we had an architect from OpenAI tell us the same thing about agent systems a few days ago (our company is a big spender so they serve a consulting function), so I don&#x27;t think anybody is really finding success with multi-agent systems currently. IMO the core tech is nowhere near good enough yet.</div><br/><div id="40395645" class="c"><input type="checkbox" id="c-40395645" checked=""/><div class="controls bullet"><span class="by">pennomi</span><span>|</span><a href="#40395358">root</a><span>|</span><a href="#40395550">parent</a><span>|</span><a href="#40396261">next</a><span>|</span><label class="collapse" for="c-40395645">[-]</label><label class="expand" for="c-40395645">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Too many errors that just propogate on top of each other<p>LLMs are like the perfect improv comedy troupe, they virtually always say “yes, and…”</div><br/><div id="40395708" class="c"><input type="checkbox" id="c-40395708" checked=""/><div class="controls bullet"><span class="by">echelon</span><span>|</span><a href="#40395358">root</a><span>|</span><a href="#40395645">parent</a><span>|</span><a href="#40396261">next</a><span>|</span><label class="collapse" for="c-40395708">[-]</label><label class="expand" for="c-40395708">[1 more]</label></div><br/><div class="children"><div class="content">&gt; perfect improv comedy troupe<p>Check out Vtubers like CodeMiko, who improvs against LLM agents. Or 24&#x2F;7 streaming LLM cartoon shows that take audience plot suggestions.</div><br/></div></div></div></div><div id="40396261" class="c"><input type="checkbox" id="c-40396261" checked=""/><div class="controls bullet"><span class="by">lmeyerov</span><span>|</span><a href="#40395358">root</a><span>|</span><a href="#40395550">parent</a><span>|</span><a href="#40395645">prev</a><span>|</span><a href="#40395495">next</a><span>|</span><label class="collapse" for="c-40396261">[-]</label><label class="expand" for="c-40396261">[1 more]</label></div><br/><div class="children"><div class="content">we do multistep programs in louie.ai via a variety of agents&#x2F;tools, like &quot;get X data from DB Y, wrangle cols A+B in Python, and then draw an interactive map + graph&quot;<p>The ultimate answer is fairly short if you are a senior python data scientist, like 50loc. The agents will wander and iterate until they push through. You might correct &amp; tweak if a bit off.<p>Importantly, this does agents opposite of the way Devin AI engineer replacements are presented. Here, you get it to do a few steps, and then move on to the next few steps. The agents still crank away a ton and do all sorts of clever things for you... to get you more reliably to the next step, vs something big &amp; wrong.</div><br/></div></div></div></div><div id="40395495" class="c"><input type="checkbox" id="c-40395495" checked=""/><div class="controls bullet"><span class="by">metaskills</span><span>|</span><a href="#40395358">parent</a><span>|</span><a href="#40395550">prev</a><span>|</span><a href="#40395607">next</a><span>|</span><label class="collapse" for="c-40395495">[-]</label><label class="expand" for="c-40395495">[2 more]</label></div><br/><div class="children"><div class="content">Thanks @beoberha, I am too. I like one take I heard on Twitter. The sentiment was something like these types of systems are useful under the AI-Powered Productivity industry which has incremental gains, no big bangs. Said another way, if your job was to help a TON of your employees be more productive individually, it is worth it because companies measure those efforts broadly and the payoff is there. But again, not big. My advice for folks to stay lower level and hook AI automation up with simple, closed loop, LLM patterns that feel more like basic API calls in a choreographed manner. OMG, hope all that made sense</div><br/><div id="40395599" class="c"><input type="checkbox" id="c-40395599" checked=""/><div class="controls bullet"><span class="by">purposesystem</span><span>|</span><a href="#40395358">root</a><span>|</span><a href="#40395495">parent</a><span>|</span><a href="#40395607">next</a><span>|</span><label class="collapse" for="c-40395599">[-]</label><label class="expand" for="c-40395599">[1 more]</label></div><br/><div class="children"><div class="content">that&#x27;s actually a great reply, thanks</div><br/></div></div></div></div><div id="40395607" class="c"><input type="checkbox" id="c-40395607" checked=""/><div class="controls bullet"><span class="by">fzliu</span><span>|</span><a href="#40395358">parent</a><span>|</span><a href="#40395495">prev</a><span>|</span><a href="#40395490">next</a><span>|</span><label class="collapse" for="c-40395607">[-]</label><label class="expand" for="c-40395607">[1 more]</label></div><br/><div class="children"><div class="content">A lot of folks I&#x27;ve spoken with say that single-agent systems are still extremely limited, let alone multi-agent platforms. In general, it seems to boil down to:<p>- Agents need lots of manual tuning and guardrails to make them useful<p>- Agents with too many guardrails are not general-purpose enough to be worth the time and effort to build<p>I believe truly great agents will only come from models whose weights are dynamically updated. I hope I&#x27;m wrong.</div><br/></div></div><div id="40395490" class="c"><input type="checkbox" id="c-40395490" checked=""/><div class="controls bullet"><span class="by">m3kw9</span><span>|</span><a href="#40395358">parent</a><span>|</span><a href="#40395607">prev</a><span>|</span><a href="#40395877">next</a><span>|</span><label class="collapse" for="c-40395490">[-]</label><label class="expand" for="c-40395490">[2 more]</label></div><br/><div class="children"><div class="content">By the time you do get around to it OpenAi would have built a full interface for this.  This is the type of stuff that’s gonna get steamrolled.</div><br/><div id="40395784" class="c"><input type="checkbox" id="c-40395784" checked=""/><div class="controls bullet"><span class="by">WXLCKNO</span><span>|</span><a href="#40395358">root</a><span>|</span><a href="#40395490">parent</a><span>|</span><a href="#40395877">next</a><span>|</span><label class="collapse" for="c-40395784">[-]</label><label class="expand" for="c-40395784">[1 more]</label></div><br/><div class="children"><div class="content">Pretty much this. I&#x27;d love counter examples of startups in the space that haven&#x27;t been crushed from the top yet.</div><br/></div></div></div></div></div></div><div id="40396298" class="c"><input type="checkbox" id="c-40396298" checked=""/><div class="controls bullet"><span class="by">david_shi</span><span>|</span><a href="#40395358">prev</a><span>|</span><a href="#40395548">next</a><span>|</span><label class="collapse" for="c-40396298">[-]</label><label class="expand" for="c-40396298">[1 more]</label></div><br/><div class="children"><div class="content">A bit off topic, but has anyone seen any agent systems focused on improving the agents capabilities with more usage?</div><br/></div></div><div id="40395548" class="c"><input type="checkbox" id="c-40395548" checked=""/><div class="controls bullet"><span class="by">__loam</span><span>|</span><a href="#40396298">prev</a><span>|</span><a href="#40396228">next</a><span>|</span><label class="collapse" for="c-40395548">[-]</label><label class="expand" for="c-40395548">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve not seen any of these &quot;agentic&quot; systems be all that useful in practice. Complicated chain of software where a lot can wrong at any step, and the probability of failure explodes when you have many steps.</div><br/></div></div><div id="40396228" class="c"><input type="checkbox" id="c-40396228" checked=""/><div class="controls bullet"><span class="by">ec109685</span><span>|</span><a href="#40395548">prev</a><span>|</span><a href="#40395109">next</a><span>|</span><label class="collapse" for="c-40396228">[-]</label><label class="expand" for="c-40396228">[3 more]</label></div><br/><div class="children"><div class="content">I don’t understand the comment about server send events not being async friendly.<p>What is unfriendly about this?<p><pre><code>  import OpenAI from &#x27;openai&#x27;;

  const openai = new OpenAI();

  async function main() {
    const stream = await openai.chat.completions.create({
      model: &#x27;gpt-4&#x27;,
      messages: [{ role: &#x27;user&#x27;, content: &#x27;Say this is a test&#x27; }],
      stream: true,
  });
    for await (const chunk of stream) {
    process.stdout.write(chunk.choices[0]?.delta?.content || &#x27;&#x27;);
    }
  }

  main();
</code></pre>
It’s easy to collect the streaming output and return it all when the llm’s response is done.</div><br/><div id="40396273" class="c"><input type="checkbox" id="c-40396273" checked=""/><div class="controls bullet"><span class="by">wokwokwok</span><span>|</span><a href="#40396228">parent</a><span>|</span><a href="#40396266">next</a><span>|</span><label class="collapse" for="c-40396273">[-]</label><label class="expand" for="c-40396273">[1 more]</label></div><br/><div class="children"><div class="content">They’re referring to the:<p>&gt; assistant.on(&quot;textDelta”, () =&gt; …<p>Callbacks, which are not async and can’t be streamed that way <i>directly</i> without wrapping it in some helper function.<p>(Which does seem obvious; I’m also not sure why they called it out specifically as not being async friendly? I guess most callback style functions these days have async equivalents in popular libraries and these ones don’t)</div><br/></div></div></div></div><div id="40395747" class="c"><input type="checkbox" id="c-40395747" checked=""/><div class="controls bullet"><span class="by">behnamoh</span><span>|</span><a href="#40395109">prev</a><span>|</span><a href="#40396093">next</a><span>|</span><label class="collapse" for="c-40395747">[-]</label><label class="expand" for="c-40395747">[2 more]</label></div><br/><div class="children"><div class="content">I stay away from such frameworks because:<p>- Writing what I want in Python&#x2F;other-lingo gives me much more customizability than these frameworks offer.<p>- No worries about the future plans of the repo and having to deal with abandonware.<p>- No vendor lock in. Currently most repos like this focus on OpenAI&#x27;s models, but I prefer to work with local models of all kinds and any abstraction above llama.cpp or llama-cpp-python is a no-no for me.<p>The last point means I refuse to build on top of ollama&#x27;s API as it&#x27;s yet another wrapper around llama.cpp.</div><br/><div id="40397432" class="c"><input type="checkbox" id="c-40397432" checked=""/><div class="controls bullet"><span class="by">rcarmo</span><span>|</span><a href="#40395747">parent</a><span>|</span><a href="#40396093">next</a><span>|</span><label class="collapse" for="c-40397432">[-]</label><label class="expand" for="c-40397432">[1 more]</label></div><br/><div class="children"><div class="content">Not using the ollama API means you have to keep track of context yourself, and run all your stuff in the same box. Hardly ideal.</div><br/></div></div></div></div><div id="40396093" class="c"><input type="checkbox" id="c-40396093" checked=""/><div class="controls bullet"><span class="by">tr14</span><span>|</span><a href="#40395747">prev</a><span>|</span><a href="#40395307">next</a><span>|</span><label class="collapse" for="c-40396093">[-]</label><label class="expand" for="c-40396093">[1 more]</label></div><br/><div class="children"><div class="content">AI botnet?</div><br/></div></div><div id="40395307" class="c"><input type="checkbox" id="c-40395307" checked=""/><div class="controls bullet"><span class="by">spiritplumber</span><span>|</span><a href="#40396093">prev</a><span>|</span><a href="#40395501">next</a><span>|</span><label class="collapse" for="c-40395307">[-]</label><label class="expand" for="c-40395307">[1 more]</label></div><br/><div class="children"><div class="content">Ooh, shiny!</div><br/></div></div><div id="40395501" class="c"><input type="checkbox" id="c-40395501" checked=""/><div class="controls bullet"><span class="by">moltar</span><span>|</span><a href="#40395307">prev</a><span>|</span><a href="#40395472">next</a><span>|</span><label class="collapse" for="c-40395501">[-]</label><label class="expand" for="c-40395501">[7 more]</label></div><br/><div class="children"><div class="content">Bare JS. What is this 2001?</div><br/><div id="40395527" class="c"><input type="checkbox" id="c-40395527" checked=""/><div class="controls bullet"><span class="by">metaskills</span><span>|</span><a href="#40395501">parent</a><span>|</span><a href="#40395472">next</a><span>|</span><label class="collapse" for="c-40395527">[-]</label><label class="expand" for="c-40395527">[6 more]</label></div><br/><div class="children"><div class="content">LMAO. Yes, I love ESM modules. So maybe more like 2012 or 2015. Would you like to see TypeScript?</div><br/><div id="40395561" class="c"><input type="checkbox" id="c-40395561" checked=""/><div class="controls bullet"><span class="by">alluro2</span><span>|</span><a href="#40395501">root</a><span>|</span><a href="#40395527">parent</a><span>|</span><a href="#40395887">next</a><span>|</span><label class="collapse" for="c-40395561">[-]</label><label class="expand" for="c-40395561">[1 more]</label></div><br/><div class="children"><div class="content">Thank you for using vanilla JS!</div><br/></div></div><div id="40395887" class="c"><input type="checkbox" id="c-40395887" checked=""/><div class="controls bullet"><span class="by">fy20</span><span>|</span><a href="#40395501">root</a><span>|</span><a href="#40395527">parent</a><span>|</span><a href="#40395561">prev</a><span>|</span><a href="#40395871">next</a><span>|</span><label class="collapse" for="c-40395887">[-]</label><label class="expand" for="c-40395887">[1 more]</label></div><br/><div class="children"><div class="content">Not OP, but I use TypeScript because it adds a layer of safety to the codebase.<p>It&#x27;s like having good test coverage - you can make large changes and if the tests pass (the code compiles), you can be fairly confident that you didn&#x27;t mess anything up.<p>I&#x27;ve written Ruby for years, so I&#x27;m used to dynamically typed languages. But JavaScript is it&#x27;s own level of special, and there&#x27;s so many ways you can accidentally mess things up.<p>Having tests cover every single path (especially failure paths) can be very time consuming, and often hard or messy to setup (how would you mock the OpenAI module returning an error when adding metadata to a thread?), where as using something like TypeScript can make sure your code handles all paths somewhat correctly (at least as well as the types you defined).<p>Your code looks clean, and you appear to have good test coverage, so you do you though :-)</div><br/></div></div><div id="40395871" class="c"><input type="checkbox" id="c-40395871" checked=""/><div class="controls bullet"><span class="by">taf2</span><span>|</span><a href="#40395501">root</a><span>|</span><a href="#40395527">parent</a><span>|</span><a href="#40395887">prev</a><span>|</span><a href="#40396180">next</a><span>|</span><label class="collapse" for="c-40395871">[-]</label><label class="expand" for="c-40395871">[2 more]</label></div><br/><div class="children"><div class="content">Yes this is great so much easier to work with</div><br/><div id="40396020" class="c"><input type="checkbox" id="c-40396020" checked=""/><div class="controls bullet"><span class="by">metaskills</span><span>|</span><a href="#40395501">root</a><span>|</span><a href="#40395871">parent</a><span>|</span><a href="#40396180">next</a><span>|</span><label class="collapse" for="c-40396020">[-]</label><label class="expand" for="c-40396020">[1 more]</label></div><br/><div class="children"><div class="content">Y&#x27;all just made my day!</div><br/></div></div></div></div></div></div></div></div><div id="40395472" class="c"><input type="checkbox" id="c-40395472" checked=""/><div class="controls bullet"><span class="by">obiefernandez</span><span>|</span><a href="#40395501">prev</a><span>|</span><label class="collapse" for="c-40395472">[-]</label><label class="expand" for="c-40395472">[3 more]</label></div><br/><div class="children"><div class="content">My main conversation “loop” at <a href="https:&#x2F;&#x2F;olympia.chat" rel="nofollow">https:&#x2F;&#x2F;olympia.chat</a> has tool functions connected to “helper AIs” for things such as integrating with email. It lets me minimize functions on the main loop and actually works really well.</div><br/><div id="40396398" class="c"><input type="checkbox" id="c-40396398" checked=""/><div class="controls bullet"><span class="by">Terretta</span><span>|</span><a href="#40395472">parent</a><span>|</span><a href="#40396335">next</a><span>|</span><label class="collapse" for="c-40396398">[-]</label><label class="expand" for="c-40396398">[1 more]</label></div><br/><div class="children"><div class="content">Sid Kapoor, Content Specialist, forgot to include himself in Growth or Pro plans.  Guess he <i>is</i> Basic!</div><br/></div></div><div id="40396335" class="c"><input type="checkbox" id="c-40396335" checked=""/><div class="controls bullet"><span class="by">bongodongobob</span><span>|</span><a href="#40395472">parent</a><span>|</span><a href="#40396398">prev</a><span>|</span><label class="collapse" for="c-40396335">[-]</label><label class="expand" for="c-40396335">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m sorry but that is absolutely hilarious.</div><br/></div></div></div></div></div></div></div></div></div></body></html>