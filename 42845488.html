<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1738054866593" as="style"/><link rel="stylesheet" href="styles.css?v=1738054866593"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://newsletter.languagemodels.co/p/the-illustrated-deepseek-r1">The Illustrated DeepSeek-R1</a> <span class="domain">(<a href="https://newsletter.languagemodels.co">newsletter.languagemodels.co</a>)</span></div><div class="subtext"><span>amrrs</span> | <span>51 comments</span></div><br/><div><div id="42849485" class="c"><input type="checkbox" id="c-42849485" checked=""/><div class="controls bullet"><span class="by">QuadrupleA</span><span>|</span><a href="#42846454">next</a><span>|</span><label class="collapse" for="c-42849485">[-]</label><label class="expand" for="c-42849485">[9 more]</label></div><br/><div class="children"><div class="content">Am I the only one not that impressed with Deepseek R1? Its &quot;thinking&quot; seems full of the usual LLM blindsides, and ultimately generating more of it then summarizing doesn&#x27;t seem to overcome any real limits.<p>It&#x27;s like making mortgage backed securities out of bad mortgages, you never really overcome the badness of the underlying loans, no matter how many layers you pile on top<p>I haven&#x27;t used or studied DeepSeek R1 (or o1) in exhaustive depth, but I guess I&#x27;m just not understanding the level of breathless hype right now.</div><br/><div id="42850207" class="c"><input type="checkbox" id="c-42850207" checked=""/><div class="controls bullet"><span class="by">TrackerFF</span><span>|</span><a href="#42849485">parent</a><span>|</span><a href="#42849599">next</a><span>|</span><label class="collapse" for="c-42850207">[-]</label><label class="expand" for="c-42850207">[1 more]</label></div><br/><div class="children"><div class="content">What&#x27;s there not to understand?<p>If it matches the latest GPT O-N model in performance - or is just close, even, at a fraction of the compute (50x less?) and it is free, then that&#x27;s huge news.<p>They just upended the current LLM&#x2F;AI&#x2F;ML dominance, or at least the perceived dominance. Billions and billions have been pumped into the race, where investors are betting on the winner - and here comes a Chinese hedge fund side-project on shoestring budget, matching those billion dollar behemoths. And they&#x27;ll continue to release their work.<p>They just made the OpenAI et. al. secret sauce a lot less valuable.</div><br/></div></div><div id="42849599" class="c"><input type="checkbox" id="c-42849599" checked=""/><div class="controls bullet"><span class="by">itissid</span><span>|</span><a href="#42849485">parent</a><span>|</span><a href="#42850207">prev</a><span>|</span><a href="#42849713">next</a><span>|</span><label class="collapse" for="c-42849599">[-]</label><label class="expand" for="c-42849599">[3 more]</label></div><br/><div class="children"><div class="content">It is leaps and bounds better than LLMs. For one you are doing RL which is classic AI like tuning that optimizes a reward function with nice qualities- it&#x27;s the same stuff used to train chess games and Go by showing them the actual moves.<p>LLMs pre o1 and deepseek R1 were RHLF tuned which is like if you trained a LM how to play chess by showing people two boards and doing a vibe check on which &quot;looks&quot; better.<p>Think of it this way say you were dropped in a maze that you had to solve but you could do only one of two things:<p>1. Look at two  random moves from your start position and selected which one looked better to get out.<p>2. Made a series of moves and then backtracked, then use a quantitative function to exploit the best path.<p>The latter is what R1 does and it chooses optimal and more certain path to success.<p>Apply this to math and coding tokens and you have a competitive LLM.</div><br/><div id="42849607" class="c"><input type="checkbox" id="c-42849607" checked=""/><div class="controls bullet"><span class="by">itissid</span><span>|</span><a href="#42849485">root</a><span>|</span><a href="#42849599">parent</a><span>|</span><a href="#42849713">next</a><span>|</span><label class="collapse" for="c-42849607">[-]</label><label class="expand" for="c-42849607">[2 more]</label></div><br/><div class="children"><div class="content">I am using the 32Gb distilled model on my local 3090 with Continue in VSCode. It beats everything out of the water.</div><br/><div id="42849658" class="c"><input type="checkbox" id="c-42849658" checked=""/><div class="controls bullet"><span class="by">dontwearitout</span><span>|</span><a href="#42849485">root</a><span>|</span><a href="#42849607">parent</a><span>|</span><a href="#42849713">next</a><span>|</span><label class="collapse" for="c-42849658">[-]</label><label class="expand" for="c-42849658">[1 more]</label></div><br/><div class="children"><div class="content">How many tokens&#x2F;s do you get on a 3090? With the extra tokens for the internal monologue, is it still performant enough for smooth VSCode integration?</div><br/></div></div></div></div></div></div><div id="42849713" class="c"><input type="checkbox" id="c-42849713" checked=""/><div class="controls bullet"><span class="by">lm28469</span><span>|</span><a href="#42849485">parent</a><span>|</span><a href="#42849599">prev</a><span>|</span><a href="#42849687">next</a><span>|</span><label class="collapse" for="c-42849713">[-]</label><label class="expand" for="c-42849713">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve been using deepseek for a while, I never paid for chat gpt or any other services.<p>The fact that r1 is now free and unlimited VS chat gpt 200$ a month subscription is impressive enough for me. If the development cost is anywhere close to what they advertise publicly it&#x27;s even more impressive<p>It&#x27;s as good or better than chat gpt free, gemini free, &amp;c. and that&#x27;s all I care about</div><br/></div></div><div id="42849687" class="c"><input type="checkbox" id="c-42849687" checked=""/><div class="controls bullet"><span class="by">throwup238</span><span>|</span><a href="#42849485">parent</a><span>|</span><a href="#42849713">prev</a><span>|</span><a href="#42849956">next</a><span>|</span><label class="collapse" for="c-42849687">[-]</label><label class="expand" for="c-42849687">[1 more]</label></div><br/><div class="children"><div class="content">You’re not the only one. It’s not as impressive at coding compared to O1 as people make it out to be and it’s explicitly spelled out in DeepSeek’s R1 paper that they had trouble with improving over DeepSeek-V3:<p><i>&gt; Software Engineering Tasks: Due to the long evaluation times, which impact the efficiency of the RL process, large-scale RL has not been applied extensively in software engineering tasks. As a result, DeepSeek-R1 has not demonstrated a huge improvement over DeepSeek-V3 on software engineering benchmarks. Future versions will address this by implementing rejection sampling on software engineering data or incorporating asynchronous evaluations during the RL process to improve efficiency.</i> (last bullet point of page 16, which is the last page of the paper before the bibliography - hmm…) [1]<p>It does even worse on my real world coding problems than the benchmarks would suggest. Some of my tests: write a Qt QAbstractListModel in C++ that parses markdown into block using a C&#x2F;C++ MD parsing library, write Rust cxx-qt bindings for QTextDocument (all docs included in context), write a window switching script for Wayland with an alternative to wmctrl, etc. I also asked it some geochemistry questions that I had trialed O1 with previously, and the reasoning had a lot hallucinations. The answers were suboptimal to say the least.<p>Having access to the thought process in &lt;think&gt;&lt;&#x2F;think&gt; tags is cool but it just reveals how underdeveloped the actual reasoning is compared to whatever o1 is doing. I’ve had it get stuck on silly things like whether a C++ library for markdown exists because I underspecified that I’m okay with header only C libs. O1 has faired much better on my qualitative test suite - even more so when using it via API with a “high” reasoning_effort.<p>With all of the hype over the last few days, it feels like I’m taking crazy pills (loving all the action though).<p>[1] <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2501.12948" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2501.12948</a></div><br/></div></div><div id="42849956" class="c"><input type="checkbox" id="c-42849956" checked=""/><div class="controls bullet"><span class="by">assimpleaspossi</span><span>|</span><a href="#42849485">parent</a><span>|</span><a href="#42849687">prev</a><span>|</span><a href="#42849556">next</a><span>|</span><label class="collapse" for="c-42849956">[-]</label><label class="expand" for="c-42849956">[1 more]</label></div><br/><div class="children"><div class="content">fwiw, National Public Radio (NPR) news in the USA said that AI experts stated it was &quot;almost as good&quot; as other current offerings like chatGPT and Gemini. That its real advantage is the low cost of providing the information. However, this is only a claim made by the company without any proof.</div><br/></div></div></div></div><div id="42846454" class="c"><input type="checkbox" id="c-42846454" checked=""/><div class="controls bullet"><span class="by">jasonjmcghee</span><span>|</span><a href="#42849485">prev</a><span>|</span><a href="#42846786">next</a><span>|</span><label class="collapse" for="c-42846454">[-]</label><label class="expand" for="c-42846454">[7 more]</label></div><br/><div class="children"><div class="content">For the uninitiated, this is the same author as the many other &quot;The Illustrated...&quot; blog posts.<p>A particularly popular one: <a href="https:&#x2F;&#x2F;jalammar.github.io&#x2F;illustrated-transformer&#x2F;" rel="nofollow">https:&#x2F;&#x2F;jalammar.github.io&#x2F;illustrated-transformer&#x2F;</a><p>Always very high quality.</div><br/><div id="42846803" class="c"><input type="checkbox" id="c-42846803" checked=""/><div class="controls bullet"><span class="by">jamestimmins</span><span>|</span><a href="#42846454">parent</a><span>|</span><a href="#42846572">next</a><span>|</span><label class="collapse" for="c-42846803">[-]</label><label class="expand" for="c-42846803">[5 more]</label></div><br/><div class="children"><div class="content">Have you read his book Hands-On Large Language Models?<p>Looks interesting, but I&#x27;m skeptical that a book can feasibly stay up to date with the speed of development.</div><br/><div id="42849861" class="c"><input type="checkbox" id="c-42849861" checked=""/><div class="controls bullet"><span class="by">jampekka</span><span>|</span><a href="#42846454">root</a><span>|</span><a href="#42846803">parent</a><span>|</span><a href="#42847065">next</a><span>|</span><label class="collapse" for="c-42849861">[-]</label><label class="expand" for="c-42849861">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Looks interesting, but I&#x27;m skeptical that a book can feasibly stay up to date with the speed of development.<p>The basic structure of the base models has not really changed since the first GPT launched in 2018. You still have to understand gradient descent, tokenization, embeddings, self-attention, MLPs, supervised fine tuning, RLHF etc for the foreseeable future.<p>Adding RL based CoT training would be a relatively straightforward addendum to a new edition, and it&#x27;s an application of long established methods like PPO.<p>All &quot;generations&quot; of models are presented as revolutionary -- and results-wise they maybe are -- but technically they are usually quite incremental &quot;tweaks&quot; to the previous architecture.<p>Even more &quot;radical&quot; departures like state space models are closely related to same basic techniques and architectures.</div><br/></div></div><div id="42847065" class="c"><input type="checkbox" id="c-42847065" checked=""/><div class="controls bullet"><span class="by">jasonjmcghee</span><span>|</span><a href="#42846454">root</a><span>|</span><a href="#42846803">parent</a><span>|</span><a href="#42849861">prev</a><span>|</span><a href="#42846572">next</a><span>|</span><label class="collapse" for="c-42847065">[-]</label><label class="expand" for="c-42847065">[3 more]</label></div><br/><div class="children"><div class="content">I have not, but Jay has created a ton of value and knowledge for free and don&#x27;t fault him for throwing an ad for his book &#x2F; trying to benefit a bit financially.</div><br/><div id="42847494" class="c"><input type="checkbox" id="c-42847494" checked=""/><div class="controls bullet"><span class="by">jamestimmins</span><span>|</span><a href="#42846454">root</a><span>|</span><a href="#42847065">parent</a><span>|</span><a href="#42846572">next</a><span>|</span><label class="collapse" for="c-42847494">[-]</label><label class="expand" for="c-42847494">[2 more]</label></div><br/><div class="children"><div class="content">Yeah no shade for someone selling their knowledge; I&#x27;m just trying to suss out how useful the book is for learning foundations.</div><br/><div id="42848991" class="c"><input type="checkbox" id="c-42848991" checked=""/><div class="controls bullet"><span class="by">whoisburbansky</span><span>|</span><a href="#42846454">root</a><span>|</span><a href="#42847494">parent</a><span>|</span><a href="#42846572">next</a><span>|</span><label class="collapse" for="c-42848991">[-]</label><label class="expand" for="c-42848991">[1 more]</label></div><br/><div class="children"><div class="content">Foundations don&#x27;t change much with &quot;the speed of development&quot;</div><br/></div></div></div></div></div></div></div></div><div id="42846572" class="c"><input type="checkbox" id="c-42846572" checked=""/><div class="controls bullet"><span class="by">punkspider</span><span>|</span><a href="#42846454">parent</a><span>|</span><a href="#42846803">prev</a><span>|</span><a href="#42846786">next</a><span>|</span><label class="collapse" for="c-42846572">[-]</label><label class="expand" for="c-42846572">[1 more]</label></div><br/><div class="children"><div class="content">Thanks so much for mentioning this. His name carries a lot of weight for me as well.</div><br/></div></div></div></div><div id="42846786" class="c"><input type="checkbox" id="c-42846786" checked=""/><div class="controls bullet"><span class="by">raphaelj</span><span>|</span><a href="#42846454">prev</a><span>|</span><a href="#42846619">next</a><span>|</span><label class="collapse" for="c-42846786">[-]</label><label class="expand" for="c-42846786">[5 more]</label></div><br/><div class="children"><div class="content">Do we know which changes made DeepSeek V3 so much faster and better at training than other models? DeepSeek R1&#x27;s performances seem to be highly related to V3 being a very good model to start with.<p>I went through the paper and I understood they made these improvements compared to &quot;regular&quot; MoE models:<p>1. Latent Multi-head Attention. If I understand correctly, they were able to do some caching on the attention computation. This one is still a little bit confusing to me;<p>2. New MoE architecture with one shared expert and a large number of small routed experts (256 total, but 8 in use in the same token inference). This was already used in DeepSeek v2;<p>3. Better load balancing of the training of experts. During training, they add bias or &quot;bonus&quot; value to experts that are less used, to make them more likely to be selected in the future training steps;<p>4. They added a few smaller transformer layers to predict not only the first next token, but a few additional tokens. Their training error&#x2F;loss function then uses all these predicted tokens as input, not only the first one. This is supposed to improve the transformer capabilities in predicting sequences of tokens;<p>5. They are using FP8 instead of FP16 when it does not impact accuracy.<p>It&#x27;s not clear to me which changes are the most important, but my guess would be that 4) is a critical improvement.<p>1), 2), 3) and 5) could explain why their model trains faster by some small factor (+&#x2F;- 2x), but neither the 10x advertised boost nor how is performs greatly better than models with way more activated parameters (e.g. llama 3).</div><br/><div id="42849009" class="c"><input type="checkbox" id="c-42849009" checked=""/><div class="controls bullet"><span class="by">whoisburbansky</span><span>|</span><a href="#42846786">parent</a><span>|</span><a href="#42847126">next</a><span>|</span><label class="collapse" for="c-42849009">[-]</label><label class="expand" for="c-42849009">[2 more]</label></div><br/><div class="children"><div class="content">The key idea of Latent MHA is that &quot;regular&quot; multi-headed attention needs you to keep a bunch of giant key-value (KV) matrices around in memory to do inference. The &quot;Latent&quot; part just means that DeepSeek takes the `n` KV matrices in a given n-headed attention block and replaces them with a lower-rank approximation (think of this as compressing the matrices), so that they take up less VRAM in a GPU at the cost of a little extra compute and a little lost accuracy. So not caching, strictly speaking, but weight compression to trade compute off for better memory usage, which is good because the KV matrices are one of the more expensive part of this transformer architecture. MoE addresses the other expensive part (the fully-connected layers) by making it so only a subset of the fully-connected layers are active at any given forward pass.</div><br/><div id="42849016" class="c"><input type="checkbox" id="c-42849016" checked=""/><div class="controls bullet"><span class="by">whoisburbansky</span><span>|</span><a href="#42846786">root</a><span>|</span><a href="#42849009">parent</a><span>|</span><a href="#42847126">next</a><span>|</span><label class="collapse" for="c-42849016">[-]</label><label class="expand" for="c-42849016">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;planetbanatt.net&#x2F;articles&#x2F;mla.html" rel="nofollow">https:&#x2F;&#x2F;planetbanatt.net&#x2F;articles&#x2F;mla.html</a> this is a great overview of how MLA works.</div><br/></div></div></div></div><div id="42847126" class="c"><input type="checkbox" id="c-42847126" checked=""/><div class="controls bullet"><span class="by">alecco</span><span>|</span><a href="#42846786">parent</a><span>|</span><a href="#42849009">prev</a><span>|</span><a href="#42849054">next</a><span>|</span><label class="collapse" for="c-42847126">[-]</label><label class="expand" for="c-42847126">[1 more]</label></div><br/><div class="children"><div class="content">They also did bandwidth scaling to handle work around the nerfed H800 interconnects.<p>&gt; efficient cross-node all-to-all communication kernels to fully utilize IB and NVLink bandwidths<p>&gt; The key idea of DualPipe is to overlap the computation and communication within a pair of individual forward and backward chunks. To be specific, we divide each chunk into four components: attention, all-to-all dispatch, MLP, and all-to-all combine. Specially, for a backward chunk, both attention and MLP are further split into two parts, backward for input and backward for weights, like in ZeroBubble (Qi et al., 2023b). In addition, we have a PP communication component.<p>(I know some of those words)<p><a href="https:&#x2F;&#x2F;arxiv.org&#x2F;html&#x2F;2412.19437v1" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;html&#x2F;2412.19437v1</a></div><br/></div></div><div id="42849054" class="c"><input type="checkbox" id="c-42849054" checked=""/><div class="controls bullet"><span class="by">sinuhe69</span><span>|</span><a href="#42846786">parent</a><span>|</span><a href="#42847126">prev</a><span>|</span><a href="#42846619">next</a><span>|</span><label class="collapse" for="c-42849054">[-]</label><label class="expand" for="c-42849054">[1 more]</label></div><br/><div class="children"><div class="content">I think the fact that they used synthetic&#x2F;distilled high-quality data from GPT4-o output to train in the style of Phi models are of significance as well.</div><br/></div></div></div></div><div id="42846619" class="c"><input type="checkbox" id="c-42846619" checked=""/><div class="controls bullet"><span class="by">whoistraitor</span><span>|</span><a href="#42846786">prev</a><span>|</span><a href="#42848101">next</a><span>|</span><label class="collapse" for="c-42846619">[-]</label><label class="expand" for="c-42846619">[9 more]</label></div><br/><div class="children"><div class="content">It’s remarkable we’ve hit a threshold where so much can be done with synthetic data. The reasoning race seems an utterly solvable problem now (thanks mostly to the verifiability of results). I guess the challenge then becomes non-reasoning domains, where qualitative and truly creative results are desired.</div><br/><div id="42846758" class="c"><input type="checkbox" id="c-42846758" checked=""/><div class="controls bullet"><span class="by">kenjackson</span><span>|</span><a href="#42846619">parent</a><span>|</span><a href="#42846826">next</a><span>|</span><label class="collapse" for="c-42846758">[-]</label><label class="expand" for="c-42846758">[7 more]</label></div><br/><div class="children"><div class="content">It seems like we need an evaluation model for creativity.  I&#x27;m curious, is there research on this -- for example, can one score a random painting and output how creative&#x2F;good a given population is likely to find it?</div><br/><div id="42849394" class="c"><input type="checkbox" id="c-42849394" checked=""/><div class="controls bullet"><span class="by">baq</span><span>|</span><a href="#42846619">root</a><span>|</span><a href="#42846758">parent</a><span>|</span><a href="#42846787">next</a><span>|</span><label class="collapse" for="c-42849394">[-]</label><label class="expand" for="c-42849394">[1 more]</label></div><br/><div class="children"><div class="content">There are two kinds of creativity at play here. One is mashing together combinations of learned things - it’s kinda like shuffling a deck of cards where basically every shuffle gets you a deck that has never been seen and won’t be seen again, but it’s still the same 52 cards every time. The other kind is going outside of the box and inventing truly new, unseen&#x2F;untrained concepts. This one is hard, but I don’t think it’s impossible - the &lt;think&gt; slop stirring the learned concepts with a bit of randomness should make progress here.</div><br/></div></div><div id="42846787" class="c"><input type="checkbox" id="c-42846787" checked=""/><div class="controls bullet"><span class="by">virgildotcodes</span><span>|</span><a href="#42846619">root</a><span>|</span><a href="#42846758">parent</a><span>|</span><a href="#42849394">prev</a><span>|</span><a href="#42847027">next</a><span>|</span><label class="collapse" for="c-42846787">[-]</label><label class="expand" for="c-42846787">[4 more]</label></div><br/><div class="children"><div class="content">How do you account for the impact of culture&#x2F;lived experience of the specific population viewing the painting? Intuitively it seems like that would be the biggest factor, rather than the objective attributes of the painting, no?</div><br/><div id="42846844" class="c"><input type="checkbox" id="c-42846844" checked=""/><div class="controls bullet"><span class="by">bentograd</span><span>|</span><a href="#42846619">root</a><span>|</span><a href="#42846787">parent</a><span>|</span><a href="#42847027">next</a><span>|</span><label class="collapse" for="c-42846844">[-]</label><label class="expand" for="c-42846844">[3 more]</label></div><br/><div class="children"><div class="content">All art is subjective. Any attempt to &quot;verify&quot; a piece of art would be entirely dependent on cultural and personal sensitivities. Art isn&#x27;t a math problem with a solution.</div><br/><div id="42849431" class="c"><input type="checkbox" id="c-42849431" checked=""/><div class="controls bullet"><span class="by">baq</span><span>|</span><a href="#42846619">root</a><span>|</span><a href="#42846844">parent</a><span>|</span><a href="#42850004">next</a><span>|</span><label class="collapse" for="c-42849431">[-]</label><label class="expand" for="c-42849431">[1 more]</label></div><br/><div class="children"><div class="content">But you can dissect it into concepts and see if it is something truly new to the model - if the output contains things which aren’t there in the weights, you have a nice specimen to study and, crucially, a recipe to get a bunch of matrices to output untrained things.</div><br/></div></div><div id="42850004" class="c"><input type="checkbox" id="c-42850004" checked=""/><div class="controls bullet"><span class="by">cubefox</span><span>|</span><a href="#42846619">root</a><span>|</span><a href="#42846844">parent</a><span>|</span><a href="#42849431">prev</a><span>|</span><a href="#42847027">next</a><span>|</span><label class="collapse" for="c-42850004">[-]</label><label class="expand" for="c-42850004">[1 more]</label></div><br/><div class="children"><div class="content">This is like saying: All cooks are equally good, even the most disgusting slop (e.g. water&#x2F;flour soup) isn&#x27;t any better than a dish from a cook with several Michelin stars. Of course the latter is better. And if it is better, it is objectively better. Even if 0.001% of people prefer flour soup.</div><br/></div></div></div></div></div></div><div id="42847027" class="c"><input type="checkbox" id="c-42847027" checked=""/><div class="controls bullet"><span class="by">esafak</span><span>|</span><a href="#42846619">root</a><span>|</span><a href="#42846758">parent</a><span>|</span><a href="#42846787">prev</a><span>|</span><a href="#42846826">next</a><span>|</span><label class="collapse" for="c-42847027">[-]</label><label class="expand" for="c-42847027">[1 more]</label></div><br/><div class="children"><div class="content">You can train a supervised model, taking into account the properties of the rater as well as the artwork, and tease out the factors that make it rated so.</div><br/></div></div></div></div><div id="42846826" class="c"><input type="checkbox" id="c-42846826" checked=""/><div class="controls bullet"><span class="by">researchers</span><span>|</span><a href="#42846619">parent</a><span>|</span><a href="#42846758">prev</a><span>|</span><a href="#42848101">next</a><span>|</span><label class="collapse" for="c-42846826">[-]</label><label class="expand" for="c-42846826">[1 more]</label></div><br/><div class="children"><div class="content">Tuning for qualitative outcomes is pretty much solved via RLHF&#x2F;DPO (what this post calls &quot;preference tuning&quot;). Right?</div><br/></div></div></div></div><div id="42848101" class="c"><input type="checkbox" id="c-42848101" checked=""/><div class="controls bullet"><span class="by">8n4vidtmkvmk</span><span>|</span><a href="#42846619">prev</a><span>|</span><a href="#42846898">next</a><span>|</span><label class="collapse" for="c-42848101">[-]</label><label class="expand" for="c-42848101">[1 more]</label></div><br/><div class="children"><div class="content">&gt; This is a large number of long chain-of-thought reasoning examples (600,000 of them). These are very hard to come by and very expensive to label with humans at this scale. Which is why the process to create them is the second special thing to highlight<p>I didn&#x27;t know the reasonings were part of the training data. I thought we basically just told the LLM to &quot;explain its thinking&quot; or something as an intermediate step, but the fact that the &#x27;thinking&#x27; is part of the training step makes more sense and I can see how this improves things in a non-trivial way.<p>Still not sure if using word tokens as the intermediate &quot;thinking&quot; is the correct or optimal way of doing things, but I don&#x27;t know. Maybe after everything is compressed into latent space it&#x27;s essentially the same stuff.</div><br/></div></div><div id="42846898" class="c"><input type="checkbox" id="c-42846898" checked=""/><div class="controls bullet"><span class="by">alecco</span><span>|</span><a href="#42848101">prev</a><span>|</span><a href="#42846460">next</a><span>|</span><label class="collapse" for="c-42846898">[-]</label><label class="expand" for="c-42846898">[4 more]</label></div><br/><div class="children"><div class="content">How is this very high signal vs noise post out of the front page in 2hs?<p>Are people so upset with the stock market crash that they are flagging it?</div><br/><div id="42847527" class="c"><input type="checkbox" id="c-42847527" checked=""/><div class="controls bullet"><span class="by">jasonjmcghee</span><span>|</span><a href="#42846898">parent</a><span>|</span><a href="#42848558">next</a><span>|</span><label class="collapse" for="c-42847527">[-]</label><label class="expand" for="c-42847527">[2 more]</label></div><br/><div class="children"><div class="content">Maybe too much of the same topic? &quot;How R1 was trained&quot; also seemed to quickly fall off. But the big arxiv paper with 1000+ upvotes stuck around a while.</div><br/><div id="42847749" class="c"><input type="checkbox" id="c-42847749" checked=""/><div class="controls bullet"><span class="by">htk</span><span>|</span><a href="#42846898">root</a><span>|</span><a href="#42847527">parent</a><span>|</span><a href="#42848558">next</a><span>|</span><label class="collapse" for="c-42847749">[-]</label><label class="expand" for="c-42847749">[1 more]</label></div><br/><div class="children"><div class="content">Spot on. I&#x27;ve read the very accessible paper and it&#x27;s better than any of the how-to&#x27;s written elsewhere. Nothing against good content being written, but the source material is already pretty good.</div><br/></div></div></div></div><div id="42848558" class="c"><input type="checkbox" id="c-42848558" checked=""/><div class="controls bullet"><span class="by">khazhoux</span><span>|</span><a href="#42846898">parent</a><span>|</span><a href="#42847527">prev</a><span>|</span><a href="#42846460">next</a><span>|</span><label class="collapse" for="c-42848558">[-]</label><label class="expand" for="c-42848558">[1 more]</label></div><br/><div class="children"><div class="content">dang has provided an answer for how the algorithm works whenever I&#x27;ve asked similar question.<p>But I still don&#x27;t get it.  6 hours + 170 points and it&#x27;s on third page.  Meanwhile second page has &quot;Null Byte on Steroids&quot; at 12 hours + 20 points.  ??</div><br/></div></div></div></div><div id="42846512" class="c"><input type="checkbox" id="c-42846512" checked=""/><div class="controls bullet"><span class="by">blackeyeblitzar</span><span>|</span><a href="#42846460">prev</a><span>|</span><a href="#42846240">next</a><span>|</span><label class="collapse" for="c-42846512">[-]</label><label class="expand" for="c-42846512">[11 more]</label></div><br/><div class="children"><div class="content">The thing I still don’t understand is how DeepSeek built the base model cheaply, and why their models seem to think they are GPT4 when asked. This article says the base model is from their previous paper, but that paper also doesn’t make clear what they trained on. The earlier paper is mostly a description of optimization techniques they applied. It does mention pretraining on 14.8T tokens with 2.7M H800 GPU hours to produce the base DeepSeek-V3. But what were those tokens? The paper describes the corpus only in vague ways.</div><br/><div id="42846610" class="c"><input type="checkbox" id="c-42846610" checked=""/><div class="controls bullet"><span class="by">moritonal</span><span>|</span><a href="#42846512">parent</a><span>|</span><a href="#42846839">next</a><span>|</span><label class="collapse" for="c-42846610">[-]</label><label class="expand" for="c-42846610">[1 more]</label></div><br/><div class="children"><div class="content">I imagine it&#x27;s a mix of either using ChatGPT as an the oracle to get training data. Or, it&#x27;s the radiocarbon issue where the Internet has so much info on ChatGPT other models now get confused.</div><br/></div></div><div id="42846839" class="c"><input type="checkbox" id="c-42846839" checked=""/><div class="controls bullet"><span class="by">llm_nerd</span><span>|</span><a href="#42846512">parent</a><span>|</span><a href="#42846610">prev</a><span>|</span><a href="#42846557">next</a><span>|</span><label class="collapse" for="c-42846839">[-]</label><label class="expand" for="c-42846839">[1 more]</label></div><br/><div class="children"><div class="content">Various other models also think they&#x27;re ChatGPT or built by OpenAI, or at least those are the highest probability tokens when talking about an AI model or an AI company because of the massive prevalence in training data (the internet). It isn&#x27;t the big reveal that it is often being held to be.<p>Add that training off of ChatGPT wouldn&#x27;t reduce their training costs at all, but would actually increase their training costs. Literally all of the same training difficulty, but then add paying OpenAI for an enormous number of API calls. Not really seeing the win.<p>&gt;The paper describes the corpus only in vague ways.<p>Anyone who runs a public website has logs absolutely <i>filled</i> by a seemingly infinite number of information aggregators. Just like everyone else they scraped the entire internet, pulled in all of Wikipedia, etc. Probably lots of pirate books, movie transcripts, etc.<p>The fact that training could be done more effectively is something that intuitively makes absolute sense to everyone in the field, but we just didn&#x27;t make that leap. Similar to how a human isn&#x27;t trained to recognize digits by training on 60,000 training digits then suddenly failing if a real world digit is slightly rotated or morphed in some way, we are making these improvements to content ingestion.</div><br/></div></div><div id="42846557" class="c"><input type="checkbox" id="c-42846557" checked=""/><div class="controls bullet"><span class="by">moralestapia</span><span>|</span><a href="#42846512">parent</a><span>|</span><a href="#42846839">prev</a><span>|</span><a href="#42846240">next</a><span>|</span><label class="collapse" for="c-42846557">[-]</label><label class="expand" for="c-42846557">[8 more]</label></div><br/><div class="children"><div class="content">A friend just sent me a screenshot where he asks DeepSeek if it has an app for Mac and it replies that they have a ChatGPT app from OpenAI, lol.<p>I 100% believe they distilled GPT-4, hence the low &quot;training&quot; cost.</div><br/><div id="42846705" class="c"><input type="checkbox" id="c-42846705" checked=""/><div class="controls bullet"><span class="by">Philpax</span><span>|</span><a href="#42846512">root</a><span>|</span><a href="#42846557">parent</a><span>|</span><a href="#42846785">next</a><span>|</span><label class="collapse" for="c-42846705">[-]</label><label class="expand" for="c-42846705">[2 more]</label></div><br/><div class="children"><div class="content">Er, how would that reduce the cost? You still need to train the model, which is the expensive bit.<p>Also, the base model for V3 and the only-RL-tuned R1-Zero are available, and they behave like base models, which seems unlikely if they used data from OpenAI as their primary data source.<p>It&#x27;s much more likely that they&#x27;ve consumed the background radiation of the web, where OpenAI contamination is dominant.</div><br/><div id="42849473" class="c"><input type="checkbox" id="c-42849473" checked=""/><div class="controls bullet"><span class="by">Salgat</span><span>|</span><a href="#42846512">root</a><span>|</span><a href="#42846705">parent</a><span>|</span><a href="#42846785">next</a><span>|</span><label class="collapse" for="c-42849473">[-]</label><label class="expand" for="c-42849473">[1 more]</label></div><br/><div class="children"><div class="content">Hypothetical question: is the chinese government capable of exploiting chatgpt to get around the query limit? For example, making queries through compromised devices or even snooping local traffic on devices? Let&#x27;s face it, these models are closely alligned with China&#x27;s national security so it&#x27;s not a farfetched question to ask.</div><br/></div></div></div></div><div id="42846785" class="c"><input type="checkbox" id="c-42846785" checked=""/><div class="controls bullet"><span class="by">kenjackson</span><span>|</span><a href="#42846512">root</a><span>|</span><a href="#42846557">parent</a><span>|</span><a href="#42846705">prev</a><span>|</span><a href="#42849300">next</a><span>|</span><label class="collapse" for="c-42846785">[-]</label><label class="expand" for="c-42846785">[2 more]</label></div><br/><div class="children"><div class="content">They fixed that.  Now it replies: &quot;Hi! I&#x27;m DeepSeek-V3, an AI assistant independently developed by the Chinese company DeepSeek Inc. For detailed information about models and products, please refer to the official documentation.&quot;</div><br/><div id="42847508" class="c"><input type="checkbox" id="c-42847508" checked=""/><div class="controls bullet"><span class="by">moralestapia</span><span>|</span><a href="#42846512">root</a><span>|</span><a href="#42846785">parent</a><span>|</span><a href="#42849300">next</a><span>|</span><label class="collapse" for="c-42847508">[-]</label><label class="expand" for="c-42847508">[1 more]</label></div><br/><div class="children"><div class="content">???<p>I just did and it told me about ChatGPT and OpenAI.<p>Are you affiliated with them, btw?</div><br/></div></div></div></div><div id="42849300" class="c"><input type="checkbox" id="c-42849300" checked=""/><div class="controls bullet"><span class="by">nullc</span><span>|</span><a href="#42846512">root</a><span>|</span><a href="#42846557">parent</a><span>|</span><a href="#42846785">prev</a><span>|</span><a href="#42847498">next</a><span>|</span><label class="collapse" for="c-42849300">[-]</label><label class="expand" for="c-42849300">[1 more]</label></div><br/><div class="children"><div class="content">You can&#x27;t distill from GPT-4 because Open AI conceals the probabilities (and has for a couple years now-- since before gpt4), presumably to prevent that.  You can fine tune against output though. I might guess that they used something like openorca or some other public data set that includes gpt4 output as part of their initial fine tuning.</div><br/></div></div><div id="42847498" class="c"><input type="checkbox" id="c-42847498" checked=""/><div class="controls bullet"><span class="by">blackeyeblitzar</span><span>|</span><a href="#42846512">root</a><span>|</span><a href="#42846557">parent</a><span>|</span><a href="#42849300">prev</a><span>|</span><a href="#42846240">next</a><span>|</span><label class="collapse" for="c-42847498">[-]</label><label class="expand" for="c-42847498">[2 more]</label></div><br/><div class="children"><div class="content">How does such a distillation work in theory? They don’t have weights from OpenAI’s models, and can only call their APIs, right? So how can they actually build off of it?</div><br/><div id="42850010" class="c"><input type="checkbox" id="c-42850010" checked=""/><div class="controls bullet"><span class="by">moralestapia</span><span>|</span><a href="#42846512">root</a><span>|</span><a href="#42847498">parent</a><span>|</span><a href="#42846240">next</a><span>|</span><label class="collapse" for="c-42850010">[-]</label><label class="expand" for="c-42850010">[1 more]</label></div><br/><div class="children"><div class="content">Like RLHF but the HF part is GPT4 instead.</div><br/></div></div></div></div></div></div></div></div><div id="42846240" class="c"><input type="checkbox" id="c-42846240" checked=""/><div class="controls bullet"><span class="by">caithrin</span><span>|</span><a href="#42846512">prev</a><span>|</span><a href="#42846823">next</a><span>|</span><label class="collapse" for="c-42846240">[-]</label><label class="expand" for="c-42846240">[1 more]</label></div><br/><div class="children"><div class="content">This is fantastic work, thank you!</div><br/></div></div><div id="42847054" class="c"><input type="checkbox" id="c-42847054" checked=""/><div class="controls bullet"><span class="by">youssefabdelm</span><span>|</span><a href="#42846823">prev</a><span>|</span><label class="collapse" for="c-42847054">[-]</label><label class="expand" for="c-42847054">[1 more]</label></div><br/><div class="children"><div class="content">The &quot;illustrated&quot;... He needs to read up on Tufte or Bret Victor or something, these are just diagrams with text inside of boxes.</div><br/></div></div></div></div></div></div></div></body></html>