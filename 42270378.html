<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1732870866314" as="style"/><link rel="stylesheet" href="styles.css?v=1732870866314"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://hez2010.github.io/async-runtimes-benchmarks-2024/">How much memory do you need in 2024 to run 1M concurrent tasks?</a> <span class="domain">(<a href="https://hez2010.github.io">hez2010.github.io</a>)</span></div><div class="subtext"><span>neonsunset</span> | <span>110 comments</span></div><br/><div><div id="42271951" class="c"><input type="checkbox" id="c-42271951" checked=""/><div class="controls bullet"><span class="by">xargon7</span><span>|</span><a href="#42272318">next</a><span>|</span><label class="collapse" for="c-42271951">[-]</label><label class="expand" for="c-42271951">[2 more]</label></div><br/><div class="children"><div class="content">There&#x27;s a difference between &quot;running a task that waits for 10 seconds&quot; and &quot;scheduling a wakeup in 10 seconds&quot;.<p>The code for several of the languages that are low-memory usage that do the second while the high memory usage results do the first. For example, on my machine the article&#x27;s go code uses 2.5GB of memory but the following code uses only 124MB. That difference is in-line with the rust results.<p><pre><code>  package main
  
  import (
    &quot;os&quot;
    &quot;strconv&quot;
    &quot;sync&quot;
    &quot;time&quot;
  )
  
  func main() {
    numRoutines, _ := strconv.Atoi(os.Args[1])
    var wg sync.WaitGroup
    for i := 0; i &lt; numRoutines; i++ {
      wg.Add(1)
      time.AfterFunc(10*time.Second, wg.Done)
    }
    wg.Wait()
  }</code></pre></div><br/><div id="42272012" class="c"><input type="checkbox" id="c-42272012" checked=""/><div class="controls bullet"><span class="by">neonsunset</span><span>|</span><a href="#42271951">parent</a><span>|</span><a href="#42272318">next</a><span>|</span><label class="collapse" for="c-42272012">[-]</label><label class="expand" for="c-42272012">[1 more]</label></div><br/><div class="children"><div class="content">Spawning a periodically waking up Task in .NET (say every 250ms) that performs work like sending out a network request would retain comparable memory usage (in terms of async overhead itself).<p>Even at 100k tasks the bottleneck is going to be the network stack itself (sending outgoing 400k RPS takes a lot of CPU and syscall overhead, even with SocketAsyncEngine!).<p>Doing so in Go would require either spawning Goroutines, or performing scheduling by hand or through some form of aggregation over channel readers. Something that Tasks give you immediately.<p>The concurrency primitive overhead becomes more important if you want to quickly interleave multiple operations at once. In .NET you simply do not await them at callsite until you need their result later - this post showcases how low the overhead of doing so is.</div><br/></div></div></div></div><div id="42272318" class="c"><input type="checkbox" id="c-42272318" checked=""/><div class="controls bullet"><span class="by">jakobnissen</span><span>|</span><a href="#42271951">prev</a><span>|</span><a href="#42271789">next</a><span>|</span><label class="collapse" for="c-42272318">[-]</label><label class="expand" for="c-42272318">[1 more]</label></div><br/><div class="children"><div class="content">Just tried this in Julia: 16.0 GB of memory for 1M tasks!<p>I believe each task in Julia has its own stack, so this makes sense. Still, it does mean you&#x27;ve got to take account of ~16 KB of memory per running task which is not great.</div><br/></div></div><div id="42271789" class="c"><input type="checkbox" id="c-42271789" checked=""/><div class="controls bullet"><span class="by">piterrro</span><span>|</span><a href="#42272318">prev</a><span>|</span><a href="#42270801">next</a><span>|</span><label class="collapse" for="c-42271789">[-]</label><label class="expand" for="c-42271789">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t know what&#x27;s a fair way to do this for all languages listed in the benchmark, but for Go vs Node the only fair way would be to use a single goroutine to schedule timers and another one to pick them up when they tick, this way we don&#x27;t create a huge stack and it&#x27;s much more comparable to what you&#x27;re really doing in Node.<p>Consider the following code:<p>package main<p>import (
    &quot;fmt&quot;
    &quot;os&quot;
    &quot;strconv&quot;
    &quot;time&quot;
)<p>func main() {<p><pre><code>    numTimers, _ := strconv.Atoi(os.Args[1])

    timerChan := make(chan struct{})

    &#x2F;&#x2F; Goroutine 1: Schedule timers
    go func() {
        for i := 0; i &lt; numTimers; i++ {
            timer := time.NewTimer(10 * time.Second)
            go func(t *time.Timer) {
                &lt;-t.C
                timerChan &lt;- struct{}{}
            }(timer)
        }
    }()

    &#x2F;&#x2F; Goroutine 2: Receive and process timer signals
    for i := 0; i &lt; numTimers; i++ {
        &lt;-timerChan
    }</code></pre>
}<p>Also for Node it&#x27;s weird not to have Bun and Deno included. I suppose you can have other runtimes for other languages too.<p>In the end I think this benchmark is comparing different things and not really useful for anything...</div><br/></div></div><div id="42270801" class="c"><input type="checkbox" id="c-42270801" checked=""/><div class="controls bullet"><span class="by">AkshitGarg</span><span>|</span><a href="#42271789">prev</a><span>|</span><a href="#42272292">next</a><span>|</span><label class="collapse" for="c-42270801">[-]</label><label class="expand" for="c-42270801">[33 more]</label></div><br/><div class="children"><div class="content">I feel this benchmark compares apples to oranges in some cases.<p>For example, for node, the author puts a million promises into the runtime event loop and uses `Promise.all` to wait for them all.<p>This is very different from, say, the Go version where the author creates a million goroutines and puts `waitgroup.Done` as a defer call.<p>While this might be the idiomatic way of concurrency in the respective languages, it does not account for how goroutines are fundamentally different from promises, and how the runtime does things differently. For JS, there&#x27;s a single event loop. Counting the JS execution threads, the event loop thread and whatever else the runtime uses for async I&#x2F;O, the execution model is fundamentally different from Go. Go (if not using `GOMAXPROCS`) spawns an OS thread for every physical thread that your machine has, and then uses a userspace scheduler to distribute goroutines to those threads. It may spawn more OS threads to account for OS threads sleeping on syscalls. Although I don&#x27;t think the runtime will spawn extra threads in this case.<p>It also depends on what the &quot;concurrent tasks&quot; (I know, concurrency != parallelism) are. Tasks such as reading a file or doing a network call are better done with something like promises, but CPU-bound tasks are better done with goroutines or Node worker_threads. It would be interesting to see how the memory usage changes when doing async I&#x2F;O vs CPU-bound tasks concurrently in different languages.</div><br/><div id="42271121" class="c"><input type="checkbox" id="c-42271121" checked=""/><div class="controls bullet"><span class="by">n2d4</span><span>|</span><a href="#42270801">parent</a><span>|</span><a href="#42270895">next</a><span>|</span><label class="collapse" for="c-42271121">[-]</label><label class="expand" for="c-42271121">[18 more]</label></div><br/><div class="children"><div class="content">Actually, I think this benchmark did the right thing, that I wish more benchmarks would do. I&#x27;m much less interested in what the differences between compilers 
are than in what the actual output will be if I ask a professional Go or Node.js dev to solve the same task. (TBF, it would&#x27;ve been better if the task benchmarked was something useful, eg. handling an HTTP request.)<p>Go heavily encourages a certain kind of programming; JavaScript heavily encourages  a different kind; and the article does a great job at showing what the consequences are.</div><br/><div id="42271585" class="c"><input type="checkbox" id="c-42271585" checked=""/><div class="controls bullet"><span class="by">rtpg</span><span>|</span><a href="#42270801">root</a><span>|</span><a href="#42271121">parent</a><span>|</span><a href="#42271220">next</a><span>|</span><label class="collapse" for="c-42271585">[-]</label><label class="expand" for="c-42271585">[4 more]</label></div><br/><div class="children"><div class="content">But you wouldn&#x27;t call a million tasks with `Promise.all` in Node, right? That&#x27;s just not a thing that one does.<p>Instead, there&#x27;s usually going to be some queue outside the VM that will leave you with _some_ sort of chunking and otherwise working in smaller, more manageable bits (that might, incidentally, be shaped in ways that the VM can handle in interesting ways).<p>It&#x27;s definitely true to say that the &quot;idioamatic&quot; way of handling things is worth going into, but if part of your synthetic benchmark involves doing something quite out of the ordinary, it feels suspicious.<p>I generally agree that a &quot;real&quot; benchmark here would be nice. It would be interesting if someone could come up with the &quot;minimum viable non-trivial business logic&quot; that people could use for these benchmarks (perhaps coupled with automation tooling to run the benchmarks)</div><br/><div id="42271622" class="c"><input type="checkbox" id="c-42271622" checked=""/><div class="controls bullet"><span class="by">hamandcheese</span><span>|</span><a href="#42270801">root</a><span>|</span><a href="#42271585">parent</a><span>|</span><a href="#42271220">next</a><span>|</span><label class="collapse" for="c-42271622">[-]</label><label class="expand" for="c-42271622">[3 more]</label></div><br/><div class="children"><div class="content">&gt; But you wouldn&#x27;t call a million tasks with `Promise.all` in Node, right? That&#x27;s just not a thing that one does.<p>But neither would you wait on a waitgroup of size 1 million in Go... right?</div><br/><div id="42271917" class="c"><input type="checkbox" id="c-42271917" checked=""/><div class="controls bullet"><span class="by">ricardobeat</span><span>|</span><a href="#42270801">root</a><span>|</span><a href="#42271622">parent</a><span>|</span><a href="#42271751">next</a><span>|</span><label class="collapse" for="c-42271917">[-]</label><label class="expand" for="c-42271917">[1 more]</label></div><br/><div class="children"><div class="content">You could, and the tasks would run concurrently. Node is single threaded so unless you used one of the I&#x2F;O calls backed by a thread pool, they would all execute sequentially .</div><br/></div></div><div id="42271751" class="c"><input type="checkbox" id="c-42271751" checked=""/><div class="controls bullet"><span class="by">rtpg</span><span>|</span><a href="#42270801">root</a><span>|</span><a href="#42271622">parent</a><span>|</span><a href="#42271917">prev</a><span>|</span><a href="#42271220">next</a><span>|</span><label class="collapse" for="c-42271751">[-]</label><label class="expand" for="c-42271751">[1 more]</label></div><br/><div class="children"><div class="content">yeah, right? I mean I don&#x27;t have a dog in this race, just wished we could get into &quot;normal&quot; repros without having to wonder if some magic is kicking in</div><br/></div></div></div></div></div></div><div id="42271220" class="c"><input type="checkbox" id="c-42271220" checked=""/><div class="controls bullet"><span class="by">Quothling</span><span>|</span><a href="#42270801">root</a><span>|</span><a href="#42271121">parent</a><span>|</span><a href="#42271585">prev</a><span>|</span><a href="#42271501">next</a><span>|</span><label class="collapse" for="c-42271220">[-]</label><label class="expand" for="c-42271220">[12 more]</label></div><br/><div class="children"><div class="content">&gt; Go heavily encourages a certain kind of programming;<p>True, but it really doesn&#x27;t encourage you to run 1m goroutines with the standard memory setting. Though it&#x27;s probably fair to run Go wastefully when you&#x27;re comparing it to Promise.All.</div><br/><div id="42271230" class="c"><input type="checkbox" id="c-42271230" checked=""/><div class="controls bullet"><span class="by">n2d4</span><span>|</span><a href="#42270801">root</a><span>|</span><a href="#42271220">parent</a><span>|</span><a href="#42271501">next</a><span>|</span><label class="collapse" for="c-42271230">[-]</label><label class="expand" for="c-42271230">[11 more]</label></div><br/><div class="children"><div class="content">Of course! That&#x27;s why the article is telling you that some languages (C#, Rust) are better at it than others (Go, Java). Doesn&#x27;t mean that Go and Java are bad languages! Just that they aren&#x27;t good to do this thing.</div><br/><div id="42271338" class="c"><input type="checkbox" id="c-42271338" checked=""/><div class="controls bullet"><span class="by">Quothling</span><span>|</span><a href="#42270801">root</a><span>|</span><a href="#42271230">parent</a><span>|</span><a href="#42271501">next</a><span>|</span><label class="collapse" for="c-42271338">[-]</label><label class="expand" for="c-42271338">[10 more]</label></div><br/><div class="children"><div class="content">The article is telling us that you can run really inefficient code. Goroutines should be run with worker pools and a buffered channel and it&#x27;s silly to not do that and then compare it to things like an optimized Rust crate like Tokio.</div><br/><div id="42271400" class="c"><input type="checkbox" id="c-42271400" checked=""/><div class="controls bullet"><span class="by">Aeolun</span><span>|</span><a href="#42270801">root</a><span>|</span><a href="#42271338">parent</a><span>|</span><a href="#42271501">next</a><span>|</span><label class="collapse" for="c-42271400">[-]</label><label class="expand" for="c-42271400">[9 more]</label></div><br/><div class="children"><div class="content">Is that the ideomatic way to do it, or the best way you can imagine?</div><br/><div id="42271413" class="c"><input type="checkbox" id="c-42271413" checked=""/><div class="controls bullet"><span class="by">Quothling</span><span>|</span><a href="#42270801">root</a><span>|</span><a href="#42271400">parent</a><span>|</span><a href="#42271501">next</a><span>|</span><label class="collapse" for="c-42271413">[-]</label><label class="expand" for="c-42271413">[8 more]</label></div><br/><div class="children"><div class="content">&gt; Is that the ideomatic way to do it<p>Well... I&#x27;m actually not sure what ideomatic means (English isn&#x27;t my first language), but it&#x27;s the standard way of doing it. You&#x27;ll even find it as step 2 and 3 here: <a href="https:&#x2F;&#x2F;go.dev&#x2F;tour&#x2F;concurrency&#x2F;1" rel="nofollow">https:&#x2F;&#x2F;go.dev&#x2F;tour&#x2F;concurrency&#x2F;1</a><p>&gt; or the best way you can imagine<p>I would do a lot much more to tune it if you were in a position where you&#x27;d know it would run that many &quot;tasks&quot;. I think what many non-Go programmers might run into here is that Go doesn&#x27;t come with any sort of &quot;magic&quot;. Instead it comes with a highly opinionated way of doing things. Compare that to C# which comes with a highly optimized CLR and a bunch really excellent libraries which are continuously optimized by Microsoft and you&#x27;re going to end up with an article like this. The async libraries are maintaining which tasks are running (though Promise.All is obviously also binding a huge amount of memory you don&#x27;t have to), while the Go example is running 1 million at once.<p>You&#x27;ll also notice that there is no benchmark for execution time. With Go you might actually want to pay with memory, though I&#x27;d argue that you&#x27;d almost never want to run 1 million Goroutines at once.<p>Though to be fair to this specific author, it looks like they copied the previous benchmarks and then ran it as-is.</div><br/><div id="42271712" class="c"><input type="checkbox" id="c-42271712" checked=""/><div class="controls bullet"><span class="by">pbhjpbhj</span><span>|</span><a href="#42270801">root</a><span>|</span><a href="#42271413">parent</a><span>|</span><a href="#42271520">next</a><span>|</span><label class="collapse" for="c-42271712">[-]</label><label class="expand" for="c-42271712">[2 more]</label></div><br/><div class="children"><div class="content">Idiomatic is the word the parent was looking for. The base word is idiom.<p>It was probably the intent of the parent to mean &#x27;making use of the particular features of the language that are not necessarily common to other languages&#x27;.<p>I&#x27;m not a programmer, but you appear to give good examples.<p>I hope I&#x27;m not teaching you to suck eggs... {That&#x27;s an idiom, meaning teaching someone something they&#x27;re already expert in. Like teaching your Grandma to suck eggs - which weirdly means blowing out the insides of a raw egg. That&#x27;s done when using the egg to paint; which is a traditional Easter craft.}</div><br/><div id="42271788" class="c"><input type="checkbox" id="c-42271788" checked=""/><div class="controls bullet"><span class="by">Quothling</span><span>|</span><a href="#42270801">root</a><span>|</span><a href="#42271712">parent</a><span>|</span><a href="#42271520">next</a><span>|</span><label class="collapse" for="c-42271788">[-]</label><label class="expand" for="c-42271788">[1 more]</label></div><br/><div class="children"><div class="content">I actually did find &quot;idiomatic&quot; when I looked it up, but I honestly still didn&#x27;t quite grasp it from the cambridge dictionary. Thanks for explaining it in a way I understand.</div><br/></div></div></div></div><div id="42271520" class="c"><input type="checkbox" id="c-42271520" checked=""/><div class="controls bullet"><span class="by">guitarbill</span><span>|</span><a href="#42270801">root</a><span>|</span><a href="#42271413">parent</a><span>|</span><a href="#42271712">prev</a><span>|</span><a href="#42271534">next</a><span>|</span><label class="collapse" for="c-42271520">[-]</label><label class="expand" for="c-42271520">[2 more]</label></div><br/><div class="children"><div class="content">The post was edited, previously it just said roughly this part: &quot;step 2 and 3 here: <a href="https:&#x2F;&#x2F;go.dev&#x2F;tour&#x2F;concurrency&#x2F;1" rel="nofollow">https:&#x2F;&#x2F;go.dev&#x2F;tour&#x2F;concurrency&#x2F;1</a>&quot;. Which - as far as I can tell - does not mention worker pools...</div><br/><div id="42271758" class="c"><input type="checkbox" id="c-42271758" checked=""/><div class="controls bullet"><span class="by">Quothling</span><span>|</span><a href="#42270801">root</a><span>|</span><a href="#42271520">parent</a><span>|</span><a href="#42271534">next</a><span>|</span><label class="collapse" for="c-42271758">[-]</label><label class="expand" for="c-42271758">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;re right. It is using channels and buffers, but you&#x27;re right.<p>It&#x27;s not part of the actual documentation either, at least not exactly: <a href="https:&#x2F;&#x2F;go.dev&#x2F;doc&#x2F;effective_go#concurrency" rel="nofollow">https:&#x2F;&#x2F;go.dev&#x2F;doc&#x2F;effective_go#concurrency</a> You will achieve much the same if you follow it, but my answer should have been yes and no as far as being the &quot;standard&quot; Go way.</div><br/></div></div></div></div><div id="42271534" class="c"><input type="checkbox" id="c-42271534" checked=""/><div class="controls bullet"><span class="by">jchw</span><span>|</span><a href="#42270801">root</a><span>|</span><a href="#42271413">parent</a><span>|</span><a href="#42271520">prev</a><span>|</span><a href="#42271501">next</a><span>|</span><label class="collapse" for="c-42271534">[-]</label><label class="expand" for="c-42271534">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;m torn.<p>As far as practicality goes I actually agree with you: if I knew I were trying to do something to the order of 1,000,000 tasks in Go I would probably use a worker pool for this exact reason. I have done this pattern in Go. It is certainly not unidiomatic.<p>However, it also isn&#x27;t the obvious way to do 1,000,000 things concurrently in Go. The obvious way to do 1,000,000 things concurrently in Go is to do a for loop and launch a Goroutine for each thing. It is the native unit of task. It is very tightly tied to how I&#x2F;O works in Go.<p>If you are trying to do something like a web server, then the calculus changes a lot. In Go, due to the way I&#x2F;O works, you really can&#x27;t do much but have a goroutine or two per connection. However, on the other hand, the overhead that goroutines imply starts to look a lot smaller once you put real workloads on each of the millions of tasks.<p>This benchmark really does tell you something about the performance and overhead of the Go programming language, but it won&#x27;t necessarily translate to production workloads the way that it seems like it will. In real workloads where the tasks themselves are usually a lot heavier than the constant cost per task, I actually suspect <i>other</i> issues with Go are likely to crop up first (especially in performance critical contexts, latency.) So realistically, it would probably be a bad idea to extrapolate from a benchmark this synthetic to try to determine anything about real world workloads.<p>Ultimately though, for whatever purpose a synthetic benchmark like this <i>does</i> serve, I think they did the correct thing. I guess I just wonder exactly what the point of it is. Like, the optimized Rust example uses around 0.12 KiB <i>per task</i>. That&#x27;s extremely cool, but where in the real world are you going to find tasks where the actual state doesn&#x27;t completely eclipse that metric? Meanwhile, Go is using around 2.64 KiB per task. 22x larger than Rust as it may be, it&#x27;s still not very much. I think for most real world cases, you would struggle to find too many tasks where the working set per task is actually that small. Of course, if you <i>do</i>, then I&#x27;d reckon optimized async Rust will be a true barn-burner at the task, and a lot of those cases where <i>every byte and millisecond counts</i>, Go does often lose. There are many examples.[1]<p>In many cases Go is far from optimal: Channels, goroutines, the regex engine, various codec implementations in the standard library, etc. are all far from the most optimal implementation you could imagine. However, I feel like they usually do a good job making the performance very sufficient for a wide range of real world tasks. They have made some tradeoffs that a lot of us find very practical and sensible and it makes Go feel like a language you can usually depend on. I think this is especially true in a world where it was already fine when you can run huge websites on Python + Django and other stacks that are relatively much less efficient in memory and CPU usage than Go.<p>I&#x27;ll tell you what this benchmark tells me <i>really</i> though: C# is seriously impressive.<p>[1]: <a href="https:&#x2F;&#x2F;discord.com&#x2F;blog&#x2F;why-discord-is-switching-from-go-to-rust" rel="nofollow">https:&#x2F;&#x2F;discord.com&#x2F;blog&#x2F;why-discord-is-switching-from-go-to...</a></div><br/><div id="42271828" class="c"><input type="checkbox" id="c-42271828" checked=""/><div class="controls bullet"><span class="by">Quothling</span><span>|</span><a href="#42270801">root</a><span>|</span><a href="#42271534">parent</a><span>|</span><a href="#42271501">next</a><span>|</span><label class="collapse" for="c-42271828">[-]</label><label class="expand" for="c-42271828">[2 more]</label></div><br/><div class="children"><div class="content">I agree with everything you said and I think you contributed a lot to what I said making things much more clear.<p>&gt; I&#x27;ll tell you what this benchmark tells me really though: C# is seriously impressive.<p>The C# team has done some really great work in recent years. I personally hate working with it and it&#x27;s &quot;magic&quot;, but it&#x27;s certainly in a very good place as far as trusting the CLR to &quot;just work&quot;.<p>Hilariously I also found the Python benchmark to be rather impressive. I was expecting much worse. Not knowing Python well enough, however, makes it hard to really &quot;trust&quot; the benchmark. A talented Python team might be capable of reducing memory usage as much as following every step of the Go concurrency tour would for Go.</div><br/><div id="42271902" class="c"><input type="checkbox" id="c-42271902" checked=""/><div class="controls bullet"><span class="by">neonsunset</span><span>|</span><a href="#42270801">root</a><span>|</span><a href="#42271828">parent</a><span>|</span><a href="#42271501">next</a><span>|</span><label class="collapse" for="c-42271902">[-]</label><label class="expand" for="c-42271902">[1 more]</label></div><br/><div class="children"><div class="content">Userspace scheduling of Goroutines, virtual stack and non-deterministic pointer type allocation in Go are as much magic if not more, the syntactic sugar of C# is there to get the language out of your way and usually comes at no cost :)<p>If you do not like the aesthetics of C# and find Elixir or OCaml family tolerable - perhaps try F#? If you use task CEs there you end up with roughly the same performance profile and get to access huge ecosystem making it one of the few FP languages that can be used in production with minimal risk.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="42271501" class="c"><input type="checkbox" id="c-42271501" checked=""/><div class="controls bullet"><span class="by">YetAnotherNick</span><span>|</span><a href="#42270801">root</a><span>|</span><a href="#42271121">parent</a><span>|</span><a href="#42271220">prev</a><span>|</span><a href="#42270895">next</a><span>|</span><label class="collapse" for="c-42271501">[-]</label><label class="expand" for="c-42271501">[1 more]</label></div><br/><div class="children"><div class="content">The fundamental problem is there are two kind of sleep function. One that actually sleeps and other that is a actually a timer that just calls certain callback after a desired interval. Promise is just a syntactic sugar on top of second type. Go certainly could call another function after desired interval using `Timer`.<p>I think better comparison would be wasting CPU for 10 seconds instead of sleep.</div><br/></div></div></div></div><div id="42270895" class="c"><input type="checkbox" id="c-42270895" checked=""/><div class="controls bullet"><span class="by">SPascareli13</span><span>|</span><a href="#42270801">parent</a><span>|</span><a href="#42271121">prev</a><span>|</span><a href="#42271041">next</a><span>|</span><label class="collapse" for="c-42270895">[-]</label><label class="expand" for="c-42270895">[3 more]</label></div><br/><div class="children"><div class="content">As far as I know there is no way to do Promise like async in go, you HAVE to create a goroutine for each concurrent async task. If this is really the case then I believe the submition is valid.<p>But I do think that spawning a goroutine just to do a non-blocking task and get its return is kinda wasteful.</div><br/><div id="42271166" class="c"><input type="checkbox" id="c-42271166" checked=""/><div class="controls bullet"><span class="by">n2d4</span><span>|</span><a href="#42270801">root</a><span>|</span><a href="#42270895">parent</a><span>|</span><a href="#42271041">next</a><span>|</span><label class="collapse" for="c-42271166">[-]</label><label class="expand" for="c-42271166">[2 more]</label></div><br/><div class="children"><div class="content">You could in theory create your own event loop and then get the exact same behaviour as Promises in Go, but you probably shouldn&#x27;t. Goroutines are the way to do this in Go, and it wouldn&#x27;t be useful to benchmark code that would never be written in real life.</div><br/><div id="42271249" class="c"><input type="checkbox" id="c-42271249" checked=""/><div class="controls bullet"><span class="by">peterhon</span><span>|</span><a href="#42270801">root</a><span>|</span><a href="#42271166">parent</a><span>|</span><a href="#42271041">next</a><span>|</span><label class="collapse" for="c-42271249">[-]</label><label class="expand" for="c-42271249">[1 more]</label></div><br/><div class="children"><div class="content">I guess what you can do in golang that would be very similar to the rust impl would be this (and could be helpful even in real life, if all you need is a whole lot of timers):<p><pre><code>  func test2(count int) {
  
   timers := make([]*time.Timer,count)
   for idx, _ := range timers {
    timers[idx] = time.NewTimer(10 * time.Second)
   }
   for idx, _ := range timers {
    &lt;-timers[idx].C
   }
  }
</code></pre>
This yields to 263552 Maximum resident set size (kbytes) according to &#x2F;usr&#x2F;bin&#x2F;time -v<p>I&#x27;m not sure if I missed it, but I don&#x27;t see the benchmark specify how the memory was measured, so I assumed the time -v.</div><br/></div></div></div></div></div></div><div id="42271041" class="c"><input type="checkbox" id="c-42271041" checked=""/><div class="controls bullet"><span class="by">threeseed</span><span>|</span><a href="#42270801">parent</a><span>|</span><a href="#42270895">prev</a><span>|</span><a href="#42271392">next</a><span>|</span><label class="collapse" for="c-42271041">[-]</label><label class="expand" for="c-42271041">[9 more]</label></div><br/><div class="children"><div class="content">The requirement is to run 1 million concurrent tasks.<p>Of course each language will have a different way of achieving this task each of which will have their unique pros&#x2F;cons. That&#x27;s why we have these different languages to begin with.</div><br/><div id="42271206" class="c"><input type="checkbox" id="c-42271206" checked=""/><div class="controls bullet"><span class="by">jakewins</span><span>|</span><a href="#42270801">root</a><span>|</span><a href="#42271041">parent</a><span>|</span><a href="#42271276">next</a><span>|</span><label class="collapse" for="c-42271206">[-]</label><label class="expand" for="c-42271206">[6 more]</label></div><br/><div class="children"><div class="content">The accounting here is weird though; Go isn’t using that RAM, it’s expecting the application to. The reason that doesn’t happen is because it’s a micro benchmark that produces no useful work..<p>The way the results are presented a reader may think the Go memory usage sounds equivalent to the others - boilerplate, ticket-to-play - and then the Go usage sounds super high.<p>But they are not the same; that memory is in anticipation of a real world program using it</div><br/><div id="42271411" class="c"><input type="checkbox" id="c-42271411" checked=""/><div class="controls bullet"><span class="by">Aeolun</span><span>|</span><a href="#42270801">root</a><span>|</span><a href="#42271206">parent</a><span>|</span><a href="#42271276">next</a><span>|</span><label class="collapse" for="c-42271411">[-]</label><label class="expand" for="c-42271411">[5 more]</label></div><br/><div class="children"><div class="content">Isn’t that kind of dumb when none of the other languages do this? Apparently allocating memory is really fast? Maybe we should change the test to load 1MB of data in every task?</div><br/><div id="42271527" class="c"><input type="checkbox" id="c-42271527" checked=""/><div class="controls bullet"><span class="by">melodyogonna</span><span>|</span><a href="#42270801">root</a><span>|</span><a href="#42271411">parent</a><span>|</span><a href="#42271554">next</a><span>|</span><label class="collapse" for="c-42271527">[-]</label><label class="expand" for="c-42271527">[3 more]</label></div><br/><div class="children"><div class="content">Most of those languages (excepting Java virtual threads) uses stackless coroutines. Go uses stackful coroutines which allocates some memory upfront for a goroutine to use</div><br/><div id="42271867" class="c"><input type="checkbox" id="c-42271867" checked=""/><div class="controls bullet"><span class="by">gpderetta</span><span>|</span><a href="#42270801">root</a><span>|</span><a href="#42271527">parent</a><span>|</span><a href="#42271554">next</a><span>|</span><label class="collapse" for="c-42271867">[-]</label><label class="expand" for="c-42271867">[2 more]</label></div><br/><div class="children"><div class="content">Then it is fair to compare the memory usage of a stackful coroutine to a stack less one as they are the idiomatic way to perform async task on each language.</div><br/><div id="42272194" class="c"><input type="checkbox" id="c-42272194" checked=""/><div class="controls bullet"><span class="by">jakewins</span><span>|</span><a href="#42270801">root</a><span>|</span><a href="#42271867">parent</a><span>|</span><a href="#42271554">next</a><span>|</span><label class="collapse" for="c-42272194">[-]</label><label class="expand" for="c-42272194">[1 more]</label></div><br/><div class="children"><div class="content">I mean this is subjective, but  as long as it’s clear that one number is “this is the memory the runtime itself consumes to solve this problem” and the other number is “this is the runtime memory use <i>and</i> it includes pre-allocated stack space that a real application would then use”, sure<p>Point being: Someone reading this to choose which runtime will fit their use case needs to be carefully to not assume the numbers measure the same thing. For some real world use cases the pre allocated stack will perform better than the runtimes that instead will do heap allocations.</div><br/></div></div></div></div></div></div><div id="42271554" class="c"><input type="checkbox" id="c-42271554" checked=""/><div class="controls bullet"><span class="by">perryizgr8</span><span>|</span><a href="#42270801">root</a><span>|</span><a href="#42271411">parent</a><span>|</span><a href="#42271527">prev</a><span>|</span><a href="#42271276">next</a><span>|</span><label class="collapse" for="c-42271554">[-]</label><label class="expand" for="c-42271554">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Apparently allocating memory is really fast?<p>Apart from i&#x2F;o, allocating memory is usually the slowest thing you can do on a computer, in my experience.</div><br/></div></div></div></div></div></div><div id="42271276" class="c"><input type="checkbox" id="c-42271276" checked=""/><div class="controls bullet"><span class="by">lmm</span><span>|</span><a href="#42270801">root</a><span>|</span><a href="#42271041">parent</a><span>|</span><a href="#42271206">prev</a><span>|</span><a href="#42271259">next</a><span>|</span><label class="collapse" for="c-42271276">[-]</label><label class="expand" for="c-42271276">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The requirement is to run 1 million concurrent tasks.<p>That&#x27;s not a real requirement though. No business actually needs to run 1 million concurrent tasks with no concern for what&#x27;s in them.</div><br/></div></div></div></div><div id="42271392" class="c"><input type="checkbox" id="c-42271392" checked=""/><div class="controls bullet"><span class="by">gleenn</span><span>|</span><a href="#42270801">parent</a><span>|</span><a href="#42271041">prev</a><span>|</span><a href="#42272292">next</a><span>|</span><label class="collapse" for="c-42271392">[-]</label><label class="expand" for="c-42271392">[2 more]</label></div><br/><div class="children"><div class="content">Also, for Java, Virtual Threads are a very new feature (Java 21 IIRC or somewhere around there). OS threads have been around for decades. As a heavy JVM user it would have been nice to actually see those both broken out to compare as well!</div><br/><div id="42271498" class="c"><input type="checkbox" id="c-42271498" checked=""/><div class="controls bullet"><span class="by">codetiger</span><span>|</span><a href="#42270801">root</a><span>|</span><a href="#42271392">parent</a><span>|</span><a href="#42272292">next</a><span>|</span><label class="collapse" for="c-42271498">[-]</label><label class="expand" for="c-42271498">[1 more]</label></div><br/><div class="children"><div class="content">The original benchmark had the comparison between Java thread and Java Virtual thread. <a href="https:&#x2F;&#x2F;pkolaczk.github.io&#x2F;memory-consumption-of-async&#x2F;" rel="nofollow">https:&#x2F;&#x2F;pkolaczk.github.io&#x2F;memory-consumption-of-async&#x2F;</a></div><br/></div></div></div></div></div></div><div id="42272292" class="c"><input type="checkbox" id="c-42272292" checked=""/><div class="controls bullet"><span class="by">piokoch</span><span>|</span><a href="#42270801">prev</a><span>|</span><a href="#42271794">next</a><span>|</span><label class="collapse" for="c-42272292">[-]</label><label class="expand" for="c-42272292">[1 more]</label></div><br/><div class="children"><div class="content">It seems there are just two clubs: you go with bare metal (Rust, C# native AOT) or you use some higher level abstraction (virtual machine, garbage collector) and then there is no significant difference between Java, Node, Go or Python.<p>For me Python worked surprisingly well, while Go was surprisingly high on memory consumption.</div><br/></div></div><div id="42271794" class="c"><input type="checkbox" id="c-42271794" checked=""/><div class="controls bullet"><span class="by">blixt</span><span>|</span><a href="#42272292">prev</a><span>|</span><a href="#42271903">next</a><span>|</span><label class="collapse" for="c-42271794">[-]</label><label class="expand" for="c-42271794">[3 more]</label></div><br/><div class="children"><div class="content">While it’s nice to compare languages with simple idiomatic code I think it’s unfair to developers to show them the performance of an entirely empty function body and graphs with bars that focus on only one variable. It paints a picture that you can safely pick language X because it had the smaller bar.<p>I urge anyone making decisions from looking at these graphs to run this benchmark themselves and add two things:<p>- Add at least the most minimal real world task inside of these function bodies to get a better feel for how the languages use memory<p>- Measure the duration in addition to the memory to get a feel for the difference in scheduling between the languages</div><br/><div id="42271831" class="c"><input type="checkbox" id="c-42271831" checked=""/><div class="controls bullet"><span class="by">tossandthrow</span><span>|</span><a href="#42271794">parent</a><span>|</span><a href="#42271903">next</a><span>|</span><label class="collapse" for="c-42271831">[-]</label><label class="expand" for="c-42271831">[2 more]</label></div><br/><div class="children"><div class="content">This urge is as old as statistics. And I dare to say that most people after reading the article in question are well prepared to use the results for what they are.</div><br/><div id="42271878" class="c"><input type="checkbox" id="c-42271878" checked=""/><div class="controls bullet"><span class="by">blixt</span><span>|</span><a href="#42271794">root</a><span>|</span><a href="#42271831">parent</a><span>|</span><a href="#42271903">next</a><span>|</span><label class="collapse" for="c-42271878">[-]</label><label class="expand" for="c-42271878">[1 more]</label></div><br/><div class="children"><div class="content">I can’t say I share your optimism. I’ve seen plenty of developers point to graphs like these as a reason for why they picked a language or framework for a problem. And it comes down to the benchmark how good of a proxy it actually is for such problems. I just hope that with enough feedback the author would consider making the benchmark more nuanced to paint a picture of why these differences in languages exist (as opposed to saying which languages “lose” or “win”).</div><br/></div></div></div></div></div></div><div id="42271903" class="c"><input type="checkbox" id="c-42271903" checked=""/><div class="controls bullet"><span class="by">jeswin</span><span>|</span><a href="#42271794">prev</a><span>|</span><a href="#42272231">next</a><span>|</span><label class="collapse" for="c-42271903">[-]</label><label class="expand" for="c-42271903">[1 more]</label></div><br/><div class="children"><div class="content">Good to see NativeAOT getting positive press.<p>Go won because it served a need felt by many programmers: a garbage-collected language which compiled to native code, with robust libraries supported by a large corp.<p>With Native AOT, C# is walking into the same space. With arguably better library selection, equivalent performance, and native code compilation. And a much more powerful, well-thought-out language - at a slight complexity cost. If you&#x27;re starting a project today (with the luxury of choosing a language), you should give C# + NativeAOT a consideration.</div><br/></div></div><div id="42272231" class="c"><input type="checkbox" id="c-42272231" checked=""/><div class="controls bullet"><span class="by">nolist_policy</span><span>|</span><a href="#42271903">prev</a><span>|</span><a href="#42271291">next</a><span>|</span><label class="collapse" for="c-42272231">[-]</label><label class="expand" for="c-42272231">[1 more]</label></div><br/><div class="children"><div class="content">Reminds me of the famous<p><pre><code>  SCO: &quot;thread creation is about a thousand times faster than on native Linux&quot;
</code></pre>
linux kernel mailing list thread where Linus Torvalds replies<p><pre><code>  Talk is cheap. Show me the code.
</code></pre>
<a href="https:&#x2F;&#x2F;lkml.org&#x2F;lkml&#x2F;2000&#x2F;8&#x2F;25&#x2F;132" rel="nofollow">https:&#x2F;&#x2F;lkml.org&#x2F;lkml&#x2F;2000&#x2F;8&#x2F;25&#x2F;132</a><p><a href="https:&#x2F;&#x2F;lkml.org&#x2F;lkml&#x2F;2000&#x2F;8&#x2F;26&#x2F;52" rel="nofollow">https:&#x2F;&#x2F;lkml.org&#x2F;lkml&#x2F;2000&#x2F;8&#x2F;26&#x2F;52</a></div><br/></div></div><div id="42271291" class="c"><input type="checkbox" id="c-42271291" checked=""/><div class="controls bullet"><span class="by">Mawr</span><span>|</span><a href="#42272231">prev</a><span>|</span><a href="#42270775">next</a><span>|</span><label class="collapse" for="c-42271291">[-]</label><label class="expand" for="c-42271291">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Now Go loses by over 13 times to the winner. It also loses by over 2 times to Java, which contradicts the general perception of the JVM being a memory hog and Go being lightweight.<p>Well, if it isn&#x27;t the classic unwavering confidence that an artificial &quot;hello world&quot;-like benchmark is in any way representative of real world programs.</div><br/></div></div><div id="42270775" class="c"><input type="checkbox" id="c-42270775" checked=""/><div class="controls bullet"><span class="by">theamk</span><span>|</span><a href="#42271291">prev</a><span>|</span><a href="#42270788">next</a><span>|</span><label class="collapse" for="c-42270775">[-]</label><label class="expand" for="c-42270775">[3 more]</label></div><br/><div class="children"><div class="content">&gt; high number of concurrent tasks can consume a significant amount of memory<p>note absolute numbers here: in the worst case, 1M tasks consumed 2.7 GB of RAM, with ~2700 bytes overhead per task. That&#x27;d still fit in the cheapest server with room to spare.<p>My conclusion would be opposite: as long as per-task data is more than a few KB, the memory overhead of task scheduler is negligible.</div><br/><div id="42271509" class="c"><input type="checkbox" id="c-42271509" checked=""/><div class="controls bullet"><span class="by">pkulak</span><span>|</span><a href="#42270775">parent</a><span>|</span><a href="#42270788">next</a><span>|</span><label class="collapse" for="c-42271509">[-]</label><label class="expand" for="c-42271509">[2 more]</label></div><br/><div class="children"><div class="content">Except it’s more than that. Go and Java maintain a stack for every virtual thread. They are clever about it, but it’s very possible that doing anything more than a sleep would have blown up memory on those two systems.</div><br/><div id="42271596" class="c"><input type="checkbox" id="c-42271596" checked=""/><div class="controls bullet"><span class="by">bilbo0s</span><span>|</span><a href="#42270775">root</a><span>|</span><a href="#42271509">parent</a><span>|</span><a href="#42270788">next</a><span>|</span><label class="collapse" for="c-42271596">[-]</label><label class="expand" for="c-42271596">[1 more]</label></div><br/><div class="children"><div class="content">I have a sneaky suspicion if you do anything other than the sleep during these 1 million tasks, you&#x27;ll blow up memory on all of these systems.<p>That&#x27;s kind of the Achille&#x27;s Heel of the benchmark. Any business needing to spawn 1 million tasks, certainly wants to do something on them. It&#x27;s the &quot;do something on them&quot; part that usually leads to difficulties for these things. Not really the &quot;spawn a million tasks&quot; part.</div><br/></div></div></div></div></div></div><div id="42270788" class="c"><input type="checkbox" id="c-42270788" checked=""/><div class="controls bullet"><span class="by">cperciva</span><span>|</span><a href="#42270775">prev</a><span>|</span><a href="#42272136">next</a><span>|</span><label class="collapse" for="c-42270788">[-]</label><label class="expand" for="c-42270788">[20 more]</label></div><br/><div class="children"><div class="content">This depends a lot on how you define &quot;concurrent tasks&quot;, but the article provides a definition:<p><i>Let&#x27;s launch N concurrent tasks, where each task waits for 10 seconds and then the program exists after all tasks finish. The number of tasks is controlled by the command line argument.</i><p>Leaving aside semantics like &quot;since the tasks aren&#x27;t specified as doing anything with side effects, the compiler can remove them as dead code&quot;, all you really need here is a timer and a continuation for each &quot;task&quot; -- i.e 24 bytes on most platforms.  Allowing for allocation overhead and a data structure to manage all the timers efficiently, you might use as much as double that; with some tricks (e.g. function pointer compression) you could get it down to half that.<p>Eyeballing the graph, it looks like the winner is around 200MB for 1M concurrent tasks, so about 4x worse than a reasonably efficient but not heavily optimized implementation would be.<p>I have no idea what Go is doing to get 2500 bytes per task.</div><br/><div id="42271089" class="c"><input type="checkbox" id="c-42271089" checked=""/><div class="controls bullet"><span class="by">masklinn</span><span>|</span><a href="#42270788">parent</a><span>|</span><a href="#42270860">next</a><span>|</span><label class="collapse" for="c-42271089">[-]</label><label class="expand" for="c-42271089">[18 more]</label></div><br/><div class="children"><div class="content">&gt; I have no idea what Go is doing to get 2500 bytes per task.<p>TFA creates a goroutine (green thread) for each task (using a waitgroup to synchronise them). IIRC goroutines default to 2k stacks, so that’s about right.<p>One could argue it’s not fair and it should be timers which would be much lighter. There’s no “efficient wait” for them but that’s essentially the same as the appendix rust program.</div><br/><div id="42271186" class="c"><input type="checkbox" id="c-42271186" checked=""/><div class="controls bullet"><span class="by">jakewins</span><span>|</span><a href="#42270788">root</a><span>|</span><a href="#42271089">parent</a><span>|</span><a href="#42271308">next</a><span>|</span><label class="collapse" for="c-42271186">[-]</label><label class="expand" for="c-42271186">[11 more]</label></div><br/><div class="children"><div class="content">Fair or not, it’s a strange way to count - Go isn’t using that RAM. It’s preallocating it because any real world program will.</div><br/><div id="42271310" class="c"><input type="checkbox" id="c-42271310" checked=""/><div class="controls bullet"><span class="by">masklinn</span><span>|</span><a href="#42270788">root</a><span>|</span><a href="#42271186">parent</a><span>|</span><a href="#42271286">next</a><span>|</span><label class="collapse" for="c-42271310">[-]</label><label class="expand" for="c-42271310">[8 more]</label></div><br/><div class="children"><div class="content">Go is absolutely using that ram, it’s not available to other services on the system.</div><br/><div id="42272050" class="c"><input type="checkbox" id="c-42272050" checked=""/><div class="controls bullet"><span class="by">xarope</span><span>|</span><a href="#42270788">root</a><span>|</span><a href="#42271310">parent</a><span>|</span><a href="#42271352">next</a><span>|</span><label class="collapse" for="c-42272050">[-]</label><label class="expand" for="c-42272050">[2 more]</label></div><br/><div class="children"><div class="content">The argument then, is what if we DO load 2K worth [0] of randomized data into each of those 1m goroutines (and equivalents in the other languages), and do some actual processing.  Would we still see the equivalent 10x (whatever math works it out to be) memory &quot;bloat&quot;?  And what about performance?<p>We, as devs, have &quot;4&quot; such resources available to us, memory, network, I&#x2F;O and compute.   And it behooves us to not prematurely optimize on just one.<p>[0] I can see more arguments&#x2F;discussions now, &quot;2K is too low, it should be 2MB&quot; etc...!</div><br/><div id="42272309" class="c"><input type="checkbox" id="c-42272309" checked=""/><div class="controls bullet"><span class="by">masklinn</span><span>|</span><a href="#42270788">root</a><span>|</span><a href="#42272050">parent</a><span>|</span><a href="#42271352">next</a><span>|</span><label class="collapse" for="c-42272309">[-]</label><label class="expand" for="c-42272309">[1 more]</label></div><br/><div class="children"><div class="content">So the argument is “if you measure something completely different from and unrelated to the article you do not get the same result”?<p>I guess that’s true.<p>And to be clear, I do agree with the top comment (which seems to be by you), TFA uses timers in the other runtimes and go does have timers so using goroutines is unwarranted and unfair.</div><br/></div></div></div></div><div id="42271352" class="c"><input type="checkbox" id="c-42271352" checked=""/><div class="controls bullet"><span class="by">jakewins</span><span>|</span><a href="#42270788">root</a><span>|</span><a href="#42271310">parent</a><span>|</span><a href="#42272050">prev</a><span>|</span><a href="#42271286">next</a><span>|</span><label class="collapse" for="c-42271352">[-]</label><label class="expand" for="c-42271352">[5 more]</label></div><br/><div class="children"><div class="content">You know what I mean. If this was a real world program where those million tasks actually performed work, then this stack space is available for the application to do that work.<p>It’s not memory that’s consumed by the runtime, it’s memory the runtime expects the program to use - it’s just that this program does no useful work.</div><br/><div id="42271578" class="c"><input type="checkbox" id="c-42271578" checked=""/><div class="controls bullet"><span class="by">aeturnum</span><span>|</span><a href="#42270788">root</a><span>|</span><a href="#42271352">parent</a><span>|</span><a href="#42271710">next</a><span>|</span><label class="collapse" for="c-42271578">[-]</label><label class="expand" for="c-42271578">[3 more]</label></div><br/><div class="children"><div class="content">I am not u&#x2F;masklinn - but I don&#x27;t know what you mean. Doesn&#x27;t the runtime consume memory by setting it aside for future use? Like what else does &quot;using&quot; ram mean other than claiming it for a time?</div><br/><div id="42272267" class="c"><input type="checkbox" id="c-42272267" checked=""/><div class="controls bullet"><span class="by">jakewins</span><span>|</span><a href="#42270788">root</a><span>|</span><a href="#42271578">parent</a><span>|</span><a href="#42272224">next</a><span>|</span><label class="collapse" for="c-42272267">[-]</label><label class="expand" for="c-42272267">[1 more]</label></div><br/><div class="children"><div class="content">If the example was extended to, say, once the sleep is completed then parse and process some JSON data (simulating the sleep being a wait on some remote service), then how would memory use be affected?<p>In the Go number reported, the majority of the memory is the stack Go allocated <i>for the application code</i> anticipating processing to happen. In the Node example, the processing instead will need heap allocation.<p>Point being that the two numbers are different - one measures just the overhead of the runtime, the other adds the memory reserved for the app to do work.<p>The result then looks wasteful for Go because the benchmark.. doesn’t do anything. In a real app though, preallocating stack can often be faster than doing just-in-time heap allocation.<p>Not always of course! Just noting that the numbers are different things; one is runtime cost, one is runtime cost plus an optimization that assumes memory will be needed for processing after the sleep.</div><br/></div></div><div id="42272224" class="c"><input type="checkbox" id="c-42272224" checked=""/><div class="controls bullet"><span class="by">hatefulmoron</span><span>|</span><a href="#42270788">root</a><span>|</span><a href="#42271578">parent</a><span>|</span><a href="#42272267">prev</a><span>|</span><a href="#42271710">next</a><span>|</span><label class="collapse" for="c-42272224">[-]</label><label class="expand" for="c-42272224">[1 more]</label></div><br/><div class="children"><div class="content">I think he means that if the Go code had done something more useful, it would use about the same amount of memory. Compare that to another implementation, which might allocate nearly no memory when the tasks don&#x27;t do anything significant but would quickly catch up to Go if they did.</div><br/></div></div></div></div><div id="42271710" class="c"><input type="checkbox" id="c-42271710" checked=""/><div class="controls bullet"><span class="by">flockonus</span><span>|</span><a href="#42270788">root</a><span>|</span><a href="#42271352">parent</a><span>|</span><a href="#42271578">prev</a><span>|</span><a href="#42271286">next</a><span>|</span><label class="collapse" for="c-42271710">[-]</label><label class="expand" for="c-42271710">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ll yield it would be interesting to have a similar benchmark but instead of sleeping - which indeed by itself is nonsense, to instead each task compute a small fib sequence, or write a small file; something like that.</div><br/></div></div></div></div></div></div><div id="42271286" class="c"><input type="checkbox" id="c-42271286" checked=""/><div class="controls bullet"><span class="by">winternewt</span><span>|</span><a href="#42270788">root</a><span>|</span><a href="#42271186">parent</a><span>|</span><a href="#42271310">prev</a><span>|</span><a href="#42271308">next</a><span>|</span><label class="collapse" for="c-42271286">[-]</label><label class="expand" for="c-42271286">[2 more]</label></div><br/><div class="children"><div class="content">Please elaborate. If each stack is 2KB then surely all of that virtual memory is committed to physical RAM, and hence is using actual memory?</div><br/><div id="42271877" class="c"><input type="checkbox" id="c-42271877" checked=""/><div class="controls bullet"><span class="by">scrapheap</span><span>|</span><a href="#42270788">root</a><span>|</span><a href="#42271286">parent</a><span>|</span><a href="#42271308">next</a><span>|</span><label class="collapse" for="c-42271877">[-]</label><label class="expand" for="c-42271877">[1 more]</label></div><br/><div class="children"><div class="content">Yes and no.<p>If that memory isn&#x27;t being used and other things need the memory then the OS will very quickly dump it into swap, and as it&#x27;s never being touched the OS will never need to bring it back in to physical memory.  So while it&#x27;s allocated it doesn&#x27;t tie up the physical RAM.</div><br/></div></div></div></div></div></div><div id="42271308" class="c"><input type="checkbox" id="c-42271308" checked=""/><div class="controls bullet"><span class="by">cperciva</span><span>|</span><a href="#42270788">root</a><span>|</span><a href="#42271089">parent</a><span>|</span><a href="#42271186">prev</a><span>|</span><a href="#42270860">next</a><span>|</span><label class="collapse" for="c-42271308">[-]</label><label class="expand" for="c-42271308">[6 more]</label></div><br/><div class="children"><div class="content">Aha, 2k stacks.  I figured that stacks would be page size (or more) so 2500 seemed both too small for the thread to have a stack and too large for it to not have a stack.<p>2k stacks are an interesting design choice though... presumably they&#x27;re packed, in which case stack overflow is a serious concern.  Most threading systems will do something like allocating a single page for the stack but reserving 31 guard pages in case it needs to grow.</div><br/><div id="42271407" class="c"><input type="checkbox" id="c-42271407" checked=""/><div class="controls bullet"><span class="by">masklinn</span><span>|</span><a href="#42270788">root</a><span>|</span><a href="#42271308">parent</a><span>|</span><a href="#42271431">next</a><span>|</span><label class="collapse" for="c-42271407">[-]</label><label class="expand" for="c-42271407">[1 more]</label></div><br/><div class="children"><div class="content">Goroutines being go structures, the runtime can cooperate with itself so it doesn&#x27;t need to do any sort of probing: function prologues can check if there&#x27;s enough stack space for its frame, and grow the stack if not.<p>In reality it does use a guard area (technically I think it&#x27;s more of a redzone? It doesn&#x27;t cause access errors and functions with known small static frames can use it without checking).</div><br/></div></div><div id="42271431" class="c"><input type="checkbox" id="c-42271431" checked=""/><div class="controls bullet"><span class="by">uluyol</span><span>|</span><a href="#42270788">root</a><span>|</span><a href="#42271308">parent</a><span>|</span><a href="#42271407">prev</a><span>|</span><a href="#42271375">next</a><span>|</span><label class="collapse" for="c-42271431">[-]</label><label class="expand" for="c-42271431">[3 more]</label></div><br/><div class="children"><div class="content">Go stacks are dynamically copied and resized. Stack overflow is not a concern.</div><br/><div id="42271474" class="c"><input type="checkbox" id="c-42271474" checked=""/><div class="controls bullet"><span class="by">cperciva</span><span>|</span><a href="#42270788">root</a><span>|</span><a href="#42271431">parent</a><span>|</span><a href="#42271375">next</a><span>|</span><label class="collapse" for="c-42271474">[-]</label><label class="expand" for="c-42271474">[2 more]</label></div><br/><div class="children"><div class="content">Oh yuck.  Invalidating all the pointers to the stack?  That&#x27;s got to be expensive.<p>I guess if you&#x27;re already doing garbage collection moving the stack doesn&#x27;t make things all that much worse though... still, yuck.</div><br/><div id="42271619" class="c"><input type="checkbox" id="c-42271619" checked=""/><div class="controls bullet"><span class="by">masklinn</span><span>|</span><a href="#42270788">root</a><span>|</span><a href="#42271474">parent</a><span>|</span><a href="#42271375">next</a><span>|</span><label class="collapse" for="c-42271619">[-]</label><label class="expand" for="c-42271619">[1 more]</label></div><br/><div class="children"><div class="content">Yeah it’s the drawback, originally it used segmented stacks but that has its own issues.<p>And it’s probably not the worst issue because deep stacks and stack pointers will mostly be relevant for long running routines which will stabilise their stack use after a while (even if some are likely subject to threshold effects if they’re at the edge, I would not be surprised if some codebases ballasted stacks ahead of time). Also because stack pointers will get promoted to the heap if they escape so the number of stack pointers is not unlimited, and the pointer has to live downwards on the stack.</div><br/></div></div></div></div></div></div><div id="42271375" class="c"><input type="checkbox" id="c-42271375" checked=""/><div class="controls bullet"><span class="by">YZF</span><span>|</span><a href="#42270788">root</a><span>|</span><a href="#42271308">parent</a><span>|</span><a href="#42271431">prev</a><span>|</span><a href="#42270860">next</a><span>|</span><label class="collapse" for="c-42271375">[-]</label><label class="expand" for="c-42271375">[1 more]</label></div><br/><div class="children"><div class="content">A goroutine stack can grow. (EDIT: With stack copying AFAICT... so no virtual pages reserved for a stack to grow... probably some reason for this design?)</div><br/></div></div></div></div></div></div><div id="42270860" class="c"><input type="checkbox" id="c-42270860" checked=""/><div class="controls bullet"><span class="by">liveoneggs</span><span>|</span><a href="#42270788">parent</a><span>|</span><a href="#42271089">prev</a><span>|</span><a href="#42272136">next</a><span>|</span><label class="collapse" for="c-42270860">[-]</label><label class="expand" for="c-42270860">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;tpaschalis.me&#x2F;goroutines-size&#x2F;" rel="nofollow">https:&#x2F;&#x2F;tpaschalis.me&#x2F;goroutines-size&#x2F;</a><p><a href="https:&#x2F;&#x2F;github.com&#x2F;golang&#x2F;go&#x2F;blob&#x2F;master&#x2F;src&#x2F;runtime&#x2F;stack.go#L75">https:&#x2F;&#x2F;github.com&#x2F;golang&#x2F;go&#x2F;blob&#x2F;master&#x2F;src&#x2F;runtime&#x2F;stack.g...</a></div><br/></div></div></div></div><div id="42272136" class="c"><input type="checkbox" id="c-42272136" checked=""/><div class="controls bullet"><span class="by">JyB</span><span>|</span><a href="#42270788">prev</a><span>|</span><a href="#42271404">next</a><span>|</span><label class="collapse" for="c-42272136">[-]</label><label class="expand" for="c-42272136">[1 more]</label></div><br/><div class="children"><div class="content">I’m still baffled that some people are bold enough to voluntarily posts those kind of most-of-the-time useless “benchmark” that will inevitably be riddled with errors.  
I don’t know what pushes them. In the end you look like a clown more often than not.</div><br/></div></div><div id="42271404" class="c"><input type="checkbox" id="c-42271404" checked=""/><div class="controls bullet"><span class="by">aba_cz</span><span>|</span><a href="#42272136">prev</a><span>|</span><a href="#42271821">next</a><span>|</span><label class="collapse" for="c-42271404">[-]</label><label class="expand" for="c-42271404">[4 more]</label></div><br/><div class="children"><div class="content">Regarding Java I&#x27;m pretty sure that benchmark is broken at least a little bit and testing something else as not specifying initial size for ArrayList means list of size 10 which gets resized all the time when `add()` is called, leading to big amount of unused objects needing garbage collection.</div><br/><div id="42271762" class="c"><input type="checkbox" id="c-42271762" checked=""/><div class="controls bullet"><span class="by">bekantan</span><span>|</span><a href="#42271404">parent</a><span>|</span><a href="#42271584">next</a><span>|</span><label class="collapse" for="c-42271762">[-]</label><label class="expand" for="c-42271762">[1 more]</label></div><br/><div class="children"><div class="content">It would indeed be better to create appropriately sized storage.<p>However, I don&#x27;t think that underlying array is resized every time `add` is called. I&#x27;d expect that resize will happen less than 30 times for 1M adds (capacity grows geometrically with a=10 and r=1.5)</div><br/></div></div><div id="42271584" class="c"><input type="checkbox" id="c-42271584" checked=""/><div class="controls bullet"><span class="by">brabel</span><span>|</span><a href="#42271404">parent</a><span>|</span><a href="#42271762">prev</a><span>|</span><a href="#42271821">next</a><span>|</span><label class="collapse" for="c-42271584">[-]</label><label class="expand" for="c-42271584">[2 more]</label></div><br/><div class="children"><div class="content">Yeah that is a junior mistake... They should&#x27;ve pre-sized the ArrayList, or better, used an array because that&#x27;s more memory efficient (and I would say would be what any decent dev would do when the size of tasks is known beforehand).<p>&gt; Some folks pointed out that in Rust (tokio) it can use a loop iterating over the Vec instead of join_all to avoid the resize to the list<p>Right, but some folks also pointed out you should&#x27;ve used an array in Java in the previous blog post, 2 years ago, and you didn&#x27;t do that.<p>And folks also pointed out Elixir shouldn&#x27;t have used Task in the previous benchmark (folk here being the creator of Elixir himself): <a href="https:&#x2F;&#x2F;github.com&#x2F;pkolaczk&#x2F;async-runtimes-benchmarks&#x2F;pull&#x2F;7">https:&#x2F;&#x2F;github.com&#x2F;pkolaczk&#x2F;async-runtimes-benchmarks&#x2F;pull&#x2F;7</a></div><br/><div id="42271767" class="c"><input type="checkbox" id="c-42271767" checked=""/><div class="controls bullet"><span class="by">sfn42</span><span>|</span><a href="#42271404">root</a><span>|</span><a href="#42271584">parent</a><span>|</span><a href="#42271821">next</a><span>|</span><label class="collapse" for="c-42271767">[-]</label><label class="expand" for="c-42271767">[1 more]</label></div><br/><div class="children"><div class="content">The difference between an arraylist with correct initial size and an array is almost nothing. Arraylist itself is just a wrapper around an array.</div><br/></div></div></div></div></div></div><div id="42271821" class="c"><input type="checkbox" id="c-42271821" checked=""/><div class="controls bullet"><span class="by">jillesvangurp</span><span>|</span><a href="#42271404">prev</a><span>|</span><a href="#42271694">next</a><span>|</span><label class="collapse" for="c-42271821">[-]</label><label class="expand" for="c-42271821">[1 more]</label></div><br/><div class="children"><div class="content">Did a similar benchmark in Kotlin using co-routines.<p><pre><code>    import kotlin.time.Duration.Companion.milliseconds
    import kotlin.time.measureTime
    import kotlinx.coroutines.async
    import kotlinx.coroutines.awaitAll
    import kotlinx.coroutines.coroutineScope
    import kotlinx.coroutines.delay
    
    suspend fun main() {
        measureTime {
            coroutineScope {
                (0..1000000).map {
                    async {
                        delay(1.milliseconds)
                    }
                }.awaitAll()
            }
        }.let { t -&gt;
            println(&quot;Took $t&quot;)
            val runtime = Runtime.getRuntime()
    
            val maxHeapSize = runtime.maxMemory() 
            val allocatedHeapSize = runtime.totalMemory()
            val freeHeapSize = runtime.freeMemory()
    
            println(&quot;Max Heap: ${maxHeapSize &#x2F; 1024 &#x2F; 1024} MB&quot;)
            println(&quot;Allocated Heap: ${allocatedHeapSize &#x2F; 1024 &#x2F; 1024} MB&quot;)
            println(&quot;Free Heap: ${freeHeapSize &#x2F; 1024 &#x2F; 1024} MB&quot;)
        }
    }
</code></pre>
This produces the following output:<p><pre><code>   Took 1.597011084s
   Max Heap: 4096 MB
   Allocated Heap: 2238 MB
   Free Heap: 1548 MB
</code></pre>
So whatever is needed to load classes and a million co-routines with some heap state. Of course the whole thing isn&#x27;t doing any work and this isn&#x27;t much of a benchmark. And of course if I run it with kotlin-js it actually ends up using promises. So, it&#x27;s not going to be any better there than on the JVM.</div><br/></div></div><div id="42271694" class="c"><input type="checkbox" id="c-42271694" checked=""/><div class="controls bullet"><span class="by">iforgotpassword</span><span>|</span><a href="#42271821">prev</a><span>|</span><a href="#42271289">next</a><span>|</span><label class="collapse" for="c-42271694">[-]</label><label class="expand" for="c-42271694">[1 more]</label></div><br/><div class="children"><div class="content">Can someone explain the node version to me? My js knowledge is from a decade ago. AFAIK, setTimeout creates a timer and returns a handle to it. What does promisify do? I&#x27;d assume it&#x27;s a general wrapper that takes a function that returns X and wraps it so that it returns Promise&lt;X&gt;. So that code actually runs 10k tasks that each create a timer with a timeout of 10 seconds and return immediately.</div><br/></div></div><div id="42271289" class="c"><input type="checkbox" id="c-42271289" checked=""/><div class="controls bullet"><span class="by">afavour</span><span>|</span><a href="#42271694">prev</a><span>|</span><a href="#42271012">next</a><span>|</span><label class="collapse" for="c-42271289">[-]</label><label class="expand" for="c-42271289">[7 more]</label></div><br/><div class="children"><div class="content">Maybe I’m missing something here but surely Node <i>isn’t</i> doing anything concurrently? Promises don’t execute concurrently, they just tidy up async execution. The code as given will just sequentially resolve a million promises. No wonder it looks so good. You’d need to be using workers to actually do anything concurrently.</div><br/><div id="42271309" class="c"><input type="checkbox" id="c-42271309" checked=""/><div class="controls bullet"><span class="by">charlotte-fyi</span><span>|</span><a href="#42271289">parent</a><span>|</span><a href="#42271314">next</a><span>|</span><label class="collapse" for="c-42271309">[-]</label><label class="expand" for="c-42271309">[2 more]</label></div><br/><div class="children"><div class="content">That&#x27;s not entirely true. There&#x27;s a thread pool of workers underneath libuv. Tasks that would block do indeed execute concurrently.</div><br/><div id="42271320" class="c"><input type="checkbox" id="c-42271320" checked=""/><div class="controls bullet"><span class="by">afavour</span><span>|</span><a href="#42271289">root</a><span>|</span><a href="#42271309">parent</a><span>|</span><a href="#42271314">next</a><span>|</span><label class="collapse" for="c-42271320">[-]</label><label class="expand" for="c-42271320">[1 more]</label></div><br/><div class="children"><div class="content">Oh, I know. But the code used in this test doesn’t utilize that thread pool at all. It just uses setTimeout.</div><br/></div></div></div></div><div id="42271314" class="c"><input type="checkbox" id="c-42271314" checked=""/><div class="controls bullet"><span class="by">Izkata</span><span>|</span><a href="#42271289">parent</a><span>|</span><a href="#42271309">prev</a><span>|</span><a href="#42271315">next</a><span>|</span><label class="collapse" for="c-42271314">[-]</label><label class="expand" for="c-42271314">[3 more]</label></div><br/><div class="children"><div class="content">You&#x27;re thinking of parallelism.  Concurrency doesn&#x27;t require them to actually be running at the same time.</div><br/><div id="42271330" class="c"><input type="checkbox" id="c-42271330" checked=""/><div class="controls bullet"><span class="by">afavour</span><span>|</span><a href="#42271289">root</a><span>|</span><a href="#42271314">parent</a><span>|</span><a href="#42271315">next</a><span>|</span><label class="collapse" for="c-42271330">[-]</label><label class="expand" for="c-42271330">[2 more]</label></div><br/><div class="children"><div class="content">Fair point. Kind of makes the comparisons between languages a little unfair, though. Go and Rust would be executing these operations in parallel, Node would not. Would make a significant difference to real world performance!</div><br/><div id="42271345" class="c"><input type="checkbox" id="c-42271345" checked=""/><div class="controls bullet"><span class="by">Izkata</span><span>|</span><a href="#42271289">root</a><span>|</span><a href="#42271330">parent</a><span>|</span><a href="#42271315">next</a><span>|</span><label class="collapse" for="c-42271345">[-]</label><label class="expand" for="c-42271345">[1 more]</label></div><br/><div class="children"><div class="content">The measurement is memory, not performance.  Paused&#x2F;queued tasks in the sequential node version still count, and in theory could be worse since the Go and Rust ones would be consuming them in parallel and not building up the queue as much.</div><br/></div></div></div></div></div></div></div></div><div id="42271012" class="c"><input type="checkbox" id="c-42271012" checked=""/><div class="controls bullet"><span class="by">promiseofbeans</span><span>|</span><a href="#42271289">prev</a><span>|</span><a href="#42272248">next</a><span>|</span><label class="collapse" for="c-42271012">[-]</label><label class="expand" for="c-42271012">[1 more]</label></div><br/><div class="children"><div class="content">It would be nice if the author also compared different runtimes (e.g. NodeJS vs Deno, or cpython vs pypy) and core language engines (e.g. v8 vs spider monkey vs JavaScript core)</div><br/></div></div><div id="42272248" class="c"><input type="checkbox" id="c-42272248" checked=""/><div class="controls bullet"><span class="by">voodooEntity</span><span>|</span><a href="#42271012">prev</a><span>|</span><a href="#42270771">next</a><span>|</span><label class="collapse" for="c-42272248">[-]</label><label class="expand" for="c-42272248">[1 more]</label></div><br/><div class="children"><div class="content">I came here to rage (im just honest) because the go code example is bad and absolute not representative. Im coding go code for multiple years, especially alot of multithreading, and what is presented there as result is just wrong. Apart from no necessaty to use a waitgroup for threading, as many others here already have stated even with waitgroup you cacn reduce the memory significantly down to like 130mb for 1mio threads.<p>Also some other languages seem to be missrepresented.<p>Seems like someone had good intentions but no idea about the languages he tried to compare and the result is this article.</div><br/></div></div><div id="42270771" class="c"><input type="checkbox" id="c-42270771" checked=""/><div class="controls bullet"><span class="by">davidatbu</span><span>|</span><a href="#42272248">prev</a><span>|</span><a href="#42271468">next</a><span>|</span><label class="collapse" for="c-42270771">[-]</label><label class="expand" for="c-42270771">[9 more]</label></div><br/><div class="children"><div class="content">I write (async) Rust regularly, and I don&#x27;t understand how the version in the appendix doesn&#x27;t take 10x1,000,000 seconds to complete. In other words, I&#x27;d have expected no concurrency to take place.<p>Am I wrong?<p>UPDATE: From the replies below, it looks like I was right about &quot;no concurrency takes place&quot;, but I was wrong about how long it takes, because `tokio::time::sleep()` keeps track of when the future was created, (ie when `sleep()` was called) instead of when the future is first `.await`ed (which was my unsaid assumption).</div><br/><div id="42270807" class="c"><input type="checkbox" id="c-42270807" checked=""/><div class="controls bullet"><span class="by">claytonwramsey</span><span>|</span><a href="#42270771">parent</a><span>|</span><a href="#42271479">next</a><span>|</span><label class="collapse" for="c-42270807">[-]</label><label class="expand" for="c-42270807">[2 more]</label></div><br/><div class="children"><div class="content">The implementation of `sleep` [1] decides the wake up time by when `sleep` is called, rather than when its future is polled. So the first task waits one second, then the remaining tasks see that they have already passed the wake-up time and so return instantly.<p>[1]: <a href="https:&#x2F;&#x2F;docs.rs&#x2F;tokio&#x2F;latest&#x2F;tokio&#x2F;time&#x2F;fn.sleep.html" rel="nofollow">https:&#x2F;&#x2F;docs.rs&#x2F;tokio&#x2F;latest&#x2F;tokio&#x2F;time&#x2F;fn.sleep.html</a></div><br/><div id="42270863" class="c"><input type="checkbox" id="c-42270863" checked=""/><div class="controls bullet"><span class="by">davidatbu</span><span>|</span><a href="#42270771">root</a><span>|</span><a href="#42270807">parent</a><span>|</span><a href="#42271479">next</a><span>|</span><label class="collapse" for="c-42270863">[-]</label><label class="expand" for="c-42270863">[1 more]</label></div><br/><div class="children"><div class="content">This makes total sense!</div><br/></div></div></div></div><div id="42271479" class="c"><input type="checkbox" id="c-42271479" checked=""/><div class="controls bullet"><span class="by">vbsd</span><span>|</span><a href="#42270771">parent</a><span>|</span><a href="#42270807">prev</a><span>|</span><a href="#42270831">next</a><span>|</span><label class="collapse" for="c-42271479">[-]</label><label class="expand" for="c-42271479">[2 more]</label></div><br/><div class="children"><div class="content">&gt; because `tokio::time::sleep()` keeps track of when the future was created, (ie when `sleep()` was called) instead of when the future is first `.await`ed<p>I’m not a Rust programmer but I strongly suspect this updated explanation is erroneous. It’s probably more like this: start time is recorded when the task execution is started. However, the task immediately yields control back to the async loop. Then the async loop starts another task, and so on. It’s just that the async loop only returns the control to sleeping task no earlier than the moment 1s passes after the task execution was initialy started. I’d be surprised if it had anything to do with when sleep() was called.</div><br/><div id="42271970" class="c"><input type="checkbox" id="c-42271970" checked=""/><div class="controls bullet"><span class="by">davidatbu</span><span>|</span><a href="#42270771">root</a><span>|</span><a href="#42271479">parent</a><span>|</span><a href="#42270831">next</a><span>|</span><label class="collapse" for="c-42271970">[-]</label><label class="expand" for="c-42271970">[1 more]</label></div><br/><div class="children"><div class="content">Someone linked the code in another comment, and the start time is most definitely recorded when the future is created: <a href="https:&#x2F;&#x2F;docs.rs&#x2F;tokio&#x2F;1.41.1&#x2F;src&#x2F;tokio&#x2F;time&#x2F;sleep.rs.html#128-131" rel="nofollow">https:&#x2F;&#x2F;docs.rs&#x2F;tokio&#x2F;1.41.1&#x2F;src&#x2F;tokio&#x2F;time&#x2F;sleep.rs.html#12...</a></div><br/></div></div></div></div><div id="42270831" class="c"><input type="checkbox" id="c-42270831" checked=""/><div class="controls bullet"><span class="by">fuzzybear3965</span><span>|</span><a href="#42270771">parent</a><span>|</span><a href="#42271479">prev</a><span>|</span><a href="#42270786">next</a><span>|</span><label class="collapse" for="c-42270831">[-]</label><label class="expand" for="c-42270831">[2 more]</label></div><br/><div class="children"><div class="content">Yeah, I think you&#x27;re wrong. It should only take ~10s. tokio::time::sleep records the time it was called before returning the future [1]. So, all 1 million tasks should be stamped with +&#x2F;- the same time (within a few milliseconds).<p>[1]: <a href="https:&#x2F;&#x2F;docs.rs&#x2F;tokio&#x2F;1.41.1&#x2F;src&#x2F;tokio&#x2F;time&#x2F;sleep.rs.html#128-131" rel="nofollow">https:&#x2F;&#x2F;docs.rs&#x2F;tokio&#x2F;1.41.1&#x2F;src&#x2F;tokio&#x2F;time&#x2F;sleep.rs.html#12...</a></div><br/><div id="42270866" class="c"><input type="checkbox" id="c-42270866" checked=""/><div class="controls bullet"><span class="by">davidatbu</span><span>|</span><a href="#42270771">root</a><span>|</span><a href="#42270831">parent</a><span>|</span><a href="#42270786">next</a><span>|</span><label class="collapse" for="c-42270866">[-]</label><label class="expand" for="c-42270866">[1 more]</label></div><br/><div class="children"><div class="content">This makes total sense!</div><br/></div></div></div></div><div id="42270786" class="c"><input type="checkbox" id="c-42270786" checked=""/><div class="controls bullet"><span class="by">ch33zer</span><span>|</span><a href="#42270771">parent</a><span>|</span><a href="#42270831">prev</a><span>|</span><a href="#42271468">next</a><span>|</span><label class="collapse" for="c-42270786">[-]</label><label class="expand" for="c-42270786">[2 more]</label></div><br/><div class="children"><div class="content">Tokyo::sleep is async</div><br/><div id="42270876" class="c"><input type="checkbox" id="c-42270876" checked=""/><div class="controls bullet"><span class="by">davidatbu</span><span>|</span><a href="#42270771">root</a><span>|</span><a href="#42270786">parent</a><span>|</span><a href="#42271468">next</a><span>|</span><label class="collapse" for="c-42270876">[-]</label><label class="expand" for="c-42270876">[1 more]</label></div><br/><div class="children"><div class="content">I think the points people made in other replies make sense, but &quot;Tokio::sleep is async&quot; by itself is not enough of an explanation. If it were the case that `Tokio::sleep()` tracked the moment `.await` was called as it&#x27;s start time, I believe it would indeed take 10x1,000,000 seconds, _even if it&#x27;s async_.</div><br/></div></div></div></div></div></div><div id="42271468" class="c"><input type="checkbox" id="c-42271468" checked=""/><div class="controls bullet"><span class="by">samsartor</span><span>|</span><a href="#42270771">prev</a><span>|</span><a href="#42271590">next</a><span>|</span><label class="collapse" for="c-42271468">[-]</label><label class="expand" for="c-42271468">[2 more]</label></div><br/><div class="children"><div class="content">Reminder that Rust does not automatically schedule anything. Unless you _explicitly_ call `tokio::spawn` or `async_std::spawn` you are still living entirely in state-machine land.<p>Rust&#x27;s `join_all` uses `FuturesUnordered` behind the scenes, which is pretty intelligent in terms of keeping track of which tasks are ready to make progress, but it does not use tokio&#x2F;async_std for scheduling. AFAICT the only thing being measured about tokio&#x2F;async_std is the heap size of their `sleep` implementations.<p>I&#x27;d be very interesting in seeing how Tokio&#x27;s actual scheduler performs. The two ways to do that are:<p>- using <a href="https:&#x2F;&#x2F;docs.rs&#x2F;tokio&#x2F;latest&#x2F;tokio&#x2F;task&#x2F;join_set&#x2F;struct.JoinSet.html" rel="nofollow">https:&#x2F;&#x2F;docs.rs&#x2F;tokio&#x2F;latest&#x2F;tokio&#x2F;task&#x2F;join_set&#x2F;struct.Join...</a> to spawn all the futures and then await them<p>- spawn each future in the global scheduler, and then await the JoinHandles using the for loop from the appendix<p>As other commenters have noted, calling `sleep` only constructs a state machine. So the Appendix isn&#x27;t actually concurrent. Again, you need to either put those state machines into the tokio&#x2F;async_std schedulers with `spawn`, or combine the state machines with `FuturesUnordered`.</div><br/><div id="42271536" class="c"><input type="checkbox" id="c-42271536" checked=""/><div class="controls bullet"><span class="by">jhgg</span><span>|</span><a href="#42271468">parent</a><span>|</span><a href="#42271590">next</a><span>|</span><label class="collapse" for="c-42271536">[-]</label><label class="expand" for="c-42271536">[1 more]</label></div><br/><div class="children"><div class="content">I did this measurement, and using time -v, the maximum resident size in KB comes out to 440,424 kb for 1m tasks, 46,820 kb for 100k, and 7,156 kb for 10k.</div><br/></div></div></div></div><div id="42271590" class="c"><input type="checkbox" id="c-42271590" checked=""/><div class="controls bullet"><span class="by">citrin_ru</span><span>|</span><a href="#42271468">prev</a><span>|</span><a href="#42271713">next</a><span>|</span><label class="collapse" for="c-42271590">[-]</label><label class="expand" for="c-42271590">[1 more]</label></div><br/><div class="children"><div class="content">It would be more interesting to see a benchmark where a task will not be empty but would have an open network connection e.g. would make an HTTP request to a test server with 10 seconds response time. Network is a frequent reason real world applications spawn 1M tasks.</div><br/></div></div><div id="42271713" class="c"><input type="checkbox" id="c-42271713" checked=""/><div class="controls bullet"><span class="by">m4r1k</span><span>|</span><a href="#42271590">prev</a><span>|</span><a href="#42271464">next</a><span>|</span><label class="collapse" for="c-42271713">[-]</label><label class="expand" for="c-42271713">[1 more]</label></div><br/><div class="children"><div class="content">For those interested in Java Native Image, I previously wrote about its advantages beyond just memory footprint reduction, such as the dramatic improvement in startup time -&gt; <a href="https:&#x2F;&#x2F;medium.com&#x2F;google-cloud&#x2F;cut-container-startup-time-for-better-performance-and-costs-part2-3a30edf2b82c" rel="nofollow">https:&#x2F;&#x2F;medium.com&#x2F;google-cloud&#x2F;cut-container-startup-time-f...</a></div><br/></div></div><div id="42271464" class="c"><input type="checkbox" id="c-42271464" checked=""/><div class="controls bullet"><span class="by">abdellah123</span><span>|</span><a href="#42271713">prev</a><span>|</span><a href="#42271785">next</a><span>|</span><label class="collapse" for="c-42271464">[-]</label><label class="expand" for="c-42271464">[1 more]</label></div><br/><div class="children"><div class="content">Can we do something more real world at least? what&#x27;s the cost (hetzner monthly) of maintaining 1M concurrent websocket connection where each make a query to a postgres db randomly every 1-4 seconds.<p>The cost wouldn&#x27;t be just Memory because the network card and CPU also enter the game.</div><br/></div></div><div id="42271785" class="c"><input type="checkbox" id="c-42271785" checked=""/><div class="controls bullet"><span class="by">martypitt</span><span>|</span><a href="#42271464">prev</a><span>|</span><a href="#42271825">next</a><span>|</span><label class="collapse" for="c-42271785">[-]</label><label class="expand" for="c-42271785">[2 more]</label></div><br/><div class="children"><div class="content">Seriously impressive results from C#. I&#x27;m a JVM guy by day, and long-time admirer of C# as a language, but always assumed the two were broadly comparable performance-wise.<p>This is a sample of 1 usecase, (so questionable real-worldness) but the difference is really eye-opening. Congrats to the C# team!</div><br/><div id="42271908" class="c"><input type="checkbox" id="c-42271908" checked=""/><div class="controls bullet"><span class="by">ReptileMan</span><span>|</span><a href="#42271785">parent</a><span>|</span><a href="#42271825">next</a><span>|</span><label class="collapse" for="c-42271908">[-]</label><label class="expand" for="c-42271908">[1 more]</label></div><br/><div class="children"><div class="content">Just a minor nitpick - this is the .NET Runtime vs JVM. My personal observations are that CPU wise they are close, but for reasons unknown JVM has always been more memory hoggish.<p>The JIT compiler that microsoft created has been nothing short of amazing.</div><br/></div></div></div></div><div id="42271825" class="c"><input type="checkbox" id="c-42271825" checked=""/><div class="controls bullet"><span class="by">rcarmo</span><span>|</span><a href="#42271785">prev</a><span>|</span><a href="#42272270">next</a><span>|</span><label class="collapse" for="c-42271825">[-]</label><label class="expand" for="c-42271825">[1 more]</label></div><br/><div class="children"><div class="content">No Erlang, though. That ought to be amazingly small for that kind of synthetic benchmark.</div><br/></div></div><div id="42272270" class="c"><input type="checkbox" id="c-42272270" checked=""/><div class="controls bullet"><span class="by">indulona</span><span>|</span><a href="#42271825">prev</a><span>|</span><a href="#42270826">next</a><span>|</span><label class="collapse" for="c-42272270">[-]</label><label class="expand" for="c-42272270">[1 more]</label></div><br/><div class="children"><div class="content">Go&#x27;s performance has been neglected in past 10y. I even posted about it<p><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=41827288">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=41827288</a></div><br/></div></div><div id="42270826" class="c"><input type="checkbox" id="c-42270826" checked=""/><div class="controls bullet"><span class="by">pgAdmin4</span><span>|</span><a href="#42272270">prev</a><span>|</span><a href="#42271862">next</a><span>|</span><label class="collapse" for="c-42270826">[-]</label><label class="expand" for="c-42270826">[5 more]</label></div><br/><div class="children"><div class="content">Why C with pthreads missing in this benchmark ?</div><br/><div id="42270927" class="c"><input type="checkbox" id="c-42270927" checked=""/><div class="controls bullet"><span class="by">throwaway81523</span><span>|</span><a href="#42270826">parent</a><span>|</span><a href="#42271931">next</a><span>|</span><label class="collapse" for="c-42270927">[-]</label><label class="expand" for="c-42270927">[3 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think 1M posix threads is a thing.  1K is no big deal though.</div><br/><div id="42270975" class="c"><input type="checkbox" id="c-42270975" checked=""/><div class="controls bullet"><span class="by">liontwist</span><span>|</span><a href="#42270826">root</a><span>|</span><a href="#42270927">parent</a><span>|</span><a href="#42271931">next</a><span>|</span><label class="collapse" for="c-42270975">[-]</label><label class="expand" for="c-42270975">[2 more]</label></div><br/><div class="children"><div class="content">~100k is a thing on Linux.</div><br/><div id="42271174" class="c"><input type="checkbox" id="c-42271174" checked=""/><div class="controls bullet"><span class="by">fulafel</span><span>|</span><a href="#42270826">root</a><span>|</span><a href="#42270975">parent</a><span>|</span><a href="#42271931">next</a><span>|</span><label class="collapse" for="c-42271174">[-]</label><label class="expand" for="c-42271174">[1 more]</label></div><br/><div class="children"><div class="content">On Linux, 400k threads was a thing on even on 2002 hardware that was 32-bit and thus limited to 4GB: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37621887">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37621887</a><p>In the titular post there&#x27;s a link to a previous comparison between approaches, and plain OS threads used from Rust fare quite well, even if the author doesn&#x27;t up the OS limits to keep that in the running for the higher thread cases: <a href="https:&#x2F;&#x2F;pkolaczk.github.io&#x2F;memory-consumption-of-async&#x2F;" rel="nofollow">https:&#x2F;&#x2F;pkolaczk.github.io&#x2F;memory-consumption-of-async&#x2F;</a></div><br/></div></div></div></div></div></div><div id="42271931" class="c"><input type="checkbox" id="c-42271931" checked=""/><div class="controls bullet"><span class="by">thesnide</span><span>|</span><a href="#42270826">parent</a><span>|</span><a href="#42270927">prev</a><span>|</span><a href="#42271862">next</a><span>|</span><label class="collapse" for="c-42271931">[-]</label><label class="expand" for="c-42271931">[1 more]</label></div><br/><div class="children"><div class="content">that. Or just using a C coroutine lib.</div><br/></div></div></div></div><div id="42271862" class="c"><input type="checkbox" id="c-42271862" checked=""/><div class="controls bullet"><span class="by">win32_func</span><span>|</span><a href="#42270826">prev</a><span>|</span><a href="#42272075">next</a><span>|</span><label class="collapse" for="c-42271862">[-]</label><label class="expand" for="c-42271862">[1 more]</label></div><br/><div class="children"><div class="content">The JS version can quickly be improved to use less memory (~10%).<p><pre><code>    async function main() {
        const numTasks = parseInt(process.argv[2], 10);
        const taskDuration = 10000; &#x2F;&#x2F; 10 seconds

        const tasks = Array.from({ length: numTasks }, () =&gt;
            new Promise(resolve =&gt; setTimeout(resolve, taskDuration))
        );

        await Promise.all(tasks); &#x2F;&#x2F; Wait for all tasks to resolve
        console.log(&quot;All tasks completed.&quot;);
    }

    main().catch(err =&gt; {
        console.error(&quot;Error occurred:&quot;, err);
    });</code></pre></div><br/></div></div><div id="42272075" class="c"><input type="checkbox" id="c-42272075" checked=""/><div class="controls bullet"><span class="by">datadeft</span><span>|</span><a href="#42271862">prev</a><span>|</span><a href="#42271502">next</a><span>|</span><label class="collapse" for="c-42272075">[-]</label><label class="expand" for="c-42272075">[1 more]</label></div><br/><div class="children"><div class="content">No Erlang&#x2F;Elixir?? The author would be surprised.</div><br/></div></div><div id="42271502" class="c"><input type="checkbox" id="c-42271502" checked=""/><div class="controls bullet"><span class="by">maxyurk</span><span>|</span><a href="#42272075">prev</a><span>|</span><label class="collapse" for="c-42271502">[-]</label><label class="expand" for="c-42271502">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;eli.thegreenplace.net&#x2F;2018&#x2F;measuring-context-switching-and-memory-overheads-for-linux-threads&#x2F;" rel="nofollow">https:&#x2F;&#x2F;eli.thegreenplace.net&#x2F;2018&#x2F;measuring-context-switchi...</a>
it&#x27;s not a good enough example of a &quot;task&quot; to reflect real world usage.</div><br/></div></div></div></div></div></div></div></body></html>