<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1697101265565" as="style"/><link rel="stylesheet" href="styles.css?v=1697101265565"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.nature.com/articles/d41586-023-03196-y">It’s time to allow researchers to submit manuscripts to multiple journals</a> <span class="domain">(<a href="https://www.nature.com">www.nature.com</a>)</span></div><div class="subtext"><span>wjb3</span> | <span>63 comments</span></div><br/><div><div id="37851051" class="c"><input type="checkbox" id="c-37851051" checked=""/><div class="controls bullet"><span class="by">ssivark</span><span>|</span><a href="#37852434">next</a><span>|</span><label class="collapse" for="c-37851051">[-]</label><label class="expand" for="c-37851051">[4 more]</label></div><br/><div class="children"><div class="content">The best way to allow multiple submissions while amortizing the review work is to make reviews (and rebuttals) public, and overlay them on submissions made public on some preprint server.<p>This establishes priority (if credit is a concern), can be made blind &#x2F; double-blind if so desired, and also makes public the reviews (which are as much a public service as writing research papers). Which editorial boards “accept” the paper for publication is then simply a matter of collecting <i>endorsement tags</i> on the submission.</div><br/><div id="37854381" class="c"><input type="checkbox" id="c-37854381" checked=""/><div class="controls bullet"><span class="by">Helmut10001</span><span>|</span><a href="#37851051">parent</a><span>|</span><a href="#37851503">next</a><span>|</span><label class="collapse" for="c-37854381">[-]</label><label class="expand" for="c-37854381">[1 more]</label></div><br/><div class="children"><div class="content">I recently submitted to PLOS One. They publish the complete review alongside, after acceptance. I feel like this is already a big win for transparency. Immediate review publication would be even better.</div><br/></div></div><div id="37851503" class="c"><input type="checkbox" id="c-37851503" checked=""/><div class="controls bullet"><span class="by">nextos</span><span>|</span><a href="#37851051">parent</a><span>|</span><a href="#37854381">prev</a><span>|</span><a href="#37852434">next</a><span>|</span><label class="collapse" for="c-37851503">[-]</label><label class="expand" for="c-37851503">[2 more]</label></div><br/><div class="children"><div class="content">With a few minor changes, eLife is a non-profit journal that has that kind of peer review process: <a href="https:&#x2F;&#x2F;elifesciences.org&#x2F;about&#x2F;peer-review" rel="nofollow noreferrer">https:&#x2F;&#x2F;elifesciences.org&#x2F;about&#x2F;peer-review</a><p>It is quite well regarded now, they publish excellent research and the whole process is crystal clear.</div><br/><div id="37851638" class="c"><input type="checkbox" id="c-37851638" checked=""/><div class="controls bullet"><span class="by">radus</span><span>|</span><a href="#37851051">root</a><span>|</span><a href="#37851503">parent</a><span>|</span><a href="#37852434">next</a><span>|</span><label class="collapse" for="c-37851638">[-]</label><label class="expand" for="c-37851638">[1 more]</label></div><br/><div class="children"><div class="content">One of my favorite journals. Perhaps of interest to HNers is their fairly active GitHub: <a href="https:&#x2F;&#x2F;github.com&#x2F;elifesciences">https:&#x2F;&#x2F;github.com&#x2F;elifesciences</a>, and my favorite project of theirs, Lens: <a href="https:&#x2F;&#x2F;github.com&#x2F;elifesciences&#x2F;lens">https:&#x2F;&#x2F;github.com&#x2F;elifesciences&#x2F;lens</a>, it&#x27;s a paper viewer that actually makes reading papers easier (there&#x27;s loads of these out there but most are crap and inferior to a PDF).</div><br/></div></div></div></div></div></div><div id="37852434" class="c"><input type="checkbox" id="c-37852434" checked=""/><div class="controls bullet"><span class="by">mycologos</span><span>|</span><a href="#37851051">prev</a><span>|</span><a href="#37854587">next</a><span>|</span><label class="collapse" for="c-37852434">[-]</label><label class="expand" for="c-37852434">[2 more]</label></div><br/><div class="children"><div class="content">I do computer science research and publish regularly (in conferences, not journals, since that&#x27;s how computer science mostly works -- you write a paper, look for the soonest upcoming relevant conference deadline, submit there, and get a response 2-3 months later). I think discussions about peer review often fail to explain all of the things peer review can accomplish:<p>1) Verifying that work is correct, assuming that the author is honest (e.g., you take their data at face value)<p>2) Verifying that work is correct, assuming that the author is malicious (e.g., you scrutinize their data to see if it&#x27;s fabricated)<p>3) Certifying that the paper is &quot;interesting&quot; (universities, grant-making bodies, and other bureaucratic entities want some evidence that the researcher their funding is good, and somebody has to hand out the gold stars)<p>It takes time for even an expert to do 1), and it takes still more time to do 2). There aren&#x27;t really good incentives to do it beyond caring about your field, or wanting to build on the thing you&#x27;re reading. 3) can be done more quickly, but it&#x27;s subjective, but a world where things are only assessed for correctness and not interesting-ness is a world where external funding bodies rely on other weird proxies like citation metrics or something to figure out who&#x27;s good, and it&#x27;s not clear to me that that&#x27;s better.<p>My perception from computer science is that it should be <i>harder</i> to submit papers, because there are too many authors who simply rarely produce good papers and are clogging up the conferences with endless resubmissions until they get reviewers lazy enough to all say &quot;weak accept&quot;.</div><br/><div id="37854588" class="c"><input type="checkbox" id="c-37854588" checked=""/><div class="controls bullet"><span class="by">mnky9800n</span><span>|</span><a href="#37852434">parent</a><span>|</span><a href="#37854587">next</a><span>|</span><label class="collapse" for="c-37854588">[-]</label><label class="expand" for="c-37854588">[1 more]</label></div><br/><div class="children"><div class="content">Also sometimes reviewers point out interesting ideas you didn&#x27;t think of because you always have tunnel vision by the point you submit a paper.</div><br/></div></div></div></div><div id="37854587" class="c"><input type="checkbox" id="c-37854587" checked=""/><div class="controls bullet"><span class="by">ahmedsaad1977</span><span>|</span><a href="#37852434">prev</a><span>|</span><a href="#37851085">next</a><span>|</span><label class="collapse" for="c-37854587">[-]</label><label class="expand" for="c-37854587">[2 more]</label></div><br/><div class="children"><div class="content">If the peer reivew is turned into a properly paid work through a platform, many researchers from under-developed countries will surely join to become reveiwers. This will bridge the demand-supply gap and and make the publishing faster.<p><a href="https:&#x2F;&#x2F;www.thelancet.com&#x2F;journals&#x2F;lancet&#x2F;article&#x2F;PIIS0140-6736(21)02804-X&#x2F;fulltext" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.thelancet.com&#x2F;journals&#x2F;lancet&#x2F;article&#x2F;PIIS0140-6...</a></div><br/><div id="37854683" class="c"><input type="checkbox" id="c-37854683" checked=""/><div class="controls bullet"><span class="by">staunton</span><span>|</span><a href="#37854587">parent</a><span>|</span><a href="#37851085">next</a><span>|</span><label class="collapse" for="c-37854683">[-]</label><label class="expand" for="c-37854683">[1 more]</label></div><br/><div class="children"><div class="content">Who wants to pay for something that used to be free?</div><br/></div></div></div></div><div id="37851085" class="c"><input type="checkbox" id="c-37851085" checked=""/><div class="controls bullet"><span class="by">bo1024</span><span>|</span><a href="#37854587">prev</a><span>|</span><a href="#37850869">next</a><span>|</span><label class="collapse" for="c-37851085">[-]</label><label class="expand" for="c-37851085">[12 more]</label></div><br/><div class="children"><div class="content">Computer Science&#x27;s conventions solve these problems (although CS certainly has other problems):<p><pre><code>  * papers are generally posted to arxiv.org immediately on being finished, so everyone can access them
  * conferences have fixed deadlines and relatively short, fixed&#x2F;enforced review cycles</code></pre></div><br/><div id="37851289" class="c"><input type="checkbox" id="c-37851289" checked=""/><div class="controls bullet"><span class="by">liliumregale</span><span>|</span><a href="#37851085">parent</a><span>|</span><a href="#37851198">next</a><span>|</span><label class="collapse" for="c-37851289">[-]</label><label class="expand" for="c-37851289">[10 more]</label></div><br/><div class="children"><div class="content">Let&#x27;s distinguish between papers and preprints, please. arXiv has contributed to a blurring of the distinction. The arXiv preprints are useful but should always be taken with a grain of salt. There is nearly no filtering done on things uploaded to arXiv.<p>Everyone accessing someone&#x27;s uncritically reviewed work is a bittersweet gift.</div><br/><div id="37851941" class="c"><input type="checkbox" id="c-37851941" checked=""/><div class="controls bullet"><span class="by">impendia</span><span>|</span><a href="#37851085">root</a><span>|</span><a href="#37851289">parent</a><span>|</span><a href="#37853838">next</a><span>|</span><label class="collapse" for="c-37851941">[-]</label><label class="expand" for="c-37851941">[2 more]</label></div><br/><div class="children"><div class="content">In mathematics, at least, papers and preprints are indeed widely considered to be the same thing. In practice, for people working in the field, they are.<p>Math papers tend to be highly technical, read by other specialists in the field. When it comes for correctness -- whether or not I should take a paper with a grain of salt -- the authors&#x27; reputation counts for <i>much</i> more than the journal&#x27;s. And in case of student authors, who are just beginning to publish, the advisor is implicitly staking their reputation on the work as well.<p>There are also preprints on the arXiv, written by people unknown in the community, claiming to prove the Riemann Hypothesis or some such. These aren&#x27;t taken seriously by anyone.<p>An outsider might not be able to tell which preprints can be considered equivalent to papers, but such people are not likely to be seriously reading math research in the first place.</div><br/><div id="37852437" class="c"><input type="checkbox" id="c-37852437" checked=""/><div class="controls bullet"><span class="by">eru</span><span>|</span><a href="#37851085">root</a><span>|</span><a href="#37851941">parent</a><span>|</span><a href="#37853838">next</a><span>|</span><label class="collapse" for="c-37852437">[-]</label><label class="expand" for="c-37852437">[1 more]</label></div><br/><div class="children"><div class="content">You can always overlay a reputation system on top of your pre-print server.<p>The informal one you describe here, or any formal one you can come up with.</div><br/></div></div></div></div><div id="37853838" class="c"><input type="checkbox" id="c-37853838" checked=""/><div class="controls bullet"><span class="by">mo_42</span><span>|</span><a href="#37851085">root</a><span>|</span><a href="#37851289">parent</a><span>|</span><a href="#37851941">prev</a><span>|</span><a href="#37854568">next</a><span>|</span><label class="collapse" for="c-37853838">[-]</label><label class="expand" for="c-37853838">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Everyone accessing someone&#x27;s uncritically reviewed work is a bittersweet gift.<p>Review work is not always done by senior researcher (e.g., professors). Senior researchers often hand this down to PhDs. Having 3 to 4 reviews by nice junior reviewers doesn&#x27;t sound very critical.</div><br/><div id="37854584" class="c"><input type="checkbox" id="c-37854584" checked=""/><div class="controls bullet"><span class="by">mnky9800n</span><span>|</span><a href="#37851085">root</a><span>|</span><a href="#37853838">parent</a><span>|</span><a href="#37854568">next</a><span>|</span><label class="collapse" for="c-37854584">[-]</label><label class="expand" for="c-37854584">[1 more]</label></div><br/><div class="children"><div class="content">They have to say they did this and you are forgetting the editor&#x27;s role in paper evaluation. This criticism can and is taken into account and you can send papers out for more reviews if you get conflicting ones. In my experience as an editor, junior people typically give better reviews than senior (unless they are emeritus and then have unlimited time). I suppose this has to do with confidence in the junior person who will question their review themselves.</div><br/></div></div></div></div><div id="37854568" class="c"><input type="checkbox" id="c-37854568" checked=""/><div class="controls bullet"><span class="by">mnky9800n</span><span>|</span><a href="#37851085">root</a><span>|</span><a href="#37851289">parent</a><span>|</span><a href="#37853838">prev</a><span>|</span><a href="#37854484">next</a><span>|</span><label class="collapse" for="c-37854568">[-]</label><label class="expand" for="c-37854568">[1 more]</label></div><br/><div class="children"><div class="content">Yes. For example, here is a paper by some Cornell people where they reinvent machine learning model evaluation with the only motivation that I can tell is hubris and self service:<p><a href="https:&#x2F;&#x2F;browse.arxiv.org&#x2F;pdf&#x2F;2310.02335.pdf" rel="nofollow noreferrer">https:&#x2F;&#x2F;browse.arxiv.org&#x2F;pdf&#x2F;2310.02335.pdf</a><p>Do not trust arxiv papers. They have not been vetted.</div><br/></div></div><div id="37854484" class="c"><input type="checkbox" id="c-37854484" checked=""/><div class="controls bullet"><span class="by">YetAnotherNick</span><span>|</span><a href="#37851085">root</a><span>|</span><a href="#37851289">parent</a><span>|</span><a href="#37854568">prev</a><span>|</span><a href="#37851592">next</a><span>|</span><label class="collapse" for="c-37854484">[-]</label><label class="expand" for="c-37854484">[1 more]</label></div><br/><div class="children"><div class="content">Arxiv paper quality is better than journals&#x27; average paper&#x27;s quality. Because publishing in Arxiv doesn&#x27;t count as paper in resume in many places, there are far fewer papers who publish just for resume.</div><br/></div></div><div id="37854060" class="c"><input type="checkbox" id="c-37854060" checked=""/><div class="controls bullet"><span class="by">uxp8u61q</span><span>|</span><a href="#37851085">root</a><span>|</span><a href="#37851289">parent</a><span>|</span><a href="#37851592">prev</a><span>|</span><a href="#37851198">next</a><span>|</span><label class="collapse" for="c-37854060">[-]</label><label class="expand" for="c-37854060">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m confused. Do you accept published papers as gospel? They should be taken with a grain of salt too.</div><br/><div id="37854110" class="c"><input type="checkbox" id="c-37854110" checked=""/><div class="controls bullet"><span class="by">zarzavat</span><span>|</span><a href="#37851085">root</a><span>|</span><a href="#37854060">parent</a><span>|</span><a href="#37851198">next</a><span>|</span><label class="collapse" for="c-37854110">[-]</label><label class="expand" for="c-37854110">[1 more]</label></div><br/><div class="children"><div class="content">Depends on the field certainly. A paper in the Annals of Mathematics is definitely a lot more rock solid than whatever goes on the arXiv, or reviewed papers in certain fields that are particular magnets for junk science.</div><br/></div></div></div></div></div></div><div id="37851198" class="c"><input type="checkbox" id="c-37851198" checked=""/><div class="controls bullet"><span class="by">LudwigNagasena</span><span>|</span><a href="#37851085">parent</a><span>|</span><a href="#37851289">prev</a><span>|</span><a href="#37850869">next</a><span>|</span><label class="collapse" for="c-37851198">[-]</label><label class="expand" for="c-37851198">[1 more]</label></div><br/><div class="children"><div class="content">Also, publicly available reviews and comments at openreview.net.</div><br/></div></div></div></div><div id="37850869" class="c"><input type="checkbox" id="c-37850869" checked=""/><div class="controls bullet"><span class="by">dash2</span><span>|</span><a href="#37851085">prev</a><span>|</span><a href="#37854551">next</a><span>|</span><label class="collapse" for="c-37850869">[-]</label><label class="expand" for="c-37850869">[1 more]</label></div><br/><div class="children"><div class="content">&quot;The fear that multiple submissions would overwhelm the peer-review system lacks empirical evidence and is outweighed by the burden placed on researchers.&quot;<p>Actually, here&#x27;s a paper showing that the peer review is already overstretched:<p><a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2309.15884" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2309.15884</a></div><br/></div></div><div id="37854551" class="c"><input type="checkbox" id="c-37854551" checked=""/><div class="controls bullet"><span class="by">kryptiskt</span><span>|</span><a href="#37850869">prev</a><span>|</span><a href="#37851757">next</a><span>|</span><label class="collapse" for="c-37854551">[-]</label><label class="expand" for="c-37854551">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;d rather do away with the whole publish or perish thing.<p>One half-baked idea: For academic hiring, only ever judge the quality of a candidate&#x27;s research based on their five best papers (as they themselves have nominated), then there is no pressure to publish anything that doesn&#x27;t break into the top five.</div><br/><div id="37854606" class="c"><input type="checkbox" id="c-37854606" checked=""/><div class="controls bullet"><span class="by">mbork_pl</span><span>|</span><a href="#37854551">parent</a><span>|</span><a href="#37851757">next</a><span>|</span><label class="collapse" for="c-37854606">[-]</label><label class="expand" for="c-37854606">[2 more]</label></div><br/><div class="children"><div class="content">And then someone publishes five good papers and does nothing* for the rest of their life.<p>I mean, the idea looks nice, but there will always be people trying to game the system.<p>But don&#x27;t get me wrong – I still like your idea, I just think it would need some refining (as you yourself admit, ofc).<p>* As in, no research.</div><br/></div></div></div></div><div id="37851757" class="c"><input type="checkbox" id="c-37851757" checked=""/><div class="controls bullet"><span class="by">bluenose69</span><span>|</span><a href="#37854551">prev</a><span>|</span><a href="#37852386">next</a><span>|</span><label class="collapse" for="c-37851757">[-]</label><label class="expand" for="c-37851757">[1 more]</label></div><br/><div class="children"><div class="content">The author suggests that &quot;The fear that multiple submissions would overwhelm the peer-review system lacks empirical evidence&quot;.  Maybe it won&#x27;t &quot;overwhelm&quot; it, but it will certainly add to the reviewing workload.  Simply stated, if authors submit to N journals and each asks for 2 reviewers, that&#x27;s 2N units of work (assuming they can get the reviewers), compared to 2 units of work.<p>But it may be worse than that, actually.  I will not be much inclined to bother reviewing, if I know that the authors might pull their manuscript if another journal gives a green light quicker than the journal for which I have been asked to review.<p>The solution to a slow reviewing process is not to ask reviewers to do more of this unrewarded work.</div><br/></div></div><div id="37852386" class="c"><input type="checkbox" id="c-37852386" checked=""/><div class="controls bullet"><span class="by">CobrastanJorji</span><span>|</span><a href="#37851757">prev</a><span>|</span><a href="#37851732">next</a><span>|</span><label class="collapse" for="c-37852386">[-]</label><label class="expand" for="c-37852386">[3 more]</label></div><br/><div class="children"><div class="content">While we&#x27;re talking about needed journal changes, it&#x27;s worth pointing out that Nature, the journal, now allows articles submitted by authors to be open to anyone, which is great, but only if the authors pay Nature $11,690 per article. Otherwise, only institutions which subscribe to Nature can see the articles.</div><br/><div id="37854596" class="c"><input type="checkbox" id="c-37854596" checked=""/><div class="controls bullet"><span class="by">mnky9800n</span><span>|</span><a href="#37852386">parent</a><span>|</span><a href="#37852460">next</a><span>|</span><label class="collapse" for="c-37854596">[-]</label><label class="expand" for="c-37854596">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s because nature is a predatory journal. Submit to society journals please.</div><br/></div></div><div id="37852460" class="c"><input type="checkbox" id="c-37852460" checked=""/><div class="controls bullet"><span class="by">mycologos</span><span>|</span><a href="#37852386">parent</a><span>|</span><a href="#37854596">prev</a><span>|</span><a href="#37851732">next</a><span>|</span><label class="collapse" for="c-37852460">[-]</label><label class="expand" for="c-37852460">[1 more]</label></div><br/><div class="children"><div class="content">As far as I know, an author is allowed to share the preprint of their Nature submission, e.g. by posting it on their website or Arxiv, without paying an open access fee [1]. The difference between the submitted and final version of a paper is I think usually pretty minor, so this seems decent enough.<p>[1] <a href="https:&#x2F;&#x2F;www.nature.com&#x2F;nature-portfolio&#x2F;editorial-policies&#x2F;preprints-and-conference-proceedings" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.nature.com&#x2F;nature-portfolio&#x2F;editorial-policies&#x2F;p...</a></div><br/></div></div></div></div><div id="37854085" class="c"><input type="checkbox" id="c-37854085" checked=""/><div class="controls bullet"><span class="by">SubiculumCode</span><span>|</span><a href="#37851732">prev</a><span>|</span><a href="#37850801">next</a><span>|</span><label class="collapse" for="c-37854085">[-]</label><label class="expand" for="c-37854085">[2 more]</label></div><br/><div class="children"><div class="content">I want to post my research and journals compete to publish it</div><br/><div id="37854392" class="c"><input type="checkbox" id="c-37854392" checked=""/><div class="controls bullet"><span class="by">ykonstant</span><span>|</span><a href="#37854085">parent</a><span>|</span><a href="#37850801">next</a><span>|</span><label class="collapse" for="c-37854392">[-]</label><label class="expand" for="c-37854392">[1 more]</label></div><br/><div class="children"><div class="content">I would pay money to watch a battle royale with Elsevier managers.</div><br/></div></div></div></div><div id="37850801" class="c"><input type="checkbox" id="c-37850801" checked=""/><div class="controls bullet"><span class="by">PaulHoule</span><span>|</span><a href="#37854085">prev</a><span>|</span><a href="#37851525">next</a><span>|</span><label class="collapse" for="c-37850801">[-]</label><label class="expand" for="c-37850801">[30 more]</label></div><br/><div class="children"><div class="content">Peer review is a joke.  Peer reviewers don’t look at your data and the programs you used to analyze it.  They don’t look at your experimental apparatus, they don’t repeat your experiment, they don’t talk to the subjects you interviewed, at best they can spot obvious “red flags”.<p>(Of course, in 2023 you should be able to publish your data and all your software with the paper.)</div><br/><div id="37851505" class="c"><input type="checkbox" id="c-37851505" checked=""/><div class="controls bullet"><span class="by">radus</span><span>|</span><a href="#37850801">parent</a><span>|</span><a href="#37851044">next</a><span>|</span><label class="collapse" for="c-37851505">[-]</label><label class="expand" for="c-37851505">[14 more]</label></div><br/><div class="children"><div class="content">Some of the things that peer reviewers do, in my experience, in biology:<p>- question whether or not the conclusions you are making are supported by the data you are presenting<p>- ask for additional experiments<p>- evaluate whether or not your research is sufficiently novel and properly contextualized<p>- spotting obvious red flags - you seem to discount this, but it&#x27;s quite valuable<p>In my experience, the process of peer review has been onerous, sometimes taking years of work and many experiments, and has by and large led to a better end-product. There are not so great aspects of peer review, but it&#x27;s definitely not a joke as you characterize it.<p>I&#x27;ll add that in biology and adjacent fields, it makes no sense to discount peer review because the reviewers do not repeat your experiment - doing so is simply not practical, and you don&#x27;t have to stretch your imagination very far to understand why.</div><br/><div id="37851768" class="c"><input type="checkbox" id="c-37851768" checked=""/><div class="controls bullet"><span class="by">sxg</span><span>|</span><a href="#37850801">root</a><span>|</span><a href="#37851505">parent</a><span>|</span><a href="#37851044">next</a><span>|</span><label class="collapse" for="c-37851768">[-]</label><label class="expand" for="c-37851768">[13 more]</label></div><br/><div class="children"><div class="content">I also work in biological sciences research, but I&#x27;m more skeptical of peer review than you appear to be. My main criticism is that peer review is an n=2 process. Why not publish an unreviewed pre-print in bioRxiv and explicitly solicit constructive, public feedback directly on the pre-print on bioRxiv? I envision something similar to GitHub where users can open issues and have nuanced discussions about the work. The authors can address these issues by replying to users and updating the data and&#x2F;or manuscript while bioRxiv logs the change history. Journals can then select sufficiently mature manuscripts on bioRxiv and invite the authors to publish.<p>This would massively increase the number of people that review a manuscript while also shortening the feedback cycle. The papers I&#x27;ve published have typically been in the peer review process for months to years with just a handful of feedback cycles of sometimes dubious utility. This can be improved!<p>Edit: I forgot to mention the issue of politics in peer review! If you&#x27;re in a relatively small field, most of the big researchers all know each other, so peer review isn&#x27;t truly blinded in practice. Junior researchers are also pressured into acquiescing to the peer reviewers rather than having an actual scientific debate (speaking from experience).</div><br/><div id="37851990" class="c"><input type="checkbox" id="c-37851990" checked=""/><div class="controls bullet"><span class="by">dbingham</span><span>|</span><a href="#37850801">root</a><span>|</span><a href="#37851768">parent</a><span>|</span><a href="#37852281">next</a><span>|</span><label class="collapse" for="c-37851990">[-]</label><label class="expand" for="c-37851990">[5 more]</label></div><br/><div class="children"><div class="content">As it happens, I&#x27;m building &quot;Github for Journals&quot;.<p>I pivoted away from attempting a crowd source review approach with a reputation system to trying to support journals in going Diamond Open Access.<p>But the platform I&#x27;ve built supports co-author collaboration, preprints and preprint review, journal publishing flows, and post publication review - all in a continuous flow that utilizes an interface drawing from Github PRs and Google Docs.<p>You can submit a paper, collect feedback from co-authors, then submit it as a preprint and collect preprint feedback, then submit to a journal and run the journal review process, then collect feedback on the final published paper.  And you can manage multiple versions of the paper, collecting review rounds on each version, through that whole process.<p>It&#x27;s in alpha, I&#x27;m pushing really hard with a short runway to get the journal flows to usable beta while trying to raise seed funding... the catch being I feel very strongly that it needs to be non-profit, so seed funding here is grants and donations.<p>I&#x27;m looking for journal editors who want to participate in UX research.  I&#x27;m also interested in talking to folks who run preprint servers to see if they&#x27;d have any interest in using the platform.  If you (being any reader) know any, or have leads for funding, reach out: dbingham@theroadgoeson.com</div><br/><div id="37852029" class="c"><input type="checkbox" id="c-37852029" checked=""/><div class="controls bullet"><span class="by">cpncrunch</span><span>|</span><a href="#37850801">root</a><span>|</span><a href="#37851990">parent</a><span>|</span><a href="#37852281">next</a><span>|</span><label class="collapse" for="c-37852029">[-]</label><label class="expand" for="c-37852029">[4 more]</label></div><br/><div class="children"><div class="content">When you say &quot;submit to a journal&quot; does that mean you are not a journal? Why operate as a preprint server, but not offer to publish with peer-review? (Perhaps I&#x27;m misinterpreting your comment).</div><br/><div id="37852091" class="c"><input type="checkbox" id="c-37852091" checked=""/><div class="controls bullet"><span class="by">sxg</span><span>|</span><a href="#37850801">root</a><span>|</span><a href="#37852029">parent</a><span>|</span><a href="#37852096">next</a><span>|</span><label class="collapse" for="c-37852091">[-]</label><label class="expand" for="c-37852091">[2 more]</label></div><br/><div class="children"><div class="content">It doesn&#x27;t sound like that poster operates as a journal, and that makes sense. Academic researchers need to publish papers in long-standing and highly respected journals in order to be promoted and eventually gain tenure. Journals do not add value by simply providing space for researchers to publish their work—they add value by existing as a reputable brand that can endow select researchers with academic and social credit.</div><br/><div id="37852110" class="c"><input type="checkbox" id="c-37852110" checked=""/><div class="controls bullet"><span class="by">cpncrunch</span><span>|</span><a href="#37850801">root</a><span>|</span><a href="#37852091">parent</a><span>|</span><a href="#37852096">next</a><span>|</span><label class="collapse" for="c-37852110">[-]</label><label class="expand" for="c-37852110">[1 more]</label></div><br/><div class="children"><div class="content">As mentioned in my other comment, crappy peer-review is a big problem for most journals, so a solution to that needs to be found.</div><br/></div></div></div></div><div id="37852096" class="c"><input type="checkbox" id="c-37852096" checked=""/><div class="controls bullet"><span class="by">dbingham</span><span>|</span><a href="#37850801">root</a><span>|</span><a href="#37852029">parent</a><span>|</span><a href="#37852091">prev</a><span>|</span><a href="#37852281">next</a><span>|</span><label class="collapse" for="c-37852096">[-]</label><label class="expand" for="c-37852096">[1 more]</label></div><br/><div class="children"><div class="content">The platform is intended to host many journals in the same way Github hosts many open source projects.  And to facilitate interactions, conversation, and collaboration among authors, editors, and reviewers across them.</div><br/></div></div></div></div></div></div><div id="37852281" class="c"><input type="checkbox" id="c-37852281" checked=""/><div class="controls bullet"><span class="by">Fomite</span><span>|</span><a href="#37850801">root</a><span>|</span><a href="#37851768">parent</a><span>|</span><a href="#37851990">prev</a><span>|</span><a href="#37852161">next</a><span>|</span><label class="collapse" for="c-37852281">[-]</label><label class="expand" for="c-37852281">[2 more]</label></div><br/><div class="children"><div class="content">I think the key is that peer review is a <i>promise</i> of an n=2 process.<p>There&#x27;s no promise that an unreviewed pre-print is going to get two constructive readers. It&#x27;s also wildly subject to bias - being on a pre-print with a junior, female researcher was eye opening as to the merits of double blind review.</div><br/><div id="37852421" class="c"><input type="checkbox" id="c-37852421" checked=""/><div class="controls bullet"><span class="by">eru</span><span>|</span><a href="#37850801">root</a><span>|</span><a href="#37852281">parent</a><span>|</span><a href="#37852161">next</a><span>|</span><label class="collapse" for="c-37852421">[-]</label><label class="expand" for="c-37852421">[1 more]</label></div><br/><div class="children"><div class="content">You could blind the pre-print process, too?</div><br/></div></div></div></div><div id="37852161" class="c"><input type="checkbox" id="c-37852161" checked=""/><div class="controls bullet"><span class="by">tkgally</span><span>|</span><a href="#37850801">root</a><span>|</span><a href="#37851768">parent</a><span>|</span><a href="#37852281">prev</a><span>|</span><a href="#37852406">next</a><span>|</span><label class="collapse" for="c-37852161">[-]</label><label class="expand" for="c-37852161">[3 more]</label></div><br/><div class="children"><div class="content">&gt; Junior researchers are also pressured into acquiescing to the peer reviewers rather than having an actual scientific debate<p>Yes. When I was teaching at the graduate school level, doctoral students sometimes came to me for advice about how they should respond to peer reviewer comments. Those comments were usually constructive and worthwhile, but sometimes they seemed to indicate either a misunderstanding or an ideological bias on the part of the reviewer. (This was in the social sciences, where ideology comes with the territory.) But even in those latter cases, the junior researchers just wanted to know how they could best placate the reviewer and get their paper published. None had the nerve, time, or desire for an actual scholarly debate.</div><br/><div id="37852291" class="c"><input type="checkbox" id="c-37852291" checked=""/><div class="controls bullet"><span class="by">Fomite</span><span>|</span><a href="#37850801">root</a><span>|</span><a href="#37852161">parent</a><span>|</span><a href="#37852406">next</a><span>|</span><label class="collapse" for="c-37852291">[-]</label><label class="expand" for="c-37852291">[2 more]</label></div><br/><div class="children"><div class="content">As both a grad student and a postdoc I wrote appeals to rejections for peer review that succeeded.</div><br/><div id="37852958" class="c"><input type="checkbox" id="c-37852958" checked=""/><div class="controls bullet"><span class="by">sxg</span><span>|</span><a href="#37850801">root</a><span>|</span><a href="#37852291">parent</a><span>|</span><a href="#37852406">next</a><span>|</span><label class="collapse" for="c-37852958">[-]</label><label class="expand" for="c-37852958">[1 more]</label></div><br/><div class="children"><div class="content">Yes, you can certainly do that, but I wonder how long the appeal and approval process took? I&#x27;d bet it&#x27;s measured in months.</div><br/></div></div></div></div></div></div><div id="37852406" class="c"><input type="checkbox" id="c-37852406" checked=""/><div class="controls bullet"><span class="by">radus</span><span>|</span><a href="#37850801">root</a><span>|</span><a href="#37851768">parent</a><span>|</span><a href="#37852161">prev</a><span>|</span><a href="#37851991">next</a><span>|</span><label class="collapse" for="c-37852406">[-]</label><label class="expand" for="c-37852406">[1 more]</label></div><br/><div class="children"><div class="content">I agree with your suggestion and would 100% welcome that process - though I don&#x27;t think they&#x27;re necessarily mutually exclusive. As I see it, the main difference between the status quo and the more open process you suggest is that in theory reviewers that are hand-picked by the editor are more likely to have directly relevant experience, ideally translating to a better, and potentially more efficient review. Of course, that also comes with the drawbacks that you mentioned - that the reviewers are easily de-anonymized, and that they may be biased against your research since they&#x27;re essentially competitors -- I&#x27;ve had the good fortune of not being negatively affected by this, but I have many colleagues who have not been so lucky.<p>Edit: Also, to comment more on my own experience, I was lucky to be working in a well-established lab with a PI whose name carried a lot of weight and who had a lot of experience getting papers through the review process. We also had the resources to address requests that might&#x27;ve been too much for a less well-funded lab. I&#x27;m aware that this colours my views and didn&#x27;t mean to suggest that peer review, or the publication process, are perfect. The main reason I wanted to provide my perspective is that I feel that on HN there&#x27;s often an undercurrent of criticism that is levied against the state of scientific research that isn&#x27;t entirely fair in ways that may not be obvious to readers that haven&#x27;t experienced it first-hand.</div><br/></div></div><div id="37851991" class="c"><input type="checkbox" id="c-37851991" checked=""/><div class="controls bullet"><span class="by">cpncrunch</span><span>|</span><a href="#37850801">root</a><span>|</span><a href="#37851768">parent</a><span>|</span><a href="#37852406">prev</a><span>|</span><a href="#37851044">next</a><span>|</span><label class="collapse" for="c-37851991">[-]</label><label class="expand" for="c-37851991">[1 more]</label></div><br/><div class="children"><div class="content">Exactly. The quality of peer review is generally pretty poor. There are a lot of really terrible studies and reviews being published in high quality journals from people like the Mayo clinic, that you have to wonder how they passed peer review.<p>And then on the other hand, if you ever actually have to submit a paper to peer review, you&#x27;ll see how clueless a lot of the reviewers actually are. About half do give useful critiques and comments, but the other half seem to have weird beliefs about the subject in question, and they pan your paper due to you not sharing said weird beliefs.</div><br/></div></div></div></div></div></div><div id="37851044" class="c"><input type="checkbox" id="c-37851044" checked=""/><div class="controls bullet"><span class="by">PeterisP</span><span>|</span><a href="#37850801">parent</a><span>|</span><a href="#37851505">prev</a><span>|</span><a href="#37851680">next</a><span>|</span><label class="collapse" for="c-37851044">[-]</label><label class="expand" for="c-37851044">[2 more]</label></div><br/><div class="children"><div class="content">It still is a quite useful filter, as without it most fields would be even more overwhelmed. As a reviewer, have you seen what garbage gets submitted sometimes? There are incentives to attempt to get garbage published, so throwing out a significant part of submissions does add quite a lot of value to readers, so that they get at a somewhat curated list of papers from that journal or conference.<p>And while all you say is true, it&#x27;s probably the most we can get for free in a reasonable amount of time; requiring an independent lab to repeat an experiment would generally be far more delay and cost than we&#x27;d accept, other researchers do generally want to see the outcome as soon as the first experiment is documented; and there are people doing great research which won&#x27;t bother to submit if they&#x27;d have to pay for the replication - it&#x27;s generally the bad research that has motivation to spend more money for a publication. The general public might want to wait for extra confirmation, but they&#x27;re not the target audience of research papers, those are intended as communication by researchers for researchers. And also quite a few media outlets would disagree and probably prefer grabbing up hot rumors even earlier, even if they turn out to be false afterwards.</div><br/><div id="37851184" class="c"><input type="checkbox" id="c-37851184" checked=""/><div class="controls bullet"><span class="by">swatcoder</span><span>|</span><a href="#37850801">root</a><span>|</span><a href="#37851044">parent</a><span>|</span><a href="#37851680">next</a><span>|</span><label class="collapse" for="c-37851184">[-]</label><label class="expand" for="c-37851184">[1 more]</label></div><br/><div class="children"><div class="content">All of what you wrote is true too, but it’s also the hollowed out support beam at bottom of “evidence-based everything” culture, which has taken over almost everything.<p>The truth is that good science is <i>slow</i> and that most “evidence-based” practices are referring to a huge, nebulous cloud of bad results and weak suggestions rather than the evidence that supposedly gives them authority over traditional or intuitive practices.<p>Scientists participate on “Little Science” and the responsible ones often maintain the perspective that you’re describing here.<p>But modern society has built itself around  the institution of “Big Science” which is structurally forced to assert truths before they can responsibly be defended.<p>It’s way bigger than the general public being curious or the media wanting to get eyeballs — it’s everything going on in government, economics, medicine, psychology, agriculture, etc etc etc<p>It’s a house of cards and you’ve just summarized what the core problem is.</div><br/></div></div></div></div><div id="37851680" class="c"><input type="checkbox" id="c-37851680" checked=""/><div class="controls bullet"><span class="by">fsckboy</span><span>|</span><a href="#37850801">parent</a><span>|</span><a href="#37851044">prev</a><span>|</span><a href="#37851285">next</a><span>|</span><label class="collapse" for="c-37851680">[-]</label><label class="expand" for="c-37851680">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>Peer review is a joke. Peer reviewers don’t look at your data and the programs you used to analyze it. They don’t look at your experimental apparatus, they don’t repeat your experiment, they don’t talk to the subjects you interviewed, at best they can spot obvious “red flags”.</i><p>if those were the worst problems with peer review, we&#x27;d be in a much better place. Your peer reviewers are frequently higher status scientists working (competing) in the same research area you are trying to publish in. Generally, they do not want their own work outshined or overthrown.</div><br/></div></div><div id="37851285" class="c"><input type="checkbox" id="c-37851285" checked=""/><div class="controls bullet"><span class="by">standardUser</span><span>|</span><a href="#37850801">parent</a><span>|</span><a href="#37851680">prev</a><span>|</span><a href="#37851086">next</a><span>|</span><label class="collapse" for="c-37851285">[-]</label><label class="expand" for="c-37851285">[1 more]</label></div><br/><div class="children"><div class="content">Reminds me of code reviews, where sometimes a reviewer will go on a deep dive but usually they just scan it for obvious issues and typos. The thing is, even if my code is only getting a cursory review, I still prefer to have multiple people review it to increase the chances that obvious issues are caught. At least if it&#x27;s important code.</div><br/></div></div><div id="37851086" class="c"><input type="checkbox" id="c-37851086" checked=""/><div class="controls bullet"><span class="by">0cf8612b2e1e</span><span>|</span><a href="#37850801">parent</a><span>|</span><a href="#37851285">prev</a><span>|</span><a href="#37851032">next</a><span>|</span><label class="collapse" for="c-37851086">[-]</label><label class="expand" for="c-37851086">[5 more]</label></div><br/><div class="children"><div class="content">Fraud is considered rare, and trust is fundamental. In which case, you choose to believe what they said they did and interrogate of what they said they did is reasonable. Nobody has the budget, time, and sometimes magical fingers required to reproduce every submission.<p>You can disagree with this approach, but then there needs to be huge budgets set aside for reproduction.</div><br/><div id="37851776" class="c"><input type="checkbox" id="c-37851776" checked=""/><div class="controls bullet"><span class="by">aydyn</span><span>|</span><a href="#37850801">root</a><span>|</span><a href="#37851086">parent</a><span>|</span><a href="#37851168">next</a><span>|</span><label class="collapse" for="c-37851776">[-]</label><label class="expand" for="c-37851776">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Fraud is considered rare, and trust is fundamental.<p>This is a nice sentiment but demonstrably false.<p>Fraud is common in academia and everyone knows it. A large part of academic science is a grift for funding. Is not &quot;Trust&quot; that is fundamental, is tit-for-tat.</div><br/></div></div><div id="37851168" class="c"><input type="checkbox" id="c-37851168" checked=""/><div class="controls bullet"><span class="by">vermilingua</span><span>|</span><a href="#37850801">root</a><span>|</span><a href="#37851086">parent</a><span>|</span><a href="#37851776">prev</a><span>|</span><a href="#37851032">next</a><span>|</span><label class="collapse" for="c-37851168">[-]</label><label class="expand" for="c-37851168">[3 more]</label></div><br/><div class="children"><div class="content">Fraud is <i>considered</i> rare, but maybe not actually that rare; hence the replication crisis.</div><br/><div id="37851228" class="c"><input type="checkbox" id="c-37851228" checked=""/><div class="controls bullet"><span class="by">PaulHoule</span><span>|</span><a href="#37850801">root</a><span>|</span><a href="#37851168">parent</a><span>|</span><a href="#37851288">next</a><span>|</span><label class="collapse" for="c-37851228">[-]</label><label class="expand" for="c-37851228">[1 more]</label></div><br/><div class="children"><div class="content">A lot of times it is not deliberate fraud just incompetence.  There is the strange fact that the answer to precision QED calculations alway seemed to change when experimental results changed.  One enduring lesson from a physics PhD is that a 50 page long calculation without unit tests is… wrong.</div><br/></div></div><div id="37851288" class="c"><input type="checkbox" id="c-37851288" checked=""/><div class="controls bullet"><span class="by">nextos</span><span>|</span><a href="#37850801">root</a><span>|</span><a href="#37851168">parent</a><span>|</span><a href="#37851228">prev</a><span>|</span><a href="#37851032">next</a><span>|</span><label class="collapse" for="c-37851288">[-]</label><label class="expand" for="c-37851288">[1 more]</label></div><br/><div class="children"><div class="content">Misrepresentation of data and selective reporting to fit particular agendas of the last author are quite common. I have been involved in a couple of projects where I was asked to misrepresent or misreport findings.<p>Sadly, integrity offices will rarely conduct serious investigations, and won&#x27;t conclude misconduct happened unless what was done was incredibly harmful. Professors are often too big to fail, they attract tons of grants and are politically entrenched.</div><br/></div></div></div></div></div></div><div id="37851032" class="c"><input type="checkbox" id="c-37851032" checked=""/><div class="controls bullet"><span class="by">krastanov</span><span>|</span><a href="#37850801">parent</a><span>|</span><a href="#37851086">prev</a><span>|</span><a href="#37851585">next</a><span>|</span><label class="collapse" for="c-37851032">[-]</label><label class="expand" for="c-37851032">[1 more]</label></div><br/><div class="children"><div class="content">I partially agree, and I can enumerate other issues with peer review that you have not listed, but it is worthwhile to point out some of the positive features of the peer review concept:<p>- Peer review in reputable non-profit journals actually provides constructive suggestions that make papers and research itself better. APS&#x27;s PRX and PRL, as well as Quantum are journals where I have seen these idealistic positive effects;<p>- Filtering out the obvious red flags is pretty valuable even if boring;<p>- Thanks to people who care about the &quot;ideal&quot; of peer review we now have the infrastructure necessary to make reproducability much easier: mandatory data and code sharing on archival services, open (even crowdsourced) peer review, immediate feedback, etc.</div><br/></div></div><div id="37851585" class="c"><input type="checkbox" id="c-37851585" checked=""/><div class="controls bullet"><span class="by">smusamashah</span><span>|</span><a href="#37850801">parent</a><span>|</span><a href="#37851032">prev</a><span>|</span><a href="#37852277">next</a><span>|</span><label class="collapse" for="c-37851585">[-]</label><label class="expand" for="c-37851585">[1 more]</label></div><br/><div class="children"><div class="content">Can Journals adopt a pull request review like process on some central server? I am imagining Github PR review like capability on arxiv where anyone or authorized people can review the submission and submitters can respond to comments, all publicly.<p>I don&#x27;t if this is how it&#x27;s done already. I have seen people complaining about peer review here and was wondering why there isn&#x27;t a solution to that while software already enjoys a well established peer review system.</div><br/></div></div><div id="37852277" class="c"><input type="checkbox" id="c-37852277" checked=""/><div class="controls bullet"><span class="by">Fomite</span><span>|</span><a href="#37850801">parent</a><span>|</span><a href="#37851585">prev</a><span>|</span><a href="#37851741">next</a><span>|</span><label class="collapse" for="c-37852277">[-]</label><label class="expand" for="c-37852277">[1 more]</label></div><br/><div class="children"><div class="content">If you make your code available, I&#x27;m going to make sure it runs and does what you say.</div><br/></div></div><div id="37851741" class="c"><input type="checkbox" id="c-37851741" checked=""/><div class="controls bullet"><span class="by">aydyn</span><span>|</span><a href="#37850801">parent</a><span>|</span><a href="#37852277">prev</a><span>|</span><a href="#37851525">next</a><span>|</span><label class="collapse" for="c-37851741">[-]</label><label class="expand" for="c-37851741">[3 more]</label></div><br/><div class="children"><div class="content">Idk about you guys but the only reason I do peer review is to reject competitors and enemies.<p>If I really hate them, I give them a &quot;Major Revision&quot; aka a laundry list of expensive follow-up experiments and then reject them on the 2nd or 3rd round after a few months.<p>There&#x27;s actually zero benefit to earnestly engaging in peer review.</div><br/><div id="37852250" class="c"><input type="checkbox" id="c-37852250" checked=""/><div class="controls bullet"><span class="by">otikik</span><span>|</span><a href="#37850801">root</a><span>|</span><a href="#37851741">parent</a><span>|</span><a href="#37851931">next</a><span>|</span><label class="collapse" for="c-37852250">[-]</label><label class="expand" for="c-37852250">[1 more]</label></div><br/><div class="children"><div class="content">It sounds like you would do well in many other businesses. Don&#x27;t let academia hinder your potential. Have you considered selling timeshares to elderly people?</div><br/></div></div><div id="37851931" class="c"><input type="checkbox" id="c-37851931" checked=""/><div class="controls bullet"><span class="by">BeetleB</span><span>|</span><a href="#37850801">root</a><span>|</span><a href="#37851741">parent</a><span>|</span><a href="#37852250">prev</a><span>|</span><a href="#37851525">next</a><span>|</span><label class="collapse" for="c-37851931">[-]</label><label class="expand" for="c-37851931">[1 more]</label></div><br/><div class="children"><div class="content">You are an exemplar of all that is wrong in academia, but I upvoted you because there are so many like you.<p>(I know it from personal experience).<p>Personally, I decided to leave and make a more honest living. It seems you chose not to.</div><br/></div></div></div></div></div></div><div id="37851525" class="c"><input type="checkbox" id="c-37851525" checked=""/><div class="controls bullet"><span class="by">Metacelsus</span><span>|</span><a href="#37850801">prev</a><span>|</span><label class="collapse" for="c-37851525">[-]</label><label class="expand" for="c-37851525">[1 more]</label></div><br/><div class="children"><div class="content">As someone currently preparing a manuscript for submission (and choosing which journal to send it to), I definitely agree.</div><br/></div></div></div></div></div></div></div></body></html>