<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1706173267814" as="style"/><link rel="stylesheet" href="styles.css?v=1706173267814"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/lucidrains/self-rewarding-lm-pytorch">Self-rewarding-lm-PyTorch: Self-Rewarding Language Model from MetaAI</a> <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>swyx</span> | <span>24 comments</span></div><br/><div><div id="39127517" class="c"><input type="checkbox" id="c-39127517" checked=""/><div class="controls bullet"><span class="by">starbugs</span><span>|</span><a href="#39125892">next</a><span>|</span><label class="collapse" for="c-39127517">[-]</label><label class="expand" for="c-39127517">[1 more]</label></div><br/><div class="children"><div class="content">Sorry if this is a dumb question, but how does that make sure that the training process is not going into the wrong direction because of error accumulation?<p>Maybe I didn&#x27;t understand something fundamental here. (Not an LLM expert.)</div><br/></div></div><div id="39125892" class="c"><input type="checkbox" id="c-39125892" checked=""/><div class="controls bullet"><span class="by">potatoman22</span><span>|</span><a href="#39127517">prev</a><span>|</span><a href="#39126128">next</a><span>|</span><label class="collapse" for="c-39125892">[-]</label><label class="expand" for="c-39125892">[4 more]</label></div><br/><div class="children"><div class="content">&quot;Fine-tuning Llama 2 70B on three iterations of our approach yields a model that outperforms many existing systems on the AlpacaEval 2.0 leaderboard, including Claude 2, Gemini Pro, and GPT-4 0613.&quot;<p>Cool and impressive. I&#x27;m curious if this training method will become more common.</div><br/><div id="39126016" class="c"><input type="checkbox" id="c-39126016" checked=""/><div class="controls bullet"><span class="by">lhl</span><span>|</span><a href="#39125892">parent</a><span>|</span><a href="#39126128">next</a><span>|</span><label class="collapse" for="c-39126016">[-]</label><label class="expand" for="c-39126016">[3 more]</label></div><br/><div class="children"><div class="content">A new 7B model, Snorkel-Mistral-PairRM-DPO, using a similar self-rewarding pipeline was just released:<p>* Announcement: <a href="https:&#x2F;&#x2F;twitter.com&#x2F;billyuchenlin&#x2F;status&#x2F;1749975138307825933" rel="nofollow">https:&#x2F;&#x2F;twitter.com&#x2F;billyuchenlin&#x2F;status&#x2F;1749975138307825933</a><p>* Model Card: <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;snorkelai&#x2F;Snorkel-Mistral-PairRM-DPO" rel="nofollow">https:&#x2F;&#x2F;huggingface.co&#x2F;snorkelai&#x2F;Snorkel-Mistral-PairRM-DPO</a><p>* Response Re-Ranker: <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;llm-blender&#x2F;PairRM" rel="nofollow">https:&#x2F;&#x2F;huggingface.co&#x2F;llm-blender&#x2F;PairRM</a><p>&quot;We would also like to acknowledge contemporary work published independently on arXiv on 2024-01-18 by Meta &amp; NYU (Yuan, et al) in a paper called Self-Rewarding Language Models, which proposes a similar general approach for creating alignment pairs from a larger set of candidate responses, but using the LLM as the reward model. While this may work for general-purpose models, our experience has shown that task-specific reward models guided by SMEs are necessary for most enterprise applications of LLMs for specific use cases, which is why we focus on the use of external reward models.&quot;</div><br/><div id="39127200" class="c"><input type="checkbox" id="c-39127200" checked=""/><div class="controls bullet"><span class="by">azinman2</span><span>|</span><a href="#39125892">root</a><span>|</span><a href="#39126016">parent</a><span>|</span><a href="#39126128">next</a><span>|</span><label class="collapse" for="c-39127200">[-]</label><label class="expand" for="c-39127200">[2 more]</label></div><br/><div class="children"><div class="content">I assume this doesn’t yet run on llama.cpp?</div><br/><div id="39127568" class="c"><input type="checkbox" id="c-39127568" checked=""/><div class="controls bullet"><span class="by">tarruda</span><span>|</span><a href="#39125892">root</a><span>|</span><a href="#39127200">parent</a><span>|</span><a href="#39126128">next</a><span>|</span><label class="collapse" for="c-39127568">[-]</label><label class="expand" for="c-39127568">[1 more]</label></div><br/><div class="children"><div class="content">It is based on Mistral which llama.cpp supports, so I assume it does run (you might need to  convert to GGUF format and quantize it).</div><br/></div></div></div></div></div></div></div></div><div id="39126128" class="c"><input type="checkbox" id="c-39126128" checked=""/><div class="controls bullet"><span class="by">frogamel</span><span>|</span><a href="#39125892">prev</a><span>|</span><a href="#39125786">next</a><span>|</span><label class="collapse" for="c-39126128">[-]</label><label class="expand" for="c-39126128">[2 more]</label></div><br/><div class="children"><div class="content">I might be miunderstanding something here, but what complexity here is resolved by making this a framework? Isnt this just:<p>1. Train model like normal<p>2. Evaluate model using self<p>3. Use eval results for DPO finetune</div><br/><div id="39126162" class="c"><input type="checkbox" id="c-39126162" checked=""/><div class="controls bullet"><span class="by">lucidrains</span><span>|</span><a href="#39126128">parent</a><span>|</span><a href="#39125786">next</a><span>|</span><label class="collapse" for="c-39126162">[-]</label><label class="expand" for="c-39126162">[1 more]</label></div><br/><div class="children"><div class="content">No, you aren&#x27;t wrong. For ML people, it is quite simple and hopefully the final code reflects that<p>The aim is really to give a good base for follow up research &#x2F; modifications, which I think there will be many for this paper</div><br/></div></div></div></div><div id="39125786" class="c"><input type="checkbox" id="c-39125786" checked=""/><div class="controls bullet"><span class="by">greyface-</span><span>|</span><a href="#39126128">prev</a><span>|</span><a href="#39125946">next</a><span>|</span><label class="collapse" for="c-39125786">[-]</label><label class="expand" for="c-39125786">[2 more]</label></div><br/><div class="children"><div class="content">From 4 days ago, the paper that this implementation is based on: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=39051279">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=39051279</a></div><br/><div id="39126813" class="c"><input type="checkbox" id="c-39126813" checked=""/><div class="controls bullet"><span class="by">dang</span><span>|</span><a href="#39125786">parent</a><span>|</span><a href="#39125946">next</a><span>|</span><label class="collapse" for="c-39126813">[-]</label><label class="expand" for="c-39126813">[1 more]</label></div><br/><div class="children"><div class="content">Thanks! Macroexpanded:<p><i>Self-Rewarding Language Models</i> - <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=39051279">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=39051279</a> - Jan 2024 (58 comments)</div><br/></div></div></div></div><div id="39125946" class="c"><input type="checkbox" id="c-39125946" checked=""/><div class="controls bullet"><span class="by">lucidrains</span><span>|</span><a href="#39125786">prev</a><span>|</span><a href="#39126809">next</a><span>|</span><label class="collapse" for="c-39125946">[-]</label><label class="expand" for="c-39125946">[9 more]</label></div><br/><div class="children"><div class="content">hey, appreciate the interest! repo is not done yet, but probably will be around month&#x27;s end</div><br/><div id="39126073" class="c"><input type="checkbox" id="c-39126073" checked=""/><div class="controls bullet"><span class="by">dannyw</span><span>|</span><a href="#39125946">parent</a><span>|</span><a href="#39126497">next</a><span>|</span><label class="collapse" for="c-39126073">[-]</label><label class="expand" for="c-39126073">[7 more]</label></div><br/><div class="children"><div class="content">Hey lucidrains! Epicmafia was so much fun in its glory days :)</div><br/><div id="39126083" class="c"><input type="checkbox" id="c-39126083" checked=""/><div class="controls bullet"><span class="by">lucidrains</span><span>|</span><a href="#39125946">root</a><span>|</span><a href="#39126073">parent</a><span>|</span><a href="#39126497">next</a><span>|</span><label class="collapse" for="c-39126083">[-]</label><label class="expand" for="c-39126083">[6 more]</label></div><br/><div class="children"><div class="content">Lol, hey Danny. Indeed it was great times<p>I may bring it back, rebuilt in rails and svelte</div><br/><div id="39126193" class="c"><input type="checkbox" id="c-39126193" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#39125946">root</a><span>|</span><a href="#39126083">parent</a><span>|</span><a href="#39126252">next</a><span>|</span><label class="collapse" for="c-39126193">[-]</label><label class="expand" for="c-39126193">[3 more]</label></div><br/><div class="children"><div class="content">&gt; svelte<p>based. I helped start Svelte Society. please let me know if you need anything from the Svelte community, not sure how far along you are in the rebuild. prob can get a few volunteers for you.</div><br/></div></div><div id="39126252" class="c"><input type="checkbox" id="c-39126252" checked=""/><div class="controls bullet"><span class="by">RockRobotRock</span><span>|</span><a href="#39125946">root</a><span>|</span><a href="#39126083">parent</a><span>|</span><a href="#39126193">prev</a><span>|</span><a href="#39126497">next</a><span>|</span><label class="collapse" for="c-39126252">[-]</label><label class="expand" for="c-39126252">[2 more]</label></div><br/><div class="children"><div class="content">EpicMafia was seriously amazing. 13 years later, I still have friends I met on that game.<p>Thank you!</div><br/><div id="39126267" class="c"><input type="checkbox" id="c-39126267" checked=""/><div class="controls bullet"><span class="by">lucidrains</span><span>|</span><a href="#39125946">root</a><span>|</span><a href="#39126252">parent</a><span>|</span><a href="#39126497">next</a><span>|</span><label class="collapse" for="c-39126267">[-]</label><label class="expand" for="c-39126267">[1 more]</label></div><br/><div class="children"><div class="content">Yeah I know<p>I&#x27;ve been to weddings from players who met on the site. It was magical</div><br/></div></div></div></div></div></div></div></div><div id="39126497" class="c"><input type="checkbox" id="c-39126497" checked=""/><div class="controls bullet"><span class="by">choppaface</span><span>|</span><a href="#39125946">parent</a><span>|</span><a href="#39126073">prev</a><span>|</span><a href="#39126809">next</a><span>|</span><label class="collapse" for="c-39126497">[-]</label><label class="expand" for="c-39126497">[1 more]</label></div><br/><div class="children"><div class="content">did you get training compute from HF or thru a16z e.g. andromeda or some private cluster?</div><br/></div></div></div></div><div id="39126809" class="c"><input type="checkbox" id="c-39126809" checked=""/><div class="controls bullet"><span class="by">code51</span><span>|</span><a href="#39125946">prev</a><span>|</span><a href="#39126068">next</a><span>|</span><label class="collapse" for="c-39126809">[-]</label><label class="expand" for="c-39126809">[1 more]</label></div><br/><div class="children"><div class="content">Singular focus on AlpacaEval feels a bit limiting to validate the gains.<p>What&#x27;s the evidence here that this is not just a kind of leaderboard hacking for LLMs?</div><br/></div></div><div id="39126068" class="c"><input type="checkbox" id="c-39126068" checked=""/><div class="controls bullet"><span class="by">greatpostman</span><span>|</span><a href="#39126809">prev</a><span>|</span><a href="#39125939">next</a><span>|</span><label class="collapse" for="c-39126068">[-]</label><label class="expand" for="c-39126068">[1 more]</label></div><br/><div class="children"><div class="content">Meanwhile google still hasn’t released anything substantial</div><br/></div></div><div id="39125939" class="c"><input type="checkbox" id="c-39125939" checked=""/><div class="controls bullet"><span class="by">nmitchko</span><span>|</span><a href="#39126068">prev</a><span>|</span><a href="#39125897">next</a><span>|</span><label class="collapse" for="c-39125939">[-]</label><label class="expand" for="c-39125939">[2 more]</label></div><br/><div class="children"><div class="content">Great work, will try this tonight.<p>Only question, why do you name variables with the λ symbol?</div><br/><div id="39125947" class="c"><input type="checkbox" id="c-39125947" checked=""/><div class="controls bullet"><span class="by">lucidrains</span><span>|</span><a href="#39125939">parent</a><span>|</span><a href="#39125897">next</a><span>|</span><label class="collapse" for="c-39125947">[-]</label><label class="expand" for="c-39125947">[1 more]</label></div><br/><div class="children"><div class="content">just to better match the math equations in the SPIN paper</div><br/></div></div></div></div></div></div></div></div></div></body></html>