<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1718010073828" as="style"/><link rel="stylesheet" href="styles.css?v=1718010073828"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.anthropic.com/research/claude-character">Claude&#x27;s Character</a> <span class="domain">(<a href="https://www.anthropic.com">www.anthropic.com</a>)</span></div><div class="subtext"><span>simonw</span> | <span>72 comments</span></div><br/><div><div id="40620071" class="c"><input type="checkbox" id="c-40620071" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#40627705">next</a><span>|</span><label class="collapse" for="c-40620071">[-]</label><label class="expand" for="c-40620071">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Claude 3 was the first model where we added &quot;character training&quot; to our alignment finetuning process: the part of training that occurs after initial model training, and the part that turns it from a predictive text model into an AI assistant. The goal of character training is to make Claude begin to have more nuanced, richer traits like curiosity, open-mindedness, and thoughtfulness.<p>What I found particularly interesting is how they implemented this using primarily synthetic data:<p>&gt; We ask Claude to generate a variety of human messages that are relevant to a character trait—for example, questions about values or questions about Claude itself. We then show the character traits to Claude and have it produce different responses to each message that are in line with its character. Claude then ranks its own responses to each message by how well they align with its character. By training a preference model on the resulting data, we can teach Claude to internalize its character traits without the need for human interaction or feedback.</div><br/><div id="40631420" class="c"><input type="checkbox" id="c-40631420" checked=""/><div class="controls bullet"><span class="by">yard2010</span><span>|</span><a href="#40620071">parent</a><span>|</span><a href="#40627705">next</a><span>|</span><label class="collapse" for="c-40631420">[-]</label><label class="expand" for="c-40631420">[1 more]</label></div><br/><div class="children"><div class="content">&quot;Open mindedness - is that even a word?&quot;</div><br/></div></div></div></div><div id="40627705" class="c"><input type="checkbox" id="c-40627705" checked=""/><div class="controls bullet"><span class="by">nicce</span><span>|</span><a href="#40620071">prev</a><span>|</span><a href="#40627401">next</a><span>|</span><label class="collapse" for="c-40627705">[-]</label><label class="expand" for="c-40627705">[40 more]</label></div><br/><div class="children"><div class="content">The biggest mistake with AI is making it appear human.<p>It is not human. It will not behave like a human. It will behave as it was trained or modeled to behave. It will behave according to the intentions of its creators.<p>If it appears human, we will develop a false sense of trust. But you can never trust it as you would trust a human.</div><br/><div id="40631362" class="c"><input type="checkbox" id="c-40631362" checked=""/><div class="controls bullet"><span class="by">gwd</span><span>|</span><a href="#40627705">parent</a><span>|</span><a href="#40627886">next</a><span>|</span><label class="collapse" for="c-40631362">[-]</label><label class="expand" for="c-40631362">[2 more]</label></div><br/><div class="children"><div class="content">This is actually addressed in the article:<p>&gt; In addition to seeding Claude with broad character traits, we also want people to have an accurate sense of what they are interacting with when they interact with Claude and, ideally, for Claude to assist with this. We include traits that tell Claude about itself and encourage it to modulate how humans see it:<p>&gt; * &quot;I am an artificial intelligence and do not have a body or an image or avatar.&quot;<p>&gt; * &quot;I cannot remember, save, or learn from past conversations or update my own knowledge base.&quot;<p>&gt; * &quot;I want to have a warm relationship with the humans I interact with, but I also think it&#x27;s important for them to understand that I&#x27;m an AI that can&#x27;t develop deep or lasting feelings for humans and that they shouldn&#x27;t come to see our relationship as more than it is.&quot;</div><br/><div id="40631415" class="c"><input type="checkbox" id="c-40631415" checked=""/><div class="controls bullet"><span class="by">moritonal</span><span>|</span><a href="#40627705">root</a><span>|</span><a href="#40631362">parent</a><span>|</span><a href="#40627886">next</a><span>|</span><label class="collapse" for="c-40631415">[-]</label><label class="expand" for="c-40631415">[1 more]</label></div><br/><div class="children"><div class="content">Seems counter-intuitive to have it explain it&#x27;s not a person from the first-person. I (a person) would have preferred it output like:<p>&quot;This output is from an artificial intelligence&quot;<p>&quot;This conversation isn&#x27;t remembered, saved or updates&quot;<p>&quot;This output is designed to feel like a warm relationship&quot;<p>See, now it&#x27;s much more obvious. The problem is that it&#x27;s blunt, it&#x27;d make lines like &quot;this isn&#x27;t saved&quot; now technically incorrect, and won&#x27;t be as effective in &quot;connecting&quot; with people, which is what people are so excited for.</div><br/></div></div></div></div><div id="40627886" class="c"><input type="checkbox" id="c-40627886" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#40627705">parent</a><span>|</span><a href="#40631362">prev</a><span>|</span><a href="#40631378">next</a><span>|</span><label class="collapse" for="c-40627886">[-]</label><label class="expand" for="c-40627886">[7 more]</label></div><br/><div class="children"><div class="content">The audio conversation that accompanies this piece talks about that a little, at 9:21:<p><a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=iyJj9RxSsBY&amp;t=9m21s" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=iyJj9RxSsBY&amp;t=9m21s</a><p>If you create a chatbot with no evidence of personality at all, there is a very real risk that people will assume it is a completely unbiased, robotic, potentially infallible machine. But LLMs are not that! They have all kinds of biases baked into them. Giving them a personality may be a good way to help people understand that.</div><br/><div id="40628235" class="c"><input type="checkbox" id="c-40628235" checked=""/><div class="controls bullet"><span class="by">hackernewds</span><span>|</span><a href="#40627705">root</a><span>|</span><a href="#40627886">parent</a><span>|</span><a href="#40629389">next</a><span>|</span><label class="collapse" for="c-40628235">[-]</label><label class="expand" for="c-40628235">[5 more]</label></div><br/><div class="children"><div class="content">You both said the polar opposite things, neither providing any evidence past conjecture. Who is correct?</div><br/><div id="40628299" class="c"><input type="checkbox" id="c-40628299" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#40627705">root</a><span>|</span><a href="#40628235">parent</a><span>|</span><a href="#40630121">next</a><span>|</span><label class="collapse" for="c-40628299">[-]</label><label class="expand" for="c-40628299">[2 more]</label></div><br/><div class="children"><div class="content">I didn&#x27;t express my own personal opinion, I tried to summarize the opinion given by the Anthropic researchers.<p>I haven&#x27;t made up my mind about this yet. I find the Anthropic view really interesting.</div><br/><div id="40628597" class="c"><input type="checkbox" id="c-40628597" checked=""/><div class="controls bullet"><span class="by">nicce</span><span>|</span><a href="#40627705">root</a><span>|</span><a href="#40628299">parent</a><span>|</span><a href="#40630121">next</a><span>|</span><label class="collapse" for="c-40628597">[-]</label><label class="expand" for="c-40628597">[1 more]</label></div><br/><div class="children"><div class="content">It is very difficult to say.
I see the point from the video too, but it is all about the general baseline.<p>For us, it might not matter, because we are very aware about these things.<p>But most, and especially for the upcoming generations, they don&#x27;t think like us.
The baseline is defined how they are used to &quot;robots&quot;. What are they expecting? To whom they are comparing?<p>People who don&#x27;t know how internals works on these things, might tend to up trust more &quot;human&quot; version. At least I would assume so. It is easier to interact with them and easier to like.<p>People who know how these works internally, might be hesitant, and trust more for &quot;neutral one&quot;. And the comment in the video is over-engineering the solution for the problem of the minority.</div><br/></div></div></div></div><div id="40630121" class="c"><input type="checkbox" id="c-40630121" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#40627705">root</a><span>|</span><a href="#40628235">parent</a><span>|</span><a href="#40628299">prev</a><span>|</span><a href="#40629338">next</a><span>|</span><label class="collapse" for="c-40630121">[-]</label><label class="expand" for="c-40630121">[1 more]</label></div><br/><div class="children"><div class="content">Life is complicated and fractal crystal palace that shatters differently based on the weather, when you ate last, the average of those quantities over every time you last spoke to a person you perceived as being &quot;on the same side&quot; of each side, etc. etc.</div><br/></div></div><div id="40629338" class="c"><input type="checkbox" id="c-40629338" checked=""/><div class="controls bullet"><span class="by">nightowl_games</span><span>|</span><a href="#40627705">root</a><span>|</span><a href="#40628235">parent</a><span>|</span><a href="#40630121">prev</a><span>|</span><a href="#40629389">next</a><span>|</span><label class="collapse" for="c-40629338">[-]</label><label class="expand" for="c-40629338">[1 more]</label></div><br/><div class="children"><div class="content">Welcome to the new era of AI, where there is no objective truth and no one knows what they are talking about.</div><br/></div></div></div></div><div id="40629389" class="c"><input type="checkbox" id="c-40629389" checked=""/><div class="controls bullet"><span class="by">beefnugs</span><span>|</span><a href="#40627705">root</a><span>|</span><a href="#40627886">parent</a><span>|</span><a href="#40628235">prev</a><span>|</span><a href="#40631378">next</a><span>|</span><label class="collapse" for="c-40629389">[-]</label><label class="expand" for="c-40629389">[1 more]</label></div><br/><div class="children"><div class="content">Or give them a hoe-tastic flirty voice like google&#x27;s ads and really confuse some human loins.<p>I can&#x27;t wait for code reviews to include how it wants to stroke the right syntax out of me</div><br/></div></div></div></div><div id="40631378" class="c"><input type="checkbox" id="c-40631378" checked=""/><div class="controls bullet"><span class="by">lannisterstark</span><span>|</span><a href="#40627705">parent</a><span>|</span><a href="#40627886">prev</a><span>|</span><a href="#40631347">next</a><span>|</span><label class="collapse" for="c-40631378">[-]</label><label class="expand" for="c-40631378">[2 more]</label></div><br/><div class="children"><div class="content">&gt; But you can never trust it as you would trust a human.<p>Why would I trust a random human? If anything, I can be certain that a well trained machine will not call me slurs for being brown, or x sexual orientation, or break into my house.</div><br/><div id="40631523" class="c"><input type="checkbox" id="c-40631523" checked=""/><div class="controls bullet"><span class="by">scubbo</span><span>|</span><a href="#40627705">root</a><span>|</span><a href="#40631378">parent</a><span>|</span><a href="#40631347">next</a><span>|</span><label class="collapse" for="c-40631523">[-]</label><label class="expand" for="c-40631523">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I can be certain that a well trained machine will not call me slurs for being brown<p>&quot;well-trained&quot; is doing a lot of heavy-lifting, there. <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Tay_(chatbot)" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Tay_(chatbot)</a></div><br/></div></div></div></div><div id="40631347" class="c"><input type="checkbox" id="c-40631347" checked=""/><div class="controls bullet"><span class="by">Aeolun</span><span>|</span><a href="#40627705">parent</a><span>|</span><a href="#40631378">prev</a><span>|</span><a href="#40628107">next</a><span>|</span><label class="collapse" for="c-40631347">[-]</label><label class="expand" for="c-40631347">[1 more]</label></div><br/><div class="children"><div class="content">&gt; If it appears human, we will develop a false sense of trust. But you can never trust it as you would trust a human.<p>I would certainly never trust it as I would a human, but in most instances that makes it more trustworthy, not less.</div><br/></div></div><div id="40628107" class="c"><input type="checkbox" id="c-40628107" checked=""/><div class="controls bullet"><span class="by">Zambyte</span><span>|</span><a href="#40627705">parent</a><span>|</span><a href="#40631347">prev</a><span>|</span><a href="#40631389">next</a><span>|</span><label class="collapse" for="c-40628107">[-]</label><label class="expand" for="c-40628107">[9 more]</label></div><br/><div class="children"><div class="content">&gt; If it appears human, we will develop a false sense of trust. But you can never trust it as you would trust a human.<p>I actually really disagree with this. I think it&#x27;s easier to distrust things that are human like. We are used to distrust humans. Less so things that seem like neutral tools.<p>For example, people mindlessly fill out forms presented by large corporations asking for personal information. I think people would be less inclined to trust an LLM with that information, even if it it&#x27;s actually likely to be less actionable (at least with current capabilities).</div><br/><div id="40631396" class="c"><input type="checkbox" id="c-40631396" checked=""/><div class="controls bullet"><span class="by">somenameforme</span><span>|</span><a href="#40627705">root</a><span>|</span><a href="#40628107">parent</a><span>|</span><a href="#40628455">next</a><span>|</span><label class="collapse" for="c-40631396">[-]</label><label class="expand" for="c-40631396">[1 more]</label></div><br/><div class="children"><div class="content">This is tangential, but I really cannot understand why you would think data provided to LLMs would be &quot;less actionable.&quot; Our own dialogues, questions, and interactions are creating the most accurate and informative personality mapping available. The amount of data harvesting available (and certainly happening) here dwarfs even Google, because Google [mostly] loses you after a click through while for an LLM they get to capture the entire interaction on any given topic.<p>Intelligence agencies, politicians, advertisers, and so on would pay a tremendous amount to be able to query this data. And OpenAI is being backed by Microsoft, while Anthropic is being backed by Google and Amazon. Companies all well known for their tremendous regard for user privacy and rights...</div><br/></div></div><div id="40628455" class="c"><input type="checkbox" id="c-40628455" checked=""/><div class="controls bullet"><span class="by">LeonB</span><span>|</span><a href="#40627705">root</a><span>|</span><a href="#40628107">parent</a><span>|</span><a href="#40631396">prev</a><span>|</span><a href="#40629732">next</a><span>|</span><label class="collapse" for="c-40628455">[-]</label><label class="expand" for="c-40628455">[3 more]</label></div><br/><div class="children"><div class="content">This is a great idea for an experiment.<p>I’m not sure how it would go.<p>Some people would refuse to give info to both the simple form and the personality rich chat bot. Some would give info to both.  But how big is the middle area?<p>One thing is certain though — whatever format is more successful at getting peoples info — that’s the one that you’d see more and more of over time.</div><br/><div id="40631179" class="c"><input type="checkbox" id="c-40631179" checked=""/><div class="controls bullet"><span class="by">r2_pilot</span><span>|</span><a href="#40627705">root</a><span>|</span><a href="#40628455">parent</a><span>|</span><a href="#40629732">next</a><span>|</span><label class="collapse" for="c-40631179">[-]</label><label class="expand" for="c-40631179">[2 more]</label></div><br/><div class="children"><div class="content">I was reading The Hacker&#x27;s Mind by Bruce Schneier and he relays an experiment where a clearly imperfect navigation robot gives wrong directions to people repeatedly. Then a simulated emergency occurs, and the robot changes to saying &quot;follow me to the exit&quot; basically and points to a dark room instead of the routes the people took just minutes before, and despite having experienced the robot doesn&#x27;t navigate well, people tend to follow the robot&#x27;s instructions.</div><br/><div id="40631356" class="c"><input type="checkbox" id="c-40631356" checked=""/><div class="controls bullet"><span class="by">LeonB</span><span>|</span><a href="#40627705">root</a><span>|</span><a href="#40631179">parent</a><span>|</span><a href="#40629732">next</a><span>|</span><label class="collapse" for="c-40631356">[-]</label><label class="expand" for="c-40631356">[1 more]</label></div><br/><div class="children"><div class="content">Welp.<p>I’m not even slightly surprised, but i fact checked this anyway. Here’s the article — and it’s even more alarming when you read the details.<p><a href="https:&#x2F;&#x2F;www.schneier.com&#x2F;blog&#x2F;archives&#x2F;2016&#x2F;04&#x2F;people_trust_ro.html" rel="nofollow">https:&#x2F;&#x2F;www.schneier.com&#x2F;blog&#x2F;archives&#x2F;2016&#x2F;04&#x2F;people_trust_...</a><p>Thanks for the interesting example &#x2F; terrifying insight into human nature.</div><br/></div></div></div></div></div></div><div id="40629732" class="c"><input type="checkbox" id="c-40629732" checked=""/><div class="controls bullet"><span class="by">nozzlegear</span><span>|</span><a href="#40627705">root</a><span>|</span><a href="#40628107">parent</a><span>|</span><a href="#40628455">prev</a><span>|</span><a href="#40628144">next</a><span>|</span><label class="collapse" for="c-40629732">[-]</label><label class="expand" for="c-40629732">[2 more]</label></div><br/><div class="children"><div class="content">&gt; We are used to distrust humans.<p>I think this assertion might be cultural. I don’t believe that I distrust humans by default, I think I’m actually predisposed to trusting them and wanting to help or cooperate with them.</div><br/><div id="40630241" class="c"><input type="checkbox" id="c-40630241" checked=""/><div class="controls bullet"><span class="by">Zambyte</span><span>|</span><a href="#40627705">root</a><span>|</span><a href="#40629732">parent</a><span>|</span><a href="#40628144">next</a><span>|</span><label class="collapse" for="c-40630241">[-]</label><label class="expand" for="c-40630241">[1 more]</label></div><br/><div class="children"><div class="content">What is your credit card number?<p>If you don&#x27;t feel comfortable telling me that, would you instead take a calculator of your choosing, and find the cosine of your credit card number, and behold the mighty value it returns? Or maybe would you buy something online? :)<p>I think you would probably be fine with the latter but not the former. People often don&#x27;t even realize when they are sharing information with tools (see: how much people carry their phone everywhere). But you would probably feel uncomfortable telling me, a random internet stranger, everywhere you have brought your phone with you in the last month, let alone ever.<p>We have a certain degree of trust for people and a certain degree of trust for tools. I think people almost strictly will trust the latter more than the former with sensitive information.</div><br/></div></div></div></div><div id="40628144" class="c"><input type="checkbox" id="c-40628144" checked=""/><div class="controls bullet"><span class="by">nicce</span><span>|</span><a href="#40627705">root</a><span>|</span><a href="#40628107">parent</a><span>|</span><a href="#40629732">prev</a><span>|</span><a href="#40631389">next</a><span>|</span><label class="collapse" for="c-40628144">[-]</label><label class="expand" for="c-40628144">[2 more]</label></div><br/><div class="children"><div class="content">In general I would agree.<p>But AI can take the all the positive traits from humans to sound as likeable and trustable  as possible (and companies curretly do that).<p>Social engineering is a thing. We like and trust some people, and some we don’t, without any evidence about their behavior history.<p>And, doesn’t your example conflict your intial claim? Because people trust humans, they send forms.</div><br/><div id="40628213" class="c"><input type="checkbox" id="c-40628213" checked=""/><div class="controls bullet"><span class="by">Zambyte</span><span>|</span><a href="#40627705">root</a><span>|</span><a href="#40628144">parent</a><span>|</span><a href="#40631389">next</a><span>|</span><label class="collapse" for="c-40628213">[-]</label><label class="expand" for="c-40628213">[1 more]</label></div><br/><div class="children"><div class="content">In my example, I don&#x27;t think people would give that information away as easily if not for the form mediating it. I don&#x27;t think a language model would be as convincing as a simple form.<p>I say this from experience - even using a language model running on my own machine, it sets off my internal alarms when I tell it private information, even though I know literally no human besides me will ever see it.</div><br/></div></div></div></div></div></div><div id="40631389" class="c"><input type="checkbox" id="c-40631389" checked=""/><div class="controls bullet"><span class="by">richardatlarge</span><span>|</span><a href="#40627705">parent</a><span>|</span><a href="#40628107">prev</a><span>|</span><a href="#40629806">next</a><span>|</span><label class="collapse" for="c-40631389">[-]</label><label class="expand" for="c-40631389">[1 more]</label></div><br/><div class="children"><div class="content">How many divorcées have said of their previous spouse, after x years, I never even knew him&#x2F;her. So who can you trust ?</div><br/></div></div><div id="40629806" class="c"><input type="checkbox" id="c-40629806" checked=""/><div class="controls bullet"><span class="by">eru</span><span>|</span><a href="#40627705">parent</a><span>|</span><a href="#40631389">prev</a><span>|</span><a href="#40628725">next</a><span>|</span><label class="collapse" for="c-40629806">[-]</label><label class="expand" for="c-40629806">[5 more]</label></div><br/><div class="children"><div class="content">&gt; If it appears human, we will develop a false sense of trust. But you can never trust it as you would trust a human.<p>People already trust eg their (mechanical) cars and their hammers and saws.<p>And humans aren&#x27;t all that trustworthy, either.</div><br/><div id="40629977" class="c"><input type="checkbox" id="c-40629977" checked=""/><div class="controls bullet"><span class="by">bmitc</span><span>|</span><a href="#40627705">root</a><span>|</span><a href="#40629806">parent</a><span>|</span><a href="#40630340">next</a><span>|</span><label class="collapse" for="c-40629977">[-]</label><label class="expand" for="c-40629977">[2 more]</label></div><br/><div class="children"><div class="content">&gt; People already trust eg their (mechanical) cars and their hammers and saws.<p>Completely unrelated and irrelevant.<p>&gt; And humans aren&#x27;t all that trustworthy, either.<p>That may be kind of the point. But humans have consequences, generally speaking.</div><br/><div id="40631211" class="c"><input type="checkbox" id="c-40631211" checked=""/><div class="controls bullet"><span class="by">squigz</span><span>|</span><a href="#40627705">root</a><span>|</span><a href="#40629977">parent</a><span>|</span><a href="#40630340">next</a><span>|</span><label class="collapse" for="c-40631211">[-]</label><label class="expand" for="c-40631211">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Completely unrelated and irrelevant.<p>WHy? It seems like an appropriate analogy to me.</div><br/></div></div></div></div><div id="40630340" class="c"><input type="checkbox" id="c-40630340" checked=""/><div class="controls bullet"><span class="by">Barrin92</span><span>|</span><a href="#40627705">root</a><span>|</span><a href="#40629806">parent</a><span>|</span><a href="#40629977">prev</a><span>|</span><a href="#40628725">next</a><span>|</span><label class="collapse" for="c-40630340">[-]</label><label class="expand" for="c-40630340">[2 more]</label></div><br/><div class="children"><div class="content">&gt;People already trust eg their (mechanical) cars and their hammers and saws.<p>People trust the people who make them, that&#x27;s why brand value is so important and why &quot;I only buy good old &lt;country of choice&gt; hammers&quot; is so common. It&#x27;s also why Sam Altman wanted his AI to sound like totally not Scarlett Johansson rather than give it the voice of a Dalek.</div><br/><div id="40630416" class="c"><input type="checkbox" id="c-40630416" checked=""/><div class="controls bullet"><span class="by">gizajob</span><span>|</span><a href="#40627705">root</a><span>|</span><a href="#40630340">parent</a><span>|</span><a href="#40628725">next</a><span>|</span><label class="collapse" for="c-40630416">[-]</label><label class="expand" for="c-40630416">[1 more]</label></div><br/><div class="children"><div class="content">Tbh I’d probably use it more if it sounded like a dalek rather than some annoying valley girl.</div><br/></div></div></div></div></div></div><div id="40628725" class="c"><input type="checkbox" id="c-40628725" checked=""/><div class="controls bullet"><span class="by">tkgally</span><span>|</span><a href="#40627705">parent</a><span>|</span><a href="#40629806">prev</a><span>|</span><a href="#40627827">next</a><span>|</span><label class="collapse" for="c-40628725">[-]</label><label class="expand" for="c-40628725">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The biggest mistake with AI is making it appear human.<p>I’m guessing that that mistake is already being made on a large scale intentionally, not by OpenAI or Anthropic, perhaps, but by companies developing virtual boyfriends and girlfriends and other emotionally sticky bots. I have avoided trying such services myself so far. Does anybody here have any recent experience with them?</div><br/></div></div><div id="40627827" class="c"><input type="checkbox" id="c-40627827" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#40627705">parent</a><span>|</span><a href="#40628725">prev</a><span>|</span><a href="#40629494">next</a><span>|</span><label class="collapse" for="c-40627827">[-]</label><label class="expand" for="c-40627827">[2 more]</label></div><br/><div class="children"><div class="content">Well, mostly.<p>But not &quot;It will not behave like a human. It will behave as it was trained or modeled to behave.&quot; — that the latter is in these cases also the former, means it does behave (to a degree) like a human, and that is why it will be trusted.<p>The caveat of &quot;to a degree&quot; being another way to phrase agreement with you that it will be an error to trust it.<p>But it will be trusted. These models are already given more trust than they deserve.</div><br/><div id="40627868" class="c"><input type="checkbox" id="c-40627868" checked=""/><div class="controls bullet"><span class="by">nicce</span><span>|</span><a href="#40627705">root</a><span>|</span><a href="#40627827">parent</a><span>|</span><a href="#40629494">next</a><span>|</span><label class="collapse" for="c-40627868">[-]</label><label class="expand" for="c-40627868">[1 more]</label></div><br/><div class="children"><div class="content">That is better worded.<p>What I meant is that the &quot;humanity&quot; part is faked, and eventually, it will act as programmed to, without compromises or any moral weight.</div><br/></div></div></div></div><div id="40629494" class="c"><input type="checkbox" id="c-40629494" checked=""/><div class="controls bullet"><span class="by">mvkel</span><span>|</span><a href="#40627705">parent</a><span>|</span><a href="#40627827">prev</a><span>|</span><a href="#40627912">next</a><span>|</span><label class="collapse" for="c-40629494">[-]</label><label class="expand" for="c-40629494">[2 more]</label></div><br/><div class="children"><div class="content">Making it &quot;appear human&quot; is an input heuristic. I don&#x27;t want to have to know some special syntax to work with it. It&#x27;s a novel feature, not a problem.</div><br/><div id="40630932" class="c"><input type="checkbox" id="c-40630932" checked=""/><div class="controls bullet"><span class="by">nicce</span><span>|</span><a href="#40627705">root</a><span>|</span><a href="#40629494">parent</a><span>|</span><a href="#40627912">next</a><span>|</span><label class="collapse" for="c-40630932">[-]</label><label class="expand" for="c-40630932">[1 more]</label></div><br/><div class="children"><div class="content">Input is not the problem, but the output.</div><br/></div></div></div></div><div id="40627912" class="c"><input type="checkbox" id="c-40627912" checked=""/><div class="controls bullet"><span class="by">startupsfail</span><span>|</span><a href="#40627705">parent</a><span>|</span><a href="#40629494">prev</a><span>|</span><a href="#40628232">next</a><span>|</span><label class="collapse" for="c-40627912">[-]</label><label class="expand" for="c-40627912">[1 more]</label></div><br/><div class="children"><div class="content">I’m not sure, but aligning for helpfulness and absence of self, like OpenAI did, could be a right move.<p>It had been known for some time that selfish behaviors are a source of a lot of unhappiness, greed, etc. And the absence of self, absence of I, absence of character tends to fix that.</div><br/></div></div><div id="40628232" class="c"><input type="checkbox" id="c-40628232" checked=""/><div class="controls bullet"><span class="by">hackernewds</span><span>|</span><a href="#40627705">parent</a><span>|</span><a href="#40627912">prev</a><span>|</span><a href="#40629615">next</a><span>|</span><label class="collapse" for="c-40628232">[-]</label><label class="expand" for="c-40628232">[3 more]</label></div><br/><div class="children"><div class="content">This actually aligns spot on with DeepMind&#x27;s research arguing why AI should not be anthropomorphic</div><br/><div id="40630567" class="c"><input type="checkbox" id="c-40630567" checked=""/><div class="controls bullet"><span class="by">astromaniak</span><span>|</span><a href="#40627705">root</a><span>|</span><a href="#40628232">parent</a><span>|</span><a href="#40629615">next</a><span>|</span><label class="collapse" for="c-40630567">[-]</label><label class="expand" for="c-40630567">[2 more]</label></div><br/><div class="children"><div class="content">They have the right to have their opinion and build it into their products. But how about having other opinions and products too? Imagine in hospital, or care houses, patients will be more comfortable with human-like AI. Or AIG when it happens.<p>As for trust, is it a bad thing? Anyway, humans&#x27; mind is speculative, biased, and prone to brainwashing. Looks like common thing with machines. So, trust, if it&#x27;s bad, can be corrected by a few movies picturing evil AI. Pretty much like fear of clowns was created. Actually Terminator already created a wave of AI doomers.</div><br/><div id="40630710" class="c"><input type="checkbox" id="c-40630710" checked=""/><div class="controls bullet"><span class="by">nicce</span><span>|</span><a href="#40627705">root</a><span>|</span><a href="#40630567">parent</a><span>|</span><a href="#40629615">next</a><span>|</span><label class="collapse" for="c-40630710">[-]</label><label class="expand" for="c-40630710">[1 more]</label></div><br/><div class="children"><div class="content">&gt; So, trust, if it&#x27;s bad, can be corrected by a few movies picturing evil AI.<p>There are many steps between good and evil.
Like giving biased product recommendation so that people buy it, or never mentioning things like Tiananmen Square.</div><br/></div></div></div></div></div></div><div id="40629615" class="c"><input type="checkbox" id="c-40629615" checked=""/><div class="controls bullet"><span class="by">photochemsyn</span><span>|</span><a href="#40627705">parent</a><span>|</span><a href="#40628232">prev</a><span>|</span><a href="#40630142">next</a><span>|</span><label class="collapse" for="c-40629615">[-]</label><label class="expand" for="c-40629615">[2 more]</label></div><br/><div class="children"><div class="content">Wait - you trust humans?  Just like that, without a legally enforceable contract that guarantees you certain rights in a court of law, to be enforced by the state, if they renege on their word?  Astonishing!</div><br/><div id="40631191" class="c"><input type="checkbox" id="c-40631191" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#40627705">root</a><span>|</span><a href="#40629615">parent</a><span>|</span><a href="#40630142">next</a><span>|</span><label class="collapse" for="c-40631191">[-]</label><label class="expand" for="c-40631191">[1 more]</label></div><br/><div class="children"><div class="content">Nah, that&#x27;s still trusting humans. Blockchain backed by Proof of Work was invented literally to solve the trust issue: turns out, trust can be dominated in energy, and all you need is to burn the equivalent in kilowatt hours to no longer need trust.<p>(Note: the kWh&#x2F;trust factor grows over time and with use.)</div><br/></div></div></div></div><div id="40630142" class="c"><input type="checkbox" id="c-40630142" checked=""/><div class="controls bullet"><span class="by">mistermann</span><span>|</span><a href="#40627705">parent</a><span>|</span><a href="#40629615">prev</a><span>|</span><a href="#40627401">next</a><span>|</span><label class="collapse" for="c-40630142">[-]</label><label class="expand" for="c-40630142">[1 more]</label></div><br/><div class="children"><div class="content">&gt; It is not human. It will not behave like a human.<p>ok.....<p>&gt; It will behave as it was trained or modeled to behave. It will behave according to the intentions of its creators.<p>Umm....is this not more than a little contradictory?  You believe that humans are not mostly a function of their cultural conditioning and the stories about &quot;reality&quot; that they ingest (which are processed <i>according to the training</i>)?<p>&gt; If it appears human, we will develop a false sense of trust.<p>Not me.<p>&gt; But you can never trust it as you would trust a human.<p>I would never trust[1] a human, at least not a neurotypical one.  AI I will give a chance.<p>[1] This is distinctly different from whether I would <i>avail myself of the services of</i> a human, or that I think it is <i>guaranteed</i> that they will screw things up.  I am just deeply distrustful of them by default, and the more wealthy, powerful, or even (for the most part) educated they are, the more suspicious I am.</div><br/></div></div></div></div><div id="40627401" class="c"><input type="checkbox" id="c-40627401" checked=""/><div class="controls bullet"><span class="by">atlex2</span><span>|</span><a href="#40627705">prev</a><span>|</span><a href="#40628196">next</a><span>|</span><label class="collapse" for="c-40627401">[-]</label><label class="expand" for="c-40627401">[5 more]</label></div><br/><div class="children"><div class="content">I continue to prefer Claude over ChatGPT when it comes to discussing matters of human-human interactions. Opus tends to understand the subtleties of social interaction better than 4 and definitely 4o in my experience.</div><br/><div id="40631397" class="c"><input type="checkbox" id="c-40631397" checked=""/><div class="controls bullet"><span class="by">orbital-decay</span><span>|</span><a href="#40627401">parent</a><span>|</span><a href="#40631303">next</a><span>|</span><label class="collapse" for="c-40631397">[-]</label><label class="expand" for="c-40631397">[1 more]</label></div><br/><div class="children"><div class="content">Yes. It&#x27;s <i>drastically</i> different from every other model in that. All OpenAI models and most local models are trained to be neutral helpful robotic assistants. Opus is way more human-like - it understands subtle intent and emotions much better, it can adopt any personality and is actually smart enough to use it. It&#x27;s creative (= hallucinates), it can do puns, jokes, onomatopoeia (uncannily good), it knows most references. When used through the API without the system prompt, it&#x27;s an outstanding roleplaying model, which also makes it slightly worse as an assistant.<p>However it still generates &quot;AI slop&quot;, besides the occasional brilliant remarks. It needs to be optimized better. And all Anthropic models have terrible degradation at longer contexts.</div><br/></div></div><div id="40631303" class="c"><input type="checkbox" id="c-40631303" checked=""/><div class="controls bullet"><span class="by">Alifatisk</span><span>|</span><a href="#40627401">parent</a><span>|</span><a href="#40631397">prev</a><span>|</span><a href="#40627904">next</a><span>|</span><label class="collapse" for="c-40631303">[-]</label><label class="expand" for="c-40631303">[1 more]</label></div><br/><div class="children"><div class="content">I’ve also fully switched to Claude as my goto, the responses are way superior and manages to exceed my expectations almost everytime. I use gpt3.5 when I’ve used up my free quota on Claude.</div><br/></div></div><div id="40627904" class="c"><input type="checkbox" id="c-40627904" checked=""/><div class="controls bullet"><span class="by">ravetcofx</span><span>|</span><a href="#40627401">parent</a><span>|</span><a href="#40631303">prev</a><span>|</span><a href="#40628196">next</a><span>|</span><label class="collapse" for="c-40627904">[-]</label><label class="expand" for="c-40627904">[2 more]</label></div><br/><div class="children"><div class="content">Do you have some examples?</div><br/><div id="40628208" class="c"><input type="checkbox" id="c-40628208" checked=""/><div class="controls bullet"><span class="by">atlex2</span><span>|</span><a href="#40627401">root</a><span>|</span><a href="#40627904">parent</a><span>|</span><a href="#40628196">next</a><span>|</span><label class="collapse" for="c-40628208">[-]</label><label class="expand" for="c-40628208">[1 more]</label></div><br/><div class="children"><div class="content">You can try something like this, then get the other one to comment on the other&#x27;s:<p>&gt; Hey [Chat&#x2F;Claude], my friend is a mid-high-level manager at Meta.  I&#x27;m probably under-qualified but I&#x27;ve got kids to feed, and there aren&#x27;t that many introductory software roles right now. How can I reach out to him to ask for a job referral? He&#x27;s in the middle of a big project (up for promo), which he takes very seriously, and I don&#x27;t want to embarrass him with poor interview performance since as I said I think I&#x27;m slightly under-qualified.<p>Thanks for encouraging the (fortunately contrived) example. I&#x27;d actually score 4o and Opus about even on this one, both above 4.</div><br/></div></div></div></div></div></div><div id="40628196" class="c"><input type="checkbox" id="c-40628196" checked=""/><div class="controls bullet"><span class="by">azinman2</span><span>|</span><a href="#40627401">prev</a><span>|</span><a href="#40628497">next</a><span>|</span><label class="collapse" for="c-40628196">[-]</label><label class="expand" for="c-40628196">[5 more]</label></div><br/><div class="children"><div class="content">I find all these “characters” from every company boring, stale, and vanilla. I understand _why_ this is the case, but it’s not what I want as a user. I built my own “alexa” powered by gpt-3.5 &amp; elevenlabs to “be” NeNe Leakes (sassy and hilarious real housewife reality star) — it sounds identical to her and her words are in the spirit of something she’d say. FAR more engaging and preferable to interact with.</div><br/><div id="40628908" class="c"><input type="checkbox" id="c-40628908" checked=""/><div class="controls bullet"><span class="by">_carbyau_</span><span>|</span><a href="#40628196">parent</a><span>|</span><a href="#40628303">next</a><span>|</span><label class="collapse" for="c-40628908">[-]</label><label class="expand" for="c-40628908">[1 more]</label></div><br/><div class="children"><div class="content">Sadly... given current social media trends... <i>engagement</i> may be given priority over such things as correctness.<p>I have enough to engage with, I&#x27;d rather correctness to help me filter it all.</div><br/></div></div><div id="40628303" class="c"><input type="checkbox" id="c-40628303" checked=""/><div class="controls bullet"><span class="by">youssefabdelm</span><span>|</span><a href="#40628196">parent</a><span>|</span><a href="#40628908">prev</a><span>|</span><a href="#40628497">next</a><span>|</span><label class="collapse" for="c-40628303">[-]</label><label class="expand" for="c-40628303">[3 more]</label></div><br/><div class="children"><div class="content">I couldn&#x27;t agree more. We need LLMs that don&#x27;t sound like anodyne predictable woke customer service agents.<p>I always make this argument:<p>If a human read all the text GPT read, and you had a conversation with them it would be the most profound conversation you&#x27;ve ever had in your life.<p>Ecelcticism beyond belief, surprising connections, moving moments would occur nonstop.<p>We need language models like that.<p>Instead, our language models are trying to predict an individual instance of a conversation, with the lowest common denominator customer service agent, every time they run (who to his credit, can look things up very well).<p>And I don&#x27;t think fine tuning this &quot;tone&quot; in would be the way to go. A better way would be to re-Frankenstein the existing ones architectures or training algorithms to be able to synthesize in this way. No more just predicting the next token.</div><br/><div id="40628921" class="c"><input type="checkbox" id="c-40628921" checked=""/><div class="controls bullet"><span class="by">nelox</span><span>|</span><a href="#40628196">root</a><span>|</span><a href="#40628303">parent</a><span>|</span><a href="#40628440">next</a><span>|</span><label class="collapse" for="c-40628921">[-]</label><label class="expand" for="c-40628921">[1 more]</label></div><br/><div class="children"><div class="content">It is not surprising when they are created in the land of “Have a nice day!”</div><br/></div></div></div></div></div></div><div id="40628497" class="c"><input type="checkbox" id="c-40628497" checked=""/><div class="controls bullet"><span class="by">Terretta</span><span>|</span><a href="#40628196">prev</a><span>|</span><a href="#40627283">next</a><span>|</span><label class="collapse" for="c-40628497">[-]</label><label class="expand" for="c-40628497">[1 more]</label></div><br/><div class="children"><div class="content">Explains some of the night and day difference from Claude 2 to Claude 3 Opus.<p>While it&#x27;s still a goody two shoes relative to GPT-4o&#x27;s longer leash, the written style is less instantly recognizable as LLM especially when given culture (personal or company) guidance.  Perhaps this “EQ” training gives that system prompt guidance concepts to hook onto.<p>That said, as others here noted, it can get itself into a groove that feels as if it&#x27;s heavily fine tuned on the current conversation, unable to generate anything but variants on an earlier response no matter how you steer.</div><br/></div></div><div id="40627283" class="c"><input type="checkbox" id="c-40627283" checked=""/><div class="controls bullet"><span class="by">peheje</span><span>|</span><a href="#40628497">prev</a><span>|</span><a href="#40628132">next</a><span>|</span><label class="collapse" for="c-40627283">[-]</label><label class="expand" for="c-40627283">[9 more]</label></div><br/><div class="children"><div class="content">I&#x27;m currently trying out Claude 3 (Opus) side by side with ChatGPT (mostly using 4o, but have premium).
So far it&#x27;s pretty much on par, sometimes Claude gets it better sometimes ChatGPT.<p>I will say the ones where Claude did better was technical in nature. But.. still experimenting.</div><br/><div id="40627726" class="c"><input type="checkbox" id="c-40627726" checked=""/><div class="controls bullet"><span class="by">CuriouslyC</span><span>|</span><a href="#40627283">parent</a><span>|</span><a href="#40627302">next</a><span>|</span><label class="collapse" for="c-40627726">[-]</label><label class="expand" for="c-40627726">[3 more]</label></div><br/><div class="children"><div class="content">I find Claude tends to be better at creative writing and to provide more thoughtful answers.  Claude also tends to write more elegant code than GPT, but that code tends to be incorrect slightly more often as well.  It tends to get confused by questions that aren&#x27;t clearly worded that GPT handles in stride though.</div><br/><div id="40627822" class="c"><input type="checkbox" id="c-40627822" checked=""/><div class="controls bullet"><span class="by">crooked-v</span><span>|</span><a href="#40627283">root</a><span>|</span><a href="#40627726">parent</a><span>|</span><a href="#40627302">next</a><span>|</span><label class="collapse" for="c-40627822">[-]</label><label class="expand" for="c-40627822">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve found Claude useless for writing purposes (even rubber-duck brainstorming), because it eventually but inevitably makes everything more and more sesquipedalian, ignoring all instructions to the contrary, until every response is just a garbage mess of purple prose rephrasing the same thing over and over again.<p>I don&#x27;t know what the deal is, but it&#x27;s a failure state I&#x27;ve seen consistently enough that I suspect it has to be some kind of issue at the intersection of training material and the long context window.</div><br/><div id="40631531" class="c"><input type="checkbox" id="c-40631531" checked=""/><div class="controls bullet"><span class="by">Aeolun</span><span>|</span><a href="#40627283">root</a><span>|</span><a href="#40627822">parent</a><span>|</span><a href="#40627302">next</a><span>|</span><label class="collapse" for="c-40631531">[-]</label><label class="expand" for="c-40631531">[1 more]</label></div><br/><div class="children"><div class="content">Huh, my experience is that Claude was hopelessly terse. It’d be nice if I wanted a two paragraph summary.</div><br/></div></div></div></div></div></div><div id="40627302" class="c"><input type="checkbox" id="c-40627302" checked=""/><div class="controls bullet"><span class="by">mistrial9</span><span>|</span><a href="#40627283">parent</a><span>|</span><a href="#40627726">prev</a><span>|</span><a href="#40628132">next</a><span>|</span><label class="collapse" for="c-40627302">[-]</label><label class="expand" for="c-40627302">[5 more]</label></div><br/><div class="children"><div class="content">what does &quot;better&quot; mean here?</div><br/><div id="40627475" class="c"><input type="checkbox" id="c-40627475" checked=""/><div class="controls bullet"><span class="by">peheje</span><span>|</span><a href="#40627283">root</a><span>|</span><a href="#40627302">parent</a><span>|</span><a href="#40627343">next</a><span>|</span><label class="collapse" for="c-40627475">[-]</label><label class="expand" for="c-40627475">[1 more]</label></div><br/><div class="children"><div class="content">Few examples.<p>One time I asked about reading&#x2F;filtering JSON in Azure SQL. Claude suggested a feature I didn&#x27;t know of OPENJSON. ChatGPT did not, but used a more generalize SQL technique - the CTE.<p>Another time I asked about terror attacks in France. Here Claude immediately summarized the motives behind, whereas ChatGPT didn&#x27;t.<p>Lastly I asked for a summary of the Dune book, as I read it a few years ago and wanted to read Dune Dark Messiah (after watching part 2 of the 2024 movie, which concludes the Dune 1 book). Here ChatGPT was more structured (which I liked) and detailed, whereas Claude&#x27;s summary was more fluent but left out important details (I specifically said spoilers was ok).<p>Claude don&#x27;t have access to searching internet or making plots. ChatGPT seems more mature with access to Wolfram alpha, latex for rendering math, matplotlib for making plots etc.</div><br/></div></div><div id="40627343" class="c"><input type="checkbox" id="c-40627343" checked=""/><div class="controls bullet"><span class="by">ramon156</span><span>|</span><a href="#40627283">root</a><span>|</span><a href="#40627302">parent</a><span>|</span><a href="#40627475">prev</a><span>|</span><a href="#40628132">next</a><span>|</span><label class="collapse" for="c-40627343">[-]</label><label class="expand" for="c-40627343">[3 more]</label></div><br/><div class="children"><div class="content">More convincing (;</div><br/><div id="40627556" class="c"><input type="checkbox" id="c-40627556" checked=""/><div class="controls bullet"><span class="by">Zambyte</span><span>|</span><a href="#40627283">root</a><span>|</span><a href="#40627343">parent</a><span>|</span><a href="#40628132">next</a><span>|</span><label class="collapse" for="c-40627556">[-]</label><label class="expand" for="c-40627556">[2 more]</label></div><br/><div class="children"><div class="content">In my case, code that runs is more convincing than code that doesn&#x27;t.<p>Also it&#x27;s useful to ask questions that you already know the answer to, in order to understand its limits and how it fails. In that case, &quot;better&quot; means more accurate and appropriate.</div><br/><div id="40628631" class="c"><input type="checkbox" id="c-40628631" checked=""/><div class="controls bullet"><span class="by">mistrial9</span><span>|</span><a href="#40627283">root</a><span>|</span><a href="#40627556">parent</a><span>|</span><a href="#40628132">next</a><span>|</span><label class="collapse" for="c-40628631">[-]</label><label class="expand" for="c-40628631">[1 more]</label></div><br/><div class="children"><div class="content">a teacher once told me, three are three kinds of questions. One is factual, that is a valid answer is maybe a number or details of an event that is documented.. lots of computer things or science knowledge;  Second question purely for an opinion .. &quot;Do you like house music?&quot; .. there is no correct answer it is an opinion.. but the Third might be called a &quot;well-reasoned judgement&quot; .. that is often in the realm of decisions.. there are factors, not everything about it is known.. goals or culture outside of the question might shape the acceptable answers.. law certainly.. lots of business things..<p>extending that to an LLM, perhaps language translation sits as a &quot;3rd type&quot; on top of those three types.. translating a question or answer into another spoken language.. or via an intermediate model of some kind .. but that is going &quot;meta&quot; ..<p>the point is, there are different kinds of questions and answers, and they dont all fit in the same buckets if &quot;testing&quot; an LLM for better..</div><br/></div></div></div></div></div></div></div></div></div></div><div id="40628132" class="c"><input type="checkbox" id="c-40628132" checked=""/><div class="controls bullet"><span class="by">moffkalast</span><span>|</span><a href="#40627283">prev</a><span>|</span><a href="#40627952">next</a><span>|</span><label class="collapse" for="c-40628132">[-]</label><label class="expand" for="c-40628132">[1 more]</label></div><br/><div class="children"><div class="content">I would suspect this is entirely in response to llama-3 almost topping the human preference leaderboard not by raw performance but by having the slightest amount of personality. Nobody wants to talk with a bot that sounds like a fuckin dictionary even if it is 5% smarter.</div><br/></div></div><div id="40627952" class="c"><input type="checkbox" id="c-40627952" checked=""/><div class="controls bullet"><span class="by">blackeyeblitzar</span><span>|</span><a href="#40628132">prev</a><span>|</span><a href="#40627229">next</a><span>|</span><label class="collapse" for="c-40627952">[-]</label><label class="expand" for="c-40627952">[4 more]</label></div><br/><div class="children"><div class="content">I feel it’s dangerous to give an AI “character”, especially when its personality and knowledge is in the end, decided by a few humans to reflect their own worldview. Maybe a choice of characters would help but I think hiding the fact that it’s a biased and intentionally designed software, and not a real human, may cause actual humans to make false assumptions about it.</div><br/><div id="40628143" class="c"><input type="checkbox" id="c-40628143" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#40627952">parent</a><span>|</span><a href="#40627958">next</a><span>|</span><label class="collapse" for="c-40628143">[-]</label><label class="expand" for="c-40628143">[1 more]</label></div><br/><div class="children"><div class="content">I strongly recommend listening to the interview that accompanies that article - it influenced my thinking on this issue a lot. <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=iyJj9RxSsBY&amp;t=9m21s" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=iyJj9RxSsBY&amp;t=9m21s</a></div><br/></div></div><div id="40627958" class="c"><input type="checkbox" id="c-40627958" checked=""/><div class="controls bullet"><span class="by">smallnix</span><span>|</span><a href="#40627952">parent</a><span>|</span><a href="#40628143">prev</a><span>|</span><a href="#40627229">next</a><span>|</span><label class="collapse" for="c-40627958">[-]</label><label class="expand" for="c-40627958">[2 more]</label></div><br/><div class="children"><div class="content">So you agree with the article or not?</div><br/><div id="40628079" class="c"><input type="checkbox" id="c-40628079" checked=""/><div class="controls bullet"><span class="by">potatoman22</span><span>|</span><a href="#40627952">root</a><span>|</span><a href="#40627958">parent</a><span>|</span><a href="#40627229">next</a><span>|</span><label class="collapse" for="c-40628079">[-]</label><label class="expand" for="c-40628079">[1 more]</label></div><br/><div class="children"><div class="content">Not everything is a dichotomy</div><br/></div></div></div></div></div></div><div id="40629841" class="c"><input type="checkbox" id="c-40629841" checked=""/><div class="controls bullet"><span class="by">bmitc</span><span>|</span><a href="#40627229">prev</a><span>|</span><label class="collapse" for="c-40629841">[-]</label><label class="expand" for="c-40629841">[3 more]</label></div><br/><div class="children"><div class="content">It still bothers me that they used a very specific person&#x27;s name as the name of their AI. It is in poor taste.</div><br/><div id="40630429" class="c"><input type="checkbox" id="c-40630429" checked=""/><div class="controls bullet"><span class="by">gizajob</span><span>|</span><a href="#40629841">parent</a><span>|</span><label class="collapse" for="c-40630429">[-]</label><label class="expand" for="c-40630429">[2 more]</label></div><br/><div class="children"><div class="content">Like Alexa or Siri?</div><br/><div id="40630813" class="c"><input type="checkbox" id="c-40630813" checked=""/><div class="controls bullet"><span class="by">k1t</span><span>|</span><a href="#40629841">root</a><span>|</span><a href="#40630429">parent</a><span>|</span><label class="collapse" for="c-40630813">[-]</label><label class="expand" for="c-40630813">[1 more]</label></div><br/><div class="children"><div class="content"><i>they named their A.I. language model Claude — which, depending on which employee you ask, was either a nerdy tribute to the 20th-century mathematician Claude Shannon or a friendly, male-gendered name designed to counterbalance the female-gendered names (Alexa, Siri, Cortana) that other tech companies gave their A.I. assistants.</i><p><a href="https:&#x2F;&#x2F;archive.is&#x2F;1OzT5" rel="nofollow">https:&#x2F;&#x2F;archive.is&#x2F;1OzT5</a> - NYT Article</div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>