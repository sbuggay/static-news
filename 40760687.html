<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1719133273248" as="style"/><link rel="stylesheet" href="styles.css?v=1719133273248"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://chipsandcheese.com/2024/06/22/testing-amds-bergamo-zen-4c-spam/">Testing AMD&#x27;s Bergamo: Zen 4c</a> <span class="domain">(<a href="https://chipsandcheese.com">chipsandcheese.com</a>)</span></div><div class="subtext"><span>latchkey</span> | <span>66 comments</span></div><br/><div><div id="40761375" class="c"><input type="checkbox" id="c-40761375" checked=""/><div class="controls bullet"><span class="by">Pet_Ant</span><span>|</span><a href="#40761485">next</a><span>|</span><label class="collapse" for="c-40761375">[-]</label><label class="expand" for="c-40761375">[30 more]</label></div><br/><div class="children"><div class="content">The actual title seems to be &quot;Testing AMD’s Bergamo: Zen 4c Spam&quot; which I really like because for the perspectives of 20 years ago this would feel a bit like &quot;spam&quot; or a CPU-core &quot;Zergling rush&quot;.<p>As I said before, I do believe that this is the future of CPUs core. [1] With RAM latency not really having kept pace with CPUs have more performant cores really seems like a waste. In a Cloud setting where you always have some work to do it seems like simpler cores but more of them is really the answer. It&#x27;s in the environment that the weight of x86&#x27;s legacy will catch up with us and we&#x27;ll need to get rid of all the waste transistors decoding cruft.<p><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=40535915">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=40535915</a></div><br/><div id="40764583" class="c"><input type="checkbox" id="c-40764583" checked=""/><div class="controls bullet"><span class="by">zorgmonkey</span><span>|</span><a href="#40761375">parent</a><span>|</span><a href="#40762227">next</a><span>|</span><label class="collapse" for="c-40764583">[-]</label><label class="expand" for="c-40764583">[3 more]</label></div><br/><div class="children"><div class="content">I largely agree with you, but funnily enough the very same blog has a great post on the x86 decoding myth <a href="https:&#x2F;&#x2F;chipsandcheese.com&#x2F;2021&#x2F;07&#x2F;13&#x2F;arm-or-x86-isa-doesnt-matter&#x2F;" rel="nofollow">https:&#x2F;&#x2F;chipsandcheese.com&#x2F;2021&#x2F;07&#x2F;13&#x2F;arm-or-x86-isa-doesnt-...</a></div><br/><div id="40765516" class="c"><input type="checkbox" id="c-40765516" checked=""/><div class="controls bullet"><span class="by">trueismywork</span><span>|</span><a href="#40761375">root</a><span>|</span><a href="#40764583">parent</a><span>|</span><a href="#40762227">next</a><span>|</span><label class="collapse" for="c-40765516">[-]</label><label class="expand" for="c-40765516">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not sure I agree with that. The unknown length of instructions in x86 does make decoders more power hungry. There&#x27;s no doubt about that. That is a big problem for power efificency of x86 and the blog doesn&#x27;t address that at all.<p>M1 really is a counterexample to all theory that Jim is saying etc. The real proof would be if same results were also reproduced on M1 instead of Zen</div><br/><div id="40765764" class="c"><input type="checkbox" id="c-40765764" checked=""/><div class="controls bullet"><span class="by">oelang</span><span>|</span><a href="#40761375">root</a><span>|</span><a href="#40765516">parent</a><span>|</span><a href="#40762227">next</a><span>|</span><label class="collapse" for="c-40765764">[-]</label><label class="expand" for="c-40765764">[1 more]</label></div><br/><div class="children"><div class="content">Jim was involved in the early versions of Zen &amp; M1, I believe he knows.<p>Apples M series looks very impressive because typically, at launch, they are node ahead of the competition, so early access deals with TSMC is the secret weapon this buys them about 6 months. They also are primarily laptop chips, AMD has competitive technology but always launches the low power chips after the desktop &amp; server parts.</div><br/></div></div></div></div></div></div><div id="40762227" class="c"><input type="checkbox" id="c-40762227" checked=""/><div class="controls bullet"><span class="by">ComputerGuru</span><span>|</span><a href="#40761375">parent</a><span>|</span><a href="#40764583">prev</a><span>|</span><a href="#40765361">next</a><span>|</span><label class="collapse" for="c-40762227">[-]</label><label class="expand" for="c-40762227">[11 more]</label></div><br/><div class="children"><div class="content">I agreed with you up until the x86 comment. Legacy x86 support is largely a red herring. The constraints are architectural (as you noted, per-core memory bandwidth, plus other things) more than they are due to being tied down to legacy instruction sets.</div><br/><div id="40762368" class="c"><input type="checkbox" id="c-40762368" checked=""/><div class="controls bullet"><span class="by">mlyle</span><span>|</span><a href="#40761375">root</a><span>|</span><a href="#40762227">parent</a><span>|</span><a href="#40762509">next</a><span>|</span><label class="collapse" for="c-40762368">[-]</label><label class="expand" for="c-40762368">[6 more]</label></div><br/><div class="children"><div class="content">If the goal ends up being many-many-core, x86&#x27;s complexity tax may start to matter.  The cost of x86 compatibility relative to all the complexities required for performance has been small, but if we end up deciding that memory latency is going to kill us and we can&#x27;t keep complex cores fed, then that is a vote for simpler architectures.<p>I suspect the future will be something between these extremes (tons of dumb cores or ever-more-complicated cores to try and squeeze out IPC), though.</div><br/><div id="40763602" class="c"><input type="checkbox" id="c-40763602" checked=""/><div class="controls bullet"><span class="by">hajile</span><span>|</span><a href="#40761375">root</a><span>|</span><a href="#40762368">parent</a><span>|</span><a href="#40762509">next</a><span>|</span><label class="collapse" for="c-40763602">[-]</label><label class="expand" for="c-40763602">[5 more]</label></div><br/><div class="children"><div class="content">The x86 tax ALREADY matters. Intel was only able to increase the number of decoders by adding entirely independent decoder complexes while reducing the number of decoders per branch.<p>In practice, this means that decode increases for branchy code, but non-branchy code will be limited to just 3 decoders. In contrast, an ARM X4 or Apple M4 can decode 10 instructions under all conditions.<p>This also play into ideas like Larabee&#x2F;Knights processors where you basically want the tiniest core possible attached to a massive SIMD engine. x86 decode eats up a lot of real estate. Even worse, x86 decode adds a bunch of extra stages which in turn increase the size of the branch predictor.<p>That&#x27;s not the biggest issue though. Dealing with all of this and all the x86 footguns threaded throughout the pipeline slows down development. It takes more designers and more QAs more time to make and test everything. ARM can develop a similar CPU design for a fraction of the cost compared to AMD&#x2F;Intel and in less time too because there&#x27;s simply fewer edge cases they have to work with. This ultimately means the ARM chips can be sold for significantly less money or higher margins.</div><br/><div id="40764059" class="c"><input type="checkbox" id="c-40764059" checked=""/><div class="controls bullet"><span class="by">jart</span><span>|</span><a href="#40761375">root</a><span>|</span><a href="#40763602">parent</a><span>|</span><a href="#40764028">next</a><span>|</span><label class="collapse" for="c-40764059">[-]</label><label class="expand" for="c-40764059">[2 more]</label></div><br/><div class="children"><div class="content">Then show me the low-cost ARM version of AMD&#x27;s 96-core Threadripper.</div><br/><div id="40764264" class="c"><input type="checkbox" id="c-40764264" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#40761375">root</a><span>|</span><a href="#40764059">parent</a><span>|</span><a href="#40764028">next</a><span>|</span><label class="collapse" for="c-40764264">[-]</label><label class="expand" for="c-40764264">[1 more]</label></div><br/><div class="children"><div class="content">Ampere One was supposed to be out by now.</div><br/></div></div></div></div><div id="40764028" class="c"><input type="checkbox" id="c-40764028" checked=""/><div class="controls bullet"><span class="by">TinkersW</span><span>|</span><a href="#40761375">root</a><span>|</span><a href="#40763602">parent</a><span>|</span><a href="#40764059">prev</a><span>|</span><a href="#40764128">next</a><span>|</span><label class="collapse" for="c-40764028">[-]</label><label class="expand" for="c-40764028">[1 more]</label></div><br/><div class="children"><div class="content">In the talk given by lead architect for skymont they implied it could decode 9 under all conditions, not just when there are heavy branches.</div><br/></div></div><div id="40764128" class="c"><input type="checkbox" id="c-40764128" checked=""/><div class="controls bullet"><span class="by">nuudlman</span><span>|</span><a href="#40761375">root</a><span>|</span><a href="#40763602">parent</a><span>|</span><a href="#40764028">prev</a><span>|</span><a href="#40762509">next</a><span>|</span><label class="collapse" for="c-40764128">[-]</label><label class="expand" for="c-40764128">[1 more]</label></div><br/><div class="children"><div class="content">The fun thing with branch predictors is that they tell you where the next branch is (among other things like the direction of the branch). Since hardware is built out of finite wires, the prediction will saturate to some maximum distance (something in the next few cache lines).<p>How this affects decode clusters is left as an exercise to the reader.</div><br/></div></div></div></div></div></div><div id="40762509" class="c"><input type="checkbox" id="c-40762509" checked=""/><div class="controls bullet"><span class="by">Pet_Ant</span><span>|</span><a href="#40761375">root</a><span>|</span><a href="#40762227">parent</a><span>|</span><a href="#40762368">prev</a><span>|</span><a href="#40765361">next</a><span>|</span><label class="collapse" for="c-40762509">[-]</label><label class="expand" for="c-40762509">[4 more]</label></div><br/><div class="children"><div class="content">Each core needs to handle the full complexity of x86. Now, as super-scalar OoO x86 cores have evolved the percentage of die allocated to  decoding the cruft has gone down.<p>…but when we start swarming simple cores, that cost starts to rise. Each core needs to be able to decode everything. Now when you can a 100 cores, even if the cruft is just 4%, that means you can have 4 more cores. This is for free if you are willing to recompile your code.<p>Now, it may turn out that we need more decoding complexity than something like RISC-V currently has (Qualcomm has been working in it), but these will be deliberate, intentionally chose instead of accrued, that meet the needs of today and current trade offs, and not of the eart 80’s.</div><br/><div id="40762798" class="c"><input type="checkbox" id="c-40762798" checked=""/><div class="controls bullet"><span class="by">magicalhippo</span><span>|</span><a href="#40761375">root</a><span>|</span><a href="#40762509">parent</a><span>|</span><a href="#40765361">next</a><span>|</span><label class="collapse" for="c-40762798">[-]</label><label class="expand" for="c-40762798">[3 more]</label></div><br/><div class="children"><div class="content">As a developer of fairly standard software, there&#x27;s very little I can say I rely on from the x86&#x2F;x64 ISA.<p>One big one is probably around consistency model[1] and such which affects atomic operations and synchronizing multi-threaded code. Usually not directly though, I typically use libraries or OS primitives.<p>Are there any non-obvious (to me anyway) ways us &quot;typical devs&quot; rely on x86&#x2F;x64?<p>I get the sense that a lot of software is one recompile away from running on some other ISA, but perhaps I&#x27;m overly naive.<p>[1]: <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Consistency_model" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Consistency_model</a></div><br/><div id="40763695" class="c"><input type="checkbox" id="c-40763695" checked=""/><div class="controls bullet"><span class="by">ajross</span><span>|</span><a href="#40761375">root</a><span>|</span><a href="#40762798">parent</a><span>|</span><a href="#40765361">next</a><span>|</span><label class="collapse" for="c-40763695">[-]</label><label class="expand" for="c-40763695">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Are there any non-obvious (to me anyway) ways us &quot;typical devs&quot; rely on x86&#x2F;x64?<p>Generally the answer is &quot;we bought this product 12 years ago and it doesn&#x27;t have an ARM version&quot;.  Or variants like &quot;We can&#x27;t retire this set of systems which is still running the binary we blessed in this other contract&quot;.<p>It&#x27;s true that no one writing &quot;fairly standard software&quot; is freaking out over the inability to work on a platform without AVX-VNNI, or deals with lockless algorithms that can&#x27;t be made feasibly correct with only acquire&#x2F;release memory ordering semantics.  But that&#x27;s not really where the friction is.</div><br/><div id="40764689" class="c"><input type="checkbox" id="c-40764689" checked=""/><div class="controls bullet"><span class="by">EasyMark</span><span>|</span><a href="#40761375">root</a><span>|</span><a href="#40763695">parent</a><span>|</span><a href="#40765361">next</a><span>|</span><label class="collapse" for="c-40764689">[-]</label><label class="expand" for="c-40764689">[1 more]</label></div><br/><div class="children"><div class="content">A lot of systems are “good enough” and run flawlessly for years&#x2F;decades so unless you have a good business case you won’t be able to move from x86 to ARM or the new RISC open stuff because the original system cost a couple million dollars.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="40765361" class="c"><input type="checkbox" id="c-40765361" checked=""/><div class="controls bullet"><span class="by">uluyol</span><span>|</span><a href="#40761375">parent</a><span>|</span><a href="#40762227">prev</a><span>|</span><a href="#40763143">next</a><span>|</span><label class="collapse" for="c-40765361">[-]</label><label class="expand" for="c-40765361">[1 more]</label></div><br/><div class="children"><div class="content">This idea was explored over a decade ago, in the context of cloud computing: <a href="https:&#x2F;&#x2F;www.cs.cmu.edu&#x2F;~fawnproj&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.cs.cmu.edu&#x2F;~fawnproj&#x2F;</a></div><br/></div></div><div id="40763143" class="c"><input type="checkbox" id="c-40763143" checked=""/><div class="controls bullet"><span class="by">jorvi</span><span>|</span><a href="#40761375">parent</a><span>|</span><a href="#40765361">prev</a><span>|</span><a href="#40763939">next</a><span>|</span><label class="collapse" for="c-40763143">[-]</label><label class="expand" for="c-40763143">[12 more]</label></div><br/><div class="children"><div class="content">&gt; As I said before, I do believe that this is the future of CPUs core<p>It is not. Or at least not <i>the</i> future, singular. Many applications still favor strong single-core performance, which means in, say, a 64-core CPU, ~56 (if not more) of them will be twiddling their thumbs.<p>&gt; It&#x27;s in the environment that the weight of x86&#x27;s legacy will catch up with us and we&#x27;ll need to get rid of all the waste transistors decoding cruft.<p>This very same site has a well-known article named “ISA doesn’t matter”. As noted though, with many-core, having to budget decoder silicon&#x2F;power might start to matter enough.</div><br/><div id="40764103" class="c"><input type="checkbox" id="c-40764103" checked=""/><div class="controls bullet"><span class="by">jart</span><span>|</span><a href="#40761375">root</a><span>|</span><a href="#40763143">parent</a><span>|</span><a href="#40763376">next</a><span>|</span><label class="collapse" for="c-40764103">[-]</label><label class="expand" for="c-40764103">[10 more]</label></div><br/><div class="children"><div class="content">Why does everyone keep repeating this mantra? I wrote the x86 decoder for <a href="https:&#x2F;&#x2F;github.com&#x2F;jart&#x2F;blink">https:&#x2F;&#x2F;github.com&#x2F;jart&#x2F;blink</a> which is based off intel&#x27;s xed disassembler. It&#x27;s so tiny to do if you you have the know-how to do it.<p><pre><code>    master jart@studio:~&#x2F;blink$ ls -hal o&#x2F;tiny&#x2F;blink&#x2F;x86.o
    -rw-r--r-- 1 jart staff 23K Jun 22 19:03 o&#x2F;tiny&#x2F;blink&#x2F;x86.o
</code></pre>
Modern microprocessors have 100,000,000,000+ transistors, so how much die space could 184,000 bits for x86 decoding really need? What proof is there that this isn&#x27;t just some holy war over the user-facing design. The stuff that actually matters is probably just memory speed and other chip internals, and companies like Intel, AMD, NVIDIA, and ARM aren&#x27;t sharing that with us. So if you think you understand the challenges and tradeoffs they&#x27;re facing, then I&#x27;m willing to bet it&#x27;s just false confidence and peanut gallery consensus, since we don&#x27;t know what we don&#x27;t know.</div><br/><div id="40764253" class="c"><input type="checkbox" id="c-40764253" checked=""/><div class="controls bullet"><span class="by">innocenat</span><span>|</span><a href="#40761375">root</a><span>|</span><a href="#40764103">parent</a><span>|</span><a href="#40763376">next</a><span>|</span><label class="collapse" for="c-40764253">[-]</label><label class="expand" for="c-40764253">[9 more]</label></div><br/><div class="children"><div class="content">Decoding 1 x86 instruction per cycle is easy. That&#x27;s solved like 40 years ago.<p>The problem is that superscalar CPU needs to decode multiple x86 instructions per cycle. I think latest Intel big core pipeline can do (IIRC) 6 instructions per cycle, so to keep the pipeline full the decode MUST be able to decode 6 per cycle too.<p>If it&#x27;s ARM, it&#x27;s easy to do multiple decode. M1 do (IIRC) 8 per cycle easily, because the instruction length is fixed. So the first decoder starts at PC, the second starts at PC+4, etc. But x86 instructions are variable length, so after the first decoder decodes instruction at IP, where does the second decoder start decoding at?</div><br/><div id="40764284" class="c"><input type="checkbox" id="c-40764284" checked=""/><div class="controls bullet"><span class="by">kijiki</span><span>|</span><a href="#40761375">root</a><span>|</span><a href="#40764253">parent</a><span>|</span><a href="#40763376">next</a><span>|</span><label class="collapse" for="c-40764284">[-]</label><label class="expand" for="c-40764284">[8 more]</label></div><br/><div class="children"><div class="content">It isn&#x27;t quite that bad. The decoders write stop bits back into the L1D, to demarc where the instructions align. Since those bits aren&#x27;t indexed in the cache and don&#x27;t affect associativity, they don&#x27;t really cost much. A handful of 6T SRAMs per cache line.</div><br/><div id="40764563" class="c"><input type="checkbox" id="c-40764563" checked=""/><div class="controls bullet"><span class="by">jart</span><span>|</span><a href="#40761375">root</a><span>|</span><a href="#40764284">parent</a><span>|</span><a href="#40763376">next</a><span>|</span><label class="collapse" for="c-40764563">[-]</label><label class="expand" for="c-40764563">[7 more]</label></div><br/><div class="children"><div class="content">I would have assumed it just decodes the x86 into a 32-bit ARM-like internal ISA, similar to how a JIT works in software. x86 decoding is extremely costly in software if you build an interpreter. Probably like 30% maybe and that&#x27;s assuming you have a cache. But with JIT code morphing in Blink, decoding cost drops to essentially nothing. As best as I understand it, all x86 microprocessors since the NexGen i586 have worked this way too. Once you&#x27;re code morphing the frontend user-facing ISA, a much bigger problem rears its ugly head, which is the 4096-byte page size. That&#x27;s something Apple really harped on with their M1 design which increased it to 16kb. It matters since morphed code can&#x27;t be connected across page boundaries.</div><br/><div id="40765062" class="c"><input type="checkbox" id="c-40765062" checked=""/><div class="controls bullet"><span class="by">kijiki</span><span>|</span><a href="#40761375">root</a><span>|</span><a href="#40764563">parent</a><span>|</span><a href="#40764612">next</a><span>|</span><label class="collapse" for="c-40765062">[-]</label><label class="expand" for="c-40765062">[1 more]</label></div><br/><div class="children"><div class="content">It decodes to uOPs optimized for the exact microarchitecture of that particular CPU. High performance ARM64 designs do the same.<p>But in the specific case of tracking variable length instruction boundaries, that happens in the L1i cache. uOP caches make decode bandwidth less critical, but it is still important enough to optimize.</div><br/></div></div><div id="40764612" class="c"><input type="checkbox" id="c-40764612" checked=""/><div class="controls bullet"><span class="by">innocenat</span><span>|</span><a href="#40761375">root</a><span>|</span><a href="#40764563">parent</a><span>|</span><a href="#40765062">prev</a><span>|</span><a href="#40763376">next</a><span>|</span><label class="collapse" for="c-40764612">[-]</label><label class="expand" for="c-40764612">[5 more]</label></div><br/><div class="children"><div class="content">That&#x27;s called uOP cache, which Intel has been using since Sandy Bridge (and AMD but I don&#x27;t remember on top of my head since when). But that&#x27;s more transistors for the cache and its control mechanism.</div><br/><div id="40764664" class="c"><input type="checkbox" id="c-40764664" checked=""/><div class="controls bullet"><span class="by">jart</span><span>|</span><a href="#40761375">root</a><span>|</span><a href="#40764612">parent</a><span>|</span><a href="#40763376">next</a><span>|</span><label class="collapse" for="c-40764664">[-]</label><label class="expand" for="c-40764664">[4 more]</label></div><br/><div class="children"><div class="content">It&#x27;s definitely better than what NVIDIA does, inventing an entirely new ISA each year. If the hardware isn&#x27;t paying the cost for a frontend, then it shovels the burden onto software. There&#x27;s a reason every AI app has to bundle a 500mb matrix multiplication library in each download, and it&#x27;s because GPUs force you to compile your code ten times for the last ten years of ISAs.</div><br/><div id="40765229" class="c"><input type="checkbox" id="c-40765229" checked=""/><div class="controls bullet"><span class="by">saagarjha</span><span>|</span><a href="#40761375">root</a><span>|</span><a href="#40764664">parent</a><span>|</span><a href="#40765519">next</a><span>|</span><label class="collapse" for="c-40765229">[-]</label><label class="expand" for="c-40765229">[1 more]</label></div><br/><div class="children"><div class="content">Part of it is that, but part of it is that people pay for getting from 95% optimal to 99% optimal, and doing that is actually a lot of work. If you peek inside the matrix multiplication library you&#x27;ll note that it&#x27;s not just &quot;we have the best algorithm for the last 7 GPU microarchitectures&quot; but also 7 implementations <i>for the latest architecture</i> because that&#x27;s just how you need to be to go fast. Kind of like how if you take an uninformed look at glibc memcpy you&#x27;ll see there is an AVX2 path and a ERMS path but also it will switch between algorithms based on the size of the input. You can easily go &quot;yeah my SSE2 code is tiny and gets decent performance&quot; but if you stop there you&#x27;re leaving something on the table, and with GPUs it&#x27;s this but even more extreme.</div><br/></div></div><div id="40765519" class="c"><input type="checkbox" id="c-40765519" checked=""/><div class="controls bullet"><span class="by">camel-cdr</span><span>|</span><a href="#40761375">root</a><span>|</span><a href="#40764664">parent</a><span>|</span><a href="#40765229">prev</a><span>|</span><a href="#40764733">next</a><span>|</span><label class="collapse" for="c-40765519">[-]</label><label class="expand" for="c-40765519">[1 more]</label></div><br/><div class="children"><div class="content">Using the uops directy as the isa would be a bad idea for code density.
In RISC-V land, vendors tend to target standard extensions&#x2F;profiles, but when they hardware is capable of other operations they often expose those through custom extensions.</div><br/></div></div><div id="40764733" class="c"><input type="checkbox" id="c-40764733" checked=""/><div class="controls bullet"><span class="by">kiratp</span><span>|</span><a href="#40761375">root</a><span>|</span><a href="#40764664">parent</a><span>|</span><a href="#40765519">prev</a><span>|</span><a href="#40763376">next</a><span>|</span><label class="collapse" for="c-40764733">[-]</label><label class="expand" for="c-40764733">[1 more]</label></div><br/><div class="children"><div class="content">IMO if the trade off is cheaper, faster hardware iteration then Nvidia’s strategy makes a lot of sense.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="40763376" class="c"><input type="checkbox" id="c-40763376" checked=""/><div class="controls bullet"><span class="by">ajross</span><span>|</span><a href="#40761375">root</a><span>|</span><a href="#40763143">parent</a><span>|</span><a href="#40764103">prev</a><span>|</span><a href="#40763939">next</a><span>|</span><label class="collapse" for="c-40763376">[-]</label><label class="expand" for="c-40763376">[1 more]</label></div><br/><div class="children"><div class="content">&gt; with many-core, having to budget decoder silicon&#x2F;power might start to matter enough<p>That seems backwards to me.  Narrower, simpler cores with fewer execution engines have a <i>much easier</i> time decoding.  It&#x27;s the combinatorics of x86&#x27;s variable length instructions and prefix coding that makes wide decoders superlinearly expensive.</div><br/></div></div></div></div><div id="40763939" class="c"><input type="checkbox" id="c-40763939" checked=""/><div class="controls bullet"><span class="by">jiggawatts</span><span>|</span><a href="#40761375">parent</a><span>|</span><a href="#40763143">prev</a><span>|</span><a href="#40761485">next</a><span>|</span><label class="collapse" for="c-40763939">[-]</label><label class="expand" for="c-40763939">[2 more]</label></div><br/><div class="children"><div class="content">Something I&#x27;ve realised is that we&#x27;re entering the era of &quot;kilocores&quot;, where we start counting cores by the thousands, much like the early computers had kilo-words of memory. Soon... mega-cores, then giga-cores, and on!</div><br/><div id="40765510" class="c"><input type="checkbox" id="c-40765510" checked=""/><div class="controls bullet"><span class="by">foota</span><span>|</span><a href="#40761375">root</a><span>|</span><a href="#40763939">parent</a><span>|</span><a href="#40761485">next</a><span>|</span><label class="collapse" for="c-40765510">[-]</label><label class="expand" for="c-40765510">[1 more]</label></div><br/><div class="children"><div class="content">Hate to burst your bubble, but with the end of Moores law this seems unlikely to pass.</div><br/></div></div></div></div></div></div><div id="40761485" class="c"><input type="checkbox" id="c-40761485" checked=""/><div class="controls bullet"><span class="by">adrian_b</span><span>|</span><a href="#40761375">prev</a><span>|</span><a href="#40764365">next</a><span>|</span><label class="collapse" for="c-40761485">[-]</label><label class="expand" for="c-40761485">[2 more]</label></div><br/><div class="children"><div class="content">The article says &quot;AMD’s server platform also leaves potential for expansion. Top end Genoa SKUs use 12 compute chiplets while Bergamo is limited to just eight. 12 Zen 4c compute dies would let AMD fit 192 cores in a single socket&quot;.<p>It should be noted that the successor of Bergamo, Turin dense, which is expected by the end of the year, will have 12 compute chiplets, for a total of 192 Zen 5c cores, bringing thus both more cores and faster cores.</div><br/><div id="40762495" class="c"><input type="checkbox" id="c-40762495" checked=""/><div class="controls bullet"><span class="by">metadat</span><span>|</span><a href="#40761485">parent</a><span>|</span><a href="#40764365">next</a><span>|</span><label class="collapse" for="c-40762495">[-]</label><label class="expand" for="c-40762495">[1 more]</label></div><br/><div class="children"><div class="content">192 cores per socket?  If so, that&#x27;s pretty wild.</div><br/></div></div></div></div><div id="40764365" class="c"><input type="checkbox" id="c-40764365" checked=""/><div class="controls bullet"><span class="by">crote</span><span>|</span><a href="#40761485">prev</a><span>|</span><a href="#40763865">next</a><span>|</span><label class="collapse" for="c-40764365">[-]</label><label class="expand" for="c-40764365">[5 more]</label></div><br/><div class="children"><div class="content">I wonder if these large cache sizes make it possible to operate functionally RAM-less servers? When optimized for size, it&#x27;d probably be possible to fit some microservices in an MB of 8 of RAM. You can fit a decent bit of per-connection client state in a few KB, which can take up the rest of the cache. Throw in the X3D cache for 96MB per CCD and you can actually do some pretty serious stuff.<p>With the right preprocessing, it <i>should</i> be possible to essentially stream from NIC straight to CPU, process some stuff, and output it straight to the NIC again <i>without ever touching RAM</i> - although I doubt current DMA hardware allows this. It&#x27;d require quite a bit of re-engineering of the on-wire protocol to remove the need for any nontrivially-sized buffers, but I reckon it isn&#x27;t impossible.</div><br/><div id="40764426" class="c"><input type="checkbox" id="c-40764426" checked=""/><div class="controls bullet"><span class="by">yusyusyus</span><span>|</span><a href="#40764365">parent</a><span>|</span><a href="#40764819">next</a><span>|</span><label class="collapse" for="c-40764426">[-]</label><label class="expand" for="c-40764426">[1 more]</label></div><br/><div class="children"><div class="content">&gt; With the right preprocessing, it should be possible to essentially stream from NIC straight to CPU, process some stuff, and output it straight to the NIC again without ever touching RAM<p>this already exists [0]<p>[0] <a href="https:&#x2F;&#x2F;www.intel.com&#x2F;content&#x2F;dam&#x2F;www&#x2F;public&#x2F;us&#x2F;en&#x2F;documents&#x2F;technology-briefs&#x2F;data-direct-i-o-technology-brief.pdf" rel="nofollow">https:&#x2F;&#x2F;www.intel.com&#x2F;content&#x2F;dam&#x2F;www&#x2F;public&#x2F;us&#x2F;en&#x2F;documents...</a></div><br/></div></div><div id="40764819" class="c"><input type="checkbox" id="c-40764819" checked=""/><div class="controls bullet"><span class="by">foota</span><span>|</span><a href="#40764365">parent</a><span>|</span><a href="#40764426">prev</a><span>|</span><a href="#40764773">next</a><span>|</span><label class="collapse" for="c-40764819">[-]</label><label class="expand" for="c-40764819">[1 more]</label></div><br/><div class="children"><div class="content">This is theoretically true, but I think you&#x27;d have to get a lot of support from AMD and be responsible for implementing most of a traditional computer yourself. I have a feeling it&#x27;s be roughly as feasible to do it all with fully custom hardware.<p>Otoh if you just mean try to write software to minimize the need to hit memory, that&#x27;s totally reasonable -- and what you have to do if you want the best performance.</div><br/></div></div><div id="40764773" class="c"><input type="checkbox" id="c-40764773" checked=""/><div class="controls bullet"><span class="by">timschmidt</span><span>|</span><a href="#40764365">parent</a><span>|</span><a href="#40764819">prev</a><span>|</span><a href="#40764776">next</a><span>|</span><label class="collapse" for="c-40764773">[-]</label><label class="expand" for="c-40764773">[1 more]</label></div><br/><div class="children"><div class="content">Lots of older or low end wireless routers have only 16 or 32mb RAM.  A full linux stack fits in that.  I do a full HTTPS stack on ESP32-C3 in ~500k.  Lots of limitations, of course.  Probably the biggest difficulty is that most modern systems simply refuse to boot without RAM installed, so you can&#x27;t choose any platform without BIOS &#x2F; EFI modifications.  Definitely a worthwhile idea though.</div><br/></div></div><div id="40764776" class="c"><input type="checkbox" id="c-40764776" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#40764365">parent</a><span>|</span><a href="#40764773">prev</a><span>|</span><a href="#40763865">next</a><span>|</span><label class="collapse" for="c-40764776">[-]</label><label class="expand" for="c-40764776">[1 more]</label></div><br/><div class="children"><div class="content">Intel definitely has cache injection for DMA; I&#x27;m not sure about AMD. With DPDK you should be able to process packets completely in the L3.</div><br/></div></div></div></div><div id="40763865" class="c"><input type="checkbox" id="c-40763865" checked=""/><div class="controls bullet"><span class="by">Havoc</span><span>|</span><a href="#40764365">prev</a><span>|</span><a href="#40761054">next</a><span>|</span><label class="collapse" for="c-40763865">[-]</label><label class="expand" for="c-40763865">[5 more]</label></div><br/><div class="children"><div class="content">Every time I hear about a 100+ core my mind jumps to python GIL</div><br/><div id="40764697" class="c"><input type="checkbox" id="c-40764697" checked=""/><div class="controls bullet"><span class="by">EasyMark</span><span>|</span><a href="#40763865">parent</a><span>|</span><a href="#40761054">next</a><span>|</span><label class="collapse" for="c-40764697">[-]</label><label class="expand" for="c-40764697">[4 more]</label></div><br/><div class="children"><div class="content">Has been heavily worked on in python 3.12 and up, don’t count out python just yet :)</div><br/><div id="40765515" class="c"><input type="checkbox" id="c-40765515" checked=""/><div class="controls bullet"><span class="by">Sesse__</span><span>|</span><a href="#40763865">root</a><span>|</span><a href="#40764697">parent</a><span>|</span><a href="#40761054">next</a><span>|</span><label class="collapse" for="c-40765515">[-]</label><label class="expand" for="c-40765515">[3 more]</label></div><br/><div class="children"><div class="content">Spoiler alert: Software doesn&#x27;t jump from “uses one core” to “efficiently uses 192 cores” once you remove the first lock.</div><br/><div id="40765728" class="c"><input type="checkbox" id="c-40765728" checked=""/><div class="controls bullet"><span class="by">merb</span><span>|</span><a href="#40763865">root</a><span>|</span><a href="#40765515">parent</a><span>|</span><a href="#40765572">next</a><span>|</span><label class="collapse" for="c-40765728">[-]</label><label class="expand" for="c-40765728">[1 more]</label></div><br/><div class="children"><div class="content">well back in the days when somebody invented gunicorn it was basically running one worker per core, if the software allowed it. thus you at least could scale on the process level, which of course was super slow if you only had like 10 req&#x2F;s on a 60 cores machine.</div><br/></div></div></div></div></div></div></div></div><div id="40761054" class="c"><input type="checkbox" id="c-40761054" checked=""/><div class="controls bullet"><span class="by">tedunangst</span><span>|</span><a href="#40763865">prev</a><span>|</span><a href="#40763535">next</a><span>|</span><label class="collapse" for="c-40761054">[-]</label><label class="expand" for="c-40761054">[12 more]</label></div><br/><div class="children"><div class="content">I remember as part of the TBB library release, Intel remarked that 100 pentium cores had the same transistor count of a core2. Took a while, but starting to turn the corner on slower and wider becoming more common.</div><br/><div id="40763208" class="c"><input type="checkbox" id="c-40763208" checked=""/><div class="controls bullet"><span class="by">dialup_sounds</span><span>|</span><a href="#40761054">parent</a><span>|</span><a href="#40762440">next</a><span>|</span><label class="collapse" for="c-40763208">[-]</label><label class="expand" for="c-40763208">[3 more]</label></div><br/><div class="children"><div class="content">Reminds me of the ill-fated Larabee, which was supposed to be something like 50 Pentium-like cores in a GPU-shaped trenchcoat.</div><br/><div id="40763637" class="c"><input type="checkbox" id="c-40763637" checked=""/><div class="controls bullet"><span class="by">hajile</span><span>|</span><a href="#40761054">root</a><span>|</span><a href="#40763208">parent</a><span>|</span><a href="#40762440">next</a><span>|</span><label class="collapse" for="c-40763637">[-]</label><label class="expand" for="c-40763637">[2 more]</label></div><br/><div class="children"><div class="content">Larabee was launched as the first generation Knight-series chip (it even had the GPU-specific stuff still in there disabled IIRC).<p>I believe the Knight-series chips were killed because they ran into a bunch of issues and politics with Knight&#x27;s Mill then killed it in favor of their upcoming GPU architecture only for that to have issues and be delayed too.<p>I suspect that a RISC-V version of Larabee would work better as the ratio of SIMD to the rest of the core would be a lot better.</div><br/><div id="40764206" class="c"><input type="checkbox" id="c-40764206" checked=""/><div class="controls bullet"><span class="by">kijiki</span><span>|</span><a href="#40761054">root</a><span>|</span><a href="#40763637">parent</a><span>|</span><a href="#40762440">next</a><span>|</span><label class="collapse" for="c-40764206">[-]</label><label class="expand" for="c-40764206">[1 more]</label></div><br/><div class="children"><div class="content">A dual-issue in-order RISC-V isn&#x27;t enough smaller than a P54c to make a significant difference. The overwhelming majority of Larabee&#x27;s area went to SIMD units and caches.</div><br/></div></div></div></div></div></div><div id="40762440" class="c"><input type="checkbox" id="c-40762440" checked=""/><div class="controls bullet"><span class="by">imtringued</span><span>|</span><a href="#40761054">parent</a><span>|</span><a href="#40763208">prev</a><span>|</span><a href="#40762435">next</a><span>|</span><label class="collapse" for="c-40762440">[-]</label><label class="expand" for="c-40762440">[7 more]</label></div><br/><div class="children"><div class="content">The problem with adding more cores is that SRAM is the real bottleneck. Adding more cores means more cache.<p>Until someone figures out how to do 3D stackable SRAM similar to how SSDs work, SRAM will always consume most of the area on your chip.</div><br/><div id="40765260" class="c"><input type="checkbox" id="c-40765260" checked=""/><div class="controls bullet"><span class="by">fulafel</span><span>|</span><a href="#40761054">root</a><span>|</span><a href="#40762440">parent</a><span>|</span><a href="#40762659">next</a><span>|</span><label class="collapse" for="c-40765260">[-]</label><label class="expand" for="c-40765260">[1 more]</label></div><br/><div class="children"><div class="content">The real real problem is that we don&#x27;t know how to effectively use growing transistor budgets to speed applications up compared to the single core era. Adding cache and more cores are both options that make for very sublinear improvements at the margin.<p>(for 95% of usage - somen niche things can utilize resources better, those not coincidentally often being the focus of benchmarks)</div><br/></div></div><div id="40762659" class="c"><input type="checkbox" id="c-40762659" checked=""/><div class="controls bullet"><span class="by">JonChesterfield</span><span>|</span><a href="#40761054">root</a><span>|</span><a href="#40762440">parent</a><span>|</span><a href="#40765260">prev</a><span>|</span><a href="#40762494">next</a><span>|</span><label class="collapse" for="c-40762659">[-]</label><label class="expand" for="c-40762659">[4 more]</label></div><br/><div class="children"><div class="content">This isn&#x27;t fill the reticle with CPU, it&#x27;s make a dozen separate chips and package them on a network fabric. Amount of cache can increase linearly with number of cores without a problem.<p>There is some outstanding uncertainty about cache coherency vs performance as N goes up which shows up in numa cliff fashion. My pet theory is that&#x27;ll be what ultimately kills x64 - the concurrency semantics are skewed really hard towards convenience and thus away from scalability.</div><br/><div id="40762894" class="c"><input type="checkbox" id="c-40762894" checked=""/><div class="controls bullet"><span class="by">doctor_eval</span><span>|</span><a href="#40761054">root</a><span>|</span><a href="#40762659">parent</a><span>|</span><a href="#40762494">next</a><span>|</span><label class="collapse" for="c-40762894">[-]</label><label class="expand" for="c-40762894">[3 more]</label></div><br/><div class="children"><div class="content">I know next to nothing about CPU architecture so please forgive a stupid question.<p>Are you saying that the x86 memory model means RAM latency is more impactful than on some other architectures?<p>Is this (tangentially) related to the memory mode that Apple reportedly added to the M1 to emulate x86 memory model to make emulation faster? - presumably to account for assumptions that compilers make about the state of the CPU after certain operations?</div><br/><div id="40764369" class="c"><input type="checkbox" id="c-40764369" checked=""/><div class="controls bullet"><span class="by">CoastalCoder</span><span>|</span><a href="#40761054">root</a><span>|</span><a href="#40762894">parent</a><span>|</span><a href="#40765010">next</a><span>|</span><label class="collapse" for="c-40764369">[-]</label><label class="expand" for="c-40764369">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m guessing GP&#x27;s point is that x86 makes really strong memory consistency guarantees.<p>It makes life easier for programmers of multithreaded software, but at the cost of high synchronization overhead.<p>Contrast to e.g. Arm, where programmers can avoid a lot of that synchronization, but in exchange they have to be more careful.<p>* IIRC from some recent reading.</div><br/></div></div><div id="40765010" class="c"><input type="checkbox" id="c-40765010" checked=""/><div class="controls bullet"><span class="by">inkyoto</span><span>|</span><a href="#40761054">root</a><span>|</span><a href="#40762894">parent</a><span>|</span><a href="#40764369">prev</a><span>|</span><a href="#40762494">next</a><span>|</span><label class="collapse" for="c-40765010">[-]</label><label class="expand" for="c-40765010">[1 more]</label></div><br/><div class="children"><div class="content">The preceding comment was about the CPU cache coherency, which is the bane of the symmetric multiprocessor (SMP) system design. The problem arises due to the fact the main memory is shared across processors (or CPU cores). Consider this rough sketch:<p><pre><code>                                            [memory (shared)]
                                                    ⇕
                                           [L3 cache (shared)]
                                                    ⇕
  [core 0] ⟺ [L1 cache (private)]   ⟺   [L2 cache (shared)]   ⟺   [L1 cache (private)] ⟺ [core N]
                                                    ⇕
                                     [core 1] ⟺ [L1 cache (private)]

</code></pre>
Each CPU (or CPU core) has its own private L1 cache that other CPU&#x27;s&#x2F;CPU cores do not have access to. Now, 
code running on the CPU 0 has modified 32 bytes at the address 0x1234 but the modification does not occur directly in the main memory, it takes places within a cache and changes to the data now have to be written back into the main memory. Depending on the complexity of the system design, the change has to be back propagates through a hierarchy of L2&#x2F;L3&#x2F;L4 (POWER CPU&#x27;s have a L4 cache) caches until the main memory that is shared across all CPU&#x27;s is updated.<p>It is easy and simple if no other CPU is trying to access the address 0x1234 at the same time – the change is simply written back and the job is done.<p>But when another CPU is trying to access the same 0x1234 address at the same time whilst the change has not made it back into the main memory, there is a problem as stale data reads are typically not allowed, and another CPU &#x2F; CPU cores has to wait for the CPU 0 to complete the write back. Since multiple cache level are involved in modern system design, the problem is known as the cache coherency problem, and it is a very complex problem to solve in SMP designs.<p>It is a grossly oversimplified description of the problem, but it should be able to illustrate what the parent was referring to.</div><br/></div></div></div></div></div></div><div id="40762494" class="c"><input type="checkbox" id="c-40762494" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#40761054">root</a><span>|</span><a href="#40762440">parent</a><span>|</span><a href="#40762659">prev</a><span>|</span><a href="#40762435">next</a><span>|</span><label class="collapse" for="c-40762494">[-]</label><label class="expand" for="c-40762494">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s called V-Cache.</div><br/></div></div></div></div></div></div><div id="40763535" class="c"><input type="checkbox" id="c-40763535" checked=""/><div class="controls bullet"><span class="by">saxonww</span><span>|</span><a href="#40761054">prev</a><span>|</span><a href="#40761190">next</a><span>|</span><label class="collapse" for="c-40763535">[-]</label><label class="expand" for="c-40763535">[3 more]</label></div><br/><div class="children"><div class="content">My immediate thought is that Sun beat both of these guys to market with the T1 20 years ago. Not exactly the same thing, but I wonder how close to the same idea they are; the line seems to have stopped with the M8, which is a 32c&#x2F;256t part from 2017.</div><br/><div id="40764068" class="c"><input type="checkbox" id="c-40764068" checked=""/><div class="controls bullet"><span class="by">kllrnohj</span><span>|</span><a href="#40763535">parent</a><span>|</span><a href="#40764169">next</a><span>|</span><label class="collapse" for="c-40764068">[-]</label><label class="expand" for="c-40764068">[1 more]</label></div><br/><div class="children"><div class="content">&gt; the line seems to have stopped with the M8, which is a 32c&#x2F;256t part from 2017.<p>Epyc Naples was also 32c and also 2017. 4- and 8-way SMT wasn&#x27;t something AMD or Intel ever bothered with, no, but IBM also did with the POWER line. It seems to help in some workloads, but probably isn&#x27;t generally useful enough for volume solutions.</div><br/></div></div><div id="40764169" class="c"><input type="checkbox" id="c-40764169" checked=""/><div class="controls bullet"><span class="by">kijiki</span><span>|</span><a href="#40763535">parent</a><span>|</span><a href="#40764068">prev</a><span>|</span><a href="#40761190">next</a><span>|</span><label class="collapse" for="c-40764169">[-]</label><label class="expand" for="c-40764169">[1 more]</label></div><br/><div class="children"><div class="content">There is an absolutely huge difference between a 32c&#x2F;256t part and a 128c&#x2F;256t part. And Tera&#x27;s MTA predated the T1 by quite a bit with a similar (and evidently doomed) architecture...</div><br/></div></div></div></div><div id="40761190" class="c"><input type="checkbox" id="c-40761190" checked=""/><div class="controls bullet"><span class="by">nullc</span><span>|</span><a href="#40763535">prev</a><span>|</span><a href="#40761364">next</a><span>|</span><label class="collapse" for="c-40761190">[-]</label><label class="expand" for="c-40761190">[4 more]</label></div><br/><div class="children"><div class="content">Is the 4c core slower in any other way than L3 cache reductions?<p>Would be interesting to see a compute bound perfectly scaling workload and compare it in terms of absolute performance and performance per watt between Bergamo and Genoa.</div><br/><div id="40761209" class="c"><input type="checkbox" id="c-40761209" checked=""/><div class="controls bullet"><span class="by">mlyle</span><span>|</span><a href="#40761190">parent</a><span>|</span><a href="#40761337">next</a><span>|</span><label class="collapse" for="c-40761209">[-]</label><label class="expand" for="c-40761209">[1 more]</label></div><br/><div class="children"><div class="content">Same performance per cycle; less L3 and lower maximum frequency.<p>Zen4C is said to be a little better performance per watt than Zen4, but it&#x27;s not clear how much.</div><br/></div></div><div id="40761337" class="c"><input type="checkbox" id="c-40761337" checked=""/><div class="controls bullet"><span class="by">toast0</span><span>|</span><a href="#40761190">parent</a><span>|</span><a href="#40761209">prev</a><span>|</span><a href="#40761360">next</a><span>|</span><label class="collapse" for="c-40761337">[-]</label><label class="expand" for="c-40761337">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Is the 4c core slower in any other way than L3 cache reductions?<p>It&#x27;s got a lower clock ceiling. Not much lower than acheivable clocks in really dense zen4 Epyc, but a lot less than an 8 core Ryzen.</div><br/></div></div><div id="40761360" class="c"><input type="checkbox" id="c-40761360" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#40761190">parent</a><span>|</span><a href="#40761337">prev</a><span>|</span><a href="#40761364">next</a><span>|</span><label class="collapse" for="c-40761360">[-]</label><label class="expand" for="c-40761360">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;www.phoronix.com&#x2F;review&#x2F;amd-epyc-9754-bergamo&#x2F;2" rel="nofollow">https:&#x2F;&#x2F;www.phoronix.com&#x2F;review&#x2F;amd-epyc-9754-bergamo&#x2F;2</a></div><br/></div></div></div></div></div></div></div></div></div></body></html>