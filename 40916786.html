<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1720688470030" as="style"/><link rel="stylesheet" href="styles.css?v=1720688470030"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://turbopuffer.com/blog/turbopuffer">Turbopuffer: Fast search on object storage</a> <span class="domain">(<a href="https://turbopuffer.com">turbopuffer.com</a>)</span></div><div class="subtext"><span>Sirupsen</span> | <span>67 comments</span></div><br/><div><div id="40920438" class="c"><input type="checkbox" id="c-40920438" checked=""/><div class="controls bullet"><span class="by">softwaredoug</span><span>|</span><a href="#40920639">next</a><span>|</span><label class="collapse" for="c-40920438">[-]</label><label class="expand" for="c-40920438">[3 more]</label></div><br/><div class="children"><div class="content">Having worked with Simon he knows his sh*t. We talked a lot about what the ideal search stack would look when we worked together at Shopify on search (him more infra, me more ML+relevance). I discussed how I just want a thing in the cloud to provide my retrieval arms, let me express ranking in a fluent &quot;py-data&quot; first way, and get out of my way<p>My ideal is that turbopuffer ultimately is like a Polars dataframe where all my ranking is expressed in my search API. I could just lazily express some lexical or embedding similarity, boost with various attributes like, maybe by recency, popularity, etc to get a first pass (again all just with dataframe math). Then compute features for a reranking model I run on my side - dataframe math - and it &quot;just works&quot; - runs all this as some kind of query execution DAG - and stays out of my way.</div><br/><div id="40934181" class="c"><input type="checkbox" id="c-40934181" checked=""/><div class="controls bullet"><span class="by">snthpy</span><span>|</span><a href="#40920438">parent</a><span>|</span><a href="#40922580">next</a><span>|</span><label class="collapse" for="c-40934181">[-]</label><label class="expand" for="c-40934181">[1 more]</label></div><br/><div class="children"><div class="content">Could you give an example of what you mean by _fluent &quot;py-data&quot; first way_ ?<p>You mean like a fluent API like `data.transform().filter()...` , that sort of thing?</div><br/></div></div><div id="40922580" class="c"><input type="checkbox" id="c-40922580" checked=""/><div class="controls bullet"><span class="by">bkitano19</span><span>|</span><a href="#40920438">parent</a><span>|</span><a href="#40934181">prev</a><span>|</span><a href="#40920639">next</a><span>|</span><label class="collapse" for="c-40922580">[-]</label><label class="expand" for="c-40922580">[1 more]</label></div><br/><div class="children"><div class="content">+1, had the fortune to work with him at a previous startup and meetup in person. Our convo very much broadened my perspective on engineering as a career and a craft, always excited to see what he&#x27;s working on. Good luck Simon!</div><br/></div></div></div></div><div id="40920639" class="c"><input type="checkbox" id="c-40920639" checked=""/><div class="controls bullet"><span class="by">cmcollier</span><span>|</span><a href="#40920438">prev</a><span>|</span><a href="#40923564">next</a><span>|</span><label class="collapse" for="c-40920639">[-]</label><label class="expand" for="c-40920639">[11 more]</label></div><br/><div class="children"><div class="content">Unrelated to the core topic, I really enjoy the aesthetic of their website.  Another similar one is from Fixie.ai (also, interestingly, one of their customers).</div><br/><div id="40924468" class="c"><input type="checkbox" id="c-40924468" checked=""/><div class="controls bullet"><span class="by">k2so</span><span>|</span><a href="#40920639">parent</a><span>|</span><a href="#40923242">next</a><span>|</span><label class="collapse" for="c-40924468">[-]</label><label class="expand" for="c-40924468">[1 more]</label></div><br/><div class="children"><div class="content">This was my first thought too, after reading through their blog. This feels like a no-frills website made by an engineer, who makes things that just work.<p>The documentation is great, I really appreciate them putting the roadmap front and centre.</div><br/></div></div><div id="40923242" class="c"><input type="checkbox" id="c-40923242" checked=""/><div class="controls bullet"><span class="by">xarope</span><span>|</span><a href="#40920639">parent</a><span>|</span><a href="#40924468">prev</a><span>|</span><a href="#40925835">next</a><span>|</span><label class="collapse" for="c-40923242">[-]</label><label class="expand" for="c-40923242">[1 more]</label></div><br/><div class="children"><div class="content">Yes, I like the turboxyz123 animation and contrast to the minimalist website (reminds me of the zen garden with a single rock).  I think people forget nowadays in their haste to add the latest and greatest react animation, that too much noise is a thing.</div><br/></div></div><div id="40921496" class="c"><input type="checkbox" id="c-40921496" checked=""/><div class="controls bullet"><span class="by">itunpredictable</span><span>|</span><a href="#40920639">parent</a><span>|</span><a href="#40925835">prev</a><span>|</span><a href="#40928101">next</a><span>|</span><label class="collapse" for="c-40921496">[-]</label><label class="expand" for="c-40921496">[1 more]</label></div><br/><div class="children"><div class="content">This website rocks</div><br/></div></div><div id="40928101" class="c"><input type="checkbox" id="c-40928101" checked=""/><div class="controls bullet"><span class="by">5-</span><span>|</span><a href="#40920639">parent</a><span>|</span><a href="#40921496">prev</a><span>|</span><a href="#40923134">next</a><span>|</span><label class="collapse" for="c-40928101">[-]</label><label class="expand" for="c-40928101">[2 more]</label></div><br/><div class="children"><div class="content">indeed! what a nice, minimal page... that comes with ~1.6mb of javascript.</div><br/><div id="40933197" class="c"><input type="checkbox" id="c-40933197" checked=""/><div class="controls bullet"><span class="by">bmar</span><span>|</span><a href="#40920639">root</a><span>|</span><a href="#40928101">parent</a><span>|</span><a href="#40923134">next</a><span>|</span><label class="collapse" for="c-40933197">[-]</label><label class="expand" for="c-40933197">[1 more]</label></div><br/><div class="children"><div class="content">What&#x27;s wrong with that?</div><br/></div></div></div></div><div id="40923134" class="c"><input type="checkbox" id="c-40923134" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#40920639">parent</a><span>|</span><a href="#40928101">prev</a><span>|</span><a href="#40921849">next</a><span>|</span><label class="collapse" for="c-40923134">[-]</label><label class="expand" for="c-40923134">[3 more]</label></div><br/><div class="children"><div class="content">what does fixie do these days?</div><br/><div id="40924182" class="c"><input type="checkbox" id="c-40924182" checked=""/><div class="controls bullet"><span class="by">sitkack</span><span>|</span><a href="#40920639">root</a><span>|</span><a href="#40923134">parent</a><span>|</span><a href="#40921849">next</a><span>|</span><label class="collapse" for="c-40924182">[-]</label><label class="expand" for="c-40924182">[2 more]</label></div><br/><div class="children"><div class="content">They pivoted, but will probably pivot back to their original quest.</div><br/><div id="40927583" class="c"><input type="checkbox" id="c-40927583" checked=""/><div class="controls bullet"><span class="by">zkoch</span><span>|</span><a href="#40920639">root</a><span>|</span><a href="#40924182">parent</a><span>|</span><a href="#40921849">next</a><span>|</span><label class="collapse" for="c-40927583">[-]</label><label class="expand" for="c-40927583">[1 more]</label></div><br/><div class="children"><div class="content">Nah, we&#x27;re pretty happy with the new trajectory. :)</div><br/></div></div></div></div></div></div><div id="40921849" class="c"><input type="checkbox" id="c-40921849" checked=""/><div class="controls bullet"><span class="by">nsguy</span><span>|</span><a href="#40920639">parent</a><span>|</span><a href="#40923134">prev</a><span>|</span><a href="#40923564">next</a><span>|</span><label class="collapse" for="c-40921849">[-]</label><label class="expand" for="c-40921849">[1 more]</label></div><br/><div class="children"><div class="content">Yeah! fast, clean, cool, unique.</div><br/></div></div></div></div><div id="40923564" class="c"><input type="checkbox" id="c-40923564" checked=""/><div class="controls bullet"><span class="by">nh2</span><span>|</span><a href="#40920639">prev</a><span>|</span><a href="#40922055">next</a><span>|</span><label class="collapse" for="c-40923564">[-]</label><label class="expand" for="c-40923564">[7 more]</label></div><br/><div class="children"><div class="content">&gt; $3600.00&#x2F;TB&#x2F;month<p>It doesn&#x27;t have to be that way.<p>At Hetzner I pay $200&#x2F;TB&#x2F;month for RAM. That&#x27;s 18x cheaper.<p>Sometimes you can reach the goal faster with less complexity by removing the part with the 20x markup.</div><br/><div id="40925135" class="c"><input type="checkbox" id="c-40925135" checked=""/><div class="controls bullet"><span class="by">AYBABTME</span><span>|</span><a href="#40923564">parent</a><span>|</span><a href="#40924513">next</a><span>|</span><label class="collapse" for="c-40925135">[-]</label><label class="expand" for="c-40925135">[3 more]</label></div><br/><div class="children"><div class="content">200$&#x2F;TB&#x2F;month for raw RAM, not RAM that&#x27;s presented to you behind a usable API that&#x27;s distributed and operated by someone else, freeing you of time.<p>It&#x27;s not particularly useful to compare the cost of raw unorganized information medium on a single node, to highly organized information platform. It&#x27;s like saying &quot;this CPU chip is expensive, just look at the price of this sand&quot;.</div><br/><div id="40927344" class="c"><input type="checkbox" id="c-40927344" checked=""/><div class="controls bullet"><span class="by">hodgesrm</span><span>|</span><a href="#40923564">root</a><span>|</span><a href="#40925135">parent</a><span>|</span><a href="#40925368">next</a><span>|</span><label class="collapse" for="c-40927344">[-]</label><label class="expand" for="c-40927344">[1 more]</label></div><br/><div class="children"><div class="content">&gt; It&#x27;s not particularly useful to compare the cost of raw unorganized information medium on a single node, to highly organized information platform.<p>Except that it does prompt you to ask what you could do to use that cheap compute and RAM. In the case of Hetzner that might be large caches that allow you to apply those resources on remote data whilst minimizing transfer and API costs.</div><br/></div></div><div id="40925368" class="c"><input type="checkbox" id="c-40925368" checked=""/><div class="controls bullet"><span class="by">kirmerzlikin</span><span>|</span><a href="#40923564">root</a><span>|</span><a href="#40925135">parent</a><span>|</span><a href="#40927344">prev</a><span>|</span><a href="#40924513">next</a><span>|</span><label class="collapse" for="c-40925368">[-]</label><label class="expand" for="c-40925368">[1 more]</label></div><br/><div class="children"><div class="content">AFAIU, 3600$ is also a price for &quot;raw RAM&quot; that will be used by your common database via sys calls and not via a &quot;usable API operated by someone else&quot;</div><br/></div></div></div></div><div id="40924513" class="c"><input type="checkbox" id="c-40924513" checked=""/><div class="controls bullet"><span class="by">TechDebtDevin</span><span>|</span><a href="#40923564">parent</a><span>|</span><a href="#40925135">prev</a><span>|</span><a href="#40925202">next</a><span>|</span><label class="collapse" for="c-40924513">[-]</label><label class="expand" for="c-40924513">[1 more]</label></div><br/><div class="children"><div class="content">I will likely never leave Hetzner.</div><br/></div></div><div id="40925202" class="c"><input type="checkbox" id="c-40925202" checked=""/><div class="controls bullet"><span class="by">formerly_proven</span><span>|</span><a href="#40923564">parent</a><span>|</span><a href="#40924513">prev</a><span>|</span><a href="#40922055">next</a><span>|</span><label class="collapse" for="c-40925202">[-]</label><label class="expand" for="c-40925202">[2 more]</label></div><br/><div class="children"><div class="content">You seem to be quoting the highest figure from the article out of context as-if that is their pricing, but the opposite is the case.<p>&gt; $3600.00&#x2F;TB&#x2F;month (incumbents)<p>&gt; $70.00&#x2F;TB&#x2F;month (turbopuffer)<p>That&#x27;s still 3x cheaper than your number and it&#x27;s a SaaS API, not just a piece of rented hardware.</div><br/><div id="40930686" class="c"><input type="checkbox" id="c-40930686" checked=""/><div class="controls bullet"><span class="by">nh2</span><span>|</span><a href="#40923564">root</a><span>|</span><a href="#40925202">parent</a><span>|</span><a href="#40922055">next</a><span>|</span><label class="collapse" for="c-40930686">[-]</label><label class="expand" for="c-40930686">[1 more]</label></div><br/><div class="children"><div class="content">&gt; as-if that is their pricing<p>No, that&#x27;s not what I&#x27;m saying. Their &quot;Storage Costs&quot; table shows costs to rent storage from some provider (AWS?). It&#x27;s clear that those are costs that the user has to pay for infrastructure needed for certain types of software (e.g. Turbopuffer is designed to be running on &quot;S3 + SSD Cache&quot;, while other software may be designed to run on &quot;RAM + 3x SSD&quot;).<p>I&#x27;m comparing RAM costs from that table with RAM costs in the real world.<p>The idea backed by that table is &quot;RAM is so expensive, so we need to build software to run it on cheaper storage instead&quot;.<p>My statement is &quot;RAM is that expensive only on that provider, there are others where it is not; on those, you may just run it in RAM and save on software complexity&quot;.<p>You will still need some software for your SaaS API to serve queries from RAM, but it won&#x27;t need the complexity of trying to make it fast when serving from a higher-latency storage backend (S3).</div><br/></div></div></div></div></div></div><div id="40922055" class="c"><input type="checkbox" id="c-40922055" checked=""/><div class="controls bullet"><span class="by">omneity</span><span>|</span><a href="#40923564">prev</a><span>|</span><a href="#40920788">next</a><span>|</span><label class="collapse" for="c-40922055">[-]</label><label class="expand" for="c-40922055">[5 more]</label></div><br/><div class="children"><div class="content">&gt; In 2022, production-grade vector databases were relying on in-memory storage<p>This is irking me. pg_vector has existed from before that, doesn&#x27;t require in-memory storage and can definitely handle vector search for 100m+ documents in a decently performant manner. Did they have a particular requirement somewhere?</div><br/><div id="40922076" class="c"><input type="checkbox" id="c-40922076" checked=""/><div class="controls bullet"><span class="by">jbellis</span><span>|</span><a href="#40922055">parent</a><span>|</span><a href="#40920788">next</a><span>|</span><label class="collapse" for="c-40922076">[-]</label><label class="expand" for="c-40922076">[4 more]</label></div><br/><div class="children"><div class="content">Have you tried it? pgvector performance falls off a cliff once you can&#x27;t cache in ram. Vector search isn&#x27;t like &quot;normal&quot; workloads that follow a nice pareto distribution.</div><br/><div id="40922426" class="c"><input type="checkbox" id="c-40922426" checked=""/><div class="controls bullet"><span class="by">omneity</span><span>|</span><a href="#40922055">root</a><span>|</span><a href="#40922076">parent</a><span>|</span><a href="#40920788">next</a><span>|</span><label class="collapse" for="c-40922426">[-]</label><label class="expand" for="c-40922426">[3 more]</label></div><br/><div class="children"><div class="content">Tried and deployed in production with similar sized collections.<p>You only need enough memory to load the index, definitely not the whole collection. A typical index would most likely fit within a few GBs. And even if you need dozens of GBs of RAM it won’t cost nearly as much as $20k&#x2F;month as the article surmises.</div><br/><div id="40926357" class="c"><input type="checkbox" id="c-40926357" checked=""/><div class="controls bullet"><span class="by">lyu07282</span><span>|</span><a href="#40922055">root</a><span>|</span><a href="#40922426">parent</a><span>|</span><a href="#40920788">next</a><span>|</span><label class="collapse" for="c-40926357">[-]</label><label class="expand" for="c-40926357">[2 more]</label></div><br/><div class="children"><div class="content">How do you get to &quot;a few GBs&quot;? A hundred million embeddings, if you have 4 byte floats 1024 dimensions would be &gt;400 GB alone.</div><br/><div id="40928308" class="c"><input type="checkbox" id="c-40928308" checked=""/><div class="controls bullet"><span class="by">omneity</span><span>|</span><a href="#40922055">root</a><span>|</span><a href="#40926357">parent</a><span>|</span><a href="#40920788">next</a><span>|</span><label class="collapse" for="c-40928308">[-]</label><label class="expand" for="c-40928308">[1 more]</label></div><br/><div class="children"><div class="content">I did say the index, not the embeddings themselves. The index is a more compact representation of your embeddings collection, and that&#x27;s what you need in memory. One approach for indexing is to calculate centroids of your embeddings.<p>You have multiple parameters to tweak, that affect retrieval performance as well as the memory footprint of your indexes. Here&#x27;s a rundown on that:
<a href="https:&#x2F;&#x2F;tembo.io&#x2F;blog&#x2F;vector-indexes-in-pgvector" rel="nofollow">https:&#x2F;&#x2F;tembo.io&#x2F;blog&#x2F;vector-indexes-in-pgvector</a></div><br/></div></div></div></div></div></div></div></div></div></div><div id="40920788" class="c"><input type="checkbox" id="c-40920788" checked=""/><div class="controls bullet"><span class="by">bigbones</span><span>|</span><a href="#40922055">prev</a><span>|</span><a href="#40928528">next</a><span>|</span><label class="collapse" for="c-40920788">[-]</label><label class="expand" for="c-40920788">[5 more]</label></div><br/><div class="children"><div class="content">Sounds like a source-unavailable version of Quickwit? <a href="https:&#x2F;&#x2F;quickwit.io&#x2F;" rel="nofollow">https:&#x2F;&#x2F;quickwit.io&#x2F;</a></div><br/><div id="40920922" class="c"><input type="checkbox" id="c-40920922" checked=""/><div class="controls bullet"><span class="by">pushrax</span><span>|</span><a href="#40920788">parent</a><span>|</span><a href="#40928528">next</a><span>|</span><label class="collapse" for="c-40920922">[-]</label><label class="expand" for="c-40920922">[4 more]</label></div><br/><div class="children"><div class="content">LSM tree storage engine vs time series storage engine, similar philosophy but different use cases</div><br/><div id="40923436" class="c"><input type="checkbox" id="c-40923436" checked=""/><div class="controls bullet"><span class="by">singhrac</span><span>|</span><a href="#40920788">root</a><span>|</span><a href="#40920922">parent</a><span>|</span><a href="#40928528">next</a><span>|</span><label class="collapse" for="c-40923436">[-]</label><label class="expand" for="c-40923436">[3 more]</label></div><br/><div class="children"><div class="content">Maybe I misunderstood both products but I think neither Quickwit or Turbopuffer is either of those things intrinsically (though log structured messages are a good fit for Quickfit). I think Quickwit is essentially Lucene&#x2F;Elasticsearch (i.e. sparse queries or BM25) and Turbopuffer does vector search (or dense queries) like say Faiss&#x2F;Pinecone&#x2F;Qdrant&#x2F;Vectorize, both over object storage.</div><br/><div id="40926621" class="c"><input type="checkbox" id="c-40926621" checked=""/><div class="controls bullet"><span class="by">pushrax</span><span>|</span><a href="#40920788">root</a><span>|</span><a href="#40923436">parent</a><span>|</span><a href="#40928528">next</a><span>|</span><label class="collapse" for="c-40926621">[-]</label><label class="expand" for="c-40926621">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s true that turbopuffer does vector search, though it also does BM25.<p>The biggest difference at a low level is that turbopuffer records have unique primary keys, and can be updated, like in a normal database. Old records that were overwritten won&#x27;t be returned in searches. The LSM tree storage engine is used to achieve this. The LSM tree also enables maintenance of global indexes that can be used for efficient retrieval without any time-based filter.<p>Quickwit records are immutable. You can&#x27;t overwrite a record (well, you can, but overwritten records will also be returned in searches). The data files it produces are organized into a time series, and if you don&#x27;t pass a time-based filter it has to look at every file.</div><br/><div id="40927816" class="c"><input type="checkbox" id="c-40927816" checked=""/><div class="controls bullet"><span class="by">singhrac</span><span>|</span><a href="#40920788">root</a><span>|</span><a href="#40926621">parent</a><span>|</span><a href="#40928528">next</a><span>|</span><label class="collapse" for="c-40927816">[-]</label><label class="expand" for="c-40927816">[1 more]</label></div><br/><div class="children"><div class="content">Ah I didn’t catch that Quickwit had immutable records. That explains the focus on log usage. Thanks!</div><br/></div></div></div></div></div></div></div></div></div></div><div id="40928528" class="c"><input type="checkbox" id="c-40928528" checked=""/><div class="controls bullet"><span class="by">solatic</span><span>|</span><a href="#40920788">prev</a><span>|</span><a href="#40921379">next</a><span>|</span><label class="collapse" for="c-40928528">[-]</label><label class="expand" for="c-40928528">[5 more]</label></div><br/><div class="children"><div class="content">Is it feasible to try to build this kind of approach (hot SSD cache nodes sitting in front of object storage) with prior open-source art (Lucene)? Or are the search indexes themselves also proprietary in this solution?<p>Having witnessed some very large Elasticsearch production deployments, being able to throw everything into S3 would be <i>incredible</i>. The applicability here isn&#x27;t only for vector search.</div><br/><div id="40929482" class="c"><input type="checkbox" id="c-40929482" checked=""/><div class="controls bullet"><span class="by">rohitnair</span><span>|</span><a href="#40928528">parent</a><span>|</span><a href="#40928889">next</a><span>|</span><label class="collapse" for="c-40929482">[-]</label><label class="expand" for="c-40929482">[3 more]</label></div><br/><div class="children"><div class="content">Elasticsearch and OpenSearch already support S3 backed indices. See features like <a href="https:&#x2F;&#x2F;opensearch.org&#x2F;docs&#x2F;latest&#x2F;tuning-your-cluster&#x2F;availability-and-recovery&#x2F;snapshots&#x2F;searchable_snapshot&#x2F;" rel="nofollow">https:&#x2F;&#x2F;opensearch.org&#x2F;docs&#x2F;latest&#x2F;tuning-your-cluster&#x2F;avail...</a> The files in S3 are plain old Lucene segment files (just wrapped in OpenSearch snapshots which provide a way to track metadata around those files).</div><br/><div id="40929561" class="c"><input type="checkbox" id="c-40929561" checked=""/><div class="controls bullet"><span class="by">francoismassot</span><span>|</span><a href="#40928528">root</a><span>|</span><a href="#40929482">parent</a><span>|</span><a href="#40928889">next</a><span>|</span><label class="collapse" for="c-40929561">[-]</label><label class="expand" for="c-40929561">[2 more]</label></div><br/><div class="children"><div class="content">But you don’t have fast search on those files stored on object storage.</div><br/><div id="40929618" class="c"><input type="checkbox" id="c-40929618" checked=""/><div class="controls bullet"><span class="by">rohitnair</span><span>|</span><a href="#40928528">root</a><span>|</span><a href="#40929561">parent</a><span>|</span><a href="#40928889">next</a><span>|</span><label class="collapse" for="c-40929618">[-]</label><label class="expand" for="c-40929618">[1 more]</label></div><br/><div class="children"><div class="content">Yes, there is a cold start penalty but once the data is cached, it is equivalent to disk backed indices. There is also active work being done to improve the performance, example <a href="https:&#x2F;&#x2F;github.com&#x2F;opensearch-project&#x2F;OpenSearch&#x2F;issues&#x2F;13806">https:&#x2F;&#x2F;github.com&#x2F;opensearch-project&#x2F;OpenSearch&#x2F;issues&#x2F;1380...</a></div><br/></div></div></div></div></div></div><div id="40928889" class="c"><input type="checkbox" id="c-40928889" checked=""/><div class="controls bullet"><span class="by">francoismassot</span><span>|</span><a href="#40928528">parent</a><span>|</span><a href="#40929482">prev</a><span>|</span><a href="#40921379">next</a><span>|</span><label class="collapse" for="c-40928889">[-]</label><label class="expand" for="c-40928889">[1 more]</label></div><br/><div class="children"><div class="content">If you don&#x27;t need vector search and have very large Elasticsearch deployment, you can have a look at Quickwit, it&#x27;s a search engine on object storage, it&#x27;s OSS and works for append-only datasets (like logs, traces, ...)<p>Repo: <a href="https:&#x2F;&#x2F;github.com&#x2F;quickwit-oss&#x2F;quickwit">https:&#x2F;&#x2F;github.com&#x2F;quickwit-oss&#x2F;quickwit</a></div><br/></div></div></div></div><div id="40921379" class="c"><input type="checkbox" id="c-40921379" checked=""/><div class="controls bullet"><span class="by">eknkc</span><span>|</span><a href="#40928528">prev</a><span>|</span><a href="#40924313">next</a><span>|</span><label class="collapse" for="c-40921379">[-]</label><label class="expand" for="c-40921379">[17 more]</label></div><br/><div class="children"><div class="content">Is there a good general purpose solution where I can store a large read only database in s3 or something and do lookups directly on it?<p>Duckdb can open parquet files over http and query them but I found it to trigger a lot of small requests reading bunch of places from the files. I mean a lot.<p>I mostly need key &#x2F; value lookups and could potentially store each key in a seperate object in s3 but for a couple hundred million objects.. It would be a lot more managable to have a single file and maybe a cacheable index.</div><br/><div id="40922842" class="c"><input type="checkbox" id="c-40922842" checked=""/><div class="controls bullet"><span class="by">tionis</span><span>|</span><a href="#40921379">parent</a><span>|</span><a href="#40923712">next</a><span>|</span><label class="collapse" for="c-40922842">[-]</label><label class="expand" for="c-40922842">[6 more]</label></div><br/><div class="children"><div class="content">You could use a sqlite database and use range queries using something like this:
<a href="https:&#x2F;&#x2F;github.com&#x2F;psanford&#x2F;sqlite3vfshttp">https:&#x2F;&#x2F;github.com&#x2F;psanford&#x2F;sqlite3vfshttp</a>
<a href="https:&#x2F;&#x2F;github.com&#x2F;phiresky&#x2F;sql.js-httpvfs">https:&#x2F;&#x2F;github.com&#x2F;phiresky&#x2F;sql.js-httpvfs</a><p>Simon Willison wrote about it:
<a href="https:&#x2F;&#x2F;simonwillison.net&#x2F;2022&#x2F;Aug&#x2F;10&#x2F;sqlite-http&#x2F;" rel="nofollow">https:&#x2F;&#x2F;simonwillison.net&#x2F;2022&#x2F;Aug&#x2F;10&#x2F;sqlite-http&#x2F;</a></div><br/><div id="40924633" class="c"><input type="checkbox" id="c-40924633" checked=""/><div class="controls bullet"><span class="by">eknkc</span><span>|</span><a href="#40921379">root</a><span>|</span><a href="#40922842">parent</a><span>|</span><a href="#40924060">next</a><span>|</span><label class="collapse" for="c-40924633">[-]</label><label class="expand" for="c-40924633">[4 more]</label></div><br/><div class="children"><div class="content">Yep this thing is the reason I thought about doing it in the first place. Tried duckdb which has built in support for range requests over http.<p>Whole idea makes sense but I feel like the file format should be specifically tuned for this use case. Otherwise you end up with a lot of range requests because it was designed for disk access. I wondered if anything was actually designed for that.</div><br/><div id="40925697" class="c"><input type="checkbox" id="c-40925697" checked=""/><div class="controls bullet"><span class="by">hobofan</span><span>|</span><a href="#40921379">root</a><span>|</span><a href="#40924633">parent</a><span>|</span><a href="#40924060">next</a><span>|</span><label class="collapse" for="c-40925697">[-]</label><label class="expand" for="c-40925697">[3 more]</label></div><br/><div class="children"><div class="content">Parquet and other columnar storage formats are essentially already tuned for that.<p>A lot of requests in themselves shouldn&#x27;t be that horrible with Cloudfront nowadays, as you both have low latency and with HTTP2 a low-overhead RPC channel.<p>There are some potential remedies, but each come with significant architetural impact:<p>- Bigger range queries; For smallish tables, instead of trying to do point-based access for individual rows, instead retrieve bigger chunks at once and scan through them locally -&gt; Less requests, but likely also more wasted bandwidth<p>- Compute the specific view live with a remote DuckDB -&gt; Has the downside of having to introduce a DuckDB instance that you have to manage between the browser and S3<p>- Precompute the data you are interested into new parquest files -&gt; Only works if you can anticipate the query patterns enough<p>I read in the sibling comment that your main issue seems to be re-reading of metadata. DuckDB is AFAIK able to cache the metadata, but won&#x27;t across instances. I&#x27;ve seen someone have the same issue, and the problem was that they only created short-lived DuckDB in-memory instances (every time the wanted to run a query), so every time the fresh DB had to retrieve the metadata again.</div><br/><div id="40925766" class="c"><input type="checkbox" id="c-40925766" checked=""/><div class="controls bullet"><span class="by">eknkc</span><span>|</span><a href="#40921379">root</a><span>|</span><a href="#40925697">parent</a><span>|</span><a href="#40924060">next</a><span>|</span><label class="collapse" for="c-40925766">[-]</label><label class="expand" for="c-40925766">[2 more]</label></div><br/><div class="children"><div class="content">Thanks for the insights. Precomputing is not really suitable for this and the thing is, I&#x27;m mostly using it as a lookup table on key &#x2F; value queries. I know Duckdb is mostly suitable for aggregation but the http range query support was too attractive to pass on.<p>I did some tests, querying &quot;where col = &#x27;x&#x27;&quot;. If the database was a remote duckdb native db, it would issue a bunch of http range requests and the second exact call would not trigger any new requests. Also, querying for col = foo and then col = foob would yield less and less requests as I assume it has the necesary data on hand.<p>Doing it on parquet, with a single long running duckdb cli instance, I get the same requests over and over again. The difference though, I&#x27;d need to &quot;attach&quot; the duckdb database under a schema name but would query the parquet file using &quot;select from &#x27;<a href="http:&#x2F;&#x2F;...&#x2F;x.parquet" rel="nofollow">http:&#x2F;&#x2F;...&#x2F;x.parquet</a>&#x27;&quot; syntax. Maybe this causes it to be ephemeral for each query. Will see if the attach syntax also works for parquet.</div><br/><div id="40925941" class="c"><input type="checkbox" id="c-40925941" checked=""/><div class="controls bullet"><span class="by">hobofan</span><span>|</span><a href="#40921379">root</a><span>|</span><a href="#40925766">parent</a><span>|</span><a href="#40924060">next</a><span>|</span><label class="collapse" for="c-40925941">[-]</label><label class="expand" for="c-40925941">[1 more]</label></div><br/><div class="children"><div class="content">I think both should work, but you have to set the object cache pragma IIRC: <a href="https:&#x2F;&#x2F;duckdb.org&#x2F;docs&#x2F;configuration&#x2F;pragmas.html#object-cache" rel="nofollow">https:&#x2F;&#x2F;duckdb.org&#x2F;docs&#x2F;configuration&#x2F;pragmas.html#object-ca...</a></div><br/></div></div></div></div></div></div></div></div><div id="40924060" class="c"><input type="checkbox" id="c-40924060" checked=""/><div class="controls bullet"><span class="by">arcanemachiner</span><span>|</span><a href="#40921379">root</a><span>|</span><a href="#40922842">parent</a><span>|</span><a href="#40924633">prev</a><span>|</span><a href="#40923712">next</a><span>|</span><label class="collapse" for="c-40924060">[-]</label><label class="expand" for="c-40924060">[1 more]</label></div><br/><div class="children"><div class="content">That whole thing still blows my mind.</div><br/></div></div></div></div><div id="40923712" class="c"><input type="checkbox" id="c-40923712" checked=""/><div class="controls bullet"><span class="by">cdchn</span><span>|</span><a href="#40921379">parent</a><span>|</span><a href="#40922842">prev</a><span>|</span><a href="#40922166">next</a><span>|</span><label class="collapse" for="c-40923712">[-]</label><label class="expand" for="c-40923712">[2 more]</label></div><br/><div class="children"><div class="content">&gt;Is there a good general purpose solution where I can store a large read only database in s3 or something and do lookups directly on it?<p>I think this is pretty much what AWS Athena is.</div><br/><div id="40926053" class="c"><input type="checkbox" id="c-40926053" checked=""/><div class="controls bullet"><span class="by">tiew9Vii</span><span>|</span><a href="#40921379">root</a><span>|</span><a href="#40923712">parent</a><span>|</span><a href="#40922166">next</a><span>|</span><label class="collapse" for="c-40926053">[-]</label><label class="expand" for="c-40926053">[1 more]</label></div><br/><div class="children"><div class="content">Cloud backed SQLLite looks like it might be good for this. Doesn’t support S3 though<p><a href="https:&#x2F;&#x2F;sqlite.org&#x2F;cloudsqlite&#x2F;doc&#x2F;trunk&#x2F;www&#x2F;index.wiki" rel="nofollow">https:&#x2F;&#x2F;sqlite.org&#x2F;cloudsqlite&#x2F;doc&#x2F;trunk&#x2F;www&#x2F;index.wiki</a></div><br/></div></div></div></div><div id="40922166" class="c"><input type="checkbox" id="c-40922166" checked=""/><div class="controls bullet"><span class="by">imiric</span><span>|</span><a href="#40921379">parent</a><span>|</span><a href="#40923712">prev</a><span>|</span><a href="#40922137">next</a><span>|</span><label class="collapse" for="c-40922166">[-]</label><label class="expand" for="c-40922166">[4 more]</label></div><br/><div class="children"><div class="content">ClickHouse can also read from S3. I&#x27;m not sure how it compares to DuckDB re efficiency, but it worked fine for my simple use case.</div><br/><div id="40922670" class="c"><input type="checkbox" id="c-40922670" checked=""/><div class="controls bullet"><span class="by">masterj</span><span>|</span><a href="#40921379">root</a><span>|</span><a href="#40922166">parent</a><span>|</span><a href="#40922137">next</a><span>|</span><label class="collapse" for="c-40922670">[-]</label><label class="expand" for="c-40922670">[3 more]</label></div><br/><div class="children"><div class="content">Neither of these support indexes afaik. They are designed to do fast scans &#x2F; computation.</div><br/><div id="40930836" class="c"><input type="checkbox" id="c-40930836" checked=""/><div class="controls bullet"><span class="by">orthecreedence</span><span>|</span><a href="#40921379">root</a><span>|</span><a href="#40922670">parent</a><span>|</span><a href="#40923656">next</a><span>|</span><label class="collapse" for="c-40930836">[-]</label><label class="expand" for="c-40930836">[1 more]</label></div><br/><div class="children"><div class="content">Depends what you mean by &quot;indexes.&quot; DuckDB can read path parameters (ex s3:&#x2F;&#x2F;my-bucket&#x2F;category=beverages&#x2F;month=2022-01-01&#x2F;*&#x2F;*.parquet) where `category` and `month` can be filtered at the query level, skipping any non-matching files. I think that qualifies as an index. Obviously, you&#x27;d have to create these up-front, or risk moving lots of data between paths.</div><br/></div></div><div id="40923656" class="c"><input type="checkbox" id="c-40923656" checked=""/><div class="controls bullet"><span class="by">hodgesrm</span><span>|</span><a href="#40921379">root</a><span>|</span><a href="#40922670">parent</a><span>|</span><a href="#40930836">prev</a><span>|</span><a href="#40922137">next</a><span>|</span><label class="collapse" for="c-40923656">[-]</label><label class="expand" for="c-40923656">[1 more]</label></div><br/><div class="children"><div class="content">It depends on what you mean by &quot;support.&quot; ClickHouse as I recall can read min&#x2F;max indexes from Parquet row groups. One of my colleagues is working on a PR to add support for bloom filter indexes. So that will be covered as well.<p>Right now one of the main performance problems is that Clickhouse does not cache index metadata yet, so you still have to scan files rather than keeping the metadata in memory. ClickHouse does this for native MergeTree tables. There are a couple of steps to get there but I have no doubt that metadata caching will be properly handled soon.<p>Disclaimer: I work for Altinity, an enterprise provider for ClickHouse software.</div><br/></div></div></div></div></div></div><div id="40922137" class="c"><input type="checkbox" id="c-40922137" checked=""/><div class="controls bullet"><span class="by">jiggawatts</span><span>|</span><a href="#40921379">parent</a><span>|</span><a href="#40922166">prev</a><span>|</span><a href="#40927099">next</a><span>|</span><label class="collapse" for="c-40922137">[-]</label><label class="expand" for="c-40922137">[3 more]</label></div><br/><div class="children"><div class="content">&gt; trigger a lot of small requests reading bunch of places from the files. I mean a lot.<p>That’s… the whole point. That’s how Parquet files are supposed to be used. They’re an improvement over CSV or JSON because clients can read small subsets of them efficiently!<p>For comparison, I’ve tried a few other client products that don’t use Parquet files properly and just read the whole file every time, no matter how trivial the query is.</div><br/><div id="40924681" class="c"><input type="checkbox" id="c-40924681" checked=""/><div class="controls bullet"><span class="by">eknkc</span><span>|</span><a href="#40921379">root</a><span>|</span><a href="#40922137">parent</a><span>|</span><a href="#40927099">next</a><span>|</span><label class="collapse" for="c-40924681">[-]</label><label class="expand" for="c-40924681">[2 more]</label></div><br/><div class="children"><div class="content">This makes sense but the problem I had with duckdb + parquet is it looks like there is no metadata caching so each and every query triggers a lot of requests.<p>Duckdb can query a remote duckdb database too, in that case it looks like there is caching. Which might be better.<p>I wonder if anyone actually worked on a specific file format for this use case (relatively high latency random access) to minimize reads to as little blocks as possible.</div><br/><div id="40924698" class="c"><input type="checkbox" id="c-40924698" checked=""/><div class="controls bullet"><span class="by">jiggawatts</span><span>|</span><a href="#40921379">root</a><span>|</span><a href="#40924681">parent</a><span>|</span><a href="#40927099">next</a><span>|</span><label class="collapse" for="c-40924698">[-]</label><label class="expand" for="c-40924698">[1 more]</label></div><br/><div class="children"><div class="content">Sounds like a bug or missing feature in DuckDB more than an issue with the format</div><br/></div></div></div></div></div></div><div id="40927099" class="c"><input type="checkbox" id="c-40927099" checked=""/><div class="controls bullet"><span class="by">canadiantim</span><span>|</span><a href="#40921379">parent</a><span>|</span><a href="#40922137">prev</a><span>|</span><a href="#40924313">next</a><span>|</span><label class="collapse" for="c-40927099">[-]</label><label class="expand" for="c-40927099">[1 more]</label></div><br/><div class="children"><div class="content">LanceDB</div><br/></div></div></div></div><div id="40924313" class="c"><input type="checkbox" id="c-40924313" checked=""/><div class="controls bullet"><span class="by">zX41ZdbW</span><span>|</span><a href="#40921379">prev</a><span>|</span><a href="#40921306">next</a><span>|</span><label class="collapse" for="c-40924313">[-]</label><label class="expand" for="c-40924313">[2 more]</label></div><br/><div class="children"><div class="content">A correction to the article. It mentions<p><pre><code>    Warehouse BigQuery, Snowflake, Clickhouse ≥1s Minutes
</code></pre>
For ClickHouse, it should be: read latency &lt;= 100ms, write latency &lt;= 1s.<p>Logging, real-time analytics, and RAG are also suitable for ClickHouse.</div><br/><div id="40926746" class="c"><input type="checkbox" id="c-40926746" checked=""/><div class="controls bullet"><span class="by">Sirupsen</span><span>|</span><a href="#40924313">parent</a><span>|</span><a href="#40921306">next</a><span>|</span><label class="collapse" for="c-40926746">[-]</label><label class="expand" for="c-40926746">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, thinking about this more I now understand Clickhouse to be more of an operational warehouse similar to Materialize, Pinot, Druid, etc. if I understand correctly? So bunching with BigQuery&#x2F;Snowflake&#x2F;Trino&#x2F;Databricks... wasn&#x27;t the right category (although operational warehouses certainly can have a ton of overlap)<p>I left that category out for simplicity (plenty of others that didn&#x27;t make it into the taxonomy, e.g. queues, nosql, time-series, graph, embedded, ..)</div><br/></div></div></div></div><div id="40921306" class="c"><input type="checkbox" id="c-40921306" checked=""/><div class="controls bullet"><span class="by">drodgers</span><span>|</span><a href="#40924313">prev</a><span>|</span><a href="#40923728">next</a><span>|</span><label class="collapse" for="c-40921306">[-]</label><label class="expand" for="c-40921306">[1 more]</label></div><br/><div class="children"><div class="content">I love the object-storage-first approach; it seems like such a natural fit for the could.</div><br/></div></div><div id="40923728" class="c"><input type="checkbox" id="c-40923728" checked=""/><div class="controls bullet"><span class="by">cdchn</span><span>|</span><a href="#40921306">prev</a><span>|</span><a href="#40926181">next</a><span>|</span><label class="collapse" for="c-40923728">[-]</label><label class="expand" for="c-40923728">[1 more]</label></div><br/><div class="children"><div class="content">The very long introductory page has a ton of very juicy data in it, even if you don&#x27;t care about the product itself.</div><br/></div></div><div id="40926181" class="c"><input type="checkbox" id="c-40926181" checked=""/><div class="controls bullet"><span class="by">arnorhs</span><span>|</span><a href="#40923728">prev</a><span>|</span><a href="#40922957">next</a><span>|</span><label class="collapse" for="c-40926181">[-]</label><label class="expand" for="c-40926181">[1 more]</label></div><br/><div class="children"><div class="content">This looks super interesting. I&#x27;m not that familiar with vector databases. I thought they were  mostly something used for RAG and other AI-related stuff.<p>Seems like a topic I need to delive into a bit more.</div><br/></div></div><div id="40922957" class="c"><input type="checkbox" id="c-40922957" checked=""/><div class="controls bullet"><span class="by">endisneigh</span><span>|</span><a href="#40926181">prev</a><span>|</span><a href="#40923669">next</a><span>|</span><label class="collapse" for="c-40922957">[-]</label><label class="expand" for="c-40922957">[1 more]</label></div><br/><div class="children"><div class="content">Slightly relevant - do people really want article recommendations? I don’t think I’ve ever read an article and wanted a recommendation. Even with this one - I sort of read it and that’s it; no feeling of wanting recommendations.<p>Am I alone in this?<p>In any case this seems like a pretty interesting approach. Reminds me of Warpstream which does something similar with S3 to replace Kafka.</div><br/></div></div><div id="40923669" class="c"><input type="checkbox" id="c-40923669" checked=""/><div class="controls bullet"><span class="by">yawnxyz</span><span>|</span><a href="#40922957">prev</a><span>|</span><a href="#40920899">next</a><span>|</span><label class="collapse" for="c-40923669">[-]</label><label class="expand" for="c-40923669">[1 more]</label></div><br/><div class="children"><div class="content">can&#x27;t wait for the day the get into GA!</div><br/></div></div><div id="40920899" class="c"><input type="checkbox" id="c-40920899" checked=""/><div class="controls bullet"><span class="by">vidar</span><span>|</span><a href="#40923669">prev</a><span>|</span><a href="#40922360">next</a><span>|</span><label class="collapse" for="c-40920899">[-]</label><label class="expand" for="c-40920899">[1 more]</label></div><br/><div class="children"><div class="content">Can you compare to S3 Athena (ELI5)?</div><br/></div></div><div id="40922360" class="c"><input type="checkbox" id="c-40922360" checked=""/><div class="controls bullet"><span class="by">yamumsahoe</span><span>|</span><a href="#40920899">prev</a><span>|</span><a href="#40922898">next</a><span>|</span><label class="collapse" for="c-40922360">[-]</label><label class="expand" for="c-40922360">[1 more]</label></div><br/><div class="children"><div class="content">unsure if they are comparable, but is this and quickwit comparable?</div><br/></div></div><div id="40922898" class="c"><input type="checkbox" id="c-40922898" checked=""/><div class="controls bullet"><span class="by">hipadev23</span><span>|</span><a href="#40922360">prev</a><span>|</span><a href="#40921143">next</a><span>|</span><label class="collapse" for="c-40922898">[-]</label><label class="expand" for="c-40922898">[1 more]</label></div><br/><div class="children"><div class="content">That’s some woefully disappointing and incorrect metrics (read and write latency are both sub-second, storage medium would be “ Memory + Replicated SSDs”) you’ve got for Clickhouse there, but I understand what you’re going for and why you categorized it where you did.</div><br/></div></div><div id="40921143" class="c"><input type="checkbox" id="c-40921143" checked=""/><div class="controls bullet"><span class="by">CyberDildonics</span><span>|</span><a href="#40922898">prev</a><span>|</span><a href="#40922010">next</a><span>|</span><label class="collapse" for="c-40921143">[-]</label><label class="expand" for="c-40921143">[1 more]</label></div><br/><div class="children"><div class="content">Sounds like a filesystem with attributes in a database.</div><br/></div></div></div></div></div></div></div></body></html>