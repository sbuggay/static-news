<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1736240477098" as="style"/><link rel="stylesheet" href="styles.css?v=1736240477098"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://techcrunch.com/2025/01/06/nvidias-project-digits-is-a-personal-ai-computer/">Nvidia&#x27;s Project Digits is a &#x27;personal AI supercomputer&#x27;</a> <span class="domain">(<a href="https://techcrunch.com">techcrunch.com</a>)</span></div><div class="subtext"><span>magicalhippo</span> | <span>140 comments</span></div><br/><div><div id="42620643" class="c"><input type="checkbox" id="c-42620643" checked=""/><div class="controls bullet"><span class="by">derbaum</span><span>|</span><a href="#42620569">next</a><span>|</span><label class="collapse" for="c-42620643">[-]</label><label class="expand" for="c-42620643">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m a bit surprised by the amount of comments comparing the cost to (often cheap) cloud solutions. Nvidia&#x27;s value proposition is completely different in my opinion. Say I have a startup in the EU that handles personal data or some company secrets and wants to use an LLM to analyse it (like using RAG). Having that data never leave your basement sure can be worth more than $3000 if performance is not a bottleneck.</div><br/></div></div><div id="42620569" class="c"><input type="checkbox" id="c-42620569" checked=""/><div class="controls bullet"><span class="by">blackoil</span><span>|</span><a href="#42620643">prev</a><span>|</span><a href="#42619320">next</a><span>|</span><label class="collapse" for="c-42620569">[-]</label><label class="expand" for="c-42620569">[2 more]</label></div><br/><div class="children"><div class="content">Is there any effort in local cloud computing? I can&#x27;t justify $3000 for a fun device. But if all devices (6 phone, 2 iPads, a desktop and 2 laptops) in my home can leverage that for fast LLM, gaming, and photo&#x2F;video editing, now it makes so much more sense.</div><br/><div id="42620586" class="c"><input type="checkbox" id="c-42620586" checked=""/><div class="controls bullet"><span class="by">KeplerBoy</span><span>|</span><a href="#42620569">parent</a><span>|</span><a href="#42619320">next</a><span>|</span><label class="collapse" for="c-42620586">[-]</label><label class="expand" for="c-42620586">[1 more]</label></div><br/><div class="children"><div class="content">You can just setup your local openAI like API endpoints for LLMs. Most devices and apps won&#x27;t be able to use them, because consumers don&#x27;t run self-hosted apps, but for a simple chatGPT style app this is totally viable. Today.</div><br/></div></div></div></div><div id="42619320" class="c"><input type="checkbox" id="c-42619320" checked=""/><div class="controls bullet"><span class="by">Karupan</span><span>|</span><a href="#42620569">prev</a><span>|</span><a href="#42619962">next</a><span>|</span><label class="collapse" for="c-42619320">[-]</label><label class="expand" for="c-42619320">[45 more]</label></div><br/><div class="children"><div class="content">I feel this is bigger than the 5x series GPUs. Given the craze around AI&#x2F;LLMs, this can also potentially eat into Apple’s slice of the enthusiast AI dev segment once the M4 Max&#x2F;Ultra Mac minis are released. I sure wished I held some Nvidia stocks, they seem to be doing everything right in the last few years!</div><br/><div id="42620289" class="c"><input type="checkbox" id="c-42620289" checked=""/><div class="controls bullet"><span class="by">llm_trw</span><span>|</span><a href="#42619320">parent</a><span>|</span><a href="#42619339">next</a><span>|</span><label class="collapse" for="c-42620289">[-]</label><label class="expand" for="c-42620289">[1 more]</label></div><br/><div class="children"><div class="content">From the people I talk to the enthusiast market is nvidia 4090&#x2F;3090 saturated because people want to do their fine tunes also porn on their off time. The Venn diagram of users who post about diffusion models and llms running at home is pretty much a circle.</div><br/></div></div><div id="42619339" class="c"><input type="checkbox" id="c-42619339" checked=""/><div class="controls bullet"><span class="by">dagmx</span><span>|</span><a href="#42619320">parent</a><span>|</span><a href="#42620289">prev</a><span>|</span><a href="#42619433">next</a><span>|</span><label class="collapse" for="c-42619339">[-]</label><label class="expand" for="c-42619339">[25 more]</label></div><br/><div class="children"><div class="content">I think the enthusiast side of things is a negligible part of the market.<p>That said, enthusiasts do help drive a lot of the improvements to the tech stack so if they start using this, it’ll entrench NVIDIA even more.</div><br/><div id="42619510" class="c"><input type="checkbox" id="c-42619510" checked=""/><div class="controls bullet"><span class="by">Karupan</span><span>|</span><a href="#42619320">root</a><span>|</span><a href="#42619339">parent</a><span>|</span><a href="#42619479">next</a><span>|</span><label class="collapse" for="c-42619510">[-]</label><label class="expand" for="c-42619510">[3 more]</label></div><br/><div class="children"><div class="content">I’m not so sure it’s negligible. My anecdotal experience is that since Apple Silicon chips were found to be “ok” enough to run inference with MLX, more non-technical people in my circle have asked me how they can run LLMs on their macs.<p>Surely a smaller market than gamers or datacenters for sure.</div><br/><div id="42619637" class="c"><input type="checkbox" id="c-42619637" checked=""/><div class="controls bullet"><span class="by">dagmx</span><span>|</span><a href="#42619320">root</a><span>|</span><a href="#42619510">parent</a><span>|</span><a href="#42619479">next</a><span>|</span><label class="collapse" for="c-42619637">[-]</label><label class="expand" for="c-42619637">[2 more]</label></div><br/><div class="children"><div class="content">I mean negligible to their bottom line. There may be tons of units bought or not, but the margin on a single datacenter system would buy tens of these.<p>It’s purely an ecosystem play imho. It benefits the kind of people who will go on to make potentially cool things and will stay loyal.</div><br/><div id="42619863" class="c"><input type="checkbox" id="c-42619863" checked=""/><div class="controls bullet"><span class="by">htrp</span><span>|</span><a href="#42619320">root</a><span>|</span><a href="#42619637">parent</a><span>|</span><a href="#42619479">next</a><span>|</span><label class="collapse" for="c-42619863">[-]</label><label class="expand" for="c-42619863">[1 more]</label></div><br/><div class="children"><div class="content">&gt;It’s purely an ecosystem play imho. It benefits the kind of people who will go on to make potentially cool things and will stay loyal.<p>100%<p>The people who prototype on a 3k workstation will also be the people who decide how to architect for a 3k GPU buildout for model training.</div><br/></div></div></div></div></div></div><div id="42619479" class="c"><input type="checkbox" id="c-42619479" checked=""/><div class="controls bullet"><span class="by">qwertox</span><span>|</span><a href="#42619320">root</a><span>|</span><a href="#42619339">parent</a><span>|</span><a href="#42619510">prev</a><span>|</span><a href="#42619885">next</a><span>|</span><label class="collapse" for="c-42619479">[-]</label><label class="expand" for="c-42619479">[6 more]</label></div><br/><div class="children"><div class="content">You could have said the same about gamers buying expensive hardware in the 00&#x27;s. It&#x27;s what made Nvidia big.</div><br/><div id="42620002" class="c"><input type="checkbox" id="c-42620002" checked=""/><div class="controls bullet"><span class="by">Cumpiler69</span><span>|</span><a href="#42619320">root</a><span>|</span><a href="#42619479">parent</a><span>|</span><a href="#42619885">next</a><span>|</span><label class="collapse" for="c-42620002">[-]</label><label class="expand" for="c-42620002">[5 more]</label></div><br/><div class="children"><div class="content">There&#x27;s a lot more gamers than people wanting to play with LLms at home.</div><br/><div id="42620091" class="c"><input type="checkbox" id="c-42620091" checked=""/><div class="controls bullet"><span class="by">estebarb</span><span>|</span><a href="#42619320">root</a><span>|</span><a href="#42620002">parent</a><span>|</span><a href="#42620074">next</a><span>|</span><label class="collapse" for="c-42620091">[-]</label><label class="expand" for="c-42620091">[1 more]</label></div><br/><div class="children"><div class="content">Sure, but those developers will create functionality that will require advanced GPUs and people will want that functionality. Eventually OS will expect it and it will became default everywhere. So, it is an important step that will push nvidia growing in the following years.</div><br/></div></div><div id="42620074" class="c"><input type="checkbox" id="c-42620074" checked=""/><div class="controls bullet"><span class="by">anonylizard</span><span>|</span><a href="#42619320">root</a><span>|</span><a href="#42620002">parent</a><span>|</span><a href="#42620091">prev</a><span>|</span><a href="#42619885">next</a><span>|</span><label class="collapse" for="c-42620074">[-]</label><label class="expand" for="c-42620074">[3 more]</label></div><br/><div class="children"><div class="content">There&#x27;s a titanic market with people wanting some uncensored local LLM&#x2F;image&#x2F;video generation model. This market extremely overlaps with gamers today, but will grow exponentially every year.</div><br/><div id="42620079" class="c"><input type="checkbox" id="c-42620079" checked=""/><div class="controls bullet"><span class="by">Cumpiler69</span><span>|</span><a href="#42619320">root</a><span>|</span><a href="#42620074">parent</a><span>|</span><a href="#42619885">next</a><span>|</span><label class="collapse" for="c-42620079">[-]</label><label class="expand" for="c-42620079">[2 more]</label></div><br/><div class="children"><div class="content">How big is that market you claim? Local LLM image generation already exists out off the box on latest Samsung flagship phones and it&#x27;s mostly a Gimmick that gets old pretty quickly. Hardly comparable to gaming in terms of market size and profitablity.<p>Plus, YouTube and the Google images is already full of AI generated slop and people are already tired of it. &quot;AI fatigue&quot; amongst majority of general consumers is a documented thing. Gaming fatigues is not.</div><br/><div id="42620282" class="c"><input type="checkbox" id="c-42620282" checked=""/><div class="controls bullet"><span class="by">madwolf</span><span>|</span><a href="#42619320">root</a><span>|</span><a href="#42620079">parent</a><span>|</span><a href="#42619885">next</a><span>|</span><label class="collapse" for="c-42620282">[-]</label><label class="expand" for="c-42620282">[1 more]</label></div><br/><div class="children"><div class="content">I think he implied AI generated porn. Perhaps also other kind of images that are at odds with morality and&#x2F;or the law. I&#x27;m not sure but probably Samsung phones don&#x27;t let you do that.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="42619885" class="c"><input type="checkbox" id="c-42619885" checked=""/><div class="controls bullet"><span class="by">gr3ml1n</span><span>|</span><a href="#42619320">root</a><span>|</span><a href="#42619339">parent</a><span>|</span><a href="#42619479">prev</a><span>|</span><a href="#42619430">next</a><span>|</span><label class="collapse" for="c-42619885">[-]</label><label class="expand" for="c-42619885">[2 more]</label></div><br/><div class="children"><div class="content">AMD thought the enthusiast side of things was a negligible side of the market.</div><br/><div id="42620274" class="c"><input type="checkbox" id="c-42620274" checked=""/><div class="controls bullet"><span class="by">dagmx</span><span>|</span><a href="#42619320">root</a><span>|</span><a href="#42619885">parent</a><span>|</span><a href="#42619430">next</a><span>|</span><label class="collapse" for="c-42620274">[-]</label><label class="expand" for="c-42620274">[1 more]</label></div><br/><div class="children"><div class="content">That’s not what I’m saying. I’m saying that the people buying this aren’t going to shift their bottom line in any kind of noticeable way. They’re already sold out of their money makers. This is just an entrenchment opportunity.</div><br/></div></div></div></div><div id="42619430" class="c"><input type="checkbox" id="c-42619430" checked=""/><div class="controls bullet"><span class="by">VikingCoder</span><span>|</span><a href="#42619320">root</a><span>|</span><a href="#42619339">parent</a><span>|</span><a href="#42619885">prev</a><span>|</span><a href="#42619404">next</a><span>|</span><label class="collapse" for="c-42619430">[-]</label><label class="expand" for="c-42619430">[10 more]</label></div><br/><div class="children"><div class="content">If I were NVidia, I would be throwing everything I could at making entertainment experiences that need one of these to run...<p>I mean, this is awfully close to being &quot;Her&quot; in a box, right?</div><br/><div id="42619453" class="c"><input type="checkbox" id="c-42619453" checked=""/><div class="controls bullet"><span class="by">dagmx</span><span>|</span><a href="#42619320">root</a><span>|</span><a href="#42619430">parent</a><span>|</span><a href="#42620410">next</a><span>|</span><label class="collapse" for="c-42619453">[-]</label><label class="expand" for="c-42619453">[8 more]</label></div><br/><div class="children"><div class="content">I feel like a lot of people miss that Her was a dystopian future, not an ideal to hit.<p>Also, it’s $3000. For that you could buy subscriptions to OpenAI etc and have the dystopian partner everywhere you go.</div><br/><div id="42620519" class="c"><input type="checkbox" id="c-42620519" checked=""/><div class="controls bullet"><span class="by">nostromo</span><span>|</span><a href="#42619320">root</a><span>|</span><a href="#42619453">parent</a><span>|</span><a href="#42620406">next</a><span>|</span><label class="collapse" for="c-42620519">[-]</label><label class="expand" for="c-42620519">[1 more]</label></div><br/><div class="children"><div class="content">Fun fact:  Her was set in the year 2025.</div><br/></div></div><div id="42620406" class="c"><input type="checkbox" id="c-42620406" checked=""/><div class="controls bullet"><span class="by">int_19h</span><span>|</span><a href="#42619320">root</a><span>|</span><a href="#42619453">parent</a><span>|</span><a href="#42620519">prev</a><span>|</span><a href="#42619642">next</a><span>|</span><label class="collapse" for="c-42620406">[-]</label><label class="expand" for="c-42620406">[1 more]</label></div><br/><div class="children"><div class="content">This is exactly the scenario where you don&#x27;t want &quot;the cloud&quot; anywhere.</div><br/></div></div><div id="42619642" class="c"><input type="checkbox" id="c-42619642" checked=""/><div class="controls bullet"><span class="by">croes</span><span>|</span><a href="#42619320">root</a><span>|</span><a href="#42619453">parent</a><span>|</span><a href="#42620406">prev</a><span>|</span><a href="#42619627">next</a><span>|</span><label class="collapse" for="c-42619642">[-]</label><label class="expand" for="c-42619642">[2 more]</label></div><br/><div class="children"><div class="content">OpenAI doesn’t make any profit. So either it dies or prices go up. Not to mention the privacy aspect of your own machine and the freedom of choice which models to run</div><br/><div id="42620369" class="c"><input type="checkbox" id="c-42620369" checked=""/><div class="controls bullet"><span class="by">blackoil</span><span>|</span><a href="#42619320">root</a><span>|</span><a href="#42619642">parent</a><span>|</span><a href="#42619627">next</a><span>|</span><label class="collapse" for="c-42620369">[-]</label><label class="expand" for="c-42620369">[1 more]</label></div><br/><div class="children"><div class="content">&gt; So either it dies or prices go up.<p>Or efficiency gains in hardware and software catchup making current price point profitable.</div><br/></div></div></div></div><div id="42619627" class="c"><input type="checkbox" id="c-42619627" checked=""/><div class="controls bullet"><span class="by">VikingCoder</span><span>|</span><a href="#42619320">root</a><span>|</span><a href="#42619453">parent</a><span>|</span><a href="#42619642">prev</a><span>|</span><a href="#42619529">next</a><span>|</span><label class="collapse" for="c-42619627">[-]</label><label class="expand" for="c-42619627">[1 more]</label></div><br/><div class="children"><div class="content">We already live in dystopian hell and I&#x27;d like to have Scarlett Johansen whispering in my ear, thanks.<p>Also, I don&#x27;t particularly want my data to be processed by anyone else.</div><br/></div></div><div id="42619529" class="c"><input type="checkbox" id="c-42619529" checked=""/><div class="controls bullet"><span class="by">t0lo</span><span>|</span><a href="#42619320">root</a><span>|</span><a href="#42619453">parent</a><span>|</span><a href="#42619627">prev</a><span>|</span><a href="#42619500">next</a><span>|</span><label class="collapse" for="c-42619529">[-]</label><label class="expand" for="c-42619529">[1 more]</label></div><br/><div class="children"><div class="content">The dystopian overton window has shifted, didn&#x27;t you know, moral ambiguity is a win now? :) Tesla was right.</div><br/></div></div><div id="42619500" class="c"><input type="checkbox" id="c-42619500" checked=""/><div class="controls bullet"><span class="by">tacticus</span><span>|</span><a href="#42619320">root</a><span>|</span><a href="#42619453">parent</a><span>|</span><a href="#42619529">prev</a><span>|</span><a href="#42620410">next</a><span>|</span><label class="collapse" for="c-42619500">[-]</label><label class="expand" for="c-42619500">[1 more]</label></div><br/><div class="children"><div class="content">they don&#x27;t miss that part. they just want to be the evil character.</div><br/></div></div></div></div><div id="42620410" class="c"><input type="checkbox" id="c-42620410" checked=""/><div class="controls bullet"><span class="by">int_19h</span><span>|</span><a href="#42619320">root</a><span>|</span><a href="#42619430">parent</a><span>|</span><a href="#42619453">prev</a><span>|</span><a href="#42619404">next</a><span>|</span><label class="collapse" for="c-42620410">[-]</label><label class="expand" for="c-42620410">[1 more]</label></div><br/><div class="children"><div class="content">The real interesting stuff will happen when we get multimodal LMs that can do VR output.</div><br/></div></div></div></div><div id="42619404" class="c"><input type="checkbox" id="c-42619404" checked=""/><div class="controls bullet"><span class="by">computably</span><span>|</span><a href="#42619320">root</a><span>|</span><a href="#42619339">parent</a><span>|</span><a href="#42619430">prev</a><span>|</span><a href="#42619397">next</a><span>|</span><label class="collapse" for="c-42619404">[-]</label><label class="expand" for="c-42619404">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, it&#x27;s more about preempting competitors from attracting any ecosystem development than the revenue itself.</div><br/></div></div><div id="42619397" class="c"><input type="checkbox" id="c-42619397" checked=""/><div class="controls bullet"><span class="by">option</span><span>|</span><a href="#42619320">root</a><span>|</span><a href="#42619339">parent</a><span>|</span><a href="#42619404">prev</a><span>|</span><a href="#42619433">next</a><span>|</span><label class="collapse" for="c-42619397">[-]</label><label class="expand" for="c-42619397">[2 more]</label></div><br/><div class="children"><div class="content">today’s enthusiast, grad student, hacker is tomorrow’s startup founder, CEO, CTO or 10x contributor in large tech company</div><br/><div id="42620210" class="c"><input type="checkbox" id="c-42620210" checked=""/><div class="controls bullet"><span class="by">Mistletoe</span><span>|</span><a href="#42619320">root</a><span>|</span><a href="#42619397">parent</a><span>|</span><a href="#42619433">next</a><span>|</span><label class="collapse" for="c-42620210">[-]</label><label class="expand" for="c-42620210">[1 more]</label></div><br/><div class="children"><div class="content">&gt; tomorrow’s startup founder, CEO, CTO or 10x contributor in large tech company<p>Do we need more of those?  We need plumbers and people that know how to build houses.  We are completely full on founders and executives.</div><br/></div></div></div></div></div></div><div id="42619433" class="c"><input type="checkbox" id="c-42619433" checked=""/><div class="controls bullet"><span class="by">paxys</span><span>|</span><a href="#42619320">parent</a><span>|</span><a href="#42619339">prev</a><span>|</span><a href="#42619472">next</a><span>|</span><label class="collapse" for="c-42619433">[-]</label><label class="expand" for="c-42619433">[4 more]</label></div><br/><div class="children"><div class="content">“Bigger” in what sense? For AI? Sure, because this an AI product. 5x series are gaming cards.</div><br/><div id="42619503" class="c"><input type="checkbox" id="c-42619503" checked=""/><div class="controls bullet"><span class="by">a________d</span><span>|</span><a href="#42619320">root</a><span>|</span><a href="#42619433">parent</a><span>|</span><a href="#42619490">next</a><span>|</span><label class="collapse" for="c-42619503">[-]</label><label class="expand" for="c-42619503">[1 more]</label></div><br/><div class="children"><div class="content">Not expecting this to compete with the 5x series in terms of gaming; But it&#x27;s interesting to note the increase in gaming performance Jensen was speaking about with Blackwell was larger related to inferenced frames generated by the tensor cores.<p>I wonder how it would go as a productivity&#x2F;tinkering&#x2F;gaming rig? Could a GPU potentially be stacked in the same way an additional Digit can?</div><br/></div></div><div id="42619490" class="c"><input type="checkbox" id="c-42619490" checked=""/><div class="controls bullet"><span class="by">Karupan</span><span>|</span><a href="#42619320">root</a><span>|</span><a href="#42619433">parent</a><span>|</span><a href="#42619503">prev</a><span>|</span><a href="#42619497">next</a><span>|</span><label class="collapse" for="c-42619490">[-]</label><label class="expand" for="c-42619490">[1 more]</label></div><br/><div class="children"><div class="content">Bigger in the sense of the announcements.</div><br/></div></div><div id="42619497" class="c"><input type="checkbox" id="c-42619497" checked=""/><div class="controls bullet"><span class="by">AuryGlenz</span><span>|</span><a href="#42619320">root</a><span>|</span><a href="#42619433">parent</a><span>|</span><a href="#42619490">prev</a><span>|</span><a href="#42619472">next</a><span>|</span><label class="collapse" for="c-42619497">[-]</label><label class="expand" for="c-42619497">[1 more]</label></div><br/><div class="children"><div class="content">Eh.  Gaming cards, but also significantly faster.  If the model fits in the VRAM the 5090 is a much better buy.</div><br/></div></div></div></div><div id="42619472" class="c"><input type="checkbox" id="c-42619472" checked=""/><div class="controls bullet"><span class="by">qwertox</span><span>|</span><a href="#42619320">parent</a><span>|</span><a href="#42619433">prev</a><span>|</span><a href="#42619769">next</a><span>|</span><label class="collapse" for="c-42619472">[-]</label><label class="expand" for="c-42619472">[2 more]</label></div><br/><div class="children"><div class="content">This is somewhat similar to what GeForce was to gamers back in the days, but for AI enthusiasts. Sure, the price is much higher, but at least it&#x27;s a completely integrated solution.</div><br/><div id="42619685" class="c"><input type="checkbox" id="c-42619685" checked=""/><div class="controls bullet"><span class="by">Karupan</span><span>|</span><a href="#42619320">root</a><span>|</span><a href="#42619472">parent</a><span>|</span><a href="#42619769">next</a><span>|</span><label class="collapse" for="c-42619685">[-]</label><label class="expand" for="c-42619685">[1 more]</label></div><br/><div class="children"><div class="content">Yep that&#x27;s what I&#x27;m thinking as well. I was going to buy a 5090 mainly to play around with LLM code generation, but this is a worthy option for roughly the same price as building a new PC with a 5090.</div><br/></div></div></div></div><div id="42619769" class="c"><input type="checkbox" id="c-42619769" checked=""/><div class="controls bullet"><span class="by">doctorpangloss</span><span>|</span><a href="#42619320">parent</a><span>|</span><a href="#42619472">prev</a><span>|</span><a href="#42619544">next</a><span>|</span><label class="collapse" for="c-42619769">[-]</label><label class="expand" for="c-42619769">[5 more]</label></div><br/><div class="children"><div class="content">What slice?<p>Also, macOS devices are not very good inference solutions. They are just believed to be by diehards.<p>I don&#x27;t think Digits will perform well either.<p>If NVIDIA wanted you to have good performance on a budget, it would ship NVLink on the 5090.</div><br/><div id="42619818" class="c"><input type="checkbox" id="c-42619818" checked=""/><div class="controls bullet"><span class="by">Karupan</span><span>|</span><a href="#42619320">root</a><span>|</span><a href="#42619769">parent</a><span>|</span><a href="#42619816">next</a><span>|</span><label class="collapse" for="c-42619818">[-]</label><label class="expand" for="c-42619818">[3 more]</label></div><br/><div class="children"><div class="content">They are perfectly fine for certain people. I can run Qwen-2.5-coder 14B on my M2 Max MacBook Pro with 32gb at ~16 tok&#x2F;sec. At least in my circle, people are budget conscious and would prefer using existing devices rather than pay for subscriptions where possible.<p>And we know why they won&#x27;t ship NVLink anymore on prosumer GPUs: they control almost the entire segment and why give more away for free? Good for the company and investors, bad for us consumers.</div><br/><div id="42620177" class="c"><input type="checkbox" id="c-42620177" checked=""/><div class="controls bullet"><span class="by">acchow</span><span>|</span><a href="#42619320">root</a><span>|</span><a href="#42619818">parent</a><span>|</span><a href="#42619816">next</a><span>|</span><label class="collapse" for="c-42620177">[-]</label><label class="expand" for="c-42620177">[2 more]</label></div><br/><div class="children"><div class="content">&gt; I can run Qwen-2.5-coder 14B on my M2 Max MacBook Pro with 32gb at ~16 tok&#x2F;sec. At least in my circle, people are budget conscious<p>Qwen 2.5 32B on openrouter is $0.16&#x2F;million output tokens. At your 16 tokens per second, 1 million tokens is 17 continuous hours of output.<p>Openrouter will charge you 16 cents for that.<p>I think you may want to reevaluate which is the real budget choice here<p>Edit: elaborating, that extra 16GB ram on the Mac to hold the Qwen model costs $400, or equivalently 1770 days of continuous output. All assuming electricity is free</div><br/><div id="42620372" class="c"><input type="checkbox" id="c-42620372" checked=""/><div class="controls bullet"><span class="by">Karupan</span><span>|</span><a href="#42619320">root</a><span>|</span><a href="#42620177">parent</a><span>|</span><a href="#42619816">next</a><span>|</span><label class="collapse" for="c-42620372">[-]</label><label class="expand" for="c-42620372">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a no brainer for me cause I already own the MacBook and I don&#x27;t mind waiting a few extra seconds. Also, I didn&#x27;t buy the mac for this purpose, it&#x27;s just my daily device. So yes, I&#x27;m sure OpenRouter is cheaper, but I just don&#x27;t have to think about using it as long as the open models are reasonable good for my use. Of course your needs may be quite different.</div><br/></div></div></div></div></div></div><div id="42619816" class="c"><input type="checkbox" id="c-42619816" checked=""/><div class="controls bullet"><span class="by">YetAnotherNick</span><span>|</span><a href="#42619320">root</a><span>|</span><a href="#42619769">parent</a><span>|</span><a href="#42619818">prev</a><span>|</span><a href="#42619544">next</a><span>|</span><label class="collapse" for="c-42619816">[-]</label><label class="expand" for="c-42619816">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Also, macOS devices are not very good inference solutions<p>They are good for single batch inference and have very good tok&#x2F;sec&#x2F;user. ollama works perfectly in mac.</div><br/></div></div></div></div><div id="42619544" class="c"><input type="checkbox" id="c-42619544" checked=""/><div class="controls bullet"><span class="by">puppymaster</span><span>|</span><a href="#42619320">parent</a><span>|</span><a href="#42619769">prev</a><span>|</span><a href="#42620359">next</a><span>|</span><label class="collapse" for="c-42619544">[-]</label><label class="expand" for="c-42619544">[1 more]</label></div><br/><div class="children"><div class="content">it eats into all NVDA consumer-facing clients no? I can see why openai and etc are looking for alternative hardware solution to train their next model.</div><br/></div></div><div id="42620359" class="c"><input type="checkbox" id="c-42620359" checked=""/><div class="controls bullet"><span class="by">csomar</span><span>|</span><a href="#42619320">parent</a><span>|</span><a href="#42619544">prev</a><span>|</span><a href="#42620175">next</a><span>|</span><label class="collapse" for="c-42620359">[-]</label><label class="expand" for="c-42620359">[5 more]</label></div><br/><div class="children"><div class="content">Am I the only one disappointed by these? They cost roughly half the price of a macbook pro and offer hmm.. half the capacity in RAM. Sure speed matters in AI, but what do I do with speed when I can&#x27;t load a 70b model.<p>On the other hand, with a $5000 macbook pro, I can easily load a 70b model and have a &quot;full&quot; macbook pro as a plus. I am not sure I fully understand the value of these cards for someone that want to run personal AI models.</div><br/><div id="42620481" class="c"><input type="checkbox" id="c-42620481" checked=""/><div class="controls bullet"><span class="by">gnabgib</span><span>|</span><a href="#42619320">root</a><span>|</span><a href="#42620359">parent</a><span>|</span><a href="#42620456">next</a><span>|</span><label class="collapse" for="c-42620481">[-]</label><label class="expand" for="c-42620481">[1 more]</label></div><br/><div class="children"><div class="content">Are you, perhaps, commenting on the wrong thread?  Project Digits is a $3k 128GB computer.. the best your your $5K MBP can have for ram is.. 128GB.</div><br/></div></div><div id="42620456" class="c"><input type="checkbox" id="c-42620456" checked=""/><div class="controls bullet"><span class="by">rictic</span><span>|</span><a href="#42619320">root</a><span>|</span><a href="#42620359">parent</a><span>|</span><a href="#42620481">prev</a><span>|</span><a href="#42620448">next</a><span>|</span><label class="collapse" for="c-42620456">[-]</label><label class="expand" for="c-42620456">[1 more]</label></div><br/><div class="children"><div class="content">Hm? They have 128GB of RAM. Macbook Pros cap out at 128GB as well. Will be interesting to see how a Project Digits machine performs in terms of inference speed.</div><br/></div></div><div id="42620448" class="c"><input type="checkbox" id="c-42620448" checked=""/><div class="controls bullet"><span class="by">macawfish</span><span>|</span><a href="#42619320">root</a><span>|</span><a href="#42620359">parent</a><span>|</span><a href="#42620456">prev</a><span>|</span><a href="#42620175">next</a><span>|</span><label class="collapse" for="c-42620448">[-]</label><label class="expand" for="c-42620448">[2 more]</label></div><br/><div class="children"><div class="content">Then buy two and stack them!<p>Also I&#x27;m unfamiliar with macs is there really a MacBook pro with 256GB of RAM?</div><br/><div id="42620521" class="c"><input type="checkbox" id="c-42620521" checked=""/><div class="controls bullet"><span class="by">csomar</span><span>|</span><a href="#42619320">root</a><span>|</span><a href="#42620448">parent</a><span>|</span><a href="#42620175">next</a><span>|</span><label class="collapse" for="c-42620521">[-]</label><label class="expand" for="c-42620521">[1 more]</label></div><br/><div class="children"><div class="content">No, macbooks pro cap at 128GB. But, still, they are a laptop. It&#x27;ll be interesting to see if Apple can offer a good counter for the desktop. The mac pro can go to 192Gb which is closer to the 128Gb Digits + your Desktop machine. At $9299 price tag, it&#x27;s not too competitive but close.</div><br/></div></div></div></div></div></div><div id="42620175" class="c"><input type="checkbox" id="c-42620175" checked=""/><div class="controls bullet"><span class="by">trhway</span><span>|</span><a href="#42619320">parent</a><span>|</span><a href="#42620359">prev</a><span>|</span><a href="#42619962">next</a><span>|</span><label class="collapse" for="c-42620175">[-]</label><label class="expand" for="c-42620175">[1 more]</label></div><br/><div class="children"><div class="content">&gt;enthusiast AI dev segment<p>i think it isn&#x27;t about enthusiast. To me it looks like Huang&#x2F;NVDA is pushing further a small revolution using the opening provided by the AI wave - up until now the GPU was add-on to the general computing core onto which that computing core offloaded some computing. With AI that offloaded computing becomes de-facto the main computing and Huang&#x2F;NVDA is turning tables by making the CPU is just a small add-on on the GPU, with some general computing offloaded to that CPU.<p>The CPU being located that &quot;close&quot; and with unified memory - that would stimulate development of parallelization for a lot of general computing so that it would be executed on GPU, very fast that way, instead of on the CPU. For example classic of enterprise computing - databases, the SQL ones - a lot, if not, with some work, everything, in these databases can be executed on GPU with a significant performance gain vs. CPU. Why it isn&#x27;t happening today? Load&#x2F;unload onto GPU eats into performance, complexity of having only some operations offloaded to GPU is very high in dev effort, etc. Streamlined development on a platform with unified memory will change it. That way Huang&#x2F;NVDA may pull out rug from under the CPU-first platforms like AMD&#x2F;INTC and would own both - new AI computing as well as significant share of the classic enterprise one.</div><br/></div></div></div></div><div id="42619962" class="c"><input type="checkbox" id="c-42619962" checked=""/><div class="controls bullet"><span class="by">ryao</span><span>|</span><a href="#42619320">prev</a><span>|</span><a href="#42619363">next</a><span>|</span><label class="collapse" for="c-42619962">[-]</label><label class="expand" for="c-42619962">[7 more]</label></div><br/><div class="children"><div class="content">This looks like a successor to the Nvidia Jetson AGX Orin 64GB Developer Kit:<p><a href="https:&#x2F;&#x2F;www.okdo.com&#x2F;wp-content&#x2F;uploads&#x2F;2023&#x2F;03&#x2F;jetson-agx-orin-64GB-developer-kit-datasheet-web-us.pdf" rel="nofollow">https:&#x2F;&#x2F;www.okdo.com&#x2F;wp-content&#x2F;uploads&#x2F;2023&#x2F;03&#x2F;jetson-agx-o...</a><p>I wonder what the specifications are in terms of memory bandwidth and computational capability.</div><br/><div id="42619979" class="c"><input type="checkbox" id="c-42619979" checked=""/><div class="controls bullet"><span class="by">kcb</span><span>|</span><a href="#42619962">parent</a><span>|</span><a href="#42619363">next</a><span>|</span><label class="collapse" for="c-42619979">[-]</label><label class="expand" for="c-42619979">[6 more]</label></div><br/><div class="children"><div class="content">Hopefully, the OS support isn&#x27;t as awful as the Jetson platforms usually are. Unless they change, you&#x27;ll get 1 or 2 major kernel updates ever and have to do bizarre stuff like install a 6 year old Ubuntu on your x86 PC to run the utility to flash the OS.</div><br/><div id="42620030" class="c"><input type="checkbox" id="c-42620030" checked=""/><div class="controls bullet"><span class="by">ryao</span><span>|</span><a href="#42619962">root</a><span>|</span><a href="#42619979">parent</a><span>|</span><a href="#42619363">next</a><span>|</span><label class="collapse" for="c-42620030">[-]</label><label class="expand" for="c-42620030">[5 more]</label></div><br/><div class="children"><div class="content">The community likely will make instructions for installing mainstream Linux distributions on it.</div><br/><div id="42620055" class="c"><input type="checkbox" id="c-42620055" checked=""/><div class="controls bullet"><span class="by">kcb</span><span>|</span><a href="#42619962">root</a><span>|</span><a href="#42620030">parent</a><span>|</span><a href="#42619363">next</a><span>|</span><label class="collapse" for="c-42620055">[-]</label><label class="expand" for="c-42620055">[4 more]</label></div><br/><div class="children"><div class="content">Doesn&#x27;t really help though if it requires an nvidia kernel.</div><br/><div id="42620082" class="c"><input type="checkbox" id="c-42620082" checked=""/><div class="controls bullet"><span class="by">ryao</span><span>|</span><a href="#42619962">root</a><span>|</span><a href="#42620055">parent</a><span>|</span><a href="#42620257">next</a><span>|</span><label class="collapse" for="c-42620082">[-]</label><label class="expand" for="c-42620082">[1 more]</label></div><br/><div class="children"><div class="content">The Linux kernel license requires Nvidia to disclose their Linux kernel sources and Nvidia open sourced their kernel driver.<p>That said, you can probably boot a Debian or Gentoo system using the Nvidia provided kernel if need be.</div><br/></div></div><div id="42620257" class="c"><input type="checkbox" id="c-42620257" checked=""/><div class="controls bullet"><span class="by">snerbles</span><span>|</span><a href="#42619962">root</a><span>|</span><a href="#42620055">parent</a><span>|</span><a href="#42620082">prev</a><span>|</span><a href="#42619363">next</a><span>|</span><label class="collapse" for="c-42620257">[-]</label><label class="expand" for="c-42620257">[2 more]</label></div><br/><div class="children"><div class="content">The official Linux kernel driver for Blackwell is GPL&#x2F;MIT licensed: <a href="https:&#x2F;&#x2F;developer.nvidia.com&#x2F;blog&#x2F;nvidia-transitions-fully-towards-open-source-gpu-kernel-modules&#x2F;" rel="nofollow">https:&#x2F;&#x2F;developer.nvidia.com&#x2F;blog&#x2F;nvidia-transitions-fully-t...</a></div><br/><div id="42620462" class="c"><input type="checkbox" id="c-42620462" checked=""/><div class="controls bullet"><span class="by">sliken</span><span>|</span><a href="#42619962">root</a><span>|</span><a href="#42620257">parent</a><span>|</span><a href="#42619363">next</a><span>|</span><label class="collapse" for="c-42620462">[-]</label><label class="expand" for="c-42620462">[1 more]</label></div><br/><div class="children"><div class="content">Keep in mind that a kernel module != driver.  It&#x27;s just doing initialization and passing data to&#x2F;from the driver, which is closed source and in user space.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="42619363" class="c"><input type="checkbox" id="c-42619363" checked=""/><div class="controls bullet"><span class="by">narrator</span><span>|</span><a href="#42619962">prev</a><span>|</span><a href="#42619874">next</a><span>|</span><label class="collapse" for="c-42619363">[-]</label><label class="expand" for="c-42619363">[23 more]</label></div><br/><div class="children"><div class="content">Nvidia releases a Linux desktop supercomputer that&#x27;s better price&#x2F;performance wise than anything Wintel is doing and their whole new software stack will only run on WSL2. They aren&#x27;t porting to Win32. Wow, it may actually be the year of Linux on the Desktop.</div><br/><div id="42619820" class="c"><input type="checkbox" id="c-42619820" checked=""/><div class="controls bullet"><span class="by">bee_rider</span><span>|</span><a href="#42619363">parent</a><span>|</span><a href="#42619598">next</a><span>|</span><label class="collapse" for="c-42619820">[-]</label><label class="expand" for="c-42619820">[1 more]</label></div><br/><div class="children"><div class="content">Seems more like a workstation. So, that’s just a continuation of the last could Decades of Unix on the Workstation, right?</div><br/></div></div><div id="42619598" class="c"><input type="checkbox" id="c-42619598" checked=""/><div class="controls bullet"><span class="by">sliken</span><span>|</span><a href="#42619363">parent</a><span>|</span><a href="#42619820">prev</a><span>|</span><a href="#42619549">next</a><span>|</span><label class="collapse" for="c-42619598">[-]</label><label class="expand" for="c-42619598">[7 more]</label></div><br/><div class="children"><div class="content">Not sure how to judge better price&#x2F;perf.  I wouldn&#x27;t expect 20 Neoverse N2 cores to do particularly well vs 16 zen5 cores.  The GPU side looks promising, but they aren&#x27;t mentioning memory bandwidth, configuration, spec, or performance.<p>Did see vague claims of &quot;starting at $3k&quot;, max 4TB nvme, and max 128GB ram.<p>I&#x27;d expect AMD Strix Halo (AI Max plus 395) to be reasonably competitive.</div><br/><div id="42619722" class="c"><input type="checkbox" id="c-42619722" checked=""/><div class="controls bullet"><span class="by">skavi</span><span>|</span><a href="#42619363">root</a><span>|</span><a href="#42619598">parent</a><span>|</span><a href="#42619674">next</a><span>|</span><label class="collapse" for="c-42619722">[-]</label><label class="expand" for="c-42619722">[4 more]</label></div><br/><div class="children"><div class="content">It’s actually “10 Arm Cortex-X925 and 10 Cortex-A725” [0]. These are much newer cores and have a reasonable chance of being competitive.<p>[0]: <a href="https:&#x2F;&#x2F;newsroom.arm.com&#x2F;blog&#x2F;arm-nvidia-project-digits-high-performance-ai" rel="nofollow">https:&#x2F;&#x2F;newsroom.arm.com&#x2F;blog&#x2F;arm-nvidia-project-digits-high...</a></div><br/><div id="42619778" class="c"><input type="checkbox" id="c-42619778" checked=""/><div class="controls bullet"><span class="by">sliken</span><span>|</span><a href="#42619363">root</a><span>|</span><a href="#42619722">parent</a><span>|</span><a href="#42619674">next</a><span>|</span><label class="collapse" for="c-42619778">[-]</label><label class="expand" for="c-42619778">[3 more]</label></div><br/><div class="children"><div class="content">Good catch, they called it &quot;Grace Blackwell&quot;.  Changing the CPU cores completely and calling it Grace seems weird.  Maybe it was just a mistake during the keynote.</div><br/><div id="42620025" class="c"><input type="checkbox" id="c-42620025" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#42619363">root</a><span>|</span><a href="#42619778">parent</a><span>|</span><a href="#42619674">next</a><span>|</span><label class="collapse" for="c-42620025">[-]</label><label class="expand" for="c-42620025">[2 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think it was a mistake; maybe they intend Grace to be a broader brand like Ryzen not one particular model.</div><br/><div id="42620566" class="c"><input type="checkbox" id="c-42620566" checked=""/><div class="controls bullet"><span class="by">kristopolous</span><span>|</span><a href="#42619363">root</a><span>|</span><a href="#42620025">parent</a><span>|</span><a href="#42619674">next</a><span>|</span><label class="collapse" for="c-42620566">[-]</label><label class="expand" for="c-42620566">[1 more]</label></div><br/><div class="children"><div class="content">it&#x27;s an interesting idea. I mean grace hopper was an actual person but nvidia can have whatever arbitrary naming rules they&#x27;d like.</div><br/></div></div></div></div></div></div></div></div><div id="42619674" class="c"><input type="checkbox" id="c-42619674" checked=""/><div class="controls bullet"><span class="by">z4y5f3</span><span>|</span><a href="#42619363">root</a><span>|</span><a href="#42619598">parent</a><span>|</span><a href="#42619722">prev</a><span>|</span><a href="#42619549">next</a><span>|</span><label class="collapse" for="c-42619674">[-]</label><label class="expand" for="c-42619674">[2 more]</label></div><br/><div class="children"><div class="content">NVIDIA is likely citing 1 PFlops at FP 4 sparse (they did this for GB200), so that is 128 TFlops BF16 dense, or 2&#x2F;3 of what RTX 4090 is capable of. I would put the memory bandwidth at 546 GBps, using the same 512 bit LPDDR5X 8533 Mbps as Apple M4 max.</div><br/><div id="42620444" class="c"><input type="checkbox" id="c-42620444" checked=""/><div class="controls bullet"><span class="by">gardnr</span><span>|</span><a href="#42619363">root</a><span>|</span><a href="#42619674">parent</a><span>|</span><a href="#42619549">next</a><span>|</span><label class="collapse" for="c-42620444">[-]</label><label class="expand" for="c-42620444">[1 more]</label></div><br/><div class="children"><div class="content">Based on your evaluation, it sounds like it will run inference at speed similar to an M4 Max and also allow &quot;startups&quot; to experiment with fine tuning larger models or larger context windows.<p>It&#x27;s the best &quot;dev board&quot; setup I&#x27;ve seen so far. It might be part of their larger commercial plan but it definitely hits the sweet spot for the home enthusiast who have been pleading for more VRAM.</div><br/></div></div></div></div></div></div><div id="42619549" class="c"><input type="checkbox" id="c-42619549" checked=""/><div class="controls bullet"><span class="by">immibis</span><span>|</span><a href="#42619363">parent</a><span>|</span><a href="#42619598">prev</a><span>|</span><a href="#42619399">next</a><span>|</span><label class="collapse" for="c-42619549">[-]</label><label class="expand" for="c-42619549">[1 more]</label></div><br/><div class="children"><div class="content">Never underestimate the open source world&#x27;s power to create a crappy desktop experience.</div><br/></div></div><div id="42619399" class="c"><input type="checkbox" id="c-42619399" checked=""/><div class="controls bullet"><span class="by">CamperBob2</span><span>|</span><a href="#42619363">parent</a><span>|</span><a href="#42619549">prev</a><span>|</span><a href="#42619444">next</a><span>|</span><label class="collapse" for="c-42619399">[-]</label><label class="expand" for="c-42619399">[8 more]</label></div><br/><div class="children"><div class="content">Where does it say they won&#x27;t be supporting Win32?</div><br/><div id="42619432" class="c"><input type="checkbox" id="c-42619432" checked=""/><div class="controls bullet"><span class="by">narrator</span><span>|</span><a href="#42619363">root</a><span>|</span><a href="#42619399">parent</a><span>|</span><a href="#42619444">next</a><span>|</span><label class="collapse" for="c-42619432">[-]</label><label class="expand" for="c-42619432">[7 more]</label></div><br/><div class="children"><div class="content">Here he says that in order for the cloud and the PC to be compatible, he&#x27;s going to only support WSL2, the Windows subsystem for Linux which is a Linux API on top of Windows.<p>Here&#x27;s a link to the part of the keynote where he says this:<p><a href="https:&#x2F;&#x2F;youtu.be&#x2F;MC7L_EWylb0?t=7259" rel="nofollow">https:&#x2F;&#x2F;youtu.be&#x2F;MC7L_EWylb0?t=7259</a></div><br/><div id="42619602" class="c"><input type="checkbox" id="c-42619602" checked=""/><div class="controls bullet"><span class="by">sliken</span><span>|</span><a href="#42619363">root</a><span>|</span><a href="#42619432">parent</a><span>|</span><a href="#42619600">next</a><span>|</span><label class="collapse" for="c-42619602">[-]</label><label class="expand" for="c-42619602">[1 more]</label></div><br/><div class="children"><div class="content">The keynote mentioned that it could be used as a Linux workstation.</div><br/></div></div><div id="42619600" class="c"><input type="checkbox" id="c-42619600" checked=""/><div class="controls bullet"><span class="by">stonogo</span><span>|</span><a href="#42619363">root</a><span>|</span><a href="#42619432">parent</a><span>|</span><a href="#42619602">prev</a><span>|</span><a href="#42619444">next</a><span>|</span><label class="collapse" for="c-42619600">[-]</label><label class="expand" for="c-42619600">[5 more]</label></div><br/><div class="children"><div class="content">&quot;Linux API on top of Windows&quot; is an interesting way to describe a virtual machine.</div><br/><div id="42619650" class="c"><input type="checkbox" id="c-42619650" checked=""/><div class="controls bullet"><span class="by">pulse7</span><span>|</span><a href="#42619363">root</a><span>|</span><a href="#42619600">parent</a><span>|</span><a href="#42619614">next</a><span>|</span><label class="collapse" for="c-42619650">[-]</label><label class="expand" for="c-42619650">[1 more]</label></div><br/><div class="children"><div class="content">WSL1 was &quot;Linux API on top of Windows&quot;, WSL2 is &quot;Linux VM on top of Windows&quot;</div><br/></div></div><div id="42619614" class="c"><input type="checkbox" id="c-42619614" checked=""/><div class="controls bullet"><span class="by">sedatk</span><span>|</span><a href="#42619363">root</a><span>|</span><a href="#42619600">parent</a><span>|</span><a href="#42619650">prev</a><span>|</span><a href="#42619634">next</a><span>|</span><label class="collapse" for="c-42619614">[-]</label><label class="expand" for="c-42619614">[1 more]</label></div><br/><div class="children"><div class="content">That’s more like WSL1, yes.</div><br/></div></div><div id="42619634" class="c"><input type="checkbox" id="c-42619634" checked=""/><div class="controls bullet"><span class="by">SteveNuts</span><span>|</span><a href="#42619363">root</a><span>|</span><a href="#42619600">parent</a><span>|</span><a href="#42619614">prev</a><span>|</span><a href="#42619444">next</a><span>|</span><label class="collapse" for="c-42619634">[-]</label><label class="expand" for="c-42619634">[2 more]</label></div><br/><div class="children"><div class="content">WSL2 is no longer a VM, afaik.</div><br/><div id="42619684" class="c"><input type="checkbox" id="c-42619684" checked=""/><div class="controls bullet"><span class="by">gnabgib</span><span>|</span><a href="#42619363">root</a><span>|</span><a href="#42619634">parent</a><span>|</span><a href="#42619444">next</a><span>|</span><label class="collapse" for="c-42619684">[-]</label><label class="expand" for="c-42619684">[1 more]</label></div><br/><div class="children"><div class="content">Other way around (1 wasn&#x27;t, 2 runs in a managed HyperV VM) <a href="https:&#x2F;&#x2F;learn.microsoft.com&#x2F;en-us&#x2F;windows&#x2F;wsl&#x2F;compare-versions#comparing-features" rel="nofollow">https:&#x2F;&#x2F;learn.microsoft.com&#x2F;en-us&#x2F;windows&#x2F;wsl&#x2F;compare-versio...</a></div><br/></div></div></div></div></div></div></div></div></div></div><div id="42619444" class="c"><input type="checkbox" id="c-42619444" checked=""/><div class="controls bullet"><span class="by">rvz</span><span>|</span><a href="#42619363">parent</a><span>|</span><a href="#42619399">prev</a><span>|</span><a href="#42619874">next</a><span>|</span><label class="collapse" for="c-42619444">[-]</label><label class="expand" for="c-42619444">[5 more]</label></div><br/><div class="children"><div class="content">&gt; Wow, it may actually be the year of Linux on the Desktop.<p>?<p>Yeah starting at $3,000. Surely a cheap desktop computer to buy for someone who just wants to surf the web and send email &#x2F;s.<p>There is a reason why it is for &quot;enthusiasts&quot; and not for the general wider consumer or typical PC buyer.</div><br/><div id="42619984" class="c"><input type="checkbox" id="c-42619984" checked=""/><div class="controls bullet"><span class="by">Topfi</span><span>|</span><a href="#42619363">root</a><span>|</span><a href="#42619444">parent</a><span>|</span><a href="#42619826">next</a><span>|</span><label class="collapse" for="c-42619984">[-]</label><label class="expand" for="c-42619984">[2 more]</label></div><br/><div class="children"><div class="content">I see the most direct competitor in the Mac Studio, though of course we will have to wait for reviews to gauge how fair that comparison is. The Studio does have a fairly large niche as a solid workstation, though, so I could see this being successful.<p>For general desktop use, as you described, nearly any piece of modern hardware, from a RasPI, to most modern smartphones with a dock, could realistically serve most people well.<p>The thing is, you need to serve both, low-end use cases like browsing, and high-end dev work via workstations, because even for the &quot;average user&quot;, there is often one specific program on which they need to rely and which has limited support outside the OS they have grown up with. Course, there will be some programs like Desktop Microsoft Office which will never be ported, but still, Digitis could open the doors to some devs working natively on Linux.<p>A solid, compact, high-performance, yet low power workstation with a fully supported Linux desktop out of the box could bridge that gap, similar to how I have seen some developers adopt macOS over Linux and Windows since the release of the Studio and Max MacBooks.<p>Again, we have yet to see independent testing, but I would be surprised if anything of this size, simplicity, efficiency and performance was possible in any hardware configuration currently on the market.</div><br/><div id="42620450" class="c"><input type="checkbox" id="c-42620450" checked=""/><div class="controls bullet"><span class="by">sliken</span><span>|</span><a href="#42619363">root</a><span>|</span><a href="#42619984">parent</a><span>|</span><a href="#42619826">next</a><span>|</span><label class="collapse" for="c-42620450">[-]</label><label class="expand" for="c-42620450">[1 more]</label></div><br/><div class="children"><div class="content">I did want a M2 max studio, ended up with a 12 core Zen 4 + radeon 7800 XT for about half the money.<p>A Nvidia Project Digit&#x2F;GB10 for $3k with 128GB ram does sound tempting.  Especially since it&#x27;s very likely to have standard NVMe storage that I can expand or replace as needed, unlike the Apple solution.  Decent linux support is welcome as well.<p>Here&#x27;s hoping, if not I can fall back to a 128GB ram AMD Strix Halo&#x2F;395 AI Max plus.  CPU perf should be in the same ballpark, but not likely to come anywhere close on GPU performance, but still likely to have decent tokens&#x2F;sec for casual home tinkering.</div><br/></div></div></div></div><div id="42619826" class="c"><input type="checkbox" id="c-42619826" checked=""/><div class="controls bullet"><span class="by">yjftsjthsd-h</span><span>|</span><a href="#42619363">root</a><span>|</span><a href="#42619444">parent</a><span>|</span><a href="#42619984">prev</a><span>|</span><a href="#42619765">next</a><span>|</span><label class="collapse" for="c-42619826">[-]</label><label class="expand" for="c-42619826">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Surely a cheap desktop computer to buy for someone who just wants to surf the web and send email &#x2F;s.<p>That end of the market is occupied by Chromebooks... AKA a different GNU&#x2F;Linux.</div><br/></div></div><div id="42619765" class="c"><input type="checkbox" id="c-42619765" checked=""/><div class="controls bullet"><span class="by">fooker</span><span>|</span><a href="#42619363">root</a><span>|</span><a href="#42619444">parent</a><span>|</span><a href="#42619826">prev</a><span>|</span><a href="#42619874">next</a><span>|</span><label class="collapse" for="c-42619765">[-]</label><label class="expand" for="c-42619765">[1 more]</label></div><br/><div class="children"><div class="content">The typical PC buyer is an enthusiast now.</div><br/></div></div></div></div></div></div><div id="42619874" class="c"><input type="checkbox" id="c-42619874" checked=""/><div class="controls bullet"><span class="by">Tepix</span><span>|</span><a href="#42619363">prev</a><span>|</span><a href="#42619841">next</a><span>|</span><label class="collapse" for="c-42619874">[-]</label><label class="expand" for="c-42619874">[1 more]</label></div><br/><div class="children"><div class="content">With more and more personal AI, i think having a truly private device that can run large LLMs (remember: larger is better) is fantastic!<p>Ideally we can configure things like Apple Intelligence to use this instead of OpenAI and Apple&#x27;s cloud.</div><br/></div></div><div id="42619841" class="c"><input type="checkbox" id="c-42619841" checked=""/><div class="controls bullet"><span class="by">mrtksn</span><span>|</span><a href="#42619874">prev</a><span>|</span><a href="#42619182">next</a><span>|</span><label class="collapse" for="c-42619841">[-]</label><label class="expand" for="c-42619841">[7 more]</label></div><br/><div class="children"><div class="content">Okay, so this is not a peripheral that you connect to your computer to run specialized tasks, this is a full computer running Linux.<p>It&#x27;s a garden hermit. Imagine a future where everyone has one of those(not exactly this version but some future version), it lives with you it learns with you and unlike the cloud based SaaS AI you can teach it things immediately and diverge from the average to your advantage.</div><br/><div id="42619852" class="c"><input type="checkbox" id="c-42619852" checked=""/><div class="controls bullet"><span class="by">noduerme</span><span>|</span><a href="#42619841">parent</a><span>|</span><a href="#42619972">next</a><span>|</span><label class="collapse" for="c-42619852">[-]</label><label class="expand" for="c-42619852">[4 more]</label></div><br/><div class="children"><div class="content">&quot;garden hermit&quot; is a very interesting and evocative phrase. Where is that from?</div><br/><div id="42619867" class="c"><input type="checkbox" id="c-42619867" checked=""/><div class="controls bullet"><span class="by">mrtksn</span><span>|</span><a href="#42619841">root</a><span>|</span><a href="#42619852">parent</a><span>|</span><a href="#42619972">next</a><span>|</span><label class="collapse" for="c-42619867">[-]</label><label class="expand" for="c-42619867">[3 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a real thing: <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Garden_hermit" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Garden_hermit</a><p>In the past, in Europe, some wealthy people used to look after of a scholar living on their premises so they can ask them questions etc.</div><br/><div id="42620485" class="c"><input type="checkbox" id="c-42620485" checked=""/><div class="controls bullet"><span class="by">noduerme</span><span>|</span><a href="#42619841">root</a><span>|</span><a href="#42619867">parent</a><span>|</span><a href="#42620224">next</a><span>|</span><label class="collapse" for="c-42620485">[-]</label><label class="expand" for="c-42620485">[1 more]</label></div><br/><div class="children"><div class="content">aha, this is really something. I just got around to watching &quot;Furiosa&quot; last night. So something like having a personal &quot;history man&quot; (although, my take on the whole Mad Max series is that it&#x27;s just bottled up fear-porn about white settlers going uncivilized and becoming &quot;tribal&quot; - a colonial horror tale, &quot;The Heart of Darkness&quot; with motorcycles - common anywhere a relatively small group spread themselves out on a lot of ill-gotten land, did some nasty deeds and lost touch with the mothership).<p>In the Furiosa context, it&#x27;s a bit like a medicine man or shaman, then. A private, unreliable source of verbal hand me downs, whose main utility is to make elites feel like they have access to knowledge without needing to acquire it for themselves or question its veracity.<p>We really are entering a new dark age.</div><br/></div></div><div id="42620224" class="c"><input type="checkbox" id="c-42620224" checked=""/><div class="controls bullet"><span class="by">Mistletoe</span><span>|</span><a href="#42619841">root</a><span>|</span><a href="#42619867">parent</a><span>|</span><a href="#42620485">prev</a><span>|</span><a href="#42619972">next</a><span>|</span><label class="collapse" for="c-42620224">[-]</label><label class="expand" for="c-42620224">[1 more]</label></div><br/><div class="children"><div class="content">This is so strange, my girlfriend was just telling me about those yesterday.  The word “ornamental hermit” fills me with about as much disgust as I can experience.<p>&gt; Later, suggestions of hermits were replaced with actual hermits – men hired for the sole purpose of inhabiting a small structure and functioning as any other garden ornament.</div><br/></div></div></div></div></div></div><div id="42619972" class="c"><input type="checkbox" id="c-42619972" checked=""/><div class="controls bullet"><span class="by">Topfi</span><span>|</span><a href="#42619841">parent</a><span>|</span><a href="#42619852">prev</a><span>|</span><a href="#42619182">next</a><span>|</span><label class="collapse" for="c-42619972">[-]</label><label class="expand" for="c-42619972">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;d love to own one, but doubt this will go beyond a very specific niche. Despite there being advantages, very few still operate their own Plex server over subscriptions to streaming services, and on the local front, I feel that the progress of hardware, alongside findings that smaller models can handle a variety of tasks quite well, will mean a high performance, local workstation of this type will have niche appeal at most.</div><br/><div id="42620086" class="c"><input type="checkbox" id="c-42620086" checked=""/><div class="controls bullet"><span class="by">mrtksn</span><span>|</span><a href="#42619841">root</a><span>|</span><a href="#42619972">parent</a><span>|</span><a href="#42619182">next</a><span>|</span><label class="collapse" for="c-42620086">[-]</label><label class="expand" for="c-42620086">[1 more]</label></div><br/><div class="children"><div class="content">I have this feeling that at some point it will be very advantageous to have personal AI because when you use something that everyone can use the output of this something becomes very low value.<p>Maybe it will still make sense to have your personal AI in some data center, but on the other hand, there is the trend of governments and mega corps regulating what you can do with your computer. Try going out of the basics, try to do something fun and edge case - it is very likely that your general availability AI will refuse to help you.<p>when it is your own property, you get the chance to overcome restrictions and develop the thing beyond the average.<p>As a result, having something that can do things that no other else can do and not having restrictions on what you can do with this thing can become the ultimate superpower.</div><br/></div></div></div></div></div></div><div id="42619182" class="c"><input type="checkbox" id="c-42619182" checked=""/><div class="controls bullet"><span class="by">magicalhippo</span><span>|</span><a href="#42619841">prev</a><span>|</span><a href="#42619310">next</a><span>|</span><label class="collapse" for="c-42619182">[-]</label><label class="expand" for="c-42619182">[7 more]</label></div><br/><div class="children"><div class="content">Not much was unveiled but it showed a Blackwell GPU with 1PFLOP of FP4 compute, 128GB unified DDR5X memory, 20 ARM cores, and ConnectX powering two QSFP slots so one can stack multiple of them.<p>edit: While the title says &quot;personal&quot;, Jensen did say this was aimed at startups and similar, so not your living room necessarily.</div><br/><div id="42619341" class="c"><input type="checkbox" id="c-42619341" checked=""/><div class="controls bullet"><span class="by">computably</span><span>|</span><a href="#42619182">parent</a><span>|</span><a href="#42619310">next</a><span>|</span><label class="collapse" for="c-42619341">[-]</label><label class="expand" for="c-42619341">[6 more]</label></div><br/><div class="children"><div class="content">From the size and pricing ($3000) alone, it&#x27;s safe to conclude it has less raw FLOPs than a 5090. Since it uses LPDDR5X, almost certainly less memory bandwidth too (5090 @ 1.8 TB&#x2F;s, M4 Max w&#x2F; 128GB LPDDR5X @ 546 GB&#x2F;s). Basically the only advantage is how much VRAM it packs in a small form factor, and presumably greater power efficiency at its smaller scale.<p>The only thing it really competes with is the Mac Studio for LocalLlama-type enthusiasts and devs. It isn&#x27;t cheap enough to dent the used market, nor powerful enough to stand in for bigger cards.</div><br/><div id="42620598" class="c"><input type="checkbox" id="c-42620598" checked=""/><div class="controls bullet"><span class="by">KeplerBoy</span><span>|</span><a href="#42619182">root</a><span>|</span><a href="#42619341">parent</a><span>|</span><a href="#42619643">next</a><span>|</span><label class="collapse" for="c-42620598">[-]</label><label class="expand" for="c-42620598">[1 more]</label></div><br/><div class="children"><div class="content">Of course. It has much less FLOPs than the 5090, after all this will have a TDP of ~50W and run off a regular USB-PD power supply.<p>It&#x27;s basically the successor to the AGX Orin and in line with its pricing (considering it comes with a fast NIC).
The AGX Orin had RTX 3050 levels of performance.</div><br/></div></div><div id="42619643" class="c"><input type="checkbox" id="c-42619643" checked=""/><div class="controls bullet"><span class="by">sliken</span><span>|</span><a href="#42619182">root</a><span>|</span><a href="#42619341">parent</a><span>|</span><a href="#42620598">prev</a><span>|</span><a href="#42620016">next</a><span>|</span><label class="collapse" for="c-42619643">[-]</label><label class="expand" for="c-42619643">[3 more]</label></div><br/><div class="children"><div class="content">I believe $3,000 is for the unmentioned minimum config, no idea on the mentioned 4TB storage and 128GB ram version.<p>Running a 96GB ram model isn&#x27;t cheap (often with unified memory 25% is reserved for CPUs), so maybe it will win there.</div><br/><div id="42619893" class="c"><input type="checkbox" id="c-42619893" checked=""/><div class="controls bullet"><span class="by">ac29</span><span>|</span><a href="#42619182">root</a><span>|</span><a href="#42619643">parent</a><span>|</span><a href="#42620016">next</a><span>|</span><label class="collapse" for="c-42619893">[-]</label><label class="expand" for="c-42619893">[2 more]</label></div><br/><div class="children"><div class="content">The NVIDIA press release [0] says &quot;Each Project DIGITS features 128GB of unified, coherent memory and up to 4TB of NVMe storage&quot;, which makes it sound like the RAM is fixed size.<p>[0] <a href="https:&#x2F;&#x2F;nvidianews.nvidia.com&#x2F;news&#x2F;nvidia-puts-grace-blackwell-on-every-desk-and-at-every-ai-developers-fingertips" rel="nofollow">https:&#x2F;&#x2F;nvidianews.nvidia.com&#x2F;news&#x2F;nvidia-puts-grace-blackwe...</a></div><br/><div id="42620480" class="c"><input type="checkbox" id="c-42620480" checked=""/><div class="controls bullet"><span class="by">sliken</span><span>|</span><a href="#42619182">root</a><span>|</span><a href="#42619893">parent</a><span>|</span><a href="#42620016">next</a><span>|</span><label class="collapse" for="c-42620480">[-]</label><label class="expand" for="c-42620480">[1 more]</label></div><br/><div class="children"><div class="content">Awesome.<p>Maybe there will be storage options of 1,2,and 4TB and optional 25&#x2F;100&#x2F;200&#x2F;400 GBit interfaces.  Or maybe everything except the CPU&#x2F;GPU is constant, but having a 50%, 75%, or 100% of the CPU&#x2F;GPU cores so they can bin their chips.</div><br/></div></div></div></div></div></div><div id="42620016" class="c"><input type="checkbox" id="c-42620016" checked=""/><div class="controls bullet"><span class="by">kcb</span><span>|</span><a href="#42619182">root</a><span>|</span><a href="#42619341">parent</a><span>|</span><a href="#42619643">prev</a><span>|</span><a href="#42619310">next</a><span>|</span><label class="collapse" for="c-42620016">[-]</label><label class="expand" for="c-42620016">[1 more]</label></div><br/><div class="children"><div class="content">Making comparisons to the 5090 is silly. That thing draws 500W+ and will require a boat anchor of metal to keep it cool. The device they showed is something more along the lines of a mobile dev kit.</div><br/></div></div></div></div></div></div><div id="42619310" class="c"><input type="checkbox" id="c-42619310" checked=""/><div class="controls bullet"><span class="by">modeless</span><span>|</span><a href="#42619182">prev</a><span>|</span><a href="#42619451">next</a><span>|</span><label class="collapse" for="c-42619310">[-]</label><label class="expand" for="c-42619310">[11 more]</label></div><br/><div class="children"><div class="content">Finally a real ARM workstation from Nvidia! This will be much faster than Apple&#x27;s offerings for AI work. And at $3000 it is <i>much</i> cheaper than any Mac with 128 GB RAM.</div><br/><div id="42619631" class="c"><input type="checkbox" id="c-42619631" checked=""/><div class="controls bullet"><span class="by">sliken</span><span>|</span><a href="#42619310">parent</a><span>|</span><a href="#42619451">next</a><span>|</span><label class="collapse" for="c-42619631">[-]</label><label class="expand" for="c-42619631">[10 more]</label></div><br/><div class="children"><div class="content">On the CPU size the Neoverse N2 doesn&#x27;t compete particularly well with apple&#x27;s M4, or the Zen5 for the matter.<p>Bit bit hard to tell what&#x27;s on offer on the GPU side, I wouldn&#x27;t be surprised if it was RTX 4070 to 5070 in that range.<p>If the price&#x2F;perf is high enough $3k wouldn&#x27;t be a bad deal, I suspect a Strix Halo (better CPU cores, 256GB&#x2F;sec memory interface, likely slower GPU cores) will be better price&#x2F;perf, same max ram for unified memory, and cheaper.</div><br/><div id="42619746" class="c"><input type="checkbox" id="c-42619746" checked=""/><div class="controls bullet"><span class="by">skavi</span><span>|</span><a href="#42619310">root</a><span>|</span><a href="#42619631">parent</a><span>|</span><a href="#42619696">next</a><span>|</span><label class="collapse" for="c-42619746">[-]</label><label class="expand" for="c-42619746">[1 more]</label></div><br/><div class="children"><div class="content">It’s actually “10 Arm Cortex-X925 and 10 Cortex-A725” [0]. These are much newer cores and have a reasonable chance of being competitive.<p>[0]: <a href="https:&#x2F;&#x2F;newsroom.arm.com&#x2F;blog&#x2F;arm-nvidia-project-digits-high-performance-ai" rel="nofollow">https:&#x2F;&#x2F;newsroom.arm.com&#x2F;blog&#x2F;arm-nvidia-project-digits-high...</a></div><br/></div></div><div id="42619696" class="c"><input type="checkbox" id="c-42619696" checked=""/><div class="controls bullet"><span class="by">modeless</span><span>|</span><a href="#42619310">root</a><span>|</span><a href="#42619631">parent</a><span>|</span><a href="#42619746">prev</a><span>|</span><a href="#42619451">next</a><span>|</span><label class="collapse" for="c-42619696">[-]</label><label class="expand" for="c-42619696">[8 more]</label></div><br/><div class="children"><div class="content">AI work happens predominantly on the GPU, not the CPU. This GPU with CUDA will run rings around M4 with MLX. And with <i>much</i> more RAM than you can get in a Mac for $3k.<p>A lot of people have been justifying their Mac Studio or Mac Pro purchases by the potential for running large AI models locally. Project Digits will be much better at that for cheaper. Maybe it won&#x27;t run compile Chromium as fast, but that&#x27;s not what it&#x27;s for.</div><br/><div id="42620510" class="c"><input type="checkbox" id="c-42620510" checked=""/><div class="controls bullet"><span class="by">gardnr</span><span>|</span><a href="#42619310">root</a><span>|</span><a href="#42619696">parent</a><span>|</span><a href="#42619789">next</a><span>|</span><label class="collapse" for="c-42620510">[-]</label><label class="expand" for="c-42620510">[1 more]</label></div><br/><div class="children"><div class="content">Remember: inference is memory bound.<p><a href="https:&#x2F;&#x2F;www.databricks.com&#x2F;blog&#x2F;llm-inference-performance-engineering-best-practices" rel="nofollow">https:&#x2F;&#x2F;www.databricks.com&#x2F;blog&#x2F;llm-inference-performance-en...</a></div><br/></div></div><div id="42619789" class="c"><input type="checkbox" id="c-42619789" checked=""/><div class="controls bullet"><span class="by">sliken</span><span>|</span><a href="#42619310">root</a><span>|</span><a href="#42619696">parent</a><span>|</span><a href="#42620510">prev</a><span>|</span><a href="#42619451">next</a><span>|</span><label class="collapse" for="c-42619789">[-]</label><label class="expand" for="c-42619789">[6 more]</label></div><br/><div class="children"><div class="content">The quotes I&#x27;ve seen mention the maximum config (128GB ram and 4TB of storage) and the minimum price.  Nothing saying $3k for 128GB ram and 4TB of storage.  I hope I&#x27;m wrong, but I&#x27;m betting the max price is at least twice the minimum price.</div><br/><div id="42619894" class="c"><input type="checkbox" id="c-42619894" checked=""/><div class="controls bullet"><span class="by">gnabgib</span><span>|</span><a href="#42619310">root</a><span>|</span><a href="#42619789">parent</a><span>|</span><a href="#42620296">next</a><span>|</span><label class="collapse" for="c-42619894">[-]</label><label class="expand" for="c-42619894">[1 more]</label></div><br/><div class="children"><div class="content">NVidia says 128GB ram at $3k[0], it looks like the 4TB storage might be variable (and possibly CPU or GPU cores?).  This article says 128GB too.. but used <i>up to</i> twice in a row with different meanings which doesn&#x27;t help.<p>[0]: <a href="https:&#x2F;&#x2F;nvidianews.nvidia.com&#x2F;news&#x2F;nvidia-puts-grace-blackwell-on-every-desk-and-at-every-ai-developers-fingertips" rel="nofollow">https:&#x2F;&#x2F;nvidianews.nvidia.com&#x2F;news&#x2F;nvidia-puts-grace-blackwe...</a></div><br/></div></div><div id="42620296" class="c"><input type="checkbox" id="c-42620296" checked=""/><div class="controls bullet"><span class="by">p_l</span><span>|</span><a href="#42619310">root</a><span>|</span><a href="#42619789">parent</a><span>|</span><a href="#42619894">prev</a><span>|</span><a href="#42619451">next</a><span>|</span><label class="collapse" for="c-42620296">[-]</label><label class="expand" for="c-42620296">[4 more]</label></div><br/><div class="children"><div class="content">It&#x27;s GB200 in desktop compatible enclosure, the RAM is fixed, the SSDs are not, the network ports are fixed too.</div><br/><div id="42620613" class="c"><input type="checkbox" id="c-42620613" checked=""/><div class="controls bullet"><span class="by">KeplerBoy</span><span>|</span><a href="#42619310">root</a><span>|</span><a href="#42620296">parent</a><span>|</span><a href="#42620490">next</a><span>|</span><label class="collapse" for="c-42620613">[-]</label><label class="expand" for="c-42620613">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s GB10 a much cut down version to fit the price point, and space, weight and power requirements.</div><br/></div></div><div id="42620490" class="c"><input type="checkbox" id="c-42620490" checked=""/><div class="controls bullet"><span class="by">sliken</span><span>|</span><a href="#42619310">root</a><span>|</span><a href="#42620296">parent</a><span>|</span><a href="#42620613">prev</a><span>|</span><a href="#42620452">next</a><span>|</span><label class="collapse" for="c-42620490">[-]</label><label class="expand" for="c-42620490">[1 more]</label></div><br/><div class="children"><div class="content">The CPU is apparently the result of a &quot;secret&quot; project that wasn&#x27;t on published roadmaps.  It&#x27;s called the GB110.   So maybe they will offer differently binned CPU&#x2F;GPUs with a different fraction of cores disabled and you can pick your SSD.</div><br/></div></div><div id="42620452" class="c"><input type="checkbox" id="c-42620452" checked=""/><div class="controls bullet"><span class="by">dagmx</span><span>|</span><a href="#42619310">root</a><span>|</span><a href="#42620296">parent</a><span>|</span><a href="#42620490">prev</a><span>|</span><a href="#42619451">next</a><span>|</span><label class="collapse" for="c-42620452">[-]</label><label class="expand" for="c-42620452">[1 more]</label></div><br/><div class="children"><div class="content">It’s most definitely not a GB200 in a desktop enclosure.<p>The processor is using completely different cores, and the GPU is somewhere around a 5070 for TOPs.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="42619451" class="c"><input type="checkbox" id="c-42619451" checked=""/><div class="controls bullet"><span class="by">tkanarsky</span><span>|</span><a href="#42619310">prev</a><span>|</span><a href="#42620584">next</a><span>|</span><label class="collapse" for="c-42619451">[-]</label><label class="expand" for="c-42619451">[1 more]</label></div><br/><div class="children"><div class="content">This seems surprisingly cheap for what you get! Excited to see what people cook with this</div><br/></div></div><div id="42620584" class="c"><input type="checkbox" id="c-42620584" checked=""/><div class="controls bullet"><span class="by">sam_goody</span><span>|</span><a href="#42619451">prev</a><span>|</span><a href="#42619690">next</a><span>|</span><label class="collapse" for="c-42620584">[-]</label><label class="expand" for="c-42620584">[1 more]</label></div><br/><div class="children"><div class="content">So, a company that doesn&#x27;t feel like sharing all their secret sauce with Anthropic can run DeepSeek Coder on three of these for $9K, and it should be be more or less the same experience.<p>Do I understand that right? It seems way to cheap.</div><br/></div></div><div id="42619690" class="c"><input type="checkbox" id="c-42619690" checked=""/><div class="controls bullet"><span class="by">ttul</span><span>|</span><a href="#42620584">prev</a><span>|</span><a href="#42619304">next</a><span>|</span><label class="collapse" for="c-42619690">[-]</label><label class="expand" for="c-42619690">[1 more]</label></div><br/><div class="children"><div class="content">I bought a Lamba Labs workstation with a 4090 last year. I guess I’m buying one of these things now because the Lambda workstation just became a relic…</div><br/></div></div><div id="42619304" class="c"><input type="checkbox" id="c-42619304" checked=""/><div class="controls bullet"><span class="by">macawfish</span><span>|</span><a href="#42619690">prev</a><span>|</span><a href="#42619923">next</a><span>|</span><label class="collapse" for="c-42619304">[-]</label><label class="expand" for="c-42619304">[1 more]</label></div><br/><div class="children"><div class="content">Is this going to make up for the lack of VRAM in the new consumer GPUs?</div><br/></div></div><div id="42619923" class="c"><input type="checkbox" id="c-42619923" checked=""/><div class="controls bullet"><span class="by">friend_Fernando</span><span>|</span><a href="#42619304">prev</a><span>|</span><a href="#42619850">next</a><span>|</span><label class="collapse" for="c-42619923">[-]</label><label class="expand" for="c-42619923">[1 more]</label></div><br/><div class="children"><div class="content">Little by little, we&#x27;re getting an answer to the question: &quot;What kind of investment does an outrageous influx of capitalization spur?&quot; One might think it would be an AI silicon-moat, and it might yet be some of that.<p>But it&#x27;s clear that everyone&#x27;s favorite goal is keretsuification. If you&#x27;re looking for abnormal profits, you can&#x27;t do better than to add a letter to FAANG. Nvidia already got into the cloud business, and now it&#x27;s making workstations.<p>The era of specialists doing specialist things is not really behind us. They&#x27;re just not making automatic money, nor most of it. Nvidia excelled in that pool, but it too can&#x27;t wait to leave it. It knows it can always fail as a specialist, but not as a kereitsu.</div><br/></div></div><div id="42619850" class="c"><input type="checkbox" id="c-42619850" checked=""/><div class="controls bullet"><span class="by">palmfacehn</span><span>|</span><a href="#42619923">prev</a><span>|</span><a href="#42619359">next</a><span>|</span><label class="collapse" for="c-42619850">[-]</label><label class="expand" for="c-42619850">[2 more]</label></div><br/><div class="children"><div class="content">Would love to see something like this with an ATX form factor, socketed GPU, socketed GPU and non-soldered RAM.</div><br/><div id="42620625" class="c"><input type="checkbox" id="c-42620625" checked=""/><div class="controls bullet"><span class="by">blackoil</span><span>|</span><a href="#42619850">parent</a><span>|</span><a href="#42619359">next</a><span>|</span><label class="collapse" for="c-42620625">[-]</label><label class="expand" for="c-42620625">[1 more]</label></div><br/><div class="children"><div class="content">Isn&#x27;t that just a regular PC with one or more 5090 or equivalent workstation GPU?</div><br/></div></div></div></div><div id="42619359" class="c"><input type="checkbox" id="c-42619359" checked=""/><div class="controls bullet"><span class="by">rafaelmn</span><span>|</span><a href="#42619850">prev</a><span>|</span><a href="#42620304">next</a><span>|</span><label class="collapse" for="c-42619359">[-]</label><label class="expand" for="c-42619359">[2 more]</label></div><br/><div class="children"><div class="content">Feels like data center AI HW demand peak is over now that these things are trickling down to consumers and they are diversifying customers. Also going lower than expected on gaming HW, seems like they have enough fab capacity.</div><br/><div id="42619518" class="c"><input type="checkbox" id="c-42619518" checked=""/><div class="controls bullet"><span class="by">bushbaba</span><span>|</span><a href="#42619359">parent</a><span>|</span><a href="#42620304">next</a><span>|</span><label class="collapse" for="c-42619518">[-]</label><label class="expand" for="c-42619518">[1 more]</label></div><br/><div class="children"><div class="content">Their DC sales likely aren’t growing at the rates prior seen. Law of big numbers. They gotta diversify to satisfy growth &amp; profit expectations</div><br/></div></div></div></div><div id="42620304" class="c"><input type="checkbox" id="c-42620304" checked=""/><div class="controls bullet"><span class="by">poisonborz</span><span>|</span><a href="#42619359">prev</a><span>|</span><a href="#42619384">next</a><span>|</span><label class="collapse" for="c-42620304">[-]</label><label class="expand" for="c-42620304">[2 more]</label></div><br/><div class="children"><div class="content">Welcome to tomorrow&#x27;s &quot;personal&quot; computer, a single unmodifiable SoC with closed source software stack.</div><br/><div id="42620633" class="c"><input type="checkbox" id="c-42620633" checked=""/><div class="controls bullet"><span class="by">blackoil</span><span>|</span><a href="#42620304">parent</a><span>|</span><a href="#42619384">next</a><span>|</span><label class="collapse" for="c-42620633">[-]</label><label class="expand" for="c-42620633">[1 more]</label></div><br/><div class="children"><div class="content">That is the PC of today and yesterday and yesteryears.</div><br/></div></div></div></div><div id="42619384" class="c"><input type="checkbox" id="c-42619384" checked=""/><div class="controls bullet"><span class="by">gigel82</span><span>|</span><a href="#42620304">prev</a><span>|</span><a href="#42620113">next</a><span>|</span><label class="collapse" for="c-42619384">[-]</label><label class="expand" for="c-42619384">[2 more]</label></div><br/><div class="children"><div class="content">What we need is more diversity in the space. Something between the Jetson and this thing, at under $1000 that can run in a LAN to do LLM, STT, TTS, etc. would be an awesome (if niche) device to enable truly local &#x2F; private AI scenarios for privacy-sensitive folks.</div><br/></div></div><div id="42620113" class="c"><input type="checkbox" id="c-42620113" checked=""/><div class="controls bullet"><span class="by">bobheadmaker</span><span>|</span><a href="#42619384">prev</a><span>|</span><a href="#42619842">next</a><span>|</span><label class="collapse" for="c-42620113">[-]</label><label class="expand" for="c-42620113">[1 more]</label></div><br/><div class="children"><div class="content">Pricing seems off!</div><br/></div></div><div id="42619842" class="c"><input type="checkbox" id="c-42619842" checked=""/><div class="controls bullet"><span class="by">YetAnotherNick</span><span>|</span><a href="#42620113">prev</a><span>|</span><a href="#42619561">next</a><span>|</span><label class="collapse" for="c-42619842">[-]</label><label class="expand" for="c-42619842">[2 more]</label></div><br/><div class="children"><div class="content">I highly doubt it&#x27;s half or ever quarter of GB200, unless they have hidden water cooling or something outside. GB200 is 1200 Watts. Digits doesn&#x27;t look like it would be above 200W, and cooling 200W would be impressive.</div><br/><div id="42620638" class="c"><input type="checkbox" id="c-42620638" checked=""/><div class="controls bullet"><span class="by">blackoil</span><span>|</span><a href="#42619842">parent</a><span>|</span><a href="#42619561">next</a><span>|</span><label class="collapse" for="c-42620638">[-]</label><label class="expand" for="c-42620638">[1 more]</label></div><br/><div class="children"><div class="content">GB200 is ~USD 60,000&#x2F;. So, it should be like 20th of that.</div><br/></div></div></div></div><div id="42619561" class="c"><input type="checkbox" id="c-42619561" checked=""/><div class="controls bullet"><span class="by">anigbrowl</span><span>|</span><a href="#42619842">prev</a><span>|</span><a href="#42619782">next</a><span>|</span><label class="collapse" for="c-42619561">[-]</label><label class="expand" for="c-42619561">[2 more]</label></div><br/><div class="children"><div class="content">Honestly surprised at how affordable this is, I was expecting $5-6k as I scanned the opening paragraphs.</div><br/><div id="42619663" class="c"><input type="checkbox" id="c-42619663" checked=""/><div class="controls bullet"><span class="by">sliken</span><span>|</span><a href="#42619561">parent</a><span>|</span><a href="#42619782">next</a><span>|</span><label class="collapse" for="c-42619663">[-]</label><label class="expand" for="c-42619663">[1 more]</label></div><br/><div class="children"><div class="content">Might well be, from what I can tell the price &quot;starts at $3k&quot;, which might well be config&#x27;d like the minimum mac studio for RAM and storage.  Mac studios easily hit $5k-$6k or more.</div><br/></div></div></div></div><div id="42619782" class="c"><input type="checkbox" id="c-42619782" checked=""/><div class="controls bullet"><span class="by">trhway</span><span>|</span><a href="#42619561">prev</a><span>|</span><a href="#42619474">next</a><span>|</span><label class="collapse" for="c-42619782">[-]</label><label class="expand" for="c-42619782">[3 more]</label></div><br/><div class="children"><div class="content">$3000? The GB10 inside it seems to be a half of GB200 which is like $60K. One can wonder about availability at those $3K.</div><br/><div id="42620506" class="c"><input type="checkbox" id="c-42620506" checked=""/><div class="controls bullet"><span class="by">sliken</span><span>|</span><a href="#42619782">parent</a><span>|</span><a href="#42619946">next</a><span>|</span><label class="collapse" for="c-42620506">[-]</label><label class="expand" for="c-42620506">[1 more]</label></div><br/><div class="children"><div class="content">TheRegister mentions:<p><pre><code>   Specs we’ve seen suggest the GB10 features a 20-core Grace CPU and a GPU that packs manages a 40th the performance of the twin Blackwell GPUs used in Nvidia’s GB200 AI server.</code></pre></div><br/></div></div><div id="42619946" class="c"><input type="checkbox" id="c-42619946" checked=""/><div class="controls bullet"><span class="by">kcb</span><span>|</span><a href="#42619782">parent</a><span>|</span><a href="#42620506">prev</a><span>|</span><a href="#42619474">next</a><span>|</span><label class="collapse" for="c-42619946">[-]</label><label class="expand" for="c-42619946">[1 more]</label></div><br/><div class="children"><div class="content">No way is the GPU half a GB200. I&#x27;d expect something much lower end and power conscious.<p>They mention 1 PFLOP for FP4, GB200 is 40 PFLOP.</div><br/></div></div></div></div><div id="42619474" class="c"><input type="checkbox" id="c-42619474" checked=""/><div class="controls bullet"><span class="by">giacomoforte</span><span>|</span><a href="#42619782">prev</a><span>|</span><a href="#42619265">next</a><span>|</span><label class="collapse" for="c-42619474">[-]</label><label class="expand" for="c-42619474">[5 more]</label></div><br/><div class="children"><div class="content">It costs the equivalent of 2 years of cloud GPU H100s at current prices.<p>Edit: Sorry fucked up my math. I wanted to do 40x52x4, $4&#x2F;hr being the cloud compute price but that us actually $8300, so it is actually equivalent to about 4.5 months of cloud compute. 40 hours because I presume that this will only be used for prototyping and debugging, i.e during office hours.</div><br/><div id="42619486" class="c"><input type="checkbox" id="c-42619486" checked=""/><div class="controls bullet"><span class="by">sabareesh</span><span>|</span><a href="#42619474">parent</a><span>|</span><a href="#42619265">next</a><span>|</span><label class="collapse" for="c-42619486">[-]</label><label class="expand" for="c-42619486">[4 more]</label></div><br/><div class="children"><div class="content">what are current h100 price ? lowest i have seen is only 0.99 per hour</div><br/><div id="42619521" class="c"><input type="checkbox" id="c-42619521" checked=""/><div class="controls bullet"><span class="by">billconan</span><span>|</span><a href="#42619474">root</a><span>|</span><a href="#42619486">parent</a><span>|</span><a href="#42619847">next</a><span>|</span><label class="collapse" for="c-42619521">[-]</label><label class="expand" for="c-42619521">[1 more]</label></div><br/><div class="children"><div class="content">and 2 years have 17520 hours.</div><br/></div></div><div id="42619847" class="c"><input type="checkbox" id="c-42619847" checked=""/><div class="controls bullet"><span class="by">YetAnotherNick</span><span>|</span><a href="#42619474">root</a><span>|</span><a href="#42619486">parent</a><span>|</span><a href="#42619521">prev</a><span>|</span><a href="#42619265">next</a><span>|</span><label class="collapse" for="c-42619847">[-]</label><label class="expand" for="c-42619847">[2 more]</label></div><br/><div class="children"><div class="content">Where can you find 99c&#x2F;hour? Cheapest I can find is double that.</div><br/><div id="42620457" class="c"><input type="checkbox" id="c-42620457" checked=""/><div class="controls bullet"><span class="by">saagarjha</span><span>|</span><a href="#42619474">root</a><span>|</span><a href="#42619847">parent</a><span>|</span><a href="#42619265">next</a><span>|</span><label class="collapse" for="c-42620457">[-]</label><label class="expand" for="c-42620457">[1 more]</label></div><br/><div class="children"><div class="content">Lambda has on-demand GH200 right now for $1.49. There might be a cheaper deal elsewhere for a contract.</div><br/></div></div></div></div></div></div></div></div><div id="42619265" class="c"><input type="checkbox" id="c-42619265" checked=""/><div class="controls bullet"><span class="by">The28thDuck</span><span>|</span><a href="#42619474">prev</a><span>|</span><a href="#42619681">next</a><span>|</span><label class="collapse" for="c-42619265">[-]</label><label class="expand" for="c-42619265">[2 more]</label></div><br/><div class="children"><div class="content">But can it mine Bitcoin?</div><br/><div id="42619625" class="c"><input type="checkbox" id="c-42619625" checked=""/><div class="controls bullet"><span class="by">deactivatedexp</span><span>|</span><a href="#42619265">parent</a><span>|</span><a href="#42619681">next</a><span>|</span><label class="collapse" for="c-42619625">[-]</label><label class="expand" for="c-42619625">[1 more]</label></div><br/><div class="children"><div class="content">it can fight better than kratos</div><br/></div></div></div></div><div id="42619681" class="c"><input type="checkbox" id="c-42619681" checked=""/><div class="controls bullet"><span class="by">rubatuga</span><span>|</span><a href="#42619265">prev</a><span>|</span><label class="collapse" for="c-42619681">[-]</label><label class="expand" for="c-42619681">[7 more]</label></div><br/><div class="children"><div class="content">Would consider at a lower price of $500 USD, way too expensive for what it brings.</div><br/><div id="42619697" class="c"><input type="checkbox" id="c-42619697" checked=""/><div class="controls bullet"><span class="by">lz400</span><span>|</span><a href="#42619681">parent</a><span>|</span><label class="collapse" for="c-42619697">[-]</label><label class="expand" for="c-42619697">[6 more]</label></div><br/><div class="children"><div class="content">I think it&#x27;s cheap at $3000. 128gb RAM, top of the line GPU capabilities, 4tb storage... it&#x27;s much better than what a top shelf mbp can do and much cheaper</div><br/><div id="42620463" class="c"><input type="checkbox" id="c-42620463" checked=""/><div class="controls bullet"><span class="by">saagarjha</span><span>|</span><a href="#42619681">root</a><span>|</span><a href="#42619697">parent</a><span>|</span><a href="#42620063">next</a><span>|</span><label class="collapse" for="c-42620463">[-]</label><label class="expand" for="c-42620463">[2 more]</label></div><br/><div class="children"><div class="content">This definitely loses on CPU performance.</div><br/><div id="42620520" class="c"><input type="checkbox" id="c-42620520" checked=""/><div class="controls bullet"><span class="by">sliken</span><span>|</span><a href="#42619681">root</a><span>|</span><a href="#42620463">parent</a><span>|</span><a href="#42620063">next</a><span>|</span><label class="collapse" for="c-42620520">[-]</label><label class="expand" for="c-42620520">[1 more]</label></div><br/><div class="children"><div class="content">I originally thought so, since the previous Grace CPUs used the neoverse N2, which loses to Apple&#x27;s M4 cores.<p>However apparently 10 of the cores are the Cortex-X925 CPUs, which are a serious upgrade.  Basically 10 performance cores and 10 efficiency cores that should be pretty competitive with any current apple CPU.</div><br/></div></div></div></div><div id="42620063" class="c"><input type="checkbox" id="c-42620063" checked=""/><div class="controls bullet"><span class="by">sergiotapia</span><span>|</span><a href="#42619681">root</a><span>|</span><a href="#42619697">parent</a><span>|</span><a href="#42620463">prev</a><span>|</span><a href="#42620232">next</a><span>|</span><label class="collapse" for="c-42620063">[-]</label><label class="expand" for="c-42620063">[2 more]</label></div><br/><div class="children"><div class="content">correct, I just spent $4k on an &quot;AI&quot; machine to do stuff. 96GB ram, ryzen 9 9950x 16 core, 4TB nvme, 24tb hdd, rtx 4090.<p>If this thing was available six months ago I would have bought it instead!</div><br/><div id="42620252" class="c"><input type="checkbox" id="c-42620252" checked=""/><div class="controls bullet"><span class="by">Mistletoe</span><span>|</span><a href="#42619681">root</a><span>|</span><a href="#42620063">parent</a><span>|</span><a href="#42620232">next</a><span>|</span><label class="collapse" for="c-42620252">[-]</label><label class="expand" for="c-42620252">[1 more]</label></div><br/><div class="children"><div class="content">What do you do on it?</div><br/></div></div></div></div><div id="42620232" class="c"><input type="checkbox" id="c-42620232" checked=""/><div class="controls bullet"><span class="by">lispm</span><span>|</span><a href="#42619681">root</a><span>|</span><a href="#42619697">parent</a><span>|</span><a href="#42620063">prev</a><span>|</span><label class="collapse" for="c-42620232">[-]</label><label class="expand" for="c-42620232">[1 more]</label></div><br/><div class="children"><div class="content">upto 4tb storage</div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>