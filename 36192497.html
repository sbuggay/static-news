<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1685955681113" as="style"/><link rel="stylesheet" href="styles.css?v=1685955681113"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://meta.stackexchange.com/questions/389811/moderation-strike-stack-overflow-inc-cannot-consistently-ignore-mistreat-an">Moderation strike</a> <span class="domain">(<a href="https://meta.stackexchange.com">meta.stackexchange.com</a>)</span></div><div class="subtext"><span>mwint</span> | <span>99 comments</span></div><br/><div><div id="36192715" class="c"><input type="checkbox" id="c-36192715" checked=""/><div class="controls bullet"><span class="by">fabian2k</span><span>|</span><a href="#36192739">next</a><span>|</span><label class="collapse" for="c-36192715">[-]</label><label class="expand" for="c-36192715">[7 more]</label></div><br/><div class="children"><div class="content">The Open Letter linked in this post is probably a better explanation for most people:<p><a href="https:&#x2F;&#x2F;openletter.mousetail.nl&#x2F;" rel="nofollow">https:&#x2F;&#x2F;openletter.mousetail.nl&#x2F;</a><p>The meta post linked here is targeted more towards an internal audience of active users.<p>There are two big parts to this issue, one is that the company is overriding the decisions of the communities and essentially preventing them from moderating AI-authored content entirely. The second one is the way this was done, with no feedback at all, extremely quickly, with vast differences between the public policy and what they told the moderators.</div><br/><div id="36193064" class="c"><input type="checkbox" id="c-36193064" checked=""/><div class="controls bullet"><span class="by">USB5</span><span>|</span><a href="#36192715">parent</a><span>|</span><a href="#36193290">next</a><span>|</span><label class="collapse" for="c-36193064">[-]</label><label class="expand" for="c-36193064">[1 more]</label></div><br/><div class="children"><div class="content">Surprisingly brief and well-written letter. I hope they overcome.</div><br/></div></div><div id="36193290" class="c"><input type="checkbox" id="c-36193290" checked=""/><div class="controls bullet"><span class="by">mellosouls</span><span>|</span><a href="#36192715">parent</a><span>|</span><a href="#36193064">prev</a><span>|</span><a href="#36192739">next</a><span>|</span><label class="collapse" for="c-36193290">[-]</label><label class="expand" for="c-36193290">[5 more]</label></div><br/><div class="children"><div class="content"><i>We deeply believe in the core mission of the Stack Exchange network: to provide a repository of high-quality information in the form of questions and answers, and the recent actions taken by Stack Overflow, Inc. are directly harmful to that goal</i><p>Unfortunately, this seems a naive take; the core mission of the network is to serve the commercial purposes of the business.</div><br/><div id="36193930" class="c"><input type="checkbox" id="c-36193930" checked=""/><div class="controls bullet"><span class="by">2-718-281-828</span><span>|</span><a href="#36192715">root</a><span>|</span><a href="#36193290">parent</a><span>|</span><a href="#36193944">next</a><span>|</span><label class="collapse" for="c-36193930">[-]</label><label class="expand" for="c-36193930">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s a very snarky way to put it. It&#x27;s very well within the rights of the SE community to express their perspective and demand this to be respected. That&#x27;s not naive. Naive would be assuming this is guaranteed to work. But if they actually implement a moderation strike then SE is going to fall apart sooner than later. So, it&#x27;s not like they have no leverage.</div><br/></div></div><div id="36193944" class="c"><input type="checkbox" id="c-36193944" checked=""/><div class="controls bullet"><span class="by">leroman</span><span>|</span><a href="#36192715">root</a><span>|</span><a href="#36193290">parent</a><span>|</span><a href="#36193930">prev</a><span>|</span><a href="#36193336">next</a><span>|</span><label class="collapse" for="c-36193944">[-]</label><label class="expand" for="c-36193944">[1 more]</label></div><br/><div class="children"><div class="content">I think this is a naive (or cynical?) take on a business, its also their goal to hire and retain both employees and customers.<p>If the latter is done based on a lie, then you cant align your “commercial purpose” and people who fulfill it..</div><br/></div></div><div id="36193336" class="c"><input type="checkbox" id="c-36193336" checked=""/><div class="controls bullet"><span class="by">pbhjpbhj</span><span>|</span><a href="#36192715">root</a><span>|</span><a href="#36193290">parent</a><span>|</span><a href="#36193944">prev</a><span>|</span><a href="#36192739">next</a><span>|</span><label class="collapse" for="c-36193336">[-]</label><label class="expand" for="c-36193336">[2 more]</label></div><br/><div class="children"><div class="content">How about a principled and optimistic take? And&#x2F;Or, the basis under which moderators have been offering their services.<p>We may have been duped by a company&#x27;s lies, of course. Seems like they&#x27;ve committed  a mix of copyright infringement and fraud in that case.</div><br/><div id="36193474" class="c"><input type="checkbox" id="c-36193474" checked=""/><div class="controls bullet"><span class="by">mellosouls</span><span>|</span><a href="#36192715">root</a><span>|</span><a href="#36193336">parent</a><span>|</span><a href="#36192739">next</a><span>|</span><label class="collapse" for="c-36193474">[-]</label><label class="expand" for="c-36193474">[1 more]</label></div><br/><div class="children"><div class="content">Like I said, &quot;unfortunately&quot;.</div><br/></div></div></div></div></div></div></div></div><div id="36192739" class="c"><input type="checkbox" id="c-36192739" checked=""/><div class="controls bullet"><span class="by">notatoad</span><span>|</span><a href="#36192715">prev</a><span>|</span><a href="#36193428">next</a><span>|</span><label class="collapse" for="c-36192739">[-]</label><label class="expand" for="c-36192739">[27 more]</label></div><br/><div class="children"><div class="content">So if I’m understanding, stack allowed moderators to issue 30-day bans without following normal escalation policies, if a moderator had any reason to suspect that a user posted AI-generated content.<p>The new policy is that you have to follow all the normal policies for all the posts, you don’t get to pull out the banhammer just for a suspicion of AI.  And the moderators are striking because their want to keep the power to issue uncontestable 30-day bans whenever they feel like it?</div><br/><div id="36192776" class="c"><input type="checkbox" id="c-36192776" checked=""/><div class="controls bullet"><span class="by">fabian2k</span><span>|</span><a href="#36192739">parent</a><span>|</span><a href="#36193428">next</a><span>|</span><label class="collapse" for="c-36192776">[-]</label><label class="expand" for="c-36192776">[26 more]</label></div><br/><div class="children"><div class="content">No, the new policy means that in almost all cases you cannot moderate content you consider AI-authored at all. This means moderators cannot delete those posts nor suspend the users for this specific reason.<p>The result is pretty much that AI-generated content is essentially allowed as it cannot be effectively moderated. Even though many sites still have an official policy that disallows it.<p>Disclaimer: I&#x27;m a mod on a small SE site, though I have not acted as a mod on any AI-generated content.</div><br/><div id="36193075" class="c"><input type="checkbox" id="c-36193075" checked=""/><div class="controls bullet"><span class="by">Zetice</span><span>|</span><a href="#36192739">root</a><span>|</span><a href="#36192776">parent</a><span>|</span><a href="#36192879">next</a><span>|</span><label class="collapse" for="c-36193075">[-]</label><label class="expand" for="c-36193075">[8 more]</label></div><br/><div class="children"><div class="content">The fact something is or isn&#x27;t AI doesn&#x27;t require independent moderation procedures.  Either the content has an answer to the question or it doesn&#x27;t.</div><br/><div id="36193209" class="c"><input type="checkbox" id="c-36193209" checked=""/><div class="controls bullet"><span class="by">wtallis</span><span>|</span><a href="#36192739">root</a><span>|</span><a href="#36193075">parent</a><span>|</span><a href="#36193217">next</a><span>|</span><label class="collapse" for="c-36193209">[-]</label><label class="expand" for="c-36193209">[2 more]</label></div><br/><div class="children"><div class="content">If something doesn&#x27;t answer the question, then it should be removed by moderators. But it shouldn&#x27;t stop there: junk generated by AI is going to be mass-produced, and anyone posting incorrect AI-generated answers is probably going to be a repeat offender. Taking proactive action against such users who are operating so far outside the purpose of the site is very likely necessary to have any hope of maintaining a reasonable signal to noise ratio.</div><br/><div id="36193896" class="c"><input type="checkbox" id="c-36193896" checked=""/><div class="controls bullet"><span class="by">omegabravo</span><span>|</span><a href="#36192739">root</a><span>|</span><a href="#36193209">parent</a><span>|</span><a href="#36193217">next</a><span>|</span><label class="collapse" for="c-36193896">[-]</label><label class="expand" for="c-36193896">[1 more]</label></div><br/><div class="children"><div class="content">probably, or is?<p>The offence here is spamming, AI is orthogonal.  Users spamming should be given a timeout.</div><br/></div></div></div></div><div id="36193217" class="c"><input type="checkbox" id="c-36193217" checked=""/><div class="controls bullet"><span class="by">rtpg</span><span>|</span><a href="#36192739">root</a><span>|</span><a href="#36193075">parent</a><span>|</span><a href="#36193209">prev</a><span>|</span><a href="#36193431">next</a><span>|</span><label class="collapse" for="c-36193217">[-]</label><label class="expand" for="c-36193217">[1 more]</label></div><br/><div class="children"><div class="content">Incorrect answers are not what moderators are moderating. A super easy way to make answers that look right even if they are wrong, for people trying to game SO&#x27;s point system, is a perfect way for there to be just a huge amount of extra work for mods without ~any benefit.<p>There are definitely alternatives to the unilateral ban (Thinking about how, like, chess.com does bans based on people cheating), but saying &quot;AI content is qualitatively no different&quot; ignores the bigger ecosystem problem from having the average answer quality simply go down</div><br/></div></div><div id="36193431" class="c"><input type="checkbox" id="c-36193431" checked=""/><div class="controls bullet"><span class="by">pbhjpbhj</span><span>|</span><a href="#36192739">root</a><span>|</span><a href="#36193075">parent</a><span>|</span><a href="#36193217">prev</a><span>|</span><a href="#36193487">next</a><span>|</span><label class="collapse" for="c-36193431">[-]</label><label class="expand" for="c-36193431">[1 more]</label></div><br/><div class="children"><div class="content">The problem is that moderation does not necessarily check the solution. A moderator can&#x27;t acquire the specific version of hardware the questioner had, recreate the failure conditions, then test the solution. Instead, a moderator looks to see if an answer seems reasonable and fits the correct syntax and site-specific rules.<p>LLMs are great at producing bullshit that looks convincing.<p>Essentially, one has to trust responders to provide answers to some extent. Untrustworthy responders can use generators to bullshit their way into acquiring trust.</div><br/></div></div><div id="36193487" class="c"><input type="checkbox" id="c-36193487" checked=""/><div class="controls bullet"><span class="by">paganel</span><span>|</span><a href="#36192739">root</a><span>|</span><a href="#36193075">parent</a><span>|</span><a href="#36193431">prev</a><span>|</span><a href="#36193363">next</a><span>|</span><label class="collapse" for="c-36193487">[-]</label><label class="expand" for="c-36193487">[1 more]</label></div><br/><div class="children"><div class="content">Because AI doesn&#x27;t answer the question, there&#x27;s nothing &quot;volitional&quot; in it, it&#x27;s just a (computationally smart) rehash of past answers, hoping that it will all fit together somehow.</div><br/></div></div><div id="36193363" class="c"><input type="checkbox" id="c-36193363" checked=""/><div class="controls bullet"><span class="by">ohgodplsno</span><span>|</span><a href="#36192739">root</a><span>|</span><a href="#36193075">parent</a><span>|</span><a href="#36193487">prev</a><span>|</span><a href="#36193203">next</a><span>|</span><label class="collapse" for="c-36193363">[-]</label><label class="expand" for="c-36193363">[1 more]</label></div><br/><div class="children"><div class="content">Taking aside the fact that the AI generated answers are awfully wrong most of the time, this line of thinking also leads to an absolutely dreadful state of internet where everything is AI generated crap. This is made worse by the fact that StackOverflow has points, badges and everything. People buy and sell stars on github to increase their chances of being hired somewhere. People absolutely will game the shit out of StackOverflow, not caring for a single second if it actually makes it a better place if it means they get shiny badges and get to put &quot;top commenter on the C# subject on SO (588100 points)&quot; on their resume.</div><br/></div></div><div id="36193203" class="c"><input type="checkbox" id="c-36193203" checked=""/><div class="controls bullet"><span class="by">fzeroracer</span><span>|</span><a href="#36192739">root</a><span>|</span><a href="#36193075">parent</a><span>|</span><a href="#36193363">prev</a><span>|</span><a href="#36192879">next</a><span>|</span><label class="collapse" for="c-36193203">[-]</label><label class="expand" for="c-36193203">[1 more]</label></div><br/><div class="children"><div class="content">If that&#x27;s your base criteria, why not remove humans from the equation entirely and just turn Stack Overflow into purely AI driven? It doesn&#x27;t matter if the answer is correct, only the speed and formatting of the answer.</div><br/></div></div></div></div><div id="36192879" class="c"><input type="checkbox" id="c-36192879" checked=""/><div class="controls bullet"><span class="by">LewisVerstappen</span><span>|</span><a href="#36192739">root</a><span>|</span><a href="#36192776">parent</a><span>|</span><a href="#36193075">prev</a><span>|</span><a href="#36192962">next</a><span>|</span><label class="collapse" for="c-36192879">[-]</label><label class="expand" for="c-36192879">[15 more]</label></div><br/><div class="children"><div class="content">How do you know if content is AI generated?<p>If mods could decree a piece of content as AI generated (and delete it) willy nilly, then that would be far worse IMO.</div><br/><div id="36192902" class="c"><input type="checkbox" id="c-36192902" checked=""/><div class="controls bullet"><span class="by">mwint</span><span>|</span><a href="#36192739">root</a><span>|</span><a href="#36192879">parent</a><span>|</span><a href="#36192911">next</a><span>|</span><label class="collapse" for="c-36192902">[-]</label><label class="expand" for="c-36192902">[6 more]</label></div><br/><div class="children"><div class="content">As a common example, you see someone who asks a question in the format:<p>“helo plz can help w cod, is broke has error”<p>And then the next day posts four answers in perfect English to four different topics, with that GPT “vibe”.<p>You can’t reliably detect generated content in a vacuum, but Stack Overflow is a very metadata-rich environment for moderators.</div><br/><div id="36193250" class="c"><input type="checkbox" id="c-36193250" checked=""/><div class="controls bullet"><span class="by">cja</span><span>|</span><a href="#36192739">root</a><span>|</span><a href="#36192902">parent</a><span>|</span><a href="#36192911">next</a><span>|</span><label class="collapse" for="c-36193250">[-]</label><label class="expand" for="c-36193250">[5 more]</label></div><br/><div class="children"><div class="content">As a user of SO, etc. I don&#x27;t care how they wrote the answer. Is it a good answer? Does it help me? That&#x27;s what I&#x27;m interested in.<p>Why censor good answers?</div><br/><div id="36193305" class="c"><input type="checkbox" id="c-36193305" checked=""/><div class="controls bullet"><span class="by">minitech</span><span>|</span><a href="#36192739">root</a><span>|</span><a href="#36193250">parent</a><span>|</span><a href="#36193451">next</a><span>|</span><label class="collapse" for="c-36193305">[-]</label><label class="expand" for="c-36193305">[3 more]</label></div><br/><div class="children"><div class="content">They’re usually not good answers, and they’re subject to the bullshit asymmetry principle.</div><br/><div id="36193556" class="c"><input type="checkbox" id="c-36193556" checked=""/><div class="controls bullet"><span class="by">Marazan</span><span>|</span><a href="#36192739">root</a><span>|</span><a href="#36193305">parent</a><span>|</span><a href="#36193451">next</a><span>|</span><label class="collapse" for="c-36193556">[-]</label><label class="expand" for="c-36193556">[2 more]</label></div><br/><div class="children"><div class="content">This is a vital comment that people need to understand.<p>It is _effort_ to moderate content, to read answers and see if they are legitimate. It is almost zero effort to chatgpt out &quot;answers&quot;.<p>The people providing the ChatGPT answers _do not care_ about them, they are only looking to pad their Rep.<p>It is an attack against the very core of the StackExchange system.</div><br/><div id="36193797" class="c"><input type="checkbox" id="c-36193797" checked=""/><div class="controls bullet"><span class="by">egeozcan</span><span>|</span><a href="#36192739">root</a><span>|</span><a href="#36193556">parent</a><span>|</span><a href="#36193451">next</a><span>|</span><label class="collapse" for="c-36193797">[-]</label><label class="expand" for="c-36193797">[1 more]</label></div><br/><div class="children"><div class="content">Why do people want to pad their rep? I have nearly 14K &quot;rep&quot; on SO, never had any positive effect on my career whatsoever.<p>Also, theoretically (never happened), if someone mentioned their exceptional SE profile on their resume or their cover letter, I&#x27;d for sure ask them some details from the topics they suggest to be experts on.<p>Will they also bring ChatGPT to the interview? That&#x27;d be fun to watch.</div><br/></div></div></div></div></div></div><div id="36193451" class="c"><input type="checkbox" id="c-36193451" checked=""/><div class="controls bullet"><span class="by">pbhjpbhj</span><span>|</span><a href="#36192739">root</a><span>|</span><a href="#36193250">parent</a><span>|</span><a href="#36193305">prev</a><span>|</span><a href="#36192911">next</a><span>|</span><label class="collapse" for="c-36193451">[-]</label><label class="expand" for="c-36193451">[1 more]</label></div><br/><div class="children"><div class="content">Why turn SO into a cache of LLM responses, why not just ask an LLM if you want answers and don&#x27;t care if those answers work?</div><br/></div></div></div></div></div></div><div id="36192911" class="c"><input type="checkbox" id="c-36192911" checked=""/><div class="controls bullet"><span class="by">fabian2k</span><span>|</span><a href="#36192739">root</a><span>|</span><a href="#36192879">parent</a><span>|</span><a href="#36192902">prev</a><span>|</span><a href="#36192962">next</a><span>|</span><label class="collapse" for="c-36192911">[-]</label><label class="expand" for="c-36192911">[8 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not the ideal person to ask here. But in general the output of specific AI tools like ChatGPT produces certain patterns that are quite noticeable. And you have to keep in mind that you usually have more than a single post available in these cases. The pattern of posting content is also a signal by itself.<p>So if e.g. a user posts a dozen long answers within 10 minutes, and they all have characteristics of ChatGPT, that would be a pretty good signal.</div><br/><div id="36193033" class="c"><input type="checkbox" id="c-36193033" checked=""/><div class="controls bullet"><span class="by">BasedAnon</span><span>|</span><a href="#36192739">root</a><span>|</span><a href="#36192911">parent</a><span>|</span><a href="#36192946">next</a><span>|</span><label class="collapse" for="c-36193033">[-]</label><label class="expand" for="c-36193033">[1 more]</label></div><br/><div class="children"><div class="content">&gt;But in general the output of specific AI tools like ChatGPT produces certain patterns that are quite noticeable<p>Only if you don&#x27;t prompt it to do otherwise.</div><br/></div></div><div id="36192946" class="c"><input type="checkbox" id="c-36192946" checked=""/><div class="controls bullet"><span class="by">LewisVerstappen</span><span>|</span><a href="#36192739">root</a><span>|</span><a href="#36192911">parent</a><span>|</span><a href="#36193033">prev</a><span>|</span><a href="#36192962">next</a><span>|</span><label class="collapse" for="c-36192946">[-]</label><label class="expand" for="c-36192946">[6 more]</label></div><br/><div class="children"><div class="content">&gt; So if e.g. a user posts a dozen long answers within 10 minutes, and they all have characteristics of ChatGPT, that would be a pretty good signal.<p>Ah yeah, the frequency of posts definitely makes sense.<p>&gt; output of specific AI tools like ChatGPT produces certain patterns that are quite noticeable<p>I would agree with you for gpt 3.5, but I don&#x27;t think this is the case for GPT-4 (I&#x27;ve spent several hundred hours using GPT-4 for various tasks - mainly related to coding &amp; learning random subjects).</div><br/><div id="36192953" class="c"><input type="checkbox" id="c-36192953" checked=""/><div class="controls bullet"><span class="by">fabian2k</span><span>|</span><a href="#36192739">root</a><span>|</span><a href="#36192946">parent</a><span>|</span><a href="#36192962">next</a><span>|</span><label class="collapse" for="c-36192953">[-]</label><label class="expand" for="c-36192953">[5 more]</label></div><br/><div class="children"><div class="content">In this case it certainly matters that ChatGPT is free. There are just many more people using that than paying for GPT-4 access.</div><br/><div id="36193070" class="c"><input type="checkbox" id="c-36193070" checked=""/><div class="controls bullet"><span class="by">pointlessone</span><span>|</span><a href="#36192739">root</a><span>|</span><a href="#36192953">parent</a><span>|</span><a href="#36192962">next</a><span>|</span><label class="collapse" for="c-36193070">[-]</label><label class="expand" for="c-36193070">[4 more]</label></div><br/><div class="children"><div class="content">Still, if the answer happens to be factually correct is it an issue?<p>Say, a person has an answer but English is not their native language and they manage to stir ChatGPT into writing a good answer. Would we prefer to have that posted instead of keeping a question hanging without an answer at all?<p>The only issue I can see with AI use is the rate of new content generation. Recent models are quite OK at giving a decent answer. SO is not a pinnacle of exceptionally well thought out answers from people either. There are great detailed and well sourced answers but more often then not you get an incomplete, outdated or even just plain wrong answers. Bespoke artisanal hand-crafted ethically sourced answers from fully organic free range humans that still lead to stack overflows and misalignments elements on webpages.</div><br/><div id="36193299" class="c"><input type="checkbox" id="c-36193299" checked=""/><div class="controls bullet"><span class="by">JdeBP</span><span>|</span><a href="#36192739">root</a><span>|</span><a href="#36193070">parent</a><span>|</span><a href="#36192962">next</a><span>|</span><label class="collapse" for="c-36193299">[-]</label><label class="expand" for="c-36193299">[3 more]</label></div><br/><div class="children"><div class="content">&quot;But what if they were correct answers?&quot; is largely an irrelevant hypothetical side-issue.<p>In practice, as reported in comments at <a href="https:&#x2F;&#x2F;meta.superuser.com&#x2F;q&#x2F;15021&#x2F;38062" rel="nofollow">https:&#x2F;&#x2F;meta.superuser.com&#x2F;q&#x2F;15021&#x2F;38062</a> and in many other Meta Q&amp;As, the answers that people are lazily machine-generating at high volume are far from correct; and the consequent upvotes that they garner reveal the unsurprising fact that there are a lot of people who vote in favour of things based upon writing style alone.</div><br/><div id="36193936" class="c"><input type="checkbox" id="c-36193936" checked=""/><div class="controls bullet"><span class="by">egeozcan</span><span>|</span><a href="#36192739">root</a><span>|</span><a href="#36193299">parent</a><span>|</span><a href="#36193465">next</a><span>|</span><label class="collapse" for="c-36193936">[-]</label><label class="expand" for="c-36193936">[1 more]</label></div><br/><div class="children"><div class="content">&gt;  &quot;But what if they were correct answers?&quot; is largely an irrelevant hypothetical side-issue.<p>Why? It becomes irrelevant if an account is spamming, sure delete everything regardless, but if I have a generated and correct answer in my otherwise pristine account?<p>What I&#x27;m trying to say is, the fact that some people use it to spam shouldn&#x27;t make it a simple ban condition. Otherwise that&#x27;d be banning emails to fight spam.</div><br/></div></div><div id="36193465" class="c"><input type="checkbox" id="c-36193465" checked=""/><div class="controls bullet"><span class="by">pointlessone</span><span>|</span><a href="#36192739">root</a><span>|</span><a href="#36193299">parent</a><span>|</span><a href="#36193936">prev</a><span>|</span><a href="#36192962">next</a><span>|</span><label class="collapse" for="c-36193465">[-]</label><label class="expand" for="c-36193465">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m sceptical of the premise. ChatGPT doesn&#x27;t watermark its answers. There&#x27;s no decent way to detect what is &quot;OpenAI garbage&quot; and what is not. One of the comments says: &quot;I detect such answers by the fact that they simply make no sense, although they seem well-written.&quot; I feel like this is a subject of survivorship bias. Would the commenter know a good ChatGPT answer from a human-produced answer?<p>A separate question is why there&#x27;s still a lot of crap questions&#x2F;answers on SO if quality is the goal? There&#x27;s a plenty of low-effort and incorrect answers made by real people that are not penalised in any way.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="36192962" class="c"><input type="checkbox" id="c-36192962" checked=""/><div class="controls bullet"><span class="by">notatoad</span><span>|</span><a href="#36192739">root</a><span>|</span><a href="#36192776">parent</a><span>|</span><a href="#36192879">prev</a><span>|</span><a href="#36193428">next</a><span>|</span><label class="collapse" for="c-36192962">[-]</label><label class="expand" for="c-36192962">[2 more]</label></div><br/><div class="children"><div class="content">but you can still moderate it for all the normal quality issues, it has to be on-topic and truthful and properly sourced.  it&#x27;s only if it&#x27;s a good answer, but you think it might have been ai generated that you can&#x27;t moderate it?<p>i&#x27;m really not seeing the problem here.</div><br/><div id="36193058" class="c"><input type="checkbox" id="c-36193058" checked=""/><div class="controls bullet"><span class="by">JdeBP</span><span>|</span><a href="#36192739">root</a><span>|</span><a href="#36192962">parent</a><span>|</span><a href="#36193428">next</a><span>|</span><label class="collapse" for="c-36193058">[-]</label><label class="expand" for="c-36193058">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s because you&#x27;ve entirely missed the part where the diamond moderators report that in private they were given far stricter rules than were let on in public, which disallowed this sort of weaselling.</div><br/></div></div></div></div></div></div></div></div><div id="36193428" class="c"><input type="checkbox" id="c-36193428" checked=""/><div class="controls bullet"><span class="by">dannyw</span><span>|</span><a href="#36192739">prev</a><span>|</span><a href="#36193925">next</a><span>|</span><label class="collapse" for="c-36193428">[-]</label><label class="expand" for="c-36193428">[1 more]</label></div><br/><div class="children"><div class="content">Management and business continue to treat volunteer moderators like their employees or contractors; which even in the some of the better examples in the corporate world, can be mildly abusive as people need to eat and have families to feed.<p>You can&#x27;t treat volunteers like that. You have to keep them happy. You have to treat them with respect. You&#x27;re not paying them for their free labour.</div><br/></div></div><div id="36193925" class="c"><input type="checkbox" id="c-36193925" checked=""/><div class="controls bullet"><span class="by">culebron21</span><span>|</span><a href="#36193428">prev</a><span>|</span><a href="#36193476">next</a><span>|</span><label class="collapse" for="c-36193925">[-]</label><label class="expand" for="c-36193925">[1 more]</label></div><br/><div class="children"><div class="content">I agree with the statement that AI-generated content is garbage. But having seen moderation on SO turn into gatekeeping in the last ~7 years, I start suspecting this is a case of fight for being gatekeeper. I don&#x27;t trust the mods that they did conduct anti-AI policy the right way -- I suspect they could overdo it very easily. With no sane ways for users to appeal. Current state of moderation leaves me no desire to contritube to SO -- neither via questions&#x2F;answers, nor via using moderation tools (I can make edits and review answers or edits of others).<p>Similar situation with moderation took hold in Wikipedia back in the 2000s, when it became only up to them whether a paragraph is &quot;neutral&quot; or &quot;an opinion&quot; and must be deleted (e.g. some pages have pieces saying &quot;it&#x27;s a common misconception that ___&quot;, but in some pages they got deleted with edit comment &quot;it&#x27;s a POV, must not be in Wikipedia&quot;).</div><br/></div></div><div id="36193476" class="c"><input type="checkbox" id="c-36193476" checked=""/><div class="controls bullet"><span class="by">rpastuszak</span><span>|</span><a href="#36193925">prev</a><span>|</span><a href="#36193621">next</a><span>|</span><label class="collapse" for="c-36193476">[-]</label><label class="expand" for="c-36193476">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>They don’t really understand what they’ve just copied and presented as an answer to a question.<p>&gt; Content posted without innate domain understanding, but written in a “smart” way, is dangerous to the integrity of the Stack Exchange network’s goal: To be a repository of high-quality question and answer content.</i><p>Tricking our bullshit detectors (eg cues present in the text or implied context) is the biggest problem I have with <i>usefulness</i> of AI generated content.<p>I wrote the Medieval Content Farm (<a href="https:&#x2F;&#x2F;tidings.potato.horse&#x2F;about" rel="nofollow">https:&#x2F;&#x2F;tidings.potato.horse&#x2F;about</a>) as an excuse to talk about this (and cope), although people focus more on the fact that I present it as a joke.</div><br/></div></div><div id="36193621" class="c"><input type="checkbox" id="c-36193621" checked=""/><div class="controls bullet"><span class="by">throw101010</span><span>|</span><a href="#36193476">prev</a><span>|</span><a href="#36192926">next</a><span>|</span><label class="collapse" for="c-36193621">[-]</label><label class="expand" for="c-36193621">[3 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think they can win, and I don&#x27;t mean just the moderators here, SO in general can&#x27;t win a fight against AI with bans of all kinds.<p>I see one possibility for them, embrace AI and generate a quick&#x2F;automated first reply by AI marked as such  (with a disclaimer) for every post. It should be subject to the same voting system.<p>The error of moderators and SO here is to discard AI generated answers because some wrong (but sounding right) answers it can generate... when often AI answers are also correct and even at times out do what a single human would have found&#x2F;answered.<p>If you can harness the existing human knowledge and correct the &quot;bad&quot; ones (badly rated AI answer given less weight) to feed the models of the future it seems like a win for everyone in the long run. A ban misses this opportunity and generates even more work for moderators which will inevitably also ban some innocent users and valuable content.</div><br/><div id="36193693" class="c"><input type="checkbox" id="c-36193693" checked=""/><div class="controls bullet"><span class="by">sofixa</span><span>|</span><a href="#36193621">parent</a><span>|</span><a href="#36193776">next</a><span>|</span><label class="collapse" for="c-36193693">[-]</label><label class="expand" for="c-36193693">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I don&#x27;t think they can win, and I don&#x27;t mean just the moderators here, SO in general can&#x27;t win a fight against AI with bans of all kinds.
&gt; I see one possibility for them, embrace AI and generate a quick&#x2F;automated first reply by AI marked as such (with a disclaimer) for every post<p>Problem is, most contributors would probably stop contributing (answering questions) if that were the case. If there&#x27;s an automatic answer that is correct 2&#x2F;3 of all times, that would mean lots of time spent reviewing automatic answers and lots of time &quot;wasted&quot; (where a contribution isn&#x27;t needed), which will probably discourage most of them</div><br/></div></div><div id="36193776" class="c"><input type="checkbox" id="c-36193776" checked=""/><div class="controls bullet"><span class="by">tjungblut</span><span>|</span><a href="#36193621">parent</a><span>|</span><a href="#36193693">prev</a><span>|</span><a href="#36192926">next</a><span>|</span><label class="collapse" for="c-36193776">[-]</label><label class="expand" for="c-36193776">[1 more]</label></div><br/><div class="children"><div class="content">Indeed. For me the most infuriating part is the amount of low-quality questions that could easily be answered by AI before submitting the question. They definitely should embrace AI and generate an answer. If you think that question isn&#x27;t properly answered, include why the AI proposed solution is wrong and let humans answer it.<p>As for the correctness of the solution: that&#x27;s why the voting system and tickmarks are there. Wrong solutions would ideally be downvoted and never marked correct, I don&#x27;t really see how AI is making a big difference here. Moderators today aren&#x27;t running the answered code either.</div><br/></div></div></div></div><div id="36192926" class="c"><input type="checkbox" id="c-36192926" checked=""/><div class="controls bullet"><span class="by">selcuka</span><span>|</span><a href="#36193621">prev</a><span>|</span><a href="#36193027">next</a><span>|</span><label class="collapse" for="c-36192926">[-]</label><label class="expand" for="c-36192926">[3 more]</label></div><br/><div class="children"><div class="content">It makes sense from a business perspective (they have been losing traffic to chatGPT), but unfortunately it may also mean the end of Stack Overflow as we know it. The whole value of SO was to be able to connect with subject experts in a reasonably easy and quick way.<p>Computer generated answers compiled from existing resources may work for simple questions, but not for things that require specific knowledge and experience.</div><br/><div id="36193382" class="c"><input type="checkbox" id="c-36193382" checked=""/><div class="controls bullet"><span class="by">busterarm</span><span>|</span><a href="#36192926">parent</a><span>|</span><a href="#36193437">next</a><span>|</span><label class="collapse" for="c-36193382">[-]</label><label class="expand" for="c-36193382">[1 more]</label></div><br/><div class="children"><div class="content">I have not found a reasonably good answer to a question in at least 5 years.  Seems more like 10.<p>I still get a better hit rate from mailing lists and github issues.</div><br/></div></div><div id="36193437" class="c"><input type="checkbox" id="c-36193437" checked=""/><div class="controls bullet"><span class="by">starball-tgz</span><span>|</span><a href="#36192926">parent</a><span>|</span><a href="#36193382">prev</a><span>|</span><a href="#36193027">next</a><span>|</span><label class="collapse" for="c-36193437">[-]</label><label class="expand" for="c-36193437">[1 more]</label></div><br/><div class="children"><div class="content">that&#x27;s not the only value. There&#x27;s a lot more. Emphasizing on &quot;no-noise&quot; is a big one. Stack Overflow was created to solve the problem of having to dig through long forum threads to get answers, or getting blocked by paywalls. There&#x27;s also value in searchability and showing up in search engines. Running LLMs like ChatGPT is not cheap in a lot of ways.</div><br/></div></div></div></div><div id="36193027" class="c"><input type="checkbox" id="c-36193027" checked=""/><div class="controls bullet"><span class="by">PeterStuer</span><span>|</span><a href="#36192926">prev</a><span>|</span><a href="#36192659">next</a><span>|</span><label class="collapse" for="c-36193027">[-]</label><label class="expand" for="c-36193027">[6 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not a black and white issue. Most domain experts already use AI assistants for their daily work. There is absolutely nothing wrong with that. It can and has demonstrated to greatly enhance productivity.<p>The SO problem isn&#x27;t AI, it&#x27;s people submitting low value answers, regardless of the way they used to produce those.<p>It is if anything a failiure of their reputation system, both in incentives and in repercussions.</div><br/><div id="36193052" class="c"><input type="checkbox" id="c-36193052" checked=""/><div class="controls bullet"><span class="by">tptacek</span><span>|</span><a href="#36193027">parent</a><span>|</span><a href="#36192659">next</a><span>|</span><label class="collapse" for="c-36193052">[-]</label><label class="expand" for="c-36193052">[5 more]</label></div><br/><div class="children"><div class="content">They do? For what, do most domain experts use AI assistants for?</div><br/><div id="36193327" class="c"><input type="checkbox" id="c-36193327" checked=""/><div class="controls bullet"><span class="by">lannisterstark</span><span>|</span><a href="#36193027">root</a><span>|</span><a href="#36193052">parent</a><span>|</span><a href="#36193436">next</a><span>|</span><label class="collapse" for="c-36193327">[-]</label><label class="expand" for="c-36193327">[1 more]</label></div><br/><div class="children"><div class="content">I use them every day for generating basic framework of whatever task I am doing, mostly coding. &quot;Write an HTTP request that does this for this xyz test url that takes x y or z as input, create a table with the outputs, sample json attached.&quot; etc.<p>It saves me hours working on mundane shit every week.</div><br/></div></div><div id="36193436" class="c"><input type="checkbox" id="c-36193436" checked=""/><div class="controls bullet"><span class="by">ambrozk</span><span>|</span><a href="#36193027">root</a><span>|</span><a href="#36193052">parent</a><span>|</span><a href="#36193327">prev</a><span>|</span><a href="#36193095">next</a><span>|</span><label class="collapse" for="c-36193436">[-]</label><label class="expand" for="c-36193436">[1 more]</label></div><br/><div class="children"><div class="content">I used it extensively to debug a very thorny MySQL version upgrade. In my experience, it knows a <i>lot</i> about MySQL, and can reason about weird behavior very very effectively. A typical use is asking it something like, &quot;Prior to my MySQL upgrade, my DB integration tests all passed, but now, they&#x27;re non-deterministically failing with the following error. What could be causing this?&quot; It then proposes hypotheses, which I either accept or push back on with new information. Surprisingly, this process led to it actually debugging a great number of my problems.</div><br/></div></div><div id="36193095" class="c"><input type="checkbox" id="c-36193095" checked=""/><div class="controls bullet"><span class="by">dagw</span><span>|</span><a href="#36193027">root</a><span>|</span><a href="#36193052">parent</a><span>|</span><a href="#36193436">prev</a><span>|</span><a href="#36193129">next</a><span>|</span><label class="collapse" for="c-36193095">[-]</label><label class="expand" for="c-36193095">[1 more]</label></div><br/><div class="children"><div class="content">90% of academics I know use chatGPT to help write grant applications or articles. Not for anything related to their actual domain, but more for improving language and clarity.</div><br/></div></div><div id="36193129" class="c"><input type="checkbox" id="c-36193129" checked=""/><div class="controls bullet"><span class="by">PeterStuer</span><span>|</span><a href="#36193027">root</a><span>|</span><a href="#36193052">parent</a><span>|</span><a href="#36193095">prev</a><span>|</span><a href="#36192659">next</a><span>|</span><label class="collapse" for="c-36193129">[-]</label><label class="expand" for="c-36193129">[1 more]</label></div><br/><div class="children"><div class="content">Proofreading, commenting, exploration, investigation, inspiration ...<p>Just because you are an expert does not mean you tackle every mundane but needed part of the work bare fisted or you memorized every edge case.</div><br/></div></div></div></div></div></div><div id="36192659" class="c"><input type="checkbox" id="c-36192659" checked=""/><div class="controls bullet"><span class="by">the_shivers</span><span>|</span><a href="#36193027">prev</a><span>|</span><a href="#36192952">next</a><span>|</span><label class="collapse" for="c-36192659">[-]</label><label class="expand" for="c-36192659">[7 more]</label></div><br/><div class="children"><div class="content">I see where the strikers are coming from, but isn&#x27;t this an intractable problem? There&#x27;s no way to tell if content is AI generated.</div><br/><div id="36193069" class="c"><input type="checkbox" id="c-36193069" checked=""/><div class="controls bullet"><span class="by">hammyhavoc</span><span>|</span><a href="#36192659">parent</a><span>|</span><a href="#36192881">next</a><span>|</span><label class="collapse" for="c-36193069">[-]</label><label class="expand" for="c-36193069">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s definitely a recognizable default style to a lot of ChatGPT output. Sure, with some prompts you can get away from that, but it&#x27;s ultimately still following a somewhat predictable pattern.<p>However, as a counterpoint, I now see people who spend a lot of time using ChatGPT actually end up writing in real-time, in-person, like ChatGPT&#x27;s default vanilla output. Just like some American kids now say &quot;mummy&quot; because of watching so much Peppa Pig.</div><br/></div></div><div id="36192881" class="c"><input type="checkbox" id="c-36192881" checked=""/><div class="controls bullet"><span class="by">selcuka</span><span>|</span><a href="#36192659">parent</a><span>|</span><a href="#36193069">prev</a><span>|</span><a href="#36193359">next</a><span>|</span><label class="collapse" for="c-36192881">[-]</label><label class="expand" for="c-36192881">[2 more]</label></div><br/><div class="children"><div class="content">You can tell it in some cases, especially those that contain typical LLM hallucinations. Many LLM generated answers are either plain wrong, or have made up function or argument names.</div><br/><div id="36192893" class="c"><input type="checkbox" id="c-36192893" checked=""/><div class="controls bullet"><span class="by">LewisVerstappen</span><span>|</span><a href="#36192659">root</a><span>|</span><a href="#36192881">parent</a><span>|</span><a href="#36193359">next</a><span>|</span><label class="collapse" for="c-36192893">[-]</label><label class="expand" for="c-36192893">[1 more]</label></div><br/><div class="children"><div class="content">That’s definitely not the case with GPT4</div><br/></div></div></div></div><div id="36193359" class="c"><input type="checkbox" id="c-36193359" checked=""/><div class="controls bullet"><span class="by">sampo</span><span>|</span><a href="#36192659">parent</a><span>|</span><a href="#36192881">prev</a><span>|</span><a href="#36192856">next</a><span>|</span><label class="collapse" for="c-36193359">[-]</label><label class="expand" for="c-36193359">[1 more]</label></div><br/><div class="children"><div class="content">&gt; There&#x27;s no way to tell if content is AI generated.<p>In general no. But I don&#x27;t think anyone human writes in the typical style of a ChatGPT answer, so in practice there is a large class of cases where you can tell.</div><br/></div></div><div id="36192856" class="c"><input type="checkbox" id="c-36192856" checked=""/><div class="controls bullet"><span class="by">USB5</span><span>|</span><a href="#36192659">parent</a><span>|</span><a href="#36193359">prev</a><span>|</span><a href="#36192952">next</a><span>|</span><label class="collapse" for="c-36192856">[-]</label><label class="expand" for="c-36192856">[2 more]</label></div><br/><div class="children"><div class="content">There would be if it were a strike, because the so-called &quot;strikers&quot; would operate the company as employees.<p>This is a boycott, not a strike.</div><br/><div id="36192894" class="c"><input type="checkbox" id="c-36192894" checked=""/><div class="controls bullet"><span class="by">selcuka</span><span>|</span><a href="#36192659">root</a><span>|</span><a href="#36192856">parent</a><span>|</span><a href="#36192952">next</a><span>|</span><label class="collapse" for="c-36192894">[-]</label><label class="expand" for="c-36192894">[1 more]</label></div><br/><div class="children"><div class="content">No, boycott means refusing to <i>use</i> a service. This is about refusing to moderate, so it&#x27;s a strike. Moderators are volunteer workers.</div><br/></div></div></div></div></div></div><div id="36192952" class="c"><input type="checkbox" id="c-36192952" checked=""/><div class="controls bullet"><span class="by">coolgoose</span><span>|</span><a href="#36192659">prev</a><span>|</span><a href="#36192836">next</a><span>|</span><label class="collapse" for="c-36192952">[-]</label><label class="expand" for="c-36192952">[2 more]</label></div><br/><div class="children"><div class="content">On one hand I simpatise with the problem, on another Stackoverflow is one of those platforms where the close random hammer for seemingly random reasons was always used.</div><br/><div id="36193322" class="c"><input type="checkbox" id="c-36193322" checked=""/><div class="controls bullet"><span class="by">sideshowb</span><span>|</span><a href="#36192952">parent</a><span>|</span><a href="#36192836">next</a><span>|</span><label class="collapse" for="c-36193322">[-]</label><label class="expand" for="c-36193322">[1 more]</label></div><br/><div class="children"><div class="content">Turns out the mods don&#x27;t like it when told their actions are &quot;too subjective&quot;. Irony overflow.</div><br/></div></div></div></div><div id="36192836" class="c"><input type="checkbox" id="c-36192836" checked=""/><div class="controls bullet"><span class="by">lamontcg</span><span>|</span><a href="#36192952">prev</a><span>|</span><a href="#36193207">next</a><span>|</span><label class="collapse" for="c-36192836">[-]</label><label class="expand" for="c-36192836">[7 more]</label></div><br/><div class="children"><div class="content">What happens when sites like SO become so polluted with AI generated text that the next generation of LLMs trained on the Internet is just AIs being trained on AIs?</div><br/><div id="36193293" class="c"><input type="checkbox" id="c-36193293" checked=""/><div class="controls bullet"><span class="by">aezart</span><span>|</span><a href="#36192836">parent</a><span>|</span><a href="#36192857">next</a><span>|</span><label class="collapse" for="c-36193293">[-]</label><label class="expand" for="c-36193293">[1 more]</label></div><br/><div class="children"><div class="content">Rapid degradation, like recording multiple generations of VHS tapes. The LLMs make the internet dumber, the LLMs get dumber by learning from it. Rinse and repeat.</div><br/></div></div><div id="36192857" class="c"><input type="checkbox" id="c-36192857" checked=""/><div class="controls bullet"><span class="by">ioseph</span><span>|</span><a href="#36192836">parent</a><span>|</span><a href="#36193293">prev</a><span>|</span><a href="#36192869">next</a><span>|</span><label class="collapse" for="c-36192857">[-]</label><label class="expand" for="c-36192857">[3 more]</label></div><br/><div class="children"><div class="content">The internet often feels like this already, i.e. if I Google a question the top result will be often be a Quora post</div><br/><div id="36193555" class="c"><input type="checkbox" id="c-36193555" checked=""/><div class="controls bullet"><span class="by">arketyp</span><span>|</span><a href="#36192836">root</a><span>|</span><a href="#36192857">parent</a><span>|</span><a href="#36193100">next</a><span>|</span><label class="collapse" for="c-36193555">[-]</label><label class="expand" for="c-36193555">[1 more]</label></div><br/><div class="children"><div class="content">Makes me think culture itself was always already like this.</div><br/></div></div><div id="36193100" class="c"><input type="checkbox" id="c-36193100" checked=""/><div class="controls bullet"><span class="by">hammyhavoc</span><span>|</span><a href="#36192836">root</a><span>|</span><a href="#36192857">parent</a><span>|</span><a href="#36193555">prev</a><span>|</span><a href="#36192869">next</a><span>|</span><label class="collapse" for="c-36193100">[-]</label><label class="expand" for="c-36193100">[1 more]</label></div><br/><div class="children"><div class="content">Using `-site:` will probably make you very happy if you don&#x27;t already use it and want to get rid of low quality Q&amp;A sites choking your SERPs.</div><br/></div></div></div></div><div id="36192869" class="c"><input type="checkbox" id="c-36192869" checked=""/><div class="controls bullet"><span class="by">thrtythreeforty</span><span>|</span><a href="#36192836">parent</a><span>|</span><a href="#36192857">prev</a><span>|</span><a href="#36192862">next</a><span>|</span><label class="collapse" for="c-36192869">[-]</label><label class="expand" for="c-36192869">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m willing to bet OpenAI knows how to detect OpenAI output, either via stenographic techniques or via keeping a database of all the text it&#x27;s generated. Both, probably.<p>Which means future OpenAI models would be getting trained on the output of <i>competitor</i> models. Like Bard. Oof.</div><br/></div></div><div id="36192862" class="c"><input type="checkbox" id="c-36192862" checked=""/><div class="controls bullet"><span class="by">LewisVerstappen</span><span>|</span><a href="#36192836">parent</a><span>|</span><a href="#36192869">prev</a><span>|</span><a href="#36193207">next</a><span>|</span><label class="collapse" for="c-36192862">[-]</label><label class="expand" for="c-36192862">[1 more]</label></div><br/><div class="children"><div class="content">The intelligence comes from RLHF.</div><br/></div></div></div></div><div id="36193207" class="c"><input type="checkbox" id="c-36193207" checked=""/><div class="controls bullet"><span class="by">gorgoiler</span><span>|</span><a href="#36192836">prev</a><span>|</span><a href="#36193775">next</a><span>|</span><label class="collapse" for="c-36193207">[-]</label><label class="expand" for="c-36193207">[3 more]</label></div><br/><div class="children"><div class="content">Given <i>f(prompt, model) -&gt; text</i> is there some <i>h(model, text) -&gt; [0,1)</i> which tells you if the the text was generated by the model?  Crucially, could you publish <i>h</i> without publishing the model?<p>It’s a bit like public key cryptography — if generating text is using <i>sign()</i> to sign a prompt with your model then is there a publicly available <i>verify()</i> that verifies the output came from
the model but which doesn’t leak the private model itself?<p>What sort of things exist like this (other than private, API models recording all text they’ve generated)?</div><br/><div id="36193568" class="c"><input type="checkbox" id="c-36193568" checked=""/><div class="controls bullet"><span class="by">timmaxw</span><span>|</span><a href="#36193207">parent</a><span>|</span><a href="#36193364">next</a><span>|</span><label class="collapse" for="c-36193568">[-]</label><label class="expand" for="c-36193568">[1 more]</label></div><br/><div class="children"><div class="content">Scott Aaronson has worked on this with OpenAI. Ctrl-F for &quot;watermarking&quot; in <a href="https:&#x2F;&#x2F;scottaaronson.blog&#x2F;?p=6823" rel="nofollow">https:&#x2F;&#x2F;scottaaronson.blog&#x2F;?p=6823</a>. I don&#x27;t know if they&#x27;ve actually deployed it in ChatGPT or not.</div><br/></div></div><div id="36193364" class="c"><input type="checkbox" id="c-36193364" checked=""/><div class="controls bullet"><span class="by">jraph</span><span>|</span><a href="#36193207">parent</a><span>|</span><a href="#36193568">prev</a><span>|</span><a href="#36193775">next</a><span>|</span><label class="collapse" for="c-36193364">[-]</label><label class="expand" for="c-36193364">[1 more]</label></div><br/><div class="children"><div class="content">Interesting mathematics problem aside.<p>I think OpenAI sells a subscription to a ChatGPT detector. So you can pay for h. Does it work correctly? I don&#x27;t know. Selling the poison and the antidote seems like a good business move though (I know, you asked &quot;other than private API&quot; - not sure they record the generated text, not sure they don&#x27;t).<p>Now, a ChatGPT-generated text (for current versions of ChatGPT) is more or less recognizable so for moderation purpose I would guess you don&#x27;t really need h, you can smell the bullshit. It has a specific way to be overconfident and it feels like it&#x27;s giving you a lesson in a specific impersonal way without emotions. Something like this. I have the same kind of feeling when reading a WikiHow page, WikiHow has a very specific and recognizable style to explain things.<p>I guess you can recognize patterns &#x2F; specific behaviors on accounts posting ChatGPT texts too, which can help for particularly short texts.</div><br/></div></div></div></div><div id="36193775" class="c"><input type="checkbox" id="c-36193775" checked=""/><div class="controls bullet"><span class="by">eterevsky</span><span>|</span><a href="#36193207">prev</a><span>|</span><a href="#36192666">next</a><span>|</span><label class="collapse" for="c-36193775">[-]</label><label class="expand" for="c-36193775">[2 more]</label></div><br/><div class="children"><div class="content">&gt; The problem with AI-generated content<p>It sounds like the author&#x27;s main problem with AI answers is that they are purely textual, and the AI is unable to verify them. Does it mean that the stance will change if the AI bot is able to run its code before submitting the answer? Aren&#x27;t there already AI agents available that can do just that?</div><br/><div id="36193850" class="c"><input type="checkbox" id="c-36193850" checked=""/><div class="controls bullet"><span class="by">charcircuit</span><span>|</span><a href="#36193775">parent</a><span>|</span><a href="#36192666">next</a><span>|</span><label class="collapse" for="c-36193850">[-]</label><label class="expand" for="c-36193850">[1 more]</label></div><br/><div class="children"><div class="content">The goal of stack exchange is to create a repository of question answer pairs of knowledge. The problem here is that generational AI isn&#x27;t able to create these new pairs. Either it is regurgitating existing knowledge or it is making up a potential answer. Repeat knowledge in the repository is discouraged and is why questions get marked as duplicate. Making up answers is problematic because it can be hard to verify and it lowers the quality of the repository. An AI being able to run code doesn&#x27;t mean it is able to verify a solution.<p>Stack Exchange is not about answering people&#x27;s questions. There can exist a different site for that and for a site like that it could make sense for current LLM to help.</div><br/></div></div></div></div><div id="36192666" class="c"><input type="checkbox" id="c-36192666" checked=""/><div class="controls bullet"><span class="by">dataflow</span><span>|</span><a href="#36193775">prev</a><span>|</span><a href="#36193615">next</a><span>|</span><label class="collapse" for="c-36192666">[-]</label><label class="expand" for="c-36192666">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;m confused. What exactly was going <i>so</i> wrong with the temporary AI ban that they felt a near-180-degree turn would be better? I did see the mention of &quot;the rate of inaccuracy experienced by automated detectors aiming to identify AI- and specifically GPT-generated content&quot;, but that hardly seems so catastrophic as to suggest the opposite would be better.</div><br/><div id="36192901" class="c"><input type="checkbox" id="c-36192901" checked=""/><div class="controls bullet"><span class="by">selcuka</span><span>|</span><a href="#36192666">parent</a><span>|</span><a href="#36193615">next</a><span>|</span><label class="collapse" for="c-36192901">[-]</label><label class="expand" for="c-36192901">[2 more]</label></div><br/><div class="children"><div class="content">Because they were losing traffic to chatGPT. Stack Overflow has been all about numbers and revenue for some time now.</div><br/><div id="36192927" class="c"><input type="checkbox" id="c-36192927" checked=""/><div class="controls bullet"><span class="by">dataflow</span><span>|</span><a href="#36192666">root</a><span>|</span><a href="#36192901">parent</a><span>|</span><a href="#36193615">next</a><span>|</span><label class="collapse" for="c-36192927">[-]</label><label class="expand" for="c-36192927">[1 more]</label></div><br/><div class="children"><div class="content">Oh shoot, thanks for explaining that! When you put it that way, it definitely looks like a threat to the business!</div><br/></div></div></div></div></div></div><div id="36193615" class="c"><input type="checkbox" id="c-36193615" checked=""/><div class="controls bullet"><span class="by">slushh</span><span>|</span><a href="#36192666">prev</a><span>|</span><a href="#36192884">next</a><span>|</span><label class="collapse" for="c-36193615">[-]</label><label class="expand" for="c-36193615">[1 more]</label></div><br/><div class="children"><div class="content">&gt;as a last-resort effort to protect the Stack Exchange platform and users from a total loss in value.<p>The strike is not the last last-resort effort. Stack Exchange should not only open source all answers, but also open the platform with ActivityPub. Then, those moderators can create another frontend where they ban the AI users. Otherwise, the moderators will create their own platform without Stack Exchange being the main hub.<p>It&#x27;s wild that moderator conflicts happen on Stack Exchange and Reddit at the same time.</div><br/></div></div><div id="36192884" class="c"><input type="checkbox" id="c-36192884" checked=""/><div class="controls bullet"><span class="by">geitir</span><span>|</span><a href="#36193615">prev</a><span>|</span><a href="#36192904">next</a><span>|</span><label class="collapse" for="c-36192884">[-]</label><label class="expand" for="c-36192884">[4 more]</label></div><br/><div class="children"><div class="content">Honestly stack overflow is just a for profit Wikipedia. It’s content should be scraped and an open source version replace it</div><br/><div id="36192961" class="c"><input type="checkbox" id="c-36192961" checked=""/><div class="controls bullet"><span class="by">weinzierl</span><span>|</span><a href="#36192884">parent</a><span>|</span><a href="#36192904">next</a><span>|</span><label class="collapse" for="c-36192961">[-]</label><label class="expand" for="c-36192961">[3 more]</label></div><br/><div class="children"><div class="content">It&#x27;s so sad to see how a project that once set out to <i>NOT</i> be like the other popular QA sites of that time could still end up so horribly similar. How a group of good people, with best intentions could still end up with a site in a state like this. The way to hell is paved with good intentions, 
I guess.</div><br/><div id="36192997" class="c"><input type="checkbox" id="c-36192997" checked=""/><div class="controls bullet"><span class="by">selcuka</span><span>|</span><a href="#36192884">root</a><span>|</span><a href="#36192961">parent</a><span>|</span><a href="#36193018">next</a><span>|</span><label class="collapse" for="c-36192997">[-]</label><label class="expand" for="c-36192997">[1 more]</label></div><br/><div class="children"><div class="content">&gt; How a group of good people, with best intentions could still end up with a site in a state like this.<p>Almost any for-profit platform is doomed to become a dumpster, in the end. After Joel Spolsky and Jeff Atwood, the original founders, sold it to Prosus 2 years ago it has been free falling.</div><br/></div></div><div id="36193018" class="c"><input type="checkbox" id="c-36193018" checked=""/><div class="controls bullet"><span class="by">ozr</span><span>|</span><a href="#36192884">root</a><span>|</span><a href="#36192961">parent</a><span>|</span><a href="#36192997">prev</a><span>|</span><a href="#36192904">next</a><span>|</span><label class="collapse" for="c-36193018">[-]</label><label class="expand" for="c-36193018">[1 more]</label></div><br/><div class="children"><div class="content">The original founders checked out long before the acquisition, and it&#x27;s only gotten worse since then.  Just the way these things go.</div><br/></div></div></div></div></div></div><div id="36192904" class="c"><input type="checkbox" id="c-36192904" checked=""/><div class="controls bullet"><span class="by">MrThoughtful</span><span>|</span><a href="#36192884">prev</a><span>|</span><a href="#36193692">next</a><span>|</span><label class="collapse" for="c-36192904">[-]</label><label class="expand" for="c-36192904">[8 more]</label></div><br/><div class="children"><div class="content">Why is anybody moderating on Stack Overflow at all?<p>What is the incentive?</div><br/><div id="36193676" class="c"><input type="checkbox" id="c-36193676" checked=""/><div class="controls bullet"><span class="by">pbhjpbhj</span><span>|</span><a href="#36192904">parent</a><span>|</span><a href="#36193086">next</a><span>|</span><label class="collapse" for="c-36193676">[-]</label><label class="expand" for="c-36193676">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m a top 5% moderator on AskUbuntu and have answers on half a dozen SE sites.<p>I used to use LinuxQuestions, a forum site, but found that SE provided better answers for me (better format, less searching), so in return I answered questions there if I could. I also used to blog tricky problems I&#x27;d solved on my *nix boxen; SE was marginally easier than making a blog post and would get better responses&#x2F;corrections.<p>That was the initial motivation: community participation, <i>quid pro quo</i>.<p>Keeping SE sites like U&amp;L and AU useful is my on-going motivation, in part I enjoy helping others, in part I enjoy using my Linux knowledge acquired over many years as a user.<p>Yes, the company get value but all answers are &quot;open source&quot; and it serves the public good too.</div><br/></div></div><div id="36193086" class="c"><input type="checkbox" id="c-36193086" checked=""/><div class="controls bullet"><span class="by">hammyhavoc</span><span>|</span><a href="#36192904">parent</a><span>|</span><a href="#36193676">prev</a><span>|</span><a href="#36193692">next</a><span>|</span><label class="collapse" for="c-36193086">[-]</label><label class="expand" for="c-36193086">[6 more]</label></div><br/><div class="children"><div class="content">To have a useful and functional community for a niche topic. The same reason someone would moderate a forum or sub-Reddit.<p>What&#x27;s the incentive for dang to moderate HN? If it&#x27;s garbage and uncurated, people probably won&#x27;t use it because the filtering tools to parse the data are non-existent.<p>People come for an answer to their question, perhaps they answer the questions of others. Just like how any &quot;community&quot; works.<p>&quot;Their treasure was knowledge.&quot;</div><br/><div id="36193104" class="c"><input type="checkbox" id="c-36193104" checked=""/><div class="controls bullet"><span class="by">MrThoughtful</span><span>|</span><a href="#36192904">root</a><span>|</span><a href="#36193086">parent</a><span>|</span><a href="#36193156">next</a><span>|</span><label class="collapse" for="c-36193104">[-]</label><label class="expand" for="c-36193104">[3 more]</label></div><br/><div class="children"><div class="content">Looking at the questions, they seem not very niche to me:<p><a href="https:&#x2F;&#x2F;stackoverflow.com&#x2F;questions&#x2F;" rel="nofollow">https:&#x2F;&#x2F;stackoverflow.com&#x2F;questions&#x2F;</a><p>Just that typical questions about popular technologies.<p>Isn&#x27;t Dang being paid to moderate HN?</div><br/><div id="36193137" class="c"><input type="checkbox" id="c-36193137" checked=""/><div class="controls bullet"><span class="by">hammyhavoc</span><span>|</span><a href="#36192904">root</a><span>|</span><a href="#36193104">parent</a><span>|</span><a href="#36193141">next</a><span>|</span><label class="collapse" for="c-36193137">[-]</label><label class="expand" for="c-36193137">[1 more]</label></div><br/><div class="children"><div class="content">They&#x27;re niche relative to &quot;where else are you going to ask them successfully?&quot;. If you go on Twitter, whilst it may have way more people, you&#x27;re probably not going to reach the same demographics in as meaningful a way.<p>I would assume so, yes, but the point still stands: he needs to moderate it or people won&#x27;t find value in it, thus he&#x27;ll be out of a position.<p>What&#x27;s the value in Wikipedia? The curated knowledge. You only have to go on the average Talk tab for an article on Wikipedia to realize how hard-won most content is, and no, the best outcome doesn&#x27;t always happen, and plenty of genuine nonsense still makes its way into articles and stays there for years on end.</div><br/></div></div><div id="36193141" class="c"><input type="checkbox" id="c-36193141" checked=""/><div class="controls bullet"><span class="by">JdeBP</span><span>|</span><a href="#36192904">root</a><span>|</span><a href="#36193104">parent</a><span>|</span><a href="#36193137">prev</a><span>|</span><a href="#36193156">next</a><span>|</span><label class="collapse" for="c-36193141">[-]</label><label class="expand" for="c-36193141">[1 more]</label></div><br/><div class="children"><div class="content">There are 180 <i>other</i> Stack Exchange sites, with subjects ranging from Latin through Woodworking to Biblical Hermeneutics.  This is a General Strike.</div><br/></div></div></div></div><div id="36193156" class="c"><input type="checkbox" id="c-36193156" checked=""/><div class="controls bullet"><span class="by">quantumwoke</span><span>|</span><a href="#36192904">root</a><span>|</span><a href="#36193086">parent</a><span>|</span><a href="#36193104">prev</a><span>|</span><a href="#36193692">next</a><span>|</span><label class="collapse" for="c-36193156">[-]</label><label class="expand" for="c-36193156">[2 more]</label></div><br/><div class="children"><div class="content">dang is paid to moderate HN.</div><br/><div id="36193182" class="c"><input type="checkbox" id="c-36193182" checked=""/><div class="controls bullet"><span class="by">hammyhavoc</span><span>|</span><a href="#36192904">root</a><span>|</span><a href="#36193156">parent</a><span>|</span><a href="#36193692">next</a><span>|</span><label class="collapse" for="c-36193182">[-]</label><label class="expand" for="c-36193182">[1 more]</label></div><br/><div class="children"><div class="content">I addressed this here: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36193137" rel="nofollow">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36193137</a></div><br/></div></div></div></div></div></div></div></div><div id="36193692" class="c"><input type="checkbox" id="c-36193692" checked=""/><div class="controls bullet"><span class="by">red_admiral</span><span>|</span><a href="#36192904">prev</a><span>|</span><a href="#36193426">next</a><span>|</span><label class="collapse" for="c-36193692">[-]</label><label class="expand" for="c-36193692">[2 more]</label></div><br/><div class="children"><div class="content">&gt; They want the internal AI policy given to moderators to be revealed to the community [teekert&#x27;s comment]<p>It wouldn&#x27;t be that hard from someone to leak it? If all moderators across different sites can see it, it&#x27;s not exactly a state secret.</div><br/><div id="36193751" class="c"><input type="checkbox" id="c-36193751" checked=""/><div class="controls bullet"><span class="by">JdeBP</span><span>|</span><a href="#36193692">parent</a><span>|</span><a href="#36193426">next</a><span>|</span><label class="collapse" for="c-36193751">[-]</label><label class="expand" for="c-36193751">[1 more]</label></div><br/><div class="children"><div class="content">When the complaint is the lack of trustworthiness and of sticking to avowed principles, being untrustworthy and abandoning one&#x27;s own principles in response is not a wise course of action.</div><br/></div></div></div></div><div id="36193426" class="c"><input type="checkbox" id="c-36193426" checked=""/><div class="controls bullet"><span class="by">shp0ngle</span><span>|</span><a href="#36193692">prev</a><span>|</span><a href="#36193321">next</a><span>|</span><label class="collapse" for="c-36193426">[-]</label><label class="expand" for="c-36193426">[1 more]</label></div><br/><div class="children"><div class="content">Yeah it makes sense. When I ask something at StackOverflow, I don’t want AI hallucinated sludge as the reply.<p>Or if there is an AI hallucinated sludge, I want it clearly marked as such</div><br/></div></div><div id="36193321" class="c"><input type="checkbox" id="c-36193321" checked=""/><div class="controls bullet"><span class="by">wcerfgba</span><span>|</span><a href="#36193426">prev</a><span>|</span><a href="#36193438">next</a><span>|</span><label class="collapse" for="c-36193321">[-]</label><label class="expand" for="c-36193321">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think criticising AI on grounds of it not &#x27;understanding&#x27; is a strong argument, since we have neither a definition for, nor a way to measure, what understanding <i>is</i>.</div><br/></div></div><div id="36193438" class="c"><input type="checkbox" id="c-36193438" checked=""/><div class="controls bullet"><span class="by">zoogeny</span><span>|</span><a href="#36193321">prev</a><span>|</span><a href="#36193105">next</a><span>|</span><label class="collapse" for="c-36193438">[-]</label><label class="expand" for="c-36193438">[1 more]</label></div><br/><div class="children"><div class="content">&gt; ChatGPT, for example, doesn’t understand the responses it gives you; it simply associates a given prompt with information it has access to and regurgitates plausible-sounding sentences<p>I don&#x27;t like this tone, in the sense that suggesting what ChatGPT does is &quot;simply&quot; and &quot;regurgitates&quot; feels like a biased interpretation of what the tech is doing.<p>I think it is fair to say: ChatGPT is very good at creating convincing appearing content that is also incorrect. Validating content that appears high-quality in form but is actually low-quality in content is a major challenge for moderators. Banning suspicious accounts that moderators believe are spamming ChatGPT based responses is easier than individually validating each and every post from such accounts manually. As the number of posts from ChatGPT backed accounts multiplies this would become increasingly difficult and time consuming.<p>I understand their pain and I hope they find a solution. But my gut tells me that whatever solution they come up with will be forced to tolerate some amount of GPT generated content.</div><br/></div></div><div id="36193105" class="c"><input type="checkbox" id="c-36193105" checked=""/><div class="controls bullet"><span class="by">Nuzzerino</span><span>|</span><a href="#36193438">prev</a><span>|</span><a href="#36193329">next</a><span>|</span><label class="collapse" for="c-36193105">[-]</label><label class="expand" for="c-36193105">[1 more]</label></div><br/><div class="children"><div class="content">I for one welcome our new robot overlords. I&#x27;ll step up to help clear the queues.</div><br/></div></div><div id="36193329" class="c"><input type="checkbox" id="c-36193329" checked=""/><div class="controls bullet"><span class="by">teekert</span><span>|</span><a href="#36193105">prev</a><span>|</span><a href="#36192721">next</a><span>|</span><label class="collapse" for="c-36193329">[-]</label><label class="expand" for="c-36193329">[1 more]</label></div><br/><div class="children"><div class="content">TL;DR: They want the internal AI policy given to moderators to be revealed to the community, and in general want a more open&#x2F;equal relationship with SO management.<p>Maybe it&#x27;s because I&#x27;m not a native English speaker but I can&#x27;t really figure out if they are against or for AI answers?<p>They say ChatGPT is s parrot leading to poor quality, so I assume they are against, but Stack Overflow did indeed ban ChatGPT messages? Then they say AI detectors have many false positives, so I guess they are against strong filtering? So what are they for then? This piece needs a tl;dr or bullet list... So yeah I asked our large language friend:<p>Stances from the text:<p><pre><code>    A general moderation strike is being initiated.
    The strike is in protest of recent and upcoming changes to policy and the platform by Stack Exchange, Inc.
    Striking community members will refrain from moderating and curating content.
    Critical community-driven anti-spam and quality control infrastructure will be shut down.
    The new policy on AI-generated content is harmful and overrides community consensus.
    There has been a serious failure to communicate on the part of Stack Exchange, Inc.
    AI-generated content poses risks to the integrity of the platform and represents an honesty issue.
    Stack Exchange, Inc. has ignored the needs and consensus of the community and made decisions without consulting those most affected.
    The striking users want the AI policy change to be retracted or modified to address concerns and empower moderators.
    They want the internal AI policy given to moderators to be revealed to the community.
    Clear and open communication from Stack Exchange, Inc. regarding policy changes is demanded.
    Collaboration with the community instead of fighting it is expected.
    Stack Exchange, Inc. should be honest about the company&#x27;s relationship with the community.
    A change in leadership philosophy toward the community is needed.
    Leadership should allocate resources based on community needs and involve the community in feature development.
    Neglecting and mistreating volunteers can lead to a decrease in goodwill and motivation.
    The concerns laid out in the open letter and the post should be addressed to end the strike.
</code></pre>
Imho this is the key thing: They want the internal AI policy given to moderators to be revealed to the community, and in general want a more open&#x2F;equal relationship with SO management.</div><br/></div></div><div id="36192721" class="c"><input type="checkbox" id="c-36192721" checked=""/><div class="controls bullet"><span class="by">AlbertCory</span><span>|</span><a href="#36193329">prev</a><span>|</span><a href="#36193279">next</a><span>|</span><label class="collapse" for="c-36192721">[-]</label><label class="expand" for="c-36192721">[1 more]</label></div><br/><div class="children"><div class="content">Just for yucks, I asked GPT specifically to write an answer that would <i>avoid</i> the AI detector. It failed; SO still detected it.</div><br/></div></div><div id="36193279" class="c"><input type="checkbox" id="c-36193279" checked=""/><div class="controls bullet"><span class="by">fzeroracer</span><span>|</span><a href="#36192721">prev</a><span>|</span><a href="#36192736">next</a><span>|</span><label class="collapse" for="c-36193279">[-]</label><label class="expand" for="c-36193279">[1 more]</label></div><br/><div class="children"><div class="content">Honestly good on them. We&#x27;ve seen that the rise in ChatGPT spam has led to spamming of repositories with poor quality PRs [1] and this whole AI craze just feels like the SEO disaster hitting mach 10. The quality of content or answers doesn&#x27;t actually matter, just that it&#x27;s formatted in a way that seems authoritative. This stuff needed to be purged from the internet yesterday.<p>[1] <a href="https:&#x2F;&#x2F;mastodon.social&#x2F;@danluu&#x2F;110335983520055904" rel="nofollow">https:&#x2F;&#x2F;mastodon.social&#x2F;@danluu&#x2F;110335983520055904</a></div><br/></div></div><div id="36192846" class="c"><input type="checkbox" id="c-36192846" checked=""/><div class="controls bullet"><span class="by">USB5</span><span>|</span><a href="#36192736">prev</a><span>|</span><label class="collapse" for="c-36192846">[-]</label><label class="expand" for="c-36192846">[2 more]</label></div><br/><div class="children"><div class="content">This isn&#x27;t a strike lol. It&#x27;s a boycott.</div><br/><div id="36193106" class="c"><input type="checkbox" id="c-36193106" checked=""/><div class="controls bullet"><span class="by">ctenb</span><span>|</span><a href="#36192846">parent</a><span>|</span><label class="collapse" for="c-36193106">[-]</label><label class="expand" for="c-36193106">[1 more]</label></div><br/><div class="children"><div class="content">Strike is the right word for workers refusing to work for particular reasons. Boycott pertains to users, not workers.</div><br/></div></div></div></div></div></div></div></div></div></body></html>