<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1730019650594" as="style"/><link rel="stylesheet" href="styles.css?v=1730019650594"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.assembled.com/blog/how-we-saved-hundreds-of-engineering-hours-by-writing-tests-with-llms">Using LLMs to enhance our testing practices</a>Â <span class="domain">(<a href="https://www.assembled.com">www.assembled.com</a>)</span></div><div class="subtext"><span>johnjwang</span> | <span>53 comments</span></div><br/><div><div id="41958160" class="c"><input type="checkbox" id="c-41958160" checked=""/><div class="controls bullet"><span class="by">renegade-otter</span><span>|</span><a href="#41960877">next</a><span>|</span><label class="collapse" for="c-41958160">[-]</label><label class="expand" for="c-41958160">[15 more]</label></div><br/><div class="children"><div class="content">In every single system I have worked on, tests were not just tests - they were their own parallel application, and it required careful architecture and constant refactoring in order for it to not get out of hand.<p>&quot;More tests&quot; is not the goal - you need to write high impact tests, you need to think about how to test the most of your app surface with least amount of test code. Sometimes I spend more time on the test code than the actual code (probably normal).<p>Also, I feel like people would be inclined to go with whatever the LLM gives them, as opposed to really sitting down and thinking about all the unhappy paths and edge cases of UX. Using an autocomplete to &quot;bang it out&quot; seems foolish.</div><br/><div id="41960878" class="c"><input type="checkbox" id="c-41960878" checked=""/><div class="controls bullet"><span class="by">danmaz74</span><span>|</span><a href="#41958160">parent</a><span>|</span><a href="#41959996">next</a><span>|</span><label class="collapse" for="c-41960878">[-]</label><label class="expand" for="c-41960878">[1 more]</label></div><br/><div class="children"><div class="content">I subscribe to the concept of the &quot;pyramid of tests&quot; - lots of simpler unit tests, fewer integration tests, and very few end-to-end tests. I find that using LLMs to write unit tests is very useful. If I just wrote code which has good naming both for the classes, methods and variables, useful comments where necessary and if I already have other tests which the LLMs can use as examples for how I test things, I usually just need to read the created tests and sometimes add some test cases, just writing the &quot;it should &#x27;this and that&#x27;&quot; part for cases which weren&#x27;t covered.<p>An added bonus is that if the tests aren&#x27;t what you expect, often it helps you understand that the code isn&#x27;t as clear as it should be.</div><br/></div></div><div id="41959996" class="c"><input type="checkbox" id="c-41959996" checked=""/><div class="controls bullet"><span class="by">jeswin</span><span>|</span><a href="#41958160">parent</a><span>|</span><a href="#41960878">prev</a><span>|</span><a href="#41958286">next</a><span>|</span><label class="collapse" for="c-41959996">[-]</label><label class="expand" for="c-41959996">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Using an autocomplete to &quot;bang it out&quot; seems foolish.<p>Based on my own experience, I find the widespread scepticism on HN about AI-assisted coding misplaced. There will be corner cases, there will be errors, and there will be bugs. There will also be apps for which AI is not helpful at all. But that&#x27;s fine - nobody is saying otherwise. The question is only about whether it is a _significant_ nett saving on the time spent across various project types. The answer to that is a resounding Yes.<p>The entire set of tests for a web framework I wrote recently were generated with Claude and GPT. You can see them here: <a href="https:&#x2F;&#x2F;github.com&#x2F;webjsx&#x2F;webjsx&#x2F;tree&#x2F;main&#x2F;src&#x2F;test">https:&#x2F;&#x2F;github.com&#x2F;webjsx&#x2F;webjsx&#x2F;tree&#x2F;main&#x2F;src&#x2F;test</a><p>On an average, these tests are better than tests I would have written myself. The project was written mostly by AI as well, like most other stuff I&#x27;ve written since GPT4 came out.<p>&quot;Using an autocomplete to bang it out&quot; is exactly what one should do - in most cases.</div><br/></div></div><div id="41958286" class="c"><input type="checkbox" id="c-41958286" checked=""/><div class="controls bullet"><span class="by">swatcoder</span><span>|</span><a href="#41958160">parent</a><span>|</span><a href="#41959996">prev</a><span>|</span><a href="#41959753">next</a><span>|</span><label class="collapse" for="c-41958286">[-]</label><label class="expand" for="c-41958286">[1 more]</label></div><br/><div class="children"><div class="content">Fully agreed.<p>It&#x27;s bad enough when human team members are submitting useless, brittle tests with their PR&#x27;s just to satisfy some org pressure to write them. The lazy ones provide a false sense of security even though they neglect critical scenarios, the unstable ones undermine trust in the test output because they intermittently raise false negatives that nobody has time to debug, and the pointless ones do nothing but reify architecture so it becomes too laborious to refactor anything.<p>As contextually aware generators, there are doubtless good uses for LLM&#x27;s in test developement, but (as with many other domains) they threaten to amplify an already troubling problem with low-quality, high-volume content spam.</div><br/></div></div><div id="41959753" class="c"><input type="checkbox" id="c-41959753" checked=""/><div class="controls bullet"><span class="by">BeetleB</span><span>|</span><a href="#41958160">parent</a><span>|</span><a href="#41958286">prev</a><span>|</span><a href="#41958449">next</a><span>|</span><label class="collapse" for="c-41959753">[-]</label><label class="expand" for="c-41959753">[3 more]</label></div><br/><div class="children"><div class="content">Mostly agree.<p>My first thought when I read this post was: Is his goal to test the code, or validate the features?<p>The first problem is he&#x27;s providing the code, and asking for tests. If his code has a bug, the tests will enshrine those bugs. It&#x27;s like me writing some code, and then giving it to a junior colleague, not providing any context, and saying &quot;Hey, write some tests for this.&quot;<p>This is backwards. I&#x27;m not a TDD guy, but you should think of your test cases <i>independent</i> of your code.</div><br/><div id="41960192" class="c"><input type="checkbox" id="c-41960192" checked=""/><div class="controls bullet"><span class="by">_puk</span><span>|</span><a href="#41958160">root</a><span>|</span><a href="#41959753">parent</a><span>|</span><a href="#41960132">next</a><span>|</span><label class="collapse" for="c-41960192">[-]</label><label class="expand" for="c-41960192">[1 more]</label></div><br/><div class="children"><div class="content">But in a system that exists without tests (this is the real world after all), the current functionality is already enshrined in the app.<p>Adding tests that capture the current state of things, so that when that bug is uncovered tests can easily be updated to the correct functionality to prove the bug prior to fixing it is a much better place to be than the status quo.<p>The horse may have bolted from the barn, but we can at least close the farm gate in the hopes of recapturing it eventually.</div><br/></div></div><div id="41960132" class="c"><input type="checkbox" id="c-41960132" checked=""/><div class="controls bullet"><span class="by">sumedh</span><span>|</span><a href="#41958160">root</a><span>|</span><a href="#41959753">parent</a><span>|</span><a href="#41960192">prev</a><span>|</span><a href="#41958449">next</a><span>|</span><label class="collapse" for="c-41960132">[-]</label><label class="expand" for="c-41960132">[1 more]</label></div><br/><div class="children"><div class="content">&gt; not providing any context<p>You can provide the context to an AI model though, you can share the source with it.</div><br/></div></div></div></div><div id="41958449" class="c"><input type="checkbox" id="c-41958449" checked=""/><div class="controls bullet"><span class="by">viraptor</span><span>|</span><a href="#41958160">parent</a><span>|</span><a href="#41959753">prev</a><span>|</span><a href="#41960257">next</a><span>|</span><label class="collapse" for="c-41958449">[-]</label><label class="expand" for="c-41958449">[1 more]</label></div><br/><div class="children"><div class="content">Pretty much this and I prefer the opposite. &quot;Here&#x27;s the new test case from me, make the code pass it&quot; is a decent workflow with Aider.<p>I get that occasionally there are some really trivial but important tests that take time and would be nice to automate. But that&#x27;s a minority in my experience.</div><br/></div></div><div id="41960257" class="c"><input type="checkbox" id="c-41960257" checked=""/><div class="controls bullet"><span class="by">bryanrasmussen</span><span>|</span><a href="#41958160">parent</a><span>|</span><a href="#41958449">prev</a><span>|</span><a href="#41958463">next</a><span>|</span><label class="collapse" for="c-41960257">[-]</label><label class="expand" for="c-41960257">[1 more]</label></div><br/><div class="children"><div class="content">&gt;Sometimes I spend more time on the test code than the actual code (probably normal).<p>This seems like the kind of thing that should be highly dependent on the kind of project one is doing, if you have an MVP and your test code is taking longer than the actual code then it is clear the test code is antagonistic to the whole concept of an MVP.</div><br/></div></div><div id="41958463" class="c"><input type="checkbox" id="c-41958463" checked=""/><div class="controls bullet"><span class="by">skissane</span><span>|</span><a href="#41958160">parent</a><span>|</span><a href="#41960257">prev</a><span>|</span><a href="#41959675">next</a><span>|</span><label class="collapse" for="c-41958463">[-]</label><label class="expand" for="c-41958463">[4 more]</label></div><br/><div class="children"><div class="content">&gt; &quot;More tests&quot; is not the goal - you need to write high impact tests, you need to think about how to test the most of your app surface with least amount of test code.<p>Are there ways we can measure this?<p>One idea that Iâve had, is collect code coverage separately for each test. If a test isnât covering any unique code or branches, maybe it is superfluous - although not necessarily, it can make sense to separately test all the boundary conditions of a function, even if doing so doesnât hit any unique branches.<p>Maybe prefer a smaller test which covers the same code to a bigger one. However, sometimes if a test is very DRY, it can be more brittle, since it can be non-obvious how to update it to handle a code change. A repetitive test, updating it can be laborious, but at least reasonably obvious how to do so.<p>Could an LLM evaluate test quality, if you give it a prompt containing some expert advice on good and bad testing practices?</div><br/><div id="41959268" class="c"><input type="checkbox" id="c-41959268" checked=""/><div class="controls bullet"><span class="by">fijiaarone</span><span>|</span><a href="#41958160">root</a><span>|</span><a href="#41958463">parent</a><span>|</span><a href="#41959675">next</a><span>|</span><label class="collapse" for="c-41959268">[-]</label><label class="expand" for="c-41959268">[3 more]</label></div><br/><div class="children"><div class="content">Sometimes you actually have to think, or hire someone who can. 
Go join the comments section on the Goodharts Law post to go on about measuring magical metrics.</div><br/><div id="41959304" class="c"><input type="checkbox" id="c-41959304" checked=""/><div class="controls bullet"><span class="by">skissane</span><span>|</span><a href="#41958160">root</a><span>|</span><a href="#41959268">parent</a><span>|</span><a href="#41959675">next</a><span>|</span><label class="collapse" for="c-41959304">[-]</label><label class="expand" for="c-41959304">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Sometimes you actually have to think, or hire someone who can.<p>I&#x27;m perfectly capable of thinking. Thinking about &quot;how can I create a system which reduces some of my cognitive load on testing so I can spend more of my cognitive resources on other things&quot; is a particularly valuable form of thinking.<p>&gt; Go join the comments section on the Goodharts Law post to go on about measuring magical metrics.<p>That problem is when managers take a metric and turn it into a KPI. That doesn&#x27;t happen to all metrics. I can think of many metrics I&#x27;ve personally collected that no manager ever once gazed upon.<p>The real measure of a metric&#x27;s value, is how meaningful a domain expert finds it to be. And if the answer to that is &quot;not very&quot; â is that an inherent property of metrics, or a sign that the metric needs to be refined?</div><br/><div id="41959640" class="c"><input type="checkbox" id="c-41959640" checked=""/><div class="controls bullet"><span class="by">jaredsohn</span><span>|</span><a href="#41958160">root</a><span>|</span><a href="#41959304">parent</a><span>|</span><a href="#41959675">next</a><span>|</span><label class="collapse" for="c-41959640">[-]</label><label class="expand" for="c-41959640">[1 more]</label></div><br/><div class="children"><div class="content">Good tests reduce your cognitive load; you can have more confidence that code will work and spend less time worrying that someone will break it.<p>BTW, I think above are the best metrics to use for tests. Actually measuring it can be hard, but I think keeping track of when functionality doesn&#x27;t work and people break your code is a good start.<p>And I think all of this should be measured in terms of doing the right thing business logic-wise and weighing importance of what needs testing based on the business value of when things don&#x27;t work.</div><br/></div></div></div></div></div></div></div></div><div id="41959675" class="c"><input type="checkbox" id="c-41959675" checked=""/><div class="controls bullet"><span class="by">dngit</span><span>|</span><a href="#41958160">parent</a><span>|</span><a href="#41958463">prev</a><span>|</span><a href="#41959126">next</a><span>|</span><label class="collapse" for="c-41959675">[-]</label><label class="expand" for="c-41959675">[1 more]</label></div><br/><div class="children"><div class="content">Great point on focusing on high-impact tests. I agree that LLMs risk giving a false sense of coverage. Maybe a smart strategy is generating boilerplate tests while we focus on custom edge cases.</div><br/></div></div><div id="41959126" class="c"><input type="checkbox" id="c-41959126" checked=""/><div class="controls bullet"><span class="by">nrnrjrjrj</span><span>|</span><a href="#41958160">parent</a><span>|</span><a href="#41959675">prev</a><span>|</span><a href="#41960877">next</a><span>|</span><label class="collapse" for="c-41959126">[-]</label><label class="expand" for="c-41959126">[1 more]</label></div><br/><div class="children"><div class="content">There is an art to writing tests especially getting absraction levels right. For example do you integration test hitting the password field with 1000 cases or do that as a unit test, and does doing it as a unit test sufficiently cover this.<p>AI could do all this thinking in the future but not yet I believe!<p>Let alone the codebase is likely a mess of bad practice already (never seen one that isn&#x27;t! That is life) so often part of the job is leaving the campground a bit better than how you found it.<p>LLMs can help now on last mile stuff. Fill in this one test. Generate data for 100 test cases. Etc.</div><br/></div></div></div></div><div id="41960574" class="c"><input type="checkbox" id="c-41960574" checked=""/><div class="controls bullet"><span class="by">DeathArrow</span><span>|</span><a href="#41960877">prev</a><span>|</span><a href="#41959723">next</a><span>|</span><label class="collapse" for="c-41960574">[-]</label><label class="expand" for="c-41960574">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s hard to generate tests for typical C# code. Or for any context where you have external dependencies.<p>If you have injected services in your current service, the LLM doesn&#x27;t know anything about those so it makes poor guesses. You have to bring those in context, so they can be mocked properly.<p>You end up spending a lot of time guiding the LLM, so it&#x27;s not measurably faster than writing test by hand.<p>I want my prompt to be: &quot;write unit tests for XYZ method&quot; without having to accurately describe it the prompt what the method does, how it does it and why it does it. Writing too many details in the prompt takes the same time as writing the code myself.<p>Github Copilot should be better since it&#x27;s supposed to have access to you entire code base. But somehow it doesn&#x27;t look at dependencies and it just uses the knowledge of the codebase for stylistic purposes.<p>It&#x27;s probably my fault, there are for sure better ways to use LLMs for code, but I am probably not the only one who struggles.</div><br/></div></div><div id="41959723" class="c"><input type="checkbox" id="c-41959723" checked=""/><div class="controls bullet"><span class="by">mkleczek</span><span>|</span><a href="#41960574">prev</a><span>|</span><a href="#41958851">next</a><span>|</span><label class="collapse" for="c-41959723">[-]</label><label class="expand" for="c-41959723">[4 more]</label></div><br/><div class="children"><div class="content">I am very sceptical of LLM (or any AI) code generation usefulness and it does not really have anything to do with AI itself.<p>In the past I&#x27;ve been involved in several projects deeply using MDA (Model Driven Architecture) techniques which used various code generation methods to develop software. One of the main obstacles was the problem of maintaining the generated code.<p>IOW: how should we treat generated code?<p>If we treat it in the same way as code produced by humans (ie. we maintain it) then the maintenance cost grows (super-linearly) with the amount of code we generate. To make matters worse for LLM: since the code it generates is buggy it means we have more buggy code to maintain. Code review is not the answer because code review power in finding bugs is very weak.<p>This is unlike compilers (that also generate code) because we don&#x27;t maintain code generated by compilers - we regenerate it anytime we need.<p>The fundamental issue is: for a given set of requirements the goal is to produce less code, not more. _Any_ code generation (however smart it might be) goes against this goal.<p>EDIT: typos</div><br/><div id="41959769" class="c"><input type="checkbox" id="c-41959769" checked=""/><div class="controls bullet"><span class="by">mvdtnz</span><span>|</span><a href="#41959723">parent</a><span>|</span><a href="#41958851">next</a><span>|</span><label class="collapse" for="c-41959769">[-]</label><label class="expand" for="c-41959769">[3 more]</label></div><br/><div class="children"><div class="content">You should NEVER modify generated code. All of our generated code is pretended with a big comment that says &quot;GENERATED CODE DO NOT MODIFY. This code could be regenerated at any time and any changes will be lost.&quot;<p>If you need to change behaviour of generated code you need to change your generator to provide the right hooks.<p>Obviously none of this applies to &quot;AI&quot; generated code because the &quot;AI&quot; generator is not deterministic and will hallucinate different bugs from run to run. You must treat &quot;AI&quot; generated code as if it was written by the dumbest person you&#x27;ve ever worked with.</div><br/><div id="41959777" class="c"><input type="checkbox" id="c-41959777" checked=""/><div class="controls bullet"><span class="by">mkleczek</span><span>|</span><a href="#41959723">root</a><span>|</span><a href="#41959769">parent</a><span>|</span><a href="#41959927">next</a><span>|</span><label class="collapse" for="c-41959777">[-]</label><label class="expand" for="c-41959777">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s exactly my point :)</div><br/></div></div><div id="41959927" class="c"><input type="checkbox" id="c-41959927" checked=""/><div class="controls bullet"><span class="by">fragmede</span><span>|</span><a href="#41959723">root</a><span>|</span><a href="#41959769">parent</a><span>|</span><a href="#41959777">prev</a><span>|</span><a href="#41958851">next</a><span>|</span><label class="collapse" for="c-41959927">[-]</label><label class="expand" for="c-41959927">[1 more]</label></div><br/><div class="children"><div class="content">The reason you don&#x27;t modify generated code is it gets clobbered upon regeneration. The reason it&#x27;s okay to modify LLM-generated code is that it gets fed that back into the LLM for subsequent modification.</div><br/></div></div></div></div></div></div><div id="41958851" class="c"><input type="checkbox" id="c-41958851" checked=""/><div class="controls bullet"><span class="by">mastersummoner</span><span>|</span><a href="#41959723">prev</a><span>|</span><a href="#41958562">next</a><span>|</span><label class="collapse" for="c-41958851">[-]</label><label class="expand" for="c-41958851">[1 more]</label></div><br/><div class="children"><div class="content">I actually tested Claude Sonnet to see how it would fare at writing a test suite for a background worker. My previous experience was with some version of GPT via Copilot, and it was... not good.<p>I was, however, extremely impressed with Claude this time around. Not only did it do a great job off the bat, but it taught me some techniques and tricks available in the language&#x2F;framework (Ruby, Rspec) which I wasn&#x27;t familiar with.<p>I&#x27;m certain that it helped having a decent prompt, asking it to consider all the potential user paths and edge cases, and also having a very good understanding of the code myself. Still, this was the first time for me I could honestly say that an LLM actually saved me time as a developer.</div><br/></div></div><div id="41958562" class="c"><input type="checkbox" id="c-41958562" checked=""/><div class="controls bullet"><span class="by">nazgul17</span><span>|</span><a href="#41958851">prev</a><span>|</span><a href="#41959994">next</a><span>|</span><label class="collapse" for="c-41958562">[-]</label><label class="expand" for="c-41958562">[3 more]</label></div><br/><div class="children"><div class="content">Should we not, instead, write tests ourselves and have LLMs write the code to make them pass?</div><br/><div id="41958712" class="c"><input type="checkbox" id="c-41958712" checked=""/><div class="controls bullet"><span class="by">jayd16</span><span>|</span><a href="#41958562">parent</a><span>|</span><a href="#41959994">next</a><span>|</span><label class="collapse" for="c-41958712">[-]</label><label class="expand" for="c-41958712">[2 more]</label></div><br/><div class="children"><div class="content">Just ask it to do both.</div><br/><div id="41959096" class="c"><input type="checkbox" id="c-41959096" checked=""/><div class="controls bullet"><span class="by">sdesol</span><span>|</span><a href="#41958562">root</a><span>|</span><a href="#41958712">parent</a><span>|</span><a href="#41959994">next</a><span>|</span><label class="collapse" for="c-41959096">[-]</label><label class="expand" for="c-41959096">[1 more]</label></div><br/><div class="children"><div class="content">And remember to always challenge the response with both the same and different models. No joke. Just continue the conversation for the example in the blog and ask the LLM &quot;Do you see anything wrong with the code?&quot; and it will spit out &quot;Yes&quot; and explain why.</div><br/></div></div></div></div></div></div><div id="41957714" class="c"><input type="checkbox" id="c-41957714" checked=""/><div class="controls bullet"><span class="by">iambateman</span><span>|</span><a href="#41959994">prev</a><span>|</span><a href="#41957470">next</a><span>|</span><label class="collapse" for="c-41957714">[-]</label><label class="expand" for="c-41957714">[2 more]</label></div><br/><div class="children"><div class="content">I did this for Laravel a few months ago and itâs great. Itâs basically the same as the article describes, and it has definitely increased the number of tests I write.<p>Happy to open source if anyone is interested.</div><br/><div id="41959887" class="c"><input type="checkbox" id="c-41959887" checked=""/><div class="controls bullet"><span class="by">frays</span><span>|</span><a href="#41957714">parent</a><span>|</span><a href="#41957470">next</a><span>|</span><label class="collapse" for="c-41959887">[-]</label><label class="expand" for="c-41959887">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;d certainly be interested to read more about your experience!</div><br/></div></div></div></div><div id="41957470" class="c"><input type="checkbox" id="c-41957470" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#41957714">prev</a><span>|</span><a href="#41957510">next</a><span>|</span><label class="collapse" for="c-41957470">[-]</label><label class="expand" for="c-41957470">[2 more]</label></div><br/><div class="children"><div class="content">If you add &quot;white-space: pre-wrap&quot; to the elements containing those prompt examples you&#x27;ll avoid the horizontal scrollbar (which I&#x27;m getting even on desktop) and make them easier to read.</div><br/><div id="41957638" class="c"><input type="checkbox" id="c-41957638" checked=""/><div class="controls bullet"><span class="by">johnjwang</span><span>|</span><a href="#41957470">parent</a><span>|</span><a href="#41957510">next</a><span>|</span><label class="collapse" for="c-41957638">[-]</label><label class="expand" for="c-41957638">[1 more]</label></div><br/><div class="children"><div class="content">Thanks for the suggestion -- I&#x27;ll take a look into adding this!</div><br/></div></div></div></div><div id="41957510" class="c"><input type="checkbox" id="c-41957510" checked=""/><div class="controls bullet"><span class="by">satisfice</span><span>|</span><a href="#41957470">prev</a><span>|</span><a href="#41958183">next</a><span>|</span><label class="collapse" for="c-41957510">[-]</label><label class="expand" for="c-41957510">[18 more]</label></div><br/><div class="children"><div class="content">Like nearly all the articles about AI doing &quot;testing&quot; or any other skilled activity, the last part of it admits that it is an unreliable method. What I don&#x27;t see in this article-- which I suspect is because they haven&#x27;t done any-- is any description of a competent and reasonably complete testing process of this method of writing &quot;tests.&quot; What they probably did is to try this, feel good about it (because testing is not their passion, so they are easily impressed), and then mark it off in their minds as a solved problem.<p>The retort by AI fanboys is always &quot;humans are unreliable, too.&quot; Yes, they are. But they have other important qualities: accountability, humility, legibility, and the ability to learn experientially as well as conceptually.<p>LLM&#x27;s are good at instantiating typical or normal patterns (based on its training data). Skilled testing cannot be limited to typicality, although that&#x27;s a start. What I&#x27;d say is that this is an interesting idea that has an important hazard associated with it: complacency on the part of the developer who uses this method, which turns things that COULD be missed by a skilled tester into things that are GUARANTEED to be missed.</div><br/><div id="41957633" class="c"><input type="checkbox" id="c-41957633" checked=""/><div class="controls bullet"><span class="by">johnjwang</span><span>|</span><a href="#41957510">parent</a><span>|</span><a href="#41957928">next</a><span>|</span><label class="collapse" for="c-41957633">[-]</label><label class="expand" for="c-41957633">[3 more]</label></div><br/><div class="children"><div class="content">Author here: Yes, there are certain functions where writing good tests will be difficult for an LLM, but in my experience I&#x27;ve found that the majority of functions that I write don&#x27;t need anything out of the ordinary and are relatively straightforward.<p>Using LLMs allows us to have much higher coverage than if we didn&#x27;t use it. To me and our engineering team, this is a pretty good thing because in the time prioritization matrix, if I can get a higher quality code base with higher test coverage with minimal extra work, I will definitely take it (and in fact it&#x27;s something I encourage our engineering teams to do).<p>Most of the base tests that we use were created originally by some of our best engineers. The patterns they developed are used throughout our code base and LLMs can take these and make our code very consistent, which I also view as a plus.<p>re: Complacency: We actually haven&#x27;t found this to be the case. In fact, we&#x27;ve seen more tests being written with this method. Just think about how much easier it is to review a PR and make edits vs write a PR. You can actually spend your time enforcing higher quality tests because you don&#x27;t have to do most of the boilerplate for writing a test.</div><br/><div id="41957843" class="c"><input type="checkbox" id="c-41957843" checked=""/><div class="controls bullet"><span class="by">youoy</span><span>|</span><a href="#41957510">root</a><span>|</span><a href="#41957633">parent</a><span>|</span><a href="#41958264">next</a><span>|</span><label class="collapse" for="c-41957843">[-]</label><label class="expand" for="c-41957843">[1 more]</label></div><br/><div class="children"><div class="content">I would say that the complacency part is identifying good test with good coverage. I agree that writing test is one of the best use cases for LLMs, and it definitely saves engineers a lot of time. But if you follow them to blindly it is easy to get carried away by how easy it is to write tests that focus on coverage instead of actually testing more quality things. Which is what the previous comment was pointing at:<p>&gt; which turns things that COULD be missed by a skilled tester into things that are GUARANTEED to be missed.</div><br/></div></div><div id="41958264" class="c"><input type="checkbox" id="c-41958264" checked=""/><div class="controls bullet"><span class="by">satisfice</span><span>|</span><a href="#41957510">root</a><span>|</span><a href="#41957633">parent</a><span>|</span><a href="#41957843">prev</a><span>|</span><a href="#41957928">next</a><span>|</span><label class="collapse" for="c-41958264">[-]</label><label class="expand" for="c-41958264">[1 more]</label></div><br/><div class="children"><div class="content">Have you systematically tested this approach? It sounds like you are reporting on your good vibes. Your writing is strictly anecdotal.<p>Iâve been working with AI, too. I see what Iâm guessing is the same unreliability that you admit in the last part of your article. For some reason, you are sanguine about it, whereas I see it as a serious problem.<p>You say you arenât complacent, but your words donât seem to address the complacency issue. âMore testsâ does not mean better testing, or even good enough testing.<p>Google âautomation biasâ and tell me what policies and procedures or training is in place to avoid it.</div><br/></div></div></div></div><div id="41957928" class="c"><input type="checkbox" id="c-41957928" checked=""/><div class="controls bullet"><span class="by">wenc</span><span>|</span><a href="#41957510">parent</a><span>|</span><a href="#41957633">prev</a><span>|</span><a href="#41957657">next</a><span>|</span><label class="collapse" for="c-41957928">[-]</label><label class="expand" for="c-41957928">[1 more]</label></div><br/><div class="children"><div class="content">I do use LLMs to bootsrap my unit testing (because there is a lot boilerplate in unit tests and mocks), but I tend to finish the unit tests myself. This gives me confidence that my tests are accurate to the best of my knowledge.<p>Having good tests allows me to be more liberal with LLMs on implementation. I still only use LLMs to bootstrap the implementation, and I finish it myself. LLMs, being generative, are really good for ideating different implementations (it proposes implementations that I would never have thought of), but I never take any implementation as-is -- I always try to step through it and finish it off manually.<p>Some might argue that it&#x27;d be faster if I wrote the entire thing myself, but it depends on the problem domain. So much of what I do is involve implementing code for unsolved problems (I&#x27;m not writing CRUD apps for instance) that I really do get a speed-up from LLMs.<p>I imagine folks writing conventional code might spend more time fixing LLM mistakes and thus think that LLMs slow them down. But this is not true for my problem domain.</div><br/></div></div><div id="41957657" class="c"><input type="checkbox" id="c-41957657" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#41957510">parent</a><span>|</span><a href="#41957928">prev</a><span>|</span><a href="#41958183">next</a><span>|</span><label class="collapse" for="c-41957657">[-]</label><label class="expand" for="c-41957657">[13 more]</label></div><br/><div class="children"><div class="content">The answer to this is code review. If an LLM writes code for you - be it implementation or tests - you review it before you land it.<p>If you don&#x27;t understand how the code works, don&#x27;t approve it.<p>Sure, complacent developers will get burned. They&#x27;ll find plenty of other non-AI ways to burn themselves too.</div><br/><div id="41957833" class="c"><input type="checkbox" id="c-41957833" checked=""/><div class="controls bullet"><span class="by">hitradostava</span><span>|</span><a href="#41957510">root</a><span>|</span><a href="#41957657">parent</a><span>|</span><a href="#41958183">next</a><span>|</span><label class="collapse" for="c-41957833">[-]</label><label class="expand" for="c-41957833">[12 more]</label></div><br/><div class="children"><div class="content">100% agree. We don&#x27;t expect human developers to be perfect, why should we expect AI assistants. Code going to production should go through review.<p>I do think that LLMs will increase the volume of bad code though. I use Cursor a lot, and occasionally it will produce perfect code, but often I need to direct and refine, and sometimes throw away. But I&#x27;m sure many devs will get lazy and just push once they&#x27;ve got the thing working...</div><br/><div id="41958043" class="c"><input type="checkbox" id="c-41958043" checked=""/><div class="controls bullet"><span class="by">sdesol</span><span>|</span><a href="#41957510">root</a><span>|</span><a href="#41957833">parent</a><span>|</span><a href="#41959390">next</a><span>|</span><label class="collapse" for="c-41958043">[-]</label><label class="expand" for="c-41958043">[6 more]</label></div><br/><div class="children"><div class="content">&gt; 100% agree. We don&#x27;t expect human developers to be perfect, why should we expect AI assistants.<p>I think the issue is that we are currently being sold that it is. I&#x27;m blown away by how useful AI is, and how stupid it can be at the same time.  Take a look at the following example:<p><a href="https:&#x2F;&#x2F;app.gitsense.com&#x2F;?doc=f7419bfb27c896&amp;highlight=&amp;other-models=Claude+3.5+Sonnet%2CGPT-4o%2CLlama+3.1+70B&amp;samples=5" rel="nofollow">https:&#x2F;&#x2F;app.gitsense.com&#x2F;?doc=f7419bfb27c896&amp;highlight=&amp;othe...</a><p>If you click on the sentence, you can see how dumb Sonnet-3.5 and GPT-4 can be. Each model was asked to spell-check and grammar-check the sentence 5 times each, and you can see that GPT-4o-mini was the only one that got this right all 5 times.  The other models mostly got it comically wrong.<p>I believe LLM is going to change things for the better for developers, but we need to properly set expectations. I suspect this will be difficult, since a lot of VC money is being pumped into AI.<p>I also think a lot of mistakes can be prevented if you include in your prompt, how and why it did what it did.  For example, the prompt that was used in the blog post should include &quot;After writing the test, summarize how each rule was applied.&quot;</div><br/><div id="41958128" class="c"><input type="checkbox" id="c-41958128" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#41957510">root</a><span>|</span><a href="#41958043">parent</a><span>|</span><a href="#41959390">next</a><span>|</span><label class="collapse" for="c-41958128">[-]</label><label class="expand" for="c-41958128">[5 more]</label></div><br/><div class="children"><div class="content">&quot;I think the issue is that we are currently being sold that it is.&quot;<p>The message that these systems are flawed appears to be pretty universal to me:<p>ChatGPT footer: &quot;ChatGPT can make mistakes. Check important info.&quot;<p>Claude footer: &quot;Claude can make mistakes. Please double-check responses.&quot;<p><a href="https:&#x2F;&#x2F;www.meta.ai&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.meta.ai&#x2F;</a> &quot;Messages are generated by AI and may be inaccurate or inappropriate.&quot;<p>etc etc etc.<p>I still think the problem here is science fiction. We have decades of sci-fi telling us that AI systems never make mistakes, but instead will cause harm by following their rules too closely (paperclip factories, 2001: A Space Odyssey etc).<p>Turns out the actual AI systems we have make mistakes all the time.</div><br/><div id="41959788" class="c"><input type="checkbox" id="c-41959788" checked=""/><div class="controls bullet"><span class="by">DanHulton</span><span>|</span><a href="#41957510">root</a><span>|</span><a href="#41958128">parent</a><span>|</span><a href="#41958214">next</a><span>|</span><label class="collapse" for="c-41959788">[-]</label><label class="expand" for="c-41959788">[1 more]</label></div><br/><div class="children"><div class="content">But on the other other hand, there&#x27;s the commercials generated to sell new models or new model features, that FREQUENTLY lie about actual capabilities and fake demos and don&#x27;t actually end with an equivalent amount of time going over how actual usage may be shit and completely unlike the advertisement.<p>I&#x27;d say parent is absolutely correct - we ARE being sold (quite literally, through promotional material, i.e. ads) that these models are way more capable than they actually are.</div><br/></div></div><div id="41958214" class="c"><input type="checkbox" id="c-41958214" checked=""/><div class="controls bullet"><span class="by">sdesol</span><span>|</span><a href="#41957510">root</a><span>|</span><a href="#41958128">parent</a><span>|</span><a href="#41959788">prev</a><span>|</span><a href="#41958535">next</a><span>|</span><label class="collapse" for="c-41958214">[-]</label><label class="expand" for="c-41958214">[1 more]</label></div><br/><div class="children"><div class="content">You do have to admit, the footer is extremely small and it&#x27;s also not in the most prominent place. I think most &quot;AI companies&quot; probably don&#x27;t go into a sales pitch saying &quot;It&#x27;s awesome, but it might be full of shit&quot;.<p>I do see your science fiction angle, but I think the bigger issue is the media, VCs, etc. are not clearly spelling out that we are nowhere near science fiction AI.</div><br/></div></div><div id="41958535" class="c"><input type="checkbox" id="c-41958535" checked=""/><div class="controls bullet"><span class="by">jazzyjackson</span><span>|</span><a href="#41957510">root</a><span>|</span><a href="#41958128">parent</a><span>|</span><a href="#41958214">prev</a><span>|</span><a href="#41959390">next</a><span>|</span><label class="collapse" for="c-41958535">[-]</label><label class="expand" for="c-41958535">[2 more]</label></div><br/><div class="children"><div class="content">I appreciate the footer on Kagi Assistant: &quot;Assistant can make mistakes. Think for yourself when using it&quot; - a reminder that theres a tendency to outsource your own train of thought</div><br/><div id="41958960" class="c"><input type="checkbox" id="c-41958960" checked=""/><div class="controls bullet"><span class="by">sdesol</span><span>|</span><a href="#41957510">root</a><span>|</span><a href="#41958535">parent</a><span>|</span><a href="#41959390">next</a><span>|</span><label class="collapse" for="c-41958960">[-]</label><label class="expand" for="c-41958960">[1 more]</label></div><br/><div class="children"><div class="content">I would have to imagine 90+ percent of people use LLM and AI to outsource their thought and most will not heed this warning.  OpenAI might say &quot;Check important info.&quot; but they know most people probably won&#x27;t do a google search or visit their library to fact check things.</div><br/></div></div></div></div></div></div></div></div><div id="41959390" class="c"><input type="checkbox" id="c-41959390" checked=""/><div class="controls bullet"><span class="by">mvdtnz</span><span>|</span><a href="#41957510">root</a><span>|</span><a href="#41957833">parent</a><span>|</span><a href="#41958043">prev</a><span>|</span><a href="#41958183">next</a><span>|</span><label class="collapse" for="c-41959390">[-]</label><label class="expand" for="c-41959390">[5 more]</label></div><br/><div class="children"><div class="content">&gt; We don&#x27;t expect human developers to be perfect, why should we expect AI assistants.<p>What absolute nonsense. What an absurd false equivalence. It&#x27;s not that we expect perfection or even human level performance from &quot;AI&quot;. It&#x27;s that the crap that comes out of LLMs is not even at the level of a first year student. I&#x27;ve never in my entire life reviewed the code of a junior engineer and seen them invent third party APIs from whole cloth. I&#x27;ve never had a junior send me code that generates a payload that doesn&#x27;t validate at the first layer of the operation with zero manual testing to check it. No junior has ever asked me to review a pull request containing references to an open source framework that doesn&#x27;t exist anywhere in my application. Yet these scenarios are commonplace in &quot;AI&quot; generated code.</div><br/><div id="41959783" class="c"><input type="checkbox" id="c-41959783" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#41957510">root</a><span>|</span><a href="#41959390">parent</a><span>|</span><a href="#41958183">next</a><span>|</span><label class="collapse" for="c-41959783">[-]</label><label class="expand" for="c-41959783">[4 more]</label></div><br/><div class="children"><div class="content">That problem genuinely doesn&#x27;t matter to me at all.<p>If an LLM hallucinates a method that doesn&#x27;t exist I find out the moment I try and run the code.<p>If I&#x27;m using ChatGPT Code Interpreter (for Python) or Claude analysis mode (for JavaScript) I don&#x27;t even have to intervene: the LLM can run in a loop, generating code, testing that it executes without errors and correcting any mistakes it makes.<p>I still need to carefully review the code, but the mistakes which cause it not to run at all are by far the least amount of work to identify.</div><br/><div id="41960068" class="c"><input type="checkbox" id="c-41960068" checked=""/><div class="controls bullet"><span class="by">mvdtnz</span><span>|</span><a href="#41957510">root</a><span>|</span><a href="#41959783">parent</a><span>|</span><a href="#41958183">next</a><span>|</span><label class="collapse" for="c-41960068">[-]</label><label class="expand" for="c-41960068">[3 more]</label></div><br/><div class="children"><div class="content">Yes I&#x27;ve seen the dreck you produce with LLMs. Not a shining endorsement in my eyes.<p><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=41929174">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=41929174</a></div><br/><div id="41960126" class="c"><input type="checkbox" id="c-41960126" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#41957510">root</a><span>|</span><a href="#41960068">parent</a><span>|</span><a href="#41958183">next</a><span>|</span><label class="collapse" for="c-41960126">[-]</label><label class="expand" for="c-41960126">[2 more]</label></div><br/><div class="children"><div class="content">Which of those did you think were dreck?<p>I think the source code for tools like this one is genuinely good code: <a href="https:&#x2F;&#x2F;github.com&#x2F;simonw&#x2F;tools&#x2F;blob&#x2F;main&#x2F;extract-urls.html">https:&#x2F;&#x2F;github.com&#x2F;simonw&#x2F;tools&#x2F;blob&#x2F;main&#x2F;extract-urls.html</a><p>What do you see that&#x27;s wrong with that?</div><br/><div id="41960239" class="c"><input type="checkbox" id="c-41960239" checked=""/><div class="controls bullet"><span class="by">mvdtnz</span><span>|</span><a href="#41957510">root</a><span>|</span><a href="#41960126">parent</a><span>|</span><a href="#41958183">next</a><span>|</span><label class="collapse" for="c-41960239">[-]</label><label class="expand" for="c-41960239">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a toy. It doesn&#x27;t do useful work. The code is fine for the pathetically small sample but that coding style does not scale to real software scales.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="41958183" class="c"><input type="checkbox" id="c-41958183" checked=""/><div class="controls bullet"><span class="by">apwell23</span><span>|</span><a href="#41957510">prev</a><span>|</span><a href="#41936991">next</a><span>|</span><label class="collapse" for="c-41958183">[-]</label><label class="expand" for="c-41958183">[3 more]</label></div><br/><div class="children"><div class="content">i would love to used to use it change code in ways that compiles and see if test fails. Coverage metric sometimes doesn&#x27;t really tell you if some piece of code is covered or not.</div><br/><div id="41958643" class="c"><input type="checkbox" id="c-41958643" checked=""/><div class="controls bullet"><span class="by">taberiand</span><span>|</span><a href="#41958183">parent</a><span>|</span><a href="#41958414">next</a><span>|</span><label class="collapse" for="c-41958643">[-]</label><label class="expand" for="c-41958643">[1 more]</label></div><br/><div class="children"><div class="content">I believe that&#x27;s called mutation testing. Using an LLM to perform the mutation sounds like a great idea</div><br/></div></div><div id="41958414" class="c"><input type="checkbox" id="c-41958414" checked=""/><div class="controls bullet"><span class="by">sesm</span><span>|</span><a href="#41958183">parent</a><span>|</span><a href="#41958643">prev</a><span>|</span><a href="#41936991">next</a><span>|</span><label class="collapse" for="c-41958414">[-]</label><label class="expand" for="c-41958414">[1 more]</label></div><br/><div class="children"><div class="content">Coverage metric can tell if lines of code were executed, but they can&#x27;t tell if execution result was checked.</div><br/></div></div></div></div></div></div></div></div></div></body></html>