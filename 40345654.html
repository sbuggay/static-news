<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1715677264332" as="style"/><link rel="stylesheet" href="styles.css?v=1715677264332"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://chaphlagical.icu/Deblur-GS/">Deblur-GS: 3D Gaussian splatting from camera motion blurred images</a> <span class="domain">(<a href="https://chaphlagical.icu">chaphlagical.icu</a>)</span></div><div class="subtext"><span>smusamashah</span> | <span>35 comments</span></div><br/><div><div id="40349791" class="c"><input type="checkbox" id="c-40349791" checked=""/><div class="controls bullet"><span class="by">Retr0id</span><span>|</span><a href="#40351728">next</a><span>|</span><label class="collapse" for="c-40349791">[-]</label><label class="expand" for="c-40349791">[3 more]</label></div><br/><div class="children"><div class="content">The example blurred images look very &quot;clean&quot; for lack of a better term, as if they were produced synthetically by motion-blurring crisp images in a particular direction. I wonder how well it fares with real shaky-camera footage (where the path of motion blur in a given frame might not even be a straight line)</div><br/><div id="40350108" class="c"><input type="checkbox" id="c-40350108" checked=""/><div class="controls bullet"><span class="by">dylan604</span><span>|</span><a href="#40349791">parent</a><span>|</span><a href="#40351728">next</a><span>|</span><label class="collapse" for="c-40350108">[-]</label><label class="expand" for="c-40350108">[2 more]</label></div><br/><div class="children"><div class="content">So much so, to me it looks like they took the clean image and added the blur in post, but I really do not believe nor claim that&#x27;s what they did. It&#x27;s just what it looks like. The speeds of the motion aren&#x27;t even the same, so the interpolation is just off which is what gives it the uncanny valley feeling for me.</div><br/><div id="40350961" class="c"><input type="checkbox" id="c-40350961" checked=""/><div class="controls bullet"><span class="by">synapticpaint</span><span>|</span><a href="#40349791">root</a><span>|</span><a href="#40350108">parent</a><span>|</span><a href="#40351728">next</a><span>|</span><label class="collapse" for="c-40350961">[-]</label><label class="expand" for="c-40350961">[1 more]</label></div><br/><div class="children"><div class="content">The camera motions do not need to be the same. Gaussian splatting reconstructs the scene in 3d, and you can then render the scene from arbitrary angles, so they just gave it a random camera motion to show you the 3dness of it.</div><br/></div></div></div></div></div></div><div id="40351728" class="c"><input type="checkbox" id="c-40351728" checked=""/><div class="controls bullet"><span class="by">1-6</span><span>|</span><a href="#40349791">prev</a><span>|</span><a href="#40347188">next</a><span>|</span><label class="collapse" for="c-40351728">[-]</label><label class="expand" for="c-40351728">[1 more]</label></div><br/><div class="children"><div class="content">I’m interested in the number of unsolved cases this tech will help solve.</div><br/></div></div><div id="40347188" class="c"><input type="checkbox" id="c-40347188" checked=""/><div class="controls bullet"><span class="by">zevv</span><span>|</span><a href="#40351728">prev</a><span>|</span><a href="#40347445">next</a><span>|</span><label class="collapse" for="c-40347188">[-]</label><label class="expand" for="c-40347188">[11 more]</label></div><br/><div class="children"><div class="content">My friend doesn&#x27;t quite grasp this yet, can someone explain? Is the reconstructed detail all &quot;real&quot; and extracted from the blurred input, or is there some model at work here, filling in the image with plausible details, but basically making up stuff that was not really there to start with?</div><br/><div id="40348410" class="c"><input type="checkbox" id="c-40348410" checked=""/><div class="controls bullet"><span class="by">peppertree</span><span>|</span><a href="#40347188">parent</a><span>|</span><a href="#40348308">next</a><span>|</span><label class="collapse" for="c-40348410">[-]</label><label class="expand" for="c-40348410">[3 more]</label></div><br/><div class="children"><div class="content">No it does not &quot;make up things&quot; using generative AI. Current GS implementations assume camera poses are static. This paper assigns a linear motion trajectory to camera during training.</div><br/><div id="40348732" class="c"><input type="checkbox" id="c-40348732" checked=""/><div class="controls bullet"><span class="by">creativeSlumber</span><span>|</span><a href="#40347188">root</a><span>|</span><a href="#40348410">parent</a><span>|</span><a href="#40348308">next</a><span>|</span><label class="collapse" for="c-40348732">[-]</label><label class="expand" for="c-40348732">[2 more]</label></div><br/><div class="children"><div class="content">So can it handle when both camera and multiple objects in scene are moving in different trajectories?</div><br/><div id="40348780" class="c"><input type="checkbox" id="c-40348780" checked=""/><div class="controls bullet"><span class="by">dheera</span><span>|</span><a href="#40347188">root</a><span>|</span><a href="#40348732">parent</a><span>|</span><a href="#40348308">next</a><span>|</span><label class="collapse" for="c-40348780">[-]</label><label class="expand" for="c-40348780">[1 more]</label></div><br/><div class="children"><div class="content">Not with traditional 3D Gaussian splatting, but it is potentially possible to separate the time axis and do a 4D Gaussian splatting with some regularization to accommodate dynamic scenes.<p>Here&#x27;s some early work in this area which seems promising:
<a href="https:&#x2F;&#x2F;guanjunwu.github.io&#x2F;4dgs&#x2F;" rel="nofollow">https:&#x2F;&#x2F;guanjunwu.github.io&#x2F;4dgs&#x2F;</a></div><br/></div></div></div></div></div></div><div id="40348308" class="c"><input type="checkbox" id="c-40348308" checked=""/><div class="controls bullet"><span class="by">tomp</span><span>|</span><a href="#40347188">parent</a><span>|</span><a href="#40348410">prev</a><span>|</span><a href="#40347436">next</a><span>|</span><label class="collapse" for="c-40348308">[-]</label><label class="expand" for="c-40348308">[3 more]</label></div><br/><div class="children"><div class="content">I skimmed the Overview and am not an expert.<p>It seems to me they don&#x27;t use any ML at all. They use backpropagation to jointly optimise the entire physics&#x2F;motion model, which models camera motion and the generated blurry images (they generate multiple images for each camera frame along the path of motion of the camera, and then merge them, simulating motion blur)</div><br/><div id="40348572" class="c"><input type="checkbox" id="c-40348572" checked=""/><div class="controls bullet"><span class="by">dheera</span><span>|</span><a href="#40347188">root</a><span>|</span><a href="#40348308">parent</a><span>|</span><a href="#40347436">next</a><span>|</span><label class="collapse" for="c-40348572">[-]</label><label class="expand" for="c-40348572">[2 more]</label></div><br/><div class="children"><div class="content">It is ML in the sense of optimizing a nonconvex loss function over a dataset. It is not a fancy diffusion model or even a generative model, but it is no less a machine learning problem.</div><br/><div id="40348595" class="c"><input type="checkbox" id="c-40348595" checked=""/><div class="controls bullet"><span class="by">tomp</span><span>|</span><a href="#40347188">root</a><span>|</span><a href="#40348572">parent</a><span>|</span><a href="#40347436">next</a><span>|</span><label class="collapse" for="c-40348595">[-]</label><label class="expand" for="c-40348595">[1 more]</label></div><br/><div class="children"><div class="content">“Not ML” as in “not learning from data to apply in new situations” but rather they do “mathematical optimisation”.<p>The data they optimise over is just the images of the current camera trajectory (as far as I understand)</div><br/></div></div></div></div></div></div><div id="40347436" class="c"><input type="checkbox" id="c-40347436" checked=""/><div class="controls bullet"><span class="by">karmakaze</span><span>|</span><a href="#40347188">parent</a><span>|</span><a href="#40348308">prev</a><span>|</span><a href="#40348388">next</a><span>|</span><label class="collapse" for="c-40347436">[-]</label><label class="expand" for="c-40347436">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s accurate. What&#x27;s worth nothing though is that everything we &#x27;see&#x27; with our own eyes is constructed from sampling our environment. The image we construct is what we expected to see given the sample data. This is one reason why eyewitness testimony can be vivid and false without any foul play.</div><br/></div></div><div id="40348388" class="c"><input type="checkbox" id="c-40348388" checked=""/><div class="controls bullet"><span class="by">chpatrick</span><span>|</span><a href="#40347188">parent</a><span>|</span><a href="#40347436">prev</a><span>|</span><a href="#40351963">next</a><span>|</span><label class="collapse" for="c-40348388">[-]</label><label class="expand" for="c-40348388">[1 more]</label></div><br/><div class="children"><div class="content">Gaussian blur is a reversible operation, but in practice it&#x27;s not possible on still images. With multiple pictures you might have enough information.</div><br/></div></div><div id="40351963" class="c"><input type="checkbox" id="c-40351963" checked=""/><div class="controls bullet"><span class="by">choppaface</span><span>|</span><a href="#40347188">parent</a><span>|</span><a href="#40348388">prev</a><span>|</span><a href="#40347602">next</a><span>|</span><label class="collapse" for="c-40351963">[-]</label><label class="expand" for="c-40351963">[1 more]</label></div><br/><div class="children"><div class="content">Gaussian Splatting creates an &quot;approximation&quot; of a 3D scene (captured from a video) using hundreds of thousands (or even millions) of tiny gaussian clouds.  Each gaussian might be as small as a couple of pixels, and all these 3D gaussians get projected onto the 2D image plane (fast in GPU) to realize a single image (i.e. a single pose of the video camera).  These gaussians are in 3D, so they explicitly represent the scene geometry e.g. real physical surfaces, and an approximation of physical textures.  When a camera blurs an image, the physical surface &#x2F; object gets blurred across many pixels.  But if you can reconstruct the 3D scene accurately, then you can re-project the 3D gaussians into 2D images that end up <i>not blurry</i>.  Another way to view the OP is that this technique is a tweak to the &quot;sharp images only&quot; Gaussian Splatting work from last year to deal with blurry images.<p>The OP paper is cool but isn&#x27;t alone, here&#x27;s some concurrent work: <a href="https:&#x2F;&#x2F;github.com&#x2F;SpectacularAI&#x2F;3dgs-deblur">https:&#x2F;&#x2F;github.com&#x2F;SpectacularAI&#x2F;3dgs-deblur</a><p>Also related from a couple years ago, using NeRF methods (another area of current 3D research) to denoise night images and recover HDR: <a href="https:&#x2F;&#x2F;bmild.github.io&#x2F;rawnerf&#x2F;" rel="nofollow">https:&#x2F;&#x2F;bmild.github.io&#x2F;rawnerf&#x2F;</a>    NeRF, like Gaussian Splatting, seeks to reconstruct the scene in 3D, and RawNeRF adapts the approach to deal with noisy images as well as large exposure variation.<p>In terms of Gaussian Splats vs GenAI, usually GenAI models have been trained on a prior of millions of images so that they can impute &#x2F; inference some part of the 3D scene or some part of the input images.  However Gaussian Splats (and NeRF) lack those priors.</div><br/></div></div><div id="40347602" class="c"><input type="checkbox" id="c-40347602" checked=""/><div class="controls bullet"><span class="by">barrysteve</span><span>|</span><a href="#40347188">parent</a><span>|</span><a href="#40351963">prev</a><span>|</span><a href="#40347445">next</a><span>|</span><label class="collapse" for="c-40347602">[-]</label><label class="expand" for="c-40347602">[1 more]</label></div><br/><div class="children"><div class="content">Both. The paper mentions using a deblurrer and novel view synthesis model(ExBluRF).</div><br/></div></div></div></div><div id="40347445" class="c"><input type="checkbox" id="c-40347445" checked=""/><div class="controls bullet"><span class="by">emilk</span><span>|</span><a href="#40347188">prev</a><span>|</span><a href="#40351079">next</a><span>|</span><label class="collapse" for="c-40347445">[-]</label><label class="expand" for="c-40347445">[1 more]</label></div><br/><div class="children"><div class="content">Very cool! A next step could be to model a rolling-shutter</div><br/></div></div><div id="40351079" class="c"><input type="checkbox" id="c-40351079" checked=""/><div class="controls bullet"><span class="by">sroussey</span><span>|</span><a href="#40347445">prev</a><span>|</span><a href="#40348076">next</a><span>|</span><label class="collapse" for="c-40351079">[-]</label><label class="expand" for="c-40351079">[2 more]</label></div><br/><div class="children"><div class="content">This could make various “night mode” photos much clearer. And the motion perhaps even helpful.</div><br/><div id="40351477" class="c"><input type="checkbox" id="c-40351477" checked=""/><div class="controls bullet"><span class="by">luyu_wu</span><span>|</span><a href="#40351079">parent</a><span>|</span><a href="#40348076">next</a><span>|</span><label class="collapse" for="c-40351477">[-]</label><label class="expand" for="c-40351477">[1 more]</label></div><br/><div class="children"><div class="content">Huawei does something similar with an algorithm on their newest phones. AFAIK it&#x27;s a double exposure recombination method though, not gaussian splatting, cool nonetheless!</div><br/></div></div></div></div><div id="40348076" class="c"><input type="checkbox" id="c-40348076" checked=""/><div class="controls bullet"><span class="by">tomaskafka</span><span>|</span><a href="#40351079">prev</a><span>|</span><a href="#40349009">next</a><span>|</span><label class="collapse" for="c-40348076">[-]</label><label class="expand" for="c-40348076">[1 more]</label></div><br/><div class="children"><div class="content">Absolutely impressive - seems on par with what&#x27;s happening in our eyes and brain. If this becomes realtime, we could turn the noisy low fps image from cameras on AR headsets in dark environments into smooth bright image.</div><br/></div></div><div id="40349009" class="c"><input type="checkbox" id="c-40349009" checked=""/><div class="controls bullet"><span class="by">adkaplan</span><span>|</span><a href="#40348076">prev</a><span>|</span><a href="#40349224">next</a><span>|</span><label class="collapse" for="c-40349009">[-]</label><label class="expand" for="c-40349009">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20240511220923&#x2F;https:&#x2F;&#x2F;chaphlagical.icu&#x2F;Deblur-GS&#x2F;" rel="nofollow">https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20240511220923&#x2F;https:&#x2F;&#x2F;chaphlagi...</a><p>Down for me, archive above.</div><br/></div></div><div id="40349224" class="c"><input type="checkbox" id="c-40349224" checked=""/><div class="controls bullet"><span class="by">smusamashah</span><span>|</span><a href="#40349009">prev</a><span>|</span><a href="#40352234">next</a><span>|</span><label class="collapse" for="c-40349224">[-]</label><label class="expand" for="c-40349224">[1 more]</label></div><br/><div class="children"><div class="content">The reconstruction looks even better than ground truth images in their examples.</div><br/></div></div><div id="40352234" class="c"><input type="checkbox" id="c-40352234" checked=""/><div class="controls bullet"><span class="by">DeathArrow</span><span>|</span><a href="#40349224">prev</a><span>|</span><a href="#40347115">next</a><span>|</span><label class="collapse" for="c-40352234">[-]</label><label class="expand" for="c-40352234">[1 more]</label></div><br/><div class="children"><div class="content">What benefits does it have over existing algorithms such as ESRGAN, CCSR, DAT, SPAN, SUPIR?</div><br/></div></div><div id="40347115" class="c"><input type="checkbox" id="c-40347115" checked=""/><div class="controls bullet"><span class="by">nathancahill</span><span>|</span><a href="#40352234">prev</a><span>|</span><a href="#40348197">next</a><span>|</span><label class="collapse" for="c-40347115">[-]</label><label class="expand" for="c-40347115">[1 more]</label></div><br/><div class="children"><div class="content">I know it&#x27;s a meme at this point but this is real life &quot;Enhance please&quot;. Incredibly impressive what we&#x27;re able to do to reconstruct missing data.</div><br/></div></div><div id="40348197" class="c"><input type="checkbox" id="c-40348197" checked=""/><div class="controls bullet"><span class="by">borgchick</span><span>|</span><a href="#40347115">prev</a><span>|</span><a href="#40351531">next</a><span>|</span><label class="collapse" for="c-40348197">[-]</label><label class="expand" for="c-40348197">[2 more]</label></div><br/><div class="children"><div class="content">finally, all the UFO videos can be clear!</div><br/><div id="40349339" class="c"><input type="checkbox" id="c-40349339" checked=""/><div class="controls bullet"><span class="by">bee_rider</span><span>|</span><a href="#40348197">parent</a><span>|</span><a href="#40351531">next</a><span>|</span><label class="collapse" for="c-40349339">[-]</label><label class="expand" for="c-40349339">[1 more]</label></div><br/><div class="children"><div class="content">The aliens are actually pan-dimensional light beings. That is why they are afraid of high quality cameras, if they get caught in a photo they are stuck here forever. Running this algorithm on pictures of UFOs is actually an intergalactic warcrime.</div><br/></div></div></div></div><div id="40351531" class="c"><input type="checkbox" id="c-40351531" checked=""/><div class="controls bullet"><span class="by">dukeofdoom</span><span>|</span><a href="#40348197">prev</a><span>|</span><a href="#40348226">next</a><span>|</span><label class="collapse" for="c-40351531">[-]</label><label class="expand" for="c-40351531">[2 more]</label></div><br/><div class="children"><div class="content">The opposite might be useful too. Often when shooting outside there is too much light, and a high shutter speed is automatically used. Resulting in footage that has not enough motion blur. Ideally you would want to have the shutter speed at twice the frame rate for smooth looking motion blur. 
But I think this might be a little harder to add in camera or post. For example when filming someone &quot;talking with their hands&quot;. You would want to add blur to their hands, but not necessarily to their head which is probably mostly stationary.</div><br/><div id="40351553" class="c"><input type="checkbox" id="c-40351553" checked=""/><div class="controls bullet"><span class="by">klysm</span><span>|</span><a href="#40351531">parent</a><span>|</span><a href="#40348226">next</a><span>|</span><label class="collapse" for="c-40351553">[-]</label><label class="expand" for="c-40351553">[1 more]</label></div><br/><div class="children"><div class="content">I’m not sure it works out that simply in practice because of camera movement vs subject movement</div><br/></div></div></div></div><div id="40348226" class="c"><input type="checkbox" id="c-40348226" checked=""/><div class="controls bullet"><span class="by">germinator</span><span>|</span><a href="#40351531">prev</a><span>|</span><label class="collapse" for="c-40348226">[-]</label><label class="expand" for="c-40348226">[7 more]</label></div><br/><div class="children"><div class="content">I really want to be impressed, but I&#x27;ve been reading papers about breakthroughs in deblurring and upscaling for two decades now, and the state of the art in commercial and open-source tools is still pretty underwhelming. Chances are, if you have a low-res keepsake photo, or take a blurry nature shot, you&#x27;re gonna be stuck with that.<p>Video, where the result needs to be temporally coherent and make sense in 3D, can&#x27;t be the easier one.</div><br/><div id="40349859" class="c"><input type="checkbox" id="c-40349859" checked=""/><div class="controls bullet"><span class="by">contravariant</span><span>|</span><a href="#40348226">parent</a><span>|</span><a href="#40351765">next</a><span>|</span><label class="collapse" for="c-40349859">[-]</label><label class="expand" for="c-40349859">[1 more]</label></div><br/><div class="children"><div class="content">At this stage there&#x27;s really only a couple of options. More than there used to be, but still.<p>When you want to stay faithful to the actual data then your options are limited, for quite a large part of the image a simple convolution is about as good as it gets, except for the edges. Basically the only problem we couldn&#x27;t solve 20 years ago was excessive ringing (which is why softer scaling algorithms were preferred). You can put quite a lot of effort into getting clearer edges, especially for thin lines, but for most content you can&#x27;t expect too much more sharpness than what the basic methods get you.<p>And then there is the generative approach where you just make stuff up. It&#x27;s quite effective but a bit iffy. It&#x27;s fine for entertainment but it&#x27;s debatable if the result is actually a true rescale of the image (and if you average over the distribution of possible images the result is too soft again).<p>In theory video can do better by merging several frames of the same content.</div><br/></div></div><div id="40351765" class="c"><input type="checkbox" id="c-40351765" checked=""/><div class="controls bullet"><span class="by">smoothbran</span><span>|</span><a href="#40348226">parent</a><span>|</span><a href="#40349859">prev</a><span>|</span><a href="#40348281">next</a><span>|</span><label class="collapse" for="c-40351765">[-]</label><label class="expand" for="c-40351765">[1 more]</label></div><br/><div class="children"><div class="content">Video is absolutely the easier case - there&#x27;s a lot more information to go on. A single blurry photo has lost information compared to the original, but you can theoretically recover that information in a video where you get to see the subject with a variety of different blurs&#x2F;distortions applied.<p>Note that a limitation of this result is that it assumes a static scene, but that&#x27;s already a typical limitation of most gaussian splat applications anyway, so it kind of doesn&#x27;t matter?</div><br/></div></div><div id="40348281" class="c"><input type="checkbox" id="c-40348281" checked=""/><div class="controls bullet"><span class="by">tomp</span><span>|</span><a href="#40348226">parent</a><span>|</span><a href="#40351765">prev</a><span>|</span><a href="#40348847">next</a><span>|</span><label class="collapse" for="c-40348281">[-]</label><label class="expand" for="c-40348281">[1 more]</label></div><br/><div class="children"><div class="content">this work won&#x27;t solve that. it requires a video (sequence of images)</div><br/></div></div><div id="40348847" class="c"><input type="checkbox" id="c-40348847" checked=""/><div class="controls bullet"><span class="by">IshKebab</span><span>|</span><a href="#40348226">parent</a><span>|</span><a href="#40348281">prev</a><span>|</span><a href="#40350599">next</a><span>|</span><label class="collapse" for="c-40348847">[-]</label><label class="expand" for="c-40348847">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Video, where the result needs to be temporally coherent and make sense in 3D, can&#x27;t be the easier one.<p>Why not? Video is a much more tractable problem because you have much more information to go on.</div><br/></div></div><div id="40350599" class="c"><input type="checkbox" id="c-40350599" checked=""/><div class="controls bullet"><span class="by">echelon</span><span>|</span><a href="#40348226">parent</a><span>|</span><a href="#40348847">prev</a><span>|</span><a href="#40350948">next</a><span>|</span><label class="collapse" for="c-40350599">[-]</label><label class="expand" for="c-40350599">[1 more]</label></div><br/><div class="children"><div class="content">If your brain can imagine it de-blurred or de-scuffed, we&#x27;ll get there with techniques eventually.</div><br/></div></div></div></div></div></div></div></div></div></body></html>