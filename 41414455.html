<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1725181262576" as="style"/><link rel="stylesheet" href="styles.css?v=1725181262576"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://venturebeat.com/ai/ai-is-growing-faster-than-companies-can-secure-it-warn-industry-leaders/">AI is growing faster than companies can secure it, warn industry leaders</a> <span class="domain">(<a href="https://venturebeat.com">venturebeat.com</a>)</span></div><div class="subtext"><span>Duximo</span> | <span>31 comments</span></div><br/><div><div id="41414863" class="c"><input type="checkbox" id="c-41414863" checked=""/><div class="controls bullet"><span class="by">sameoldtune</span><span>|</span><a href="#41414904">next</a><span>|</span><label class="collapse" for="c-41414863">[-]</label><label class="expand" for="c-41414863">[5 more]</label></div><br/><div class="children"><div class="content">Slight sidebar based on the content of the article. I don’t like the term “hallucination” for when a LLM produces nonsense. As if it otherwise has some grasp of reality and when it is wrong it is because it is hallucinating. Everything it produces is a “hallucination“, some of those are just more useful than others.</div><br/><div id="41415246" class="c"><input type="checkbox" id="c-41415246" checked=""/><div class="controls bullet"><span class="by">threatofrain</span><span>|</span><a href="#41414863">parent</a><span>|</span><a href="#41414935">next</a><span>|</span><label class="collapse" for="c-41415246">[-]</label><label class="expand" for="c-41415246">[1 more]</label></div><br/><div class="children"><div class="content">I think it&#x27;s fair to say that these models may have some grasp of reality insofar as the data we collect ballparks reality, and also insofar as the mechanism to learn from the data effectively extracts the truth value of the data.<p>We might say the same thing about people.<p>Ultimately, just how problematic is it to label something as a hallucination? Are investors about to be massively duped? If I create a mechanism to reduce hallucinations and I call it therapy, is that really problematic?</div><br/></div></div><div id="41414935" class="c"><input type="checkbox" id="c-41414935" checked=""/><div class="controls bullet"><span class="by">ocihangir</span><span>|</span><a href="#41414863">parent</a><span>|</span><a href="#41415246">prev</a><span>|</span><a href="#41415126">next</a><span>|</span><label class="collapse" for="c-41414935">[-]</label><label class="expand" for="c-41414935">[2 more]</label></div><br/><div class="children"><div class="content">Same here. Many terms in LLM world are not quite right such as prompt “engineering”. It is almost like they were coined by non-tech folks.</div><br/><div id="41415308" class="c"><input type="checkbox" id="c-41415308" checked=""/><div class="controls bullet"><span class="by">soulofmischief</span><span>|</span><a href="#41414863">root</a><span>|</span><a href="#41414935">parent</a><span>|</span><a href="#41415126">next</a><span>|</span><label class="collapse" for="c-41415308">[-]</label><label class="expand" for="c-41415308">[1 more]</label></div><br/><div class="children"><div class="content">What&#x27;s wrong with the use of the word?</div><br/></div></div></div></div><div id="41415126" class="c"><input type="checkbox" id="c-41415126" checked=""/><div class="controls bullet"><span class="by">mirekrusin</span><span>|</span><a href="#41414863">parent</a><span>|</span><a href="#41414935">prev</a><span>|</span><a href="#41414904">next</a><span>|</span><label class="collapse" for="c-41415126">[-]</label><label class="expand" for="c-41415126">[1 more]</label></div><br/><div class="children"><div class="content">Technically the same problem applies to humans.</div><br/></div></div></div></div><div id="41414904" class="c"><input type="checkbox" id="c-41414904" checked=""/><div class="controls bullet"><span class="by">PeterStuer</span><span>|</span><a href="#41414863">prev</a><span>|</span><a href="#41415347">next</a><span>|</span><label class="collapse" for="c-41414904">[-]</label><label class="expand" for="c-41414904">[11 more]</label></div><br/><div class="children"><div class="content">The Internet grew faster than companies could &#x27;secure&#x27; it, and I would say that was not just a good thing, but key to its success.</div><br/><div id="41415233" class="c"><input type="checkbox" id="c-41415233" checked=""/><div class="controls bullet"><span class="by">metabagel</span><span>|</span><a href="#41414904">parent</a><span>|</span><a href="#41414980">next</a><span>|</span><label class="collapse" for="c-41415233">[-]</label><label class="expand" for="c-41415233">[3 more]</label></div><br/><div class="children"><div class="content">This isn’t a good analogy. The internet provably works. AI doesn’t provably work. It works some of the time, and there’s no indication we are anywhere close to a version of AI which provably works all of the time, or even up to human standard.</div><br/><div id="41415312" class="c"><input type="checkbox" id="c-41415312" checked=""/><div class="controls bullet"><span class="by">soulofmischief</span><span>|</span><a href="#41414904">root</a><span>|</span><a href="#41415233">parent</a><span>|</span><a href="#41414980">next</a><span>|</span><label class="collapse" for="c-41415312">[-]</label><label class="expand" for="c-41415312">[2 more]</label></div><br/><div class="children"><div class="content">There were and are many unknowns and fear about the internet at the time, too.</div><br/><div id="41415356" class="c"><input type="checkbox" id="c-41415356" checked=""/><div class="controls bullet"><span class="by">6510</span><span>|</span><a href="#41414904">root</a><span>|</span><a href="#41415312">parent</a><span>|</span><a href="#41414980">next</a><span>|</span><label class="collapse" for="c-41415356">[-]</label><label class="expand" for="c-41415356">[1 more]</label></div><br/><div class="children"><div class="content">I was just fixing some php from 2001 and it allows visitors to execute php, inject js, read&#x2F;write the database, send emails, extract md5 passwords, extract email addresses.<p>I&#x27;m surprised things worked out so well.</div><br/></div></div></div></div></div></div><div id="41414980" class="c"><input type="checkbox" id="c-41414980" checked=""/><div class="controls bullet"><span class="by">Mistletoe</span><span>|</span><a href="#41414904">parent</a><span>|</span><a href="#41415233">prev</a><span>|</span><a href="#41415142">next</a><span>|</span><label class="collapse" for="c-41414980">[-]</label><label class="expand" for="c-41414980">[5 more]</label></div><br/><div class="children"><div class="content">I have the opposite impression looking around at the current situation.  The tech giants moved fast and broke things and they broke humanity.</div><br/><div id="41415040" class="c"><input type="checkbox" id="c-41415040" checked=""/><div class="controls bullet"><span class="by">rixrax</span><span>|</span><a href="#41414904">root</a><span>|</span><a href="#41414980">parent</a><span>|</span><a href="#41415225">next</a><span>|</span><label class="collapse" for="c-41415040">[-]</label><label class="expand" for="c-41415040">[3 more]</label></div><br/><div class="children"><div class="content">You&#x27;re probably not wrong. But I think we should recognize that what is humanity is rather fluid. If you were to talk to the 15th century clergymen, I think they would tell the horrors of printing press and how it has&#x2F;will break humanity. And they wouldn&#x27;t be wrong either. Humanity evolves, and, well, that&#x27;s it. And overall, hopefully, and this is where we hopefully can effect positive change, we can steer the change to more humane, and moral direction.</div><br/><div id="41415216" class="c"><input type="checkbox" id="c-41415216" checked=""/><div class="controls bullet"><span class="by">Vecr</span><span>|</span><a href="#41414904">root</a><span>|</span><a href="#41415040">parent</a><span>|</span><a href="#41415225">next</a><span>|</span><label class="collapse" for="c-41415216">[-]</label><label class="expand" for="c-41415216">[2 more]</label></div><br/><div class="children"><div class="content">It matters what you think of democracy. &quot;The people&quot; don&#x27;t want transformative AI. The polls bear it out.</div><br/><div id="41415228" class="c"><input type="checkbox" id="c-41415228" checked=""/><div class="controls bullet"><span class="by">exe34</span><span>|</span><a href="#41414904">root</a><span>|</span><a href="#41415216">parent</a><span>|</span><a href="#41415225">next</a><span>|</span><label class="collapse" for="c-41415228">[-]</label><label class="expand" for="c-41415228">[1 more]</label></div><br/><div class="children"><div class="content">the people want to have their cake and eat it.</div><br/></div></div></div></div></div></div><div id="41415225" class="c"><input type="checkbox" id="c-41415225" checked=""/><div class="controls bullet"><span class="by">exe34</span><span>|</span><a href="#41414904">root</a><span>|</span><a href="#41414980">parent</a><span>|</span><a href="#41415040">prev</a><span>|</span><a href="#41415142">next</a><span>|</span><label class="collapse" for="c-41415225">[-]</label><label class="expand" for="c-41415225">[1 more]</label></div><br/><div class="children"><div class="content">I think they simply shone a light on human nature. Those aspects were there and still affected people, but we had the illusion that we were rational humanist actors - and even then that was only in the west. the internet simply shattered the illusion.</div><br/></div></div></div></div><div id="41415142" class="c"><input type="checkbox" id="c-41415142" checked=""/><div class="controls bullet"><span class="by">Timber-6539</span><span>|</span><a href="#41414904">parent</a><span>|</span><a href="#41414980">prev</a><span>|</span><a href="#41415347">next</a><span>|</span><label class="collapse" for="c-41415142">[-]</label><label class="expand" for="c-41415142">[2 more]</label></div><br/><div class="children"><div class="content">While somewhat true, doesn&#x27;t mean the same mistake has to be repeated to get progress on AI.</div><br/><div id="41415189" class="c"><input type="checkbox" id="c-41415189" checked=""/><div class="controls bullet"><span class="by">moralestapia</span><span>|</span><a href="#41414904">root</a><span>|</span><a href="#41415142">parent</a><span>|</span><a href="#41415347">next</a><span>|</span><label class="collapse" for="c-41415189">[-]</label><label class="expand" for="c-41415189">[1 more]</label></div><br/><div class="children"><div class="content">What &quot;mistake&quot; are you talking about?</div><br/></div></div></div></div></div></div><div id="41415347" class="c"><input type="checkbox" id="c-41415347" checked=""/><div class="controls bullet"><span class="by">jahdgOI</span><span>|</span><a href="#41414904">prev</a><span>|</span><a href="#41415097">next</a><span>|</span><label class="collapse" for="c-41415347">[-]</label><label class="expand" for="c-41415347">[1 more]</label></div><br/><div class="children"><div class="content">Pretty easy to secure: Call it chatbots and not AI.<p>Of course then they couldn&#x27;t leak the latest exponential growth stories to the press, which now appear every week.</div><br/></div></div><div id="41415097" class="c"><input type="checkbox" id="c-41415097" checked=""/><div class="controls bullet"><span class="by">levzettelin</span><span>|</span><a href="#41415347">prev</a><span>|</span><a href="#41415184">next</a><span>|</span><label class="collapse" for="c-41415097">[-]</label><label class="expand" for="c-41415097">[3 more]</label></div><br/><div class="children"><div class="content">Probably just companies trying to impede progress of other companies. Not to say that the statement is wrong necessarily. But given that this is coming from a group of people that could very easily solve the problem, I&#x27;ll take it with a grain of salt.</div><br/><div id="41415209" class="c"><input type="checkbox" id="c-41415209" checked=""/><div class="controls bullet"><span class="by">metabagel</span><span>|</span><a href="#41415097">parent</a><span>|</span><a href="#41415184">next</a><span>|</span><label class="collapse" for="c-41415209">[-]</label><label class="expand" for="c-41415209">[2 more]</label></div><br/><div class="children"><div class="content">It’s not an easily solvable problem. They can’t make an AI which won’t lie or make stuff up, which is sort of the root of the problem. Imagine an AI which is granted access to control systems. We can’t trust such an AI to run control systems any more than we can trust it not to lie or make stuff up. There isn’t the sort of rigor behind AI development to permit creating a provably correct AI. There needs to be more study in order to understand the limits of AI fallibility and failure modes.</div><br/><div id="41415239" class="c"><input type="checkbox" id="c-41415239" checked=""/><div class="controls bullet"><span class="by">levzettelin</span><span>|</span><a href="#41415097">root</a><span>|</span><a href="#41415209">parent</a><span>|</span><a href="#41415184">next</a><span>|</span><label class="collapse" for="c-41415239">[-]</label><label class="expand" for="c-41415239">[1 more]</label></div><br/><div class="children"><div class="content">They could just collectively stop working on the problem until they feel that the issue is resolved (moratorium). That&#x27;s what I meant by &quot;they could very easily solve the problem&quot;.</div><br/></div></div></div></div></div></div><div id="41415184" class="c"><input type="checkbox" id="c-41415184" checked=""/><div class="controls bullet"><span class="by">metabagel</span><span>|</span><a href="#41415097">prev</a><span>|</span><a href="#41415038">next</a><span>|</span><label class="collapse" for="c-41415184">[-]</label><label class="expand" for="c-41415184">[1 more]</label></div><br/><div class="children"><div class="content">&gt; “If you plan for the models and the chatbots that exist today… you’re going to be so far behind,” he reiterated, urging companies to prepare for the future of AI governance.<p>This is the key. Folks are looking at current capabilities rather than the trend line. We need to be ahead of the development AI. There probably ought to be laws regarding how AIs can be used or not used. There probably ought to be required disclosure when AI is used to create a work of art.</div><br/></div></div><div id="41415038" class="c"><input type="checkbox" id="c-41415038" checked=""/><div class="controls bullet"><span class="by">llmthrow102</span><span>|</span><a href="#41415184">prev</a><span>|</span><a href="#41415085">next</a><span>|</span><label class="collapse" for="c-41415038">[-]</label><label class="expand" for="c-41415038">[4 more]</label></div><br/><div class="children"><div class="content">Make companies and their leadership responsible for any harm or damage that comes from AI generated content or actions. If a recipe is a hallucinated recipe and poisons someone, treat it the same as if someone created a salad recipe calling for raw kidney beans and rhubarb leaves in order to intentionally harm someone.<p>AI creates a ton of garbage unmitigated, and cracking down on when that garbage is harmful will be a good way to reduce the amount of garbage these companies put out.</div><br/><div id="41415160" class="c"><input type="checkbox" id="c-41415160" checked=""/><div class="controls bullet"><span class="by">kumarvvr</span><span>|</span><a href="#41415038">parent</a><span>|</span><a href="#41415085">next</a><span>|</span><label class="collapse" for="c-41415160">[-]</label><label class="expand" for="c-41415160">[3 more]</label></div><br/><div class="children"><div class="content">Can you hold a hammer manufacturer responsible for a murder?<p>It is the users, and laws, that must control this.<p>Companies should add traceability to their AI products.<p>Govt.&#x27;s should ban non traceable content.<p>Holding users accountable for their actions is the only way forward to be safe and innovative at the same time.</div><br/><div id="41415253" class="c"><input type="checkbox" id="c-41415253" checked=""/><div class="controls bullet"><span class="by">llmthrow102</span><span>|</span><a href="#41415038">root</a><span>|</span><a href="#41415160">parent</a><span>|</span><a href="#41415180">next</a><span>|</span><label class="collapse" for="c-41415253">[-]</label><label class="expand" for="c-41415253">[1 more]</label></div><br/><div class="children"><div class="content">If a company has an AI tool, then you must treat everything that comes out of that tool as if it came from the company directly. If something harmful comes out, then the product is defective and they must compensate users like any other defective product.<p>If a hammer manufacturer sometimes produced a hammer that exploded like a hand grenade on impact, they would be held liable for that.</div><br/></div></div><div id="41415180" class="c"><input type="checkbox" id="c-41415180" checked=""/><div class="controls bullet"><span class="by">nicbou</span><span>|</span><a href="#41415038">root</a><span>|</span><a href="#41415160">parent</a><span>|</span><a href="#41415253">prev</a><span>|</span><a href="#41415085">next</a><span>|</span><label class="collapse" for="c-41415180">[-]</label><label class="expand" for="c-41415180">[1 more]</label></div><br/><div class="children"><div class="content">In this case the hammer would follow the murderer&#x27;s intent. It&#x27;s not a suitable analogy.</div><br/></div></div></div></div></div></div><div id="41415085" class="c"><input type="checkbox" id="c-41415085" checked=""/><div class="controls bullet"><span class="by">photonthug</span><span>|</span><a href="#41415038">prev</a><span>|</span><a href="#41414981">next</a><span>|</span><label class="collapse" for="c-41415085">[-]</label><label class="expand" for="c-41415085">[1 more]</label></div><br/><div class="children"><div class="content">Puff piece wherein it’s revealed that the fix for spending lots of money to put ai in charge of things it obviously can’t do properly is spending a lot more money on “ai security” that just points out that ai isn’t working, and seems to have no real path towards fixing the problem.<p>The security aspect mentioned here is that ai generated recipes could poison you when they hallucinate.  The fix is “governance” which isn’t really described or defined, but no doubt it’s as necessary as it is costly.  We could probably just not use cooks that seem to randomly poison the food and not create a new industry of equally suspect chef-policing but hey, where’s the fun in that?</div><br/></div></div><div id="41414981" class="c"><input type="checkbox" id="c-41414981" checked=""/><div class="controls bullet"><span class="by">xchip</span><span>|</span><a href="#41415085">prev</a><span>|</span><a href="#41414873">next</a><span>|</span><label class="collapse" for="c-41414981">[-]</label><label class="expand" for="c-41414981">[1 more]</label></div><br/><div class="children"><div class="content">by &quot;secure it&quot; they mean &quot;charge you&quot;</div><br/></div></div><div id="41414873" class="c"><input type="checkbox" id="c-41414873" checked=""/><div class="controls bullet"><span class="by">troupo</span><span>|</span><a href="#41414981">prev</a><span>|</span><a href="#41415336">next</a><span>|</span><label class="collapse" for="c-41414873">[-]</label><label class="expand" for="c-41414873">[2 more]</label></div><br/><div class="children"><div class="content">Someone on Twitter said: &quot;Do not fear AI. Fear the people and companies that run AI&quot;.<p>After all, it&#x27;s the same industry that came up with pervasive and invasive tracking, automated insurance refusals, automated credit lookups and checks, racial ...ahem... neighbourhood profiling for benefits etc. etc.</div><br/><div id="41415311" class="c"><input type="checkbox" id="c-41415311" checked=""/><div class="controls bullet"><span class="by">cen4</span><span>|</span><a href="#41414873">parent</a><span>|</span><a href="#41415336">next</a><span>|</span><label class="collapse" for="c-41415311">[-]</label><label class="expand" for="c-41415311">[1 more]</label></div><br/><div class="children"><div class="content">No need to fear anything. Will be handled similar to Parasites and Pandemics. Scale is over rated, if the host gets drained and dies too quickly. Past couple decades have taught corporate wonderland how to combine mindlessly ambitious people(parasites) and button press scalability, to generate mesmerizing levels of profits. But the scheme is getting old. Everyone has copied the model. The host is taking more hits than it can afford. And therefore there is greater recognition about which parasites to keep locked up and which can be safely controlled.</div><br/></div></div></div></div></div></div></div></div></div></body></html>