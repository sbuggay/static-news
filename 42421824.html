<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1734426072227" as="style"/><link rel="stylesheet" href="styles.css?v=1734426072227"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://surfingcomplexity.blog/2024/12/14/quick-takes-on-the-recent-openai-public-incident-write-up/">Quick takes on the recent OpenAI public incident write-up</a> <span class="domain">(<a href="https://surfingcomplexity.blog">surfingcomplexity.blog</a>)</span></div><div class="subtext"><span>azhenley</span> | <span>33 comments</span></div><br/><div><div id="42436719" class="c"><input type="checkbox" id="c-42436719" checked=""/><div class="controls bullet"><span class="by">btown</span><span>|</span><a href="#42439285">next</a><span>|</span><label class="collapse" for="c-42436719">[-]</label><label class="expand" for="c-42436719">[11 more]</label></div><br/><div class="children"><div class="content">&gt;  In order to make that fix, we needed to access the Kubernetes control plane – which we could not do due to the increased load to the Kubernetes API servers.<p>Something that I wish all databases and API servers would do, and that few actually do in practice, is to allocate a certain amount of headroom (memory and CPU) to &quot;break glass in case of emergency&quot; sessions. Have an interrupt fired periodically that listens exclusively on a port that will only be used for emergency instructions (but uses equal security measures to production, and is only visible internally). Ensure that it can allocate against a preallocated block of memory; allow it to schedule higher-priority threads. A small concession to make in the usual course of business, but when it&#x27;s useful it&#x27;s vital.</div><br/><div id="42439591" class="c"><input type="checkbox" id="c-42439591" checked=""/><div class="controls bullet"><span class="by">dotancohen</span><span>|</span><a href="#42436719">parent</a><span>|</span><a href="#42436852">next</a><span>|</span><label class="collapse" for="c-42439591">[-]</label><label class="expand" for="c-42439591">[1 more]</label></div><br/><div class="children"><div class="content">I have a 1 GiB file to rm in case of emergency on every filesystem I manage - both personal and professional. I&#x27;ve only had to delete it maybe three or four times that I remember, but it&#x27;s been a system-saver each time. I&#x27;ve long considered writing a process that just consumes some CPU, memory, and bandwidth for the same emergency buffer. I&#x27;ve even considered that it should even examine `last` every second and free up those resources when I SSH in.</div><br/></div></div><div id="42436852" class="c"><input type="checkbox" id="c-42436852" checked=""/><div class="controls bullet"><span class="by">tcdent</span><span>|</span><a href="#42436719">parent</a><span>|</span><a href="#42439591">prev</a><span>|</span><a href="#42438533">next</a><span>|</span><label class="collapse" for="c-42436852">[-]</label><label class="expand" for="c-42436852">[7 more]</label></div><br/><div class="children"><div class="content">Resource exhaustion can be super frustrating, and always feels like a third world slum situation when it happens.<p>Like, why would operating systems allow themselves to run out of headroom entirely in this day and age?</div><br/><div id="42439294" class="c"><input type="checkbox" id="c-42439294" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#42436719">root</a><span>|</span><a href="#42436852">parent</a><span>|</span><a href="#42437646">next</a><span>|</span><label class="collapse" for="c-42439294">[-]</label><label class="expand" for="c-42439294">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>a third world slum situation when it happens</i><p>&gt; <i>why would operating systems allow themselves to run out of headroom entirely in this day and age?</i><p>Following the analogy, perhaps for the same reason the richest cities in the richest, most developed Western nations, are rapidly beginning to look very much like third-world slums?<p>Over-optimization is the name of the game. All systems need some amount of slack in them to stay flexible, robust (and livable). Unfortunately, cutting into the slack is always profitable on the margin, so without top-down intervention, the slack will be cut into until it&#x27;s gone entirely. &quot;Look, these machines are utilized only to 75% of capacity; adding this new system will only increase it by 5%&quot;; &quot;look, we can save XX$&#x2F;month by cutting on compute, the machines will still be maxing out at 90%, so we&#x27;ll still have a buffer&quot;. &quot;Oh, this new telemetry service will bump that only by 1%&quot;.<p>&quot;Look, there&#x27;s so much free space here in between these blocks of flats; adding another block won&#x27;t hurt.&quot;<p>And so on. Until your machines are running at 99% capacity and you risk global outage every time someone sneezes near the server room. Until your city starts to look like London, and if you&#x27;re from Central Europe like me, you may start to realize that being a few months or years behind on the most recent gadgets is small price to pay in exchange for cities that are affordable and <i>clean</i>.</div><br/></div></div><div id="42437646" class="c"><input type="checkbox" id="c-42437646" checked=""/><div class="controls bullet"><span class="by">throwaway290</span><span>|</span><a href="#42436719">root</a><span>|</span><a href="#42436852">parent</a><span>|</span><a href="#42439294">prev</a><span>|</span><a href="#42438533">next</a><span>|</span><label class="collapse" for="c-42437646">[-]</label><label class="expand" for="c-42437646">[5 more]</label></div><br/><div class="children"><div class="content">Because it makes computer slower and people pay for compute.<p>I think consumer systems do it. macos shows the &quot;quit some app, you&#x27;re out of ram&quot; but the system itself works.<p>but if you are asking that OS knows this is containers process and this is control plane process and  treat them differently, I think no one does that.<p>Imagine how frustrating would it be if your os does it wrongly and you end up paying 10x because the os nerfed your main process because it thought something more important was running</div><br/><div id="42439455" class="c"><input type="checkbox" id="c-42439455" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#42436719">root</a><span>|</span><a href="#42437646">parent</a><span>|</span><a href="#42437782">next</a><span>|</span><label class="collapse" for="c-42439455">[-]</label><label class="expand" for="c-42439455">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>Imagine how frustrating would it be if your os does it wrongly and you end up paying 10x because the os nerfed your main process because it thought something more important was running</i><p>Imagine how frustrating it is when the Linux on your desktop suddenly decides to start randomly killing processes, or worse, attempts to swap some memory out, causing a feedback loop of delays that completely freezes the system until you power-cycle the machine.<p>That&#x27;s one of the two things Windows always did better (the other thing is disabling write buffering for removable storage, on the account of that storage being, well, <i>removable</i>).<p>Resource limits are not something you want to discover when you&#x27;ve exceeded them; they need to be managed and alerted about in advance. &quot;Makes computer slower&quot; and alerting the &quot;people who pay for compute&quot; is preferable to crashing - <i>especially in distributed systems</i>, where failures cascade (particularly when the whole system has been penny-pinched &#x2F; overoptimized to the same degree as any single computer within it).</div><br/></div></div><div id="42437782" class="c"><input type="checkbox" id="c-42437782" checked=""/><div class="controls bullet"><span class="by">yuliyp</span><span>|</span><a href="#42436719">root</a><span>|</span><a href="#42437646">parent</a><span>|</span><a href="#42439455">prev</a><span>|</span><a href="#42438533">next</a><span>|</span><label class="collapse" for="c-42437782">[-]</label><label class="expand" for="c-42437782">[3 more]</label></div><br/><div class="children"><div class="content">&gt; OS knows this is containers process and this is control plane process and treat them differently, I think no one does that<p>cgroups on Linux does exactly this, and are a standard part of ensuring that containers don&#x27;t exceed their allocated resources.</div><br/><div id="42439625" class="c"><input type="checkbox" id="c-42439625" checked=""/><div class="controls bullet"><span class="by">dotancohen</span><span>|</span><a href="#42436719">root</a><span>|</span><a href="#42437782">parent</a><span>|</span><a href="#42437918">next</a><span>|</span><label class="collapse" for="c-42439625">[-]</label><label class="expand" for="c-42439625">[1 more]</label></div><br/><div class="children"><div class="content">Most software running on w Linux server are not running in a container, which itself has (minimal) resource overhead.<p>Unless you are talking about VMs in cloud computing, but even in those cases the VM is usually abstracted away and the end client only sees a VPS (e.g. with EC2 or GCE).</div><br/></div></div><div id="42437918" class="c"><input type="checkbox" id="c-42437918" checked=""/><div class="controls bullet"><span class="by">throwaway290</span><span>|</span><a href="#42436719">root</a><span>|</span><a href="#42437782">parent</a><span>|</span><a href="#42439625">prev</a><span>|</span><a href="#42438533">next</a><span>|</span><label class="collapse" for="c-42437918">[-]</label><label class="expand" for="c-42437918">[1 more]</label></div><br/><div class="children"><div class="content">OK with some configuration a server OS can do it too. Looks like ClosedAI doesn&#x27;t pay sysadmins enough if they did not configure such a standard thing.</div><br/></div></div></div></div></div></div></div></div><div id="42438533" class="c"><input type="checkbox" id="c-42438533" checked=""/><div class="controls bullet"><span class="by">xyzzy123</span><span>|</span><a href="#42436719">parent</a><span>|</span><a href="#42436852">prev</a><span>|</span><a href="#42439285">next</a><span>|</span><label class="collapse" for="c-42438533">[-]</label><label class="expand" for="c-42438533">[2 more]</label></div><br/><div class="children"><div class="content">As I understand it you can configure api rate limiting per-user but you&#x27;d need to work out &quot;reasonable&quot; values on your own to allow enough headroom for admin requests.<p>This would require per-cluster testing (and is complex to test since you need to induce representative load) so I suppose hardly anyone does it.</div><br/><div id="42438995" class="c"><input type="checkbox" id="c-42438995" checked=""/><div class="controls bullet"><span class="by">dilyevsky</span><span>|</span><a href="#42436719">root</a><span>|</span><a href="#42438533">parent</a><span>|</span><a href="#42439285">next</a><span>|</span><label class="collapse" for="c-42438995">[-]</label><label class="expand" for="c-42438995">[1 more]</label></div><br/><div class="children"><div class="content">There’s a whole set of features built[0] to prevent this exact scenario - runaway controllers consuming all api resources. Not sure why it didn’t work, maybe they are running an old release<p>[0] - <a href="https:&#x2F;&#x2F;kubernetes.io&#x2F;docs&#x2F;concepts&#x2F;cluster-administration&#x2F;flow-control&#x2F;" rel="nofollow">https:&#x2F;&#x2F;kubernetes.io&#x2F;docs&#x2F;concepts&#x2F;cluster-administration&#x2F;f...</a></div><br/></div></div></div></div></div></div><div id="42439285" class="c"><input type="checkbox" id="c-42439285" checked=""/><div class="controls bullet"><span class="by">geocrasher</span><span>|</span><a href="#42436719">prev</a><span>|</span><a href="#42437996">next</a><span>|</span><label class="collapse" for="c-42439285">[-]</label><label class="expand" for="c-42439285">[1 more]</label></div><br/><div class="children"><div class="content"><p><pre><code>   In short, the root cause was a new telemetry service configuration that unexpectedly generated massive Kubernetes API load across large clusters, overwhelming the control plane and breaking DNS-based service discovery.
</code></pre>
The DNS song seems appropriate.<p><a href="https:&#x2F;&#x2F;soundcloud.com&#x2F;ryan-flowers-916961339&#x2F;dns-to-the-tune-of-let-it-be" rel="nofollow">https:&#x2F;&#x2F;soundcloud.com&#x2F;ryan-flowers-916961339&#x2F;dns-to-the-tun...</a></div><br/></div></div><div id="42437996" class="c"><input type="checkbox" id="c-42437996" checked=""/><div class="controls bullet"><span class="by">StarlaAtNight</span><span>|</span><a href="#42439285">prev</a><span>|</span><a href="#42435772">next</a><span>|</span><label class="collapse" for="c-42437996">[-]</label><label class="expand" for="c-42437996">[2 more]</label></div><br/><div class="children"><div class="content">This quote cracked me up:<p>“I HAVE NO TOOLS BECAUSE I’VE DESTROYED MY TOOLS WITH MY TOOLS”</div><br/><div id="42438848" class="c"><input type="checkbox" id="c-42438848" checked=""/><div class="controls bullet"><span class="by">akshayshah</span><span>|</span><a href="#42437996">parent</a><span>|</span><a href="#42435772">next</a><span>|</span><label class="collapse" for="c-42438848">[-]</label><label class="expand" for="c-42438848">[1 more]</label></div><br/><div class="children"><div class="content">James Mickens is a comedic genius. The linked article always makes me laugh out loud.<p><a href="https:&#x2F;&#x2F;www.usenix.org&#x2F;system&#x2F;files&#x2F;1311_05-08_mickens.pdf" rel="nofollow">https:&#x2F;&#x2F;www.usenix.org&#x2F;system&#x2F;files&#x2F;1311_05-08_mickens.pdf</a></div><br/></div></div></div></div><div id="42435772" class="c"><input type="checkbox" id="c-42435772" checked=""/><div class="controls bullet"><span class="by">dilyevsky</span><span>|</span><a href="#42437996">prev</a><span>|</span><a href="#42435556">next</a><span>|</span><label class="collapse" for="c-42435772">[-]</label><label class="expand" for="c-42435772">[3 more]</label></div><br/><div class="children"><div class="content">Something doesn&#x27;t add up - CoreDNS&#x27;s kubernetes plugin should be serving Service RRs from its internal cache even if APIServer is down because it&#x27;s using cache.Indexer. The records would be stale but unless their application pods all restarted, which they could not since APIServer was down, or all CoreDNS pods got restarted, which, again, they could not, just records expiring from the cache shouldn&#x27;t have caused full discovery outage.</div><br/><div id="42435886" class="c"><input type="checkbox" id="c-42435886" checked=""/><div class="controls bullet"><span class="by">jimmyl02</span><span>|</span><a href="#42435772">parent</a><span>|</span><a href="#42435556">next</a><span>|</span><label class="collapse" for="c-42435886">[-]</label><label class="expand" for="c-42435886">[2 more]</label></div><br/><div class="children"><div class="content">wouldn&#x27;t it be coredns caches the information and records from API server for X amount of time (it seems like this might be 20 minutes?) then once the 20 minutes expired coredns would query api server, receive no response, then fail?<p>I think the idea of just serving cached responses indefinitely when api server is unreachable is what you&#x27;re describing but not sure if this is default. (and probably has other tradeoffs that I&#x27;m not sure about too)</div><br/><div id="42435990" class="c"><input type="checkbox" id="c-42435990" checked=""/><div class="controls bullet"><span class="by">dilyevsky</span><span>|</span><a href="#42435772">root</a><span>|</span><a href="#42435886">parent</a><span>|</span><a href="#42435556">next</a><span>|</span><label class="collapse" for="c-42435990">[-]</label><label class="expand" for="c-42435990">[1 more]</label></div><br/><div class="children"><div class="content">Based on my understanding of the plugin code it <i>is</i> the default. The way cache.Indexer works is it&#x27;s continuously streaming resources from APIServer using Watch API and updates internal map. I think if Watch API is down it just sits there and doesn&#x27;t purge anything but I haven&#x27;t tested that. The 20 min expiry is probably referring to CodeDNS <i>cache</i> stanza which is a separate plugin[0].<p>[0] - <a href="https:&#x2F;&#x2F;coredns.io&#x2F;plugins&#x2F;cache" rel="nofollow">https:&#x2F;&#x2F;coredns.io&#x2F;plugins&#x2F;cache</a></div><br/></div></div></div></div></div></div><div id="42435556" class="c"><input type="checkbox" id="c-42435556" checked=""/><div class="controls bullet"><span class="by">JohnMakin</span><span>|</span><a href="#42435772">prev</a><span>|</span><a href="#42438569">next</a><span>|</span><label class="collapse" for="c-42435556">[-]</label><label class="expand" for="c-42435556">[5 more]</label></div><br/><div class="children"><div class="content">I caused an API server outage once with a monitoring tool, however in my case it was a monstrosity of a 20,000 line script. We quickly realized what we had done and turned it off, and I have seen in very large clusters with 1000+ nodes that you need to be especially sensitive about monitoring API server resource usage depending on what precisely you are doing. Surprised they hadn&#x27;t learned this lesson yet, given the likely scale of their workloads.</div><br/><div id="42437045" class="c"><input type="checkbox" id="c-42437045" checked=""/><div class="controls bullet"><span class="by">dboreham</span><span>|</span><a href="#42435556">parent</a><span>|</span><a href="#42438569">next</a><span>|</span><label class="collapse" for="c-42437045">[-]</label><label class="expand" for="c-42437045">[4 more]</label></div><br/><div class="children"><div class="content">&gt; 20,000 line script<p>Dude.</div><br/><div id="42437140" class="c"><input type="checkbox" id="c-42437140" checked=""/><div class="controls bullet"><span class="by">fuzzy_biscuit</span><span>|</span><a href="#42435556">root</a><span>|</span><a href="#42437045">parent</a><span>|</span><a href="#42438569">next</a><span>|</span><label class="collapse" for="c-42437140">[-]</label><label class="expand" for="c-42437140">[3 more]</label></div><br/><div class="children"><div class="content">They meant manuscript I assume.</div><br/><div id="42438387" class="c"><input type="checkbox" id="c-42438387" checked=""/><div class="controls bullet"><span class="by">cbsmith</span><span>|</span><a href="#42435556">root</a><span>|</span><a href="#42437140">parent</a><span>|</span><a href="#42438569">next</a><span>|</span><label class="collapse" for="c-42438387">[-]</label><label class="expand" for="c-42438387">[2 more]</label></div><br/><div class="children"><div class="content">Yeah, &quot;script&quot; is just an abbreviation of &quot;manuscript&quot;, right? ;-)</div><br/><div id="42439487" class="c"><input type="checkbox" id="c-42439487" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#42435556">root</a><span>|</span><a href="#42438387">parent</a><span>|</span><a href="#42438569">next</a><span>|</span><label class="collapse" for="c-42439487">[-]</label><label class="expand" for="c-42439487">[1 more]</label></div><br/><div class="children"><div class="content">Right, and the (manu)script that size makes a long <i>scroll</i>. Humanity had to <i>more</i> or <i>less</i> invent <i>pagination</i> to deal with this.<p>(I&#x27;ll see myself out.)</div><br/></div></div></div></div></div></div></div></div></div></div><div id="42438569" class="c"><input type="checkbox" id="c-42438569" checked=""/><div class="controls bullet"><span class="by">feyman_r</span><span>|</span><a href="#42435556">prev</a><span>|</span><a href="#42435888">next</a><span>|</span><label class="collapse" for="c-42438569">[-]</label><label class="expand" for="c-42438569">[3 more]</label></div><br/><div class="children"><div class="content">For me, this was stunning : “ 2:51pm to 3:20pm: The change was applied to all clusters”<p>How can such a large change not be staged in some manner or the other? Feedback loops have a way of catching up later which is why it’s important to roll out gradually.</div><br/><div id="42438914" class="c"><input type="checkbox" id="c-42438914" checked=""/><div class="controls bullet"><span class="by">antod</span><span>|</span><a href="#42438569">parent</a><span>|</span><a href="#42439508">next</a><span>|</span><label class="collapse" for="c-42438914">[-]</label><label class="expand" for="c-42438914">[1 more]</label></div><br/><div class="children"><div class="content">In the words of DevOps Borat...<p>&quot;To make error is human. To propagate error to all server in automatic way is #devops.&quot;</div><br/></div></div><div id="42439508" class="c"><input type="checkbox" id="c-42439508" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#42438569">parent</a><span>|</span><a href="#42438914">prev</a><span>|</span><a href="#42435888">next</a><span>|</span><label class="collapse" for="c-42439508">[-]</label><label class="expand" for="c-42439508">[1 more]</label></div><br/><div class="children"><div class="content">DNS makes for an atypically <i>slow</i> feedback loop. If you&#x27;re not aware of it, then for an otherwise safe-looking change, you may test and complete the gradual roll-out before the failure hits you.</div><br/></div></div></div></div><div id="42435888" class="c"><input type="checkbox" id="c-42435888" checked=""/><div class="controls bullet"><span class="by">ilaksh</span><span>|</span><a href="#42438569">prev</a><span>|</span><a href="#42438885">next</a><span>|</span><label class="collapse" for="c-42435888">[-]</label><label class="expand" for="c-42435888">[1 more]</label></div><br/><div class="children"><div class="content">Wow, sounds like a nightmare. Operations staff definitely have real jobs.</div><br/></div></div><div id="42438885" class="c"><input type="checkbox" id="c-42438885" checked=""/><div class="controls bullet"><span class="by">nijave</span><span>|</span><a href="#42435888">prev</a><span>|</span><a href="#42435703">next</a><span>|</span><label class="collapse" for="c-42438885">[-]</label><label class="expand" for="c-42438885">[2 more]</label></div><br/><div class="children"><div class="content">Seems like automated node access could have also been helpful here. Kill the offending pods directly on the nodes to relieve API server pressure long enough to rollback</div><br/><div id="42439009" class="c"><input type="checkbox" id="c-42439009" checked=""/><div class="controls bullet"><span class="by">dilyevsky</span><span>|</span><a href="#42438885">parent</a><span>|</span><a href="#42435703">next</a><span>|</span><label class="collapse" for="c-42439009">[-]</label><label class="expand" for="c-42439009">[1 more]</label></div><br/><div class="children"><div class="content">The only problem is you have to find out where those pods are and your primary source of this information is currently under dos attack by said pods</div><br/></div></div></div></div><div id="42435703" class="c"><input type="checkbox" id="c-42435703" checked=""/><div class="controls bullet"><span class="by">jimmyl02</span><span>|</span><a href="#42438885">prev</a><span>|</span><a href="#42435014">next</a><span>|</span><label class="collapse" for="c-42435703">[-]</label><label class="expand" for="c-42435703">[2 more]</label></div><br/><div class="children"><div class="content">splitting the control and data plane is a great way to improve resilience and prevent everything from being hard down. I wonder how it could be accomplished with service discovery &#x2F; routing.<p>maybe instead of relying on kubernetes DNS for discovery it can be closer to something like envoy.the control plane updates configs that are stored locally (and are eventually consistent) so even if the control plane dies the data plane has access to location information of other peer clusters.</div><br/><div id="42438394" class="c"><input type="checkbox" id="c-42438394" checked=""/><div class="controls bullet"><span class="by">cbsmith</span><span>|</span><a href="#42435703">parent</a><span>|</span><a href="#42435014">next</a><span>|</span><label class="collapse" for="c-42438394">[-]</label><label class="expand" for="c-42438394">[1 more]</label></div><br/><div class="children"><div class="content">&gt; maybe instead of relying on kubernetes DNS for discovery it can be closer to something like envoy.the control plane updates configs that are stored locally (and are eventually consistent) so even if the control plane dies the data plane has access to location information of other peer clusters.<p>That is generally how it is done... there&#x27;s this never ending conflict between &quot;push&quot; architectures and &quot;pull&quot; architectures, and this scenario sure makes &quot;push&quot; seem better, and it is... until you&#x27;re in one of those scenarios where &quot;pull&quot; is better. ;-)</div><br/></div></div></div></div><div id="42435014" class="c"><input type="checkbox" id="c-42435014" checked=""/><div class="controls bullet"><span class="by">dang</span><span>|</span><a href="#42435703">prev</a><span>|</span><a href="#42422040">next</a><span>|</span><label class="collapse" for="c-42435014">[-]</label><label class="expand" for="c-42435014">[1 more]</label></div><br/><div class="children"><div class="content">Recent and related:<p><i>ChatGPT Down</i> - <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=42394391">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=42394391</a> - Dec 2024 (30 comments)</div><br/></div></div></div></div></div></div></div></body></html>