<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1735376451365" as="style"/><link rel="stylesheet" href="styles.css?v=1735376451365"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://arxiv.org/abs/2404.01332">Explaining Large Language Models Decisions Using Shapley Values</a>Â <span class="domain">(<a href="https://arxiv.org">arxiv.org</a>)</span></div><div class="subtext"><span>veryluckyxyz</span> | <span>4 comments</span></div><br/><div><div id="42529036" class="c"><input type="checkbox" id="c-42529036" checked=""/><div class="controls bullet"><span class="by">goldemerald</span><span>|</span><label class="collapse" for="c-42529036">[-]</label><label class="expand" for="c-42529036">[3 more]</label></div><br/><div class="children"><div class="content">While I love XAI and am always happy to see more work in this area, I wonder if other people use the same heuristics as me when judging a random arxiv link. This paper has one author, was not written in latex, and no comment referencing a peer reviewed venue. Do other people in this field look at these same signals and pre-judge the paper negatively?<p>I did attempt to check my bias and skim the paper, it does seem well written and takes a decent shot towards understanding LLMs. However, I am not a fan of black-box explanations, so I didn&#x27;t read much (I really like Sparse autoencoders). Has anyone else read the paper? How is the quality?</div><br/><div id="42529417" class="c"><input type="checkbox" id="c-42529417" checked=""/><div class="controls bullet"><span class="by">cauliflower2718</span><span>|</span><a href="#42529036">parent</a><span>|</span><a href="#42529238">next</a><span>|</span><label class="collapse" for="c-42529417">[-]</label><label class="expand" for="c-42529417">[1 more]</label></div><br/><div class="children"><div class="content">It looks like it&#x27;s written in latex to me. Standard formatting varies across departments, and the author is in the business school at CMU.<p>In some fields, single author papers are more common. Also, outside of ML conference culture, the journal publication process can be pretty slow.<p>Based on the above (which is separate from an actual evaluation of the paper), there are no immediate red flags.<p>Source: I am a PhD student and read papers across stats&#x2F;CS&#x2F;OR.</div><br/></div></div><div id="42529238" class="c"><input type="checkbox" id="c-42529238" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#42529036">parent</a><span>|</span><a href="#42529417">prev</a><span>|</span><label class="collapse" for="c-42529238">[-]</label><label class="expand" for="c-42529238">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I wonder if other people use the same heuristics as me when judging a random arxiv link.<p>My prior after the header was the same as yours. The fight and interesting part is in the work past the initial reaction.<p>i.e. if I react with my first order, least effort, reaction, your comment leaves the reader with a brief, shocked, laugh at you seemingly doing performance art. A seemingly bland assessment and overly broad question...only to conclude with &quot;Has anyone else read the paper? Do you like it?&quot;<p>But that&#x27;s not what you meant. You&#x27;re geniunely curious if its a long tail, inappropriate, reaction to have that initial assessment based on pattern matching. And you didn&#x27;t mean &quot;did anyone else read it&quot;, you meant &quot;Humbly, I&#x27;m admitting I&#x27;m skimmed, but I wasn&#x27;t blown away for reasons X, Y, and Z. What do you all think? :)&quot;<p>The paper is superb and one of the best I recall reading in recent memory.<p>It&#x27;s a much whiter box than Spare Autoencoders. Handwaving what a bag of floats <i>might</i> do in <i>general</i> is much less interesting or helpful than being able to statistically quantify the behavior of the systems we&#x27;re building.<p>The author is a PhD candidate at the Carnegie Mellon School of Business, and I was quite taken with their ability to hop across fields to get a rather simple and important way to systematically and statistically review the systems we&#x27;re building.</div><br/></div></div></div></div></div></div></div></div></div></body></html>