<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1725786069084" as="style"/><link rel="stylesheet" href="styles.css?v=1725786069084"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://misinforeview.hks.harvard.edu/article/gpt-fabricated-scientific-papers-on-google-scholar-key-features-spread-and-implications-for-preempting-evidence-manipulation/">GPT-fabricated scientific papers on Google Scholar</a> <span class="domain">(<a href="https://misinforeview.hks.harvard.edu">misinforeview.hks.harvard.edu</a>)</span></div><div class="subtext"><span>celadevra_</span> | <span>83 comments</span></div><br/><div><div id="41477844" class="c"><input type="checkbox" id="c-41477844" checked=""/><div class="controls bullet"><span class="by">Strilanc</span><span>|</span><a href="#41479063">next</a><span>|</span><label class="collapse" for="c-41477844">[-]</label><label class="expand" for="c-41477844">[19 more]</label></div><br/><div class="children"><div class="content">When I went to the APS March Meeting earlier this year, I talked with the editor of a scientific journal and asked them if they were worried about LLM generated papers. They said actually their main worry wasn&#x27;t LLM-generated papers, it was LLM-generated <i>reviews</i>.<p>LLMs are much better at plausibly summarizing content than they are at doing long sequences of reasoning, so they&#x27;re much better at generating believable reviews than believable papers. Plus reviews are pretty tedious to do, giving an incentive to half-ass it with an LLM. Plus reviews are usually not shared publicly, taking away some of the potential embarrassment.</div><br/><div id="41477907" class="c"><input type="checkbox" id="c-41477907" checked=""/><div class="controls bullet"><span class="by">empiko</span><span>|</span><a href="#41477844">parent</a><span>|</span><a href="#41478913">next</a><span>|</span><label class="collapse" for="c-41477907">[-]</label><label class="expand" for="c-41477907">[10 more]</label></div><br/><div class="children"><div class="content">We already got an LLM generated meta review that was very clearly just summarization of reviews. There were some pretty egregious cases of borderline hallucinated remarks. This was ACL Rolling Review, so basically the most prestigious NLP venue and the editors told us to suck it up. Very disappointing and I genuinely worry about the state of science and how this will affect people who rely on scientometric criteria.</div><br/><div id="41478269" class="c"><input type="checkbox" id="c-41478269" checked=""/><div class="controls bullet"><span class="by">userbinator</span><span>|</span><a href="#41477844">root</a><span>|</span><a href="#41477907">parent</a><span>|</span><a href="#41478395">next</a><span>|</span><label class="collapse" for="c-41478269">[-]</label><label class="expand" for="c-41478269">[1 more]</label></div><br/><div class="children"><div class="content"><i>so basically the most prestigious NLP venue</i><p>I see &quot;dogfooding&quot; has now been taken to its natural conclusion.</div><br/></div></div><div id="41478395" class="c"><input type="checkbox" id="c-41478395" checked=""/><div class="controls bullet"><span class="by">jll29</span><span>|</span><a href="#41477844">root</a><span>|</span><a href="#41477907">parent</a><span>|</span><a href="#41478269">prev</a><span>|</span><a href="#41477988">next</a><span>|</span><label class="collapse" for="c-41478395">[-]</label><label class="expand" for="c-41478395">[2 more]</label></div><br/><div class="children"><div class="content">Most conferences have been flooded with submissions, and ACL is no exception.<p>A consequence of that is that there are not sufficient numbers of reviewers available who are qualified to review these manuscripts.<p>Conference organizers might be keen to accept many or most who offer to volunteer, but clearly there is now a large pool of people that have never done this before, and were never taught how to do this. Add some time pressure, and people will try out some tool, just because it exists.<p>GPT-generated docs have a particular tone that you can detect if you&#x27;ve played a bit with ChatGPT and if you have a feel for  language. Such reviews should be kicked out. I would be interested to view this review (anonymized if you like - by taking out bits that reveal too narrowly what it&#x27;s about).<p>The &quot;rolling&quot; model of ARR is a pain, though, because instead of slaving for a month you feel like slaving (conducting scientific peer review free of charge = slave labor) all year round.
Last month, I got contacted by a book editor to review a scientific book for $100. I told her I&#x27;m not going to read 350 pages, to write two pages worth of book review; to do this properly one would need two days, and I quoted my consulting day rate. On top of that, this email came in the vacation month of August. Of course, said person was never heard of again.</div><br/><div id="41478764" class="c"><input type="checkbox" id="c-41478764" checked=""/><div class="controls bullet"><span class="by">joshvm</span><span>|</span><a href="#41477844">root</a><span>|</span><a href="#41478395">parent</a><span>|</span><a href="#41477988">next</a><span>|</span><label class="collapse" for="c-41478764">[-]</label><label class="expand" for="c-41478764">[1 more]</label></div><br/><div class="children"><div class="content">We had what we strongly suspect is an LLM-written review for NeurIPS. It was kind of subtle if you weren&#x27;t looking carefully and I can see that an AC might miss it. The suggestions for improvement weren&#x27;t _wrong_, but the GPT response picked up on some extremely specific things in the paper that were mostly irrelevant (other reviewers actually pointed out the odd typo and small corrections or improvemnts where we&#x27;d made statements).<p>Pretty hard to combat. We just rebutted as if it were a real review - maybe it was - and hope that the chairs see it. Speaking to other folks, opinions are split over whether this sort of review should be flagged. I know some people who tried to query a review and it didn&#x27;t help.<p>There were other small cues - the English was perfect, while other reviewers made small slips indicative of non-native speakers. One was simply the discrepancy between the tone of the review (generally very positive) and the middle-of-the-road rating and confidence. The structure of the review was very &quot;The authors do X, Y, Z. This is important because A, B, C.&quot; and the reviewer didn&#x27;t bother to fill out any of the other review sections (they just wrote single-word answeres to all of them).<p>The kicker was actually putting our paper in to 4o and asking it to write a review and seeing the same keywords pop up.</div><br/></div></div></div></div><div id="41477988" class="c"><input type="checkbox" id="c-41477988" checked=""/><div class="controls bullet"><span class="by">reliabilityguy</span><span>|</span><a href="#41477844">root</a><span>|</span><a href="#41477907">parent</a><span>|</span><a href="#41478395">prev</a><span>|</span><a href="#41478233">next</a><span>|</span><label class="collapse" for="c-41477988">[-]</label><label class="expand" for="c-41477988">[1 more]</label></div><br/><div class="children"><div class="content">Well, given that the only thing that matters for tenure reviews is the “service”, i.e., roughly a list of conferences the applicant reviewed&#x2F;performed some sort of service at, this is barely a surprise.<p>Right now there is now incentive to do a high quality review unless the reviewer is motivated.</div><br/></div></div><div id="41478233" class="c"><input type="checkbox" id="c-41478233" checked=""/><div class="controls bullet"><span class="by">Der_Einzige</span><span>|</span><a href="#41477844">root</a><span>|</span><a href="#41477907">parent</a><span>|</span><a href="#41477988">prev</a><span>|</span><a href="#41478010">next</a><span>|</span><label class="collapse" for="c-41478233">[-]</label><label class="expand" for="c-41478233">[4 more]</label></div><br/><div class="children"><div class="content">With NeurIPS 2024 reviews going on right now, I&#x27;m sure that a whole lot of these kind of reviews are being generated daily.</div><br/><div id="41478709" class="c"><input type="checkbox" id="c-41478709" checked=""/><div class="controls bullet"><span class="by">bravura</span><span>|</span><a href="#41477844">root</a><span>|</span><a href="#41478233">parent</a><span>|</span><a href="#41478010">next</a><span>|</span><label class="collapse" for="c-41478709">[-]</label><label class="expand" for="c-41478709">[3 more]</label></div><br/><div class="children"><div class="content">With ICLR paper deadline coming up, I guess it&#x27;s worth wargaming how GPT4 would review my submission.</div><br/><div id="41478775" class="c"><input type="checkbox" id="c-41478775" checked=""/><div class="controls bullet"><span class="by">joshvm</span><span>|</span><a href="#41477844">root</a><span>|</span><a href="#41478709">parent</a><span>|</span><a href="#41478792">next</a><span>|</span><label class="collapse" for="c-41478775">[-]</label><label class="expand" for="c-41478775">[1 more]</label></div><br/><div class="children"><div class="content">See my other post - we had exactly this for NeurIPS. It is definitely worth seeing what GPT says about your paper if only because it&#x27;s a free review. The criticisms it gave us weren&#x27;t wrong per se, they were just weakly backed up and it would still be up to a reviewer to judge how relevant they are or not. Every paper has downsides, but you need domain knowledge to judge if it&#x27;s a small issue or a killer. Amusingly, our LLM-reviewer gave a much lower score than when we asked GPT to provide a rating (and also significantly lower than the other reviewers).<p>One example was that GPT took an explicit geographic location from a figure caption and used that as a reference point when suggesting improvements (along the lines of &quot;location X is under-represented on this map&quot;) I assume because it places some high degree of relevance to figures and the abstract when summarising papers. I think you might be able to combat this by writing defensively - in our case we might have avoided that by saying &quot;more information about geographic diversity may be found in X and the supplementary information&quot;</div><br/></div></div><div id="41478792" class="c"><input type="checkbox" id="c-41478792" checked=""/><div class="controls bullet"><span class="by">zaptrem</span><span>|</span><a href="#41477844">root</a><span>|</span><a href="#41478709">parent</a><span>|</span><a href="#41478775">prev</a><span>|</span><a href="#41478010">next</a><span>|</span><label class="collapse" for="c-41478792">[-]</label><label class="expand" for="c-41478792">[1 more]</label></div><br/><div class="children"><div class="content">Better yet, generate some adversarial perturbations to the text (or an invisible prompt) to cause it to give you a perfect review!</div><br/></div></div></div></div></div></div><div id="41478010" class="c"><input type="checkbox" id="c-41478010" checked=""/><div class="controls bullet"><span class="by">nextaccountic</span><span>|</span><a href="#41477844">root</a><span>|</span><a href="#41477907">parent</a><span>|</span><a href="#41478233">prev</a><span>|</span><a href="#41478913">next</a><span>|</span><label class="collapse" for="c-41478010">[-]</label><label class="expand" for="c-41478010">[1 more]</label></div><br/><div class="children"><div class="content">Could you share it publicly or would you face adverse consequences?<p>If you can please publish it and maybe post here on HN or reddit.</div><br/></div></div></div></div><div id="41478913" class="c"><input type="checkbox" id="c-41478913" checked=""/><div class="controls bullet"><span class="by">jampekka</span><span>|</span><a href="#41477844">parent</a><span>|</span><a href="#41477907">prev</a><span>|</span><a href="#41478355">next</a><span>|</span><label class="collapse" for="c-41478913">[-]</label><label class="expand" for="c-41478913">[1 more]</label></div><br/><div class="children"><div class="content">LLMs reviewing LLM generated articles via LLM editors is more or less guaranteed to become a massive thing given the incentive structures&#x2F;survival pressures of everyone involved.<p>Researchers get massive CVs, reviewers and editors get off easy, admins get to show great output numbers from their institutions, and of course the publishers continue making hand over fist.<p>It&#x27;s a rather broken system.</div><br/></div></div><div id="41478355" class="c"><input type="checkbox" id="c-41478355" checked=""/><div class="controls bullet"><span class="by">basch</span><span>|</span><a href="#41477844">parent</a><span>|</span><a href="#41478913">prev</a><span>|</span><a href="#41478087">next</a><span>|</span><label class="collapse" for="c-41478355">[-]</label><label class="expand" for="c-41478355">[4 more]</label></div><br/><div class="children"><div class="content">It might follow to say that current LLM;s arent trained to generate papers, BUT they also don&#x27;t really need to reason.<p>They just need to mimic the appearance of reason, follow the same pattern of progression.  Ingesting enough of what amounts to executed templates will teach it to generate its own results as if output from the same template.</div><br/><div id="41478600" class="c"><input type="checkbox" id="c-41478600" checked=""/><div class="controls bullet"><span class="by">Eisenstein</span><span>|</span><a href="#41477844">root</a><span>|</span><a href="#41478355">parent</a><span>|</span><a href="#41478087">next</a><span>|</span><label class="collapse" for="c-41478600">[-]</label><label class="expand" for="c-41478600">[3 more]</label></div><br/><div class="children"><div class="content">What is the difference between &#x27;reasoning&#x27; and &#x27;appearing to be reasoning&#x27; if the results are the same with the same input?</div><br/><div id="41478774" class="c"><input type="checkbox" id="c-41478774" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#41477844">root</a><span>|</span><a href="#41478600">parent</a><span>|</span><a href="#41478659">next</a><span>|</span><label class="collapse" for="c-41478774">[-]</label><label class="expand" for="c-41478774">[1 more]</label></div><br/><div class="children"><div class="content">The outputs aren&#x27;t really the same, they simply seem plausible at first glance.<p>For example, I recently experimented with using ChatGPT to translate a Wikipedia article, on the grounds that it mighy maintain all the formatting and that Transformer models are also used by Google Translate.<p>As it was an experiment, I did actually check the results before submitting the translated article.<p>First roughly 3&#x2F;4 were fine. Final quarter was completely invented but plausible, including references.<p>LLMs are very useful tools, I&#x27;ll gladly use them to help with various tasks and they can (with low reliability but it has happened) even manage a whole project, but right now they should treated with caution and not left unsupervised — Peter principle, being promoted beyond their competence, still applies even though they&#x27;re not human employees.</div><br/></div></div><div id="41478659" class="c"><input type="checkbox" id="c-41478659" checked=""/><div class="controls bullet"><span class="by">nis0s</span><span>|</span><a href="#41477844">root</a><span>|</span><a href="#41478600">parent</a><span>|</span><a href="#41478774">prev</a><span>|</span><a href="#41478087">next</a><span>|</span><label class="collapse" for="c-41478659">[-]</label><label class="expand" for="c-41478659">[1 more]</label></div><br/><div class="children"><div class="content">From what I’ve seen, the results are not the same. In the latter scenario, there’s a risk of encountering a non sequitur all of a sudden, and the citations may be nonexistent. There’s also no guarantee that what you’re stating is factually correct when your logic is unbounded by reality.</div><br/></div></div></div></div></div></div><div id="41478087" class="c"><input type="checkbox" id="c-41478087" checked=""/><div class="controls bullet"><span class="by">kovezd</span><span>|</span><a href="#41477844">parent</a><span>|</span><a href="#41478355">prev</a><span>|</span><a href="#41479063">next</a><span>|</span><label class="collapse" for="c-41478087">[-]</label><label class="expand" for="c-41478087">[3 more]</label></div><br/><div class="children"><div class="content">I can see how LLMs contribute to raise the standard in that field. For example, surveying related research. Also, maybe in the not too distant future, reproducing (some) of the results.</div><br/><div id="41478368" class="c"><input type="checkbox" id="c-41478368" checked=""/><div class="controls bullet"><span class="by">jll29</span><span>|</span><a href="#41477844">root</a><span>|</span><a href="#41478087">parent</a><span>|</span><a href="#41479063">next</a><span>|</span><label class="collapse" for="c-41478368">[-]</label><label class="expand" for="c-41478368">[2 more]</label></div><br/><div class="children"><div class="content">Writing consists of iterated re-writing (to me, anyways), i.e. better and better ways to express content 1. correctly, 2. clearly and 3. space-economically.<p>By writing it down (yourself) you understand what claims each piece of related work discussed has made (and can realistically make - as there sometims are inflationary lists of claims in papers), and this helps you formulate your own claim as it relates to them (new task, novel method for known task, like older method but works better, nearly as good as a past method but runs faster etc.).<p>If you outsource it to a machine you no longer see it through, and the result will be poor unless you are a very bad writer.<p>I can, however, see a role for LLMs in an electronic &quot;learn how to write better&quot; tutoring system.</div><br/><div id="41478613" class="c"><input type="checkbox" id="c-41478613" checked=""/><div class="controls bullet"><span class="by">Eisenstein</span><span>|</span><a href="#41477844">root</a><span>|</span><a href="#41478368">parent</a><span>|</span><a href="#41479063">next</a><span>|</span><label class="collapse" for="c-41478613">[-]</label><label class="expand" for="c-41478613">[1 more]</label></div><br/><div class="children"><div class="content">Does every researcher write summaries of related research themselves?</div><br/></div></div></div></div></div></div></div></div><div id="41479063" class="c"><input type="checkbox" id="c-41479063" checked=""/><div class="controls bullet"><span class="by">tkgally</span><span>|</span><a href="#41477844">prev</a><span>|</span><a href="#41477788">next</a><span>|</span><label class="collapse" for="c-41479063">[-]</label><label class="expand" for="c-41479063">[1 more]</label></div><br/><div class="children"><div class="content">For a paper that includes both a broad discussion of the scholarly issues raised by LLMs and wide-ranging policy recommendations, I wish the authors had taken a more nuanced approach to data collection than just searching for “as of my last knowledge update” and&#x2F;or “I don’t have access to real-time data” and weeding out the false positives manually. LLMs can be used in scholarly writing in many ways that will not be caught with such a coarse sieve. Some are obviously illegitimate, such as having an LLM write an entire paper with fabricated data. But there are other ways that are not so clearly unacceptable.<p>For example, the authors’ statement that “[GPT’s] undeclared use—beyond proofreading—has potentially far-reaching implications for both science and society” suggests that, for them, using LLMs for “proofreading” is okay. But “proofreading” is understood in various ways. For some people, it would include only correcting spelling and grammatical mistakes. For others, especially for people who are not native speakers of English, it can also include changing the wording and even rewriting entire sentences and paragraphs to make the meaning clearer. To what extent can one use an LLM for such revision without declaring that one has done so?</div><br/></div></div><div id="41477788" class="c"><input type="checkbox" id="c-41477788" checked=""/><div class="controls bullet"><span class="by">refibrillator</span><span>|</span><a href="#41479063">prev</a><span>|</span><a href="#41477612">next</a><span>|</span><label class="collapse" for="c-41477788">[-]</label><label class="expand" for="c-41477788">[5 more]</label></div><br/><div class="children"><div class="content">Hmm there may be a bug in the authors’ python script that searches google scholar for the phrases &quot;as of my last knowledge update&quot; or &quot;I don&#x27;t have access to real-time data&quot;. You can see the code in appendix B.<p>The bug happens if the ‘bib’ key doesn’t exist in the api response. That leads to the urls array having more rows than the paper_data array. So the columns could become mismatched in the final data frame. It seems they made a third array called flag which could be used to detect and remove the bad results, but it’s not used any where in the posted code.<p>Not clear to me how this would affect their analysis, it does seem like something they would catch when manually reviewing the papers. But perhaps the bibliographic data wasn’t reviewed and only used to calculate the summary stats etc.</div><br/><div id="41478008" class="c"><input type="checkbox" id="c-41478008" checked=""/><div class="controls bullet"><span class="by">viraptor</span><span>|</span><a href="#41477788">parent</a><span>|</span><a href="#41478338">next</a><span>|</span><label class="collapse" for="c-41478008">[-]</label><label class="expand" for="c-41478008">[1 more]</label></div><br/><div class="children"><div class="content">That sounds important enough to contact the authors. Best case, they fixed it up manually; worst case, lots of papers are publicly accused of being made up and the whole farming&#x2F;fish-focused summary they produced is completely wrong.</div><br/></div></div><div id="41478338" class="c"><input type="checkbox" id="c-41478338" checked=""/><div class="controls bullet"><span class="by">Lerc</span><span>|</span><a href="#41477788">parent</a><span>|</span><a href="#41478008">prev</a><span>|</span><a href="#41478101">next</a><span>|</span><label class="collapse" for="c-41478338">[-]</label><label class="expand" for="c-41478338">[2 more]</label></div><br/><div class="children"><div class="content">As a tangent to the paper topic itself,  what should be the standard procedure for publishing data gathering code like this?  Given that they don&#x27;t specify which version of any libraries or APIs used and that updates occur over time, API&#x27;s change etc. inevitably resulting in code rot.  It will eventually be impossible to figure out exactly what this code did.<p>With meticulous version records it should at least be possible to ascertain what the code did by reconstructing that exact version (assuming stored back versions exist)</div><br/><div id="41478512" class="c"><input type="checkbox" id="c-41478512" checked=""/><div class="controls bullet"><span class="by">jerpint</span><span>|</span><a href="#41477788">root</a><span>|</span><a href="#41478338">parent</a><span>|</span><a href="#41478101">next</a><span>|</span><label class="collapse" for="c-41478512">[-]</label><label class="expand" for="c-41478512">[1 more]</label></div><br/><div class="children"><div class="content">Using a colab with printed outputs could be a good option to at the very least hint to reproducing results independently</div><br/></div></div></div></div><div id="41478101" class="c"><input type="checkbox" id="c-41478101" checked=""/><div class="controls bullet"><span class="by">hiddencost</span><span>|</span><a href="#41477788">parent</a><span>|</span><a href="#41478338">prev</a><span>|</span><a href="#41477612">next</a><span>|</span><label class="collapse" for="c-41478101">[-]</label><label class="expand" for="c-41478101">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;www.hb.se&#x2F;en&#x2F;research&#x2F;research-portal&#x2F;researchers&#x2F;JUHA&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.hb.se&#x2F;en&#x2F;research&#x2F;research-portal&#x2F;researchers&#x2F;JU...</a><p>Contact info for the first author</div><br/></div></div></div></div><div id="41477612" class="c"><input type="checkbox" id="c-41477612" checked=""/><div class="controls bullet"><span class="by">nomilk</span><span>|</span><a href="#41477788">prev</a><span>|</span><a href="#41478784">next</a><span>|</span><label class="collapse" for="c-41477612">[-]</label><label class="expand" for="c-41477612">[6 more]</label></div><br/><div class="children"><div class="content">GPT might make fabricating scientific papers easier, but let&#x27;s not forget how many humans fabricated scientific research in recent years - they did a great job without AI!<p>For any who haven&#x27;t seen&#x2F;heard, this makes for some entertaining and eye-opening viewing!<p><a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;results?search_query=academic+fraud" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;results?search_query=academic+fraud</a></div><br/><div id="41478360" class="c"><input type="checkbox" id="c-41478360" checked=""/><div class="controls bullet"><span class="by">benreesman</span><span>|</span><a href="#41477612">parent</a><span>|</span><a href="#41477851">next</a><span>|</span><label class="collapse" for="c-41478360">[-]</label><label class="expand" for="c-41478360">[3 more]</label></div><br/><div class="children"><div class="content">I think it’s important to remember that while the tidal wave of spam just starting to crest courtesy of the less scrupulous LLM vendors is uh, necessary to address, this century’s war on epistemology was well underway already in the grand traditions of periodic wars on the idea that facts are even aspirationally, directionally worthwhile. The phrase “alternative facts” hit the mainstream in 2016 and the idea that resistance is futile on broad-spectrum digital weaponized bytes was muscular then (that was around the time I was starting to feel ill for being a key architect of it).<p>Now technology is a human artifact and always ends up resembling its creators or financiers or both: I’d have nice fonts on my computer in 2024 most likely either way, but it’s directly because of Jobs they were available in 1984 to a household budget.<p>If someone other than Altman had or some other insight than “this thing can lie in a newly scalable way” was the escape velocity moment on LLMs then we’d still have test sets and metrics and just science going on in the Commanding Heights of the S&amp;P 500, but these people are a symptom of our apathy around any noble instinct. If we had stuck firm on our values no effective altruism cult leader type would even make the press.</div><br/><div id="41479074" class="c"><input type="checkbox" id="c-41479074" checked=""/><div class="controls bullet"><span class="by">__loam</span><span>|</span><a href="#41477612">root</a><span>|</span><a href="#41478360">parent</a><span>|</span><a href="#41477851">next</a><span>|</span><label class="collapse" for="c-41479074">[-]</label><label class="expand" for="c-41479074">[2 more]</label></div><br/><div class="children"><div class="content">Post-modernism was a mistake.</div><br/><div id="41479094" class="c"><input type="checkbox" id="c-41479094" checked=""/><div class="controls bullet"><span class="by">benreesman</span><span>|</span><a href="#41477612">root</a><span>|</span><a href="#41479074">parent</a><span>|</span><a href="#41477851">next</a><span>|</span><label class="collapse" for="c-41479094">[-]</label><label class="expand" for="c-41479094">[1 more]</label></div><br/><div class="children"><div class="content">Indeed. I used to think that when it hybridized with Objectivism that was the nastiest malware around but god damn if Amodei and co haven’t rootkitted society to a new level.</div><br/></div></div></div></div></div></div><div id="41477851" class="c"><input type="checkbox" id="c-41477851" checked=""/><div class="controls bullet"><span class="by">bumby</span><span>|</span><a href="#41477612">parent</a><span>|</span><a href="#41478360">prev</a><span>|</span><a href="#41478772">next</a><span>|</span><label class="collapse" for="c-41477851">[-]</label><label class="expand" for="c-41477851">[1 more]</label></div><br/><div class="children"><div class="content">Is there good data on how many are fraudulent? I know there’s reasonable data on replicability issues, but that’s potentially different.</div><br/></div></div><div id="41478772" class="c"><input type="checkbox" id="c-41478772" checked=""/><div class="controls bullet"><span class="by">croes</span><span>|</span><a href="#41477612">parent</a><span>|</span><a href="#41477851">prev</a><span>|</span><a href="#41478784">next</a><span>|</span><label class="collapse" for="c-41478772">[-]</label><label class="expand" for="c-41478772">[1 more]</label></div><br/><div class="children"><div class="content">But AI is to papers what the assembly line was to cars.</div><br/></div></div></div></div><div id="41478784" class="c"><input type="checkbox" id="c-41478784" checked=""/><div class="controls bullet"><span class="by">kgeist</span><span>|</span><a href="#41477612">prev</a><span>|</span><a href="#41478897">next</a><span>|</span><label class="collapse" for="c-41478784">[-]</label><label class="expand" for="c-41478784">[1 more]</label></div><br/><div class="children"><div class="content">I wonder how many of the GPT-generated papers are actually made by people whose native language is not English and who want to improve their English. That would explain various &quot;as of my last knowledge update&quot; still left intact in the papers, if the authors don&#x27;t fully understand what it means.</div><br/></div></div><div id="41478897" class="c"><input type="checkbox" id="c-41478897" checked=""/><div class="controls bullet"><span class="by">daghamm</span><span>|</span><a href="#41478784">prev</a><span>|</span><a href="#41478387">next</a><span>|</span><label class="collapse" for="c-41478897">[-]</label><label class="expand" for="c-41478897">[1 more]</label></div><br/><div class="children"><div class="content">Last time we discussed this, someone basically searched for phrases such as &quot;certainly I can do X for you&quot; and assumed that meant GPT was used. HN noticed that many of the accused papers actually predated openai.<p>Hope this research is better.</div><br/></div></div><div id="41478387" class="c"><input type="checkbox" id="c-41478387" checked=""/><div class="controls bullet"><span class="by">pcrh</span><span>|</span><a href="#41478897">prev</a><span>|</span><a href="#41477647">next</a><span>|</span><label class="collapse" for="c-41478387">[-]</label><label class="expand" for="c-41478387">[2 more]</label></div><br/><div class="children"><div class="content">This kind of fabricated result is not a problem for practitioners in the relevant fields, who can easily distinguish between false and real work.<p>If there are instances where the ability to make such distinctions is lost, it is most likely to be so because the content lacks novelty, i.e. it simply regurgitates known and established facts. In which case it is a pointless  effort, even if it might inflate the supposed author&#x27;s list of publications.<p>As to the integrity of researchers, this is a known issue. The temptation to fabricate data existed long before the latest innovations in AI, and is very easy to do in most fields, particularly in medicine or biosciences which constitute the bulk of irreproducible research. Policing this kind of behavior is not altered by GPT or similar.<p>The bigger problem, however, is when non-experts attempt to become informed and are unable to distinguish between plausible and implausible sources of information. This is already a problem even without AI, consider the debates over the origins of SARS-CoV2, for example.  The solution to this is the cultivation and funding of sources of expertise, e.g. in Universities and similar.</div><br/><div id="41478581" class="c"><input type="checkbox" id="c-41478581" checked=""/><div class="controls bullet"><span class="by">EnigmaFlare</span><span>|</span><a href="#41478387">parent</a><span>|</span><a href="#41477647">next</a><span>|</span><label class="collapse" for="c-41478581">[-]</label><label class="expand" for="c-41478581">[1 more]</label></div><br/><div class="children"><div class="content">Non-experts actually attempting to become informed (instead of just feeling like they&#x27;re informed) can easily tell the difference too. The people being fooled are the ones who <i>want</i> to be fooled. They&#x27;re looking for something to support their pre-existing belief. And for those people, they&#x27;ll always find something they can convince themselves supports their belief, so I don&#x27;t think it matters what false information is floating around.<p>It seems to be kind of a new thing for laymen to be reading scientific papers. 20 years ago, they just weren&#x27;t accessible. You had to physically go to a local university library and work out how to use the arcane search tools, which wouldn&#x27;t really find what you wanted anyway. And even then, you couldn&#x27;t take it home and half the time you couldn&#x27;t even photocopy it because you needed a student ID card to use the photocopier.</div><br/></div></div></div></div><div id="41477647" class="c"><input type="checkbox" id="c-41477647" checked=""/><div class="controls bullet"><span class="by">hodgesrm</span><span>|</span><a href="#41478387">prev</a><span>|</span><a href="#41477576">next</a><span>|</span><label class="collapse" for="c-41477647">[-]</label><label class="expand" for="c-41477647">[8 more]</label></div><br/><div class="children"><div class="content">&gt; Two main risks arise... First, the abundance of fabricated “studies” seeping into all areas of the research infrastructure... A second risk lies in the increased possibility that convincingly scientific-looking content was in fact deceitfully created with AI tools...<p>A third risk: ChatGPT has no understanding of &quot;truth&quot; in the sense of facts reported by established, trusted sources. I&#x27;m doing a research project related to use of data lakes and tried using ChatGPT to search for original sources. It&#x27;s a shitshow of fabricated links and pedestrian summaries of marketing materials.<p>This feels like an evolutionary dead end.</div><br/><div id="41477829" class="c"><input type="checkbox" id="c-41477829" checked=""/><div class="controls bullet"><span class="by">kenjackson</span><span>|</span><a href="#41477647">parent</a><span>|</span><a href="#41478021">next</a><span>|</span><label class="collapse" for="c-41477829">[-]</label><label class="expand" for="c-41477829">[4 more]</label></div><br/><div class="children"><div class="content">It sounds like your use of AI is one of the worst uses.  Standard semantic search would be much better and appropriate.</div><br/><div id="41478689" class="c"><input type="checkbox" id="c-41478689" checked=""/><div class="controls bullet"><span class="by">nis0s</span><span>|</span><a href="#41477647">root</a><span>|</span><a href="#41477829">parent</a><span>|</span><a href="#41478287">next</a><span>|</span><label class="collapse" for="c-41478689">[-]</label><label class="expand" for="c-41478689">[1 more]</label></div><br/><div class="children"><div class="content">If summarization and analysis isn’t the main use of AI, then what is?</div><br/></div></div><div id="41478287" class="c"><input type="checkbox" id="c-41478287" checked=""/><div class="controls bullet"><span class="by">hodgesrm</span><span>|</span><a href="#41477647">root</a><span>|</span><a href="#41477829">parent</a><span>|</span><a href="#41478689">prev</a><span>|</span><a href="#41478104">next</a><span>|</span><label class="collapse" for="c-41478287">[-]</label><label class="expand" for="c-41478287">[1 more]</label></div><br/><div class="children"><div class="content">No disagreement with that. My expectations were not high--but I was still surprised how bad it was. There are absolutely no guardrails.</div><br/></div></div><div id="41478104" class="c"><input type="checkbox" id="c-41478104" checked=""/><div class="controls bullet"><span class="by">HeatrayEnjoyer</span><span>|</span><a href="#41477647">root</a><span>|</span><a href="#41477829">parent</a><span>|</span><a href="#41478287">prev</a><span>|</span><a href="#41478021">next</a><span>|</span><label class="collapse" for="c-41478104">[-]</label><label class="expand" for="c-41478104">[1 more]</label></div><br/><div class="children"><div class="content">How do you run a semantic search</div><br/></div></div></div></div><div id="41478021" class="c"><input type="checkbox" id="c-41478021" checked=""/><div class="controls bullet"><span class="by">viraptor</span><span>|</span><a href="#41477647">parent</a><span>|</span><a href="#41477829">prev</a><span>|</span><a href="#41477845">next</a><span>|</span><label class="collapse" for="c-41478021">[-]</label><label class="expand" for="c-41478021">[2 more]</label></div><br/><div class="children"><div class="content">&gt; tried using ChatGPT to search for original sources<p>That&#x27;s a bad idea, do not do that. Regardless of the the knowledge contained in ChatGPT, it&#x27;s a completely wrong tool&#x2F;tech - like using a jackhammer as a screwdriver. If your want original sources, then services like <a href="https:&#x2F;&#x2F;perplexity.ai" rel="nofollow">https:&#x2F;&#x2F;perplexity.ai</a> can do it. It&#x27;s not even an issue with ChatGPT as such, it was never intended for that - that&#x27;s why they&#x27;re trying to create search as well <a href="https:&#x2F;&#x2F;openai.com&#x2F;index&#x2F;searchgpt-prototype&#x2F;" rel="nofollow">https:&#x2F;&#x2F;openai.com&#x2F;index&#x2F;searchgpt-prototype&#x2F;</a></div><br/><div id="41478309" class="c"><input type="checkbox" id="c-41478309" checked=""/><div class="controls bullet"><span class="by">hodgesrm</span><span>|</span><a href="#41477647">root</a><span>|</span><a href="#41478021">parent</a><span>|</span><a href="#41477845">next</a><span>|</span><label class="collapse" for="c-41478309">[-]</label><label class="expand" for="c-41478309">[1 more]</label></div><br/><div class="children"><div class="content">Perplexity.ai looks a lot better. Thanks for the link.<p>(edited: typo)</div><br/></div></div></div></div></div></div><div id="41477576" class="c"><input type="checkbox" id="c-41477576" checked=""/><div class="controls bullet"><span class="by">layer8</span><span>|</span><a href="#41477647">prev</a><span>|</span><a href="#41478357">next</a><span>|</span><label class="collapse" for="c-41477576">[-]</label><label class="expand" for="c-41477576">[14 more]</label></div><br/><div class="children"><div class="content">I appreciate that, appropriately, the article image is not AI-generated.</div><br/><div id="41478611" class="c"><input type="checkbox" id="c-41478611" checked=""/><div class="controls bullet"><span class="by">EnigmaFlare</span><span>|</span><a href="#41477576">parent</a><span>|</span><a href="#41478005">next</a><span>|</span><label class="collapse" for="c-41478611">[-]</label><label class="expand" for="c-41478611">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s silly that there&#x27;s a stigma attached to AI generated images in cases where it&#x27;s perfectly reasonable to do. People seem to appreciate things more for the fact that they were created by spending time out of another human&#x27;s life more than what it actually is.</div><br/><div id="41479091" class="c"><input type="checkbox" id="c-41479091" checked=""/><div class="controls bullet"><span class="by">__loam</span><span>|</span><a href="#41477576">root</a><span>|</span><a href="#41478611">parent</a><span>|</span><a href="#41478005">next</a><span>|</span><label class="collapse" for="c-41479091">[-]</label><label class="expand" for="c-41479091">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s built on theft and it&#x27;s a negative quality signal usually.</div><br/></div></div></div></div><div id="41478005" class="c"><input type="checkbox" id="c-41478005" checked=""/><div class="controls bullet"><span class="by">snakeyjake</span><span>|</span><a href="#41477576">parent</a><span>|</span><a href="#41478611">prev</a><span>|</span><a href="#41477598">next</a><span>|</span><label class="collapse" for="c-41478005">[-]</label><label class="expand" for="c-41478005">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;re not allowed to express a preference for media that isn&#x27;t AI-generated garbage on HN without being downvoted.<p>All of the grindset entrepreneurs who think that AI-generated garbage is the future of humanity and their startup get mad and they stumble over themselves to show you AI-generated garbage that they think is good but only fools Facebook-addicted geriatrics and grindset entrepreneur FoUnDeRs who run chatgpt wrappers cosplaying as AI startups.</div><br/></div></div><div id="41477598" class="c"><input type="checkbox" id="c-41477598" checked=""/><div class="controls bullet"><span class="by">judge2020</span><span>|</span><a href="#41477576">parent</a><span>|</span><a href="#41478005">prev</a><span>|</span><a href="#41478357">next</a><span>|</span><label class="collapse" for="c-41477598">[-]</label><label class="expand" for="c-41477598">[10 more]</label></div><br/><div class="children"><div class="content">I was able to get pretty close with chatgpt: <a href="https:&#x2F;&#x2F;rr.judge.sh&#x2F;Commabutterfly&#x2F;76b34e&#x2F;nmwguWGt8pIe.jpg" rel="nofollow">https:&#x2F;&#x2F;rr.judge.sh&#x2F;Commabutterfly&#x2F;76b34e&#x2F;nmwguWGt8pIe.jpg</a><p>&gt; create a picture of scrabble pieces strewn on a table, with a closeup of a line of scrabble letters spelling &quot;CHATGPT&quot; on top of them. photographic, realistic quality, maintain realism and believability</div><br/><div id="41477664" class="c"><input type="checkbox" id="c-41477664" checked=""/><div class="controls bullet"><span class="by">layer8</span><span>|</span><a href="#41477576">root</a><span>|</span><a href="#41477598">parent</a><span>|</span><a href="#41477646">next</a><span>|</span><label class="collapse" for="c-41477664">[-]</label><label class="expand" for="c-41477664">[1 more]</label></div><br/><div class="children"><div class="content">The number markings on the Scrabble pieces are nonsensical, the wooden ground looks like plastic, there are strange artifacts like the white smudge on the edge of the “E” tile in the front, and so on.<p>AI-generated images are clearly identifiable as such, and it just gets annoying to continually see those desultory fabrications.</div><br/></div></div><div id="41477646" class="c"><input type="checkbox" id="c-41477646" checked=""/><div class="controls bullet"><span class="by">GaggiX</span><span>|</span><a href="#41477576">root</a><span>|</span><a href="#41477598">parent</a><span>|</span><a href="#41477664">prev</a><span>|</span><a href="#41477607">next</a><span>|</span><label class="collapse" for="c-41477646">[-]</label><label class="expand" for="c-41477646">[6 more]</label></div><br/><div class="children"><div class="content">You can get much better results with Ideogram 2 (also free):<p><a href="https:&#x2F;&#x2F;ideogram.ai&#x2F;assets&#x2F;image&#x2F;lossless&#x2F;response&#x2F;vF81gKjHSA6fYUSxyzzljQ" rel="nofollow">https:&#x2F;&#x2F;ideogram.ai&#x2F;assets&#x2F;image&#x2F;lossless&#x2F;response&#x2F;vF81gKjHS...</a><p><a href="https:&#x2F;&#x2F;ideogram.ai&#x2F;assets&#x2F;image&#x2F;lossless&#x2F;response&#x2F;EcRpDLumSAOGdLsCSraBhw" rel="nofollow">https:&#x2F;&#x2F;ideogram.ai&#x2F;assets&#x2F;image&#x2F;lossless&#x2F;response&#x2F;EcRpDLumS...</a><p>Almost the same prompt.</div><br/><div id="41478077" class="c"><input type="checkbox" id="c-41478077" checked=""/><div class="controls bullet"><span class="by">vunderba</span><span>|</span><a href="#41477576">root</a><span>|</span><a href="#41477646">parent</a><span>|</span><a href="#41477652">next</a><span>|</span><label class="collapse" for="c-41478077">[-]</label><label class="expand" for="c-41478077">[2 more]</label></div><br/><div class="children"><div class="content">You can also get reasonably close with an open model that you can run locally (flux dev).<p><a href="https:&#x2F;&#x2F;replicate.com&#x2F;p&#x2F;xm41nvz05drm00chsywb6am7f0">https:&#x2F;&#x2F;replicate.com&#x2F;p&#x2F;xm41nvz05drm00chsywb6am7f0</a><p><a href="https:&#x2F;&#x2F;replicate.com&#x2F;p&#x2F;kdw8bnkj39rm40chsyzbyg5e04">https:&#x2F;&#x2F;replicate.com&#x2F;p&#x2F;kdw8bnkj39rm40chsyzbyg5e04</a><p>But of course anyone who has even a passing familiarity with scrabble is going to be able to tell that something&#x27;s off.</div><br/><div id="41478118" class="c"><input type="checkbox" id="c-41478118" checked=""/><div class="controls bullet"><span class="by">GaggiX</span><span>|</span><a href="#41477576">root</a><span>|</span><a href="#41478077">parent</a><span>|</span><a href="#41477652">next</a><span>|</span><label class="collapse" for="c-41478118">[-]</label><label class="expand" for="c-41478118">[1 more]</label></div><br/><div class="children"><div class="content">The biggest problem with the default Flux model is that it generates images with that strong AI look, probably caused by the distillation of the CFG. You should try some LoRAs for this, and also prompt the model to generate the rack that holds the letters.</div><br/></div></div></div></div><div id="41477652" class="c"><input type="checkbox" id="c-41477652" checked=""/><div class="controls bullet"><span class="by">renewiltord</span><span>|</span><a href="#41477576">root</a><span>|</span><a href="#41477646">parent</a><span>|</span><a href="#41478077">prev</a><span>|</span><a href="#41477607">next</a><span>|</span><label class="collapse" for="c-41477652">[-]</label><label class="expand" for="c-41477652">[3 more]</label></div><br/><div class="children"><div class="content">Great tip. The text handling here is far superior.</div><br/><div id="41477670" class="c"><input type="checkbox" id="c-41477670" checked=""/><div class="controls bullet"><span class="by">layer8</span><span>|</span><a href="#41477576">root</a><span>|</span><a href="#41477652">parent</a><span>|</span><a href="#41477607">next</a><span>|</span><label class="collapse" for="c-41477670">[-]</label><label class="expand" for="c-41477670">[2 more]</label></div><br/><div class="children"><div class="content">The “1”s are still inconsistent, and of course the numbers are all wrong.</div><br/><div id="41477697" class="c"><input type="checkbox" id="c-41477697" checked=""/><div class="controls bullet"><span class="by">skybrian</span><span>|</span><a href="#41477576">root</a><span>|</span><a href="#41477670">parent</a><span>|</span><a href="#41477607">next</a><span>|</span><label class="collapse" for="c-41477697">[-]</label><label class="expand" for="c-41477697">[1 more]</label></div><br/><div class="children"><div class="content">This seems like a good idea for a contest.</div><br/></div></div></div></div></div></div></div></div><div id="41477607" class="c"><input type="checkbox" id="c-41477607" checked=""/><div class="controls bullet"><span class="by">Daub</span><span>|</span><a href="#41477576">root</a><span>|</span><a href="#41477598">parent</a><span>|</span><a href="#41477646">prev</a><span>|</span><a href="#41478357">next</a><span>|</span><label class="collapse" for="c-41477607">[-]</label><label class="expand" for="c-41477607">[2 more]</label></div><br/><div class="children"><div class="content">I prefer yours. Better lighting.</div><br/><div id="41477663" class="c"><input type="checkbox" id="c-41477663" checked=""/><div class="controls bullet"><span class="by">doesnt_know</span><span>|</span><a href="#41477576">root</a><span>|</span><a href="#41477607">parent</a><span>|</span><a href="#41478357">next</a><span>|</span><label class="collapse" for="c-41477663">[-]</label><label class="expand" for="c-41477663">[1 more]</label></div><br/><div class="children"><div class="content">The points on all the tiles are messed up and there are tiles with random squiggles where there should be letters...</div><br/></div></div></div></div></div></div></div></div><div id="41478357" class="c"><input type="checkbox" id="c-41478357" checked=""/><div class="controls bullet"><span class="by">oefrha</span><span>|</span><a href="#41477576">prev</a><span>|</span><a href="#41477644">next</a><span>|</span><label class="collapse" for="c-41478357">[-]</label><label class="expand" for="c-41478357">[1 more]</label></div><br/><div class="children"><div class="content">How about people stop responding to titles for a change. This isn’t about papers that merely used ChatGPT and got caught by some cutting edge detection techniques, it’s about papers that blatantly include ChatGPT boilerplates like<p>&gt; “as of my last knowledge update” and&#x2F;or “I don’t have access to real-time data”<p>which suggests no human (don’t even need to be a researcher) read every sentence of these damn “papers”. That’s a pretty low bar to clear, if you can’t even bother to read generated crap before including it in your paper, your academic integrity is negative and not a word from you can carry any weight.</div><br/></div></div><div id="41477644" class="c"><input type="checkbox" id="c-41477644" checked=""/><div class="controls bullet"><span class="by">OutOfHere</span><span>|</span><a href="#41478357">prev</a><span>|</span><a href="#41477661">next</a><span>|</span><label class="collapse" for="c-41477644">[-]</label><label class="expand" for="c-41477644">[11 more]</label></div><br/><div class="children"><div class="content">Just because ChatGPT was used to help write a paper doesn&#x27;t in itself mean that the data or findings are fabricated.</div><br/><div id="41477694" class="c"><input type="checkbox" id="c-41477694" checked=""/><div class="controls bullet"><span class="by">ceejayoz</span><span>|</span><a href="#41477644">parent</a><span>|</span><a href="#41477700">next</a><span>|</span><label class="collapse" for="c-41477694">[-]</label><label class="expand" for="c-41477694">[2 more]</label></div><br/><div class="children"><div class="content">Sure, but there are some... pretty egregious cases. <a href="https:&#x2F;&#x2F;mashable.com&#x2F;article&#x2F;ai-rat-penis-diagram-midjourney-science" rel="nofollow">https:&#x2F;&#x2F;mashable.com&#x2F;article&#x2F;ai-rat-penis-diagram-midjourney...</a></div><br/><div id="41478473" class="c"><input type="checkbox" id="c-41478473" checked=""/><div class="controls bullet"><span class="by">hakanderyal</span><span>|</span><a href="#41477644">root</a><span>|</span><a href="#41477694">parent</a><span>|</span><a href="#41477700">next</a><span>|</span><label class="collapse" for="c-41478473">[-]</label><label class="expand" for="c-41478473">[1 more]</label></div><br/><div class="children"><div class="content">That’s the funniest piece of writing I’ve read in a longtime, thanks!<p>I wonder what they were thinking submitting the paper.</div><br/></div></div></div></div><div id="41477700" class="c"><input type="checkbox" id="c-41477700" checked=""/><div class="controls bullet"><span class="by">riedel</span><span>|</span><a href="#41477644">parent</a><span>|</span><a href="#41477694">prev</a><span>|</span><a href="#41478435">next</a><span>|</span><label class="collapse" for="c-41477700">[-]</label><label class="expand" for="c-41477700">[2 more]</label></div><br/><div class="children"><div class="content">True. I am seeing chatgpt used by my colleagues (mostly no English native speakers) day to day and it mostly improves their writing (except for those wotfd that pop up  a bit too often [0] like utilize [1]).  So not all bad.<p>I am also hearing that a lot of reviewers and readers use it though. So we are often joking that PhD students (in CS) nowadays only write bullet point from their research. Generate prose that is used to generate bullet points.<p>[0] <a href="https:&#x2F;&#x2F;www.scientificamerican.com&#x2F;article&#x2F;chatbots-have-thoroughly-infiltrated-scientific-publishing&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.scientificamerican.com&#x2F;article&#x2F;chatbots-have-tho...</a><p>[1] <a href="https:&#x2F;&#x2F;medium.com&#x2F;learning-data&#x2F;words-and-phrases-that-make-it-obvious-you-used-chatgpt-2ba374033ac6" rel="nofollow">https:&#x2F;&#x2F;medium.com&#x2F;learning-data&#x2F;words-and-phrases-that-make...</a></div><br/><div id="41477923" class="c"><input type="checkbox" id="c-41477923" checked=""/><div class="controls bullet"><span class="by">CuriouslyC</span><span>|</span><a href="#41477644">root</a><span>|</span><a href="#41477700">parent</a><span>|</span><a href="#41478435">next</a><span>|</span><label class="collapse" for="c-41477923">[-]</label><label class="expand" for="c-41477923">[1 more]</label></div><br/><div class="children"><div class="content">Scientific writing is pretty bad usually so I&#x27;ll count this as an improvement</div><br/></div></div></div></div><div id="41478435" class="c"><input type="checkbox" id="c-41478435" checked=""/><div class="controls bullet"><span class="by">anigbrowl</span><span>|</span><a href="#41477644">parent</a><span>|</span><a href="#41477700">prev</a><span>|</span><a href="#41477823">next</a><span>|</span><label class="collapse" for="c-41478435">[-]</label><label class="expand" for="c-41478435">[1 more]</label></div><br/><div class="children"><div class="content">You can probably find some quality stuff in your local landfill too, but I am personally unwilling to sift through garbage.</div><br/></div></div><div id="41477823" class="c"><input type="checkbox" id="c-41477823" checked=""/><div class="controls bullet"><span class="by">j16sdiz</span><span>|</span><a href="#41477644">parent</a><span>|</span><a href="#41478435">prev</a><span>|</span><a href="#41478131">next</a><span>|</span><label class="collapse" for="c-41477823">[-]</label><label class="expand" for="c-41477823">[2 more]</label></div><br/><div class="children"><div class="content">How can I trust the paper when there is no proper proofreading?</div><br/><div id="41478308" class="c"><input type="checkbox" id="c-41478308" checked=""/><div class="controls bullet"><span class="by">OutOfHere</span><span>|</span><a href="#41477644">root</a><span>|</span><a href="#41477823">parent</a><span>|</span><a href="#41478131">next</a><span>|</span><label class="collapse" for="c-41478308">[-]</label><label class="expand" for="c-41478308">[1 more]</label></div><br/><div class="children"><div class="content">How do you know there is no proper proofreading? There is no way to tell, is there? Just because content was generated by an LLM doesn&#x27;t in itself mean that it wasn&#x27;t proofread.</div><br/></div></div></div></div><div id="41478131" class="c"><input type="checkbox" id="c-41478131" checked=""/><div class="controls bullet"><span class="by">cratermoon</span><span>|</span><a href="#41477644">parent</a><span>|</span><a href="#41477823">prev</a><span>|</span><a href="#41477727">next</a><span>|</span><label class="collapse" for="c-41478131">[-]</label><label class="expand" for="c-41478131">[2 more]</label></div><br/><div class="children"><div class="content">The problem is not that <i>a</i> paper has fabricated content generated by ChatGPT,
the problem is that there are <i>many</i> papers and they are polluting scholarship to the point that the base of evidence used in policy-making could be poisoned to the point of uselessness.</div><br/><div id="41478301" class="c"><input type="checkbox" id="c-41478301" checked=""/><div class="controls bullet"><span class="by">OutOfHere</span><span>|</span><a href="#41477644">root</a><span>|</span><a href="#41478131">parent</a><span>|</span><a href="#41477727">next</a><span>|</span><label class="collapse" for="c-41478301">[-]</label><label class="expand" for="c-41478301">[1 more]</label></div><br/><div class="children"><div class="content">Firstly, &quot;fabricated content&quot; is a meaningless phrase. For the sake of argument, I use Github Copilot for &quot;fabricating&quot; every line of code. Does this make my code polluted? No, because I review every line of code, editing what&#x27;s necessary, and more. It&#x27;s the same way with scholarship. It doesn&#x27;t say anything in itself.<p>Perhaps &quot;unreviewed scholarship&quot; would be a more concerning claim, but I don&#x27;t yet see the evidence for it being a major concern.</div><br/></div></div></div></div></div></div><div id="41477661" class="c"><input type="checkbox" id="c-41477661" checked=""/><div class="controls bullet"><span class="by">gerdesj</span><span>|</span><a href="#41477644">prev</a><span>|</span><a href="#41477636">next</a><span>|</span><label class="collapse" for="c-41477661">[-]</label><label class="expand" for="c-41477661">[5 more]</label></div><br/><div class="children"><div class="content">Colour me surprised.  An IT related search will generally end up with loads of returns that lead to AI generated wankery.<p>For example, suppose you wish to back up switch configs or dump a file or whatever and tftp is so easy and simple to setup.  You&#x27;ll tear it down later or firewall it or whatever.<p>So a quick search &quot;linux tftp serevr&quot; gets you to say: <a href="https:&#x2F;&#x2F;thelinuxcode.com&#x2F;install_tftp_server_ubuntu&#x2F;" rel="nofollow">https:&#x2F;&#x2F;thelinuxcode.com&#x2F;install_tftp_server_ubuntu&#x2F;</a><p>All good until you try to use the --create flag which should allow you to upload to the server.  That flag is not valid for tftp-hpa, it is valid on tftpd (another tftp daemon)<p>That&#x27;s a hallucination.  Hallucinations are fucking annoying and increasingly prevalent.  In Windows land the humans hallucinate - C:\ SFC &#x2F;SCANNOW does not fix anything except for something really madly self imposed.</div><br/><div id="41478221" class="c"><input type="checkbox" id="c-41478221" checked=""/><div class="controls bullet"><span class="by">mkl</span><span>|</span><a href="#41477661">parent</a><span>|</span><a href="#41478126">next</a><span>|</span><label class="collapse" for="c-41478221">[-]</label><label class="expand" for="c-41478221">[1 more]</label></div><br/><div class="children"><div class="content">It says to put the --create option in &#x2F;etc&#x2F;default&#x2F;tftpd-hpa.  tftpd-hpa does support --create (at least on Ubuntu).  The client program tftp-hpa (no d) doesn&#x27;t support --create, but that&#x27;s not what the instructions are talking about.</div><br/></div></div><div id="41478126" class="c"><input type="checkbox" id="c-41478126" checked=""/><div class="controls bullet"><span class="by">viraptor</span><span>|</span><a href="#41477661">parent</a><span>|</span><a href="#41478221">prev</a><span>|</span><a href="#41477780">next</a><span>|</span><label class="collapse" for="c-41478126">[-]</label><label class="expand" for="c-41478126">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s not an AI hallucination. The content comes from Ubuntu community wiki <a href="https:&#x2F;&#x2F;help.ubuntu.com&#x2F;community&#x2F;TFTP" rel="nofollow">https:&#x2F;&#x2F;help.ubuntu.com&#x2F;community&#x2F;TFTP</a> - it was written in 2015. And at least in Debian, tftpd-hpa man page lists --create as valid <a href="https:&#x2F;&#x2F;manpages.debian.org&#x2F;testing&#x2F;tftpd-hpa&#x2F;tftpd.8.en.html" rel="nofollow">https:&#x2F;&#x2F;manpages.debian.org&#x2F;testing&#x2F;tftpd-hpa&#x2F;tftpd.8.en.htm...</a><p>Seems valid upstream too <a href="https:&#x2F;&#x2F;github.com&#x2F;Distrotech&#x2F;tftp-hpa&#x2F;blob&#x2F;5e95f248e8435eb3413eb2a2d377d17e37b712ff&#x2F;tftpd&#x2F;tftpd.c#L332">https:&#x2F;&#x2F;github.com&#x2F;Distrotech&#x2F;tftp-hpa&#x2F;blob&#x2F;5e95f248e8435eb3...</a></div><br/></div></div><div id="41477780" class="c"><input type="checkbox" id="c-41477780" checked=""/><div class="controls bullet"><span class="by">bongodongobob</span><span>|</span><a href="#41477661">parent</a><span>|</span><a href="#41478126">prev</a><span>|</span><a href="#41477636">next</a><span>|</span><label class="collapse" for="c-41477780">[-]</label><label class="expand" for="c-41477780">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s funny you mention this because yesterday I had it write me a shell script to set up a TFTP server from scratch. I had it walk me through the process first, then said &quot;ok now make that into a script.&quot; And it did and it works.</div><br/></div></div></div></div><div id="41477636" class="c"><input type="checkbox" id="c-41477636" checked=""/><div class="controls bullet"><span class="by">jeremynixon</span><span>|</span><a href="#41477661">prev</a><span>|</span><a href="#41477787">next</a><span>|</span><label class="collapse" for="c-41477636">[-]</label><label class="expand" for="c-41477636">[2 more]</label></div><br/><div class="children"><div class="content">There is article shows no evidence of fabrication, fraud or misinformation, while making accusations of all of them. All it shows is that ChatGPT was used, which is wildly escalated into &quot;evidence manipulation&quot; (ironically without evidence).<p>Much more work is needed to show that this means anything.</div><br/><div id="41478086" class="c"><input type="checkbox" id="c-41478086" checked=""/><div class="controls bullet"><span class="by">viraptor</span><span>|</span><a href="#41477636">parent</a><span>|</span><a href="#41477787">next</a><span>|</span><label class="collapse" for="c-41478086">[-]</label><label class="expand" for="c-41478086">[1 more]</label></div><br/><div class="children"><div class="content">If the result was not read even to check for obvious boilerplate GPT markers, then we can&#x27;t expect anything else in them was. That means anything else, numbers, interpretation, conclusion was potentially never checked.<p>The authors use fraud in a specific sense here: &quot;using ChatGPT fraudulently or undeclared&quot; where they proved that the produced text was included without proper review. They also never accused those papers of misinformation, so they don&#x27;t need to show evidence of that.</div><br/></div></div></div></div><div id="41477787" class="c"><input type="checkbox" id="c-41477787" checked=""/><div class="controls bullet"><span class="by">Barrin92</span><span>|</span><a href="#41477636">prev</a><span>|</span><a href="#41477897">next</a><span>|</span><label class="collapse" for="c-41477787">[-]</label><label class="expand" for="c-41477787">[3 more]</label></div><br/><div class="children"><div class="content">Honestly what we need to do is establish much stronger credentialing schemes. The &quot;only a good guy with an AI can stop a bad guy with an AI&quot; approach of trying to filter out bad content is just a hopeless arms race and unproductive.<p>In a sense we need to go back two steps and websites need to be much stronger curators of knowledge again, and we need some reliable ways to sign and attribute real authorship to publications. So that when someone publishes a fake paper there is always a human being who signed it and can be held accountable. There&#x27;s a practically unlimited number of automated systems, but only a limited number of people trying to benefit from it.<p>In the same way https went from being rare to being the norm because the assumption that things are default-authentic doesn&#x27;t hold, the same just needs to happen to publishing. If you have a functioning reputation system and you can put on a price on fake information 99% of it is dis-incentivized.</div><br/><div id="41477921" class="c"><input type="checkbox" id="c-41477921" checked=""/><div class="controls bullet"><span class="by">tbrownaw</span><span>|</span><a href="#41477787">parent</a><span>|</span><a href="#41477897">next</a><span>|</span><label class="collapse" for="c-41477921">[-]</label><label class="expand" for="c-41477921">[2 more]</label></div><br/><div class="children"><div class="content">Is this not already a thing? You can look up purported papers by DOI, and whatever journal it came from supposedly had it reviewed and should know who sent it to them.<p>(And if that doesn&#x27;t work, how is what you&#x27;re suggesting meaningfully different?)</div><br/><div id="41478272" class="c"><input type="checkbox" id="c-41478272" checked=""/><div class="controls bullet"><span class="by">Barrin92</span><span>|</span><a href="#41477787">root</a><span>|</span><a href="#41477921">parent</a><span>|</span><a href="#41477897">next</a><span>|</span><label class="collapse" for="c-41478272">[-]</label><label class="expand" for="c-41478272">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not at all a thing. Here&#x27;s a recent study looking at citation fraud on Google Scholar including  professional citation boosting services including with fake identities. It&#x27;s widespread practice. <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2402.04607" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2402.04607</a><p>Having a machine verifiable, cryptographic identity system that renders these kinds of things transparent, basically the equivalent of a ledger but instead of using it for get-rich schemes using it for identity would probably make verification enforceable.</div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>