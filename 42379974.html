<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1733907673899" as="style"/><link rel="stylesheet" href="styles.css?v=1733907673899"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://supabase.com/blog/durable-workflows-in-postgres-dbos">Running Durable Workflows in Postgres Using DBOS</a> <span class="domain">(<a href="https://supabase.com">supabase.com</a>)</span></div><div class="subtext"><span>kiwicopple</span> | <span>46 comments</span></div><br/><div><div id="42385949" class="c"><input type="checkbox" id="c-42385949" checked=""/><div class="controls bullet"><span class="by">chucke</span><span>|</span><a href="#42385458">next</a><span>|</span><label class="collapse" for="c-42385949">[-]</label><label class="expand" for="c-42385949">[1 more]</label></div><br/><div class="children"><div class="content">&gt; DBOS has a special @DBOS.Transaction decorator. This runs the entire step inside a Postgres transaction. This guarantees exactly-once execution for databases transactional steps.<p>I stopped here. I know, authors really want to chase the exactly-once dragon, but this won&#x27;t scale. If the step takes a long time, it&#x27;ll keep the transaction open with it for that time. The master replica has to bookkeeping that. That state has to be replicated. That will also affect MVVC further on. As your scale grows, you&#x27;ll see disk usage growing and eventually swapping, replica lags, AND vacuum halting for surges. I hope your uncalled engineers have a steady supply of coffee.</div><br/></div></div><div id="42385458" class="c"><input type="checkbox" id="c-42385458" checked=""/><div class="controls bullet"><span class="by">beders</span><span>|</span><a href="#42385949">prev</a><span>|</span><a href="#42382426">next</a><span>|</span><label class="collapse" for="c-42385458">[-]</label><label class="expand" for="c-42385458">[2 more]</label></div><br/><div class="children"><div class="content">It is important to note that employing any workflow engine needs careful examination of the benefits vs. drawbacks.<p>You will need full and complete control over workflow orchestration, restarts, deletes, logging, versioning etc.<p>Your steps will get stuck, they will error out unexpectedly and you will need complete transparency and operational tools to deal with that.<p>In many cases you will be better off doing the book-keeping yourself. A process should be defined in terms of your domain data. Typically you have statuses (not the best choice, but I digress) that change over time, so you can report on the whole lifecycle of your shopping cart.<p>Now, and this is crucial, how you implement state changes - any state change - should exactly be the same for a &quot;workflow&quot; than for a non-workflow! It needs to be.
A shipment is either not ready yet or done - this information should not be in a &quot;workflow state&quot;.<p>Let&#x27;s say you shut down your system and start it back up: do you have a mechanism in place that can &quot;continue where it 
left off&quot;? If so, you likely don&#x27;t need a workflow engine.<p>In our case, on startup, we need to query the system for carts that are waiting for shipments and that are not being dealt with yet.
Then fan out tasks for those.<p>That is robust in the face of changed data. If you employ a workflow engine, changed data always needs to two consider two worlds: your own domain data <i>and</i> any book-keeping that is potentially done in any workflow.</div><br/><div id="42386011" class="c"><input type="checkbox" id="c-42386011" checked=""/><div class="controls bullet"><span class="by">nialse</span><span>|</span><a href="#42385458">parent</a><span>|</span><a href="#42382426">next</a><span>|</span><label class="collapse" for="c-42386011">[-]</label><label class="expand" for="c-42386011">[1 more]</label></div><br/><div class="children"><div class="content">Grounding to reality is key. There’s often a tendency to trust the map over the terrain. This architecture seems to promote relying on the database always have a perfect representation of state. But consider a scenario where a company restores a 12-hour-old backup, losing hours of state. States that can’t be externally revalidated in such cases are a serious concern.</div><br/></div></div></div></div><div id="42382426" class="c"><input type="checkbox" id="c-42382426" checked=""/><div class="controls bullet"><span class="by">abelanger</span><span>|</span><a href="#42385458">prev</a><span>|</span><a href="#42385026">next</a><span>|</span><label class="collapse" for="c-42382426">[-]</label><label class="expand" for="c-42382426">[7 more]</label></div><br/><div class="children"><div class="content">Disclaimer: I&#x27;m a co-founder of Hatchet (<a href="https:&#x2F;&#x2F;github.com&#x2F;hatchet-dev&#x2F;hatchet">https:&#x2F;&#x2F;github.com&#x2F;hatchet-dev&#x2F;hatchet</a>), which is a Postgres-backed task queue that supports durable execution.<p>&gt; Because a step transition is just a Postgres write (~1ms) versus an async dispatch from an external orchestrator (~100ms), it means DBOS is 25x faster than AWS Step Functions<p>Durable execution engines deployed as an external orchestrator will always been slower than direct DB writes, but the 1ms delay versus ~100ms doesn&#x27;t seem inherent to the orchestrator being external. In the case of Hatchet, pushing work takes ~15ms and invoking the work takes ~1ms if deployed in the same VPC, and 90% of that execution time is on the database. In the best-case, the external orchestrator should take 2x as long to write a step transition (round-trip network call to the orchestrator + database write), so an ideal external orchestrator would be ~2ms of latency here.<p>There are also some tradeoffs to a library-only mode that aren&#x27;t discussed. How would work that requires global coordination between workers behave in this model? Let&#x27;s say, for example, a global rate limit -- you&#x27;d ideally want to avoid contention on rate limit rows, assuming they&#x27;re stored in Postgres, but each worker attempting to acquire a rate limit simultaneously would slow down start time significantly (and place additional load on the DB). Whereas with a single external orchestrator (or leader election), you can significantly increase throughput by acquiring rate limits as part of a push-based assignment process.<p>The same problem of coordination arises if many workers are competing for the same work --  for example if a machine crashes while doing work, as described in the article. I&#x27;m assuming there&#x27;s some kind of polling happening which uses FOR UPDATE SKIP LOCKED, which concerns me as you start to scale up the number of workers.</div><br/><div id="42386009" class="c"><input type="checkbox" id="c-42386009" checked=""/><div class="controls bullet"><span class="by">diptanu</span><span>|</span><a href="#42382426">parent</a><span>|</span><a href="#42382837">next</a><span>|</span><label class="collapse" for="c-42386009">[-]</label><label class="expand" for="c-42386009">[1 more]</label></div><br/><div class="children"><div class="content">Great points. Besides performance, centralized coordination and distributed dataplane is better for operability of schedulers as well. Some examples - Being able to roll out new features in the scheduler, tracing scheduling behavior and decisions, deploying configuration changes.<p>Even with a centralized scheduler it should be possible to create a DevEx that makes use of decorators to author workflows easily.<p>We are doing that with Indexify(<a href="https:&#x2F;&#x2F;github.com&#x2F;tensorlakeai&#x2F;indexify">https:&#x2F;&#x2F;github.com&#x2F;tensorlakeai&#x2F;indexify</a>) for authoring data intensive workflows to process unstructured data(documents, videos, etc) - it’s like Spark but uses Python instead of Scala&#x2F;SQL&#x2F;UDFs. 
Indexify’s scheduler is centralized and it uses RocksDB under the hood for persistence, and long term we are moving to a hybrid storage system - S3 for less frequently updated data, and SSD for read cache and frequently updated data(on going tasks).<p>The scheduler’s latency for scheduling new tasks is consistently under &lt; 800 microseconds on SSDs.<p>This is how schedulers have been designed traditionally that have a proven track record of working in production - Borg, Hashicorp Nomad, etc. There are many ways a centralized scheduler can scale out beyond a single machine - parallel scheduling across different by sharding jobs, node pools, and then linearizing and deduplicating conflicts during writes is one such approach.<p>Love DBOs and Hatchet! cheering for you @jedberg and @abelanger :-)<p>Disclaimer - I am the founder of Tensorlake, and worked on Nomad and Apache Mesos in the past.</div><br/></div></div><div id="42382837" class="c"><input type="checkbox" id="c-42382837" checked=""/><div class="controls bullet"><span class="by">KraftyOne</span><span>|</span><a href="#42382426">parent</a><span>|</span><a href="#42386009">prev</a><span>|</span><a href="#42385026">next</a><span>|</span><label class="collapse" for="c-42382837">[-]</label><label class="expand" for="c-42382837">[5 more]</label></div><br/><div class="children"><div class="content">You have a great point that scaling a library model requires careful design, but we think that&#x27;s worth it to provide a superior developer experience.<p>For example, the DBOS library provides an API to instruct a worker to recover specific tasks. In our hosted platform (DBOS Cloud), when a worker crashes, a central server uses this API to tell the workers what to recover. We like this design because it provides the best of both worlds--the coordination decision is centralized, so it&#x27;s performant&#x2F;scalable, but the actual recovery and workflow execution is done in-process, so DBOS doesn&#x27;t turn your program into a distributed system the way Step Functions&#x2F;Temporal do (I haven&#x27;t used Hatchet).</div><br/><div id="42382998" class="c"><input type="checkbox" id="c-42382998" checked=""/><div class="controls bullet"><span class="by">abelanger</span><span>|</span><a href="#42382426">root</a><span>|</span><a href="#42382837">parent</a><span>|</span><a href="#42385026">next</a><span>|</span><label class="collapse" for="c-42382998">[-]</label><label class="expand" for="c-42382998">[4 more]</label></div><br/><div class="children"><div class="content">Definitely agree that the dev experience is better with a library, particularly for lightweight and low-volume tasks (Hatchet is also moving in the same direction, we&#x27;ll be releasing library-only mode this month). And I really like the transactional safety built into DBOS!<p>My concern is as you start to see higher volume, more workers, or load patterns that don&#x27;t correspond to your primary API. At that point, a dedicated database and service to orchestrate tasks starts to become more necessary.</div><br/><div id="42383234" class="c"><input type="checkbox" id="c-42383234" checked=""/><div class="controls bullet"><span class="by">jedberg</span><span>|</span><a href="#42382426">root</a><span>|</span><a href="#42382998">parent</a><span>|</span><a href="#42385026">next</a><span>|</span><label class="collapse" for="c-42383234">[-]</label><label class="expand" for="c-42383234">[3 more]</label></div><br/><div class="children"><div class="content">I disagree.  Once you get to the scale that breaks a library based system like DBOS, you need to move away from a central coordinator.  At that point your software has to adjust and you have to build your application to work without those types of centralized systems.<p>Centralized systems don&#x27;t scale to the biggest problems no matter how clever you are.<p>And usually the best way to scale is to <i>decentralize</i>.  Make idempotent updates that can be done more locally and use eventual consistency to keep things aligned.</div><br/><div id="42383620" class="c"><input type="checkbox" id="c-42383620" checked=""/><div class="controls bullet"><span class="by">abelanger</span><span>|</span><a href="#42382426">root</a><span>|</span><a href="#42383234">parent</a><span>|</span><a href="#42385026">next</a><span>|</span><label class="collapse" for="c-42383620">[-]</label><label class="expand" for="c-42383620">[2 more]</label></div><br/><div class="children"><div class="content">You can get around some of this coordination by doing more work locally, in-process -- but you&#x27;re risking the availability of your primary API. The work that you&#x27;re doing as a background job or workflow may:<p>1. Be unbounded -- 1 API call may correspond to thousands or hundreds of thousands of reads or writes<p>2. Be resource intensive, on either the database side by eating up connections which are needed by your API, or by blocking your event loop&#x2F;process, particularly in Python and Typescript<p>&gt; Once you get to the scale that breaks a library based system like DBOS, you need to move away from a central coordinator<p>There are different levels of coordination here. At some point, workers are always going to have to coordinate &quot;who is working on what&quot; -- whether that&#x27;s by placing locks and using status updates in the database, using a traditional queue, or using a central server like you described with DBOS Cloud. The same goes for a dedicated orchestrator -- those can also partition by &quot;who is working on which workers.&quot; In other words, a dedicated service can also be decentralized, these don&#x27;t seem mutually exclusive.<p>To make this more concrete -- let&#x27;s say, for example, you have hundreds of workers on a library based system like DBOS which all correspond to individual connections and transactions to read&#x2F;write data. Whereas in a system like Temporal or Hatchet, you might have 10s of nodes to support 1000s of workers, with the ability to bulk enqueue and dequeue more work, which will increase throughput and reduce DB load rather significantly. You&#x27;d lose (most of) the benefits of bulk writes in a library based system.</div><br/><div id="42383784" class="c"><input type="checkbox" id="c-42383784" checked=""/><div class="controls bullet"><span class="by">KraftyOne</span><span>|</span><a href="#42382426">root</a><span>|</span><a href="#42383620">parent</a><span>|</span><a href="#42385026">next</a><span>|</span><label class="collapse" for="c-42383784">[-]</label><label class="expand" for="c-42383784">[1 more]</label></div><br/><div class="children"><div class="content">To be clear, a DBOS worker isn&#x27;t just one connection, but an entire application server that can handle many requests concurrently and batch&#x2F;bulk write database operations. Past that, I don&#x27;t really think we&#x27;re disagreeing: there are clever optimizations (batching, offloading coordination where possible) you can do in both a library-based and workflow-server-based system to scale better, but at truly massive scale you&#x27;ll bottleneck in Postgres.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="42385026" class="c"><input type="checkbox" id="c-42385026" checked=""/><div class="controls bullet"><span class="by">jameson</span><span>|</span><a href="#42382426">prev</a><span>|</span><a href="#42385482">next</a><span>|</span><label class="collapse" for="c-42385026">[-]</label><label class="expand" for="c-42385026">[2 more]</label></div><br/><div class="children"><div class="content">Could someone clarify on how it can achieve exactly-once processing with idempotency key?<p>Using the example they provided:<p>1. Validate payment<p>2. Check inventory<p>3. Ship order<p>4. Notify customer<p>I&#x27;m curious about case when one of the operation times out. The workflow engine needs to then either time out or it may even crash before receving a response<p>In this scenario, the only option for the workflow is to retry with the same idempotency key it used, but this may <i>re-execute the failed operation which may have been succeeded in the prior run</i> because workflow did not receive the response. The succeeded operations would skip because workflow has run completion record for same idempotency key. Is that correct?</div><br/><div id="42385371" class="c"><input type="checkbox" id="c-42385371" checked=""/><div class="controls bullet"><span class="by">thelastbender12</span><span>|</span><a href="#42385026">parent</a><span>|</span><a href="#42385482">next</a><span>|</span><label class="collapse" for="c-42385371">[-]</label><label class="expand" for="c-42385371">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The succeeded operations would skip because workflow has run completion record for same idempotency key. Is that correct?<p>This sounds about right. But you need to make sure the service being called in that step is indeed idempotent, and will return the same response which it earlier couldn&#x27;t in time.</div><br/></div></div></div></div><div id="42385482" class="c"><input type="checkbox" id="c-42385482" checked=""/><div class="controls bullet"><span class="by">gregwebs</span><span>|</span><a href="#42385026">prev</a><span>|</span><a href="#42382048">next</a><span>|</span><label class="collapse" for="c-42385482">[-]</label><label class="expand" for="c-42385482">[1 more]</label></div><br/><div class="children"><div class="content">This appears to be an open source MIT library that anyone can just use. The docs say it can be run locally against PG. but then they say to use DBOS cloud in production without mentioning that it can also be ran in production against any PG database. Just checking that I am not missing something. I would like to support this project while using it but adding a vendor is not always possible (for example I don’t see SOC2 mentioned).</div><br/></div></div><div id="42382048" class="c"><input type="checkbox" id="c-42382048" checked=""/><div class="controls bullet"><span class="by">antics</span><span>|</span><a href="#42385482">prev</a><span>|</span><a href="#42381420">next</a><span>|</span><label class="collapse" for="c-42382048">[-]</label><label class="expand" for="c-42382048">[4 more]</label></div><br/><div class="children"><div class="content">&gt; # Exactly-once execution<p>&gt; DBOS has a special @DBOS.Transaction decorator. This runs the entire step inside a Postgres transaction. This guarantees exactly-once execution for databases transactional steps.<p>Totally awesome, great work, just a small note... IME a lot of (most?) pg deployments have synchronous replication turned off because it is very tricky to get it to perform well[1]. If you have it turned off, pg could journal the step, formally acknowledge it, and then (as I understand DBOS) totally lose that journal when the primary fails, causing you to re-run the step.<p>When I was on call for pg last, failover with some data loss happened to me twice. So it does happen. I think this is worth noting because if you plan for this to be a hard requirement, (unless I&#x27;m mistaken) you need to set up sync replication or you need to plan for this to possibly fail.<p>Lastly, note that the pg docs[1] have this to say about sync replication:<p>&gt; Synchronous replication usually requires carefully planned and placed standby servers to ensure applications perform acceptably. Waiting doesn&#x27;t utilize system resources, but transaction locks continue to be held until the transfer is confirmed. As a result, incautious use of synchronous replication will reduce performance for database applications because of increased response times and higher contention.<p>I see the DBOS author around here somewhere so if the state of the art for DBOS has changed please do let me know and I&#x27;ll correct the comment.<p>[1] <a href="https:&#x2F;&#x2F;www.postgresql.org&#x2F;docs&#x2F;current&#x2F;warm-standby.html#SYNCHRONOUS-REPLICATION-PERFORMANCE" rel="nofollow">https:&#x2F;&#x2F;www.postgresql.org&#x2F;docs&#x2F;current&#x2F;warm-standby.html#SY...</a></div><br/><div id="42382365" class="c"><input type="checkbox" id="c-42382365" checked=""/><div class="controls bullet"><span class="by">KraftyOne</span><span>|</span><a href="#42382048">parent</a><span>|</span><a href="#42381420">next</a><span>|</span><label class="collapse" for="c-42382365">[-]</label><label class="expand" for="c-42382365">[3 more]</label></div><br/><div class="children"><div class="content">Yeah, that&#x27;s totally fair--DBOS is totally built on Postgres, so it can&#x27;t provide stronger durability guarantees than your Postgres does. If Postgres  loses data, then DBOS can lose data too. There&#x27;s no way around that if you&#x27;re using Postgres for data storage, no matter how you architect the system.</div><br/><div id="42383744" class="c"><input type="checkbox" id="c-42383744" checked=""/><div class="controls bullet"><span class="by">halfcat</span><span>|</span><a href="#42382048">root</a><span>|</span><a href="#42382365">parent</a><span>|</span><a href="#42381420">next</a><span>|</span><label class="collapse" for="c-42383744">[-]</label><label class="expand" for="c-42383744">[2 more]</label></div><br/><div class="children"><div class="content">That’s my intuition as well, but it does raise a question in my mind.<p>We have storage solutions that are far more robust than the individual hard drives that they’re built upon.<p>One example that comes to mind is Microsoft Exchange databases. Traditionally these were run on servers that had redundant storage (RAID), and at some point Microsoft said you could run it without RAID, and let their Database Availability Groups handle the redundancy.<p>With Postgres that would look like, say, during an HTTP request, you write the change to multiple Postgres instances, before acknowledging the update to the requesting client.</div><br/><div id="42383841" class="c"><input type="checkbox" id="c-42383841" checked=""/><div class="controls bullet"><span class="by">KraftyOne</span><span>|</span><a href="#42382048">root</a><span>|</span><a href="#42383744">parent</a><span>|</span><a href="#42381420">next</a><span>|</span><label class="collapse" for="c-42383841">[-]</label><label class="expand" for="c-42383841">[1 more]</label></div><br/><div class="children"><div class="content">Yes exactly!  That&#x27;s how Postgres synchronous replication works. If you turn on synchronous replication, then you won&#x27;t lose data unless all your replicas are wiped out. The question the original poster was asking was what guarantees can be provided if you DON&#x27;T use synchronous replication--and the answer is that there&#x27;s no such thing as a free lunch.</div><br/></div></div></div></div></div></div></div></div><div id="42381420" class="c"><input type="checkbox" id="c-42381420" checked=""/><div class="controls bullet"><span class="by">adamgordonbell</span><span>|</span><a href="#42382048">prev</a><span>|</span><a href="#42382035">next</a><span>|</span><label class="collapse" for="c-42381420">[-]</label><label class="expand" for="c-42381420">[1 more]</label></div><br/><div class="children"><div class="content">I built a small side thing using DBOS ( using python SDK) and the ergonomics were pretty nice.<p>Then I found out Qian Li and Peter Kraft from that team are sharing breakdowns of interesting database research papers on twitter and I&#x27;ve been following them for that.<p><a href="https:&#x2F;&#x2F;x.com&#x2F;petereliaskraft&#x2F;status&#x2F;1862937787420295672" rel="nofollow">https:&#x2F;&#x2F;x.com&#x2F;petereliaskraft&#x2F;status&#x2F;1862937787420295672</a></div><br/></div></div><div id="42382035" class="c"><input type="checkbox" id="c-42382035" checked=""/><div class="controls bullet"><span class="by">hotpocket777</span><span>|</span><a href="#42381420">prev</a><span>|</span><a href="#42380900">next</a><span>|</span><label class="collapse" for="c-42382035">[-]</label><label class="expand" for="c-42382035">[2 more]</label></div><br/><div class="children"><div class="content">Does DBOS offer a way to get messages in or data out of running workflows? (Similar to signals&#x2F;queries in Temporal) Interested in long-running workflows, and this particular area seemed to be lacking last time I looked into it.<p>I don’t want to <i>just</i> sleep; I want a workflow to be able to respond to an event.</div><br/><div id="42382183" class="c"><input type="checkbox" id="c-42382183" checked=""/><div class="controls bullet"><span class="by">KraftyOne</span><span>|</span><a href="#42382035">parent</a><span>|</span><a href="#42380900">next</a><span>|</span><label class="collapse" for="c-42382183">[-]</label><label class="expand" for="c-42382183">[1 more]</label></div><br/><div class="children"><div class="content">Yes, absolutely, that&#x27;s an extremely important use case! In DBOS you can send messages to workflows and workflows can publish events that others can read. It&#x27;s all backed by Postgres (LISTEN&#x2F;NOTIFY under the hood).<p>Documentation: <a href="https:&#x2F;&#x2F;docs.dbos.dev&#x2F;python&#x2F;tutorials&#x2F;workflow-tutorial#workflow-events" rel="nofollow">https:&#x2F;&#x2F;docs.dbos.dev&#x2F;python&#x2F;tutorials&#x2F;workflow-tutorial#wor...</a><p>Here&#x27;s a demo e-commerce application that uses messages and events to build an interactive long-running checkout workflow: <a href="https:&#x2F;&#x2F;docs.dbos.dev&#x2F;python&#x2F;examples&#x2F;widget-store" rel="nofollow">https:&#x2F;&#x2F;docs.dbos.dev&#x2F;python&#x2F;examples&#x2F;widget-store</a></div><br/></div></div></div></div><div id="42380900" class="c"><input type="checkbox" id="c-42380900" checked=""/><div class="controls bullet"><span class="by">yandie</span><span>|</span><a href="#42382035">prev</a><span>|</span><a href="#42380883">next</a><span>|</span><label class="collapse" for="c-42380900">[-]</label><label class="expand" for="c-42380900">[4 more]</label></div><br/><div class="children"><div class="content">Temporal can use postgres as a backend. What makes this product different?</div><br/><div id="42380985" class="c"><input type="checkbox" id="c-42380985" checked=""/><div class="controls bullet"><span class="by">KraftyOne</span><span>|</span><a href="#42380900">parent</a><span>|</span><a href="#42380979">next</a><span>|</span><label class="collapse" for="c-42380985">[-]</label><label class="expand" for="c-42380985">[2 more]</label></div><br/><div class="children"><div class="content">DBOS Co-founder here. Great question!  The big difference is that DBOS runs as a library inside your program, whereas the Temporal architecture is an external workflow server managing tasks on distributed workers. The advantages of DBOS are:<p>1. Simpler architecturally. Just a normal Python process versus a workflow server coordinating multiple workers.<p>2. Easier dev&#x2F;debugging. A Temporal program is essentially distributed microservices, with control flow split between the workflow server and workers. That complicates any testing&#x2F;debugging because you have to work through multiple components. Whereas DBOS is just your process.<p>3. Performance. A state transition in DBOS requires only a database write (~1 ms) whereas in Temporal it requires an async dispatch from the workflow server (tens-hundreds of ms).</div><br/><div id="42381697" class="c"><input type="checkbox" id="c-42381697" checked=""/><div class="controls bullet"><span class="by">abtinf</span><span>|</span><a href="#42380900">root</a><span>|</span><a href="#42380985">parent</a><span>|</span><a href="#42380979">next</a><span>|</span><label class="collapse" for="c-42381697">[-]</label><label class="expand" for="c-42381697">[1 more]</label></div><br/><div class="children"><div class="content">Note that it is possible to embed temporal server into a program. I wrote a simple demo that embeds client&#x2F;worker&#x2F;server all into one Go app. It should be straightforward to modify this to support clustering.<p><a href="https:&#x2F;&#x2F;github.com&#x2F;abtinf&#x2F;temporal-a-day&#x2F;blob&#x2F;main&#x2F;001-all-in-one-hello&#x2F;main.go">https:&#x2F;&#x2F;github.com&#x2F;abtinf&#x2F;temporal-a-day&#x2F;blob&#x2F;main&#x2F;001-all-i...</a></div><br/></div></div></div></div><div id="42380979" class="c"><input type="checkbox" id="c-42380979" checked=""/><div class="controls bullet"><span class="by">dangoodmanUT</span><span>|</span><a href="#42380900">parent</a><span>|</span><a href="#42380985">prev</a><span>|</span><a href="#42380883">next</a><span>|</span><label class="collapse" for="c-42380979">[-]</label><label class="expand" for="c-42380979">[1 more]</label></div><br/><div class="children"><div class="content">Seems like you didn&#x27;t read any of it</div><br/></div></div></div></div><div id="42380883" class="c"><input type="checkbox" id="c-42380883" checked=""/><div class="controls bullet"><span class="by">dangoodmanUT</span><span>|</span><a href="#42380900">prev</a><span>|</span><a href="#42384189">next</a><span>|</span><label class="collapse" for="c-42380883">[-]</label><label class="expand" for="c-42380883">[9 more]</label></div><br/><div class="children"><div class="content">Maybe I&#x27;m not seeing it, but why do none of these &quot;postgres durable packages&quot; ever integrate with existing transactions? That&#x27;s the biggest flaw of temporal, and seems so obvious that they can hook into transactions to ensure that starting a workflow is transactionally secure with other operations, and you don&#x27;t have to manage idempotency yourself (or worry about handling &quot;already started&quot; errors and holding up DB connections bc you launched in transaction)</div><br/><div id="42380922" class="c"><input type="checkbox" id="c-42380922" checked=""/><div class="controls bullet"><span class="by">KraftyOne</span><span>|</span><a href="#42380883">parent</a><span>|</span><a href="#42384189">next</a><span>|</span><label class="collapse" for="c-42380922">[-]</label><label class="expand" for="c-42380922">[8 more]</label></div><br/><div class="children"><div class="content">(DBOS co-founder here) DBOS does exactly this! From the post:<p>DBOS has a special @DBOS.Transaction decorator. This runs the entire step inside a Postgres transaction. This guarantees exactly-once execution for databases transactional steps.</div><br/><div id="42380963" class="c"><input type="checkbox" id="c-42380963" checked=""/><div class="controls bullet"><span class="by">dangoodmanUT</span><span>|</span><a href="#42380883">root</a><span>|</span><a href="#42380922">parent</a><span>|</span><a href="#42384189">next</a><span>|</span><label class="collapse" for="c-42380963">[-]</label><label class="expand" for="c-42380963">[7 more]</label></div><br/><div class="children"><div class="content">Sorry, i mean with external transactions to the workflow steps. Like I can select, insert, and launch a workflow in a HTTP handler</div><br/><div id="42381037" class="c"><input type="checkbox" id="c-42381037" checked=""/><div class="controls bullet"><span class="by">KraftyOne</span><span>|</span><a href="#42380883">root</a><span>|</span><a href="#42380963">parent</a><span>|</span><a href="#42384189">next</a><span>|</span><label class="collapse" for="c-42381037">[-]</label><label class="expand" for="c-42381037">[6 more]</label></div><br/><div class="children"><div class="content">Yeah, you can launch workflows directly from an HTTP handler. So here&#x27;s some code that idempotently launches a background task from a FastAPI endpoint:<p><pre><code>    @app.get(&quot;&#x2F;background&#x2F;{task_id}&#x2F;{n}&quot;)
    def launch_background_task(task_id: str, n: int) -&gt; None:
      with SetWorkflowID(task_id): # Set an idempotency key
        DBOS.start_workflow(background_task, n) # Start the workflow in the background
</code></pre>
Does that answer your question?</div><br/><div id="42384418" class="c"><input type="checkbox" id="c-42384418" checked=""/><div class="controls bullet"><span class="by">andyferris</span><span>|</span><a href="#42380883">root</a><span>|</span><a href="#42381037">parent</a><span>|</span><a href="#42384189">next</a><span>|</span><label class="collapse" for="c-42384418">[-]</label><label class="expand" for="c-42384418">[5 more]</label></div><br/><div class="children"><div class="content">Not OP, but I don&#x27;t think that&#x27;s it.<p>Suppose you had an existing postgres-backed CRUD app with existing postgres transactions, and you want to add a feature to launch a workflow _atomically_ within an existing transaction, can you do that? (I.e. can the DBOS transaction be a nested transaction within a transaction defined outside the DBOS library?)</div><br/><div id="42384507" class="c"><input type="checkbox" id="c-42384507" checked=""/><div class="controls bullet"><span class="by">KraftyOne</span><span>|</span><a href="#42380883">root</a><span>|</span><a href="#42384418">parent</a><span>|</span><a href="#42384896">next</a><span>|</span><label class="collapse" for="c-42384507">[-]</label><label class="expand" for="c-42384507">[3 more]</label></div><br/><div class="children"><div class="content">Got it! I&#x27;m not sure if that was what OP was asking, but it&#x27;s a really interesting question.<p>We don&#x27;t currently support launching a workflow atomically from within an existing database transaction. I&#x27;d love to learn about the use case for that!<p>We do support calling a database transaction as a workflow step, which executes entirely atomically and exactly-once: <a href="https:&#x2F;&#x2F;docs.dbos.dev&#x2F;python&#x2F;tutorials&#x2F;transaction-tutorial" rel="nofollow">https:&#x2F;&#x2F;docs.dbos.dev&#x2F;python&#x2F;tutorials&#x2F;transaction-tutorial</a></div><br/><div id="42384834" class="c"><input type="checkbox" id="c-42384834" checked=""/><div class="controls bullet"><span class="by">andyferris</span><span>|</span><a href="#42380883">root</a><span>|</span><a href="#42384507">parent</a><span>|</span><a href="#42384896">next</a><span>|</span><label class="collapse" for="c-42384834">[-]</label><label class="expand" for="c-42384834">[2 more]</label></div><br/><div class="children"><div class="content">In the apps I&#x27;ve written, generally the user interaction with the API is synchronous and has some immediate effect (e.g. uploading a file - the file is committed and guaranteed accessible by the time the HTTP success response is sent, giving the system strong causal consistency) and within that same transaction I enqueue the related background task (e.g. processing the file) so that we never get an uploaded file with no associated background task (or vice-versa).<p>(The background task may involve its own transactions when dequeued later, and spawn further background tasks, etc)</div><br/><div id="42385057" class="c"><input type="checkbox" id="c-42385057" checked=""/><div class="controls bullet"><span class="by">KraftyOne</span><span>|</span><a href="#42380883">root</a><span>|</span><a href="#42384834">parent</a><span>|</span><a href="#42384896">next</a><span>|</span><label class="collapse" for="c-42385057">[-]</label><label class="expand" for="c-42385057">[1 more]</label></div><br/><div class="children"><div class="content">Got it!  So you can make the entire HTTP endpoint a DBOS workflow that performs the synchronous work then launches a background task.  Something like this:<p><pre><code>    @app.get(&quot;&#x2F;endpoint&quot;)
    @DBOS.workflow()
    def http_workflow():
        synchronous_task() # Run the synchronous task
        DBOS.start_workflow(background_task) # Start the background task asynchronously

</code></pre>
This is atomic in the sense that if the synchronous task runs, the background task will always also run.</div><br/></div></div></div></div></div></div><div id="42384896" class="c"><input type="checkbox" id="c-42384896" checked=""/><div class="controls bullet"><span class="by">Thaxll</span><span>|</span><a href="#42380883">root</a><span>|</span><a href="#42384418">parent</a><span>|</span><a href="#42384507">prev</a><span>|</span><a href="#42384189">next</a><span>|</span><label class="collapse" for="c-42384896">[-]</label><label class="expand" for="c-42384896">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s kind of weird to do that though, it mixes up concerns, why would an operation starts to mess up with specifc db integration.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="42384189" class="c"><input type="checkbox" id="c-42384189" checked=""/><div class="controls bullet"><span class="by">opiniateddev</span><span>|</span><a href="#42380883">prev</a><span>|</span><a href="#42382317">next</a><span>|</span><label class="collapse" for="c-42384189">[-]</label><label class="expand" for="c-42384189">[2 more]</label></div><br/><div class="children"><div class="content">how is it different from Conductor? <a href="https:&#x2F;&#x2F;github.com&#x2F;conductor-oss&#x2F;conductor">https:&#x2F;&#x2F;github.com&#x2F;conductor-oss&#x2F;conductor</a></div><br/><div id="42384610" class="c"><input type="checkbox" id="c-42384610" checked=""/><div class="controls bullet"><span class="by">KraftyOne</span><span>|</span><a href="#42384189">parent</a><span>|</span><a href="#42382317">next</a><span>|</span><label class="collapse" for="c-42384610">[-]</label><label class="expand" for="c-42384610">[1 more]</label></div><br/><div class="children"><div class="content">I haven&#x27;t used Conductor, but quickly looking at the README, Conductor lets you define JSON workflows to orchestrate existing microservices. By contrast, DBOS helps you build highly reliable applications--it runs as a library inside your program and helps you build durable workflows that run alongside your code and are written in the same language.</div><br/></div></div></div></div><div id="42382317" class="c"><input type="checkbox" id="c-42382317" checked=""/><div class="controls bullet"><span class="by">efxhoy</span><span>|</span><a href="#42384189">prev</a><span>|</span><a href="#42384386">next</a><span>|</span><label class="collapse" for="c-42382317">[-]</label><label class="expand" for="c-42382317">[2 more]</label></div><br/><div class="children"><div class="content">Interesting! Is there anything like this that I could host myself?</div><br/><div id="42382380" class="c"><input type="checkbox" id="c-42382380" checked=""/><div class="controls bullet"><span class="by">KraftyOne</span><span>|</span><a href="#42382317">parent</a><span>|</span><a href="#42384386">next</a><span>|</span><label class="collapse" for="c-42382380">[-]</label><label class="expand" for="c-42382380">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, the core DBOS library is totally open-source and you can run it anywhere as long as it has a Postgres to connect to.  Check it out: <a href="https:&#x2F;&#x2F;github.com&#x2F;dbos-inc&#x2F;dbos-transact-py">https:&#x2F;&#x2F;github.com&#x2F;dbos-inc&#x2F;dbos-transact-py</a></div><br/></div></div></div></div><div id="42384386" class="c"><input type="checkbox" id="c-42384386" checked=""/><div class="controls bullet"><span class="by">halfcat</span><span>|</span><a href="#42382317">prev</a><span>|</span><a href="#42381008">next</a><span>|</span><label class="collapse" for="c-42384386">[-]</label><label class="expand" for="c-42384386">[2 more]</label></div><br/><div class="children"><div class="content">This is very cool. How does this compare to tools like Celery and Dagster?<p>Like we might use Celery when we need to run specific tasks on specific workers (e.g. accessing some database that sits inside a corporate network, not accessible from the cloud). It seems like we can do something like that using DBOS queues or events, but is there a concept of running multiple workers in different locations?<p>Compared to Dagster, a DBOS workflow seems like a de facto DAG, running the steps in the right order, and being resumable if a step fails, and the difference here would be that with Dagster the steps are more granular, in the sense that we can re-run a specific step in isolation? In other words, a DBOS workflow will retry failed steps, but can we submit a request to “only re-run step 2”? This comes up often in working with ETL-style tasks, where steps 1 and 2 complete, but we need to resubmit steps 3 and 4 of a pipeline.<p>Dagster also provides nice visual feedback, where even a non-technical user can see that step 3 failed, and right-click it to materialize it. Maybe I need to play with the OpenTelemetry piece to see how that compares.<p>Celery and Dagster have their own drawbacks (heavier, complexity of more infrastructure, learning curve), so just trying to see where the edges are, and how far we could take a tool like DBOS. From an initial look, it seems like it could address a lot of these scenarios with less complexity.</div><br/><div id="42384550" class="c"><input type="checkbox" id="c-42384550" checked=""/><div class="controls bullet"><span class="by">KraftyOne</span><span>|</span><a href="#42384386">parent</a><span>|</span><a href="#42381008">next</a><span>|</span><label class="collapse" for="c-42384550">[-]</label><label class="expand" for="c-42384550">[1 more]</label></div><br/><div class="children"><div class="content">Compared to Celery, DBOS provides a similar queuing abstraction (Docs: <a href="https:&#x2F;&#x2F;docs.dbos.dev&#x2F;python&#x2F;tutorials&#x2F;queue-tutorial" rel="nofollow">https:&#x2F;&#x2F;docs.dbos.dev&#x2F;python&#x2F;tutorials&#x2F;queue-tutorial</a>) DBOS tries to spread out queued tasks among all workers (on DBOS Cloud, the workers autoscale with load), but there isn&#x27;t yet support for running specific tasks on specific workers. Would love to learn more about that use case!<p>Compared to Dagster (or Prefect or Airflow), exactly like you said, a DBOS workflow is basically a more flexible and lightweight DAG. The visualization piece is something we&#x27;re actively developing leveraging OpenTelemetry--look for some cool new viz features by the end of the month!  I&#x27;m interested in the &quot;retry step 2 only&quot; or &quot;retry from step 2&quot; use cases--would love to learn more about them--we don&#x27;t currently support them but easily could (because it&#x27;s all just Postgres tables under the hood).  If you&#x27;re building in this space please reach out, would love to chat!</div><br/></div></div></div></div><div id="42381008" class="c"><input type="checkbox" id="c-42381008" checked=""/><div class="controls bullet"><span class="by">exceptione</span><span>|</span><a href="#42384386">prev</a><span>|</span><label class="collapse" for="c-42381008">[-]</label><label class="expand" for="c-42381008">[6 more]</label></div><br/><div class="children"><div class="content">Bit disappointed, looked for .net core support but no.<p>Languages that are supported: Typescript and Python. I know programming languages as a topic is as inflammable as religion, but boy do I feel sad that these two are considered the most important these days. For server applications.<p>Anyways, can people here recommend alternatives with bindings for .net core?</div><br/><div id="42381351" class="c"><input type="checkbox" id="c-42381351" checked=""/><div class="controls bullet"><span class="by">jedberg</span><span>|</span><a href="#42381008">parent</a><span>|</span><a href="#42383584">next</a><span>|</span><label class="collapse" for="c-42381351">[-]</label><label class="expand" for="c-42381351">[2 more]</label></div><br/><div class="children"><div class="content">Interesting, I don&#x27;t think we&#x27;ve ever gotten a request for .net support.  Our two most popular asks after PY and TS are Golang and Java, which basically tracks with the StackOverflow language survey:<p><a href="https:&#x2F;&#x2F;survey.stackoverflow.co&#x2F;2024&#x2F;technology#most-popular-technologies-language-prof" rel="nofollow">https:&#x2F;&#x2F;survey.stackoverflow.co&#x2F;2024&#x2F;technology#most-popular...</a></div><br/><div id="42385720" class="c"><input type="checkbox" id="c-42385720" checked=""/><div class="controls bullet"><span class="by">nagyv</span><span>|</span><a href="#42381008">root</a><span>|</span><a href="#42381351">parent</a><span>|</span><a href="#42383584">next</a><span>|</span><label class="collapse" for="c-42385720">[-]</label><label class="expand" for="c-42385720">[1 more]</label></div><br/><div class="children"><div class="content">Where can we express interest? Golang (or Ruby) would be interesting</div><br/></div></div></div></div><div id="42383584" class="c"><input type="checkbox" id="c-42383584" checked=""/><div class="controls bullet"><span class="by">halfcat</span><span>|</span><a href="#42381008">parent</a><span>|</span><a href="#42381351">prev</a><span>|</span><a href="#42381533">next</a><span>|</span><label class="collapse" for="c-42383584">[-]</label><label class="expand" for="c-42383584">[1 more]</label></div><br/><div class="children"><div class="content">I haven’t used it, but .net developers I know seem to like Hangfire<p><a href="https:&#x2F;&#x2F;www.hangfire.io&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.hangfire.io&#x2F;</a></div><br/></div></div><div id="42381533" class="c"><input type="checkbox" id="c-42381533" checked=""/><div class="controls bullet"><span class="by">nawgz</span><span>|</span><a href="#42381008">parent</a><span>|</span><a href="#42383584">prev</a><span>|</span><label class="collapse" for="c-42381533">[-]</label><label class="expand" for="c-42381533">[2 more]</label></div><br/><div class="children"><div class="content">TypeScript has the best developer ergonomics<p>Python has<p>So it&#x27;s obvious why people would only support these two languages even when their performance isn&#x27;t best in class</div><br/><div id="42384433" class="c"><input type="checkbox" id="c-42384433" checked=""/><div class="controls bullet"><span class="by">revskill</span><span>|</span><a href="#42381008">root</a><span>|</span><a href="#42381533">parent</a><span>|</span><label class="collapse" for="c-42384433">[-]</label><label class="expand" for="c-42384433">[1 more]</label></div><br/><div class="children"><div class="content">PMs only care about developer performance.</div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>