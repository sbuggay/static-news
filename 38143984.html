<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1699174857834" as="style"/><link rel="stylesheet" href="styles.css?v=1699174857834"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://magazine.sebastianraschka.com/p/ai-and-open-source-in-2023">AI and Open Source in 2023</a> <span class="domain">(<a href="https://magazine.sebastianraschka.com">magazine.sebastianraschka.com</a>)</span></div><div class="subtext"><span>belter</span> | <span>58 comments</span></div><br/><div><div id="38144853" class="c"><input type="checkbox" id="c-38144853" checked=""/><div class="controls bullet"><span class="by">andy99</span><span>|</span><a href="#38145001">next</a><span>|</span><label class="collapse" for="c-38144853">[-]</label><label class="expand" for="c-38144853">[12 more]</label></div><br/><div class="children"><div class="content">Most importantly, 2023 was the year when &quot;open source&quot; got watered down to mean &quot;you can look at the source code &#x2F; weights&quot; if you agree with a bunch of stuff. Most of the models referenced, like stable diffusion (RAIL license) and Llama &amp; derivatives (proprietary facebook license with conditions on uses and some commercial terms) are not open source in the sense that it was understood a year ago. People protested a bit when the terminology started being abused, and now that&#x27;s mostly died down and people now call these restrictive licenses open source. This (plus ongoing regulatory capture) is going to be the wedge that destroys software freedom and brings us back to a regime where a few companies dictate how computers can be used.</div><br/><div id="38145162" class="c"><input type="checkbox" id="c-38145162" checked=""/><div class="controls bullet"><span class="by">ebalit</span><span>|</span><a href="#38144853">parent</a><span>|</span><a href="#38145176">next</a><span>|</span><label class="collapse" for="c-38145162">[-]</label><label class="expand" for="c-38145162">[4 more]</label></div><br/><div class="children"><div class="content">Mistral 7B [1] and many models stemming from it are released under permissive Apache license.<p>Some might argue that a &quot;pure&quot; open-source would require the dataset and the training &quot;recipe&quot; as it would be needed to reproduce the training, but it would be so expensive that most people wouldn&#x27;t be able to do much with it.<p>IMO, a release with open weights without the &quot;source&quot; is much better than the opposite, a release with open source and no trained weights.<p>And it&#x27;s not like there was no progress on the open dataset front:
- Together just released RedPajama V2, with enough tokens to train a very sizeable base model.
- Tsinghua released UltraFeedback which allowed more people to align models using RLHF methods (like the Zephyr models from Hugging Face)
- and many many others<p>[1] <a href="https:&#x2F;&#x2F;mistral.ai&#x2F;news&#x2F;announcing-mistral-7b&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;mistral.ai&#x2F;news&#x2F;announcing-mistral-7b&#x2F;</a>
[2] <a href="https:&#x2F;&#x2F;github.com&#x2F;togethercomputer&#x2F;RedPajama-Data">https:&#x2F;&#x2F;github.com&#x2F;togethercomputer&#x2F;RedPajama-Data</a></div><br/><div id="38149413" class="c"><input type="checkbox" id="c-38149413" checked=""/><div class="controls bullet"><span class="by">HPsquared</span><span>|</span><a href="#38144853">root</a><span>|</span><a href="#38145162">parent</a><span>|</span><a href="#38146530">next</a><span>|</span><label class="collapse" for="c-38149413">[-]</label><label class="expand" for="c-38149413">[1 more]</label></div><br/><div class="children"><div class="content">Even if they don&#x27;t release the (copyrighted) training data itself, do they provide a &quot;recipe&quot; to reproduce it?<p>Like, a list of sources used and how they were harvested?</div><br/></div></div><div id="38146530" class="c"><input type="checkbox" id="c-38146530" checked=""/><div class="controls bullet"><span class="by">graphGL</span><span>|</span><a href="#38144853">root</a><span>|</span><a href="#38145162">parent</a><span>|</span><a href="#38149413">prev</a><span>|</span><a href="#38145176">next</a><span>|</span><label class="collapse" for="c-38146530">[-]</label><label class="expand" for="c-38146530">[2 more]</label></div><br/><div class="children"><div class="content">&gt; <i>IMO, a release with open weights without the &quot;source&quot; is much better than the opposite, a release with open source and no trained weights.</i><p>Why not both?</div><br/><div id="38147305" class="c"><input type="checkbox" id="c-38147305" checked=""/><div class="controls bullet"><span class="by">totetsu</span><span>|</span><a href="#38144853">root</a><span>|</span><a href="#38146530">parent</a><span>|</span><a href="#38145176">next</a><span>|</span><label class="collapse" for="c-38147305">[-]</label><label class="expand" for="c-38147305">[1 more]</label></div><br/><div class="children"><div class="content">Isn’t everyone using data sets they don’t have rights to? Or at least not right to release.</div><br/></div></div></div></div></div></div><div id="38145176" class="c"><input type="checkbox" id="c-38145176" checked=""/><div class="controls bullet"><span class="by">seydor</span><span>|</span><a href="#38144853">parent</a><span>|</span><a href="#38145162">prev</a><span>|</span><a href="#38144889">next</a><span>|</span><label class="collapse" for="c-38145176">[-]</label><label class="expand" for="c-38145176">[1 more]</label></div><br/><div class="children"><div class="content">mistral appears to be quite open, and even better than llama imho</div><br/></div></div><div id="38144889" class="c"><input type="checkbox" id="c-38144889" checked=""/><div class="controls bullet"><span class="by">Der_Einzige</span><span>|</span><a href="#38144853">parent</a><span>|</span><a href="#38145176">prev</a><span>|</span><a href="#38145828">next</a><span>|</span><label class="collapse" for="c-38144889">[-]</label><label class="expand" for="c-38144889">[5 more]</label></div><br/><div class="children"><div class="content">In practice this matters less than you think. You can’t easily prove that any outputs were generated by a particular model in general, so any user can simply ignore your licenses and do as they please.<p>I know it rustles purist feathers, but I don’t understand why we live in this pretend world that assumes that folks particularly care about respecting licenses. Consider how little success that the GNU folks have had with using the courts for any enforcement of their licenses, and that’s by stallmans own admission.<p>AI is itself a subversive technology, whose current versions rely on subversive training techniques. Why should we expect everyone to suddenly want to follow the rules when they read a poorly written restrictive open source license?</div><br/><div id="38145033" class="c"><input type="checkbox" id="c-38145033" checked=""/><div class="controls bullet"><span class="by">andy99</span><span>|</span><a href="#38144853">root</a><span>|</span><a href="#38144889">parent</a><span>|</span><a href="#38148500">next</a><span>|</span><label class="collapse" for="c-38145033">[-]</label><label class="expand" for="c-38145033">[1 more]</label></div><br/><div class="children"><div class="content">For personal or noncommercial use I agree the restrictions are meaningless. As they are for &quot;bad actors&quot; that would potentially abuse the tools in contravention of the license. But the license terms are a risk for commercial users especially when dealing with a big company like Meta. These risks werent previously there in say pytorch that is MIT licensed. The ironic thing with these licenses is that they are least enforceable on those who would be most likely to abuse them: <a href="https:&#x2F;&#x2F;katedowninglaw.com&#x2F;2023&#x2F;07&#x2F;13&#x2F;ai-licensing-cant-balance-open-with-responsible&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;katedowninglaw.com&#x2F;2023&#x2F;07&#x2F;13&#x2F;ai-licensing-cant-bala...</a><p>Re success of free licenses, linux (other than a few arguable abuses) has remained free and unencumbered thanks to GPL licensing.</div><br/></div></div><div id="38148500" class="c"><input type="checkbox" id="c-38148500" checked=""/><div class="controls bullet"><span class="by">codetrotter</span><span>|</span><a href="#38144853">root</a><span>|</span><a href="#38144889">parent</a><span>|</span><a href="#38145033">prev</a><span>|</span><a href="#38145095">next</a><span>|</span><label class="collapse" for="c-38148500">[-]</label><label class="expand" for="c-38148500">[1 more]</label></div><br/><div class="children"><div class="content">&gt; You can’t easily prove that any outputs were generated by a particular model in general<p>But we also don’t know if there’s a trick up the sleeve that allows any of those models to be asked a very specific question that will result in a very specific answer.<p>Similarly to how map makers hide mistakes in their maps that they can point to when they want to prove that someone took their maps and presented it as their own.<p>Imagine using Llama for a customer support bot with a custom prompt, but there exist some phrase you don’t know that will make it say something that only Llama would say in response to that.</div><br/></div></div><div id="38145095" class="c"><input type="checkbox" id="c-38145095" checked=""/><div class="controls bullet"><span class="by">nologic01</span><span>|</span><a href="#38144853">root</a><span>|</span><a href="#38144889">parent</a><span>|</span><a href="#38148500">prev</a><span>|</span><a href="#38145828">next</a><span>|</span><label class="collapse" for="c-38145095">[-]</label><label class="expand" for="c-38145095">[2 more]</label></div><br/><div class="children"><div class="content">Somehow the &quot;AI defense&quot; (namely that it is not possible to &quot;prove&quot; anything was used illegally) will open Pandora&#x27;s box in terms of providing viable channels for whitewashing explicit theft activity. Steal anything proprietary, run it through an AI filter that mixes it with other stuff and claim it as your own.</div><br/><div id="38147081" class="c"><input type="checkbox" id="c-38147081" checked=""/><div class="controls bullet"><span class="by">AnthonyMouse</span><span>|</span><a href="#38144853">root</a><span>|</span><a href="#38145095">parent</a><span>|</span><a href="#38145828">next</a><span>|</span><label class="collapse" for="c-38147081">[-]</label><label class="expand" for="c-38147081">[1 more]</label></div><br/><div class="children"><div class="content">A human could have done that at any point in the past. The only novelty is now a machine can do it.</div><br/></div></div></div></div></div></div><div id="38145828" class="c"><input type="checkbox" id="c-38145828" checked=""/><div class="controls bullet"><span class="by">emadm</span><span>|</span><a href="#38144853">parent</a><span>|</span><a href="#38144889">prev</a><span>|</span><a href="#38145001">next</a><span>|</span><label class="collapse" for="c-38145828">[-]</label><label class="expand" for="c-38145828">[1 more]</label></div><br/><div class="children"><div class="content">Check out our fully open recent 3b model which outperforms most 7b models and runs on an iPhone&#x2F;cpu, fully open including data and details<p>Tuned versions outperform 13b vicuña, wizard etc<p><a href="https:&#x2F;&#x2F;stability.wandb.io&#x2F;stability-llm&#x2F;stable-lm&#x2F;reports&#x2F;StableLM-3B-4E1T--VmlldzoyMjU4?accessToken=u3zujipenkx5g7rtcj9qojjgxpconyjktjkli2po09nffrffdhhchq045vp0wyfo" rel="nofollow noreferrer">https:&#x2F;&#x2F;stability.wandb.io&#x2F;stability-llm&#x2F;stable-lm&#x2F;reports&#x2F;S...</a></div><br/></div></div></div></div><div id="38145001" class="c"><input type="checkbox" id="c-38145001" checked=""/><div class="controls bullet"><span class="by">nologic01</span><span>|</span><a href="#38144853">prev</a><span>|</span><a href="#38145472">next</a><span>|</span><label class="collapse" for="c-38145001">[-]</label><label class="expand" for="c-38145001">[9 more]</label></div><br/><div class="children"><div class="content">Is there a truly open source effort in the LLM space? Like a collaborative, crowd-sourced effort (possibly with academic institutions playing a major role) that relies on creative commons licensed or otherwise open data and produces a public good as final outcome?<p>There is this ridiculous idea of AI moats and other machinations for the next big VC thing (god bless them, people have spend their energy on worse pursuits) but in a fundamental sense there is a public good type infrastructure crying out to be developed for each major linguistic domain.<p>Maybe such an effort would not be cutting edge enough to power the next corporate chatbot that will eliminate 99% of all jobs, but it would be a significant step up in our ability to process text.</div><br/><div id="38145815" class="c"><input type="checkbox" id="c-38145815" checked=""/><div class="controls bullet"><span class="by">emadm</span><span>|</span><a href="#38145001">parent</a><span>|</span><a href="#38148678">next</a><span>|</span><label class="collapse" for="c-38145815">[-]</label><label class="expand" for="c-38145815">[2 more]</label></div><br/><div class="children"><div class="content">We back rwkv, eleuther ai and others at stability ai<p>We also have our carper.ai lab for the rl buts<p>We are rolling out open language models and datasets soon for a number of languages too, see our recent Japanese language models for example<p>Got some big plans soon, have funded it all ourself but sure other would like to help</div><br/><div id="38146585" class="c"><input type="checkbox" id="c-38146585" checked=""/><div class="controls bullet"><span class="by">senseiV</span><span>|</span><a href="#38145001">root</a><span>|</span><a href="#38145815">parent</a><span>|</span><a href="#38148678">next</a><span>|</span><label class="collapse" for="c-38146585">[-]</label><label class="expand" for="c-38146585">[1 more]</label></div><br/><div class="children"><div class="content">ah yes RWKV, always great to mention, crazy about how no one talks about it, it literally the most powerful multilang model at 1b and 3b scales, probs going for 14b and 7b too</div><br/></div></div></div></div><div id="38148678" class="c"><input type="checkbox" id="c-38148678" checked=""/><div class="controls bullet"><span class="by">doctorpangloss</span><span>|</span><a href="#38145001">parent</a><span>|</span><a href="#38145815">prev</a><span>|</span><a href="#38145093">next</a><span>|</span><label class="collapse" for="c-38148678">[-]</label><label class="expand" for="c-38148678">[1 more]</label></div><br/><div class="children"><div class="content">&gt; that relies on creative commons licensed or otherwise open data<p>You can try very hard to make neural network stuff a holistic social experience. There is a lot of value in that! I think it&#x27;s meaningless though, a colossal waste of time.<p>In the objective reality we live in: We wouldn&#x27;t be talking about transformers, attention, etc. if it weren&#x27;t for papers that used so called &quot;not&quot; &quot;open data.&quot;<p>It&#x27;s all tainted. There&#x27;s no shortcuts.<p>If you buy into holistic social experiences as an essential part of your chatbot or whatever, you expose yourself to being sniped in some basic way by merely <i>one</i> comment on the Internet. Bullshit Street is a two lane road.</div><br/></div></div><div id="38145093" class="c"><input type="checkbox" id="c-38145093" checked=""/><div class="controls bullet"><span class="by">dartos</span><span>|</span><a href="#38145001">parent</a><span>|</span><a href="#38148678">prev</a><span>|</span><a href="#38145038">next</a><span>|</span><label class="collapse" for="c-38145093">[-]</label><label class="expand" for="c-38145093">[1 more]</label></div><br/><div class="children"><div class="content">RWKV is fully open source and even part of the Linux foundation<p>Idk why nobody ever talks about it</div><br/></div></div><div id="38145038" class="c"><input type="checkbox" id="c-38145038" checked=""/><div class="controls bullet"><span class="by">vinni2</span><span>|</span><a href="#38145001">parent</a><span>|</span><a href="#38145093">prev</a><span>|</span><a href="#38145623">next</a><span>|</span><label class="collapse" for="c-38145038">[-]</label><label class="expand" for="c-38145038">[3 more]</label></div><br/><div class="children"><div class="content">I think OpenAssistant is the closest to what you are describing but their models are not yet that great. <a href="https:&#x2F;&#x2F;open-assistant.io&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;open-assistant.io&#x2F;</a></div><br/><div id="38145406" class="c"><input type="checkbox" id="c-38145406" checked=""/><div class="controls bullet"><span class="by">nulld3v</span><span>|</span><a href="#38145001">root</a><span>|</span><a href="#38145038">parent</a><span>|</span><a href="#38145623">next</a><span>|</span><label class="collapse" for="c-38145406">[-]</label><label class="expand" for="c-38145406">[2 more]</label></div><br/><div class="children"><div class="content">Open Assistant just shut down: <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=gqtmUHhaplo">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=gqtmUHhaplo</a><p>Cited reasons: Lack of resources, lack of maintainer time and there being many new good alternatives.</div><br/><div id="38146117" class="c"><input type="checkbox" id="c-38146117" checked=""/><div class="controls bullet"><span class="by">vinni2</span><span>|</span><a href="#38145001">root</a><span>|</span><a href="#38145406">parent</a><span>|</span><a href="#38145623">next</a><span>|</span><label class="collapse" for="c-38146117">[-]</label><label class="expand" for="c-38146117">[1 more]</label></div><br/><div class="children"><div class="content">oh I didn’t know that.</div><br/></div></div></div></div></div></div><div id="38145623" class="c"><input type="checkbox" id="c-38145623" checked=""/><div class="controls bullet"><span class="by">TheCaptain4815</span><span>|</span><a href="#38145001">parent</a><span>|</span><a href="#38145038">prev</a><span>|</span><a href="#38145472">next</a><span>|</span><label class="collapse" for="c-38145623">[-]</label><label class="expand" for="c-38145623">[1 more]</label></div><br/><div class="children"><div class="content">ElutherAi fits that I believe. In the olden days (1.5 years ago) they probably had the best open source model with their NeoX model, but it’s been ellipsed by Llamma and other “open source” models I believe. They still have an active discord with a great community pushing forward.</div><br/></div></div></div></div><div id="38145472" class="c"><input type="checkbox" id="c-38145472" checked=""/><div class="controls bullet"><span class="by">jimmySixDOF</span><span>|</span><a href="#38145001">prev</a><span>|</span><a href="#38145817">next</a><span>|</span><label class="collapse" for="c-38145472">[-]</label><label class="expand" for="c-38145472">[2 more]</label></div><br/><div class="children"><div class="content">On a retrospective take of the state of AI 1 year this month into LLMs post ChatGPT, I would like to single out Simon Wilson as the MVP for Open AI tooling contribution.  His datasett projects are a great work in in progress and the prodigious blog posts and TIL snips are state of the art. Great onboarding to the whole ecosystem.  I find myself using something he has produced in some way everyday.<p><a href="https:&#x2F;&#x2F;simonwillison.net&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;simonwillison.net&#x2F;</a></div><br/></div></div><div id="38145817" class="c"><input type="checkbox" id="c-38145817" checked=""/><div class="controls bullet"><span class="by">raincole</span><span>|</span><a href="#38145472">prev</a><span>|</span><a href="#38145164">next</a><span>|</span><label class="collapse" for="c-38145817">[-]</label><label class="expand" for="c-38145817">[2 more]</label></div><br/><div class="children"><div class="content">I think open models are more like closed source freemium applications. You got the weights, which are &quot;compiled&quot; from the source material. You&#x27;re free to use it, but you can&#x27;t, for example, remove one source material from it.</div><br/><div id="38148872" class="c"><input type="checkbox" id="c-38148872" checked=""/><div class="controls bullet"><span class="by">PeterStuer</span><span>|</span><a href="#38145817">parent</a><span>|</span><a href="#38145164">next</a><span>|</span><label class="collapse" for="c-38148872">[-]</label><label class="expand" for="c-38148872">[1 more]</label></div><br/><div class="children"><div class="content">Which part of e.g. the llama2 license is stopping you from doing that?</div><br/></div></div></div></div><div id="38145164" class="c"><input type="checkbox" id="c-38145164" checked=""/><div class="controls bullet"><span class="by">seydor</span><span>|</span><a href="#38145817">prev</a><span>|</span><a href="#38146280">next</a><span>|</span><label class="collapse" for="c-38145164">[-]</label><label class="expand" for="c-38145164">[3 more]</label></div><br/><div class="children"><div class="content">$NVDA went to the moon, AI stocks skyrocketed including any beer with &quot;AI&quot; in its name. The rest of the story is typical by now: vc money flows,  companies hide their trade secrets  (prompts), public research is derailed. It&#x27;s all very premature, LLMs was not the end of the road.</div><br/><div id="38146592" class="c"><input type="checkbox" id="c-38146592" checked=""/><div class="controls bullet"><span class="by">anonylizard</span><span>|</span><a href="#38145164">parent</a><span>|</span><a href="#38145214">next</a><span>|</span><label class="collapse" for="c-38146592">[-]</label><label class="expand" for="c-38146592">[1 more]</label></div><br/><div class="children"><div class="content">Its not premature at all.<p>Sharing research stops the second REVENUE starts flowing in. AI was always funded by VC&#x2F;Research budget. When you are on a timer without a viable product, its beneficial to open source research to accelerate the time to reach a sellable product.<p>With GPT3.5, that point was reached, it is commercially very valuable, and OpenAI&#x27;s revenue is very high even just as a consumer product, let alone all the API integrations that produce real, real value (All the outsourcing agents in India and Philippine are not more sophisticated than GPT4).<p>Now it makes money, time to make everything a trade secret. Google doesn&#x27;t open source their search algorithm, and there&#x27;s nothing wrong with that.<p>LLMs are not the end of the road, and the massive amounts of revenue generated by LLMs will fund the next generation of AIs to be developed. GPUs are closed source, doesn&#x27;t stop them from advancing rapidly. We are in a high interest rate environment, and AI is still getting titanic amounts of investment, because its proven to generate real income, not some speculative bet anymore.</div><br/></div></div><div id="38145214" class="c"><input type="checkbox" id="c-38145214" checked=""/><div class="controls bullet"><span class="by">brrrrrm</span><span>|</span><a href="#38145164">parent</a><span>|</span><a href="#38146592">prev</a><span>|</span><a href="#38146280">next</a><span>|</span><label class="collapse" for="c-38145214">[-]</label><label class="expand" for="c-38145214">[1 more]</label></div><br/><div class="children"><div class="content">Why do you say “prompts” is the canonical trade secret?</div><br/></div></div></div></div><div id="38144766" class="c"><input type="checkbox" id="c-38144766" checked=""/><div class="controls bullet"><span class="by">gumballindie</span><span>|</span><a href="#38146280">prev</a><span>|</span><a href="#38145707">next</a><span>|</span><label class="collapse" for="c-38144766">[-]</label><label class="expand" for="c-38144766">[27 more]</label></div><br/><div class="children"><div class="content">As soon as DRM for text and images is implemented companies such openai will be in for a ride. Unfortunately though open source models will be sacrificed in the process, but we need means to protect against the rampant ip theft ai companies do.</div><br/><div id="38144904" class="c"><input type="checkbox" id="c-38144904" checked=""/><div class="controls bullet"><span class="by">minimaxir</span><span>|</span><a href="#38144766">parent</a><span>|</span><a href="#38145118">next</a><span>|</span><label class="collapse" for="c-38144904">[-]</label><label class="expand" for="c-38144904">[8 more]</label></div><br/><div class="children"><div class="content">Which means that companies will just license the data used to train models because they have the money to do so, or use their own data instead. That&#x27;s how Adobe&#x27;s Firefly works right now, and OpenAI just signed a licensing agreement with Shutterstock: <a href="https:&#x2F;&#x2F;venturebeat.com&#x2F;ai&#x2F;shutterstock-signs-6-year-training-data-agreement-with-openai&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;venturebeat.com&#x2F;ai&#x2F;shutterstock-signs-6-year-trainin...</a><p>Even if it became impossible to train AI on internet-accessible data, there&#x27;s no change to the proliferation of generative AI other than keeping it entrenched and centralized in the power of a few players, and it has no impact on potentially taking jobs from artists, other than making it <i>harder</i> for artists to compete due to the lack of open-source alternatives.</div><br/><div id="38145030" class="c"><input type="checkbox" id="c-38145030" checked=""/><div class="controls bullet"><span class="by">gumballindie</span><span>|</span><a href="#38144766">root</a><span>|</span><a href="#38144904">parent</a><span>|</span><a href="#38145118">next</a><span>|</span><label class="collapse" for="c-38145030">[-]</label><label class="expand" for="c-38145030">[7 more]</label></div><br/><div class="children"><div class="content">No problem then, people willing to make their content available to ai can do so by using such websites, people that value their work can use something else.</div><br/><div id="38145401" class="c"><input type="checkbox" id="c-38145401" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#38144766">root</a><span>|</span><a href="#38145030">parent</a><span>|</span><a href="#38145118">next</a><span>|</span><label class="collapse" for="c-38145401">[-]</label><label class="expand" for="c-38145401">[6 more]</label></div><br/><div class="children"><div class="content">That has the same vibe as responding to the invention of the Jacquard loom by saying: &quot;No problem then, people willing to make their designs available to automation can do so by using such punched cards, people that value their work can use something else.&quot;<p>Home weaving does still exist. Not a very big employer any more, though.</div><br/><div id="38146097" class="c"><input type="checkbox" id="c-38146097" checked=""/><div class="controls bullet"><span class="by">LastTrain</span><span>|</span><a href="#38144766">root</a><span>|</span><a href="#38145401">parent</a><span>|</span><a href="#38146633">next</a><span>|</span><label class="collapse" for="c-38146097">[-]</label><label class="expand" for="c-38146097">[4 more]</label></div><br/><div class="children"><div class="content">All analogies are fraught but this one takes the cake. A more apt one is not wanting the Jaquard loom people to steal my designs.</div><br/><div id="38146528" class="c"><input type="checkbox" id="c-38146528" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#38144766">root</a><span>|</span><a href="#38146097">parent</a><span>|</span><a href="#38146636">next</a><span>|</span><label class="collapse" for="c-38146528">[-]</label><label class="expand" for="c-38146528">[2 more]</label></div><br/><div class="children"><div class="content">It was difficult for me to find even this half-baked[0] analogy, given we&#x27;ve never had AI before.<p>The point I was aiming for is that even if your stuff isn&#x27;t ever stolen (regardless of what exactly you mean by that), you&#x27;re still going to be out of a job because the automaton is <i>good enough</i> to out-compete you economically.<p>At least, that&#x27;s my expectation, though I hope not for a few more years at least.<p>[0] yes that pun was deliberate</div><br/><div id="38146672" class="c"><input type="checkbox" id="c-38146672" checked=""/><div class="controls bullet"><span class="by">gumballindie</span><span>|</span><a href="#38144766">root</a><span>|</span><a href="#38146528">parent</a><span>|</span><a href="#38146636">next</a><span>|</span><label class="collapse" for="c-38146672">[-]</label><label class="expand" for="c-38146672">[1 more]</label></div><br/><div class="children"><div class="content">I am not worried about job losses, not that it would be easy to achieve by current ai, nor am i against ai. I am against corporations taking what doesnt belong to them and using it against us.<p>Technically speaking if ai would be as capable as you think it would mean that we wouldnt need said corporations since ai can provide all the services they do - otherwise it would be illogical and contradictory to claim ai can do everything under the sun.<p>My beef is with the oligarchy thats eroding our freedoms, privacy, and ownership. You should be too because our democracy and way of life is threatened by them. Ai is just another tool they want to monopolise.</div><br/></div></div></div></div><div id="38146636" class="c"><input type="checkbox" id="c-38146636" checked=""/><div class="controls bullet"><span class="by">gumballindie</span><span>|</span><a href="#38144766">root</a><span>|</span><a href="#38146097">parent</a><span>|</span><a href="#38146528">prev</a><span>|</span><a href="#38146633">next</a><span>|</span><label class="collapse" for="c-38146636">[-]</label><label class="expand" for="c-38146636">[1 more]</label></div><br/><div class="children"><div class="content">Except its not designs being stolen but rather products. Also stealing designs is not allowed in modern times since you know we evolved.</div><br/></div></div></div></div><div id="38146633" class="c"><input type="checkbox" id="c-38146633" checked=""/><div class="controls bullet"><span class="by">gumballindie</span><span>|</span><a href="#38144766">root</a><span>|</span><a href="#38145401">parent</a><span>|</span><a href="#38146097">prev</a><span>|</span><a href="#38145118">next</a><span>|</span><label class="collapse" for="c-38146633">[-]</label><label class="expand" for="c-38146633">[1 more]</label></div><br/><div class="children"><div class="content">I doubt procedural text and image generators will have the same impact, plus the Jacquard loom didnt involve stealing someone else’s textiles to build new products.</div><br/></div></div></div></div></div></div></div></div><div id="38145118" class="c"><input type="checkbox" id="c-38145118" checked=""/><div class="controls bullet"><span class="by">babyshake</span><span>|</span><a href="#38144766">parent</a><span>|</span><a href="#38144904">prev</a><span>|</span><a href="#38145084">next</a><span>|</span><label class="collapse" for="c-38145118">[-]</label><label class="expand" for="c-38145118">[2 more]</label></div><br/><div class="children"><div class="content">Watermarking images, particularly very high resolution images, I can understand, but I fail to see how with text, you would watermark it in a way that provides sufficient evidence it has been used for training data, unless the model is just quoting it at length.</div><br/><div id="38148953" class="c"><input type="checkbox" id="c-38148953" checked=""/><div class="controls bullet"><span class="by">Closi</span><span>|</span><a href="#38144766">root</a><span>|</span><a href="#38145118">parent</a><span>|</span><a href="#38145084">next</a><span>|</span><label class="collapse" for="c-38148953">[-]</label><label class="expand" for="c-38148953">[1 more]</label></div><br/><div class="children"><div class="content">Text watermarks are possible - one previously-used method is to use different ascii characters for spaces and dashes, that looks invisible to the user but can be detected if it’s a straight copy-paste (even when printed due to slightly differing lengths).<p>Of course it’s possible to process these out, same as an image watermark.</div><br/></div></div></div></div><div id="38145084" class="c"><input type="checkbox" id="c-38145084" checked=""/><div class="controls bullet"><span class="by">jrm4</span><span>|</span><a href="#38144766">parent</a><span>|</span><a href="#38145118">prev</a><span>|</span><a href="#38144845">next</a><span>|</span><label class="collapse" for="c-38145084">[-]</label><label class="expand" for="c-38145084">[10 more]</label></div><br/><div class="children"><div class="content">You&#x27;re probably getting downvoted because &quot;DRM&quot; was nearly a complete technical failure already, and there&#x27;s no reason believe it would be different for AI?</div><br/><div id="38145285" class="c"><input type="checkbox" id="c-38145285" checked=""/><div class="controls bullet"><span class="by">ls612</span><span>|</span><a href="#38144766">root</a><span>|</span><a href="#38145084">parent</a><span>|</span><a href="#38145131">next</a><span>|</span><label class="collapse" for="c-38145285">[-]</label><label class="expand" for="c-38145285">[5 more]</label></div><br/><div class="children"><div class="content">Unfortunatley I think you are wrong about this. DRM schemes are evolving to be nearly unbreakable in the future with the widespread adoption of security processors in everything.<p>As long as there is a massive fundamental asymmetry between assembling a chip with a small amount of ROM and disassembling &amp; reading that ROM while still making the chip usable, DRM schemes using PKI methods will become widespread and nigh unbreakable.</div><br/><div id="38145434" class="c"><input type="checkbox" id="c-38145434" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#38144766">root</a><span>|</span><a href="#38145285">parent</a><span>|</span><a href="#38147549">next</a><span>|</span><label class="collapse" for="c-38145434">[-]</label><label class="expand" for="c-38145434">[2 more]</label></div><br/><div class="children"><div class="content">Point [camera&#x2F;microphone&#x2F;eyeball] at [video&#x2F;audio&#x2F;text], [press record&#x2F;press record&#x2F;start writing down what you see].</div><br/><div id="38147951" class="c"><input type="checkbox" id="c-38147951" checked=""/><div class="controls bullet"><span class="by">badsectoracula</span><span>|</span><a href="#38144766">root</a><span>|</span><a href="#38145434">parent</a><span>|</span><a href="#38147549">next</a><span>|</span><label class="collapse" for="c-38147951">[-]</label><label class="expand" for="c-38147951">[1 more]</label></div><br/><div class="children"><div class="content">Most likely you could also use AI to clean up the image&#x2F;audio&#x2F;text too, after all one of the earlier uses of GPU accelerated neural networks i remember was Waifu2x for upscaling lowres anime :-P</div><br/></div></div></div></div><div id="38147549" class="c"><input type="checkbox" id="c-38147549" checked=""/><div class="controls bullet"><span class="by">jrm4</span><span>|</span><a href="#38144766">root</a><span>|</span><a href="#38145285">parent</a><span>|</span><a href="#38145434">prev</a><span>|</span><a href="#38146739">next</a><span>|</span><label class="collapse" for="c-38147549">[-]</label><label class="expand" for="c-38147549">[1 more]</label></div><br/><div class="children"><div class="content">Analog hole, fam.<p>As correctly noted below, if the eye can see it or the ear can hear it, you have no meaningful DRM.</div><br/></div></div><div id="38146739" class="c"><input type="checkbox" id="c-38146739" checked=""/><div class="controls bullet"><span class="by">Pannoniae</span><span>|</span><a href="#38144766">root</a><span>|</span><a href="#38145285">parent</a><span>|</span><a href="#38147549">prev</a><span>|</span><a href="#38145131">next</a><span>|</span><label class="collapse" for="c-38146739">[-]</label><label class="expand" for="c-38146739">[1 more]</label></div><br/><div class="children"><div class="content">If this truly happens, it will be easier to bribe an employee to leak the private keys, so the DRM will be useless...</div><br/></div></div></div></div><div id="38145131" class="c"><input type="checkbox" id="c-38145131" checked=""/><div class="controls bullet"><span class="by">gumballindie</span><span>|</span><a href="#38144766">root</a><span>|</span><a href="#38145084">parent</a><span>|</span><a href="#38145285">prev</a><span>|</span><a href="#38144845">next</a><span>|</span><label class="collapse" for="c-38145131">[-]</label><label class="expand" for="c-38145131">[4 more]</label></div><br/><div class="children"><div class="content">Normally i wouldnt advocate for drm but there needs to be a way to protect our content from this madness. I understand the backlash though and I am not worried about downvotes.</div><br/><div id="38147562" class="c"><input type="checkbox" id="c-38147562" checked=""/><div class="controls bullet"><span class="by">jrm4</span><span>|</span><a href="#38144766">root</a><span>|</span><a href="#38145131">parent</a><span>|</span><a href="#38145903">next</a><span>|</span><label class="collapse" for="c-38147562">[-]</label><label class="expand" for="c-38147562">[1 more]</label></div><br/><div class="children"><div class="content">There are lots of ways, it&#x27;s just that none of them should or can meaningfully involve pretending that the technology of conversion of content into ones and zeros can go backwards.<p>Policy, education, law, etc.</div><br/></div></div><div id="38145903" class="c"><input type="checkbox" id="c-38145903" checked=""/><div class="controls bullet"><span class="by">Krasnol</span><span>|</span><a href="#38144766">root</a><span>|</span><a href="#38145131">parent</a><span>|</span><a href="#38147562">prev</a><span>|</span><a href="#38146602">next</a><span>|</span><label class="collapse" for="c-38145903">[-]</label><label class="expand" for="c-38145903">[1 more]</label></div><br/><div class="children"><div class="content">Your content was never protected in the sense you want it to be protected.<p>Since the moment you put it up online for people to see and hear, they were able to move on and create something else based upon this. Most of the time unconsciously. This is how humanity works. This is the reason we&#x27;re still on this planet. AI accelerates the process like any other tool we&#x27;ve come up with since we climbed down the trees.<p>You can complain and scream as much as you want, but it won&#x27;t change. Even if you manage to regulate the whole western part of the internet. The rest of the world is bigger and won&#x27;t sleep.</div><br/></div></div><div id="38146602" class="c"><input type="checkbox" id="c-38146602" checked=""/><div class="controls bullet"><span class="by">CamperBob2</span><span>|</span><a href="#38144766">root</a><span>|</span><a href="#38145131">parent</a><span>|</span><a href="#38145903">prev</a><span>|</span><a href="#38144845">next</a><span>|</span><label class="collapse" for="c-38146602">[-]</label><label class="expand" for="c-38146602">[1 more]</label></div><br/><div class="children"><div class="content">&quot;Normally i wouldnt advocate for drm but there needs to be a way to protect our content from this madness,&quot; said everybody you&#x27;ve ever disagreed with up until now.</div><br/></div></div></div></div></div></div><div id="38144845" class="c"><input type="checkbox" id="c-38144845" checked=""/><div class="controls bullet"><span class="by">artninja1988</span><span>|</span><a href="#38144766">parent</a><span>|</span><a href="#38145084">prev</a><span>|</span><a href="#38145089">next</a><span>|</span><label class="collapse" for="c-38144845">[-]</label><label class="expand" for="c-38144845">[5 more]</label></div><br/><div class="children"><div class="content">No such thing as IP theft</div><br/><div id="38144959" class="c"><input type="checkbox" id="c-38144959" checked=""/><div class="controls bullet"><span class="by">minimaxir</span><span>|</span><a href="#38144766">root</a><span>|</span><a href="#38144845">parent</a><span>|</span><a href="#38144941">next</a><span>|</span><label class="collapse" for="c-38144959">[-]</label><label class="expand" for="c-38144959">[3 more]</label></div><br/><div class="children"><div class="content">It&#x27;s entirely possible to steal IP, but the &quot;AI art is theft&quot; part of it is still legally up in the air.</div><br/><div id="38145080" class="c"><input type="checkbox" id="c-38145080" checked=""/><div class="controls bullet"><span class="by">jrm4</span><span>|</span><a href="#38144766">root</a><span>|</span><a href="#38144959">parent</a><span>|</span><a href="#38145050">next</a><span>|</span><label class="collapse" for="c-38145080">[-]</label><label class="expand" for="c-38145080">[1 more]</label></div><br/><div class="children"><div class="content">I think what OP is referring to is the entirely reasonable legal argument that IP infringement is not actually &quot;theft&quot;<p>The idea being: &quot;Theft&quot; isn&#x27;t about &quot;you get something you don&#x27;t own,&quot; it means &quot;you deprive someone else of THEIR property.&quot;</div><br/></div></div><div id="38145050" class="c"><input type="checkbox" id="c-38145050" checked=""/><div class="controls bullet"><span class="by">gumballindie</span><span>|</span><a href="#38144766">root</a><span>|</span><a href="#38144959">parent</a><span>|</span><a href="#38145080">prev</a><span>|</span><a href="#38144941">next</a><span>|</span><label class="collapse" for="c-38145050">[-]</label><label class="expand" for="c-38145050">[1 more]</label></div><br/><div class="children"><div class="content">There are all sorts of things that are legal and immoral or disagreeable so even if ai art theft is legalised it’s still theft if the author doesnt want it to be used that way. It seems like “ai” is quite reliant on ingesting and storing massive property data to emulate “intelligence” - and thats equal to people downloading and storing movies and music. A thing we are not permitted to by the same corporations that you wish to help.</div><br/></div></div></div></div><div id="38144941" class="c"><input type="checkbox" id="c-38144941" checked=""/><div class="controls bullet"><span class="by">gumballindie</span><span>|</span><a href="#38144766">root</a><span>|</span><a href="#38144845">parent</a><span>|</span><a href="#38144959">prev</a><span>|</span><a href="#38145089">next</a><span>|</span><label class="collapse" for="c-38144941">[-]</label><label class="expand" for="c-38144941">[1 more]</label></div><br/><div class="children"><div class="content">Let me guess - you think ip and copyright are “rent seeking”? What a weird age we live in. Where people defend corporations from stealing our work. Quite a shift from the reverse.</div><br/></div></div></div></div><div id="38145089" class="c"><input type="checkbox" id="c-38145089" checked=""/><div class="controls bullet"><span class="by">candiddevmike</span><span>|</span><a href="#38144766">parent</a><span>|</span><a href="#38144845">prev</a><span>|</span><a href="#38145707">next</a><span>|</span><label class="collapse" for="c-38145089">[-]</label><label class="expand" for="c-38145089">[1 more]</label></div><br/><div class="children"><div class="content">IMO, I think the entire &quot;train on as much data as possible&quot; is nearing its end.  There are diminishing returns and it seems like a dead end strategy.</div><br/></div></div></div></div></div></div></div></div></div></body></html>