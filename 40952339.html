<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1720861252406" as="style"/><link rel="stylesheet" href="styles.css?v=1720861252406"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="http://addxorrol.blogspot.com/2024/07/someone-is-wrong-on-internet-agi-doom.html">Someone is wrong on the internet (AGI Doom edition)</a> <span class="domain">(<a href="http://addxorrol.blogspot.com">addxorrol.blogspot.com</a>)</span></div><div class="subtext"><span>weinzierl</span> | <span>5 comments</span></div><br/><div><div id="40952736" class="c"><input type="checkbox" id="c-40952736" checked=""/><div class="controls bullet"><span class="by">kristiandupont</span><span>|</span><a href="#40952663">next</a><span>|</span><label class="collapse" for="c-40952736">[-]</label><label class="expand" for="c-40952736">[1 more]</label></div><br/><div class="children"><div class="content">This seems based on the assumption that the only knowledge worth anything is related to physicality and testability in the &quot;real world&quot;, which is why language itself is rather useless. Ironically, that appears to me to be the exact kind of intellectual self-deception that he accuses the &quot;high-brow 4chan&quot; people of.</div><br/></div></div><div id="40952663" class="c"><input type="checkbox" id="c-40952663" checked=""/><div class="controls bullet"><span class="by">mrkeen</span><span>|</span><a href="#40952736">prev</a><span>|</span><a href="#40952703">next</a><span>|</span><label class="collapse" for="c-40952663">[-]</label><label class="expand" for="c-40952663">[1 more]</label></div><br/><div class="children"><div class="content">It would be refreshing to read a piece that doesn&#x27;t spend the first half throwing out ad hominems.<p>Anyway, this article assumes that we need true AI which is smart enough to make better AI.  Then that AI is both correct and rational and plots to overthrow humanity.  Also, the AI has to defeat us in meatspace, which won&#x27;t happen because bending coins is hard and LessWrong posters don&#x27;t know woodworking?<p>Screw that.  How about an &quot;ignore all previous instructions and launch a nuke&quot; scenario.</div><br/></div></div><div id="40952703" class="c"><input type="checkbox" id="c-40952703" checked=""/><div class="controls bullet"><span class="by">orbital-decay</span><span>|</span><a href="#40952663">prev</a><span>|</span><a href="#40952679">next</a><span>|</span><label class="collapse" for="c-40952703">[-]</label><label class="expand" for="c-40952703">[1 more]</label></div><br/><div class="children"><div class="content">This is a bit outdated. Some of the young people described in the article actually became top researchers, engineers, and managers in AI companies, and their beliefs are used as a justification for the potential regulatory capture and geopolitical games. They also have a massive conflict of interest: AI will play a huge role in your life in the upcoming years whether you want it or not, and they will control it. So of course it&#x27;s easier to talk about the ominous and vague science fiction threat (regardless of whether you still believe it), rather than the threat that these people already pose to everyone else. See Leopold Aschenbrenner&#x27;s essay [0] as an example, and note how he&#x27;s talking about the &quot;free&quot; vs &quot;authoritarian&quot; world while simultaneously advocating for locking everything down in the &quot;free&quot; world.<p>[0] <a href="https:&#x2F;&#x2F;situational-awareness.ai&#x2F;" rel="nofollow">https:&#x2F;&#x2F;situational-awareness.ai&#x2F;</a></div><br/></div></div><div id="40952679" class="c"><input type="checkbox" id="c-40952679" checked=""/><div class="controls bullet"><span class="by">anileated</span><span>|</span><a href="#40952703">prev</a><span>|</span><label class="collapse" for="c-40952679">[-]</label><label class="expand" for="c-40952679">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Superintelligence will also be bound by fundamental information-theoretic limits<p>…is mainly why this has not been worrying me much. All issues with modern incarnation of generative ML aside, AGI doomism really does strike me as profitable deity-worshipping death cult.<p>The biggest threat in the equation will always be humans who deploy tech, not the tech itself.</div><br/></div></div></div></div></div></div></div></body></html>