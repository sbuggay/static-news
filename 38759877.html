<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1703494858722" as="style"/><link rel="stylesheet" href="styles.css?v=1703494858722"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a>Ask HN: How do I train a custom LLM/ChatGPT on my own documents in Dec 2023?</a> </div><div class="subtext"><span>divan</span> | <span>51 comments</span></div><br/><div><div id="38760098" class="c"><input type="checkbox" id="c-38760098" checked=""/><div class="controls bullet"><span class="by">ilaksh</span><span>|</span><a href="#38760081">next</a><span>|</span><label class="collapse" for="c-38760098">[-]</label><label class="expand" for="c-38760098">[16 more]</label></div><br/><div class="children"><div class="content">You don&#x27;t train on documents. There are many startups claiming that but they are deliberately using a misleading term because they know that&#x27;s what people are searching for.<p>You still do RAG. Llamaindex is still the best option that I know of. Most of the startups that have working products are likely using llamaindex. All of the ones that say they are training on documents are actually using RAG.<p>Test it out. If it really and truly doesn&#x27;t work, search for a script that creates question and answer pairs automatically with gpt-4. Then try using that for qLoRA. I have never heard of anyone successfully using that for a private document knowledgebase though. Only for skills like math, reasoning, Python, etc. I think the issue is that you need a LOT of data and it needs to repeat concepts or any facts you need to learn many, many times in different supporting ways.<p>What absolutely does not work is trying to just feed a set of documents into fine tuning. I personally have proven that dozens of times because I had a client who is determined to do it. He has been mislead.<p>What it will do is learn the patterns that are in those documents.</div><br/><div id="38760752" class="c"><input type="checkbox" id="c-38760752" checked=""/><div class="controls bullet"><span class="by">sroecker</span><span>|</span><a href="#38760098">parent</a><span>|</span><a href="#38760251">next</a><span>|</span><label class="collapse" for="c-38760752">[-]</label><label class="expand" for="c-38760752">[1 more]</label></div><br/><div class="children"><div class="content">We just held a workshop about this a few weeks ago: <a href="https:&#x2F;&#x2F;red.ht&#x2F;llmappdev" rel="nofollow noreferrer">https:&#x2F;&#x2F;red.ht&#x2F;llmappdev</a>
We created a simple chatbot using local models with Ollama (llamacpp), LlamaIndex and streamlit.
Have a look at the streamlit folder, it&#x27;s super easy.<p>I used this simple example to teach about RAG, the importance of the system prompt and prompt injection.
The notebook folder has a few more examples, local models can even do natural language SQL querying now.</div><br/></div></div><div id="38760251" class="c"><input type="checkbox" id="c-38760251" checked=""/><div class="controls bullet"><span class="by">seedless-sensat</span><span>|</span><a href="#38760098">parent</a><span>|</span><a href="#38760752">prev</a><span>|</span><a href="#38760189">next</a><span>|</span><label class="collapse" for="c-38760251">[-]</label><label class="expand" for="c-38760251">[4 more]</label></div><br/><div class="children"><div class="content">What is RAG? That&#x27;s hard to search for</div><br/><div id="38760949" class="c"><input type="checkbox" id="c-38760949" checked=""/><div class="controls bullet"><span class="by">nmstoker</span><span>|</span><a href="#38760098">root</a><span>|</span><a href="#38760251">parent</a><span>|</span><a href="#38760512">next</a><span>|</span><label class="collapse" for="c-38760949">[-]</label><label class="expand" for="c-38760949">[1 more]</label></div><br/><div class="children"><div class="content">Seems fairly easy to search for to me - top results are all relevant:<p><a href="https:&#x2F;&#x2F;kagi.com&#x2F;search?q=ml+rag" rel="nofollow noreferrer">https:&#x2F;&#x2F;kagi.com&#x2F;search?q=ml+rag</a><p><a href="https:&#x2F;&#x2F;www.google.com&#x2F;search?q=ml+rag" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.google.com&#x2F;search?q=ml+rag</a></div><br/></div></div><div id="38760512" class="c"><input type="checkbox" id="c-38760512" checked=""/><div class="controls bullet"><span class="by">rjzzleep</span><span>|</span><a href="#38760098">root</a><span>|</span><a href="#38760251">parent</a><span>|</span><a href="#38760949">prev</a><span>|</span><a href="#38760260">next</a><span>|</span><label class="collapse" for="c-38760512">[-]</label><label class="expand" for="c-38760512">[1 more]</label></div><br/><div class="children"><div class="content">This one seems like a good summary<p>Retrieval-Augmented Generation for Large Language Models: A Survey<p><a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2312.10997" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2312.10997</a><p>The photos of this post are also good for a high level look<p><a href="https:&#x2F;&#x2F;twitter.com&#x2F;dotey&#x2F;status&#x2F;1738400607336120573&#x2F;photo&#x2F;2" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;dotey&#x2F;status&#x2F;1738400607336120573&#x2F;photo&#x2F;2</a><p>From the various posts I have seen people claim that phi-2 is a good model to start off from.<p>If you just want to do embeddings, there are various tutorials to use pgvector for that.</div><br/></div></div><div id="38760260" class="c"><input type="checkbox" id="c-38760260" checked=""/><div class="controls bullet"><span class="by">accrual</span><span>|</span><a href="#38760098">root</a><span>|</span><a href="#38760251">parent</a><span>|</span><a href="#38760512">prev</a><span>|</span><a href="#38760189">next</a><span>|</span><label class="collapse" for="c-38760260">[-]</label><label class="expand" for="c-38760260">[1 more]</label></div><br/><div class="children"><div class="content">Retrieval-augmented generation, RAG + LLM will turn up more results.</div><br/></div></div></div></div><div id="38760189" class="c"><input type="checkbox" id="c-38760189" checked=""/><div class="controls bullet"><span class="by">benjaminwootton</span><span>|</span><a href="#38760098">parent</a><span>|</span><a href="#38760251">prev</a><span>|</span><a href="#38760126">next</a><span>|</span><label class="collapse" for="c-38760189">[-]</label><label class="expand" for="c-38760189">[3 more]</label></div><br/><div class="children"><div class="content">To sing the praises of Bedrock again, it does have continuous pre-training as well as RAG “knowledge bases”.  The former is based on JSON fragments and the RAG stuff is PDFs and other document formats.<p>With regards to its efficacy, I haven’t gone to production with it yet but I was reasonably impressed.<p>I uploaded 100 legal case documents to Bedrock via Claude and could push it pretty hard asking about the various cases and for situations across the knowledge base.<p>It did feel like it broke down and got confused at a certain point of complexity of questioning, but I still think it’s already useful as a “copilot” or search engine and surely it will only improve over time.</div><br/><div id="38760632" class="c"><input type="checkbox" id="c-38760632" checked=""/><div class="controls bullet"><span class="by">ilaksh</span><span>|</span><a href="#38760098">root</a><span>|</span><a href="#38760189">parent</a><span>|</span><a href="#38760126">next</a><span>|</span><label class="collapse" for="c-38760632">[-]</label><label class="expand" for="c-38760632">[2 more]</label></div><br/><div class="children"><div class="content">I forgot about the continuous pre-training thing. How long and how much did they cost on Bedrock?<p>I had tried to suggest continuous pre-training to my client but it seemed expensive and when I mentioned that  he lost interest and just kept wanting me to do fine tuning.<p>Also to clarify, did you do the continuous pre-training or RAG? And did you compare the efficacy of one or the other or both?</div><br/><div id="38760652" class="c"><input type="checkbox" id="c-38760652" checked=""/><div class="controls bullet"><span class="by">benjaminwootton</span><span>|</span><a href="#38760098">root</a><span>|</span><a href="#38760632">parent</a><span>|</span><a href="#38760126">next</a><span>|</span><label class="collapse" for="c-38760652">[-]</label><label class="expand" for="c-38760652">[1 more]</label></div><br/><div class="children"><div class="content">I used the RAG knowledge bases for most of my testing described above.<p>I got a toy demo up and running with continuous pre-training but haven’t evaluated it unfortunately.</div><br/></div></div></div></div></div></div><div id="38760126" class="c"><input type="checkbox" id="c-38760126" checked=""/><div class="controls bullet"><span class="by">dfhg</span><span>|</span><a href="#38760098">parent</a><span>|</span><a href="#38760189">prev</a><span>|</span><a href="#38760121">next</a><span>|</span><label class="collapse" for="c-38760126">[-]</label><label class="expand" for="c-38760126">[3 more]</label></div><br/><div class="children"><div class="content">Another question, which one is preferred, LlamaIndex or Langchain, for RAG? Thanks in advance for your insights.</div><br/><div id="38760430" class="c"><input type="checkbox" id="c-38760430" checked=""/><div class="controls bullet"><span class="by">isoprophlex</span><span>|</span><a href="#38760098">root</a><span>|</span><a href="#38760126">parent</a><span>|</span><a href="#38760444">next</a><span>|</span><label class="collapse" for="c-38760430">[-]</label><label class="expand" for="c-38760430">[1 more]</label></div><br/><div class="children"><div class="content">You basically don&#x27;t use langchain for anything besides 30 minute demos that you copied from someone else&#x27;s github. It has a completely spaghettified API, is not performant, and forces you into excessive mental contortions to reason about otherwise simple tasks.<p>LlamaIndex is pretty good.</div><br/></div></div><div id="38760444" class="c"><input type="checkbox" id="c-38760444" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#38760098">root</a><span>|</span><a href="#38760126">parent</a><span>|</span><a href="#38760430">prev</a><span>|</span><a href="#38760121">next</a><span>|</span><label class="collapse" for="c-38760444">[-]</label><label class="expand" for="c-38760444">[1 more]</label></div><br/><div class="children"><div class="content">LlamaIndex is mainly focused on RAG. LangChain does a ton of other stuff too. I&#x27;d focus on LlamaIndex first.</div><br/></div></div></div></div><div id="38760121" class="c"><input type="checkbox" id="c-38760121" checked=""/><div class="controls bullet"><span class="by">dfhg</span><span>|</span><a href="#38760098">parent</a><span>|</span><a href="#38760126">prev</a><span>|</span><a href="#38760142">next</a><span>|</span><label class="collapse" for="c-38760121">[-]</label><label class="expand" for="c-38760121">[3 more]</label></div><br/><div class="children"><div class="content">Are there public examples of working products using RAG, compared with fine-tuning or training from scratch?</div><br/><div id="38760393" class="c"><input type="checkbox" id="c-38760393" checked=""/><div class="controls bullet"><span class="by">tinco</span><span>|</span><a href="#38760098">root</a><span>|</span><a href="#38760121">parent</a><span>|</span><a href="#38760282">next</a><span>|</span><label class="collapse" for="c-38760393">[-]</label><label class="expand" for="c-38760393">[1 more]</label></div><br/><div class="children"><div class="content">The OpenAI assistants API is an implementation of a RAG pipeline. It performs both RAG on any documents you upload, and on any conversation you have with it that exceeds the context.</div><br/></div></div><div id="38760282" class="c"><input type="checkbox" id="c-38760282" checked=""/><div class="controls bullet"><span class="by">c0pium</span><span>|</span><a href="#38760098">root</a><span>|</span><a href="#38760121">parent</a><span>|</span><a href="#38760393">prev</a><span>|</span><a href="#38760142">next</a><span>|</span><label class="collapse" for="c-38760282">[-]</label><label class="expand" for="c-38760282">[1 more]</label></div><br/><div class="children"><div class="content">Copilots use RAG:<p><a href="https:&#x2F;&#x2F;www.microsoft.com&#x2F;en-us&#x2F;research&#x2F;group&#x2F;dynamics-insights-apps-artificial-intelligence-machine-learning&#x2F;articles&#x2F;prompt-engineering-improving-our-ability-to-communicate-with-an-llm&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.microsoft.com&#x2F;en-us&#x2F;research&#x2F;group&#x2F;dynamics-insi...</a></div><br/></div></div></div></div><div id="38760142" class="c"><input type="checkbox" id="c-38760142" checked=""/><div class="controls bullet"><span class="by">min76</span><span>|</span><a href="#38760098">parent</a><span>|</span><a href="#38760121">prev</a><span>|</span><a href="#38760081">next</a><span>|</span><label class="collapse" for="c-38760142">[-]</label><label class="expand" for="c-38760142">[1 more]</label></div><br/><div class="children"><div class="content">Well said.
The problem is, there are way too many alternatives. Any idea how llamaindex&#x27;s ingestion engine compares to unstructured.io? ( Which is used in langchain)</div><br/></div></div></div></div><div id="38760081" class="c"><input type="checkbox" id="c-38760081" checked=""/><div class="controls bullet"><span class="by">benjaminwootton</span><span>|</span><a href="#38760098">prev</a><span>|</span><a href="#38760807">next</a><span>|</span><label class="collapse" for="c-38760081">[-]</label><label class="expand" for="c-38760081">[6 more]</label></div><br/><div class="children"><div class="content">AWS Bedrock is fairly easy.  You can do it in 5 or 6 clicks.<p>You have to upload your documents to S3, create a “Knowledge Base” then sync your documents into a vector database like OpenSearch or PineCone.  You are then good to go via their playground or the AWS API.<p>I made a video here describing the process, check around 14 minutes in:<p><a href="https:&#x2F;&#x2F;ensembleanalytics.io&#x2F;blog&#x2F;introducing-bedrock-knowledge-bases" rel="nofollow noreferrer">https:&#x2F;&#x2F;ensembleanalytics.io&#x2F;blog&#x2F;introducing-bedrock-knowle...</a><p>Bedrock is a decent product I think.  All of the models in one place (apart from the big dogs from OpenAI) and a common API across them.</div><br/><div id="38760325" class="c"><input type="checkbox" id="c-38760325" checked=""/><div class="controls bullet"><span class="by">hrdwdmrbl</span><span>|</span><a href="#38760081">parent</a><span>|</span><a href="#38760807">next</a><span>|</span><label class="collapse" for="c-38760325">[-]</label><label class="expand" for="c-38760325">[5 more]</label></div><br/><div class="children"><div class="content">Is there a limit? Could I create a knowledge base with 10,000 documents? 100k? 1M?</div><br/><div id="38760370" class="c"><input type="checkbox" id="c-38760370" checked=""/><div class="controls bullet"><span class="by">benjaminwootton</span><span>|</span><a href="#38760081">root</a><span>|</span><a href="#38760325">parent</a><span>|</span><a href="#38760351">next</a><span>|</span><label class="collapse" for="c-38760370">[-]</label><label class="expand" for="c-38760370">[1 more]</label></div><br/><div class="children"><div class="content">The documents are encoded as vectors and stored in a database, so I suspect it would be effectively unlimited.  You would just pay for storage and compute.<p>AWS OpenSearch has fairly good integration so you could look up costs for that.  It’s not the cheapest AWS service to run and not exactly serverless as you pay by the hour.</div><br/></div></div><div id="38760351" class="c"><input type="checkbox" id="c-38760351" checked=""/><div class="controls bullet"><span class="by">8organicbits</span><span>|</span><a href="#38760081">root</a><span>|</span><a href="#38760325">parent</a><span>|</span><a href="#38760370">prev</a><span>|</span><a href="#38760807">next</a><span>|</span><label class="collapse" for="c-38760351">[-]</label><label class="expand" for="c-38760351">[3 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;bedrock&#x2F;latest&#x2F;userguide&#x2F;quotas.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;bedrock&#x2F;latest&#x2F;userguide&#x2F;quotas....</a></div><br/><div id="38760357" class="c"><input type="checkbox" id="c-38760357" checked=""/><div class="controls bullet"><span class="by">hrdwdmrbl</span><span>|</span><a href="#38760081">root</a><span>|</span><a href="#38760351">parent</a><span>|</span><a href="#38760807">next</a><span>|</span><label class="collapse" for="c-38760357">[-]</label><label class="expand" for="c-38760357">[2 more]</label></div><br/><div class="children"><div class="content">I’m sorry, I don’t understand those limits. It uses a lot of unfamiliar terms like “batch inference” and “modality”. I just want a nice UI that I can give my hard-drive to and then ask it questions.</div><br/></div></div></div></div></div></div></div></div><div id="38760807" class="c"><input type="checkbox" id="c-38760807" checked=""/><div class="controls bullet"><span class="by">ukuina</span><span>|</span><a href="#38760081">prev</a><span>|</span><a href="#38760083">next</a><span>|</span><label class="collapse" for="c-38760807">[-]</label><label class="expand" for="c-38760807">[1 more]</label></div><br/><div class="children"><div class="content">PrivateGPT is one of the better-known examples, but most people are not aware that GPT4 Assistants handle RAG natively now: <a href="https:&#x2F;&#x2F;platform.openai.com&#x2F;docs&#x2F;assistants&#x2F;overview" rel="nofollow noreferrer">https:&#x2F;&#x2F;platform.openai.com&#x2F;docs&#x2F;assistants&#x2F;overview</a></div><br/></div></div><div id="38760083" class="c"><input type="checkbox" id="c-38760083" checked=""/><div class="controls bullet"><span class="by">lolinder</span><span>|</span><a href="#38760807">prev</a><span>|</span><a href="#38760719">next</a><span>|</span><label class="collapse" for="c-38760083">[-]</label><label class="expand" for="c-38760083">[3 more]</label></div><br/><div class="children"><div class="content">I haven&#x27;t personally tried this for anything serious yet, but to get the thread started:<p>Cheshire Cat [0] looks promising. It&#x27;s a framework for building AI assistants by providing it with documents that it stores as &quot;memories&quot; that can be retrieved later. I&#x27;m not sure how well it works yet, but it has an active community on Discord and seems to be developing rapidly.<p>The main perk over the cloud options is that you can point it at any language model, including fully local—my local install pointed at my local Ollama running Mistral.<p>[0] <a href="https:&#x2F;&#x2F;github.com&#x2F;cheshire-cat-ai&#x2F;core">https:&#x2F;&#x2F;github.com&#x2F;cheshire-cat-ai&#x2F;core</a></div><br/><div id="38760116" class="c"><input type="checkbox" id="c-38760116" checked=""/><div class="controls bullet"><span class="by">ilaksh</span><span>|</span><a href="#38760083">parent</a><span>|</span><a href="#38760719">next</a><span>|</span><label class="collapse" for="c-38760116">[-]</label><label class="expand" for="c-38760116">[2 more]</label></div><br/><div class="children"><div class="content">But that&#x27;s not training. That&#x27;s RAG. They seem to be using qdrant which I believe is a vector store.</div><br/><div id="38760335" class="c"><input type="checkbox" id="c-38760335" checked=""/><div class="controls bullet"><span class="by">lolinder</span><span>|</span><a href="#38760083">root</a><span>|</span><a href="#38760116">parent</a><span>|</span><a href="#38760719">next</a><span>|</span><label class="collapse" for="c-38760335">[-]</label><label class="expand" for="c-38760335">[1 more]</label></div><br/><div class="children"><div class="content">They&#x27;ve updated the question to clarify that RAG counts, and as many have noted, properly &quot;training&quot; on a set of documents isn&#x27;t really a thing.</div><br/></div></div></div></div></div></div><div id="38760719" class="c"><input type="checkbox" id="c-38760719" checked=""/><div class="controls bullet"><span class="by">liampulles</span><span>|</span><a href="#38760083">prev</a><span>|</span><a href="#38760898">next</a><span>|</span><label class="collapse" for="c-38760719">[-]</label><label class="expand" for="c-38760719">[1 more]</label></div><br/><div class="children"><div class="content">What is your usecase? If you want to search for relevant info in your documents and get relevant info, and you want to avoid hallucination, you might avoid the text generation altogether.<p>Instead you can extract text embeddings from your documents, put them in a vector DB, and then you have a super search. You can convert your search query to an embedding, search the DB and keep the e.g. 10 closest matches.</div><br/></div></div><div id="38760898" class="c"><input type="checkbox" id="c-38760898" checked=""/><div class="controls bullet"><span class="by">yu3zhou4</span><span>|</span><a href="#38760719">prev</a><span>|</span><a href="#38760275">next</a><span>|</span><label class="collapse" for="c-38760898">[-]</label><label class="expand" for="c-38760898">[3 more]</label></div><br/><div class="children"><div class="content">And what’s the correct answer in December 2023 if one wants to narrow down only to tools and services provided on Azure?</div><br/><div id="38760926" class="c"><input type="checkbox" id="c-38760926" checked=""/><div class="controls bullet"><span class="by">yu3zhou4</span><span>|</span><a href="#38760898">parent</a><span>|</span><a href="#38760275">next</a><span>|</span><label class="collapse" for="c-38760926">[-]</label><label class="expand" for="c-38760926">[2 more]</label></div><br/><div class="children"><div class="content">Is Llamaindex + hosted model on Azure OpenAI Services still the best option?</div><br/><div id="38760946" class="c"><input type="checkbox" id="c-38760946" checked=""/><div class="controls bullet"><span class="by">isoprophlex</span><span>|</span><a href="#38760898">root</a><span>|</span><a href="#38760926">parent</a><span>|</span><a href="#38760275">next</a><span>|</span><label class="collapse" for="c-38760946">[-]</label><label class="expand" for="c-38760946">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s Azure AI studio which is kinda like AWS bedrock. It&#x27;s not bad, but for max control and versatility i&#x27;d start out rolling my own w&#x2F; for example llamaindex+azure-branded openai like you say.</div><br/></div></div></div></div></div></div><div id="38760275" class="c"><input type="checkbox" id="c-38760275" checked=""/><div class="controls bullet"><span class="by">kmkarim</span><span>|</span><a href="#38760898">prev</a><span>|</span><a href="#38760794">next</a><span>|</span><label class="collapse" for="c-38760275">[-]</label><label class="expand" for="c-38760275">[5 more]</label></div><br/><div class="children"><div class="content">Slightly off topic but is there recommended advice on how to tune &#x2F; train not for document retrieval but for consistent JSON output with specific enums?<p>i.e given a text, always return back a certain set of fields. For some keys here is the possible set of enums etc. One shot prompting does work but curious how others approach this if you have training data on hand.</div><br/><div id="38760434" class="c"><input type="checkbox" id="c-38760434" checked=""/><div class="controls bullet"><span class="by">Hugsun</span><span>|</span><a href="#38760275">parent</a><span>|</span><a href="#38760388">next</a><span>|</span><label class="collapse" for="c-38760434">[-]</label><label class="expand" for="c-38760434">[1 more]</label></div><br/><div class="children"><div class="content">There are many interesting tools that achieve this, like Outlines[0] and jsonformer[1].
I haven&#x27;t tried them myself but they look very promising.<p>[0]: <a href="https:&#x2F;&#x2F;github.com&#x2F;outlines-dev&#x2F;outlines">https:&#x2F;&#x2F;github.com&#x2F;outlines-dev&#x2F;outlines</a>
[1]: <a href="https:&#x2F;&#x2F;github.com&#x2F;1rgs&#x2F;jsonformer">https:&#x2F;&#x2F;github.com&#x2F;1rgs&#x2F;jsonformer</a></div><br/></div></div><div id="38760388" class="c"><input type="checkbox" id="c-38760388" checked=""/><div class="controls bullet"><span class="by">techn00</span><span>|</span><a href="#38760275">parent</a><span>|</span><a href="#38760434">prev</a><span>|</span><a href="#38760797">next</a><span>|</span><label class="collapse" for="c-38760388">[-]</label><label class="expand" for="c-38760388">[1 more]</label></div><br/><div class="children"><div class="content">You want grammars to restrict the output, search for &quot;gbnf grammar&quot;. That and combined with a good prompt with an example, also check out outlines.dev</div><br/></div></div><div id="38760797" class="c"><input type="checkbox" id="c-38760797" checked=""/><div class="controls bullet"><span class="by">ukuina</span><span>|</span><a href="#38760275">parent</a><span>|</span><a href="#38760388">prev</a><span>|</span><a href="#38760453">next</a><span>|</span><label class="collapse" for="c-38760797">[-]</label><label class="expand" for="c-38760797">[1 more]</label></div><br/><div class="children"><div class="content">Microsoft Guidance will do this.</div><br/></div></div><div id="38760453" class="c"><input type="checkbox" id="c-38760453" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#38760275">parent</a><span>|</span><a href="#38760797">prev</a><span>|</span><a href="#38760794">next</a><span>|</span><label class="collapse" for="c-38760453">[-]</label><label class="expand" for="c-38760453">[1 more]</label></div><br/><div class="children"><div class="content">For OpenAI, use their functions schema mechanism.<p>Aside from that, take a look at llama.cpp grammars.</div><br/></div></div></div></div><div id="38760794" class="c"><input type="checkbox" id="c-38760794" checked=""/><div class="controls bullet"><span class="by">viraptor</span><span>|</span><a href="#38760275">prev</a><span>|</span><a href="#38760415">next</a><span>|</span><label class="collapse" for="c-38760794">[-]</label><label class="expand" for="c-38760794">[1 more]</label></div><br/><div class="children"><div class="content">So far the recommendations are mostly hosted, so here&#x27;s one local: <a href="https:&#x2F;&#x2F;github.com&#x2F;weaviate&#x2F;Verba">https:&#x2F;&#x2F;github.com&#x2F;weaviate&#x2F;Verba</a><p>I&#x27;m very happy with its results, even though the system is still young and a little bit janky. You can use it with either GPT API, or your local models through LiteLlm. (I&#x27;m running ollama + dolphin-mixtral)</div><br/></div></div><div id="38760415" class="c"><input type="checkbox" id="c-38760415" checked=""/><div class="controls bullet"><span class="by">sophiebits</span><span>|</span><a href="#38760794">prev</a><span>|</span><a href="#38760618">next</a><span>|</span><label class="collapse" for="c-38760415">[-]</label><label class="expand" for="c-38760415">[1 more]</label></div><br/><div class="children"><div class="content">If you’re looking for something that is hosted for you, at Notion we launched a feature for this a few weeks ago and it works quite well in my experience. RAG is one of the techniques used. <a href="https:&#x2F;&#x2F;www.notion.so&#x2F;blog&#x2F;introducing-q-and-a" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.notion.so&#x2F;blog&#x2F;introducing-q-and-a</a></div><br/></div></div><div id="38760618" class="c"><input type="checkbox" id="c-38760618" checked=""/><div class="controls bullet"><span class="by">iAkashPaul</span><span>|</span><a href="#38760415">prev</a><span>|</span><a href="#38760920">next</a><span>|</span><label class="collapse" for="c-38760618">[-]</label><label class="expand" for="c-38760618">[1 more]</label></div><br/><div class="children"><div class="content">A go-to method is to ingest different chunksizes based on the document hierarchy &amp; then use langchain with a bunch of retrievers depending on the doc type.<p>Then create an index about the metadata of each doc. So that you can ask the RAGbot what all it can answer about.<p>Another way to ensure it stays on-domain is to generate synthetic questions &amp; check for similarity against user queries. There&#x27;s a whole rabbit hole of query decomposition to avoid straying off topic as well.</div><br/></div></div><div id="38760920" class="c"><input type="checkbox" id="c-38760920" checked=""/><div class="controls bullet"><span class="by">GabrieleR</span><span>|</span><a href="#38760618">prev</a><span>|</span><a href="#38760123">next</a><span>|</span><label class="collapse" for="c-38760920">[-]</label><label class="expand" for="c-38760920">[1 more]</label></div><br/><div class="children"><div class="content">Try with private gpt github repo</div><br/></div></div><div id="38760123" class="c"><input type="checkbox" id="c-38760123" checked=""/><div class="controls bullet"><span class="by">xnx</span><span>|</span><a href="#38760920">prev</a><span>|</span><a href="#38760377">next</a><span>|</span><label class="collapse" for="c-38760123">[-]</label><label class="expand" for="c-38760123">[1 more]</label></div><br/><div class="children"><div class="content">GPT-4 Turbo has a 128K (~300 pages) context window, which probably handles a lot of use cases which might have previously needed extra training&#x2F;refinement.</div><br/></div></div><div id="38760377" class="c"><input type="checkbox" id="c-38760377" checked=""/><div class="controls bullet"><span class="by">quickthrower2</span><span>|</span><a href="#38760123">prev</a><span>|</span><a href="#38760543">next</a><span>|</span><label class="collapse" for="c-38760377">[-]</label><label class="expand" for="c-38760377">[1 more]</label></div><br/><div class="children"><div class="content">Easiest is OpenAI assistants api. Use the playground and it’s a no code experience.</div><br/></div></div><div id="38760543" class="c"><input type="checkbox" id="c-38760543" checked=""/><div class="controls bullet"><span class="by">constantinum</span><span>|</span><a href="#38760377">prev</a><span>|</span><a href="#38760676">next</a><span>|</span><label class="collapse" for="c-38760543">[-]</label><label class="expand" for="c-38760543">[1 more]</label></div><br/><div class="children"><div class="content">Unstract - <a href="https:&#x2F;&#x2F;unstract.com&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;unstract.com&#x2F;</a>
They are a month away from launch(both open source and cloud)
The team might be able to give you a quick demo on your specific requirements.</div><br/></div></div><div id="38760676" class="c"><input type="checkbox" id="c-38760676" checked=""/><div class="controls bullet"><span class="by">csbartus</span><span>|</span><a href="#38760543">prev</a><span>|</span><a href="#38760346">next</a><span>|</span><label class="collapse" for="c-38760676">[-]</label><label class="expand" for="c-38760676">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;khoj.dev&#x2F;">https:&#x2F;&#x2F;khoj.dev&#x2F;</a><p>Tried this summer, and kinda worked!</div><br/></div></div><div id="38760346" class="c"><input type="checkbox" id="c-38760346" checked=""/><div class="controls bullet"><span class="by">jrpt</span><span>|</span><a href="#38760676">prev</a><span>|</span><a href="#38760065">next</a><span>|</span><label class="collapse" for="c-38760346">[-]</label><label class="expand" for="c-38760346">[1 more]</label></div><br/><div class="children"><div class="content">What are you trying to do more specifically? You can use <a href="https:&#x2F;&#x2F;docalysis.com&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;docalysis.com&#x2F;</a> for most document RAG tasks.</div><br/></div></div><div id="38760112" class="c"><input type="checkbox" id="c-38760112" checked=""/><div class="controls bullet"><span class="by">galacticaactual</span><span>|</span><a href="#38760065">prev</a><span>|</span><a href="#38760226">next</a><span>|</span><label class="collapse" for="c-38760112">[-]</label><label class="expand" for="c-38760112">[4 more]</label></div><br/><div class="children"><div class="content">Train on your own documents or analyze your own documents for answers? Very different things.<p>For the first (fine tuning) follow “AI Jason” on YouTube. He has some great tutorials.<p>For the second (RAG or similar), fire up a cloud VM with GPUs or use Ollama locally and read through the LlamaIndex docs on how to build a RAG pipeline.</div><br/><div id="38760132" class="c"><input type="checkbox" id="c-38760132" checked=""/><div class="controls bullet"><span class="by">dfhg</span><span>|</span><a href="#38760112">parent</a><span>|</span><a href="#38760226">next</a><span>|</span><label class="collapse" for="c-38760132">[-]</label><label class="expand" for="c-38760132">[3 more]</label></div><br/><div class="children"><div class="content">Would you kindly elaborate a little bit the difference between training on own documents vs analyzing documents for answers?</div><br/><div id="38760466" class="c"><input type="checkbox" id="c-38760466" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#38760112">root</a><span>|</span><a href="#38760132">parent</a><span>|</span><a href="#38760226">next</a><span>|</span><label class="collapse" for="c-38760466">[-]</label><label class="expand" for="c-38760466">[2 more]</label></div><br/><div class="children"><div class="content">The word &quot;training&quot; implies creating a new model by fine-tuning an existing model on top of new documents.<p>As several other comments in this thread have already indicated: this is almost always the wrong direction. Which is confusing because it&#x27;s the direction everyone always assumes they should go in at first.<p>The approaches that does work is surprisingly simple: take the user&#x27;s question, search for snippets of your documents that appear to be about that question, then paste all of those snippets into the prompt along with the user&#x27;s question and see what answer you get.<p>This is known as RAG: Retrieval Augmented Generation. It&#x27;s a very powerful approach.</div><br/><div id="38760882" class="c"><input type="checkbox" id="c-38760882" checked=""/><div class="controls bullet"><span class="by">codetrotter</span><span>|</span><a href="#38760112">root</a><span>|</span><a href="#38760466">parent</a><span>|</span><a href="#38760226">next</a><span>|</span><label class="collapse" for="c-38760882">[-]</label><label class="expand" for="c-38760882">[1 more]</label></div><br/><div class="children"><div class="content">&gt; take the user&#x27;s question, search for snippets of your documents that appear to be about that question, then paste all of those snippets into the prompt along with the user&#x27;s question and see what answer you get.<p>We use RAG at my job, but we don’t do any preprocessing on the message from the user, so the results are not always great for us.<p>Do any of you have experience using a small local model just for extracting keywords from messages which you then use for the retrieval? And then feed the search result and your prompt into OpenAI or whatever as normal.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></body></html>