<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1729674074069" as="style"/><link rel="stylesheet" href="styles.css?v=1729674074069"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://clickhouse.com/blog/a-new-powerful-json-data-type-for-clickhouse">A new JSON data type for ClickHouse</a> <span class="domain">(<a href="https://clickhouse.com">clickhouse.com</a>)</span></div><div class="subtext"><span>markhneedham</span> | <span>66 comments</span></div><br/><div><div id="41916513" class="c"><input type="checkbox" id="c-41916513" checked=""/><div class="controls bullet"><span class="by">ramraj07</span><span>|</span><a href="#41917686">next</a><span>|</span><label class="collapse" for="c-41916513">[-]</label><label class="expand" for="c-41916513">[5 more]</label></div><br/><div class="children"><div class="content">Great to see it in ClickHouse.<p>Snowflake released a white paper before its IPO days and mentioned this same feature (secretly exploding JSON into columns). Explains how snowflake feels faster than it should, they’ve secretly done a lot of amazing things and just offered it as a polished product like Apple.</div><br/><div id="41921821" class="c"><input type="checkbox" id="c-41921821" checked=""/><div class="controls bullet"><span class="by">leetrout</span><span>|</span><a href="#41916513">parent</a><span>|</span><a href="#41921240">next</a><span>|</span><label class="collapse" for="c-41921821">[-]</label><label class="expand" for="c-41921821">[1 more]</label></div><br/><div class="children"><div class="content">Scratch data does this as well with duckdb<p><a href="https:&#x2F;&#x2F;github.com&#x2F;scratchdata&#x2F;scratchdata">https:&#x2F;&#x2F;github.com&#x2F;scratchdata&#x2F;scratchdata</a></div><br/></div></div><div id="41921240" class="c"><input type="checkbox" id="c-41921240" checked=""/><div class="controls bullet"><span class="by">statictype</span><span>|</span><a href="#41916513">parent</a><span>|</span><a href="#41921821">prev</a><span>|</span><a href="#41921925">next</a><span>|</span><label class="collapse" for="c-41921240">[-]</label><label class="expand" for="c-41921240">[2 more]</label></div><br/><div class="children"><div class="content">Do you have a link to the Snowflake whitepaper?</div><br/><div id="41923174" class="c"><input type="checkbox" id="c-41923174" checked=""/><div class="controls bullet"><span class="by">JosephRedfern</span><span>|</span><a href="#41916513">root</a><span>|</span><a href="#41921240">parent</a><span>|</span><a href="#41921925">next</a><span>|</span><label class="collapse" for="c-41923174">[-]</label><label class="expand" for="c-41923174">[1 more]</label></div><br/><div class="children"><div class="content">Perhaps this: <a href="https:&#x2F;&#x2F;event.cwi.nl&#x2F;lsde&#x2F;papers&#x2F;p215-dageville-snowflake.pdf" rel="nofollow">https:&#x2F;&#x2F;event.cwi.nl&#x2F;lsde&#x2F;papers&#x2F;p215-dageville-snowflake.pd...</a></div><br/></div></div></div></div><div id="41921925" class="c"><input type="checkbox" id="c-41921925" checked=""/><div class="controls bullet"><span class="by">nojvek</span><span>|</span><a href="#41916513">parent</a><span>|</span><a href="#41921240">prev</a><span>|</span><a href="#41917686">next</a><span>|</span><label class="collapse" for="c-41921925">[-]</label><label class="expand" for="c-41921925">[1 more]</label></div><br/><div class="children"><div class="content">Singlestore has been doing json -&gt; column expansion for a while as well.<p><a href="https:&#x2F;&#x2F;www.singlestore.com&#x2F;blog&#x2F;json-builtins-over-columnstore&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.singlestore.com&#x2F;blog&#x2F;json-builtins-over-columnst...</a><p>For a colstore database, dealing with json as strings is a big perf hit.</div><br/></div></div></div></div><div id="41917686" class="c"><input type="checkbox" id="c-41917686" checked=""/><div class="controls bullet"><span class="by">breadwinner</span><span>|</span><a href="#41916513">prev</a><span>|</span><a href="#41917470">next</a><span>|</span><label class="collapse" for="c-41917686">[-]</label><label class="expand" for="c-41917686">[12 more]</label></div><br/><div class="children"><div class="content">If you&#x27;re evaluating ClickHouse take a look at Apache Pinot as well. ClickHouse was designed for single-machine installations, although it has been enhanced to support clusters. But this support is lacking, for example if you add additional nodes it is not easy to redistribute data. Pinot is much easier to scale horizontally. Also take a look at star-tree indexes of Pinot [1]. If you&#x27;re doing multi-dimensional analysis (Pivot table etc.) there is a huge difference in performance if you take advantage of star-tree.<p>[1] <a href="https:&#x2F;&#x2F;docs.pinot.apache.org&#x2F;basics&#x2F;indexing&#x2F;star-tree-index" rel="nofollow">https:&#x2F;&#x2F;docs.pinot.apache.org&#x2F;basics&#x2F;indexing&#x2F;star-tree-inde...</a></div><br/><div id="41918255" class="c"><input type="checkbox" id="c-41918255" checked=""/><div class="controls bullet"><span class="by">zX41ZdbW</span><span>|</span><a href="#41917686">parent</a><span>|</span><a href="#41919381">next</a><span>|</span><label class="collapse" for="c-41918255">[-]</label><label class="expand" for="c-41918255">[2 more]</label></div><br/><div class="children"><div class="content">&gt; ClickHouse was designed for single-machine installations<p>This is incorrect. ClickHouse is designed for distributed setups from the beginning, including cross-DC installations. It has been used on large production clusters even before it was open-sourced. When it became open-source in June 2016, the largest cluster was 394 machines across 6 data-centers with 25 ms RTT between the most distant data-centers.</div><br/><div id="41922730" class="c"><input type="checkbox" id="c-41922730" checked=""/><div class="controls bullet"><span class="by">justCHurious</span><span>|</span><a href="#41917686">root</a><span>|</span><a href="#41918255">parent</a><span>|</span><a href="#41919381">next</a><span>|</span><label class="collapse" for="c-41922730">[-]</label><label class="expand" for="c-41922730">[1 more]</label></div><br/><div class="children"><div class="content">On a side note, can someone please comment on this part<p>&gt; for example if you add additional nodes it is not easy to redistribute data.<p>This is precisely one of the issues I predict we&#x27;ll face with our cluster as we&#x27;re ramping up OTEL data and it&#x27;s being sent to a small cluster, and I&#x27;m deathly afraid that it will continue sending to the every shard in equal measure without moving around existing data. I can not find any good method of redistributing the load other than &quot;use the third party backup program and pray it doesn&#x27;t shit the bed&quot;.</div><br/></div></div></div></div><div id="41919381" class="c"><input type="checkbox" id="c-41919381" checked=""/><div class="controls bullet"><span class="by">cvalka</span><span>|</span><a href="#41917686">parent</a><span>|</span><a href="#41918255">prev</a><span>|</span><a href="#41917746">next</a><span>|</span><label class="collapse" for="c-41919381">[-]</label><label class="expand" for="c-41919381">[1 more]</label></div><br/><div class="children"><div class="content">Absolutely incorrect. ClickHouse was created by Yandex and it&#x27;s cluster ready from day one.</div><br/></div></div><div id="41917746" class="c"><input type="checkbox" id="c-41917746" checked=""/><div class="controls bullet"><span class="by">haolez</span><span>|</span><a href="#41917686">parent</a><span>|</span><a href="#41919381">prev</a><span>|</span><a href="#41917470">next</a><span>|</span><label class="collapse" for="c-41917746">[-]</label><label class="expand" for="c-41917746">[8 more]</label></div><br/><div class="children"><div class="content">What&#x27;s the use case? Analytics on humongous quantities of data? Something besides that?</div><br/><div id="41917818" class="c"><input type="checkbox" id="c-41917818" checked=""/><div class="controls bullet"><span class="by">breadwinner</span><span>|</span><a href="#41917686">root</a><span>|</span><a href="#41917746">parent</a><span>|</span><a href="#41918238">next</a><span>|</span><label class="collapse" for="c-41917818">[-]</label><label class="expand" for="c-41917818">[6 more]</label></div><br/><div class="children"><div class="content">Use case is &quot;user-facing analytics&quot;, for example consider ordering food from Uber Eats. You have thousands of concurrent users, latency should be in milliseconds, and things like delivery time estimate must updated in real-time.<p>Spark can do analysis on huge quantities of data, and so can Microsoft Fabric. What Pinot can do that those tools can&#x27;t is extremely low latency (milliseconds vs. seconds), concurrency (1000s of queries per second), and ability to update data in real-time.<p>Excellent intro video on Pinot: <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=_lqdfq2c9cQ" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=_lqdfq2c9cQ</a></div><br/><div id="41917944" class="c"><input type="checkbox" id="c-41917944" checked=""/><div class="controls bullet"><span class="by">listenallyall</span><span>|</span><a href="#41917686">root</a><span>|</span><a href="#41917818">parent</a><span>|</span><a href="#41918238">next</a><span>|</span><label class="collapse" for="c-41917944">[-]</label><label class="expand" for="c-41917944">[5 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think Uber&#x27;s estimated time-to-arrival is a statistic on which a database vendor, or development team, should brag about. It&#x27;s horribly imprecise.</div><br/><div id="41918655" class="c"><input type="checkbox" id="c-41918655" checked=""/><div class="controls bullet"><span class="by">akavi</span><span>|</span><a href="#41917686">root</a><span>|</span><a href="#41917944">parent</a><span>|</span><a href="#41919083">next</a><span>|</span><label class="collapse" for="c-41918655">[-]</label><label class="expand" for="c-41918655">[3 more]</label></div><br/><div class="children"><div class="content">Also isn&#x27;t something that a (geo)sharded postgres DB with the appropriate indexes couldn&#x27;t handle with aplomb. Number of orders to a given restaurant can&#x27;t be more than a dozen a minute or so.</div><br/><div id="41920691" class="c"><input type="checkbox" id="c-41920691" checked=""/><div class="controls bullet"><span class="by">SoftTalker</span><span>|</span><a href="#41917686">root</a><span>|</span><a href="#41918655">parent</a><span>|</span><a href="#41919083">next</a><span>|</span><label class="collapse" for="c-41920691">[-]</label><label class="expand" for="c-41920691">[2 more]</label></div><br/><div class="children"><div class="content">Especially as restaurants have a limit on their capacity to prepare food. You can&#x27;t just spin up another instance of a staffed kitchen. Do these mobile-food-ordering apps include any kind of backdown on order acceptance e.g. &quot;Joe&#x27;s Diner is too busy right now, do you want to wait or try someplace else?&quot;</div><br/><div id="41921803" class="c"><input type="checkbox" id="c-41921803" checked=""/><div class="controls bullet"><span class="by">codetrotter</span><span>|</span><a href="#41917686">root</a><span>|</span><a href="#41920691">parent</a><span>|</span><a href="#41919083">next</a><span>|</span><label class="collapse" for="c-41921803">[-]</label><label class="expand" for="c-41921803">[1 more]</label></div><br/><div class="children"><div class="content">Sometimes you’ll also have a situation where your food is prepared quickly but no drivers want to pick up the food for a while.<p>At least it used to be like that a few years ago.<p><a href="https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;UberEATS&#x2F;comments&#x2F;nucd2x&#x2F;no_tip_no_food&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;UberEATS&#x2F;comments&#x2F;nucd2x&#x2F;no_tip_no_...</a><p><a href="https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;UberEATS&#x2F;comments&#x2F;rtn2xe&#x2F;no_tip_no_trip&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;UberEATS&#x2F;comments&#x2F;rtn2xe&#x2F;no_tip_no_...</a><p><a href="https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;UberEATS&#x2F;comments&#x2F;uce6cs&#x2F;orders_sitting_on_the_shelf_when_the_restaurant&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;UberEATS&#x2F;comments&#x2F;uce6cs&#x2F;orders_sit...</a><p><a href="https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;doordash&#x2F;comments&#x2F;17ojre0&#x2F;doordash_themselves_about_tips&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;doordash&#x2F;comments&#x2F;17ojre0&#x2F;doordash_...</a><p><a href="https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;doordash&#x2F;comments&#x2F;np6rik&#x2F;you_have_every_right_to_not_tip_but_just_know&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;doordash&#x2F;comments&#x2F;np6rik&#x2F;you_have_e...</a><p><a href="https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;doordash&#x2F;comments&#x2F;o32nl4&#x2F;no_tip_orders_just_sitting_on_the_shelves&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;doordash&#x2F;comments&#x2F;o32nl4&#x2F;no_tip_ord...</a><p>Don’t know if the situation has improved since.<p>The reason this happens is because Uber Eats and DoorDash and others have&#x2F;had this concept where you’d “tip” for the delivery. Which is actually not a tip, but just a shitty way of disguising delivery fees and putting customers against the people that deliver the food. But that in turn has its background in how the restaurant business treats their workers in the USA, which has been wacky even long before these food delivery apps became a thing.<p>Anyway, regardless of your opinion on “tipping” and these practices the point was to say that there are additional complications with how much time it will take for your order to arrive aside from just the time it takes to prepare the food and the time it takes to travel from the restaurant to your door, even when the food has been prepared and a delivery driver is right there at the restaurant. If the “tip” is too low, or zero, your order could be left sitting on the shelf with nobody willing to pick it up. At least a few years ago it was like that.</div><br/></div></div></div></div></div></div><div id="41919083" class="c"><input type="checkbox" id="c-41919083" checked=""/><div class="controls bullet"><span class="by">cyanydeez</span><span>|</span><a href="#41917686">root</a><span>|</span><a href="#41917944">parent</a><span>|</span><a href="#41918655">prev</a><span>|</span><a href="#41918238">next</a><span>|</span><label class="collapse" for="c-41919083">[-]</label><label class="expand" for="c-41919083">[1 more]</label></div><br/><div class="children"><div class="content">What about it&#x27;s ability to choose pricing based on source-destination and projected incomes.</div><br/></div></div></div></div></div></div><div id="41918238" class="c"><input type="checkbox" id="c-41918238" checked=""/><div class="controls bullet"><span class="by">whalesalad</span><span>|</span><a href="#41917686">root</a><span>|</span><a href="#41917746">parent</a><span>|</span><a href="#41917818">prev</a><span>|</span><a href="#41917470">next</a><span>|</span><label class="collapse" for="c-41918238">[-]</label><label class="expand" for="c-41918238">[1 more]</label></div><br/><div class="children"><div class="content">I thought “humongous quantities of data” was a baseline assumption for a discussion involving clickhouse et all?</div><br/></div></div></div></div></div></div><div id="41917470" class="c"><input type="checkbox" id="c-41917470" checked=""/><div class="controls bullet"><span class="by">everfrustrated</span><span>|</span><a href="#41917686">prev</a><span>|</span><a href="#41914944">next</a><span>|</span><label class="collapse" for="c-41917470">[-]</label><label class="expand" for="c-41917470">[4 more]</label></div><br/><div class="children"><div class="content">&gt;Dynamically changing data: allow values with different data types (possibly incompatible and not known beforehand) for the same JSON paths without unification into a least common type, preserving the integrity of mixed-type data.<p>I&#x27;m so excited for this! One of my major bug-bears with storing logs in Elasticsearch is the set-type-on-first-seen-occurrence headache.<p>Hope to see this leave experimental support soon!</div><br/><div id="41918984" class="c"><input type="checkbox" id="c-41918984" checked=""/><div class="controls bullet"><span class="by">atombender</span><span>|</span><a href="#41917470">parent</a><span>|</span><a href="#41914944">next</a><span>|</span><label class="collapse" for="c-41918984">[-]</label><label class="expand" for="c-41918984">[3 more]</label></div><br/><div class="children"><div class="content">I never understood why ELK&#x2F;Kinana chose this method, when there&#x27;s a much simpler solution: Augment each field name with the data type.<p>For example, consider the documents {&quot;value&quot;: 42} and {&quot;value&quot;: &quot;foo&quot;}. To index this, index {&quot;value::int&quot;: 42} and {&quot;value::str&quot;: &quot;foo&quot;} instead. Now you have two distinct fields that don&#x27;t conflict with each other.<p>To search this, the logical choice would be to first make sure that the query language is typed. So a query like value=42 would know to search the int field, while a query like value=&quot;42&quot; would look in the string field. There&#x27;s never any situation where there&#x27;s any ambiguity about which data type is to be searched. KQL doesn&#x27;t have this, but that&#x27;s one of their many design mistakes.<p>You can do the same for any data type, including arrays and objects. There is absolutely no downside; I&#x27;ve successfully implemented it for a specific project. (OK, one downside: More fields. But the nature of the beast. These are, after all, distinct sets of data.)</div><br/><div id="41919760" class="c"><input type="checkbox" id="c-41919760" checked=""/><div class="controls bullet"><span class="by">mr_toad</span><span>|</span><a href="#41917470">root</a><span>|</span><a href="#41918984">parent</a><span>|</span><a href="#41914944">next</a><span>|</span><label class="collapse" for="c-41919760">[-]</label><label class="expand" for="c-41919760">[2 more]</label></div><br/><div class="children"><div class="content">&gt; For example, consider the documents {&quot;value&quot;: 42} and {&quot;value&quot;: &quot;foo&quot;}. To index this, index {&quot;value::int&quot;: 42} and {&quot;value::str&quot;: &quot;foo&quot;} instead. Now you have two distinct fields that don&#x27;t conflict with each other.<p>But now all my queries that look for “value” don’t work.  And I’ve got two columns in my report where I only want one.</div><br/><div id="41922981" class="c"><input type="checkbox" id="c-41922981" checked=""/><div class="controls bullet"><span class="by">atombender</span><span>|</span><a href="#41917470">root</a><span>|</span><a href="#41919760">parent</a><span>|</span><a href="#41914944">next</a><span>|</span><label class="collapse" for="c-41922981">[-]</label><label class="expand" for="c-41922981">[1 more]</label></div><br/><div class="children"><div class="content">The query layer would of course handle this. ELK has KQL, which could do it for you, but it doesn&#x27;t. That&#x27;s why I&#x27;m saying it&#x27;s a design mistake.<p>If your data mixes data types, I would argue that your report (whatever that is) _should_ get two columns.</div><br/></div></div></div></div></div></div></div></div><div id="41914944" class="c"><input type="checkbox" id="c-41914944" checked=""/><div class="controls bullet"><span class="by">abe94</span><span>|</span><a href="#41917470">prev</a><span>|</span><a href="#41916575">next</a><span>|</span><label class="collapse" for="c-41914944">[-]</label><label class="expand" for="c-41914944">[1 more]</label></div><br/><div class="children"><div class="content">We&#x27;ve been waiting for more JSON support for Clickhouse - the new type looks promising - and the dynamic column, and no need to specifcy subtypes is particularly helpful for us.</div><br/></div></div><div id="41916575" class="c"><input type="checkbox" id="c-41916575" checked=""/><div class="controls bullet"><span class="by">notamy</span><span>|</span><a href="#41914944">prev</a><span>|</span><a href="#41921084">next</a><span>|</span><label class="collapse" for="c-41916575">[-]</label><label class="expand" for="c-41916575">[8 more]</label></div><br/><div class="children"><div class="content">Clickhouse is great stuff. I use it for OLAP with a modest database (~600mil rows, ~300GB before compression) and it handles everything I throw at it without issues. I&#x27;m hopeful this new JSON data type will be better at a use-case that I currently solve with nested tuples.</div><br/><div id="41919882" class="c"><input type="checkbox" id="c-41919882" checked=""/><div class="controls bullet"><span class="by">jabart</span><span>|</span><a href="#41916575">parent</a><span>|</span><a href="#41917468">next</a><span>|</span><label class="collapse" for="c-41919882">[-]</label><label class="expand" for="c-41919882">[1 more]</label></div><br/><div class="children"><div class="content">Similar for us except 700mil rows in one table, 2.5 billion total rows. That&#x27;s growing quickly because we started shoving OTEL to the cluster. None of our queries seem to phase Clickhouse. It&#x27;s like magic. The 48 cores per node also helps</div><br/></div></div><div id="41917468" class="c"><input type="checkbox" id="c-41917468" checked=""/><div class="controls bullet"><span class="by">philosopher1234</span><span>|</span><a href="#41916575">parent</a><span>|</span><a href="#41919882">prev</a><span>|</span><a href="#41921084">next</a><span>|</span><label class="collapse" for="c-41917468">[-]</label><label class="expand" for="c-41917468">[6 more]</label></div><br/><div class="children"><div class="content">Postgres should be good enough for 300GB, no?</div><br/><div id="41918826" class="c"><input type="checkbox" id="c-41918826" checked=""/><div class="controls bullet"><span class="by">wiredfool</span><span>|</span><a href="#41916575">root</a><span>|</span><a href="#41917468">parent</a><span>|</span><a href="#41918445">next</a><span>|</span><label class="collapse" for="c-41918826">[-]</label><label class="expand" for="c-41918826">[1 more]</label></div><br/><div class="children"><div class="content">I had a postgres database where the main index (160gb) was larger than the entire equivalent clickhouse database (60gb). And between the partitioning and the natural keys, the primary key index in clickhouse was about 20k per partition * ~ 1k partitions.<p>Now, it wasn&#x27;t a good schema to start with, and there was about a factor of 3 or 4 size that could be pulled out, but clickhouse was a factor of 20 better for on disk size for what we were doing.</div><br/></div></div><div id="41918445" class="c"><input type="checkbox" id="c-41918445" checked=""/><div class="controls bullet"><span class="by">marginalia_nu</span><span>|</span><a href="#41916575">root</a><span>|</span><a href="#41917468">parent</a><span>|</span><a href="#41918826">prev</a><span>|</span><a href="#41917871">next</a><span>|</span><label class="collapse" for="c-41918445">[-]</label><label class="expand" for="c-41918445">[1 more]</label></div><br/><div class="children"><div class="content">At least in my experience, that&#x27;s about when regular DBMS:es kinda start to suck for ad-hoc queries.  You can push them a bit farther for non-analytical usecases if you&#x27;re really careful and have prepared indexes that assist every query you make, but that&#x27;s rarely a luxury you have in OLAP-land.</div><br/></div></div><div id="41917871" class="c"><input type="checkbox" id="c-41917871" checked=""/><div class="controls bullet"><span class="by">tempest_</span><span>|</span><a href="#41916575">root</a><span>|</span><a href="#41917468">parent</a><span>|</span><a href="#41918445">prev</a><span>|</span><a href="#41917496">next</a><span>|</span><label class="collapse" for="c-41917871">[-]</label><label class="expand" for="c-41917871">[1 more]</label></div><br/><div class="children"><div class="content">It depends, if you want to do any kind of aggregation, counts, or count distinct pg falls over pretty quickly.</div><br/></div></div><div id="41917496" class="c"><input type="checkbox" id="c-41917496" checked=""/><div class="controls bullet"><span class="by">notamy</span><span>|</span><a href="#41916575">root</a><span>|</span><a href="#41917468">parent</a><span>|</span><a href="#41917871">prev</a><span>|</span><a href="#41918261">next</a><span>|</span><label class="collapse" for="c-41917496">[-]</label><label class="expand" for="c-41917496">[1 more]</label></div><br/><div class="children"><div class="content">Probably, but Clickhouse has been zero-maintenance for me + my dataset is growing at 100~200GB&#x2F;month. Having the Clickhouse automatic compression makes me worry a <i>lot</i> less about disk space.</div><br/></div></div><div id="41918261" class="c"><input type="checkbox" id="c-41918261" checked=""/><div class="controls bullet"><span class="by">whalesalad</span><span>|</span><a href="#41916575">root</a><span>|</span><a href="#41917468">parent</a><span>|</span><a href="#41917496">prev</a><span>|</span><a href="#41921084">next</a><span>|</span><label class="collapse" for="c-41918261">[-]</label><label class="expand" for="c-41918261">[1 more]</label></div><br/><div class="children"><div class="content">For write heavy workloads I find psql to be a dog tbh. I use it everywhere but am anxious to try new tools.<p>For truly big data (terabytes per month) we rely on BigQuery. For smaller data that is more OLTP write heavy we are using psql… but I think there is room in the middle.</div><br/></div></div></div></div></div></div><div id="41921084" class="c"><input type="checkbox" id="c-41921084" checked=""/><div class="controls bullet"><span class="by">peteforde</span><span>|</span><a href="#41916575">prev</a><span>|</span><a href="#41918476">next</a><span>|</span><label class="collapse" for="c-41921084">[-]</label><label class="expand" for="c-41921084">[8 more]</label></div><br/><div class="children"><div class="content">I admit that I didn&#x27;t read the entire article in depth, but I did my best to meaningfully skim-parse it.<p>Can someone briefly explain how or if adding data types to JSON - a standardized grammar - leaves something that still qualifies as JSON?<p>I have no problem with people creating supersets of JSON, but if my standard lib JSON parser can&#x27;t read your &quot;JSON&quot; then wouldn&#x27;t it be better to call it something like &quot;CH-JSON&quot;?<p>If I am wildly missing something, I&#x27;m happy to be schooled. The end result certainly sounds cool, even though I haven&#x27;t needed ClickHouse yet.</div><br/><div id="41922493" class="c"><input type="checkbox" id="c-41922493" checked=""/><div class="controls bullet"><span class="by">zahlman</span><span>|</span><a href="#41921084">parent</a><span>|</span><a href="#41921350">next</a><span>|</span><label class="collapse" for="c-41922493">[-]</label><label class="expand" for="c-41922493">[1 more]</label></div><br/><div class="children"><div class="content">Clickhouse is a DBMS. What I understood: by &quot;a new JSON data type for ClickHouse&quot;, they don&#x27;t mean &quot;a new data type added to the JSON standard for the benefit of ClickHouse&quot;, but rather &quot;a new data type recognized by ClickHouse (i.e., that can be represented in its databases) which is used for storing JSON data&quot;.</div><br/></div></div><div id="41921350" class="c"><input type="checkbox" id="c-41921350" checked=""/><div class="controls bullet"><span class="by">chirau</span><span>|</span><a href="#41921084">parent</a><span>|</span><a href="#41922493">prev</a><span>|</span><a href="#41921163">next</a><span>|</span><label class="collapse" for="c-41921350">[-]</label><label class="expand" for="c-41921350">[2 more]</label></div><br/><div class="children"><div class="content">The article is about the internal storage mechanics of ClickHouse and how it optimizes handling JSON data behind the scenes. The data types like Dynamic and Variant that are discussed are part of ClickHouse’s internal mechanisms to improve performance, specifically for columnar storage of JSON data. The optimizations just help ClickHouse process and store data more efficiently.<p>The data remains standard JSON and so standard JSON parsers wouldn’t be affected since the optimizations are part of the storage layer and not the JSON structure itself.</div><br/><div id="41922302" class="c"><input type="checkbox" id="c-41922302" checked=""/><div class="controls bullet"><span class="by">chipdart</span><span>|</span><a href="#41921084">root</a><span>|</span><a href="#41921350">parent</a><span>|</span><a href="#41921163">next</a><span>|</span><label class="collapse" for="c-41922302">[-]</label><label class="expand" for="c-41922302">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The data remains standard JSON and so standard JSON parsers wouldn’t be affected (...)<p>No, not really.<p>The blog post talks about storing JSON data in a column-oriented database.<p>The blog post talks about importing data from JSON docs into their database. Prior to this, they stored JSON documents in their database like any standard off-the-shelf database does. Now they parse the JSON document when importing, and they store those values in their column-oriented database as key-value pairs, and preserve type information.<p>The silly part is that this all sounds like a intern project who was tasked with adding support to import data stored in JSON files into a column-oriented database, and an exporter along with it. But no, it seems an ETL job now counts as inventing JSON.</div><br/></div></div></div></div><div id="41921163" class="c"><input type="checkbox" id="c-41921163" checked=""/><div class="controls bullet"><span class="by">lemax</span><span>|</span><a href="#41921084">parent</a><span>|</span><a href="#41921350">prev</a><span>|</span><a href="#41922210">next</a><span>|</span><label class="collapse" for="c-41921163">[-]</label><label class="expand" for="c-41921163">[3 more]</label></div><br/><div class="children"><div class="content">As far as I understand they&#x27;re talking about the internal storage mechanics of ClickHouse, these aren&#x27;t user exposed JSON data types, they just power the underlying optimizations they&#x27;re introducing.</div><br/><div id="41921837" class="c"><input type="checkbox" id="c-41921837" checked=""/><div class="controls bullet"><span class="by">selcuka</span><span>|</span><a href="#41921084">root</a><span>|</span><a href="#41921163">parent</a><span>|</span><a href="#41922210">next</a><span>|</span><label class="collapse" for="c-41921837">[-]</label><label class="expand" for="c-41921837">[2 more]</label></div><br/><div class="children"><div class="content">Which is the same as PostgreSQL [1] or SQLite [2] that can store JSON values in binary formats (both called JSONB) but when you &quot;SELECT&quot; it you get standard JSON.<p>[1] <a href="https:&#x2F;&#x2F;www.postgresql.org&#x2F;docs&#x2F;current&#x2F;datatype-json.html" rel="nofollow">https:&#x2F;&#x2F;www.postgresql.org&#x2F;docs&#x2F;current&#x2F;datatype-json.html</a><p>[2] <a href="https:&#x2F;&#x2F;www.sqlite.org&#x2F;json1.html" rel="nofollow">https:&#x2F;&#x2F;www.sqlite.org&#x2F;json1.html</a></div><br/><div id="41922818" class="c"><input type="checkbox" id="c-41922818" checked=""/><div class="controls bullet"><span class="by">lucianbr</span><span>|</span><a href="#41921084">root</a><span>|</span><a href="#41921837">parent</a><span>|</span><a href="#41922210">next</a><span>|</span><label class="collapse" for="c-41922818">[-]</label><label class="expand" for="c-41922818">[1 more]</label></div><br/><div class="children"><div class="content">They both store JSON, each in some particular way, but they don&#x27;t both store it in the same way. Just like they both store tabular data, but not in the same way, and therefore get different performance characteristics.<p>Are you arguing that since Clickhouse is a database like Postgres, there&#x27;s no point for CH to exist as we already have Postgres? Column-oriented databases have their uses.</div><br/></div></div></div></div></div></div><div id="41922210" class="c"><input type="checkbox" id="c-41922210" checked=""/><div class="controls bullet"><span class="by">chipdart</span><span>|</span><a href="#41921084">parent</a><span>|</span><a href="#41921163">prev</a><span>|</span><a href="#41918476">next</a><span>|</span><label class="collapse" for="c-41922210">[-]</label><label class="expand" for="c-41922210">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Can someone briefly explain how or if adding data types to JSON - a standardized grammar - leaves something that still qualifies as JSON?<p>I had to scroll way down the article, passing over tons of what feel like astroturfing comments advertising a vendor and their product line, to see the very first comment pointing out the elephant in the room.<p>I agree, whatever it&#x27;s described in the blog post is clearly not JSON. It&#x27;s a data interchange format, and it might be mappable to JSON under the right circumstances, but JSON it is not. It&#x27;s not even a superset or a subset.<p>I mean, by the same line of reasoning both toml, CSV, and y&#x27;all are JSON. Come on. Even BSON is described as a different format that can be transcoded to JSON.<p>The article reads like a cheap attempt to gather attention to a format that otherwise would not justify it.</div><br/></div></div></div></div><div id="41918476" class="c"><input type="checkbox" id="c-41918476" checked=""/><div class="controls bullet"><span class="by">CSDude</span><span>|</span><a href="#41921084">prev</a><span>|</span><a href="#41916252">next</a><span>|</span><label class="collapse" for="c-41918476">[-]</label><label class="expand" for="c-41918476">[2 more]</label></div><br/><div class="children"><div class="content">When I tried it a few weeks ago, because ClickHouse names the files based on column names, weird JSON keys resulted in very long filenames and slashes and it did not play well with it the file system and gave errors, I wonder that is fixed?</div><br/><div id="41921812" class="c"><input type="checkbox" id="c-41921812" checked=""/><div class="controls bullet"><span class="by">setr</span><span>|</span><a href="#41918476">parent</a><span>|</span><a href="#41916252">next</a><span>|</span><label class="collapse" for="c-41921812">[-]</label><label class="expand" for="c-41921812">[1 more]</label></div><br/><div class="children"><div class="content">Isn’t that the issue challenge #3 addresses?<p><a href="https:&#x2F;&#x2F;clickhouse.com&#x2F;blog&#x2F;a-new-powerful-json-data-type-for-clickhouse#preventing-an-avalanche-of-column-files" rel="nofollow">https:&#x2F;&#x2F;clickhouse.com&#x2F;blog&#x2F;a-new-powerful-json-data-type-fo...</a></div><br/></div></div></div></div><div id="41916252" class="c"><input type="checkbox" id="c-41916252" checked=""/><div class="controls bullet"><span class="by">officex</span><span>|</span><a href="#41918476">prev</a><span>|</span><a href="#41917231">next</a><span>|</span><label class="collapse" for="c-41916252">[-]</label><label class="expand" for="c-41916252">[1 more]</label></div><br/><div class="children"><div class="content">Great to see! I remember checking you guys out in Q1, great team</div><br/></div></div><div id="41917231" class="c"><input type="checkbox" id="c-41917231" checked=""/><div class="controls bullet"><span class="by">fuziontech</span><span>|</span><a href="#41916252">prev</a><span>|</span><a href="#41916266">next</a><span>|</span><label class="collapse" for="c-41917231">[-]</label><label class="expand" for="c-41917231">[2 more]</label></div><br/><div class="children"><div class="content">Using ClickHouse is one of the best decisions we&#x27;ve made here at PostHog. It has allowed us to scale performance all while allowing us to build more products on the same set of data.<p>Since we&#x27;ve been using ClickHouse long before this JSON functionality was available (or even before the earlier version of this called `Object(&#x27;json&#x27;)` was avaiable) we ended up setting up a job that would materialize json fields out of a json blob and into materialized columns based on query patterns against the keys in the JSON blob. Then, once those materialized columns were created we would just route the queries to those columns at runtime if they were available. This saved us a _ton_ on CPU and IO utilization. Even though ClickHouse uses some really fast SIMD JSON functions, the best way to make a computer go faster is to make the computer do less and this new JSON type does exactly that and it&#x27;s so turn key!<p><a href="https:&#x2F;&#x2F;posthog.com&#x2F;handbook&#x2F;engineering&#x2F;databases&#x2F;materialized-columns">https:&#x2F;&#x2F;posthog.com&#x2F;handbook&#x2F;engineering&#x2F;databases&#x2F;materiali...</a><p>The team over at ClickHouse Inc. as well as the community behind it moves surprisingly fast. I can&#x27;t recommend it enough and excited for everything else that is on the roadmap here. I&#x27;m really excited for what is on the horizon with Parquet and Iceberg support.</div><br/></div></div><div id="41916266" class="c"><input type="checkbox" id="c-41916266" checked=""/><div class="controls bullet"><span class="by">baq</span><span>|</span><a href="#41917231">prev</a><span>|</span><a href="#41918294">next</a><span>|</span><label class="collapse" for="c-41916266">[-]</label><label class="expand" for="c-41916266">[17 more]</label></div><br/><div class="children"><div class="content">Clickhouse is criminally underused.<p>It&#x27;s common knowledge that &#x27;postgres is all you need&#x27; - but if you somehow reach the stage of &#x27;postgres isn&#x27;t all I need and I have hard proof&#x27; this should be the next tech you look at.<p>Also, clickhouse-local is rather amazing at csv processing using sql. Highly recommended for when you are fed up with google sheets or even excel.</div><br/><div id="41916879" class="c"><input type="checkbox" id="c-41916879" checked=""/><div class="controls bullet"><span class="by">mrsilencedogood</span><span>|</span><a href="#41916266">parent</a><span>|</span><a href="#41917011">next</a><span>|</span><label class="collapse" for="c-41916879">[-]</label><label class="expand" for="c-41916879">[1 more]</label></div><br/><div class="children"><div class="content">This is my take too. At one of my old jobs, we were early (very early) to the Hadoop and then Spark games. Maybe too early, because by the time Spark 2 made it all easy, we had already written a lot of mapreduce-streaming and then some RDD-based code. Towards the end of my tenure there, I was experimenting with alternate datastores, and clickhouse was one I evaluated. It worked really, really well in my demos. But I couldn&#x27;t get buy-in because management was a little wary of the russian side of it (which they have now distanced&#x2F;divorced from, I think?) and also they didn&#x27;t really have the appetite for such a large undertaking anymore. (The org was going through some things.) (So instead a different team blessed by the company owner basically DIYd a system to store .feather files on NVME SSDs... anyway).<p>If I were still there, I&#x27;d be pushing a lot harder to finally throw away the legacy system (which has lost so many people it&#x27;s basically ossified, anyway) and just &quot;rebase&quot; it all onto clickhouse and pyspark sparksql. We would throw away so much shitty cruft, and a lot of the newer mapreduce and RDD code is pretty portable to the point that it could be plugged into RDD&#x27;s pipe() method.<p>Anyway. My current job, we just stood up a new product that, from day 1, was ingesting billions of rows (event data) (~nothing for clickhouse, to be clear. but obviously way too much for pg). And it&#x27;s just chugging along. Clickhouse is definitely in my toolbox right after postgres, as you state.</div><br/></div></div><div id="41917011" class="c"><input type="checkbox" id="c-41917011" checked=""/><div class="controls bullet"><span class="by">osigurdson</span><span>|</span><a href="#41916266">parent</a><span>|</span><a href="#41916879">prev</a><span>|</span><a href="#41916384">next</a><span>|</span><label class="collapse" for="c-41917011">[-]</label><label class="expand" for="c-41917011">[1 more]</label></div><br/><div class="children"><div class="content">Agree. CH is a great technology to have some awareness of. I use it for &quot;real things&quot; (100B+ data points) but honestly it can really simplify little things as well.<p>I&#x27;d throw in one more to round it out however. The three rings of power are Postgres, ClickHouse and NATS. Postgres is the most powerful ring however and lots of times all you need.</div><br/></div></div><div id="41916384" class="c"><input type="checkbox" id="c-41916384" checked=""/><div class="controls bullet"><span class="by">oulipo</span><span>|</span><a href="#41916266">parent</a><span>|</span><a href="#41917011">prev</a><span>|</span><a href="#41917443">next</a><span>|</span><label class="collapse" for="c-41916384">[-]</label><label class="expand" for="c-41916384">[11 more]</label></div><br/><div class="children"><div class="content">would you recommend clickhouse over duckdb? and why?</div><br/><div id="41917416" class="c"><input type="checkbox" id="c-41917416" checked=""/><div class="controls bullet"><span class="by">nasretdinov</span><span>|</span><a href="#41916266">root</a><span>|</span><a href="#41916384">parent</a><span>|</span><a href="#41916824">next</a><span>|</span><label class="collapse" for="c-41917416">[-]</label><label class="expand" for="c-41917416">[5 more]</label></div><br/><div class="children"><div class="content">IMO the only reason to not use ClickHouse is when you either have &quot;small&quot; amount of data or &quot;small&quot; servers (&lt;100 Gb of data, servers with &lt;64 Gb of RAM). Otherwise ClickHouse is a better solution since it&#x27;s a standalone DB that supports replication and in general has very very robust cluster support, easily scaling to hundreds of nodes.<p>Typically when you discover the need for OLAP DB is when you reach that scale, so I&#x27;m personally not sure what the real use case for DuckDB is to be completely honest.</div><br/><div id="41922767" class="c"><input type="checkbox" id="c-41922767" checked=""/><div class="controls bullet"><span class="by">justCHurious</span><span>|</span><a href="#41916266">root</a><span>|</span><a href="#41917416">parent</a><span>|</span><a href="#41917802">next</a><span>|</span><label class="collapse" for="c-41922767">[-]</label><label class="expand" for="c-41922767">[1 more]</label></div><br/><div class="children"><div class="content">There is another place where you should not use CH, and it&#x27;s in a system with shared resources. CH loves, and earned the right, to have spikes of hogging resources. They even allude to this on the Keeper setup - if you put the nodes for the two systems in the same machine, CH will inevitably push Keeper off the bed and the two will come to a disagreement. You should not have it on a k8s Pod for that reason, for example. But then again, you shouldn&#x27;t have ANY storage of that capacity in a k8s pod anyways.</div><br/></div></div><div id="41917802" class="c"><input type="checkbox" id="c-41917802" checked=""/><div class="controls bullet"><span class="by">geysersam</span><span>|</span><a href="#41916266">root</a><span>|</span><a href="#41917416">parent</a><span>|</span><a href="#41922767">prev</a><span>|</span><a href="#41916824">next</a><span>|</span><label class="collapse" for="c-41917802">[-]</label><label class="expand" for="c-41917802">[3 more]</label></div><br/><div class="children"><div class="content">DuckDB probably performs better per core than clickhouse does for most queries. So as long as your workload fits on a single machine (it&#x27;s likely that it does) it&#x27;s often the most performant option.<p>Besides, it&#x27;s so simple, just a single executable.<p>Of course if you&#x27;re at a scale where you need a cluster it&#x27;s not an option anymore.</div><br/><div id="41918358" class="c"><input type="checkbox" id="c-41918358" checked=""/><div class="controls bullet"><span class="by">zX41ZdbW</span><span>|</span><a href="#41916266">root</a><span>|</span><a href="#41917802">parent</a><span>|</span><a href="#41916824">next</a><span>|</span><label class="collapse" for="c-41918358">[-]</label><label class="expand" for="c-41918358">[2 more]</label></div><br/><div class="children"><div class="content">The good parts of DuckDB that you&#x27;ve mentioned, including the fact that it is a single-executable, are modeled after ClickHouse.</div><br/><div id="41919029" class="c"><input type="checkbox" id="c-41919029" checked=""/><div class="controls bullet"><span class="by">RyanHamilton</span><span>|</span><a href="#41916266">root</a><span>|</span><a href="#41918358">parent</a><span>|</span><a href="#41916824">next</a><span>|</span><label class="collapse" for="c-41919029">[-]</label><label class="expand" for="c-41919029">[1 more]</label></div><br/><div class="children"><div class="content">Can you provide a reference for that belief?  To me that&#x27;s not true.  They started from solving very different problems.</div><br/></div></div></div></div></div></div></div></div><div id="41916824" class="c"><input type="checkbox" id="c-41916824" checked=""/><div class="controls bullet"><span class="by">PeterCorless</span><span>|</span><a href="#41916266">root</a><span>|</span><a href="#41916384">parent</a><span>|</span><a href="#41917416">prev</a><span>|</span><a href="#41916826">next</a><span>|</span><label class="collapse" for="c-41916824">[-]</label><label class="expand" for="c-41916824">[3 more]</label></div><br/><div class="children"><div class="content">Note that every use case is different and YMMV.<p><a href="https:&#x2F;&#x2F;www.vantage.sh&#x2F;blog&#x2F;clickhouse-local-vs-duckdb" rel="nofollow">https:&#x2F;&#x2F;www.vantage.sh&#x2F;blog&#x2F;clickhouse-local-vs-duckdb</a></div><br/><div id="41917673" class="c"><input type="checkbox" id="c-41917673" checked=""/><div class="controls bullet"><span class="by">hn1986</span><span>|</span><a href="#41916266">root</a><span>|</span><a href="#41916824">parent</a><span>|</span><a href="#41917854">prev</a><span>|</span><a href="#41916826">next</a><span>|</span><label class="collapse" for="c-41917673">[-]</label><label class="expand" for="c-41917673">[1 more]</label></div><br/><div class="children"><div class="content">Great link . Curious how it compares now that Duckdb is 1.0+</div><br/></div></div></div></div><div id="41916826" class="c"><input type="checkbox" id="c-41916826" checked=""/><div class="controls bullet"><span class="by">theLiminator</span><span>|</span><a href="#41916266">root</a><span>|</span><a href="#41916384">parent</a><span>|</span><a href="#41916824">prev</a><span>|</span><a href="#41917443">next</a><span>|</span><label class="collapse" for="c-41916826">[-]</label><label class="expand" for="c-41916826">[2 more]</label></div><br/><div class="children"><div class="content">Not to mention polars, datafusion, etc. Single node OLAP space is really heating up.</div><br/><div id="41916975" class="c"><input type="checkbox" id="c-41916975" checked=""/><div class="controls bullet"><span class="by">fiddlerwoaroof</span><span>|</span><a href="#41916266">root</a><span>|</span><a href="#41916826">parent</a><span>|</span><a href="#41917443">next</a><span>|</span><label class="collapse" for="c-41916975">[-]</label><label class="expand" for="c-41916975">[1 more]</label></div><br/><div class="children"><div class="content">Clickhouse scales from a local tool like Duckdb to a database cluster that can back your reporting applications and other OLAP applications.</div><br/></div></div></div></div></div></div><div id="41917443" class="c"><input type="checkbox" id="c-41917443" checked=""/><div class="controls bullet"><span class="by">CalRobert</span><span>|</span><a href="#41916266">parent</a><span>|</span><a href="#41916384">prev</a><span>|</span><a href="#41916459">next</a><span>|</span><label class="collapse" for="c-41917443">[-]</label><label class="expand" for="c-41917443">[2 more]</label></div><br/><div class="children"><div class="content">Clickhouse and Postgres are just different tools though - OLTP vs OLAP.</div><br/><div id="41919312" class="c"><input type="checkbox" id="c-41919312" checked=""/><div class="controls bullet"><span class="by">fiddlerwoaroof</span><span>|</span><a href="#41916266">root</a><span>|</span><a href="#41917443">parent</a><span>|</span><a href="#41916459">next</a><span>|</span><label class="collapse" for="c-41919312">[-]</label><label class="expand" for="c-41919312">[1 more]</label></div><br/><div class="children"><div class="content">It’s fairly common in my experience for reports to initially be driven by a Postgres database until you hit data volumes Postgres cannot handle.</div><br/></div></div></div></div></div></div><div id="41916510" class="c"><input type="checkbox" id="c-41916510" checked=""/><div class="controls bullet"><span class="by">anonygler</span><span>|</span><a href="#41917684">prev</a><span>|</span><label class="collapse" for="c-41916510">[-]</label><label class="expand" for="c-41916510">[1 more]</label></div><br/><div class="children"><div class="content">I keep misreading this company as ClickHole and expecting some sort of satirical content.</div><br/></div></div></div></div></div></div></div></body></html>