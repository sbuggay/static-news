<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1724403664680" as="style"/><link rel="stylesheet" href="styles.css?v=1724403664680"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://trainy.ai/blog/gpu-utilization-misleading">GPU utilization can be a misleading metric</a> <span class="domain">(<a href="https://trainy.ai">trainy.ai</a>)</span></div><div class="subtext"><span>roanakb</span> | <span>22 comments</span></div><br/><div><div id="41322732" class="c"><input type="checkbox" id="c-41322732" checked=""/><div class="controls bullet"><span class="by">SnowflakeOnIce</span><span>|</span><a href="#41323002">next</a><span>|</span><label class="collapse" for="c-41322732">[-]</label><label class="expand" for="c-41322732">[7 more]</label></div><br/><div class="children"><div class="content">&gt; you can get 100% GPU utilization by just reading&#x2F;writing to memory while doing 0 computations<p>Indeed! Utilization is a proxy for what you actually want (which is good use of available hardware). 100% GPU utilization doesn&#x27;t actually indicate this.<p>On the other hand, if you <i>aren&#x27;t</i> getting 100% GPU utilization, you aren&#x27;t making good use of the hardware.</div><br/><div id="41326398" class="c"><input type="checkbox" id="c-41326398" checked=""/><div class="controls bullet"><span class="by">tanelpoder</span><span>|</span><a href="#41322732">parent</a><span>|</span><a href="#41324724">next</a><span>|</span><label class="collapse" for="c-41326398">[-]</label><label class="expand" for="c-41326398">[1 more]</label></div><br/><div class="children"><div class="content">This reminds me of the Linux&#x2F;Unix disk busy &quot;%util&quot; metric in tools like sar and iostat. People sometimes interpret the 100%util as a physical ceiling for the disk IO capacity, just like with CPUs (&quot;we need more disks to get disk I&#x2F;O utilization down!&quot;).<p>It is a correct metric when your block device has a <i>single</i> physical spinning disk that can only accept one request at a time (dispatch queue depth=1). But the moment you deal with SSDs (capable of highly concurrent NAND IO), SAN storage block devices striped over many physical disks or even a single spinning disk that can internally queue and reorder IOs for more efficient seeking, just hitting 100%util at the host block device level doesn&#x27;t mean that you&#x27;ve hit some IOPS ceiling.<p>So, looks like the GPU &quot;SM efficiency&quot; analysis is somewhat like logging in to the storage array itself and checking how busy each physical disk (or at least each disk controller) inside that storage array is.</div><br/></div></div><div id="41324724" class="c"><input type="checkbox" id="c-41324724" checked=""/><div class="controls bullet"><span class="by">serial_dev</span><span>|</span><a href="#41322732">parent</a><span>|</span><a href="#41326398">prev</a><span>|</span><a href="#41326197">next</a><span>|</span><label class="collapse" for="c-41324724">[-]</label><label class="expand" for="c-41324724">[1 more]</label></div><br/><div class="children"><div class="content">This sounds like the good old &quot;having high test coverage is bad because I can get to 100% just by calling functions and doing nothing, asserting nothing with them&quot;.<p>100% test coverage doesn&#x27;t mean your tests are good, but having 50% (or pick your number) means they are bad &#x2F; not sufficient.</div><br/></div></div><div id="41326197" class="c"><input type="checkbox" id="c-41326197" checked=""/><div class="controls bullet"><span class="by">shaklee3</span><span>|</span><a href="#41322732">parent</a><span>|</span><a href="#41324724">prev</a><span>|</span><a href="#41322746">next</a><span>|</span><label class="collapse" for="c-41326197">[-]</label><label class="expand" for="c-41326197">[3 more]</label></div><br/><div class="children"><div class="content">This is not true. Lots of algorithms simply can&#x27;t use 100% of the GPU even though they&#x27;re written as optimal as possible. FFT is one.</div><br/><div id="41326229" class="c"><input type="checkbox" id="c-41326229" checked=""/><div class="controls bullet"><span class="by">defrost</span><span>|</span><a href="#41322732">root</a><span>|</span><a href="#41326197">parent</a><span>|</span><a href="#41322746">next</a><span>|</span><label class="collapse" for="c-41326229">[-]</label><label class="expand" for="c-41326229">[2 more]</label></div><br/><div class="children"><div class="content">In remote sensing | computation physicas <i>applications</i> it&#x27;s rare to have a <i>single</i> FFT to compute (whatever algorithm is chosen).<p>Hence the practice of stuffing many FFT&#x27;s through GPU grids in parallel and working to max out the hardware usage in order to increase application throughput.<p>eg:<p><a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;1707.07263" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;1707.07263</a><p><a href="https:&#x2F;&#x2F;ieeexplore.ieee.org&#x2F;document&#x2F;9835388" rel="nofollow">https:&#x2F;&#x2F;ieeexplore.ieee.org&#x2F;document&#x2F;9835388</a></div><br/><div id="41326317" class="c"><input type="checkbox" id="c-41326317" checked=""/><div class="controls bullet"><span class="by">shaklee3</span><span>|</span><a href="#41322732">root</a><span>|</span><a href="#41326229">parent</a><span>|</span><a href="#41322746">next</a><span>|</span><label class="collapse" for="c-41326317">[-]</label><label class="expand" for="c-41326317">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t mean a single fft. I mean the fft algorithms are inherently not going to use the GPU at 100% utilization by any metric.</div><br/></div></div></div></div></div></div><div id="41322746" class="c"><input type="checkbox" id="c-41322746" checked=""/><div class="controls bullet"><span class="by">roanakb</span><span>|</span><a href="#41322732">parent</a><span>|</span><a href="#41326197">prev</a><span>|</span><a href="#41323002">next</a><span>|</span><label class="collapse" for="c-41322746">[-]</label><label class="expand" for="c-41322746">[1 more]</label></div><br/><div class="children"><div class="content">Yup, similar to SM efficiency in that sense too. If you aren&#x27;t seeing &gt;80%, there is certainly time left on the table. But getting a high SM efficiency value doesn&#x27;t guarantee you&#x27;re making good use of the hardware as well. (still a better proxy than GPU util though)</div><br/></div></div></div></div><div id="41323002" class="c"><input type="checkbox" id="c-41323002" checked=""/><div class="controls bullet"><span class="by">antognini</span><span>|</span><a href="#41322732">prev</a><span>|</span><a href="#41325686">next</a><span>|</span><label class="collapse" for="c-41323002">[-]</label><label class="expand" for="c-41323002">[2 more]</label></div><br/><div class="children"><div class="content">When understanding the performance of your model it&#x27;s very helpful to look at a roofline plot [1].  The roofline plot will show you the floating-point performance as a function of arithmetic intensity for the various ops in your model.  The plot has two regimes: a memory-bound regime on the left and a compute-bound regime on the right.  This can help to identify memory-bound ops that are taking a significant fraction of compute time.<p>[1]: <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Roofline_model" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Roofline_model</a></div><br/><div id="41323084" class="c"><input type="checkbox" id="c-41323084" checked=""/><div class="controls bullet"><span class="by">roanakb</span><span>|</span><a href="#41323002">parent</a><span>|</span><a href="#41325686">next</a><span>|</span><label class="collapse" for="c-41323084">[-]</label><label class="expand" for="c-41323084">[1 more]</label></div><br/><div class="children"><div class="content">Agreed, roofline plots would be quite powerful in this context. From a quick search, seems like the only way to create a roofline plot for your model would be to use Nsight [1]? Would be interested to know if there are any simpler tools, since one of the big benefits of SM efficiency is how easily the metric is accessed.<p>[1]: <a href="https:&#x2F;&#x2F;www.nvidia.com&#x2F;en-us&#x2F;on-demand&#x2F;session&#x2F;gtcspring21-s32062&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.nvidia.com&#x2F;en-us&#x2F;on-demand&#x2F;session&#x2F;gtcspring21-s...</a></div><br/></div></div></div></div><div id="41325686" class="c"><input type="checkbox" id="c-41325686" checked=""/><div class="controls bullet"><span class="by">DamonsJ</span><span>|</span><a href="#41323002">prev</a><span>|</span><a href="#41322999">next</a><span>|</span><label class="collapse" for="c-41325686">[-]</label><label class="expand" for="c-41325686">[2 more]</label></div><br/><div class="children"><div class="content">&quot;If we have a CUDA kernel that continuously runs for 10 seconds but only uses 1 SM, on an H100, this would register 100% utilization, but the SM efficiency would be 1 &#x2F; 132 = 0.7%.&quot;<p>does this situation register 100% utilization?
BTW, the SM OCCUPANCY is also a metric you need to care about if you concern on kernel efficiency</div><br/><div id="41326107" class="c"><input type="checkbox" id="c-41326107" checked=""/><div class="controls bullet"><span class="by">roanakb</span><span>|</span><a href="#41325686">parent</a><span>|</span><a href="#41322999">next</a><span>|</span><label class="collapse" for="c-41326107">[-]</label><label class="expand" for="c-41326107">[1 more]</label></div><br/><div class="children"><div class="content">Yup, you&#x27;ll see 100% utilization on a kernel over a time period if it&#x27;s considered active, which includes just having a single thread executing [1]. SM occupancy is great but can be a little difficult to interpret since you&#x27;re not simply trying to maximize it, unlike SM efficiency.<p>[1]: <a href="https:&#x2F;&#x2F;pytorch.org&#x2F;blog&#x2F;pytorch-profiler-1.9-released&#x2F;#gpu-metric-on-timeline" rel="nofollow">https:&#x2F;&#x2F;pytorch.org&#x2F;blog&#x2F;pytorch-profiler-1.9-released&#x2F;#gpu-...</a></div><br/></div></div></div></div><div id="41322999" class="c"><input type="checkbox" id="c-41322999" checked=""/><div class="controls bullet"><span class="by">sundalia</span><span>|</span><a href="#41325686">prev</a><span>|</span><a href="#41323218">next</a><span>|</span><label class="collapse" for="c-41322999">[-]</label><label class="expand" for="c-41322999">[2 more]</label></div><br/><div class="children"><div class="content">Application-specific metrics are the way to go. For ML training this is one example:
<a href="https:&#x2F;&#x2F;cloud.google.com&#x2F;blog&#x2F;products&#x2F;ai-machine-learning&#x2F;goodput-metric-as-measure-of-ml-productivity" rel="nofollow">https:&#x2F;&#x2F;cloud.google.com&#x2F;blog&#x2F;products&#x2F;ai-machine-learning&#x2F;g...</a></div><br/><div id="41323130" class="c"><input type="checkbox" id="c-41323130" checked=""/><div class="controls bullet"><span class="by">roanakb</span><span>|</span><a href="#41322999">parent</a><span>|</span><a href="#41323218">next</a><span>|</span><label class="collapse" for="c-41323130">[-]</label><label class="expand" for="c-41323130">[1 more]</label></div><br/><div class="children"><div class="content">Nice, seems like ML Productivity Goodput is a pretty well thought-out metric to understand the overall efficiency of your cluster. I&#x27;ll consider adding this into our cluster management platform. Only potential drawbacks I&#x27;d guess are it being somewhat difficult to compute since it relies on metrics like MFUs, and not something we can observe layer-by-layer to understand inefficient kernels, but I&#x27;ll take a deeper look. Thanks!</div><br/></div></div></div></div><div id="41323218" class="c"><input type="checkbox" id="c-41323218" checked=""/><div class="controls bullet"><span class="by">saagarjha</span><span>|</span><a href="#41322999">prev</a><span>|</span><a href="#41327053">next</a><span>|</span><label class="collapse" for="c-41323218">[-]</label><label class="expand" for="c-41323218">[1 more]</label></div><br/><div class="children"><div class="content">If you have a basic understanding of what your kernels are supposed to do, looking at pipe usage and roofline analysis in Nsight Compute is often helpful, since it will show you how hard you’re saturating those.</div><br/></div></div><div id="41327053" class="c"><input type="checkbox" id="c-41327053" checked=""/><div class="controls bullet"><span class="by">AeZ1E</span><span>|</span><a href="#41323218">prev</a><span>|</span><a href="#41325705">next</a><span>|</span><label class="collapse" for="c-41327053">[-]</label><label class="expand" for="c-41327053">[1 more]</label></div><br/><div class="children"><div class="content">gpu utilization is not everything, people! mfus are where it&#x27;s at. time to recalibrate those expectations and tap into the true potential of your gpus. brace yourselves, the real efficiency is yet to come!</div><br/></div></div><div id="41325705" class="c"><input type="checkbox" id="c-41325705" checked=""/><div class="controls bullet"><span class="by">pavelstoev</span><span>|</span><a href="#41327053">prev</a><span>|</span><a href="#41322272">next</a><span>|</span><label class="collapse" for="c-41325705">[-]</label><label class="expand" for="c-41325705">[2 more]</label></div><br/><div class="children"><div class="content">I recommend hidet backend in torch.compile - implements many advanced model-specific optimizations automatically. <a href="https:&#x2F;&#x2F;github.com&#x2F;hidet-org&#x2F;hidet">https:&#x2F;&#x2F;github.com&#x2F;hidet-org&#x2F;hidet</a></div><br/><div id="41326121" class="c"><input type="checkbox" id="c-41326121" checked=""/><div class="controls bullet"><span class="by">roanakb</span><span>|</span><a href="#41325705">parent</a><span>|</span><a href="#41322272">next</a><span>|</span><label class="collapse" for="c-41326121">[-]</label><label class="expand" for="c-41326121">[1 more]</label></div><br/><div class="children"><div class="content">oh this looks great, thank you for bringing this up! I&#x27;ll have to give it a try, but seems like the FSDP limitation on torch.compile might carry over?</div><br/></div></div></div></div><div id="41322272" class="c"><input type="checkbox" id="c-41322272" checked=""/><div class="controls bullet"><span class="by">sergiotapia</span><span>|</span><a href="#41325705">prev</a><span>|</span><label class="collapse" for="c-41322272">[-]</label><label class="expand" for="c-41322272">[4 more]</label></div><br/><div class="children"><div class="content">running GPU models and maximizing utilization is pretty opaque to me as a layman coming into the scene.<p>take this example: <a href="https:&#x2F;&#x2F;gist.github.com&#x2F;sergiotapia&#x2F;efc9b3f7163ba803a260b481470255c1" rel="nofollow">https:&#x2F;&#x2F;gist.github.com&#x2F;sergiotapia&#x2F;efc9b3f7163ba803a260b481...</a> - running a fairly simple model that takes only 70ms per image pair, but because I have 300 images it becomes a big time sink.<p>by using ThreadPoolExecutor, I cut that down to about 16 seconds. i wonder if there is a fairly obvious way to truly utlize my beefy L40S GPU! is it MPS? I haven&#x27;t been successful at even running the MPS daemon on my linux server yet. very opaque for sure!</div><br/><div id="41323628" class="c"><input type="checkbox" id="c-41323628" checked=""/><div class="controls bullet"><span class="by">dahart</span><span>|</span><a href="#41322272">parent</a><span>|</span><a href="#41322565">next</a><span>|</span><label class="collapse" for="c-41323628">[-]</label><label class="expand" for="c-41323628">[1 more]</label></div><br/><div class="children"><div class="content">Start with Nsight Systems and turn on GPU metrics. It’s super easy and the plots will give you an immediate sense of your utilization, and low-hanging optimization opportunities.<p>So using 10-wide parallel processing took your batch from 21 seconds down to 16 seconds, did I do the arithmetic correctly? That suggests the single-threaded version isn’t too bad. I mean a 25% improvement is great and nothing to sneeze at, but batching might only be trimming the gaps in between image pairs, or queueing up your memory copies while the previous inference is running. You can verify this with nsys profiles.<p>&gt; i wonder if there is a fairly obvious way to truly utilize my beefy L40S GPU! is it MPS?<p>No idea, it’s not always easy (and generally speaking gets harder and harder as you approach 100%), but first profile to see what your utilization is before going down any big technical route. Maybe with your ThreadPoolExecutor, you’re already getting max utilization and using MPS can’t possibly help.</div><br/></div></div><div id="41322565" class="c"><input type="checkbox" id="c-41322565" checked=""/><div class="controls bullet"><span class="by">zaptrem</span><span>|</span><a href="#41322272">parent</a><span>|</span><a href="#41323628">prev</a><span>|</span><a href="#41322617">next</a><span>|</span><label class="collapse" for="c-41322565">[-]</label><label class="expand" for="c-41322565">[1 more]</label></div><br/><div class="children"><div class="content">Batch as many requests together as possible and your utilization will increase.</div><br/></div></div><div id="41322617" class="c"><input type="checkbox" id="c-41322617" checked=""/><div class="controls bullet"><span class="by">asaiacai</span><span>|</span><a href="#41322272">parent</a><span>|</span><a href="#41322565">prev</a><span>|</span><label class="collapse" for="c-41322617">[-]</label><label class="expand" for="c-41322617">[1 more]</label></div><br/><div class="children"><div class="content">totally agreed. A lot of our findings during this process is that there&#x27;s still a lot of alpha in finding the right kernels for the job&#x2F;model. We&#x27;re hoping that in the future `torch.compile` will become more mature because current docs on performance at least on pytorch side definitely leave us wanting more</div><br/></div></div></div></div></div></div></div></div></div></body></html>