<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1722330064774" as="style"/><link rel="stylesheet" href="styles.css?v=1722330064774"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://arxiv.org/abs/2407.15811">Diffusion Training from Scratch on a Micro-Budget</a> <span class="domain">(<a href="https://arxiv.org">arxiv.org</a>)</span></div><div class="subtext"><span>fzliu</span> | <span>15 comments</span></div><br/><div><div id="41106544" class="c"><input type="checkbox" id="c-41106544" checked=""/><div class="controls bullet"><span class="by">worstspotgain</span><span>|</span><a href="#41106247">next</a><span>|</span><label class="collapse" for="c-41106544">[-]</label><label class="expand" for="c-41106544">[6 more]</label></div><br/><div class="children"><div class="content">Asymptotic improvements are flattening the cost curves so fast that AI regulation might become practically meaningless by the end of the year. If you want unregulated output you&#x27;ll have tons of offshore models to choose from.<p>The risk is that the good guys end up being the only ones hampered by it. Hopefully it won&#x27;t be so large a burden that the bad guys and especially the so-so guys (those with a real chance, e.g. Alibaba) get a massive leg up.</div><br/><div id="41106982" class="c"><input type="checkbox" id="c-41106982" checked=""/><div class="controls bullet"><span class="by">uyzstvqs</span><span>|</span><a href="#41106544">parent</a><span>|</span><a href="#41106652">next</a><span>|</span><label class="collapse" for="c-41106982">[-]</label><label class="expand" for="c-41106982">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Asymptotic improvements are flattening the cost curves so fast that AI regulation might become practically meaningless by the end of the year.<p>Awesome. This will mean actually good open-source models, not just API endpoints by big tech which are unusable because of dataset censorship and bias alignment (SD3, Gemini).<p>In other words, big tech will actually need to make good stuff to be competitive, not trash protected by a granted monopoly.</div><br/><div id="41107179" class="c"><input type="checkbox" id="c-41107179" checked=""/><div class="controls bullet"><span class="by">sigmoid10</span><span>|</span><a href="#41106544">root</a><span>|</span><a href="#41106982">parent</a><span>|</span><a href="#41106652">next</a><span>|</span><label class="collapse" for="c-41107179">[-]</label><label class="expand" for="c-41107179">[1 more]</label></div><br/><div class="children"><div class="content">Those improvements are definitely real, but we also have pretty solidly established and confirmed scaling laws by now. Until someone utterly breaks those, big players will always have an edge, simply because they can spend more compute on training and inference. The only way to change this is with a new architecture that benefits more from intelligent adjustments in a space than cannot be searched efficiently with raw compute. And even then we are  not far from the point where these models could try out those adjustments themselves. So by the time you get to tune your own GAI in your home like you could do with a human, corporations might have millions of them improving themselves to something you could never achieve on your own.</div><br/></div></div></div></div><div id="41106652" class="c"><input type="checkbox" id="c-41106652" checked=""/><div class="controls bullet"><span class="by">FeepingCreature</span><span>|</span><a href="#41106544">parent</a><span>|</span><a href="#41106982">prev</a><span>|</span><a href="#41106247">next</a><span>|</span><label class="collapse" for="c-41106652">[-]</label><label class="expand" for="c-41106652">[3 more]</label></div><br/><div class="children"><div class="content">Unregulated output at small scales. The really big training runs will still cost millions.</div><br/><div id="41106713" class="c"><input type="checkbox" id="c-41106713" checked=""/><div class="controls bullet"><span class="by">worstspotgain</span><span>|</span><a href="#41106544">root</a><span>|</span><a href="#41106652">parent</a><span>|</span><a href="#41106247">next</a><span>|</span><label class="collapse" for="c-41106713">[-]</label><label class="expand" for="c-41106713">[2 more]</label></div><br/><div class="children"><div class="content">Not when we&#x27;re talking asymptotically. The linked paper for instance claims 14- to 118-fold cost reductions. 1-2 GPU generations from now you&#x27;ll train this model for $0.12.</div><br/><div id="41107049" class="c"><input type="checkbox" id="c-41107049" checked=""/><div class="controls bullet"><span class="by">impossiblefork</span><span>|</span><a href="#41106544">root</a><span>|</span><a href="#41106713">parent</a><span>|</span><a href="#41106247">next</a><span>|</span><label class="collapse" for="c-41107049">[-]</label><label class="expand" for="c-41107049">[1 more]</label></div><br/><div class="children"><div class="content">Surely not $0.12.<p>Maybe $100.</div><br/></div></div></div></div></div></div></div></div><div id="41106247" class="c"><input type="checkbox" id="c-41106247" checked=""/><div class="controls bullet"><span class="by">orbital-decay</span><span>|</span><a href="#41106544">prev</a><span>|</span><a href="#41106349">next</a><span>|</span><label class="collapse" for="c-41106247">[-]</label><label class="expand" for="c-41106247">[2 more]</label></div><br/><div class="children"><div class="content">Reminds me of PixArt-α which was also trained on the similarly tiny budget ($28,000). [0] How good is their result, though? Training a toy model is one thing, making something usable (let alone competitive) is another.<p>Edit: they do have comparisons in the paper, and PixArt-α seems to be... more coherent?<p>[0] <a href="https:&#x2F;&#x2F;pixart-alpha.github.io&#x2F;" rel="nofollow">https:&#x2F;&#x2F;pixart-alpha.github.io&#x2F;</a></div><br/><div id="41106473" class="c"><input type="checkbox" id="c-41106473" checked=""/><div class="controls bullet"><span class="by">daghamm</span><span>|</span><a href="#41106247">parent</a><span>|</span><a href="#41106349">next</a><span>|</span><label class="collapse" for="c-41106473">[-]</label><label class="expand" for="c-41106473">[1 more]</label></div><br/><div class="children"><div class="content">They mention that as state of the art, this one is supposed to be 14-18x better.<p>By the way, has anyone ran these locally? Is the inference time also lower?</div><br/></div></div></div></div><div id="41106349" class="c"><input type="checkbox" id="c-41106349" checked=""/><div class="controls bullet"><span class="by">Flux159</span><span>|</span><a href="#41106247">prev</a><span>|</span><a href="#41106100">next</a><span>|</span><label class="collapse" for="c-41106349">[-]</label><label class="expand" for="c-41106349">[3 more]</label></div><br/><div class="children"><div class="content">This kind of research is great for reducing training costs as well as enabling more people to experiment with training large models. Hopefully in 5-10 years we&#x27;ll be able to train a model on par with SD 1.5 with consumer gpus since that would be great for teaching model development.</div><br/><div id="41106623" class="c"><input type="checkbox" id="c-41106623" checked=""/><div class="controls bullet"><span class="by">Blackthorn</span><span>|</span><a href="#41106349">parent</a><span>|</span><a href="#41106100">next</a><span>|</span><label class="collapse" for="c-41106623">[-]</label><label class="expand" for="c-41106623">[2 more]</label></div><br/><div class="children"><div class="content">Getting parity with SD 1.5 should require a similarly comprehensive data set, which seems a lot harder to source than a computer GPU. Especially now that we&#x27;ve got the A I-equivalent of pre&#x2F;post nuclear steel.</div><br/><div id="41107223" class="c"><input type="checkbox" id="c-41107223" checked=""/><div class="controls bullet"><span class="by">roenxi</span><span>|</span><a href="#41106349">root</a><span>|</span><a href="#41106623">parent</a><span>|</span><a href="#41106100">next</a><span>|</span><label class="collapse" for="c-41107223">[-]</label><label class="expand" for="c-41107223">[1 more]</label></div><br/><div class="children"><div class="content">Given how little artistic data humans need, there are probably breakthroughs coming that will reduce the size of the data set needed. Or make it so that a lot of the data required is more generic (like how a human artist needs vast amounts of audio-visual data from walking around every day, but maybe as little as a few megabytes to go from nothing to copying a new style and subject - then we can have a curated open source &quot;highlights of the first 20 years of life&quot; data set that everyone uses for basic training).</div><br/></div></div></div></div></div></div><div id="41106336" class="c"><input type="checkbox" id="c-41106336" checked=""/><div class="controls bullet"><span class="by">p1esk</span><span>|</span><a href="#41106470">prev</a><span>|</span><label class="collapse" for="c-41106336">[-]</label><label class="expand" for="c-41106336">[1 more]</label></div><br/><div class="children"><div class="content">Interesting - they say using FP8 didn’t provide any speed up.</div><br/></div></div></div></div></div></div></div></body></html>