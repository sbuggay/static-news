<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1727254868408" as="style"/><link rel="stylesheet" href="styles.css?v=1727254868408"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124">Why Most Published Research Findings Are False (2005)</a> <span class="domain">(<a href="https://journals.plos.org">journals.plos.org</a>)</span></div><div class="subtext"><span>Michelangelo11</span> | <span>145 comments</span></div><br/><div><div id="41641568" class="c"><input type="checkbox" id="c-41641568" checked=""/><div class="controls bullet"><span class="by">elashri</span><span>|</span><a href="#41642265">next</a><span>|</span><label class="collapse" for="c-41641568">[-]</label><label class="expand" for="c-41641568">[32 more]</label></div><br/><div class="children"><div class="content">There is at least one thing wrong about this. This is an essay about a paper published a simulation based scenarios in medical research. It then try to generalize to &quot;research&quot; and avoid this very narrow support to the claim. I think this is something true and it should make us more cautious when deciding based on single studies. But things are different in other fields.<p>Also this is called research. You don&#x27;t know the answer before head. You have limitations in tech and tools you use. You might miss something, didn&#x27;t have access to more information that could change the outcome. That is why research is a process. Unfortunately common science books talks only about discoveries, results that are considered fact but usually don&#x27;t do much about the history of how we got there. I would like to suggest a great book called &quot;How experiments end&quot;[1] and enjoy going into details on how scientific conscious is built for many experiments in different fields (mostly physics).<p>[1] <a href="https:&#x2F;&#x2F;press.uchicago.edu&#x2F;ucp&#x2F;books&#x2F;book&#x2F;chicago&#x2F;H&#x2F;bo5969426.html" rel="nofollow">https:&#x2F;&#x2F;press.uchicago.edu&#x2F;ucp&#x2F;books&#x2F;book&#x2F;chicago&#x2F;H&#x2F;bo596942...</a></div><br/><div id="41642682" class="c"><input type="checkbox" id="c-41642682" checked=""/><div class="controls bullet"><span class="by">ants_everywhere</span><span>|</span><a href="#41641568">parent</a><span>|</span><a href="#41641826">next</a><span>|</span><label class="collapse" for="c-41642682">[-]</label><label class="expand" for="c-41642682">[4 more]</label></div><br/><div class="children"><div class="content">I think the best way to view this paper is as a sort of meta-analysis of a wider literature around null hypothesis testing and p-values. That literature goes back at least to the 1970s with the work of people like Paul Meehl and Gene Glass. But you can push it further back, like the 1957 Lindley Paradox that Ioannidis cites.<p>Part of the reason this paper was impactful is that it was short and punchy, took aim at all of medicine rather than a smaller subfield, and didn&#x27;t require as much mathematical understanding as other papers.<p>I knew some of the big names that were hit by the replication crisis. And before that I spent some time trying to talk to psychology researchers at a top school about the problems with statistical testing. But they had limited knowledge of stats and didn&#x27;t want to go out on a limb when everyone else in the field seemed okay with the status quo. A paper like this can be read by everyone and makes a forceful argument.<p>&gt; It then try to generalize to &quot;research&quot; and avoid this very narrow support to the claim<p>This is a good point. The methods in medicine and the social sciences are especially weak and prone to these sorts of criticisms. In the physical sciences, often you can run enough iterations of the experiment to overwhelm any prior.<p>&gt; You have limitations in tech and tools you use. You might miss something, didn&#x27;t have access to more information that could change the outcome. That is why research is a process.<p>I totally agree. Science is basically a control system, or a root finding algorithm, or gradient descent. At any time t there is a gap between the best known science and the truth. But the point is that science converges to the truth over time, whereas no other alternative does.</div><br/><div id="41643993" class="c"><input type="checkbox" id="c-41643993" checked=""/><div class="controls bullet"><span class="by">verisimi</span><span>|</span><a href="#41641568">root</a><span>|</span><a href="#41642682">parent</a><span>|</span><a href="#41641826">next</a><span>|</span><label class="collapse" for="c-41643993">[-]</label><label class="expand" for="c-41643993">[3 more]</label></div><br/><div class="children"><div class="content">The scientific method converges on the truth.  But science need not.<p>If the foundational assumptions are wrong or impossible to challenge, time t can extend indefinitely.  Additionally, it is surely possible that whole sections of science is waylaid and diverges from truth on account of funding, legislation, big personalities, etc.</div><br/><div id="41644330" class="c"><input type="checkbox" id="c-41644330" checked=""/><div class="controls bullet"><span class="by">DrNosferatu</span><span>|</span><a href="#41641568">root</a><span>|</span><a href="#41643993">parent</a><span>|</span><a href="#41641826">next</a><span>|</span><label class="collapse" for="c-41644330">[-]</label><label class="expand" for="c-41644330">[2 more]</label></div><br/><div class="children"><div class="content">But what is “truth”?</div><br/><div id="41645120" class="c"><input type="checkbox" id="c-41645120" checked=""/><div class="controls bullet"><span class="by">nolist_policy</span><span>|</span><a href="#41641568">root</a><span>|</span><a href="#41644330">parent</a><span>|</span><a href="#41641826">next</a><span>|</span><label class="collapse" for="c-41645120">[-]</label><label class="expand" for="c-41645120">[1 more]</label></div><br/><div class="children"><div class="content">Useful models that allow us to make predictions.</div><br/></div></div></div></div></div></div></div></div><div id="41641826" class="c"><input type="checkbox" id="c-41641826" checked=""/><div class="controls bullet"><span class="by">thatguysaguy</span><span>|</span><a href="#41641568">parent</a><span>|</span><a href="#41642682">prev</a><span>|</span><a href="#41642137">next</a><span>|</span><label class="collapse" for="c-41641826">[-]</label><label class="expand" for="c-41641826">[23 more]</label></div><br/><div class="children"><div class="content">I think it&#x27;s clear that this paper has stood the rest of time over the last 20 years. Our estimates of how much published work fails to replicate or is outright fraudulent have only increased since then.</div><br/><div id="41641946" class="c"><input type="checkbox" id="c-41641946" checked=""/><div class="controls bullet"><span class="by">giantg2</span><span>|</span><a href="#41641568">root</a><span>|</span><a href="#41641826">parent</a><span>|</span><a href="#41641839">next</a><span>|</span><label class="collapse" for="c-41641946">[-]</label><label class="expand" for="c-41641946">[8 more]</label></div><br/><div class="children"><div class="content">[Please consider the following with an open mind]<p>Just because a study doesn&#x27;t replicate, doesn&#x27;t make it false. This is especially true in medicine where the potential global subjects&#x2F;population are very diverse. You can do a small study that <i>suggests further research</i> based on a small sample size, or even a case study. The next study might have a conflicting finding, but that doesn&#x27;t make the first one false - rather a step in the overall process of gaining new information.</div><br/><div id="41642109" class="c"><input type="checkbox" id="c-41642109" checked=""/><div class="controls bullet"><span class="by">llamaimperative</span><span>|</span><a href="#41641568">root</a><span>|</span><a href="#41641946">parent</a><span>|</span><a href="#41642128">next</a><span>|</span><label class="collapse" for="c-41642109">[-]</label><label class="expand" for="c-41642109">[5 more]</label></div><br/><div class="children"><div class="content">I think it&#x27;s much, much more powerful to think of &quot;failure to replicate&quot; as &quot;failure to generalize.&quot;<p>In lieu of <i>actual fraud</i> or a methodological mistake that wasn&#x27;t represented&#x2F;caught in peer review, it&#x27;s still extremely difficult to control for all possible sources of variation. That&#x27;s especially true as you go further &quot;up the stack&quot; from math -&gt; physics -&gt; chem -&gt; bio -&gt; psych -&gt; social. It is absolutely possible to honestly conduct a very high quality experiment with a real finding, but fail to account for something like &quot;on the way here, 80% of participants encountered a frustrating traffic jam.&quot;<p>Their finding could be true for people who just encountered a traffic jam, and lack of replication would be due to an unsuccessful <i>generalization</i> from what they found.</div><br/><div id="41642140" class="c"><input type="checkbox" id="c-41642140" checked=""/><div class="controls bullet"><span class="by">scns</span><span>|</span><a href="#41641568">root</a><span>|</span><a href="#41642109">parent</a><span>|</span><a href="#41642128">next</a><span>|</span><label class="collapse" for="c-41642140">[-]</label><label class="expand" for="c-41642140">[4 more]</label></div><br/><div class="children"><div class="content">Dislike being a pedant but the stack was missing math up front</div><br/><div id="41644988" class="c"><input type="checkbox" id="c-41644988" checked=""/><div class="controls bullet"><span class="by">bakuninsbart</span><span>|</span><a href="#41641568">root</a><span>|</span><a href="#41642140">parent</a><span>|</span><a href="#41642149">next</a><span>|</span><label class="collapse" for="c-41644988">[-]</label><label class="expand" for="c-41644988">[1 more]</label></div><br/><div class="children"><div class="content">Math isn&#x27;t a science, it is a tool we can use to construct coherent arguments. We can do this about our world, which science aims to do, but we can do this about many worlds. We can consider correct deductions within a mathematical system as fact, but they do not represent facts in the &quot;real&quot; world.</div><br/></div></div><div id="41642149" class="c"><input type="checkbox" id="c-41642149" checked=""/><div class="controls bullet"><span class="by">llamaimperative</span><span>|</span><a href="#41641568">root</a><span>|</span><a href="#41642140">parent</a><span>|</span><a href="#41644988">prev</a><span>|</span><a href="#41642128">next</a><span>|</span><label class="collapse" for="c-41642149">[-]</label><label class="expand" for="c-41642149">[2 more]</label></div><br/><div class="children"><div class="content">Haha, math strikes me as a bit different from the others... but I&#x27;ll add it just for you ;)</div><br/><div id="41643544" class="c"><input type="checkbox" id="c-41643544" checked=""/><div class="controls bullet"><span class="by">gopher_space</span><span>|</span><a href="#41641568">root</a><span>|</span><a href="#41642149">parent</a><span>|</span><a href="#41642128">next</a><span>|</span><label class="collapse" for="c-41643544">[-]</label><label class="expand" for="c-41643544">[1 more]</label></div><br/><div class="children"><div class="content">Dislike being a pedant but the stack is missing philosophy up front.</div><br/></div></div></div></div></div></div></div></div><div id="41642128" class="c"><input type="checkbox" id="c-41642128" checked=""/><div class="controls bullet"><span class="by">jahewson</span><span>|</span><a href="#41641568">root</a><span>|</span><a href="#41641946">parent</a><span>|</span><a href="#41642109">prev</a><span>|</span><a href="#41641839">next</a><span>|</span><label class="collapse" for="c-41642128">[-]</label><label class="expand" for="c-41642128">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Just because a study doesn&#x27;t replicate, doesn&#x27;t make it false.<p>But it also doesn’t make it <i>not</i> false. It makes the null hypothesis more likely to be true.</div><br/><div id="41643318" class="c"><input type="checkbox" id="c-41643318" checked=""/><div class="controls bullet"><span class="by">robwwilliams</span><span>|</span><a href="#41641568">root</a><span>|</span><a href="#41642128">parent</a><span>|</span><a href="#41641839">next</a><span>|</span><label class="collapse" for="c-41643318">[-]</label><label class="expand" for="c-41643318">[1 more]</label></div><br/><div class="children"><div class="content">That is certainly one possible interpretation.<p>The other is the introduction or loss of critical cofactors or confounders that radically change environment and context.<p>Think of experiments of certain types before and after COVID-19.</div><br/></div></div></div></div></div></div><div id="41641839" class="c"><input type="checkbox" id="c-41641839" checked=""/><div class="controls bullet"><span class="by">tptacek</span><span>|</span><a href="#41641568">root</a><span>|</span><a href="#41641826">parent</a><span>|</span><a href="#41641946">prev</a><span>|</span><a href="#41642137">next</a><span>|</span><label class="collapse" for="c-41641839">[-]</label><label class="expand" for="c-41641839">[14 more]</label></div><br/><div class="children"><div class="content">Outright research fraud is probably very rare; the cases we&#x27;ve heard about stick out, but people outside of academia usually don&#x27;t have a good intuition for just how vast the annual output of the sciences are. Remember the famous PhD comic, showing how your thesis is going to be an infinitesimal fraction of the work of your field.</div><br/><div id="41641954" class="c"><input type="checkbox" id="c-41641954" checked=""/><div class="controls bullet"><span class="by">kelipso</span><span>|</span><a href="#41641568">root</a><span>|</span><a href="#41641839">parent</a><span>|</span><a href="#41641933">next</a><span>|</span><label class="collapse" for="c-41641954">[-]</label><label class="expand" for="c-41641954">[4 more]</label></div><br/><div class="children"><div class="content">Research fraud is likely very rare but it&#x27;s not about a few stories that show up about unreplicable studies that stick out. There was a study a few years where they tried to replicate a bunch of top cited psychology papers and the majority of the experiments were not replicated. Then people did the same for other disciplines afterwards and, while it wasn&#x27;t as bad as psychology, there were plenty of papers they couldn&#x27;t replicate.</div><br/><div id="41642353" class="c"><input type="checkbox" id="c-41642353" checked=""/><div class="controls bullet"><span class="by">tptacek</span><span>|</span><a href="#41641568">root</a><span>|</span><a href="#41641954">parent</a><span>|</span><a href="#41641933">next</a><span>|</span><label class="collapse" for="c-41642353">[-]</label><label class="expand" for="c-41642353">[3 more]</label></div><br/><div class="children"><div class="content">Every time this topic comes up I&#x27;m reminded of what Stefan Savage, a hero of mine, said about academic papers (&quot;studies&quot;, in the sense we&#x27;re discussing here): they are the beginnings of conversations, not the end. It shouldn&#x27;t shock people that results in papers might not replicate; papers aren&#x27;t infallible, which makes sense when you consider the process that produces them.</div><br/><div id="41644959" class="c"><input type="checkbox" id="c-41644959" checked=""/><div class="controls bullet"><span class="by">oxym0ron</span><span>|</span><a href="#41641568">root</a><span>|</span><a href="#41642353">parent</a><span>|</span><a href="#41643343">next</a><span>|</span><label class="collapse" for="c-41644959">[-]</label><label class="expand" for="c-41644959">[1 more]</label></div><br/><div class="children"><div class="content">Yes, papers start conversations, not end them. Replication issues are part of the academic process.</div><br/></div></div><div id="41643343" class="c"><input type="checkbox" id="c-41643343" checked=""/><div class="controls bullet"><span class="by">robwwilliams</span><span>|</span><a href="#41641568">root</a><span>|</span><a href="#41642353">parent</a><span>|</span><a href="#41644959">prev</a><span>|</span><a href="#41641933">next</a><span>|</span><label class="collapse" for="c-41643343">[-]</label><label class="expand" for="c-41643343">[1 more]</label></div><br/><div class="children"><div class="content">That is a generous interpretation. But in many cases we try our best to dress up studies and tell good stories—-preferably stories with compelling positive statistics and with slick figures. The story telling often obscures the key data.</div><br/></div></div></div></div></div></div><div id="41641933" class="c"><input type="checkbox" id="c-41641933" checked=""/><div class="controls bullet"><span class="by">dekhn</span><span>|</span><a href="#41641568">root</a><span>|</span><a href="#41641839">parent</a><span>|</span><a href="#41641954">prev</a><span>|</span><a href="#41642137">next</a><span>|</span><label class="collapse" for="c-41641933">[-]</label><label class="expand" for="c-41641933">[9 more]</label></div><br/><div class="children"><div class="content">Is incompetence fraud?  Or just incompetence?  I&#x27;m asking because a fair number of the molecular biologists who get caught by Elizabeth Bik for copy&#x2F;pasting images of gels insist they just made honest mistakes (with some commentary about the atrocious nature of record-keeping in modern biology).<p>I alter Ionnides&#x27;s conclusion to be instead: &quot;Roughly 50% of papers in quantitative biological sciences contain at least one error serious enough to invalidate the conclusion&quot; and &quot;Roughly 75% of really interesting papers are missing at least one load-bearing method detail that reproducers must figure out on their own&quot; (my own personal observations of the literature are consistent with these rates; I was always flabbergasted at people who just took Figure 3 as correct).</div><br/><div id="41641993" class="c"><input type="checkbox" id="c-41641993" checked=""/><div class="controls bullet"><span class="by">kelipso</span><span>|</span><a href="#41641568">root</a><span>|</span><a href="#41641933">parent</a><span>|</span><a href="#41642759">next</a><span>|</span><label class="collapse" for="c-41641993">[-]</label><label class="expand" for="c-41641993">[4 more]</label></div><br/><div class="children"><div class="content">There is no one hovering over scientists all the time ready to stick a hot poker in them when they make a mistake or get careless. I was in academia and my impression is there is a reluctance to double and triple check results to make sure they are right as long as the results match your instincts, whether it&#x27;s time pressure, laziness, bias, or just being human.</div><br/><div id="41642306" class="c"><input type="checkbox" id="c-41642306" checked=""/><div class="controls bullet"><span class="by">dekhn</span><span>|</span><a href="#41641568">root</a><span>|</span><a href="#41641993">parent</a><span>|</span><a href="#41642759">next</a><span>|</span><label class="collapse" for="c-41642306">[-]</label><label class="expand" for="c-41642306">[3 more]</label></div><br/><div class="children"><div class="content">At least in my own mental model of publishing a paper (I&#x27;ve published only a few), I&#x27;d want my coauthors to stick hot pokers in my if I made a mistake or got careless.  But then, my entire thesis was driven by a reproducible Makefile that downloaded the latest results from a supercomputer, re-ran the whole analysis, and wrote the latex necessary (at least partly to avoid making trivial mistakes).  It was clear everything I was doing was just getting in the way of publishing high prestige papers.</div><br/><div id="41643387" class="c"><input type="checkbox" id="c-41643387" checked=""/><div class="controls bullet"><span class="by">robwwilliams</span><span>|</span><a href="#41641568">root</a><span>|</span><a href="#41642306">parent</a><span>|</span><a href="#41642759">next</a><span>|</span><label class="collapse" for="c-41643387">[-]</label><label class="expand" for="c-41643387">[2 more]</label></div><br/><div class="children"><div class="content">All too easy to understand your situation. NIH is finally but slowly waking up and is imposing more “onerous” (aka: essential and correct) data management and sharing (DMS) document. Every grant applicant now submits following these guidelines:<p><a href="https:&#x2F;&#x2F;grants.nih.gov&#x2F;grants&#x2F;guide&#x2F;notice-files&#x2F;NOT-OD-24-175.html" rel="nofollow">https:&#x2F;&#x2F;grants.nih.gov&#x2F;grants&#x2F;guide&#x2F;notice-files&#x2F;NOT-OD-24-1...</a><p>Unfortunately, not all NIH institutes understand how to evaluate and moderate this key new policy. Oddly enough the peer reviewers do NOT have access to DMS plans as of this year.</div><br/><div id="41645033" class="c"><input type="checkbox" id="c-41645033" checked=""/><div class="controls bullet"><span class="by">IG_Semmelweiss</span><span>|</span><a href="#41641568">root</a><span>|</span><a href="#41643387">parent</a><span>|</span><a href="#41642759">next</a><span>|</span><label class="collapse" for="c-41645033">[-]</label><label class="expand" for="c-41645033">[1 more]</label></div><br/><div class="children"><div class="content">Is this a process whereby the researcher is forced to submit the thesis (null, etc) of the research, ahead of the study and its findings?</div><br/></div></div></div></div></div></div></div></div><div id="41642759" class="c"><input type="checkbox" id="c-41642759" checked=""/><div class="controls bullet"><span class="by">kelnos</span><span>|</span><a href="#41641568">root</a><span>|</span><a href="#41641933">parent</a><span>|</span><a href="#41641993">prev</a><span>|</span><a href="#41642115">next</a><span>|</span><label class="collapse" for="c-41642759">[-]</label><label class="expand" for="c-41642759">[3 more]</label></div><br/><div class="children"><div class="content">&gt; <i>Is incompetence fraud? Or just incompetence?</i><p>Fraud requires intent; it&#x27;s a word that describes what happened, but also the motivations of the people involved.  Incompetence doesn&#x27;t assume any intent at all; it&#x27;s merely a description of the (lack of) ability of the people involved.<p>Incompetent people can certainly commit fraud (perhaps to try to cover up their incompetence), but that&#x27;s by no means required.<p>&gt; <i>...insist they just made honest mistakes</i><p>If they&#x27;re lying about that, it&#x27;s fraud; they&#x27;re either covering up their unrealized incompetence with fraud, or trying to cover up their intended fraud with protestations of mere incompetence.  If they really did make honest mistakes, then it&#x27;s just garden-variety incompetence.  (Or just... mistakes.  To me, incompetence is when someone consistently makes mistakes often.  One-time or few-time mistakes are just things that happen to people, no matter how good the are at what they do.)</div><br/><div id="41644891" class="c"><input type="checkbox" id="c-41644891" checked=""/><div class="controls bullet"><span class="by">dataviz</span><span>|</span><a href="#41641568">root</a><span>|</span><a href="#41642759">parent</a><span>|</span><a href="#41643471">next</a><span>|</span><label class="collapse" for="c-41644891">[-]</label><label class="expand" for="c-41644891">[1 more]</label></div><br/><div class="children"><div class="content">People often use incompetence as an excuse for what were actually intentional bad decisions. Never attribute to malice that which is adequately explained by stupidity.<p>Maybe someone was incompetent but also knew they were cutting corners. Should they get a pass because they claim they didn&#x27;t mean to do it? We should hold people accountable regardless of intent.</div><br/></div></div><div id="41643471" class="c"><input type="checkbox" id="c-41643471" checked=""/><div class="controls bullet"><span class="by">pfdietz</span><span>|</span><a href="#41641568">root</a><span>|</span><a href="#41642759">parent</a><span>|</span><a href="#41644891">prev</a><span>|</span><a href="#41642115">next</a><span>|</span><label class="collapse" for="c-41643471">[-]</label><label class="expand" for="c-41643471">[1 more]</label></div><br/><div class="children"><div class="content">The legal phrase I like is &quot;knew or should have known&quot;.  If there is a situation where you should have known something was wrong, it&#x27;s as bad as if you really knew it was wrong.   To hold otherwise incentivizes willful blindness and plausible deniability.</div><br/></div></div></div></div><div id="41642115" class="c"><input type="checkbox" id="c-41642115" checked=""/><div class="controls bullet"><span class="by">llamaimperative</span><span>|</span><a href="#41641568">root</a><span>|</span><a href="#41641933">parent</a><span>|</span><a href="#41642759">prev</a><span>|</span><a href="#41642137">next</a><span>|</span><label class="collapse" for="c-41642115">[-]</label><label class="expand" for="c-41642115">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I&#x27;m asking because a fair number of the molecular biologists who get caught by Elizabeth Bik for copy&#x2F;pasting images of gels insist they just made honest mistakes<p>You&#x27;re talking about (almost certainly) fraudsters denying they committed fraud. The vast majority of non-replicable results have nothing to do with these types of errors, purposeful or not.</div><br/></div></div></div></div></div></div></div></div><div id="41642137" class="c"><input type="checkbox" id="c-41642137" checked=""/><div class="controls bullet"><span class="by">a_bonobo</span><span>|</span><a href="#41641568">parent</a><span>|</span><a href="#41641826">prev</a><span>|</span><a href="#41644397">next</a><span>|</span><label class="collapse" for="c-41642137">[-]</label><label class="expand" for="c-41642137">[1 more]</label></div><br/><div class="children"><div class="content">I remember criticism back from when this paper first came out: it went something like &#x27;all this shows that using maths it is possible to construct a world where most published research findings are false.&#x27;</div><br/></div></div><div id="41644397" class="c"><input type="checkbox" id="c-41644397" checked=""/><div class="controls bullet"><span class="by">InDubioProRubio</span><span>|</span><a href="#41641568">parent</a><span>|</span><a href="#41642137">prev</a><span>|</span><a href="#41643021">next</a><span>|</span><label class="collapse" for="c-41644397">[-]</label><label class="expand" for="c-41644397">[1 more]</label></div><br/><div class="children"><div class="content">Could one filter for the true research, by searching for &quot;outliers&quot; which are not outliars, aka data that does not fit the ruling narrative, but at the same time has no narrative of its own?</div><br/></div></div><div id="41643021" class="c"><input type="checkbox" id="c-41643021" checked=""/><div class="controls bullet"><span class="by">throwoutway</span><span>|</span><a href="#41641568">parent</a><span>|</span><a href="#41644397">prev</a><span>|</span><a href="#41642265">next</a><span>|</span><label class="collapse" for="c-41643021">[-]</label><label class="expand" for="c-41643021">[2 more]</label></div><br/><div class="children"><div class="content">&gt; But things are different in other fields.<p>Everyone claims its different in their field</div><br/><div id="41643212" class="c"><input type="checkbox" id="c-41643212" checked=""/><div class="controls bullet"><span class="by">singleshot_</span><span>|</span><a href="#41641568">root</a><span>|</span><a href="#41643021">parent</a><span>|</span><a href="#41642265">next</a><span>|</span><label class="collapse" for="c-41643212">[-]</label><label class="expand" for="c-41643212">[1 more]</label></div><br/><div class="children"><div class="content">Strangely, we don&#x27;t in my field!</div><br/></div></div></div></div></div></div><div id="41642265" class="c"><input type="checkbox" id="c-41642265" checked=""/><div class="controls bullet"><span class="by">SideQuark</span><span>|</span><a href="#41641568">prev</a><span>|</span><a href="#41641525">next</a><span>|</span><label class="collapse" for="c-41642265">[-]</label><label class="expand" for="c-41642265">[1 more]</label></div><br/><div class="children"><div class="content">This paper, almost 20 years old, has plenty of follow-up work showing the claims in this original paper aren’t true.<p>One simple angle is Ioannidis simply makes up some parameters to show things could be bad. Later empirical work measuring those parameters found Ioannidis off by orders of magnitude.<p>One example <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1301.3718" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1301.3718</a><p>There’s ample other published papers showing other holes in the claims.<p><a href="https:&#x2F;&#x2F;scholar.google.com&#x2F;scholar?cites=15681017780418799273&amp;as_sdt=800005&amp;sciodt=0,15&amp;hl=en" rel="nofollow">https:&#x2F;&#x2F;scholar.google.com&#x2F;scholar?cites=1568101778041879927...</a><p>Google scholar papers citing this</div><br/></div></div><div id="41641525" class="c"><input type="checkbox" id="c-41641525" checked=""/><div class="controls bullet"><span class="by">vouaobrasil</span><span>|</span><a href="#41642265">prev</a><span>|</span><a href="#41642558">next</a><span>|</span><label class="collapse" for="c-41641525">[-]</label><label class="expand" for="c-41641525">[2 more]</label></div><br/><div class="children"><div class="content">&gt;  In this framework, a research finding is less likely to be true [...] where there is greater flexibility in designs, definitions, outcomes, and analytical modes<p>It&#x27;s worth noting though that in many research fields, teasing out the correct hypotheses and all affecting factors are difficult. And, sometimes it takes quite a few studies before the right definitions are even found; definitions which are a prerequisite to make a useful hypothesis. Thus, one cannot ignore the usefulness of approximation in scientific experiments, not only to the truth, but to the right questions to ask.<p>Not saying that all biases are inherent in the study of sciences, but the paper cited seems to take it for granted that a lot of science is still groping around in the dark, and to expect well-defined studies every time is simply unreasonable.</div><br/><div id="41641642" class="c"><input type="checkbox" id="c-41641642" checked=""/><div class="controls bullet"><span class="by">3np</span><span>|</span><a href="#41641525">parent</a><span>|</span><a href="#41642558">next</a><span>|</span><label class="collapse" for="c-41641642">[-]</label><label class="expand" for="c-41641642">[1 more]</label></div><br/><div class="children"><div class="content">This is only meaningful if &quot;the replicaton crisis&quot; is systematically addressed.</div><br/></div></div></div></div><div id="41642558" class="c"><input type="checkbox" id="c-41642558" checked=""/><div class="controls bullet"><span class="by">dang</span><span>|</span><a href="#41641525">prev</a><span>|</span><a href="#41641937">next</a><span>|</span><label class="collapse" for="c-41642558">[-]</label><label class="expand" for="c-41642558">[2 more]</label></div><br/><div class="children"><div class="content">Related. Others?<p><i>Why most published research findings are false (2005)</i> - <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37520930">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37520930</a> - Sept 2023 (2 comments)<p><i>Why most published research findings are false (2005)</i> - <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=33265439">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=33265439</a> - Oct 2022 (80 comments)<p><i>Why Most Published Research Findings Are False (2005)</i> - <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=18106679">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=18106679</a> - Sept 2018 (40 comments)<p><i>Why Most Published Research Findings Are False</i> - <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=8340405">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=8340405</a> - Sept 2014 (2 comments)<p><i>Why Most Published Research Findings Are False</i> - <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=1825007">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=1825007</a> - Oct 2010 (40 comments)<p><i>Why Most Published Research Findings Are False (2005)</i> - <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=833879">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=833879</a> - Sept 2009 (2 comments)</div><br/><div id="41642901" class="c"><input type="checkbox" id="c-41642901" checked=""/><div class="controls bullet"><span class="by">cb321</span><span>|</span><a href="#41642558">parent</a><span>|</span><a href="#41641937">next</a><span>|</span><label class="collapse" for="c-41642901">[-]</label><label class="expand" for="c-41642901">[1 more]</label></div><br/><div class="children"><div class="content">As clarification, the article linked in the subject is dated 2022 BUT it is actually just &quot;a correction&quot; of the very famous 2005 article.   The correction is eentsy-weentsy - just a missing pair of parenthesis if you click through:<p><pre><code>    There is an error in Table 2. A set of parentheses is missing in the equation for Research Finding = Yes and True Relationship = No. Please see the correct Table 2 here.</code></pre></div><br/></div></div></div></div><div id="41641937" class="c"><input type="checkbox" id="c-41641937" checked=""/><div class="controls bullet"><span class="by">tombert</span><span>|</span><a href="#41642558">prev</a><span>|</span><a href="#41642294">next</a><span>|</span><label class="collapse" for="c-41641937">[-]</label><label class="expand" for="c-41641937">[47 more]</label></div><br/><div class="children"><div class="content">As I’ve transitioned to more exploratory and researchy roles in my career, I have started to understand the science fraudsters like Jan Hendrik Schön.<p>When you spent an entire week working on a test or experiment that you <i>know</i> should work, at least if you give it enough time, but it isn’t for whatever reason, it can be extremely tempting to invent the numbers that you think it should be, especially if your employer is pressuring you for a result. Now, obviously, reason we run these tests is precisely because we <i>don’t</i> actually know what the results will be, but that’s sometimes more obvious in hindsight.<p>Obviously it’s wrong, and I haven’t done it, but I would be lying if I said that the thought hadn’t crossed my mind.</div><br/><div id="41642018" class="c"><input type="checkbox" id="c-41642018" checked=""/><div class="controls bullet"><span class="by">bluefirebrand</span><span>|</span><a href="#41641937">parent</a><span>|</span><a href="#41642020">next</a><span>|</span><label class="collapse" for="c-41642018">[-]</label><label class="expand" for="c-41642018">[25 more]</label></div><br/><div class="children"><div class="content">&gt; When you spent an entire week working on a test or experiment that you know should work<p>I thought the whole point of doing experiments was to challenge what we &quot;know&quot; so we can refine our understanding?</div><br/><div id="41642057" class="c"><input type="checkbox" id="c-41642057" checked=""/><div class="controls bullet"><span class="by">llamaimperative</span><span>|</span><a href="#41641937">root</a><span>|</span><a href="#41642018">parent</a><span>|</span><a href="#41644811">next</a><span>|</span><label class="collapse" for="c-41642057">[-]</label><label class="expand" for="c-41642057">[15 more]</label></div><br/><div class="children"><div class="content">Sure in la-la-land where science isn&#x27;t conducted by humans.<p>In reality, scientists are highly motivated (i.e. biased) individuals like anyone else. Therefore science cannot be done effectively by individuals.<p>The system that derives truth from experiments - the actual scientific system - is the competitive dynamic between scientists who are trying to tarnish each others&#x27; legacies and bolster their own. The scientific method etc. primarily makes scientific claims scrutinizable in detail, but without scrutiny they are still <i>highly</i> liable to produce false information.</div><br/><div id="41642737" class="c"><input type="checkbox" id="c-41642737" checked=""/><div class="controls bullet"><span class="by">hiimkeks</span><span>|</span><a href="#41641937">root</a><span>|</span><a href="#41642057">parent</a><span>|</span><a href="#41643286">next</a><span>|</span><label class="collapse" for="c-41642737">[-]</label><label class="expand" for="c-41642737">[4 more]</label></div><br/><div class="children"><div class="content">A bit of a nitpick, but...<p>&gt; The system that derives truth from experiments - the actual scientific system...<p>Yes!<p>&gt; ... is the competitive dynamic between scientists who are trying to tarnish each others&#x27; legacies and bolster their own.<p>Hm. To some degree, sure, that is one dynamic, but (a) this leads to&#x2F;presupposes a truckload of perverse incentives and (b) this is not inherent in the system if we rearrange incentives</div><br/><div id="41642960" class="c"><input type="checkbox" id="c-41642960" checked=""/><div class="controls bullet"><span class="by">llamaimperative</span><span>|</span><a href="#41641937">root</a><span>|</span><a href="#41642737">parent</a><span>|</span><a href="#41643192">next</a><span>|</span><label class="collapse" for="c-41642960">[-]</label><label class="expand" for="c-41642960">[2 more]</label></div><br/><div class="children"><div class="content">Do you have an idea for a better one? It is pretty darn close to natural selection, which while ugly, <i>does</i> produce surprisingly good results in many domains.<p>Of course the <i>implementation</i> is far from perfect. For example, the interaction between impact factor and grant funding produces pressure toward ideological conformity <i>and</i> excessive analytical “creativity”. But the underlying principle of competitive scrutiny is probably a desirable one.</div><br/><div id="41644322" class="c"><input type="checkbox" id="c-41644322" checked=""/><div class="controls bullet"><span class="by">komali2</span><span>|</span><a href="#41641937">root</a><span>|</span><a href="#41642960">parent</a><span>|</span><a href="#41643192">next</a><span>|</span><label class="collapse" for="c-41644322">[-]</label><label class="expand" for="c-41644322">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Do you have an idea for a better one? It is pretty darn close to natural selection, which while ugly, does produce surprisingly good results in many domains.<p>Cooperation is also an extremely fit behavior in natural selection.</div><br/></div></div></div></div><div id="41643192" class="c"><input type="checkbox" id="c-41643192" checked=""/><div class="controls bullet"><span class="by">jtc331</span><span>|</span><a href="#41641937">root</a><span>|</span><a href="#41642737">parent</a><span>|</span><a href="#41642960">prev</a><span>|</span><a href="#41643286">next</a><span>|</span><label class="collapse" for="c-41643192">[-]</label><label class="expand" for="c-41643192">[1 more]</label></div><br/><div class="children"><div class="content">How do you eliminate the personal incentive to have found a meaningful result? I don’t think that can be changed without redesigning the human psyche.</div><br/></div></div></div></div><div id="41643286" class="c"><input type="checkbox" id="c-41643286" checked=""/><div class="controls bullet"><span class="by">6510</span><span>|</span><a href="#41641937">root</a><span>|</span><a href="#41642057">parent</a><span>|</span><a href="#41642737">prev</a><span>|</span><a href="#41642612">next</a><span>|</span><label class="collapse" for="c-41643286">[-]</label><label class="expand" for="c-41643286">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Sure in la-la-land where science isn&#x27;t conducted by humans.<p>If someone has a large bag of money laying around the plan is this:<p>There are lots of companies that will run material A though machine B for you. There are a lot of science machines. One is to put a lot of them into a large building and make a web page where one can order the processing of substances in a kind of <i>design your own rube goldberg machine</i>.<p>It can start with all purchasable liquids and gasses, mixing, drying, heating, freezing, distilling etc and measure color, weight, volume, viscosity, nuclear resonance etc, microscope video, etc. Have as much automation as possible, collect all the machines. A robot cocktail bar basically.<p>Work your way up to assembling special contraptions all ordered though the gui.<p>Jim can have x samples of his special cement mixture mixed and strength tested. Jack can have his cold fusion cells assembled. Stanley can have his water powered combustion engine. Howard can have his motor powered by magnets. Veljko can have his gravity powered engine. Thomas can have his electrogravitics. Wilhelm can have his orgone energy.<p>or not... hah....<p>If any people are involved they should not know what they are working on.<p>It wont be cheap but then you get an url with your nice little test report and opinions be damned.</div><br/></div></div><div id="41642215" class="c"><input type="checkbox" id="c-41642215" checked=""/><div class="controls bullet"><span class="by">wredue</span><span>|</span><a href="#41641937">root</a><span>|</span><a href="#41642057">parent</a><span>|</span><a href="#41642612">prev</a><span>|</span><a href="#41644811">next</a><span>|</span><label class="collapse" for="c-41642215">[-]</label><label class="expand" for="c-41642215">[8 more]</label></div><br/><div class="children"><div class="content">And yet, it is still the best we got for also producing highly reliable and correct information.<p>Personally, I think the “highly” in your statement is quite over exaggerated. Humans can be convinced to produce bad science, for sure, and there are even journals set up by religious orgs that specifically exist to do just that.<p>But at the same time, science landed humans on the moon.</div><br/><div id="41642728" class="c"><input type="checkbox" id="c-41642728" checked=""/><div class="controls bullet"><span class="by">kelnos</span><span>|</span><a href="#41641937">root</a><span>|</span><a href="#41642215">parent</a><span>|</span><a href="#41643013">next</a><span>|</span><label class="collapse" for="c-41642728">[-]</label><label class="expand" for="c-41642728">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>Personally, I think the “highly” in your statement is quite over exaggerated.</i><p>Except that the entire point of the article here is that it&#x27;s <i>not</i> exaggerated.<p>&gt; <i>But at the same time, science landed humans on the moon.</i><p>Cherry-picking a highly successful, well-known example doesn&#x27;t prove a point.</div><br/></div></div><div id="41643013" class="c"><input type="checkbox" id="c-41643013" checked=""/><div class="controls bullet"><span class="by">mcmoor</span><span>|</span><a href="#41641937">root</a><span>|</span><a href="#41642215">parent</a><span>|</span><a href="#41642728">prev</a><span>|</span><a href="#41643017">next</a><span>|</span><label class="collapse" for="c-41643013">[-]</label><label class="expand" for="c-41643013">[4 more]</label></div><br/><div class="children"><div class="content">This is what makes me troubled regarding medical science. I&#x27;ve heard tons of things about fraud and unreproducible results but new wonder drugs (that actually worked!) are deployed every year.</div><br/><div id="41643109" class="c"><input type="checkbox" id="c-41643109" checked=""/><div class="controls bullet"><span class="by">llamaimperative</span><span>|</span><a href="#41641937">root</a><span>|</span><a href="#41643013">parent</a><span>|</span><a href="#41643017">next</a><span>|</span><label class="collapse" for="c-41643109">[-]</label><label class="expand" for="c-41643109">[3 more]</label></div><br/><div class="children"><div class="content">Clinical trials in general are <i>extremely</i>, extremely above board. The level of scrutiny is extreme, and the stakes are unbelievably high for pharma companies and the individuals involved. There are better ways for an unscrupulous pharma co to gain an edge.<p>That said, wonder drugs are few and far between. The GLPs are at least a once-in-a-decade breakthrough, so that’s probably most of the noise you’re hearing (there are a lot of brand names already).</div><br/><div id="41643200" class="c"><input type="checkbox" id="c-41643200" checked=""/><div class="controls bullet"><span class="by">jtc331</span><span>|</span><a href="#41641937">root</a><span>|</span><a href="#41643109">parent</a><span>|</span><a href="#41643017">next</a><span>|</span><label class="collapse" for="c-41643200">[-]</label><label class="expand" for="c-41643200">[2 more]</label></div><br/><div class="children"><div class="content">What about Vioxx?</div><br/><div id="41643251" class="c"><input type="checkbox" id="c-41643251" checked=""/><div class="controls bullet"><span class="by">llamaimperative</span><span>|</span><a href="#41641937">root</a><span>|</span><a href="#41643200">parent</a><span>|</span><a href="#41643017">next</a><span>|</span><label class="collapse" for="c-41643251">[-]</label><label class="expand" for="c-41643251">[1 more]</label></div><br/><div class="children"><div class="content">&gt; in general<p>No one is under the illusion it’s perfect or ungameable. A drug slipping by every few years is bad and often tragic, but IMO nowhere close to indicative of a systematic problem. It is a system that is worthy of a high degree of trust.</div><br/></div></div></div></div></div></div></div></div><div id="41643017" class="c"><input type="checkbox" id="c-41643017" checked=""/><div class="controls bullet"><span class="by">parodysbird</span><span>|</span><a href="#41641937">root</a><span>|</span><a href="#41642215">parent</a><span>|</span><a href="#41643013">prev</a><span>|</span><a href="#41642850">next</a><span>|</span><label class="collapse" for="c-41643017">[-]</label><label class="expand" for="c-41643017">[1 more]</label></div><br/><div class="children"><div class="content">&gt; But at the same time, science landed humans on the moon.<p>That was engineering. Closely linked to science, but not the same process of inquiry.</div><br/></div></div><div id="41642850" class="c"><input type="checkbox" id="c-41642850" checked=""/><div class="controls bullet"><span class="by">EGreg</span><span>|</span><a href="#41641937">root</a><span>|</span><a href="#41642215">parent</a><span>|</span><a href="#41643017">prev</a><span>|</span><a href="#41644811">next</a><span>|</span><label class="collapse" for="c-41642850">[-]</label><label class="expand" for="c-41642850">[1 more]</label></div><br/><div class="children"><div class="content">No, we have better systems now</div><br/></div></div></div></div></div></div><div id="41644811" class="c"><input type="checkbox" id="c-41644811" checked=""/><div class="controls bullet"><span class="by">_fizz_buzz_</span><span>|</span><a href="#41641937">root</a><span>|</span><a href="#41642018">parent</a><span>|</span><a href="#41642057">prev</a><span>|</span><a href="#41642556">next</a><span>|</span><label class="collapse" for="c-41644811">[-]</label><label class="expand" for="c-41644811">[1 more]</label></div><br/><div class="children"><div class="content">Setting up real experiments in a lab is super hard e.g. is all equipment properly calibrated, is the way I am measuring actually right, are my reference measurements correct, are my samples &quot;clean&quot;. A lot of things can go wrong that it is even sometimes challenging to replicate experiments that are 100% known to work. So, it takes some discipline to not cheat in the sense that e.g. one cleans up the data a bit too much.</div><br/></div></div><div id="41642556" class="c"><input type="checkbox" id="c-41642556" checked=""/><div class="controls bullet"><span class="by">tombert</span><span>|</span><a href="#41641937">root</a><span>|</span><a href="#41642018">parent</a><span>|</span><a href="#41644811">prev</a><span>|</span><a href="#41643814">next</a><span>|</span><label class="collapse" for="c-41642556">[-]</label><label class="expand" for="c-41642556">[3 more]</label></div><br/><div class="children"><div class="content">In theory, but it is extremely easy to get into the mindset that your hypothesis is absolutely true, and as such your goal is to prove that hypothesis.<p>I’ve never fabricated numbers for anything I’ve done, but there certainly have been times where I thought about it, usually after the fourth or fifth broken multi-hour test, especially if the test breakage doesn’t directly contradict the hypothesis.</div><br/><div id="41644019" class="c"><input type="checkbox" id="c-41644019" checked=""/><div class="controls bullet"><span class="by">thayne</span><span>|</span><a href="#41641937">root</a><span>|</span><a href="#41642556">parent</a><span>|</span><a href="#41642955">next</a><span>|</span><label class="collapse" for="c-41644019">[-]</label><label class="expand" for="c-41644019">[1 more]</label></div><br/><div class="children"><div class="content">Maybe it&#x27;s different in other fields, but from my background in physics it seems like if your hypothesis is wrong that is usually way more interesting than it being right. As long as it isn&#x27;t just because of some contamination in the data.<p>Although, contrary to what I was taught in elementary school, most of the experiments in the physics department of my university didn&#x27;t even really have a hypothesis. They were usually either of the form &quot;we are going to do this thing, and see what happens&quot;, or &quot;we&#x27;re going to measure this thing more accurately than anyone before&quot;.</div><br/></div></div><div id="41642955" class="c"><input type="checkbox" id="c-41642955" checked=""/><div class="controls bullet"><span class="by">DiggyJohnson</span><span>|</span><a href="#41641937">root</a><span>|</span><a href="#41642556">parent</a><span>|</span><a href="#41644019">prev</a><span>|</span><a href="#41643814">next</a><span>|</span><label class="collapse" for="c-41642955">[-]</label><label class="expand" for="c-41642955">[1 more]</label></div><br/><div class="children"><div class="content">Thanks for staying your point so clearly. I’m a bystander to this discussion, but agree with you about the reality of this.</div><br/></div></div></div></div><div id="41643814" class="c"><input type="checkbox" id="c-41643814" checked=""/><div class="controls bullet"><span class="by">kqr</span><span>|</span><a href="#41641937">root</a><span>|</span><a href="#41642018">parent</a><span>|</span><a href="#41642556">prev</a><span>|</span><a href="#41642576">next</a><span>|</span><label class="collapse" for="c-41643814">[-]</label><label class="expand" for="c-41643814">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s a valid way to look at it, but Fisher (who all but invented hypothesis testing) took a different perspective. To him, most things we know because of informal experiences. Only when trying to find small effects or when we have insufficient experience do we conduct experiments, which are effectively experience meticulously planned in advance.<p>A significant result in an experiment, according to Fisher, is just an experience to add to the mental pros-and-cons list. It is not defintive proof of anything.</div><br/></div></div><div id="41642576" class="c"><input type="checkbox" id="c-41642576" checked=""/><div class="controls bullet"><span class="by">ants_everywhere</span><span>|</span><a href="#41641937">root</a><span>|</span><a href="#41642018">parent</a><span>|</span><a href="#41643814">prev</a><span>|</span><a href="#41642051">next</a><span>|</span><label class="collapse" for="c-41642576">[-]</label><label class="expand" for="c-41642576">[1 more]</label></div><br/><div class="children"><div class="content">There are externally motivated scientists who are in it for the prestige or awards. Some fields are more like this than others, but they show up in all fields.<p>Plus these days there&#x27;s a lot of pressure to run universities more like businesses. To eat, academics have to hit certain numbers, so you see behaviors common in business like faking the KPIs.</div><br/></div></div><div id="41642051" class="c"><input type="checkbox" id="c-41642051" checked=""/><div class="controls bullet"><span class="by">MathMonkeyMan</span><span>|</span><a href="#41641937">root</a><span>|</span><a href="#41642018">parent</a><span>|</span><a href="#41642576">prev</a><span>|</span><a href="#41642515">next</a><span>|</span><label class="collapse" for="c-41642051">[-]</label><label class="expand" for="c-41642051">[1 more]</label></div><br/><div class="children"><div class="content">Because of that, backing up a claim with research adds weight to the claim.<p>If the claim is false, though, you can still sometimes get research to support it. If you or the researcher stands to profit from the false claim, then there is a conflict of interest.</div><br/></div></div><div id="41642515" class="c"><input type="checkbox" id="c-41642515" checked=""/><div class="controls bullet"><span class="by">SilasX</span><span>|</span><a href="#41641937">root</a><span>|</span><a href="#41642018">parent</a><span>|</span><a href="#41642051">prev</a><span>|</span><a href="#41642062">next</a><span>|</span><label class="collapse" for="c-41642515">[-]</label><label class="expand" for="c-41642515">[1 more]</label></div><br/><div class="children"><div class="content">I think that’s what the parent is acknowledging in the end of the second paragraph.</div><br/></div></div><div id="41642062" class="c"><input type="checkbox" id="c-41642062" checked=""/><div class="controls bullet"><span class="by">renewiltord</span><span>|</span><a href="#41641937">root</a><span>|</span><a href="#41642018">parent</a><span>|</span><a href="#41642515">prev</a><span>|</span><a href="#41642020">next</a><span>|</span><label class="collapse" for="c-41642062">[-]</label><label class="expand" for="c-41642062">[1 more]</label></div><br/><div class="children"><div class="content">Well, that depends. What are you paying the guy to do?</div><br/></div></div></div></div><div id="41642020" class="c"><input type="checkbox" id="c-41642020" checked=""/><div class="controls bullet"><span class="by">pragmomm</span><span>|</span><a href="#41641937">parent</a><span>|</span><a href="#41642018">prev</a><span>|</span><a href="#41642634">next</a><span>|</span><label class="collapse" for="c-41642020">[-]</label><label class="expand" for="c-41642020">[17 more]</label></div><br/><div class="children"><div class="content">You should also understand that there are external forces here, like state sponsorships that monetarily rewards for scientists to simply file enough research findings.<p>The startling rise in the publication of sham science papers has its roots in China, where young doctors and scientists seeking promotion were required to have published scientific papers. Shadow organisations – known as “paper mills” – began to supply fabricated work for publication in journals there.
<a href="https:&#x2F;&#x2F;www.theguardian.com&#x2F;science&#x2F;2024&#x2F;feb&#x2F;03&#x2F;the-situation-has-become-appalling-fake-scientific-papers-push-research-credibility-to-crisis-point" rel="nofollow">https:&#x2F;&#x2F;www.theguardian.com&#x2F;science&#x2F;2024&#x2F;feb&#x2F;03&#x2F;the-situatio...</a><p>The number of retractions issued for research articles in 2023 has passed 10,000 — smashing annual records — as publishers struggle to clean up a slew of sham papers and peer-review fraud. Among large research-producing nations, Saudi Arabia, Pakistan, Russia and China have the highest retraction rates over the past two decades, a Nature analysis has found. <a href="https:&#x2F;&#x2F;www.nature.com&#x2F;articles&#x2F;d41586-023-03974-8" rel="nofollow">https:&#x2F;&#x2F;www.nature.com&#x2F;articles&#x2F;d41586-023-03974-8</a><p>That&#x27;s why a recent article <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=41607430">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=41607430</a>, where the measurement of China leads world in 57 of 64 critical technologies was based on number of journal citations, was laughable.</div><br/><div id="41642116" class="c"><input type="checkbox" id="c-41642116" checked=""/><div class="controls bullet"><span class="by">a_bonobo</span><span>|</span><a href="#41641937">root</a><span>|</span><a href="#41642020">parent</a><span>|</span><a href="#41642176">next</a><span>|</span><label class="collapse" for="c-41642116">[-]</label><label class="expand" for="c-41642116">[2 more]</label></div><br/><div class="children"><div class="content">Talking with some Chinese colleagues in the past, they were talking about having a &#x27;base&#x27; salary which was not enough to have a family on. For every published paper they&#x27;d get a one-time payment. So you&#x27;d have to get a bunch of papers out every year just to survive; no wonder people start to invent papers.<p>Of course the same thing is happening in the &#x27;Western&#x27; world too, with a publication ratchet going on. New hire has 50 papers out? OK! The next pool of potential hires has 50, 55, 52 papers out, so obviously you take the 55 papers-person. You want outstanding people! Then the next hire needs 60 papers. And so on.</div><br/><div id="41642897" class="c"><input type="checkbox" id="c-41642897" checked=""/><div class="controls bullet"><span class="by">nativeit</span><span>|</span><a href="#41641937">root</a><span>|</span><a href="#41642116">parent</a><span>|</span><a href="#41642176">next</a><span>|</span><label class="collapse" for="c-41642897">[-]</label><label class="expand" for="c-41642897">[1 more]</label></div><br/><div class="children"><div class="content">...an effect known as &quot;wonkflation&quot;.</div><br/></div></div></div></div><div id="41642176" class="c"><input type="checkbox" id="c-41642176" checked=""/><div class="controls bullet"><span class="by">resoluteteeth</span><span>|</span><a href="#41641937">root</a><span>|</span><a href="#41642020">parent</a><span>|</span><a href="#41642116">prev</a><span>|</span><a href="#41642322">next</a><span>|</span><label class="collapse" for="c-41642176">[-]</label><label class="expand" for="c-41642176">[8 more]</label></div><br/><div class="children"><div class="content">I think there are maybe two separate issues here.<p>Paper mills are bad but mostly from the perspective of academic institutions trying to verify people&#x27;s credentials&#x2F;resumes. Paper mills aren&#x27;t really that much of a concern in the sense of published research results being false in the way the article is talking about because people aren&#x27;t really reading the papers they publish. In that sense it doesn&#x27;t really matter if there are places where non-scientists need to get one paper published to check some box to get a promotion, because nobody is  really considering those papers part of established scientific knowledge.<p>On the other hand, scientists intentionally (by actually falsifying data) or unintentionally (as a result of statistical effects of what is researched and what is published) publishing bogus results in journals that are considered legitimate which <i>aren&#x27;t</i> paper mills actually causes real harm as a result of people believing the bogus results, and unfortunately the pressures that cause that (publishing papers quickly, getting publishable results, etc.) exist everywhere, and definitely not just in China, nor did they originate in China.</div><br/></div></div><div id="41642322" class="c"><input type="checkbox" id="c-41642322" checked=""/><div class="controls bullet"><span class="by">DiscourseFan</span><span>|</span><a href="#41641937">root</a><span>|</span><a href="#41642020">parent</a><span>|</span><a href="#41642176">prev</a><span>|</span><a href="#41642634">next</a><span>|</span><label class="collapse" for="c-41642322">[-]</label><label class="expand" for="c-41642322">[6 more]</label></div><br/><div class="children"><div class="content">This is what happens when Silicon Valley execs, trying to make their employees more replaceable, call for more STEM education; suddenly, tons of funding and institutional resources go into STEM research with no real reason or motivation or material for this research. It&#x27;s like an gerbil wheel: once you get on the ride, once you get tricked into becoming a &quot;scientist&quot; just because a few billionaires wanted to cut slightly thicker margins, there&#x27;s no stop. Bullshit your way through undergraduate education, bullshit your way through a PhD; finally, if you&#x27;re good enough at making up statistics, you get a job training a whole host of other bullshitters to ride the gravy train.</div><br/><div id="41642873" class="c"><input type="checkbox" id="c-41642873" checked=""/><div class="controls bullet"><span class="by">aleph_minus_one</span><span>|</span><a href="#41641937">root</a><span>|</span><a href="#41642322">parent</a><span>|</span><a href="#41642634">next</a><span>|</span><label class="collapse" for="c-41642873">[-]</label><label class="expand" for="c-41642873">[5 more]</label></div><br/><div class="children"><div class="content">&gt; tons of funding and institutional resources go into STEM research with no real reason or motivation or material for this research.<p>I <i>do</i> believe that there exists an insane amount of (STEM) questions where there exist <i>very good</i> reasons to do research on - much, much more than is currently done.<p>---<p>And by the way:<p>&gt; This is what happens when Silicon Valley execs, trying to make their employees more replaceable, call for more STEM education<p>More STEM education does not make the employees more replaceable. The reason why the Silicon Valley execs call for more STEM education is rather that<p>- they want to save money training the employees,<p>- they want to save money doing research (let rather the taxpayer pay for the research).</div><br/><div id="41644672" class="c"><input type="checkbox" id="c-41644672" checked=""/><div class="controls bullet"><span class="by">DiscourseFan</span><span>|</span><a href="#41641937">root</a><span>|</span><a href="#41642873">parent</a><span>|</span><a href="#41643169">next</a><span>|</span><label class="collapse" for="c-41644672">[-]</label><label class="expand" for="c-41644672">[2 more]</label></div><br/><div class="children"><div class="content">repeating what user u&#x2F;randomdata said already,<p>&gt; - they want to save money training the employees,<p>&gt; - they want to save money doing research (let rather the taxpayer pay for the research).<p>means they want to offload costs to the public in order to increase profits, which is what I said above.</div><br/><div id="41645219" class="c"><input type="checkbox" id="c-41645219" checked=""/><div class="controls bullet"><span class="by">aleph_minus_one</span><span>|</span><a href="#41641937">root</a><span>|</span><a href="#41644672">parent</a><span>|</span><a href="#41643169">next</a><span>|</span><label class="collapse" for="c-41645219">[-]</label><label class="expand" for="c-41645219">[1 more]</label></div><br/><div class="children"><div class="content">Offloading costs is a different thing than making employees more replaceable.</div><br/></div></div></div></div><div id="41643169" class="c"><input type="checkbox" id="c-41643169" checked=""/><div class="controls bullet"><span class="by">randomdata</span><span>|</span><a href="#41641937">root</a><span>|</span><a href="#41642873">parent</a><span>|</span><a href="#41644672">prev</a><span>|</span><a href="#41642634">next</a><span>|</span><label class="collapse" for="c-41643169">[-]</label><label class="expand" for="c-41643169">[2 more]</label></div><br/><div class="children"><div class="content"><i>&gt; - they want to save money training the employees,</i><p>So what you&#x27;re saying is that they push for STEM education to make their employees more replaceable...?</div><br/><div id="41645210" class="c"><input type="checkbox" id="c-41645210" checked=""/><div class="controls bullet"><span class="by">aleph_minus_one</span><span>|</span><a href="#41641937">root</a><span>|</span><a href="#41643169">parent</a><span>|</span><a href="#41642634">next</a><span>|</span><label class="collapse" for="c-41645210">[-]</label><label class="expand" for="c-41645210">[1 more]</label></div><br/><div class="children"><div class="content">&gt; 
So what you&#x27;re saying is that they push for STEM education to make their employees more replaceable...?<p>A general rule of thumb is rather that better education and&#x2F;or specialized knowledge makes employees <i>nore</i> productive, but also <i>less</i> replaceable.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="41642634" class="c"><input type="checkbox" id="c-41642634" checked=""/><div class="controls bullet"><span class="by">highcountess</span><span>|</span><a href="#41641937">parent</a><span>|</span><a href="#41642020">prev</a><span>|</span><a href="#41642046">next</a><span>|</span><label class="collapse" for="c-41642634">[-]</label><label class="expand" for="c-41642634">[3 more]</label></div><br/><div class="children"><div class="content">I’ve been in a meeting with government research officials where a director of the primary global institution in that field described how when she writes or does research and writes papers she draws a graph she needs to support her research or a point she is trying to make and then goes to look for the data to create that graph.<p>Maybe I’m missing something, but I do not believe that is the way it is stopped to go. Btw, she has a PhD and failed up into a global scale.<p>I’ve been meaning to find out if there are any open tools to evaluate someone’s dissertation.<p>It was equal part stunning and seemingly a bit traumatizing to me considering I still remember it as if it had happened earlier today. I think what surprised me too was her open admission of it, even with external parties present.</div><br/><div id="41643258" class="c"><input type="checkbox" id="c-41643258" checked=""/><div class="controls bullet"><span class="by">randomdata</span><span>|</span><a href="#41641937">root</a><span>|</span><a href="#41642634">parent</a><span>|</span><a href="#41642046">next</a><span>|</span><label class="collapse" for="c-41643258">[-]</label><label class="expand" for="c-41643258">[2 more]</label></div><br/><div class="children"><div class="content">So she establishes a hypothesis (draws a graph or picks a point to make) and then tests it through experimentation (looks for data to support the hypothesis)? Isn&#x27;t that just the scientific method worded another way?</div><br/><div id="41643398" class="c"><input type="checkbox" id="c-41643398" checked=""/><div class="controls bullet"><span class="by">elashri</span><span>|</span><a href="#41641937">root</a><span>|</span><a href="#41643258">parent</a><span>|</span><a href="#41642046">next</a><span>|</span><label class="collapse" for="c-41643398">[-]</label><label class="expand" for="c-41643398">[1 more]</label></div><br/><div class="children"><div class="content">Wait until the GP knows about how scientists generate Monte-Carlo (MC) simulation data to see what a positive results looks like and then do meta analysis for both real data and MC.</div><br/></div></div></div></div></div></div></div></div><div id="41642294" class="c"><input type="checkbox" id="c-41642294" checked=""/><div class="controls bullet"><span class="by">md224</span><span>|</span><a href="#41641937">prev</a><span>|</span><a href="#41642533">next</a><span>|</span><label class="collapse" for="c-41642294">[-]</label><label class="expand" for="c-41642294">[1 more]</label></div><br/><div class="children"><div class="content">Something that continues to puzzle me: how do molecular biologists manage to come up with such mindbogglingly complex diagrams of metabolic pathways in the midst of a replication crisis? Is our understanding of biology just a giant house of cards or is there something about the topic that allows for more robust investigation?</div><br/></div></div><div id="41642533" class="c"><input type="checkbox" id="c-41642533" checked=""/><div class="controls bullet"><span class="by">smeej</span><span>|</span><a href="#41642294">prev</a><span>|</span><a href="#41641744">next</a><span>|</span><label class="collapse" for="c-41642533">[-]</label><label class="expand" for="c-41642533">[1 more]</label></div><br/><div class="children"><div class="content">This kind of report always raises the question for me of what the existing system&#x27;s goals are. I think people assume that &quot;new, reliable knowledge&quot; is among the goals, but I don&#x27;t see that the incentives align toward that goal, so I don&#x27;t know that that&#x27;s actually among them.<p>Does the world really want&#x2F;need such a system? (The answer seems obvious to me, but not above question.) If so, how could it be designed? What incentives would it need? What conflicting interests would need to be disincentivized?<p>I think it&#x27;s been pretty evident for a long time that the &quot;peer-reviewed publications system&quot; doesn&#x27;t produce the results people think it should. I just don&#x27;t hear anybody really thinking through the systems involved to try to invent one that would.</div><br/></div></div><div id="41641744" class="c"><input type="checkbox" id="c-41641744" checked=""/><div class="controls bullet"><span class="by">youainti</span><span>|</span><a href="#41642533">prev</a><span>|</span><a href="#41641574">next</a><span>|</span><label class="collapse" for="c-41641744">[-]</label><label class="expand" for="c-41641744">[1 more]</label></div><br/><div class="children"><div class="content">Please note the peerpub comments discussing that it appears that followup research shows about 15% is wrong, not the 5% anticipated.<p><a href="https:&#x2F;&#x2F;pubpeer.com&#x2F;publications&#x2F;14B6D332F814462D2673B6E9EF9AF9" rel="nofollow">https:&#x2F;&#x2F;pubpeer.com&#x2F;publications&#x2F;14B6D332F814462D2673B6E9EF9...</a></div><br/></div></div><div id="41641574" class="c"><input type="checkbox" id="c-41641574" checked=""/><div class="controls bullet"><span class="by">motohagiography</span><span>|</span><a href="#41641744">prev</a><span>|</span><a href="#41641755">next</a><span>|</span><label class="collapse" for="c-41641574">[-]</label><label class="expand" for="c-41641574">[3 more]</label></div><br/><div class="children"><div class="content">i wonder if science could benefit from publishing using pseudonyms the way software has. if it&#x27;s any good, people will use it, the reputations will be made by the quality of contributions alone, it makes fraud expensive and mostly not worth it, etc.</div><br/><div id="41641797" class="c"><input type="checkbox" id="c-41641797" checked=""/><div class="controls bullet"><span class="by">wwweston</span><span>|</span><a href="#41641574">parent</a><span>|</span><a href="#41641755">next</a><span>|</span><label class="collapse" for="c-41641797">[-]</label><label class="expand" for="c-41641797">[2 more]</label></div><br/><div class="children"><div class="content">People have uses for conclusions that sometimes don&#x27;t have anything to do with their validity.<p>So while &quot;if it&#x27;s any good, people will use it&quot; is true and quality contributions will be useful, the converse is <i>not</i> true: the use or reach of published work may be only tenuously connected to whether it&#x27;s good.<p>Reputation signals like credentials and authority have their limits&#x2F;noise, but bring some extra signal to the situation.</div><br/><div id="41642343" class="c"><input type="checkbox" id="c-41642343" checked=""/><div class="controls bullet"><span class="by">motohagiography</span><span>|</span><a href="#41641574">root</a><span>|</span><a href="#41641797">parent</a><span>|</span><a href="#41641755">next</a><span>|</span><label class="collapse" for="c-41642343">[-]</label><label class="expand" for="c-41642343">[1 more]</label></div><br/><div class="children"><div class="content">what&#x27;s missing from this paper is a probability using its own model that it too is false. counter to the headline, it implies that by its own probable falsehood, most published research is in fact true.<p>I admit to missing the joke in the first reading.<p>pseudonyms may prevent the abuse of invalid papers by removing the ability of the authors to front institutional reputations for partisan claims.<p>the movement for science and data to drive policy outside of their domains sounds nice until you find that the science and data are irrepreducible, and the institutions have become laundering vehicles for debased opinions that wash the hands of policymakers. as though the potential for abuse has become the value.<p>maybe it&#x27;s a rarefied kind of funny, but the kernel of truth it reveals is that it could be time to start using pseudonyms in some disciplines to make the axis of policymakers and academics more honest.</div><br/></div></div></div></div></div></div><div id="41641755" class="c"><input type="checkbox" id="c-41641755" checked=""/><div class="controls bullet"><span class="by">withinboredom</span><span>|</span><a href="#41641574">prev</a><span>|</span><a href="#41642587">next</a><span>|</span><label class="collapse" for="c-41641755">[-]</label><label class="expand" for="c-41641755">[10 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve implemented several things from computer science papers in my career now, mostly related to database stuff. They are mostly terribly wrong or show the exact OPPOSITE as to what they claim in the paper. It&#x27;s so frustrating. Even occasionally, they offer their code used to write the paper and it is missing entire features they claim are integral for it to function properly; to the point that I wonder how they even came up with the results they came up with.<p>My favorite example was a huge paper that was almost entirely mathematics-based. It wasn&#x27;t until you implemented everything that you would realize it just didn&#x27;t even make any sense. Then, when you read between the lines, you even saw their acknowledgement of that fact in the conclusion. Clever dude.<p>Anyway, I have very little faith in academic papers; at least when it comes to computer science. Of all the things out there, it is just code. It isn&#x27;t hard to write and verify what you purport (usually takes less than a week to write the code), so I have no idea what the peer reviews actually do. As a peer in the industry, I would reject so many papers by this point.<p>And don&#x27;t even get me started on when I send the (now professor) questions via email to see if I just implemented it wrong, or whatever, that just never fucking reply.</div><br/><div id="41642015" class="c"><input type="checkbox" id="c-41642015" checked=""/><div class="controls bullet"><span class="by">jltsiren</span><span>|</span><a href="#41641755">parent</a><span>|</span><a href="#41641867">next</a><span>|</span><label class="collapse" for="c-41642015">[-]</label><label class="expand" for="c-41642015">[3 more]</label></div><br/><div class="children"><div class="content">This is a common failure mode when people outside academic CS read CS papers. They take the papers too literally.<p>Computer science studies computation as an abstract concept. The work may be motivated by what happens in the industry, but it&#x27;s not supposed to produce anything immediately applicable. Papers may include fake justifications and fake applications, because populist politicians decided long ago that all publicly funded research must have practical real-world applications. But you should not take them at face value.<p>Academic CS values abstract results over concrete results, because real-world systems change too rapidly. Real-world results tend to become obsolete too quickly to be relevant in the time scales the academia is supposed to operate.<p>If you are not in academic CS, you should be careful when reading the papers that you understand the context. Most of the time, you are not in the target audience. Even when there is something relevant in the paper, it&#x27;s probably not the main result, but an idea related to it. And if you start investigating where that idea came from, it probably builds on many earlier results that seemed obscure and practically irrelevant on their own.<p>Peer reviewers usually spend a few hours on a single review (though there is a lot of variation between fields). A week would be so expensive that most established academics would have to stop teaching and doing research and become full-time reviewers.</div><br/><div id="41645313" class="c"><input type="checkbox" id="c-41645313" checked=""/><div class="controls bullet"><span class="by">withinboredom</span><span>|</span><a href="#41641755">root</a><span>|</span><a href="#41642015">parent</a><span>|</span><a href="#41645040">next</a><span>|</span><label class="collapse" for="c-41645313">[-]</label><label class="expand" for="c-41645313">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Academic CS values abstract results over concrete results, because real-world systems change too rapidly. Real-world results tend to become obsolete too quickly to be relevant in the time scales the academia is supposed to operate.<p>This isn&#x27;t true. When I&#x27;m implementing a paper, I usually go for JUST implementing what they describe, usually by hand. Like if it is a new SQL syntax, I will write a custom recursive descent parser, and hand-roll the query planner, for just the new stuff and hard code some other parts, just as a demonstration. I&#x27;m not interested in the industry application part, I&#x27;m interested in replicating their work. Once I can replicate it, assuming it is correct, then I will factor the work into a production system.<p>It&#x27;s this first part that I am frustrated with, not the full implementation in production software.</div><br/></div></div></div></div><div id="41641867" class="c"><input type="checkbox" id="c-41641867" checked=""/><div class="controls bullet"><span class="by">Lerc</span><span>|</span><a href="#41641755">parent</a><span>|</span><a href="#41642015">prev</a><span>|</span><a href="#41642531">next</a><span>|</span><label class="collapse" for="c-41641867">[-]</label><label class="expand" for="c-41641867">[1 more]</label></div><br/><div class="children"><div class="content">For papers with code, I have a seen a tendency to consider the code, not the paper to be the ground truth.   If the code works, then it doesn&#x27;t matter what the paper says, the information is there.<p>If the code doesn&#x27;t work, it seems like a red flag.<p>It&#x27;s not an advantage that can be applied to biology or physics, but at least computer science catches a break here.</div><br/></div></div><div id="41642531" class="c"><input type="checkbox" id="c-41642531" checked=""/><div class="controls bullet"><span class="by">meling</span><span>|</span><a href="#41641755">parent</a><span>|</span><a href="#41641867">prev</a><span>|</span><a href="#41641773">next</a><span>|</span><label class="collapse" for="c-41642531">[-]</label><label class="expand" for="c-41642531">[1 more]</label></div><br/><div class="children"><div class="content">If it is as bad as you claim, it would be interesting if you could back this up with a falsification report for the papers in question.</div><br/></div></div><div id="41641773" class="c"><input type="checkbox" id="c-41641773" checked=""/><div class="controls bullet"><span class="by">reasonableklout</span><span>|</span><a href="#41641755">parent</a><span>|</span><a href="#41642531">prev</a><span>|</span><a href="#41641938">next</a><span>|</span><label class="collapse" for="c-41641773">[-]</label><label class="expand" for="c-41641773">[2 more]</label></div><br/><div class="children"><div class="content">Wow, sounds awful. Help the rest of us out - what was the huge paper that didn&#x27;t work or was actively misleading?</div><br/><div id="41641809" class="c"><input type="checkbox" id="c-41641809" checked=""/><div class="controls bullet"><span class="by">withinboredom</span><span>|</span><a href="#41641755">root</a><span>|</span><a href="#41641773">parent</a><span>|</span><a href="#41641938">next</a><span>|</span><label class="collapse" for="c-41641809">[-]</label><label class="expand" for="c-41641809">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;d rather not, for obvious reasons. The less obvious reason is that I don&#x27;t remember the title&#x2F;author of the paper. It was back in 2016&#x2F;17 when I was working on a temporal database project at work and was searching literature for temporal query syntax though.</div><br/></div></div></div></div><div id="41641938" class="c"><input type="checkbox" id="c-41641938" checked=""/><div class="controls bullet"><span class="by">DaoVeles</span><span>|</span><a href="#41641755">parent</a><span>|</span><a href="#41641773">prev</a><span>|</span><a href="#41642587">next</a><span>|</span><label class="collapse" for="c-41641938">[-]</label><label class="expand" for="c-41641938">[2 more]</label></div><br/><div class="children"><div class="content">It is also frustrating when a papers summary says one thing, you pay for the full thing only to see it is a complete opposite of the claims. Waste of time and money, bleh!</div><br/><div id="41644342" class="c"><input type="checkbox" id="c-41644342" checked=""/><div class="controls bullet"><span class="by">geysersam</span><span>|</span><a href="#41641755">root</a><span>|</span><a href="#41641938">parent</a><span>|</span><a href="#41642587">next</a><span>|</span><label class="collapse" for="c-41644342">[-]</label><label class="expand" for="c-41644342">[1 more]</label></div><br/><div class="children"><div class="content">Scihub. Use scihub. What use is it that you pay the publishing company for the paper? The researchers doing the work won&#x27;t see any of that money.</div><br/></div></div></div></div></div></div><div id="41642587" class="c"><input type="checkbox" id="c-41642587" checked=""/><div class="controls bullet"><span class="by">tdba</span><span>|</span><a href="#41641755">prev</a><span>|</span><a href="#41641977">next</a><span>|</span><label class="collapse" for="c-41642587">[-]</label><label class="expand" for="c-41642587">[1 more]</label></div><br/><div class="children"><div class="content">One study tried to replicate 100 psychology studies and only 36% attained significance.<p><a href="https:&#x2F;&#x2F;osf.io&#x2F;ezcuj&#x2F;wiki&#x2F;home&#x2F;" rel="nofollow">https:&#x2F;&#x2F;osf.io&#x2F;ezcuj&#x2F;wiki&#x2F;home&#x2F;</a></div><br/></div></div><div id="41641977" class="c"><input type="checkbox" id="c-41641977" checked=""/><div class="controls bullet"><span class="by">DaoVeles</span><span>|</span><a href="#41642587">prev</a><span>|</span><a href="#41644328">next</a><span>|</span><label class="collapse" for="c-41641977">[-]</label><label class="expand" for="c-41641977">[1 more]</label></div><br/><div class="children"><div class="content">It has been said that &quot;Publish or Perish&quot; would make a good tomb stone epitaph for a lot of modern sciences.<p>I speak to a lot of people in various science fields and generally they are some of the heaviest drinkers I know simply because of the system they have been forced into. They want to do good but are railroaded into this nonsense for dear of losing their livelihood.<p>Like those that are trying to progress our treatment of mental health but have ended up almost exclusively in the biochemicals space because that is where the money is even though that is not the only path. It is a real shame.<p>Also other heavy drinkers are the ecologists and climatologists, for good reason. They can see the road ahead and it is bleak. They hope they are wrong.</div><br/></div></div><div id="41644328" class="c"><input type="checkbox" id="c-41644328" checked=""/><div class="controls bullet"><span class="by">DrNosferatu</span><span>|</span><a href="#41641977">prev</a><span>|</span><a href="#41641570">next</a><span>|</span><label class="collapse" for="c-41644328">[-]</label><label class="expand" for="c-41644328">[1 more]</label></div><br/><div class="children"><div class="content">Have LLMs cross check papers and point out experiments to be repeated.</div><br/></div></div><div id="41641570" class="c"><input type="checkbox" id="c-41641570" checked=""/><div class="controls bullet"><span class="by">skybrian</span><span>|</span><a href="#41644328">prev</a><span>|</span><a href="#41642130">next</a><span>|</span><label class="collapse" for="c-41641570">[-]</label><label class="expand" for="c-41641570">[2 more]</label></div><br/><div class="children"><div class="content">(2005). I wonder what&#x27;s changed?</div><br/><div id="41641753" class="c"><input type="checkbox" id="c-41641753" checked=""/><div class="controls bullet"><span class="by">youainti</span><span>|</span><a href="#41641570">parent</a><span>|</span><a href="#41642130">next</a><span>|</span><label class="collapse" for="c-41641753">[-]</label><label class="expand" for="c-41641753">[1 more]</label></div><br/><div class="children"><div class="content">Over on peerpub there has been some discussion of studies on the topic.<p><a href="https:&#x2F;&#x2F;pubpeer.com&#x2F;publications&#x2F;14B6D332F814462D2673B6E9EF9AF9#4" rel="nofollow">https:&#x2F;&#x2F;pubpeer.com&#x2F;publications&#x2F;14B6D332F814462D2673B6E9EF9...</a></div><br/></div></div></div></div><div id="41642130" class="c"><input type="checkbox" id="c-41642130" checked=""/><div class="controls bullet"><span class="by">Animats</span><span>|</span><a href="#41641570">prev</a><span>|</span><a href="#41642374">next</a><span>|</span><label class="collapse" for="c-41642130">[-]</label><label class="expand" for="c-41642130">[1 more]</label></div><br/><div class="children"><div class="content">How broad a range is this result supposed to cover? It seems to be mostly applicable to areas where data is too close to the noise threshold. Some phenomena are like that, and some are not.<p><i>&quot;If your experiment needs statistics, you ought to have done a better experiment&quot;</i> - Rutherford</div><br/></div></div><div id="41642374" class="c"><input type="checkbox" id="c-41642374" checked=""/><div class="controls bullet"><span class="by">meling</span><span>|</span><a href="#41642130">prev</a><span>|</span><a href="#41642636">next</a><span>|</span><label class="collapse" for="c-41642374">[-]</label><label class="expand" for="c-41642374">[1 more]</label></div><br/><div class="children"><div class="content">I only read the abstract; “Simulations show that for most study designs and settings, it is more likely for a research claim to be false than true.”<p>True vs false seems like a very crude metric, no?<p>Perhaps this paper’s research claim is also false.</div><br/></div></div><div id="41642636" class="c"><input type="checkbox" id="c-41642636" checked=""/><div class="controls bullet"><span class="by">ninetyninenine</span><span>|</span><a href="#41642374">prev</a><span>|</span><a href="#41642891">next</a><span>|</span><label class="collapse" for="c-41642636">[-]</label><label class="expand" for="c-41642636">[1 more]</label></div><br/><div class="children"><div class="content">So whenever someone gives me a detailed argument with cited sources I can show them this and render the truth into an unobtainable objective.</div><br/></div></div><div id="41642891" class="c"><input type="checkbox" id="c-41642891" checked=""/><div class="controls bullet"><span class="by">Daub</span><span>|</span><a href="#41642636">prev</a><span>|</span><a href="#41641761">next</a><span>|</span><label class="collapse" for="c-41642891">[-]</label><label class="expand" for="c-41642891">[1 more]</label></div><br/><div class="children"><div class="content">From my experience, my main criticism of research in the field of computer vision is that most of it is &#x27;meh&#x27;. In a university that focused on security research, I saw mountains of research into detection&#x2F;recognition, yet most of it offered no more than slightly different ways of doing the same old thing.<p>I also saw: a head of design school insisting that they and their spouse were credited on all student and staff movies, the same person insisting that massive amounts of school cash be spent promoting their solo exhibition that no one other than students attended, a chair of research who insisted they were given an authorship role on all published output in the school, labs being instituted and teaching hires brought in to support a senior admin&#x27;s research interested (despite them not having any published output in this area), research ideas stolen from undergrad students and given to PhD students... I could go on all day.<p>If anyone is interested in how things got like this, you might start with Margret Thatcher. It was she who was the first to insist that funding of universities be tied to research. Given the state of British research in those days it was a reasonable decision, but it produced a climate where quantity is valued over quality and true &#x27;impact&#x27;.</div><br/></div></div><div id="41641761" class="c"><input type="checkbox" id="c-41641761" checked=""/><div class="controls bullet"><span class="by">blackeyeblitzar</span><span>|</span><a href="#41642891">prev</a><span>|</span><a href="#41642867">next</a><span>|</span><label class="collapse" for="c-41641761">[-]</label><label class="expand" for="c-41641761">[1 more]</label></div><br/><div class="children"><div class="content">It’s a matter of incentives. Everyone who wants a PhD has to publish and before that they need to produce findings that align with the values of their professors. These bad incentives combined with rampant statistical errors lead to bad findings. We need to stop putting “studies” on a pedestal.</div><br/></div></div><div id="41642867" class="c"><input type="checkbox" id="c-41642867" checked=""/><div class="controls bullet"><span class="by">iskander</span><span>|</span><a href="#41641761">prev</a><span>|</span><a href="#41642671">next</a><span>|</span><label class="collapse" for="c-41642867">[-]</label><label class="expand" for="c-41642867">[1 more]</label></div><br/><div class="children"><div class="content">I think unpopular to mention here but John Ioannidis did a really weird turn in his career and published some atrociously non-rigorous Covid research that falls squarely in the cross-hairs of &quot;why...research findings are false&quot;.</div><br/></div></div><div id="41642671" class="c"><input type="checkbox" id="c-41642671" checked=""/><div class="controls bullet"><span class="by">hofo</span><span>|</span><a href="#41642867">prev</a><span>|</span><a href="#41642054">next</a><span>|</span><label class="collapse" for="c-41642671">[-]</label><label class="expand" for="c-41642671">[1 more]</label></div><br/><div class="children"><div class="content">Oh the irony</div><br/></div></div><div id="41642054" class="c"><input type="checkbox" id="c-41642054" checked=""/><div class="controls bullet"><span class="by">angry_octet</span><span>|</span><a href="#41642671">prev</a><span>|</span><a href="#41642518">next</a><span>|</span><label class="collapse" for="c-41642054">[-]</label><label class="expand" for="c-41642054">[3 more]</label></div><br/><div class="children"><div class="content">... including the junk pushed by Ioannidis. His completely trashed his credibility during COVID.</div><br/><div id="41642539" class="c"><input type="checkbox" id="c-41642539" checked=""/><div class="controls bullet"><span class="by">pessimizer</span><span>|</span><a href="#41642054">parent</a><span>|</span><a href="#41642518">next</a><span>|</span><label class="collapse" for="c-41642539">[-]</label><label class="expand" for="c-41642539">[2 more]</label></div><br/><div class="children"><div class="content">By being less wrong than almost everyone else. Since everyone else was wrong together they shunned him (as science dictates), and now agree to not talk about how wrong they were.</div><br/><div id="41643067" class="c"><input type="checkbox" id="c-41643067" checked=""/><div class="controls bullet"><span class="by">angry_octet</span><span>|</span><a href="#41642054">root</a><span>|</span><a href="#41642539">parent</a><span>|</span><a href="#41642518">next</a><span>|</span><label class="collapse" for="c-41643067">[-]</label><label class="expand" for="c-41643067">[1 more]</label></div><br/><div class="children"><div class="content">He used his reputation and statistical expertise to mislead the world as to the true prevalence (COVID infection rate) and supported the fantasies of Bhattacharya, Kulldorff and Gupta. It is hard to estimate what effect his misinformation had on COVID control measures, and there was no shortage of attention seeking clowns, but he stepped up to the plate and he can take credit for some of the millions of deaths. It was scientific misconduct but his position shields him from consequences.</div><br/></div></div></div></div></div></div><div id="41641748" class="c"><input type="checkbox" id="c-41641748" checked=""/><div class="controls bullet"><span class="by">carabiner</span><span>|</span><a href="#41642518">prev</a><span>|</span><a href="#41641563">next</a><span>|</span><label class="collapse" for="c-41641748">[-]</label><label class="expand" for="c-41641748">[2 more]</label></div><br/><div class="children"><div class="content">This only applies to life sciences, social sciences right? Or are most papers in computer science or mechanical engineering also false?</div><br/><div id="41641845" class="c"><input type="checkbox" id="c-41641845" checked=""/><div class="controls bullet"><span class="by">thatguysaguy</span><span>|</span><a href="#41641748">parent</a><span>|</span><a href="#41641563">next</a><span>|</span><label class="collapse" for="c-41641845">[-]</label><label class="expand" for="c-41641845">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s very bad in CS as well. See e.g.: <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1807.03341" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1807.03341</a><p>IIRC there was also a paper analyzing how often results in some NLP conference held up when a different random seed or hyperparameters were used. It was quite depressing.</div><br/></div></div></div></div><div id="41641563" class="c"><input type="checkbox" id="c-41641563" checked=""/><div class="controls bullet"><span class="by">titanomachy</span><span>|</span><a href="#41641748">prev</a><span>|</span><a href="#41641527">next</a><span>|</span><label class="collapse" for="c-41641563">[-]</label><label class="expand" for="c-41641563">[1 more]</label></div><br/><div class="children"><div class="content">2022</div><br/></div></div><div id="41641527" class="c"><input type="checkbox" id="c-41641527" checked=""/><div class="controls bullet"><span class="by">marcosdumay</span><span>|</span><a href="#41641563">prev</a><span>|</span><a href="#41641659">next</a><span>|</span><label class="collapse" for="c-41641527">[-]</label><label class="expand" for="c-41641527">[17 more]</label></div><br/><div class="children"><div class="content">Yeah, when you try new things, you often get them wrong.<p>Why do we expect most published results to be true?</div><br/><div id="41641600" class="c"><input type="checkbox" id="c-41641600" checked=""/><div class="controls bullet"><span class="by">bluefirebrand</span><span>|</span><a href="#41641527">parent</a><span>|</span><a href="#41641542">next</a><span>|</span><label class="collapse" for="c-41641600">[-]</label><label class="expand" for="c-41641600">[13 more]</label></div><br/><div class="children"><div class="content">Because people use published results to justify all sorts of government policy, business activity, social programs, and such.<p>If we cannot trust that results of research are true, then how can we justify using them to make any kind of decisions in society?<p>&quot;Believe the science&quot;, &quot;Trust the experts&quot; etc sort of falls flat if this stuff is all based on shaky research</div><br/><div id="41641805" class="c"><input type="checkbox" id="c-41641805" checked=""/><div class="controls bullet"><span class="by">marcosdumay</span><span>|</span><a href="#41641527">root</a><span>|</span><a href="#41641600">parent</a><span>|</span><a href="#41642252">next</a><span>|</span><label class="collapse" for="c-41641805">[-]</label><label class="expand" for="c-41641805">[10 more]</label></div><br/><div class="children"><div class="content">&gt; If we cannot trust that results of research are true, then how can we justify using them to make any kind of decisions in society?<p>Well, don&#x27;t.<p>Make your decisions based on replicated results. Stop hyping single studies.</div><br/><div id="41643999" class="c"><input type="checkbox" id="c-41643999" checked=""/><div class="controls bullet"><span class="by">ozgrakkurt</span><span>|</span><a href="#41641527">root</a><span>|</span><a href="#41641805">parent</a><span>|</span><a href="#41641861">next</a><span>|</span><label class="collapse" for="c-41643999">[-]</label><label class="expand" for="c-41643999">[1 more]</label></div><br/><div class="children"><div class="content">I agree with this but it is very harsh on a person to doubt too much, gotta believe something. So there doesn’t seem to be a real solution for this kind of thing</div><br/></div></div><div id="41641861" class="c"><input type="checkbox" id="c-41641861" checked=""/><div class="controls bullet"><span class="by">XorNot</span><span>|</span><a href="#41641527">root</a><span>|</span><a href="#41641805">parent</a><span>|</span><a href="#41643999">prev</a><span>|</span><a href="#41641990">next</a><span>|</span><label class="collapse" for="c-41641861">[-]</label><label class="expand" for="c-41641861">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Stop hyping single studies.<p>This right here really. The reason people go &quot;oh well science changes every week&quot; is because what happens is the media writes this headline: &quot;&lt;Thing&gt; shown to do &lt;effect&gt; in <i>brand new study!</i>&quot; and then includes a bunch of text which implies it works great...and one or two sentences, out of context, from the lead research behind it saying &quot;yes I think this is a very interesting result&quot;.<p>They omit all the actual important details like sample sizes, demographics, history of the field or where the result sits in terms of the field.</div><br/></div></div><div id="41641990" class="c"><input type="checkbox" id="c-41641990" checked=""/><div class="controls bullet"><span class="by">adamrezich</span><span>|</span><a href="#41641527">root</a><span>|</span><a href="#41641805">parent</a><span>|</span><a href="#41641861">prev</a><span>|</span><a href="#41642252">next</a><span>|</span><label class="collapse" for="c-41641990">[-]</label><label class="expand" for="c-41641990">[7 more]</label></div><br/><div class="children"><div class="content">After decades upon decades of teaching Western society to “Trust The Science”—where “Science” means “published academic research papers”—you can&#x27;t <i>un</i>teach society from thinking this way with a simple four-word appeal to logic.<p>The damage has already long since been done. It&#x27;s great that people are starting to realize the mistake, but it&#x27;s going to take a lot more work than just saying “stop hyping single studies” in this comments thread to radically alter the status quo.<p>I once knew a guy who ended his friendship of many years with me over an argument about “safe drug use sites”, or whatever they&#x27;re called—those places where drug addicts can go to “safely” do drugs with medical staff nearby in case they inadvertently overdose. Dude was of the belief that these initiatives were unequivocally good, and that any common-sense thinking along the lines of, “hey, isn&#x27;t that only going to encourage further self-destructive behavior in vulnerable members of the populace?” could be countered by pointing to a handful of studies that supposedly showed that these “safe shoot-up sites” had been Proven To Be Unequivocally Good, Actually.<p>I took a look at one of these published academic research “studies”—said research was conducted by finding local drug dealers and asking them, before and after a “safe shoot-up site” was constructed, how their business was doing. The answer they got was, “more or less the same”—so the paper concluded (by means of a rather remarkable extrapolation, if I do say so myself) that these “safe shoot-up sites” were Provably Objectively Good For Society.<p>After pointing this out to my friend of many years, he informed me that I had apparently become some flavor of far-right Nazi or whatever, and blocked me on all social media platforms, never speaking to me again.<p>You&#x27;re not going to get people like him to see reason by just saying “stop hyping single studies” and calling it a day. Our entire culture revolves around placing a rather unreasonable amount of completely blind faith in the veracity of published academic research findings.</div><br/><div id="41642716" class="c"><input type="checkbox" id="c-41642716" checked=""/><div class="controls bullet"><span class="by">lemmsjid</span><span>|</span><a href="#41641527">root</a><span>|</span><a href="#41641990">parent</a><span>|</span><a href="#41642049">next</a><span>|</span><label class="collapse" for="c-41642716">[-]</label><label class="expand" for="c-41642716">[2 more]</label></div><br/><div class="children"><div class="content">I was intrigued and took a Quick Look at the top studies on this subject and the metrics used are things like relative overdose deaths in an area, crime statistics, and usage of treatment programs.  They say that by virtue of a number of epidemiological metrics that safe consumption sites appear to be associated with harm reduction in terms of overdoses, while not increasing crime stats. I don’t see outsized claims of objective truth being made, more of the standard, “here’s how we got the numbers, here’s the numbers, they appear to point in this direction.”<p>I’m not doubting your claim but I’m wondering how that very weird paper you’re citing bubbles up to the top, when there’s some very middle of the road meta analyses that don’t make outsized claims like access to objective truth.</div><br/><div id="41642929" class="c"><input type="checkbox" id="c-41642929" checked=""/><div class="controls bullet"><span class="by">adamrezich</span><span>|</span><a href="#41641527">root</a><span>|</span><a href="#41642716">parent</a><span>|</span><a href="#41642049">next</a><span>|</span><label class="collapse" for="c-41642929">[-]</label><label class="expand" for="c-41642929">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not that the paper itself made the claim of having access to objective Truth, it&#x27;s that papers like these make conclusions, and these conclusions get taken in aggregate to advance various agendas, and the whole premise is treated (in aggregate) as being functionally identical to building a rocket based on conclusions reached by mathematics and physics research papers—because both situations involve making decisions based upon “scientific research”, so in both situations you can justify your actions by pointing to “Science”.</div><br/></div></div></div></div><div id="41642049" class="c"><input type="checkbox" id="c-41642049" checked=""/><div class="controls bullet"><span class="by">blackbear_</span><span>|</span><a href="#41641527">root</a><span>|</span><a href="#41641990">parent</a><span>|</span><a href="#41642716">prev</a><span>|</span><a href="#41642252">next</a><span>|</span><label class="collapse" for="c-41642049">[-]</label><label class="expand" for="c-41642049">[4 more]</label></div><br/><div class="children"><div class="content">So what do you suggest?</div><br/><div id="41642466" class="c"><input type="checkbox" id="c-41642466" checked=""/><div class="controls bullet"><span class="by">mistermann</span><span>|</span><a href="#41641527">root</a><span>|</span><a href="#41642049">parent</a><span>|</span><a href="#41642310">next</a><span>|</span><label class="collapse" for="c-41642466">[-]</label><label class="expand" for="c-41642466">[1 more]</label></div><br/><div class="children"><div class="content">Philosophy has all sorts of different ways to study this complex, multifaceted problem.  Too bad it got kicked to the curb by science and is now mostly laughed at.<p>As ye sow, so shall ye reap, IRL maybe.</div><br/></div></div><div id="41642310" class="c"><input type="checkbox" id="c-41642310" checked=""/><div class="controls bullet"><span class="by">adamrezich</span><span>|</span><a href="#41641527">root</a><span>|</span><a href="#41642049">parent</a><span>|</span><a href="#41642466">prev</a><span>|</span><a href="#41642252">next</a><span>|</span><label class="collapse" for="c-41642310">[-]</label><label class="expand" for="c-41642310">[2 more]</label></div><br/><div class="children"><div class="content">No idea—all I know how to do is recognize patterns and program computers.<p>But admitting to the existence of a problem is the first step toward fixing it, and, judging by the downvotes on various comments on this story here, we still have a ways to go before the existence of the problem is commonly-accepted.</div><br/><div id="41643303" class="c"><input type="checkbox" id="c-41643303" checked=""/><div class="controls bullet"><span class="by">marcosdumay</span><span>|</span><a href="#41641527">root</a><span>|</span><a href="#41642310">parent</a><span>|</span><a href="#41642252">next</a><span>|</span><label class="collapse" for="c-41643303">[-]</label><label class="expand" for="c-41643303">[1 more]</label></div><br/><div class="children"><div class="content">You are threading into one of those areas that seem to replicate very well.<p>The difficulty or risk of using drugs does not appear to be a bottleneck on the amount of it people use. This probably does not hold all over the world, but I&#x27;m not aware of anybody actually finding an exception.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="41642252" class="c"><input type="checkbox" id="c-41642252" checked=""/><div class="controls bullet"><span class="by">wredue</span><span>|</span><a href="#41641527">root</a><span>|</span><a href="#41641600">parent</a><span>|</span><a href="#41641805">prev</a><span>|</span><a href="#41641914">next</a><span>|</span><label class="collapse" for="c-41642252">[-]</label><label class="expand" for="c-41642252">[1 more]</label></div><br/><div class="children"><div class="content">If government used science to back up policy, we would most definitely not be having a huge portion of the problems we currently have.</div><br/></div></div><div id="41641914" class="c"><input type="checkbox" id="c-41641914" checked=""/><div class="controls bullet"><span class="by">thaumasiotes</span><span>|</span><a href="#41641527">root</a><span>|</span><a href="#41641600">parent</a><span>|</span><a href="#41642252">prev</a><span>|</span><a href="#41641542">next</a><span>|</span><label class="collapse" for="c-41641914">[-]</label><label class="expand" for="c-41641914">[1 more]</label></div><br/><div class="children"><div class="content">&gt; people use published results to justify all sorts of government policy, business activity, social programs, and such.<p>That would be a reason to expect those results to be false, not a reason to expect them to be true.</div><br/></div></div></div></div><div id="41641542" class="c"><input type="checkbox" id="c-41641542" checked=""/><div class="controls bullet"><span class="by">ekianjo</span><span>|</span><a href="#41641527">parent</a><span>|</span><a href="#41641600">prev</a><span>|</span><a href="#41641659">next</a><span>|</span><label class="collapse" for="c-41641542">[-]</label><label class="expand" for="c-41641542">[3 more]</label></div><br/><div class="children"><div class="content">because people believe that peer review improve things but in fact not really. its more of a stamping process</div><br/><div id="41641590" class="c"><input type="checkbox" id="c-41641590" checked=""/><div class="controls bullet"><span class="by">elashri</span><span>|</span><a href="#41641527">root</a><span>|</span><a href="#41641542">parent</a><span>|</span><a href="#41641789">next</a><span>|</span><label class="collapse" for="c-41641590">[-]</label><label class="expand" for="c-41641590">[1 more]</label></div><br/><div class="children"><div class="content">Yes that a misconception that many people think that peer-review involves some sort of verification or replication which is not true.<p>I would blame mainstream media in part for this and how they report on research and don&#x27;t emphasize this nature. Mainstream media also is not interested in reporting on progress but likes catchy headlines&#x2F;findings.</div><br/></div></div></div></div></div></div><div id="41641659" class="c"><input type="checkbox" id="c-41641659" checked=""/><div class="controls bullet"><span class="by">ape4</span><span>|</span><a href="#41641527">prev</a><span>|</span><a href="#41641609">next</a><span>|</span><label class="collapse" for="c-41641659">[-]</label><label class="expand" for="c-41641659">[2 more]</label></div><br/><div class="children"><div class="content">So is this paper false too?
.. infinite recursion...</div><br/><div id="41641793" class="c"><input type="checkbox" id="c-41641793" checked=""/><div class="controls bullet"><span class="by">wccrawford</span><span>|</span><a href="#41641659">parent</a><span>|</span><a href="#41641609">next</a><span>|</span><label class="collapse" for="c-41641793">[-]</label><label class="expand" for="c-41641793">[1 more]</label></div><br/><div class="children"><div class="content">Most probably.</div><br/></div></div></div></div><div id="41641609" class="c"><input type="checkbox" id="c-41641609" checked=""/><div class="controls bullet"><span class="by">debacle</span><span>|</span><a href="#41641659">prev</a><span>|</span><a href="#41642079">next</a><span>|</span><label class="collapse" for="c-41641609">[-]</label><label class="expand" for="c-41641609">[1 more]</label></div><br/><div class="children"><div class="content">Most? Really?</div><br/></div></div><div id="41642079" class="c"><input type="checkbox" id="c-41642079" checked=""/><div class="controls bullet"><span class="by">23B1</span><span>|</span><a href="#41641609">prev</a><span>|</span><a href="#41642761">next</a><span>|</span><label class="collapse" for="c-41642079">[-]</label><label class="expand" for="c-41642079">[4 more]</label></div><br/><div class="children"><div class="content">Imagine if tech billionaires, instead of building dickships and buying single-family homes, decided to truly invest in humanity by realigning incentives in science.</div><br/><div id="41642198" class="c"><input type="checkbox" id="c-41642198" checked=""/><div class="controls bullet"><span class="by">joycesticks</span><span>|</span><a href="#41642079">parent</a><span>|</span><a href="#41642761">next</a><span>|</span><label class="collapse" for="c-41642198">[-]</label><label class="expand" for="c-41642198">[3 more]</label></div><br/><div class="children"><div class="content">Damn people are getting pretty good at manifesting these days<p>Check out ResearchHub[1], it&#x27;s a company founded by a tech billionaire that&#x27;s trying to realign incentives in science<p>[1] - <a href="https:&#x2F;&#x2F;www.researchhub.com&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.researchhub.com&#x2F;</a></div><br/><div id="41642683" class="c"><input type="checkbox" id="c-41642683" checked=""/><div class="controls bullet"><span class="by">23B1</span><span>|</span><a href="#41642079">root</a><span>|</span><a href="#41642198">parent</a><span>|</span><a href="#41642807">next</a><span>|</span><label class="collapse" for="c-41642683">[-]</label><label class="expand" for="c-41642683">[1 more]</label></div><br/><div class="children"><div class="content">Heh, thanks.</div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>