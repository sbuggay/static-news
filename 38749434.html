<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1703408453838" as="style"/><link rel="stylesheet" href="styles.css?v=1703408453838"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/cumulo-autumn/StreamDiffusion">StreamDiffusion: A pipeline-level solution for real-time interactive generation</a> <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>Flux159</span> | <span>53 comments</span></div><br/><div><div id="38749460" class="c"><input type="checkbox" id="c-38749460" checked=""/><div class="controls bullet"><span class="by">Flux159</span><span>|</span><a href="#38752173">next</a><span>|</span><label class="collapse" for="c-38749460">[-]</label><label class="expand" for="c-38749460">[1 more]</label></div><br/><div class="children"><div class="content">Arxiv paper here <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2312.12491" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2312.12491</a><p>I think that it&#x27;s possible to get faster than their default timings for a 4090 (I have been able to get 10fps without optimizations with SDXL Turbo and 1 iteration step), but their other improvements like using a Stochastic Similarity Filter to prevent unnecessary generations are good for getting fast results w&#x2F;out having to pin your GPU at 100% all the time.</div><br/></div></div><div id="38752173" class="c"><input type="checkbox" id="c-38752173" checked=""/><div class="controls bullet"><span class="by">_joel</span><span>|</span><a href="#38749460">prev</a><span>|</span><a href="#38749839">next</a><span>|</span><label class="collapse" for="c-38752173">[-]</label><label class="expand" for="c-38752173">[1 more]</label></div><br/><div class="children"><div class="content">Maybe we&#x27;re all living in a simulation^H^H^H^H^H pipeline-level solution for real-time interactive generation.</div><br/></div></div><div id="38749839" class="c"><input type="checkbox" id="c-38749839" checked=""/><div class="controls bullet"><span class="by">acheong08</span><span>|</span><a href="#38752173">prev</a><span>|</span><a href="#38750608">next</a><span>|</span><label class="collapse" for="c-38749839">[-]</label><label class="expand" for="c-38749839">[15 more]</label></div><br/><div class="children"><div class="content">This feels unreal. It feels like a decade passed within a year.</div><br/><div id="38750124" class="c"><input type="checkbox" id="c-38750124" checked=""/><div class="controls bullet"><span class="by">jimmyl02</span><span>|</span><a href="#38749839">parent</a><span>|</span><a href="#38750949">next</a><span>|</span><label class="collapse" for="c-38750124">[-]</label><label class="expand" for="c-38750124">[4 more]</label></div><br/><div class="children"><div class="content">the entire open source AI space feels like this right now. basically every day there is some new advancement that either makes something deemed impossible achievable and it&#x27;s actually really hard to keep up with all the changes.</div><br/><div id="38750272" class="c"><input type="checkbox" id="c-38750272" checked=""/><div class="controls bullet"><span class="by">legel</span><span>|</span><a href="#38749839">root</a><span>|</span><a href="#38750124">parent</a><span>|</span><a href="#38750298">next</a><span>|</span><label class="collapse" for="c-38750272">[-]</label><label class="expand" for="c-38750272">[2 more]</label></div><br/><div class="children"><div class="content">100% agreed.  I&#x27;ve been developing deep neural networks for over 10 years and this is just surreal.<p>On the bright side, one source of &quot;sanity&quot; that I&#x27;m finding is to review a collection of daily &quot;hot&quot; publications in AI&#x2F;ML curated here: <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;papers" rel="nofollow noreferrer">https:&#x2F;&#x2F;huggingface.co&#x2F;papers</a></div><br/><div id="38750915" class="c"><input type="checkbox" id="c-38750915" checked=""/><div class="controls bullet"><span class="by">kwerk</span><span>|</span><a href="#38749839">root</a><span>|</span><a href="#38750272">parent</a><span>|</span><a href="#38750298">next</a><span>|</span><label class="collapse" for="c-38750915">[-]</label><label class="expand" for="c-38750915">[1 more]</label></div><br/><div class="children"><div class="content">Thanks for sharing.</div><br/></div></div></div></div></div></div><div id="38750949" class="c"><input type="checkbox" id="c-38750949" checked=""/><div class="controls bullet"><span class="by">knlam</span><span>|</span><a href="#38749839">parent</a><span>|</span><a href="#38750124">prev</a><span>|</span><a href="#38749968">next</a><span>|</span><label class="collapse" for="c-38750949">[-]</label><label class="expand" for="c-38750949">[1 more]</label></div><br/><div class="children"><div class="content">Now as a frontend developer I understand how folks complain the frontend landscape change so fast that it is impossible to keep up</div><br/></div></div><div id="38749968" class="c"><input type="checkbox" id="c-38749968" checked=""/><div class="controls bullet"><span class="by">amelius</span><span>|</span><a href="#38749839">parent</a><span>|</span><a href="#38750949">prev</a><span>|</span><a href="#38751815">next</a><span>|</span><label class="collapse" for="c-38749968">[-]</label><label class="expand" for="c-38749968">[2 more]</label></div><br/><div class="children"><div class="content">These softwares develop faster than I can apt-get install them.</div><br/><div id="38750256" class="c"><input type="checkbox" id="c-38750256" checked=""/><div class="controls bullet"><span class="by">throwup238</span><span>|</span><a href="#38749839">root</a><span>|</span><a href="#38749968">parent</a><span>|</span><a href="#38751815">next</a><span>|</span><label class="collapse" for="c-38750256">[-]</label><label class="expand" for="c-38750256">[1 more]</label></div><br/><div class="children"><div class="content">Not even ArchLinux’s rolling community repositories can keep up.<p>I’ve had to git clone everything like a package manager-less serf. Where even is my filesystem?!</div><br/></div></div></div></div><div id="38751815" class="c"><input type="checkbox" id="c-38751815" checked=""/><div class="controls bullet"><span class="by">Roritharr</span><span>|</span><a href="#38749839">parent</a><span>|</span><a href="#38749968">prev</a><span>|</span><a href="#38751150">next</a><span>|</span><label class="collapse" for="c-38751815">[-]</label><label class="expand" for="c-38751815">[1 more]</label></div><br/><div class="children"><div class="content">This is the only thing that has me curious if that&#x27;s how the progress curve feels like in the opening act of the Singularity.</div><br/></div></div><div id="38751150" class="c"><input type="checkbox" id="c-38751150" checked=""/><div class="controls bullet"><span class="by">mattigames</span><span>|</span><a href="#38749839">parent</a><span>|</span><a href="#38751815">prev</a><span>|</span><a href="#38750651">next</a><span>|</span><label class="collapse" for="c-38751150">[-]</label><label class="expand" for="c-38751150">[5 more]</label></div><br/><div class="children"><div class="content">I can&#x27;t wait until it can do my job and then I will just run it on my PC and connect it to slack so my employeer will receive similar results of when I did it manually and I will be payed  without spending any time actually working, I will be able to focus on my hobbies for once. This is how this all will play out in the end right?</div><br/><div id="38751438" class="c"><input type="checkbox" id="c-38751438" checked=""/><div class="controls bullet"><span class="by">godelski</span><span>|</span><a href="#38749839">root</a><span>|</span><a href="#38751150">parent</a><span>|</span><a href="#38751641">next</a><span>|</span><label class="collapse" for="c-38751438">[-]</label><label class="expand" for="c-38751438">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I will be payed without spending any time actually working,<p>&gt; This is how this all will play out in the end right?<p>Somebody is gonna tell him right? I don&#x27;t want to be the one to crush such innocence.</div><br/></div></div><div id="38751641" class="c"><input type="checkbox" id="c-38751641" checked=""/><div class="controls bullet"><span class="by">buryat</span><span>|</span><a href="#38749839">root</a><span>|</span><a href="#38751150">parent</a><span>|</span><a href="#38751438">prev</a><span>|</span><a href="#38751222">next</a><span>|</span><label class="collapse" for="c-38751641">[-]</label><label class="expand" for="c-38751641">[1 more]</label></div><br/><div class="children"><div class="content">start recording your thought process very detailed while solving problems, then train a model and sell the model to work as you, roll in money (likely not as you would be outcompeted by other models).</div><br/></div></div><div id="38751222" class="c"><input type="checkbox" id="c-38751222" checked=""/><div class="controls bullet"><span class="by">sroussey</span><span>|</span><a href="#38749839">root</a><span>|</span><a href="#38751150">parent</a><span>|</span><a href="#38751641">prev</a><span>|</span><a href="#38751485">next</a><span>|</span><label class="collapse" for="c-38751222">[-]</label><label class="expand" for="c-38751222">[1 more]</label></div><br/><div class="children"><div class="content">Your employer can just replace you then and save the money</div><br/></div></div><div id="38751485" class="c"><input type="checkbox" id="c-38751485" checked=""/><div class="controls bullet"><span class="by">holoduke</span><span>|</span><a href="#38749839">root</a><span>|</span><a href="#38751150">parent</a><span>|</span><a href="#38751222">prev</a><span>|</span><a href="#38750651">next</a><span>|</span><label class="collapse" for="c-38751485">[-]</label><label class="expand" for="c-38751485">[1 more]</label></div><br/><div class="children"><div class="content">If you are the first. Yes dor a time. Make sure you duplicate your work among 500 other jobs and become a millionaire.  Because it will last not so long when everyone finds out</div><br/></div></div></div></div><div id="38750651" class="c"><input type="checkbox" id="c-38750651" checked=""/><div class="controls bullet"><span class="by">gigel82</span><span>|</span><a href="#38749839">parent</a><span>|</span><a href="#38751150">prev</a><span>|</span><a href="#38750608">next</a><span>|</span><label class="collapse" for="c-38750651">[-]</label><label class="expand" for="c-38750651">[1 more]</label></div><br/><div class="children"><div class="content">Reminds me of an incremental game ( <a href="https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;incremental_games&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;incremental_games&#x2F;</a> ) - BTW, don&#x27;t start playing one of those or you&#x27;ll ruin your holidays... :)</div><br/></div></div></div></div><div id="38750608" class="c"><input type="checkbox" id="c-38750608" checked=""/><div class="controls bullet"><span class="by">smusamashah</span><span>|</span><a href="#38749839">prev</a><span>|</span><a href="#38749581">next</a><span>|</span><label class="collapse" for="c-38750608">[-]</label><label class="expand" for="c-38750608">[2 more]</label></div><br/><div class="children"><div class="content">I just tried the realtime-text2img demo (uses npm for frontend which i think is too much for this). Modified it to produce only 1 image instead of 16. Works well on a laptop with RTX-3080. It&#x27;s probably 2 images &#x2F; sec.<p>EDIT: The `examples\screen` demo almost feels realtime. Says 4 fps on the window but don&#x27;t what it represents.<p>EDIT: Denoising in img2img is very low though which means thee returned image is only slightly different from base image.</div><br/><div id="38751431" class="c"><input type="checkbox" id="c-38751431" checked=""/><div class="controls bullet"><span class="by">godelski</span><span>|</span><a href="#38750608">parent</a><span>|</span><a href="#38749581">next</a><span>|</span><label class="collapse" for="c-38751431">[-]</label><label class="expand" for="c-38751431">[1 more]</label></div><br/><div class="children"><div class="content">How&#x27;s the actual quality, diversity, and alignment though. I&#x27;m away from my GPU for a few days. It&#x27;s always hard to judge generative papers without getting hands on because you write to the reviewers which means you gotta cherry pick (I think this is bad, but it&#x27;s where we&#x27;re at). They&#x27;re using tiny autoencoder? Artspew did that too and was getting higher FPS (but weren&#x27;t using TensorRT but were using triton) but the quality was garbage (still cool). Regardless, these are impressive even if the quality isn&#x27;t anywhere near whats shown, but it&#x27;s hard to tell.</div><br/></div></div></div></div><div id="38749581" class="c"><input type="checkbox" id="c-38749581" checked=""/><div class="controls bullet"><span class="by">ilaksh</span><span>|</span><a href="#38750608">prev</a><span>|</span><a href="#38749998">next</a><span>|</span><label class="collapse" for="c-38749581">[-]</label><label class="expand" for="c-38749581">[5 more]</label></div><br/><div class="children"><div class="content">How does the demo with the girl moving in and out of frame work? Is it ControlNet?</div><br/><div id="38749694" class="c"><input type="checkbox" id="c-38749694" checked=""/><div class="controls bullet"><span class="by">woleium</span><span>|</span><a href="#38749581">parent</a><span>|</span><a href="#38749718">next</a><span>|</span><label class="collapse" for="c-38749694">[-]</label><label class="expand" for="c-38749694">[1 more]</label></div><br/><div class="children"><div class="content">Its video input. from tfa:<p>Stochastic Similarity Filter reduces processing during video input by minimizing conversion operations when there is little change from the previous frame, thereby alleviating GPU processing load, as shown by the red frame in the above GIF</div><br/></div></div><div id="38749718" class="c"><input type="checkbox" id="c-38749718" checked=""/><div class="controls bullet"><span class="by">Flux159</span><span>|</span><a href="#38749581">parent</a><span>|</span><a href="#38749694">prev</a><span>|</span><a href="#38749831">next</a><span>|</span><label class="collapse" for="c-38749718">[-]</label><label class="expand" for="c-38749718">[1 more]</label></div><br/><div class="children"><div class="content">I think it’s just img2img with a prompt &amp; rcfg scale and no controlnet since theres a GitHub issue about adding controlnet support open at the moment.</div><br/></div></div><div id="38749831" class="c"><input type="checkbox" id="c-38749831" checked=""/><div class="controls bullet"><span class="by">ec109685</span><span>|</span><a href="#38749581">parent</a><span>|</span><a href="#38749718">prev</a><span>|</span><a href="#38749998">next</a><span>|</span><label class="collapse" for="c-38749831">[-]</label><label class="expand" for="c-38749831">[2 more]</label></div><br/><div class="children"><div class="content">So left is the source image and right is the resultant image?</div><br/><div id="38750097" class="c"><input type="checkbox" id="c-38750097" checked=""/><div class="controls bullet"><span class="by">washadjeffmad</span><span>|</span><a href="#38749581">root</a><span>|</span><a href="#38749831">parent</a><span>|</span><a href="#38749998">next</a><span>|</span><label class="collapse" for="c-38750097">[-]</label><label class="expand" for="c-38750097">[1 more]</label></div><br/><div class="children"><div class="content">yes. compare to animatediff.</div><br/></div></div></div></div></div></div><div id="38749998" class="c"><input type="checkbox" id="c-38749998" checked=""/><div class="controls bullet"><span class="by">modeless</span><span>|</span><a href="#38749581">prev</a><span>|</span><a href="#38750027">next</a><span>|</span><label class="collapse" for="c-38749998">[-]</label><label class="expand" for="c-38749998">[5 more]</label></div><br/><div class="children"><div class="content">Does 100fps mean I can provide a new input every 10 ms and get a new output every 10ms? Or do inputs need to be batched together to get that average throughput?</div><br/><div id="38750131" class="c"><input type="checkbox" id="c-38750131" checked=""/><div class="controls bullet"><span class="by">stale2002</span><span>|</span><a href="#38749998">parent</a><span>|</span><a href="#38750027">next</a><span>|</span><label class="collapse" for="c-38750131">[-]</label><label class="expand" for="c-38750131">[4 more]</label></div><br/><div class="children"><div class="content">I haven&#x27;t tried it, but just taking an educated guess, which is that I don&#x27;t think batching should be required.<p>The slow part for models is loading the model up.  But once the model is up, you can send it whatever input that you want.<p>Parsing and sending the image data just doesn&#x27;t pass my gut check as to what would be the bottleneck here.</div><br/><div id="38751570" class="c"><input type="checkbox" id="c-38751570" checked=""/><div class="controls bullet"><span class="by">godelski</span><span>|</span><a href="#38749998">root</a><span>|</span><a href="#38750131">parent</a><span>|</span><a href="#38750174">next</a><span>|</span><label class="collapse" for="c-38751570">[-]</label><label class="expand" for="c-38751570">[1 more]</label></div><br/><div class="children"><div class="content">Everyone does warmup before you measure. But measuring isn&#x27;t always done right because we actually measure the GPU time only but some people naively use CPU time which is problematic because the process is asynchrenous. They have a few timing scripts though and I&#x27;m away from my GPU. There are some interesting things but they look like they know how to time. But it can also get confusing because is it considering batches or not. Some works do batch some do single. Only problem is when it isn&#x27;t communicated correctly or left ambiguous.<p>Their paper is ambiguous unfortunately. Abstract, intro, and conclusion suggests single image by motivating with sequential generation (specifically mentioning metaverse). Experiment section says<p>&gt; We note that we evaluate the throughput mainly via the average inference time per image through processing 100 images.<p>That implies batch along with their name Stream Batch...<p>Looking at the code I&#x27;m a bit confused. I&#x27;m away from my GPU so can&#x27;t run. Maybe someone can let me know? This block[0] measures correctly but is using a downloaded image? Then just opens the image in the preprocess? (multi looks identical) This block[1] is using CPU? But running CPU. (there&#x27;s another like this)<p>So I&#x27;m quite a bit confused tbh.<p>[0] <a href="https:&#x2F;&#x2F;github.com&#x2F;cumulo-autumn&#x2F;StreamDiffusion&#x2F;blob&#x2F;03e2a7ff7a82f7967a211419c231704db3cd5aa2&#x2F;examples&#x2F;benchmark&#x2F;single.py#L115-L128">https:&#x2F;&#x2F;github.com&#x2F;cumulo-autumn&#x2F;StreamDiffusion&#x2F;blob&#x2F;03e2a7...</a><p>[1] <a href="https:&#x2F;&#x2F;github.com&#x2F;cumulo-autumn&#x2F;StreamDiffusion&#x2F;blob&#x2F;03e2a7ff7a82f7967a211419c231704db3cd5aa2&#x2F;examples&#x2F;optimal-performance&#x2F;single.py#L54-L62">https:&#x2F;&#x2F;github.com&#x2F;cumulo-autumn&#x2F;StreamDiffusion&#x2F;blob&#x2F;03e2a7...</a></div><br/></div></div><div id="38750174" class="c"><input type="checkbox" id="c-38750174" checked=""/><div class="controls bullet"><span class="by">modeless</span><span>|</span><a href="#38749998">root</a><span>|</span><a href="#38750131">parent</a><span>|</span><a href="#38751570">prev</a><span>|</span><a href="#38750027">next</a><span>|</span><label class="collapse" for="c-38750174">[-]</label><label class="expand" for="c-38750174">[2 more]</label></div><br/><div class="children"><div class="content">That&#x27;s not the issue, the issue is GPU utilization. Batching enables higher utilization and higher images per second throughput, but doesn&#x27;t improve latency.</div><br/><div id="38750419" class="c"><input type="checkbox" id="c-38750419" checked=""/><div class="controls bullet"><span class="by">Kubuxu</span><span>|</span><a href="#38749998">root</a><span>|</span><a href="#38750174">parent</a><span>|</span><a href="#38750027">next</a><span>|</span><label class="collapse" for="c-38750419">[-]</label><label class="expand" for="c-38750419">[1 more]</label></div><br/><div class="children"><div class="content">In essence batching allows for more efficient usage of memory bandwidth. Without batching for every generation you need to transfer the whole model from GPU memory to GPU core once for every image which sets an upper bound on speed.
With batching the bottlenecks start showing up elsewhere.<p>For SD1.5 4090 is able to do ~17it&#x2F;s without batching and ~90-100it&#x2F;s with batching.<p>Although these numbers might be old at this point, I looked at it ~3mo ago.</div><br/></div></div></div></div></div></div></div></div><div id="38750027" class="c"><input type="checkbox" id="c-38750027" checked=""/><div class="controls bullet"><span class="by">kristopolous</span><span>|</span><a href="#38749998">prev</a><span>|</span><a href="#38750375">next</a><span>|</span><label class="collapse" for="c-38750027">[-]</label><label class="expand" for="c-38750027">[1 more]</label></div><br/><div class="children"><div class="content">This more or less just worked as documented. Most of these demos tend to blow up and give really wonky deep errors.<p>Good job. Give it a try. Look into the server.py of realtime-txt2img to change the model if you want to generate something other than anime. Pointing it to say <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;runwayml&#x2F;stable-diffusion-v1-5" rel="nofollow noreferrer">https:&#x2F;&#x2F;huggingface.co&#x2F;runwayml&#x2F;stable-diffusion-v1-5</a> works fine.<p>The results are genuinely fast. Not great, but fast. If you change to the SDXL via LCM-LoRA <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;latent-consistency" rel="nofollow noreferrer">https:&#x2F;&#x2F;huggingface.co&#x2F;latent-consistency</a> you may get better stuff but that&#x27;s when it&#x27;s going to get difficult and you&#x27;ll start to run into those mysterious crashes I talked about that require, you know, actual work.<p>my setup: 4090&#x2F;3990x&#x2F;CUDA 12.2&#x2F;debian sid. ymmv.</div><br/></div></div><div id="38750375" class="c"><input type="checkbox" id="c-38750375" checked=""/><div class="controls bullet"><span class="by">programjames</span><span>|</span><a href="#38750027">prev</a><span>|</span><a href="#38749797">next</a><span>|</span><label class="collapse" for="c-38750375">[-]</label><label class="expand" for="c-38750375">[6 more]</label></div><br/><div class="children"><div class="content">This paper is horribly written. It&#x27;s like the authors are trying to sell me on them as researchers, instead of helping me understand their research (y&#x27;know, the entire reason journals got started??). An entire section for &quot;stream batching&quot; was just too much, and none of their ideas were innovative or unique. It was incredibly dense, simply because it&#x27;s obfuscated, which makes me believe the authors themselves don&#x27;t really understand what they&#x27;re doing.<p>The results aren&#x27;t even very good. They claim 60x speedup, but compared to what? HuggingFace&#x27;s Diffusers Autopipeline... a company notorious for buggy code and inefficient pipelines. And that&#x27;s for <i>naively</i> running the pipeline on every image. Give me a break.</div><br/><div id="38751861" class="c"><input type="checkbox" id="c-38751861" checked=""/><div class="controls bullet"><span class="by">godelski</span><span>|</span><a href="#38750375">parent</a><span>|</span><a href="#38750513">next</a><span>|</span><label class="collapse" for="c-38751861">[-]</label><label class="expand" for="c-38751861">[1 more]</label></div><br/><div class="children"><div class="content">&gt; instead of helping me understand their research (y&#x27;know, the entire reason journals got started??)<p>ML is crazy right now and people don&#x27;t see papers as means of researchers communicating to other researchers. You write papers to reviewers. But your reviewers are stochastic so it&#x27;s hard to write to them because they may or may not be in your niche.<p>I&#x27;ll add though that this isn&#x27;t why journals were created and that CS&#x2F;ML doesn&#x27;t typically use journals ({T,J}MLR, PAMI, and a few exist, sure) and instead write to conferences. Fixed dates, zero sum, 1.5 shot setting (1 rebuttal, zero revisions). Journals were created for dissemination of papers, indirectly about communicating to one another, but you know... now we got Arxiv and blogs and websites are sometimes way better just like how papers got better with pictures with computer graphics.</div><br/></div></div><div id="38750513" class="c"><input type="checkbox" id="c-38750513" checked=""/><div class="controls bullet"><span class="by">kristopolous</span><span>|</span><a href="#38750375">parent</a><span>|</span><a href="#38751861">prev</a><span>|</span><a href="#38749797">next</a><span>|</span><label class="collapse" for="c-38750513">[-]</label><label class="expand" for="c-38750513">[4 more]</label></div><br/><div class="children"><div class="content">Somehow just hacking together code to create something is considered publishable these days. The code works but it really is just pasted together stuff from the last few weeks of research.</div><br/><div id="38751878" class="c"><input type="checkbox" id="c-38751878" checked=""/><div class="controls bullet"><span class="by">godelski</span><span>|</span><a href="#38750375">root</a><span>|</span><a href="#38750513">parent</a><span>|</span><a href="#38751339">next</a><span>|</span><label class="collapse" for="c-38751878">[-]</label><label class="expand" for="c-38751878">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think I have a problem with this tbh. Though this specifically looks more engineering and product oriented. What I do have a problem with is comparing papers across vastly different TRLs and comparing works done with 100 GPU years of compute to works with 1 GPU year (or less). Just completely different class of works and comparing is void of context, you know?<p>The reason I don&#x27;t have a problem is I see papers as how we researchers communicate with other researchers. But I feel that&#x27;s not how everyone sees them and there&#x27;s the aspect that this is how we&#x27;re judged so incentives get misaligned with actual goal. Idk if the reward hacking is ironic or makes sense because our job is to optimize. But don&#x27;t let anyone try to convince you that reward (or any cost function) is enough.</div><br/></div></div></div></div></div></div><div id="38749797" class="c"><input type="checkbox" id="c-38749797" checked=""/><div class="controls bullet"><span class="by">brcmthrowaway</span><span>|</span><a href="#38750375">prev</a><span>|</span><a href="#38752023">next</a><span>|</span><label class="collapse" for="c-38749797">[-]</label><label class="expand" for="c-38749797">[10 more]</label></div><br/><div class="children"><div class="content">What is the fps on Apple Silicon?</div><br/><div id="38750339" class="c"><input type="checkbox" id="c-38750339" checked=""/><div class="controls bullet"><span class="by">washadjeffmad</span><span>|</span><a href="#38749797">parent</a><span>|</span><a href="#38751636">next</a><span>|</span><label class="collapse" for="c-38750339">[-]</label><label class="expand" for="c-38750339">[7 more]</label></div><br/><div class="children"><div class="content">0 because there&#x27;s no MPS support.<p>However, a Studio with an M1 Max 64GB is ~13x slower at generative AI with SD1.5 and SDXL than an RTX 4090 24GB at the same cost (~$1,800, refurb) right now.</div><br/><div id="38750634" class="c"><input type="checkbox" id="c-38750634" checked=""/><div class="controls bullet"><span class="by">Terretta</span><span>|</span><a href="#38749797">root</a><span>|</span><a href="#38750339">parent</a><span>|</span><a href="#38751636">next</a><span>|</span><label class="collapse" for="c-38750634">[-]</label><label class="expand" for="c-38750634">[6 more]</label></div><br/><div class="children"><div class="content">&gt; <i>0 because there&#x27;s no MPS support. ...  Studio with an M1 Max 64GB is ~13x slower at generative AI with SD1.5 and SDXL than an RTX 4090 24GB at the same cost (~$1,800, refurb)</i><p>Does the 4090 have a computer attached to it?  It seems like with no computer, the speed would also be 0.</div><br/><div id="38750888" class="c"><input type="checkbox" id="c-38750888" checked=""/><div class="controls bullet"><span class="by">echelon</span><span>|</span><a href="#38749797">root</a><span>|</span><a href="#38750634">parent</a><span>|</span><a href="#38750790">next</a><span>|</span><label class="collapse" for="c-38750888">[-]</label><label class="expand" for="c-38750888">[3 more]</label></div><br/><div class="children"><div class="content">AI is best done in the Linux&#x2F;Ubuntu&#x2F;Pytorch&#x2F;Nvidia ecosystem. Windows has some exposure due to WSL&#x2F;Nvidia.<p>Mac is not a great place for AI&#x2F;ML yet. Both the hardware and the software present challenges. It&#x27;ll take time.<p>When I was hacking AI stuff on a Macbook, I had a second Framework laptop with EGPU that I SSH&#x27;d to.</div><br/><div id="38751255" class="c"><input type="checkbox" id="c-38751255" checked=""/><div class="controls bullet"><span class="by">sroussey</span><span>|</span><a href="#38749797">root</a><span>|</span><a href="#38750888">parent</a><span>|</span><a href="#38750790">next</a><span>|</span><label class="collapse" for="c-38751255">[-]</label><label class="expand" for="c-38751255">[2 more]</label></div><br/><div class="children"><div class="content">I think the tensor core in the 4090 really help, and of course CUDA supporting every hardware they offer (cough cough, rocm) means that researchers are going to start there.<p>That said, I think Apple will have some interesting stuff in a year or two (M4 or more likely M5) where they can flex their NPU, Accelerate framework, and unified memory GPU and have it work with more modern requirements.<p>Time will tell what their software and hardware story is for local inference for generative AI.<p>Siri (dictation, some assistant stuff, and TTS) runs on device, and I doubt they want to undo that.<p>I doubt they will do much for training, but maybe a NUMA version of a MacPro with several M4 Ultras will prove me wrong?</div><br/><div id="38751270" class="c"><input type="checkbox" id="c-38751270" checked=""/><div class="controls bullet"><span class="by">echelon</span><span>|</span><a href="#38749797">root</a><span>|</span><a href="#38751255">parent</a><span>|</span><a href="#38750790">next</a><span>|</span><label class="collapse" for="c-38751270">[-]</label><label class="expand" for="c-38751270">[1 more]</label></div><br/><div class="children"><div class="content">&gt; That said, I think Apple will have some interesting stuff in a year or two (M4 or more likely M5) where they can flex their NPU, Accelerate framework, and unified memory GPU and have it work with more modern requirements.<p>Plus two years for software support by the broader ecosystem.<p>Even Windows, with Cuda + drivers, suffers from less support.</div><br/></div></div></div></div></div></div><div id="38750790" class="c"><input type="checkbox" id="c-38750790" checked=""/><div class="controls bullet"><span class="by">teaearlgraycold</span><span>|</span><a href="#38749797">root</a><span>|</span><a href="#38750634">parent</a><span>|</span><a href="#38750888">prev</a><span>|</span><a href="#38751636">next</a><span>|</span><label class="collapse" for="c-38750790">[-]</label><label class="expand" for="c-38750790">[2 more]</label></div><br/><div class="children"><div class="content">If we’re being snarky “Apple Silicon” won’t work without a motherboard and power supply either.</div><br/><div id="38751397" class="c"><input type="checkbox" id="c-38751397" checked=""/><div class="controls bullet"><span class="by">givinguflac</span><span>|</span><a href="#38749797">root</a><span>|</span><a href="#38750790">parent</a><span>|</span><a href="#38751636">next</a><span>|</span><label class="collapse" for="c-38751397">[-]</label><label class="expand" for="c-38751397">[1 more]</label></div><br/><div class="children"><div class="content">I get what you’re saying but I don’t think there was snark. Just the fact that a 4090 without a computer attached won’t work. It’s not like you can buy apple silicon without a Mac attached.</div><br/></div></div></div></div></div></div></div></div><div id="38751636" class="c"><input type="checkbox" id="c-38751636" checked=""/><div class="controls bullet"><span class="by">yazaddaruvala</span><span>|</span><a href="#38749797">parent</a><span>|</span><a href="#38750339">prev</a><span>|</span><a href="#38749840">next</a><span>|</span><label class="collapse" for="c-38751636">[-]</label><label class="expand" for="c-38751636">[1 more]</label></div><br/><div class="children"><div class="content">I run DrawThings with SDXL Turbo on my M1 Pro w&#x2F; 32GB RAM<p>I get a 512x512 5 step image generated in 5 seconds. No refiner, upscaler, or face restoration.<p>My understanding is that DrawThings hasn’t been optimized for SDXL Turbo and&#x2F;or pipelined generation yet.<p>For reference: SDXL Base+Refiner with face restoration at 2k x 2k 50 step image generation takes about 120 seconds.</div><br/></div></div><div id="38749840" class="c"><input type="checkbox" id="c-38749840" checked=""/><div class="controls bullet"><span class="by">gaogao</span><span>|</span><a href="#38749797">parent</a><span>|</span><a href="#38751636">prev</a><span>|</span><a href="#38752023">next</a><span>|</span><label class="collapse" for="c-38749840">[-]</label><label class="expand" for="c-38749840">[1 more]</label></div><br/><div class="children"><div class="content">At least an 1&#x2F;8 or so, but yeah, getting it running on Apple at at least 24fps would be huge. Some degree of interpolation might do it. You maybe could get away with 12fps esp. with an anime aesthetic since that&#x27;s basically animating on 2&#x27;s.</div><br/></div></div></div></div><div id="38752023" class="c"><input type="checkbox" id="c-38752023" checked=""/><div class="controls bullet"><span class="by">timexironman</span><span>|</span><a href="#38749797">prev</a><span>|</span><a href="#38750591">next</a><span>|</span><label class="collapse" for="c-38752023">[-]</label><label class="expand" for="c-38752023">[1 more]</label></div><br/><div class="children"><div class="content">Is there a video of it I can view anywhere?</div><br/></div></div><div id="38749865" class="c"><input type="checkbox" id="c-38749865" checked=""/><div class="controls bullet"><span class="by">badloginagain</span><span>|</span><a href="#38750180">prev</a><span>|</span><label class="collapse" for="c-38749865">[-]</label><label class="expand" for="c-38749865">[2 more]</label></div><br/><div class="children"><div class="content">Yo I just heard about MidJourney this year.<p>And this appears to be a local runtime stable diffusion streaming library?<p>Bruh.</div><br/><div id="38749941" class="c"><input type="checkbox" id="c-38749941" checked=""/><div class="controls bullet"><span class="by">Keyframe</span><span>|</span><a href="#38749865">parent</a><span>|</span><label class="collapse" for="c-38749941">[-]</label><label class="expand" for="c-38749941">[1 more]</label></div><br/><div class="children"><div class="content">Singularity is real, but it&#x27;s people. Amazing fast-paced progress.</div><br/></div></div></div></div></div></div></div></div></div></body></html>