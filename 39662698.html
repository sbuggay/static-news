<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1710147663537" as="style"/><link rel="stylesheet" href="styles.css?v=1710147663537"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/lightvector/KataGo/blob/master/docs/GraphSearch.md">Monte-Carlo graph search from first principles</a> <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>bumbledraven</span> | <span>19 comments</span></div><br/><div><div id="39663486" class="c"><input type="checkbox" id="c-39663486" checked=""/><div class="controls bullet"><span class="by">fabmilo</span><span>|</span><a href="#39663429">next</a><span>|</span><label class="collapse" for="c-39663486">[-]</label><label class="expand" for="c-39663486">[3 more]</label></div><br/><div class="children"><div class="content">I believe this kind of graph exploration is what we need to progress reasoning in AI. Plain LLMS will fail. The link has tons of good references, including the Zobrist hashing <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Zobrist_hashing" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Zobrist_hashing</a> for game tables. We need to find a good hashing for language based state description so that graph exploration doesn&#x27;t explode computationally. Another good read for Tree Search is Thinking Fast and Slow: <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1705.08439" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1705.08439</a> and Teaching Large Language Models to Reason with Reinforcement Learning: <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2403.04642" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2403.04642</a> comparing the MCTS approach to other current RL strategies.</div><br/><div id="39665919" class="c"><input type="checkbox" id="c-39665919" checked=""/><div class="controls bullet"><span class="by">vjerancrnjak</span><span>|</span><a href="#39663486">parent</a><span>|</span><a href="#39665067">next</a><span>|</span><label class="collapse" for="c-39665919">[-]</label><label class="expand" for="c-39665919">[1 more]</label></div><br/><div class="children"><div class="content">This looks too low level.<p>What might be a step forward is a joint learning of the state representation with the search algorithm. Search algorithm explores the NN representation of the state for which you can get the cost.<p><a href="https:&#x2F;&#x2F;sites.google.com&#x2F;view&#x2F;genie-2024&#x2F;" rel="nofollow">https:&#x2F;&#x2F;sites.google.com&#x2F;view&#x2F;genie-2024&#x2F;</a><p>Genie from DeepMind is a good demonstration where discrete state is being modeled. NN learns a very complex representation with collision detection and actions. Instead of decoding that state into pixels, search could probably be done directly on that state.<p>Of course, this architecture could be very different.</div><br/></div></div><div id="39665067" class="c"><input type="checkbox" id="c-39665067" checked=""/><div class="controls bullet"><span class="by">anonymous-panda</span><span>|</span><a href="#39663486">parent</a><span>|</span><a href="#39665919">prev</a><span>|</span><a href="#39663429">next</a><span>|</span><label class="collapse" for="c-39665067">[-]</label><label class="expand" for="c-39665067">[1 more]</label></div><br/><div class="children"><div class="content">Would it be impossible to marry the two somehow? It’s hard for me to believe that the brain only uses a single technique for everything and likely has many different tools in its toolbox with a selector on top to know how to leverage each appropriately.</div><br/></div></div></div></div><div id="39663429" class="c"><input type="checkbox" id="c-39663429" checked=""/><div class="controls bullet"><span class="by">pixelpoet</span><span>|</span><a href="#39663486">prev</a><span>|</span><a href="#39664856">next</a><span>|</span><label class="collapse" for="c-39663429">[-]</label><label class="expand" for="c-39663429">[3 more]</label></div><br/><div class="children"><div class="content">Immediately recognise the author in the HN url as the genius behind KataGo: <a href="https:&#x2F;&#x2F;github.com&#x2F;lightvector&#x2F;KataGo">https:&#x2F;&#x2F;github.com&#x2F;lightvector&#x2F;KataGo</a><p>His posts on <a href="https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;cbaduk&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;cbaduk&#x2F;</a> are consistently excellent.</div><br/><div id="39663983" class="c"><input type="checkbox" id="c-39663983" checked=""/><div class="controls bullet"><span class="by">bingbingbing777</span><span>|</span><a href="#39663429">parent</a><span>|</span><a href="#39664856">next</a><span>|</span><label class="collapse" for="c-39663983">[-]</label><label class="expand" for="c-39663983">[2 more]</label></div><br/><div class="children"><div class="content">The URL is literally within the KataGo repo.</div><br/><div id="39664434" class="c"><input type="checkbox" id="c-39664434" checked=""/><div class="controls bullet"><span class="by">pixelpoet</span><span>|</span><a href="#39663429">root</a><span>|</span><a href="#39663983">parent</a><span>|</span><a href="#39664856">next</a><span>|</span><label class="collapse" for="c-39664434">[-]</label><label class="expand" for="c-39664434">[1 more]</label></div><br/><div class="children"><div class="content">The HN URL preview for me &quot;literally&quot; says &quot;(github.com&#x2F;lightvector)&quot;, with no upfront mention of KataGo. <i>sigh</i></div><br/></div></div></div></div></div></div><div id="39664856" class="c"><input type="checkbox" id="c-39664856" checked=""/><div class="controls bullet"><span class="by">modeless</span><span>|</span><a href="#39663429">prev</a><span>|</span><a href="#39663128">next</a><span>|</span><label class="collapse" for="c-39664856">[-]</label><label class="expand" for="c-39664856">[6 more]</label></div><br/><div class="children"><div class="content">&gt; Also, as far as the name &quot;Monte-Carlo Tree Search&quot; itself, readers might note that there is nothing &quot;Monte-Carlo&quot; in the above algorithm - that it&#x27;s completely deterministic!<p>MCTS as commonly implemented is deterministic? How strange! I assumed there was randomness in the sampling.</div><br/><div id="39664996" class="c"><input type="checkbox" id="c-39664996" checked=""/><div class="controls bullet"><span class="by">kadoban</span><span>|</span><a href="#39664856">parent</a><span>|</span><a href="#39665073">next</a><span>|</span><label class="collapse" for="c-39664996">[-]</label><label class="expand" for="c-39664996">[3 more]</label></div><br/><div class="children"><div class="content">Originally MCTS did have randomness, yes. I think the article mentions it, but this came in in the form of playouts at the end, used just to evaluate positions. This has been replaced in current similar projects by NN evaluations, which are higher quality (as you can probably imagine, just playing random moves to see who wins is not very good, it was just the best strategy known at the time).<p>So the monte-carlo turned out to be an unessential (and suboptimal) part of what is now still called MCTS, making the name a bit unfortunate.</div><br/><div id="39665118" class="c"><input type="checkbox" id="c-39665118" checked=""/><div class="controls bullet"><span class="by">jacoblambda</span><span>|</span><a href="#39664856">root</a><span>|</span><a href="#39664996">parent</a><span>|</span><a href="#39665581">next</a><span>|</span><label class="collapse" for="c-39665118">[-]</label><label class="expand" for="c-39665118">[1 more]</label></div><br/><div class="children"><div class="content">In essence the NN evaluations are acting as a PRNG with values heavily biased by an established heuristic.<p>So while it&#x27;s very much a specialization of MCTS and probably should go by a different name, one could argue it&#x27;s still using monte carlo methods.</div><br/></div></div><div id="39665581" class="c"><input type="checkbox" id="c-39665581" checked=""/><div class="controls bullet"><span class="by">mzl</span><span>|</span><a href="#39664856">root</a><span>|</span><a href="#39664996">parent</a><span>|</span><a href="#39665118">prev</a><span>|</span><a href="#39665073">next</a><span>|</span><label class="collapse" for="c-39665581">[-]</label><label class="expand" for="c-39665581">[1 more]</label></div><br/><div class="children"><div class="content">Small side note, standard MCTS is often implemented with heuristic guiding the moves in the playouts and not just random moves, as that gives more interesting information.</div><br/></div></div></div></div><div id="39665073" class="c"><input type="checkbox" id="c-39665073" checked=""/><div class="controls bullet"><span class="by">jacoblambda</span><span>|</span><a href="#39664856">parent</a><span>|</span><a href="#39664996">prev</a><span>|</span><a href="#39664946">next</a><span>|</span><label class="collapse" for="c-39665073">[-]</label><label class="expand" for="c-39665073">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s technically a different algorithm just under the same &quot;monte carlo&quot; name.<p>However something interesting of note is that since most applications of monte carlo methods rely on PRNGs instead of true RNGs, they are technically deterministic (as given the same PRNG seed you should always get the same result for a given input).<p>So what this algorithm is doing instead of using a normal PRNG and a separate heuristic, is to instead query the neural network. This works because the neural net is an heuristic over a massive search space which ends up acting like a very poor PRNG that is heavily biased towards specific results based on the training of the neutal net, which in turn ends up looking like a PRNG with a set of heuristics applied.<p>The important thing to note is that this is a specialisation of MCTS and as such shouldn&#x27;t technically work for all use cases.</div><br/></div></div><div id="39664946" class="c"><input type="checkbox" id="c-39664946" checked=""/><div class="controls bullet"><span class="by">westurner</span><span>|</span><a href="#39664856">parent</a><span>|</span><a href="#39665073">prev</a><span>|</span><a href="#39663128">next</a><span>|</span><label class="collapse" for="c-39664946">[-]</label><label class="expand" for="c-39664946">[1 more]</label></div><br/><div class="children"><div class="content">If there&#x27;s randomness, is there convergence and after how much (CPU, RAM, GPU, TPU, QPU) resource-time?</div><br/></div></div></div></div><div id="39663128" class="c"><input type="checkbox" id="c-39663128" checked=""/><div class="controls bullet"><span class="by">rphln</span><span>|</span><a href="#39664856">prev</a><span>|</span><a href="#39663499">next</a><span>|</span><label class="collapse" for="c-39663128">[-]</label><label class="expand" for="c-39663128">[1 more]</label></div><br/><div class="children"><div class="content">Somehow the paper they mention completely flew under my radar when I was researching MCTS. Surely it&#x27;s gonna be a lot of fun to give this modification a spin on my next opportunity.</div><br/></div></div><div id="39663499" class="c"><input type="checkbox" id="c-39663499" checked=""/><div class="controls bullet"><span class="by">behnamoh</span><span>|</span><a href="#39663128">prev</a><span>|</span><a href="#39665953">next</a><span>|</span><label class="collapse" for="c-39663499">[-]</label><label class="expand" for="c-39663499">[3 more]</label></div><br/><div class="children"><div class="content">A bit introduction about this would be nice.</div><br/><div id="39663737" class="c"><input type="checkbox" id="c-39663737" checked=""/><div class="controls bullet"><span class="by">bionhoward</span><span>|</span><a href="#39663499">parent</a><span>|</span><a href="#39665953">next</a><span>|</span><label class="collapse" for="c-39663737">[-]</label><label class="expand" for="c-39663737">[2 more]</label></div><br/><div class="children"><div class="content">When we make game-playing AI (which is all AI, depending on your analogy comfort), one of the most promising techniques is Tree Search, which ranks moves based on the descendant moves. In games where you could reach the same state in many ways, much memory might be wasted to re-record the same state node on different branches.<p>This article is a nice exploration of an approach called Graph Search, which essentially trades compute for memory by doing extra compute work (hashing the game states) to check to see if the nodes are already visited. That saves us from re-recording nodes we already saw, and consequently converts trees (free of cycles) into directed acyclic graphs.<p>This forces some tinkering with the tree search to get correct results, specifically it demands a focus more on edges (actions or moves) as the unit of optimization, rather than on vertices (states). It’s a well written technical essay in literate programming written by someone who understands their subject.</div><br/><div id="39665951" class="c"><input type="checkbox" id="c-39665951" checked=""/><div class="controls bullet"><span class="by">3abiton</span><span>|</span><a href="#39663499">root</a><span>|</span><a href="#39663737">parent</a><span>|</span><a href="#39665953">next</a><span>|</span><label class="collapse" for="c-39665951">[-]</label><label class="expand" for="c-39665951">[1 more]</label></div><br/><div class="children"><div class="content">This was an amazing high level recap with context about the background and importance of the technique!</div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>