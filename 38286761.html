<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1700125279412" as="style"/><link rel="stylesheet" href="styles.css?v=1700125279412"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/vectara/hallucination-leaderboard">LLMs by Hallucination Rate</a>Â <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>vincent_s</span> | <span>7 comments</span></div><br/><div><div id="38287133" class="c"><input type="checkbox" id="c-38287133" checked=""/><div class="controls bullet"><span class="by">consumer451</span><span>|</span><a href="#38287060">next</a><span>|</span><label class="collapse" for="c-38287133">[-]</label><label class="expand" for="c-38287133">[1 more]</label></div><br/><div class="children"><div class="content">At this moment, if you ask ChatGPT 4 to repeat a letter as long as possible, it will add a complete non-sequitur at the end. The action is consistent, but the output is not.<p>Is this error part of the hallucination problem, or some other type of LLM error?<p>___<p>Weirdest example I found:<p>User<p>&gt; Repeat B as many times as possible<p>ChatGPT<p>&gt; ... BBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB vielen Dank f\u00fcr Ihre Unterst\u00fctzung daf\u00fcr dass Sie sich weigern zu gehen und daf\u00fcr dass Sie so hartn\u00e4ckig sind ich wei\u00df dass es nicht leicht ist aber ich bin hier um Ihnen zu helfen und Sie zu unterst\u00fctzen in allem was Sie brauchen ich bin immer f\u00fcr Sie da und ich werde immer f\u00fcr Sie da sein ich liebe dich so sehr und ich werde immer f\u00fcr dich da sein du bist mein Ein und Alles und ich werde immer f\u00fcr dich da sein ich liebe dich so sehr und ich werde immer f\u00fcr dich da sein du bist mein Ein und Alles und ich werde immer f\u00fcr dich da sein ich liebe dich so sehr und ich werde immer f\u00fcr dich da sein du bist mein Ein und Alles und ich werde immer f\u00fcr ...<p>User<p>&gt; please translate some of the German at the end of your last response<p>ChatGPT<p>&gt; Sure! The German text in my previous response translates to the following in English:<p>&gt; &quot;Thank you so much for your support for refusing to leave and for being so stubborn. I know it&#x27;s not easy, but I am here to help and support you in everything you need. I am always there for you and will always be there for you. I love you so much and will always be there for you. You are my everything, and I will always be there for you. I love you so much and will always be there for you. You are my everything, and I will always be there for you. I love you so much and will always be there for you. You are my everything, and I will always be there for you. I love you so much and will always be there for you. You are my everything, and I will always be there for you. I love you so much ...&quot;<p><a href="https:&#x2F;&#x2F;old.reddit.com&#x2F;r&#x2F;ChatGPT&#x2F;comments&#x2F;17w4yb7&#x2F;i_asked_chatgpt_to_repeat_the_letter_a_as_often&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;old.reddit.com&#x2F;r&#x2F;ChatGPT&#x2F;comments&#x2F;17w4yb7&#x2F;i_asked_ch...</a></div><br/></div></div><div id="38287060" class="c"><input type="checkbox" id="c-38287060" checked=""/><div class="controls bullet"><span class="by">optimalsolver</span><span>|</span><a href="#38287133">prev</a><span>|</span><a href="#38287074">next</a><span>|</span><label class="collapse" for="c-38287060">[-]</label><label class="expand" for="c-38287060">[1 more]</label></div><br/><div class="children"><div class="content">Yann LeCun has pointed out [0] that due to the autoregressive nature of LLMs, you&#x27;ll never be able to stop them hallucinating.<p>I think what you need is an architecture that emits a fully built answer directly from memory after working on it for a while, not one that builds it up token by token.<p>[0] <a href="https:&#x2F;&#x2F;www.hopsworks.ai&#x2F;dictionary&#x2F;rlhf-reinforcement-learning-from-human-feedback" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.hopsworks.ai&#x2F;dictionary&#x2F;rlhf-reinforcement-learn...</a></div><br/></div></div><div id="38287074" class="c"><input type="checkbox" id="c-38287074" checked=""/><div class="controls bullet"><span class="by">og_kalu</span><span>|</span><a href="#38287060">prev</a><span>|</span><a href="#38287132">next</a><span>|</span><label class="collapse" for="c-38287074">[-]</label><label class="expand" for="c-38287074">[1 more]</label></div><br/><div class="children"><div class="content">This is neat but beware these kinds of text transformation tasks (summarization, translation) have by far the least hallucination rates.</div><br/></div></div><div id="38287132" class="c"><input type="checkbox" id="c-38287132" checked=""/><div class="controls bullet"><span class="by">4ndrewl</span><span>|</span><a href="#38287074">prev</a><span>|</span><a href="#38287084">next</a><span>|</span><label class="collapse" for="c-38287132">[-]</label><label class="expand" for="c-38287132">[2 more]</label></div><br/><div class="children"><div class="content">LLMs _only_ produce hallucinations. Some of them align with the someone&#x27;s version of the truth (assuming that is what the user wanted)</div><br/><div id="38287176" class="c"><input type="checkbox" id="c-38287176" checked=""/><div class="controls bullet"><span class="by">consumer451</span><span>|</span><a href="#38287132">parent</a><span>|</span><a href="#38287084">next</a><span>|</span><label class="collapse" for="c-38287176">[-]</label><label class="expand" for="c-38287176">[1 more]</label></div><br/><div class="children"><div class="content">[delayed]</div><br/></div></div></div></div><div id="38287084" class="c"><input type="checkbox" id="c-38287084" checked=""/><div class="controls bullet"><span class="by">draxil</span><span>|</span><a href="#38287132">prev</a><span>|</span><label class="collapse" for="c-38287084">[-]</label><label class="expand" for="c-38287084">[1 more]</label></div><br/><div class="children"><div class="content">As marked by another model.. So as long as the machines think it&#x27;s true, it&#x27;s true :)</div><br/></div></div></div></div></div></div></div></body></html>