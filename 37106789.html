<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1691917258801" as="style"/><link rel="stylesheet" href="styles.css?v=1691917258801"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://arxiv.org/abs/2308.05660">Thermodynamic Linear Algebra</a> <span class="domain">(<a href="https://arxiv.org">arxiv.org</a>)</span></div><div class="subtext"><span>aifer4</span> | <span>39 comments</span></div><br/><div><div id="37107263" class="c"><input type="checkbox" id="c-37107263" checked=""/><div class="controls bullet"><span class="by">Talinx</span><span>|</span><a href="#37107227">next</a><span>|</span><label class="collapse" for="c-37107263">[-]</label><label class="expand" for="c-37107263">[2 more]</label></div><br/><div class="children"><div class="content">Does this hold up when taking quantum mechanics into account?<p>Let&#x27;s assume you need at least <i>m</i> = <i>n</i>^2 particles for a physical system modelling a <i>n</i> by <i>n</i> matrix and model the change of the system from setting the state of the particles (to the matrix elements) to measurement by a finite number of interactions between particles (by exchanging a photon):<p>- a particle can interact with a particle of the heat bath<p>- a particle can interact with another particle of the <i>m</i> particles of the system<p>I guess this result holds up if the second interaction kind does not matter because the first interaction alone then takes a constant time for each particle. The whole thing becomes a massively parallel computation (with <i>m</i> threads).<p>But the second interaction should matter, otherwise how can the system capture&#x2F;model dependencies between variables (I guess)?<p>My intuition would be that subsystems of particles get closer to the equilibrium by interaction with the heat bath and then two subsystems combine their wave functions to one by the second kind of interaction. You got subsystems that are in local thermal equilibrium that combine and split their wave functions and as time goes to <i>t_0</i> the subsystems sizes that are in local equilibrium get larger and larger until they reach size <i>m</i> at time <i>t_0</i>. This does seem to take longer for more particles (not that massively parallel anymore). Anyone got any insight into how this scales?<p>(This only matters under the assumption that the number of photon exchanges (that each particle experiences) for each of the <i>m</i> particles is finite and constant (or gets larger with larger <i>m</i>) for a fixed temperature. I could easily have missed some things that could make these thoughts irrelevant.)</div><br/><div id="37107283" class="c"><input type="checkbox" id="c-37107283" checked=""/><div class="controls bullet"><span class="by">aifer4</span><span>|</span><a href="#37107263">parent</a><span>|</span><a href="#37107227">next</a><span>|</span><label class="collapse" for="c-37107283">[-]</label><label class="expand" for="c-37107283">[1 more]</label></div><br/><div class="children"><div class="content">These results probably would not hold in the same form for a quantum system. By a quantum system, I mean a system where the decoherence time is on the order of the other timescales present in the system (e.g.
 the correlation time). In fact, it would be much more difficult to engineer such a system, and we would not want one for this purpose; the results rely on convergence to a classical canonical equilibrium distribution, which has to be generalized in the quantum case, meaning it may not have the properties we want. Also, we would have to deal with the measurement backaction on the system in the quantum limit, which we definitely don&#x27;t want. In the classical limit, where the energy is much larger than Planck&#x27;s constant divided by the timescale of the system, this is not an issue. One more thing: our algorithms use continuous measurement of the system. For a quantum system, due to the quantum Zeno effect, the system would be effectively &quot;frozen&quot;, so we would definitely not sample the full distribution.</div><br/></div></div></div></div><div id="37107227" class="c"><input type="checkbox" id="c-37107227" checked=""/><div class="controls bullet"><span class="by">fnordpiglet</span><span>|</span><a href="#37107263">prev</a><span>|</span><a href="#37107654">next</a><span>|</span><label class="collapse" for="c-37107227">[-]</label><label class="expand" for="c-37107227">[4 more]</label></div><br/><div class="children"><div class="content">In my layman’s naive view the promise of generative AI is the ability to estimate highly dimensional non linear systems effectively and efficiently. At some level these can be viewed as solving non linear systems. In my career a specific class of important problems has been estimating systems of partial different equations, and specially stochastic partial differential equations. Monte Carlo methods are often the most computable estimations. I’ve often found we approach these things by either actually linearizing or estimating a linearization of the system and using linear algebra to solve, then transforming back. All these techniques requires enormous amount of computation and extremely complex math and numerical methods. To my naive understanding (I’m more of a core systems person that’s been adjacent to the work) quantum promises to help here by directly simulating the system.<p>Would this thermodynamic technique provide solutions to these sorts of non linear optimization and system solving problems?  It feels from my reading it might, and in a simpler way to express.<p>Forgive my likely display of extraordinary ignorance.</div><br/><div id="37107292" class="c"><input type="checkbox" id="c-37107292" checked=""/><div class="controls bullet"><span class="by">aifer4</span><span>|</span><a href="#37107227">parent</a><span>|</span><a href="#37107654">next</a><span>|</span><label class="collapse" for="c-37107292">[-]</label><label class="expand" for="c-37107292">[3 more]</label></div><br/><div class="children"><div class="content">One way to think about these methods is that we are essentially implementing a Monte-Carlo algorithm physically, where on each &quot;iteration&quot; there is a matrix-vector multiplication. The physical system does this matrix-vector multiplication for us in constant time, so it does have an advantage over these digital methods. Not only that, but the &quot;clock speed&quot; of the physical system can be almost arbitrarily short, although this comes with an energy cost.</div><br/><div id="37107419" class="c"><input type="checkbox" id="c-37107419" checked=""/><div class="controls bullet"><span class="by">fnordpiglet</span><span>|</span><a href="#37107227">root</a><span>|</span><a href="#37107292">parent</a><span>|</span><a href="#37107654">next</a><span>|</span><label class="collapse" for="c-37107419">[-]</label><label class="expand" for="c-37107419">[2 more]</label></div><br/><div class="children"><div class="content">Yes that’s precisely what made me harken back to my solving of large stochastic PDE system questions :-)<p>The different though is instead of a matrix multiplication it’s a nonlinear optimization. The crucial part is the nonlinearity. But I assume given this technique is as you say Monte Carlo at its root, that shouldn’t specifically matter?</div><br/><div id="37107469" class="c"><input type="checkbox" id="c-37107469" checked=""/><div class="controls bullet"><span class="by">aifer4</span><span>|</span><a href="#37107227">root</a><span>|</span><a href="#37107419">parent</a><span>|</span><a href="#37107654">next</a><span>|</span><label class="collapse" for="c-37107469">[-]</label><label class="expand" for="c-37107469">[1 more]</label></div><br/><div class="children"><div class="content">You mentioned that such problems may be solved by solving a linear approximation of the non-linear problem (and I am in no way an expert in non-linear optimization). To the extent that the bottleneck in that approach is solving the resulting linear system, this method offers a speedup. We are also thinking about using similar thermodynamic methods to solve non-linear systems directly, but some of the nice properties of the harmonic oscillator are not present in that case, so it&#x27;s currently not clear how much (if any) speedup is there.</div><br/></div></div></div></div></div></div></div></div><div id="37107654" class="c"><input type="checkbox" id="c-37107654" checked=""/><div class="controls bullet"><span class="by">guyomes</span><span>|</span><a href="#37107227">prev</a><span>|</span><a href="#37107034">next</a><span>|</span><label class="collapse" for="c-37107654">[-]</label><label class="expand" for="c-37107654">[2 more]</label></div><br/><div class="children"><div class="content">This is very interesting, especially considering the energy-time tradeoff. I wonder how it compares to optical computing [1], where FFT can be done efficiently [2], or to analog computing for linear algebra [3].<p>[1]: <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Optical_computing#Optical_Fourier_co-processors" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Optical_computing#Optical_Four...</a><p>[2]: <a href="https:&#x2F;&#x2F;doi.org&#x2F;10.1038&#x2F;s41598-017-13733-1" rel="nofollow noreferrer">https:&#x2F;&#x2F;doi.org&#x2F;10.1038&#x2F;s41598-017-13733-1</a><p>[3]: <a href="https:&#x2F;&#x2F;doi.org&#x2F;10.1109&#x2F;MM.2017.55" rel="nofollow noreferrer">https:&#x2F;&#x2F;doi.org&#x2F;10.1109&#x2F;MM.2017.55</a></div><br/><div id="37107798" class="c"><input type="checkbox" id="c-37107798" checked=""/><div class="controls bullet"><span class="by">aifer4</span><span>|</span><a href="#37107654">parent</a><span>|</span><a href="#37107034">next</a><span>|</span><label class="collapse" for="c-37107798">[-]</label><label class="expand" for="c-37107798">[1 more]</label></div><br/><div class="children"><div class="content">Had a quick read of [3]. This work comments on three contributions to the error in an analog scheme to solve linear systems via an ODE that is encoded in the circuit dynamics, although the specific ODE being solved is not given in the paper. The three sources addressed are: gain error, offset error, and nonlinearity. It is mentioned that the first two can be corrected by calibration, while the nonlinearity error can be mitigated by scaling down the inputs to the problem (the matrix A and vector b in the equation Ax = b). It says that scaling down the problem results in lower accuracy, which I suspect can be captured by the tradeoff we show analytically between time, energy, and accuracy. It is also mentioned that “when the analog accelerator outputs are steady, we can sample the solutions once with higher-precision ADCs. However, the method here does not involve time-averaging the output of the circuit. A core result of our paper is that the accuracy converges with the length of time over which the output is averaged, so I suspect that taking a single sample is a drawback of the method presented here.</div><br/></div></div></div></div><div id="37107034" class="c"><input type="checkbox" id="c-37107034" checked=""/><div class="controls bullet"><span class="by">cperciva</span><span>|</span><a href="#37107654">prev</a><span>|</span><a href="#37106882">next</a><span>|</span><label class="collapse" for="c-37107034">[-]</label><label class="expand" for="c-37107034">[5 more]</label></div><br/><div class="children"><div class="content">A classical computer can solve a linear system in O(N) time on O(N^2) processors, too.</div><br/><div id="37107076" class="c"><input type="checkbox" id="c-37107076" checked=""/><div class="controls bullet"><span class="by">aifer4</span><span>|</span><a href="#37107034">parent</a><span>|</span><a href="#37107573">next</a><span>|</span><label class="collapse" for="c-37107076">[-]</label><label class="expand" for="c-37107076">[1 more]</label></div><br/><div class="children"><div class="content">This is an important observation, and is one of the reasons we included an energy-time tradeoff analysis in the paper. To our knowledge, this is the first result where the product energy * time has been shown to scale with dimension for solving linear systems of equations (in any computational paradigm).</div><br/></div></div><div id="37107573" class="c"><input type="checkbox" id="c-37107573" checked=""/><div class="controls bullet"><span class="by">thomasahle</span><span>|</span><a href="#37107034">parent</a><span>|</span><a href="#37107076">prev</a><span>|</span><a href="#37107159">next</a><span>|</span><label class="collapse" for="c-37107573">[-]</label><label class="expand" for="c-37107573">[1 more]</label></div><br/><div class="children"><div class="content">Here there are N cells with N^2 couplings. So as you say, a normal computer with this many processors could also solve a linear system in O(N sqrt(kappa)) time. (Using conjugate gradient, since matrix-vector-mult on the system would be O(N) time.)<p>However, (1) these thermodynamic cells are much simpler than processors, and (2) it seems the overall energy required to simulate the SDE, once the couplings are initialized, only scales with O(N), not O(N^2) as in your digital case.</div><br/></div></div></div></div><div id="37106882" class="c"><input type="checkbox" id="c-37106882" checked=""/><div class="controls bullet"><span class="by">jeremysalwen</span><span>|</span><a href="#37107034">prev</a><span>|</span><a href="#37106790">next</a><span>|</span><label class="collapse" for="c-37106882">[-]</label><label class="expand" for="c-37106882">[5 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve heard complaints about other alternative computing approaches in that they rely on the assumption of arbitrarily precise measurements, which ends up being impossible or taking an extreme amount of time due to the way the physics of measurement works.  Could you explain a bit why this is different?</div><br/><div id="37106977" class="c"><input type="checkbox" id="c-37106977" checked=""/><div class="controls bullet"><span class="by">thomasahle</span><span>|</span><a href="#37106882">parent</a><span>|</span><a href="#37106950">next</a><span>|</span><label class="collapse" for="c-37106977">[-]</label><label class="expand" for="c-37106977">[2 more]</label></div><br/><div class="children"><div class="content">Notice that the complexity depends on the error as eps^(-2), since the method is based on integrating a stochastic differential equation (SDE) over time. So this is an approximation algorithm, and not something that requires &quot;arbitrarily precise measurements&quot;.<p>You could simulate the SDE digitally, but you would probably need d^2 time per iteration, where this approach just initializes the systems and waits for it to converge to a sufficient precision. Turns out the convergence time depends on sqrt(condition number) similar to the best iterative linear solvers, conjugate gradient (CG).<p>You can debate whether it&#x27;s fair to assume a fully connected d^2 chip, since a similar size cpu or gpu could perhaps do each iteration of CG in constant time, and so would have the same (or better) complexity as the thermodynamic method. However, each cell the the proposed chip is way simpler than a cpu cell, so it should be cheaper&#x2F;more energy efficient.</div><br/><div id="37107073" class="c"><input type="checkbox" id="c-37107073" checked=""/><div class="controls bullet"><span class="by">farissbahi</span><span>|</span><a href="#37106882">root</a><span>|</span><a href="#37106977">parent</a><span>|</span><a href="#37106950">next</a><span>|</span><label class="collapse" for="c-37107073">[-]</label><label class="expand" for="c-37107073">[1 more]</label></div><br/><div class="children"><div class="content">Great explanation!</div><br/></div></div></div></div><div id="37106950" class="c"><input type="checkbox" id="c-37106950" checked=""/><div class="controls bullet"><span class="by">hiddencost</span><span>|</span><a href="#37106882">parent</a><span>|</span><a href="#37106977">prev</a><span>|</span><a href="#37106941">next</a><span>|</span><label class="collapse" for="c-37106950">[-]</label><label class="expand" for="c-37106950">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;quant-ph&#x2F;0502072" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;quant-ph&#x2F;0502072</a><p>Your comment reminded me of this classic of the genre.<p>An extremely approachable read.</div><br/></div></div><div id="37106941" class="c"><input type="checkbox" id="c-37106941" checked=""/><div class="controls bullet"><span class="by">aifer4</span><span>|</span><a href="#37106882">parent</a><span>|</span><a href="#37106950">prev</a><span>|</span><a href="#37106790">next</a><span>|</span><label class="collapse" for="c-37106941">[-]</label><label class="expand" for="c-37106941">[1 more]</label></div><br/><div class="children"><div class="content">Good question. There are different ways that errors come into analog computations, including thermal noise, measurement imprecision, and imprecision of the device&#x27;s physical parameters. This work addresses thermal noise (which is always present at finite temperature), and provides algorithms which are indifferent to thermal noise, or even benefit from it. The other sources of error can, in principle, be made arbitrarily small (at least down to the quantum limit), but in practice are also limiting factors. Progress has been made on error mitigation methods to deal with these other sources of error, so stay tuned.</div><br/></div></div></div></div><div id="37106790" class="c"><input type="checkbox" id="c-37106790" checked=""/><div class="controls bullet"><span class="by">aifer4</span><span>|</span><a href="#37106882">prev</a><span>|</span><a href="#37107478">next</a><span>|</span><label class="collapse" for="c-37106790">[-]</label><label class="expand" for="c-37106790">[1 more]</label></div><br/><div class="children"><div class="content">Latest research from <a href="https:&#x2F;&#x2F;normalcomputing.ai&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;normalcomputing.ai&#x2F;</a>. Feedback welcome!</div><br/></div></div><div id="37107478" class="c"><input type="checkbox" id="c-37107478" checked=""/><div class="controls bullet"><span class="by">chenghuzi</span><span>|</span><a href="#37106790">prev</a><span>|</span><a href="#37107201">next</a><span>|</span><label class="collapse" for="c-37107478">[-]</label><label class="expand" for="c-37107478">[4 more]</label></div><br/><div class="children"><div class="content">The RC circuit looks familiar. Is it related to neuromorphic computing hardware? Can it be implemented with existing hardware?</div><br/><div id="37107508" class="c"><input type="checkbox" id="c-37107508" checked=""/><div class="controls bullet"><span class="by">aifer4</span><span>|</span><a href="#37107478">parent</a><span>|</span><a href="#37107201">next</a><span>|</span><label class="collapse" for="c-37107508">[-]</label><label class="expand" for="c-37107508">[3 more]</label></div><br/><div class="children"><div class="content">An interesting feature of this approach is that the proposed hardware doesn&#x27;t rely on non-linear elements, memristors, or even active elements (besides an optional noise source). It is simply a passive network of oscillators with a DC bias on each cell. That said, the hardware to implement this at scale does not currently seem to exist. To my knowledge, the state of the art is <a href="https:&#x2F;&#x2F;app.normalcomputing.ai&#x2F;composer" rel="nofollow noreferrer">https:&#x2F;&#x2F;app.normalcomputing.ai&#x2F;composer</a></div><br/><div id="37107633" class="c"><input type="checkbox" id="c-37107633" checked=""/><div class="controls bullet"><span class="by">chenghuzi</span><span>|</span><a href="#37107478">root</a><span>|</span><a href="#37107508">parent</a><span>|</span><a href="#37107201">next</a><span>|</span><label class="collapse" for="c-37107633">[-]</label><label class="expand" for="c-37107633">[2 more]</label></div><br/><div class="children"><div class="content">From what I see, it&#x27;s like mimicking the annealing process and the &quot;derivative&quot; automatically drives you to the solution. If that&#x27;s the case, implementing such hardware should be not that hard except for the programmable coupling part. A bit off-topic, this reminds me of the duality between any deep forward network and a modern Hopfield network with some special energy functions, in which the duality is based on the fact that the forward running process can be seen as an energy minimization process.</div><br/><div id="37107888" class="c"><input type="checkbox" id="c-37107888" checked=""/><div class="controls bullet"><span class="by">aifer4</span><span>|</span><a href="#37107478">root</a><span>|</span><a href="#37107633">parent</a><span>|</span><a href="#37107201">next</a><span>|</span><label class="collapse" for="c-37107888">[-]</label><label class="expand" for="c-37107888">[1 more]</label></div><br/><div class="children"><div class="content">The relationship with Hopfield networks sounds fascinating, would love to discuss further. As you mentioned, there is a connection to annealing in that we are encoding the solution to our problem in the minimization of a physical system&#x27;s energy. Indeed, the all-to-all coupling is the hard part!</div><br/></div></div></div></div></div></div></div></div><div id="37107201" class="c"><input type="checkbox" id="c-37107201" checked=""/><div class="controls bullet"><span class="by">notphya</span><span>|</span><a href="#37107478">prev</a><span>|</span><a href="#37107205">next</a><span>|</span><label class="collapse" for="c-37107201">[-]</label><label class="expand" for="c-37107201">[4 more]</label></div><br/><div class="children"><div class="content">We have mass-energy equivalence.<p>Do we also have information-energy equivalence? Can we use the Landauer bounds to prove by transitivity that information and energy are equivalent?</div><br/><div id="37107223" class="c"><input type="checkbox" id="c-37107223" checked=""/><div class="controls bullet"><span class="by">aifer4</span><span>|</span><a href="#37107201">parent</a><span>|</span><a href="#37107301">next</a><span>|</span><label class="collapse" for="c-37107223">[-]</label><label class="expand" for="c-37107223">[1 more]</label></div><br/><div class="children"><div class="content">Straying a bit off topic, but I think one of the more sensible approaches to information-energy equivalence is a thermodynamic engine with an information reservoir (in addition to the heat and work reservoirs normally considered). <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;1408.1224.pdf" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;1408.1224.pdf</a> <a href="https:&#x2F;&#x2F;journals.aps.org&#x2F;prx&#x2F;pdf&#x2F;10.1103&#x2F;PhysRevX.3.041003" rel="nofollow noreferrer">https:&#x2F;&#x2F;journals.aps.org&#x2F;prx&#x2F;pdf&#x2F;10.1103&#x2F;PhysRevX.3.041003</a></div><br/></div></div><div id="37107301" class="c"><input type="checkbox" id="c-37107301" checked=""/><div class="controls bullet"><span class="by">NooneAtAll3</span><span>|</span><a href="#37107201">parent</a><span>|</span><a href="#37107223">prev</a><span>|</span><a href="#37107394">next</a><span>|</span><label class="collapse" for="c-37107301">[-]</label><label class="expand" for="c-37107301">[1 more]</label></div><br/><div class="children"><div class="content">Maxwell&#x27;s demon?<p>more of information-entropy equivalence, but close enough</div><br/></div></div></div></div><div id="37107205" class="c"><input type="checkbox" id="c-37107205" checked=""/><div class="controls bullet"><span class="by">farissbahi</span><span>|</span><a href="#37107201">prev</a><span>|</span><a href="#37107509">next</a><span>|</span><label class="collapse" for="c-37107205">[-]</label><label class="expand" for="c-37107205">[1 more]</label></div><br/><div class="children"><div class="content">You can play with it here too! <a href="https:&#x2F;&#x2F;app.normalcomputing.ai&#x2F;composer" rel="nofollow noreferrer">https:&#x2F;&#x2F;app.normalcomputing.ai&#x2F;composer</a><p>cc <a href="https:&#x2F;&#x2F;twitter.com&#x2F;NormalComputing" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;NormalComputing</a></div><br/></div></div><div id="37107509" class="c"><input type="checkbox" id="c-37107509" checked=""/><div class="controls bullet"><span class="by">pama</span><span>|</span><a href="#37107205">prev</a><span>|</span><a href="#37107111">next</a><span>|</span><label class="collapse" for="c-37107509">[-]</label><label class="expand" for="c-37107509">[5 more]</label></div><br/><div class="children"><div class="content">Other than simulating the Hamiltonian on a digital computer, are there any prototype hardware devices that can perform this computation?</div><br/><div id="37107514" class="c"><input type="checkbox" id="c-37107514" checked=""/><div class="controls bullet"><span class="by">aifer4</span><span>|</span><a href="#37107509">parent</a><span>|</span><a href="#37107111">next</a><span>|</span><label class="collapse" for="c-37107514">[-]</label><label class="expand" for="c-37107514">[4 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;app.normalcomputing.ai&#x2F;composer" rel="nofollow noreferrer">https:&#x2F;&#x2F;app.normalcomputing.ai&#x2F;composer</a></div><br/><div id="37107566" class="c"><input type="checkbox" id="c-37107566" checked=""/><div class="controls bullet"><span class="by">pama</span><span>|</span><a href="#37107509">root</a><span>|</span><a href="#37107514">parent</a><span>|</span><a href="#37107111">next</a><span>|</span><label class="collapse" for="c-37107566">[-]</label><label class="expand" for="c-37107566">[3 more]</label></div><br/><div class="children"><div class="content">Thanks. Do you have somewhere a demo of the hardware performing these computations?</div><br/><div id="37107582" class="c"><input type="checkbox" id="c-37107582" checked=""/><div class="controls bullet"><span class="by">aifer4</span><span>|</span><a href="#37107509">root</a><span>|</span><a href="#37107566">parent</a><span>|</span><a href="#37107111">next</a><span>|</span><label class="collapse" for="c-37107582">[-]</label><label class="expand" for="c-37107582">[2 more]</label></div><br/><div class="children"><div class="content">We do not (yet?). Here is a simulation I made of similar hardware demonstrating the equilibration step of the algorithm <a href="https:&#x2F;&#x2F;app.normalcomputing.ai&#x2F;composer&#x2F;playground" rel="nofollow noreferrer">https:&#x2F;&#x2F;app.normalcomputing.ai&#x2F;composer&#x2F;playground</a></div><br/><div id="37107607" class="c"><input type="checkbox" id="c-37107607" checked=""/><div class="controls bullet"><span class="by">farissbahi</span><span>|</span><a href="#37107509">root</a><span>|</span><a href="#37107582">parent</a><span>|</span><a href="#37107111">next</a><span>|</span><label class="collapse" for="c-37107607">[-]</label><label class="expand" for="c-37107607">[1 more]</label></div><br/><div class="children"><div class="content">Patrick Coles gives an excellent walkthrough on this as well. <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;live&#x2F;dd1jURhLR8Y?feature=share&amp;t=2843">https:&#x2F;&#x2F;www.youtube.com&#x2F;live&#x2F;dd1jURhLR8Y?feature=share&amp;t=284...</a></div><br/></div></div></div></div></div></div></div></div></div></div><div id="37107111" class="c"><input type="checkbox" id="c-37107111" checked=""/><div class="controls bullet"><span class="by">foota</span><span>|</span><a href="#37107509">prev</a><span>|</span><a href="#37107172">next</a><span>|</span><label class="collapse" for="c-37107111">[-]</label><label class="expand" for="c-37107111">[3 more]</label></div><br/><div class="children"><div class="content">Isn&#x27;t there a relation between entropy and computation? It would be interesting to see how these are related.</div><br/><div id="37107132" class="c"><input type="checkbox" id="c-37107132" checked=""/><div class="controls bullet"><span class="by">aifer4</span><span>|</span><a href="#37107111">parent</a><span>|</span><a href="#37107172">next</a><span>|</span><label class="collapse" for="c-37107132">[-]</label><label class="expand" for="c-37107132">[2 more]</label></div><br/><div class="children"><div class="content">Definitely. Landauer&#x27;s principle gives a lower bound on the amount of energy a computation requires, which is k_B T ln(2) times the number of bits erased in the process, the decrease in Shannon entropy. Our energy cost analysis is not based on the Landauer limit, but simply on the energy difference between equilibrium states. But our algorithm for estimating the determinant is based on effectively measuring the entropy difference between equilibrium states.</div><br/><div id="37107996" class="c"><input type="checkbox" id="c-37107996" checked=""/><div class="controls bullet"><span class="by">canjobear</span><span>|</span><a href="#37107111">root</a><span>|</span><a href="#37107132">parent</a><span>|</span><a href="#37107172">next</a><span>|</span><label class="collapse" for="c-37107996">[-]</label><label class="expand" for="c-37107996">[1 more]</label></div><br/><div class="children"><div class="content">I always have trouble thinking of computation in terms of “bits erased”. How many bits are erased when I sort an array? Or invert a matrix? Or compute a function like f(x)=1, which seems to maximally erase information, but doesn’t intuitively seem like it should cost a lot of energy.</div><br/></div></div></div></div></div></div><div id="37107865" class="c"><input type="checkbox" id="c-37107865" checked=""/><div class="controls bullet"><span class="by">iraqmtpizza</span><span>|</span><a href="#37107172">prev</a><span>|</span><label class="collapse" for="c-37107865">[-]</label><label class="expand" for="c-37107865">[1 more]</label></div><br/><div class="children"><div class="content">can we factor 35 with Shor&#x27;s algorithm yet lol</div><br/></div></div></div></div></div></div></div></body></html>