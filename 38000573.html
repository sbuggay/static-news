<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1698310857959" as="style"/><link rel="stylesheet" href="styles.css?v=1698310857959"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://resobscura.substack.com/p/simulating-history-with-multimodal">Simulating History with Multimodal AI: An Update</a>Â <span class="domain">(<a href="https://resobscura.substack.com">resobscura.substack.com</a>)</span></div><div class="subtext"><span>benbreen</span> | <span>6 comments</span></div><br/><div><div id="38022190" class="c"><input type="checkbox" id="c-38022190" checked=""/><div class="controls bullet"><span class="by">qingcharles</span><span>|</span><a href="#38022332">next</a><span>|</span><label class="collapse" for="c-38022190">[-]</label><label class="expand" for="c-38022190">[4 more]</label></div><br/><div class="children"><div class="content">This is fantastic.<p>With the developments in AI it won&#x27;t be long before you can just drop into ancient Rome and have the entire VR world generated on the fly with all the NPCs acting as they would based on the AI&#x27;s understanding of the era taken from every contemporary document it has access to.<p>I predicted a few years ago that as AI improves we&#x27;ll move closer and closer to being able to build an (inaccurate but close) VR time machine. The alarming thing I&#x27;ve discovered with AI is that you don&#x27;t need a huge corpus of prior communications to reasonably emulate somebody&#x27;s personality.<p>None of us are as unique or amazing as we think we are :)<p>(weirdly I got an almost identical output to the writer in the article even though I modified the prompt he used and asked for a hyper realistic photograph: <a href="https:&#x2F;&#x2F;imgur.com&#x2F;a&#x2F;uizM07g" rel="nofollow noreferrer">https:&#x2F;&#x2F;imgur.com&#x2F;a&#x2F;uizM07g</a> )</div><br/><div id="38022896" class="c"><input type="checkbox" id="c-38022896" checked=""/><div class="controls bullet"><span class="by">RandomLensman</span><span>|</span><a href="#38022190">parent</a><span>|</span><a href="#38022194">next</a><span>|</span><label class="collapse" for="c-38022896">[-]</label><label class="expand" for="c-38022896">[2 more]</label></div><br/><div class="children"><div class="content">And we will believe all the lies AI will tell us about the past because we have no way to verify - what an amazing future.<p>Alternatively, we will only understand anything in ancient Rome if we understand Latin and other languages because the NPC stay true to that.<p>The biggest issue would be that Romans viewed certain things so different to us, so our ability to understand would need heavy support to work.</div><br/><div id="38023153" class="c"><input type="checkbox" id="c-38023153" checked=""/><div class="controls bullet"><span class="by">taneq</span><span>|</span><a href="#38022190">root</a><span>|</span><a href="#38022896">parent</a><span>|</span><a href="#38022194">next</a><span>|</span><label class="collapse" for="c-38023153">[-]</label><label class="expand" for="c-38023153">[1 more]</label></div><br/><div class="children"><div class="content">Aw man, this is gonna be like Civilization with hyper-aggressive Gandhi all over again.</div><br/></div></div></div></div><div id="38022194" class="c"><input type="checkbox" id="c-38022194" checked=""/><div class="controls bullet"><span class="by">jackblemming</span><span>|</span><a href="#38022190">parent</a><span>|</span><a href="#38022896">prev</a><span>|</span><a href="#38022332">next</a><span>|</span><label class="collapse" for="c-38022194">[-]</label><label class="expand" for="c-38022194">[1 more]</label></div><br/><div class="children"><div class="content">&gt;I predicted<p>Star Trek was a few decades before you.</div><br/></div></div></div></div><div id="38022332" class="c"><input type="checkbox" id="c-38022332" checked=""/><div class="controls bullet"><span class="by">tomohelix</span><span>|</span><a href="#38022190">prev</a><span>|</span><label class="collapse" for="c-38022332">[-]</label><label class="expand" for="c-38022332">[1 more]</label></div><br/><div class="children"><div class="content">Has there been any breakthroughs or sign of a breakthrough in term of LLM training efficiency and inference cost? Right now it seems like the capabilities of the models are the focus with more accurate image generation, videos, less hallucinations, etc. But it always at the cost of computing power. Average guy can&#x27;t afford a $600 GPU to run Stable Diffusion at home at full capacity...</div><br/></div></div></div></div></div></div></div></body></html>