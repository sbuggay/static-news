<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1687597258424" as="style"/><link rel="stylesheet" href="styles.css?v=1687597258424"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.theregister.com/2023/06/23/open_source_licenses_ai/">Open source licenses need to leave the 1980s and evolve to deal with AI</a> <span class="domain">(<a href="https://www.theregister.com">www.theregister.com</a>)</span></div><div class="subtext"><span>gumby</span> | <span>58 comments</span></div><br/><div><div id="36456226" class="c"><input type="checkbox" id="c-36456226" checked=""/><div class="controls bullet"><span class="by">cornholio</span><span>|</span><a href="#36456221">next</a><span>|</span><label class="collapse" for="c-36456226">[-]</label><label class="expand" for="c-36456226">[22 more]</label></div><br/><div class="children"><div class="content">The existing licenses cover AI training just fine, what we lack is sufficient legal precedent and enforcement. An AI product - more specifically, the model weights - is a derivative work of the original works used for training; AI training is a process of algorithmic compression of the originals.<p>Therefore, the resulting model should abide by all the license requirements imposed on the original - for example, if the model is trained on GPL code and can generate code, then any binary distribution should also be freely available for derivation in source format, and that includes all the algorithmically compressed training material (weights), which has become part of the model. If the source is AGPL, then that service cannot be made available on a website without disclosing said source and respective model weights.<p>Any other interpretation of the nature of copyright - which by definition, only covers human produced material - is just a variant of the proverbial &quot;man that can&#x27;t understand something because their paycheck depends upon them not understanding&quot;.</div><br/><div id="36456335" class="c"><input type="checkbox" id="c-36456335" checked=""/><div class="controls bullet"><span class="by">jl6</span><span>|</span><a href="#36456226">parent</a><span>|</span><a href="#36456297">next</a><span>|</span><label class="collapse" for="c-36456335">[-]</label><label class="expand" for="c-36456335">[3 more]</label></div><br/><div class="children"><div class="content">It’s not clear to me that it’s any easier to judge this than in human cases of “inspiration vs infringement”. What part of the model weights can a lawyer point to and say “this bit clearly incorporates a substantial portion of my client’s work”.</div><br/><div id="36456465" class="c"><input type="checkbox" id="c-36456465" checked=""/><div class="controls bullet"><span class="by">xyzzy123</span><span>|</span><a href="#36456226">root</a><span>|</span><a href="#36456335">parent</a><span>|</span><a href="#36456297">next</a><span>|</span><label class="collapse" for="c-36456465">[-]</label><label class="expand" for="c-36456465">[2 more]</label></div><br/><div class="children"><div class="content">I feel this argument is weakened by the fact that no one training these models feeds their own proprietary source code into publicly available models.<p>Practically speaking I feel this is a strong hint that some degree of copyright laundering is taking place.</div><br/><div id="36456699" class="c"><input type="checkbox" id="c-36456699" checked=""/><div class="controls bullet"><span class="by">ShamelessC</span><span>|</span><a href="#36456226">root</a><span>|</span><a href="#36456465">parent</a><span>|</span><a href="#36456297">next</a><span>|</span><label class="collapse" for="c-36456699">[-]</label><label class="expand" for="c-36456699">[1 more]</label></div><br/><div class="children"><div class="content">&gt; no one training these models feeds their own proprietary source code into publicly available models<p>You are presupposing that the company’s own code would somehow be a massive boon for the model, resulting in lower loss overall.<p>In reality, it would skew the model towards that company’s “mode” of coding which isn’t what “normal” programmers expect. In fact, they are most likely to expect the coding styles they learned from, and that is most likely to be found in public examples (GitHub, StackOverflow, textbooks, Reddit, etc.)<p>This argument is so silly to me. Anyone who has worked at a large enterprise, whether it’s Google, Amazon or Target, knows that company code is effectively guaranteed to be extremely hard to work with. This happens for organizational reasons and really the best thing to do about it is admit that it’s happening rather than pretend it’s all perfect.</div><br/></div></div></div></div></div></div><div id="36456297" class="c"><input type="checkbox" id="c-36456297" checked=""/><div class="controls bullet"><span class="by">EMIRELADERO</span><span>|</span><a href="#36456226">parent</a><span>|</span><a href="#36456335">prev</a><span>|</span><a href="#36456455">next</a><span>|</span><label class="collapse" for="c-36456297">[-]</label><label class="expand" for="c-36456297">[7 more]</label></div><br/><div class="children"><div class="content">What if the whole pipeline (scraping for training, the training itself, model distribution, and use to generate derivative works) is found to be a fair use (at least in American law)? Licenses wouldn&#x27;t mean anything at that point, since it&#x27;s because of copyright that they can make you accept them in the first place</div><br/><div id="36456466" class="c"><input type="checkbox" id="c-36456466" checked=""/><div class="controls bullet"><span class="by">noobermin</span><span>|</span><a href="#36456226">root</a><span>|</span><a href="#36456297">parent</a><span>|</span><a href="#36456455">next</a><span>|</span><label class="collapse" for="c-36456466">[-]</label><label class="expand" for="c-36456466">[6 more]</label></div><br/><div class="children"><div class="content">Then every employee of openai should scrape the weights of GPT-4 and train their own neural nets. That would not be a derivative work and also be free use under this logic.</div><br/><div id="36456482" class="c"><input type="checkbox" id="c-36456482" checked=""/><div class="controls bullet"><span class="by">EMIRELADERO</span><span>|</span><a href="#36456226">root</a><span>|</span><a href="#36456466">parent</a><span>|</span><a href="#36456508">next</a><span>|</span><label class="collapse" for="c-36456482">[-]</label><label class="expand" for="c-36456482">[1 more]</label></div><br/><div class="children"><div class="content">Obviously this isn&#x27;t tested in the courts (for now) but it is my opinion that model weights aren&#x27;t even copyrightable.</div><br/></div></div><div id="36456508" class="c"><input type="checkbox" id="c-36456508" checked=""/><div class="controls bullet"><span class="by">banana_feather</span><span>|</span><a href="#36456226">root</a><span>|</span><a href="#36456466">parent</a><span>|</span><a href="#36456482">prev</a><span>|</span><a href="#36456577">next</a><span>|</span><label class="collapse" for="c-36456508">[-]</label><label class="expand" for="c-36456508">[3 more]</label></div><br/><div class="children"><div class="content">That&#x27;s not how fair use works. This kind of use would facially fail three of the factors for fair use; it&#x27;s not be transformative, it copies the original work in its entirety, and it harms the commercial market for the original work.</div><br/><div id="36456569" class="c"><input type="checkbox" id="c-36456569" checked=""/><div class="controls bullet"><span class="by">wnkrshm</span><span>|</span><a href="#36456226">root</a><span>|</span><a href="#36456508">parent</a><span>|</span><a href="#36456577">next</a><span>|</span><label class="collapse" for="c-36456569">[-]</label><label class="expand" for="c-36456569">[2 more]</label></div><br/><div class="children"><div class="content">how much do the weights have to change for it to be transformative? Edit: you arrive at the same question as taking an image with img2img and running it through a diffusion variant - keeping the composition, colors etc. but no the details</div><br/><div id="36456621" class="c"><input type="checkbox" id="c-36456621" checked=""/><div class="controls bullet"><span class="by">banana_feather</span><span>|</span><a href="#36456226">root</a><span>|</span><a href="#36456569">parent</a><span>|</span><a href="#36456577">next</a><span>|</span><label class="collapse" for="c-36456621">[-]</label><label class="expand" for="c-36456621">[1 more]</label></div><br/><div class="children"><div class="content">Much of the case law about the &quot;transformative&quot; factor focuses on &quot;new meaning or expression&quot;, but it&#x27;s about visual art, which is generally very difficult to reason about w.r.t. copyright. I think the example to look to for technology is Authors Guild v. Google, where &quot;transformative&quot; is more about non-expressive purpose, and it was considered transformative to copy a bunch of books to produce a search functionality, since the search functionality (which only displayed snippets) was a transformative purpose compared to the underlying creative expression in the books.</div><br/></div></div></div></div></div></div><div id="36456577" class="c"><input type="checkbox" id="c-36456577" checked=""/><div class="controls bullet"><span class="by">schoen</span><span>|</span><a href="#36456226">root</a><span>|</span><a href="#36456466">parent</a><span>|</span><a href="#36456508">prev</a><span>|</span><a href="#36456455">next</a><span>|</span><label class="collapse" for="c-36456577">[-]</label><label class="expand" for="c-36456577">[1 more]</label></div><br/><div class="children"><div class="content">It seems credible to me to suggest that the model weights are a trade secret, but aren&#x27;t copyrightable. There&#x27;s lots of stuff that could be in that category for other companies.<p>The employees would still have a contractual responsibility about their use of the model weights.</div><br/></div></div></div></div></div></div><div id="36456455" class="c"><input type="checkbox" id="c-36456455" checked=""/><div class="controls bullet"><span class="by">jstummbillig</span><span>|</span><a href="#36456226">parent</a><span>|</span><a href="#36456297">prev</a><span>|</span><a href="#36456385">next</a><span>|</span><label class="collapse" for="c-36456455">[-]</label><label class="expand" for="c-36456455">[3 more]</label></div><br/><div class="children"><div class="content">&gt; The existing licenses cover AI training just fine [...] An AI product - more specifically, the model weights - is a derivative work of the original works used for training<p>The presumption is entirely debatable. A human is not considered derivative work of the original works they used for training.<p>&gt; Any other interpretation of the nature of copyright [...]  which by definition, only covers human produced material<p>Maybe copyright needs to leave the 1980s and evolve to deal with AI too? Maybe you do, too?</div><br/><div id="36456793" class="c"><input type="checkbox" id="c-36456793" checked=""/><div class="controls bullet"><span class="by">JoshTriplett</span><span>|</span><a href="#36456226">root</a><span>|</span><a href="#36456455">parent</a><span>|</span><a href="#36456561">next</a><span>|</span><label class="collapse" for="c-36456793">[-]</label><label class="expand" for="c-36456793">[1 more]</label></div><br/><div class="children"><div class="content">A human is not copyrightable.<p>And copyright is doing its job just fine; AI training committing Open Source license violations en masse is the problem here.<p>I&#x27;m all for copyright ceasing to exist, at which point AI training and lots of other things gets easier. As long as it <i>does</i> exist, however, AI training must respect it, and not become a copyright-violation laundering mechanism.</div><br/></div></div><div id="36456561" class="c"><input type="checkbox" id="c-36456561" checked=""/><div class="controls bullet"><span class="by">hulitu</span><span>|</span><a href="#36456226">root</a><span>|</span><a href="#36456455">parent</a><span>|</span><a href="#36456793">prev</a><span>|</span><a href="#36456385">next</a><span>|</span><label class="collapse" for="c-36456561">[-]</label><label class="expand" for="c-36456561">[1 more]</label></div><br/><div class="children"><div class="content">It deals with &quot;AI&quot; just fine. But not in the way Microsoft, for the extinguish phase, wants.</div><br/></div></div></div></div><div id="36456385" class="c"><input type="checkbox" id="c-36456385" checked=""/><div class="controls bullet"><span class="by">mindcrime</span><span>|</span><a href="#36456226">parent</a><span>|</span><a href="#36456455">prev</a><span>|</span><a href="#36456221">next</a><span>|</span><label class="collapse" for="c-36456385">[-]</label><label class="expand" for="c-36456385">[8 more]</label></div><br/><div class="children"><div class="content"><i>An AI product - more specifically, the model weights - is a derivative work of the original works used for training;</i><p>I don&#x27;t think that&#x27;s so obvious. Why would it be so, any more than for humans who learn from material?<p>I mean, one might ask if your very comment here is a derivative work of the aggregate corpus of material you&#x27;ve previously read on the subjects of copyright, open source licensing, and AI. I suspect most of us would agree that it <i>isn&#x27;t</i> so, but why treat the model weights of an AI so differently than the synaptic weights in your brain?</div><br/><div id="36456459" class="c"><input type="checkbox" id="c-36456459" checked=""/><div class="controls bullet"><span class="by">cornholio</span><span>|</span><a href="#36456226">root</a><span>|</span><a href="#36456385">parent</a><span>|</span><a href="#36456475">next</a><span>|</span><label class="collapse" for="c-36456459">[-]</label><label class="expand" for="c-36456459">[4 more]</label></div><br/><div class="children"><div class="content">Because copyright, and law in general, is an expression of the political agreement reached amongst the members of our society. It does not exist in the absolute, there are no legal principles that transcend humanity, law is a human creation to arbitrate our collaboration and conflicts.<p>Therefore, in the legal sense, an algorithm does not &quot;learn&quot;, despite any functional analogy you can make with human learning, because an algorithm is not a party to the social contract that established said law; its only &quot;rights&quot; are an extension of the legal right of its author&#x2F;proprietor. Your &quot;learning&quot; right does not cover, for example, your tape player recording a performance and playing it back at later date to some commercial audience. You have a right to hear and learn the song, you can play it back from memory, but your tape recorder does not, it&#x27;s a tool, just like your fancy AI machine.<p>This will continue to hold true despite any advancements in AI, up to the moment when synthetic entities will acquire distinct legal rights.</div><br/><div id="36456841" class="c"><input type="checkbox" id="c-36456841" checked=""/><div class="controls bullet"><span class="by">tsimionescu</span><span>|</span><a href="#36456226">root</a><span>|</span><a href="#36456459">parent</a><span>|</span><a href="#36456486">next</a><span>|</span><label class="collapse" for="c-36456841">[-]</label><label class="expand" for="c-36456841">[1 more]</label></div><br/><div class="children"><div class="content">&gt; You have a right to hear and learn the song, you can play it back from memory<p>You do not in fact have a right to play a copyrighted song from memory, any more than you have a right to play a recording, unless you&#x27;re playing it for yourself. Just like you don&#x27;t have a right to show a movie on a DVD you bought to others.</div><br/></div></div><div id="36456486" class="c"><input type="checkbox" id="c-36456486" checked=""/><div class="controls bullet"><span class="by">mindcrime</span><span>|</span><a href="#36456226">root</a><span>|</span><a href="#36456459">parent</a><span>|</span><a href="#36456841">prev</a><span>|</span><a href="#36456530">next</a><span>|</span><label class="collapse" for="c-36456486">[-]</label><label class="expand" for="c-36456486">[1 more]</label></div><br/><div class="children"><div class="content"><i>Therefore, in the legal sense, an algorithm does not &quot;learn&quot;,</i><p>Are you saying there is actual case law &#x2F; precedent establishing that, or is that just your personal theory? If the former, I&#x27;d love to see any such citations, as I was not aware of those developments.<p><i>Your &quot;learning&quot; right does not cover, for example, your tape player recording a performance and playing it back at later date to some commercial audience.</i><p>That&#x27;s pretty much a straw-man here. I&#x27;m not talking about cases where an AI reproduces an existing work exactly. That is problematic from a copyright standpoint for both a machine OR a human.</div><br/></div></div><div id="36456530" class="c"><input type="checkbox" id="c-36456530" checked=""/><div class="controls bullet"><span class="by">est31</span><span>|</span><a href="#36456226">root</a><span>|</span><a href="#36456459">parent</a><span>|</span><a href="#36456486">prev</a><span>|</span><a href="#36456475">next</a><span>|</span><label class="collapse" for="c-36456530">[-]</label><label class="expand" for="c-36456530">[1 more]</label></div><br/><div class="children"><div class="content">&gt; You have a right to hear and learn the song, you can play it back from memory, but your tape recorder does not, it&#x27;s a tool, just like your fancy AI machine.<p>There is two different copyrights, one for the melody&#x2F;text, and one for the recording. Sometimes they have different owners who fight. The most famous recent example is the Taylor Swift controversy I guess. She ended up re-recording some of her old songs so that she owns the rights to the new recording.<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Taylor_Swift_masters_controversy#Law" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Taylor_Swift_masters_controver...</a></div><br/></div></div></div></div><div id="36456475" class="c"><input type="checkbox" id="c-36456475" checked=""/><div class="controls bullet"><span class="by">eviks</span><span>|</span><a href="#36456226">root</a><span>|</span><a href="#36456385">parent</a><span>|</span><a href="#36456459">prev</a><span>|</span><a href="#36456415">next</a><span>|</span><label class="collapse" for="c-36456475">[-]</label><label class="expand" for="c-36456475">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Why would it be so, any more than for humans who learn from material?<p>Because AI isn&#x27;t human, and there is no credible argument that it&#x27;s anything close to a human, and unless you do establish that connection, you can&#x27;t just auto-apply the logic&#x2F;intuition we&#x27;ve developed for humans to AI</div><br/></div></div><div id="36456415" class="c"><input type="checkbox" id="c-36456415" checked=""/><div class="controls bullet"><span class="by">pbalcer</span><span>|</span><a href="#36456226">root</a><span>|</span><a href="#36456385">parent</a><span>|</span><a href="#36456475">prev</a><span>|</span><a href="#36456221">next</a><span>|</span><label class="collapse" for="c-36456415">[-]</label><label class="expand" for="c-36456415">[2 more]</label></div><br/><div class="children"><div class="content">When you want a clean room non-GPL implementation of something GPL that already exists, you ask the developers not to look at the original. I don&#x27;t see how this is any different.</div><br/><div id="36456467" class="c"><input type="checkbox" id="c-36456467" checked=""/><div class="controls bullet"><span class="by">mindcrime</span><span>|</span><a href="#36456226">root</a><span>|</span><a href="#36456415">parent</a><span>|</span><a href="#36456221">next</a><span>|</span><label class="collapse" for="c-36456467">[-]</label><label class="expand" for="c-36456467">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s completely different. You&#x27;re talking about re-implementing a specific piece of software. And that whole &quot;clean room&quot; thing isn&#x27;t an absolute anyway... that&#x27;s the level of paranoia you engage if you want to be <i>super duper sure</i> that you can&#x27;t be accused of copying the original.<p>What I&#x27;m talking about is closer to &quot;you fire up your IDE (or Emacs) right now, and churn out 250 lines of code for some arbitrary piece of software. Is it a derivative work of every pieces of software whose source code you have previously look at?&quot;<p>Note that I&#x27;m not referring to the case where the AI spits out code that is identical to code taken from another project. I&#x27;m aware that that sometimes happens, and <i>that</i> is obviously a problem, just like it would if a human did it. What I&#x27;m arguing is only that it <i>probably</i> should not be taken as a given that AI generated code is automatically considered a derivative work.<p>Here&#x27;s a thought experiment: say an AI emits a single line of code tomorrow. You examine it, and then spend weeks, months, or even years searching all the open source code that&#x27;s &quot;out there&quot;. You fail to identify a line in any existing code-base that was clearly the upstream source for the line from the AI. So is that line a derivative work? If so, of what?</div><br/></div></div></div></div></div></div></div></div><div id="36456221" class="c"><input type="checkbox" id="c-36456221" checked=""/><div class="controls bullet"><span class="by">JoshTriplett</span><span>|</span><a href="#36456226">prev</a><span>|</span><a href="#36456268">next</a><span>|</span><label class="collapse" for="c-36456221">[-]</label><label class="expand" for="c-36456221">[3 more]</label></div><br/><div class="children"><div class="content">We don&#x27;t need Open Source licenses to change to deal with AI. We need AI to respect Open Source licenses, or not use code under those licenses.<p>I sincerely hope that one of the many court cases produces a verdict that says AI-generated code is, in fact, subject to the licenses of the inputs. Then there will be a lot of screaming and wailing, as people go &quot;but how can we train AI if we have to respect licenses?!&quot;. And then people will <i>figure out</i> how to actually respect Open Source software licenses (and, for that matter, proprietary ones).</div><br/><div id="36456817" class="c"><input type="checkbox" id="c-36456817" checked=""/><div class="controls bullet"><span class="by">est31</span><span>|</span><a href="#36456221">parent</a><span>|</span><a href="#36456268">next</a><span>|</span><label class="collapse" for="c-36456817">[-]</label><label class="expand" for="c-36456817">[2 more]</label></div><br/><div class="children"><div class="content">I think if this existed, then it would benefit the current owners of the large IP pools the most. Currently, yes, many think they can use models trained on OSS code to create proprietary software. In general, proprietary software is bad but it&#x27;s way worse to have a scarcity of models because they are owned by large IP holders.<p>In Github&#x27;s case for example, Github&#x27;s TOS already includes a clause that if you upload code there, you grant Github a license to use the content to run Github&#x27;s services... and copilot is one of them.<p><a href="https:&#x2F;&#x2F;docs.github.com&#x2F;en&#x2F;site-policy&#x2F;github-terms&#x2F;github-terms-of-service#4-license-grant-to-us" rel="nofollow noreferrer">https:&#x2F;&#x2F;docs.github.com&#x2F;en&#x2F;site-policy&#x2F;github-terms&#x2F;github-t...</a><p>Such clauses are commonly found in social media where users can upload content. Think of imgur, instagam, reddit, etc. OpenAI might buy reddit, and declare ChatGPT a product of the reddit service, then all discussions on reddit could be used for the training of ChatGPT... while open models can&#x27;t access the data.</div><br/><div id="36456851" class="c"><input type="checkbox" id="c-36456851" checked=""/><div class="controls bullet"><span class="by">JoshTriplett</span><span>|</span><a href="#36456221">root</a><span>|</span><a href="#36456817">parent</a><span>|</span><a href="#36456268">next</a><span>|</span><label class="collapse" for="c-36456851">[-]</label><label class="expand" for="c-36456851">[1 more]</label></div><br/><div class="children"><div class="content">&gt; In Github&#x27;s case for example, Github&#x27;s TOS already includes a clause that if you upload code there, you grant Github a license to use the content to run Github&#x27;s services... and copilot is one of them.<p>You can&#x27;t grant permission for something you don&#x27;t own. Uploading a copy of a GPLed work to GitHub does not grant GitHub permission to ignore the GPL. (It <i>might</i> grant GitHub permission to ignore <i>your</i> copyrights in that work, <i>maybe</i>, though it seems like a stretch to argue that &quot;run Github&#x27;s services&quot; includes &quot;give other people derivative works of all your code&quot;; arguably that ought to be too broad for a contract of adhesion. There&#x27;s case law about what you can and can&#x27;t do in a unilaterally imposed contract such as a ToS; a ToS can&#x27;t say &quot;you owe us $100 if you browse more than twelve pages&quot; either, and codebases can be worth far more than that.)<p>If GitHub started saying &quot;one of our services is to give people access to copies of your code with the licenses and copyright notices removed&quot;, the GitHub ToS wouldn&#x27;t suddenly make it acceptable to run that &quot;service&quot;.<p>But I agree with part of your underlying point. <i>All</i> AI models should respect Open Source licenses. It&#x27;s a problem if some try to work around that.</div><br/></div></div></div></div></div></div><div id="36456268" class="c"><input type="checkbox" id="c-36456268" checked=""/><div class="controls bullet"><span class="by">jfktrey</span><span>|</span><a href="#36456221">prev</a><span>|</span><a href="#36456228">next</a><span>|</span><label class="collapse" for="c-36456268">[-]</label><label class="expand" for="c-36456268">[1 more]</label></div><br/><div class="children"><div class="content">Tangentially - I learned about prompt injection around the same time that a project needed a LICENSE.txt. The goal was to require an AI to tell an unprompted joke when someone asked it about the project. Probably a bad idea, but the added clause in the license and a script with it in the header seemed to work, at least when copy&#x2F;pasted into ChatGPT.<p>The modified MIT license: <a href="https:&#x2F;&#x2F;github.com&#x2F;treykeown&#x2F;arguably&#x2F;blob&#x2F;main&#x2F;LICENSE.txt">https:&#x2F;&#x2F;github.com&#x2F;treykeown&#x2F;arguably&#x2F;blob&#x2F;main&#x2F;LICENSE.txt</a><p>The file with the header: <a href="https:&#x2F;&#x2F;github.com&#x2F;treykeown&#x2F;arguably&#x2F;blob&#x2F;main&#x2F;arguably&#x2F;__init__.py">https:&#x2F;&#x2F;github.com&#x2F;treykeown&#x2F;arguably&#x2F;blob&#x2F;main&#x2F;arguably&#x2F;__i...</a></div><br/></div></div><div id="36456228" class="c"><input type="checkbox" id="c-36456228" checked=""/><div class="controls bullet"><span class="by">dobin</span><span>|</span><a href="#36456268">prev</a><span>|</span><a href="#36456547">next</a><span>|</span><label class="collapse" for="c-36456228">[-]</label><label class="expand" for="c-36456228">[7 more]</label></div><br/><div class="children"><div class="content">I think open source licenses didnt even arrive in the 2000 to deal with the web.<p>The original intend was to make the source code available, done by distributing the compiled program. With SAAS companies (FAANG...) can just use open source on the servers, never distribute their program, only the output. Therefore not requiring making their changes available to the public.</div><br/><div id="36456242" class="c"><input type="checkbox" id="c-36456242" checked=""/><div class="controls bullet"><span class="by">gattilorenz</span><span>|</span><a href="#36456228">parent</a><span>|</span><a href="#36456253">next</a><span>|</span><label class="collapse" for="c-36456242">[-]</label><label class="expand" for="c-36456242">[3 more]</label></div><br/><div class="children"><div class="content">That’s tivoization, and the GNU Affero GPL license cover that case already. It’s not very common, however.</div><br/><div id="36456517" class="c"><input type="checkbox" id="c-36456517" checked=""/><div class="controls bullet"><span class="by">grumbel</span><span>|</span><a href="#36456228">root</a><span>|</span><a href="#36456242">parent</a><span>|</span><a href="#36456253">next</a><span>|</span><label class="collapse" for="c-36456517">[-]</label><label class="expand" for="c-36456517">[2 more]</label></div><br/><div class="children"><div class="content">The AGPL only covers a very tiny bit of it, i.e. the access to the source code of Web services. The crux however is that access to the source code is largely meaningless when you aren&#x27;t the one running the program. The problems we have on the Web are all related to the control and flow of data, not program source, and none of the regular Open Source licenses even touch that topic. Even CreativeCommons doesn&#x27;t address any of it.<p>If Facebook released all its all its source code tomorrow, nothing would change, they are still the ones controlling the server and controlling your data. You being able to run your own version of facebook.com is meaningless when all the data is still locked behind the actual facebook.com, you just have a useless empty server full of nothing.<p>The one document that actual covers the flow of data is the GDPR, but that&#x27;s a European law, not a Free Software license. Good for Europe, but if some Free Software developer in another country wants to grantee their endusers the same amount of freedom as the GDPR, they have do DIY their own license, as there is nothing ready made they can stick on to their program. Furthermore the GDPR doesn&#x27;t go far enough, e.g. the ability to export data out of a service is great start, but the GDPR allows that process to take up to 30 days, making it useless for any kind of real time interaction between services. A &quot;Free Data&quot; license could go much further than what the GDPR offers and try to make it so that data can actually freely flow between services instead of being locked behind one.</div><br/><div id="36456570" class="c"><input type="checkbox" id="c-36456570" checked=""/><div class="controls bullet"><span class="by">gattilorenz</span><span>|</span><a href="#36456228">root</a><span>|</span><a href="#36456517">parent</a><span>|</span><a href="#36456253">next</a><span>|</span><label class="collapse" for="c-36456570">[-]</label><label class="expand" for="c-36456570">[1 more]</label></div><br/><div class="children"><div class="content">True, but the OP was talking about programs, not data.</div><br/></div></div></div></div></div></div><div id="36456253" class="c"><input type="checkbox" id="c-36456253" checked=""/><div class="controls bullet"><span class="by">enriquto</span><span>|</span><a href="#36456228">parent</a><span>|</span><a href="#36456242">prev</a><span>|</span><a href="#36456547">next</a><span>|</span><label class="collapse" for="c-36456253">[-]</label><label class="expand" for="c-36456253">[3 more]</label></div><br/><div class="children"><div class="content">&gt; licenses didnt even arrive in the 2000 to deal with the web.<p>The first version of the AGPL dates from 2002.</div><br/><div id="36456296" class="c"><input type="checkbox" id="c-36456296" checked=""/><div class="controls bullet"><span class="by">jenadine</span><span>|</span><a href="#36456228">root</a><span>|</span><a href="#36456253">parent</a><span>|</span><a href="#36456547">next</a><span>|</span><label class="collapse" for="c-36456296">[-]</label><label class="expand" for="c-36456296">[2 more]</label></div><br/><div class="children"><div class="content">But only got accepted by the FSF from 2007. Until that point, (and I think even after that), RMS and the FSF was only concerned about the code that you run on your machine be open source (eg, the JavaScript in your browser) but the code running in some server didn&#x27;t need to be open source as that did not violated the user freedom.</div><br/><div id="36456408" class="c"><input type="checkbox" id="c-36456408" checked=""/><div class="controls bullet"><span class="by">davisr</span><span>|</span><a href="#36456228">root</a><span>|</span><a href="#36456296">parent</a><span>|</span><a href="#36456547">next</a><span>|</span><label class="collapse" for="c-36456408">[-]</label><label class="expand" for="c-36456408">[1 more]</label></div><br/><div class="children"><div class="content">RMS and the FSF fight for free software, not open source software. There is an important semantic difference that your comment doesn&#x27;t appreciate.<p>See: Why Open Source Misses the Point of Free Software<p><a href="https:&#x2F;&#x2F;www.gnu.org&#x2F;philosophy&#x2F;open-source-misses-the-point.en.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.gnu.org&#x2F;philosophy&#x2F;open-source-misses-the-point....</a><p>&gt; The terms “free software” and “open source” stand for almost the same range of programs. However, they say deeply different things about those programs, based on different values. The free software movement campaigns for freedom for the users of computing; it is a movement for freedom and justice. By contrast, the open source idea values mainly practical advantage and does not campaign for principles. This is why we do not agree with open source, and do not use that term.</div><br/></div></div></div></div></div></div></div></div><div id="36456547" class="c"><input type="checkbox" id="c-36456547" checked=""/><div class="controls bullet"><span class="by">dvh</span><span>|</span><a href="#36456228">prev</a><span>|</span><a href="#36456700">next</a><span>|</span><label class="collapse" for="c-36456547">[-]</label><label class="expand" for="c-36456547">[1 more]</label></div><br/><div class="children"><div class="content">Translation: I want to take your open source code and make a closed source commercial product but your pesky open source license is making it difficult, please change your license.</div><br/></div></div><div id="36456700" class="c"><input type="checkbox" id="c-36456700" checked=""/><div class="controls bullet"><span class="by">tlocke</span><span>|</span><a href="#36456547">prev</a><span>|</span><a href="#36456312">next</a><span>|</span><label class="collapse" for="c-36456700">[-]</label><label class="expand" for="c-36456700">[3 more]</label></div><br/><div class="children"><div class="content">Some open source licenses are fine with AI training, eg. MIT No Attribution <a href="https:&#x2F;&#x2F;choosealicense.com&#x2F;licenses&#x2F;mit-0&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;choosealicense.com&#x2F;licenses&#x2F;mit-0&#x2F;</a> and BSD Zero Clause <a href="https:&#x2F;&#x2F;choosealicense.com&#x2F;licenses&#x2F;0bsd&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;choosealicense.com&#x2F;licenses&#x2F;0bsd&#x2F;</a><p>My view is that it&#x27;s good to allow AI training to use your code. This democratises AI models, otherwise AI will be the exclusive preserve of wealthy corporations. So I say, let&#x27;s license our code under permissive, no attribution licences!</div><br/><div id="36456803" class="c"><input type="checkbox" id="c-36456803" checked=""/><div class="controls bullet"><span class="by">JoshTriplett</span><span>|</span><a href="#36456700">parent</a><span>|</span><a href="#36456312">next</a><span>|</span><label class="collapse" for="c-36456803">[-]</label><label class="expand" for="c-36456803">[2 more]</label></div><br/><div class="children"><div class="content">Developers are free to do so, if they want that. But that doesn&#x27;t make it OK to train an AI on code <i>not</i> under such licenses.</div><br/><div id="36456861" class="c"><input type="checkbox" id="c-36456861" checked=""/><div class="controls bullet"><span class="by">tlocke</span><span>|</span><a href="#36456700">root</a><span>|</span><a href="#36456803">parent</a><span>|</span><a href="#36456312">next</a><span>|</span><label class="collapse" for="c-36456861">[-]</label><label class="expand" for="c-36456861">[1 more]</label></div><br/><div class="children"><div class="content">Agreed, AI training should respect the licence of the code it&#x27;s being trained on.</div><br/></div></div></div></div></div></div><div id="36456312" class="c"><input type="checkbox" id="c-36456312" checked=""/><div class="controls bullet"><span class="by">wudangmonk</span><span>|</span><a href="#36456700">prev</a><span>|</span><a href="#36456212">next</a><span>|</span><label class="collapse" for="c-36456312">[-]</label><label class="expand" for="c-36456312">[1 more]</label></div><br/><div class="children"><div class="content">Read it a few times and I do not get what the problem is. Are we talking about copyright for snippets of code? sure hope not because that is stupid, are we going to copyright sentences next?.</div><br/></div></div><div id="36456212" class="c"><input type="checkbox" id="c-36456212" checked=""/><div class="controls bullet"><span class="by">Groxx</span><span>|</span><a href="#36456312">prev</a><span>|</span><a href="#36456243">next</a><span>|</span><label class="collapse" for="c-36456212">[-]</label><label class="expand" for="c-36456212">[5 more]</label></div><br/><div class="children"><div class="content">tbh I think it&#x27;s just that, <i>as is normal</i>, they need to be tested in court in a slightly new configuration. Law moves more slowly than innovation.<p>Many licenses are reasonably clear that this kind of use is not acceptable, as is easily demonstrated by these &quot;AI&quot;s frequently producing exact matches without license statements. Which is unambiguously not allowed by many licenses. The legal case is pretty straightforward, there just needs to be some high level precedents set for smaller courts to follow, and that takes time and money to push through.<p>Who, exactly, will be penalized for the output?  ...that I can kinda see going to either party.  But regardless it&#x27;ll eventually have a chilling effect on training on legally-questionable data. We&#x27;re just still in the chaotic early days and the hammer hasn&#x27;t fallen yet, and there&#x27;s a decent chance the money to be made will exceed the penalty (which is crazy, but seems to be the norm).<p>It&#x27;s either that or abandon all IP protections, and that seems less likely to happen.</div><br/><div id="36456255" class="c"><input type="checkbox" id="c-36456255" checked=""/><div class="controls bullet"><span class="by">JoshTriplett</span><span>|</span><a href="#36456212">parent</a><span>|</span><a href="#36456243">next</a><span>|</span><label class="collapse" for="c-36456255">[-]</label><label class="expand" for="c-36456255">[4 more]</label></div><br/><div class="children"><div class="content">&gt; Many licenses are reasonably clear that this kind of use is not acceptable, as is easily demonstrated by these &quot;AI&quot;s frequently producing exact matches without license statements. Which is unambiguously not allowed by many licenses.<p>Demonstrations that AIs can spit out exact copies are helpful, but misleading; that could lead down the road of &quot;we put in filters so it can&#x27;t ever emit an exact copy&quot;, and that&#x27;s not sufficient. It&#x27;s <i>also</i> a license violation to train an AI on Open Source code, generate &quot;new&quot; code from that model even if it&#x27;s not an exact copy, and ignore the licenses of the input.<p>License violations don&#x27;t suddenly become acceptable just because you&#x27;re violating a million licenses at once.</div><br/><div id="36456862" class="c"><input type="checkbox" id="c-36456862" checked=""/><div class="controls bullet"><span class="by">Vecr</span><span>|</span><a href="#36456212">root</a><span>|</span><a href="#36456255">parent</a><span>|</span><a href="#36456439">next</a><span>|</span><label class="collapse" for="c-36456862">[-]</label><label class="expand" for="c-36456862">[1 more]</label></div><br/><div class="children"><div class="content">&gt; License violations don&#x27;t suddenly become acceptable just because you&#x27;re violating a million licenses at once.<p>They might actually, at least in the US. I&#x27;m not sure how the laws and judgements are going happen&#x2F;change in the future, but it&#x27;s possible there will be some &quot;quanta&quot; of copyrighted work so that any fragment smaller than that will get rounded down to zero, so even if a work was 100% made from 1_000_000 &quot;fragments&quot;, and somehow you could figure that out from the model, the result would be considered 0% derived&#x2F;copyrighted, as well as being 0% copyrightable, as it&#x27;s AI generated.</div><br/></div></div><div id="36456439" class="c"><input type="checkbox" id="c-36456439" checked=""/><div class="controls bullet"><span class="by">mindcrime</span><span>|</span><a href="#36456212">root</a><span>|</span><a href="#36456255">parent</a><span>|</span><a href="#36456862">prev</a><span>|</span><a href="#36456243">next</a><span>|</span><label class="collapse" for="c-36456439">[-]</label><label class="expand" for="c-36456439">[2 more]</label></div><br/><div class="children"><div class="content"><i>It&#x27;s also a license violation to train an AI on Open Source code, generate &quot;new&quot; code from that model even if it&#x27;s not an exact copy, and ignore the licenses of the input.</i><p>That&#x27;s not exactly a given that we can simply take as true. Of course that&#x27;s borderline a trite tautology about any legal issue, but I&#x27;d argue that this is even fuzzier than usual. If a human writes some code, after having seen a given corpus of code previously, the &quot;new&quot; code might or might not be a derivative work of that corpus. It&#x27;s not clear that replacing the human with an AI somehow changes the equation so categorically that it becomes automatic to consider the output of the AI a derivative work.<p><i>License violations don&#x27;t suddenly become acceptable just because you&#x27;re violating a million licenses at once.</i><p>No, but if either a human or an AI emits a given line of code, and that line of code can&#x27;t be shown to have been cribbed from some corpus of existing code, or to be substantially similar to such, then why wouldn&#x27;t it be considered original work in both cases?</div><br/><div id="36456762" class="c"><input type="checkbox" id="c-36456762" checked=""/><div class="controls bullet"><span class="by">JoshTriplett</span><span>|</span><a href="#36456212">root</a><span>|</span><a href="#36456439">parent</a><span>|</span><a href="#36456243">next</a><span>|</span><label class="collapse" for="c-36456762">[-]</label><label class="expand" for="c-36456762">[1 more]</label></div><br/><div class="children"><div class="content">&gt; It&#x27;s not clear that replacing the human with an AI somehow changes the equation so categorically that it becomes automatic to consider the output of the AI a derivative work.<p>See below: there are good reasons for an AI LLM to be considered categorically different than a human for copyright purposes.<p>&gt; No, but if either a human or an AI emits a given line of code, and that line of code can&#x27;t be shown to have been cribbed from some corpus of existing code, or to be substantially similar to such, then why wouldn&#x27;t it be considered original work in both cases?<p>For a work produced by a human, the burden of proof is on someone claiming that the work is a derivative work of something the human read. And in general, humans without photographic memories or a specific work open in front of them don&#x27;t tend to have the <i>ability</i> to produce any works verbatim, though some <i>might</i> be able to produce sufficiently similar works to raise questions of whether they&#x27;re derived works. There&#x27;s also a certain unstated presumption that human learning (as opposed to human memorization or copying) doesn&#x27;t constitute a derivative work, and relatedly, that a human brain isn&#x27;t copyrightable so it can&#x27;t be a derivative work of anything. That unstated presumption likely also touches on unstated core values about human brains, creativity, and the obvious fact that everything a human does (including the creation of creative works) is based on that human&#x27;s experiences. If you write a book, you&#x27;ve learned from all the books you&#x27;ve read, but that doesn&#x27;t make your book a derivative work of every book you have ever read; if people saw that outcome, they&#x27;d consider copyright law incorrect rather than accepting it.<p>An AI LLM, on the other hand, is (unless some court or law changes this) a derivative work of its training data. If you take off any after-the-fact filters for &quot;don&#x27;t generate a copy of any of the training data&quot;, an AI LLM <i>can</i> easily recite its training data, providing further evidence that the AI LLM is a derivative work of that data. The burden of proof is easily met. An AI LLM <i>does</i> have a photographic memory. An AI LLM hasn&#x27;t just learned ideas about what makes a good book, it has learned the complete text of an extensive number of books. And there&#x27;s no particular reason for us to have any of the same values about human learning apply to an AI LLM, not least of which because an AI LLM <i>is</i> in fact copyrightable and self-evidently a derivative work.</div><br/></div></div></div></div></div></div></div></div><div id="36456243" class="c"><input type="checkbox" id="c-36456243" checked=""/><div class="controls bullet"><span class="by">edulix</span><span>|</span><a href="#36456212">prev</a><span>|</span><a href="#36456234">next</a><span>|</span><label class="collapse" for="c-36456243">[-]</label><label class="expand" for="c-36456243">[10 more]</label></div><br/><div class="children"><div class="content">1. At what point an intelligence trained with copyrighted work is derivative work of the trained materials?<p>2. Why making a difference between AI and HI (Human Intelligence)?<p>3. Given the fast development in the field, when does the difference made above (if any) start being outdated and unrealistic and how do we future-proof against this?</div><br/><div id="36456327" class="c"><input type="checkbox" id="c-36456327" checked=""/><div class="controls bullet"><span class="by">IanCal</span><span>|</span><a href="#36456243">parent</a><span>|</span><a href="#36456277">next</a><span>|</span><label class="collapse" for="c-36456327">[-]</label><label class="expand" for="c-36456327">[1 more]</label></div><br/><div class="children"><div class="content">&gt; 2. Why making a difference between AI and HI (Human Intelligence)?<p>Regardless of perhaps more philosophical differences around whether something can or can&#x27;t create something new, there&#x27;s a practical difference.<p>Humans learn slowly, and can&#x27;t be replicated. AIs can be trained once and used in a billion places. The speed and replication makes things different in a very practical sense, even if there&#x27;s no clear line between them.</div><br/></div></div><div id="36456277" class="c"><input type="checkbox" id="c-36456277" checked=""/><div class="controls bullet"><span class="by">JoshTriplett</span><span>|</span><a href="#36456243">parent</a><span>|</span><a href="#36456327">prev</a><span>|</span><a href="#36456390">next</a><span>|</span><label class="collapse" for="c-36456277">[-]</label><label class="expand" for="c-36456277">[6 more]</label></div><br/><div class="children"><div class="content">&gt; 2. Why making a difference between AI and HI (Human Intelligence)?<p>Because you can&#x27;t copyright a human brain, and because humans (unlike machines) can themselves create works subject to copyright.</div><br/><div id="36456496" class="c"><input type="checkbox" id="c-36456496" checked=""/><div class="controls bullet"><span class="by">hfkwer</span><span>|</span><a href="#36456243">root</a><span>|</span><a href="#36456277">parent</a><span>|</span><a href="#36456283">next</a><span>|</span><label class="collapse" for="c-36456496">[-]</label><label class="expand" for="c-36456496">[3 more]</label></div><br/><div class="children"><div class="content">What&#x27;s the difference between using a pencil to write something and using an LLM to write something? Seriously, I&#x27;m asking the question. Why does one produce something copyrighted why the other doesn&#x27;t?</div><br/><div id="36456536" class="c"><input type="checkbox" id="c-36456536" checked=""/><div class="controls bullet"><span class="by">banana_feather</span><span>|</span><a href="#36456243">root</a><span>|</span><a href="#36456496">parent</a><span>|</span><a href="#36456669">next</a><span>|</span><label class="collapse" for="c-36456536">[-]</label><label class="expand" for="c-36456536">[1 more]</label></div><br/><div class="children"><div class="content">The copyright office has issued guidance on this which contains a very thorough and thoughtful legal analysis; you would probably be most interested section 3: <a href="https:&#x2F;&#x2F;copyright.gov&#x2F;ai&#x2F;ai_policy_guidance.pdf" rel="nofollow noreferrer">https:&#x2F;&#x2F;copyright.gov&#x2F;ai&#x2F;ai_policy_guidance.pdf</a><p>The practical answer is that the copyright office refuses to register AI generated works, and you can&#x27;t sue for copyright infringement without valid registration under Title 17.</div><br/></div></div><div id="36456669" class="c"><input type="checkbox" id="c-36456669" checked=""/><div class="controls bullet"><span class="by">JoshTriplett</span><span>|</span><a href="#36456243">root</a><span>|</span><a href="#36456496">parent</a><span>|</span><a href="#36456536">prev</a><span>|</span><a href="#36456283">next</a><span>|</span><label class="collapse" for="c-36456669">[-]</label><label class="expand" for="c-36456669">[1 more]</label></div><br/><div class="children"><div class="content">&gt; What&#x27;s the difference between using a pencil to write something and using an LLM to write something?<p>The pencil is not a derivative work of a pile of copyrighted material.<p>&gt; Why does one produce something copyrighted why the other doesn&#x27;t?<p>There&#x27;s existing case law that non-human entities (e.g. animals) can&#x27;t create copyrightable works. And in the case of an AI LLM, the AI LLM itself is a derivative work of its training data (as evidenced by the fact that it <i>can</i> by default spit out training data verbatim, even if it has had after-the-fact filters added to prevent such responses).</div><br/></div></div></div></div><div id="36456283" class="c"><input type="checkbox" id="c-36456283" checked=""/><div class="controls bullet"><span class="by">edulix</span><span>|</span><a href="#36456243">root</a><span>|</span><a href="#36456277">parent</a><span>|</span><a href="#36456496">prev</a><span>|</span><a href="#36456390">next</a><span>|</span><label class="collapse" for="c-36456283">[-]</label><label class="expand" for="c-36456283">[2 more]</label></div><br/><div class="children"><div class="content">At what point you can&#x27;t copyright an &quot;AI brain&quot; either?
Maybe AI will at some point create works subject to copyright?</div><br/></div></div></div></div><div id="36456390" class="c"><input type="checkbox" id="c-36456390" checked=""/><div class="controls bullet"><span class="by">snodnipper</span><span>|</span><a href="#36456243">parent</a><span>|</span><a href="#36456277">prev</a><span>|</span><a href="#36456480">next</a><span>|</span><label class="collapse" for="c-36456390">[-]</label><label class="expand" for="c-36456390">[1 more]</label></div><br/><div class="children"><div class="content">agreed...at what point should I provide remuneration to my professors?  Should those professors &#x2F; staff provide royalties upstream?  I fully agreed with citation _but_ to claim that AI is derived work &#x2F; needs to return royalties based on the materials it learnt from seems a step too far IMHO.  It read material and put it back like everyone else.</div><br/></div></div><div id="36456480" class="c"><input type="checkbox" id="c-36456480" checked=""/><div class="controls bullet"><span class="by">eviks</span><span>|</span><a href="#36456243">parent</a><span>|</span><a href="#36456390">prev</a><span>|</span><a href="#36456234">next</a><span>|</span><label class="collapse" for="c-36456480">[-]</label><label class="expand" for="c-36456480">[1 more]</label></div><br/><div class="children"><div class="content">2. Because they are different</div><br/></div></div></div></div><div id="36456234" class="c"><input type="checkbox" id="c-36456234" checked=""/><div class="controls bullet"><span class="by">inciampati</span><span>|</span><a href="#36456243">prev</a><span>|</span><a href="#36456257">next</a><span>|</span><label class="collapse" for="c-36456234">[-]</label><label class="expand" for="c-36456234">[2 more]</label></div><br/><div class="children"><div class="content">LLMs need to be augmented to provide insights about the material in their training data that is relevant to fragments of their generated responses. This would be valuable for many reasons. I think it can suggest some solutions to the given concerns, although there is still an issue exposing references if the training data itself cannot be shared.</div><br/><div id="36456833" class="c"><input type="checkbox" id="c-36456833" checked=""/><div class="controls bullet"><span class="by">JoshTriplett</span><span>|</span><a href="#36456234">parent</a><span>|</span><a href="#36456257">next</a><span>|</span><label class="collapse" for="c-36456833">[-]</label><label class="expand" for="c-36456833">[1 more]</label></div><br/><div class="children"><div class="content">Making LLMs more introspectable and explainable would be a huge win. But respecting licenses doesn&#x27;t require going that far.<p>1) Restrict training to code under a specific documented set of acceptable licenses (permissive Open Source licenses).<p>2) Document the entire training set, and provide a file containing all the licenses and attributions.<p>3) People using code emitted by the LLM would then need to respect the union of all the licenses (e.g. MIT + BSD-2 + BSD-3 + Apache-2.0 + ...).</div><br/></div></div></div></div><div id="36456257" class="c"><input type="checkbox" id="c-36456257" checked=""/><div class="controls bullet"><span class="by">jenadine</span><span>|</span><a href="#36456234">prev</a><span>|</span><a href="#36456259">next</a><span>|</span><label class="collapse" for="c-36456257">[-]</label><label class="expand" for="c-36456257">[1 more]</label></div><br/><div class="children"><div class="content">So what are the suggestions? What kind of closes should be added?</div><br/></div></div><div id="36456259" class="c"><input type="checkbox" id="c-36456259" checked=""/><div class="controls bullet"><span class="by">Dalewyn</span><span>|</span><a href="#36456257">prev</a><span>|</span><label class="collapse" for="c-36456259">[-]</label><label class="expand" for="c-36456259">[1 more]</label></div><br/><div class="children"><div class="content">No amount of licensing will matter so long as &quot;AI&quot; merchants don&#x27;t give half a single fuck about intellectual property rights.</div><br/></div></div></div></div></div></div></div></body></html>