<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1702198857130" as="style"/><link rel="stylesheet" href="styles.css?v=1702198857130"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.theverge.com/23655762/l4s-internet-apple-comcast-latency-speed-bandwidth">What Is L4S?</a>Â <span class="domain">(<a href="https://www.theverge.com">www.theverge.com</a>)</span></div><div class="subtext"><span>Anonboxis</span> | <span>7 comments</span></div><br/><div><div id="38589653" class="c"><input type="checkbox" id="c-38589653" checked=""/><div class="controls bullet"><span class="by">e63f67dd-065b</span><span>|</span><a href="#38590126">next</a><span>|</span><label class="collapse" for="c-38589653">[-]</label><label class="expand" for="c-38589653">[3 more]</label></div><br/><div class="children"><div class="content">The article doesn&#x27;t actually explain anything about L4S other than &quot;make latency go lower&quot;. Here&#x27;s the actual RFC: <a href="https:&#x2F;&#x2F;www.rfc-editor.org&#x2F;rfc&#x2F;rfc9330.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.rfc-editor.org&#x2F;rfc&#x2F;rfc9330.html</a><p>This is the first time I&#x27;ve heard of it, but it looks pretty cool. From what I can tell skimming through the RFC, it&#x27;s a new congestion control standard that aims to minimise queuing latency. It co-exists with existing AQM technology, and is different in that it actively signals to other nodes about the state of its own queues.<p>&gt; Below, we outline the three main components to the L4S architecture: 1) the Scalable congestion control on the sending host; 2) the AQM at the network bottleneck; and 3) the protocol between them.<p>&gt; But first, the main point to grasp is that low latency is not provided by the network; low latency results from the careful behaviour of the Scalable congestion controllers used by L4S senders. The network does have a role, primarily to isolate the low latency of the carefully behaving L4S traffic from the higher queuing delay needed by traffic with preexisting Classic behaviour. The network also alters the way it signals queue growth to the transport. It uses the Explicit Congestion Notification (ECN) protocol, but it signals the very start of queue growth immediately, without the smoothing delay typical of Classic AQMs. Because ECN support is essential for L4S, senders use the ECN field as the protocol that allows the network to identify which packets are L4S and which are Classic.<p>&gt; What L4S Adds to Existing Approaches: ... Diffserv ... State-of-the-art AQMs ... Per-flow queuing or marking ... Alternative Back-off ECN (ABE) ...  Bottleneck Bandwidth and Round-trip propagation time (BBR)<p>My question, from a background with almost no networking, is this: there is a fundamental tradeoff between latency and throughput; what exactly is the tradeoff they&#x27;re trying to make here? I understand the desire to move into lower latency, but how does this effect their utilisation?</div><br/><div id="38589914" class="c"><input type="checkbox" id="c-38589914" checked=""/><div class="controls bullet"><span class="by">orbital-decay</span><span>|</span><a href="#38589653">parent</a><span>|</span><a href="#38589808">next</a><span>|</span><label class="collapse" for="c-38589914">[-]</label><label class="expand" for="c-38589914">[1 more]</label></div><br/><div class="children"><div class="content"><i>&gt; there is a fundamental tradeoff between latency and throughput</i><p>Only for the <i>unpredictable</i> part of the load. If you can predict it, you can have both. For that you need to control the entire stack though, starting from the OS and the apps. That&#x27;s what the &quot;scalable congestion control on the sending host&quot; is about.</div><br/></div></div><div id="38589808" class="c"><input type="checkbox" id="c-38589808" checked=""/><div class="controls bullet"><span class="by">Yujf</span><span>|</span><a href="#38589653">parent</a><span>|</span><a href="#38589914">prev</a><span>|</span><a href="#38590126">next</a><span>|</span><label class="collapse" for="c-38589808">[-]</label><label class="expand" for="c-38589808">[1 more]</label></div><br/><div class="children"><div class="content">The idea is that there should not really be a trade-off. If you manage congestion well, you can send just what the network will allow, keeping throughput high but lowering latency. It could even increase throughput as you do not have the default TCP congestion algorithm which drops it&#x27;s rate after dropped packets meaning it does not dully utilize the link</div><br/></div></div></div></div><div id="38590126" class="c"><input type="checkbox" id="c-38590126" checked=""/><div class="controls bullet"><span class="by">klevo</span><span>|</span><a href="#38589653">prev</a><span>|</span><a href="#38589584">next</a><span>|</span><label class="collapse" for="c-38590126">[-]</label><label class="expand" for="c-38590126">[1 more]</label></div><br/><div class="children"><div class="content">I hope it&#x27;s gonna go better than the rollout of IPV6 :-)</div><br/></div></div><div id="38589584" class="c"><input type="checkbox" id="c-38589584" checked=""/><div class="controls bullet"><span class="by">Dalewyn</span><span>|</span><a href="#38590126">prev</a><span>|</span><a href="#38589637">next</a><span>|</span><label class="collapse" for="c-38589584">[-]</label><label class="expand" for="c-38589584">[1 more]</label></div><br/><div class="children"><div class="content">&gt;What is L4S?<p>The answer is buried <i>over halfway down</i> the fucking, droning malaise of an article:<p>&gt;L4S stands for Low Latency, Low Loss, Scalable Throughput, and its goal is to make sure your packets spend as little time needlessly waiting in line as possible by reducing the need for queuing.<p>As such, here&#x27;s an archive version of this crap because it does not deserve user traffic: <a href="https:&#x2F;&#x2F;archive.is&#x2F;XWzbL" rel="nofollow noreferrer">https:&#x2F;&#x2F;archive.is&#x2F;XWzbL</a></div><br/></div></div><div id="38589637" class="c"><input type="checkbox" id="c-38589637" checked=""/><div class="controls bullet"><span class="by">fithisux</span><span>|</span><a href="#38589584">prev</a><span>|</span><label class="collapse" for="c-38589637">[-]</label><label class="expand" for="c-38589637">[1 more]</label></div><br/><div class="children"><div class="content">So L4S has to do with your device only?<p>I&#x27;m missing something because the ACK of a packet may be enough to indicate congestion.</div><br/></div></div></div></div></div></div></div></body></html>