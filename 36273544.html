<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1686474046306" as="style"/><link rel="stylesheet" href="styles.css?v=1686474046306"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/Voultapher/sort-research-rs/blob/main/writeup/intel_avx512/text.md">A performance analysis of Intel x86-SIMD-sort (AVX-512)</a> <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>Twirrim</span> | <span>37 comments</span></div><br/><div><div id="36274278" class="c"><input type="checkbox" id="c-36274278" checked=""/><div class="controls bullet"><span class="by">mlochbaum</span><span>|</span><a href="#36275672">next</a><span>|</span><label class="collapse" for="c-36274278">[-]</label><label class="expand" for="c-36274278">[7 more]</label></div><br/><div class="children"><div class="content">Steps to build a fast, highly adaptive AVX-512 sorting algorithm in C:<p>- Clone fluxsort (<a href="https:&#x2F;&#x2F;github.com&#x2F;scandum&#x2F;fluxsort">https:&#x2F;&#x2F;github.com&#x2F;scandum&#x2F;fluxsort</a>)<p>- Replace the partitioning code in flux_default_partition and flux_reverse_partition with the obvious AVX-512 version using a compare and two compress instructions<p>- If you&#x27;re feeling ambitious, swap out the small array sorting, or incorporate crumsort&#x27;s fulcrum partition for larger arrays.<p>I know why I haven&#x27;t done this: my computer doesn&#x27;t have AVX-512, and hardly anyone else&#x27;s that I know seems to. Maybe a couple Zen 4 owners. I&#x27;m less clear on why the tech giants are reinventing the wheel to make these sorting alrogithms that don&#x27;t even handle pre-sorted data rather than working with some of the very high-quality open source stuff out there. Is adaptivity really considered that worthless?<p>Fluxsort makes this particularly simple because it gets great performance out of a stable out-of-place partition. It&#x27;s a bit newer; maybe the authors weren&#x27;t aware of this work or started before it was published. But these algorithms both use (fairly difficult) in-place partitioning code; why not slot that into the well-known pdqsort?</div><br/><div id="36274638" class="c"><input type="checkbox" id="c-36274638" checked=""/><div class="controls bullet"><span class="by">gavinray</span><span>|</span><a href="#36274278">parent</a><span>|</span><a href="#36274664">next</a><span>|</span><label class="collapse" for="c-36274638">[-]</label><label class="expand" for="c-36274638">[5 more]</label></div><br/><div class="children"><div class="content">If you look at the history of the author&#x27;s own sorting implementation (ipnsort), it started as an attempt to port fluxsort to Rust:<p><a href="https:&#x2F;&#x2F;github.com&#x2F;Voultapher&#x2F;Presentations&#x2F;blob&#x2F;master&#x2F;rust-stable-sort&#x2F;present.md">https:&#x2F;&#x2F;github.com&#x2F;Voultapher&#x2F;Presentations&#x2F;blob&#x2F;master&#x2F;rust...</a><p><a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=3JZAQ4Gsl-g">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=3JZAQ4Gsl-g</a><p>It starts there, eventually the author abandons the linked PR because of a better approach found with ipnsort:<p><a href="https:&#x2F;&#x2F;github.com&#x2F;rust-lang&#x2F;rust&#x2F;pull&#x2F;100856#issuecomment-1404659163">https:&#x2F;&#x2F;github.com&#x2F;rust-lang&#x2F;rust&#x2F;pull&#x2F;100856#issuecomment-1...</a></div><br/><div id="36275105" class="c"><input type="checkbox" id="c-36275105" checked=""/><div class="controls bullet"><span class="by">Voultapher</span><span>|</span><a href="#36274278">root</a><span>|</span><a href="#36274638">parent</a><span>|</span><a href="#36274775">next</a><span>|</span><label class="collapse" for="c-36275105">[-]</label><label class="expand" for="c-36275105">[3 more]</label></div><br/><div class="children"><div class="content">You are right the initial kick-off point was an attempt to port fluxsort for a stable sort in Rust, but that quickly turned out to be unfeasible because Rust implementations have way higher requirements in terms of safety. The user can modify values during a comparison operation, leave the logic at any comparison point via an panic (exception) and the comparison function may not be a total order. Together these effects make most of the code in fluxsort useless for Rust. I had been working on ipn_stable and ipn_unstable to completely different implementations. ipnsort, previously ipn_unstable started off with the pdqsort port that is the current Rust `slice::sort_unstable` and from there on I iterated and tried out different ideas.</div><br/><div id="36275225" class="c"><input type="checkbox" id="c-36275225" checked=""/><div class="controls bullet"><span class="by">mlochbaum</span><span>|</span><a href="#36274278">root</a><span>|</span><a href="#36275105">parent</a><span>|</span><a href="#36274775">next</a><span>|</span><label class="collapse" for="c-36275225">[-]</label><label class="expand" for="c-36275225">[2 more]</label></div><br/><div class="children"><div class="content">Well, I know what you mean but &quot;completely different&quot; is potentially misleading here. The current ipnsort is using bidirectional merges developed for quadsort (the merging part of fluxsort) and the fulcrum partition from crumsort, also by Scandum (all credited in comments; check the source if you want to see more influences!). To balance things out, the strategy for using the namesake sorting networks is new to me: pick a few fixed sizes and handle the rest by rounding down then a few steps of insertion sorting.</div><br/><div id="36275393" class="c"><input type="checkbox" id="c-36275393" checked=""/><div class="controls bullet"><span class="by">Voultapher</span><span>|</span><a href="#36274278">root</a><span>|</span><a href="#36275225">parent</a><span>|</span><a href="#36274775">next</a><span>|</span><label class="collapse" for="c-36275393">[-]</label><label class="expand" for="c-36275393">[1 more]</label></div><br/><div class="children"><div class="content">I should clarify, I meant that ipn_stable and ipn_unstable were separate projects, albeit with some cross-over ideas.<p>I can&#x27;t rule out that someone else had that idea for limiting the use of sorting-networks, all I can say is that I came up with that myself. At the same time a lot of the good ideas in ipnsort are ideas from other people, and I try my best to accredit them. As I commented before, my goal is not peak perf for integers at any cost. Here is a commit <a href="https:&#x2F;&#x2F;github.com&#x2F;Voultapher&#x2F;sort-research-rs&#x2F;commit&#x2F;d908feb0070717510ddc20b632c1568ce6949b0a">https:&#x2F;&#x2F;github.com&#x2F;Voultapher&#x2F;sort-research-rs&#x2F;commit&#x2F;d908fe...</a> that improves perf by 7% across sizes for the random pattern. But that comes with a non negligible binary size and compile time impact even for integers. And while I use heuristics to only use sorting-networks where sensible, they can guess wrong. This is a generic sort implementation with the goal of being a good all-round implementation fit for a standard library and those various uses.</div><br/></div></div></div></div></div></div><div id="36274775" class="c"><input type="checkbox" id="c-36274775" checked=""/><div class="controls bullet"><span class="by">mlochbaum</span><span>|</span><a href="#36274278">root</a><span>|</span><a href="#36274638">parent</a><span>|</span><a href="#36275105">prev</a><span>|</span><a href="#36274664">next</a><span>|</span><label class="collapse" for="c-36274775">[-]</label><label class="expand" for="c-36274775">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not talking about ipnsort, which I think is great. It makes good use of existing work and doesn&#x27;t use AVX at all. So extending it with AVX-512 partition code would also be a good project!</div><br/></div></div></div></div><div id="36274664" class="c"><input type="checkbox" id="c-36274664" checked=""/><div class="controls bullet"><span class="by">moonchild</span><span>|</span><a href="#36274278">parent</a><span>|</span><a href="#36274638">prev</a><span>|</span><a href="#36275672">next</a><span>|</span><label class="collapse" for="c-36274664">[-]</label><label class="expand" for="c-36274664">[1 more]</label></div><br/><div class="children"><div class="content">Avx512 is also good for merging and pattern detection.  Merging in the case of a large input (rather than just opportunistic for presorted subsequences) is arguably the most interesting part—a big queueing and data movement problem.</div><br/></div></div></div></div><div id="36275672" class="c"><input type="checkbox" id="c-36275672" checked=""/><div class="controls bullet"><span class="by">fooblaster</span><span>|</span><a href="#36274278">prev</a><span>|</span><a href="#36274221">next</a><span>|</span><label class="collapse" for="c-36275672">[-]</label><label class="expand" for="c-36275672">[5 more]</label></div><br/><div class="children"><div class="content">From what I understand, these sorts are only for direct lists of primitives. For most of the sorts I see, I&#x27;m trying to sort an array of structs with an embedded key. I know this organization destroys the memory access patterns that make SIMD effective. Is the best alternative to move the key out of the struct, and sort two arrays: one of primitive keys and another of original indices? This sort would still be very amenable to SIMD. It just requires a final pass where you rearrange the original array with the indices. Alternately, you could avoid sorting an array of indices and try sorting an struct of arrays directly. I don&#x27;t see a lot of people handling this very frequent situation in these benchmarks. Any pointers?</div><br/><div id="36275781" class="c"><input type="checkbox" id="c-36275781" checked=""/><div class="controls bullet"><span class="by">mlochbaum</span><span>|</span><a href="#36275672">parent</a><span>|</span><a href="#36278729">next</a><span>|</span><label class="collapse" for="c-36275781">[-]</label><label class="expand" for="c-36275781">[1 more]</label></div><br/><div class="children"><div class="content">It depends on the size of the structs. For struct <i>pointers</i> you&#x27;re likely better off sorting keys and pointers simultaneously. It doesn&#x27;t matter much until you get to large sizes (millions), but sorting indices and then selecting with them is random access. If the original ordering is messy, selecting can be slower than the sorting step. For structs a few words long, the unit you&#x27;re moving is a larger portion of a cache line, and I&#x27;d expect the data movement to drown out any SIMD advantage. A radix sort might be all right because it moves less, but I&#x27;d probably go with sorting indices as the first thing to try unless I knew the arrays were huge. For very large structs there&#x27;s an interesting effort called mountain sort[0], &quot;probably the best sorting algorithm if you need to sort actual mountains by height&quot;. Given that it minimizes number of moves it&#x27;s ignoring cache entirely. I haven&#x27;t benchmarked so I can&#x27;t say much about how practical it is.<p>[0] <a href="https:&#x2F;&#x2F;github.com&#x2F;Morwenn&#x2F;mountain-sort">https:&#x2F;&#x2F;github.com&#x2F;Morwenn&#x2F;mountain-sort</a></div><br/></div></div><div id="36278729" class="c"><input type="checkbox" id="c-36278729" checked=""/><div class="controls bullet"><span class="by">anonymoushn</span><span>|</span><a href="#36275672">parent</a><span>|</span><a href="#36275781">prev</a><span>|</span><a href="#36275814">next</a><span>|</span><label class="collapse" for="c-36278729">[-]</label><label class="expand" for="c-36278729">[1 more]</label></div><br/><div class="children"><div class="content">Often you can sort a u128 (or smaller integer) that is actually the key and a pointer or the key and an index into an array. You may find that a single pass to rearrange the original array to the sorted order is slower than multiple passes because of cache issues. I would certainly be interested in reading about this sort of thing if you find anything :)</div><br/></div></div><div id="36275814" class="c"><input type="checkbox" id="c-36275814" checked=""/><div class="controls bullet"><span class="by">BobbyJo</span><span>|</span><a href="#36275672">parent</a><span>|</span><a href="#36278729">prev</a><span>|</span><a href="#36275818">next</a><span>|</span><label class="collapse" for="c-36275814">[-]</label><label class="expand" for="c-36275814">[1 more]</label></div><br/><div class="children"><div class="content">In situations where I need to sort a list of large objects, I normally create an separate &quot;OrderedView&quot; or &quot;Ordering&quot; which holds either two lists [comparable_value] and [index] like you describe, or a single list of [comparable_value, index] (depending on the types and languages the second option will be faster). Then it just provides either an iterator. If you only need the ordering once this saves you from going back and re-ordering the original array.<p>If you need to run through the list multiple times, it probably makes sense to actually go back and re-order the original so that the accesses are linear memory. That is, unless the values are pointers in which the indirection will likely kill the benefit.</div><br/></div></div><div id="36275818" class="c"><input type="checkbox" id="c-36275818" checked=""/><div class="controls bullet"><span class="by">blt</span><span>|</span><a href="#36275672">parent</a><span>|</span><a href="#36275814">prev</a><span>|</span><a href="#36274221">next</a><span>|</span><label class="collapse" for="c-36275818">[-]</label><label class="expand" for="c-36275818">[1 more]</label></div><br/><div class="children"><div class="content">I agree this is a super common case. I don&#x27;t have a benchmark, but I bet when actually moving structs the C qsort starts looking a lot more reasonable.</div><br/></div></div></div></div><div id="36274221" class="c"><input type="checkbox" id="c-36274221" checked=""/><div class="controls bullet"><span class="by">slashdev</span><span>|</span><a href="#36275672">prev</a><span>|</span><a href="#36274582">next</a><span>|</span><label class="collapse" for="c-36274221">[-]</label><label class="expand" for="c-36274221">[10 more]</label></div><br/><div class="children"><div class="content">So Rust&#x27;s ipnsort is actually one of the better sorting implementations across a variety of input sizes. Faster than avx512 sort on small arrays, slower on mid sized arrays, and almost the same on large ones.<p>The avx512 sort seems like a questionable choice given it requires specialized hardware and is not the best option under many real-world conditions.</div><br/><div id="36275170" class="c"><input type="checkbox" id="c-36275170" checked=""/><div class="controls bullet"><span class="by">Voultapher</span><span>|</span><a href="#36274221">parent</a><span>|</span><a href="#36274265">next</a><span>|</span><label class="collapse" for="c-36275170">[-]</label><label class="expand" for="c-36275170">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;d like to emphasize that ipnsort is primarily designed as the new Rust std library unstable sort, which means it optimizes for all these factors simultaneously:<p>- input type (including stuff that is not an integer or float)<p>- input size<p>- input pattern<p>- prediction state<p>- binary size<p>- compile times<p>- varying ISAs and Hardware<p>Especially binary size and compile times mean I&#x27;m not chasing the performance crown for integers in some HPC setting. I can trivially pull out another 7% perf by ignoring binary size, compile times and effects on types that are not integers <a href="https:&#x2F;&#x2F;github.com&#x2F;Voultapher&#x2F;sort-research-rs&#x2F;commit&#x2F;d908feb0070717510ddc20b632c1568ce6949b0a">https:&#x2F;&#x2F;github.com&#x2F;Voultapher&#x2F;sort-research-rs&#x2F;commit&#x2F;d908fe...</a>.</div><br/><div id="36275353" class="c"><input type="checkbox" id="c-36275353" checked=""/><div class="controls bullet"><span class="by">mlochbaum</span><span>|</span><a href="#36274221">root</a><span>|</span><a href="#36275170">parent</a><span>|</span><a href="#36274265">next</a><span>|</span><label class="collapse" for="c-36275353">[-]</label><label class="expand" for="c-36275353">[2 more]</label></div><br/><div class="children"><div class="content">This is a point that I&#x27;m kind of fuzzy on: is there a specific requirement to not change the algorithm too much based on type&#x2F;comparison? Like if the user calls it on a 1-byte type with default comparison, the best way to do this in a vacuum is a counting sort. Smaller generated code and everything. Both C&#x2F;C++ and Rust developers seem unwilling to do this, but not having asked I don&#x27;t know why exactly.<p>On the other hand Julia just switched to radix sort much of the time in their latest version, so other languages can have different approaches.</div><br/><div id="36279462" class="c"><input type="checkbox" id="c-36279462" checked=""/><div class="controls bullet"><span class="by">xoranth</span><span>|</span><a href="#36274221">root</a><span>|</span><a href="#36275353">parent</a><span>|</span><a href="#36274265">next</a><span>|</span><label class="collapse" for="c-36279462">[-]</label><label class="expand" for="c-36279462">[1 more]</label></div><br/><div class="children"><div class="content">As a datapoint, numpy also chooses between radix and timsort based on data type. From the docs [^0]:<p>&gt; ‘stable’ automatically chooses the best stable sorting algorithm for the data type being sorted. It, along with ‘mergesort’ is currently mapped to timsort or radix sort depending on the data type. API forward compatibility currently limits the ability to select the implementation and it is hardwired for the different data types.<p>[^0]: <a href="https:&#x2F;&#x2F;numpy.org&#x2F;doc&#x2F;stable&#x2F;reference&#x2F;generated&#x2F;numpy.sort.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;numpy.org&#x2F;doc&#x2F;stable&#x2F;reference&#x2F;generated&#x2F;numpy.sort....</a></div><br/></div></div></div></div></div></div><div id="36274265" class="c"><input type="checkbox" id="c-36274265" checked=""/><div class="controls bullet"><span class="by">PartiallyTyped</span><span>|</span><a href="#36274221">parent</a><span>|</span><a href="#36275170">prev</a><span>|</span><a href="#36274582">next</a><span>|</span><label class="collapse" for="c-36274265">[-]</label><label class="expand" for="c-36274265">[6 more]</label></div><br/><div class="children"><div class="content">It&#x27;s possible that AVX512 sort does better on newer architectures, no? Author&#x27;s machine is a 3 generations old cpu.</div><br/><div id="36274995" class="c"><input type="checkbox" id="c-36274995" checked=""/><div class="controls bullet"><span class="by">slashdev</span><span>|</span><a href="#36274221">root</a><span>|</span><a href="#36274265">parent</a><span>|</span><a href="#36274422">next</a><span>|</span><label class="collapse" for="c-36274995">[-]</label><label class="expand" for="c-36274995">[3 more]</label></div><br/><div class="children"><div class="content">Yeah, that would probably change the calculus. There were major frequency (heat) issues on older Intel cpus when running avx512.</div><br/><div id="36277164" class="c"><input type="checkbox" id="c-36277164" checked=""/><div class="controls bullet"><span class="by">celrod</span><span>|</span><a href="#36274221">root</a><span>|</span><a href="#36274995">parent</a><span>|</span><a href="#36275174">next</a><span>|</span><label class="collapse" for="c-36277164">[-]</label><label class="expand" for="c-36277164">[1 more]</label></div><br/><div class="children"><div class="content">The vqsort README says it is a non-issue on that generation CPU (Skylake-X) based on their benchmarks: <a href="https:&#x2F;&#x2F;github.com&#x2F;google&#x2F;highway&#x2F;tree&#x2F;master&#x2F;hwy&#x2F;contrib&#x2F;sort#study-of-avx-512-downclocking">https:&#x2F;&#x2F;github.com&#x2F;google&#x2F;highway&#x2F;tree&#x2F;master&#x2F;hwy&#x2F;contrib&#x2F;so...</a>
At least on their low clock speed server CPU (&lt;=3GHz), downclocking was hard to measure compared to clock speed variability they got with std::sort.<p>The 10980xe used for windows benchmarks here normally boosts much higher, so bigger differences could be expected. The author of OP mentioned measuring clock speeds with perf and seeing some difference.</div><br/></div></div><div id="36275174" class="c"><input type="checkbox" id="c-36275174" checked=""/><div class="controls bullet"><span class="by">PartiallyTyped</span><span>|</span><a href="#36274221">root</a><span>|</span><a href="#36274995">parent</a><span>|</span><a href="#36277164">prev</a><span>|</span><a href="#36274422">next</a><span>|</span><label class="collapse" for="c-36275174">[-]</label><label class="expand" for="c-36275174">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s also the complication that AVX512 was removed in 12xxx and down, and iirc has a softlock in 11xxx.</div><br/></div></div></div></div><div id="36274422" class="c"><input type="checkbox" id="c-36274422" checked=""/><div class="controls bullet"><span class="by">threadl0cal</span><span>|</span><a href="#36274221">root</a><span>|</span><a href="#36274265">parent</a><span>|</span><a href="#36274995">prev</a><span>|</span><a href="#36274411">next</a><span>|</span><label class="collapse" for="c-36274422">[-]</label><label class="expand" for="c-36274422">[1 more]</label></div><br/><div class="children"><div class="content">Only one way to find out -- benchmarks, innit?</div><br/></div></div><div id="36274411" class="c"><input type="checkbox" id="c-36274411" checked=""/><div class="controls bullet"><span class="by">pstuart</span><span>|</span><a href="#36274221">root</a><span>|</span><a href="#36274265">parent</a><span>|</span><a href="#36274422">prev</a><span>|</span><a href="#36274582">next</a><span>|</span><label class="collapse" for="c-36274411">[-]</label><label class="expand" for="c-36274411">[1 more]</label></div><br/><div class="children"><div class="content">IIRC, there were issues with it causing frequency throttling on Intel cpus, whereas AMD&#x27;s avoid that by &quot;double pumping&quot;. It would be very interesting to compare and contrast there.<p>Seems like there&#x27;s be value in it for all the new ML hotness that&#x27;s come about. The AMD 7950x seems like it hits the sweet spot for that.</div><br/></div></div></div></div></div></div><div id="36274582" class="c"><input type="checkbox" id="c-36274582" checked=""/><div class="controls bullet"><span class="by">nerpderp82</span><span>|</span><a href="#36274221">prev</a><span>|</span><a href="#36274731">next</a><span>|</span><label class="collapse" for="c-36274582">[-]</label><label class="expand" for="c-36274582">[3 more]</label></div><br/><div class="children"><div class="content">The author posted here a couple hours ago, <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36268877" rel="nofollow">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36268877</a></div><br/><div id="36276083" class="c"><input type="checkbox" id="c-36276083" checked=""/><div class="controls bullet"><span class="by">Twirrim</span><span>|</span><a href="#36274582">parent</a><span>|</span><a href="#36274675">next</a><span>|</span><label class="collapse" for="c-36276083">[-]</label><label class="expand" for="c-36276083">[1 more]</label></div><br/><div class="children"><div class="content">Argh.  Apologies to the author.  I didn&#x27;t see the original when I looked before submitting, and I expected HN to pop up a link to the existing post, like it usually does.  Wasn&#x27;t my intention to post a dupe :(</div><br/></div></div><div id="36274675" class="c"><input type="checkbox" id="c-36274675" checked=""/><div class="controls bullet"><span class="by">gavinray</span><span>|</span><a href="#36274582">parent</a><span>|</span><a href="#36276083">prev</a><span>|</span><a href="#36274731">next</a><span>|</span><label class="collapse" for="c-36274675">[-]</label><label class="expand" for="c-36274675">[1 more]</label></div><br/><div class="children"><div class="content">Ah that&#x27;s sort of a bummer -- same title and everything (initially).<p>Hopefully they will notice this thread and comment though, or the threads can be merged.</div><br/></div></div></div></div><div id="36274731" class="c"><input type="checkbox" id="c-36274731" checked=""/><div class="controls bullet"><span class="by">gavinray</span><span>|</span><a href="#36274582">prev</a><span>|</span><a href="#36275806">next</a><span>|</span><label class="collapse" for="c-36274731">[-]</label><label class="expand" for="c-36274731">[4 more]</label></div><br/><div class="children"><div class="content">In the event the author shows up: What is the mental process like when you work on&#x2F;figure out these sorts of things?<p>Do you have a sort of intuitive understanding&#x2F;feeling for what you ought to do, or a mental visualization, or what goes on inside of your head?<p>Some of this code is mind-bending and I&#x27;m struggling to see how someone arrives at stuff like this:<p>[1]: <a href="https:&#x2F;&#x2F;github.com&#x2F;Voultapher&#x2F;sort-research-rs&#x2F;blob&#x2F;42bf339d0d31de61c0490dceffdfd7f55324cbc8&#x2F;src&#x2F;unstable&#x2F;rust_ipnsort.rs#L279-L300">https:&#x2F;&#x2F;github.com&#x2F;Voultapher&#x2F;sort-research-rs&#x2F;blob&#x2F;42bf339d...</a><p>[2]: <a href="https:&#x2F;&#x2F;github.com&#x2F;Voultapher&#x2F;sort-research-rs&#x2F;blob&#x2F;42bf339d0d31de61c0490dceffdfd7f55324cbc8&#x2F;src&#x2F;unstable&#x2F;rust_ipnsort.rs#L1215-L1239">https:&#x2F;&#x2F;github.com&#x2F;Voultapher&#x2F;sort-research-rs&#x2F;blob&#x2F;42bf339d...</a></div><br/><div id="36275248" class="c"><input type="checkbox" id="c-36275248" checked=""/><div class="controls bullet"><span class="by">Voultapher</span><span>|</span><a href="#36274731">parent</a><span>|</span><a href="#36276010">next</a><span>|</span><label class="collapse" for="c-36275248">[-]</label><label class="expand" for="c-36275248">[2 more]</label></div><br/><div class="children"><div class="content">Ok so both the things you linked are not my ideas. The first one is AFAIK originally from the BlockQuicksort paper <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;1604.06697.pdf" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;1604.06697.pdf</a> section 3.2. Which Orson Peters used in his pdqsort, which I know base ipnsort on. The second one is from Igor van den Hoven in his work on quadsort as I mention in the function description. Really a lot of this stuff is building on top of other peoples work and refining it. Seemingly I&#x27;m the first to write neat little ASCII graphics for them in the code making them easier to approach. There are some novel ideas by me in there too though, for example <a href="https:&#x2F;&#x2F;github.com&#x2F;Voultapher&#x2F;sort-research-rs&#x2F;blob&#x2F;42bf339d0d31de61c0490dceffdfd7f55324cbc8&#x2F;src&#x2F;unstable&#x2F;rust_ipnsort.rs#L1501">https:&#x2F;&#x2F;github.com&#x2F;Voultapher&#x2F;sort-research-rs&#x2F;blob&#x2F;42bf339d...</a> the way I marry a limited number of sorting-networks, insertion sort and the bi-directional merge into one, very fast but binary size and compile time efficient package is novel. Or that with LLVM you can do 2 instead of 4 writes per loop iteration in the bi-directional merge, which Igor has now ported back to his stuff as well. Generally I&#x27;d say my work has been more about figuring out novel ways to combine existing ideas into one good cohesive package fit for a standard library sort implementation. As well as taking ideas that work in the C and C++ world and doing the legwork to adapt them for use in Rust, which requires a lot more considerations and a lot of code can&#x27;t be ported straight up. I wrote a little more about that in another comment here.</div><br/><div id="36275307" class="c"><input type="checkbox" id="c-36275307" checked=""/><div class="controls bullet"><span class="by">gavinray</span><span>|</span><a href="#36274731">root</a><span>|</span><a href="#36275248">parent</a><span>|</span><a href="#36276010">next</a><span>|</span><label class="collapse" for="c-36275307">[-]</label><label class="expand" for="c-36275307">[1 more]</label></div><br/><div class="children"><div class="content">Thanks for the reply!<p>Do you feel like you have a sort of &quot;intuition&quot; for which things might work, and you experiment starting from that, or what is your general thought process like?<p>Or maybe you start by drawing things out on paper? Really curious what the process of reasoning and thinking about something like this is.</div><br/></div></div></div></div><div id="36276010" class="c"><input type="checkbox" id="c-36276010" checked=""/><div class="controls bullet"><span class="by">tesdinger</span><span>|</span><a href="#36274731">parent</a><span>|</span><a href="#36275248">prev</a><span>|</span><a href="#36275806">next</a><span>|</span><label class="collapse" for="c-36276010">[-]</label><label class="expand" for="c-36276010">[1 more]</label></div><br/><div class="children"><div class="content">You cleverly wrote &quot;sort&quot; two times without referring to actual sorting in a thread about sorting.<p>The first algorithm that you linked is easy to explain. As soon as a value has been stored in another location its original location can be overwritten. To get started we move something to an additional location called temp A &gt; Temp. Then we can overwrite it with the intended value Z &gt; A. Then we can overwrite Z and so on and so forth.</div><br/></div></div></div></div><div id="36275806" class="c"><input type="checkbox" id="c-36275806" checked=""/><div class="controls bullet"><span class="by">mafik</span><span>|</span><a href="#36274731">prev</a><span>|</span><a href="#36274687">next</a><span>|</span><label class="collapse" for="c-36275806">[-]</label><label class="expand" for="c-36275806">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve read the C++ code used in the benchmark and noticed several issues that would affect its performance (wrapping comparison function behind multiple layers of indirection, throwing exceptions (!?) from comparator, passing arguments as references rather than values, not using the C++ sort &quot;Compare&quot; template argument). Given the amount od indirection and boilerplate I&#x27;m pretty skeptical of the results od this benchmark.</div><br/></div></div><div id="36274687" class="c"><input type="checkbox" id="c-36274687" checked=""/><div class="controls bullet"><span class="by">inciampati</span><span>|</span><a href="#36275806">prev</a><span>|</span><a href="#36274491">next</a><span>|</span><label class="collapse" for="c-36274687">[-]</label><label class="expand" for="c-36274687">[3 more]</label></div><br/><div class="children"><div class="content">The data stops before it gets to useful sizes (10e7 and up). How are people implementing sorting algorithms not routinely working at 10e9-10e12 where the workload is actually a bottleneck?</div><br/><div id="36275038" class="c"><input type="checkbox" id="c-36275038" checked=""/><div class="controls bullet"><span class="by">henrydark</span><span>|</span><a href="#36274687">parent</a><span>|</span><a href="#36274491">next</a><span>|</span><label class="collapse" for="c-36275038">[-]</label><label class="expand" for="c-36275038">[2 more]</label></div><br/><div class="children"><div class="content">I run ml algorithms like boosted trees (i.e xgboost) on data sets with 30k-1m rows and 200-2k columns. Sorting is the bottleneck, it&#x27;s what the algorithm does. I doubt I&#x27;m special, and I&#x27;m sure these size are common</div><br/><div id="36277827" class="c"><input type="checkbox" id="c-36277827" checked=""/><div class="controls bullet"><span class="by">nwmcsween</span><span>|</span><a href="#36274687">root</a><span>|</span><a href="#36275038">parent</a><span>|</span><a href="#36274491">next</a><span>|</span><label class="collapse" for="c-36277827">[-]</label><label class="expand" for="c-36277827">[1 more]</label></div><br/><div class="children"><div class="content">IIRC the average qsort len is less than 20 according to debian code search.</div><br/></div></div></div></div></div></div><div id="36274491" class="c"><input type="checkbox" id="c-36274491" checked=""/><div class="controls bullet"><span class="by">Conscat</span><span>|</span><a href="#36274687">prev</a><span>|</span><a href="#36274602">next</a><span>|</span><label class="collapse" for="c-36274491">[-]</label><label class="expand" for="c-36274491">[1 more]</label></div><br/><div class="children"><div class="content">I wonder if AVX-512 CPU throttling is a big problem for sorting algorithms based on those instructions.</div><br/></div></div><div id="36274602" class="c"><input type="checkbox" id="c-36274602" checked=""/><div class="controls bullet"><span class="by">Cold_Miserable</span><span>|</span><a href="#36274491">prev</a><span>|</span><label class="collapse" for="c-36274602">[-]</label><label class="expand" for="c-36274602">[2 more]</label></div><br/><div class="children"><div class="content">AVX512 is scarcely faster than radix at 1 million elements while being vastly more complicated.</div><br/><div id="36278744" class="c"><input type="checkbox" id="c-36278744" checked=""/><div class="controls bullet"><span class="by">anonymoushn</span><span>|</span><a href="#36274602">parent</a><span>|</span><label class="collapse" for="c-36278744">[-]</label><label class="expand" for="c-36278744">[1 more]</label></div><br/><div class="children"><div class="content">Post benchmarks?</div><br/></div></div></div></div></div></div></div></div></div></body></html>