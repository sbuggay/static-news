<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1720602064561" as="style"/><link rel="stylesheet" href="styles.css?v=1720602064561"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/lm-sys/RouteLLM">RouteLLM: A framework for serving and evaluating LLM routers</a> <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>djhu9</span> | <span>27 comments</span></div><br/><div><div id="40925017" class="c"><input type="checkbox" id="c-40925017" checked=""/><div class="controls bullet"><span class="by">Havoc</span><span>|</span><a href="#40923007">next</a><span>|</span><label class="collapse" for="c-40925017">[-]</label><label class="expand" for="c-40925017">[1 more]</label></div><br/><div class="children"><div class="content">Interesting that it is generalizable to other pairs. That implies some sort of prompt property or characteristic that could be widely used.<p>I don’t think using different models is the right approach though. They behave differently. Better to use a big and small one from same family. Or alternatively using this to drive whether to give the ai more “thinking time” via chain of thought or agents.</div><br/></div></div><div id="40923007" class="c"><input type="checkbox" id="c-40923007" checked=""/><div class="controls bullet"><span class="by">furyofantares</span><span>|</span><a href="#40925017">prev</a><span>|</span><a href="#40924836">next</a><span>|</span><label class="collapse" for="c-40923007">[-]</label><label class="expand" for="c-40923007">[7 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t really get who these are for - do people use them in their projects?<p>I don&#x27;t find success just using a prompt against some other model without having some way to evaluate it and usually updating it for that model.</div><br/><div id="40923238" class="c"><input type="checkbox" id="c-40923238" checked=""/><div class="controls bullet"><span class="by">vatican_banker</span><span>|</span><a href="#40923007">parent</a><span>|</span><a href="#40924335">next</a><span>|</span><label class="collapse" for="c-40923238">[-]</label><label class="expand" for="c-40923238">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Trained routers are provided out of the box, which we have shown to reduce costs by up to 85%<p>The answer is here. This is a cost-saving tool.<p>All companies and their moms want to be in the GenAI game but have strict budgets. Tools like this help to keep GenAI projects within budget.</div><br/></div></div><div id="40924335" class="c"><input type="checkbox" id="c-40924335" checked=""/><div class="controls bullet"><span class="by">rodrigobahiense</span><span>|</span><a href="#40923007">parent</a><span>|</span><a href="#40923238">prev</a><span>|</span><a href="#40923095">next</a><span>|</span><label class="collapse" for="c-40924335">[-]</label><label class="expand" for="c-40924335">[1 more]</label></div><br/><div class="children"><div class="content">For the company I work for, one of the most important aspects is ensuring we can fallback to different models in case of content filtering since they are not equally sensitive&#x2F;restrict.</div><br/></div></div><div id="40923095" class="c"><input type="checkbox" id="c-40923095" checked=""/><div class="controls bullet"><span class="by">brandall10</span><span>|</span><a href="#40923007">parent</a><span>|</span><a href="#40924335">prev</a><span>|</span><a href="#40924303">next</a><span>|</span><label class="collapse" for="c-40923095">[-]</label><label class="expand" for="c-40923095">[1 more]</label></div><br/><div class="children"><div class="content">You may have a variety of model types&#x2F;sizes, fine tunes, etc, that serve different purposes - optimizing for cost&#x2F;speed&#x2F;specificity of task. At least that&#x27;s the general theory with routing. This one only seems to optimize for cost&#x2F;quality.</div><br/></div></div><div id="40924303" class="c"><input type="checkbox" id="c-40924303" checked=""/><div class="controls bullet"><span class="by">monarchwadia</span><span>|</span><a href="#40923007">parent</a><span>|</span><a href="#40923095">prev</a><span>|</span><a href="#40923097">next</a><span>|</span><label class="collapse" for="c-40924303">[-]</label><label class="expand" for="c-40924303">[1 more]</label></div><br/><div class="children"><div class="content">I think a lot of people are just interested in hitting the LLM without any bells or whistles, from Typescript. A low level connector lib would come in handy, yeah?  <a href="https:&#x2F;&#x2F;github.com&#x2F;monarchwadia&#x2F;ragged">https:&#x2F;&#x2F;github.com&#x2F;monarchwadia&#x2F;ragged</a></div><br/></div></div><div id="40923097" class="c"><input type="checkbox" id="c-40923097" checked=""/><div class="controls bullet"><span class="by">veb</span><span>|</span><a href="#40923007">parent</a><span>|</span><a href="#40924303">prev</a><span>|</span><a href="#40924836">next</a><span>|</span><label class="collapse" for="c-40923097">[-]</label><label class="expand" for="c-40923097">[2 more]</label></div><br/><div class="children"><div class="content">From what I understand, it&#x27;s from people using it in their workflows - say, Claude but keep hitting the rate limits, so they have to wait until Claude says &quot;you got 10 messages left until 9pm&quot;, so when they hit that, or before they switch to (maybe) ChatGPT manually.<p>With the router thingy, it keeps a record, so you know every query where you stand, and can switch to another model automatically instead of interrupting workflow?<p>I may be explaining this very badly, but I think that&#x27;s one use-case for how these LLM Routers help.</div><br/><div id="40923322" class="c"><input type="checkbox" id="c-40923322" checked=""/><div class="controls bullet"><span class="by">PiRho3141</span><span>|</span><a href="#40923007">root</a><span>|</span><a href="#40923097">parent</a><span>|</span><a href="#40924836">next</a><span>|</span><label class="collapse" for="c-40923322">[-]</label><label class="expand" for="c-40923322">[1 more]</label></div><br/><div class="children"><div class="content">This is for applications that use LLMs or Chat GPT via API.</div><br/></div></div></div></div></div></div><div id="40924836" class="c"><input type="checkbox" id="c-40924836" checked=""/><div class="controls bullet"><span class="by">daghamm</span><span>|</span><a href="#40923007">prev</a><span>|</span><a href="#40923002">next</a><span>|</span><label class="collapse" for="c-40924836">[-]</label><label class="expand" for="c-40924836">[2 more]</label></div><br/><div class="children"><div class="content">My take from this is that 85% of times we don&#x27;t need a powerfull LLM like 4o.<p>Or am I reading this wrong? :)</div><br/><div id="40924994" class="c"><input type="checkbox" id="c-40924994" checked=""/><div class="controls bullet"><span class="by">thomashop</span><span>|</span><a href="#40924836">parent</a><span>|</span><a href="#40923002">next</a><span>|</span><label class="collapse" for="c-40924994">[-]</label><label class="expand" for="c-40924994">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;re reading it right. They have developed a system that automatically decides which model is sufficient, depending on your inputs, saving you costs even within one conversation stream.<p>The OpenAI-compatible API allows you to talk to the router like a regular GPT model.</div><br/></div></div></div></div><div id="40923002" class="c"><input type="checkbox" id="c-40923002" checked=""/><div class="controls bullet"><span class="by">worstspotgain</span><span>|</span><a href="#40924836">prev</a><span>|</span><a href="#40923293">next</a><span>|</span><label class="collapse" for="c-40923002">[-]</label><label class="expand" for="c-40923002">[1 more]</label></div><br/><div class="children"><div class="content">I like their &quot;LLM isovalue&quot; graph, and the idea that different vendors can be forced to partake in the same synergy&#x2F;distillation scheme. Vendors dislike these schemes, but they&#x27;re probably OK with them as long as they&#x27;re niche.</div><br/></div></div><div id="40923293" class="c"><input type="checkbox" id="c-40923293" checked=""/><div class="controls bullet"><span class="by">tananaev</span><span>|</span><a href="#40923002">prev</a><span>|</span><a href="#40923246">next</a><span>|</span><label class="collapse" for="c-40923293">[-]</label><label class="expand" for="c-40923293">[5 more]</label></div><br/><div class="children"><div class="content">The problem is to understand how complex the request is, you have to use a smart enough model.</div><br/><div id="40923730" class="c"><input type="checkbox" id="c-40923730" checked=""/><div class="controls bullet"><span class="by">Grimblewald</span><span>|</span><a href="#40923293">parent</a><span>|</span><a href="#40923327">next</a><span>|</span><label class="collapse" for="c-40923730">[-]</label><label class="expand" for="c-40923730">[1 more]</label></div><br/><div class="children"><div class="content">not true at all, you could have a efficient cheap model which is generally terrible at most things but has a savant like capacity for categorizing tasks by requirement and difficulty. Even easier when you dont need to support multiple languages and a truly staggering breadth of domains, like a conventional llm does. You could train a really small model to reject out of domain requests and partition the rest, running at a fraction of the cost of a more capable model.</div><br/></div></div><div id="40923327" class="c"><input type="checkbox" id="c-40923327" checked=""/><div class="controls bullet"><span class="by">ethegwo</span><span>|</span><a href="#40923293">parent</a><span>|</span><a href="#40923730">prev</a><span>|</span><a href="#40923312">next</a><span>|</span><label class="collapse" for="c-40923327">[-]</label><label class="expand" for="c-40923327">[1 more]</label></div><br/><div class="children"><div class="content">The weak-to-strong assumption is that it is easier to eval the result of a task than to generate it. If it is wrong, human can not make a stronger intelligence than us.</div><br/></div></div><div id="40923312" class="c"><input type="checkbox" id="c-40923312" checked=""/><div class="controls bullet"><span class="by">PiRho3141</span><span>|</span><a href="#40923293">parent</a><span>|</span><a href="#40923327">prev</a><span>|</span><a href="#40923315">next</a><span>|</span><label class="collapse" for="c-40923312">[-]</label><label class="expand" for="c-40923312">[1 more]</label></div><br/><div class="children"><div class="content">Not true. You can easily train a BERT single class classification model without having to train an LLM.</div><br/></div></div><div id="40923315" class="c"><input type="checkbox" id="c-40923315" checked=""/><div class="controls bullet"><span class="by">CuriouslyC</span><span>|</span><a href="#40923293">parent</a><span>|</span><a href="#40923312">prev</a><span>|</span><a href="#40923246">next</a><span>|</span><label class="collapse" for="c-40923315">[-]</label><label class="expand" for="c-40923315">[1 more]</label></div><br/><div class="children"><div class="content">You can distill evaluation ability</div><br/></div></div></div></div><div id="40923246" class="c"><input type="checkbox" id="c-40923246" checked=""/><div class="controls bullet"><span class="by">vatican_banker</span><span>|</span><a href="#40923293">prev</a><span>|</span><a href="#40923279">next</a><span>|</span><label class="collapse" for="c-40923246">[-]</label><label class="expand" for="c-40923246">[4 more]</label></div><br/><div class="children"><div class="content">The tool currently allows only one set of strong and weak models.<p>I’d be really good to allow more than two models and change dynamically based on multiple constraints like latency, reasoning complexity, costs, etc.</div><br/><div id="40924164" class="c"><input type="checkbox" id="c-40924164" checked=""/><div class="controls bullet"><span class="by">voiper1</span><span>|</span><a href="#40923246">parent</a><span>|</span><a href="#40923300">next</a><span>|</span><label class="collapse" for="c-40924164">[-]</label><label class="expand" for="c-40924164">[2 more]</label></div><br/><div class="children"><div class="content">I think unify.ai (like openrouter) does that - it has several paramters you can choose from.<p>But the underlying &quot;how to choose a model that&#x27;s smart enough but not too smart&quot; seems difficult to understand.</div><br/><div id="40924714" class="c"><input type="checkbox" id="c-40924714" checked=""/><div class="controls bullet"><span class="by">TechDebtDevin</span><span>|</span><a href="#40923246">root</a><span>|</span><a href="#40924164">parent</a><span>|</span><a href="#40923300">next</a><span>|</span><label class="collapse" for="c-40924714">[-]</label><label class="expand" for="c-40924714">[1 more]</label></div><br/><div class="children"><div class="content">Its just sentiment analysis.</div><br/></div></div></div></div><div id="40923300" class="c"><input type="checkbox" id="c-40923300" checked=""/><div class="controls bullet"><span class="by">KTibow</span><span>|</span><a href="#40923246">parent</a><span>|</span><a href="#40924164">prev</a><span>|</span><a href="#40923279">next</a><span>|</span><label class="collapse" for="c-40923300">[-]</label><label class="expand" for="c-40923300">[1 more]</label></div><br/><div class="children"><div class="content">Some of that is already possible, since it can generate a difficulty score for a prompt that could be manually mapped between models based on ranges.</div><br/></div></div></div></div><div id="40924078" class="c"><input type="checkbox" id="c-40924078" checked=""/><div class="controls bullet"><span class="by">fazmi</span><span>|</span><a href="#40923245">prev</a><span>|</span><a href="#40923248">next</a><span>|</span><label class="collapse" for="c-40924078">[-]</label><label class="expand" for="c-40924078">[1 more]</label></div><br/><div class="children"><div class="content">Poppt</div><br/></div></div></div></div></div></div></div></body></html>