<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1684227658934" as="style"/><link rel="stylesheet" href="styles.css?v=1684227658934"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/eth-sri/lmql">LMQL: A query language for programming (large) language models</a>Â <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>behnamoh</span> | <span>9 comments</span></div><br/><div><div id="35958955" class="c"><input type="checkbox" id="c-35958955" checked=""/><div class="controls bullet"><span class="by">veselin</span><span>|</span><a href="#35958707">next</a><span>|</span><label class="collapse" for="c-35958955">[-]</label><label class="expand" for="c-35958955">[1 more]</label></div><br/><div class="children"><div class="content">One of main reasons somebody may want to use such a library is to constrain the output of a LLM. The language is designed to make this easy and abstract this part of the querying away. There are trivial cases when some value is coming from multiple choice, but one can also easily constrain one word to depend on a previously generated word.</div><br/></div></div><div id="35958707" class="c"><input type="checkbox" id="c-35958707" checked=""/><div class="controls bullet"><span class="by">IanCal</span><span>|</span><a href="#35958955">prev</a><span>|</span><a href="#35957675">next</a><span>|</span><label class="collapse" for="c-35958707">[-]</label><label class="expand" for="c-35958707">[2 more]</label></div><br/><div class="children"><div class="content">Is it possible to roll back the output and insert essentially into the <i>previous</i> line of the LLM output? But not losing what they&#x27;re writing now.<p>Here&#x27;s the flow I&#x27;ve been picturing while writing code writing models. Feel free to take this idea anyone, would appreciate a heads up if it works and you publish sota before I get around to it :)<p>Let&#x27;s give llms ide level info. As they type, if there&#x27;s a function they&#x27;re starting to call use a language server to get tooltip docs and put it in a comment just above the line it&#x27;s writing. Put auto complete help, type docs, etc in their context while they code.<p>Edit<p>Second thought, this kind of thing feels very low in compute compared to the LLM calculations, is this the kind of thing that could be passed up to a remote service as a wasm bundle&#x2F;similar, to control the streaming output?</div><br/><div id="35959078" class="c"><input type="checkbox" id="c-35959078" checked=""/><div class="controls bullet"><span class="by">lbeurerkellner</span><span>|</span><a href="#35958707">parent</a><span>|</span><a href="#35957675">next</a><span>|</span><label class="collapse" for="c-35959078">[-]</label><label class="expand" for="c-35959078">[1 more]</label></div><br/><div class="children"><div class="content">If I understand correctly what you are imagining is some sort of local retrieval enhancement to generate a specific part of the overall response, which later is removed, once e.g. the generated piece of code (e.g. a function call) has completed generation.<p>Indeed, this is a form of LLM prompting that we are also exploring in our preview release channel with something called in-context functions. See <a href="https:&#x2F;&#x2F;next.lmql.ai" rel="nofollow">https:&#x2F;&#x2F;next.lmql.ai</a> and choose the &quot;In-Context Functions&quot; example in the New Features showcase screen.<p>With in-context functions, you can provide additional instructions&#x2F;data to the LLM, that will apply locally only. Once such an in-context function returns, additional instructions&#x2F;retrieved info is removed and only the LLM-generated end-result remains.</div><br/></div></div></div></div><div id="35957675" class="c"><input type="checkbox" id="c-35957675" checked=""/><div class="controls bullet"><span class="by">CGamesPlay</span><span>|</span><a href="#35958707">prev</a><span>|</span><a href="#35958190">next</a><span>|</span><label class="collapse" for="c-35957675">[-]</label><label class="expand" for="c-35957675">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s a lot of cool stuff in this library. It&#x27;s been submitted many times to HN, the authors had some discourse here: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=35484673" rel="nofollow">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=35484673</a></div><br/></div></div><div id="35958190" class="c"><input type="checkbox" id="c-35958190" checked=""/><div class="controls bullet"><span class="by">lbeurerkellner</span><span>|</span><a href="#35957675">prev</a><span>|</span><a href="#35957843">next</a><span>|</span><label class="collapse" for="c-35958190">[-]</label><label class="expand" for="c-35958190">[1 more]</label></div><br/><div class="children"><div class="content">Author here, thanks for posting us.<p>Be sure to play around with our entirely web-based playground IDE here: <a href="https:&#x2F;&#x2F;lmql.ai&#x2F;playground" rel="nofollow">https:&#x2F;&#x2F;lmql.ai&#x2F;playground</a> and our example showcase at <a href="https:&#x2F;&#x2F;lmql.ai" rel="nofollow">https:&#x2F;&#x2F;lmql.ai</a>. We are happy to answer any questions that come up.</div><br/></div></div><div id="35957843" class="c"><input type="checkbox" id="c-35957843" checked=""/><div class="controls bullet"><span class="by">tehsauce</span><span>|</span><a href="#35958190">prev</a><span>|</span><label class="collapse" for="c-35957843">[-]</label><label class="expand" for="c-35957843">[3 more]</label></div><br/><div class="children"><div class="content">What reason is there to learn a new query language when I can program a LLM with any existing language?</div><br/><div id="35958139" class="c"><input type="checkbox" id="c-35958139" checked=""/><div class="controls bullet"><span class="by">lbeurerkellner</span><span>|</span><a href="#35957843">parent</a><span>|</span><a href="#35957888">next</a><span>|</span><label class="collapse" for="c-35958139">[-]</label><label class="expand" for="c-35958139">[1 more]</label></div><br/><div class="children"><div class="content">Author here.<p>LMQL gives you a concise way to define multi-part prompts and enforce constraint on LLMs. For instance, you can make sure the model always adheres to a specific output format, where parsing of the output is automatically taken care of. Also abstracts a number of things like APIs and local models, tokenisation, optimisation and makes tool integration (e.g. tool function calls during LLM reasoning) much easier.<p>In practice this saves you a lot of ugly text concatenation and output parsing code, letting you focus on the core logic of your project. Overall, however, you will still use your host language to call LMQL. E.g. we are fully integrated with Python, where LMQL query code simply lives in decorated functions (<a href="https:&#x2F;&#x2F;docs.lmql.ai&#x2F;en&#x2F;latest&#x2F;python&#x2F;python.html" rel="nofollow">https:&#x2F;&#x2F;docs.lmql.ai&#x2F;en&#x2F;latest&#x2F;python&#x2F;python.html</a>).</div><br/></div></div><div id="35957888" class="c"><input type="checkbox" id="c-35957888" checked=""/><div class="controls bullet"><span class="by">CGamesPlay</span><span>|</span><a href="#35957843">parent</a><span>|</span><a href="#35958139">prev</a><span>|</span><label class="collapse" for="c-35957888">[-]</label><label class="expand" for="c-35957888">[1 more]</label></div><br/><div class="children"><div class="content">Think of this more like SQL rather than Python. This language doesn&#x27;t replace your main language, and you could implement all of the logic in your main language, obviously. But this provides you with easy-to-access primitives for beam search, constrained responses, etc.</div><br/></div></div></div></div></div></div></div></div></div></body></html>