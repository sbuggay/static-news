<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1712912459811" as="style"/><link rel="stylesheet" href="styles.css?v=1712912459811"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/getlago/lago/wiki/Using-Clickhouse-to-scale-an-events-engine">Using ClickHouse to scale an events engine</a> <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>wyndham</span> | <span>92 comments</span></div><br/><div><div id="40005561" class="c"><input type="checkbox" id="c-40005561" checked=""/><div class="controls bullet"><span class="by">mritchie712</span><span>|</span><a href="#40005842">next</a><span>|</span><label class="collapse" for="c-40005561">[-]</label><label class="expand" for="c-40005561">[10 more]</label></div><br/><div class="children"><div class="content">&gt; Recently, the most interesting rift in the Postgres vs OLAP space is [Hydra](<a href="https:&#x2F;&#x2F;www.hydra.so">https:&#x2F;&#x2F;www.hydra.so</a>), an open-source, column-oriented distribution of Postgres that was very recently launched (after our migration to ClickHouse). Had Hydra been available during our decision-making time period, we might’ve made a different choice.<p>There will likely be a good OLAP solution (possibly implemented as an extension) in Postgres in the next year or so. There are a few companies are working on it (Hydra, Parade[0], tembo etc.).<p>0 - <a href="https:&#x2F;&#x2F;www.paradedb.com&#x2F;">https:&#x2F;&#x2F;www.paradedb.com&#x2F;</a></div><br/><div id="40009239" class="c"><input type="checkbox" id="c-40009239" checked=""/><div class="controls bullet"><span class="by">snihalani</span><span>|</span><a href="#40005561">parent</a><span>|</span><a href="#40009417">next</a><span>|</span><label class="collapse" for="c-40009239">[-]</label><label class="expand" for="c-40009239">[3 more]</label></div><br/><div class="children"><div class="content">Have you seen: <a href="https:&#x2F;&#x2F;benchmark.clickhouse.com&#x2F;" rel="nofollow">https:&#x2F;&#x2F;benchmark.clickhouse.com&#x2F;</a></div><br/><div id="40009259" class="c"><input type="checkbox" id="c-40009259" checked=""/><div class="controls bullet"><span class="by">iimblack</span><span>|</span><a href="#40005561">root</a><span>|</span><a href="#40009239">parent</a><span>|</span><a href="#40010406">next</a><span>|</span><label class="collapse" for="c-40009259">[-]</label><label class="expand" for="c-40009259">[1 more]</label></div><br/><div class="children"><div class="content">That’s cool. Clickhouse and Alloy’s performances are impressive.</div><br/></div></div><div id="40010406" class="c"><input type="checkbox" id="c-40010406" checked=""/><div class="controls bullet"><span class="by">riku_iki</span><span>|</span><a href="#40005561">root</a><span>|</span><a href="#40009239">parent</a><span>|</span><a href="#40009259">prev</a><span>|</span><a href="#40009417">next</a><span>|</span><label class="collapse" for="c-40010406">[-]</label><label class="expand" for="c-40010406">[1 more]</label></div><br/><div class="children"><div class="content">that benchmark is very weak, they used just 100M rows which is laughable, also no joins have been tested.</div><br/></div></div></div></div><div id="40009417" class="c"><input type="checkbox" id="c-40009417" checked=""/><div class="controls bullet"><span class="by">philippemnoel</span><span>|</span><a href="#40005561">parent</a><span>|</span><a href="#40009239">prev</a><span>|</span><a href="#40010331">next</a><span>|</span><label class="collapse" for="c-40009417">[-]</label><label class="expand" for="c-40009417">[2 more]</label></div><br/><div class="children"><div class="content">ParadeDB founder here. You can see how we compare to other Postgres-based analytical offerings on ClickBench here: <a href="https:&#x2F;&#x2F;blog.paradedb.com&#x2F;pages&#x2F;introducing_analytics">https:&#x2F;&#x2F;blog.paradedb.com&#x2F;pages&#x2F;introducing_analytics</a></div><br/><div id="40010437" class="c"><input type="checkbox" id="c-40010437" checked=""/><div class="controls bullet"><span class="by">riku_iki</span><span>|</span><a href="#40005561">root</a><span>|</span><a href="#40009417">parent</a><span>|</span><a href="#40010331">next</a><span>|</span><label class="collapse" for="c-40010437">[-]</label><label class="expand" for="c-40010437">[1 more]</label></div><br/><div class="children"><div class="content">Please note that Postgres(tuned) in clickbench was undertuned by Hydra devs from whatever reasons: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37260464">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37260464</a></div><br/></div></div></div></div><div id="40010331" class="c"><input type="checkbox" id="c-40010331" checked=""/><div class="controls bullet"><span class="by">Mortiffer</span><span>|</span><a href="#40005561">parent</a><span>|</span><a href="#40009417">prev</a><span>|</span><a href="#40010465">next</a><span>|</span><label class="collapse" for="c-40010331">[-]</label><label class="expand" for="c-40010331">[1 more]</label></div><br/><div class="children"><div class="content">so Paradedb  and Hydra are using same codebase or just similar approach ?</div><br/></div></div><div id="40010465" class="c"><input type="checkbox" id="c-40010465" checked=""/><div class="controls bullet"><span class="by">ddorian43</span><span>|</span><a href="#40005561">parent</a><span>|</span><a href="#40010331">prev</a><span>|</span><a href="#40005677">next</a><span>|</span><label class="collapse" for="c-40010465">[-]</label><label class="expand" for="c-40010465">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think `tembo` is working on it though, probably just hosting an existing extension.</div><br/></div></div><div id="40005677" class="c"><input type="checkbox" id="c-40005677" checked=""/><div class="controls bullet"><span class="by">riku_iki</span><span>|</span><a href="#40005561">parent</a><span>|</span><a href="#40010465">prev</a><span>|</span><a href="#40005842">next</a><span>|</span><label class="collapse" for="c-40005677">[-]</label><label class="expand" for="c-40005677">[2 more]</label></div><br/><div class="children"><div class="content">&gt; 0 - <a href="https:&#x2F;&#x2F;www.paradedb.com&#x2F;">https:&#x2F;&#x2F;www.paradedb.com&#x2F;</a><p>this looks like repackaging of datafusion as PG extension?..</div><br/><div id="40006029" class="c"><input type="checkbox" id="c-40006029" checked=""/><div class="controls bullet"><span class="by">mritchie712</span><span>|</span><a href="#40005561">root</a><span>|</span><a href="#40005677">parent</a><span>|</span><a href="#40005842">next</a><span>|</span><label class="collapse" for="c-40006029">[-]</label><label class="expand" for="c-40006029">[1 more]</label></div><br/><div class="children"><div class="content">yes, that&#x27;s a succinct way to put it.</div><br/></div></div></div></div></div></div><div id="40005842" class="c"><input type="checkbox" id="c-40005842" checked=""/><div class="controls bullet"><span class="by">joshstrange</span><span>|</span><a href="#40005561">prev</a><span>|</span><a href="#40009697">next</a><span>|</span><label class="collapse" for="c-40005842">[-]</label><label class="expand" for="c-40005842">[29 more]</label></div><br/><div class="children"><div class="content">I feel like with all the Clickhouse praise on HN that we &#x2F;must&#x2F; be doing something fundamentally wrong because I hate every interaction I have with Clickhouse.<p>* Timeouts (only 30s???) unless I used the cli client<p>* Cancelling rows - Just kill me, so many bugs and FINAL&#x2F;PREWHERE are massive foot-guns<p>* Cluster just feels annoying and fragile don&#x27;t forget &quot;ON CLUSTER&quot; or you&#x27;ll have a bad time<p>Again, I feel like we must be doing something wrong but we are paying an arm and a leg for that &quot;privilege&quot;.</div><br/><div id="40005983" class="c"><input type="checkbox" id="c-40005983" checked=""/><div class="controls bullet"><span class="by">nsguy</span><span>|</span><a href="#40005842">parent</a><span>|</span><a href="#40006131">next</a><span>|</span><label class="collapse" for="c-40005983">[-]</label><label class="expand" for="c-40005983">[9 more]</label></div><br/><div class="children"><div class="content">What is your use case? If you&#x27;re deleting rows that already feels like maybe it&#x27;s not the intended use case. I think about clickhouse as taking in a firehose of immutable data that you want to aggregate&#x2F;analyze&#x2F;report on. Let&#x27;s say a million records per second. I&#x27;ll make up an example, the orientation, speed and acceleration of every Tesla vehicle in the world in real time every second.</div><br/><div id="40006107" class="c"><input type="checkbox" id="c-40006107" checked=""/><div class="controls bullet"><span class="by">joshstrange</span><span>|</span><a href="#40005842">root</a><span>|</span><a href="#40005983">parent</a><span>|</span><a href="#40006131">next</a><span>|</span><label class="collapse" for="c-40006107">[-]</label><label class="expand" for="c-40006107">[8 more]</label></div><br/><div class="children"><div class="content">It&#x27;s to power all our analytics. We ETL data into it and some data is write-once so we don&#x27;t have updates&#x2F;deletes but a number of our tables have summary data ETL&#x27;d into them which means cleaning up the old rows.<p>I&#x27;m sure CH shines for insert-only workloads but that doesn&#x27;t cover all our needs.</div><br/><div id="40007127" class="c"><input type="checkbox" id="c-40007127" checked=""/><div class="controls bullet"><span class="by">darthShadow</span><span>|</span><a href="#40005842">root</a><span>|</span><a href="#40006107">parent</a><span>|</span><a href="#40006561">next</a><span>|</span><label class="collapse" for="c-40007127">[-]</label><label class="expand" for="c-40007127">[1 more]</label></div><br/><div class="children"><div class="content">You have already gotten excellent options from the other comments, but here&#x27;s another one that&#x27;s not been mentioned yet.<p>You may want to consider adjusting your partition key (if feasible) as a function of datetime so you can just drop a complete partition when required, rather than needing separate delete queries.<p>In my experience, it has proven to be a very quick and clean way to clear out older data.</div><br/></div></div><div id="40006561" class="c"><input type="checkbox" id="c-40006561" checked=""/><div class="controls bullet"><span class="by">nsguy</span><span>|</span><a href="#40005842">root</a><span>|</span><a href="#40006107">parent</a><span>|</span><a href="#40007127">prev</a><span>|</span><a href="#40006178">next</a><span>|</span><label class="collapse" for="c-40006561">[-]</label><label class="expand" for="c-40006561">[2 more]</label></div><br/><div class="children"><div class="content">You can always use different databases for different use cases.<p>There are many applications that require extremely high insertion rates (millions of records per second), very large total number of rows (billions, trillions) and flexible&#x2F;fast querying&#x2F;aggregation with high read rates (100&#x27;s of millions or higher rows&#x2F;s) and that&#x27;s sort of the sweet spot IMO for ClickHouse and where you&#x27;ll be pressed to find alternatives. I&#x27;m sure it can be used in other situations but maybe there are more choices if you&#x27;re in those.</div><br/><div id="40007860" class="c"><input type="checkbox" id="c-40007860" checked=""/><div class="controls bullet"><span class="by">bigger_cheese</span><span>|</span><a href="#40005842">root</a><span>|</span><a href="#40006561">parent</a><span>|</span><a href="#40006178">next</a><span>|</span><label class="collapse" for="c-40007860">[-]</label><label class="expand" for="c-40007860">[1 more]</label></div><br/><div class="children"><div class="content">&gt;You can always use different databases for different use cases.<p>Unfortunately this is not always realistic, especially in large organizations, I know where I am there is a big push from top (i.e the IT budget people) to standardize everything they want to simplify licenses, support contracts etc.<p>I may not be doing cutting edge stuff (I work at an Industrial plant) but we do have mixed data use cases where it <i>could</i> be beneficial to use different dbs but realistically I don&#x27;t see it happening.</div><br/></div></div></div></div><div id="40006178" class="c"><input type="checkbox" id="c-40006178" checked=""/><div class="controls bullet"><span class="by">mosen</span><span>|</span><a href="#40005842">root</a><span>|</span><a href="#40006107">parent</a><span>|</span><a href="#40006561">prev</a><span>|</span><a href="#40006280">next</a><span>|</span><label class="collapse" for="c-40006178">[-]</label><label class="expand" for="c-40006178">[1 more]</label></div><br/><div class="children"><div class="content">Have you looked into the ReplacingMergeTree table engine? (Although we still needed to use FINAL with this one)</div><br/></div></div><div id="40006280" class="c"><input type="checkbox" id="c-40006280" checked=""/><div class="controls bullet"><span class="by">hipadev23</span><span>|</span><a href="#40005842">root</a><span>|</span><a href="#40006107">parent</a><span>|</span><a href="#40006178">prev</a><span>|</span><a href="#40007751">next</a><span>|</span><label class="collapse" for="c-40006280">[-]</label><label class="expand" for="c-40006280">[1 more]</label></div><br/><div class="children"><div class="content">CH works just fine for cleaning up rows: Delete with mutations sync=1, or use optimize with deduplicate by, or use aggregate trees and optimize final, or query aggregate tables with final=1.<p>Numerous ways to achieve removal of old&#x2F;stale rows.</div><br/></div></div><div id="40007751" class="c"><input type="checkbox" id="c-40007751" checked=""/><div class="controls bullet"><span class="by">myrloc</span><span>|</span><a href="#40005842">root</a><span>|</span><a href="#40006107">parent</a><span>|</span><a href="#40006280">prev</a><span>|</span><a href="#40007398">next</a><span>|</span><label class="collapse" for="c-40007751">[-]</label><label class="expand" for="c-40007751">[1 more]</label></div><br/><div class="children"><div class="content">Sounds like you need to use a ReplacingMergeTree + final keyword.</div><br/></div></div><div id="40007398" class="c"><input type="checkbox" id="c-40007398" checked=""/><div class="controls bullet"><span class="by">unixhero</span><span>|</span><a href="#40005842">root</a><span>|</span><a href="#40006107">parent</a><span>|</span><a href="#40007751">prev</a><span>|</span><a href="#40006131">next</a><span>|</span><label class="collapse" for="c-40007398">[-]</label><label class="expand" for="c-40007398">[1 more]</label></div><br/><div class="children"><div class="content">Tableau</div><br/></div></div></div></div></div></div><div id="40006131" class="c"><input type="checkbox" id="c-40006131" checked=""/><div class="controls bullet"><span class="by">ergonaught</span><span>|</span><a href="#40005842">parent</a><span>|</span><a href="#40005983">prev</a><span>|</span><a href="#40007533">next</a><span>|</span><label class="collapse" for="c-40006131">[-]</label><label class="expand" for="c-40006131">[1 more]</label></div><br/><div class="children"><div class="content">Most, though certainly not all, problems I see with ClickHouse usage come from pretending it is another database or that it is intended for other use cases.</div><br/></div></div><div id="40007533" class="c"><input type="checkbox" id="c-40007533" checked=""/><div class="controls bullet"><span class="by">citrin_ru</span><span>|</span><a href="#40005842">parent</a><span>|</span><a href="#40006131">prev</a><span>|</span><a href="#40008309">next</a><span>|</span><label class="collapse" for="c-40007533">[-]</label><label class="expand" for="c-40007533">[1 more]</label></div><br/><div class="children"><div class="content">&gt; * Timeouts (only 30s???) unless I used the cli client<p>Almost all clients (client libraries) allow a configurable timeout. In server settings there is a max query time settings which can be adjusted if necessary: <a href="https:&#x2F;&#x2F;clickhouse.com&#x2F;docs&#x2F;en&#x2F;operations&#x2F;settings&#x2F;query-complexity#max-execution-time" rel="nofollow">https:&#x2F;&#x2F;clickhouse.com&#x2F;docs&#x2F;en&#x2F;operations&#x2F;settings&#x2F;query-com...</a></div><br/></div></div><div id="40008309" class="c"><input type="checkbox" id="c-40008309" checked=""/><div class="controls bullet"><span class="by">orf</span><span>|</span><a href="#40005842">parent</a><span>|</span><a href="#40007533">prev</a><span>|</span><a href="#40006130">next</a><span>|</span><label class="collapse" for="c-40008309">[-]</label><label class="expand" for="c-40008309">[2 more]</label></div><br/><div class="children"><div class="content">From the docs on FINAL:<p>&gt; However, using FINAL is sometimes necessary in order to produce accurate results<p>Welp.</div><br/><div id="40008747" class="c"><input type="checkbox" id="c-40008747" checked=""/><div class="controls bullet"><span class="by">FridgeSeal</span><span>|</span><a href="#40005842">root</a><span>|</span><a href="#40008309">parent</a><span>|</span><a href="#40006130">next</a><span>|</span><label class="collapse" for="c-40008747">[-]</label><label class="expand" for="c-40008747">[1 more]</label></div><br/><div class="children"><div class="content">If you use tables like “ReplacingMergeTree” which _explicitly_ states that merges happen in the background, and non-merged rows _will_ be visible.<p>It’s a table design optimised for specific workloads, and the docs and design detail those tradeoffs.<p>We use it at work for workloads that can tolerate “retreading” over stale data, because it means they can efficiently write to the db without round tripping, or locking and row updates, and without the table growing massive. It works fantastically in our use case.</div><br/></div></div></div></div><div id="40006130" class="c"><input type="checkbox" id="c-40006130" checked=""/><div class="controls bullet"><span class="by">zX41ZdbW</span><span>|</span><a href="#40005842">parent</a><span>|</span><a href="#40008309">prev</a><span>|</span><a href="#40006078">next</a><span>|</span><label class="collapse" for="c-40006130">[-]</label><label class="expand" for="c-40006130">[3 more]</label></div><br/><div class="children"><div class="content">Interesting about &quot;Timeouts (only 30s???)&quot; - most likely, this is a limitation configured explicitly for a user on your server. You can set it up with the `max_execution_time`, and by default, it is unlimited.<p>For example, I&#x27;ve set it up, along with many more limitations for my public playground <a href="https:&#x2F;&#x2F;play.clickhouse.com&#x2F;" rel="nofollow">https:&#x2F;&#x2F;play.clickhouse.com&#x2F;</a>, and it allows me to, at least, make it public and not worry much.<p>It could also be a configuration of a proxy if you connect through a proxy. ClickHouse has built-in HTTP API, so you can query it directly from the browser or put it behind Cloudflare, etc... Where do you host ClickHouse?</div><br/><div id="40006204" class="c"><input type="checkbox" id="c-40006204" checked=""/><div class="controls bullet"><span class="by">joshstrange</span><span>|</span><a href="#40005842">root</a><span>|</span><a href="#40006130">parent</a><span>|</span><a href="#40006078">next</a><span>|</span><label class="collapse" for="c-40006204">[-]</label><label class="expand" for="c-40006204">[2 more]</label></div><br/><div class="children"><div class="content">I can believe it&#x27;s a config issue, I&#x27;ll have to look into it. I didn&#x27;t setup the cluster&#x2F;dbs and when I asked about I was told &quot;use the cli&quot;. I&#x27;ll try to see if I can get that fixed.</div><br/><div id="40008947" class="c"><input type="checkbox" id="c-40008947" checked=""/><div class="controls bullet"><span class="by">michaelbuckbee</span><span>|</span><a href="#40005842">root</a><span>|</span><a href="#40006204">parent</a><span>|</span><a href="#40006078">next</a><span>|</span><label class="collapse" for="c-40008947">[-]</label><label class="expand" for="c-40008947">[1 more]</label></div><br/><div class="children"><div class="content">Any chance you CH is proxied through a Heroku app? Heroku has 30s timeouts.</div><br/></div></div></div></div></div></div><div id="40006078" class="c"><input type="checkbox" id="c-40006078" checked=""/><div class="controls bullet"><span class="by">shin_lao</span><span>|</span><a href="#40005842">parent</a><span>|</span><a href="#40006130">prev</a><span>|</span><a href="#40006394">next</a><span>|</span><label class="collapse" for="c-40006078">[-]</label><label class="expand" for="c-40006078">[10 more]</label></div><br/><div class="children"><div class="content">It&#x27;s meant to store immutable data, and isn&#x27;t great if you need low-latency updates. Also it&#x27;s quirky in some ways.</div><br/><div id="40006126" class="c"><input type="checkbox" id="c-40006126" checked=""/><div class="controls bullet"><span class="by">joshstrange</span><span>|</span><a href="#40005842">root</a><span>|</span><a href="#40006078">parent</a><span>|</span><a href="#40006394">next</a><span>|</span><label class="collapse" for="c-40006126">[-]</label><label class="expand" for="c-40006126">[9 more]</label></div><br/><div class="children"><div class="content">&gt; It&#x27;s meant to store immutable data<p>I don&#x27;t disagree, I feel like we might be using it wrong. We were trying to replace ES with it but it just doesn&#x27;t feel like it fits our needed usecase.</div><br/><div id="40006192" class="c"><input type="checkbox" id="c-40006192" checked=""/><div class="controls bullet"><span class="by">shin_lao</span><span>|</span><a href="#40005842">root</a><span>|</span><a href="#40006126">parent</a><span>|</span><a href="#40006394">next</a><span>|</span><label class="collapse" for="c-40006192">[-]</label><label class="expand" for="c-40006192">[8 more]</label></div><br/><div class="children"><div class="content">How many rows do you have on average per day?</div><br/><div id="40006326" class="c"><input type="checkbox" id="c-40006326" checked=""/><div class="controls bullet"><span class="by">joshstrange</span><span>|</span><a href="#40005842">root</a><span>|</span><a href="#40006192">parent</a><span>|</span><a href="#40006394">next</a><span>|</span><label class="collapse" for="c-40006326">[-]</label><label class="expand" for="c-40006326">[7 more]</label></div><br/><div class="children"><div class="content">A couple million (&lt;10M), I don&#x27;t have a better number available right now. Not all (or even most) of those need cancelling rows thankfully.</div><br/><div id="40006393" class="c"><input type="checkbox" id="c-40006393" checked=""/><div class="controls bullet"><span class="by">hipadev23</span><span>|</span><a href="#40005842">root</a><span>|</span><a href="#40006326">parent</a><span>|</span><a href="#40006394">next</a><span>|</span><label class="collapse" for="c-40006393">[-]</label><label class="expand" for="c-40006393">[6 more]</label></div><br/><div class="children"><div class="content">You don’t need a cluster nor should you be having any issues you mentioned. I run 10x that volume daily on a single gcp box (8 core &#x2F; 64GB). We migrated off BigQuery and went from $10k&#x2F;mo to about $250&#x2F;mo. And it’s faster for both low-latency and big slow queries.</div><br/><div id="40006537" class="c"><input type="checkbox" id="c-40006537" checked=""/><div class="controls bullet"><span class="by">joshstrange</span><span>|</span><a href="#40005842">root</a><span>|</span><a href="#40006393">parent</a><span>|</span><a href="#40006394">next</a><span>|</span><label class="collapse" for="c-40006537">[-]</label><label class="expand" for="c-40006537">[5 more]</label></div><br/><div class="children"><div class="content">The plan is to 10x that volume in the not too distant future but given what you&#x27;ve said I can believe we are horribly over-provisioned&#x2F;over-scaled. Thank you!</div><br/><div id="40006599" class="c"><input type="checkbox" id="c-40006599" checked=""/><div class="controls bullet"><span class="by">hipadev23</span><span>|</span><a href="#40005842">root</a><span>|</span><a href="#40006537">parent</a><span>|</span><a href="#40006394">next</a><span>|</span><label class="collapse" for="c-40006599">[-]</label><label class="expand" for="c-40006599">[4 more]</label></div><br/><div class="children"><div class="content">It sounds like you’re probably using Clickhouse Cloud? If so, I was not impressed. Overly pushy sales people, pricing isn’t competitive, and they’re trying to cater to the snowflake&#x2F;databricks crowd without smoothing any rough edges (like the default timeout being enabled on a GUI).<p>Overall I’d say CH isn’t as tolerant or forgiving as BigQuery, Snowflake, or Databricks. You can write the worst SQL possible and BQ will happily charge you $5&#x2F;TB for that cartesian self-join. CH meanwhile will error with memory limit or even crash.</div><br/><div id="40006631" class="c"><input type="checkbox" id="c-40006631" checked=""/><div class="controls bullet"><span class="by">joshstrange</span><span>|</span><a href="#40005842">root</a><span>|</span><a href="#40006599">parent</a><span>|</span><a href="#40006394">next</a><span>|</span><label class="collapse" for="c-40006631">[-]</label><label class="expand" for="c-40006631">[3 more]</label></div><br/><div class="children"><div class="content">We are using Altinity. I believe it&#x27;s a 3-server cluster and we have 2 clusters (our prod one and another one we are trying to promote to production once our data integrity checks pass, at which point we will spin the other down).</div><br/><div id="40010166" class="c"><input type="checkbox" id="c-40010166" checked=""/><div class="controls bullet"><span class="by">hodgesrm</span><span>|</span><a href="#40005842">root</a><span>|</span><a href="#40006631">parent</a><span>|</span><a href="#40006685">next</a><span>|</span><label class="collapse" for="c-40010166">[-]</label><label class="expand" for="c-40010166">[1 more]</label></div><br/><div class="children"><div class="content">Hi Josh, sorry to hear about the issues. Sounds like things that should be solvable. ClickHouse does require thinking a bit differently from other stores like BigQuery. I sent you an email. Feel free to contact me at the email posted on my HN account. Looking forward to helping you bend ClickHouse to your will.</div><br/></div></div><div id="40006685" class="c"><input type="checkbox" id="c-40006685" checked=""/><div class="controls bullet"><span class="by">hipadev23</span><span>|</span><a href="#40005842">root</a><span>|</span><a href="#40006631">parent</a><span>|</span><a href="#40010166">prev</a><span>|</span><a href="#40006394">next</a><span>|</span><label class="collapse" for="c-40006685">[-]</label><label class="expand" for="c-40006685">[1 more]</label></div><br/><div class="children"><div class="content">Robert Hodges of Altinity will likely be here shortly, they monitor HN for any mention of clickhouse, maybe they can get you fixed up without their standard $10k&#x2F;mo support contract.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="40006394" class="c"><input type="checkbox" id="c-40006394" checked=""/><div class="controls bullet"><span class="by">alecfong</span><span>|</span><a href="#40005842">parent</a><span>|</span><a href="#40006078">prev</a><span>|</span><a href="#40009697">next</a><span>|</span><label class="collapse" for="c-40006394">[-]</label><label class="expand" for="c-40006394">[2 more]</label></div><br/><div class="children"><div class="content">What foot guns have you run into with FINAL?</div><br/><div id="40006529" class="c"><input type="checkbox" id="c-40006529" checked=""/><div class="controls bullet"><span class="by">joshstrange</span><span>|</span><a href="#40005842">root</a><span>|</span><a href="#40006394">parent</a><span>|</span><a href="#40009697">next</a><span>|</span><label class="collapse" for="c-40006529">[-]</label><label class="expand" for="c-40006529">[1 more]</label></div><br/><div class="children"><div class="content">Just forgetting to use it or PREWHERE. Since queries run just fine without those you can think you have something working when you actually have duplicate rules.</div><br/></div></div></div></div></div></div><div id="40009697" class="c"><input type="checkbox" id="c-40009697" checked=""/><div class="controls bullet"><span class="by">alooPotato</span><span>|</span><a href="#40005842">prev</a><span>|</span><a href="#40009933">next</a><span>|</span><label class="collapse" for="c-40009697">[-]</label><label class="expand" for="c-40009697">[8 more]</label></div><br/><div class="children"><div class="content">We use BigQuery a lot for internal analytics and we&#x27;ve been super happy. I don&#x27;t see a lot of love for BigQuery on HN and I wonder why. Tons of features, no hassle and easy to throw a bunch of TB at it.<p>I guess maybe the cost?</div><br/><div id="40009926" class="c"><input type="checkbox" id="c-40009926" checked=""/><div class="controls bullet"><span class="by">mnahkies</span><span>|</span><a href="#40009697">parent</a><span>|</span><a href="#40009732">next</a><span>|</span><label class="collapse" for="c-40009926">[-]</label><label class="expand" for="c-40009926">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m a big fan of big query as well, but the cost can be problematic if you&#x27;re not careful.<p>Generally speaking I&#x27;ve found it manageable if you make good use of partitioning and do incremental aggregation (we use dbt, though you have to do some macro gymnastics to make the partition key filter eligible for pruning due to restrictions on use of dynamic values <a href="https:&#x2F;&#x2F;docs.getdbt.com&#x2F;docs&#x2F;build&#x2F;incremental-models" rel="nofollow">https:&#x2F;&#x2F;docs.getdbt.com&#x2F;docs&#x2F;build&#x2F;incremental-models</a>)<p>It&#x27;s also important to monitor your cost and watch for the point where switching from the per-tb queried pricing model to slots makes sense.</div><br/><div id="40010018" class="c"><input type="checkbox" id="c-40010018" checked=""/><div class="controls bullet"><span class="by">alooPotato</span><span>|</span><a href="#40009697">root</a><span>|</span><a href="#40009926">parent</a><span>|</span><a href="#40009732">next</a><span>|</span><label class="collapse" for="c-40010018">[-]</label><label class="expand" for="c-40010018">[1 more]</label></div><br/><div class="children"><div class="content">yeah between partitioning, clustering, materialized views, and smart tuning it seems like there are enough knobs to control costs.</div><br/></div></div></div></div><div id="40009732" class="c"><input type="checkbox" id="c-40009732" checked=""/><div class="controls bullet"><span class="by">RadiozRadioz</span><span>|</span><a href="#40009697">parent</a><span>|</span><a href="#40009926">prev</a><span>|</span><a href="#40009952">next</a><span>|</span><label class="collapse" for="c-40009732">[-]</label><label class="expand" for="c-40009732">[3 more]</label></div><br/><div class="children"><div class="content">Probably also because it is proprietary and only exists in one cloud platform.</div><br/><div id="40009804" class="c"><input type="checkbox" id="c-40009804" checked=""/><div class="controls bullet"><span class="by">wodenokoto</span><span>|</span><a href="#40009697">root</a><span>|</span><a href="#40009732">parent</a><span>|</span><a href="#40009952">next</a><span>|</span><label class="collapse" for="c-40009804">[-]</label><label class="expand" for="c-40009804">[2 more]</label></div><br/><div class="children"><div class="content">No, it’s because it’s google and HN are certain it will get cancelled at any moment.</div><br/><div id="40010012" class="c"><input type="checkbox" id="c-40010012" checked=""/><div class="controls bullet"><span class="by">alooPotato</span><span>|</span><a href="#40009697">root</a><span>|</span><a href="#40009804">parent</a><span>|</span><a href="#40009952">next</a><span>|</span><label class="collapse" for="c-40010012">[-]</label><label class="expand" for="c-40010012">[1 more]</label></div><br/><div class="children"><div class="content">seems unlikely, I think its the most popular google cloud product</div><br/></div></div></div></div></div></div><div id="40009952" class="c"><input type="checkbox" id="c-40009952" checked=""/><div class="controls bullet"><span class="by">doo_daa</span><span>|</span><a href="#40009697">parent</a><span>|</span><a href="#40009732">prev</a><span>|</span><a href="#40009819">next</a><span>|</span><label class="collapse" for="c-40009952">[-]</label><label class="expand" for="c-40009952">[1 more]</label></div><br/><div class="children"><div class="content">We are lucky enough to be able to run BigQuery with flat rate billing.
It&#x27;s incredibly powerful and it&#x27;s a really good example of SaaS and Serverless done right. It just works.</div><br/></div></div><div id="40009819" class="c"><input type="checkbox" id="c-40009819" checked=""/><div class="controls bullet"><span class="by">wodenokoto</span><span>|</span><a href="#40009697">parent</a><span>|</span><a href="#40009952">prev</a><span>|</span><a href="#40009933">next</a><span>|</span><label class="collapse" for="c-40009819">[-]</label><label class="expand" for="c-40009819">[1 more]</label></div><br/><div class="children"><div class="content">I was quite surprised that other clouds don’t have an easy to get started analytics data warehouse solution like big query.</div><br/></div></div></div></div><div id="40009933" class="c"><input type="checkbox" id="c-40009933" checked=""/><div class="controls bullet"><span class="by">breadchris</span><span>|</span><a href="#40009697">prev</a><span>|</span><a href="#40006648">next</a><span>|</span><label class="collapse" for="c-40009933">[-]</label><label class="expand" for="c-40009933">[2 more]</label></div><br/><div class="children"><div class="content">ClickHouse is awesome, but as the post shows, some code is involved in getting the data there.<p>I have been working on Scratchdata [1], which makes it easy to try out a column database to optimize aggregation queries (avg, sum, max). We have helped people [2] take their Postgres with 1 billion rows of information (1.5 TB) and significantly reduce their real-time data analysis query time. Because their data was stored more efficiently, they saved on their storage bill.<p>You can send data as a curl request and it will get batch-processed and flattened into ClickHouse:<p>curl -X POST &quot;<a href="http:&#x2F;&#x2F;app.scratchdata.com&#x2F;api&#x2F;data&#x2F;insert&#x2F;your_table?api_key=xxx">http:&#x2F;&#x2F;app.scratchdata.com&#x2F;api&#x2F;data&#x2F;insert&#x2F;your_table?api_ke...</a>&quot; --data &#x27;{&quot;user&quot;: &quot;alice&quot;, &quot;event&quot;: &quot;click&quot;}&#x27;<p>The founder, Jay, is super nice and just wants to help people save time and money. If you give us a ring, he or I will personally help you [3].<p>[1] <a href="https:&#x2F;&#x2F;www.scratchdb.com&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.scratchdb.com&#x2F;</a>
[2] <a href="https:&#x2F;&#x2F;www.scratchdb.com&#x2F;blog&#x2F;embeddables&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.scratchdb.com&#x2F;blog&#x2F;embeddables&#x2F;</a>
[3] <a href="https:&#x2F;&#x2F;q29ksuefpvm.typeform.com&#x2F;to&#x2F;baKR3j0p?typeform-source=www.scratchdb.com#source=hero" rel="nofollow">https:&#x2F;&#x2F;q29ksuefpvm.typeform.com&#x2F;to&#x2F;baKR3j0p?typeform-source...</a></div><br/><div id="40010418" class="c"><input type="checkbox" id="c-40010418" checked=""/><div class="controls bullet"><span class="by">wiredfool</span><span>|</span><a href="#40009933">parent</a><span>|</span><a href="#40006648">next</a><span>|</span><label class="collapse" for="c-40010418">[-]</label><label class="expand" for="c-40010418">[1 more]</label></div><br/><div class="children"><div class="content">My first big win for clickhouse was replacing a 1.2tb, billion + row postgresql DB with clickhouse. It was static data with occasional full replacement loads. We got the DB down to ~ 60GB, with query speeds about 45x faster.<p>Now, the postgres schema wasn&#x27;t ideal, and we could have saved ~ 3x on it with corresponding speed increases for queries with a refactor similar to the clickhouse schema, but that wasn&#x27;t really enough to move the needle to near real-time queries.<p>Ultimately, the entire clickhouse DB was smaller than the original postgres primary key index. The index was too big to fit in memory on an affordable machine, so it&#x27;s pretty obvious where the performance is coming from.</div><br/></div></div></div></div><div id="40006648" class="c"><input type="checkbox" id="c-40006648" checked=""/><div class="controls bullet"><span class="by">HermitX</span><span>|</span><a href="#40009933">prev</a><span>|</span><a href="#40007198">next</a><span>|</span><label class="collapse" for="c-40006648">[-]</label><label class="expand" for="c-40006648">[2 more]</label></div><br/><div class="children"><div class="content">Is ClickHouse a suitable engine for analyzing events? Absolutely, as long as you&#x27;re analyzing a large table, its speed is definitely fast enough. However, you might want to consider the cost of maintaining an OSS ClickHouse cluster, especially when you need to scale up, as the operational costs can be quite high.<p>If your analysis in Postgres was based on multiple tables and required a lot of JOIN operations, I don&#x27;t think ClickHouse is a good choice. In such cases, you often need to denormalize multiple data tables into one large table in advance, which means complex ETL and maintenance costs.<p>For these more common scenarios, I think StarRocks (www.StarRocks.io) is a better choice. It&#x27;s a Linux Foundation open-source project, with single-table query speeds comparable to ClickHouse (you can check Clickbench), and unmatched multi-table join query speeds, plus it can directly query open data lakes.</div><br/><div id="40007028" class="c"><input type="checkbox" id="c-40007028" checked=""/><div class="controls bullet"><span class="by">jakearmitage</span><span>|</span><a href="#40006648">parent</a><span>|</span><a href="#40007198">next</a><span>|</span><label class="collapse" for="c-40007028">[-]</label><label class="expand" for="c-40007028">[1 more]</label></div><br/><div class="children"><div class="content">&gt; consider the cost of maintaining an OSS ClickHouse cluster
I mean... it is pretty straightforward. 40~60 line Terraform, Ansible with templates for the proper configs that get exported from Terraform so you can write the IPs so they can see each other, and you are done.<p>What else could you possibly need? Backing up is built into it with S3 support: <a href="https:&#x2F;&#x2F;clickhouse.com&#x2F;docs&#x2F;en&#x2F;operations&#x2F;backup#configuring-backuprestore-to-use-an-s3-endpoint" rel="nofollow">https:&#x2F;&#x2F;clickhouse.com&#x2F;docs&#x2F;en&#x2F;operations&#x2F;backup#configuring...</a><p>Upgrades are a breeze: <a href="https:&#x2F;&#x2F;clickhouse.com&#x2F;docs&#x2F;en&#x2F;operations&#x2F;update" rel="nofollow">https:&#x2F;&#x2F;clickhouse.com&#x2F;docs&#x2F;en&#x2F;operations&#x2F;update</a><p>People insist that OMG MAINTENANCE I NEED TO PAY THOUSANDS FOR MANAGED is better, when in reality, it is not.</div><br/></div></div></div></div><div id="40007198" class="c"><input type="checkbox" id="c-40007198" checked=""/><div class="controls bullet"><span class="by">drewda</span><span>|</span><a href="#40006648">prev</a><span>|</span><a href="#40007379">next</a><span>|</span><label class="collapse" for="c-40007198">[-]</label><label class="expand" for="c-40007198">[2 more]</label></div><br/><div class="children"><div class="content">This change may make sense for Lago as a hosted multi-tenant service, as offered by Lago the company.<p>Simultaneously this change may <i>not</i> make sense for Lago as an open-source project self-hosted by a single tenant.<p>But that may also mean that it effectively makes sense for Lago as a business... to make it harder to self host.<p>I don&#x27;t at all fault Lago for making decisions to prioritize their multi-tenant cloud offering. That&#x27;s probably just the nature of running open-source SaaS these days.</div><br/><div id="40010478" class="c"><input type="checkbox" id="c-40010478" checked=""/><div class="controls bullet"><span class="by">config_yml</span><span>|</span><a href="#40007198">parent</a><span>|</span><a href="#40007379">next</a><span>|</span><label class="collapse" for="c-40010478">[-]</label><label class="expand" for="c-40010478">[1 more]</label></div><br/><div class="children"><div class="content">Exactly, I&#x27;ve seen this at Sentry where you now have to run Kafka, Clickhouse, Redis, PG, Zookeeper, memcached and what have you. I get it, but the amount of baggage to handle is a bit difficult.</div><br/></div></div></div></div><div id="40007379" class="c"><input type="checkbox" id="c-40007379" checked=""/><div class="controls bullet"><span class="by">stephen123</span><span>|</span><a href="#40007198">prev</a><span>|</span><a href="#40005455">next</a><span>|</span><label class="collapse" for="c-40007379">[-]</label><label class="expand" for="c-40007379">[11 more]</label></div><br/><div class="children"><div class="content">How were they doing millions of events per minute with postgres.<p>I&#x27;m struggling with pg write performance ATM and want some tips.</div><br/><div id="40009619" class="c"><input type="checkbox" id="c-40009619" checked=""/><div class="controls bullet"><span class="by">Ozzie_osman</span><span>|</span><a href="#40007379">parent</a><span>|</span><a href="#40007386">next</a><span>|</span><label class="collapse" for="c-40009619">[-]</label><label class="expand" for="c-40009619">[1 more]</label></div><br/><div class="children"><div class="content">If you&#x27;re not already doing this: remove unnecessary indices, partition the table, batch your inserts&#x2F;updates, or try COPY instead of INSERT.</div><br/></div></div><div id="40007386" class="c"><input type="checkbox" id="c-40007386" checked=""/><div class="controls bullet"><span class="by">unixhero</span><span>|</span><a href="#40007379">parent</a><span>|</span><a href="#40009619">prev</a><span>|</span><a href="#40008975">next</a><span>|</span><label class="collapse" for="c-40007386">[-]</label><label class="expand" for="c-40007386">[7 more]</label></div><br/><div class="children"><div class="content">Turn off indexing and other optimizations done on a table level</div><br/><div id="40008110" class="c"><input type="checkbox" id="c-40008110" checked=""/><div class="controls bullet"><span class="by">stephen123</span><span>|</span><a href="#40007379">root</a><span>|</span><a href="#40007386">parent</a><span>|</span><a href="#40008975">next</a><span>|</span><label class="collapse" for="c-40008110">[-]</label><label class="expand" for="c-40008110">[6 more]</label></div><br/><div class="children"><div class="content">What do you do to then query the data?
I usually need indexes so queries are not slow.
Perhaps I could insert into a staging table then bulk copy the data over to an indexed table, but that seems silly.</div><br/><div id="40009524" class="c"><input type="checkbox" id="c-40009524" checked=""/><div class="controls bullet"><span class="by">ndriscoll</span><span>|</span><a href="#40007379">root</a><span>|</span><a href="#40008110">parent</a><span>|</span><a href="#40008360">next</a><span>|</span><label class="collapse" for="c-40009524">[-]</label><label class="expand" for="c-40009524">[1 more]</label></div><br/><div class="children"><div class="content">If your application language&#x2F;framework allows, you can do the batching there. e.g. have your single request handler put work into an (in-memory) queue. Then another thread&#x2F;async worker pull batches off the queue and do your db work in batch, and trigger the response to the original handler. In an http context, this is all synchronous from the client perspective, and you can get 2-10x throughput at a cost of like 2 ms latency under load.<p>I gave more detail with a toy example here: 
<a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=39245416">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=39245416</a><p>I&#x27;ve since played around with this a little more and you can do it pretty generically (at least make the worker generic where you give it a function `Chunk[A] =&gt; Task[Chunk[Result[B]]]` to do the database logic). I don&#x27;t have that handy to post right now, but probably you&#x27;re not using Scala anyway so the details aren&#x27;t that relevant.<p>I&#x27;ve tried out a similar thing in Rust and it&#x27;s a lot more finicky but still doable there. Should be similar in go I&#x27;d think.</div><br/></div></div><div id="40008360" class="c"><input type="checkbox" id="c-40008360" checked=""/><div class="controls bullet"><span class="by">lmz</span><span>|</span><a href="#40007379">root</a><span>|</span><a href="#40008110">parent</a><span>|</span><a href="#40009524">prev</a><span>|</span><a href="#40008299">next</a><span>|</span><label class="collapse" for="c-40008360">[-]</label><label class="expand" for="c-40008360">[1 more]</label></div><br/><div class="children"><div class="content">Isn&#x27;t that basically the idea behind the &quot;lambda architecture&quot;? Of course you typically don&#x27;t use the same product for both the real time and the batch aspects.</div><br/></div></div><div id="40008299" class="c"><input type="checkbox" id="c-40008299" checked=""/><div class="controls bullet"><span class="by">unixhero</span><span>|</span><a href="#40007379">root</a><span>|</span><a href="#40008110">parent</a><span>|</span><a href="#40008360">prev</a><span>|</span><a href="#40008213">next</a><span>|</span><label class="collapse" for="c-40008299">[-]</label><label class="expand" for="c-40008299">[1 more]</label></div><br/><div class="children"><div class="content">You said you struggled with writes... so I mentioned an advice on how to speed up writes... the internet know a lot more about this than me tho</div><br/></div></div><div id="40008213" class="c"><input type="checkbox" id="c-40008213" checked=""/><div class="controls bullet"><span class="by">phantompeace</span><span>|</span><a href="#40007379">root</a><span>|</span><a href="#40008110">parent</a><span>|</span><a href="#40008299">prev</a><span>|</span><a href="#40008975">next</a><span>|</span><label class="collapse" for="c-40008213">[-]</label><label class="expand" for="c-40008213">[2 more]</label></div><br/><div class="children"><div class="content">Could replicating to a DB with indexing (purely for queries) work?</div><br/><div id="40008609" class="c"><input type="checkbox" id="c-40008609" checked=""/><div class="controls bullet"><span class="by">remram</span><span>|</span><a href="#40007379">root</a><span>|</span><a href="#40008213">parent</a><span>|</span><a href="#40008975">next</a><span>|</span><label class="collapse" for="c-40008609">[-]</label><label class="expand" for="c-40008609">[1 more]</label></div><br/><div class="children"><div class="content">If one can&#x27;t keep up, the other one can&#x27;t either.<p>You could use partitions though.</div><br/></div></div></div></div></div></div></div></div><div id="40008975" class="c"><input type="checkbox" id="c-40008975" checked=""/><div class="controls bullet"><span class="by">whalesalad</span><span>|</span><a href="#40007379">parent</a><span>|</span><a href="#40007386">prev</a><span>|</span><a href="#40005455">next</a><span>|</span><label class="collapse" for="c-40008975">[-]</label><label class="expand" for="c-40008975">[2 more]</label></div><br/><div class="children"><div class="content">What’s your hardware? RDS? Nvme storage?</div><br/><div id="40010516" class="c"><input type="checkbox" id="c-40010516" checked=""/><div class="controls bullet"><span class="by">stephen123</span><span>|</span><a href="#40007379">root</a><span>|</span><a href="#40008975">parent</a><span>|</span><a href="#40005455">next</a><span>|</span><label class="collapse" for="c-40010516">[-]</label><label class="expand" for="c-40010516">[1 more]</label></div><br/><div class="children"><div class="content">Its google cloud sql.</div><br/></div></div></div></div></div></div><div id="40005455" class="c"><input type="checkbox" id="c-40005455" checked=""/><div class="controls bullet"><span class="by">samber</span><span>|</span><a href="#40007379">prev</a><span>|</span><a href="#40008789">next</a><span>|</span><label class="collapse" for="c-40005455">[-]</label><label class="expand" for="c-40005455">[4 more]</label></div><br/><div class="children"><div class="content">I&#x27;m curious: how many rows Lago store in its CH cluster? Do they collect data for fighting fraud?<p>PG can handle a billion rows easily.</div><br/><div id="40006444" class="c"><input type="checkbox" id="c-40006444" checked=""/><div class="controls bullet"><span class="by">didip</span><span>|</span><a href="#40005455">parent</a><span>|</span><a href="#40005641">next</a><span>|</span><label class="collapse" for="c-40006444">[-]</label><label class="expand" for="c-40006444">[1 more]</label></div><br/><div class="children"><div class="content">OLAP databases need to be able to handle billions of rows per hour&#x2F;day.<p>I super love PG but PG is too far away from that.</div><br/></div></div><div id="40005641" class="c"><input type="checkbox" id="c-40005641" checked=""/><div class="controls bullet"><span class="by">JosephRedfern</span><span>|</span><a href="#40005455">parent</a><span>|</span><a href="#40006444">prev</a><span>|</span><a href="#40006151">next</a><span>|</span><label class="collapse" for="c-40005641">[-]</label><label class="expand" for="c-40005641">[1 more]</label></div><br/><div class="children"><div class="content">Reading between the lines, given they&#x27;re talking &gt; 1 million rows per minute, I&#x27;d guess on the order of trillions of rows rather than billions (assuming they retain data for more than a couple of weeks)</div><br/></div></div><div id="40006151" class="c"><input type="checkbox" id="c-40006151" checked=""/><div class="controls bullet"><span class="by">jacobsenscott</span><span>|</span><a href="#40005455">parent</a><span>|</span><a href="#40005641">prev</a><span>|</span><a href="#40008789">next</a><span>|</span><label class="collapse" for="c-40006151">[-]</label><label class="expand" for="c-40006151">[1 more]</label></div><br/><div class="children"><div class="content">PG can handle billions of rows for certain use cases, but not easily. Generally you can make things work but you definitely start entering &quot;heroic effort&quot; territory.</div><br/></div></div></div></div><div id="40008789" class="c"><input type="checkbox" id="c-40008789" checked=""/><div class="controls bullet"><span class="by">jackbauer24</span><span>|</span><a href="#40005455">prev</a><span>|</span><a href="#40005353">next</a><span>|</span><label class="collapse" for="c-40008789">[-]</label><label class="expand" for="c-40008789">[1 more]</label></div><br/><div class="children"><div class="content">scale is becoming more and more important, not just for cost, but also as a key technology feature to help deal with unexpected traffic and reduce the cost of manual operations.</div><br/></div></div><div id="40005353" class="c"><input type="checkbox" id="c-40005353" checked=""/><div class="controls bullet"><span class="by">mathnode</span><span>|</span><a href="#40008789">prev</a><span>|</span><a href="#40008137">next</a><span>|</span><label class="collapse" for="c-40005353">[-]</label><label class="expand" for="c-40005353">[14 more]</label></div><br/><div class="children"><div class="content">And if you use MariaDB, just enable columnstore. Why not treat yourself to s3 backed storage while you are there?<p>It is extremely cost effective when you can scale a different workload without migrating.</div><br/><div id="40005407" class="c"><input type="checkbox" id="c-40005407" checked=""/><div class="controls bullet"><span class="by">hipadev23</span><span>|</span><a href="#40005353">parent</a><span>|</span><a href="#40008137">next</a><span>|</span><label class="collapse" for="c-40005407">[-]</label><label class="expand" for="c-40005407">[13 more]</label></div><br/><div class="children"><div class="content">This is no shade to postgres or maria, but they don’t hold a candle to the simplicity, speed, and cost efficiency of clickhouse for olap needs.</div><br/><div id="40009597" class="c"><input type="checkbox" id="c-40009597" checked=""/><div class="controls bullet"><span class="by">philippemnoel</span><span>|</span><a href="#40005353">root</a><span>|</span><a href="#40005407">parent</a><span>|</span><a href="#40005436">next</a><span>|</span><label class="collapse" for="c-40009597">[-]</label><label class="expand" for="c-40009597">[2 more]</label></div><br/><div class="children"><div class="content">That&#x27;s true, but we&#x27;re trying to change that at ParadeDB. Postgres is still way ahead of ClickHouse in terms of operational simplicity, ease of hiring for DBAs who are used to operating it at scale, ecosystem tooling, etc. If you can patch the speed and cost efficiency of Postgres for analytics to a level comparable to ClickHouse, then you get the best of both worlds</div><br/><div id="40009651" class="c"><input type="checkbox" id="c-40009651" checked=""/><div class="controls bullet"><span class="by">pradeepchhetri</span><span>|</span><a href="#40005353">root</a><span>|</span><a href="#40009597">parent</a><span>|</span><a href="#40005436">next</a><span>|</span><label class="collapse" for="c-40009651">[-]</label><label class="expand" for="c-40009651">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Postgres is still way ahead of ClickHouse in terms of operational simplicity<p>Having served as both ClickHouse and Postgres SRE, I don&#x27;t agree with this statement.<p>- Minimal downtime major version upgrades in PostgreSQL is very challenging.<p>- glibc version upgrade breaks postgres indices. This basically prevents from upgrading linux OS.<p>And there are other things which makes postgres operationally difficult.<p>Any database with primary-replica architecture is operationally difficult IMO.</div><br/></div></div></div></div><div id="40005436" class="c"><input type="checkbox" id="c-40005436" checked=""/><div class="controls bullet"><span class="by">flessner</span><span>|</span><a href="#40005353">root</a><span>|</span><a href="#40005407">parent</a><span>|</span><a href="#40009597">prev</a><span>|</span><a href="#40006633">next</a><span>|</span><label class="collapse" for="c-40005436">[-]</label><label class="expand" for="c-40005436">[1 more]</label></div><br/><div class="children"><div class="content">And I mean why should they? They work great for what they are made for and that is all that matters!</div><br/></div></div><div id="40006633" class="c"><input type="checkbox" id="c-40006633" checked=""/><div class="controls bullet"><span class="by">silisili</span><span>|</span><a href="#40005353">root</a><span>|</span><a href="#40005407">parent</a><span>|</span><a href="#40005436">prev</a><span>|</span><a href="#40007247">next</a><span>|</span><label class="collapse" for="c-40006633">[-]</label><label class="expand" for="c-40006633">[1 more]</label></div><br/><div class="children"><div class="content">As a caveat, I&#x27;d probably say &#x27;at large volumes.&#x27;<p>For a lot of what people may want to do, they&#x27;d probably notice very little difference between the three.</div><br/></div></div><div id="40007247" class="c"><input type="checkbox" id="c-40007247" checked=""/><div class="controls bullet"><span class="by">mathnode</span><span>|</span><a href="#40005353">root</a><span>|</span><a href="#40005407">parent</a><span>|</span><a href="#40006633">prev</a><span>|</span><a href="#40005648">next</a><span>|</span><label class="collapse" for="c-40007247">[-]</label><label class="expand" for="c-40007247">[1 more]</label></div><br/><div class="children"><div class="content">For multi-tb or pb needs I would not stray from mariadb. Especially when using columnstore. I have taken the pepsi challenge, even after trying vertica and netezza. Not HANA though; one has had enough of SAP.</div><br/></div></div><div id="40005648" class="c"><input type="checkbox" id="c-40005648" checked=""/><div class="controls bullet"><span class="by">riku_iki</span><span>|</span><a href="#40005353">root</a><span>|</span><a href="#40005407">parent</a><span>|</span><a href="#40007247">prev</a><span>|</span><a href="#40008137">next</a><span>|</span><label class="collapse" for="c-40005648">[-]</label><label class="expand" for="c-40005648">[7 more]</label></div><br/><div class="children"><div class="content">I have tons of OOMs with clickhouse on larger than RAM OLAP queries.<p>While postgres works fine (even it is slower, but actually returns results)</div><br/><div id="40005829" class="c"><input type="checkbox" id="c-40005829" checked=""/><div class="controls bullet"><span class="by">nsguy</span><span>|</span><a href="#40005353">root</a><span>|</span><a href="#40005648">parent</a><span>|</span><a href="#40008137">next</a><span>|</span><label class="collapse" for="c-40005829">[-]</label><label class="expand" for="c-40005829">[6 more]</label></div><br/><div class="children"><div class="content">There are various knobs in ClickHouse that allow you to trade memory usage for performance. ( <a href="https:&#x2F;&#x2F;clickhouse.com&#x2F;docs&#x2F;en&#x2F;operations&#x2F;settings&#x2F;query-complexity#settings-max_bytes_before_external_group_by" rel="nofollow">https:&#x2F;&#x2F;clickhouse.com&#x2F;docs&#x2F;en&#x2F;operations&#x2F;settings&#x2F;query-com...</a> e.g.)<p>But yes, I&#x27;ve seen similar issues, running out of memory during query processing, it&#x27;s a price you pay for higher performance. You need to know what&#x27;s happening under the hood and do more work to make sure your queries will work well. I think postgres can be a thousand or more times slower, and doesn&#x27;t have the horizontal scalability, so if you need to do complex queries&#x2F;aggregations over billions of records then &quot;return result&quot; doesn&#x27;t cut it. If postgres addresses your needs then great- you don&#x27;t need to use ClickHouse...</div><br/><div id="40006092" class="c"><input type="checkbox" id="c-40006092" checked=""/><div class="controls bullet"><span class="by">riku_iki</span><span>|</span><a href="#40005353">root</a><span>|</span><a href="#40005829">parent</a><span>|</span><a href="#40008137">next</a><span>|</span><label class="collapse" for="c-40006092">[-]</label><label class="expand" for="c-40006092">[5 more]</label></div><br/><div class="children"><div class="content">&gt; There are various knobs in ClickHouse that allow you to trade memory usage for performance.<p>but what knobs to use and what values to use in each specific case? Query just usually fails with some generic OOM message without much information.</div><br/><div id="40007905" class="c"><input type="checkbox" id="c-40007905" checked=""/><div class="controls bullet"><span class="by">alright2565</span><span>|</span><a href="#40005353">root</a><span>|</span><a href="#40006092">parent</a><span>|</span><a href="#40008137">next</a><span>|</span><label class="collapse" for="c-40007905">[-]</label><label class="expand" for="c-40007905">[4 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not actually so esoteric. The two main knobs are<p>- max_concurrent_queries, since each query uses a certain amount of memory<p>- max_memory_usage, which is the max per-query memory usage<p>Here&#x27;s my full config for running clickhouse on a 2GiB server without OOMs. Some stuff in here is likely irrelevant, but it&#x27;s a starting point.<p><pre><code>    diff --git a&#x2F;clickhouse-config.xml b&#x2F;clickhouse-config.xml
    index f8213b65..7d7459cb 100644
    --- a&#x2F;clickhouse-config.xml
    +++ b&#x2F;clickhouse-config.xml
    @@ -197,7 +197,7 @@
     
         &lt;!-- &lt;listen_backlog&gt;4096&lt;&#x2F;listen_backlog&gt; --&gt;
     
    -    &lt;max_connections&gt;4096&lt;&#x2F;max_connections&gt;
    +    &lt;max_connections&gt;2000&lt;&#x2F;max_connections&gt;
     
         &lt;!-- For &#x27;Connection: keep-alive&#x27; in HTTP 1.1 --&gt;
         &lt;keep_alive_timeout&gt;3&lt;&#x2F;keep_alive_timeout&gt;
    @@ -270,7 +270,7 @@
         --&gt;
     
         &lt;!-- Maximum number of concurrent queries. --&gt;
    -    &lt;max_concurrent_queries&gt;100&lt;&#x2F;max_concurrent_queries&gt;
    +    &lt;max_concurrent_queries&gt;4&lt;&#x2F;max_concurrent_queries&gt;
     
         &lt;!-- Maximum memory usage (resident set size) for server process.
              Zero value or unset means default. Default is &quot;max_server_memory_usage_to_ram_ratio&quot; of available physical RAM.
    @@ -335,7 +335,7 @@
              In bytes. Cache is single for server. Memory is allocated only on demand.
              You should not lower this value.
           --&gt;
    -    &lt;mark_cache_size&gt;5368709120&lt;&#x2F;mark_cache_size&gt;
    +    &lt;mark_cache_size&gt;805306368&lt;&#x2F;mark_cache_size&gt;
     
     
         &lt;!-- If you enable the `min_bytes_to_use_mmap_io` setting,
    @@ -981,11 +980,11 @@
         &lt;&#x2F;distributed_ddl&gt;
     
         &lt;!-- Settings to fine tune MergeTree tables. See documentation in source code, in MergeTreeSettings.h --&gt;
    -    &lt;!--
         &lt;merge_tree&gt;
    -        &lt;max_suspicious_broken_parts&gt;5&lt;&#x2F;max_suspicious_broken_parts&gt;
    +        &lt;merge_max_block_size&gt;2048&lt;&#x2F;merge_max_block_size&gt;
    +        &lt;max_bytes_to_merge_at_max_space_in_pool&gt;1073741824&lt;&#x2F;max_bytes_to_merge_at_max_space_in_pool&gt;
    +        &lt;number_of_free_entries_in_pool_to_lower_max_size_of_merge&gt;0&lt;&#x2F;number_of_free_entries_in_pool_to_lower_max_size_of_merge&gt;
         &lt;&#x2F;merge_tree&gt;
    -    --&gt;
     
         &lt;!-- Protection from accidental DROP.
              If size of a MergeTree table is greater than max_table_size_to_drop (in bytes) than table could not be dropped with any DROP query.
    diff --git a&#x2F;clickhouse-users.xml b&#x2F;clickhouse-users.xml
    index f1856207..bbd4ced6 100644
    --- a&#x2F;clickhouse-users.xml
    +++ b&#x2F;clickhouse-users.xml
    @@ -7,7 +7,12 @@
             &lt;!-- Default settings. --&gt;
             &lt;default&gt;
                 &lt;!-- Maximum memory usage for processing single query, in bytes. --&gt;
    -            &lt;max_memory_usage&gt;10000000000&lt;&#x2F;max_memory_usage&gt;
    +            &lt;max_memory_usage&gt;536870912&lt;&#x2F;max_memory_usage&gt;
    +
    +            &lt;queue_max_wait_ms&gt;1000&lt;&#x2F;queue_max_wait_ms&gt;
    +            &lt;max_execution_time&gt;30&lt;&#x2F;max_execution_time&gt;
    +            &lt;background_pool_size&gt;4&lt;&#x2F;background_pool_size&gt;
    +
     
                 &lt;!-- How to choose between replicas during distributed query processing.
                      random - choose random replica from set of replicas with minimum number of errors</code></pre></div><br/><div id="40008035" class="c"><input type="checkbox" id="c-40008035" checked=""/><div class="controls bullet"><span class="by">riku_iki</span><span>|</span><a href="#40005353">root</a><span>|</span><a href="#40007905">parent</a><span>|</span><a href="#40008137">next</a><span>|</span><label class="collapse" for="c-40008035">[-]</label><label class="expand" for="c-40008035">[3 more]</label></div><br/><div class="children"><div class="content">&gt;  The two main knobs are<p>my experience is that those are not enough, multiple algorithms will just fail saying you hit max memory limit. There are many other knobs, for example: when to start external aggregation or sorting. For some cases I couldn&#x27;t figure out setup and query just hits OOM without any ideas how to fix it.</div><br/><div id="40009037" class="c"><input type="checkbox" id="c-40009037" checked=""/><div class="controls bullet"><span class="by">FridgeSeal</span><span>|</span><a href="#40005353">root</a><span>|</span><a href="#40008035">parent</a><span>|</span><a href="#40008137">next</a><span>|</span><label class="collapse" for="c-40009037">[-]</label><label class="expand" for="c-40009037">[2 more]</label></div><br/><div class="children"><div class="content">How is your table setup? It’s plausible the on-disk&#x2F;index layout is not amenable to the kinds of queries you’re trying to do.<p>What kind of queries are you trying to do? Also, what kind of machine are you running on?</div><br/><div id="40009067" class="c"><input type="checkbox" id="c-40009067" checked=""/><div class="controls bullet"><span class="by">riku_iki</span><span>|</span><a href="#40005353">root</a><span>|</span><a href="#40009037">parent</a><span>|</span><a href="#40008137">next</a><span>|</span><label class="collapse" for="c-40009067">[-]</label><label class="expand" for="c-40009067">[1 more]</label></div><br/><div class="children"><div class="content">Trivial example would be to run select count(distinct) from large table with high cardinality values: <a href="https:&#x2F;&#x2F;github.com&#x2F;ClickHouse&#x2F;ClickHouse&#x2F;issues&#x2F;47520">https:&#x2F;&#x2F;github.com&#x2F;ClickHouse&#x2F;ClickHouse&#x2F;issues&#x2F;47520</a></div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="40008137" class="c"><input type="checkbox" id="c-40008137" checked=""/><div class="controls bullet"><span class="by">andretti1977</span><span>|</span><a href="#40005353">prev</a><span>|</span><a href="#40007906">next</a><span>|</span><label class="collapse" for="c-40008137">[-]</label><label class="expand" for="c-40008137">[2 more]</label></div><br/><div class="children"><div class="content">I have a tangentially related question since I don’t use an Olap db: is deleting data so hard to perform? Is it necessarily an immutable storage?<p>If so, is it a gdpr compliant storage solution? I am asking it since gdpr compliance may require data deletion (or at least anonimization)</div><br/><div id="40009030" class="c"><input type="checkbox" id="c-40009030" checked=""/><div class="controls bullet"><span class="by">FridgeSeal</span><span>|</span><a href="#40008137">parent</a><span>|</span><a href="#40007906">next</a><span>|</span><label class="collapse" for="c-40009030">[-]</label><label class="expand" for="c-40009030">[1 more]</label></div><br/><div class="children"><div class="content">Columnar Db’s want stuff to be contiguous on disk, and deletes cause the rest of the data in that “block” to be rewritten (imagine deleting a chunk out of the middle of an excel table: you’ve got to move everything else up).<p>This in turn, creates read+write load. Modern OLAP db’s often support it, often via mitigating strategies to minimise the amount of extra work they incur: mark tainted rows, exclude them from queries, and clean up asynchronously; etc.</div><br/></div></div></div></div><div id="40005444" class="c"><input type="checkbox" id="c-40005444" checked=""/><div class="controls bullet"><span class="by">dangoodmanUT</span><span>|</span><a href="#40007906">prev</a><span>|</span><label class="collapse" for="c-40005444">[-]</label><label class="expand" for="c-40005444">[5 more]</label></div><br/><div class="children"><div class="content">deleting this comment because apparently jokes are not received well here</div><br/><div id="40005547" class="c"><input type="checkbox" id="c-40005547" checked=""/><div class="controls bullet"><span class="by">mritchie712</span><span>|</span><a href="#40005444">parent</a><span>|</span><label class="collapse" for="c-40005547">[-]</label><label class="expand" for="c-40005547">[4 more]</label></div><br/><div class="children"><div class="content">&gt; Recently, the most interesting rift in the Postgres vs OLAP space is [Hydra](<a href="https:&#x2F;&#x2F;www.hydra.so">https:&#x2F;&#x2F;www.hydra.so</a>), an open-source, column-oriented distribution of Postgres that was very recently launched (after our migration to ClickHouse). Had Hydra been available during our decision-making time period, we might’ve made a different choice.<p>There will likely be a good OLAP solution (possibly implemented as an extension) in Postgres in the next year or so. Many companies are working on it (Hydra, Parade[0], etc.)<p>0 - <a href="https:&#x2F;&#x2F;www.paradedb.com&#x2F;">https:&#x2F;&#x2F;www.paradedb.com&#x2F;</a></div><br/><div id="40005736" class="c"><input type="checkbox" id="c-40005736" checked=""/><div class="controls bullet"><span class="by">kapilvt</span><span>|</span><a href="#40005444">root</a><span>|</span><a href="#40005547">parent</a><span>|</span><label class="collapse" for="c-40005736">[-]</label><label class="expand" for="c-40005736">[3 more]</label></div><br/><div class="children"><div class="content">for others curious<p>ParadeDB - AGPL License
<a href="https:&#x2F;&#x2F;github.com&#x2F;paradedb&#x2F;paradedb&#x2F;blob&#x2F;dev&#x2F;LICENSE">https:&#x2F;&#x2F;github.com&#x2F;paradedb&#x2F;paradedb&#x2F;blob&#x2F;dev&#x2F;LICENSE</a><p>Hydra - Apache 2.0
<a href="https:&#x2F;&#x2F;github.com&#x2F;hydradatabase&#x2F;hydra&#x2F;blob&#x2F;main&#x2F;LICENSE">https:&#x2F;&#x2F;github.com&#x2F;hydradatabase&#x2F;hydra&#x2F;blob&#x2F;main&#x2F;LICENSE</a><p>also hydra seems derived from citusdata&#x27;s columnar implementation.</div><br/><div id="40007273" class="c"><input type="checkbox" id="c-40007273" checked=""/><div class="controls bullet"><span class="by">mdaniel</span><span>|</span><a href="#40005444">root</a><span>|</span><a href="#40005736">parent</a><span>|</span><label class="collapse" for="c-40007273">[-]</label><label class="expand" for="c-40007273">[2 more]</label></div><br/><div class="children"><div class="content">Don&#x27;t feel bad, lots of people get bitten by not reading all the way down to the bottom of their readme: <a href="https:&#x2F;&#x2F;github.com&#x2F;hydradatabase&#x2F;hydra&#x2F;blob&#x2F;v1.1.2&#x2F;README.md#license">https:&#x2F;&#x2F;github.com&#x2F;hydradatabase&#x2F;hydra&#x2F;blob&#x2F;v1.1.2&#x2F;README.md...</a> While <i>Hydra</i> may very well license their own code Apache 2, they ship the AGPLv3 columnar which to my very best IANAL understanding taints the whole stack and AGPLv3&#x27;s everything all the way through <a href="https:&#x2F;&#x2F;github.com&#x2F;hydradatabase&#x2F;hydra&#x2F;blob&#x2F;v1.1.2&#x2F;columnar&#x2F;LICENSE">https:&#x2F;&#x2F;github.com&#x2F;hydradatabase&#x2F;hydra&#x2F;blob&#x2F;v1.1.2&#x2F;columnar&#x2F;...</a></div><br/><div id="40008015" class="c"><input type="checkbox" id="c-40008015" checked=""/><div class="controls bullet"><span class="by">alright2565</span><span>|</span><a href="#40005444">root</a><span>|</span><a href="#40007273">parent</a><span>|</span><label class="collapse" for="c-40008015">[-]</label><label class="expand" for="c-40008015">[1 more]</label></div><br/><div class="children"><div class="content">the only additional requirement that the AGPL introduces is that if you modify the AGPL software, you have to provide people who can access it over the network the code.<p>If you just use a pre-built package, the AGPL has the exact same requirements as the GPL.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></body></html>