<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1724058071688" as="style"/><link rel="stylesheet" href="styles.css?v=1724058071688"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://emnudge.dev/blog/markov-chains-are-funny/">Markov chains are funnier than LLMs</a> <span class="domain">(<a href="https://emnudge.dev">emnudge.dev</a>)</span></div><div class="subtext"><span>todsacerdoti</span> | <span>91 comments</span></div><br/><div><div id="41287805" class="c"><input type="checkbox" id="c-41287805" checked=""/><div class="controls bullet"><span class="by">fishtoaster</span><span>|</span><a href="#41287416">next</a><span>|</span><label class="collapse" for="c-41287805">[-]</label><label class="expand" for="c-41287805">[9 more]</label></div><br/><div class="children"><div class="content">I came to this same conclusion some years ago while working on a side project.<p>Before anything LLM existed, I built a site[0] to generate fake &quot;AWS Blog Posts.&quot;  I trained a markov chain generator on all AWS announcement posts up to that point, copied the html + css of aws&#x27;s standard blog posts, then glued them all together with some python + JS.  It turned out, IMO, pretty funny!  People familiar with AWS&#x27;s blog posts would often get several sentences in before they realized they were looking at word-soup.<p>When GPT was new, I looked into using that to &quot;upgrade&quot; it.  I spent a weekend messing around with Minimaxir&#x27;s gpt-2-simple generating blog posts based on AWS content.  What I found was, ultimately, it was way less fun.  The posts were far too realistic to be interesting.  They read like totally-real blog posts that just happened to not be true.<p>I realized then that the humor of those early markov generations was the ridiculousness.  The point where, a few words or sentences in, you realized it was all nonsense.  LLM&#x27;s these days are too good for that - the text they generate is sometimes <i>wrong</i>, but rarely nonsense in a humorous way.<p>Markov chain content was wrong in a &quot;kid&#x27;s say the darndest things&quot; way, while modern LLMs are wrong in a &quot;My uncle doesn&#x27;t know basic geography&quot; way.<p>[0] <a href="https:&#x2F;&#x2F;totes-not-amazon.com&#x2F;" rel="nofollow">https:&#x2F;&#x2F;totes-not-amazon.com&#x2F;</a> - click any link to get a new one.</div><br/><div id="41288941" class="c"><input type="checkbox" id="c-41288941" checked=""/><div class="controls bullet"><span class="by">mdp2021</span><span>|</span><a href="#41287805">parent</a><span>|</span><a href="#41288128">next</a><span>|</span><label class="collapse" for="c-41288941">[-]</label><label class="expand" for="c-41288941">[7 more]</label></div><br/><div class="children"><div class="content">&gt; <i>modern LLMs are wrong in a &quot;My uncle doesn&#x27;t know basic geography&quot; way</i><p>Oh, certainly not. I have been using LLM chatbots extensively this week. If your uncle were not just confident while stating falsities, but uncapable of self-assessment, he would have been murdered.</div><br/><div id="41289187" class="c"><input type="checkbox" id="c-41289187" checked=""/><div class="controls bullet"><span class="by">Kiro</span><span>|</span><a href="#41287805">root</a><span>|</span><a href="#41288941">parent</a><span>|</span><a href="#41289009">next</a><span>|</span><label class="collapse" for="c-41289187">[-]</label><label class="expand" for="c-41289187">[2 more]</label></div><br/><div class="children"><div class="content">&gt; I have been using LLM chatbots extensively this week.<p>This reads as &quot;I&#x27;ve <i>actually</i> used LLMs&quot; like it&#x27;s a rare occurrence giving you a unique insight, when most of us have been using LLMs extensively for almost two years now.</div><br/><div id="41289205" class="c"><input type="checkbox" id="c-41289205" checked=""/><div class="controls bullet"><span class="by">mdp2021</span><span>|</span><a href="#41287805">root</a><span>|</span><a href="#41289187">parent</a><span>|</span><a href="#41289009">next</a><span>|</span><label class="collapse" for="c-41289205">[-]</label><label class="expand" for="c-41289205">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>This reads</i><p>Oh please. Guidelines: «respond to the strongest plausible interpretation».</div><br/></div></div></div></div><div id="41289009" class="c"><input type="checkbox" id="c-41289009" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#41287805">root</a><span>|</span><a href="#41288941">parent</a><span>|</span><a href="#41289187">prev</a><span>|</span><a href="#41288128">next</a><span>|</span><label class="collapse" for="c-41289009">[-]</label><label class="expand" for="c-41289009">[4 more]</label></div><br/><div class="children"><div class="content">Or made a stellar career as a salesman or politician.</div><br/><div id="41289045" class="c"><input type="checkbox" id="c-41289045" checked=""/><div class="controls bullet"><span class="by">mdp2021</span><span>|</span><a href="#41287805">root</a><span>|</span><a href="#41289009">parent</a><span>|</span><a href="#41288128">next</a><span>|</span><label class="collapse" for="c-41289045">[-]</label><label class="expand" for="c-41289045">[3 more]</label></div><br/><div class="children"><div class="content">Until you are caught (in good societies).</div><br/><div id="41289064" class="c"><input type="checkbox" id="c-41289064" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#41287805">root</a><span>|</span><a href="#41289045">parent</a><span>|</span><a href="#41288128">next</a><span>|</span><label class="collapse" for="c-41289064">[-]</label><label class="expand" for="c-41289064">[2 more]</label></div><br/><div class="children"><div class="content">Or <i>fresh</i> ones. Established democracies end up with political structures that self-select for being able to sound right and cooperate right, entirely independent of truth and merit.</div><br/><div id="41289217" class="c"><input type="checkbox" id="c-41289217" checked=""/><div class="controls bullet"><span class="by">mdp2021</span><span>|</span><a href="#41287805">root</a><span>|</span><a href="#41289064">parent</a><span>|</span><a href="#41288128">next</a><span>|</span><label class="collapse" for="c-41289217">[-]</label><label class="expand" for="c-41289217">[1 more]</label></div><br/><div class="children"><div class="content">I coincidentally just stumbled on a recent implicit comment by Angél Boligan Corbo:<p><a href="https:&#x2F;&#x2F;image.cagle.com&#x2F;287573&#x2F;980&#x2F;-the-talker.png" rel="nofollow">https:&#x2F;&#x2F;image.cagle.com&#x2F;287573&#x2F;980&#x2F;-the-talker.png</a></div><br/></div></div></div></div></div></div></div></div></div></div><div id="41288128" class="c"><input type="checkbox" id="c-41288128" checked=""/><div class="controls bullet"><span class="by">fouronnes3</span><span>|</span><a href="#41287805">parent</a><span>|</span><a href="#41288941">prev</a><span>|</span><a href="#41287416">next</a><span>|</span><label class="collapse" for="c-41288128">[-]</label><label class="expand" for="c-41288128">[1 more]</label></div><br/><div class="children"><div class="content">Reminds me of git man pages generators. Extremely fun as well when you can&#x27;t quite tell if it&#x27;s real.</div><br/></div></div></div></div><div id="41287416" class="c"><input type="checkbox" id="c-41287416" checked=""/><div class="controls bullet"><span class="by">tkgally</span><span>|</span><a href="#41287805">prev</a><span>|</span><a href="#41287084">next</a><span>|</span><label class="collapse" for="c-41287416">[-]</label><label class="expand" for="c-41287416">[20 more]</label></div><br/><div class="children"><div class="content">Prompt to Claude 3.5 Sonnet: Below is a recently published essay followed by some of the discussion about it on Hacker News. Write 10 short jokes on this theme, making sure that the jokes are funny in the way described by the essay&#x27;s author. [essay and discussion omitted]<p>Claude&#x27;s response: I understand you&#x27;d like me to write 10 short jokes on the theme of Markov chains being funnier than large language models, in the style described by the essay author. I&#x27;ll do my best to create some jokes that aim for &quot;unserious surprise&quot; and violate expected patterns in amusing ways:<p>1. Why did the Markov chain cross the road? To get to the other side of unpredictability.<p>2. An LLM and a Markov chain walk into a bar. The LLM orders a statistically probable drink. The Markov chain orders a lampshade made of cheese.<p>3. What do you call a Markov chain that tells dad jokes? A Mark-ov Twain.<p>4. How many LLMs does it take to screw in a lightbulb? One - but it&#x27;ll spend 20 minutes explaining the optimal lightbulb-screwing process first.<p>5. Knock knock. 
Who&#x27;s there?
Markov.
Markov who?
Markov chain reaction of nonsensical hilarity.<p>6. An LLM, a Markov chain, and GPT-4 walk into a bar. The bartender says &quot;We don&#x27;t serve your kind here.&quot; GPT-4 leaves. The LLM stays to debate ethics. The Markov chain orders a bicycle made of spaghetti.<p>7. What&#x27;s an LLM&#x27;s favorite movie? Predictable and Furious 17: The Safest Driving Yet.<p>8. How does a Markov chain tell a story? &quot;Once upon a time, there was a princess who lived in a castle made of bananas and ruled over a kingdom of sentient toasters.&quot;<p>9. What did the Markov chain say to the LLM? &quot;Your mother was a abacus and your father smelled of silicon!&quot;<p>10. Why don&#x27;t Markov chains make good therapists? Because their advice is always &quot;And then you should banana the feelings until they become a hat.&quot;</div><br/><div id="41287490" class="c"><input type="checkbox" id="c-41287490" checked=""/><div class="controls bullet"><span class="by">anvuong</span><span>|</span><a href="#41287416">parent</a><span>|</span><a href="#41287625">next</a><span>|</span><label class="collapse" for="c-41287490">[-]</label><label class="expand" for="c-41287490">[6 more]</label></div><br/><div class="children"><div class="content">&quot;An LLM, a Markov chain, and GPT-4 walk into a bar. The bartender says &quot;We don&#x27;t serve your kind here.&quot; GPT-4 leaves. The LLM stays to debate ethics. The Markov chain orders a bicycle made of spaghetti.&quot;<p>This is actually gold.</div><br/><div id="41287513" class="c"><input type="checkbox" id="c-41287513" checked=""/><div class="controls bullet"><span class="by">muglug</span><span>|</span><a href="#41287416">root</a><span>|</span><a href="#41287490">parent</a><span>|</span><a href="#41288793">next</a><span>|</span><label class="collapse" for="c-41287513">[-]</label><label class="expand" for="c-41287513">[4 more]</label></div><br/><div class="children"><div class="content">It’s... not?<p>Even for the low bar of a geek joke it makes no sense since GPT-4 <i>is</i> an LLM.</div><br/><div id="41288157" class="c"><input type="checkbox" id="c-41288157" checked=""/><div class="controls bullet"><span class="by">bryanrasmussen</span><span>|</span><a href="#41287416">root</a><span>|</span><a href="#41287513">parent</a><span>|</span><a href="#41289000">next</a><span>|</span><label class="collapse" for="c-41288157">[-]</label><label class="expand" for="c-41288157">[1 more]</label></div><br/><div class="children"><div class="content">In normal English usage this would imply that the LLM was not GPT-4 LLM but some stereotypical anonymous LLM.<p>In business terms GPT-4 can be said to be superior because it understood the instruction and left, in AI terms the anonymous LLM might be superior because it may have understood the instruction but responded in an &quot;intelligent&quot; manner by arguing about the morality of the instructions.<p>At a meta-level the joke thus argues that GPT in achieving business ends has had its intelligence hampered. As have we all.<p>At the same meta-level as the joke was constructed by Claude it can be argued that Claude is commenting on both the intellectual limitations of the Markov chain (insane babblings), and GPT-4 (unimaginative, inhibited business type) and that the best version is some LLM that is not GPT-4 with its limitations - an LLM like Claude. Sneaky Claude.</div><br/></div></div><div id="41289000" class="c"><input type="checkbox" id="c-41289000" checked=""/><div class="controls bullet"><span class="by">Kuinox</span><span>|</span><a href="#41287416">root</a><span>|</span><a href="#41287513">parent</a><span>|</span><a href="#41288157">prev</a><span>|</span><a href="#41287582">next</a><span>|</span><label class="collapse" for="c-41289000">[-]</label><label class="expand" for="c-41289000">[1 more]</label></div><br/><div class="children"><div class="content">Does the markov chain would write something that make more sense ?</div><br/></div></div><div id="41287582" class="c"><input type="checkbox" id="c-41287582" checked=""/><div class="controls bullet"><span class="by">tourmalinetaco</span><span>|</span><a href="#41287416">root</a><span>|</span><a href="#41287513">parent</a><span>|</span><a href="#41289000">prev</a><span>|</span><a href="#41288793">next</a><span>|</span><label class="collapse" for="c-41287582">[-]</label><label class="expand" for="c-41287582">[1 more]</label></div><br/><div class="children"><div class="content">That’s what makes it gold.</div><br/></div></div></div></div><div id="41288793" class="c"><input type="checkbox" id="c-41288793" checked=""/><div class="controls bullet"><span class="by">nevertoolate</span><span>|</span><a href="#41287416">root</a><span>|</span><a href="#41287490">parent</a><span>|</span><a href="#41287513">prev</a><span>|</span><a href="#41287625">next</a><span>|</span><label class="collapse" for="c-41288793">[-]</label><label class="expand" for="c-41288793">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;re watching a stage play - a banquet is in progress. The guests are enjoying an appetizer of raw oysters. The entree consists of boiled dog.</div><br/></div></div></div></div><div id="41287625" class="c"><input type="checkbox" id="c-41287625" checked=""/><div class="controls bullet"><span class="by">tonyarkles</span><span>|</span><a href="#41287416">parent</a><span>|</span><a href="#41287490">prev</a><span>|</span><a href="#41288412">next</a><span>|</span><label class="collapse" for="c-41287625">[-]</label><label class="expand" for="c-41287625">[1 more]</label></div><br/><div class="children"><div class="content">&gt; 2. An LLM and a Markov chain walk into a bar. The LLM orders a statistically probable drink. The Markov chain orders a lampshade made of cheese.<p>That’s pretty decent!</div><br/></div></div><div id="41288412" class="c"><input type="checkbox" id="c-41288412" checked=""/><div class="controls bullet"><span class="by">antman</span><span>|</span><a href="#41287416">parent</a><span>|</span><a href="#41287625">prev</a><span>|</span><a href="#41287745">next</a><span>|</span><label class="collapse" for="c-41288412">[-]</label><label class="expand" for="c-41288412">[1 more]</label></div><br/><div class="children"><div class="content">&quot;How many LLMs does it take to screw in a lightbulb? One - but it&#x27;ll spend 20 minutes explaining the optimal lightbulb-screwing process first.&quot; that was not funny that is accurately painful!</div><br/></div></div><div id="41287745" class="c"><input type="checkbox" id="c-41287745" checked=""/><div class="controls bullet"><span class="by">minimaxir</span><span>|</span><a href="#41287416">parent</a><span>|</span><a href="#41288412">prev</a><span>|</span><a href="#41289071">next</a><span>|</span><label class="collapse" for="c-41287745">[-]</label><label class="expand" for="c-41287745">[1 more]</label></div><br/><div class="children"><div class="content">Claude 3.5 Sonnet in general is the first modern LLM I&#x27;ve tried that&#x27;s actually good at jokes that are inventive. The GPT-based LLMs are all too RLHFed to be wacky.</div><br/></div></div><div id="41289071" class="c"><input type="checkbox" id="c-41289071" checked=""/><div class="controls bullet"><span class="by">dan_mctree</span><span>|</span><a href="#41287416">parent</a><span>|</span><a href="#41287745">prev</a><span>|</span><a href="#41287491">next</a><span>|</span><label class="collapse" for="c-41289071">[-]</label><label class="expand" for="c-41289071">[1 more]</label></div><br/><div class="children"><div class="content">Why are bananas the funniest food? Even Claude seems to have caught on</div><br/></div></div><div id="41287491" class="c"><input type="checkbox" id="c-41287491" checked=""/><div class="controls bullet"><span class="by">floren</span><span>|</span><a href="#41287416">parent</a><span>|</span><a href="#41289071">prev</a><span>|</span><a href="#41288023">next</a><span>|</span><label class="collapse" for="c-41287491">[-]</label><label class="expand" for="c-41287491">[6 more]</label></div><br/><div class="children"><div class="content">So was it that LLMs <i>used</i> to be capable of making actual jokes, or were they always this bad and I was just more impressed by the talking computer back then?</div><br/><div id="41288999" class="c"><input type="checkbox" id="c-41288999" checked=""/><div class="controls bullet"><span class="by">red75prime</span><span>|</span><a href="#41287416">root</a><span>|</span><a href="#41287491">parent</a><span>|</span><a href="#41287522">next</a><span>|</span><label class="collapse" for="c-41288999">[-]</label><label class="expand" for="c-41288999">[1 more]</label></div><br/><div class="children"><div class="content">I chuckled a bit. They are OK, if you don&#x27;t get exposed to them too often. And with an LLM you can get as much exposure as you want (and all of the jokes are naturally from roughly the same probability distribution).<p>I don&#x27;t expect too much until AI self-play learning will be made possible, so I don&#x27;t get disappointed by the expected shortcomings.</div><br/></div></div><div id="41287522" class="c"><input type="checkbox" id="c-41287522" checked=""/><div class="controls bullet"><span class="by">minimaxir</span><span>|</span><a href="#41287416">root</a><span>|</span><a href="#41287491">parent</a><span>|</span><a href="#41288999">prev</a><span>|</span><a href="#41287970">next</a><span>|</span><label class="collapse" for="c-41287522">[-]</label><label class="expand" for="c-41287522">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a different <i>style</i> of comedy. Absurdism vs. joke setups (and not quite nailing it)</div><br/></div></div><div id="41287970" class="c"><input type="checkbox" id="c-41287970" checked=""/><div class="controls bullet"><span class="by">delusional</span><span>|</span><a href="#41287416">root</a><span>|</span><a href="#41287491">parent</a><span>|</span><a href="#41287522">prev</a><span>|</span><a href="#41288023">next</a><span>|</span><label class="collapse" for="c-41287970">[-]</label><label class="expand" for="c-41287970">[3 more]</label></div><br/><div class="children"><div class="content">It&#x27;s the &quot;impressed by the spectacle&quot; one. I tried jokes with LLMs many times, and they&#x27;re always this. Riffing on a couple of themes loosely related to what was asked. Always unfunny and uncreative.</div><br/><div id="41288382" class="c"><input type="checkbox" id="c-41288382" checked=""/><div class="controls bullet"><span class="by">jack_pp</span><span>|</span><a href="#41287416">root</a><span>|</span><a href="#41287970">parent</a><span>|</span><a href="#41288184">next</a><span>|</span><label class="collapse" for="c-41288382">[-]</label><label class="expand" for="c-41288382">[1 more]</label></div><br/><div class="children"><div class="content">I found some of those jokes good, definitely better than I would&#x27;ve ever written them. If you watch shows about comedy like say Hacks you&#x27;ll see human comedians riff on stuff and a lot of the off the top jokes get discarded or improved. So Claude did fine in my book</div><br/></div></div><div id="41288184" class="c"><input type="checkbox" id="c-41288184" checked=""/><div class="controls bullet"><span class="by">tkgally</span><span>|</span><a href="#41287416">root</a><span>|</span><a href="#41287970">parent</a><span>|</span><a href="#41288382">prev</a><span>|</span><a href="#41288023">next</a><span>|</span><label class="collapse" for="c-41288184">[-]</label><label class="expand" for="c-41288184">[1 more]</label></div><br/><div class="children"><div class="content">I wonder, though, whether jokes like these could be useful to professional humorists who have to come up with gags on a deadline. From what I’ve read about monologue writing teams for late-night talk shows and the like, the writers first propose many ideas, most of which are shot down quickly and the remainder of which get tweaked and polished before being used. Some of the above jokes by Claude look to me as though they might serve as good starting points for such brainstorming. At least, they’re better than anything <i>I</i> could create in a short amount of time.</div><br/></div></div></div></div></div></div><div id="41288023" class="c"><input type="checkbox" id="c-41288023" checked=""/><div class="controls bullet"><span class="by">wodenokoto</span><span>|</span><a href="#41287416">parent</a><span>|</span><a href="#41287491">prev</a><span>|</span><a href="#41289028">next</a><span>|</span><label class="collapse" for="c-41288023">[-]</label><label class="expand" for="c-41288023">[2 more]</label></div><br/><div class="children"><div class="content">&gt; What do you call a Markov chain that tells dad jokes? A Mark-ov Twain.<p>I honestly thought that one was pretty good.</div><br/><div id="41288166" class="c"><input type="checkbox" id="c-41288166" checked=""/><div class="controls bullet"><span class="by">bryanrasmussen</span><span>|</span><a href="#41287416">root</a><span>|</span><a href="#41288023">parent</a><span>|</span><a href="#41289028">next</a><span>|</span><label class="collapse" for="c-41288166">[-]</label><label class="expand" for="c-41288166">[1 more]</label></div><br/><div class="children"><div class="content">was it instructed to insult Mark Twain? Because otherwise, I take exception.</div><br/></div></div></div></div><div id="41289028" class="c"><input type="checkbox" id="c-41289028" checked=""/><div class="controls bullet"><span class="by">raverbashing</span><span>|</span><a href="#41287416">parent</a><span>|</span><a href="#41288023">prev</a><span>|</span><a href="#41287084">next</a><span>|</span><label class="collapse" for="c-41289028">[-]</label><label class="expand" for="c-41289028">[1 more]</label></div><br/><div class="children"><div class="content">These are ok but they got nothing on the absurdist Markov Chain jokes (but that being said, the MC misses a lot of times as well)</div><br/></div></div></div></div><div id="41287084" class="c"><input type="checkbox" id="c-41287084" checked=""/><div class="controls bullet"><span class="by">dgacmu</span><span>|</span><a href="#41287416">prev</a><span>|</span><a href="#41287566">next</a><span>|</span><label class="collapse" for="c-41287084">[-]</label><label class="expand" for="c-41287084">[1 more]</label></div><br/><div class="children"><div class="content">Some friends of mine in college ran a markov chain generator on the &quot;police reports&quot; section of our college newspaper (1). The best 10% of the results, from a three-token generator, were some of the funniest machine-generated text I&#x27;ve ever seen -- it had an absurdity that modern LLMs seem to avoid due to making higher-level semantic sense.<p>It probably also helped that there was a creep exposing himself in the library during this period, which made for some good base material.<p>(1) The Daily Utah Chronicle; if memory serves, said friends also tried the markov chain generator on the personals section to good effect as well.</div><br/></div></div><div id="41287566" class="c"><input type="checkbox" id="c-41287566" checked=""/><div class="controls bullet"><span class="by">pants2</span><span>|</span><a href="#41287084">prev</a><span>|</span><a href="#41289180">next</a><span>|</span><label class="collapse" for="c-41287566">[-]</label><label class="expand" for="c-41287566">[2 more]</label></div><br/><div class="children"><div class="content">If you want some empirical evidence: &#x2F;r&#x2F;subreddit simulator[1] is a Markov-based Reddit parody, and 
 &#x2F;r&#x2F;SubSimulatorGPT2[2] is its LLM-powered cousin. The Markov version got way more upvotes and is simply funnier!<p>1. <a href="https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;SubredditSimulator&#x2F;top&#x2F;?t=all" rel="nofollow">https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;SubredditSimulator&#x2F;top&#x2F;?t=all</a><p>2. <a href="https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;SubSimulatorGPT2&#x2F;top&#x2F;?t=all" rel="nofollow">https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;SubSimulatorGPT2&#x2F;top&#x2F;?t=all</a></div><br/><div id="41288425" class="c"><input type="checkbox" id="c-41288425" checked=""/><div class="controls bullet"><span class="by">mcmoor</span><span>|</span><a href="#41287566">parent</a><span>|</span><a href="#41289180">next</a><span>|</span><label class="collapse" for="c-41288425">[-]</label><label class="expand" for="c-41288425">[1 more]</label></div><br/><div class="children"><div class="content">Nah, I think it&#x27;s solely due to the former being much older and more well-known. And I always liked the latter much more anyway.</div><br/></div></div></div></div><div id="41289180" class="c"><input type="checkbox" id="c-41289180" checked=""/><div class="controls bullet"><span class="by">dghf</span><span>|</span><a href="#41287566">prev</a><span>|</span><a href="#41287062">next</a><span>|</span><label class="collapse" for="c-41289180">[-]</label><label class="expand" for="c-41289180">[1 more]</label></div><br/><div class="children"><div class="content">I remember the KJV&#x2F;SICP mash-up. My favourite, both for funniness and emotional truth:<p>&gt; And Satan stood against them in the global environment.</div><br/></div></div><div id="41287062" class="c"><input type="checkbox" id="c-41287062" checked=""/><div class="controls bullet"><span class="by">hatthew</span><span>|</span><a href="#41289180">prev</a><span>|</span><a href="#41287279">next</a><span>|</span><label class="collapse" for="c-41287062">[-]</label><label class="expand" for="c-41287062">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve posted a few &quot;fake XYZ written by AI&quot; on reddit over the years, and the model that got the best reactions was GPT-2. Markov chains aren&#x27;t good enough to make something that is interesting for more than a sentence or two, and GPT-3 onwards is too clean and boring. GPT-2 is the perfect middle ground that can get grammar largely correct and maintain a cohesive idea, but doesn&#x27;t yet know enough of the specifics of various topics to make things that make sense in the context of that topic.</div><br/><div id="41287075" class="c"><input type="checkbox" id="c-41287075" checked=""/><div class="controls bullet"><span class="by">metadat</span><span>|</span><a href="#41287062">parent</a><span>|</span><a href="#41287279">next</a><span>|</span><label class="collapse" for="c-41287075">[-]</label><label class="expand" for="c-41287075">[1 more]</label></div><br/><div class="children"><div class="content">Can you share any of the best examples?</div><br/></div></div></div></div><div id="41287279" class="c"><input type="checkbox" id="c-41287279" checked=""/><div class="controls bullet"><span class="by">jcalvinowens</span><span>|</span><a href="#41287062">prev</a><span>|</span><a href="#41287250">next</a><span>|</span><label class="collapse" for="c-41287279">[-]</label><label class="expand" for="c-41287279">[6 more]</label></div><br/><div class="children"><div class="content">Unfortunately the account no longer exists... but about a decade ago while I was in school, I created a Markov twitter bot trained on:<p>1. All of Linus Torvalds&#x27; mail to LKML for the prior year.<p>2. All of Jesus&#x27; direct quotes from the king james bible.<p>It was absolutely hilarious. The two training sets had very little overlap, so it was necessary to add a heuristic that weighted options from each set more heavily the longer the chain had been &quot;stuck&quot; in the other set.</div><br/><div id="41287622" class="c"><input type="checkbox" id="c-41287622" checked=""/><div class="controls bullet"><span class="by">SonOfLilit</span><span>|</span><a href="#41287279">parent</a><span>|</span><a href="#41287362">next</a><span>|</span><label class="collapse" for="c-41287622">[-]</label><label class="expand" for="c-41287622">[1 more]</label></div><br/><div class="children"><div class="content">This very similar bot still exists (and was quoted a few times in Unsong):<p><a href="https:&#x2F;&#x2F;www.tumblr.com&#x2F;kingjamesprogramming" rel="nofollow">https:&#x2F;&#x2F;www.tumblr.com&#x2F;kingjamesprogramming</a></div><br/></div></div><div id="41287362" class="c"><input type="checkbox" id="c-41287362" checked=""/><div class="controls bullet"><span class="by">throwawayk7h</span><span>|</span><a href="#41287279">parent</a><span>|</span><a href="#41287622">prev</a><span>|</span><a href="#41289165">next</a><span>|</span><label class="collapse" for="c-41287362">[-]</label><label class="expand" for="c-41287362">[3 more]</label></div><br/><div class="children"><div class="content">This sounds great. Did you save any examples?</div><br/><div id="41287617" class="c"><input type="checkbox" id="c-41287617" checked=""/><div class="controls bullet"><span class="by">NobodyNada</span><span>|</span><a href="#41287279">root</a><span>|</span><a href="#41287362">parent</a><span>|</span><a href="#41289165">next</a><span>|</span><label class="collapse" for="c-41287617">[-]</label><label class="expand" for="c-41287617">[2 more]</label></div><br/><div class="children"><div class="content">&quot;King James Programming&quot; is along similar lines: <a href="https:&#x2F;&#x2F;www.tumblr.com&#x2F;kingjamesprogramming" rel="nofollow">https:&#x2F;&#x2F;www.tumblr.com&#x2F;kingjamesprogramming</a></div><br/><div id="41288276" class="c"><input type="checkbox" id="c-41288276" checked=""/><div class="controls bullet"><span class="by">throwawayk7h</span><span>|</span><a href="#41287279">root</a><span>|</span><a href="#41287617">parent</a><span>|</span><a href="#41289165">next</a><span>|</span><label class="collapse" for="c-41288276">[-]</label><label class="expand" for="c-41288276">[1 more]</label></div><br/><div class="children"><div class="content">Yes, this is the first thing in the article.</div><br/></div></div></div></div></div></div></div></div><div id="41287250" class="c"><input type="checkbox" id="c-41287250" checked=""/><div class="controls bullet"><span class="by">dimatura</span><span>|</span><a href="#41287279">prev</a><span>|</span><a href="#41287082">next</a><span>|</span><label class="collapse" for="c-41287250">[-]</label><label class="expand" for="c-41287250">[1 more]</label></div><br/><div class="children"><div class="content">The evolution of the AI weirdness blog (<a href="https:&#x2F;&#x2F;www.aiweirdness.com&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.aiweirdness.com&#x2F;</a>) over the past few years somewhat supports this idea, except that the author got plenty of funny results with LLMs - but mostly the early ones, up to around GPT3 (and smaller variants of GPT3). For example, cereal names generated by the Ada version of GPT were much funnier than the Da Vinci ones: <a href="https:&#x2F;&#x2F;www.aiweirdness.com&#x2F;new-breakfast-cereals-from-ai&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.aiweirdness.com&#x2F;new-breakfast-cereals-from-ai&#x2F;</a></div><br/></div></div><div id="41287082" class="c"><input type="checkbox" id="c-41287082" checked=""/><div class="controls bullet"><span class="by">bigyikes</span><span>|</span><a href="#41287250">prev</a><span>|</span><a href="#41287465">next</a><span>|</span><label class="collapse" for="c-41287082">[-]</label><label class="expand" for="c-41287082">[12 more]</label></div><br/><div class="children"><div class="content">Turn up the temperature?<p>Markov chains have a cruder understanding of language.<p>Turn up the temperature (the “randomness”) of an LLM and you can achieve a similarly crude approximation.<p>Further, author uses ChatGPT-3.5. ChatGPT has been rlhf’d to sound as generic as possible, and 3.5 has a worse understanding of humor compared to 4.<p>I don’t buy the thesis of this article.</div><br/><div id="41287141" class="c"><input type="checkbox" id="c-41287141" checked=""/><div class="controls bullet"><span class="by">ziddoap</span><span>|</span><a href="#41287082">parent</a><span>|</span><a href="#41287098">next</a><span>|</span><label class="collapse" for="c-41287141">[-]</label><label class="expand" for="c-41287141">[3 more]</label></div><br/><div class="children"><div class="content">&gt;<i>rlhf&#x27;d</i><p>For those of us not in the know about all the various machine learning acronyms:<p>RLHF = Reinforcement learning from human feedback</div><br/><div id="41287887" class="c"><input type="checkbox" id="c-41287887" checked=""/><div class="controls bullet"><span class="by">DaiPlusPlus</span><span>|</span><a href="#41287082">root</a><span>|</span><a href="#41287141">parent</a><span>|</span><a href="#41287098">next</a><span>|</span><label class="collapse" for="c-41287887">[-]</label><label class="expand" for="c-41287887">[2 more]</label></div><br/><div class="children"><div class="content">(Somewhat off-topic)<p>When GPT went public along with OpenAI’s articles and papers back in late-2022 through 2023, my impression was OpenAI wanted us all to see&#x2F;read about RLHF. It felt odd because surely the whole LLM-thing (e.g. how does it even work?!?[1]) was the far bigger research-story than just constant reassurances it won’t end-up like MSFT’s Tay bot; my understanding is that as a research or secret-sauce RLHF, compared to the core meat-and-potatoes of LLMs, is an ugly-hack afterthought.<p>By-way of a bad analogy: it’s as if they created a fantastical new 3D world game engine, like Unreal or Unity, which has a fundamentally different architecture to anything before, but has a bug that occasionally replaces ground terrain with ocean - and their solution to this is to write a pixel-shader that detects this and color-shifts blue into green so people don’t notice - and they then put-out press-releases about how great their pixel-shader is - rather than about the rest of the engine - and no-one seems to be talking about the underlying bug, let alone fixing it.<p>————-<p>[1] I still haven’t heard a decent explanation of how feeding the world’s corpus of English text (and computer program code) into a statistical-modeller results in something that can perform almost any information-processing task via instructions input as natural-language.</div><br/><div id="41288068" class="c"><input type="checkbox" id="c-41288068" checked=""/><div class="controls bullet"><span class="by">treyd</span><span>|</span><a href="#41287082">root</a><span>|</span><a href="#41287887">parent</a><span>|</span><a href="#41287098">next</a><span>|</span><label class="collapse" for="c-41288068">[-]</label><label class="expand" for="c-41288068">[1 more]</label></div><br/><div class="children"><div class="content">Yeah that analogy is fairly poor.  You have to think about it in terms of some probability distribution that each step of the model is sampling from.  Out of the distribution of all text, find the top n values for the next token that maximize `P(next | prefix)`, which is done efficiently through making a vector embedding to encode the tokens inside the statistical model.<p>Things that look like Q-and-A transcripts do exist in the training set, think interviews, books, stage plays, etc, and at a different layer of abstraction the rules of English text <i>in general</i> are very well represented.  What RLHF is doing is slightly shifting the shape of the probability distribution to make it look more like the Q-and-A formats that are desired.  They build a large dataset with human tagging to collect samples of good and bad outputs and using reinforcement learning techniques to generate outputs that look <i>more like</i> the good examples and <i>less like</i> the bad ones.<p>This probably involves creating a (much smaller, not-LLM) model that is trained to discriminate good outputs and bad outputs, learning to mimic the human tagging.  There&#x27;s some papers that have been published.<p>Here&#x27;s one article from Huggingface: <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;blog&#x2F;rlhf" rel="nofollow">https:&#x2F;&#x2F;huggingface.co&#x2F;blog&#x2F;rlhf</a></div><br/></div></div></div></div></div></div><div id="41287098" class="c"><input type="checkbox" id="c-41287098" checked=""/><div class="controls bullet"><span class="by">dartos</span><span>|</span><a href="#41287082">parent</a><span>|</span><a href="#41287141">prev</a><span>|</span><a href="#41287422">next</a><span>|</span><label class="collapse" for="c-41287098">[-]</label><label class="expand" for="c-41287098">[7 more]</label></div><br/><div class="children"><div class="content">I wish there was a locked chatgpt version for researchers</div><br/><div id="41287358" class="c"><input type="checkbox" id="c-41287358" checked=""/><div class="controls bullet"><span class="by">rck</span><span>|</span><a href="#41287082">root</a><span>|</span><a href="#41287098">parent</a><span>|</span><a href="#41287196">next</a><span>|</span><label class="collapse" for="c-41287358">[-]</label><label class="expand" for="c-41287358">[1 more]</label></div><br/><div class="children"><div class="content">You could play with open models and different temperatures using the lmgen script from this repo we just released:<p><a href="https:&#x2F;&#x2F;github.com&#x2F;RichardKelley&#x2F;hflm?tab=readme-ov-file#lmgen">https:&#x2F;&#x2F;github.com&#x2F;RichardKelley&#x2F;hflm?tab=readme-ov-file#lmg...</a></div><br/></div></div><div id="41287196" class="c"><input type="checkbox" id="c-41287196" checked=""/><div class="controls bullet"><span class="by">eru</span><span>|</span><a href="#41287082">root</a><span>|</span><a href="#41287098">parent</a><span>|</span><a href="#41287358">prev</a><span>|</span><a href="#41287827">next</a><span>|</span><label class="collapse" for="c-41287196">[-]</label><label class="expand" for="c-41287196">[4 more]</label></div><br/><div class="children"><div class="content">Some of the open-weights models come close to what you might want?</div><br/><div id="41287342" class="c"><input type="checkbox" id="c-41287342" checked=""/><div class="controls bullet"><span class="by">dartos</span><span>|</span><a href="#41287082">root</a><span>|</span><a href="#41287196">parent</a><span>|</span><a href="#41287827">next</a><span>|</span><label class="collapse" for="c-41287342">[-]</label><label class="expand" for="c-41287342">[3 more]</label></div><br/><div class="children"><div class="content">Sort of. They fill the “locked” requirement, but open models aren’t SOTA like gpt or Claud.</div><br/><div id="41287447" class="c"><input type="checkbox" id="c-41287447" checked=""/><div class="controls bullet"><span class="by">coder543</span><span>|</span><a href="#41287082">root</a><span>|</span><a href="#41287342">parent</a><span>|</span><a href="#41287458">next</a><span>|</span><label class="collapse" for="c-41287447">[-]</label><label class="expand" for="c-41287447">[1 more]</label></div><br/><div class="children"><div class="content">Llama3.1-405B benchmarks at a level that I would certainly consider comparable to other SOTA models, as long as multimodality isn’t needed.<p>Regardless, OpenAI provides access to quite a few of their older models through the API, since the API lets you pass in a specific model version. I’m sure the older models won’t be available forever,  but that is a much more stable target for researchers than just opening the ChatGPT website and typing in things.</div><br/></div></div><div id="41287458" class="c"><input type="checkbox" id="c-41287458" checked=""/><div class="controls bullet"><span class="by">Reubend</span><span>|</span><a href="#41287082">root</a><span>|</span><a href="#41287342">parent</a><span>|</span><a href="#41287447">prev</a><span>|</span><a href="#41287827">next</a><span>|</span><label class="collapse" for="c-41287458">[-]</label><label class="expand" for="c-41287458">[1 more]</label></div><br/><div class="children"><div class="content">LLAMA 3.1 405b-Instruct is state of the art at the time of writing. It averages slightly worse than ChatGPT 4o, but to a mostly negligible extent for most research.</div><br/></div></div></div></div></div></div><div id="41287827" class="c"><input type="checkbox" id="c-41287827" checked=""/><div class="controls bullet"><span class="by">jijji</span><span>|</span><a href="#41287082">root</a><span>|</span><a href="#41287098">parent</a><span>|</span><a href="#41287196">prev</a><span>|</span><a href="#41287422">next</a><span>|</span><label class="collapse" for="c-41287827">[-]</label><label class="expand" for="c-41287827">[1 more]</label></div><br/><div class="children"><div class="content">there sort of is, if you install ollama (<a href="https:&#x2F;&#x2F;ollama.com">https:&#x2F;&#x2F;ollama.com</a>) and then execute: ollama run llama2-uncensored it will install and run the local chat interface for llama2 in an uncensored version which gives a little bit better results with less guardrails.   Same with wizardlm-uncensored and wizard-vicuna-uncensored.  For reference, the SOTA version with guardrails you could run: ollama run llama3.1:405b</div><br/></div></div></div></div><div id="41287422" class="c"><input type="checkbox" id="c-41287422" checked=""/><div class="controls bullet"><span class="by">dankwizard</span><span>|</span><a href="#41287082">parent</a><span>|</span><a href="#41287098">prev</a><span>|</span><a href="#41287465">next</a><span>|</span><label class="collapse" for="c-41287422">[-]</label><label class="expand" for="c-41287422">[1 more]</label></div><br/><div class="children"><div class="content">you have no sense of humor</div><br/></div></div></div></div><div id="41287465" class="c"><input type="checkbox" id="c-41287465" checked=""/><div class="controls bullet"><span class="by">tombert</span><span>|</span><a href="#41287082">prev</a><span>|</span><a href="#41288137">next</a><span>|</span><label class="collapse" for="c-41287465">[-]</label><label class="expand" for="c-41287465">[1 more]</label></div><br/><div class="children"><div class="content">I am in a private Discord server that has two bots in it.  One is a bot that is a basic Markov chain trained on the entire chat history. The second is a proper LLM trained on some amount of tokens backward.  Both will occasionally just randomly chime in during the chat.<p>The markov chain bot is always considerably funnier.</div><br/></div></div><div id="41288137" class="c"><input type="checkbox" id="c-41288137" checked=""/><div class="controls bullet"><span class="by">magicalhippo</span><span>|</span><a href="#41287465">prev</a><span>|</span><a href="#41289013">next</a><span>|</span><label class="collapse" for="c-41288137">[-]</label><label class="expand" for="c-41288137">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve also enjoyed the Postmodernism essay generator[1], which uses[2] a recursive transition network[3] to generate the text.<p>[1]: <a href="https:&#x2F;&#x2F;www.elsewhere.org&#x2F;journal&#x2F;pomo&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.elsewhere.org&#x2F;journal&#x2F;pomo&#x2F;</a> (refresh for new, random essay)<p>[2]: <a href="https:&#x2F;&#x2F;www.elsewhere.org&#x2F;journal&#x2F;wp-content&#x2F;uploads&#x2F;2005&#x2F;11&#x2F;tr-cs96-264.pdf" rel="nofollow">https:&#x2F;&#x2F;www.elsewhere.org&#x2F;journal&#x2F;wp-content&#x2F;uploads&#x2F;2005&#x2F;11...</a><p>[3]: <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Recursive_transition_network" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Recursive_transition_network</a></div><br/></div></div><div id="41289013" class="c"><input type="checkbox" id="c-41289013" checked=""/><div class="controls bullet"><span class="by">yarg</span><span>|</span><a href="#41288137">prev</a><span>|</span><a href="#41288519">next</a><span>|</span><label class="collapse" for="c-41289013">[-]</label><label class="expand" for="c-41289013">[1 more]</label></div><br/><div class="children"><div class="content">Unserious surprise summarised it nicely for me;<p>It does not mean that Markov chains are better - something trained to make predictions should ideally not fall too far away from our own internal prediction engines (which have been honed across aeons).<p>It&#x27;s that it starts to come close that&#x27;s the problem (or cause); it&#x27;s the uncanny valley for text.</div><br/></div></div><div id="41288519" class="c"><input type="checkbox" id="c-41288519" checked=""/><div class="controls bullet"><span class="by">_emacsomancer_</span><span>|</span><a href="#41289013">prev</a><span>|</span><a href="#41288848">next</a><span>|</span><label class="collapse" for="c-41288519">[-]</label><label class="expand" for="c-41288519">[1 more]</label></div><br/><div class="children"><div class="content">Funnily enough, I was idly playing with a last-updated-12-years-ago Markov chain text generator[0] in Emacs, and had quickly a number of amusing Markov chain outputs from mash-ups of the Elisp manual and Alice in Wonderland, including:<p>&quot;13.7 Anonymous Functions<p>Although functions are usually defined with the built-in defmacro macro, but any
list that begins with an M--&#x27;<p>`Why with an M?&#x27; said Alice.<p>`Why not?&#x27; said the March Hare.&quot;<p>[0]: <a href="https:&#x2F;&#x2F;github.com&#x2F;skeeto&#x2F;markov-text">https:&#x2F;&#x2F;github.com&#x2F;skeeto&#x2F;markov-text</a></div><br/></div></div><div id="41288848" class="c"><input type="checkbox" id="c-41288848" checked=""/><div class="controls bullet"><span class="by">ku1ik</span><span>|</span><a href="#41288519">prev</a><span>|</span><a href="#41287397">next</a><span>|</span><label class="collapse" for="c-41288848">[-]</label><label class="expand" for="c-41288848">[1 more]</label></div><br/><div class="children"><div class="content">This is something people miss when talking about LLMs: „It’s the most average thing you could have possibly produced given the context.”<p>They can’t be creative by design. They’re useful when you want to reproduce, but not when you want to create something completely new (that you can maybe do by getting a bunch of average outputs from an LLM and getting inspired yourself).<p>When GPT-4 came out I was playing with it, and I often tried to get some unique, creative output from it, but very soon I learned it was futile. It was back when it all still felt magical, and I guess many of us tried various things with it.</div><br/></div></div><div id="41287397" class="c"><input type="checkbox" id="c-41287397" checked=""/><div class="controls bullet"><span class="by">meowface</span><span>|</span><a href="#41288848">prev</a><span>|</span><a href="#41286911">next</a><span>|</span><label class="collapse" for="c-41287397">[-]</label><label class="expand" for="c-41287397">[1 more]</label></div><br/><div class="children"><div class="content">Many years ago I trained a Markov chain chat bot on all of the conversation history in a group chat with me and my friends. It was regularly incredibly hilarious. I also would train it on subsets of them, like two of the friends but no one else, and name that version of the bot a combination of their names. Something about it was just so funny.</div><br/></div></div><div id="41286911" class="c"><input type="checkbox" id="c-41286911" checked=""/><div class="controls bullet"><span class="by">AdieuToLogic</span><span>|</span><a href="#41287397">prev</a><span>|</span><a href="#41288754">next</a><span>|</span><label class="collapse" for="c-41286911">[-]</label><label class="expand" for="c-41286911">[8 more]</label></div><br/><div class="children"><div class="content">&gt; Asking an LLM for an “original thought” is almost oxymoronic, if not just moronic. It was built with the express purpose of not doing that.<p>What a wonderful insight.</div><br/><div id="41287202" class="c"><input type="checkbox" id="c-41287202" checked=""/><div class="controls bullet"><span class="by">eru</span><span>|</span><a href="#41286911">parent</a><span>|</span><a href="#41287083">next</a><span>|</span><label class="collapse" for="c-41287202">[-]</label><label class="expand" for="c-41287202">[2 more]</label></div><br/><div class="children"><div class="content">I can&#x27;t tell whether you are sarcastic?<p>I assume you are, because that makes more sense.<p>It&#x27;s really easy to get lots and lots of originality.  Just crank up the randomness.  What&#x27;s harder is to get something that&#x27;s good and original.</div><br/><div id="41288046" class="c"><input type="checkbox" id="c-41288046" checked=""/><div class="controls bullet"><span class="by">vidarh</span><span>|</span><a href="#41286911">root</a><span>|</span><a href="#41287202">parent</a><span>|</span><a href="#41287083">next</a><span>|</span><label class="collapse" for="c-41288046">[-]</label><label class="expand" for="c-41288046">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s hard for humans too. Perhaps if one tries to interspers &quot;internal monologue&quot; with the temperature cranked up, with the main output, and prompting the LLM to consider and weave in aspects from the inner monologue when continuing while taking care to make it coherent... (I&#x27;m sure it&#x27;d be harder than that - but basically inject random internal &quot;thoughts&quot; without letting them <i>control</i> the output)</div><br/></div></div></div></div><div id="41287083" class="c"><input type="checkbox" id="c-41287083" checked=""/><div class="controls bullet"><span class="by">make3</span><span>|</span><a href="#41286911">parent</a><span>|</span><a href="#41287202">prev</a><span>|</span><a href="#41288754">next</a><span>|</span><label class="collapse" for="c-41287083">[-]</label><label class="expand" for="c-41287083">[5 more]</label></div><br/><div class="children"><div class="content">also, not really true, right, even though it sounds intellectual and strong to say. these algorithms are trained to generalize as best as they can to unseen text, and most often don&#x27;t ever see any data point twice, except for data that has accidentally not been filtered. it&#x27;s totally possible that it gets reasoning abilities that generalize well.</div><br/><div id="41287119" class="c"><input type="checkbox" id="c-41287119" checked=""/><div class="controls bullet"><span class="by">lossolo</span><span>|</span><a href="#41286911">root</a><span>|</span><a href="#41287083">parent</a><span>|</span><a href="#41288754">next</a><span>|</span><label class="collapse" for="c-41287119">[-]</label><label class="expand" for="c-41287119">[4 more]</label></div><br/><div class="children"><div class="content">Generalize over their training data—they cannot generalize out of distribution. If they could, they would have already solved most human problems. So no, they do not generalize on unseen text. They will produce what is most statistically probable based on their training data. Things that are still unknown and statistically improbable based on our current knowledge are out of reach for LLMs based on transformers.</div><br/><div id="41288058" class="c"><input type="checkbox" id="c-41288058" checked=""/><div class="controls bullet"><span class="by">vidarh</span><span>|</span><a href="#41286911">root</a><span>|</span><a href="#41287119">parent</a><span>|</span><a href="#41287145">next</a><span>|</span><label class="collapse" for="c-41288058">[-]</label><label class="expand" for="c-41288058">[1 more]</label></div><br/><div class="children"><div class="content">You can get them to solve unseen problems just fine. E.g. one example: Specify a grammar in BNF notation and tell it to generate or parse sentences for you. You can produce a more than random enough grammar that it it can&#x27;t have derived the parsing of it from past text, but necessarily reasons about BNF notation sufficiently well to be able to use it to deduce the grammar, and use that to parse subsequent sentences. You can have it analyse them and tag them according to the grammar to. And generate sentences.<p>My impression, from seeing quite a few people trying to demonstrate they can&#x27;t handle out of distribution problems it hat people are <i>very</i> predictable about how they go about this, and tend to pick well known problems that are likely to be overrepresented in the training set, and then tweak them a bit.<p>At least in one instance the other day, what I got from GPT when I tried to replicate it suggests to me it did the same that humans that have seen these problems before did, and carelessly failed to &quot;pay attention&quot; because it fit a well known template it&#x27;s been exposed to a lot in training. After it answered wrong it was sufficient to ask it to &quot;review the question and answer again&quot; for it to spot the mistake and correct itself.<p>I&#x27;m sure that won&#x27;t work for every problem of this sort, but the quality of tests people do on LLMs is really awful, at least because people tend to do very narrow tests like that and make broad pronouncements about what LLM&#x27;s &quot;can&#x27;t&quot; do based on it.</div><br/></div></div><div id="41287145" class="c"><input type="checkbox" id="c-41287145" checked=""/><div class="controls bullet"><span class="by">totetsu</span><span>|</span><a href="#41286911">root</a><span>|</span><a href="#41287119">parent</a><span>|</span><a href="#41288058">prev</a><span>|</span><a href="#41287130">next</a><span>|</span><label class="collapse" for="c-41287145">[-]</label><label class="expand" for="c-41287145">[1 more]</label></div><br/><div class="children"><div class="content">Couldn&#x27;t they show up new as yet unknown things, if they are statistically probable given the training data</div><br/></div></div><div id="41287130" class="c"><input type="checkbox" id="c-41287130" checked=""/><div class="controls bullet"><span class="by">make3</span><span>|</span><a href="#41286911">root</a><span>|</span><a href="#41287119">parent</a><span>|</span><a href="#41287145">prev</a><span>|</span><a href="#41288754">next</a><span>|</span><label class="collapse" for="c-41287130">[-]</label><label class="expand" for="c-41287130">[1 more]</label></div><br/><div class="children"><div class="content">&quot;generalize to its dataset&quot; is a contradiction, especially as these models are trained in the one epoch regimen on datasets of the scale of all of the internet. if you think being able to generalize in ways similar to the whole of the internet does not give your meaningful abilities to reason, I&#x27;m not sure what I can tell you</div><br/></div></div></div></div></div></div></div></div><div id="41288754" class="c"><input type="checkbox" id="c-41288754" checked=""/><div class="controls bullet"><span class="by">raister</span><span>|</span><a href="#41286911">prev</a><span>|</span><a href="#41287057">next</a><span>|</span><label class="collapse" for="c-41288754">[-]</label><label class="expand" for="c-41288754">[1 more]</label></div><br/><div class="children"><div class="content">For anyone interested, I&#x27;ve wrote a while ago this book: &quot;Markov Chains for programmers&quot;. Link: <a href="https:&#x2F;&#x2F;czekster.github.io&#x2F;markov&#x2F;" rel="nofollow">https:&#x2F;&#x2F;czekster.github.io&#x2F;markov&#x2F;</a></div><br/></div></div><div id="41287057" class="c"><input type="checkbox" id="c-41287057" checked=""/><div class="controls bullet"><span class="by">canjobear</span><span>|</span><a href="#41288754">prev</a><span>|</span><a href="#41286414">next</a><span>|</span><label class="collapse" for="c-41287057">[-]</label><label class="expand" for="c-41287057">[1 more]</label></div><br/><div class="children"><div class="content">“Talk to Transformer” GPT-2 was very funny, then GPT-3 was not funny at all. We blew through the uncanny valley in a couple of years.</div><br/></div></div><div id="41286414" class="c"><input type="checkbox" id="c-41286414" checked=""/><div class="controls bullet"><span class="by">ggm</span><span>|</span><a href="#41287057">prev</a><span>|</span><a href="#41288828">next</a><span>|</span><label class="collapse" for="c-41286414">[-]</label><label class="expand" for="c-41286414">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Mark_V._Shaney" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Mark_V._Shaney</a></div><br/></div></div><div id="41288828" class="c"><input type="checkbox" id="c-41288828" checked=""/><div class="controls bullet"><span class="by">treprinum</span><span>|</span><a href="#41286414">prev</a><span>|</span><a href="#41287987">next</a><span>|</span><label class="collapse" for="c-41288828">[-]</label><label class="expand" for="c-41288828">[1 more]</label></div><br/><div class="children"><div class="content">Generative AI often uses Markov chains as its theoretical basis and is modeled in the language of conditional probabilities albeit not stuck to a single ancestor but to a chain of ancestors. One can often view LLMs as scaled out Markov chains (more like &quot;Erlang&quot; chains allowing deeper memory) that encode the probability of the next token based on the past of the size of the context window and then doing some magic when picking next tokens.</div><br/></div></div><div id="41287987" class="c"><input type="checkbox" id="c-41287987" checked=""/><div class="controls bullet"><span class="by">ineptech</span><span>|</span><a href="#41288828">prev</a><span>|</span><a href="#41288716">next</a><span>|</span><label class="collapse" for="c-41287987">[-]</label><label class="expand" for="c-41287987">[1 more]</label></div><br/><div class="children"><div class="content">Relatedly, the author Robert Anton Wilson tried to  manually implement a Markov-chain-bot in the 1960s by cutting up passages from various books, selecting them from a hat, and looking for overlapping words and phrase fragments.  The best results were included in the Illuminatus! trilogy, some attributed to a character named Markoff Chaney.</div><br/></div></div><div id="41288716" class="c"><input type="checkbox" id="c-41288716" checked=""/><div class="controls bullet"><span class="by">notjulianjaynes</span><span>|</span><a href="#41287987">prev</a><span>|</span><a href="#41289024">next</a><span>|</span><label class="collapse" for="c-41288716">[-]</label><label class="expand" for="c-41288716">[1 more]</label></div><br/><div class="children"><div class="content">In college (around 2012ish) I made some poems by transcribing a recording of myself mumbling gibberish into Dragon Naturally Speaking, which partially relied on Markov chains for its ASR. It would output some string of text, and then I&#x27;d delete all the words it output from its dictionary; repeat. It worked very well for creating a list of (slant) rhymes, I have not found a better way to do this. As a literary tool, I&#x27;ve found LLMs to be seriously lacking in the ability to fuck around like this.</div><br/></div></div><div id="41289024" class="c"><input type="checkbox" id="c-41289024" checked=""/><div class="controls bullet"><span class="by">paweladamczuk</span><span>|</span><a href="#41288716">prev</a><span>|</span><a href="#41287094">next</a><span>|</span><label class="collapse" for="c-41289024">[-]</label><label class="expand" for="c-41289024">[3 more]</label></div><br/><div class="children"><div class="content">Am I the only one feeling uneasy when the Bible is used for funny experiments like this?<p>Would you use an image of Christ on the cross to test an AI image modification model?</div><br/><div id="41289084" class="c"><input type="checkbox" id="c-41289084" checked=""/><div class="controls bullet"><span class="by">nly</span><span>|</span><a href="#41289024">parent</a><span>|</span><a href="#41287094">next</a><span>|</span><label class="collapse" for="c-41289084">[-]</label><label class="expand" for="c-41289084">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m sure most people here would given that like 50% of the world don&#x27;t believe in an Abrahamic religion, and a % of those that do have a sense of humour.</div><br/><div id="41289155" class="c"><input type="checkbox" id="c-41289155" checked=""/><div class="controls bullet"><span class="by">paweladamczuk</span><span>|</span><a href="#41289024">root</a><span>|</span><a href="#41289084">parent</a><span>|</span><a href="#41287094">next</a><span>|</span><label class="collapse" for="c-41289155">[-]</label><label class="expand" for="c-41289155">[1 more]</label></div><br/><div class="children"><div class="content">I wouldn&#x27;t. And not because I believe it or lack a sense of humour.</div><br/></div></div></div></div></div></div><div id="41287094" class="c"><input type="checkbox" id="c-41287094" checked=""/><div class="controls bullet"><span class="by">trescenzi</span><span>|</span><a href="#41289024">prev</a><span>|</span><a href="#41287056">next</a><span>|</span><label class="collapse" for="c-41287094">[-]</label><label class="expand" for="c-41287094">[4 more]</label></div><br/><div class="children"><div class="content">Reminds me of how the fake magic cards before chatgpt were always hilarious and sometimes playable, now they are usually playable and sometimes hilarious. Definitively a downgrade if you’d ask me.</div><br/><div id="41287188" class="c"><input type="checkbox" id="c-41287188" checked=""/><div class="controls bullet"><span class="by">JoshTriplett</span><span>|</span><a href="#41287094">parent</a><span>|</span><a href="#41287056">next</a><span>|</span><label class="collapse" for="c-41287188">[-]</label><label class="expand" for="c-41287188">[3 more]</label></div><br/><div class="children"><div class="content">&gt; always hilarious and sometimes playable<p>I saw plenty of those back then, and as far as I could tell, examples were <i>always</i> cherry-picked from a larger set.</div><br/><div id="41287544" class="c"><input type="checkbox" id="c-41287544" checked=""/><div class="controls bullet"><span class="by">stochaztic</span><span>|</span><a href="#41287094">root</a><span>|</span><a href="#41287188">parent</a><span>|</span><a href="#41287466">next</a><span>|</span><label class="collapse" for="c-41287544">[-]</label><label class="expand" for="c-41287544">[1 more]</label></div><br/><div class="children"><div class="content">Yes, I ran the RoboRosewater account, which is where most people saw the concept I believe. I had a few documents with thousands of cards of output, went through them for any notable ones, and formatted and posted them. Probably 5-10% of the output made my personal cut for notability.</div><br/></div></div><div id="41287466" class="c"><input type="checkbox" id="c-41287466" checked=""/><div class="controls bullet"><span class="by">kibibu</span><span>|</span><a href="#41287094">root</a><span>|</span><a href="#41287188">parent</a><span>|</span><a href="#41287544">prev</a><span>|</span><a href="#41287056">next</a><span>|</span><label class="collapse" for="c-41287466">[-]</label><label class="expand" for="c-41287466">[1 more]</label></div><br/><div class="children"><div class="content">Maybe the right solution is using a Markov chain or gpt1 to generate ideas and an LLM to cherry pick.</div><br/></div></div></div></div></div></div><div id="41287056" class="c"><input type="checkbox" id="c-41287056" checked=""/><div class="controls bullet"><span class="by">complaintdept</span><span>|</span><a href="#41287094">prev</a><span>|</span><a href="#41288697">next</a><span>|</span><label class="collapse" for="c-41287056">[-]</label><label class="expand" for="c-41287056">[3 more]</label></div><br/><div class="children"><div class="content">My favorite markov experiment was feeding it the works of Nietzsche from Project Gutenberg. Really brought out the late stage syphilis, but was still very distinctly Nietzsche.</div><br/><div id="41287091" class="c"><input type="checkbox" id="c-41287091" checked=""/><div class="controls bullet"><span class="by">techjamie</span><span>|</span><a href="#41287056">parent</a><span>|</span><a href="#41288697">next</a><span>|</span><label class="collapse" for="c-41287091">[-]</label><label class="expand" for="c-41287091">[2 more]</label></div><br/><div class="children"><div class="content">I love messing with Markov chains, and before Reddit dunked their API, I would feed my Markov chain comments from NSFW subreddits and political subreddits at different sample sizes. I would spend ages just watching it whiplash about some political topic and sampling thirst comments.</div><br/><div id="41287220" class="c"><input type="checkbox" id="c-41287220" checked=""/><div class="controls bullet"><span class="by">duskwuff</span><span>|</span><a href="#41287056">root</a><span>|</span><a href="#41287091">parent</a><span>|</span><a href="#41288697">next</a><span>|</span><label class="collapse" for="c-41287220">[-]</label><label class="expand" for="c-41287220">[1 more]</label></div><br/><div class="children"><div class="content">The live feeds are all dead now, but you can still download archives of Reddit posts&#x2F;comments from before they locked down the API:<p><a href="https:&#x2F;&#x2F;academictorrents.com&#x2F;details&#x2F;9c263fc85366c1ef8f5bb9da0203f4c8c8db75f4" rel="nofollow">https:&#x2F;&#x2F;academictorrents.com&#x2F;details&#x2F;9c263fc85366c1ef8f5bb9d...</a></div><br/></div></div></div></div></div></div><div id="41288697" class="c"><input type="checkbox" id="c-41288697" checked=""/><div class="controls bullet"><span class="by">larodi</span><span>|</span><a href="#41287056">prev</a><span>|</span><a href="#41287659">next</a><span>|</span><label class="collapse" for="c-41288697">[-]</label><label class="expand" for="c-41288697">[1 more]</label></div><br/><div class="children"><div class="content">Markov chains are funnier for one very basic reason:<p>you can teach them to 5th or 9th graders.<p>LLMS you can not, or at least it will take insane amount of allegory to do so. Markov chains are very tightly related regex, and one may be surprised that there is a probabilistic regex. Also to the graphical structure of Markov chains  is a lot like a FSM, and FSM perhaps can be explained to very small children :D</div><br/></div></div><div id="41287659" class="c"><input type="checkbox" id="c-41287659" checked=""/><div class="controls bullet"><span class="by">johntb86</span><span>|</span><a href="#41288697">prev</a><span>|</span><a href="#41288279">next</a><span>|</span><label class="collapse" for="c-41287659">[-]</label><label class="expand" for="c-41287659">[1 more]</label></div><br/><div class="children"><div class="content">LLMs can be funny. For example, look at Golden Gate Claude ( <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=40459543">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=40459543</a> ). But they&#x27;re not good at intentionally being funny, so we need to break them to get absurdist humor instead.</div><br/></div></div><div id="41288279" class="c"><input type="checkbox" id="c-41288279" checked=""/><div class="controls bullet"><span class="by">atoav</span><span>|</span><a href="#41287659">prev</a><span>|</span><a href="#41288924">next</a><span>|</span><label class="collapse" for="c-41288279">[-]</label><label class="expand" for="c-41288279">[1 more]</label></div><br/><div class="children"><div class="content">The cool thing about market chains is that you can tune the probability with which it will jump between &quot;genres&quot; of it&#x27;s training-content by making the analyzed N-Grams shorter or longer.<p>E.g. it starts out as a news headline and ends with a bible verse.</div><br/></div></div><div id="41288924" class="c"><input type="checkbox" id="c-41288924" checked=""/><div class="controls bullet"><span class="by">benob</span><span>|</span><a href="#41288279">prev</a><span>|</span><a href="#41287690">next</a><span>|</span><label class="collapse" for="c-41288924">[-]</label><label class="expand" for="c-41288924">[1 more]</label></div><br/><div class="children"><div class="content">LLMs are high-order Markov chains with a factored estimator. N-gram LMs are also Markov chains with a different estimator.</div><br/></div></div><div id="41287690" class="c"><input type="checkbox" id="c-41287690" checked=""/><div class="controls bullet"><span class="by">cancerhacker</span><span>|</span><a href="#41288924">prev</a><span>|</span><label class="collapse" for="c-41287690">[-]</label><label class="expand" for="c-41287690">[2 more]</label></div><br/><div class="children"><div class="content">Surprised no mention of. “The Policeman’s Beard is half constructed”[1] - the first book “written” by a computer program. And I imagine the git-man-page-generator[2] is similarly built (and far more fun!)<p>[1] <a href="https:&#x2F;&#x2F;archive.org&#x2F;details&#x2F;policemansbeardi0000unse" rel="nofollow">https:&#x2F;&#x2F;archive.org&#x2F;details&#x2F;policemansbeardi0000unse</a>
 [2] <a href="https:&#x2F;&#x2F;git-man-page-generator.lokaltog.net&#x2F;" rel="nofollow">https:&#x2F;&#x2F;git-man-page-generator.lokaltog.net&#x2F;</a></div><br/><div id="41287812" class="c"><input type="checkbox" id="c-41287812" checked=""/><div class="controls bullet"><span class="by">cout</span><span>|</span><a href="#41287690">parent</a><span>|</span><label class="collapse" for="c-41287812">[-]</label><label class="expand" for="c-41287812">[1 more]</label></div><br/><div class="children"><div class="content">They had their love, but they also had their typewriters.</div><br/></div></div></div></div></div></div></div></div></div></body></html>