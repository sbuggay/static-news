<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1723194080904" as="style"/><link rel="stylesheet" href="styles.css?v=1723194080904"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://thechipletter.substack.com/p/intels-immiseration">Intel&#x27;s Immiseration</a> <span class="domain">(<a href="https://thechipletter.substack.com">thechipletter.substack.com</a>)</span></div><div class="subtext"><span>rbanffy</span> | <span>157 comments</span></div><br/><div><div id="41195300" class="c"><input type="checkbox" id="c-41195300" checked=""/><div class="controls bullet"><span class="by">PaulHoule</span><span>|</span><a href="#41195690">next</a><span>|</span><label class="collapse" for="c-41195300">[-]</label><label class="expand" for="c-41195300">[90 more]</label></div><br/><div class="children"><div class="content">The biggest problem I&#x27;ve seen with Intel is that they are &quot;getting high on their own supply&quot; and the whole tech press enables them with the sole exception of Charlie Demerjian.<p>They should pick a few random people out of the phone book and pay them handsomely for their advice,  this way they might start to &quot;see themselves as other see them&quot;.  Most of all they need to recognize the phenomenon of &quot;brand destruction&quot; which has manifest in clueless campaigns such as &quot;Ultrabooks&quot;,  brands that should have been killed off years ago (&quot;Celeron&quot;,  sorry,  low performance brands have a shelf life,  there&#x27;s a reason why Honda is still making the Civic but GM is not making the Chevette) and that they should write it in their bylaws that they are getting out of the GPU business permanently (they&#x27;ve made so many awful products it will take 15 years for people to get the idea that an Intel GPU adds value,  instead it&#x27;s this awful thing you have to turn off so that it won&#x27;t screw up graphics in your web browser when you&#x27;re using a Discrete GPU.)  People might get their heads around the idea that an Intel CPU is a premium brand <i>if</i> it had a GPU chiplet from a reputable manufacturer like AMD or NVIDIA.<p>(Oddly when Intel has had a truly premium brand,  as in SSDs,  they&#x27;ve ignored it.  Hardly anybody noticed the great 95% latency performance that of Intel SSDs because hardly anybody realizes that 95% latency is <i>what you feel when your computer feels slow</i>.  Intel SSDs were one Intel product that I would seek out by name,  at least until they sold their SSD division.  Most people who&#x27;ve run a lot of Intel SSDs swear by them.)</div><br/><div id="41195542" class="c"><input type="checkbox" id="c-41195542" checked=""/><div class="controls bullet"><span class="by">Miraste</span><span>|</span><a href="#41195300">parent</a><span>|</span><a href="#41195544">next</a><span>|</span><label class="collapse" for="c-41195542">[-]</label><label class="expand" for="c-41195542">[43 more]</label></div><br/><div class="children"><div class="content">A lot of these are symptoms of the root cause: a bad product. Ultrabooks aren&#x27;t a terrible concept; they&#x27;re the Wintel version of Macbook Airs. Making a non-Apple Apple device is a fine business strategy, and Samsung has made plenty of money off of it. The problem was that Intel chips continually crippled them, making them hot and slow with no battery life. People don&#x27;t like Celerons and iGPUs because they all run at the speed of molasses.<p>Any of these branding decisions would have worked fine, if the products did. But no amount of marketing will fix bad engineering.</div><br/><div id="41199048" class="c"><input type="checkbox" id="c-41199048" checked=""/><div class="controls bullet"><span class="by">Panzer04</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41195542">parent</a><span>|</span><a href="#41196209">next</a><span>|</span><label class="collapse" for="c-41199048">[-]</label><label class="expand" for="c-41199048">[6 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think I agree at all with your assertions about ultrabooks and blaming intel CPUs.<p>To be honest, all x86 processors are reasonably efficient if you pick the right power points to run them at. My experience with my laptops is that windows will arbitrarily use 2-3x idle power draw while on battery for no apparent reason. There is no reason for a CPU to be running higher than idle the vast majority of the time in a laptop, for tasks that you would be using a laptop for on battery.<p>I think most laptops are just poorly designed and Windows isn&#x27;t reliable about using minimal power. MFGs make big laptops with 60whr batteries (instead of 100wh), they put bloatware on them that consume excess power at idle, MS Windows doesn&#x27;t reliably ensure low power consumption on battery (seriously, I have to hibernate&#x2F;shut down my laptop when I stop using it, otherwise it will consume its entire battery in 8hrs during sleep mode, somehow), and so on. Most problems with Windows laptops aren&#x27;t Intel&#x27;s fault, IMO.<p>I agree that Intel really should clarify, at least, the difference between their &quot;Celeron&quot; class (e-core only) and &quot;Core&quot; class processors (with P cores), since there&#x27;s such a massive difference in performance capability between them.</div><br/><div id="41199160" class="c"><input type="checkbox" id="c-41199160" checked=""/><div class="controls bullet"><span class="by">WalterBright</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41199048">parent</a><span>|</span><a href="#41199412">next</a><span>|</span><label class="collapse" for="c-41199160">[-]</label><label class="expand" for="c-41199160">[1 more]</label></div><br/><div class="children"><div class="content">&gt; There is no reason for a CPU to be running higher than idle the vast majority of the time in a laptop, for tasks that you would be using a laptop for on battery.<p>True. I once got suspicious and opened the process list window. I had installed a server so I could stream to my Roku device, and I wasn&#x27;t streaming, yet the server was sucking up quite a bit of compute time, all the time.<p>I uninstalled it.</div><br/></div></div><div id="41199412" class="c"><input type="checkbox" id="c-41199412" checked=""/><div class="controls bullet"><span class="by">Dalewyn</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41199048">parent</a><span>|</span><a href="#41199160">prev</a><span>|</span><a href="#41199453">next</a><span>|</span><label class="collapse" for="c-41199412">[-]</label><label class="expand" for="c-41199412">[2 more]</label></div><br/><div class="children"><div class="content">&gt;Most problems with Windows laptops aren&#x27;t Intel&#x27;s fault, IMO.<p>Intel works very thoroughly with Microsoft, and it is <i>absolutely</i> on Intel for bringing forth the most inexcusable failure mode: Laptops &quot;sleeping&quot; with the CPU still on and proceeding to cook themselves in your backpack because they thought they were still on mains power.<p>Why is this on Intel? Because they removed a C-state that actually slept properly in favor of a C-state that theoretically saved more power but in practice almost never works with how people <i>actually</i> use laptops.<p>AMD might also share the blame here. I don&#x27;t know, because I don&#x27;t care to know further with how stupid everything is.</div><br/><div id="41199538" class="c"><input type="checkbox" id="c-41199538" checked=""/><div class="controls bullet"><span class="by">Panzer04</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41199412">parent</a><span>|</span><a href="#41199453">next</a><span>|</span><label class="collapse" for="c-41199538">[-]</label><label class="expand" for="c-41199538">[1 more]</label></div><br/><div class="children"><div class="content">Agree on the sleep state stuff. idk who&#x27;s fault it really is, but at least on the software front I mostly blame microsoft, because it&#x27;s really their duty to deliver consistent, reliable power consumption on battery power.</div><br/></div></div></div></div><div id="41199453" class="c"><input type="checkbox" id="c-41199453" checked=""/><div class="controls bullet"><span class="by">wwtrv</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41199048">parent</a><span>|</span><a href="#41199412">prev</a><span>|</span><a href="#41196209">next</a><span>|</span><label class="collapse" for="c-41199453">[-]</label><label class="expand" for="c-41199453">[2 more]</label></div><br/><div class="children"><div class="content">&gt; will arbitrarily use 2-3x idle power draw while on battery for no apparent reason<p>You might be thinking about Linux? IIRC OS X wasn&#x27;t particularly impressive about that back in the x86 days and high-end Macs had horrible battery life.</div><br/><div id="41199522" class="c"><input type="checkbox" id="c-41199522" checked=""/><div class="controls bullet"><span class="by">Panzer04</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41199453">parent</a><span>|</span><a href="#41196209">next</a><span>|</span><label class="collapse" for="c-41199522">[-]</label><label class="expand" for="c-41199522">[1 more]</label></div><br/><div class="children"><div class="content">No, this is Windows. It absolutely can use minimal power, but my experience closely monitoring my laptops consumption is it will regularly spike from 5-6w to 15-20w for extended periods, which obviously obliterates battery life. I&#x27;ve been unable to figure out why.<p>My particular specimen came with a 97wh battery (XPS), so it would be able to linger on for ~10+hrs if it could maintain its idle power consumption with brief spikes to do work, but in reality it&#x27;s basically always less than that in my experience (and worse, its inconsistent as hell about it).<p>The other issue is sleep states, which as another commenter mentions leads to laptops using all of their battery in your backpack so it&#x27;s dead by the time you actually try to use it :&#x27;(<p>It&#x27;s made worse by comparison to modern phones, which deliver reliable, consistent power consumption throughout the day - so a laptop that regularly lasts a fraction of the time and doesn&#x27;t know how to sleep just looks awful by comparison.</div><br/></div></div></div></div></div></div><div id="41196209" class="c"><input type="checkbox" id="c-41196209" checked=""/><div class="controls bullet"><span class="by">adrian_b</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41195542">parent</a><span>|</span><a href="#41199048">prev</a><span>|</span><a href="#41198957">next</a><span>|</span><label class="collapse" for="c-41196209">[-]</label><label class="expand" for="c-41196209">[3 more]</label></div><br/><div class="children"><div class="content">While the Intel laptop CPUs may have been not good enough, that is not where Intel has lost money.<p>The current financial results have shown decent profits for the consumer CPUs, which could have been greater if Intel had succeeded to produce more Meteor Lake CPUs. Intel could not produce as many Meteor Lake CPUs as the demand because their new Intel 4 manufacturing process has low production yields.<p>While Intel lost money in their foundry, that was unavoidable due to the high expenses needed for catching up with TSMC.<p>Where Intel had great losses was in server CPUs. The reason for these losses must have been that Intel had to grant very large discounts to the big buyers of server CPUs, in order to convince them to not buy superior AMD server CPUs.<p>These losses in server CPUs were easily predictable, because even if Intel has succeeded to reach in time all the publicly announced milestones of their roadmap, their roadmap itself does not hope to reach parity with the AMD server CPUs before H2 2025 (and that assuming that AMD will not introduce Zen 6 during 2025, which would move the target).<p>It looks like Intel has made a PR mistake. Even if their public roadmap has shown all the time that they will continue to have big losses for at least one more year, that was obvious only for technical people, who could compare the future Intel products with the AMD products, because Intel has not said any word in their roadmap about what the competition will have at the same time. For non-technical people, the Intel press releases sounded more optimistic than they should have been, leading to disappointment caused by financial results that should not have been surprising.</div><br/><div id="41197139" class="c"><input type="checkbox" id="c-41197139" checked=""/><div class="controls bullet"><span class="by">Tuna-Fish</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41196209">parent</a><span>|</span><a href="#41198957">next</a><span>|</span><label class="collapse" for="c-41197139">[-]</label><label class="expand" for="c-41197139">[2 more]</label></div><br/><div class="children"><div class="content">&gt; The current financial results have shown decent profits for the consumer CPUs,<p>Only after serious financial alchemy. The client group has a decent op margin, but the foundry group has an absolutely terrible one, and the client group sells products that they buy (internally) from the foundry group at arbitrarily set prices. What would the client margins be if the internal price they pay for their products was set so that the foundry breaks even?</div><br/><div id="41200034" class="c"><input type="checkbox" id="c-41200034" checked=""/><div class="controls bullet"><span class="by">walterbell</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41197139">parent</a><span>|</span><a href="#41198957">next</a><span>|</span><label class="collapse" for="c-41200034">[-]</label><label class="expand" for="c-41200034">[1 more]</label></div><br/><div class="children"><div class="content">Are client margins different for Lunar Lake, where the compute&#x2F;platform tiles are made by TSMC?</div><br/></div></div></div></div></div></div><div id="41198957" class="c"><input type="checkbox" id="c-41198957" checked=""/><div class="controls bullet"><span class="by">jakobson14</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41195542">parent</a><span>|</span><a href="#41196209">prev</a><span>|</span><a href="#41195704">next</a><span>|</span><label class="collapse" for="c-41198957">[-]</label><label class="expand" for="c-41198957">[1 more]</label></div><br/><div class="children"><div class="content">ultimately it was a focus on marketing that led them to kill engineering<p>(if itanium and the many failures and lucky breaks that led up to it hadn&#x27;t already convinced you that intel might never have had good engineering)</div><br/></div></div><div id="41195704" class="c"><input type="checkbox" id="c-41195704" checked=""/><div class="controls bullet"><span class="by">soulbadguy</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41195542">parent</a><span>|</span><a href="#41198957">prev</a><span>|</span><a href="#41196388">next</a><span>|</span><label class="collapse" for="c-41195704">[-]</label><label class="expand" for="c-41195704">[2 more]</label></div><br/><div class="children"><div class="content">bad product is a symptoms of a even deeper cause... Lack of competition. The decline of intel started long ago. The financial results here are just very very lagging indicator of that. The lack of competition combined with very agressive anti competitive practice allow them to survive on pretty bad product line.
In a healthy market, competition would have force intel to improve well before the point we are now</div><br/><div id="41198969" class="c"><input type="checkbox" id="c-41198969" checked=""/><div class="controls bullet"><span class="by">jakobson14</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41195704">parent</a><span>|</span><a href="#41196388">next</a><span>|</span><label class="collapse" for="c-41198969">[-]</label><label class="expand" for="c-41198969">[1 more]</label></div><br/><div class="children"><div class="content">They are only moving because AMD is finally providing that competition, but it&#x27;s not fair to say that &quot;if only AMD had gotten their act together sooner, intel would be a better comapny.&quot;<p>Ultimately, intel chose to let intel rot while AMD was out of the picture. (ignoring that intel&#x27;s backroom deals with Dell and co. are a big part of what pushed AMD out)</div><br/></div></div></div></div><div id="41196388" class="c"><input type="checkbox" id="c-41196388" checked=""/><div class="controls bullet"><span class="by">einpoklum</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41195542">parent</a><span>|</span><a href="#41195704">prev</a><span>|</span><a href="#41195544">next</a><span>|</span><label class="collapse" for="c-41196388">[-]</label><label class="expand" for="c-41196388">[30 more]</label></div><br/><div class="children"><div class="content">&gt; Ultrabooks aren&#x27;t a terrible concept; they&#x27;re the Wintel version of Macbook Airs.<p>I&#x27;d say both are a terrible concept. I mean, it sells, but it&#x27;s still terrible. A laptop being thin is not really such a virtue and people&#x27;s life would be better with a decent-travel keyboard, better heat dissipation and more ports than with 5-10mm less laptop height.</div><br/><div id="41199462" class="c"><input type="checkbox" id="c-41199462" checked=""/><div class="controls bullet"><span class="by">wwtrv</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41196388">parent</a><span>|</span><a href="#41196736">next</a><span>|</span><label class="collapse" for="c-41199462">[-]</label><label class="expand" for="c-41199462">[1 more]</label></div><br/><div class="children"><div class="content">&gt; people&#x27;s life would be better with a decent-travel keyboard<p>Most people don&#x27;t generally seem to agree with that, though (not explicitly, they just generally don&#x27;t prioritize things like that)</div><br/></div></div><div id="41196736" class="c"><input type="checkbox" id="c-41196736" checked=""/><div class="controls bullet"><span class="by">wtallis</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41196388">parent</a><span>|</span><a href="#41199462">prev</a><span>|</span><a href="#41197582">next</a><span>|</span><label class="collapse" for="c-41196736">[-]</label><label class="expand" for="c-41196736">[9 more]</label></div><br/><div class="children"><div class="content">Heat dissipation and lots of ports are why I have a desktop. I don&#x27;t want that from my MacBook Air. A fan isn&#x27;t necessary or desirable for a machine that is primarily used for web browsing, watching movies, and light gaming.</div><br/><div id="41198822" class="c"><input type="checkbox" id="c-41198822" checked=""/><div class="controls bullet"><span class="by">Groxx</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41196736">parent</a><span>|</span><a href="#41196933">next</a><span>|</span><label class="collapse" for="c-41198822">[-]</label><label class="expand" for="c-41198822">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve recently started using a fanless laptop as my primary day to day device, and 100% agreed I&#x27;m never going back.<p>I&#x27;ll give up a LOT of performance for silent and long battery life, because I find waiting a second occasionally <i>much</i> less annoying than a fan blasting randomly, or my legs baking.  SSDs have largely resolved the perceived UX latency issues that used to occur, CPUs and GPUs now are far more powerful than needed for everything but specialized stuff (compiling, encoding, stuff that intentionally maxes out the machine. Regular applications do not do this, on purpose, but they do regularly bog down on I&#x2F;O).<p>Though the screen on this thing is awful.</div><br/></div></div><div id="41196933" class="c"><input type="checkbox" id="c-41196933" checked=""/><div class="controls bullet"><span class="by">saulpw</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41196736">parent</a><span>|</span><a href="#41198822">prev</a><span>|</span><a href="#41197772">next</a><span>|</span><label class="collapse" for="c-41196933">[-]</label><label class="expand" for="c-41196933">[5 more]</label></div><br/><div class="children"><div class="content">You know what I want for my desktop, is a battery, so my computer doesn&#x27;t reboot when I lose power for 5 seconds.  Yes I know about UPSes, but they&#x27;re $100+ and unwieldy.  I just need 30 seconds grace period to save my work!<p>This is the main reason why I probably won&#x27;t get a desktop again.</div><br/><div id="41198119" class="c"><input type="checkbox" id="c-41198119" checked=""/><div class="controls bullet"><span class="by">chmod775</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41196933">parent</a><span>|</span><a href="#41197772">next</a><span>|</span><label class="collapse" for="c-41198119">[-]</label><label class="expand" for="c-41198119">[4 more]</label></div><br/><div class="children"><div class="content">Amortized cost of a desktop is like 1&#x2F;3rd that of a laptop of comparable performance. You&#x27;re willing to pay thousands more because you don&#x27;t want to pay for an UPS? This doesn&#x27;t check out.<p>The space argument makes more sense and from that I assume you&#x27;re in a space constrained apartment.<p>At the end of day I&#x27;m more curious what causes those intermittent power outages. Are you regularly tripping breakers?</div><br/><div id="41199008" class="c"><input type="checkbox" id="c-41199008" checked=""/><div class="controls bullet"><span class="by">saulpw</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41198119">parent</a><span>|</span><a href="#41197772">next</a><span>|</span><label class="collapse" for="c-41199008">[-]</label><label class="expand" for="c-41199008">[3 more]</label></div><br/><div class="children"><div class="content">It happens twice a year, it goes out neighborhood-wide during a storm or an animal chewed through something.<p>Anyway I don&#x27;t know where you get that &quot;amortized cost&quot; number.  They seem a lot closer in price than that to me.</div><br/><div id="41199063" class="c"><input type="checkbox" id="c-41199063" checked=""/><div class="controls bullet"><span class="by">Panzer04</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41199008">parent</a><span>|</span><a href="#41197772">next</a><span>|</span><label class="collapse" for="c-41199063">[-]</label><label class="expand" for="c-41199063">[2 more]</label></div><br/><div class="children"><div class="content">Depends on the class of performance you want. I think at the low end laptops are surprisingly cost-competitive with desktops, but if you want high-end laptops either don&#x27;t exist or are hilariously expensive.<p>Also depends on the type of laptop. A desktop-replacement laptop with extremely basic frame and screen (ie. cheap and shit) can have excellent specs at a competitive price, whereas an XPS or mac with a great screen, aluminium frame etc will be very expensive relative to the specification.</div><br/><div id="41200058" class="c"><input type="checkbox" id="c-41200058" checked=""/><div class="controls bullet"><span class="by">chmod775</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41199063">parent</a><span>|</span><a href="#41197772">next</a><span>|</span><label class="collapse" for="c-41200058">[-]</label><label class="expand" for="c-41200058">[1 more]</label></div><br/><div class="children"><div class="content">This. Additionally desktop parts last longer and can be upgraded individually. They also have good resale value, offsetting the cost of upgrades (especially true for GPUs).</div><br/></div></div></div></div></div></div></div></div></div></div><div id="41197772" class="c"><input type="checkbox" id="c-41197772" checked=""/><div class="controls bullet"><span class="by">the_af</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41196736">parent</a><span>|</span><a href="#41196933">prev</a><span>|</span><a href="#41197582">next</a><span>|</span><label class="collapse" for="c-41197772">[-]</label><label class="expand" for="c-41197772">[2 more]</label></div><br/><div class="children"><div class="content">For some of us, a laptop is essentially an easily movable desktop. It&#x27;s not portable as in &quot;I want to travel with it&quot;, it&#x27;s portable as in &quot;I can easily take it anywhere within my house&#x2F;office&quot;.<p>Those kind of &quot;movable desktops&quot; benefit from performance, additional ports, etc, and instead have little use for thinness or less weight.<p>I simply cannot see myself ever owning a bulky, noisy desktop ever again.</div><br/><div id="41198200" class="c"><input type="checkbox" id="c-41198200" checked=""/><div class="controls bullet"><span class="by">wtallis</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41197772">parent</a><span>|</span><a href="#41197582">next</a><span>|</span><label class="collapse" for="c-41198200">[-]</label><label class="expand" for="c-41198200">[1 more]</label></div><br/><div class="children"><div class="content">The desktop replacement segment of the laptop market exists, but does not undermine the validity of more portable machines or make a fanless laptop a terrible idea. The viability of desktop replacement notebooks <i>as desktop replacements</i> is in large part due to the efficiency gains driven by the demand for the other kind of laptop—the ones that are thin and light. A 5lb+ slab of a notebook is still a pretty constrained form factor compared to the thermals and acoustics of a mini tower desktop.<p>I can understand you characterizing desktops as bulky, but calling them <i>noisy</i> in comparison to desktop replacement laptops is ridiculously wrong. Small fans with restricted airflow are what makes computers noisy, and they&#x27;re much easier to avoid with a desktop form factor. Your laptop cannot <i>sustain</i> desktop performance without getting loud, and if it doesn&#x27;t get loud under sustained load it&#x27;s because your laptop is choosing to instead get slow.</div><br/></div></div></div></div></div></div><div id="41197582" class="c"><input type="checkbox" id="c-41197582" checked=""/><div class="controls bullet"><span class="by">katbyte</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41196388">parent</a><span>|</span><a href="#41196736">prev</a><span>|</span><a href="#41197200">next</a><span>|</span><label class="collapse" for="c-41197582">[-]</label><label class="expand" for="c-41197582">[3 more]</label></div><br/><div class="children"><div class="content">I would have agreed with you a couple months ago, but picked up an air for travel so I could leave the 15” MBP at home and I’m really enjoying it and appreciating how thin and light it is. Wouldn’t want it for home or office use but for occasional on the go use? Perfect. And I imagine for many it would suite their needs pretty well</div><br/><div id="41198846" class="c"><input type="checkbox" id="c-41198846" checked=""/><div class="controls bullet"><span class="by">blackoil</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41197582">parent</a><span>|</span><a href="#41197200">next</a><span>|</span><label class="collapse" for="c-41198846">[-]</label><label class="expand" for="c-41198846">[2 more]</label></div><br/><div class="children"><div class="content">Thin and Light are two independent variables, you can make a lightweight PC which still has good keyboard, thermals, repairable and ports by making it few mm thick. Its utility on the go comes primarily from weight and not thinness.</div><br/><div id="41199469" class="c"><input type="checkbox" id="c-41199469" checked=""/><div class="controls bullet"><span class="by">Dalewyn</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41198846">parent</a><span>|</span><a href="#41197200">next</a><span>|</span><label class="collapse" for="c-41199469">[-]</label><label class="expand" for="c-41199469">[1 more]</label></div><br/><div class="children"><div class="content">I travel frequently. Thinness is absolutely a significant mobility factor.<p>I actually hate thinness for the sake of being thin, I want practical amounts of USB-A ports and a god damn headphone jack. But a thinner laptop is easier to stow in my luggage and handle in space-limited environments like a hotel room desk or a seat table in an airliner or lounge.<p>Likewise, I don&#x27;t want a chungus portable phone from 1993, but I also want my smartphone to be thick enough to reasonably grasp and have a headphone jack.<p>This is also putting aside the fact that most people in general clearly prefer thinner and lighter computing over thicker and&#x2F;or heavier.<p>There are times and places for a bigly desktop replacement tabletop heavy enough to crush your kneecaps and hot enough to burn your skin, but most people don&#x27;t need that.</div><br/></div></div></div></div></div></div><div id="41197200" class="c"><input type="checkbox" id="c-41197200" checked=""/><div class="controls bullet"><span class="by">soulbadguy</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41196388">parent</a><span>|</span><a href="#41197582">prev</a><span>|</span><a href="#41196467">next</a><span>|</span><label class="collapse" for="c-41197200">[-]</label><label class="expand" for="c-41197200">[2 more]</label></div><br/><div class="children"><div class="content">There is nothing wrong about the concept of ultrabook. Just terrible implementation.</div><br/><div id="41199499" class="c"><input type="checkbox" id="c-41199499" checked=""/><div class="controls bullet"><span class="by">bee_rider</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41197200">parent</a><span>|</span><a href="#41196467">next</a><span>|</span><label class="collapse" for="c-41199499">[-]</label><label class="expand" for="c-41199499">[1 more]</label></div><br/><div class="children"><div class="content">The implementation is left up to the OEMs but they seem to have done pretty well. Thin and lights are in a pretty good spot overall.<p>Have people forgotten how bad laptops were in like 2010? Great big chunks of plastic that somehow still feel cheap and weightless, keyboard flex, mushy keys. They were really quite bad.</div><br/></div></div></div></div><div id="41196467" class="c"><input type="checkbox" id="c-41196467" checked=""/><div class="controls bullet"><span class="by">paganel</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41196388">parent</a><span>|</span><a href="#41197200">prev</a><span>|</span><a href="#41197029">next</a><span>|</span><label class="collapse" for="c-41196467">[-]</label><label class="expand" for="c-41196467">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t really care that much about brands nor laptops for that matter, but my M1 Air is really, really nice given the money I&#x27;ve paid for it. Why should I burden myself with carrying a big laptop thing when I can instead carry a Macbook Air that is much lighter and which does very good job?</div><br/></div></div><div id="41197029" class="c"><input type="checkbox" id="c-41197029" checked=""/><div class="controls bullet"><span class="by">askafriend</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41196388">parent</a><span>|</span><a href="#41196467">prev</a><span>|</span><a href="#41196493">next</a><span>|</span><label class="collapse" for="c-41197029">[-]</label><label class="expand" for="c-41197029">[9 more]</label></div><br/><div class="children"><div class="content">That&#x27;s wrong and the market has proven it. The M3 MacBook Air is the best computer for most people - period, not just best ultrabook or best laptop. There are almost no compromises for 99% of people&#x27;s usage.</div><br/><div id="41199078" class="c"><input type="checkbox" id="c-41199078" checked=""/><div class="controls bullet"><span class="by">Panzer04</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41197029">parent</a><span>|</span><a href="#41199843">next</a><span>|</span><label class="collapse" for="c-41199078">[-]</label><label class="expand" for="c-41199078">[4 more]</label></div><br/><div class="children"><div class="content">Well, I mean, if you ignore the 8GB RAM base model.. and the pricetag at 2-3x a similarly-performing windows equivalent, and probably +50% on similar screen windows equivalent.<p>I can make a great computer that meets everyone&#x27;s use cases for 2x the going price too :).<p>Unfortunately it is far too easy for a non-savvy person to walk into a store and buy a piece of shit windows laptop for the same price as a macbook, because they don&#x27;t know what they want or need and the salesmen aren&#x27;t that interested in making sure you get good value :&#x27;(</div><br/><div id="41199514" class="c"><input type="checkbox" id="c-41199514" checked=""/><div class="controls bullet"><span class="by">wwtrv</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41199078">parent</a><span>|</span><a href="#41199843">next</a><span>|</span><label class="collapse" for="c-41199514">[-]</label><label class="expand" for="c-41199514">[3 more]</label></div><br/><div class="children"><div class="content">&gt; and the pricetag at 2-3x a similarly-performing windows equivalent, and probably +50% on similar screen windows equivalent.<p>Can you actually list any of these &quot;equivalents&quot;? I&#x27;m actually genuinely curious<p>Just to get this straight you&#x27;re saying that you can get a Windows laptop that&#x27;s just as fast, has comparable battery life and build quality as an M3 Air for $400-650 (i.e. 1&#x2F;3 - 1&#x2F;2 of the cheapest 16 GB Air)? Really?<p>&gt; Unfortunately it is far too easy for a non-savvy person<p>So could you help those of use who are not that savvy by being more specific?</div><br/><div id="41199820" class="c"><input type="checkbox" id="c-41199820" checked=""/><div class="controls bullet"><span class="by">Rinzler89</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41199514">parent</a><span>|</span><a href="#41199805">next</a><span>|</span><label class="collapse" for="c-41199820">[-]</label><label class="expand" for="c-41199820">[1 more]</label></div><br/><div class="children"><div class="content"><i>&gt;Can you actually list any of these &quot;equivalents&quot;? I&#x27;m actually genuinely curious</i><p>I paid 780 Euros a year ago for a 14&quot; Lenovo with an 8 core AMD Ryzen 7840HS, 32GB LPDDR5X and 1TB NVME, and 2560x1600 IPS display. I can&#x27;t justify spending double the Euros for a Mac with less RAM and storage. I just can&#x27;t.<p>If I were doing stuff like photo&#x2F;video editing for a living or developing iOS or MacOS apps, a MacBook would totally be worth it due to it being better for those tasks (or the only option), but for my own use cases of web + Windows + Linux + light PC gaming, Apple&#x27;s products make no sense to me especially given their prices in Europe compared to Col and wages.<p>Oh and best of all, the screen can open almost 180 degrees meaning I can prop it up higher on a flip stand for better neck ergonomics and still view the screen at a 90 degree angle VS MacBooks which can only open ~135 degrees reducing the positions at which you can use the machine as the moment I prop one up, the screen faces my chest isntead of my face while opened all the way.<p>Macs may be technically superior on paper but they have all these design quirks because they only want you to use them this very specific way that one guy in Cupertino though of is the right way to use a laptop, while I say screw that, I&#x27;m the customer, I use it however I think is best for me.</div><br/></div></div><div id="41199805" class="c"><input type="checkbox" id="c-41199805" checked=""/><div class="controls bullet"><span class="by">Panzer04</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41199514">parent</a><span>|</span><a href="#41199820">prev</a><span>|</span><a href="#41199843">next</a><span>|</span><label class="collapse" for="c-41199805">[-]</label><label class="expand" for="c-41199805">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think you could find a windows laptop with comparable build quality (or display quality, which I consider important if you intend to use a laptop for its intended purpose) for 1&#x2F;2 the price of the air. I do think you could find a laptop in the same performance ballpark (ie. 75%+ of the single core speed, which seems to be where the newest gen Intel mobile chips sit in comparison). This is a bigger difference than I expected, admittedly, though the gap closes if you care about multicore performance numbers.<p>Here in AU, a 16GB air with 512GB SSD = 2400AUD. The base model (8&#x2F;256)) = 1800 AUD.<p>I would consider an appropriate comparison model to the air to be something like this:
<a href="https:&#x2F;&#x2F;www.harveynorman.com.au&#x2F;acer-swift-go-evo-14-inch-core-ultra-5-125h-16gb-512gb-ssd-laptop.html#productTabDescription" rel="nofollow">https:&#x2F;&#x2F;www.harveynorman.com.au&#x2F;acer-swift-go-evo-14-inch-co...</a><p>For 1&#x2F;2 the price, you get a laptop with an OLED screen and one of the newest&#x2F;fastest non-M3 processors you can buy. It also happened to be the cheapest laptop with a new Meteor lake processor I could find, though I&#x27;d have to imagine there are laptops with worse specifications in other areas for the cheaper.<p>You can obviously spend up from there to improve build quality, get more SSD space (probably by swapping out the stock NVMe drive), more RAM (if you&#x27;re lucky maybe they have SODIMMs, though I&#x27;d guess most laptops, especially non-16&quot;, might have soldered memory).<p>In terms of non-savvy vs savvy, mostly it&#x27;s that a non-savvy laptop buyer, generally speaking, doesn&#x27;t understand:<p>- Screen quality&#x2F;tech. Resolution, TN vs IPS vs OLED, matte vs gloss, maximum brightness<p>- How different processor generations compare. Especially walking into a store, it&#x27;s common in my experience for laptops with 5500u (Zen 2 6 core) to be sitting next to a laptop with a new eg. 125H, both at similar prices. The newer processor is the pick (performance wise), but this is completely nonobvious. It&#x27;s particularly bad at lower specs, where you can have an i3 N300 (8 e cores) next to perhaps a Ryzen 5700u or Intel 13600h...<p>In theory salespeople should lead them in the right direction, but likely as not they can spend twice as much on a fancy laptop that looks schmick (and probably is) when they could get 90% of the same experience with something like the Acer above. eg:
<a href="https:&#x2F;&#x2F;www.harveynorman.com.au&#x2F;hp-envy-x360-14-inch-ultra-7-155u-16gb-512gb-ssd-2-in-1-laptop-blue.html#productTabSpecifications" rel="nofollow">https:&#x2F;&#x2F;www.harveynorman.com.au&#x2F;hp-envy-x360-14-inch-ultra-7...</a><p>This is admittedly a 2in1, and it has a better processor, but it could well be worse in every other way.</div><br/></div></div></div></div></div></div><div id="41199843" class="c"><input type="checkbox" id="c-41199843" checked=""/><div class="controls bullet"><span class="by">eertami</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41197029">parent</a><span>|</span><a href="#41199078">prev</a><span>|</span><a href="#41197196">next</a><span>|</span><label class="collapse" for="c-41199843">[-]</label><label class="expand" for="c-41199843">[2 more]</label></div><br/><div class="children"><div class="content">The market? I don&#x27;t know a single person personally or professionally with a MacBook Air. I haven&#x27;t seen one in person in like 7 years.</div><br/><div id="41200001" class="c"><input type="checkbox" id="c-41200001" checked=""/><div class="controls bullet"><span class="by">piva00</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41199843">parent</a><span>|</span><a href="#41197196">next</a><span>|</span><label class="collapse" for="c-41200001">[-]</label><label class="expand" for="c-41200001">[1 more]</label></div><br/><div class="children"><div class="content">Anecdotes don&#x27;t really cut it though. I see MacBook Airs all the time, even had a MBA M1 that I handed down to my partner when I got a MBP M3, she uses it both personally and professionally. Two other friends have MBAs, a third just bought one yesterday.<p>At cafés in Stockholm I&#x27;d say 50% of the laptops I see people working with are a version of the MBA. At local universities it&#x27;s an even higher percentage.</div><br/></div></div></div></div><div id="41197196" class="c"><input type="checkbox" id="c-41197196" checked=""/><div class="controls bullet"><span class="by">soulbadguy</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41197029">parent</a><span>|</span><a href="#41199843">prev</a><span>|</span><a href="#41196493">next</a><span>|</span><label class="collapse" for="c-41197196">[-]</label><label class="expand" for="c-41197196">[2 more]</label></div><br/><div class="children"><div class="content">&gt; The M3 MacBook Air is the best computer for most people.<p>Maybe, that it doesnt imply that it&#x27;s the best because it&#x27;s an ultrabook, or that a non-ultrabook version of the macbook air (not the macbook pro...) wouldn&#x27;t have been better.</div><br/><div id="41199521" class="c"><input type="checkbox" id="c-41199521" checked=""/><div class="controls bullet"><span class="by">wwtrv</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41197196">parent</a><span>|</span><a href="#41196493">next</a><span>|</span><label class="collapse" for="c-41199521">[-]</label><label class="expand" for="c-41199521">[1 more]</label></div><br/><div class="children"><div class="content">To be fair from the perspective of most consumers what downsides does the Air have that are only there because it&#x27;s an &quot;ultrabook&quot;?</div><br/></div></div></div></div></div></div><div id="41196493" class="c"><input type="checkbox" id="c-41196493" checked=""/><div class="controls bullet"><span class="by">Almondsetat</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41196388">parent</a><span>|</span><a href="#41197029">prev</a><span>|</span><a href="#41195544">next</a><span>|</span><label class="collapse" for="c-41196493">[-]</label><label class="expand" for="c-41196493">[4 more]</label></div><br/><div class="children"><div class="content">Who are you to say what would make people&#x27;s lives better?</div><br/><div id="41196612" class="c"><input type="checkbox" id="c-41196612" checked=""/><div class="controls bullet"><span class="by">PaulHoule</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41196493">parent</a><span>|</span><a href="#41195544">next</a><span>|</span><label class="collapse" for="c-41196612">[-]</label><label class="expand" for="c-41196612">[3 more]</label></div><br/><div class="children"><div class="content">An actual computer user who&#x27;s probably at least as qualified as whoever made these decisions at Intel.</div><br/><div id="41197093" class="c"><input type="checkbox" id="c-41197093" checked=""/><div class="controls bullet"><span class="by">Almondsetat</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41196612">parent</a><span>|</span><a href="#41195544">next</a><span>|</span><label class="collapse" for="c-41197093">[-]</label><label class="expand" for="c-41197093">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m an actual computer user and I disagree. Now what?</div><br/><div id="41199791" class="c"><input type="checkbox" id="c-41199791" checked=""/><div class="controls bullet"><span class="by">fredoliveira</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41197093">parent</a><span>|</span><a href="#41195544">next</a><span>|</span><label class="collapse" for="c-41199791">[-]</label><label class="expand" for="c-41199791">[1 more]</label></div><br/><div class="children"><div class="content">Now, hopefully, we all come to a simple realization: opinions vary.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="41195544" class="c"><input type="checkbox" id="c-41195544" checked=""/><div class="controls bullet"><span class="by">impossiblefork</span><span>|</span><a href="#41195300">parent</a><span>|</span><a href="#41195542">prev</a><span>|</span><a href="#41195696">next</a><span>|</span><label class="collapse" for="c-41195544">[-]</label><label class="expand" for="c-41195544">[16 more]</label></div><br/><div class="children"><div class="content">But don&#x27;t they need to get into the GPU business?<p>Surely GPUs or similarly very parallel machines for things like ML training are very needed and will remain very needed. Seeing as firms such as Groq have done fine, surely Intel can do something of that sort without much difficulty?<p>Since their GPU business has been unsuccessful perhaps they can go for whatever makes sense, as there&#x27;s nothing of this sort that they can release that will compete with their own products.</div><br/><div id="41195591" class="c"><input type="checkbox" id="c-41195591" checked=""/><div class="controls bullet"><span class="by">pradn</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41195544">parent</a><span>|</span><a href="#41199599">next</a><span>|</span><label class="collapse" for="c-41195591">[-]</label><label class="expand" for="c-41195591">[14 more]</label></div><br/><div class="children"><div class="content">The AI boom is, in theory, a godsend for Intel and AMD. You can focus on creating good tensor computation hardware, without having to worry about getting gamers on board. No need for &quot;Game ready drivers&quot; or compatibility with complex legacy graphics APIs.<p>Of course, there&#x27;s the elephant the room for general purpose tensor machines, which is CUDA - famously closely guarded Nvidia. But with the new wave of &quot;above-CUDA&quot; APIs like TensorFlow, PyTorch, and Keras, there&#x27;s an opportunity to skip the CUDA layer altogether.</div><br/><div id="41196233" class="c"><input type="checkbox" id="c-41196233" checked=""/><div class="controls bullet"><span class="by">mlsu</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41195591">parent</a><span>|</span><a href="#41195736">next</a><span>|</span><label class="collapse" for="c-41196233">[-]</label><label class="expand" for="c-41196233">[2 more]</label></div><br/><div class="children"><div class="content">The AI boom that lead to Nvidia&#x27;s market position is still, 3 years on, almost entirely speculative. The only products that are currently driving value (i.e., that are providing consumer surplus, for which businesses and individuals are actually opening their checkbooks for) are paid chat-bots.<p>Nvidia ate the whole pie because they were in the right place at the right time with shovels to sell. Getting into it now, in house, would be a huge bet that the pot of gold will be there when they get to the end of the rainbow -- and they have a long way to go.</div><br/><div id="41196474" class="c"><input type="checkbox" id="c-41196474" checked=""/><div class="controls bullet"><span class="by">Dalewyn</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41196233">parent</a><span>|</span><a href="#41195736">next</a><span>|</span><label class="collapse" for="c-41196474">[-]</label><label class="expand" for="c-41196474">[1 more]</label></div><br/><div class="children"><div class="content">Intel actually has it even worse because they completely failed to bring ARC to market in time. The product came out (very) late, underdelivered, and permanently damaged the brand reputation. Yes, the drivers and thus the cards have gotten better, but who&#x27;s talking about them now? Noone.<p>They say the opposite of love is indifference, and basically everything Intel has sold outside of CPUs and NICs have suffered market indifference. Actually, maybe even the NICs given everyone seems to prefer Realtek NICs over Intel NICs these days.<p>Nvidia and AMD have it way better because if the market doesn&#x27;t love them, you bet the market will hate on them instead of be indifferent.</div><br/></div></div></div></div><div id="41195736" class="c"><input type="checkbox" id="c-41195736" checked=""/><div class="controls bullet"><span class="by">Sparkyte</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41195591">parent</a><span>|</span><a href="#41196233">prev</a><span>|</span><a href="#41195754">next</a><span>|</span><label class="collapse" for="c-41195736">[-]</label><label class="expand" for="c-41195736">[3 more]</label></div><br/><div class="children"><div class="content">AI doesn&#x27;t exist with the right amount of collected data, we&#x27;re going to hit a wall very soon where we just get bad AI data constantly because we are throwing data to the wall and hoping it sticks. Businesses should not be investing in AI right yet maybe 2-3 more years.<p>The businesses that should are the startups and businesses who are helping define the model, like ChatGPT and Microsoft, but the adoption is still too early. If I was McDonald&#x27;s or Wendy&#x27;s and I wanted to use AI to help promote sales to customers I would need to be able to grab demographic data which may not be appropriate PII data.<p>All of the lawsuits happening right now for data collected without permission of the data provider is going to all change the landscape.</div><br/><div id="41196052" class="c"><input type="checkbox" id="c-41196052" checked=""/><div class="controls bullet"><span class="by">nullc</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41195736">parent</a><span>|</span><a href="#41195754">next</a><span>|</span><label class="collapse" for="c-41196052">[-]</label><label class="expand" for="c-41196052">[2 more]</label></div><br/><div class="children"><div class="content">I think there is still a good business to be made taking the AI stuff we have <i>right now</i> and making it highly performant.<p>Stable diffusion models are awesome and super useful.  I don&#x27;t necessarily mean the simplistic text-&gt;image stuff (though it&#x27;s clearly useful)-- but denoising, in painting, animation from stills, 3d from stills.... style changes, etc.<p>LLMs are at least somewhat useful.<p>We can radically improve image and video compression with performant enough AI.<p>Plenty of other applications of AI right now are already useful or would be useful if inference were made more efficient or more local (thus private).  No more data needed.<p>You don&#x27;t need some grand vision of an AI future to get a total addressable market for high performance AI that is in the same ballpark as high performance GPUs for non-AI usage.</div><br/><div id="41196109" class="c"><input type="checkbox" id="c-41196109" checked=""/><div class="controls bullet"><span class="by">Sparkyte</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41196052">parent</a><span>|</span><a href="#41195754">next</a><span>|</span><label class="collapse" for="c-41196109">[-]</label><label class="expand" for="c-41196109">[1 more]</label></div><br/><div class="children"><div class="content">But for every business the chase seems to fail in finding worth. I can already tell you from where I am working we are struggling because eventually data is too old to be good or too incomplete. We need at least 3-4 years of collecting and storing the information to make full use of AI.</div><br/></div></div></div></div></div></div><div id="41195754" class="c"><input type="checkbox" id="c-41195754" checked=""/><div class="controls bullet"><span class="by">PaulHoule</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41195591">parent</a><span>|</span><a href="#41195736">prev</a><span>|</span><a href="#41196220">next</a><span>|</span><label class="collapse" for="c-41195754">[-]</label><label class="expand" for="c-41195754">[3 more]</label></div><br/><div class="children"><div class="content">In practice it&#x27;s the other way around.<p>In practice AMD and Intel GPUs should be suitable for machine learning but the software story isn&#x27;t good.  I know I can buy a NVIDIA card and know it&#x27;s a good investment because everything worth with CUDA and be training models in less than a day.  If I went with some other brand I&#x27;d expect to put 6 man*months into figuring out the software story,  and that&#x27;s a lot more than the price difference in the cards.<p>I&#x27;ve been wondering about the soundness of Intel&#x27;s software strategy in that OneAPI (&quot;One&quot; is a bad smell in marketing speak,  the only premium product in my mind that has &quot;One&quot; in the name is &quot;Purina ONE&quot; pet food,  the XBOX ONE is an astonishing own goal of a name because you&#x27;d never get your mom to understand that an XBOX ONE is better than an XBOX or XBOX 360) is based on OpenCL and the one thing I know about OpenCL is that I don&#x27;t know anyone who likes coding for it.  The idea that you could code for FPGA and GPU out of the same API also seems delusional because FPGA is (mostly) about latency and GPU is about throughput.  That is,  FPGA can do certain small operations insanely fast and avoid the overhead of 16-bit math when 13-bit math will do,  GPU is all about doing large operations in bulk.</div><br/><div id="41195975" class="c"><input type="checkbox" id="c-41195975" checked=""/><div class="controls bullet"><span class="by">bryanlarsen</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41195754">parent</a><span>|</span><a href="#41196220">next</a><span>|</span><label class="collapse" for="c-41195975">[-]</label><label class="expand" for="c-41195975">[2 more]</label></div><br/><div class="children"><div class="content">&gt;  If I went with some other brand I&#x27;d expect to put 6 man*months into figuring out the software story, and that&#x27;s a lot more than the price difference in the cards.<p>Several companies are spending &gt;$10B annually on AI compute.   There are a lot more than 6 man-months of savings in it for them...</div><br/><div id="41196197" class="c"><input type="checkbox" id="c-41196197" checked=""/><div class="controls bullet"><span class="by">PaulHoule</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41195975">parent</a><span>|</span><a href="#41196220">next</a><span>|</span><label class="collapse" for="c-41196197">[-]</label><label class="expand" for="c-41196197">[1 more]</label></div><br/><div class="children"><div class="content">One firm saving $2B saves $2B, open source software that opens up the market for everyone is priceless.<p>A company like OpenAI that is mostly concerned about pace might see going with the #2 GPU vendor is risky, even if it has the possibility to save money.</div><br/></div></div></div></div></div></div><div id="41196020" class="c"><input type="checkbox" id="c-41196020" checked=""/><div class="controls bullet"><span class="by">ein0p</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41195591">parent</a><span>|</span><a href="#41196220">prev</a><span>|</span><a href="#41198992">next</a><span>|</span><label class="collapse" for="c-41196020">[-]</label><label class="expand" for="c-41196020">[3 more]</label></div><br/><div class="children"><div class="content">The whole situation with Intel and AI is also baffling to me. They have an excellent product in this space - Gaudi2. Faster than A100 and very attractively priced. I’ve tried it, it works fine. Gaudi3 is also about to come out, and it’s twice as fast as Gaudi2. Yet nobody is buying. I get why you wouldn’t want this for training - it requires some minor code modifications and your Triton kernels are worthless. But for generative inference this is just what the doctor ordered.</div><br/><div id="41197211" class="c"><input type="checkbox" id="c-41197211" checked=""/><div class="controls bullet"><span class="by">soulbadguy</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41196020">parent</a><span>|</span><a href="#41198992">next</a><span>|</span><label class="collapse" for="c-41197211">[-]</label><label class="expand" for="c-41197211">[2 more]</label></div><br/><div class="children"><div class="content">&gt;  generative inference this is just what the doctor ordered.<p>Naive question, wouldn&#x27;t you need a descent tool chain for inference as well ?</div><br/><div id="41197368" class="c"><input type="checkbox" id="c-41197368" checked=""/><div class="controls bullet"><span class="by">ein0p</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41197211">parent</a><span>|</span><a href="#41198992">next</a><span>|</span><label class="collapse" for="c-41197368">[-]</label><label class="expand" for="c-41197368">[1 more]</label></div><br/><div class="children"><div class="content">Assuming you mean “decent” toolchain, it’s actually pretty decent. Could it use some polish? Yes. But any decent ML engineer would be able to get a high performance server (or a batch job) running in a relatively short time. Or in almost no time at all if using a lot of the FOSS models. You just basically create a model in PyTorch and then hand it over to Gaudi stuff which patches it with optimized, Gaudi specific ops and converts things into an inference graph.<p>“Closeness to CUDA” is less important for inference because all the experimentation is already done by then, and if need be you could just implement the model using Gaudi ops to begin with, in a span of a few days including tuning and debugging.</div><br/></div></div></div></div></div></div><div id="41198992" class="c"><input type="checkbox" id="c-41198992" checked=""/><div class="controls bullet"><span class="by">jakobson14</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41195591">parent</a><span>|</span><a href="#41196020">prev</a><span>|</span><a href="#41199599">next</a><span>|</span><label class="collapse" for="c-41198992">[-]</label><label class="expand" for="c-41198992">[1 more]</label></div><br/><div class="children"><div class="content">No there isn&#x27;t. Let&#x27;s take pytorch as an example.<p>CUDA is an API. OpenCL is an API. Pytorch is <i>not.</i><p>Pytorch is very firmly GLUED to CUDA. It will probably NEVER support anything else beyond token inference on mobile devices. The only reason Pytorch supports AMD at all is because of AMD&#x27;s &quot;I can&#x27;t beleive it&#x27;s not CUDA&quot; HIP translation layer.<p>OpenCL is a real cross-platform API and with 3.0 it&#x27;s finally &quot;good&quot; and coincidentally, intel is....half-heartedly interested in it, except they&#x27;re shooting themselves in the foot by trying to also cover useless CPUs for inference&#x2F;training and spreading themselves too thin (OneAPI). Because all intel can think about are CPUs. Everything must drive sales of CPUs.<p>At this rate just about the only think that might save us from CUDA is rusticl. If a real, full-fat, high-quality openCL 3.0 driver sudently popped into existence on every GPU platform under the sun, maybe pytorch et al could finally be convinced to give a shit about an API other than CUDA.</div><br/></div></div></div></div><div id="41199599" class="c"><input type="checkbox" id="c-41199599" checked=""/><div class="controls bullet"><span class="by">bee_rider</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41195544">parent</a><span>|</span><a href="#41195591">prev</a><span>|</span><a href="#41195696">next</a><span>|</span><label class="collapse" for="c-41199599">[-]</label><label class="expand" for="c-41199599">[1 more]</label></div><br/><div class="children"><div class="content">Intel getting into the GPU business is good, for sure and I hope they don’t give up on it.<p>It is a tiny thing, but Intel really seems to charge a premium for PCIe lanes. Maybe if they sell a lot of dGPUs they’ll be less stingy with the sockets to plug them in to…</div><br/></div></div></div></div><div id="41195696" class="c"><input type="checkbox" id="c-41195696" checked=""/><div class="controls bullet"><span class="by">Sparkyte</span><span>|</span><a href="#41195300">parent</a><span>|</span><a href="#41195544">prev</a><span>|</span><a href="#41196699">next</a><span>|</span><label class="collapse" for="c-41195696">[-]</label><label class="expand" for="c-41195696">[14 more]</label></div><br/><div class="children"><div class="content">Intel has always been an echo chamber of fiscal earnings and cutting corners to appease investors. For the longest time they stagnated on Mac hardware improvements because it would cost money, they would not have lost Mac as a business customer if they continued to innovate.</div><br/><div id="41195807" class="c"><input type="checkbox" id="c-41195807" checked=""/><div class="controls bullet"><span class="by">PaulHoule</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41195696">parent</a><span>|</span><a href="#41195970">next</a><span>|</span><label class="collapse" for="c-41195807">[-]</label><label class="expand" for="c-41195807">[6 more]</label></div><br/><div class="children"><div class="content">Also they should have had a policy of &quot;not one transistor for the national labs&quot; and &quot;not one transistor for hyperscalers&quot;,  particularly because anything they do to appease hyperscalers just saves them money that they&#x27;ll spend on their custom silicon transition.<p>There&#x27;s something prestigious about HPC but the story of how commercial data processing went parallel in the oughts shows how out of touch the HPC community is.<p>In the meantime Intel has botched the deployment of SIMD,  slowplaying to the point where maybe 7 or 8 years from now some mainstream software might support AVX512,  maybe.  Somebody should be tarred and feathered for introducing the idea that features should be fused off for all but the highest paying customers.  If the customer is not paying for the fused off functionality,  the shareholders are.  It sounds really ruthless and avaricious and might impress some business analysts as a form of vice signalling but it&#x27;s pure waste.</div><br/><div id="41195993" class="c"><input type="checkbox" id="c-41195993" checked=""/><div class="controls bullet"><span class="by">Sparkyte</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41195807">parent</a><span>|</span><a href="#41196684">next</a><span>|</span><label class="collapse" for="c-41195993">[-]</label><label class="expand" for="c-41195993">[2 more]</label></div><br/><div class="children"><div class="content">Right it is wasteful. The reason some businesses are so successful is that they look at the common denominators rather than trying to perpetuate worth. Fewer variants and don&#x27;t wall off features. AMD did this for the longest period getting back on it feet, but I am seeing a failure of them continuing down this path. They need to stop making variants and focus on 3 or 4 sets of consumer processors.</div><br/><div id="41196152" class="c"><input type="checkbox" id="c-41196152" checked=""/><div class="controls bullet"><span class="by">PaulHoule</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41195993">parent</a><span>|</span><a href="#41196684">next</a><span>|</span><label class="collapse" for="c-41196152">[-]</label><label class="expand" for="c-41196152">[1 more]</label></div><br/><div class="children"><div class="content">Yep,  “too many SKUs” killed off the consumer HDD a few years faster than it had to die. If these companies had focus groups that reached out to ordinary people they’d realize it sounds absolutely incredible to most people that you need one hard drive for a 3-5 bay NAS, another for a 6-9 bay NAS, another if you are recording from video cameras.<p>Even if there was a real benefit from optimizing firmware and saving a few cents with cheap washers for drives in a low vibration environment there is a much more certain cost in that you have to qualify the firmware, risk introducing errors, etc.  I can imagine that Best Buy might have been able to stock one model of high capacity HDD but no way were they going to stock more colors of WD drive than there are on the rainbow flag.  That lack of product sense locked manufacturers out of the retail market.<p>(Makes me think of the cringe monthly hard drive roundup in Anandtech where an enterprise drive produced in huge numbers in a single SKU would usually be $80-100 cheaper than prosumer drives that,  according to the spec sheet, consumed about 0.5W less and were about 3db quieter…  And I have plenty of those enterprise drives still spinning after all these years, the only time I think about the noise is when the machine boots and the drives emit a throaty chirp that makes me think of a Ferrari spooling up.)</div><br/></div></div></div></div><div id="41196684" class="c"><input type="checkbox" id="c-41196684" checked=""/><div class="controls bullet"><span class="by">mrandish</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41195807">parent</a><span>|</span><a href="#41195993">prev</a><span>|</span><a href="#41195970">next</a><span>|</span><label class="collapse" for="c-41196684">[-]</label><label class="expand" for="c-41196684">[3 more]</label></div><br/><div class="children"><div class="content"><i>&gt; &quot; Somebody should be tarred and feathered for introducing the idea that features should be fused off for all but the highest paying customers. If the customer is not paying for the fused off functionality, the shareholders are.&quot;</i><p>This is very well put.<p>While I&#x27;ve always understood the economic motivation for margin optimization and the technical reality that CPU wafers aren&#x27;t very granular, fundamentally, it&#x27;s a long-term losing idea to intentionally fab gates that don&#x27;t add end-user value. While it may work in the shorter-term, when it becomes the plan of record (as opposed to fixing a one-gen design or product mix error) it signals a shift to prioritizing value extraction over value creation.</div><br/><div id="41197047" class="c"><input type="checkbox" id="c-41197047" checked=""/><div class="controls bullet"><span class="by">oivey</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41196684">parent</a><span>|</span><a href="#41197515">next</a><span>|</span><label class="collapse" for="c-41197047">[-]</label><label class="expand" for="c-41197047">[1 more]</label></div><br/><div class="children"><div class="content">Even more simply, their goal stopped being making the best product at the best price. Features that were fused off could have made their products better for no extra manufacturing cost. Your business is broken when you view your products as being too featureful as a cost.</div><br/></div></div><div id="41197515" class="c"><input type="checkbox" id="c-41197515" checked=""/><div class="controls bullet"><span class="by">Sparkyte</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41196684">parent</a><span>|</span><a href="#41197047">prev</a><span>|</span><a href="#41195970">next</a><span>|</span><label class="collapse" for="c-41197515">[-]</label><label class="expand" for="c-41197515">[1 more]</label></div><br/><div class="children"><div class="content">Current investor strategy is immediate gains no long term investment because that is deemed risky. Because they want to buy in and bail when they&#x27;ve doubled their investment.</div><br/></div></div></div></div></div></div><div id="41195970" class="c"><input type="checkbox" id="c-41195970" checked=""/><div class="controls bullet"><span class="by">jzb</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41195696">parent</a><span>|</span><a href="#41195807">prev</a><span>|</span><a href="#41196635">next</a><span>|</span><label class="collapse" for="c-41195970">[-]</label><label class="expand" for="c-41195970">[6 more]</label></div><br/><div class="children"><div class="content">&quot;they would not have lost Mac as a business customer if they continued to innovate&quot;<p>I&#x27;m not entirely sure this is true. I mean, I guess it depends on whether one expected Intel to be able to make not just a decent chip for PCs&#x2F;laptops, but also one for phones &amp; tablets. Once Apple started dabbling in its own chips for the iPhone and iPad, it seemed inevitable that they&#x27;d expand that to their macOS systems too. Apple has been a rough customer to please for chip designers&#x2F;manufacturers, I&#x27;m not sure any company could&#x27;ve satisfied them with a general-purpose chip.</div><br/><div id="41196450" class="c"><input type="checkbox" id="c-41196450" checked=""/><div class="controls bullet"><span class="by">hbn</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41195970">parent</a><span>|</span><a href="#41196635">next</a><span>|</span><label class="collapse" for="c-41196450">[-]</label><label class="expand" for="c-41196450">[5 more]</label></div><br/><div class="children"><div class="content">If they played their cards right as the top dog ~20 years ago, they could have perhaps ended up with the relationship with Apple that TSMC does today.</div><br/><div id="41196515" class="c"><input type="checkbox" id="c-41196515" checked=""/><div class="controls bullet"><span class="by">talldayo</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41196450">parent</a><span>|</span><a href="#41196635">next</a><span>|</span><label class="collapse" for="c-41196515">[-]</label><label class="expand" for="c-41196515">[4 more]</label></div><br/><div class="children"><div class="content">1. Intel didn&#x27;t have big fabs 20 years ago, so they didn&#x27;t have anything to offer Apple that would resemble TSMC&#x27;s partnership.<p>2. There&#x27;s no money in designing licensed CPU cores as a middleman for a company that drives margins so low they&#x27;re associated with suicide nets and forced labor.<p>3. If TSMC is lost due to Chinese aggression (which is a non-zero chance), Apple is left fabless and has to choose between importing Samsung silicon at-cost or partnering with Intel.</div><br/><div id="41199596" class="c"><input type="checkbox" id="c-41199596" checked=""/><div class="controls bullet"><span class="by">qwytw</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41196515">parent</a><span>|</span><a href="#41196637">next</a><span>|</span><label class="collapse" for="c-41199596">[-]</label><label class="expand" for="c-41199596">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Intel didn&#x27;t have big fabs 20 years ago,<p>They had leading edge ARM chips though. If Apple used XScale (i.e. the default choice had Intel not decided to get rid of it due to &quot;reasons&quot;) for the iPhone that would have significantly  reduced the likelihood  of them developing competitive chips themselves.<p>Also 20 years? Samsung was still making Apple&#x27;s chips back in 2014.<p>&gt; 2. There&#x27;s no money in designing licensed CPU cores as a middleman for a company that drives margins so low they&#x27;re associated with suicide nets and forced labor.<p>Is Apple significantly or at all worse than their competitors in this regard? In any case only reason Apple is designing their own chips is because there weren&#x27;t any decent options for their use cases available on the market (and Intel only has itself to blame for that...)</div><br/></div></div><div id="41196637" class="c"><input type="checkbox" id="c-41196637" checked=""/><div class="controls bullet"><span class="by">PaulHoule</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41196515">parent</a><span>|</span><a href="#41199596">prev</a><span>|</span><a href="#41196635">next</a><span>|</span><label class="collapse" for="c-41196637">[-]</label><label class="expand" for="c-41196637">[2 more]</label></div><br/><div class="children"><div class="content">Might take them a few years to update their software to run on the Samsung stack.<p>What are they going to do without all the auxiliary processors they build in?<p>Or do they have a team which has their software working on other people&#x27;s silicon in case their supply chain get blown up?</div><br/><div id="41197082" class="c"><input type="checkbox" id="c-41197082" checked=""/><div class="controls bullet"><span class="by">talldayo</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41196637">parent</a><span>|</span><a href="#41196635">next</a><span>|</span><label class="collapse" for="c-41197082">[-]</label><label class="expand" for="c-41197082">[1 more]</label></div><br/><div class="children"><div class="content">Also, importantly, how hard will the US government be taxing imports and propping-up Intel? I think that an anti-Apple and pro-Apple administration would both want them to stop shipping jobs offshore. There&#x27;s a tariff knob that can be adjusted until only Intel (or GlobalFoundries, lmao) are feasible choices, and if the US wants their Intel investment recouped then they may well push for that kind of deal.<p>Personally, I find the &quot;samurai&#x27;s honor&quot; shit where one company avoids another to be childish and stupid. If you make Apple&#x27;s board choose between ending their grudge-match or blowing up their margins, I don&#x27;t think they&#x27;ll care much either. Or maybe I&#x27;m wrong, and the 2027 iPhone is manufactured with 24nm wafers intended for the Toyota Prius.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="41196635" class="c"><input type="checkbox" id="c-41196635" checked=""/><div class="controls bullet"><span class="by">AtlasBarfed</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41195696">parent</a><span>|</span><a href="#41195970">prev</a><span>|</span><a href="#41196699">next</a><span>|</span><label class="collapse" for="c-41196635">[-]</label><label class="expand" for="c-41196635">[1 more]</label></div><br/><div class="children"><div class="content">Companies that are built on engineering eventually become subsumed by soul-sucking profit sucking bonus sucking middle management types that just plop themselves in their big huge hierarchy and destroy the company long-term with inertia and apathy.<p>See also. Boeing Medtronic GE AT&amp;t</div><br/></div></div></div></div><div id="41196699" class="c"><input type="checkbox" id="c-41196699" checked=""/><div class="controls bullet"><span class="by">spookie</span><span>|</span><a href="#41195300">parent</a><span>|</span><a href="#41195696">prev</a><span>|</span><a href="#41198777">next</a><span>|</span><label class="collapse" for="c-41196699">[-]</label><label class="expand" for="c-41196699">[1 more]</label></div><br/><div class="children"><div class="content">Having a third competitor in the GPU is great, for both Intel and the consumer. If one starts blaming newcomers for their shortcomings then we are failing to see the bigger picture.<p>When you talk about web browsers failing to display content because of the iGPUs I fail to even have heard of such a case. Maybe the performance is bad but that&#x27;s it. Either way, that&#x27;s more of a failure of the OS and not Intel. Windows is particularly biased to not use your dGPU on a laptop, but I blame the kernel for making badly calculated assumptions based on nothing but !={game, 3D modelling tool} then iGPU, and not the hardware.</div><br/></div></div><div id="41198777" class="c"><input type="checkbox" id="c-41198777" checked=""/><div class="controls bullet"><span class="by">gorgoiler</span><span>|</span><a href="#41195300">parent</a><span>|</span><a href="#41196699">prev</a><span>|</span><a href="#41199257">next</a><span>|</span><label class="collapse" for="c-41198777">[-]</label><label class="expand" for="c-41198777">[1 more]</label></div><br/><div class="children"><div class="content">Your second quote has always resonated very strongly with me, both as a concept and also from the original-ish verse:<p><pre><code>  Oh would some power
    the gift He gives us
  To see ourselves
    as others see us
  It would from many
    a blunder free us
  And foolish notion
  What airs in dress
    and gait would leave us
  And even in CPU fabrication!
</code></pre>
<i>— adapted from “To a Louse”, R. Burns</i></div><br/></div></div><div id="41199257" class="c"><input type="checkbox" id="c-41199257" checked=""/><div class="controls bullet"><span class="by">larodi</span><span>|</span><a href="#41195300">parent</a><span>|</span><a href="#41198777">prev</a><span>|</span><a href="#41195707">next</a><span>|</span><label class="collapse" for="c-41199257">[-]</label><label class="expand" for="c-41199257">[1 more]</label></div><br/><div class="children"><div class="content">from <a href="https:&#x2F;&#x2F;genius.com&#x2F;Top-cat-a-friend-in-need-panik-and-m-rode-mix-lyrics" rel="nofollow">https:&#x2F;&#x2F;genius.com&#x2F;Top-cat-a-friend-in-need-panik-and-m-rode...</a><p>&quot;&quot;&quot;
A Friend In Need Is A Friend Indeed<p>But a friend with weed is better<p>So if you want to get high<p>Bring your own supply<p>Or we will know you as a joker smoker
&quot;&quot;&quot;</div><br/></div></div><div id="41195707" class="c"><input type="checkbox" id="c-41195707" checked=""/><div class="controls bullet"><span class="by">immibis</span><span>|</span><a href="#41195300">parent</a><span>|</span><a href="#41199257">prev</a><span>|</span><a href="#41195512">next</a><span>|</span><label class="collapse" for="c-41195707">[-]</label><label class="expand" for="c-41195707">[1 more]</label></div><br/><div class="children"><div class="content">I have an Arc A770 and it seems to work fine so far... though I&#x27;ve only had it for a month. There are some tolerable teething problems: I can&#x27;t set the fan curve from Linux so I had to duct tape some extra fans, and it&#x27;s incompatible with BIOS boot (requires UEFI) which should be considered acceptable in 2024. For presumably the same reason, there&#x27;s no graphics output in early Linux boot until the GPU driver is loaded.<p>The IGPU in my previous machine&#x27;s i7-6700K (Skylake) was also just fine. Intel Graphics Media Accelerator, yeah that really sucked, but that was like 15 years ago?</div><br/></div></div><div id="41195512" class="c"><input type="checkbox" id="c-41195512" checked=""/><div class="controls bullet"><span class="by">christkv</span><span>|</span><a href="#41195300">parent</a><span>|</span><a href="#41195707">prev</a><span>|</span><a href="#41195508">next</a><span>|</span><label class="collapse" for="c-41195512">[-]</label><label class="expand" for="c-41195512">[8 more]</label></div><br/><div class="children"><div class="content">The CEO had only been in charge since 2021 bringing an engineer back to the helm. How long does it take to bring a big ship like Intel around and undo decades of internal rot? It will be interesting to see who is let go in the coming months.</div><br/><div id="41195724" class="c"><input type="checkbox" id="c-41195724" checked=""/><div class="controls bullet"><span class="by">code_biologist</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41195512">parent</a><span>|</span><a href="#41195553">next</a><span>|</span><label class="collapse" for="c-41195724">[-]</label><label class="expand" for="c-41195724">[2 more]</label></div><br/><div class="children"><div class="content">Though prior to Gelsinger, Youtuber and chip leaker &#x2F; rumor monger &quot;Moore&#x27;s Law is Dead&quot; mentioned that Jim Keller&#x27;s stint at Intel was so short (April 2018 - June 2020) because of internal cultural toxicity. In particular, things like leaders of major groups in Intel trying to get employees of other groups fired, so as to make their own relative progress look better. Take with a pound of salt of course, but MLiD&#x27;s sources have been pretty decent.<p>You only resolve that kind of badness by firing a bunch of SVPs and VPs and Gelsinger hasn&#x27;t done that, for many possible reasons.</div><br/><div id="41197516" class="c"><input type="checkbox" id="c-41197516" checked=""/><div class="controls bullet"><span class="by">jiggawatts</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41195724">parent</a><span>|</span><a href="#41195553">next</a><span>|</span><label class="collapse" for="c-41197516">[-]</label><label class="expand" for="c-41197516">[1 more]</label></div><br/><div class="children"><div class="content">I knew Intel was a dying company when Jim Keller quit in disgust. The man is pure productivity, a relentless optimiser that just wants to build great things. Intel broke him and he ran away screaming.<p>PS: Microsoft demoting Jeffrey Snover (inventor of PowerShell) is in the same category of a business decaying from the top down. He quit too, and is now working for Google.</div><br/></div></div></div></div><div id="41195553" class="c"><input type="checkbox" id="c-41195553" checked=""/><div class="controls bullet"><span class="by">akira2501</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41195512">parent</a><span>|</span><a href="#41195724">prev</a><span>|</span><a href="#41195508">next</a><span>|</span><label class="collapse" for="c-41195553">[-]</label><label class="expand" for="c-41195553">[5 more]</label></div><br/><div class="children"><div class="content">&gt; How long does it take to bring a big ship like Intel around and undo decades of internal rot?<p>If it takes that long,  then this is your actual problem,  and not how many engineers are in the loop at the board level.</div><br/><div id="41195715" class="c"><input type="checkbox" id="c-41195715" checked=""/><div class="controls bullet"><span class="by">soulbadguy</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41195553">parent</a><span>|</span><a href="#41195730">next</a><span>|</span><label class="collapse" for="c-41195715">[-]</label><label class="expand" for="c-41195715">[1 more]</label></div><br/><div class="children"><div class="content">&gt;If it takes that long, then this is your actual problem<p>Most IC design  life cycle are 5+ years. Expecting to turn over in less is part of the problem  intel is having currently.</div><br/></div></div><div id="41195730" class="c"><input type="checkbox" id="c-41195730" checked=""/><div class="controls bullet"><span class="by">macintux</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41195553">parent</a><span>|</span><a href="#41195715">prev</a><span>|</span><a href="#41195508">next</a><span>|</span><label class="collapse" for="c-41195730">[-]</label><label class="expand" for="c-41195730">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;m skeptical. Big company, design &amp; manufacturing cycles on the order of years because chips are that sophisticated these days, I don&#x27;t know what you&#x27;d expect to see within 3 years of a new CEO.</div><br/><div id="41196018" class="c"><input type="checkbox" id="c-41196018" checked=""/><div class="controls bullet"><span class="by">barkingcat</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41195730">parent</a><span>|</span><a href="#41195508">next</a><span>|</span><label class="collapse" for="c-41196018">[-]</label><label class="expand" for="c-41196018">[2 more]</label></div><br/><div class="children"><div class="content">to be honest, they should have done a layoff 3 years ago, as soon as Pat Gelsinger came onboard, and fired 2 entire layers of management.<p>No engineers or support people, but just pure middle managers - fire 2 or 3 layers. if they did that 3 years ago, they would be in a better position now.</div><br/><div id="41198648" class="c"><input type="checkbox" id="c-41198648" checked=""/><div class="controls bullet"><span class="by">Red_Leaves_Flyy</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41196018">parent</a><span>|</span><a href="#41195508">next</a><span>|</span><label class="collapse" for="c-41198648">[-]</label><label class="expand" for="c-41198648">[1 more]</label></div><br/><div class="children"><div class="content">Gelsinger would be shooting blind and in order to cut enough to force compliance he would ultimately be sabotaged as the entire workforce unites against him unless he had the ability to bring in a few thousand loyal soldiers to manage every unit. He’s got the much harder job of ferreting out deep corruption and incompetence that perniciously hides in corners protected by knowing whose buried what bodies. Rough job that he cannot possibly accomplish. Instead he’s probably trying to root out these toxic messes and quarantine them in safe environments where they can be productive enough to realize ROI but disempowered and segregated while he works on fixing the broken systems and teams that got Intel to this point. Maybe this layoff was in his back pocket waiting for the right time to cut the shit loose with cover or maybe he failed to realize that should have been his first order of business and this was a desperate move to stop the hemorrhaging and Intels books are going to be even worse two years out when the consequences of firing qualified staff begins to manifest.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="41195508" class="c"><input type="checkbox" id="c-41195508" checked=""/><div class="controls bullet"><span class="by">is_true</span><span>|</span><a href="#41195300">parent</a><span>|</span><a href="#41195512">prev</a><span>|</span><a href="#41196194">next</a><span>|</span><label class="collapse" for="c-41195508">[-]</label><label class="expand" for="c-41195508">[1 more]</label></div><br/><div class="children"><div class="content">Does the new owner provides the same performance?</div><br/></div></div><div id="41196194" class="c"><input type="checkbox" id="c-41196194" checked=""/><div class="controls bullet"><span class="by">samstave</span><span>|</span><a href="#41195300">parent</a><span>|</span><a href="#41195508">prev</a><span>|</span><a href="#41195690">next</a><span>|</span><label class="collapse" for="c-41196194">[-]</label><label class="expand" for="c-41196194">[3 more]</label></div><br/><div class="children"><div class="content">Disclaimer: I used to work at Intel:<p>Specifically, I was the second person on the planet to game on a Celeron Proc. How? Me and my best friend ran the Intel Developer Relations Group Gaming Test Lab in the later half of the 90s.<p>Our job was to specifically test all PC games that were being developed against the Intel Celeron procs and the amd alts... with a focus on Subjective Gaming Performance of the Celeron as an &quot;Optimized&quot; feature leader whereby developers were given handsome marketing monies to optimize the games against latest SIMD instructions to allow for the games to be more performant on the Celeron.<p>THe goal: Show the world that a $1,000 fully capable gaming PC was possible, in their budget, and <i>desirable</i>.<p>---<p>The Issue at the time was the graphic bottlenecks -- all the pieces had yet to come to fore: AGP, Unreal, OpenGL, ~~NERDS~~ NURBS!, Games, Graphix Chips (VooDoo, 3DFX, blah blah)<p>Celeron should have died long ago - but certainly when the first, actual GPUs came along and did the heavy lifting.<p>I have a lot of thoughts about Intels mess (Transmetta really fucked Intel up in the way an abusive step-relative would) and caused them to lose focus...<p>Then, just the ridiculous amount of marketing over engineering....<p><i>(if anyone worked at intel in the DRG circles in SC5 - and has access to emails of that day - search my name and the thread I started asking why we cant just physically stack CPUs on top of eachother... (this was prior to the Voxel timeline) and was laughed at. it wasnt until several years after that I went on a hike with a labs head and found out about the 64-core text CPUs that were only coming out)</i><p>---<p>I was just having shower-thoughts about intels future as effectively computing <i>grout</i> -- a mechanism to get data from real-world INTO NVIDIA GPUs and then displayed again real-world. And thats it. Thats the only thing Intel may be doing in the future - is grout to display the data components solely computed, as NVIDIA CEO stated himself &quot;All compute will be done on NVIDIA chips&quot; -- <i>delivery</i> of the data through intel&#x27;s grout (minimally) then again delivered to an NVIDIA desktop GPU...<p>Intel is like the maintenance staff of a home. NVIDIA is the architect, interior designer, party planner and end user.<p><i>(Intel was my first ever stock package: $70 with a $125 option price. 10K shares. I left before ever vesting... it was the late 90s and I had to chase the dream intc: <a href="https:&#x2F;&#x2F;i.imgur.com&#x2F;U9PWURv.png" rel="nofollow">https:&#x2F;&#x2F;i.imgur.com&#x2F;U9PWURv.png</a> )</i></div><br/><div id="41198906" class="c"><input type="checkbox" id="c-41198906" checked=""/><div class="controls bullet"><span class="by">gdiamos</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41196194">parent</a><span>|</span><a href="#41195690">next</a><span>|</span><label class="collapse" for="c-41198906">[-]</label><label class="expand" for="c-41198906">[2 more]</label></div><br/><div class="children"><div class="content">Even then, why is Intel better grout than AMD today?</div><br/><div id="41198946" class="c"><input type="checkbox" id="c-41198946" checked=""/><div class="controls bullet"><span class="by">samstave</span><span>|</span><a href="#41195300">root</a><span>|</span><a href="#41198906">parent</a><span>|</span><a href="#41195690">next</a><span>|</span><label class="collapse" for="c-41198946">[-]</label><label class="expand" for="c-41198946">[1 more]</label></div><br/><div class="children"><div class="content">Good point to ask -- I meant any &quot;CPU Only&quot; technology company.<p>Personally what Intel should have shifted to was owning and building all the Fabs.<p>Sure they have them and are building them etc... but they missed the timing a bit.<p>I dont follow them close enough any longer - but they really should have gone all in on being the US TSMC... rather than the bit of catchup they are in...<p>They arent going anywhere (the birth of Intel from Fairchild was in Missle circuits - and the US War Leviathan will always have intel circuits in the big-ticket items. Forever.</div><br/></div></div></div></div></div></div></div></div><div id="41195690" class="c"><input type="checkbox" id="c-41195690" checked=""/><div class="controls bullet"><span class="by">kjellsbells</span><span>|</span><a href="#41195300">prev</a><span>|</span><a href="#41195781">next</a><span>|</span><label class="collapse" for="c-41195690">[-]</label><label class="expand" for="c-41195690">[20 more]</label></div><br/><div class="children"><div class="content">The classic moat metaphor that the OP article and others use needs to be fleshed out to match Intel&#x27;s predicament.<p>A moat protects a castle that adversaries want to take over. The presence of the castle defines what can and cannot be done with the surrounding landscape. But if the castle ceases to protect what people care about, or make meaningful additions to the environment, it becomes irrelevant and the presence of the moat makes no difference.<p>Intel&#x27;s problem isn&#x27;t that competitors want to storm the castle and achieve domination over the landscape that x86 controls. It&#x27;s that the competition have built their own castles on the other side of the river, and a lot of the peasants are tilling the lands around Castle ARM and Chateau NVIDIA.<p>To put it another way, Intel thought the castle was &quot;control of computing&quot; and the moat was &quot;leadership in x86&quot; but irrelevance comes a little closer with each passing chip generation. It is fortunate for Intel that corraling an ecosystem into existence around the alternatives to x86 is an insanely difficult task, but it has been done with ARM, it has been done (albeit for a niche) with NVIDIA and it can be done again with whatever comes next.</div><br/><div id="41195755" class="c"><input type="checkbox" id="c-41195755" checked=""/><div class="controls bullet"><span class="by">soulbadguy</span><span>|</span><a href="#41195690">parent</a><span>|</span><a href="#41197140">next</a><span>|</span><label class="collapse" for="c-41195755">[-]</label><label class="expand" for="c-41195755">[17 more]</label></div><br/><div class="children"><div class="content">&gt;Intel&#x27;s problem isn&#x27;t that competitors want to storm the castle and achieve domination over the landscape that x86 controls.<p>IMO it&#x27;s both. While the importance x86 is declining, AMD is aggressively eating what ever part of it is left. 
I also think that in the long term, as intel and amd build better x86 chips, the value proposition of ARM will slowly fade in favor of something like risc-v</div><br/><div id="41196160" class="c"><input type="checkbox" id="c-41196160" checked=""/><div class="controls bullet"><span class="by">apantel</span><span>|</span><a href="#41195690">root</a><span>|</span><a href="#41195755">parent</a><span>|</span><a href="#41197140">next</a><span>|</span><label class="collapse" for="c-41196160">[-]</label><label class="expand" for="c-41196160">[16 more]</label></div><br/><div class="children"><div class="content">Asking because I don’t know: what is the value proposition of ARM?</div><br/><div id="41196476" class="c"><input type="checkbox" id="c-41196476" checked=""/><div class="controls bullet"><span class="by">adrian_b</span><span>|</span><a href="#41195690">root</a><span>|</span><a href="#41196160">parent</a><span>|</span><a href="#41196549">next</a><span>|</span><label class="collapse" for="c-41196476">[-]</label><label class="expand" for="c-41196476">[12 more]</label></div><br/><div class="children"><div class="content">The value of ARM is that anyone with enough money can license Arm cores and incorporate them in their own products, which can be optimized for some custom applications.<p>The level of customization possible with an x86 CPU is much less. You must buy a complete computer board or module and incorporate it in your product.<p>While for custom applications it is easy to create a superior solution with Arm cores, for general-purpose computers it is hard to compete with the Intel and AMD CPUs. All the computers with Arm cores have worse performance per dollar than similar x86 computers. (For instance there was recently a thread on HN about a credit-card-sized computer with an Intel N100 CPU and with the same price or lower as a Raspberry Pi, but with a much higher performance.)</div><br/><div id="41196945" class="c"><input type="checkbox" id="c-41196945" checked=""/><div class="controls bullet"><span class="by">hypercube33</span><span>|</span><a href="#41195690">root</a><span>|</span><a href="#41196476">parent</a><span>|</span><a href="#41196765">next</a><span>|</span><label class="collapse" for="c-41196945">[-]</label><label class="expand" for="c-41196945">[3 more]</label></div><br/><div class="children"><div class="content">AMD does offer custom x86 - see the steam deck, surface laptops and Xbox and PS4 and 5. Given there aren&#x27;t a ton of small fish making custom parts they are excellent at what they are made for.<p>AMD is pushing x86 to Apple ARM levels that keep power use low enough (best I&#x27;ve seen is 16 hour battery life on a device - I think MacBooks best this still) but performance per watt I haven&#x27;t seen ARM really top charts. They are awesome and I want arm and risc-v to really shine in laptops but the only player on the PC side is Qualcomm who was told to destroy their only flagship by ARM.</div><br/><div id="41199128" class="c"><input type="checkbox" id="c-41199128" checked=""/><div class="controls bullet"><span class="by">Panzer04</span><span>|</span><a href="#41195690">root</a><span>|</span><a href="#41196945">parent</a><span>|</span><a href="#41197126">next</a><span>|</span><label class="collapse" for="c-41199128">[-]</label><label class="expand" for="c-41199128">[1 more]</label></div><br/><div class="children"><div class="content">These sorts of processors are available from Intel as well (if anything, more available, as you can buy low-end 5w processors with modern e-cores in them, eg. N95&#x2F;N97). The commenter above is referring to these, and they are common in Mini-Pcs with 8-16GB of RAM and cost &lt;200USD. These sorts of processors crush the ARM competition at the same level right now (ie. the pi).<p>In fact, AMD doesn&#x27;t seem to have anything in the same segment currently, although they do exist in the higher tiers alongside Intel with their laptop processors.</div><br/></div></div><div id="41197126" class="c"><input type="checkbox" id="c-41197126" checked=""/><div class="controls bullet"><span class="by">soulbadguy</span><span>|</span><a href="#41195690">root</a><span>|</span><a href="#41196945">parent</a><span>|</span><a href="#41199128">prev</a><span>|</span><a href="#41196765">next</a><span>|</span><label class="collapse" for="c-41197126">[-]</label><label class="expand" for="c-41197126">[1 more]</label></div><br/><div class="children"><div class="content">&gt; AMD does offer custom x86<p>Not the same thing. On X86 you have to pay AMD or intel to design something for you.<p>In arm, you get to decide who design your chip or even have your own in house CPU design team.</div><br/></div></div></div></div><div id="41196765" class="c"><input type="checkbox" id="c-41196765" checked=""/><div class="controls bullet"><span class="by">AlexDragusin</span><span>|</span><a href="#41195690">root</a><span>|</span><a href="#41196476">parent</a><span>|</span><a href="#41196945">prev</a><span>|</span><a href="#41196760">next</a><span>|</span><label class="collapse" for="c-41196765">[-]</label><label class="expand" for="c-41196765">[1 more]</label></div><br/><div class="children"><div class="content">Radxa X4 low-cost, credit card-sized Intel N100 SBC goes for $60 and up <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=41007348">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=41007348</a></div><br/></div></div><div id="41196760" class="c"><input type="checkbox" id="c-41196760" checked=""/><div class="controls bullet"><span class="by">klelatti</span><span>|</span><a href="#41195690">root</a><span>|</span><a href="#41196476">parent</a><span>|</span><a href="#41196765">prev</a><span>|</span><a href="#41196549">next</a><span>|</span><label class="collapse" for="c-41196760">[-]</label><label class="expand" for="c-41196760">[7 more]</label></div><br/><div class="children"><div class="content">You’ve missed out one of Arm’s central value propositions which is power efficiency and the reason why it has more than 99% of the smartphone market.</div><br/><div id="41196980" class="c"><input type="checkbox" id="c-41196980" checked=""/><div class="controls bullet"><span class="by">adrian_b</span><span>|</span><a href="#41195690">root</a><span>|</span><a href="#41196760">parent</a><span>|</span><a href="#41196549">next</a><span>|</span><label class="collapse" for="c-41196980">[-]</label><label class="expand" for="c-41196980">[6 more]</label></div><br/><div class="children"><div class="content">There have been tons of proprietary CPU architectures with the same power efficiency as Arm. Only the x86 architecture is an outlier that requires an unusually complicated instruction decoder, which may degrade a little the energy efficiency.<p>Arm has eliminated most of the competing CPU architectures not by providing better power or energy efficiency, but by its business model of being licensable to anyone.<p>The ARM ISA was somewhat better than MIPS and SPARC, both of which have been handicapped by including some experimental features that have been later proved to be bad ideas. However there have been many other RISC ISAs more or less equivalent with ARM. Only the business model has extracted ARM from the crowd, not its technical advantages.</div><br/><div id="41197044" class="c"><input type="checkbox" id="c-41197044" checked=""/><div class="controls bullet"><span class="by">klelatti</span><span>|</span><a href="#41195690">root</a><span>|</span><a href="#41196980">parent</a><span>|</span><a href="#41196549">next</a><span>|</span><label class="collapse" for="c-41197044">[-]</label><label class="expand" for="c-41197044">[5 more]</label></div><br/><div class="children"><div class="content">You&#x27;re conflating the characteristics of the ISA with the value proposition offered by the designs using it. Not the same at all.<p>Other historical architectures typically targeted higher performance.<p>Arm specifically went after low-power applications, which continues today when we see the priorities in the design of Arm and x86 cores, for example.</div><br/><div id="41197213" class="c"><input type="checkbox" id="c-41197213" checked=""/><div class="controls bullet"><span class="by">adrian_b</span><span>|</span><a href="#41195690">root</a><span>|</span><a href="#41197044">parent</a><span>|</span><a href="#41197148">next</a><span>|</span><label class="collapse" for="c-41197213">[-]</label><label class="expand" for="c-41197213">[2 more]</label></div><br/><div class="children"><div class="content">Arm &quot;specifically went after low-power applications&quot; only in comparison with x86 or in comparison with a few other architectures restricted to workstations and servers, like DEC Alpha or Intel Itanium.<p>Before 2000, there were at least a dozen CPU architectures that went for the same low-power applications as Arm. There were a lot of microcontroller or processor vendors and each one of them had at least one proprietary ISA, if not 2 or 3 or even more different proprietary ISAs.<p>More than 20 years ago, I have redesigned various kinds of communication equipment, in order to replace many other kinds of CPUs, for example Motorola MC683xx or ColdFire or IBM PowerPC CPUs, with Arm CPUs.<p>In none of those cases the Arm CPUs had a lower power consumption or any other technical advantage. In fact in all cases the Arm CPUs were technically inferior to the CPUs replaced by them, which has required the implementation of various hardware and software workarounds.<p>There was only one reason why the Arm CPUs had been selected to replace their predecessors with different architectures, and that was the lower price. Their lower price was in great part due to the fact that there already were many competing vendors of Arm CPUs, so if you did not like one of them it was easy to replace it with another vendor.</div><br/><div id="41197344" class="c"><input type="checkbox" id="c-41197344" checked=""/><div class="controls bullet"><span class="by">klelatti</span><span>|</span><a href="#41195690">root</a><span>|</span><a href="#41197213">parent</a><span>|</span><a href="#41197148">next</a><span>|</span><label class="collapse" for="c-41197344">[-]</label><label class="expand" for="c-41197344">[1 more]</label></div><br/><div class="children"><div class="content">I get it that you don’t like Arm but that doesn’t change the fact that low power was and is central to their value proposition - and this latter fact doesn’t preclude other firms having low power offerings.</div><br/></div></div></div></div><div id="41197148" class="c"><input type="checkbox" id="c-41197148" checked=""/><div class="controls bullet"><span class="by">soulbadguy</span><span>|</span><a href="#41195690">root</a><span>|</span><a href="#41197044">parent</a><span>|</span><a href="#41197213">prev</a><span>|</span><a href="#41196549">next</a><span>|</span><label class="collapse" for="c-41197148">[-]</label><label class="expand" for="c-41197148">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s been said many time and the correlation between ISA and power efficiency have been debunked many time. ARM is power efficient because most ARM implementation are power efficient. Right now x86 AMD strix are about on par with  qualcom x elites</div><br/><div id="41197217" class="c"><input type="checkbox" id="c-41197217" checked=""/><div class="controls bullet"><span class="by">klelatti</span><span>|</span><a href="#41195690">root</a><span>|</span><a href="#41197148">parent</a><span>|</span><a href="#41196549">next</a><span>|</span><label class="collapse" for="c-41197217">[-]</label><label class="expand" for="c-41197217">[1 more]</label></div><br/><div class="children"><div class="content">Agreed. That power efficiency is still a central part of the Arm value proposition though. Others are competing with real designs on this with Arm in laptops but not in - for example - smartphones.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="41196549" class="c"><input type="checkbox" id="c-41196549" checked=""/><div class="controls bullet"><span class="by">NortySpock</span><span>|</span><a href="#41195690">root</a><span>|</span><a href="#41196160">parent</a><span>|</span><a href="#41196476">prev</a><span>|</span><a href="#41196377">next</a><span>|</span><label class="collapse" for="c-41196549">[-]</label><label class="expand" for="c-41196549">[1 more]</label></div><br/><div class="children"><div class="content">(simplifying) ARM provides verified, tested, standardized, reasonably well designed chips (logic circuits) that your company can purchase a license for and then send that chip design &#x2F; logic circuit to be etched on a wafer, cut, encapsulated, and soldered to a printed circuit board.<p>Those ARM CPUs support a standard (but ARM-flavored) assembly programming language. (Formally: Instruction Set Architecture)<p>Designing your own chip previously was risky because you might have logic or hardware bugs in your chip that were very hard to debug, and then you hope that someone will bother to write assembly code that works on your chip. Since you probably designed your own assembly language that co-evolved with your chip, those assembly code developers are going to be sinking a lot of time into understanding your chips and assembly code quirks to wring performance out of them.<p>RISC-V standardizes a RISC-V flavored assembly code (ISA) and also provides some certification test packages to prove that &quot;this particular chip design&quot; can execute the RISC-V assembly language according to specifications.</div><br/></div></div><div id="41196377" class="c"><input type="checkbox" id="c-41196377" checked=""/><div class="controls bullet"><span class="by">selimnairb</span><span>|</span><a href="#41195690">root</a><span>|</span><a href="#41196160">parent</a><span>|</span><a href="#41196549">prev</a><span>|</span><a href="#41197140">next</a><span>|</span><label class="collapse" for="c-41196377">[-]</label><label class="expand" for="c-41196377">[2 more]</label></div><br/><div class="children"><div class="content">In PCs, ARM CPUs perform just as good or better than AMD64 but have much better battery life. In the cloud, ARM CPUs are much cheaper (ca. 25% less) for the same or better performance.</div><br/><div id="41196438" class="c"><input type="checkbox" id="c-41196438" checked=""/><div class="controls bullet"><span class="by">soulbadguy</span><span>|</span><a href="#41195690">root</a><span>|</span><a href="#41196377">parent</a><span>|</span><a href="#41197140">next</a><span>|</span><label class="collapse" for="c-41196438">[-]</label><label class="expand" for="c-41196438">[1 more]</label></div><br/><div class="children"><div class="content">Not quite. I think we need to split the value of ARM the instruction from specific implementation.<p>1 - In term of pure efficiency, nothing magical about ARM. Looking at AMD latest strix laptop platform they are about on par with qualcomm new arm laptop chips.<p>Apple M* CPU are still better. However, a lot of that efficiency is platform derived.<p>2 - The lower cost in the cloud is a function of the middle man being removed. Amazon is selling graviton cheaper simply because they don&#x27;t have to pay the markup of AMD or Intel.</div><br/></div></div></div></div></div></div></div></div><div id="41197140" class="c"><input type="checkbox" id="c-41197140" checked=""/><div class="controls bullet"><span class="by">moffkalast</span><span>|</span><a href="#41195690">parent</a><span>|</span><a href="#41195755">prev</a><span>|</span><a href="#41195781">next</a><span>|</span><label class="collapse" for="c-41197140">[-]</label><label class="expand" for="c-41197140">[2 more]</label></div><br/><div class="children"><div class="content">AMD&#x27;s stormed the castle with Ryzen long ago and planted their flag, but since everyone&#x27;s still asleep at Castle Intel they haven&#x27;t really noticed.</div><br/><div id="41197740" class="c"><input type="checkbox" id="c-41197740" checked=""/><div class="controls bullet"><span class="by">JonChesterfield</span><span>|</span><a href="#41195690">root</a><span>|</span><a href="#41197140">parent</a><span>|</span><a href="#41195781">next</a><span>|</span><label class="collapse" for="c-41197740">[-]</label><label class="expand" for="c-41197740">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s sorrow and confusion at intel that the server and desktop markets are shrinking. People just aren&#x27;t buying as many computers any more. Not to worry though, they&#x27;ll probably want more in the future.<p>The rest of the world has noticed that people are buying lots of computers. This doesn&#x27;t seem to cause any cognitive dissonance for intel though. Perhaps &quot;computer&quot; means &quot;thing intel sells&quot; and excludes the work of the heathen outsiders. It makes for some quite confused reporting from the financial press.</div><br/></div></div></div></div></div></div><div id="41195781" class="c"><input type="checkbox" id="c-41195781" checked=""/><div class="controls bullet"><span class="by">causal</span><span>|</span><a href="#41195690">prev</a><span>|</span><a href="#41196096">next</a><span>|</span><label class="collapse" for="c-41195781">[-]</label><label class="expand" for="c-41195781">[5 more]</label></div><br/><div class="children"><div class="content">The article quotes a mention of Intel getting into the foundry business - this seems like the most obvious good move to make, even if a little late, right?<p>Being able to operate a general fab for chips seems far more important now than the design of the chips, since design has been somewhat commoditized by ARM. Any big downside for this move?</div><br/><div id="41196040" class="c"><input type="checkbox" id="c-41196040" checked=""/><div class="controls bullet"><span class="by">barkingcat</span><span>|</span><a href="#41195781">parent</a><span>|</span><a href="#41197765">next</a><span>|</span><label class="collapse" for="c-41196040">[-]</label><label class="expand" for="c-41196040">[3 more]</label></div><br/><div class="children"><div class="content">the downside is that the foundry process has to work properly, and by all reports, it hasn&#x27;t started working properly yet.</div><br/><div id="41196092" class="c"><input type="checkbox" id="c-41196092" checked=""/><div class="controls bullet"><span class="by">causal</span><span>|</span><a href="#41195781">root</a><span>|</span><a href="#41196040">parent</a><span>|</span><a href="#41197765">next</a><span>|</span><label class="collapse" for="c-41196092">[-]</label><label class="expand" for="c-41196092">[2 more]</label></div><br/><div class="children"><div class="content">Only report I saw on it was that Intel said they have tested working 18A chips.</div><br/><div id="41196412" class="c"><input type="checkbox" id="c-41196412" checked=""/><div class="controls bullet"><span class="by">sct202</span><span>|</span><a href="#41195781">root</a><span>|</span><a href="#41196092">parent</a><span>|</span><a href="#41197765">next</a><span>|</span><label class="collapse" for="c-41196412">[-]</label><label class="expand" for="c-41196412">[1 more]</label></div><br/><div class="children"><div class="content">They have to be able to mass produce on that node for it to save them. Samsung has been claiming technological leadership for that past few years with their 3nm node but nothing has come to market using it. IBM demoed a 2nm test chip in 2021, but has no ability to mass produce.</div><br/></div></div></div></div></div></div><div id="41197765" class="c"><input type="checkbox" id="c-41197765" checked=""/><div class="controls bullet"><span class="by">JonChesterfield</span><span>|</span><a href="#41195781">parent</a><span>|</span><a href="#41196040">prev</a><span>|</span><a href="#41196096">next</a><span>|</span><label class="collapse" for="c-41197765">[-]</label><label class="expand" for="c-41197765">[1 more]</label></div><br/><div class="children"><div class="content">There was lots of talk at the last earnings about &quot;clean sheet redesign&quot; to achieve &quot;world class foundary&quot; and a &quot;world class semiconductor. Sounds like getting the organisation ready to split in two to me.<p>That probably kills the vertical integration that made intel the world leader in the past though.</div><br/></div></div></div></div><div id="41196096" class="c"><input type="checkbox" id="c-41196096" checked=""/><div class="controls bullet"><span class="by">BadHumans</span><span>|</span><a href="#41195781">prev</a><span>|</span><a href="#41196936">next</a><span>|</span><label class="collapse" for="c-41196096">[-]</label><label class="expand" for="c-41196096">[17 more]</label></div><br/><div class="children"><div class="content">We are coming up on 7 years since the first Ryzen chip. In 7 years AMD went from very behind to a little behind then on-par and finally now market leader. The fact Intel let this happen in such a short time frame is a bit mind boggling.</div><br/><div id="41198797" class="c"><input type="checkbox" id="c-41198797" checked=""/><div class="controls bullet"><span class="by">userbinator</span><span>|</span><a href="#41196096">parent</a><span>|</span><a href="#41196345">next</a><span>|</span><label class="collapse" for="c-41198797">[-]</label><label class="expand" for="c-41198797">[1 more]</label></div><br/><div class="children"><div class="content">AMD and Intel have always been racing each other closely. Remember when the Athlons outperformed Netburst P4s while Intel was trying to get the latter to higher clock speeds? Then the Core series put Intel in the lead again, and now they&#x27;re losing to AMD once more. Here&#x27;s some 15-year-old benchmarks for your amusement:<p><a href="https:&#x2F;&#x2F;www.tomshardware.com&#x2F;reviews&#x2F;athlon-64-power,2259-9.html" rel="nofollow">https:&#x2F;&#x2F;www.tomshardware.com&#x2F;reviews&#x2F;athlon-64-power,2259-9....</a></div><br/></div></div><div id="41196345" class="c"><input type="checkbox" id="c-41196345" checked=""/><div class="controls bullet"><span class="by">layer8</span><span>|</span><a href="#41196096">parent</a><span>|</span><a href="#41198797">prev</a><span>|</span><a href="#41196406">next</a><span>|</span><label class="collapse" for="c-41196345">[-]</label><label class="expand" for="c-41196345">[8 more]</label></div><br/><div class="children"><div class="content">AMD is not the market leader in any segment, by any approximation: <a href="https:&#x2F;&#x2F;www.theregister.com&#x2F;2024&#x2F;05&#x2F;10&#x2F;amd_gains_on_intel&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.theregister.com&#x2F;2024&#x2F;05&#x2F;10&#x2F;amd_gains_on_intel&#x2F;</a></div><br/><div id="41196539" class="c"><input type="checkbox" id="c-41196539" checked=""/><div class="controls bullet"><span class="by">adrian_b</span><span>|</span><a href="#41196096">root</a><span>|</span><a href="#41196345">parent</a><span>|</span><a href="#41196471">next</a><span>|</span><label class="collapse" for="c-41196539">[-]</label><label class="expand" for="c-41196539">[1 more]</label></div><br/><div class="children"><div class="content">In server CPUs, Intel still has a larger market share than AMD, but judging for the published financial results, where most of the loss is in server CPUs, Intel has succeeded to keep that diminishing market share only by accepting a great loss caused by huge discounts, which has determined the action price fall, so perhaps trying so hard to retain the market share has not been an optimal decision.<p>So AMD definitely leads over Intel from the POV of the profits obtained in the server CPU market segment.<p>There are also various small markets where AMD leads comfortably over Intel by volume, e.g. Amazon currently sells much more AMD CPUs than Intel CPUs.</div><br/></div></div><div id="41196471" class="c"><input type="checkbox" id="c-41196471" checked=""/><div class="controls bullet"><span class="by">BadHumans</span><span>|</span><a href="#41196096">root</a><span>|</span><a href="#41196345">parent</a><span>|</span><a href="#41196539">prev</a><span>|</span><a href="#41196406">next</a><span>|</span><label class="collapse" for="c-41196471">[-]</label><label class="expand" for="c-41196471">[6 more]</label></div><br/><div class="children"><div class="content">My phrasing is confusing and I apologize for that. I do not mean market leader in that there are more AMD CPUs than Intel CPU. I&#x27;m speaking about hardware performance.</div><br/><div id="41196561" class="c"><input type="checkbox" id="c-41196561" checked=""/><div class="controls bullet"><span class="by">layer8</span><span>|</span><a href="#41196096">root</a><span>|</span><a href="#41196471">parent</a><span>|</span><a href="#41196406">next</a><span>|</span><label class="collapse" for="c-41196561">[-]</label><label class="expand" for="c-41196561">[5 more]</label></div><br/><div class="children"><div class="content">You are right for multi-core performance, but Intel has still a slight edge in single-core performance, and in idle power usage, which is important to many. Intel also has a stronger offering in the now-popular mini PC segment.</div><br/><div id="41199100" class="c"><input type="checkbox" id="c-41199100" checked=""/><div class="controls bullet"><span class="by">scheeseman486</span><span>|</span><a href="#41196096">root</a><span>|</span><a href="#41196561">parent</a><span>|</span><a href="#41197779">next</a><span>|</span><label class="collapse" for="c-41199100">[-]</label><label class="expand" for="c-41199100">[1 more]</label></div><br/><div class="children"><div class="content">The X3D chips typically edge out Intel for single core performance and Intel chips also need to be run <i>hard</i> to match them. Idle power consumption is pretty bad on AMD desktop chips, but under load AMD is typically far more efficient. Regardless, on the desktop any of Intel&#x27;s advantages at the high end are somewhat moot considering that all of those chips ship with and are currently running microcode that is overvolting and degrading the silicon, causing permanent damage. There&#x27;s plans for a fix, but there&#x27;s a good chance that fix will come with lower performance. The N100 is a bargain, but as soon as you want passable graphics AMD becomes the only option.<p>Intel are facing credible competition from both AMD and ARM in most market segments amidst a quality control catastrophe, cultural problems, R&amp;D problems. Their future outlook doesn&#x27;t look very good.</div><br/></div></div><div id="41197779" class="c"><input type="checkbox" id="c-41197779" checked=""/><div class="controls bullet"><span class="by">JonChesterfield</span><span>|</span><a href="#41196096">root</a><span>|</span><a href="#41196561">parent</a><span>|</span><a href="#41199100">prev</a><span>|</span><a href="#41196744">next</a><span>|</span><label class="collapse" for="c-41197779">[-]</label><label class="expand" for="c-41197779">[1 more]</label></div><br/><div class="children"><div class="content">Didn&#x27;t they lose the single core lead recently, despite running their chips so aggressively clocked that they&#x27;re burning out at stock settings?<p>The APU systems from AMD work really well as mini-pc systems, though I&#x27;m unfamiliar with Intel products there. Perhaps they&#x27;re better.</div><br/></div></div><div id="41197757" class="c"><input type="checkbox" id="c-41197757" checked=""/><div class="controls bullet"><span class="by">BadHumans</span><span>|</span><a href="#41196096">root</a><span>|</span><a href="#41196561">parent</a><span>|</span><a href="#41196744">prev</a><span>|</span><a href="#41196406">next</a><span>|</span><label class="collapse" for="c-41197757">[-]</label><label class="expand" for="c-41197757">[1 more]</label></div><br/><div class="children"><div class="content">If we are mentioning mini PCs then I think it is only fair to mention that every single console went to AMD for chips.</div><br/></div></div></div></div></div></div></div></div><div id="41196406" class="c"><input type="checkbox" id="c-41196406" checked=""/><div class="controls bullet"><span class="by">nasdaq-txn</span><span>|</span><a href="#41196096">parent</a><span>|</span><a href="#41196345">prev</a><span>|</span><a href="#41196936">next</a><span>|</span><label class="collapse" for="c-41196406">[-]</label><label class="expand" for="c-41196406">[7 more]</label></div><br/><div class="children"><div class="content">Market leader in what? Intel&#x27;s Q2 revenue is over double that of AMD&#x27;s. Intel still controls well over 60% of the x86 space. Intel and AMD&#x27;s most performant x86 offerings are fairly close to each other.</div><br/><div id="41196487" class="c"><input type="checkbox" id="c-41196487" checked=""/><div class="controls bullet"><span class="by">BadHumans</span><span>|</span><a href="#41196096">root</a><span>|</span><a href="#41196406">parent</a><span>|</span><a href="#41196936">next</a><span>|</span><label class="collapse" for="c-41196487">[-]</label><label class="expand" for="c-41196487">[6 more]</label></div><br/><div class="children"><div class="content">Performance. Intel still manages to squeak out some wins against AMD when it comes to single-threaded CPU task but in every other metric, they are chasing AMD.</div><br/><div id="41196671" class="c"><input type="checkbox" id="c-41196671" checked=""/><div class="controls bullet"><span class="by">adrian_b</span><span>|</span><a href="#41196096">root</a><span>|</span><a href="#41196487">parent</a><span>|</span><a href="#41197804">next</a><span>|</span><label class="collapse" for="c-41196671">[-]</label><label class="expand" for="c-41196671">[1 more]</label></div><br/><div class="children"><div class="content">Not only in performance, but also in profits, as shown by the Intel vs. AMD financial results. Especially in the server CPU market segment, where Intel has a diminishing market share and losses of billions, while AMD has an increasing market share and profits.<p>The new Zen 5 has much better single-thread performance than any Intel CPU (e.g. the slower 5.5 GHz Zen 5 launched this week matches a 6.0 GHz Raptor Lake), so for a couple of months, until Intel launches Arrow Lake S, AMD will have much better single-thread performance. After that, Intel and AMD will be again at parity, with negligible differences in ST speed.</div><br/></div></div><div id="41197804" class="c"><input type="checkbox" id="c-41197804" checked=""/><div class="controls bullet"><span class="by">JonChesterfield</span><span>|</span><a href="#41196096">root</a><span>|</span><a href="#41196487">parent</a><span>|</span><a href="#41196671">prev</a><span>|</span><a href="#41196936">next</a><span>|</span><label class="collapse" for="c-41197804">[-]</label><label class="expand" for="c-41197804">[4 more]</label></div><br/><div class="children"><div class="content">Power too. I think we&#x27;re still in the happy place where buying epyc is cheaper than being given xeons for free after you look at the electricity bill over the life of the machine.</div><br/><div id="41199158" class="c"><input type="checkbox" id="c-41199158" checked=""/><div class="controls bullet"><span class="by">Panzer04</span><span>|</span><a href="#41196096">root</a><span>|</span><a href="#41197804">parent</a><span>|</span><a href="#41196936">next</a><span>|</span><label class="collapse" for="c-41199158">[-]</label><label class="expand" for="c-41199158">[3 more]</label></div><br/><div class="children"><div class="content">Is this actually true? At 200w power draw 24&#x2F;365 you&#x27;re talking 1800kwh. at 0.2$&#x2F;kwh that&#x27;s 360$.<p>These server processors seem to be charged out at multiple thousands of dollars. Is the difference in efficiency in server actually as large as claimed? Surely a sufficient discount on the capital cost of a processor can more than make up for extra power usage.<p>I guess it all depends on the comparative price&#x2F;power consumption, it just feels like the difference would have to be rather large to me.</div><br/><div id="41199296" class="c"><input type="checkbox" id="c-41199296" checked=""/><div class="controls bullet"><span class="by">simplyinfinity</span><span>|</span><a href="#41196096">root</a><span>|</span><a href="#41199158">parent</a><span>|</span><a href="#41196936">next</a><span>|</span><label class="collapse" for="c-41199296">[-]</label><label class="expand" for="c-41199296">[2 more]</label></div><br/><div class="children"><div class="content">You&#x27;re not considering the core count difference. Amd has 128cores 256 threads at 2.2ghz at  360w tdp  while Intel has 144c&#x2F;144t, @ 2.2ghz @ 330w Tdp. Cloud providers care about density and power usage.
More cores per server = less power = more servers per rack = more capacity = more opportunities for sales of products.</div><br/><div id="41199575" class="c"><input type="checkbox" id="c-41199575" checked=""/><div class="controls bullet"><span class="by">Panzer04</span><span>|</span><a href="#41196096">root</a><span>|</span><a href="#41199296">parent</a><span>|</span><a href="#41196936">next</a><span>|</span><label class="collapse" for="c-41199575">[-]</label><label class="expand" for="c-41199575">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not really in the space - I was curious. I think people tend to overstate the importance of power consumption relative to the price of the products they buy and the value of their time (eg. if it&#x27;s a workstation part, higher performance is worth a significant tradeoff in power if it gets jobs like compilation done 10% faster based on the employee time it can save)<p>For servers, I&#x27;m always curious because even though they run 24&#x2F;365 (so power consumption is v.important), the capital cost of new server chips is incredibly high - eg. those 144c chips I presume you&#x27;re referring to cost 10k+, so even over a 5y service life that&#x27;s probably only 20% of the chip only, and relative to the AMD chip the additional inefficiency could easily by compensated by an appropriate discount.<p>Obviously all of this is why intel still exists in the DC, they just can&#x27;t charge the same prices as AMD can is all.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="41196936" class="c"><input type="checkbox" id="c-41196936" checked=""/><div class="controls bullet"><span class="by">theparanoid</span><span>|</span><a href="#41196096">prev</a><span>|</span><a href="#41196393">next</a><span>|</span><label class="collapse" for="c-41196936">[-]</label><label class="expand" for="c-41196936">[1 more]</label></div><br/><div class="children"><div class="content">Intel&#x27;s decline was obvious when I worked for them in 2010, their compensation package wasn&#x27;t competitive with FANG and they consistently missed out or lost their better engineers.</div><br/></div></div><div id="41196393" class="c"><input type="checkbox" id="c-41196393" checked=""/><div class="controls bullet"><span class="by">42lux</span><span>|</span><a href="#41196936">prev</a><span>|</span><a href="#41197054">next</a><span>|</span><label class="collapse" for="c-41196393">[-]</label><label class="expand" for="c-41196393">[2 more]</label></div><br/><div class="children"><div class="content">They just slept for a decade... I had an overclocked i7 3970k (2012) and there was no need to update for 8 years. The perfomance increase was always marginal. I finally pulled the trigger when AVX happened.</div><br/><div id="41199664" class="c"><input type="checkbox" id="c-41199664" checked=""/><div class="controls bullet"><span class="by">nikanj</span><span>|</span><a href="#41196393">parent</a><span>|</span><a href="#41197054">next</a><span>|</span><label class="collapse" for="c-41199664">[-]</label><label class="expand" for="c-41199664">[1 more]</label></div><br/><div class="children"><div class="content">And then you learn AVX is only available on some cores, lowers the operating frequency of the whole cpu when you use it, and generally seems like an unstable prototype</div><br/></div></div></div></div><div id="41197054" class="c"><input type="checkbox" id="c-41197054" checked=""/><div class="controls bullet"><span class="by">gumby</span><span>|</span><a href="#41196393">prev</a><span>|</span><a href="#41197192">next</a><span>|</span><label class="collapse" for="c-41197054">[-]</label><label class="expand" for="c-41197054">[1 more]</label></div><br/><div class="children"><div class="content">The &quot;paradox of the x86&quot; is simply the classic Innovator&#x27;s Dilemma.  In fact the history of the last 20 years against ARM could be a case study right out of the book.<p>Worse for Intel, AMD flubbed it time and time again, but now Intel is too weak to defend against a resurgent AMD.<p>Meanwhile they are cutting headcount deeply yet only now suspended the dividend.  Madness!<p>They should take a page out of AMD&#x27;s book and spin off fab.  That new company can then be flooded with &quot;strategic&quot; government aid, and maybe the rest of intel can catch up (or not) but it would at least give the shareholders a better chance.  Right now the combination is acting like two anchors tied together.</div><br/></div></div><div id="41197192" class="c"><input type="checkbox" id="c-41197192" checked=""/><div class="controls bullet"><span class="by">sargun</span><span>|</span><a href="#41197054">prev</a><span>|</span><a href="#41196725">next</a><span>|</span><label class="collapse" for="c-41197192">[-]</label><label class="expand" for="c-41197192">[2 more]</label></div><br/><div class="children"><div class="content">I feel like Intel has embarked upon a bunch of good ideas like SDI (<a href="https:&#x2F;&#x2F;www.intel.com&#x2F;content&#x2F;www&#x2F;us&#x2F;en&#x2F;manufacturing&#x2F;software-defined-infrastructure.html" rel="nofollow">https:&#x2F;&#x2F;www.intel.com&#x2F;content&#x2F;www&#x2F;us&#x2F;en&#x2F;manufacturing&#x2F;softwa...</a>), IoT &#x2F; Edison (<a href="https:&#x2F;&#x2F;ark.intel.com&#x2F;content&#x2F;www&#x2F;us&#x2F;en&#x2F;ark&#x2F;products&#x2F;84572&#x2F;intel-edison-compute-module-iot.html" rel="nofollow">https:&#x2F;&#x2F;ark.intel.com&#x2F;content&#x2F;www&#x2F;us&#x2F;en&#x2F;ark&#x2F;products&#x2F;84572&#x2F;i...</a>), Silicon Photonics (<a href="https:&#x2F;&#x2F;www.intel.com&#x2F;content&#x2F;www&#x2F;us&#x2F;en&#x2F;products&#x2F;details&#x2F;network-io&#x2F;silicon-photonics.html" rel="nofollow">https:&#x2F;&#x2F;www.intel.com&#x2F;content&#x2F;www&#x2F;us&#x2F;en&#x2F;products&#x2F;details&#x2F;net...</a>), and SDN (<a href="https:&#x2F;&#x2F;www.intc.com&#x2F;news-events&#x2F;press-releases&#x2F;detail&#x2F;640&#x2F;intel-to-acquire-fulcrum-microsystems" rel="nofollow">https:&#x2F;&#x2F;www.intc.com&#x2F;news-events&#x2F;press-releases&#x2F;detail&#x2F;640&#x2F;i...</a>).<p>But, they manage to fail to capitalize on any of these. What&#x27;s wrong with them?</div><br/><div id="41198893" class="c"><input type="checkbox" id="c-41198893" checked=""/><div class="controls bullet"><span class="by">bn-l</span><span>|</span><a href="#41197192">parent</a><span>|</span><a href="#41196725">next</a><span>|</span><label class="collapse" for="c-41198893">[-]</label><label class="expand" for="c-41198893">[1 more]</label></div><br/><div class="children"><div class="content">Ask them why they sold their ssd division. It’s almost intentionally bad.</div><br/></div></div></div></div><div id="41196725" class="c"><input type="checkbox" id="c-41196725" checked=""/><div class="controls bullet"><span class="by">projektfu</span><span>|</span><a href="#41197192">prev</a><span>|</span><a href="#41198870">next</a><span>|</span><label class="collapse" for="c-41196725">[-]</label><label class="expand" for="c-41196725">[1 more]</label></div><br/><div class="children"><div class="content">I think referring to bankruptcy is excessive.  Intel bulls might be going bankrupt, but the share price doesn&#x27;t affect most companies unless their only reasonable way to raise money is through the stock market.  The Intel bond yields are not too high yet.<p>The question then becomes, is this a low (trading around book value) with recovery in the future, or is it the beginning of a long, dark time, leading to an inability to raise money down the line?</div><br/></div></div><div id="41198870" class="c"><input type="checkbox" id="c-41198870" checked=""/><div class="controls bullet"><span class="by">osigurdson</span><span>|</span><a href="#41196725">prev</a><span>|</span><a href="#41196240">next</a><span>|</span><label class="collapse" for="c-41198870">[-]</label><label class="expand" for="c-41198870">[1 more]</label></div><br/><div class="children"><div class="content">I know what to do... a re-org!</div><br/></div></div><div id="41196240" class="c"><input type="checkbox" id="c-41196240" checked=""/><div class="controls bullet"><span class="by">debatem1</span><span>|</span><a href="#41198870">prev</a><span>|</span><a href="#41195546">next</a><span>|</span><label class="collapse" for="c-41196240">[-]</label><label class="expand" for="c-41196240">[4 more]</label></div><br/><div class="children"><div class="content">Intel&#x27;s main problem is its people. Sorry to say.<p>The management culture there is insanely siloed and toxic, full of scar tissue from previous periods of political turmoil and a few relentless sociopaths who absolutely will not stop climbing just because it&#x27;s obviously damaging to the company.<p>The engineering culture is full of secrets, moats, and the general sense that while making progress might be your job, stopping it is <i>everyone&#x27;s</i> job. And there are always more of them than there are of you.<p>Perhaps most fatally, responsibility for decisionmaking is ultimately delegated to the process of decisionmaking rather than the people involved. The resulting proliferation of checkboxes and box checkers have elevated dysfunctions like &quot;the perfect being the enemy of the good&quot; and &quot;none of us is as dumb as all of us&quot; into de facto mottos for large parts of the company.<p>All of this happens against the backdrop of eroding mind and marketshare, a total lack of real product clarity, and a pervasive culture of bullshit that puffs politically convenient non-accomplishments into events worth of companywide applause while spinning, downplaying, or even hiding bad news of calamitous import.<p>Intel has vast reserves of talent but without deep (IMO, impossible) cultural changes it will inevitably fail under its own weight.</div><br/><div id="41197019" class="c"><input type="checkbox" id="c-41197019" checked=""/><div class="controls bullet"><span class="by">age1mlclg6</span><span>|</span><a href="#41196240">parent</a><span>|</span><a href="#41195546">next</a><span>|</span><label class="collapse" for="c-41197019">[-]</label><label class="expand" for="c-41197019">[3 more]</label></div><br/><div class="children"><div class="content">I had to create an account to say that I agree with this comment.<p>I am a former Intel engineer who worked there for 8 years. I left Intel 2 years after the ACT mass layoff in 2016.<p>The culture there is extremely toxic from top to bottom.  The VP&#x27;s and top level executives were out to get stocks and golden parachutes.  The middle managers played politics.  In addition, they also pulled a blind over leadership on many significant happenings.  The engineers &#x2F; technicians kept secrets as a way of keeping themselves relevant and valuable in case of layoff events.<p>The main and sole money maker for Intel is getting quality silicon out of the door and that should be the number one objective for everyone.  However, due to stack ranking, that is getting as many bullet points as possible in order to appear relevant when it comes annual review or mass layoff events, many people come up with bullshit projects that while on the surface look extremely impressive, have nothing relevant to pushing quality silicon out.  The middle managers play favorites and push or highlight those bullshit projects.<p>When they fly expensive executives around for the BUM&#x27;s (Business Update Meetings) or to pitch some bullshit ideas, not many had the courage to ask the relevant questions.  The few who asked them were met with canned and non-informative responses that only showed that these expensive suits had no awareness of what was going on externally. At the same time, we were too busy patting ourselves on the back, claiming that we were number one.<p>We were too busy playing political games and competing internally that we forgot about the real external competitions, and then it was too late and they zoomed right past us.<p>I doubt the CEO (past and present) or VP&#x27;s care or even have an inkling on what has been going on in the culture.</div><br/><div id="41198909" class="c"><input type="checkbox" id="c-41198909" checked=""/><div class="controls bullet"><span class="by">bn-l</span><span>|</span><a href="#41196240">root</a><span>|</span><a href="#41197019">parent</a><span>|</span><a href="#41195546">next</a><span>|</span><label class="collapse" for="c-41198909">[-]</label><label class="expand" for="c-41198909">[2 more]</label></div><br/><div class="children"><div class="content">It sounds a lot like the chaos and inefficiencies of the caste system. Hmm.</div><br/><div id="41199666" class="c"><input type="checkbox" id="c-41199666" checked=""/><div class="controls bullet"><span class="by">xwolfi</span><span>|</span><a href="#41196240">root</a><span>|</span><a href="#41198909">parent</a><span>|</span><a href="#41195546">next</a><span>|</span><label class="collapse" for="c-41199666">[-]</label><label class="expand" for="c-41199666">[1 more]</label></div><br/><div class="children"><div class="content">Tbh, it sounds like every group of humans...</div><br/></div></div></div></div></div></div></div></div><div id="41196327" class="c"><input type="checkbox" id="c-41196327" checked=""/><div class="controls bullet"><span class="by">einpoklum</span><span>|</span><a href="#41195546">prev</a><span>|</span><a href="#41196445">next</a><span>|</span><label class="collapse" for="c-41196327">[-]</label><label class="expand" for="c-41196327">[8 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t know, a lot of these explanations seem more like reading astrological maps in hindsight. Example:<p>&gt; <i>Intel passed on making the System on Chip for Apple’s new iPhone, Instead Apple used an Arm designed processor in an SoC built by Samsung. Too late Intel realised the mistake.</i><p>Mistake? AMD didn&#x27;t even try to build SoCs to compete with ARM &#x2F; Qualcomm &#x2F; etc. They seem to be doing ok.<p>Now, you could say &quot;Well, throwing 10^10 USD on trying to build an SoC was the mistake&quot; - maybe, but then it&#x27;s the opposite mistake than the article claims.</div><br/><div id="41196900" class="c"><input type="checkbox" id="c-41196900" checked=""/><div class="controls bullet"><span class="by">klelatti</span><span>|</span><a href="#41196327">parent</a><span>|</span><a href="#41198013">next</a><span>|</span><label class="collapse" for="c-41196900">[-]</label><label class="expand" for="c-41196900">[6 more]</label></div><br/><div class="children"><div class="content">No it was a both a huge mistake and a symptom of underlying problems. Making smartphone SoCs is a huge profitable market that would have given Intel massive volumes to support R&amp;D etc and slowed TSMC. The fact that they couldn’t manage it with every apparent advantage is very telling.</div><br/><div id="41197072" class="c"><input type="checkbox" id="c-41197072" checked=""/><div class="controls bullet"><span class="by">talldayo</span><span>|</span><a href="#41196327">root</a><span>|</span><a href="#41196900">parent</a><span>|</span><a href="#41197271">next</a><span>|</span><label class="collapse" for="c-41197072">[-]</label><label class="expand" for="c-41197072">[4 more]</label></div><br/><div class="children"><div class="content">Feels like you&#x27;re rewriting history, to me. Smartphone SoCs are <i>not</i> hugely profitable, and a big point of the past 10 years were Chinese manufacturers entirely ignoring ARM IP to increase profits. The only people that make money off ARM hardware are the export-officiated manufacturers that don&#x27;t pay per-unit licenses; which is exclusively Apple. Nobody else has a more permissive ARM architecture license, not even Nvidia.<p>Intel at the time was fabless, would have needed to license or design a RISC architecture, and would have ended up just as squeezed as any other part of Apple&#x27;s supply chain. And if Intel made a serious profit, Apple would have replaced them anyways. It&#x27;s an all-risk-no-reward scenario.</div><br/><div id="41197133" class="c"><input type="checkbox" id="c-41197133" checked=""/><div class="controls bullet"><span class="by">klelatti</span><span>|</span><a href="#41196327">root</a><span>|</span><a href="#41197072">parent</a><span>|</span><a href="#41197875">next</a><span>|</span><label class="collapse" for="c-41197133">[-]</label><label class="expand" for="c-41197133">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Intel at the time was fabless<p>????????!</div><br/><div id="41198020" class="c"><input type="checkbox" id="c-41198020" checked=""/><div class="controls bullet"><span class="by">201984</span><span>|</span><a href="#41196327">root</a><span>|</span><a href="#41197133">parent</a><span>|</span><a href="#41197875">next</a><span>|</span><label class="collapse" for="c-41198020">[-]</label><label class="expand" for="c-41198020">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, what?!</div><br/></div></div></div></div><div id="41197875" class="c"><input type="checkbox" id="c-41197875" checked=""/><div class="controls bullet"><span class="by">sizzle</span><span>|</span><a href="#41196327">root</a><span>|</span><a href="#41197072">parent</a><span>|</span><a href="#41197133">prev</a><span>|</span><a href="#41197271">next</a><span>|</span><label class="collapse" for="c-41197875">[-]</label><label class="expand" for="c-41197875">[1 more]</label></div><br/><div class="children"><div class="content">Best take I’ve read here or anywhere. Thanks for the clarity.</div><br/></div></div></div></div><div id="41197271" class="c"><input type="checkbox" id="c-41197271" checked=""/><div class="controls bullet"><span class="by">soulbadguy</span><span>|</span><a href="#41196327">root</a><span>|</span><a href="#41196900">parent</a><span>|</span><a href="#41197072">prev</a><span>|</span><a href="#41198013">next</a><span>|</span><label class="collapse" for="c-41197271">[-]</label><label class="expand" for="c-41197271">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Making smartphone SoCs is a huge profitable market that would have given Intel massive volumes to support R&amp;D etc and slowed TSMC.<p>Not quite, and that&#x27;s the core of the &quot;innovator&quot; dilemma. The reason why intel passed on making SOC, is the same why nvidia decided to pass on getting into xboxss and playstations. Those market have much lower margin than server side business.<p>AMD, and TSMC can operate in those space because they are much more efficient companies, intel is not.<p>Intel got addicted to fat server CPU margin, grew inefficient...</div><br/></div></div></div></div></div></div><div id="41196445" class="c"><input type="checkbox" id="c-41196445" checked=""/><div class="controls bullet"><span class="by">scotty79</span><span>|</span><a href="#41196327">prev</a><span>|</span><a href="#41196336">next</a><span>|</span><label class="collapse" for="c-41196445">[-]</label><label class="expand" for="c-41196445">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m buying PCs for myself for three decades and never chose Intel for my build (apart from the Pentium 133 in my first pc computer). Every time I considered it but alternative was just significantly cheaper option at power levels that interested me.<p>The only Intel&#x27;s I got were in laptops where I was interested only about the price of a whole PC that interested me for other reasons than CPU.<p>Since Internet became a thing I choose CPU by downloading price and benchmark results, drawing price&#x2F;power chart and choosing a point on a good edge of a point cloud that&#x27;s not unreasonably expensive. It never happened to be Intel.</div><br/></div></div><div id="41196336" class="c"><input type="checkbox" id="c-41196336" checked=""/><div class="controls bullet"><span class="by">talldayo</span><span>|</span><a href="#41196445">prev</a><span>|</span><label class="collapse" for="c-41196336">[-]</label><label class="expand" for="c-41196336">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Intel couldn&#x27;t break into smartphone SoCs with clear process leadership and the financial strength to invest heavily. Why should it be able to break into other competitive markets today when it no longer has those advantages?<p>Maybe because you&#x27;re looking at it backwards? There must be some conspiracy among Softbank investors to portray everyone that doesn&#x27;t pay for ARM licenses as a Muppet. Intel has no competitive advantage manufacturing licensed RISC CPUs when their desktop and server markets are hot, and even when x86 dies it will still be less attractive than owning fabs. With how bad the Cortex designs continue to be and how much leeway ARM gives licensees like Apple, even businesses like Qualcomm can&#x27;t be bothered to take the ISA seriously. It feels disingenuous to say ARM is the panacea when designing ARM cores would have left Intel in an even worse position.<p>Look at Samsung; a company people on this site would describe as misery incarnate, but chances are they&#x27;re typing their comment from a device using Samsung-fabbed silicon. They&#x27;re not even that competitive either; they just offer a cheap alternative to TSMC that offers OEMs an economically-minded option for less dense components.</div><br/><div id="41196498" class="c"><input type="checkbox" id="c-41196498" checked=""/><div class="controls bullet"><span class="by">klelatti</span><span>|</span><a href="#41196336">parent</a><span>|</span><label class="collapse" for="c-41196498">[-]</label><label class="expand" for="c-41196498">[1 more]</label></div><br/><div class="children"><div class="content">&gt; It feels disingenuous to say ARM is the panacea when designing ARM cores would have left Intel in an even worse position.<p>Sorry, where does the article say Intel should design Arm cores in 2024?</div><br/></div></div></div></div></div></div></div></div></div></body></html>