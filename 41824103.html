<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1728810068115" as="style"/><link rel="stylesheet" href="styles.css?v=1728810068115"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://arxiv.org/abs/2410.04444">Gödel Agent: A self-referential agent framework for recursive self-improvement</a> <span class="domain">(<a href="https://arxiv.org">arxiv.org</a>)</span></div><div class="subtext"><span>tkgally</span> | <span>22 comments</span></div><br/><div><div id="41825540" class="c"><input type="checkbox" id="c-41825540" checked=""/><div class="controls bullet"><span class="by">blackcat201</span><span>|</span><a href="#41824633">next</a><span>|</span><label class="collapse" for="c-41825540">[-]</label><label class="expand" for="c-41825540">[1 more]</label></div><br/><div class="children"><div class="content">Shameless plug, for anyone who&#x27;s interested in &quot;self-improvement&quot; agent check out StreamBench[1] where we benchmark and try out what&#x27;s essential for improvements in online settings. Basically we find feedback signal is vital and the stronger the signal the more improvement you can get if you were able to feed it back to the agent in terms of weights (LoRA) or in-context examples.<p>[1] <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2406.08747" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2406.08747</a></div><br/></div></div><div id="41824633" class="c"><input type="checkbox" id="c-41824633" checked=""/><div class="controls bullet"><span class="by">gdiamos</span><span>|</span><a href="#41825540">prev</a><span>|</span><a href="#41824930">next</a><span>|</span><label class="collapse" for="c-41824633">[-]</label><label class="expand" for="c-41824633">[2 more]</label></div><br/><div class="children"><div class="content">Can it modify its training data?</div><br/><div id="41825840" class="c"><input type="checkbox" id="c-41825840" checked=""/><div class="controls bullet"><span class="by">keskival</span><span>|</span><a href="#41824633">parent</a><span>|</span><a href="#41824930">next</a><span>|</span><label class="collapse" for="c-41825840">[-]</label><label class="expand" for="c-41825840">[1 more]</label></div><br/><div class="children"><div class="content">Nope, just the code which sets up the agentic system and related prompts.</div><br/></div></div></div></div><div id="41824930" class="c"><input type="checkbox" id="c-41824930" checked=""/><div class="controls bullet"><span class="by">grahamj</span><span>|</span><a href="#41824633">prev</a><span>|</span><a href="#41825184">next</a><span>|</span><label class="collapse" for="c-41824930">[-]</label><label class="expand" for="c-41824930">[8 more]</label></div><br/><div class="children"><div class="content">heh I was just working on something that tries to improve itself today. I wrote a simple agent executor that makes calling one a simple function call, and then wrote an agent which invents other agents. By calling that in a loop for a while I ended up with, effectively, a large library of functions I not only didn&#x27;t write but didn&#x27;t even think up.<p>By passing those functions as tools in LLM requests any of the agents can make use of any of the other agents so it&#x27;s basically expanding its own capabilities.<p>Not quite sure what task to sick it on yet but it&#x27;s fun to play with.</div><br/></div></div><div id="41825184" class="c"><input type="checkbox" id="c-41825184" checked=""/><div class="controls bullet"><span class="by">digitcatphd</span><span>|</span><a href="#41824930">prev</a><span>|</span><a href="#41824839">next</a><span>|</span><label class="collapse" for="c-41825184">[-]</label><label class="expand" for="c-41825184">[1 more]</label></div><br/><div class="children"><div class="content">I’m skeptical this would work in production better than RLHF, if the agent makes a mistake, how is it supposed to know to correct itself and understand what it did wrong to prevent it? It seems better to try again recursively until it finds the solution like a human</div><br/></div></div><div id="41825893" class="c"><input type="checkbox" id="c-41825893" checked=""/><div class="controls bullet"><span class="by">optimalsolver</span><span>|</span><a href="#41824839">prev</a><span>|</span><a href="#41824727">next</a><span>|</span><label class="collapse" for="c-41825893">[-]</label><label class="expand" for="c-41825893">[2 more]</label></div><br/><div class="children"><div class="content">&gt;The rapid advancement of large language models (LLMs) has significantly enhanced the capabilities of AI-driven agents across various tasks<p>No it hasn&#x27;t.</div><br/><div id="41826018" class="c"><input type="checkbox" id="c-41826018" checked=""/><div class="controls bullet"><span class="by">derektank</span><span>|</span><a href="#41825893">parent</a><span>|</span><a href="#41824727">next</a><span>|</span><label class="collapse" for="c-41826018">[-]</label><label class="expand" for="c-41826018">[1 more]</label></div><br/><div class="children"><div class="content">Siri is a lot more capable at managing calendars with the iOS 18.1 update, at least in the 20 minutes I spent playing around with a friend&#x27;s iPhone that was in the beta. My understanding is that most of the capability improvement is due to it running ChatGPT-4o on the backend</div><br/></div></div></div></div><div id="41824727" class="c"><input type="checkbox" id="c-41824727" checked=""/><div class="controls bullet"><span class="by">pajeets</span><span>|</span><a href="#41825893">prev</a><span>|</span><a href="#41824666">next</a><span>|</span><label class="collapse" for="c-41824727">[-]</label><label class="expand" for="c-41824727">[5 more]</label></div><br/><div class="children"><div class="content">meh im not convinced that any sort of framework or side tool that works on top of large language models is the solution<p>we really need something intelligent (no, o1 doesn&#x27;t count) and its unclear what that will look like. Perhaps it will be some RNN with neurosymbolism</div><br/><div id="41825494" class="c"><input type="checkbox" id="c-41825494" checked=""/><div class="controls bullet"><span class="by">randomNumber7</span><span>|</span><a href="#41824727">parent</a><span>|</span><a href="#41825247">next</a><span>|</span><label class="collapse" for="c-41825494">[-]</label><label class="expand" for="c-41825494">[1 more]</label></div><br/><div class="children"><div class="content">I would say reinforcement learning needs to be part of the solution.<p>Don&#x27;t know how to prove it but I&#x27;m pretty sure you can&#x27;t reach agi only with (un-&#x2F;self-)supervised learning.</div><br/></div></div><div id="41825247" class="c"><input type="checkbox" id="c-41825247" checked=""/><div class="controls bullet"><span class="by">yathaid</span><span>|</span><a href="#41824727">parent</a><span>|</span><a href="#41825494">prev</a><span>|</span><a href="#41824666">next</a><span>|</span><label class="collapse" for="c-41825247">[-]</label><label class="expand" for="c-41825247">[3 more]</label></div><br/><div class="children"><div class="content">I am not sure it is useful to bring in something as nebulous as &quot;intelligence&quot; and hand wave everything else away, unless you are going to tightly define what intelligence means.<p>There are only two objective measurements needed:<p>-is it making progress towards its goal?<p>-is it able to acquire capabilities it didn&#x27;t have previously?<p>I am not sure if even the first one is objective enough.<p>Dismissing the argument without stating why you aren&#x27;t convinced just comes across as a form of AI ludditism.</div><br/><div id="41825546" class="c"><input type="checkbox" id="c-41825546" checked=""/><div class="controls bullet"><span class="by">randomNumber7</span><span>|</span><a href="#41824727">root</a><span>|</span><a href="#41825247">parent</a><span>|</span><a href="#41825500">next</a><span>|</span><label class="collapse" for="c-41825546">[-]</label><label class="expand" for="c-41825546">[1 more]</label></div><br/><div class="children"><div class="content">You don&#x27;t need these criteria when you can see in advance that something is impossible.<p>I think something that only learns to reproduce text, can not become an intelligent actor.<p>It&#x27;s necessary to act in an environment with Feedback.<p>And while it of course depends on the definition of intelligence, the article is about the Gödel machine, which is a fancy word for AGI</div><br/></div></div><div id="41825500" class="c"><input type="checkbox" id="c-41825500" checked=""/><div class="controls bullet"><span class="by">whatshisface</span><span>|</span><a href="#41824727">root</a><span>|</span><a href="#41825247">parent</a><span>|</span><a href="#41825546">prev</a><span>|</span><a href="#41824666">next</a><span>|</span><label class="collapse" for="c-41825500">[-]</label><label class="expand" for="c-41825500">[1 more]</label></div><br/><div class="children"><div class="content">The word capabilities is as hard to define as intelligence.</div><br/></div></div></div></div></div></div><div id="41824666" class="c"><input type="checkbox" id="c-41824666" checked=""/><div class="controls bullet"><span class="by">m3kw9</span><span>|</span><a href="#41824727">prev</a><span>|</span><label class="collapse" for="c-41824666">[-]</label><label class="expand" for="c-41824666">[1 more]</label></div><br/><div class="children"><div class="content">If their demo work, they must be close to AGI right?</div><br/></div></div></div></div></div></div></div></body></html>