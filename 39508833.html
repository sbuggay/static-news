<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1708938059326" as="style"/><link rel="stylesheet" href="styles.css?v=1708938059326"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://twitter.com/mjuric/status/1761981816125469064">Losing Trust in Google</a> <span class="domain">(<a href="https://twitter.com">twitter.com</a>)</span></div><div class="subtext"><span>cheviethai123</span> | <span>16 comments</span></div><br/><div><div id="39509039" class="c"><input type="checkbox" id="c-39509039" checked=""/><div class="controls bullet"><span class="by">bjord</span><span>|</span><a href="#39509027">next</a><span>|</span><label class="collapse" for="c-39509039">[-]</label><label class="expand" for="c-39509039">[1 more]</label></div><br/><div class="children"><div class="content">99% sure this is the &quot;google hates white people&quot; thing that a specific set of people have been absolutely losing their minds about<p>gemini produced images of non-white people in a lot of situations in which it shouldn&#x27;t have<p>I&#x27;ve read theorized(?) that, in order to counteract disproportionately large amounts of pictures of white people in training data, they basically added instructions after the fact in an effort to generate more non-white people, and totally over-corrected<p>feel free to correct me if I&#x27;m wrong, I haven&#x27;t paid super close attention</div><br/></div></div><div id="39509027" class="c"><input type="checkbox" id="c-39509027" checked=""/><div class="controls bullet"><span class="by">fshbbdssbbgdd</span><span>|</span><a href="#39509039">prev</a><span>|</span><a href="#39508957">next</a><span>|</span><label class="collapse" for="c-39509027">[-]</label><label class="expand" for="c-39509027">[1 more]</label></div><br/><div class="children"><div class="content">If you make a language model which just predicts the next word without trying to shape the output to be “good”, what you get is GPT instead of ChatGPT. You try to ask it a question and it will keep asking more questions (with a similar writing style). Or curse at you, or change the subject. RLHF (Reinforcement Learn with Human Feedback) was the breakthrough that fixed this.<p>Ok, so probably we agree that the product needs to try to be “good” and not just generate the most probable content. Cue a million opinions about what “good” is. Whatever comes out is the result of a value judgment, there is no going around it.</div><br/></div></div><div id="39508957" class="c"><input type="checkbox" id="c-39508957" checked=""/><div class="controls bullet"><span class="by">kybernetikos</span><span>|</span><a href="#39509027">prev</a><span>|</span><a href="#39509019">next</a><span>|</span><label class="collapse" for="c-39508957">[-]</label><label class="expand" for="c-39508957">[4 more]</label></div><br/><div class="children"><div class="content">Anyone mind summarizing this &#x2F; linking to a different source? For some reason that I don&#x27;t care to investigate too thoroughly, twitter links never seem to work for me.</div><br/><div id="39508991" class="c"><input type="checkbox" id="c-39508991" checked=""/><div class="controls bullet"><span class="by">bjord</span><span>|</span><a href="#39508957">parent</a><span>|</span><a href="#39509024">next</a><span>|</span><label class="collapse" for="c-39508991">[-]</label><label class="expand" for="c-39508991">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;archive.is&#x2F;ZXygP" rel="nofollow">https:&#x2F;&#x2F;archive.is&#x2F;ZXygP</a></div><br/></div></div><div id="39508969" class="c"><input type="checkbox" id="c-39508969" checked=""/><div class="controls bullet"><span class="by">Iulioh</span><span>|</span><a href="#39508957">parent</a><span>|</span><a href="#39509024">prev</a><span>|</span><a href="#39509019">next</a><span>|</span><label class="collapse" for="c-39508969">[-]</label><label class="expand" for="c-39508969">[1 more]</label></div><br/><div class="children"><div class="content">Tldr:<p>Gemini is prioritizing ideology over facts, profit over truth abd google is explicitly doing it. 
it is not incidental<p>But I don&#x27;t know exactly what OP is talking about</div><br/></div></div></div></div><div id="39509019" class="c"><input type="checkbox" id="c-39509019" checked=""/><div class="controls bullet"><span class="by">Zetobal</span><span>|</span><a href="#39508957">prev</a><span>|</span><a href="#39508988">next</a><span>|</span><label class="collapse" for="c-39509019">[-]</label><label class="expand" for="c-39509019">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not the model it&#x27;s the instruction set. Especially for image generation they just wrote a shitty prompt optimizer which is even more embarrassing.</div><br/></div></div><div id="39508988" class="c"><input type="checkbox" id="c-39508988" checked=""/><div class="controls bullet"><span class="by">verticalscaler</span><span>|</span><a href="#39509019">prev</a><span>|</span><a href="#39508963">next</a><span>|</span><label class="collapse" for="c-39508988">[-]</label><label class="expand" for="c-39508988">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m done with @Google. I know many good individuals working there, but as a company they&#x27;ve irrevocably lost my trust. I&#x27;m &quot;moving out&quot;. Here&#x27;s why:<p>I&#x27;ve been reading Google&#x27;s Gemini damage control posts. I think they&#x27;re simply not telling the truth. For one, their text-only product has the same (if not worse) issues. And second, if you know a bit about how these models are built, you know you don&#x27;t get these &quot;incorrect&quot; answers through one-off innocent mistakes. Gemini&#x27;s outputs reflect the many, many, FTE-years of labeling efforts, training, fine-tuning, prompt design, QA&#x2F;verification -- all iteratively guided by the team who built it. You can also be certain that before releasing it, many people have tried the product internally, that many demos were given to senior PMs and VPs, that they all thought it was fine, and that they all ultimately signed off on the release. With that prior, the balance of probabilities is strongly against the outputs being an innocent bug -- as @googlepubpolicy is now trying to spin it: Gemini is a product that functions exactly as designed, and an accurate reflection of the values people who built it.<p>Those values appear to include a desire to reshape the world in a specific way that is so strong that it allowed the people involved to rationalize to themselves that it&#x27;s not just acceptable but desirable to train their AI to prioritize ideology ahead of giving user the facts. To revise history, to obfuscate the present, and to outright hide information that doesn&#x27;t align with the company&#x27;s (staff&#x27;s) impression of what is &quot;good&quot;. I don&#x27;t care if some of that ideology may or may not align with your or my thinking about what would make the world a better place: for anyone with a shred of awareness of human history it should be clear how unbelievably irresponsible it is to build a system that aims to become an authoritative compendium of human knowledge (remember Google&#x27;s mission statement?), but which actually prioritizes ideology over facts. History is littered with many who have tried this sort of moral flexibility &quot;for the greater good&quot;; rather than helping, they typically resulted in decades of setbacks (and tens of millions of victims).<p>Setting social irresponsibility aside, in a purely business sense, it is beyond stupid to build a product which will explicitly put your company&#x27;s social agenda before the customer&#x27;s needs. Think about it: G&#x27;s Search -- for all its issues -- has been perceived as a good tool, because it focused on providing accurate and useful information. Its mission was aligned with the users&#x27; goals (&quot;get me to the correct answer for the stuff I need, and fast!&quot;). That&#x27;s why we all use(d) it. I always assumed Google&#x27;s AI efforts would follow the pattern, which would transfer over the user base &amp; lock in another 1-2 decade of dominance.<p>But they&#x27;ve done the opposite. After Gemini, rather than as a user-centric company, Google will be perceived as an activist organization first -- ready to lie to the user to advance their (staff&#x27;s) social agenda. That&#x27;s huge. Would you hire a personal assistant who openly has an unaligned (and secret -- they hide the system prompts) agenda, who you fundamentally can&#x27;t trust? Who strongly believes they know better than you? Who you suspect will covertly lie to you (directly or through omission) when your interests diverge? Forget the cookies, ads, privacy issues, or YouTube content moderation; Google just made 50%+ of the population run through this scenario and question the trustworthiness of the core business and the people running it. And not at the typical financial (&quot;they&#x27;re fleecing me!&quot;) level, but ideological level (&quot;they hate people like me!&quot;). That&#x27;ll be hard to reset, IMHO.<p>What about the future? Take a look at Google&#x27;s AI Responsibility Principles (ai.google&#x2F;responsibility…) and ask yourself what would Search look like if the staff who brought you Gemini was tasked to interpret them &amp; rebuild it accordingly? Would you trust that product? Would you use it? Well, with Google&#x27;s promise to include Gemini everywhere, that&#x27;s what we&#x27;ll be getting (technologyreview.com&#x2F;2024&#x2F;02&#x2F;08&#x2F;108…). In this brave new world, every time you run a search you&#x27;ll be asking yourself &quot;did it tell me the truth, or did it lie, or hide something?&quot;. That&#x27;s lethal for a company built around organizing information.<p>And that&#x27;s why, as of this weekend, I&#x27;ve started divorcing my personal life and taking my information out of the Google ecosystem. It will probably take a ~year (having invested in nearly everything, from Search to Pixel to Assistant to more obscure things like Voice), but has to be done. Still, really, really sad...</div><br/></div></div><div id="39508963" class="c"><input type="checkbox" id="c-39508963" checked=""/><div class="controls bullet"><span class="by">Iulioh</span><span>|</span><a href="#39508988">prev</a><span>|</span><a href="#39508970">next</a><span>|</span><label class="collapse" for="c-39508963">[-]</label><label class="expand" for="c-39508963">[4 more]</label></div><br/><div class="children"><div class="content">I&#x27;m out of the loop, what are the examples of this bias?</div><br/><div id="39509000" class="c"><input type="checkbox" id="c-39509000" checked=""/><div class="controls bullet"><span class="by">fsh</span><span>|</span><a href="#39508963">parent</a><span>|</span><a href="#39508999">next</a><span>|</span><label class="collapse" for="c-39509000">[-]</label><label class="expand" for="c-39509000">[2 more]</label></div><br/><div class="children"><div class="content">Gemini tends to generate images of non-white people which made some white people very mad.</div><br/><div id="39509025" class="c"><input type="checkbox" id="c-39509025" checked=""/><div class="controls bullet"><span class="by">dns_snek</span><span>|</span><a href="#39508963">root</a><span>|</span><a href="#39509000">parent</a><span>|</span><a href="#39508999">next</a><span>|</span><label class="collapse" for="c-39509025">[-]</label><label class="expand" for="c-39509025">[1 more]</label></div><br/><div class="children"><div class="content">Take off the spin. When asked to generate nazi soldiers, it generated black, asian, and native american people wearing nazi uniforms.<p>When asked to generate white people, it said it&#x27;s not allowed to.</div><br/></div></div></div></div><div id="39508999" class="c"><input type="checkbox" id="c-39508999" checked=""/><div class="controls bullet"><span class="by">gigatexal</span><span>|</span><a href="#39508963">parent</a><span>|</span><a href="#39509000">prev</a><span>|</span><a href="#39508970">next</a><span>|</span><label class="collapse" for="c-39508999">[-]</label><label class="expand" for="c-39508999">[1 more]</label></div><br/><div class="children"><div class="content">Apparently the new model when asked for historical figures that were historically white would &quot;hallucinate&quot; more diverse persons. And the article&#x27;s author is claiming that the training had these biases from the jump.<p>Re: the Twitter post it reads like a &quot;I&#x27;m leaving social media&#x27; post and then the author waits to see all the engagement -- all the &quot;no don&#x27;t leave, we love you!&quot; nonesense. Or maybe it&#x27;s the radicalization origin of a tech person: oh they trained the data to be woke from the beginning, rawr I&#x27;m gonna crusade against this! sort of thinking.<p>It&#x27;s an AI model who cares? It&#x27;s not like anyone is getting their facts from it and if they are they need to be shown the folly of that. They&#x27;re tools. I find them best at reasoning somewhat well about code and that&#x27;s about it.</div><br/></div></div></div></div><div id="39508970" class="c"><input type="checkbox" id="c-39508970" checked=""/><div class="controls bullet"><span class="by">knowriju</span><span>|</span><a href="#39508963">prev</a><span>|</span><label class="collapse" for="c-39508970">[-]</label><label class="expand" for="c-39508970">[3 more]</label></div><br/><div class="children"><div class="content">I wonder what the folks in Cupertino are thinking when they look at this brouhaha over Google being supremely risk averse and receiving such blacklash. 
How will Siri answer if you ask &quot;Is Elon Musk just a meme lord or Tech Bro&#x27;s cultural savior&quot;.<p>Side Note: As a person living outside US, I find US focused discorse&#x27;s obsession with race and skin color such fascinating. It is almost similar to people obsessing over the color of a button on the home page when the page itself takes 1 minute to load.</div><br/><div id="39509028" class="c"><input type="checkbox" id="c-39509028" checked=""/><div class="controls bullet"><span class="by">gigatexal</span><span>|</span><a href="#39508970">parent</a><span>|</span><label class="collapse" for="c-39509028">[-]</label><label class="expand" for="c-39509028">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;ll buy 5 more iphones and put them in a drawer if Siri responded with something like this: &quot;Elon, the son of a diamond miner from South Africa, while an accomplished businessman is just that. His wealth came from the work of others and timing. And now he&#x27;s so red-pilled that this AI assistant questions his sanity and stability. Having threatened his business relations by smoking pot on a podcast he now shills alt-right theories on the social media site he bought for a meme price. So to answer your prompt: meme lord.&quot;</div><br/><div id="39509041" class="c"><input type="checkbox" id="c-39509041" checked=""/><div class="controls bullet"><span class="by">gigatexal</span><span>|</span><a href="#39508970">root</a><span>|</span><a href="#39509028">parent</a><span>|</span><label class="collapse" for="c-39509041">[-]</label><label class="expand" for="c-39509041">[1 more]</label></div><br/><div class="children"><div class="content">Imagine you could get a Siri with the attitude of the Carrot weather bot... oh man one can dream.</div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>