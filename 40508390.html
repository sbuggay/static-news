<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1716973278411" as="style"/><link rel="stylesheet" href="styles.css?v=1716973278411"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.oreilly.com/radar/what-we-learned-from-a-year-of-building-with-llms-part-i/">What We Learned from a Year of Building with LLMs</a> <span class="domain">(<a href="https://www.oreilly.com">www.oreilly.com</a>)</span></div><div class="subtext"><span>7d7n</span> | <span>44 comments</span></div><br/><div><div id="40509763" class="c"><input type="checkbox" id="c-40509763" checked=""/><div class="controls bullet"><span class="by">wokwokwok</span><span>|</span><a href="#40509582">next</a><span>|</span><label class="collapse" for="c-40509763">[-]</label><label class="expand" for="c-40509763">[1 more]</label></div><br/><div class="children"><div class="content">Mildly surprised to see no mention of my top 2 LLM fails:<p>1) you’re sampling a distribution; if you only sample once, your sample is not representative of the distribution.<p>For evaluating prompts and running in production; your hallucination rate is inversely proportional to the number of times you sample.<p>Sample many times and vote is a highly effective (but slow) strategy.<p>There is almost zero value in evaluating a prompt by only running it once.<p>2) Sequences are generated in order.<p>Asking an LLM to make a decision and justify its decision in that order is literally meaningless.<p>Once the “decision” tokens are  generated; the justification does not influence them. It’s not like they happen “all at once” there is a specific sequence to generating output where the later output <i>cannot magically</i> influence the output which has already been generated.<p>This is true for sequential outputs from an LLM (obviously), but it is also true <i>inside single outputs</i>. The sequence of tokens in the output is a <i>sequence</i>.<p>If you’re generating structured output (eg json, xml) which is not sequenced, and your output is something like {decision: …, reason:…} it literally does nothing.<p>…but, it <i>is</i> valuable to “show the working out” when, as above, you then evaluate multiple solutions to a single request and pick the best one(s).</div><br/></div></div><div id="40509582" class="c"><input type="checkbox" id="c-40509582" checked=""/><div class="controls bullet"><span class="by">Havoc</span><span>|</span><a href="#40509763">prev</a><span>|</span><a href="#40508965">next</a><span>|</span><label class="collapse" for="c-40509582">[-]</label><label class="expand" for="c-40509582">[3 more]</label></div><br/><div class="children"><div class="content">Surely step one is carefully consider whether LLMs are the solution to you problem? That to me is the part where this is likely to go wrong for most people</div><br/><div id="40509636" class="c"><input type="checkbox" id="c-40509636" checked=""/><div class="controls bullet"><span class="by">bootsmann</span><span>|</span><a href="#40509582">parent</a><span>|</span><a href="#40508965">next</a><span>|</span><label class="collapse" for="c-40509636">[-]</label><label class="expand" for="c-40509636">[2 more]</label></div><br/><div class="children"><div class="content">Enforcing a BM25 baseline for every RAG project will keep so many &quot;talk to your pdf&quot; projects off your plate.</div><br/><div id="40509883" class="c"><input type="checkbox" id="c-40509883" checked=""/><div class="controls bullet"><span class="by">Havoc</span><span>|</span><a href="#40509582">root</a><span>|</span><a href="#40509636">parent</a><span>|</span><a href="#40508965">next</a><span>|</span><label class="collapse" for="c-40509883">[-]</label><label class="expand" for="c-40509883">[1 more]</label></div><br/><div class="children"><div class="content">Do you mean as an additional step to determine whether the content the rag wants to pull is actually relevant? Or as a filter of sorts as to hat projects to work on?</div><br/></div></div></div></div></div></div><div id="40508965" class="c"><input type="checkbox" id="c-40508965" checked=""/><div class="controls bullet"><span class="by">l5870uoo9y</span><span>|</span><a href="#40509582">prev</a><span>|</span><a href="#40508679">next</a><span>|</span><label class="collapse" for="c-40508965">[-]</label><label class="expand" for="c-40508965">[3 more]</label></div><br/><div class="children"><div class="content">&gt; Thus, you may expect that effective prompting for Text-to-SQL should include structured schema definitions; indeed.<p>I found that the simpler the better, when testing lots of different SQL schema formats on <a href="https:&#x2F;&#x2F;www.sqlai.ai&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.sqlai.ai&#x2F;</a>. CSV (table name, table column, data type) outperformed both a JSON formatted and SQL schema dump. And not to mention consumed fewer tokens.<p>If you need the database schema in a consistent format (e.g. CSV) just have LLM extract data and convert whatever the user provides into CSV. It shines at this.</div><br/><div id="40509292" class="c"><input type="checkbox" id="c-40509292" checked=""/><div class="controls bullet"><span class="by">FrostKiwi</span><span>|</span><a href="#40508965">parent</a><span>|</span><a href="#40508679">next</a><span>|</span><label class="collapse" for="c-40509292">[-]</label><label class="expand" for="c-40509292">[2 more]</label></div><br/><div class="children"><div class="content">Interesting, thanks for sharing! I was wondering about this. When starting out with feeding Tabular data, I instinctively went with CSV, but always worried: What if there is a better choice? What if longer tables, the LLMs forgets the column order?</div><br/><div id="40509567" class="c"><input type="checkbox" id="c-40509567" checked=""/><div class="controls bullet"><span class="by">firejake308</span><span>|</span><a href="#40508965">root</a><span>|</span><a href="#40509292">parent</a><span>|</span><a href="#40508679">next</a><span>|</span><label class="collapse" for="c-40509567">[-]</label><label class="expand" for="c-40509567">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s exactly what happened to me when I tried to get the open-source models to extract a CSV from textual data with a lot of yes&#x2F;no fields; i.e., the model forgot the column order and started confusing the cell values. I found I had to use more powerful models like Mistral Large or ChatGPT. So I think that is a valid thing to worry about with smaller models, but maybe less of a concern with larger ones.</div><br/></div></div></div></div></div></div><div id="40508679" class="c"><input type="checkbox" id="c-40508679" checked=""/><div class="controls bullet"><span class="by">mloncode</span><span>|</span><a href="#40508965">prev</a><span>|</span><a href="#40509835">next</a><span>|</span><label class="collapse" for="c-40508679">[-]</label><label class="expand" for="c-40508679">[5 more]</label></div><br/><div class="children"><div class="content">Hello this is Hamel, one of the authors (among the list of other amazing authors). Happy to answer any questions as well as tag any of my colleagues to answer any questions!<p>(Note: this is only Part 1 of 3 of a series that has already been written and the other 2 parts will be released shortly)</div><br/><div id="40508971" class="c"><input type="checkbox" id="c-40508971" checked=""/><div class="controls bullet"><span class="by">sieszpak</span><span>|</span><a href="#40508679">parent</a><span>|</span><a href="#40508950">next</a><span>|</span><label class="collapse" for="c-40508971">[-]</label><label class="expand" for="c-40508971">[2 more]</label></div><br/><div class="children"><div class="content">I would like to know your opinion about grafRAG and the ontology. Knowledge Graphs (KG) are a game changer for companies with a lot of unstructured data in the context of applying them with LLM</div><br/><div id="40509108" class="c"><input type="checkbox" id="c-40509108" checked=""/><div class="controls bullet"><span class="by">bbischof</span><span>|</span><a href="#40508679">root</a><span>|</span><a href="#40508971">parent</a><span>|</span><a href="#40508950">next</a><span>|</span><label class="collapse" for="c-40509108">[-]</label><label class="expand" for="c-40509108">[1 more]</label></div><br/><div class="children"><div class="content">Bryan here, one of the authors.<p>Sure. Ultimately, you want to use KG to increase your ability to do great retrieval.<p>Why do graphs help with retrieval? Well, don’t overlook the classic pageant example: graphs provide signal about the interconnectivity of the docs.<p>Also, sometimes the graph itself are a kind of object you want to retrieve over.</div><br/></div></div></div></div><div id="40508950" class="c"><input type="checkbox" id="c-40508950" checked=""/><div class="controls bullet"><span class="by">umangrathi</span><span>|</span><a href="#40508679">parent</a><span>|</span><a href="#40508971">prev</a><span>|</span><a href="#40509267">next</a><span>|</span><label class="collapse" for="c-40508950">[-]</label><label class="expand" for="c-40508950">[1 more]</label></div><br/><div class="children"><div class="content">It was a great read, aligned on many thought processes from our own tinkering in breaking down tasks for LLM. Eagerly look forward to the next 2 parts, this one has been educational.</div><br/></div></div><div id="40509267" class="c"><input type="checkbox" id="c-40509267" checked=""/><div class="controls bullet"><span class="by">rasmus1610</span><span>|</span><a href="#40508679">parent</a><span>|</span><a href="#40508950">prev</a><span>|</span><a href="#40509835">next</a><span>|</span><label class="collapse" for="c-40509267">[-]</label><label class="expand" for="c-40509267">[1 more]</label></div><br/><div class="children"><div class="content">Just wanted to say Thank you for publishing something so valuable. So many great tips in there!</div><br/></div></div></div></div><div id="40509835" class="c"><input type="checkbox" id="c-40509835" checked=""/><div class="controls bullet"><span class="by">anon373839</span><span>|</span><a href="#40508679">prev</a><span>|</span><a href="#40508796">next</a><span>|</span><label class="collapse" for="c-40509835">[-]</label><label class="expand" for="c-40509835">[1 more]</label></div><br/><div class="children"><div class="content">Is anyone using DSPy? It seems like a really interesting project, but I haven’t heard much from people building with it.</div><br/></div></div><div id="40508796" class="c"><input type="checkbox" id="c-40508796" checked=""/><div class="controls bullet"><span class="by">hubraumhugo</span><span>|</span><a href="#40509835">prev</a><span>|</span><a href="#40508704">next</a><span>|</span><label class="collapse" for="c-40508796">[-]</label><label class="expand" for="c-40508796">[6 more]</label></div><br/><div class="children"><div class="content">Comprehensive and practical write-up that aligns with most of my experiences.<p>One controversial point that has led to discussions in my team is this:<p>&gt; A common anti-pattern&#x2F;code smell in software is the “God Object,” where we have a single class or function that does everything. The same applies to prompts too.<p>In theory, a monolithic agent&#x2F;prompt with infinite context size, a large toolset, and perfect attention would be ideal.<p>Multi-agent systems will always be less effective and more error-prone than monolithic systems on a given problem because of less context of the overall problem. Individual agents work best when they have entirely different functionalities.<p>I wrote down my thoughts about agent architectures here: <a href="https:&#x2F;&#x2F;www.kadoa.com&#x2F;blog&#x2F;ai-agents-hype-vs-reality" rel="nofollow">https:&#x2F;&#x2F;www.kadoa.com&#x2F;blog&#x2F;ai-agents-hype-vs-reality</a></div><br/><div id="40508953" class="c"><input type="checkbox" id="c-40508953" checked=""/><div class="controls bullet"><span class="by">tedsanders</span><span>|</span><a href="#40508796">parent</a><span>|</span><a href="#40509586">next</a><span>|</span><label class="collapse" for="c-40508953">[-]</label><label class="expand" for="c-40508953">[4 more]</label></div><br/><div class="children"><div class="content">As an OpenAI employee who has worked with dozens of API customers, I mostly agree with the article&#x27;s tip to break up tasks into smaller, more reliable subtasks.<p>If each step of your task requires knowledge of the big picture, then yeah it ought to help to put all your context into a single API call.<p>But if you can decompose your task into relatively independent subtasks, then it helps to use a custom prompt&#x2F;custom model for each of those steps. Extraneous context and complexity are just opportunities for the model to make mistakes, and the more you can strip those out, the better. 3 steps with 99% reliability are better than 1 step with 90% reliability.<p>Of course, it all depends on what you&#x27;re trying to do.<p>I&#x27;d say single, big API calls are better when:<p>- Much of the information&#x2F;substeps are interrelated<p>- You want immediate output for a user-facing app, without having to wait for intermediate steps<p>Multiple, sequenced API calls are better when:<p>- You can decompose the task into smaller steps, each of which do not require full context<p>- There&#x27;s a tree or graph of steps, and you want to prune irrelevant branches as you proceed from the root<p>- You want to have some 100% reliabile logic live outside of the LLM in parsing&#x2F;routing code<p>- You want to customize the prompts based on results from previous steps</div><br/><div id="40509067" class="c"><input type="checkbox" id="c-40509067" checked=""/><div class="controls bullet"><span class="by">7d7n</span><span>|</span><a href="#40508796">root</a><span>|</span><a href="#40508953">parent</a><span>|</span><a href="#40509006">next</a><span>|</span><label class="collapse" for="c-40509067">[-]</label><label class="expand" for="c-40509067">[1 more]</label></div><br/><div class="children"><div class="content">100% agree with Ted&#x27;s take. One of the authors wrote about splitting up prompts here too: <a href="https:&#x2F;&#x2F;eugeneyan.com&#x2F;writing&#x2F;prompting&#x2F;#split-catch-all-prompts-into-multiple-smaller-ones" rel="nofollow">https:&#x2F;&#x2F;eugeneyan.com&#x2F;writing&#x2F;prompting&#x2F;#split-catch-all-pro...</a></div><br/></div></div><div id="40509006" class="c"><input type="checkbox" id="c-40509006" checked=""/><div class="controls bullet"><span class="by">hubraumhugo</span><span>|</span><a href="#40508796">root</a><span>|</span><a href="#40508953">parent</a><span>|</span><a href="#40509067">prev</a><span>|</span><a href="#40508969">next</a><span>|</span><label class="collapse" for="c-40509006">[-]</label><label class="expand" for="c-40509006">[1 more]</label></div><br/><div class="children"><div class="content">Agree, that&#x27;s a very good summary. Would love to see some benchmarks for the two approaches.</div><br/></div></div><div id="40508969" class="c"><input type="checkbox" id="c-40508969" checked=""/><div class="controls bullet"><span class="by">umangrathi</span><span>|</span><a href="#40508796">root</a><span>|</span><a href="#40508953">parent</a><span>|</span><a href="#40509006">prev</a><span>|</span><a href="#40509586">next</a><span>|</span><label class="collapse" for="c-40508969">[-]</label><label class="expand" for="c-40508969">[1 more]</label></div><br/><div class="children"><div class="content">smaller tasks also helps in choosing smaller models to work with, instead of waiting for a large model to respond (really not usable when doing customer facing work)</div><br/></div></div></div></div><div id="40509586" class="c"><input type="checkbox" id="c-40509586" checked=""/><div class="controls bullet"><span class="by">sjducb</span><span>|</span><a href="#40508796">parent</a><span>|</span><a href="#40508953">prev</a><span>|</span><a href="#40508704">next</a><span>|</span><label class="collapse" for="c-40509586">[-]</label><label class="expand" for="c-40509586">[1 more]</label></div><br/><div class="children"><div class="content">I wonder how helpful “prompt unit tests” would be here?<p>Write the initial prompt, and write some tests to validate the output of the prompt. Then  as the prompt grows you can observe the decline in performance at the initial task. Then you can decide if the new larger prompt is worth the decline in performance at it’s initial task.<p>It might not work for all tasks, but a good candidate would be - write SQL queries from natural language.</div><br/></div></div></div></div><div id="40508704" class="c"><input type="checkbox" id="c-40508704" checked=""/><div class="controls bullet"><span class="by">hugobowne</span><span>|</span><a href="#40508796">prev</a><span>|</span><a href="#40508882">next</a><span>|</span><label class="collapse" for="c-40508704">[-]</label><label class="expand" for="c-40508704">[1 more]</label></div><br/><div class="children"><div class="content">hey there, Hugo here and big fan of this work. Such a fan I&#x27;m actually doing a livestream podcast recording with all the authors here, if you&#x27;re interested in hearing more from them: <a href="https:&#x2F;&#x2F;lu.ma&#x2F;e8huz3s6?utm_source=hn" rel="nofollow">https:&#x2F;&#x2F;lu.ma&#x2F;e8huz3s6?utm_source=hn</a><p>should be fun!</div><br/></div></div><div id="40508882" class="c"><input type="checkbox" id="c-40508882" checked=""/><div class="controls bullet"><span class="by">surfingdino</span><span>|</span><a href="#40508704">prev</a><span>|</span><a href="#40508856">next</a><span>|</span><label class="collapse" for="c-40508882">[-]</label><label class="expand" for="c-40508882">[4 more]</label></div><br/><div class="children"><div class="content">One thing I am getting from this is that you need to be able to write prompts using well-structured English. That may be a challenge to a significant percentage of the population.<p>I am curious to know if the authors tried to build LLMs in languages other than English and what did they learn while doing so?<p>An excellent post reminding me of the best O&#x27;Reilly articles from the past. Looking forward to parts 2 and 3.</div><br/><div id="40508970" class="c"><input type="checkbox" id="c-40508970" checked=""/><div class="controls bullet"><span class="by">azinman2</span><span>|</span><a href="#40508882">parent</a><span>|</span><a href="#40508968">next</a><span>|</span><label class="collapse" for="c-40508970">[-]</label><label class="expand" for="c-40508970">[2 more]</label></div><br/><div class="children"><div class="content">&gt; that you need to be able to write prompts using well-structured English. That may be a challenge to a significant percentage of the population.<p>I didn’t realize at first you meant to highlight a language barrier — being well structured is a challenge for most in their native tongue!</div><br/><div id="40509074" class="c"><input type="checkbox" id="c-40509074" checked=""/><div class="controls bullet"><span class="by">surfingdino</span><span>|</span><a href="#40508882">root</a><span>|</span><a href="#40508970">parent</a><span>|</span><a href="#40508968">next</a><span>|</span><label class="collapse" for="c-40509074">[-]</label><label class="expand" for="c-40509074">[1 more]</label></div><br/><div class="children"><div class="content">Well, it&#x27;s early in the morning and I have not had my coffee, yet. English being my second language doesn&#x27;t help either :-) Probably best for me to wait until I wake up before writing a prompt.</div><br/></div></div></div></div><div id="40508968" class="c"><input type="checkbox" id="c-40508968" checked=""/><div class="controls bullet"><span class="by">empiko</span><span>|</span><a href="#40508882">parent</a><span>|</span><a href="#40508970">prev</a><span>|</span><a href="#40508856">next</a><span>|</span><label class="collapse" for="c-40508968">[-]</label><label class="expand" for="c-40508968">[1 more]</label></div><br/><div class="children"><div class="content">&quot;fix the English in the following prompt: {prompt}&quot;</div><br/></div></div></div></div><div id="40508856" class="c"><input type="checkbox" id="c-40508856" checked=""/><div class="controls bullet"><span class="by">goldemerald</span><span>|</span><a href="#40508882">prev</a><span>|</span><a href="#40508798">next</a><span>|</span><label class="collapse" for="c-40508856">[-]</label><label class="expand" for="c-40508856">[4 more]</label></div><br/><div class="children"><div class="content">&quot;Ready to -dive- delve in?&quot; is an amazingly hilarious reference. For those who don&#x27;t know, LLMs (especially ChatGPT) use the word delve significantly more often than human created content. It&#x27;s a primary tell-tale sign that someone used an LLM to write the text. Keep an eye out for delving, and you&#x27;ll see it everywhere.</div><br/><div id="40509081" class="c"><input type="checkbox" id="c-40509081" checked=""/><div class="controls bullet"><span class="by">threeseed</span><span>|</span><a href="#40508856">parent</a><span>|</span><a href="#40509103">next</a><span>|</span><label class="collapse" for="c-40509081">[-]</label><label class="expand" for="c-40509081">[1 more]</label></div><br/><div class="children"><div class="content">I believe this was debunked as just a US-centric view.<p>In places that grew up learning UK English we use delve not that dissimilar to ChatGPT.</div><br/></div></div><div id="40509103" class="c"><input type="checkbox" id="c-40509103" checked=""/><div class="controls bullet"><span class="by">7d7n</span><span>|</span><a href="#40508856">parent</a><span>|</span><a href="#40509081">prev</a><span>|</span><a href="#40509095">next</a><span>|</span><label class="collapse" for="c-40509103">[-]</label><label class="expand" for="c-40509103">[1 more]</label></div><br/><div class="children"><div class="content">haha I&#x27;m glad you noticed!<p>it&#x27;s originally &quot;Ready to ~~delve~~ dive in?&quot; but something got lost in translation</div><br/></div></div></div></div><div id="40508798" class="c"><input type="checkbox" id="c-40508798" checked=""/><div class="controls bullet"><span class="by">DubiousPusher</span><span>|</span><a href="#40508856">prev</a><span>|</span><a href="#40509197">next</a><span>|</span><label class="collapse" for="c-40508798">[-]</label><label class="expand" for="c-40508798">[4 more]</label></div><br/><div class="children"><div class="content">Pretty good. Despite my high scepticism of the technology I have spent the last year working with LLMs myself. I would add a few things.<p>The LLM is like another user. And it can surprise you just like a user can. All the things you&#x27;ve done over the years to sanitize user input apply to LLM responses.<p>There is power beyond the conversational aspects of LLMs. Always ask, do you need to pass the actual text back to your user or can you leverage the LLM and constrain what you return?<p>LLMs are the best tool we&#x27;ve ever had for understanding user intent. They obsolete the hierarchies of decision trees and spaghetti logic we&#x27;ve written for years to classify user input into discrete tasks (realizing this and throwing away so much code has been the joy of the last year of my work).<p>Being concise is key and these things suck at it.<p>If you leave a user alone with the LLM, some users will break it. No matter what you do.</div><br/><div id="40509806" class="c"><input type="checkbox" id="c-40509806" checked=""/><div class="controls bullet"><span class="by">Terr_</span><span>|</span><a href="#40508798">parent</a><span>|</span><a href="#40508944">next</a><span>|</span><label class="collapse" for="c-40509806">[-]</label><label class="expand" for="c-40509806">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The LLM is like another user.<p>I like to think of LLMs as client-side code, at least in terms of their risk-profile.<p>No data you put into them (whether training or prompt) is reliably hidden from a persistent user, and they can also force it to output what they want.</div><br/></div></div><div id="40508944" class="c"><input type="checkbox" id="c-40508944" checked=""/><div class="controls bullet"><span class="by">umangrathi</span><span>|</span><a href="#40508798">parent</a><span>|</span><a href="#40509806">prev</a><span>|</span><a href="#40509197">next</a><span>|</span><label class="collapse" for="c-40508944">[-]</label><label class="expand" for="c-40508944">[2 more]</label></div><br/><div class="children"><div class="content">This has been really interesting read. Aligned that if you leave a user along with LLM, some one will break. Hence we choose to use large number of templates wherever suitable as compared to a free reign for LLM to respond with.</div><br/><div id="40509364" class="c"><input type="checkbox" id="c-40509364" checked=""/><div class="controls bullet"><span class="by">distalx</span><span>|</span><a href="#40508798">root</a><span>|</span><a href="#40508944">parent</a><span>|</span><a href="#40509197">next</a><span>|</span><label class="collapse" for="c-40509364">[-]</label><label class="expand" for="c-40509364">[1 more]</label></div><br/><div class="children"><div class="content">In my opinion, using templates can help keep responses reliable. But it can also make interactions feel robotic, diminishing the &quot;wow&quot; factor of LLMs. There might be better options out there that we haven&#x27;t found yet.</div><br/></div></div></div></div></div></div><div id="40509197" class="c"><input type="checkbox" id="c-40509197" checked=""/><div class="controls bullet"><span class="by">__loam</span><span>|</span><a href="#40508798">prev</a><span>|</span><a href="#40508561">next</a><span>|</span><label class="collapse" for="c-40509197">[-]</label><label class="expand" for="c-40509197">[10 more]</label></div><br/><div class="children"><div class="content">I feel like an insane person everytime I look at the LLM development space and see what the state of the art is.<p>If I&#x27;m understanding this correctly, the standard way to get structured output seems to be to retry the query until the stochastic language model produces expected output. RAG also seems like a hilariously thin wrapper over traditional search systems, and it still might hallucinate in that tiny distance between the search result and the user. Like we&#x27;re talking about writing sentences and coaching what amounts to an auto complete system to magically give us something we want. How is this industry getting hundreds of billions of dollars in investment?<p>Also the error rate is about 5-10% according to this article. That&#x27;s pretty bad!</div><br/><div id="40509395" class="c"><input type="checkbox" id="c-40509395" checked=""/><div class="controls bullet"><span class="by">yaantc</span><span>|</span><a href="#40509197">parent</a><span>|</span><a href="#40509358">next</a><span>|</span><label class="collapse" for="c-40509395">[-]</label><label class="expand" for="c-40509395">[2 more]</label></div><br/><div class="children"><div class="content">&gt; [...] the standard way to get structured output seems to be to retry the query until the stochastic language model produces expected output.<p>No, that would be very inefficient. At each token generation step, the LLM provides a likelihood for all the defined token based on the past context. The structured output is defined by a grammar, which defines the legal tokens for the next step. You can then take the intersection of both (ignore any token not allowed by the grammar), and then select among the authorized token based on the LLM likelihood for them in the usual way. So it&#x27;s a direct constraint, and it&#x27;s efficient.</div><br/><div id="40509472" class="c"><input type="checkbox" id="c-40509472" checked=""/><div class="controls bullet"><span class="by">__loam</span><span>|</span><a href="#40509197">root</a><span>|</span><a href="#40509395">parent</a><span>|</span><a href="#40509358">next</a><span>|</span><label class="collapse" for="c-40509472">[-]</label><label class="expand" for="c-40509472">[1 more]</label></div><br/><div class="children"><div class="content">Yeah that sounds way better. I saw one of the python libraries they recommended mention retries and I thought, this can&#x27;t be that awful can it?</div><br/></div></div></div></div><div id="40509358" class="c"><input type="checkbox" id="c-40509358" checked=""/><div class="controls bullet"><span class="by">Kiro</span><span>|</span><a href="#40509197">parent</a><span>|</span><a href="#40509395">prev</a><span>|</span><a href="#40509237">next</a><span>|</span><label class="collapse" for="c-40509358">[-]</label><label class="expand" for="c-40509358">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Also the error rate is about 5-10% according to this article. That&#x27;s pretty bad!<p>Having 90-95% success rate on something that was previously impossible is acceptable. Without LLMs the success rate would be 0% for the things I&#x27;m doing.</div><br/></div></div><div id="40509237" class="c"><input type="checkbox" id="c-40509237" checked=""/><div class="controls bullet"><span class="by">palata</span><span>|</span><a href="#40509197">parent</a><span>|</span><a href="#40509358">prev</a><span>|</span><a href="#40509366">next</a><span>|</span><label class="collapse" for="c-40509237">[-]</label><label class="expand" for="c-40509237">[3 more]</label></div><br/><div class="children"><div class="content">&gt; How is this industry getting hundreds of billions of dollars in investment?<p>FOMO? To me it&#x27;s the Gold Rush, except that it&#x27;s not clear if anyone wants that kind of gold at the end :-).</div><br/><div id="40509310" class="c"><input type="checkbox" id="c-40509310" checked=""/><div class="controls bullet"><span class="by">__loam</span><span>|</span><a href="#40509197">root</a><span>|</span><a href="#40509237">parent</a><span>|</span><a href="#40509366">next</a><span>|</span><label class="collapse" for="c-40509310">[-]</label><label class="expand" for="c-40509310">[2 more]</label></div><br/><div class="children"><div class="content">Google is so terrified that someone is threatening their market position, the one in which they have over $100b in cash and get something like $20b in profit quarterly, that they&#x27;re willing to shove this technology into some of the most important infrastructure on the internet so they can get fucksmith to tell everyone to put glue in their pizza sauce. I&#x27;ll never understand how a company in maybe one of the most secure financial situations in all of human history has leadership that is this afraid.</div><br/><div id="40509587" class="c"><input type="checkbox" id="c-40509587" checked=""/><div class="controls bullet"><span class="by">oispakaljaa</span><span>|</span><a href="#40509197">root</a><span>|</span><a href="#40509310">parent</a><span>|</span><a href="#40509366">next</a><span>|</span><label class="collapse" for="c-40509587">[-]</label><label class="expand" for="c-40509587">[1 more]</label></div><br/><div class="children"><div class="content">Line must go up.</div><br/></div></div></div></div></div></div><div id="40509366" class="c"><input type="checkbox" id="c-40509366" checked=""/><div class="controls bullet"><span class="by">rcarmo</span><span>|</span><a href="#40509197">parent</a><span>|</span><a href="#40509237">prev</a><span>|</span><a href="#40509361">next</a><span>|</span><label class="collapse" for="c-40509366">[-]</label><label class="expand" for="c-40509366">[2 more]</label></div><br/><div class="children"><div class="content">Via APIs, yes. But if you have direct access to the model you can use libraries like <a href="https:&#x2F;&#x2F;github.com&#x2F;guidance-ai&#x2F;guidance">https:&#x2F;&#x2F;github.com&#x2F;guidance-ai&#x2F;guidance</a> to manipulate the output structure directly.</div><br/><div id="40509520" class="c"><input type="checkbox" id="c-40509520" checked=""/><div class="controls bullet"><span class="by">__loam</span><span>|</span><a href="#40509197">root</a><span>|</span><a href="#40509366">parent</a><span>|</span><a href="#40509361">next</a><span>|</span><label class="collapse" for="c-40509520">[-]</label><label class="expand" for="c-40509520">[1 more]</label></div><br/><div class="children"><div class="content">This seems like it could do some cool code completion stuff with local models.</div><br/></div></div></div></div><div id="40509361" class="c"><input type="checkbox" id="c-40509361" checked=""/><div class="controls bullet"><span class="by">freddref</span><span>|</span><a href="#40509197">parent</a><span>|</span><a href="#40509366">prev</a><span>|</span><a href="#40508561">next</a><span>|</span><label class="collapse" for="c-40509361">[-]</label><label class="expand" for="c-40509361">[1 more]</label></div><br/><div class="children"><div class="content">Humans probably have about the same error rate. It&#x27;s easy to miss a comma or quote.<p>These systems compete with humans, not with formatters.</div><br/></div></div></div></div></div></div></div></div></div></body></html>