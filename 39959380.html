<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1712566861305" as="style"/><link rel="stylesheet" href="styles.css?v=1712566861305"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://sourcegraph.com/blog/the-lifecycle-of-a-code-ai-completion">The lifecycle of a code AI completion</a> <span class="domain">(<a href="https://sourcegraph.com">sourcegraph.com</a>)</span></div><div class="subtext"><span>tosh</span> | <span>72 comments</span></div><br/><div><div id="39965529" class="c"><input type="checkbox" id="c-39965529" checked=""/><div class="controls bullet"><span class="by">yaohui-wyh</span><span>|</span><a href="#39963915">next</a><span>|</span><label class="collapse" for="c-39965529">[-]</label><label class="expand" for="c-39965529">[3 more]</label></div><br/><div class="children"><div class="content">This article has been around for some time, and it still shines. It focuses on building a product rather than just prototyping an LLM wrapper and waiting for the dark magic of GenAI.<p>Chapters like &quot;The Strive for Faster Latencies&quot; and &quot;Post-Processing&quot; are truly inspiring.<p>Creating production-level DevTools demands much more effort than merely wrapping around a ChatCompletion endpoint and mindlessly stuffing a context window with everything accessible inside the IDE (so-called &quot;prompt engineering&quot;).</div><br/><div id="39966453" class="c"><input type="checkbox" id="c-39966453" checked=""/><div class="controls bullet"><span class="by">benreesman</span><span>|</span><a href="#39965529">parent</a><span>|</span><a href="#39966341">next</a><span>|</span><label class="collapse" for="c-39966453">[-]</label><label class="expand" for="c-39966453">[1 more]</label></div><br/><div class="children"><div class="content">I <i>attempt</i> to use LLMs in coding tasks many times a day, the capability is there: Opus can make and execute a plan, GPT-4 can find and fix a few persistent typographical errors when Opus attempts verbatim output, and Dolphin-8x7 (or a bunch of other consistently candid models) can de-noise out the static interference from the Morality Police over-aligment.<p>For a long time it’s been about extravagances like the ability to recover from a lost session, or get a link queried and used as context, or do a reset of the slowly but inevitably corrupted state without losing all of your painstaking assembled point in some abstract state space.<p>Basic product building on <i>the core LLM experience</i> is way more important than incremental improvements on LLMs, I’d take robustness, consistency, and revision control over an LLM <i>breakthrough</i>, a chat bot session is a tech demo if I lose my work with my browser tab.<p>These folks get it, I agree.</div><br/></div></div><div id="39966341" class="c"><input type="checkbox" id="c-39966341" checked=""/><div class="controls bullet"><span class="by">metadat</span><span>|</span><a href="#39965529">parent</a><span>|</span><a href="#39966453">prev</a><span>|</span><a href="#39963915">next</a><span>|</span><label class="collapse" for="c-39966341">[-]</label><label class="expand" for="c-39966341">[1 more]</label></div><br/><div class="children"><div class="content">&gt; This article has been around for some time, ..<p>Interesting, what gave you this impression?  This article was first published only 4-6 months ago around Oct 2023.<p>Don&#x27;t get me wrong, I&#x27;m a fan of sourgraph and their founder, Quinn, is quite charismatic.  I almost went for a job offer with them 5+ years ago.  But let&#x27;s be real, startups are not a winning game for a non-founder, thank goodness I stuck it out with BigCorp.  In any case, this isn&#x27;t that old of a post, cheers.</div><br/></div></div></div></div><div id="39963915" class="c"><input type="checkbox" id="c-39963915" checked=""/><div class="controls bullet"><span class="by">Lucasoato</span><span>|</span><a href="#39965529">prev</a><span>|</span><a href="#39963540">next</a><span>|</span><label class="collapse" for="c-39963915">[-]</label><label class="expand" for="c-39963915">[23 more]</label></div><br/><div class="children"><div class="content">One thing I really miss is a standard way to block any copilot&#x2F;ai code completion tool from reaching specific files.
That’s particularly important for .env files, containing sensitive info. We don’t want leaking secrets outside our machine, imagine the risks if they become part of the next training dataset.
That’d be really easy to standardize, it’s just another .gitignore-like file.</div><br/><div id="39964173" class="c"><input type="checkbox" id="c-39964173" checked=""/><div class="controls bullet"><span class="by">ado__dev</span><span>|</span><a href="#39963915">parent</a><span>|</span><a href="#39964030">next</a><span>|</span><label class="collapse" for="c-39964173">[-]</label><label class="expand" for="c-39964173">[1 more]</label></div><br/><div class="children"><div class="content">So Cody allows you multiple ways to manage this.<p>In the Cody settings.json file you can disable autocomplete on entire languages&#x2F;file types.<p>Additionally, we recently rolled out a Cody Ignore file type where you can specify files&#x2F;folders that Cody will not look at for context. This feature is still in experimental mode though. <a href="https:&#x2F;&#x2F;sourcegraph.com&#x2F;docs&#x2F;cody&#x2F;capabilities&#x2F;ignore-context#cody-ignore" rel="nofollow">https:&#x2F;&#x2F;sourcegraph.com&#x2F;docs&#x2F;cody&#x2F;capabilities&#x2F;ignore-contex...</a><p>With Cody, we have a relationship w&#x2F; both Anthropic and OpenAI to never use any data submitted via Cody users for training and data is not retained either.</div><br/></div></div><div id="39964030" class="c"><input type="checkbox" id="c-39964030" checked=""/><div class="controls bullet"><span class="by">timrogers</span><span>|</span><a href="#39963915">parent</a><span>|</span><a href="#39964173">prev</a><span>|</span><a href="#39964652">next</a><span>|</span><label class="collapse" for="c-39964030">[-]</label><label class="expand" for="c-39964030">[5 more]</label></div><br/><div class="children"><div class="content">GitHub employee here<p>This does exist in GitHub Copilot - it’s called content exclusions: <a href="https:&#x2F;&#x2F;docs.github.com&#x2F;en&#x2F;copilot&#x2F;managing-github-copilot-in-your-organization&#x2F;configuring-content-exclusions-for-github-copilot" rel="nofollow">https:&#x2F;&#x2F;docs.github.com&#x2F;en&#x2F;copilot&#x2F;managing-github-copilot-i...</a><p>I’m not sure if Cody has a similar feature, or if there’s any move towards a standardised solution.</div><br/><div id="39966416" class="c"><input type="checkbox" id="c-39966416" checked=""/><div class="controls bullet"><span class="by">speedgoose</span><span>|</span><a href="#39963915">root</a><span>|</span><a href="#39964030">parent</a><span>|</span><a href="#39966222">next</a><span>|</span><label class="collapse" for="c-39966416">[-]</label><label class="expand" for="c-39966416">[1 more]</label></div><br/><div class="children"><div class="content">Could you make this feature available to every subscriber?</div><br/></div></div><div id="39966222" class="c"><input type="checkbox" id="c-39966222" checked=""/><div class="controls bullet"><span class="by">ametrau</span><span>|</span><a href="#39963915">root</a><span>|</span><a href="#39964030">parent</a><span>|</span><a href="#39966416">prev</a><span>|</span><a href="#39964652">next</a><span>|</span><label class="collapse" for="c-39966222">[-]</label><label class="expand" for="c-39966222">[3 more]</label></div><br/><div class="children"><div class="content">Not just any subscriber is allowed though:<p>&gt; This feature is available for organization accounts with a Copilot Business subscription.<p>And even if you exclude the moment anyone starts a chat the files are read and sent and could form suggestions:<p>&gt; Excluding content from GitHub Copilot currently only affects code completion. GitHub Copilot Chat is not affected by these settings.<p>Both quotes from your link</div><br/><div id="39966241" class="c"><input type="checkbox" id="c-39966241" checked=""/><div class="controls bullet"><span class="by">avmich</span><span>|</span><a href="#39963915">root</a><span>|</span><a href="#39966222">parent</a><span>|</span><a href="#39964652">next</a><span>|</span><label class="collapse" for="c-39966241">[-]</label><label class="expand" for="c-39966241">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Not just anyone is allowed though:<p>Does it mean engineers created the feature but managers disabled it for some users?</div><br/><div id="39967230" class="c"><input type="checkbox" id="c-39967230" checked=""/><div class="controls bullet"><span class="by">IMTDb</span><span>|</span><a href="#39963915">root</a><span>|</span><a href="#39966241">parent</a><span>|</span><a href="#39964652">next</a><span>|</span><label class="collapse" for="c-39967230">[-]</label><label class="expand" for="c-39967230">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s called Price discrimination (<a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Price_discrimination" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Price_discrimination</a>) almost all SAAS use it.<p>In this context, it means that I (a hobbyist) get to enjoy copilot at a discounted rate because there are some feature (context exclusion) which were costly to implement that I am not using. So it makes sense for me to take a less expensive plan which only includes the core features without the cruft. If there is any of these additional feature that I need, then  I just need to pay for the engineering time that went into them, which takes less than a few seconds, it&#x27;s just a button to click on. Fair and square.</div><br/></div></div></div></div></div></div></div></div><div id="39964652" class="c"><input type="checkbox" id="c-39964652" checked=""/><div class="controls bullet"><span class="by">jameslevy</span><span>|</span><a href="#39963915">parent</a><span>|</span><a href="#39964030">prev</a><span>|</span><a href="#39965807">next</a><span>|</span><label class="collapse" for="c-39964652">[-]</label><label class="expand" for="c-39964652">[1 more]</label></div><br/><div class="children"><div class="content">These types of tools should exclude all files and directories in the .gitignore as standard operating procedure, unless those files are specifically included. Not just because of secrets, but also because these files are not considered to be part of the repository source code and it would be unusual to need to access them for most tasks.</div><br/></div></div><div id="39965807" class="c"><input type="checkbox" id="c-39965807" checked=""/><div class="controls bullet"><span class="by">datascienced</span><span>|</span><a href="#39963915">parent</a><span>|</span><a href="#39964652">prev</a><span>|</span><a href="#39964817">next</a><span>|</span><label class="collapse" for="c-39965807">[-]</label><label class="expand" for="c-39965807">[2 more]</label></div><br/><div class="children"><div class="content">It should probably use .gitignore as a default then you can opt in &#x2F; out further. This would be a securer default than everything in.</div><br/><div id="39967180" class="c"><input type="checkbox" id="c-39967180" checked=""/><div class="controls bullet"><span class="by">danw1979</span><span>|</span><a href="#39963915">root</a><span>|</span><a href="#39965807">parent</a><span>|</span><a href="#39964817">next</a><span>|</span><label class="collapse" for="c-39967180">[-]</label><label class="expand" for="c-39967180">[1 more]</label></div><br/><div class="children"><div class="content">.gitignore unless there’s a specific .codyignore ?<p>Or maybe a set of sensible global default ignores, based on the usual suspects from gitignore.io or suchlike ?</div><br/></div></div></div></div><div id="39964817" class="c"><input type="checkbox" id="c-39964817" checked=""/><div class="controls bullet"><span class="by">wanderingmind</span><span>|</span><a href="#39963915">parent</a><span>|</span><a href="#39965807">prev</a><span>|</span><a href="#39965474">next</a><span>|</span><label class="collapse" for="c-39964817">[-]</label><label class="expand" for="c-39964817">[1 more]</label></div><br/><div class="children"><div class="content">We need a standardized .aiignore file that everyone can work with. Aider does this with .aiderignore. They all just need to agree on the common filename</div><br/></div></div><div id="39965474" class="c"><input type="checkbox" id="c-39965474" checked=""/><div class="controls bullet"><span class="by">imiric</span><span>|</span><a href="#39963915">parent</a><span>|</span><a href="#39964817">prev</a><span>|</span><a href="#39964215">next</a><span>|</span><label class="collapse" for="c-39965474">[-]</label><label class="expand" for="c-39965474">[2 more]</label></div><br/><div class="children"><div class="content">I agree, but you really shouldn&#x27;t keep unencrypted secrets locally to begin with.<p>Most secret managers allow you to either specify value references in .env files, or provide a way of running programs that specifically gives them access to secrets.</div><br/><div id="39967254" class="c"><input type="checkbox" id="c-39967254" checked=""/><div class="controls bullet"><span class="by">danw1979</span><span>|</span><a href="#39963915">root</a><span>|</span><a href="#39965474">parent</a><span>|</span><a href="#39964215">next</a><span>|</span><label class="collapse" for="c-39967254">[-]</label><label class="expand" for="c-39967254">[1 more]</label></div><br/><div class="children"><div class="content">I wouldn’t want Cody interrogating my local Terraform state or tfvars, for example.  There might not be unecrypted secrets in there, but there’s configuration data that I don’t want to disclose too.</div><br/></div></div></div></div><div id="39964215" class="c"><input type="checkbox" id="c-39964215" checked=""/><div class="controls bullet"><span class="by">Jimmc414</span><span>|</span><a href="#39963915">parent</a><span>|</span><a href="#39965474">prev</a><span>|</span><a href="#39963954">next</a><span>|</span><label class="collapse" for="c-39964215">[-]</label><label class="expand" for="c-39964215">[1 more]</label></div><br/><div class="children"><div class="content">I created a cli tool that copies a  GitHub or local repo into a text file for llm ingestion.  It only pulls the filetypes you specify.<p><a href="https:&#x2F;&#x2F;github.com&#x2F;jimmc414&#x2F;1filellm">https:&#x2F;&#x2F;github.com&#x2F;jimmc414&#x2F;1filellm</a></div><br/></div></div><div id="39963954" class="c"><input type="checkbox" id="c-39963954" checked=""/><div class="controls bullet"><span class="by">eddd-ddde</span><span>|</span><a href="#39963915">parent</a><span>|</span><a href="#39964215">prev</a><span>|</span><a href="#39966728">next</a><span>|</span><label class="collapse" for="c-39963954">[-]</label><label class="expand" for="c-39963954">[7 more]</label></div><br/><div class="children"><div class="content">Why not just use .gitignore itself? It&#x27;s also unlikely they want to train on build files and such.</div><br/><div id="39965376" class="c"><input type="checkbox" id="c-39965376" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#39963915">root</a><span>|</span><a href="#39963954">parent</a><span>|</span><a href="#39963973">next</a><span>|</span><label class="collapse" for="c-39965376">[-]</label><label class="expand" for="c-39965376">[1 more]</label></div><br/><div class="children"><div class="content">I often start a new project and work on it using Copilot for quite a while before making it official, running &quot;git init&quot; and creating a .gitignore file.</div><br/></div></div><div id="39963973" class="c"><input type="checkbox" id="c-39963973" checked=""/><div class="controls bullet"><span class="by">myko</span><span>|</span><a href="#39963915">root</a><span>|</span><a href="#39963954">parent</a><span>|</span><a href="#39965376">prev</a><span>|</span><a href="#39966728">next</a><span>|</span><label class="collapse" for="c-39963973">[-]</label><label class="expand" for="c-39963973">[5 more]</label></div><br/><div class="children"><div class="content">That makes sense but not everyone uses git. A new file that you can point to your gitignore in would probably be a good idea.</div><br/><div id="39963996" class="c"><input type="checkbox" id="c-39963996" checked=""/><div class="controls bullet"><span class="by">orhmeh09</span><span>|</span><a href="#39963915">root</a><span>|</span><a href="#39963973">parent</a><span>|</span><a href="#39965812">next</a><span>|</span><label class="collapse" for="c-39963996">[-]</label><label class="expand" for="c-39963996">[3 more]</label></div><br/><div class="children"><div class="content">If you do not use git, you might not be GitHub&#x27;s target audience.</div><br/><div id="39964357" class="c"><input type="checkbox" id="c-39964357" checked=""/><div class="controls bullet"><span class="by">Atotalnoob</span><span>|</span><a href="#39963915">root</a><span>|</span><a href="#39963996">parent</a><span>|</span><a href="#39964216">next</a><span>|</span><label class="collapse" for="c-39964357">[-]</label><label class="expand" for="c-39964357">[1 more]</label></div><br/><div class="children"><div class="content">You can purchase GitHub copilot and use it (even for corporations) and not use GitHub.<p>My company buys copilot for all devs, but doesn’t use GH or GHE</div><br/></div></div><div id="39964216" class="c"><input type="checkbox" id="c-39964216" checked=""/><div class="controls bullet"><span class="by">fragmede</span><span>|</span><a href="#39963915">root</a><span>|</span><a href="#39963996">parent</a><span>|</span><a href="#39964357">prev</a><span>|</span><a href="#39965812">next</a><span>|</span><label class="collapse" for="c-39964216">[-]</label><label class="expand" for="c-39964216">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s clever, but GitHub is recognized as the way to do things, so I&#x27;ve seen a couple repos where the only commits are of binaries to download, which technically uses git, but I wouldn&#x27;t really say that&#x27;s using git.</div><br/></div></div></div></div></div></div></div></div><div id="39966728" class="c"><input type="checkbox" id="c-39966728" checked=""/><div class="controls bullet"><span class="by">bamboozled</span><span>|</span><a href="#39963915">parent</a><span>|</span><a href="#39963954">prev</a><span>|</span><a href="#39963540">next</a><span>|</span><label class="collapse" for="c-39966728">[-]</label><label class="expand" for="c-39966728">[2 more]</label></div><br/><div class="children"><div class="content">You shouldn’t have sensitive secrets on your workstation in your .env file though. It’s not what it’s for.</div><br/><div id="39967544" class="c"><input type="checkbox" id="c-39967544" checked=""/><div class="controls bullet"><span class="by">0x008</span><span>|</span><a href="#39963915">root</a><span>|</span><a href="#39966728">parent</a><span>|</span><a href="#39963540">next</a><span>|</span><label class="collapse" for="c-39967544">[-]</label><label class="expand" for="c-39967544">[1 more]</label></div><br/><div class="children"><div class="content">Where would I keep them instead? I always wonder. Let’s say I am developing an app against OpenAI API. Where do I put the OpenAI API Key in VS Code?<p>As far as I know .env file is the main supported way of setting environmental variables in VS Code.</div><br/></div></div></div></div></div></div><div id="39963540" class="c"><input type="checkbox" id="c-39963540" checked=""/><div class="controls bullet"><span class="by">mayank</span><span>|</span><a href="#39963915">prev</a><span>|</span><a href="#39965481">next</a><span>|</span><label class="collapse" for="c-39963540">[-]</label><label class="expand" for="c-39963540">[4 more]</label></div><br/><div class="children"><div class="content">Very interesting! I wonder to what extent this assumption is true in tying completions to traditional code autocomplete.<p>&gt; One of the biggest constraints on the retrieval implementation is latency<p>If I’m getting a multi line block of code written automagically for me based on <i>comments</i> and the like, I’d personally value quality over latency and be more than happy to wait on a spinner. And I’d also be happy to map separate shortcuts for when I’m prepared to do so (avoiding the need to detect my intent).</div><br/><div id="39964198" class="c"><input type="checkbox" id="c-39964198" checked=""/><div class="controls bullet"><span class="by">ado__dev</span><span>|</span><a href="#39963540">parent</a><span>|</span><a href="#39965481">next</a><span>|</span><label class="collapse" for="c-39964198">[-]</label><label class="expand" for="c-39964198">[3 more]</label></div><br/><div class="children"><div class="content">This is great feedback and something we are looking at in regards to Cody. We value developer choice and at the moment for Chat developers can choose between various LLM models (Claude 3 Opus, GPT 4-Turbo, Mixtral 8x7b) that offer different benefits.<p>For autocomplete, at the moment we only support Starcoder because it has given us the best return on latency + quality, but we&#x27;d def love to support (and give users the choice to set an LLM of their choice, so if they prefer waiting longer for higher quality results, they should be able to)<p>You can do that with our local Ollama support, but that&#x27;s still experimental and YMMV. Here&#x27;s how to set it up: <a href="https:&#x2F;&#x2F;sourcegraph.com&#x2F;blog&#x2F;local-code-completion-with-ollama-and-cody" rel="nofollow">https:&#x2F;&#x2F;sourcegraph.com&#x2F;blog&#x2F;local-code-completion-with-olla...</a></div><br/><div id="39965633" class="c"><input type="checkbox" id="c-39965633" checked=""/><div class="controls bullet"><span class="by">dsissitka</span><span>|</span><a href="#39963540">root</a><span>|</span><a href="#39964198">parent</a><span>|</span><a href="#39965481">next</a><span>|</span><label class="collapse" for="c-39965633">[-]</label><label class="expand" for="c-39965633">[2 more]</label></div><br/><div class="children"><div class="content">&gt; We value developer choice and at the moment for Chat developers can choose between various LLM models (Claude 3 Opus, GPT 4-Turbo, Mixtral 8x7b) that offer different benefits.<p>I wish y&#x27;all would put a little more effort into user experience. When you go to subscribe it says:<p>&gt; Claude Instant 1.2, Claude 2, ChatGPT 3.5 Turbo, ChatGPT 4 Turbo Preview<p>Trying to figure out what&#x27;s supported was tedious enough[0] that I just ended up renewing my Copilot subscription instead.<p>[0] Your contact page for &quot;information about products and purchasing&quot; talks about scheduling a meeting. One of your welcome emails points us to your Discord but then your Discord points us to your forum.</div><br/><div id="39966001" class="c"><input type="checkbox" id="c-39966001" checked=""/><div class="controls bullet"><span class="by">ado__dev</span><span>|</span><a href="#39963540">root</a><span>|</span><a href="#39965633">parent</a><span>|</span><a href="#39965481">next</a><span>|</span><label class="collapse" for="c-39966001">[-]</label><label class="expand" for="c-39966001">[1 more]</label></div><br/><div class="children"><div class="content">Thank you for the feedback. I totally agree there and we&#x27;ll address this.</div><br/></div></div></div></div></div></div></div></div><div id="39965481" class="c"><input type="checkbox" id="c-39965481" checked=""/><div class="controls bullet"><span class="by">nicklecompte</span><span>|</span><a href="#39963540">prev</a><span>|</span><a href="#39963576">next</a><span>|</span><label class="collapse" for="c-39965481">[-]</label><label class="expand" for="c-39965481">[4 more]</label></div><br/><div class="children"><div class="content">&gt; Because of the language-specific nature of this heuristic, we generally do not support multi-line completions for all languages. However, we’re always happy to extend our list of supported languages and, since Cody is open-source, you can also contribute and improve the list. (link to <a href="https:&#x2F;&#x2F;github.com&#x2F;sourcegraph&#x2F;cody&#x2F;blob&#x2F;main&#x2F;vscode&#x2F;src&#x2F;completions&#x2F;language.ts">https:&#x2F;&#x2F;github.com&#x2F;sourcegraph&#x2F;cody&#x2F;blob&#x2F;main&#x2F;vscode&#x2F;src&#x2F;com...</a>)<p>That link to the list of supported languages is broken. I couldn&#x27;t find a similar file elsewhere in the repo: maybe the list got folded up into a function in another file? Also a bit annoying that I couldn&#x27;t find the info on the company&#x27;s website (though I gave up pretty quickly).</div><br/><div id="39965825" class="c"><input type="checkbox" id="c-39965825" checked=""/><div class="controls bullet"><span class="by">sqs</span><span>|</span><a href="#39965481">parent</a><span>|</span><a href="#39965612">next</a><span>|</span><label class="collapse" for="c-39965825">[-]</label><label class="expand" for="c-39965825">[1 more]</label></div><br/><div class="children"><div class="content">The list of supported languages is at <a href="https:&#x2F;&#x2F;sourcegraph.com&#x2F;docs&#x2F;cody&#x2F;faq#what-programming-languages-does-cody-support" rel="nofollow">https:&#x2F;&#x2F;sourcegraph.com&#x2F;docs&#x2F;cody&#x2F;faq#what-programming-langu...</a>. It works for all programming languages, but it works better on some than others, depending on the LLM and the language-specific work we&#x27;ve done on context-fetching, syntax-related heuristics, etc. On the LLM point, Cody supports multiple LLMs for both chat and autocomplete (Claude 3, GPT-4 Turbo, Mixtral, StarCoder, etc.), which is great for users but makes it tough to give any formal definition of &quot;supported language&quot;.</div><br/></div></div><div id="39965612" class="c"><input type="checkbox" id="c-39965612" checked=""/><div class="controls bullet"><span class="by">friendlynokill</span><span>|</span><a href="#39965481">parent</a><span>|</span><a href="#39965825">prev</a><span>|</span><a href="#39963576">next</a><span>|</span><label class="collapse" for="c-39965612">[-]</label><label class="expand" for="c-39965612">[2 more]</label></div><br/><div class="children"><div class="content">This should be the correct link: <a href="https:&#x2F;&#x2F;github.com&#x2F;sourcegraph&#x2F;cody&#x2F;blob&#x2F;main&#x2F;vscode&#x2F;src&#x2F;graph&#x2F;lsp&#x2F;languages.ts">https:&#x2F;&#x2F;github.com&#x2F;sourcegraph&#x2F;cody&#x2F;blob&#x2F;main&#x2F;vscode&#x2F;src&#x2F;gra...</a></div><br/><div id="39965720" class="c"><input type="checkbox" id="c-39965720" checked=""/><div class="controls bullet"><span class="by">nicklecompte</span><span>|</span><a href="#39965481">root</a><span>|</span><a href="#39965612">parent</a><span>|</span><a href="#39963576">next</a><span>|</span><label class="collapse" for="c-39965720">[-]</label><label class="expand" for="c-39965720">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think it is. There is a test file which includes C#, Kotlin, etc among supported languages, and those aren&#x27;t included in the file you linked: <a href="https:&#x2F;&#x2F;github.com&#x2F;sourcegraph&#x2F;cody&#x2F;blob&#x2F;main&#x2F;vscode&#x2F;src&#x2F;completions&#x2F;get-inline-completions-tests&#x2F;languages.test.ts">https:&#x2F;&#x2F;github.com&#x2F;sourcegraph&#x2F;cody&#x2F;blob&#x2F;main&#x2F;vscode&#x2F;src&#x2F;com...</a><p>But this test didn&#x27;t seem to include TypeScript so it&#x27;s obviously not comprehensive. I&#x27;m not convinced this information is actually in one place.</div><br/></div></div></div></div></div></div><div id="39963576" class="c"><input type="checkbox" id="c-39963576" checked=""/><div class="controls bullet"><span class="by">ForHackernews</span><span>|</span><a href="#39965481">prev</a><span>|</span><a href="#39963569">next</a><span>|</span><label class="collapse" for="c-39963576">[-]</label><label class="expand" for="c-39963576">[23 more]</label></div><br/><div class="children"><div class="content">&gt; Congratulations, you just wrote a code completion AI!<p>&gt; In fact, this is pretty much how we started out with Cody autocomplete back in March!<p>Am I wrong in thinking that there&#x27;s only like 3(?) actual AI companies and everything else is just some frontend to ChatGPT&#x2F;LLama&#x2F;Claude?<p>Is this sustainable? I guess the car industry is full of rebadged models with the same engines and chassis. It&#x27;s just wild that we keep hearing about the AI boom as though there&#x27;s a vibrant competitive ecosystem and not just Nvidia, a couple of software partners and then a sea of whiteboxers.</div><br/><div id="39964226" class="c"><input type="checkbox" id="c-39964226" checked=""/><div class="controls bullet"><span class="by">Metricon</span><span>|</span><a href="#39963576">parent</a><span>|</span><a href="#39963592">next</a><span>|</span><label class="collapse" for="c-39964226">[-]</label><label class="expand" for="c-39964226">[1 more]</label></div><br/><div class="children"><div class="content">For those who might not be aware of this, there is also an open source project on GitHub called &quot;Twinny&quot; which is an offline Visual Studio Code plugin equivalent to Copilot: <a href="https:&#x2F;&#x2F;github.com&#x2F;rjmacarthy&#x2F;twinny">https:&#x2F;&#x2F;github.com&#x2F;rjmacarthy&#x2F;twinny</a><p>It can be used with a number of local model services. Currently for my setup on a NVIDIA 4090, I&#x27;m running both the base and instruct model for deepseek-coder 6.7b using 5_K_M Quantization GGUF files (for performance) through llama.cpp &quot;server&quot; where the base model is for completions and the instruct model for chat interactions.<p>llama.cpp: <a href="https:&#x2F;&#x2F;github.com&#x2F;ggerganov&#x2F;llama.cpp&#x2F;">https:&#x2F;&#x2F;github.com&#x2F;ggerganov&#x2F;llama.cpp&#x2F;</a><p>deepseek-coder 6.7b base GGUF files: <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;TheBloke&#x2F;deepseek-coder-6.7B-base-GGUF" rel="nofollow">https:&#x2F;&#x2F;huggingface.co&#x2F;TheBloke&#x2F;deepseek-coder-6.7B-base-GGU...</a><p>deepseek-coder 6.7b instruct GGUF files: <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;TheBloke&#x2F;deepseek-coder-6.7B-instruct-GGUF" rel="nofollow">https:&#x2F;&#x2F;huggingface.co&#x2F;TheBloke&#x2F;deepseek-coder-6.7B-instruct...</a></div><br/></div></div><div id="39963592" class="c"><input type="checkbox" id="c-39963592" checked=""/><div class="controls bullet"><span class="by">airstrike</span><span>|</span><a href="#39963576">parent</a><span>|</span><a href="#39964226">prev</a><span>|</span><a href="#39963714">next</a><span>|</span><label class="collapse" for="c-39963592">[-]</label><label class="expand" for="c-39963592">[1 more]</label></div><br/><div class="children"><div class="content">you&#x27;ve got to differentiate between training, inference and hardware. they all benefit from the &quot;AI boom&quot; but at different levels and have varying levels of substitutability (Google tells me that&#x27;s a real word)</div><br/></div></div><div id="39965021" class="c"><input type="checkbox" id="c-39965021" checked=""/><div class="controls bullet"><span class="by">Art9681</span><span>|</span><a href="#39963576">parent</a><span>|</span><a href="#39963714">prev</a><span>|</span><a href="#39963853">next</a><span>|</span><label class="collapse" for="c-39965021">[-]</label><label class="expand" for="c-39965021">[1 more]</label></div><br/><div class="children"><div class="content">Now think about the amount of products built and scaled worldwide by this audience on top of the few cloud compute providers out there.</div><br/></div></div><div id="39963853" class="c"><input type="checkbox" id="c-39963853" checked=""/><div class="controls bullet"><span class="by">freecodyx</span><span>|</span><a href="#39963576">parent</a><span>|</span><a href="#39965021">prev</a><span>|</span><a href="#39963597">next</a><span>|</span><label class="collapse" for="c-39963853">[-]</label><label class="expand" for="c-39963853">[1 more]</label></div><br/><div class="children"><div class="content">it make sense, in order to come up with a base model, you will need a lot of quality training data, tons of compute.<p>the role of an AI startup is to come up with ideas, thus useful products.
Most of existing products pre-AI, are also front ends to existing operations systems and exiting databases, because creating the whole stack does not make sense.
At least we have state of the art open models that we can use freely</div><br/></div></div><div id="39963597" class="c"><input type="checkbox" id="c-39963597" checked=""/><div class="controls bullet"><span class="by">lozenge</span><span>|</span><a href="#39963576">parent</a><span>|</span><a href="#39963853">prev</a><span>|</span><a href="#39965849">next</a><span>|</span><label class="collapse" for="c-39963597">[-]</label><label class="expand" for="c-39963597">[16 more]</label></div><br/><div class="children"><div class="content">I mean... the article goes on to explain all their value add... which of course can be replicated, but it&#x27;s not as if you can just grab an API key and do the same.</div><br/><div id="39963631" class="c"><input type="checkbox" id="c-39963631" checked=""/><div class="controls bullet"><span class="by">ForHackernews</span><span>|</span><a href="#39963576">root</a><span>|</span><a href="#39963597">parent</a><span>|</span><a href="#39963875">next</a><span>|</span><label class="collapse" for="c-39963631">[-]</label><label class="expand" for="c-39963631">[12 more]</label></div><br/><div class="children"><div class="content">But OpenAI could make this themselves in a few weeks, right? If they happen to decide to, then this company is done.<p>That&#x27;s what I don&#x27;t get about all these AI startups. The core value of their business is an API call they don&#x27;t own.  It&#x27;s like people who were selling ______ apps on iPhone when Apple added their own built-in _____ features to iOS, except the entire industry is like that.</div><br/><div id="39963814" class="c"><input type="checkbox" id="c-39963814" checked=""/><div class="controls bullet"><span class="by">fluoridation</span><span>|</span><a href="#39963576">root</a><span>|</span><a href="#39963631">parent</a><span>|</span><a href="#39963770">next</a><span>|</span><label class="collapse" for="c-39963814">[-]</label><label class="expand" for="c-39963814">[2 more]</label></div><br/><div class="children"><div class="content">Well, the same happened in the early days of the PC. There were all these companies that sold basic utilities like disk scanners, defragmenters, partitioners, antiviruses, etc. When operating systems started to get bigger and include these utilities by default, that industry dried up overnight. I don&#x27;t think there&#x27;s anything wrong in building an inherently ephemeral business that just seeks to fill a niche that exists just because someone else hasn&#x27;t filled it yet.</div><br/><div id="39964013" class="c"><input type="checkbox" id="c-39964013" checked=""/><div class="controls bullet"><span class="by">littlestymaar</span><span>|</span><a href="#39963576">root</a><span>|</span><a href="#39963814">parent</a><span>|</span><a href="#39963770">next</a><span>|</span><label class="collapse" for="c-39964013">[-]</label><label class="expand" for="c-39964013">[1 more]</label></div><br/><div class="children"><div class="content">Don&#x27;t forget text editors! And even though it didn&#x27;t last, many people made very good money on these.</div><br/></div></div></div></div><div id="39963770" class="c"><input type="checkbox" id="c-39963770" checked=""/><div class="controls bullet"><span class="by">skybrian</span><span>|</span><a href="#39963576">root</a><span>|</span><a href="#39963631">parent</a><span>|</span><a href="#39963814">prev</a><span>|</span><a href="#39963820">next</a><span>|</span><label class="collapse" for="c-39963770">[-]</label><label class="expand" for="c-39963770">[6 more]</label></div><br/><div class="children"><div class="content">Well sure, a company with ample funding could in theory do anything. It seems sort of like asking why Google didn&#x27;t beat GitHub on code hosting. They did try, but their focus was elsewhere, so they gave it up. [1] And OpenAI doesn&#x27;t seem to be doing developer tools at all?<p>GitHub and Microsoft are more likely candidates. GitHub Copilot is a competing product that could be improved if they chose to do so.<p>[1] <a href="https:&#x2F;&#x2F;code.google.com&#x2F;archive&#x2F;" rel="nofollow">https:&#x2F;&#x2F;code.google.com&#x2F;archive&#x2F;</a></div><br/><div id="39963807" class="c"><input type="checkbox" id="c-39963807" checked=""/><div class="controls bullet"><span class="by">ForHackernews</span><span>|</span><a href="#39963576">root</a><span>|</span><a href="#39963770">parent</a><span>|</span><a href="#39963820">next</a><span>|</span><label class="collapse" for="c-39963807">[-]</label><label class="expand" for="c-39963807">[5 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not really saying that small companies should never compete with big companies.<p>I&#x27;m saying that a small company whose biggest competitor is also their key supplier is, if not doomed, at least operating on borrowed time. If my value proposition is reselling AWS hosting with an easy-to-use dashboard, I better pray to god Amazon never makes AWS simpler.</div><br/><div id="39964223" class="c"><input type="checkbox" id="c-39964223" checked=""/><div class="controls bullet"><span class="by">ado__dev</span><span>|</span><a href="#39963576">root</a><span>|</span><a href="#39963807">parent</a><span>|</span><a href="#39964249">next</a><span>|</span><label class="collapse" for="c-39964223">[-]</label><label class="expand" for="c-39964223">[1 more]</label></div><br/><div class="children"><div class="content">I feel like that can be said about any SaaS app. The reality is, mega-corps move very slowly and often can&#x27;t deliver the same user experience as a start up. If everyone had the approach of &quot;well I shouldn&#x27;t make this app because if Google wanted to, they could do it in a few weeks&quot; we wouldn&#x27;t have 90% of the startups we see today.</div><br/></div></div><div id="39964249" class="c"><input type="checkbox" id="c-39964249" checked=""/><div class="controls bullet"><span class="by">fragmede</span><span>|</span><a href="#39963576">root</a><span>|</span><a href="#39963807">parent</a><span>|</span><a href="#39964223">prev</a><span>|</span><a href="#39964378">next</a><span>|</span><label class="collapse" for="c-39964249">[-]</label><label class="expand" for="c-39964249">[1 more]</label></div><br/><div class="children"><div class="content">Aren&#x27;t we all operating on borrowed time though? Even if some company exists for 3 years and is able to founders a small acquihire exit, what&#x27;s wrong with borrowing some time from AWS&#x2F;OpenAI? We can&#x27;t all come up with PageRank and patent it and form a company around it.</div><br/></div></div><div id="39964378" class="c"><input type="checkbox" id="c-39964378" checked=""/><div class="controls bullet"><span class="by">skybrian</span><span>|</span><a href="#39963576">root</a><span>|</span><a href="#39963807">parent</a><span>|</span><a href="#39964249">prev</a><span>|</span><a href="#39963820">next</a><span>|</span><label class="collapse" for="c-39964378">[-]</label><label class="expand" for="c-39964378">[2 more]</label></div><br/><div class="children"><div class="content">From the article, it sounds like they are using Claude? Maybe there&#x27;s more than one possible supplier. There probably will be more.<p>Edit: looks like the autocomplete provider is configurable in the VS Code plugin settings. Not sure what the default is.</div><br/><div id="39964528" class="c"><input type="checkbox" id="c-39964528" checked=""/><div class="controls bullet"><span class="by">ado__dev</span><span>|</span><a href="#39963576">root</a><span>|</span><a href="#39964378">parent</a><span>|</span><a href="#39963820">next</a><span>|</span><label class="collapse" for="c-39964528">[-]</label><label class="expand" for="c-39964528">[1 more]</label></div><br/><div class="children"><div class="content">Currently for chat we support Claude 2, Claude 3 Haiku, Sonnet, and Opus, GPT-4 Turbo, and Mixtral 8x7b.<p>For autocomplete we&#x27;re using Starcoder 16b.<p>We also support local inference with any LLM via Ollama (this is experimental and only for Cody Free&#x2F;Pro users). Enterprise customers can choose which LLMs they want.</div><br/></div></div></div></div></div></div></div></div><div id="39963820" class="c"><input type="checkbox" id="c-39963820" checked=""/><div class="controls bullet"><span class="by">phillipcarter</span><span>|</span><a href="#39963576">root</a><span>|</span><a href="#39963631">parent</a><span>|</span><a href="#39963770">prev</a><span>|</span><a href="#39963875">next</a><span>|</span><label class="collapse" for="c-39963820">[-]</label><label class="expand" for="c-39963820">[3 more]</label></div><br/><div class="children"><div class="content">The “core value” of many companies is a database service they don’t own, but their businesses seem to do just fine. There’s a few who get obviated over time (usually they are also slow to react), but they’re a minority.<p>I would also question the idea that OpenAI could build a code editing companion this robust in a fee weeks. It’s been a long time since the models have been the limiting factor in these tools.</div><br/><div id="39964404" class="c"><input type="checkbox" id="c-39964404" checked=""/><div class="controls bullet"><span class="by">timrogers</span><span>|</span><a href="#39963576">root</a><span>|</span><a href="#39963820">parent</a><span>|</span><a href="#39964327">next</a><span>|</span><label class="collapse" for="c-39964404">[-]</label><label class="expand" for="c-39964404">[1 more]</label></div><br/><div class="children"><div class="content">I think I’d argue that the models are still a limiting factor for these kinds of tools - but there’s still also plenty of competitive space outside of models. The context you gather, the way you gather it and your prompting matters.</div><br/></div></div><div id="39964327" class="c"><input type="checkbox" id="c-39964327" checked=""/><div class="controls bullet"><span class="by">ForHackernews</span><span>|</span><a href="#39963576">root</a><span>|</span><a href="#39963820">parent</a><span>|</span><a href="#39964404">prev</a><span>|</span><a href="#39963875">next</a><span>|</span><label class="collapse" for="c-39964327">[-]</label><label class="expand" for="c-39964327">[1 more]</label></div><br/><div class="children"><div class="content">Most companies have valuable data that they <i>do</i> own stored in a commodity database they don&#x27;t. I know if Amazon started charging 10x for RDS, it would be painful but we could migrate in a few weeks.</div><br/></div></div></div></div></div></div><div id="39963875" class="c"><input type="checkbox" id="c-39963875" checked=""/><div class="controls bullet"><span class="by">tayo42</span><span>|</span><a href="#39963576">root</a><span>|</span><a href="#39963597">parent</a><span>|</span><a href="#39963631">prev</a><span>|</span><a href="#39965849">next</a><span>|</span><label class="collapse" for="c-39963875">[-]</label><label class="expand" for="c-39963875">[3 more]</label></div><br/><div class="children"><div class="content">Which part do you think you couldn&#x27;t do on your own with your own api key?</div><br/><div id="39963984" class="c"><input type="checkbox" id="c-39963984" checked=""/><div class="controls bullet"><span class="by">ec109685</span><span>|</span><a href="#39963576">root</a><span>|</span><a href="#39963875">parent</a><span>|</span><a href="#39965849">next</a><span>|</span><label class="collapse" for="c-39963984">[-]</label><label class="expand" for="c-39963984">[2 more]</label></div><br/><div class="children"><div class="content">They’ve been thinking about the problem continuously for the past year, can run experiments across their user base and thus have a lot more context and insight than someone whipping up an implementation.</div><br/><div id="39964237" class="c"><input type="checkbox" id="c-39964237" checked=""/><div class="controls bullet"><span class="by">tayo42</span><span>|</span><a href="#39963576">root</a><span>|</span><a href="#39963984">parent</a><span>|</span><a href="#39965849">next</a><span>|</span><label class="collapse" for="c-39964237">[-]</label><label class="expand" for="c-39964237">[1 more]</label></div><br/><div class="children"><div class="content">well they wrote a whole blog about how they do it... and im sure this isn&#x27;t the only one on how to approach this. they also only have a 30% acceptance rate, which is only 10% over their initial attempt with just a prompt.</div><br/></div></div></div></div></div></div></div></div><div id="39965849" class="c"><input type="checkbox" id="c-39965849" checked=""/><div class="controls bullet"><span class="by">hackerlight</span><span>|</span><a href="#39963576">parent</a><span>|</span><a href="#39963597">prev</a><span>|</span><a href="#39963569">next</a><span>|</span><label class="collapse" for="c-39965849">[-]</label><label class="expand" for="c-39965849">[1 more]</label></div><br/><div class="children"><div class="content">Your question can be reformulated as &quot;will the application layer&#x27;s lunch be eaten by better foundation models?&quot;</div><br/></div></div></div></div><div id="39963569" class="c"><input type="checkbox" id="c-39963569" checked=""/><div class="controls bullet"><span class="by">ypeterholmes</span><span>|</span><a href="#39963576">prev</a><span>|</span><a href="#39965639">next</a><span>|</span><label class="collapse" for="c-39963569">[-]</label><label class="expand" for="c-39963569">[2 more]</label></div><br/><div class="children"><div class="content">Fantastic article and impressive work by this company. They&#x27;re basically wrapping LLM&#x27;s with a working memory, and tying it to user input. And thus we step a little closer to AGI&#x2F;ASI.</div><br/><div id="39967563" class="c"><input type="checkbox" id="c-39967563" checked=""/><div class="controls bullet"><span class="by">0x008</span><span>|</span><a href="#39963569">parent</a><span>|</span><a href="#39965639">next</a><span>|</span><label class="collapse" for="c-39967563">[-]</label><label class="expand" for="c-39967563">[1 more]</label></div><br/><div class="children"><div class="content">It’s probably Retrieval Augmented Generation? Just wanted to put this here in case somebody is not familiar with this pattern.</div><br/></div></div></div></div><div id="39965639" class="c"><input type="checkbox" id="c-39965639" checked=""/><div class="controls bullet"><span class="by">jerrygoyal</span><span>|</span><a href="#39963569">prev</a><span>|</span><a href="#39964231">next</a><span>|</span><label class="collapse" for="c-39965639">[-]</label><label class="expand" for="c-39965639">[6 more]</label></div><br/><div class="children"><div class="content">has anyone tried Cody and Github Copilot and compared? I&#x27;m using GitHub Copilot and wouldn&#x27;t mind switching to a better alternative.</div><br/><div id="39966003" class="c"><input type="checkbox" id="c-39966003" checked=""/><div class="controls bullet"><span class="by">ado__dev</span><span>|</span><a href="#39965639">parent</a><span>|</span><a href="#39967069">next</a><span>|</span><label class="collapse" for="c-39966003">[-]</label><label class="expand" for="c-39966003">[2 more]</label></div><br/><div class="children"><div class="content">(I left this comment earlier but I&#x27;ll c+p here as well)<p>I wrote a blog post comparing Cody to Copilot a little while ago. Some of the stuff might be outdated now, but I think it still captures the essence of the differences between the two. Obviously I&#x27;m a little biased as I work for Sourcegraph, but I tried to be as fair as one could be. Happy to dive deeper into any details.
<a href="https:&#x2F;&#x2F;sourcegraph.com&#x2F;blog&#x2F;copilot-vs-cody-why-context-mat" rel="nofollow">https:&#x2F;&#x2F;sourcegraph.com&#x2F;blog&#x2F;copilot-vs-cody-why-context-mat</a>...<p>Our biggest differentiators are context, choice, and scale. We&#x27;ve been helping developers find and understand code for the last 10 years and are now applying a lot of that to Cody in regards to fetching the right context. When it comes choice, we support multiple LLMs and are always on the lookout in supporting the right LLM for the job. We recently rolled out Claude 3 Opus as well as Ollama support for offline&#x2F;local inference.<p>Cody also has a free tier where you can give it a try and compare for yourself, which is what I always recommend people do :)</div><br/><div id="39966131" class="c"><input type="checkbox" id="c-39966131" checked=""/><div class="controls bullet"><span class="by">hobo_in_library</span><span>|</span><a href="#39965639">root</a><span>|</span><a href="#39966003">parent</a><span>|</span><a href="#39967069">next</a><span>|</span><label class="collapse" for="c-39966131">[-]</label><label class="expand" for="c-39966131">[1 more]</label></div><br/><div class="children"><div class="content">that url got cut off and 404s (prob copy&#x2F;pasta from another comment)<p>Correct url: <a href="https:&#x2F;&#x2F;sourcegraph.com&#x2F;blog&#x2F;copilot-vs-cody-why-context-matters-for-code-ai" rel="nofollow">https:&#x2F;&#x2F;sourcegraph.com&#x2F;blog&#x2F;copilot-vs-cody-why-context-mat...</a></div><br/></div></div></div></div><div id="39967069" class="c"><input type="checkbox" id="c-39967069" checked=""/><div class="controls bullet"><span class="by">skybrian</span><span>|</span><a href="#39965639">parent</a><span>|</span><a href="#39966003">prev</a><span>|</span><a href="#39966631">next</a><span>|</span><label class="collapse" for="c-39967069">[-]</label><label class="expand" for="c-39967069">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve used Copilot for months and Cody just today. I&#x27;m in the habit of using autocomplete to generate multiline chunks of code. So far, Copilot seems a bit better at autocomplete.<p>In particular, Copilot seems to do better at generating missing TypeScript import statements. These are relative imports of files in the same small repo. Neither of them seems to really understand my codebase in the way that Cody promises - they make up imports of nonexistent files. Copilot <i>sometimes</i> guesses the right file, I think based on my understanding my naming conventions better.</div><br/></div></div><div id="39966631" class="c"><input type="checkbox" id="c-39966631" checked=""/><div class="controls bullet"><span class="by">veselin</span><span>|</span><a href="#39965639">parent</a><span>|</span><a href="#39967069">prev</a><span>|</span><a href="#39966644">next</a><span>|</span><label class="collapse" for="c-39966631">[-]</label><label class="expand" for="c-39966631">[1 more]</label></div><br/><div class="children"><div class="content">I used them both.<p>I ended up disabling copilot. The reason is that the completions do not always integrate with the rest of the code, in particular with non-matching brackets. Often it just repeats some other part of the code. I had much fewer cases of this with Cody. But, arguably, the difference is not huge. But then add on top of this choice of models.</div><br/></div></div><div id="39966644" class="c"><input type="checkbox" id="c-39966644" checked=""/><div class="controls bullet"><span class="by">solumunus</span><span>|</span><a href="#39965639">parent</a><span>|</span><a href="#39966631">prev</a><span>|</span><a href="#39964231">next</a><span>|</span><label class="collapse" for="c-39966644">[-]</label><label class="expand" for="c-39966644">[1 more]</label></div><br/><div class="children"><div class="content">I switched from Copilot to Supermaven and in my experience it’s more than twice as effective. The suggestions are better and incredibly fast. Co pilot was a nice productivity boost but this is next level for me, I’m genuinely building features noticeably faster.</div><br/></div></div></div></div><div id="39964231" class="c"><input type="checkbox" id="c-39964231" checked=""/><div class="controls bullet"><span class="by">Exuma</span><span>|</span><a href="#39965639">prev</a><span>|</span><a href="#39963755">next</a><span>|</span><label class="collapse" for="c-39964231">[-]</label><label class="expand" for="c-39964231">[3 more]</label></div><br/><div class="children"><div class="content">how does this compare to copilot? i would be willing to switch (or try it at least) if it can give better experience inside neovim</div><br/><div id="39964264" class="c"><input type="checkbox" id="c-39964264" checked=""/><div class="controls bullet"><span class="by">ado__dev</span><span>|</span><a href="#39964231">parent</a><span>|</span><a href="#39964242">next</a><span>|</span><label class="collapse" for="c-39964264">[-]</label><label class="expand" for="c-39964264">[1 more]</label></div><br/><div class="children"><div class="content">I wrote a blog post comparing Cody to Copilot a little while ago. Some of the stuff might be outdated now, but I think it still captures the essence of the differences between the two. Obviously I&#x27;m a little biased as I work for Sourcegraph, but I tried to be as fair as one could be. Happy to dive deeper into any details.<p><a href="https:&#x2F;&#x2F;sourcegraph.com&#x2F;blog&#x2F;copilot-vs-cody-why-context-matters-for-code-ai" rel="nofollow">https:&#x2F;&#x2F;sourcegraph.com&#x2F;blog&#x2F;copilot-vs-cody-why-context-mat...</a><p>Our biggest differentiators are context, choice, and scale. We&#x27;ve been helping developers find and understand code for the last 10 years and are now applying a lot of that to Cody in regards to fetching the right context. When it comes choice, we support multiple LLMs and are always on the lookout in supporting the right LLM for the job. We recently rolled out Claude 3 Opus as well as Ollama support for offline&#x2F;local inference.<p>Cody also has a free tier where you can give it a try and compare for yourself, which is what I always recommend people do :)<p>On Neovim, Cody actually does have experimental support for neovim: <a href="https:&#x2F;&#x2F;sourcegraph.com&#x2F;docs&#x2F;cody&#x2F;clients&#x2F;install-neovim" rel="nofollow">https:&#x2F;&#x2F;sourcegraph.com&#x2F;docs&#x2F;cody&#x2F;clients&#x2F;install-neovim</a>. Not all features are supported as in VS Code though.</div><br/></div></div><div id="39964242" class="c"><input type="checkbox" id="c-39964242" checked=""/><div class="controls bullet"><span class="by">phillipcarter</span><span>|</span><a href="#39964231">parent</a><span>|</span><a href="#39964264">prev</a><span>|</span><a href="#39963755">next</a><span>|</span><label class="collapse" for="c-39964242">[-]</label><label class="expand" for="c-39964242">[1 more]</label></div><br/><div class="children"><div class="content">Cody is very good. I recommend giving it a try.<p>FWIW I believe Cody is much more actively developed than Copilot is these days, and so it has a more comprehensive feature set.</div><br/></div></div></div></div></div></div></div></div></div></body></html>