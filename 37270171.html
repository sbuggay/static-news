<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1693040458787" as="style"/><link rel="stylesheet" href="styles.css?v=1693040458787"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/trholding/llama2.c/releases/tag/L2E_v0.1">Llama2.c L2E LLM – Multi OS Binary and Unikernel Release</a> <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>AMICABoard</span> | <span>4 comments</span></div><br/><div><div id="37270172" class="c"><input type="checkbox" id="c-37270172" checked=""/><div class="controls bullet"><span class="by">AMICABoard</span><span>|</span><a href="#37270912">next</a><span>|</span><label class="collapse" for="c-37270172">[-]</label><label class="expand" for="c-37270172">[1 more]</label></div><br/><div class="children"><div class="content">Have you ever wanted to boot and inference a herd of 1000&#x27;s of Virtual baby Llama 2 models on big ass enterprise servers? No? Well, now you can! (Almost baremetal)<p>Also drop the binary portable run.com cosmocc build on any OS and run! Truly portable. (Soon baremetal)<p>Special Thanks &amp; Credits:<p>llama2.c - @karpathy<p>cosmopolitan - @jart<p>unikraft - @unikraft<p>Would love to hear your feed back here!</div><br/></div></div><div id="37270912" class="c"><input type="checkbox" id="c-37270912" checked=""/><div class="controls bullet"><span class="by">ragnarok123</span><span>|</span><a href="#37270172">prev</a><span>|</span><a href="#37270735">next</a><span>|</span><label class="collapse" for="c-37270912">[-]</label><label class="expand" for="c-37270912">[1 more]</label></div><br/><div class="children"><div class="content">Does it offer a local api so i can embed this in my python build?</div><br/></div></div><div id="37270735" class="c"><input type="checkbox" id="c-37270735" checked=""/><div class="controls bullet"><span class="by">politelemon</span><span>|</span><a href="#37270912">prev</a><span>|</span><label class="collapse" for="c-37270735">[-]</label><label class="expand" for="c-37270735">[1 more]</label></div><br/><div class="children"><div class="content">Is this similar to llama.cpp? I&#x27;m not very versed in this area.</div><br/></div></div></div></div></div></div></div></body></html>