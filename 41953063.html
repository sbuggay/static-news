<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1730019650594" as="style"/><link rel="stylesheet" href="styles.css?v=1730019650594"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a>Tell HN: GpuOwl/PRPLL, GPU software used to find the largest prime number</a> </div><div class="subtext"><span>mpreda</span> | <span>25 comments</span></div><br/><div><div id="41953514" class="c"><input type="checkbox" id="c-41953514" checked=""/><div class="controls bullet"><span class="by">motorolnik</span><span>|</span><a href="#41960600">next</a><span>|</span><label class="collapse" for="c-41953514">[-]</label><label class="expand" for="c-41953514">[5 more]</label></div><br/><div class="children"><div class="content">Hi,
I&#x27;ve got few questions:<p>1). What profiling tools do you use for GPU code?<p>2). Where one would start, in terms of learning resources, about coding using inline GPU assembler?<p>3). Do you verify GPU assembler generated by a compiler from C&#x2F;C++ code, in terms of effectiveness? If so, which tools do you use for that?<p>4). Is SIMD on GPUs a thing?<p>5). What are the primary factors being taken into account by you (cache sizes, microoptimizations, etc.) when you write code for a tool like gpuowl&#x2F;prpll? Which factor is the most important?
Thanks!</div><br/><div id="41953930" class="c"><input type="checkbox" id="c-41953930" checked=""/><div class="controls bullet"><span class="by">mpreda</span><span>|</span><a href="#41953514">parent</a><span>|</span><a href="#41953553">next</a><span>|</span><label class="collapse" for="c-41953930">[-]</label><label class="expand" for="c-41953930">[2 more]</label></div><br/><div class="children"><div class="content">1. My profiling is rudimentary but effective. I measure per-kernel execution time with OpenCL events (which register with high accuracy start&#x2F;end times w. practically no overhead), and also I continously measure per-iteration time by dividing wall-time for blocks of 20&#x27;000 iterations by that nb. These measuremens are consistent and sensitive.<p>2. I&#x27;m not aware of good learning resources. Explore existing such code, e.g. opencl miners tend to use asm. Read in amdgpu&#x2F; in LLVM. Disassemble code from OpenCL and read the ISA. Explore and experiment, but it&#x27;s tedious. I would not recommend to jump into ISA initially. BTW AMD does have good GCN ISA docs available online, that is useful!<p>3. Yes I often read the compiled ISA, and over time I discover bugs and also better understand the ISA.<p>4. OpenCL is SIMD, and yes it matches the GPU HW.<p>5. most important is to reduce the number of registers used (#VGPRs), as that influences heavilly the occupancy of the kernel. Use fewer costly instructions such as FP64 mul&#x2F;FMA. Sequential memory access, and in general reduce global memory access as it&#x27;s very slow. Merge small kernels into one (keep the data in the kernel). Never spill VGPRs.</div><br/><div id="41960748" class="c"><input type="checkbox" id="c-41960748" checked=""/><div class="controls bullet"><span class="by">mpreda</span><span>|</span><a href="#41953514">root</a><span>|</span><a href="#41953930">parent</a><span>|</span><a href="#41953553">next</a><span>|</span><label class="collapse" for="c-41960748">[-]</label><label class="expand" for="c-41960748">[1 more]</label></div><br/><div class="children"><div class="content">My above answer was typed on a mobile phone while travelling, so it was maybe exceedingly brief. But now, on a real keyboard, I can go into more detail on any point if there&#x27;s interest.</div><br/></div></div></div></div><div id="41953553" class="c"><input type="checkbox" id="c-41953553" checked=""/><div class="controls bullet"><span class="by">motorolnik</span><span>|</span><a href="#41953514">parent</a><span>|</span><a href="#41953930">prev</a><span>|</span><a href="#41960600">next</a><span>|</span><label class="collapse" for="c-41953553">[-]</label><label class="expand" for="c-41953553">[2 more]</label></div><br/><div class="children"><div class="content">And another more general question: (6) gcc, clang, and nvcc have some OpenMP offloading capabilities which allow to compile code into binaries which can then run on GPUs. Is the code they produce through OpenMP anywhere close to what one gets directly with i.e. opencl?</div><br/><div id="41953971" class="c"><input type="checkbox" id="c-41953971" checked=""/><div class="controls bullet"><span class="by">mpreda</span><span>|</span><a href="#41953514">root</a><span>|</span><a href="#41953553">parent</a><span>|</span><a href="#41960600">next</a><span>|</span><label class="collapse" for="c-41953971">[-]</label><label class="expand" for="c-41953971">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t know, I haven&#x27;t eplored OpenMP myself.. maybe some day.</div><br/></div></div></div></div></div></div><div id="41960600" class="c"><input type="checkbox" id="c-41960600" checked=""/><div class="controls bullet"><span class="by">DeathArrow</span><span>|</span><a href="#41953514">prev</a><span>|</span><a href="#41959966">next</a><span>|</span><label class="collapse" for="c-41960600">[-]</label><label class="expand" for="c-41960600">[3 more]</label></div><br/><div class="children"><div class="content">Why do you use OpenCL instead of CUDA?</div><br/><div id="41960726" class="c"><input type="checkbox" id="c-41960726" checked=""/><div class="controls bullet"><span class="by">mpreda</span><span>|</span><a href="#41960600">parent</a><span>|</span><a href="#41959966">next</a><span>|</span><label class="collapse" for="c-41960726">[-]</label><label class="expand" for="c-41960726">[2 more]</label></div><br/><div class="children"><div class="content">Indeed CUDA is nice due to the way it uses C++, integrates host and GPU code in a single file, and in the convenience of compilation. Basically I think CUDA is a bit easier to start with than OpenCL.<p>OTOH CUDA only works on Nvidia, and that&#x27;s a major limitation.<p>GpuOwl uses heavily FP64 (&quot;double&quot; floating point), and FP64 is more readily available at consumer prices on AMD GPUs. We (the GIMPS project) use a lot of Radeon VII and Radeon Pro VII GPUs, which have great FP64 at a cheap price (I am personally running 8x Radeon Pro VII that I bought new for about $300 a piece).<p>So you see, for us AMD GPUs are the first citizen. Of course I want to support Nvidia GPUs as well, and OpenCL allows that. Luke Durant did run GpuOwl on a lot of Nvidia GPUs in the cloud, and I&#x27;m happy GpuOwl did work well for him on Nvidia.</div><br/><div id="41960899" class="c"><input type="checkbox" id="c-41960899" checked=""/><div class="controls bullet"><span class="by">DeathArrow</span><span>|</span><a href="#41960600">root</a><span>|</span><a href="#41960726">parent</a><span>|</span><a href="#41959966">next</a><span>|</span><label class="collapse" for="c-41960899">[-]</label><label class="expand" for="c-41960899">[1 more]</label></div><br/><div class="children"><div class="content">Thank you. It makes sense to use OpenCL if you have AMD GPUs in mind.<p>I thought though that prospective HPC users have more Nvidia A100 and H100 in mind when buying hardware.</div><br/></div></div></div></div></div></div><div id="41959966" class="c"><input type="checkbox" id="c-41959966" checked=""/><div class="controls bullet"><span class="by">kristopolous</span><span>|</span><a href="#41960600">prev</a><span>|</span><a href="#41958924">next</a><span>|</span><label class="collapse" for="c-41959966">[-]</label><label class="expand" for="c-41959966">[1 more]</label></div><br/><div class="children"><div class="content">The binary of this number is over 16MB of 1s. that&#x27;s nuts.</div><br/></div></div><div id="41958924" class="c"><input type="checkbox" id="c-41958924" checked=""/><div class="controls bullet"><span class="by">dgacmu</span><span>|</span><a href="#41959966">prev</a><span>|</span><a href="#41953108">next</a><span>|</span><label class="collapse" for="c-41958924">[-]</label><label class="expand" for="c-41958924">[4 more]</label></div><br/><div class="children"><div class="content">First, congrats! Awesome work and appreciate you sharing more.<p>Second: I&#x27;m confused by something in your readme. It says:<p>&gt; For Mersenne primes search, the PRP test is by far preferred over LL, such that LL is not used anymore for search.<p>But later notes that PRP is computationally nearly identical to LL. Was that sentence supposed to say TF and P-1 instead of PRP or am I misunderstanding something about the actual computational cost of PRP?</div><br/><div id="41958959" class="c"><input type="checkbox" id="c-41958959" checked=""/><div class="controls bullet"><span class="by">cbright</span><span>|</span><a href="#41958924">parent</a><span>|</span><a href="#41953108">next</a><span>|</span><label class="collapse" for="c-41958959">[-]</label><label class="expand" for="c-41958959">[3 more]</label></div><br/><div class="children"><div class="content">The PRP test has the same computational cost as an LL test.  The reason why GIMPS now prefers to do PRP tests instead of LL tests is because an efficiently verifiable proof-of-work certificate was developed for PRP tests [1].<p>[1] <a href="https:&#x2F;&#x2F;doi.org&#x2F;10.4230&#x2F;LIPIcs.ITCS.2019.60" rel="nofollow">https:&#x2F;&#x2F;doi.org&#x2F;10.4230&#x2F;LIPIcs.ITCS.2019.60</a></div><br/><div id="41960807" class="c"><input type="checkbox" id="c-41960807" checked=""/><div class="controls bullet"><span class="by">mpreda</span><span>|</span><a href="#41958924">root</a><span>|</span><a href="#41958959">parent</a><span>|</span><a href="#41959156">next</a><span>|</span><label class="collapse" for="c-41960807">[-]</label><label class="expand" for="c-41960807">[1 more]</label></div><br/><div class="children"><div class="content">Yes. In fact the transition from LL to PRP took place in two steps, at different moments in time.<p>We used to use the LL test because the LL result is a bit stronger than the PRP result, LL stating that the number is prime, while PRP saying only that it is likely prime. This is the reason LL is still used as an after-test following any successful PRP discovery, as it happened for the most recent M52 as well.<p>The first transition from LL to PRP happened because a very strong and cheap error-checking algorithm, that we call &quot;the Gerbicz error check&quot;, was discovered by Robert Gerbicz. This error-check in its most efficient form only works for PRP not for LL. This error-check allows to verify the correctitude of the computation, as it progresses on the GPU, with high confidence and low overhead. It does protect against a lot of HW errors originating from e.g. the GPU VRAM overheating, the GPU having been under-volted too aggressively, bad VRAM; but also from SW bugs and from FFT precision issues.<p>As the test of a single exponent takes a long time (let&#x27;s say 24h on a fast GPU), having confidence that this long computation is proceeding along correctly instead of wasting cycles is a great benefit from the error-check.<p>The second step of the transition from LL to PRP happened when the PRP proof was introduced, following on the ideas from the VDF (Verifiable Delay Function) article, which allowed to verify cheaply that a PRP test was indeed executed correcty. This eliminated the need for the Double Check (DC) which was standard procedure with the LL test; practically speeding the process up with 100%.</div><br/></div></div><div id="41959156" class="c"><input type="checkbox" id="c-41959156" checked=""/><div class="controls bullet"><span class="by">dgacmu</span><span>|</span><a href="#41958924">root</a><span>|</span><a href="#41958959">parent</a><span>|</span><a href="#41960807">prev</a><span>|</span><a href="#41953108">next</a><span>|</span><label class="collapse" for="c-41959156">[-]</label><label class="expand" for="c-41959156">[1 more]</label></div><br/><div class="children"><div class="content">Ah, that&#x27;s interesting and makes sense. Thank you!</div><br/></div></div></div></div></div></div><div id="41953108" class="c"><input type="checkbox" id="c-41953108" checked=""/><div class="controls bullet"><span class="by">mpreda</span><span>|</span><a href="#41958924">prev</a><span>|</span><a href="#41953444">next</a><span>|</span><label class="collapse" for="c-41953108">[-]</label><label class="expand" for="c-41953108">[3 more]</label></div><br/><div class="children"><div class="content">Some topic ideas:<p><pre><code>  - Why use OpenCL when implementing GPU software
  - Does it run on AMD or on Nvidia GPUs?
  - How does the primality test implemented in GpuOwl work?
  - How fast is it to test a Mersenne candidate?
  - Why use FFTs? how large are the FFTs?
  - What do you use for sin&#x2F;cos?</code></pre></div><br/><div id="41959931" class="c"><input type="checkbox" id="c-41959931" checked=""/><div class="controls bullet"><span class="by">latchkey</span><span>|</span><a href="#41953108">parent</a><span>|</span><a href="#41953444">next</a><span>|</span><label class="collapse" for="c-41959931">[-]</label><label class="expand" for="c-41959931">[2 more]</label></div><br/><div class="children"><div class="content">It definitely runs on our AMD MI300x. But, the documentation is pretty fragmented and requires a bunch of math knowledge that I don&#x27;t have, so I&#x27;m not really sure how to run it. Just some proof of working...<p><a href="https:&#x2F;&#x2F;x.com&#x2F;HotAisle&#x2F;status&#x2F;1848780396609106359" rel="nofollow">https:&#x2F;&#x2F;x.com&#x2F;HotAisle&#x2F;status&#x2F;1848780396609106359</a><p>If someone can come up with a way to perf test this against an H100, hit me up! It seems like something that could make a fun competition given the use of OpenCL. =)</div><br/><div id="41960824" class="c"><input type="checkbox" id="c-41960824" checked=""/><div class="controls bullet"><span class="by">mpreda</span><span>|</span><a href="#41953108">root</a><span>|</span><a href="#41959931">parent</a><span>|</span><a href="#41953444">next</a><span>|</span><label class="collapse" for="c-41960824">[-]</label><label class="expand" for="c-41960824">[1 more]</label></div><br/><div class="children"><div class="content">Point taken. I need to improve the documentation and make it easier to start with.<p>There is a lot of documentation and HowTos on the Mersenne Forums [1] where experienced users help newcomers, and that relieves effort from myself.<p>[1] <a href="http:&#x2F;&#x2F;mersenneforum.org&#x2F;" rel="nofollow">http:&#x2F;&#x2F;mersenneforum.org&#x2F;</a></div><br/></div></div></div></div></div></div><div id="41953444" class="c"><input type="checkbox" id="c-41953444" checked=""/><div class="controls bullet"><span class="by">iyn</span><span>|</span><a href="#41953108">prev</a><span>|</span><a href="#41957473">next</a><span>|</span><label class="collapse" for="c-41953444">[-]</label><label class="expand" for="c-41953444">[3 more]</label></div><br/><div class="children"><div class="content">Wow, congrats!<p>Indeed, I’m curious why you’ve used OpenCL. And what was the hardware&#x2F;general setup used for finding the prime?<p>What was your motivation behind building this software?</div><br/><div id="41960850" class="c"><input type="checkbox" id="c-41960850" checked=""/><div class="controls bullet"><span class="by">mpreda</span><span>|</span><a href="#41953444">parent</a><span>|</span><a href="#41953964">next</a><span>|</span><label class="collapse" for="c-41960850">[-]</label><label class="expand" for="c-41960850">[1 more]</label></div><br/><div class="children"><div class="content">The HW setup for finding the prime was Nvidia and AMD GPUs with good FP64 in the cloud, using &quot;spot&quot; instances for better price. This allowed scaling up quickly to many GPUs, and it did have a significant cost.<p>My personal setup is 8x Radeon Pro VII which also provide heating during the cold season. During summer the effort is in removing the excess heat, and the GPUs run in a reduced-power mode (slower &amp; more efficient).</div><br/></div></div><div id="41953964" class="c"><input type="checkbox" id="c-41953964" checked=""/><div class="controls bullet"><span class="by">mpreda</span><span>|</span><a href="#41953444">parent</a><span>|</span><a href="#41960850">prev</a><span>|</span><a href="#41957473">next</a><span>|</span><label class="collapse" for="c-41953964">[-]</label><label class="expand" for="c-41953964">[1 more]</label></div><br/><div class="children"><div class="content">OpenCL works on both AMD and Nvidia GPUs with mostly the same source code. By supporting at-runtime compilation it allows a lot of code particularization&#x2F;instantiation before compilation, which reduces the power (cost) of the generated code. In general OpenCL is close enough to the HW and the generated code is improving over time (LLVM).<p>Motivation: a long time ago I had an AMD GPU and no way to run an LL test on it, so I decided to write my own. And I was hooked by the power of the GPU and the quest for ever more efficient, faster implem.</div><br/></div></div></div></div><div id="41957473" class="c"><input type="checkbox" id="c-41957473" checked=""/><div class="controls bullet"><span class="by">rigmonger</span><span>|</span><a href="#41953444">prev</a><span>|</span><a href="#41959598">next</a><span>|</span><label class="collapse" for="c-41957473">[-]</label><label class="expand" for="c-41957473">[2 more]</label></div><br/><div class="children"><div class="content">First of all, thank you for your work and congratulations on your achievements, both in the search for Mersenne primes and software development.<p>I am contributing to GIMPS with 2 Radeon Pro VII cards. I&#x27;m wondering what will happen when ROCm stops supporting these GPUs.<p>Do you have any plans to keep them working with GPUOwl&#x2F;Prpll when they are no longer supported by ROCm?</div><br/><div id="41960869" class="c"><input type="checkbox" id="c-41960869" checked=""/><div class="controls bullet"><span class="by">mpreda</span><span>|</span><a href="#41957473">parent</a><span>|</span><a href="#41959598">next</a><span>|</span><label class="collapse" for="c-41960869">[-]</label><label class="expand" for="c-41960869">[1 more]</label></div><br/><div class="children"><div class="content">IF ROCm stops supporting Radeon Pro VII, the first solution is to stay on the most recent ROCm that still supports them.<p>Second, &quot;does not support anymore&quot; does not necessarily mean that it stops working on the old HW, but it could mean that new features&#x2F;extension aren&#x27;t implemented for the old HW anymore, and we may not care about those.<p>Third, AMD does contribute and integrates changes with upstream LLVM. This open-source work could be used by third parties (with significant effort I assume) to continue support.</div><br/></div></div></div></div><div id="41959598" class="c"><input type="checkbox" id="c-41959598" checked=""/><div class="controls bullet"><span class="by">primecurious</span><span>|</span><a href="#41957473">prev</a><span>|</span><label class="collapse" for="c-41959598">[-]</label><label class="expand" for="c-41959598">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;d also like to draw attention that a lot of this work was sponsored by IMC the market maker, Mihai&#x27;s employer.</div><br/><div id="41960679" class="c"><input type="checkbox" id="c-41960679" checked=""/><div class="controls bullet"><span class="by">mpreda</span><span>|</span><a href="#41959598">parent</a><span>|</span><label class="collapse" for="c-41960679">[-]</label><label class="expand" for="c-41960679">[2 more]</label></div><br/><div class="children"><div class="content">What! This is absolutely not true. My open source work was not sponsored by anyone. And IMC is not my employer. But really, how did you get this idea?</div><br/><div id="41960896" class="c"><input type="checkbox" id="c-41960896" checked=""/><div class="controls bullet"><span class="by">mpreda</span><span>|</span><a href="#41959598">root</a><span>|</span><a href="#41960679">parent</a><span>|</span><label class="collapse" for="c-41960896">[-]</label><label class="expand" for="c-41960896">[1 more]</label></div><br/><div class="children"><div class="content">&quot;primecurious&quot;, who you are and what is the purpose of such statements? how would you know who is or isn&#x27;t sponsoring my work?<p>But just to set it straight, GpuOwl received exactly $0 contributions or sponsoring from exactly nobody. It&#x27;s a pleasure work from my side, and it&#x27;s open sourced for the easy access of curious minds to the algorithms and techniques implemented. I did receive great help, in the form of source-code contributions, most importantly from George Woltman.</div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>