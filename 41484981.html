<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1725872472874" as="style"/><link rel="stylesheet" href="styles.css?v=1725872472874"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://old.reddit.com/r/LocalLLaMA/s/4Ly2yj78aM">Confirmed: Reflection 70B&#x27;s official API is a wrapper for Sonnet 3.5</a> <span class="domain">(<a href="https://old.reddit.com">old.reddit.com</a>)</span></div><div class="subtext"><span>apsec112</span> | <span>30 comments</span></div><br/><div><div id="41485234" class="c"><input type="checkbox" id="c-41485234" checked=""/><div class="controls bullet"><span class="by">scosman</span><span>|</span><a href="#41485077">next</a><span>|</span><label class="collapse" for="c-41485234">[-]</label><label class="expand" for="c-41485234">[5 more]</label></div><br/><div class="children"><div class="content">Context: someone announced a Llama 3.1 70B fine tune with incredible benchmark results a few days ago. It&#x27;s been a dramatic ride:<p>- The weight releases were messed up: released Lora for Llama 3.0, claiming it was a 3.1 fine tune<p>- Evals initially didn&#x27;t meet expectations when run on released weights<p>- The evals starting performing near&#x2F;at SOTA when using a hosted endpoint<p>- Folks are finding clever ways to see what model is running on the endpoint (using model specific tokens, and model specific censoring). This post claims there&#x27;s proof it&#x27;s not running on their model, but just a prompt on Sonnet 3.5<p>- After it was caught and posted as being Sonnet, it stop reproducing. Then others in the thread claimed to find evidence he just switched the hosted model to GPT 4o using similar techniques.<p>Lots of mixed results, inconsistent repos, and general confusion from the bad weight releases. Lots of wasted time. Not clear what&#x27;s true and what&#x27;s not.</div><br/><div id="41486165" class="c"><input type="checkbox" id="c-41486165" checked=""/><div class="controls bullet"><span class="by">ga6840</span><span>|</span><a href="#41485234">parent</a><span>|</span><a href="#41486255">next</a><span>|</span><label class="collapse" for="c-41486165">[-]</label><label class="expand" for="c-41486165">[2 more]</label></div><br/><div class="children"><div class="content">Who is Sahil Chaudhary? Why he doesn&#x27;t announce such a great advancement himself? Why Matt Shumer first announces it only because -- according to a later claim on X.com -- he trusted Sahil, does that mean Matt is unable to participate most of the progress? Then why announce a breakthrough without mentioning he was not fully involved to a level he can verify the result in the first place?</div><br/><div id="41486259" class="c"><input type="checkbox" id="c-41486259" checked=""/><div class="controls bullet"><span class="by">jazzyjackson</span><span>|</span><a href="#41485234">root</a><span>|</span><a href="#41486165">parent</a><span>|</span><a href="#41486255">next</a><span>|</span><label class="collapse" for="c-41486259">[-]</label><label class="expand" for="c-41486259">[1 more]</label></div><br/><div class="children"><div class="content">One more reason not to pay attention to things that only seem to exist on x.com</div><br/></div></div></div></div><div id="41485690" class="c"><input type="checkbox" id="c-41485690" checked=""/><div class="controls bullet"><span class="by">GaggiX</span><span>|</span><a href="#41485234">parent</a><span>|</span><a href="#41486255">prev</a><span>|</span><a href="#41485077">next</a><span>|</span><label class="collapse" for="c-41485690">[-]</label><label class="expand" for="c-41485690">[1 more]</label></div><br/><div class="children"><div class="content">When they were using the Sonnet 3.5 API, they censored the word &quot;Claude&quot; and replaced &quot;Anthropic&quot; with &quot;Meta&quot;, then later when people realized this, they removed it.<p>Also, after GPT-4o they switched to a llama checkpoint (probably 405B-inst), so now the tokenizer is in common (no more tokenization trick).</div><br/></div></div></div></div><div id="41485077" class="c"><input type="checkbox" id="c-41485077" checked=""/><div class="controls bullet"><span class="by">TheAceOfHearts</span><span>|</span><a href="#41485234">prev</a><span>|</span><a href="#41486392">next</a><span>|</span><label class="collapse" for="c-41485077">[-]</label><label class="expand" for="c-41485077">[1 more]</label></div><br/><div class="children"><div class="content">The link is broken, the correct link seems to be this post [0].<p>[0] <a href="https:&#x2F;&#x2F;old.reddit.com&#x2F;r&#x2F;LocalLLaMA&#x2F;comments&#x2F;1fc98fu&#x2F;confirmed_reflection_70bs_official_api_is_sonnet&#x2F;" rel="nofollow">https:&#x2F;&#x2F;old.reddit.com&#x2F;r&#x2F;LocalLLaMA&#x2F;comments&#x2F;1fc98fu&#x2F;confirm...</a></div><br/></div></div><div id="41486392" class="c"><input type="checkbox" id="c-41486392" checked=""/><div class="controls bullet"><span class="by">throwaway81523</span><span>|</span><a href="#41485077">prev</a><span>|</span><a href="#41485180">next</a><span>|</span><label class="collapse" for="c-41486392">[-]</label><label class="expand" for="c-41486392">[1 more]</label></div><br/><div class="children"><div class="content">Working old.reddit link with tracker bypassed: <a href="https:&#x2F;&#x2F;old.reddit.com&#x2F;r&#x2F;LocalLLaMA&#x2F;comments&#x2F;1fc98fu" rel="nofollow">https:&#x2F;&#x2F;old.reddit.com&#x2F;r&#x2F;LocalLLaMA&#x2F;comments&#x2F;1fc98fu</a></div><br/></div></div><div id="41485180" class="c"><input type="checkbox" id="c-41485180" checked=""/><div class="controls bullet"><span class="by">salomonk_mur</span><span>|</span><a href="#41486392">prev</a><span>|</span><a href="#41485230">next</a><span>|</span><label class="collapse" for="c-41485180">[-]</label><label class="expand" for="c-41485180">[8 more]</label></div><br/><div class="children"><div class="content">It&#x27;s amazing what people will do for clout. His whole reputation is ruined. What was Schumer&#x27;s endgame?</div><br/><div id="41485699" class="c"><input type="checkbox" id="c-41485699" checked=""/><div class="controls bullet"><span class="by">ipsum2</span><span>|</span><a href="#41485180">parent</a><span>|</span><a href="#41485623">next</a><span>|</span><label class="collapse" for="c-41485699">[-]</label><label class="expand" for="c-41485699">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s also amazing that GlaiveAI will be synonymous with fraud in ML now, because an investor decided to fake some benchmarks. The founder of GlaiveAI, Sahil Chaudhary also participated in the creation of the model.</div><br/></div></div><div id="41485623" class="c"><input type="checkbox" id="c-41485623" checked=""/><div class="controls bullet"><span class="by">joegibbs</span><span>|</span><a href="#41485180">parent</a><span>|</span><a href="#41485699">prev</a><span>|</span><a href="#41485332">next</a><span>|</span><label class="collapse" for="c-41485623">[-]</label><label class="expand" for="c-41485623">[2 more]</label></div><br/><div class="children"><div class="content">That&#x27;s what I&#x27;m wondering. Did he think that nobody would bother checking it? Then he was saying all that stuff about the model being &quot;corrupted during upload&quot; - maybe he didn&#x27;t think it was going to get as much traction as it did?</div><br/><div id="41485666" class="c"><input type="checkbox" id="c-41485666" checked=""/><div class="controls bullet"><span class="by">JTyQZSnP3cQGa8B</span><span>|</span><a href="#41485180">root</a><span>|</span><a href="#41485623">parent</a><span>|</span><a href="#41485332">next</a><span>|</span><label class="collapse" for="c-41485666">[-]</label><label class="expand" for="c-41485666">[1 more]</label></div><br/><div class="children"><div class="content">I doubt it considering he’s been overselling his scam all over LinkedIn.</div><br/></div></div></div></div><div id="41485332" class="c"><input type="checkbox" id="c-41485332" checked=""/><div class="controls bullet"><span class="by">blackeyeblitzar</span><span>|</span><a href="#41485180">parent</a><span>|</span><a href="#41485623">prev</a><span>|</span><a href="#41485230">next</a><span>|</span><label class="collapse" for="c-41485332">[-]</label><label class="expand" for="c-41485332">[4 more]</label></div><br/><div class="children"><div class="content">I haven’t followed this story. What did he do that ruined his reputation? The story link here is broken for me.</div><br/><div id="41485665" class="c"><input type="checkbox" id="c-41485665" checked=""/><div class="controls bullet"><span class="by">postalcoder</span><span>|</span><a href="#41485180">root</a><span>|</span><a href="#41485332">parent</a><span>|</span><a href="#41485230">next</a><span>|</span><label class="collapse" for="c-41485665">[-]</label><label class="expand" for="c-41485665">[3 more]</label></div><br/><div class="children"><div class="content">An AI engagement farmer on twitter claimed to create a llama 3.1 fine tine, trained on &quot;reflection&quot; (ie internal thinking) prompting that outperformed the likes of Llama 405B and even the closed source models on benchmarks.<p>The guy says that the model is so good because it was tuned on data generated by Glaive AI. He tells everyone he uses Glaive AI and that everyone else should use it too.<p>Releases the model on HF, is an absolute poopstorm. People cannot recreate the stated benchmarks, the guy who released the model literally said &quot;they uploaded it wrong&quot;. Pretty much turns to dog-ate-my-homework type excuses that don&#x27;t make sense either. Turns out people find it&#x27;s just llama 3.0 with some lora applied.<p>Then some others do some digging to find out that Glaive AI is a company that Matt Schumer invested in, which he did not disclose on Twitter.<p>He does a holding pattern on Twitter, saying something to the effect of &quot;the weight got scrambled!&quot; and says that they&#x27;re going to give access to a hosted endpoint and then figure out the weight issue later.<p>People try out this hosted model and find out it&#x27;s actually just proxying requests through to anthropic&#x27;s sonnet 3.5 api, with some filtering for words like &quot;Claude&quot;.<p>After he was found out, they switch the proxy over to gpt 4o.<p>The endgame of this guy was probably 1. to promote his company and 2. to raise funding for another company. Both failed spectacularly, this guy is a scammer to the nth degree.<p>Edit: uncensored &quot;Glaive AI&quot;.</div><br/><div id="41485727" class="c"><input type="checkbox" id="c-41485727" checked=""/><div class="controls bullet"><span class="by">ipsum2</span><span>|</span><a href="#41485180">root</a><span>|</span><a href="#41485665">parent</a><span>|</span><a href="#41485230">next</a><span>|</span><label class="collapse" for="c-41485727">[-]</label><label class="expand" for="c-41485727">[2 more]</label></div><br/><div class="children"><div class="content">This is accurate, but you don&#x27;t need to censor GlaiveAI. They helped create the model. They&#x27;re complicit in the scam.</div><br/><div id="41485836" class="c"><input type="checkbox" id="c-41485836" checked=""/><div class="controls bullet"><span class="by">postalcoder</span><span>|</span><a href="#41485180">root</a><span>|</span><a href="#41485727">parent</a><span>|</span><a href="#41485230">next</a><span>|</span><label class="collapse" for="c-41485836">[-]</label><label class="expand" for="c-41485836">[1 more]</label></div><br/><div class="children"><div class="content">I took out Glaive so as not to give them free publicity – all I did was mess up the formatting of my comment.<p>And yes, you&#x27;re correct. Glaive employee(s) contributed to the model uploaded on HF.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="41485230" class="c"><input type="checkbox" id="c-41485230" checked=""/><div class="controls bullet"><span class="by">loop22</span><span>|</span><a href="#41485180">prev</a><span>|</span><a href="#41485842">next</a><span>|</span><label class="collapse" for="c-41485230">[-]</label><label class="expand" for="c-41485230">[3 more]</label></div><br/><div class="children"><div class="content">A much better summary is this Twitter&#x2F;X thread: <a href="https:&#x2F;&#x2F;x.com&#x2F;RealJosephus&#x2F;status&#x2F;1832904398831280448" rel="nofollow">https:&#x2F;&#x2F;x.com&#x2F;RealJosephus&#x2F;status&#x2F;1832904398831280448</a></div><br/><div id="41486441" class="c"><input type="checkbox" id="c-41486441" checked=""/><div class="controls bullet"><span class="by">esperent</span><span>|</span><a href="#41485230">parent</a><span>|</span><a href="#41485842">next</a><span>|</span><label class="collapse" for="c-41486441">[-]</label><label class="expand" for="c-41486441">[2 more]</label></div><br/><div class="children"><div class="content">How does one read this without a Twitter account? I only see one post.</div><br/><div id="41486533" class="c"><input type="checkbox" id="c-41486533" checked=""/><div class="controls bullet"><span class="by">elwypea</span><span>|</span><a href="#41485230">root</a><span>|</span><a href="#41486441">parent</a><span>|</span><a href="#41485842">next</a><span>|</span><label class="collapse" for="c-41486533">[-]</label><label class="expand" for="c-41486533">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;xcancel.com&#x2F;RealJosephus&#x2F;status&#x2F;1832904398831280448" rel="nofollow">https:&#x2F;&#x2F;xcancel.com&#x2F;RealJosephus&#x2F;status&#x2F;1832904398831280448</a></div><br/></div></div></div></div></div></div><div id="41485842" class="c"><input type="checkbox" id="c-41485842" checked=""/><div class="controls bullet"><span class="by">zozbot234</span><span>|</span><a href="#41485230">prev</a><span>|</span><a href="#41485364">next</a><span>|</span><label class="collapse" for="c-41485842">[-]</label><label class="expand" for="c-41485842">[3 more]</label></div><br/><div class="children"><div class="content">Okay, let&#x27;s think this through step by step.  Isn&#x27;t &#x27;reflection thinking&#x27; a pretty well known technique in the AI prompt field?  So this model was supposed to be so much better... why, exactly? It makes very little sense to me.  Is it just about separating the &quot;reflections&#x2F;chain of thoughts&quot; from the &quot;final output&quot; via specific tags?</div><br/><div id="41486308" class="c"><input type="checkbox" id="c-41486308" checked=""/><div class="controls bullet"><span class="by">jazzyjackson</span><span>|</span><a href="#41485842">parent</a><span>|</span><a href="#41486014">next</a><span>|</span><label class="collapse" for="c-41486308">[-]</label><label class="expand" for="c-41486308">[1 more]</label></div><br/><div class="children"><div class="content">Supposedly was not just prompted to use reflection, but fine tuned on synthetic data demonstrating how to use the &lt;|thinking|&gt; tokens to reason, what self correction looks like etc</div><br/></div></div><div id="41486014" class="c"><input type="checkbox" id="c-41486014" checked=""/><div class="controls bullet"><span class="by">imtringued</span><span>|</span><a href="#41485842">parent</a><span>|</span><a href="#41486308">prev</a><span>|</span><a href="#41485364">next</a><span>|</span><label class="collapse" for="c-41486014">[-]</label><label class="expand" for="c-41486014">[1 more]</label></div><br/><div class="children"><div class="content">The problem with LLMs is that they struggle to generalize out of distribution. By training the model on a sequence of semantically tagged steps, you allow the model to stay in the training distribution for a larger amount of prompts.<p>I don&#x27;t think it is 100% a scam, as in, his technique does improve performance, since a lot of the benefits can be replicated by a system prompt, but the wild performance claims are probably completely fabricated.</div><br/></div></div></div></div><div id="41485364" class="c"><input type="checkbox" id="c-41485364" checked=""/><div class="controls bullet"><span class="by">0cf8612b2e1e</span><span>|</span><a href="#41485842">prev</a><span>|</span><a href="#41485068">next</a><span>|</span><label class="collapse" for="c-41485364">[-]</label><label class="expand" for="c-41485364">[1 more]</label></div><br/><div class="children"><div class="content">Recent thread: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=41459781">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=41459781</a><p>Author’s original (soon to be deleted tweet?)<p><pre><code>  I&#x27;m excited to announce Reflection 70B, the world’s top open-source model.

  Trained using Reflection-Tuning, a technique developed to enable LLMs to fix their own mistakes.

  405B coming next week - we expect it to be the best model in the world.</code></pre></div><br/></div></div><div id="41485068" class="c"><input type="checkbox" id="c-41485068" checked=""/><div class="controls bullet"><span class="by">v64</span><span>|</span><a href="#41485364">prev</a><span>|</span><a href="#41486139">next</a><span>|</span><label class="collapse" for="c-41485068">[-]</label><label class="expand" for="c-41485068">[1 more]</label></div><br/><div class="children"><div class="content">link does not work for me, discussion is here <a href="https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;LocalLLaMA&#x2F;comments&#x2F;1fc98fu&#x2F;confirmed_reflection_70bs_official_api_is_sonnet&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;LocalLLaMA&#x2F;comments&#x2F;1fc98fu&#x2F;confirm...</a></div><br/></div></div><div id="41486139" class="c"><input type="checkbox" id="c-41486139" checked=""/><div class="controls bullet"><span class="by">ricardobeat</span><span>|</span><a href="#41485068">prev</a><span>|</span><a href="#41485963">next</a><span>|</span><label class="collapse" for="c-41486139">[-]</label><label class="expand" for="c-41486139">[2 more]</label></div><br/><div class="children"><div class="content">Looks like old.reddit.com is now also putting everything behind a login prompt. Archive is unable to fetch the post. Any other way to read this?</div><br/><div id="41486216" class="c"><input type="checkbox" id="c-41486216" checked=""/><div class="controls bullet"><span class="by">seszett</span><span>|</span><a href="#41486139">parent</a><span>|</span><a href="#41485963">next</a><span>|</span><label class="collapse" for="c-41486216">[-]</label><label class="expand" for="c-41486216">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s because the link is wrong (and is interpreted as someone wanted to post something, which obviously needs login) but one comment provides the good one:<p><a href="https:&#x2F;&#x2F;old.reddit.com&#x2F;r&#x2F;LocalLLaMA&#x2F;comments&#x2F;1fc98fu&#x2F;confirmed_reflection_70bs_official_api_is_sonnet&#x2F;" rel="nofollow">https:&#x2F;&#x2F;old.reddit.com&#x2F;r&#x2F;LocalLLaMA&#x2F;comments&#x2F;1fc98fu&#x2F;confirm...</a></div><br/></div></div></div></div><div id="41485963" class="c"><input type="checkbox" id="c-41485963" checked=""/><div class="controls bullet"><span class="by">mikkom</span><span>|</span><a href="#41486139">prev</a><span>|</span><a href="#41486013">next</a><span>|</span><label class="collapse" for="c-41485963">[-]</label><label class="expand" for="c-41485963">[1 more]</label></div><br/><div class="children"><div class="content">Where exactly is this &quot;official API&quot;?</div><br/></div></div><div id="41486013" class="c"><input type="checkbox" id="c-41486013" checked=""/><div class="controls bullet"><span class="by">ben30</span><span>|</span><a href="#41485963">prev</a><span>|</span><a href="#41485935">next</a><span>|</span><label class="collapse" for="c-41486013">[-]</label><label class="expand" for="c-41486013">[1 more]</label></div><br/><div class="children"><div class="content">Milkshake duck</div><br/></div></div><div id="41485935" class="c"><input type="checkbox" id="c-41485935" checked=""/><div class="controls bullet"><span class="by">mcemilg</span><span>|</span><a href="#41486013">prev</a><span>|</span><label class="collapse" for="c-41485935">[-]</label><label class="expand" for="c-41485935">[2 more]</label></div><br/><div class="children"><div class="content">Whatever happens, this has excited me a bit. The possibility of a 70B parameter model performing at the level of Sonnet 3.5 could change many things. Currently, Sonnet 3.5 is the backbone of many coding assistant applications, and a 70B parameter model can run locally quite comfortably or be easily served. It could have been revolutionary. I think they’ve unintentionally set a great goal for small labs to achieve…</div><br/></div></div></div></div></div></div></div></body></html>