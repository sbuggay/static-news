<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1690966863055" as="style"/><link rel="stylesheet" href="styles.css?v=1690966863055"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.beatandraise.com/">Reading SEC filings using LLMs</a>Â <span class="domain">(<a href="https://www.beatandraise.com">www.beatandraise.com</a>)</span></div><div class="subtext"><span>nnechm</span> | <span>25 comments</span></div><br/><div><div id="36967206" class="c"><input type="checkbox" id="c-36967206" checked=""/><div class="controls bullet"><span class="by">nnechm</span><span>|</span><a href="#36968437">next</a><span>|</span><label class="collapse" for="c-36967206">[-]</label><label class="expand" for="c-36967206">[21 more]</label></div><br/><div class="children"><div class="content">I have been working on getting ChatGPT to answer questions that equity research analysts, investors would like to get from SEC filings. The application uses a combination of hybrid text search and LLMs for completion and does not rely much on embedding based distance searches.<p>A core assumption underlying this is that LLMs are already pretty good and will continue to get better at reading texts. If provided with the right thing to read, they will do very well on &#x27;reading comprehension&#x27;.<p>Open ended writing is more susceptible to errors, especially in questions related to finance. For e.g google&#x27;s revenues are just as likely to be 280.2 billion vs 279 billion in a probabilistic model that guesses the next part of the sentence -  Google&#x27;s revenues for FY 2022 are ....<p>So this leaves us with the main problem to solve; Serving the right texts to the LLM aka text search.<p>Once the right text is served, we can generate any pretty much anything in the text, Income statements, ceo comments, accounts payable on the fly, For e.g try - `can you get me Nvidia and AMD&#x27;s income statement from March 2020 ?` as in here. <a href="https:&#x2F;&#x2F;imgur.com&#x2F;gallery&#x2F;H8Vfd5X" rel="nofollow noreferrer">https:&#x2F;&#x2F;imgur.com&#x2F;gallery&#x2F;H8Vfd5X</a>
A few more examples, Apple&#x27;s sales in China, Google&#x27;s revenue by quarter: <a href="https:&#x2F;&#x2F;imgur.com&#x2F;a&#x2F;oCCay3o" rel="nofollow noreferrer">https:&#x2F;&#x2F;imgur.com&#x2F;a&#x2F;oCCay3o</a><p>Currently, the application supports ~8k companies that are registered with the SEC. Pdfs are still work in progress, so tesla etc don&#x27;t work as well.<p>The stack is Nextjs on Supabase. So Postgres&#x27;s inbuilt text search does a lot of heavy lifting.<p>If one thinks of the bigger picture, we can extend&#x2F;improve this to pdfs and the entire universe of stocks and more. a.k.a a big component of what CapitalIQ, Factset, Bloomberg and Reuters do can now be generated on the fly accurately for a fraction of the cost.<p>Generating graphs with gross margin increasing etc are just one step further and stuff like EV&#x2F;Ebitda, yet another step further,  as one can call a stock pricing api for each date of the report.<p>I would guess a number of LLM applications follow a similar process, ask a question --&gt; LLM converts to query --&gt; datalakes&#x2F;bases --&gt; searching and serving texts --&gt; answer.
Goes without saying, I would appreciate any feedback, especially from those who are building stuff that looks architecturally similar :) !</div><br/><div id="36967254" class="c"><input type="checkbox" id="c-36967254" checked=""/><div class="controls bullet"><span class="by">anotherhue</span><span>|</span><a href="#36967206">parent</a><span>|</span><a href="#36967898">next</a><span>|</span><label class="collapse" for="c-36967254">[-]</label><label class="expand" for="c-36967254">[6 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve been trying something similar with parliamentary debates. They&#x27;re long winded, often full of empty speech, and a chore to read.<p>The LLMs are able to hone in on the details and provide interesting responses like &quot;What questions were asked of the minister that they failed to address&quot; and &quot;What should the opposition leader have mentioned in their response that the minister would have found difficult to answer&quot;<p>Crucially, they&#x27;re well transcribed: <a href="https:&#x2F;&#x2F;api.oireachtas.ie&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;api.oireachtas.ie&#x2F;</a></div><br/><div id="36968580" class="c"><input type="checkbox" id="c-36968580" checked=""/><div class="controls bullet"><span class="by">dcsan</span><span>|</span><a href="#36967206">root</a><span>|</span><a href="#36967254">parent</a><span>|</span><a href="#36967405">next</a><span>|</span><label class="collapse" for="c-36968580">[-]</label><label class="expand" for="c-36968580">[1 more]</label></div><br/><div class="children"><div class="content">Could you ask an LLM if they were persuaded by a speaker of one side of a debate as a method of evaluation? Ie the bot&#x27;s before and after opinion based on fine-tuning with the pro and con arguments?<p>I was also thinking about a society of bots type application where you could have autonomous bot researchers, debaters, judges and audience. Would be interesting to feed in the topics and grab some popcorn</div><br/></div></div><div id="36967405" class="c"><input type="checkbox" id="c-36967405" checked=""/><div class="controls bullet"><span class="by">nnechm</span><span>|</span><a href="#36967206">root</a><span>|</span><a href="#36967254">parent</a><span>|</span><a href="#36968580">prev</a><span>|</span><a href="#36967898">next</a><span>|</span><label class="collapse" for="c-36967405">[-]</label><label class="expand" for="c-36967405">[4 more]</label></div><br/><div class="children"><div class="content">I think one thing you can try is to figure out what lies where, so chunking arbitrarily will not work as well as chunking with headings for e.g<p>For e.g,  if the question is: &quot;What should the opposition leader have mentioned in their response that the minister would have found difficult to answer.&quot;<p>An embedding based search will find it fairly difficult to match this against a text. Based on my experience, you have to figure out what is a nonanswer first (i don&#x27;t think that&#x27;s easy but gpt4 is very good at a lot of language based stuff.)<p>you can try Q1: question A1: Answer then prompt GPT, do you think A1 answers the question and then save it.
And then, 
Q1: question, A1: Answer, Q2: Follow up based on the following questions, do you think  A1 answers Q1 and then save it to a db.<p>You can then augment it in the code with our own knowledge of how politicians lie, using certain words etc :) to improve what gpt4 might miss...</div><br/><div id="36967717" class="c"><input type="checkbox" id="c-36967717" checked=""/><div class="controls bullet"><span class="by">anotherhue</span><span>|</span><a href="#36967206">root</a><span>|</span><a href="#36967405">parent</a><span>|</span><a href="#36967898">next</a><span>|</span><label class="collapse" for="c-36967717">[-]</label><label class="expand" for="c-36967717">[3 more]</label></div><br/><div class="children"><div class="content">&gt; &quot;We&#x27;re definitely moving forward with strong measures to improve the situation, and while progress might not be immediately visible, we&#x27;re fully engaged in this essential journey.&quot;</div><br/><div id="36967845" class="c"><input type="checkbox" id="c-36967845" checked=""/><div class="controls bullet"><span class="by">nnechm</span><span>|</span><a href="#36967206">root</a><span>|</span><a href="#36967717">parent</a><span>|</span><a href="#36967936">next</a><span>|</span><label class="collapse" for="c-36967845">[-]</label><label class="expand" for="c-36967845">[1 more]</label></div><br/><div class="children"><div class="content">This is how GPT4 answers the question... I assumed the question, but presumably will be along those lines :)<p><a href="https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;c736abf4-ae3c-4fbd-9427-b7d2f9413213" rel="nofollow noreferrer">https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;c736abf4-ae3c-4fbd-9427-b7d2f9...</a></div><br/></div></div><div id="36967936" class="c"><input type="checkbox" id="c-36967936" checked=""/><div class="controls bullet"><span class="by">hef19898</span><span>|</span><a href="#36967206">root</a><span>|</span><a href="#36967717">parent</a><span>|</span><a href="#36967845">prev</a><span>|</span><a href="#36967898">next</a><span>|</span><label class="collapse" for="c-36967936">[-]</label><label class="expand" for="c-36967936">[1 more]</label></div><br/><div class="children"><div class="content">Man, it seems the people writing politicians, or managers, statements seem at serious risk being replaced with a LLM...</div><br/></div></div></div></div></div></div></div></div><div id="36967898" class="c"><input type="checkbox" id="c-36967898" checked=""/><div class="controls bullet"><span class="by">hef19898</span><span>|</span><a href="#36967206">parent</a><span>|</span><a href="#36967254">prev</a><span>|</span><a href="#36967264">next</a><span>|</span><label class="collapse" for="c-36967898">[-]</label><label class="expand" for="c-36967898">[2 more]</label></div><br/><div class="children"><div class="content">I once had a collegue who used ChatGPT to sumarize our then employer&#x27;s SEC filings. Results were, well, putting it mildly, mixed. Best case was a slightly less biased version of the &quot;shareholder letters&quot; (read: propaganda pieces) published around the same time.<p>What ChatGPT completey missed was stuff like omissions (I&#x27;ll kind of give it a pass here, how can software analyse the absence of something without having access to supplemental documents; it still shoes hoe dangerous it is to rely <i>only</i> on a LLM for such analysis) and, more importantly, the connection between certain tid bits and, and here it became outright dangerous, ChatGPT didn&#x27;t provide anything meaningful on risks and financials.<p>The tid bit it missed, one of the most important ones at the time, was a huge multi year contract given to a large investor in said company. To find it, including the honestly hilarious amount, one had to connect the disclosure of not specified contract to a named investor, the specifics of said contract (not mentioning the investor by name), the amount stated in some finacial statement from the document and, here obviously ChatGPT failed completely, knowledge of what said investor (a pretty (in)-famous company) specialized in. ChatGPT did even mention a single of those data points. Fun fact, said contract covered a significant junk of the amount the investing company had invested to begin with. And all that during a time in which the financial stability of the reporting company was at least questionable. Oh, and ChatGPT didn&#x27;t even realize that risk (cash and equivilants on hand devided by burn rate per year is simple maths), or repeat the <i>exact</i> passage in which the SEC filling said that the survival of the reporting was in doubt.<p>In short, without some <i>serious</i> promp working, and including addditional data sources, I think ChatGPT is utterly useless in analyzing SEC filings, even worse it can be outright misleading. Not that SEC filings are increadibly hard to read, some basic financial knowledge and someone pointing out the highlights, based on a basic unserstanding of how those filongs actually work are supossed to work, and you are there.</div><br/><div id="36968119" class="c"><input type="checkbox" id="c-36968119" checked=""/><div class="controls bullet"><span class="by">nnechm</span><span>|</span><a href="#36967206">root</a><span>|</span><a href="#36967898">parent</a><span>|</span><a href="#36967264">next</a><span>|</span><label class="collapse" for="c-36968119">[-]</label><label class="expand" for="c-36968119">[1 more]</label></div><br/><div class="children"><div class="content">I do not really imagine this as something that does all the investment work and makes a decision.<p>Instead, the mental model is you have an army of people who can read texts really well, as in &#x27;reading comprehension&#x27; as they call it in english tests...  This army can get you information on the fly.<p>Investment research involves a lot of back and forth reading and fetching tables and making conclusions, which in turn might not have much to do with stock price performance, but there&#x27;s a whole industry of financial information and news for that :)<p>So currently, the scope is to make widely available information beyond what FactSet and CapIQ offer and even that&#x27;s a long way away :)</div><br/></div></div></div></div><div id="36967264" class="c"><input type="checkbox" id="c-36967264" checked=""/><div class="controls bullet"><span class="by">drited</span><span>|</span><a href="#36967206">parent</a><span>|</span><a href="#36967898">prev</a><span>|</span><a href="#36967635">next</a><span>|</span><label class="collapse" for="c-36967264">[-]</label><label class="expand" for="c-36967264">[2 more]</label></div><br/><div class="children"><div class="content">One of the advantages of data from CapIQ &#x2F;Refinitiv is that you&#x27;re not just pulling data from a single report but rather data has been curated across time from multiple historical reports so that historical income statements, balance sheets, footnote data etc spanning many years can be generated.<p>When you say that generating graphs of gross margin, EV&#x2F;Ebitda is just one step further, are you talking about generating those based in just a single report&#x27;s information or are you combining information from multiple years to for example show gross margin trends over 10 years and EV&#x2F;TTM Ebitda?</div><br/><div id="36967344" class="c"><input type="checkbox" id="c-36967344" checked=""/><div class="controls bullet"><span class="by">nnechm</span><span>|</span><a href="#36967206">root</a><span>|</span><a href="#36967264">parent</a><span>|</span><a href="#36967635">next</a><span>|</span><label class="collapse" for="c-36967344">[-]</label><label class="expand" for="c-36967344">[1 more]</label></div><br/><div class="children"><div class="content">I am talking about comparing multiple reports, i.e gross margin trends over 10 years and EV&#x2F;TTM Ebitda etc across several reports. Currently only financials are possible, but the ratios depend on stock prices, so we are working on that !<p>You can think of it like this, you now have an army of readers that can go through tables really quickly.<p>FactSet, CapIQ etc use a combination of automation&#x2F;manual entry and fit these tables into a homogenized schema so that they can be saved, compared etc. So if you want to get Apple&#x27;s Greater China sales from 2020, you would be lucky if they decided to create an item for that. <a href="https:&#x2F;&#x2F;imgur.com&#x2F;a&#x2F;bp2hb7n" rel="nofollow noreferrer">https:&#x2F;&#x2F;imgur.com&#x2F;a&#x2F;bp2hb7n</a><p>Here are two examples, AMD&#x27;s revenues and AMD&#x27;s revenue outlook using beatandraise.com
<a href="https:&#x2F;&#x2F;imgur.com&#x2F;a&#x2F;61jqiUk" rel="nofollow noreferrer">https:&#x2F;&#x2F;imgur.com&#x2F;a&#x2F;61jqiUk</a>
I doubt you can get AMD&#x27;s own outlook on CapIQ for e.g<p>Context sizes mean getting 100s of reports on one call is not possible, but multiple iterations will still do the trick. So in effect, you can actually create a dataset like FactSet for a lot lower cost, more comprehensive and can be customized to what the user wants, if you see my point... :)</div><br/></div></div></div></div><div id="36967635" class="c"><input type="checkbox" id="c-36967635" checked=""/><div class="controls bullet"><span class="by">lifeisstillgood</span><span>|</span><a href="#36967206">parent</a><span>|</span><a href="#36967264">prev</a><span>|</span><a href="#36967295">next</a><span>|</span><label class="collapse" for="c-36967635">[-]</label><label class="expand" for="c-36967635">[2 more]</label></div><br/><div class="children"><div class="content">So (if I get it right) you are using the LLM to convert the human language question into (presumably) code that is basis for running &quot;normal&quot; searches and returning text.<p>Avoiding any fears of hallucinations.<p>But earlier you say &quot;LLMs will get better at comprehension&quot;.  So are you using an LLM to markup the original text in some way ?</div><br/><div id="36967714" class="c"><input type="checkbox" id="c-36967714" checked=""/><div class="controls bullet"><span class="by">nnechm</span><span>|</span><a href="#36967206">root</a><span>|</span><a href="#36967635">parent</a><span>|</span><a href="#36967295">next</a><span>|</span><label class="collapse" for="c-36967714">[-]</label><label class="expand" for="c-36967714">[1 more]</label></div><br/><div class="children"><div class="content">Yes, that&#x27;s right, I avoid hallucinations that way. In addition, I mark up existing texts so that the LLM knows what it is reading even if it is a piece of a larger text, so for e.g if you need to get Apple&#x27;s Greater China sales for each quarter in 2020... <a href="https:&#x2F;&#x2F;imgur.com&#x2F;a&#x2F;oCCay3o" rel="nofollow noreferrer">https:&#x2F;&#x2F;imgur.com&#x2F;a&#x2F;oCCay3o</a><p>I am not making 4 calls with the entire text, I instead get pieces of each which would best match the question. 
There are additional challenges, for instance, GPT4 struggles to know the difference between the words guidance and outlook, which mean the same thing but somehow they don&#x27;t for GPT4.<p>When I say they become better readers, I meant it in a general sense as in better in the case above. You basically have someone who can read through tables really well, and that can change investment research fundamentally, which is a lot of reading tables and graphs :)</div><br/></div></div></div></div><div id="36967295" class="c"><input type="checkbox" id="c-36967295" checked=""/><div class="controls bullet"><span class="by">cerved</span><span>|</span><a href="#36967206">parent</a><span>|</span><a href="#36967635">prev</a><span>|</span><a href="#36968437">next</a><span>|</span><label class="collapse" for="c-36967295">[-]</label><label class="expand" for="c-36967295">[8 more]</label></div><br/><div class="children"><div class="content">Neat idea!<p>How do you parse the PDFs?</div><br/><div id="36968115" class="c"><input type="checkbox" id="c-36968115" checked=""/><div class="controls bullet"><span class="by">yawnxyz</span><span>|</span><a href="#36967206">root</a><span>|</span><a href="#36967295">parent</a><span>|</span><a href="#36967436">next</a><span>|</span><label class="collapse" for="c-36968115">[-]</label><label class="expand" for="c-36968115">[2 more]</label></div><br/><div class="children"><div class="content">I have a tool that applies LLMs to abstracts and research papers â @opendocsg&#x2F;pdf2md on Node &#x2F; Sveltekit has been really good for me</div><br/><div id="36968128" class="c"><input type="checkbox" id="c-36968128" checked=""/><div class="controls bullet"><span class="by">nnechm</span><span>|</span><a href="#36967206">root</a><span>|</span><a href="#36968115">parent</a><span>|</span><a href="#36967436">next</a><span>|</span><label class="collapse" for="c-36968128">[-]</label><label class="expand" for="c-36968128">[1 more]</label></div><br/><div class="children"><div class="content">Thanks ! It&#x27;s really interesting to see how LLMs have now brought back projects that were last updated years ago back into the limelight :)</div><br/></div></div></div></div><div id="36967436" class="c"><input type="checkbox" id="c-36967436" checked=""/><div class="controls bullet"><span class="by">nnechm</span><span>|</span><a href="#36967206">root</a><span>|</span><a href="#36967295">parent</a><span>|</span><a href="#36968115">prev</a><span>|</span><a href="#36967401">next</a><span>|</span><label class="collapse" for="c-36967436">[-]</label><label class="expand" for="c-36967436">[3 more]</label></div><br/><div class="children"><div class="content">Pdf parsing was more tedious that I would have liked at this stage so I stuck to the SEC which requires that companies file in a text format :) so that helped.<p>I used poppler on a digital ocean droplet, but the sheer variety of company pdfs especially european companies, some of which have to be OCRed, meant results were not really uniform. GPT still does very well, but not as well as on text documents directly. So in short, this is next on the list...</div><br/><div id="36968605" class="c"><input type="checkbox" id="c-36968605" checked=""/><div class="controls bullet"><span class="by">andylynch</span><span>|</span><a href="#36967206">root</a><span>|</span><a href="#36967436">parent</a><span>|</span><a href="#36967401">next</a><span>|</span><label class="collapse" for="c-36968605">[-]</label><label class="expand" for="c-36968605">[2 more]</label></div><br/><div class="children"><div class="content">Are you pulling out the inline XBRL or taking a different approach?   I&#x27;m curious to hear others&#x27; practical experience with it good or bad.</div><br/><div id="36968612" class="c"><input type="checkbox" id="c-36968612" checked=""/><div class="controls bullet"><span class="by">nnechm</span><span>|</span><a href="#36967206">root</a><span>|</span><a href="#36968605">parent</a><span>|</span><a href="#36967401">next</a><span>|</span><label class="collapse" for="c-36968612">[-]</label><label class="expand" for="c-36968612">[1 more]</label></div><br/><div class="children"><div class="content">I am not using inline XBRL, instead relying on gpt&#x27;s ability to read tables.</div><br/></div></div></div></div></div></div><div id="36967401" class="c"><input type="checkbox" id="c-36967401" checked=""/><div class="controls bullet"><span class="by">petarb</span><span>|</span><a href="#36967206">root</a><span>|</span><a href="#36967295">parent</a><span>|</span><a href="#36967436">prev</a><span>|</span><a href="#36968437">next</a><span>|</span><label class="collapse" for="c-36967401">[-]</label><label class="expand" for="c-36967401">[2 more]</label></div><br/><div class="children"><div class="content">Apache Tika has worked well for me in the past, ended up running it on an AWS Lambda<p><a href="https:&#x2F;&#x2F;tika.apache.org&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;tika.apache.org&#x2F;</a></div><br/><div id="36967438" class="c"><input type="checkbox" id="c-36967438" checked=""/><div class="controls bullet"><span class="by">nnechm</span><span>|</span><a href="#36967206">root</a><span>|</span><a href="#36967401">parent</a><span>|</span><a href="#36968437">next</a><span>|</span><label class="collapse" for="c-36967438">[-]</label><label class="expand" for="c-36967438">[1 more]</label></div><br/><div class="children"><div class="content">Thanks, will try that.</div><br/></div></div></div></div></div></div></div></div><div id="36968437" class="c"><input type="checkbox" id="c-36968437" checked=""/><div class="controls bullet"><span class="by">halotrope</span><span>|</span><a href="#36967206">prev</a><span>|</span><label class="collapse" for="c-36968437">[-]</label><label class="expand" for="c-36968437">[3 more]</label></div><br/><div class="children"><div class="content">This looks great! We have a similar tool on <a href="https:&#x2F;&#x2F;markets.sh" rel="nofollow noreferrer">https:&#x2F;&#x2F;markets.sh</a> but more geared towards news and general information about stocks (You can ask e.g &quot;What are the current issues with the Disney company?&quot;)<p>We found the hardest part about this is the pre-ranking of sections and finding the relevant information. Do you feed the whole report into OpenAI?</div><br/><div id="36968576" class="c"><input type="checkbox" id="c-36968576" checked=""/><div class="controls bullet"><span class="by">nnechm</span><span>|</span><a href="#36968437">parent</a><span>|</span><label class="collapse" for="c-36968576">[-]</label><label class="expand" for="c-36968576">[2 more]</label></div><br/><div class="children"><div class="content">Thanks, I don&#x27;t feed the whole report in, unless necessary. Context size is a real limiting factor :), so you need to split it up into chunks that are meaningful on their own and find those relevant to the question. 
In this case, what are the current issues with the Disney company, This is how I would do it :) I get all the news articles related to Disney, this would then have  sections (depends if you are using a json or a scraper), now you would then need to pick only those chunks and the surrounding ones (this would be an on the fly search) and then pass it to openai...  This one is a very open ended question, this is what I get in beatandraise.com :)
<a href="https:&#x2F;&#x2F;imgur.com&#x2F;a&#x2F;dqmcrRA" rel="nofollow noreferrer">https:&#x2F;&#x2F;imgur.com&#x2F;a&#x2F;dqmcrRA</a></div><br/><div id="36968590" class="c"><input type="checkbox" id="c-36968590" checked=""/><div class="controls bullet"><span class="by">nnechm</span><span>|</span><a href="#36968437">root</a><span>|</span><a href="#36968576">parent</a><span>|</span><label class="collapse" for="c-36968590">[-]</label><label class="expand" for="c-36968590">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t do handle news articles, and was just focusing on filings, so my answer would look for a filing. That&#x27;s why it looks the way it does :)</div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>