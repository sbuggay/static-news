<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1688720460405" as="style"/><link rel="stylesheet" href="styles.css?v=1688720460405"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://owen.cafe/posts/six-times-faster-than-c/">{n} times faster than C</a> <span class="domain">(<a href="https://owen.cafe">owen.cafe</a>)</span></div><div class="subtext"><span>414owen</span> | <span>166 comments</span></div><br/><div><div id="36622891" class="c"><input type="checkbox" id="c-36622891" checked=""/><div class="controls bullet"><span class="by">torstenvl</span><span>|</span><a href="#36623262">next</a><span>|</span><label class="collapse" for="c-36622891">[-]</label><label class="expand" for="c-36622891">[63 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not so sure that the right take-away is &quot;hand-written assembler is 6x faster than C.&quot; It&#x27;s more like &quot;jumps are a lot slower than conditional arithmetic.&quot; And that can [edit:often] be achieved easily in C by simply not using switch statements when an if statement or two will work fine.<p>Rewriting the C function as follows got a 5.5x speedup:<p><pre><code>    int run_switches(char *input) {
        int r = 0;
        char c; 
        while (1) {
            c = *input++;
            if (c == &#x27;s&#x27;) r++;
            if (c == &#x27;p&#x27;) r--;
            if (c == &#x27;\0&#x27;) break;
        }
        return r;
    }
</code></pre>
Results:<p><pre><code>    [16:50:14 user@boxer ~&#x2F;looptest] $ gcc -O3 bench.c loop1.c -o lone
    [16:50:37 user@boxer ~&#x2F;looptest] $ gcc -O3 bench.c loop2.c -o ltwo
    [16:50:47 user@boxer ~&#x2F;looptest] $ time .&#x2F;lone 1000 1
    449000
    .&#x2F;lone 1000 1  3.58s user 0.00s system 99% cpu 3.589 total
    [16:50:57 user@boxer ~&#x2F;looptest] $ time .&#x2F;ltwo 1000 1
    449000
    .&#x2F;ltwo 1000 1  0.65s user 0.00s system 99% cpu 0.658 total</code></pre></div><br/><div id="36623958" class="c"><input type="checkbox" id="c-36623958" checked=""/><div class="controls bullet"><span class="by">414owen</span><span>|</span><a href="#36622891">parent</a><span>|</span><a href="#36623708">next</a><span>|</span><label class="collapse" for="c-36623958">[-]</label><label class="expand" for="c-36623958">[13 more]</label></div><br/><div class="children"><div class="content">Nice! There&#x27;s a part two in which I rewrote the C. I got a 12x speedup :)<p><a href="https:&#x2F;&#x2F;owen.cafe&#x2F;posts&#x2F;the-same-speed-as-c&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;owen.cafe&#x2F;posts&#x2F;the-same-speed-as-c&#x2F;</a><p>And as others have pointed out, you can tweak the input, then vectorize the algo, if you want to go that route.<p>I considered this a pedagogical exercise and I sincerely hope nobody will start dropping down to assembly without a very good reason to.</div><br/><div id="36625534" class="c"><input type="checkbox" id="c-36625534" checked=""/><div class="controls bullet"><span class="by">sriku</span><span>|</span><a href="#36622891">root</a><span>|</span><a href="#36623958">parent</a><span>|</span><a href="#36625198">next</a><span>|</span><label class="collapse" for="c-36625534">[-]</label><label class="expand" for="c-36625534">[7 more]</label></div><br/><div class="children"><div class="content">Wondering how res += (c==&#x27;s&#x27;)-(c==&#x27;p&#x27;) might do. I sure there is some C undefined behaviour relevant there. Curious but too lazy to check it myself!</div><br/><div id="36626053" class="c"><input type="checkbox" id="c-36626053" checked=""/><div class="controls bullet"><span class="by">Tempest1981</span><span>|</span><a href="#36622891">root</a><span>|</span><a href="#36625534">parent</a><span>|</span><a href="#36627419">next</a><span>|</span><label class="collapse" for="c-36626053">[-]</label><label class="expand" for="c-36626053">[3 more]</label></div><br/><div class="children"><div class="content">While `false` evaluates to 0, not sure `true` always evaluate to 1 in C... maybe compiler dependent. Maybe add `? 1 : 0`</div><br/><div id="36626585" class="c"><input type="checkbox" id="c-36626585" checked=""/><div class="controls bullet"><span class="by">ladberg</span><span>|</span><a href="#36622891">root</a><span>|</span><a href="#36626053">parent</a><span>|</span><a href="#36626653">next</a><span>|</span><label class="collapse" for="c-36626585">[-]</label><label class="expand" for="c-36626585">[1 more]</label></div><br/><div class="children"><div class="content">C doesn&#x27;t even originally have true&#x2F;false, I think you may be conflating the two concepts that &quot;any nonzero int is truthy&quot; and &quot;boolean expressions evaluate to ints&quot;. The standard mandates that boolean expressions like equality always evaluate to 0&#x2F;1.</div><br/></div></div><div id="36626653" class="c"><input type="checkbox" id="c-36626653" checked=""/><div class="controls bullet"><span class="by">loeg</span><span>|</span><a href="#36622891">root</a><span>|</span><a href="#36626053">parent</a><span>|</span><a href="#36626585">prev</a><span>|</span><a href="#36627419">next</a><span>|</span><label class="collapse" for="c-36626653">[-]</label><label class="expand" for="c-36626653">[1 more]</label></div><br/><div class="children"><div class="content">The `true` constant is always 1. C11 §7.18 (3):<p>&gt; true which expands to the integer constant 1,<p>And equality yields a 1 or 0. C11 §6.5.9 (3):<p>&gt; The == (equal to) and != (not equal to) operators are analogous to the relational operators except for their lower precedence. Each of the operators yields 1 if the specified relation is true and 0 if it is false.</div><br/></div></div></div></div><div id="36627419" class="c"><input type="checkbox" id="c-36627419" checked=""/><div class="controls bullet"><span class="by">romnon</span><span>|</span><a href="#36622891">root</a><span>|</span><a href="#36625534">parent</a><span>|</span><a href="#36626053">prev</a><span>|</span><a href="#36625198">next</a><span>|</span><label class="collapse" for="c-36627419">[-]</label><label class="expand" for="c-36627419">[3 more]</label></div><br/><div class="children"><div class="content">ive seen people doing += !!(c==&#x27;s&#x27;)-!!(c==&#x27;p&#x27;) for that</div><br/><div id="36628481" class="c"><input type="checkbox" id="c-36628481" checked=""/><div class="controls bullet"><span class="by">sweetjuly</span><span>|</span><a href="#36622891">root</a><span>|</span><a href="#36627419">parent</a><span>|</span><a href="#36628420">next</a><span>|</span><label class="collapse" for="c-36628481">[-]</label><label class="expand" for="c-36628481">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m sure people do that (even though it&#x27;s not necessary per some year C standard) but generally the pattern is actually for converting things which are not <i>already</i> 0 or 1 <i>into</i> 0 or 1. For example, you might want to use it here:<p><pre><code>    int num_empty_strings = !!(strlen(s1)) + !!(strlen(s2)) + !!(strlen(s3))
</code></pre>
which is equivalent to:<p><pre><code>    int num_empty_strings = (strlen(s1) != 0) + (strlen(s2) != 0) + (strlen(s3) != 0)
</code></pre>
Which you use is really a matter of coding style.</div><br/></div></div><div id="36628420" class="c"><input type="checkbox" id="c-36628420" checked=""/><div class="controls bullet"><span class="by">simonkagedal</span><span>|</span><a href="#36622891">root</a><span>|</span><a href="#36627419">parent</a><span>|</span><a href="#36628481">prev</a><span>|</span><a href="#36625198">next</a><span>|</span><label class="collapse" for="c-36628420">[-]</label><label class="expand" for="c-36628420">[1 more]</label></div><br/><div class="children"><div class="content">That is entirely unneccessary. An == expression will always evaluate to 1 or 0. The !!x trick can be useful in some other situations, though.<p>Here’s a thing you could do (but I don’t know why):<p>+= !(c-’s’) - !(c-’p’)</div><br/></div></div></div></div></div></div><div id="36625198" class="c"><input type="checkbox" id="c-36625198" checked=""/><div class="controls bullet"><span class="by">JohnMakin</span><span>|</span><a href="#36622891">root</a><span>|</span><a href="#36623958">parent</a><span>|</span><a href="#36625534">prev</a><span>|</span><a href="#36623708">next</a><span>|</span><label class="collapse" for="c-36625198">[-]</label><label class="expand" for="c-36625198">[5 more]</label></div><br/><div class="children"><div class="content">Thank you for your post and reply but I fear with a post + title like this you may just be chumming the waters.</div><br/><div id="36625328" class="c"><input type="checkbox" id="c-36625328" checked=""/><div class="controls bullet"><span class="by">jdsalaro</span><span>|</span><a href="#36622891">root</a><span>|</span><a href="#36625198">parent</a><span>|</span><a href="#36623708">next</a><span>|</span><label class="collapse" for="c-36625328">[-]</label><label class="expand" for="c-36625328">[4 more]</label></div><br/><div class="children"><div class="content">What do you mean by &quot;chumming the waters&quot; in this context?</div><br/><div id="36625393" class="c"><input type="checkbox" id="c-36625393" checked=""/><div class="controls bullet"><span class="by">bombcar</span><span>|</span><a href="#36622891">root</a><span>|</span><a href="#36625328">parent</a><span>|</span><a href="#36625365">next</a><span>|</span><label class="collapse" for="c-36625393">[-]</label><label class="expand" for="c-36625393">[2 more]</label></div><br/><div class="children"><div class="content">People who just skim the headline and article will come away convinced that dropping to assembly is the “way to go fast” even if they never actually do it.</div><br/><div id="36626015" class="c"><input type="checkbox" id="c-36626015" checked=""/><div class="controls bullet"><span class="by">sh34r</span><span>|</span><a href="#36622891">root</a><span>|</span><a href="#36625393">parent</a><span>|</span><a href="#36625365">next</a><span>|</span><label class="collapse" for="c-36626015">[-]</label><label class="expand" for="c-36626015">[1 more]</label></div><br/><div class="children"><div class="content">Anyone with a passing understanding of Assembly or compilers would find that idea laughable. As for the others, it turns out not knowing what you don’t know can be very expensive.</div><br/></div></div></div></div><div id="36625365" class="c"><input type="checkbox" id="c-36625365" checked=""/><div class="controls bullet"><span class="by">mayli</span><span>|</span><a href="#36622891">root</a><span>|</span><a href="#36625328">parent</a><span>|</span><a href="#36625393">prev</a><span>|</span><a href="#36623708">next</a><span>|</span><label class="collapse" for="c-36625365">[-]</label><label class="expand" for="c-36625365">[1 more]</label></div><br/><div class="children"><div class="content">&quot;Clickbait&quot;</div><br/></div></div></div></div></div></div></div></div><div id="36623708" class="c"><input type="checkbox" id="c-36623708" checked=""/><div class="controls bullet"><span class="by">haberman</span><span>|</span><a href="#36622891">parent</a><span>|</span><a href="#36623958">prev</a><span>|</span><a href="#36628710">next</a><span>|</span><label class="collapse" for="c-36623708">[-]</label><label class="expand" for="c-36623708">[30 more]</label></div><br/><div class="children"><div class="content">&gt; jumps are a lot slower than conditional arithmetic.<p>This statement is true <i>if</i> the jumps are unpredictable.  If the jumps are predictable, then jumps will be faster.<p>Linus had a whole rant about this back in the day, arguing that cmov is not useful if branches are predictable: <a href="https:&#x2F;&#x2F;yarchive.net&#x2F;comp&#x2F;linux&#x2F;cmov.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;yarchive.net&#x2F;comp&#x2F;linux&#x2F;cmov.html</a></div><br/><div id="36624031" class="c"><input type="checkbox" id="c-36624031" checked=""/><div class="controls bullet"><span class="by">torstenvl</span><span>|</span><a href="#36622891">root</a><span>|</span><a href="#36623708">parent</a><span>|</span><a href="#36627280">next</a><span>|</span><label class="collapse" for="c-36624031">[-]</label><label class="expand" for="c-36624031">[27 more]</label></div><br/><div class="children"><div class="content">I haven&#x27;t run any benchmarks, but jump-if-equal and set-if-equal would seem to have the same level of predictability.<p>My naive, untested intuition is that there&#x27;s only one meaningful difference: the former has to dump the entire pipeline on a miss, and the latter only has to nop a single instruction on a miss.<p>But maybe I&#x27;m missing something. I&#x27;ll re-read his rant.<p>EDIT:<p>Linus rants a lot, but makes one concrete claim:<p><pre><code>    You can always replace it by
    
      j&lt;negated condition&gt; forward
      mov ..., %reg
     forward:
    
    and assuming the branch is AT ALL predictable (and 95+% of all branches
    are), *the branch-over will actually be a LOT better for a CPU.*
</code></pre>
So, I decided to test that.<p><pre><code>    [18:50:14 user@boxer ~&#x2F;src&#x2F;looptest] $ diff -u loop2.s loop4.s
    --- loop2.s 2023-07-06 18:40:11.000000000 -0400
    +++ loop4.s 2023-07-06 18:46:58.000000000 -0400
    @@ -17,11 +17,15 @@
      incq %rdi
      xorl %edx, %edx
      cmpb $115, %cl
    - sete %dl
    + jne _run_switches_jmptgt1
    + mov $1,   %dl
    +_run_switches_jmptgt1:  
      addl %edx, %eax
      xorl %edx, %edx
      cmpb $112, %cl
    - sete %dl
    + jne _run_switches_jmptgt2
    + mov $1,   %dl
    +_run_switches_jmptgt2:  
      subl %edx, %eax
      testb %cl, %cl
      jne LBB0_1
    [18:50:29 user@boxer ~&#x2F;src&#x2F;looptest] $ gcc -O3 bench.c loop2.s -o l2
    [18:50:57 user@boxer ~&#x2F;src&#x2F;looptest] $ gcc -O3 bench.c loop4.s -o l4
    [18:51:02 user@boxer ~&#x2F;src&#x2F;looptest] $ time .&#x2F;l2 1000 1
    449000
    .&#x2F;l2 1000 1  0.69s user 0.00s system 99% cpu 0.697 total
    [18:51:09 user@boxer ~&#x2F;src&#x2F;looptest] $ time .&#x2F;l4 1000 1
    449000
    .&#x2F;l4 1000 1  4.53s user 0.01s system 99% cpu 4.542 total
</code></pre>
I feel pretty confident that Linus has made a poor prediction about poor prediction here. Jumps are indeed slower.<p>To be fair to Linus, since Clang and I are using sete here, not cmov, I also tested cmov, and the difference was insignificant:<p><pre><code>    [19:53:12 user@boxer ~&#x2F;src&#x2F;looptest] $ time .&#x2F;l2 1000 1            
    449000
    .&#x2F;l2 1000 1  0.69s user 0.00s system 99% cpu 0.700 total
    [19:53:15 user@boxer ~&#x2F;src&#x2F;looptest] $ time .&#x2F;l5 1000 1            
    449000
    .&#x2F;l5 1000 1  0.68s user 0.00s system 99% cpu 0.683 total
</code></pre>
Jumps are slower.</div><br/><div id="36624254" class="c"><input type="checkbox" id="c-36624254" checked=""/><div class="controls bullet"><span class="by">haberman</span><span>|</span><a href="#36622891">root</a><span>|</span><a href="#36624031">parent</a><span>|</span><a href="#36626003">next</a><span>|</span><label class="collapse" for="c-36624254">[-]</label><label class="expand" for="c-36624254">[16 more]</label></div><br/><div class="children"><div class="content">&gt; jump-if-equal and set-if-equal would seem to have the same level of predictability.<p>The difference is that branches have dedicated hardware (branch predictors) that will speculatively execute subsequent instructions based on their best guess about which way the branch will go.  Whereas conditional moves cannot execute any subsequent instructions until the correct value is available.<p>Put another way, CPUs have control flow speculation, but not conditional move speculation.  I don&#x27;t know if conditional move speculation would be a feasible thing to implement or not, but I&#x27;m pretty sure that no mainstream CPUs have such a feature.</div><br/><div id="36625582" class="c"><input type="checkbox" id="c-36625582" checked=""/><div class="controls bullet"><span class="by">bjourne</span><span>|</span><a href="#36622891">root</a><span>|</span><a href="#36624254">parent</a><span>|</span><a href="#36625103">next</a><span>|</span><label class="collapse" for="c-36625582">[-]</label><label class="expand" for="c-36625582">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Whereas conditional moves cannot execute any subsequent instructions until the correct value is available.<p>That is incorrect. Super-scalar processors have no problem executing subsequent instructions before the cmov writebacks. However, the register cmov writes to can of course not be read before cmov has has passed the execution unit. But that&#x27;s not different from other arithmetic instructions.</div><br/><div id="36627524" class="c"><input type="checkbox" id="c-36627524" checked=""/><div class="controls bullet"><span class="by">haberman</span><span>|</span><a href="#36622891">root</a><span>|</span><a href="#36625582">parent</a><span>|</span><a href="#36625103">next</a><span>|</span><label class="collapse" for="c-36627524">[-]</label><label class="expand" for="c-36627524">[1 more]</label></div><br/><div class="children"><div class="content">You are correct, I should have clarified, subsequent instructions <i>that depend on the result of the cmov</i> cannot execute until the cmov has executed.  Whereas subsequent instructions <i>that depend on the result of the branch instruction</i> can be speculatively executed even before the branch conditional has been evaluated.</div><br/></div></div></div></div><div id="36625103" class="c"><input type="checkbox" id="c-36625103" checked=""/><div class="controls bullet"><span class="by">Lk7Of3vfJS2n</span><span>|</span><a href="#36622891">root</a><span>|</span><a href="#36624254">parent</a><span>|</span><a href="#36625582">prev</a><span>|</span><a href="#36626003">next</a><span>|</span><label class="collapse" for="c-36625103">[-]</label><label class="expand" for="c-36625103">[13 more]</label></div><br/><div class="children"><div class="content">I&#x27;d be curious to learn why CPUs don&#x27;t have conditional move speculation.</div><br/><div id="36625358" class="c"><input type="checkbox" id="c-36625358" checked=""/><div class="controls bullet"><span class="by">Tuna-Fish</span><span>|</span><a href="#36622891">root</a><span>|</span><a href="#36625103">parent</a><span>|</span><a href="#36626867">next</a><span>|</span><label class="collapse" for="c-36625358">[-]</label><label class="expand" for="c-36625358">[8 more]</label></div><br/><div class="children"><div class="content">Because modern CPUs as a rule don&#x27;t speculate on values to arithmetic, only on control flow, and CMOV acts like arithmetic.<p>That is, if there is an add instruction on rax and rbx, no matter what, the add instruction will not execute until both rbx and rbx are available. If the result went into rax, and there is an another instruction that uses that as a source, no matter what that instruction will not execute until the add has completed.<p>CMOV is implemented as an ALU instruction that always writes into it&#x27;s output, and either writes the value that is already in there (which is why it depends on the value of it&#x27;s output) or the value provided, depending on flags.</div><br/><div id="36626418" class="c"><input type="checkbox" id="c-36626418" checked=""/><div class="controls bullet"><span class="by">torstenvl</span><span>|</span><a href="#36622891">root</a><span>|</span><a href="#36625358">parent</a><span>|</span><a href="#36626255">next</a><span>|</span><label class="collapse" for="c-36626418">[-]</label><label class="expand" for="c-36626418">[5 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not saying you&#x27;re wrong — I&#x27;m completely ignorant at the microcode level — but it seems to me like between<p><pre><code>    cmp x, y
    je z
</code></pre>
and<p><pre><code>    cmp x, y
    sete z
</code></pre>
the actual speculative part is the same: speculating as to the result of cmp x, y<p>If that&#x27;s true, why would it not simply pipeline sete and the following instructions and simply execute (or not execute) sete according to its prediction, and then double check itself and reverse (or apply) the operation if the prediction was wrong?<p>I probably just have a bad mental model of what&#x27;s going on under the (under the) hood, so whatever patience you have to deal with my stupid questions would be greatly appreciated.</div><br/><div id="36629029" class="c"><input type="checkbox" id="c-36629029" checked=""/><div class="controls bullet"><span class="by">ithkuil</span><span>|</span><a href="#36622891">root</a><span>|</span><a href="#36626418">parent</a><span>|</span><a href="#36626836">next</a><span>|</span><label class="collapse" for="c-36629029">[-]</label><label class="expand" for="c-36629029">[1 more]</label></div><br/><div class="children"><div class="content">The purpose of control flow speculation is to avoid stalling the pipeline.<p>If each instruction was executed in one single clock cycle, the cost of executing a branch would be one cycle and that&#x27;s it.<p>However since there is a maximum speed at which operations can happen in hardware, the period of such a clock cycle that can execute a whole instruction would be very long and so the amount of &quot;instructions per second&quot; the CPU could execute would be low.<p>Now, if you can break up each instruction in smaller steps and execute the smaller steps in an overlapping manner, such that while you&#x27;re executing the second step of the first instruction you&#x27;re executing the first step of the next instruction and so on (like on an assembly line in a factory) you can have a much shorter clock period for each of these steps, and at the end of each clock tick an instruction would complete execution. The CPU will be still running one instruction per clock cycle, but since each clock period is shorter the overall instruction per second rate will be higher.<p>But for this to work the next instruction you want to execute must be known in advance so that at each clock cycle the CPU can start step 1 of a new instruction.<p>That&#x27;s easy when the program is executing sequentially but when there are branches involved it&#x27;s more tricky.<p>And that&#x27;s tricky also if the branch is not conditional! If the instruction execution is broken into many small steps, it may take one or more steps before figuring out that you have a branch in the first place, let alone decoding where you need to branch to. In the meantime the CPU will have happily started to execute the first &quot;steps&quot; of the next instruction.<p>This is called a &quot;branch hazard&quot;<p>Early CPU implementations handled branch hazards by just throwing away the intermediate states if the few instructions that we&#x27;re half way through the pipeline and call it a day (stalling the pipeline).<p>Early RISC CPUs attempted to be clever and use a trick called &quot;delay slots&quot;: the instruction(s) already in the pipeline will continue to execute as if they were logically before the branch. This puta the onus to the programmer (or the compiler) to make sure that only instructions that are safe to be executed regardless of whether the branch is taken or not, are actually put after the branch instruction (otherwise you can just write nops).<p>But branch delay slots are not a panacea. As pipelines got deeper it became I practical to have a large number of delay slots and even a small number of delay slots were often just filled with nops anyway.<p>Improving on UNconditional branches was done by &quot;looking ahead&quot; in the instruction stream for branch instructions. When the instructions are all of the same size it&#x27;s easy to quickly look a few instructions ahead and tell when you found a branch. You also need an instruction encoding scheme that is relatively fast to decode, at the very least it should be fast to decode branches (the more complicated the logic to decode a branch is, the farther ahead you&#x27;d have to look in the instruction stream, which in turn would limit the size of the sequence of instructions you can fill your pipeline with between subsequent branches).<p>To further complicate the matter, even if you found the branch instruction and you decoded it, it doesn&#x27;t mean you yet know where it will branch to!<p>Indirect jumps (where the address is in a register) are similar to conditional jumps in that you don&#x27;t know the address you&#x27;re jumping to by merely looking ahead in the instruction stream and noticing the branch instruction. You need to either wait until you execute the branch and stall the pipeline in the meantime, or keep them in the pipeline and flush the pipeline once you know the target of the branch.<p>The next trick that CPU designers came up way before speculative execution is &quot;branch target prediction&quot;.<p>The CPU keeps a little associative memory that maps addresses of a branch instruction to branch targets. When the lookahead logic spots a branch instruction it looks in this map and gets a guess of the branch target and uses that immediately ad the next instruction so that the pipeline is kept fed with something.<p>If by the time the branch instruction is executed the guess turned out to be wrong, the pipeline is flushed in the same way it would have to be flushed anyway if we had no clever branch lookahead in the first place. But if the guess was right we paid only one cycle to execute the branch.<p>This works for indirect unconditional branches and also for conditional branches! The prediction logic can be more subtle and complicated, many many things gave been attempted but this the general idea.</div><br/></div></div><div id="36626836" class="c"><input type="checkbox" id="c-36626836" checked=""/><div class="controls bullet"><span class="by">celrod</span><span>|</span><a href="#36622891">root</a><span>|</span><a href="#36626418">parent</a><span>|</span><a href="#36629029">prev</a><span>|</span><a href="#36626255">next</a><span>|</span><label class="collapse" for="c-36626836">[-]</label><label class="expand" for="c-36626836">[3 more]</label></div><br/><div class="children"><div class="content">Taking the example:<p><pre><code>      cmpb $115, %cl
      sete %dl
      addl %edx, %eax
</code></pre>
vs<p><pre><code>      cmpb $115, %cl
      jne _run_switches_jmptgt1
      mov $1,   %dl
     _run_switches_jmptgt1:  
      addl %edx, %eax
</code></pre>
The argument about why `jne` might be faster is that that in the former case, the CPU always executes a dependency chain of length 3: `cmpb` -&gt; `sete` -&gt; `addl`. Each of these instructions have to be computed one after the other, as `sete` depends on the result of `cmpb`, and `addl` depends on the result of `sete`.<p>With `jne`, the CPU might predict the branch is not taken, in which case, the dependency chain is
`mov` -&gt; `addl` (the `mov` of an immediate might be handled by register renaming?).<p>Or that it is taken, in which case in which case the dependency chain is just `addl`.<p>I guess you&#x27;re arguing that the CPU should handle `sete` the same way?
That is, instead of treating `addl` as dependent on the result, predict what `sete` does and start executing `addl` before `sete` finishes, rewinding if that went wrong?</div><br/><div id="36627212" class="c"><input type="checkbox" id="c-36627212" checked=""/><div class="controls bullet"><span class="by">torstenvl</span><span>|</span><a href="#36622891">root</a><span>|</span><a href="#36626836">parent</a><span>|</span><a href="#36626255">next</a><span>|</span><label class="collapse" for="c-36627212">[-]</label><label class="expand" for="c-36627212">[2 more]</label></div><br/><div class="children"><div class="content">Yeah, or at least I don&#x27;t understand why that wouldn&#x27;t be possible.<p>Microcode can set the EIP register based on its prediction of what the result of cmpb $115, %cl will be.<p>Why can&#x27;t it set the EDX register based on its prediction of what the result of cmpb $115, %cl will be?</div><br/><div id="36628002" class="c"><input type="checkbox" id="c-36628002" checked=""/><div class="controls bullet"><span class="by">gpderetta</span><span>|</span><a href="#36622891">root</a><span>|</span><a href="#36627212">parent</a><span>|</span><a href="#36626255">next</a><span>|</span><label class="collapse" for="c-36628002">[-]</label><label class="expand" for="c-36628002">[1 more]</label></div><br/><div class="children"><div class="content">In principle is perfectly possible to speculatively execute cmov (and viceversa to change jump-over-one-instruction into conditional execution).<p>But Intel historically didn&#x27;t do it as programs tend to use  cmov when the condition is unpredictable , so there was little reason to optimize it.<p>After Spectre, I believe intel has given an architectural guarantee that cmov is never speculated so it can be used as part of speculation attack prevention.</div><br/></div></div></div></div></div></div></div></div><div id="36626255" class="c"><input type="checkbox" id="c-36626255" checked=""/><div class="controls bullet"><span class="by">sitkack</span><span>|</span><a href="#36622891">root</a><span>|</span><a href="#36625358">parent</a><span>|</span><a href="#36626418">prev</a><span>|</span><a href="#36626867">next</a><span>|</span><label class="collapse" for="c-36626255">[-]</label><label class="expand" for="c-36626255">[2 more]</label></div><br/><div class="children"><div class="content">I hope you work on compiler backends.</div><br/><div id="36626452" class="c"><input type="checkbox" id="c-36626452" checked=""/><div class="controls bullet"><span class="by">epcoa</span><span>|</span><a href="#36622891">root</a><span>|</span><a href="#36626255">parent</a><span>|</span><a href="#36626867">next</a><span>|</span><label class="collapse" for="c-36626452">[-]</label><label class="expand" for="c-36626452">[1 more]</label></div><br/><div class="children"><div class="content">With all due respect this is quite literally the level of stuff covered in an undergrad EE architecture course and is covered in an elementary text like Patterson and Hennessy.</div><br/></div></div></div></div></div></div><div id="36626867" class="c"><input type="checkbox" id="c-36626867" checked=""/><div class="controls bullet"><span class="by">nwallin</span><span>|</span><a href="#36622891">root</a><span>|</span><a href="#36625103">parent</a><span>|</span><a href="#36625358">prev</a><span>|</span><a href="#36628694">next</a><span>|</span><label class="collapse" for="c-36626867">[-]</label><label class="expand" for="c-36626867">[3 more]</label></div><br/><div class="children"><div class="content">Speculative execution is all about control flow. It&#x27;s about what value is in the instruction pointer at some nebulous point in the future.<p>A conditional jump can put one of two values into the instruction pointer, they will either increment the instruction pointer (jump not taken) or put the immediate value into the instruction pointer. (jump taken)<p>cmov&#x2F;sete are utterly deterministic; they always increment the instruction pointer. There&#x27;s nothing to speculate on, there&#x27;s nothing to predict. They just go to the next instruction.</div><br/><div id="36628754" class="c"><input type="checkbox" id="c-36628754" checked=""/><div class="controls bullet"><span class="by">sweetjuly</span><span>|</span><a href="#36622891">root</a><span>|</span><a href="#36626867">parent</a><span>|</span><a href="#36627049">next</a><span>|</span><label class="collapse" for="c-36628754">[-]</label><label class="expand" for="c-36628754">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Speculative execution is all about control flow<p>It&#x27;s murkier than that. Speculation also deals with the order in which instructions can be executed. Take for example memory ordering (discussed in a mini essay elsewhere here): we typically speculate that all loads are unrelated to any other older in-flight stores with unresolved addresses so that we can optimistically launch them. This is not a control flow issue but it is something we both speculate <i>and</i> predict (memory dependence predictors!) despite the next PC being essentially deterministic.</div><br/></div></div><div id="36627049" class="c"><input type="checkbox" id="c-36627049" checked=""/><div class="controls bullet"><span class="by">kazinator</span><span>|</span><a href="#36622891">root</a><span>|</span><a href="#36626867">parent</a><span>|</span><a href="#36628754">prev</a><span>|</span><a href="#36628694">next</a><span>|</span><label class="collapse" for="c-36627049">[-]</label><label class="expand" for="c-36627049">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>Speculative execution is all about control flow. It&#x27;s about what value is in the instruction pointer at some nebulous point in the future.</i><p>.. and all about what we can wheedle out of all the background speculation that will help us get root on this box.</div><br/></div></div></div></div><div id="36628694" class="c"><input type="checkbox" id="c-36628694" checked=""/><div class="controls bullet"><span class="by">sweetjuly</span><span>|</span><a href="#36622891">root</a><span>|</span><a href="#36625103">parent</a><span>|</span><a href="#36626867">prev</a><span>|</span><a href="#36626003">next</a><span>|</span><label class="collapse" for="c-36628694">[-]</label><label class="expand" for="c-36628694">[1 more]</label></div><br/><div class="children"><div class="content">One other perspective is that by speculating the outcomes of conditional instructions, you naturally open yourself up to <i>mispeculating</i> them. This sounds obvious but the consequences for the uarch are quite severe. This is because anytime you mispeculate an instruction, most (all?) contemporary CPUs throw out all younger speculative progress (even if it is unrelated!) and restart at the instruction it originally mispeculated. Throwing out all this work is both i) a waste of power&#x2F;cycles (you did all this speculative work for nothing!) and ii) quite an expensive operation because you either have to iteratively rollback the state (slow!) or take a snapshot the state on every conditional instruction (expensive from power&#x2F;area perspective).<p>A similar idea to what you&#x27;re proposing (and a possible solution to the above issue) does come up in another part of the processor however! Specifically, high performance processors launch loads very aggressively and often times return data as soon as the address is known. This is because memory is often the bottleneck for performance. This, unfortunately, has some challenges. Namely, memory ordering violations. Take for example the following snippet (ARMv8):<p><pre><code>    mov x1, #1    
    udiv x3, x2, x1
    str x2, [x3]
    ldr x4, [x2]
    add x5, x4, x4
</code></pre>
This is a silly and somewhat contrived code sequence, but note here that both str x2 and ldr x4 access the same address and thus the value in x4 should be x2. Note, however, that since str x2&#x27;s address (x3) is produced by a slow division operation but ldr x4&#x27;s address (x2) is available much more quickly, ldr x4 likely will launch before the CPU even knows that str x2 conflicts with it. Thus, the data returned by the load will be whatever random old stale data is in the cache rather than the correct value that is currently sitting in x2. This means that the subsequent add which consumes this data will produce an incorrect value, leading the whole program to derail. Once the CPU detects this issue, it has to throw away all the state and restart execution of the program at ldr x4 in order to fix its mistake and fix up the memory ordering violation. In essence, the CPU is speculating that str x2 and ldr x4 are unrelated because doing so is very important for performance. Unfortunately, however, memory ordering violations are actually somewhat common and constantly having to restart execution has negative performance implication.<p>Now, this is actually a very similar problem as we&#x27;d see with conditional instruction speculation! So how do we solve this issue for memory ordering violations? Well, we predict which pairs of stores and loads are dependent and block the load from launching until the address of its supposed dependent store resolves. If this predictor is functioning well, we are able to both aggressively launch loads while also avoiding many costly fixups!<p>So, how would we translate this to conditional instruction speculation? Well, one idea is that we could predict both whether a given instruction <i>is predictable</i> and, if so, which way we should predict it. If a conditional instruction is predicted as unpredictable, its result will not be speculated (thereby avoiding frequent costly restarts) but if it is predicted to be predictable, we can try to predict which one to take.<p>Would this work? Maybe. Will anyone actually do this? Likely not. As others have suggested, conditional instructions are almost exclusively used for hard to predict conditions <i>specifically</i> because CPUs don&#x27;t speculate them. Thus, in most existing code the predictor would just say &quot;yep can&#x27;t predict it&quot; and we&#x27;d just have ended up wasting a bunch of area and power on a predictor that never gets used.<p>If you&#x27;re really dedicated to this cause though, feel free to write a paper on it. Spitballing performance numbers is easy but often wrong in quite surprising ways, so maybe this might just work for some weird reason I&#x27;ve missed :)</div><br/></div></div></div></div></div></div><div id="36626003" class="c"><input type="checkbox" id="c-36626003" checked=""/><div class="controls bullet"><span class="by">MobiusHorizons</span><span>|</span><a href="#36622891">root</a><span>|</span><a href="#36624031">parent</a><span>|</span><a href="#36624254">prev</a><span>|</span><a href="#36624583">next</a><span>|</span><label class="collapse" for="c-36626003">[-]</label><label class="expand" for="c-36626003">[1 more]</label></div><br/><div class="children"><div class="content">Jumps are slower on completely random input. If I understand Linus’s point correctly, he is suggesting that random inputs like this are unusual (although a good way to measure worst case performance)</div><br/></div></div><div id="36624583" class="c"><input type="checkbox" id="c-36624583" checked=""/><div class="controls bullet"><span class="by">AnotherGoodName</span><span>|</span><a href="#36622891">root</a><span>|</span><a href="#36624031">parent</a><span>|</span><a href="#36626003">prev</a><span>|</span><a href="#36625542">next</a><span>|</span><label class="collapse" for="c-36624583">[-]</label><label class="expand" for="c-36624583">[5 more]</label></div><br/><div class="children"><div class="content">The inputs here are random which is the problem and why this isn&#x27;t demonstrating that. Create an input of all &#x27;s&#x27; and compare it.</div><br/><div id="36624634" class="c"><input type="checkbox" id="c-36624634" checked=""/><div class="controls bullet"><span class="by">torstenvl</span><span>|</span><a href="#36622891">root</a><span>|</span><a href="#36624583">parent</a><span>|</span><a href="#36625542">next</a><span>|</span><label class="collapse" for="c-36624634">[-]</label><label class="expand" for="c-36624634">[4 more]</label></div><br/><div class="children"><div class="content">Better than random input, but still only ~half as fast as using sete<p><pre><code>    [19:13:34 user@boxer ~&#x2F;src&#x2F;looptest] $ diff -u bench.c bench-alls.c      
    --- bench.c 2023-07-06 16:04:16.000000000 -0400
    +++ bench-alls.c 2023-07-06 19:13:34.000000000 -0400
    @@ -17,7 +17,7 @@
       int num_rand_calls = number &#x2F; CHAR_BIT + 1;
       unsigned char *buffer = malloc(num_rand_calls * CHAR_BIT);
       for (int i = 0; i &lt; num_rand_calls; i++) {
    -    buffer[i] = rand();
    +    buffer[i] = &#x27;s&#x27;; &#x2F;&#x2F;rand();
       }
       return buffer;
     }
    [19:13:37 user@boxer ~&#x2F;src&#x2F;looptest] $ gcc -O3 bench-alls.c loop2.s -o l2
    [19:13:42 user@boxer ~&#x2F;src&#x2F;looptest] $ gcc -O3 bench-alls.c loop4.s -o l4
    [19:13:47 user@boxer ~&#x2F;src&#x2F;looptest] $ time .&#x2F;l2 1000 1
    250001000
    .&#x2F;l2 1000 1  0.69s user 0.00s system 99% cpu 0.699 total
    [19:13:55 user@boxer ~&#x2F;src&#x2F;looptest] $ time .&#x2F;l4 1000 1
    250001000
    .&#x2F;l4 1000 1  1.28s user 0.00s system 99% cpu 1.290 total
</code></pre>
Jumps are slower.</div><br/><div id="36626272" class="c"><input type="checkbox" id="c-36626272" checked=""/><div class="controls bullet"><span class="by">Guvante</span><span>|</span><a href="#36622891">root</a><span>|</span><a href="#36624634">parent</a><span>|</span><a href="#36624756">next</a><span>|</span><label class="collapse" for="c-36626272">[-]</label><label class="expand" for="c-36626272">[2 more]</label></div><br/><div class="children"><div class="content">Microbenchmarks are hard. You aren&#x27;t doing any meaningful work that could benefit from speculatively executing instead of stalling for the conditional value.<p>Similarly you might be busting the pipeline by chaining together the jumps so close together.<p>Not saying your point is wrong, just saying your proof isn&#x27;t super solid.</div><br/></div></div></div></div></div></div><div id="36625542" class="c"><input type="checkbox" id="c-36625542" checked=""/><div class="controls bullet"><span class="by">seventhson</span><span>|</span><a href="#36622891">root</a><span>|</span><a href="#36624031">parent</a><span>|</span><a href="#36624583">prev</a><span>|</span><a href="#36628317">next</a><span>|</span><label class="collapse" for="c-36625542">[-]</label><label class="expand" for="c-36625542">[3 more]</label></div><br/><div class="children"><div class="content">Linus&#x27; post is 15+ years old. Much has changed in Intel hardware since then.  He was probably right on the money re the hardware available at the time.</div><br/><div id="36626528" class="c"><input type="checkbox" id="c-36626528" checked=""/><div class="controls bullet"><span class="by">torstenvl</span><span>|</span><a href="#36622891">root</a><span>|</span><a href="#36625542">parent</a><span>|</span><a href="#36628336">next</a><span>|</span><label class="collapse" for="c-36626528">[-]</label><label class="expand" for="c-36626528">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>I don&#x27;t know when the change was made, but conditional moves are fast and efficient on the last several generations of AMD and Intel processors. Usually, you are trading 1 or 2 extra cycles of latency against the chance of a ~15 cycle mispredicted branch penalty. If your branch cannot be predicted correctly ~85% of the time, this can be a significant win.</i><p><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=10749195">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=10749195</a></div><br/></div></div><div id="36628336" class="c"><input type="checkbox" id="c-36628336" checked=""/><div class="controls bullet"><span class="by">zaxomi</span><span>|</span><a href="#36622891">root</a><span>|</span><a href="#36625542">parent</a><span>|</span><a href="#36626528">prev</a><span>|</span><a href="#36628317">next</a><span>|</span><label class="collapse" for="c-36628336">[-]</label><label class="expand" for="c-36628336">[1 more]</label></div><br/><div class="children"><div class="content">I read the rant. He is talking about Pentium 4.</div><br/></div></div></div></div><div id="36628317" class="c"><input type="checkbox" id="c-36628317" checked=""/><div class="controls bullet"><span class="by">zaxomi</span><span>|</span><a href="#36622891">root</a><span>|</span><a href="#36624031">parent</a><span>|</span><a href="#36625542">prev</a><span>|</span><a href="#36627280">next</a><span>|</span><label class="collapse" for="c-36628317">[-]</label><label class="expand" for="c-36628317">[1 more]</label></div><br/><div class="children"><div class="content">Did you test this on a Pentium 4, the processor that Linus is talking about?</div><br/></div></div></div></div><div id="36627280" class="c"><input type="checkbox" id="c-36627280" checked=""/><div class="controls bullet"><span class="by">EVa5I7bHFq9mnYK</span><span>|</span><a href="#36622891">root</a><span>|</span><a href="#36623708">parent</a><span>|</span><a href="#36624031">prev</a><span>|</span><a href="#36628710">next</a><span>|</span><label class="collapse" for="c-36627280">[-]</label><label class="expand" for="c-36627280">[2 more]</label></div><br/><div class="children"><div class="content">Is this the reason I dont usually see any speed up if I eliminate array boundary checking in C#? The jump condition is almost always false, is this what &quot;predictable&quot; means?</div><br/><div id="36628044" class="c"><input type="checkbox" id="c-36628044" checked=""/><div class="controls bullet"><span class="by">gpderetta</span><span>|</span><a href="#36622891">root</a><span>|</span><a href="#36627280">parent</a><span>|</span><a href="#36628710">next</a><span>|</span><label class="collapse" for="c-36628044">[-]</label><label class="expand" for="c-36628044">[1 more]</label></div><br/><div class="children"><div class="content">Indeed.<p>The cost of bound checking is second order effects like making vectorization harder, slightly higher instruction (and possibly data) cache pressure, or requiring higher decode bandwidth. For the vast majority of programs these bottlenecks do not really matter.</div><br/></div></div></div></div></div></div><div id="36628710" class="c"><input type="checkbox" id="c-36628710" checked=""/><div class="controls bullet"><span class="by">okaleniuk</span><span>|</span><a href="#36622891">parent</a><span>|</span><a href="#36623708">prev</a><span>|</span><a href="#36623180">next</a><span>|</span><label class="collapse" for="c-36628710">[-]</label><label class="expand" for="c-36628710">[1 more]</label></div><br/><div class="children"><div class="content">Yes, but this will backfire on ARM, where jumps are as roughly fast as conditional arithmetic.<p>The whole point of using C is not to think about the underlying architecture. As soon as you start taking &quot;jumps are a lot slower than conditional arithmetic on x86&quot; into account, you&#x27;re not writing in C, you&#x27;re writing in assembly with extra steps :-)</div><br/></div></div><div id="36623180" class="c"><input type="checkbox" id="c-36623180" checked=""/><div class="controls bullet"><span class="by">BoppreH</span><span>|</span><a href="#36622891">parent</a><span>|</span><a href="#36628710">prev</a><span>|</span><a href="#36624329">next</a><span>|</span><label class="collapse" for="c-36623180">[-]</label><label class="expand" for="c-36623180">[2 more]</label></div><br/><div class="children"><div class="content">What version of GCC are you using? For me both versions perform the same, both on Ubuntu and Windows:<p><pre><code>    $ time .&#x2F;lone 1000 1
        851000

        real    0m3.578s
        user    0m3.574s
        sys     0m0.004s
        
    $ time .&#x2F;ltwo 1000 1
        851000

        real    0m3.583s
        user    0m3.583s
        sys     0m0.000s

    $ gcc --version
        gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0
        Copyright (C) 2019 Free Software Foundation, Inc.
        This is free software; see the source for copying conditions.  There is NO
        warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.</code></pre></div><br/><div id="36623280" class="c"><input type="checkbox" id="c-36623280" checked=""/><div class="controls bullet"><span class="by">torstenvl</span><span>|</span><a href="#36622891">root</a><span>|</span><a href="#36623180">parent</a><span>|</span><a href="#36624329">next</a><span>|</span><label class="collapse" for="c-36623280">[-]</label><label class="expand" for="c-36623280">[1 more]</label></div><br/><div class="children"><div class="content">Sorry, I write &#x27;gcc&#x27; purely out of force of habit.  I&#x27;m using Clang&#x2F;LLVM.<p><pre><code>    [17:23:00 user@boxer ~&#x2F;looptest] $ uname -a
    Darwin boxer.local 21.6.0 Darwin Kernel Version 21.6.0: Thu Jun  8 23:57:12 PDT 2023; root:xnu-8020.240.18.701.6~1&#x2F;RELEASE_X86_64 x86_64
    [17:23:47 user@boxer ~&#x2F;looptest] $ cc -v
    Apple clang version 14.0.0 (clang-1400.0.29.202)
    Target: x86_64-apple-darwin21.6.0
    Thread model: posix
    InstalledDir: &#x2F;Library&#x2F;Developer&#x2F;CommandLineTools&#x2F;usr&#x2F;bin
</code></pre>
Clang generates the sete instruction for me with the above code:<p><pre><code>    [17:23:49 user@boxer ~&#x2F;looptest] $ gcc -c -O3 loop2.c   
    [17:25:00 user@boxer ~&#x2F;looptest] $ objdump -d --symbolize-operands --x86-asm-syntax=intel --no-show-raw-insn loop2.o
    
    loop2.o: file format mach-o 64-bit x86-64
    
    Disassembly of section __TEXT,__text:
    
    0000000000000000 &lt;_run_switches&gt;:
           0:       push rbp
           1:       mov rbp, rsp
           4:       xor eax, eax
           6:       nop word ptr cs:[rax + rax]
    &lt;L0&gt;:
          10:       movzx ecx, byte ptr [rdi]
          13:       add rdi, 1
          17:       xor edx, edx
          19:       cmp cl, 115
          1c:       sete dl
          1f:       add eax, edx
          21:       xor edx, edx
          23:       cmp cl, 112
          26:       sete dl
          29:       sub eax, edx
          2b:       test cl, cl
          2d:       jne  &lt;L0&gt;
          2f:       pop rbp
          30:       ret</code></pre></div><br/></div></div></div></div><div id="36624329" class="c"><input type="checkbox" id="c-36624329" checked=""/><div class="controls bullet"><span class="by">p1necone</span><span>|</span><a href="#36622891">parent</a><span>|</span><a href="#36623180">prev</a><span>|</span><a href="#36623284">next</a><span>|</span><label class="collapse" for="c-36624329">[-]</label><label class="expand" for="c-36624329">[4 more]</label></div><br/><div class="children"><div class="content">Is rewriting switch statements to a bunch of ifs <i>always</i> faster? Or is there some number of cases where the switch is faster? Seems like it should be added as a compiler optimization if it&#x27;s consistent.</div><br/><div id="36628184" class="c"><input type="checkbox" id="c-36628184" checked=""/><div class="controls bullet"><span class="by">flohofwoe</span><span>|</span><a href="#36622891">root</a><span>|</span><a href="#36624329">parent</a><span>|</span><a href="#36624941">next</a><span>|</span><label class="collapse" for="c-36628184">[-]</label><label class="expand" for="c-36628184">[1 more]</label></div><br/><div class="children"><div class="content">It shouldn&#x27;t if the control flow is actually identical.<p>E.g. note how both the switch- and if-based functions generate the same code using a lookup table here:<p><a href="https:&#x2F;&#x2F;godbolt.org&#x2F;z&#x2F;qoT3M7r5G" rel="nofollow noreferrer">https:&#x2F;&#x2F;godbolt.org&#x2F;z&#x2F;qoT3M7r5G</a></div><br/></div></div><div id="36624941" class="c"><input type="checkbox" id="c-36624941" checked=""/><div class="controls bullet"><span class="by">Karellen</span><span>|</span><a href="#36622891">root</a><span>|</span><a href="#36624329">parent</a><span>|</span><a href="#36628184">prev</a><span>|</span><a href="#36623284">next</a><span>|</span><label class="collapse" for="c-36624941">[-]</label><label class="expand" for="c-36624941">[2 more]</label></div><br/><div class="children"><div class="content">It shouldn&#x27;t be.<p>If the fastest way to implement a particular `switch` in assembly is with the equivalent of a set of `if`s, a reasonably smart compiler &quot;should&quot; be able to output the assembly to do that. And I thought that gcc and clang at least have actually been smart enough to do that for a while now.<p>But if the number of `if`s is high and the distribution sufficiently dense, where a jump table is better than a bunch of `if`s, then a `switch` should output that.<p>OTOH, a sufficiently smart compiler could theoretically turn a bunch of `if`s into a `switch`-like jump table - but it&#x27;s much harder to reason that case through correctly than it is the other way, so I&#x27;m not sure any current compilers are sufficiently smart to do that.</div><br/><div id="36625306" class="c"><input type="checkbox" id="c-36625306" checked=""/><div class="controls bullet"><span class="by">kevin_thibedeau</span><span>|</span><a href="#36622891">root</a><span>|</span><a href="#36624941">parent</a><span>|</span><a href="#36623284">next</a><span>|</span><label class="collapse" for="c-36625306">[-]</label><label class="expand" for="c-36625306">[1 more]</label></div><br/><div class="children"><div class="content">On x64, GCC is supposed to use a a jump table with more than 4 cases when the cases are dense enough (gaps of 9 or less) to minimize wasted memory, otherwise it generates sequential comparisons. Testing on Godbolt, it looks like GCC 13.1 uses 10 cases as the jump table threshold for ARM64.</div><br/></div></div></div></div></div></div><div id="36623284" class="c"><input type="checkbox" id="c-36623284" checked=""/><div class="controls bullet"><span class="by">DeathArrow</span><span>|</span><a href="#36622891">parent</a><span>|</span><a href="#36624329">prev</a><span>|</span><a href="#36625110">next</a><span>|</span><label class="collapse" for="c-36623284">[-]</label><label class="expand" for="c-36623284">[10 more]</label></div><br/><div class="children"><div class="content">Shouldn&#x27;t the compiler be able to do that, too?</div><br/><div id="36624525" class="c"><input type="checkbox" id="c-36624525" checked=""/><div class="controls bullet"><span class="by">AnotherGoodName</span><span>|</span><a href="#36622891">root</a><span>|</span><a href="#36623284">parent</a><span>|</span><a href="#36624026">next</a><span>|</span><label class="collapse" for="c-36624525">[-]</label><label class="expand" for="c-36624525">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not true in general.<p>In general branching code is faster than branchless code and there&#x27;s many many places that will demonstrate this with a quick Google. You know how many cycles a correctly predicted branch takes? 0.<p>On the other hand branchless code has to wait for each calculation to reach a certain stage in the pipeline since the thing to be output is dependent on the result. The CPU will have a whole lot of halts.<p>So why is this faster? Because the input is literally random(). The branch predictor will be wrong. This isn&#x27;t normal though. The compiler is creating code that will be faster in most normal use cases.<p>It&#x27;s an artificial benchmark that works against the output the compiler produces.</div><br/><div id="36627650" class="c"><input type="checkbox" id="c-36627650" checked=""/><div class="controls bullet"><span class="by">rendaw</span><span>|</span><a href="#36622891">root</a><span>|</span><a href="#36624525">parent</a><span>|</span><a href="#36624026">next</a><span>|</span><label class="collapse" for="c-36627650">[-]</label><label class="expand" for="c-36627650">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;re saying that humans have information to context that allows them to provide use-case-specific optimizations which a compiler which must anticipate general usage couldn&#x27;t.  That&#x27;s what profile guided optimizers are for though, right?</div><br/></div></div></div></div><div id="36624026" class="c"><input type="checkbox" id="c-36624026" checked=""/><div class="controls bullet"><span class="by">thomasahle</span><span>|</span><a href="#36622891">root</a><span>|</span><a href="#36623284">parent</a><span>|</span><a href="#36624525">prev</a><span>|</span><a href="#36623649">next</a><span>|</span><label class="collapse" for="c-36624026">[-]</label><label class="expand" for="c-36624026">[1 more]</label></div><br/><div class="children"><div class="content">I tried <a href="https:&#x2F;&#x2F;godbolt.org&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;godbolt.org&#x2F;</a>, and neither Clang nor GCC trunk give the same code for the two programs.<p>Pretty shocking for such a simple program.</div><br/></div></div><div id="36623649" class="c"><input type="checkbox" id="c-36623649" checked=""/><div class="controls bullet"><span class="by">ModernMech</span><span>|</span><a href="#36622891">root</a><span>|</span><a href="#36623284">parent</a><span>|</span><a href="#36624026">prev</a><span>|</span><a href="#36625110">next</a><span>|</span><label class="collapse" for="c-36623649">[-]</label><label class="expand" for="c-36623649">[6 more]</label></div><br/><div class="children"><div class="content">Yes, there’s always the “sufficiently smart compiler” that can generate this code. Question is, does that compiler exist?</div><br/><div id="36623741" class="c"><input type="checkbox" id="c-36623741" checked=""/><div class="controls bullet"><span class="by">Groxx</span><span>|</span><a href="#36622891">root</a><span>|</span><a href="#36623649">parent</a><span>|</span><a href="#36623806">next</a><span>|</span><label class="collapse" for="c-36623741">[-]</label><label class="expand" for="c-36623741">[1 more]</label></div><br/><div class="children"><div class="content">I sure hope so.  The semantics are trivially identical, the optimizations should be as well, by default - they should depend on semantics, not syntax.  And GCC in another comment under this thread seems to be doing similar or identical optimizations in both cases.<p>I wholly admit that this implies nothing about <i>all</i> optimizers. But it&#x27;s a pretty reasonable one to expect.</div><br/></div></div><div id="36623806" class="c"><input type="checkbox" id="c-36623806" checked=""/><div class="controls bullet"><span class="by">charcircuit</span><span>|</span><a href="#36622891">root</a><span>|</span><a href="#36623649">parent</a><span>|</span><a href="#36623741">prev</a><span>|</span><a href="#36625132">next</a><span>|</span><label class="collapse" for="c-36623806">[-]</label><label class="expand" for="c-36623806">[1 more]</label></div><br/><div class="children"><div class="content">&gt;does that compiler exist?<p>and if so are the compile times worth it</div><br/></div></div><div id="36625132" class="c"><input type="checkbox" id="c-36625132" checked=""/><div class="controls bullet"><span class="by">icsa</span><span>|</span><a href="#36622891">root</a><span>|</span><a href="#36623649">parent</a><span>|</span><a href="#36623806">prev</a><span>|</span><a href="#36625110">next</a><span>|</span><label class="collapse" for="c-36625132">[-]</label><label class="expand" for="c-36625132">[3 more]</label></div><br/><div class="children"><div class="content">These days, I&#x27;s put my money on zig cc.
I.E. zig cc -Os or zig cc -O3</div><br/><div id="36625263" class="c"><input type="checkbox" id="c-36625263" checked=""/><div class="controls bullet"><span class="by">eyegor</span><span>|</span><a href="#36622891">root</a><span>|</span><a href="#36625132">parent</a><span>|</span><a href="#36625110">next</a><span>|</span><label class="collapse" for="c-36625263">[-]</label><label class="expand" for="c-36625263">[2 more]</label></div><br/><div class="children"><div class="content">Does the zig compiler have many fancy bits? I was under the impression the c support was a &quot;nothing special&quot; compiler that punted to llvm for optimizations.</div><br/><div id="36626543" class="c"><input type="checkbox" id="c-36626543" checked=""/><div class="controls bullet"><span class="by">plorkyeran</span><span>|</span><a href="#36622891">root</a><span>|</span><a href="#36625263">parent</a><span>|</span><a href="#36625110">next</a><span>|</span><label class="collapse" for="c-36626543">[-]</label><label class="expand" for="c-36626543">[1 more]</label></div><br/><div class="children"><div class="content">Correct, zig currently does not do any of its own optimizations. It won&#x27;t necessarily have <i>identical</i> results to clang because it&#x27;ll generate equivalent but not identical IR and the optimizer passes may happen to do something different as a result, but it&#x27;s not going to be consistently different.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="36625110" class="c"><input type="checkbox" id="c-36625110" checked=""/><div class="controls bullet"><span class="by">BbzzbB</span><span>|</span><a href="#36622891">parent</a><span>|</span><a href="#36623284">prev</a><span>|</span><a href="#36627638">next</a><span>|</span><label class="collapse" for="c-36625110">[-]</label><label class="expand" for="c-36625110">[1 more]</label></div><br/><div class="children"><div class="content">Is there any good article comparing performance across programming languages? Seems like everytime I see one they&#x27;re broken because the tested logic is poorly implemented in language(s) XYZ.</div><br/></div></div></div></div><div id="36623262" class="c"><input type="checkbox" id="c-36623262" checked=""/><div class="controls bullet"><span class="by">nwallin</span><span>|</span><a href="#36622891">prev</a><span>|</span><a href="#36628684">next</a><span>|</span><label class="collapse" for="c-36623262">[-]</label><label class="expand" for="c-36623262">[19 more]</label></div><br/><div class="children"><div class="content">IMHO the original code wasn&#x27;t written in a way that&#x27;s particularly friendly to compilers. If you write it like this:<p><pre><code>    int run_switches_branchless(const char* s) {
        int result = 0;
        for (; *s; ++s) {
            result += *s == &#x27;s&#x27;;
            result -= *s == &#x27;p&#x27;;
        }
        return result;
    }
</code></pre>
...the compiler will do all the branchless sete&#x2F;cmov stuff as it sees fit. It will be the same speed as the optimized assembly in the post, +&#x2F;- something insignificant. However it won&#x27;t unroll and vectorize the loop. If you write it like this:<p><pre><code>    int run_switches_vectorized(const char* s, size_t size) {
        int result = 0;
        for (; size--; ++s) {
            result += *s == &#x27;s&#x27;;
            result -= *s == &#x27;p&#x27;;
        }
        return result;
    }
</code></pre>
It will know the size of the loop, and will unroll it and use AVX-512 instructions if they&#x27;re available. This will be substantially faster than the first loop for large inputs, although I&#x27;m too lazy to benchmark just how much faster it is.<p>Now, this requires knowing the size of your string in advance, and maybe you&#x27;re the sort of C programmer who doesn&#x27;t keep track of how big your strings are. I&#x27;m not your coworker, I don&#x27;t review your code. Do what you want. But you really <i>really</i> probably shouldn&#x27;t.<p><a href="https:&#x2F;&#x2F;godbolt.org&#x2F;z&#x2F;rde51zMd8" rel="nofollow noreferrer">https:&#x2F;&#x2F;godbolt.org&#x2F;z&#x2F;rde51zMd8</a></div><br/><div id="36623823" class="c"><input type="checkbox" id="c-36623823" checked=""/><div class="controls bullet"><span class="by">414owen</span><span>|</span><a href="#36623262">parent</a><span>|</span><a href="#36627023">next</a><span>|</span><label class="collapse" for="c-36623823">[-]</label><label class="expand" for="c-36623823">[13 more]</label></div><br/><div class="children"><div class="content">The version that&#x27;s friendly to the compiler is described in part two: <a href="https:&#x2F;&#x2F;owen.cafe&#x2F;posts&#x2F;the-same-speed-as-c&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;owen.cafe&#x2F;posts&#x2F;the-same-speed-as-c&#x2F;</a><p>It achieves 3.88GiB&#x2F;s<p>I intentionally didn&#x27;t go down the route of vectorizing. I wanted to keep the scope of the problem small, and show off the assembly tips and tricks in the post, but maybe there&#x27;s potential for a future post, where I pad the input string and vectorize the algorithm :)</div><br/><div id="36625221" class="c"><input type="checkbox" id="c-36625221" checked=""/><div class="controls bullet"><span class="by">nwallin</span><span>|</span><a href="#36623262">root</a><span>|</span><a href="#36623823">parent</a><span>|</span><a href="#36627023">next</a><span>|</span><label class="collapse" for="c-36625221">[-]</label><label class="expand" for="c-36625221">[12 more]</label></div><br/><div class="children"><div class="content">So I downloaded your code. On my desktop, with loop-9 gcc I got ~4.5GB&#x2F;s, and with loop-7 I got ~4.4GB&#x2F;s. With the following code:<p><pre><code>    #include &lt;stddef.h&gt;
    
    int run_switches(const char *s, size_t n) {
      int res = 0;
      for (; n--; ++s)
        res += (*s == &#x27;s&#x27;) - (*s == &#x27;p&#x27;);
      return res;
    }
</code></pre>
I got ~31GB&#x2F;s in GCC and ~33GB&#x2F;s in Clang. This is without any padding, or SIMD intrinsics, or any such nonsense. This is just untying the compiler&#x27;s hands and giving it permission to do its job properly.<p>Don&#x27;t want to pass the string length? That&#x27;s fine, we can figure that out for ourselves. This code:<p><pre><code>    #include &lt;stddef.h&gt;
    #include &lt;string.h&gt;

    int run_switches(const char *s) {
      int res = 0;
      for (size_t n = strlen(s); n--; ++s)
        res += (*s == &#x27;s&#x27;) - (*s == &#x27;p&#x27;);

      return res;
    }
</code></pre>
Is 27GB&#x2F;s. With a little bit of blocking:<p><pre><code>    #include &lt;stddef.h&gt;
    
    int run_switches(const char *s, size_t n) {
      int res = 0;
      char tmp = 0;
      for (size_t i = n &amp; 63; i--; ++s)
        tmp += (*s == &#x27;s&#x27;) - (*s == &#x27;p&#x27;);
      res += tmp;
    
      for (n &gt;&gt;= 6; n--;) {
        tmp = 0;
        for (size_t i = 64; i--; ++s)
          tmp += (*s == &#x27;s&#x27;) - (*s == &#x27;p&#x27;);
        res += tmp;
      }
    
      return res;
    }
</code></pre>
That&#x27;s ~55GB&#x2F;s.<p>Anyway, the point is, you&#x27;re pretty far from the point where you ought to give up on C and dive into assembly.</div><br/><div id="36628713" class="c"><input type="checkbox" id="c-36628713" checked=""/><div class="controls bullet"><span class="by">magicalhippo</span><span>|</span><a href="#36623262">root</a><span>|</span><a href="#36625221">parent</a><span>|</span><a href="#36626429">next</a><span>|</span><label class="collapse" for="c-36628713">[-]</label><label class="expand" for="c-36628713">[1 more]</label></div><br/><div class="children"><div class="content">Another good reason to write optimization-friendly C (or similar) over assembly code, especially in libraries, is that the compiler will evolve with CPUs, while the assembly code will not.<p>I&#x27;ve seen plenty of cases where replacing hand-written assembly with C (or similar) lead to a substantial performance increase because the assembly code was written for some old CPU and not the best way of doing things on current CPUs.</div><br/></div></div><div id="36626429" class="c"><input type="checkbox" id="c-36626429" checked=""/><div class="controls bullet"><span class="by">utopcell</span><span>|</span><a href="#36623262">root</a><span>|</span><a href="#36625221">parent</a><span>|</span><a href="#36628713">prev</a><span>|</span><a href="#36627023">next</a><span>|</span><label class="collapse" for="c-36626429">[-]</label><label class="expand" for="c-36626429">[10 more]</label></div><br/><div class="children"><div class="content">Indeed. I suppose the two lessons are, stick with C, and don&#x27;t forget the semantics of your original problem when optimizing.<p><pre><code>    int run_switches(const char *s) {
      int res = 0;
      uint8_t tmp = 0;
      size_t n = strlen(s);
      for (size_t i = n &amp; 127; i--; ++s)
        tmp += (*s == &#x27;s&#x27;);
      res += tmp;
    
      for (size_t j = n &gt;&gt; 7; j--;) {
        tmp = 0;
        for (size_t i = 128; i--; ++s)
          tmp += (*s == &#x27;s&#x27;);
        res += tmp;
      }
    
      return 2 * res - n;
    }</code></pre></div><br/><div id="36626636" class="c"><input type="checkbox" id="c-36626636" checked=""/><div class="controls bullet"><span class="by">nwallin</span><span>|</span><a href="#36623262">root</a><span>|</span><a href="#36626429">parent</a><span>|</span><a href="#36628151">next</a><span>|</span><label class="collapse" for="c-36626636">[-]</label><label class="expand" for="c-36626636">[7 more]</label></div><br/><div class="children"><div class="content">Neat! Although you&#x27;ll need to make a copy of `n`. The second loop will reduce the value of n to null.<p>Edit: Also, there&#x27;s an off by one error. should be:<p><pre><code>    #include &lt;stddef.h&gt;
    #include &lt;stdint.h&gt;
    
    int run_switches(const char *s, const size_t n) {
      int res = 0;
      uint8_t tmp = 0;
      for (int i = n &amp; 127; i--; ++s)
        tmp += *s == &#x27;s&#x27;;
      res += tmp;
    
      for (int size = n &gt;&gt; 7; size--;) {
        tmp = 0;
        for (int i = 128; i--; ++s)
          tmp += *s == &#x27;s&#x27;;
        res += tmp;
      }
    
      return 2 * res - n + 1;
    }
</code></pre>
~90GB&#x2F;s on my machine, compared to 4.5GB&#x2F;s for his best effort on his blog. So 20x as fast.</div><br/><div id="36627329" class="c"><input type="checkbox" id="c-36627329" checked=""/><div class="controls bullet"><span class="by">repsilat</span><span>|</span><a href="#36623262">root</a><span>|</span><a href="#36626636">parent</a><span>|</span><a href="#36626780">next</a><span>|</span><label class="collapse" for="c-36627329">[-]</label><label class="expand" for="c-36627329">[3 more]</label></div><br/><div class="children"><div class="content">This is a wonderful thread.<p>Which tricks in there are worth playing around with more widely?<p>Is the uint8_t just &quot;no point in using something bigger&quot; or does it likely help the compiler? Does&#x2F;can the signedness matter as well as the size?<p>Ditto looping downwards -- is it often likely to improve things? Can it generalize to pointer&#x2F;iterator ranges, or is it often worth trying to phrase them in terms of array&#x2F;index accesses instead?<p>I guess the compiler&#x27;s unrolling heuristics generally aren&#x27;t as good as that blocking &quot;mod then div&quot; alternative to Duff&#x27;s device? Obviously taking `s` out of the loop condition is part of the magic.<p>Not checking the &#x27;p&#x27; character by comparison is an easy optimization to understand.<p>Any places to read about this sort of thing, or any tricks or guidelines that come to mind? I write a fair bit of performance-sensitive code but it&#x27;s all probably 20x slower than it could be because I have no intuition for what transformations compilers will do beyond &quot;this prob gets inlined&quot; etc.</div><br/><div id="36628348" class="c"><input type="checkbox" id="c-36628348" checked=""/><div class="controls bullet"><span class="by">xoranth</span><span>|</span><a href="#36623262">root</a><span>|</span><a href="#36627329">parent</a><span>|</span><a href="#36627980">next</a><span>|</span><label class="collapse" for="c-36628348">[-]</label><label class="expand" for="c-36628348">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I guess the compiler&#x27;s unrolling heuristics generally aren&#x27;t as good as that blocking &quot;mod then div&quot; alternative to Duff&#x27;s device? Obviously taking `s` out of the loop condition is part of the magic.<p>The magic in this case is the compiler autovectorizer. Making the length of the loop a loop invariant allows the autovectorizer to kick in.<p>The reason &quot;blocking&quot; by accumulating on uint8_t helps further is that it allows the compiler to accumulate on 8 bit SIMD lanes, instead 32 bit SIMD lanes.
The same operation on 8 bit SIMD lanes will, to a first approximation, do x4 the work per cycle.</div><br/></div></div><div id="36627980" class="c"><input type="checkbox" id="c-36627980" checked=""/><div class="controls bullet"><span class="by">zokier</span><span>|</span><a href="#36623262">root</a><span>|</span><a href="#36627329">parent</a><span>|</span><a href="#36628348">prev</a><span>|</span><a href="#36626780">next</a><span>|</span><label class="collapse" for="c-36627980">[-]</label><label class="expand" for="c-36627980">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Is the uint8_t just &quot;no point in using something bigger&quot; or does it likely help the compiler? Does&#x2F;can the signedness matter as well as the size?<p>In a good world you could use just uint_fast8_t and compiler would optimize this question for you. In real world I don&#x27;t think compilers are smart enough, or there are too many other constraints limiting them :(</div><br/></div></div></div></div><div id="36626780" class="c"><input type="checkbox" id="c-36626780" checked=""/><div class="controls bullet"><span class="by">utopcell</span><span>|</span><a href="#36623262">root</a><span>|</span><a href="#36626636">parent</a><span>|</span><a href="#36627329">prev</a><span>|</span><a href="#36627304">next</a><span>|</span><label class="collapse" for="c-36626780">[-]</label><label class="expand" for="c-36626780">[2 more]</label></div><br/><div class="children"><div class="content">Bummer! Edited the answer. Not sure about the off-by-one though.
Say the string is str[] = &quot;spp\0&quot;. n = strlen(str) is 3.
In the end, res would be 1 and 2 * res - n == -1.</div><br/><div id="36626900" class="c"><input type="checkbox" id="c-36626900" checked=""/><div class="controls bullet"><span class="by">nwallin</span><span>|</span><a href="#36623262">root</a><span>|</span><a href="#36626780">parent</a><span>|</span><a href="#36627304">next</a><span>|</span><label class="collapse" for="c-36626900">[-]</label><label class="expand" for="c-36626900">[1 more]</label></div><br/><div class="children"><div class="content">Oh. Found it. It&#x27;s because I wasn&#x27;t using strlen and had been passing over the length of the buffer instead of the length of the string. Only my code had the off by 1.</div><br/></div></div></div></div><div id="36627304" class="c"><input type="checkbox" id="c-36627304" checked=""/><div class="controls bullet"><span class="by">skavi</span><span>|</span><a href="#36623262">root</a><span>|</span><a href="#36626636">parent</a><span>|</span><a href="#36626780">prev</a><span>|</span><a href="#36628151">next</a><span>|</span><label class="collapse" for="c-36627304">[-]</label><label class="expand" for="c-36627304">[1 more]</label></div><br/><div class="children"><div class="content">Am I missing something, or does this not really account for alignment? Is the compiler doing smarter loop splitting?</div><br/></div></div></div></div><div id="36628151" class="c"><input type="checkbox" id="c-36628151" checked=""/><div class="controls bullet"><span class="by">smarnach</span><span>|</span><a href="#36623262">root</a><span>|</span><a href="#36626429">parent</a><span>|</span><a href="#36626636">prev</a><span>|</span><a href="#36627684">next</a><span>|</span><label class="collapse" for="c-36628151">[-]</label><label class="expand" for="c-36628151">[1 more]</label></div><br/><div class="children"><div class="content">This makes the assumption that the only characters in the string are &quot;s&quot; and &quot;p&quot;. There is no basis for this assumption. I think this code solves a different problem rather than being an optimisation of the original code.</div><br/></div></div><div id="36627684" class="c"><input type="checkbox" id="c-36627684" checked=""/><div class="controls bullet"><span class="by">teo_zero</span><span>|</span><a href="#36623262">root</a><span>|</span><a href="#36626429">parent</a><span>|</span><a href="#36628151">prev</a><span>|</span><a href="#36627023">next</a><span>|</span><label class="collapse" for="c-36627684">[-]</label><label class="expand" for="c-36627684">[1 more]</label></div><br/><div class="children"><div class="content">But this is not the original problem! Only p&#x27;s should decrease the counter, in your code every non-s does.</div><br/></div></div></div></div></div></div></div></div><div id="36627023" class="c"><input type="checkbox" id="c-36627023" checked=""/><div class="controls bullet"><span class="by">shusaku</span><span>|</span><a href="#36623262">parent</a><span>|</span><a href="#36623823">prev</a><span>|</span><a href="#36625584">next</a><span>|</span><label class="collapse" for="c-36627023">[-]</label><label class="expand" for="c-36627023">[1 more]</label></div><br/><div class="children"><div class="content">You forgot an important line of the code:<p>&#x2F;* DON’T REFACTOR THIS FOR READABILITY IT WILL SLOW DOWN *&#x2F;</div><br/></div></div><div id="36625584" class="c"><input type="checkbox" id="c-36625584" checked=""/><div class="controls bullet"><span class="by">elcritch</span><span>|</span><a href="#36623262">parent</a><span>|</span><a href="#36627023">prev</a><span>|</span><a href="#36623408">next</a><span>|</span><label class="collapse" for="c-36625584">[-]</label><label class="expand" for="c-36625584">[1 more]</label></div><br/><div class="children"><div class="content">Nice! I tried it in Nim and it appears to trigger it with:<p><pre><code>    {.overflowChecks:off.}
    proc run_switches*(input: cstring): int {.exportc.} =
      result = 0
      for c in input:
        result.inc int(&#x27;s&#x27; == c)
        result.dec int(&#x27;p&#x27; == c)
</code></pre>
That gives a ~5x speedup on an Apple M1. Keeping overflow checks on only gets it up to ~2x the default C version. Always nice to know good ways to trigger SIMD opts.</div><br/></div></div><div id="36623408" class="c"><input type="checkbox" id="c-36623408" checked=""/><div class="controls bullet"><span class="by">jonny_eh</span><span>|</span><a href="#36623262">parent</a><span>|</span><a href="#36625584">prev</a><span>|</span><a href="#36628684">next</a><span>|</span><label class="collapse" for="c-36623408">[-]</label><label class="expand" for="c-36623408">[3 more]</label></div><br/><div class="children"><div class="content">&gt; But you really really probably shouldn&#x27;t.<p>Shouldn&#x27;t &quot;not&quot; keep track of string length?</div><br/><div id="36623661" class="c"><input type="checkbox" id="c-36623661" checked=""/><div class="controls bullet"><span class="by">nwallin</span><span>|</span><a href="#36623262">root</a><span>|</span><a href="#36623408">parent</a><span>|</span><a href="#36623646">next</a><span>|</span><label class="collapse" for="c-36623661">[-]</label><label class="expand" for="c-36623661">[1 more]</label></div><br/><div class="children"><div class="content">Err... yes. You shouldn&#x27;t not keep track of string&#x2F;buffer sizes.</div><br/></div></div></div></div></div></div><div id="36628684" class="c"><input type="checkbox" id="c-36628684" checked=""/><div class="controls bullet"><span class="by">okaleniuk</span><span>|</span><a href="#36623262">prev</a><span>|</span><a href="#36624240">next</a><span>|</span><label class="collapse" for="c-36628684">[-]</label><label class="expand" for="c-36628684">[1 more]</label></div><br/><div class="children"><div class="content">I think, it&#x27;s a particular quirk of x86 architecture. Branching is expensive in comparison because not doing branching is super cheap.
<a href="https:&#x2F;&#x2F;wordsandbuttons.online&#x2F;challenge_your_performance_intuition_with_cpp_operators.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;wordsandbuttons.online&#x2F;challenge_your_performance_in...</a><p>However, on other processors, this might not be the case.
<a href="https:&#x2F;&#x2F;wordsandbuttons.online&#x2F;using_logical_operators_for_logical_operations_is_good.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;wordsandbuttons.online&#x2F;using_logical_operators_for_l...</a><p>The good question is what do we need C for in general? Of course, we can hand-tailor our code to run best on one particular piece of hardware. And we don&#x27;t need C for that, it would be the wrong tool. We need assembly (and a decent macro system for some sugar)<p>But the original goal of C was to make translating system-level code from one platform to another easier. And we&#x27;re expected to lose efficiency on this operation. It&#x27;s like instead of writing a poem in Hindi and translating it in Urdu, we write one in Esperanto and then translate to whatever language we want automatically. You don&#x27;t get two brilliant poems, you only get two poor translations, but you get them fast. That&#x27;s what C is for.</div><br/></div></div><div id="36624240" class="c"><input type="checkbox" id="c-36624240" checked=""/><div class="controls bullet"><span class="by">Const-me</span><span>|</span><a href="#36628684">prev</a><span>|</span><a href="#36622811">next</a><span>|</span><label class="collapse" for="c-36624240">[-]</label><label class="expand" for="c-36624240">[7 more]</label></div><br/><div class="children"><div class="content">I’m probably an optimization expert, and I would solve that problem completely differently.<p>On my computer, the initial C version runs at 389 MB &#x2F; second. I haven’t tested the assembly versions, but if they deliver the same 6.2x speedup, would result in 2.4 GB&#x2F;second here.<p>Here’s C++ version which for long buffers exceeds 24 GB&#x2F;second on my computer: <a href="https:&#x2F;&#x2F;gist.github.com&#x2F;Const-me&#x2F;3ade77faad47f0fbb0538965ae7f8e04" rel="nofollow noreferrer">https:&#x2F;&#x2F;gist.github.com&#x2F;Const-me&#x2F;3ade77faad47f0fbb0538965ae7...</a>
That’s 61x speedup compared to the original version, without any assembly, based on AVX2 intrinsics.</div><br/><div id="36624746" class="c"><input type="checkbox" id="c-36624746" checked=""/><div class="controls bullet"><span class="by">xoranth</span><span>|</span><a href="#36624240">parent</a><span>|</span><a href="#36624301">next</a><span>|</span><label class="collapse" for="c-36624746">[-]</label><label class="expand" for="c-36624746">[1 more]</label></div><br/><div class="children"><div class="content">Interesting. I think you can vectorize the prologue using movemask + popcnt instead of keeping a counter in the ymm registers (warning: untested code, still need to benchmark it):<p><pre><code>    const __m256i zero = _mm256_setzero_si256();
    const __m256i s = _mm256_set1_epi8( &#x27;s&#x27; );
    const __m256i p = _mm256_set1_epi8( &#x27;p&#x27; );

    const size_t a = (size_t)input;
    const size_t rem = a % 32;
    const char* aligned = input - rem;

    const __m256i v = _mm256_load_si256(( const __m256i*) input);
    const __m256i z = _mm256_cmpeq_epi8( v, zero );

    size_t m_plus = _mm256_movemask_epi8(_mm_cmpeq_epi8(v, s));
    size_t m_minus = _mm256_movemask_epi8(_mm_cmpeq_epi8(v, p));
    size_t m_zero = _mm256_movemask_epi8(_mm_cmpeq_epi8(v, z));
    size_t offset_zero = _mm_tzcnt_64(m_zero &gt;&gt; rem);

    m_plus = _bzhi_u64(m_plus &gt;&gt; rem, offset_zero);
    m_minus = _bzhi_u64(m_minus &gt;&gt; rem, offset_zero);

    &#x2F;&#x2F; Skip loop we already found the end of the string...
    while (m_zero == 0) {
        &#x2F;&#x2F; ...
    }
    
    &#x2F;&#x2F; ...
    
    return m_plus + res - m_minus;</code></pre></div><br/></div></div><div id="36624301" class="c"><input type="checkbox" id="c-36624301" checked=""/><div class="controls bullet"><span class="by">gavinray</span><span>|</span><a href="#36624240">parent</a><span>|</span><a href="#36624746">prev</a><span>|</span><a href="#36626491">next</a><span>|</span><label class="collapse" for="c-36624301">[-]</label><label class="expand" for="c-36624301">[2 more]</label></div><br/><div class="children"><div class="content">Do you know if this is possible using &quot;std::experimental::simd&quot; out of curiosity?<p><a href="https:&#x2F;&#x2F;en.cppreference.com&#x2F;w&#x2F;cpp&#x2F;experimental&#x2F;simd" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.cppreference.com&#x2F;w&#x2F;cpp&#x2F;experimental&#x2F;simd</a></div><br/><div id="36624569" class="c"><input type="checkbox" id="c-36624569" checked=""/><div class="controls bullet"><span class="by">Const-me</span><span>|</span><a href="#36624240">root</a><span>|</span><a href="#36624301">parent</a><span>|</span><a href="#36626491">next</a><span>|</span><label class="collapse" for="c-36624569">[-]</label><label class="expand" for="c-36624569">[1 more]</label></div><br/><div class="children"><div class="content">I don’t have any experience with that library.<p>Still, based on the documentation you have linked, I’m not sure it could possibly generate some code similar to my version. I could be wrong but I don’t see APIs which aggregate or accumulate the `simd_mask` vectors they output for results of vector comparisons.</div><br/></div></div></div></div><div id="36626491" class="c"><input type="checkbox" id="c-36626491" checked=""/><div class="controls bullet"><span class="by">utopcell</span><span>|</span><a href="#36624240">parent</a><span>|</span><a href="#36624301">prev</a><span>|</span><a href="#36626232">next</a><span>|</span><label class="collapse" for="c-36626491">[-]</label><label class="expand" for="c-36626491">[1 more]</label></div><br/><div class="children"><div class="content">you might want to rewrite this in a form that is compatible with @414owen&#x27;s repo.</div><br/></div></div><div id="36626232" class="c"><input type="checkbox" id="c-36626232" checked=""/><div class="controls bullet"><span class="by">bluedevilzn</span><span>|</span><a href="#36624240">parent</a><span>|</span><a href="#36626491">prev</a><span>|</span><a href="#36622811">next</a><span>|</span><label class="collapse" for="c-36626232">[-]</label><label class="expand" for="c-36626232">[2 more]</label></div><br/><div class="children"><div class="content">What’s a good source to learn and practice AVX?</div><br/><div id="36627035" class="c"><input type="checkbox" id="c-36627035" checked=""/><div class="controls bullet"><span class="by">utopcell</span><span>|</span><a href="#36624240">root</a><span>|</span><a href="#36626232">parent</a><span>|</span><a href="#36622811">next</a><span>|</span><label class="collapse" for="c-36627035">[-]</label><label class="expand" for="c-36627035">[1 more]</label></div><br/><div class="children"><div class="content">You could study Google&#x27;s Highway library [1].<p>[1] <a href="https:&#x2F;&#x2F;github.com&#x2F;google&#x2F;highway">https:&#x2F;&#x2F;github.com&#x2F;google&#x2F;highway</a></div><br/></div></div></div></div></div></div><div id="36622811" class="c"><input type="checkbox" id="c-36622811" checked=""/><div class="controls bullet"><span class="by">Sesse__</span><span>|</span><a href="#36624240">prev</a><span>|</span><a href="#36628388">next</a><span>|</span><label class="collapse" for="c-36622811">[-]</label><label class="expand" for="c-36622811">[1 more]</label></div><br/><div class="children"><div class="content">This code screams for SIMD! If you can change the prototype to take an explicit length, you could easily read and process 16 bytes at a time (the compares will give you values you can just add and subtract directly). Heck, even calling strlen() at the function&#x27;s start to get the explicit length would probably be worth it.</div><br/></div></div><div id="36628388" class="c"><input type="checkbox" id="c-36628388" checked=""/><div class="controls bullet"><span class="by">arun-mani-j</span><span>|</span><a href="#36622811">prev</a><span>|</span><a href="#36622827">next</a><span>|</span><label class="collapse" for="c-36628388">[-]</label><label class="expand" for="c-36628388">[3 more]</label></div><br/><div class="children"><div class="content">Any guide on how a person who uses Python or JavaScript can learn such things? I mean knowing which assembly code would be better, which algorithm makes better usage of processor etc.? :)<p>Also, how is such optimization carried out in a large scale software? Like, do you tweak the generated assembly code manually? (Sorry I&#x27;m a very very very beginner to low-level code)</div><br/><div id="36628470" class="c"><input type="checkbox" id="c-36628470" checked=""/><div class="controls bullet"><span class="by">sigmoid10</span><span>|</span><a href="#36628388">parent</a><span>|</span><a href="#36628441">next</a><span>|</span><label class="collapse" for="c-36628470">[-]</label><label class="expand" for="c-36628470">[1 more]</label></div><br/><div class="children"><div class="content">You do this by first learning C (or similar languages) and then compilers and maybe also operating systems. What you&#x27;re seeing in this blog is the equivalent result of at least one or two years university level education, so it&#x27;s not like there is a single book or tutorial you could use to get you up to speed, especially if you have no previous experience in that area. And building a better compiler optimisation in general is a PhD thesis level task. But it&#x27;s also not necessary if you want to design user applications on today&#x27;s hardware.</div><br/></div></div><div id="36628441" class="c"><input type="checkbox" id="c-36628441" checked=""/><div class="controls bullet"><span class="by">dottedmag</span><span>|</span><a href="#36628388">parent</a><span>|</span><a href="#36628470">prev</a><span>|</span><a href="#36622827">next</a><span>|</span><label class="collapse" for="c-36628441">[-]</label><label class="expand" for="c-36628441">[1 more]</label></div><br/><div class="children"><div class="content">You could try this (in-progress) course: <a href="https:&#x2F;&#x2F;www.computerenhance.com&#x2F;p&#x2F;table-of-contents" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.computerenhance.com&#x2F;p&#x2F;table-of-contents</a></div><br/></div></div></div></div><div id="36622827" class="c"><input type="checkbox" id="c-36622827" checked=""/><div class="controls bullet"><span class="by">camel-cdr</span><span>|</span><a href="#36628388">prev</a><span>|</span><a href="#36623914">next</a><span>|</span><label class="collapse" for="c-36622827">[-]</label><label class="expand" for="c-36622827">[9 more]</label></div><br/><div class="children"><div class="content">I threw together a quick risc-v vectorized implementation:<p><pre><code>    size_t run(char *str) {
            uint8_t *p = (uint8_t*)str;
            long end = 0;
            size_t res = 0, vl;
            while (1) {
             vl = __riscv_vsetvlmax_e8m8();
                    vuint8m8_t v = __riscv_vle8ff_v_u8m8(p, &amp;vl, vl);
                    end = __riscv_vfirst_m_b1(__riscv_vmseq_vx_u8m8_b1(v, &#x27;\0&#x27;, vl), vl);
                    if (end &gt;= 0)
                            break;
                    res += __riscv_vcpop_m_b1(__riscv_vmseq_vx_u8m8_b1(v, &#x27;s&#x27;, vl), vl);
                    res -= __riscv_vcpop_m_b1(__riscv_vmseq_vx_u8m8_b1(v, &#x27;p&#x27;, vl), vl);
                    p += vl;
            }
            vl = __riscv_vsetvl_e8m8(end);
            vuint8m8_t v = __riscv_vle8_v_u8m8(p, vl);
            res += __riscv_vcpop_m_b1(__riscv_vmseq_vx_u8m8_b1(v, &#x27;s&#x27;, vl), vl);
            res -= __riscv_vcpop_m_b1(__riscv_vmseq_vx_u8m8_b1(v, &#x27;p&#x27;, vl), vl);
            return res;
    }

</code></pre>
Here are the results from the above, the switch and the table c implementation, ran on my mangopi mq pro (C906, in order rv64gc with rvv 0.7.1, and a 128 bit vector length):<p><pre><code>    switch: 0.19 Bytes&#x2F;Cycle
    tbl:    0.17 Bytes&#x2F;Cycle
    rvv:    1.57 Bytes&#x2F;Cycle (dips down to 1.35 after ~30 KiB)
</code></pre>
Edit: you can go up to 2&#x2F;1.7 Bytes&#x2F;Cycle, if you make sure the pointer is page aligned (and vl isn&#x27;t larger than the page size), see comments</div><br/><div id="36623156" class="c"><input type="checkbox" id="c-36623156" checked=""/><div class="controls bullet"><span class="by">dzaima</span><span>|</span><a href="#36622827">parent</a><span>|</span><a href="#36623914">next</a><span>|</span><label class="collapse" for="c-36623156">[-]</label><label class="expand" for="c-36623156">[8 more]</label></div><br/><div class="children"><div class="content">To be fully correct, you&#x27;d need the load to be a fault-only-first load (which rvv does have), otherwise that could fail if the null byte was just before the end of allocated memory.</div><br/><div id="36623455" class="c"><input type="checkbox" id="c-36623455" checked=""/><div class="controls bullet"><span class="by">camel-cdr</span><span>|</span><a href="#36622827">root</a><span>|</span><a href="#36623156">parent</a><span>|</span><a href="#36623365">next</a><span>|</span><label class="collapse" for="c-36623455">[-]</label><label class="expand" for="c-36623455">[2 more]</label></div><br/><div class="children"><div class="content">I just found your rvv intrinsics-viewer [0], that&#x27;ll be so helpful.<p>I tried building one, my self, but my miserable web skills didn&#x27;t allow me to lazily load the instructions, which made it too slow for actual use.<p>Can I share your project on lemmy?<p>[0] <a href="https:&#x2F;&#x2F;dzaima.github.io&#x2F;intrinsics-viewer" rel="nofollow noreferrer">https:&#x2F;&#x2F;dzaima.github.io&#x2F;intrinsics-viewer</a></div><br/><div id="36623725" class="c"><input type="checkbox" id="c-36623725" checked=""/><div class="controls bullet"><span class="by">dzaima</span><span>|</span><a href="#36622827">root</a><span>|</span><a href="#36623455">parent</a><span>|</span><a href="#36623365">next</a><span>|</span><label class="collapse" for="c-36623725">[-]</label><label class="expand" for="c-36623725">[1 more]</label></div><br/><div class="children"><div class="content">Go ahead! I&#x27;m not much of a web dev either, but decided to struggle through it to, mainly, just have better searching. (originally for intel &amp; ARM intrinsics, which are also available if downloaded offline)</div><br/></div></div></div></div><div id="36623365" class="c"><input type="checkbox" id="c-36623365" checked=""/><div class="controls bullet"><span class="by">camel-cdr</span><span>|</span><a href="#36622827">root</a><span>|</span><a href="#36623156">parent</a><span>|</span><a href="#36623455">prev</a><span>|</span><a href="#36623914">next</a><span>|</span><label class="collapse" for="c-36623365">[-]</label><label class="expand" for="c-36623365">[5 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not sure I fully understand fault-only-first load, but reading the description of vle8ff.v I think I only need to exchange the load inside of the loop?<p>How does the normal load deal with faults?<p>I&#x27;ll update the parent comment, it slowed down the speed from 2&#x2F;1.7 to 1.57&#x2F;1.36 Bytes&#x2F;Cycle.</div><br/><div id="36623648" class="c"><input type="checkbox" id="c-36623648" checked=""/><div class="controls bullet"><span class="by">dzaima</span><span>|</span><a href="#36622827">root</a><span>|</span><a href="#36623365">parent</a><span>|</span><a href="#36623914">next</a><span>|</span><label class="collapse" for="c-36623648">[-]</label><label class="expand" for="c-36623648">[4 more]</label></div><br/><div class="children"><div class="content">You&#x27;d probably want to have a new __riscv_vsetvlmax_e8m8 at the start of each loop iteration, as otherwise an earlier iteration could cut off the vl (e.g. page unloaded by the OS), and thus the loop continues with the truncated vl.<p>The normal load should just segfault if any loaded byte is outside of readable memory, same as with a scalar load which is similarly partly outside.</div><br/><div id="36623944" class="c"><input type="checkbox" id="c-36623944" checked=""/><div class="controls bullet"><span class="by">camel-cdr</span><span>|</span><a href="#36622827">root</a><span>|</span><a href="#36623648">parent</a><span>|</span><a href="#36623914">next</a><span>|</span><label class="collapse" for="c-36623944">[-]</label><label class="expand" for="c-36623944">[3 more]</label></div><br/><div class="children"><div class="content">&gt;  You&#x27;d probably want to have a new __riscv_vsetvlmax_e8m8 at the start of each loop iteration, as otherwise an earlier iteration could cut off the vl (e.g. page unloaded by the OS), and thus the loop continues with the truncated vl.<p>Oh, yeah, that was a big oversight, unfortunately, this didn&#x27;t undo the performance regression.<p>&gt; The normal load should just segfault if any loaded byte is outside of readable memory, same as with a scalar load which is similarly partly outside.<p>I don&#x27;t quite understand how that plays out.<p>The reference memcpy implementation uses `vle8.v` and the reference strlen implementation uses `vle8ff.v`.<p>I think I understand how it works in strlen, but why does memcpy work without the ff? Does it just skip the instruction, or repeat it? Because in either case, shouldn&#x27;t `vle8.v` work with strlen as well? There must be another option, but I can&#x27;t think of any.<p>Also, does this mean I can get the original performance back, if I make sure to page align my pointers and use `vle8.v`?</div><br/><div id="36624017" class="c"><input type="checkbox" id="c-36624017" checked=""/><div class="controls bullet"><span class="by">dzaima</span><span>|</span><a href="#36622827">root</a><span>|</span><a href="#36623944">parent</a><span>|</span><a href="#36623914">next</a><span>|</span><label class="collapse" for="c-36624017">[-]</label><label class="expand" for="c-36624017">[2 more]</label></div><br/><div class="children"><div class="content">The memcpy doesn&#x27;t use a vlmax, it uses a hand-chosen vl. The load won&#x27;t fault on any elements not loaded (here, elements past the vl), so the memcpy is fine as it only loads items it&#x27;ll definitely need, whereas your original code can read elements past the null byte.<p>And yeah, aligning the pointer manually would work (though then it wouldn&#x27;t be portable code, as the spec does allow for rvv implementations with VLEN of up to 65536 (8KB per register; 64KB with LMUL=8), which&#x27;ll be larger than the regular 4KB pages).</div><br/><div id="36624141" class="c"><input type="checkbox" id="c-36624141" checked=""/><div class="controls bullet"><span class="by">camel-cdr</span><span>|</span><a href="#36622827">root</a><span>|</span><a href="#36624017">parent</a><span>|</span><a href="#36623914">next</a><span>|</span><label class="collapse" for="c-36624141">[-]</label><label class="expand" for="c-36624141">[1 more]</label></div><br/><div class="children"><div class="content">Ah, this makes a lot more sense now. I thought the &quot;fault&quot; was about the kernel interrupting when a new page needs to be loaded into physical memory, which would also happen for memcpy.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="36623914" class="c"><input type="checkbox" id="c-36623914" checked=""/><div class="controls bullet"><span class="by">xoranth</span><span>|</span><a href="#36622827">prev</a><span>|</span><a href="#36622584">next</a><span>|</span><label class="collapse" for="c-36623914">[-]</label><label class="expand" for="c-36623914">[4 more]</label></div><br/><div class="children"><div class="content">I think I managed to improve on both this post, and its sequel, at the cost of specializing the function for the case of a string made only of &#x27;s&#x27; and &#x27;p&#x27;.<p>The benchmark only tests strings made of &#x27;s&#x27; and &#x27;p&#x27;, so I think it is fair.<p>The idea is as follow. We want to increase `res` by one when the next character is `s`. Naively, we might try something like this:<p><pre><code>    res += (c - &#x27;r&#x27;);  &#x2F;&#x2F; is `res += 1` when c == &#x27;s&#x27; 
</code></pre>
This doesn&#x27;t work, as `&#x27;p&#x27; - &#x27;r&#x27; == -2`, and we&#x27;d need it to be -1.<p>But `&#x27;p&#x27; - &#x27;r&#x27;`, when viewer as an unsigned integer, underflows, setting the carry flag.
Turns out x64 has an instruction (adc) that adds two registers _plus_ the carry flag.<p>Therefore we can replace two `cmp, cmov` with one `sub, adc`:<p><pre><code>    run_switches:
            xor    eax, eax            # res = 0
    loop:
            movsx  ecx, byte ptr [rdi]
            test   ecx, ecx
            je     ret
            inc    rdi
            sub    ecx, &#x27;r&#x27;
            adc    eax, ecx     # Magic happens here
            jmp    loop
    ret:
            ret
            </code></pre>
Benchmarks are as follows (`bench-x64-8` is the asm above):<p><pre><code>    Summary
      &#x27;01-six-times-faster-than-c&#x2F;bench-x64-8 1000 1&#x27; ran
        1.08 ± 0.00 times faster than &#x27;02-the-same-speed-as-c&#x2F;bench-c-4-clang 1000 1&#x27;
        1.66 ± 0.00 times faster than &#x27;01-six-times-faster-than-c&#x2F;bench-x64-7 1000 1&#x27;
</code></pre>
Of course, one could improve things further using SWAR&#x2F;SIMD...</div><br/><div id="36628447" class="c"><input type="checkbox" id="c-36628447" checked=""/><div class="controls bullet"><span class="by">gpderetta</span><span>|</span><a href="#36623914">parent</a><span>|</span><a href="#36624157">next</a><span>|</span><label class="collapse" for="c-36628447">[-]</label><label class="expand" for="c-36628447">[1 more]</label></div><br/><div class="children"><div class="content">Even simpler: just sum all elements of the array. Then at the end subtract &#x27;p&#x27;*len from the sum, then divide by (&#x27;s&#x27;-&#x27;p&#x27;) to get the s count. The &#x27;p&#x27; count is len minus the &#x27;s&#x27; count.<p>The initial sum is easily vectorized as well.<p>If I&#x27;ve not made any mistakes it should work. Only issue is possible overflow on the running sum.<p>Can&#x27;t be bothered to benchmark it though:).</div><br/></div></div><div id="36624157" class="c"><input type="checkbox" id="c-36624157" checked=""/><div class="controls bullet"><span class="by">414owen</span><span>|</span><a href="#36623914">parent</a><span>|</span><a href="#36628447">prev</a><span>|</span><a href="#36622584">next</a><span>|</span><label class="collapse" for="c-36624157">[-]</label><label class="expand" for="c-36624157">[2 more]</label></div><br/><div class="children"><div class="content">Very interesting approach. I should probably have specified that the somewhat naive assembly in `02-the-same-speed-as-c&#x2F;loop-5.x64.s` is the fastest version I have.<p>On my machine I&#x27;m getting 0.244s for `loop-5.x64.s` and 0.422s for your implementation above.<p>I&#x27;m not sure why exactly we&#x27;re seeing this discrepancy, and for what it&#x27;s worth your implementation looks faster to me. I guess this is why you need to always benchmark on the hardware you&#x27;re going to be running the code on...</div><br/><div id="36624316" class="c"><input type="checkbox" id="c-36624316" checked=""/><div class="controls bullet"><span class="by">xoranth</span><span>|</span><a href="#36623914">root</a><span>|</span><a href="#36624157">parent</a><span>|</span><a href="#36622584">next</a><span>|</span><label class="collapse" for="c-36624316">[-]</label><label class="expand" for="c-36624316">[1 more]</label></div><br/><div class="children"><div class="content">I rerun the benchmark vs loop-5 and loop-7 from the second post. Runtime is basically the same on my machine.<p>I would have expected yours to be faster given that it needs to execute fewer instructions per loop iteration.
Though maybe the CPU can run `adc` on more ports compared to a load from memory?<p><pre><code>    Summary
      &#x27;01-six-times-faster-than-c&#x2F;bench-x64-8 1000 1&#x27; ran
        1.00 ± 0.00 times faster than &#x27;02-the-same-speed-as-c&#x2F;bench-x64-7 1000 1&#x27;
        1.66 ± 0.00 times faster than &#x27;01-six-times-faster-than-c&#x2F;bench-x64-7 1000 1&#x27;

    Summary
      &#x27;01-six-times-faster-than-c&#x2F;bench-x64-8 1000 1&#x27; ran
        1.01 ± 0.00 times faster than &#x27;02-the-same-speed-as-c&#x2F;bench-x64-5 1000 1&#x27;
        1.66 ± 0.00 times faster than &#x27;01-six-times-faster-than-c&#x2F;bench-x64-7 1000 1&#x27;</code></pre></div><br/></div></div></div></div></div></div><div id="36622584" class="c"><input type="checkbox" id="c-36622584" checked=""/><div class="controls bullet"><span class="by">eklitzke</span><span>|</span><a href="#36623914">prev</a><span>|</span><a href="#36624400">next</a><span>|</span><label class="collapse" for="c-36622584">[-]</label><label class="expand" for="c-36622584">[5 more]</label></div><br/><div class="children"><div class="content">Rearranging branches (and perhaps blocks too?) will definitely be done if you are building using FDO, because without FDO (or PGO) the compiler has no idea how likely each branch is to be taken. Cmov can also be enabled by FDO in some cases.<p>However, whether or not using cmov is effective compared to a regular test&#x2F;jump is highly dependent on how predictable the branch is, with cmov typically performing better when the branch is very unpredictable. Since they got a 6x speedup with cmov, I assume that their test input (which isn&#x27;t described in the post, and is also not in their GitHub repo) consists of random strings consisting almost entirely of s and p characters. There&#x27;s nothing wrong with this, but it does make the post seem a little misleading to me, as their clever speedup is mostly about exploiting an unmentioned property of the data that is highly specific to their benchmark.</div><br/><div id="36624125" class="c"><input type="checkbox" id="c-36624125" checked=""/><div class="controls bullet"><span class="by">nwallin</span><span>|</span><a href="#36622584">parent</a><span>|</span><a href="#36623739">next</a><span>|</span><label class="collapse" for="c-36624125">[-]</label><label class="expand" for="c-36624125">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I assume that their test input (which isn&#x27;t described in the post, and is also not in their GitHub repo) consists of random strings consisting almost entirely of s and p characters.<p>test code is here: <a href="https:&#x2F;&#x2F;github.com&#x2F;414owen&#x2F;blog-code&#x2F;blob&#x2F;master&#x2F;02-the-same-speed-as-c&#x2F;bench.c#L36">https:&#x2F;&#x2F;github.com&#x2F;414owen&#x2F;blog-code&#x2F;blob&#x2F;master&#x2F;02-the-same...</a> it randomly selects between &#x27;s&#x27; or &#x27;p&#x27;. The characters can&#x27;t be anything other than &#x27;s&#x27;, &#x27;p&#x27;, or the terminating null. Knowing that particular fact about our input gives us this ...clever... optimization:<p><pre><code>    int run_switches(const char* s) {
        int result = 0;
        while (*s)
            result += (1 | *s++) - &#x27;r&#x27;;
        return result;
    }
</code></pre>
which compiles to:<p><pre><code>    run_switches:
            movzx   eax, BYTE PTR [rdi]
            xor     edx, edx
            test    al, al
            je      .L1
    .L3:
            or      eax, 1
            inc     rdi
            movsx   eax, al
            lea     edx, [rdx-114+rax]
            movzx   eax, BYTE PTR [rdi]
            test    al, al
            jne     .L3
    .L1:
            mov     eax, edx
            ret
</code></pre>
This is too clever by half, of course, but it perfectly illustrates your point about exploiting properties of the data.</div><br/></div></div><div id="36623739" class="c"><input type="checkbox" id="c-36623739" checked=""/><div class="controls bullet"><span class="by">414owen</span><span>|</span><a href="#36622584">parent</a><span>|</span><a href="#36624125">prev</a><span>|</span><a href="#36624658">next</a><span>|</span><label class="collapse" for="c-36623739">[-]</label><label class="expand" for="c-36623739">[2 more]</label></div><br/><div class="children"><div class="content">&gt; because without FDO (or PGO) the compiler has no idea how likely each branch is to be taken<p>So, the maximum amount of times you can hit &#x27;\0&#x27; is once in the string, because then the function returns, but you can hit the other characters many times, which seems to be information a compiler has access to without PGO.<p>PGO does help, of course, and on my machine gives me 2.80s, which is better than the code at the end of the `Rearranging blocks` section :)<p>&gt; I assume that their test input (which isn&#x27;t described in the post, and is also not in their GitHub repo)<p>It&#x27;s described under `Benchmarking setup`, and is in the repository here: <a href="https:&#x2F;&#x2F;github.com&#x2F;414owen&#x2F;blog-code&#x2F;blob&#x2F;master&#x2F;01-six-times-faster-than-c&#x2F;bench.c">https:&#x2F;&#x2F;github.com&#x2F;414owen&#x2F;blog-code&#x2F;blob&#x2F;master&#x2F;01-six-time...</a><p>Side note: There&#x27;s a part two to this post (linked at the bottom) where I make the C code as fast as I possibly can, and it beats all the assembly in this post.<p>I never said writing assembly is (necessarily) a good idea, I just find optimizing it, and deciphering compiler output, an interesting challenge, and a good learning opportunity.</div><br/><div id="36626265" class="c"><input type="checkbox" id="c-36626265" checked=""/><div class="controls bullet"><span class="by">aengvs</span><span>|</span><a href="#36622584">root</a><span>|</span><a href="#36623739">parent</a><span>|</span><a href="#36624658">next</a><span>|</span><label class="collapse" for="c-36626265">[-]</label><label class="expand" for="c-36626265">[1 more]</label></div><br/><div class="children"><div class="content">Imagine a scenario where most of the strings being processed contain a single null character, with no other characters. In that case checking for the null character first would be optimal.<p>Does the compiler know that this isn&#x27;t true? No, it doesn&#x27;t. The author of the article is making an assumption about the contents of the data that might seem reasonable but isn&#x27;t necessarily true.</div><br/></div></div></div></div></div></div><div id="36624400" class="c"><input type="checkbox" id="c-36624400" checked=""/><div class="controls bullet"><span class="by">sltkr</span><span>|</span><a href="#36622584">prev</a><span>|</span><a href="#36625655">next</a><span>|</span><label class="collapse" for="c-36624400">[-]</label><label class="expand" for="c-36624400">[1 more]</label></div><br/><div class="children"><div class="content">How much faster is this:<p><pre><code>    int run_switches(const char *buf) {
       size_t len = strlen(buf);
       int res = 0;
       for (size_t i = 0; i &lt; len; ++i) {
         res += (buf[i] == &#x27;s&#x27;) - (buf[i] == &#x27;p&#x27;);
       }
       return res;
    }
</code></pre>
strlen() should be implemented in a pretty fast way, and after the buffer size is known, the compiler can autovectorize the inner loop, which does happen in practice: <a href="https:&#x2F;&#x2F;gcc.godbolt.org&#x2F;z&#x2F;qYfadPYoq" rel="nofollow noreferrer">https:&#x2F;&#x2F;gcc.godbolt.org&#x2F;z&#x2F;qYfadPYoq</a></div><br/></div></div><div id="36625655" class="c"><input type="checkbox" id="c-36625655" checked=""/><div class="controls bullet"><span class="by">eru</span><span>|</span><a href="#36624400">prev</a><span>|</span><a href="#36621911">next</a><span>|</span><label class="collapse" for="c-36625655">[-]</label><label class="expand" for="c-36625655">[1 more]</label></div><br/><div class="children"><div class="content">Compare also <a href="https:&#x2F;&#x2F;codegolf.stackexchange.com&#x2F;a&#x2F;236630&#x2F;32575" rel="nofollow noreferrer">https:&#x2F;&#x2F;codegolf.stackexchange.com&#x2F;a&#x2F;236630&#x2F;32575</a> &quot;High throughput Fizz Buzz&quot; where someone uses assembly to generate Fizz Buzz at around 54-56GiB&#x2F;s.</div><br/></div></div><div id="36621911" class="c"><input type="checkbox" id="c-36621911" checked=""/><div class="controls bullet"><span class="by">torstenvl</span><span>|</span><a href="#36625655">prev</a><span>|</span><a href="#36622501">next</a><span>|</span><label class="collapse" for="c-36621911">[-]</label><label class="expand" for="c-36621911">[4 more]</label></div><br/><div class="children"><div class="content">There&#x27;s an error in the pseudocode.<p><pre><code>      cmp     ecx, &#x27;s&#x27;            #   if (c == &#x27;s&#x27;)
      jne     loop                #     continue
      add     eax, 1              #   res++
      jmp     loop                #   continue
</code></pre>
should be<p><pre><code>      cmp     ecx, &#x27;s&#x27;            #   if (c != &#x27;s&#x27;)
      jne     loop                #     continue
      add     eax, 1              #   res++
      jmp     loop                #   continue</code></pre></div><br/><div id="36622987" class="c"><input type="checkbox" id="c-36622987" checked=""/><div class="controls bullet"><span class="by">agumonkey</span><span>|</span><a href="#36621911">parent</a><span>|</span><a href="#36623288">next</a><span>|</span><label class="collapse" for="c-36622987">[-]</label><label class="expand" for="c-36622987">[2 more]</label></div><br/><div class="children"><div class="content">I believe the first `jne` should be `je`, right ?</div><br/><div id="36623031" class="c"><input type="checkbox" id="c-36623031" checked=""/><div class="controls bullet"><span class="by">torstenvl</span><span>|</span><a href="#36621911">root</a><span>|</span><a href="#36622987">parent</a><span>|</span><a href="#36623288">next</a><span>|</span><label class="collapse" for="c-36623031">[-]</label><label class="expand" for="c-36623031">[1 more]</label></div><br/><div class="children"><div class="content">No, the assembler is correct.  Jump (early) back to the beginning of the loop if not equal to s; otherwise, continue executing the next instruction (add eax, 1) and then unconditionally jump back to the beginning of the loop.</div><br/></div></div></div></div></div></div><div id="36622501" class="c"><input type="checkbox" id="c-36622501" checked=""/><div class="controls bullet"><span class="by">aidenn0</span><span>|</span><a href="#36621911">prev</a><span>|</span><a href="#36623208">next</a><span>|</span><label class="collapse" for="c-36622501">[-]</label><label class="expand" for="c-36622501">[5 more]</label></div><br/><div class="children"><div class="content">A while back, I wrote a UTF-8 decoder in Common Lisp, targeting SBCL (it already has one built in, this was an exercise).  Pretty much all of the optimization win (after the obvious low-hanging fruit) was structuring the code so that the compiler would generate cmov* instructions rather than branches.</div><br/><div id="36622681" class="c"><input type="checkbox" id="c-36622681" checked=""/><div class="controls bullet"><span class="by">whartung</span><span>|</span><a href="#36622501">parent</a><span>|</span><a href="#36623188">next</a><span>|</span><label class="collapse" for="c-36622681">[-]</label><label class="expand" for="c-36622681">[2 more]</label></div><br/><div class="children"><div class="content">What&#x27;s some examples of the code changes that you made? And did you just do repeated disassemblies of the functions to see that it was using the correct instructions, or did you do some benchmarking to show your changes were actual improvements?</div><br/><div id="36623075" class="c"><input type="checkbox" id="c-36623075" checked=""/><div class="controls bullet"><span class="by">aidenn0</span><span>|</span><a href="#36622501">root</a><span>|</span><a href="#36622681">parent</a><span>|</span><a href="#36623188">next</a><span>|</span><label class="collapse" for="c-36623075">[-]</label><label class="expand" for="c-36623075">[1 more]</label></div><br/><div class="children"><div class="content">Gosh, I&#x27;d have to see if I can dig it up this was a few years ago.<p>I did all of the above, plus profiling (sb-sprof combined with disassemble will show assembly level profiling).</div><br/></div></div></div></div><div id="36623188" class="c"><input type="checkbox" id="c-36623188" checked=""/><div class="controls bullet"><span class="by">moonchild</span><span>|</span><a href="#36622501">parent</a><span>|</span><a href="#36622681">prev</a><span>|</span><a href="#36623208">next</a><span>|</span><label class="collapse" for="c-36623188">[-]</label><label class="expand" for="c-36623188">[2 more]</label></div><br/><div class="children"><div class="content">Branches are prone to be faster than conditional moves if they are correctly predicted, because they do not increase the critical path length.  And utf-8 decoders are commonly run on all-ascii input.  What were you benchmarking on?</div><br/><div id="36623422" class="c"><input type="checkbox" id="c-36623422" checked=""/><div class="controls bullet"><span class="by">aidenn0</span><span>|</span><a href="#36622501">root</a><span>|</span><a href="#36623188">parent</a><span>|</span><a href="#36623208">next</a><span>|</span><label class="collapse" for="c-36623422">[-]</label><label class="expand" for="c-36623422">[1 more]</label></div><br/><div class="children"><div class="content">I ran separate benchmarks on all-ASCII, BMP-only, and ascii with non-BMP.  ASCII was <i>not</i> slower on the low-branch version.</div><br/></div></div></div></div></div></div><div id="36623208" class="c"><input type="checkbox" id="c-36623208" checked=""/><div class="controls bullet"><span class="by">BoppreH</span><span>|</span><a href="#36622501">prev</a><span>|</span><a href="#36625163">next</a><span>|</span><label class="collapse" for="c-36623208">[-]</label><label class="expand" for="c-36623208">[3 more]</label></div><br/><div class="children"><div class="content">You can also use math to avoid most of the jumps:<p><pre><code>    int run_switches(char *input) {
      int res = 0;
      while (true) {
        char c = *input++;
        if (c == &#x27;\0&#x27;) return res;
        &#x2F;&#x2F; Here&#x27;s the trick:
        res += (c == &#x27;s&#x27;) - (c == &#x27;p&#x27;);
      }
    }
</code></pre>
This gives a 3.7x speed compared to loop-1.c. The lower line count is also nice.</div><br/><div id="36623319" class="c"><input type="checkbox" id="c-36623319" checked=""/><div class="controls bullet"><span class="by">svachalek</span><span>|</span><a href="#36623208">parent</a><span>|</span><a href="#36625163">next</a><span>|</span><label class="collapse" for="c-36623319">[-]</label><label class="expand" for="c-36623319">[2 more]</label></div><br/><div class="children"><div class="content">Nice. The way I read the cmove version, it&#x27;s more or less this except the trick line goes<p><pre><code>    res += (c == &#x27;s&#x27;) ? 1 : (c == &#x27;p&#x27;) ? -1 : 0
</code></pre>
I haven&#x27;t done C in decades so I don&#x27;t trust myself to performance test this but I&#x27;m curious how it compares. Pretty disappointed that TFA didn&#x27;t go back and try that in C.</div><br/><div id="36625014" class="c"><input type="checkbox" id="c-36625014" checked=""/><div class="controls bullet"><span class="by">414owen</span><span>|</span><a href="#36623208">root</a><span>|</span><a href="#36623319">parent</a><span>|</span><a href="#36625163">next</a><span>|</span><label class="collapse" for="c-36625014">[-]</label><label class="expand" for="c-36625014">[1 more]</label></div><br/><div class="children"><div class="content">So I actually did try that, but and IIRC it didn&#x27;t produce a CMOV with either gcc or clang. I didn&#x27;t put it in the repo because it wasn&#x27;t an improvement (on my machine) and I decided not to write about it.<p>Maybe you get different results though?</div><br/></div></div></div></div></div></div><div id="36625163" class="c"><input type="checkbox" id="c-36625163" checked=""/><div class="controls bullet"><span class="by">jtriangle</span><span>|</span><a href="#36623208">prev</a><span>|</span><a href="#36618345">next</a><span>|</span><label class="collapse" for="c-36625163">[-]</label><label class="expand" for="c-36625163">[8 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a cardinal rule that any time someone utters &quot;XYZ is n faster than C&quot; someone comes along and shows C is actually 2x faster than XYZ.</div><br/><div id="36625176" class="c"><input type="checkbox" id="c-36625176" checked=""/><div class="controls bullet"><span class="by">JohnMakin</span><span>|</span><a href="#36625163">parent</a><span>|</span><a href="#36618345">next</a><span>|</span><label class="collapse" for="c-36625176">[-]</label><label class="expand" for="c-36625176">[7 more]</label></div><br/><div class="children"><div class="content">I had an old compilers professor say something like this once. “If you think you can do something better than the C compiler, I promise you you can’t.”</div><br/><div id="36627938" class="c"><input type="checkbox" id="c-36627938" checked=""/><div class="controls bullet"><span class="by">zokier</span><span>|</span><a href="#36625163">root</a><span>|</span><a href="#36625176">parent</a><span>|</span><a href="#36625493">next</a><span>|</span><label class="collapse" for="c-36627938">[-]</label><label class="expand" for="c-36627938">[1 more]</label></div><br/><div class="children"><div class="content">That is just dumb and overly reductive. There is just lot of properties about programs that can not be expressed to compiler with portable ISO C but could be exploited for optimization. Of course reducing portability progressively improves situation, like using GCC extensions or machine-specific intrinsics. But even then its ridiculous to claim that C compilers could in general case generate true optimal code.</div><br/></div></div><div id="36625493" class="c"><input type="checkbox" id="c-36625493" checked=""/><div class="controls bullet"><span class="by">kstrauser</span><span>|</span><a href="#36625163">root</a><span>|</span><a href="#36625176">parent</a><span>|</span><a href="#36627938">prev</a><span>|</span><a href="#36627195">next</a><span>|</span><label class="collapse" for="c-36625493">[-]</label><label class="expand" for="c-36625493">[4 more]</label></div><br/><div class="children"><div class="content"><i>To a point</i>. A modern C compiler generates mind boggingly fast assembler. However, some languages make it way easier to write sophisticated algorithms more easily.<p>For instance, suppose you&#x27;re writing a program to find the nth Fibonacci number for whatever reason. In Python, the naive version might look like:<p><pre><code>  def fib(n):
      if n &lt;= 1:
          return n
      return fib(n - 1) + fib(n - 2)
</code></pre>
On my machine, that takes about 12 seconds to find the 40th number. Altering that slightly like:<p><pre><code>  from functools import cache
  @cache
  def fib(n): ...
</code></pre>
makes the whole program take about 30 milliseconds total. The 400th takes about 32ms and emits an answer that won&#x27;t fit in a 256-bit int.<p><i>Of course</i> you can do the exact same kind of caching in C! I mean, the main Python interpreter&#x27;s written in C, so by extension any algorithm you can express in Python you can also express in C. It&#x27;d probably be a lot faster, too!<p>But in practice, if I&#x27;m writing that in Python, I can use the obvious algorithm, spent 10 seconds slapping a caching decorator on it, verify that the end result is ridiculous fast and efficient, then move on to other problems.<p>Any reasonable C compiler will emit assembler that&#x27;s vastly better than anything I could come up with. Conversely, I personally can write far better algorithms in Python than I could in C, because it&#x27;s easier <i>for me</i> to express cleverness in that language. Those algorithmic improvements tend to have a far better speed payoff than I&#x27;d personally get from a more efficient implementation of a crappy method.</div><br/><div id="36625840" class="c"><input type="checkbox" id="c-36625840" checked=""/><div class="controls bullet"><span class="by">hinkley</span><span>|</span><a href="#36625163">root</a><span>|</span><a href="#36625493">parent</a><span>|</span><a href="#36627195">next</a><span>|</span><label class="collapse" for="c-36625840">[-]</label><label class="expand" for="c-36625840">[3 more]</label></div><br/><div class="children"><div class="content">How many brains has the Fibonacci example broken...<p>You&#x27;d unroll it to a loop on both C and Python. Fibonacci doesn&#x27;t need a cache. It needs K previous values, where K=1.</div><br/><div id="36629036" class="c"><input type="checkbox" id="c-36629036" checked=""/><div class="controls bullet"><span class="by">adament</span><span>|</span><a href="#36625163">root</a><span>|</span><a href="#36625840">parent</a><span>|</span><a href="#36626174">next</a><span>|</span><label class="collapse" for="c-36629036">[-]</label><label class="expand" for="c-36629036">[1 more]</label></div><br/><div class="children"><div class="content">If for some reason you really wanted to compute Fib(n) for ridiculously large numbers of n, you would probably use that [Fib(n), Fib(n-1)] = A [Fib(n-1), Fib(n-2)] for the transition matrix A = [[1, 1], [1, 0]] and thus [Fib(n+1), Fib(n)] = A^n [Fib(1), Fib(0)] and then use exponentiation by squaring to compute A^n directly and thus Fib(n) in log_2(n) steps.</div><br/></div></div><div id="36626174" class="c"><input type="checkbox" id="c-36626174" checked=""/><div class="controls bullet"><span class="by">kstrauser</span><span>|</span><a href="#36625163">root</a><span>|</span><a href="#36625840">parent</a><span>|</span><a href="#36629036">prev</a><span>|</span><a href="#36627195">next</a><span>|</span><label class="collapse" for="c-36626174">[-]</label><label class="expand" for="c-36626174">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, I almost said “suppose you were writing a Fibonacci program <i>because who did you annoy to make this your life now</i>...”<p>Like, obviously you’re not going to be writing `fib(n)` for real. I still claim that other languages — not just Python, either — make it easier to express cleverer algorithms than C does. You can’t write anything in Rust you can’t write in C, but it’ll probably be easier to say it more efficiently, and more correctly, in Rust. And much of the time, using a better design is going to blow compiler improvements out of the water.<p>(The professor was right if you limit the scope of the statement to “programs written in C or assembler”, of course. Unless you’re a freaking genius, a compiler’s going to write better object code.)</div><br/></div></div></div></div></div></div><div id="36627195" class="c"><input type="checkbox" id="c-36627195" checked=""/><div class="controls bullet"><span class="by">saagarjha</span><span>|</span><a href="#36625163">root</a><span>|</span><a href="#36625176">parent</a><span>|</span><a href="#36625493">prev</a><span>|</span><a href="#36618345">next</a><span>|</span><label class="collapse" for="c-36627195">[-]</label><label class="expand" for="c-36627195">[1 more]</label></div><br/><div class="children"><div class="content">Someone has to teach the compiler how to be clever.</div><br/></div></div></div></div></div></div><div id="36618345" class="c"><input type="checkbox" id="c-36618345" checked=""/><div class="controls bullet"><span class="by">414owen</span><span>|</span><a href="#36625163">prev</a><span>|</span><a href="#36623878">next</a><span>|</span><label class="collapse" for="c-36618345">[-]</label><label class="expand" for="c-36618345">[14 more]</label></div><br/><div class="children"><div class="content">A clickbait title for an in-depth look at hand-optimizing a very simple loop.</div><br/><div id="36623217" class="c"><input type="checkbox" id="c-36623217" checked=""/><div class="controls bullet"><span class="by">ftxbro</span><span>|</span><a href="#36618345">parent</a><span>|</span><a href="#36623878">next</a><span>|</span><label class="collapse" for="c-36623217">[-]</label><label class="expand" for="c-36623217">[13 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not a compiler expert but if it&#x27;s a &quot;very simple loop&quot; is it still too complex for the compiler to make good machine code? Did they use a bad compiler on purpose? Or are computers just not yet fast enough to do a good job with very simple loops in practical compilers?</div><br/><div id="36623568" class="c"><input type="checkbox" id="c-36623568" checked=""/><div class="controls bullet"><span class="by">moonchild</span><span>|</span><a href="#36618345">root</a><span>|</span><a href="#36623217">parent</a><span>|</span><a href="#36623521">next</a><span>|</span><label class="collapse" for="c-36623568">[-]</label><label class="expand" for="c-36623568">[1 more]</label></div><br/><div class="children"><div class="content">&gt; are computers just not yet fast enough to do a good job with very simple loops in practical compilers?<p>The short answer to this question is &#x27;yes&#x27;, but there are some extenuating factors:<p>- Although we could do interesting things with unlimited computational resources, the current crop of c compilers is simply not very good, compared with what&#x27;s possible today.<p>- Performance is always workload-dependent; the compiler has been somewhat shafted here because it doesn&#x27;t know what sorts of inputs the function usually receives.  The compiler output is better than the &#x27;improved&#x27; code for some inputs.  (It&#x27;s possible you could get a better result from the existing compilers and c code just by using profile-guided optimisation.)<p>- The difference is prone to be more pronounced in simple loops than large ones.  This is a contrived use-case.  There is not a factor of 6 of performance hiding in optimised c code which could be recovered by doing the sorts of optimisations done by the op.  Probably something more like 10-20%.</div><br/></div></div><div id="36623521" class="c"><input type="checkbox" id="c-36623521" checked=""/><div class="controls bullet"><span class="by">cjensen</span><span>|</span><a href="#36618345">root</a><span>|</span><a href="#36623217">parent</a><span>|</span><a href="#36623568">prev</a><span>|</span><a href="#36623420">next</a><span>|</span><label class="collapse" for="c-36623521">[-]</label><label class="expand" for="c-36623521">[6 more]</label></div><br/><div class="children"><div class="content">The problem is the author of the article is making some huge implicit assumptions that the compiler can&#x27;t possibly know about.<p>Consider this statement: &quot;However, we know some things about this loop. We know that the only time we break out of it is when we hit the null terminator (’\0’). The code clang generates checks for the null terminator first, but this makes no sense.&quot;<p>This statement contains huge assumptions about the lengths of the input strings and the frequency of the letters &#x27;s&#x27; and &#x27;p&#x27; in the input. And then has the chutzpah to call the compiler&#x27;s failure to read his mind about this as &quot;making no sense.&quot;<p>Good first effort by the author, but has not sufficiently thought through the problem.</div><br/><div id="36624742" class="c"><input type="checkbox" id="c-36624742" checked=""/><div class="controls bullet"><span class="by">414owen</span><span>|</span><a href="#36618345">root</a><span>|</span><a href="#36623521">parent</a><span>|</span><a href="#36624800">next</a><span>|</span><label class="collapse" for="c-36624742">[-]</label><label class="expand" for="c-36624742">[4 more]</label></div><br/><div class="children"><div class="content">That&#x27;s the thing, a C compiler has all the information it needs to know that the maximum amount of times a &#x27;\0&#x27; can be processed in the loop is once (because the function returns), but there&#x27;s no upper bound on the amount of times other characters are seen in the loop.<p>I might be missing a reason that this information of opaque to the compiler though, in which case, this section of the article is indeed lacking, but I&#x27;m happy to learn :)</div><br/><div id="36625050" class="c"><input type="checkbox" id="c-36625050" checked=""/><div class="controls bullet"><span class="by">cjensen</span><span>|</span><a href="#36618345">root</a><span>|</span><a href="#36624742">parent</a><span>|</span><a href="#36626866">next</a><span>|</span><label class="collapse" for="c-36625050">[-]</label><label class="expand" for="c-36625050">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not just that the C compiler lacks the information... but the <i>reader</i> of this article also lacks this information.<p>String length tells you the frequency with which nul terminators will be found. Without knowing frequency of occurrence of the nul terminator, &#x27;s&#x27;, and &#x27;p&#x27; then you cannot know which one occurs most often.<p>Consider two benchmark cases:
(1) every string tested contains exactly one character
(2) every string tested is 1MB long and is composed entirely of &#x27;s&#x27; and &#x27;p&#x27;.<p>The author&#x27;s first &quot;optimization&quot; assumes nul is rare. It would make benchmark (1) worse, and (2) better.<p>The article is a good example of &quot;specification is hard, code is easy.&quot; He insufficiently specified the problem to be solved, and his test cases contained information not in the code and not in the text of the article.</div><br/><div id="36628372" class="c"><input type="checkbox" id="c-36628372" checked=""/><div class="controls bullet"><span class="by">414owen</span><span>|</span><a href="#36618345">root</a><span>|</span><a href="#36625050">parent</a><span>|</span><a href="#36626866">next</a><span>|</span><label class="collapse" for="c-36628372">[-]</label><label class="expand" for="c-36628372">[1 more]</label></div><br/><div class="children"><div class="content">I guess the question is whether the compiler should optimize a function containing a loop for a single null terminator, or for more data.<p>I would suggest the latter is what you want most of the time.<p>There&#x27;s also the option of running a quick check for the null terminator before the loop, and then optimizing the loop for the other options.<p>But in any case, I think the demonstration of the technique of rearranging branches is interesting, and I needed a program to apply it to.</div><br/></div></div></div></div><div id="36626866" class="c"><input type="checkbox" id="c-36626866" checked=""/><div class="controls bullet"><span class="by">aengvs</span><span>|</span><a href="#36618345">root</a><span>|</span><a href="#36624742">parent</a><span>|</span><a href="#36625050">prev</a><span>|</span><a href="#36624800">next</a><span>|</span><label class="collapse" for="c-36626866">[-]</label><label class="expand" for="c-36626866">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not the upper bound that matters but the frequency. How frequently should the compiler assume an &#x27;s&#x27; appears in the dataset, or any other character?<p>We know that E[# of &#x27;\0&#x27; in a string] == 1.<p>But what is E[# of &#x27;s&#x27; in a string]? Is it greater or less than E[# of &#x27;\0&#x27; in a string], and how should the compiler know this?<p>You haven&#x27;t given the compiler any reason to assume that &#x27;s&#x27; or &#x27;p&#x27; will appear more often than &#x27;\0&#x27;.</div><br/></div></div></div></div><div id="36624800" class="c"><input type="checkbox" id="c-36624800" checked=""/><div class="controls bullet"><span class="by">smcin</span><span>|</span><a href="#36618345">root</a><span>|</span><a href="#36623521">parent</a><span>|</span><a href="#36624742">prev</a><span>|</span><a href="#36623420">next</a><span>|</span><label class="collapse" for="c-36624800">[-]</label><label class="expand" for="c-36624800">[1 more]</label></div><br/><div class="children"><div class="content">Ok the author should have written <i>&quot;this makes no sense... on this particular case&quot;</i></div><br/></div></div></div></div><div id="36623420" class="c"><input type="checkbox" id="c-36623420" checked=""/><div class="controls bullet"><span class="by">twoodfin</span><span>|</span><a href="#36618345">root</a><span>|</span><a href="#36623217">parent</a><span>|</span><a href="#36623521">prev</a><span>|</span><a href="#36623878">next</a><span>|</span><label class="collapse" for="c-36623420">[-]</label><label class="expand" for="c-36623420">[5 more]</label></div><br/><div class="children"><div class="content">This is the right answer:<p><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36622584">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36622584</a><p>Optimal assembly (forgoing SIMD, at least) for this loop on modern x86 is highly dependent on the entropy of the runtime data.</div><br/><div id="36623456" class="c"><input type="checkbox" id="c-36623456" checked=""/><div class="controls bullet"><span class="by">ftxbro</span><span>|</span><a href="#36618345">root</a><span>|</span><a href="#36623420">parent</a><span>|</span><a href="#36623878">next</a><span>|</span><label class="collapse" for="c-36623456">[-]</label><label class="expand" for="c-36623456">[4 more]</label></div><br/><div class="children"><div class="content">OK so they were abusing the benchmark, like the compiler&#x27;s output would be faster on less contrived test data? Do I have to search what are fdo or pgo or cmov to understand the answer?</div><br/><div id="36623759" class="c"><input type="checkbox" id="c-36623759" checked=""/><div class="controls bullet"><span class="by">tylerhou</span><span>|</span><a href="#36618345">root</a><span>|</span><a href="#36623456">parent</a><span>|</span><a href="#36623878">next</a><span>|</span><label class="collapse" for="c-36623759">[-]</label><label class="expand" for="c-36623759">[3 more]</label></div><br/><div class="children"><div class="content">The compiler will generate different code if it knew the rates at which branches were taken.<p>If a branch is almost always taken or almost never taken, a compiler will want to emit a jump. The frontend will be able to predict the jump with high probability, and a successfully-predicted jump is &quot;free.&quot; The cost of a misprediction is paid for by the near-zero cost of the many successful predictions.<p>If a branch is hard to predict (and taking versus not taking it would load a different value into a register&#x2F;memory), the compiler wants to emit a conditional move (cmov). A conditional move is slightly &quot;more expensive&quot; in the backend because the CPU has to wait for the condition to resolve before it can execute instructions dependent on the output. However, it is much cheaper than many mispredicted branches (mispredicts around half of the time).<p>FDO (feedback-directed optimization) or PGO (profile-guided optimization) means &quot;run the code on some sample input and profile how often branches are taken&#x2F;not taken.&quot; It gives the compiler more information to generate better code.<p>The problem with the blog post is that the compiler has no idea what the function&#x27;s input data will look like. It (arbitrarily) chose to generate branches instead of cmovs. However, if the benchmark input is better suited for cmovs, then the benchmark will (wrongly) show that the compiler generates &quot;slow&quot; assembly. But that&#x27;s not a fair test, because with PGO&#x2F;FDO the compiler would generate equivalent assembly to the &quot;fast&quot; assembly (actually, probably faster). Finally, the human (OP) is using their knowledge of the benchmark data &quot;unfairly&quot; to write better assembly than the compiler.<p>The takeaway is: most of the time, one can&#x27;t optimize code&#x2F;assembly in a vacuum. You also need to know what the input data and access patterns look like. FDO&#x2F;PGO gives the compiler more data to understand what the input data&#x2F;access patterns look like.</div><br/><div id="36623960" class="c"><input type="checkbox" id="c-36623960" checked=""/><div class="controls bullet"><span class="by">ftxbro</span><span>|</span><a href="#36618345">root</a><span>|</span><a href="#36623759">parent</a><span>|</span><a href="#36623878">next</a><span>|</span><label class="collapse" for="c-36623960">[-]</label><label class="expand" for="c-36623960">[2 more]</label></div><br/><div class="children"><div class="content">Thank you this is an amazingly comprehensive answer! Now I wonder what would be the workflow for using these compiler features. Like if I am a normal or bad C programmer and I write my program and use valgrind to check that it doesn&#x27;t have obvious problems and I compile it with -march native or whatever, then I can add some step to the workflow to somehow re-compile it in a way that uses the branching or access patterns of some examples that I let it process for that purpose?</div><br/><div id="36623995" class="c"><input type="checkbox" id="c-36623995" checked=""/><div class="controls bullet"><span class="by">tylerhou</span><span>|</span><a href="#36618345">root</a><span>|</span><a href="#36623960">parent</a><span>|</span><a href="#36623878">next</a><span>|</span><label class="collapse" for="c-36623995">[-]</label><label class="expand" for="c-36623995">[1 more]</label></div><br/><div class="children"><div class="content">Yes, Clang supports FDO, but it might be hard to set up (I&#x27;ve never set up FDO myself). You could check out <a href="https:&#x2F;&#x2F;github.com&#x2F;google&#x2F;autofdo">https:&#x2F;&#x2F;github.com&#x2F;google&#x2F;autofdo</a> and <a href="https:&#x2F;&#x2F;clang.llvm.org&#x2F;docs&#x2F;UsersManual.html#profile-guided-optimization" rel="nofollow noreferrer">https:&#x2F;&#x2F;clang.llvm.org&#x2F;docs&#x2F;UsersManual.html#profile-guided-...</a>.<p>(People within Google say &quot;FDO&quot;, basically everyone else says &quot;PGO&quot;.)</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="36623878" class="c"><input type="checkbox" id="c-36623878" checked=""/><div class="controls bullet"><span class="by">gavinray</span><span>|</span><a href="#36618345">prev</a><span>|</span><a href="#36622216">next</a><span>|</span><label class="collapse" for="c-36623878">[-]</label><label class="expand" for="c-36623878">[2 more]</label></div><br/><div class="children"><div class="content">Fantastic post, I appreciated that the ASM was displayed in tabs as both &quot;standard&quot; and &quot;visual-arrows&quot;-annotated.<p>Kept me reading into the follow-up article.<p>Also, I love the UI of this blog.</div><br/><div id="36628757" class="c"><input type="checkbox" id="c-36628757" checked=""/><div class="controls bullet"><span class="by">414owen</span><span>|</span><a href="#36623878">parent</a><span>|</span><a href="#36622216">next</a><span>|</span><label class="collapse" for="c-36628757">[-]</label><label class="expand" for="c-36628757">[1 more]</label></div><br/><div class="children"><div class="content">Kind words, much appreciated!</div><br/></div></div></div></div><div id="36622216" class="c"><input type="checkbox" id="c-36622216" checked=""/><div class="controls bullet"><span class="by">vardump</span><span>|</span><a href="#36623878">prev</a><span>|</span><a href="#36626202">next</a><span>|</span><label class="collapse" for="c-36622216">[-]</label><label class="expand" for="c-36622216">[1 more]</label></div><br/><div class="children"><div class="content">I think it&#x27;s straightforward to optimize to a point it&#x27;s maybe about 10x faster than the &quot;optimized&quot; version. The answer is of course SIMD vectorization.</div><br/></div></div><div id="36626202" class="c"><input type="checkbox" id="c-36626202" checked=""/><div class="controls bullet"><span class="by">sitkack</span><span>|</span><a href="#36622216">prev</a><span>|</span><a href="#36624255">next</a><span>|</span><label class="collapse" for="c-36626202">[-]</label><label class="expand" for="c-36626202">[1 more]</label></div><br/><div class="children"><div class="content">This is such a wonderful post! Heavenly.</div><br/></div></div><div id="36624255" class="c"><input type="checkbox" id="c-36624255" checked=""/><div class="controls bullet"><span class="by">lukas099</span><span>|</span><a href="#36626202">prev</a><span>|</span><a href="#36623236">next</a><span>|</span><label class="collapse" for="c-36624255">[-]</label><label class="expand" for="c-36624255">[2 more]</label></div><br/><div class="children"><div class="content">Would it be possible to write a code profiler and compiler that work together to optimize code based on real-world data? The profiler would output data that would feed back into the compiler, telling it which branches were selected most often, which would recompile optimizing for the profile. Would this even work? Has it already been done?</div><br/><div id="36624576" class="c"><input type="checkbox" id="c-36624576" checked=""/><div class="controls bullet"><span class="by">garenp</span><span>|</span><a href="#36624255">parent</a><span>|</span><a href="#36623236">next</a><span>|</span><label class="collapse" for="c-36624576">[-]</label><label class="expand" for="c-36624576">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a thing:
<a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Profile-guided_optimization" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Profile-guided_optimization</a></div><br/></div></div></div></div><div id="36623236" class="c"><input type="checkbox" id="c-36623236" checked=""/><div class="controls bullet"><span class="by">failuser</span><span>|</span><a href="#36624255">prev</a><span>|</span><a href="#36627918">next</a><span>|</span><label class="collapse" for="c-36623236">[-]</label><label class="expand" for="c-36623236">[1 more]</label></div><br/><div class="children"><div class="content">Having a full-blown predicate support is so nice to have, but it interferes with compact instruction encoding.<p>Such bloated ISA like x86 might actually handle predicate support, but who will try such a radical change?</div><br/></div></div><div id="36627918" class="c"><input type="checkbox" id="c-36627918" checked=""/><div class="controls bullet"><span class="by">olliej</span><span>|</span><a href="#36623236">prev</a><span>|</span><a href="#36625653">next</a><span>|</span><label class="collapse" for="c-36627918">[-]</label><label class="expand" for="c-36627918">[1 more]</label></div><br/><div class="children"><div class="content">I see other people have done minor rewrites, but the post does mention reordering branches, so the obvious question is whether there was any attempt to use PGO, which is an obvious first step in optimization.</div><br/></div></div><div id="36625653" class="c"><input type="checkbox" id="c-36625653" checked=""/><div class="controls bullet"><span class="by">throwaway14356</span><span>|</span><a href="#36627918">prev</a><span>|</span><a href="#36624513">next</a><span>|</span><label class="collapse" for="c-36625653">[-]</label><label class="expand" for="c-36625653">[3 more]</label></div><br/><div class="children"><div class="content">naive q: could one just count one of the letters and subtract it from the total number of letters?</div><br/><div id="36627211" class="c"><input type="checkbox" id="c-36627211" checked=""/><div class="controls bullet"><span class="by">saagarjha</span><span>|</span><a href="#36625653">parent</a><span>|</span><a href="#36624513">next</a><span>|</span><label class="collapse" for="c-36627211">[-]</label><label class="expand" for="c-36627211">[2 more]</label></div><br/><div class="children"><div class="content">You’d need to count both as other characters are ignored.</div><br/><div id="36628004" class="c"><input type="checkbox" id="c-36628004" checked=""/><div class="controls bullet"><span class="by">throwaway14356</span><span>|</span><a href="#36625653">root</a><span>|</span><a href="#36627211">parent</a><span>|</span><a href="#36624513">next</a><span>|</span><label class="collapse" for="c-36628004">[-]</label><label class="expand" for="c-36628004">[1 more]</label></div><br/><div class="children"><div class="content">naïve q2: does that mean most comparisons are no match 3 times? could one do a bitwise operation and fuzzy test for all 3 in one go?</div><br/></div></div></div></div></div></div><div id="36624513" class="c"><input type="checkbox" id="c-36624513" checked=""/><div class="controls bullet"><span class="by">kristianpaul</span><span>|</span><a href="#36625653">prev</a><span>|</span><a href="#36623375">next</a><span>|</span><label class="collapse" for="c-36624513">[-]</label><label class="expand" for="c-36624513">[1 more]</label></div><br/><div class="children"><div class="content">How fast is forth compared to C these days?</div><br/></div></div><div id="36623375" class="c"><input type="checkbox" id="c-36623375" checked=""/><div class="controls bullet"><span class="by">RobotToaster</span><span>|</span><a href="#36624513">prev</a><span>|</span><a href="#36627917">next</a><span>|</span><label class="collapse" for="c-36623375">[-]</label><label class="expand" for="c-36623375">[2 more]</label></div><br/><div class="children"><div class="content">Was the C compiled with optimisation enabled?</div><br/><div id="36623500" class="c"><input type="checkbox" id="c-36623500" checked=""/><div class="controls bullet"><span class="by">414owen</span><span>|</span><a href="#36623375">parent</a><span>|</span><a href="#36627917">next</a><span>|</span><label class="collapse" for="c-36623500">[-]</label><label class="expand" for="c-36623500">[1 more]</label></div><br/><div class="children"><div class="content">Yes, I explained in the `Benchmarking setup` section that I used `march=native`, but I guess I forgot to mention I used -O3.</div><br/></div></div></div></div></div></div></div></div></div></body></html>