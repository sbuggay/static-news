<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1737795674365" as="style"/><link rel="stylesheet" href="styles.css?v=1737795674365"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/lightpanda-io/browser">Show HN: Lightpanda, an open-source headless browser in Zig</a> <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>fbouvier</span> | <span>101 comments</span></div><br/><div><div id="42812928" class="c"><input type="checkbox" id="c-42812928" checked=""/><div class="controls bullet"><span class="by">fbouvier</span><span>|</span><a href="#42820445">next</a><span>|</span><label class="collapse" for="c-42812928">[-]</label><label class="expand" for="c-42812928">[45 more]</label></div><br/><div class="children"><div class="content">Author here. The browser is made from scratch (not based on Chromium&#x2F;Webkit), in Zig, using v8 as a JS engine.<p>Our idea is to build a lightweight browser optimized for AI use cases like LLM training and agent workflows. And more generally any type of web automation.<p>It&#x27;s a work in progress, there are hundreds of Web APIs, and for now we just support some of them (DOM, XHR, Fetch). So expect most websites to fail or crash. The plan is to increase coverage over time.<p>Happy to answer any questions.</div><br/><div id="42814724" class="c"><input type="checkbox" id="c-42814724" checked=""/><div class="controls bullet"><span class="by">JoelEinbinder</span><span>|</span><a href="#42812928">parent</a><span>|</span><a href="#42815546">next</a><span>|</span><label class="collapse" for="c-42814724">[-]</label><label class="expand" for="c-42814724">[14 more]</label></div><br/><div class="children"><div class="content">When I&#x27;ve talked to people running this kind of ai scraping&#x2F;agent workflow, the costs of the AI parts dwarf that of the web browser parts. This causes computational cost of the browser to become irrelevant. I&#x27;m curious what situation you got yourself in where optimizing the browser results in meaningful savings. I&#x27;d also like to be in that place!<p>I think your ram usage benchmark is deceptive. I&#x27;d expect a minimal browser to have much lower peak memory usage than chrome on a minimal website. But it should even out or get worse as the websites get richer. The nature of web scraping is that the worst sites take up the vast majority of your cpu cycles. I don&#x27;t think lowering the ram usage of the browser process will have much real world impact.</div><br/><div id="42815171" class="c"><input type="checkbox" id="c-42815171" checked=""/><div class="controls bullet"><span class="by">fbouvier</span><span>|</span><a href="#42812928">root</a><span>|</span><a href="#42814724">parent</a><span>|</span><a href="#42815086">next</a><span>|</span><label class="collapse" for="c-42815171">[-]</label><label class="expand" for="c-42815171">[10 more]</label></div><br/><div class="children"><div class="content">The cost of the browser part is still a problem. In our previous startup, we were scraping &gt;20 millions of webpages per day, with thousands of instances of Chrome headless in parallel.<p>Regarding the RAM usage, it&#x27;s still ~10x better than Chrome :) It seems to be coming mostly from v8, I guess that we could do better with a lightweight JS engine alternative.</div><br/><div id="42816523" class="c"><input type="checkbox" id="c-42816523" checked=""/><div class="controls bullet"><span class="by">cush</span><span>|</span><a href="#42812928">root</a><span>|</span><a href="#42815171">parent</a><span>|</span><a href="#42816943">next</a><span>|</span><label class="collapse" for="c-42816523">[-]</label><label class="expand" for="c-42816523">[1 more]</label></div><br/><div class="children"><div class="content">&gt; there are hundreds of Web APIs, and for now we just support some of them (DOM, XHR, Fetch)<p>&gt; it&#x27;s still ~10x better than Chrome<p>Do you expect it to stay that way once you&#x27;ve reached parity?</div><br/></div></div><div id="42816943" class="c"><input type="checkbox" id="c-42816943" checked=""/><div class="controls bullet"><span class="by">nwienert</span><span>|</span><a href="#42812928">root</a><span>|</span><a href="#42815171">parent</a><span>|</span><a href="#42816523">prev</a><span>|</span><a href="#42818690">next</a><span>|</span><label class="collapse" for="c-42816943">[-]</label><label class="expand" for="c-42816943">[3 more]</label></div><br/><div class="children"><div class="content">Playwright can run webkit very easily and it&#x27;s dramatically less resource-intensive than Chrome.</div><br/><div id="42817875" class="c"><input type="checkbox" id="c-42817875" checked=""/><div class="controls bullet"><span class="by">fbouvier</span><span>|</span><a href="#42812928">root</a><span>|</span><a href="#42816943">parent</a><span>|</span><a href="#42818690">next</a><span>|</span><label class="collapse" for="c-42817875">[-]</label><label class="expand" for="c-42817875">[2 more]</label></div><br/><div class="children"><div class="content">Yes but WebKit is not a browser per se, it&#x27;s a rendering engine.<p>It&#x27;s less resource-intensive than Chrome, but here we are talking orders of magnitude between Lightpanda and Chrome. If you are ~10x faster while using ~10x less RAM you are using ~100x less resources.</div><br/><div id="42818518" class="c"><input type="checkbox" id="c-42818518" checked=""/><div class="controls bullet"><span class="by">bdhcuidbebe</span><span>|</span><a href="#42812928">root</a><span>|</span><a href="#42817875">parent</a><span>|</span><a href="#42818690">next</a><span>|</span><label class="collapse" for="c-42818518">[-]</label><label class="expand" for="c-42818518">[1 more]</label></div><br/><div class="children"><div class="content">How well does it compare to specialized headless scraper browsers, like camoufox (firefox based) or secret agent (chrome based)?<p>Either should reduce your ram usage compared to stock chrome by a lot.</div><br/></div></div></div></div></div></div><div id="42818690" class="c"><input type="checkbox" id="c-42818690" checked=""/><div class="controls bullet"><span class="by">radium3d</span><span>|</span><a href="#42812928">root</a><span>|</span><a href="#42815171">parent</a><span>|</span><a href="#42816943">prev</a><span>|</span><a href="#42815456">next</a><span>|</span><label class="collapse" for="c-42818690">[-]</label><label class="expand" for="c-42818690">[1 more]</label></div><br/><div class="children"><div class="content">As a web developer and server manager AI trainers scraping websites with no throttle <i>is</i> the problem. lol</div><br/></div></div><div id="42815456" class="c"><input type="checkbox" id="c-42815456" checked=""/><div class="controls bullet"><span class="by">Tostino</span><span>|</span><a href="#42812928">root</a><span>|</span><a href="#42815171">parent</a><span>|</span><a href="#42818690">prev</a><span>|</span><a href="#42815086">next</a><span>|</span><label class="collapse" for="c-42815456">[-]</label><label class="expand" for="c-42815456">[4 more]</label></div><br/><div class="children"><div class="content">You may reduce ram, but also performance. A good JIT costs ram.</div><br/><div id="42815601" class="c"><input type="checkbox" id="c-42815601" checked=""/><div class="controls bullet"><span class="by">fbouvier</span><span>|</span><a href="#42812928">root</a><span>|</span><a href="#42815456">parent</a><span>|</span><a href="#42819510">next</a><span>|</span><label class="collapse" for="c-42815601">[-]</label><label class="expand" for="c-42815601">[2 more]</label></div><br/><div class="children"><div class="content">Yes, that&#x27;s true. It&#x27;s a balance to find between RAM and speed.<p>I was thinking more on use cases that require to disable JIT anyway (WASM, iOS integration, security).</div><br/><div id="42815636" class="c"><input type="checkbox" id="c-42815636" checked=""/><div class="controls bullet"><span class="by">Tostino</span><span>|</span><a href="#42812928">root</a><span>|</span><a href="#42815601">parent</a><span>|</span><a href="#42819510">next</a><span>|</span><label class="collapse" for="c-42815636">[-]</label><label class="expand" for="c-42815636">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, could be nice to allow the user to select the type of ECMAScript engine that fits their use-case &#x2F; performance requirements (balancing the resources available).</div><br/></div></div></div></div><div id="42819510" class="c"><input type="checkbox" id="c-42819510" checked=""/><div class="controls bullet"><span class="by">cxr</span><span>|</span><a href="#42812928">root</a><span>|</span><a href="#42815456">parent</a><span>|</span><a href="#42815601">prev</a><span>|</span><a href="#42815086">next</a><span>|</span><label class="collapse" for="c-42819510">[-]</label><label class="expand" for="c-42819510">[1 more]</label></div><br/><div class="children"><div class="content">If your target is consistent enough (perhaps even stationary), then at some point &quot;JIT&quot; means <i>wasting</i> CPU cycles.</div><br/></div></div></div></div></div></div><div id="42815086" class="c"><input type="checkbox" id="c-42815086" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#42812928">root</a><span>|</span><a href="#42814724">parent</a><span>|</span><a href="#42815171">prev</a><span>|</span><a href="#42815546">next</a><span>|</span><label class="collapse" for="c-42815086">[-]</label><label class="expand" for="c-42815086">[3 more]</label></div><br/><div class="children"><div class="content">Generally, for consumer use cases, it&#x27;s best to A) do it locally, preserving some of the original web contract B) run JS to get actual content C) post-process to reduce inference cost D) get latency as low as possible<p>Then, as the article points out, the Big Guns making the LLMs are a big use case for this because they get a 10x speedup and can begin contemplating running JS.<p>It sounds like the people you&#x27;ve talked to are in a messy middle: no incentive to improve efficiency of loading pages, simply because there&#x27;s something else in the system that has a fixed cost to it.<p>I&#x27;m not sure why that would rule out improving anything else, it doesn&#x27;t seem they should be stuck doing nothing other than flailing around for cheaper LLM inference.<p>&gt; I think your ram usage benchmark is deceptive. I&#x27;d expect a minimal browser to have much lower peak memory usage than chrome on a minimal website.<p>I&#x27;m a bit lost, the ram usage benchmark says its ~10x less, and you feel its deceptive because you&#x27;d expect ram usage to be less? Steelmanning: 10% of Chrome&#x27;s usage is <i>still</i> too high?</div><br/><div id="42815163" class="c"><input type="checkbox" id="c-42815163" checked=""/><div class="controls bullet"><span class="by">JoelEinbinder</span><span>|</span><a href="#42812928">root</a><span>|</span><a href="#42815086">parent</a><span>|</span><a href="#42815546">next</a><span>|</span><label class="collapse" for="c-42815163">[-]</label><label class="expand" for="c-42815163">[2 more]</label></div><br/><div class="children"><div class="content">The benchmark shows lower ram usage on a very simple demo website. I expect that if the benchmark ran on a random set of real websites, ram usage would not be meaningfully lower than Chrome. Happy to be impressed and wrong if it remains lower.</div><br/><div id="42815229" class="c"><input type="checkbox" id="c-42815229" checked=""/><div class="controls bullet"><span class="by">fbouvier</span><span>|</span><a href="#42812928">root</a><span>|</span><a href="#42815163">parent</a><span>|</span><a href="#42815546">next</a><span>|</span><label class="collapse" for="c-42815229">[-]</label><label class="expand" for="c-42815229">[1 more]</label></div><br/><div class="children"><div class="content">I believe it will be still significantly lower as we skip the graphical rendering.<p>But to validate that we need to increase our Web APIs coverage.</div><br/></div></div></div></div></div></div></div></div><div id="42815546" class="c"><input type="checkbox" id="c-42815546" checked=""/><div class="controls bullet"><span class="by">bityard</span><span>|</span><a href="#42812928">parent</a><span>|</span><a href="#42814724">prev</a><span>|</span><a href="#42817053">next</a><span>|</span><label class="collapse" for="c-42815546">[-]</label><label class="expand" for="c-42815546">[16 more]</label></div><br/><div class="children"><div class="content">Please put a priority on making it hard to abuse the web with your tool.<p>At a _bare_ minimum, that means obeying robot.txt and NOT crawling a site that doesn&#x27;t want to be crawled. And there should not be an option to override that. It goes without saying that you should not allow users to make hundreds or thousands of &quot;blind&quot; parallel requests as these tend to have the effect of DoSing sites that are being hosted on modest hardware. You should also be measuring response times and throttling your requests accordingly. If a website issues a response code or other signal that you are hitting it too fast or too often, slow down.<p>I say this because since around the start of the new year, AI bots have been ravaging what&#x27;s left of the open web and causing REAL stress and problems for admins of small and mid-sized websites and their human visitors: <a href="https:&#x2F;&#x2F;www.heise.de&#x2F;en&#x2F;news&#x2F;AI-bots-paralyze-Linux-news-site-and-others-10252162.html" rel="nofollow">https:&#x2F;&#x2F;www.heise.de&#x2F;en&#x2F;news&#x2F;AI-bots-paralyze-Linux-news-sit...</a></div><br/><div id="42815962" class="c"><input type="checkbox" id="c-42815962" checked=""/><div class="controls bullet"><span class="by">gkbrk</span><span>|</span><a href="#42812928">root</a><span>|</span><a href="#42815546">parent</a><span>|</span><a href="#42819586">next</a><span>|</span><label class="collapse" for="c-42815962">[-]</label><label class="expand" for="c-42815962">[10 more]</label></div><br/><div class="children"><div class="content">Please don&#x27;t.<p>Software I installed on my computer needs to the what I want as the user. I don&#x27;t want every random thing I install to come with DRM.<p>The project looks useful, and if it ends up getting popular I imagine someone would make a DRM-free version anyway.</div><br/><div id="42816001" class="c"><input type="checkbox" id="c-42816001" checked=""/><div class="controls bullet"><span class="by">tossandthrow</span><span>|</span><a href="#42812928">root</a><span>|</span><a href="#42815962">parent</a><span>|</span><a href="#42816195">next</a><span>|</span><label class="collapse" for="c-42816001">[-]</label><label class="expand" for="c-42816001">[5 more]</label></div><br/><div class="children"><div class="content">Where do you read DRM?<p>Parent commenter merely and humbly asks the author of the library to make sure that it has sane defaults and support for ethical crawling.<p>I find it disturbing that you would recommend against that.</div><br/><div id="42816030" class="c"><input type="checkbox" id="c-42816030" checked=""/><div class="controls bullet"><span class="by">gkbrk</span><span>|</span><a href="#42812928">root</a><span>|</span><a href="#42816001">parent</a><span>|</span><a href="#42816195">next</a><span>|</span><label class="collapse" for="c-42816030">[-]</label><label class="expand" for="c-42816030">[4 more]</label></div><br/><div class="children"><div class="content">Here&#x27;s what the parent comment wrote.<p>&gt; And there should not be an option to override that.<p>This is not just a sane default. This is software telling you what you are allowed to do based on what the rights owner wants, literally DRM.<p>This is exactly like Android not allowing screenshots to be taken in certain apps because the rights owner didn&#x27;t allow it.</div><br/><div id="42816247" class="c"><input type="checkbox" id="c-42816247" checked=""/><div class="controls bullet"><span class="by">blacksmith_tb</span><span>|</span><a href="#42812928">root</a><span>|</span><a href="#42816030">parent</a><span>|</span><a href="#42816851">next</a><span>|</span><label class="collapse" for="c-42816247">[-]</label><label class="expand" for="c-42816247">[2 more]</label></div><br/><div class="children"><div class="content">Not sure what &quot;digital rights&quot; that &quot;manages&quot;? I don&#x27;t see it as an unreasonable suggestion that the tool shouldn&#x27;t be set up out of the box to DoS sites it&#x27;s scraping, that doesn&#x27;t prevent anyone who is technical enough to know what they&#x27;re doing to fork it and remove whatever limits are there by default? I can&#x27;t see it as a &quot;my computer should do what I want!&quot; issue, if you don&#x27;t like how this package works, change it or use another?</div><br/><div id="42817655" class="c"><input type="checkbox" id="c-42817655" checked=""/><div class="controls bullet"><span class="by">benatkin</span><span>|</span><a href="#42812928">root</a><span>|</span><a href="#42816247">parent</a><span>|</span><a href="#42816851">next</a><span>|</span><label class="collapse" for="c-42817655">[-]</label><label class="expand" for="c-42817655">[1 more]</label></div><br/><div class="children"><div class="content">Digital Restrictions Management, then. Have it your way.</div><br/></div></div></div></div><div id="42816851" class="c"><input type="checkbox" id="c-42816851" checked=""/><div class="controls bullet"><span class="by">JambalayaJimbo</span><span>|</span><a href="#42812928">root</a><span>|</span><a href="#42816030">parent</a><span>|</span><a href="#42816247">prev</a><span>|</span><a href="#42816195">next</a><span>|</span><label class="collapse" for="c-42816851">[-]</label><label class="expand" for="c-42816851">[1 more]</label></div><br/><div class="children"><div class="content">This is software telling you what you are allowed to do based on what the software developer wants* (assuming the developers cares of course...). Which is how all software works. I would not want my users of my software doing anything malicious with it, so I would not give them the option.<p>If I create an open-source messaging app I am also not going to give users the option of clicking a button to spam recipients with dick pics. Even if it was dead-simple for a determined user to add code for this dick pic button themselves.</div><br/></div></div></div></div></div></div><div id="42816195" class="c"><input type="checkbox" id="c-42816195" checked=""/><div class="controls bullet"><span class="by">bityard</span><span>|</span><a href="#42812928">root</a><span>|</span><a href="#42815962">parent</a><span>|</span><a href="#42816001">prev</a><span>|</span><a href="#42819586">next</a><span>|</span><label class="collapse" for="c-42816195">[-]</label><label class="expand" for="c-42816195">[4 more]</label></div><br/><div class="children"><div class="content">I feel like you may have a misunderstanding of what DRM is. Talking about DRM outside the context of media distribution doesn&#x27;t really make any sense.<p>Yes, someone can fork this and modify it however they want. They can already do the same with curl, Firefox, Chromium, etc. The point is that this is project is deliberately advertising itself as an AI-friendly web scraper. If successful, lots of people who don&#x27;t know any better are going to download it and deploy it without a full understanding (and possibly caring) of the consequences on the open web. And as I already point out, this is not hypothetical, it is already happening. Right now. As we speak.<p>Do you want cloudflare everywhere? This is how you get cloudflare everywhere.<p>My plea for the dev is that they choose to take the high road and put web-server-friendly SANE DEFAULTS in place to curb the bulk of abusive web scraping behavior to lessen the number of gray hairs it causes web admins like myself. That is all.</div><br/><div id="42817082" class="c"><input type="checkbox" id="c-42817082" checked=""/><div class="controls bullet"><span class="by">randunel</span><span>|</span><a href="#42812928">root</a><span>|</span><a href="#42816195">parent</a><span>|</span><a href="#42817693">next</a><span>|</span><label class="collapse" for="c-42817082">[-]</label><label class="expand" for="c-42817082">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s exactly DRM, management of legal access to digital content. The &quot;media&quot; part has been optional for decades.<p>The comment they replied to didn&#x27;t suggest sane defaults, but DRM. Here&#x27;s the quote, no defaults work that way (inability to override):<p>&gt; At a _bare_ minimum, that means obeying robot.txt and NOT crawling a site that doesn&#x27;t want to be crawled. And there should not be an option to override that.</div><br/><div id="42817684" class="c"><input type="checkbox" id="c-42817684" checked=""/><div class="controls bullet"><span class="by">samatman</span><span>|</span><a href="#42812928">root</a><span>|</span><a href="#42817082">parent</a><span>|</span><a href="#42817693">next</a><span>|</span><label class="collapse" for="c-42817684">[-]</label><label class="expand" for="c-42817684">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ll also add something that I expect to be somewhat controversial, given earlier conversations on HN[0]: I see contexts in which it would be perfectly valid to use this and ignore robots.txt.<p>If I were directing some LLM agent to specifically access a site on my behalf, and get a usable digest of that information to answer questions, or whever, that use of the headless browser is not a spider, it&#x27;s a user agent.  Just an unusual one.<p>The amount of traffic generated is consistent with browsing, not scraping.  So no, I don&#x27;t think building in a mandatory robots.txt respecter is a reasonable ask.  Someone who wants to deploy it at scale while ignoring robots.txt is just going to disable that, and it causes problems for legitimate use cases where the headless browser is not a robot in any reasonable or normal interpretation of the term.<p>[0]: I don&#x27;t entirely understand why this is controversial, but it was.</div><br/></div></div></div></div><div id="42817693" class="c"><input type="checkbox" id="c-42817693" checked=""/><div class="controls bullet"><span class="by">benatkin</span><span>|</span><a href="#42812928">root</a><span>|</span><a href="#42816195">parent</a><span>|</span><a href="#42817082">prev</a><span>|</span><a href="#42819586">next</a><span>|</span><label class="collapse" for="c-42817693">[-]</label><label class="expand" for="c-42817693">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Talking about DRM outside the context of media distribution doesn&#x27;t really make any sense.<p>It’s a cultural thing, and it makes a lot of sense. This fits with DRM culture that has walled gardens in iOS and Android.</div><br/></div></div></div></div></div></div><div id="42819586" class="c"><input type="checkbox" id="c-42819586" checked=""/><div class="controls bullet"><span class="by">MichaelMoser123</span><span>|</span><a href="#42812928">root</a><span>|</span><a href="#42815546">parent</a><span>|</span><a href="#42815962">prev</a><span>|</span><a href="#42817710">next</a><span>|</span><label class="collapse" for="c-42819586">[-]</label><label class="expand" for="c-42819586">[1 more]</label></div><br/><div class="children"><div class="content">That would make it impossible to use this as a testing tool. How should automatic testing of web applications work, if you obey all of these rules? There is also the problem of load testing. This kind of stuff is by its nature of dual use, a load test is also a kind of DDOS attack.</div><br/></div></div><div id="42817710" class="c"><input type="checkbox" id="c-42817710" checked=""/><div class="controls bullet"><span class="by">benatkin</span><span>|</span><a href="#42812928">root</a><span>|</span><a href="#42815546">parent</a><span>|</span><a href="#42819586">prev</a><span>|</span><a href="#42818942">next</a><span>|</span><label class="collapse" for="c-42817710">[-]</label><label class="expand" for="c-42817710">[1 more]</label></div><br/><div class="children"><div class="content">Make it faster and furiouser.<p>There are so many variables involved that it’s hard to predict what it will mean for the open web to have a faster alternative to headless Chrome. At least it isn’t controlled by Google directly or indirectly (Mozilla’s funding source) or Apple.</div><br/></div></div><div id="42818942" class="c"><input type="checkbox" id="c-42818942" checked=""/><div class="controls bullet"><span class="by">cchance</span><span>|</span><a href="#42812928">root</a><span>|</span><a href="#42815546">parent</a><span>|</span><a href="#42817710">prev</a><span>|</span><a href="#42819872">next</a><span>|</span><label class="collapse" for="c-42818942">[-]</label><label class="expand" for="c-42818942">[2 more]</label></div><br/><div class="children"><div class="content">Its literally open source, any effort put into hamstringing it would just be forked and removed lol</div><br/><div id="42819438" class="c"><input type="checkbox" id="c-42819438" checked=""/><div class="controls bullet"><span class="by">xena</span><span>|</span><a href="#42812928">root</a><span>|</span><a href="#42818942">parent</a><span>|</span><a href="#42819872">next</a><span>|</span><label class="collapse" for="c-42819438">[-]</label><label class="expand" for="c-42819438">[1 more]</label></div><br/><div class="children"><div class="content">Any barrier to abuse makes abuse harder.</div><br/></div></div></div></div><div id="42819872" class="c"><input type="checkbox" id="c-42819872" checked=""/><div class="controls bullet"><span class="by">holoduke</span><span>|</span><a href="#42812928">root</a><span>|</span><a href="#42815546">parent</a><span>|</span><a href="#42818942">prev</a><span>|</span><a href="#42817053">next</a><span>|</span><label class="collapse" for="c-42819872">[-]</label><label class="expand" for="c-42819872">[1 more]</label></div><br/><div class="children"><div class="content">In 10 lines of code I could create a proxy tool that removes all your suggested guidelines so the scraper still operates. In other words. Not really helping.</div><br/></div></div></div></div><div id="42817053" class="c"><input type="checkbox" id="c-42817053" checked=""/><div class="controls bullet"><span class="by">danielsht</span><span>|</span><a href="#42812928">parent</a><span>|</span><a href="#42815546">prev</a><span>|</span><a href="#42818771">next</a><span>|</span><label class="collapse" for="c-42817053">[-]</label><label class="expand" for="c-42817053">[2 more]</label></div><br/><div class="children"><div class="content">Very impressive! At Airtop.ai we looked into lightweight browsers like this one since we run a huge fleet of cloud browsers but found that anything other than a non-headless Chromium based browser would trigger bot detection pretty quickly. Even spoofing user agents triggers bot detection because fingerprinting tools like FingerprintJS will use things like JS features, canvas fingerprinting, WebGL fingerprinting, font enumeration, etc.<p>Can you share if you&#x27;ve looked into how your browser fares against bot detection tools like these?</div><br/><div id="42817232" class="c"><input type="checkbox" id="c-42817232" checked=""/><div class="controls bullet"><span class="by">fbouvier</span><span>|</span><a href="#42812928">root</a><span>|</span><a href="#42817053">parent</a><span>|</span><a href="#42818771">next</a><span>|</span><label class="collapse" for="c-42817232">[-]</label><label class="expand" for="c-42817232">[1 more]</label></div><br/><div class="children"><div class="content">Thanks! No we haven&#x27;t worked on bot detection.</div><br/></div></div></div></div><div id="42818771" class="c"><input type="checkbox" id="c-42818771" checked=""/><div class="controls bullet"><span class="by">keepamovin</span><span>|</span><a href="#42812928">parent</a><span>|</span><a href="#42817053">prev</a><span>|</span><a href="#42814730">next</a><span>|</span><label class="collapse" for="c-42818771">[-]</label><label class="expand" for="c-42818771">[1 more]</label></div><br/><div class="children"><div class="content">If you support Page.startScreencast or even just capture screenshot we could experiment with using this as a backend for BrowserBox, when lightpanda matures. Cool stuff!<p><a href="https:&#x2F;&#x2F;github.com&#x2F;BrowserBox&#x2F;BrowserBox&#x2F;">https:&#x2F;&#x2F;github.com&#x2F;BrowserBox&#x2F;BrowserBox&#x2F;</a></div><br/></div></div><div id="42814730" class="c"><input type="checkbox" id="c-42814730" checked=""/><div class="controls bullet"><span class="by">sesm</span><span>|</span><a href="#42812928">parent</a><span>|</span><a href="#42818771">prev</a><span>|</span><a href="#42818490">next</a><span>|</span><label class="collapse" for="c-42814730">[-]</label><label class="expand" for="c-42814730">[3 more]</label></div><br/><div class="children"><div class="content">Great job! And good luck on your journey!<p>One question: which JS engines did you consider and why you chose V8 in the end?</div><br/><div id="42814844" class="c"><input type="checkbox" id="c-42814844" checked=""/><div class="controls bullet"><span class="by">fbouvier</span><span>|</span><a href="#42812928">root</a><span>|</span><a href="#42814730">parent</a><span>|</span><a href="#42818490">next</a><span>|</span><label class="collapse" for="c-42814844">[-]</label><label class="expand" for="c-42814844">[2 more]</label></div><br/><div class="children"><div class="content">We have also considered JavaScriptCore (used by Bun) and QuickJS. We did choose v8 because it&#x27;s state of the art, quite well documented and easy to embed.<p>The code is made to support others JS engine in the future. We do want to add a lightweight alternative like QuickJS or Kiesel <a href="https:&#x2F;&#x2F;kiesel.dev&#x2F;" rel="nofollow">https:&#x2F;&#x2F;kiesel.dev&#x2F;</a></div><br/><div id="42819242" class="c"><input type="checkbox" id="c-42819242" checked=""/><div class="controls bullet"><span class="by">ksec</span><span>|</span><a href="#42812928">root</a><span>|</span><a href="#42814844">parent</a><span>|</span><a href="#42818490">next</a><span>|</span><label class="collapse" for="c-42819242">[-]</label><label class="expand" for="c-42819242">[1 more]</label></div><br/><div class="children"><div class="content">Thank You I was thinking of JSC and Bun as well. Was half expecting JSC since that combination seems to work well.</div><br/></div></div></div></div></div></div><div id="42818490" class="c"><input type="checkbox" id="c-42818490" checked=""/><div class="controls bullet"><span class="by">867-5309</span><span>|</span><a href="#42812928">parent</a><span>|</span><a href="#42814730">prev</a><span>|</span><a href="#42814673">next</a><span>|</span><label class="collapse" for="c-42818490">[-]</label><label class="expand" for="c-42818490">[2 more]</label></div><br/><div class="children"><div class="content">does this work with selenium&#x2F;chromedriver?</div><br/><div id="42818497" class="c"><input type="checkbox" id="c-42818497" checked=""/><div class="controls bullet"><span class="by">fbouvier</span><span>|</span><a href="#42812928">root</a><span>|</span><a href="#42818490">parent</a><span>|</span><a href="#42814673">next</a><span>|</span><label class="collapse" for="c-42818497">[-]</label><label class="expand" for="c-42818497">[1 more]</label></div><br/><div class="children"><div class="content">For now we just support CDP. But Selenium is definitely in our roadmap.</div><br/></div></div></div></div><div id="42814673" class="c"><input type="checkbox" id="c-42814673" checked=""/><div class="controls bullet"><span class="by">toobulkeh</span><span>|</span><a href="#42812928">parent</a><span>|</span><a href="#42818490">prev</a><span>|</span><a href="#42814729">next</a><span>|</span><label class="collapse" for="c-42814673">[-]</label><label class="expand" for="c-42814673">[1 more]</label></div><br/><div class="children"><div class="content">I’d love to see better optimized web socket support and “save” features that cache LLM queries to optimize fallback</div><br/></div></div><div id="42814729" class="c"><input type="checkbox" id="c-42814729" checked=""/><div class="controls bullet"><span class="by">dtj1123</span><span>|</span><a href="#42812928">parent</a><span>|</span><a href="#42814673">prev</a><span>|</span><a href="#42815780">next</a><span>|</span><label class="collapse" for="c-42814729">[-]</label><label class="expand" for="c-42814729">[2 more]</label></div><br/><div class="children"><div class="content">Very nice. Does this &#x2F; will this support the puppeteer-extra stealth plugin?</div><br/><div id="42814865" class="c"><input type="checkbox" id="c-42814865" checked=""/><div class="controls bullet"><span class="by">katiehallett</span><span>|</span><a href="#42812928">root</a><span>|</span><a href="#42814729">parent</a><span>|</span><a href="#42815780">next</a><span>|</span><label class="collapse" for="c-42814865">[-]</label><label class="expand" for="c-42814865">[1 more]</label></div><br/><div class="children"><div class="content">Thanks! Right now no, but since we use the CDP (playwright, puppeteer), I guess it would be possible to support it</div><br/></div></div></div></div><div id="42815780" class="c"><input type="checkbox" id="c-42815780" checked=""/><div class="controls bullet"><span class="by">afk1914</span><span>|</span><a href="#42812928">parent</a><span>|</span><a href="#42814729">prev</a><span>|</span><a href="#42815872">next</a><span>|</span><label class="collapse" for="c-42815780">[-]</label><label class="expand" for="c-42815780">[2 more]</label></div><br/><div class="children"><div class="content">I am curious how Lightpanda compares to chrome-headless-shell ({headless: &#x27;shell&#x27;} in Puppeteer) in benchmarks.</div><br/><div id="42815931" class="c"><input type="checkbox" id="c-42815931" checked=""/><div class="controls bullet"><span class="by">fbouvier</span><span>|</span><a href="#42812928">root</a><span>|</span><a href="#42815780">parent</a><span>|</span><a href="#42815872">next</a><span>|</span><label class="collapse" for="c-42815931">[-]</label><label class="expand" for="c-42815931">[1 more]</label></div><br/><div class="children"><div class="content">We did not run benchmarks with chrome-headless-shell (aka the old headless mode) but I guess that performance wise it&#x27;s on the same scale as the new headless mode.</div><br/></div></div></div></div><div id="42815872" class="c"><input type="checkbox" id="c-42815872" checked=""/><div class="controls bullet"><span class="by">xena</span><span>|</span><a href="#42812928">parent</a><span>|</span><a href="#42815780">prev</a><span>|</span><a href="#42820445">next</a><span>|</span><label class="collapse" for="c-42815872">[-]</label><label class="expand" for="c-42815872">[1 more]</label></div><br/><div class="children"><div class="content">How do I make sure that people can&#x27;t use lightpanda to bypass bot protection tools?</div><br/></div></div></div></div><div id="42820445" class="c"><input type="checkbox" id="c-42820445" checked=""/><div class="controls bullet"><span class="by">randomMatrix101</span><span>|</span><a href="#42812928">prev</a><span>|</span><a href="#42820090">next</a><span>|</span><label class="collapse" for="c-42820445">[-]</label><label class="expand" for="c-42820445">[1 more]</label></div><br/><div class="children"><div class="content">Very cool project, congrats guys!</div><br/></div></div><div id="42820090" class="c"><input type="checkbox" id="c-42820090" checked=""/><div class="controls bullet"><span class="by">psanchez</span><span>|</span><a href="#42820445">prev</a><span>|</span><a href="#42816664">next</a><span>|</span><label class="collapse" for="c-42820090">[-]</label><label class="expand" for="c-42820090">[1 more]</label></div><br/><div class="children"><div class="content">I think this is a really cool project. Scrapping aside, I would definitely use this with playwright for end2end tests if it had 100% compatibility with chrome and ran with a fraction of the time&#x2F;memory.<p>At my company we have a small project where we are running the equivalent of 6.5 hours of end2end tests daily using playwright. Running the tests in parallel takes around half an hour. Your project is still in very early stages, but assuming 10x speed, that would mean we could pass all our tests in roughtly 3 min (best case scenario).<p>That being said, I would make use of your browser, but would likely not make use of your business offering (our tests require internal VPN, have some custom solution for reporting, would be a lot of work to change for little savings; we run all tests currently in spot&#x2F;preemptible instances which are already 80% cheaper).<p>Business-wise I found very little info on your website. &quot;4x the efficiency at half the cost&quot; is a good catch phrase, but compared to what? I mean, you can have servers in Hetzner or in AWS and one is already a fraction of the cost of the other. How convenient is to launch things on your remote platform vs launch them locally or setting it up? does it provide any advantages in the case of web scrapping compared to other solutions? how parallelizable is it? Do you have any paying customers already?<p>Supercool tech project. Best of luck!</div><br/></div></div><div id="42816664" class="c"><input type="checkbox" id="c-42816664" checked=""/><div class="controls bullet"><span class="by">frankgrecojr</span><span>|</span><a href="#42820090">prev</a><span>|</span><a href="#42817449">next</a><span>|</span><label class="collapse" for="c-42816664">[-]</label><label class="expand" for="c-42816664">[6 more]</label></div><br/><div class="children"><div class="content">The hello world example does not work. In fact, no website I&#x27;ve tried works. It&#x27;s usually always panics. For the example in the readme, the errors are:<p>```<p>.&#x2F;lightpanda-aarch64-macos --host 127.0.0.1 --port 9222<p>info(websocket): starting blocking worker to listen on 127.0.0.1:9222<p>info(server): accepting new conn...<p>info(server): client connected<p>info(browser): GET <a href="https:&#x2F;&#x2F;wikipedia.com&#x2F;" rel="nofollow">https:&#x2F;&#x2F;wikipedia.com&#x2F;</a> 200<p>info(browser): fetch <a href="https:&#x2F;&#x2F;wikipedia.com&#x2F;portal&#x2F;wikipedia.org&#x2F;assets&#x2F;js&#x2F;index-24c3e2ca18.js" rel="nofollow">https:&#x2F;&#x2F;wikipedia.com&#x2F;portal&#x2F;wikipedia.org&#x2F;assets&#x2F;js&#x2F;index-2...</a>: http.Status.ok<p>info(browser): eval script portal&#x2F;wikipedia.org&#x2F;assets&#x2F;js&#x2F;index-24c3e2ca18.js: ReferenceError: location is not defined<p>info(browser): fetch <a href="https:&#x2F;&#x2F;wikipedia.com&#x2F;portal&#x2F;wikipedia.org&#x2F;assets&#x2F;js&#x2F;gt-ie9-ce3fe8e88d.js" rel="nofollow">https:&#x2F;&#x2F;wikipedia.com&#x2F;portal&#x2F;wikipedia.org&#x2F;assets&#x2F;js&#x2F;gt-ie9-...</a>: http.Status.ok<p>error(events): event handler error: error.JSExecCallback<p>info(events): event handler error try catch: TypeError: Cannot read properties of undefined (reading &#x27;length&#x27;)<p>info(server): close cmd, closing conn...<p>info(server): accepting new conn...<p>thread 5274880 panic: attempt to use null value<p>zsh: abort      .&#x2F;lightpanda-aarch64-macos --host 127.0.0.1 --port 9222<p>```</div><br/><div id="42818479" class="c"><input type="checkbox" id="c-42818479" checked=""/><div class="controls bullet"><span class="by">lbotos</span><span>|</span><a href="#42816664">parent</a><span>|</span><a href="#42819267">next</a><span>|</span><label class="collapse" for="c-42818479">[-]</label><label class="expand" for="c-42818479">[1 more]</label></div><br/><div class="children"><div class="content">Not OP -- do you have some kind of proxy or firewall?<p>Looks like you couldn&#x27;t download <a href="https:&#x2F;&#x2F;wikipedia.com&#x2F;portal&#x2F;wikipedia.org&#x2F;assets&#x2F;js&#x2F;gt-ie9-ce3fe8e88d.js" rel="nofollow">https:&#x2F;&#x2F;wikipedia.com&#x2F;portal&#x2F;wikipedia.org&#x2F;assets&#x2F;js&#x2F;gt-ie9-...</a> for some reason.<p>In my contributions to joplin s3 backend &quot;Cannot read properties of undefined (reading &#x27;length&#x27;)&quot; was usually when you were trying to access an object that wasn&#x27;t instantiated. (Can&#x27;t figure out length of &lt;undefined&gt;)<p>So for some reason it seems you can&#x27;t execute JS?</div><br/></div></div><div id="42819267" class="c"><input type="checkbox" id="c-42819267" checked=""/><div class="controls bullet"><span class="by">zelcon</span><span>|</span><a href="#42816664">parent</a><span>|</span><a href="#42818479">prev</a><span>|</span><a href="#42817449">next</a><span>|</span><label class="collapse" for="c-42819267">[-]</label><label class="expand" for="c-42819267">[4 more]</label></div><br/><div class="children"><div class="content">That&#x27;s Zig for you. A ``modern&#x27;&#x27; systems programming language with no borrow checker or even RAII.</div><br/><div id="42819795" class="c"><input type="checkbox" id="c-42819795" checked=""/><div class="controls bullet"><span class="by">hansvm</span><span>|</span><a href="#42816664">root</a><span>|</span><a href="#42819267">parent</a><span>|</span><a href="#42819912">next</a><span>|</span><label class="collapse" for="c-42819795">[-]</label><label class="expand" for="c-42819795">[2 more]</label></div><br/><div class="children"><div class="content">Those statements are mostly true and also worth talking about, but they&#x27;re not pertinent to that error (remotely provided JS not behaving correctly), or the eventual crash (which you&#x27;d cause exactly the same way for the same reason in Rust with a .unwrap() call).</div><br/><div id="42819951" class="c"><input type="checkbox" id="c-42819951" checked=""/><div class="controls bullet"><span class="by">jbggs</span><span>|</span><a href="#42816664">root</a><span>|</span><a href="#42819795">parent</a><span>|</span><a href="#42819912">next</a><span>|</span><label class="collapse" for="c-42819951">[-]</label><label class="expand" for="c-42819951">[1 more]</label></div><br/><div class="children"><div class="content">you shouldn&#x27;t be unwrapping, error cases should be properly handled.  users shouldn&#x27;t see null dereference errors without any context, even in cli tools...</div><br/></div></div></div></div><div id="42819912" class="c"><input type="checkbox" id="c-42819912" checked=""/><div class="controls bullet"><span class="by">igorguerrero</span><span>|</span><a href="#42816664">root</a><span>|</span><a href="#42819267">parent</a><span>|</span><a href="#42819795">prev</a><span>|</span><a href="#42817449">next</a><span>|</span><label class="collapse" for="c-42819912">[-]</label><label class="expand" for="c-42819912">[1 more]</label></div><br/><div class="children"><div class="content">You could build the same thing in Rust and have the same exact issue.</div><br/></div></div></div></div></div></div><div id="42817449" class="c"><input type="checkbox" id="c-42817449" checked=""/><div class="controls bullet"><span class="by">dang</span><span>|</span><a href="#42816664">prev</a><span>|</span><a href="#42814807">next</a><span>|</span><label class="collapse" for="c-42817449">[-]</label><label class="expand" for="c-42817449">[1 more]</label></div><br/><div class="children"><div class="content">(This was on the frontpage as <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=42812859">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=42812859</a> but someone pointed out to me that it had been a Show HN a few weeks ago: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=42430629">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=42430629</a>, so I&#x27;ve made a fresh copy of that submission and moved the comments hither. I hope that&#x27;s ok with everyone!)</div><br/></div></div><div id="42814807" class="c"><input type="checkbox" id="c-42814807" checked=""/><div class="controls bullet"><span class="by">weinzierl</span><span>|</span><a href="#42817449">prev</a><span>|</span><a href="#42817524">next</a><span>|</span><label class="collapse" for="c-42814807">[-]</label><label class="expand" for="c-42814807">[2 more]</label></div><br/><div class="children"><div class="content">If I don&#x27;t need JavaScript or any interactivity, just modern HTML + modern CSS, is there any modern lightweight renderer to png or svg?<p>Something in the spirit of wkhtmltoimage or WeasyPrint that does not require a full blown browser but more modern with support of recent HTML and CSS?<p>In a sense this is Lightpanda&#x27;s complement to a &quot;full panda&quot;. Just the fully rendered DOM to pixels.</div><br/><div id="42816237" class="c"><input type="checkbox" id="c-42816237" checked=""/><div class="controls bullet"><span class="by">nicoburns</span><span>|</span><a href="#42814807">parent</a><span>|</span><a href="#42817524">next</a><span>|</span><label class="collapse" for="c-42816237">[-]</label><label class="expand" for="c-42816237">[1 more]</label></div><br/><div class="children"><div class="content">We&#x27;re working on this here: <a href="https:&#x2F;&#x2F;github.com&#x2F;DioxusLabs&#x2F;blitz">https:&#x2F;&#x2F;github.com&#x2F;DioxusLabs&#x2F;blitz</a> See the &quot;screenshot&quot; example for rendering to png. 
There&#x27;s no SVG backend currently, but one could be added.<p>(proper announcement of project coming soon)</div><br/></div></div></div></div><div id="42817524" class="c"><input type="checkbox" id="c-42817524" checked=""/><div class="controls bullet"><span class="by">zlagen</span><span>|</span><a href="#42814807">prev</a><span>|</span><a href="#42814613">next</a><span>|</span><label class="collapse" for="c-42817524">[-]</label><label class="expand" for="c-42817524">[3 more]</label></div><br/><div class="children"><div class="content">what do you think would be the use cases for this project? being lightweight is awesome but usually you need a real browser for most use cases. Testing sites and scraping for example. It may work for some scraping use cases but I think that if the site uses any kind of bot blocking this is not going to cut it.</div><br/><div id="42817824" class="c"><input type="checkbox" id="c-42817824" checked=""/><div class="controls bullet"><span class="by">fbouvier</span><span>|</span><a href="#42817524">parent</a><span>|</span><a href="#42814613">next</a><span>|</span><label class="collapse" for="c-42817824">[-]</label><label class="expand" for="c-42817824">[2 more]</label></div><br/><div class="children"><div class="content">There are a lot of uses cases:<p>- LLM training (RAG, fine tuning)<p>- AI agents<p>- scraping<p>- SERP<p>- testing<p>- any kind of web automation basically<p>Bot protection of course might be a problem but it depends also on the volume of requests, IP, and other parameters.<p>AI agents will do more and more actions on behalf of humans in the future and I believe the bot protection mechanism will evolve to include them as legit.</div><br/><div id="42818994" class="c"><input type="checkbox" id="c-42818994" checked=""/><div class="controls bullet"><span class="by">zlagen</span><span>|</span><a href="#42817524">root</a><span>|</span><a href="#42817824">parent</a><span>|</span><a href="#42814613">next</a><span>|</span><label class="collapse" for="c-42818994">[-]</label><label class="expand" for="c-42818994">[1 more]</label></div><br/><div class="children"><div class="content">thanks, it doesn&#x27;t seem like it&#x27;s the direction it&#x27;s going at the moment. If you look at the robots.txt of many websites, they are actually banning AI bots from crawling the site. To me it seems more likely that each site will have its own AI agent to perform operations but controlled by the site.</div><br/></div></div></div></div></div></div><div id="42814613" class="c"><input type="checkbox" id="c-42814613" checked=""/><div class="controls bullet"><span class="by">cropcirclbureau</span><span>|</span><a href="#42817524">prev</a><span>|</span><a href="#42818910">next</a><span>|</span><label class="collapse" for="c-42814613">[-]</label><label class="expand" for="c-42814613">[4 more]</label></div><br/><div class="children"><div class="content">Pretty cool. Do you have a list of features you plan to support and plan to cut? Also, how much does this differ from the DOM impls that test frameworks use? I recall Jest or someone sporting such a feature.</div><br/><div id="42814894" class="c"><input type="checkbox" id="c-42814894" checked=""/><div class="controls bullet"><span class="by">fbouvier</span><span>|</span><a href="#42814613">parent</a><span>|</span><a href="#42818910">next</a><span>|</span><label class="collapse" for="c-42814894">[-]</label><label class="expand" for="c-42814894">[3 more]</label></div><br/><div class="children"><div class="content">The most important &quot;feature&quot; is to increase our Web APIs coverage :)<p>But of course we plan to add others features, including<p>- tight integration with LLM<p>- embed mode (as a C library and as a WASM module) so you can add a real browser to your project the same way you add libcurl</div><br/><div id="42815642" class="c"><input type="checkbox" id="c-42815642" checked=""/><div class="controls bullet"><span class="by">andrethegiant</span><span>|</span><a href="#42814613">root</a><span>|</span><a href="#42814894">parent</a><span>|</span><a href="#42818910">next</a><span>|</span><label class="collapse" for="c-42815642">[-]</label><label class="expand" for="c-42815642">[2 more]</label></div><br/><div class="children"><div class="content">Could it potentially fit in a Cloudflare worker? Workers are also V8 and can run wasm, but are constrained to 128MB RAM and 10MB zipped bundle size</div><br/><div id="42815763" class="c"><input type="checkbox" id="c-42815763" checked=""/><div class="controls bullet"><span class="by">fbouvier</span><span>|</span><a href="#42814613">root</a><span>|</span><a href="#42815642">parent</a><span>|</span><a href="#42818910">next</a><span>|</span><label class="collapse" for="c-42815763">[-]</label><label class="expand" for="c-42815763">[1 more]</label></div><br/><div class="children"><div class="content">WASM support is not there yet but it&#x27;s on the roadmap and we had it in our mind since the beginning of the project, and have made our dev choices accordingly.<p>So yes it could be used in a serverless platform like Cloudflare workers. Our startup time is a huge advantage here (20ms vs 600ms for Chrome headless in our local tests).<p>Regarding v8 in Cloudflare workers I think we can not used directly, ie. we still need to embed a JS engine in the wasm module.</div><br/></div></div></div></div></div></div></div></div><div id="42818910" class="c"><input type="checkbox" id="c-42818910" checked=""/><div class="controls bullet"><span class="by">the__alchemist</span><span>|</span><a href="#42814613">prev</a><span>|</span><a href="#42819259">next</a><span>|</span><label class="collapse" for="c-42818910">[-]</label><label class="expand" for="c-42818910">[2 more]</label></div><br/><div class="children"><div class="content">I have a meta question from browsing the repo: Why do C, C++, and Zig code bases, by convention, include a license at the top of every module&quot; IMO it makes more sense to insetead include of an overview of the module&#x27;s purpose, and how it fits in with the rest of the program, and one license at the top-level, as the project already has.</div><br/><div id="42818972" class="c"><input type="checkbox" id="c-42818972" checked=""/><div class="controls bullet"><span class="by">AndyKelley</span><span>|</span><a href="#42818910">parent</a><span>|</span><a href="#42819259">next</a><span>|</span><label class="collapse" for="c-42818972">[-]</label><label class="expand" for="c-42818972">[1 more]</label></div><br/><div class="children"><div class="content">100% of my projects, including the Zig compiler itself, have only the license file at the root of the project tree, except of course for files that were copy pasted from other projects.</div><br/></div></div></div></div><div id="42819259" class="c"><input type="checkbox" id="c-42819259" checked=""/><div class="controls bullet"><span class="by">zelcon</span><span>|</span><a href="#42818910">prev</a><span>|</span><a href="#42816607">next</a><span>|</span><label class="collapse" for="c-42819259">[-]</label><label class="expand" for="c-42819259">[4 more]</label></div><br/><div class="children"><div class="content">Why didn&#x27;t you just fork Chromium and strip out the renderer? This is guaranteed to bitrot when the web standards change unless you keep up with it forever and have perpetual funding. Yes, modifying Chromium is hard, but this seems harder.</div><br/><div id="42819495" class="c"><input type="checkbox" id="c-42819495" checked=""/><div class="controls bullet"><span class="by">tetris11</span><span>|</span><a href="#42819259">parent</a><span>|</span><a href="#42819675">next</a><span>|</span><label class="collapse" for="c-42819495">[-]</label><label class="expand" for="c-42819495">[2 more]</label></div><br/><div class="children"><div class="content">Why do anything: because it shows what&#x27;s possible, and makes the next effort that much more easier.<p>I call this process of frontier effort and discovery: &quot;science&quot;</div><br/><div id="42819533" class="c"><input type="checkbox" id="c-42819533" checked=""/><div class="controls bullet"><span class="by">zelcon</span><span>|</span><a href="#42819259">root</a><span>|</span><a href="#42819495">parent</a><span>|</span><a href="#42819675">next</a><span>|</span><label class="collapse" for="c-42819533">[-]</label><label class="expand" for="c-42819533">[1 more]</label></div><br/><div class="children"><div class="content">Redoing what others have already done is not what I think of when I hear &quot;frontier effort&quot;</div><br/></div></div></div></div><div id="42819675" class="c"><input type="checkbox" id="c-42819675" checked=""/><div class="controls bullet"><span class="by">cxr</span><span>|</span><a href="#42819259">parent</a><span>|</span><a href="#42819495">prev</a><span>|</span><a href="#42816607">next</a><span>|</span><label class="collapse" for="c-42819675">[-]</label><label class="expand" for="c-42819675">[1 more]</label></div><br/><div class="children"><div class="content">&gt; modifying Chromium is hard, but this seems harder<p>Prove it.</div><br/></div></div></div></div><div id="42816607" class="c"><input type="checkbox" id="c-42816607" checked=""/><div class="controls bullet"><span class="by">gwittel</span><span>|</span><a href="#42819259">prev</a><span>|</span><a href="#42816556">next</a><span>|</span><label class="collapse" for="c-42816607">[-]</label><label class="expand" for="c-42816607">[1 more]</label></div><br/><div class="children"><div class="content">Interesting.  Looks really neat!  How do you deal with anti bot stuff like Fingerprintjs, Cloudflare turnstile, etc? Maybe you’re new enough to not get flagged but I find this (and CDP) a challenge at times with these anti-bot systems.</div><br/></div></div><div id="42816556" class="c"><input type="checkbox" id="c-42816556" checked=""/><div class="controls bullet"><span class="by">surfmike</span><span>|</span><a href="#42816607">prev</a><span>|</span><a href="#42817795">next</a><span>|</span><label class="collapse" for="c-42816556">[-]</label><label class="expand" for="c-42816556">[1 more]</label></div><br/><div class="children"><div class="content">Another browser in this space is <a href="https:&#x2F;&#x2F;ultralig.ht&#x2F;" rel="nofollow">https:&#x2F;&#x2F;ultralig.ht&#x2F;</a>, it&#x27;s geared for in-game UI but I wonder how easy it would be to retool it for a similar use case.</div><br/></div></div><div id="42814859" class="c"><input type="checkbox" id="c-42814859" checked=""/><div class="controls bullet"><span class="by">Kathc</span><span>|</span><a href="#42817795">prev</a><span>|</span><a href="#42815545">next</a><span>|</span><label class="collapse" for="c-42814859">[-]</label><label class="expand" for="c-42814859">[6 more]</label></div><br/><div class="children"><div class="content">An open-source browser built from scratch is bold. What inspired the development of Lightpanda?</div><br/><div id="42814928" class="c"><input type="checkbox" id="c-42814928" checked=""/><div class="controls bullet"><span class="by">katiehallett</span><span>|</span><a href="#42814859">parent</a><span>|</span><a href="#42815319">next</a><span>|</span><label class="collapse" for="c-42814928">[-]</label><label class="expand" for="c-42814928">[4 more]</label></div><br/><div class="children"><div class="content">Thanks! The three of us worked together at our former company - ecomm saas start up where we spent a ton of $ on scraping infrastructure spinning up headless Chrome instances.<p>It started out as more of an R&amp;D thesis - is it possible to strip out graphical rendering from Chrome headless? Turns out no - so we tried to build it from scratch. And the beta results validated the thesis.<p>I wrote a whole thing about it here if you&#x27;re interested in delving deeper <a href="https:&#x2F;&#x2F;substack.thewebscraping.club&#x2F;p&#x2F;rethinking-the-web-browser" rel="nofollow">https:&#x2F;&#x2F;substack.thewebscraping.club&#x2F;p&#x2F;rethinking-the-web-br...</a></div><br/><div id="42817697" class="c"><input type="checkbox" id="c-42817697" checked=""/><div class="controls bullet"><span class="by">corford</span><span>|</span><a href="#42814859">root</a><span>|</span><a href="#42814928">parent</a><span>|</span><a href="#42815319">next</a><span>|</span><label class="collapse" for="c-42817697">[-]</label><label class="expand" for="c-42817697">[3 more]</label></div><br/><div class="children"><div class="content">Not sure what category of ecomm sites you were scraping but I scrape &gt;10million ecomm URLs daily and, honestly, in my experience the compute is not a major issue (8 times out of 10 you can either use API endpoints and&#x2F;or session stuffing to avoid needing a browser for every request; and in the 2 out of 10 sites where you really need a browser for all requests it&#x27;s usually to circumvent aggressive anti-bot which means you&#x27;re very likely going to need full chrome or FF anyway - and you can parallelise quite effectively across tabs).<p>One niche where I could definitely see a use for this though is scraping terribly coded sites that need some JS execution to safely get the data you want (e.g. they do some bonkers client side calculations that you don&#x27;t want to reverse engineer). It would be nice to not pay the perf tax of chrome in these cases.<p>Having said all of that, I have to say from a geek perspective it&#x27;s super neat what you guys are hacking on! Zig+V8+CDP bindings is very cool.</div><br/><div id="42819804" class="c"><input type="checkbox" id="c-42819804" checked=""/><div class="controls bullet"><span class="by">hansvm</span><span>|</span><a href="#42814859">root</a><span>|</span><a href="#42817697">parent</a><span>|</span><a href="#42819004">next</a><span>|</span><label class="collapse" for="c-42819804">[-]</label><label class="expand" for="c-42819804">[1 more]</label></div><br/><div class="children"><div class="content">&gt; not pay the perf tax<p>I&#x27;ve typically used pyminiracer in such cases and provided some dummy window objects and whatnot as necessary for the script to succeed.</div><br/></div></div><div id="42819004" class="c"><input type="checkbox" id="c-42819004" checked=""/><div class="controls bullet"><span class="by">zlagen</span><span>|</span><a href="#42814859">root</a><span>|</span><a href="#42817697">parent</a><span>|</span><a href="#42819804">prev</a><span>|</span><a href="#42815319">next</a><span>|</span><label class="collapse" for="c-42819004">[-]</label><label class="expand" for="c-42819004">[1 more]</label></div><br/><div class="children"><div class="content">fully agree here, using a browser for everything is the dumb way. You just usually use it to circumvent the blocking and then reuse the cookies to call the endpoints directly.</div><br/></div></div></div></div></div></div><div id="42815319" class="c"><input type="checkbox" id="c-42815319" checked=""/><div class="controls bullet"><span class="by">dolmen</span><span>|</span><a href="#42814859">parent</a><span>|</span><a href="#42814928">prev</a><span>|</span><a href="#42815545">next</a><span>|</span><label class="collapse" for="c-42815319">[-]</label><label class="expand" for="c-42815319">[1 more]</label></div><br/><div class="children"><div class="content">Scrapping modern web pages is hard without full support for JS frameworks and dynamic loading. But a full browser, even headless, has huge ressource consumption. This has a huge cost when scraping at scale.</div><br/></div></div></div></div><div id="42815545" class="c"><input type="checkbox" id="c-42815545" checked=""/><div class="controls bullet"><span class="by">kavalg</span><span>|</span><a href="#42814859">prev</a><span>|</span><a href="#42815712">next</a><span>|</span><label class="collapse" for="c-42815545">[-]</label><label class="expand" for="c-42815545">[2 more]</label></div><br/><div class="children"><div class="content">Why AGPL? I am not blaming you. I am just curious about the reasoning behind your choice.</div><br/><div id="42815694" class="c"><input type="checkbox" id="c-42815694" checked=""/><div class="controls bullet"><span class="by">fbouvier</span><span>|</span><a href="#42815545">parent</a><span>|</span><a href="#42815712">next</a><span>|</span><label class="collapse" for="c-42815694">[-]</label><label class="expand" for="c-42815694">[1 more]</label></div><br/><div class="children"><div class="content">We had some discussions about it. It seems to us that AGPL will ensure that a company running our browser in a cloud managed offer will have to keep its modifications open for the community.<p>We might be wrong, maybe AGPL will damage the project more than eg. Apache2. In that case we will reconsider our choice. It&#x27;s always easier this way :)<p>Our underlying library <a href="https:&#x2F;&#x2F;github.com&#x2F;lightpanda-io&#x2F;zig-js-runtime">https:&#x2F;&#x2F;github.com&#x2F;lightpanda-io&#x2F;zig-js-runtime</a> is licensed with Apache2.</div><br/></div></div></div></div><div id="42815712" class="c"><input type="checkbox" id="c-42815712" checked=""/><div class="controls bullet"><span class="by">cratermoon</span><span>|</span><a href="#42815545">prev</a><span>|</span><a href="#42814620">next</a><span>|</span><label class="collapse" for="c-42815712">[-]</label><label class="expand" for="c-42815712">[7 more]</label></div><br/><div class="children"><div class="content">So is this the scraper we need to block? <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=42750420">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=42750420</a></div><br/><div id="42815905" class="c"><input type="checkbox" id="c-42815905" checked=""/><div class="controls bullet"><span class="by">fbouvier</span><span>|</span><a href="#42815712">parent</a><span>|</span><a href="#42814620">next</a><span>|</span><label class="collapse" for="c-42815905">[-]</label><label class="expand" for="c-42815905">[6 more]</label></div><br/><div class="children"><div class="content">I fully understand your concern and agree that scrapers shouldn&#x27;t be hurting web servers.<p>I don&#x27;t think they are using our browser :)<p>But in my opinion, blocking a browser as such is not the right solution. In this case, it&#x27;s the user who should be blocked, not the browser.</div><br/><div id="42815954" class="c"><input type="checkbox" id="c-42815954" checked=""/><div class="controls bullet"><span class="by">jjcoffman</span><span>|</span><a href="#42815712">root</a><span>|</span><a href="#42815905">parent</a><span>|</span><a href="#42814620">next</a><span>|</span><label class="collapse" for="c-42815954">[-]</label><label class="expand" for="c-42815954">[5 more]</label></div><br/><div class="children"><div class="content">If your browser doesn&#x27;t play nicely and obey robots.txt when its headless I don&#x27;t think it&#x27;s that crazy to block the browser and not the user.</div><br/><div id="42819824" class="c"><input type="checkbox" id="c-42819824" checked=""/><div class="controls bullet"><span class="by">hansvm</span><span>|</span><a href="#42815712">root</a><span>|</span><a href="#42815954">parent</a><span>|</span><a href="#42816142">next</a><span>|</span><label class="collapse" for="c-42819824">[-]</label><label class="expand" for="c-42819824">[1 more]</label></div><br/><div class="children"><div class="content">The first thing that came to mind when I saw this project wasn&#x27;t scraping (where I&#x27;d typically either want a less detectible browser or a more performant option), but as a browser engine that&#x27;s actually sane to link against if I wanted to, e.g., write a modern TUI browser.<p>Banning the root library (even if you could with UA spoofing and whatnot) is right up there with banning Chrome to keep out low-wage scraping centers and their armies of employees. It&#x27;s not even a little effective also risks significant collateral damage.</div><br/></div></div><div id="42816142" class="c"><input type="checkbox" id="c-42816142" checked=""/><div class="controls bullet"><span class="by">fbouvier</span><span>|</span><a href="#42815712">root</a><span>|</span><a href="#42815954">parent</a><span>|</span><a href="#42819824">prev</a><span>|</span><a href="#42816433">next</a><span>|</span><label class="collapse" for="c-42816142">[-]</label><label class="expand" for="c-42816142">[1 more]</label></div><br/><div class="children"><div class="content">Every tool can be used in a good or bad way, Chrome, Firefox, cURL, etc. It&#x27;s not the browser who doesn&#x27;t play nicely, it&#x27;s the user.<p>It&#x27;s the user&#x27;s responsibility to behave well, like in life :)</div><br/></div></div><div id="42816433" class="c"><input type="checkbox" id="c-42816433" checked=""/><div class="controls bullet"><span class="by">slt2021</span><span>|</span><a href="#42815712">root</a><span>|</span><a href="#42815954">parent</a><span>|</span><a href="#42816142">prev</a><span>|</span><a href="#42814620">next</a><span>|</span><label class="collapse" for="c-42816433">[-]</label><label class="expand" for="c-42816433">[2 more]</label></div><br/><div class="children"><div class="content">it is trivial to spoof user-agent, if you want to stop a motivated scraper, you need a different solution that exploits the fact that robots use headless browser</div><br/><div id="42816507" class="c"><input type="checkbox" id="c-42816507" checked=""/><div class="controls bullet"><span class="by">sangnoir</span><span>|</span><a href="#42815712">root</a><span>|</span><a href="#42816433">parent</a><span>|</span><a href="#42814620">next</a><span>|</span><label class="collapse" for="c-42816507">[-]</label><label class="expand" for="c-42816507">[1 more]</label></div><br/><div class="children"><div class="content">&gt; it is trivial to spoof user-agent<p>It&#x27;s also trivial to detect spoofed user agents via fingerprinting. The best defense against scrapers is done in layers, with user-agent name block as the bare minimum.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="42814620" class="c"><input type="checkbox" id="c-42814620" checked=""/><div class="controls bullet"><span class="by">m3kw9</span><span>|</span><a href="#42815712">prev</a><span>|</span><a href="#42819592">next</a><span>|</span><label class="collapse" for="c-42814620">[-]</label><label class="expand" for="c-42814620">[8 more]</label></div><br/><div class="children"><div class="content">How does this work because the browser needs to render a page and the vision model needs to know where a button is, so it still needs to see an image.  How does headless make it easier?</div><br/><div id="42814714" class="c"><input type="checkbox" id="c-42814714" checked=""/><div class="controls bullet"><span class="by">katiehallett</span><span>|</span><a href="#42814620">parent</a><span>|</span><a href="#42819592">next</a><span>|</span><label class="collapse" for="c-42814714">[-]</label><label class="expand" for="c-42814714">[7 more]</label></div><br/><div class="children"><div class="content">Headless mode skips the visual rendering meant for humans, but the DOM structure and layout still exist, allowing the model to parse elements programmatically (e.g. button locations). Instead of &#x27;seeing&#x27; an image, the model interacts with the page&#x27;s underlying structure, which is faster and more efficient. Our browser removes the rendering engine as well, so it won&#x27;t handle 100% of automation use cases, but it&#x27;s also what allows us to be faster and lighter than Chrome in headless mode.</div><br/><div id="42816611" class="c"><input type="checkbox" id="c-42816611" checked=""/><div class="controls bullet"><span class="by">10000truths</span><span>|</span><a href="#42814620">root</a><span>|</span><a href="#42814714">parent</a><span>|</span><a href="#42815232">next</a><span>|</span><label class="collapse" for="c-42816611">[-]</label><label class="expand" for="c-42816611">[1 more]</label></div><br/><div class="children"><div class="content">The issue is that DOM structure does not correspond one-to-one with perceived structure. I could render things in the DOM that aren&#x27;t visible to people (e.g. a transparent 5px x 5px button), or render things to people that aren&#x27;t visible in the DOM (e.g. Facebook&#x27;s DOM obfuscation shenanigans to evade ad-blocking, or rendering custom text to a WebGL canvas). Sure, most websites don&#x27;t go that far, but most websites also aren&#x27;t valuable targets for automated crawling&#x2F;scraping. These kinds of disparities <i>will</i> be exploited to detect and block automated agents if browser automation becomes sufficiently popular, and then we&#x27;re back to needing to render the whole browser and operate on the rendered image to keep ahead of the arms race.</div><br/></div></div><div id="42815232" class="c"><input type="checkbox" id="c-42815232" checked=""/><div class="controls bullet"><span class="by">wiradikusuma</span><span>|</span><a href="#42814620">root</a><span>|</span><a href="#42814714">parent</a><span>|</span><a href="#42816611">prev</a><span>|</span><a href="#42819592">next</a><span>|</span><label class="collapse" for="c-42815232">[-]</label><label class="expand" for="c-42815232">[5 more]</label></div><br/><div class="children"><div class="content">But what if the human programmer needs to visually verify that their code works by eyeballing which element got selected, etc?</div><br/><div id="42815333" class="c"><input type="checkbox" id="c-42815333" checked=""/><div class="controls bullet"><span class="by">fbouvier</span><span>|</span><a href="#42814620">root</a><span>|</span><a href="#42815232">parent</a><span>|</span><a href="#42815363">next</a><span>|</span><label class="collapse" for="c-42815333">[-]</label><label class="expand" for="c-42815333">[2 more]</label></div><br/><div class="children"><div class="content">You&#x27;re right, the debugging part is a good use case for graphical rendering in a headless environment.<p>I see it as a build time&#x2F;runtime question. At build (dev) time I want to have a graphical response (debugging, computer vision, etc.). And then, when the script is ready, I can use Lightpanda at runtime as a lightweight alternative.</div><br/><div id="42818211" class="c"><input type="checkbox" id="c-42818211" checked=""/><div class="controls bullet"><span class="by">codetrotter</span><span>|</span><a href="#42814620">root</a><span>|</span><a href="#42815333">parent</a><span>|</span><a href="#42815363">next</a><span>|</span><label class="collapse" for="c-42818211">[-]</label><label class="expand" for="c-42818211">[1 more]</label></div><br/><div class="children"><div class="content">I was doing a personal side project for a while where I was trying to make my own little Wayback Machine-alike. Mine was very rudimentary, built on top of Firefox and WebDriver plus Squid proxy.<p>For debugging purposes you could have your headless browser function as a HTTP Proxy Server, maybe? And in your headless browser you could capture a static snapshot of the DOM after your JavaScript runtime has executed the scripts for the page. Similar to how the archive.today guy serves static snapshots of websites. And then developers using your headless browser could point their Firefox or Chrome browser to the HTTP Proxy server hosted by your headless browser program, in order to get a static snapshot view of what the DOM is like after your headless browser has executed JavaScript from the page. And then Firefox or Chrome will render static HTML view of what the page looked like to your headless browser, that the developer can inspect to make decisions about further interactions with the page. As a tool for debugging.</div><br/></div></div></div></div><div id="42815363" class="c"><input type="checkbox" id="c-42815363" checked=""/><div class="controls bullet"><span class="by">chrisweekly</span><span>|</span><a href="#42814620">root</a><span>|</span><a href="#42815232">parent</a><span>|</span><a href="#42815333">prev</a><span>|</span><a href="#42815366">next</a><span>|</span><label class="collapse" for="c-42815363">[-]</label><label class="expand" for="c-42815363">[1 more]</label></div><br/><div class="children"><div class="content">If you want a human to eyeball it, you don&#x27;t use a &quot;headless&quot; browser.</div><br/></div></div><div id="42815366" class="c"><input type="checkbox" id="c-42815366" checked=""/><div class="controls bullet"><span class="by">dolmen</span><span>|</span><a href="#42814620">root</a><span>|</span><a href="#42815232">parent</a><span>|</span><a href="#42815363">prev</a><span>|</span><a href="#42819592">next</a><span>|</span><label class="collapse" for="c-42815366">[-]</label><label class="expand" for="c-42815366">[1 more]</label></div><br/><div class="children"><div class="content">The human programmer can save the DOM as HTML in a file and open it in a headfull browser.<p>But the use case for Lightpanda is for machine agents, not humans.</div><br/></div></div></div></div></div></div></div></div><div id="42819592" class="c"><input type="checkbox" id="c-42819592" checked=""/><div class="controls bullet"><span class="by">stuckkeys</span><span>|</span><a href="#42814620">prev</a><span>|</span><a href="#42815357">next</a><span>|</span><label class="collapse" for="c-42819592">[-]</label><label class="expand" for="c-42819592">[1 more]</label></div><br/><div class="children"><div class="content">How does it do against captchas?</div><br/></div></div><div id="42815357" class="c"><input type="checkbox" id="c-42815357" checked=""/><div class="controls bullet"><span class="by">monkmartinez</span><span>|</span><a href="#42819592">prev</a><span>|</span><label class="collapse" for="c-42815357">[-]</label><label class="expand" for="c-42815357">[4 more]</label></div><br/><div class="children"><div class="content">This is pretty neat, but I have to ask; Why does everyone want to build and&#x2F;or use a headless browser?<p>When I use pyautogui and my desktop chrome app I never have problems with captchas or trigger bot detectors. When I use a &quot;headless&quot; playwright, selenium, or puppeteer, I almost always run into problems. My conclusion is that &quot;headless&quot; scrapping creates more problems than it solves. Why don&#x27;t we use the chrome, firefox, safari, or edge that we are using on a day to day basis?</div><br/><div id="42815492" class="c"><input type="checkbox" id="c-42815492" checked=""/><div class="controls bullet"><span class="by">fbouvier</span><span>|</span><a href="#42815357">parent</a><span>|</span><a href="#42815361">next</a><span>|</span><label class="collapse" for="c-42815492">[-]</label><label class="expand" for="c-42815492">[2 more]</label></div><br/><div class="children"><div class="content">I guess it depends on the scale of your requests.<p>When you want to browse a few websites from time to time, a local headful browser might be a solution. But when you have thousands or millions of webpages, you need a server environment and a headless browser.</div><br/><div id="42815565" class="c"><input type="checkbox" id="c-42815565" checked=""/><div class="controls bullet"><span class="by">fbouvier</span><span>|</span><a href="#42815357">root</a><span>|</span><a href="#42815492">parent</a><span>|</span><a href="#42815361">next</a><span>|</span><label class="collapse" for="c-42815565">[-]</label><label class="expand" for="c-42815565">[1 more]</label></div><br/><div class="children"><div class="content">In the past I&#x27;ve run hundreds of headful instances of Chrome in a server environment using Xvfb. It was not a pleasant experience :)</div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>