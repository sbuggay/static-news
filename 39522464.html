<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1709110850068" as="style"/><link rel="stylesheet" href="styles.css?v=1709110850068"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.anandtech.com/show/21277/micron-kicks-off-production-of-hbm3e-memory">Micron Kicks Off Production of HBM3E Memory – AnandTech</a> <span class="domain">(<a href="https://www.anandtech.com">www.anandtech.com</a>)</span></div><div class="subtext"><span>0xd1r</span> | <span>12 comments</span></div><br/><div><div id="39535546" class="c"><input type="checkbox" id="c-39535546" checked=""/><div class="controls bullet"><span class="by">omneity</span><span>|</span><a href="#39534583">next</a><span>|</span><label class="collapse" for="c-39535546">[-]</label><label class="expand" for="c-39535546">[1 more]</label></div><br/><div class="children"><div class="content">Would this explain why I started seeing so many ads from HBM manufacturers with no product an individual like me can purchase? (I&#x27;m not even close to hardware)<p>Not naming the company but seems like HBM manufacturers might be going all-in to benefit from Nvidia&#x27;s surge.</div><br/></div></div><div id="39534583" class="c"><input type="checkbox" id="c-39534583" checked=""/><div class="controls bullet"><span class="by">brucethemoose2</span><span>|</span><a href="#39535546">prev</a><span>|</span><a href="#39535006">next</a><span>|</span><label class="collapse" for="c-39534583">[-]</label><label class="expand" for="c-39534583">[8 more]</label></div><br/><div class="children"><div class="content">How about higher capacity GDDR6X?<p>48GB consumer cards (or 96GB pro cards) would sell like hotcakes if AMD&#x2F;Intel dare to break the artificial VRAM segmentation status quo.</div><br/><div id="39535526" class="c"><input type="checkbox" id="c-39535526" checked=""/><div class="controls bullet"><span class="by">HeWhoLurksLate</span><span>|</span><a href="#39534583">parent</a><span>|</span><a href="#39534899">next</a><span>|</span><label class="collapse" for="c-39535526">[-]</label><label class="expand" for="c-39535526">[2 more]</label></div><br/><div class="children"><div class="content">I swear I&#x27;m getting Deja Vu right now, I coulda sworn I&#x27;ve seen this thread before.  There&#x27;s gonna be a guy commenting that &quot;you don&#x27;t need it&quot; somebody else saying &quot;but I want it!&quot; And a few trying to figure out the economics of it and whether or not it makes any sense.<p>Personally I&#x27;d love to have as much VRAM as possible (and as high a bandwidth as is possible too) to mess around with simulations in- but that&#x27;s <i>definitely</i> a pro workload.<p>I&#x27;d love to see like a flagship card have a stupid amounts of VRAM spec option - like an RTX 4090 with 32-48gb of VRAM just to see what happens with it on the market.</div><br/><div id="39535565" class="c"><input type="checkbox" id="c-39535565" checked=""/><div class="controls bullet"><span class="by">omneity</span><span>|</span><a href="#39534583">root</a><span>|</span><a href="#39535526">parent</a><span>|</span><a href="#39534899">next</a><span>|</span><label class="collapse" for="c-39535565">[-]</label><label class="expand" for="c-39535565">[1 more]</label></div><br/><div class="children"><div class="content">A friend just got an M3 Max with 128GB (V)RAM and he&#x27;s extremely happy with it (AI workloads wise). That could be an option if you can run your simulations on macOS.</div><br/></div></div></div></div><div id="39534899" class="c"><input type="checkbox" id="c-39534899" checked=""/><div class="controls bullet"><span class="by">teaearlgraycold</span><span>|</span><a href="#39534583">parent</a><span>|</span><a href="#39535526">prev</a><span>|</span><a href="#39535214">next</a><span>|</span><label class="collapse" for="c-39534899">[-]</label><label class="expand" for="c-39534899">[1 more]</label></div><br/><div class="children"><div class="content">Build it and people will start porting their CUDA stuff to run on other architectures.</div><br/></div></div><div id="39535214" class="c"><input type="checkbox" id="c-39535214" checked=""/><div class="controls bullet"><span class="by">Brananarchy</span><span>|</span><a href="#39534583">parent</a><span>|</span><a href="#39534899">prev</a><span>|</span><a href="#39535006">next</a><span>|</span><label class="collapse" for="c-39535214">[-]</label><label class="expand" for="c-39535214">[4 more]</label></div><br/><div class="children"><div class="content">You over estimate the &#x27;semi-pro&#x27; market for graphics cards. Gamers are barely willing to pay for 20GB. There&#x27;s no market for consumer cards with an order of magnitude more RAM until games are built to use that memory.</div><br/><div id="39535308" class="c"><input type="checkbox" id="c-39535308" checked=""/><div class="controls bullet"><span class="by">ianbutler</span><span>|</span><a href="#39534583">root</a><span>|</span><a href="#39535214">parent</a><span>|</span><a href="#39535287">next</a><span>|</span><label class="collapse" for="c-39535308">[-]</label><label class="expand" for="c-39535308">[1 more]</label></div><br/><div class="children"><div class="content">This is for ML, not gamers. There is an entirely different market here.</div><br/></div></div><div id="39535287" class="c"><input type="checkbox" id="c-39535287" checked=""/><div class="controls bullet"><span class="by">cinntaile</span><span>|</span><a href="#39534583">root</a><span>|</span><a href="#39535214">parent</a><span>|</span><a href="#39535308">prev</a><span>|</span><a href="#39535006">next</a><span>|</span><label class="collapse" for="c-39535287">[-]</label><label class="expand" for="c-39535287">[2 more]</label></div><br/><div class="children"><div class="content">48GB cards would sell like hotcakes. The problem is that they would sell way less cards aimed at professionals, where they have much higher margins.</div><br/><div id="39535489" class="c"><input type="checkbox" id="c-39535489" checked=""/><div class="controls bullet"><span class="by">AnthonyMouse</span><span>|</span><a href="#39534583">root</a><span>|</span><a href="#39535287">parent</a><span>|</span><a href="#39535006">next</a><span>|</span><label class="collapse" for="c-39535489">[-]</label><label class="expand" for="c-39535489">[1 more]</label></div><br/><div class="children"><div class="content">Intel doesn&#x27;t sell a lot of graphics cards whatsoever though. Be the first to offer 48GB of VRAM for under $1000 and that could change pretty fast.</div><br/></div></div></div></div></div></div></div></div><div id="39535006" class="c"><input type="checkbox" id="c-39535006" checked=""/><div class="controls bullet"><span class="by">hmottestad</span><span>|</span><a href="#39534583">prev</a><span>|</span><label class="collapse" for="c-39535006">[-]</label><label class="expand" for="c-39535006">[2 more]</label></div><br/><div class="children"><div class="content">And Samsung just launched 36 GB packages of HBM3E: <a href="https:&#x2F;&#x2F;www.anandtech.com&#x2F;show&#x2F;21278&#x2F;samsung-launches-12hi-36gb-hbm3e-memory-stacks-with-10-gts-speed" rel="nofollow">https:&#x2F;&#x2F;www.anandtech.com&#x2F;show&#x2F;21278&#x2F;samsung-launches-12hi-3...</a><p>Combined with this[1] interesting paper from summer 2023 on HBM combined with Xeon processors which would now allow for 144 GB on a single CPU. In theory at least.<p>1: <a href="https:&#x2F;&#x2F;lenovopress.lenovo.com&#x2F;lp1738-implementing-intel-high-bandwidth-memory" rel="nofollow">https:&#x2F;&#x2F;lenovopress.lenovo.com&#x2F;lp1738-implementing-intel-hig...</a></div><br/><div id="39535355" class="c"><input type="checkbox" id="c-39535355" checked=""/><div class="controls bullet"><span class="by">hiddencost</span><span>|</span><a href="#39535006">parent</a><span>|</span><label class="collapse" for="c-39535355">[-]</label><label class="expand" for="c-39535355">[1 more]</label></div><br/><div class="children"><div class="content">&gt; launched<p>Not true. They announced completion of development, with intention to begin mass production in H1. So a couple months out, at least.<p>&gt; Micron&#x27;s memory roadmap for AI is further solidified with the upcoming release of a 36 GB 12-Hi HBM3E product in March 2024.<p>So likely competitive timing with Samsung for 36&#x2F;12.</div><br/></div></div></div></div></div></div></div></div></div></body></html>