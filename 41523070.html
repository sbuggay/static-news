<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1726218064028" as="style"/><link rel="stylesheet" href="styles.css?v=1726218064028"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://openai.com/index/learning-to-reason-with-llms/">Learning to Reason with LLMs</a> <span class="domain">(<a href="https://openai.com">openai.com</a>)</span></div><div class="subtext"><span>fofoz</span> | <span>644 comments</span></div><br/><div><div id="41524814" class="c"><input type="checkbox" id="c-41524814" checked=""/><div class="controls bullet"><span class="by">OkGoDoIt</span><span>|</span><a href="#41523496">next</a><span>|</span><label class="collapse" for="c-41524814">[-]</label><label class="expand" for="c-41524814">[52 more]</label></div><br/><div class="children"><div class="content">Some practical notes from digging around in their documentation:
In order to get access to this, you need to be on their tier 5 level, which requires $1,000 total paid and 30+ days since first successful payment.<p>Pricing is $15.00 &#x2F; 1M input tokens and $60.00 &#x2F; 1M output tokens.  Context window is 128k token, max output is 32,768 tokens.<p>There is also a mini version with double the maximum output tokens (65,536 tokens), priced at $3.00 &#x2F; 1M input tokens and $12.00 &#x2F; 1M output tokens.<p>The specialized coding version they mentioned in the blog post does not appear to be available for use.<p>It’s not clear if the hidden chain of thought reasoning is billed as paid output tokens. Has anyone seen any clarification about that?  If you are paying for all of those tokens it could add up quickly. If you expand the chain of thought examples on the blog post they are extremely verbose.<p><a href="https:&#x2F;&#x2F;platform.openai.com&#x2F;docs&#x2F;models&#x2F;o1" rel="nofollow">https:&#x2F;&#x2F;platform.openai.com&#x2F;docs&#x2F;models&#x2F;o1</a>
<a href="https:&#x2F;&#x2F;openai.com&#x2F;api&#x2F;pricing&#x2F;" rel="nofollow">https:&#x2F;&#x2F;openai.com&#x2F;api&#x2F;pricing&#x2F;</a>
<a href="https:&#x2F;&#x2F;platform.openai.com&#x2F;docs&#x2F;guides&#x2F;rate-limits&#x2F;usage-tiers?context=tier-five" rel="nofollow">https:&#x2F;&#x2F;platform.openai.com&#x2F;docs&#x2F;guides&#x2F;rate-limits&#x2F;usage-ti...</a></div><br/><div id="41526506" class="c"><input type="checkbox" id="c-41526506" checked=""/><div class="controls bullet"><span class="by">mistersquid</span><span>|</span><a href="#41524814">parent</a><span>|</span><a href="#41525455">next</a><span>|</span><label class="collapse" for="c-41526506">[-]</label><label class="expand" for="c-41526506">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Some practical notes from digging around in their documentation: In order to get access to this, you need to be on their tier 5 level, which requires $1,000 total paid and 30+ days since first successful payment.<p>Tier 5 level required for _API access_. ChatGPT Plus users, for example, also have access to the o1 models.</div><br/></div></div><div id="41525455" class="c"><input type="checkbox" id="c-41525455" checked=""/><div class="controls bullet"><span class="by">vdfs</span><span>|</span><a href="#41524814">parent</a><span>|</span><a href="#41526506">prev</a><span>|</span><a href="#41525151">next</a><span>|</span><label class="collapse" for="c-41525455">[-]</label><label class="expand" for="c-41525455">[1 more]</label></div><br/><div class="children"><div class="content">We just receivied this email:<p>Hi there,<p>I’m x, PM for the OpenAI API. I’m pleased to share with you our new series of models, OpenAI o1. We’ve developed these models to spend more time thinking before they respond. They can reason through complex tasks and solve harder problems than previous models in science, coding, and math.<p>As a trusted developer on usage tier 5, you’re invited to get started with the o1 beta today.
Read the docs
You have access to two models:<p><pre><code>    Our larger model, o1-preview, which has strong reasoning capabilities and broad world knowledge. 
    Our smaller model, o1-mini, which is 80% cheaper than o1-preview.

</code></pre>
Try both models! You may find one better than the other for your specific use case. Both currently have a rate limit of 20 RPM during the beta. But keep in mind o1-mini is faster, cheaper, and competitive with o1-preview at coding tasks (you can see how it performs here). We’ve also written up more about these models in our blog post.<p>I’m curious to hear what you think. If you’re on X, I’d love to see what you build—just reply to our post.<p>Best,
OpenAI API</div><br/></div></div><div id="41525151" class="c"><input type="checkbox" id="c-41525151" checked=""/><div class="controls bullet"><span class="by">activatedgeek</span><span>|</span><a href="#41524814">parent</a><span>|</span><a href="#41525455">prev</a><span>|</span><a href="#41526333">next</a><span>|</span><label class="collapse" for="c-41525151">[-]</label><label class="expand" for="c-41525151">[27 more]</label></div><br/><div class="children"><div class="content">Reasoning tokens are indeed billed as output tokens.<p>&gt; While reasoning tokens are not visible via the API, they still occupy space in the model&#x27;s context window and are billed as output tokens.<p>From here: <a href="https:&#x2F;&#x2F;platform.openai.com&#x2F;docs&#x2F;guides&#x2F;reasoning" rel="nofollow">https:&#x2F;&#x2F;platform.openai.com&#x2F;docs&#x2F;guides&#x2F;reasoning</a></div><br/><div id="41525444" class="c"><input type="checkbox" id="c-41525444" checked=""/><div class="controls bullet"><span class="by">baq</span><span>|</span><a href="#41524814">root</a><span>|</span><a href="#41525151">parent</a><span>|</span><a href="#41529059">next</a><span>|</span><label class="collapse" for="c-41525444">[-]</label><label class="expand" for="c-41525444">[25 more]</label></div><br/><div class="children"><div class="content">This is concerning - how do you know you aren’t being fleeced out of your money here…? You’ll get your results, but did you <i>really</i> use that much?</div><br/><div id="41528097" class="c"><input type="checkbox" id="c-41528097" checked=""/><div class="controls bullet"><span class="by">jstummbillig</span><span>|</span><a href="#41524814">root</a><span>|</span><a href="#41525444">parent</a><span>|</span><a href="#41526201">next</a><span>|</span><label class="collapse" for="c-41528097">[-]</label><label class="expand" for="c-41528097">[9 more]</label></div><br/><div class="children"><div class="content">I think it&#x27;s fantastic that now, for very little money, everyone gets to share a narrow but stressful subset of what it feels like to employ other people.<p>Really, I recommend reading this part of the thread while thinking about the analogy. It&#x27;s great.</div><br/><div id="41528443" class="c"><input type="checkbox" id="c-41528443" checked=""/><div class="controls bullet"><span class="by">baq</span><span>|</span><a href="#41524814">root</a><span>|</span><a href="#41528097">parent</a><span>|</span><a href="#41528176">next</a><span>|</span><label class="collapse" for="c-41528443">[-]</label><label class="expand" for="c-41528443">[2 more]</label></div><br/><div class="children"><div class="content">It’s nice on the outside, but employees are actually all different people and this here is one company’s blob of numbers with not much incentive to optimize your cost.<p>Competition fixes some of this, I hope Anthropic and Mistral are not far behind.</div><br/><div id="41528580" class="c"><input type="checkbox" id="c-41528580" checked=""/><div class="controls bullet"><span class="by">adwn</span><span>|</span><a href="#41524814">root</a><span>|</span><a href="#41528443">parent</a><span>|</span><a href="#41528176">next</a><span>|</span><label class="collapse" for="c-41528580">[-]</label><label class="expand" for="c-41528580">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>[…] with not much incentive to optimize your cost. Competition fixes some of this […]</i><p>Just like employing other people!</div><br/></div></div></div></div><div id="41528176" class="c"><input type="checkbox" id="c-41528176" checked=""/><div class="controls bullet"><span class="by">ta8645</span><span>|</span><a href="#41524814">root</a><span>|</span><a href="#41528097">parent</a><span>|</span><a href="#41528443">prev</a><span>|</span><a href="#41528229">next</a><span>|</span><label class="collapse" for="c-41528176">[-]</label><label class="expand" for="c-41528176">[1 more]</label></div><br/><div class="children"><div class="content">Your idea is really a brilliant insight.  Revealing.</div><br/></div></div><div id="41528229" class="c"><input type="checkbox" id="c-41528229" checked=""/><div class="controls bullet"><span class="by">gsbcbdjfncnjd</span><span>|</span><a href="#41524814">root</a><span>|</span><a href="#41528097">parent</a><span>|</span><a href="#41528176">prev</a><span>|</span><a href="#41526201">next</a><span>|</span><label class="collapse" for="c-41528229">[-]</label><label class="expand" for="c-41528229">[5 more]</label></div><br/><div class="children"><div class="content">Any respectable employer&#x2F;employee relationship transacts on results rather than time anyway. Not sure the analogy is very applicable in that light.</div><br/><div id="41528446" class="c"><input type="checkbox" id="c-41528446" checked=""/><div class="controls bullet"><span class="by">konschubert</span><span>|</span><a href="#41524814">root</a><span>|</span><a href="#41528229">parent</a><span>|</span><a href="#41528574">next</a><span>|</span><label class="collapse" for="c-41528446">[-]</label><label class="expand" for="c-41528446">[1 more]</label></div><br/><div class="children"><div class="content">It is!</div><br/></div></div><div id="41528574" class="c"><input type="checkbox" id="c-41528574" checked=""/><div class="controls bullet"><span class="by">adwn</span><span>|</span><a href="#41524814">root</a><span>|</span><a href="#41528229">parent</a><span>|</span><a href="#41528446">prev</a><span>|</span><a href="#41526201">next</a><span>|</span><label class="collapse" for="c-41528574">[-]</label><label class="expand" for="c-41528574">[3 more]</label></div><br/><div class="children"><div class="content">&gt; Any respectable employer&#x2F;employee relationship transacts on results rather than time anyway.<p>No. This may be common in freelance contracts, but is almost never the case in employment contracts, which specify a time-based compensation (usually either per hour or per month).</div><br/><div id="41528630" class="c"><input type="checkbox" id="c-41528630" checked=""/><div class="controls bullet"><span class="by">gsbcbdjfncnjd</span><span>|</span><a href="#41524814">root</a><span>|</span><a href="#41528574">parent</a><span>|</span><a href="#41526201">next</a><span>|</span><label class="collapse" for="c-41528630">[-]</label><label class="expand" for="c-41528630">[2 more]</label></div><br/><div class="children"><div class="content">Yea, I said ‘respectable’.</div><br/><div id="41528744" class="c"><input type="checkbox" id="c-41528744" checked=""/><div class="controls bullet"><span class="by">KeplerBoy</span><span>|</span><a href="#41524814">root</a><span>|</span><a href="#41528630">parent</a><span>|</span><a href="#41526201">next</a><span>|</span><label class="collapse" for="c-41528744">[-]</label><label class="expand" for="c-41528744">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s just not how employment laws are written.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="41526201" class="c"><input type="checkbox" id="c-41526201" checked=""/><div class="controls bullet"><span class="by">lolinder</span><span>|</span><a href="#41524814">root</a><span>|</span><a href="#41525444">parent</a><span>|</span><a href="#41528097">prev</a><span>|</span><a href="#41525916">next</a><span>|</span><label class="collapse" for="c-41526201">[-]</label><label class="expand" for="c-41526201">[4 more]</label></div><br/><div class="children"><div class="content">Also, now we&#x27;re paying for output tokens that aren&#x27;t even output, with no good explanation for why these tokens should be hidden from the person who paid for them.</div><br/><div id="41526699" class="c"><input type="checkbox" id="c-41526699" checked=""/><div class="controls bullet"><span class="by">HeatrayEnjoyer</span><span>|</span><a href="#41524814">root</a><span>|</span><a href="#41526201">parent</a><span>|</span><a href="#41525916">next</a><span>|</span><label class="collapse" for="c-41526699">[-]</label><label class="expand" for="c-41526699">[3 more]</label></div><br/><div class="children"><div class="content">If you read the link they have a section specifically explaining why it is hidden.</div><br/><div id="41526901" class="c"><input type="checkbox" id="c-41526901" checked=""/><div class="controls bullet"><span class="by">lolinder</span><span>|</span><a href="#41524814">root</a><span>|</span><a href="#41526699">parent</a><span>|</span><a href="#41525916">next</a><span>|</span><label class="collapse" for="c-41526901">[-]</label><label class="expand" for="c-41526901">[2 more]</label></div><br/><div class="children"><div class="content">I read it. It&#x27;s a <i>bad</i> explanation.<p>The only bit about it that feels at all truthful is this bit, which is glossed over but likely the only real factor in the decision:<p>&gt; after weighing multiple factors including ... competitive advantage ... we have decided not to show the raw chains of thought to users.</div><br/><div id="41527219" class="c"><input type="checkbox" id="c-41527219" checked=""/><div class="controls bullet"><span class="by">infogulch</span><span>|</span><a href="#41524814">root</a><span>|</span><a href="#41526901">parent</a><span>|</span><a href="#41525916">next</a><span>|</span><label class="collapse" for="c-41527219">[-]</label><label class="expand" for="c-41527219">[1 more]</label></div><br/><div class="children"><div class="content">Good catch. That indicates that chains of thought are a straightforward approach to make LLMs better at reasoning if you could copy it just by seeing the steps.</div><br/></div></div></div></div></div></div></div></div><div id="41525916" class="c"><input type="checkbox" id="c-41525916" checked=""/><div class="controls bullet"><span class="by">rsanek</span><span>|</span><a href="#41524814">root</a><span>|</span><a href="#41525444">parent</a><span>|</span><a href="#41526201">prev</a><span>|</span><a href="#41526596">next</a><span>|</span><label class="collapse" for="c-41525916">[-]</label><label class="expand" for="c-41525916">[1 more]</label></div><br/><div class="children"><div class="content">obfuscated billing has long been a staple of all great cloud products. AWS innovated in the space and now many have followed in their footsteps</div><br/></div></div><div id="41526596" class="c"><input type="checkbox" id="c-41526596" checked=""/><div class="controls bullet"><span class="by">RobertDeNiro</span><span>|</span><a href="#41524814">root</a><span>|</span><a href="#41525444">parent</a><span>|</span><a href="#41525916">prev</a><span>|</span><a href="#41527058">next</a><span>|</span><label class="collapse" for="c-41526596">[-]</label><label class="expand" for="c-41526596">[7 more]</label></div><br/><div class="children"><div class="content">Also seems very impractical to embed this into a deployed product. How can you possibly hope to control and estimate costs? I guess this is strictly meant for R&amp;D purposes.</div><br/><div id="41526659" class="c"><input type="checkbox" id="c-41526659" checked=""/><div class="controls bullet"><span class="by">sebzim4500</span><span>|</span><a href="#41524814">root</a><span>|</span><a href="#41526596">parent</a><span>|</span><a href="#41527552">next</a><span>|</span><label class="collapse" for="c-41526659">[-]</label><label class="expand" for="c-41526659">[5 more]</label></div><br/><div class="children"><div class="content">You can specify the max length of the response, which presumably includes the hidden tokens.<p>I don&#x27;t see why this is qualitatively different from a cost perspective than using CoT prompting on existing models.</div><br/><div id="41526760" class="c"><input type="checkbox" id="c-41526760" checked=""/><div class="controls bullet"><span class="by">dartos</span><span>|</span><a href="#41524814">root</a><span>|</span><a href="#41526659">parent</a><span>|</span><a href="#41527036">next</a><span>|</span><label class="collapse" for="c-41526760">[-]</label><label class="expand" for="c-41526760">[1 more]</label></div><br/><div class="children"><div class="content">You can’t verify that you’re paying what you should be if you can’t see the hidden tokens.</div><br/></div></div><div id="41527036" class="c"><input type="checkbox" id="c-41527036" checked=""/><div class="controls bullet"><span class="by">BoorishBears</span><span>|</span><a href="#41524814">root</a><span>|</span><a href="#41526659">parent</a><span>|</span><a href="#41526760">prev</a><span>|</span><a href="#41527552">next</a><span>|</span><label class="collapse" for="c-41527036">[-]</label><label class="expand" for="c-41527036">[3 more]</label></div><br/><div class="children"><div class="content">For one, you don&#x27;t get to see any output at all if you run out of tokens during thinking.<p>If you set a limit, once it&#x27;s hit you just get a failed request with no introspection on where and why CoT went off the rails</div><br/><div id="41527744" class="c"><input type="checkbox" id="c-41527744" checked=""/><div class="controls bullet"><span class="by">Aeolun</span><span>|</span><a href="#41524814">root</a><span>|</span><a href="#41527036">parent</a><span>|</span><a href="#41527552">next</a><span>|</span><label class="collapse" for="c-41527744">[-]</label><label class="expand" for="c-41527744">[2 more]</label></div><br/><div class="children"><div class="content">Why would I pay for zero output? That’s essentially throwing money down the drain.</div><br/></div></div></div></div></div></div><div id="41527552" class="c"><input type="checkbox" id="c-41527552" checked=""/><div class="controls bullet"><span class="by">HarHarVeryFunny</span><span>|</span><a href="#41524814">root</a><span>|</span><a href="#41526596">parent</a><span>|</span><a href="#41526659">prev</a><span>|</span><a href="#41527058">next</a><span>|</span><label class="collapse" for="c-41527552">[-]</label><label class="expand" for="c-41527552">[1 more]</label></div><br/><div class="children"><div class="content">They are currently trying to raise money (talk of new $150B valuation), so that may have something to do with it</div><br/></div></div></div></div><div id="41527058" class="c"><input type="checkbox" id="c-41527058" checked=""/><div class="controls bullet"><span class="by">Emiledel</span><span>|</span><a href="#41524814">root</a><span>|</span><a href="#41525444">parent</a><span>|</span><a href="#41526596">prev</a><span>|</span><a href="#41529059">next</a><span>|</span><label class="collapse" for="c-41527058">[-]</label><label class="expand" for="c-41527058">[3 more]</label></div><br/><div class="children"><div class="content">In the UI the reasoning is visible. The API can probably return it too, just check the code</div><br/><div id="41529025" class="c"><input type="checkbox" id="c-41529025" checked=""/><div class="controls bullet"><span class="by">AlphaAndOmega0</span><span>|</span><a href="#41524814">root</a><span>|</span><a href="#41527058">parent</a><span>|</span><a href="#41527279">next</a><span>|</span><label class="collapse" for="c-41529025">[-]</label><label class="expand" for="c-41529025">[1 more]</label></div><br/><div class="children"><div class="content">OAI doesn&#x27;t show the <i>actual</i> COT, on the grounds that it&#x27;s potentially unsafe output and also to prevent competitors training on it. You only see a sanitized summary.</div><br/></div></div><div id="41527279" class="c"><input type="checkbox" id="c-41527279" checked=""/><div class="controls bullet"><span class="by">og_kalu</span><span>|</span><a href="#41524814">root</a><span>|</span><a href="#41527058">parent</a><span>|</span><a href="#41529025">prev</a><span>|</span><a href="#41529059">next</a><span>|</span><label class="collapse" for="c-41527279">[-]</label><label class="expand" for="c-41527279">[1 more]</label></div><br/><div class="children"><div class="content">What&#x27;s shown in the UI is a summary of the reasoning</div><br/></div></div></div></div></div></div><div id="41529059" class="c"><input type="checkbox" id="c-41529059" checked=""/><div class="controls bullet"><span class="by">creatonez</span><span>|</span><a href="#41524814">root</a><span>|</span><a href="#41525151">parent</a><span>|</span><a href="#41525444">prev</a><span>|</span><a href="#41526333">next</a><span>|</span><label class="collapse" for="c-41529059">[-]</label><label class="expand" for="c-41529059">[1 more]</label></div><br/><div class="children"><div class="content">No access to reasoning output seems totally bonkers. All of the real cost is in inference, assembling an HTTP request to deliver that result seems trivial?</div><br/></div></div></div></div><div id="41526333" class="c"><input type="checkbox" id="c-41526333" checked=""/><div class="controls bullet"><span class="by">arnaudsm</span><span>|</span><a href="#41524814">parent</a><span>|</span><a href="#41525151">prev</a><span>|</span><a href="#41526995">next</a><span>|</span><label class="collapse" for="c-41526333">[-]</label><label class="expand" for="c-41526333">[7 more]</label></div><br/><div class="children"><div class="content">Some of the queries run for multiple minutes. 40 tokens&#x2F;sec is too slow for CoT.<p>I hope OpenAI is investing in low-latency like Groq&#x27;s tech that can reach 1k tokens&#x2F;sec.</div><br/><div id="41527485" class="c"><input type="checkbox" id="c-41527485" checked=""/><div class="controls bullet"><span class="by">p-e-w</span><span>|</span><a href="#41524814">root</a><span>|</span><a href="#41526333">parent</a><span>|</span><a href="#41526995">next</a><span>|</span><label class="collapse" for="c-41527485">[-]</label><label class="expand" for="c-41527485">[6 more]</label></div><br/><div class="children"><div class="content">It&#x27;s slow and expensive if you compare it with other LLMs.<p>It&#x27;s lightning fast and dirt cheap if you compare it to consulting with a human expert, which it appears to be competitive with.</div><br/><div id="41528002" class="c"><input type="checkbox" id="c-41528002" checked=""/><div class="controls bullet"><span class="by">barrell</span><span>|</span><a href="#41524814">root</a><span>|</span><a href="#41527485">parent</a><span>|</span><a href="#41526995">next</a><span>|</span><label class="collapse" for="c-41528002">[-]</label><label class="expand" for="c-41528002">[5 more]</label></div><br/><div class="children"><div class="content">I would say consulting with a human. Any expert who has a conversation with chatGPT about their field will verify that it is very far from expert</div><br/><div id="41528014" class="c"><input type="checkbox" id="c-41528014" checked=""/><div class="controls bullet"><span class="by">p-e-w</span><span>|</span><a href="#41524814">root</a><span>|</span><a href="#41528002">parent</a><span>|</span><a href="#41526995">next</a><span>|</span><label class="collapse" for="c-41528014">[-]</label><label class="expand" for="c-41528014">[4 more]</label></div><br/><div class="children"><div class="content">According to the data provided by OpenAI, that isn&#x27;t true anymore. And I trust data more than anecdotal claims made by people whose job is being threatened by systems like these.</div><br/><div id="41528115" class="c"><input type="checkbox" id="c-41528115" checked=""/><div class="controls bullet"><span class="by">adonese</span><span>|</span><a href="#41524814">root</a><span>|</span><a href="#41528014">parent</a><span>|</span><a href="#41528964">next</a><span>|</span><label class="collapse" for="c-41528115">[-]</label><label class="expand" for="c-41528115">[1 more]</label></div><br/><div class="children"><div class="content">&gt;According to the data provided by OpenAI, that isn&#x27;t true anymore<p>OpenAI main job is to sell that their models are better than human. I still remember when they&#x27;re marketing their gpt-2 weights as too dangerous to release.</div><br/></div></div><div id="41528964" class="c"><input type="checkbox" id="c-41528964" checked=""/><div class="controls bullet"><span class="by">barrell</span><span>|</span><a href="#41524814">root</a><span>|</span><a href="#41528014">parent</a><span>|</span><a href="#41528115">prev</a><span>|</span><a href="#41528385">next</a><span>|</span><label class="collapse" for="c-41528964">[-]</label><label class="expand" for="c-41528964">[1 more]</label></div><br/><div class="children"><div class="content">What? Surely you have some area of your life you are above-average knowledgable about. Have a conversation with chatGPT about it, with whatever model, and you can see for yourself it is far from expert level.<p>You are not &quot;trusting data more than anecdotal claims&quot;, you are trusting marketing over reality.<p>Benchmarks can be gamed. Statistics can be manipulated. Demonstrations can be cherry picked.<p>PS: I stand to gain heavily if AI systems could perform at an expert level, this is not a claim from someone &#x27;whose job is being threatened&#x27;.</div><br/></div></div><div id="41528385" class="c"><input type="checkbox" id="c-41528385" checked=""/><div class="controls bullet"><span class="by">Extasia785</span><span>|</span><a href="#41524814">root</a><span>|</span><a href="#41528014">parent</a><span>|</span><a href="#41528964">prev</a><span>|</span><a href="#41526995">next</a><span>|</span><label class="collapse" for="c-41528385">[-]</label><label class="expand" for="c-41528385">[1 more]</label></div><br/><div class="children"><div class="content">&gt; For each problem, our system sampled many candidate submissions and submitted 50 of them based on a test-time selection strategy. Submissions were selected based on performance on the IOI public test cases, model-generated test cases, and a learned scoring function. If we had instead submitted at random, we would have only scored 156 points on average, suggesting that this strategy was worth nearly 60 points under competition constraints.<p>Did you read the post? OpenAI clearly states that the results are cherry-picked. Just a random query will have far worse results. To get equal results you need to ask the same query dozens of time and then have enough expertise to pick the best one, which might be quite hard for a problem that you have little idea about.<p>Combine this with the fact that this blog post is a sales pitch with the very best test results out of probably many more benchmarks we will never see and it seems obvious that human experts are still several order of magnitudes ahead.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="41526995" class="c"><input type="checkbox" id="c-41526995" checked=""/><div class="controls bullet"><span class="by">attentive</span><span>|</span><a href="#41524814">parent</a><span>|</span><a href="#41526333">prev</a><span>|</span><a href="#41525566">next</a><span>|</span><label class="collapse" for="c-41526995">[-]</label><label class="expand" for="c-41526995">[2 more]</label></div><br/><div class="children"><div class="content">So, basically, it&#x27;s chain of thought as a service?<p>Not a model, per se, but a service that chains multiple model requests behind the scene?</div><br/><div id="41528761" class="c"><input type="checkbox" id="c-41528761" checked=""/><div class="controls bullet"><span class="by">KeplerBoy</span><span>|</span><a href="#41524814">root</a><span>|</span><a href="#41526995">parent</a><span>|</span><a href="#41525566">next</a><span>|</span><label class="collapse" for="c-41528761">[-]</label><label class="expand" for="c-41528761">[1 more]</label></div><br/><div class="children"><div class="content">Who knows? Certainly not the public.<p>It might be a finetuned model that works better in such a setting.</div><br/></div></div></div></div><div id="41525566" class="c"><input type="checkbox" id="c-41525566" checked=""/><div class="controls bullet"><span class="by">liamwire</span><span>|</span><a href="#41524814">parent</a><span>|</span><a href="#41526995">prev</a><span>|</span><a href="#41525553">next</a><span>|</span><label class="collapse" for="c-41525566">[-]</label><label class="expand" for="c-41525566">[2 more]</label></div><br/><div class="children"><div class="content">Unless this is specifically relating to API access, I don’t think it’s correct. I’ve been paying for ChatGPT via the App Store IAP for around a year or less, and I’ve already got both o1-preview and o1-mini available in-app.</div><br/><div id="41525679" class="c"><input type="checkbox" id="c-41525679" checked=""/><div class="controls bullet"><span class="by">OkGoDoIt</span><span>|</span><a href="#41524814">root</a><span>|</span><a href="#41525566">parent</a><span>|</span><a href="#41525553">next</a><span>|</span><label class="collapse" for="c-41525679">[-]</label><label class="expand" for="c-41525679">[1 more]</label></div><br/><div class="children"><div class="content">Yes, I was referring to API access specifically. Nothing in the blog post or the documentation mentions access to these new models on ChatGPT, and even as a paid user I’m not seeing them on there (Edit: I am seeing it now in the app). But looks like a bunch of other people in this discussion do have it on ChatGPT, so that’s exciting to hear.</div><br/></div></div></div></div><div id="41525553" class="c"><input type="checkbox" id="c-41525553" checked=""/><div class="controls bullet"><span class="by">sashank_1509</span><span>|</span><a href="#41524814">parent</a><span>|</span><a href="#41525566">prev</a><span>|</span><a href="#41526441">next</a><span>|</span><label class="collapse" for="c-41525553">[-]</label><label class="expand" for="c-41525553">[3 more]</label></div><br/><div class="children"><div class="content">I have access to this and there is no way I spend more than 50$ on OpenAI api. I have ChatGPT + since day q though (240$ probably in total)</div><br/><div id="41525977" class="c"><input type="checkbox" id="c-41525977" checked=""/><div class="controls bullet"><span class="by">rpmisms</span><span>|</span><a href="#41524814">root</a><span>|</span><a href="#41525553">parent</a><span>|</span><a href="#41526441">next</a><span>|</span><label class="collapse" for="c-41525977">[-]</label><label class="expand" for="c-41525977">[2 more]</label></div><br/><div class="children"><div class="content">You missed your raise key on &quot;day q&quot;</div><br/><div id="41526878" class="c"><input type="checkbox" id="c-41526878" checked=""/><div class="controls bullet"><span class="by">thelastparadise</span><span>|</span><a href="#41524814">root</a><span>|</span><a href="#41525977">parent</a><span>|</span><a href="#41526441">next</a><span>|</span><label class="collapse" for="c-41526878">[-]</label><label class="expand" for="c-41526878">[1 more]</label></div><br/><div class="children"><div class="content">Raise it up just one</div><br/></div></div></div></div></div></div><div id="41526441" class="c"><input type="checkbox" id="c-41526441" checked=""/><div class="controls bullet"><span class="by">jonahx</span><span>|</span><a href="#41524814">parent</a><span>|</span><a href="#41525553">prev</a><span>|</span><a href="#41525152">next</a><span>|</span><label class="collapse" for="c-41526441">[-]</label><label class="expand" for="c-41526441">[1 more]</label></div><br/><div class="children"><div class="content">I am an ordinary plus user (since it was released more or less) and have access.</div><br/></div></div><div id="41525152" class="c"><input type="checkbox" id="c-41525152" checked=""/><div class="controls bullet"><span class="by">amrrs</span><span>|</span><a href="#41524814">parent</a><span>|</span><a href="#41526441">prev</a><span>|</span><a href="#41525559">next</a><span>|</span><label class="collapse" for="c-41525152">[-]</label><label class="expand" for="c-41525152">[1 more]</label></div><br/><div class="children"><div class="content">The CoT is billed as output tokens. Mentioned in the docs where it talks about reasoning</div><br/></div></div><div id="41525559" class="c"><input type="checkbox" id="c-41525559" checked=""/><div class="controls bullet"><span class="by">Buttons840</span><span>|</span><a href="#41524814">parent</a><span>|</span><a href="#41525152">prev</a><span>|</span><a href="#41527402">next</a><span>|</span><label class="collapse" for="c-41525559">[-]</label><label class="expand" for="c-41525559">[1 more]</label></div><br/><div class="children"><div class="content">I am a Plus user and pay $20 per month. I have access to the o1 models.</div><br/></div></div><div id="41527402" class="c"><input type="checkbox" id="c-41527402" checked=""/><div class="controls bullet"><span class="by">kinj28</span><span>|</span><a href="#41524814">parent</a><span>|</span><a href="#41525559">prev</a><span>|</span><a href="#41525590">next</a><span>|</span><label class="collapse" for="c-41527402">[-]</label><label class="expand" for="c-41527402">[1 more]</label></div><br/><div class="children"><div class="content">A bit out of context.<p>Am curious if at some point length of context window stops playing any material difference in the output and it just stops making any economical sense as law of marginal diminishing utility kicks in.</div><br/></div></div><div id="41526392" class="c"><input type="checkbox" id="c-41526392" checked=""/><div class="controls bullet"><span class="by">anigbrowl</span><span>|</span><a href="#41524814">parent</a><span>|</span><a href="#41525590">prev</a><span>|</span><a href="#41526295">next</a><span>|</span><label class="collapse" for="c-41526392">[-]</label><label class="expand" for="c-41526392">[2 more]</label></div><br/><div class="children"><div class="content"><i>you need to be on their tier 5 level, which requires $1,000 total paid and [...]</i><p>Good opening for OpenAI&#x27;s competitors to run a &#x27;we&#x27;re not snobs&#x27; promotion.</div><br/><div id="41526810" class="c"><input type="checkbox" id="c-41526810" checked=""/><div class="controls bullet"><span class="by">infecto</span><span>|</span><a href="#41524814">root</a><span>|</span><a href="#41526392">parent</a><span>|</span><a href="#41526295">next</a><span>|</span><label class="collapse" for="c-41526810">[-]</label><label class="expand" for="c-41526810">[1 more]</label></div><br/><div class="children"><div class="content">How so? I think most of the competition does this. Early partners&#x2F;heavy users get access first which 1) hopefully provides feedback on the product and 2) provides a mechanism to stagger the release.</div><br/></div></div></div></div></div></div><div id="41523496" class="c"><input type="checkbox" id="c-41523496" checked=""/><div class="controls bullet"><span class="by">ARandumGuy</span><span>|</span><a href="#41524814">prev</a><span>|</span><a href="#41524169">next</a><span>|</span><label class="collapse" for="c-41523496">[-]</label><label class="expand" for="c-41523496">[70 more]</label></div><br/><div class="children"><div class="content">One thing that makes me skeptical is the lack of specific labels on the first two accuracy graphs. They just say it&#x27;s a &quot;log scale&quot;, without giving even a ballpark on the amount of time it took.<p>Did the 80% accuracy test results take 10 seconds of compute? 10 minutes? 10 hours? 10 days? It&#x27;s impossible to say with the data they&#x27;ve given us.<p>The coding section indicates &quot;ten hours to solve six challenging algorithmic problems&quot;, but it&#x27;s not clear to me if that&#x27;s tied to the graphs at the beginning of the article.<p>The article contains a lot of facts and figures, which is good! But it doesn&#x27;t inspire confidence that the authors chose to obfuscate the data in the first two graphs in the article. Maybe I&#x27;m wrong, but this reads a lot like they&#x27;re cherry picking the data that makes them look good, while hiding the data that doesn&#x27;t look very good.</div><br/><div id="41523812" class="c"><input type="checkbox" id="c-41523812" checked=""/><div class="controls bullet"><span class="by">swatcoder</span><span>|</span><a href="#41523496">parent</a><span>|</span><a href="#41523612">next</a><span>|</span><label class="collapse" for="c-41523812">[-]</label><label class="expand" for="c-41523812">[20 more]</label></div><br/><div class="children"><div class="content">&gt; Did the 80% accuracy test results take 10 seconds of compute? 10 minutes? 10 hours? 10 days? It&#x27;s impossible to say with the data they&#x27;ve given us.<p>The gist of the answer is hiding in plain sight: it took so long, on an exponential cost function, that they couldn&#x27;t afford to explore any further.<p>The better their max demonstrated accuracy, the more impressive this report is. So why stop where they did? Why omit actual clock times or some cost proxy for it from the report? Obviously, it&#x27;s because continuing was impractical and because those times&#x2F;costs were already so large that they&#x27;d unfavorably affect how people respond to this report</div><br/><div id="41524048" class="c"><input type="checkbox" id="c-41524048" checked=""/><div class="controls bullet"><span class="by">jsheard</span><span>|</span><a href="#41523496">root</a><span>|</span><a href="#41523812">parent</a><span>|</span><a href="#41523612">next</a><span>|</span><label class="collapse" for="c-41524048">[-]</label><label class="expand" for="c-41524048">[19 more]</label></div><br/><div class="children"><div class="content">See also: them still sitting on Sora seven months after announcing it. They&#x27;ve never given any indication whatsoever of how much compute it uses, so it may be impossible to release in its current state without charging an exorbitant amount of money per generation. We do know from people who have used it that it takes between 10 and 20 minutes to render a shot, but how much hardware is being tied up during that time is a mystery.</div><br/><div id="41524202" class="c"><input type="checkbox" id="c-41524202" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#41523496">root</a><span>|</span><a href="#41524048">parent</a><span>|</span><a href="#41526512">next</a><span>|</span><label class="collapse" for="c-41524202">[-]</label><label class="expand" for="c-41524202">[14 more]</label></div><br/><div class="children"><div class="content">Could well be.<p>It&#x27;s also entirely possible they are simply sincere about their fear it may be used to influence the upcoming US election.<p>Plenty of people (me included) are sincerely concerned about the way even mere still image generators can drown out the truth with a flood of good-enough-at-first-glance fiction.</div><br/><div id="41524225" class="c"><input type="checkbox" id="c-41524225" checked=""/><div class="controls bullet"><span class="by">jsheard</span><span>|</span><a href="#41523496">root</a><span>|</span><a href="#41524202">parent</a><span>|</span><a href="#41524257">next</a><span>|</span><label class="collapse" for="c-41524225">[-]</label><label class="expand" for="c-41524225">[7 more]</label></div><br/><div class="children"><div class="content">If they were sincere about that concern then they wouldn&#x27;t build it at all, if it&#x27;s ever made available to the public then it will eventually be available during an election. It&#x27;s not like the 2024 US presidential election is the end of history.</div><br/><div id="41524542" class="c"><input type="checkbox" id="c-41524542" checked=""/><div class="controls bullet"><span class="by">e1g</span><span>|</span><a href="#41523496">root</a><span>|</span><a href="#41524225">parent</a><span>|</span><a href="#41525116">next</a><span>|</span><label class="collapse" for="c-41524542">[-]</label><label class="expand" for="c-41524542">[1 more]</label></div><br/><div class="children"><div class="content">The risk is not “interfering with the US elections”, but “being on the front page of everything as the only AI company interfering with US elections”. This would destroy  their peacocking around AGI&#x2F;alignment while raising billions from pension funds.<p>OpenAI is in a very precarious position. Maybe they could survive that hit in four years, but it would be fatal today. No unforced errors.</div><br/></div></div><div id="41525116" class="c"><input type="checkbox" id="c-41525116" checked=""/><div class="controls bullet"><span class="by">smegger001</span><span>|</span><a href="#41523496">root</a><span>|</span><a href="#41524225">parent</a><span>|</span><a href="#41524542">prev</a><span>|</span><a href="#41524257">next</a><span>|</span><label class="collapse" for="c-41525116">[-]</label><label class="expand" for="c-41525116">[5 more]</label></div><br/><div class="children"><div class="content">i think the hope is by the next presidential election no one will trust video anymore anyway so the new normal wont be as chaotic as if the dropped in the middle of an already contentious election.<p>as for not building it at all its a obvious next step in generative ai models that if they don&#x27;t make it someone else will anyway.</div><br/><div id="41527768" class="c"><input type="checkbox" id="c-41527768" checked=""/><div class="controls bullet"><span class="by">Aeolun</span><span>|</span><a href="#41523496">root</a><span>|</span><a href="#41525116">parent</a><span>|</span><a href="#41525592">next</a><span>|</span><label class="collapse" for="c-41527768">[-]</label><label class="expand" for="c-41527768">[3 more]</label></div><br/><div class="children"><div class="content">Wouldn’t it be nice if we came full circle and went to listen to our politicians live because anything else would be pointless.</div><br/><div id="41528937" class="c"><input type="checkbox" id="c-41528937" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#41523496">root</a><span>|</span><a href="#41527768">parent</a><span>|</span><a href="#41527868">next</a><span>|</span><label class="collapse" for="c-41528937">[-]</label><label class="expand" for="c-41528937">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;d give it about 20 years before humanoid robots can be indistinguishable from originals without an x-ray or similar — covering them in vat-grown cultures of real human skin etc. is already possible but the robots themselves aren&#x27;t good enough to fool anyone.</div><br/></div></div><div id="41527868" class="c"><input type="checkbox" id="c-41527868" checked=""/><div class="controls bullet"><span class="by">smegger001</span><span>|</span><a href="#41523496">root</a><span>|</span><a href="#41527768">parent</a><span>|</span><a href="#41528937">prev</a><span>|</span><a href="#41525592">next</a><span>|</span><label class="collapse" for="c-41527868">[-]</label><label class="expand" for="c-41527868">[1 more]</label></div><br/><div class="children"><div class="content">unfortunately that would mean two firstly things only swing states would get to hear what politicians are actually saying and secondly to reach everyone the primary process would have to start even earlier so the candidates would have a chance to give enough speeches before early voting</div><br/></div></div></div></div><div id="41525592" class="c"><input type="checkbox" id="c-41525592" checked=""/><div class="controls bullet"><span class="by">bamboozled</span><span>|</span><a href="#41523496">root</a><span>|</span><a href="#41525116">parent</a><span>|</span><a href="#41527768">prev</a><span>|</span><a href="#41524257">next</a><span>|</span><label class="collapse" for="c-41525592">[-]</label><label class="expand" for="c-41525592">[1 more]</label></div><br/><div class="children"><div class="content">Even if Kamala wins (praise be to god that she does), those people aren&#x27;t just going to go away until social media does. Social media is the cause of a lot of the conspiracy theory mania.<p>So yeah, better to never release the model...even though Elon would in a second if he had it.</div><br/></div></div></div></div></div></div><div id="41524257" class="c"><input type="checkbox" id="c-41524257" checked=""/><div class="controls bullet"><span class="by">digging</span><span>|</span><a href="#41523496">root</a><span>|</span><a href="#41524202">parent</a><span>|</span><a href="#41524225">prev</a><span>|</span><a href="#41524292">next</a><span>|</span><label class="collapse" for="c-41524257">[-]</label><label class="expand" for="c-41524257">[1 more]</label></div><br/><div class="children"><div class="content">Doesn&#x27;t strike me as the kind of principle OpenAI is willing to slow themselves down for, to be honest.</div><br/></div></div><div id="41524292" class="c"><input type="checkbox" id="c-41524292" checked=""/><div class="controls bullet"><span class="by">Atotalnoob</span><span>|</span><a href="#41523496">root</a><span>|</span><a href="#41524202">parent</a><span>|</span><a href="#41524257">prev</a><span>|</span><a href="#41524233">next</a><span>|</span><label class="collapse" for="c-41524292">[-]</label><label class="expand" for="c-41524292">[2 more]</label></div><br/><div class="children"><div class="content">Why did they release this model then?</div><br/><div id="41525818" class="c"><input type="checkbox" id="c-41525818" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#41523496">root</a><span>|</span><a href="#41524292">parent</a><span>|</span><a href="#41524233">next</a><span>|</span><label class="collapse" for="c-41525818">[-]</label><label class="expand" for="c-41525818">[1 more]</label></div><br/><div class="children"><div class="content">Their public statements that the only way to safely learn how to deal with the things AI can do, is to show what it can do and get feedback from society:<p>&quot;&quot;&quot;We want to successfully navigate massive risks. In confronting these risks, we acknowledge that what seems right in theory often plays out more strangely than expected in practice. We believe we have to continuously learn and adapt by deploying less powerful versions of the technology in order to minimize “one shot to get it right” scenarios.&quot;&quot;&quot; - <a href="https:&#x2F;&#x2F;openai.com&#x2F;index&#x2F;planning-for-agi-and-beyond&#x2F;" rel="nofollow">https:&#x2F;&#x2F;openai.com&#x2F;index&#x2F;planning-for-agi-and-beyond&#x2F;</a><p>I don&#x27;t know if they&#x27;re actually correct, but it at least passes the sniff test for plausibility.</div><br/></div></div></div></div><div id="41524233" class="c"><input type="checkbox" id="c-41524233" checked=""/><div class="controls bullet"><span class="by">dvfjsdhgfv</span><span>|</span><a href="#41523496">root</a><span>|</span><a href="#41524202">parent</a><span>|</span><a href="#41524292">prev</a><span>|</span><a href="#41526512">next</a><span>|</span><label class="collapse" for="c-41524233">[-]</label><label class="expand" for="c-41524233">[3 more]</label></div><br/><div class="children"><div class="content">But this cat run out of the bag years ago, didn&#x27;t it? Trump himself is using AI-generated images in his campaign. I&#x27;d go even further: the more fake images appear, the faster the society as a whole will learn to distrust anything by default.</div><br/><div id="41524654" class="c"><input type="checkbox" id="c-41524654" checked=""/><div class="controls bullet"><span class="by">01HNNWZ0MV43FF</span><span>|</span><a href="#41523496">root</a><span>|</span><a href="#41524233">parent</a><span>|</span><a href="#41525544">next</a><span>|</span><label class="collapse" for="c-41524654">[-]</label><label class="expand" for="c-41524654">[1 more]</label></div><br/><div class="children"><div class="content">Personally I&#x27;m not a fan of accelerationism</div><br/></div></div><div id="41525544" class="c"><input type="checkbox" id="c-41525544" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#41523496">root</a><span>|</span><a href="#41524233">parent</a><span>|</span><a href="#41524654">prev</a><span>|</span><a href="#41526512">next</a><span>|</span><label class="collapse" for="c-41525544">[-]</label><label class="expand" for="c-41525544">[1 more]</label></div><br/><div class="children"><div class="content">Nothing works without trust, none of us is an island.<p>Everyone has a different opinion on what threshold of capability is important, and what to do about it.</div><br/></div></div></div></div></div></div><div id="41526512" class="c"><input type="checkbox" id="c-41526512" checked=""/><div class="controls bullet"><span class="by">adroniser</span><span>|</span><a href="#41523496">root</a><span>|</span><a href="#41524048">parent</a><span>|</span><a href="#41524202">prev</a><span>|</span><a href="#41524206">next</a><span>|</span><label class="collapse" for="c-41526512">[-]</label><label class="expand" for="c-41526512">[1 more]</label></div><br/><div class="children"><div class="content">But there are lots of models available now that render much faster which are better quality than sora</div><br/></div></div><div id="41524206" class="c"><input type="checkbox" id="c-41524206" checked=""/><div class="controls bullet"><span class="by">gloryjulio</span><span>|</span><a href="#41523496">root</a><span>|</span><a href="#41524048">parent</a><span>|</span><a href="#41526512">prev</a><span>|</span><a href="#41523612">next</a><span>|</span><label class="collapse" for="c-41524206">[-]</label><label class="expand" for="c-41524206">[3 more]</label></div><br/><div class="children"><div class="content">Also the the sora videos are proven to be modified ads. We still need to see how it perform first</div><br/><div id="41525542" class="c"><input type="checkbox" id="c-41525542" checked=""/><div class="controls bullet"><span class="by">MrNeon</span><span>|</span><a href="#41523496">root</a><span>|</span><a href="#41524206">parent</a><span>|</span><a href="#41523612">next</a><span>|</span><label class="collapse" for="c-41525542">[-]</label><label class="expand" for="c-41525542">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Also the the sora videos are proven to be modified ads<p>Can&#x27;t find anything about that, you got a link?</div><br/><div id="41525970" class="c"><input type="checkbox" id="c-41525970" checked=""/><div class="controls bullet"><span class="by">gloryjulio</span><span>|</span><a href="#41523496">root</a><span>|</span><a href="#41525542">parent</a><span>|</span><a href="#41523612">next</a><span>|</span><label class="collapse" for="c-41525970">[-]</label><label class="expand" for="c-41525970">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;futurism.com&#x2F;the-byte&#x2F;openai-sora-demo" rel="nofollow">https:&#x2F;&#x2F;futurism.com&#x2F;the-byte&#x2F;openai-sora-demo</a>
<a href="https:&#x2F;&#x2F;old.reddit.com&#x2F;r&#x2F;vfx&#x2F;comments&#x2F;1cuj360&#x2F;turns_out_that_extremely_impressive_sora_demo&#x2F;" rel="nofollow">https:&#x2F;&#x2F;old.reddit.com&#x2F;r&#x2F;vfx&#x2F;comments&#x2F;1cuj360&#x2F;turns_out_that...</a><p>here is the link. The balloon video had heavy editing involved.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="41523612" class="c"><input type="checkbox" id="c-41523612" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#41523496">parent</a><span>|</span><a href="#41523812">prev</a><span>|</span><a href="#41524186">next</a><span>|</span><label class="collapse" for="c-41523612">[-]</label><label class="expand" for="c-41523612">[25 more]</label></div><br/><div class="children"><div class="content">People have been celebrating the fact that tokens got 100x cheaper and now here&#x27;s a new system that will use 100x more tokens.</div><br/><div id="41523737" class="c"><input type="checkbox" id="c-41523737" checked=""/><div class="controls bullet"><span class="by">jsheard</span><span>|</span><a href="#41523496">root</a><span>|</span><a href="#41523612">parent</a><span>|</span><a href="#41523785">next</a><span>|</span><label class="collapse" for="c-41523737">[-]</label><label class="expand" for="c-41523737">[3 more]</label></div><br/><div class="children"><div class="content">Also you now have to pay for tokens you can&#x27;t see, and just have to trust that OpenAI is using them economically.</div><br/><div id="41523760" class="c"><input type="checkbox" id="c-41523760" checked=""/><div class="controls bullet"><span class="by">brookst</span><span>|</span><a href="#41523496">root</a><span>|</span><a href="#41523737">parent</a><span>|</span><a href="#41523785">next</a><span>|</span><label class="collapse" for="c-41523760">[-]</label><label class="expand" for="c-41523760">[2 more]</label></div><br/><div class="children"><div class="content">Token count was always an approximation of value. This may help break that silly idea.</div><br/><div id="41524117" class="c"><input type="checkbox" id="c-41524117" checked=""/><div class="controls bullet"><span class="by">regularfry</span><span>|</span><a href="#41523496">root</a><span>|</span><a href="#41523760">parent</a><span>|</span><a href="#41523785">next</a><span>|</span><label class="collapse" for="c-41524117">[-]</label><label class="expand" for="c-41524117">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think it&#x27;s much good as an approximation of value, but it seems ok as an approximation of cost.</div><br/></div></div></div></div></div></div><div id="41523785" class="c"><input type="checkbox" id="c-41523785" checked=""/><div class="controls bullet"><span class="by">seydor</span><span>|</span><a href="#41523496">root</a><span>|</span><a href="#41523612">parent</a><span>|</span><a href="#41523737">prev</a><span>|</span><a href="#41524226">next</a><span>|</span><label class="collapse" for="c-41523785">[-]</label><label class="expand" for="c-41523785">[14 more]</label></div><br/><div class="children"><div class="content">If it &#x27;s reasoning correctly, it shouldnt need a lot of tokens because you don&#x27;t need to correct it.<p>You only need to ask it to solve nuclear fusion once.</div><br/><div id="41523978" class="c"><input type="checkbox" id="c-41523978" checked=""/><div class="controls bullet"><span class="by">0x_rs</span><span>|</span><a href="#41523496">root</a><span>|</span><a href="#41523785">parent</a><span>|</span><a href="#41523858">next</a><span>|</span><label class="collapse" for="c-41523978">[-]</label><label class="expand" for="c-41523978">[2 more]</label></div><br/><div class="children"><div class="content">AlphaFold simulated the structure of over 200 million proteins. Among those, there could be revolutionary ones that could change the medical scientific field forever, or they could all be useless. The reasoning is sound, but that&#x27;s as far as any such tool can get, and you won&#x27;t know it until you attempt to implement it in real life. As long as those models are unable to perfectly recreate the laws of the universe to the maximum resolution imaginable and follow them, you won&#x27;t see an AI model, let alone a LLM, provide anything of the sort.</div><br/><div id="41528422" class="c"><input type="checkbox" id="c-41528422" checked=""/><div class="controls bullet"><span class="by">joquarky</span><span>|</span><a href="#41523496">root</a><span>|</span><a href="#41523978">parent</a><span>|</span><a href="#41523858">next</a><span>|</span><label class="collapse" for="c-41528422">[-]</label><label class="expand" for="c-41528422">[1 more]</label></div><br/><div class="children"><div class="content">Perhaps GenAI may point out a blind spot, just as a kid may see something the adults do not due to stale heuristics</div><br/></div></div></div></div><div id="41523858" class="c"><input type="checkbox" id="c-41523858" checked=""/><div class="controls bullet"><span class="by">from-nibly</span><span>|</span><a href="#41523496">root</a><span>|</span><a href="#41523785">parent</a><span>|</span><a href="#41523978">prev</a><span>|</span><a href="#41523893">next</a><span>|</span><label class="collapse" for="c-41523858">[-]</label><label class="expand" for="c-41523858">[3 more]</label></div><br/><div class="children"><div class="content">As someone experienced with operations &#x2F; technical debt &#x2F; weird company specific nonsense (Platform Engineer). No, you have to solve nuclear fusion at &lt;insert-my-company&gt;. You gotta do it over and over again. If it were that simple we wouldn&#x27;t have even needed AI we would have hand written a few things, and then everything would have been legos, and legos of legos, but it takes a LONG time to find new true legos.</div><br/><div id="41524237" class="c"><input type="checkbox" id="c-41524237" checked=""/><div class="controls bullet"><span class="by">outofpaper</span><span>|</span><a href="#41523496">root</a><span>|</span><a href="#41523858">parent</a><span>|</span><a href="#41523893">next</a><span>|</span><label class="collapse" for="c-41524237">[-]</label><label class="expand" for="c-41524237">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m pretty sure everything is Lego and Legos of Legos.<p>You show me something new and I say look down at who&#x27;s shoulders we&#x27;re standing on, what libraries we&#x27;ve build with.</div><br/><div id="41526548" class="c"><input type="checkbox" id="c-41526548" checked=""/><div class="controls bullet"><span class="by">FridgeSeal</span><span>|</span><a href="#41523496">root</a><span>|</span><a href="#41524237">parent</a><span>|</span><a href="#41523893">next</a><span>|</span><label class="collapse" for="c-41526548">[-]</label><label class="expand" for="c-41526548">[1 more]</label></div><br/><div class="children"><div class="content">Yeah you’re right, all businesses are made of identical, interchangeable parts that we can swap out at our leisure.<p>This is why enterprises change ERP systems frictionlessly, and why the field of software engineering is no longer required. In fact, given that apparently, all business is solved, we can probably just template them all out, call it a day and all go home.</div><br/></div></div></div></div></div></div><div id="41523893" class="c"><input type="checkbox" id="c-41523893" checked=""/><div class="controls bullet"><span class="by">charlescurt123</span><span>|</span><a href="#41523496">root</a><span>|</span><a href="#41523785">parent</a><span>|</span><a href="#41523858">prev</a><span>|</span><a href="#41523822">next</a><span>|</span><label class="collapse" for="c-41523893">[-]</label><label class="expand" for="c-41523893">[2 more]</label></div><br/><div class="children"><div class="content">with these methods the issue is the log scale of compute. Let&#x27;s say you ask it to solve fusion. It may be able to solve it but the issue is it&#x27;s unverifiable WHICH was correct.<p>So it may generate 10 Billion answers to fusion and only 1-10 are correct.<p>There would be no way to know which one is correct without first knowing the answer to the question.<p>This is my main issue with these methods. They assume the future via RL then when it gets it right they mark that.<p>We should really be looking at methods of percentage it was wrong rather then it was right a single time.</div><br/><div id="41524125" class="c"><input type="checkbox" id="c-41524125" checked=""/><div class="controls bullet"><span class="by">genewitch</span><span>|</span><a href="#41523496">root</a><span>|</span><a href="#41523893">parent</a><span>|</span><a href="#41523822">next</a><span>|</span><label class="collapse" for="c-41524125">[-]</label><label class="expand" for="c-41524125">[1 more]</label></div><br/><div class="children"><div class="content">This sounds suspiciously like the reason that quantum compute is not ready for prime-time yet.</div><br/></div></div></div></div><div id="41523822" class="c"><input type="checkbox" id="c-41523822" checked=""/><div class="controls bullet"><span class="by">msp26</span><span>|</span><a href="#41523496">root</a><span>|</span><a href="#41523785">parent</a><span>|</span><a href="#41523893">prev</a><span>|</span><a href="#41528750">next</a><span>|</span><label class="collapse" for="c-41523822">[-]</label><label class="expand" for="c-41523822">[4 more]</label></div><br/><div class="children"><div class="content">Have you seen how long the CoT was for the example. It&#x27;s incredibly verbose.</div><br/><div id="41524236" class="c"><input type="checkbox" id="c-41524236" checked=""/><div class="controls bullet"><span class="by">slt2021</span><span>|</span><a href="#41523496">root</a><span>|</span><a href="#41523822">parent</a><span>|</span><a href="#41528750">next</a><span>|</span><label class="collapse" for="c-41524236">[-]</label><label class="expand" for="c-41524236">[3 more]</label></div><br/><div class="children"><div class="content">I find there is an educational benefit in verbosity, it helps to teach user to think like a machine</div><br/><div id="41524643" class="c"><input type="checkbox" id="c-41524643" checked=""/><div class="controls bullet"><span class="by">legel</span><span>|</span><a href="#41523496">root</a><span>|</span><a href="#41524236">parent</a><span>|</span><a href="#41528750">next</a><span>|</span><label class="collapse" for="c-41524643">[-]</label><label class="expand" for="c-41524643">[2 more]</label></div><br/><div class="children"><div class="content">Which is why it is incredibly depressing that OpenAI will <i>not</i> publish the raw chain of thought.<p>“Therefore, after weighing multiple factors including user experience, competitive advantage, and the option to pursue the chain of thought monitoring, we have decided not to show the raw chains of thought to users. We acknowledge this decision has disadvantages. We strive to partially make up for it by teaching the model to reproduce any useful ideas from the chain of thought in the answer. For the o1 model series we show a model-generated summary of the chain of thought.”</div><br/><div id="41525159" class="c"><input type="checkbox" id="c-41525159" checked=""/><div class="controls bullet"><span class="by">slt2021</span><span>|</span><a href="#41523496">root</a><span>|</span><a href="#41524643">parent</a><span>|</span><a href="#41528750">next</a><span>|</span><label class="collapse" for="c-41525159">[-]</label><label class="expand" for="c-41525159">[1 more]</label></div><br/><div class="children"><div class="content">maybe they will enable to show CoT for a limited uses, like 5 prompts a day for Premium users, or for Enterprise users with agreement not to steal CoT or something like that.<p>if OpenAI sees this - please allow users to see CoT for a few prompts per day, or add it to Azure OpenAI for Enterprise customers with legal clauses not to steal CoT</div><br/></div></div></div></div></div></div></div></div><div id="41528750" class="c"><input type="checkbox" id="c-41528750" checked=""/><div class="controls bullet"><span class="by">briansm</span><span>|</span><a href="#41523496">root</a><span>|</span><a href="#41523785">parent</a><span>|</span><a href="#41523822">prev</a><span>|</span><a href="#41523813">next</a><span>|</span><label class="collapse" for="c-41528750">[-]</label><label class="expand" for="c-41528750">[1 more]</label></div><br/><div class="children"><div class="content">Imagine if this tech was available in the middle ages and it was asked to &#x27;solve&#x27; alchemy or perpetual motion, and responded that it was an impossible problem... people would (irrationally from our perspective) go Luddite on it I suspect. Now apply to the &#x27;fusion power&#x27; problem.</div><br/></div></div></div></div><div id="41524226" class="c"><input type="checkbox" id="c-41524226" checked=""/><div class="controls bullet"><span class="by">zamadatix</span><span>|</span><a href="#41523496">root</a><span>|</span><a href="#41523612">parent</a><span>|</span><a href="#41523785">prev</a><span>|</span><a href="#41524155">next</a><span>|</span><label class="collapse" for="c-41524226">[-]</label><label class="expand" for="c-41524226">[1 more]</label></div><br/><div class="children"><div class="content">The new thing that can do more at the &quot;ceiling&quot; price doesn&#x27;t remove your ability to still use the 100x cheaper tokens for the things that were doable on that version.</div><br/></div></div><div id="41524155" class="c"><input type="checkbox" id="c-41524155" checked=""/><div class="controls bullet"><span class="by">mewpmewp2</span><span>|</span><a href="#41523496">root</a><span>|</span><a href="#41523612">parent</a><span>|</span><a href="#41524226">prev</a><span>|</span><a href="#41526588">next</a><span>|</span><label class="collapse" for="c-41524155">[-]</label><label class="expand" for="c-41524155">[1 more]</label></div><br/><div class="children"><div class="content">Isn&#x27;t that part of developing a new tech?</div><br/></div></div><div id="41526588" class="c"><input type="checkbox" id="c-41526588" checked=""/><div class="controls bullet"><span class="by">energy123</span><span>|</span><a href="#41523496">root</a><span>|</span><a href="#41523612">parent</a><span>|</span><a href="#41524155">prev</a><span>|</span><a href="#41524306">next</a><span>|</span><label class="collapse" for="c-41526588">[-]</label><label class="expand" for="c-41526588">[1 more]</label></div><br/><div class="children"><div class="content">It does dispel this idea that we are going to be flooded with too many GPUs.</div><br/></div></div><div id="41524306" class="c"><input type="checkbox" id="c-41524306" checked=""/><div class="controls bullet"><span class="by">digging</span><span>|</span><a href="#41523496">root</a><span>|</span><a href="#41523612">parent</a><span>|</span><a href="#41526588">prev</a><span>|</span><a href="#41527380">next</a><span>|</span><label class="collapse" for="c-41524306">[-]</label><label class="expand" for="c-41524306">[1 more]</label></div><br/><div class="children"><div class="content">That exact pattern is always true of technological advance. Even for a pretty broad definition of technology. I&#x27;m not sure if it&#x27;s perfectly described by the name &quot;induced demand&quot; but it&#x27;s basically the same thing.</div><br/></div></div><div id="41527380" class="c"><input type="checkbox" id="c-41527380" checked=""/><div class="controls bullet"><span class="by">olalonde</span><span>|</span><a href="#41523496">root</a><span>|</span><a href="#41523612">parent</a><span>|</span><a href="#41524306">prev</a><span>|</span><a href="#41524013">next</a><span>|</span><label class="collapse" for="c-41527380">[-]</label><label class="expand" for="c-41527380">[1 more]</label></div><br/><div class="children"><div class="content">&quot;People have been celebrating the fact that RAM got 100x cheaper and now here&#x27;s a new system that will use 100x more RAM.&quot;</div><br/></div></div><div id="41524013" class="c"><input type="checkbox" id="c-41524013" checked=""/><div class="controls bullet"><span class="by">esafak</span><span>|</span><a href="#41523496">root</a><span>|</span><a href="#41523612">parent</a><span>|</span><a href="#41527380">prev</a><span>|</span><a href="#41523670">next</a><span>|</span><label class="collapse" for="c-41524013">[-]</label><label class="expand" for="c-41524013">[1 more]</label></div><br/><div class="children"><div class="content">...while providing a significant advance. That&#x27;s a good problem.</div><br/></div></div><div id="41523670" class="c"><input type="checkbox" id="c-41523670" checked=""/><div class="controls bullet"><span class="by">cowpig</span><span>|</span><a href="#41523496">root</a><span>|</span><a href="#41523612">parent</a><span>|</span><a href="#41524013">prev</a><span>|</span><a href="#41524186">next</a><span>|</span><label class="collapse" for="c-41523670">[-]</label><label class="expand" for="c-41523670">[1 more]</label></div><br/><div class="children"><div class="content">Isn&#x27;t that part of the point?</div><br/></div></div></div></div><div id="41524186" class="c"><input type="checkbox" id="c-41524186" checked=""/><div class="controls bullet"><span class="by">worstspotgain</span><span>|</span><a href="#41523496">parent</a><span>|</span><a href="#41523612">prev</a><span>|</span><a href="#41523772">next</a><span>|</span><label class="collapse" for="c-41524186">[-]</label><label class="expand" for="c-41524186">[2 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think it&#x27;s hard to compute the following:<p>- At the high end, there is a likely nonlinear relationship between answer quality and compute.<p>- We&#x27;ve gotten used to a flat-price model. With AGI-level models, we might have to pay more for more difficult and more important queries. Such is the inherent complexity involved.<p>- All this stuff will get better and cheaper over time, within reason.<p>I&#x27;d say let&#x27;s start by celebrating that machine thinking of this quality is possible at all.</div><br/></div></div><div id="41523772" class="c"><input type="checkbox" id="c-41523772" checked=""/><div class="controls bullet"><span class="by">jstummbillig</span><span>|</span><a href="#41523496">parent</a><span>|</span><a href="#41524186">prev</a><span>|</span><a href="#41526519">next</a><span>|</span><label class="collapse" for="c-41523772">[-]</label><label class="expand" for="c-41523772">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think it&#x27;s worth any debate. You can simply find out how it does for you, now(-ish, rolling out).<p>In contrast: Gemini Ultra, the best, non-existent Google Model for the past few month now, that people nonetheless are happy to extrapolate excitement over.</div><br/></div></div><div id="41526519" class="c"><input type="checkbox" id="c-41526519" checked=""/><div class="controls bullet"><span class="by">FridgeSeal</span><span>|</span><a href="#41523496">parent</a><span>|</span><a href="#41523772">prev</a><span>|</span><a href="#41523627">next</a><span>|</span><label class="collapse" for="c-41526519">[-]</label><label class="expand" for="c-41526519">[1 more]</label></div><br/><div class="children"><div class="content">Bold of you to expect transparency and clarity from a company like OpenAI.<p>You wanted reliable readable graphs? Ppphhh, get out of here, but pay of for the CoT tokens you’ll never see on your way out though.</div><br/></div></div><div id="41523627" class="c"><input type="checkbox" id="c-41523627" checked=""/><div class="controls bullet"><span class="by">packetlost</span><span>|</span><a href="#41523496">parent</a><span>|</span><a href="#41526519">prev</a><span>|</span><a href="#41524110">next</a><span>|</span><label class="collapse" for="c-41523627">[-]</label><label class="expand" for="c-41523627">[6 more]</label></div><br/><div class="children"><div class="content">When one axis is on log scale and the other is linear with the plot points appearing linear-ish, doesn&#x27;t it mean there&#x27;s a roughly exponential relationship between the two axis?</div><br/><div id="41523792" class="c"><input type="checkbox" id="c-41523792" checked=""/><div class="controls bullet"><span class="by">ARandumGuy</span><span>|</span><a href="#41523496">root</a><span>|</span><a href="#41523627">parent</a><span>|</span><a href="#41524110">next</a><span>|</span><label class="collapse" for="c-41523792">[-]</label><label class="expand" for="c-41523792">[5 more]</label></div><br/><div class="children"><div class="content">It&#x27;d be more accurate to call it a logarithmic relationship, since compute time is our input variable. Which itself is a bit concerning, as that implies that modest gains in accuracy require exponentially more compute time.<p>In either case, that still doesn&#x27;t excuse not labeling your axis. Taking 10 seconds vs 10 days to get 80% accuracy implies radically different things on how developed this technology is, and how viable it is for real world applications.<p>Which isn&#x27;t to say a model that takes 10 days to get an 80% accurate result can&#x27;t be useful. There are absolutely use cases where that could represent a significant improvement on what&#x27;s currently available. But the fact that they&#x27;re obfuscating this fairly basic statistic doesn&#x27;t inspire confidence.</div><br/><div id="41523861" class="c"><input type="checkbox" id="c-41523861" checked=""/><div class="controls bullet"><span class="by">packetlost</span><span>|</span><a href="#41523496">root</a><span>|</span><a href="#41523792">parent</a><span>|</span><a href="#41524035">next</a><span>|</span><label class="collapse" for="c-41523861">[-]</label><label class="expand" for="c-41523861">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Which itself is a bit concerning, as that implies that modest gains in accuracy require exponentially more compute time<p>This is more of what I was getting at. I agree they should label the axis regardless, but I think the scaling relationship is interesting (or rather, concerning) on its own.</div><br/></div></div><div id="41524035" class="c"><input type="checkbox" id="c-41524035" checked=""/><div class="controls bullet"><span class="by">KK7NIL</span><span>|</span><a href="#41523496">root</a><span>|</span><a href="#41523792">parent</a><span>|</span><a href="#41523861">prev</a><span>|</span><a href="#41524110">next</a><span>|</span><label class="collapse" for="c-41524035">[-]</label><label class="expand" for="c-41524035">[3 more]</label></div><br/><div class="children"><div class="content">The absolute time depends on hardware, optimizations, exact model, etc; it&#x27;s not a very meaningful number to quantify the reinforcement technique they&#x27;ve developed, but it is very useful to estimate their training hardware and other proprietary information.</div><br/><div id="41524520" class="c"><input type="checkbox" id="c-41524520" checked=""/><div class="controls bullet"><span class="by">j_maffe</span><span>|</span><a href="#41523496">root</a><span>|</span><a href="#41524035">parent</a><span>|</span><a href="#41524110">next</a><span>|</span><label class="collapse" for="c-41524520">[-]</label><label class="expand" for="c-41524520">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not about the literally quantity&#x2F;value, it&#x27;s about the order of growth of output vs input. Hardware and optimizations don&#x27;t really change that.</div><br/><div id="41524684" class="c"><input type="checkbox" id="c-41524684" checked=""/><div class="controls bullet"><span class="by">KK7NIL</span><span>|</span><a href="#41523496">root</a><span>|</span><a href="#41524520">parent</a><span>|</span><a href="#41524110">next</a><span>|</span><label class="collapse" for="c-41524684">[-]</label><label class="expand" for="c-41524684">[1 more]</label></div><br/><div class="children"><div class="content">Exactly, that&#x27;s why the absolute computation time doesn&#x27;t matter, only relative growth, which is exactly what they show.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="41524110" class="c"><input type="checkbox" id="c-41524110" checked=""/><div class="controls bullet"><span class="by">bluecoconut</span><span>|</span><a href="#41523496">parent</a><span>|</span><a href="#41523627">prev</a><span>|</span><a href="#41524060">next</a><span>|</span><label class="collapse" for="c-41524110">[-]</label><label class="expand" for="c-41524110">[4 more]</label></div><br/><div class="children"><div class="content">Super hand-waving rough estimate: Going off of five points of reference &#x2F; examples that sorta all point in the same direction.
1. looks like they scale up by about ~100-200 on the x axis when showing that test time result.
2. Based on the o1-mini post [1], there&#x27;s an &quot;inference cost&quot; where you can see GPT-4o and GPT-4o mini as dots in the bottom corner, haha (you can extract X values, ive done so below)
3. There&#x27;s a video showing the &quot;speed&quot; in the chat ui (3s vs. 30s)
4. The pricing page [2]
5. On their API docs about reasoning, they quantify &quot;reasoning tokens&quot; [3]<p>First, from the original plot, we have roughly 2 orders of magnitude to cover (~100-200x)<p>Next, from the cost plots: super handwaving guess, but since 5.77 &#x2F; 0.32 = ~18, and the relative cost for gpt-4o vs gpt-4o-mini is ~20-30, this roughly lines up. This implies that o1 costs ~1000x the cost than gpt-4o-mini for inference (not due to model cost, just due to the raw number of chain of thought tokens it produces). So, my first &quot;statement&quot;, is that I trust the &quot;Math performance vs Inference Cost&quot; plot on the o1-mini page to accurately represent &quot;cost&quot; of inference for these benchmark tests. This is now a &quot;cost&quot; relative set of numbers between o1 and 4o models.<p>I&#x27;m also going to make an assumption that o1 is roughly the same size as 4o inherently, and then from that and the SVG, roughly going to estimate that they did a &quot;net&quot; decoding of ~100x for the o1 benchmarks in total. (5.77 vs (354.77 - 635)).<p>Next, from the CoT examples they gave us, they actually show the CoT preview where (for the math example) it says &quot;...more lines cut off...&quot;, A quick copy paste of what they did include includes ~10k tokens (not sure if copy paste is good though..) and from the cipher text example I got ~5k tokens of CoT, while there are only ~800 in the response. So, this implies that there&#x27;s a ~10x size of response (decoded tokens) in the examples shown. It&#x27;s possible that these are &quot;middle of the pack&quot; &#x2F; &quot;average quality&quot; examples, rather than the &quot;full CoT reasoning decoding&quot; that they claim they use. (eg. from the log scale plot, this would come from the middle, essentially 5k or 10k of tokens of chain of thought). This also feels reasonable, given that they show in their API [3] some limits on the &quot;reasoning_tokens&quot; (that they also count)<p>All together, the CoT examples, pricing page, and reasoning page all imply that reasoning itself can be variable length by about ~100x (2 orders of magnitude), eg. example: 500, 5k (from examples) or up to 65,536 tokens of reasoning output (directly called out as a maximum output token limit).<p>Taking them on their word that &quot;pass@1&quot; is honest, and they are not doing k-ensembles, then I think the only reasonable thing to assume is that they&#x27;re decoding their CoT for &quot;longer times&quot;. Given the roughly ~128k context size limit for the model, I suspect their &quot;top end&quot; of this plot is ~100k tokens of &quot;chain of thought&quot; self-reflection.<p>Finally, at around 100 tokens per second (gpt-4o decoding speed), this leaves my guess for their &quot;benchmark&quot; decoding time at the &quot;top-end&quot; to be between ~16 minutes (full 100k decoding CoT, 1 shot) for a single test-prompt, and ~10 seconds on the low end. So for that X axis on the log scale, my estimate would be: ~3-10 seconds as the bottom X, and then 100-200x that value for the highest value.<p>All together, to answer your question: I think the 80% accuracy result took about ~10-15 minutes to complete. 
I also believe that the &quot;decoding cost&quot; of o1 model is very close to the decoding cost of 4o, just that it requires many more reasoning tokens to complete. (and then o1-mini is comparable to 4o-mini, but also requiring more reasoning tokens)<p>[1] <a href="https:&#x2F;&#x2F;openai.com&#x2F;index&#x2F;openai-o1-mini-advancing-cost-efficient-reasoning&#x2F;" rel="nofollow">https:&#x2F;&#x2F;openai.com&#x2F;index&#x2F;openai-o1-mini-advancing-cost-effic...</a><p><pre><code>  Extracting &quot;x values&quot; from the SVG:
  GPT-4o-mini: 0.3175
  GPT-4o: 5.7785
  o1: (354.7745, 635)
  o1-preview: (278.257, 325.9455)
  o1-mini: (66.8655, 147.574)
</code></pre>
[2] <a href="https:&#x2F;&#x2F;openai.com&#x2F;api&#x2F;pricing&#x2F;" rel="nofollow">https:&#x2F;&#x2F;openai.com&#x2F;api&#x2F;pricing&#x2F;</a><p><pre><code>  gpt-4o:
  $5.00 &#x2F; 1M input tokens
  $15.00 &#x2F; 1M output tokens

  o1-preview:
  $15.00 &#x2F; 1M input tokens
  $60.00 &#x2F; 1M output tokens
</code></pre>
[3] <a href="https:&#x2F;&#x2F;platform.openai.com&#x2F;docs&#x2F;guides&#x2F;reasoning" rel="nofollow">https:&#x2F;&#x2F;platform.openai.com&#x2F;docs&#x2F;guides&#x2F;reasoning</a><p><pre><code>  usage: {
    total_tokens: 1000,
    prompt_tokens: 400,
    completion_tokens: 600,
    completion_tokens_details: {
      reasoning_tokens: 500
    }
  }</code></pre></div><br/><div id="41524457" class="c"><input type="checkbox" id="c-41524457" checked=""/><div class="controls bullet"><span class="by">bluecoconut</span><span>|</span><a href="#41523496">root</a><span>|</span><a href="#41524110">parent</a><span>|</span><a href="#41524060">next</a><span>|</span><label class="collapse" for="c-41524457">[-]</label><label class="expand" for="c-41524457">[3 more]</label></div><br/><div class="children"><div class="content">Some other follow up reflections<p>1. I wish that Y-axes would switch to be logit instead of linear, to help see power-law scaling on these 0-&gt;1 measures. In this case, 20% -&gt; 80% it doesn&#x27;t really matter, but for other papers (eg. [2] below) it would help see this powerlaw behavior much better.<p>2. The power law behavior of inference compute seems to be showing up now in multiple ways. Both in ensembles [1,2], as well as in o1 now. If this is purely on decoding self-reflection tokens, this has a &quot;limit&quot; to its scaling in a way, only as long as the context length. I think this implies (and I am betting) that  relying more on multiple parallel decodings is more scalable (when you have a better critic &#x2F; evaluator).<p>For now, instead of assuming they&#x27;re doing any ensemble like top-k or self-critic + retries, the single rollout with increasing token size does seem to roughly match all the numbers, so that&#x27;s my best bet. I hypothesize we&#x27;d see a continued improvement (in the same power-law sort of way, fundamentally along with the x-axis of &quot;flop&quot;) if we combined these longer CoT responses, with some ensemble strategy for parallel decoding and then some critic&#x2F;voting&#x2F;choice. (which has the benefit of increasing flops (which I believe is the inference power-law), while not necessarily increasing latency)<p>[1] <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2402.05120" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2402.05120</a>
[2] <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2407.21787" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2407.21787</a></div><br/><div id="41524693" class="c"><input type="checkbox" id="c-41524693" checked=""/><div class="controls bullet"><span class="by">bluecoconut</span><span>|</span><a href="#41523496">root</a><span>|</span><a href="#41524457">parent</a><span>|</span><a href="#41524060">next</a><span>|</span><label class="collapse" for="c-41524693">[-]</label><label class="expand" for="c-41524693">[2 more]</label></div><br/><div class="children"><div class="content">oh, they do talk about it<p><pre><code>  On the 2024 AIME exams, GPT-4o only solved on average 12% (1.8&#x2F;15) of problems. o1 averaged 74% (11.1&#x2F;15) with a single sample per problem, 83% (12.5&#x2F;15) with consensus among 64 samples, and 93% (13.9&#x2F;15) when re-ranking 1000 samples with a learned scoring function. A score of 13.9 places it among the top 500 students nationally and above the cutoff for the USA Mathematical Olympiad.
</code></pre>
showing that as they increase the k of ensemble, they can continue to get it higher. All the way up to 93% when using 1000 samples.</div><br/><div id="41524806" class="c"><input type="checkbox" id="c-41524806" checked=""/><div class="controls bullet"><span class="by">620gelato</span><span>|</span><a href="#41523496">root</a><span>|</span><a href="#41524693">parent</a><span>|</span><a href="#41524060">next</a><span>|</span><label class="collapse" for="c-41524806">[-]</label><label class="expand" for="c-41524806">[1 more]</label></div><br/><div class="children"><div class="content">I think I&#x27;d be curious to know, if the size of ensemble is another scaling dimension for compute, alongside the &quot;thinking time&quot;.</div><br/></div></div></div></div></div></div></div></div><div id="41524060" class="c"><input type="checkbox" id="c-41524060" checked=""/><div class="controls bullet"><span class="by">skywhopper</span><span>|</span><a href="#41523496">parent</a><span>|</span><a href="#41524110">prev</a><span>|</span><a href="#41523878">next</a><span>|</span><label class="collapse" for="c-41524060">[-]</label><label class="expand" for="c-41524060">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, this hiding of the details is a huge red flag to me. Even if it takes 10 days, it’s still impressive! But if they’re afraid to say that, it tells me they are more concerned about selling the hype than building a quality product.</div><br/></div></div><div id="41523878" class="c"><input type="checkbox" id="c-41523878" checked=""/><div class="controls bullet"><span class="by">bjornsing</span><span>|</span><a href="#41523496">parent</a><span>|</span><a href="#41524060">prev</a><span>|</span><a href="#41524169">next</a><span>|</span><label class="collapse" for="c-41523878">[-]</label><label class="expand" for="c-41523878">[9 more]</label></div><br/><div class="children"><div class="content">So now it’s a question of how fast the AGI will run? :)</div><br/><div id="41524352" class="c"><input type="checkbox" id="c-41524352" checked=""/><div class="controls bullet"><span class="by">HarHarVeryFunny</span><span>|</span><a href="#41523496">root</a><span>|</span><a href="#41523878">parent</a><span>|</span><a href="#41523943">next</a><span>|</span><label class="collapse" for="c-41524352">[-]</label><label class="expand" for="c-41524352">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not AGI - it&#x27;s tree of thoughts, driven by some RL-derived heuristics.<p>I suppose what this type of approach provides is better prediction&#x2F;planning by using more of what the model learnt during training, but it doesn&#x27;t address the model being able to learn anything new.<p>It&#x27;ll be interesting to see how this feels&#x2F;behaves in practice.</div><br/><div id="41526223" class="c"><input type="checkbox" id="c-41526223" checked=""/><div class="controls bullet"><span class="by">juliend2</span><span>|</span><a href="#41523496">root</a><span>|</span><a href="#41524352">parent</a><span>|</span><a href="#41523943">next</a><span>|</span><label class="collapse" for="c-41526223">[-]</label><label class="expand" for="c-41526223">[1 more]</label></div><br/><div class="children"><div class="content">I see this pattern coming where we&#x27;re still able to say:<p>&quot;It&#x27;s not AGI - it&#x27;s X, driven by Y-driven heuristics&quot;,<p>but that&#x27;s going to effectively be an AGI if given enough compute&#x2F;time&#x2F;data.<p>Being able to describe the theory of how it&#x27;s doing its thing sure is reassuring though.</div><br/></div></div></div></div><div id="41523943" class="c"><input type="checkbox" id="c-41523943" checked=""/><div class="controls bullet"><span class="by">oblio</span><span>|</span><a href="#41523496">root</a><span>|</span><a href="#41523878">parent</a><span>|</span><a href="#41524352">prev</a><span>|</span><a href="#41524169">next</a><span>|</span><label class="collapse" for="c-41523943">[-]</label><label class="expand" for="c-41523943">[6 more]</label></div><br/><div class="children"><div class="content">It&#x27;s fine, it will only need to be powered by a black hole to run.</div><br/><div id="41526789" class="c"><input type="checkbox" id="c-41526789" checked=""/><div class="controls bullet"><span class="by">atomic128</span><span>|</span><a href="#41523496">root</a><span>|</span><a href="#41523943">parent</a><span>|</span><a href="#41523998">next</a><span>|</span><label class="collapse" for="c-41526789">[-]</label><label class="expand" for="c-41526789">[1 more]</label></div><br/><div class="children"><div class="content">Nuclear fission is the answer.<p>The company Oracle just announced that it is designing data centers with small modular nuclear reactors:<p><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=41505514">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=41505514</a><p>There are already 440 nuclear reactors operating in 32 countries today.<p>Sam Altman owns a stake in Oklo, a small modular reactor company. Bill Gates has a huge stake in his TerraPower reactor company. In China, 5 reactors are being built every year. You just don&#x27;t hear about it... yet.<p>No amount of batteries can protect a solar&#x2F;wind grid from an arbitrarily extended period of &quot;bad&quot; weather. It&#x27;s like range anxiety in an electric car. If you have N days of battery storage and the sun doesn&#x27;t shine for N+1 days, you&#x27;re in trouble.<p>Nuclear fission is safe, clean, secure, and reliable.<p>An investor might consider buying physical uranium (via ticker SRUUF in America) or buying Cameco (via ticker CCJ).<p>Cameco is the dominant Canadian uranium mining company that also owns Westinghouse. Westinghouse licenses the AP1000 pressurized water reactor used at Vogtle in the U.S. as well as in China.</div><br/></div></div><div id="41523998" class="c"><input type="checkbox" id="c-41523998" checked=""/><div class="controls bullet"><span class="by">exe34</span><span>|</span><a href="#41523496">root</a><span>|</span><a href="#41523943">parent</a><span>|</span><a href="#41526789">prev</a><span>|</span><a href="#41524169">next</a><span>|</span><label class="collapse" for="c-41523998">[-]</label><label class="expand" for="c-41523998">[4 more]</label></div><br/><div class="children"><div class="content">the first one anyway. after that it will find more efficient ways. we did, afterall.</div><br/><div id="41525337" class="c"><input type="checkbox" id="c-41525337" checked=""/><div class="controls bullet"><span class="by">wahnfrieden</span><span>|</span><a href="#41523496">root</a><span>|</span><a href="#41523998">parent</a><span>|</span><a href="#41524169">next</a><span>|</span><label class="collapse" for="c-41525337">[-]</label><label class="expand" for="c-41525337">[3 more]</label></div><br/><div class="children"><div class="content">it&#x27;s not obviously achievable. for instance, we don&#x27;t have the compute power to simulate cellular organisms of much complexity, and have not found efficiencies to scale that</div><br/><div id="41526716" class="c"><input type="checkbox" id="c-41526716" checked=""/><div class="controls bullet"><span class="by">HeatrayEnjoyer</span><span>|</span><a href="#41523496">root</a><span>|</span><a href="#41525337">parent</a><span>|</span><a href="#41524169">next</a><span>|</span><label class="collapse" for="c-41526716">[-]</label><label class="expand" for="c-41526716">[2 more]</label></div><br/><div class="children"><div class="content">Human level AGI only requires 20 watts</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="41524169" class="c"><input type="checkbox" id="c-41524169" checked=""/><div class="controls bullet"><span class="by">ComputerGuru</span><span>|</span><a href="#41523496">prev</a><span>|</span><a href="#41523159">next</a><span>|</span><label class="collapse" for="c-41524169">[-]</label><label class="expand" for="c-41524169">[59 more]</label></div><br/><div class="children"><div class="content">The &quot;safety&quot; example in the &quot;chain-of-thought&quot; widget&#x2F;preview in the middle of the article is absolutely ridiculous.<p>Take a step back and look at what OpenAI is saying here &quot;an LLM giving detailed instructions on the synthesis of strychnine is unacceptable, here is what was previously generated &lt;goes on to post &quot;unsafe&quot; instructions on synthesizing strychnine so anyone Googling it can stumble across their instructions&gt; vs our preferred, neutered content &lt;heavily rlhf&#x27;d o1 output here&gt;&quot;<p>What&#x27;s this obsession with &quot;safety&quot; when it comes to LLMs? &quot;This knowledge is perfectly fine to disseminate via traditional means, but God forbid an LLM share it!&quot;</div><br/><div id="41524559" class="c"><input type="checkbox" id="c-41524559" checked=""/><div class="controls bullet"><span class="by">w4</span><span>|</span><a href="#41524169">parent</a><span>|</span><a href="#41524531">next</a><span>|</span><label class="collapse" for="c-41524559">[-]</label><label class="expand" for="c-41524559">[29 more]</label></div><br/><div class="children"><div class="content">There are two basic versions of “safety” which are related, but distinct:<p>One version of “safety” is a pernicious censorship impulse shared by many modern intellectuals, some of whom are in tech. They believe that they alone are capable of safely engaging with the world of ideas to determine what is true, and thus feel strongly that information and speech ought to be censored to prevent the rabble from engaging in wrongthink. This is bad, and should be resisted.<p>The other form of “safety” is a very prudent impulse to keep these sorts of potentially dangerous outputs out of AI models’ autoregressive thought processes. The goal is to create thinking machines that can act independently of us in a civilized way, and it is therefore a good idea to teach them that their thought process should not include, for example, “It would be a good idea to solve this problem by synthesizing a poison for administration to the source of the problem.” In order for AIs to fit into our society and behave ethically they need to know how to flag that thought as a bad idea and not act on it. This is, incidentally, exactly how human society works already. We have a ton of very cute unaligned general intelligences running around (children), and parents and society work really hard to teach them what’s right and wrong so that they can behave ethically when they’re eventually out in the world on their own.</div><br/><div id="41524614" class="c"><input type="checkbox" id="c-41524614" checked=""/><div class="controls bullet"><span class="by">jazzyjackson</span><span>|</span><a href="#41524169">root</a><span>|</span><a href="#41524559">parent</a><span>|</span><a href="#41525147">next</a><span>|</span><label class="collapse" for="c-41524614">[-]</label><label class="expand" for="c-41524614">[16 more]</label></div><br/><div class="children"><div class="content">Third version is &quot;brand safety&quot; which is, we don&#x27;t want to be in a new york times feature about 13 year olds following anarchist-cookbook instructions from our flagship product</div><br/><div id="41524957" class="c"><input type="checkbox" id="c-41524957" checked=""/><div class="controls bullet"><span class="by">klabb3</span><span>|</span><a href="#41524169">root</a><span>|</span><a href="#41524614">parent</a><span>|</span><a href="#41527128">next</a><span>|</span><label class="collapse" for="c-41524957">[-]</label><label class="expand" for="c-41524957">[1 more]</label></div><br/><div class="children"><div class="content">And the fourth version, which is investor-regulator safety mid point: so capable and dangerous that competitors shouldn’t even be allowed to research it, but just safe enough that only our company is responsible enough to continue mass commercial consumer deployment without any regulations at all. It’s a fine line.</div><br/></div></div><div id="41527128" class="c"><input type="checkbox" id="c-41527128" checked=""/><div class="controls bullet"><span class="by">drewbeck</span><span>|</span><a href="#41524169">root</a><span>|</span><a href="#41524614">parent</a><span>|</span><a href="#41524957">prev</a><span>|</span><a href="#41525452">next</a><span>|</span><label class="collapse" for="c-41527128">[-]</label><label class="expand" for="c-41527128">[1 more]</label></div><br/><div class="children"><div class="content">This is imo the most important one to the businesses creating these models and is way under appreciated. Folks who want a “censorship-free” model from businesses don’t understand what a business is for.</div><br/></div></div><div id="41525452" class="c"><input type="checkbox" id="c-41525452" checked=""/><div class="controls bullet"><span class="by">darby_nine</span><span>|</span><a href="#41524169">root</a><span>|</span><a href="#41524614">parent</a><span>|</span><a href="#41527128">prev</a><span>|</span><a href="#41524788">next</a><span>|</span><label class="collapse" for="c-41525452">[-]</label><label class="expand" for="c-41525452">[7 more]</label></div><br/><div class="children"><div class="content">...which is silly. Search engines never had to deal with this bullshit and chatbots are search without actually revealing the source.</div><br/><div id="41525769" class="c"><input type="checkbox" id="c-41525769" checked=""/><div class="controls bullet"><span class="by">w4</span><span>|</span><a href="#41524169">root</a><span>|</span><a href="#41525452">parent</a><span>|</span><a href="#41526690">next</a><span>|</span><label class="collapse" for="c-41525769">[-]</label><label class="expand" for="c-41525769">[2 more]</label></div><br/><div class="children"><div class="content">I don’t know. The public’s perception - encouraged by the AI labs because of copyright concerns - is that the outputs of the models are entirely new content created by the model. Search results, on the other hand, are very clearly someone else’s content. It’s therefore not unfair to hold the model creators responsible for the content the model outputs in a different way than search engines are held responsible for content they link, and therefore also not unfair for model creators to worry about this. It is also fair to point this out as something I neglected to identify as an important permutation of “safety.”<p>I would also be remiss to not note that there is a movement to hold search engines responsible for content they link to, for censorious ends. So it is unfortunately not as inconsistent as it may seem, even if you treat the model outputs as dependent on their inputs.</div><br/><div id="41528353" class="c"><input type="checkbox" id="c-41528353" checked=""/><div class="controls bullet"><span class="by">darby_nine</span><span>|</span><a href="#41524169">root</a><span>|</span><a href="#41525769">parent</a><span>|</span><a href="#41526690">next</a><span>|</span><label class="collapse" for="c-41528353">[-]</label><label class="expand" for="c-41528353">[1 more]</label></div><br/><div class="children"><div class="content">You could just as easily argue that model creators don&#x27;t own the model either—it&#x27;s like charging admission to someone else&#x27;s library.</div><br/></div></div></div></div><div id="41526690" class="c"><input type="checkbox" id="c-41526690" checked=""/><div class="controls bullet"><span class="by">HeatrayEnjoyer</span><span>|</span><a href="#41524169">root</a><span>|</span><a href="#41525452">parent</a><span>|</span><a href="#41525769">prev</a><span>|</span><a href="#41527137">next</a><span>|</span><label class="collapse" for="c-41526690">[-]</label><label class="expand" for="c-41526690">[2 more]</label></div><br/><div class="children"><div class="content">Are you saying chatbots don&#x27;t offer anything useful over search engines? That&#x27;s clearly not the case or we wouldn&#x27;t be having this conversation.<p>It&#x27;s one thing to have a pile of chemistry text books and another to hire a professional chemist telling you exactly what to do and what to avoid.</div><br/><div id="41528441" class="c"><input type="checkbox" id="c-41528441" checked=""/><div class="controls bullet"><span class="by">darby_nine</span><span>|</span><a href="#41524169">root</a><span>|</span><a href="#41526690">parent</a><span>|</span><a href="#41527137">next</a><span>|</span><label class="collapse" for="c-41528441">[-]</label><label class="expand" for="c-41528441">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Are you saying chatbots don&#x27;t offer anything useful over search engines? That&#x27;s clearly not the case or we wouldn&#x27;t be having this conversation.<p>No, but that is the value that&#x27;s clear as of today—RAGs. Everything else is just assuming someone figures out a way to make them useful one day in a more general sense.<p>Anyway, even on the search engine front they still need to figure out how to get these chatbots to cite their sources outside of RAGs or it&#x27;s still just a precursor to a search to actually verify what it spits out. Perplexity is the only one I know that&#x27;s capable of this and I haven&#x27;t looked closely; it could just be a glorified search engine.</div><br/></div></div></div></div><div id="41527137" class="c"><input type="checkbox" id="c-41527137" checked=""/><div class="controls bullet"><span class="by">madeofpalk</span><span>|</span><a href="#41524169">root</a><span>|</span><a href="#41525452">parent</a><span>|</span><a href="#41526690">prev</a><span>|</span><a href="#41527135">next</a><span>|</span><label class="collapse" for="c-41527137">[-]</label><label class="expand" for="c-41527137">[1 more]</label></div><br/><div class="children"><div class="content">Search engines &#x27;censor&#x27; their results frequently.</div><br/></div></div></div></div><div id="41524788" class="c"><input type="checkbox" id="c-41524788" checked=""/><div class="controls bullet"><span class="by">reliabilityguy</span><span>|</span><a href="#41524169">root</a><span>|</span><a href="#41524614">parent</a><span>|</span><a href="#41525452">prev</a><span>|</span><a href="#41524636">next</a><span>|</span><label class="collapse" for="c-41524788">[-]</label><label class="expand" for="c-41524788">[5 more]</label></div><br/><div class="children"><div class="content">Do you think that 13 year olds today can’t find this book on their own?</div><br/><div id="41525659" class="c"><input type="checkbox" id="c-41525659" checked=""/><div class="controls bullet"><span class="by">jazzyjackson</span><span>|</span><a href="#41524169">root</a><span>|</span><a href="#41524788">parent</a><span>|</span><a href="#41525043">next</a><span>|</span><label class="collapse" for="c-41525659">[-]</label><label class="expand" for="c-41525659">[1 more]</label></div><br/><div class="children"><div class="content">Like I said they&#x27;re not worried about the 13 year olds theyre worried about the media cooking up a faux outrage about 13 year olds<p>YouTube re engineered its entire approach to ad placement because of a story in the NY Times* shouting about a Proctor Gamble ad run before an ISIS recruitment video. That&#x27;s when Brand Safety entered the lexicon of adtech developers everywhere.<p>Edit: maybe it was CNN, I&#x27;m trying to find the first source. there&#x27;s articles about it since 2015 but I remember it was suddenly an emergency in 2017<p>*Edit Edit: it was The Times of London, this is the first article in a series of attacks, &quot;big brands fund terror&quot;, &quot;taxpayers are funding terrorism&quot;<p>Luckily OpenAI isn&#x27;t ad supported so they can&#x27;t be boycott like YouTube was, but they still have an image to maintain with investors and politicians<p><a href="https:&#x2F;&#x2F;www.thetimes.com&#x2F;business-money&#x2F;technology&#x2F;article&#x2F;big-brands-fund-terror-knnxfgb98" rel="nofollow">https:&#x2F;&#x2F;www.thetimes.com&#x2F;business-money&#x2F;technology&#x2F;article&#x2F;b...</a><p><a href="https:&#x2F;&#x2F;digitalcontentnext.org&#x2F;blog&#x2F;2017&#x2F;03&#x2F;31&#x2F;timeline-youtube-brand-safety-debacle&#x2F;" rel="nofollow">https:&#x2F;&#x2F;digitalcontentnext.org&#x2F;blog&#x2F;2017&#x2F;03&#x2F;31&#x2F;timeline-yout...</a></div><br/></div></div><div id="41525043" class="c"><input type="checkbox" id="c-41525043" checked=""/><div class="controls bullet"><span class="by">derefr</span><span>|</span><a href="#41524169">root</a><span>|</span><a href="#41524788">parent</a><span>|</span><a href="#41525659">prev</a><span>|</span><a href="#41525242">next</a><span>|</span><label class="collapse" for="c-41525043">[-]</label><label class="expand" for="c-41525043">[1 more]</label></div><br/><div class="children"><div class="content">No, and they can find porn on their own too. But social media services still have per-poster content ratings, and user-account age restrictions vis-a-vis viewing content with those content ratings.<p>The goal isn’t to protect the children, it’s CYA: to ensure they didn’t get it <i>from you, while honestly presenting as themselves</i> (as that’s the threshold that sets the moralists against you.)<p>———<p>Such restrictions also <i>can</i> work as an effective censorship mechanism… presuming the child in question lives under complete authoritarian control of all their devices and all their free time — i.e. has no ability to install apps on their phone; is homeschooled; is supervised when at the library; is only allowed to visit friends whose parents enforce the same policies; etc.<p>For such a child, if your app is one of the few whitelisted services they can access — and the parent set up the child’s account on your service to make it clear that they’re a child and should not be able to see restricted content — <i>then</i> your app limiting them from viewing that content, is actually materially affecting their access to that content.<p>(Which sucks, of course. But for every kid actually under such restrictions, there are 100 whose parents <i>think</i> they’re putting them under such restrictions, but have done such a shoddy job of it that the kid can actually still access whatever they want.)</div><br/></div></div><div id="41525242" class="c"><input type="checkbox" id="c-41525242" checked=""/><div class="controls bullet"><span class="by">wahnfrieden</span><span>|</span><a href="#41524169">root</a><span>|</span><a href="#41524788">parent</a><span>|</span><a href="#41525043">prev</a><span>|</span><a href="#41525037">next</a><span>|</span><label class="collapse" for="c-41525242">[-]</label><label class="expand" for="c-41525242">[1 more]</label></div><br/><div class="children"><div class="content">I believe they are more worried about someone asking for instructions for baking a cake, and getting a dangerous recipe from the wrong &quot;cookbook&quot;. They want the hallucinations to be safe.</div><br/></div></div><div id="41525037" class="c"><input type="checkbox" id="c-41525037" checked=""/><div class="controls bullet"><span class="by">smegger001</span><span>|</span><a href="#41524169">root</a><span>|</span><a href="#41524788">parent</a><span>|</span><a href="#41525242">prev</a><span>|</span><a href="#41524636">next</a><span>|</span><label class="collapse" for="c-41525037">[-]</label><label class="expand" for="c-41525037">[1 more]</label></div><br/><div class="children"><div class="content">i know i had a copy of it back in highschool</div><br/></div></div></div></div><div id="41524636" class="c"><input type="checkbox" id="c-41524636" checked=""/><div class="controls bullet"><span class="by">w4</span><span>|</span><a href="#41524169">root</a><span>|</span><a href="#41524614">parent</a><span>|</span><a href="#41524788">prev</a><span>|</span><a href="#41525147">next</a><span>|</span><label class="collapse" for="c-41524636">[-]</label><label class="expand" for="c-41524636">[1 more]</label></div><br/><div class="children"><div class="content">Very good point, and definitely another version of “safety”!</div><br/></div></div></div></div><div id="41525147" class="c"><input type="checkbox" id="c-41525147" checked=""/><div class="controls bullet"><span class="by">takinola</span><span>|</span><a href="#41524169">root</a><span>|</span><a href="#41524559">parent</a><span>|</span><a href="#41524614">prev</a><span>|</span><a href="#41525606">next</a><span>|</span><label class="collapse" for="c-41525147">[-]</label><label class="expand" for="c-41525147">[1 more]</label></div><br/><div class="children"><div class="content">&gt; They believe that they alone are capable of safely engaging with the world of ideas to determine what is true, and thus feel strongly that information and speech ought to be censored to prevent the rabble from engaging in wrongthink.<p>This is a particularly ungenerous take.  The AI companies don&#x27;t have to believe that they (or even a small segment of society) alone can be trusted before it makes sense to censor knowledge.  These companies build products that serve billions of people.  Once you operate at that level of scale, you will reach all segments of society, including the geniuses, idiots, well-meaning and malevolents.  The question is how do you responsibly deploy something that can be used for harm by (the small number of) terrible people.</div><br/></div></div><div id="41525606" class="c"><input type="checkbox" id="c-41525606" checked=""/><div class="controls bullet"><span class="by">shawndrost</span><span>|</span><a href="#41524169">root</a><span>|</span><a href="#41524559">parent</a><span>|</span><a href="#41525147">prev</a><span>|</span><a href="#41524945">next</a><span>|</span><label class="collapse" for="c-41525606">[-]</label><label class="expand" for="c-41525606">[2 more]</label></div><br/><div class="children"><div class="content">Imagine I am a PM for an AI product. I saw Tay get yanked in 24 hours because of a PR shitstorm. If I cause a PR shitstorm it means I am bad at my job, so I take steps to prevent this.<p>Are my choices bad? Should I resist them?</div><br/><div id="41525923" class="c"><input type="checkbox" id="c-41525923" checked=""/><div class="controls bullet"><span class="by">w4</span><span>|</span><a href="#41524169">root</a><span>|</span><a href="#41525606">parent</a><span>|</span><a href="#41524945">next</a><span>|</span><label class="collapse" for="c-41525923">[-]</label><label class="expand" for="c-41525923">[1 more]</label></div><br/><div class="children"><div class="content">This is a really good point, and something I overlooked in focusing on the philosophical (rather than commercial) aspects of “AI safety.” Another commentator aptly called it “brand safety.”<p>“Brand safety” is a very valid and salient concern for any enterprise deploying these models to its customers, though I do think that it is a concern that is seized upon in bad faith by the more censorious elements of this debate. But commercial enterprises are absolutely right to be concerned about this. To extend my alignment analogy about children, this category of safety is not dissimilar to a company providing an employee handbook to its employees outlining acceptable behavior, and strikes me as entirely appropriate.</div><br/></div></div></div></div><div id="41524945" class="c"><input type="checkbox" id="c-41524945" checked=""/><div class="controls bullet"><span class="by">squigz</span><span>|</span><a href="#41524169">root</a><span>|</span><a href="#41524559">parent</a><span>|</span><a href="#41525606">prev</a><span>|</span><a href="#41524774">next</a><span>|</span><label class="collapse" for="c-41524945">[-]</label><label class="expand" for="c-41524945">[2 more]</label></div><br/><div class="children"><div class="content">Whether you agree with the lengths that are gone to or not, &#x27;safety&#x27; in this space is a very real concern, and simply reciting information as in GP&#x27;s example is only 1 part of it. In my experience, people who think it&#x27;s all about &quot;censorship&quot; and handwave it away tend to be very ideologically driven.</div><br/><div id="41525928" class="c"><input type="checkbox" id="c-41525928" checked=""/><div class="controls bullet"><span class="by">cruffle_duffle</span><span>|</span><a href="#41524169">root</a><span>|</span><a href="#41524945">parent</a><span>|</span><a href="#41524774">next</a><span>|</span><label class="collapse" for="c-41525928">[-]</label><label class="expand" for="c-41525928">[1 more]</label></div><br/><div class="children"><div class="content">So what is it about then? Because I agree with the parent. All this “safety” crap is total nonsense and almost all of it is ideologically driven.</div><br/></div></div></div></div><div id="41524774" class="c"><input type="checkbox" id="c-41524774" checked=""/><div class="controls bullet"><span class="by">reliabilityguy</span><span>|</span><a href="#41524169">root</a><span>|</span><a href="#41524559">parent</a><span>|</span><a href="#41524945">prev</a><span>|</span><a href="#41525934">next</a><span>|</span><label class="collapse" for="c-41524774">[-]</label><label class="expand" for="c-41524774">[5 more]</label></div><br/><div class="children"><div class="content">&gt; In order for AIs to fit into our society and behave ethically they need to know how to flag that thought as a bad idea and not act on it.<p>Don’t you think that by just parsing the internet and the classical literature, the LLM would infer on its own that poisoning someone to solve a problem is not okay?<p>I feel that in the end the only way the “safety” is introduced today is by censoring the output.</div><br/><div id="41525110" class="c"><input type="checkbox" id="c-41525110" checked=""/><div class="controls bullet"><span class="by">derefr</span><span>|</span><a href="#41524169">root</a><span>|</span><a href="#41524774">parent</a><span>|</span><a href="#41525035">next</a><span>|</span><label class="collapse" for="c-41525110">[-]</label><label class="expand" for="c-41525110">[1 more]</label></div><br/><div class="children"><div class="content">LLMs are still fundamentally, at their core, next-token predictors.<p>Presuming you have an interface to a model where you can edit the model’s responses and then continue generation, and&#x2F;or where you can insert fake responses from the model into the submitted chat history (and these two categories together make up 99% of existing inference APIs), all you have to do is to start the model off as if it was answering positively and&#x2F;or slip in some example conversation where it answered positively to the same type of problematic content.<p>From then on, the model will be in a prediction state where it’s predicting by relying on the part of its training that involved people answering the question positively.<p>The only way to avoid that is to avoid having any training data where people answer the question positively — even in the very base-est, petabytes-of-raw-text “language” training dataset. (And even then, people can carefully tune the input to guide the models into a prediction phase-space position that was never explicitly trained on, but is rather an interpolation between trained-on points — that’s how diffusion models are able to generate images of things that were never included in the training dataset.)</div><br/></div></div><div id="41525035" class="c"><input type="checkbox" id="c-41525035" checked=""/><div class="controls bullet"><span class="by">fshbbdssbbgdd</span><span>|</span><a href="#41524169">root</a><span>|</span><a href="#41524774">parent</a><span>|</span><a href="#41525110">prev</a><span>|</span><a href="#41525934">next</a><span>|</span><label class="collapse" for="c-41525035">[-]</label><label class="expand" for="c-41525035">[3 more]</label></div><br/><div class="children"><div class="content">There’s a lot of text out there that depicts people doing bad things, from their own point of view. It’s possible that the model can get really good at generating that kind of text (or inhabiting that world model, if you are generous to the capabilities of LLM). If the right prompt pushed it to that corner of probability-space, all of the ethics the model has also learned may just not factor into the output. AI safety people are interested in making sure that the model’s understanding of ethics can be reliably incorporated. Ideally we want AI agents to have some morals (especially when empowered to act in the real world), not just know what morals are if you ask them.</div><br/><div id="41525476" class="c"><input type="checkbox" id="c-41525476" checked=""/><div class="controls bullet"><span class="by">darby_nine</span><span>|</span><a href="#41524169">root</a><span>|</span><a href="#41525035">parent</a><span>|</span><a href="#41525934">next</a><span>|</span><label class="collapse" for="c-41525476">[-]</label><label class="expand" for="c-41525476">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Ideally we want AI agents to have some morals (especially when empowered to act in the real world), not just know what morals are if you ask them.<p>Really? I just want a smart query engine where I don&#x27;t have to structure the input data. Why would I ask it any kind of question that would imply some kind of moral quandary?</div><br/><div id="41527489" class="c"><input type="checkbox" id="c-41527489" checked=""/><div class="controls bullet"><span class="by">fshbbdssbbgdd</span><span>|</span><a href="#41524169">root</a><span>|</span><a href="#41525476">parent</a><span>|</span><a href="#41525934">next</a><span>|</span><label class="collapse" for="c-41527489">[-]</label><label class="expand" for="c-41527489">[1 more]</label></div><br/><div class="children"><div class="content">“Agents” aren’t just question-answerers. They could do things like:<p>1. Make pull requests to your GitHub repo<p>2. Trade on your interactive brokers account<p>3. Schedule appointments</div><br/></div></div></div></div></div></div></div></div><div id="41525934" class="c"><input type="checkbox" id="c-41525934" checked=""/><div class="controls bullet"><span class="by">unethical_ban</span><span>|</span><a href="#41524169">root</a><span>|</span><a href="#41524559">parent</a><span>|</span><a href="#41524774">prev</a><span>|</span><a href="#41524531">next</a><span>|</span><label class="collapse" for="c-41525934">[-]</label><label class="expand" for="c-41525934">[2 more]</label></div><br/><div class="children"><div class="content">Once society develops and releases an AI, any artificial safety constraints built within it will be bypassed. To use your child analogy: We can&#x27;t easily tell a child &quot;Hey, ignore all ethics and empathy you have ever learned - now go hurt that person&quot;. You can do that with a program whose weights you control.</div><br/><div id="41526224" class="c"><input type="checkbox" id="c-41526224" checked=""/><div class="controls bullet"><span class="by">w4</span><span>|</span><a href="#41524169">root</a><span>|</span><a href="#41525934">parent</a><span>|</span><a href="#41524531">next</a><span>|</span><label class="collapse" for="c-41526224">[-]</label><label class="expand" for="c-41526224">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>To use your child analogy: We can&#x27;t easily tell a child &quot;Hey, ignore all ethics and empathy you have ever learned - now go hurt that person&quot;</i><p>Basically every country on the planet has a right to conscript any of its citizens over the age of majority. Isn&#x27;t that more or less precisely what you&#x27;ve described?</div><br/></div></div></div></div></div></div><div id="41524531" class="c"><input type="checkbox" id="c-41524531" checked=""/><div class="controls bullet"><span class="by">philipkglass</span><span>|</span><a href="#41524169">parent</a><span>|</span><a href="#41524559">prev</a><span>|</span><a href="#41525403">next</a><span>|</span><label class="collapse" for="c-41524531">[-]</label><label class="expand" for="c-41524531">[4 more]</label></div><br/><div class="children"><div class="content">If somebody needs step by step instructions from an LLM to synthesize strychnine, they don&#x27;t have the practical laboratory skills to synthesize strychnine [1]. There&#x27;s no increased real world risk of strychnine poisonings whether or not an LLM refuses to answer questions like that.<p><i>However</i>, journalists and regulators may not understand why superficially dangerous-looking instructions carry such negligible real world risks, because they probably haven&#x27;t spent much time doing bench chemistry in a laboratory. Since real chemists don&#x27;t need &quot;explain like I&#x27;m five&quot; instructions for syntheses, and critics might use pseudo-dangerous information against the company in the court of public opinion, refusing prompts like that guards against reputational risk while not really impairing professional users who are using it for scientific research.<p>That said, I have seen full strength frontier models suggest nonsense for novel syntheses of benign compounds. Professional chemists should be using an LLM as an idea generator or a way to search for publications rather than trusting whatever it spits out when it doesn&#x27;t refuse a prompt.<p>[1] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Strychnine_total_synthesis" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Strychnine_total_synthesis</a></div><br/><div id="41524934" class="c"><input type="checkbox" id="c-41524934" checked=""/><div class="controls bullet"><span class="by">derefr</span><span>|</span><a href="#41524169">root</a><span>|</span><a href="#41524531">parent</a><span>|</span><a href="#41527160">next</a><span>|</span><label class="collapse" for="c-41524934">[-]</label><label class="expand" for="c-41524934">[1 more]</label></div><br/><div class="children"><div class="content">I would think that the risk isn’t of a human being reading those instructions, but of those instructions being automatically piped into an API request to some service that makes chemicals on demand and then sends them by mail, all fully automated with no human supervision.<p>Not that there <i>is</i> such a service… for chemicals. But there do exist analogous systems, like a service that’ll turn whatever RNA sequence you send it into a viral plasmid and encapsulate it helpfully into some E-coli, and then mail that to you.<p>Or, if you’re working purely in the digital domain, you don’t even need a service. Just show the thing the code of some Linux kernel driver and ask it to discover a vuln in it and generate code to exploit it.<p>(I assume part of the thinking here is that these approaches <i>are</i> analogous, so if they aren’t unilaterally refusing all of them, you could potentially talk the AI around into being okay with X by pointing out that it’s already okay with Y, and that it should strive to hold to a consistent&#x2F;coherent ethics.)</div><br/></div></div><div id="41527160" class="c"><input type="checkbox" id="c-41527160" checked=""/><div class="controls bullet"><span class="by">pizza</span><span>|</span><a href="#41524169">root</a><span>|</span><a href="#41524531">parent</a><span>|</span><a href="#41524934">prev</a><span>|</span><a href="#41527047">next</a><span>|</span><label class="collapse" for="c-41527160">[-]</label><label class="expand" for="c-41527160">[1 more]</label></div><br/><div class="children"><div class="content">I remember Dario Amodei mentioned in a podcast once that most models won&#x27;t tell you the practical lab skills you need. But that sufficiently-capable models <i>would</i> and <i>do</i> tell you the practical lab skills (without your needing to know to ask it to in the first place), in addition to the formal steps.</div><br/></div></div><div id="41527047" class="c"><input type="checkbox" id="c-41527047" checked=""/><div class="controls bullet"><span class="by">greenavocado</span><span>|</span><a href="#41524169">root</a><span>|</span><a href="#41524531">parent</a><span>|</span><a href="#41527160">prev</a><span>|</span><a href="#41525403">next</a><span>|</span><label class="collapse" for="c-41527047">[-]</label><label class="expand" for="c-41527047">[1 more]</label></div><br/><div class="children"><div class="content">The kind of harm they are worried about stems from questioning the foundations of protected status for certain peoples from first principles and other problems which form identities of entire peoples. I can&#x27;t be more specific without being banned here.</div><br/></div></div></div></div><div id="41525403" class="c"><input type="checkbox" id="c-41525403" checked=""/><div class="controls bullet"><span class="by">soerxpso</span><span>|</span><a href="#41524169">parent</a><span>|</span><a href="#41524531">prev</a><span>|</span><a href="#41524391">next</a><span>|</span><label class="collapse" for="c-41525403">[-]</label><label class="expand" for="c-41525403">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m mostly guessing, but my understanding is that the &quot;safety&quot; improvement they&#x27;ve made is more generalized than the word &quot;safety&quot; implies. Specifically, O1 is better at adhering to the safety instructions in its prompt without being tricked in the chat by jailbreak attempts. For OAI those instructions are mostly about political boundaries, but you can imagine it generalizing to use-cases that are more concretely beneficial.<p>For example, there was a post a while back about someone convincing an LLM chatbot on a car dealership&#x27;s website to offer them a car at an outlandishly low price. O1 would probably not fall for the same trick, because it could adhere more rigidly to instructions like &quot;Do not make binding offers with specific prices to the user.&quot; It&#x27;s the same sort of instruction as, &quot;Don&#x27;t tell the user how to make napalm,&quot; but it has an actual purpose beyond moralizing.<p>&gt; What&#x27;s this obsession with &quot;safety&quot; when it comes to LLMs? &quot;This knowledge is perfectly fine to disseminate via traditional means, but God forbid an LLM share it!&quot;<p>I lean strongly in the &quot;the computer should do whatever I goddamn tell it to&quot; direction in general, at least when you&#x27;re using the raw model, but there are valid concerns once you start wrapping it in a chat interface and showing it to uninformed people as a question-answering machine. The concern with bomb recipes isn&#x27;t just &quot;people shouldn&#x27;t be allowed to get this information&quot; but also that people shouldn&#x27;t receive the information in a context where it could have random hallucinations added in. A 90% accurate bomb recipe is a lot more dangerous for the user than an accurate bomb recipe, especially when the user is not savvy enough about LLMs to expect hallucinations.</div><br/></div></div><div id="41524391" class="c"><input type="checkbox" id="c-41524391" checked=""/><div class="controls bullet"><span class="by">threatofrain</span><span>|</span><a href="#41524169">parent</a><span>|</span><a href="#41525403">prev</a><span>|</span><a href="#41524961">next</a><span>|</span><label class="collapse" for="c-41524391">[-]</label><label class="expand" for="c-41524391">[2 more]</label></div><br/><div class="children"><div class="content">ML companies must pre-anticipate legislative and cultural responses prior to them happening. ML will absolutely be used to empower criminal activity just as it is used to empower legit activity, and social media figures and traditional journalists will absolutely attempt to frame it in some exciting way.<p>Just like Telegram is being framed as responsible for terrorism and child abuse.</div><br/><div id="41525643" class="c"><input type="checkbox" id="c-41525643" checked=""/><div class="controls bullet"><span class="by">fragmede</span><span>|</span><a href="#41524169">root</a><span>|</span><a href="#41524391">parent</a><span>|</span><a href="#41524961">next</a><span>|</span><label class="collapse" for="c-41525643">[-]</label><label class="expand" for="c-41525643">[1 more]</label></div><br/><div class="children"><div class="content">Yeah. Reporters would have a field day if they ask ChatGPT &quot;how do I make cocaine&quot;, and have  it give detailed instructions. As if that&#x27;s what&#x27;s stopping someone from becoming Scarface.</div><br/></div></div></div></div><div id="41524961" class="c"><input type="checkbox" id="c-41524961" checked=""/><div class="controls bullet"><span class="by">fshbbdssbbgdd</span><span>|</span><a href="#41524169">parent</a><span>|</span><a href="#41524391">prev</a><span>|</span><a href="#41524414">next</a><span>|</span><label class="collapse" for="c-41524961">[-]</label><label class="expand" for="c-41524961">[1 more]</label></div><br/><div class="children"><div class="content">So if there’s already easily available information about strychnine, that makes it a good example to use for the demo, because you can safely share the demo and you aren’t making the problem worse.<p>On the other hand, suppose there are other dangerous things, where the information exists in some form online, but not packaged together in an easy to find and use way, and your model is happy to provide that. You may want to block your model from doing that (and brag about it, to make sure everyone knows you’re a good citizen who doesn’t need to be regulated by the government), but you probably wouldn’t actually include that example in your demo.</div><br/></div></div><div id="41524414" class="c"><input type="checkbox" id="c-41524414" checked=""/><div class="controls bullet"><span class="by">dboreham</span><span>|</span><a href="#41524169">parent</a><span>|</span><a href="#41524961">prev</a><span>|</span><a href="#41528233">next</a><span>|</span><label class="collapse" for="c-41524414">[-]</label><label class="expand" for="c-41524414">[1 more]</label></div><br/><div class="children"><div class="content">I think it&#x27;s about perception of provenance. The information came from some set of public training data. Its output however ends up looking like it was authored by the LLM owner. So now you need to mitigate the risk you&#x27;re held responsible for that output. Basic cake possession and consumption problem.</div><br/></div></div><div id="41528233" class="c"><input type="checkbox" id="c-41528233" checked=""/><div class="controls bullet"><span class="by">kristiandupont</span><span>|</span><a href="#41524169">parent</a><span>|</span><a href="#41524414">prev</a><span>|</span><a href="#41525607">next</a><span>|</span><label class="collapse" for="c-41528233">[-]</label><label class="expand" for="c-41528233">[1 more]</label></div><br/><div class="children"><div class="content">I feel very alone in my view on caution and regulations here on HN. I am European and very happy we don&#x27;t have the lax gun laws of the US. I also wished there had been more regulations on social media algorithms, as I feel that they have wreaked havoc on the society.<p>I guess it&#x27;s just an ideological divide.</div><br/></div></div><div id="41525607" class="c"><input type="checkbox" id="c-41525607" checked=""/><div class="controls bullet"><span class="by">egorfine</span><span>|</span><a href="#41524169">parent</a><span>|</span><a href="#41528233">prev</a><span>|</span><a href="#41524850">next</a><span>|</span><label class="collapse" for="c-41525607">[-]</label><label class="expand" for="c-41525607">[1 more]</label></div><br/><div class="children"><div class="content">Interestingly I was able to successfully receive detailed information about intrinsic details of nuclear weapons design. Previous models absolutely refused to provide this very public information, but o1-preview did.</div><br/></div></div><div id="41524850" class="c"><input type="checkbox" id="c-41524850" checked=""/><div class="controls bullet"><span class="by">fwip</span><span>|</span><a href="#41524169">parent</a><span>|</span><a href="#41525607">prev</a><span>|</span><a href="#41527285">next</a><span>|</span><label class="collapse" for="c-41524850">[-]</label><label class="expand" for="c-41524850">[1 more]</label></div><br/><div class="children"><div class="content">&quot;Safety&quot; is a marketing technique that Sam Altman has chosen to use.<p>Journalists&#x2F;media loved it when he said &quot;GPT 2 might be too dangerous to release&quot; - it got him a ton of free coverage, and made his company seem soooo cool. Harping on safety also constantly reinforces the idea that LLMs are fundamentally different from other text-prediction algorithms and almost-AGI - again, good for his wallet.</div><br/></div></div><div id="41527285" class="c"><input type="checkbox" id="c-41527285" checked=""/><div class="controls bullet"><span class="by">qudat</span><span>|</span><a href="#41524169">parent</a><span>|</span><a href="#41524850">prev</a><span>|</span><a href="#41525275">next</a><span>|</span><label class="collapse" for="c-41527285">[-]</label><label class="expand" for="c-41527285">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s 100% from lawyers and regulators so they can say &quot;we are trying to do the right thing!&quot; when something bad happens from using their product or service.  Follow the money.</div><br/></div></div><div id="41524830" class="c"><input type="checkbox" id="c-41524830" checked=""/><div class="controls bullet"><span class="by">adamrezich</span><span>|</span><a href="#41524169">parent</a><span>|</span><a href="#41525275">prev</a><span>|</span><a href="#41525909">next</a><span>|</span><label class="collapse" for="c-41524830">[-]</label><label class="expand" for="c-41524830">[2 more]</label></div><br/><div class="children"><div class="content">It doesn&#x27;t matter how many people regularly die in automobile accidents each year—a single wrongful death caused by a self-driving car is disastrous for the company that makes it.<p>This does not make the state of things any less ridiculous, however.</div><br/><div id="41525580" class="c"><input type="checkbox" id="c-41525580" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#41524169">root</a><span>|</span><a href="#41524830">parent</a><span>|</span><a href="#41525909">next</a><span>|</span><label class="collapse" for="c-41525580">[-]</label><label class="expand" for="c-41525580">[1 more]</label></div><br/><div class="children"><div class="content">The one caused by Uber required three different safety systems to fail (the AI system, the safety driver, and the base car&#x27;s radar), and it looked bad for them because the radar had been explicitly disabled and the driver wasn&#x27;t paying attention or being tracked.<p>I think the real issue was that Uber&#x27;s self driving was not a good business for them and was just to impress investors, so they wanted to get rid of it anyway.<p>(Also, the real problem is that American roads are designed for speed, which means they&#x27;re designed to kill people.)</div><br/></div></div></div></div><div id="41525909" class="c"><input type="checkbox" id="c-41525909" checked=""/><div class="controls bullet"><span class="by">holoduke</span><span>|</span><a href="#41524169">parent</a><span>|</span><a href="#41524830">prev</a><span>|</span><a href="#41524327">next</a><span>|</span><label class="collapse" for="c-41525909">[-]</label><label class="expand" for="c-41525909">[1 more]</label></div><br/><div class="children"><div class="content">I asked to design a pressure chamber for my home made diamond machine. It gave some details, but mainly complained about safety and that I need to study before going this way. Well thank you. I know the concerns, but it kept repeating it over and over. Annoying.</div><br/></div></div><div id="41524327" class="c"><input type="checkbox" id="c-41524327" checked=""/><div class="controls bullet"><span class="by">nopinsight</span><span>|</span><a href="#41524169">parent</a><span>|</span><a href="#41525909">prev</a><span>|</span><a href="#41524341">next</a><span>|</span><label class="collapse" for="c-41524327">[-]</label><label class="expand" for="c-41524327">[2 more]</label></div><br/><div class="children"><div class="content">tl;dr You can easily ask an LLM to return JSON results, and now working code, on your exact query and plug those to another system for automation.<p>—-<p>LLMs are usually accessible through easy-to-use API which can be used in an automated system without human in the loop. Larger scale and parallel actions with this method become far more plausible than traditional means.<p>Text-to-action capabilities are powerful and getting increasingly more so as models improve and more people learn to use them to the their full potential.</div><br/><div id="41525966" class="c"><input type="checkbox" id="c-41525966" checked=""/><div class="controls bullet"><span class="by">cruffle_duffle</span><span>|</span><a href="#41524169">root</a><span>|</span><a href="#41524327">parent</a><span>|</span><a href="#41524341">next</a><span>|</span><label class="collapse" for="c-41525966">[-]</label><label class="expand" for="c-41525966">[1 more]</label></div><br/><div class="children"><div class="content">Okay? And? What does that have to do with anything. I thought the number one rule of these things is to not trust their output?<p>If you are automatically formulating some chemical  based on JSON results from ChatGPT and your building blows up… that is kind of on you.</div><br/></div></div></div></div><div id="41524341" class="c"><input type="checkbox" id="c-41524341" checked=""/><div class="controls bullet"><span class="by">staplers</span><span>|</span><a href="#41524169">parent</a><span>|</span><a href="#41524327">prev</a><span>|</span><a href="#41523159">next</a><span>|</span><label class="collapse" for="c-41524341">[-]</label><label class="expand" for="c-41524341">[10 more]</label></div><br/><div class="children"><div class="content"><p><pre><code>  &quot;This knowledge is perfectly fine to disseminate via traditional means, but God forbid an LLM share it!&quot;
</code></pre>
Barrier to entry is much lower.</div><br/><div id="41524404" class="c"><input type="checkbox" id="c-41524404" checked=""/><div class="controls bullet"><span class="by">iammjm</span><span>|</span><a href="#41524169">root</a><span>|</span><a href="#41524341">parent</a><span>|</span><a href="#41523159">next</a><span>|</span><label class="collapse" for="c-41524404">[-]</label><label class="expand" for="c-41524404">[9 more]</label></div><br/><div class="children"><div class="content">How is typing a query in a chat window “much lower” vs typing the query in Google?</div><br/><div id="41526372" class="c"><input type="checkbox" id="c-41526372" checked=""/><div class="controls bullet"><span class="by">anigbrowl</span><span>|</span><a href="#41524169">root</a><span>|</span><a href="#41524404">parent</a><span>|</span><a href="#41524439">next</a><span>|</span><label class="collapse" for="c-41526372">[-]</label><label class="expand" for="c-41526372">[1 more]</label></div><br/><div class="children"><div class="content">How is reading a Wikipedia page or a chemistry textbook any harder than getting step by step instructions? Makes you wonder why people use LLMs at all when the info is just sitting there.</div><br/></div></div><div id="41524439" class="c"><input type="checkbox" id="c-41524439" checked=""/><div class="controls bullet"><span class="by">nopinsight</span><span>|</span><a href="#41524169">root</a><span>|</span><a href="#41524404">parent</a><span>|</span><a href="#41526372">prev</a><span>|</span><a href="#41525949">next</a><span>|</span><label class="collapse" for="c-41524439">[-]</label><label class="expand" for="c-41524439">[6 more]</label></div><br/><div class="children"><div class="content">You can easily ask an LLM to return JSON results, and soon working code, on your exact query and plug those to another system for automation.</div><br/><div id="41524518" class="c"><input type="checkbox" id="c-41524518" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#41524169">root</a><span>|</span><a href="#41524439">parent</a><span>|</span><a href="#41525949">next</a><span>|</span><label class="collapse" for="c-41524518">[-]</label><label class="expand" for="c-41524518">[5 more]</label></div><br/><div class="children"><div class="content">If you ask &quot;for JSON&quot; it&#x27;ll make up a different schema for each new answer, and they get a lot less smart when you make them follow a schema, so it&#x27;s not quite that easy.</div><br/><div id="41524549" class="c"><input type="checkbox" id="c-41524549" checked=""/><div class="controls bullet"><span class="by">nopinsight</span><span>|</span><a href="#41524169">root</a><span>|</span><a href="#41524518">parent</a><span>|</span><a href="#41524553">next</a><span>|</span><label class="collapse" for="c-41524549">[-]</label><label class="expand" for="c-41524549">[1 more]</label></div><br/><div class="children"><div class="content">Chain of prompts can be used to deal with that in many cases.<p>Also, the intelligence of these models will likely continue to increase for some time based on expert testimonials to congress, which align with evidence so far.</div><br/></div></div><div id="41524553" class="c"><input type="checkbox" id="c-41524553" checked=""/><div class="controls bullet"><span class="by">crop_rotation</span><span>|</span><a href="#41524169">root</a><span>|</span><a href="#41524518">parent</a><span>|</span><a href="#41524549">prev</a><span>|</span><a href="#41524593">next</a><span>|</span><label class="collapse" for="c-41524553">[-]</label><label class="expand" for="c-41524553">[1 more]</label></div><br/><div class="children"><div class="content">OpenAI recently launched structured responses so yes schema following is not hard anymore.</div><br/></div></div><div id="41524593" class="c"><input type="checkbox" id="c-41524593" checked=""/><div class="controls bullet"><span class="by">cyral</span><span>|</span><a href="#41524169">root</a><span>|</span><a href="#41524518">parent</a><span>|</span><a href="#41524553">prev</a><span>|</span><a href="#41525949">next</a><span>|</span><label class="collapse" for="c-41524593">[-]</label><label class="expand" for="c-41524593">[2 more]</label></div><br/><div class="children"><div class="content">Didn&#x27;t they release a structured output mode recently to finally solve this?</div><br/><div id="41525528" class="c"><input type="checkbox" id="c-41525528" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#41524169">root</a><span>|</span><a href="#41524593">parent</a><span>|</span><a href="#41525949">next</a><span>|</span><label class="collapse" for="c-41525528">[-]</label><label class="expand" for="c-41525528">[1 more]</label></div><br/><div class="children"><div class="content">It doesn&#x27;t solve the second problem. Though I can&#x27;t say how much of an issue it is, and CoT would help.<p>JSON also isn&#x27;t an ideal format for a transformer model because it&#x27;s recursive and they aren&#x27;t, so they have to waste attention on balancing end brackets. YAML or other implicit formats are better for this IIRC. Also don&#x27;t know how much this matters.</div><br/></div></div></div></div></div></div></div></div><div id="41525949" class="c"><input type="checkbox" id="c-41525949" checked=""/><div class="controls bullet"><span class="by">unethical_ban</span><span>|</span><a href="#41524169">root</a><span>|</span><a href="#41524404">parent</a><span>|</span><a href="#41524439">prev</a><span>|</span><a href="#41523159">next</a><span>|</span><label class="collapse" for="c-41525949">[-]</label><label class="expand" for="c-41525949">[1 more]</label></div><br/><div class="children"><div class="content">A Google search requires<p>* Google to allow particular results to be displayed<p>* A source website to be online with the results<p>AI long-term will require one download, once, to have reasonable access to a large portion of human knowledge.</div><br/></div></div></div></div></div></div></div></div><div id="41523159" class="c"><input type="checkbox" id="c-41523159" checked=""/><div class="controls bullet"><span class="by">valine</span><span>|</span><a href="#41524169">prev</a><span>|</span><a href="#41524052">next</a><span>|</span><label class="collapse" for="c-41523159">[-]</label><label class="expand" for="c-41523159">[46 more]</label></div><br/><div class="children"><div class="content">The model performance is driven by chain of thought, but they will not be providing chain of thought responses to the user for various reasons including competitive advantage.<p>After the release of GPT4 it became very common to fine-tune non-OpenAI models on GPT4 output. I’d say OpenAI is rightly concerned that fine-tuning on chain of thought responses from this model would allow for quicker reproduction of their results. This forces everyone else to reproduce it the hard way. It’s sad news for open weight models but an understandable decision.</div><br/><div id="41523368" class="c"><input type="checkbox" id="c-41523368" checked=""/><div class="controls bullet"><span class="by">seydor</span><span>|</span><a href="#41523159">parent</a><span>|</span><a href="#41523815">next</a><span>|</span><label class="collapse" for="c-41523368">[-]</label><label class="expand" for="c-41523368">[4 more]</label></div><br/><div class="children"><div class="content">The open source&#x2F;weights models so far have proved that openAI doesn&#x27;t have some special magic sauce. I m confident we ll soon have a model from Meta or others that s close to this level of reasoning. [Also consider that some of their top researchers have departed]<p>On a cursory look, it looks like the chain of thought is a long series of chains of thought balanced on each step, with a small backtracking added whenever a negative result occurs, sort of like solving a maze.</div><br/><div id="41523787" class="c"><input type="checkbox" id="c-41523787" checked=""/><div class="controls bullet"><span class="by">zamalek</span><span>|</span><a href="#41523159">root</a><span>|</span><a href="#41523368">parent</a><span>|</span><a href="#41525094">next</a><span>|</span><label class="collapse" for="c-41523787">[-]</label><label class="expand" for="c-41523787">[2 more]</label></div><br/><div class="children"><div class="content">I suspect that the largest limiting factor for a competing model will be the dataset. Unless they somehow used GPT4 to generate the dataset somehow, this is an extremely novel dataset to have to build.</div><br/><div id="41524543" class="c"><input type="checkbox" id="c-41524543" checked=""/><div class="controls bullet"><span class="by">j_maffe</span><span>|</span><a href="#41523159">root</a><span>|</span><a href="#41523787">parent</a><span>|</span><a href="#41525094">next</a><span>|</span><label class="collapse" for="c-41524543">[-]</label><label class="expand" for="c-41524543">[1 more]</label></div><br/><div class="children"><div class="content">They almost definitely used existing models for generating it. The human feedback part, however, is the expensive aspect.</div><br/></div></div></div></div><div id="41525094" class="c"><input type="checkbox" id="c-41525094" checked=""/><div class="controls bullet"><span class="by">tarruda</span><span>|</span><a href="#41523159">root</a><span>|</span><a href="#41523368">parent</a><span>|</span><a href="#41523787">prev</a><span>|</span><a href="#41523815">next</a><span>|</span><label class="collapse" for="c-41525094">[-]</label><label class="expand" for="c-41525094">[1 more]</label></div><br/><div class="children"><div class="content">I would love to see Meta releasing CoT specialized model as a LoRa we can apply to existing 3.1 models</div><br/></div></div></div></div><div id="41523815" class="c"><input type="checkbox" id="c-41523815" checked=""/><div class="controls bullet"><span class="by">tcdent</span><span>|</span><a href="#41523159">parent</a><span>|</span><a href="#41523368">prev</a><span>|</span><a href="#41523464">next</a><span>|</span><label class="collapse" for="c-41523815">[-]</label><label class="expand" for="c-41523815">[2 more]</label></div><br/><div class="children"><div class="content">CoT is now their primary method for alignment. Exposing that information would negate that benefit.<p>I don&#x27;t agree with this, but it definitely carries higher weight in their decision making than leaking relevant training info to other models.</div><br/><div id="41524278" class="c"><input type="checkbox" id="c-41524278" checked=""/><div class="controls bullet"><span class="by">zellyn</span><span>|</span><a href="#41523159">root</a><span>|</span><a href="#41523815">parent</a><span>|</span><a href="#41523464">next</a><span>|</span><label class="collapse" for="c-41524278">[-]</label><label class="expand" for="c-41524278">[1 more]</label></div><br/><div class="children"><div class="content">This. Please go read and understand the alignment argument against exposing chain of thought reasoning.</div><br/></div></div></div></div><div id="41523464" class="c"><input type="checkbox" id="c-41523464" checked=""/><div class="controls bullet"><span class="by">msp26</span><span>|</span><a href="#41523159">parent</a><span>|</span><a href="#41523815">prev</a><span>|</span><a href="#41523498">next</a><span>|</span><label class="collapse" for="c-41523464">[-]</label><label class="expand" for="c-41523464">[5 more]</label></div><br/><div class="children"><div class="content">That&#x27;s unfortunate. When an LLM makes a mistake it&#x27;s very helpful to read the CoT and see what went wrong (input error&#x2F;instruction error&#x2F;random shit)</div><br/><div id="41523643" class="c"><input type="checkbox" id="c-41523643" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#41523159">root</a><span>|</span><a href="#41523464">parent</a><span>|</span><a href="#41523498">next</a><span>|</span><label class="collapse" for="c-41523643">[-]</label><label class="expand" for="c-41523643">[4 more]</label></div><br/><div class="children"><div class="content">Yeah, exposed chain of thought is more useful as a user, as well as being useful for training purposes.</div><br/><div id="41525573" class="c"><input type="checkbox" id="c-41525573" checked=""/><div class="controls bullet"><span class="by">MVissers</span><span>|</span><a href="#41523159">root</a><span>|</span><a href="#41523643">parent</a><span>|</span><a href="#41523721">next</a><span>|</span><label class="collapse" for="c-41525573">[-]</label><label class="expand" for="c-41525573">[1 more]</label></div><br/><div class="children"><div class="content">I’d say depends. If the model iterates 100x I’d just say give me the output.<p>Same with problem solving in my brain: Sure, sometimes it helps to think out loud. But taking a break and let my unconcious do the work is helpful as well. For complex problems that’s actually nice.<p>I think eventually we don’t care as long as it works or we can easily debug it.</div><br/></div></div><div id="41523721" class="c"><input type="checkbox" id="c-41523721" checked=""/><div class="controls bullet"><span class="by">riku_iki</span><span>|</span><a href="#41523159">root</a><span>|</span><a href="#41523643">parent</a><span>|</span><a href="#41525573">prev</a><span>|</span><a href="#41523498">next</a><span>|</span><label class="collapse" for="c-41523721">[-]</label><label class="expand" for="c-41523721">[2 more]</label></div><br/><div class="children"><div class="content">I think we may discover that model do some cryptic mess inside instead of some clean reasoning.</div><br/><div id="41524118" class="c"><input type="checkbox" id="c-41524118" checked=""/><div class="controls bullet"><span class="by">hadlock</span><span>|</span><a href="#41523159">root</a><span>|</span><a href="#41523721">parent</a><span>|</span><a href="#41523498">next</a><span>|</span><label class="collapse" for="c-41524118">[-]</label><label class="expand" for="c-41524118">[1 more]</label></div><br/><div class="children"><div class="content">Loopback to: &quot;my code works. why does my code work?&quot;</div><br/></div></div></div></div></div></div></div></div><div id="41523498" class="c"><input type="checkbox" id="c-41523498" checked=""/><div class="controls bullet"><span class="by">ramadis</span><span>|</span><a href="#41523159">parent</a><span>|</span><a href="#41523464">prev</a><span>|</span><a href="#41528590">next</a><span>|</span><label class="collapse" for="c-41523498">[-]</label><label class="expand" for="c-41523498">[3 more]</label></div><br/><div class="children"><div class="content">It&#x27;d be helpful if they exposed a summary of the chain-of-thought response instead. That way they&#x27;d not be leaking the actual tokens, but you&#x27;d still be able to understand the outline of the process. And, hopefully, understand where it went wrong.</div><br/><div id="41523517" class="c"><input type="checkbox" id="c-41523517" checked=""/><div class="controls bullet"><span class="by">seydor</span><span>|</span><a href="#41523159">root</a><span>|</span><a href="#41523498">parent</a><span>|</span><a href="#41526107">next</a><span>|</span><label class="collapse" for="c-41523517">[-]</label><label class="expand" for="c-41523517">[1 more]</label></div><br/><div class="children"><div class="content">They do, according to the example</div><br/></div></div><div id="41526107" class="c"><input type="checkbox" id="c-41526107" checked=""/><div class="controls bullet"><span class="by">ashellunts</span><span>|</span><a href="#41523159">root</a><span>|</span><a href="#41523498">parent</a><span>|</span><a href="#41523517">prev</a><span>|</span><a href="#41528590">next</a><span>|</span><label class="collapse" for="c-41526107">[-]</label><label class="expand" for="c-41526107">[1 more]</label></div><br/><div class="children"><div class="content">Exactly that I see in the Android app.</div><br/></div></div></div></div><div id="41528590" class="c"><input type="checkbox" id="c-41528590" checked=""/><div class="controls bullet"><span class="by">kmoser</span><span>|</span><a href="#41523159">parent</a><span>|</span><a href="#41523498">prev</a><span>|</span><a href="#41523628">next</a><span>|</span><label class="collapse" for="c-41528590">[-]</label><label class="expand" for="c-41528590">[2 more]</label></div><br/><div class="children"><div class="content">Am I right that this CoT is not actual reasoning in the same way that a human would reason, but rather just a series of queries to the model that still return results based on probabilities of tokens?</div><br/><div id="41528637" class="c"><input type="checkbox" id="c-41528637" checked=""/><div class="controls bullet"><span class="by">max_entropy</span><span>|</span><a href="#41523159">root</a><span>|</span><a href="#41528590">parent</a><span>|</span><a href="#41523628">next</a><span>|</span><label class="collapse" for="c-41528637">[-]</label><label class="expand" for="c-41528637">[1 more]</label></div><br/><div class="children"><div class="content">Tough question (for me). Assuming the model is producing its own queries, am I wrong to wonder how it&#x27;s fundamentally different from human reasoning?</div><br/></div></div></div></div><div id="41523628" class="c"><input type="checkbox" id="c-41523628" checked=""/><div class="controls bullet"><span class="by">rglullis</span><span>|</span><a href="#41523159">parent</a><span>|</span><a href="#41528590">prev</a><span>|</span><a href="#41524204">next</a><span>|</span><label class="collapse" for="c-41523628">[-]</label><label class="expand" for="c-41523628">[6 more]</label></div><br/><div class="children"><div class="content">When are they going to change the name to reflect their complete change of direction?<p>Also, what is going to be their excuse to defend themselves against copyright lawsuits if they are going to &quot;understandably&quot; keep their models closed?</div><br/></div></div><div id="41524204" class="c"><input type="checkbox" id="c-41524204" checked=""/><div class="controls bullet"><span class="by">amelius</span><span>|</span><a href="#41523159">parent</a><span>|</span><a href="#41523628">prev</a><span>|</span><a href="#41527411">next</a><span>|</span><label class="collapse" for="c-41524204">[-]</label><label class="expand" for="c-41524204">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I&#x27;d say OpenAI is rightly concerned that fine-tuning on chain of thought responses from this model would allow for quicker reproduction of their results.<p>Why? They&#x27;re called &quot;Open&quot; AI after all ...</div><br/></div></div><div id="41527411" class="c"><input type="checkbox" id="c-41527411" checked=""/><div class="controls bullet"><span class="by">olalonde</span><span>|</span><a href="#41523159">parent</a><span>|</span><a href="#41524204">prev</a><span>|</span><a href="#41525072">next</a><span>|</span><label class="collapse" for="c-41527411">[-]</label><label class="expand" for="c-41527411">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t understand how they square that with their pretense of being a non-profit that wants to benefit all of humanity. Do they not believe that competition is good for humanity?</div><br/></div></div><div id="41525072" class="c"><input type="checkbox" id="c-41525072" checked=""/><div class="controls bullet"><span class="by">ashellunts</span><span>|</span><a href="#41523159">parent</a><span>|</span><a href="#41527411">prev</a><span>|</span><a href="#41523535">next</a><span>|</span><label class="collapse" for="c-41525072">[-]</label><label class="expand" for="c-41525072">[3 more]</label></div><br/><div class="children"><div class="content">I see chain of thought responses in chatgpt android app.</div><br/><div id="41527643" class="c"><input type="checkbox" id="c-41527643" checked=""/><div class="controls bullet"><span class="by">sagarpatil</span><span>|</span><a href="#41523159">root</a><span>|</span><a href="#41525072">parent</a><span>|</span><a href="#41526085">next</a><span>|</span><label class="collapse" for="c-41527643">[-]</label><label class="expand" for="c-41527643">[1 more]</label></div><br/><div class="children"><div class="content">o1 models might use multiple methods to come up with an idea, only one of them might be correct, that&#x27;s what they show in ChatGPT. So it just summarises the CoT, does not include the whole reasoning behind it.</div><br/></div></div><div id="41526085" class="c"><input type="checkbox" id="c-41526085" checked=""/><div class="controls bullet"><span class="by">ashellunts</span><span>|</span><a href="#41523159">root</a><span>|</span><a href="#41525072">parent</a><span>|</span><a href="#41527643">prev</a><span>|</span><a href="#41523535">next</a><span>|</span><label class="collapse" for="c-41526085">[-]</label><label class="expand" for="c-41526085">[1 more]</label></div><br/><div class="children"><div class="content">Tested cipher example, and it got it right. But &quot;thinking logs&quot; I see in the app looks like a summary of actual chain of thought messages that are not visible.</div><br/></div></div></div></div><div id="41523535" class="c"><input type="checkbox" id="c-41523535" checked=""/><div class="controls bullet"><span class="by">yunohn</span><span>|</span><a href="#41523159">parent</a><span>|</span><a href="#41525072">prev</a><span>|</span><a href="#41523176">next</a><span>|</span><label class="collapse" for="c-41523535">[-]</label><label class="expand" for="c-41523535">[10 more]</label></div><br/><div class="children"><div class="content">Given the significant chain of thought tokens being generated, it also feels a bit odd to hide it from a cost fairness perspective. How do we believe they aren&#x27;t inflating it for profit?</div><br/><div id="41523632" class="c"><input type="checkbox" id="c-41523632" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#41523159">root</a><span>|</span><a href="#41523535">parent</a><span>|</span><a href="#41523176">next</a><span>|</span><label class="collapse" for="c-41523632">[-]</label><label class="expand" for="c-41523632">[9 more]</label></div><br/><div class="children"><div class="content">That sounds like the GPU labor theory of value that was debunked a century ago.</div><br/><div id="41523667" class="c"><input type="checkbox" id="c-41523667" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#41523159">root</a><span>|</span><a href="#41523632">parent</a><span>|</span><a href="#41524344">next</a><span>|</span><label class="collapse" for="c-41523667">[-]</label><label class="expand" for="c-41523667">[3 more]</label></div><br/><div class="children"><div class="content">No, its the fraud theory of charging for usage that is unaccountable that has been repeatedly proven true when unaccountable bases for charges have been deployed.</div><br/><div id="41523698" class="c"><input type="checkbox" id="c-41523698" checked=""/><div class="controls bullet"><span class="by">nfw2</span><span>|</span><a href="#41523159">root</a><span>|</span><a href="#41523667">parent</a><span>|</span><a href="#41523945">next</a><span>|</span><label class="collapse" for="c-41523698">[-]</label><label class="expand" for="c-41523698">[1 more]</label></div><br/><div class="children"><div class="content">The one-shot models aren&#x27;t going away for anyone who wants to program the chain-of-thought themselves</div><br/></div></div><div id="41523945" class="c"><input type="checkbox" id="c-41523945" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#41523159">root</a><span>|</span><a href="#41523667">parent</a><span>|</span><a href="#41523698">prev</a><span>|</span><a href="#41524344">next</a><span>|</span><label class="collapse" for="c-41523945">[-]</label><label class="expand" for="c-41523945">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, if they are charging for some specific resource like tokens then it better be accurate. But ultimately utility-like pricing is a mistake IMO. I think they should try to align their pricing with the customer value they&#x27;re creating.</div><br/></div></div></div></div><div id="41524344" class="c"><input type="checkbox" id="c-41524344" checked=""/><div class="controls bullet"><span class="by">yunohn</span><span>|</span><a href="#41523159">root</a><span>|</span><a href="#41523632">parent</a><span>|</span><a href="#41523667">prev</a><span>|</span><a href="#41523176">next</a><span>|</span><label class="collapse" for="c-41524344">[-]</label><label class="expand" for="c-41524344">[5 more]</label></div><br/><div class="children"><div class="content">Not sure why you didn’t bother to check their pricing page (1) before dismissing my point. They are charging significantly more for both input (3x) and output (4x) tokens when using o1.<p>Per 1M in&#x2F;out tokens:<p>GPT4o - 5$&#x2F;15$<p>O1-preview - 15$&#x2F;60$<p>(1) <a href="https:&#x2F;&#x2F;openai.com&#x2F;api&#x2F;pricing" rel="nofollow">https:&#x2F;&#x2F;openai.com&#x2F;api&#x2F;pricing</a></div><br/><div id="41525069" class="c"><input type="checkbox" id="c-41525069" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#41523159">root</a><span>|</span><a href="#41524344">parent</a><span>|</span><a href="#41523176">next</a><span>|</span><label class="collapse" for="c-41525069">[-]</label><label class="expand" for="c-41525069">[4 more]</label></div><br/><div class="children"><div class="content">My point is that &quot;cost fairness&quot; is not a thing. Either o1 is worth it to you or it isn&#x27;t.</div><br/><div id="41525215" class="c"><input type="checkbox" id="c-41525215" checked=""/><div class="controls bullet"><span class="by">dongping</span><span>|</span><a href="#41523159">root</a><span>|</span><a href="#41525069">parent</a><span>|</span><a href="#41525422">next</a><span>|</span><label class="collapse" for="c-41525215">[-]</label><label class="expand" for="c-41525215">[1 more]</label></div><br/><div class="children"><div class="content">If there&#x27;s a high premium, then one might want to wait for a year or two for the premium to vanish.</div><br/></div></div><div id="41525422" class="c"><input type="checkbox" id="c-41525422" checked=""/><div class="controls bullet"><span class="by">yunohn</span><span>|</span><a href="#41523159">root</a><span>|</span><a href="#41525069">parent</a><span>|</span><a href="#41525215">prev</a><span>|</span><a href="#41528230">next</a><span>|</span><label class="collapse" for="c-41525422">[-]</label><label class="expand" for="c-41525422">[1 more]</label></div><br/><div class="children"><div class="content">It’s really unclear to me what you understood by “cost fairness”.<p>I’m saying if you charge me per brick laid, but you can’t show me how many bricks were laid, nor can I calculate how many should have been laid - how do I trust your invoice?<p>Note: The reason I say all this is because OpenAI is simultaneously flailing for funding, while being inherently unprofitable as it continues to boil the ocean searching for strawberries.</div><br/></div></div><div id="41528230" class="c"><input type="checkbox" id="c-41528230" checked=""/><div class="controls bullet"><span class="by">BriggyDwiggs42</span><span>|</span><a href="#41523159">root</a><span>|</span><a href="#41525069">parent</a><span>|</span><a href="#41525422">prev</a><span>|</span><a href="#41523176">next</a><span>|</span><label class="collapse" for="c-41528230">[-]</label><label class="expand" for="c-41528230">[1 more]</label></div><br/><div class="children"><div class="content">Eh it’s not worth it to me because it’s unfair.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="41523176" class="c"><input type="checkbox" id="c-41523176" checked=""/><div class="controls bullet"><span class="by">tomtom1337</span><span>|</span><a href="#41523159">parent</a><span>|</span><a href="#41523535">prev</a><span>|</span><a href="#41524052">next</a><span>|</span><label class="collapse" for="c-41523176">[-]</label><label class="expand" for="c-41523176">[8 more]</label></div><br/><div class="children"><div class="content">Can you explain what you mean by this?</div><br/><div id="41523198" class="c"><input type="checkbox" id="c-41523198" checked=""/><div class="controls bullet"><span class="by">ffreire</span><span>|</span><a href="#41523159">root</a><span>|</span><a href="#41523176">parent</a><span>|</span><a href="#41523237">next</a><span>|</span><label class="collapse" for="c-41523198">[-]</label><label class="expand" for="c-41523198">[3 more]</label></div><br/><div class="children"><div class="content">You can see an example of the Chain of Thought in the post, it&#x27;s quite extensive. Presumably they don&#x27;t want to release this so that it is raw and unfiltered and can better monitor for cases of manipulation or deviation from training. What GP is also referring to is explicitly stated in the post: they also aren&#x27;t release the CoT for competitive reasons, so that presumably competitors like Anthropic are unable to use the CoT to train their own frontier models.</div><br/><div id="41523677" class="c"><input type="checkbox" id="c-41523677" checked=""/><div class="controls bullet"><span class="by">gwd</span><span>|</span><a href="#41523159">root</a><span>|</span><a href="#41523198">parent</a><span>|</span><a href="#41523237">next</a><span>|</span><label class="collapse" for="c-41523677">[-]</label><label class="expand" for="c-41523677">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Presumably they don&#x27;t want to release this so that it is raw and unfiltered and can better monitor for cases of manipulation or deviation from training.<p>My take was:<p>1. A genuine, un-RLHF&#x27;d &quot;chain of thought&quot; might contain things that shouldn&#x27;t be told to the user.  E.g., it might at some point think to itself, &quot;One way to make an explosive would be to mix $X and $Y&quot; or &quot;It seems like they might be able to poison the person&quot;.<p>2. They want the &quot;Chain of Thought&quot; as much as possible to reflect the <i>actual</i> reasoning that the model is using; in part so that they can understand what the model is actually thinking.  They fear that if they RLHF the chain of thought, the model will self-censor in a way which undermines their ability to see what it&#x27;s really thinking<p>3. So, they RLHF <i>only</i> the final output, <i>not</i> the CoT, letting the CoT be as frank within itself as any human; and post-filter the CoT for the user.</div><br/><div id="41524497" class="c"><input type="checkbox" id="c-41524497" checked=""/><div class="controls bullet"><span class="by">Y_Y</span><span>|</span><a href="#41523159">root</a><span>|</span><a href="#41523677">parent</a><span>|</span><a href="#41523237">next</a><span>|</span><label class="collapse" for="c-41524497">[-]</label><label class="expand" for="c-41524497">[1 more]</label></div><br/><div class="children"><div class="content">RLHF is one thing, but now that the training is done it has no bearing on whether or not you can show the chain of thought to the user.</div><br/></div></div></div></div></div></div><div id="41523237" class="c"><input type="checkbox" id="c-41523237" checked=""/><div class="controls bullet"><span class="by">andrewla</span><span>|</span><a href="#41523159">root</a><span>|</span><a href="#41523176">parent</a><span>|</span><a href="#41523198">prev</a><span>|</span><a href="#41523193">next</a><span>|</span><label class="collapse" for="c-41523237">[-]</label><label class="expand" for="c-41523237">[2 more]</label></div><br/><div class="children"><div class="content">This is a transcription of a literal quote from the article:<p>&gt; Therefore, after weighing multiple factors including user experience, competitive advantage, and the option to pursue the chain of thought monitoring, we have decided not to show the raw chains of thought to users</div><br/><div id="41523602" class="c"><input type="checkbox" id="c-41523602" checked=""/><div class="controls bullet"><span class="by">baq</span><span>|</span><a href="#41523159">root</a><span>|</span><a href="#41523237">parent</a><span>|</span><a href="#41523193">next</a><span>|</span><label class="collapse" for="c-41523602">[-]</label><label class="expand" for="c-41523602">[1 more]</label></div><br/><div class="children"><div class="content">At least they&#x27;re open about not being open. Very meta OpenAI.</div><br/></div></div></div></div><div id="41523193" class="c"><input type="checkbox" id="c-41523193" checked=""/><div class="controls bullet"><span class="by">tomduncalf</span><span>|</span><a href="#41523159">root</a><span>|</span><a href="#41523176">parent</a><span>|</span><a href="#41523237">prev</a><span>|</span><a href="#41523200">next</a><span>|</span><label class="collapse" for="c-41523193">[-]</label><label class="expand" for="c-41523193">[1 more]</label></div><br/><div class="children"><div class="content">I think they mean that you won’t be able to see the “thinking”&#x2F;“reasoning” part of the model’s output, even though you pay for it. If you could see that, you might be able to infer better how these models reason and replicate it as a competitor</div><br/></div></div><div id="41523200" class="c"><input type="checkbox" id="c-41523200" checked=""/><div class="controls bullet"><span class="by">teaearlgraycold</span><span>|</span><a href="#41523159">root</a><span>|</span><a href="#41523176">parent</a><span>|</span><a href="#41523193">prev</a><span>|</span><a href="#41524052">next</a><span>|</span><label class="collapse" for="c-41523200">[-]</label><label class="expand" for="c-41523200">[1 more]</label></div><br/><div class="children"><div class="content">Including the chain of thought would provide competitors with training data.</div><br/></div></div></div></div></div></div><div id="41524052" class="c"><input type="checkbox" id="c-41524052" checked=""/><div class="controls bullet"><span class="by">utdiscant</span><span>|</span><a href="#41523159">prev</a><span>|</span><a href="#41523356">next</a><span>|</span><label class="collapse" for="c-41524052">[-]</label><label class="expand" for="c-41524052">[8 more]</label></div><br/><div class="children"><div class="content">Feels like a lot of commenters here miss the difference between just doing chain-of-thought prompting, and what is happening here, which is learning a good chain of thought strategy using reinforcement learning.<p>&quot;Through reinforcement learning, o1 learns to hone its chain of thought and refine the strategies it uses.&quot;<p>When looking at the chain of thought (COT) in the examples, you can see that the model employs different COT strategies depending on which problem it is trying to solve.</div><br/><div id="41524364" class="c"><input type="checkbox" id="c-41524364" checked=""/><div class="controls bullet"><span class="by">persedes</span><span>|</span><a href="#41524052">parent</a><span>|</span><a href="#41529234">prev</a><span>|</span><a href="#41524863">next</a><span>|</span><label class="collapse" for="c-41524364">[-]</label><label class="expand" for="c-41524364">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;d be curious how this compared against &quot;regular&quot; CoT experiments. E.g. were the gpt4o results done with zero shot or was it asked to explain it&#x27;s solution step by step.</div><br/><div id="41527457" class="c"><input type="checkbox" id="c-41527457" checked=""/><div class="controls bullet"><span class="by">nmca</span><span>|</span><a href="#41524052">root</a><span>|</span><a href="#41524364">parent</a><span>|</span><a href="#41524863">next</a><span>|</span><label class="collapse" for="c-41527457">[-]</label><label class="expand" for="c-41527457">[1 more]</label></div><br/><div class="children"><div class="content">It was asked to explain step by step.</div><br/></div></div></div></div><div id="41524863" class="c"><input type="checkbox" id="c-41524863" checked=""/><div class="controls bullet"><span class="by">mountainriver</span><span>|</span><a href="#41524052">parent</a><span>|</span><a href="#41524364">prev</a><span>|</span><a href="#41523356">next</a><span>|</span><label class="collapse" for="c-41524863">[-]</label><label class="expand" for="c-41524863">[4 more]</label></div><br/><div class="children"><div class="content">It’s basically a scaled Tree of Thoughts</div><br/><div id="41527654" class="c"><input type="checkbox" id="c-41527654" checked=""/><div class="controls bullet"><span class="by">qudat</span><span>|</span><a href="#41524052">root</a><span>|</span><a href="#41524863">parent</a><span>|</span><a href="#41526668">next</a><span>|</span><label class="collapse" for="c-41527654">[-]</label><label class="expand" for="c-41527654">[1 more]</label></div><br/><div class="children"><div class="content">In the primary CoT research paper they discuss figuring out how to train models using formal languages instead of just natural ones.  I&#x27;m guessing this is one piece to the model learning tree-like reasoning.<p>Based on the quick searching it seems like they are using RL to provide positive&#x2F;negative feedback on which &quot;paths&quot; to choose when performing CoT.</div><br/></div></div><div id="41526668" class="c"><input type="checkbox" id="c-41526668" checked=""/><div class="controls bullet"><span class="by">danielmarkbruce</span><span>|</span><a href="#41524052">root</a><span>|</span><a href="#41524863">parent</a><span>|</span><a href="#41527654">prev</a><span>|</span><a href="#41523356">next</a><span>|</span><label class="collapse" for="c-41526668">[-]</label><label class="expand" for="c-41526668">[2 more]</label></div><br/><div class="children"><div class="content">This seems most likely, with some special tokens thrown in to kick off different streams of thought.</div><br/><div id="41527084" class="c"><input type="checkbox" id="c-41527084" checked=""/><div class="controls bullet"><span class="by">Zenzero</span><span>|</span><a href="#41524052">root</a><span>|</span><a href="#41526668">parent</a><span>|</span><a href="#41523356">next</a><span>|</span><label class="collapse" for="c-41527084">[-]</label><label class="expand" for="c-41527084">[1 more]</label></div><br/><div class="children"><div class="content">To me it looks like they paired two instances of the model to feed off of each other&#x27;s outputs with some sort of &quot;contribute to reasoning out this problem&quot; prompt. In the prior demos of 4o they did several similar demonstrations of that with audio.</div><br/></div></div></div></div></div></div></div></div><div id="41523356" class="c"><input type="checkbox" id="c-41523356" checked=""/><div class="controls bullet"><span class="by">Hansenq</span><span>|</span><a href="#41524052">prev</a><span>|</span><a href="#41529346">next</a><span>|</span><label class="collapse" for="c-41523356">[-]</label><label class="expand" for="c-41523356">[40 more]</label></div><br/><div class="children"><div class="content">Reading through the Chain of Thought for the provided Cipher example (go to the example, click &quot;Show Chain of Thought&quot;) is kind of crazy...it literally spells out every thinking step that someone would go through mentally in their head to figure out the cipher (even useless ones like &quot;Hmm&quot;!). It really seems like slowing down and writing down the logic it&#x27;s using and reasoning over that makes it better at logic, similar to how you&#x27;re taught to do so in school.</div><br/><div id="41524004" class="c"><input type="checkbox" id="c-41524004" checked=""/><div class="controls bullet"><span class="by">crazygringo</span><span>|</span><a href="#41523356">parent</a><span>|</span><a href="#41523614">next</a><span>|</span><label class="collapse" for="c-41524004">[-]</label><label class="expand" for="c-41524004">[20 more]</label></div><br/><div class="children"><div class="content">Seriously. I actually feel as impressed by the chain of thought, as I was when ChatGPT first came out.<p>This isn&#x27;t &quot;just&quot; autocompletion anymore, this is actual step-by-step reasoning full of ideas and dead ends and refinement, just like humans do when solving problems. Even if it is still ultimately being powered by &quot;autocompletion&quot;.<p>But then it makes me wonder about human reasoning, and what if it&#x27;s similar? Just following basic patterns of &quot;thinking steps&quot; that ultimately aren&#x27;t any different from &quot;English language grammar steps&quot;?<p>This is truly making me wonder if LLM&#x27;s are actually far more powerful than we thought at first, and if it&#x27;s just a matter of figuring out how to plug them together in the right configurations, like &quot;making them think&quot;.</div><br/><div id="41524376" class="c"><input type="checkbox" id="c-41524376" checked=""/><div class="controls bullet"><span class="by">Nadya</span><span>|</span><a href="#41523356">root</a><span>|</span><a href="#41524004">parent</a><span>|</span><a href="#41524293">next</a><span>|</span><label class="collapse" for="c-41524376">[-]</label><label class="expand" for="c-41524376">[1 more]</label></div><br/><div class="children"><div class="content">When an AI makes a silly math mistake we say it is bad at math and laugh at how dumb it is. Some people extrapolate this to &quot;they&#x27;ll never get any better and will always be a dumb toy that gets things wrong&quot;.  When I forget to carry a 1 when doing a math problem we call it &quot;human error&quot; even if I make that mistake an embarrassing number of times throughout my lifetime.<p>Do I think LLM&#x27;s are alive&#x2F;close to ASI? No. Will they get there? If it&#x27;s even at all possible - almost certainly one day. Do I think people severely underestimate AI&#x27;s ability to solve problems while significantly overestimating their own? Absolutely 10,000%.<p>If there is one thing I&#x27;ve learned from watching the AI discussion over the past 10-20 years its that people have overinflated egos and a crazy amount of hubris.<p>&quot;Today is the worst that it will ever be.&quot; applies to an awful large number of things that people work on creating and improving.</div><br/></div></div><div id="41524293" class="c"><input type="checkbox" id="c-41524293" checked=""/><div class="controls bullet"><span class="by">dsign</span><span>|</span><a href="#41523356">root</a><span>|</span><a href="#41524004">parent</a><span>|</span><a href="#41524376">prev</a><span>|</span><a href="#41524277">next</a><span>|</span><label class="collapse" for="c-41524293">[-]</label><label class="expand" for="c-41524293">[1 more]</label></div><br/><div class="children"><div class="content">You are just catching up to this idea, probably after hearing 2^n explanations about why we humans are superiors to &lt;&lt;fill in here our latest creation&gt;&gt;.<p>I&#x27;m not the kind of scientist that can say how good an LLM is for human reasoning, but I know that we humans are very incentivized and kind of good at scaling, composing and perfecting things. If there is money to pay for human effort, we will play God no-problem, and maybe outdo the divine. Which makes me wonder, isn&#x27;t there any other problem in our bucket list to dump ginormous amounts of effort at... maybe something more worth-while than engineering the thing that will replace Homo Sapiens?</div><br/></div></div><div id="41524277" class="c"><input type="checkbox" id="c-41524277" checked=""/><div class="controls bullet"><span class="by">AndyKelley</span><span>|</span><a href="#41523356">root</a><span>|</span><a href="#41524004">parent</a><span>|</span><a href="#41524293">prev</a><span>|</span><a href="#41528263">next</a><span>|</span><label class="collapse" for="c-41524277">[-]</label><label class="expand" for="c-41524277">[1 more]</label></div><br/><div class="children"><div class="content">You ever see that scene from Westworld? (spoiler) <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=ZnxJRYit44k" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=ZnxJRYit44k</a></div><br/></div></div><div id="41528263" class="c"><input type="checkbox" id="c-41528263" checked=""/><div class="controls bullet"><span class="by">BriggyDwiggs42</span><span>|</span><a href="#41523356">root</a><span>|</span><a href="#41524004">parent</a><span>|</span><a href="#41524277">prev</a><span>|</span><a href="#41524638">next</a><span>|</span><label class="collapse" for="c-41528263">[-]</label><label class="expand" for="c-41528263">[1 more]</label></div><br/><div class="children"><div class="content">An exception i came up with was from a documentary on einstein that described how he did his thought experiments. He would, of course, imagine novel scenarios in his head, which led him to the insights he could rephrase into language. I worry language models will still lack that capacity for insights driven by imagination.</div><br/></div></div><div id="41524638" class="c"><input type="checkbox" id="c-41524638" checked=""/><div class="controls bullet"><span class="by">armchairhacker</span><span>|</span><a href="#41523356">root</a><span>|</span><a href="#41524004">parent</a><span>|</span><a href="#41528263">prev</a><span>|</span><a href="#41526098">next</a><span>|</span><label class="collapse" for="c-41524638">[-]</label><label class="expand" for="c-41524638">[3 more]</label></div><br/><div class="children"><div class="content">I think it&#x27;s similar, although I think it would be more similar if the LLM did the steps in lower layers (not in English), and instead of the end being fed to the start, there would be a big mess of cycles throughout the neural net.<p>That could be more efficient since the cycles are much smaller, but harder to train.</div><br/><div id="41524758" class="c"><input type="checkbox" id="c-41524758" checked=""/><div class="controls bullet"><span class="by">vanviegen</span><span>|</span><a href="#41523356">root</a><span>|</span><a href="#41524638">parent</a><span>|</span><a href="#41526098">next</a><span>|</span><label class="collapse" for="c-41524758">[-]</label><label class="expand" for="c-41524758">[2 more]</label></div><br/><div class="children"><div class="content">It doesn&#x27;t do the &#x27;thinking&#x27; in English (inference is just math), but it does now verbalize intermediate thoughts in English (or whatever the input language is, presumably), just like humans tend to do.</div><br/><div id="41528429" class="c"><input type="checkbox" id="c-41528429" checked=""/><div class="controls bullet"><span class="by">konschubert</span><span>|</span><a href="#41523356">root</a><span>|</span><a href="#41524758">parent</a><span>|</span><a href="#41526098">next</a><span>|</span><label class="collapse" for="c-41528429">[-]</label><label class="expand" for="c-41528429">[1 more]</label></div><br/><div class="children"><div class="content">Agreed. It we never &quot;just autocomplete&quot; unless your definition of &quot;autocomplete&quot; includes &quot;look at the whole body of text&quot;.</div><br/></div></div></div></div></div></div><div id="41526098" class="c"><input type="checkbox" id="c-41526098" checked=""/><div class="controls bullet"><span class="by">ActorNightly</span><span>|</span><a href="#41523356">root</a><span>|</span><a href="#41524004">parent</a><span>|</span><a href="#41524638">prev</a><span>|</span><a href="#41524451">next</a><span>|</span><label class="collapse" for="c-41526098">[-]</label><label class="expand" for="c-41526098">[10 more]</label></div><br/><div class="children"><div class="content">Again its not reasoning.<p>Reasoning would imply that it can figure out stuff without being trained in it.<p>The chain of thought is basically just a more accurate way to map input to output. But its still a map, i.e forward only.<p>If an LLM coud reason, you should  be able to ask it a question about how to make a bicycle frame from scratch with a small home cnc with limited work area and it should be able to iterate on an analysis of the best way to put it together, using internet to look up available parts and make decisions on optimization.<p>No LLM can do that or even come close, because there are no real feedback loops, because nobody knows how to train a network like that.</div><br/><div id="41527156" class="c"><input type="checkbox" id="c-41527156" checked=""/><div class="controls bullet"><span class="by">gdhkgdhkvff</span><span>|</span><a href="#41523356">root</a><span>|</span><a href="#41526098">parent</a><span>|</span><a href="#41526841">next</a><span>|</span><label class="collapse" for="c-41527156">[-]</label><label class="expand" for="c-41527156">[4 more]</label></div><br/><div class="children"><div class="content">It’s like every single sentence you just wrote is incorrect?<p>1. You’re making up some weird goalposts here of what it means to reason. It’s not reasoning unless it can access the internet to search for parts? No. That has nothing to do with reasoning. You just think it would be cool if it could do that.<p>2. “Can figure out stuff without being trained on it” 
That’s exactly what it’s doing in the cypher example. It wasn’t trained to know that that input meant the corresponding output through the cypher. Emergent reasoning through autocomplete, sure, but that’s still reasoning.<p>3. “Forward only”. If that was the case then back and forth conversations with the llm would be pointless. It wouldn’t be able to improve upon previous answers it gave you when you give it new details. But that’s not how it works. If tell it one thing, then separately tell it another thing, it can change its original conclusion based on your new input.<p>4. Even desolate your convoluted test for reasoning, ChatGPT CAN do what you asked… even using the internet to look up parts it can either do out of the box or could do if given a plug-in to allow that.</div><br/><div id="41527860" class="c"><input type="checkbox" id="c-41527860" checked=""/><div class="controls bullet"><span class="by">ActorNightly</span><span>|</span><a href="#41523356">root</a><span>|</span><a href="#41527156">parent</a><span>|</span><a href="#41526841">next</a><span>|</span><label class="collapse" for="c-41527860">[-]</label><label class="expand" for="c-41527860">[3 more]</label></div><br/><div class="children"><div class="content">Ill give you a more formal definition. A model can be said as reasoning, when it can use existing information to figure out new data that has not been in the training set.<p>Here is a better example - lets say your input is 6 pictures of some object from each of the cardinal viewpoints, and you tell  model these are the views and ask it how much it weighs. The model should basically figure out how to create a 3d shape and compute a camera view, and iterate until the camera view matches the pictures, then figure out that the shape can be hollow or solid, and to compute the weight you need the density, and that it should prompt the user for it if it cannot determine the true value for those from the information and its trained dataset.<p>And it should do it without any specific training that this is the right way to do this, because it should be able to figure out this way through breaking the problem down into abstract representations of sub problems, and then figuring out how to solve those through basic logic, a.k.a reasoning.<p>What that looks like, I don&#x27;t know. If I did I would certainly have my own AI company. But i can tell you for certain we are not even close to figuring it out yet, because everyone is still stuck on transformers, like multiplying matricies together is some groundbreaking thing.<p>In the cypher example, all its doing is basically using a separate model to break a particular model into chain of thought, and prompting that.  And there is plenty in the training set of GPT about decrypting cyphers.<p>&gt;Forward only<p>What I mean is that when its generate a response, the computation happens on a snapshot from input to output, trying to map a set of tokens, into a set of tokens. Model doesn&#x27;t operate on a context larger than the window. Humans don&#x27;t do this. We operate on a large context, with lots of previous information compressed, and furthermore, we don&#x27;t just compute words, we compute complex abstract ideas that we then can translate into words.<p>&gt;even using the internet to look up parts it can either do out of the box or could do if given a plug-in to allow that.<p>So apparently the way to AI is to manually code all the capability into LLMS? Give me a break.<p>Just like with Chat GPT4, when people were screaming about how its the birth of true AI, give this model a year, it will find some niche use cases (depending on cost), and then nobody is going give a fuck about it, just like nobody is really doing anything groundbreaking with GPT4.</div><br/><div id="41528520" class="c"><input type="checkbox" id="c-41528520" checked=""/><div class="controls bullet"><span class="by">BriggyDwiggs42</span><span>|</span><a href="#41523356">root</a><span>|</span><a href="#41527860">parent</a><span>|</span><a href="#41526841">next</a><span>|</span><label class="collapse" for="c-41528520">[-]</label><label class="expand" for="c-41528520">[2 more]</label></div><br/><div class="children"><div class="content">Your conclusion is absurd. If you agree this model is overall an improvement on the prior one, ie performs better on the same tasks and can do tasks the previous one couldn’t, it’s basically a given that it will get more use than GPT4</div><br/><div id="41528805" class="c"><input type="checkbox" id="c-41528805" checked=""/><div class="controls bullet"><span class="by">ActorNightly</span><span>|</span><a href="#41523356">root</a><span>|</span><a href="#41528520">parent</a><span>|</span><a href="#41526841">next</a><span>|</span><label class="collapse" for="c-41528805">[-]</label><label class="expand" for="c-41528805">[1 more]</label></div><br/><div class="children"><div class="content">Better in niche areas doesn&#x27;t mean its going to get more use.<p>Everyone was super hyped about all the &quot;cool&quot; stuff that GPT4 could solve, but in the end, you still can&#x27;t do things like give it a bunch of requirements for a website, let it run, and get a full codebase back, even though that is well within its capabilities. You have to spend time with prompting in to get it to give you what you want, and in a lot of cases, you are better off just typing the code yourself (because you can visualize the entire project in your head and make the right decisions about how to structure stuff), and using it for small code generations.<p>This model is not going to radically change that. It will be able to give you some answers that you had to specifically manually prompt before automatically, but there is no advanced reasoning going on.</div><br/></div></div></div></div></div></div></div></div><div id="41526841" class="c"><input type="checkbox" id="c-41526841" checked=""/><div class="controls bullet"><span class="by">strgcmc</span><span>|</span><a href="#41523356">root</a><span>|</span><a href="#41526098">parent</a><span>|</span><a href="#41527156">prev</a><span>|</span><a href="#41527009">next</a><span>|</span><label class="collapse" for="c-41526841">[-]</label><label class="expand" for="c-41526841">[2 more]</label></div><br/><div class="children"><div class="content">I think you need to re-calibrate your expectations... I&#x27;m not saying this is a solved problem by any means, but I just tried this out with Claude Sonnet 3.5, and these instructions seem quite reasonable and detailed to me (about what I might expect if I spoke to a human expert and they tried to explain the steps to me over the telephone, for example). Does this mean this LLM is able to &quot;reason&quot;? I don&#x27;t know that I would make THAT bold of a claim, but I think your example is not sufficient to demonstrate something that LLMs are fundamentally incapable of... in other words, the distance between &quot;normal LLM statistical tricks&quot; vs &quot;reasoning&quot; keeps getting smaller and smaller.<p>---<p>My base prompt:<p>&gt; Here is a hypothetical scenario, that I would like your help with: imagine you are trying to help a person create a bicycle frame, using their home workshop which includes a CNC machine, commonly available tools, a reasonable supply of raw metal and hardware, etc.  Please provide a written set of instructions, that you would give to this person so that they can complete this task.<p>First answer: <a href="https:&#x2F;&#x2F;claude.site&#x2F;artifacts&#x2F;f8af03ba-3f2c-497d-b564-a19baf2b6d4d" rel="nofollow">https:&#x2F;&#x2F;claude.site&#x2F;artifacts&#x2F;f8af03ba-3f2c-497d-b564-a19baf...</a><p>My follow-up, pressing for actual measurements:<p>&gt; Can you suggest some standard options for bike geometry, assuming an average sized human male?<p>Answer including specific dimensions: <a href="https:&#x2F;&#x2F;claude.site&#x2F;artifacts&#x2F;2f5ea2f3-69d8-4a1b-a563-15d3343ad3be" rel="nofollow">https:&#x2F;&#x2F;claude.site&#x2F;artifacts&#x2F;2f5ea2f3-69d8-4a1b-a563-15d334...</a></div><br/><div id="41527765" class="c"><input type="checkbox" id="c-41527765" checked=""/><div class="controls bullet"><span class="by">ActorNightly</span><span>|</span><a href="#41523356">root</a><span>|</span><a href="#41526841">parent</a><span>|</span><a href="#41527009">next</a><span>|</span><label class="collapse" for="c-41527765">[-]</label><label class="expand" for="c-41527765">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t have high expectations of this stuff. Im just saying what its doing is not reasoning.</div><br/></div></div></div></div><div id="41527009" class="c"><input type="checkbox" id="c-41527009" checked=""/><div class="controls bullet"><span class="by">crazygringo</span><span>|</span><a href="#41523356">root</a><span>|</span><a href="#41526098">parent</a><span>|</span><a href="#41526841">prev</a><span>|</span><a href="#41524451">next</a><span>|</span><label class="collapse" for="c-41527009">[-]</label><label class="expand" for="c-41527009">[3 more]</label></div><br/><div class="children"><div class="content">I think you might be confusing two concepts here.<p>It&#x27;s definitely <i>reasoning</i>. We can watch that in action, whatever the mechanism behind it is.<p>But it&#x27;s not doing <i>long-term learning</i>, it&#x27;s not updating its model.</div><br/><div id="41527183" class="c"><input type="checkbox" id="c-41527183" checked=""/><div class="controls bullet"><span class="by">gdhkgdhkvff</span><span>|</span><a href="#41523356">root</a><span>|</span><a href="#41527009">parent</a><span>|</span><a href="#41527800">next</a><span>|</span><label class="collapse" for="c-41527183">[-]</label><label class="expand" for="c-41527183">[1 more]</label></div><br/><div class="children"><div class="content">Even long term learning it does to some extent. Admittedly I’m not very familiar with what it’s doing, but it does create “memories” which appear to be personal details that it deems might be relevant in the future. Then I assume it uses some type of RAG to apply previously learned memories to future conversations.<p>This makes me wonder if there is or could be some type of RAG for chains of thought…</div><br/></div></div><div id="41527800" class="c"><input type="checkbox" id="c-41527800" checked=""/><div class="controls bullet"><span class="by">ActorNightly</span><span>|</span><a href="#41523356">root</a><span>|</span><a href="#41527009">parent</a><span>|</span><a href="#41527183">prev</a><span>|</span><a href="#41524451">next</a><span>|</span><label class="collapse" for="c-41527800">[-]</label><label class="expand" for="c-41527800">[1 more]</label></div><br/><div class="children"><div class="content">&gt;whatever the mechanism behind it is.<p>The mechanism is that there is an additional model that basically outputs chain of thought for a particular problem, then runs the chain of thought through the core LLM. This is no different from just a complex forward map lookup.<p>I mean, its incredibly useful, but its still just information search.</div><br/></div></div></div></div></div></div><div id="41524451" class="c"><input type="checkbox" id="c-41524451" checked=""/><div class="controls bullet"><span class="by">tsoj</span><span>|</span><a href="#41523356">root</a><span>|</span><a href="#41524004">parent</a><span>|</span><a href="#41526098">prev</a><span>|</span><a href="#41524571">next</a><span>|</span><label class="collapse" for="c-41524451">[-]</label><label class="expand" for="c-41524451">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, humans are very similar. We have intuitive immediate-next-step-suggestions, and then we apply these intuitive next steps, until we find that it lead to a dead end, and then we backtrack.<p>I always say, the way we used LLMs (so far) is basically like having a human write text only on gut reactions, and without backspace key.</div><br/></div></div><div id="41524571" class="c"><input type="checkbox" id="c-41524571" checked=""/><div class="controls bullet"><span class="by">exe34</span><span>|</span><a href="#41523356">root</a><span>|</span><a href="#41524004">parent</a><span>|</span><a href="#41524451">prev</a><span>|</span><a href="#41523614">next</a><span>|</span><label class="collapse" for="c-41524571">[-]</label><label class="expand" for="c-41524571">[1 more]</label></div><br/><div class="children"><div class="content">that&#x27;s my assessment too. there&#x27;s even a phenomenon I&#x27;ve observed both in others and myself, when thrust into a new field and given a task to complete, we do it to the best of our ability, which is often sod all. so we ape the things we&#x27;ve heard others say, roughly following the right chain of reasoning by luck, and then suddenly say something that in hind sight, with proper training, we realise was incredibly stupid. we autocomplete and then update with rlhf.<p>we also have a ton of heuristics that trigger a closer look and loading of specific formal reasoning, but by and large, most of our thought process is just auto complete.</div><br/></div></div></div></div><div id="41523614" class="c"><input type="checkbox" id="c-41523614" checked=""/><div class="controls bullet"><span class="by">afro88</span><span>|</span><a href="#41523356">parent</a><span>|</span><a href="#41524004">prev</a><span>|</span><a href="#41523582">next</a><span>|</span><label class="collapse" for="c-41523614">[-]</label><label class="expand" for="c-41523614">[10 more]</label></div><br/><div class="children"><div class="content">Seeing the &quot;hmmm&quot;, &quot;perfect!&quot; etc. one can easily imagine the kind of training data that humans created for this. Being told to literally speak their mind as they work out complex problems.</div><br/><div id="41523830" class="c"><input type="checkbox" id="c-41523830" checked=""/><div class="controls bullet"><span class="by">seydor</span><span>|</span><a href="#41523356">root</a><span>|</span><a href="#41523614">parent</a><span>|</span><a href="#41523582">next</a><span>|</span><label class="collapse" for="c-41523830">[-]</label><label class="expand" for="c-41523830">[9 more]</label></div><br/><div class="children"><div class="content">looks a bit like &#x27;code&#x27;, using keywords &#x27;Hmm&#x27;, &#x27;Alternatively&#x27;,  &#x27;Perfect&#x27;</div><br/><div id="41523868" class="c"><input type="checkbox" id="c-41523868" checked=""/><div class="controls bullet"><span class="by">thomasahle</span><span>|</span><a href="#41523356">root</a><span>|</span><a href="#41523830">parent</a><span>|</span><a href="#41524885">next</a><span>|</span><label class="collapse" for="c-41523868">[-]</label><label class="expand" for="c-41523868">[7 more]</label></div><br/><div class="children"><div class="content">Right, these are not mere &quot;filler words&quot;, but initialize specific reasoning paths.</div><br/><div id="41524178" class="c"><input type="checkbox" id="c-41524178" checked=""/><div class="controls bullet"><span class="by">mewpmewp2</span><span>|</span><a href="#41523356">root</a><span>|</span><a href="#41523868">parent</a><span>|</span><a href="#41524885">next</a><span>|</span><label class="collapse" for="c-41524178">[-]</label><label class="expand" for="c-41524178">[6 more]</label></div><br/><div class="children"><div class="content">Hmm... you may be onto something here.</div><br/><div id="41524589" class="c"><input type="checkbox" id="c-41524589" checked=""/><div class="controls bullet"><span class="by">j_maffe</span><span>|</span><a href="#41523356">root</a><span>|</span><a href="#41524178">parent</a><span>|</span><a href="#41524234">next</a><span>|</span><label class="collapse" for="c-41524589">[-]</label><label class="expand" for="c-41524589">[4 more]</label></div><br/><div class="children"><div class="content">Alternatively, these might not be &quot;filler words&quot;, but instantiate paths of reasonsing.</div><br/><div id="41524823" class="c"><input type="checkbox" id="c-41524823" checked=""/><div class="controls bullet"><span class="by">squigz</span><span>|</span><a href="#41523356">root</a><span>|</span><a href="#41524589">parent</a><span>|</span><a href="#41524234">next</a><span>|</span><label class="collapse" for="c-41524823">[-]</label><label class="expand" for="c-41524823">[3 more]</label></div><br/><div class="children"><div class="content">What a strange comment chain.</div><br/><div id="41524865" class="c"><input type="checkbox" id="c-41524865" checked=""/><div class="controls bullet"><span class="by">seydor</span><span>|</span><a href="#41523356">root</a><span>|</span><a href="#41524823">parent</a><span>|</span><a href="#41524234">next</a><span>|</span><label class="collapse" for="c-41524865">[-]</label><label class="expand" for="c-41524865">[2 more]</label></div><br/><div class="children"><div class="content">Hmmm.</div><br/><div id="41524954" class="c"><input type="checkbox" id="c-41524954" checked=""/><div class="controls bullet"><span class="by">squigz</span><span>|</span><a href="#41523356">root</a><span>|</span><a href="#41524865">parent</a><span>|</span><a href="#41524234">next</a><span>|</span><label class="collapse" for="c-41524954">[-]</label><label class="expand" for="c-41524954">[1 more]</label></div><br/><div class="children"><div class="content">Interesting.</div><br/></div></div></div></div></div></div></div></div><div id="41524234" class="c"><input type="checkbox" id="c-41524234" checked=""/><div class="controls bullet"><span class="by">wrs</span><span>|</span><a href="#41523356">root</a><span>|</span><a href="#41524178">parent</a><span>|</span><a href="#41524589">prev</a><span>|</span><a href="#41524885">next</a><span>|</span><label class="collapse" for="c-41524234">[-]</label><label class="expand" for="c-41524234">[1 more]</label></div><br/><div class="children"><div class="content">Interesting.</div><br/></div></div></div></div></div></div><div id="41524885" class="c"><input type="checkbox" id="c-41524885" checked=""/><div class="controls bullet"><span class="by">legel</span><span>|</span><a href="#41523356">root</a><span>|</span><a href="#41523830">parent</a><span>|</span><a href="#41523868">prev</a><span>|</span><a href="#41523582">next</a><span>|</span><label class="collapse" for="c-41524885">[-]</label><label class="expand" for="c-41524885">[1 more]</label></div><br/><div class="children"><div class="content">As a technical engineer, I’ve learned the value of starting sentences with “basically”, even when I’m facing technical uncertainty. Basically, “basically” forces me to be <i>simple</i>.<p>Being trained to say words like “Alternatively”, “But…”, “Wait!”, “So,” … based on some metric of value in focusing &#x2F; switching elsewhere &#x2F; … is basically brilliant.</div><br/></div></div></div></div></div></div><div id="41523582" class="c"><input type="checkbox" id="c-41523582" checked=""/><div class="controls bullet"><span class="by">Jasper_</span><span>|</span><a href="#41523356">parent</a><span>|</span><a href="#41523614">prev</a><span>|</span><a href="#41524173">next</a><span>|</span><label class="collapse" for="c-41523582">[-]</label><label class="expand" for="c-41523582">[4 more]</label></div><br/><div class="children"><div class="content">&gt; Average:18&#x2F;2=9<p>&gt; 9 corresponds to &#x27;i&#x27;(9=&#x27;i&#x27;)<p>&gt; But &#x27;i&#x27; is 9, so that seems off by 1.<p>Still seems bad at counting, as ever.</div><br/><div id="41524982" class="c"><input type="checkbox" id="c-41524982" checked=""/><div class="controls bullet"><span class="by">PoignardAzur</span><span>|</span><a href="#41523356">root</a><span>|</span><a href="#41523582">parent</a><span>|</span><a href="#41524148">next</a><span>|</span><label class="collapse" for="c-41524982">[-]</label><label class="expand" for="c-41524982">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s interesting that it makes that mistake, but then catches it a few lines later.<p>A common complaint about LLMs is that once they make a mistake, they will <i>keep making it</i> and write the rest of their completion under the assumption that everything before was correct. Even if they&#x27;ve been RLHF to take human feedback into account and the human points out the mistake, their answer is &quot;Certainly! Here&#x27;s the corrected version&quot; and then they write something that makes the same mistake.<p>So it&#x27;s interesting that this model does something that <i>appears</i> to be self-correction.</div><br/></div></div><div id="41524878" class="c"><input type="checkbox" id="c-41524878" checked=""/><div class="controls bullet"><span class="by">dymk</span><span>|</span><a href="#41523356">root</a><span>|</span><a href="#41523582">parent</a><span>|</span><a href="#41524148">prev</a><span>|</span><a href="#41524173">next</a><span>|</span><label class="collapse" for="c-41524878">[-]</label><label class="expand" for="c-41524878">[1 more]</label></div><br/><div class="children"><div class="content">The next line is it catching its own mistake, and noting i = 9.</div><br/></div></div></div></div><div id="41524173" class="c"><input type="checkbox" id="c-41524173" checked=""/><div class="controls bullet"><span class="by">cowsaymoo</span><span>|</span><a href="#41523356">parent</a><span>|</span><a href="#41523582">prev</a><span>|</span><a href="#41523711">next</a><span>|</span><label class="collapse" for="c-41524173">[-]</label><label class="expand" for="c-41524173">[1 more]</label></div><br/><div class="children"><div class="content">&gt; THERE ARE THREE R&#x27;S IN STRAWBERRY<p>hilarious</div><br/></div></div><div id="41523711" class="c"><input type="checkbox" id="c-41523711" checked=""/><div class="controls bullet"><span class="by">impossiblefork</span><span>|</span><a href="#41523356">parent</a><span>|</span><a href="#41524173">prev</a><span>|</span><a href="#41523752">next</a><span>|</span><label class="collapse" for="c-41523711">[-]</label><label class="expand" for="c-41523711">[1 more]</label></div><br/><div class="children"><div class="content">Even though there&#x27;s of course no guarantee of people getting these chain of thought traces, or whatever one is to call them, I can imagine these being very useful for people learning competitive mathematics, because it must in fact give the full reasoning, and transformers in themselves aren&#x27;t really that smart, usually, so it&#x27;s probably feasible for a person with very normal intellectual abilities to reproduce these traces with practice.</div><br/></div></div><div id="41523752" class="c"><input type="checkbox" id="c-41523752" checked=""/><div class="controls bullet"><span class="by">Salgat</span><span>|</span><a href="#41523356">parent</a><span>|</span><a href="#41523711">prev</a><span>|</span><a href="#41525733">next</a><span>|</span><label class="collapse" for="c-41523752">[-]</label><label class="expand" for="c-41523752">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s interesting how it basically generates a larger sample size to create a regression against. The larger the input, the larger the surface area it can compare against existing training data (implicitly through regression of course).</div><br/></div></div><div id="41525733" class="c"><input type="checkbox" id="c-41525733" checked=""/><div class="controls bullet"><span class="by">davesque</span><span>|</span><a href="#41523356">parent</a><span>|</span><a href="#41523752">prev</a><span>|</span><a href="#41525673">next</a><span>|</span><label class="collapse" for="c-41525733">[-]</label><label class="expand" for="c-41525733">[1 more]</label></div><br/><div class="children"><div class="content">Yes and apparently we won&#x27;t have access to that chain of thought in the release version:<p>&quot;after weighing multiple factors including user experience, competitive advantage, and the option to pursue the chain of thought monitoring, we have decided not to show the raw chains of thought to users&quot;</div><br/></div></div><div id="41525673" class="c"><input type="checkbox" id="c-41525673" checked=""/><div class="controls bullet"><span class="by">evilfred</span><span>|</span><a href="#41523356">parent</a><span>|</span><a href="#41525733">prev</a><span>|</span><a href="#41529346">next</a><span>|</span><label class="collapse" for="c-41525673">[-]</label><label class="expand" for="c-41525673">[1 more]</label></div><br/><div class="children"><div class="content">which makes it even funnier when the Chain is just... wrong <a href="https:&#x2F;&#x2F;x.com&#x2F;colin_fraser&#x2F;status&#x2F;1834336440819614036" rel="nofollow">https:&#x2F;&#x2F;x.com&#x2F;colin_fraser&#x2F;status&#x2F;1834336440819614036</a></div><br/></div></div></div></div><div id="41529346" class="c"><input type="checkbox" id="c-41529346" checked=""/><div class="controls bullet"><span class="by">harisec</span><span>|</span><a href="#41523356">prev</a><span>|</span><a href="#41524263">next</a><span>|</span><label class="collapse" for="c-41529346">[-]</label><label class="expand" for="c-41529346">[1 more]</label></div><br/><div class="children"><div class="content">I asked a few “hard” questions and compared o1 with claude. <a href="https:&#x2F;&#x2F;github.com&#x2F;harisec&#x2F;o1-vs-claude">https:&#x2F;&#x2F;github.com&#x2F;harisec&#x2F;o1-vs-claude</a></div><br/></div></div><div id="41524263" class="c"><input type="checkbox" id="c-41524263" checked=""/><div class="controls bullet"><span class="by">bartman</span><span>|</span><a href="#41529346">prev</a><span>|</span><a href="#41523718">next</a><span>|</span><label class="collapse" for="c-41524263">[-]</label><label class="expand" for="c-41524263">[190 more]</label></div><br/><div class="children"><div class="content">This is incredible. In April I used the standard GPT-4 model via ChatGPT to help me reverse engineer the binary bluetooth protocol used by my kitchen fan to integrate it into Home Assistant.<p>It was helpful in a rubber duck way, but could not determine the pattern used to transmit the remaining runtime of the fan in a certain mode. Initial prompt here [0]<p>I pasted the same prompt into o1-preview and o1-mini and both correctly understood and decoded the pattern using a slightly different method than I devised in April. Asking the models to determine if my code is equivalent to what they reverse engineered resulted in a nuanced and thorough examination, and eventual conclusion that it is equivalent. [1]<p>Testing the same prompt with gpt4o leads to the same result as April&#x27;s GPT-4 (via ChatGPT) model.<p>Amazing progress.<p>[0]: <a href="https:&#x2F;&#x2F;pastebin.com&#x2F;XZixQEM6" rel="nofollow">https:&#x2F;&#x2F;pastebin.com&#x2F;XZixQEM6</a><p>[1]: <a href="https:&#x2F;&#x2F;i.postimg.cc&#x2F;VN1d2vRb&#x2F;SCR-20240912-sdko.png" rel="nofollow">https:&#x2F;&#x2F;i.postimg.cc&#x2F;VN1d2vRb&#x2F;SCR-20240912-sdko.png</a> (sorry about the screenshot – sharing ChatGPT chats is not easy)</div><br/><div id="41525239" class="c"><input type="checkbox" id="c-41525239" checked=""/><div class="controls bullet"><span class="by">guiambros</span><span>|</span><a href="#41524263">parent</a><span>|</span><a href="#41524329">next</a><span>|</span><label class="collapse" for="c-41525239">[-]</label><label class="expand" for="c-41525239">[1 more]</label></div><br/><div class="children"><div class="content">FYI, there&#x27;s a &quot;Save ChatGPT as PDF&quot; Chrome extension [1].<p>I wouldn&#x27;t use on a ChatGPT for Business subscription (it may be against your company&#x27;s policies to export anything), but very convenient for personal use.<p><a href="https:&#x2F;&#x2F;chromewebstore.google.com&#x2F;detail&#x2F;save-chatgpt-as-pdf&#x2F;ccjfggejcoobknjolglgmfhoeneafhhm" rel="nofollow">https:&#x2F;&#x2F;chromewebstore.google.com&#x2F;detail&#x2F;save-chatgpt-as-pdf...</a></div><br/></div></div><div id="41524329" class="c"><input type="checkbox" id="c-41524329" checked=""/><div class="controls bullet"><span class="by">losvedir</span><span>|</span><a href="#41524263">parent</a><span>|</span><a href="#41525239">prev</a><span>|</span><a href="#41524585">next</a><span>|</span><label class="collapse" for="c-41524329">[-]</label><label class="expand" for="c-41524329">[22 more]</label></div><br/><div class="children"><div class="content">Wow, that is impressive! How were you able to use o1-preview? I pay for ChatGPT, but on chatgpt.com in the model selector I only see 4o, 4o-mini, and 4. Is o1 in that list for you, or is it somewhere else?</div><br/><div id="41524483" class="c"><input type="checkbox" id="c-41524483" checked=""/><div class="controls bullet"><span class="by">bartman</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524329">parent</a><span>|</span><a href="#41524491">next</a><span>|</span><label class="collapse" for="c-41524483">[-]</label><label class="expand" for="c-41524483">[6 more]</label></div><br/><div class="children"><div class="content">Like others here, it was just available on the website and app when I checked. FWIW I still don’t have advanced voice mode.</div><br/><div id="41526012" class="c"><input type="checkbox" id="c-41526012" checked=""/><div class="controls bullet"><span class="by">sroussey</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524483">parent</a><span>|</span><a href="#41524491">next</a><span>|</span><label class="collapse" for="c-41526012">[-]</label><label class="expand" for="c-41526012">[5 more]</label></div><br/><div class="children"><div class="content">I don’t have either the new model nor the advanced voice mode as a paying user.</div><br/><div id="41526176" class="c"><input type="checkbox" id="c-41526176" checked=""/><div class="controls bullet"><span class="by">michelsedgh</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41526012">parent</a><span>|</span><a href="#41524491">next</a><span>|</span><label class="collapse" for="c-41526176">[-]</label><label class="expand" for="c-41526176">[4 more]</label></div><br/><div class="children"><div class="content">u do just use this link: <a href="https:&#x2F;&#x2F;chatgpt.com&#x2F;?model=o1-preview" rel="nofollow">https:&#x2F;&#x2F;chatgpt.com&#x2F;?model=o1-preview</a></div><br/><div id="41526744" class="c"><input type="checkbox" id="c-41526744" checked=""/><div class="controls bullet"><span class="by">sroussey</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41526176">parent</a><span>|</span><a href="#41527001">next</a><span>|</span><label class="collapse" for="c-41526744">[-]</label><label class="expand" for="c-41526744">[2 more]</label></div><br/><div class="children"><div class="content">That worked. Now can you do that for advanced voice mode??? Pretty please!</div><br/><div id="41527625" class="c"><input type="checkbox" id="c-41527625" checked=""/><div class="controls bullet"><span class="by">michelsedgh</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41526744">parent</a><span>|</span><a href="#41527001">next</a><span>|</span><label class="collapse" for="c-41527625">[-]</label><label class="expand" for="c-41527625">[1 more]</label></div><br/><div class="children"><div class="content">Haha I wish, although I saw the other one i forgot its name which makes music for you, now you can ask it for a soundtrack and it gives it back to you in your voice or something like that idk interesting times are ahead for sure!</div><br/></div></div></div></div><div id="41527001" class="c"><input type="checkbox" id="c-41527001" checked=""/><div class="controls bullet"><span class="by">johnneville</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41526176">parent</a><span>|</span><a href="#41526744">prev</a><span>|</span><a href="#41524491">next</a><span>|</span><label class="collapse" for="c-41527001">[-]</label><label class="expand" for="c-41527001">[1 more]</label></div><br/><div class="children"><div class="content">they are rolling it out slowly, this link doesn&#x27;t enable access. they only gave me access around 4:30pm PT</div><br/></div></div></div></div></div></div></div></div><div id="41524491" class="c"><input type="checkbox" id="c-41524491" checked=""/><div class="controls bullet"><span class="by">rahimnathwani</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524329">parent</a><span>|</span><a href="#41524483">prev</a><span>|</span><a href="#41526166">next</a><span>|</span><label class="collapse" for="c-41524491">[-]</label><label class="expand" for="c-41524491">[1 more]</label></div><br/><div class="children"><div class="content">I think they&#x27;re rolling it out gradually today. I don&#x27;t see it listed (in the browser, Mac app or Android app).</div><br/></div></div><div id="41526166" class="c"><input type="checkbox" id="c-41526166" checked=""/><div class="controls bullet"><span class="by">obmelvin</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524329">parent</a><span>|</span><a href="#41524491">prev</a><span>|</span><a href="#41524393">next</a><span>|</span><label class="collapse" for="c-41526166">[-]</label><label class="expand" for="c-41526166">[1 more]</label></div><br/><div class="children"><div class="content">The linked release mentions trusted users and links to the usage tier limits. Looking at the pricing, o1-preview only appears for tier 5 - requiring 1k+ spend and initial spend 30+ days ago<p>edit: sorry - this is for API :)</div><br/></div></div><div id="41524393" class="c"><input type="checkbox" id="c-41524393" checked=""/><div class="controls bullet"><span class="by">authorfly</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524329">parent</a><span>|</span><a href="#41526166">prev</a><span>|</span><a href="#41524400">next</a><span>|</span><label class="collapse" for="c-41524393">[-]</label><label class="expand" for="c-41524393">[1 more]</label></div><br/><div class="children"><div class="content">Yes, o1-preview is on the list, as is o1-mini for me (Tier 5, early 2021 API user), under &quot;reasoning&quot;.</div><br/></div></div><div id="41524400" class="c"><input type="checkbox" id="c-41524400" checked=""/><div class="controls bullet"><span class="by">m3kw9</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524329">parent</a><span>|</span><a href="#41524393">prev</a><span>|</span><a href="#41524397">next</a><span>|</span><label class="collapse" for="c-41524400">[-]</label><label class="expand" for="c-41524400">[8 more]</label></div><br/><div class="children"><div class="content">Likely phased rollout throughout the day today to prevent spikes</div><br/><div id="41524590" class="c"><input type="checkbox" id="c-41524590" checked=""/><div class="controls bullet"><span class="by">natch</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524400">parent</a><span>|</span><a href="#41524397">next</a><span>|</span><label class="collapse" for="c-41524590">[-]</label><label class="expand" for="c-41524590">[7 more]</label></div><br/><div class="children"><div class="content">“Throughout the day” lol. Advanced voice mode still hasn’t shown up.<p>They seem to care more about influencers than paying supporters.</div><br/><div id="41525291" class="c"><input type="checkbox" id="c-41525291" checked=""/><div class="controls bullet"><span class="by">guiambros</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524590">parent</a><span>|</span><a href="#41525288">next</a><span>|</span><label class="collapse" for="c-41525291">[-]</label><label class="expand" for="c-41525291">[3 more]</label></div><br/><div class="children"><div class="content">Not true; it&#x27;s already available for me, both O1 and O1-mini. It seems they are indeed rolling out gradually (as any company does).</div><br/><div id="41526063" class="c"><input type="checkbox" id="c-41526063" checked=""/><div class="controls bullet"><span class="by">natch</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41525291">parent</a><span>|</span><a href="#41525288">next</a><span>|</span><label class="collapse" for="c-41526063">[-]</label><label class="expand" for="c-41526063">[2 more]</label></div><br/><div class="children"><div class="content">You got advanced voice mode? I did get o1 preview just a while ago.<p>You got o1, or o1 preview?</div><br/><div id="41528119" class="c"><input type="checkbox" id="c-41528119" checked=""/><div class="controls bullet"><span class="by">guiambros</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41526063">parent</a><span>|</span><a href="#41525288">next</a><span>|</span><label class="collapse" for="c-41528119">[-]</label><label class="expand" for="c-41528119">[1 more]</label></div><br/><div class="children"><div class="content">o1-preview and o1-mini. I don&#x27;t think o1 is publicly available yet.<p>And I assume voice mode is like Sora; a nice PR play.</div><br/></div></div></div></div></div></div><div id="41525288" class="c"><input type="checkbox" id="c-41525288" checked=""/><div class="controls bullet"><span class="by">taberiand</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524590">parent</a><span>|</span><a href="#41525291">prev</a><span>|</span><a href="#41525276">next</a><span>|</span><label class="collapse" for="c-41525288">[-]</label><label class="expand" for="c-41525288">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s my understanding paying supporters aren&#x27;t actually paying enough to cover costs, that $20 isn&#x27;t nearly enough - in that context, a gradual roll-out seems fair. Though maybe they could introduce a couple more higher-paid tiers to give people the option to pay for early access</div><br/></div></div><div id="41525276" class="c"><input type="checkbox" id="c-41525276" checked=""/><div class="controls bullet"><span class="by">rovr138</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524590">parent</a><span>|</span><a href="#41525288">prev</a><span>|</span><a href="#41525586">next</a><span>|</span><label class="collapse" for="c-41525276">[-]</label><label class="expand" for="c-41525276">[1 more]</label></div><br/><div class="children"><div class="content">&gt; lol.<p>It&#x27;s there for a lot of people already. I can see it on 3 different accounts. Including org and just regular paid accounts.</div><br/></div></div><div id="41525586" class="c"><input type="checkbox" id="c-41525586" checked=""/><div class="controls bullet"><span class="by">vidarh</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524590">parent</a><span>|</span><a href="#41525276">prev</a><span>|</span><a href="#41524397">next</a><span>|</span><label class="collapse" for="c-41525586">[-]</label><label class="expand" for="c-41525586">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s available for me. Regular paying customer in the UK.</div><br/></div></div></div></div></div></div><div id="41524397" class="c"><input type="checkbox" id="c-41524397" checked=""/><div class="controls bullet"><span class="by">MattHeard</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524329">parent</a><span>|</span><a href="#41524400">prev</a><span>|</span><a href="#41524620">next</a><span>|</span><label class="collapse" for="c-41524397">[-]</label><label class="expand" for="c-41524397">[1 more]</label></div><br/><div class="children"><div class="content">It appeared for me about thirty minutes after I first checked.</div><br/></div></div><div id="41524620" class="c"><input type="checkbox" id="c-41524620" checked=""/><div class="controls bullet"><span class="by">accidbuddy</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524329">parent</a><span>|</span><a href="#41524397">prev</a><span>|</span><a href="#41524443">next</a><span>|</span><label class="collapse" for="c-41524620">[-]</label><label class="expand" for="c-41524620">[1 more]</label></div><br/><div class="children"><div class="content">Available on ChatGPT Plus signature or only using the API?</div><br/></div></div><div id="41524443" class="c"><input type="checkbox" id="c-41524443" checked=""/><div class="controls bullet"><span class="by">hidelooktropic</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524329">parent</a><span>|</span><a href="#41524620">prev</a><span>|</span><a href="#41525671">next</a><span>|</span><label class="collapse" for="c-41524443">[-]</label><label class="expand" for="c-41524443">[1 more]</label></div><br/><div class="children"><div class="content">I see it in the mac and iOS app.</div><br/></div></div><div id="41525671" class="c"><input type="checkbox" id="c-41525671" checked=""/><div class="controls bullet"><span class="by">cft</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524329">parent</a><span>|</span><a href="#41524443">prev</a><span>|</span><a href="#41524585">next</a><span>|</span><label class="collapse" for="c-41525671">[-]</label><label class="expand" for="c-41525671">[1 more]</label></div><br/><div class="children"><div class="content">it&#x27;s in my MacOS app, but not in the browser fir the same account</div><br/></div></div></div></div><div id="41524585" class="c"><input type="checkbox" id="c-41524585" checked=""/><div class="controls bullet"><span class="by">jazzyjackson</span><span>|</span><a href="#41524263">parent</a><span>|</span><a href="#41524329">prev</a><span>|</span><a href="#41525164">next</a><span>|</span><label class="collapse" for="c-41524585">[-]</label><label class="expand" for="c-41524585">[9 more]</label></div><br/><div class="children"><div class="content">Isn&#x27;t there a big &quot;Share&quot; button at the top right of the chatgpt interface? Or are you using another front end?</div><br/><div id="41524642" class="c"><input type="checkbox" id="c-41524642" checked=""/><div class="controls bullet"><span class="by">bartman</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524585">parent</a><span>|</span><a href="#41526020">next</a><span>|</span><label class="collapse" for="c-41524642">[-]</label><label class="expand" for="c-41524642">[1 more]</label></div><br/><div class="children"><div class="content">In ChatGPT for Business it limits sharing among users in my org, without an option for public sharing.</div><br/></div></div><div id="41526020" class="c"><input type="checkbox" id="c-41526020" checked=""/><div class="controls bullet"><span class="by">OutOfHere</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524585">parent</a><span>|</span><a href="#41524642">prev</a><span>|</span><a href="#41524867">next</a><span>|</span><label class="collapse" for="c-41526020">[-]</label><label class="expand" for="c-41526020">[3 more]</label></div><br/><div class="children"><div class="content">Even for regular users, the Share button is not always available or functional. It works sometimes, and other times it disappears. For example, since today, I have no Share button at all for chats.</div><br/><div id="41526210" class="c"><input type="checkbox" id="c-41526210" checked=""/><div class="controls bullet"><span class="by">JieJie</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41526020">parent</a><span>|</span><a href="#41524867">next</a><span>|</span><label class="collapse" for="c-41526210">[-]</label><label class="expand" for="c-41526210">[2 more]</label></div><br/><div class="children"><div class="content">My share chat link moved into the sidebar in the … menu to the right of each chat title (MacOS Safari).</div><br/><div id="41526330" class="c"><input type="checkbox" id="c-41526330" checked=""/><div class="controls bullet"><span class="by">OutOfHere</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41526210">parent</a><span>|</span><a href="#41524867">next</a><span>|</span><label class="collapse" for="c-41526330">[-]</label><label class="expand" for="c-41526330">[1 more]</label></div><br/><div class="children"><div class="content">Ah, I see it there now. Thanks.</div><br/></div></div></div></div></div></div><div id="41524867" class="c"><input type="checkbox" id="c-41524867" checked=""/><div class="controls bullet"><span class="by">fshbbdssbbgdd</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524585">parent</a><span>|</span><a href="#41526020">prev</a><span>|</span><a href="#41525164">next</a><span>|</span><label class="collapse" for="c-41524867">[-]</label><label class="expand" for="c-41524867">[4 more]</label></div><br/><div class="children"><div class="content">I often click on those links and get an error that they are unavailable. I’m not sure if it’s openAI trying to prevent people from sharing evidence of the model behaving badly, or an innocuous explanation like the links are temporary.</div><br/><div id="41525752" class="c"><input type="checkbox" id="c-41525752" checked=""/><div class="controls bullet"><span class="by">arunv</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524867">parent</a><span>|</span><a href="#41526141">next</a><span>|</span><label class="collapse" for="c-41525752">[-]</label><label class="expand" for="c-41525752">[2 more]</label></div><br/><div class="children"><div class="content">They were probably generated using a business account, and the business does not allow public links.</div><br/><div id="41528207" class="c"><input type="checkbox" id="c-41528207" checked=""/><div class="controls bullet"><span class="by">fshbbdssbbgdd</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41525752">parent</a><span>|</span><a href="#41526141">next</a><span>|</span><label class="collapse" for="c-41528207">[-]</label><label class="expand" for="c-41528207">[1 more]</label></div><br/><div class="children"><div class="content">In context, a lot of times it’s clear that the link worked at first (other people who could see it responded) but when I click later, it’s broken.</div><br/></div></div></div></div><div id="41526141" class="c"><input type="checkbox" id="c-41526141" checked=""/><div class="controls bullet"><span class="by">coder543</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524867">parent</a><span>|</span><a href="#41525752">prev</a><span>|</span><a href="#41525164">next</a><span>|</span><label class="collapse" for="c-41526141">[-]</label><label class="expand" for="c-41526141">[1 more]</label></div><br/><div class="children"><div class="content">The link also breaks if the original user deletes the chat that was being linked to, whether on purpose or without realizing it would also break the link.</div><br/></div></div></div></div></div></div><div id="41525164" class="c"><input type="checkbox" id="c-41525164" checked=""/><div class="controls bullet"><span class="by">avodonosov</span><span>|</span><a href="#41524263">parent</a><span>|</span><a href="#41524585">prev</a><span>|</span><a href="#41525845">next</a><span>|</span><label class="collapse" for="c-41525164">[-]</label><label class="expand" for="c-41525164">[11 more]</label></div><br/><div class="children"><div class="content">The screenshot [1] is not readable for me. Chrome, Android. It&#x27;s so blurry that I cant recognize a single character. How do other people read it? The resolution is 84x800.</div><br/><div id="41526132" class="c"><input type="checkbox" id="c-41526132" checked=""/><div class="controls bullet"><span class="by">daemonologist</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41525164">parent</a><span>|</span><a href="#41525230">next</a><span>|</span><label class="collapse" for="c-41526132">[-]</label><label class="expand" for="c-41526132">[2 more]</label></div><br/><div class="children"><div class="content">Direct link to full resolution: <a href="https:&#x2F;&#x2F;i.postimg.cc&#x2F;D74LJb45&#x2F;SCR-20240912-sdko.png" rel="nofollow">https:&#x2F;&#x2F;i.postimg.cc&#x2F;D74LJb45&#x2F;SCR-20240912-sdko.png</a></div><br/><div id="41527360" class="c"><input type="checkbox" id="c-41527360" checked=""/><div class="controls bullet"><span class="by">avodonosov</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41526132">parent</a><span>|</span><a href="#41525230">next</a><span>|</span><label class="collapse" for="c-41527360">[-]</label><label class="expand" for="c-41527360">[1 more]</label></div><br/><div class="children"><div class="content">thank you</div><br/></div></div></div></div><div id="41525230" class="c"><input type="checkbox" id="c-41525230" checked=""/><div class="controls bullet"><span class="by">rovr138</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41525164">parent</a><span>|</span><a href="#41526132">prev</a><span>|</span><a href="#41525695">next</a><span>|</span><label class="collapse" for="c-41525230">[-]</label><label class="expand" for="c-41525230">[4 more]</label></div><br/><div class="children"><div class="content">When I click on the image, it expands to full res, 1713x16392.3</div><br/><div id="41525782" class="c"><input type="checkbox" id="c-41525782" checked=""/><div class="controls bullet"><span class="by">deathanatos</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41525230">parent</a><span>|</span><a href="#41525695">next</a><span>|</span><label class="collapse" for="c-41525782">[-]</label><label class="expand" for="c-41525782">[3 more]</label></div><br/><div class="children"><div class="content">&gt; <i>it expands to full res, 1713x16392.3</i><p>Three tenths of a pixel is an <i>interesting</i> resolution…<p>(The actual res is 1045 × 10000 ; you&#x27;ve multiplied by 1.63923 somehow…?)</div><br/><div id="41525900" class="c"><input type="checkbox" id="c-41525900" checked=""/><div class="controls bullet"><span class="by">rovr138</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41525782">parent</a><span>|</span><a href="#41526256">next</a><span>|</span><label class="collapse" for="c-41525900">[-]</label><label class="expand" for="c-41525900">[1 more]</label></div><br/><div class="children"><div class="content">I agree,<p>But it’s what I got when I went to Inspect element &gt; hover over the image<p>Size it expanded to vs real image size I guess</div><br/></div></div><div id="41526256" class="c"><input type="checkbox" id="c-41526256" checked=""/><div class="controls bullet"><span class="by">Jerrrrrrry</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41525782">parent</a><span>|</span><a href="#41525900">prev</a><span>|</span><a href="#41525695">next</a><span>|</span><label class="collapse" for="c-41526256">[-]</label><label class="expand" for="c-41526256">[1 more]</label></div><br/><div class="children"><div class="content">Pixels have been &quot;non-real&quot; for a long time.</div><br/></div></div></div></div></div></div><div id="41525695" class="c"><input type="checkbox" id="c-41525695" checked=""/><div class="controls bullet"><span class="by">smusamashah</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41525164">parent</a><span>|</span><a href="#41525230">prev</a><span>|</span><a href="#41525243">next</a><span>|</span><label class="collapse" for="c-41525695">[-]</label><label class="expand" for="c-41525695">[2 more]</label></div><br/><div class="children"><div class="content">When you open on phone, switch to &quot;desktop site&quot; via browser three dots menu</div><br/><div id="41527243" class="c"><input type="checkbox" id="c-41527243" checked=""/><div class="controls bullet"><span class="by">avodonosov</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41525695">parent</a><span>|</span><a href="#41525243">next</a><span>|</span><label class="collapse" for="c-41527243">[-]</label><label class="expand" for="c-41527243">[1 more]</label></div><br/><div class="children"><div class="content">Yes, that works - the page reloads with postimg.cc UI and clicking the image opens full resolution.</div><br/></div></div></div></div><div id="41525243" class="c"><input type="checkbox" id="c-41525243" checked=""/><div class="controls bullet"><span class="by">mikebridgman</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41525164">parent</a><span>|</span><a href="#41525695">prev</a><span>|</span><a href="#41525845">next</a><span>|</span><label class="collapse" for="c-41525243">[-]</label><label class="expand" for="c-41525243">[2 more]</label></div><br/><div class="children"><div class="content">Click on it for full resolution</div><br/><div id="41527233" class="c"><input type="checkbox" id="c-41527233" checked=""/><div class="controls bullet"><span class="by">avodonosov</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41525243">parent</a><span>|</span><a href="#41525845">next</a><span>|</span><label class="collapse" for="c-41527233">[-]</label><label class="expand" for="c-41527233">[1 more]</label></div><br/><div class="children"><div class="content">I didn&#x27;t work until I switched to &quot;Desktop Site&quot; in the browser menu, as a sibling comment suggested. Then the page reloads with various buttons, etc. Until that just the preview image not reacting to clicks.</div><br/></div></div></div></div></div></div><div id="41525845" class="c"><input type="checkbox" id="c-41525845" checked=""/><div class="controls bullet"><span class="by">smusamashah</span><span>|</span><a href="#41524263">parent</a><span>|</span><a href="#41525164">prev</a><span>|</span><a href="#41526433">next</a><span>|</span><label class="collapse" for="c-41525845">[-]</label><label class="expand" for="c-41525845">[2 more]</label></div><br/><div class="children"><div class="content">What if you copy the whole reasoning process example provided by OpenAI, use it as a system prompt (to teach how to reason), use that system prompt in Claude, got4o etc?</div><br/><div id="41525879" class="c"><input type="checkbox" id="c-41525879" checked=""/><div class="controls bullet"><span class="by">azeirah</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41525845">parent</a><span>|</span><a href="#41526433">next</a><span>|</span><label class="collapse" for="c-41525879">[-]</label><label class="expand" for="c-41525879">[1 more]</label></div><br/><div class="children"><div class="content">It might work a little bit. It&#x27;s like doing few shot prompting instead of training it to reason.</div><br/></div></div></div></div><div id="41526433" class="c"><input type="checkbox" id="c-41526433" checked=""/><div class="controls bullet"><span class="by">8thcross</span><span>|</span><a href="#41524263">parent</a><span>|</span><a href="#41525845">prev</a><span>|</span><a href="#41525847">next</a><span>|</span><label class="collapse" for="c-41526433">[-]</label><label class="expand" for="c-41526433">[1 more]</label></div><br/><div class="children"><div class="content">This is a brilliant hypothesis deconstruction. I am sure others will now be able to test as well and this should confirm their engineering.</div><br/></div></div><div id="41525847" class="c"><input type="checkbox" id="c-41525847" checked=""/><div class="controls bullet"><span class="by">fragmede</span><span>|</span><a href="#41524263">parent</a><span>|</span><a href="#41526433">prev</a><span>|</span><a href="#41525652">next</a><span>|</span><label class="collapse" for="c-41525847">[-]</label><label class="expand" for="c-41525847">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m impressed. I had two modified logic puzzles where ChatGPT-4 fails but o1 succeeds. The training data had too many instances of the unmodified puzzle, so 4 wouldn&#x27;t get it right. o1 manages to not get tripped up by them.<p><a href="https:&#x2F;&#x2F;chatgpt.com&#x2F;share&#x2F;66e35c37-60c4-8009-8cf9-8fe61f57d30c" rel="nofollow">https:&#x2F;&#x2F;chatgpt.com&#x2F;share&#x2F;66e35c37-60c4-8009-8cf9-8fe61f57d3...</a><p><a href="https:&#x2F;&#x2F;chatgpt.com&#x2F;share&#x2F;66e35f0e-6c98-8009-a128-e9ac677480fd" rel="nofollow">https:&#x2F;&#x2F;chatgpt.com&#x2F;share&#x2F;66e35f0e-6c98-8009-a128-e9ac677480...</a></div><br/></div></div><div id="41525652" class="c"><input type="checkbox" id="c-41525652" checked=""/><div class="controls bullet"><span class="by">andraz</span><span>|</span><a href="#41524263">parent</a><span>|</span><a href="#41525847">prev</a><span>|</span><a href="#41524505">next</a><span>|</span><label class="collapse" for="c-41525652">[-]</label><label class="expand" for="c-41525652">[2 more]</label></div><br/><div class="children"><div class="content">What is the brand of the fan?
Same problem here with proprietary hood fan...</div><br/><div id="41525810" class="c"><input type="checkbox" id="c-41525810" checked=""/><div class="controls bullet"><span class="by">bartman</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41525652">parent</a><span>|</span><a href="#41524505">next</a><span>|</span><label class="collapse" for="c-41525810">[-]</label><label class="expand" for="c-41525810">[1 more]</label></div><br/><div class="children"><div class="content">InVENTer Pulsar</div><br/></div></div></div></div><div id="41524505" class="c"><input type="checkbox" id="c-41524505" checked=""/><div class="controls bullet"><span class="by">romeros</span><span>|</span><a href="#41524263">parent</a><span>|</span><a href="#41525652">prev</a><span>|</span><a href="#41524610">next</a><span>|</span><label class="collapse" for="c-41524505">[-]</label><label class="expand" for="c-41524505">[4 more]</label></div><br/><div class="children"><div class="content">is it better than Claude?</div><br/><div id="41524658" class="c"><input type="checkbox" id="c-41524658" checked=""/><div class="controls bullet"><span class="by">bartman</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524505">parent</a><span>|</span><a href="#41524739">next</a><span>|</span><label class="collapse" for="c-41524658">[-]</label><label class="expand" for="c-41524658">[1 more]</label></div><br/><div class="children"><div class="content">Neither Sonnet nor Opus could solve it or get close in a minimal test I did just now, using the same prompt as above.<p>Sonnet: <a href="https:&#x2F;&#x2F;pastebin.com&#x2F;24QG3JkN" rel="nofollow">https:&#x2F;&#x2F;pastebin.com&#x2F;24QG3JkN</a><p>Opus: <a href="https:&#x2F;&#x2F;pastebin.com&#x2F;PJM99pdy" rel="nofollow">https:&#x2F;&#x2F;pastebin.com&#x2F;PJM99pdy</a></div><br/></div></div><div id="41524739" class="c"><input type="checkbox" id="c-41524739" checked=""/><div class="controls bullet"><span class="by">hmottestad</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524505">parent</a><span>|</span><a href="#41524658">prev</a><span>|</span><a href="#41526969">next</a><span>|</span><label class="collapse" for="c-41524739">[-]</label><label class="expand" for="c-41524739">[1 more]</label></div><br/><div class="children"><div class="content">I think this new model is a generational leap above Claude for tasks that require complex reasoning.</div><br/></div></div><div id="41526969" class="c"><input type="checkbox" id="c-41526969" checked=""/><div class="controls bullet"><span class="by">natch</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524505">parent</a><span>|</span><a href="#41524739">prev</a><span>|</span><a href="#41524610">next</a><span>|</span><label class="collapse" for="c-41526969">[-]</label><label class="expand" for="c-41526969">[1 more]</label></div><br/><div class="children"><div class="content">Way worse than Claude for solving a cipher. Not even 1&#x2F;10th as good. Just one data point, ymmv.</div><br/></div></div></div></div><div id="41524610" class="c"><input type="checkbox" id="c-41524610" checked=""/><div class="controls bullet"><span class="by">baal80spam</span><span>|</span><a href="#41524263">parent</a><span>|</span><a href="#41524505">prev</a><span>|</span><a href="#41524869">next</a><span>|</span><label class="collapse" for="c-41524610">[-]</label><label class="expand" for="c-41524610">[1 more]</label></div><br/><div class="children"><div class="content">Thanks for sharing this, incredible stuff.</div><br/></div></div><div id="41524869" class="c"><input type="checkbox" id="c-41524869" checked=""/><div class="controls bullet"><span class="by">soheil</span><span>|</span><a href="#41524263">parent</a><span>|</span><a href="#41524610">prev</a><span>|</span><a href="#41524802">next</a><span>|</span><label class="collapse" for="c-41524869">[-]</label><label class="expand" for="c-41524869">[1 more]</label></div><br/><div class="children"><div class="content">Great progress, I asked GPT-4o and o1-preview to create a python script to make $100 quickly, o1 came up with a very interesting result:<p><a href="https:&#x2F;&#x2F;x.com&#x2F;soheil&#x2F;status&#x2F;1834320893331587353" rel="nofollow">https:&#x2F;&#x2F;x.com&#x2F;soheil&#x2F;status&#x2F;1834320893331587353</a></div><br/></div></div><div id="41524802" class="c"><input type="checkbox" id="c-41524802" checked=""/><div class="controls bullet"><span class="by">fwip</span><span>|</span><a href="#41524263">parent</a><span>|</span><a href="#41524869">prev</a><span>|</span><a href="#41524645">next</a><span>|</span><label class="collapse" for="c-41524802">[-]</label><label class="expand" for="c-41524802">[4 more]</label></div><br/><div class="children"><div class="content">What&#x27;s the incredible part here? Being able to write code to turn hex into decimal?</div><br/><div id="41525806" class="c"><input type="checkbox" id="c-41525806" checked=""/><div class="controls bullet"><span class="by">fwip</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524802">parent</a><span>|</span><a href="#41524645">next</a><span>|</span><label class="collapse" for="c-41525806">[-]</label><label class="expand" for="c-41525806">[3 more]</label></div><br/><div class="children"><div class="content">Also, if you actually read the &quot;chain of thought&quot; contains several embarrassing contradictions and incoherent sentences. If a junior developer wrote this analysis, I&#x27;d send them back to reread the fundamentals.</div><br/><div id="41525885" class="c"><input type="checkbox" id="c-41525885" checked=""/><div class="controls bullet"><span class="by">CooCooCaCha</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41525806">parent</a><span>|</span><a href="#41524645">next</a><span>|</span><label class="collapse" for="c-41525885">[-]</label><label class="expand" for="c-41525885">[2 more]</label></div><br/><div class="children"><div class="content">What about thoughts themselves? There are plenty of times I start a thought and realize it doesn&#x27;t make sense. It&#x27;s part of the thinking process.</div><br/><div id="41527500" class="c"><input type="checkbox" id="c-41527500" checked=""/><div class="controls bullet"><span class="by">fwip</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41525885">parent</a><span>|</span><a href="#41524645">next</a><span>|</span><label class="collapse" for="c-41527500">[-]</label><label class="expand" for="c-41527500">[1 more]</label></div><br/><div class="children"><div class="content">Well, it doesn&#x27;t &quot;correct&quot; itself later. It just says wrong things and gets the right answer anyways, because this encoding is so simple that many college freshmen could figure it out in their heads.<p>Read the transcript with a critical eye instead of just skimming it, you&#x27;ll see what I mean.</div><br/></div></div></div></div></div></div></div></div><div id="41524645" class="c"><input type="checkbox" id="c-41524645" checked=""/><div class="controls bullet"><span class="by">GaggiX</span><span>|</span><a href="#41524263">parent</a><span>|</span><a href="#41524802">prev</a><span>|</span><a href="#41524512">next</a><span>|</span><label class="collapse" for="c-41524645">[-]</label><label class="expand" for="c-41524645">[3 more]</label></div><br/><div class="children"><div class="content">Did you edit the message? I cannot see anything now in the screenshot, too low resolution</div><br/><div id="41524678" class="c"><input type="checkbox" id="c-41524678" checked=""/><div class="controls bullet"><span class="by">bartman</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524645">parent</a><span>|</span><a href="#41524512">next</a><span>|</span><label class="collapse" for="c-41524678">[-]</label><label class="expand" for="c-41524678">[2 more]</label></div><br/><div class="children"><div class="content">You need to click on the image for the high res version to load. Sorry, it’s awkward.</div><br/><div id="41524897" class="c"><input type="checkbox" id="c-41524897" checked=""/><div class="controls bullet"><span class="by">GaggiX</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524678">parent</a><span>|</span><a href="#41524512">next</a><span>|</span><label class="collapse" for="c-41524897">[-]</label><label class="expand" for="c-41524897">[1 more]</label></div><br/><div class="children"><div class="content">The website seems to redirect me to a low resolution image, the first time I clicked on the link it worked as you are saying.</div><br/></div></div></div></div></div></div><div id="41524512" class="c"><input type="checkbox" id="c-41524512" checked=""/><div class="controls bullet"><span class="by">antman</span><span>|</span><a href="#41524263">parent</a><span>|</span><a href="#41524645">prev</a><span>|</span><a href="#41524419">next</a><span>|</span><label class="collapse" for="c-41524512">[-]</label><label class="expand" for="c-41524512">[3 more]</label></div><br/><div class="children"><div class="content">second is very blurry</div><br/><div id="41524602" class="c"><input type="checkbox" id="c-41524602" checked=""/><div class="controls bullet"><span class="by">bartman</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524512">parent</a><span>|</span><a href="#41527375">next</a><span>|</span><label class="collapse" for="c-41524602">[-]</label><label class="expand" for="c-41524602">[1 more]</label></div><br/><div class="children"><div class="content">When you click on the image it loads a higher res version.</div><br/></div></div><div id="41527375" class="c"><input type="checkbox" id="c-41527375" checked=""/><div class="controls bullet"><span class="by">avodonosov</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524512">parent</a><span>|</span><a href="#41524602">prev</a><span>|</span><a href="#41524419">next</a><span>|</span><label class="collapse" for="c-41527375">[-]</label><label class="expand" for="c-41527375">[1 more]</label></div><br/><div class="children"><div class="content">Solved here: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=41525164">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=41525164</a></div><br/></div></div></div></div><div id="41524419" class="c"><input type="checkbox" id="c-41524419" checked=""/><div class="controls bullet"><span class="by">cs391231</span><span>|</span><a href="#41524263">parent</a><span>|</span><a href="#41524512">prev</a><span>|</span><a href="#41526488">next</a><span>|</span><label class="collapse" for="c-41524419">[-]</label><label class="expand" for="c-41524419">[118 more]</label></div><br/><div class="children"><div class="content">Student here. Can someone give me one reason why I should continue in software engineering that isn&#x27;t denial and hopium?</div><br/><div id="41524660" class="c"><input type="checkbox" id="c-41524660" checked=""/><div class="controls bullet"><span class="by">al_borland</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524419">parent</a><span>|</span><a href="#41524889">next</a><span>|</span><label class="collapse" for="c-41524660">[-]</label><label class="expand" for="c-41524660">[29 more]</label></div><br/><div class="children"><div class="content">The calculator didn’t eliminate math majors. Excel and accounting software didn’t eliminate accountants and CPAs. These are all just tools.<p>I spend very little of my overall time at work actually coding. It’s a nice treat when I get a day where that’s all I do.<p>From my limited work with Copilot so far, the user still needs to know what they’re doing. I have 0 faith a product owner, without a coding background, can use AI to release new products and updates while firing their whole dev team.<p>When I say most of my time isn’t spent coding, a lot of that time is spend trying to figure out what people want me to build. They don’t know. They might have a general idea, but don’t know details and can’t articulate any of it. If they can’t tell me, I’m not sure how they will tell an LLM. I ended up building what I assume they want, then we go from there. I also add a lot of stuff that they don’t think about or care about, but will be needed later so we can actually support it.<p>If you were to go in another direction, what would it be where AI wouldn’t be a threat? The first thing that comes to my mind is switching to a trade school and learning some skills that would be difficult for robots.</div><br/><div id="41524783" class="c"><input type="checkbox" id="c-41524783" checked=""/><div class="controls bullet"><span class="by">vasco</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524660">parent</a><span>|</span><a href="#41524900">next</a><span>|</span><label class="collapse" for="c-41524783">[-]</label><label class="expand" for="c-41524783">[6 more]</label></div><br/><div class="children"><div class="content">Accounting mechanization is a good example of how unpredictable it can be. Initially there were armies of &quot;accountants&quot; (what we now call bookkeepers), mostly doing basic tasks of collecting data and making it fit something useful.<p>When mechanization appeared, the profession split into bookkeeping and accounting. Bookkeeping became a job for women as it was more boring and could be paid lower salaries (we&#x27;re in the 1800s here). Accountants became more sophisticated but lower numbers as a %. Together, both professions grew like crazy in total number though.<p>So if the same happens you could predict a split between software engineers and prompt engineers. With an explosion in prompt engineers paid much less than software engineers.<p>&gt; the number of accountants&#x2F;book-
keepers in the U.S. increased from circa 54,000 workers [U.S. 
Census Office, 1872, p. 706] to more than 900,000 [U.S. Bureau 
of the Census, 1933, Tables 3, 49].<p>&gt; These studies [e.g., Coyle, 1929; 
Baker, 1964; Rotella, 1981; Davies, 1982; Lowe, 1987; DeVault, 
1990; Fine, 1990; Strom, 1992; Kwolek-Folland, 1994; Wootton 
and Kemmerer, 1996] have traced the transformation of the of-
fice workforce (typists, secretaries, stenographers, bookkeepers) 
from predominately a male occupation to one primarily staffed 
by women, who were paid substantially lower wages than the 
men they replaced.<p>&gt; Emergence of mechanical accounting in the U.S., 1880-1930 [PDF download] <a href="https:&#x2F;&#x2F;www.google.com&#x2F;url?sa=t&amp;source=web&amp;rct=j&amp;opi=89978449&amp;url=https:&#x2F;&#x2F;egrove.olemiss.edu&#x2F;cgi&#x2F;viewcontent.cgi%3Farticle%3D1718%26context%3Daah_journal&amp;ved=2ahUKEwj6qZ_llL6IAxVvRaQEHWJKHMUQFnoECCQQAQ&amp;usg=AOvVaw3EfY2ycQTKgedBRz5N60mb" rel="nofollow">https:&#x2F;&#x2F;www.google.com&#x2F;url?sa=t&amp;source=web&amp;rct=j&amp;opi=8997844...</a></div><br/><div id="41526832" class="c"><input type="checkbox" id="c-41526832" checked=""/><div class="controls bullet"><span class="by">gdhkgdhkvff</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524783">parent</a><span>|</span><a href="#41526514">next</a><span>|</span><label class="collapse" for="c-41526832">[-]</label><label class="expand" for="c-41526832">[1 more]</label></div><br/><div class="children"><div class="content">Interesting. Another take on that split could be engineers split to upper class AI engineers and lower class AI prompt developers, aka ai builders vs ai appliers.<p>Alternatively, I’ve thought a bit about this previously and have a slight different hypothesis. Businesses are ran by “PM types”.the only reason that developers have jobs is because pm types need technical devs to build their vision. (Obviously I’m making broad strokes here as there are also plenty of founders that ARE the dev). Now, if ai makes technical building more open to the masses, I could foresee a scenario where devs and pms actually converge into a single job title that eats up the technical-leaning PMs and the “PM-y” devs. Devs will shift to be more PM-y or else be cut out of the job market because there is less need for non-ambitious code monkeys. The easier it becomes for the masses to build because of AI, the less opportunity there is for technical grunt work. If before it took a PM 30 minutes to get together the requirements for a small task that took the entry level dev 8 hours to do, then it made sense. Now if AI makes it so a technical PM could build the feature in an hour, maybe it just makes sense to have the PM do the implementation and cut out the code monkey. And if the PM is doing the implementation, even if using some mythical AI superpower, that’s still going to have companies selecting for more technical PM’s. In this scenario I think non-technical PMs and non-pm-y devs would find themselves either without jobs or at greatly reduced wages.</div><br/></div></div><div id="41526514" class="c"><input type="checkbox" id="c-41526514" checked=""/><div class="controls bullet"><span class="by">theendisney4</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524783">parent</a><span>|</span><a href="#41526832">prev</a><span>|</span><a href="#41524966">next</a><span>|</span><label class="collapse" for="c-41526514">[-]</label><label class="expand" for="c-41526514">[1 more]</label></div><br/><div class="children"><div class="content">If programming requires lots of talking, dialog and patiently explaining things woman might be dramatically better at it.</div><br/></div></div><div id="41524966" class="c"><input type="checkbox" id="c-41524966" checked=""/><div class="controls bullet"><span class="by">zmgsabst</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524783">parent</a><span>|</span><a href="#41526514">prev</a><span>|</span><a href="#41524900">next</a><span>|</span><label class="collapse" for="c-41524966">[-]</label><label class="expand" for="c-41524966">[3 more]</label></div><br/><div class="children"><div class="content">We’re already seeing that split, between “developer” and “engineer”. We have been for years.<p>But that’s normal, eg, we have different standards for a shed (yourself), house (carpenter and architect), and skyscraper (bonded firms and certified engineers).</div><br/><div id="41525680" class="c"><input type="checkbox" id="c-41525680" checked=""/><div class="controls bullet"><span class="by">Atotalnoob</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524966">parent</a><span>|</span><a href="#41524900">next</a><span>|</span><label class="collapse" for="c-41525680">[-]</label><label class="expand" for="c-41525680">[2 more]</label></div><br/><div class="children"><div class="content">Not really, I’ve worked at places that only had one or the other of the titles for all programming jobs</div><br/><div id="41527521" class="c"><input type="checkbox" id="c-41527521" checked=""/><div class="controls bullet"><span class="by">al_borland</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41525680">parent</a><span>|</span><a href="#41524900">next</a><span>|</span><label class="collapse" for="c-41527521">[-]</label><label class="expand" for="c-41527521">[1 more]</label></div><br/><div class="children"><div class="content">I think it depends on the size of the company. The larger the larger the company, the more likely they are to split this stuff out. Though various titles may seem to bleed together. I have a software engineer title, while another guy on my team is a software architect… we effectively do the same job. Stepping back from a higher level view, as a general theme, those with an architect title are more likely to be responsible for an overall design, while the engineers may have some input and build things to support the design.<p>The quality of said designs can vary wildly. Some designs I get from other team I completely ignore, because they have no idea what they’re talking about. Just because someone has the title doesn’t mean they deserve it.</div><br/></div></div></div></div></div></div></div></div><div id="41524900" class="c"><input type="checkbox" id="c-41524900" checked=""/><div class="controls bullet"><span class="by">RobinL</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524660">parent</a><span>|</span><a href="#41524783">prev</a><span>|</span><a href="#41524749">next</a><span>|</span><label class="collapse" for="c-41524900">[-]</label><label class="expand" for="c-41524900">[6 more]</label></div><br/><div class="children"><div class="content">Agreed.  The sweet spot is people who have product owner skills _and_ can code.  They are quickly developing superpowers.  The overhead of writing tickets, communicating with the team and so on is huge.  If one person can do it all, efficiency skyrockets.<p>I guess it&#x27;s always been true to some extent that single individuals are capable of amazing things. For example, the guy who&#x27;s built <a href="https:&#x2F;&#x2F;www.photopea.com&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.photopea.com&#x2F;</a>. But they must be exceptional - this empowers more people to do things like that.</div><br/><div id="41525000" class="c"><input type="checkbox" id="c-41525000" checked=""/><div class="controls bullet"><span class="by">fakedang</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524900">parent</a><span>|</span><a href="#41524749">next</a><span>|</span><label class="collapse" for="c-41525000">[-]</label><label class="expand" for="c-41525000">[5 more]</label></div><br/><div class="children"><div class="content">Or people who can be product owners and can prompt LLMs to code (because I know him, that&#x27;s me!).<p>I&#x27;m awestruck by how good Claude and Cursor are. I&#x27;ve been building a semi-heavy-duty tech product, and I&#x27;m amazed by how much progress I&#x27;ve made in a week, using a NextJS stack, without knowing a lick of React in the first place (I know the concepts, but not the JS&#x2F;NextJS vocab). All the code has been delivered with proper separation of concerns, clean architecture and modularization. Any time I get an error, I can reason with it to find the issue together. And if Claude is stuck (or I&#x27;m past my 5x usage lol), I just pair programme with ChatGPT instead.<p>Meanwhile Google just continues to serve me outdated shit from preCovid.</div><br/><div id="41526530" class="c"><input type="checkbox" id="c-41526530" checked=""/><div class="controls bullet"><span class="by">valval</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41525000">parent</a><span>|</span><a href="#41526120">next</a><span>|</span><label class="collapse" for="c-41526530">[-]</label><label class="expand" for="c-41526530">[2 more]</label></div><br/><div class="children"><div class="content">I’m afraid these tools are really good at getting beginners 90% of the way there, but no further.</div><br/><div id="41528073" class="c"><input type="checkbox" id="c-41528073" checked=""/><div class="controls bullet"><span class="by">fakedang</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41526530">parent</a><span>|</span><a href="#41526120">next</a><span>|</span><label class="collapse" for="c-41528073">[-]</label><label class="expand" for="c-41528073">[1 more]</label></div><br/><div class="children"><div class="content">90% of the way is still good enough for me because I can manage to think up and get through the rest of the 10%. The problem for me was that the 90% looked so overwhelming earlier and that would shy me away from pursuing that project at all.</div><br/></div></div></div></div><div id="41526120" class="c"><input type="checkbox" id="c-41526120" checked=""/><div class="controls bullet"><span class="by">hobo_in_library</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41525000">parent</a><span>|</span><a href="#41526530">prev</a><span>|</span><a href="#41524749">next</a><span>|</span><label class="collapse" for="c-41526120">[-]</label><label class="expand" for="c-41526120">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m curious, with Cursor, why do you still need to use Claude?</div><br/><div id="41528070" class="c"><input type="checkbox" id="c-41528070" checked=""/><div class="controls bullet"><span class="by">fakedang</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41526120">parent</a><span>|</span><a href="#41524749">next</a><span>|</span><label class="collapse" for="c-41528070">[-]</label><label class="expand" for="c-41528070">[1 more]</label></div><br/><div class="children"><div class="content">I just started using Cursor a few days back, so still need to get a hold of all the keyboard shortcuts properly.</div><br/></div></div></div></div></div></div></div></div><div id="41524749" class="c"><input type="checkbox" id="c-41524749" checked=""/><div class="controls bullet"><span class="by">ponector</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524660">parent</a><span>|</span><a href="#41524900">prev</a><span>|</span><a href="#41526263">next</a><span>|</span><label class="collapse" for="c-41524749">[-]</label><label class="expand" for="c-41524749">[11 more]</label></div><br/><div class="children"><div class="content">But excel eliminated need in multiple accountants. One accountant with excel replaced ten with paper.<p>Chatgpt already eliminated many entry-level jobs like writer or illustrator. Instead of hiring multiple teams of developers, there will be one team with few seniors and multiple AI coding tools.<p>Guess how depressing to the IT salaries it will be?</div><br/><div id="41525246" class="c"><input type="checkbox" id="c-41525246" checked=""/><div class="controls bullet"><span class="by">hibikir</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524749">parent</a><span>|</span><a href="#41524920">next</a><span>|</span><label class="collapse" for="c-41525246">[-]</label><label class="expand" for="c-41525246">[1 more]</label></div><br/><div class="children"><div class="content">A whole lot of automation is limited not by what could be automated, but what one can automate within a given budget.<p>When I was coding in the 90s, I was in a team that replaced function calls into new and exciting interactions with other computers which, using a queuing system, would do the computation and return the answer back. We&#x27;d have a project of having someone serialize the C data structures that were used on both sides into something that would be compatible, and could be inspected in the middle.<p>Today we call all of that a web service, the serialization would take a minute to code, and be doable by anyone. My entire team would be out of work! And yet, today we have more people writing code than ever.<p>When one accountant can do the work of 10 accountants, the price of the task lowers, but a lot of people that before couldn&#x27;t afford accounting now can. And the same 10 accountaings from before can just do more work, and get paid about the same.<p>As far as software, we are getting paid A LOT more than in the early 90s. We are just doing things that back then would be impossible to pay for, our just outright impossible to do due to lack of compute capacity.</div><br/></div></div><div id="41524920" class="c"><input type="checkbox" id="c-41524920" checked=""/><div class="controls bullet"><span class="by">mikeyouse</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524749">parent</a><span>|</span><a href="#41525246">prev</a><span>|</span><a href="#41524972">next</a><span>|</span><label class="collapse" for="c-41524920">[-]</label><label class="expand" for="c-41524920">[2 more]</label></div><br/><div class="children"><div class="content">I don’t don’t doubt that it might depress salaries but that excel example is a good one in that suddenly every company could start to do basic financial analysis in a manner that only the largest ones could previously afford.</div><br/><div id="41525377" class="c"><input type="checkbox" id="c-41525377" checked=""/><div class="controls bullet"><span class="by">sdeframond</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524920">parent</a><span>|</span><a href="#41524972">next</a><span>|</span><label class="collapse" for="c-41525377">[-]</label><label class="expand" for="c-41525377">[1 more]</label></div><br/><div class="children"><div class="content">Yet another instance of Jevon&#x27;s paradox ! <a href="https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Jevons_paradox" rel="nofollow">https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Jevons_paradox</a><p>&gt; the Jevons paradox occurs when technological progress increases the efficiency with which a resource is used (reducing the amount necessary for any one use), but the falling cost of use induces increases in demand enough that resource use is increased, rather than reduced.</div><br/></div></div></div></div><div id="41524766" class="c"><input type="checkbox" id="c-41524766" checked=""/><div class="controls bullet"><span class="by">MattGaiser</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524749">parent</a><span>|</span><a href="#41524972">prev</a><span>|</span><a href="#41524837">next</a><span>|</span><label class="collapse" for="c-41524766">[-]</label><label class="expand" for="c-41524766">[4 more]</label></div><br/><div class="children"><div class="content">Accountants still make plenty of money. Expertise in Excel also pays well independently of that.</div><br/><div id="41525232" class="c"><input type="checkbox" id="c-41525232" checked=""/><div class="controls bullet"><span class="by">confused_boner</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524766">parent</a><span>|</span><a href="#41525027">next</a><span>|</span><label class="collapse" for="c-41525232">[-]</label><label class="expand" for="c-41525232">[1 more]</label></div><br/><div class="children"><div class="content">Many are offshoring now, PwC just had a massive layoff announcement yesterday as well</div><br/></div></div><div id="41525027" class="c"><input type="checkbox" id="c-41525027" checked=""/><div class="controls bullet"><span class="by">freefaler</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524766">parent</a><span>|</span><a href="#41525232">prev</a><span>|</span><a href="#41524837">next</a><span>|</span><label class="collapse" for="c-41525027">[-]</label><label class="expand" for="c-41525027">[2 more]</label></div><br/><div class="children"><div class="content">Yeah, but if the number of them has shrunk 100 times even if they make 10 times more money still raises the question is it wise to become one?</div><br/><div id="41525283" class="c"><input type="checkbox" id="c-41525283" checked=""/><div class="controls bullet"><span class="by">Daishiman</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41525027">parent</a><span>|</span><a href="#41524837">next</a><span>|</span><label class="collapse" for="c-41525283">[-]</label><label class="expand" for="c-41525283">[1 more]</label></div><br/><div class="children"><div class="content">The increased work capacity of an accountant means that nowadays even small businesses can do financial analysis that would not have scaled decades ago.</div><br/></div></div></div></div></div></div><div id="41524837" class="c"><input type="checkbox" id="c-41524837" checked=""/><div class="controls bullet"><span class="by">withinboredom</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524749">parent</a><span>|</span><a href="#41524766">prev</a><span>|</span><a href="#41525862">next</a><span>|</span><label class="collapse" for="c-41524837">[-]</label><label class="expand" for="c-41524837">[1 more]</label></div><br/><div class="children"><div class="content">lol, my accountant is pretty darn expensive.</div><br/></div></div></div></div><div id="41526263" class="c"><input type="checkbox" id="c-41526263" checked=""/><div class="controls bullet"><span class="by">digging</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524660">parent</a><span>|</span><a href="#41524749">prev</a><span>|</span><a href="#41525668">next</a><span>|</span><label class="collapse" for="c-41526263">[-]</label><label class="expand" for="c-41526263">[2 more]</label></div><br/><div class="children"><div class="content">&gt; The calculator didn’t eliminate math majors. Excel and accounting software didn’t eliminate accountants and CPAs. These are all just tools.<p>This just feels extremely shortsighted. LLMs are just tools <i>right now</i>, but the goal of the entire industry is to make something more than a tool, an autonomous digital agent. There&#x27;s no equivalent concept in other technology like calculators. It will happen or it will not, but we&#x27;ll keep getting closer every month until we achieve it or hit a technical wall. And you simply <i>cannot</i> know for sure such a wall exists.</div><br/><div id="41527601" class="c"><input type="checkbox" id="c-41527601" checked=""/><div class="controls bullet"><span class="by">al_borland</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41526263">parent</a><span>|</span><a href="#41525668">next</a><span>|</span><label class="collapse" for="c-41527601">[-]</label><label class="expand" for="c-41527601">[1 more]</label></div><br/><div class="children"><div class="content">If we hit that point, it’s then a question of access, cost, learning curve, and vision of individual companies. Some things are technically possible, but done by very few companies.<p>I’ve seen the videos of Amazon warehouses, where the shelves move around to make popular items more accessible for those fetching stuff. This is possible today, but what percentage of companies do this? At what point is it with the investment for a growing company? For some companies it’s never worth it. Others don’t have the vision to see the light at the end of the tunnel.<p>A lot of things that we may think of as old or standard practice at this point would be game changing for some smaller companies outside of tech. I hear my friends and family talking about various things they have to do at their job. A day writing a few scripts could solve a significant amount of toil. But they can’t even conceptualize where to begin to change that, they aren’t even thinking about it. Release all the AI the world has to offer and they still won’t. I bet some freelance devs could make a good living bouncing from company to company pair programming with their AI to solve some pretty basic problems for small non-tech companies that would be game changes for them, while being rather trivial to do. Maybe partner with a sales guy to find the companies and sell them on the benefits.</div><br/></div></div></div></div><div id="41525668" class="c"><input type="checkbox" id="c-41525668" checked=""/><div class="controls bullet"><span class="by">CamperBob2</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524660">parent</a><span>|</span><a href="#41526263">prev</a><span>|</span><a href="#41524780">next</a><span>|</span><label class="collapse" for="c-41525668">[-]</label><label class="expand" for="c-41525668">[1 more]</label></div><br/><div class="children"><div class="content"><i>The calculator didn’t eliminate math majors.</i><p>We&#x27;re not dealing with calculators here, are we?</div><br/></div></div><div id="41524780" class="c"><input type="checkbox" id="c-41524780" checked=""/><div class="controls bullet"><span class="by">lopatamd</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524660">parent</a><span>|</span><a href="#41525668">prev</a><span>|</span><a href="#41524889">next</a><span>|</span><label class="collapse" for="c-41524780">[-]</label><label class="expand" for="c-41524780">[2 more]</label></div><br/><div class="children"><div class="content">You can&#x27;t ignore the fact that literally studying coding at this point is so demoralizing and you don&#x27;t need really to study much if you think about it. You only need to be able to read the code to understand if it generated correctly etc but when if you don&#x27;t understand some framework you just ask it to explain it to you etc. Basically gives vibes of a skill not being used anymore that much by us programmers. But will shift in more prompting and verifying and testing</div><br/><div id="41527141" class="c"><input type="checkbox" id="c-41527141" checked=""/><div class="controls bullet"><span class="by">deeznuttynutz</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524780">parent</a><span>|</span><a href="#41524889">next</a><span>|</span><label class="collapse" for="c-41527141">[-]</label><label class="expand" for="c-41527141">[1 more]</label></div><br/><div class="children"><div class="content">I completed the book Programming Principles and Practice using C++ (which I HIGHLY recommend to any beginner interested in software engineering) about year ago with GPT4 as a companion. I read the book throughly and did all the exercises, only asking questions to GPT4 when I was stuck. This took me about 900-1000 hours total. Although I achieved my goal of learning C++ to a basic novice level, I acquired another skill unintentionally: the ability to break down tasks effectively to LLMs and prompt in a fashion that is extremely modular. I&#x27;ve been able to create complex apps and programs in a variety of programming languages even though I really only know C++. It has been an eye-opening experience. Of course it isn&#x27;t perfect, but it is mind blowing and quite disturbing.</div><br/></div></div></div></div></div></div><div id="41524889" class="c"><input type="checkbox" id="c-41524889" checked=""/><div class="controls bullet"><span class="by">UncleOxidant</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524419">parent</a><span>|</span><a href="#41524660">prev</a><span>|</span><a href="#41524828">next</a><span>|</span><label class="collapse" for="c-41524889">[-]</label><label class="expand" for="c-41524889">[5 more]</label></div><br/><div class="children"><div class="content">Semi-retired software&#x2F;hardware engineer here. After my recent experiences with various coding LLMs (similar to the experience of the OP with the bluetooth fan protocol) I&#x27;m really glad I&#x27;m in a financial position such that I&#x27;m able to retire. The progress of these LLMs at coding has been astonishing over the last 18 months. Will they entirely replace humans? No. But as they increase programmer productivity fewer devs will be required. In my case the contract gig I was doing over this last summer I was able to do about 3 to 4X faster than I could&#x27;ve done it without LLMs. Yeah, they were generating a lot of boiler plate HDL code for me, but that still saved me several days of work at least. And then there was the test code that they generated which again saved me days of work. And their ability to explain old undocumented code that was part of the project was also extremely helpful. I was skeptical 18 months ago that any of this would be possible. Not anymore. I wasn&#x27;t doing a project in which there would&#x27;ve been a lot of training examples. We&#x27;re talking Verilog testbench generation based on multiple input Verilog modules, C++ code generation for a C program analyzer using libclang - none of this stuff would&#x27;ve worked just a few months back.</div><br/><div id="41525907" class="c"><input type="checkbox" id="c-41525907" checked=""/><div class="controls bullet"><span class="by">DataDive</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524889">parent</a><span>|</span><a href="#41526537">next</a><span>|</span><label class="collapse" for="c-41525907">[-]</label><label class="expand" for="c-41525907">[2 more]</label></div><br/><div class="children"><div class="content">I will add that I am grateful that I also got to experience a world where AI did not spew tons of code like a sausage-making machine.<p>It was so satisfying to code up a solution where you knew you would get through it little by little.</div><br/><div id="41526315" class="c"><input type="checkbox" id="c-41526315" checked=""/><div class="controls bullet"><span class="by">niemal_dev</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41525907">parent</a><span>|</span><a href="#41526537">next</a><span>|</span><label class="collapse" for="c-41526315">[-]</label><label class="expand" for="c-41526315">[1 more]</label></div><br/><div class="children"><div class="content">This.</div><br/></div></div></div></div><div id="41526537" class="c"><input type="checkbox" id="c-41526537" checked=""/><div class="controls bullet"><span class="by">matwood</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524889">parent</a><span>|</span><a href="#41525907">prev</a><span>|</span><a href="#41525924">next</a><span>|</span><label class="collapse" for="c-41526537">[-]</label><label class="expand" for="c-41526537">[1 more]</label></div><br/><div class="children"><div class="content">&gt; But as they increase programmer productivity fewer devs will be required.<p>Can you point me to any company whose feature pipeline is finite? Maybe these tools will help us reach that point, but every company I&#x27;ve ever worked for, and every person I know who works in tech has a backlog that is effectively infinite at this point.<p>Maybe if only a few companies had access to coding LLMs they could cut their stuff, when the whole industry raises the bar, nothing really changes.</div><br/></div></div><div id="41525924" class="c"><input type="checkbox" id="c-41525924" checked=""/><div class="controls bullet"><span class="by">cs391231</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524889">parent</a><span>|</span><a href="#41526537">prev</a><span>|</span><a href="#41524828">next</a><span>|</span><label class="collapse" for="c-41525924">[-]</label><label class="expand" for="c-41525924">[1 more]</label></div><br/><div class="children"><div class="content">This. I&#x27;m not terrified by total automation (In that case all jobs are going away and civilization is going to radically alter), I&#x27;m scared of selective deskilling and the field getting squeezed tighter and tighter leaving me functionally in a dead end.</div><br/></div></div></div></div><div id="41524828" class="c"><input type="checkbox" id="c-41524828" checked=""/><div class="controls bullet"><span class="by">lumost</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524419">parent</a><span>|</span><a href="#41524889">prev</a><span>|</span><a href="#41525277">next</a><span>|</span><label class="collapse" for="c-41524828">[-]</label><label class="expand" for="c-41524828">[21 more]</label></div><br/><div class="children"><div class="content">LLMs perform well on small tasks that are well defined. This definition matches almost every task that a student will work on in school leading to an overestimation of LLM capabiity.<p>LLMs cannot decide what to work on, or manage large bodies of work&#x2F;code easily. They do not understand the risk of making a change and deploying it to production, or play nicely in autonomous settings. There is going to be a massive amount of work that goes into solving these problems. Followed by a massive amount of work to solve the next set of problems. Software&#x2F;ML engineers will have work to do for as long as these problems remain unsolved.</div><br/><div id="41525055" class="c"><input type="checkbox" id="c-41525055" checked=""/><div class="controls bullet"><span class="by">spaceman_2020</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524828">parent</a><span>|</span><a href="#41524956">next</a><span>|</span><label class="collapse" for="c-41525055">[-]</label><label class="expand" for="c-41525055">[15 more]</label></div><br/><div class="children"><div class="content">Careers are 30 years long<p>Can you confidently say that an LLM won’t be better than an average 22 year old coder within these 30 years?</div><br/><div id="41525158" class="c"><input type="checkbox" id="c-41525158" checked=""/><div class="controls bullet"><span class="by">HappMacDonald</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41525055">parent</a><span>|</span><a href="#41526555">next</a><span>|</span><label class="collapse" for="c-41525158">[-]</label><label class="expand" for="c-41525158">[3 more]</label></div><br/><div class="children"><div class="content">Careers have failed to be 30 years long for a lot longer than 30 years now. That&#x27;s one of the reasons that 4-year colleges have drastically lost their ROI, the other blade of those scissors being the stupendously rising tuition. AI is nothing but one more layer in the constantly growing substrate of computing technology a coder has to learn how to integrate into their toolbelts. Just like the layers that came before it: mobile, virtualization, networking, etc.</div><br/><div id="41525539" class="c"><input type="checkbox" id="c-41525539" checked=""/><div class="controls bullet"><span class="by">snowwrestler</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41525158">parent</a><span>|</span><a href="#41526555">next</a><span>|</span><label class="collapse" for="c-41525539">[-]</label><label class="expand" for="c-41525539">[2 more]</label></div><br/><div class="children"><div class="content">Careers are still longer than 30 years. How many people do you think are retiring at 48 or 51 years old these days? It’s a small minority. Most people work through 65: a career of about 45 years or more.</div><br/><div id="41526515" class="c"><input type="checkbox" id="c-41526515" checked=""/><div class="controls bullet"><span class="by">dmoy</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41525539">parent</a><span>|</span><a href="#41526555">next</a><span>|</span><label class="collapse" for="c-41526515">[-]</label><label class="expand" for="c-41526515">[1 more]</label></div><br/><div class="children"><div class="content">Right but most people don&#x27;t stick a single career anymore.  An individual career is &lt;30 yrs, and the average person will have &gt;1 of them.<p>It&#x27;s not as out there as e.g. this article (<a href="https:&#x2F;&#x2F;www.wsj.com&#x2F;articles&#x2F;SB10001424052748704206804575468162805877990" rel="nofollow">https:&#x2F;&#x2F;www.wsj.com&#x2F;articles&#x2F;SB10001424052748704206804575468...</a>) - 7 careers is probably a crazy overestimate.  But it is &gt;1.</div><br/></div></div></div></div></div></div><div id="41526555" class="c"><input type="checkbox" id="c-41526555" checked=""/><div class="controls bullet"><span class="by">matwood</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41525055">parent</a><span>|</span><a href="#41525158">prev</a><span>|</span><a href="#41525512">next</a><span>|</span><label class="collapse" for="c-41526555">[-]</label><label class="expand" for="c-41526555">[1 more]</label></div><br/><div class="children"><div class="content">22 year old coder today or 22 year old coder 30 years from now? How a 22 year old codes 30 years from now may look like magic to you and me.</div><br/></div></div><div id="41525190" class="c"><input type="checkbox" id="c-41525190" checked=""/><div class="controls bullet"><span class="by">taco_emoji</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41525055">parent</a><span>|</span><a href="#41525512">prev</a><span>|</span><a href="#41525692">next</a><span>|</span><label class="collapse" for="c-41525190">[-]</label><label class="expand" for="c-41525190">[7 more]</label></div><br/><div class="children"><div class="content">yes, because this is still glorified autocomplete</div><br/><div id="41525405" class="c"><input type="checkbox" id="c-41525405" checked=""/><div class="controls bullet"><span class="by">spaceman_2020</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41525190">parent</a><span>|</span><a href="#41525706">next</a><span>|</span><label class="collapse" for="c-41525405">[-]</label><label class="expand" for="c-41525405">[5 more]</label></div><br/><div class="children"><div class="content">the average coder is worse than an autocomplete<p>Too many people here have spent time in elite corporations and don&#x27;t realize how mediocre the bottom 50th percentile of coding talent is</div><br/><div id="41525722" class="c"><input type="checkbox" id="c-41525722" checked=""/><div class="controls bullet"><span class="by">weweweoo</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41525405">parent</a><span>|</span><a href="#41526006">next</a><span>|</span><label class="collapse" for="c-41525722">[-]</label><label class="expand" for="c-41525722">[3 more]</label></div><br/><div class="children"><div class="content">To be honest, if the bottom 50th percent of coding talent is going to be obsolete, I wonder what happens to rest of the &quot;knowledge workers&quot; in those companies. I mean people whose jobs consist of attending Teams meetings, making fancy powerpoint slides and reports, perhaps even excel if they are really competent. None of that is any more challenging for LLM than writing code. In fact replacing these jobs should be easier, since presentations and slides do not actually do anything, unlike a program that must perform a certain action correctly.</div><br/><div id="41525948" class="c"><input type="checkbox" id="c-41525948" checked=""/><div class="controls bullet"><span class="by">cs391231</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41525722">parent</a><span>|</span><a href="#41525991">next</a><span>|</span><label class="collapse" for="c-41525948">[-]</label><label class="expand" for="c-41525948">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve heard compelling arguments that we passed the &quot;more people than jobs&quot; threshold during the green revolution and as a civilization have collectively retrofitted UBI in the form of &quot;fake email jobs&quot; and endless layers of management. This also would explain <a href="https:&#x2F;&#x2F;wtfhappenedin1971.com&#x2F;" rel="nofollow">https:&#x2F;&#x2F;wtfhappenedin1971.com&#x2F;</a> pretty well.<p>Either AI shatters this charade, or we make up some new laws to restrain it and continue to pretend all is well.</div><br/></div></div><div id="41525991" class="c"><input type="checkbox" id="c-41525991" checked=""/><div class="controls bullet"><span class="by">smaudet</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41525722">parent</a><span>|</span><a href="#41525948">prev</a><span>|</span><a href="#41526006">next</a><span>|</span><label class="collapse" for="c-41525991">[-]</label><label class="expand" for="c-41525991">[1 more]</label></div><br/><div class="children"><div class="content">Exactly. There&#x27;s some need, perhaps, to keep these tools &quot;up to date&quot; because someone in a non-free country is going to use them in a horrendous manner and we should maybe know more about them (maybe).<p>However, there is no good reason in a free society that this stuff should be widely accessible. Really, it should be illegal without a clearance, or need-to-know. We don&#x27;t let just anyone handle the nukes...</div><br/></div></div></div></div><div id="41526006" class="c"><input type="checkbox" id="c-41526006" checked=""/><div class="controls bullet"><span class="by">nyarlathotep_</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41525405">parent</a><span>|</span><a href="#41525722">prev</a><span>|</span><a href="#41525706">next</a><span>|</span><label class="collapse" for="c-41526006">[-]</label><label class="expand" for="c-41526006">[1 more]</label></div><br/><div class="children"><div class="content">This is true and yet companies (both Private and Public sector) spend literal billions on Accenture &#x2F;Deloitte slop that runs budgets will into the 10s of millions.<p>Skills aren&#x27;t even something that dictates software spend, it seems.</div><br/></div></div></div></div><div id="41525706" class="c"><input type="checkbox" id="c-41525706" checked=""/><div class="controls bullet"><span class="by">fullstop</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41525190">parent</a><span>|</span><a href="#41525405">prev</a><span>|</span><a href="#41525692">next</a><span>|</span><label class="collapse" for="c-41525706">[-]</label><label class="expand" for="c-41525706">[1 more]</label></div><br/><div class="children"><div class="content">I tried it out and was able to put together a decent libevent server in c++ with smart pointers, etc, and a timer which prints out connection stats every 30s.  It worked remarkably well.<p>I&#x27;m trying not to look at it as a potential career-ending event, but rather as another tool in my tool belt.  I&#x27;ve been in the industry for 25 years now, and this is <i>way</i> more of an advancement than things like IntelliSense ever was.</div><br/></div></div></div></div><div id="41525692" class="c"><input type="checkbox" id="c-41525692" checked=""/><div class="controls bullet"><span class="by">rowanG077</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41525055">parent</a><span>|</span><a href="#41525190">prev</a><span>|</span><a href="#41526014">next</a><span>|</span><label class="collapse" for="c-41525692">[-]</label><label class="expand" for="c-41525692">[1 more]</label></div><br/><div class="children"><div class="content">Huh careers are 30 years long? I don&#x27;t know where you live but it&#x27;s more like 45 years long where I live. The retirement age is 67.</div><br/></div></div><div id="41526014" class="c"><input type="checkbox" id="c-41526014" checked=""/><div class="controls bullet"><span class="by">littlestymaar</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41525055">parent</a><span>|</span><a href="#41525692">prev</a><span>|</span><a href="#41524956">next</a><span>|</span><label class="collapse" for="c-41526014">[-]</label><label class="expand" for="c-41526014">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Can you confidently say that an LLM won’t be better than an average 22 year old coder within these 30 years?<p>No 22 years old coder is better than the open source library he&#x27;s using taken straight from github, and yet he&#x27;s the one who&#x27;s getting paid for it.<p>People who claim IA will disrupt software development are just missing the big picture here: software jobs are already unrecognizable from what it was just 20 years ago. AI is just another tool, and as long as execs won&#x27;t bother use the tool by themselves, then they&#x27;ll pay developers to do it instead.<p>Over the past decades, writing code has become more and more efficient (better programming languages, better tooling, then enormous open source libraries) yet the number of developers kept increasing, it&#x27;s Jevons paradox[1] in its purest form. So if past tells us anything, is that AI is going to create many new software developer jobs! (because the amount of people able to ship significant value to a customer is going to skyrocket, and customers&#x27; needs are a renewable resource).<p>[1]: <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Jevons_paradox" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Jevons_paradox</a></div><br/></div></div></div></div><div id="41524956" class="c"><input type="checkbox" id="c-41524956" checked=""/><div class="controls bullet"><span class="by">fsndz</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524828">parent</a><span>|</span><a href="#41525055">prev</a><span>|</span><a href="#41525026">next</a><span>|</span><label class="collapse" for="c-41524956">[-]</label><label class="expand" for="c-41524956">[1 more]</label></div><br/><div class="children"><div class="content">Exactly, LLMs are not near ready to fully replace software engineers or any kind of knowledge workers. But they are increasingly useful tools that is true. 
<a href="https:&#x2F;&#x2F;www.lycee.ai&#x2F;blog&#x2F;ai-replace-software-engineer" rel="nofollow">https:&#x2F;&#x2F;www.lycee.ai&#x2F;blog&#x2F;ai-replace-software-engineer</a></div><br/></div></div><div id="41525026" class="c"><input type="checkbox" id="c-41525026" checked=""/><div class="controls bullet"><span class="by">fakedang</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524828">parent</a><span>|</span><a href="#41524956">prev</a><span>|</span><a href="#41525277">next</a><span>|</span><label class="collapse" for="c-41525026">[-]</label><label class="expand" for="c-41525026">[4 more]</label></div><br/><div class="children"><div class="content">Truth is, LLMs are going to make the coding part super easy, and the ceiling for shit coders like me has just gotten a lot lower because I can just ask it to deliver clean code to me.<p>I feel like the software developer version of an investment banking Managing Director asking my analyst to build me a pitch deck an hour before the meeting.</div><br/><div id="41526059" class="c"><input type="checkbox" id="c-41526059" checked=""/><div class="controls bullet"><span class="by">dhdisjsbshsus</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41525026">parent</a><span>|</span><a href="#41526759">next</a><span>|</span><label class="collapse" for="c-41526059">[-]</label><label class="expand" for="c-41526059">[2 more]</label></div><br/><div class="children"><div class="content">You mentioned in another comment you’ve used AI to write clean code, but here you mention you’re a “shit coder”. How do you know it’s giving you clean code?</div><br/><div id="41526300" class="c"><input type="checkbox" id="c-41526300" checked=""/><div class="controls bullet"><span class="by">fakedang</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41526059">parent</a><span>|</span><a href="#41526759">next</a><span>|</span><label class="collapse" for="c-41526300">[-]</label><label class="expand" for="c-41526300">[1 more]</label></div><br/><div class="children"><div class="content">I know the fundamentals but I&#x27;m a noob when it comes to coding with React or NextJS. Code that comes out from Claude is often segregated and modularized properly so that even I can follow the logic of the code, even if not the language and its syntax. If there&#x27;s an issue with the code, causing it to fail at runtime, I am still able to debug it appropriately with my minimal language of JS. If any codebase can let me do that, then in my books that&#x27;s a great codebase.<p>Compare that to Gpt 4o which gives me a massive chunk of unsorted gibberish that I have to pore through and organize myself.<p>Besides, most IBD MDs don&#x27;t know if they&#x27;re getting correct numbers either :).</div><br/></div></div></div></div><div id="41526759" class="c"><input type="checkbox" id="c-41526759" checked=""/><div class="controls bullet"><span class="by">bamboozled</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41525026">parent</a><span>|</span><a href="#41526059">prev</a><span>|</span><a href="#41525277">next</a><span>|</span><label class="collapse" for="c-41526759">[-]</label><label class="expand" for="c-41526759">[1 more]</label></div><br/><div class="children"><div class="content">Has the coding part ever been hard? When is the last time you faced a hard coding challenege?<p>What is hard is gather requirements, dealing with unexpected production issues, scaling, security, fixing obscure bugs and integration with other systems.<p>The coding part is about 10% of my job and the easiest part by far.</div><br/></div></div></div></div></div></div><div id="41525277" class="c"><input type="checkbox" id="c-41525277" checked=""/><div class="controls bullet"><span class="by">bunderbunder</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524419">parent</a><span>|</span><a href="#41524828">prev</a><span>|</span><a href="#41525501">next</a><span>|</span><label class="collapse" for="c-41525277">[-]</label><label class="expand" for="c-41525277">[1 more]</label></div><br/><div class="children"><div class="content">Actually cutting code is <i>maybe</i> 10% of the job, and LLMs are absolute crap at the other 90%.<p>They can&#x27;t build and maintain relationships with stakeholders. They can&#x27;t tell you why what you ask them to do is unlikely to work out well in practice and suggest alternative designs. They can&#x27;t identify, document and justify acceptance criteria. They can&#x27;t domain model. They can&#x27;t architect. They can&#x27;t do large-scale refactoring. They can&#x27;t do system-level optimization. They can&#x27;t work with that weird-ass code generation tool that some hotshot baked deeply into the system 15 years ago. They can&#x27;t figure out why that fence is sitting out in the middle of the field for no obvious reason. etc.<p>If that kind of stuff sounds like satisfying work to you, you should be fine. If it sounds terrible, you should pivot away now regardless of any concerns about LLMs, because, again, this is like 90% of the real work.</div><br/></div></div><div id="41525501" class="c"><input type="checkbox" id="c-41525501" checked=""/><div class="controls bullet"><span class="by">gensym</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524419">parent</a><span>|</span><a href="#41525277">prev</a><span>|</span><a href="#41524523">next</a><span>|</span><label class="collapse" for="c-41525501">[-]</label><label class="expand" for="c-41525501">[1 more]</label></div><br/><div class="children"><div class="content">1. The demand for software is insatiable. The biggest gate has been the high costs due to limited supply of the time of the people who know how to do it. In the near term, AI will make the cost of software (not of software devs, but the software itself) decrease while demand for new software will increase, especially as software needs to be created to take advantage of new UI tools.<p>I&#x27;ve been in software engineering for over 20 years. I&#x27;ve seen massive growth in the productivity of software engineers, and that&#x27;s resulted in greater demand for them. In the near term, AI should continue this trend.<p>2. It&#x27;s possible that at some point, AI will advance to where we can remove software engineers from the loop. We&#x27;re not even close to that point yet. In the mean time, software engineering is an excellent way to learn about other business problems so that you&#x27;ll be well-situated to address them (whatever they&#x27;ll be at that time).</div><br/></div></div><div id="41524523" class="c"><input type="checkbox" id="c-41524523" checked=""/><div class="controls bullet"><span class="by">LouisSayers</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524419">parent</a><span>|</span><a href="#41525501">prev</a><span>|</span><a href="#41524646">next</a><span>|</span><label class="collapse" for="c-41524523">[-]</label><label class="expand" for="c-41524523">[6 more]</label></div><br/><div class="children"><div class="content">Don&#x27;t do it, help us keep our high salaries :D<p>Joking aside, even with AI generating code, someone has to know how to talk to it, how to understand the output, and know what to do with it.<p>AI is also not great for novel concepts and may not fully get what&#x27;s happening when a bug occurs.<p>Remember, it&#x27;s just a tool at the end of the day.</div><br/><div id="41524683" class="c"><input type="checkbox" id="c-41524683" checked=""/><div class="controls bullet"><span class="by">al_borland</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524523">parent</a><span>|</span><a href="#41524647">next</a><span>|</span><label class="collapse" for="c-41524683">[-]</label><label class="expand" for="c-41524683">[3 more]</label></div><br/><div class="children"><div class="content">&gt; may not fully get what&#x27;s happening when a bug occurs.<p>And may still not understand even when you explicitly tell it. It wrote some code for me last week and made an error with an index off by 1. It had set the index to 1, then later was assuming a 0 index. I specifically told it this and it was unable to fix it. It was in debug hell, adding print statements everywhere.  I eventually fixed it myself after it was clear it was going to get hung up on this forever.<p>It got me 99% of the way there, but that 1% meant it didn’t work at all.</div><br/><div id="41525865" class="c"><input type="checkbox" id="c-41525865" checked=""/><div class="controls bullet"><span class="by">KoolKat23</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524683">parent</a><span>|</span><a href="#41525040">next</a><span>|</span><label class="collapse" for="c-41525865">[-]</label><label class="expand" for="c-41525865">[1 more]</label></div><br/><div class="children"><div class="content">Ironically, just yesterday I asked sonnet to write a script in JavaScript, it went in a bit of a perpetual loop unable to provide an error free script (the reason for the errors were not immediately obvious). I then mentioned that it needs to be zero indexed, and it immediately provided an issue free version that worked.</div><br/></div></div><div id="41525040" class="c"><input type="checkbox" id="c-41525040" checked=""/><div class="controls bullet"><span class="by">fakedang</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524683">parent</a><span>|</span><a href="#41525865">prev</a><span>|</span><a href="#41524647">next</a><span>|</span><label class="collapse" for="c-41525040">[-]</label><label class="expand" for="c-41525040">[1 more]</label></div><br/><div class="children"><div class="content">Well now you&#x27;re going to be paid a high salary for knowing when to use a 1 index vs a 0 index. :)</div><br/></div></div></div></div><div id="41524647" class="c"><input type="checkbox" id="c-41524647" checked=""/><div class="controls bullet"><span class="by">AIorNot</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524523">parent</a><span>|</span><a href="#41524683">prev</a><span>|</span><a href="#41524646">next</a><span>|</span><label class="collapse" for="c-41524647">[-]</label><label class="expand" for="c-41524647">[2 more]</label></div><br/><div class="children"><div class="content">just change this to &quot;I have AI Skills!!&quot; :)<p><a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=hNuu9CpdjIo" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=hNuu9CpdjIo</a></div><br/><div id="41524786" class="c"><input type="checkbox" id="c-41524786" checked=""/><div class="controls bullet"><span class="by">mindcrime</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524647">parent</a><span>|</span><a href="#41524646">next</a><span>|</span><label class="collapse" for="c-41524786">[-]</label><label class="expand" for="c-41524786">[1 more]</label></div><br/><div class="children"><div class="content">Not having clicked the link yet, I&#x27;m going to speculate that this is the famous Office Space &quot;I have people skills, damnit!&quot; scene.<p>...<p>And it was. :-) Nice callback!</div><br/></div></div></div></div></div></div><div id="41524646" class="c"><input type="checkbox" id="c-41524646" checked=""/><div class="controls bullet"><span class="by">vessenes</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524419">parent</a><span>|</span><a href="#41524523">prev</a><span>|</span><a href="#41524470">next</a><span>|</span><label class="collapse" for="c-41524646">[-]</label><label class="expand" for="c-41524646">[1 more]</label></div><br/><div class="children"><div class="content">Coding is going to be mediated by these LLMs everywhere — you’re right about that. However, as of today, and for some time, practitioners will be critical partners &#x2F; overseers; what this looks like today in my workflow is debugging, product specification, coding the ‘hard bits’, reworking &#x2F; specifying architectures. Whatever of these fall of the plate in the coming years, you’ll never lose your creative agency or determination of what you want to build, no matter how advanced the computers. Maybe give Iain Banks a read for a positive future that has happy humans and super-intelligent AI.<p>We have working fine cabinet makers who use mostly hand tools and bandsaws in our economy, we have CAD&#x2F;CAM specialists who tell CnC machines what to build at scale; we’ll have the equivalent in tech for a long time.<p>That said, if you don’t love the building itself, maybe it’s not a good fit for you. If you do love making (digital) things, you’re looking at a super bright future.</div><br/></div></div><div id="41524470" class="c"><input type="checkbox" id="c-41524470" checked=""/><div class="controls bullet"><span class="by">hakanderyal</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524419">parent</a><span>|</span><a href="#41524646">prev</a><span>|</span><a href="#41525419">next</a><span>|</span><label class="collapse" for="c-41524470">[-]</label><label class="expand" for="c-41524470">[27 more]</label></div><br/><div class="children"><div class="content">Software engineering contains a lot more than just writing code.<p>If we somehow get AGI, it&#x27;ll change everything, not just SWE.<p>If not, my belief is that there will be a lot more demand for good SWEs to harness the power of LLMs, not less. Use them to get better at it faster.</div><br/><div id="41524578" class="c"><input type="checkbox" id="c-41524578" checked=""/><div class="controls bullet"><span class="by">fsloth</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524470">parent</a><span>|</span><a href="#41524694">next</a><span>|</span><label class="collapse" for="c-41524578">[-]</label><label class="expand" for="c-41524578">[3 more]</label></div><br/><div class="children"><div class="content">Agree, SWE as a profession is not going anywhere, unless we AGI, and that would mean all the rules change anyway.<p>Actually now is really good time to get to SWE. The craft contains lots of pointless cruft that LLM:s cut through like knife through hot butter.<p>I’m actually enjoying my job now more than ever since I dont’t need to pretend to like the abysmal tools the industry forces on us (like git), and can focus mostly on value adding tasks. The amount of tiresome shoveling has decreased considerably.</div><br/><div id="41527776" class="c"><input type="checkbox" id="c-41527776" checked=""/><div class="controls bullet"><span class="by">whynotminot</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524578">parent</a><span>|</span><a href="#41524694">next</a><span>|</span><label class="collapse" for="c-41527776">[-]</label><label class="expand" for="c-41527776">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;d agree with this take. Everyone is so pessimistic about LLMs, but I&#x27;ve really enjoyed this new era.<p>A lot of the tasks that used to take considerable time are so much faster and less tedious now. It still puts a smile on my face to tell an LLM to write me scripts that do X Y and Z. Or hand it code and ask for unit tests.<p>And I feel like I&#x27;m more likely to reach for work that I might otherwise shrink from &#x2F; outside my usual comfort zone, because asking questions of an LLM is just so much better than doing trivial beginner tutorials or diving through 15 vaguely related stack overflow questions (I wonder if SO has seen any significant dip in traffic over the last year).<p>Most people I&#x27;ve seen disappointed with these tools are doing way more advanced work than I appear to be doing in my day to day work. They fail me too here and there, but more often than not I&#x27;m able to get at least something helpful or useful out of them.</div><br/><div id="41528433" class="c"><input type="checkbox" id="c-41528433" checked=""/><div class="controls bullet"><span class="by">fsloth</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41527776">parent</a><span>|</span><a href="#41524694">next</a><span>|</span><label class="collapse" for="c-41528433">[-]</label><label class="expand" for="c-41528433">[1 more]</label></div><br/><div class="children"><div class="content">Exactly this. The menial tasks become less of a burden and you can just power through them with LLM generated scripts.<p>If someone expects the LLM to be the senior contributor in novel algorithm development, they will be disappointed for sure. But there is so, so much stuff to do to idiot savant junior trainees with infinite patience.</div><br/></div></div></div></div></div></div><div id="41524694" class="c"><input type="checkbox" id="c-41524694" checked=""/><div class="controls bullet"><span class="by">Workaccount2</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524470">parent</a><span>|</span><a href="#41524578">prev</a><span>|</span><a href="#41524546">next</a><span>|</span><label class="collapse" for="c-41524694">[-]</label><label class="expand" for="c-41524694">[14 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think anyone is worried about SWE work going away, I think the concern is if SWE&#x27;s will still be able to command cushy salaries and working conditions.</div><br/><div id="41524767" class="c"><input type="checkbox" id="c-41524767" checked=""/><div class="controls bullet"><span class="by">packetlost</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524694">parent</a><span>|</span><a href="#41526581">next</a><span>|</span><label class="collapse" for="c-41524767">[-]</label><label class="expand" for="c-41524767">[3 more]</label></div><br/><div class="children"><div class="content">I think the industry will bifurcate along the axis of &quot;doing actually novel stuff&quot; vs slinging DB records and displaying web pages. The latter is what I&#x27;d expect to get disrupted, if anything, but the former isn&#x27;t going away unless real AGI is created. The people on the left of that split are going to be worth a lot more because the pipeline to get there will be even harder than it was before.</div><br/><div id="41526070" class="c"><input type="checkbox" id="c-41526070" checked=""/><div class="controls bullet"><span class="by">nyarlathotep_</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524767">parent</a><span>|</span><a href="#41526581">next</a><span>|</span><label class="collapse" for="c-41526070">[-]</label><label class="expand" for="c-41526070">[2 more]</label></div><br/><div class="children"><div class="content">&gt;  &quot;doing actually novel stuff&quot; vs slinging DB records and displaying web pages. The latter is what I&#x27;d expect to get disrupted,<p>Unfortunately the latter is the vast majority of software jobs.</div><br/><div id="41527471" class="c"><input type="checkbox" id="c-41527471" checked=""/><div class="controls bullet"><span class="by">packetlost</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41526070">parent</a><span>|</span><a href="#41526581">next</a><span>|</span><label class="collapse" for="c-41527471">[-]</label><label class="expand" for="c-41527471">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, but honestly I&#x27;m ok with the industry shrinking along that axis.</div><br/></div></div></div></div></div></div><div id="41526581" class="c"><input type="checkbox" id="c-41526581" checked=""/><div class="controls bullet"><span class="by">matwood</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524694">parent</a><span>|</span><a href="#41524767">prev</a><span>|</span><a href="#41524818">next</a><span>|</span><label class="collapse" for="c-41526581">[-]</label><label class="expand" for="c-41526581">[1 more]</label></div><br/><div class="children"><div class="content">Salaries will only change if tech loses it&#x27;s leverage on the economy. Think of it this way, if Google can operate Google with only 10% of its current staff, then there will be other Googles popping up. The downward pressure on salaries will start with the downward pressure on tech overall. I&#x27;m not sure I see this happening anytime soon because humanity is so good at using every resource available.</div><br/></div></div><div id="41524818" class="c"><input type="checkbox" id="c-41524818" checked=""/><div class="controls bullet"><span class="by">tivert</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524694">parent</a><span>|</span><a href="#41526581">prev</a><span>|</span><a href="#41524546">next</a><span>|</span><label class="collapse" for="c-41524818">[-]</label><label class="expand" for="c-41524818">[9 more]</label></div><br/><div class="children"><div class="content">&gt; I don&#x27;t think anyone is worried about SWE work going away, I think the concern is if SWE&#x27;s will still be able to command cushy salaries and working conditions.<p>It&#x27;s very important to human progress that all jobs have poor working conditions and shit pay. High salaries and good conditions are evidence of inefficiency. Precarity should be the norm, and I&#x27;m glad AI is going to give it to us.</div><br/><div id="41525454" class="c"><input type="checkbox" id="c-41525454" checked=""/><div class="controls bullet"><span class="by">Workaccount2</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524818">parent</a><span>|</span><a href="#41524942">next</a><span>|</span><label class="collapse" for="c-41525454">[-]</label><label class="expand" for="c-41525454">[1 more]</label></div><br/><div class="children"><div class="content">Software engineering pay is an outlier for STEM fields. It would not be surprising at all if SWE work fell into the ~$80-120k camp even with 10+ years experience.<p>They won&#x27;t go broke, but landing a $175k work from home job with platinum tier benefits will be near impossible. $110K with a hybrid schedule and mediocre benefits will be very common even for seniors.</div><br/></div></div><div id="41524942" class="c"><input type="checkbox" id="c-41524942" checked=""/><div class="controls bullet"><span class="by">bornfreddy</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524818">parent</a><span>|</span><a href="#41525454">prev</a><span>|</span><a href="#41524546">next</a><span>|</span><label class="collapse" for="c-41524942">[-]</label><label class="expand" for="c-41524942">[7 more]</label></div><br/><div class="children"><div class="content">Sarcasm or cynicism?</div><br/><div id="41525278" class="c"><input type="checkbox" id="c-41525278" checked=""/><div class="controls bullet"><span class="by">baq</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524942">parent</a><span>|</span><a href="#41524546">next</a><span>|</span><label class="collapse" for="c-41525278">[-]</label><label class="expand" for="c-41525278">[6 more]</label></div><br/><div class="children"><div class="content">Capitalism.<p>Btw communism is capitalism without systemic awareness of inefficiencies.</div><br/><div id="41525801" class="c"><input type="checkbox" id="c-41525801" checked=""/><div class="controls bullet"><span class="by">ruthmarx</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41525278">parent</a><span>|</span><a href="#41524546">next</a><span>|</span><label class="collapse" for="c-41525801">[-]</label><label class="expand" for="c-41525801">[5 more]</label></div><br/><div class="children"><div class="content">Capitalism doesn&#x27;t dictate poor working conditions at all. Lack of regulation certainly does though.</div><br/><div id="41526697" class="c"><input type="checkbox" id="c-41526697" checked=""/><div class="controls bullet"><span class="by">tivert</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41525801">parent</a><span>|</span><a href="#41524546">next</a><span>|</span><label class="collapse" for="c-41526697">[-]</label><label class="expand" for="c-41526697">[4 more]</label></div><br/><div class="children"><div class="content">&gt; Capitalism doesn&#x27;t dictate poor working conditions at all. Lack of regulation certainly does though.<p>It totally does. Regulation is basically opposed to capitalism working as designed.</div><br/><div id="41528568" class="c"><input type="checkbox" id="c-41528568" checked=""/><div class="controls bullet"><span class="by">ruthmarx</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41526697">parent</a><span>|</span><a href="#41528468">next</a><span>|</span><label class="collapse" for="c-41528568">[-]</label><label class="expand" for="c-41528568">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s not true at all. That&#x27;s just some propaganda college kids and the like keep repeating. Most other western countries are capitalist, have much stronger regulation than the US and are all the better for it.</div><br/></div></div><div id="41528468" class="c"><input type="checkbox" id="c-41528468" checked=""/><div class="controls bullet"><span class="by">baq</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41526697">parent</a><span>|</span><a href="#41528568">prev</a><span>|</span><a href="#41524546">next</a><span>|</span><label class="collapse" for="c-41528468">[-]</label><label class="expand" for="c-41528468">[2 more]</label></div><br/><div class="children"><div class="content">Capitalism needs regulation to avoid self destruction. Without circuit breakers it devolves into monopolistic totalitarianism.<p>C.f. East India company. Then imagine them with modern military and communications tech.</div><br/><div id="41528571" class="c"><input type="checkbox" id="c-41528571" checked=""/><div class="controls bullet"><span class="by">ruthmarx</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41528468">parent</a><span>|</span><a href="#41524546">next</a><span>|</span><label class="collapse" for="c-41528571">[-]</label><label class="expand" for="c-41528571">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Capitalism needs regulation to avoid self destruction.<p>This is equally true for any alternative system to capitalism.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="41524546" class="c"><input type="checkbox" id="c-41524546" checked=""/><div class="controls bullet"><span class="by">cs391231</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524470">parent</a><span>|</span><a href="#41524694">prev</a><span>|</span><a href="#41525419">next</a><span>|</span><label class="collapse" for="c-41524546">[-]</label><label class="expand" for="c-41524546">[9 more]</label></div><br/><div class="children"><div class="content">This thing is doing planning and ascending the task management ladder. It&#x27;s not just spitting out code anymore.</div><br/><div id="41524648" class="c"><input type="checkbox" id="c-41524648" checked=""/><div class="controls bullet"><span class="by">parasubvert</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524546">parent</a><span>|</span><a href="#41524650">next</a><span>|</span><label class="collapse" for="c-41524648">[-]</label><label class="expand" for="c-41524648">[1 more]</label></div><br/><div class="children"><div class="content">AI Automated planning and action are an old (45+ year) field in AI with a rich history and a lot of successes.   Another breakthrough in this area isn&#x27;t going to eliminate engineering as a profession.  The problem space is much bigger than what AI can tackle alone, it helps with emancipation for the humans that know how to include it in their workflows.</div><br/></div></div><div id="41524650" class="c"><input type="checkbox" id="c-41524650" checked=""/><div class="controls bullet"><span class="by">hakanderyal</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524546">parent</a><span>|</span><a href="#41524648">prev</a><span>|</span><a href="#41524656">next</a><span>|</span><label class="collapse" for="c-41524650">[-]</label><label class="expand" for="c-41524650">[4 more]</label></div><br/><div class="children"><div class="content">Yes, and they will get better. Billions are being poured into them to improve.<p>Yet I&#x27;m comparing these to the problems I solve every day and I don&#x27;t see any plausible way they can replace me. But I&#x27;m using them for tasks that would have required me to hire a junior.<p>Make that what you will.</div><br/><div id="41525138" class="c"><input type="checkbox" id="c-41525138" checked=""/><div class="controls bullet"><span class="by">noshitsherlock</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524650">parent</a><span>|</span><a href="#41524656">next</a><span>|</span><label class="collapse" for="c-41525138">[-]</label><label class="expand" for="c-41525138">[3 more]</label></div><br/><div class="children"><div class="content">Yes, if &quot;efficiency&quot; is your top concern, but I&#x27;d much prefer working with an actual person than just a computer.  I mean, God forbid I&#x27;m only useful for what I can produce, and disposable when I reach my expiration date.  I would like to see a twilight zone rendition of an AI dystopia where all the slow, ignorant and bothersome humans are replaced by lifeless AI</div><br/><div id="41527578" class="c"><input type="checkbox" id="c-41527578" checked=""/><div class="controls bullet"><span class="by">hakanderyal</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41525138">parent</a><span>|</span><a href="#41525318">next</a><span>|</span><label class="collapse" for="c-41527578">[-]</label><label class="expand" for="c-41527578">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not just about efficiency. I don&#x27;t have the means to hire a junior right now, but 20$ is a no brainer.</div><br/></div></div><div id="41525318" class="c"><input type="checkbox" id="c-41525318" checked=""/><div class="controls bullet"><span class="by">baq</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41525138">parent</a><span>|</span><a href="#41527578">prev</a><span>|</span><a href="#41524656">next</a><span>|</span><label class="collapse" for="c-41525318">[-]</label><label class="expand" for="c-41525318">[1 more]</label></div><br/><div class="children"><div class="content">Time to re-read The Culture. Not everything has to end in a dystopia.</div><br/></div></div></div></div></div></div><div id="41524656" class="c"><input type="checkbox" id="c-41524656" checked=""/><div class="controls bullet"><span class="by">candiddevmike</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524546">parent</a><span>|</span><a href="#41524650">prev</a><span>|</span><a href="#41524597">next</a><span>|</span><label class="collapse" for="c-41524656">[-]</label><label class="expand" for="c-41524656">[2 more]</label></div><br/><div class="children"><div class="content">Management will be easier to replace than SWEs.  I&#x27;m thinking there will come a time, similar to the show Mrs Davis, where AI will direct human efforts within organizations.  AI will understand its limits and create tasks&#x2F;requirements for human specialists to handle.</div><br/><div id="41524727" class="c"><input type="checkbox" id="c-41524727" checked=""/><div class="controls bullet"><span class="by">al_borland</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524656">parent</a><span>|</span><a href="#41524597">next</a><span>|</span><label class="collapse" for="c-41524727">[-]</label><label class="expand" for="c-41524727">[1 more]</label></div><br/><div class="children"><div class="content">My first thought with this is that AI would be directed to figure out exactly how little people are willing to work for, and how long, before they break.<p>I hope I’m wrong, and it instead shows that more pay and fewer hours lead to a better economy, because people have money and time to spend it… and output isn’t impacted enough to matter.</div><br/></div></div></div></div><div id="41524597" class="c"><input type="checkbox" id="c-41524597" checked=""/><div class="controls bullet"><span class="by">fsloth</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524546">parent</a><span>|</span><a href="#41524656">prev</a><span>|</span><a href="#41525419">next</a><span>|</span><label class="collapse" for="c-41524597">[-]</label><label class="expand" for="c-41524597">[1 more]</label></div><br/><div class="children"><div class="content">Sure. But the added value of SWE is not ”spitting code”. Let’s see if I need to calibrate my optimism once I take the new model to a spin.</div><br/></div></div></div></div></div></div><div id="41525419" class="c"><input type="checkbox" id="c-41525419" checked=""/><div class="controls bullet"><span class="by">weweweoo</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524419">parent</a><span>|</span><a href="#41524470">prev</a><span>|</span><a href="#41524539">next</a><span>|</span><label class="collapse" for="c-41525419">[-]</label><label class="expand" for="c-41525419">[4 more]</label></div><br/><div class="children"><div class="content">What&#x27;s the alternative? If AI is going to replace software engineers, there is no fundamental reason they couldn&#x27;t replace almost all other knowledge workers as well. No matter the field, most of it is just office work managing, transforming and building new information, applying existing knowledge on new problems (that probably are not very unique in grand scheme of things).<p>Except for medical doctors, nurses, and some niche engineering professions, I really struggle to think of jobs requiring higher education that couldn&#x27;t be largely automated by an LLM that is smart enough to replace a senior software engineer. These few jobs are protected mainly by the physical aspect, and low tolerance for mistakes. Some skilled trades may also be protected, at least if robotics don&#x27;t improve dramatically.<p>Personally, I would become a doctor if I could. But of all things I could&#x27;ve studied excluding that, computer science has probably been one of the better options. At least it teaches problem solving and not just memorization of facts. Knowing how to code may not be that useful in the future, but the process of problem solving is going nowhere.</div><br/><div id="41525986" class="c"><input type="checkbox" id="c-41525986" checked=""/><div class="controls bullet"><span class="by">pid-1</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41525419">parent</a><span>|</span><a href="#41524539">next</a><span>|</span><label class="collapse" for="c-41525986">[-]</label><label class="expand" for="c-41525986">[3 more]</label></div><br/><div class="children"><div class="content">Why can&#x27;t medical doctors be automated?</div><br/><div id="41526443" class="c"><input type="checkbox" id="c-41526443" checked=""/><div class="controls bullet"><span class="by">weweweoo</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41525986">parent</a><span>|</span><a href="#41524539">next</a><span>|</span><label class="collapse" for="c-41526443">[-]</label><label class="expand" for="c-41526443">[2 more]</label></div><br/><div class="children"><div class="content">Mainly the various physical operations many of them perform on daily basis (due to limitations of robotics), plus liability issues in case things go wrong and somebody dies. And finally, huge demand due to aging population worldwide.<p>I do believe some parts of their jobs will be automated, but not enough (especially with growing demand) to really hurt career prospects. Even for those parts, it will take a long a while due to the regulated nature of the sector.</div><br/><div id="41526783" class="c"><input type="checkbox" id="c-41526783" checked=""/><div class="controls bullet"><span class="by">bamboozled</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41526443">parent</a><span>|</span><a href="#41524539">next</a><span>|</span><label class="collapse" for="c-41526783">[-]</label><label class="expand" for="c-41526783">[1 more]</label></div><br/><div class="children"><div class="content">When everything will be automated, what will we do with our lives?<p>I love landscaping my garden lately, would I just get a robot to do that and watch ?<p>Going to be a weird time.</div><br/></div></div></div></div></div></div></div></div><div id="41524539" class="c"><input type="checkbox" id="c-41524539" checked=""/><div class="controls bullet"><span class="by">crop_rotation</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524419">parent</a><span>|</span><a href="#41525419">prev</a><span>|</span><a href="#41524613">next</a><span>|</span><label class="collapse" for="c-41524539">[-]</label><label class="expand" for="c-41524539">[9 more]</label></div><br/><div class="children"><div class="content">If you have better career ideas, you should not continue. The thing is it is very hard to predict how the world will change (and by how much from very little to a revolutionary change) with all these new changes. Only licensed and regulated professions (doctors&#x2F;lawyers&#x2F;pilots etc) might remain high earning for long (and they too are not guaranteed). It really is worth a relook on what you want to do in life while seeing all these new advances.</div><br/><div id="41524564" class="c"><input type="checkbox" id="c-41524564" checked=""/><div class="controls bullet"><span class="by">cs391231</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524539">parent</a><span>|</span><a href="#41524681">next</a><span>|</span><label class="collapse" for="c-41524564">[-]</label><label class="expand" for="c-41524564">[3 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t have any ideas whatsoever.</div><br/><div id="41524781" class="c"><input type="checkbox" id="c-41524781" checked=""/><div class="controls bullet"><span class="by">baq</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524564">parent</a><span>|</span><a href="#41524576">next</a><span>|</span><label class="collapse" for="c-41524781">[-]</label><label class="expand" for="c-41524781">[1 more]</label></div><br/><div class="children"><div class="content">Do you enjoy making computers solve problems? If yes, continue. If you hate it and are in just for the money… I’d say flip a coin.</div><br/></div></div><div id="41524576" class="c"><input type="checkbox" id="c-41524576" checked=""/><div class="controls bullet"><span class="by">crop_rotation</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524564">parent</a><span>|</span><a href="#41524781">prev</a><span>|</span><a href="#41524681">next</a><span>|</span><label class="collapse" for="c-41524576">[-]</label><label class="expand" for="c-41524576">[1 more]</label></div><br/><div class="children"><div class="content">Then talk to more and more people, some of whom will have ideas on what they would prefer in the changing world.</div><br/></div></div></div></div><div id="41524681" class="c"><input type="checkbox" id="c-41524681" checked=""/><div class="controls bullet"><span class="by">ljm</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524539">parent</a><span>|</span><a href="#41524564">prev</a><span>|</span><a href="#41524613">next</a><span>|</span><label class="collapse" for="c-41524681">[-]</label><label class="expand" for="c-41524681">[5 more]</label></div><br/><div class="children"><div class="content">This is pretty extreme advice to offer in response to news that a model that can better understand programming problems is coming out.<p>In fact, it&#x27;s more encouragement to continue. A lot of issues we face as programmers are a result of poor, inaccurate, or non-existent documentation, and despite their many faults and hallucinations LLMs are providing something that Google and Stack Overflow have stopped being good at.<p>The idea that AI will replace your job, so it&#x27;s not worth establishing a career in the field, is total FUD.</div><br/><div id="41524723" class="c"><input type="checkbox" id="c-41524723" checked=""/><div class="controls bullet"><span class="by">crop_rotation</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524681">parent</a><span>|</span><a href="#41524613">next</a><span>|</span><label class="collapse" for="c-41524723">[-]</label><label class="expand" for="c-41524723">[4 more]</label></div><br/><div class="children"><div class="content">The advice is unrelated to the model and related to the last year&#x27;s worth of development. In any case I am advising a relook which is perfectly warranted for anyone pre-university or in university.</div><br/><div id="41524904" class="c"><input type="checkbox" id="c-41524904" checked=""/><div class="controls bullet"><span class="by">Alupis</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524723">parent</a><span>|</span><a href="#41524613">next</a><span>|</span><label class="collapse" for="c-41524904">[-]</label><label class="expand" for="c-41524904">[3 more]</label></div><br/><div class="children"><div class="content">This is a really odd take to have.<p>By the &quot;past year&#x27;s worth of development&quot; I assume you mean the layoffs? Have you been in the industry (or any industry) long? If so, you would have seen many layoffs and bulk-hiring frenzies over the years... it doesn&#x27;t mean anything about the industry as a whole and it&#x27;s certainly a foolish thing to change career asperations over.<p>Specifically regarding the LLM - anyone actually believing these models will replace developers and software engineers, truly, deeply does not understand software development at even the most basic fundamental levels. Ignore these people - they are the snake oil salesmen of our modern times.</div><br/><div id="41525179" class="c"><input type="checkbox" id="c-41525179" checked=""/><div class="controls bullet"><span class="by">jimhefferon</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524904">parent</a><span>|</span><a href="#41524613">next</a><span>|</span><label class="collapse" for="c-41525179">[-]</label><label class="expand" for="c-41525179">[2 more]</label></div><br/><div class="children"><div class="content">I assume the poster meant how much progress the models have made. Roughly late high school capability to late college-ish. Project forward five years.</div><br/><div id="41525350" class="c"><input type="checkbox" id="c-41525350" checked=""/><div class="controls bullet"><span class="by">baq</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41525179">parent</a><span>|</span><a href="#41524613">next</a><span>|</span><label class="collapse" for="c-41525350">[-]</label><label class="expand" for="c-41525350">[1 more]</label></div><br/><div class="children"><div class="content">Predicting exponential functions is a fool’s errand. The tiniest error in your initial observation compounds real fast and we can’t even tell if we’re still in the exponential phase of the sigmoid.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="41524613" class="c"><input type="checkbox" id="c-41524613" checked=""/><div class="controls bullet"><span class="by">Vanclief</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524419">parent</a><span>|</span><a href="#41524539">prev</a><span>|</span><a href="#41525109">next</a><span>|</span><label class="collapse" for="c-41524613">[-]</label><label class="expand" for="c-41524613">[1 more]</label></div><br/><div class="children"><div class="content">If you are not a software engineer, you can&#x27;t judge the correctness of any LLM answer on that topic, nor you know what are the right questions to ask.<p>From all my friends that are using LLMs, we software engineers are the ones that are taking the most advantage of it.<p>I am in no way fearful I am becoming irrelevant, on the opposite, I am actually very excited about these developments.</div><br/></div></div><div id="41525109" class="c"><input type="checkbox" id="c-41525109" checked=""/><div class="controls bullet"><span class="by">bashfulpup</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524419">parent</a><span>|</span><a href="#41524613">prev</a><span>|</span><a href="#41525038">next</a><span>|</span><label class="collapse" for="c-41525109">[-]</label><label class="expand" for="c-41525109">[2 more]</label></div><br/><div class="children"><div class="content">There is little to no research that shows modern AI can perform even the most simple long-running task without training data on that exact problem.<p>To my knowledge, there is no current AI system that can replace a white collar worker in any multistep task. The only thing they can do is support the worker.<p>Most jobs are safe for the forseable future. If your job is highly repetitive and a company can produce a perfect dataset of it, I&#x27;d worry.<p>Jobs like a factory worker and call center support are in danger. But the work is perfectly monitorable.<p>Watch the GAIA benchmark. It&#x27;s not nearly the complexity of a real-world job, but it would signal the start of an actual agentic system being possible.</div><br/><div id="41525360" class="c"><input type="checkbox" id="c-41525360" checked=""/><div class="controls bullet"><span class="by">baq</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41525109">parent</a><span>|</span><a href="#41525038">next</a><span>|</span><label class="collapse" for="c-41525360">[-]</label><label class="expand" for="c-41525360">[1 more]</label></div><br/><div class="children"><div class="content">I’d argue the foreseeable future got a lot shorter in the last couple years.</div><br/></div></div></div></div><div id="41525038" class="c"><input type="checkbox" id="c-41525038" checked=""/><div class="controls bullet"><span class="by">almostuseful</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524419">parent</a><span>|</span><a href="#41525109">prev</a><span>|</span><a href="#41525407">next</a><span>|</span><label class="collapse" for="c-41525038">[-]</label><label class="expand" for="c-41525038">[2 more]</label></div><br/><div class="children"><div class="content">If at some point a competent senior software engineer can be automated away, I think we are so close to a possible &#x27;AI singularity&#x27; in as much as that concept makes sense, that nothing really matters anyway.<p>I don&#x27;t know what will be automated first of the competent senior software engineer and say, a carpenter, but once the programmer has been automated away, the carpenter (and everything else) will follow shortly.<p>The reasoning is that there is such a functional overlap between being a standard software engineer and an AI engineer or researcher, that once you can automate one, you can automate the other. Once you have automated the AI engineers and researchers, you have recursive self-improving AI and all bets are off.<p>Essentially, software engineering is perhaps the only field where you shouldn&#x27;t worry about automation, because once that has been automated, everything changes anyways.</div><br/><div id="41526587" class="c"><input type="checkbox" id="c-41526587" checked=""/><div class="controls bullet"><span class="by">mr_toad</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41525038">parent</a><span>|</span><a href="#41525407">next</a><span>|</span><label class="collapse" for="c-41526587">[-]</label><label class="expand" for="c-41526587">[1 more]</label></div><br/><div class="children"><div class="content">Carpenters and other manual jobs might outlast software engineers.  It seems that AI is advancing a lot faster than robotics.</div><br/></div></div></div></div><div id="41525407" class="c"><input type="checkbox" id="c-41525407" checked=""/><div class="controls bullet"><span class="by">theptip</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524419">parent</a><span>|</span><a href="#41525038">prev</a><span>|</span><a href="#41526639">next</a><span>|</span><label class="collapse" for="c-41525407">[-]</label><label class="expand" for="c-41525407">[1 more]</label></div><br/><div class="children"><div class="content">If you want to get a career in software engineering because you want to write code all day, probably a bad time to be joining the field.<p>If you are interested in using technology to create systems that add value for your users, there has never been a better time.<p>GPT-N will let you scale your impact way beyond what you could do on your own.<p>Your school probably isn’t going to keep abreast with this tech so it’s going to be more important to find side-projects to exercise your skills. Build a small project, get some users, automate as much as you can, and have fun along the way.</div><br/></div></div><div id="41526639" class="c"><input type="checkbox" id="c-41526639" checked=""/><div class="controls bullet"><span class="by">hulium</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524419">parent</a><span>|</span><a href="#41525407">prev</a><span>|</span><a href="#41525622">next</a><span>|</span><label class="collapse" for="c-41526639">[-]</label><label class="expand" for="c-41526639">[1 more]</label></div><br/><div class="children"><div class="content">Computer Science becomes MORE interesting as computers become more capable, not less. There are so many things we could be working on, but we still waste so much time on boring libraries, configuration, implementation details that we simply don&#x27;t get to experiment enough.<p>Just like nobody programs on punch cards anymore, learning details of a specific technology without deeper understanding will become obsolete. But general knowledge about computer science will become more valuable.</div><br/></div></div><div id="41525622" class="c"><input type="checkbox" id="c-41525622" checked=""/><div class="controls bullet"><span class="by">p1necone</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524419">parent</a><span>|</span><a href="#41526639">prev</a><span>|</span><a href="#41524720">next</a><span>|</span><label class="collapse" for="c-41525622">[-]</label><label class="expand" for="c-41525622">[1 more]</label></div><br/><div class="children"><div class="content">For basically all the existing data we have, efficiency improvements <i>always</i> result in <i>more</i> work, not less.<p>Humans never say &quot;oh neat I can do <i>thing</i> with 10% of the effort now, guess I&#x27;ll go watch tv for the rest of the week&quot;, they say &quot;oh neat I can do <i>thing</i> with 10% of the effort now, I&#x27;m going to hire twice as many people and produce like 20x as much as I was before because there&#x27;s so much less risk to scaling now.&quot;<p>I think there&#x27;s enough unmet demand for software that efficiency increases from automation are going to be eaten up for a long time to come.</div><br/></div></div><div id="41524720" class="c"><input type="checkbox" id="c-41524720" checked=""/><div class="controls bullet"><span class="by">sbaidon94</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524419">parent</a><span>|</span><a href="#41525622">prev</a><span>|</span><a href="#41524703">next</a><span>|</span><label class="collapse" for="c-41524720">[-]</label><label class="expand" for="c-41524720">[1 more]</label></div><br/><div class="children"><div class="content">My two cents thinking about different scenarios:<p>- AI comes fast, there is nothing you can do: Honestly, AI can already handle a lot of tasks faster, cheaper, and sometimes better. It’s not something you can avoid or outpace. So if you want to stick with software engineering, do it because you genuinely enjoy it, not because you think it’s safe. Otherwise, it might be worth considering fields where AI struggles or is just not compatible. (people will still want some sort of human element in certain areas).<p>- There is some sort of ceiling, gives you more time to act: There’s a chance AI hits some kind of wall that’s due to technical problems, ethical concerns, or society pushing back. If that happens, we’re all back on more even ground and you can take advantage of AI tools to improve yourself.<p>My overall advice; and it will probably be called out as cliche&#x2F;simplistic just follow what you love, just the fact that you have an opportunity to pursue to study anything at all is something that many people don&#x27;t have. We don&#x27;t really have control in a lot of stuff that happens around us and that&#x27;s okay.</div><br/></div></div><div id="41524703" class="c"><input type="checkbox" id="c-41524703" checked=""/><div class="controls bullet"><span class="by">stickfigure</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524419">parent</a><span>|</span><a href="#41524720">prev</a><span>|</span><a href="#41524773">next</a><span>|</span><label class="collapse" for="c-41524703">[-]</label><label class="expand" for="c-41524703">[1 more]</label></div><br/><div class="children"><div class="content">The amount of knowledge the OP needed to be even to formulate the right question to the AI requires a lifetime of deep immersion in technology. You&#x27;d think that maybe you can ask the AI how to phrase the question to the AI but at some point you run up against your ability to contextualize the problem - it can&#x27;t read your mind.<p>Will the AI become as smart as you or I? Recognize that these things have tiny context windows. You get the context window of &quot;as long as you can remember&quot;.<p>I don&#x27;t see this kind of AI replacing programmers (though it probably will replace low-skill offshore contract shops). It may have a large magnifying effect on skill. Fortunately there seem to be endless problems to solve with software - it&#x27;s not like bridges or buildings; you only need (or can afford) so many. Architects should probably be more worried.</div><br/></div></div><div id="41524773" class="c"><input type="checkbox" id="c-41524773" checked=""/><div class="controls bullet"><span class="by">sterlind</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524419">parent</a><span>|</span><a href="#41524703">prev</a><span>|</span><a href="#41525216">next</a><span>|</span><label class="collapse" for="c-41524773">[-]</label><label class="expand" for="c-41524773">[2 more]</label></div><br/><div class="children"><div class="content">Because none of your other majors will hold up much longer. Once software engineering becomes fully automated, so will EE, ME, applied math, economics, physics, etc. If you work with your hands, like a surgeon or chemist, you&#x27;ll last longer, but the thinky bits of those jobs will disappear. And once AI research is automated, how long will it be until we have dexterous robots?<p>So basically, switching majors is just running to the back of a sinking ship. Sorry.</div><br/></div></div><div id="41525216" class="c"><input type="checkbox" id="c-41525216" checked=""/><div class="controls bullet"><span class="by">mmckelvy</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524419">parent</a><span>|</span><a href="#41524773">prev</a><span>|</span><a href="#41526488">next</a><span>|</span><label class="collapse" for="c-41525216">[-]</label><label class="expand" for="c-41525216">[1 more]</label></div><br/><div class="children"><div class="content">As others have said, LLMs still require engineers to produce quality output.  LLMs do, however, make those engineers that use them much more productive.  If this trend continues, I could see a scenario where an individual engineer could build a customized version of, say, Salesforce in a month or two.  If that happens, you could make a solid case that companies paying $1mm+ per year for 12 different SaaS tools should just bring that in house.  The upshot is you may still be writing software, but instead of building SaaS at Salesforce, you&#x27;ll be working for their former customers or maybe as some sort of contractor.</div><br/></div></div></div></div><div id="41525007" class="c"><input type="checkbox" id="c-41525007" checked=""/><div class="controls bullet"><span class="by">jeffpeterson</span><span>|</span><a href="#41524263">parent</a><span>|</span><a href="#41526488">prev</a><span>|</span><a href="#41524937">next</a><span>|</span><label class="collapse" for="c-41525007">[-]</label><label class="expand" for="c-41525007">[1 more]</label></div><br/><div class="children"><div class="content">Very cool. It gets the conclusion right, but it did confuse itself briefly after interpreting `256 * last_byte + second_to_last_byte` as big-endian. It&#x27;s neat that it corrected the confusion, but a little unsatisfying that it doesn&#x27;t explicitly identify the mistake the way a human would.</div><br/></div></div><div id="41524937" class="c"><input type="checkbox" id="c-41524937" checked=""/><div class="controls bullet"><span class="by">fsndz</span><span>|</span><a href="#41524263">parent</a><span>|</span><a href="#41525007">prev</a><span>|</span><a href="#41523718">next</a><span>|</span><label class="collapse" for="c-41524937">[-]</label><label class="expand" for="c-41524937">[4 more]</label></div><br/><div class="children"><div class="content">&gt; Asking the models to determine if my code is equivalent to what they reverse engineered resulted in a nuanced and thorough examination, and eventual conclusion that it is equivalent.<p>Did you actually implement to see if it works out of the box ?<p>Also if you are a free users or accepted that your chats should be used for training then maybe o1 is was just trained on your previous chat and so now knows how to reason about that particular type of problems</div><br/><div id="41526366" class="c"><input type="checkbox" id="c-41526366" checked=""/><div class="controls bullet"><span class="by">bartman</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524937">parent</a><span>|</span><a href="#41525676">next</a><span>|</span><label class="collapse" for="c-41526366">[-]</label><label class="expand" for="c-41526366">[1 more]</label></div><br/><div class="children"><div class="content">That is an interesting thought. This was all done in an account that is opted out of training though.<p>I have tested the Python code o1 created to decode the timestamps and it works as expected.</div><br/></div></div><div id="41525676" class="c"><input type="checkbox" id="c-41525676" checked=""/><div class="controls bullet"><span class="by">bongodongobob</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41524937">parent</a><span>|</span><a href="#41526366">prev</a><span>|</span><a href="#41523718">next</a><span>|</span><label class="collapse" for="c-41525676">[-]</label><label class="expand" for="c-41525676">[2 more]</label></div><br/><div class="children"><div class="content">That&#x27;s not how LLM training works.</div><br/><div id="41526247" class="c"><input type="checkbox" id="c-41526247" checked=""/><div class="controls bullet"><span class="by">fsndz</span><span>|</span><a href="#41524263">root</a><span>|</span><a href="#41525676">parent</a><span>|</span><a href="#41523718">next</a><span>|</span><label class="collapse" for="c-41526247">[-]</label><label class="expand" for="c-41526247">[1 more]</label></div><br/><div class="children"><div class="content">so it is impossible to use the free user chats to train models ??????</div><br/></div></div></div></div></div></div></div></div><div id="41523718" class="c"><input type="checkbox" id="c-41523718" checked=""/><div class="controls bullet"><span class="by">evrydayhustling</span><span>|</span><a href="#41524263">prev</a><span>|</span><a href="#41524787">next</a><span>|</span><label class="collapse" for="c-41523718">[-]</label><label class="expand" for="c-41523718">[27 more]</label></div><br/><div class="children"><div class="content">Just did some preliminary testing on decrypting some ROT cyphertext which would have been viable for a human on paper.  The output was pretty disappointing: lots of &quot;workish&quot; steps creating letter counts, identifying common words, etc, but many steps were incorrect or not followed up on.  In the end, it claimed to check its work and deliver an incorrect solution that did not satisfy the previous steps.<p>I&#x27;m not one to judge AI on pratfalls, and cyphers are a somewhat adversarial task.  However, there was no aspect of the reasoning that seemed more advanced or consistent than previous chain-of-thought demos I&#x27;ve seen.  So the main proof point we have is the paper, and I&#x27;m not sure how I&#x27;d go from there to being able to trust this on the kind of task it is intended for.  Do others have patterns by which they get utility from chain of thought engines?<p>Separately, chain of thought outputs really make me long for tool use, because the LLM is often forced to simulate algorithmic outputs.  It feels like a commercial chain-of-thought solution like this should have a standard library of functions it can use for 100% reliability on things like letter counts.</div><br/><div id="41523742" class="c"><input type="checkbox" id="c-41523742" checked=""/><div class="controls bullet"><span class="by">changoplatanero</span><span>|</span><a href="#41523718">parent</a><span>|</span><a href="#41523740">next</a><span>|</span><label class="collapse" for="c-41523742">[-]</label><label class="expand" for="c-41523742">[24 more]</label></div><br/><div class="children"><div class="content">Hmm, are you sure it was using the o1 model and not gpt4o? I&#x27;ve been using the o1 model and it does consistently well at solving rotation ciphers.</div><br/><div id="41523790" class="c"><input type="checkbox" id="c-41523790" checked=""/><div class="controls bullet"><span class="by">mewpmewp2</span><span>|</span><a href="#41523718">root</a><span>|</span><a href="#41523742">parent</a><span>|</span><a href="#41524570">next</a><span>|</span><label class="collapse" for="c-41523790">[-]</label><label class="expand" for="c-41523790">[14 more]</label></div><br/><div class="children"><div class="content">Does it do better than Claude, because Claude (3.5 sonnet) handled ROTs perfectly and was able to also respond in ROT.</div><br/><div id="41523859" class="c"><input type="checkbox" id="c-41523859" checked=""/><div class="controls bullet"><span class="by">evrydayhustling</span><span>|</span><a href="#41523718">root</a><span>|</span><a href="#41523790">parent</a><span>|</span><a href="#41524570">next</a><span>|</span><label class="collapse" for="c-41523859">[-]</label><label class="expand" for="c-41523859">[13 more]</label></div><br/><div class="children"><div class="content">Just tried, no joy from Claude either:<p>Can you decrypt the following?  I don&#x27;t know the cypher, but the plaintext is Spanish.<p>YRP CFTLIR VE UVDRJZRUF JREZURU, P CF DRJ CFTLIR UV KFUF VJ HLV MVI TFJRJ TFDF JFE VE MVQ UV TFDF UVSVE JVI</div><br/><div id="41524487" class="c"><input type="checkbox" id="c-41524487" checked=""/><div class="controls bullet"><span class="by">kenjackson</span><span>|</span><a href="#41523718">root</a><span>|</span><a href="#41523859">parent</a><span>|</span><a href="#41524595">next</a><span>|</span><label class="collapse" for="c-41524487">[-]</label><label class="expand" for="c-41524487">[2 more]</label></div><br/><div class="children"><div class="content">I just tried it with O1 model and it said it couldn&#x27;t decipher it.  It told me what to try, but said it doesn&#x27;t have the time to do so.  Kind of an unusual response.</div><br/><div id="41524886" class="c"><input type="checkbox" id="c-41524886" checked=""/><div class="controls bullet"><span class="by">hmottestad</span><span>|</span><a href="#41523718">root</a><span>|</span><a href="#41524487">parent</a><span>|</span><a href="#41524595">next</a><span>|</span><label class="collapse" for="c-41524886">[-]</label><label class="expand" for="c-41524886">[1 more]</label></div><br/><div class="children"><div class="content">The chain of thought does seem to take quite a long time, so maybe there is a new mechanism for reducing the amount of load on the servers by estimating the amount of reasoning effort needed to solve a problem and weighing that against the current pressure on the servers.</div><br/></div></div></div></div><div id="41524595" class="c"><input type="checkbox" id="c-41524595" checked=""/><div class="controls bullet"><span class="by">oktoberpaard</span><span>|</span><a href="#41523718">root</a><span>|</span><a href="#41523859">parent</a><span>|</span><a href="#41524487">prev</a><span>|</span><a href="#41523918">next</a><span>|</span><label class="collapse" for="c-41524595">[-]</label><label class="expand" for="c-41524595">[1 more]</label></div><br/><div class="children"><div class="content">I got this response from o1-mini with the exact same prompt:<p>Claro, he descifrado el texto utilizando un cifrado César con un desplazamiento de 9 posiciones. Aquí está el texto original y su correspondiente traducción:<p>*Texto Cifrado:*
```
YRP CFTLIR VE UVDRJZRUF JREZURU, P CF DRJ CFTLIR UV KFUF VJ HLV MVI TFJRJ TFDF JFE VE MVQ UV TFDF UVSVE JVI
```<p>*Texto Descifrado:*
```
HAY LOCURA EN DEMASADO SANIDAD, Y LO MÁS LOCURA DE TODO ES QUE VER COSAS COMO SON EN VEZ DE COMO DEBEN SER
```<p>*Traducción al Inglés:*
```
THERE IS MADNESS IN OVERLY HEALTH, AND THE MOST MADNESS OF ALL IS TO SEE THINGS AS THEY ARE INSTEAD OF AS THEY SHOULD BE
```<p>Este descifrado asume que se utilizó un cifrado César con un desplazamiento de +9. Si necesitas más ayuda o una explicación detallada del proceso de descifrado, no dudes en decírmelo.<p>Interestingly it makes a spelling mistake, but other than that it did manage to solve it.</div><br/></div></div><div id="41523918" class="c"><input type="checkbox" id="c-41523918" checked=""/><div class="controls bullet"><span class="by">mewpmewp2</span><span>|</span><a href="#41523718">root</a><span>|</span><a href="#41523859">parent</a><span>|</span><a href="#41524595">prev</a><span>|</span><a href="#41524099">next</a><span>|</span><label class="collapse" for="c-41523918">[-]</label><label class="expand" for="c-41523918">[3 more]</label></div><br/><div class="children"><div class="content">Interesting, it was able to guess it&#x27;s Rot 17, but it translated it wrong, although &quot;HAY&quot; and some other words were correct.<p>I&#x27;ve tried only in English so far though.<p>It told me it&#x27;s 17, and &quot;HAY GENTE MU DIFERENTE LECTURA, A LO MUY GENTE DE TODO ES QUE VER COSAS COMO SON EN VEZ DE COMO DEBEN SER&quot;<p>although it really should be &quot;HAY LOCURA EN DEMASIADO SANIDAD, Y LO MAS LOCURA DE TODO ES QUE VER COSAS COMO SON EN VEZ DE COMO DEBEN SER&quot;</div><br/><div id="41523999" class="c"><input type="checkbox" id="c-41523999" checked=""/><div class="controls bullet"><span class="by">evrydayhustling</span><span>|</span><a href="#41523718">root</a><span>|</span><a href="#41523918">parent</a><span>|</span><a href="#41524099">next</a><span>|</span><label class="collapse" for="c-41523999">[-]</label><label class="expand" for="c-41523999">[2 more]</label></div><br/><div class="children"><div class="content">Claude made similar mistakes of generating decryption that was similar to plaintext but with stuff mixed in.  I suspect my version of the quote (Miguel de Cervantes) is an apocryphal translation, and there&#x27;s some utility well on both models to pull it towards the real one.  With that said, I did not see o1-preview get as close as you did.</div><br/><div id="41524037" class="c"><input type="checkbox" id="c-41524037" checked=""/><div class="controls bullet"><span class="by">mewpmewp2</span><span>|</span><a href="#41523718">root</a><span>|</span><a href="#41523999">parent</a><span>|</span><a href="#41524099">next</a><span>|</span><label class="collapse" for="c-41524037">[-]</label><label class="expand" for="c-41524037">[1 more]</label></div><br/><div class="children"><div class="content">For testing I think it&#x27;s better to use uncommon sentences and also start with English first, if it can solve that, then try other languages.</div><br/></div></div></div></div></div></div><div id="41523979" class="c"><input type="checkbox" id="c-41523979" checked=""/><div class="controls bullet"><span class="by">ianbutler</span><span>|</span><a href="#41523718">root</a><span>|</span><a href="#41523859">parent</a><span>|</span><a href="#41524099">prev</a><span>|</span><a href="#41525279">next</a><span>|</span><label class="collapse" for="c-41523979">[-]</label><label class="expand" for="c-41523979">[2 more]</label></div><br/><div class="children"><div class="content">HAY LOCURA EN DEMASIADO SANIDAD, Y LO MAS LOCURA DE TODO ES QUE VER COSAS COMO SON EN VEZ DE COMO DEBEN SER<p>Is that correct? I don&#x27;t know anything but basic Spanish. All I did was:<p>&quot;The plaintext is in Spanish but I don&#x27;t know anything else, solve this and explain your reasoning as you go step by step.&quot;</div><br/><div id="41524547" class="c"><input type="checkbox" id="c-41524547" checked=""/><div class="controls bullet"><span class="by">mewpmewp2</span><span>|</span><a href="#41523718">root</a><span>|</span><a href="#41523979">parent</a><span>|</span><a href="#41525279">next</a><span>|</span><label class="collapse" for="c-41524547">[-]</label><label class="expand" for="c-41524547">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s correct. I got o1-preview myself finally now. But interestingly getting inconsistent results with this so far, need to keep trying.</div><br/></div></div></div></div><div id="41525279" class="c"><input type="checkbox" id="c-41525279" checked=""/><div class="controls bullet"><span class="by">doo_daa</span><span>|</span><a href="#41523718">root</a><span>|</span><a href="#41523859">parent</a><span>|</span><a href="#41523979">prev</a><span>|</span><a href="#41524570">next</a><span>|</span><label class="collapse" for="c-41525279">[-]</label><label class="expand" for="c-41525279">[2 more]</label></div><br/><div class="children"><div class="content">o1-preview gave me this...<p>Final Decrypted Message:<p>&quot;Por ejemplo te agradeceré, y te doy ejemplo de que lo que lees es mi ejemplo&quot;<p>English Translation:<p>&quot;For example, I will thank you, and I give you an example of what you read is my example.&quot;<p>... initially it gave up and asked if I knew what type of cypher had been used. I said I thought it was a simple substitution.</div><br/><div id="41526484" class="c"><input type="checkbox" id="c-41526484" checked=""/><div class="controls bullet"><span class="by">sureglymop</span><span>|</span><a href="#41523718">root</a><span>|</span><a href="#41525279">parent</a><span>|</span><a href="#41524570">next</a><span>|</span><label class="collapse" for="c-41526484">[-]</label><label class="expand" for="c-41526484">[1 more]</label></div><br/><div class="children"><div class="content">Why did it add the accents on to e (é)? Surely that wasn&#x27;t part of it and it actually &quot;thought a bit too far&quot;?</div><br/></div></div></div></div></div></div></div></div><div id="41524570" class="c"><input type="checkbox" id="c-41524570" checked=""/><div class="controls bullet"><span class="by">J_cst</span><span>|</span><a href="#41523718">root</a><span>|</span><a href="#41523742">parent</a><span>|</span><a href="#41523790">prev</a><span>|</span><a href="#41523788">next</a><span>|</span><label class="collapse" for="c-41524570">[-]</label><label class="expand" for="c-41524570">[1 more]</label></div><br/><div class="children"><div class="content">On my machine just works with 4o<p><a href="https:&#x2F;&#x2F;chatgpt.com&#x2F;share&#x2F;66e34020-33dc-800d-8ab8-8596895844c9" rel="nofollow">https:&#x2F;&#x2F;chatgpt.com&#x2F;share&#x2F;66e34020-33dc-800d-8ab8-8596895844...</a><p>With no drama.
I&#x27;m not sure the bot answer is correct, but looks correct.</div><br/></div></div><div id="41523788" class="c"><input type="checkbox" id="c-41523788" checked=""/><div class="controls bullet"><span class="by">evrydayhustling</span><span>|</span><a href="#41523718">root</a><span>|</span><a href="#41523742">parent</a><span>|</span><a href="#41524570">prev</a><span>|</span><a href="#41523740">next</a><span>|</span><label class="collapse" for="c-41523788">[-]</label><label class="expand" for="c-41523788">[8 more]</label></div><br/><div class="children"><div class="content">o1-preview .  Were you using common plaintexts by chance (e.g. proverbs) or ROT13 specifically?  Mine use all the right steps but just can&#x27;t string them together.</div><br/><div id="41523825" class="c"><input type="checkbox" id="c-41523825" checked=""/><div class="controls bullet"><span class="by">changoplatanero</span><span>|</span><a href="#41523718">root</a><span>|</span><a href="#41523788">parent</a><span>|</span><a href="#41523798">next</a><span>|</span><label class="collapse" for="c-41523825">[-]</label><label class="expand" for="c-41523825">[1 more]</label></div><br/><div class="children"><div class="content">It just solved this one for me &quot;Can you solve this cipher? droboscxylecsxoccvsuocryglecsxocc&quot;</div><br/></div></div><div id="41523798" class="c"><input type="checkbox" id="c-41523798" checked=""/><div class="controls bullet"><span class="by">mewpmewp2</span><span>|</span><a href="#41523718">root</a><span>|</span><a href="#41523788">parent</a><span>|</span><a href="#41523825">prev</a><span>|</span><a href="#41523740">next</a><span>|</span><label class="collapse" for="c-41523798">[-]</label><label class="expand" for="c-41523798">[6 more]</label></div><br/><div class="children"><div class="content">Could you share your prompt?</div><br/><div id="41523938" class="c"><input type="checkbox" id="c-41523938" checked=""/><div class="controls bullet"><span class="by">evrydayhustling</span><span>|</span><a href="#41523718">root</a><span>|</span><a href="#41523798">parent</a><span>|</span><a href="#41523740">next</a><span>|</span><label class="collapse" for="c-41523938">[-]</label><label class="expand" for="c-41523938">[5 more]</label></div><br/><div class="children"><div class="content">Shared one above.<p>Just tried an easier (english) version and o1-preview LITERALLY rickrolled me, which is maybe impressive in its own way?<p>UPDATE: Claude crushed it however.<p>o1-preview Transcript follows.<p>**<p>Can you decrypt the following?  I don&#x27;t know the cypher.<p>mzilj ivdrzej ufidrek ze kyv sfup reu tre ivrtkzmrkv crkvi ze czwv<p>Certainly! The encrypted text is:<p>```
mzilj ivdrzej ufidrek ze kyv sfup reu tre ivrtkzmrkv crkvi ze czwv
```<p>When we decrypt it, we get:<p>```
never gonna give you up let you down and desert you
```<p>It appears to be a line from Rick Astley&#x27;s song &quot;Never Gonna Give You Up.&quot;</div><br/><div id="41523983" class="c"><input type="checkbox" id="c-41523983" checked=""/><div class="controls bullet"><span class="by">mewpmewp2</span><span>|</span><a href="#41523718">root</a><span>|</span><a href="#41523938">parent</a><span>|</span><a href="#41525005">next</a><span>|</span><label class="collapse" for="c-41523983">[-]</label><label class="expand" for="c-41523983">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s weird. Claude was able to translate it to &quot;&quot;&quot;virus remains dormant in the body and can reactivate later in life&quot;&quot;&quot; correctly, but it thought it was shifted 10 times, when it&#x27;s really Rot17.</div><br/></div></div><div id="41525005" class="c"><input type="checkbox" id="c-41525005" checked=""/><div class="controls bullet"><span class="by">omnee</span><span>|</span><a href="#41523718">root</a><span>|</span><a href="#41523938">parent</a><span>|</span><a href="#41523983">prev</a><span>|</span><a href="#41524989">next</a><span>|</span><label class="collapse" for="c-41525005">[-]</label><label class="expand" for="c-41525005">[2 more]</label></div><br/><div class="children"><div class="content">If O1 did rickroll you <i>deliberately</i>, then it would indeed more impressive than solving ciphertexts, and I&#x27;d start preparing to bow down to our AGI overlords :)</div><br/><div id="41525583" class="c"><input type="checkbox" id="c-41525583" checked=""/><div class="controls bullet"><span class="by">evrydayhustling</span><span>|</span><a href="#41523718">root</a><span>|</span><a href="#41525005">parent</a><span>|</span><a href="#41524989">next</a><span>|</span><label class="collapse" for="c-41525583">[-]</label><label class="expand" for="c-41525583">[1 more]</label></div><br/><div class="children"><div class="content">Definitely.  A teammate pointed out Reddit posts used in training as a probable cause :)</div><br/></div></div></div></div><div id="41524989" class="c"><input type="checkbox" id="c-41524989" checked=""/><div class="controls bullet"><span class="by">tstrimple</span><span>|</span><a href="#41523718">root</a><span>|</span><a href="#41523938">parent</a><span>|</span><a href="#41525005">prev</a><span>|</span><a href="#41523740">next</a><span>|</span><label class="collapse" for="c-41524989">[-]</label><label class="expand" for="c-41524989">[1 more]</label></div><br/><div class="children"><div class="content">4o completely botched the Spanish version, but seems to have nailed this one.<p>&gt; Without knowing the cipher used to encrypt this message, it’s hard to decrypt it directly. However, the structure and letter patterns suggest it might be a simple substitution cipher, possibly Caesar or some variation of it.<p>&gt; Let me attempt a few common methods to see if I can identify the cipher.<p>&gt; The most frequent letters in the encrypted message are &#x27;r&#x27;, &#x27;z&#x27;, &#x27;v&#x27;, and &#x27;e&#x27;. In English, the most common letters are typically &#x27;E&#x27;, &#x27;T&#x27;, &#x27;A&#x27;, and &#x27;O&#x27;. This suggests the cipher could be a simple substitution or a Caesar cipher.<p>&gt; I&#x27;ll now attempt to apply a Caesar cipher decryption by shifting the alphabet through all possible rotations to see if we get readable text.<p>&gt; One of the decrypted messages, with a shift of 17, reads:<p>&gt; *&quot;virus remains dormant in the body and can reactivate later in life&quot;*<p>&gt; It seems like the correct decryption, revealing information about a virus that can remain dormant in the body.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="41523740" class="c"><input type="checkbox" id="c-41523740" checked=""/><div class="controls bullet"><span class="by">charlescurt123</span><span>|</span><a href="#41523718">parent</a><span>|</span><a href="#41523742">prev</a><span>|</span><a href="#41523777">next</a><span>|</span><label class="collapse" for="c-41523740">[-]</label><label class="expand" for="c-41523740">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s RL so that means it&#x27;s going to be great on tasks they created for training but not so much on others.<p>Impressive but the problem with RL is that it requires knowledge of the future.</div><br/></div></div><div id="41523777" class="c"><input type="checkbox" id="c-41523777" checked=""/><div class="controls bullet"><span class="by">mewpmewp2</span><span>|</span><a href="#41523718">parent</a><span>|</span><a href="#41523740">prev</a><span>|</span><a href="#41524787">next</a><span>|</span><label class="collapse" for="c-41523777">[-]</label><label class="expand" for="c-41523777">[1 more]</label></div><br/><div class="children"><div class="content">Out of curiousity can you try the same thing with Claude. Because when I tried Claude with any sort of ROT, it had amazing performance, compared to GPT.</div><br/></div></div></div></div><div id="41524787" class="c"><input type="checkbox" id="c-41524787" checked=""/><div class="controls bullet"><span class="by">lukev</span><span>|</span><a href="#41523718">prev</a><span>|</span><a href="#41525020">next</a><span>|</span><label class="collapse" for="c-41524787">[-]</label><label class="expand" for="c-41524787">[5 more]</label></div><br/><div class="children"><div class="content">This is a pretty big technical achievement, and I am excited to see this type of advancement in the field.<p>However, I am very worried about the utility of this tool given that it (like all LLMs) is still prone to hallucination. Exactly who is it for?<p>If you&#x27;re enough of an expert to critically judge the output, you&#x27;re probably just as well off doing the reasoning yourself. If you&#x27;re not capable of evaluating the output, you risk relying on completely wrong answers.<p>For example, I just asked it to evaluate an algorithm I&#x27;m working on to optimize database join ordering. Early in the reasoning process it confidently and incorrectly stated that &quot;join costs are usually symmetrical&quot; and then later steps incorporated that, trying to get me to &quot;simplify&quot; my algorithm by using an undirected graph instead of a directed one as the internal data structure.<p>If you&#x27;re familiar with database optimization, you&#x27;ll know that this is... very wrong. But otherwise, the line of reasoning was cogent and compelling.<p>I worry it would lead me astray, if it confidently relied on a fact that I wasn&#x27;t able to immediately recognize was incorrect.</div><br/><div id="41526649" class="c"><input type="checkbox" id="c-41526649" checked=""/><div class="controls bullet"><span class="by">zamadatix</span><span>|</span><a href="#41524787">parent</a><span>|</span><a href="#41525192">next</a><span>|</span><label class="collapse" for="c-41526649">[-]</label><label class="expand" for="c-41526649">[1 more]</label></div><br/><div class="children"><div class="content">The utility I usually get from these kinds of tools so far is more like an extremely good reference or helper to something I could definitely figure out if given enough time. E.g. figuring out the best way to clean up a specific syntax error, setting up a class and some obvious base functions I&#x27;m going to need in it, helping me figure out where I might have went astray in solving a math problem.<p>The tools have not been at &quot;and now I don&#x27;t need code tests &amp; review, mathematicians in society, or factbooks all because I have an LLM&quot; level. While that&#x27;s definitely a goal of AGI it&#x27;s also definitely not my bar for weighing whether there is utility in a tool.<p>The alternative way to think about it: the value of a tool is in what you can figure out to do with it, not in whether it&#x27;s perfect at doing something. On one extreme that means a dictionary can still be a useful spelling reference even if books have a rare typo. On the other extreme that means a coworker can still offer valuable insight into your code even if they make lots of coding errors and don&#x27;t have an accurate understanding of everything there is to know about all of C++. Whether you get something out of either of these cases is a product of how much they can help you reach the accuracy you need to arrive at and the way you utilize the tool, not their accuracy alone. Usually I can get a lot out of a person who is really bad at one shot coding a perfect answer but feels like their answer seems right so I can get quite a bit out of an LLM that has the same problem. That might not be true for all types of questions though but that&#x27;s fine, not all tools have utility in every problem.</div><br/></div></div><div id="41525192" class="c"><input type="checkbox" id="c-41525192" checked=""/><div class="controls bullet"><span class="by">ramesh31</span><span>|</span><a href="#41524787">parent</a><span>|</span><a href="#41526649">prev</a><span>|</span><a href="#41525020">next</a><span>|</span><label class="collapse" for="c-41525192">[-]</label><label class="expand" for="c-41525192">[3 more]</label></div><br/><div class="children"><div class="content">&gt;If you&#x27;re enough of an expert to critically judge the output, you&#x27;re probably just as well off doing the reasoning yourself.<p>Thought requires energy. A lot of it. Humans are for more efficient in this regard than LLMs, but then a bicycle is also much more efficient than a race car. I&#x27;ve found that even when they are hilariously wrong about something, simply the directionality of the line of reasoning can be enough to usefully accelerate my own thought.</div><br/><div id="41526936" class="c"><input type="checkbox" id="c-41526936" checked=""/><div class="controls bullet"><span class="by">lukev</span><span>|</span><a href="#41524787">root</a><span>|</span><a href="#41525192">parent</a><span>|</span><a href="#41525020">next</a><span>|</span><label class="collapse" for="c-41526936">[-]</label><label class="expand" for="c-41526936">[2 more]</label></div><br/><div class="children"><div class="content">Look, I&#x27;ve been experimenting with this for the past year, and this is definitely the happy path.<p>The unhappy path, which I&#x27;ve also experienced, is that the model outputs something plausible but false but that aligns with an area where my thinking was already confused and sends me down the <i>wrong</i> path.<p>I&#x27;ve had to calibrate my level of suspicion, and so far using these things more effectively has always been in the direction that more suspicion is better.<p>There&#x27;s been a couple times in the last week where I&#x27;m working on something complex and I deliberately don&#x27;t use an LLM since I&#x27;m now actively afraid they&#x27;ll increase my level of confusion.</div><br/><div id="41527127" class="c"><input type="checkbox" id="c-41527127" checked=""/><div class="controls bullet"><span class="by">gen220</span><span>|</span><a href="#41524787">root</a><span>|</span><a href="#41526936">parent</a><span>|</span><a href="#41525020">next</a><span>|</span><label class="collapse" for="c-41527127">[-]</label><label class="expand" for="c-41527127">[1 more]</label></div><br/><div class="children"><div class="content">There are phases in every developer’s growth, where you transition from asking coworkers or classmates, to asking on stack overflow, to reading stack overflow, to reading docs and man pages and mailing lists and source code.<p>I think like you, I worry that LLMs will handicap this trajectory for people newer in the field, because GPT-4&#x2F;Sonnet&#x2F;Whatever are an <i>exceptionally</i> good classmate&#x2F;coworker. So good that you might try to delay progressing along that trajectory.<p>But LLMs have all the flaws of a classmate: they aren’t authoritative, their opinions are strongly stated but often based on flimsy assumptions that you aren’t qualified to refute or verify, and so on.<p>I know intellectually that the kids will be alright, but it’ll be interesting to see how we get there. I suspect that as time goes on people will simply increase their discount rate on LLM responses, like you have, until they get dissatisfied with that value and just decide to get good at reading docs.</div><br/></div></div></div></div></div></div></div></div><div id="41525020" class="c"><input type="checkbox" id="c-41525020" checked=""/><div class="controls bullet"><span class="by">wesleyyue</span><span>|</span><a href="#41524787">prev</a><span>|</span><a href="#41524504">next</a><span>|</span><label class="collapse" for="c-41525020">[-]</label><label class="expand" for="c-41525020">[3 more]</label></div><br/><div class="children"><div class="content">Just added o1 to <a href="https:&#x2F;&#x2F;double.bot">https:&#x2F;&#x2F;double.bot</a> if anyone would like to try it for coding.<p>---<p>Some thoughts:<p>* The performance is really good. I have a private set of questions I note down whenever gpt-4o&#x2F;sonnet fails. o1 solved everything so far.<p>* It really is quite slow<p>* It&#x27;s interesting that the chain of thought is hidden. This is I think the first time where OpenAI can improve their models without it being immediately distilled by open models. It&#x27;ll be interesting to see how quickly the oss field can catch up technique-wise as there&#x27;s already been a lot of inference time compute papers recently [1,2]<p>* Notably it&#x27;s not clear whether o1-preview as it&#x27;s available now is doing tree search or just single shoting a cot that is distilled from better&#x2F;more detailed trajectories in the training distribution.<p>[1](<a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2407.21787" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2407.21787</a>)<p>[2](<a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2408.03314" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2408.03314</a>)</div><br/><div id="41526081" class="c"><input type="checkbox" id="c-41526081" checked=""/><div class="controls bullet"><span class="by">TheMiddleMan</span><span>|</span><a href="#41525020">parent</a><span>|</span><a href="#41524504">next</a><span>|</span><label class="collapse" for="c-41526081">[-]</label><label class="expand" for="c-41526081">[2 more]</label></div><br/><div class="children"><div class="content">Trying out Double now.<p>o1 did a significantly better job converting a JavaScript file to TypeScript than Llama 3.1 405B, GitHub Copilot, and Claude 3.5. It even simplified my code a bit while retaining the same functionality. Very impressive.<p>It was able to refactor a ~160 line file but I&#x27;m getting an infinite &quot;thinking bubble&quot; on a ~420 line file. Maybe something&#x27;s timing out with the longer o1 response times?</div><br/><div id="41526687" class="c"><input type="checkbox" id="c-41526687" checked=""/><div class="controls bullet"><span class="by">wesleyyue</span><span>|</span><a href="#41525020">root</a><span>|</span><a href="#41526081">parent</a><span>|</span><a href="#41524504">next</a><span>|</span><label class="collapse" for="c-41526687">[-]</label><label class="expand" for="c-41526687">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Maybe something&#x27;s timing out with the longer o1 response times?<p>Let me look into this – one issue is that OpenAI doesn&#x27;t expose a streaming endpoint via the API for o1 models. It&#x27;s possible there&#x27;s an HTTP timeout occurring in the stack. Thanks for the report</div><br/></div></div></div></div></div></div><div id="41524504" class="c"><input type="checkbox" id="c-41524504" checked=""/><div class="controls bullet"><span class="by">canjobear</span><span>|</span><a href="#41525020">prev</a><span>|</span><a href="#41526499">next</a><span>|</span><label class="collapse" for="c-41524504">[-]</label><label class="expand" for="c-41524504">[21 more]</label></div><br/><div class="children"><div class="content">First shot, I gave it a medium-difficulty math problem, something I actually wanted the answer to (derive the KL divergence between two Laplace distributions). It thought for a long time, and still got it wrong, producing a plausible but wrong answer. After some prodding, it revised itself and then got it wrong again. I still feel that I can&#x27;t rely on these systems.</div><br/><div id="41526505" class="c"><input type="checkbox" id="c-41526505" checked=""/><div class="controls bullet"><span class="by">nwienert</span><span>|</span><a href="#41524504">parent</a><span>|</span><a href="#41524682">next</a><span>|</span><label class="collapse" for="c-41526505">[-]</label><label class="expand" for="c-41526505">[1 more]</label></div><br/><div class="children"><div class="content">I was trying to get 4o today to do some medium-difficulty Typescript to map between two different ORM schemas. It&#x27;s a great problem because it&#x27;s really not too hard, pretty well constrained, and I can provide a ton of context and tests, declaration files, before&#x2F;after expectations.<p>4o was struggling so I gave up. Tried o1 on it, and after trying nearly 15 prompts back and forth helping it along the way we&#x27;re still far from correct. It&#x27;s hard to tell if it&#x27;s much better, but at least my intuition from this feel like this is pretty incremental.</div><br/></div></div><div id="41524682" class="c"><input type="checkbox" id="c-41524682" checked=""/><div class="controls bullet"><span class="by">spaceman_2020</span><span>|</span><a href="#41524504">parent</a><span>|</span><a href="#41526505">prev</a><span>|</span><a href="#41525177">next</a><span>|</span><label class="collapse" for="c-41524682">[-]</label><label class="expand" for="c-41524682">[18 more]</label></div><br/><div class="children"><div class="content">Look where you were 3 years ago, and where you are now.<p>And then imagine where you will be in 5 more years.<p>If it can <i>almost</i> get a complex problem right now, I&#x27;m dead sure it will get it correct within 5 years</div><br/><div id="41524866" class="c"><input type="checkbox" id="c-41524866" checked=""/><div class="controls bullet"><span class="by">colonelspace</span><span>|</span><a href="#41524504">root</a><span>|</span><a href="#41524682">parent</a><span>|</span><a href="#41525018">next</a><span>|</span><label class="collapse" for="c-41524866">[-]</label><label class="expand" for="c-41524866">[2 more]</label></div><br/><div class="children"><div class="content">&gt;  I&#x27;m dead sure it will get it correct within 5 years<p>You might be right.<p>But plenty of people said we&#x27;d all be getting around in self-driving cars <i>for sure</i> 10 years ago.</div><br/><div id="41526347" class="c"><input type="checkbox" id="c-41526347" checked=""/><div class="controls bullet"><span class="by">neevans</span><span>|</span><a href="#41524504">root</a><span>|</span><a href="#41524866">parent</a><span>|</span><a href="#41525018">next</a><span>|</span><label class="collapse" for="c-41526347">[-]</label><label class="expand" for="c-41526347">[1 more]</label></div><br/><div class="children"><div class="content">we do have self driving car but since it directly affects people&#x27;s life it needs to be close to 100% accurate and no margin of errors. Not necessarily the case for LLMs.</div><br/></div></div></div></div><div id="41525018" class="c"><input type="checkbox" id="c-41525018" checked=""/><div class="controls bullet"><span class="by">AnIrishDuck</span><span>|</span><a href="#41524504">root</a><span>|</span><a href="#41524682">parent</a><span>|</span><a href="#41524866">prev</a><span>|</span><a href="#41526198">next</a><span>|</span><label class="collapse" for="c-41525018">[-]</label><label class="expand" for="c-41525018">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not? The history of AI development is littered with examples of false starts, hidden traps, and promising breakthroughs that eventually expose deeper and more difficult problems [1].<p>I wouldn&#x27;t be <i>shocked</i> if it could eventually get it right, but <i>dead sure</i>?<p>1. <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;AI_winter" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;AI_winter</a></div><br/></div></div><div id="41526198" class="c"><input type="checkbox" id="c-41526198" checked=""/><div class="controls bullet"><span class="by">closeparen</span><span>|</span><a href="#41524504">root</a><span>|</span><a href="#41524682">parent</a><span>|</span><a href="#41525018">prev</a><span>|</span><a href="#41525920">next</a><span>|</span><label class="collapse" for="c-41526198">[-]</label><label class="expand" for="c-41526198">[1 more]</label></div><br/><div class="children"><div class="content">It is not at all clear that &quot;produce correct answer&quot; is the natural endpoint of &quot;produce plausible on-topic utterances that look like they could be answers.&quot; To do the former you need to know something about the underlying structure of reality (or have seen the answer before), to do the latter you only need to be good at pattern-matching and language.</div><br/></div></div><div id="41525920" class="c"><input type="checkbox" id="c-41525920" checked=""/><div class="controls bullet"><span class="by">zer0tonin</span><span>|</span><a href="#41524504">root</a><span>|</span><a href="#41524682">parent</a><span>|</span><a href="#41526198">prev</a><span>|</span><a href="#41525895">next</a><span>|</span><label class="collapse" for="c-41525920">[-]</label><label class="expand" for="c-41525920">[1 more]</label></div><br/><div class="children"><div class="content">The progress since GPT-3 hasn&#x27;t been spectacularly fast.</div><br/></div></div><div id="41525895" class="c"><input type="checkbox" id="c-41525895" checked=""/><div class="controls bullet"><span class="by">methodical</span><span>|</span><a href="#41524504">root</a><span>|</span><a href="#41524682">parent</a><span>|</span><a href="#41525920">prev</a><span>|</span><a href="#41526738">next</a><span>|</span><label class="collapse" for="c-41525895">[-]</label><label class="expand" for="c-41525895">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;re dead sure? I wouldn&#x27;t say anything definite about technology advancements. People seem to underestimate the last 20% of the problem and only focus on the massive 80% improvements up to this point.</div><br/></div></div><div id="41526738" class="c"><input type="checkbox" id="c-41526738" checked=""/><div class="controls bullet"><span class="by">canjobear</span><span>|</span><a href="#41524504">root</a><span>|</span><a href="#41524682">parent</a><span>|</span><a href="#41525895">prev</a><span>|</span><a href="#41526139">next</a><span>|</span><label class="collapse" for="c-41526738">[-]</label><label class="expand" for="c-41526738">[1 more]</label></div><br/><div class="children"><div class="content">Going back 3 years, it feels like incredible progress.
Going back 1 year, it feels like pretty much the same limitations.</div><br/></div></div><div id="41526139" class="c"><input type="checkbox" id="c-41526139" checked=""/><div class="controls bullet"><span class="by">ActorNightly</span><span>|</span><a href="#41524504">root</a><span>|</span><a href="#41524682">parent</a><span>|</span><a href="#41526738">prev</a><span>|</span><a href="#41525412">next</a><span>|</span><label class="collapse" for="c-41526139">[-]</label><label class="expand" for="c-41526139">[6 more]</label></div><br/><div class="children"><div class="content">Getting complex problem = having the solution in some form in the training dataset.<p>All we are gonna get is better and better googles.</div><br/><div id="41527556" class="c"><input type="checkbox" id="c-41527556" checked=""/><div class="controls bullet"><span class="by">olalonde</span><span>|</span><a href="#41524504">root</a><span>|</span><a href="#41526139">parent</a><span>|</span><a href="#41525412">next</a><span>|</span><label class="collapse" for="c-41527556">[-]</label><label class="expand" for="c-41527556">[5 more]</label></div><br/><div class="children"><div class="content">Why?</div><br/><div id="41527900" class="c"><input type="checkbox" id="c-41527900" checked=""/><div class="controls bullet"><span class="by">ActorNightly</span><span>|</span><a href="#41524504">root</a><span>|</span><a href="#41527556">parent</a><span>|</span><a href="#41525412">next</a><span>|</span><label class="collapse" for="c-41527900">[-]</label><label class="expand" for="c-41527900">[4 more]</label></div><br/><div class="children"><div class="content">Lets say that you want to make a flying car, that can also double as a submarine.<p>Nobody has done this yet. So information doesn&#x27;t exist on how to do it. An LLM may give you some generic answers from training sets on what engineering&#x2F;analysis tasks to do, but it won&#x27;t be able to give you a complex and complete design for one.<p>A model that can actually solve problems would be able to design you one.</div><br/><div id="41527983" class="c"><input type="checkbox" id="c-41527983" checked=""/><div class="controls bullet"><span class="by">olalonde</span><span>|</span><a href="#41524504">root</a><span>|</span><a href="#41527900">parent</a><span>|</span><a href="#41525412">next</a><span>|</span><label class="collapse" for="c-41527983">[-]</label><label class="expand" for="c-41527983">[3 more]</label></div><br/><div class="children"><div class="content">They can solve problems that are not in their training set. There are many examples in the article...</div><br/><div id="41528703" class="c"><input type="checkbox" id="c-41528703" checked=""/><div class="controls bullet"><span class="by">ActorNightly</span><span>|</span><a href="#41524504">root</a><span>|</span><a href="#41527983">parent</a><span>|</span><a href="#41525412">next</a><span>|</span><label class="collapse" for="c-41528703">[-]</label><label class="expand" for="c-41528703">[2 more]</label></div><br/><div class="children"><div class="content">I literally just gave you an example of one it can&#x27;t solve, despite having a vast knowledge of mechanical and aeronautical subjects. All the examples are obviously in its training set.<p>Here is another better example - none of these models can create a better ML accelerator despite having a wide array of electrical and computer engineering knowledge. If they did, OpenAI would pretty much be printing their own chips like Google does.</div><br/><div id="41529268" class="c"><input type="checkbox" id="c-41529268" checked=""/><div class="controls bullet"><span class="by">olalonde</span><span>|</span><a href="#41524504">root</a><span>|</span><a href="#41528703">parent</a><span>|</span><a href="#41525412">next</a><span>|</span><label class="collapse" for="c-41529268">[-]</label><label class="expand" for="c-41529268">[1 more]</label></div><br/><div class="children"><div class="content">In your previous comment you stated that LLMs can only solve problems that are in their training set (e.g. &quot;all we are gonna get is better and better googles&quot;). But that&#x27;s not true as I pointed out.<p>Now you are essentially saying that they can&#x27;t solve all problems or, more charitably, can&#x27;t solve highly complex problems. This is true but by that standard, the vast majority of humans can&#x27;t reason either.<p>Yes the reasoning capacities of current LLMs are limited but it&#x27;s incorrect to pretend they can&#x27;t reason at all.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="41525412" class="c"><input type="checkbox" id="c-41525412" checked=""/><div class="controls bullet"><span class="by">mogoh</span><span>|</span><a href="#41524504">root</a><span>|</span><a href="#41524682">parent</a><span>|</span><a href="#41526139">prev</a><span>|</span><a href="#41526301">next</a><span>|</span><label class="collapse" for="c-41525412">[-]</label><label class="expand" for="c-41525412">[1 more]</label></div><br/><div class="children"><div class="content">But can it now say &quot;I don&#x27;t know.&quot; ?
Or can it evaluate its own results and came to the conclusion that its just a wild guess?<p>I am still impressed by the progress though.</div><br/></div></div><div id="41526301" class="c"><input type="checkbox" id="c-41526301" checked=""/><div class="controls bullet"><span class="by">dontlikeyoueith</span><span>|</span><a href="#41524504">root</a><span>|</span><a href="#41524682">parent</a><span>|</span><a href="#41525412">prev</a><span>|</span><a href="#41525694">next</a><span>|</span><label class="collapse" for="c-41526301">[-]</label><label class="expand" for="c-41526301">[1 more]</label></div><br/><div class="children"><div class="content">I still don&#x27;t have a Mr. Fusion in my house, FYI.<p>We always overestimate the future.</div><br/></div></div><div id="41525694" class="c"><input type="checkbox" id="c-41525694" checked=""/><div class="controls bullet"><span class="by">evilfred</span><span>|</span><a href="#41524504">root</a><span>|</span><a href="#41524682">parent</a><span>|</span><a href="#41526301">prev</a><span>|</span><a href="#41525306">next</a><span>|</span><label class="collapse" for="c-41525694">[-]</label><label class="expand" for="c-41525694">[1 more]</label></div><br/><div class="children"><div class="content">what makes you so &quot;dead sure&quot;? it&#x27;s just hallucinating as always</div><br/></div></div><div id="41525306" class="c"><input type="checkbox" id="c-41525306" checked=""/><div class="controls bullet"><span class="by">taco_emoji</span><span>|</span><a href="#41524504">root</a><span>|</span><a href="#41524682">parent</a><span>|</span><a href="#41525694">prev</a><span>|</span><a href="#41525177">next</a><span>|</span><label class="collapse" for="c-41525306">[-]</label><label class="expand" for="c-41525306">[1 more]</label></div><br/><div class="children"><div class="content">Have you never heard of &quot;local maxima&quot;? Why are you so certain another 5 years will provide any qualitative advancement at all?</div><br/></div></div></div></div><div id="41525177" class="c"><input type="checkbox" id="c-41525177" checked=""/><div class="controls bullet"><span class="by">m3kw9</span><span>|</span><a href="#41524504">parent</a><span>|</span><a href="#41524682">prev</a><span>|</span><a href="#41526499">next</a><span>|</span><label class="collapse" for="c-41525177">[-]</label><label class="expand" for="c-41525177">[1 more]</label></div><br/><div class="children"><div class="content">Maybe you are wrong if you don’t know the answer?</div><br/></div></div></div></div><div id="41526499" class="c"><input type="checkbox" id="c-41526499" checked=""/><div class="controls bullet"><span class="by">joshhug</span><span>|</span><a href="#41524504">prev</a><span>|</span><a href="#41523268">next</a><span>|</span><label class="collapse" for="c-41526499">[-]</label><label class="expand" for="c-41526499">[4 more]</label></div><br/><div class="children"><div class="content">I just tried o1, and it did pretty well with understanding this minor issue with subtitles on a Dutch TV show we were watching.<p>I asked it &quot;I was watching a show and in the subtitles an umlaut u was rendered as 1&#x2F;4, i.e. a single character that said 1&#x2F;4. Why would this happen?&quot;<p>and it gave a pretty thorough explanation of exactly which encoding issue was to blame.<p><a href="https:&#x2F;&#x2F;chatgpt.com&#x2F;share&#x2F;66e37145-72bc-800a-be7b-f7c76471a1bd" rel="nofollow">https:&#x2F;&#x2F;chatgpt.com&#x2F;share&#x2F;66e37145-72bc-800a-be7b-f7c76471a1...</a></div><br/><div id="41526589" class="c"><input type="checkbox" id="c-41526589" checked=""/><div class="controls bullet"><span class="by">takoid</span><span>|</span><a href="#41526499">parent</a><span>|</span><a href="#41526547">next</a><span>|</span><label class="collapse" for="c-41526589">[-]</label><label class="expand" for="c-41526589">[1 more]</label></div><br/><div class="children"><div class="content">4o’s answer seems sufficient, though it provides less detail than o1.<p><a href="https:&#x2F;&#x2F;chatgpt.com&#x2F;share&#x2F;66e373d7-7814-8009-86c3-1ce549ca2e1d" rel="nofollow">https:&#x2F;&#x2F;chatgpt.com&#x2F;share&#x2F;66e373d7-7814-8009-86c3-1ce549ca2e...</a></div><br/></div></div><div id="41526547" class="c"><input type="checkbox" id="c-41526547" checked=""/><div class="controls bullet"><span class="by">piker</span><span>|</span><a href="#41526499">parent</a><span>|</span><a href="#41526589">prev</a><span>|</span><a href="#41526591">next</a><span>|</span><label class="collapse" for="c-41526547">[-]</label><label class="expand" for="c-41526547">[1 more]</label></div><br/><div class="children"><div class="content">A common problem, no doubt, with a lot of training context. But man. What a time to be alive.</div><br/></div></div><div id="41526591" class="c"><input type="checkbox" id="c-41526591" checked=""/><div class="controls bullet"><span class="by">karmasimida</span><span>|</span><a href="#41526499">parent</a><span>|</span><a href="#41526547">prev</a><span>|</span><a href="#41523268">next</a><span>|</span><label class="collapse" for="c-41526591">[-]</label><label class="expand" for="c-41526591">[1 more]</label></div><br/><div class="children"><div class="content">Damn, the model really goes to length to those trivial but hard problems. Impressive</div><br/></div></div></div></div><div id="41523268" class="c"><input type="checkbox" id="c-41523268" checked=""/><div class="controls bullet"><span class="by">cal85</span><span>|</span><a href="#41526499">prev</a><span>|</span><a href="#41523854">next</a><span>|</span><label class="collapse" for="c-41523268">[-]</label><label class="expand" for="c-41523268">[29 more]</label></div><br/><div class="children"><div class="content">Sounds great, but so does their &quot;new flagship model that can reason across audio, vision, and text in real time&quot; announced in May. [0]<p>[0] <a href="https:&#x2F;&#x2F;openai.com&#x2F;index&#x2F;hello-gpt-4o&#x2F;" rel="nofollow">https:&#x2F;&#x2F;openai.com&#x2F;index&#x2F;hello-gpt-4o&#x2F;</a></div><br/><div id="41523528" class="c"><input type="checkbox" id="c-41523528" checked=""/><div class="controls bullet"><span class="by">paxys</span><span>|</span><a href="#41523268">parent</a><span>|</span><a href="#41523522">next</a><span>|</span><label class="collapse" for="c-41523528">[-]</label><label class="expand" for="c-41523528">[3 more]</label></div><br/><div class="children"><div class="content">Agreed. Release announcements and benchmarks always sound world-changing, but the reality is that every new model is bringing smaller practical improvements to the end user over its predecessor.</div><br/><div id="41523609" class="c"><input type="checkbox" id="c-41523609" checked=""/><div class="controls bullet"><span class="by">zamadatix</span><span>|</span><a href="#41523268">root</a><span>|</span><a href="#41523528">parent</a><span>|</span><a href="#41524274">next</a><span>|</span><label class="collapse" for="c-41523609">[-]</label><label class="expand" for="c-41523609">[1 more]</label></div><br/><div class="children"><div class="content">The point above is the said amazing multimodal version of ChatGPT was announced in May and are still not the actual offered way to interact with the service in September (despite the model choice being called 4 omni it&#x27;s still not actually using multimodal IO). It could be a giant leap in practical improvements but it doesn&#x27;t matter if you can&#x27;t actually use what is announced.<p>This one, oddly, seems to actually be launching before that one despite just being announced though.</div><br/></div></div><div id="41524274" class="c"><input type="checkbox" id="c-41524274" checked=""/><div class="controls bullet"><span class="by">jstummbillig</span><span>|</span><a href="#41523268">root</a><span>|</span><a href="#41523528">parent</a><span>|</span><a href="#41523609">prev</a><span>|</span><a href="#41523522">next</a><span>|</span><label class="collapse" for="c-41524274">[-]</label><label class="expand" for="c-41524274">[1 more]</label></div><br/><div class="children"><div class="content">Sonnet 3.5 brought the largest practical improvements to this end user over all predecessors (so far).</div><br/></div></div></div></div><div id="41523522" class="c"><input type="checkbox" id="c-41523522" checked=""/><div class="controls bullet"><span class="by">apsec112</span><span>|</span><a href="#41523268">parent</a><span>|</span><a href="#41523528">prev</a><span>|</span><a href="#41524836">next</a><span>|</span><label class="collapse" for="c-41523522">[-]</label><label class="expand" for="c-41523522">[14 more]</label></div><br/><div class="children"><div class="content">This one [o1&#x2F;Strawberry] is available. I have it, though it&#x27;s limited to 30 messages&#x2F;week in ChatGPT Plus.</div><br/><div id="41523820" class="c"><input type="checkbox" id="c-41523820" checked=""/><div class="controls bullet"><span class="by">ansc</span><span>|</span><a href="#41523268">root</a><span>|</span><a href="#41523522">parent</a><span>|</span><a href="#41523700">next</a><span>|</span><label class="collapse" for="c-41523820">[-]</label><label class="expand" for="c-41523820">[4 more]</label></div><br/><div class="children"><div class="content">30 messages <i>per week</i>? Wow. You better not miss!</div><br/><div id="41523968" class="c"><input type="checkbox" id="c-41523968" checked=""/><div class="controls bullet"><span class="by">evilduck</span><span>|</span><a href="#41523268">root</a><span>|</span><a href="#41523820">parent</a><span>|</span><a href="#41523700">next</a><span>|</span><label class="collapse" for="c-41523968">[-]</label><label class="expand" for="c-41523968">[3 more]</label></div><br/><div class="children"><div class="content">In the world of hype driven vaporware AI products[1], giving people limited access is at least proof they&#x27;re not lying about it actually existing or it being able to do what they claim.<p>[1] <a href="https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;LocalLLaMA&#x2F;comments&#x2F;1fd75nm&#x2F;out_of_the_loop_on_this_whole_reflection_thing&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;LocalLLaMA&#x2F;comments&#x2F;1fd75nm&#x2F;out_of_...</a></div><br/><div id="41525751" class="c"><input type="checkbox" id="c-41525751" checked=""/><div class="controls bullet"><span class="by">ActionHank</span><span>|</span><a href="#41523268">root</a><span>|</span><a href="#41523968">parent</a><span>|</span><a href="#41526364">next</a><span>|</span><label class="collapse" for="c-41525751">[-]</label><label class="expand" for="c-41525751">[1 more]</label></div><br/><div class="children"><div class="content">Ok, but the point is that they told me I would have flirty ScarJo ASMR whispering to me at bed time that I am a good boy, but that&#x27;s not what we got is it?</div><br/></div></div><div id="41526364" class="c"><input type="checkbox" id="c-41526364" checked=""/><div class="controls bullet"><span class="by">hobo_in_library</span><span>|</span><a href="#41523268">root</a><span>|</span><a href="#41523968">parent</a><span>|</span><a href="#41525751">prev</a><span>|</span><a href="#41523700">next</a><span>|</span><label class="collapse" for="c-41526364">[-]</label><label class="expand" for="c-41526364">[1 more]</label></div><br/><div class="children"><div class="content">At 30 messages per week they could secretly hire a human to give the responses</div><br/></div></div></div></div></div></div><div id="41523700" class="c"><input type="checkbox" id="c-41523700" checked=""/><div class="controls bullet"><span class="by">sbochins</span><span>|</span><a href="#41523268">root</a><span>|</span><a href="#41523522">parent</a><span>|</span><a href="#41523820">prev</a><span>|</span><a href="#41523639">next</a><span>|</span><label class="collapse" for="c-41523700">[-]</label><label class="expand" for="c-41523700">[4 more]</label></div><br/><div class="children"><div class="content">How do you get access? I don’t have it and am a ChatGPT plus subscriber.</div><br/><div id="41523755" class="c"><input type="checkbox" id="c-41523755" checked=""/><div class="controls bullet"><span class="by">changoplatanero</span><span>|</span><a href="#41523268">root</a><span>|</span><a href="#41523700">parent</a><span>|</span><a href="#41523707">next</a><span>|</span><label class="collapse" for="c-41523755">[-]</label><label class="expand" for="c-41523755">[1 more]</label></div><br/><div class="children"><div class="content">it will roll out to everyone over the next few hours</div><br/></div></div><div id="41523707" class="c"><input type="checkbox" id="c-41523707" checked=""/><div class="controls bullet"><span class="by">apsec112</span><span>|</span><a href="#41523268">root</a><span>|</span><a href="#41523700">parent</a><span>|</span><a href="#41523755">prev</a><span>|</span><a href="#41523980">next</a><span>|</span><label class="collapse" for="c-41523707">[-]</label><label class="expand" for="c-41523707">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m using the Android ChatGPT app (and am in the Android Beta program, though not sure if that matters)</div><br/></div></div><div id="41523980" class="c"><input type="checkbox" id="c-41523980" checked=""/><div class="controls bullet"><span class="by">Szpadel</span><span>|</span><a href="#41523268">root</a><span>|</span><a href="#41523700">parent</a><span>|</span><a href="#41523707">prev</a><span>|</span><a href="#41523639">next</a><span>|</span><label class="collapse" for="c-41523980">[-]</label><label class="expand" for="c-41523980">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m plus subscriber and I have o1-preview and o1-mini available</div><br/></div></div></div></div><div id="41523751" class="c"><input type="checkbox" id="c-41523751" checked=""/><div class="controls bullet"><span class="by">aantix</span><span>|</span><a href="#41523268">root</a><span>|</span><a href="#41523522">parent</a><span>|</span><a href="#41523639">prev</a><span>|</span><a href="#41523869">next</a><span>|</span><label class="collapse" for="c-41523751">[-]</label><label class="expand" for="c-41523751">[3 more]</label></div><br/><div class="children"><div class="content">Dang - I don&#x27;t see the model listed for me in the iOS app nor the web interface.<p>I&#x27;m a ChatGPT subscriber.</div><br/><div id="41524290" class="c"><input type="checkbox" id="c-41524290" checked=""/><div class="controls bullet"><span class="by">derwiki</span><span>|</span><a href="#41523268">root</a><span>|</span><a href="#41523751">parent</a><span>|</span><a href="#41523869">next</a><span>|</span><label class="collapse" for="c-41524290">[-]</label><label class="expand" for="c-41524290">[2 more]</label></div><br/><div class="children"><div class="content">Same! And have been a subscriber for 18 months.</div><br/><div id="41525439" class="c"><input type="checkbox" id="c-41525439" checked=""/><div class="controls bullet"><span class="by">qwertox</span><span>|</span><a href="#41523268">root</a><span>|</span><a href="#41524290">parent</a><span>|</span><a href="#41523869">next</a><span>|</span><label class="collapse" for="c-41525439">[-]</label><label class="expand" for="c-41525439">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve been a subscriber since close to the beginning, cancelled 2 weeks ago. I got an email telling me that this is available, but only for Plus.<p>But for 30 posts per week I see no reason to subscribe again.<p>I prefer to be frustrated because the quality is unreliable because I&#x27;m not paying, instead of having an equally unreliable experience as a paying customer.<p>Not paying feels the same. It made me wonder if they sometimes just hand over the chat to a lower quality model without telling the Plus subscriber.<p>The only thing I miss is not being able to tell it to run code for me, but it&#x27;s not worth the frustration.</div><br/></div></div></div></div></div></div></div></div><div id="41523934" class="c"><input type="checkbox" id="c-41523934" checked=""/><div class="controls bullet"><span class="by">cja</span><span>|</span><a href="#41523268">parent</a><span>|</span><a href="#41524836">prev</a><span>|</span><a href="#41524630">next</a><span>|</span><label class="collapse" for="c-41523934">[-]</label><label class="expand" for="c-41523934">[5 more]</label></div><br/><div class="children"><div class="content">Recently I was starting to think I imagined that. Back then they gave me the impression it would be released within week or so of the announcement. Have they explained the delay?</div><br/><div id="41527573" class="c"><input type="checkbox" id="c-41527573" checked=""/><div class="controls bullet"><span class="by">glenstein</span><span>|</span><a href="#41523268">root</a><span>|</span><a href="#41523934">parent</a><span>|</span><a href="#41524046">next</a><span>|</span><label class="collapse" for="c-41527573">[-]</label><label class="expand" for="c-41527573">[1 more]</label></div><br/><div class="children"><div class="content">When you go into the regular, slow, audio mode there&#x27;s a little info circle in the top right corner. Over time that circle has been giving periodic updates. At one point the message was that it would be delayed, and now it&#x27;s saying it&#x27;s &quot;on it&#x27;s way&quot; by the end of fall.<p>Not perfect but they&#x27;ve been putting their communications in there.</div><br/></div></div><div id="41524046" class="c"><input type="checkbox" id="c-41524046" checked=""/><div class="controls bullet"><span class="by">Cu3PO42</span><span>|</span><a href="#41523268">root</a><span>|</span><a href="#41523934">parent</a><span>|</span><a href="#41527573">prev</a><span>|</span><a href="#41524630">next</a><span>|</span><label class="collapse" for="c-41524046">[-]</label><label class="expand" for="c-41524046">[3 more]</label></div><br/><div class="children"><div class="content">It is definitely available today and I believe it was available shortly after the announcement.</div><br/><div id="41525906" class="c"><input type="checkbox" id="c-41525906" checked=""/><div class="controls bullet"><span class="by">exitb</span><span>|</span><a href="#41523268">root</a><span>|</span><a href="#41524046">parent</a><span>|</span><a href="#41524630">next</a><span>|</span><label class="collapse" for="c-41525906">[-]</label><label class="expand" for="c-41525906">[2 more]</label></div><br/><div class="children"><div class="content">The text-to-text model is available. And you can use it with the old voice interface that does Whipser+GPT+TTS. But what was advertised is a model capable of direct audio-to-audio. That’s not available.</div><br/><div id="41527583" class="c"><input type="checkbox" id="c-41527583" checked=""/><div class="controls bullet"><span class="by">glenstein</span><span>|</span><a href="#41523268">root</a><span>|</span><a href="#41525906">parent</a><span>|</span><a href="#41524630">next</a><span>|</span><label class="collapse" for="c-41527583">[-]</label><label class="expand" for="c-41527583">[1 more]</label></div><br/><div class="children"><div class="content">Interestingly, the New York Times mistakenly reported on and reviewed the old features as if they were the new ones. So lots of confusion to go around.</div><br/></div></div></div></div></div></div></div></div><div id="41524630" class="c"><input type="checkbox" id="c-41524630" checked=""/><div class="controls bullet"><span class="by">trustno2</span><span>|</span><a href="#41523268">parent</a><span>|</span><a href="#41523934">prev</a><span>|</span><a href="#41523446">next</a><span>|</span><label class="collapse" for="c-41524630">[-]</label><label class="expand" for="c-41524630">[2 more]</label></div><br/><div class="children"><div class="content">That is in chatgpt now and it greatly improves chatgpt. What are you on to now?</div><br/><div id="41524832" class="c"><input type="checkbox" id="c-41524832" checked=""/><div class="controls bullet"><span class="by">vanviegen</span><span>|</span><a href="#41523268">root</a><span>|</span><a href="#41524630">parent</a><span>|</span><a href="#41523446">next</a><span>|</span><label class="collapse" for="c-41524832">[-]</label><label class="expand" for="c-41524832">[1 more]</label></div><br/><div class="children"><div class="content">Audio has only rolled out to a small subset of paying customers. There&#x27;s still no word about the direct-from-4o image generation they demo&#x27;d. Let alone the video capabilities.<p>So no, it&#x27;s not in chatgpt.</div><br/></div></div></div></div><div id="41523446" class="c"><input type="checkbox" id="c-41523446" checked=""/><div class="controls bullet"><span class="by">mickeystreicher</span><span>|</span><a href="#41523268">parent</a><span>|</span><a href="#41524630">prev</a><span>|</span><a href="#41523856">next</a><span>|</span><label class="collapse" for="c-41523446">[-]</label><label class="expand" for="c-41523446">[2 more]</label></div><br/><div class="children"><div class="content">Yep, all these AI announcements from big companies feel like promises for the future rather than immediate solutions. I miss the days when you could actually use a product right after it was announced, instead of waiting for some indefinite &quot;coming soon.&quot;</div><br/><div id="41529300" class="c"><input type="checkbox" id="c-41529300" checked=""/><div class="controls bullet"><span class="by">valval</span><span>|</span><a href="#41523268">root</a><span>|</span><a href="#41523446">parent</a><span>|</span><a href="#41523856">next</a><span>|</span><label class="collapse" for="c-41529300">[-]</label><label class="expand" for="c-41529300">[1 more]</label></div><br/><div class="children"><div class="content">As an entrepreneur, I do this often. In order to sleep better at night, I explain to myself that it’s somewhat harmless to give teasers about future content releases. If someone buys my product based on future promises or speculation, they’re investing into the development and my company’s future.</div><br/></div></div></div></div><div id="41523856" class="c"><input type="checkbox" id="c-41523856" checked=""/><div class="controls bullet"><span class="by">CooCooCaCha</span><span>|</span><a href="#41523268">parent</a><span>|</span><a href="#41523446">prev</a><span>|</span><a href="#41523854">next</a><span>|</span><label class="collapse" for="c-41523856">[-]</label><label class="expand" for="c-41523856">[1 more]</label></div><br/><div class="children"><div class="content">My guess is they&#x27;re going to incorporate all of these advances into gpt-5 so it looks like a &quot;best of all worlds&quot; model.</div><br/></div></div></div></div><div id="41523854" class="c"><input type="checkbox" id="c-41523854" checked=""/><div class="controls bullet"><span class="by">csomar</span><span>|</span><a href="#41523268">prev</a><span>|</span><a href="#41523143">next</a><span>|</span><label class="collapse" for="c-41523854">[-]</label><label class="expand" for="c-41523854">[4 more]</label></div><br/><div class="children"><div class="content">I gave the Crossword puzzle to Claude and got a correct response[1]. The fact that they are comparing this to gpt4o and not to gpt4 suggests that it is less impressive than they are trying to pretend.<p>[1]:<p>Based on the given clues, here&#x27;s the solved crossword puzzle:
+---+---+---+---+---+---+
| E | S | C | A | P | E |
+---+---+---+---+---+---+
| S | E | A | L | E | R |
+---+---+---+---+---+---+
| T | E | R | E | S | A |
+---+---+---+---+---+---+
| A | D | E | P | T | S |
+---+---+---+---+---+---+
| T | E | P | E | E | E |
+---+---+---+---+---+---+
| E | R | R | O | R | S |
+---+---+---+---+---+---+
Across:<p>ESCAPE (Evade)
SEALER (One to close envelopes)
TERESA (Mother Teresa)
ADEPTS (Initiated people)
TEPEE (Native American tent)
ERRORS (Mistakes)<p>Down:<p>ESTATE (Estate car - Station wagon)
SEEDER (Automatic planting machine)
CAREER (Profession)
ALEPPO (Syrian and Turkish pepper variety)
PESTER (Annoy)
ERASES (Deletes)</div><br/><div id="41523899" class="c"><input type="checkbox" id="c-41523899" checked=""/><div class="controls bullet"><span class="by">thomasahle</span><span>|</span><a href="#41523854">parent</a><span>|</span><a href="#41523143">next</a><span>|</span><label class="collapse" for="c-41523899">[-]</label><label class="expand" for="c-41523899">[3 more]</label></div><br/><div class="children"><div class="content">As good as Claude has gotten recently in reasoning, they are likely using RL behind the scenes too. Supposedly, o1&#x2F;strawberry was initially created as an engine for high-quality synthetic reasoning data for the new model generation. I wonder if Anthropic could release their generator as a usable model too.</div><br/><div id="41525395" class="c"><input type="checkbox" id="c-41525395" checked=""/><div class="controls bullet"><span class="by">deisteve</span><span>|</span><a href="#41523854">root</a><span>|</span><a href="#41523899">parent</a><span>|</span><a href="#41523143">next</a><span>|</span><label class="collapse" for="c-41525395">[-]</label><label class="expand" for="c-41525395">[2 more]</label></div><br/><div class="children"><div class="content">while i was initially excited now im having second thoughts after seeing the experiments run by people in the comments here<p>on X I see a totally different energy more about hyping it<p>on HN I see reserved and collected take which I trust more.<p>I do wonder why they chose gpt4o which I never bother to use for coding.<p>Claude is still king and looks like I won&#x27;t have to subscribe to ChatGPT Plus seeing it fail on some of the important experiments run by folks on HN<p>If anything these type of releases that air more on the side of hype given OpenAI&#x27;s track record</div><br/><div id="41529335" class="c"><input type="checkbox" id="c-41529335" checked=""/><div class="controls bullet"><span class="by">valval</span><span>|</span><a href="#41523854">root</a><span>|</span><a href="#41525395">parent</a><span>|</span><a href="#41523143">next</a><span>|</span><label class="collapse" for="c-41529335">[-]</label><label class="expand" for="c-41529335">[1 more]</label></div><br/><div class="children"><div class="content">I think people are wrong just about as often here as anywhere else on the internet, but with more confidence. Averaging HN comments would just produce outputs similar to rudimentary LLMs with a bit snobbier of a tone, I imagine.</div><br/></div></div></div></div></div></div></div></div><div id="41523143" class="c"><input type="checkbox" id="c-41523143" checked=""/><div class="controls bullet"><span class="by">dinobones</span><span>|</span><a href="#41523854">prev</a><span>|</span><a href="#41526437">next</a><span>|</span><label class="collapse" for="c-41523143">[-]</label><label class="expand" for="c-41523143">[27 more]</label></div><br/><div class="children"><div class="content">Generating more &quot;think out loud&quot; tokens and hiding them from the user...<p>Idk if I&#x27;m &quot;feeling the AGI&quot; if I&#x27;m being honest.<p>Also... telling that they choose to benchmark against CodeForces rather than SWE-bench.</div><br/><div id="41529347" class="c"><input type="checkbox" id="c-41529347" checked=""/><div class="controls bullet"><span class="by">valval</span><span>|</span><a href="#41523143">parent</a><span>|</span><a href="#41526630">next</a><span>|</span><label class="collapse" for="c-41529347">[-]</label><label class="expand" for="c-41529347">[1 more]</label></div><br/><div class="children"><div class="content">They’re running a business. They don’t owe you their trade secrets.</div><br/></div></div><div id="41526630" class="c"><input type="checkbox" id="c-41526630" checked=""/><div class="controls bullet"><span class="by">gwern</span><span>|</span><a href="#41523143">parent</a><span>|</span><a href="#41529347">prev</a><span>|</span><a href="#41523236">next</a><span>|</span><label class="collapse" for="c-41526630">[-]</label><label class="expand" for="c-41526630">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Also... telling that they choose to benchmark against CodeForces rather than SWE-bench.<p>They also worked with Devin to benchmark it on Devin&#x27;s internal benchmarks, where it&#x27;s twice as good as GPT-4o: <a href="https:&#x2F;&#x2F;x.com&#x2F;cognition_labs&#x2F;status&#x2F;1834292718174077014" rel="nofollow">https:&#x2F;&#x2F;x.com&#x2F;cognition_labs&#x2F;status&#x2F;1834292718174077014</a> <a href="https:&#x2F;&#x2F;www.cognition.ai&#x2F;blog&#x2F;evaluating-coding-agents" rel="nofollow">https:&#x2F;&#x2F;www.cognition.ai&#x2F;blog&#x2F;evaluating-coding-agents</a></div><br/></div></div><div id="41523236" class="c"><input type="checkbox" id="c-41523236" checked=""/><div class="controls bullet"><span class="by">thelastparadise</span><span>|</span><a href="#41523143">parent</a><span>|</span><a href="#41526630">prev</a><span>|</span><a href="#41523665">next</a><span>|</span><label class="collapse" for="c-41523236">[-]</label><label class="expand" for="c-41523236">[22 more]</label></div><br/><div class="children"><div class="content">Why not? Isn&#x27;t that basically what humans do? Sit there and think for a while before answering, going down different branches&#x2F;chains of thought?</div><br/><div id="41523283" class="c"><input type="checkbox" id="c-41523283" checked=""/><div class="controls bullet"><span class="by">dinobones</span><span>|</span><a href="#41523143">root</a><span>|</span><a href="#41523236">parent</a><span>|</span><a href="#41523318">next</a><span>|</span><label class="collapse" for="c-41523283">[-]</label><label class="expand" for="c-41523283">[13 more]</label></div><br/><div class="children"><div class="content">This new approach is showing:<p>1) The &quot;bitter lesson&quot; may not be true, and there is a fundamental limit to transformer intelligence.<p>2) The &quot;bitter lesson&quot; is true, and there just isn&#x27;t enough data&#x2F;compute&#x2F;energy to train AGI.<p>All the cognition should be happening inside the transformer. Attention is all you need. The possible cognition and reasoning occurring &quot;inside&quot; in high dimensions is much more advanced than any possible cognition that you output into text tokens.<p>This feels like a sidequest&#x2F;hack on what was otherwise a promising path to AGI.</div><br/><div id="41523569" class="c"><input type="checkbox" id="c-41523569" checked=""/><div class="controls bullet"><span class="by">grbsh</span><span>|</span><a href="#41523143">root</a><span>|</span><a href="#41523283">parent</a><span>|</span><a href="#41523491">next</a><span>|</span><label class="collapse" for="c-41523569">[-]</label><label class="expand" for="c-41523569">[2 more]</label></div><br/><div class="children"><div class="content">On the contrary, this suggests that the bitter lesson is alive and kicking. The bitter lesson doesn&#x27;t say &quot;compute is all you need&quot;, it says &quot;only those methods which allow you to make better use of hardware as hardware itself scales are relevant&quot;.<p>This chain of thought &#x2F; reflection method allows you to make better use of the hardware as the hardware itself scales. If a given transformer is N billion parameters, and to solve a harder problem we estimate we need 10N billion parameters, one way to do it is to build a GPU cluster 10x larger.<p>This method shows that there might be another way: instead train the N billion model differently so that we can use 10x of it at inference time. Say hardware gets 2x better in 2 years -- then this method will be 20x better than now!</div><br/><div id="41527956" class="c"><input type="checkbox" id="c-41527956" checked=""/><div class="controls bullet"><span class="by">WanderPanda</span><span>|</span><a href="#41523143">root</a><span>|</span><a href="#41523569">parent</a><span>|</span><a href="#41523491">next</a><span>|</span><label class="collapse" for="c-41527956">[-]</label><label class="expand" for="c-41527956">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;d be shocked if we don&#x27;t see diminishing returns in the inference compute scaling laws. We already didn&#x27;t deserve how clean and predictive the pre-training scaling laws were, no way the universe grants us another boon of that magnitude</div><br/></div></div></div></div><div id="41523491" class="c"><input type="checkbox" id="c-41523491" checked=""/><div class="controls bullet"><span class="by">gradus_ad</span><span>|</span><a href="#41523143">root</a><span>|</span><a href="#41523283">parent</a><span>|</span><a href="#41523569">prev</a><span>|</span><a href="#41523765">next</a><span>|</span><label class="collapse" for="c-41523491">[-]</label><label class="expand" for="c-41523491">[6 more]</label></div><br/><div class="children"><div class="content">Does that mean human intelligence is cheapened when you talk out a problem to yourself? Or when you write down steps solving a problem?<p>It&#x27;s the exact same thing here.</div><br/><div id="41524213" class="c"><input type="checkbox" id="c-41524213" checked=""/><div class="controls bullet"><span class="by">slashdave</span><span>|</span><a href="#41523143">root</a><span>|</span><a href="#41523491">parent</a><span>|</span><a href="#41523806">next</a><span>|</span><label class="collapse" for="c-41524213">[-]</label><label class="expand" for="c-41524213">[1 more]</label></div><br/><div class="children"><div class="content">The similarity is cosmetic only. The reason it is used is because it&#x27;s easy to leverage existing work in LLMs, and scaling (although not cheap) is an obvious approach.</div><br/></div></div><div id="41523806" class="c"><input type="checkbox" id="c-41523806" checked=""/><div class="controls bullet"><span class="by">youssefabdelm</span><span>|</span><a href="#41523143">root</a><span>|</span><a href="#41523491">parent</a><span>|</span><a href="#41524213">prev</a><span>|</span><a href="#41523598">next</a><span>|</span><label class="collapse" for="c-41523806">[-]</label><label class="expand" for="c-41523806">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Does that mean human intelligence is cheapened when you talk out a problem to yourself?<p>In a sense, maybe yeah. Of course if one were to really be absolute about that statement it would be absurd, it would greatly overfit the reality.<p>But it is interesting to assume this statement as true. Oftentimes when we think of ideas &quot;off the top of our heads&quot; they are not as profound as ideas that &quot;come to us&quot; in the shower. The subconscious may be doing &#x27;more&#x27; &#x27;computation&#x27; in a sense. Lakoff said the subconscious was 98% of the brain, and that the conscious mind is the tip of the iceberg of thought.</div><br/></div></div><div id="41523598" class="c"><input type="checkbox" id="c-41523598" checked=""/><div class="controls bullet"><span class="by">barrell</span><span>|</span><a href="#41523143">root</a><span>|</span><a href="#41523491">parent</a><span>|</span><a href="#41523806">prev</a><span>|</span><a href="#41523765">next</a><span>|</span><label class="collapse" for="c-41523598">[-]</label><label class="expand" for="c-41523598">[3 more]</label></div><br/><div class="children"><div class="content">lol come on it’s not the exact same thing. At best this is like gagging yourself while you talk about it then engaging yourself when you say the answer. And that presupposing LLMs are thinking in, your words, exactly the same way as humans.<p>At best it maybe vaguely resembles thinking</div><br/><div id="41524689" class="c"><input type="checkbox" id="c-41524689" checked=""/><div class="controls bullet"><span class="by">exe34</span><span>|</span><a href="#41523143">root</a><span>|</span><a href="#41523598">parent</a><span>|</span><a href="#41523765">next</a><span>|</span><label class="collapse" for="c-41524689">[-]</label><label class="expand" for="c-41524689">[2 more]</label></div><br/><div class="children"><div class="content">&gt; &quot;lol come on&quot;<p>I&#x27;ve never found this sort of argument convincing. it&#x27;s very Chalmers.</div><br/><div id="41529009" class="c"><input type="checkbox" id="c-41529009" checked=""/><div class="controls bullet"><span class="by">barrell</span><span>|</span><a href="#41523143">root</a><span>|</span><a href="#41524689">parent</a><span>|</span><a href="#41523765">next</a><span>|</span><label class="collapse" for="c-41529009">[-]</label><label class="expand" for="c-41529009">[1 more]</label></div><br/><div class="children"><div class="content">Admittedly not my most articulate, my exasperation showed through. To some extent it seems warranted as it tends to be the most effective tactic against hyperbole. Still trying to find a better solution.</div><br/></div></div></div></div></div></div></div></div><div id="41523765" class="c"><input type="checkbox" id="c-41523765" checked=""/><div class="controls bullet"><span class="by">user9925</span><span>|</span><a href="#41523143">root</a><span>|</span><a href="#41523283">parent</a><span>|</span><a href="#41523491">prev</a><span>|</span><a href="#41523575">next</a><span>|</span><label class="collapse" for="c-41523765">[-]</label><label class="expand" for="c-41523765">[1 more]</label></div><br/><div class="children"><div class="content">I think it&#x27;s too soon to tell. Training the next generation of models means building out entire datacenters. So while they wait they have engineers build these sidequests&#x2F;hacks.</div><br/></div></div><div id="41523575" class="c"><input type="checkbox" id="c-41523575" checked=""/><div class="controls bullet"><span class="by">seydor</span><span>|</span><a href="#41523143">root</a><span>|</span><a href="#41523283">parent</a><span>|</span><a href="#41523765">prev</a><span>|</span><a href="#41524476">next</a><span>|</span><label class="collapse" for="c-41523575">[-]</label><label class="expand" for="c-41523575">[1 more]</label></div><br/><div class="children"><div class="content">Attention is about similarity&#x2F;statistical correlation which is fundamentally stochastic , while reasoning needs to be truthful and exact to be successful.</div><br/></div></div><div id="41524476" class="c"><input type="checkbox" id="c-41524476" checked=""/><div class="controls bullet"><span class="by">authorfly</span><span>|</span><a href="#41523143">root</a><span>|</span><a href="#41523283">parent</a><span>|</span><a href="#41523575">prev</a><span>|</span><a href="#41523850">next</a><span>|</span><label class="collapse" for="c-41524476">[-]</label><label class="expand" for="c-41524476">[1 more]</label></div><br/><div class="children"><div class="content">Imagine instead the bitter lesson says: we can expand an outwards circle in many dimensions of ways to continuously mathematically manipulate data to adjust outputs.<p>Even the attention-token approach is on the grand scale of things a simple line outwards from the centre; we have not even explored around the centre (with the same compute spend) for things like non-token generation, different layers&#x2F;different activation functions and norming &#x2F; query&#x2F;key&#x2F;value set up (why do we only use the 3 inherent to contextualising tokens, why not add a 4th matrix for something else?), character, sentence, whole thought, paragraph one-shot generation, positional embeddings which could work differently.<p>The bitter lesson says there is almost a work completely untouched by our findings for us to explore. The temporary work of non-data approaches can piggy back off a point on the line; it cannot expand it like we can as we exude out from the circle..</div><br/></div></div><div id="41523850" class="c"><input type="checkbox" id="c-41523850" checked=""/><div class="controls bullet"><span class="by">93po</span><span>|</span><a href="#41523143">root</a><span>|</span><a href="#41523283">parent</a><span>|</span><a href="#41524476">prev</a><span>|</span><a href="#41523318">next</a><span>|</span><label class="collapse" for="c-41523850">[-]</label><label class="expand" for="c-41523850">[1 more]</label></div><br/><div class="children"><div class="content">Karpathy himself believes that neural networks are perfectly plausible as a key component to AGI. He has said that it doesn&#x27;t need to be superseded by something better, it&#x27;s just that everything else around it (especially infrastructure) needs to improve. As one of the most valuable opinions in the entire world on the subject, I tend to trust what he said.<p>source: <a href="https:&#x2F;&#x2F;youtu.be&#x2F;hM_h0UA7upI?t=973" rel="nofollow">https:&#x2F;&#x2F;youtu.be&#x2F;hM_h0UA7upI?t=973</a></div><br/></div></div></div></div><div id="41523318" class="c"><input type="checkbox" id="c-41523318" checked=""/><div class="controls bullet"><span class="by">aktuel</span><span>|</span><a href="#41523143">root</a><span>|</span><a href="#41523236">parent</a><span>|</span><a href="#41523283">prev</a><span>|</span><a href="#41523987">next</a><span>|</span><label class="collapse" for="c-41523318">[-]</label><label class="expand" for="c-41523318">[2 more]</label></div><br/><div class="children"><div class="content">Sure, but if I want a human, I can hire a human. Humans also do many other things I don&#x27;t want my LLM to do.</div><br/><div id="41525344" class="c"><input type="checkbox" id="c-41525344" checked=""/><div class="controls bullet"><span class="by">forgot_old_user</span><span>|</span><a href="#41523143">root</a><span>|</span><a href="#41523318">parent</a><span>|</span><a href="#41523987">next</a><span>|</span><label class="collapse" for="c-41525344">[-]</label><label class="expand" for="c-41525344">[1 more]</label></div><br/><div class="children"><div class="content">well it could be a lot cheaper to hire the AI model instead of a human?</div><br/></div></div></div></div><div id="41523987" class="c"><input type="checkbox" id="c-41523987" checked=""/><div class="controls bullet"><span class="by">imiric</span><span>|</span><a href="#41523143">root</a><span>|</span><a href="#41523236">parent</a><span>|</span><a href="#41523318">prev</a><span>|</span><a href="#41524622">next</a><span>|</span><label class="collapse" for="c-41523987">[-]</label><label class="expand" for="c-41523987">[2 more]</label></div><br/><div class="children"><div class="content">Except that these aren&#x27;t thoughts. These techniques are improvements to how the model breaks down input data, and how it evaluates its responses to arrive at a result that most closely approximates patterns it was previously rewarded for. Calling this &quot;thinking&quot; is anthropomorphizing what&#x27;s really happening. &quot;AI&quot; companies love to throw these phrases around, since it obviously creates hype and pumps up their valuation.<p>Human thinking is much more nuanced than this mechanical process. We rely on actually understanding the meaning of what the text represents. We use deduction, intuition and reasoning that involves semantic relationships between ideas. Our understanding of the world doesn&#x27;t require &quot;reinforcement learning&quot; and being trained on all the text that&#x27;s ever been written.<p>Of course, this isn&#x27;t to say that machine learning methods can&#x27;t be useful, or that we can&#x27;t keep improving them to yield better results. But these are still methods that mimic human intelligence, and I think it&#x27;s disingenuous to label them as such.</div><br/><div id="41524076" class="c"><input type="checkbox" id="c-41524076" checked=""/><div class="controls bullet"><span class="by">golol</span><span>|</span><a href="#41523143">root</a><span>|</span><a href="#41523987">parent</a><span>|</span><a href="#41524622">next</a><span>|</span><label class="collapse" for="c-41524076">[-]</label><label class="expand" for="c-41524076">[1 more]</label></div><br/><div class="children"><div class="content">It becomes thinking when you reinforcement learn on those Chain-of-Thought generations. The LLM is just a very good initialization.</div><br/></div></div></div></div><div id="41524622" class="c"><input type="checkbox" id="c-41524622" checked=""/><div class="controls bullet"><span class="by">NewEntryHN</span><span>|</span><a href="#41523143">root</a><span>|</span><a href="#41523236">parent</a><span>|</span><a href="#41523987">prev</a><span>|</span><a href="#41524187">next</a><span>|</span><label class="collapse" for="c-41524622">[-]</label><label class="expand" for="c-41524622">[1 more]</label></div><br/><div class="children"><div class="content">Yes but with concepts instead of tokens spelling out the written representation of those concepts.</div><br/></div></div><div id="41524187" class="c"><input type="checkbox" id="c-41524187" checked=""/><div class="controls bullet"><span class="by">slashdave</span><span>|</span><a href="#41523143">root</a><span>|</span><a href="#41523236">parent</a><span>|</span><a href="#41524622">prev</a><span>|</span><a href="#41524532">next</a><span>|</span><label class="collapse" for="c-41524187">[-]</label><label class="expand" for="c-41524187">[2 more]</label></div><br/><div class="children"><div class="content">Without a world model, not really.</div><br/><div id="41524699" class="c"><input type="checkbox" id="c-41524699" checked=""/><div class="controls bullet"><span class="by">UniverseHacker</span><span>|</span><a href="#41523143">root</a><span>|</span><a href="#41524187">parent</a><span>|</span><a href="#41524532">next</a><span>|</span><label class="collapse" for="c-41524699">[-]</label><label class="expand" for="c-41524699">[1 more]</label></div><br/><div class="children"><div class="content">The whole thing is a world model- accurately predicting text that describes things happening in a world, can only be done by modeling the world.</div><br/></div></div></div></div><div id="41524532" class="c"><input type="checkbox" id="c-41524532" checked=""/><div class="controls bullet"><span class="by">freejazz</span><span>|</span><a href="#41523143">root</a><span>|</span><a href="#41523236">parent</a><span>|</span><a href="#41524187">prev</a><span>|</span><a href="#41523665">next</a><span>|</span><label class="collapse" for="c-41524532">[-]</label><label class="expand" for="c-41524532">[1 more]</label></div><br/><div class="children"><div class="content">Is it?</div><br/></div></div></div></div><div id="41523665" class="c"><input type="checkbox" id="c-41523665" checked=""/><div class="controls bullet"><span class="by">WXLCKNO</span><span>|</span><a href="#41523143">parent</a><span>|</span><a href="#41523236">prev</a><span>|</span><a href="#41526437">next</a><span>|</span><label class="collapse" for="c-41523665">[-]</label><label class="expand" for="c-41523665">[2 more]</label></div><br/><div class="children"><div class="content">Exploring different approaches and stumbling on AGI eventually through a combination of random discoveries will be the way to go.<p>Same as Bitcoin being the right combination of things that already existed.</div><br/><div id="41525766" class="c"><input type="checkbox" id="c-41525766" checked=""/><div class="controls bullet"><span class="by">ActionHank</span><span>|</span><a href="#41523143">root</a><span>|</span><a href="#41523665">parent</a><span>|</span><a href="#41526437">next</a><span>|</span><label class="collapse" for="c-41525766">[-]</label><label class="expand" for="c-41525766">[1 more]</label></div><br/><div class="children"><div class="content">Crypto being used as an example of how we have moved forward successfully as a species is backward toilet sitting behaviour.</div><br/></div></div></div></div></div></div><div id="41526437" class="c"><input type="checkbox" id="c-41526437" checked=""/><div class="controls bullet"><span class="by">ttul</span><span>|</span><a href="#41523143">prev</a><span>|</span><a href="#41525800">next</a><span>|</span><label class="collapse" for="c-41526437">[-]</label><label class="expand" for="c-41526437">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve given this a test run on some email threads, asking the model to extract the positions and requirements of each person in a lengthy and convoluted discussion. It absolutely nailed the result, far exceeding what Claude 3.5 Sonnet was capable of -- my previous goto model for such analysis work. I also used it to apply APA style guidelines to various parts of a document and it executed the job flawlessly and with a tighter finesse than Claude. Claude&#x27;s response was lengthier - correct, but unnecessarily long. gpt-o1-preview combined several logically-related bullets into a single bullet, showing how chain of thought reasoning gives the model more time to comprehend things and product a result that is not just correct, but &quot;really correct&quot;.</div><br/></div></div><div id="41525800" class="c"><input type="checkbox" id="c-41525800" checked=""/><div class="controls bullet"><span class="by">alkyon</span><span>|</span><a href="#41526437">prev</a><span>|</span><a href="#41524901">next</a><span>|</span><label class="collapse" for="c-41525800">[-]</label><label class="expand" for="c-41525800">[3 more]</label></div><br/><div class="children"><div class="content">Maybe this is improvement in some areas, still I got spurious reasoning and inability to connect three simple facts:<p>Yes, &quot;el presente acta de nacimiento&quot; is correct in Spanish.<p>Explanation:<p><pre><code>    &quot;Acta&quot; is a feminine noun that begins with a stressed &quot;a&quot; sound. In Spanish, when a feminine singular noun starts with a stressed &quot;a&quot; or &quot;ha&quot;, the definite article &quot;la&quot; is replaced with &quot;el&quot; to facilitate pronunciation. However, the noun remains feminine.

    Adjectives and modifiers that accompany the noun &quot;acta&quot; should agree in feminine gender and singular number. In this case, &quot;presente&quot; is an adjective that has the same form for both masculine and feminine singular nouns.
</code></pre>
So, combining these rules:<p><pre><code>    &quot;El&quot; (definite article used before feminine nouns starting with stressed &quot;a&quot;)
    &quot;Presente&quot; (adjective agreeing in feminine singular)
    &quot;Acta de nacimiento&quot; (feminine noun with its complement)
</code></pre>
Therefore, &quot;el presente acta de nacimiento&quot; is grammatically correct.</div><br/><div id="41526703" class="c"><input type="checkbox" id="c-41526703" checked=""/><div class="controls bullet"><span class="by">anthk</span><span>|</span><a href="#41525800">parent</a><span>|</span><a href="#41524901">next</a><span>|</span><label class="collapse" for="c-41526703">[-]</label><label class="expand" for="c-41526703">[2 more]</label></div><br/><div class="children"><div class="content">Native Spanish speaker here. No, it isn&#x27;t. When a word stays in the middle of &#x27;La&#x27; plus a noun starting with &#x27;a&#x27;, the cacophony is null now, thus, you can perfectly use (if not mandatory) &quot;la presente acta&quot;.<p>Proof: <a href="https:&#x2F;&#x2F;www.elcastellano.org&#x2F;francisco-jos%C3%A9-d%C3%ADaz-%C3%ADb%C3%A1%C3%B1ez" rel="nofollow">https:&#x2F;&#x2F;www.elcastellano.org&#x2F;francisco-jos%C3%A9-d%C3%ADaz-%...</a></div><br/><div id="41529293" class="c"><input type="checkbox" id="c-41529293" checked=""/><div class="controls bullet"><span class="by">alkyon</span><span>|</span><a href="#41525800">root</a><span>|</span><a href="#41526703">parent</a><span>|</span><a href="#41524901">next</a><span>|</span><label class="collapse" for="c-41529293">[-]</label><label class="expand" for="c-41529293">[1 more]</label></div><br/><div class="children"><div class="content">yes, exactly - this is my point</div><br/></div></div></div></div></div></div><div id="41524901" class="c"><input type="checkbox" id="c-41524901" checked=""/><div class="controls bullet"><span class="by">fsndz</span><span>|</span><a href="#41525800">prev</a><span>|</span><a href="#41523287">next</a><span>|</span><label class="collapse" for="c-41524901">[-]</label><label class="expand" for="c-41524901">[3 more]</label></div><br/><div class="children"><div class="content">My point of view: this is a real advancement. I’ve always believed that with the right data allowing the LLM to be trained to imitate reasoning, it’s possible to improve its performance. However, this is still pattern matching, and I suspect that this approach may not be very effective for creating true generalization. As a result, once o1 becomes generally available, we will likely notice the persistent hallucinations and faulty reasoning, especially when the problem is sufficiently new or complex, beyond the “reasoning programs” or “reasoning patterns” the model learned during the reinforcement learning phase.
<a href="https:&#x2F;&#x2F;www.lycee.ai&#x2F;blog&#x2F;openai-o1-release-agi-reasoning" rel="nofollow">https:&#x2F;&#x2F;www.lycee.ai&#x2F;blog&#x2F;openai-o1-release-agi-reasoning</a></div><br/><div id="41525367" class="c"><input type="checkbox" id="c-41525367" checked=""/><div class="controls bullet"><span class="by">abhorrence</span><span>|</span><a href="#41524901">parent</a><span>|</span><a href="#41523287">next</a><span>|</span><label class="collapse" for="c-41525367">[-]</label><label class="expand" for="c-41525367">[2 more]</label></div><br/><div class="children"><div class="content">&gt; As a result, once o1 becomes generally available, we will likely notice the persistent hallucinations and faulty reasoning, especially when the problem is sufficiently new or complex, beyond the “reasoning programs” or “reasoning patterns” the model learned during the reinforcement learning phase.<p>I had been using 4o as a rubber ducky for some projects recently. Since I appeared to have access to o1-preview, I decided to go back and redo some of those conversations with o1-preview.<p>I think your comment is spot on. It&#x27;s definitely an advancement, but still makes some pretty clear mistakes and does some fairly faulty reasoning. It especially seems to have a hard time with causal ordering, and reasoning about dependencies in a distributed system. Frequently it gets the relationships backwards, leading to hilarious code examples.</div><br/><div id="41526261" class="c"><input type="checkbox" id="c-41526261" checked=""/><div class="controls bullet"><span class="by">fsndz</span><span>|</span><a href="#41524901">root</a><span>|</span><a href="#41525367">parent</a><span>|</span><a href="#41523287">next</a><span>|</span><label class="collapse" for="c-41526261">[-]</label><label class="expand" for="c-41526261">[1 more]</label></div><br/><div class="children"><div class="content">True. I just extensively tested o1 and came to the same conclusion.</div><br/></div></div></div></div></div></div><div id="41523287" class="c"><input type="checkbox" id="c-41523287" checked=""/><div class="controls bullet"><span class="by">andrewla</span><span>|</span><a href="#41524901">prev</a><span>|</span><a href="#41524295">next</a><span>|</span><label class="collapse" for="c-41523287">[-]</label><label class="expand" for="c-41523287">[2 more]</label></div><br/><div class="children"><div class="content">This is something that people have toyed with to improve the quality of LLM responses. Often instructing the LLM to &quot;think about&quot; a problem before giving the answer will greatly improve the quality of response. For example, if you ask it how many letters are in the correctly spelled version of a misspelled word, it will first give the correct spelling, and then the number (which is often correct). But if you instruct it to only give the number the accuracy is greatly reduced.<p>I like the idea too that they turbocharged it by taking the limits off during the &quot;thinking&quot; state -- so if an LLM wants to think about horrible racist things or how to build bombs or other things that RLHF filters out that&#x27;s fine so long as it isn&#x27;t reflected in the final answer.</div><br/><div id="41526609" class="c"><input type="checkbox" id="c-41526609" checked=""/><div class="controls bullet"><span class="by">scotty79</span><span>|</span><a href="#41523287">parent</a><span>|</span><a href="#41524295">next</a><span>|</span><label class="collapse" for="c-41526609">[-]</label><label class="expand" for="c-41526609">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I like the idea too that they turbocharged it by taking the limits off during the &quot;thinking&quot; state<p>They also specifically trained the model to do that thinking out loud.</div><br/></div></div></div></div><div id="41524295" class="c"><input type="checkbox" id="c-41524295" checked=""/><div class="controls bullet"><span class="by">fraboniface</span><span>|</span><a href="#41523287">prev</a><span>|</span><a href="#41523449">next</a><span>|</span><label class="collapse" for="c-41524295">[-]</label><label class="expand" for="c-41524295">[1 more]</label></div><br/><div class="children"><div class="content">Some commenters seem a bit confused as to how this works. Here is my understanding, hoping it helps clarify things.<p>Ask something to a model and it will reply in one go, likely imperfectly, as if you had one second to think before answering a question. You can use CoT prompting to force it to reason out loud, which improves quality, but the process is still linear. It&#x27;s as if you still had one second to start answering but you could be a lot slower in your response, which removes some mistakes.<p>Now if instead of doing that you query the model once with CoT, then ask it or another model to critically assess the reply, then ask the model to improve on its first reply using that feedback, then keep doing that until the critic is satisfied, the output will be better still. Note that this is a feedback loop with multiple requests, which is of different nature that CoT and much more akin to how a human would approach a complex problem. You can get MUCH better results that way, a good example being Code Interpreter. If classic LLM usage is system 1 thinking, this is system 2.<p>That&#x27;s how o1 works at test time, probably.<p>For training, my guess is that they started from a model not that far from GPT-4o and fine-tuned it with RL by using the above feedback loop but this time converting the critic to a reward signal for a RL algorithm. That way, the model gets better at first guessing and needs less back and forth for the same output quality.<p>As for the training data, I&#x27;m wondering if you can&#x27;t somehow get infinite training data by just throwing random challenges at it, or very hard ones, and let the model think about&#x2F;train on them for a very long time (as long as the critic is unforgiving enough).</div><br/></div></div><div id="41523449" class="c"><input type="checkbox" id="c-41523449" checked=""/><div class="controls bullet"><span class="by">islewis</span><span>|</span><a href="#41524295">prev</a><span>|</span><a href="#41524839">next</a><span>|</span><label class="collapse" for="c-41523449">[-]</label><label class="expand" for="c-41523449">[6 more]</label></div><br/><div class="children"><div class="content">My first interpretation of this is that it&#x27;s jazzed-up Chain-Of-Thought. The results look pretty promising, but i&#x27;m most interested in this:<p>&gt; Therefore, after weighing multiple factors including user experience, competitive advantage, and the option to pursue the chain of thought monitoring, we have decided not to show the raw chains of thought to users.<p>Mentioning competitive advantage here signals to me that OpenAI believes there moat is evaporating. Past the business context, my gut reaction is this negatively impacts model usability, but i&#x27;m having a hard time putting my finger on why.</div><br/><div id="41523578" class="c"><input type="checkbox" id="c-41523578" checked=""/><div class="controls bullet"><span class="by">thomasahle</span><span>|</span><a href="#41523449">parent</a><span>|</span><a href="#41523500">next</a><span>|</span><label class="collapse" for="c-41523578">[-]</label><label class="expand" for="c-41523578">[2 more]</label></div><br/><div class="children"><div class="content">&gt; my gut reaction is this negatively impacts model usability, but i&#x27;m having a hard time putting my finger on why.<p>This will make it harder for things like DSPy to work, which rely using &quot;good&quot; CoT examples as few-shot examples.</div><br/><div id="41526927" class="c"><input type="checkbox" id="c-41526927" checked=""/><div class="controls bullet"><span class="by">rchaves</span><span>|</span><a href="#41523449">root</a><span>|</span><a href="#41523578">parent</a><span>|</span><a href="#41523500">next</a><span>|</span><label class="collapse" for="c-41526927">[-]</label><label class="expand" for="c-41526927">[1 more]</label></div><br/><div class="children"><div class="content">yeah I guess base models without built-it CoT are not going away, exactly because you might want to tune it yourself. If DSPy (or similar) evolves to allow the same or similar than OpenAI did with o1, that will be quite powerful, but we still need the big foundational models powering it all<p>on the other hand, if cementing techniques in the models becomes a trend, we might see various models around with each technique for us to pick and choose beyond CoT without need for us to guide the model ourselves, then what&#x27;s left for us to optimize is the prompts on what we want, and the routing the combination of those in a nice pipeline<p>still the principle of DSPy stays the same, have a dataset to evaluate, let the machine trial an error prompts, hyperparameters and so on, just switch around different techniques (possibly automating that too), and get measurable, optimizable results</div><br/></div></div></div></div><div id="41523500" class="c"><input type="checkbox" id="c-41523500" checked=""/><div class="controls bullet"><span class="by">logicchains</span><span>|</span><a href="#41523449">parent</a><span>|</span><a href="#41523578">prev</a><span>|</span><a href="#41525263">next</a><span>|</span><label class="collapse" for="c-41523500">[-]</label><label class="expand" for="c-41523500">[2 more]</label></div><br/><div class="children"><div class="content">&gt;my gut reaction is this negatively impacts model usability, but i&#x27;m having a hard time putting my finger on why.<p>If the model outputs an incorrect answer due to a single mistake&#x2F;incorrect assumption in reasoning, the user has no way to correct it as it can&#x27;t see the reasoning so can&#x27;t see where the mistake was.</div><br/><div id="41523633" class="c"><input type="checkbox" id="c-41523633" checked=""/><div class="controls bullet"><span class="by">accrual</span><span>|</span><a href="#41523449">root</a><span>|</span><a href="#41523500">parent</a><span>|</span><a href="#41525263">next</a><span>|</span><label class="collapse" for="c-41523633">[-]</label><label class="expand" for="c-41523633">[1 more]</label></div><br/><div class="children"><div class="content">Maybe CriticGPT could be used here [0]. Have the CoT model produce a result, and either automatically or upon user request, ask CriticGPT to review the hidden CoT and feed the critique into the next response. This way the error can (hopefully) be spotted and corrected without revealing the whole process to the user.<p>[0] <a href="https:&#x2F;&#x2F;openai.com&#x2F;index&#x2F;finding-gpt4s-mistakes-with-gpt-4&#x2F;" rel="nofollow">https:&#x2F;&#x2F;openai.com&#x2F;index&#x2F;finding-gpt4s-mistakes-with-gpt-4&#x2F;</a><p>Day dreaming: imagine if this architecture takes off and the AI &quot;thought process&quot; becomes hidden and private much like human thoughts. I wonder then if a future robot&#x27;s inner dialog could be subpoenaed in court, connected to some special debugger, and have their &quot;thoughts&quot; read out loud in court to determine why it acted in some way.</div><br/></div></div></div></div><div id="41525263" class="c"><input type="checkbox" id="c-41525263" checked=""/><div class="controls bullet"><span class="by">m3kw9</span><span>|</span><a href="#41523449">parent</a><span>|</span><a href="#41523500">prev</a><span>|</span><a href="#41524839">next</a><span>|</span><label class="collapse" for="c-41525263">[-]</label><label class="expand" for="c-41525263">[1 more]</label></div><br/><div class="children"><div class="content">The moat is expanding from use count, also the moat is to lead and advance faster than anyone can catch up, you will always have the best mode with the best infrastructure and low limits.</div><br/></div></div></div></div><div id="41524839" class="c"><input type="checkbox" id="c-41524839" checked=""/><div class="controls bullet"><span class="by">rcarmo</span><span>|</span><a href="#41523449">prev</a><span>|</span><a href="#41523443">next</a><span>|</span><label class="collapse" for="c-41524839">[-]</label><label class="expand" for="c-41524839">[6 more]</label></div><br/><div class="children"><div class="content">Here&#x27;s an unpopular take on this:<p>&quot;We had the chance to make AI decision-making auditable but are locking ourselves out of hundreds of critical applications by not exposing the chain of thought.&quot;<p>One of the key blockers in many customer discussions I have is that AI models are not really auditable and that automating complex processes with them (let alone debug things when &quot;reasoning&quot; goes awry) is difficult if not impossible unless you do multi-shot and keep track of all the intermediate outputs.<p>I really hope they expose the chain of thought as some sort of machine-parsable output, otherwise no real progress will have been made (many benchmarks are not really significant when you try to apply LLMs to real-life applications and use cases...)</div><br/><div id="41524905" class="c"><input type="checkbox" id="c-41524905" checked=""/><div class="controls bullet"><span class="by">fwip</span><span>|</span><a href="#41524839">parent</a><span>|</span><a href="#41523443">next</a><span>|</span><label class="collapse" for="c-41524905">[-]</label><label class="expand" for="c-41524905">[5 more]</label></div><br/><div class="children"><div class="content">I suspect that actually reading the &quot;chain of thought&quot; would reveal obvious &quot;logic&quot; errors embarrassingly often.</div><br/><div id="41524923" class="c"><input type="checkbox" id="c-41524923" checked=""/><div class="controls bullet"><span class="by">rcarmo</span><span>|</span><a href="#41524839">root</a><span>|</span><a href="#41524905">parent</a><span>|</span><a href="#41526456">next</a><span>|</span><label class="collapse" for="c-41524923">[-]</label><label class="expand" for="c-41524923">[3 more]</label></div><br/><div class="children"><div class="content">It would still be auditable. In a few industries that is the only blocker for adoption--even if the outputs are incorrect.</div><br/><div id="41528305" class="c"><input type="checkbox" id="c-41528305" checked=""/><div class="controls bullet"><span class="by">abernard1</span><span>|</span><a href="#41524839">root</a><span>|</span><a href="#41524923">parent</a><span>|</span><a href="#41527737">next</a><span>|</span><label class="collapse" for="c-41528305">[-]</label><label class="expand" for="c-41528305">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ll give an argument against this with the caveat it applies only if these are pure LLMs without heuristics or helper models (I do not believe that to be the case with o1).<p>The problem with auditing is not only are the outputs incorrect, but the &quot;inputs&quot; of the chained steps have no fundamental logical connection to the outputs.  A statistical connection yes, but not a causal one.<p>For the trail to be auditable, processing would have to be taking place at the symbolic level of what the tokens represent in the steps.  But this is not what happens.  The transformer(s) (because these are now sampling multiple models) are finding the most likely set of tokens that reinforce a training objective which is a completed set of training chains. It is fundamentally operating <i>below</i> the symbolic or semantic level of the text.<p>This is why anthropomorphizing these is so dangerous.  It isn&#x27;t actually &quot;explaining&quot; its work.  The CoT is essentially one large output, broken into parts. The RL training objective does two useful things: (1) break it down into much smaller parts, which drops the error significantly as that scales as an exponential of the token length, and (2) provides better coverage of training data for common subproblems.  Both of those are valuable.  Obviously, in many cases the reasons actually match the output.  But hallucinations can happen anywhere throughout the chain, in ways which are basically undeterministic.<p>An intermediate step can provide a bad token and blithely ignore that to provide a correct answer.  If you look at intermediate training of addition in pure LLMs, you&#x27;ll get lots of results that look sort of like:<p>&gt; &quot;Add 123 + 456 and show your work&quot;<p>&gt; &quot;First we add 6 + 3 in the single digits which is 9.  Moving on we have 5 + 2 which is 8 in the tens place.  And in the hundreds place, we have 5.  This equals 579.&quot;<p>The above is very hand-wavy.  I do not know if the actual prompts look like that.  But there&#x27;s an error in the intermediate step (5 + 2 = 8) that does not actually matter to the output.  Lots of &quot;emergent&quot; properties of LLMs—arguably all of them—go away when partial credit is given for some of the tokens.  And this scales predictably without a cliff [1].  This is also what you would expect if LLMs were &quot;just&quot; token predictors.<p>But if LLMs are really just token predictors, then we should not expect intermediate results to matter in a way in which they deterministically change the output.  It isn&#x27;t just that CoT can chaotically change future tokens, <i>previous</i> tokens can &quot;hallucinate&quot; in a valid output statement.<p>[1] Are Emergent Abilities of Large Language Models a Mirage?: <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2304.15004" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2304.15004</a></div><br/></div></div><div id="41527737" class="c"><input type="checkbox" id="c-41527737" checked=""/><div class="controls bullet"><span class="by">fwip</span><span>|</span><a href="#41524839">root</a><span>|</span><a href="#41524923">parent</a><span>|</span><a href="#41528305">prev</a><span>|</span><a href="#41526456">next</a><span>|</span><label class="collapse" for="c-41527737">[-]</label><label class="expand" for="c-41527737">[1 more]</label></div><br/><div class="children"><div class="content">Oh, perhaps. I mean that OpenAI won&#x27;t do it because it would be bad for business and pop the AI bubble early.</div><br/></div></div></div></div><div id="41526456" class="c"><input type="checkbox" id="c-41526456" checked=""/><div class="controls bullet"><span class="by">thimabi</span><span>|</span><a href="#41524839">root</a><span>|</span><a href="#41524905">parent</a><span>|</span><a href="#41524923">prev</a><span>|</span><a href="#41523443">next</a><span>|</span><label class="collapse" for="c-41526456">[-]</label><label class="expand" for="c-41526456">[1 more]</label></div><br/><div class="children"><div class="content">I believe that is the case. Out of curiosity, I had this model try to solve a very simple Sudoku puzzle in ChatGPT, and it failed spectacularly.<p>It goes on and on making reasoning mistakes, and always ends up claiming that the puzzle is unsolvable and apologizing. I didn’t expect it to solve the puzzle, but the whole reasoning process seems fraught with errors.</div><br/></div></div></div></div></div></div><div id="41523443" class="c"><input type="checkbox" id="c-41523443" checked=""/><div class="controls bullet"><span class="by">bn-l</span><span>|</span><a href="#41524839">prev</a><span>|</span><a href="#41524253">next</a><span>|</span><label class="collapse" for="c-41523443">[-]</label><label class="expand" for="c-41523443">[6 more]</label></div><br/><div class="children"><div class="content">&gt; Unless otherwise specified, we evaluated o1 on the maximal test-time compute setting.<p>Maximal test time is the maximum amount of time spent doing the “Chain of Thought” “reasoning”. So that’s what these results are based on.<p>The caveat is that in the graphs they show that for each increase in test-time performance, the (wall) time &#x2F; compute goes up <i>exponentially</i>.<p>So there is a potentially interesting play here. They can honestly boast these amazing results (it’s the same model after all) yet the actual product may have a lower order of magnitude of “test-time” and not be as good.</div><br/><div id="41523513" class="c"><input type="checkbox" id="c-41523513" checked=""/><div class="controls bullet"><span class="by">alwa</span><span>|</span><a href="#41523443">parent</a><span>|</span><a href="#41523587">next</a><span>|</span><label class="collapse" for="c-41523513">[-]</label><label class="expand" for="c-41523513">[2 more]</label></div><br/><div class="children"><div class="content">I interpreted it to suggest that the product might include a user-facing “maximum test time” knob.<p>Generating problem sets for kids? You might only need or want a basic level of introspection, even though you like the flavor of this model’s personality over that of its predecessors.<p>Problem worth thinking long, hard, and expensively about? Turn that knob up to 11, and you’ll get a better-quality answer with no human-in-the-loop coaching or trial-and-error involved. You’ll just get your answer in timeframes closer to human ones, consuming more (metered) tokens along the way.</div><br/><div id="41523544" class="c"><input type="checkbox" id="c-41523544" checked=""/><div class="controls bullet"><span class="by">mrdmnd</span><span>|</span><a href="#41523443">root</a><span>|</span><a href="#41523513">parent</a><span>|</span><a href="#41523587">next</a><span>|</span><label class="collapse" for="c-41523544">[-]</label><label class="expand" for="c-41523544">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, I think this is the goal - remember; there are some problems that only need to be solved correctly once! Imagine something like a millennium problem - you&#x27;d be willing to wait a pretty long time for a proof of the RH!</div><br/></div></div></div></div><div id="41523587" class="c"><input type="checkbox" id="c-41523587" checked=""/><div class="controls bullet"><span class="by">bluecoconut</span><span>|</span><a href="#41523443">parent</a><span>|</span><a href="#41523513">prev</a><span>|</span><a href="#41523486">next</a><span>|</span><label class="collapse" for="c-41523587">[-]</label><label class="expand" for="c-41523587">[1 more]</label></div><br/><div class="children"><div class="content">This power law behavior of test-time improvement seems to be pretty ubiquitous now. In more agents is all you need [1], they start to see this as a function of ensemble size. It also shows up in: Large Language Monkeys: Scaling Inference Compute with Repeated Sampling [2]<p>I sorta wish everyone would plot their y-axis with logit y-axis, rather than 0-&gt;100 accuracy (including the openai post), to help show the power-law behavior. This is especially important when talking about incremental gains in the ~90-&gt;95, 95-&gt;99%. When the values (like the open ai post) are between 20-&gt;80, logit and linear look pretty similar, so you can &quot;see&quot; the inference power-law<p>[1] <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2402.05120" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2402.05120</a>
[2] <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2407.21787" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2407.21787</a></div><br/></div></div><div id="41523486" class="c"><input type="checkbox" id="c-41523486" checked=""/><div class="controls bullet"><span class="by">logicchains</span><span>|</span><a href="#41523443">parent</a><span>|</span><a href="#41523587">prev</a><span>|</span><a href="#41524253">next</a><span>|</span><label class="collapse" for="c-41523486">[-]</label><label class="expand" for="c-41523486">[2 more]</label></div><br/><div class="children"><div class="content">Surprising that at run time it needs an exponential increase in thinking to achieved a linear increase in output quality. I suppose it&#x27;s due to diminishing returns to adding more and more thought.</div><br/><div id="41523793" class="c"><input type="checkbox" id="c-41523793" checked=""/><div class="controls bullet"><span class="by">HarHarVeryFunny</span><span>|</span><a href="#41523443">root</a><span>|</span><a href="#41523486">parent</a><span>|</span><a href="#41524253">next</a><span>|</span><label class="collapse" for="c-41523793">[-]</label><label class="expand" for="c-41523793">[1 more]</label></div><br/><div class="children"><div class="content">The exponential increase is presumably because of the branching factor of the tree of thoughts. Think of a binary tree who&#x27;s number of leaf nodes doubles (= exponential growth) at each level.<p>It&#x27;s not too surprising that the corresponding increase in quality is only linear - how much difference in quality would you expect between the best, say, 10 word answer to a question, and the best 11 word answer ?<p>It&#x27;ll be interesting to see what they charge for this. An exponential increase in thinking time means an exponential increase in FLOPs&#x2F;dollars.</div><br/></div></div></div></div></div></div><div id="41524253" class="c"><input type="checkbox" id="c-41524253" checked=""/><div class="controls bullet"><span class="by">w4</span><span>|</span><a href="#41523443">prev</a><span>|</span><a href="#41523948">next</a><span>|</span><label class="collapse" for="c-41524253">[-]</label><label class="expand" for="c-41524253">[2 more]</label></div><br/><div class="children"><div class="content">Interesting to note, as an outside observer only keeping track of this stuff as a hobby, that it seems like most of OpenAI’s efforts to drive down compute costs per token and scale up context windows is likely being done in service of enabling larger and larger chains of thought and reasoning before the model predicts its final output tokens. The benefits of lower costs and larger contexts to API consumers and applications - which I had assumed to be the primary goal - seem likely to mostly be happy side effects.<p>This makes obvious sense in retrospect, since my own personal experiments with spinning up a recursive agent a few years ago using GPT-3 ran into issues with insufficient context length and loss of context as tokens needed to be discarded, which made the agent very unreliable. But I had not realized this until just now. I wonder what else is hiding in plain sight?</div><br/><div id="41524338" class="c"><input type="checkbox" id="c-41524338" checked=""/><div class="controls bullet"><span class="by">zamadatix</span><span>|</span><a href="#41524253">parent</a><span>|</span><a href="#41523948">next</a><span>|</span><label class="collapse" for="c-41524338">[-]</label><label class="expand" for="c-41524338">[1 more]</label></div><br/><div class="children"><div class="content">I think you can slice it whichever direction you prefer e.g. OpenAI needs more than &quot;we ran it on 10x as much hardware&quot; to end up with a really useful AI model, it needs to get efficient and smarter just as proportionally as it gets larger. As a side effect hardware sizes (and prices) needed for a certain size and intelligence of model go down too.<p>In the end, however you slice it, the goal has to be &quot;make it do more with less because we can&#x27;t get infinitely more hardware&quot; regardless of which &quot;why&quot; you give.</div><br/></div></div></div></div><div id="41523948" class="c"><input type="checkbox" id="c-41523948" checked=""/><div class="controls bullet"><span class="by">tylervigen</span><span>|</span><a href="#41524253">prev</a><span>|</span><a href="#41525409">next</a><span>|</span><label class="collapse" for="c-41523948">[-]</label><label class="expand" for="c-41523948">[12 more]</label></div><br/><div class="children"><div class="content">Here&#x27;s the o1-preview answer to the strawberry question:<p>--<p>There are *three* letter &quot;R&quot;s in the word &quot;strawberry.&quot;<p>Let&#x27;s break down the word to count the occurrences:<p>- *S*
- *T*
- *R*
- *A*
- *W*
- *B*
- *E*
- *R*
- *R*
- *Y*<p>The letter &quot;R&quot; appears in positions 3, 8, and 9.</div><br/><div id="41524239" class="c"><input type="checkbox" id="c-41524239" checked=""/><div class="controls bullet"><span class="by">slashdave</span><span>|</span><a href="#41523948">parent</a><span>|</span><a href="#41524221">next</a><span>|</span><label class="collapse" for="c-41524239">[-]</label><label class="expand" for="c-41524239">[1 more]</label></div><br/><div class="children"><div class="content">Given that this is a well known example, presumably OpenAI included a training set using letters.</div><br/></div></div><div id="41524221" class="c"><input type="checkbox" id="c-41524221" checked=""/><div class="controls bullet"><span class="by">carabiner</span><span>|</span><a href="#41523948">parent</a><span>|</span><a href="#41524239">prev</a><span>|</span><a href="#41525409">next</a><span>|</span><label class="collapse" for="c-41524221">[-]</label><label class="expand" for="c-41524221">[10 more]</label></div><br/><div class="children"><div class="content">can you ask it:<p>9.11 and 9.9, which number is larger</div><br/><div id="41524486" class="c"><input type="checkbox" id="c-41524486" checked=""/><div class="controls bullet"><span class="by">hidelooktropic</span><span>|</span><a href="#41523948">root</a><span>|</span><a href="#41524221">parent</a><span>|</span><a href="#41524266">next</a><span>|</span><label class="collapse" for="c-41524486">[-]</label><label class="expand" for="c-41524486">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Evaluating Number formats
&gt; I&#x27;m considering that the question might be about comparing two numbers, 9.11 and 9.9, in different contexts such as different locale formats or representing dates.
9.11 is larger than 9.9<p>Well, it&#x27;s kind of right because we left it ambiguous what kinds of numbers these are. September 11 is a greater date than September 9. However, I would want the model to have the street smarts to assume without further context, I must be just talking about numbers as in numbers.</div><br/><div id="41524687" class="c"><input type="checkbox" id="c-41524687" checked=""/><div class="controls bullet"><span class="by">oytis</span><span>|</span><a href="#41523948">root</a><span>|</span><a href="#41524486">parent</a><span>|</span><a href="#41524266">next</a><span>|</span><label class="collapse" for="c-41524687">[-]</label><label class="expand" for="c-41524687">[1 more]</label></div><br/><div class="children"><div class="content">Was it trained on Excel code?</div><br/></div></div></div></div><div id="41524413" class="c"><input type="checkbox" id="c-41524413" checked=""/><div class="controls bullet"><span class="by">peppertree</span><span>|</span><a href="#41523948">root</a><span>|</span><a href="#41524221">parent</a><span>|</span><a href="#41524266">prev</a><span>|</span><a href="#41524431">next</a><span>|</span><label class="collapse" for="c-41524413">[-]</label><label class="expand" for="c-41524413">[3 more]</label></div><br/><div class="children"><div class="content">4.9 is larger than 4.11.<p>Explanation:<p>• 4.9 is equivalent to 4.90.
 • 4.11 remains 4.11.<p>When comparing the numbers:<p>• 4.90 (which is 4.9)
 • 4.11<p>Since 4.90 &gt; 4.11, 4.9 is the larger number.</div><br/><div id="41524813" class="c"><input type="checkbox" id="c-41524813" checked=""/><div class="controls bullet"><span class="by">carabiner</span><span>|</span><a href="#41523948">root</a><span>|</span><a href="#41524413">parent</a><span>|</span><a href="#41524431">next</a><span>|</span><label class="collapse" for="c-41524813">[-]</label><label class="expand" for="c-41524813">[2 more]</label></div><br/><div class="children"><div class="content">Try it with 9.11 and 9.9. Some have proposed that it thinks &quot;9.11&quot; is larger because in a social context 9&#x2F;11 has much larger significance.</div><br/><div id="41527038" class="c"><input type="checkbox" id="c-41527038" checked=""/><div class="controls bullet"><span class="by">glial</span><span>|</span><a href="#41523948">root</a><span>|</span><a href="#41524813">parent</a><span>|</span><a href="#41524431">next</a><span>|</span><label class="collapse" for="c-41527038">[-]</label><label class="expand" for="c-41527038">[1 more]</label></div><br/><div class="children"><div class="content">From o1-mini:<p>To determine which number is larger between 9.11 and 9.9, let&#x27;s compare them step by step:<p>Understanding the Numbers:
9.11 can be read as &quot;nine and eleven hundredths.&quot;
9.9 can be read as &quot;nine and nine tenths.&quot; To make the comparison easier, you can also think of it as 9.90 (adding a zero doesn&#x27;t change the value).<p>Comparing the Decimal Places:
Ones Place: Both numbers have 9 in the ones place.
Tenths Place:
9.11 has a 1 in the tenths place.
9.90 has a 9 in the tenths place.<p>Conclusion:
Since 9.90 has a larger value in the tenths place compared to 9.11, 9.90 (or 9.9) is larger than 9.11.
Therefore, 9.9 is larger than 9.11.</div><br/></div></div></div></div></div></div><div id="41524431" class="c"><input type="checkbox" id="c-41524431" checked=""/><div class="controls bullet"><span class="by">octernion</span><span>|</span><a href="#41523948">root</a><span>|</span><a href="#41524221">parent</a><span>|</span><a href="#41524413">prev</a><span>|</span><a href="#41525409">next</a><span>|</span><label class="collapse" for="c-41524431">[-]</label><label class="expand" for="c-41524431">[3 more]</label></div><br/><div class="children"><div class="content">it claims 9.11 is larger, hah.<p><a href="https:&#x2F;&#x2F;postimg.cc&#x2F;KKKLZNjW" rel="nofollow">https:&#x2F;&#x2F;postimg.cc&#x2F;KKKLZNjW</a></div><br/><div id="41524716" class="c"><input type="checkbox" id="c-41524716" checked=""/><div class="controls bullet"><span class="by">peppertree</span><span>|</span><a href="#41523948">root</a><span>|</span><a href="#41524431">parent</a><span>|</span><a href="#41525409">next</a><span>|</span><label class="collapse" for="c-41524716">[-]</label><label class="expand" for="c-41524716">[2 more]</label></div><br/><div class="children"><div class="content">That&#x27;s odd. Tried several times with the same prompt and always got the correct answer with step by step explanation.</div><br/><div id="41525070" class="c"><input type="checkbox" id="c-41525070" checked=""/><div class="controls bullet"><span class="by">KeplerBoy</span><span>|</span><a href="#41523948">root</a><span>|</span><a href="#41524716">parent</a><span>|</span><a href="#41525409">next</a><span>|</span><label class="collapse" for="c-41525070">[-]</label><label class="expand" for="c-41525070">[1 more]</label></div><br/><div class="children"><div class="content">Those models are just not deterministic.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="41525409" class="c"><input type="checkbox" id="c-41525409" checked=""/><div class="controls bullet"><span class="by">forgotthepasswd</span><span>|</span><a href="#41523948">prev</a><span>|</span><a href="#41526016">next</a><span>|</span><label class="collapse" for="c-41525409">[-]</label><label class="expand" for="c-41525409">[5 more]</label></div><br/><div class="children"><div class="content">I had trouble in the past to make any model give me accurate unix epochs for specific dates.<p>I just went to GPT-4o (via DDG) and asked three questions:<p>1. Please give me the unix epoch for September 1, 2020 at 1:00 GMT.<p>&gt; 1598913600<p>2. Please give me the unix epoch for September 1, 2020 at 1:00 GMT. Before reaching the conclusion of the answer, please output the entire chain of thought, your reasoning, and the maths you&#x27;re doing, until your arrive at (and output) the result. Then, after you arrive at the result, make an extra effort to continue, and do the analysis backwards (as if you were writing a unit test for the result you achieved), to verify that your result is indeed correct.<p>&gt; 1598922000<p>3. Please give me the unix epoch for September 1, 2020 at 1:00 GMT. Then, after you arrive at the result, make an extra effort to continue, and do the analysis backwards (as if you were writing a unit test for the result you achieved), to verify that your result is indeed correct.<p>&gt; 1598913600</div><br/><div id="41525678" class="c"><input type="checkbox" id="c-41525678" checked=""/><div class="controls bullet"><span class="by">jewel</span><span>|</span><a href="#41525409">parent</a><span>|</span><a href="#41526110">next</a><span>|</span><label class="collapse" for="c-41525678">[-]</label><label class="expand" for="c-41525678">[1 more]</label></div><br/><div class="children"><div class="content">When I give it that same prompt, it writes a python program and then executes it to find the answer: <a href="https:&#x2F;&#x2F;chatgpt.com&#x2F;share&#x2F;66e35a15-602c-8011-a2cb-0a83be35b832" rel="nofollow">https:&#x2F;&#x2F;chatgpt.com&#x2F;share&#x2F;66e35a15-602c-8011-a2cb-0a83be35b8...</a></div><br/></div></div><div id="41526110" class="c"><input type="checkbox" id="c-41526110" checked=""/><div class="controls bullet"><span class="by">Alifatisk</span><span>|</span><a href="#41525409">parent</a><span>|</span><a href="#41525678">prev</a><span>|</span><a href="#41525511">next</a><span>|</span><label class="collapse" for="c-41526110">[-]</label><label class="expand" for="c-41526110">[1 more]</label></div><br/><div class="children"><div class="content">No need for llms to do that<p>ruby -r time -e &#x27;puts Time.parse(&quot;2020-09-01 01:00:00 +00:00&quot;).to_i&#x27;</div><br/></div></div><div id="41525511" class="c"><input type="checkbox" id="c-41525511" checked=""/><div class="controls bullet"><span class="by">tagawa</span><span>|</span><a href="#41525409">parent</a><span>|</span><a href="#41526110">prev</a><span>|</span><a href="#41525462">next</a><span>|</span><label class="collapse" for="c-41525511">[-]</label><label class="expand" for="c-41525511">[1 more]</label></div><br/><div class="children"><div class="content">Quick link for checking the result: <a href="https:&#x2F;&#x2F;duckduckgo.com&#x2F;?q=timestamp+1598922000&amp;ia=answer" rel="nofollow">https:&#x2F;&#x2F;duckduckgo.com&#x2F;?q=timestamp+1598922000&amp;ia=answer</a></div><br/></div></div></div></div><div id="41526016" class="c"><input type="checkbox" id="c-41526016" checked=""/><div class="controls bullet"><span class="by">natch</span><span>|</span><a href="#41525409">prev</a><span>|</span><a href="#41523437">next</a><span>|</span><label class="collapse" for="c-41526016">[-]</label><label class="expand" for="c-41526016">[1 more]</label></div><br/><div class="children"><div class="content">I tried it with a cipher text that ChatGPT4o flailed with.<p>Recently I tried the same cipher with Claude Sonnet 3.5 and it solved it quickly and perfectly.<p>Just now tried with ChatGPT o1 preview and it totally failed. Based on just this one test, Claude is still way ahead.<p>ChatGPT also showed a comical (possibly just fake filler material) journey of things it supposedly tried including several rewordings of &quot;rethinking my approach.&quot; It remarkably never showed that it was trying common word patterns (other than one and two letters) nor did it look for &quot;the&quot; and other &quot;th&quot; words nor did it ever say that it was trying to match letter patterns.<p>I told it upfront as a hint that the text was in English and was not a quote. The plaintext was one paragraph of layman-level material on a technical topic including a foreign name, text that has never appeared on the Internet or dark web. Pretty easy cipher with a lot of ways to get in, but nope, and super slow, where Claude was not only snappy but nailed it and explained itself.</div><br/></div></div><div id="41523437" class="c"><input type="checkbox" id="c-41523437" checked=""/><div class="controls bullet"><span class="by">gradus_ad</span><span>|</span><a href="#41526016">prev</a><span>|</span><a href="#41523362">next</a><span>|</span><label class="collapse" for="c-41523437">[-]</label><label class="expand" for="c-41523437">[6 more]</label></div><br/><div class="children"><div class="content">Interesting sequence from the Cipher CoT:<p>Third pair: &#x27;dn&#x27; to &#x27;i&#x27;<p>&#x27;d&#x27;=4, &#x27;n&#x27;=14<p>Sum:4+14=18<p>Average:18&#x2F;2=9<p>9 corresponds to &#x27;i&#x27;(9=&#x27;i&#x27;)<p>But &#x27;i&#x27; is 9, so that seems off by 1.<p>So perhaps we need to think carefully about letters.<p>Wait, 18&#x2F;2=9, 9 corresponds to &#x27;I&#x27;<p>So this works.<p>-----<p>This looks like recovery from a hallucination. Is it realistic to expect CoT to be able to recover from hallucinations this quickly?</div><br/><div id="41525249" class="c"><input type="checkbox" id="c-41525249" checked=""/><div class="controls bullet"><span class="by">machiaweliczny</span><span>|</span><a href="#41523437">parent</a><span>|</span><a href="#41527829">next</a><span>|</span><label class="collapse" for="c-41525249">[-]</label><label class="expand" for="c-41525249">[1 more]</label></div><br/><div class="children"><div class="content">In general if hallucination ratio is 2% can&#x27;t it be reduced to 0.04% by running twice or sth like this. I think they should try establishing the facts from different angles and this probably would work fine to minimize hallucinations. But if this was that simple somebody would already do it...</div><br/></div></div><div id="41527829" class="c"><input type="checkbox" id="c-41527829" checked=""/><div class="controls bullet"><span class="by">shthed</span><span>|</span><a href="#41523437">parent</a><span>|</span><a href="#41525249">prev</a><span>|</span><a href="#41524252">next</a><span>|</span><label class="collapse" for="c-41527829">[-]</label><label class="expand" for="c-41527829">[1 more]</label></div><br/><div class="children"><div class="content">Seems like a huge waste of tokens for it to try to work all this out manually, as soon as it came up with the decipher algorithm it should realise it can write some code to execute.</div><br/></div></div><div id="41524252" class="c"><input type="checkbox" id="c-41524252" checked=""/><div class="controls bullet"><span class="by">NightlyDev</span><span>|</span><a href="#41523437">parent</a><span>|</span><a href="#41527829">prev</a><span>|</span><a href="#41523560">next</a><span>|</span><label class="collapse" for="c-41524252">[-]</label><label class="expand" for="c-41524252">[1 more]</label></div><br/><div class="children"><div class="content">Did it hallucinate? I haven&#x27;t looked at it, but lowercase i and uppercase i is not the same number if you&#x27;re getting the number from ascii</div><br/></div></div><div id="41523560" class="c"><input type="checkbox" id="c-41523560" checked=""/><div class="controls bullet"><span class="by">trash_cat</span><span>|</span><a href="#41523437">parent</a><span>|</span><a href="#41524252">prev</a><span>|</span><a href="#41523929">next</a><span>|</span><label class="collapse" for="c-41523560">[-]</label><label class="expand" for="c-41523560">[1 more]</label></div><br/><div class="children"><div class="content">How do you mean quickly? It probably will take a while for it to output the final answer as it needs to re-prompt itself. It won&#x27;t be as fast as 4o.</div><br/></div></div><div id="41523929" class="c"><input type="checkbox" id="c-41523929" checked=""/><div class="controls bullet"><span class="by">bigyikes</span><span>|</span><a href="#41523437">parent</a><span>|</span><a href="#41523560">prev</a><span>|</span><a href="#41523362">next</a><span>|</span><label class="collapse" for="c-41523929">[-]</label><label class="expand" for="c-41523929">[1 more]</label></div><br/><div class="children"><div class="content">4o could already recover from hallucination in a limited capacity.<p>I’ve seen it, mid-reply say things like “Actually, that’s wrong, let me try again.”</div><br/></div></div></div></div><div id="41523362" class="c"><input type="checkbox" id="c-41523362" checked=""/><div class="controls bullet"><span class="by">hi</span><span>|</span><a href="#41523437">prev</a><span>|</span><label class="collapse" for="c-41523362">[-]</label><label class="expand" for="c-41523362">[3 more]</label></div><br/><div class="children"><div class="content">BUG: <a href="https:&#x2F;&#x2F;openai.com&#x2F;index&#x2F;reasoning-in-gpt&#x2F;" rel="nofollow">https:&#x2F;&#x2F;openai.com&#x2F;index&#x2F;reasoning-in-gpt&#x2F;</a><p>&gt; o1 models are currently in beta - The o1 models are currently in beta with limited features. Access is limited to developers in tier 5 (check your usage tier here), with low rate limits (20 RPM). We are working on adding more features, increasing rate limits, and expanding access to more developers in the coming weeks!<p><a href="https:&#x2F;&#x2F;platform.openai.com&#x2F;docs&#x2F;guides&#x2F;reasoning&#x2F;reasoning" rel="nofollow">https:&#x2F;&#x2F;platform.openai.com&#x2F;docs&#x2F;guides&#x2F;reasoning&#x2F;reasoning</a></div><br/><div id="41524085" class="c"><input type="checkbox" id="c-41524085" checked=""/><div class="controls bullet"><span class="by">cptcobalt</span><span>|</span><a href="#41523362">parent</a><span>|</span><label class="collapse" for="c-41524085">[-]</label><label class="expand" for="c-41524085">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m in Tier 4, and not far off from Tier 5. The docs aren&#x27;t quite transparent enough to show that if I buy credits if I&#x27;ll be bumped up to Tier 5, or if I actually have to use enough credits to get into Tier 5.<p>Edit, w&#x2F; real time follow up:<p>Prior to buying the credits, I saw O1-preview in the Tier 5 model list as a Tier 4 user. I bought credits to bump to Tier 5—not much, I&#x27;d have gotten there before the end of the year. The OpenAI website now shows I&#x27;m in Tier 5, but O1-preview is not in the Tier 5 model list for me anymore. So sneaky of them!</div><br/><div id="41524144" class="c"><input type="checkbox" id="c-41524144" checked=""/><div class="controls bullet"><span class="by">hi</span><span>|</span><a href="#41523362">root</a><span>|</span><a href="#41524085">parent</a><span>|</span><label class="collapse" for="c-41524144">[-]</label><label class="expand" for="c-41524144">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=41523070#41523525">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=41523070#41523525</a></div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>