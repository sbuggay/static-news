<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1738400470282" as="style"/><link rel="stylesheet" href="styles.css?v=1738400470282"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://openai.com/index/openai-o3-mini/">OpenAI O3-Mini</a> <span class="domain">(<a href="https://openai.com">openai.com</a>)</span></div><div class="subtext"><span>johnneville</span> | <span>467 comments</span></div><br/><div><div id="42891858" class="c"><input type="checkbox" id="c-42891858" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#42891760">next</a><span>|</span><label class="collapse" for="c-42891858">[-]</label><label class="expand" for="c-42891858">[34 more]</label></div><br/><div class="children"><div class="content">I used o3-mini to summarize this thread so far. Here&#x27;s the result: <a href="https:&#x2F;&#x2F;gist.github.com&#x2F;simonw&#x2F;09e5922be0cbb85894cf05e6d75ae050" rel="nofollow">https:&#x2F;&#x2F;gist.github.com&#x2F;simonw&#x2F;09e5922be0cbb85894cf05e6d75ae...</a><p>For 18,936 input, 2,905 output it cost 3.3612 cents.<p>Here&#x27;s the script I used to do it: <a href="https:&#x2F;&#x2F;til.simonwillison.net&#x2F;llms&#x2F;claude-hacker-news-themes#user-content-adding-a--m-model-option" rel="nofollow">https:&#x2F;&#x2F;til.simonwillison.net&#x2F;llms&#x2F;claude-hacker-news-themes...</a></div><br/><div id="42896755" class="c"><input type="checkbox" id="c-42896755" checked=""/><div class="controls bullet"><span class="by">s_dev</span><span>|</span><a href="#42891858">parent</a><span>|</span><a href="#42896912">next</a><span>|</span><label class="collapse" for="c-42896755">[-]</label><label class="expand" for="c-42896755">[8 more]</label></div><br/><div class="children"><div class="content">Currently on the internet people skip the article and go straight to the comments. Soon people will skip the comments and go striaght to an AI summary reading neither the original article nor the comments.</div><br/><div id="42896807" class="c"><input type="checkbox" id="c-42896807" checked=""/><div class="controls bullet"><span class="by">darthrupert</span><span>|</span><a href="#42891858">root</a><span>|</span><a href="#42896755">parent</a><span>|</span><a href="#42896912">next</a><span>|</span><label class="collapse" for="c-42896807">[-]</label><label class="expand" for="c-42896807">[7 more]</label></div><br/><div class="children"><div class="content">That would be an actual improvement. Reading the comments section usually just leads to personal energy waste.</div><br/><div id="42896869" class="c"><input type="checkbox" id="c-42896869" checked=""/><div class="controls bullet"><span class="by">anonzzzies</span><span>|</span><a href="#42891858">root</a><span>|</span><a href="#42896807">parent</a><span>|</span><a href="#42896868">next</a><span>|</span><label class="collapse" for="c-42896869">[-]</label><label class="expand" for="c-42896869">[5 more]</label></div><br/><div class="children"><div class="content">On both HN &amp; Reddit, I find the comments more informative and less frustrating than reading the article usually. But I guess YMMV.</div><br/><div id="42896887" class="c"><input type="checkbox" id="c-42896887" checked=""/><div class="controls bullet"><span class="by">brabel</span><span>|</span><a href="#42891858">root</a><span>|</span><a href="#42896869">parent</a><span>|</span><a href="#42896898">next</a><span>|</span><label class="collapse" for="c-42896887">[-]</label><label class="expand" for="c-42896887">[3 more]</label></div><br/><div class="children"><div class="content">You need to read the article first to know that. But most people won&#x27;t.</div><br/><div id="42896951" class="c"><input type="checkbox" id="c-42896951" checked=""/><div class="controls bullet"><span class="by">anonzzzies</span><span>|</span><a href="#42891858">root</a><span>|</span><a href="#42896887">parent</a><span>|</span><a href="#42896889">next</a><span>|</span><label class="collapse" for="c-42896951">[-]</label><label class="expand" for="c-42896951">[1 more]</label></div><br/><div class="children"><div class="content">If the comments say it&#x27;s worth it I read it, but often (especially on HN) the top comment starts with a summary of errors&#x2F;inconsistencies in the article and then I don&#x27;t really feel the need.</div><br/></div></div><div id="42896889" class="c"><input type="checkbox" id="c-42896889" checked=""/><div class="controls bullet"><span class="by">Jensson</span><span>|</span><a href="#42891858">root</a><span>|</span><a href="#42896887">parent</a><span>|</span><a href="#42896951">prev</a><span>|</span><a href="#42896898">next</a><span>|</span><label class="collapse" for="c-42896889">[-]</label><label class="expand" for="c-42896889">[1 more]</label></div><br/><div class="children"><div class="content">You can read the article after the comments.</div><br/></div></div></div></div><div id="42896898" class="c"><input type="checkbox" id="c-42896898" checked=""/><div class="controls bullet"><span class="by">darthrupert</span><span>|</span><a href="#42891858">root</a><span>|</span><a href="#42896869">parent</a><span>|</span><a href="#42896887">prev</a><span>|</span><a href="#42896868">next</a><span>|</span><label class="collapse" for="c-42896898">[-]</label><label class="expand" for="c-42896898">[1 more]</label></div><br/><div class="children"><div class="content">I agree, they are! But reading through them, or even worse, engaging with them, is a serious energy drain.<p>Especially if somebody is being wrong.</div><br/></div></div></div></div><div id="42896868" class="c"><input type="checkbox" id="c-42896868" checked=""/><div class="controls bullet"><span class="by">zapkyeskrill</span><span>|</span><a href="#42891858">root</a><span>|</span><a href="#42896807">parent</a><span>|</span><a href="#42896869">prev</a><span>|</span><a href="#42896912">next</a><span>|</span><label class="collapse" for="c-42896868">[-]</label><label class="expand" for="c-42896868">[1 more]</label></div><br/><div class="children"><div class="content">Yes, but who will comment then and on what?</div><br/></div></div></div></div></div></div><div id="42896912" class="c"><input type="checkbox" id="c-42896912" checked=""/><div class="controls bullet"><span class="by">wkat4242</span><span>|</span><a href="#42891858">parent</a><span>|</span><a href="#42896755">prev</a><span>|</span><a href="#42892301">next</a><span>|</span><label class="collapse" for="c-42896912">[-]</label><label class="expand" for="c-42896912">[2 more]</label></div><br/><div class="children"><div class="content">Why use a reasoning model for a summarisation task? Serious question, would it benefit?<p>I don&#x27;t have much experience with reasoning models yet. That&#x27;s why.</div><br/><div id="42896969" class="c"><input type="checkbox" id="c-42896969" checked=""/><div class="controls bullet"><span class="by">BoorishBears</span><span>|</span><a href="#42891858">root</a><span>|</span><a href="#42896912">parent</a><span>|</span><a href="#42892301">next</a><span>|</span><label class="collapse" for="c-42896969">[-]</label><label class="expand" for="c-42896969">[1 more]</label></div><br/><div class="children"><div class="content">In theory you could get a better summary if it manages to reason out underlying motivations of a summary for example, or proposes a summary and then &quot;considers&quot; it, realizing it missed something.<p>You can illicit that with any model by prompting underlying reasons or using chain-of-thought, but a reasoning model could do it without prompting</div><br/></div></div></div></div><div id="42892301" class="c"><input type="checkbox" id="c-42892301" checked=""/><div class="controls bullet"><span class="by">threecheese</span><span>|</span><a href="#42891858">parent</a><span>|</span><a href="#42896912">prev</a><span>|</span><a href="#42896653">next</a><span>|</span><label class="collapse" for="c-42892301">[-]</label><label class="expand" for="c-42892301">[7 more]</label></div><br/><div class="children"><div class="content">I haven’t tried o3, but one issue I struggle with in large context analysis tasks is the LLMs are never thorough. In a task like this thread summarization, I typically need to break the document down and loop through chunks to ensure it actually “reads” everything. I might have had to recurse into individual conversations with some small max-depth and leaf count and run inference on each, and then have some aggregation at the end, otherwise it would miss a lot (or appear to, based on the output).<p>Is this a case of PEBKAC?</div><br/><div id="42893858" class="c"><input type="checkbox" id="c-42893858" checked=""/><div class="controls bullet"><span class="by">sdesol</span><span>|</span><a href="#42891858">root</a><span>|</span><a href="#42892301">parent</a><span>|</span><a href="#42892551">next</a><span>|</span><label class="collapse" for="c-42893858">[-]</label><label class="expand" for="c-42893858">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I haven’t tried o3, but one issue I struggle with in large context analysis tasks is the LLMs are never thorough.<p>o3 does look very promising with regards to large context analysis. I used the same raw data and ran the same prompt as Simon for GPT-4o, GPT-4o mini and DeepSeek R1 and compared their output. You can find the analysis below:<p><a href="https:&#x2F;&#x2F;beta.gitsense.com&#x2F;?chat=46493969-17b2-4806-a99c-5d93012b3580" rel="nofollow">https:&#x2F;&#x2F;beta.gitsense.com&#x2F;?chat=46493969-17b2-4806-a99c-5d93...</a><p>The o3-min model was quite thorough.  With reasoning models, it looks like dealing with long context might have gotten a lot better.<p>Edit:<p>I was curious if I could get R1 to be more thorough and got the following interesting tidbits.<p>- Depth Variance: R1 analysis provides more technical infrastructure insights, while o3-mini focuses on developer experience<p>- Geopolitical Focus: Only R1 analysis addresses China-West tensions explicitly<p>- Philosophical Scope: R1 contains broader industry meta-commentary absent in o3-mini<p>- Contrarian Views: o3-mini dedicates specific section to minority opinions<p>- Temporal Aspects: R1 emphasizes future-looking questions, o3-mini focuses on current implementation<p>You can find the full analysis at<p><a href="https:&#x2F;&#x2F;beta.gitsense.com&#x2F;?chat=95741f4f-b11f-4f0b-8239-83c7e558ac2a&amp;model=Fake+LLM+Simulator+1" rel="nofollow">https:&#x2F;&#x2F;beta.gitsense.com&#x2F;?chat=95741f4f-b11f-4f0b-8239-83c7...</a></div><br/></div></div><div id="42892551" class="c"><input type="checkbox" id="c-42892551" checked=""/><div class="controls bullet"><span class="by">syntaxing</span><span>|</span><a href="#42891858">root</a><span>|</span><a href="#42892301">parent</a><span>|</span><a href="#42893858">prev</a><span>|</span><a href="#42892659">next</a><span>|</span><label class="collapse" for="c-42892551">[-]</label><label class="expand" for="c-42892551">[1 more]</label></div><br/><div class="children"><div class="content">Depending on what you’re trying to do, it’s worth trying the 1M context Qwen Models. They only released 7 and 14B so it’s “intelligence” is limited but should be more than capable for coherent summary.</div><br/></div></div><div id="42892659" class="c"><input type="checkbox" id="c-42892659" checked=""/><div class="controls bullet"><span class="by">andrewci</span><span>|</span><a href="#42891858">root</a><span>|</span><a href="#42892301">parent</a><span>|</span><a href="#42892551">prev</a><span>|</span><a href="#42894774">next</a><span>|</span><label class="collapse" for="c-42892659">[-]</label><label class="expand" for="c-42892659">[1 more]</label></div><br/><div class="children"><div class="content">Are there any tools you use to do this chunking? Or is this a custom workflow? I&#x27;ve noticed the same thing both on copy&#x2F;paste text and uploaded documents when using the LLM chat tools.</div><br/></div></div><div id="42894774" class="c"><input type="checkbox" id="c-42894774" checked=""/><div class="controls bullet"><span class="by">scarface_74</span><span>|</span><a href="#42891858">root</a><span>|</span><a href="#42892301">parent</a><span>|</span><a href="#42892659">prev</a><span>|</span><a href="#42893877">next</a><span>|</span><label class="collapse" for="c-42894774">[-]</label><label class="expand" for="c-42894774">[2 more]</label></div><br/><div class="children"><div class="content">Try Google’s NotebookLM</div><br/><div id="42896923" class="c"><input type="checkbox" id="c-42896923" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#42891858">root</a><span>|</span><a href="#42894774">parent</a><span>|</span><a href="#42893877">next</a><span>|</span><label class="collapse" for="c-42896923">[-]</label><label class="expand" for="c-42896923">[1 more]</label></div><br/><div class="children"><div class="content">I put one of my own blog posts through NotebookLM soon after it became available, it hallucinated content I didn&#x27;t write and missed out things I had written.<p>Nice TTS, but otherwise I found it unimpressive.</div><br/></div></div></div></div><div id="42893877" class="c"><input type="checkbox" id="c-42893877" checked=""/><div class="controls bullet"><span class="by">mvkel</span><span>|</span><a href="#42891858">root</a><span>|</span><a href="#42892301">parent</a><span>|</span><a href="#42894774">prev</a><span>|</span><a href="#42896653">next</a><span>|</span><label class="collapse" for="c-42893877">[-]</label><label class="expand" for="c-42893877">[1 more]</label></div><br/><div class="children"><div class="content">o1-pro is incredibly good at this. You&#x27;ll be amazed</div><br/></div></div></div></div><div id="42896653" class="c"><input type="checkbox" id="c-42896653" checked=""/><div class="controls bullet"><span class="by">qwertox</span><span>|</span><a href="#42891858">parent</a><span>|</span><a href="#42892301">prev</a><span>|</span><a href="#42892108">next</a><span>|</span><label class="collapse" for="c-42896653">[-]</label><label class="expand" for="c-42896653">[2 more]</label></div><br/><div class="children"><div class="content">How is the `system` prompt &quot;injected&quot;? Afaik o1 onwards no longer have a SYSTEM role. Is it just a normal part of the prompt?</div><br/><div id="42896700" class="c"><input type="checkbox" id="c-42896700" checked=""/><div class="controls bullet"><span class="by">naiv</span><span>|</span><a href="#42891858">root</a><span>|</span><a href="#42896653">parent</a><span>|</span><a href="#42892108">next</a><span>|</span><label class="collapse" for="c-42896700">[-]</label><label class="expand" for="c-42896700">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s called &#x27;developer message&#x27; now<p><a href="https:&#x2F;&#x2F;x.com&#x2F;OpenAIDevs&#x2F;status&#x2F;1885407759887155301" rel="nofollow">https:&#x2F;&#x2F;x.com&#x2F;OpenAIDevs&#x2F;status&#x2F;1885407759887155301</a></div><br/></div></div></div></div><div id="42892108" class="c"><input type="checkbox" id="c-42892108" checked=""/><div class="controls bullet"><span class="by">layman51</span><span>|</span><a href="#42891858">parent</a><span>|</span><a href="#42896653">prev</a><span>|</span><a href="#42894763">next</a><span>|</span><label class="collapse" for="c-42892108">[-]</label><label class="expand" for="c-42892108">[2 more]</label></div><br/><div class="children"><div class="content">I noticed that it thought that GoatInGrey wrote “openai is no longer relevant.” However, they were just quoting a different user (buyucu) who was the person who first wrote that.</div><br/><div id="42894417" class="c"><input type="checkbox" id="c-42894417" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#42891858">root</a><span>|</span><a href="#42892108">parent</a><span>|</span><a href="#42894763">next</a><span>|</span><label class="collapse" for="c-42894417">[-]</label><label class="expand" for="c-42894417">[1 more]</label></div><br/><div class="children"><div class="content">Good catch. That&#x27;s likely an artifact of the way I flatten the nested JSON from the comments API.<p>I originally did that to save on tokens but modern models have much larger input windows so I may not need to do that any more.</div><br/></div></div></div></div><div id="42894763" class="c"><input type="checkbox" id="c-42894763" checked=""/><div class="controls bullet"><span class="by">tkgally</span><span>|</span><a href="#42891858">parent</a><span>|</span><a href="#42892108">prev</a><span>|</span><a href="#42894372">next</a><span>|</span><label class="collapse" for="c-42894763">[-]</label><label class="expand" for="c-42894763">[1 more]</label></div><br/><div class="children"><div class="content">Borrowing most of Simon’s prompt, I tried the following with o3-mini-high in the chat interface with Search turned on:<p>“Summarize the themes of the opinions expressed in discussions on Hacker News on January 31 and February 1, 2025, about OpenAI’s release od [sic] ChatGPT o3-mini. For each theme, output a header. Include direct &quot;quotations&quot; (with author attribution) where appropriate. You MUST quote directly from users when crediting them, with double quotes. Fix HTML entities. Go long. Include a section of quotes that illustrate opinions uncommon in the rest of the piece”<p>The result is here:<p><a href="https:&#x2F;&#x2F;chatgpt.com&#x2F;share&#x2F;679d790d-df6c-8011-ad78-3695c2e254fd" rel="nofollow">https:&#x2F;&#x2F;chatgpt.com&#x2F;share&#x2F;679d790d-df6c-8011-ad78-3695c2e254...</a><p>Most of the cited quotations seem to be accurate, but at least one (by uncomplexity_) does not appear in the named commenter’s comment history.<p>I haven’t attempted to judge how accurate the summary is. Since the discussions here are continuing at this moment, this summary will be gradually falling out of date in any case.</div><br/></div></div><div id="42894372" class="c"><input type="checkbox" id="c-42894372" checked=""/><div class="controls bullet"><span class="by">Valakas_</span><span>|</span><a href="#42891858">parent</a><span>|</span><a href="#42894763">prev</a><span>|</span><a href="#42892340">next</a><span>|</span><label class="collapse" for="c-42894372">[-]</label><label class="expand" for="c-42894372">[2 more]</label></div><br/><div class="children"><div class="content">For those that like simpler ways (although dependent on Google) NotebookLM does all that in 2 clicks. And you can ask it questions about it, references are provided.</div><br/><div id="42894403" class="c"><input type="checkbox" id="c-42894403" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#42891858">root</a><span>|</span><a href="#42894372">parent</a><span>|</span><a href="#42892340">next</a><span>|</span><label class="collapse" for="c-42894403">[-]</label><label class="expand" for="c-42894403">[1 more]</label></div><br/><div class="children"><div class="content">After you&#x27;ve run my hn-summary.sh script you can ask follow up questions like this:<p><pre><code>  llm -c &quot;did anyone talk about pricing?&quot;</code></pre></div><br/></div></div></div></div><div id="42892340" class="c"><input type="checkbox" id="c-42892340" checked=""/><div class="controls bullet"><span class="by">breakingcups</span><span>|</span><a href="#42891858">parent</a><span>|</span><a href="#42894372">prev</a><span>|</span><a href="#42892989">next</a><span>|</span><label class="collapse" for="c-42892340">[-]</label><label class="expand" for="c-42892340">[4 more]</label></div><br/><div class="children"><div class="content">It&#x27;s definitely making some errors</div><br/><div id="42892573" class="c"><input type="checkbox" id="c-42892573" checked=""/><div class="controls bullet"><span class="by">kandesbunzler</span><span>|</span><a href="#42891858">root</a><span>|</span><a href="#42892340">parent</a><span>|</span><a href="#42892989">next</a><span>|</span><label class="collapse" for="c-42892573">[-]</label><label class="expand" for="c-42892573">[3 more]</label></div><br/><div class="children"><div class="content">Like?</div><br/><div id="42893720" class="c"><input type="checkbox" id="c-42893720" checked=""/><div class="controls bullet"><span class="by">aprilthird2021</span><span>|</span><a href="#42891858">root</a><span>|</span><a href="#42892573">parent</a><span>|</span><a href="#42892989">next</a><span>|</span><label class="collapse" for="c-42893720">[-]</label><label class="expand" for="c-42893720">[2 more]</label></div><br/><div class="children"><div class="content">Even though it was told that it MUST quote users directly, it still outputs:<p>&gt; It’s already a game changer for many people. But to have so many names like o1, o3-mini, GPT-4o, &amp; GPT-4o-mini suggests there may be too much focus on internal tech details rather than clear communication.&quot; (paraphrase based on multiple similar sentiments)<p>It also hallucinates quotes.<p>For example:<p>&gt; &quot;I’m pretty sure &#x27;o3-mini&#x27; works better for that purpose than &#x27;GPT 4.1.3&#x27;.&quot; – TeMPOraL<p>But that comment is not in the user TeMPOraL&#x27;s comment history.<p>Sentiment analysis is also faulty.<p>For example:<p>&gt; &quot;I’d bet most users just 50&#x2F;50 it, which actually makes it more remarkable that there was a 56% selection rate.&quot; – jackbrookes
 – This quip injects humor into an otherwise technical discussion about evaluation metrics.<p>It&#x27;s not a quip though. That comment was meant in earnest</div><br/><div id="42894628" class="c"><input type="checkbox" id="c-42894628" checked=""/><div class="controls bullet"><span class="by">romanhn</span><span>|</span><a href="#42891858">root</a><span>|</span><a href="#42893720">parent</a><span>|</span><a href="#42892989">next</a><span>|</span><label class="collapse" for="c-42894628">[-]</label><label class="expand" for="c-42894628">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s funny, the quote exists, but it got the user wrong.</div><br/></div></div></div></div></div></div></div></div><div id="42892989" class="c"><input type="checkbox" id="c-42892989" checked=""/><div class="controls bullet"><span class="by">largbae</span><span>|</span><a href="#42891858">parent</a><span>|</span><a href="#42892340">prev</a><span>|</span><a href="#42892105">next</a><span>|</span><label class="collapse" for="c-42892989">[-]</label><label class="expand" for="c-42892989">[1 more]</label></div><br/><div class="children"><div class="content">Thanks for sharing this!  And no apparent self-awareness! OpenAI has come a long way from the Sydney days: <a href="https:&#x2F;&#x2F;answers.microsoft.com&#x2F;en-us&#x2F;bing&#x2F;forum&#x2F;all&#x2F;this-ai-chatbot-sidney-is-misbehaving&#x2F;e3d6a29f-06c9-441c-bc7d-51a68e856761" rel="nofollow">https:&#x2F;&#x2F;answers.microsoft.com&#x2F;en-us&#x2F;bing&#x2F;forum&#x2F;all&#x2F;this-ai-c...</a></div><br/></div></div><div id="42892633" class="c"><input type="checkbox" id="c-42892633" checked=""/><div class="controls bullet"><span class="by">Eduard</span><span>|</span><a href="#42891858">parent</a><span>|</span><a href="#42892105">prev</a><span>|</span><a href="#42894887">next</a><span>|</span><label class="collapse" for="c-42892633">[-]</label><label class="expand" for="c-42892633">[2 more]</label></div><br/><div class="children"><div class="content">3.3612 cents (I guess USD cents) is expensive!</div><br/><div id="42893560" class="c"><input type="checkbox" id="c-42893560" checked=""/><div class="controls bullet"><span class="by">BoorishBears</span><span>|</span><a href="#42891858">root</a><span>|</span><a href="#42892633">parent</a><span>|</span><a href="#42894887">next</a><span>|</span><label class="collapse" for="c-42893560">[-]</label><label class="expand" for="c-42893560">[1 more]</label></div><br/><div class="children"><div class="content">Same immediate thought: the free option I provide on my production site is a model that runs on 2xA40. That&#x27;s 96GB of VRAM for 78 cents an hour serving at least 4 or 5 concurrent requests at any given time.<p>O3 Mini is probably not a very large model and OpenAI has layers upon layers of efficiencies, so they must be making an absolute <i>killing</i> charging 3.3 cents for a few seconds of compute</div><br/></div></div></div></div><div id="42894887" class="c"><input type="checkbox" id="c-42894887" checked=""/><div class="controls bullet"><span class="by">thousand_nights</span><span>|</span><a href="#42891858">parent</a><span>|</span><a href="#42892633">prev</a><span>|</span><a href="#42891760">next</a><span>|</span><label class="collapse" for="c-42894887">[-]</label><label class="expand" for="c-42894887">[1 more]</label></div><br/><div class="children"><div class="content">good morning!</div><br/></div></div></div></div><div id="42891760" class="c"><input type="checkbox" id="c-42891760" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#42891858">prev</a><span>|</span><a href="#42893814">next</a><span>|</span><label class="collapse" for="c-42891760">[-]</label><label class="expand" for="c-42891760">[8 more]</label></div><br/><div class="children"><div class="content">I just pushed a new release of my LLM CLI tool with support for the new model and the reasoning_effort option: <a href="https:&#x2F;&#x2F;llm.datasette.io&#x2F;en&#x2F;stable&#x2F;changelog.html#v0-21" rel="nofollow">https:&#x2F;&#x2F;llm.datasette.io&#x2F;en&#x2F;stable&#x2F;changelog.html#v0-21</a><p>Example usage:<p><pre><code>  llm -m o3-mini &#x27;write a poem about a pirate and a walrus&#x27; \
    -o reasoning_effort high
</code></pre>
Output (comparing that with the default reasoning effort): <a href="https:&#x2F;&#x2F;github.com&#x2F;simonw&#x2F;llm&#x2F;issues&#x2F;728#issuecomment-2628321507">https:&#x2F;&#x2F;github.com&#x2F;simonw&#x2F;llm&#x2F;issues&#x2F;728#issuecomment-262832...</a><p>(If anyone has a better demo prompt I&#x27;d love to hear about it)</div><br/><div id="42892492" class="c"><input type="checkbox" id="c-42892492" checked=""/><div class="controls bullet"><span class="by">beklein</span><span>|</span><a href="#42891760">parent</a><span>|</span><a href="#42892620">next</a><span>|</span><label class="collapse" for="c-42892492">[-]</label><label class="expand" for="c-42892492">[1 more]</label></div><br/><div class="children"><div class="content">Thank you for all the effort you put into this tool and keeping it up to date!</div><br/></div></div><div id="42892620" class="c"><input type="checkbox" id="c-42892620" checked=""/><div class="controls bullet"><span class="by">theturtle32</span><span>|</span><a href="#42891760">parent</a><span>|</span><a href="#42892492">prev</a><span>|</span><a href="#42893814">next</a><span>|</span><label class="collapse" for="c-42892620">[-]</label><label class="expand" for="c-42892620">[6 more]</label></div><br/><div class="children"><div class="content">A reasoning model is not meant for writing poetry. It&#x27;s not very useful to evaluate it on such tasks.</div><br/><div id="42892709" class="c"><input type="checkbox" id="c-42892709" checked=""/><div class="controls bullet"><span class="by">mediaman</span><span>|</span><a href="#42891760">root</a><span>|</span><a href="#42892620">parent</a><span>|</span><a href="#42893447">next</a><span>|</span><label class="collapse" for="c-42892709">[-]</label><label class="expand" for="c-42892709">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not clear that writing poetry is a bad use case. Reasoning models seem to actually do pretty well with creative writing and poetry. Deepseek&#x27;s R1, for example, has much better poem structure than the underlying V3, and writers are saying R1 was the first model where they actually felt like it was a useful writing companion. R1 seems to think at length about word choice, correcting structure, pentameter, and so on.</div><br/><div id="42893377" class="c"><input type="checkbox" id="c-42893377" checked=""/><div class="controls bullet"><span class="by">1propionyl</span><span>|</span><a href="#42891760">root</a><span>|</span><a href="#42892709">parent</a><span>|</span><a href="#42893447">next</a><span>|</span><label class="collapse" for="c-42893377">[-]</label><label class="expand" for="c-42893377">[1 more]</label></div><br/><div class="children"><div class="content">Indeed. I would assume that a reasoning model would do far better at things like actually maintaining meter or rhyme scheme, something that models (even with good attention mechanisms) generally do very poorly at.</div><br/></div></div></div></div><div id="42893447" class="c"><input type="checkbox" id="c-42893447" checked=""/><div class="controls bullet"><span class="by">mquander</span><span>|</span><a href="#42891760">root</a><span>|</span><a href="#42892620">parent</a><span>|</span><a href="#42892709">prev</a><span>|</span><a href="#42894646">next</a><span>|</span><label class="collapse" for="c-42893447">[-]</label><label class="expand" for="c-42893447">[1 more]</label></div><br/><div class="children"><div class="content">I tried to tell my English teachers that all through high school but it never worked.</div><br/></div></div><div id="42894646" class="c"><input type="checkbox" id="c-42894646" checked=""/><div class="controls bullet"><span class="by">DonHopkins</span><span>|</span><a href="#42891760">root</a><span>|</span><a href="#42892620">parent</a><span>|</span><a href="#42893447">prev</a><span>|</span><a href="#42893793">next</a><span>|</span><label class="collapse" for="c-42894646">[-]</label><label class="expand" for="c-42894646">[1 more]</label></div><br/><div class="children"><div class="content">There exists poetry that requires a lot of mathematical understanding! This is &quot;literally&quot; (and I mean literally in the literary sense) from a Stanislaw Lem story about an electronic bard, translated from Polish by Michael Kandel:<p><a href="https:&#x2F;&#x2F;www.donhopkins.com&#x2F;home&#x2F;catalog&#x2F;lem&#x2F;WonderfulPoems.html" rel="nofollow">https:&#x2F;&#x2F;www.donhopkins.com&#x2F;home&#x2F;catalog&#x2F;lem&#x2F;WonderfulPoems.h...</a><p>Prompt:<p>A love poem, lyrical, pastoral, and expressed in the language of pure mathematics. Tensor algebra mainly, with a little topology and higher calculus, if need be. But with feeling, you understand, and in the cybernetic spirit.<p>Response:<p><pre><code>    Come, let us hasten to a higher plane,
    Where dyads tread the fairy fields of Venn,
    Their indices bedecked from one to n,
    Commingled in an endless Markov chain!
    Come, every frustum longs to be a cone,
    And every vector dreams of matrices.
    Hark to the gentle gradient of the breeze:
    It whispers of a more ergodic zone.

    In Riemann, Hilbert or in Banach space
    Let superscripts and subscripts go their ways.
    Our asymptotes no longer out of phase,
    We shall encounter, counting, face to face.

    I&#x27;ll grant thee random access to my heart,
    Thou&#x27;lt tell me all the constants of thy love;
    And so we two shall all love&#x27;s lemmas prove,
    And in our bound partition never part.

    For what did Cauchy know, or Christoffel,
    Or Fourier, or any Boole or Euler,
    Wielding their compasses, their pens and rulers,
    Of thy supernal sinusoidal spell?

    Cancel me not -- for what then shall remain?
    Abscissas, some mantissas, modules, modes,
    A root or two, a torus and a node:
    The inverse of my verse, a null domain.

    Ellipse of bliss, converse, O lips divine!
    The product of our scalars is defined!
    Cyberiad draws nigh, and the skew mind
    cuts capers like a happy haversine.

    I see the eigenvalue in thine eye,
    I hear the tender tensor in thy sigh.
    Bernoulli would have been content to die,
    Had he but known such a squared cosine 2 phi!
</code></pre>
From The Cyberiad, by Stanislaw Lem.<p>Translated from Polish by Michael Kandel.<p>Here&#x27;s a previous discussion of Marcin Wichary&#x27;s translation of one of Lem&#x27;s stories from Polish to English. He created the Lem Google Doodle, and he stalked and met Stanislaw Lem when he was a boy. Plus a discussion of Michael Kandel&#x27;s translation of the poetry of the Electric Bard from The First Sally of Cyberiad, comparing it to machine translation:<p><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=28600200">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=28600200</a><p>Stanislaw Lem has finally gotten the translations his genius deserves:<p><a href="https:&#x2F;&#x2F;www.washingtonpost.com&#x2F;entertainment&#x2F;books&#x2F;stanislaw-lem-has-finally-gotten-the-translations-his-genius-deserves&#x2F;2020&#x2F;03&#x2F;03&#x2F;3227b18c-5982-11ea-ab68-101ecfec2532_story.html" rel="nofollow">https:&#x2F;&#x2F;www.washingtonpost.com&#x2F;entertainment&#x2F;books&#x2F;stanislaw...</a><p>&gt;Lem’s fiction is filled with haunting, prescient landscapes. In these reissued and newly issued translations — some by the pitch-perfect Lem-o-phile, Michael Kandel — each sentence is as hard, gleaming and unpredictable as the next marvelous invention or plot twist. It’s hard to keep up with Lem’s hyper-drive of an imagination but always fun to try.</div><br/></div></div><div id="42893793" class="c"><input type="checkbox" id="c-42893793" checked=""/><div class="controls bullet"><span class="by">aprilthird2021</span><span>|</span><a href="#42891760">root</a><span>|</span><a href="#42892620">parent</a><span>|</span><a href="#42894646">prev</a><span>|</span><a href="#42893814">next</a><span>|</span><label class="collapse" for="c-42893793">[-]</label><label class="expand" for="c-42893793">[1 more]</label></div><br/><div class="children"><div class="content">To be blunt, an AI isn&#x27;t a good tool for writing poetry either. At least, not the kind people read as a high literature form. For commercials, jingles, Hallmark cards, etc. sure</div><br/></div></div></div></div></div></div><div id="42893814" class="c"><input type="checkbox" id="c-42893814" checked=""/><div class="controls bullet"><span class="by">anotherpaulg</span><span>|</span><a href="#42891760">prev</a><span>|</span><a href="#42890823">next</a><span>|</span><label class="collapse" for="c-42893814">[-]</label><label class="expand" for="c-42893814">[4 more]</label></div><br/><div class="children"><div class="content">For AI coding, o3-mini scored similarly to o1 at 10X less cost on the aider polyglot benchmark [0]. This comparison was with both models using high reasoning effort. o3-mini with medium effort scored in between R1 and Sonnet.<p><pre><code>  62% $186 o1 high
  60%  $18 o3-mini high
  57%   $5 DeepSeek R1
  54%   $9 o3-mini medium
  52%  $14 Sonnet
  48%   $0 DeepSeek V3
</code></pre>
[0] <a href="https:&#x2F;&#x2F;aider.chat&#x2F;docs&#x2F;leaderboards&#x2F;" rel="nofollow">https:&#x2F;&#x2F;aider.chat&#x2F;docs&#x2F;leaderboards&#x2F;</a></div><br/><div id="42894796" class="c"><input type="checkbox" id="c-42894796" checked=""/><div class="controls bullet"><span class="by">stavros</span><span>|</span><a href="#42893814">parent</a><span>|</span><a href="#42894005">next</a><span>|</span><label class="collapse" for="c-42894796">[-]</label><label class="expand" for="c-42894796">[1 more]</label></div><br/><div class="children"><div class="content">Do you have plans to try o3-mini-high as the architect and Sonnet as the model?</div><br/></div></div><div id="42894005" class="c"><input type="checkbox" id="c-42894005" checked=""/><div class="controls bullet"><span class="by">throw83288</span><span>|</span><a href="#42893814">parent</a><span>|</span><a href="#42894796">prev</a><span>|</span><a href="#42890823">next</a><span>|</span><label class="collapse" for="c-42894005">[-]</label><label class="expand" for="c-42894005">[2 more]</label></div><br/><div class="children"><div class="content">What do you expect to come from full o3 in terms of automating software engineering?</div><br/><div id="42894232" class="c"><input type="checkbox" id="c-42894232" checked=""/><div class="controls bullet"><span class="by">nextworddev</span><span>|</span><a href="#42893814">root</a><span>|</span><a href="#42894005">parent</a><span>|</span><a href="#42890823">next</a><span>|</span><label class="collapse" for="c-42894232">[-]</label><label class="expand" for="c-42894232">[1 more]</label></div><br/><div class="children"><div class="content">o3 (high) might score 80%+</div><br/></div></div></div></div></div></div><div id="42890823" class="c"><input type="checkbox" id="c-42890823" checked=""/><div class="controls bullet"><span class="by">georgewsinger</span><span>|</span><a href="#42893814">prev</a><span>|</span><a href="#42890667">next</a><span>|</span><label class="collapse" for="c-42890823">[-]</label><label class="expand" for="c-42890823">[16 more]</label></div><br/><div class="children"><div class="content">Did anyone else notice that o3-mini&#x27;s SWE bench dropped from 61% in the leaked System Card earlier today to 49.3% in this blog post, which puts o3-mini back in line with Claude on real-world coding tasks?<p>Am I missing something?</div><br/><div id="42890907" class="c"><input type="checkbox" id="c-42890907" checked=""/><div class="controls bullet"><span class="by">anothermathbozo</span><span>|</span><a href="#42890823">parent</a><span>|</span><a href="#42890900">next</a><span>|</span><label class="collapse" for="c-42890907">[-]</label><label class="expand" for="c-42890907">[5 more]</label></div><br/><div class="children"><div class="content">I think this is with and without &quot;tools.&quot; They explain it in the system card:<p>&gt; We evaluate SWE-bench in two settings:  
&gt; *• Agentless*, which is used for all models except o3-mini (tools). This setting uses the Agentless 1.0 scaffold, and models are given 5 tries to generate a candidate patch. We compute pass@1 by averaging the per-instance pass rates of all samples that generated a valid (i.e., non-empty) patch. If the model fails to generate a valid patch on every attempt, that instance is considered incorrect.<p>&gt; *• o3-mini (tools)*, which uses an internal tool scaffold designed for efficient iterative file editing and debugging. In this setting, we average over 4 tries per instance to compute pass@1 (unlike Agentless, the error rate does not significantly impact results). o3-mini (tools) was evaluated using a non-final checkpoint that differs slightly from the o3-mini launch candidate.</div><br/><div id="42891269" class="c"><input type="checkbox" id="c-42891269" checked=""/><div class="controls bullet"><span class="by">Bjorkbat</span><span>|</span><a href="#42890823">root</a><span>|</span><a href="#42890907">parent</a><span>|</span><a href="#42890959">next</a><span>|</span><label class="collapse" for="c-42891269">[-]</label><label class="expand" for="c-42891269">[3 more]</label></div><br/><div class="children"><div class="content">So am I to understand that they used their internal tooling scaffold on the o3(tools) results only?  Because if so, I really don&#x27;t like that.<p>While it&#x27;s nonetheless impressive that they scored 61% on SWE-bench with o3-mini combined with their tool scaffolding, comparing Agentless performance with other models seems less impressive, 40% vs 35% when compared to o1-mini if you look at the graph on page 28 of their system card pdf (<a href="https:&#x2F;&#x2F;cdn.openai.com&#x2F;o3-mini-system-card.pdf" rel="nofollow">https:&#x2F;&#x2F;cdn.openai.com&#x2F;o3-mini-system-card.pdf</a>).<p>It just feels like data manipulation to suggest that o3-mini is much more performant than past models.  A fairer picture would still paint a performance improvement, but it look less exciting and more incremental.<p>Of course the real improvement is cost, but still, it kind of rubs me the wrong way.</div><br/><div id="42891545" class="c"><input type="checkbox" id="c-42891545" checked=""/><div class="controls bullet"><span class="by">pockmarked19</span><span>|</span><a href="#42890823">root</a><span>|</span><a href="#42891269">parent</a><span>|</span><a href="#42890959">next</a><span>|</span><label class="collapse" for="c-42891545">[-]</label><label class="expand" for="c-42891545">[2 more]</label></div><br/><div class="children"><div class="content">YC usually says “a startup is the point in your life where tricks stop working”.<p>Sam Altman is somehow finding this out now, the hard way.<p>Most paying customers will find out within minutes whether the models can serve their use case, a benchmark isn’t going to change that except for media manipulation (and even that doesn’t work all that well, since journalists don’t really know what they are saying and readers can tell).</div><br/><div id="42896806" class="c"><input type="checkbox" id="c-42896806" checked=""/><div class="controls bullet"><span class="by">galaxyLogic</span><span>|</span><a href="#42890823">root</a><span>|</span><a href="#42891545">parent</a><span>|</span><a href="#42890959">next</a><span>|</span><label class="collapse" for="c-42896806">[-]</label><label class="expand" for="c-42896806">[1 more]</label></div><br/><div class="children"><div class="content">My guess is this cheap mini-model comes out now after DeepSeek very recently shook the stock-market greatly with its cheap price and relatively good performance. .</div><br/></div></div></div></div></div></div><div id="42890959" class="c"><input type="checkbox" id="c-42890959" checked=""/><div class="controls bullet"><span class="by">georgewsinger</span><span>|</span><a href="#42890823">root</a><span>|</span><a href="#42890907">parent</a><span>|</span><a href="#42891269">prev</a><span>|</span><a href="#42890900">next</a><span>|</span><label class="collapse" for="c-42890959">[-]</label><label class="expand" for="c-42890959">[1 more]</label></div><br/><div class="children"><div class="content">Makes sense. Thanks for the correction.</div><br/></div></div></div></div><div id="42890900" class="c"><input type="checkbox" id="c-42890900" checked=""/><div class="controls bullet"><span class="by">jakereps</span><span>|</span><a href="#42890823">parent</a><span>|</span><a href="#42890907">prev</a><span>|</span><a href="#42890918">next</a><span>|</span><label class="collapse" for="c-42890900">[-]</label><label class="expand" for="c-42890900">[2 more]</label></div><br/><div class="children"><div class="content">The caption on the graph explains.<p>&gt; including with the open-source Agentless scaffold (39%) and an internal tools scaffold (61%), see our system card .<p>I have no idea what an &quot;internal tools scaffold&quot; is but the graph on the card that they link directly to specifies &quot;o3-mini (tools)&quot; where the blog post is talking about others.</div><br/><div id="42891361" class="c"><input type="checkbox" id="c-42891361" checked=""/><div class="controls bullet"><span class="by">DrewHintz</span><span>|</span><a href="#42890823">root</a><span>|</span><a href="#42890900">parent</a><span>|</span><a href="#42890918">next</a><span>|</span><label class="collapse" for="c-42891361">[-]</label><label class="expand" for="c-42891361">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m guessing an &quot;internal tools scaffold&quot; is something like Goose: <a href="https:&#x2F;&#x2F;github.com&#x2F;block&#x2F;goose">https:&#x2F;&#x2F;github.com&#x2F;block&#x2F;goose</a><p>Instead of just generating a patch (copilot style), it generates the patch, applies the patch, runs the code, and then iterates based on the execution output.</div><br/></div></div></div></div><div id="42890857" class="c"><input type="checkbox" id="c-42890857" checked=""/><div class="controls bullet"><span class="by">logicchains</span><span>|</span><a href="#42890823">parent</a><span>|</span><a href="#42890916">prev</a><span>|</span><a href="#42890667">next</a><span>|</span><label class="collapse" for="c-42890857">[-]</label><label class="expand" for="c-42890857">[6 more]</label></div><br/><div class="children"><div class="content">Maybe they found a need to quantize it further for release, or lobotomise it with more &quot;alignment&quot;.</div><br/><div id="42891404" class="c"><input type="checkbox" id="c-42891404" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#42890823">root</a><span>|</span><a href="#42890857">parent</a><span>|</span><a href="#42890881">next</a><span>|</span><label class="collapse" for="c-42891404">[-]</label><label class="expand" for="c-42891404">[4 more]</label></div><br/><div class="children"><div class="content">&gt; lobotomise<p>Anyone can write very fast software if you don&#x27;t mind it sometimes crashing or having weird bugs.<p>Why do people try to meme as if AI is different? It has unexpected outputs sometimes, getting it to not do that is 50% &quot;more alignment&quot; and 50% &quot;hallucinate less&quot;.<p>Just today I saw someone get the Amazon bot to roleplay furry erotica. Funny, sure, but it&#x27;s still obviously a bug that a *sales bot* would do that.<p>And given these models do actually get stuff wrong, is it really <i>incorrect</i> for them to refuse to help with things they might be dangerous if the user isn&#x27;t already skilled, like Claude in this story about DIY fusion? <a href="https:&#x2F;&#x2F;www.corememory.com&#x2F;p&#x2F;a-young-man-used-ai-to-build-a-nuclear" rel="nofollow">https:&#x2F;&#x2F;www.corememory.com&#x2F;p&#x2F;a-young-man-used-ai-to-build-a-...</a></div><br/><div id="42891527" class="c"><input type="checkbox" id="c-42891527" checked=""/><div class="controls bullet"><span class="by">Rastonbury</span><span>|</span><a href="#42890823">root</a><span>|</span><a href="#42891404">parent</a><span>|</span><a href="#42892074">next</a><span>|</span><label class="collapse" for="c-42891527">[-]</label><label class="expand" for="c-42891527">[1 more]</label></div><br/><div class="children"><div class="content">They are implying the release was rushed and they had to reduce the functionality of the model in order to make sure it did not teach people how to make dirty bombs</div><br/></div></div><div id="42892074" class="c"><input type="checkbox" id="c-42892074" checked=""/><div class="controls bullet"><span class="by">bee_rider</span><span>|</span><a href="#42890823">root</a><span>|</span><a href="#42891404">parent</a><span>|</span><a href="#42891527">prev</a><span>|</span><a href="#42890881">next</a><span>|</span><label class="collapse" for="c-42892074">[-]</label><label class="expand" for="c-42892074">[2 more]</label></div><br/><div class="children"><div class="content">If somebody wants their Amazon bot to role play as an erotic furry, that’s up to them, right? Who cares. It is working as intended if it keeps them going back to the site and buying things I guess.<p>I don’t know why somebody would want that, seems annoying. But I also don’t expect people to explain why they do this kind of stuff.</div><br/><div id="42892316" class="c"><input type="checkbox" id="c-42892316" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#42890823">root</a><span>|</span><a href="#42892074">parent</a><span>|</span><a href="#42890881">next</a><span>|</span><label class="collapse" for="c-42892316">[-]</label><label class="expand" for="c-42892316">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s still a bug. Not really working as intended — it doesn&#x27;t sell anything from that.<p>A very funny bug, but a bug nonetheless.<p>And given this was shared via screenshots, it was done for a laugh.</div><br/></div></div></div></div></div></div><div id="42890881" class="c"><input type="checkbox" id="c-42890881" checked=""/><div class="controls bullet"><span class="by">kkzz99</span><span>|</span><a href="#42890823">root</a><span>|</span><a href="#42890857">parent</a><span>|</span><a href="#42891404">prev</a><span>|</span><a href="#42890667">next</a><span>|</span><label class="collapse" for="c-42890881">[-]</label><label class="expand" for="c-42890881">[1 more]</label></div><br/><div class="children"><div class="content">Or the number was never real to begin with.</div><br/></div></div></div></div></div></div><div id="42890667" class="c"><input type="checkbox" id="c-42890667" checked=""/><div class="controls bullet"><span class="by">sss111</span><span>|</span><a href="#42890823">prev</a><span>|</span><a href="#42894680">next</a><span>|</span><label class="collapse" for="c-42890667">[-]</label><label class="expand" for="c-42890667">[61 more]</label></div><br/><div class="children"><div class="content">So far, it seems like this is the hierarchy<p>o1 &gt; GPT-4o &gt; o3-mini &gt; o1-mini &gt; GPT-4o-mini<p>o3 mini system card: <a href="https:&#x2F;&#x2F;cdn.openai.com&#x2F;o3-mini-system-card.pdf" rel="nofollow">https:&#x2F;&#x2F;cdn.openai.com&#x2F;o3-mini-system-card.pdf</a></div><br/><div id="42890696" class="c"><input type="checkbox" id="c-42890696" checked=""/><div class="controls bullet"><span class="by">sho_hn</span><span>|</span><a href="#42890667">parent</a><span>|</span><a href="#42891225">next</a><span>|</span><label class="collapse" for="c-42890696">[-]</label><label class="expand" for="c-42890696">[24 more]</label></div><br/><div class="children"><div class="content">I think OpenAI really needs to rethink its product naming, especially now that they have a portfolio where there&#x27;s no such clear hierarchy, but they have a place along different axis (speed, cost, reasoning, capabilities, etc).<p>Your summary attempt e.g. also misses o3-mini vs o3-mini-high. Lots of trade-ofs.</div><br/><div id="42891599" class="c"><input type="checkbox" id="c-42891599" checked=""/><div class="controls bullet"><span class="by">nullpoint420</span><span>|</span><a href="#42890667">root</a><span>|</span><a href="#42890696">parent</a><span>|</span><a href="#42893204">next</a><span>|</span><label class="collapse" for="c-42891599">[-]</label><label class="expand" for="c-42891599">[7 more]</label></div><br/><div class="children"><div class="content">Can&#x27;t wait for the eventual rename to GPT Core, GPT Plus, GPT Pro, and GPT Pro Max models!<p>I can see it now:<p>&gt; Unlock our industry leading reasoning features by upgrading to the GPT 4 Pro Max plan.</div><br/><div id="42893568" class="c"><input type="checkbox" id="c-42893568" checked=""/><div class="controls bullet"><span class="by">kugelblitz</span><span>|</span><a href="#42890667">root</a><span>|</span><a href="#42891599">parent</a><span>|</span><a href="#42891965">next</a><span>|</span><label class="collapse" for="c-42893568">[-]</label><label class="expand" for="c-42893568">[2 more]</label></div><br/><div class="children"><div class="content">Had the same problem while trying to decide which Roborock device to get. There&#x27;s the S series, Saros series, Q Series and the Qrevo. And from the Qrevo, there&#x27;s Qrevo Curv, Edge, Slim, Master, MaxV, Plus, Pro, S and without anything. The S Series had S8, S8+, S8 Pro Ultra, S8 Max Ultra, S8 MaxV Ultra. It was so confusing.</div><br/><div id="42896709" class="c"><input type="checkbox" id="c-42896709" checked=""/><div class="controls bullet"><span class="by">slowmotiony</span><span>|</span><a href="#42890667">root</a><span>|</span><a href="#42893568">parent</a><span>|</span><a href="#42891965">next</a><span>|</span><label class="collapse" for="c-42896709">[-]</label><label class="expand" for="c-42896709">[1 more]</label></div><br/><div class="children"><div class="content">I ordered the wrong xbox on amazon once. Wanted the series X, got the one X instead</div><br/></div></div></div></div><div id="42891965" class="c"><input type="checkbox" id="c-42891965" checked=""/><div class="controls bullet"><span class="by">raphman</span><span>|</span><a href="#42890667">root</a><span>|</span><a href="#42891599">parent</a><span>|</span><a href="#42893568">prev</a><span>|</span><a href="#42891943">next</a><span>|</span><label class="collapse" for="c-42891965">[-]</label><label class="expand" for="c-42891965">[1 more]</label></div><br/><div class="children"><div class="content">Oh, I&#x27;ll probably wait for GPT 4 Pro Max v2 NG (improved)</div><br/></div></div><div id="42891943" class="c"><input type="checkbox" id="c-42891943" checked=""/><div class="controls bullet"><span class="by">wlll</span><span>|</span><a href="#42890667">root</a><span>|</span><a href="#42891599">parent</a><span>|</span><a href="#42891965">prev</a><span>|</span><a href="#42892225">next</a><span>|</span><label class="collapse" for="c-42891943">[-]</label><label class="expand" for="c-42891943">[1 more]</label></div><br/><div class="children"><div class="content">I think I&#x27;ll wait for the GTI model myself.</div><br/></div></div><div id="42892225" class="c"><input type="checkbox" id="c-42892225" checked=""/><div class="controls bullet"><span class="by">FridgeSeal</span><span>|</span><a href="#42890667">root</a><span>|</span><a href="#42891599">parent</a><span>|</span><a href="#42891943">prev</a><span>|</span><a href="#42893131">next</a><span>|</span><label class="collapse" for="c-42892225">[-]</label><label class="expand" for="c-42892225">[1 more]</label></div><br/><div class="children"><div class="content">OpenAI chatGPT Pro Max XS Core, not to be confused with ChatGPT Max S Pro Net Core X, or ChatGPT Pro Max XS Professional CoPilot Edition.</div><br/></div></div><div id="42893131" class="c"><input type="checkbox" id="c-42893131" checked=""/><div class="controls bullet"><span class="by">jmkni</span><span>|</span><a href="#42890667">root</a><span>|</span><a href="#42891599">parent</a><span>|</span><a href="#42892225">prev</a><span>|</span><a href="#42893204">next</a><span>|</span><label class="collapse" for="c-42893131">[-]</label><label class="expand" for="c-42893131">[1 more]</label></div><br/><div class="children"><div class="content">ngl I&#x27;d find that easier to follow lol</div><br/></div></div></div></div><div id="42893204" class="c"><input type="checkbox" id="c-42893204" checked=""/><div class="controls bullet"><span class="by">__MatrixMan__</span><span>|</span><a href="#42890667">root</a><span>|</span><a href="#42890696">parent</a><span>|</span><a href="#42891599">prev</a><span>|</span><a href="#42890761">next</a><span>|</span><label class="collapse" for="c-42893204">[-]</label><label class="expand" for="c-42893204">[1 more]</label></div><br/><div class="children"><div class="content">Careful what you wish for. Next thing you know they&#x27;re going to have names like Betsy and be full of unique quirky behavior to help remind us that they&#x27;re different people.</div><br/></div></div><div id="42890761" class="c"><input type="checkbox" id="c-42890761" checked=""/><div class="controls bullet"><span class="by">rf15</span><span>|</span><a href="#42890667">root</a><span>|</span><a href="#42890696">parent</a><span>|</span><a href="#42893204">prev</a><span>|</span><a href="#42891304">next</a><span>|</span><label class="collapse" for="c-42890761">[-]</label><label class="expand" for="c-42890761">[5 more]</label></div><br/><div class="children"><div class="content">They&#x27;re strongly tied to Microsoft, so confusing branding is to be expected.</div><br/><div id="42891359" class="c"><input type="checkbox" id="c-42891359" checked=""/><div class="controls bullet"><span class="by">ngokevin</span><span>|</span><a href="#42890667">root</a><span>|</span><a href="#42890761">parent</a><span>|</span><a href="#42890965">next</a><span>|</span><label class="collapse" for="c-42891359">[-]</label><label class="expand" for="c-42891359">[1 more]</label></div><br/><div class="children"><div class="content">It needs to be clowned on here:<p>- Xbox, Xbox 360, Xbox One, Xbox One S&#x2F;X, Xbox Series S&#x2F;X<p>- Windows 3.1...98, 2000, ME, XP, Vista, 7, 8, 10<p>I guess it&#x27;s better than headphones names (QC35, WH-1000XM3, M50x, HD560s).</div><br/></div></div><div id="42890965" class="c"><input type="checkbox" id="c-42890965" checked=""/><div class="controls bullet"><span class="by">ANewFormation</span><span>|</span><a href="#42890667">root</a><span>|</span><a href="#42890761">parent</a><span>|</span><a href="#42891359">prev</a><span>|</span><a href="#42890904">next</a><span>|</span><label class="collapse" for="c-42890965">[-]</label><label class="expand" for="c-42890965">[1 more]</label></div><br/><div class="children"><div class="content">I can&#x27;t wait for Project Unify which just devolves into a brand new p3-mini type naming convention. It&#x27;s pretty much identical to the o3-mini, except the API is changed just enough to be completely incompatible and it crashes on any query using a word with more than two syllables. Fix coming soon, for 4 years so far.<p>On the bright side the app now has curved edges!</div><br/></div></div><div id="42890904" class="c"><input type="checkbox" id="c-42890904" checked=""/><div class="controls bullet"><span class="by">chris_va</span><span>|</span><a href="#42890667">root</a><span>|</span><a href="#42890761">parent</a><span>|</span><a href="#42890965">prev</a><span>|</span><a href="#42891539">next</a><span>|</span><label class="collapse" for="c-42890904">[-]</label><label class="expand" for="c-42890904">[1 more]</label></div><br/><div class="children"><div class="content">One of my favorite parodies: <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=EUXnJraKM3k" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=EUXnJraKM3k</a></div><br/></div></div><div id="42891539" class="c"><input type="checkbox" id="c-42891539" checked=""/><div class="controls bullet"><span class="by">nejsjsjsbsb</span><span>|</span><a href="#42890667">root</a><span>|</span><a href="#42890761">parent</a><span>|</span><a href="#42890904">prev</a><span>|</span><a href="#42891304">next</a><span>|</span><label class="collapse" for="c-42891539">[-]</label><label class="expand" for="c-42891539">[1 more]</label></div><br/><div class="children"><div class="content">Flashbacks of the .NET zoo. At least they reigned that in.</div><br/></div></div></div></div><div id="42891304" class="c"><input type="checkbox" id="c-42891304" checked=""/><div class="controls bullet"><span class="by">Euphorbium</span><span>|</span><a href="#42890667">root</a><span>|</span><a href="#42890696">parent</a><span>|</span><a href="#42890761">prev</a><span>|</span><a href="#42890742">next</a><span>|</span><label class="collapse" for="c-42891304">[-]</label><label class="expand" for="c-42891304">[3 more]</label></div><br/><div class="children"><div class="content">They can still do models o3o, oo3 and 3oo. Mini-o3o-high, not to be confused with mini-O3o-high (the first o is capital).</div><br/><div id="42891670" class="c"><input type="checkbox" id="c-42891670" checked=""/><div class="controls bullet"><span class="by">margalabargala</span><span>|</span><a href="#42890667">root</a><span>|</span><a href="#42891304">parent</a><span>|</span><a href="#42891548">next</a><span>|</span><label class="collapse" for="c-42891670">[-]</label><label class="expand" for="c-42891670">[1 more]</label></div><br/><div class="children"><div class="content">They should just start encoding the model ID in trinary using o, O, and 0.<p>Model 00oOo is better than Model 0OoO0!</div><br/></div></div><div id="42891548" class="c"><input type="checkbox" id="c-42891548" checked=""/><div class="controls bullet"><span class="by">brookst</span><span>|</span><a href="#42890667">root</a><span>|</span><a href="#42891304">parent</a><span>|</span><a href="#42891670">prev</a><span>|</span><a href="#42890742">next</a><span>|</span><label class="collapse" for="c-42891548">[-]</label><label class="expand" for="c-42891548">[1 more]</label></div><br/><div class="children"><div class="content">You’re thinking too small. What about o10, O1o, o3-m1n1?</div><br/></div></div></div></div><div id="42890742" class="c"><input type="checkbox" id="c-42890742" checked=""/><div class="controls bullet"><span class="by">echelon</span><span>|</span><a href="#42890667">root</a><span>|</span><a href="#42890696">parent</a><span>|</span><a href="#42891304">prev</a><span>|</span><a href="#42890759">next</a><span>|</span><label class="collapse" for="c-42890742">[-]</label><label class="expand" for="c-42890742">[5 more]</label></div><br/><div class="children"><div class="content">It&#x27;s like AWS SKU naming (`c5d.metal`, `p5.48xlarge`, etc.), except non-technical consumers are expected to understand it.</div><br/><div id="42890883" class="c"><input type="checkbox" id="c-42890883" checked=""/><div class="controls bullet"><span class="by">maeil</span><span>|</span><a href="#42890667">root</a><span>|</span><a href="#42890742">parent</a><span>|</span><a href="#42891549">next</a><span>|</span><label class="collapse" for="c-42890883">[-]</label><label class="expand" for="c-42890883">[2 more]</label></div><br/><div class="children"><div class="content">Have you seen Azure VM SKU naming? It&#x27;s.. impressive.</div><br/><div id="42891155" class="c"><input type="checkbox" id="c-42891155" checked=""/><div class="controls bullet"><span class="by">buildbot</span><span>|</span><a href="#42890667">root</a><span>|</span><a href="#42890883">parent</a><span>|</span><a href="#42891549">next</a><span>|</span><label class="collapse" for="c-42891155">[-]</label><label class="expand" for="c-42891155">[1 more]</label></div><br/><div class="children"><div class="content">And it doesn’t even line up with the actual instances you’ll be offered. At one point I was using some random Nvidia A10 node that was supposed to be similar to Standard_NV36adms_A10_v5, but was an NC series for some reason with slightly different letters…</div><br/></div></div></div></div><div id="42891549" class="c"><input type="checkbox" id="c-42891549" checked=""/><div class="controls bullet"><span class="by">nejsjsjsbsb</span><span>|</span><a href="#42890667">root</a><span>|</span><a href="#42890742">parent</a><span>|</span><a href="#42890883">prev</a><span>|</span><a href="#42890759">next</a><span>|</span><label class="collapse" for="c-42891549">[-]</label><label class="expand" for="c-42891549">[2 more]</label></div><br/><div class="children"><div class="content">Those are not names but hashes used to look up the specs.</div><br/><div id="42892930" class="c"><input type="checkbox" id="c-42892930" checked=""/><div class="controls bullet"><span class="by">echelon</span><span>|</span><a href="#42890667">root</a><span>|</span><a href="#42891549">parent</a><span>|</span><a href="#42890759">next</a><span>|</span><label class="collapse" for="c-42892930">[-]</label><label class="expand" for="c-42892930">[1 more]</label></div><br/><div class="children"><div class="content">I was thinking we might treat model names analogously, but their specs can be moving targets.</div><br/></div></div></div></div></div></div><div id="42890759" class="c"><input type="checkbox" id="c-42890759" checked=""/><div class="controls bullet"><span class="by">sss111</span><span>|</span><a href="#42890667">root</a><span>|</span><a href="#42890696">parent</a><span>|</span><a href="#42890742">prev</a><span>|</span><a href="#42890814">next</a><span>|</span><label class="collapse" for="c-42890759">[-]</label><label class="expand" for="c-42890759">[1 more]</label></div><br/><div class="children"><div class="content">Yeah I tried my best :(<p>I think they could&#x27;ve borrowed a page out of Apple&#x27;s book, even mountain names would be better. Plus Sonoma, Ventura, and Yosemite are cool names.</div><br/></div></div><div id="42890814" class="c"><input type="checkbox" id="c-42890814" checked=""/><div class="controls bullet"><span class="by">kaaskop</span><span>|</span><a href="#42890667">root</a><span>|</span><a href="#42890696">parent</a><span>|</span><a href="#42890759">prev</a><span>|</span><a href="#42891225">next</a><span>|</span><label class="collapse" for="c-42890814">[-]</label><label class="expand" for="c-42890814">[1 more]</label></div><br/><div class="children"><div class="content">Yeah their naming scheme is super confusing, I honestly confuse them all the time.</div><br/></div></div></div></div><div id="42891225" class="c"><input type="checkbox" id="c-42891225" checked=""/><div class="controls bullet"><span class="by">thot_experiment</span><span>|</span><a href="#42890667">parent</a><span>|</span><a href="#42890696">prev</a><span>|</span><a href="#42890736">next</a><span>|</span><label class="collapse" for="c-42891225">[-]</label><label class="expand" for="c-42891225">[2 more]</label></div><br/><div class="children"><div class="content">at least if i ran the company you&#x27;d know that<p>ChatGPTasdhjf-final-final-use_this_one.pt &gt; ChatGPTasdhjf-final.pt &gt; ChatGPTasdhjf.pt &gt; ChatGPTasd.pt&gt; ChatGPT.pt</div><br/><div id="42895763" class="c"><input type="checkbox" id="c-42895763" checked=""/><div class="controls bullet"><span class="by">idonotknowwhy</span><span>|</span><a href="#42890667">root</a><span>|</span><a href="#42891225">parent</a><span>|</span><a href="#42890736">next</a><span>|</span><label class="collapse" for="c-42895763">[-]</label><label class="expand" for="c-42895763">[1 more]</label></div><br/><div class="children"><div class="content">Did you just ls my &#x2F;workspace dir? Lol</div><br/></div></div></div></div><div id="42890736" class="c"><input type="checkbox" id="c-42890736" checked=""/><div class="controls bullet"><span class="by">gundmc</span><span>|</span><a href="#42890667">parent</a><span>|</span><a href="#42891225">prev</a><span>|</span><a href="#42890684">next</a><span>|</span><label class="collapse" for="c-42890736">[-]</label><label class="expand" for="c-42890736">[4 more]</label></div><br/><div class="children"><div class="content">If this is the hierarchy, why does 4o score so much higher than o1 on LLM Arena?<p>Worrisome for OpenAI that Gemini&#x27;s mini&#x2F;flash reasoning model outscores both o1 and 4o handily.</div><br/><div id="42890754" class="c"><input type="checkbox" id="c-42890754" checked=""/><div class="controls bullet"><span class="by">crazysim</span><span>|</span><a href="#42890667">root</a><span>|</span><a href="#42890736">parent</a><span>|</span><a href="#42893437">next</a><span>|</span><label class="collapse" for="c-42890754">[-]</label><label class="expand" for="c-42890754">[2 more]</label></div><br/><div class="children"><div class="content">Is it possible people are voting for speed of responsiveness too?</div><br/><div id="42892179" class="c"><input type="checkbox" id="c-42892179" checked=""/><div class="controls bullet"><span class="by">kgeist</span><span>|</span><a href="#42890667">root</a><span>|</span><a href="#42890754">parent</a><span>|</span><a href="#42893437">next</a><span>|</span><label class="collapse" for="c-42892179">[-]</label><label class="expand" for="c-42892179">[1 more]</label></div><br/><div class="children"><div class="content">I suspect people on LLM Arena don&#x27;t ask complex questions too often, and reasoning models seem to perform worse than simple models when the goal is just casual conversation or retrieving embedded knowledge. Reasoning models probably &#x27;overthink&#x27; in such cases. And slower, too.</div><br/></div></div></div></div><div id="42893437" class="c"><input type="checkbox" id="c-42893437" checked=""/><div class="controls bullet"><span class="by">energy123</span><span>|</span><a href="#42890667">root</a><span>|</span><a href="#42890736">parent</a><span>|</span><a href="#42890754">prev</a><span>|</span><a href="#42890684">next</a><span>|</span><label class="collapse" for="c-42893437">[-]</label><label class="expand" for="c-42893437">[1 more]</label></div><br/><div class="children"><div class="content">o1 on LLM Arena often times out (network error) while thinking. But they still allow you to vote and they make it seem as if your vote is registered.</div><br/></div></div></div></div><div id="42890684" class="c"><input type="checkbox" id="c-42890684" checked=""/><div class="controls bullet"><span class="by">losvedir</span><span>|</span><a href="#42890667">parent</a><span>|</span><a href="#42890736">prev</a><span>|</span><a href="#42890894">next</a><span>|</span><label class="collapse" for="c-42890684">[-]</label><label class="expand" for="c-42890684">[5 more]</label></div><br/><div class="children"><div class="content">What about &quot;o1 Pro mode&quot;. Is that just o1 but with more reasoning time, like this new o3-mini&#x27;s different amount of reasoning options?</div><br/><div id="42894841" class="c"><input type="checkbox" id="c-42894841" checked=""/><div class="controls bullet"><span class="by">bobjordan</span><span>|</span><a href="#42890667">root</a><span>|</span><a href="#42890684">parent</a><span>|</span><a href="#42890801">next</a><span>|</span><label class="collapse" for="c-42894841">[-]</label><label class="expand" for="c-42894841">[1 more]</label></div><br/><div class="children"><div class="content">I have been paying $200 per month for 01-pro mode and I am very disappointed right now because they have completely replaced the model today. It used to think for 1-5 minutes and deliver an unbelievably useful one-shot answer. Now, it only thinks for 7 seconds just like the 03-mini model and I can&#x27;t tell the difference in the answers. I hope this is just a day 1 implementation bug but I suspect they have just decided to throw the $200 per month customers under the bus so that they&#x27;d have more capacity to launch the 03 model for everybody. I can&#x27;t tell the difference between the models now and it is definitely not because the free 03 model delivers the quality that 01-pro-mode had! I&#x27;m so disappointed!</div><br/></div></div><div id="42890801" class="c"><input type="checkbox" id="c-42890801" checked=""/><div class="controls bullet"><span class="by">MichaelBurge</span><span>|</span><a href="#42890667">root</a><span>|</span><a href="#42890684">parent</a><span>|</span><a href="#42894841">prev</a><span>|</span><a href="#42890894">next</a><span>|</span><label class="collapse" for="c-42890801">[-]</label><label class="expand" for="c-42890801">[3 more]</label></div><br/><div class="children"><div class="content">o1-pro is a different model than o1.</div><br/><div id="42892087" class="c"><input type="checkbox" id="c-42892087" checked=""/><div class="controls bullet"><span class="by">losvedir</span><span>|</span><a href="#42890667">root</a><span>|</span><a href="#42890801">parent</a><span>|</span><a href="#42891765">next</a><span>|</span><label class="collapse" for="c-42892087">[-]</label><label class="expand" for="c-42892087">[1 more]</label></div><br/><div class="children"><div class="content">Are you sure? Do you have any source for that? In this article[0] that was discussed here on HN this week, they say (claim):<p>&gt; In fact, the O1 model used in OpenAI&#x27;s ChatGPT Plus subscription for $20&#x2F;month is basically the same model as the one used in the O1-Pro model featured in their new ChatGPT Pro subscription for 10x the price ($200&#x2F;month, which raised plenty of eyebrows in the developer community); the main difference is that O1-Pro thinks for a lot longer before responding, generating vastly more COT logic tokens, and consuming a far larger amount of inference compute for every response.<p>Granted &quot;basically&quot; is pulling a lot of weight there, but that was the first time I&#x27;d seen anyone speculate either way.<p>[0] <a href="https:&#x2F;&#x2F;youtubetranscriptoptimizer.com&#x2F;blog&#x2F;05_the_short_case_for_nvda" rel="nofollow">https:&#x2F;&#x2F;youtubetranscriptoptimizer.com&#x2F;blog&#x2F;05_the_short_cas...</a></div><br/></div></div><div id="42891765" class="c"><input type="checkbox" id="c-42891765" checked=""/><div class="controls bullet"><span class="by">JohnPrine</span><span>|</span><a href="#42890667">root</a><span>|</span><a href="#42890801">parent</a><span>|</span><a href="#42892087">prev</a><span>|</span><a href="#42890894">next</a><span>|</span><label class="collapse" for="c-42891765">[-]</label><label class="expand" for="c-42891765">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think this is true</div><br/></div></div></div></div></div></div><div id="42890894" class="c"><input type="checkbox" id="c-42890894" checked=""/><div class="controls bullet"><span class="by">usaar333</span><span>|</span><a href="#42890667">parent</a><span>|</span><a href="#42890684">prev</a><span>|</span><a href="#42890732">next</a><span>|</span><label class="collapse" for="c-42890894">[-]</label><label class="expand" for="c-42890894">[1 more]</label></div><br/><div class="children"><div class="content">For non-stem perhaps.<p>For math&#x2F;coding problems, o3 mini is tied if not better than o1.</div><br/></div></div><div id="42890732" class="c"><input type="checkbox" id="c-42890732" checked=""/><div class="controls bullet"><span class="by">LoveMortuus</span><span>|</span><a href="#42890667">parent</a><span>|</span><a href="#42890894">prev</a><span>|</span><a href="#42890757">next</a><span>|</span><label class="collapse" for="c-42890732">[-]</label><label class="expand" for="c-42890732">[6 more]</label></div><br/><div class="children"><div class="content">How would the DeepSeek fit into this?<p>Or can it not compare? I don&#x27;t know much about this stuff, but I&#x27;ve heard recently many people talk about DeepSeek and how unexpected it was.</div><br/><div id="42890771" class="c"><input type="checkbox" id="c-42890771" checked=""/><div class="controls bullet"><span class="by">sss111</span><span>|</span><a href="#42890667">root</a><span>|</span><a href="#42890732">parent</a><span>|</span><a href="#42890757">next</a><span>|</span><label class="collapse" for="c-42890771">[-]</label><label class="expand" for="c-42890771">[5 more]</label></div><br/><div class="children"><div class="content">Deepseek V3 is equivalent to 4o. Deepseek R1 is equivalent to o1 (if not better)<p>I think someone should just build an AI model comparing website at this point. Include all benchmarks and pricing</div><br/><div id="42891354" class="c"><input type="checkbox" id="c-42891354" checked=""/><div class="controls bullet"><span class="by">jsk2600</span><span>|</span><a href="#42890667">root</a><span>|</span><a href="#42890771">parent</a><span>|</span><a href="#42893773">next</a><span>|</span><label class="collapse" for="c-42891354">[-]</label><label class="expand" for="c-42891354">[3 more]</label></div><br/><div class="children"><div class="content">This one is good: <a href="https:&#x2F;&#x2F;artificialanalysis.ai&#x2F;" rel="nofollow">https:&#x2F;&#x2F;artificialanalysis.ai&#x2F;</a></div><br/><div id="42891698" class="c"><input type="checkbox" id="c-42891698" checked=""/><div class="controls bullet"><span class="by">withinboredom</span><span>|</span><a href="#42890667">root</a><span>|</span><a href="#42891354">parent</a><span>|</span><a href="#42893773">next</a><span>|</span><label class="collapse" for="c-42891698">[-]</label><label class="expand" for="c-42891698">[2 more]</label></div><br/><div class="children"><div class="content">Looks like this only compares commercial models, and not the ones I can download and actually run locally.</div><br/><div id="42892155" class="c"><input type="checkbox" id="c-42892155" checked=""/><div class="controls bullet"><span class="by">TuxSH</span><span>|</span><a href="#42890667">root</a><span>|</span><a href="#42891698">parent</a><span>|</span><a href="#42893773">next</a><span>|</span><label class="collapse" for="c-42892155">[-]</label><label class="expand" for="c-42892155">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;livebench.ai&#x2F;#&#x2F;" rel="nofollow">https:&#x2F;&#x2F;livebench.ai&#x2F;#&#x2F;</a><p>My experience is as follows:<p>- &quot;Reason&quot; toggle just got enabled for me as a free tier user of ChatGPT&#x27;s webchat. Apparently this is o3-mini
- I have Copilot Pro (offered to me for free), which apparently has o1 too (as well as Sonnet, etc.)<p>From my experience DeepSeek R1 (webchat) is more expressive, more creative and its writing style is leagues better than OpenAI&#x27;s models, however it under-performs Sonnet when changing code (&quot;code completion&quot;).<p>Comparison screenshots for prompt &quot;In C++, is a reference to &quot;const C&quot; a &quot;const reference to C&quot;?&quot;: <a href="https:&#x2F;&#x2F;imgur.com&#x2F;a&#x2F;c-is-reference-to-const-c-const-reference-to-c-llm-comparison-km8cwZd" rel="nofollow">https:&#x2F;&#x2F;imgur.com&#x2F;a&#x2F;c-is-reference-to-const-c-const-referenc...</a><p>tl;dr keep using Claude for code and DeepSeek webchat for technical questions</div><br/></div></div></div></div></div></div><div id="42893773" class="c"><input type="checkbox" id="c-42893773" checked=""/><div class="controls bullet"><span class="by">dutchbookmaker</span><span>|</span><a href="#42890667">root</a><span>|</span><a href="#42890771">parent</a><span>|</span><a href="#42891354">prev</a><span>|</span><a href="#42890757">next</a><span>|</span><label class="collapse" for="c-42893773">[-]</label><label class="expand" for="c-42893773">[1 more]</label></div><br/><div class="children"><div class="content">I had resubscribed to use o1 2 weeks ago and haven&#x27;t even logged in this week because of R1.<p>One thing I notice that is huge is being able to see the chain of thought lets me see when my prompt was lacking and the model is a bit confused on what I want.<p>If I was anymore impressed with R1 I would probably start getting accused of being a CCP shill or wumao lol.<p>With that said, I think it is very hard to compare models for your own use case.  I do suspect there is a shiny new toy bias with all this too.<p>Poor Sonnet 3.5. I have neglected it so much lately I actually don&#x27;t know if I have a subscription or not right now.<p>I do expect an Anthropic reasoning model though to blow everything else away.</div><br/></div></div></div></div></div></div><div id="42890757" class="c"><input type="checkbox" id="c-42890757" checked=""/><div class="controls bullet"><span class="by">ActVen</span><span>|</span><a href="#42890667">parent</a><span>|</span><a href="#42890732">prev</a><span>|</span><a href="#42891825">next</a><span>|</span><label class="collapse" for="c-42890757">[-]</label><label class="expand" for="c-42890757">[2 more]</label></div><br/><div class="children"><div class="content">I really wish they would open up the reasoning effort toggle on o1 API. o1 Pro Mode is still the best overall model I have used for many complex tasks.</div><br/><div id="42894856" class="c"><input type="checkbox" id="c-42894856" checked=""/><div class="controls bullet"><span class="by">bobjordan</span><span>|</span><a href="#42890667">root</a><span>|</span><a href="#42890757">parent</a><span>|</span><a href="#42891825">next</a><span>|</span><label class="collapse" for="c-42894856">[-]</label><label class="expand" for="c-42894856">[1 more]</label></div><br/><div class="children"><div class="content">Have you tried the o1-pro mode model today, because now it sucks!</div><br/></div></div></div></div><div id="42891825" class="c"><input type="checkbox" id="c-42891825" checked=""/><div class="controls bullet"><span class="by">lumost</span><span>|</span><a href="#42890667">parent</a><span>|</span><a href="#42890757">prev</a><span>|</span><a href="#42890992">next</a><span>|</span><label class="collapse" for="c-42891825">[-]</label><label class="expand" for="c-42891825">[1 more]</label></div><br/><div class="children"><div class="content">I actually switched back from o1-preview to GPT-4o due to tooling integration and web search. I find that more often than not, the ability of GPT-4o to use these tools outweighs o1&#x27;s improved accuracy.</div><br/></div></div><div id="42890992" class="c"><input type="checkbox" id="c-42890992" checked=""/><div class="controls bullet"><span class="by">koakuma-chan</span><span>|</span><a href="#42890667">parent</a><span>|</span><a href="#42891825">prev</a><span>|</span><a href="#42892007">next</a><span>|</span><label class="collapse" for="c-42890992">[-]</label><label class="expand" for="c-42890992">[6 more]</label></div><br/><div class="children"><div class="content">You cannot compare GPT-4o and o*(-mini) because GPT-4o is not a reasoning model.</div><br/><div id="42896831" class="c"><input type="checkbox" id="c-42896831" checked=""/><div class="controls bullet"><span class="by">scrollop</span><span>|</span><a href="#42890667">root</a><span>|</span><a href="#42890992">parent</a><span>|</span><a href="#42891827">next</a><span>|</span><label class="collapse" for="c-42896831">[-]</label><label class="expand" for="c-42896831">[1 more]</label></div><br/><div class="children"><div class="content">Why can&#x27;t you ask both questions (on a variety of topics etc), and grade the answers vs an ideal answer?<p>Ends before means.<p>If 4o answered better than o3, would you still use 03 for your task just because you were told it can &quot;reason&quot;?</div><br/></div></div><div id="42891827" class="c"><input type="checkbox" id="c-42891827" checked=""/><div class="controls bullet"><span class="by">lxgr</span><span>|</span><a href="#42890667">root</a><span>|</span><a href="#42890992">parent</a><span>|</span><a href="#42896831">prev</a><span>|</span><a href="#42892007">next</a><span>|</span><label class="collapse" for="c-42891827">[-]</label><label class="expand" for="c-42891827">[4 more]</label></div><br/><div class="children"><div class="content">Sure you can. &quot;Reasoning&quot; is ultimately an implementation detail, and the only thing that matters for capabilities is results, not process.</div><br/><div id="42892496" class="c"><input type="checkbox" id="c-42892496" checked=""/><div class="controls bullet"><span class="by">koakuma-chan</span><span>|</span><a href="#42890667">root</a><span>|</span><a href="#42891827">parent</a><span>|</span><a href="#42892007">next</a><span>|</span><label class="collapse" for="c-42892496">[-]</label><label class="expand" for="c-42892496">[3 more]</label></div><br/><div class="children"><div class="content">By &quot;reasoning&quot; I meant the fact that o*(-mini) does &quot;chain-of-thought&quot;, in other words, it prompts itself to &quot;reason&quot; before responding to you, whereas GPT-4o(-mini) just directly responds to your prompt. Thus, it is not appropriate to compare o*(-mini) and GPT-4o(-mini) unless you implement &quot;chain-of-thought&quot; for GPT-4o(-mini) and compare that with o*(-mini). See also: <a href="https:&#x2F;&#x2F;docs.anthropic.com&#x2F;en&#x2F;docs&#x2F;build-with-claude&#x2F;prompt-engineering&#x2F;chain-of-thought" rel="nofollow">https:&#x2F;&#x2F;docs.anthropic.com&#x2F;en&#x2F;docs&#x2F;build-with-claude&#x2F;prompt-...</a></div><br/><div id="42893386" class="c"><input type="checkbox" id="c-42893386" checked=""/><div class="controls bullet"><span class="by">wordpad25</span><span>|</span><a href="#42890667">root</a><span>|</span><a href="#42892496">parent</a><span>|</span><a href="#42892007">next</a><span>|</span><label class="collapse" for="c-42893386">[-]</label><label class="expand" for="c-42893386">[2 more]</label></div><br/><div class="children"><div class="content">That&#x27;s like saying you can&#x27;t compare a sedan to a truck.<p>Sure you can.<p>Even though one is more appropriate for certain tasks than the other.</div><br/><div id="42893824" class="c"><input type="checkbox" id="c-42893824" checked=""/><div class="controls bullet"><span class="by">dutchbookmaker</span><span>|</span><a href="#42890667">root</a><span>|</span><a href="#42893386">parent</a><span>|</span><a href="#42892007">next</a><span>|</span><label class="collapse" for="c-42893824">[-]</label><label class="expand" for="c-42893824">[1 more]</label></div><br/><div class="children"><div class="content">It is a nuanced point but what is better, a sedan or a truck? I think we are still at that stage of the conversation so it doesn&#x27;t make much sense.<p>I do think it is a good metaphor for how all this shakes out though in time.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="42892007" class="c"><input type="checkbox" id="c-42892007" checked=""/><div class="controls bullet"><span class="by">singularity2001</span><span>|</span><a href="#42890667">parent</a><span>|</span><a href="#42890992">prev</a><span>|</span><a href="#42890725">next</a><span>|</span><label class="collapse" for="c-42892007">[-]</label><label class="expand" for="c-42892007">[1 more]</label></div><br/><div class="children"><div class="content">no the reasoning models should not directly be compared with the normal models: they often take 10 times as long to answer which only makes sense for difficult questions</div><br/></div></div><div id="42890810" class="c"><input type="checkbox" id="c-42890810" checked=""/><div class="controls bullet"><span class="by">ALittleLight</span><span>|</span><a href="#42890667">parent</a><span>|</span><a href="#42890725">prev</a><span>|</span><a href="#42890679">next</a><span>|</span><label class="collapse" for="c-42890810">[-]</label><label class="expand" for="c-42890810">[3 more]</label></div><br/><div class="children"><div class="content">That seems very bad.  What&#x27;s the point of a new model that&#x27;s worse than 4o?  I guess it&#x27;s cheaper in the API and a bit better at coding - but, this doesn&#x27;t seem compelling.<p>With DeepSeek I heard OpenAI saying the plan was to move releases on models that were meaningfully better than the competition.  Seems like what we&#x27;re getting is the scheduled releases that are worse than the current versions.</div><br/><div id="42892763" class="c"><input type="checkbox" id="c-42892763" checked=""/><div class="controls bullet"><span class="by">thegeomaster</span><span>|</span><a href="#42890667">root</a><span>|</span><a href="#42890810">parent</a><span>|</span><a href="#42890679">next</a><span>|</span><label class="collapse" for="c-42892763">[-]</label><label class="expand" for="c-42892763">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s quite a bit better than coding --- they hint that it can tie o1&#x27;s performance for coding, which already benchmarks higher than 4o. And it&#x27;s significantly cheaper, and presumably faster. I believe API costs account for the vast majority of COGS at most today&#x27;s AI startups, so they would be very motivated to switch to a cheaper model that has similar performance.</div><br/><div id="42893587" class="c"><input type="checkbox" id="c-42893587" checked=""/><div class="controls bullet"><span class="by">mgens</span><span>|</span><a href="#42890667">root</a><span>|</span><a href="#42892763">parent</a><span>|</span><a href="#42890679">next</a><span>|</span><label class="collapse" for="c-42893587">[-]</label><label class="expand" for="c-42893587">[1 more]</label></div><br/><div class="children"><div class="content">Right. For large-volume requests that use reasoning this will be quite useful. I have a task that requires the LLM to convert thousands of free-text statements into SQL select statements, and o3-mini-high is able to get many of the more complicated ones that GPT-4o and Sonnet 3.5 failed at. So I will be switching this task to either o3-mini or DeepSeek-R1.</div><br/></div></div></div></div></div></div><div id="42890679" class="c"><input type="checkbox" id="c-42890679" checked=""/><div class="controls bullet"><span class="by">forrestthewoods</span><span>|</span><a href="#42890667">parent</a><span>|</span><a href="#42890810">prev</a><span>|</span><a href="#42891663">next</a><span>|</span><label class="collapse" for="c-42890679">[-]</label><label class="expand" for="c-42890679">[3 more]</label></div><br/><div class="children"><div class="content">OpenAI needs a new branding scheme.</div><br/><div id="42891626" class="c"><input type="checkbox" id="c-42891626" checked=""/><div class="controls bullet"><span class="by">nejsjsjsbsb</span><span>|</span><a href="#42890667">root</a><span>|</span><a href="#42890679">parent</a><span>|</span><a href="#42890711">next</a><span>|</span><label class="collapse" for="c-42891626">[-]</label><label class="expand" for="c-42891626">[1 more]</label></div><br/><div class="children"><div class="content">The Llama folk know how. Good old 90s version scheme.</div><br/></div></div><div id="42890711" class="c"><input type="checkbox" id="c-42890711" checked=""/><div class="controls bullet"><span class="by">airstrike</span><span>|</span><a href="#42890667">root</a><span>|</span><a href="#42890679">parent</a><span>|</span><a href="#42891626">prev</a><span>|</span><a href="#42891663">next</a><span>|</span><label class="collapse" for="c-42890711">[-]</label><label class="expand" for="c-42890711">[1 more]</label></div><br/><div class="children"><div class="content">ChatGPT Series X O one</div><br/></div></div></div></div><div id="42891663" class="c"><input type="checkbox" id="c-42891663" checked=""/><div class="controls bullet"><span class="by">withinboredom</span><span>|</span><a href="#42890667">parent</a><span>|</span><a href="#42890679">prev</a><span>|</span><a href="#42894680">next</a><span>|</span><label class="collapse" for="c-42891663">[-]</label><label class="expand" for="c-42891663">[1 more]</label></div><br/><div class="children"><div class="content">yeah, you can def tell they are partnered with Microsoft.</div><br/></div></div></div></div><div id="42894680" class="c"><input type="checkbox" id="c-42894680" checked=""/><div class="controls bullet"><span class="by">waynecochran</span><span>|</span><a href="#42890667">prev</a><span>|</span><a href="#42890806">next</a><span>|</span><label class="collapse" for="c-42894680">[-]</label><label class="expand" for="c-42894680">[4 more]</label></div><br/><div class="children"><div class="content">I just had it convert Swift code to Kotlin and was surprised at how the comment was translated.
It &quot;knew&quot; the author of the paper and what is was doing!? That is wild.<p>Swift:<p><pre><code>        &#x2F;&#x2F;
        &#x2F;&#x2F; Double Reflection Algorithm from Table I (page 7)
        &#x2F;&#x2F; in Section 4 of https:&#x2F;&#x2F;tinyurl.com&#x2F;yft2674p
        &#x2F;&#x2F;
        for i in 1 ..&lt; N {
            let X1 = spine[i]
            ...
</code></pre>
Kotlin:<p><pre><code>        &#x2F;&#x2F; Use the Double Reflection Algorithm (from Wang et al.) to compute subsequent frames.
        for (i in 1 until N) {
            val X1 = Vector3f(spine[i])
            ...</code></pre></div><br/><div id="42896921" class="c"><input type="checkbox" id="c-42896921" checked=""/><div class="controls bullet"><span class="by">mattmanser</span><span>|</span><a href="#42894680">parent</a><span>|</span><a href="#42895235">next</a><span>|</span><label class="collapse" for="c-42896921">[-]</label><label class="expand" for="c-42896921">[2 more]</label></div><br/><div class="children"><div class="content">Someone else has written this exact code on the internet, OpenAI stole it, and now chatgpt is regurgitating it. Just like it can regurgitate whole articles.<p>You need to stop being wow&#x27;d by human intelligence masquerading as AI!</div><br/><div id="42896957" class="c"><input type="checkbox" id="c-42896957" checked=""/><div class="controls bullet"><span class="by">smallerfish</span><span>|</span><a href="#42894680">root</a><span>|</span><a href="#42896921">parent</a><span>|</span><a href="#42895235">next</a><span>|</span><label class="collapse" for="c-42896957">[-]</label><label class="expand" for="c-42896957">[1 more]</label></div><br/><div class="children"><div class="content">Where? Searching for &quot;Use the Double Reflection Algorithm (from Wang et al.)&quot; only returns this post.</div><br/></div></div></div></div><div id="42895235" class="c"><input type="checkbox" id="c-42895235" checked=""/><div class="controls bullet"><span class="by">smallerize</span><span>|</span><a href="#42894680">parent</a><span>|</span><a href="#42896921">prev</a><span>|</span><a href="#42890806">next</a><span>|</span><label class="collapse" for="c-42895235">[-]</label><label class="expand" for="c-42895235">[1 more]</label></div><br/><div class="children"><div class="content">Wow, haven&#x27;t seen a viglink in a while.</div><br/></div></div></div></div><div id="42890806" class="c"><input type="checkbox" id="c-42890806" checked=""/><div class="controls bullet"><span class="by">ilaksh</span><span>|</span><a href="#42894680">prev</a><span>|</span><a href="#42892684">next</a><span>|</span><label class="collapse" for="c-42890806">[-]</label><label class="expand" for="c-42890806">[12 more]</label></div><br/><div class="children"><div class="content">It looks like a pretty significant increase on SWE-Bench. Although that makes me wonder if there was some formatting or gotcha that was holding the results back before.<p>If this will work for your use case then it could be a huge discount versus o1. Worth trying again if o1-mini couldn&#x27;t handle the task before. $4&#x2F;million output tokens versus $60.<p><a href="https:&#x2F;&#x2F;platform.openai.com&#x2F;docs&#x2F;pricing" rel="nofollow">https:&#x2F;&#x2F;platform.openai.com&#x2F;docs&#x2F;pricing</a><p>I am Tier 5 but I don&#x27;t believe I have access to it in the API (at least it&#x27;s not on the limits page and I haven&#x27;t received an email). It says &quot;rolling out to select Tier 3-5 customers&quot; which means I will have to wait around and just be lucky I guess.</div><br/><div id="42891188" class="c"><input type="checkbox" id="c-42891188" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#42890806">parent</a><span>|</span><a href="#42891092">next</a><span>|</span><label class="collapse" for="c-42891188">[-]</label><label class="expand" for="c-42891188">[3 more]</label></div><br/><div class="children"><div class="content">Tier 3 here and already see it on Limits page, so maybe the wait won&#x27;t be long.</div><br/><div id="42892313" class="c"><input type="checkbox" id="c-42892313" checked=""/><div class="controls bullet"><span class="by">ilaksh</span><span>|</span><a href="#42890806">root</a><span>|</span><a href="#42891188">parent</a><span>|</span><a href="#42891092">next</a><span>|</span><label class="collapse" for="c-42892313">[-]</label><label class="expand" for="c-42892313">[2 more]</label></div><br/><div class="children"><div class="content">Yep, I got an email about o3-mini in the API an hour ago.</div><br/><div id="42893024" class="c"><input type="checkbox" id="c-42893024" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#42890806">root</a><span>|</span><a href="#42892313">parent</a><span>|</span><a href="#42891092">next</a><span>|</span><label class="collapse" for="c-42893024">[-]</label><label class="expand" for="c-42893024">[1 more]</label></div><br/><div class="children"><div class="content">I apparently got one at the same time too, but I missed it distracted by this HN thread :). Not only I got o3-mini (which I already noticed on the Limits page), but they also gave me access to o1 now! I&#x27;m Tier 3; until yesterday, o1 was still Tier 5 (IIRC).<p>Thanks OpenAI! Nice gift and a neat distraction from DeepSeek-R1 - which I still can&#x27;t use directly, because their API stopped working moments after I topped up my credits and generated an API key, and is still down for me... :&#x2F;.</div><br/></div></div></div></div></div></div><div id="42891092" class="c"><input type="checkbox" id="c-42891092" checked=""/><div class="controls bullet"><span class="by">TechDebtDevin</span><span>|</span><a href="#42890806">parent</a><span>|</span><a href="#42891188">prev</a><span>|</span><a href="#42893062">next</a><span>|</span><label class="collapse" for="c-42891092">[-]</label><label class="expand" for="c-42891092">[7 more]</label></div><br/><div class="children"><div class="content">Genuinely curious, What made you choose OpenAI as your preferred api provider? Its always been the least attractive to me.</div><br/><div id="42891213" class="c"><input type="checkbox" id="c-42891213" checked=""/><div class="controls bullet"><span class="by">ilaksh</span><span>|</span><a href="#42890806">root</a><span>|</span><a href="#42891092">parent</a><span>|</span><a href="#42891536">next</a><span>|</span><label class="collapse" for="c-42891213">[-]</label><label class="expand" for="c-42891213">[1 more]</label></div><br/><div class="children"><div class="content">I have mainly been using Claude 3.5&#x2F;3.6 Sonnet via API in the last several months (or since 3.5 Sonnet came out). However, I was using o1 for a challenging task at one point, but last I tested it had issues with some extra backslashes for that application.<p>I also have tested with DeepSeek R1 and will test some more with that although in a way Claude 3.6 with CoT is pretty good. Last time I tried to test R1 their API was out.</div><br/></div></div><div id="42891536" class="c"><input type="checkbox" id="c-42891536" checked=""/><div class="controls bullet"><span class="by">eknkc</span><span>|</span><a href="#42890806">root</a><span>|</span><a href="#42891092">parent</a><span>|</span><a href="#42891213">prev</a><span>|</span><a href="#42891282">next</a><span>|</span><label class="collapse" for="c-42891536">[-]</label><label class="expand" for="c-42891536">[1 more]</label></div><br/><div class="children"><div class="content">We extensively used the batch APIs to decrease cost and handle large amount of data. I also need JSON responses for a lot of things and OpenAI seem to have the best json schema output option out there.</div><br/></div></div><div id="42891282" class="c"><input type="checkbox" id="c-42891282" checked=""/><div class="controls bullet"><span class="by">ipaddr</span><span>|</span><a href="#42890806">root</a><span>|</span><a href="#42891092">parent</a><span>|</span><a href="#42891536">prev</a><span>|</span><a href="#42891196">next</a><span>|</span><label class="collapse" for="c-42891282">[-]</label><label class="expand" for="c-42891282">[3 more]</label></div><br/><div class="children"><div class="content">Who else might be a good choice?  Deepseek is down.  Who has the cheapest gpt3.5 level or above api</div><br/><div id="42891400" class="c"><input type="checkbox" id="c-42891400" checked=""/><div class="controls bullet"><span class="by">TechDebtDevin</span><span>|</span><a href="#42890806">root</a><span>|</span><a href="#42891282">parent</a><span>|</span><a href="#42891792">next</a><span>|</span><label class="collapse" for="c-42891400">[-]</label><label class="expand" for="c-42891400">[1 more]</label></div><br/><div class="children"><div class="content">Ive personaly been using Deepseek (which has been better than for 3.5 for a really long time), and Perplexity, which is nice for their built in search. Ive actually been using Deepseek since it was free. Its been generally good for me. Ive mostly chosen both because of pricing as I generally dont use APIs for extermely complex prompts.</div><br/></div></div><div id="42891792" class="c"><input type="checkbox" id="c-42891792" checked=""/><div class="controls bullet"><span class="by">Aperocky</span><span>|</span><a href="#42890806">root</a><span>|</span><a href="#42891282">parent</a><span>|</span><a href="#42891400">prev</a><span>|</span><a href="#42891196">next</a><span>|</span><label class="collapse" for="c-42891792">[-]</label><label class="expand" for="c-42891792">[1 more]</label></div><br/><div class="children"><div class="content">Run it locally, the distilled smaller ones aren&#x27;t bad at all.</div><br/></div></div></div></div><div id="42891196" class="c"><input type="checkbox" id="c-42891196" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#42890806">root</a><span>|</span><a href="#42891092">parent</a><span>|</span><a href="#42891282">prev</a><span>|</span><a href="#42893062">next</a><span>|</span><label class="collapse" for="c-42891196">[-]</label><label class="expand" for="c-42891196">[1 more]</label></div><br/><div class="children"><div class="content">Until recently they were the only game in town, so maybe they accrued significant spend back then?</div><br/></div></div></div></div><div id="42893062" class="c"><input type="checkbox" id="c-42893062" checked=""/><div class="controls bullet"><span class="by">sshh12</span><span>|</span><a href="#42890806">parent</a><span>|</span><a href="#42891092">prev</a><span>|</span><a href="#42892684">next</a><span>|</span><label class="collapse" for="c-42893062">[-]</label><label class="expand" for="c-42893062">[1 more]</label></div><br/><div class="children"><div class="content">Tier 5 and I got it almost instantly</div><br/></div></div></div></div><div id="42892684" class="c"><input type="checkbox" id="c-42892684" checked=""/><div class="controls bullet"><span class="by">vok</span><span>|</span><a href="#42890806">prev</a><span>|</span><a href="#42890858">next</a><span>|</span><label class="collapse" for="c-42892684">[-]</label><label class="expand" for="c-42892684">[10 more]</label></div><br/><div class="children"><div class="content">Well, o3-mini-high just successfully found the root cause of a seg fault that o1 missed: mistakenly using _mm512_store_si512 for an unaligned store that should have been _mm512_storeu_si512.</div><br/><div id="42894014" class="c"><input type="checkbox" id="c-42894014" checked=""/><div class="controls bullet"><span class="by">throw83288</span><span>|</span><a href="#42892684">parent</a><span>|</span><a href="#42894461">next</a><span>|</span><label class="collapse" for="c-42894014">[-]</label><label class="expand" for="c-42894014">[7 more]</label></div><br/><div class="children"><div class="content">How do I avoid the angst about this stuff as a student in computer science? I love this field but frankly I&#x27;ve been at a loss since the rapid development of these models.</div><br/><div id="42894245" class="c"><input type="checkbox" id="c-42894245" checked=""/><div class="controls bullet"><span class="by">jumploops</span><span>|</span><a href="#42892684">root</a><span>|</span><a href="#42894014">parent</a><span>|</span><a href="#42894259">next</a><span>|</span><label class="collapse" for="c-42894245">[-]</label><label class="expand" for="c-42894245">[1 more]</label></div><br/><div class="children"><div class="content">LLMs are the new compilers.<p>As a student, you should continue to focus on fundamentals, but also adapt LLMs into your workflow where you can.<p>Skip writing the assembly (now curly braces and semicolons), and focus on what the software you’re building actually does, who it serves, and how it works.<p>Programming is both changing a lot, and not at all. The mechanics may look different, but the purpose is still the same: effectively telling computers what to do.</div><br/></div></div><div id="42894259" class="c"><input type="checkbox" id="c-42894259" checked=""/><div class="controls bullet"><span class="by">abdullahkhalids</span><span>|</span><a href="#42892684">root</a><span>|</span><a href="#42894014">parent</a><span>|</span><a href="#42894245">prev</a><span>|</span><a href="#42895199">next</a><span>|</span><label class="collapse" for="c-42894259">[-]</label><label class="expand" for="c-42894259">[1 more]</label></div><br/><div class="children"><div class="content">As a former prof. What you should be learning from any STEM degree (and many other degrees as well) is to think clearly, rigorously, creatively, and with discipline, etc. You also need to learn the skill of learning content and skills quickly.<p>The specific contents or skills of your degree don&#x27;t matter that much. In pretty much any STEM field, over the last 100ish years, whatever you learned in your undergraduate was mostly irrelevant by the time you retired.<p>Everyone got by, by staying on top of the new developments in the field and doing them. With AI, the particular skills needed to use the power of computers to do things in the world have changed. Just learn those skills.</div><br/></div></div><div id="42895199" class="c"><input type="checkbox" id="c-42895199" checked=""/><div class="controls bullet"><span class="by">mhh__</span><span>|</span><a href="#42892684">root</a><span>|</span><a href="#42894014">parent</a><span>|</span><a href="#42894259">prev</a><span>|</span><a href="#42895023">next</a><span>|</span><label class="collapse" for="c-42895199">[-]</label><label class="expand" for="c-42895199">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s either over, or giving a lot of idiots false confidence — I meet people somewhat regularly who believe they don&#x27;t really need to know what they&#x27;re doing any more. This is probably an arbitrage.</div><br/></div></div><div id="42895023" class="c"><input type="checkbox" id="c-42895023" checked=""/><div class="controls bullet"><span class="by">danparsonson</span><span>|</span><a href="#42892684">root</a><span>|</span><a href="#42894014">parent</a><span>|</span><a href="#42895199">prev</a><span>|</span><a href="#42895656">next</a><span>|</span><label class="collapse" for="c-42895023">[-]</label><label class="expand" for="c-42895023">[1 more]</label></div><br/><div class="children"><div class="content">For all the value that they bring, there is still a good dose of parlour tricks and toy examples around, and they need an intelligent guiding hand to get the best out of them. As a meat brain, you can bring big picture design skills that the bots don&#x27;t have, keeping them on track to deliver a coherent codebase, and fixing the inevitable hallucinations. Think of it like having a team of optimistic code monkeys with terrible memory, and you as the coordinator. I would focus on building skills in things like software design&#x2F;architecture, requirements gathering (what do people want and how do you design software to deliver it?), in-depth hardware knowledge (how to get the best out of your platform), good API design, debugging, etc. Leave the CRUD to the robots and be the brain.</div><br/></div></div><div id="42895656" class="c"><input type="checkbox" id="c-42895656" checked=""/><div class="controls bullet"><span class="by">raincole</span><span>|</span><a href="#42892684">root</a><span>|</span><a href="#42894014">parent</a><span>|</span><a href="#42895023">prev</a><span>|</span><a href="#42896536">next</a><span>|</span><label class="collapse" for="c-42895656">[-]</label><label class="expand" for="c-42895656">[1 more]</label></div><br/><div class="children"><div class="content">Angst?<p>It just means you&#x27;re less likely be fixing someone else&#x27;s &quot;mistakenly _mm512_store_si512 for been _mm512_storeu_si512&quot; error because AI fix(ed) it for you and you can focus on other parts of computer science. Computer science surely isn&#x27;t just fixing _mm512_store_si512.</div><br/></div></div></div></div><div id="42894461" class="c"><input type="checkbox" id="c-42894461" checked=""/><div class="controls bullet"><span class="by">jiocrag</span><span>|</span><a href="#42892684">parent</a><span>|</span><a href="#42894014">prev</a><span>|</span><a href="#42893438">next</a><span>|</span><label class="collapse" for="c-42894461">[-]</label><label class="expand" for="c-42894461">[1 more]</label></div><br/><div class="children"><div class="content">why is this impressive at all? It effectively amounts to correcting a typo.</div><br/></div></div><div id="42893438" class="c"><input type="checkbox" id="c-42893438" checked=""/><div class="controls bullet"><span class="by">nextworddev</span><span>|</span><a href="#42892684">parent</a><span>|</span><a href="#42894461">prev</a><span>|</span><a href="#42890858">next</a><span>|</span><label class="collapse" for="c-42893438">[-]</label><label class="expand" for="c-42893438">[1 more]</label></div><br/><div class="children"><div class="content">rip development jobs &#x2F;s.. or not &#x2F;s</div><br/></div></div></div></div><div id="42890858" class="c"><input type="checkbox" id="c-42890858" checked=""/><div class="controls bullet"><span class="by">Bjorkbat</span><span>|</span><a href="#42892684">prev</a><span>|</span><a href="#42890681">next</a><span>|</span><label class="collapse" for="c-42890858">[-]</label><label class="expand" for="c-42890858">[4 more]</label></div><br/><div class="children"><div class="content">I have to admit I&#x27;m kind of surprised by the SWE-bench results.  At the highest level of performance o3-mini&#x27;s CodeForces score is, well, high.  I&#x27;ve honestly never really sat down to understand how elo works, all I know is that it scored better than o1, which allegedly as better than ~90% of all competitors on CodeForces.  So, you know, o3-mini is pretty good at CodeForces.<p>But it&#x27;s SWE-bench scores aren&#x27;t meaningfully better than Claude, 49.3 vs Claude&#x27;s 49.0 on the public leaderboard (might be higher now due to recent updates?)<p>My immediate thoughts, CodeForces (and competitive programming in general) is a poor proxy for performance on general software engineering tasks.  Besides that, for all the work put into OpenAI&#x27;s most recent model it still has a hard time living up to an LLM initially released by Anthropic some time ago, at least according to this benchmark.<p>Mind you, the Github issues that the problems in SWE-bench were based-off have been around long enough that it&#x27;s pretty much a given that they&#x27;ve all found their way into the training data of most modern LLMs, so I&#x27;m really surprised that o3 isn&#x27;t meaningfully better than Sonnet.</div><br/><div id="42894998" class="c"><input type="checkbox" id="c-42894998" checked=""/><div class="controls bullet"><span class="by">dagelf</span><span>|</span><a href="#42890858">parent</a><span>|</span><a href="#42895514">next</a><span>|</span><label class="collapse" for="c-42894998">[-]</label><label class="expand" for="c-42894998">[1 more]</label></div><br/><div class="children"><div class="content">I think the innovation here is probably that its a much smaller and so cheaper model to run.</div><br/></div></div><div id="42895514" class="c"><input type="checkbox" id="c-42895514" checked=""/><div class="controls bullet"><span class="by">vectorhacker</span><span>|</span><a href="#42890858">parent</a><span>|</span><a href="#42894998">prev</a><span>|</span><a href="#42895195">next</a><span>|</span><label class="collapse" for="c-42895514">[-]</label><label class="expand" for="c-42895514">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, I no longer consider the SWE-bench useful because these models can just &quot;memorize&quot; the solutions to the PRs.</div><br/></div></div><div id="42895195" class="c"><input type="checkbox" id="c-42895195" checked=""/><div class="controls bullet"><span class="by">aprilthird2021</span><span>|</span><a href="#42890858">parent</a><span>|</span><a href="#42895514">prev</a><span>|</span><a href="#42890681">next</a><span>|</span><label class="collapse" for="c-42895195">[-]</label><label class="expand" for="c-42895195">[1 more]</label></div><br/><div class="children"><div class="content">&gt; My immediate thoughts, CodeForces (and competitive programming in general) is a poor proxy for performance on general software engineering task<p>Yep. A general software engineering task has a lot of information encoded in it that is either already known to a human or is contextually understood by a human.<p>A competitive programming task often has to provide all the context as it&#x27;s not based off an existing product or codebase or technology or paradigm known to the user</div><br/></div></div></div></div><div id="42890681" class="c"><input type="checkbox" id="c-42890681" checked=""/><div class="controls bullet"><span class="by">pookieinc</span><span>|</span><a href="#42890858">prev</a><span>|</span><a href="#42890743">next</a><span>|</span><label class="collapse" for="c-42890681">[-]</label><label class="expand" for="c-42890681">[30 more]</label></div><br/><div class="children"><div class="content">Can&#x27;t wait to try this. What&#x27;s amazing to me is that when this was revealed just one short month ago, the AI landscape looked very different than it does today with more AI companies jumping into the fray with very compelling models. I wonder how the AI shift has affected this release internally, future releases and their mindset moving forward... How does the efficiency change, the scope of their models, etc.</div><br/><div id="42890808" class="c"><input type="checkbox" id="c-42890808" checked=""/><div class="controls bullet"><span class="by">patrickhogan1</span><span>|</span><a href="#42890681">parent</a><span>|</span><a href="#42890722">next</a><span>|</span><label class="collapse" for="c-42890808">[-]</label><label class="expand" for="c-42890808">[2 more]</label></div><br/><div class="children"><div class="content">I thought it was o3 that was released one month ago and received high scores on ARC Prize - <a href="https:&#x2F;&#x2F;arcprize.org&#x2F;blog&#x2F;oai-o3-pub-breakthrough" rel="nofollow">https:&#x2F;&#x2F;arcprize.org&#x2F;blog&#x2F;oai-o3-pub-breakthrough</a><p>If they were the same, I would have expected explicit references to o3 in the system card and how o3-mini is distilled or built from o3 - <a href="https:&#x2F;&#x2F;cdn.openai.com&#x2F;o3-mini-system-card.pdf" rel="nofollow">https:&#x2F;&#x2F;cdn.openai.com&#x2F;o3-mini-system-card.pdf</a> - but there are no references.<p>Excited at the pace all the same. Excited to dig in. The model naming all around is so confusing. Very difficult to tell what breakthrough innovations occurred.</div><br/><div id="42893759" class="c"><input type="checkbox" id="c-42893759" checked=""/><div class="controls bullet"><span class="by">nycdatasci</span><span>|</span><a href="#42890681">root</a><span>|</span><a href="#42890808">parent</a><span>|</span><a href="#42890722">next</a><span>|</span><label class="collapse" for="c-42893759">[-]</label><label class="expand" for="c-42893759">[1 more]</label></div><br/><div class="children"><div class="content">Yeah - the naming is confusing.  We&#x27;re seeing o3-mini.  o3 yields marginally better performance given exponentially more compute.  Unlike OpenAI, customers will not have an option to throw an endless amount of money at specific tasks&#x2F;prompts.</div><br/></div></div></div></div><div id="42890722" class="c"><input type="checkbox" id="c-42890722" checked=""/><div class="controls bullet"><span class="by">echelon</span><span>|</span><a href="#42890681">parent</a><span>|</span><a href="#42890808">prev</a><span>|</span><a href="#42890743">next</a><span>|</span><label class="collapse" for="c-42890722">[-]</label><label class="expand" for="c-42890722">[27 more]</label></div><br/><div class="children"><div class="content">There&#x27;s no moat, and they have to work even harder.<p>Competition is good.</div><br/><div id="42891145" class="c"><input type="checkbox" id="c-42891145" checked=""/><div class="controls bullet"><span class="by">lesuorac</span><span>|</span><a href="#42890681">root</a><span>|</span><a href="#42890722">parent</a><span>|</span><a href="#42891273">next</a><span>|</span><label class="collapse" for="c-42891145">[-]</label><label class="expand" for="c-42891145">[20 more]</label></div><br/><div class="children"><div class="content">I really don&#x27;t think this is true. OpenAI has no moat because they have nothing unique; they&#x27;re using mostly other people&#x27;s (like Transformers) architectures and other companies hardware.<p>Their value-prop (moat) is that they&#x27;ve burnt more money than everybody else. That moat is trivially circumvented by lighting a larger pile of money and less trivially by lighting the pile more efficently.<p>OpenAI isn&#x27;t the only company. The Tech companies being beaten massively by Microsoft in #of H100s purchases are the ones with a moat. Google &#x2F; Amazon with their custom AI chips are going to have a better performance per cost than others and that will be a moat. If you want to get the same performance per cost then you need to spend the time making your own chips which is years of effort (=moat).</div><br/><div id="42891563" class="c"><input type="checkbox" id="c-42891563" checked=""/><div class="controls bullet"><span class="by">sumedh</span><span>|</span><a href="#42890681">root</a><span>|</span><a href="#42891145">parent</a><span>|</span><a href="#42892047">next</a><span>|</span><label class="collapse" for="c-42891563">[-]</label><label class="expand" for="c-42891563">[8 more]</label></div><br/><div class="children"><div class="content">&gt; That moat is trivially circumvented by lighting a larger pile of money and less trivially by lighting the pile more efficently.<p>Google with all its money and smart engineers was not able to build a simple chat application.</div><br/><div id="42891783" class="c"><input type="checkbox" id="c-42891783" checked=""/><div class="controls bullet"><span class="by">mianos</span><span>|</span><a href="#42890681">root</a><span>|</span><a href="#42891563">parent</a><span>|</span><a href="#42891914">next</a><span>|</span><label class="collapse" for="c-42891783">[-]</label><label class="expand" for="c-42891783">[1 more]</label></div><br/><div class="children"><div class="content">But with their internal progression structure they can build and cancel eight mediocre chat apps.</div><br/></div></div><div id="42891914" class="c"><input type="checkbox" id="c-42891914" checked=""/><div class="controls bullet"><span class="by">malaya_zemlya</span><span>|</span><a href="#42890681">root</a><span>|</span><a href="#42891563">parent</a><span>|</span><a href="#42891783">prev</a><span>|</span><a href="#42892047">next</a><span>|</span><label class="collapse" for="c-42891914">[-]</label><label class="expand" for="c-42891914">[6 more]</label></div><br/><div class="children"><div class="content">What do you mean?
Gemini app is available on IOS, Android and on the web (as AI Studio <a href="https:&#x2F;&#x2F;aistudio.google.com&#x2F;" rel="nofollow">https:&#x2F;&#x2F;aistudio.google.com&#x2F;</a>).</div><br/><div id="42892562" class="c"><input type="checkbox" id="c-42892562" checked=""/><div class="controls bullet"><span class="by">robrenaud</span><span>|</span><a href="#42890681">root</a><span>|</span><a href="#42891914">parent</a><span>|</span><a href="#42892527">next</a><span>|</span><label class="collapse" for="c-42892562">[-]</label><label class="expand" for="c-42892562">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a joke about how Google has released&#x2F;cancelled&#x2F;renamed many messenging apps.</div><br/></div></div><div id="42892527" class="c"><input type="checkbox" id="c-42892527" checked=""/><div class="controls bullet"><span class="by">tmnvdb</span><span>|</span><a href="#42890681">root</a><span>|</span><a href="#42891914">parent</a><span>|</span><a href="#42892562">prev</a><span>|</span><a href="#42893853">next</a><span>|</span><label class="collapse" for="c-42892527">[-]</label><label class="expand" for="c-42892527">[3 more]</label></div><br/><div class="children"><div class="content">It is not very good though.</div><br/><div id="42895181" class="c"><input type="checkbox" id="c-42895181" checked=""/><div class="controls bullet"><span class="by">aprilthird2021</span><span>|</span><a href="#42890681">root</a><span>|</span><a href="#42892527">parent</a><span>|</span><a href="#42893853">next</a><span>|</span><label class="collapse" for="c-42895181">[-]</label><label class="expand" for="c-42895181">[2 more]</label></div><br/><div class="children"><div class="content">Gemini is pretty good, And it does one thing way better than most other AI models, when I hold down my phone&#x27;s home button it&#x27;s available right away</div><br/><div id="42896935" class="c"><input type="checkbox" id="c-42896935" checked=""/><div class="controls bullet"><span class="by">evrenesat</span><span>|</span><a href="#42890681">root</a><span>|</span><a href="#42895181">parent</a><span>|</span><a href="#42893853">next</a><span>|</span><label class="collapse" for="c-42896935">[-]</label><label class="expand" for="c-42896935">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s a shame on Google, Apple, Samsung, etc. Voice and other activation methods should be open to any app that claims to be an assistant. An ugly way of &quot;gatekeeping&quot;.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="42892047" class="c"><input type="checkbox" id="c-42892047" checked=""/><div class="controls bullet"><span class="by">lukan</span><span>|</span><a href="#42890681">root</a><span>|</span><a href="#42891145">parent</a><span>|</span><a href="#42891563">prev</a><span>|</span><a href="#42891396">next</a><span>|</span><label class="collapse" for="c-42892047">[-]</label><label class="expand" for="c-42892047">[2 more]</label></div><br/><div class="children"><div class="content">&quot;OpenAI has no moat because they have nothing unique&quot;<p>It seems they have high quality trainingsdata. And the knowledge to work with it.</div><br/><div id="42895184" class="c"><input type="checkbox" id="c-42895184" checked=""/><div class="controls bullet"><span class="by">aprilthird2021</span><span>|</span><a href="#42890681">root</a><span>|</span><a href="#42892047">parent</a><span>|</span><a href="#42891396">next</a><span>|</span><label class="collapse" for="c-42895184">[-]</label><label class="expand" for="c-42895184">[1 more]</label></div><br/><div class="children"><div class="content">They buy most of their data from Scale AI types. It&#x27;s not any higher quality than is available to any other model farm</div><br/></div></div></div></div><div id="42891396" class="c"><input type="checkbox" id="c-42891396" checked=""/><div class="controls bullet"><span class="by">sangnoir</span><span>|</span><a href="#42890681">root</a><span>|</span><a href="#42891145">parent</a><span>|</span><a href="#42892047">prev</a><span>|</span><a href="#42891520">next</a><span>|</span><label class="collapse" for="c-42891396">[-]</label><label class="expand" for="c-42891396">[4 more]</label></div><br/><div class="children"><div class="content">&gt; That moat is trivially circumvented by lighting a larger pile of money and less trivially by lighting the pile more efficently.<p>DeepSeek has proven that the latter is possible, which drops a couple of River crossing rocks into the moat.</div><br/><div id="42891640" class="c"><input type="checkbox" id="c-42891640" checked=""/><div class="controls bullet"><span class="by">withinboredom</span><span>|</span><a href="#42890681">root</a><span>|</span><a href="#42891396">parent</a><span>|</span><a href="#42891520">next</a><span>|</span><label class="collapse" for="c-42891640">[-]</label><label class="expand" for="c-42891640">[3 more]</label></div><br/><div class="children"><div class="content">The fact that I can basically run o1-mini with deepseek:8b, locally, is amazing. Even on battery power, it works acceptably.</div><br/><div id="42892540" class="c"><input type="checkbox" id="c-42892540" checked=""/><div class="controls bullet"><span class="by">tmnvdb</span><span>|</span><a href="#42890681">root</a><span>|</span><a href="#42891640">parent</a><span>|</span><a href="#42891520">next</a><span>|</span><label class="collapse" for="c-42892540">[-]</label><label class="expand" for="c-42892540">[2 more]</label></div><br/><div class="children"><div class="content">Those models are not comparable</div><br/><div id="42892677" class="c"><input type="checkbox" id="c-42892677" checked=""/><div class="controls bullet"><span class="by">withinboredom</span><span>|</span><a href="#42890681">root</a><span>|</span><a href="#42892540">parent</a><span>|</span><a href="#42891520">next</a><span>|</span><label class="collapse" for="c-42892677">[-]</label><label class="expand" for="c-42892677">[1 more]</label></div><br/><div class="children"><div class="content">hmmm... check the deepseek-r1 repo readme :) They compare them there, but it would be nice to have external benchmarks.</div><br/></div></div></div></div></div></div></div></div><div id="42891520" class="c"><input type="checkbox" id="c-42891520" checked=""/><div class="controls bullet"><span class="by">brookst</span><span>|</span><a href="#42890681">root</a><span>|</span><a href="#42891145">parent</a><span>|</span><a href="#42891396">prev</a><span>|</span><a href="#42896738">next</a><span>|</span><label class="collapse" for="c-42891520">[-]</label><label class="expand" for="c-42891520">[4 more]</label></div><br/><div class="children"><div class="content">Brand is a moat</div><br/><div id="42891654" class="c"><input type="checkbox" id="c-42891654" checked=""/><div class="controls bullet"><span class="by">cruffle_duffle</span><span>|</span><a href="#42890681">root</a><span>|</span><a href="#42891520">parent</a><span>|</span><a href="#42893143">next</a><span>|</span><label class="collapse" for="c-42891654">[-]</label><label class="expand" for="c-42891654">[2 more]</label></div><br/><div class="children"><div class="content">Ask Jeeves and Altavista surely have something to say about that!</div><br/><div id="42893873" class="c"><input type="checkbox" id="c-42893873" checked=""/><div class="controls bullet"><span class="by">geerlingguy</span><span>|</span><a href="#42890681">root</a><span>|</span><a href="#42891654">parent</a><span>|</span><a href="#42893143">next</a><span>|</span><label class="collapse" for="c-42893873">[-]</label><label class="expand" for="c-42893873">[1 more]</label></div><br/><div class="children"><div class="content">Add Yahoo! to that list</div><br/></div></div></div></div><div id="42893143" class="c"><input type="checkbox" id="c-42893143" checked=""/><div class="controls bullet"><span class="by">esafak</span><span>|</span><a href="#42890681">root</a><span>|</span><a href="#42891520">parent</a><span>|</span><a href="#42891654">prev</a><span>|</span><a href="#42896738">next</a><span>|</span><label class="collapse" for="c-42893143">[-]</label><label class="expand" for="c-42893143">[1 more]</label></div><br/><div class="children"><div class="content">Their brand is as tainted as Meta&#x27;s, which was bad enough to merit a rebranding from Facebook.</div><br/></div></div></div></div><div id="42896738" class="c"><input type="checkbox" id="c-42896738" checked=""/><div class="controls bullet"><span class="by">petesergeant</span><span>|</span><a href="#42890681">root</a><span>|</span><a href="#42891145">parent</a><span>|</span><a href="#42891520">prev</a><span>|</span><a href="#42891273">next</a><span>|</span><label class="collapse" for="c-42896738">[-]</label><label class="expand" for="c-42896738">[1 more]</label></div><br/><div class="children"><div class="content">&gt; OpenAI has no moat<p>... is definitely something I&#x27;ve said before, and recently, but:<p>&gt; That moat is trivially circumvented by lighting a larger pile of money<p>If that was true, someone would have done it.</div><br/></div></div></div></div><div id="42891273" class="c"><input type="checkbox" id="c-42891273" checked=""/><div class="controls bullet"><span class="by">lumost</span><span>|</span><a href="#42890681">root</a><span>|</span><a href="#42890722">parent</a><span>|</span><a href="#42891145">prev</a><span>|</span><a href="#42893950">next</a><span>|</span><label class="collapse" for="c-42891273">[-]</label><label class="expand" for="c-42891273">[3 more]</label></div><br/><div class="children"><div class="content">Capex was the theoretical moat, same as TSMC and similar businesses. DeepSeek poked a hole in this theory. OpenAI will need to deliver massive improvements to justify a 1 billion dollar training cost relative to 5 million dollars.</div><br/><div id="42892118" class="c"><input type="checkbox" id="c-42892118" checked=""/><div class="controls bullet"><span class="by">usef-</span><span>|</span><a href="#42890681">root</a><span>|</span><a href="#42891273">parent</a><span>|</span><a href="#42893950">next</a><span>|</span><label class="collapse" for="c-42892118">[-]</label><label class="expand" for="c-42892118">[2 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t know if you are, but a lot of people are still comparing one Deepseek training run to the entire costs of OpenAI.<p>The deepseek paper states that the $5mil number doesn&#x27;t include development costs, only the final training run. And it doesn&#x27;t include the estimated $1.4billion cost of the infrastructure&#x2F;chips Deepseek owns.<p>Most of OpenAI&#x27;s billion dollar costs is in inference, not training. It takes a lot of compute to serve so many users.<p>Dario said recently that Claude was in the tens of millions (and that it was a year earlier, so some cost decline is expected), do we have some reason to think OpenAI was so vastly different?</div><br/><div id="42895004" class="c"><input type="checkbox" id="c-42895004" checked=""/><div class="controls bullet"><span class="by">lumost</span><span>|</span><a href="#42890681">root</a><span>|</span><a href="#42892118">parent</a><span>|</span><a href="#42893950">next</a><span>|</span><label class="collapse" for="c-42895004">[-]</label><label class="expand" for="c-42895004">[1 more]</label></div><br/><div class="children"><div class="content">Anthropic’s ceo was predicting billion dollar training runs for 2025. Current training runs were likely in the tens&#x2F;hundreds of millions of dollars USD.<p>Inference capex costs are not a defensive moat as I can rent gpus and sell inference with linear scaling costs. A hypothetical 10 billion dollar training run on proprietary data was a massive moat.<p><a href="https:&#x2F;&#x2F;www.itpro.com&#x2F;technology&#x2F;artificial-intelligence&#x2F;dollar100-billion-to-build-an-ai-model-anthropic-ceo-dario-amodei-predicts-soaring-ai-training-costs-but-models-will-become-far-more-powerful#:~:text=Amodei%20said%20AI%20training%20costs,sometime%20in%20the%20next%20year." rel="nofollow">https:&#x2F;&#x2F;www.itpro.com&#x2F;technology&#x2F;artificial-intelligence&#x2F;dol...</a></div><br/></div></div></div></div></div></div><div id="42893950" class="c"><input type="checkbox" id="c-42893950" checked=""/><div class="controls bullet"><span class="by">dutchbookmaker</span><span>|</span><a href="#42890681">root</a><span>|</span><a href="#42890722">parent</a><span>|</span><a href="#42891273">prev</a><span>|</span><a href="#42890805">next</a><span>|</span><label class="collapse" for="c-42893950">[-]</label><label class="expand" for="c-42893950">[2 more]</label></div><br/><div class="children"><div class="content">It is still curious though as far as what is actually being automated?<p>I find huge value in these models as an augmentation of my intelligence and as a kind of cybernetic partner.<p>I can&#x27;t think of anything that can actually be automated though in terms of white collar jobs.<p>The white collar model test case I have in mind is a bank analyst under a bank operations manger. I have done both in the past but there is something really lacking with the idea of the operations manager replacing the analyst with a reasoning model even though DeepSeek annihilates every bank analyst reasoning I ever worked with right now.<p>If you can&#x27;t even arbitrage the average bank analyst there might be these really non-intuitive no AI arbitrage conditions with white color work.</div><br/><div id="42894412" class="c"><input type="checkbox" id="c-42894412" checked=""/><div class="controls bullet"><span class="by">gdhkgdhkvff</span><span>|</span><a href="#42890681">root</a><span>|</span><a href="#42893950">parent</a><span>|</span><a href="#42890805">next</a><span>|</span><label class="collapse" for="c-42894412">[-]</label><label class="expand" for="c-42894412">[1 more]</label></div><br/><div class="children"><div class="content">I don’t want to pretend I know how bank analysts work, but at the very least I would assume that 4 bank analysts with reasoning models would outperform 5 bank analysts without.</div><br/></div></div></div></div><div id="42890805" class="c"><input type="checkbox" id="c-42890805" checked=""/><div class="controls bullet"><span class="by">wahnfrieden</span><span>|</span><a href="#42890681">root</a><span>|</span><a href="#42890722">parent</a><span>|</span><a href="#42893950">prev</a><span>|</span><a href="#42890743">next</a><span>|</span><label class="collapse" for="c-42890805">[-]</label><label class="expand" for="c-42890805">[1 more]</label></div><br/><div class="children"><div class="content">Collaboration is even better, per open source results.<p>It is the closed competition model that’s being left in the dust.</div><br/></div></div></div></div></div></div><div id="42890743" class="c"><input type="checkbox" id="c-42890743" checked=""/><div class="controls bullet"><span class="by">devindotcom</span><span>|</span><a href="#42890681">prev</a><span>|</span><a href="#42890702">next</a><span>|</span><label class="collapse" for="c-42890743">[-]</label><label class="expand" for="c-42890743">[3 more]</label></div><br/><div class="children"><div class="content">Sure as a clock, tick follows tock. Can&#x27;t imagine trying to build out cost structures, business plans, product launches etc on such rapidly shifting sands. Good that you get more for your money, I suppose. But I get the feeling no model or provider is worth committing to in any serious way.</div><br/><div id="42896814" class="c"><input type="checkbox" id="c-42896814" checked=""/><div class="controls bullet"><span class="by">thom</span><span>|</span><a href="#42890743">parent</a><span>|</span><a href="#42893791">next</a><span>|</span><label class="collapse" for="c-42896814">[-]</label><label class="expand" for="c-42896814">[1 more]</label></div><br/><div class="children"><div class="content">Terrible time to open a shovel store, amazing time to pick up a shovel.</div><br/></div></div><div id="42893791" class="c"><input type="checkbox" id="c-42893791" checked=""/><div class="controls bullet"><span class="by">puffybunion</span><span>|</span><a href="#42890743">parent</a><span>|</span><a href="#42896814">prev</a><span>|</span><a href="#42890702">next</a><span>|</span><label class="collapse" for="c-42893791">[-]</label><label class="expand" for="c-42893791">[1 more]</label></div><br/><div class="children"><div class="content">this is the best outcome, though, rather than a monopoly, which is exactly what everyone is hoping to have.</div><br/></div></div></div></div><div id="42890702" class="c"><input type="checkbox" id="c-42890702" checked=""/><div class="controls bullet"><span class="by">cjbarber</span><span>|</span><a href="#42890743">prev</a><span>|</span><a href="#42890774">next</a><span>|</span><label class="collapse" for="c-42890702">[-]</label><label class="expand" for="c-42890702">[3 more]</label></div><br/><div class="children"><div class="content">The interesting question to me is how far these reasoning models can be scaled. With another 12 months of compute scaling (for synthetic data generation and RL) how good will these models be at coding? I talked with Finbarr Timbers (ex-DeepMind) yesterday about this and his take is that we&#x27;ll hit diminishing returns – not because we can&#x27;t make models more powerful, but because we&#x27;re approaching diminishing returns in areas that matter to users and that AI models may be nearing a plateau where capability gains matter less than UX.</div><br/><div id="42893872" class="c"><input type="checkbox" id="c-42893872" checked=""/><div class="controls bullet"><span class="by">futureshock</span><span>|</span><a href="#42890702">parent</a><span>|</span><a href="#42890774">next</a><span>|</span><label class="collapse" for="c-42893872">[-]</label><label class="expand" for="c-42893872">[2 more]</label></div><br/><div class="children"><div class="content">I think in a lot of ways we are already there. Users are clearly already having difficulty seeing which model is better or if new models are improving over old models. People go back to the same gotcha questions and get different answers based on the random seed. Even the benchmarks are getting very saturated.<p>These models already do an excellent job with your homework, your corporate PowerPoints and your idle questions. At some point only experts would be able to decide if one response was really better than another.<p>Our biggest challenge is going to be finding problem domains with low performance that we can still scale up to human performance. And those will be so niche that no one will care.<p>Agents on the other hand still have a lot of potential. If you can get a model to stay on task with long context and remain grounded then you can start firing your staff.</div><br/><div id="42895021" class="c"><input type="checkbox" id="c-42895021" checked=""/><div class="controls bullet"><span class="by">dagelf</span><span>|</span><a href="#42890702">root</a><span>|</span><a href="#42893872">parent</a><span>|</span><a href="#42890774">next</a><span>|</span><label class="collapse" for="c-42895021">[-]</label><label class="expand" for="c-42895021">[1 more]</label></div><br/><div class="children"><div class="content">Don&#x27;t underestimate how much the long tail means to the general public.</div><br/></div></div></div></div></div></div><div id="42890774" class="c"><input type="checkbox" id="c-42890774" checked=""/><div class="controls bullet"><span class="by">dilap</span><span>|</span><a href="#42890702">prev</a><span>|</span><a href="#42891294">next</a><span>|</span><label class="collapse" for="c-42890774">[-]</label><label class="expand" for="c-42890774">[5 more]</label></div><br/><div class="children"><div class="content">Haven&#x27;t used openai in a bit -- whyyy did they change &quot;system&quot; role (now basically an industry-wide standard) to &quot;developer&quot;? That seems pointlessly disruptive.</div><br/><div id="42890902" class="c"><input type="checkbox" id="c-42890902" checked=""/><div class="controls bullet"><span class="by">logicchains</span><span>|</span><a href="#42890774">parent</a><span>|</span><a href="#42893629">next</a><span>|</span><label class="collapse" for="c-42890902">[-]</label><label class="expand" for="c-42890902">[3 more]</label></div><br/><div class="children"><div class="content">They mention in the model card, it&#x27;s so that they can have a separate &quot;system&quot; role that the user can&#x27;t change, and they trained the model to prioritise it over the &quot;developer&quot; role, to combat &quot;jailbreaks&quot;. Thank God for DeepSeek.</div><br/><div id="42891300" class="c"><input type="checkbox" id="c-42891300" checked=""/><div class="controls bullet"><span class="by">sroussey</span><span>|</span><a href="#42890774">root</a><span>|</span><a href="#42890902">parent</a><span>|</span><a href="#42893629">next</a><span>|</span><label class="collapse" for="c-42891300">[-]</label><label class="expand" for="c-42891300">[2 more]</label></div><br/><div class="children"><div class="content">They should have just created something above system and left as it was.</div><br/><div id="42891925" class="c"><input type="checkbox" id="c-42891925" checked=""/><div class="controls bullet"><span class="by">Etheryte</span><span>|</span><a href="#42890774">root</a><span>|</span><a href="#42891300">parent</a><span>|</span><a href="#42893629">next</a><span>|</span><label class="collapse" for="c-42891925">[-]</label><label class="expand" for="c-42891925">[1 more]</label></div><br/><div class="children"><div class="content">Agreed, just add root and call it a day. Everyone who needs to care can instantly guesstimate what it is.</div><br/></div></div></div></div></div></div><div id="42893629" class="c"><input type="checkbox" id="c-42893629" checked=""/><div class="controls bullet"><span class="by">BoorishBears</span><span>|</span><a href="#42890774">parent</a><span>|</span><a href="#42890902">prev</a><span>|</span><a href="#42891294">next</a><span>|</span><label class="collapse" for="c-42893629">[-]</label><label class="expand" for="c-42893629">[1 more]</label></div><br/><div class="children"><div class="content">2 years ago I&#x27;d say it&#x27;s an oversight, because there&#x27;s 0 chance a top down directive would ask for this.<p>But given how OpenAI employees act online these days I wouldn&#x27;t be surprised if someone on the ground proposed it as a way to screw with all the 3rd parties who are using OpenAI compatible endpoints or even use OpenAI&#x27;s SDK in their official docs in some cases.</div><br/></div></div></div></div><div id="42891294" class="c"><input type="checkbox" id="c-42891294" checked=""/><div class="controls bullet"><span class="by">jen729w</span><span>|</span><a href="#42890774">prev</a><span>|</span><a href="#42891605">next</a><span>|</span><label class="collapse" for="c-42891294">[-]</label><label class="expand" for="c-42891294">[77 more]</label></div><br/><div class="children"><div class="content">&gt; Testers preferred o3-mini&#x27;s responses to o1-mini 56% of the time<p>I hope by this they don&#x27;t mean me, when I&#x27;m asked &#x27;which of these two responses do you prefer&#x27;.<p>They&#x27;re both 2,000 words, and I asked a question because I have something to do. <i>I&#x27;m not reading them both</i>; I&#x27;m usually just selecting the one that answered first.<p>That prompt is pointless. Perhaps as evidenced by the essentially 50% response rate: it&#x27;s a coin-flip.</div><br/><div id="42891590" class="c"><input type="checkbox" id="c-42891590" checked=""/><div class="controls bullet"><span class="by">dkjaudyeqooe</span><span>|</span><a href="#42891294">parent</a><span>|</span><a href="#42891508">next</a><span>|</span><label class="collapse" for="c-42891590">[-]</label><label class="expand" for="c-42891590">[23 more]</label></div><br/><div class="children"><div class="content">It&#x27;s kind of strange that they gave that stat. Maybe they thought people would somehow think about &quot;56% better&quot; or something.<p>Because when you think about it, it really is quite damning. Minus statistical noise it&#x27;s no better.</div><br/><div id="42892780" class="c"><input type="checkbox" id="c-42892780" checked=""/><div class="controls bullet"><span class="by">cm2187</span><span>|</span><a href="#42891294">root</a><span>|</span><a href="#42891590">parent</a><span>|</span><a href="#42891882">next</a><span>|</span><label class="collapse" for="c-42892780">[-]</label><label class="expand" for="c-42892780">[5 more]</label></div><br/><div class="children"><div class="content">And another way to rephrase it is that almost half of the users prefer the older model, which is terrible PR.</div><br/><div id="42893281" class="c"><input type="checkbox" id="c-42893281" checked=""/><div class="controls bullet"><span class="by">tgsovlerkhgsel</span><span>|</span><a href="#42891294">root</a><span>|</span><a href="#42892780">parent</a><span>|</span><a href="#42893570">next</a><span>|</span><label class="collapse" for="c-42893281">[-]</label><label class="expand" for="c-42893281">[1 more]</label></div><br/><div class="children"><div class="content">Not if the goal is to claim that the models deliver comparable quality, but with the new one excelling at something else (here: inferrence cost).</div><br/></div></div><div id="42893570" class="c"><input type="checkbox" id="c-42893570" checked=""/><div class="controls bullet"><span class="by">kettleballroll</span><span>|</span><a href="#42891294">root</a><span>|</span><a href="#42892780">parent</a><span>|</span><a href="#42893281">prev</a><span>|</span><a href="#42891882">next</a><span>|</span><label class="collapse" for="c-42893570">[-]</label><label class="expand" for="c-42893570">[3 more]</label></div><br/><div class="children"><div class="content">Typically in these tests you have three options &quot;A is better&quot;, &quot;B is better&quot; or &quot;they&#x27;re equal&#x2F;can&#x27;t decide&quot;. So if 56% prefer O3 Mini, it&#x27;s likely that way less than half prefer O1.also, the way I understand it, they&#x27;re comparing a mini model with a large one.</div><br/><div id="42893621" class="c"><input type="checkbox" id="c-42893621" checked=""/><div class="controls bullet"><span class="by">directevolve</span><span>|</span><a href="#42891294">root</a><span>|</span><a href="#42893570">parent</a><span>|</span><a href="#42891882">next</a><span>|</span><label class="collapse" for="c-42893621">[-]</label><label class="expand" for="c-42893621">[2 more]</label></div><br/><div class="children"><div class="content">If you use ChatGPT, it sometimes gives you two versions of its response, and you have to choose one or the other if you want to continue prompting. Sure, not picking a response might be a third category. But if that&#x27;s how they were approaching the analysis, they could have put out a more favorable-looking stat.</div><br/><div id="42893756" class="c"><input type="checkbox" id="c-42893756" checked=""/><div class="controls bullet"><span class="by">ignoramous</span><span>|</span><a href="#42891294">root</a><span>|</span><a href="#42893621">parent</a><span>|</span><a href="#42891882">next</a><span>|</span><label class="collapse" for="c-42893756">[-]</label><label class="expand" for="c-42893756">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>If you use ChatGPT, it sometimes gives you two versions</i><p>Does no one else hate it when this happens (especially when on a handheld device)?</div><br/></div></div></div></div></div></div></div></div><div id="42891882" class="c"><input type="checkbox" id="c-42891882" checked=""/><div class="controls bullet"><span class="by">Powdering7082</span><span>|</span><a href="#42891294">root</a><span>|</span><a href="#42891590">parent</a><span>|</span><a href="#42892780">prev</a><span>|</span><a href="#42893767">next</a><span>|</span><label class="collapse" for="c-42891882">[-]</label><label class="expand" for="c-42891882">[11 more]</label></div><br/><div class="children"><div class="content">That would be 12%, why would you assume that is eaten by statistical noise?</div><br/><div id="42892021" class="c"><input type="checkbox" id="c-42892021" checked=""/><div class="controls bullet"><span class="by">senorrib</span><span>|</span><a href="#42891294">root</a><span>|</span><a href="#42891882">parent</a><span>|</span><a href="#42892209">next</a><span>|</span><label class="collapse" for="c-42892021">[-]</label><label class="expand" for="c-42892021">[9 more]</label></div><br/><div class="children"><div class="content">The OPs comment is probably a testament of that. With such a poorly designed A&#x2F;B test I doubt this has a p-value of &lt; 0.10.</div><br/><div id="42892564" class="c"><input type="checkbox" id="c-42892564" checked=""/><div class="controls bullet"><span class="by">throwaway287391</span><span>|</span><a href="#42891294">root</a><span>|</span><a href="#42892021">parent</a><span>|</span><a href="#42892209">next</a><span>|</span><label class="collapse" for="c-42892564">[-]</label><label class="expand" for="c-42892564">[8 more]</label></div><br/><div class="children"><div class="content">Erm, why not? A 0.56 result with n=1000 ratings is statistically significantly better than 0.5 with a p-value of 0.00001864, well beyond any standard statistical significance threshold I&#x27;ve ever heard of. I don&#x27;t know how many ratings they collected but 1000 doesn&#x27;t seem crazy at all. Assuming of course that raters are blind to which model is which and the order of the 2 responses is randomized with every rating -- or, is that what you meant by &quot;poorly designed&quot;? If so, where do they indicate they failed to randomize&#x2F;blind the raters?</div><br/><div id="42893262" class="c"><input type="checkbox" id="c-42893262" checked=""/><div class="controls bullet"><span class="by">godelski</span><span>|</span><a href="#42891294">root</a><span>|</span><a href="#42892564">parent</a><span>|</span><a href="#42892685">next</a><span>|</span><label class="collapse" for="c-42893262">[-]</label><label class="expand" for="c-42893262">[1 more]</label></div><br/><div class="children"><div class="content"><p><pre><code>  &gt; If so, where do they indicate they failed to randomize&#x2F;blind the raters?

  Win rate if user is under time constraint
</code></pre>
This is hard to read tbh. Is it STEM? Non-STEM? If it is STEM then this shows there is a bias. If it is Non-STEM then this shows a bias. If it is a mix, well we can&#x27;t know anything without understanding the split.<p>Note that Non-STEM is still within error. STEM is less than 2 sigma variance, so our confidence still shouldn&#x27;t be that high.</div><br/></div></div><div id="42892685" class="c"><input type="checkbox" id="c-42892685" checked=""/><div class="controls bullet"><span class="by">n2d4</span><span>|</span><a href="#42891294">root</a><span>|</span><a href="#42892564">parent</a><span>|</span><a href="#42893262">prev</a><span>|</span><a href="#42892209">next</a><span>|</span><label class="collapse" for="c-42892685">[-]</label><label class="expand" for="c-42892685">[6 more]</label></div><br/><div class="children"><div class="content">Because you&#x27;re not testing &quot;will a user click the left or right button&quot; (for which asking a thousand users to click a button would be a pretty good estimation), you&#x27;re testing &quot;which response is preferred&quot;.<p>If 10% of people just click based on how fast the response was because they don&#x27;t want to read both outputs, your p-value for the latter hypothesis will be atrocious, no matter how large the sample is.</div><br/><div id="42892726" class="c"><input type="checkbox" id="c-42892726" checked=""/><div class="controls bullet"><span class="by">johnmaguire</span><span>|</span><a href="#42891294">root</a><span>|</span><a href="#42892685">parent</a><span>|</span><a href="#42892752">next</a><span>|</span><label class="collapse" for="c-42892726">[-]</label><label class="expand" for="c-42892726">[2 more]</label></div><br/><div class="children"><div class="content">&gt; If 10% of people just click based on how fast the response was<p>Couldn&#x27;t this be considered a form of preference?<p>Whether it&#x27;s the type of preference OpenAI was testing for, or the type of preference you care about, is another matter.</div><br/><div id="42892907" class="c"><input type="checkbox" id="c-42892907" checked=""/><div class="controls bullet"><span class="by">n2d4</span><span>|</span><a href="#42891294">root</a><span>|</span><a href="#42892726">parent</a><span>|</span><a href="#42892752">next</a><span>|</span><label class="collapse" for="c-42892907">[-]</label><label class="expand" for="c-42892907">[1 more]</label></div><br/><div class="children"><div class="content">Sure, it could be, you can define &quot;preference&quot; as basically anything, but it just loses its meaning if you do that. I think most people would think &quot;56% prefer this product&quot; means &quot;when well-informed, 56% of users would rather have this product than the other&quot;.</div><br/></div></div></div></div><div id="42892752" class="c"><input type="checkbox" id="c-42892752" checked=""/><div class="controls bullet"><span class="by">throwaway287391</span><span>|</span><a href="#42891294">root</a><span>|</span><a href="#42892685">parent</a><span>|</span><a href="#42892726">prev</a><span>|</span><a href="#42892209">next</a><span>|</span><label class="collapse" for="c-42892752">[-]</label><label class="expand" for="c-42892752">[3 more]</label></div><br/><div class="children"><div class="content">Yes, I am assuming they evaluated the models in good faith, understand how to design a basic user study, and therefore when they ran a study intended to compare the response quality between two different models, they showed the raters both fully-formed responses at the same time, regardless of the actual latency of each model.</div><br/><div id="42892878" class="c"><input type="checkbox" id="c-42892878" checked=""/><div class="controls bullet"><span class="by">n2d4</span><span>|</span><a href="#42891294">root</a><span>|</span><a href="#42892752">parent</a><span>|</span><a href="#42892209">next</a><span>|</span><label class="collapse" for="c-42892878">[-]</label><label class="expand" for="c-42892878">[2 more]</label></div><br/><div class="children"><div class="content">I would recommend you read the comment that started this thread then, because that&#x27;s the context we&#x27;re talking about: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=42891294">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=42891294</a></div><br/><div id="42892921" class="c"><input type="checkbox" id="c-42892921" checked=""/><div class="controls bullet"><span class="by">throwaway287391</span><span>|</span><a href="#42891294">root</a><span>|</span><a href="#42892878">parent</a><span>|</span><a href="#42892209">next</a><span>|</span><label class="collapse" for="c-42892921">[-]</label><label class="expand" for="c-42892921">[1 more]</label></div><br/><div class="children"><div class="content">I did read that comment. I don&#x27;t think that person is saying they were part of the study that OpenAI used to evaluate the models. They would probably know if they had gotten paid to evaluate LLM responses.<p>But I&#x27;m glad you pointed that out, I now suspect that is responsible for a large part of the disagreement between &quot;huh? a statistically significant blind evaluation is a statistically significant blind evaluation&quot; vs &quot;oh, this was obviously a terrible study&quot; repliers is due to different interpretations of that post. Thanks. I genuinely didn&#x27;t consider the alternative interpretation before.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="42892209" class="c"><input type="checkbox" id="c-42892209" checked=""/><div class="controls bullet"><span class="by">aqme28</span><span>|</span><a href="#42891294">root</a><span>|</span><a href="#42891882">parent</a><span>|</span><a href="#42892021">prev</a><span>|</span><a href="#42893767">next</a><span>|</span><label class="collapse" for="c-42892209">[-]</label><label class="expand" for="c-42892209">[1 more]</label></div><br/><div class="children"><div class="content">They even include error bars. It doesn&#x27;t seem to be statistical noise, but it&#x27;s still not great.</div><br/></div></div></div></div><div id="42893767" class="c"><input type="checkbox" id="c-42893767" checked=""/><div class="controls bullet"><span class="by">m3kw9</span><span>|</span><a href="#42891294">root</a><span>|</span><a href="#42891590">parent</a><span>|</span><a href="#42891882">prev</a><span>|</span><a href="#42892099">next</a><span>|</span><label class="collapse" for="c-42893767">[-]</label><label class="expand" for="c-42893767">[1 more]</label></div><br/><div class="children"><div class="content">It’s 3x cheaper and faster</div><br/></div></div><div id="42892099" class="c"><input type="checkbox" id="c-42892099" checked=""/><div class="controls bullet"><span class="by">afro88</span><span>|</span><a href="#42891294">root</a><span>|</span><a href="#42891590">parent</a><span>|</span><a href="#42893767">prev</a><span>|</span><a href="#42891799">next</a><span>|</span><label class="collapse" for="c-42892099">[-]</label><label class="expand" for="c-42892099">[4 more]</label></div><br/><div class="children"><div class="content">Yeah. I immediately thought: I wonder if that 56% is in one or two categories and the rest are worse?</div><br/><div id="42893323" class="c"><input type="checkbox" id="c-42893323" checked=""/><div class="controls bullet"><span class="by">rvnx</span><span>|</span><a href="#42891294">root</a><span>|</span><a href="#42892099">parent</a><span>|</span><a href="#42891799">next</a><span>|</span><label class="collapse" for="c-42893323">[-]</label><label class="expand" for="c-42893323">[3 more]</label></div><br/><div class="children"><div class="content">44% of the people prefers the existing model ?</div><br/><div id="42894472" class="c"><input type="checkbox" id="c-42894472" checked=""/><div class="controls bullet"><span class="by">afro88</span><span>|</span><a href="#42891294">root</a><span>|</span><a href="#42893323">parent</a><span>|</span><a href="#42893862">next</a><span>|</span><label class="collapse" for="c-42894472">[-]</label><label class="expand" for="c-42894472">[1 more]</label></div><br/><div class="children"><div class="content">Each question falls into a different category (ie math, coding, story writing etc). Typically models are better at some categories and worse at others. Saying &quot;56% of people preferred responses from o3-mini&quot; makes me wonder if those 56 are only from certain categories and the model isn&#x27;t uniformly 56% preferred.</div><br/></div></div><div id="42893862" class="c"><input type="checkbox" id="c-42893862" checked=""/><div class="controls bullet"><span class="by">KHRZ</span><span>|</span><a href="#42891294">root</a><span>|</span><a href="#42893323">parent</a><span>|</span><a href="#42894472">prev</a><span>|</span><a href="#42891799">next</a><span>|</span><label class="collapse" for="c-42893862">[-]</label><label class="expand" for="c-42893862">[1 more]</label></div><br/><div class="children"><div class="content">With many people too lazy to read 2 walls of text, a lot of picks might be random.</div><br/></div></div></div></div></div></div><div id="42891799" class="c"><input type="checkbox" id="c-42891799" checked=""/><div class="controls bullet"><span class="by">fsndz</span><span>|</span><a href="#42891294">root</a><span>|</span><a href="#42891590">parent</a><span>|</span><a href="#42892099">prev</a><span>|</span><a href="#42891508">next</a><span>|</span><label class="collapse" for="c-42891799">[-]</label><label class="expand" for="c-42891799">[1 more]</label></div><br/><div class="children"><div class="content">exactly I was surprised as well</div><br/></div></div></div></div><div id="42891508" class="c"><input type="checkbox" id="c-42891508" checked=""/><div class="controls bullet"><span class="by">brookst</span><span>|</span><a href="#42891294">parent</a><span>|</span><a href="#42891590">prev</a><span>|</span><a href="#42892123">next</a><span>|</span><label class="collapse" for="c-42891508">[-]</label><label class="expand" for="c-42891508">[18 more]</label></div><br/><div class="children"><div class="content">Those prompts are so irritating and so frequent that I’ve taken to just quickly picking whichever one looks worse at a cursory glance. I’m paying them, they shouldn’t expect high quality work from me.</div><br/><div id="42891743" class="c"><input type="checkbox" id="c-42891743" checked=""/><div class="controls bullet"><span class="by">apparent</span><span>|</span><a href="#42891294">root</a><span>|</span><a href="#42891508">parent</a><span>|</span><a href="#42891778">next</a><span>|</span><label class="collapse" for="c-42891743">[-]</label><label class="expand" for="c-42891743">[10 more]</label></div><br/><div class="children"><div class="content">Have you considered the possibility that your feedback is used to choose what type of response to give to you specifically in the future?<p>I would not consider purposely giving inaccurate feedback for this reason alone.</div><br/><div id="42891903" class="c"><input type="checkbox" id="c-42891903" checked=""/><div class="controls bullet"><span class="by">MattDaEskimo</span><span>|</span><a href="#42891294">root</a><span>|</span><a href="#42891743">parent</a><span>|</span><a href="#42891960">next</a><span>|</span><label class="collapse" for="c-42891903">[-]</label><label class="expand" for="c-42891903">[6 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t want a model that&#x27;s customized to my preferences. My preferences and understanding changes all the time.<p>I want a single source model that&#x27;s grounded in base truth. I&#x27;ll let the model know how to structure it in my prompt.</div><br/><div id="42893027" class="c"><input type="checkbox" id="c-42893027" checked=""/><div class="controls bullet"><span class="by">kenjackson</span><span>|</span><a href="#42891294">root</a><span>|</span><a href="#42891903">parent</a><span>|</span><a href="#42893083">next</a><span>|</span><label class="collapse" for="c-42893027">[-]</label><label class="expand" for="c-42893027">[2 more]</label></div><br/><div class="children"><div class="content">You know there&#x27;s no such as base truth here? You want to write something like this to start your prompts, &quot;Respond in English, using standard capitalization and punctuation, following rules of grammar as written by Strunk &amp; White, where numbers are represented using arabic numerals in base 10 notation....&quot;???</div><br/><div id="42893746" class="c"><input type="checkbox" id="c-42893746" checked=""/><div class="controls bullet"><span class="by">AutistiCoder</span><span>|</span><a href="#42891294">root</a><span>|</span><a href="#42893027">parent</a><span>|</span><a href="#42893083">next</a><span>|</span><label class="collapse" for="c-42893746">[-]</label><label class="expand" for="c-42893746">[1 more]</label></div><br/><div class="children"><div class="content">actually, I might appreciate that.<p>I like precision of language, so maybe just have a system prompt that says &quot;use precise language (ex: no symbolism of any kind)&quot;</div><br/></div></div></div></div><div id="42893083" class="c"><input type="checkbox" id="c-42893083" checked=""/><div class="controls bullet"><span class="by">orbital-decay</span><span>|</span><a href="#42891294">root</a><span>|</span><a href="#42891903">parent</a><span>|</span><a href="#42893027">prev</a><span>|</span><a href="#42893080">next</a><span>|</span><label class="collapse" for="c-42893083">[-]</label><label class="expand" for="c-42893083">[1 more]</label></div><br/><div class="children"><div class="content">What is base truth for e.g. creative writing?</div><br/></div></div><div id="42893080" class="c"><input type="checkbox" id="c-42893080" checked=""/><div class="controls bullet"><span class="by">MattGaiser</span><span>|</span><a href="#42891294">root</a><span>|</span><a href="#42891903">parent</a><span>|</span><a href="#42893083">prev</a><span>|</span><a href="#42892081">next</a><span>|</span><label class="collapse" for="c-42893080">[-]</label><label class="expand" for="c-42893080">[1 more]</label></div><br/><div class="children"><div class="content">A lot of preferences have nothing to do with any truth. Do you like code segments or full code? Do you like paragraphs or bullet points? Heck, do you want English or Japanaese?</div><br/></div></div><div id="42892081" class="c"><input type="checkbox" id="c-42892081" checked=""/><div class="controls bullet"><span class="by">szundi</span><span>|</span><a href="#42891294">root</a><span>|</span><a href="#42891903">parent</a><span>|</span><a href="#42893080">prev</a><span>|</span><a href="#42891960">next</a><span>|</span><label class="collapse" for="c-42892081">[-]</label><label class="expand" for="c-42892081">[1 more]</label></div><br/><div class="children"><div class="content">Constang meh and fixing prompts to the right direction vs unable to escape the bubble</div><br/></div></div></div></div><div id="42891960" class="c"><input type="checkbox" id="c-42891960" checked=""/><div class="controls bullet"><span class="by">francis_lewis</span><span>|</span><a href="#42891294">root</a><span>|</span><a href="#42891743">parent</a><span>|</span><a href="#42891903">prev</a><span>|</span><a href="#42891786">next</a><span>|</span><label class="collapse" for="c-42891960">[-]</label><label class="expand" for="c-42891960">[1 more]</label></div><br/><div class="children"><div class="content">I think my awareness that this may influence future responses has actually been detrimental to my response rate. The responses are often so similar that I can imagine preferring either in specific circumstances. While I’m sure that can be guided by the prompt, I’m often hesitant to click on a specific response as I can see the value of the other response in a different situation and I don’t want to bias the future responses. Maybe with more specific prompting this wouldn’t be such an issue, or maybe more of an understanding of how inter-chat personalisation is applied (maybe I’m missing some information on this too).</div><br/></div></div><div id="42891786" class="c"><input type="checkbox" id="c-42891786" checked=""/><div class="controls bullet"><span class="by">isaacremuant</span><span>|</span><a href="#42891294">root</a><span>|</span><a href="#42891743">parent</a><span>|</span><a href="#42891960">prev</a><span>|</span><a href="#42892168">next</a><span>|</span><label class="collapse" for="c-42891786">[-]</label><label class="expand" for="c-42891786">[1 more]</label></div><br/><div class="children"><div class="content">Alternatively, I&#x27;ll use the tool that is most user friendly and provides the most value for my money.<p>Wasting time on an anti pattern is not value nor is it trying to outguess the way that selection mechanism is used.</div><br/></div></div><div id="42892168" class="c"><input type="checkbox" id="c-42892168" checked=""/><div class="controls bullet"><span class="by">Der_Einzige</span><span>|</span><a href="#42891294">root</a><span>|</span><a href="#42891743">parent</a><span>|</span><a href="#42891786">prev</a><span>|</span><a href="#42891778">next</a><span>|</span><label class="collapse" for="c-42892168">[-]</label><label class="expand" for="c-42892168">[1 more]</label></div><br/><div class="children"><div class="content">Spotted the pissed off OpenAI RLHF engineer! Hahahahaha!</div><br/></div></div></div></div><div id="42891778" class="c"><input type="checkbox" id="c-42891778" checked=""/><div class="controls bullet"><span class="by">Tenoke</span><span>|</span><a href="#42891294">root</a><span>|</span><a href="#42891508">parent</a><span>|</span><a href="#42891743">prev</a><span>|</span><a href="#42891678">next</a><span>|</span><label class="collapse" for="c-42891778">[-]</label><label class="expand" for="c-42891778">[6 more]</label></div><br/><div class="children"><div class="content">That&#x27;s such a counter-productive and frankly dumb thing to do. Just don&#x27;t vote on them.</div><br/><div id="42891922" class="c"><input type="checkbox" id="c-42891922" checked=""/><div class="controls bullet"><span class="by">explain</span><span>|</span><a href="#42891294">root</a><span>|</span><a href="#42891778">parent</a><span>|</span><a href="#42891678">next</a><span>|</span><label class="collapse" for="c-42891922">[-]</label><label class="expand" for="c-42891922">[5 more]</label></div><br/><div class="children"><div class="content">You have to pick one to continue the chat.</div><br/><div id="42892150" class="c"><input type="checkbox" id="c-42892150" checked=""/><div class="controls bullet"><span class="by">DiggyJohnson</span><span>|</span><a href="#42891294">root</a><span>|</span><a href="#42891922">parent</a><span>|</span><a href="#42891966">next</a><span>|</span><label class="collapse" for="c-42892150">[-]</label><label class="expand" for="c-42892150">[1 more]</label></div><br/><div class="children"><div class="content">I know for a fact that as of yesterday I did not have to pick one to continue the conversation. It just maximizes the second choice and displayed a 2&#x2F;2 below the response.</div><br/></div></div><div id="42891966" class="c"><input type="checkbox" id="c-42891966" checked=""/><div class="controls bullet"><span class="by">apparent</span><span>|</span><a href="#42891294">root</a><span>|</span><a href="#42891922">parent</a><span>|</span><a href="#42892150">prev</a><span>|</span><a href="#42892022">next</a><span>|</span><label class="collapse" for="c-42891966">[-]</label><label class="expand" for="c-42891966">[2 more]</label></div><br/><div class="children"><div class="content">Why not always pick the one on the left, for example? I understand wanting to speed through and not spend time doing labor for OpenAI, but it seems counter-productive to spend any time feeding it false information.</div><br/><div id="42894975" class="c"><input type="checkbox" id="c-42894975" checked=""/><div class="controls bullet"><span class="by">brookst</span><span>|</span><a href="#42891294">root</a><span>|</span><a href="#42891966">parent</a><span>|</span><a href="#42892022">next</a><span>|</span><label class="collapse" for="c-42894975">[-]</label><label class="expand" for="c-42894975">[1 more]</label></div><br/><div class="children"><div class="content">My assumption is they measure the quality of user feedback, either on a per user basis or in an aggregate. I want them to interrupt me less, so I want them to either decide I’m a bad teacher or that users in general are bad teachers.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="42892123" class="c"><input type="checkbox" id="c-42892123" checked=""/><div class="controls bullet"><span class="by">janalsncm</span><span>|</span><a href="#42891294">parent</a><span>|</span><a href="#42891508">prev</a><span>|</span><a href="#42892232">next</a><span>|</span><label class="collapse" for="c-42892123">[-]</label><label class="expand" for="c-42892123">[2 more]</label></div><br/><div class="children"><div class="content">&gt; I&#x27;m usually just selecting the one that answered first<p>Which is why you randomize the order. You aren’t a tester.<p>56% vs 44% may not be noise. That’s why we have p values. It depends on sample size.</div><br/><div id="42896257" class="c"><input type="checkbox" id="c-42896257" checked=""/><div class="controls bullet"><span class="by">jhardy54</span><span>|</span><a href="#42891294">root</a><span>|</span><a href="#42892123">parent</a><span>|</span><a href="#42892232">next</a><span>|</span><label class="collapse" for="c-42896257">[-]</label><label class="expand" for="c-42896257">[1 more]</label></div><br/><div class="children"><div class="content">The order doesn&#x27;t matter. They often generate tokens at different speeds, and produce different lengths of text. &quot;The one that answered first&quot; != &quot;The first option&quot;</div><br/></div></div></div></div><div id="42892232" class="c"><input type="checkbox" id="c-42892232" checked=""/><div class="controls bullet"><span class="by">letmevoteplease</span><span>|</span><a href="#42891294">parent</a><span>|</span><a href="#42892123">prev</a><span>|</span><a href="#42892626">next</a><span>|</span><label class="collapse" for="c-42892232">[-]</label><label class="expand" for="c-42892232">[2 more]</label></div><br/><div class="children"><div class="content">The article says &quot;expert testers.&quot;<p>&quot;Evaluations by expert testers showed that o3-mini produces more accurate and clearer answers, with stronger reasoning abilities, than OpenAI o1-mini. Testers preferred o3-mini&#x27;s responses to o1-mini 56% of the time and observed a 39% reduction in major errors on difficult real-world questions. W&quot;</div><br/><div id="42896538" class="c"><input type="checkbox" id="c-42896538" checked=""/><div class="controls bullet"><span class="by">threatripper</span><span>|</span><a href="#42891294">root</a><span>|</span><a href="#42892232">parent</a><span>|</span><a href="#42892626">next</a><span>|</span><label class="collapse" for="c-42896538">[-]</label><label class="expand" for="c-42896538">[1 more]</label></div><br/><div class="children"><div class="content">Those are two different sentences. The second sentence doesn&#x27;t refer to experts explicitly.</div><br/></div></div></div></div><div id="42892626" class="c"><input type="checkbox" id="c-42892626" checked=""/><div class="controls bullet"><span class="by">brianstrimp</span><span>|</span><a href="#42891294">parent</a><span>|</span><a href="#42892232">prev</a><span>|</span><a href="#42891766">next</a><span>|</span><label class="collapse" for="c-42892626">[-]</label><label class="expand" for="c-42892626">[1 more]</label></div><br/><div class="children"><div class="content">That makes the result stronger though. <i>Even though</i> many people click randomly, there is <i>still</i> a 12% margin between both groups. Not the world, but still quite a lot.</div><br/></div></div><div id="42891766" class="c"><input type="checkbox" id="c-42891766" checked=""/><div class="controls bullet"><span class="by">sharkweek</span><span>|</span><a href="#42891294">parent</a><span>|</span><a href="#42892626">prev</a><span>|</span><a href="#42894188">next</a><span>|</span><label class="collapse" for="c-42891766">[-]</label><label class="expand" for="c-42891766">[7 more]</label></div><br/><div class="children"><div class="content">Funny - I had ChatGPT document some stuff for me this week and asked which responses I preferred as well.<p>Didn’t bother reading either of them, just selected one and went on with my day.<p>If it were me I would have set up a “hey do you mind if we give you two results and you can pick your favorite?” prompt to weed out people like me.</div><br/><div id="42891860" class="c"><input type="checkbox" id="c-42891860" checked=""/><div class="controls bullet"><span class="by">usef-</span><span>|</span><a href="#42891294">root</a><span>|</span><a href="#42891766">parent</a><span>|</span><a href="#42893866">next</a><span>|</span><label class="collapse" for="c-42891860">[-]</label><label class="expand" for="c-42891860">[4 more]</label></div><br/><div class="children"><div class="content">I&#x27;m surprised how many people claim to do this. You can just not select one.</div><br/><div id="42893723" class="c"><input type="checkbox" id="c-42893723" checked=""/><div class="controls bullet"><span class="by">ssl-3</span><span>|</span><a href="#42891294">root</a><span>|</span><a href="#42891860">parent</a><span>|</span><a href="#42892032">next</a><span>|</span><label class="collapse" for="c-42893723">[-]</label><label class="expand" for="c-42893723">[2 more]</label></div><br/><div class="children"><div class="content">We -- the people who live in front of a computer -- have been training ourselves to avoid noticing annoyances like captchas, advertising, and GDPR notices for quite a long time.<p>We find what appears to be the easiest combination &quot;Fuck off, go away&quot; buttons and use them without a moment of actual consideration.<p>(This doesn&#x27;t mean that it&#x27;s actually the easiest method.)</div><br/><div id="42895541" class="c"><input type="checkbox" id="c-42895541" checked=""/><div class="controls bullet"><span class="by">grahamj</span><span>|</span><a href="#42891294">root</a><span>|</span><a href="#42893723">parent</a><span>|</span><a href="#42892032">next</a><span>|</span><label class="collapse" for="c-42895541">[-]</label><label class="expand" for="c-42895541">[1 more]</label></div><br/><div class="children"><div class="content">I can&#x27;t even believe how many times in a day I frustratedly think &quot;whatever, go away!&quot;</div><br/></div></div></div></div><div id="42892032" class="c"><input type="checkbox" id="c-42892032" checked=""/><div class="controls bullet"><span class="by">rubyn00bie</span><span>|</span><a href="#42891294">root</a><span>|</span><a href="#42891860">parent</a><span>|</span><a href="#42893723">prev</a><span>|</span><a href="#42893866">next</a><span>|</span><label class="collapse" for="c-42892032">[-]</label><label class="expand" for="c-42892032">[1 more]</label></div><br/><div class="children"><div class="content">I think it’s somewhat natural and am not personally surprised. It’s easy to quickly select an option, that has no consequence, compared to actively considering that not selecting something is an option. Not selecting something feels more like actively participating than just checking a box and moving on. &#x2F;shrug</div><br/></div></div></div></div><div id="42893866" class="c"><input type="checkbox" id="c-42893866" checked=""/><div class="controls bullet"><span class="by">losteric</span><span>|</span><a href="#42891294">root</a><span>|</span><a href="#42891766">parent</a><span>|</span><a href="#42891860">prev</a><span>|</span><a href="#42892589">next</a><span>|</span><label class="collapse" for="c-42893866">[-]</label><label class="expand" for="c-42893866">[1 more]</label></div><br/><div class="children"><div class="content">That’s fine. Your random click would be balanced by someone else randomly clicking</div><br/></div></div><div id="42892589" class="c"><input type="checkbox" id="c-42892589" checked=""/><div class="controls bullet"><span class="by">apparent</span><span>|</span><a href="#42891294">root</a><span>|</span><a href="#42891766">parent</a><span>|</span><a href="#42893866">prev</a><span>|</span><a href="#42894188">next</a><span>|</span><label class="collapse" for="c-42892589">[-]</label><label class="expand" for="c-42892589">[1 more]</label></div><br/><div class="children"><div class="content">I wonder if they down-weight responses that come in too fast to be meaningful, or without sufficient scrolling.</div><br/></div></div></div></div><div id="42894188" class="c"><input type="checkbox" id="c-42894188" checked=""/><div class="controls bullet"><span class="by">energy123</span><span>|</span><a href="#42891294">parent</a><span>|</span><a href="#42891766">prev</a><span>|</span><a href="#42893650">next</a><span>|</span><label class="collapse" for="c-42894188">[-]</label><label class="expand" for="c-42894188">[1 more]</label></div><br/><div class="children"><div class="content">Then 56% is even more impressive. Example: if 80% choose randomly and 20% choose carefully, that implies an 80% preference rate for o3-mini (0.8*0.2 + 0.5*0.8 = 0.56)</div><br/></div></div><div id="42893650" class="c"><input type="checkbox" id="c-42893650" checked=""/><div class="controls bullet"><span class="by">directevolve</span><span>|</span><a href="#42891294">parent</a><span>|</span><a href="#42894188">prev</a><span>|</span><a href="#42891521">next</a><span>|</span><label class="collapse" for="c-42893650">[-]</label><label class="expand" for="c-42893650">[1 more]</label></div><br/><div class="children"><div class="content">Also, it&#x27;s not clear if the preference comes from the quality of the &#x27;meat&#x27; of the answer, or the way it reports its thinking and the speed with which it responds. With o1, I get a marked feeling of impatience waiting for it to spit something out, and the &#x27;progress of thought&#x27; is in faint grey text I can&#x27;t read. With o3, the &#x27;progress of thought&#x27; comes quickly, with more to read, and is more engaging even if I don&#x27;t actually get anything more than entertainment value.<p>I&#x27;m not going to say there&#x27;s nothing substantive about o3 vs. o1, but I absolutely do not put it past Sam Altman to juice the stats every chance he gets.</div><br/></div></div><div id="42891521" class="c"><input type="checkbox" id="c-42891521" checked=""/><div class="controls bullet"><span class="by">jackbrookes</span><span>|</span><a href="#42891294">parent</a><span>|</span><a href="#42893650">prev</a><span>|</span><a href="#42891557">next</a><span>|</span><label class="collapse" for="c-42891521">[-]</label><label class="expand" for="c-42891521">[4 more]</label></div><br/><div class="children"><div class="content">Yes I&#x27;d bet most users just 50&#x2F;50 it, which actually makes it more remarkable that there was a 56% selection rate</div><br/><div id="42891550" class="c"><input type="checkbox" id="c-42891550" checked=""/><div class="controls bullet"><span class="by">cgriswald</span><span>|</span><a href="#42891294">root</a><span>|</span><a href="#42891521">parent</a><span>|</span><a href="#42891557">next</a><span>|</span><label class="collapse" for="c-42891550">[-]</label><label class="expand" for="c-42891550">[3 more]</label></div><br/><div class="children"><div class="content">I read the one on the left but choose the shorter one.<p>The interface wastes so much screen real estate already and the answers are usually overly verbose unless I&#x27;ve given explicit instructions on how to answer.</div><br/><div id="42892023" class="c"><input type="checkbox" id="c-42892023" checked=""/><div class="controls bullet"><span class="by">ljm</span><span>|</span><a href="#42891294">root</a><span>|</span><a href="#42891550">parent</a><span>|</span><a href="#42891557">next</a><span>|</span><label class="collapse" for="c-42892023">[-]</label><label class="expand" for="c-42892023">[2 more]</label></div><br/><div class="children"><div class="content">The default level of verbosity you get without explicitly prompting for it to be succinct makes me think there’s an office full of workers getting paid by the token.</div><br/><div id="42892660" class="c"><input type="checkbox" id="c-42892660" checked=""/><div class="controls bullet"><span class="by">internetter</span><span>|</span><a href="#42891294">root</a><span>|</span><a href="#42892023">parent</a><span>|</span><a href="#42891557">next</a><span>|</span><label class="collapse" for="c-42892660">[-]</label><label class="expand" for="c-42892660">[1 more]</label></div><br/><div class="children"><div class="content">In my experience the verbosity significantly improves output quality</div><br/></div></div></div></div></div></div></div></div><div id="42891557" class="c"><input type="checkbox" id="c-42891557" checked=""/><div class="controls bullet"><span class="by">johnneville</span><span>|</span><a href="#42891294">parent</a><span>|</span><a href="#42891521">prev</a><span>|</span><a href="#42893399">next</a><span>|</span><label class="collapse" for="c-42891557">[-]</label><label class="expand" for="c-42891557">[1 more]</label></div><br/><div class="children"><div class="content">they also pay contractors to do these evaluations with much more detailed metrics, no idea which their number is based on though</div><br/></div></div><div id="42893399" class="c"><input type="checkbox" id="c-42893399" checked=""/><div class="controls bullet"><span class="by">ricardobeat</span><span>|</span><a href="#42891294">parent</a><span>|</span><a href="#42891557">prev</a><span>|</span><a href="#42891656">next</a><span>|</span><label class="collapse" for="c-42893399">[-]</label><label class="expand" for="c-42893399">[3 more]</label></div><br/><div class="children"><div class="content">This is just a way to prove, statistically, that one model is better than another as part of its validation. It&#x27;s not collected from normal people using ChatGPT, you don&#x27;t ever get shown two responses from different models at once.</div><br/><div id="42893421" class="c"><input type="checkbox" id="c-42893421" checked=""/><div class="controls bullet"><span class="by">yawnxyz</span><span>|</span><a href="#42891294">root</a><span>|</span><a href="#42893399">parent</a><span>|</span><a href="#42891656">next</a><span>|</span><label class="collapse" for="c-42893421">[-]</label><label class="expand" for="c-42893421">[2 more]</label></div><br/><div class="children"><div class="content">Wait what? I get shown this with ChatGPT maybe 5% of the time</div><br/><div id="42895625" class="c"><input type="checkbox" id="c-42895625" checked=""/><div class="controls bullet"><span class="by">nearbuy</span><span>|</span><a href="#42891294">root</a><span>|</span><a href="#42893421">parent</a><span>|</span><a href="#42891656">next</a><span>|</span><label class="collapse" for="c-42895625">[-]</label><label class="expand" for="c-42895625">[1 more]</label></div><br/><div class="children"><div class="content">Those are both responses from the same model. It&#x27;s not one response from o1 and another from o3.</div><br/></div></div></div></div></div></div><div id="42891656" class="c"><input type="checkbox" id="c-42891656" checked=""/><div class="controls bullet"><span class="by">mikeInAlaska</span><span>|</span><a href="#42891294">parent</a><span>|</span><a href="#42893399">prev</a><span>|</span><a href="#42894603">next</a><span>|</span><label class="collapse" for="c-42891656">[-]</label><label class="expand" for="c-42891656">[1 more]</label></div><br/><div class="children"><div class="content">Maybe we should take both answers, paste them into a new chat and ask for a summary amalgamation of them</div><br/></div></div><div id="42894603" class="c"><input type="checkbox" id="c-42894603" checked=""/><div class="controls bullet"><span class="by">shombaboor</span><span>|</span><a href="#42891294">parent</a><span>|</span><a href="#42891656">prev</a><span>|</span><a href="#42891961">next</a><span>|</span><label class="collapse" for="c-42894603">[-]</label><label class="expand" for="c-42894603">[1 more]</label></div><br/><div class="children"><div class="content">It seems like the the first response must get chosen a majority of the time just to account for friction</div><br/></div></div><div id="42891961" class="c"><input type="checkbox" id="c-42891961" checked=""/><div class="controls bullet"><span class="by">arijo</span><span>|</span><a href="#42891294">parent</a><span>|</span><a href="#42894603">prev</a><span>|</span><a href="#42891551">next</a><span>|</span><label class="collapse" for="c-42891961">[-]</label><label class="expand" for="c-42891961">[4 more]</label></div><br/><div class="children"><div class="content">People could be flipping a coin and the score would be the same.</div><br/><div id="42892642" class="c"><input type="checkbox" id="c-42892642" checked=""/><div class="controls bullet"><span class="by">brianstrimp</span><span>|</span><a href="#42891294">root</a><span>|</span><a href="#42891961">parent</a><span>|</span><a href="#42891551">next</a><span>|</span><label class="collapse" for="c-42892642">[-]</label><label class="expand" for="c-42892642">[3 more]</label></div><br/><div class="children"><div class="content">A 12% margin is literally the opposite of a coin flip. Unless you have a really bad coin.</div><br/><div id="42893135" class="c"><input type="checkbox" id="c-42893135" checked=""/><div class="controls bullet"><span class="by">buggy6257</span><span>|</span><a href="#42891294">root</a><span>|</span><a href="#42892642">parent</a><span>|</span><a href="#42891551">next</a><span>|</span><label class="collapse" for="c-42893135">[-]</label><label class="expand" for="c-42893135">[2 more]</label></div><br/><div class="children"><div class="content">You&#x27;re being downvoted for 3 reasons:<p>1) Coming off as a jerk, and from a new account is a bad look<p>2) &quot;Literally the opposite of a coin flip&quot; would probably be either 0% or 100%<p>3) Your reasoning doesn&#x27;t stand up without further info; it entirely depends on the sample size.  I could have 5 coin flips all come up heads, but over thousands or millions it averages to 50%.  56% on a small sample size is absolutely within margin of error&#x2F;noise.  56% on a MASSIVE sample size is _statistically_ significant, but isn&#x27;t even still that much to brag about for something that I feel like they probably intended to be a big step forward.</div><br/><div id="42896287" class="c"><input type="checkbox" id="c-42896287" checked=""/><div class="controls bullet"><span class="by">brianstrimp</span><span>|</span><a href="#42891294">root</a><span>|</span><a href="#42893135">parent</a><span>|</span><a href="#42891551">next</a><span>|</span><label class="collapse" for="c-42896287">[-]</label><label class="expand" for="c-42896287">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m a little puzzled by your response.<p>1. The message was net-upvoted. Whether there are downvotes in there I can&#x27;t tell, but the final karma is positive. A similarly spirited message of mine in the same thread was quite well receive as well.<p>2. I can&#x27;t see how my message would come across as a jerk? I wrote 2 simple sentences, not using any offensive language, stating a mere fact of statistics. Is that being jerk? And a long-winded berating of a new member of the community isn&#x27;t?<p>3. A coin flip is 50%. Anything else is not, once you have a certain sample size. So, this was not. That was my statement. I don&#x27;t know why you are building a strawman of 5 coin flips. 56% vs 44% is a margin of 12%, as I stated, and with a huge sample size, which they had, that&#x27;s <i>massive</i> in a space where the returns are deep in &quot;diminishing&quot; territory.</div><br/></div></div></div></div></div></div></div></div><div id="42893371" class="c"><input type="checkbox" id="c-42893371" checked=""/><div class="controls bullet"><span class="by">gcanyon</span><span>|</span><a href="#42891294">parent</a><span>|</span><a href="#42891551">prev</a><span>|</span><a href="#42892060">next</a><span>|</span><label class="collapse" for="c-42893371">[-]</label><label class="expand" for="c-42893371">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think they make it clear: I wonder if they mean testers prefer o3 mini 56% of the time <i>when they express an opinion</i>, or overall? Some percentage of people don&#x27;t choose; if that number is 10% and they aren&#x27;t excluded, that means 56% of the time people prefer o3 mini, 34% of the time people prefer o1 mini, and 10% of the time people don&#x27;t choose. I&#x27;m not sure I think it would be reasonable to present the data that way, but it seems possible.</div><br/></div></div><div id="42892060" class="c"><input type="checkbox" id="c-42892060" checked=""/><div class="controls bullet"><span class="by">teeray</span><span>|</span><a href="#42891294">parent</a><span>|</span><a href="#42893371">prev</a><span>|</span><a href="#42891772">next</a><span>|</span><label class="collapse" for="c-42892060">[-]</label><label class="expand" for="c-42892060">[2 more]</label></div><br/><div class="children"><div class="content">This prompt is like &quot;See Attendant&quot; on the gas pump. I&#x27;m just going to use another AI instead for this chat.</div><br/><div id="42893613" class="c"><input type="checkbox" id="c-42893613" checked=""/><div class="controls bullet"><span class="by">ninkendo</span><span>|</span><a href="#42891294">root</a><span>|</span><a href="#42892060">parent</a><span>|</span><a href="#42891772">next</a><span>|</span><label class="collapse" for="c-42893613">[-]</label><label class="expand" for="c-42893613">[1 more]</label></div><br/><div class="children"><div class="content">Glad to know I’m not the only person who just drives to the next station when I see a “see attendant” message.</div><br/></div></div></div></div><div id="42891772" class="c"><input type="checkbox" id="c-42891772" checked=""/><div class="controls bullet"><span class="by">danilocesar</span><span>|</span><a href="#42891294">parent</a><span>|</span><a href="#42892060">prev</a><span>|</span><a href="#42892327">next</a><span>|</span><label class="collapse" for="c-42891772">[-]</label><label class="expand" for="c-42891772">[1 more]</label></div><br/><div class="children"><div class="content">I almost always pick the second one, because it&#x27;s closer to the submit button and the one I read first.</div><br/></div></div><div id="42892327" class="c"><input type="checkbox" id="c-42892327" checked=""/><div class="controls bullet"><span class="by">resters</span><span>|</span><a href="#42891294">parent</a><span>|</span><a href="#42891772">prev</a><span>|</span><a href="#42891487">next</a><span>|</span><label class="collapse" for="c-42892327">[-]</label><label class="expand" for="c-42892327">[1 more]</label></div><br/><div class="children"><div class="content">I too have questioned the approach of showing the long side-by-side answers from two different models.<p>1) sometimes I wanted the short answer, and so even though the long answer is better I picked the short one.<p>2) sometimes both contain code that is different enough that I am inclined to go with the one that is more similar to what I already had, even if the other approach seems a bit more solid.<p>3) Sometimes one will have less detail but more big picture awareness and the other will have excellent detail but miss some overarching point that is valuable.  Depending on my mood I sometimes choose but it is annoying to have to do so because I am not allowed to say why I made the choice.<p>The area of human training methodology seems to be a big part of what got Deepseek&#x27;s model so strong.  I read the explanation of the test results as an acknowledgement by OpenAI of some weaknesses in its human feedback paradigm.<p>IMO the way it should work is that the thumbs up or down should be read in context by a reasoning being and a more in-depth training case should be developed that helps future models learn whatever insight the feedback should have triggered.<p>Feedback that A is better or worse than B is definitely not (in my view) sufficient except in cases where a response is a total dud. Usually the responses have different strengths and weaknesses and it&#x27;s pretty subjective which one is better.</div><br/></div></div><div id="42891487" class="c"><input type="checkbox" id="c-42891487" checked=""/><div class="controls bullet"><span class="by">danielmarkbruce</span><span>|</span><a href="#42891294">parent</a><span>|</span><a href="#42892327">prev</a><span>|</span><a href="#42891605">next</a><span>|</span><label class="collapse" for="c-42891487">[-]</label><label class="expand" for="c-42891487">[1 more]</label></div><br/><div class="children"><div class="content">RLUHF,  U = useless.</div><br/></div></div></div></div><div id="42891605" class="c"><input type="checkbox" id="c-42891605" checked=""/><div class="controls bullet"><span class="by">scarface_74</span><span>|</span><a href="#42891294">prev</a><span>|</span><a href="#42890845">next</a><span>|</span><label class="collapse" for="c-42891605">[-]</label><label class="expand" for="c-42891605">[7 more]</label></div><br/><div class="children"><div class="content">This took 1:53 in o3-mini<p><a href="https:&#x2F;&#x2F;chatgpt.com&#x2F;share&#x2F;679d310d-6064-8010-ba78-6bd5ed3360d3" rel="nofollow">https:&#x2F;&#x2F;chatgpt.com&#x2F;share&#x2F;679d310d-6064-8010-ba78-6bd5ed3360...</a><p>The 4o model without using the Python tool<p><a href="https:&#x2F;&#x2F;chatgpt.com&#x2F;share&#x2F;679d32bd-9ba8-8010-8f75-2f26a792e0d3" rel="nofollow">https:&#x2F;&#x2F;chatgpt.com&#x2F;share&#x2F;679d32bd-9ba8-8010-8f75-2f26a792e0...</a><p>Trying to get accurate results with the paid version of 4o with the Python interpreter.<p><a href="https:&#x2F;&#x2F;chatgpt.com&#x2F;share&#x2F;679d31f3-21d4-8010-9932-7ecadd0b870f" rel="nofollow">https:&#x2F;&#x2F;chatgpt.com&#x2F;share&#x2F;679d31f3-21d4-8010-9932-7ecadd0b87...</a><p>The share link doesn’t show the output for some reason.  But it did work correctly.   I don’t know whether the ages are correct.  I was testing whether it could handle ordering<p>I have no idea what conclusion I should draw from this besides depending on the use case, 4o may be better with “tools” if you know your domain where you are using it.<p>Tools are relatively easy to implement with LangChain or the native OpenAI SDK.</div><br/><div id="42891776" class="c"><input type="checkbox" id="c-42891776" checked=""/><div class="controls bullet"><span class="by">BeetleB</span><span>|</span><a href="#42891605">parent</a><span>|</span><a href="#42891691">next</a><span>|</span><label class="collapse" for="c-42891776">[-]</label><label class="expand" for="c-42891776">[4 more]</label></div><br/><div class="children"><div class="content">I would not expect any LLM to get this right. I think people have too high expectations for it.<p>Now if you asked it to write a Python program to list them in order, and have it enter all the names, birthdays, and year elected in a list to get the program to run - that&#x27;s more reasonable.</div><br/><div id="42891913" class="c"><input type="checkbox" id="c-42891913" checked=""/><div class="controls bullet"><span class="by">scarface_74</span><span>|</span><a href="#42891605">root</a><span>|</span><a href="#42891776">parent</a><span>|</span><a href="#42891691">next</a><span>|</span><label class="collapse" for="c-42891913">[-]</label><label class="expand" for="c-42891913">[3 more]</label></div><br/><div class="children"><div class="content">The “o” models get the order right.<p>DeepSeek also gets the order right.<p>It doesn’t show on the share link.  But it actually outputs the list correctly from the built in Python interpreter.<p>For some things, ChatGPT 4o will automatically use its Python runtime</div><br/><div id="42892851" class="c"><input type="checkbox" id="c-42892851" checked=""/><div class="controls bullet"><span class="by">BeetleB</span><span>|</span><a href="#42891605">root</a><span>|</span><a href="#42891913">parent</a><span>|</span><a href="#42891691">next</a><span>|</span><label class="collapse" for="c-42892851">[-]</label><label class="expand" for="c-42892851">[2 more]</label></div><br/><div class="children"><div class="content">That some models get it right is irrelevant. In general, if your instructions require <i>computation</i>, it&#x27;s safer to assume it won&#x27;t get it right and will hallucinate.</div><br/><div id="42893428" class="c"><input type="checkbox" id="c-42893428" checked=""/><div class="controls bullet"><span class="by">scarface_74</span><span>|</span><a href="#42891605">root</a><span>|</span><a href="#42892851">parent</a><span>|</span><a href="#42891691">next</a><span>|</span><label class="collapse" for="c-42893428">[-]</label><label class="expand" for="c-42893428">[1 more]</label></div><br/><div class="children"><div class="content">The reasoning models all do pretty good at math.<p>Have you tried them?<p>This is something I threw together with o3-mini<p><a href="https:&#x2F;&#x2F;chatgpt.com&#x2F;share&#x2F;679d5305-5f04-8010-b5c4-61c31e79b248" rel="nofollow">https:&#x2F;&#x2F;chatgpt.com&#x2F;share&#x2F;679d5305-5f04-8010-b5c4-61c31e79b2...</a><p>ChatGPT 4o doesn’t even try to do the math internally and uses its built in Python interpreter.  (The [_&gt;] link is to the Python code)<p><a href="https:&#x2F;&#x2F;chatgpt.com&#x2F;share&#x2F;679d54fe-0104-8010-8f1e-9796a08cf930" rel="nofollow">https:&#x2F;&#x2F;chatgpt.com&#x2F;share&#x2F;679d54fe-0104-8010-8f1e-9796a08cf9...</a><p>DeepSeek handles the same problem just as well using the reasoning technique.<p>Of course ChatGPT 4o went completely off the rails without using its Python interpreter<p><a href="https:&#x2F;&#x2F;chatgpt.com&#x2F;share&#x2F;679d5692-96a0-8010-8624-b1eb091270cb" rel="nofollow">https:&#x2F;&#x2F;chatgpt.com&#x2F;share&#x2F;679d5692-96a0-8010-8624-b1eb091270...</a><p>(The break down that it got right was using Python even though I told it not to)</div><br/></div></div></div></div></div></div></div></div><div id="42891691" class="c"><input type="checkbox" id="c-42891691" checked=""/><div class="controls bullet"><span class="by">margalabargala</span><span>|</span><a href="#42891605">parent</a><span>|</span><a href="#42891776">prev</a><span>|</span><a href="#42890845">next</a><span>|</span><label class="collapse" for="c-42891691">[-]</label><label class="expand" for="c-42891691">[2 more]</label></div><br/><div class="children"><div class="content">The 4o model&#x27;s output is blatantly wrong. I&#x27;m not going to look up if it&#x27;s the order or the ages that are incorrect, but:<p>36. Abraham Lincoln – 52 years, 20 days (1861)<p>37. James Garfield – 49 years, 105 days (1881)<p>38. Lyndon B. Johnson – 55 years, 87 days (1963)<p>Basically everything after #15 in the list is scrambled.</div><br/><div id="42891876" class="c"><input type="checkbox" id="c-42891876" checked=""/><div class="controls bullet"><span class="by">scarface_74</span><span>|</span><a href="#42891605">root</a><span>|</span><a href="#42891691">parent</a><span>|</span><a href="#42890845">next</a><span>|</span><label class="collapse" for="c-42891876">[-]</label><label class="expand" for="c-42891876">[1 more]</label></div><br/><div class="children"><div class="content">That was the point. The 4o model without using Python was wrong.  The o3 model worked correctly without needing an external tool</div><br/></div></div></div></div></div></div><div id="42890845" class="c"><input type="checkbox" id="c-42890845" checked=""/><div class="controls bullet"><span class="by">kumarm</span><span>|</span><a href="#42891605">prev</a><span>|</span><a href="#42890785">next</a><span>|</span><label class="collapse" for="c-42890845">[-]</label><label class="expand" for="c-42890845">[3 more]</label></div><br/><div class="children"><div class="content">I ran some quick programming tasks I have used O1 previously:<p>1. 1&#x2F;4th time for reasoning for most tasks.<p>2. Far better results.</div><br/><div id="42891329" class="c"><input type="checkbox" id="c-42891329" checked=""/><div class="controls bullet"><span class="by">CamperBob2</span><span>|</span><a href="#42890845">parent</a><span>|</span><a href="#42890785">next</a><span>|</span><label class="collapse" for="c-42891329">[-]</label><label class="expand" for="c-42891329">[2 more]</label></div><br/><div class="children"><div class="content">Compared to o1 or o1-pro?</div><br/><div id="42891899" class="c"><input type="checkbox" id="c-42891899" checked=""/><div class="controls bullet"><span class="by">yzydserd</span><span>|</span><a href="#42890845">root</a><span>|</span><a href="#42891329">parent</a><span>|</span><a href="#42890785">next</a><span>|</span><label class="collapse" for="c-42891899">[-]</label><label class="expand" for="c-42891899">[1 more]</label></div><br/><div class="children"><div class="content">A few quick tasks look to me like o3-mini-high is 4-10x faster for 80% of the quality. It gives very good and sufficient fast reasoning about coding tasks, but I think I&#x27;d ask o1-pro to do the task ie provide the code. o3-mini-high can keep up with you at thinking &#x2F; typing speed, whereas o1-pro can take several minutes. Just a quick view after playing for an hour.</div><br/></div></div></div></div></div></div><div id="42890785" class="c"><input type="checkbox" id="c-42890785" checked=""/><div class="controls bullet"><span class="by">highfrequency</span><span>|</span><a href="#42890845">prev</a><span>|</span><a href="#42893868">next</a><span>|</span><label class="collapse" for="c-42890785">[-]</label><label class="expand" for="c-42890785">[4 more]</label></div><br/><div class="children"><div class="content">Anyone else confused by inconsistency in performance numbers between this announcement and the concurrent system card? <a href="https:&#x2F;&#x2F;cdn.openai.com&#x2F;o3-mini-system-card.pdf" rel="nofollow">https:&#x2F;&#x2F;cdn.openai.com&#x2F;o3-mini-system-card.pdf</a><p>For example-<p>GPQA diamond system card: o1-preview 0.68<p>GPQA diamond PR release: o1-preview 0.78<p>Also, how should we interpret the 3 different shading colors in the barplots (white, dotted, heavy dotted on top of white)...</div><br/><div id="42890890" class="c"><input type="checkbox" id="c-42890890" checked=""/><div class="controls bullet"><span class="by">kkzz99</span><span>|</span><a href="#42890785">parent</a><span>|</span><a href="#42890876">next</a><span>|</span><label class="collapse" for="c-42890890">[-]</label><label class="expand" for="c-42890890">[2 more]</label></div><br/><div class="children"><div class="content">Actually sounds like benchslop to me.</div><br/></div></div></div></div><div id="42893868" class="c"><input type="checkbox" id="c-42893868" checked=""/><div class="controls bullet"><span class="by">mvkel</span><span>|</span><a href="#42890785">prev</a><span>|</span><a href="#42891991">next</a><span>|</span><label class="collapse" for="c-42893868">[-]</label><label class="expand" for="c-42893868">[73 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve been using cursor since it launched, sticking almost exclusively to claude-3.5-sonnet because it is incredibly consistent, and rarely loses the plot.<p>As subsequent models have been released, most of which claim to be better at coding, I&#x27;ve switched cursor to it to give them a try.<p>o1, o1-pro, deepseek-r1, and the now o3-mini. All of these models suffer from the exact same &quot;adhd.&quot; As an example, in a NextJS app, if I do a composer prompt like &quot;on page.tsx [15 LOC], using shadcn components wherever possible, update this page to have a better visual hierarchy.&quot;<p>sonnet nails it almost perfectly every time, but suffers from some date cutoff issues like thinking that shadcn-ui@latest is the repo name.<p>Every single other model, doesn&#x27;t matter which, does the following: it starts writing (from scratch), radix-ui components. I will interrupt it and say &quot;DO NOT use radix-ui, use shadcn!&quot; -- it will respond with &quot;ok!&quot; then begin writing its own components from scratch, again not using shadcn.<p>This is still problematic with o3-mini.<p>I can&#x27;t believe it&#x27;s the models. It must be the instruction-set that cursor is giving it behind the scenes, right? No amount of .cursorrules, or other instruction, seems to get cursor &quot;locked in&quot; the way sonnet just seems to be naturally.<p>It sucks being stuck on the (now ancient) sonnet, but inexplicably, it remains the only viable coding option for me.<p>Has anyone found a workaround?</div><br/><div id="42894031" class="c"><input type="checkbox" id="c-42894031" checked=""/><div class="controls bullet"><span class="by">kace91</span><span>|</span><a href="#42893868">parent</a><span>|</span><a href="#42896162">next</a><span>|</span><label class="collapse" for="c-42894031">[-]</label><label class="expand" for="c-42894031">[17 more]</label></div><br/><div class="children"><div class="content">My experience with cursor and sonnet is that it is relatively good at first tries, but completely misses the plot during corrections.<p>&quot;My attempt at solving the problem contains a test that fails? No problem, let me mock the function I&#x27;m testing, so that, rather than actually run, it returns the expected value!&quot;<p>It keeps doing that kind of shenanigans, applying modifications that solve the newly appearing problem while screwing the original attempt&#x27;s goal.<p>I usually get much better results from regular chatgpt copying and pasting, the trouble being that it is a major pain to handle the context window manually by pasting relevant info and reminding what I think is being forgotten.</div><br/><div id="42894688" class="c"><input type="checkbox" id="c-42894688" checked=""/><div class="controls bullet"><span class="by">delichon</span><span>|</span><a href="#42893868">root</a><span>|</span><a href="#42894031">parent</a><span>|</span><a href="#42896065">next</a><span>|</span><label class="collapse" for="c-42894688">[-]</label><label class="expand" for="c-42894688">[3 more]</label></div><br/><div class="children"><div class="content">Claude makes a lot of crappy change suggestions, but when you ask &quot;is that a good suggestion?&quot; it&#x27;s pretty good at judging when it isn&#x27;t. So that&#x27;s become standard operating procedure for me.<p>It&#x27;s difficult to avoid Claude&#x27;s strong bias for being agreeable. It needs more HAL 9000.</div><br/><div id="42895032" class="c"><input type="checkbox" id="c-42895032" checked=""/><div class="controls bullet"><span class="by">4b11b4</span><span>|</span><a href="#42893868">root</a><span>|</span><a href="#42894688">parent</a><span>|</span><a href="#42895309">next</a><span>|</span><label class="collapse" for="c-42895032">[-]</label><label class="expand" for="c-42895032">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m always asking Claude to propose a variety of suggestions for the problem at hand and their trade-offs, then evaluating them for the top three proposals and why. Then I&#x27;ll pick one of them and further vet the idea</div><br/></div></div><div id="42895309" class="c"><input type="checkbox" id="c-42895309" checked=""/><div class="controls bullet"><span class="by">esperent</span><span>|</span><a href="#42893868">root</a><span>|</span><a href="#42894688">parent</a><span>|</span><a href="#42895032">prev</a><span>|</span><a href="#42896065">next</a><span>|</span><label class="collapse" for="c-42895309">[-]</label><label class="expand" for="c-42895309">[1 more]</label></div><br/><div class="children"><div class="content">&gt; when you ask &quot;is that a good suggestion?&quot; it&#x27;s pretty good at judging when it isn&#x27;t<p>Basically a poor man&#x27;s COT.</div><br/></div></div></div></div><div id="42896065" class="c"><input type="checkbox" id="c-42896065" checked=""/><div class="controls bullet"><span class="by">sheepscreek</span><span>|</span><a href="#42893868">root</a><span>|</span><a href="#42894031">parent</a><span>|</span><a href="#42894688">prev</a><span>|</span><a href="#42894082">next</a><span>|</span><label class="collapse" for="c-42896065">[-]</label><label class="expand" for="c-42896065">[2 more]</label></div><br/><div class="children"><div class="content">For my advanced use case involving Python and knowledge of finance, Sonnet fared poorly. Contrary to what I am reading here, my favorite approach has been to use o1 in agent mode. It’s an absolute delight to work with. It is like I’m working with a capable peer, someone at my level.<p>Sadly there are some hard limits on o1 with Cursor and I cannot use it anymore. I do pay for their $20&#x2F;month subscription.</div><br/><div id="42896363" class="c"><input type="checkbox" id="c-42896363" checked=""/><div class="controls bullet"><span class="by">electroly</span><span>|</span><a href="#42893868">root</a><span>|</span><a href="#42896065">parent</a><span>|</span><a href="#42894082">next</a><span>|</span><label class="collapse" for="c-42896363">[-]</label><label class="expand" for="c-42896363">[1 more]</label></div><br/><div class="children"><div class="content">&gt; o1 in agent mode<p>How? It specifically tells me this is unsupported: &quot;Agent composer is currently only supported using Anthropic models or GPT-4o, please reselect the model and try again.&quot;</div><br/></div></div></div></div><div id="42894082" class="c"><input type="checkbox" id="c-42894082" checked=""/><div class="controls bullet"><span class="by">jwpapi</span><span>|</span><a href="#42893868">root</a><span>|</span><a href="#42894031">parent</a><span>|</span><a href="#42896065">prev</a><span>|</span><a href="#42895351">next</a><span>|</span><label class="collapse" for="c-42894082">[-]</label><label class="expand" for="c-42894082">[6 more]</label></div><br/><div class="children"><div class="content">Yes it’s usually worth it to try to write a really good first prompt</div><br/><div id="42894693" class="c"><input type="checkbox" id="c-42894693" checked=""/><div class="controls bullet"><span class="by">earleybird</span><span>|</span><a href="#42893868">root</a><span>|</span><a href="#42894082">parent</a><span>|</span><a href="#42895351">next</a><span>|</span><label class="collapse" for="c-42894693">[-]</label><label class="expand" for="c-42894693">[5 more]</label></div><br/><div class="children"><div class="content">More than once I&#x27;ve found myself going down this &#x27;little maze of twisty passages, all alike&#x27;.  At some point I stop, collect up the chain of prompts in the conversation, and curate them into a net new prompt that should be a bit better.  Usually I make better progress - at least for a while.</div><br/><div id="42895756" class="c"><input type="checkbox" id="c-42895756" checked=""/><div class="controls bullet"><span class="by">SamPatt</span><span>|</span><a href="#42893868">root</a><span>|</span><a href="#42894693">parent</a><span>|</span><a href="#42894745">next</a><span>|</span><label class="collapse" for="c-42895756">[-]</label><label class="expand" for="c-42895756">[1 more]</label></div><br/><div class="children"><div class="content">This becomes second nature after a while. I&#x27;ve developed an intuition about when a model loses the plot and when to start a new thread. I have a base prompt I keep for the current project I&#x27;m working on, and then I ask the model to summarize what we&#x27;ve done in the thread and combine them to start anew.<p>I can&#x27;t wait until this is a solved problem because it does slow me down.</div><br/></div></div><div id="42894745" class="c"><input type="checkbox" id="c-42894745" checked=""/><div class="controls bullet"><span class="by">dr_dshiv</span><span>|</span><a href="#42893868">root</a><span>|</span><a href="#42894693">parent</a><span>|</span><a href="#42895756">prev</a><span>|</span><a href="#42895351">next</a><span>|</span><label class="collapse" for="c-42894745">[-]</label><label class="expand" for="c-42894745">[3 more]</label></div><br/><div class="children"><div class="content">Why is it so hard to share&#x2F;find prompts or distill my own damn prompts? There must be good solutions for this —</div><br/><div id="42895474" class="c"><input type="checkbox" id="c-42895474" checked=""/><div class="controls bullet"><span class="by">garfij</span><span>|</span><a href="#42893868">root</a><span>|</span><a href="#42894745">parent</a><span>|</span><a href="#42895063">next</a><span>|</span><label class="collapse" for="c-42895474">[-]</label><label class="expand" for="c-42895474">[1 more]</label></div><br/><div class="children"><div class="content">What do you find difficult about distilling your own prompts?<p>After any back and forth session I have reasonably good results asking something like &quot;Given this workflow, how could I have prompted this better from the start to get the same results?&quot;</div><br/></div></div><div id="42895063" class="c"><input type="checkbox" id="c-42895063" checked=""/><div class="controls bullet"><span class="by">whall6</span><span>|</span><a href="#42893868">root</a><span>|</span><a href="#42894745">parent</a><span>|</span><a href="#42895474">prev</a><span>|</span><a href="#42895351">next</a><span>|</span><label class="collapse" for="c-42895063">[-]</label><label class="expand" for="c-42895063">[1 more]</label></div><br/><div class="children"><div class="content">Don’t outsource the only thing left for our brains to do themselves :&#x2F;</div><br/></div></div></div></div></div></div></div></div><div id="42895351" class="c"><input type="checkbox" id="c-42895351" checked=""/><div class="controls bullet"><span class="by">mathieuh</span><span>|</span><a href="#42893868">root</a><span>|</span><a href="#42894031">parent</a><span>|</span><a href="#42894082">prev</a><span>|</span><a href="#42894507">next</a><span>|</span><label class="collapse" for="c-42895351">[-]</label><label class="expand" for="c-42895351">[2 more]</label></div><br/><div class="children"><div class="content">Hah, I was trying it the other day in a Go project and it did exactly the same thing. I couldn’t believe my eyes, it basically rewrote all the functions back out in the test file but modified slightly so the thing that was failing wouldn’t even run.</div><br/><div id="42896470" class="c"><input type="checkbox" id="c-42896470" checked=""/><div class="controls bullet"><span class="by">nprateem</span><span>|</span><a href="#42893868">root</a><span>|</span><a href="#42895351">parent</a><span>|</span><a href="#42894507">next</a><span>|</span><label class="collapse" for="c-42896470">[-]</label><label class="expand" for="c-42896470">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve had it do similar nonsense.<p>I just don&#x27;t understand all the people who honestly believe AGI just requires more GPUs and data when these models are so inherently stupid.</div><br/></div></div></div></div><div id="42894507" class="c"><input type="checkbox" id="c-42894507" checked=""/><div class="controls bullet"><span class="by">hahajk</span><span>|</span><a href="#42893868">root</a><span>|</span><a href="#42894031">parent</a><span>|</span><a href="#42895351">prev</a><span>|</span><a href="#42896162">next</a><span>|</span><label class="collapse" for="c-42894507">[-]</label><label class="expand" for="c-42894507">[3 more]</label></div><br/><div class="children"><div class="content">Can&#x27;t you select Chatgpt as the model in cursor?</div><br/><div id="42895127" class="c"><input type="checkbox" id="c-42895127" checked=""/><div class="controls bullet"><span class="by">electroly</span><span>|</span><a href="#42893868">root</a><span>|</span><a href="#42894507">parent</a><span>|</span><a href="#42894565">next</a><span>|</span><label class="collapse" for="c-42895127">[-]</label><label class="expand" for="c-42895127">[1 more]</label></div><br/><div class="children"><div class="content">Yes but every model besides claude-3.5-sonnet sucks in Cursor, for whatever reason. They might as well not even offer the other models. The other models, even &quot;smarter&quot; models, perform vastly poorer or don&#x27;t support agent capability or both.</div><br/></div></div><div id="42894565" class="c"><input type="checkbox" id="c-42894565" checked=""/><div class="controls bullet"><span class="by">kace91</span><span>|</span><a href="#42893868">root</a><span>|</span><a href="#42894507">parent</a><span>|</span><a href="#42895127">prev</a><span>|</span><a href="#42896162">next</a><span>|</span><label class="collapse" for="c-42894565">[-]</label><label class="expand" for="c-42894565">[1 more]</label></div><br/><div class="children"><div class="content">Yes, but for some reason it seems to perform worse there.<p>Perhaps whatever algorithms Cursor uses to prepare the context it feeds the model are a good fit for Claude but not so much for the others (?). It&#x27;s a random guess, but whatever the reason, there&#x27;s a weird worsening of performance vs pure chat.</div><br/></div></div></div></div></div></div><div id="42896162" class="c"><input type="checkbox" id="c-42896162" checked=""/><div class="controls bullet"><span class="by">harshitaneja</span><span>|</span><a href="#42893868">parent</a><span>|</span><a href="#42894031">prev</a><span>|</span><a href="#42894879">next</a><span>|</span><label class="collapse" for="c-42896162">[-]</label><label class="expand" for="c-42896162">[2 more]</label></div><br/><div class="children"><div class="content">So I think I finally understood recently why we have these divergent groups with one thinking Claude 3.5 Sonnet is the best model for coding and another that follow the OpenAI SOTA at that moment. 
I have been a heavy user of ChatGPT, jumping on to pro without even thinking for more than a second once released. 
Recently though I took a pause from my usual work on statistical modelling, heuristics work and other things in certain deep domains to focus on building client APIs and frontends and decided to again give Claude a try and it is just so great to work with for this usecase.<p>My hypothesis is its a difference of what you are doing. OpenAI O models are much better than others at mathematical modelling and such tasks and Claude for more general purpose programming.</div><br/><div id="42896372" class="c"><input type="checkbox" id="c-42896372" checked=""/><div class="controls bullet"><span class="by">mycall</span><span>|</span><a href="#42893868">root</a><span>|</span><a href="#42896162">parent</a><span>|</span><a href="#42894879">next</a><span>|</span><label class="collapse" for="c-42896372">[-]</label><label class="expand" for="c-42896372">[1 more]</label></div><br/><div class="children"><div class="content">Have you used multi-agent chat sessions with each fielding their own specialities and seeing if that improves your use cases aka MoE?</div><br/></div></div></div></div><div id="42894879" class="c"><input type="checkbox" id="c-42894879" checked=""/><div class="controls bullet"><span class="by">chrismsimpson</span><span>|</span><a href="#42893868">parent</a><span>|</span><a href="#42896162">prev</a><span>|</span><a href="#42894283">next</a><span>|</span><label class="collapse" for="c-42894879">[-]</label><label class="expand" for="c-42894879">[7 more]</label></div><br/><div class="children"><div class="content">I’ve coded in many languages over the years but reasonably new to the TS&#x2F;JS&#x2F;Next world.<p>I’ve found if you give your prompts a kind long form “stream of consciousness”, where you outline snippets of code in markdown along with contextual notes and then summarise&#x2F;outline at the end what you actually wish to achieve, you can get great results.<p>Think a long form, single page “documentation” type prompts that alternate between written copy&#x2F;contextual intent&#x2F;description and code blocks. Annotating code blocks with file names above the blocks I’m sure helps too. Don’t waste your context window on redundant&#x2F;irrelevant information or code, stating a code sample is abridged or adding commented ellipses seems to do the job.</div><br/><div id="42895434" class="c"><input type="checkbox" id="c-42895434" checked=""/><div class="controls bullet"><span class="by">d357r0y3r</span><span>|</span><a href="#42893868">root</a><span>|</span><a href="#42894879">parent</a><span>|</span><a href="#42894905">next</a><span>|</span><label class="collapse" for="c-42895434">[-]</label><label class="expand" for="c-42895434">[4 more]</label></div><br/><div class="children"><div class="content">By the time I&#x27;ve fully documented and explained what I want to be done, and then review the result, usually finding that it&#x27;s worse than what I would have written myself, I end up questioning my instinct to even reach for this tool.<p>I like it for general refactoring and day to day small tasks, but anything that&#x27;s relatively domain-specific, I just can&#x27;t seem to get anything that&#x27;s worth using.</div><br/><div id="42895475" class="c"><input type="checkbox" id="c-42895475" checked=""/><div class="controls bullet"><span class="by">noahbp</span><span>|</span><a href="#42893868">root</a><span>|</span><a href="#42895434">parent</a><span>|</span><a href="#42894905">next</a><span>|</span><label class="collapse" for="c-42895475">[-]</label><label class="expand" for="c-42895475">[3 more]</label></div><br/><div class="children"><div class="content">Like most AI tools, great for beginners, time-savers for intermediate users, and frequently a waste of time in domains where you&#x27;re an expert.<p>I&#x27;ve used Cursor for shipping better frontend slop, and it&#x27;s great. I skip a lot of trial and error, but not all of it.</div><br/><div id="42896354" class="c"><input type="checkbox" id="c-42896354" checked=""/><div class="controls bullet"><span class="by">epolanski</span><span>|</span><a href="#42893868">root</a><span>|</span><a href="#42895475">parent</a><span>|</span><a href="#42895502">next</a><span>|</span><label class="collapse" for="c-42896354">[-]</label><label class="expand" for="c-42896354">[1 more]</label></div><br/><div class="children"><div class="content">,&gt; and frequently a waste of time in domains where you&#x27;re an expert.<p>I&#x27;m a domain expert and I disagree.<p>There&#x27;s many scenarios where using LLMs pays off.<p>E.g. a long file or very long function are just that, and an LLM is faster at understanding it whole not being limited in how many things you can track in your mind at once (between 4 and 6). It&#x27;s still gonna be faster at refactoring it and testing it than you will.</div><br/></div></div><div id="42895502" class="c"><input type="checkbox" id="c-42895502" checked=""/><div class="controls bullet"><span class="by">d357r0y3r</span><span>|</span><a href="#42893868">root</a><span>|</span><a href="#42895475">parent</a><span>|</span><a href="#42896354">prev</a><span>|</span><a href="#42894905">next</a><span>|</span><label class="collapse" for="c-42895502">[-]</label><label class="expand" for="c-42895502">[1 more]</label></div><br/><div class="children"><div class="content">I agree that it&#x27;s amazing as a learning tool. I think the &quot;time to ramp&quot; on a new technology or programming language has probably been cut in half or more.</div><br/></div></div></div></div></div></div><div id="42894905" class="c"><input type="checkbox" id="c-42894905" checked=""/><div class="controls bullet"><span class="by">twilightfringe</span><span>|</span><a href="#42893868">root</a><span>|</span><a href="#42894879">parent</a><span>|</span><a href="#42895434">prev</a><span>|</span><a href="#42895035">next</a><span>|</span><label class="collapse" for="c-42894905">[-]</label><label class="expand" for="c-42894905">[1 more]</label></div><br/><div class="children"><div class="content">ha! good to confirm! I tend to do this, just kind of as a double-check thing, but never sure if it actually worked or if it was a placebo, lol.<p>Or end with &quot;from the user&#x27;s perspective: all the &quot;B&quot; elements should light up in excitement when you click &quot;C&quot;&quot;</div><br/></div></div><div id="42895035" class="c"><input type="checkbox" id="c-42895035" checked=""/><div class="controls bullet"><span class="by">mvkel</span><span>|</span><a href="#42893868">root</a><span>|</span><a href="#42894879">parent</a><span>|</span><a href="#42894905">prev</a><span>|</span><a href="#42894283">next</a><span>|</span><label class="collapse" for="c-42895035">[-]</label><label class="expand" for="c-42895035">[1 more]</label></div><br/><div class="children"><div class="content">Going to try this! Thanks for the tip</div><br/></div></div></div></div><div id="42894283" class="c"><input type="checkbox" id="c-42894283" checked=""/><div class="controls bullet"><span class="by">MaxLeiter</span><span>|</span><a href="#42893868">parent</a><span>|</span><a href="#42894879">prev</a><span>|</span><a href="#42896303">next</a><span>|</span><label class="collapse" for="c-42894283">[-]</label><label class="expand" for="c-42894283">[2 more]</label></div><br/><div class="children"><div class="content">We&#x27;ve been working on solving a lot of these issues with v0.dev (disclaimer: shadcn and I work on it). We do a lot of pre and post-processing to ensure LLMs output valid shadcn code.<p>We&#x27;re also talking to the cursor&#x2F;windsurf&#x2F;zed folks on how we can improve Next.js and shadcn in the editors (maybe something like llms.txt?)</div><br/><div id="42894318" class="c"><input type="checkbox" id="c-42894318" checked=""/><div class="controls bullet"><span class="by">mvkel</span><span>|</span><a href="#42893868">root</a><span>|</span><a href="#42894283">parent</a><span>|</span><a href="#42896303">next</a><span>|</span><label class="collapse" for="c-42894318">[-]</label><label class="expand" for="c-42894318">[1 more]</label></div><br/><div class="children"><div class="content">Thanks for all the work you do! v0 is magical. I absolutely love the feature where I can add a chunky component that v0 made to my repo with npx</div><br/></div></div></div></div><div id="42896303" class="c"><input type="checkbox" id="c-42896303" checked=""/><div class="controls bullet"><span class="by">digitcatphd</span><span>|</span><a href="#42893868">parent</a><span>|</span><a href="#42894283">prev</a><span>|</span><a href="#42893927">next</a><span>|</span><label class="collapse" for="c-42896303">[-]</label><label class="expand" for="c-42896303">[2 more]</label></div><br/><div class="children"><div class="content">The reality is I suspect one will use different models for different things.
Think of it like having different modes of transportation.<p>You might use your scooter, bike, car, jet - depending on the circumstances.
A bike was invented 100 years ago? But it may be the best in the right use case. Would still be using DaVinci for some things because we haven&#x27;t bothered swapping it and it works fine.<p>For me - the value of R1&#x2F;o3 is visible logic that provides an analysis that can be critiqued by Sonnet 3.5</div><br/><div id="42896548" class="c"><input type="checkbox" id="c-42896548" checked=""/><div class="controls bullet"><span class="by">ido</span><span>|</span><a href="#42893868">root</a><span>|</span><a href="#42896303">parent</a><span>|</span><a href="#42893927">next</a><span>|</span><label class="collapse" for="c-42896548">[-]</label><label class="expand" for="c-42896548">[1 more]</label></div><br/><div class="children"><div class="content">I have an even more topical analogy! Using different languages for different tasks. When I need some one off script do automate some drudgery (take all files with certain pattern in their name, for each do some search and replace in the text inside, zip them, upload zip to URL, etc) I use python. When Im working on a multi-platform game I use c# (and unity). When I need to make something very lean that works in mobile browsers I use JS with some light-weight libraries.</div><br/></div></div></div></div><div id="42893927" class="c"><input type="checkbox" id="c-42893927" checked=""/><div class="controls bullet"><span class="by">zackproser</span><span>|</span><a href="#42893868">parent</a><span>|</span><a href="#42896303">prev</a><span>|</span><a href="#42896442">next</a><span>|</span><label class="collapse" for="c-42893927">[-]</label><label class="expand" for="c-42893927">[15 more]</label></div><br/><div class="children"><div class="content">Not trying to be snarky, but the example prompt you provided is about 1&#x2F;15th the length and detail of prompts I usually send when working with Cursor.<p>I tend to exhaustively detail what I want, including package names and versions because I&#x27;ve been to that movie before...</div><br/><div id="42895046" class="c"><input type="checkbox" id="c-42895046" checked=""/><div class="controls bullet"><span class="by">crooked-v</span><span>|</span><a href="#42893868">root</a><span>|</span><a href="#42893927">parent</a><span>|</span><a href="#42894197">next</a><span>|</span><label class="collapse" for="c-42895046">[-]</label><label class="expand" for="c-42895046">[3 more]</label></div><br/><div class="children"><div class="content">If have to write a prompt that long, it&#x27;ll be faster to just write the code.</div><br/><div id="42895169" class="c"><input type="checkbox" id="c-42895169" checked=""/><div class="controls bullet"><span class="by">aprilthird2021</span><span>|</span><a href="#42893868">root</a><span>|</span><a href="#42895046">parent</a><span>|</span><a href="#42895126">next</a><span>|</span><label class="collapse" for="c-42895169">[-]</label><label class="expand" for="c-42895169">[1 more]</label></div><br/><div class="children"><div class="content">Shocking to see this because this was essentially the reason most of the previous no code solutions never took off...</div><br/></div></div></div></div><div id="42894197" class="c"><input type="checkbox" id="c-42894197" checked=""/><div class="controls bullet"><span class="by">inerte</span><span>|</span><a href="#42893868">root</a><span>|</span><a href="#42893927">parent</a><span>|</span><a href="#42895046">prev</a><span>|</span><a href="#42895336">next</a><span>|</span><label class="collapse" for="c-42894197">[-]</label><label class="expand" for="c-42894197">[4 more]</label></div><br/><div class="children"><div class="content">What works nice also is the text to speech. I find it easier and faster to give more context by talking rather than typing, and the extra content helps the AI to do its job.<p>And even though the speech recognition fails a lot on some of the technical terms or weirdly named packages, software, etc, it still does a good job overall (if I don’t feel like correcting the wrong stuff).<p>It’s great and has become somewhat of a party trick at work. Some people don’t even use AI to code that often, and when I show them “hey have you tried this?” And just <i>tell</i> the computer what I want? Most folks are blown away.</div><br/><div id="42894753" class="c"><input type="checkbox" id="c-42894753" checked=""/><div class="controls bullet"><span class="by">cadence-</span><span>|</span><a href="#42893868">root</a><span>|</span><a href="#42894197">parent</a><span>|</span><a href="#42895122">next</a><span>|</span><label class="collapse" for="c-42894753">[-]</label><label class="expand" for="c-42894753">[1 more]</label></div><br/><div class="children"><div class="content">Does the Cursor have text-to-speech functionality?</div><br/></div></div><div id="42895122" class="c"><input type="checkbox" id="c-42895122" checked=""/><div class="controls bullet"><span class="by">fud101</span><span>|</span><a href="#42893868">root</a><span>|</span><a href="#42894197">parent</a><span>|</span><a href="#42894753">prev</a><span>|</span><a href="#42895336">next</a><span>|</span><label class="collapse" for="c-42895122">[-]</label><label class="expand" for="c-42895122">[2 more]</label></div><br/><div class="children"><div class="content">you mean speech to text right?</div><br/><div id="42895440" class="c"><input type="checkbox" id="c-42895440" checked=""/><div class="controls bullet"><span class="by">chefandy</span><span>|</span><a href="#42893868">root</a><span>|</span><a href="#42895122">parent</a><span>|</span><a href="#42895336">next</a><span>|</span><label class="collapse" for="c-42895440">[-]</label><label class="expand" for="c-42895440">[1 more]</label></div><br/><div class="children"><div class="content">Not for me. I first ask Advanced Voice to read me some code and have Siri listen and email it to an API I wrote which uses Claude to estimate the best cloud provider to run that code based on its requirements and then a n8n script deploys it and send me the results via twilio.</div><br/></div></div></div></div></div></div><div id="42895336" class="c"><input type="checkbox" id="c-42895336" checked=""/><div class="controls bullet"><span class="by">esperent</span><span>|</span><a href="#42893868">root</a><span>|</span><a href="#42893927">parent</a><span>|</span><a href="#42894197">prev</a><span>|</span><a href="#42894300">next</a><span>|</span><label class="collapse" for="c-42895336">[-]</label><label class="expand" for="c-42895336">[1 more]</label></div><br/><div class="children"><div class="content">That sounds exhausting. Wouldn&#x27;t it be faster to include you package.json in the context?<p>I sometimes do this (using Cline), plus create a .cline file at project root which I refine over time and which describes both the high level project overview, details of the stack I&#x27;m using, and technical details I want each prompt to follow.<p>Then each actual prompt can be quite short: <i>read files x, y, and z, and make the following changes...</i> where I keep the changes concise and logically connected - basically what I might do for a single pull request.</div><br/></div></div><div id="42894300" class="c"><input type="checkbox" id="c-42894300" checked=""/><div class="controls bullet"><span class="by">mvkel</span><span>|</span><a href="#42893868">root</a><span>|</span><a href="#42893927">parent</a><span>|</span><a href="#42895336">prev</a><span>|</span><a href="#42895612">next</a><span>|</span><label class="collapse" for="c-42894300">[-]</label><label class="expand" for="c-42894300">[4 more]</label></div><br/><div class="children"><div class="content">My point was that a prompt that simple could be held and executed very well by sonnet, but all other models (especially reasoning models) crash and burn.<p>It&#x27;s a 15 line tsx file so context shouldn&#x27;t be an issue.<p>Makes me wonder if reasoning models are really proper models for coding in existing codebases</div><br/><div id="42894876" class="c"><input type="checkbox" id="c-42894876" checked=""/><div class="controls bullet"><span class="by">liamwire</span><span>|</span><a href="#42893868">root</a><span>|</span><a href="#42894300">parent</a><span>|</span><a href="#42895612">next</a><span>|</span><label class="collapse" for="c-42894876">[-]</label><label class="expand" for="c-42894876">[3 more]</label></div><br/><div class="children"><div class="content">Your last point matches what I’ve seen some people (simonw?) say they’re doing currently: using aider to work with two models—one reasoning model as an architect, and one standard LLM as the actual coder. Surprisingly, the results seem pretty good vs. putting everything on
one model.</div><br/><div id="42895047" class="c"><input type="checkbox" id="c-42895047" checked=""/><div class="controls bullet"><span class="by">mvkel</span><span>|</span><a href="#42893868">root</a><span>|</span><a href="#42894876">parent</a><span>|</span><a href="#42895612">next</a><span>|</span><label class="collapse" for="c-42895047">[-]</label><label class="expand" for="c-42895047">[2 more]</label></div><br/><div class="children"><div class="content">This is probably the right way to think about it. O1-pro is an absolute monster when it comes to architecture. It is staggering the breadth and depth that it sees. Ask it to actually implement though, and it trips over its shoelaces almost immediately.</div><br/><div id="42895165" class="c"><input type="checkbox" id="c-42895165" checked=""/><div class="controls bullet"><span class="by">goosejuice</span><span>|</span><a href="#42893868">root</a><span>|</span><a href="#42895047">parent</a><span>|</span><a href="#42895612">next</a><span>|</span><label class="collapse" for="c-42895165">[-]</label><label class="expand" for="c-42895165">[1 more]</label></div><br/><div class="children"><div class="content">Can you give an example of this monstrous capability you speak of? What have you used it for professionally w.r.t. architecture.</div><br/></div></div></div></div></div></div></div></div><div id="42895612" class="c"><input type="checkbox" id="c-42895612" checked=""/><div class="controls bullet"><span class="by">hombre_fatal</span><span>|</span><a href="#42893868">root</a><span>|</span><a href="#42893927">parent</a><span>|</span><a href="#42894300">prev</a><span>|</span><a href="#42894092">next</a><span>|</span><label class="collapse" for="c-42895612">[-]</label><label class="expand" for="c-42895612">[1 more]</label></div><br/><div class="children"><div class="content">You’re basically saying you write 15x the prompt for the same result they get with sonnet.</div><br/></div></div><div id="42894092" class="c"><input type="checkbox" id="c-42894092" checked=""/><div class="controls bullet"><span class="by">jwpapi</span><span>|</span><a href="#42893868">root</a><span>|</span><a href="#42893927">parent</a><span>|</span><a href="#42895612">prev</a><span>|</span><a href="#42896442">next</a><span>|</span><label class="collapse" for="c-42894092">[-]</label><label class="expand" for="c-42894092">[1 more]</label></div><br/><div class="children"><div class="content">Yes this works good for me too rather take your time and do the first prompt right</div><br/></div></div></div></div><div id="42896442" class="c"><input type="checkbox" id="c-42896442" checked=""/><div class="controls bullet"><span class="by">adonese</span><span>|</span><a href="#42893868">parent</a><span>|</span><a href="#42893927">prev</a><span>|</span><a href="#42894147">next</a><span>|</span><label class="collapse" for="c-42896442">[-]</label><label class="expand" for="c-42896442">[1 more]</label></div><br/><div class="children"><div class="content">My general workflow with ai so far has been this:
- I use copilot mostly for writing unit tests. It mostly works well since the unit tests follow a standard template. 
- I use the chat one for alternating between different approaches and (in)validating certain approaches<p>My day job is a big monorepo, I have not investigated that yet but I believe the models context sizes fall short there and as such the above use cases only works for me.</div><br/></div></div><div id="42894147" class="c"><input type="checkbox" id="c-42894147" checked=""/><div class="controls bullet"><span class="by">energy123</span><span>|</span><a href="#42893868">parent</a><span>|</span><a href="#42896442">prev</a><span>|</span><a href="#42893907">next</a><span>|</span><label class="collapse" for="c-42894147">[-]</label><label class="expand" for="c-42894147">[3 more]</label></div><br/><div class="children"><div class="content">Context length possibly. Prompt adherence drops off with context, and anything above 20k tokens is pushing it. I get the best results by presenting the smallest amount of context possible, including removing comments and main methods and functions that it doesn&#x27;t need to see. It&#x27;s a bit more work (not <i>that</i> much if you have a script that does it for you), but the results are worth it. You could test in the chatgpt app (or lmarena direct chat) where you ask the same question but with minimal hand curated context, and see if it makes the same mistake.</div><br/><div id="42894349" class="c"><input type="checkbox" id="c-42894349" checked=""/><div class="controls bullet"><span class="by">mvkel</span><span>|</span><a href="#42893868">root</a><span>|</span><a href="#42894147">parent</a><span>|</span><a href="#42893907">next</a><span>|</span><label class="collapse" for="c-42894349">[-]</label><label class="expand" for="c-42894349">[2 more]</label></div><br/><div class="children"><div class="content">If it&#x27;s a context issue, it&#x27;s an issue with how cursor itself sends the context to these reasoning LLMs.<p>Context alone shouldn&#x27;t be the reason that sonnet succeeds consistently, but others (some which have even bigger context windows) fail.</div><br/><div id="42894376" class="c"><input type="checkbox" id="c-42894376" checked=""/><div class="controls bullet"><span class="by">energy123</span><span>|</span><a href="#42893868">root</a><span>|</span><a href="#42894349">parent</a><span>|</span><a href="#42893907">next</a><span>|</span><label class="collapse" for="c-42894376">[-]</label><label class="expand" for="c-42894376">[1 more]</label></div><br/><div class="children"><div class="content">Yes, that&#x27;s what I&#x27;m suggesting. Cursor is spamming the models with too much context, which harms reasoning models more than it harms non-reasoning models (hypothesis, but one that aligns with my experience). That&#x27;s why I recommended testing reasoning models outside of Cursor with a hand curated context.<p>The advertised context length being longer doesn&#x27;t necessarily map 1:1 with the actual ability the models have to perform difficult tasks over that full context. See for example the plots of performance on ARC vs context length for o-series models.</div><br/></div></div></div></div></div></div><div id="42893907" class="c"><input type="checkbox" id="c-42893907" checked=""/><div class="controls bullet"><span class="by">jvanderbot</span><span>|</span><a href="#42893868">parent</a><span>|</span><a href="#42894147">prev</a><span>|</span><a href="#42894221">next</a><span>|</span><label class="collapse" for="c-42893907">[-]</label><label class="expand" for="c-42893907">[13 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve found cursor to be too thin a wrapper. Aider is somehow significantly more functional. Try that.</div><br/><div id="42893943" class="c"><input type="checkbox" id="c-42893943" checked=""/><div class="controls bullet"><span class="by">dhc02</span><span>|</span><a href="#42893868">root</a><span>|</span><a href="#42893907">parent</a><span>|</span><a href="#42894221">next</a><span>|</span><label class="collapse" for="c-42893943">[-]</label><label class="expand" for="c-42893943">[12 more]</label></div><br/><div class="children"><div class="content">Aider, with o1 or R1 as the architect and Claude 3.5 as the implementer, is so much better than anything you can accomplish with a single model. It&#x27;s pretty amazing. Aider is at least one order of magnitude more effective for me than using the chat interface in Cursor. (I still use Cursor for quick edits and tab completions, to be clear).</div><br/><div id="42894009" class="c"><input type="checkbox" id="c-42894009" checked=""/><div class="controls bullet"><span class="by">dwaltrip</span><span>|</span><a href="#42893868">root</a><span>|</span><a href="#42893943">parent</a><span>|</span><a href="#42894002">next</a><span>|</span><label class="collapse" for="c-42894009">[-]</label><label class="expand" for="c-42894009">[4 more]</label></div><br/><div class="children"><div class="content">I haven&#x27;t tried aider in quite a while, what does it mean to use one model as an architect and another as the implementer?</div><br/><div id="42894061" class="c"><input type="checkbox" id="c-42894061" checked=""/><div class="controls bullet"><span class="by">Terretta</span><span>|</span><a href="#42893868">root</a><span>|</span><a href="#42894009">parent</a><span>|</span><a href="#42894002">next</a><span>|</span><label class="collapse" for="c-42894061">[-]</label><label class="expand" for="c-42894061">[3 more]</label></div><br/><div class="children"><div class="content"><i>Aider now has experimental support for using two models to complete each coding task:</i><p><i>- An Architect model is asked to describe how to solve the coding problem.</i><p><i>- An Editor model is given the Architect’s solution and asked to produce specific code editing instructions to apply those changes to existing source files.</i><p><i>Splitting up “code reasoning” and “code editing” in this manner has produced SOTA results on aider’s code editing benchmark. Using o1-preview as the Architect with either DeepSeek or o1-mini as the Editor produced the SOTA score of 85%. Using the Architect&#x2F;Editor approach also significantly improved the benchmark scores of many models, compared to their previous “solo” baseline scores (striped bars).</i><p><a href="https:&#x2F;&#x2F;aider.chat&#x2F;2024&#x2F;09&#x2F;26&#x2F;architect.html" rel="nofollow">https:&#x2F;&#x2F;aider.chat&#x2F;2024&#x2F;09&#x2F;26&#x2F;architect.html</a></div><br/><div id="42895250" class="c"><input type="checkbox" id="c-42895250" checked=""/><div class="controls bullet"><span class="by">lukas099</span><span>|</span><a href="#42893868">root</a><span>|</span><a href="#42894061">parent</a><span>|</span><a href="#42894002">next</a><span>|</span><label class="collapse" for="c-42895250">[-]</label><label class="expand" for="c-42895250">[2 more]</label></div><br/><div class="children"><div class="content">Probably gonna show a lot of ignorance here, but isn’t that a big part of the difference between our brains and AI? That instead of one system, we are many systems that are kind of sewn together? I secretly think AGI will just be a bunch of different specialized AIs working together.</div><br/><div id="42895325" class="c"><input type="checkbox" id="c-42895325" checked=""/><div class="controls bullet"><span class="by">Terretta</span><span>|</span><a href="#42893868">root</a><span>|</span><a href="#42895250">parent</a><span>|</span><a href="#42894002">next</a><span>|</span><label class="collapse" for="c-42895325">[-]</label><label class="expand" for="c-42895325">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;re in good company in that secret thought.<p>Have a look at this:  <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Society_of_Mind" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Society_of_Mind</a></div><br/></div></div></div></div></div></div></div></div><div id="42894002" class="c"><input type="checkbox" id="c-42894002" checked=""/><div class="controls bullet"><span class="by">ChadNauseam</span><span>|</span><a href="#42893868">root</a><span>|</span><a href="#42893943">parent</a><span>|</span><a href="#42894009">prev</a><span>|</span><a href="#42895963">next</a><span>|</span><label class="collapse" for="c-42894002">[-]</label><label class="expand" for="c-42894002">[6 more]</label></div><br/><div class="children"><div class="content">I normally use aider by just typing in what I want and it magically does it. How do I use o1 or R1 to play the role of the &quot;architect&quot;?</div><br/><div id="42894140" class="c"><input type="checkbox" id="c-42894140" checked=""/><div class="controls bullet"><span class="by">macNchz</span><span>|</span><a href="#42893868">root</a><span>|</span><a href="#42894002">parent</a><span>|</span><a href="#42895963">next</a><span>|</span><label class="collapse" for="c-42894140">[-]</label><label class="expand" for="c-42894140">[5 more]</label></div><br/><div class="children"><div class="content">You can start it with something like:<p><pre><code>    aider --architect --model o1 --editor-model sonnet
</code></pre>
Then you&#x27;ll be in &quot;architect&quot; mode, which first prompts o1 to design the solution, then you can accept it and allow sonnet to actually create the diffs.<p>Most of the time your way works well—I use sonnet alone 90% of the time, but the architect mode is really great at getting it unstuck when it can&#x27;t seem to implement what I want correctly, or keeps fixing its mistakes by making things worse.</div><br/><div id="42894590" class="c"><input type="checkbox" id="c-42894590" checked=""/><div class="controls bullet"><span class="by">cruffle_duffle</span><span>|</span><a href="#42893868">root</a><span>|</span><a href="#42894140">parent</a><span>|</span><a href="#42895963">next</a><span>|</span><label class="collapse" for="c-42894590">[-]</label><label class="expand" for="c-42894590">[4 more]</label></div><br/><div class="children"><div class="content">I really want to see how apps created this way scale to large codebases. I’m very skeptical they don’t turn into spaghetti messes.<p>Coding is basically just about the most precise way to encapsulate a problem as a solution possible. Taking a loose English description and expanding it into piles of code is always going to be pretty leaky no matter how much these models spit out working code.<p>In my experience you have to pay a lot of attention to every single line these things write because they’ll often change stuff or more often make wrong assumptions that you didn’t articulate.  And in my experience they <i>never</i> ask you questions unless you specifically prompt them to (and keep reminding them to), which means they are doing a hell of a lot of design and implementation that unless carefully looked over will ultimately be wrong.<p>It really reminds me a bit of when Ruby on Rails came out and the blogosphere was full of gushing “I’ve never been more productive in my life” posts. And then you find out they were basically writing a TODO app and their previous development experience was doing enterprise Java for some massive non-tech company. Of course RoR will be a breath of fresh air for those people.<p>Don’t get me wrong I use cursor as my daily driver but I am starting to find the limits for what these things can do.  And the idea of having two of these LLM’s taking some paragraph long feature description and somehow chatting with each other to create a scalable bit of code that fits into a large or growing codebase… well I find that kind of impossible.  Sure the code compiles and conforms to whatever best practices are out there but there will be absolutely no constancy across the app—especially at the UX level. These things simply cannot hold that kind of complexity in their head and even if they could part of a developers job is to translate loose English into code. And there is much, much, much, much more to that than simply writing code.</div><br/><div id="42894926" class="c"><input type="checkbox" id="c-42894926" checked=""/><div class="controls bullet"><span class="by">macNchz</span><span>|</span><a href="#42893868">root</a><span>|</span><a href="#42894590">parent</a><span>|</span><a href="#42895243">next</a><span>|</span><label class="collapse" for="c-42894926">[-]</label><label class="expand" for="c-42894926">[1 more]</label></div><br/><div class="children"><div class="content">I see what you’re saying and I think that terming this “architect” mode has an implication that it’s more capable than it really is, but ultimately this two model pairing is mostly about combining disparate abilities to separate the “thinking” from the diff generation. It’s very effective in producing better results for a single prompt, but it’s not especially helpful for “architecting” a large scale app.<p>That said, in the hands of someone who is competent at assembling a large app, I think these tools can be incredibly powerful. I have a business helping companies figure out how&#x2F;if to leverage AI and have built a bunch of different production LLM-backed applications <i>using</i> LLMs to write the code over the past year, and my impression is that there is very much something there. Taking it step by step, file by file, like you might if you wrote the code yourself, describing your concept of the abstractions, having a few files describing the overall architecture that you can add to the chat as needed—little details make a big difference in the results.</div><br/></div></div><div id="42895243" class="c"><input type="checkbox" id="c-42895243" checked=""/><div class="controls bullet"><span class="by">tribeca18</span><span>|</span><a href="#42893868">root</a><span>|</span><a href="#42894590">parent</a><span>|</span><a href="#42894926">prev</a><span>|</span><a href="#42896530">next</a><span>|</span><label class="collapse" for="c-42895243">[-]</label><label class="expand" for="c-42895243">[1 more]</label></div><br/><div class="children"><div class="content">I use Cursor and Composer in agent mode on a daily basis, and this is basically exactly what happened to me.<p>After about 3 weeks, things were looking great - but lots of spagetti code was put together, and it never told me what I didn&#x27;t know. The data &amp; state management architecture I had written was simply just not maintainable (tons of prop drilling, etc). Over time, I basically learned common practices&#x2F;etc and I&#x27;m finding that I have to deal with these problems myself. (how it used to be!)<p>We&#x27;re getting close - the best thing I&#x27;ve done is create documentation files with lots of descriptions about the architecture&#x2F;file structure&#x2F;state management&#x2F;packages&#x2F;etc, but it only goes so far.<p>We&#x27;re getting closer, but for right now - we&#x27;re not there and you have to be really careful with looking over all the changes.</div><br/></div></div><div id="42896530" class="c"><input type="checkbox" id="c-42896530" checked=""/><div class="controls bullet"><span class="by">nprateem</span><span>|</span><a href="#42893868">root</a><span>|</span><a href="#42894590">parent</a><span>|</span><a href="#42895243">prev</a><span>|</span><a href="#42895963">next</a><span>|</span><label class="collapse" for="c-42896530">[-]</label><label class="expand" for="c-42896530">[1 more]</label></div><br/><div class="children"><div class="content">The worst thing you can do with aider is let it autocommit to git. As long as you review each set of changes you can stop it going nuts.<p>I have a codebase maybe 3-500k lines which is in good shape because of this.<p>I also normally just add the specific files I need to the chat and give it 1-2 sentences for what to do. It normally does the right thing (sonnet obviously).</div><br/></div></div></div></div></div></div></div></div><div id="42895963" class="c"><input type="checkbox" id="c-42895963" checked=""/><div class="controls bullet"><span class="by">aledalgrande</span><span>|</span><a href="#42893868">root</a><span>|</span><a href="#42893943">parent</a><span>|</span><a href="#42894002">prev</a><span>|</span><a href="#42894221">next</a><span>|</span><label class="collapse" for="c-42895963">[-]</label><label class="expand" for="c-42895963">[1 more]</label></div><br/><div class="children"><div class="content">Same with Cline</div><br/></div></div></div></div></div></div><div id="42894221" class="c"><input type="checkbox" id="c-42894221" checked=""/><div class="controls bullet"><span class="by">esperent</span><span>|</span><a href="#42893868">parent</a><span>|</span><a href="#42893907">prev</a><span>|</span><a href="#42895628">next</a><span>|</span><label class="collapse" for="c-42894221">[-]</label><label class="expand" for="c-42894221">[1 more]</label></div><br/><div class="children"><div class="content">Claude uses Shadcn-ui extensively in the web interface, to the point where I think it&#x27;s been trained to use it over other UI components.<p>So I think you got lucky and you&#x27;re asking it to write using a very specific code library that it&#x27;s good at, because it happens to use it for it&#x27;s main userbase on the web chat interface.<p>I wonder if you were using a different component library, or using Svelte instead of React, would you still find Claude the best?</div><br/></div></div><div id="42895628" class="c"><input type="checkbox" id="c-42895628" checked=""/><div class="controls bullet"><span class="by">hombre_fatal</span><span>|</span><a href="#42893868">parent</a><span>|</span><a href="#42894221">prev</a><span>|</span><a href="#42894351">next</a><span>|</span><label class="collapse" for="c-42895628">[-]</label><label class="expand" for="c-42895628">[1 more]</label></div><br/><div class="children"><div class="content">I have the same experience. Just today I was integrating a new logging system with  my kubernetes cluster.<p>I tried out the OP model to make changes to my yaml files. It would give short snippets and I’d have to keep trial and erroring its suggestions.<p>Eventually I pasted the original prompt to Claude and it one-shot the dang thing with perfect config. Made me wonder why I even try new models.</div><br/></div></div><div id="42894351" class="c"><input type="checkbox" id="c-42894351" checked=""/><div class="controls bullet"><span class="by">eagleinparadise</span><span>|</span><a href="#42893868">parent</a><span>|</span><a href="#42895628">prev</a><span>|</span><a href="#42895721">next</a><span>|</span><label class="collapse" for="c-42894351">[-]</label><label class="expand" for="c-42894351">[1 more]</label></div><br/><div class="children"><div class="content">Cursor is also very user-unfriendly in providing alternative models to use in composer (agent). There&#x27;s a heavy reliance on Anthrophic for cursor.<p>Try using Gemini thinking with Cursor. It barely works. Cmd-k outputs the thinking into the code. Its unusable in chat because the formatting sucks.<p>Is there some relationship between Cursor and Anthropic, i wonder. Plenty of other platforms seem very eager to give users model flexibility, but Cursor seems to be lacking.<p>I could be wrong, just an observation.</div><br/></div></div><div id="42895721" class="c"><input type="checkbox" id="c-42895721" checked=""/><div class="controls bullet"><span class="by">pknerd</span><span>|</span><a href="#42893868">parent</a><span>|</span><a href="#42894351">prev</a><span>|</span><a href="#42894284">next</a><span>|</span><label class="collapse" for="c-42895721">[-]</label><label class="expand" for="c-42895721">[1 more]</label></div><br/><div class="children"><div class="content">OT: How many tokens are being consumed? How much are you paying for Claude APIs?</div><br/></div></div><div id="42894284" class="c"><input type="checkbox" id="c-42894284" checked=""/><div class="controls bullet"><span class="by">kristopolous</span><span>|</span><a href="#42893868">parent</a><span>|</span><a href="#42895721">prev</a><span>|</span><a href="#42895513">next</a><span>|</span><label class="collapse" for="c-42894284">[-]</label><label class="expand" for="c-42894284">[1 more]</label></div><br/><div class="children"><div class="content">&quot;not&quot; and other function words;
 <i>usually</i> work fine today but if I&#x27;m having trouble, the best thing to do is probably be inclusive, not exclusive.</div><br/></div></div><div id="42895513" class="c"><input type="checkbox" id="c-42895513" checked=""/><div class="controls bullet"><span class="by">Abishek_Muthian</span><span>|</span><a href="#42893868">parent</a><span>|</span><a href="#42894284">prev</a><span>|</span><a href="#42894772">next</a><span>|</span><label class="collapse" for="c-42895513">[-]</label><label class="expand" for="c-42895513">[1 more]</label></div><br/><div class="children"><div class="content">Just curious, did you try a code model like Codestral instead of a MoE?</div><br/></div></div><div id="42894772" class="c"><input type="checkbox" id="c-42894772" checked=""/><div class="controls bullet"><span class="by">foobiekr</span><span>|</span><a href="#42893868">parent</a><span>|</span><a href="#42895513">prev</a><span>|</span><a href="#42894392">next</a><span>|</span><label class="collapse" for="c-42894772">[-]</label><label class="expand" for="c-42894772">[1 more]</label></div><br/><div class="children"><div class="content">Have you tried any of the specialty services like Augment? I am curious if they are any better or just snake oil.</div><br/></div></div><div id="42894392" class="c"><input type="checkbox" id="c-42894392" checked=""/><div class="controls bullet"><span class="by">OkGoDoIt</span><span>|</span><a href="#42893868">parent</a><span>|</span><a href="#42894772">prev</a><span>|</span><a href="#42895532">next</a><span>|</span><label class="collapse" for="c-42894392">[-]</label><label class="expand" for="c-42894392">[1 more]</label></div><br/><div class="children"><div class="content">I also have been less impressed by o1 in cursor compared to sonnet 3.5.  Usually what I will do for a very complicated change is ask o1 to architect it, specifically asking it to give me a detailed plan for how it would be implemented, but not to actually implement anything. I then change the model to Sonnet 3.5 to have it actually do the implementation.<p>And on the side of not being able to get models to understand something specific, there’s a place in a current project where I use a special Unicode apostrophe during some string parsing because a third-party API needs it. But any code modifications by the AI to that file always replace it with a standard ascii apostrophe. I even added a comment on that line to the effect of “never replaced this apostrophe, it’s important to leave it exactly as it is!” And also put that in my cursor rules, and sometimes directly in the prompt as well, but it always replaces it even for completely unrelated changes. I’ve had to manually fix it like 10 times in the last day, it’s infuriating.</div><br/></div></div><div id="42895532" class="c"><input type="checkbox" id="c-42895532" checked=""/><div class="controls bullet"><span class="by">bugglebeetle</span><span>|</span><a href="#42893868">parent</a><span>|</span><a href="#42894392">prev</a><span>|</span><a href="#42894661">next</a><span>|</span><label class="collapse" for="c-42895532">[-]</label><label class="expand" for="c-42895532">[1 more]</label></div><br/><div class="children"><div class="content">o3 mini’s date cut-off is 2023, so it’s unfortunately not gonna be useful for anything that requires knowledge of recent framework updates, which includes probably all big frontend stuff.</div><br/></div></div></div></div><div id="42891991" class="c"><input type="checkbox" id="c-42891991" checked=""/><div class="controls bullet"><span class="by">silverlake</span><span>|</span><a href="#42893868">prev</a><span>|</span><a href="#42892097">next</a><span>|</span><label class="collapse" for="c-42891991">[-]</label><label class="expand" for="c-42891991">[10 more]</label></div><br/><div class="children"><div class="content">O3-mini solved this prompt. DeepSeek R1 had a mental breakdown. The prompt: “Bob is facing forward. To his left is Ann, to his right is Cathy. Ann and Cathy are facing backwards. Who is on Ann’s left?”</div><br/><div id="42894575" class="c"><input type="checkbox" id="c-42894575" checked=""/><div class="controls bullet"><span class="by">thinkalone</span><span>|</span><a href="#42891991">parent</a><span>|</span><a href="#42893286">next</a><span>|</span><label class="collapse" for="c-42894575">[-]</label><label class="expand" for="c-42894575">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s a fun, simple test! I tried a few models, and mistral-nemo gets it every time, even when run locally without any system prompt! <a href="https:&#x2F;&#x2F;build.nvidia.com&#x2F;nv-mistralai&#x2F;mistral-nemo-12b-instruct" rel="nofollow">https:&#x2F;&#x2F;build.nvidia.com&#x2F;nv-mistralai&#x2F;mistral-nemo-12b-instr...</a></div><br/></div></div><div id="42893286" class="c"><input type="checkbox" id="c-42893286" checked=""/><div class="controls bullet"><span class="by">lynguist</span><span>|</span><a href="#42891991">parent</a><span>|</span><a href="#42894575">prev</a><span>|</span><a href="#42892068">next</a><span>|</span><label class="collapse" for="c-42893286">[-]</label><label class="expand" for="c-42893286">[1 more]</label></div><br/><div class="children"><div class="content">Really interesting puzzle. I tried the different Chatgpts and they all solved it. I tried Deepseek and Deepseek R1, and Deepseek did have this meltdown:<p>Let&#x27;s break down the problem step by step to understand the relationships and positions of Bob, Ann, and Cathy.
1. Understanding the Initial Setup<p><pre><code>    Bob is facing forward.

    This means Bob&#x27;s front is oriented in a particular direction, which we&#x27;ll consider as the reference point for &quot;forward.&quot;

    To his left is Ann, to his right is Cathy.

    If Bob is facing forward, then:

        Ann is positioned to Bob&#x27;s left.

        Cathy is positioned to Bob&#x27;s right.

    Ann and Cathy are facing backwards.

    Both Ann and Cathy are oriented in the opposite direction to Bob. If Bob is facing forward, then Ann and Cathy are facing backward.
</code></pre>
2. Visualizing the Positions<p>To better understand the scenario, let&#x27;s visualize the positions:
Copy<p>Forward Direction: ↑<p>Bob (facing forward)
|
|       Ann (facing backward)
|       &#x2F;
|      &#x2F;
|     &#x2F;
|    &#x2F;
|   &#x2F;
|  &#x2F;
| &#x2F;
|&#x2F;
|<p>And then only the character | in a newline forever.</div><br/></div></div><div id="42892068" class="c"><input type="checkbox" id="c-42892068" checked=""/><div class="controls bullet"><span class="by">modeless</span><span>|</span><a href="#42891991">parent</a><span>|</span><a href="#42893286">prev</a><span>|</span><a href="#42892383">next</a><span>|</span><label class="collapse" for="c-42892068">[-]</label><label class="expand" for="c-42892068">[4 more]</label></div><br/><div class="children"><div class="content">R1 or R1-Distill? They are not the same thing. I think DeepSeek made a mistake releasing them at the same time and calling them all R1.<p>Full R1 solves this prompt easily for me.</div><br/><div id="42892514" class="c"><input type="checkbox" id="c-42892514" checked=""/><div class="controls bullet"><span class="by">silverlake</span><span>|</span><a href="#42891991">root</a><span>|</span><a href="#42892068">parent</a><span>|</span><a href="#42892383">next</a><span>|</span><label class="collapse" for="c-42892514">[-]</label><label class="expand" for="c-42892514">[3 more]</label></div><br/><div class="children"><div class="content">I used R1 hosted at NVidia here: <a href="https:&#x2F;&#x2F;build.nvidia.com&#x2F;deepseek-ai&#x2F;deepseek-r1&#x2F;modelcard" rel="nofollow">https:&#x2F;&#x2F;build.nvidia.com&#x2F;deepseek-ai&#x2F;deepseek-r1&#x2F;modelcard</a></div><br/><div id="42893823" class="c"><input type="checkbox" id="c-42893823" checked=""/><div class="controls bullet"><span class="by">modeless</span><span>|</span><a href="#42891991">root</a><span>|</span><a href="#42892514">parent</a><span>|</span><a href="#42892947">next</a><span>|</span><label class="collapse" for="c-42893823">[-]</label><label class="expand" for="c-42893823">[1 more]</label></div><br/><div class="children"><div class="content">Huh, that one got it wrong for me too. I don&#x27;t have patience to try it 10 times each to see if it was a coincidence, but it is absolutely true that not all implementations of LLMs produce the same outputs. It is in fact common for subtle bugs to happen that cause the outputs to be worse but not catastrophically bad, and therefore go unnoticed. So I wouldn&#x27;t trust any implementation but the original for benchmarking or even general use unless I tested it extensively.</div><br/></div></div><div id="42892947" class="c"><input type="checkbox" id="c-42892947" checked=""/><div class="controls bullet"><span class="by">SparkyMcUnicorn</span><span>|</span><a href="#42891991">root</a><span>|</span><a href="#42892514">parent</a><span>|</span><a href="#42893823">prev</a><span>|</span><a href="#42892383">next</a><span>|</span><label class="collapse" for="c-42892947">[-]</label><label class="expand" for="c-42892947">[1 more]</label></div><br/><div class="children"><div class="content">Same. With the recommended settings, it got it right. I regenerated a bunch of times, and it did suggest Cathy once or twice.<p>R1 70b also got it right just as many times for me.</div><br/></div></div></div></div></div></div><div id="42892383" class="c"><input type="checkbox" id="c-42892383" checked=""/><div class="controls bullet"><span class="by">mark_l_watson</span><span>|</span><a href="#42891991">parent</a><span>|</span><a href="#42892068">prev</a><span>|</span><a href="#42895660">next</a><span>|</span><label class="collapse" for="c-42892383">[-]</label><label class="expand" for="c-42892383">[1 more]</label></div><br/><div class="children"><div class="content">Thanks for that example! Using &#x27;ollama run&#x27; these models all failed: deepseek-r1:32b, mistral-small:latest, qwq:latest, and qwen2.5:14b.</div><br/></div></div><div id="42895660" class="c"><input type="checkbox" id="c-42895660" checked=""/><div class="controls bullet"><span class="by">sivakon</span><span>|</span><a href="#42891991">parent</a><span>|</span><a href="#42892383">prev</a><span>|</span><a href="#42893754">next</a><span>|</span><label class="collapse" for="c-42895660">[-]</label><label class="expand" for="c-42895660">[1 more]</label></div><br/><div class="children"><div class="content">deepseek answered it.<p><a href="https:&#x2F;&#x2F;leaflet.pub&#x2F;63ae4881-d726-4388-9ba3-8a5f86947443" rel="nofollow">https:&#x2F;&#x2F;leaflet.pub&#x2F;63ae4881-d726-4388-9ba3-8a5f86947443</a></div><br/></div></div><div id="42893754" class="c"><input type="checkbox" id="c-42893754" checked=""/><div class="controls bullet"><span class="by">Synaesthesia</span><span>|</span><a href="#42891991">parent</a><span>|</span><a href="#42895660">prev</a><span>|</span><a href="#42892097">next</a><span>|</span><label class="collapse" for="c-42893754">[-]</label><label class="expand" for="c-42893754">[1 more]</label></div><br/><div class="children"><div class="content">Deepseek solved it.</div><br/></div></div></div></div><div id="42892097" class="c"><input type="checkbox" id="c-42892097" checked=""/><div class="controls bullet"><span class="by">mark_l_watson</span><span>|</span><a href="#42891991">prev</a><span>|</span><a href="#42890833">next</a><span>|</span><label class="collapse" for="c-42892097">[-]</label><label class="expand" for="c-42892097">[1 more]</label></div><br/><div class="children"><div class="content">Oh, sweet: both o3-mini low and high support integrated web search. No integrated web search with o1.<p>I prefer, for philosophical reasons, open weight and open process&#x2F;science models, but OpenAI has done a very good job at productizing ChatGPT. I also use their 4o-mini API because it is cheap and compares well to using open models on Groq Cloud. I really love running local models with Ollama but the API venders keep the price so low that I understand most people not wanting the hasssle if running Deepseek-R, etc., locally.</div><br/></div></div><div id="42890833" class="c"><input type="checkbox" id="c-42890833" checked=""/><div class="controls bullet"><span class="by">msp26</span><span>|</span><a href="#42892097">prev</a><span>|</span><a href="#42895234">next</a><span>|</span><label class="collapse" for="c-42890833">[-]</label><label class="expand" for="c-42890833">[6 more]</label></div><br/><div class="children"><div class="content">I wish they&#x27;d just reveal the CoT (like gemini and deepseek do), it&#x27;s very helpful to see when the model gets misled by something in your prompt. Paying for tokens you aren&#x27;t even allowed to see is peak OpenAI.</div><br/><div id="42895533" class="c"><input type="checkbox" id="c-42895533" checked=""/><div class="controls bullet"><span class="by">liamwire</span><span>|</span><a href="#42890833">parent</a><span>|</span><a href="#42892515">next</a><span>|</span><label class="collapse" for="c-42895533">[-]</label><label class="expand" for="c-42895533">[2 more]</label></div><br/><div class="children"><div class="content">sama and OpenAI’s CPO Kevin Weil both suggested this is coming soon, as a direct response to DeepSeek, in an AMA a few hours ago: <a href="https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;OpenAI&#x2F;s&#x2F;EElFfcU8ZO" rel="nofollow">https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;OpenAI&#x2F;s&#x2F;EElFfcU8ZO</a></div><br/><div id="42896692" class="c"><input type="checkbox" id="c-42896692" checked=""/><div class="controls bullet"><span class="by">PeterHolzwarth</span><span>|</span><a href="#42890833">root</a><span>|</span><a href="#42895533">parent</a><span>|</span><a href="#42892515">next</a><span>|</span><label class="collapse" for="c-42896692">[-]</label><label class="expand" for="c-42896692">[1 more]</label></div><br/><div class="children"><div class="content">Do you have a direct link to that? My &quot;force .old on everything&quot; plugin is having problems resolving your url (sorry!).</div><br/></div></div></div></div><div id="42892515" class="c"><input type="checkbox" id="c-42892515" checked=""/><div class="controls bullet"><span class="by">tucnak</span><span>|</span><a href="#42890833">parent</a><span>|</span><a href="#42895533">prev</a><span>|</span><a href="#42895234">next</a><span>|</span><label class="collapse" for="c-42892515">[-]</label><label class="expand" for="c-42892515">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;m sorry, but it&#x27;s over for OpenAI. Some have predicted this; including me back in November[1] when I wrote &quot;o1 is a revolution in accounting, not capability&quot; which although tongue-in-cheek, has so far turned out to be correct. I&#x27;m only waiting to see what Google, Facebook et al. will accomplish now that R1-Zero result is out the bag. The nerve, the cheek of this hysterical o3-mini release—insisting to hide the COT from the consumer still, is telling us one thing and one thing alone: OpenAI is no longer able to adapt to the ever-changing landscape. Maybe the Chinese haven&#x27;t beaten them yet, but Google, Facebook et al. absolutely will, &amp; without having to resort to deception.<p>[1]: <a href="https:&#x2F;&#x2F;old.reddit.com&#x2F;r&#x2F;LocalLLaMA&#x2F;comments&#x2F;1gna0nr&#x2F;popular_opinion_o1_is_a_revolution_in_accounting&#x2F;" rel="nofollow">https:&#x2F;&#x2F;old.reddit.com&#x2F;r&#x2F;LocalLLaMA&#x2F;comments&#x2F;1gna0nr&#x2F;popular...</a></div><br/><div id="42892824" class="c"><input type="checkbox" id="c-42892824" checked=""/><div class="controls bullet"><span class="by">mediaman</span><span>|</span><a href="#42890833">root</a><span>|</span><a href="#42892515">parent</a><span>|</span><a href="#42895234">next</a><span>|</span><label class="collapse" for="c-42892824">[-]</label><label class="expand" for="c-42892824">[2 more]</label></div><br/><div class="children"><div class="content">You don&#x27;t need to wait for Google. Their Jan 21 checkpoint for their fast reasoning model is available on AIStudio. It shows full reasoning traces. It&#x27;s very good,  much faster than R1, and although they haven&#x27;t released pricing, based on flash it&#x27;s going to be quite cheap.</div><br/><div id="42893415" class="c"><input type="checkbox" id="c-42893415" checked=""/><div class="controls bullet"><span class="by">tucnak</span><span>|</span><a href="#42890833">root</a><span>|</span><a href="#42892824">parent</a><span>|</span><a href="#42895234">next</a><span>|</span><label class="collapse" for="c-42893415">[-]</label><label class="expand" for="c-42893415">[1 more]</label></div><br/><div class="children"><div class="content">Sure, their 01-21 reasoning model is really good, but there&#x27;s no pricing for it!<p>I care mostly about batching in Vertex AI, which is 17-30x times cheaper than competition (whether you use prompt caching or not) while allowing for audio, video, and arbitrary document filetype inputs; unfortunately Gemini 1.5 Pro&#x2F;Flash have remained the two so-called &quot;stable&quot; options that are available there. I can appreciate Google&#x27;s experimental models for all I can, but I cannot take them seriously until they allow me to have my sweet, sweet batches.</div><br/></div></div></div></div></div></div></div></div><div id="42895234" class="c"><input type="checkbox" id="c-42895234" checked=""/><div class="controls bullet"><span class="by">zone411</span><span>|</span><a href="#42890833">prev</a><span>|</span><a href="#42890764">next</a><span>|</span><label class="collapse" for="c-42895234">[-]</label><label class="expand" for="c-42895234">[1 more]</label></div><br/><div class="children"><div class="content">It scores 72.4 on NYT Connections, a significant improvement over the o1-mini (42.2) and surpassing DeepSeek R1 (54.4), but it falls short of the o1 (90.7).<p>(<a href="https:&#x2F;&#x2F;github.com&#x2F;lechmazur&#x2F;nyt-connections&#x2F;">https:&#x2F;&#x2F;github.com&#x2F;lechmazur&#x2F;nyt-connections&#x2F;</a>)</div><br/></div></div><div id="42890764" class="c"><input type="checkbox" id="c-42890764" checked=""/><div class="controls bullet"><span class="by">ryanhecht</span><span>|</span><a href="#42895234">prev</a><span>|</span><a href="#42892358">next</a><span>|</span><label class="collapse" for="c-42890764">[-]</label><label class="expand" for="c-42890764">[64 more]</label></div><br/><div class="children"><div class="content">&gt; While OpenAI o1 remains our broader general knowledge reasoning model, OpenAI o3-mini provides a specialized alternative for technical domains requiring precision and speed.<p>I feel like this naming scheme is growing a little tired. o1 is for general knowledge reasoning, o3-mini replaces o1-mini but might be more specialized than o1 for certain technical domains...the &quot;o&quot; in &quot;4o&quot; is for &quot;omni&quot; (referring to its multimodality) but the reasoning models start with &quot;o&quot; ...but they can&#x27;t use &quot;o2&quot; for trademark reasons so they skip straight to &quot;o3&quot; ...the word salad is getting really hard to follow!</div><br/><div id="42890930" class="c"><input type="checkbox" id="c-42890930" checked=""/><div class="controls bullet"><span class="by">zamadatix</span><span>|</span><a href="#42890764">parent</a><span>|</span><a href="#42890912">next</a><span>|</span><label class="collapse" for="c-42890930">[-]</label><label class="expand" for="c-42890930">[9 more]</label></div><br/><div class="children"><div class="content">The -mini postfix makes perfect sense, probably even clearer than the old &quot;turbo&quot; wording. Naturally, the latest small model may be better than larger older models... but not always and not necessarily in everything. What you&#x27;d expect from a -mini model is exactly what is delivered.<p>The non-reasoning line was also pretty straightforward. Newer base models get a larger prefix number and some postfixes like &#x27;o&#x27; were added to signal specific features in each model variant. Great!<p>Where things went of the rails was specifically when they decided to also name the reasoning models with an &#x27;o&#x27; for separate reasons but now as the prefix at the same time as starting a separate linear sequence but now as the postfix. I wonder if we&#x27;ll end up with both a 4o and o4...</div><br/><div id="42891006" class="c"><input type="checkbox" id="c-42891006" checked=""/><div class="controls bullet"><span class="by">lolinder</span><span>|</span><a href="#42890764">root</a><span>|</span><a href="#42890930">parent</a><span>|</span><a href="#42890912">next</a><span>|</span><label class="collapse" for="c-42891006">[-]</label><label class="expand" for="c-42891006">[8 more]</label></div><br/><div class="children"><div class="content">&gt; I wonder if we&#x27;ll end up with both a 4o and o4...<p>The perplexing thing is that <i>someone</i> has to have said that, right? It has to have been brought up in some meeting when they were brainstorming names that if you have 4o and o1 with the intention of incrementing o1 you&#x27;ll eventually end up with an o4.<p>Where they really went off the rails was not just bailing when they realized they couldn&#x27;t use o2. In that moment they had the chance to just make o1 a one-off weird name and go down a different path for its final branding.<p>OpenAI just struggles with names in general, though. ChatGPT was a terrible name picked by engineers for a product that wasn&#x27;t supposed to become wildly successful, and they haven&#x27;t really improved at it since.</div><br/><div id="42891090" class="c"><input type="checkbox" id="c-42891090" checked=""/><div class="controls bullet"><span class="by">viraptor</span><span>|</span><a href="#42890764">root</a><span>|</span><a href="#42891006">parent</a><span>|</span><a href="#42892452">next</a><span>|</span><label class="collapse" for="c-42891090">[-]</label><label class="expand" for="c-42891090">[3 more]</label></div><br/><div class="children"><div class="content">The obvious solution could be to just keep skipping the even numbers and go to o5.</div><br/><div id="42891293" class="c"><input type="checkbox" id="c-42891293" checked=""/><div class="controls bullet"><span class="by">arrowleaf</span><span>|</span><a href="#42890764">root</a><span>|</span><a href="#42891090">parent</a><span>|</span><a href="#42892452">next</a><span>|</span><label class="collapse" for="c-42891293">[-]</label><label class="expand" for="c-42891293">[2 more]</label></div><br/><div class="children"><div class="content">Or further the hype and name it o9.</div><br/></div></div></div></div><div id="42892452" class="c"><input type="checkbox" id="c-42892452" checked=""/><div class="controls bullet"><span class="by">macrolime</span><span>|</span><a href="#42890764">root</a><span>|</span><a href="#42891006">parent</a><span>|</span><a href="#42891090">prev</a><span>|</span><a href="#42892621">next</a><span>|</span><label class="collapse" for="c-42892452">[-]</label><label class="expand" for="c-42892452">[1 more]</label></div><br/><div class="children"><div class="content">And multimodal o4 should be o4o.</div><br/></div></div><div id="42892621" class="c"><input type="checkbox" id="c-42892621" checked=""/><div class="controls bullet"><span class="by">tmnvdb</span><span>|</span><a href="#42890764">root</a><span>|</span><a href="#42891006">parent</a><span>|</span><a href="#42892452">prev</a><span>|</span><a href="#42894613">next</a><span>|</span><label class="collapse" for="c-42892621">[-]</label><label class="expand" for="c-42892621">[1 more]</label></div><br/><div class="children"><div class="content">Probably they are doing so well because there are not endless meetings on customer friendly names</div><br/></div></div><div id="42894613" class="c"><input type="checkbox" id="c-42894613" checked=""/><div class="controls bullet"><span class="by">cruffle_duffle</span><span>|</span><a href="#42890764">root</a><span>|</span><a href="#42891006">parent</a><span>|</span><a href="#42892621">prev</a><span>|</span><a href="#42891101">next</a><span>|</span><label class="collapse" for="c-42894613">[-]</label><label class="expand" for="c-42894613">[1 more]</label></div><br/><div class="children"><div class="content">Why not let ChatGPT decide the naming? Surely it will be replacing humans at this task any day now?</div><br/></div></div></div></div></div></div><div id="42890912" class="c"><input type="checkbox" id="c-42890912" checked=""/><div class="controls bullet"><span class="by">unsupp0rted</span><span>|</span><a href="#42890764">parent</a><span>|</span><a href="#42890930">prev</a><span>|</span><a href="#42890816">next</a><span>|</span><label class="collapse" for="c-42890912">[-]</label><label class="expand" for="c-42890912">[13 more]</label></div><br/><div class="children"><div class="content">This is definitely intentional.<p>You can like Sama or dislike him, but he knows how to market a product. Maybe this is a bad call on his part, but it is a call.</div><br/><div id="42891000" class="c"><input type="checkbox" id="c-42891000" checked=""/><div class="controls bullet"><span class="by">thorum</span><span>|</span><a href="#42890764">root</a><span>|</span><a href="#42890912">parent</a><span>|</span><a href="#42892293">next</a><span>|</span><label class="collapse" for="c-42891000">[-]</label><label class="expand" for="c-42891000">[7 more]</label></div><br/><div class="children"><div class="content">Not really. They’re successful because they created one of the most interesting products in human history, not because they have any idea how to brand it.</div><br/><div id="42891041" class="c"><input type="checkbox" id="c-42891041" checked=""/><div class="controls bullet"><span class="by">marko-k</span><span>|</span><a href="#42890764">root</a><span>|</span><a href="#42891000">parent</a><span>|</span><a href="#42892293">next</a><span>|</span><label class="collapse" for="c-42891041">[-]</label><label class="expand" for="c-42891041">[6 more]</label></div><br/><div class="children"><div class="content">If that were the case, they’d be neck and neck with Anthropic and Claude. But ChatGPT has far more market share and name recognition, especially among normies. Branding clearly plays a huge role.</div><br/><div id="42891171" class="c"><input type="checkbox" id="c-42891171" checked=""/><div class="controls bullet"><span class="by">cj</span><span>|</span><a href="#42890764">root</a><span>|</span><a href="#42891041">parent</a><span>|</span><a href="#42891120">next</a><span>|</span><label class="collapse" for="c-42891171">[-]</label><label class="expand" for="c-42891171">[1 more]</label></div><br/><div class="children"><div class="content">ChatGPT is still benefitting from first mover advantage. Which they’ve leveraged to get to the position they’re at today.<p>Over time, competitors catch up and first mover advantage melts away.<p>I wouldn’t attribute OpenAI’s success to any extremely smart marketing moves. I think a big part of their market share grab was simply going (and staying) viral for a long time. Manufacturing virality is notoriously difficult (and based on the usability and poor UI of ChatGPT early versions, it feels like they got lucky in a lot of ways)</div><br/></div></div><div id="42891120" class="c"><input type="checkbox" id="c-42891120" checked=""/><div class="controls bullet"><span class="by">bobxmax</span><span>|</span><a href="#42890764">root</a><span>|</span><a href="#42891041">parent</a><span>|</span><a href="#42891171">prev</a><span>|</span><a href="#42891123">next</a><span>|</span><label class="collapse" for="c-42891120">[-]</label><label class="expand" for="c-42891120">[1 more]</label></div><br/><div class="children"><div class="content">I think that has more to do with the multiple year head start and multiple tens of billions of dollars in funding advantage.</div><br/></div></div><div id="42891123" class="c"><input type="checkbox" id="c-42891123" checked=""/><div class="controls bullet"><span class="by">joshstrange</span><span>|</span><a href="#42890764">root</a><span>|</span><a href="#42891041">parent</a><span>|</span><a href="#42891120">prev</a><span>|</span><a href="#42891279">next</a><span>|</span><label class="collapse" for="c-42891123">[-]</label><label class="expand" for="c-42891123">[1 more]</label></div><br/><div class="children"><div class="content">And you think that is due to their model naming?</div><br/></div></div><div id="42891279" class="c"><input type="checkbox" id="c-42891279" checked=""/><div class="controls bullet"><span class="by">jcheng</span><span>|</span><a href="#42890764">root</a><span>|</span><a href="#42891041">parent</a><span>|</span><a href="#42891123">prev</a><span>|</span><a href="#42891100">next</a><span>|</span><label class="collapse" for="c-42891279">[-]</label><label class="expand" for="c-42891279">[1 more]</label></div><br/><div class="children"><div class="content">I prefer Anthropic&#x27;s models but ChatGPT (the web interface) is far superior to Claude IMHO. Web search, long-term memory, and chat history sharing are hard to give up.</div><br/></div></div><div id="42891100" class="c"><input type="checkbox" id="c-42891100" checked=""/><div class="controls bullet"><span class="by">KeplerBoy</span><span>|</span><a href="#42890764">root</a><span>|</span><a href="#42891041">parent</a><span>|</span><a href="#42891279">prev</a><span>|</span><a href="#42892293">next</a><span>|</span><label class="collapse" for="c-42891100">[-]</label><label class="expand" for="c-42891100">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s first mover advantage.</div><br/></div></div></div></div></div></div><div id="42892293" class="c"><input type="checkbox" id="c-42892293" checked=""/><div class="controls bullet"><span class="by">FridgeSeal</span><span>|</span><a href="#42890764">root</a><span>|</span><a href="#42890912">parent</a><span>|</span><a href="#42891000">prev</a><span>|</span><a href="#42891522">next</a><span>|</span><label class="collapse" for="c-42892293">[-]</label><label class="expand" for="c-42892293">[1 more]</label></div><br/><div class="children"><div class="content">I think it’s success in spite of branding,  not because of it.<p>This naming scheme is a dumpster fire. Every other comment is trying to untangle what the actual hierarchy of model performance is.</div><br/></div></div><div id="42891522" class="c"><input type="checkbox" id="c-42891522" checked=""/><div class="controls bullet"><span class="by">mrbungie</span><span>|</span><a href="#42890764">root</a><span>|</span><a href="#42890912">parent</a><span>|</span><a href="#42892293">prev</a><span>|</span><a href="#42890816">next</a><span>|</span><label class="collapse" for="c-42891522">[-]</label><label class="expand" for="c-42891522">[4 more]</label></div><br/><div class="children"><div class="content">That&#x27;s like making a second reading and appealing to authority.<p>The naming is bad. Other people already said it you can &quot;google&quot; stuff, you can &quot;deepseek&quot; something, but to &quot;chatgpt&quot; sounds weird.<p>The model naming is even weirder, like, did they really avoid o2 because of oxigen?</div><br/><div id="42891611" class="c"><input type="checkbox" id="c-42891611" checked=""/><div class="controls bullet"><span class="by">sumedh</span><span>|</span><a href="#42890764">root</a><span>|</span><a href="#42891522">parent</a><span>|</span><a href="#42890816">next</a><span>|</span><label class="collapse" for="c-42891611">[-]</label><label class="expand" for="c-42891611">[3 more]</label></div><br/><div class="children"><div class="content">&gt;  but to &quot;chatgpt&quot; sounds weird.<p>People just say it differently, they say &quot;ask chatgpt&quot;</div><br/><div id="42891790" class="c"><input type="checkbox" id="c-42891790" checked=""/><div class="controls bullet"><span class="by">gwd</span><span>|</span><a href="#42890764">root</a><span>|</span><a href="#42891611">parent</a><span>|</span><a href="#42891739">next</a><span>|</span><label class="collapse" for="c-42891790">[-]</label><label class="expand" for="c-42891790">[1 more]</label></div><br/><div class="children"><div class="content">I normally use Claude, but &quot;Ask Claude&quot;, but unless it&#x27;s someone who knows me well, I say &quot;Ask ChatGPT&quot;, or it&#x27;s just not as claer; and I don&#x27;t think it&#x27;s primarily due to popularity.</div><br/></div></div><div id="42891739" class="c"><input type="checkbox" id="c-42891739" checked=""/><div class="controls bullet"><span class="by">mrbungie</span><span>|</span><a href="#42890764">root</a><span>|</span><a href="#42891611">parent</a><span>|</span><a href="#42891790">prev</a><span>|</span><a href="#42890816">next</a><span>|</span><label class="collapse" for="c-42891739">[-]</label><label class="expand" for="c-42891739">[1 more]</label></div><br/><div class="children"><div class="content">Obviously they do. That&#x27;s the whole point.</div><br/></div></div></div></div></div></div></div></div><div id="42890816" class="c"><input type="checkbox" id="c-42890816" checked=""/><div class="controls bullet"><span class="by">kingnothing</span><span>|</span><a href="#42890764">parent</a><span>|</span><a href="#42890912">prev</a><span>|</span><a href="#42891137">next</a><span>|</span><label class="collapse" for="c-42890816">[-]</label><label class="expand" for="c-42890816">[32 more]</label></div><br/><div class="children"><div class="content">They really need someone in marketing.<p>If the model is for technical stuff, then call it the technical model. How is anyone supposed to know what these model names mean?<p>The only page of theirs attempting to explain this is a total disaster. <a href="https:&#x2F;&#x2F;platform.openai.com&#x2F;docs&#x2F;models" rel="nofollow">https:&#x2F;&#x2F;platform.openai.com&#x2F;docs&#x2F;models</a></div><br/><div id="42890908" class="c"><input type="checkbox" id="c-42890908" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#42890764">root</a><span>|</span><a href="#42890816">parent</a><span>|</span><a href="#42890843">next</a><span>|</span><label class="collapse" for="c-42890908">[-]</label><label class="expand" for="c-42890908">[3 more]</label></div><br/><div class="children"><div class="content">&gt; <i>How is anyone supposed to know what these model names mean?</i><p>Normies don&#x27;t have to know - ChatGPT app focuses UX around capabilities and automatically picks the appropriate model for capabilities requested; you can see which model you&#x27;re using and change it, but <i>don&#x27;t need to</i>.<p>As for the techies and self-proclaimed &quot;AI experts&quot; - OpenAI is the leader in the field, and one of the most well-known and talked about tech companies in history. Whether to use, praise or criticize, this group of users is motivated to figure it out on their own.<p>It&#x27;s the privilege of fashionable companies. They could name the next model ↂ-↊↋, and it&#x27;ll take all of five minutes for everyone in tech (and everyone on LinkedIn) to learn how to type in the right Unicode characters.<p>EDIT: Originally I wrote \Omega-↊↋, but apparently HN&#x27;s Unicode filter extends to Greek alphabet now? &#x27;dang?</div><br/><div id="42891168" class="c"><input type="checkbox" id="c-42891168" checked=""/><div class="controls bullet"><span class="by">relaxing</span><span>|</span><a href="#42890764">root</a><span>|</span><a href="#42890908">parent</a><span>|</span><a href="#42890843">next</a><span>|</span><label class="collapse" for="c-42891168">[-]</label><label class="expand" for="c-42891168">[2 more]</label></div><br/><div class="children"><div class="content">What if you use ASCII 234? Ω
(edit: works!)</div><br/><div id="42891363" class="c"><input type="checkbox" id="c-42891363" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#42890764">root</a><span>|</span><a href="#42891168">parent</a><span>|</span><a href="#42890843">next</a><span>|</span><label class="collapse" for="c-42891363">[-]</label><label class="expand" for="c-42891363">[1 more]</label></div><br/><div class="children"><div class="content">Thanks! I copied mine from Wikipedia (like I typically do with Unicode characters I rarely use), where it is also Ω - the same character. For a moment I was worried I somehow got it mixed up with the Ohm symbol but I didn&#x27;t. Not sure what happened here.</div><br/></div></div></div></div></div></div><div id="42890843" class="c"><input type="checkbox" id="c-42890843" checked=""/><div class="controls bullet"><span class="by">n2d4</span><span>|</span><a href="#42890764">root</a><span>|</span><a href="#42890816">parent</a><span>|</span><a href="#42890908">prev</a><span>|</span><a href="#42890897">next</a><span>|</span><label class="collapse" for="c-42890843">[-]</label><label class="expand" for="c-42890843">[3 more]</label></div><br/><div class="children"><div class="content">&gt; They really need someone in marketing.<p>Who said this is not intentional? It seems to work well given that people are hyped every time there&#x27;s a release, no matter how big the actual improvements are — I&#x27;m pretty sure &quot;o3-mini&quot; works better for that purpose than &quot;GPT 4.1.3&quot;</div><br/><div id="42890885" class="c"><input type="checkbox" id="c-42890885" checked=""/><div class="controls bullet"><span class="by">fkyoureadthedoc</span><span>|</span><a href="#42890764">root</a><span>|</span><a href="#42890843">parent</a><span>|</span><a href="#42890897">next</a><span>|</span><label class="collapse" for="c-42890885">[-]</label><label class="expand" for="c-42890885">[2 more]</label></div><br/><div class="children"><div class="content">&gt; I&#x27;m pretty sure &quot;o3-mini&quot; works better for that purpose than &quot;GPT 4.1.3&quot;<p>Why would the marketing team of all people call it GPT 4.1.3?</div><br/><div id="42892864" class="c"><input type="checkbox" id="c-42892864" checked=""/><div class="controls bullet"><span class="by">n2d4</span><span>|</span><a href="#42890764">root</a><span>|</span><a href="#42890885">parent</a><span>|</span><a href="#42890897">next</a><span>|</span><label class="collapse" for="c-42892864">[-]</label><label class="expand" for="c-42892864">[1 more]</label></div><br/><div class="children"><div class="content">They wouldn&#x27;t! They would call it o3-mini, even though GPT 4.1.3 may or may not &quot;make more sense&quot; from a technical perspective.</div><br/></div></div></div></div></div></div><div id="42890897" class="c"><input type="checkbox" id="c-42890897" checked=""/><div class="controls bullet"><span class="by">golly_ned</span><span>|</span><a href="#42890764">root</a><span>|</span><a href="#42890816">parent</a><span>|</span><a href="#42890843">prev</a><span>|</span><a href="#42890838">next</a><span>|</span><label class="collapse" for="c-42890897">[-]</label><label class="expand" for="c-42890897">[7 more]</label></div><br/><div class="children"><div class="content">Yes, this $300Bn company generating +$3.4Bn in revenue needs to hire marketing expert. They can begin by sourcing ideas from us here to save their struggling business from total marketing disaster.</div><br/><div id="42890972" class="c"><input type="checkbox" id="c-42890972" checked=""/><div class="controls bullet"><span class="by">winrid</span><span>|</span><a href="#42890764">root</a><span>|</span><a href="#42890897">parent</a><span>|</span><a href="#42891515">next</a><span>|</span><label class="collapse" for="c-42890972">[-]</label><label class="expand" for="c-42890972">[3 more]</label></div><br/><div class="children"><div class="content">At the least they should care more about UX. I have no idea how to restore the sidebar on chatgpt on desktop lol</div><br/><div id="42891339" class="c"><input type="checkbox" id="c-42891339" checked=""/><div class="controls bullet"><span class="by">Legend2440</span><span>|</span><a href="#42890764">root</a><span>|</span><a href="#42890972">parent</a><span>|</span><a href="#42891515">next</a><span>|</span><label class="collapse" for="c-42891339">[-]</label><label class="expand" for="c-42891339">[2 more]</label></div><br/><div class="children"><div class="content">Click the &#x27;open sidebar&#x27; icon in the top left corner of the screen.</div><br/><div id="42892448" class="c"><input type="checkbox" id="c-42892448" checked=""/><div class="controls bullet"><span class="by">winrid</span><span>|</span><a href="#42890764">root</a><span>|</span><a href="#42891339">parent</a><span>|</span><a href="#42891515">next</a><span>|</span><label class="collapse" for="c-42892448">[-]</label><label class="expand" for="c-42892448">[1 more]</label></div><br/><div class="children"><div class="content">There isn&#x27;t one, unless they fixed it today.  Just a down arrow to change the model.</div><br/></div></div></div></div></div></div><div id="42891515" class="c"><input type="checkbox" id="c-42891515" checked=""/><div class="controls bullet"><span class="by">avs733</span><span>|</span><a href="#42890764">root</a><span>|</span><a href="#42890897">parent</a><span>|</span><a href="#42890972">prev</a><span>|</span><a href="#42891038">next</a><span>|</span><label class="collapse" for="c-42891515">[-]</label><label class="expand" for="c-42891515">[1 more]</label></div><br/><div class="children"><div class="content">Hype based marketing can be effective but it is high risk and unstable.<p>A marketing team isn’t a generality that makes a company known, it often focuses on communicating what products different types of customers need from your lineup.<p>If I sell three medications:<p>Steve<p>56285<p>Priximetrin<p>And only tell you they are all pain killers but for different types and levels of pain I’m going to leave revenue on the floor. That is no matter how valuable my business is or how well it’s known.</div><br/></div></div><div id="42891038" class="c"><input type="checkbox" id="c-42891038" checked=""/><div class="controls bullet"><span class="by">optimalsolver</span><span>|</span><a href="#42890764">root</a><span>|</span><a href="#42890897">parent</a><span>|</span><a href="#42891515">prev</a><span>|</span><a href="#42891031">next</a><span>|</span><label class="collapse" for="c-42891038">[-]</label><label class="expand" for="c-42891038">[1 more]</label></div><br/><div class="children"><div class="content">&gt;this $300Bn company<p>Watch this space.</div><br/></div></div></div></div><div id="42890838" class="c"><input type="checkbox" id="c-42890838" checked=""/><div class="controls bullet"><span class="by">ninetyninenine</span><span>|</span><a href="#42890764">root</a><span>|</span><a href="#42890816">parent</a><span>|</span><a href="#42890897">prev</a><span>|</span><a href="#42890851">next</a><span>|</span><label class="collapse" for="c-42890838">[-]</label><label class="expand" for="c-42890838">[7 more]</label></div><br/><div class="children"><div class="content">I bet you can get one of their models to fix that disaster.</div><br/><div id="42890846" class="c"><input type="checkbox" id="c-42890846" checked=""/><div class="controls bullet"><span class="by">ryanhecht</span><span>|</span><a href="#42890764">root</a><span>|</span><a href="#42890838">parent</a><span>|</span><a href="#42890851">next</a><span>|</span><label class="collapse" for="c-42890846">[-]</label><label class="expand" for="c-42890846">[6 more]</label></div><br/><div class="children"><div class="content">But what would we call that model?</div><br/><div id="42890923" class="c"><input type="checkbox" id="c-42890923" checked=""/><div class="controls bullet"><span class="by">ninetyninenine</span><span>|</span><a href="#42890764">root</a><span>|</span><a href="#42890846">parent</a><span>|</span><a href="#42890903">next</a><span>|</span><label class="collapse" for="c-42890923">[-]</label><label class="expand" for="c-42890923">[3 more]</label></div><br/><div class="children"><div class="content">Let’s call it “O5 Pro Max Elite”—because if nonsense naming works for smartphones, why not AI models?</div><br/><div id="42891052" class="c"><input type="checkbox" id="c-42891052" checked=""/><div class="controls bullet"><span class="by">ryandrake</span><span>|</span><a href="#42890764">root</a><span>|</span><a href="#42890923">parent</a><span>|</span><a href="#42890903">next</a><span>|</span><label class="collapse" for="c-42891052">[-]</label><label class="expand" for="c-42891052">[2 more]</label></div><br/><div class="children"><div class="content">O5 Pro Max Elite Enterprise Edition with Ultra</div><br/><div id="42891122" class="c"><input type="checkbox" id="c-42891122" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#42890764">root</a><span>|</span><a href="#42891052">parent</a><span>|</span><a href="#42890903">next</a><span>|</span><label class="collapse" for="c-42891122">[-]</label><label class="expand" for="c-42891122">[1 more]</label></div><br/><div class="children"><div class="content">Maybe they could start selling &quot;season passes&quot; next to make their offering even more clear!</div><br/></div></div></div></div></div></div><div id="42890903" class="c"><input type="checkbox" id="c-42890903" checked=""/><div class="controls bullet"><span class="by">aleph_minus_one</span><span>|</span><a href="#42890764">root</a><span>|</span><a href="#42890846">parent</a><span>|</span><a href="#42890923">prev</a><span>|</span><a href="#42890851">next</a><span>|</span><label class="collapse" for="c-42890903">[-]</label><label class="expand" for="c-42890903">[2 more]</label></div><br/><div class="children"><div class="content">&gt; But what would we call that model?<p>Ask one of their models for advice. :-)</div><br/><div id="42890968" class="c"><input type="checkbox" id="c-42890968" checked=""/><div class="controls bullet"><span class="by">ryanhecht</span><span>|</span><a href="#42890764">root</a><span>|</span><a href="#42890903">parent</a><span>|</span><a href="#42890851">next</a><span>|</span><label class="collapse" for="c-42890968">[-]</label><label class="expand" for="c-42890968">[1 more]</label></div><br/><div class="children"><div class="content">Reminds me of a joke in the musical &quot;How to Succeed in Business Without Really Trying&quot; (written in 1961):<p>PETERSON
Oh say, Tackaberry, did you get my memo?<p>TACKABERRY
What memo?<p>PETERSON
My memo about memos. We&#x27;re sending out too many memos and it&#x27;s got to stop!<p>TACKABERRY
All right. I&#x27;ll send out a memo.</div><br/></div></div></div></div></div></div></div></div><div id="42890834" class="c"><input type="checkbox" id="c-42890834" checked=""/><div class="controls bullet"><span class="by">rowanG077</span><span>|</span><a href="#42890764">root</a><span>|</span><a href="#42890816">parent</a><span>|</span><a href="#42890851">prev</a><span>|</span><a href="#42890929">next</a><span>|</span><label class="collapse" for="c-42890834">[-]</label><label class="expand" for="c-42890834">[2 more]</label></div><br/><div class="children"><div class="content">If marketing terms from intel, AMD, Dell and other tech companies have taught me anything, it&#x27;s that they need LESS of people in marketing.</div><br/><div id="42891059" class="c"><input type="checkbox" id="c-42891059" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#42890764">root</a><span>|</span><a href="#42890834">parent</a><span>|</span><a href="#42890929">next</a><span>|</span><label class="collapse" for="c-42891059">[-]</label><label class="expand" for="c-42891059">[1 more]</label></div><br/><div class="children"><div class="content">But think of all the other marketers whose job is to produce blogspam explaining confusing product names!</div><br/></div></div></div></div><div id="42890929" class="c"><input type="checkbox" id="c-42890929" checked=""/><div class="controls bullet"><span class="by">koakuma-chan</span><span>|</span><a href="#42890764">root</a><span>|</span><a href="#42890816">parent</a><span>|</span><a href="#42890834">prev</a><span>|</span><a href="#42890869">next</a><span>|</span><label class="collapse" for="c-42890929">[-]</label><label class="expand" for="c-42890929">[7 more]</label></div><br/><div class="children"><div class="content">Name is just a label. It&#x27;s not supposed to mean anything.</div><br/><div id="42890948" class="c"><input type="checkbox" id="c-42890948" checked=""/><div class="controls bullet"><span class="by">ninetyninenine</span><span>|</span><a href="#42890764">root</a><span>|</span><a href="#42890929">parent</a><span>|</span><a href="#42891044">next</a><span>|</span><label class="collapse" for="c-42890948">[-]</label><label class="expand" for="c-42890948">[3 more]</label></div><br/><div class="children"><div class="content">Think how awesome the world would be if labels ALSO had meanings.</div><br/><div id="42891020" class="c"><input type="checkbox" id="c-42891020" checked=""/><div class="controls bullet"><span class="by">koakuma-chan</span><span>|</span><a href="#42890764">root</a><span>|</span><a href="#42890948">parent</a><span>|</span><a href="#42891044">next</a><span>|</span><label class="collapse" for="c-42891020">[-]</label><label class="expand" for="c-42891020">[2 more]</label></div><br/><div class="children"><div class="content">As someone else said in another thread, if you could derive the definition from a word, the word would be as long as the definition, which would defeat the purpose.</div><br/><div id="42892652" class="c"><input type="checkbox" id="c-42892652" checked=""/><div class="controls bullet"><span class="by">ninetyninenine</span><span>|</span><a href="#42890764">root</a><span>|</span><a href="#42891020">parent</a><span>|</span><a href="#42891044">next</a><span>|</span><label class="collapse" for="c-42892652">[-]</label><label class="expand" for="c-42892652">[1 more]</label></div><br/><div class="children"><div class="content">Im not saying words. Im saying labels.<p>You use words as labels so that we use our pre existing knowledge of the word to derive meaning from the label.</div><br/></div></div></div></div></div></div><div id="42891044" class="c"><input type="checkbox" id="c-42891044" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#42890764">root</a><span>|</span><a href="#42890929">parent</a><span>|</span><a href="#42890948">prev</a><span>|</span><a href="#42890869">next</a><span>|</span><label class="collapse" for="c-42891044">[-]</label><label class="expand" for="c-42891044">[3 more]</label></div><br/><div class="children"><div class="content">There is no such thing. &quot;Meaning&quot; isn&#x27;t a property of a label, it arises from how that label is used with other labels in communication.<p>It&#x27;s actually the reason LLMs work in the first place.</div><br/><div id="42891103" class="c"><input type="checkbox" id="c-42891103" checked=""/><div class="controls bullet"><span class="by">optimalsolver</span><span>|</span><a href="#42890764">root</a><span>|</span><a href="#42891044">parent</a><span>|</span><a href="#42890869">next</a><span>|</span><label class="collapse" for="c-42891103">[-]</label><label class="expand" for="c-42891103">[2 more]</label></div><br/><div class="children"><div class="content">You&#x27;re gonna need to ground those labels in something physical at some point.<p>No one&#x27;s going to let an LLM near anything important until then.</div><br/><div id="42891135" class="c"><input type="checkbox" id="c-42891135" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#42890764">root</a><span>|</span><a href="#42891103">parent</a><span>|</span><a href="#42890869">next</a><span>|</span><label class="collapse" for="c-42891135">[-]</label><label class="expand" for="c-42891135">[1 more]</label></div><br/><div class="children"><div class="content">You only need it for bootstrapping. Fortunately, we&#x27;ve already done that when we invented first languages. LLMs are just bootstrapping off us.</div><br/></div></div></div></div></div></div></div></div><div id="42890869" class="c"><input type="checkbox" id="c-42890869" checked=""/><div class="controls bullet"><span class="by">ryanhecht</span><span>|</span><a href="#42890764">root</a><span>|</span><a href="#42890816">parent</a><span>|</span><a href="#42890929">prev</a><span>|</span><a href="#42891137">next</a><span>|</span><label class="collapse" for="c-42890869">[-]</label><label class="expand" for="c-42890869">[1 more]</label></div><br/><div class="children"><div class="content">Ugh, and some of the rows of that table are &quot;sets of models&quot; while some are singular models...there&#x27;s the &quot;Flagship models&quot; section at the top only for &quot;GPT models&quot; to be heralded as &quot;Our fast, versatile, high intelligence flagship models&quot; in the NEXT section...<p>...I like &quot;DALL·E&quot; and &quot;Whisper&quot; as names a lot, though, FWIW :p</div><br/></div></div></div></div><div id="42891137" class="c"><input type="checkbox" id="c-42891137" checked=""/><div class="controls bullet"><span class="by">fourseventy</span><span>|</span><a href="#42890764">parent</a><span>|</span><a href="#42890816">prev</a><span>|</span><a href="#42891010">next</a><span>|</span><label class="collapse" for="c-42891137">[-]</label><label class="expand" for="c-42891137">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s almost as bad as the Xbox naming scheme.</div><br/><div id="42891386" class="c"><input type="checkbox" id="c-42891386" checked=""/><div class="controls bullet"><span class="by">Someone1234</span><span>|</span><a href="#42890764">root</a><span>|</span><a href="#42891137">parent</a><span>|</span><a href="#42891010">next</a><span>|</span><label class="collapse" for="c-42891386">[-]</label><label class="expand" for="c-42891386">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t know if anything is as bad as a games console named &quot;Series.&quot;</div><br/></div></div></div></div><div id="42891010" class="c"><input type="checkbox" id="c-42891010" checked=""/><div class="controls bullet"><span class="by">observationist</span><span>|</span><a href="#42890764">parent</a><span>|</span><a href="#42891137">prev</a><span>|</span><a href="#42890880">next</a><span>|</span><label class="collapse" for="c-42891010">[-]</label><label class="expand" for="c-42891010">[4 more]</label></div><br/><div class="children"><div class="content">They should be calling it ChatGPT and ChatGPT-mini, with other models hidden behind some sort of advanced mode power user menu. They can roll out major and minor updates by number. The whole point of differentiating between models is to get users to self limit the compute they consume - rate limits make people avoid using the more powerful models, and if they have a bad experience using the less capable models, or if they&#x27;re frustrated by hopping between versions without some sort of nuanced technical understanding, it&#x27;s just a bad experience overall.<p>OpenAI is so scattered they haven&#x27;t even bothered using their own state of the art AI to come up with a coherent naming convention? C&#x27;mon, get your shit together.</div><br/><div id="42891099" class="c"><input type="checkbox" id="c-42891099" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#42890764">root</a><span>|</span><a href="#42891010">parent</a><span>|</span><a href="#42890880">next</a><span>|</span><label class="collapse" for="c-42891099">[-]</label><label class="expand" for="c-42891099">[3 more]</label></div><br/><div class="children"><div class="content">&quot;ChatGPT&quot; (chatgpt-4o) is now its own model, distinct from gpt-4o.<p>As for self-limiting usage by non-power users, they&#x27;re already doing that: ChatGPT app automatically picks a model depending on what capabilities you invoke. While they provide a limited ability to see and switch the model in use, they&#x27;re clearly expecting regular users not to care, and design their app around that.</div><br/><div id="42892197" class="c"><input type="checkbox" id="c-42892197" checked=""/><div class="controls bullet"><span class="by">observationist</span><span>|</span><a href="#42890764">root</a><span>|</span><a href="#42891099">parent</a><span>|</span><a href="#42890880">next</a><span>|</span><label class="collapse" for="c-42892197">[-]</label><label class="expand" for="c-42892197">[2 more]</label></div><br/><div class="children"><div class="content">None of that matters to normal users, and you could satisfy power users with serial numbers or even unique ideograms. Naming isn&#x27;t <i>that</i> hard, and their models are surprisingly adept at it. A consistent naming scheme improves customer experience by preventing confusion - when a new model comes out, I field questions for days from friends and family - &quot;what does this mean? which model should i use? Aww, I have to download another update?&quot; and so on. None of the stated reasons for not having a coherent naming convention for their models are valid. I&#x27;d be upset as a stakeholder, they&#x27;re burning credibility and marketing power for no good reason.<p>modelname(variant).majorVersion.minorVersion
ChatGPT(o).3.0
ChatGPT-mini(o).3.0
GPT.2.123
GPT.3.9<p>And so on. Once it&#x27;s coherent, people pick it up, and naturally call the model by &quot;modelname majorversion&quot; , and there&#x27;s no confusion or hesitance about which is which. See, it took me 2 minutes.<p>Even better: Have an OAI slack discussion company-wide, then have managers summarize their team&#x27;s discussions into a prompt demonstrating what features they want out of it, then run all the prompts together and tell the AI to put together 3 different naming schemes based on all the features the employees want. Roll out a poll and have employees vote which of the 3 gets used going forward. Or just tap into that founder mode and pick one like a boss.<p>Don&#x27;t get me wrong, I love using AI - we are smack dab in the middle of a revolution and normal people aren&#x27;t quite catching on yet, so it&#x27;s exhilarating and empowering to be able to use this stuff, like being one of the early users of the internet. We can see what&#x27;s coming, and if you lived through the internet growing up, you know there&#x27;s going to be massive, unexpected synergies and developments of systems and phenomena we don&#x27;t yet have the words for.<p>OpenAI can do better, and they should.</div><br/><div id="42893148" class="c"><input type="checkbox" id="c-42893148" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#42890764">root</a><span>|</span><a href="#42892197">parent</a><span>|</span><a href="#42890880">next</a><span>|</span><label class="collapse" for="c-42893148">[-]</label><label class="expand" for="c-42893148">[1 more]</label></div><br/><div class="children"><div class="content">I agree with your observations, and that they both could and should do better. However, they have the privilege of being <i>the</i> AI company, the most hyped-up brand in the most hyped-up segment of economy - at this point, the impact of their naming strategy is approximately nil. Sure, they&#x27;re confusing their users a bit, but their users are <i>very highly motivated</i>.<p>It&#x27;s like with videogames - most of them commit all kinds of UI&#x2F;UX sins, and I often wish they didn&#x27;t, but excepting extreme cases, the players are too motivated to care or notice.</div><br/></div></div></div></div></div></div></div></div><div id="42890880" class="c"><input type="checkbox" id="c-42890880" checked=""/><div class="controls bullet"><span class="by">layer8</span><span>|</span><a href="#42890764">parent</a><span>|</span><a href="#42891010">prev</a><span>|</span><a href="#42892358">next</a><span>|</span><label class="collapse" for="c-42890880">[-]</label><label class="expand" for="c-42890880">[3 more]</label></div><br/><div class="children"><div class="content">Inscrutable naming is a proven strategy for muddying the waters.</div><br/><div id="42891131" class="c"><input type="checkbox" id="c-42891131" checked=""/><div class="controls bullet"><span class="by">jtwaleson</span><span>|</span><a href="#42890764">root</a><span>|</span><a href="#42890880">parent</a><span>|</span><a href="#42892358">next</a><span>|</span><label class="collapse" for="c-42891131">[-]</label><label class="expand" for="c-42891131">[2 more]</label></div><br/><div class="children"><div class="content">Salesforce would like a word...</div><br/><div id="42891187" class="c"><input type="checkbox" id="c-42891187" checked=""/><div class="controls bullet"><span class="by">SAI_Peregrinus</span><span>|</span><a href="#42890764">root</a><span>|</span><a href="#42891131">parent</a><span>|</span><a href="#42892358">next</a><span>|</span><label class="collapse" for="c-42891187">[-]</label><label class="expand" for="c-42891187">[1 more]</label></div><br/><div class="children"><div class="content">The USB-IF as well. Retroactively changing the name of a previous standard was particularly ridiculous. It&#x27;s always been USB 3.1 Gen 1 like we&#x27;ve always been at war with Eastasia.</div><br/></div></div></div></div></div></div></div></div><div id="42892358" class="c"><input type="checkbox" id="c-42892358" checked=""/><div class="controls bullet"><span class="by">diegocg</span><span>|</span><a href="#42890764">prev</a><span>|</span><a href="#42893142">next</a><span>|</span><label class="collapse" for="c-42892358">[-]</label><label class="expand" for="c-42892358">[3 more]</label></div><br/><div class="children"><div class="content">I hope chatgpt reconsiders the naming of their models some time. I have troubles deciding which model is the one I should use.</div><br/><div id="42893199" class="c"><input type="checkbox" id="c-42893199" checked=""/><div class="controls bullet"><span class="by">esafak</span><span>|</span><a href="#42892358">parent</a><span>|</span><a href="#42893142">next</a><span>|</span><label class="collapse" for="c-42893199">[-]</label><label class="expand" for="c-42893199">[2 more]</label></div><br/><div class="children"><div class="content">They release models too often for a new one to be better at everything, so you have to pick the right one for your task.</div><br/><div id="42894109" class="c"><input type="checkbox" id="c-42894109" checked=""/><div class="controls bullet"><span class="by">niek_pas</span><span>|</span><a href="#42892358">root</a><span>|</span><a href="#42893199">parent</a><span>|</span><a href="#42893142">next</a><span>|</span><label class="collapse" for="c-42894109">[-]</label><label class="expand" for="c-42894109">[1 more]</label></div><br/><div class="children"><div class="content">And that’s exactly where good, recognizable branding comes in.</div><br/></div></div></div></div></div></div><div id="42893142" class="c"><input type="checkbox" id="c-42893142" checked=""/><div class="controls bullet"><span class="by">antirez</span><span>|</span><a href="#42892358">prev</a><span>|</span><a href="#42890786">next</a><span>|</span><label class="collapse" for="c-42893142">[-]</label><label class="expand" for="c-42893142">[1 more]</label></div><br/><div class="children"><div class="content">Just tested two complicated coding tasks, and surprisingly o3-mini-high nailed it while Sonnet 3.5 failed it. Will do more tests tomorrow.</div><br/></div></div><div id="42890786" class="c"><input type="checkbox" id="c-42890786" checked=""/><div class="controls bullet"><span class="by">airstrike</span><span>|</span><a href="#42893142">prev</a><span>|</span><a href="#42896732">next</a><span>|</span><label class="collapse" for="c-42890786">[-]</label><label class="expand" for="c-42890786">[5 more]</label></div><br/><div class="children"><div class="content">Hopefully this is a big improvement from o1.<p>o1 has been very disappointing after spending sufficient time with Claude Sonnet 3.5. It&#x27;s like it actively tries to gaslight me and thinks it knows more than I do. It&#x27;s too stubborn and confidently goes off in tangents, suggesting big changes to parts of the code that aren&#x27;t the issue. Claude tends to be way better at putting the pieces together in its not-quite-mental-model, so to speak.<p>I told o1 that a suggestion it gave me didn&#x27;t work and it said &quot;if it&#x27;s still &#x27;doesn&#x27;t work&#x27; in your setup...&quot; with &quot;doesn&#x27;t work&quot; in quotes like it was doubting me... I&#x27;ve canceled my ChatGPT subscription and, when I really need to use it, just go with GPT-4o instead.</div><br/><div id="42891365" class="c"><input type="checkbox" id="c-42891365" checked=""/><div class="controls bullet"><span class="by">Deegy</span><span>|</span><a href="#42890786">parent</a><span>|</span><a href="#42896732">next</a><span>|</span><label class="collapse" for="c-42891365">[-]</label><label class="expand" for="c-42891365">[4 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve also noticed that with cGPT.<p>That said I often run into a sort of opposite issue with Claude. It&#x27;s very good at making me feel like a genius. Sometimes I&#x27;ll suggest trying a specific strategy or trying to define a concept on my own, and Claude enthusiastically agrees and takes us down a 2-3 hour rabbit hole that ends up being quite a waste of time for me to back track out of.<p>I&#x27;ll then run a post-mortem through chatGPT and very often it points out the issue in my thinking very quickly.<p>That said I keep coming back to sonnet-3.5 for reasons I can&#x27;t perfectly articulate. Perhaps because I like how it fluffs my ego lol. ChatGPT on the other hand feels a bit more brash. I do wonder if I should be using o1 as my daily driver.<p>I also don&#x27;t have enough experience with o1 to determine if it would also take me down dead ends as well.</div><br/><div id="42892380" class="c"><input type="checkbox" id="c-42892380" checked=""/><div class="controls bullet"><span class="by">bazmattaz</span><span>|</span><a href="#42890786">root</a><span>|</span><a href="#42891365">parent</a><span>|</span><a href="#42894152">next</a><span>|</span><label class="collapse" for="c-42892380">[-]</label><label class="expand" for="c-42892380">[1 more]</label></div><br/><div class="children"><div class="content">Really interesting point you make about Claude. I’ve experienced the same. What is interesting is that sometimes I’ll question it and say “would it not be better to do it this way” and all of a sudden Claude u-turns and says “yes great idea that’s actually a much better approach” which leaves me thinking; are you just stroking my ego, if it’s a better approach then why didn’t you suggest it?<p>However I have suggested worse approaches on purpose and sometime Claude does pick them up as less than optimal</div><br/></div></div><div id="42894152" class="c"><input type="checkbox" id="c-42894152" checked=""/><div class="controls bullet"><span class="by">mordae</span><span>|</span><a href="#42890786">root</a><span>|</span><a href="#42891365">parent</a><span>|</span><a href="#42892380">prev</a><span>|</span><a href="#42893476">next</a><span>|</span><label class="collapse" for="c-42894152">[-]</label><label class="expand" for="c-42894152">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a little sycophant.<p>But the difference is that it actually asks questions. And also that it actually rolls with what you ask it to do. Other models are stubborn and loopy.</div><br/></div></div><div id="42893476" class="c"><input type="checkbox" id="c-42893476" checked=""/><div class="controls bullet"><span class="by">airstrike</span><span>|</span><a href="#42890786">root</a><span>|</span><a href="#42891365">parent</a><span>|</span><a href="#42894152">prev</a><span>|</span><a href="#42896732">next</a><span>|</span><label class="collapse" for="c-42893476">[-]</label><label class="expand" for="c-42893476">[1 more]</label></div><br/><div class="children"><div class="content">I agree with this but o1 will <i>also</i> confidently take you into rabbit holes. You&#x27;ll just feel worse about it lol and when you ask Claude for a post mortem, it too will find the answer you missed quickly<p>The truth is these models are very stochastic you have to try new chats whenever you even moderately suspect you&#x27;re going awry</div><br/></div></div></div></div></div></div><div id="42896732" class="c"><input type="checkbox" id="c-42896732" checked=""/><div class="controls bullet"><span class="by">anoncow</span><span>|</span><a href="#42890786">prev</a><span>|</span><a href="#42890709">next</a><span>|</span><label class="collapse" for="c-42896732">[-]</label><label class="expand" for="c-42896732">[1 more]</label></div><br/><div class="children"><div class="content">How long before o3 is available in GitHub copilot?</div><br/></div></div><div id="42890709" class="c"><input type="checkbox" id="c-42890709" checked=""/><div class="controls bullet"><span class="by">xyzzy9563</span><span>|</span><a href="#42896732">prev</a><span>|</span><a href="#42891161">next</a><span>|</span><label class="collapse" for="c-42890709">[-]</label><label class="expand" for="c-42890709">[6 more]</label></div><br/><div class="children"><div class="content">What is the comparison of this versus DeepSeek in terms of good results and cost?</div><br/><div id="42891190" class="c"><input type="checkbox" id="c-42891190" checked=""/><div class="controls bullet"><span class="by">Synaesthesia</span><span>|</span><a href="#42890709">parent</a><span>|</span><a href="#42891028">next</a><span>|</span><label class="collapse" for="c-42891190">[-]</label><label class="expand" for="c-42891190">[4 more]</label></div><br/><div class="children"><div class="content">Deepseek is the state of the art right now in terms of performance and output. It&#x27;s really fast. The way it &quot;explains&quot; how it&#x27;s thinking is remarkable.</div><br/><div id="42891459" class="c"><input type="checkbox" id="c-42891459" checked=""/><div class="controls bullet"><span class="by">fpgaminer</span><span>|</span><a href="#42890709">root</a><span>|</span><a href="#42891190">parent</a><span>|</span><a href="#42891028">next</a><span>|</span><label class="collapse" for="c-42891459">[-]</label><label class="expand" for="c-42891459">[3 more]</label></div><br/><div class="children"><div class="content">DeepSeek is great because: 1) you can run the model locally, 2) the research was openly shared, and 3) the reasoning tokens are open.  It is not, in my experience, state of the art.  In all of my side by side comparisons thus far in real world applications between DeepSeek V3 and R1 vs 4o and o1, the latter has always performed better.  OpenAI&#x27;s models are also more consistent, glitching out maybe one in 10,000, whereas DeepSeek&#x27;s models will glitch out 1 in 20.  OpenAI models also handle edge cases better and have a better overall grasp of user intentions.  I&#x27;ve had DeepSeek&#x27;s models consistently misinterpret prompts, or confuse data in the prompts with instructions.  Those are both very important things that make DeepSeek useless for real world applications.  At least without finetuning them, which then requires using those huge 600B parameter models locally.<p>So it is by no means state of the art.  Gemini Flash 2.0 also performs better than DeepSeek V3 in all my comparisons thus far.  But Gemini Flash 2.0 isn&#x27;t robust and reliable either.<p>But as a piece of research, and a cool toy to play with, I think DeepSeek is great.</div><br/><div id="42893398" class="c"><input type="checkbox" id="c-42893398" checked=""/><div class="controls bullet"><span class="by">Synaesthesia</span><span>|</span><a href="#42890709">root</a><span>|</span><a href="#42891459">parent</a><span>|</span><a href="#42891910">next</a><span>|</span><label class="collapse" for="c-42893398">[-]</label><label class="expand" for="c-42893398">[1 more]</label></div><br/><div class="children"><div class="content">I watched it complete pretty complicated tasks like &quot;write a snake game in Python&quot; and &quot;write Tetris in Python&quot; successfully. And the way it did it, with showing all the internal steps, I&#x27;ve never seen before.<p>Watch here. <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=by9PUlqtJlM" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=by9PUlqtJlM</a></div><br/></div></div><div id="42891910" class="c"><input type="checkbox" id="c-42891910" checked=""/><div class="controls bullet"><span class="by">Aperocky</span><span>|</span><a href="#42890709">root</a><span>|</span><a href="#42891459">parent</a><span>|</span><a href="#42893398">prev</a><span>|</span><a href="#42891028">next</a><span>|</span><label class="collapse" for="c-42891910">[-]</label><label class="expand" for="c-42891910">[1 more]</label></div><br/><div class="children"><div class="content">&gt; which then requires using those huge 600B parameter models locally.<p>Are you running the smaller models locally? Doesn&#x27;t seems unfair to compare it against 4o and o1 behind OpenAI APIs.</div><br/></div></div></div></div></div></div><div id="42891028" class="c"><input type="checkbox" id="c-42891028" checked=""/><div class="controls bullet"><span class="by">reissbaker</span><span>|</span><a href="#42890709">parent</a><span>|</span><a href="#42891190">prev</a><span>|</span><a href="#42891161">next</a><span>|</span><label class="collapse" for="c-42891028">[-]</label><label class="expand" for="c-42891028">[1 more]</label></div><br/><div class="children"><div class="content">Probably a good idea to wait for external benchmarks like Aider, but my guess is it&#x27;ll be somewhere between DeepSeek V3 and R1 in terms of benchmarks — R1 trades blows with o1-high, and V3 is somewhat lower — but I&#x27;d expect o3-mini to be considerably faster. Despite the blog post saying paid users can access o3-mini today, I don&#x27;t see it as an option yet in their UI... But IIRC when they announced o3-mini in December they claimed it would be similar to 4o in terms of overall latency, and 4o is much faster than V3&#x2F;R1 currently.</div><br/></div></div></div></div><div id="42891161" class="c"><input type="checkbox" id="c-42891161" checked=""/><div class="controls bullet"><span class="by">isusmelj</span><span>|</span><a href="#42890709">prev</a><span>|</span><a href="#42890909">next</a><span>|</span><label class="collapse" for="c-42891161">[-]</label><label class="expand" for="c-42891161">[3 more]</label></div><br/><div class="children"><div class="content">Does anyone know why GPT4 has knowledge cutoff December 2023 and all the other models (newer ones like 4o, O1, O3) seem to have knowledge cutoff October 2023?
<a href="https:&#x2F;&#x2F;platform.openai.com&#x2F;docs&#x2F;models#o3-mini" rel="nofollow">https:&#x2F;&#x2F;platform.openai.com&#x2F;docs&#x2F;models#o3-mini</a><p>I understand that keeping the same data and curating it might be beneficial. But it sounds odd to roll back in time with the knowledge cutoff. AFAIK, the only event that happened around that time was the start of the Gaza conflict.</div><br/><div id="42891218" class="c"><input type="checkbox" id="c-42891218" checked=""/><div class="controls bullet"><span class="by">kikki</span><span>|</span><a href="#42891161">parent</a><span>|</span><a href="#42891245">next</a><span>|</span><label class="collapse" for="c-42891218">[-]</label><label class="expand" for="c-42891218">[1 more]</label></div><br/><div class="children"><div class="content">I think trained knowledge is less and less important - as these multi-modal models have the ability to search the web and have much larger context windows.</div><br/></div></div></div></div><div id="42890909" class="c"><input type="checkbox" id="c-42890909" checked=""/><div class="controls bullet"><span class="by">Oras</span><span>|</span><a href="#42891161">prev</a><span>|</span><label class="collapse" for="c-42890909">[-]</label><label class="expand" for="c-42890909">[7 more]</label></div><br/><div class="children"><div class="content">200k context window<p>$1.1&#x2F;m for input<p>$4.4&#x2F;m for output<p>I assume thinking medium and hard would consume more tokens.<p>I feel the timing is bad for this release especially when deepseek R1  is still peaking. People will compare and might get disappointed with this model.</div><br/><div id="42892401" class="c"><input type="checkbox" id="c-42892401" checked=""/><div class="controls bullet"><span class="by">kandesbunzler</span><span>|</span><a href="#42890909">parent</a><span>|</span><a href="#42891267">next</a><span>|</span><label class="collapse" for="c-42892401">[-]</label><label class="expand" for="c-42892401">[1 more]</label></div><br/><div class="children"><div class="content">I compared free o3 mini vs Deepseek R1 (on their website) and in my tests o3 performed better every time (did some coding tests)</div><br/></div></div><div id="42891267" class="c"><input type="checkbox" id="c-42891267" checked=""/><div class="controls bullet"><span class="by">GaggiX</span><span>|</span><a href="#42890909">parent</a><span>|</span><a href="#42892401">prev</a><span>|</span><label class="collapse" for="c-42891267">[-]</label><label class="expand" for="c-42891267">[5 more]</label></div><br/><div class="children"><div class="content">The model looks quite a bit better in the benchmarks so unless they overfit the model on them it would probably perform better than deepseek.</div><br/><div id="42891703" class="c"><input type="checkbox" id="c-42891703" checked=""/><div class="controls bullet"><span class="by">WiSaGaN</span><span>|</span><a href="#42890909">root</a><span>|</span><a href="#42891267">parent</a><span>|</span><label class="collapse" for="c-42891703">[-]</label><label class="expand" for="c-42891703">[4 more]</label></div><br/><div class="children"><div class="content">My vibe question checking suggests otherwise. Even o3-mini-high is not as good as r1, even though it&#x27;s faster than r1. Considering o3-mini is more expensive per token. It&#x27;s not clear o3-mini-high is cheaper than r1 either even r1 probably consumes more token per answer.</div><br/><div id="42892408" class="c"><input type="checkbox" id="c-42892408" checked=""/><div class="controls bullet"><span class="by">kandesbunzler</span><span>|</span><a href="#42890909">root</a><span>|</span><a href="#42891703">parent</a><span>|</span><label class="collapse" for="c-42892408">[-]</label><label class="expand" for="c-42892408">[3 more]</label></div><br/><div class="children"><div class="content">well in my anecdotal tests, o3 mini (free) performed better than r1</div><br/><div id="42894413" class="c"><input type="checkbox" id="c-42894413" checked=""/><div class="controls bullet"><span class="by">WiSaGaN</span><span>|</span><a href="#42890909">root</a><span>|</span><a href="#42892408">parent</a><span>|</span><a href="#42894344">next</a><span>|</span><label class="collapse" for="c-42894413">[-]</label><label class="expand" for="c-42894413">[1 more]</label></div><br/><div class="children"><div class="content">I did math tests. Probably you did coding.</div><br/></div></div><div id="42894344" class="c"><input type="checkbox" id="c-42894344" checked=""/><div class="controls bullet"><span class="by">GaggiX</span><span>|</span><a href="#42890909">root</a><span>|</span><a href="#42892408">parent</a><span>|</span><a href="#42894413">prev</a><span>|</span><label class="collapse" for="c-42894344">[-]</label><label class="expand" for="c-42894344">[1 more]</label></div><br/><div class="children"><div class="content">Also in my coding testing o3 mini (free) is better than r1.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></body></html>