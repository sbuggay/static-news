<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1707814871947" as="style"/><link rel="stylesheet" href="styles.css?v=1707814871947"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://billwadge.com/2024/02/12/the-rise-and-fall-of-gofai/">The Rise and Fall of GOFAI</a> <span class="domain">(<a href="https://billwadge.com">billwadge.com</a>)</span></div><div class="subtext"><span>herodotus</span> | <span>18 comments</span></div><br/><div><div id="39355298" class="c"><input type="checkbox" id="c-39355298" checked=""/><div class="controls bullet"><span class="by">noelwelsh</span><span>|</span><a href="#39355745">next</a><span>|</span><label class="collapse" for="c-39355298">[-]</label><label class="expand" for="c-39355298">[2 more]</label></div><br/><div class="children"><div class="content">This is a very odd post. It claims, for example, that Good Old-Fashioned AI (GOFIA) was over before the digital computer was invented. It doesn&#x27;t correspond  to either my understanding of what is meant by the term GOFAI or the history of the field. It ignores all current work (e.g. proof assistants, Lean), the role of computational power, and the interplay between GOFAI techniques and other techniques (e.g. Monte-carlo tree search).</div><br/><div id="39355374" class="c"><input type="checkbox" id="c-39355374" checked=""/><div class="controls bullet"><span class="by">qsort</span><span>|</span><a href="#39355298">parent</a><span>|</span><a href="#39355745">next</a><span>|</span><label class="collapse" for="c-39355374">[-]</label><label class="expand" for="c-39355374">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m honestly wondering if it&#x27;s some sort of parody?<p>The part about games is also very weird. The machine that beat Kasparov was Deep Blue, not Big Blue (a nickname for IBM itself), and it was almost entirely brute force search IIRC.<p>Modern chess engines do incorporate statistical methods in the form of NNUE nets, but they would be completely worthless without traditional tree search straight out of the Russel-Norvig.<p>Exactly the same goes for Go, Shogi, etc.<p>I&#x27;m also confused about why the whole issue of undecidability is relevant. Surely this is a limitation for anything running on a computer, including statistical approaches, why would that favor an approach over the other?</div><br/></div></div></div></div><div id="39355745" class="c"><input type="checkbox" id="c-39355745" checked=""/><div class="controls bullet"><span class="by">ducktective</span><span>|</span><a href="#39355298">prev</a><span>|</span><a href="#39355624">next</a><span>|</span><label class="collapse" for="c-39355745">[-]</label><label class="expand" for="c-39355745">[1 more]</label></div><br/><div class="children"><div class="content">From what I understood, the author suggests that GOFAI or symbolic approach to the problem of AI, has fundamental theoretical problems: Gödel&#x27;s Incompleteness Theorems and the Undecidability Problem. But:<p>1- ML approach is also inherently based on mathematical foundations like Linear Algebra and Statistical methods. Any natural limitations in GOFAI also applies here.<p>2- Do we even know how ML&#x2F;DL methods really work? There is a Geoffrey Hinton interview about this and he seems to suggest that NN methods are actually a black box. So in this regard, NN-based methods are even less &quot;confidence-inspiring&quot; than symbolic reasoning.</div><br/></div></div><div id="39355624" class="c"><input type="checkbox" id="c-39355624" checked=""/><div class="controls bullet"><span class="by">lispm</span><span>|</span><a href="#39355745">prev</a><span>|</span><a href="#39355480">next</a><span>|</span><label class="collapse" for="c-39355624">[-]</label><label class="expand" for="c-39355624">[1 more]</label></div><br/><div class="children"><div class="content">Fails to mention any &quot;GOFAI&quot; stuff beyond Eliza, which was not even GOFAI and also not written in Lisp.<p>There are many &quot;GOFAI&quot; domains explored, the author does not seem to know one. Planning&#x2F;Scheduling, Natural Language Processing, Diagnosis, Software&#x2F;Hardware Verification, ...<p>There are also examples for Machine Translation applications, though the author does not know any. An early example was Metal. <a href="https:&#x2F;&#x2F;dl.acm.org&#x2F;doi&#x2F;pdf&#x2F;10.1145&#x2F;114669.114673" rel="nofollow">https:&#x2F;&#x2F;dl.acm.org&#x2F;doi&#x2F;pdf&#x2F;10.1145&#x2F;114669.114673</a></div><br/></div></div><div id="39355480" class="c"><input type="checkbox" id="c-39355480" checked=""/><div class="controls bullet"><span class="by">m463</span><span>|</span><a href="#39355624">prev</a><span>|</span><a href="#39355725">next</a><span>|</span><label class="collapse" for="c-39355480">[-]</label><label class="expand" for="c-39355480">[1 more]</label></div><br/><div class="children"><div class="content">I lived through the rise and fall of &quot;AI&quot; of this type.  &quot;prolog will be the future&quot;, etc.<p>I think the idea is that we were supposed to encode &quot;cats have 4 legs&quot; and every other problem space, and the machines would magically be smart.<p>To me this seemed sort of naive like &quot;Give your spouse a MYSQL server, and they will finally be organized, forever&quot;.</div><br/></div></div><div id="39355725" class="c"><input type="checkbox" id="c-39355725" checked=""/><div class="controls bullet"><span class="by">tromp</span><span>|</span><a href="#39355480">prev</a><span>|</span><a href="#39355539">next</a><span>|</span><label class="collapse" for="c-39355725">[-]</label><label class="expand" for="c-39355725">[1 more]</label></div><br/><div class="children"><div class="content">&gt; the programming language LISP, based closely on the λ calculus.<p>I would say LISP is at best loosely based on the λ calculus.<p>David Turner discusses LISP in Section 2 of [1].
The subsection &quot;Some Myths about LISP&quot; debunks the link between LISP and lambda calculus. McCarthy added LAMBDA to LISP without  an understanding of the lambda calculus, and a result got scoping wrong (dynamic). Eventually, LISP did adopt the correct lexical scoping.<p>[1] <a href="https:&#x2F;&#x2F;www.cs.kent.ac.uk&#x2F;people&#x2F;staff&#x2F;dat&#x2F;tfp12&#x2F;tfp12.pdf" rel="nofollow">https:&#x2F;&#x2F;www.cs.kent.ac.uk&#x2F;people&#x2F;staff&#x2F;dat&#x2F;tfp12&#x2F;tfp12.pdf</a></div><br/></div></div><div id="39355539" class="c"><input type="checkbox" id="c-39355539" checked=""/><div class="controls bullet"><span class="by">DeathArrow</span><span>|</span><a href="#39355725">prev</a><span>|</span><a href="#39355420">next</a><span>|</span><label class="collapse" for="c-39355539">[-]</label><label class="expand" for="c-39355539">[3 more]</label></div><br/><div class="children"><div class="content">What if we mix GOFAI with machine learning? Wouldn&#x27;t the result surpass the capacity of either?</div><br/><div id="39355659" class="c"><input type="checkbox" id="c-39355659" checked=""/><div class="controls bullet"><span class="by">tsimionescu</span><span>|</span><a href="#39355539">parent</a><span>|</span><a href="#39355581">next</a><span>|</span><label class="collapse" for="c-39355659">[-]</label><label class="expand" for="c-39355659">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s exactly how the AlphaX (AlphaGo, AlphaStar etc) are built. They use machine learning but also layers of Monte-Carlo tree search and other GOFAI &quot;tricks&quot;.</div><br/></div></div><div id="39355581" class="c"><input type="checkbox" id="c-39355581" checked=""/><div class="controls bullet"><span class="by">f1shy</span><span>|</span><a href="#39355539">parent</a><span>|</span><a href="#39355659">prev</a><span>|</span><a href="#39355420">next</a><span>|</span><label class="collapse" for="c-39355581">[-]</label><label class="expand" for="c-39355581">[1 more]</label></div><br/><div class="children"><div class="content">Yes. It is called neurosymbolic programming.</div><br/></div></div></div></div><div id="39355420" class="c"><input type="checkbox" id="c-39355420" checked=""/><div class="controls bullet"><span class="by">auggierose</span><span>|</span><a href="#39355539">prev</a><span>|</span><a href="#39355368">next</a><span>|</span><label class="collapse" for="c-39355420">[-]</label><label class="expand" for="c-39355420">[1 more]</label></div><br/><div class="children"><div class="content">Well, GOFAI ≠ logic, although GOFAI of course uses logic as a tool. Logic itself has been quite the success story, maybe one of the biggest of applied mathematics.</div><br/></div></div><div id="39355368" class="c"><input type="checkbox" id="c-39355368" checked=""/><div class="controls bullet"><span class="by">sterlind</span><span>|</span><a href="#39355420">prev</a><span>|</span><a href="#39355155">next</a><span>|</span><label class="collapse" for="c-39355368">[-]</label><label class="expand" for="c-39355368">[3 more]</label></div><br/><div class="children"><div class="content">GOFAI is vital. Where are the automated theorem provers? The planning algorithms? The expert systems, the optimizers, the constraint solvers? All those problem domains still exist, but they&#x27;ve been totally forsaken by new AI. Prolog is still state of the art for expert systems. Planning hasn&#x27;t changed since the early &#x27;00s. Automated provers still don&#x27;t scale.<p>Somehow, we&#x27;ve hit the point where AIs can write sonnets and play jazz, but proving simple theorems is still science fiction.<p>I just want my computer to solve logic puzzles without waiting for the heat death of the universe as I scale them up. I&#x27;m sure language models would make for fantastic heuristics, it just seems like nobody cares and the whole field is just rotting away.</div><br/><div id="39355802" class="c"><input type="checkbox" id="c-39355802" checked=""/><div class="controls bullet"><span class="by">ducktective</span><span>|</span><a href="#39355368">parent</a><span>|</span><a href="#39355408">next</a><span>|</span><label class="collapse" for="c-39355802">[-]</label><label class="expand" for="c-39355802">[1 more]</label></div><br/><div class="children"><div class="content">&gt;it just seems like nobody cares<p>This is the natural consequence of bulk of money in tech going to webdev, from engagement attraction to big data for ads.</div><br/></div></div><div id="39355408" class="c"><input type="checkbox" id="c-39355408" checked=""/><div class="controls bullet"><span class="by">kragen</span><span>|</span><a href="#39355368">parent</a><span>|</span><a href="#39355802">prev</a><span>|</span><a href="#39355155">next</a><span>|</span><label class="collapse" for="c-39355408">[-]</label><label class="expand" for="c-39355408">[1 more]</label></div><br/><div class="children"><div class="content">all these things depend crucially on search, which gets faster according to some large exponent on the quality of your search heuristic.  probably neural networks will provide much better heuristics and therefore speed for such search-based approaches</div><br/></div></div></div></div><div id="39355155" class="c"><input type="checkbox" id="c-39355155" checked=""/><div class="controls bullet"><span class="by">ForHackernews</span><span>|</span><a href="#39355368">prev</a><span>|</span><label class="collapse" for="c-39355155">[-]</label><label class="expand" for="c-39355155">[4 more]</label></div><br/><div class="children"><div class="content">Arguably old-fashioned AI led to greater insight into thinking and reasoning. Black-box LLMs are (so far) stochastic parrots. Maybe what we&#x27;ve learned is that most &quot;intelligent reasoning&quot; by people, isn&#x27;t.</div><br/><div id="39355606" class="c"><input type="checkbox" id="c-39355606" checked=""/><div class="controls bullet"><span class="by">mardifoufs</span><span>|</span><a href="#39355155">parent</a><span>|</span><a href="#39355251">next</a><span>|</span><label class="collapse" for="c-39355606">[-]</label><label class="expand" for="c-39355606">[2 more]</label></div><br/><div class="children"><div class="content">In what way did old fashioned AI lead to greater insight in thinking and reasoning? Sure that was the goal, but it completely failed at doing so, as witnessed by the lack luster results. And usually, the more it tried to use any supposed insight or &quot;model&quot; of reasoning, the harder it failed to produce results.<p>People love to repeat that &quot;stochastic parrots&quot; argument which, I mean sure I get why. But what does it say about GOFAI when even basic &quot;black boxes&quot; outperform almost everything GOFAI can do? And often with much less overfitting. Not just in language models, but also vision, classification, anomaly detection etc. There&#x27;s a reason why current techniques are, well, current.<p>I guess I just don&#x27;t see how it led to any actual insights if it hasn&#x27;t been able to reproduce any part of it. Now maybe  real GOFAI just hasn&#x27;t been tried enough, or we did it wrong, and we just need to try going back to classical techniques and theories (ie. trying to replicate human thinking)... but people are free to do that! and I&#x27;m sure most researchers would be delighted if someone came up with a way to make it work and outperform the current &quot;black box&quot; driven approach. It&#x27;s just that it never happens, but it &quot;sounds&quot; good and &quot;feels&quot; better for some to think it will, eventually.</div><br/><div id="39355760" class="c"><input type="checkbox" id="c-39355760" checked=""/><div class="controls bullet"><span class="by">ForHackernews</span><span>|</span><a href="#39355155">root</a><span>|</span><a href="#39355606">parent</a><span>|</span><a href="#39355251">next</a><span>|</span><label class="collapse" for="c-39355760">[-]</label><label class="expand" for="c-39355760">[1 more]</label></div><br/><div class="children"><div class="content">Symbolic manipulation from early AI work has been used to great effect in computer algebra systems like Maple or Mathematica. It&#x27;s a measure of the &#x27;defining down&#x27; of AI that none of that stuff counts in people&#x27;s minds any more.</div><br/></div></div></div></div><div id="39355251" class="c"><input type="checkbox" id="c-39355251" checked=""/><div class="controls bullet"><span class="by">adamnemecek</span><span>|</span><a href="#39355155">parent</a><span>|</span><a href="#39355606">prev</a><span>|</span><label class="collapse" for="c-39355251">[-]</label><label class="expand" for="c-39355251">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Arguably old-fashioned AI led to greater insight into thinking and reasoning<p>did it?</div><br/></div></div></div></div></div></div></div></div></div></body></html>