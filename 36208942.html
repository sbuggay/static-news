<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1686128463708" as="style"/><link rel="stylesheet" href="styles.css?v=1686128463708"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://jonbarron.info/zipnerf/">Zip-NeRF: Anti-Aliased Grid-Based Neural Radiance Fields</a> <span class="domain">(<a href="https://jonbarron.info">jonbarron.info</a>)</span></div><div class="subtext"><span>netuffresche</span> | <span>36 comments</span></div><br/><div><div id="36219441" class="c"><input type="checkbox" id="c-36219441" checked=""/><div class="controls bullet"><span class="by">lairv</span><span>|</span><a href="#36223702">next</a><span>|</span><label class="collapse" for="c-36219441">[-]</label><label class="expand" for="c-36219441">[3 more]</label></div><br/><div class="children"><div class="content">Another recent cool work in this field is this paper : <a href="https:&#x2F;&#x2F;repo-sam.inria.fr&#x2F;fungraph&#x2F;3d-gaussian-splatting&#x2F;" rel="nofollow">https:&#x2F;&#x2F;repo-sam.inria.fr&#x2F;fungraph&#x2F;3d-gaussian-splatting&#x2F;</a><p>They manage to get the same quality, with &lt;1hr of training, and running at 60fps 1080p, it uses point cloud instead of volumetric representation</div><br/><div id="36222459" class="c"><input type="checkbox" id="c-36222459" checked=""/><div class="controls bullet"><span class="by">porphyra</span><span>|</span><a href="#36219441">parent</a><span>|</span><a href="#36223234">next</a><span>|</span><label class="collapse" for="c-36222459">[-]</label><label class="expand" for="c-36222459">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m anxiously waiting for the code (or for someone to reimplement it open source). Sounds very fun to play with.<p>I&#x27;ve recently been having fun with OpenMVS [1]. Using Gaussian splatting (which is initialized with a point cloud) would bring it to the next level!<p>[1] <a href="https:&#x2F;&#x2F;github.com&#x2F;cdcseacave&#x2F;openMVS">https:&#x2F;&#x2F;github.com&#x2F;cdcseacave&#x2F;openMVS</a></div><br/></div></div><div id="36223234" class="c"><input type="checkbox" id="c-36223234" checked=""/><div class="controls bullet"><span class="by">EZ-Cheeze</span><span>|</span><a href="#36219441">parent</a><span>|</span><a href="#36222459">prev</a><span>|</span><a href="#36223702">next</a><span>|</span><label class="collapse" for="c-36223234">[-]</label><label class="expand" for="c-36223234">[1 more]</label></div><br/><div class="children"><div class="content">thank you SO much for posting this, and to the HN community for putting it at the top<p>i think yours is the only comment with actual value (and i&#x27;m including mine)</div><br/></div></div></div></div><div id="36223702" class="c"><input type="checkbox" id="c-36223702" checked=""/><div class="controls bullet"><span class="by">Demmme</span><span>|</span><a href="#36219441">prev</a><span>|</span><a href="#36219733">next</a><span>|</span><label class="collapse" for="c-36223702">[-]</label><label class="expand" for="c-36223702">[2 more]</label></div><br/><div class="children"><div class="content">I knew it will be worth it to make videos and pictures from the flat of my now dead grandpa .<p>I love how this can preserve spaces</div><br/><div id="36224226" class="c"><input type="checkbox" id="c-36224226" checked=""/><div class="controls bullet"><span class="by">vanderZwan</span><span>|</span><a href="#36223702">parent</a><span>|</span><a href="#36219733">next</a><span>|</span><label class="collapse" for="c-36224226">[-]</label><label class="expand" for="c-36224226">[1 more]</label></div><br/><div class="children"><div class="content">I did the same with my grandparents, guess this is a more common way of saying goodbye than I thought!<p>I&#x27;m afraid I wasn&#x27;t systematic enough to create a useful data set though, lots of gaps. I&#x27;ll make sure I won&#x27;t repeat that mistake and take a good fly-through of the apartments of my parents.</div><br/></div></div></div></div><div id="36219733" class="c"><input type="checkbox" id="c-36219733" checked=""/><div class="controls bullet"><span class="by">xrd</span><span>|</span><a href="#36223702">prev</a><span>|</span><a href="#36222876">next</a><span>|</span><label class="collapse" for="c-36219733">[-]</label><label class="expand" for="c-36219733">[6 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve been fascinated by NeRFs for a few years.<p>But, there are really no viable models that run on consumer hardware like llama or stable diffusion.<p>Or, am I wrong? NeRF Studio seems promising but never works on my 6GB nvidia.<p>I would really like to find a way to interpolate between two images using a NeRF (get the hallucination of the &quot;image in between&quot;).<p>Is there such a thing out there?</div><br/><div id="36224245" class="c"><input type="checkbox" id="c-36224245" checked=""/><div class="controls bullet"><span class="by">vanderZwan</span><span>|</span><a href="#36219733">parent</a><span>|</span><a href="#36220134">next</a><span>|</span><label class="collapse" for="c-36224245">[-]</label><label class="expand" for="c-36224245">[1 more]</label></div><br/><div class="children"><div class="content">It feels like optimizing NeRFs to the point where they are usable by consumer hardware while producing decent results is the main thing everyone is working on, so give it a few more years</div><br/></div></div><div id="36220134" class="c"><input type="checkbox" id="c-36220134" checked=""/><div class="controls bullet"><span class="by">riotnrrd</span><span>|</span><a href="#36219733">parent</a><span>|</span><a href="#36224245">prev</a><span>|</span><a href="#36220447">next</a><span>|</span><label class="collapse" for="c-36220134">[-]</label><label class="expand" for="c-36220134">[1 more]</label></div><br/><div class="children"><div class="content">I mostly have experience with Instant NGP, and it should work on older consumer NVIDIA cards. Their github page calls out Pascal cards as working, for example.  6 GB isn&#x27;t much memory, though, so you may be limited in final resolution of the latent model and thus of the output.</div><br/></div></div><div id="36220447" class="c"><input type="checkbox" id="c-36220447" checked=""/><div class="controls bullet"><span class="by">cameronfraser</span><span>|</span><a href="#36219733">parent</a><span>|</span><a href="#36220134">prev</a><span>|</span><a href="#36220175">next</a><span>|</span><label class="collapse" for="c-36220447">[-]</label><label class="expand" for="c-36220447">[1 more]</label></div><br/><div class="children"><div class="content">nerfstudio should work on 6gb of vram, i&#x27;ve used the nerfacto model extensively on a laptop with that constraint. Try reducing the num-nerf-samples-per-ray param and downscaling images</div><br/></div></div><div id="36220175" class="c"><input type="checkbox" id="c-36220175" checked=""/><div class="controls bullet"><span class="by">dheera</span><span>|</span><a href="#36219733">parent</a><span>|</span><a href="#36220447">prev</a><span>|</span><a href="#36222876">next</a><span>|</span><label class="collapse" for="c-36220175">[-]</label><label class="expand" for="c-36220175">[2 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t know about 6GB but if you have a 12GB or 16GB card you should be able to run the vast majority of NeRF work out there, most of it is designed to run on a single GPU.</div><br/><div id="36221759" class="c"><input type="checkbox" id="c-36221759" checked=""/><div class="controls bullet"><span class="by">xrd</span><span>|</span><a href="#36219733">root</a><span>|</span><a href="#36220175">parent</a><span>|</span><a href="#36222876">next</a><span>|</span><label class="collapse" for="c-36221759">[-]</label><label class="expand" for="c-36221759">[1 more]</label></div><br/><div class="children"><div class="content">Do you know if there are any NERFs that can be run in command line mode, where you can see an intermediate image by giving it two or more images? I&#x27;m less interested in video than in a single image result.</div><br/></div></div></div></div></div></div><div id="36222876" class="c"><input type="checkbox" id="c-36222876" checked=""/><div class="controls bullet"><span class="by">defaultcompany</span><span>|</span><a href="#36219733">prev</a><span>|</span><a href="#36223619">next</a><span>|</span><label class="collapse" for="c-36222876">[-]</label><label class="expand" for="c-36222876">[1 more]</label></div><br/><div class="children"><div class="content">I spent about 50 hours manually doing something similar a few years ago [1] but it was literally made by taking hundreds of 360 degree panoramas every two inches inside a room on a fixed path. The end result was awesome but it was so time consuming. It’s crazy what they are doing now using ML with a few input images.<p>[1]: <a href="https:&#x2F;&#x2F;forums.tigsource.com&#x2F;index.php?topic=69545.0" rel="nofollow">https:&#x2F;&#x2F;forums.tigsource.com&#x2F;index.php?topic=69545.0</a></div><br/></div></div><div id="36223619" class="c"><input type="checkbox" id="c-36223619" checked=""/><div class="controls bullet"><span class="by">FloatArtifact</span><span>|</span><a href="#36222876">prev</a><span>|</span><a href="#36219624">next</a><span>|</span><label class="collapse" for="c-36223619">[-]</label><label class="expand" for="c-36223619">[1 more]</label></div><br/><div class="children"><div class="content">Is there any way to get a usable point cloud suitable for 3D reconstruction in blender?</div><br/></div></div><div id="36219624" class="c"><input type="checkbox" id="c-36219624" checked=""/><div class="controls bullet"><span class="by">yarg</span><span>|</span><a href="#36223619">prev</a><span>|</span><a href="#36223223">next</a><span>|</span><label class="collapse" for="c-36219624">[-]</label><label class="expand" for="c-36219624">[7 more]</label></div><br/><div class="children"><div class="content">This is amazing, but...<p>It feels too damned clean, and I&#x27;m not sure its just the weirdly alien camera stability.</div><br/><div id="36221570" class="c"><input type="checkbox" id="c-36221570" checked=""/><div class="controls bullet"><span class="by">shahar2k</span><span>|</span><a href="#36219624">parent</a><span>|</span><a href="#36220299">next</a><span>|</span><label class="collapse" for="c-36221570">[-]</label><label class="expand" for="c-36221570">[3 more]</label></div><br/><div class="children"><div class="content">it&#x27;s exactly the camera work, this is a camera on a spline that has been heavily smoothed, a trick used in a lot of vfx work is recording ACTUAL camera movement (put a brick on an iphone to simulate the camera weight and 3d track the motion) and using that in a separate project to create a feeling of believable &quot;there-ness&quot;</div><br/><div id="36221822" class="c"><input type="checkbox" id="c-36221822" checked=""/><div class="controls bullet"><span class="by">yarg</span><span>|</span><a href="#36219624">root</a><span>|</span><a href="#36221570">parent</a><span>|</span><a href="#36220299">next</a><span>|</span><label class="collapse" for="c-36221822">[-]</label><label class="expand" for="c-36221822">[2 more]</label></div><br/><div class="children"><div class="content">There&#x27;s no doubt that&#x27;s part of it, but it&#x27;s not all - I think it&#x27;s the stillness.</div><br/><div id="36222341" class="c"><input type="checkbox" id="c-36222341" checked=""/><div class="controls bullet"><span class="by">jacobsimon</span><span>|</span><a href="#36219624">root</a><span>|</span><a href="#36221822">parent</a><span>|</span><a href="#36220299">next</a><span>|</span><label class="collapse" for="c-36222341">[-]</label><label class="expand" for="c-36222341">[1 more]</label></div><br/><div class="children"><div class="content">A little bit of motion blur would go a long way here.</div><br/></div></div></div></div></div></div><div id="36220299" class="c"><input type="checkbox" id="c-36220299" checked=""/><div class="controls bullet"><span class="by">nawgz</span><span>|</span><a href="#36219624">parent</a><span>|</span><a href="#36221570">prev</a><span>|</span><a href="#36223223">next</a><span>|</span><label class="collapse" for="c-36220299">[-]</label><label class="expand" for="c-36220299">[3 more]</label></div><br/><div class="children"><div class="content">It&#x27;s just really horrible camera work. Rolling the camera like that only makes sense when it corresponds with acceleration, but here every corner has a lot of camera roll and the amount is not correlated with the movement. That induces motion sickness, which is why it feels bad to look at despite excellent image quality.<p>A piece of commentary I&#x27;m less sure of is that there seems to be a total lack of motion blur, which is not what we&#x27;ve come to expect out of video</div><br/><div id="36221139" class="c"><input type="checkbox" id="c-36221139" checked=""/><div class="controls bullet"><span class="by">jrk</span><span>|</span><a href="#36219624">root</a><span>|</span><a href="#36220299">parent</a><span>|</span><a href="#36221117">next</a><span>|</span><label class="collapse" for="c-36221139">[-]</label><label class="expand" for="c-36221139">[1 more]</label></div><br/><div class="children"><div class="content">This is just a raw result of many frames strung together from a view synthesis technique, with an arbitrary, programmer-designed camera path. Neither of these issues is fundamental to the technique:<p>- The camera path could be anything, and nicer ones could be easily designed by an artist
- Motion blur is just a matter of supersampling in time. You actually <i>don&#x27;t want</i> blur in the base reconstruction of individual views, as that would mean loss of detail when you were sitting still.<p>In short, this video is not meant to show the output you&#x27;d actually want for an application (which might be different for a movie vs. VR vs. something else), but just to distill many outputs from a view synthesis algorithm into a form easily digestible by a human reviewer.</div><br/></div></div><div id="36221117" class="c"><input type="checkbox" id="c-36221117" checked=""/><div class="controls bullet"><span class="by">londons_explore</span><span>|</span><a href="#36219624">root</a><span>|</span><a href="#36220299">parent</a><span>|</span><a href="#36221139">prev</a><span>|</span><a href="#36223223">next</a><span>|</span><label class="collapse" for="c-36221117">[-]</label><label class="expand" for="c-36221117">[1 more]</label></div><br/><div class="children"><div class="content">I think the &#x27;bad&#x27; camera work is because the camera route is probably hard coded coordinates in a python script, and someone has done trial and error to try and find some set of paths that don&#x27;t pass through stuff...</div><br/></div></div></div></div></div></div><div id="36223223" class="c"><input type="checkbox" id="c-36223223" checked=""/><div class="controls bullet"><span class="by">coolspot</span><span>|</span><a href="#36219624">prev</a><span>|</span><a href="#36221141">next</a><span>|</span><label class="collapse" for="c-36223223">[-]</label><label class="expand" for="c-36223223">[1 more]</label></div><br/><div class="children"><div class="content">That’s a very nice house!</div><br/></div></div><div id="36221141" class="c"><input type="checkbox" id="c-36221141" checked=""/><div class="controls bullet"><span class="by">next_xibalba</span><span>|</span><a href="#36223223">prev</a><span>|</span><a href="#36219761">next</a><span>|</span><label class="collapse" for="c-36221141">[-]</label><label class="expand" for="c-36221141">[2 more]</label></div><br/><div class="children"><div class="content">Streetview about to go ham.</div><br/><div id="36221432" class="c"><input type="checkbox" id="c-36221432" checked=""/><div class="controls bullet"><span class="by">krasin</span><span>|</span><a href="#36221141">parent</a><span>|</span><a href="#36219761">next</a><span>|</span><label class="collapse" for="c-36221432">[-]</label><label class="expand" for="c-36221432">[1 more]</label></div><br/><div class="children"><div class="content">Waymo agrees: <a href="https:&#x2F;&#x2F;waymo.com&#x2F;research&#x2F;block-nerf&#x2F;" rel="nofollow">https:&#x2F;&#x2F;waymo.com&#x2F;research&#x2F;block-nerf&#x2F;</a></div><br/></div></div></div></div><div id="36219761" class="c"><input type="checkbox" id="c-36219761" checked=""/><div class="controls bullet"><span class="by">djsavvy</span><span>|</span><a href="#36221141">prev</a><span>|</span><a href="#36222468">next</a><span>|</span><label class="collapse" for="c-36219761">[-]</label><label class="expand" for="c-36219761">[2 more]</label></div><br/><div class="children"><div class="content">I’m not sure I understand what this does —- what are the inputs and outputs?</div><br/><div id="36219787" class="c"><input type="checkbox" id="c-36219787" checked=""/><div class="controls bullet"><span class="by">krasin</span><span>|</span><a href="#36219761">parent</a><span>|</span><a href="#36222468">next</a><span>|</span><label class="collapse" for="c-36219787">[-]</label><label class="expand" for="c-36219787">[1 more]</label></div><br/><div class="children"><div class="content">The inputs are just photos from different positions. Then a neural net is trained so that you can ask to render a photo from any pose (including unseen).<p>This particular work (Zip-NeRF) builds on top of the original NeRF paper: <a href="https:&#x2F;&#x2F;www.matthewtancik.com&#x2F;nerf" rel="nofollow">https:&#x2F;&#x2F;www.matthewtancik.com&#x2F;nerf</a> (the website has a good explanation what NeRF aka Neural Radiance Fields are)</div><br/></div></div></div></div><div id="36222468" class="c"><input type="checkbox" id="c-36222468" checked=""/><div class="controls bullet"><span class="by">petermcneeley</span><span>|</span><a href="#36219761">prev</a><span>|</span><a href="#36219467">next</a><span>|</span><label class="collapse" for="c-36222468">[-]</label><label class="expand" for="c-36222468">[1 more]</label></div><br/><div class="children"><div class="content">Is there a live web demo?</div><br/></div></div><div id="36219467" class="c"><input type="checkbox" id="c-36219467" checked=""/><div class="controls bullet"><span class="by">IshKebab</span><span>|</span><a href="#36222468">prev</a><span>|</span><a href="#36219429">next</a><span>|</span><label class="collapse" for="c-36219467">[-]</label><label class="expand" for="c-36219467">[2 more]</label></div><br/><div class="children"><div class="content">Very impressive! How far are we from having this sort of thing in VR? The paper says the model render time was 0.9s which I guess means very far if that is per frame?</div><br/><div id="36219819" class="c"><input type="checkbox" id="c-36219819" checked=""/><div class="controls bullet"><span class="by">krasin</span><span>|</span><a href="#36219467">parent</a><span>|</span><a href="#36219429">next</a><span>|</span><label class="collapse" for="c-36219819">[-]</label><label class="expand" for="c-36219819">[1 more]</label></div><br/><div class="children"><div class="content">instant-ngp ([1]) from NVIDIA can render NeRF in VR in real-time, assuming a very good desktop video card. Note that instant-ngp is not as photo-realistic as Zip-NeRF. But it&#x27;s still very good!<p>1. <a href="https:&#x2F;&#x2F;github.com&#x2F;NVlabs&#x2F;instant-ngp">https:&#x2F;&#x2F;github.com&#x2F;NVlabs&#x2F;instant-ngp</a></div><br/></div></div></div></div><div id="36219429" class="c"><input type="checkbox" id="c-36219429" checked=""/><div class="controls bullet"><span class="by">Y_Y</span><span>|</span><a href="#36219467">prev</a><span>|</span><a href="#36220559">next</a><span>|</span><label class="collapse" for="c-36219429">[-]</label><label class="expand" for="c-36219429">[2 more]</label></div><br/><div class="children"><div class="content">Where&#x27;s the damn code?</div><br/><div id="36219817" class="c"><input type="checkbox" id="c-36219817" checked=""/><div class="controls bullet"><span class="by">esafak</span><span>|</span><a href="#36219429">parent</a><span>|</span><a href="#36220559">next</a><span>|</span><label class="collapse" for="c-36219817">[-]</label><label class="expand" for="c-36219817">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;paperswithcode.com&#x2F;paper&#x2F;zip-nerf-anti-aliased-grid-based-neural" rel="nofollow">https:&#x2F;&#x2F;paperswithcode.com&#x2F;paper&#x2F;zip-nerf-anti-aliased-grid-...</a></div><br/></div></div></div></div><div id="36220559" class="c"><input type="checkbox" id="c-36220559" checked=""/><div class="controls bullet"><span class="by">charliea0</span><span>|</span><a href="#36219429">prev</a><span>|</span><a href="#36220993">next</a><span>|</span><label class="collapse" for="c-36220559">[-]</label><label class="expand" for="c-36220559">[1 more]</label></div><br/><div class="children"><div class="content">Definitely less aliasing, but it looks blurrier than the baseline.</div><br/></div></div><div id="36220993" class="c"><input type="checkbox" id="c-36220993" checked=""/><div class="controls bullet"><span class="by">swayvil</span><span>|</span><a href="#36220559">prev</a><span>|</span><a href="#36221567">next</a><span>|</span><label class="collapse" for="c-36220993">[-]</label><label class="expand" for="c-36220993">[3 more]</label></div><br/><div class="children"><div class="content">A house that cluttered, cramped and crowded, yet they have 2 dining tables. It defies comprehension.</div><br/><div id="36221127" class="c"><input type="checkbox" id="c-36221127" checked=""/><div class="controls bullet"><span class="by">londons_explore</span><span>|</span><a href="#36220993">parent</a><span>|</span><a href="#36221026">next</a><span>|</span><label class="collapse" for="c-36221127">[-]</label><label class="expand" for="c-36221127">[1 more]</label></div><br/><div class="children"><div class="content">I know the feeling...<p>Children can quickly clutter any house.</div><br/></div></div></div></div><div id="36221567" class="c"><input type="checkbox" id="c-36221567" checked=""/><div class="controls bullet"><span class="by">EZ-Cheeze</span><span>|</span><a href="#36220993">prev</a><span>|</span><label class="collapse" for="c-36221567">[-]</label><label class="expand" for="c-36221567">[1 more]</label></div><br/><div class="children"><div class="content">If you understand the implications of this and wanna get rich with me, email me at inventor_man@outlook.com</div><br/></div></div></div></div></div></div></div></body></html>