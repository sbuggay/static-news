<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1718355654680" as="style"/><link rel="stylesheet" href="styles.css?v=1718355654680"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://lemire.me/blog/2024/06/08/scan-html-faster-with-simd-instructions-chrome-edition/">Scan HTML faster with SIMD instructions – Chrome edition</a> <span class="domain">(<a href="https://lemire.me">lemire.me</a>)</span></div><div class="subtext"><span>p_l</span> | <span>84 comments</span></div><br/><div><div id="40673124" class="c"><input type="checkbox" id="c-40673124" checked=""/><div class="controls bullet"><span class="by">Const-me</span><span>|</span><a href="#40675446">next</a><span>|</span><label class="collapse" for="c-40673124">[-]</label><label class="expand" for="c-40673124">[31 more]</label></div><br/><div class="children"><div class="content">The reason why the single-lookup version works, the bytes being searched for have unique low 4 bits. So the lookup generates the vector with bytes equal to low_nibble_mask[ source[i] &amp; 0x0F ]. The table contains the bytes being searched for, in the elements which correspond to the low 4 bits of these bytes.<p>The next instruction compares bytes in the source vector for equality with the results of that lookup. So, for each byte in the source vector, the first 3 instructions are computing the following expression, in parallel for each of the 16 bytes in the vector:<p><pre><code>    bool eq = ( b == low_nibble_mask[ b &amp; 0x0F ] );
</code></pre>
The rest is trivial, identifying index of the first byte which compared true.<p>And one more thing.<p>&gt; If you have an old SSE2 PC, only the simple SIMD approach is available<p>That PSHUFB table lookup SSE instruction was introduced in SSSE3 extension. Now in 2024 it’s hard to find an old SSE2 PC which doesn’t also support SSSE3. You gonna need things like Pentium D launched in 2005, or AMD K10 launched in 2007.</div><br/><div id="40678673" class="c"><input type="checkbox" id="c-40678673" checked=""/><div class="controls bullet"><span class="by">stabbles</span><span>|</span><a href="#40673124">parent</a><span>|</span><a href="#40674343">next</a><span>|</span><label class="collapse" for="c-40678673">[-]</label><label class="expand" for="c-40678673">[2 more]</label></div><br/><div class="children"><div class="content">I blogged about this when I stumbled up on it the first time: <a href="https:&#x2F;&#x2F;stoppels.ch&#x2F;2022&#x2F;11&#x2F;30&#x2F;io-is-no-longer-the-bottleneck-part-2.html" rel="nofollow">https:&#x2F;&#x2F;stoppels.ch&#x2F;2022&#x2F;11&#x2F;30&#x2F;io-is-no-longer-the-bottlenec...</a> &quot;Trick 2: Creating masks efficiently&quot;. It&#x27;s pretty neat.</div><br/><div id="40678713" class="c"><input type="checkbox" id="c-40678713" checked=""/><div class="controls bullet"><span class="by">anonymoushn</span><span>|</span><a href="#40673124">root</a><span>|</span><a href="#40678673">parent</a><span>|</span><a href="#40674343">next</a><span>|</span><label class="collapse" for="c-40678713">[-]</label><label class="expand" for="c-40678713">[1 more]</label></div><br/><div class="children"><div class="content">Great post! There was a contest for counting frequencies also in 2022, you may enjoy reading some of the submissions: <a href="https:&#x2F;&#x2F;easyperf.net&#x2F;blog&#x2F;2022&#x2F;05&#x2F;28&#x2F;Performance-analysis-and-tuning-contest-6" rel="nofollow">https:&#x2F;&#x2F;easyperf.net&#x2F;blog&#x2F;2022&#x2F;05&#x2F;28&#x2F;Performance-analysis-an...</a></div><br/></div></div></div></div><div id="40674343" class="c"><input type="checkbox" id="c-40674343" checked=""/><div class="controls bullet"><span class="by">adrian_b</span><span>|</span><a href="#40673124">parent</a><span>|</span><a href="#40678673">prev</a><span>|</span><a href="#40675153">next</a><span>|</span><label class="collapse" for="c-40674343">[-]</label><label class="expand" for="c-40674343">[1 more]</label></div><br/><div class="children"><div class="content">Not only the Pentium D (2004) did not have SSSE3, but also the later CPUs until the Core Solo, which was launched at the beginning of 2006.<p>SSSE3 (a.k.a. Merom New Instructions), including PSHUFB, has been introduced first in Core Duo (mid 2006).<p>AMD has launched its first CPUs with SSSE3 only in 2011 (Bobcat &amp; Bulldozer).</div><br/></div></div><div id="40675153" class="c"><input type="checkbox" id="c-40675153" checked=""/><div class="controls bullet"><span class="by">mananaysiempre</span><span>|</span><a href="#40673124">parent</a><span>|</span><a href="#40674343">prev</a><span>|</span><a href="#40677140">next</a><span>|</span><label class="collapse" for="c-40675153">[-]</label><label class="expand" for="c-40675153">[2 more]</label></div><br/><div class="children"><div class="content">As a side note, the article and the simdjson paper don’t mention that it’s also possible to do an arbitrary set of bytes &lt; 128 in two lookups (or one lookup and one variable shift), by vectorizing<p><pre><code>  !!(bitset[b &gt;&gt; 3] &amp; oneshl[b &amp; 7]),
</code></pre>
where bitset[i] has its jth bit set iff i*8+j is in the set, and oneshl[i] is 1&lt;&lt;i. (I don’t remember where I saw this first, unfortunately, a pull request to a Rust something or other.) If you’re on x86 and thus using PSHUFB for the lookup, making the first shift an arithmetic one will also see you reject bytes ≥ 128 automatically.</div><br/><div id="40677089" class="c"><input type="checkbox" id="c-40677089" checked=""/><div class="controls bullet"><span class="by">anonymoushn</span><span>|</span><a href="#40673124">root</a><span>|</span><a href="#40675153">parent</a><span>|</span><a href="#40677140">next</a><span>|</span><label class="collapse" for="c-40677089">[-]</label><label class="expand" for="c-40677089">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t really know how this algorithm works because it doesn&#x27;t seem to consume the input at all, but some techniques are here: <a href="http:&#x2F;&#x2F;0x80.pl&#x2F;articles&#x2F;simd-byte-lookup.html" rel="nofollow">http:&#x2F;&#x2F;0x80.pl&#x2F;articles&#x2F;simd-byte-lookup.html</a></div><br/></div></div></div></div><div id="40677140" class="c"><input type="checkbox" id="c-40677140" checked=""/><div class="controls bullet"><span class="by">paulmd</span><span>|</span><a href="#40673124">parent</a><span>|</span><a href="#40675153">prev</a><span>|</span><a href="#40673391">next</a><span>|</span><label class="collapse" for="c-40677140">[-]</label><label class="expand" for="c-40677140">[3 more]</label></div><br/><div class="children"><div class="content">&gt; You gonna need things like Pentium D launched in 2005, or AMD K10 launched in 2007.<p>finally, my moment to shine<p><a href="https:&#x2F;&#x2F;i.imgur.com&#x2F;WxmKuG8.jpeg" rel="nofollow">https:&#x2F;&#x2F;i.imgur.com&#x2F;WxmKuG8.jpeg</a></div><br/><div id="40677908" class="c"><input type="checkbox" id="c-40677908" checked=""/><div class="controls bullet"><span class="by">intelVISA</span><span>|</span><a href="#40673124">root</a><span>|</span><a href="#40677140">parent</a><span>|</span><a href="#40673391">next</a><span>|</span><label class="collapse" for="c-40677908">[-]</label><label class="expand" for="c-40677908">[2 more]</label></div><br/><div class="children"><div class="content">Had one of those, it was stupidly expensive for the (low) performance - put me off AMD forever...</div><br/><div id="40678740" class="c"><input type="checkbox" id="c-40678740" checked=""/><div class="controls bullet"><span class="by">adrian_b</span><span>|</span><a href="#40673124">root</a><span>|</span><a href="#40677908">parent</a><span>|</span><a href="#40673391">next</a><span>|</span><label class="collapse" for="c-40678740">[-]</label><label class="expand" for="c-40678740">[1 more]</label></div><br/><div class="children"><div class="content">Perhaps you are confusing Athlon 64 with Athlon XP. The image shows an Athlon 64.<p>Even Athlon XP was initially fast, but then Intel, after switching to an improved 130 nm CMOS process, has succeeded to increase very fast the clock frequencies of Pentium 4, from the low 2.0 GHz until 3.06 GHz in 2002 and eventually 3.2 GHz in 2003. The clock frequency advantage became so large for Intel that Athlon XP was no longer competitive.<p>On the other hand, Athlon 64 was in a completely other class, at least when using a 64-bit operating system.<p>I had a couple of Athlon 64, a 2.4 GHz single-core and a 2.2 GHz dual-core. The 3.2 GHz Pentium 4 CPUs were no match for them.<p>With a 3.2 GHz Pentium 4 I needed 2-3 days of non-stop work (24&#x2F;24) for the compilation of a Linux distribution, while with Athlon 64 that was reduced to only a half day&#x27;s work.<p>Before the introduction of Core Duo in mid 2006, for a couple of years all the available Intel CPUs that competed with Athlon 64 were not only extremely slow, but they were also extremely loud, suggesting an airplane takeoff (because the Intel 90 nm process was a failure, with huge leakage; the Core Duo that made Intel the best again was made in an improved 65 nm process).<p>The various variants of Athlon 64 became worse than what Intel offered only after mid 2006, though even much later there were many cases when they were cheap enough to provide better performance per dollar than Intel.<p>The image shown by the other poster is of an Athlon 64 made in 2005, at a time when it was the best CPU that could be obtained from any vendor.</div><br/></div></div></div></div></div></div><div id="40673391" class="c"><input type="checkbox" id="c-40673391" checked=""/><div class="controls bullet"><span class="by">ilrwbwrkhv</span><span>|</span><a href="#40673124">parent</a><span>|</span><a href="#40677140">prev</a><span>|</span><a href="#40675446">next</a><span>|</span><label class="collapse" for="c-40673391">[-]</label><label class="expand" for="c-40673391">[22 more]</label></div><br/><div class="children"><div class="content">Do you still use c++ or have you moved to rust?</div><br/><div id="40674094" class="c"><input type="checkbox" id="c-40674094" checked=""/><div class="controls bullet"><span class="by">akira2501</span><span>|</span><a href="#40673124">root</a><span>|</span><a href="#40673391">parent</a><span>|</span><a href="#40673543">next</a><span>|</span><label class="collapse" for="c-40674094">[-]</label><label class="expand" for="c-40674094">[3 more]</label></div><br/><div class="children"><div class="content">Rust.  Never mentioned.  Shoehorned into every conversation anyways.</div><br/><div id="40676849" class="c"><input type="checkbox" id="c-40676849" checked=""/><div class="controls bullet"><span class="by">IntelMiner</span><span>|</span><a href="#40673124">root</a><span>|</span><a href="#40674094">parent</a><span>|</span><a href="#40677862">next</a><span>|</span><label class="collapse" for="c-40676849">[-]</label><label class="expand" for="c-40676849">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s the &quot;btw I use Arch&quot; of programming</div><br/></div></div><div id="40677862" class="c"><input type="checkbox" id="c-40677862" checked=""/><div class="controls bullet"><span class="by">intelVISA</span><span>|</span><a href="#40673124">root</a><span>|</span><a href="#40674094">parent</a><span>|</span><a href="#40676849">prev</a><span>|</span><a href="#40673543">next</a><span>|</span><label class="collapse" for="c-40677862">[-]</label><label class="expand" for="c-40677862">[1 more]</label></div><br/><div class="children"><div class="content">The usurper must challenge the King.</div><br/></div></div></div></div><div id="40673543" class="c"><input type="checkbox" id="c-40673543" checked=""/><div class="controls bullet"><span class="by">Const-me</span><span>|</span><a href="#40673124">root</a><span>|</span><a href="#40673391">parent</a><span>|</span><a href="#40674094">prev</a><span>|</span><a href="#40675446">next</a><span>|</span><label class="collapse" for="c-40673543">[-]</label><label class="expand" for="c-40673543">[18 more]</label></div><br/><div class="children"><div class="content">I mostly use C++ and C#, and I’m not a fan of Rust.</div><br/><div id="40674593" class="c"><input type="checkbox" id="c-40674593" checked=""/><div class="controls bullet"><span class="by">victor106</span><span>|</span><a href="#40673124">root</a><span>|</span><a href="#40673543">parent</a><span>|</span><a href="#40675446">next</a><span>|</span><label class="collapse" for="c-40674593">[-]</label><label class="expand" for="c-40674593">[17 more]</label></div><br/><div class="children"><div class="content">I love C#.<p>&gt; I’m not a fan of Rust.<p>I wonder why? Care to elaborate?</div><br/><div id="40675210" class="c"><input type="checkbox" id="c-40675210" checked=""/><div class="controls bullet"><span class="by">Const-me</span><span>|</span><a href="#40673124">root</a><span>|</span><a href="#40674593">parent</a><span>|</span><a href="#40675129">next</a><span>|</span><label class="collapse" for="c-40675210">[-]</label><label class="expand" for="c-40675210">[15 more]</label></div><br/><div class="children"><div class="content">&gt; I wonder why?<p>The whole point of Rust is memory safety and security, but I don’t care too much about either of them. I mostly work on offline desktop apps. When I do work on network exposed servers, I use C# which delivers even better safety and security for a reasonable performance overhead.<p>In pursue of that memory safety, Rust sacrificed pretty much everything else.<p>The language is incredibly hard to learn. The compiler is even slower than C++. It’s hard to do R&amp;D in Rust because memory safety forces minor changes into large refactors. The recent push to async&#x2F;await is controversial, to say the least.<p>It’s impossible to implement any non-trivial data structures in safe Rust. In my line of work designing data structures is more important than writing executable code, because the gap between RAM bandwidth and processor performance have been growing for decades now.<p>Also, interesting post and discussion: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=40172033">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=40172033</a></div><br/><div id="40675901" class="c"><input type="checkbox" id="c-40675901" checked=""/><div class="controls bullet"><span class="by">jltsiren</span><span>|</span><a href="#40673124">root</a><span>|</span><a href="#40675210">parent</a><span>|</span><a href="#40676231">next</a><span>|</span><label class="collapse" for="c-40675901">[-]</label><label class="expand" for="c-40675901">[6 more]</label></div><br/><div class="children"><div class="content">I found Rust easy to learn after ~25 years of C&#x2F;C++. It was definitely easier than learning to use Python properly. Maybe it was because I was often writing multi-threaded shared-memory code in C++, and that forces you to think in a very Rust-like way.<p>Rust makes it difficult to implement data structures that rely on pointers. But in practice, you often want to minimize the use of actual pointers, even in data structures that use pointers on an abstract level. Pointers are large, following them is slow, and they encourage making many small allocations, which has a large space overhead. And if you define the interface in terms of pointers, you can&#x27;t easily switch to an implementation where you can&#x27;t point directly to any individual item stored in the structure.</div><br/><div id="40676162" class="c"><input type="checkbox" id="c-40676162" checked=""/><div class="controls bullet"><span class="by">Const-me</span><span>|</span><a href="#40673124">root</a><span>|</span><a href="#40675901">parent</a><span>|</span><a href="#40676231">next</a><span>|</span><label class="collapse" for="c-40676162">[-]</label><label class="expand" for="c-40676162">[5 more]</label></div><br/><div class="children"><div class="content">&gt; Maybe it was because I was often writing multi-threaded shared-memory code in C++<p>I’ve been writing C&#x2F;C++ for living for about 25 years, also often writing multi-threaded shared-memory code in C++. However, seems I worked on very different projects, because I think in very Rust-incompatible way.<p>Here’s an example. Quite often I need to compute long arrays of numbers, and the problem is parallel, like multiplication of large matrices. A good way to do that is slicing the output into blocks, and computing different blocks on different CPU cores, using OpenMP or some other thread pool. Different CPU cores need concurrent write access to the same vector, this is illegal in Rust.<p>&gt; But in practice, you often want to minimize the use of actual pointers<p>In practice I often want actual pointers because graphs and trees are everywhere in computing. Many of them mutable, like DOM tree of this web page we’re visiting.<p>Pointer chasing is generally slow compared to arithmetic instructions, but much faster than hash maps which can be used to implement the same thing. A hash map lookup is chasing at least 1 pointer usually multiple (depends on the implementation), and before that spends time computing the hash.<p>&gt; they encourage making many small allocations<p>Pointer and allocations are orthogonal. It’s possible to design pointer-based data structure like tree or graph where the nodes are owned by containers, as opposed to other nodes.</div><br/><div id="40676401" class="c"><input type="checkbox" id="c-40676401" checked=""/><div class="controls bullet"><span class="by">pcwalton</span><span>|</span><a href="#40673124">root</a><span>|</span><a href="#40676162">parent</a><span>|</span><a href="#40677344">next</a><span>|</span><label class="collapse" for="c-40676401">[-]</label><label class="expand" for="c-40676401">[3 more]</label></div><br/><div class="children"><div class="content">&gt; Here’s an example. Quite often I need to compute long arrays of numbers, and the problem is parallel, like multiplication of large matrices. A good way to do that is slicing the output into blocks, and computing different blocks on different CPU cores, using OpenMP or some other thread pool. Different CPU cores need concurrent write access to the same vector, this is illegal in Rust.<p>This is actually easier in Rust than in C++, because of par_iter_mut() [1] from Rayon.<p>(In any case, usually if you want to do that sort of thing quickly then you&#x27;d use ndarray which can use BLAS.)<p>&gt; Pointer chasing is generally slow compared to arithmetic instructions, but much faster than hash maps which can be used to implement the same thing. A hash map lookup is chasing at least 1 pointer usually multiple (depends on the implementation), and before that spends time computing the hash.<p>Usually in Rust you use indices into arrays instead, which can be folded into the addressing mode on most architectures. If you really want to use a hash map, there&#x27;s slotmap which precomputes the hash.<p>[1]: <a href="https:&#x2F;&#x2F;github.com&#x2F;rust-lang-nursery&#x2F;rust-cookbook&#x2F;blob&#x2F;master&#x2F;src&#x2F;concurrency&#x2F;parallel&#x2F;rayon-iter-mut.md">https:&#x2F;&#x2F;github.com&#x2F;rust-lang-nursery&#x2F;rust-cookbook&#x2F;blob&#x2F;mast...</a></div><br/><div id="40676647" class="c"><input type="checkbox" id="c-40676647" checked=""/><div class="controls bullet"><span class="by">Const-me</span><span>|</span><a href="#40673124">root</a><span>|</span><a href="#40676401">parent</a><span>|</span><a href="#40677344">next</a><span>|</span><label class="collapse" for="c-40676647">[-]</label><label class="expand" for="c-40676647">[2 more]</label></div><br/><div class="children"><div class="content">&gt; par_iter_mut() [1] from Rayon<p>I wonder have they fixed the performance? <a href="https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;rust&#x2F;comments&#x2F;bto10h&#x2F;update_a_scaling_comparison_between_rustrayon_and&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;rust&#x2F;comments&#x2F;bto10h&#x2F;update_a_scali...</a><p>&gt; usually if you want to do that sort of thing quickly then you&#x27;d use ndarray which can use BLAS<p>In C++ I’d usually use Eigen, because these expression templates are saving memory allocations and bandwidth storing&#x2F;reloading temporary matrices. Sometimes much faster than BLAS libraries with C API. I’m not sure Rust has an equivalent.<p>&gt; indices into arrays instead, which can be folded into the addressing mode on most architectures<p>For some applications of graphs and trees it’s useful to have nodes polymorphic. An example is a visual tree in GUI: different nodes are instances of different classes. Array elements are of the same type.<p>On AMD64 that’s only true when the size of the elements being addressed is 1&#x2F;2&#x2F;4&#x2F;8 bytes, the SIB bytes only have 2 bits for the scale. For any other use case, addressing these arrays requires to multiply (or if you’re lucky at least left shift) these integers<p>Even when the elements are 8 bytes so the indexing can be merged, you need to either spend a register for the base address, or load it from memory with another instruction.<p>It’s relatively expensive to split or merge linked lists&#x2F;trees&#x2F;graphs stored that way. If the tree&#x2F;graph is long lived, mutable, and changes a lot, eventually you might need to compact or even garbage collect these arrays.</div><br/><div id="40677043" class="c"><input type="checkbox" id="c-40677043" checked=""/><div class="controls bullet"><span class="by">pcwalton</span><span>|</span><a href="#40673124">root</a><span>|</span><a href="#40676647">parent</a><span>|</span><a href="#40677344">next</a><span>|</span><label class="collapse" for="c-40677043">[-]</label><label class="expand" for="c-40677043">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I wonder have they fixed the performance? <a href="https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;rust&#x2F;comments&#x2F;bto10h&#x2F;update_a_scali" rel="nofollow">https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;rust&#x2F;comments&#x2F;bto10h&#x2F;update_a_scali</a>...<p>The comments point out a whole bunch of problems with that data. A better example would be <a href="https:&#x2F;&#x2F;parallel-rust-cpp.github.io&#x2F;introduction.html" rel="nofollow">https:&#x2F;&#x2F;parallel-rust-cpp.github.io&#x2F;introduction.html</a> which shows them as quite comparable, depending on the compiler.<p>&gt; In C++ I’d usually use Eigen, because these expression templates are saving memory allocations and bandwidth storing&#x2F;reloading temporary matrices. Sometimes much faster than BLAS libraries with C API. I’m not sure Rust has an equivalent.<p>That equivalent would be ndarray.<p>&gt; For some applications of graphs and trees it’s useful to have nodes polymorphic. An example is a visual tree in GUI: different nodes are instances of different classes. Array elements are of the same type.<p>And in that case you can use Box (or Rc&#x2F;Arc).<p>&gt; Even when the elements are 8 bytes so the indexing can be merged, you need to either spend a register for the base address, or load it from memory with another instruction.<p>I&#x27;ve never seen this be a performance problem in practice; the cost of doing a shift and add is incredibly low compared to the cost of actually fetching the memory.<p>&gt; It’s relatively expensive to split or merge linked lists&#x2F;trees&#x2F;graphs stored that way. If the tree&#x2F;graph is long lived, mutable, and changes a lot, eventually you might need to compact or even garbage collect these arrays.<p>Which is the same thing modern thread-caching mallocs also have to do, except that compacting and garbage collecting is actually <i>possible</i> with the arena approach (not that I think it&#x27;s terribly important either way).</div><br/></div></div></div></div></div></div><div id="40677344" class="c"><input type="checkbox" id="c-40677344" checked=""/><div class="controls bullet"><span class="by">jltsiren</span><span>|</span><a href="#40673124">root</a><span>|</span><a href="#40676162">parent</a><span>|</span><a href="#40676401">prev</a><span>|</span><a href="#40676231">next</a><span>|</span><label class="collapse" for="c-40677344">[-]</label><label class="expand" for="c-40677344">[1 more]</label></div><br/><div class="children"><div class="content">All data structures are compromises. If you want something (such as the ability to interleave queries and updates), you lose something else (such as performance or space-efficiency). Instead of using a single general-purpose data structure, I&#x27;ve found it useful to have several specialized structures making different compromises, with efficient conversions between them.<p>When it comes to graphs, the naive hash map representation has its uses. But I more often use representations based on conceptual arrays. The representations could be row-based or column-based, the arrays could store bytes or structs, and the concrete arrays could be vectors or something similar to B+ trees. Not all combinations are relevant, but several of them are.<p>And then there are overlays. If one representation is otherwise ideal but it doesn&#x27;t support a specific operation (such as mapping between graph positions and positions on certain paths), an overlay can fix that. Another overlay could use the graph to represent a subgraph induced by certain nodes. And another could represent the same graph after a transformation, such as merging unary paths into single nodes.<p>When you have several graph implementations and overlays, the interface has to be pretty generic. You probably want to use either node identifiers or opaque handles. The latter could be node identifiers, array offsets, or pointers, depending on the concrete graph.</div><br/></div></div></div></div></div></div><div id="40676231" class="c"><input type="checkbox" id="c-40676231" checked=""/><div class="controls bullet"><span class="by">aldanor</span><span>|</span><a href="#40673124">root</a><span>|</span><a href="#40675210">parent</a><span>|</span><a href="#40675901">prev</a><span>|</span><a href="#40675129">next</a><span>|</span><label class="collapse" for="c-40676231">[-]</label><label class="expand" for="c-40676231">[8 more]</label></div><br/><div class="children"><div class="content">Memory safety and safety is not &quot;the whole point of Rust&quot;. It&#x27;s a nice low-level language with proper sum types (!), neat sum-type approach to errors, proper and easy to use iterators and much else including nice tooling, dep management, very high standards in packages and docs overall, etc.<p>C++ lacks in pretty much all of those, so memory-safety or no, personally I can&#x27;t picture myself choosing to do C++ for low-level work at will these days. Unless it&#x27;s too low-level like dpdk or gpu kernels.<p>&gt; the language is incredibly hard to learn<p>Not really. A few months from zero and you&#x27;ll be up and running, provided you have prior C++ experience (based on cases I&#x27;ve observed in teams I&#x27;ve worked in). Maybe not including async rust though.<p>&gt; it&#x27;s impossible to implement any non-trivial data structures in safe rust<p>ANY, really? Any examples? (Other than linked list or other self-dependent structures)</div><br/><div id="40676445" class="c"><input type="checkbox" id="c-40676445" checked=""/><div class="controls bullet"><span class="by">Const-me</span><span>|</span><a href="#40673124">root</a><span>|</span><a href="#40676231">parent</a><span>|</span><a href="#40675129">next</a><span>|</span><label class="collapse" for="c-40676445">[-]</label><label class="expand" for="c-40676445">[7 more]</label></div><br/><div class="children"><div class="content">&gt; a nice low-level language<p>The usability is not great, too opinionated. For example, they have decided their strings are guaranteed to contain valid UTF-8. Many external components (like Linux kernel) don’t have these guarantees, so the Rust has another OsString type for them. I think Rust is the only language which does that. The rest of them are fine keeping invalid UTF8 &#x2F; UTF16 in their strings.<p>&gt; proper and easy to use iterators<p>C++&#x2F;11 introduced range-based for loops, they make iterators very easy to use.<p>&gt; nice tooling<p>Packages are OK I guess, but I think other classes of tools are lacking. For example, I can’t imagine working on any performance critical low-level code without a good sampling profiler.<p>&gt; ANY, really?<p>Yes. Even very simple data structures like std::vec::Vec require unsafe code, they call unsafe APIs like alloc::alloc for memory management. This can, and did, cause security bugs: <a href="https:&#x2F;&#x2F;shnatsel.medium.com&#x2F;how-rusts-standard-library-was-vulnerable-for-years-and-nobody-noticed-aebf0503c3d6" rel="nofollow">https:&#x2F;&#x2F;shnatsel.medium.com&#x2F;how-rusts-standard-library-was-v...</a><p>By comparison, modern C# is memory safe all the way down, possible to implement even very complicated data structures without a single line of unsafe code. The collection classes from the standard library don’t use unsafe code either.</div><br/><div id="40678932" class="c"><input type="checkbox" id="c-40678932" checked=""/><div class="controls bullet"><span class="by">orlp</span><span>|</span><a href="#40673124">root</a><span>|</span><a href="#40676445">parent</a><span>|</span><a href="#40678847">next</a><span>|</span><label class="collapse" for="c-40678932">[-]</label><label class="expand" for="c-40678932">[1 more]</label></div><br/><div class="children"><div class="content">&gt; For example, I can’t imagine working on any performance critical low-level code without a good sampling profiler.<p>I&#x27;m pretty happy with <a href="https:&#x2F;&#x2F;github.com&#x2F;mstange&#x2F;samply">https:&#x2F;&#x2F;github.com&#x2F;mstange&#x2F;samply</a>.<p>It worked out-of-the-box on Linx and MacOS, even on Windows after installing directly from the repo (recently added feature).</div><br/></div></div><div id="40678847" class="c"><input type="checkbox" id="c-40678847" checked=""/><div class="controls bullet"><span class="by">shakow</span><span>|</span><a href="#40673124">root</a><span>|</span><a href="#40676445">parent</a><span>|</span><a href="#40678932">prev</a><span>|</span><a href="#40678094">next</a><span>|</span><label class="collapse" for="c-40678847">[-]</label><label class="expand" for="c-40678847">[1 more]</label></div><br/><div class="children"><div class="content">&gt;  I can’t imagine working on any performance critical low-level code without a good sampling profiler.<p>cargo-flamegraph: am I a joke to you?<p><a href="https:&#x2F;&#x2F;github.com&#x2F;flamegraph-rs&#x2F;flamegraph">https:&#x2F;&#x2F;github.com&#x2F;flamegraph-rs&#x2F;flamegraph</a></div><br/></div></div><div id="40678094" class="c"><input type="checkbox" id="c-40678094" checked=""/><div class="controls bullet"><span class="by">kelnos</span><span>|</span><a href="#40673124">root</a><span>|</span><a href="#40676445">parent</a><span>|</span><a href="#40678847">prev</a><span>|</span><a href="#40677100">next</a><span>|</span><label class="collapse" for="c-40678094">[-]</label><label class="expand" for="c-40678094">[3 more]</label></div><br/><div class="children"><div class="content">&gt; <i>Even very simple data structures like std::vec::Vec require unsafe code, they call unsafe APIs like alloc::alloc for memory management. This can, and did, cause security bugs</i><p>That&#x27;s way better than everyone writing their own unsafe vec implementation in C or C++, and then having to deal with those same security bugs over and over and over.<p>And I&#x27;m sure GNU&#x27;s libstdc++, LLVM&#x27;s libc++, and whatever Microsoft calls their C++ stdlib have had a laundry list of security bugs in their implementations of the fundamental data structures over time.  Just they were found and fixed 20 years ago, in a time when the security issue du jour wasn&#x27;t huge news like it is today.<p>&gt; <i>By comparison, modern C# is memory safe all the way down, possible to implement even very complicated data structures without a single line of unsafe code</i><p>You really can&#x27;t compare a GC&#x27;d language to Rust (or C or C++), at least not without acknowledging the inherent tradeoffs being made.  And obviously that C# runtime has a bunch of unsafe C&#x2F;C++ underneath it that lets you do those things.</div><br/><div id="40678586" class="c"><input type="checkbox" id="c-40678586" checked=""/><div class="controls bullet"><span class="by">Nuzzerino</span><span>|</span><a href="#40673124">root</a><span>|</span><a href="#40678094">parent</a><span>|</span><a href="#40677100">next</a><span>|</span><label class="collapse" for="c-40678586">[-]</label><label class="expand" for="c-40678586">[2 more]</label></div><br/><div class="children"><div class="content">What tradeoffs are you referring to here, exactly? C# (in the right hands) is more flexible than what you seem to be implying here, and the GP is likely in the small minority of experts that knows how to leverage it.<p>The limiting ”tradeoffs” with C# have much more to do with the JIT than anything related to a GC. That’s why you don’t see constant expressions (but in the future that may change).<p><a href="https:&#x2F;&#x2F;github.com&#x2F;dotnet&#x2F;csharplang&#x2F;issues&#x2F;6926#issuecomment-1426695771">https:&#x2F;&#x2F;github.com&#x2F;dotnet&#x2F;csharplang&#x2F;issues&#x2F;6926#issuecommen...</a></div><br/><div id="40678913" class="c"><input type="checkbox" id="c-40678913" checked=""/><div class="controls bullet"><span class="by">Ygg2</span><span>|</span><a href="#40673124">root</a><span>|</span><a href="#40678586">parent</a><span>|</span><a href="#40677100">next</a><span>|</span><label class="collapse" for="c-40678913">[-]</label><label class="expand" for="c-40678913">[1 more]</label></div><br/><div class="children"><div class="content">&gt; What tradeoffs are you referring to here, exactly? C# (in the right hands) is more flexible than what you seem to be implying here, and the GP is likely in the small minority of experts that knows how to leverage it.<p>It&#x27;s flexible, but if you want to write something that is GC-less, you&#x27;re on your own. Most libraries (if they exist) don&#x27;t care about allocation. Or performance.<p>I&#x27;m not talking HFT here, I&#x27;m talking about performance intensive games.</div><br/></div></div></div></div></div></div><div id="40677100" class="c"><input type="checkbox" id="c-40677100" checked=""/><div class="controls bullet"><span class="by">pcwalton</span><span>|</span><a href="#40673124">root</a><span>|</span><a href="#40676445">parent</a><span>|</span><a href="#40678094">prev</a><span>|</span><a href="#40675129">next</a><span>|</span><label class="collapse" for="c-40677100">[-]</label><label class="expand" for="c-40677100">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I think Rust is the only language which does that.<p>Python 3 strings are enforced valid Unicode (but not technically UTF-8, as they can contain unpaired surrogates).<p>&gt; Packages are OK I guess, but I think other classes of tools are lacking. For example, I can’t imagine working on any performance critical low-level code without a good sampling profiler.<p>I&#x27;ve been using sampling profilers with Rust since before the language was publicly announced!<p>&gt; Yes. Even very simple data structures like std::vec::Vec require unsafe code, they call unsafe APIs like alloc::alloc for memory management. This can, and did, cause security bugs:<p>This is yet another example of &quot;Rust&#x27;s liberal use of &#x27;security bug&#x27; gives people the wrong impression&quot;. Although I wish they didn&#x27;t, Rust users often use &quot;security bug&quot; to mean any memory safety problem in safe code. By this measure every C++ program in existence is a security bug. The question is whether any <i>applications</i> were exploitable because of this, and I don&#x27;t know of any.<p>&gt; By comparison, modern C# is memory safe all the way down, possible to implement even very complicated data structures without a single line of unsafe code.<p>Only because the runtime has hundreds of thousands of lines of unsafe code written in C++, including the garbage collector that makes it possible to write those collections.</div><br/></div></div></div></div></div></div></div></div><div id="40675129" class="c"><input type="checkbox" id="c-40675129" checked=""/><div class="controls bullet"><span class="by">neonsunset</span><span>|</span><a href="#40673124">root</a><span>|</span><a href="#40674593">parent</a><span>|</span><a href="#40675210">prev</a><span>|</span><a href="#40675446">next</a><span>|</span><label class="collapse" for="c-40675129">[-]</label><label class="expand" for="c-40675129">[1 more]</label></div><br/><div class="children"><div class="content">A little more on topic, if you like SIMD <i>and</i> C#, dotnet&#x2F;runtime now has an introductory guide to Vector128&#x2F;256&#x2F;512&lt;T&gt; API:<p><a href="https:&#x2F;&#x2F;github.com&#x2F;dotnet&#x2F;runtime&#x2F;blob&#x2F;main&#x2F;docs&#x2F;coding-guidelines&#x2F;vectorization-guidelines.md">https:&#x2F;&#x2F;github.com&#x2F;dotnet&#x2F;runtime&#x2F;blob&#x2F;main&#x2F;docs&#x2F;coding-guid...</a><p>Now, the default syntax can still be a bit more wordy with byref arithmetics than ideal, but you can add a few extension methods to make it look it closer to Rust&#x27;s pointer arithmetics:<p><a href="https:&#x2F;&#x2F;github.com&#x2F;U8String&#x2F;U8String&#x2F;blob&#x2F;main&#x2F;Sources&#x2F;U8String&#x2F;CaseConverters&#x2F;U8AsciiCaseConverter.cs#L153-L171">https:&#x2F;&#x2F;github.com&#x2F;U8String&#x2F;U8String&#x2F;blob&#x2F;main&#x2F;Sources&#x2F;U8Str...</a> (unrelated note but .NET lowers this to vpternlogd if AVX512VL is available)<p>You can find more examples of SIMD use in dotnet&#x2F;runtime if that interests you:<p><a href="https:&#x2F;&#x2F;grep.app&#x2F;search?q=Vector%28128%7C256%7C512%29%3C%5Cw%2B%3E&amp;regexp=true&amp;filter[lang][0]=C%23&amp;filter[repo][0]=dotnet&#x2F;runtime" rel="nofollow">https:&#x2F;&#x2F;grep.app&#x2F;search?q=Vector%28128%7C256%7C512%29%3C%5Cw...</a><p>Many paths are vectorized: to&#x2F;from hexadecimal byte conversion, unicode encoding&#x2F;decoding, various hash algorithms, counting and searching for elements, chunking text, there&#x27;s a BLAS library now too and more.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="40675446" class="c"><input type="checkbox" id="c-40675446" checked=""/><div class="controls bullet"><span class="by">scottlamb</span><span>|</span><a href="#40673124">prev</a><span>|</span><a href="#40678217">next</a><span>|</span><label class="collapse" for="c-40675446">[-]</label><label class="expand" for="c-40675446">[2 more]</label></div><br/><div class="children"><div class="content">&gt; The results follow my expectations: the simplest vectorized classification routine has the best performance. However, you may observe that even a rather naive SIMD approach can be quite fast in this instance.<p>I&#x27;ve recently written my first SIMD code [1]. This matches my observation: you get a big improvement just moving from scalar code to autovectorized code (i.e. working in fixed widths and telling the compiler to use specific CPU features you&#x27;ve detected), another decent improvement going to basic use of vendor intrinsics, and then more and more modest improvements from extra sophistication.<p>[1] uyvy-&gt;i420 pixel format conversion code, a much easier application of SIMD. No branching, just a bunch of pixels transformed in identical fashion.</div><br/><div id="40677889" class="c"><input type="checkbox" id="c-40677889" checked=""/><div class="controls bullet"><span class="by">josephg</span><span>|</span><a href="#40675446">parent</a><span>|</span><a href="#40678217">next</a><span>|</span><label class="collapse" for="c-40677889">[-]</label><label class="expand" for="c-40677889">[1 more]</label></div><br/><div class="children"><div class="content">I think most optimisation work is like that. Early effort with each technique can yield large gains. But the marginal gain of using any specific technique decreases over time.<p>For example, I&#x27;ve gotten a lot of speedups from essentially decreasing the number of malloc calls my programs make. Its often the case that ~80% of all allocations in a program come from just a few hotspots. Rewriting those hotspots to use a better data structure can yields big speed improvements, both because malloc &amp; free are expensive calls and because the CPU hates chasing pointers. But there&#x27;s usually only so much benefit in reducing allocations. At some point, it makes sense to just accept malloc calls.<p>The reason is totally logical. Lets say you reduce the number of allocations your program does by 10x and that yields a 45% performance improvement (10 seconds -&gt; 5.5 seconds). You might think reducing allocations by 10x again would yield another 45% performance improvement - but thats just not how the math works out. We should expect that would take your 5.5 seconds down to 5.05 seconds - which is just a 9% improvement. That might not be worth it, given the next 10x reduction in malloc calls will probably be much harder to achieve.<p>If you want another 50% perf improvement, you need to run that profiler again and look at where the new hotspots are. If the CPU is spending less time following pointers, it&#x27;ll now be spending more time (proportionately) running linear code. Maybe this time the performance wins will be found using SIMD. Or by swapping to a different algorithm. Or multithreading. Or by making better use of caching. Or something else - who knows.</div><br/></div></div></div></div><div id="40678217" class="c"><input type="checkbox" id="c-40678217" checked=""/><div class="controls bullet"><span class="by">feverzsj</span><span>|</span><a href="#40675446">prev</a><span>|</span><a href="#40672994">next</a><span>|</span><label class="collapse" for="c-40678217">[-]</label><label class="expand" for="c-40678217">[1 more]</label></div><br/><div class="children"><div class="content">We really need an updated html parser for c&#x2F;c++. Most people are still using gumbo, which was abandoned by google 10 years ago. Some are using lexbor, which lacks basic document.</div><br/></div></div><div id="40672994" class="c"><input type="checkbox" id="c-40672994" checked=""/><div class="controls bullet"><span class="by">nasretdinov</span><span>|</span><a href="#40678217">prev</a><span>|</span><a href="#40677735">next</a><span>|</span><label class="collapse" for="c-40672994">[-]</label><label class="expand" for="c-40672994">[9 more]</label></div><br/><div class="children"><div class="content">To me it&#x27;s fascinating that you indeed _can_ speed up what appears to be a non-parallelisable task like parsing HTML (or JSON to a lesser extent) using SIMD. And that the gains are so substantial too.</div><br/><div id="40678945" class="c"><input type="checkbox" id="c-40678945" checked=""/><div class="controls bullet"><span class="by">emn13</span><span>|</span><a href="#40672994">parent</a><span>|</span><a href="#40673587">next</a><span>|</span><label class="collapse" for="c-40678945">[-]</label><label class="expand" for="c-40678945">[1 more]</label></div><br/><div class="children"><div class="content">As a very rough approximation, I suspect that html parsing (beyond the streaming of the data anyhow) isn&#x27;t really all that fundamentally serial.  After all, if you seek into an html document at some random point, you can generally interpret the html structure mostly locally, i.e. it&#x27;s likely possible to subdivide the task of parsing an html document.<p>Given how leniently html deals with errors and that some of the parsing rules have some context sensitivity (the various modes) actually exploiting large-scale parallelism is probably a very difficult bit of engineering.  Additionally, there may be corner cases that have much more context dependence than normal.  Also, parsing is already probably not a huge part of a browsers runtime, and aggressive parallelism might be faster but more power hungry for a very small latency win. But I can&#x27;t think of a specific fundamental limitation that prevents the normal parsing case from being quite parallelizable; I believe it&#x27;s &quot;just&quot; an engineering problem.</div><br/></div></div><div id="40673587" class="c"><input type="checkbox" id="c-40673587" checked=""/><div class="controls bullet"><span class="by">dzaima</span><span>|</span><a href="#40672994">parent</a><span>|</span><a href="#40678945">prev</a><span>|</span><a href="#40677168">next</a><span>|</span><label class="collapse" for="c-40673587">[-]</label><label class="expand" for="c-40673587">[5 more]</label></div><br/><div class="children"><div class="content">There&#x27;s a surprising amount of things that are possible to parse in a parallel fashion if one tries hard enough, though keeping significant or any gains is more tricky. The operation in the article though is only a rather tiny part of parsing HTML though.</div><br/><div id="40675349" class="c"><input type="checkbox" id="c-40675349" checked=""/><div class="controls bullet"><span class="by">floxy</span><span>|</span><a href="#40672994">root</a><span>|</span><a href="#40673587">parent</a><span>|</span><a href="#40677168">next</a><span>|</span><label class="collapse" for="c-40675349">[-]</label><label class="expand" for="c-40675349">[4 more]</label></div><br/><div class="children"><div class="content">Can anyone recommend pointers to find out more about creating programming languages &#x2F; markup languages that would be more parallel friendly for parsing?  Or maybe even embarrassingly parallel?  How does that affect the grammar, etc..  Maybe you need a different formalism rather than BNF do describe it, and you don&#x27;t use regex to tokenize, and there is no recursive descent, or state machines in parsing, etc..</div><br/><div id="40676001" class="c"><input type="checkbox" id="c-40676001" checked=""/><div class="controls bullet"><span class="by">dzaima</span><span>|</span><a href="#40672994">root</a><span>|</span><a href="#40675349">parent</a><span>|</span><a href="#40677168">next</a><span>|</span><label class="collapse" for="c-40676001">[-]</label><label class="expand" for="c-40676001">[3 more]</label></div><br/><div class="children"><div class="content">There&#x27;s not really that much specific to change I think; the general thing is just reducing the number of rules, as in a parallel thing you&#x27;ll be applying every rule to every part versus just the rules given preceding context (there is the option of filtering parts to process if there are a bunch of rules applying to the same small subset of the input, but that requires such cont).<p>All I can point at is from the array language world, with the notable thing of Co-dfns from Aaron Hsu, an APL compiler capable of running on the GPU (pointless as that may be): <a href="https:&#x2F;&#x2F;github.com&#x2F;Co-dfns&#x2F;Co-dfns&#x2F;tree&#x2F;master;">https:&#x2F;&#x2F;github.com&#x2F;Co-dfns&#x2F;Co-dfns&#x2F;tree&#x2F;master;</a> and a 284-page dissertation: <a href="https:&#x2F;&#x2F;scholarworks.iu.edu&#x2F;dspace&#x2F;items&#x2F;3ab772c9-92c9-4f59-bd95-40aff99e8c7a" rel="nofollow">https:&#x2F;&#x2F;scholarworks.iu.edu&#x2F;dspace&#x2F;items&#x2F;3ab772c9-92c9-4f59-...</a><p>And Marshall Lochbaum following (<a href="https:&#x2F;&#x2F;mlochbaum.github.io&#x2F;BQN&#x2F;implementation&#x2F;codfns.html" rel="nofollow">https:&#x2F;&#x2F;mlochbaum.github.io&#x2F;BQN&#x2F;implementation&#x2F;codfns.html</a>) that work, and covering some basics of parsing expressions of infix &amp; prefix ops to stack-based&#x2F;RPN at the bottom of <a href="https:&#x2F;&#x2F;mlochbaum.github.io&#x2F;BQN&#x2F;implementation&#x2F;index.html" rel="nofollow">https:&#x2F;&#x2F;mlochbaum.github.io&#x2F;BQN&#x2F;implementation&#x2F;index.html</a>, though the code is in BQN.<p>From that same author, parsers written in BQN, that I think should have sub-linear critical paths:<p>Markdown: <a href="https:&#x2F;&#x2F;github.com&#x2F;mlochbaum&#x2F;BQN&#x2F;blob&#x2F;master&#x2F;md.bqn">https:&#x2F;&#x2F;github.com&#x2F;mlochbaum&#x2F;BQN&#x2F;blob&#x2F;master&#x2F;md.bqn</a><p>XML: <a href="https:&#x2F;&#x2F;github.com&#x2F;mlochbaum&#x2F;bqn-libs&#x2F;blob&#x2F;master&#x2F;xml.bqn">https:&#x2F;&#x2F;github.com&#x2F;mlochbaum&#x2F;bqn-libs&#x2F;blob&#x2F;master&#x2F;xml.bqn</a><p>and a compiler of BQN itself: <a href="https:&#x2F;&#x2F;github.com&#x2F;mlochbaum&#x2F;BQN&#x2F;blob&#x2F;master&#x2F;src&#x2F;c.bqn">https:&#x2F;&#x2F;github.com&#x2F;mlochbaum&#x2F;BQN&#x2F;blob&#x2F;master&#x2F;src&#x2F;c.bqn</a> (outputs stack-based bytecode).</div><br/><div id="40676116" class="c"><input type="checkbox" id="c-40676116" checked=""/><div class="controls bullet"><span class="by">floxy</span><span>|</span><a href="#40672994">root</a><span>|</span><a href="#40676001">parent</a><span>|</span><a href="#40677168">next</a><span>|</span><label class="collapse" for="c-40676116">[-]</label><label class="expand" for="c-40676116">[2 more]</label></div><br/><div class="children"><div class="content">Are you still operating on a single stream of characters?  I was wondering about something more radical, like you start in the middle of the stream, and one thread parses the forward to the end, and the other parses <i>backwards</i> towards the beginning.</div><br/><div id="40676274" class="c"><input type="checkbox" id="c-40676274" checked=""/><div class="controls bullet"><span class="by">dzaima</span><span>|</span><a href="#40672994">root</a><span>|</span><a href="#40676116">parent</a><span>|</span><a href="#40677168">next</a><span>|</span><label class="collapse" for="c-40676274">[-]</label><label class="expand" for="c-40676274">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s an option for a potential 2x boost, which I suppose could be good enough in certain contexts, but that&#x27;s it. In particular, if you have a parser system able to utilize SIMD for all parsing, that&#x27;ll get arbitrary parallelizability for &quot;free&quot; (at the cost of some log(n) increase in total operations across all threads).</div><br/></div></div></div></div></div></div></div></div></div></div><div id="40677168" class="c"><input type="checkbox" id="c-40677168" checked=""/><div class="controls bullet"><span class="by">anonymoushn</span><span>|</span><a href="#40672994">parent</a><span>|</span><a href="#40673587">prev</a><span>|</span><a href="#40674265">next</a><span>|</span><label class="collapse" for="c-40677168">[-]</label><label class="expand" for="c-40677168">[1 more]</label></div><br/><div class="children"><div class="content">The approach to these vectorized parsers is generally to find some part of the parsing task that doesn&#x27;t have a dependency chain through every dang byte, like a naively written parser would, then do that first, then do some harder stuff after. I&#x27;m pretty used to it now so I lack perspective on whether this is weird, but in general finding long dependency chains and getting rid of them or replacing them with several shorter dependency chains will make software a lot faster.</div><br/></div></div><div id="40674265" class="c"><input type="checkbox" id="c-40674265" checked=""/><div class="controls bullet"><span class="by">magicalhippo</span><span>|</span><a href="#40672994">parent</a><span>|</span><a href="#40677168">prev</a><span>|</span><a href="#40677735">next</a><span>|</span><label class="collapse" for="c-40674265">[-]</label><label class="expand" for="c-40674265">[1 more]</label></div><br/><div class="children"><div class="content">Now all we need is for pre-2000s web to come back and we could have instant web surfing.</div><br/></div></div></div></div><div id="40677735" class="c"><input type="checkbox" id="c-40677735" checked=""/><div class="controls bullet"><span class="by">JoshTriplett</span><span>|</span><a href="#40672994">prev</a><span>|</span><a href="#40677330">next</a><span>|</span><label class="collapse" for="c-40677735">[-]</label><label class="expand" for="c-40677735">[4 more]</label></div><br/><div class="children"><div class="content">I&#x27;m surprised that this pays attention to &#x27;\r&#x27; (CR) specifically, and not &#x27;\n&#x27; (LF), &#x27; &#x27; (space), or &#x27;\t&#x27; (tab). It doesn&#x27;t seem like HTML assigns any special meaning to carriage return compared to other whitespace. What is the parser doing with the locations of carriage returns?</div><br/><div id="40678127" class="c"><input type="checkbox" id="c-40678127" checked=""/><div class="controls bullet"><span class="by">kristianp</span><span>|</span><a href="#40677735">parent</a><span>|</span><a href="#40677930">next</a><span>|</span><label class="collapse" for="c-40678127">[-]</label><label class="expand" for="c-40678127">[2 more]</label></div><br/><div class="children"><div class="content">Is it something to do with http headers?  They have CR LF pairs terminating the lines.</div><br/><div id="40678406" class="c"><input type="checkbox" id="c-40678406" checked=""/><div class="controls bullet"><span class="by">JoshTriplett</span><span>|</span><a href="#40677735">root</a><span>|</span><a href="#40678127">parent</a><span>|</span><a href="#40677930">next</a><span>|</span><label class="collapse" for="c-40678406">[-]</label><label class="expand" for="c-40678406">[1 more]</label></div><br/><div class="children"><div class="content">I wondered about that, but that wouldn&#x27;t be described as parsing <i>HTML</i>, and it shouldn&#x27;t involve parsing &#x27;&lt;&#x27; and &#x27;&amp;&#x27;.</div><br/></div></div></div></div><div id="40677930" class="c"><input type="checkbox" id="c-40677930" checked=""/><div class="controls bullet"><span class="by">rurban</span><span>|</span><a href="#40677735">parent</a><span>|</span><a href="#40678127">prev</a><span>|</span><a href="#40677330">next</a><span>|</span><label class="collapse" for="c-40677930">[-]</label><label class="expand" for="c-40677930">[1 more]</label></div><br/><div class="children"><div class="content">I also have no idea why he needs the newline-mask \r.
Only &lt;pre&gt; blocks only on windows would need that.</div><br/></div></div></div></div><div id="40677330" class="c"><input type="checkbox" id="c-40677330" checked=""/><div class="controls bullet"><span class="by">cyberax</span><span>|</span><a href="#40677735">prev</a><span>|</span><a href="#40676383">next</a><span>|</span><label class="collapse" for="c-40677330">[-]</label><label class="expand" for="c-40677330">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m really bummed that Parabix went nowhere: <a href="https:&#x2F;&#x2F;ieeexplore.ieee.org&#x2F;document&#x2F;6169041" rel="nofollow">https:&#x2F;&#x2F;ieeexplore.ieee.org&#x2F;document&#x2F;6169041</a><p>It&#x27;s apparently still alive, though: <a href="https:&#x2F;&#x2F;cs-git-research.cs.surrey.sfu.ca&#x2F;cameron&#x2F;parabix-devel&#x2F;-&#x2F;tree&#x2F;master" rel="nofollow">https:&#x2F;&#x2F;cs-git-research.cs.surrey.sfu.ca&#x2F;cameron&#x2F;parabix-dev...</a></div><br/></div></div><div id="40676383" class="c"><input type="checkbox" id="c-40676383" checked=""/><div class="controls bullet"><span class="by">Havoc</span><span>|</span><a href="#40677330">prev</a><span>|</span><a href="#40674197">next</a><span>|</span><label class="collapse" for="c-40676383">[-]</label><label class="expand" for="c-40676383">[4 more]</label></div><br/><div class="children"><div class="content">What’s the usage case for scanning html at gigs per second speed? Speeding up browsers? Crawling?</div><br/><div id="40676409" class="c"><input type="checkbox" id="c-40676409" checked=""/><div class="controls bullet"><span class="by">spartanatreyu</span><span>|</span><a href="#40676383">parent</a><span>|</span><a href="#40674197">next</a><span>|</span><label class="collapse" for="c-40676409">[-]</label><label class="expand" for="c-40676409">[3 more]</label></div><br/><div class="children"><div class="content">Sometimes html pages can get pretty big, why not optimise it?<p>Also, speeding up html parsing means speeding up browsers, crawlers, e2e tests, visual regression tests, etc...</div><br/><div id="40676419" class="c"><input type="checkbox" id="c-40676419" checked=""/><div class="controls bullet"><span class="by">abirch</span><span>|</span><a href="#40676383">root</a><span>|</span><a href="#40676409">parent</a><span>|</span><a href="#40674197">next</a><span>|</span><label class="collapse" for="c-40676419">[-]</label><label class="expand" for="c-40676419">[2 more]</label></div><br/><div class="children"><div class="content">A lot of html, css, and JavaScript may not be independent.</div><br/><div id="40678129" class="c"><input type="checkbox" id="c-40678129" checked=""/><div class="controls bullet"><span class="by">kelnos</span><span>|</span><a href="#40676383">root</a><span>|</span><a href="#40676419">parent</a><span>|</span><a href="#40674197">next</a><span>|</span><label class="collapse" for="c-40678129">[-]</label><label class="expand" for="c-40678129">[1 more]</label></div><br/><div class="children"><div class="content">Sure, but if you parse the HTMl faster, you find the &lt;script&gt; and &lt;link rel=&quot;stylesheet&quot;&gt; tags sooner, and can kick off another network thread to start fetching those files sooner.  Overall you end up with a faster page load.</div><br/></div></div></div></div></div></div></div></div><div id="40674197" class="c"><input type="checkbox" id="c-40674197" checked=""/><div class="controls bullet"><span class="by">o11c</span><span>|</span><a href="#40676383">prev</a><span>|</span><a href="#40675149">next</a><span>|</span><label class="collapse" for="c-40674197">[-]</label><label class="expand" for="c-40674197">[2 more]</label></div><br/><div class="children"><div class="content">And how does `strcspn` from various libcs compare?</div><br/></div></div><div id="40675149" class="c"><input type="checkbox" id="c-40675149" checked=""/><div class="controls bullet"><span class="by">klysm</span><span>|</span><a href="#40674197">prev</a><span>|</span><a href="#40675455">next</a><span>|</span><label class="collapse" for="c-40675149">[-]</label><label class="expand" for="c-40675149">[24 more]</label></div><br/><div class="children"><div class="content">It’s always crazy to me that we have picked encodings for data that are human-first to send between computers. JSON is in a similar boat. Absolutely enormous amounts of computing power are spent on serialization and deserialization. That latency is experienced everywhere too. If we used zero-copy serialization structures everywhere, a whole lot of compute would be saved</div><br/><div id="40678868" class="c"><input type="checkbox" id="c-40678868" checked=""/><div class="controls bullet"><span class="by">nasretdinov</span><span>|</span><a href="#40675149">parent</a><span>|</span><a href="#40675276">next</a><span>|</span><label class="collapse" for="c-40678868">[-]</label><label class="expand" for="c-40678868">[1 more]</label></div><br/><div class="children"><div class="content">&gt; That latency is experienced everywhere too.<p>Don&#x27;t confuse latency and bandwidth though. Most of those messages are relatively small, so they don&#x27;t contribute to (network) latency almost at all. Plus gzip exists, further reducing the amount of data transmitted, thus both reducing latency and improving bandwidth utilisation.<p>Also usually when it comes to cases where text would be actually a bottleneck (e.g. images, videos, audio, etc), binary formats are preferred and work very well, and generally you can tolerate e.g. images or audio being slightly broken, so you don&#x27;t need to debug those formats too frequently. It&#x27;s a nightmare do debug them though.</div><br/></div></div><div id="40675276" class="c"><input type="checkbox" id="c-40675276" checked=""/><div class="controls bullet"><span class="by">p_l</span><span>|</span><a href="#40675149">parent</a><span>|</span><a href="#40678868">prev</a><span>|</span><a href="#40676149">next</a><span>|</span><label class="collapse" for="c-40675276">[-]</label><label class="expand" for="c-40675276">[1 more]</label></div><br/><div class="children"><div class="content">Considerable portion of that was early ARPANET work often involving somewhat lacking access to hardware, so I&#x27;m it&#x27;s formative ages internet had a lot of directly attaching teletypes to network ports.<p>Also one can&#x27;t forget about TIPs, which provided &quot;phone modem to telnet-like&quot; bridge service in ARPANET.<p>Another part was how text was the one thing that people <i>had</i> standardise enough between different computers. FTP&#x27;s ASCII and binary modes aren&#x27;t about love conversion for Unix, but because &quot;binary&quot; meant totally different things on different hosts (could be 8bit octets, could be 28bit words, could be 36bit words, could be 60 bit, before internet fully settled down there were 40 bit hosts too).<p>Also people are scared of compilers.<p>All of that led to cultural bias towards textual protocols</div><br/></div></div><div id="40676149" class="c"><input type="checkbox" id="c-40676149" checked=""/><div class="controls bullet"><span class="by">btown</span><span>|</span><a href="#40675149">parent</a><span>|</span><a href="#40675276">prev</a><span>|</span><a href="#40675908">next</a><span>|</span><label class="collapse" for="c-40676149">[-]</label><label class="expand" for="c-40676149">[2 more]</label></div><br/><div class="children"><div class="content">There&#x27;s a parallel universe where the right person on the Google Chrome Network Tab team (or, earlier, the Firebug team) foresaw this a decade ago, and resolved: &quot;we will make it possible for any developer to plug in a custom binary parser in the Network Tab, able to access setup files from the project at hand, and do so in a safe and sandboxed way that&#x27;s easy to deploy to colleagues.&quot; Then a billion binary formats would have bloomed. But that&#x27;s not the world we ended up in.</div><br/><div id="40676174" class="c"><input type="checkbox" id="c-40676174" checked=""/><div class="controls bullet"><span class="by">klysm</span><span>|</span><a href="#40675149">root</a><span>|</span><a href="#40676149">parent</a><span>|</span><a href="#40675908">next</a><span>|</span><label class="collapse" for="c-40676174">[-]</label><label class="expand" for="c-40676174">[1 more]</label></div><br/><div class="children"><div class="content">I think that’s really the difference though: tooling. That’s all you need to make it easy</div><br/></div></div></div></div><div id="40675908" class="c"><input type="checkbox" id="c-40675908" checked=""/><div class="controls bullet"><span class="by">hinkley</span><span>|</span><a href="#40675149">parent</a><span>|</span><a href="#40676149">prev</a><span>|</span><a href="#40677884">next</a><span>|</span><label class="collapse" for="c-40675908">[-]</label><label class="expand" for="c-40675908">[3 more]</label></div><br/><div class="children"><div class="content">It&#x27;s about agility (feedback loops), and enough of the problems with it as a transport mechanism can be addressed by transport encodings that we put up with the rest.<p>Is there a similar format that is more amenable to SIMD but has similar ergonomics? That remains to be seen. But if someone makes a compelling case then I&#x27;m sure that not only could I be convinced but I could convince others.<p>Code is meant to be read by humans, and only incidentally by computers. Transport formats are the same thing. HTTP is an even worse format than JSON, and we have really done very little to change its line format in 35 years. It&#x27;s adequate to the task.</div><br/><div id="40676122" class="c"><input type="checkbox" id="c-40676122" checked=""/><div class="controls bullet"><span class="by">klysm</span><span>|</span><a href="#40675149">root</a><span>|</span><a href="#40675908">parent</a><span>|</span><a href="#40675946">next</a><span>|</span><label class="collapse" for="c-40676122">[-]</label><label class="expand" for="c-40676122">[1 more]</label></div><br/><div class="children"><div class="content">It not changing is not an indication of its adequacy. It’s merely an indication of backwards compatibility and lock-in effects. It’s not practical to change it even if we did have something better.</div><br/></div></div><div id="40675946" class="c"><input type="checkbox" id="c-40675946" checked=""/><div class="controls bullet"><span class="by">jvanderbot</span><span>|</span><a href="#40675149">root</a><span>|</span><a href="#40675908">parent</a><span>|</span><a href="#40676122">prev</a><span>|</span><a href="#40677884">next</a><span>|</span><label class="collapse" for="c-40675946">[-]</label><label class="expand" for="c-40675946">[1 more]</label></div><br/><div class="children"><div class="content">From the moment I understood the weakness of my encodings, it disgusted me.</div><br/></div></div></div></div><div id="40677884" class="c"><input type="checkbox" id="c-40677884" checked=""/><div class="controls bullet"><span class="by">intelVISA</span><span>|</span><a href="#40675149">parent</a><span>|</span><a href="#40675908">prev</a><span>|</span><a href="#40675856">next</a><span>|</span><label class="collapse" for="c-40677884">[-]</label><label class="expand" for="c-40677884">[1 more]</label></div><br/><div class="children"><div class="content">Most (good) orgs use zero copy binary serde in their backends, JSON is only for end users.</div><br/></div></div><div id="40675856" class="c"><input type="checkbox" id="c-40675856" checked=""/><div class="controls bullet"><span class="by">pquki4</span><span>|</span><a href="#40675149">parent</a><span>|</span><a href="#40677884">prev</a><span>|</span><a href="#40675495">next</a><span>|</span><label class="collapse" for="c-40675856">[-]</label><label class="expand" for="c-40675856">[9 more]</label></div><br/><div class="children"><div class="content">JSON is usually used for front end-back end communication or public API endpoints, otherwise protobuf&#x2F;Thrift&#x2F;Avro is commonly used in the backend for internal services (that is controlled by one organization), for very good reasons. Same for HTML -- you need to thank HTML for being able to read hacker news frontpage on a 10 year old kindle with a barely usable browser. I suggest you look all these up before complaining about nothing.</div><br/><div id="40676146" class="c"><input type="checkbox" id="c-40676146" checked=""/><div class="controls bullet"><span class="by">klysm</span><span>|</span><a href="#40675149">root</a><span>|</span><a href="#40675856">parent</a><span>|</span><a href="#40676051">next</a><span>|</span><label class="collapse" for="c-40676146">[-]</label><label class="expand" for="c-40676146">[1 more]</label></div><br/><div class="children"><div class="content">I don’t think it’s very good reasons. We could definitely have binary first serialization protocols and good tooling built into the browser. But no, we encode everything as text, even binary stuff as base64, and whack that into strings</div><br/></div></div><div id="40676051" class="c"><input type="checkbox" id="c-40676051" checked=""/><div class="controls bullet"><span class="by">geraldwhen</span><span>|</span><a href="#40675149">root</a><span>|</span><a href="#40675856">parent</a><span>|</span><a href="#40676146">prev</a><span>|</span><a href="#40675495">next</a><span>|</span><label class="collapse" for="c-40676051">[-]</label><label class="expand" for="c-40676051">[7 more]</label></div><br/><div class="children"><div class="content">All of those are slower than json in many contexts. JSON parsing and serialization is very fast!</div><br/><div id="40676134" class="c"><input type="checkbox" id="c-40676134" checked=""/><div class="controls bullet"><span class="by">klysm</span><span>|</span><a href="#40675149">root</a><span>|</span><a href="#40676051">parent</a><span>|</span><a href="#40675495">next</a><span>|</span><label class="collapse" for="c-40676134">[-]</label><label class="expand" for="c-40676134">[6 more]</label></div><br/><div class="children"><div class="content">In what context is json slower than protobuf?</div><br/><div id="40678471" class="c"><input type="checkbox" id="c-40678471" checked=""/><div class="controls bullet"><span class="by">698969</span><span>|</span><a href="#40675149">root</a><span>|</span><a href="#40676134">parent</a><span>|</span><a href="#40677417">next</a><span>|</span><label class="collapse" for="c-40678471">[-]</label><label class="expand" for="c-40678471">[1 more]</label></div><br/><div class="children"><div class="content">In browser Javascript, because there you have to load the decoder which is already  slower to parse than JSON, then run it in the JS vm to do the actual decoding whereas JSON is built in and has a native highly-optimized parser.</div><br/></div></div><div id="40677417" class="c"><input type="checkbox" id="c-40677417" checked=""/><div class="controls bullet"><span class="by">vitus</span><span>|</span><a href="#40675149">root</a><span>|</span><a href="#40676134">parent</a><span>|</span><a href="#40678471">prev</a><span>|</span><a href="#40675495">next</a><span>|</span><label class="collapse" for="c-40677417">[-]</label><label class="expand" for="c-40677417">[4 more]</label></div><br/><div class="children"><div class="content">Did you mean to ask the reverse question (in what context is protobuf slower than json)? Because that&#x27;s definitely the question on my mind, since GP&#x27;s assertion runs counter to my expectations and experience.<p>JSON is a heavy-weight format that requires significantly more memory for both serialization and deserialization, and the representations of values in JSON are optimized for human consumption rather than machine consumption.<p>Just listing a few examples:<p>- Strings in JSON require you to scan for the terminating quotation mark that isn&#x27;t escaped. Meanwhile, in protobuf, the length of the string is given to you; you can just grab the bytes directly.<p>- Parsing an integer in JSON requires multiplication by 10 and addition &#x2F; subtraction <i>for each digit</i>. Meanwhile, in protobuf, fixed64 and related types are either in host order or are just a ntohl away; int64 and other varint types only require bit twiddling (masks, shifts, etc). Do you think it&#x27;s easier to parse &quot;4294967296&quot; from a string, or 5 bytes along the lines of {0x88, 0x80, 0x80, 0x80, 0x00}?<p>- Having a format agreed-upon ahead of time (protobuf) means that your keys don&#x27;t require more string parsing (JSON).</div><br/><div id="40678622" class="c"><input type="checkbox" id="c-40678622" checked=""/><div class="controls bullet"><span class="by">anonymoushn</span><span>|</span><a href="#40675149">root</a><span>|</span><a href="#40677417">parent</a><span>|</span><a href="#40678879">next</a><span>|</span><label class="collapse" for="c-40678622">[-]</label><label class="expand" for="c-40678622">[1 more]</label></div><br/><div class="children"><div class="content">&gt; - Parsing an integer in JSON requires multiplication by 10 and addition &#x2F; subtraction for each digit. Meanwhile, in protobuf, fixed64 and related types are either in host order or are just a ntohl away; int64 and other varint types only require bit twiddling (masks, shifts, etc). Do you think it&#x27;s easier to parse &quot;4294967296&quot; from a string, or 5 bytes along the lines of {0x88, 0x80, 0x80, 0x80, 0x00}?<p>For this one, actually I think the varint may be harder because you have to parse it before you know which byte the next value starts on, but recently there has been some progress in the area of fast varint parsers. For parsing decimal numbers, a good start is here <a href="http:&#x2F;&#x2F;0x80.pl&#x2F;articles&#x2F;simd-parsing-int-sequences.html" rel="nofollow">http:&#x2F;&#x2F;0x80.pl&#x2F;articles&#x2F;simd-parsing-int-sequences.html</a>. Some users at <a href="https:&#x2F;&#x2F;highload.fun&#x2F;tasks&#x2F;1&#x2F;leaderboard" rel="nofollow">https:&#x2F;&#x2F;highload.fun&#x2F;tasks&#x2F;1&#x2F;leaderboard</a> are calculating the sum of parsed base-10 integers at about the speed of reading the string from RAM, but this task is subtly easier than parsing each number individually, which may only be doable at half or a quarter of the speed of reading the string from RAM, and then you&#x27;d have to pay a bit more to also write out the parsed values to another buffer.</div><br/></div></div><div id="40678879" class="c"><input type="checkbox" id="c-40678879" checked=""/><div class="controls bullet"><span class="by">geraldwhen</span><span>|</span><a href="#40675149">root</a><span>|</span><a href="#40677417">parent</a><span>|</span><a href="#40678622">prev</a><span>|</span><a href="#40677635">next</a><span>|</span><label class="collapse" for="c-40678879">[-]</label><label class="expand" for="c-40678879">[1 more]</label></div><br/><div class="children"><div class="content">Run benchmarks. It doesn’t matter what I think is easier to parse.<p>Protobuff is slower than JSON.parse in node by 4-8x for my data sets: large reference data needed.<p>I was only measuring decode time, since that’s I can recompute my data well in advance.</div><br/></div></div><div id="40677635" class="c"><input type="checkbox" id="c-40677635" checked=""/><div class="controls bullet"><span class="by">anonymoushn</span><span>|</span><a href="#40675149">root</a><span>|</span><a href="#40677417">parent</a><span>|</span><a href="#40678879">prev</a><span>|</span><a href="#40675495">next</a><span>|</span><label class="collapse" for="c-40677635">[-]</label><label class="expand" for="c-40677635">[1 more]</label></div><br/><div class="children"><div class="content">The benchmarks available for protobuf generally have it parsing like 5x slower than json (and I suspect the payloads are smaller, but not 5x smaller). I don&#x27;t think that the code generators shipped with protobuf generate parsers of comparable quality to simdjson, so it&#x27;s a bit unfair in that sense.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="40675495" class="c"><input type="checkbox" id="c-40675495" checked=""/><div class="controls bullet"><span class="by">bigbuppo</span><span>|</span><a href="#40675149">parent</a><span>|</span><a href="#40675856">prev</a><span>|</span><a href="#40676599">next</a><span>|</span><label class="collapse" for="c-40675495">[-]</label><label class="expand" for="c-40675495">[4 more]</label></div><br/><div class="children"><div class="content">So... what you&#x27;re saying is that we should do what cobol did in 1960?</div><br/><div id="40675805" class="c"><input type="checkbox" id="c-40675805" checked=""/><div class="controls bullet"><span class="by">dingdingdang</span><span>|</span><a href="#40675149">root</a><span>|</span><a href="#40675495">parent</a><span>|</span><a href="#40676599">next</a><span>|</span><label class="collapse" for="c-40675805">[-]</label><label class="expand" for="c-40675805">[3 more]</label></div><br/><div class="children"><div class="content">I tend to agree here, judiciously used json (these days often running under zstd compression) is seldomly the bottleneck on anything and allows immediate human debugging if need be.</div><br/><div id="40675923" class="c"><input type="checkbox" id="c-40675923" checked=""/><div class="controls bullet"><span class="by">hinkley</span><span>|</span><a href="#40675149">root</a><span>|</span><a href="#40675805">parent</a><span>|</span><a href="#40676114">next</a><span>|</span><label class="collapse" for="c-40675923">[-]</label><label class="expand" for="c-40675923">[1 more]</label></div><br/><div class="children"><div class="content">What we actually implement is often more constrained by what we can prototype and experiment on than how fast or how well we can define formal requirements and implement them.<p>So much good stuff in software is down to a mix of serendipity and &#x27;what if&#x27; and anything that reduces friction (improves ergonomics) has my vote.</div><br/></div></div><div id="40676114" class="c"><input type="checkbox" id="c-40676114" checked=""/><div class="controls bullet"><span class="by">klysm</span><span>|</span><a href="#40675149">root</a><span>|</span><a href="#40675805">parent</a><span>|</span><a href="#40675923">prev</a><span>|</span><a href="#40676599">next</a><span>|</span><label class="collapse" for="c-40676114">[-]</label><label class="expand" for="c-40676114">[1 more]</label></div><br/><div class="children"><div class="content">Bottleneck suggests optimization for throughput. I care about latency more</div><br/></div></div></div></div></div></div><div id="40676599" class="c"><input type="checkbox" id="c-40676599" checked=""/><div class="controls bullet"><span class="by">akira2501</span><span>|</span><a href="#40675149">parent</a><span>|</span><a href="#40675495">prev</a><span>|</span><a href="#40675957">next</a><span>|</span><label class="collapse" for="c-40676599">[-]</label><label class="expand" for="c-40676599">[1 more]</label></div><br/><div class="children"><div class="content">We did that.  You&#x27;re welcome to use ASN.1 or some restricted subset of it if you want,  and people did for quite some time,  but it&#x27;s brittle and inflexible nature and it&#x27;s inability to be quickly edited or observed during edit-test-debug cycles deprecated it the minute we had something human readable that could reasonably replace it.<p>In any case..  computing is entirely about serving human needs..  early computer science sort of missed the boat on that point.</div><br/></div></div></div></div><div id="40675455" class="c"><input type="checkbox" id="c-40675455" checked=""/><div class="controls bullet"><span class="by">ijidak</span><span>|</span><a href="#40675149">prev</a><span>|</span><label class="collapse" for="c-40675455">[-]</label><label class="expand" for="c-40675455">[5 more]</label></div><br/><div class="children"><div class="content">It&#x27;s amazing how ChatGPT makes code the reader may not be familiar with faster to grok.<p>The examples in this article assume familiarity with SIMD.<p>In the past, I would have tabled an article like this for deciphering later.<p>But, with ChatGPT, I was able to ask about just a few bits of code and immediately grok the implementation.<p>From a technology standpoint, the future is looking scary productive.<p>Can&#x27;t wait to see what new vistas developers open up with these new super powers.</div><br/><div id="40677624" class="c"><input type="checkbox" id="c-40677624" checked=""/><div class="controls bullet"><span class="by">anonymoushn</span><span>|</span><a href="#40675455">parent</a><span>|</span><a href="#40675521">next</a><span>|</span><label class="collapse" for="c-40677624">[-]</label><label class="expand" for="c-40677624">[1 more]</label></div><br/><div class="children"><div class="content">LLMs are completely useless for explaining code that uses shuffles, let alone code that uses lookup tables of shuffles or uses shuffles in unconventional ways.</div><br/></div></div><div id="40675521" class="c"><input type="checkbox" id="c-40675521" checked=""/><div class="controls bullet"><span class="by">secondcoming</span><span>|</span><a href="#40675455">parent</a><span>|</span><a href="#40677624">prev</a><span>|</span><label class="collapse" for="c-40675521">[-]</label><label class="expand" for="c-40675521">[3 more]</label></div><br/><div class="children"><div class="content">you’re assuming the output from ChatGPT is correct, and it’s not bluffing.</div><br/><div id="40676505" class="c"><input type="checkbox" id="c-40676505" checked=""/><div class="controls bullet"><span class="by">spartanatreyu</span><span>|</span><a href="#40675455">root</a><span>|</span><a href="#40675521">parent</a><span>|</span><label class="collapse" for="c-40676505">[-]</label><label class="expand" for="c-40676505">[2 more]</label></div><br/><div class="children"><div class="content">Bluffing is the wrong word. It assumes that the LLM is capable of knowingly telling falsehoods.<p>Instead it always has full confidence in whatever it&#x27;s last &quot;thought&quot; must be correct, even when asked to double check it&#x27;s own output, even in a loop. It&#x27;ll either doubledown on a falsehood or generate a new result and have complete confidence that it&#x27;s last result was wrong and that it&#x27;s new result must be correct, even though the initial confidence was the same.<p>&quot;Bluffing&quot; certainly isn&#x27;t the right word.<p>&quot;Hallucinating&quot; fits much better.</div><br/><div id="40678155" class="c"><input type="checkbox" id="c-40678155" checked=""/><div class="controls bullet"><span class="by">kelnos</span><span>|</span><a href="#40675455">root</a><span>|</span><a href="#40676505">parent</a><span>|</span><label class="collapse" for="c-40678155">[-]</label><label class="expand" for="c-40678155">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>By comparison, modern C# is memory safe all the way down, possible to implement even very complicated data structures without a single line of unsafe code</i><p>&quot;Confidence&quot; is the wrong word.  Confidence is a capability of thinking, sentient beings, and LLMs are not that.<p>I say this to point out the futility in your post; &quot;bluffing&quot; is a perfectly fine thing for the GP to say, because it gets the point across.  All of us here should know that an LLM can&#x27;t actually bluff.  (And if you&#x27;d prefer a different term, remember that not everyone on HN speaks English as their first language, and may not immediately come up with a more appropriate way of phrasing it.)</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></body></html>