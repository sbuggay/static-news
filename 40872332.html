<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1720083676209" as="style"/><link rel="stylesheet" href="styles.css?v=1720083676209"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://lazamar.github.io/haskell-data-compression-with-huffman-codes/">Building a data compression utility in Haskell using Huffman codes</a> <span class="domain">(<a href="https://lazamar.github.io">lazamar.github.io</a>)</span></div><div class="subtext"><span>lazamar</span> | <span>20 comments</span></div><br/><div><div id="40873443" class="c"><input type="checkbox" id="c-40873443" checked=""/><div class="controls bullet"><span class="by">benreesman</span><span>|</span><a href="#40873382">next</a><span>|</span><label class="collapse" for="c-40873443">[-]</label><label class="expand" for="c-40873443">[1 more]</label></div><br/><div class="children"><div class="content">Haskell is a really nice language. In general I don’t identify as an X programmer for any value of X: I tend to write in a half dozen languages daily and they all suck in their own special way.<p>But on two separate occasions I made important career decisions with opportunity cost to work with highly lethal GHC contributors: those people are just really good.<p>If Haskell sucks like all languages it’s because Haskell excels at using computers to <i>compute</i> something: Haskell considers data shuffling a strictly secondary concern compared to doing actual computations.</div><br/></div></div><div id="40873382" class="c"><input type="checkbox" id="c-40873382" checked=""/><div class="controls bullet"><span class="by">tromp</span><span>|</span><a href="#40873443">prev</a><span>|</span><a href="#40873138">next</a><span>|</span><label class="collapse" for="c-40873382">[-]</label><label class="expand" for="c-40873382">[2 more]</label></div><br/><div class="children"><div class="content">&gt; To make it unambiguous we must make sure that no code word is a prefix of another code word.<p>Technically, this is not quite correct. The class of so-called uniquely decodable codes is unambigous, and a superset of the prefix codes. One simple example of a 
uniquely decodable code is the reverse of a prefix code. For the example in the article that would be<p><pre><code>    a 1
    b 00
    c 10
</code></pre>
While the code for a is a prefix for the code of c, one can still unambiguously decode any code sequence by processing it in reverse order. It would be interesting to see a uniquely decodable code that is neither a prefix code nor one in reverse.</div><br/><div id="40873413" class="c"><input type="checkbox" id="c-40873413" checked=""/><div class="controls bullet"><span class="by">lazamar</span><span>|</span><a href="#40873382">parent</a><span>|</span><a href="#40873138">next</a><span>|</span><label class="collapse" for="c-40873413">[-]</label><label class="expand" for="c-40873413">[1 more]</label></div><br/><div class="children"><div class="content">That’s interesting. I guess this is not usually used because you may have a long string of bits that is ambiguous till you get to a disambiguating bit.<p>Something like<p>`100000000000000001`<p>In this case, where to know whether the first code was an `a` or a `c` you have to read all the way to where the zeroes end.</div><br/></div></div></div></div><div id="40873138" class="c"><input type="checkbox" id="c-40873138" checked=""/><div class="controls bullet"><span class="by">mrkeen</span><span>|</span><a href="#40873382">prev</a><span>|</span><a href="#40873240">next</a><span>|</span><label class="collapse" for="c-40873138">[-]</label><label class="expand" for="c-40873138">[4 more]</label></div><br/><div class="children"><div class="content">There exists an array-based, in-place algorithm for this, reducing the need to allocate trees and chase pointers.<p>I mention this only because, when I learned the tree-based approach at uni, I simply wasn&#x27;t aware that there was another way to do it, and I&#x27;m wondering how many of you that&#x27;s true for as well.<p>While the tree approach is intuitive and illuminating, it probably makes more sense to work with in-place arrays, since the situations when you care most about compression are probably the situations when you have a lot of data and want to run fast.<p><pre><code>  In-Place Calculation of Minimum-Redundancy Codes
  Moffat, Katajainen.  1995.
  http:&#x2F;&#x2F;hjemmesider.diku.dk&#x2F;~jyrki&#x2F;Paper&#x2F;WADS95.pdf</code></pre></div><br/><div id="40873162" class="c"><input type="checkbox" id="c-40873162" checked=""/><div class="controls bullet"><span class="by">lifthrasiir</span><span>|</span><a href="#40873138">parent</a><span>|</span><a href="#40873228">next</a><span>|</span><label class="collapse" for="c-40873162">[-]</label><label class="expand" for="c-40873162">[2 more]</label></div><br/><div class="children"><div class="content">&gt; In-Place Calculation of Minimum-Redundancy Codes<p>Or in general, refer to &quot;On the Implementation of Minimum Redundancy Prefix Codes&quot; by Moffat and Turpin (1997), as strongly recommended and later explained by Charles Bloom [1].<p>[1] <a href="https:&#x2F;&#x2F;cbloomrants.blogspot.com&#x2F;2010&#x2F;08&#x2F;08-12-10-lost-huffman-paper.html" rel="nofollow">https:&#x2F;&#x2F;cbloomrants.blogspot.com&#x2F;2010&#x2F;08&#x2F;08-12-10-lost-huffm...</a></div><br/><div id="40873294" class="c"><input type="checkbox" id="c-40873294" checked=""/><div class="controls bullet"><span class="by">lazamar</span><span>|</span><a href="#40873138">root</a><span>|</span><a href="#40873162">parent</a><span>|</span><a href="#40873228">next</a><span>|</span><label class="collapse" for="c-40873294">[-]</label><label class="expand" for="c-40873294">[1 more]</label></div><br/><div class="children"><div class="content">Thanks for the link. I was motivated to write the post after reading Moffat’s book ‘Managing Gigabytes’. A pearl from the 90’s.<p>The authors mention this technique in the second edition.</div><br/></div></div></div></div><div id="40873228" class="c"><input type="checkbox" id="c-40873228" checked=""/><div class="controls bullet"><span class="by">mjan22640</span><span>|</span><a href="#40873138">parent</a><span>|</span><a href="#40873162">prev</a><span>|</span><a href="#40873240">next</a><span>|</span><label class="collapse" for="c-40873228">[-]</label><label class="expand" for="c-40873228">[1 more]</label></div><br/><div class="children"><div class="content">&gt; and I&#x27;m wondering how many of you that&#x27;s true for as well<p>the phrasing sounds like a list comprehension</div><br/></div></div></div></div><div id="40873240" class="c"><input type="checkbox" id="c-40873240" checked=""/><div class="controls bullet"><span class="by">banish-m4</span><span>|</span><a href="#40873138">prev</a><span>|</span><a href="#40873300">next</a><span>|</span><label class="collapse" for="c-40873240">[-]</label><label class="expand" for="c-40873240">[1 more]</label></div><br/><div class="children"><div class="content">Last time I used Huffman codes, it was to run a MICMAC processor macroprogram (assembly text) in the fewest number of microcycles and to use the fewest microinstructions in the microprogram (microcode). So starting with a histogram of the macroinstructions executed (IIRC, I first wrote an interpreter in C to count how many of each were executed), I crafted a progressive decoding microcode program to implement all of the required ISA macro-operations. IIRC, the macro instruction ISA I created was bit-granular instead of byte-oriented. In the real world, it would&#x27;ve been slow and inconvenient. What&#x27;s nice about Huffman codes is that you can vary the prefix depth based on the distribution of values, so you don&#x27;t have to have lopsided codes based on 1 bit prefixes.<p>Also, the microprogram had to deal with branch prediction because it was a non-superscalar pipelined processor model. Guess the wrong branch, and enjoy wasting cycles on a pipeline stall while the correct branch filters forward.</div><br/></div></div><div id="40873300" class="c"><input type="checkbox" id="c-40873300" checked=""/><div class="controls bullet"><span class="by">atlintots</span><span>|</span><a href="#40873240">prev</a><span>|</span><a href="#40872934">next</a><span>|</span><label class="collapse" for="c-40873300">[-]</label><label class="expand" for="c-40873300">[1 more]</label></div><br/><div class="children"><div class="content">This is great! Are there any other similar tutorials going through writing a Haskell program, but with some more advanced features (monad transformers, lenses, etc)</div><br/></div></div><div id="40872934" class="c"><input type="checkbox" id="c-40872934" checked=""/><div class="controls bullet"><span class="by">alwinaugustin</span><span>|</span><a href="#40873300">prev</a><span>|</span><a href="#40873004">next</a><span>|</span><label class="collapse" for="c-40872934">[-]</label><label class="expand" for="c-40872934">[1 more]</label></div><br/><div class="children"><div class="content">Thanks for sharing. Very nice and insightful.</div><br/></div></div><div id="40873004" class="c"><input type="checkbox" id="c-40873004" checked=""/><div class="controls bullet"><span class="by">londons_explore</span><span>|</span><a href="#40872934">prev</a><span>|</span><a href="#40872674">next</a><span>|</span><label class="collapse" for="c-40873004">[-]</label><label class="expand" for="c-40873004">[7 more]</label></div><br/><div class="children"><div class="content">For all readers, arithmetic codes are better in nearly all ways.   They can be implemented in less RAM and code, they compress and decompress to a better ratio, and the probabilities of different symbols appearing can be dynamically updated during the stream far more easily.<p>The only reason Huffman codes are used is they were invented first and arithmetic codes were patented.    That patent has now expired, so we should use the better design.</div><br/><div id="40873342" class="c"><input type="checkbox" id="c-40873342" checked=""/><div class="controls bullet"><span class="by">lazamar</span><span>|</span><a href="#40873004">parent</a><span>|</span><a href="#40873124">next</a><span>|</span><label class="collapse" for="c-40873342">[-]</label><label class="expand" for="c-40873342">[1 more]</label></div><br/><div class="children"><div class="content">There is one way in which Huffman codes are better: they are easier to explain and simpler to implement.<p>I went for simplicity of exposition in the post, but arithmetic coders can indeed get arbitrarily close to the entropy, which is not quite the case with Huffman.</div><br/></div></div><div id="40873124" class="c"><input type="checkbox" id="c-40873124" checked=""/><div class="controls bullet"><span class="by">kqr</span><span>|</span><a href="#40873004">parent</a><span>|</span><a href="#40873342">prev</a><span>|</span><a href="#40873025">next</a><span>|</span><label class="collapse" for="c-40873124">[-]</label><label class="expand" for="c-40873124">[3 more]</label></div><br/><div class="children"><div class="content">I was under the impression that arithmetic codes are guaranteed to be <i>at least</i> one bit less efficient than Huffman codes per input block. What makes you say they have better compression ratio?<p>Are you thinking of pre-defined Huffman tables that aren&#x27;t adapted to the input? Because the latter ought to be as good as it gets.<p>(I agree with the other benefits. Since arithmetic coding tables are built in a streaming fashion rather than constructing the codebook up front, they are more memory-efficient while working.)</div><br/><div id="40873210" class="c"><input type="checkbox" id="c-40873210" checked=""/><div class="controls bullet"><span class="by">hcs</span><span>|</span><a href="#40873004">root</a><span>|</span><a href="#40873124">parent</a><span>|</span><a href="#40873179">next</a><span>|</span><label class="collapse" for="c-40873210">[-]</label><label class="expand" for="c-40873210">[1 more]</label></div><br/><div class="children"><div class="content">Huffman codes are less efficient per symbol since each symbol is a bit string, arithmetic coding effectively smears symbols across bits more finely. Whether you use a dynamic or static probability model is a different issue applying to either coding method. (Emotionally though I prefer Huffman codes, they&#x27;re just so <i>neat</i>)</div><br/></div></div><div id="40873179" class="c"><input type="checkbox" id="c-40873179" checked=""/><div class="controls bullet"><span class="by">lifthrasiir</span><span>|</span><a href="#40873004">root</a><span>|</span><a href="#40873124">parent</a><span>|</span><a href="#40873210">prev</a><span>|</span><a href="#40873025">next</a><span>|</span><label class="collapse" for="c-40873179">[-]</label><label class="expand" for="c-40873179">[1 more]</label></div><br/><div class="children"><div class="content">Huffman codes are conceptually isomorphic to arithmetic codes where all probabilities are 2^-k with k integer, so they have an obvious disadvantage due to more inaccurate symbol distribution.</div><br/></div></div></div></div><div id="40873025" class="c"><input type="checkbox" id="c-40873025" checked=""/><div class="controls bullet"><span class="by">londons_explore</span><span>|</span><a href="#40873004">parent</a><span>|</span><a href="#40873124">prev</a><span>|</span><a href="#40873172">next</a><span>|</span><label class="collapse" for="c-40873025">[-]</label><label class="expand" for="c-40873025">[1 more]</label></div><br/><div class="children"><div class="content">Two slight benefits of Huffman codes over arithmetic:<p>* They usually self synchronize when some data is corrupted (but not guaranteed, does not apply where the Huffman table is dynamic)<p>* Neither Huffman nor arithmetic codes are easy to parallelize the decoding of, but Huffman is slightly easier.</div><br/></div></div><div id="40873172" class="c"><input type="checkbox" id="c-40873172" checked=""/><div class="controls bullet"><span class="by">lifthrasiir</span><span>|</span><a href="#40873004">parent</a><span>|</span><a href="#40873025">prev</a><span>|</span><a href="#40872674">next</a><span>|</span><label class="collapse" for="c-40873172">[-]</label><label class="expand" for="c-40873172">[1 more]</label></div><br/><div class="children"><div class="content">If you do have an option to switch from Huffman, rANS is now the way to go, not a clasical arithmetic coding.</div><br/></div></div></div></div><div id="40872674" class="c"><input type="checkbox" id="c-40872674" checked=""/><div class="controls bullet"><span class="by">tankfeeder</span><span>|</span><a href="#40873004">prev</a><span>|</span><a href="#40872875">next</a><span>|</span><label class="collapse" for="c-40872674">[-]</label><label class="expand" for="c-40872674">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;rosettacode.org&#x2F;wiki&#x2F;Huffman_coding" rel="nofollow">https:&#x2F;&#x2F;rosettacode.org&#x2F;wiki&#x2F;Huffman_coding</a></div><br/></div></div><div id="40872875" class="c"><input type="checkbox" id="c-40872875" checked=""/><div class="controls bullet"><span class="by">lynx23</span><span>|</span><a href="#40872674">prev</a><span>|</span><label class="collapse" for="c-40872875">[-]</label><label class="expand" for="c-40872875">[1 more]</label></div><br/><div class="children"><div class="content">Very nice read, thanks for sharing!</div><br/></div></div></div></div></div></div></div></body></html>