<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1700643667669" as="style"/><link rel="stylesheet" href="styles.css?v=1700643667669"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://resobscura.substack.com/p/margaret-mead-technocracy-and-the">Margaret Mead, technocracy, and the origins of AI&#x27;s ideological divide</a> <span class="domain">(<a href="https://resobscura.substack.com">resobscura.substack.com</a>)</span></div><div class="subtext"><span>benbreen</span> | <span>47 comments</span></div><br/><div><div id="38370999" class="c"><input type="checkbox" id="c-38370999" checked=""/><div class="controls bullet"><span class="by">AndrewKemendo</span><span>|</span><a href="#38374138">next</a><span>|</span><label class="collapse" for="c-38370999">[-]</label><label class="expand" for="c-38370999">[20 more]</label></div><br/><div class="children"><div class="content">We failed when we killed Cybernetics and AI became part of Computer Science instead of the multidisciplinary field it actually is<p>Weiner was an outspoken socialist and was persecuted for it, to such an extent that Cybernetics got needled to death and AI became “simply a matter of computing.”<p>Hopefully we all see now how wrong that was</div><br/><div id="38371577" class="c"><input type="checkbox" id="c-38371577" checked=""/><div class="controls bullet"><span class="by">benbreen</span><span>|</span><a href="#38370999">parent</a><span>|</span><a href="#38371957">next</a><span>|</span><label class="collapse" for="c-38371577">[-]</label><label class="expand" for="c-38371577">[6 more]</label></div><br/><div class="children"><div class="content">Author here. Thank you, I thought this was an interesting point. Researching the book this post is based on, I was really struck by who was actually attending the Macy cybernetic conferences — it was incredibly eclectic. Anthropologists, physiologists, psychiatrists... and, of course, also Claude Shannon and von Neumann.<p>Carving off computer science as a separate realm with less interdisciplinary input was definitely a fork in the road for the history of science.<p>By the way, if anyone is interested, you can find the list of cybernetics conference attendees here: <a href="https:&#x2F;&#x2F;www.asc-cybernetics.org&#x2F;foundations&#x2F;history&#x2F;MacyPeople.htm" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.asc-cybernetics.org&#x2F;foundations&#x2F;history&#x2F;MacyPeop...</a><p>And if anyone is <i>really</i> interested, here&#x27;s my book, which is coming out in January: <a href="https:&#x2F;&#x2F;www.hachettebookgroup.com&#x2F;titles&#x2F;benjamin-breen&#x2F;tripping-on-utopia&#x2F;9781538722374&#x2F;?lens=grand-central-publishing" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.hachettebookgroup.com&#x2F;titles&#x2F;benjamin-breen&#x2F;trip...</a></div><br/><div id="38376733" class="c"><input type="checkbox" id="c-38376733" checked=""/><div class="controls bullet"><span class="by">justincormack</span><span>|</span><a href="#38370999">root</a><span>|</span><a href="#38371577">parent</a><span>|</span><a href="#38374715">next</a><span>|</span><label class="collapse" for="c-38376733">[-]</label><label class="expand" for="c-38376733">[1 more]</label></div><br/><div class="children"><div class="content">This article about the Ratio Club cybernetics meetings in London is interesting <a href="http:&#x2F;&#x2F;users.sussex.ac.uk&#x2F;~philh&#x2F;pubs&#x2F;Ratio2.pdf" rel="nofollow noreferrer">http:&#x2F;&#x2F;users.sussex.ac.uk&#x2F;~philh&#x2F;pubs&#x2F;Ratio2.pdf</a></div><br/></div></div><div id="38374715" class="c"><input type="checkbox" id="c-38374715" checked=""/><div class="controls bullet"><span class="by">wolverine876</span><span>|</span><a href="#38370999">root</a><span>|</span><a href="#38371577">parent</a><span>|</span><a href="#38376733">prev</a><span>|</span><a href="#38371740">next</a><span>|</span><label class="collapse" for="c-38374715">[-]</label><label class="expand" for="c-38374715">[2 more]</label></div><br/><div class="children"><div class="content">Isn&#x27;t &#x27;Cognitive Science&#x27; (at least as I remember it) about bringing together again all those domains?</div><br/><div id="38375747" class="c"><input type="checkbox" id="c-38375747" checked=""/><div class="controls bullet"><span class="by">Zolde</span><span>|</span><a href="#38370999">root</a><span>|</span><a href="#38374715">parent</a><span>|</span><a href="#38371740">next</a><span>|</span><label class="collapse" for="c-38375747">[-]</label><label class="expand" for="c-38375747">[1 more]</label></div><br/><div class="children"><div class="content">Yes, but the focus is more on human cognition, where cybernetics has more focus on (business, complex, control) systems, (automated, biological) processes, and human collectives.<p>It is interesting how cognitive science sees AI as a sub-discipline, where AI sees cognitive science as its sub-discipline.<p>McCarthy was not too enamoured with the bombastic nature of Wiener&#x27;s persona and research, and may have birthed the field of AI, in part, to carve out his own field of study, and move away from an existing and defined field. As a result, control theory and reinforcement learning have a big overlap, yet use different words, approaches, and concepts.</div><br/></div></div></div></div><div id="38371740" class="c"><input type="checkbox" id="c-38371740" checked=""/><div class="controls bullet"><span class="by">AndrewKemendo</span><span>|</span><a href="#38370999">root</a><span>|</span><a href="#38371577">parent</a><span>|</span><a href="#38374715">prev</a><span>|</span><a href="#38371957">next</a><span>|</span><label class="collapse" for="c-38371740">[-]</label><label class="expand" for="c-38371740">[2 more]</label></div><br/><div class="children"><div class="content">Awesome. Glad to see there’s other people out there that care and understand that “AI” fully understood, is marginally about the computer, and primarily about society.</div><br/><div id="38376149" class="c"><input type="checkbox" id="c-38376149" checked=""/><div class="controls bullet"><span class="by">gopher_space</span><span>|</span><a href="#38370999">root</a><span>|</span><a href="#38371740">parent</a><span>|</span><a href="#38371957">next</a><span>|</span><label class="collapse" for="c-38376149">[-]</label><label class="expand" for="c-38376149">[1 more]</label></div><br/><div class="children"><div class="content">I’m just waiting to see who starts hiring English majors first.  I’ll join or invest.</div><br/></div></div></div></div></div></div><div id="38371957" class="c"><input type="checkbox" id="c-38371957" checked=""/><div class="controls bullet"><span class="by">gkew</span><span>|</span><a href="#38370999">parent</a><span>|</span><a href="#38371577">prev</a><span>|</span><a href="#38371804">next</a><span>|</span><label class="collapse" for="c-38371957">[-]</label><label class="expand" for="c-38371957">[1 more]</label></div><br/><div class="children"><div class="content">I agree and feel sad for the vanishing of Cybernetics.<p>Transdisciplinary fields are usually more delicate; they&#x27;re often the momentary confluences of scientifically-inclined humanists and prominent scientific fields of their time. Before cybernetics there was various ambitious&#x2F;systematic philosophy&#x2F;evolution crossovers like Herbert Spencer.<p>From what I&#x27;ve researched and worked with individuals on the edge of the field, the contemporary debates seems to be going for &quot;Second-order cybernetics&quot;<p>Possible resources of interest are &quot;IEEE Transactions on Cybernetics&quot; (<a href="https:&#x2F;&#x2F;ieeexplore.ieee.org&#x2F;xpl&#x2F;RecentIssue.jsp?reload=true&amp;punumber=6221036" rel="nofollow noreferrer">https:&#x2F;&#x2F;ieeexplore.ieee.org&#x2F;xpl&#x2F;RecentIssue.jsp?reload=true&amp;...</a>), as well as the work of Hugh Dubberly (Apple II, DNS) from Dubberly Design Office.</div><br/></div></div><div id="38371804" class="c"><input type="checkbox" id="c-38371804" checked=""/><div class="controls bullet"><span class="by">dekhn</span><span>|</span><a href="#38370999">parent</a><span>|</span><a href="#38371957">prev</a><span>|</span><a href="#38376442">next</a><span>|</span><label class="collapse" for="c-38371804">[-]</label><label class="expand" for="c-38371804">[3 more]</label></div><br/><div class="children"><div class="content">BTW the only CS class I took in college (in the mid-90s) was called Cybernetics, taught by Huffman (a Wiener disciple) and I can&#x27;t say it had anything to do with AI at all; it was all control theory and information theory (compression, message integrity, boolean circuit design).  I see it as complementary to ML in CS.  Personally I took the class to learn how to make robots and was very disappointed we didn&#x27;t cover that.</div><br/><div id="38373140" class="c"><input type="checkbox" id="c-38373140" checked=""/><div class="controls bullet"><span class="by">AndrewKemendo</span><span>|</span><a href="#38370999">root</a><span>|</span><a href="#38371804">parent</a><span>|</span><a href="#38376442">next</a><span>|</span><label class="collapse" for="c-38373140">[-]</label><label class="expand" for="c-38373140">[2 more]</label></div><br/><div class="children"><div class="content">Sounds like you learned a lot about AI actually :)<p>Especially for the time</div><br/><div id="38374731" class="c"><input type="checkbox" id="c-38374731" checked=""/><div class="controls bullet"><span class="by">tgv</span><span>|</span><a href="#38370999">root</a><span>|</span><a href="#38373140">parent</a><span>|</span><a href="#38376442">next</a><span>|</span><label class="collapse" for="c-38374731">[-]</label><label class="expand" for="c-38374731">[1 more]</label></div><br/><div class="children"><div class="content">In the 90s, we taught neural networks, and statistical machine learning in AI. Cybernetics (as a term) had been out of fashion for decades by then, if only because it was taken to be how Wikipedia describsed it: the study of &quot;circular causal and feedback mechanisms in biological and social systems&quot; and was the domain of applied mathematics and PDEs, whereas neural networks weren&#x27;t even recurrent.</div><br/></div></div></div></div></div></div><div id="38376442" class="c"><input type="checkbox" id="c-38376442" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#38370999">parent</a><span>|</span><a href="#38371804">prev</a><span>|</span><a href="#38374616">next</a><span>|</span><label class="collapse" for="c-38376442">[-]</label><label class="expand" for="c-38376442">[1 more]</label></div><br/><div class="children"><div class="content">Wait... unless I&#x27;m missing a lot here, the concrete parts of cybernetics became known as control theory (and the more wishy-washy parts are known as &quot;systems thinking&quot;), and in both cases, the <i>primary idea</i> behind it all is exactly to turn dynamic problems into &quot;simply a matter of computing&quot;.<p>That&#x27;s literally what the whole thing is about - you model a problem as a bunch of cybernetics&#x2F;control theory equations (with or without helper diagrams of boxes and arrows), do some <i>computing</i> on it, and implement the result in the physical world. In many cases, the computational model is partially included in the result itself - the physical control system includes a <i>computer</i> (whether it&#x27;s an analog or digital one) that keeps the physical system stable <i>by means of computation</i>, i.e. &quot;simply a matter of computing&quot;.<p>(In general, I feel many people didn&#x27;t get the memo: &quot;computing&quot; isn&#x27;t something &quot;techbros&quot; do; computing is a fundamental part of how we understand the world works - up there with energy conservation, thermodynamics, etc.)</div><br/></div></div><div id="38374616" class="c"><input type="checkbox" id="c-38374616" checked=""/><div class="controls bullet"><span class="by">kkylin</span><span>|</span><a href="#38370999">parent</a><span>|</span><a href="#38376442">prev</a><span>|</span><a href="#38376185">next</a><span>|</span><label class="collapse" for="c-38374616">[-]</label><label class="expand" for="c-38374616">[1 more]</label></div><br/><div class="children"><div class="content">&quot;Weiner&quot; should be Wiener?<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Norbert_Wiener" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Norbert_Wiener</a></div><br/></div></div><div id="38376185" class="c"><input type="checkbox" id="c-38376185" checked=""/><div class="controls bullet"><span class="by">classified</span><span>|</span><a href="#38370999">parent</a><span>|</span><a href="#38374616">prev</a><span>|</span><a href="#38374280">next</a><span>|</span><label class="collapse" for="c-38376185">[-]</label><label class="expand" for="c-38376185">[1 more]</label></div><br/><div class="children"><div class="content"><i>Wiener</i></div><br/></div></div><div id="38374280" class="c"><input type="checkbox" id="c-38374280" checked=""/><div class="controls bullet"><span class="by">alekseiprokopev</span><span>|</span><a href="#38370999">parent</a><span>|</span><a href="#38376185">prev</a><span>|</span><a href="#38376505">next</a><span>|</span><label class="collapse" for="c-38374280">[-]</label><label class="expand" for="c-38374280">[4 more]</label></div><br/><div class="children"><div class="content">Ironically enough, the people who followed Weiner’s work were persecuted in the USSR.</div><br/><div id="38376744" class="c"><input type="checkbox" id="c-38376744" checked=""/><div class="controls bullet"><span class="by">justincormack</span><span>|</span><a href="#38370999">root</a><span>|</span><a href="#38374280">parent</a><span>|</span><a href="#38376501">next</a><span>|</span><label class="collapse" for="c-38376744">[-]</label><label class="expand" for="c-38376744">[1 more]</label></div><br/><div class="children"><div class="content">The book How not to Network a Nation is good on this history</div><br/></div></div><div id="38376501" class="c"><input type="checkbox" id="c-38376501" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#38370999">root</a><span>|</span><a href="#38374280">parent</a><span>|</span><a href="#38376744">prev</a><span>|</span><a href="#38376644">next</a><span>|</span><label class="collapse" for="c-38376501">[-]</label><label class="expand" for="c-38376501">[1 more]</label></div><br/><div class="children"><div class="content">If you say you can use fancy maths to make tanks roll faster off the assembly lines, or guide an ICBM towards Moscow&#x2F;Washington, then the regime will happily support you. But if you get in your head that you can apply the same fancy math to run the economy, the regime will object - obviously - and label you as too communist&#x2F;not communist enough, and persecute you&#x2F;ship you off to a gulag.</div><br/></div></div><div id="38376644" class="c"><input type="checkbox" id="c-38376644" checked=""/><div class="controls bullet"><span class="by">paganel</span><span>|</span><a href="#38370999">root</a><span>|</span><a href="#38374280">parent</a><span>|</span><a href="#38376501">prev</a><span>|</span><a href="#38376505">next</a><span>|</span><label class="collapse" for="c-38376644">[-]</label><label class="expand" for="c-38376644">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve left a related comment somewhere else in in the thread, but it&#x27;s interesting that here in neighbouring Romania the practice&#x2F;science of Cybernetics was quite well regarded almost until the communist government fell.<p>Its heyday had certainly been back in the &#x27;70s, as in the &#x27;80s the focus shifted to some other stuff thanks to energy inputs getting too expensive and us becoming bankrupt because of that (someone should write a history of the alternative energy sources tried by the communist government back then, some of which are now getting tested by the West, too), but for sure people weren&#x27;t getting sent to prison because of it.<p>Here&#x27;s [1] a list of Cybernetics-related books published before 1989 that I can find at an old-books store here in Bucharest, and that search reminded me that one of the main proponents of Cybernetics around these parts was Manea Manescu [2], a guy which had been prime-minister of communist Romania in the &#x27;70s (just before that he had been in charge of the  State Planning Committee) and who stood by Ceausescu&#x27;s side until the very end (that list of books I linked to includes a book with his name on it).<p>[1] <a href="https:&#x2F;&#x2F;www.targulcartii.ro&#x2F;cauta&#x2F;cibernetica?filter_name=cibernetica&amp;filter_year_to=1989&amp;filter_price_from=&amp;filter_price_to=" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.targulcartii.ro&#x2F;cauta&#x2F;cibernetica?filter_name=ci...</a><p>[2] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Manea_M%C4%83nescu" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Manea_M%C4%83nescu</a></div><br/></div></div></div></div><div id="38376505" class="c"><input type="checkbox" id="c-38376505" checked=""/><div class="controls bullet"><span class="by">paganel</span><span>|</span><a href="#38370999">parent</a><span>|</span><a href="#38374280">prev</a><span>|</span><a href="#38371175">next</a><span>|</span><label class="collapse" for="c-38376505">[-]</label><label class="expand" for="c-38376505">[1 more]</label></div><br/><div class="children"><div class="content">For what it&#x27;s worth Cybernetics did try to have a second life here in Eastern Europe going into the &#x27;70s and even past that, but the US&#x2F;Silicon Valley pull was too powerful and by the &#x27;90s all of that had been left in the past (the communist governments here falling at the end of the &#x27;80s didn&#x27;t help, of course).<p>I&#x27;m from Bucharest myself, and I live just a couple of blocks away from an institution called the Faculty of Cybernetics, meaning the computer-focused faculty of the local school&#x2F;university of economics.<p>If I&#x27;m not mistaken, and I hope that I&#x27;m not, it had been set up sometime in the early &#x27;70s when many of the technocracy higher-ups in here were really into Cybernetics and into Wiener&#x27;s works (some of which had been translated before Ceausescu fell, so when the communists were still in power). Most, if not all, of those technocrats were not engineers and also not &quot;classical&quot; computer-science people, afaik the majority of them were economists.<p>But, as a I said, when the &#x27;90s came the &quot;classical&quot; computer-science paradigm (and especially the engineering-focused part) took off for good, so that all that &quot;side-quest&quot; about Cybernetics was left in the past (apart from the some entities still being attached to it only by name).<p>The same can be said about the concept of linear programming as applied to economics and to economic forecasting, that is a quite cool concept that had been almost completely forgotten starting with the &#x27;90s but which now is having a small resurgence (I&#x27;ve &quot;re-discovered&quot; it myself by first reading about it in Schumpeter&#x27;s <i>History of Economic Analysis</i> and then by going through a Soviet dictionary of economics published sometime in the &#x27;70s).</div><br/></div></div><div id="38371175" class="c"><input type="checkbox" id="c-38371175" checked=""/><div class="controls bullet"><span class="by">reducesuffering</span><span>|</span><a href="#38370999">parent</a><span>|</span><a href="#38376505">prev</a><span>|</span><a href="#38374138">next</a><span>|</span><label class="collapse" for="c-38371175">[-]</label><label class="expand" for="c-38371175">[1 more]</label></div><br/><div class="children"><div class="content">Yep. If we don&#x27;t get paperclipped then we&#x27;re getting collectively BORG&#x27;ed. Free will? More like a tool by the system that controls the information reality around you.</div><br/></div></div></div></div><div id="38374138" class="c"><input type="checkbox" id="c-38374138" checked=""/><div class="controls bullet"><span class="by">johngossman</span><span>|</span><a href="#38370999">prev</a><span>|</span><a href="#38373994">next</a><span>|</span><label class="collapse" for="c-38374138">[-]</label><label class="expand" for="c-38374138">[3 more]</label></div><br/><div class="children"><div class="content">Another thread of intellectual history: the EA people who tend to speak most loudly about AI safety (two of them are on OpenAI&#x27;s board) owe much to the writings of Peter Singer and Derek Parfit, leading quickly back to GE Moore; the engineers owe a lot to Turing, and the computational linguists to Chomsky. You can quickly go through Turing and Chomsky to GE Moore&#x27;s classmate and friend Bertrand Russell. It&#x27;s like six degrees of Russell and Moore. Or six degrees of Sidgwick and Frege if you want to go back a little further. And so on...</div><br/><div id="38375957" class="c"><input type="checkbox" id="c-38375957" checked=""/><div class="controls bullet"><span class="by">Zolde</span><span>|</span><a href="#38374138">parent</a><span>|</span><a href="#38373994">next</a><span>|</span><label class="collapse" for="c-38375957">[-]</label><label class="expand" for="c-38375957">[2 more]</label></div><br/><div class="children"><div class="content">EA is basically Christian charity for people who live in a city that views Christianity as a dirty thing.<p>It is employed to resolve the cognitive dissonance that highly talented people struggle with, when they realize they could do anything they set their minds to (including making the world a better place), but still want to work as a quant or optimize for ad clicks, because this pays well.<p>Like Goedel stated &quot;most religions are bad, but religion is not&quot;, most people vocally identifying with EA are bad, but EA is not. To judge EA by the character flaws of prominent people like SBF, is like judging Christianity for Jim Jones&#x27;s massacre. EA is, in essence, about effectively allocating charity. Noble and good-hearted.<p>Surely, grifters and frauds would abuse EA to virtue signal or trick venture capitalists into thinking their investment also builds wells in Africa. That should reflect badly on them. Elizabeth Holmes got so far, in part, because venture capitalists were attracted to her due to her being a young female. Merely Goodhart&#x27;s Law in progress, not young female entrepreneurs being bad or without merit.</div><br/><div id="38376468" class="c"><input type="checkbox" id="c-38376468" checked=""/><div class="controls bullet"><span class="by">dale_glass</span><span>|</span><a href="#38374138">root</a><span>|</span><a href="#38375957">parent</a><span>|</span><a href="#38373994">next</a><span>|</span><label class="collapse" for="c-38376468">[-]</label><label class="expand" for="c-38376468">[1 more]</label></div><br/><div class="children"><div class="content">&gt; EA is basically Christian charity for people who live in a city that views Christianity as a dirty thing.<p>I don&#x27;t see it. They&#x27;re pretty much opposite approaches.<p>Christianity is deontological and focused on God. Christianity says that&#x27;s what is important is following the rules, and the rules exist to make God happy, and that outcomes are irrelevant.<p>EA is an utilitarian frame work, and focused on the real world. Utilitarianism says what is important is obtaining utility, and that outcomes are the ultimate measure of goodness.<p>The main difference is that from an utilitarian standpoint, Christian charity only ever works by accident. From its point of view what&#x27;s important is that you do it. The how and why, and what happens as a result is unimportant. So giving huge amounts of money to a megachurch for the pastor&#x27;s Ferrari while the poor starve is perfectly fine, because you&#x27;re not doing it for the poor people, you&#x27;re doing it for God, and you did what was asked of you.</div><br/></div></div></div></div></div></div><div id="38373994" class="c"><input type="checkbox" id="c-38373994" checked=""/><div class="controls bullet"><span class="by">gnarlouse</span><span>|</span><a href="#38374138">prev</a><span>|</span><a href="#38370513">next</a><span>|</span><label class="collapse" for="c-38373994">[-]</label><label class="expand" for="c-38373994">[2 more]</label></div><br/><div class="children"><div class="content">&gt; [Sam] Altman’s dismissal by OpenAI’s board on Friday was the culmination of a power struggle between the company’s two ideological extremes—one group born from Silicon Valley techno optimism… the other steeped in fears that AI represents an existential risk to humanity and must be controlled with extreme caution.<p>Wait, I thought Altman got canned because he was starting businesses behind the board’s back making conflicts of interest.</div><br/><div id="38376469" class="c"><input type="checkbox" id="c-38376469" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#38373994">parent</a><span>|</span><a href="#38370513">next</a><span>|</span><label class="collapse" for="c-38376469">[-]</label><label class="expand" for="c-38376469">[1 more]</label></div><br/><div class="children"><div class="content">The exact reason was (is?) obscured by the board saying nothing publicly beyond &quot;lack of candour&quot;, we&#x27;ve all been trying to guess in the meantime.</div><br/></div></div></div></div><div id="38370513" class="c"><input type="checkbox" id="c-38370513" checked=""/><div class="controls bullet"><span class="by">tgv</span><span>|</span><a href="#38373994">prev</a><span>|</span><a href="#38372591">next</a><span>|</span><label class="collapse" for="c-38370513">[-]</label><label class="expand" for="c-38370513">[10 more]</label></div><br/><div class="children"><div class="content">Mead was famous, but only one of the many voices in very long debate. Whatever people were thinking 90 years ago, it had already lost its influence by the time of AI&#x27;s societal debut in the 1980s and is totally irrelevant to AI&#x27;s impact today. While both may share a mindset, linking Mead to today&#x27;s techno-bros is a bit of a stretch.</div><br/><div id="38370874" class="c"><input type="checkbox" id="c-38370874" checked=""/><div class="controls bullet"><span class="by">sctb</span><span>|</span><a href="#38370513">parent</a><span>|</span><a href="#38372382">next</a><span>|</span><label class="collapse" for="c-38370874">[-]</label><label class="expand" for="c-38370874">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Mead was famous, but only one of the many voices in very long debate.<p>Yes, this is how voices work.<p>&gt; Whatever people were thinking 90 years ago, it had already lost its influence by the time of AI&#x27;s societal debut in the 1980s and is totally irrelevant to AI&#x27;s impact today.<p>Are you making this argument simply based on the passage of time? I can think of a lot of ideas whose longevity makes 90 years seem a sneeze.<p>&gt; While both may share a mindset, linking Mead to today&#x27;s techno-bros is a bit of a stretch.<p>If they share a mindset, would that not be an obvious link? Additionally, this article is drawing a connection not just between Mead and techno-optimists (not the same as tech-bros), but between Mead and both techno-optimism and existential risk. That&#x27;s sort of what the article&#x27;s preamble describes as the interesting thing.</div><br/><div id="38371135" class="c"><input type="checkbox" id="c-38371135" checked=""/><div class="controls bullet"><span class="by">booleandilemma</span><span>|</span><a href="#38370513">root</a><span>|</span><a href="#38370874">parent</a><span>|</span><a href="#38372382">next</a><span>|</span><label class="collapse" for="c-38371135">[-]</label><label class="expand" for="c-38371135">[1 more]</label></div><br/><div class="children"><div class="content">Why are you so intent on linking this woman to modern tech workers?</div><br/></div></div></div></div><div id="38372382" class="c"><input type="checkbox" id="c-38372382" checked=""/><div class="controls bullet"><span class="by">terminous</span><span>|</span><a href="#38370513">parent</a><span>|</span><a href="#38370874">prev</a><span>|</span><a href="#38374733">next</a><span>|</span><label class="collapse" for="c-38372382">[-]</label><label class="expand" for="c-38372382">[5 more]</label></div><br/><div class="children"><div class="content">&gt; Mead was famous, but only one of the many voices in very long debate. Whatever people were thinking 90 years ago, it had already lost its influence by the time of AI&#x27;s societal debut in the 1980s and is totally irrelevant to AI&#x27;s impact today. While both may share a mindset, linking Mead to today&#x27;s techno-bros is a bit of a stretch.<p>Plato was famous, but only one of the many voices in very long debate. Whatever people were thinking 2000+ years ago, it had already lost its influence by the time of AI&#x27;s societal debut in the 1980s and is totally irrelevant to AI&#x27;s impact today. While both may share a mindset, linking Plato to today&#x27;s techno-bros is a bit of a stretch.<p>The allegory of the cave still has resonance today. Abstract ideas are timeless. That&#x27;s the point of abstraction.</div><br/><div id="38374683" class="c"><input type="checkbox" id="c-38374683" checked=""/><div class="controls bullet"><span class="by">tgv</span><span>|</span><a href="#38370513">root</a><span>|</span><a href="#38372382">parent</a><span>|</span><a href="#38374733">next</a><span>|</span><label class="collapse" for="c-38374683">[-]</label><label class="expand" for="c-38374683">[4 more]</label></div><br/><div class="children"><div class="content">But Plato gets taught, and these writings by Mead don&#x27;t. Linking Plato to tech-bros is indeed a stretch.</div><br/><div id="38375160" class="c"><input type="checkbox" id="c-38375160" checked=""/><div class="controls bullet"><span class="by">gotorazor</span><span>|</span><a href="#38370513">root</a><span>|</span><a href="#38374683">parent</a><span>|</span><a href="#38374733">next</a><span>|</span><label class="collapse" for="c-38375160">[-]</label><label class="expand" for="c-38375160">[3 more]</label></div><br/><div class="children"><div class="content">This is kinda how history of ideas work.
People just kind of think they think and know things independently from within themselves or something.<p>Historians who study the origins of idea traces them back and make connections to thoughts and ideas of the past. Often, the inheritors of those ideas knows nothing of how they get them and think themselves clever for coming up with them all by themselves.</div><br/><div id="38376666" class="c"><input type="checkbox" id="c-38376666" checked=""/><div class="controls bullet"><span class="by">tgv</span><span>|</span><a href="#38370513">root</a><span>|</span><a href="#38375160">parent</a><span>|</span><a href="#38376000">next</a><span>|</span><label class="collapse" for="c-38376666">[-]</label><label class="expand" for="c-38376666">[1 more]</label></div><br/><div class="children"><div class="content">True, but that trace here is missing. There is no link apart from &quot;Mead said something vaguely utopian&quot;, and that doesn&#x27;t even seem specific for technology. In 1939, technology was not the most threatening thing.</div><br/></div></div><div id="38376000" class="c"><input type="checkbox" id="c-38376000" checked=""/><div class="controls bullet"><span class="by">nearbuy</span><span>|</span><a href="#38370513">root</a><span>|</span><a href="#38375160">parent</a><span>|</span><a href="#38376666">prev</a><span>|</span><a href="#38374733">next</a><span>|</span><label class="collapse" for="c-38376000">[-]</label><label class="expand" for="c-38376000">[1 more]</label></div><br/><div class="children"><div class="content">This is unfalsifiable speculation though. I could make that claim about anyone (eg, I could say actually it was H. G. Wells planted the seeds of techno-optimism in the present day AI community) and you would have no way to prove me wrong.<p>Remove Margaret Mead from the timeline and the AI camps today would probably be the exact same. Those are basically the two options with anything in life that&#x27;s both useful and dangerous: optimism or pessimism, hope or fear.</div><br/></div></div></div></div></div></div></div></div><div id="38374733" class="c"><input type="checkbox" id="c-38374733" checked=""/><div class="controls bullet"><span class="by">wolverine876</span><span>|</span><a href="#38370513">parent</a><span>|</span><a href="#38372382">prev</a><span>|</span><a href="#38371267">next</a><span>|</span><label class="collapse" for="c-38374733">[-]</label><label class="expand" for="c-38374733">[1 more]</label></div><br/><div class="children"><div class="content">&gt; AI&#x27;s societal debut in the 1980s<p>The debut would seem to be at least 1968, with HAL9000&#x27;s starring role in <i>2001: A Space Odyssey</i>.<p>(If you watch it now, you will see that Arthur C. Clarke and Stanley Kubrick made a film that is right on-target today. Even the most prominent feature of their 1968 fictional AI is its polite, conversational, very human output and input - and some very bad analysis.)</div><br/></div></div><div id="38371267" class="c"><input type="checkbox" id="c-38371267" checked=""/><div class="controls bullet"><span class="by">dmead</span><span>|</span><a href="#38370513">parent</a><span>|</span><a href="#38374733">prev</a><span>|</span><a href="#38372591">next</a><span>|</span><label class="collapse" for="c-38371267">[-]</label><label class="expand" for="c-38371267">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m a tech bro.</div><br/></div></div></div></div><div id="38372591" class="c"><input type="checkbox" id="c-38372591" checked=""/><div class="controls bullet"><span class="by">Sirizarry</span><span>|</span><a href="#38370513">prev</a><span>|</span><a href="#38371773">next</a><span>|</span><label class="collapse" for="c-38372591">[-]</label><label class="expand" for="c-38372591">[1 more]</label></div><br/><div class="children"><div class="content">Very interesting article on a figure I’ve never really read about. Timely too with all the EA drama. I look forward to reading the book</div><br/></div></div><div id="38371773" class="c"><input type="checkbox" id="c-38371773" checked=""/><div class="controls bullet"><span class="by">lhoff</span><span>|</span><a href="#38372591">prev</a><span>|</span><a href="#38371057">next</a><span>|</span><label class="collapse" for="c-38371773">[-]</label><label class="expand" for="c-38371773">[2 more]</label></div><br/><div class="children"><div class="content">I think the best summary of the whole devise that I came across is this one from today<p>&gt; „The OpenAI tussle is between the faction who think Skynet will kill them if they build it, and the faction who think Roko&#x27;s Basilisk(‚s Monster)will torture them if they don&#x27;t build it hard enough.“<p>Source: <a href="https:&#x2F;&#x2F;mastodon.social&#x2F;@jef&#x2F;111443214445962022" rel="nofollow noreferrer">https:&#x2F;&#x2F;mastodon.social&#x2F;@jef&#x2F;111443214445962022</a></div><br/><div id="38374918" class="c"><input type="checkbox" id="c-38374918" checked=""/><div class="controls bullet"><span class="by">concinds</span><span>|</span><a href="#38371773">parent</a><span>|</span><a href="#38371057">next</a><span>|</span><label class="collapse" for="c-38374918">[-]</label><label class="expand" for="c-38374918">[1 more]</label></div><br/><div class="children"><div class="content">Except the people who worry about Roko&#x27;s Basilisk are the same faction as those who believe paperclip maximizers will kill everyone. The &quot;other side&quot; isn&#x27;t part of this semi-cult, and nor do they believe in zero-safety.</div><br/></div></div></div></div><div id="38371057" class="c"><input type="checkbox" id="c-38371057" checked=""/><div class="controls bullet"><span class="by">photochemsyn</span><span>|</span><a href="#38371773">prev</a><span>|</span><a href="#38371400">next</a><span>|</span><label class="collapse" for="c-38371057">[-]</label><label class="expand" for="c-38371057">[6 more]</label></div><br/><div class="children"><div class="content">The article references Hugo Gernsback - and one of the best literary criticisms  of the techno-optimist utopia ideal can be found in William Gibson&#x27;s short story, &quot;The Gernsback Continuum&quot;.<p>As far as the &#x27;ideological divide&#x27; at OpenAI, the fact that they&#x27;re all silent about the military contracting arm of their partner Microsoft as well as potential applications of LLMs to the military arena should be proof enough that their &#x27;do-gooder&#x27; PR operation is nothing more than a branding and marketing game.<p>I suppose you could argue that military dominance of the planet in the name of do-gooder agendas is just what we need, but that&#x27;s always been little more than a justification for robbery of others, ever since the dawn of recorded history.</div><br/><div id="38371341" class="c"><input type="checkbox" id="c-38371341" checked=""/><div class="controls bullet"><span class="by">c54</span><span>|</span><a href="#38371057">parent</a><span>|</span><a href="#38371400">next</a><span>|</span><label class="collapse" for="c-38371341">[-]</label><label class="expand" for="c-38371341">[5 more]</label></div><br/><div class="children"><div class="content">What’re some of the military applications of LLMs?</div><br/><div id="38374775" class="c"><input type="checkbox" id="c-38374775" checked=""/><div class="controls bullet"><span class="by">wolverine876</span><span>|</span><a href="#38371057">root</a><span>|</span><a href="#38371341">parent</a><span>|</span><a href="#38371734">next</a><span>|</span><label class="collapse" for="c-38374775">[-]</label><label class="expand" for="c-38374775">[1 more]</label></div><br/><div class="children"><div class="content">One high priority for the military has been using AIs to analyze massive volumes of data. A common example is analyzing satellite photos for interesting objects.<p>They say the want to output a shortlist to aid human decision-making, but of course they might decide to skip that step.</div><br/></div></div><div id="38371734" class="c"><input type="checkbox" id="c-38371734" checked=""/><div class="controls bullet"><span class="by">onemoresoop</span><span>|</span><a href="#38371057">root</a><span>|</span><a href="#38371341">parent</a><span>|</span><a href="#38374775">prev</a><span>|</span><a href="#38371625">next</a><span>|</span><label class="collapse" for="c-38371734">[-]</label><label class="expand" for="c-38371734">[2 more]</label></div><br/><div class="children"><div class="content">Propaganda - now any language on earth. Coming soon - personalized with the voice of your loved ones, voice application are currently happily harvesting.</div><br/><div id="38376472" class="c"><input type="checkbox" id="c-38376472" checked=""/><div class="controls bullet"><span class="by">kombookcha</span><span>|</span><a href="#38371057">root</a><span>|</span><a href="#38371734">parent</a><span>|</span><a href="#38371625">next</a><span>|</span><label class="collapse" for="c-38376472">[-]</label><label class="expand" for="c-38376472">[1 more]</label></div><br/><div class="children"><div class="content">I strongly feel that this is where the really destructive potential of military LLM applications lies. We&#x27;ve already seen examples of faked images, voice clips and videos being disseminated of prominent political figures. It&#x27;s not difficult to imagine a well planned disinfo attack could paralyse or misdirect the political apparatus and public sentiment of a state during some critical moment in time (IE, during a coup attempt or invasion).<p>Everyone might be able to work out which snippets of media were true and which were not in a few days, but if it happens during a crisis point the loss of time and momentum could be catastrophic.</div><br/></div></div></div></div><div id="38371625" class="c"><input type="checkbox" id="c-38371625" checked=""/><div class="controls bullet"><span class="by">KineticLensman</span><span>|</span><a href="#38371057">root</a><span>|</span><a href="#38371341">parent</a><span>|</span><a href="#38371734">prev</a><span>|</span><a href="#38371400">next</a><span>|</span><label class="collapse" for="c-38371625">[-]</label><label class="expand" for="c-38371625">[1 more]</label></div><br/><div class="children"><div class="content">Influence ops, propaganda, etc</div><br/></div></div></div></div></div></div><div id="38371400" class="c"><input type="checkbox" id="c-38371400" checked=""/><div class="controls bullet"><span class="by">Merrill</span><span>|</span><a href="#38371057">prev</a><span>|</span><label class="collapse" for="c-38371400">[-]</label><label class="expand" for="c-38371400">[2 more]</label></div><br/><div class="children"><div class="content">Technology that may cause existential risk or risk of systemic collapse are one category including nuclear weapons, engineered pathogens, global warming, etc.<p>Robotics disrupting the workforce and devaluing labor are another category continuing the process of mechanization and automation that started with small electrical motors and the electrification of factories.<p>Artificial intelligence is in a third category because it threatens the disruption and impending  devaluation of broad categories of intellectual work.</div><br/><div id="38371886" class="c"><input type="checkbox" id="c-38371886" checked=""/><div class="controls bullet"><span class="by">progne</span><span>|</span><a href="#38371400">parent</a><span>|</span><label class="collapse" for="c-38371886">[-]</label><label class="expand" for="c-38371886">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;re listing sources of systemic collapse, but perhaps the greater danger is the reverse: Ilya Sutskever&#x27;s fear that it has &quot;the potential to create infinitely stable dictatorships.&quot;<p>We flourish in a middle ground between collapse and stability, and a cheap source of intelligence threatens to shift the ground one way or the other.</div><br/></div></div></div></div></div></div></div></div></div></body></html>