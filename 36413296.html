<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1687338073373" as="style"/><link rel="stylesheet" href="styles.css?v=1687338073373"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://twitter.com/swyx/status/1671272883379908608">GPT4 is 8 x 220B params = 1.7T params</a> <span class="domain">(<a href="https://twitter.com">twitter.com</a>)</span></div><div class="subtext"><span>georgehill</span> | <span>96 comments</span></div><br/><div><div id="36414363" class="c"><input type="checkbox" id="c-36414363" checked=""/><div class="controls bullet"><span class="by">andreyk</span><span>|</span><a href="#36413875">next</a><span>|</span><label class="collapse" for="c-36414363">[-]</label><label class="expand" for="c-36414363">[4 more]</label></div><br/><div class="children"><div class="content">weird title, note that the tweet said &quot;so yes, GPT4 is *technically* 10x the size of GPT3, and all the small circle big circle memes from January were actually... in the ballpark?&quot;<p>It&#x27;s really 8 models that are 220B, which is not the same as one model that is 1.7T params. There have been 1T+ models via mixtures of experts for a while now.<p>Note also the follow up tweet: &quot;since MoE is So Hot Right Now, GLaM might be the paper to pay attention to. Google already has a 1.2T model with 64 experts, while Microsoft Bing’s modes are different mixes accordingly&quot;<p>There is also this linked tweet <a href="https:&#x2F;&#x2F;twitter.com&#x2F;LiamFedus&#x2F;status&#x2F;1536791574612303872" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;LiamFedus&#x2F;status&#x2F;1536791574612303872</a> -
&quot;They are all related to Switch-Transformers and MoE. Of the 3 people on Twitter, 2 joined OpenAI. Could be related, could be unrelated&quot;<p>Which links to this tweet:
&quot;Today we&#x27;re releasing all Switch Transformer models in T5X&#x2F;JAX, including the 1.6T param Switch-C and the 395B param Switch-XXL models. Pleased to have these open-sourced!&quot;<p>Anyway... remember not to just read the headlines, they can be misleading.</div><br/><div id="36415290" class="c"><input type="checkbox" id="c-36415290" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#36414363">parent</a><span>|</span><a href="#36415007">next</a><span>|</span><label class="collapse" for="c-36415290">[-]</label><label class="expand" for="c-36415290">[2 more]</label></div><br/><div class="children"><div class="content">(OP here) - yeah i know, but i also know how AI twitter works so I put both the headline and the caveats. i always hope to elevate the level of discourse by raising the relevant facts to those at my level&#x2F;a little bit behind me in terms of understanding. think theres always a fine balance between getting deep&#x2F;technical&#x2F;precise and getting attention and you have to thread the needle in a way that feels authentic to you to do this &quot;job&quot;<p>ultimately my goal is to Learn in Public and demonstrate to experts that spending their time teaching&#x2F;sharing with me is a good use of time because i will augment&#x2F;amplify&#x2F;simplify their message.<p><i>(pls give the full podcast a listen&#x2F;read&#x2F;watch, George went deep on tinygrad&#x2F;tinybox&#x2F;tinycorp and there&#x27;s lots there he IS the authority on, and people are overly fixated on the GPT4 rumor <a href="https:&#x2F;&#x2F;www.latent.space&#x2F;p&#x2F;geohot#details" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.latent.space&#x2F;p&#x2F;geohot#details</a> )</i></div><br/><div id="36415577" class="c"><input type="checkbox" id="c-36415577" checked=""/><div class="controls bullet"><span class="by">primordialsoup</span><span>|</span><a href="#36414363">root</a><span>|</span><a href="#36415290">parent</a><span>|</span><a href="#36415007">next</a><span>|</span><label class="collapse" for="c-36415577">[-]</label><label class="expand" for="c-36415577">[1 more]</label></div><br/><div class="children"><div class="content">Makes it worse, since you have this understanding and still went with this explanation that it&#x27;s 1.7 trillion patients</div><br/></div></div></div></div><div id="36415007" class="c"><input type="checkbox" id="c-36415007" checked=""/><div class="controls bullet"><span class="by">ignoramous</span><span>|</span><a href="#36414363">parent</a><span>|</span><a href="#36415290">prev</a><span>|</span><a href="#36413875">next</a><span>|</span><label class="collapse" for="c-36415007">[-]</label><label class="expand" for="c-36415007">[1 more]</label></div><br/><div class="children"><div class="content"><i>More Efficient In-Context Learning with Generalist Language Model (GLaM)</i> on the Google blog (2021): <a href="https:&#x2F;&#x2F;archive.is&#x2F;cuyW0" rel="nofollow noreferrer">https:&#x2F;&#x2F;archive.is&#x2F;cuyW0</a><p>Btw, <i>MoE</i> is one of the 5 other ways Google thinks LLMs can be more efficient: <a href="https:&#x2F;&#x2F;archive.is&#x2F;2XMvh" rel="nofollow noreferrer">https:&#x2F;&#x2F;archive.is&#x2F;2XMvh</a></div><br/></div></div></div></div><div id="36413875" class="c"><input type="checkbox" id="c-36413875" checked=""/><div class="controls bullet"><span class="by">SheinhardtWigCo</span><span>|</span><a href="#36414363">prev</a><span>|</span><a href="#36416001">next</a><span>|</span><label class="collapse" for="c-36413875">[-]</label><label class="expand" for="c-36413875">[4 more]</label></div><br/><div class="children"><div class="content">GPT-4 is 1.7T params in the same way that an AMD Ryzen 9 7950X is 72 GHz.</div><br/><div id="36414282" class="c"><input type="checkbox" id="c-36414282" checked=""/><div class="controls bullet"><span class="by">eyegor</span><span>|</span><a href="#36413875">parent</a><span>|</span><a href="#36415179">next</a><span>|</span><label class="collapse" for="c-36414282">[-]</label><label class="expand" for="c-36414282">[1 more]</label></div><br/><div class="children"><div class="content">You might be surprised to learn that dell &quot;hpc engineers&quot; (or maybe HPE?) have attempted to sell me hardware using that exact logic to compare servers.</div><br/></div></div><div id="36415179" class="c"><input type="checkbox" id="c-36415179" checked=""/><div class="controls bullet"><span class="by">WiSaGaN</span><span>|</span><a href="#36413875">parent</a><span>|</span><a href="#36414282">prev</a><span>|</span><a href="#36416001">next</a><span>|</span><label class="collapse" for="c-36415179">[-]</label><label class="expand" for="c-36415179">[2 more]</label></div><br/><div class="children"><div class="content">I think frequency is not additive like the parameters. If we are looking for analogy in compute power, then FLOPs is a better analogy to parameters.</div><br/><div id="36415604" class="c"><input type="checkbox" id="c-36415604" checked=""/><div class="controls bullet"><span class="by">Deukhoofd</span><span>|</span><a href="#36413875">root</a><span>|</span><a href="#36415179">parent</a><span>|</span><a href="#36416001">next</a><span>|</span><label class="collapse" for="c-36415604">[-]</label><label class="expand" for="c-36415604">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m fairly certain the point of the gp was that the number of parameters are also not additive.</div><br/></div></div></div></div></div></div><div id="36413813" class="c"><input type="checkbox" id="c-36413813" checked=""/><div class="controls bullet"><span class="by">bluedevilzn</span><span>|</span><a href="#36416001">prev</a><span>|</span><a href="#36414083">next</a><span>|</span><label class="collapse" for="c-36413813">[-]</label><label class="expand" for="c-36413813">[28 more]</label></div><br/><div class="children"><div class="content">I wouldn’t trust anything geohot says. He doesn’t have access to any inside information.</div><br/><div id="36413869" class="c"><input type="checkbox" id="c-36413869" checked=""/><div class="controls bullet"><span class="by">machdiamonds</span><span>|</span><a href="#36413813">parent</a><span>|</span><a href="#36415371">next</a><span>|</span><label class="collapse" for="c-36413869">[-]</label><label class="expand" for="c-36413869">[7 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;twitter.com&#x2F;soumithchintala&#x2F;status&#x2F;1671267150101721090" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;soumithchintala&#x2F;status&#x2F;16712671501017210...</a><p>It looks like at least one other person has also heard the same information.</div><br/><div id="36416068" class="c"><input type="checkbox" id="c-36416068" checked=""/><div class="controls bullet"><span class="by">manojlds</span><span>|</span><a href="#36413813">root</a><span>|</span><a href="#36413869">parent</a><span>|</span><a href="#36415407">next</a><span>|</span><label class="collapse" for="c-36416068">[-]</label><label class="expand" for="c-36416068">[1 more]</label></div><br/><div class="children"><div class="content">And from Bing - <a href="https:&#x2F;&#x2F;twitter.com&#x2F;MParakhin&#x2F;status&#x2F;1670666605427298304" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;MParakhin&#x2F;status&#x2F;1670666605427298304</a></div><br/></div></div><div id="36415407" class="c"><input type="checkbox" id="c-36415407" checked=""/><div class="controls bullet"><span class="by">espadrine</span><span>|</span><a href="#36413813">root</a><span>|</span><a href="#36413869">parent</a><span>|</span><a href="#36416068">prev</a><span>|</span><a href="#36414749">next</a><span>|</span><label class="collapse" for="c-36415407">[-]</label><label class="expand" for="c-36415407">[2 more]</label></div><br/><div class="children"><div class="content">To be fair, this was already a common whisper at the time, so it could be a Chinese whisper effect. Even I thought this on release day: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=35165874">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=35165874</a><p>What is weird is how competitive the open-source models are to the closed ones. For instance, PaLM-2 Bison is below multiple 12B models[0], despite it being plausibly much bigger[1]. The gap with GPT-4 is not that big; the best open-source model on the leaderboard beats it 30% of the time.<p>[0]: <a href="https:&#x2F;&#x2F;chat.lmsys.org&#x2F;?leaderboard" rel="nofollow noreferrer">https:&#x2F;&#x2F;chat.lmsys.org&#x2F;?leaderboard</a><p>[1]: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=35893357">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=35893357</a></div><br/><div id="36415855" class="c"><input type="checkbox" id="c-36415855" checked=""/><div class="controls bullet"><span class="by">machdiamonds</span><span>|</span><a href="#36413813">root</a><span>|</span><a href="#36415407">parent</a><span>|</span><a href="#36414749">next</a><span>|</span><label class="collapse" for="c-36415855">[-]</label><label class="expand" for="c-36415855">[1 more]</label></div><br/><div class="children"><div class="content">From my perspective, there&#x27;s a vast divide between open source models and GPT4 at present. The lmsys leaderboard rankings are derived from users independently engaging with the LLMs and opting for the answers they find most appealing. Consequently, the rankings are influenced not only by the type of questions users ask but also by their preference for succinctness in responses. When we venture into the realm of more complex tasks, such as code generation, GPT4 unequivocally outshines all open source models.<p>That said, the advancements in models like Orca and the &quot;Textbooks are all you need&quot; paper are noteworthy (<a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2306.02707.pdf" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2306.02707.pdf</a>, <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2306.11644" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2306.11644</a>). I&#x27;m optimistic about what future smaller models could achieve.</div><br/></div></div></div></div><div id="36414749" class="c"><input type="checkbox" id="c-36414749" checked=""/><div class="controls bullet"><span class="by">startupsfail</span><span>|</span><a href="#36413813">root</a><span>|</span><a href="#36413869">parent</a><span>|</span><a href="#36415407">prev</a><span>|</span><a href="#36414721">next</a><span>|</span><label class="collapse" for="c-36414749">[-]</label><label class="expand" for="c-36414749">[2 more]</label></div><br/><div class="children"><div class="content">It’s funny that this post is trending on HN right next to the post about a paper showing how to build a model 1000x smaller than 1.7T that can code better than LLMs 10x larger.</div><br/><div id="36416006" class="c"><input type="checkbox" id="c-36416006" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#36413813">root</a><span>|</span><a href="#36414749">parent</a><span>|</span><a href="#36414721">next</a><span>|</span><label class="collapse" for="c-36416006">[-]</label><label class="expand" for="c-36416006">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t find it funny, I find it scary and mind-blowing: the impact of these headlines is <i>additive</i> - this one confirms the effectiveness of combining models, and the other one suggests you could cut the model size a couple orders of magnitude if you train on clean enough data. Together, this points at a way to achieve both GPT-4 that fits on your phone, and a much more powerful model that&#x27;s not larger than GPT-4 is now.</div><br/></div></div></div></div><div id="36414721" class="c"><input type="checkbox" id="c-36414721" checked=""/><div class="controls bullet"><span class="by">throwaway9274</span><span>|</span><a href="#36413813">root</a><span>|</span><a href="#36413869">parent</a><span>|</span><a href="#36414749">prev</a><span>|</span><a href="#36415371">next</a><span>|</span><label class="collapse" for="c-36414721">[-]</label><label class="expand" for="c-36414721">[1 more]</label></div><br/><div class="children"><div class="content">2x0=0</div><br/></div></div></div></div><div id="36415371" class="c"><input type="checkbox" id="c-36415371" checked=""/><div class="controls bullet"><span class="by">mach1ne</span><span>|</span><a href="#36413813">parent</a><span>|</span><a href="#36413869">prev</a><span>|</span><a href="#36415046">next</a><span>|</span><label class="collapse" for="c-36415371">[-]</label><label class="expand" for="c-36415371">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s luckily not relevant here. Multiple sources have independently confirmed the same rumors. This means that there is a significant probability of it being true.</div><br/></div></div><div id="36415046" class="c"><input type="checkbox" id="c-36415046" checked=""/><div class="controls bullet"><span class="by">simondotau</span><span>|</span><a href="#36413813">parent</a><span>|</span><a href="#36415371">prev</a><span>|</span><a href="#36413865">next</a><span>|</span><label class="collapse" for="c-36415046">[-]</label><label class="expand" for="c-36415046">[4 more]</label></div><br/><div class="children"><div class="content">It’s fine to say you don’t believe him, it’s fine to say he’s wrong, but if you want to claim he doesn’t have inside information, I would expect a standard of evidence as good as that you would expect for Geohot’s claim.<p>So tell me: how do you know the Geohot doesn’t have inside information?</div><br/><div id="36415281" class="c"><input type="checkbox" id="c-36415281" checked=""/><div class="controls bullet"><span class="by">rat9988</span><span>|</span><a href="#36413813">root</a><span>|</span><a href="#36415046">parent</a><span>|</span><a href="#36416076">next</a><span>|</span><label class="collapse" for="c-36415281">[-]</label><label class="expand" for="c-36415281">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s up to Geohot to prove his claim. 
Althoug he may have insider information, he isn&#x27;t in a position known to have inside information. It might be more correct to phrase it that way but we all got the meaning.</div><br/><div id="36415737" class="c"><input type="checkbox" id="c-36415737" checked=""/><div class="controls bullet"><span class="by">lohnjemon</span><span>|</span><a href="#36413813">root</a><span>|</span><a href="#36415281">parent</a><span>|</span><a href="#36416076">next</a><span>|</span><label class="collapse" for="c-36415737">[-]</label><label class="expand" for="c-36415737">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s not how it works out in practice. For example, journalists who have insider info from sources and leak it on the regular don&#x27;t do anything to prove they have insider information, they build up reputation based on how many predictions they make.<p>There&#x27;s no point in outing your sources, that&#x27;s how you lose them.</div><br/></div></div></div></div><div id="36416076" class="c"><input type="checkbox" id="c-36416076" checked=""/><div class="controls bullet"><span class="by">manojlds</span><span>|</span><a href="#36413813">root</a><span>|</span><a href="#36415046">parent</a><span>|</span><a href="#36415281">prev</a><span>|</span><a href="#36413865">next</a><span>|</span><label class="collapse" for="c-36416076">[-]</label><label class="expand" for="c-36416076">[1 more]</label></div><br/><div class="children"><div class="content">Prove a negative you mean?</div><br/></div></div></div></div><div id="36413865" class="c"><input type="checkbox" id="c-36413865" checked=""/><div class="controls bullet"><span class="by">valianteffort</span><span>|</span><a href="#36413813">parent</a><span>|</span><a href="#36415046">prev</a><span>|</span><a href="#36414083">next</a><span>|</span><label class="collapse" for="c-36413865">[-]</label><label class="expand" for="c-36413865">[15 more]</label></div><br/><div class="children"><div class="content">He doesn&#x27;t strike me as the type of person to lie (except when trolling). His reputation is solid enough that I&#x27;m sure he&#x27;s had discussions with people in the space.</div><br/><div id="36414150" class="c"><input type="checkbox" id="c-36414150" checked=""/><div class="controls bullet"><span class="by">lannisterstark</span><span>|</span><a href="#36413813">root</a><span>|</span><a href="#36413865">parent</a><span>|</span><a href="#36414281">next</a><span>|</span><label class="collapse" for="c-36414150">[-]</label><label class="expand" for="c-36414150">[3 more]</label></div><br/><div class="children"><div class="content">&gt;his reputation is solid<p>Eh, is it? Not sure if I consider him an authority on anything anymore.<p><a href="https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;ProgrammerHumor&#x2F;comments&#x2F;z2y8i0&#x2F;from_this_this_is_my_mission_an_i_will_accomplish&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;ProgrammerHumor&#x2F;comments&#x2F;z2y8i0&#x2F;fro...</a><p>&gt;This is the interview. Build this feature. You don&#x27;t get source access. Link the GitHub and license it MIT.<p>is akin to &quot;Build this for free, license it MIT so I can use it without any issues, and oh, btw, I dont have authority to hire you, teehee.&quot;</div><br/><div id="36414289" class="c"><input type="checkbox" id="c-36414289" checked=""/><div class="controls bullet"><span class="by">jimmySixDOF</span><span>|</span><a href="#36413813">root</a><span>|</span><a href="#36414150">parent</a><span>|</span><a href="#36414281">next</a><span>|</span><label class="collapse" for="c-36414289">[-]</label><label class="expand" for="c-36414289">[2 more]</label></div><br/><div class="children"><div class="content">Well he picked the right problem at the time which was (and still is!) search.  I was really looking forward to some progress on this and then he deleted tweets and dropped off the system.  I would love to see a podcast of him talking about that &amp; fyi @realGeorgeHotz is back on it now to promote Tiny grad&#x2F;box&#x2F;corp.</div><br/><div id="36415217" class="c"><input type="checkbox" id="c-36415217" checked=""/><div class="controls bullet"><span class="by">threeseed</span><span>|</span><a href="#36413813">root</a><span>|</span><a href="#36414289">parent</a><span>|</span><a href="#36414281">next</a><span>|</span><label class="collapse" for="c-36415217">[-]</label><label class="expand" for="c-36415217">[1 more]</label></div><br/><div class="children"><div class="content">As someone who has spent 20+ years working in large companies you can spot developers like him a mile away i.e. the sort of behaviour you see with skilled but arrogant grads&#x2F;interns.<p>The right approach when you&#x27;re new is to quietly pick a simple problem away from the core services where you can learn the processes and polices needed to get something into Production. More so when you&#x27;re in a company that is undergoing a brain drain.<p>Then you can progressively move to solving more demanding and critical issues.</div><br/></div></div></div></div></div></div><div id="36414281" class="c"><input type="checkbox" id="c-36414281" checked=""/><div class="controls bullet"><span class="by">ec109685</span><span>|</span><a href="#36413813">root</a><span>|</span><a href="#36413865">parent</a><span>|</span><a href="#36414150">prev</a><span>|</span><a href="#36413878">next</a><span>|</span><label class="collapse" for="c-36414281">[-]</label><label class="expand" for="c-36414281">[8 more]</label></div><br/><div class="children"><div class="content">This wasn’t very impressive: <a href="https:&#x2F;&#x2F;www.pcmag.com&#x2F;news&#x2F;hacker-george-hotz-resigns-from-twitter-4-weeks-into-his-internship" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.pcmag.com&#x2F;news&#x2F;hacker-george-hotz-resigns-from-t...</a><p>Spent two weeks trying to find someone to build a faceted search UI and then quit.</div><br/><div id="36414488" class="c"><input type="checkbox" id="c-36414488" checked=""/><div class="controls bullet"><span class="by">nl</span><span>|</span><a href="#36413813">root</a><span>|</span><a href="#36414281">parent</a><span>|</span><a href="#36414561">next</a><span>|</span><label class="collapse" for="c-36414488">[-]</label><label class="expand" for="c-36414488">[5 more]</label></div><br/><div class="children"><div class="content">I think deciding to get away from the Musk&#x2F;Twitter debacle as soon as you realize how bad it is isn&#x27;t necessarily a bad thing..</div><br/><div id="36414670" class="c"><input type="checkbox" id="c-36414670" checked=""/><div class="controls bullet"><span class="by">bboygravity</span><span>|</span><a href="#36413813">root</a><span>|</span><a href="#36414488">parent</a><span>|</span><a href="#36414561">next</a><span>|</span><label class="collapse" for="c-36414670">[-]</label><label class="expand" for="c-36414670">[4 more]</label></div><br/><div class="children"><div class="content">How is it a debacle and how is it bad?</div><br/><div id="36415321" class="c"><input type="checkbox" id="c-36415321" checked=""/><div class="controls bullet"><span class="by">threeseed</span><span>|</span><a href="#36413813">root</a><span>|</span><a href="#36414670">parent</a><span>|</span><a href="#36415066">next</a><span>|</span><label class="collapse" for="c-36415321">[-]</label><label class="expand" for="c-36415321">[2 more]</label></div><br/><div class="children"><div class="content">Because Twitter is trending towards bankruptcy.<p>a) It is valued at about a 1&#x2F;4 of what it was purchased at.<p>b) Twitter Blue has generated an irrelevant amount of revenue and churn is increasing [1].<p>c) Roadmap looks poor. Video is a terrible direction where only Google, Amazon, TikTok etc have been able to make the numbers work and that&#x27;s because it is subsidised through other revenue sources. Payments is DOA given Twitter&#x27;s inability to comply with existing regulations let alone how difficult KYC&#x2F;AML is to manage.<p>d) Regulatory and legal risk increases by the day. Lawsuits continue to pile up and EU&#x2F;FTC are hovering around as Twitter is not in compliance with previous agreements.<p>e) Brand safety continues to be a huge challenge that isn&#x27;t solvable without effectively going back to what Twitter was previously.<p>f) BlueSky and Instagram are both releasing competitor apps to the broader public in the coming months. The market simply won&#x27;t sustain this many text-based social media apps.<p>[1] <a href="https:&#x2F;&#x2F;github.com&#x2F;travisbrown&#x2F;blue">https:&#x2F;&#x2F;github.com&#x2F;travisbrown&#x2F;blue</a></div><br/><div id="36415668" class="c"><input type="checkbox" id="c-36415668" checked=""/><div class="controls bullet"><span class="by">simondotau</span><span>|</span><a href="#36413813">root</a><span>|</span><a href="#36415321">parent</a><span>|</span><a href="#36415066">next</a><span>|</span><label class="collapse" for="c-36415668">[-]</label><label class="expand" for="c-36415668">[1 more]</label></div><br/><div class="children"><div class="content">a) Meta had similar swings of over 3x between a 2021 high and a 2022 low. We can only guess what Twitter would be worth today if the stock was floated, but it isn’t. Substituting market valuations with our personal beliefs isn’t interesting.<p>b) Every social media company has a well populated graveyard of failed experiments behind them.<p>c) Opinion.<p>d) Business as usual for every social media company since the dawn of time.<p>e) Opinion. And advertiser behaviour suggests otherwise.<p>f) History is littered with new entrants which fail to unseat the incumbent. It does happen, but it’s statistically rare.</div><br/></div></div></div></div></div></div></div></div><div id="36414561" class="c"><input type="checkbox" id="c-36414561" checked=""/><div class="controls bullet"><span class="by">valianteffort</span><span>|</span><a href="#36413813">root</a><span>|</span><a href="#36414281">parent</a><span>|</span><a href="#36414488">prev</a><span>|</span><a href="#36413878">next</a><span>|</span><label class="collapse" for="c-36414561">[-]</label><label class="expand" for="c-36414561">[2 more]</label></div><br/><div class="children"><div class="content">His biggest issue was trying to convince the remaining engineers and Elon that a refactor was more promising than continuing to build on the layers of spaghetti code that runs twitter.<p>I don&#x27;t disagree with him, it&#x27;s just clear that he didn&#x27;t understand how dire the financial situation was and that even a progressive refactor starting with the most basic features would take considerable engineering hours and money.</div><br/><div id="36415239" class="c"><input type="checkbox" id="c-36415239" checked=""/><div class="controls bullet"><span class="by">hedora</span><span>|</span><a href="#36413813">root</a><span>|</span><a href="#36414561">parent</a><span>|</span><a href="#36413878">next</a><span>|</span><label class="collapse" for="c-36415239">[-]</label><label class="expand" for="c-36415239">[1 more]</label></div><br/><div class="children"><div class="content">As the saying goes, if you don’t have time to do it right, you’d better have time to do it twice.</div><br/></div></div></div></div></div></div><div id="36413878" class="c"><input type="checkbox" id="c-36413878" checked=""/><div class="controls bullet"><span class="by">zoklet-enjoyer</span><span>|</span><a href="#36413813">root</a><span>|</span><a href="#36413865">parent</a><span>|</span><a href="#36414281">prev</a><span>|</span><a href="#36414083">next</a><span>|</span><label class="collapse" for="c-36413878">[-]</label><label class="expand" for="c-36413878">[3 more]</label></div><br/><div class="children"><div class="content">He&#x27;s a crypto scammer. Look up cheap eth</div><br/><div id="36413918" class="c"><input type="checkbox" id="c-36413918" checked=""/><div class="controls bullet"><span class="by">valianteffort</span><span>|</span><a href="#36413813">root</a><span>|</span><a href="#36413878">parent</a><span>|</span><a href="#36414083">next</a><span>|</span><label class="collapse" for="c-36413918">[-]</label><label class="expand" for="c-36413918">[2 more]</label></div><br/><div class="children"><div class="content">I mean that was marketed as a memecoin from the beginning. More so than doge even.</div><br/><div id="36414888" class="c"><input type="checkbox" id="c-36414888" checked=""/><div class="controls bullet"><span class="by">pixelpoet</span><span>|</span><a href="#36413813">root</a><span>|</span><a href="#36413918">parent</a><span>|</span><a href="#36414083">next</a><span>|</span><label class="collapse" for="c-36414888">[-]</label><label class="expand" for="c-36414888">[1 more]</label></div><br/><div class="children"><div class="content">He added some code to give himself tons of it and didn&#x27;t report it to anyone, dismissed it as a joke or something when it was found and then disappeared after hyping the project. Sound familiar?<p>To me he joins the ranks of the most basic shady crypto types.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="36414083" class="c"><input type="checkbox" id="c-36414083" checked=""/><div class="controls bullet"><span class="by">eightysixfour</span><span>|</span><a href="#36413813">prev</a><span>|</span><a href="#36414474">next</a><span>|</span><label class="collapse" for="c-36414083">[-]</label><label class="expand" for="c-36414083">[2 more]</label></div><br/><div class="children"><div class="content">I find it interesting that geohot says it is what you do “when you are out of ideas,” I can’t help but think that having multiple blended models is what makes GPT-4 seem like it has more “emergent” behavior than earlier models.</div><br/><div id="36414139" class="c"><input type="checkbox" id="c-36414139" checked=""/><div class="controls bullet"><span class="by">jerpint</span><span>|</span><a href="#36414083">parent</a><span>|</span><a href="#36414474">next</a><span>|</span><label class="collapse" for="c-36414139">[-]</label><label class="expand" for="c-36414139">[1 more]</label></div><br/><div class="children"><div class="content">OpenAI has always stuck to “simpler” approaches that scale. It’s the best bet to make and it’s paid off time and time again for them. I don’t think it’s so much “they’re out of ideas”, it’s just an idea that scales well</div><br/></div></div></div></div><div id="36414474" class="c"><input type="checkbox" id="c-36414474" checked=""/><div class="controls bullet"><span class="by">andy_xor_andrew</span><span>|</span><a href="#36414083">prev</a><span>|</span><a href="#36414712">next</a><span>|</span><label class="collapse" for="c-36414474">[-]</label><label class="expand" for="c-36414474">[4 more]</label></div><br/><div class="children"><div class="content">Are the models specifically trained to be experts in certain domains?<p>Or the models are all trained on the same corpus, but just queried with different parameters?<p>Is this functionally the same as beam search?<p>Do they select the best output on a token-by-token basis, or do they let each model stream to completion and then pick the best final output?</div><br/><div id="36414745" class="c"><input type="checkbox" id="c-36414745" checked=""/><div class="controls bullet"><span class="by">radq</span><span>|</span><a href="#36414474">parent</a><span>|</span><a href="#36414679">next</a><span>|</span><label class="collapse" for="c-36414745">[-]</label><label class="expand" for="c-36414745">[1 more]</label></div><br/><div class="children"><div class="content">If it&#x27;s similar to the switch transformer architecture [1], which I suspect it is, then the models are all trained on the same corpus and the routing model learns automatically which experts to route to.<p>It&#x27;s orthogonal to beam search - the benefit of the architecture is that it allows sparse inference.<p>[1] <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2101.03961.pdf" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2101.03961.pdf</a></div><br/></div></div><div id="36414679" class="c"><input type="checkbox" id="c-36414679" checked=""/><div class="controls bullet"><span class="by">pizza</span><span>|</span><a href="#36414474">parent</a><span>|</span><a href="#36414745">prev</a><span>|</span><a href="#36414712">next</a><span>|</span><label class="collapse" for="c-36414679">[-]</label><label class="expand" for="c-36414679">[2 more]</label></div><br/><div class="children"><div class="content">Democracy of descendant models that have been trained separately by partitioning the identified clusters with strong capabilities from an ancestor model, so, in effect, they are modular, and can be learned to be combined competitively.</div><br/><div id="36415163" class="c"><input type="checkbox" id="c-36415163" checked=""/><div class="controls bullet"><span class="by">deely3</span><span>|</span><a href="#36414474">root</a><span>|</span><a href="#36414679">parent</a><span>|</span><a href="#36414712">next</a><span>|</span><label class="collapse" for="c-36415163">[-]</label><label class="expand" for="c-36415163">[1 more]</label></div><br/><div class="children"><div class="content">Heh. I understand all these words separately. Btw, to which of the question of parent comment this is an answer?</div><br/></div></div></div></div></div></div><div id="36414712" class="c"><input type="checkbox" id="c-36414712" checked=""/><div class="controls bullet"><span class="by">esperent</span><span>|</span><a href="#36414474">prev</a><span>|</span><a href="#36415433">next</a><span>|</span><label class="collapse" for="c-36414712">[-]</label><label class="expand" for="c-36414712">[3 more]</label></div><br/><div class="children"><div class="content">So <i>if</i> this is true - which is a big if since this looks like speculation rather than real information - could this work with even smaller models?<p>For example, what about 20 x 65B = 1.3T params? Or 100 x 13B = 1.3T params?<p>Hell, what about 5000 x 13B params? Thousands of small highly specialized models, with maybe one small &quot;categorization&quot; model as the first pass?</div><br/><div id="36414818" class="c"><input type="checkbox" id="c-36414818" checked=""/><div class="controls bullet"><span class="by">janalsncm</span><span>|</span><a href="#36414712">parent</a><span>|</span><a href="#36415031">next</a><span>|</span><label class="collapse" for="c-36414818">[-]</label><label class="expand" for="c-36414818">[1 more]</label></div><br/><div class="children"><div class="content">Well at the end of the day you’ll also need a model for ranking the candidates, which becomes harder as the number of candidates grows. And the mean quality of any one candidate response will drop as the model size decreases, as will the max quality.</div><br/></div></div><div id="36415031" class="c"><input type="checkbox" id="c-36415031" checked=""/><div class="controls bullet"><span class="by">cypress66</span><span>|</span><a href="#36414712">parent</a><span>|</span><a href="#36414818">prev</a><span>|</span><a href="#36415433">next</a><span>|</span><label class="collapse" for="c-36415031">[-]</label><label class="expand" for="c-36415031">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2112.06905" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2112.06905</a></div><br/></div></div></div></div><div id="36415433" class="c"><input type="checkbox" id="c-36415433" checked=""/><div class="controls bullet"><span class="by">LarsDu88</span><span>|</span><a href="#36414712">prev</a><span>|</span><a href="#36414118">next</a><span>|</span><label class="collapse" for="c-36415433">[-]</label><label class="expand" for="c-36415433">[2 more]</label></div><br/><div class="children"><div class="content">That&#x27;s on the order of 25 4090 GPUs to run inference. Not a crazy number by any means. We will see consumer robots running that by the end of the decade, mark my words.</div><br/><div id="36415848" class="c"><input type="checkbox" id="c-36415848" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#36415433">parent</a><span>|</span><a href="#36414118">next</a><span>|</span><label class="collapse" for="c-36415848">[-]</label><label class="expand" for="c-36415848">[1 more]</label></div><br/><div class="children"><div class="content">i believe that&#x27;s George&#x27;s goal with tinybox</div><br/></div></div></div></div><div id="36414118" class="c"><input type="checkbox" id="c-36414118" checked=""/><div class="controls bullet"><span class="by">it_citizen</span><span>|</span><a href="#36415433">prev</a><span>|</span><a href="#36415940">next</a><span>|</span><label class="collapse" for="c-36414118">[-]</label><label class="expand" for="c-36414118">[9 more]</label></div><br/><div class="children"><div class="content">« We can’t really make models bigger than 220B parameters »<p>Can someone explains why?</div><br/><div id="36414246" class="c"><input type="checkbox" id="c-36414246" checked=""/><div class="controls bullet"><span class="by">slimesli</span><span>|</span><a href="#36414118">parent</a><span>|</span><a href="#36414166">next</a><span>|</span><label class="collapse" for="c-36414246">[-]</label><label class="expand" for="c-36414246">[1 more]</label></div><br/><div class="children"><div class="content">Because of memory bandwidth.
H100 has 3350gB&#x2F;s of bandwidth, more gpus will give you more memory but not bandwidth.
If you load 175b parameters in 8bit then you can get theoretically 
3350&#x2F;175=19 tokens&#x2F;second.
In MoE you need to process only one expert at a time so sparse 8x220b model would be only slightly slower than dense 220b model.</div><br/></div></div><div id="36414166" class="c"><input type="checkbox" id="c-36414166" checked=""/><div class="controls bullet"><span class="by">sp332</span><span>|</span><a href="#36414118">parent</a><span>|</span><a href="#36414246">prev</a><span>|</span><a href="#36415940">next</a><span>|</span><label class="collapse" for="c-36414166">[-]</label><label class="expand" for="c-36414166">[7 more]</label></div><br/><div class="children"><div class="content">It doesn&#x27;t fit in VRAM.</div><br/><div id="36414211" class="c"><input type="checkbox" id="c-36414211" checked=""/><div class="controls bullet"><span class="by">hesdeadjim</span><span>|</span><a href="#36414118">root</a><span>|</span><a href="#36414166">parent</a><span>|</span><a href="#36415940">next</a><span>|</span><label class="collapse" for="c-36414211">[-]</label><label class="expand" for="c-36414211">[6 more]</label></div><br/><div class="children"><div class="content">I’ve been a bit surprised that Nvidia hasn’t gone to extreme lengths to fit 1tb of memory on a card just for this reason.</div><br/><div id="36414369" class="c"><input type="checkbox" id="c-36414369" checked=""/><div class="controls bullet"><span class="by">Chamix</span><span>|</span><a href="#36414118">root</a><span>|</span><a href="#36414211">parent</a><span>|</span><a href="#36414254">next</a><span>|</span><label class="collapse" for="c-36414369">[-]</label><label class="expand" for="c-36414369">[1 more]</label></div><br/><div class="children"><div class="content">The issue, as pointed above, is primarily bandwidth (at inference), not addressable memory. Put simply, the best bandwidth stack we currently have is on-package HBM -&gt; NVLink, -&gt; Mellanox InfiniBand, and for inference speed you really can&#x27;t leave the NVLink bandwidth (read, 8x DGX pod) for &gt;100b parameters. And stacking HBM dies is much harder (read, expensive) than GDDR dies which is harder than DDR etc.<p>Cost aside, HMB dies themselves aren&#x27;t getting significantly denser anytime soon, and there just simply isn&#x27;t enough package space with current manufacturing methods to pack a significantly increased number of dies on the gpu.<p>So I suspect the major hardware jumps will continue to be with NVLink&#x2F;NVSwitch. Nvlink 4 + NVSwitch 3 actually already allows for up 256x GPUs <a href="https:&#x2F;&#x2F;resources.nvidia.com&#x2F;en-us-grace-cpu&#x2F;nvidia-grace-hopper" rel="nofollow noreferrer">https:&#x2F;&#x2F;resources.nvidia.com&#x2F;en-us-grace-cpu&#x2F;nvidia-grace-ho...</a> ; increased numbers of links will let ever increasing numbers of GPUs pool with sufficient bandwidth for inference on larger models.<p>As already mentioned, see this HN post about the GH200 <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36133226">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36133226</a>, which has some further discussion about the cutting edge of bandwidth for  Nvidia DGX and Google TPU pods.</div><br/></div></div><div id="36414254" class="c"><input type="checkbox" id="c-36414254" checked=""/><div class="controls bullet"><span class="by">andrewstuart2</span><span>|</span><a href="#36414118">root</a><span>|</span><a href="#36414211">parent</a><span>|</span><a href="#36414369">prev</a><span>|</span><a href="#36415940">next</a><span>|</span><label class="collapse" for="c-36414254">[-]</label><label class="expand" for="c-36414254">[4 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;nvidianews.nvidia.com&#x2F;news&#x2F;nvidia-announces-dgx-gh200-ai-supercomputer" rel="nofollow noreferrer">https:&#x2F;&#x2F;nvidianews.nvidia.com&#x2F;news&#x2F;nvidia-announces-dgx-gh20...</a><p>I think they _are_ going pretty extreme now.</div><br/><div id="36414587" class="c"><input type="checkbox" id="c-36414587" checked=""/><div class="controls bullet"><span class="by">samplatt</span><span>|</span><a href="#36414118">root</a><span>|</span><a href="#36414254">parent</a><span>|</span><a href="#36415940">next</a><span>|</span><label class="collapse" for="c-36414587">[-]</label><label class="expand" for="c-36414587">[3 more]</label></div><br/><div class="children"><div class="content">Offtopic, but as a VR gamer that article just made me very sad. I was really hoping to see NVidia produce some decent cards in the near future, but looks like their main revenue is really going to be gargantuan number-crunchers. They&#x27;ll likely only keep increasing the VRAM of gaming cards by arbitrarily-small numbers once every few years :-(</div><br/><div id="36415338" class="c"><input type="checkbox" id="c-36415338" checked=""/><div class="controls bullet"><span class="by">speedgoose</span><span>|</span><a href="#36414118">root</a><span>|</span><a href="#36414587">parent</a><span>|</span><a href="#36414687">prev</a><span>|</span><a href="#36415940">next</a><span>|</span><label class="collapse" for="c-36415338">[-]</label><label class="expand" for="c-36415338">[1 more]</label></div><br/><div class="children"><div class="content">Yes, the future of VR gaming looks closer to the Sony Playstation or even the Apple Vision than NVIDIA&#x27;s products.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="36415940" class="c"><input type="checkbox" id="c-36415940" checked=""/><div class="controls bullet"><span class="by">reportgunner</span><span>|</span><a href="#36414118">prev</a><span>|</span><a href="#36414956">next</a><span>|</span><label class="collapse" for="c-36415940">[-]</label><label class="expand" for="c-36415940">[2 more]</label></div><br/><div class="children"><div class="content">Sad that there is a grammar error lining the top of the video.</div><br/><div id="36415979" class="c"><input type="checkbox" id="c-36415979" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#36415940">parent</a><span>|</span><a href="#36414956">next</a><span>|</span><label class="collapse" for="c-36415979">[-]</label><label class="expand" for="c-36415979">[1 more]</label></div><br/><div class="children"><div class="content">literally unwatchable</div><br/></div></div></div></div><div id="36414956" class="c"><input type="checkbox" id="c-36414956" checked=""/><div class="controls bullet"><span class="by">janalsncm</span><span>|</span><a href="#36415940">prev</a><span>|</span><a href="#36414555">next</a><span>|</span><label class="collapse" for="c-36414956">[-]</label><label class="expand" for="c-36414956">[2 more]</label></div><br/><div class="children"><div class="content">At a minimum he glossed over the multimodal capabilities of GPT-4. If they use the same set of tokens, it’s unclear how this doesn’t pollute text training data. If they use separate tokens, the model size should be bigger.</div><br/><div id="36415123" class="c"><input type="checkbox" id="c-36415123" checked=""/><div class="controls bullet"><span class="by">ShamelessC</span><span>|</span><a href="#36414956">parent</a><span>|</span><a href="#36414555">next</a><span>|</span><label class="collapse" for="c-36415123">[-]</label><label class="expand" for="c-36415123">[1 more]</label></div><br/><div class="children"><div class="content">I assume they just intersperse and&#x2F;or use a special &lt;IMAGE&gt; token to prime the models appropriately. This has been done before by others training on e.g. HTML with &lt;img&gt; tags replaced with image tokens from a vision model.</div><br/></div></div></div></div><div id="36414555" class="c"><input type="checkbox" id="c-36414555" checked=""/><div class="controls bullet"><span class="by">lyu07282</span><span>|</span><a href="#36414956">prev</a><span>|</span><a href="#36414078">next</a><span>|</span><label class="collapse" for="c-36414555">[-]</label><label class="expand" for="c-36414555">[2 more]</label></div><br/><div class="children"><div class="content">full podcast here: <a href="https:&#x2F;&#x2F;www.latent.space&#x2F;p&#x2F;geohot" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.latent.space&#x2F;p&#x2F;geohot</a></div><br/><div id="36414691" class="c"><input type="checkbox" id="c-36414691" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#36414555">parent</a><span>|</span><a href="#36414078">next</a><span>|</span><label class="collapse" for="c-36414691">[-]</label><label class="expand" for="c-36414691">[1 more]</label></div><br/><div class="children"><div class="content">thanks :) posted it on HN but got no traction, definitely underperformed my expectations. my only explanation is i think i screwed up the title :&#x2F;<p>i somewhat knew that people were going to obsess over the gpt4 tidbit, but hey ultimately George is just relaying secondhand info, and I wish more people focused on the tinycorp&#x2F;tinybox&#x2F;tinygrad story. I&#x27;m going to try again tomorrow to tell the story better.</div><br/></div></div></div></div><div id="36414078" class="c"><input type="checkbox" id="c-36414078" checked=""/><div class="controls bullet"><span class="by">MuffinFlavored</span><span>|</span><a href="#36414555">prev</a><span>|</span><a href="#36415849">next</a><span>|</span><label class="collapse" for="c-36414078">[-]</label><label class="expand" for="c-36414078">[5 more]</label></div><br/><div class="children"><div class="content">&gt; GPT-4: 8 x 220B experts trained with different data&#x2F;task distributions and 16-iter inference.<p>There was a post on HackerNews the other day about a 13B open source model.<p>Any 220B open source models? Why or why not?<p>I wonder what the 8 categories were. I wonder what goes into identifying tokens and then trying to guess which category&#x2F;model you should look up. What if tokens go between two models, how do the models route between each other?</div><br/><div id="36414105" class="c"><input type="checkbox" id="c-36414105" checked=""/><div class="controls bullet"><span class="by">jerpint</span><span>|</span><a href="#36414078">parent</a><span>|</span><a href="#36414560">next</a><span>|</span><label class="collapse" for="c-36414105">[-]</label><label class="expand" for="c-36414105">[3 more]</label></div><br/><div class="children"><div class="content">I think it’s just an ensemble of models, so you do some kind of pooling&#x2F;majority vote on your output tokens</div><br/><div id="36414173" class="c"><input type="checkbox" id="c-36414173" checked=""/><div class="controls bullet"><span class="by">heliophobicdude</span><span>|</span><a href="#36414078">root</a><span>|</span><a href="#36414105">parent</a><span>|</span><a href="#36414560">next</a><span>|</span><label class="collapse" for="c-36414173">[-]</label><label class="expand" for="c-36414173">[2 more]</label></div><br/><div class="children"><div class="content">Would this be before or after inference? Is there some sort of a delegation based on the matter?</div><br/><div id="36415116" class="c"><input type="checkbox" id="c-36415116" checked=""/><div class="controls bullet"><span class="by">cfn</span><span>|</span><a href="#36414078">root</a><span>|</span><a href="#36414173">parent</a><span>|</span><a href="#36414560">next</a><span>|</span><label class="collapse" for="c-36415116">[-]</label><label class="expand" for="c-36415116">[1 more]</label></div><br/><div class="children"><div class="content">If it is output tokens then it is after the inference.</div><br/></div></div></div></div></div></div><div id="36414560" class="c"><input type="checkbox" id="c-36414560" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#36414078">parent</a><span>|</span><a href="#36414105">prev</a><span>|</span><a href="#36415849">next</a><span>|</span><label class="collapse" for="c-36414560">[-]</label><label class="expand" for="c-36414560">[1 more]</label></div><br/><div class="children"><div class="content">same. i wish i had asked george instead of nodding along like an idiot. he probably wouldnt know but at least he’d speculate in interesting ways.</div><br/></div></div></div></div><div id="36415849" class="c"><input type="checkbox" id="c-36415849" checked=""/><div class="controls bullet"><span class="by">letitgo12345</span><span>|</span><a href="#36414078">prev</a><span>|</span><a href="#36413990">next</a><span>|</span><label class="collapse" for="c-36415849">[-]</label><label class="expand" for="c-36415849">[1 more]</label></div><br/><div class="children"><div class="content">What&#x27;s 16 iter inference?</div><br/></div></div><div id="36413990" class="c"><input type="checkbox" id="c-36413990" checked=""/><div class="controls bullet"><span class="by">ramraj07</span><span>|</span><a href="#36415849">prev</a><span>|</span><a href="#36415165">next</a><span>|</span><label class="collapse" for="c-36413990">[-]</label><label class="expand" for="c-36413990">[2 more]</label></div><br/><div class="children"><div class="content">If it’s trivial then why does every other competitor suck at replicating it? Is it possible this is just a case of sour grapes that this intellectual is annoyed they’re not at the driving wheel of the coolest thing anymore?</div><br/><div id="36414030" class="c"><input type="checkbox" id="c-36414030" checked=""/><div class="controls bullet"><span class="by">typon</span><span>|</span><a href="#36413990">parent</a><span>|</span><a href="#36415165">next</a><span>|</span><label class="collapse" for="c-36414030">[-]</label><label class="expand" for="c-36414030">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think he thinks its trivial - just that its not some revolutionary new architecture. It&#x27;s an immense engineering effort rather than a fundamental breakthrough.</div><br/></div></div></div></div><div id="36415165" class="c"><input type="checkbox" id="c-36415165" checked=""/><div class="controls bullet"><span class="by">Havoc</span><span>|</span><a href="#36413990">prev</a><span>|</span><a href="#36414096">next</a><span>|</span><label class="collapse" for="c-36415165">[-]</label><label class="expand" for="c-36415165">[2 more]</label></div><br/><div class="children"><div class="content">Interesting. And makes sense. Eg I could see one of the eight being very close focussed and trained on GitHub like data. Could help it stay on tasks too</div><br/><div id="36415303" class="c"><input type="checkbox" id="c-36415303" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#36415165">parent</a><span>|</span><a href="#36414096">next</a><span>|</span><label class="collapse" for="c-36415303">[-]</label><label class="expand" for="c-36415303">[1 more]</label></div><br/><div class="children"><div class="content">i&#x27;d love any and all informed speculation on what the 8 models could be. it seems fascinating that we don&#x27;t know.</div><br/></div></div></div></div><div id="36414096" class="c"><input type="checkbox" id="c-36414096" checked=""/><div class="controls bullet"><span class="by">jerpint</span><span>|</span><a href="#36415165">prev</a><span>|</span><a href="#36413694">next</a><span>|</span><label class="collapse" for="c-36414096">[-]</label><label class="expand" for="c-36414096">[2 more]</label></div><br/><div class="children"><div class="content">I really wonder if it is the case that the image processing is simply more tokens appended to the sequence. Would make the most sense from an architecture perspective, training must be a whole other ballgame of alchemy though</div><br/><div id="36414547" class="c"><input type="checkbox" id="c-36414547" checked=""/><div class="controls bullet"><span class="by">benob</span><span>|</span><a href="#36414096">parent</a><span>|</span><a href="#36413694">next</a><span>|</span><label class="collapse" for="c-36414547">[-]</label><label class="expand" for="c-36414547">[1 more]</label></div><br/><div class="children"><div class="content">Probably. Check the kosmos-1 paper from Microsoft that appeared a few days before GPT4 was released: <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2302.14045" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2302.14045</a></div><br/></div></div></div></div><div id="36413694" class="c"><input type="checkbox" id="c-36413694" checked=""/><div class="controls bullet"><span class="by">sylware</span><span>|</span><a href="#36414096">prev</a><span>|</span><label class="collapse" for="c-36413694">[-]</label><label class="expand" for="c-36413694">[20 more]</label></div><br/><div class="children"><div class="content">Is this still orders of magnitude smaller than a human brain?<p>How many? Based on current human neurons&#x2F;synapses knowledge?</div><br/><div id="36413772" class="c"><input type="checkbox" id="c-36413772" checked=""/><div class="controls bullet"><span class="by">birriel</span><span>|</span><a href="#36413694">parent</a><span>|</span><a href="#36413786">next</a><span>|</span><label class="collapse" for="c-36413772">[-]</label><label class="expand" for="c-36413772">[8 more]</label></div><br/><div class="children"><div class="content">2 orders of magnitude smaller, assuming 100T synaptic connections in the human brain.</div><br/><div id="36414621" class="c"><input type="checkbox" id="c-36414621" checked=""/><div class="controls bullet"><span class="by">baq</span><span>|</span><a href="#36413694">root</a><span>|</span><a href="#36413772">parent</a><span>|</span><a href="#36414370">next</a><span>|</span><label class="collapse" for="c-36414621">[-]</label><label class="expand" for="c-36414621">[1 more]</label></div><br/><div class="children"><div class="content">And how big is the memory and language part…?</div><br/></div></div><div id="36414370" class="c"><input type="checkbox" id="c-36414370" checked=""/><div class="controls bullet"><span class="by">jimmySixDOF</span><span>|</span><a href="#36413694">root</a><span>|</span><a href="#36413772">parent</a><span>|</span><a href="#36414621">prev</a><span>|</span><a href="#36414003">next</a><span>|</span><label class="collapse" for="c-36414370">[-]</label><label class="expand" for="c-36414370">[1 more]</label></div><br/><div class="children"><div class="content">In the podcast they talk about 20 Peta FLOPS as the human brain equivalent for measuring comparison.</div><br/></div></div><div id="36414003" class="c"><input type="checkbox" id="c-36414003" checked=""/><div class="controls bullet"><span class="by">ada1981</span><span>|</span><a href="#36413694">root</a><span>|</span><a href="#36413772">parent</a><span>|</span><a href="#36414370">prev</a><span>|</span><a href="#36413786">next</a><span>|</span><label class="collapse" for="c-36414003">[-]</label><label class="expand" for="c-36414003">[5 more]</label></div><br/><div class="children"><div class="content">It’s remarkable.<p>I’m curious how long until people are just using training brains in a jar to compute.</div><br/><div id="36414373" class="c"><input type="checkbox" id="c-36414373" checked=""/><div class="controls bullet"><span class="by">quickthrower2</span><span>|</span><a href="#36413694">root</a><span>|</span><a href="#36414003">parent</a><span>|</span><a href="#36413786">next</a><span>|</span><label class="collapse" for="c-36414373">[-]</label><label class="expand" for="c-36414373">[4 more]</label></div><br/><div class="children"><div class="content">They already are, for the hyperhyperparameter choices.</div><br/><div id="36414722" class="c"><input type="checkbox" id="c-36414722" checked=""/><div class="controls bullet"><span class="by">mlashcorp</span><span>|</span><a href="#36413694">root</a><span>|</span><a href="#36414373">parent</a><span>|</span><a href="#36413786">next</a><span>|</span><label class="collapse" for="c-36414722">[-]</label><label class="expand" for="c-36414722">[3 more]</label></div><br/><div class="children"><div class="content">Well, not in a jar ... Right?</div><br/><div id="36415584" class="c"><input type="checkbox" id="c-36415584" checked=""/><div class="controls bullet"><span class="by">quickthrower2</span><span>|</span><a href="#36413694">root</a><span>|</span><a href="#36414722">parent</a><span>|</span><a href="#36415053">next</a><span>|</span><label class="collapse" for="c-36415584">[-]</label><label class="expand" for="c-36415584">[1 more]</label></div><br/><div class="children"><div class="content">Open plan noisy offices are almost that.</div><br/></div></div><div id="36415053" class="c"><input type="checkbox" id="c-36415053" checked=""/><div class="controls bullet"><span class="by">zxcnmbzxcmb</span><span>|</span><a href="#36413694">root</a><span>|</span><a href="#36414722">parent</a><span>|</span><a href="#36415584">prev</a><span>|</span><a href="#36413786">next</a><span>|</span><label class="collapse" for="c-36415053">[-]</label><label class="expand" for="c-36415053">[1 more]</label></div><br/><div class="children"><div class="content">How would you know that you&#x27;re not in a jar? :-)</div><br/></div></div></div></div></div></div></div></div></div></div><div id="36413786" class="c"><input type="checkbox" id="c-36413786" checked=""/><div class="controls bullet"><span class="by">justrealist</span><span>|</span><a href="#36413694">parent</a><span>|</span><a href="#36413772">prev</a><span>|</span><a href="#36414780">next</a><span>|</span><label class="collapse" for="c-36413786">[-]</label><label class="expand" for="c-36413786">[10 more]</label></div><br/><div class="children"><div class="content">We really have no idea how to directly compare the two.<p>Also, vast portions of the human brain are dedicated to the visual cortex, smelling, breathing, muscle control... things which have value to us but which don&#x27;t contribute to knowledge work when evaluating how many parameters it would take to replace human knowledge work.</div><br/><div id="36414103" class="c"><input type="checkbox" id="c-36414103" checked=""/><div class="controls bullet"><span class="by">steve_adams_86</span><span>|</span><a href="#36413694">root</a><span>|</span><a href="#36413786">parent</a><span>|</span><a href="#36413827">next</a><span>|</span><label class="collapse" for="c-36414103">[-]</label><label class="expand" for="c-36414103">[3 more]</label></div><br/><div class="children"><div class="content">While those portions of the brain aren&#x27;t specific to learning intellectual or academic information, they might be crucial to making sense of data, help in testing what we learn, and help bridge countless gaps between model&#x2F;simulation and reality (whatever that is). Hopefully that makes sense. Sort of like... Holistic learning.<p>I wonder if our brains and bodies are not all that separate, and the intangible features of that unity might be very difficult to quantify and replicate in silica.</div><br/><div id="36414263" class="c"><input type="checkbox" id="c-36414263" checked=""/><div class="controls bullet"><span class="by">zrm</span><span>|</span><a href="#36413694">root</a><span>|</span><a href="#36414103">parent</a><span>|</span><a href="#36413827">next</a><span>|</span><label class="collapse" for="c-36414263">[-]</label><label class="expand" for="c-36414263">[2 more]</label></div><br/><div class="children"><div class="content">We can say that such and such part of the brain is &quot;for&quot; this or that. Then it releases neurotransmitters or changes the level of hormones in your body which in turn have cascading effects, and at this point information theory would like to have a word.<p>&quot;If our small minds, for some convenience, divide this glass of wine, this universe, into parts -- physics, biology, geology, astronomy, psychology, and so on -- remember that nature does not know it!&quot; -Richard Feynmann</div><br/><div id="36414648" class="c"><input type="checkbox" id="c-36414648" checked=""/><div class="controls bullet"><span class="by">passion__desire</span><span>|</span><a href="#36413694">root</a><span>|</span><a href="#36414263">parent</a><span>|</span><a href="#36413827">next</a><span>|</span><label class="collapse" for="c-36414648">[-]</label><label class="expand" for="c-36414648">[1 more]</label></div><br/><div class="children"><div class="content">Reality only computes at the level of quarks - a less wrong post</div><br/></div></div></div></div></div></div><div id="36413827" class="c"><input type="checkbox" id="c-36413827" checked=""/><div class="controls bullet"><span class="by">vbezhenar</span><span>|</span><a href="#36413694">root</a><span>|</span><a href="#36413786">parent</a><span>|</span><a href="#36414103">prev</a><span>|</span><a href="#36414494">next</a><span>|</span><label class="collapse" for="c-36413827">[-]</label><label class="expand" for="c-36413827">[5 more]</label></div><br/><div class="children"><div class="content">It&#x27;s really interesting that human organism requires so much computational power to support live.</div><br/><div id="36413868" class="c"><input type="checkbox" id="c-36413868" checked=""/><div class="controls bullet"><span class="by">gwoolhurme</span><span>|</span><a href="#36413694">root</a><span>|</span><a href="#36413827">parent</a><span>|</span><a href="#36414494">next</a><span>|</span><label class="collapse" for="c-36413868">[-]</label><label class="expand" for="c-36413868">[4 more]</label></div><br/><div class="children"><div class="content">I think it&#x27;s even more interesting that the required amount of energy to do that high computational work isn&#x27;t that high. Evolution has been working on it for a long time, and some things are really inefficient but overall it does an OK job at making squishy machines.</div><br/><div id="36413982" class="c"><input type="checkbox" id="c-36413982" checked=""/><div class="controls bullet"><span class="by">tedivm</span><span>|</span><a href="#36413694">root</a><span>|</span><a href="#36413868">parent</a><span>|</span><a href="#36415361">next</a><span>|</span><label class="collapse" for="c-36413982">[-]</label><label class="expand" for="c-36413982">[2 more]</label></div><br/><div class="children"><div class="content">The human brain uses roughly 20 watts, which is really a remarkably low number.<p><a href="https:&#x2F;&#x2F;psychology.stackexchange.com&#x2F;a&#x2F;12386" rel="nofollow noreferrer">https:&#x2F;&#x2F;psychology.stackexchange.com&#x2F;a&#x2F;12386</a></div><br/><div id="36414740" class="c"><input type="checkbox" id="c-36414740" checked=""/><div class="controls bullet"><span class="by">interlinked</span><span>|</span><a href="#36413694">root</a><span>|</span><a href="#36413982">parent</a><span>|</span><a href="#36415361">next</a><span>|</span><label class="collapse" for="c-36414740">[-]</label><label class="expand" for="c-36414740">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s 20% of total energy consumption.</div><br/></div></div></div></div><div id="36415361" class="c"><input type="checkbox" id="c-36415361" checked=""/><div class="controls bullet"><span class="by">loh</span><span>|</span><a href="#36413694">root</a><span>|</span><a href="#36413868">parent</a><span>|</span><a href="#36413982">prev</a><span>|</span><a href="#36414494">next</a><span>|</span><label class="collapse" for="c-36415361">[-]</label><label class="expand" for="c-36415361">[1 more]</label></div><br/><div class="children"><div class="content">I had a good chuckle at &quot;squishy machines&quot;. That&#x27;s a really interesting way to think about it. It makes me wonder if, some day, we will be able to build &quot;squishy machines&quot; of our own, capable of outperforming silicon while using a tiny fraction of the energy.</div><br/></div></div></div></div></div></div><div id="36414494" class="c"><input type="checkbox" id="c-36414494" checked=""/><div class="controls bullet"><span class="by">pzo</span><span>|</span><a href="#36413694">root</a><span>|</span><a href="#36413786">parent</a><span>|</span><a href="#36413827">prev</a><span>|</span><a href="#36414780">next</a><span>|</span><label class="collapse" for="c-36414494">[-]</label><label class="expand" for="c-36414494">[1 more]</label></div><br/><div class="children"><div class="content">on top of that I would add that humans have very high DPI touch sensors across full body (skin)</div><br/></div></div></div></div><div id="36414780" class="c"><input type="checkbox" id="c-36414780" checked=""/><div class="controls bullet"><span class="by">light_hue_1</span><span>|</span><a href="#36413694">parent</a><span>|</span><a href="#36413786">prev</a><span>|</span><label class="collapse" for="c-36414780">[-]</label><label class="expand" for="c-36414780">[1 more]</label></div><br/><div class="children"><div class="content">We have no idea how to estimate the computational capacity of the brain at the moment. We can make silly estimates like saying that 1 human neuron is equivalent to something in an artificial network. But this is definitely wrong, biological neurons are far more complex than this.<p>The big problem is that we don&#x27;t understand the locus of computation in the brain. What is the thing performing the meaningful unit of computation in a neuron? And what is a neuron really equivalent to?<p>The ranges are massive.<p>Some people say that computation is some high level property of the neuron as a whole, so they think each neuron is equivalent to just a few logic gates. These people would say that the brain has a capacity of about 1 petaFLOP&#x2F;s. <a href="https:&#x2F;&#x2F;lips.cs.princeton.edu&#x2F;what-is-the-computational-capacity-of-the-brain&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;lips.cs.princeton.edu&#x2F;what-is-the-computational-capa...</a><p>Then there are people who think every Na, K, and Ca ion channel performs meaningful computation. They would say the brain has a capacity of 1 zettaFLOP&#x2F;s. <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2009.10615.pdf" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2009.10615.pdf</a><p>Then there are computational researchers who just want to approximate what a neuron does. Their results say that neurons are more like whole 4-8 layer artificial networks. This would place the brain well somewhere in the yottaFLOP&#x2F;s range <a href="https:&#x2F;&#x2F;www.quantamagazine.org&#x2F;how-computationally-complex-is-a-single-neuron-20210902&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.quantamagazine.org&#x2F;how-computationally-complex-i...</a><p>And we&#x27;re learning more about how complex neurons are all the time. No one thinks the picture above is accurate in any way.<p>Then there are the extremists who think that there is something non-classical about our brains. That neurons individually or areas of the brain as a whole exploit some form of quantum computation. If they&#x27;re right, we&#x27;re not even remotely on the trajectory to matching brains, and very likely nothing we&#x27;re doing today will ever pay off in that sense. Almost no one believes them.<p>Let&#x27;s say the brain is in the zettaFLOP&#x2F;s range. That&#x27;s 10^21 FLOP&#x2F;s. Training GPT-3 took 10^23 FLOPS total over 34 days. 34 days has 2937600 seconds. 10^23&#x2F;10^7 is about 10^16 FLOP&#x2F;s. So by this back of the envelope computation the brain has about 4 orders of magnitude more capacity, or 1000x. This makes a lot of sense, they&#x27;re using a pettaFLOP&#x2F;s supercomputer basically which we already knew. We&#x27;ll have zettaFLOP&#x2F;s supercomputers soon, yottaFLOP&#x2F;s, people are worried we&#x27;re going to hit some fundamental physical limits before we get there.<p>All of this is a simplification and there are problems with every one of these estimates.<p>But, in some sense none of it means anything at all. You can have an extremely efficient algorithm that runs 1 million times faster than an extremely inefficient algorithm. Machines and brains do not run the same &quot;software&quot;, the same algorithms. So comparing their hardware directly doesn&#x27;t say anything at all.</div><br/></div></div></div></div></div></div></div></div></div></body></html>