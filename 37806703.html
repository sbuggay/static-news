<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1696842083411" as="style"/><link rel="stylesheet" href="styles.css?v=1696842083411"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://bignacio.github.io/soc/docs/articles/arm64-x86_64-on-aws/">Workloads on Arm-based AWS instances</a> <span class="domain">(<a href="https://bignacio.github.io">bignacio.github.io</a>)</span></div><div class="subtext"><span>BiraIgnacio</span> | <span>14 comments</span></div><br/><div><div id="37818170" class="c"><input type="checkbox" id="c-37818170" checked=""/><div class="controls bullet"><span class="by">TheDong</span><span>|</span><a href="#37817912">next</a><span>|</span><label class="collapse" for="c-37818170">[-]</label><label class="expand" for="c-37818170">[1 more]</label></div><br/><div class="children"><div class="content">In the &quot;test setup&quot;, it says: &quot;a t3a.micro&quot; and &quot;a t4g.micro&quot;.<p>To me, this implies they used a single ec2 instance of each size. However, ec2 instance p99s or so can be impacted by &quot;noisy neighbors&quot;, especially on the burstable types which are intentionally oversubscribed.<p>It&#x27;s still useful to know if, for example, t4gs are more prone to noisy neighbors, but with only 1 instance as a datapoint, you simply can&#x27;t tell if it was bad luck or not.<p>I think this test would be much better with either only dedicated instance types, or by running it with a large n such that an individual unlucky&#x2F;noisy-neighbor doesn&#x27;t influence the results overtly.</div><br/></div></div><div id="37817912" class="c"><input type="checkbox" id="c-37817912" checked=""/><div class="controls bullet"><span class="by">iknownothow</span><span>|</span><a href="#37818170">prev</a><span>|</span><a href="#37817604">next</a><span>|</span><label class="collapse" for="c-37817912">[-]</label><label class="expand" for="c-37817912">[4 more]</label></div><br/><div class="children"><div class="content">Aren&#x27;t &#x27;t&#x27; instances burst instances? They need to be under constant load for a long time before their burst credits for CPU, memory, network and EBS run out, after which they fall back on their baseline performance.<p>&gt; It does appear that the Arm-based instances can’t consistently maintain the same performance at high request rates.<p>I&#x27;m unwilling to trust that statement at face value for now given it&#x27;s been tested against a &#x27;t&#x27; instance.<p>EDIT: Removed note about network burst credits in compute and memory optimized instances. I&#x27;m not sure if these instances have that.</div><br/><div id="37817966" class="c"><input type="checkbox" id="c-37817966" checked=""/><div class="controls bullet"><span class="by">vegardx</span><span>|</span><a href="#37817912">parent</a><span>|</span><a href="#37817604">next</a><span>|</span><label class="collapse" for="c-37817966">[-]</label><label class="expand" for="c-37817966">[3 more]</label></div><br/><div class="children"><div class="content">The T3 instances are all burstable, but they come with the &quot;unlimited&quot; feature toggled on by default. The T2 instances had this feature toggled off by default. So with this instance type you never really run out of credits, but you could quickly end up paying more than with other general purpose instance types, like M series, if you burn through a lot of credits.</div><br/><div id="37818246" class="c"><input type="checkbox" id="c-37818246" checked=""/><div class="controls bullet"><span class="by">iknownothow</span><span>|</span><a href="#37817912">root</a><span>|</span><a href="#37817966">parent</a><span>|</span><a href="#37817604">next</a><span>|</span><label class="collapse" for="c-37818246">[-]</label><label class="expand" for="c-37818246">[2 more]</label></div><br/><div class="children"><div class="content">Thanks for pointing that out, I never noticed that setting. I just tried to launch an EC2 instance looking for this setting and here&#x27;s what I found.<p>&gt; A credit specification is only available for T2, T3, and T3a instances. Selecting Unlimited for the credit specification allows applications to burst beyond the baseline for as long as needed at any time.<p>So that would mean Unlimited is not a setting available for T4g (ARM instance) and therefore <i>may</i> explain inconsistent behavior in the ARM instance.</div><br/><div id="37818355" class="c"><input type="checkbox" id="c-37818355" checked=""/><div class="controls bullet"><span class="by">vladvasiliu</span><span>|</span><a href="#37817912">root</a><span>|</span><a href="#37818246">parent</a><span>|</span><a href="#37817604">next</a><span>|</span><label class="collapse" for="c-37818355">[-]</label><label class="expand" for="c-37818355">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s the same for t4g.<p><pre><code>    &gt; T4g instances start in unlimited mode by default, giving users the ability to sustain high CPU performance over any desired time frame while keeping cost as low as possible. For most general purpose workloads, T4g instances in unlimited mode provide ample performance without any additional charges. If the average CPU utilization of a T4g instance is lower than the baseline over a 24-hour period, the hourly instance price automatically covers all interim spikes in usage. In the cases when a T4g instance needs to run at higher CPU utilization for a prolonged period, it can do so for a small additional charge of $0.04 per vCPU-hour. In standard mode, a T4g instance can burst until it uses up all of its earned credits. For more details on T4g credits, please see the EC2 documentation page.
</code></pre>
<a href="https:&#x2F;&#x2F;aws.amazon.com&#x2F;ec2&#x2F;instance-types&#x2F;t4&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;aws.amazon.com&#x2F;ec2&#x2F;instance-types&#x2F;t4&#x2F;</a></div><br/></div></div></div></div></div></div></div></div><div id="37817604" class="c"><input type="checkbox" id="c-37817604" checked=""/><div class="controls bullet"><span class="by">LatticeAnimal</span><span>|</span><a href="#37817912">prev</a><span>|</span><a href="#37818159">next</a><span>|</span><label class="collapse" for="c-37817604">[-]</label><label class="expand" for="c-37817604">[1 more]</label></div><br/><div class="children"><div class="content">Given the title, I would have expected a price&#x2F;perf comparison across multiple tiers of servers. Focusing on two random (but similar) low performance instances makes it hard to generalize.</div><br/></div></div><div id="37818159" class="c"><input type="checkbox" id="c-37818159" checked=""/><div class="controls bullet"><span class="by">upon_drumhead</span><span>|</span><a href="#37817604">prev</a><span>|</span><a href="#37817570">next</a><span>|</span><label class="collapse" for="c-37818159">[-]</label><label class="expand" for="c-37818159">[1 more]</label></div><br/><div class="children"><div class="content">I don’t understand how 99.99999 is larger than max.</div><br/></div></div><div id="37817570" class="c"><input type="checkbox" id="c-37817570" checked=""/><div class="controls bullet"><span class="by">Espressosaurus</span><span>|</span><a href="#37818159">prev</a><span>|</span><a href="#37817803">next</a><span>|</span><label class="collapse" for="c-37817570">[-]</label><label class="expand" for="c-37817570">[2 more]</label></div><br/><div class="children"><div class="content">A couple recommendations for your visualization:<p>1) More fine-grained bins to help show the shape of the distribution (are there performance cliffs?). Try using vertical lines to denote % cutoffs.<p>2) Given the wide range between your bins, a log scale might be a good idea instead of raw frequency.<p>3) Try some other method of visualization. I&#x27;m not sure a histogram is useful for what you&#x27;re trying to convey, at least the way it&#x27;s being used here.<p>As it stands, the visual information is so dominated by the 99.5% case that the plots don&#x27;t help illustrate your tabular data.</div><br/><div id="37818005" class="c"><input type="checkbox" id="c-37818005" checked=""/><div class="controls bullet"><span class="by">wyldfire</span><span>|</span><a href="#37817570">parent</a><span>|</span><a href="#37817803">next</a><span>|</span><label class="collapse" for="c-37818005">[-]</label><label class="expand" for="c-37818005">[1 more]</label></div><br/><div class="children"><div class="content">Agreed, these graphs were challenging to read.<p>Instead of a histogram, a violin plot (especially &quot;split&quot;) might be an excellent way to compare the distributions. And that solves the bucket size problem too IMO.<p><a href="https:&#x2F;&#x2F;seaborn.pydata.org&#x2F;generated&#x2F;seaborn.violinplot.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;seaborn.pydata.org&#x2F;generated&#x2F;seaborn.violinplot.html</a></div><br/></div></div></div></div><div id="37817803" class="c"><input type="checkbox" id="c-37817803" checked=""/><div class="controls bullet"><span class="by">opentokix</span><span>|</span><a href="#37817570">prev</a><span>|</span><a href="#37817682">next</a><span>|</span><label class="collapse" for="c-37817803">[-]</label><label class="expand" for="c-37817803">[1 more]</label></div><br/><div class="children"><div class="content">I think the discrepancies can be attributed to the choice of the t-style instances. They are generally over committed.</div><br/></div></div><div id="37817682" class="c"><input type="checkbox" id="c-37817682" checked=""/><div class="controls bullet"><span class="by">59nadir</span><span>|</span><a href="#37817803">prev</a><span>|</span><a href="#37817332">next</a><span>|</span><label class="collapse" for="c-37817682">[-]</label><label class="expand" for="c-37817682">[1 more]</label></div><br/><div class="children"><div class="content">Was this tested with dedicated instances? Would there be a potential difference if it was?</div><br/></div></div><div id="37817332" class="c"><input type="checkbox" id="c-37817332" checked=""/><div class="controls bullet"><span class="by">nodesocket</span><span>|</span><a href="#37817682">prev</a><span>|</span><a href="#37806704">next</a><span>|</span><label class="collapse" for="c-37817332">[-]</label><label class="expand" for="c-37817332">[1 more]</label></div><br/><div class="children"><div class="content">Highly recommend ARM-based instances for RDS and ElastiCache in particular. That&#x27;s a easy instance type switch and nearly idiot proof. Switching Kubernetes cluster worker nodes is another story (though ARM built container adoption is getting better).</div><br/></div></div></div></div></div></div></div></body></html>