<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1711530068056" as="style"/><link rel="stylesheet" href="styles.css?v=1711530068056"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://adamkarvonen.github.io/machine_learning/2024/03/20/chess-gpt-interventions.html">Manipulating Chess-GPT&#x27;s World Model</a> <span class="domain">(<a href="https://adamkarvonen.github.io">adamkarvonen.github.io</a>)</span></div><div class="subtext"><span>seraine</span> | <span>35 comments</span></div><br/><div><div id="39835807" class="c"><input type="checkbox" id="c-39835807" checked=""/><div class="controls bullet"><span class="by">kromem</span><span>|</span><a href="#39832911">next</a><span>|</span><label class="collapse" for="c-39835807">[-]</label><label class="expand" for="c-39835807">[1 more]</label></div><br/><div class="children"><div class="content">Two thoughts regarding the new work:<p>(1) I&#x27;d consider normalizing the performance data for the random cases against another chess program with similar performance under normal conditions. It may be that introducing 20 random moves to the start of a game biases all players towards a 50&#x2F;50 win outcome. So the sub-50 performance may not reflect a failure of flipping the &quot;don&#x27;t suck&quot; switch, but simply good performance in a more average outcome scenario. It&#x27;d be interesting to see if Chess-GPT&#x27;s relative performance against other chess programs in the random scenario was better than its relative performance in the normal case.<p>(2) The &#x27;fuzziness&#x27; of the board positions you found when removing the pawn makes complete sense given one of the nuanced findings in Hazineh, et al <i>Linear Latent World Models in Simple Transformers: A Case Study on Othello-GPT</i> (2023) - specifically the finding that it was encoding representations for board configuration and not just pieces (in that case three stones in a row). It may be that piecemeal removal of a piece disrupted patterns of how games normally flow which it had learned, and as such there was greater uncertainty than the original board state. A similar issue may be at hand with the random 20 moves to start, and I&#x27;d be curious what the confidence of the board state was when starting off 20 random moves in and if that confidence stabilized as the game went on from there.<p>Overall really cool update!<p>And bigger picture, the prospects of essentially flipping an internalized skill vector for larger models to bias them back away from their regression to the mean is particularly exciting.</div><br/></div></div><div id="39832911" class="c"><input type="checkbox" id="c-39832911" checked=""/><div class="controls bullet"><span class="by">elif</span><span>|</span><a href="#39835807">prev</a><span>|</span><a href="#39832887">next</a><span>|</span><label class="collapse" for="c-39832911">[-]</label><label class="expand" for="c-39832911">[14 more]</label></div><br/><div class="children"><div class="content">&gt; had Chess-GPT play against Stockfish with this random initialization. Its performance plummeted. The larger 50 million parameter model’s win rate dropped from 70% to 17%.<p>Beating stockfish 17% of the time is still incredible for any engine.<p>and being trained on human moves rather than engine moves will make this so much more annoying to analyze cheating...</div><br/><div id="39833332" class="c"><input type="checkbox" id="c-39833332" checked=""/><div class="controls bullet"><span class="by">seraine</span><span>|</span><a href="#39832911">parent</a><span>|</span><a href="#39833010">next</a><span>|</span><label class="collapse" for="c-39833332">[-]</label><label class="expand" for="c-39833332">[4 more]</label></div><br/><div class="children"><div class="content">I updated the article to also mention this in the second blog post. All games were against Stockfish level 0, with nodes searched limited to 100,000 rather than a time based search limit to limit variability due to different processors.</div><br/><div id="39833469" class="c"><input type="checkbox" id="c-39833469" checked=""/><div class="controls bullet"><span class="by">afro88</span><span>|</span><a href="#39832911">root</a><span>|</span><a href="#39833332">parent</a><span>|</span><a href="#39834703">next</a><span>|</span><label class="collapse" for="c-39833469">[-]</label><label class="expand" for="c-39833469">[2 more]</label></div><br/><div class="children"><div class="content">I googled stockfish &quot;level 0&quot; and it came up with no results. What do you mean by level 0?</div><br/><div id="39833621" class="c"><input type="checkbox" id="c-39833621" checked=""/><div class="controls bullet"><span class="by">seraine</span><span>|</span><a href="#39832911">root</a><span>|</span><a href="#39833469">parent</a><span>|</span><a href="#39834703">next</a><span>|</span><label class="collapse" for="c-39833621">[-]</label><label class="expand" for="c-39833621">[1 more]</label></div><br/><div class="children"><div class="content">The Stockfish program can be set to play at strength level 0-20. Estimates of the levels&#x27; Elo is provided here: <a href="https:&#x2F;&#x2F;github.com&#x2F;official-stockfish&#x2F;Stockfish&#x2F;commit&#x2F;a08b8d4">https:&#x2F;&#x2F;github.com&#x2F;official-stockfish&#x2F;Stockfish&#x2F;commit&#x2F;a08b8...</a></div><br/></div></div></div></div><div id="39834703" class="c"><input type="checkbox" id="c-39834703" checked=""/><div class="controls bullet"><span class="by">quadrature</span><span>|</span><a href="#39832911">root</a><span>|</span><a href="#39833332">parent</a><span>|</span><a href="#39833469">prev</a><span>|</span><a href="#39833010">next</a><span>|</span><label class="collapse" for="c-39834703">[-]</label><label class="expand" for="c-39834703">[1 more]</label></div><br/><div class="children"><div class="content">Have you tried performing a search using Chess-GPT ?.</div><br/></div></div></div></div><div id="39833010" class="c"><input type="checkbox" id="c-39833010" checked=""/><div class="controls bullet"><span class="by">jsmith99</span><span>|</span><a href="#39832911">parent</a><span>|</span><a href="#39833332">prev</a><span>|</span><a href="#39833347">next</a><span>|</span><label class="collapse" for="c-39833010">[-]</label><label class="expand" for="c-39833010">[3 more]</label></div><br/><div class="children"><div class="content">Article says: ‘Chess-GPT also played chess well, with the best model playing at approximately 1500 Elo.’<p>So I’m guessing this wasn’t full strength stockfish.</div><br/><div id="39833190" class="c"><input type="checkbox" id="c-39833190" checked=""/><div class="controls bullet"><span class="by">jxy</span><span>|</span><a href="#39832911">root</a><span>|</span><a href="#39833010">parent</a><span>|</span><a href="#39833153">next</a><span>|</span><label class="collapse" for="c-39833190">[-]</label><label class="expand" for="c-39833190">[1 more]</label></div><br/><div class="children"><div class="content">The previous blog post [0] mentioned they were using stockfish with 0.1 seconds per move.<p>[0] <a href="https:&#x2F;&#x2F;adamkarvonen.github.io&#x2F;machine_learning&#x2F;2024&#x2F;01&#x2F;03&#x2F;chess-world-models.html" rel="nofollow">https:&#x2F;&#x2F;adamkarvonen.github.io&#x2F;machine_learning&#x2F;2024&#x2F;01&#x2F;03&#x2F;c...</a></div><br/></div></div><div id="39833153" class="c"><input type="checkbox" id="c-39833153" checked=""/><div class="controls bullet"><span class="by">noSyncCloud</span><span>|</span><a href="#39832911">root</a><span>|</span><a href="#39833010">parent</a><span>|</span><a href="#39833190">prev</a><span>|</span><a href="#39833347">next</a><span>|</span><label class="collapse" for="c-39833153">[-]</label><label class="expand" for="c-39833153">[1 more]</label></div><br/><div class="children"><div class="content">It notes in the blog post that it was SF level 0.</div><br/></div></div></div></div><div id="39833347" class="c"><input type="checkbox" id="c-39833347" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#39832911">parent</a><span>|</span><a href="#39833010">prev</a><span>|</span><a href="#39833216">next</a><span>|</span><label class="collapse" for="c-39833347">[-]</label><label class="expand" for="c-39833347">[5 more]</label></div><br/><div class="children"><div class="content">i think i dont understand what stockfish does then. doesn&#x27;t it play the basically perfect move at each step? how is it possible to beat stockfish 70% of the time? with a naive GPT type thing?</div><br/><div id="39835989" class="c"><input type="checkbox" id="c-39835989" checked=""/><div class="controls bullet"><span class="by">nl</span><span>|</span><a href="#39832911">root</a><span>|</span><a href="#39833347">parent</a><span>|</span><a href="#39833925">next</a><span>|</span><label class="collapse" for="c-39835989">[-]</label><label class="expand" for="c-39835989">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Doesn&#x27;t it play the basically perfect move at each step?<p>&quot;the basically perfect move&quot; has a lot of implications here.<p>Because chess isn&#x27;t a solved game a seemingly &quot;perfect move&quot; in a game involving two 2000 ELO rated players might not seem perfect to a 3000 ELO rated player. (To be clear: the only <i>actual</i> perfect moves are ones that all trees lead to a checkmate, but in general use &quot;perfect move&quot; means roughly the best possible move to play)<p>In this case Stockfish was set to a lower setting which corresponds to 1320 ELO.</div><br/></div></div><div id="39833384" class="c"><input type="checkbox" id="c-39833384" checked=""/><div class="controls bullet"><span class="by">makeset</span><span>|</span><a href="#39832911">root</a><span>|</span><a href="#39833347">parent</a><span>|</span><a href="#39833925">prev</a><span>|</span><a href="#39833216">next</a><span>|</span><label class="collapse" for="c-39833384">[-]</label><label class="expand" for="c-39833384">[2 more]</label></div><br/><div class="children"><div class="content">Chess is not a fully &quot;solved&quot; game, so the actual perfect move is not generally known. Like any other engine, Stockfish just tries its best and is not infallible.</div><br/></div></div></div></div><div id="39833216" class="c"><input type="checkbox" id="c-39833216" checked=""/><div class="controls bullet"><span class="by">goatlover</span><span>|</span><a href="#39832911">parent</a><span>|</span><a href="#39833347">prev</a><span>|</span><a href="#39832887">next</a><span>|</span><label class="collapse" for="c-39833216">[-]</label><label class="expand" for="c-39833216">[1 more]</label></div><br/><div class="children"><div class="content">It would be impressive if it was playing Stockfish at a grandmaster level. But it looks like it&#x27;s lower-level. Still impressive that it can learn to play decently at some level. Doubt it will ever be competitive with top engine levels.</div><br/></div></div></div></div><div id="39832887" class="c"><input type="checkbox" id="c-39832887" checked=""/><div class="controls bullet"><span class="by">jprival</span><span>|</span><a href="#39832911">prev</a><span>|</span><a href="#39831630">next</a><span>|</span><label class="collapse" for="c-39832887">[-]</label><label class="expand" for="c-39832887">[3 more]</label></div><br/><div class="children"><div class="content">Reminds me tangentially of the study that found that strong chess players were much worse at recalling randomized positions than realistic ones: <a href="https:&#x2F;&#x2F;link.springer.com&#x2F;content&#x2F;pdf&#x2F;10.3758&#x2F;BF03200937.pdf" rel="nofollow">https:&#x2F;&#x2F;link.springer.com&#x2F;content&#x2F;pdf&#x2F;10.3758&#x2F;BF03200937.pdf</a><p>I’m wary of inviting the too-easy “it’s just like how it works for people!” comparison, but the implied context and history of a game state seems to be important in processing it.</div><br/><div id="39835252" class="c"><input type="checkbox" id="c-39835252" checked=""/><div class="controls bullet"><span class="by">pvg</span><span>|</span><a href="#39832887">parent</a><span>|</span><a href="#39835265">next</a><span>|</span><label class="collapse" for="c-39835252">[-]</label><label class="expand" for="c-39835252">[1 more]</label></div><br/><div class="children"><div class="content">Is it context and history or just that real game positions have much lower entropy? Most people can easily remember a sentence after a quick look, a similar-length string of random characters a lot less so.</div><br/></div></div></div></div><div id="39831630" class="c"><input type="checkbox" id="c-39831630" checked=""/><div class="controls bullet"><span class="by">mewpmewp2</span><span>|</span><a href="#39832887">prev</a><span>|</span><a href="#39835617">next</a><span>|</span><label class="collapse" for="c-39831630">[-]</label><label class="expand" for="c-39831630">[6 more]</label></div><br/><div class="children"><div class="content">I&#x27;m curious, what kind of setup is required to train something like that? Can it be done with 4090 and how long would it take? 50M or 25M parameters? And what is the most parameters 4090 can do?<p>This inspires few ideas.</div><br/><div id="39831770" class="c"><input type="checkbox" id="c-39831770" checked=""/><div class="controls bullet"><span class="by">anotherjesse</span><span>|</span><a href="#39831630">parent</a><span>|</span><a href="#39831899">next</a><span>|</span><label class="collapse" for="c-39831770">[-]</label><label class="expand" for="c-39831770">[1 more]</label></div><br/><div class="children"><div class="content">More details in the previous blog post: <a href="https:&#x2F;&#x2F;adamkarvonen.github.io&#x2F;machine_learning&#x2F;2024&#x2F;01&#x2F;03&#x2F;chess-world-models.html" rel="nofollow">https:&#x2F;&#x2F;adamkarvonen.github.io&#x2F;machine_learning&#x2F;2024&#x2F;01&#x2F;03&#x2F;c...</a><p>&gt; A 50 million parameter GPT trained on 5 million games of chess learns to play at ~1300 Elo in one day on 4 RTX 3090 GPUs.<p>And from the paper: <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2403.15498" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2403.15498</a><p>&gt; The 25M parameter model took 72 hours to train on one RTX 3090 GPU. The 50M parameter model took 38 hours to train on four RTX 3090 GPUs.<p>definitely inspiring :)</div><br/></div></div><div id="39831899" class="c"><input type="checkbox" id="c-39831899" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#39831630">parent</a><span>|</span><a href="#39831770">prev</a><span>|</span><a href="#39835617">next</a><span>|</span><label class="collapse" for="c-39831899">[-]</label><label class="expand" for="c-39831899">[4 more]</label></div><br/><div class="children"><div class="content">I&#x27;m waiting for a build so I went fully down this trail. XD<p>A1) Yes it can be done with a 4090. (2a).<p>A2) 2 days. (4d&#x2F;4e).<p>B) Up to you, author did both and settled on 50M which they got to 1300 ELO. (note: they also did subsequent work with the same model to increase perf without further training) (2a).<p>C) Mu: there&#x27;s no limit as you can page in&#x2F;out (3a, 3c), and its trivial to store in both RAM and VRAM. 30B fits in memory with 32 GB of RAM or VRAM. (3e)<p>Starting from:<p>1. article: <a href="https:&#x2F;&#x2F;adamkarvonen.github.io&#x2F;machine_learning&#x2F;2024&#x2F;03&#x2F;20&#x2F;chess-gpt-interventions.html" rel="nofollow">https:&#x2F;&#x2F;adamkarvonen.github.io&#x2F;machine_learning&#x2F;2024&#x2F;03&#x2F;20&#x2F;c...</a><p>2. second sentence links to post on training: <a href="https:&#x2F;&#x2F;adamkarvonen.github.io&#x2F;machine_learning&#x2F;2024&#x2F;01&#x2F;03&#x2F;chess-world-models.html" rel="nofollow">https:&#x2F;&#x2F;adamkarvonen.github.io&#x2F;machine_learning&#x2F;2024&#x2F;01&#x2F;03&#x2F;c...</a>.<p>2a. &quot;A 50 million parameter GPT trained on 5 million games of chess learns to play at ~1300 Elo in one day on 4 RTX 3090 GPUs&quot;<p>2b. &quot;The 50M parameter model played at 1300 Elo with 99.8% of its moves being legal within one day of training&quot;<p>3. re: most parameters 4090 can do:<p>3a. understanding is there is no limitation, in that, you don&#x27;t _need_ to have every parameter in memory at all times, either during training or inference.<p>3b. google &quot;are amount of parameters in llm limited by vram size&quot;<p>3c. go to &#x2F;r&#x2F;LocalLLaMa link: <a href="https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;LocalLLaMA&#x2F;comments&#x2F;15j0mvm&#x2F;what_are_the_variables_to_take_into_account_to&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;LocalLLaMA&#x2F;comments&#x2F;15j0mvm&#x2F;what_ar...</a> (why? its a favorite of mine, believe its the closest you get to local training ppl talking in open space that&#x27;s not discord)<p>3d. understanding in 3a is correct.<p>3e. &quot;The model must fit in your RAM or VRAM, but you can split the model between them. With 32gb ram you could fit a 30b model&quot;<p>4. 3090 vs. 4090 training speed<p>4a. google &quot;rtx 3090 vs. 4090 llm training perf&quot;<p>4b. wander through top reddit links. useful info, but a little too technical to share in a way that doesn&#x27;t require explaining a lot.<p>4c. down the list: lamda labs link from october 2022: <a href="https:&#x2F;&#x2F;lambdalabs.com&#x2F;blog&#x2F;nvidia-rtx-4090-vs-rtx-3090-deep-learning-benchmark" rel="nofollow">https:&#x2F;&#x2F;lambdalabs.com&#x2F;blog&#x2F;nvidia-rtx-4090-vs-rtx-3090-deep...</a><p>4d. 4090 is roughly 2x the perf on TransformerXL Large, the best match for transformers based large model, i.e. an LLM<p>4e. training took 4 3090-sdays for author. So 2 days.</div><br/><div id="39832018" class="c"><input type="checkbox" id="c-39832018" checked=""/><div class="controls bullet"><span class="by">anotherjesse</span><span>|</span><a href="#39831630">root</a><span>|</span><a href="#39831899">parent</a><span>|</span><a href="#39835617">next</a><span>|</span><label class="collapse" for="c-39832018">[-]</label><label class="expand" for="c-39832018">[3 more]</label></div><br/><div class="children"><div class="content">Additionally instructions on training&#x2F;inference on mac - <a href="https:&#x2F;&#x2F;github.com&#x2F;adamkarvonen&#x2F;nanoGPT">https:&#x2F;&#x2F;github.com&#x2F;adamkarvonen&#x2F;nanoGPT</a><p>&gt; To sample on Mac, uncomment line 21 in sample.py. To train on Mac, rename train_shakespeare_char_mac.py to train_shakespeare_char.py<p>The `mac` file changed several things - I decided to try running training with the original config file - changing device to mps &#x2F; compile to false<p><pre><code>    iter 100: loss 2.0268, time 815.43ms, mfu 3.24%
    iter 200: loss 1.8523, time 818.79ms, mfu 3.24%
    iter 300: loss 1.7799, time 823.05ms, mfu 3.23%
    iter 400: loss 1.6887, time 819.08ms, mfu 3.23%
</code></pre>
Training is ~4x slower than the speed reported on the original multi-GPU run: <a href="https:&#x2F;&#x2F;wandb.ai&#x2F;adam-karvonen&#x2F;chess-gpt-batch&#x2F;runs&#x2F;zt5htyl6?nw=nwuseradamkarvonen" rel="nofollow">https:&#x2F;&#x2F;wandb.ai&#x2F;adam-karvonen&#x2F;chess-gpt-batch&#x2F;runs&#x2F;zt5htyl6...</a><p>Not bad for an M2 studio which is running lots of other workloads at the same time</div><br/><div id="39835584" class="c"><input type="checkbox" id="c-39835584" checked=""/><div class="controls bullet"><span class="by">a_wild_dandan</span><span>|</span><a href="#39831630">root</a><span>|</span><a href="#39832018">parent</a><span>|</span><a href="#39835617">next</a><span>|</span><label class="collapse" for="c-39835584">[-]</label><label class="expand" for="c-39835584">[2 more]</label></div><br/><div class="children"><div class="content">I wonder if using Apple’s new MLX Python library (for training on unified memory systems) would yield significant gains.</div><br/><div id="39836008" class="c"><input type="checkbox" id="c-39836008" checked=""/><div class="controls bullet"><span class="by">nl</span><span>|</span><a href="#39831630">root</a><span>|</span><a href="#39835584">parent</a><span>|</span><a href="#39835617">next</a><span>|</span><label class="collapse" for="c-39836008">[-]</label><label class="expand" for="c-39836008">[1 more]</label></div><br/><div class="children"><div class="content">This (the device=&#x27;mps&#x27; version) already uses the unified memory plus GPU on M-series Macs.<p>It&#x27;s possible MLX has some additional micro optimizations, but in general most people who have tried it out against hand-written MPS based training implementations haven&#x27;t found great speed ups yet.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="39835617" class="c"><input type="checkbox" id="c-39835617" checked=""/><div class="controls bullet"><span class="by">mvkel</span><span>|</span><a href="#39831630">prev</a><span>|</span><a href="#39834901">next</a><span>|</span><label class="collapse" for="c-39835617">[-]</label><label class="expand" for="c-39835617">[2 more]</label></div><br/><div class="children"><div class="content">Curious how this performs against chatgpt with few-shot prompting.<p>More and more evidence recently has shown that fine tunes&#x2F;retrieval don&#x27;t measurably improve performance over few-shot, but with this being such a specific domain&#x2F;skill, I&#x27;d be surprised if it didn&#x27;t far outperform a few-shot approach.</div><br/><div id="39835793" class="c"><input type="checkbox" id="c-39835793" checked=""/><div class="controls bullet"><span class="by">kromem</span><span>|</span><a href="#39835617">parent</a><span>|</span><a href="#39834901">next</a><span>|</span><label class="collapse" for="c-39835793">[-]</label><label class="expand" for="c-39835793">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s also not a fine tune.<p>It&#x27;s a pretrained toy model in two days on consumer hardware.</div><br/></div></div></div></div><div id="39834901" class="c"><input type="checkbox" id="c-39834901" checked=""/><div class="controls bullet"><span class="by">willd13</span><span>|</span><a href="#39835617">prev</a><span>|</span><a href="#39830513">next</a><span>|</span><label class="collapse" for="c-39834901">[-]</label><label class="expand" for="c-39834901">[1 more]</label></div><br/><div class="children"><div class="content">I would be really interested to understand the efficiency of this learning vs a more traditional approach. If you have two models - ChessGPT and a traditional chess-playing ML model - and train them on the same number of games, which reaches a higher level of chess-playing skill?</div><br/></div></div><div id="39830513" class="c"><input type="checkbox" id="c-39830513" checked=""/><div class="controls bullet"><span class="by">dang</span><span>|</span><a href="#39834901">prev</a><span>|</span><a href="#39816709">next</a><span>|</span><label class="collapse" for="c-39830513">[-]</label><label class="expand" for="c-39830513">[2 more]</label></div><br/><div class="children"><div class="content">Recent and related:<p><i>Chess-GPT&#x27;s Internal World Model</i> - <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38893456">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38893456</a> - Jan 2024 (103 comments)</div><br/><div id="39833265" class="c"><input type="checkbox" id="c-39833265" checked=""/><div class="controls bullet"><span class="by">patresh</span><span>|</span><a href="#39830513">parent</a><span>|</span><a href="#39816709">next</a><span>|</span><label class="collapse" for="c-39833265">[-]</label><label class="expand" for="c-39833265">[1 more]</label></div><br/><div class="children"><div class="content">Another related one from last year based on the Othello game (cited in the above paper) :<p><i>Do Large Language Models learn world models or just surface statistics?</i> - <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=34474043">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=34474043</a> - Jan 2023 (174 comments)</div><br/></div></div></div></div><div id="39816709" class="c"><input type="checkbox" id="c-39816709" checked=""/><div class="controls bullet"><span class="by">seraine</span><span>|</span><a href="#39830513">prev</a><span>|</span><a href="#39835546">next</a><span>|</span><label class="collapse" for="c-39816709">[-]</label><label class="expand" for="c-39816709">[1 more]</label></div><br/><div class="children"><div class="content">The code for this is located here: <a href="https:&#x2F;&#x2F;github.com&#x2F;adamkarvonen&#x2F;chess_llm_interpretability">https:&#x2F;&#x2F;github.com&#x2F;adamkarvonen&#x2F;chess_llm_interpretability</a></div><br/></div></div><div id="39835546" class="c"><input type="checkbox" id="c-39835546" checked=""/><div class="controls bullet"><span class="by">mycall</span><span>|</span><a href="#39816709">prev</a><span>|</span><a href="#39831576">next</a><span>|</span><label class="collapse" for="c-39835546">[-]</label><label class="expand" for="c-39835546">[1 more]</label></div><br/><div class="children"><div class="content">I look forward when AI intelligently starts combining games for us, i.e. ChessBattleShip</div><br/></div></div><div id="39831576" class="c"><input type="checkbox" id="c-39831576" checked=""/><div class="controls bullet"><span class="by">mxwsn</span><span>|</span><a href="#39835546">prev</a><span>|</span><a href="#39834045">next</a><span>|</span><label class="collapse" for="c-39831576">[-]</label><label class="expand" for="c-39831576">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;d be curious to see which moves gain or lose the most probability when performing the skill intervention. Or the correlation between predicted move probabilities and engine score for moves, before and after skill intervention.</div><br/></div></div><div id="39834045" class="c"><input type="checkbox" id="c-39834045" checked=""/><div class="controls bullet"><span class="by">QuantumG</span><span>|</span><a href="#39831576">prev</a><span>|</span><a href="#39832048">next</a><span>|</span><label class="collapse" for="c-39834045">[-]</label><label class="expand" for="c-39834045">[1 more]</label></div><br/><div class="children"><div class="content">Anyone got more?</div><br/></div></div><div id="39832048" class="c"><input type="checkbox" id="c-39832048" checked=""/><div class="controls bullet"><span class="by">Der_Einzige</span><span>|</span><a href="#39834045">prev</a><span>|</span><label class="collapse" for="c-39832048">[-]</label><label class="expand" for="c-39832048">[1 more]</label></div><br/><div class="children"><div class="content">All of the related work, such as activation&#x2F;representation engineering, and control&#x2F;steering vectors is also really neat!<p>You can play with steering vectors within oobabooga now: <a href="https:&#x2F;&#x2F;github.com&#x2F;Hellisotherpeople&#x2F;llm_steer-oobabooga">https:&#x2F;&#x2F;github.com&#x2F;Hellisotherpeople&#x2F;llm_steer-oobabooga</a></div><br/></div></div></div></div></div></div></div></body></html>