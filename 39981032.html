<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1712739667824" as="style"/><link rel="stylesheet" href="styles.css?v=1712739667824"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.intel.com/content/www/us/en/newsroom/news/vision-2024-gaudi-3-ai-accelerator.html">Intel Gaudi 3 AI Accelerator</a> <span class="domain">(<a href="https://www.intel.com">www.intel.com</a>)</span></div><div class="subtext"><span>goldemerald</span> | <span>213 comments</span></div><br/><div><div id="39983624" class="c"><input type="checkbox" id="c-39983624" checked=""/><div class="controls bullet"><span class="by">mk_stjames</span><span>|</span><a href="#39982320">next</a><span>|</span><label class="collapse" for="c-39983624">[-]</label><label class="expand" for="c-39983624">[31 more]</label></div><br/><div class="children"><div class="content">One nice thing about this (and the new offerings from AMD) is that they will be using the &quot;open accelerator module (OAM)&quot; interface- which standardizes the connector that they use to put them on baseboards, similar to the SXM connections of Nvidia that use MegArray connectors to thier baseboards.<p>With Nvidia, the SXM connection pinouts have always been held proprietary and confidential.  For example, P100&#x27;s and V100&#x27;s have standard PCI-e lanes connected to one of the two sides of their MegArray connectors, and if you know that pinout you could literally build PCI-e cards with SXM2&#x2F;3 connectors to repurpose those now obsolete chips (this has been done by one person).<p>There are thousands, maybe tens of thousands of P100&#x27;s you could pickup for literally &lt;$50 apiece these days which technically give you more Tflops&#x2F;$ than anything on the market, but they are useless because their interface was not ever made open and has not been reverse engineered openly and the OEM baseboards (Dell, Supermicro mainly) are still hideously expensive outside China.<p>I&#x27;m one of those people who finds &#x27;retro-super-computing&#x27; a cool hobby and thus the interfaces like OAM being open means that these devices may actually have a life for hobbyists in 8~10 years instead of being sent directly to the bins due to secret interfaces and obfuscated backplane specifications.</div><br/><div id="39987013" class="c"><input type="checkbox" id="c-39987013" checked=""/><div class="controls bullet"><span class="by">kkielhofner</span><span>|</span><a href="#39983624">parent</a><span>|</span><a href="#39983722">next</a><span>|</span><label class="collapse" for="c-39987013">[-]</label><label class="expand" for="c-39987013">[4 more]</label></div><br/><div class="children"><div class="content">Pascal series are cheap because they are CUDA compute capability 6.0 and lack Tensor Cores. Volta (7.0) was the first to have Tensor Cores and in many cases is the bare minimum for modern&#x2F;current stacks.<p>See flash attention, triton, etc as core enabling libraries. Not to mention all of the custom CUDA kernels all over the place. Take all of this and then stack layers on top of them...<p>Unfortunately there is famously &quot;GPU poor vs GPU rich&quot;. Pascal puts you at &quot;GPU destitute&quot; (regardless of assembled VRAM) and outside of implementations like llama.cpp that go incredible and impressive lengths to support these old archs you will very quickly run into show-stopping issues that make you wish you just handed over the money for &gt;= 7.0.<p>I support any use of old hardware but this kind of reminds me of my &quot;ancient&quot; X5690 that has impressive performance (relatively speaking) but always bites me because it doesn&#x27;t have AVX.</div><br/><div id="39987432" class="c"><input type="checkbox" id="c-39987432" checked=""/><div class="controls bullet"><span class="by">mk_stjames</span><span>|</span><a href="#39983624">root</a><span>|</span><a href="#39987013">parent</a><span>|</span><a href="#39987308">next</a><span>|</span><label class="collapse" for="c-39987432">[-]</label><label class="expand" for="c-39987432">[2 more]</label></div><br/><div class="children"><div class="content">This is all very true for Machine-Learning research tasks, were yes, if you want that latest PyTorch library function to work you need to be on the latest ML code.<p>But my work&#x2F;fun is in CFD.  One of the main codes I use for work was written to be supported primarily at the time of Pascal.  Other HPC stuff too that can be run via OpenCL, and is still plenty compatible.  Things compiled back then will still run today; It&#x27;s not a moving target like ML has been.</div><br/><div id="39988002" class="c"><input type="checkbox" id="c-39988002" checked=""/><div class="controls bullet"><span class="by">kkielhofner</span><span>|</span><a href="#39983624">root</a><span>|</span><a href="#39987432">parent</a><span>|</span><a href="#39987308">next</a><span>|</span><label class="collapse" for="c-39988002">[-]</label><label class="expand" for="c-39988002">[1 more]</label></div><br/><div class="children"><div class="content">Exactly. Demand for FP64 is significantly lower than for ML&#x2F;AI.<p>Pascal isn’t incredibly cheap by comparison because it’s some secret hack. It’s cheap by comparison because most of the market (AI&#x2F;ML) doesn’t want it. Speaking of which…<p>At the risk of “No True Scotsman” what qualifies as HPC gets interesting but just today I was at a Top500 site that was talking about their Volta system not being worth the power, which is relevant to parent comment but still problematic for reasons.<p>I mentioned llama.cpp because the &#x2F;r&#x2F;locallama crowd, etc has actually driven up the cost of used Pascal hardware because they treat it as a path to get VRAM on the cheap with their very very narrow use cases.<p>If we’re talking about getting a little FP64 for CFD that’s one thing. ML&#x2F;AI is another. HPC is yet another.</div><br/></div></div></div></div><div id="39987308" class="c"><input type="checkbox" id="c-39987308" checked=""/><div class="controls bullet"><span class="by">gymbeaux</span><span>|</span><a href="#39983624">root</a><span>|</span><a href="#39987013">parent</a><span>|</span><a href="#39987432">prev</a><span>|</span><a href="#39983722">next</a><span>|</span><label class="collapse" for="c-39987308">[-]</label><label class="expand" for="c-39987308">[1 more]</label></div><br/><div class="children"><div class="content">Hey that’s not fair, the X5690 is VERY efficient… at heating a home in the winter time.</div><br/></div></div></div></div><div id="39983722" class="c"><input type="checkbox" id="c-39983722" checked=""/><div class="controls bullet"><span class="by">JonChesterfield</span><span>|</span><a href="#39983624">parent</a><span>|</span><a href="#39987013">prev</a><span>|</span><a href="#39987345">next</a><span>|</span><label class="collapse" for="c-39983722">[-]</label><label class="expand" for="c-39983722">[4 more]</label></div><br/><div class="children"><div class="content">I really like this side to AMD. There&#x27;s a strategic call somewhere high up to bias towards collaboration with other companies. Sharing the fabric specifications with broadcom was an amazing thing to see. It&#x27;s not out of the question that we&#x27;ll see single chips with chiplets made by different companies attached together.</div><br/><div id="39985266" class="c"><input type="checkbox" id="c-39985266" checked=""/><div class="controls bullet"><span class="by">01HNNWZ0MV43FF</span><span>|</span><a href="#39983624">root</a><span>|</span><a href="#39983722">parent</a><span>|</span><a href="#39985564">next</a><span>|</span><label class="collapse" for="c-39985266">[-]</label><label class="expand" for="c-39985266">[1 more]</label></div><br/><div class="children"><div class="content">Maybe they feel threatened by ARM on mobile and Intel on desktop &#x2F; server. Companies that think they&#x27;re first try to monopolize. Companies that think they&#x27;re second try to cooperate.</div><br/></div></div><div id="39985564" class="c"><input type="checkbox" id="c-39985564" checked=""/><div class="controls bullet"><span class="by">rhelz</span><span>|</span><a href="#39983624">root</a><span>|</span><a href="#39983722">parent</a><span>|</span><a href="#39985266">prev</a><span>|</span><a href="#39987345">next</a><span>|</span><label class="collapse" for="c-39985564">[-]</label><label class="expand" for="c-39985564">[2 more]</label></div><br/><div class="children"><div class="content">Well, lets not forget, AMD is AMD because they reverse-engineered Intel chips....</div><br/><div id="39988371" class="c"><input type="checkbox" id="c-39988371" checked=""/><div class="controls bullet"><span class="by">treprinum</span><span>|</span><a href="#39983624">root</a><span>|</span><a href="#39985564">parent</a><span>|</span><a href="#39987345">next</a><span>|</span><label class="collapse" for="c-39988371">[-]</label><label class="expand" for="c-39988371">[1 more]</label></div><br/><div class="children"><div class="content">IBM didn&#x27;t want to rely solely on Intel when introducing PCs so it forced Intel to share its arch with another manufacturer that turned out to be AMD. It&#x27;s not like AMD stole it. Math coprocessor was in turn invented by AMD (Am9511, Am9512) and licensed by Intel (8231, 8232).</div><br/></div></div></div></div></div></div><div id="39987345" class="c"><input type="checkbox" id="c-39987345" checked=""/><div class="controls bullet"><span class="by">gymbeaux</span><span>|</span><a href="#39983624">parent</a><span>|</span><a href="#39983722">prev</a><span>|</span><a href="#39984317">next</a><span>|</span><label class="collapse" for="c-39987345">[-]</label><label class="expand" for="c-39987345">[2 more]</label></div><br/><div class="children"><div class="content">As “humble” as NVIDIA’s CEO appears to be, NVIDIA the company (he’s been running this whole time), made decision after decision with the simple intention of killing off its competition (ATI&#x2F;AMD). Gameworks is my favorite example- essentially if you wanted a video game to look as good as possible, you needed an NVIDIA GPU. Those same games played on AMD GPUs just didn’t look as good.<p>Now that video gaming is secondary (tertiary?) to Nvidia’s revenue stream, they could give a shit which brand gamers prefer. It’s small time now. All that matters is who companies are buying their GPUs from for AI stuff. Break down that CUDA wall and it’s open-season. I wonder how they plan to stave that off. It’s only a matter of time before people get tired of writing C++ code to interface with CUDA.</div><br/></div></div><div id="39984317" class="c"><input type="checkbox" id="c-39984317" checked=""/><div class="controls bullet"><span class="by">buildbot</span><span>|</span><a href="#39983624">parent</a><span>|</span><a href="#39987345">prev</a><span>|</span><a href="#39986666">next</a><span>|</span><label class="collapse" for="c-39984317">[-]</label><label class="expand" for="c-39984317">[5 more]</label></div><br/><div class="children"><div class="content">The SXM2 interface is actually publicly documented! There is an open compute spec for a 8-way baseboard. You can find the pinouts there.</div><br/><div id="39985840" class="c"><input type="checkbox" id="c-39985840" checked=""/><div class="controls bullet"><span class="by">mk_stjames</span><span>|</span><a href="#39983624">root</a><span>|</span><a href="#39984317">parent</a><span>|</span><a href="#39984820">next</a><span>|</span><label class="collapse" for="c-39985840">[-]</label><label class="expand" for="c-39985840">[3 more]</label></div><br/><div class="children"><div class="content">Upon further review... I think any actual base board schematics &#x2F; pinouts touching the Nvidia hardware directly is indeed kept behind some sort of NDA or OEM license agreement and is specifically kept out of any of those documents for the Open Compute project JBOG rigs.<p>I think this is literally the impetus for their OAM spec which makes the pinout open and shareable.  Up until that, they had to keep the actual designs of the baseboards out of the public due to that part being still controlled Nvidia IP.</div><br/><div id="39987069" class="c"><input type="checkbox" id="c-39987069" checked=""/><div class="controls bullet"><span class="by">buildbot</span><span>|</span><a href="#39983624">root</a><span>|</span><a href="#39985840">parent</a><span>|</span><a href="#39984820">next</a><span>|</span><label class="collapse" for="c-39987069">[-]</label><label class="expand" for="c-39987069">[2 more]</label></div><br/><div class="children"><div class="content">Hmm interesting, I was linked to an OCP dropbox with a version that did have the connector pinouts. Maybe something someone shouldn’t have posted then…</div><br/><div id="39987708" class="c"><input type="checkbox" id="c-39987708" checked=""/><div class="controls bullet"><span class="by">IntelMiner</span><span>|</span><a href="#39983624">root</a><span>|</span><a href="#39987069">parent</a><span>|</span><a href="#39984820">next</a><span>|</span><label class="collapse" for="c-39987708">[-]</label><label class="expand" for="c-39987708">[1 more]</label></div><br/><div class="children"><div class="content">It would be a shame if such a thing were to fall off the back of a truck as they say</div><br/></div></div></div></div></div></div><div id="39984820" class="c"><input type="checkbox" id="c-39984820" checked=""/><div class="controls bullet"><span class="by">mk_stjames</span><span>|</span><a href="#39983624">root</a><span>|</span><a href="#39984317">parent</a><span>|</span><a href="#39985840">prev</a><span>|</span><a href="#39986666">next</a><span>|</span><label class="collapse" for="c-39984820">[-]</label><label class="expand" for="c-39984820">[1 more]</label></div><br/><div class="children"><div class="content">I had read their documents such as the spec for the Big Basin JBOG, where everything is documented except the actual pinouts on the base board.  Everything leading up to it and from it is there but the actual MegArray pinout connection to a single P100&#x2F;V100 I never found.<p>But maybe there was more I missed.  I&#x27;ll take another look.</div><br/></div></div></div></div><div id="39986666" class="c"><input type="checkbox" id="c-39986666" checked=""/><div class="controls bullet"><span class="by">pavelstoev</span><span>|</span><a href="#39983624">parent</a><span>|</span><a href="#39984317">prev</a><span>|</span><a href="#39983809">next</a><span>|</span><label class="collapse" for="c-39986666">[-]</label><label class="expand" for="c-39986666">[1 more]</label></div><br/><div class="children"><div class="content">Best Tflops&#x2F;$ is actually 4090, then 3090. Also L4</div><br/></div></div><div id="39983809" class="c"><input type="checkbox" id="c-39983809" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#39983624">parent</a><span>|</span><a href="#39986666">prev</a><span>|</span><a href="#39984115">next</a><span>|</span><label class="collapse" for="c-39983809">[-]</label><label class="expand" for="c-39983809">[3 more]</label></div><br/><div class="children"><div class="content">Why don&#x27;t they sell used P100 DGX&#x2F;HGX servers as a unit? Are those bare P100s only so cheap precisely because they&#x27;re useless?</div><br/><div id="39984538" class="c"><input type="checkbox" id="c-39984538" checked=""/><div class="controls bullet"><span class="by">mk_stjames</span><span>|</span><a href="#39983624">root</a><span>|</span><a href="#39983809">parent</a><span>|</span><a href="#39984115">next</a><span>|</span><label class="collapse" for="c-39984538">[-]</label><label class="expand" for="c-39984538">[2 more]</label></div><br/><div class="children"><div class="content">I have a theory some big cloud provider moved a ton of racks from SXM2 P100&#x27;s to SXM2 V100&#x27;s (those were a thing) and thus orphaned an absolute ton of P100&#x27;s without their baseboards.<p>Or, these salvage operations just stripped racks and kept the small stuff and e-waste the racks because they think it&#x27;s the more efficient use of their storage space and would be easier to sell, without thinking correctly.</div><br/><div id="39986213" class="c"><input type="checkbox" id="c-39986213" checked=""/><div class="controls bullet"><span class="by">bushbaba</span><span>|</span><a href="#39983624">root</a><span>|</span><a href="#39984538">parent</a><span>|</span><a href="#39984115">next</a><span>|</span><label class="collapse" for="c-39986213">[-]</label><label class="expand" for="c-39986213">[1 more]</label></div><br/><div class="children"><div class="content">A ton of Nvidia GPUs fry their memory over time and need to be scrapped. Lookup nvidia (A100&#x2F;H100) row remapping failure</div><br/></div></div></div></div></div></div><div id="39984115" class="c"><input type="checkbox" id="c-39984115" checked=""/><div class="controls bullet"><span class="by">formerly_proven</span><span>|</span><a href="#39983624">parent</a><span>|</span><a href="#39983809">prev</a><span>|</span><a href="#39982320">next</a><span>|</span><label class="collapse" for="c-39984115">[-]</label><label class="expand" for="c-39984115">[11 more]</label></div><br/><div class="children"><div class="content">The price is low because they’re useless (except for replacing dead cards in a DGX), if you had a 40$ PCIe AIC-to-SXM adapter, the price would go up a lot.<p>&gt; I&#x27;m one of those people who finds &#x27;retro-super-computing&#x27; a cool hobby and thus the interfaces like OAM being open means that these devices may actually have a life for hobbyists in 8~10 years instead of being sent directly to the bins due to secret interfaces and obfuscated backplane specifications.<p>Very cool hobby. It’s also unfortunate how stringent e-waste rules lead to so much perfectly fine hardware to be scrapped. And how the remainder is typically pulled apart to the board &#x2F; module level for spares. Makes it very unlikely to stumble over more or less complete-ish systems.</div><br/><div id="39984222" class="c"><input type="checkbox" id="c-39984222" checked=""/><div class="controls bullet"><span class="by">KeplerBoy</span><span>|</span><a href="#39983624">root</a><span>|</span><a href="#39984115">parent</a><span>|</span><a href="#39982320">next</a><span>|</span><label class="collapse" for="c-39984222">[-]</label><label class="expand" for="c-39984222">[10 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not sure the prices would go up that much. What would anyone buy that card for?<p>Yes, it has a decent memory bandwidth (~750 GB&#x2F;s) and it runs CUDA. But it only has 16 GB and doesn&#x27;t support tensor cores or low precision floats. It&#x27;s in a weird place.</div><br/><div id="39984265" class="c"><input type="checkbox" id="c-39984265" checked=""/><div class="controls bullet"><span class="by">trueismywork</span><span>|</span><a href="#39983624">root</a><span>|</span><a href="#39984222">parent</a><span>|</span><a href="#39985302">next</a><span>|</span><label class="collapse" for="c-39984265">[-]</label><label class="expand" for="c-39984265">[5 more]</label></div><br/><div class="children"><div class="content">Scientific computing would buy it up like hot cakes.</div><br/><div id="39984362" class="c"><input type="checkbox" id="c-39984362" checked=""/><div class="controls bullet"><span class="by">KeplerBoy</span><span>|</span><a href="#39983624">root</a><span>|</span><a href="#39984265">parent</a><span>|</span><a href="#39985302">next</a><span>|</span><label class="collapse" for="c-39984362">[-]</label><label class="expand" for="c-39984362">[4 more]</label></div><br/><div class="children"><div class="content">Only if the specific workload needs FP64 (4.5 Tflop&#x2F;s), the 9 Tflop&#x2F;s for FP32 can be had for cheap with Turing or Ampere consumer cards.<p>Still, your point stands. It&#x27;s crazy how that 2016 GPU has two thirds the FP32 power of this new 2024 unobtanium card and infinitely more FP64.</div><br/><div id="39985363" class="c"><input type="checkbox" id="c-39985363" checked=""/><div class="controls bullet"><span class="by">algo_trader</span><span>|</span><a href="#39983624">root</a><span>|</span><a href="#39984362">parent</a><span>|</span><a href="#39985302">next</a><span>|</span><label class="collapse" for="c-39985363">[-]</label><label class="expand" for="c-39985363">[3 more]</label></div><br/><div class="children"><div class="content">Somewhat off topic:<p>Is there a similar &quot;magic value card&quot; for low memory (2GB?) 8-bit LLMs?<p>Since memory is the expensive bit, surely there are low cost low memory models?</div><br/><div id="39987061" class="c"><input type="checkbox" id="c-39987061" checked=""/><div class="controls bullet"><span class="by">KeplerBoy</span><span>|</span><a href="#39983624">root</a><span>|</span><a href="#39985363">parent</a><span>|</span><a href="#39985302">next</a><span>|</span><label class="collapse" for="c-39987061">[-]</label><label class="expand" for="c-39987061">[2 more]</label></div><br/><div class="children"><div class="content">I believe that&#x27;s what tenstorrent is aiming for.</div><br/><div id="39987236" class="c"><input type="checkbox" id="c-39987236" checked=""/><div class="controls bullet"><span class="by">abdullin</span><span>|</span><a href="#39983624">root</a><span>|</span><a href="#39987061">parent</a><span>|</span><a href="#39985302">next</a><span>|</span><label class="collapse" for="c-39987236">[-]</label><label class="expand" for="c-39987236">[1 more]</label></div><br/><div class="children"><div class="content">The main offer of Tenstorrent goes into server racks and is designed to form clusters.<p>Standalone cards are more like dev kits.<p>(I’ve been tracking Tenstorrent for 3+ years and currently have Grayskull in ML test rig together with 3090)</div><br/></div></div></div></div></div></div></div></div></div></div><div id="39985302" class="c"><input type="checkbox" id="c-39985302" checked=""/><div class="controls bullet"><span class="by">jsight</span><span>|</span><a href="#39983624">root</a><span>|</span><a href="#39984222">parent</a><span>|</span><a href="#39984265">prev</a><span>|</span><a href="#39986773">next</a><span>|</span><label class="collapse" for="c-39985302">[-]</label><label class="expand" for="c-39985302">[3 more]</label></div><br/><div class="children"><div class="content">IDK, is it really that much more powerful than the P40, which is already fairly cheap?</div><br/><div id="39987454" class="c"><input type="checkbox" id="c-39987454" checked=""/><div class="controls bullet"><span class="by">mk_stjames</span><span>|</span><a href="#39983624">root</a><span>|</span><a href="#39985302">parent</a><span>|</span><a href="#39986780">next</a><span>|</span><label class="collapse" for="c-39987454">[-]</label><label class="expand" for="c-39987454">[1 more]</label></div><br/><div class="children"><div class="content">The P100 has amazing double precision (FP64) flops (due to a 1:2 FP ratio that got nixed on all other cards) and a higher memory bandwidth which made it a really standout GPU for scientific computing applications.  Computational Fluid Dynamics, etc.<p>The P40 was aimed at the image and video cloud processing market I think, and thus the GDDR ram instead of HBM, so it got more VRAM but at much less bandwidth.</div><br/></div></div><div id="39986780" class="c"><input type="checkbox" id="c-39986780" checked=""/><div class="controls bullet"><span class="by">7speter</span><span>|</span><a href="#39983624">root</a><span>|</span><a href="#39985302">parent</a><span>|</span><a href="#39987454">prev</a><span>|</span><a href="#39986773">next</a><span>|</span><label class="collapse" for="c-39986780">[-]</label><label class="expand" for="c-39986780">[1 more]</label></div><br/><div class="children"><div class="content">Well, the p40 has 24gb VRAM, which makes it the perfect hobbyist card for a llm, assuming you can keep it cool.</div><br/></div></div></div></div><div id="39986773" class="c"><input type="checkbox" id="c-39986773" checked=""/><div class="controls bullet"><span class="by">7speter</span><span>|</span><a href="#39983624">root</a><span>|</span><a href="#39984222">parent</a><span>|</span><a href="#39985302">prev</a><span>|</span><a href="#39982320">next</a><span>|</span><label class="collapse" for="c-39986773">[-]</label><label class="expand" for="c-39986773">[1 more]</label></div><br/><div class="children"><div class="content">The pci-e p100 is has 16gb vram and won’t go below 160 dollars. Prices for these things would pick up if you could put them in some sort of pcie adapter</div><br/></div></div></div></div></div></div></div></div><div id="39982320" class="c"><input type="checkbox" id="c-39982320" checked=""/><div class="controls bullet"><span class="by">kylixz</span><span>|</span><a href="#39983624">prev</a><span>|</span><a href="#39981706">next</a><span>|</span><label class="collapse" for="c-39982320">[-]</label><label class="expand" for="c-39982320">[14 more]</label></div><br/><div class="children"><div class="content">This is a bit snarky — but will Intel actually keep this product line alive for more than a few years? Having been bitten by building products around some of their non-x86 offerings where they killed good IP off and then failed to support it… I’m skeptical.<p>I truly do hope it is successful so we can have some alternative accelerators.</div><br/><div id="39982751" class="c"><input type="checkbox" id="c-39982751" checked=""/><div class="controls bullet"><span class="by">jtriangle</span><span>|</span><a href="#39982320">parent</a><span>|</span><a href="#39984696">next</a><span>|</span><label class="collapse" for="c-39982751">[-]</label><label class="expand" for="c-39982751">[2 more]</label></div><br/><div class="children"><div class="content">The real question is, how long does it actually have to hang around really? With the way this market is going, it probably only has to be supported in earnest for a few years by which point it&#x27;ll be so far obsolete that everyone who matters will have moved on.</div><br/><div id="39983777" class="c"><input type="checkbox" id="c-39983777" checked=""/><div class="controls bullet"><span class="by">AnthonyMouse</span><span>|</span><a href="#39982320">root</a><span>|</span><a href="#39982751">parent</a><span>|</span><a href="#39984696">next</a><span>|</span><label class="collapse" for="c-39983777">[-]</label><label class="expand" for="c-39983777">[1 more]</label></div><br/><div class="children"><div class="content">We&#x27;re talking about the architecture, not the hardware model. What people want is to have a new, faster version in a few years that will run the same code written for this one.<p>Also, hardware has a lifecycle. At some point the old hardware isn&#x27;t worth running in a large scale operation because it consumes more in electricity to run 24&#x2F;7 than it would cost to replace with newer hardware. But then it falls into the hands of people who aren&#x27;t going to run it 24&#x2F;7, like hobbyists and students, which as a manufacturer you still want to support because that&#x27;s how you get people to invest their time in your stuff instead of a competitor&#x27;s.</div><br/></div></div></div></div><div id="39984696" class="c"><input type="checkbox" id="c-39984696" checked=""/><div class="controls bullet"><span class="by">iamleppert</span><span>|</span><a href="#39982320">parent</a><span>|</span><a href="#39982751">prev</a><span>|</span><a href="#39985532">next</a><span>|</span><label class="collapse" for="c-39984696">[-]</label><label class="expand" for="c-39984696">[1 more]</label></div><br/><div class="children"><div class="content">Long enough for you to get in, develop some AI product, raise investment funds, and get out with your bag!</div><br/></div></div><div id="39985532" class="c"><input type="checkbox" id="c-39985532" checked=""/><div class="controls bullet"><span class="by">fourg</span><span>|</span><a href="#39982320">parent</a><span>|</span><a href="#39984696">prev</a><span>|</span><a href="#39982698">next</a><span>|</span><label class="collapse" for="c-39985532">[-]</label><label class="expand" for="c-39985532">[2 more]</label></div><br/><div class="children"><div class="content">What’s Next: Intel Gaudi 3 accelerators&#x27; momentum will be foundational for Falcon Shores, Intel’s next-generation graphics processing unit (GPU) for AI and high-performance computing (HPC). Falcon Shores will integrate the Intel Gaudi and Intel® Xe intellectual property (IP) with a single GPU programming interface built on the Intel® oneAPI specification.</div><br/><div id="39987412" class="c"><input type="checkbox" id="c-39987412" checked=""/><div class="controls bullet"><span class="by">johnchristopher</span><span>|</span><a href="#39982320">root</a><span>|</span><a href="#39985532">parent</a><span>|</span><a href="#39982698">next</a><span>|</span><label class="collapse" for="c-39987412">[-]</label><label class="expand" for="c-39987412">[1 more]</label></div><br/><div class="children"><div class="content">I can&#x27;t tell if your comment is sarcastic or genuine :). It goes to show how out of touch I am on AI hw and sw matters.<p>Yesterday I thought about installing and trying to use <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=39372159">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=39372159</a> (Reor is an open-source AI note-taking app that runs models locally.) and feed it my markdown folder but I stop midway, asking myself &quot;don&#x27;t I need some kind of powerful GPU for that ?&quot;. And now I am thinking &quot;wait, should I wait for `standard` pluggable AI computing hardware device ? Is that Intel Gaudi 3 something like that ?&quot;.</div><br/></div></div></div></div><div id="39982698" class="c"><input type="checkbox" id="c-39982698" checked=""/><div class="controls bullet"><span class="by">forkerenok</span><span>|</span><a href="#39982320">parent</a><span>|</span><a href="#39985532">prev</a><span>|</span><a href="#39983724">next</a><span>|</span><label class="collapse" for="c-39982698">[-]</label><label class="expand" for="c-39982698">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not very involved in the broader topic, but isn&#x27;t the shortage of hardware for AI-related workloads intense enough so as to grant them the benefit of the doubt?</div><br/></div></div><div id="39983724" class="c"><input type="checkbox" id="c-39983724" checked=""/><div class="controls bullet"><span class="by">astrodust</span><span>|</span><a href="#39982320">parent</a><span>|</span><a href="#39982698">prev</a><span>|</span><a href="#39983584">next</a><span>|</span><label class="collapse" for="c-39983724">[-]</label><label class="expand" for="c-39983724">[2 more]</label></div><br/><div class="children"><div class="content">I hope it pairs well with Optane modules!</div><br/><div id="39983966" class="c"><input type="checkbox" id="c-39983966" checked=""/><div class="controls bullet"><span class="by">VHRanger</span><span>|</span><a href="#39982320">root</a><span>|</span><a href="#39983724">parent</a><span>|</span><a href="#39983584">next</a><span>|</span><label class="collapse" for="c-39983966">[-]</label><label class="expand" for="c-39983966">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ll add it right next to my Xeon Phi!</div><br/></div></div></div></div><div id="39983584" class="c"><input type="checkbox" id="c-39983584" checked=""/><div class="controls bullet"><span class="by">cptskippy</span><span>|</span><a href="#39982320">parent</a><span>|</span><a href="#39983724">prev</a><span>|</span><a href="#39987427">next</a><span>|</span><label class="collapse" for="c-39983584">[-]</label><label class="expand" for="c-39983584">[1 more]</label></div><br/><div class="children"><div class="content">I think it&#x27;s a valid question.  Intel has a habit of whispering away anything that doesn&#x27;t immediately ship millions of units or that they&#x27;re contractually obligated to support.</div><br/></div></div><div id="39987427" class="c"><input type="checkbox" id="c-39987427" checked=""/><div class="controls bullet"><span class="by">gymbeaux</span><span>|</span><a href="#39982320">parent</a><span>|</span><a href="#39983584">prev</a><span>|</span><a href="#39982868">next</a><span>|</span><label class="collapse" for="c-39987427">[-]</label><label class="expand" for="c-39987427">[1 more]</label></div><br/><div class="children"><div class="content">I haven’t read the article but my first question would be “what problem is this accelerator solving?” and if the answer is simply “you can AI without Nvidia”, that’s not good enough, because that’s the pot calling the kettle black. None of these companies is “altruistic” but between the three of them I expect AMD to be the nicest to its customers. Nvidia will squeeze the most money out of theirs, and Intel will leave theirs out to dry when corporate leadership decides it’s a failure.</div><br/></div></div><div id="39982868" class="c"><input type="checkbox" id="c-39982868" checked=""/><div class="controls bullet"><span class="by">riffic</span><span>|</span><a href="#39982320">parent</a><span>|</span><a href="#39987427">prev</a><span>|</span><a href="#39981706">next</a><span>|</span><label class="collapse" for="c-39982868">[-]</label><label class="expand" for="c-39982868">[3 more]</label></div><br/><div class="children"><div class="content">Itanic was a fun era</div><br/><div id="39983592" class="c"><input type="checkbox" id="c-39983592" checked=""/><div class="controls bullet"><span class="by">cptskippy</span><span>|</span><a href="#39982320">root</a><span>|</span><a href="#39982868">parent</a><span>|</span><a href="#39981706">next</a><span>|</span><label class="collapse" for="c-39983592">[-]</label><label class="expand" for="c-39983592">[2 more]</label></div><br/><div class="children"><div class="content">Itanium only stuck around as long as it did because they were obligated to support HP.</div><br/><div id="39987436" class="c"><input type="checkbox" id="c-39987436" checked=""/><div class="controls bullet"><span class="by">pjmlp</span><span>|</span><a href="#39982320">root</a><span>|</span><a href="#39983592">parent</a><span>|</span><a href="#39981706">next</a><span>|</span><label class="collapse" for="c-39987436">[-]</label><label class="expand" for="c-39987436">[1 more]</label></div><br/><div class="children"><div class="content">Itanium only failed because AMD was allowed to come up with AMD64, Intel would have managed to push Itanium no matter what, if there were no alternatives to a 64bit compatible x86 CPU.</div><br/></div></div></div></div></div></div></div></div><div id="39981706" class="c"><input type="checkbox" id="c-39981706" checked=""/><div class="controls bullet"><span class="by">neilmovva</span><span>|</span><a href="#39982320">prev</a><span>|</span><a href="#39981777">next</a><span>|</span><label class="collapse" for="c-39981706">[-]</label><label class="expand" for="c-39981706">[25 more]</label></div><br/><div class="children"><div class="content">A bit surprised that they&#x27;re using HBM2e, which is what Nvidia A100 (80GB) used back in 2020. But Intel is using 8 stacks here, so Gaudi 3 achieves comparable total bandwidth (3.7TB&#x2F;s) to H100 (3.4TB&#x2F;s) which uses 5 stacks of HBM3. Hopefully the older HBM has better supply - HBM3 is hard to get right now!<p>The Gaudi 3 multi-chip package also looks interesting. I see 2 central compute dies, 8 HBM die stacks, and then 6 small dies interleaved between the HBM stacks - curious to know whether those are also functional, or just structural elements for mechanical support.</div><br/><div id="39982676" class="c"><input type="checkbox" id="c-39982676" checked=""/><div class="controls bullet"><span class="by">bayindirh</span><span>|</span><a href="#39981706">parent</a><span>|</span><a href="#39987297">next</a><span>|</span><label class="collapse" for="c-39982676">[-]</label><label class="expand" for="c-39982676">[23 more]</label></div><br/><div class="children"><div class="content">&gt; A bit surprised that they&#x27;re using HBM2e, which is what Nvidia A100 (80GB) used back in 2020.<p>This is one of the secret recipes of Intel. They can use older tech and push it a little further to catch&#x2F;surpass current gen tech until current gen becomes easier&#x2F;cheaper to produce&#x2F;acquire&#x2F;integrate.<p>They have done it with their first quad core processors by merging two dual core processors (Q6xxx series), or by creating absurdly clocked single core processors aimed at very niche market segments.<p>We have not seen it until now, because they were sleeping at the wheel, and knocked unconscious by AMD.</div><br/><div id="39983187" class="c"><input type="checkbox" id="c-39983187" checked=""/><div class="controls bullet"><span class="by">JonChesterfield</span><span>|</span><a href="#39981706">root</a><span>|</span><a href="#39982676">parent</a><span>|</span><a href="#39982772">next</a><span>|</span><label class="collapse" for="c-39983187">[-]</label><label class="expand" for="c-39983187">[6 more]</label></div><br/><div class="children"><div class="content">&gt; This is one of the secret recipes of Intel<p>Any other examples of this? I remember the secret sauce being a process advantage over the competition, exactly the opposite of making old tech outperform the state of the art.</div><br/><div id="39983327" class="c"><input type="checkbox" id="c-39983327" checked=""/><div class="controls bullet"><span class="by">calaphos</span><span>|</span><a href="#39981706">root</a><span>|</span><a href="#39983187">parent</a><span>|</span><a href="#39983338">next</a><span>|</span><label class="collapse" for="c-39983327">[-]</label><label class="expand" for="c-39983327">[4 more]</label></div><br/><div class="children"><div class="content">Intels surprisingly fast 14nm processors come to mind. Born of necessity as they couldn&#x27;t get their 10 and later 7nm processes working for years. Despite that Intel managed to keep up in single core performance with newer 7nm AMD chips, although at a mich higher power draw.</div><br/><div id="39984678" class="c"><input type="checkbox" id="c-39984678" checked=""/><div class="controls bullet"><span class="by">deepnotderp</span><span>|</span><a href="#39981706">root</a><span>|</span><a href="#39983327">parent</a><span>|</span><a href="#39985873">next</a><span>|</span><label class="collapse" for="c-39984678">[-]</label><label class="expand" for="c-39984678">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s because CPU performance cares less about transistor density and more about transistor performance, and 14nm drive strength was excellent</div><br/></div></div><div id="39985873" class="c"><input type="checkbox" id="c-39985873" checked=""/><div class="controls bullet"><span class="by">0x457</span><span>|</span><a href="#39981706">root</a><span>|</span><a href="#39983327">parent</a><span>|</span><a href="#39984678">prev</a><span>|</span><a href="#39983648">next</a><span>|</span><label class="collapse" for="c-39985873">[-]</label><label class="expand" for="c-39985873">[1 more]</label></div><br/><div class="children"><div class="content">For like half of 14nm intel era, there was no competition on CPU market in any segment for them. Intel was able to improve their 14nm process and be better at branch prediction. Moving things to hardware implementation is what kept improving.<p>This isn&#x27;t the same as getting more out of the same over and over again.</div><br/></div></div><div id="39983648" class="c"><input type="checkbox" id="c-39983648" checked=""/><div class="controls bullet"><span class="by">Dalewyn</span><span>|</span><a href="#39981706">root</a><span>|</span><a href="#39983327">parent</a><span>|</span><a href="#39985873">prev</a><span>|</span><a href="#39983338">next</a><span>|</span><label class="collapse" for="c-39983648">[-]</label><label class="expand" for="c-39983648">[1 more]</label></div><br/><div class="children"><div class="content">Or today with Alder Lake and Raptor Lake(Refresh), where their CPUs made on Intel 7 (10nm) are on par if not slightly better than AMD&#x27;s offerings made on TSMC 5nm.</div><br/></div></div></div></div><div id="39983338" class="c"><input type="checkbox" id="c-39983338" checked=""/><div class="controls bullet"><span class="by">timr</span><span>|</span><a href="#39981706">root</a><span>|</span><a href="#39983187">parent</a><span>|</span><a href="#39983327">prev</a><span>|</span><a href="#39982772">next</a><span>|</span><label class="collapse" for="c-39983338">[-]</label><label class="expand" for="c-39983338">[1 more]</label></div><br/><div class="children"><div class="content">Back in the day, Intel was great for overclocking because all of their chips could run at <i>significantly</i> higher speeds and voltages than on the tin. This was because they basically just targeted the higher specs, and sold the underperforming silicon as lower-tier products.<p>Don&#x27;t know if this counts, but feels directionally similar.</div><br/></div></div></div></div><div id="39982772" class="c"><input type="checkbox" id="c-39982772" checked=""/><div class="controls bullet"><span class="by">mvkel</span><span>|</span><a href="#39981706">root</a><span>|</span><a href="#39982676">parent</a><span>|</span><a href="#39983187">prev</a><span>|</span><a href="#39983000">next</a><span>|</span><label class="collapse" for="c-39982772">[-]</label><label class="expand" for="c-39982772">[4 more]</label></div><br/><div class="children"><div class="content">Interesting.<p>Would you say this means Intel is &quot;back,&quot; or just not completely dead?</div><br/><div id="39983009" class="c"><input type="checkbox" id="c-39983009" checked=""/><div class="controls bullet"><span class="by">bayindirh</span><span>|</span><a href="#39981706">root</a><span>|</span><a href="#39982772">parent</a><span>|</span><a href="#39983000">next</a><span>|</span><label class="collapse" for="c-39983009">[-]</label><label class="expand" for="c-39983009">[3 more]</label></div><br/><div class="children"><div class="content">No, this means Intel has woken up and trying. There&#x27;s no guarantee in anything. I&#x27;m more of an AMD person, but I want to see fierce competition, not monopoly, even if it&#x27;s &quot;my team&#x27;s monopoly&quot;.</div><br/><div id="39983384" class="c"><input type="checkbox" id="c-39983384" checked=""/><div class="controls bullet"><span class="by">chucke1992</span><span>|</span><a href="#39981706">root</a><span>|</span><a href="#39983009">parent</a><span>|</span><a href="#39983000">next</a><span>|</span><label class="collapse" for="c-39983384">[-]</label><label class="expand" for="c-39983384">[2 more]</label></div><br/><div class="children"><div class="content">Well the only reason why AMD is doing good at CPU is becoming Intel is sleeping. Otherwise it would be Nvidia vs AMD (less steroids though).</div><br/><div id="39983604" class="c"><input type="checkbox" id="c-39983604" checked=""/><div class="controls bullet"><span class="by">bayindirh</span><span>|</span><a href="#39981706">root</a><span>|</span><a href="#39983384">parent</a><span>|</span><a href="#39983000">next</a><span>|</span><label class="collapse" for="c-39983604">[-]</label><label class="expand" for="c-39983604">[1 more]</label></div><br/><div class="children"><div class="content">EPYC is actually pretty good. It’s true that Intel was sleeping, but AMD’s new architecture is a beast. Has better memory support, more PCIe lanes and better overall system latency and throughput.<p>Intel’s TDP problems and AVX clock issues leave a bitter taste in the mouth.</div><br/></div></div></div></div></div></div></div></div><div id="39983000" class="c"><input type="checkbox" id="c-39983000" checked=""/><div class="controls bullet"><span class="by">alexey-salmin</span><span>|</span><a href="#39981706">root</a><span>|</span><a href="#39982676">parent</a><span>|</span><a href="#39982772">prev</a><span>|</span><a href="#39987297">next</a><span>|</span><label class="collapse" for="c-39983000">[-]</label><label class="expand" for="c-39983000">[12 more]</label></div><br/><div class="children"><div class="content">Oh dear, Q6600 was so bad, I regret ever owning it</div><br/><div id="39983376" class="c"><input type="checkbox" id="c-39983376" checked=""/><div class="controls bullet"><span class="by">chucke1992</span><span>|</span><a href="#39981706">root</a><span>|</span><a href="#39983000">parent</a><span>|</span><a href="#39983174">next</a><span>|</span><label class="collapse" for="c-39983376">[-]</label><label class="expand" for="c-39983376">[5 more]</label></div><br/><div class="children"><div class="content">Q6600 was quite good but E8400 was the best.</div><br/><div id="39983743" class="c"><input type="checkbox" id="c-39983743" checked=""/><div class="controls bullet"><span class="by">astrodust</span><span>|</span><a href="#39981706">root</a><span>|</span><a href="#39983376">parent</a><span>|</span><a href="#39983519">next</a><span>|</span><label class="collapse" for="c-39983743">[-]</label><label class="expand" for="c-39983743">[3 more]</label></div><br/><div class="children"><div class="content">Q6600 is the spiritual successor to the ABIT BP6 Dual Celeron option: <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;ABIT_BP6" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;ABIT_BP6</a></div><br/><div id="39986622" class="c"><input type="checkbox" id="c-39986622" checked=""/><div class="controls bullet"><span class="by">dfex</span><span>|</span><a href="#39981706">root</a><span>|</span><a href="#39983743">parent</a><span>|</span><a href="#39984261">next</a><span>|</span><label class="collapse" for="c-39986622">[-]</label><label class="expand" for="c-39986622">[1 more]</label></div><br/><div class="children"><div class="content">The ABit BP6 bought me so much &quot;cred&quot; at LAN Parties back in the day - the only dual socket motherboard in the building, and paired with two Creative Voodoo 2 GPUs in SLI mode, that thing was a beast (for the late nineties).<p>I seem to recall that only Quake 2 or 3 was capable of actually using that second processor during a game, but that wasn&#x27;t the point ;)</div><br/></div></div><div id="39984261" class="c"><input type="checkbox" id="c-39984261" checked=""/><div class="controls bullet"><span class="by">bayindirh</span><span>|</span><a href="#39981706">root</a><span>|</span><a href="#39983743">parent</a><span>|</span><a href="#39986622">prev</a><span>|</span><a href="#39983519">next</a><span>|</span><label class="collapse" for="c-39984261">[-]</label><label class="expand" for="c-39984261">[1 more]</label></div><br/><div class="children"><div class="content">ABIT was a legend in motherboards. I used their AN-7 Ultra and AN-8 Ultra. No newer board gave the flexibility and capabilities of these series.<p>My latest ASUS was good enough, but I didn&#x27;t (and probably won&#x27;t) build any newer systems, so ABITs will have the crown.</div><br/></div></div></div></div><div id="39983519" class="c"><input type="checkbox" id="c-39983519" checked=""/><div class="controls bullet"><span class="by">alexey-salmin</span><span>|</span><a href="#39981706">root</a><span>|</span><a href="#39983376">parent</a><span>|</span><a href="#39983743">prev</a><span>|</span><a href="#39983174">next</a><span>|</span><label class="collapse" for="c-39983519">[-]</label><label class="expand" for="c-39983519">[1 more]</label></div><br/><div class="children"><div class="content">E8400 was actually good, yes</div><br/></div></div></div></div><div id="39983174" class="c"><input type="checkbox" id="c-39983174" checked=""/><div class="controls bullet"><span class="by">mrybczyn</span><span>|</span><a href="#39981706">root</a><span>|</span><a href="#39983000">parent</a><span>|</span><a href="#39983376">prev</a><span>|</span><a href="#39983254">next</a><span>|</span><label class="collapse" for="c-39983174">[-]</label><label class="expand" for="c-39983174">[2 more]</label></div><br/><div class="children"><div class="content">What?  It was outstanding for the time, great price performance, and very tunable for clock &#x2F; voltage IIRC.</div><br/><div id="39983630" class="c"><input type="checkbox" id="c-39983630" checked=""/><div class="controls bullet"><span class="by">alexey-salmin</span><span>|</span><a href="#39981706">root</a><span>|</span><a href="#39983174">parent</a><span>|</span><a href="#39983254">next</a><span>|</span><label class="collapse" for="c-39983630">[-]</label><label class="expand" for="c-39983630">[1 more]</label></div><br/><div class="children"><div class="content">Well overclocked I don&#x27;t know, but out-of-the box single-core performance completely sucked. And in 2007 not enough applications had threads to make it up in the number of cores.<p>It was fun to play with but you&#x27;d also expect the higher-end desktop to e.g. handle x264 videos which was not the case (search for q6600 on videolan forum). And depressingly many cheaper CPUs of the time did it easily.</div><br/></div></div></div></div><div id="39983254" class="c"><input type="checkbox" id="c-39983254" checked=""/><div class="controls bullet"><span class="by">bayindirh</span><span>|</span><a href="#39981706">root</a><span>|</span><a href="#39983000">parent</a><span>|</span><a href="#39983174">prev</a><span>|</span><a href="#39983203">next</a><span>|</span><label class="collapse" for="c-39983254">[-]</label><label class="expand" for="c-39983254">[1 more]</label></div><br/><div class="children"><div class="content">I owned one, it was a performant little chip. Developed my first multi core stuff with it.<p>I loved it, to be honest.</div><br/></div></div><div id="39983203" class="c"><input type="checkbox" id="c-39983203" checked=""/><div class="controls bullet"><span class="by">JonChesterfield</span><span>|</span><a href="#39981706">root</a><span>|</span><a href="#39983000">parent</a><span>|</span><a href="#39983254">prev</a><span>|</span><a href="#39983063">next</a><span>|</span><label class="collapse" for="c-39983203">[-]</label><label class="expand" for="c-39983203">[1 more]</label></div><br/><div class="children"><div class="content">65nm tolerated a lot of voltage. Fun thing to overclock.</div><br/></div></div><div id="39983063" class="c"><input type="checkbox" id="c-39983063" checked=""/><div class="controls bullet"><span class="by">PcChip</span><span>|</span><a href="#39981706">root</a><span>|</span><a href="#39983000">parent</a><span>|</span><a href="#39983203">prev</a><span>|</span><a href="#39987297">next</a><span>|</span><label class="collapse" for="c-39983063">[-]</label><label class="expand" for="c-39983063">[2 more]</label></div><br/><div class="children"><div class="content">Really? I never owned one but even I remember the famous SLACR, I thought they were the hot item back then</div><br/><div id="39983652" class="c"><input type="checkbox" id="c-39983652" checked=""/><div class="controls bullet"><span class="by">alexey-salmin</span><span>|</span><a href="#39981706">root</a><span>|</span><a href="#39983063">parent</a><span>|</span><a href="#39987297">next</a><span>|</span><label class="collapse" for="c-39983652">[-]</label><label class="expand" for="c-39983652">[1 more]</label></div><br/><div class="children"><div class="content">It was &quot;hot&quot; but using one as a main desktop in 2007 was depressing due to abysmal single-core performance.</div><br/></div></div></div></div></div></div></div></div><div id="39987297" class="c"><input type="checkbox" id="c-39987297" checked=""/><div class="controls bullet"><span class="by">tmikaeld</span><span>|</span><a href="#39981706">parent</a><span>|</span><a href="#39982676">prev</a><span>|</span><a href="#39981777">next</a><span>|</span><label class="collapse" for="c-39987297">[-]</label><label class="expand" for="c-39987297">[1 more]</label></div><br/><div class="children"><div class="content">I was just about to comment on this, apparently all production capacity for hbm is tapped out until early 2026</div><br/></div></div></div></div><div id="39981777" class="c"><input type="checkbox" id="c-39981777" checked=""/><div class="controls bullet"><span class="by">sairahul82</span><span>|</span><a href="#39981706">prev</a><span>|</span><a href="#39981814">next</a><span>|</span><label class="collapse" for="c-39981777">[-]</label><label class="expand" for="c-39981777">[15 more]</label></div><br/><div class="children"><div class="content">Can we expect the price of &#x27;Gaudi 3 PCIe&#x27; to be reasonable enough to put in a workstation? That would be a game changer for local LLMs</div><br/><div id="39982006" class="c"><input type="checkbox" id="c-39982006" checked=""/><div class="controls bullet"><span class="by">wongarsu</span><span>|</span><a href="#39981777">parent</a><span>|</span><a href="#39981922">next</a><span>|</span><label class="collapse" for="c-39982006">[-]</label><label class="expand" for="c-39982006">[12 more]</label></div><br/><div class="children"><div class="content">Probably not. An 40GB Nvidia A100 is arguably reasonable for a workstation at $6000. Depending on your definition an 80GB A100 for $16000 is still reasonable. I don&#x27;t see this being cheaper than an 80GB A100. Probably a good bit more expensive, seeing as it has more RAM, compares itself favorably to the H100, and has enough compelling features that it probably doesn&#x27;t have to (strongly) compete on price.</div><br/><div id="39982587" class="c"><input type="checkbox" id="c-39982587" checked=""/><div class="controls bullet"><span class="by">0cf8612b2e1e</span><span>|</span><a href="#39981777">root</a><span>|</span><a href="#39982006">parent</a><span>|</span><a href="#39984622">next</a><span>|</span><label class="collapse" for="c-39982587">[-]</label><label class="expand" for="c-39982587">[4 more]</label></div><br/><div class="children"><div class="content">Surely NVidia’s pricing is more what the market will bear vs an intrinsic cost to build. Intel being the underdog should be willing to offer a discount just to get their foot in the door.</div><br/><div id="39982620" class="c"><input type="checkbox" id="c-39982620" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#39981777">root</a><span>|</span><a href="#39982587">parent</a><span>|</span><a href="#39983463">next</a><span>|</span><label class="collapse" for="c-39982620">[-]</label><label class="expand" for="c-39982620">[1 more]</label></div><br/><div class="children"><div class="content">Nvidia is charging $35K so a discount relative to that is still very expensive.</div><br/></div></div><div id="39983463" class="c"><input type="checkbox" id="c-39983463" checked=""/><div class="controls bullet"><span class="by">tormeh</span><span>|</span><a href="#39981777">root</a><span>|</span><a href="#39982587">parent</a><span>|</span><a href="#39982620">prev</a><span>|</span><a href="#39984622">next</a><span>|</span><label class="collapse" for="c-39983463">[-]</label><label class="expand" for="c-39983463">[2 more]</label></div><br/><div class="children"><div class="content">Pricing is normally what the market will bear. If this is below your cost as supplier you exit the market.</div><br/><div id="39983876" class="c"><input type="checkbox" id="c-39983876" checked=""/><div class="controls bullet"><span class="by">AnthonyMouse</span><span>|</span><a href="#39981777">root</a><span>|</span><a href="#39983463">parent</a><span>|</span><a href="#39984622">next</a><span>|</span><label class="collapse" for="c-39983876">[-]</label><label class="expand" for="c-39983876">[1 more]</label></div><br/><div class="children"><div class="content">But if your competitor&#x27;s price is dramatically <i>above</i> your cost, you can provide a huge discount as an incentive for customers to pay the transition cost to your system while still turning a tidy profit.</div><br/></div></div></div></div></div></div><div id="39984622" class="c"><input type="checkbox" id="c-39984622" checked=""/><div class="controls bullet"><span class="by">narrator</span><span>|</span><a href="#39981777">root</a><span>|</span><a href="#39982006">parent</a><span>|</span><a href="#39982587">prev</a><span>|</span><a href="#39982306">next</a><span>|</span><label class="collapse" for="c-39984622">[-]</label><label class="expand" for="c-39984622">[3 more]</label></div><br/><div class="children"><div class="content">Isn&#x27;t it much better to get a Mac Studio with an M2 Max and 192gb of Ram and 31 terraflops for $6599 and run llama.cpp?</div><br/><div id="39985652" class="c"><input type="checkbox" id="c-39985652" checked=""/><div class="controls bullet"><span class="by">magic_hamster</span><span>|</span><a href="#39981777">root</a><span>|</span><a href="#39984622">parent</a><span>|</span><a href="#39982306">next</a><span>|</span><label class="collapse" for="c-39985652">[-]</label><label class="expand" for="c-39985652">[2 more]</label></div><br/><div class="children"><div class="content">Macs don&#x27;t support CUDA which means all that wonderful hardware will be useless when trying to do anything with AI for at least a few years. There&#x27;s Metal but it has its own set of problems, biggest one being it isn&#x27;t a drop in CUDA replacement.</div><br/><div id="39986640" class="c"><input type="checkbox" id="c-39986640" checked=""/><div class="controls bullet"><span class="by">doublepg23</span><span>|</span><a href="#39981777">root</a><span>|</span><a href="#39985652">parent</a><span>|</span><a href="#39982306">next</a><span>|</span><label class="collapse" for="c-39986640">[-]</label><label class="expand" for="c-39986640">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m assuming this won&#x27;t support CUDA either?</div><br/></div></div></div></div></div></div><div id="39982306" class="c"><input type="checkbox" id="c-39982306" checked=""/><div class="controls bullet"><span class="by">chessgecko</span><span>|</span><a href="#39981777">root</a><span>|</span><a href="#39982006">parent</a><span>|</span><a href="#39984622">prev</a><span>|</span><a href="#39982327">next</a><span>|</span><label class="collapse" for="c-39982306">[-]</label><label class="expand" for="c-39982306">[3 more]</label></div><br/><div class="children"><div class="content">I think you&#x27;re right on the price, but just to give some false hope. I think newish hbm (and this is hbm2e which is a little older) is around $15&#x2F;gb so for 128 gb thats $1920. There are some other cogs, but in theory they could sell this for like $3-4k and make some gross profit while getting some hobbyist mindshare&#x2F;research code written for it.
I doubt they will though, it might eat too much into profits from the non pcie variants.</div><br/><div id="39984499" class="c"><input type="checkbox" id="c-39984499" checked=""/><div class="controls bullet"><span class="by">p1esk</span><span>|</span><a href="#39981777">root</a><span>|</span><a href="#39982306">parent</a><span>|</span><a href="#39982327">next</a><span>|</span><label class="collapse" for="c-39984499">[-]</label><label class="expand" for="c-39984499">[2 more]</label></div><br/><div class="children"><div class="content"><i>in theory they could sell this for like $3-4k</i><p>You’re joking, right? They will price it to match current H100 pricing. Multiply your estimate by 10x.</div><br/><div id="39984890" class="c"><input type="checkbox" id="c-39984890" checked=""/><div class="controls bullet"><span class="by">chessgecko</span><span>|</span><a href="#39981777">root</a><span>|</span><a href="#39984499">parent</a><span>|</span><a href="#39982327">next</a><span>|</span><label class="collapse" for="c-39984890">[-]</label><label class="expand" for="c-39984890">[1 more]</label></div><br/><div class="children"><div class="content">They could, I know they wont, but they wouldn&#x27;t lose money on the parts</div><br/></div></div></div></div></div></div><div id="39982327" class="c"><input type="checkbox" id="c-39982327" checked=""/><div class="controls bullet"><span class="by">Workaccount2</span><span>|</span><a href="#39981777">root</a><span>|</span><a href="#39982006">parent</a><span>|</span><a href="#39982306">prev</a><span>|</span><a href="#39981922">next</a><span>|</span><label class="collapse" for="c-39982327">[-]</label><label class="expand" for="c-39982327">[1 more]</label></div><br/><div class="children"><div class="content">Interestingly they are using HBME2 memory which is a few years old at this point. The price might end up being surprisingly good because of this.</div><br/></div></div></div></div><div id="39981922" class="c"><input type="checkbox" id="c-39981922" checked=""/><div class="controls bullet"><span class="by">CuriouslyC</span><span>|</span><a href="#39981777">parent</a><span>|</span><a href="#39982006">prev</a><span>|</span><a href="#39984876">next</a><span>|</span><label class="collapse" for="c-39981922">[-]</label><label class="expand" for="c-39981922">[1 more]</label></div><br/><div class="children"><div class="content">Just based on the RAM alone, let&#x27;s just say if you can&#x27;t just buy a Vision Pro without a second thought about the price tag, don&#x27;t get your hopes up.</div><br/></div></div><div id="39984876" class="c"><input type="checkbox" id="c-39984876" checked=""/><div class="controls bullet"><span class="by">ipsum2</span><span>|</span><a href="#39981777">parent</a><span>|</span><a href="#39981922">prev</a><span>|</span><a href="#39981814">next</a><span>|</span><label class="collapse" for="c-39984876">[-]</label><label class="expand" for="c-39984876">[1 more]</label></div><br/><div class="children"><div class="content">It won&#x27;t be under $10k.</div><br/></div></div></div></div><div id="39981814" class="c"><input type="checkbox" id="c-39981814" checked=""/><div class="controls bullet"><span class="by">kaycebasques</span><span>|</span><a href="#39981777">prev</a><span>|</span><a href="#39981543">next</a><span>|</span><label class="collapse" for="c-39981814">[-]</label><label class="expand" for="c-39981814">[2 more]</label></div><br/><div class="children"><div class="content">Wow, I very much appreciate the use of the 5 Ws and H [1] in this announcement. Thank you Intel for not subjecting my eyes to corp BS<p>[1] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Five_Ws" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Five_Ws</a></div><br/><div id="39982161" class="c"><input type="checkbox" id="c-39982161" checked=""/><div class="controls bullet"><span class="by">belval</span><span>|</span><a href="#39981814">parent</a><span>|</span><a href="#39981543">next</a><span>|</span><label class="collapse" for="c-39982161">[-]</label><label class="expand" for="c-39982161">[1 more]</label></div><br/><div class="children"><div class="content">I wonder if with the advent of LLMs being able to spit out perfect corpo-speak everyone will recenter to succint and short &quot;here&#x27;s the gist&quot; as the long version will become associated to cheap automated output.</div><br/></div></div></div></div><div id="39981543" class="c"><input type="checkbox" id="c-39981543" checked=""/><div class="controls bullet"><span class="by">rileyphone</span><span>|</span><a href="#39981814">prev</a><span>|</span><a href="#39981644">next</a><span>|</span><label class="collapse" for="c-39981543">[-]</label><label class="expand" for="c-39981543">[37 more]</label></div><br/><div class="children"><div class="content">128GB in one chip seems important with the rise of sparse architectures like MoE. Hopefully these are competitive with Nvidia&#x27;s offerings, though in the end they will be competing for the same fab space as Nvidia if I&#x27;m not mistaken.</div><br/><div id="39981650" class="c"><input type="checkbox" id="c-39981650" checked=""/><div class="controls bullet"><span class="by">latchkey</span><span>|</span><a href="#39981543">parent</a><span>|</span><a href="#39981644">next</a><span>|</span><label class="collapse" for="c-39981650">[-]</label><label class="expand" for="c-39981650">[36 more]</label></div><br/><div class="children"><div class="content">AMD MI300x is 192GB.</div><br/><div id="39981755" class="c"><input type="checkbox" id="c-39981755" checked=""/><div class="controls bullet"><span class="by">tucnak</span><span>|</span><a href="#39981543">root</a><span>|</span><a href="#39981650">parent</a><span>|</span><a href="#39981644">next</a><span>|</span><label class="collapse" for="c-39981755">[-]</label><label class="expand" for="c-39981755">[35 more]</label></div><br/><div class="children"><div class="content">Which would be impressive had it _actually_ worked for ML workloads.</div><br/><div id="39982289" class="c"><input type="checkbox" id="c-39982289" checked=""/><div class="controls bullet"><span class="by">huac</span><span>|</span><a href="#39981543">root</a><span>|</span><a href="#39981755">parent</a><span>|</span><a href="#39981847">next</a><span>|</span><label class="collapse" for="c-39982289">[-]</label><label class="expand" for="c-39982289">[2 more]</label></div><br/><div class="children"><div class="content">There&#x27;s a number of scaled AMD deployments, including Lamini (<a href="https:&#x2F;&#x2F;www.lamini.ai&#x2F;blog&#x2F;lamini-amd-paving-the-road-to-gpu-rich-enterprise-llms" rel="nofollow">https:&#x2F;&#x2F;www.lamini.ai&#x2F;blog&#x2F;lamini-amd-paving-the-road-to-gpu...</a>) specifically for LLM&#x27;s. There&#x27;s also a number of HPC configurations, including the world&#x27;s largest publicly disclosed supercomputer (Frontier) and Europe&#x27;s largest supercomputer (LUMI) running on MI250x. Multiple teams have trained models on those HPC setups too.<p>Do you have any more evidence as to why these categorically don&#x27;t work?</div><br/><div id="39982976" class="c"><input type="checkbox" id="c-39982976" checked=""/><div class="controls bullet"><span class="by">latchkey</span><span>|</span><a href="#39981543">root</a><span>|</span><a href="#39982289">parent</a><span>|</span><a href="#39981847">next</a><span>|</span><label class="collapse" for="c-39982976">[-]</label><label class="expand" for="c-39982976">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>Do you have any more evidence as to why these categorically don&#x27;t work?</i><p>They don&#x27;t. Loud voices parroting George, with nothing to back it up.<p>Here are another couple good links:<p><a href="https:&#x2F;&#x2F;www.evp.cloud&#x2F;post&#x2F;diving-deeper-insights-from-our-llm-inference-testing" rel="nofollow">https:&#x2F;&#x2F;www.evp.cloud&#x2F;post&#x2F;diving-deeper-insights-from-our-l...</a><p><a href="https:&#x2F;&#x2F;www.databricks.com&#x2F;blog&#x2F;training-llms-scale-amd-mi250-gpus" rel="nofollow">https:&#x2F;&#x2F;www.databricks.com&#x2F;blog&#x2F;training-llms-scale-amd-mi25...</a></div><br/></div></div></div></div><div id="39981847" class="c"><input type="checkbox" id="c-39981847" checked=""/><div class="controls bullet"><span class="by">Hugsun</span><span>|</span><a href="#39981543">root</a><span>|</span><a href="#39981755">parent</a><span>|</span><a href="#39982289">prev</a><span>|</span><a href="#39981644">next</a><span>|</span><label class="collapse" for="c-39981847">[-]</label><label class="expand" for="c-39981847">[32 more]</label></div><br/><div class="children"><div class="content">Does it not work for them? Where can I learn why?</div><br/><div id="39982050" class="c"><input type="checkbox" id="c-39982050" checked=""/><div class="controls bullet"><span class="by">tucnak</span><span>|</span><a href="#39981543">root</a><span>|</span><a href="#39981847">parent</a><span>|</span><a href="#39981644">next</a><span>|</span><label class="collapse" for="c-39982050">[-]</label><label class="expand" for="c-39982050">[31 more]</label></div><br/><div class="children"><div class="content">Just go have a look around Github issues in their ROCm repositories on Github. A few months back the top excuse re: AMD was that we&#x27;re not supposed to use their &quot;consumer&quot; cards, however the datacenter stuff is kosher. Well, guess what, we have purchased their datacenter card, MI50, and it&#x27;s similarly screwed. Too many bugs in the kernel, kernel crashes, hangs, and the ROCm code is buggy &#x2F; incomplete. When it works, it works for a short period of time, and yes HBM memory is kind of nice, but the whole thing is not worth it. Some say MI210 and MI300 are better, but it&#x27;s just wishful thinking as all the bugs are in the software, kernel driver, and firmware. I have spent too many hours troubleshooting entry-level datacenter-grade Instinct cards with no recourse from AMD whatsoever to pay 10+ thousands for MI210 a couple-year old underpowered hardware, and MI300 is just unavailable.<p>Not even from cloud providers which should be telling enough.</div><br/><div id="39983281" class="c"><input type="checkbox" id="c-39983281" checked=""/><div class="controls bullet"><span class="by">JonChesterfield</span><span>|</span><a href="#39981543">root</a><span>|</span><a href="#39982050">parent</a><span>|</span><a href="#39982259">next</a><span>|</span><label class="collapse" for="c-39983281">[-]</label><label class="expand" for="c-39983281">[7 more]</label></div><br/><div class="children"><div class="content">We absolutely hammered the MI50 in internal testing for ages. Was solid as far as I can tell.<p>Rocm is sensitive to matching kernel version to driver version to userspace version. Staying very much on the kernel version from a official release and using the corresponding driver is drastically more robust than optimistically mixing different components. In particular, rocm is released and tested as one large blob, and running that large blob on a slightly different kernel version can go very badly. Mixing things from GitHub with things from your package manager is also optimistic.<p>Imagine it as huge ball of code where cross version compatibility of pieces is totally untested.</div><br/><div id="39983985" class="c"><input type="checkbox" id="c-39983985" checked=""/><div class="controls bullet"><span class="by">tucnak</span><span>|</span><a href="#39981543">root</a><span>|</span><a href="#39983281">parent</a><span>|</span><a href="#39982259">next</a><span>|</span><label class="collapse" for="c-39983985">[-]</label><label class="expand" for="c-39983985">[6 more]</label></div><br/><div class="children"><div class="content">I would run simple llama.cpp batch jobs for 10 minutes when it would suddenly fail, and require a restart. Random VM_L2_PROTECTION_FAULT in dmesg, something having to do with doorbells. I did report this, never heard back from them.</div><br/><div id="39988195" class="c"><input type="checkbox" id="c-39988195" checked=""/><div class="controls bullet"><span class="by">JonChesterfield</span><span>|</span><a href="#39981543">root</a><span>|</span><a href="#39983985">parent</a><span>|</span><a href="#39987197">next</a><span>|</span><label class="collapse" for="c-39988195">[-]</label><label class="expand" for="c-39988195">[1 more]</label></div><br/><div class="children"><div class="content">Did you run on the blessed Ubuntu version with the blessed kernel version and the blessed driver version? As otherwise you really are in a development branch.<p>If you can point me to a repro I&#x27;ll add it to my todo list. You can probably tag me in the github issue if that&#x27;s where you reported it.</div><br/></div></div><div id="39987197" class="c"><input type="checkbox" id="c-39987197" checked=""/><div class="controls bullet"><span class="by">FeepingCreature</span><span>|</span><a href="#39981543">root</a><span>|</span><a href="#39983985">parent</a><span>|</span><a href="#39988195">prev</a><span>|</span><a href="#39985392">next</a><span>|</span><label class="collapse" for="c-39987197">[-]</label><label class="expand" for="c-39987197">[3 more]</label></div><br/><div class="children"><div class="content">Same here with SD on 7900XTX. Most of the time for me it&#x27;s sufficient to reset the card with rocm-smi --gpureset -d 0.</div><br/><div id="39987853" class="c"><input type="checkbox" id="c-39987853" checked=""/><div class="controls bullet"><span class="by">michaelt</span><span>|</span><a href="#39981543">root</a><span>|</span><a href="#39987197">parent</a><span>|</span><a href="#39985392">next</a><span>|</span><label class="collapse" for="c-39987853">[-]</label><label class="expand" for="c-39987853">[2 more]</label></div><br/><div class="children"><div class="content">Only &quot;most of the time&quot; ? :(<p>You&#x27;d hope at $15,000+ per unit, you wouldn&#x27;t have to reset it at all...</div><br/><div id="39988375" class="c"><input type="checkbox" id="c-39988375" checked=""/><div class="controls bullet"><span class="by">JonChesterfield</span><span>|</span><a href="#39981543">root</a><span>|</span><a href="#39987853">parent</a><span>|</span><a href="#39985392">next</a><span>|</span><label class="collapse" for="c-39988375">[-]</label><label class="expand" for="c-39988375">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s $1000 per, no? This is one of the gaming cards.</div><br/></div></div></div></div></div></div><div id="39985392" class="c"><input type="checkbox" id="c-39985392" checked=""/><div class="controls bullet"><span class="by">latchkey</span><span>|</span><a href="#39981543">root</a><span>|</span><a href="#39983985">parent</a><span>|</span><a href="#39987197">prev</a><span>|</span><a href="#39982259">next</a><span>|</span><label class="collapse" for="c-39985392">[-]</label><label class="expand" for="c-39985392">[1 more]</label></div><br/><div class="children"><div class="content">Would you like to share the model of GPU and versions of various software used?<p>George has a nice explanation of doorbells:<p><a href="https:&#x2F;&#x2F;youtu.be&#x2F;AqPIOtUkxNo?feature=shared&amp;t=968" rel="nofollow">https:&#x2F;&#x2F;youtu.be&#x2F;AqPIOtUkxNo?feature=shared&amp;t=968</a></div><br/></div></div></div></div></div></div><div id="39982259" class="c"><input type="checkbox" id="c-39982259" checked=""/><div class="controls bullet"><span class="by">Workaccount2</span><span>|</span><a href="#39981543">root</a><span>|</span><a href="#39982050">parent</a><span>|</span><a href="#39983281">prev</a><span>|</span><a href="#39986381">next</a><span>|</span><label class="collapse" for="c-39982259">[-]</label><label class="expand" for="c-39982259">[5 more]</label></div><br/><div class="children"><div class="content">It&#x27;s seriously impressive how well AMD has been able to maintain their incredible software deficiency for over a decade now.</div><br/><div id="39983041" class="c"><input type="checkbox" id="c-39983041" checked=""/><div class="controls bullet"><span class="by">alexey-salmin</span><span>|</span><a href="#39981543">root</a><span>|</span><a href="#39982259">parent</a><span>|</span><a href="#39983105">next</a><span>|</span><label class="collapse" for="c-39983041">[-]</label><label class="expand" for="c-39983041">[1 more]</label></div><br/><div class="children"><div class="content">They deeply care about the tradition of ATI kernel modules from 2004</div><br/></div></div><div id="39983105" class="c"><input type="checkbox" id="c-39983105" checked=""/><div class="controls bullet"><span class="by">amirhirsch</span><span>|</span><a href="#39981543">root</a><span>|</span><a href="#39982259">parent</a><span>|</span><a href="#39983041">prev</a><span>|</span><a href="#39986381">next</a><span>|</span><label class="collapse" for="c-39983105">[-]</label><label class="expand" for="c-39983105">[3 more]</label></div><br/><div class="children"><div class="content">Buying Xilinx helped a lot here.</div><br/><div id="39986292" class="c"><input type="checkbox" id="c-39986292" checked=""/><div class="controls bullet"><span class="by">fpgamlirfanboy</span><span>|</span><a href="#39981543">root</a><span>|</span><a href="#39983105">parent</a><span>|</span><a href="#39986381">next</a><span>|</span><label class="collapse" for="c-39986292">[-]</label><label class="expand" for="c-39986292">[2 more]</label></div><br/><div class="children"><div class="content">it&#x27;s so true it hurts</div><br/><div id="39987397" class="c"><input type="checkbox" id="c-39987397" checked=""/><div class="controls bullet"><span class="by">tucnak</span><span>|</span><a href="#39981543">root</a><span>|</span><a href="#39986292">parent</a><span>|</span><a href="#39986381">next</a><span>|</span><label class="collapse" for="c-39987397">[-]</label><label class="expand" for="c-39987397">[1 more]</label></div><br/><div class="children"><div class="content">Hey man have seen you around here, very knowledgeable, thanks for your input!<p>What&#x27;s your take on projects like <a href="https:&#x2F;&#x2F;github.com&#x2F;corundum&#x2F;corundum">https:&#x2F;&#x2F;github.com&#x2F;corundum&#x2F;corundum</a> I&#x27;m trying to get better at FPGA design, perhaps learn PCIe and some such but Vivado is intimidating (as opposed to Yosys&#x2F;nextpnr which you seem to hate) should I just get involved with a project like this to acclimatise somewhat?</div><br/></div></div></div></div></div></div></div></div><div id="39986381" class="c"><input type="checkbox" id="c-39986381" checked=""/><div class="controls bullet"><span class="by">cavisne</span><span>|</span><a href="#39981543">root</a><span>|</span><a href="#39982050">parent</a><span>|</span><a href="#39982259">prev</a><span>|</span><a href="#39982924">next</a><span>|</span><label class="collapse" for="c-39986381">[-]</label><label class="expand" for="c-39986381">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, I think AMD will really struggle with the cloud providers.<p>Even Nvidia GPU&#x27;s are tricky to sandbox, and it sounds like the AMD cards are really easy for the tenant to break (or at least force a restart of the underlying host).<p>AWS does have a Gaudi instance which is interesting, but overall I don&#x27;t see why Azure, AWS &amp; Google would deploy AMD or Intel GPU&#x27;s at scale vs their own chips.<p>They need some competitor to Nvidia to help negotiate, but if its going to be a painful software support story suited to only a few enterprise customers, why not do it with your own chip?</div><br/></div></div><div id="39982924" class="c"><input type="checkbox" id="c-39982924" checked=""/><div class="controls bullet"><span class="by">jmward01</span><span>|</span><a href="#39981543">root</a><span>|</span><a href="#39982050">parent</a><span>|</span><a href="#39986381">prev</a><span>|</span><a href="#39982146">next</a><span>|</span><label class="collapse" for="c-39982924">[-]</label><label class="expand" for="c-39982924">[9 more]</label></div><br/><div class="children"><div class="content">Yeah, this has stopped me from trying anything with them. They need to lead with their consumer cards so that developers can test&#x2F;build&#x2F;evaluate&#x2F;gain trust locally and then their enterprise offerings need to 100% guarantee that the stuff developers worked on will work in the data center. I keep hoping to see this but every time I look it isn&#x27;t there. There is way more support for apple silicon out there than ROCm and that has no path to enterprise. AMD is missing the boat.</div><br/><div id="39983469" class="c"><input type="checkbox" id="c-39983469" checked=""/><div class="controls bullet"><span class="by">JonChesterfield</span><span>|</span><a href="#39981543">root</a><span>|</span><a href="#39982924">parent</a><span>|</span><a href="#39983044">next</a><span>|</span><label class="collapse" for="c-39983469">[-]</label><label class="expand" for="c-39983469">[3 more]</label></div><br/><div class="children"><div class="content">In fairness it wasn&#x27;t Apple who implemented the non-mac uses of their hardware.<p>AMD&#x27;s driver is in your kernel, all the userspace is on GitHub. The ISA is documented. It&#x27;s entirely possible to treat the ASICs as mass market subsidized floating point machines and run your own code on them.<p>Modulo firmware. I&#x27;m vaguely on the path to working out what&#x27;s going on there. Changing that without talking to the hardware guys in real time might be rather difficult even with the code available though.</div><br/><div id="39987512" class="c"><input type="checkbox" id="c-39987512" checked=""/><div class="controls bullet"><span class="by">imtringued</span><span>|</span><a href="#39981543">root</a><span>|</span><a href="#39983469">parent</a><span>|</span><a href="#39983044">next</a><span>|</span><label class="collapse" for="c-39987512">[-]</label><label class="expand" for="c-39987512">[2 more]</label></div><br/><div class="children"><div class="content">You are ignoring that AMD doesn&#x27;t use an intermediate representation and every ROCm driver is basically compiling to a GPU specific ISA. It wouldn&#x27;t surprise me that there are bugs they have fixed for one ISA that they didn&#x27;t bother porting to the others. The other problem is that most likely their firmware contains classic C bugs like buffer overflows, undefined behaviour, or stuff like deadlocks.</div><br/><div id="39988173" class="c"><input type="checkbox" id="c-39988173" checked=""/><div class="controls bullet"><span class="by">JonChesterfield</span><span>|</span><a href="#39981543">root</a><span>|</span><a href="#39987512">parent</a><span>|</span><a href="#39983044">next</a><span>|</span><label class="collapse" for="c-39988173">[-]</label><label class="expand" for="c-39988173">[1 more]</label></div><br/><div class="children"><div class="content">This is sort of true. Graphics compiles to spir-v, moves that around as deployment, then runs it through llvm to create the compiled shaders. Compute doesn&#x27;t bother with spir-v (to the distress of some of our engineers) and moves llvm IR around instead. That goes through the llvm backend which does mostly the same stuff for each target machine. There probably are some bugs that were fixed on one machine and accidentally missed on another - the compiler is quite branchy - but it&#x27;s nothing like as bad as a separate codebase per ISA. Nvidia has a specific ISA per card too, they just expose PTX and SASS as abstractions over it.<p>I haven&#x27;t found the firmware source code yet - digging through confluence and perforce tries my patience and I&#x27;m supposed to be working on llvm - but I hear it&#x27;s written in assembly, where one of the hurdles to open sourcing it is the assembler is proprietary. I suspect there&#x27;s some common information shared with the hardware description language (tcl and verilog or whatever they&#x27;re using). To the extent that turns out to be true, it&#x27;ll be immune to C style undefined behaviour, but I wouldn&#x27;t bet on it being free from buffer overflows.</div><br/></div></div></div></div></div></div><div id="39983044" class="c"><input type="checkbox" id="c-39983044" checked=""/><div class="controls bullet"><span class="by">latchkey</span><span>|</span><a href="#39981543">root</a><span>|</span><a href="#39982924">parent</a><span>|</span><a href="#39983469">prev</a><span>|</span><a href="#39982146">next</a><span>|</span><label class="collapse" for="c-39983044">[-]</label><label class="expand" for="c-39983044">[5 more]</label></div><br/><div class="children"><div class="content">You are right, AMD should do more with consumer cards, but I understand why they aren&#x27;t today. It is a big ship, they&#x27;ve really only started changing course as of last Oct&#x2F;Nov, before the release of MI300x in Dec. If you have limited resources and a whole culture to change, you have to give them time to fix that.<p>That said, if you&#x27;re on the inside, like I am, and you talk to people at AMD (just got off two separate back to back calls with them), rest assured, they are dedicated to making this stuff work.<p>Part of that is to build a developer flywheel by making their top end hardware available to end users. That&#x27;s where my company Hot Aisle comes into play. Something that wasn&#x27;t available before outside of the HPC markets, is now going to be made available.</div><br/><div id="39984705" class="c"><input type="checkbox" id="c-39984705" checked=""/><div class="controls bullet"><span class="by">jmward01</span><span>|</span><a href="#39981543">root</a><span>|</span><a href="#39983044">parent</a><span>|</span><a href="#39983113">next</a><span>|</span><label class="collapse" for="c-39984705">[-]</label><label class="expand" for="c-39984705">[2 more]</label></div><br/><div class="children"><div class="content">I look forward to seeing it. NVIDIA needs real competition for their own benefit if not the market as a whole. I want a richer ecosystem where Intel, AMD, NVIDIA and other players all join in with the winner being the consumer. From a selfish point of view I also want to do more home experimentation. LLMs are so new that you can make breakthroughs without a huge team but it really helps to have hardware to make it easier to play with ideas. Consumer card memory limitations are hurting that right now.</div><br/><div id="39984730" class="c"><input type="checkbox" id="c-39984730" checked=""/><div class="controls bullet"><span class="by">latchkey</span><span>|</span><a href="#39981543">root</a><span>|</span><a href="#39984705">parent</a><span>|</span><a href="#39983113">next</a><span>|</span><label class="collapse" for="c-39984730">[-]</label><label class="expand" for="c-39984730">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I want a richer ecosystem where Intel, AMD, NVIDIA and other players all join in with the winner being the consumer.<p>This is <i>exactly</i> the void I&#x27;m trying to fill.</div><br/></div></div></div></div><div id="39983113" class="c"><input type="checkbox" id="c-39983113" checked=""/><div class="controls bullet"><span class="by">tucnak</span><span>|</span><a href="#39981543">root</a><span>|</span><a href="#39983044">parent</a><span>|</span><a href="#39984705">prev</a><span>|</span><a href="#39982146">next</a><span>|</span><label class="collapse" for="c-39983113">[-]</label><label class="expand" for="c-39983113">[2 more]</label></div><br/><div class="children"><div class="content">&gt; developer flywheel<p>This is peak comedy</div><br/><div id="39983185" class="c"><input type="checkbox" id="c-39983185" checked=""/><div class="controls bullet"><span class="by">latchkey</span><span>|</span><a href="#39981543">root</a><span>|</span><a href="#39983113">parent</a><span>|</span><a href="#39982146">next</a><span>|</span><label class="collapse" for="c-39983185">[-]</label><label class="expand" for="c-39983185">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;newsguidelines.html">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;newsguidelines.html</a><p>Comments should get more thoughtful and substantive, not less, as a topic gets more divisive.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="39981644" class="c"><input type="checkbox" id="c-39981644" checked=""/><div class="controls bullet"><span class="by">latchkey</span><span>|</span><a href="#39981543">prev</a><span>|</span><a href="#39981646">next</a><span>|</span><label class="collapse" for="c-39981644">[-]</label><label class="expand" for="c-39981644">[1 more]</label></div><br/><div class="children"><div class="content">&gt; the only MLPerf-benchmarked alternative for LLMs on the market<p>I hope to work on this for AMD MI300x soon. My company just got added to the MLCommons organization.</div><br/></div></div><div id="39981646" class="c"><input type="checkbox" id="c-39981646" checked=""/><div class="controls bullet"><span class="by">riskable</span><span>|</span><a href="#39981644">prev</a><span>|</span><a href="#39988390">next</a><span>|</span><label class="collapse" for="c-39981646">[-]</label><label class="expand" for="c-39981646">[19 more]</label></div><br/><div class="children"><div class="content">&gt; Twenty-four 200 gigabit (Gb) Ethernet ports are integrated into every Intel Gaudi 3 accelerator<p>WHAT‽  It&#x27;s basically got the equivalent of a 24-port, 200-gigabit switch built into it.  How does that make sense?  Can you imaging stringing 24 Cat 8 cables between servers in a single rack?  Wait: How do you even <i>decide</i> where those cables go?  Do you buy 24 Gaudi 3 accelerators and run cables directly between every single one of them so they can all talk 200-gigabit ethernet to each other?<p>Also: If you&#x27;ve got that many Cat 8 cables coming out the back of the thing <i>how do you even access it</i>?  You&#x27;ll have to unplug half of them (better keep track of which was connected to what port!) just to be able to grab the shell of the device in the rack.  24 ports is usually enough to take up the majority of horizontal space in the rack so maybe this thing requires a minimum of 2-4U just to use it?  That would make more sense but not help in the density department.<p>I&#x27;m imagining a lot of orders for &quot;a gradient&quot; of colors of cables so the data center folks wiring the things can keep track of which cable is supposed to go where.</div><br/><div id="39981766" class="c"><input type="checkbox" id="c-39981766" checked=""/><div class="controls bullet"><span class="by">blackeyeblitzar</span><span>|</span><a href="#39981646">parent</a><span>|</span><a href="#39981761">next</a><span>|</span><label class="collapse" for="c-39981766">[-]</label><label class="expand" for="c-39981766">[3 more]</label></div><br/><div class="children"><div class="content">See <a href="https:&#x2F;&#x2F;www.nextplatform.com&#x2F;2024&#x2F;04&#x2F;09&#x2F;with-gaudi-3-intel-can-sell-ai-accelerators-to-the-pytorch-masses&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.nextplatform.com&#x2F;2024&#x2F;04&#x2F;09&#x2F;with-gaudi-3-intel-c...</a> for more details. Here’s the relevant bits, although you should visit the article to see the networking diagrams:<p>&gt; The Gaudi 3 accelerators inside of the nodes are connected using the same OSFP links to the outside world as happened with the Gaudi 2 designs, but in this case the doubling of the speed means that Intel has had to add retimers between the Ethernet ports on the Gaudi 3 cards and the six 800 Gb&#x2F;sec OSFP ports that come out of the back of the system board. Of the 24 ports on each Gaudi 3, 21 of them are used to make a high-bandwidth all-to-all network linking those Gaudi 3 devices tightly to each other. Like this:<p>&gt; As you scale, you build a sub-cluster with sixteen of these eight-way Gaudi 3 nodes, with three leaf switches – generally based on the 51.2 Tb&#x2F;sec “Tomahawk 5” StrataXGS switch ASICs from Broadcom, according to Medina – that have half of their 64 ports running at 800 GB&#x2F;sec pointing down to the servers and half of their ports pointing up to the spine network. You need three leaf switches to do the trick:<p>&gt; To get to 4,096 Gaudi 3 accelerators across 512 server nodes, you build 32 sub-clusters and you cross link the 96 leaf switches with a three banks of sixteen spine switches, which will give you three different paths to link any Gaudi 3 to any other Gaudi 3 through two layers of network. Like this:<p>The cabling works out neatly in the rack configurations they envision. The idea here is to use standard Ethernet instead of proprietary Infiniband (which Nvidia got from acquiring Mellanox). Because each accelerator can reach other accelerators via multiple paths that will (ideally) not be over-utilized, you will be able to perform large operations across them efficiently without needing to get especially optimized about how your software manages communication.</div><br/><div id="39983135" class="c"><input type="checkbox" id="c-39983135" checked=""/><div class="controls bullet"><span class="by">Manabu-eo</span><span>|</span><a href="#39981646">root</a><span>|</span><a href="#39981766">parent</a><span>|</span><a href="#39981761">next</a><span>|</span><label class="collapse" for="c-39983135">[-]</label><label class="expand" for="c-39983135">[2 more]</label></div><br/><div class="children"><div class="content">The PCI-e HL-338 version is also listing 24 200GbE RDMA nics in a dual-slot configuration. How would they be connected?</div><br/><div id="39983878" class="c"><input type="checkbox" id="c-39983878" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#39981646">root</a><span>|</span><a href="#39983135">parent</a><span>|</span><a href="#39981761">next</a><span>|</span><label class="collapse" for="c-39983878">[-]</label><label class="expand" for="c-39983878">[1 more]</label></div><br/><div class="children"><div class="content">They may go to the top of the card where you can use an SLI-like bridge to connect multiple cards.</div><br/></div></div></div></div></div></div><div id="39981761" class="c"><input type="checkbox" id="c-39981761" checked=""/><div class="controls bullet"><span class="by">gaogao</span><span>|</span><a href="#39981646">parent</a><span>|</span><a href="#39981766">prev</a><span>|</span><a href="#39981783">next</a><span>|</span><label class="collapse" for="c-39981761">[-]</label><label class="expand" for="c-39981761">[2 more]</label></div><br/><div class="children"><div class="content">Infiniband I&#x27;ve heard as incredibly annoying to deal with procuring as well as some other aspects of it, so lots of folks very happy to get RoCE (ethernet) working instead, even if it is a bit cumbersome.</div><br/><div id="39985921" class="c"><input type="checkbox" id="c-39985921" checked=""/><div class="controls bullet"><span class="by">throwaway2037</span><span>|</span><a href="#39981646">root</a><span>|</span><a href="#39981761">parent</a><span>|</span><a href="#39981783">next</a><span>|</span><label class="collapse" for="c-39985921">[-]</label><label class="expand" for="c-39985921">[1 more]</label></div><br/><div class="children"><div class="content">&quot;RoCE&quot;?  Woah, I had to Google that.<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;RDMA_over_Converged_Ethernet" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;RDMA_over_Converged_Ethernet</a><p><pre><code>    &gt; RDMA over Converged Ethernet (RoCE) or InfiniBand over Ethernet (IBoE)[1] is a network protocol which allows remote direct memory access (RDMA) over an Ethernet network. It does this by encapsulating an InfiniBand (IB) transport packet over Ethernet.
</code></pre>
Sounds very cool.</div><br/></div></div></div></div><div id="39981783" class="c"><input type="checkbox" id="c-39981783" checked=""/><div class="controls bullet"><span class="by">buildbot</span><span>|</span><a href="#39981646">parent</a><span>|</span><a href="#39981761">prev</a><span>|</span><a href="#39981870">next</a><span>|</span><label class="collapse" for="c-39981783">[-]</label><label class="expand" for="c-39981783">[3 more]</label></div><br/><div class="children"><div class="content">200gb is not going to be using CAT, it will be fiber (or direct attached copper cable as noted by dogma1138) with a QSFP interface</div><br/><div id="39982059" class="c"><input type="checkbox" id="c-39982059" checked=""/><div class="controls bullet"><span class="by">dogma1138</span><span>|</span><a href="#39981646">root</a><span>|</span><a href="#39981783">parent</a><span>|</span><a href="#39981870">next</a><span>|</span><label class="collapse" for="c-39982059">[-]</label><label class="expand" for="c-39982059">[2 more]</label></div><br/><div class="children"><div class="content">It will most likely use copper QSFP56 cables since these interfaces are either used in inter rack or adjacent rack direct attachments or to the nearest switch.<p>O.5-1.5&#x2F;2m copper cables are easily available and cheap and 4-8m (and even longer) is also possible with copper but tends to be more expensive and harder to get by.<p>Even 800gb is possible with copper cables these days but you’ll end up spending just as much if not more on cabling as the rest of your kit…<a href="https:&#x2F;&#x2F;www.fibermall.com&#x2F;sale-460634-800g-osfp-acc-3m-flt.htm" rel="nofollow">https:&#x2F;&#x2F;www.fibermall.com&#x2F;sale-460634-800g-osfp-acc-3m-flt.h...</a></div><br/><div id="39982232" class="c"><input type="checkbox" id="c-39982232" checked=""/><div class="controls bullet"><span class="by">buildbot</span><span>|</span><a href="#39981646">root</a><span>|</span><a href="#39982059">parent</a><span>|</span><a href="#39981870">next</a><span>|</span><label class="collapse" for="c-39982232">[-]</label><label class="expand" for="c-39982232">[1 more]</label></div><br/><div class="children"><div class="content">Fair point!</div><br/></div></div></div></div></div></div><div id="39981870" class="c"><input type="checkbox" id="c-39981870" checked=""/><div class="controls bullet"><span class="by">juliangoldsmith</span><span>|</span><a href="#39981646">parent</a><span>|</span><a href="#39981783">prev</a><span>|</span><a href="#39981742">next</a><span>|</span><label class="collapse" for="c-39981870">[-]</label><label class="expand" for="c-39981870">[1 more]</label></div><br/><div class="children"><div class="content">For Gaudi2, it looks like 21&#x2F;24 ports are internal to the server.  I highly doubt those have actual individual cables.  Most likely they&#x27;re just carried on PCBs like any other signal.<p>100GBe is only supported on twinax anyway, so Cat8 is irrelevant here.  The other 3 ports are probably QSFP or something.</div><br/></div></div><div id="39981742" class="c"><input type="checkbox" id="c-39981742" checked=""/><div class="controls bullet"><span class="by">brookst</span><span>|</span><a href="#39981646">parent</a><span>|</span><a href="#39981870">prev</a><span>|</span><a href="#39981932">next</a><span>|</span><label class="collapse" for="c-39981742">[-]</label><label class="expand" for="c-39981742">[4 more]</label></div><br/><div class="children"><div class="content">Audio folks solved the &quot;which cable goes where&quot; problem ages ago with cable snakes: <a href="https:&#x2F;&#x2F;www.seismicaudiospeakers.com&#x2F;products&#x2F;24-channel-xlr-snake-cable-25-feet" rel="nofollow">https:&#x2F;&#x2F;www.seismicaudiospeakers.com&#x2F;products&#x2F;24-channel-xlr...</a><p>But I&#x27;m not how big and how expensive a 24 channel cat 8 snake would be (!).</div><br/><div id="39983913" class="c"><input type="checkbox" id="c-39983913" checked=""/><div class="controls bullet"><span class="by">nullindividual</span><span>|</span><a href="#39981646">root</a><span>|</span><a href="#39981742">parent</a><span>|</span><a href="#39981932">next</a><span>|</span><label class="collapse" for="c-39983913">[-]</label><label class="expand" for="c-39983913">[3 more]</label></div><br/><div class="children"><div class="content">I wouldn’t think that would be appropriate for Ethernet due to cross talk.</div><br/><div id="39985154" class="c"><input type="checkbox" id="c-39985154" checked=""/><div class="controls bullet"><span class="by">pezezin</span><span>|</span><a href="#39981646">root</a><span>|</span><a href="#39983913">parent</a><span>|</span><a href="#39985129">next</a><span>|</span><label class="collapse" for="c-39985154">[-]</label><label class="expand" for="c-39985154">[1 more]</label></div><br/><div class="children"><div class="content">Those cables definitely exist for Ethernet, and regarding cross talk, that&#x27;s what shielding is for.<p>Although not for 200 Gbps, at that rate you either use big twinax DACs, or go to fibre.</div><br/></div></div><div id="39985129" class="c"><input type="checkbox" id="c-39985129" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#39981646">root</a><span>|</span><a href="#39983913">parent</a><span>|</span><a href="#39985154">prev</a><span>|</span><a href="#39981932">next</a><span>|</span><label class="collapse" for="c-39985129">[-]</label><label class="expand" for="c-39985129">[1 more]</label></div><br/><div class="children"><div class="content">Four-lane and eight-lane twinax cables exist; I think each pair is individually shielded. Beyond that there&#x27;s fiber.</div><br/></div></div></div></div></div></div><div id="39981680" class="c"><input type="checkbox" id="c-39981680" checked=""/><div class="controls bullet"><span class="by">radicaldreamer</span><span>|</span><a href="#39981646">parent</a><span>|</span><a href="#39981694">prev</a><span>|</span><a href="#39988390">next</a><span>|</span><label class="collapse" for="c-39981680">[-]</label><label class="expand" for="c-39981680">[3 more]</label></div><br/><div class="children"><div class="content">The amount of power that will use up is massive, they should&#x27;ve gone for some fiber instead</div><br/><div id="39981790" class="c"><input type="checkbox" id="c-39981790" checked=""/><div class="controls bullet"><span class="by">buildbot</span><span>|</span><a href="#39981646">root</a><span>|</span><a href="#39981680">parent</a><span>|</span><a href="#39982159">next</a><span>|</span><label class="collapse" for="c-39981790">[-]</label><label class="expand" for="c-39981790">[1 more]</label></div><br/><div class="children"><div class="content">It will be fiber, Ethernet is just the protocol not the physical interface.</div><br/></div></div><div id="39982159" class="c"><input type="checkbox" id="c-39982159" checked=""/><div class="controls bullet"><span class="by">KeplerBoy</span><span>|</span><a href="#39981646">root</a><span>|</span><a href="#39981680">parent</a><span>|</span><a href="#39981790">prev</a><span>|</span><a href="#39988390">next</a><span>|</span><label class="collapse" for="c-39982159">[-]</label><label class="expand" for="c-39982159">[1 more]</label></div><br/><div class="children"><div class="content">The fiber optics are also extremely power hungry. For short runs people use direct attach copper cables to avoid having to deal with fiberoptics.</div><br/></div></div></div></div></div></div><div id="39988390" class="c"><input type="checkbox" id="c-39988390" checked=""/><div class="controls bullet"><span class="by">MrYellowP</span><span>|</span><a href="#39981646">prev</a><span>|</span><a href="#39985512">next</a><span>|</span><label class="collapse" for="c-39988390">[-]</label><label class="expand" for="c-39988390">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;www.dwds.de&#x2F;wb&#x2F;Gaudi" rel="nofollow">https:&#x2F;&#x2F;www.dwds.de&#x2F;wb&#x2F;Gaudi</a><p>That&#x27;s amusing. :D</div><br/></div></div><div id="39985512" class="c"><input type="checkbox" id="c-39985512" checked=""/><div class="controls bullet"><span class="by">InvestorType</span><span>|</span><a href="#39988390">prev</a><span>|</span><a href="#39981487">next</a><span>|</span><label class="collapse" for="c-39985512">[-]</label><label class="expand" for="c-39985512">[3 more]</label></div><br/><div class="children"><div class="content">This appears to be manufactured by TSMC (or Samsung). The press release says it will use a 5nm process, which is not on Intel&#x27;s roadmap.<p>&quot;The Intel Gaudi 3 accelerator, architected for efficient large-scale AI compute, is manufactured on a 5 nanometer (nm) process&quot;</div><br/><div id="39985867" class="c"><input type="checkbox" id="c-39985867" checked=""/><div class="controls bullet"><span class="by">ac29</span><span>|</span><a href="#39985512">parent</a><span>|</span><a href="#39981487">next</a><span>|</span><label class="collapse" for="c-39985867">[-]</label><label class="expand" for="c-39985867">[2 more]</label></div><br/><div class="children"><div class="content">Habana was an acquisition and their use of TSMC predates the acquisition.</div><br/><div id="39986737" class="c"><input type="checkbox" id="c-39986737" checked=""/><div class="controls bullet"><span class="by">modeless</span><span>|</span><a href="#39985512">root</a><span>|</span><a href="#39985867">parent</a><span>|</span><a href="#39981487">next</a><span>|</span><label class="collapse" for="c-39986737">[-]</label><label class="expand" for="c-39986737">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, but if Intel can&#x27;t even get internal customers to adopt their foundry services it seems to bode poorly for the future of the company.</div><br/></div></div></div></div></div></div><div id="39981487" class="c"><input type="checkbox" id="c-39981487" checked=""/><div class="controls bullet"><span class="by">1024core</span><span>|</span><a href="#39985512">prev</a><span>|</span><a href="#39983967">next</a><span>|</span><label class="collapse" for="c-39981487">[-]</label><label class="expand" for="c-39981487">[7 more]</label></div><br/><div class="children"><div class="content">&gt; Memory Boost for LLM Capacity Requirements: 128 gigabytes (GB) of HBMe2 memory capacity, 3.7 terabytes (TB) of memory bandwidth ...<p>I didn&#x27;t know &quot;terabytes (TB)&quot; was a unit of memory bandwidth...</div><br/><div id="39981523" class="c"><input type="checkbox" id="c-39981523" checked=""/><div class="controls bullet"><span class="by">throwup238</span><span>|</span><a href="#39981487">parent</a><span>|</span><a href="#39981632">next</a><span>|</span><label class="collapse" for="c-39981523">[-]</label><label class="expand" for="c-39981523">[1 more]</label></div><br/><div class="children"><div class="content">It’s equivalent to about thirteen football fields per arn if that helps.</div><br/></div></div><div id="39981632" class="c"><input type="checkbox" id="c-39981632" checked=""/><div class="controls bullet"><span class="by">gnabgib</span><span>|</span><a href="#39981487">parent</a><span>|</span><a href="#39981523">prev</a><span>|</span><a href="#39986925">next</a><span>|</span><label class="collapse" for="c-39981632">[-]</label><label class="expand" for="c-39981632">[4 more]</label></div><br/><div class="children"><div class="content">Bit of an embarrassing typo, they do later qualify it as 3.7TB&#x2F;s</div><br/><div id="39982739" class="c"><input type="checkbox" id="c-39982739" checked=""/><div class="controls bullet"><span class="by">SteveNuts</span><span>|</span><a href="#39981487">root</a><span>|</span><a href="#39981632">parent</a><span>|</span><a href="#39986925">next</a><span>|</span><label class="collapse" for="c-39982739">[-]</label><label class="expand" for="c-39982739">[3 more]</label></div><br/><div class="children"><div class="content">Most of the time bandwidth is expressed in giga&#x2F;gibi&#x2F;tera&#x2F;tebi <i>bits</i> per second so this is also confusing to me</div><br/><div id="39983415" class="c"><input type="checkbox" id="c-39983415" checked=""/><div class="controls bullet"><span class="by">sliken</span><span>|</span><a href="#39981487">root</a><span>|</span><a href="#39982739">parent</a><span>|</span><a href="#39983544">next</a><span>|</span><label class="collapse" for="c-39983415">[-]</label><label class="expand" for="c-39983415">[1 more]</label></div><br/><div class="children"><div class="content">Only for networking, not for anything measured inside a node.  Disk bandwidth, cache bandwidth, and memory bandwidth is nearly always measured in bytes&#x2F;sec (bandwidth), or NS&#x2F;cache line or similar (which is mix of bandwidth and latency).</div><br/></div></div></div></div></div></div><div id="39986925" class="c"><input type="checkbox" id="c-39986925" checked=""/><div class="controls bullet"><span class="by">nahnahno</span><span>|</span><a href="#39981487">parent</a><span>|</span><a href="#39981632">prev</a><span>|</span><a href="#39983967">next</a><span>|</span><label class="collapse" for="c-39986925">[-]</label><label class="expand" for="c-39986925">[1 more]</label></div><br/><div class="children"><div class="content">About as relevant a measure of speed as parsecs</div><br/></div></div></div></div><div id="39983967" class="c"><input type="checkbox" id="c-39983967" checked=""/><div class="controls bullet"><span class="by">throwaway4good</span><span>|</span><a href="#39981487">prev</a><span>|</span><a href="#39987012">next</a><span>|</span><label class="collapse" for="c-39983967">[-]</label><label class="expand" for="c-39983967">[1 more]</label></div><br/><div class="children"><div class="content">Worth noting that it is fabbed by TSMC.</div><br/></div></div><div id="39987012" class="c"><input type="checkbox" id="c-39987012" checked=""/><div class="controls bullet"><span class="by">sandGorgon</span><span>|</span><a href="#39983967">prev</a><span>|</span><a href="#39983506">next</a><span>|</span><label class="collapse" for="c-39987012">[-]</label><label class="expand" for="c-39987012">[4 more]</label></div><br/><div class="children"><div class="content">&gt;<i>Intel Gaudi software integrates the PyTorch framework and provides optimized Hugging Face community-based models – the most-common AI framework for GenAI developers today. This allows GenAI developers to operate at a high abstraction level for ease of use and productivity and ease of model porting across hardware types. </i><p>what is the programming interface here ? this is not CUDA right ...so how is this being done ?</div><br/><div id="39987232" class="c"><input type="checkbox" id="c-39987232" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#39987012">parent</a><span>|</span><a href="#39983506">next</a><span>|</span><label class="collapse" for="c-39987232">[-]</label><label class="expand" for="c-39987232">[3 more]</label></div><br/><div class="children"><div class="content">PyTorch has a bunch of backends including CUDA, ROCm, OneAPI, etc.</div><br/><div id="39987407" class="c"><input type="checkbox" id="c-39987407" checked=""/><div class="controls bullet"><span class="by">sandGorgon</span><span>|</span><a href="#39987012">root</a><span>|</span><a href="#39987232">parent</a><span>|</span><a href="#39983506">next</a><span>|</span><label class="collapse" for="c-39987407">[-]</label><label class="expand" for="c-39987407">[2 more]</label></div><br/><div class="children"><div class="content">i understand. but which backend is intel committing to ? not CUDA for sure.
or have they created a new backend</div><br/><div id="39987983" class="c"><input type="checkbox" id="c-39987983" checked=""/><div class="controls bullet"><span class="by">singhrac</span><span>|</span><a href="#39987012">root</a><span>|</span><a href="#39987407">parent</a><span>|</span><a href="#39983506">next</a><span>|</span><label class="collapse" for="c-39987983">[-]</label><label class="expand" for="c-39987983">[1 more]</label></div><br/><div class="children"><div class="content">Intel makes oneAPI. They have corresponding toolkits to cuDNN like oneMKL, oneDNN, etc.<p>However the Gaudi chips are built on top of SynapseAI, another API from before the Habana acquisition. I don’t know if there’s a plan to support oneAPI on Gaudi, but it doesn’t look like it at the moment.</div><br/></div></div></div></div></div></div></div></div><div id="39983506" class="c"><input type="checkbox" id="c-39983506" checked=""/><div class="controls bullet"><span class="by">geertj</span><span>|</span><a href="#39987012">prev</a><span>|</span><a href="#39982490">next</a><span>|</span><label class="collapse" for="c-39983506">[-]</label><label class="expand" for="c-39983506">[15 more]</label></div><br/><div class="children"><div class="content">I wonder if someone knowledgeable could comment on OneAPI vs Cuda. I feel like if Intel is going to be a serious competitor to Nvidia, both software and hardware are going to be equally important.</div><br/><div id="39984251" class="c"><input type="checkbox" id="c-39984251" checked=""/><div class="controls bullet"><span class="by">meragrin_</span><span>|</span><a href="#39983506">parent</a><span>|</span><a href="#39983577">next</a><span>|</span><label class="collapse" for="c-39984251">[-]</label><label class="expand" for="c-39984251">[1 more]</label></div><br/><div class="children"><div class="content">Apparently, Google, Qualcomm, Samsung, and ARM are rallying around oneAPI:<p><a href="https:&#x2F;&#x2F;uxlfoundation.org&#x2F;" rel="nofollow">https:&#x2F;&#x2F;uxlfoundation.org&#x2F;</a></div><br/></div></div><div id="39983577" class="c"><input type="checkbox" id="c-39983577" checked=""/><div class="controls bullet"><span class="by">ZoomerCretin</span><span>|</span><a href="#39983506">parent</a><span>|</span><a href="#39984251">prev</a><span>|</span><a href="#39982490">next</a><span>|</span><label class="collapse" for="c-39983577">[-]</label><label class="expand" for="c-39983577">[13 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not familiar with the particulars of OneAPI, but it&#x27;s just a matter of rewriting CUDA kernels into OneAPI. This is pretty trivial for the vast majority of small (&lt;5 LoC) kernels. Unlike AMD, it looks like they&#x27;re serious about dogfooding their own chips, and they have a much better reputation for their driver quality.</div><br/><div id="39983768" class="c"><input type="checkbox" id="c-39983768" checked=""/><div class="controls bullet"><span class="by">JonChesterfield</span><span>|</span><a href="#39983506">root</a><span>|</span><a href="#39983577">parent</a><span>|</span><a href="#39987459">next</a><span>|</span><label class="collapse" for="c-39983768">[-]</label><label class="expand" for="c-39983768">[6 more]</label></div><br/><div class="children"><div class="content">All the dev work at AMD is on our own hardware. Even things like the corporate laptops are ryzen based. The first gen ryzen laptop I got was <i>terrible</i> but it wasn&#x27;t intel. We also do things like develop ROCm on the non-qualified cards and build our tools with our tools. It would be crazy not to.</div><br/><div id="39985104" class="c"><input type="checkbox" id="c-39985104" checked=""/><div class="controls bullet"><span class="by">sorenjan</span><span>|</span><a href="#39983506">root</a><span>|</span><a href="#39983768">parent</a><span>|</span><a href="#39984712">next</a><span>|</span><label class="collapse" for="c-39985104">[-]</label><label class="expand" for="c-39985104">[2 more]</label></div><br/><div class="children"><div class="content">Why isn&#x27;t AMD part of the UXL Foundation? What does AMD gain from not working together with other companies do make an open alternative to Cuda?<p>Please make SYCL a priority, cross platform code would make AMD GPUs a viable alternative in the future.</div><br/><div id="39987812" class="c"><input type="checkbox" id="c-39987812" checked=""/><div class="controls bullet"><span class="by">JonChesterfield</span><span>|</span><a href="#39983506">root</a><span>|</span><a href="#39985104">parent</a><span>|</span><a href="#39984712">next</a><span>|</span><label class="collapse" for="c-39987812">[-]</label><label class="expand" for="c-39987812">[1 more]</label></div><br/><div class="children"><div class="content">Like opencl was an open alternative? Or HSA? Or HIP? Or openmp? Or spir-v? There are lots of GPU programming languages for amdgpu.<p>Opencl and hip compilers are in llvm trunk, just bring a runtime from GitHub. Openmp likewise though with much more of the runtime in trunk, just bring libhsa.so from GitHub or debian repos. All of it open source.<p>There&#x27;s also a bunch of machine learning stuff. Pytorch and Triton, maybe others. And non-C++ languages, notably Fortran, but Julia and Mojo have mostly third party implementations as well.<p>I don&#x27;t know what the UXL foundation is. I do know what sycl is, but aside from using code from intel I don&#x27;t see what it brings over any of the other single source languages.<p>At some point sycl will probably be implemented on the llvm offload infra Johannes is currently deriving from the openmp runtime, maybe by intel or maybe by one of my colleagues, at which point I expect people to continue using cuda and complaining about amdgpu. It seems very clear to me that extra GPU languages aren&#x27;t the solution to people buying everything from Nvidia.</div><br/></div></div></div></div><div id="39984712" class="c"><input type="checkbox" id="c-39984712" checked=""/><div class="controls bullet"><span class="by">ZoomerCretin</span><span>|</span><a href="#39983506">root</a><span>|</span><a href="#39983768">parent</a><span>|</span><a href="#39985104">prev</a><span>|</span><a href="#39987459">next</a><span>|</span><label class="collapse" for="c-39984712">[-]</label><label class="expand" for="c-39984712">[3 more]</label></div><br/><div class="children"><div class="content">Yes that&#x27;s why I qualified &quot;serious&quot; dogfooding. Of course you use your hardware for your own development work, but it&#x27;s clearly not enough given that showstopper driver issues are going unfixed for half a year.</div><br/><div id="39987181" class="c"><input type="checkbox" id="c-39987181" checked=""/><div class="controls bullet"><span class="by">FeepingCreature</span><span>|</span><a href="#39983506">root</a><span>|</span><a href="#39984712">parent</a><span>|</span><a href="#39988068">next</a><span>|</span><label class="collapse" for="c-39987181">[-]</label><label class="expand" for="c-39987181">[1 more]</label></div><br/><div class="children"><div class="content">Way more than half a year. The 7900XTX came out two years ago and still hits hardware resets with Stable Diffusion.</div><br/></div></div></div></div></div></div><div id="39987459" class="c"><input type="checkbox" id="c-39987459" checked=""/><div class="controls bullet"><span class="by">pjmlp</span><span>|</span><a href="#39983506">root</a><span>|</span><a href="#39983577">parent</a><span>|</span><a href="#39983768">prev</a><span>|</span><a href="#39983865">next</a><span>|</span><label class="collapse" for="c-39987459">[-]</label><label class="expand" for="c-39987459">[1 more]</label></div><br/><div class="children"><div class="content">Only for CUDA kernels that happen to be C++, good luck with C, Fortran and the PTX toolchains for Java, .NET, Haskell, Julia, Python JITs,...<p>Althought at least for Python JITs, Intel seems to also be doing something.<p>And then there is the graphical debugging experience for GPGPU on CUDA, that feels like doing CPU debugging.</div><br/></div></div><div id="39983865" class="c"><input type="checkbox" id="c-39983865" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#39983506">root</a><span>|</span><a href="#39983577">parent</a><span>|</span><a href="#39987459">prev</a><span>|</span><a href="#39983808">next</a><span>|</span><label class="collapse" for="c-39983865">[-]</label><label class="expand" for="c-39983865">[1 more]</label></div><br/><div class="children"><div class="content">IMO dogfooding Gaudi would mean training a model on it (and the only way to &quot;prove&quot; it would be to release that model).</div><br/></div></div><div id="39983808" class="c"><input type="checkbox" id="c-39983808" checked=""/><div class="controls bullet"><span class="by">alecco</span><span>|</span><a href="#39983506">root</a><span>|</span><a href="#39983577">parent</a><span>|</span><a href="#39983865">prev</a><span>|</span><a href="#39988079">next</a><span>|</span><label class="collapse" for="c-39983808">[-]</label><label class="expand" for="c-39983808">[3 more]</label></div><br/><div class="children"><div class="content">Trivial??</div><br/><div id="39984713" class="c"><input type="checkbox" id="c-39984713" checked=""/><div class="controls bullet"><span class="by">TApplencourt</span><span>|</span><a href="#39983506">root</a><span>|</span><a href="#39983808">parent</a><span>|</span><a href="#39984720">next</a><span>|</span><label class="collapse" for="c-39984713">[-]</label><label class="expand" for="c-39984713">[1 more]</label></div><br/><div class="children"><div class="content">You have SYCLomatic to help.</div><br/></div></div><div id="39984720" class="c"><input type="checkbox" id="c-39984720" checked=""/><div class="controls bullet"><span class="by">ZoomerCretin</span><span>|</span><a href="#39983506">root</a><span>|</span><a href="#39983808">parent</a><span>|</span><a href="#39984713">prev</a><span>|</span><a href="#39988079">next</a><span>|</span><label class="collapse" for="c-39984720">[-]</label><label class="expand" for="c-39984720">[1 more]</label></div><br/><div class="children"><div class="content">That statement has two qualifications.</div><br/></div></div></div></div><div id="39988079" class="c"><input type="checkbox" id="c-39988079" checked=""/><div class="controls bullet"><span class="by">JonChesterfield</span><span>|</span><a href="#39983506">root</a><span>|</span><a href="#39983577">parent</a><span>|</span><a href="#39983808">prev</a><span>|</span><a href="#39982490">next</a><span>|</span><label class="collapse" for="c-39988079">[-]</label><label class="expand" for="c-39988079">[1 more]</label></div><br/><div class="children"><div class="content">(reply to Zoomer from further down, moving up because I ended up writing a lot)<p>This experience is largely a misalignment between what AMD thinks their product is and what the Linux world thinks software is. My pet theory is it&#x27;s a holdover from the GPU being primarily a games console product as that&#x27;s what kept the company alive through the recent dark times. There&#x27;s money now but some of the best practices are sticky.<p>In games dev, you ship a SDK. Speaking with personal experience here as I was on the playstation dev tools team. That&#x27;s a compiler, debugger, profiler, language runtimes, bunch of math libs etc all packaged together with a single version number for the whole thing. A games studio downloads that and uses it for the entire dev cycle of the game. They&#x27;ve noticed that compiler bugs move so each game is essentially dependent on the &quot;characteristics&quot; of that toolchain and persuading them to gamble on a toolchain upgrade mid cycle requires some feature they really badly want.<p>HPC has some things in common with this. You &quot;module load rocm-5.2&quot; or whatever and now your whole environment is that particular toolchain release. That&#x27;s where the math libraries are and where the compiler is.<p>With that context, the internal testing process makes a lot of sense. At some point AMD picks a target OS. I think it&#x27;s literally &quot;LTS Ubuntu&quot; or a RedHat release or similar. Something that is already available anyway. That gets installed on a lot of CI machines, test machines, developer machines. Most of the boxes I can ssh into have Ubuntu on them. The userspace details don&#x27;t matter much but what this does do is fix the kernel version for a given release number. Possibly to one of two similar kernel versions. Then there&#x27;s a multiple month dev and testing process, all on that kernel.<p>Testing involves some largish number of programs that customers care about. Whatever they&#x27;re running on the clusters, or some AI things these days. It also involves a lot of performance testing where things getting slower is a bug. The release team are very clear on things not going out the door if things are broken or slower and it&#x27;s not a fun time to have your commit from months ago pulled out of the bisection as the root cause. That as-shipped configuration - kernel 5.whatever, the driver you build yourself as opposed to the one that kernel shipped with, the ROCm userspace version 4.1 or so - taken together is pretty solid. It sometimes falls over in the field anyway when running applications that aren&#x27;t in the internal testing set but users of it don&#x27;t seem anything like as cross as the HN crowd.<p>This pretty much gives you the discrepancy in user experience. If you&#x27;ve got a rocm release running on one of the HPC machines, or you&#x27;ve got a gaming SDK on a specific console version, things work fairly well and because it&#x27;s a fixed point things that don&#x27;t work can be patched around.<p>In contrast, you can take whatever linux kernel you like and use the amdkfd driver in that, combined with whatever ROCm packages your distribution has bundled. Last I looked it was ROCm 5.2 in debian, lightly patched. A colleague runs Arch which I think is more recent. Gentoo will be different again. I don&#x27;t know about the others. That kernel probably isn&#x27;t from the magic list of hammered on under testing. The driver definitely isn&#x27;t. The driver people work largely upstream but the gitlab fork can be quite divergent from it, much like the rocm llvm can be quite divergent from the upstream llvm.<p>So when you take the happy path on Linux and use whatever kernel you happen to have installed, that&#x27;s a codebase that went through whatever testing the kernel project does on the driver and reflects the fraction of a kernel dev branch that was upstream at that point in time. Sometimes it&#x27;s very stable, sometimes it&#x27;s really not. I stubbornly refuse to use the binary release of ROCm and use whatever driver is in Debian testing and occasionally have a bad time with stability as a result. But that&#x27;s because I&#x27;m deliberately running a bleeding edge dev build because bugs I stumble across have a chance of me fixing them before users run into it.<p>I don&#x27;t think people using apt-get install rocm necessarily know whether they&#x27;re using a kernel that the userspace is expected to work with or a dev version of excitement since they look the same. The documentation says to use the approved linux release - some Ubuntu flavour with a specific version number - but doesn&#x27;t draw much attention to the expected experience if you ignore that command.<p>This is strongly related to the &quot;approved cards list&quot; that HN also hates. It literally means the release testing passed on the cards in that list, and the release testing was not run on the other ones. So you&#x27;re back into the YMMV region, along with people like me stubbornly running non-approved gaming hardware on non-approved kernels with a bunch of code I built from source using a different compiler to the one used for the production binaries.<p>None of this is remotely apparent to me from our documentation but it does follow pretty directly from the games dev &#x2F; HPC design space.</div><br/></div></div></div></div></div></div><div id="39982490" class="c"><input type="checkbox" id="c-39982490" checked=""/><div class="controls bullet"><span class="by">alecco</span><span>|</span><a href="#39983506">prev</a><span>|</span><a href="#39982746">next</a><span>|</span><label class="collapse" for="c-39982490">[-]</label><label class="expand" for="c-39982490">[4 more]</label></div><br/><div class="children"><div class="content">Gaudi 3 has PCIe 4.0 (vs. H100 PCIe 5.0, so 2x the bandwidth). Probably not a deal-breaker but it&#x27;s strange for Intel (of all vendors) to lag behind in PCIe.</div><br/><div id="39982643" class="c"><input type="checkbox" id="c-39982643" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#39982490">parent</a><span>|</span><a href="#39984259">next</a><span>|</span><label class="collapse" for="c-39982643">[-]</label><label class="expand" for="c-39982643">[2 more]</label></div><br/><div class="children"><div class="content">N5, PCIe 4.0, and HBM2e. This chip was probably delayed two years.</div><br/><div id="39982801" class="c"><input type="checkbox" id="c-39982801" checked=""/><div class="controls bullet"><span class="by">alecco</span><span>|</span><a href="#39982490">root</a><span>|</span><a href="#39982643">parent</a><span>|</span><a href="#39984259">next</a><span>|</span><label class="collapse" for="c-39982801">[-]</label><label class="expand" for="c-39982801">[1 more]</label></div><br/><div class="children"><div class="content">Good point, it&#x27;s built on TSMC while Intel is pushing to become the #2 foundry. Probably it&#x27;s because Gaudi was made by an Israeli company Intel acquired in 2019 (not an internal project). Who knows.<p><a href="https:&#x2F;&#x2F;www.semianalysis.com&#x2F;p&#x2F;is-intel-back-foundry-and-product" rel="nofollow">https:&#x2F;&#x2F;www.semianalysis.com&#x2F;p&#x2F;is-intel-back-foundry-and-pro...</a></div><br/></div></div></div></div><div id="39984259" class="c"><input type="checkbox" id="c-39984259" checked=""/><div class="controls bullet"><span class="by">KeplerBoy</span><span>|</span><a href="#39982490">parent</a><span>|</span><a href="#39982643">prev</a><span>|</span><a href="#39982746">next</a><span>|</span><label class="collapse" for="c-39984259">[-]</label><label class="expand" for="c-39984259">[1 more]</label></div><br/><div class="children"><div class="content">The whitepaper says it&#x27;s PCIe 5 on Gaudi 3.</div><br/></div></div></div></div><div id="39982746" class="c"><input type="checkbox" id="c-39982746" checked=""/><div class="controls bullet"><span class="by">ancharm</span><span>|</span><a href="#39982490">prev</a><span>|</span><a href="#39986389">next</a><span>|</span><label class="collapse" for="c-39982746">[-]</label><label class="expand" for="c-39982746">[1 more]</label></div><br/><div class="children"><div class="content">Is the scheduling &#x2F; bare metal software open source through OneAPI? Can a link be posted showing it if so?</div><br/></div></div><div id="39986389" class="c"><input type="checkbox" id="c-39986389" checked=""/><div class="controls bullet"><span class="by">cavisne</span><span>|</span><a href="#39982746">prev</a><span>|</span><a href="#39984269">next</a><span>|</span><label class="collapse" for="c-39986389">[-]</label><label class="expand" for="c-39986389">[1 more]</label></div><br/><div class="children"><div class="content">Is there an equivalent to this reference for Intel Gaudi?<p><a href="https:&#x2F;&#x2F;docs.nvidia.com&#x2F;cuda&#x2F;parallel-thread-execution&#x2F;index.html#" rel="nofollow">https:&#x2F;&#x2F;docs.nvidia.com&#x2F;cuda&#x2F;parallel-thread-execution&#x2F;index...</a></div><br/></div></div><div id="39984269" class="c"><input type="checkbox" id="c-39984269" checked=""/><div class="controls bullet"><span class="by">amelius</span><span>|</span><a href="#39986389">prev</a><span>|</span><a href="#39984305">next</a><span>|</span><label class="collapse" for="c-39984269">[-]</label><label class="expand" for="c-39984269">[3 more]</label></div><br/><div class="children"><div class="content">Missing in these pictures are the thermal management solutions.</div><br/><div id="39984830" class="c"><input type="checkbox" id="c-39984830" checked=""/><div class="controls bullet"><span class="by">InitEnabler</span><span>|</span><a href="#39984269">parent</a><span>|</span><a href="#39987242">next</a><span>|</span><label class="collapse" for="c-39984830">[-]</label><label class="expand" for="c-39984830">[1 more]</label></div><br/><div class="children"><div class="content">If you look at one of the pictures you can get a peak at what they look like (I think...) in the bottom right.<p><a href="https:&#x2F;&#x2F;www.intel.com&#x2F;content&#x2F;dam&#x2F;www&#x2F;central-libraries&#x2F;us&#x2F;en&#x2F;images&#x2F;2024-04&#x2F;newsroom-intel-gaudi-3-5.jpg.rendition.intel.web.1280.720.jpg" rel="nofollow">https:&#x2F;&#x2F;www.intel.com&#x2F;content&#x2F;dam&#x2F;www&#x2F;central-libraries&#x2F;us&#x2F;e...</a></div><br/></div></div><div id="39987242" class="c"><input type="checkbox" id="c-39987242" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#39984269">parent</a><span>|</span><a href="#39984830">prev</a><span>|</span><a href="#39984305">next</a><span>|</span><label class="collapse" for="c-39987242">[-]</label><label class="expand" for="c-39987242">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s going to look very similar to an Nvidia SXM or AMD MI300 heatsink since these all have similar form factors.</div><br/></div></div></div></div><div id="39984305" class="c"><input type="checkbox" id="c-39984305" checked=""/><div class="controls bullet"><span class="by">KeplerBoy</span><span>|</span><a href="#39984269">prev</a><span>|</span><a href="#39982025">next</a><span>|</span><label class="collapse" for="c-39984305">[-]</label><label class="expand" for="c-39984305">[1 more]</label></div><br/><div class="children"><div class="content">vector floating point performance comes in at 14 Tflops&#x2F;s for FP32 and 28 Tflop&#x2F;s for FP16.<p>Not the best of times for stuff that doesn&#x27;t fit matrix processing units.</div><br/></div></div><div id="39982025" class="c"><input type="checkbox" id="c-39982025" checked=""/><div class="controls bullet"><span class="by">andersa</span><span>|</span><a href="#39984305">prev</a><span>|</span><a href="#39981808">next</a><span>|</span><label class="collapse" for="c-39982025">[-]</label><label class="expand" for="c-39982025">[1 more]</label></div><br/><div class="children"><div class="content">Price?</div><br/></div></div><div id="39981808" class="c"><input type="checkbox" id="c-39981808" checked=""/><div class="controls bullet"><span class="by">yieldcrv</span><span>|</span><a href="#39982025">prev</a><span>|</span><a href="#39985663">next</a><span>|</span><label class="collapse" for="c-39981808">[-]</label><label class="expand" for="c-39981808">[2 more]</label></div><br/><div class="children"><div class="content">Has anyone here bought an AI accelerator to run their AI SaaS service from their home to customers instead of trying to make a profit on top of OpenAI or Replicate<p>Seems like an okay $8,000 - $30,000 investment, and bare metal server maintenance isn’t that complicated these days.</div><br/><div id="39983089" class="c"><input type="checkbox" id="c-39983089" checked=""/><div class="controls bullet"><span class="by">shiftpgdn</span><span>|</span><a href="#39981808">parent</a><span>|</span><a href="#39985663">next</a><span>|</span><label class="collapse" for="c-39983089">[-]</label><label class="expand" for="c-39983089">[1 more]</label></div><br/><div class="children"><div class="content">Dingboard runs off of the owner&#x27;s pile of used gamer cards. The owner frequently posts about it on twitter.</div><br/></div></div></div></div><div id="39985663" class="c"><input type="checkbox" id="c-39985663" checked=""/><div class="controls bullet"><span class="by">metadat</span><span>|</span><a href="#39981808">prev</a><span>|</span><a href="#39982099">next</a><span>|</span><label class="collapse" for="c-39985663">[-]</label><label class="expand" for="c-39985663">[4 more]</label></div><br/><div class="children"><div class="content"><i>&gt; Twenty-four 200 gigabit (Gb) Ethernet ports are integrated into every Intel Gaudi 3 accelerator</i><p>How much does a single 200Gbit active (or inactive) fiber cable cost?  Probably thousands of dollars.. making even the cabling for each card Very Expensive.  Nevermind the network switches themselves..<p>Simultaneously impressive and disappointing.</div><br/><div id="39985761" class="c"><input type="checkbox" id="c-39985761" checked=""/><div class="controls bullet"><span class="by">carlhjerpe</span><span>|</span><a href="#39985663">parent</a><span>|</span><a href="#39985976">next</a><span>|</span><label class="collapse" for="c-39985761">[-]</label><label class="expand" for="c-39985761">[2 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;www.fs.com&#x2F;de-en&#x2F;products&#x2F;115636.html" rel="nofollow">https:&#x2F;&#x2F;www.fs.com&#x2F;de-en&#x2F;products&#x2F;115636.html</a> 2 meters seems to be about 100$, which isn&#x27;t unreasonable.<p>If you&#x27;re going fiber instead of twinax it&#x27;s another order of magnitude and a bit for trancievers, but cables are pretty cheap still.<p>You seem to be loading negative energy into this release from the get-go</div><br/><div id="39985775" class="c"><input type="checkbox" id="c-39985775" checked=""/><div class="controls bullet"><span class="by">metadat</span><span>|</span><a href="#39985663">root</a><span>|</span><a href="#39985761">parent</a><span>|</span><a href="#39985976">next</a><span>|</span><label class="collapse" for="c-39985775">[-]</label><label class="expand" for="c-39985775">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;re going to need a lot more than 2 meters... It&#x27;s probably AOC (Active-Optical Fiber Cable), they&#x27;re pricey even for 40Gbit, at DC lengths.</div><br/></div></div></div></div><div id="39985976" class="c"><input type="checkbox" id="c-39985976" checked=""/><div class="controls bullet"><span class="by">throwaway2037</span><span>|</span><a href="#39985663">parent</a><span>|</span><a href="#39985761">prev</a><span>|</span><a href="#39982099">next</a><span>|</span><label class="collapse" for="c-39985976">[-]</label><label class="expand" for="c-39985976">[1 more]</label></div><br/><div class="children"><div class="content">What do you mean by active vs inactive fiber cable?  I tried to Google about this distinction, but I couldn&#x27;t find anything helpful.</div><br/></div></div></div></div><div id="39982099" class="c"><input type="checkbox" id="c-39982099" checked=""/><div class="controls bullet"><span class="by">mpreda</span><span>|</span><a href="#39985663">prev</a><span>|</span><a href="#39984389">next</a><span>|</span><label class="collapse" for="c-39982099">[-]</label><label class="expand" for="c-39982099">[1 more]</label></div><br/><div class="children"><div class="content">How much does one such card cost?</div><br/></div></div><div id="39984389" class="c"><input type="checkbox" id="c-39984389" checked=""/><div class="controls bullet"><span class="by">einpoklum</span><span>|</span><a href="#39982099">prev</a><span>|</span><a href="#39982380">next</a><span>|</span><label class="collapse" for="c-39984389">[-]</label><label class="expand" for="c-39984389">[1 more]</label></div><br/><div class="children"><div class="content">If your metric is memory bandwidth or memory size, then this announcement gives you some concrete information. But - suppose my metric for performance is matrix-multiply-add (or just matrix-multiply) bandwidth. What MMA primitives does Gaudi offer (i.e. type combinations and matrix dimension combinations), and how many of such ops per second, in practice? The linked page says &quot;64,000 in parallel&quot;, but that does not actually tell me much.</div><br/></div></div><div id="39982380" class="c"><input type="checkbox" id="c-39982380" checked=""/><div class="controls bullet"><span class="by">AnonMO</span><span>|</span><a href="#39984389">prev</a><span>|</span><a href="#39981661">next</a><span>|</span><label class="collapse" for="c-39982380">[-]</label><label class="expand" for="c-39982380">[1 more]</label></div><br/><div class="children"><div class="content">it&#x27;s crazy that Intel can&#x27;t manufacture its own chips atm, but it looks like that might change in the coming years as new fabs come online.</div><br/></div></div><div id="39981661" class="c"><input type="checkbox" id="c-39981661" checked=""/><div class="controls bullet"><span class="by">colechristensen</span><span>|</span><a href="#39982380">prev</a><span>|</span><a href="#39982998">next</a><span>|</span><label class="collapse" for="c-39981661">[-]</label><label class="expand" for="c-39981661">[9 more]</label></div><br/><div class="children"><div class="content">Anyone have experience and suggestions for an AI accelerator?<p>Think prototype consumer product with total cost preferably &lt; $500, definitely less than $1000.</div><br/><div id="39981809" class="c"><input type="checkbox" id="c-39981809" checked=""/><div class="controls bullet"><span class="by">jsheard</span><span>|</span><a href="#39981661">parent</a><span>|</span><a href="#39981896">next</a><span>|</span><label class="collapse" for="c-39981809">[-]</label><label class="expand" for="c-39981809">[1 more]</label></div><br/><div class="children"><div class="content">The default answer is to get the biggest Nvidia gaming card you can afford, prioritizing VRAM size over speed. Ideally one of the 24GB ones.</div><br/></div></div><div id="39981896" class="c"><input type="checkbox" id="c-39981896" checked=""/><div class="controls bullet"><span class="by">Hugsun</span><span>|</span><a href="#39981661">parent</a><span>|</span><a href="#39981809">prev</a><span>|</span><a href="#39983884">next</a><span>|</span><label class="collapse" for="c-39981896">[-]</label><label class="expand" for="c-39981896">[1 more]</label></div><br/><div class="children"><div class="content">You can get very cheap tesla P40s with 24gb of ram. They are much much slower than the newer cards but offer decent value for running a local chatbot.<p>I can&#x27;t speak to the ease of configuration but know that some people have used these successfully.</div><br/></div></div><div id="39983884" class="c"><input type="checkbox" id="c-39983884" checked=""/><div class="controls bullet"><span class="by">JonChesterfield</span><span>|</span><a href="#39981661">parent</a><span>|</span><a href="#39981896">prev</a><span>|</span><a href="#39982129">next</a><span>|</span><label class="collapse" for="c-39983884">[-]</label><label class="expand" for="c-39983884">[1 more]</label></div><br/><div class="children"><div class="content">I liked my 5700XT. That seems to be $200 now. Ran arbitrary code on it just fine. Lots of machine learning seems to be obsessed with amount of memory though and increasing that is likely to increase the price. Also HN doesn&#x27;t like ROCm much, so there&#x27;s that.</div><br/></div></div><div id="39982129" class="c"><input type="checkbox" id="c-39982129" checked=""/><div class="controls bullet"><span class="by">hedgehog</span><span>|</span><a href="#39981661">parent</a><span>|</span><a href="#39983884">prev</a><span>|</span><a href="#39981811">next</a><span>|</span><label class="collapse" for="c-39982129">[-]</label><label class="expand" for="c-39982129">[1 more]</label></div><br/><div class="children"><div class="content">What else in on the BOM? Volume? At that price you likely want to use whatever resources are on the SoC that runs the thing and work around that. Feel free to e-mail me.</div><br/></div></div><div id="39981811" class="c"><input type="checkbox" id="c-39981811" checked=""/><div class="controls bullet"><span class="by">mirekrusin</span><span>|</span><a href="#39981661">parent</a><span>|</span><a href="#39982129">prev</a><span>|</span><a href="#39981985">next</a><span>|</span><label class="collapse" for="c-39981811">[-]</label><label class="expand" for="c-39981811">[1 more]</label></div><br/><div class="children"><div class="content">Rent or 3090, maybe used 4090 if you&#x27;re lucky.</div><br/></div></div><div id="39981985" class="c"><input type="checkbox" id="c-39981985" checked=""/><div class="controls bullet"><span class="by">jononor</span><span>|</span><a href="#39981661">parent</a><span>|</span><a href="#39981811">prev</a><span>|</span><a href="#39982135">next</a><span>|</span><label class="collapse" for="c-39981985">[-]</label><label class="expand" for="c-39981985">[1 more]</label></div><br/><div class="children"><div class="content">What is the workload?</div><br/></div></div><div id="39982135" class="c"><input type="checkbox" id="c-39982135" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#39981661">parent</a><span>|</span><a href="#39981985">prev</a><span>|</span><a href="#39982319">next</a><span>|</span><label class="collapse" for="c-39982135">[-]</label><label class="expand" for="c-39982135">[1 more]</label></div><br/><div class="children"><div class="content">AMD Hawk Point?</div><br/></div></div><div id="39982319" class="c"><input type="checkbox" id="c-39982319" checked=""/><div class="controls bullet"><span class="by">dist-epoch</span><span>|</span><a href="#39981661">parent</a><span>|</span><a href="#39982135">prev</a><span>|</span><a href="#39982998">next</a><span>|</span><label class="collapse" for="c-39982319">[-]</label><label class="expand" for="c-39982319">[1 more]</label></div><br/><div class="children"><div class="content">All new CPUs will have so called NPUs inside them. For helping running models locally.</div><br/></div></div></div></div><div id="39982998" class="c"><input type="checkbox" id="c-39982998" checked=""/><div class="controls bullet"><span class="by">m3kw9</span><span>|</span><a href="#39981661">prev</a><span>|</span><a href="#39981908">next</a><span>|</span><label class="collapse" for="c-39982998">[-]</label><label class="expand" for="c-39982998">[4 more]</label></div><br/><div class="children"><div class="content">Can you run Cuda on it?</div><br/><div id="39984656" class="c"><input type="checkbox" id="c-39984656" checked=""/><div class="controls bullet"><span class="by">boroboro4</span><span>|</span><a href="#39982998">parent</a><span>|</span><a href="#39981908">next</a><span>|</span><label class="collapse" for="c-39984656">[-]</label><label class="expand" for="c-39984656">[3 more]</label></div><br/><div class="children"><div class="content">No one runs Cuda, everyone runs PyTorch. Which you can run on it.</div><br/><div id="39985803" class="c"><input type="checkbox" id="c-39985803" checked=""/><div class="controls bullet"><span class="by">m3kw9</span><span>|</span><a href="#39982998">root</a><span>|</span><a href="#39984656">parent</a><span>|</span><a href="#39981908">next</a><span>|</span><label class="collapse" for="c-39985803">[-]</label><label class="expand" for="c-39985803">[2 more]</label></div><br/><div class="children"><div class="content">So does it support cuda or not are are you gonna argue little things all day?</div><br/><div id="39987372" class="c"><input type="checkbox" id="c-39987372" checked=""/><div class="controls bullet"><span class="by">kimixa</span><span>|</span><a href="#39982998">root</a><span>|</span><a href="#39985803">parent</a><span>|</span><a href="#39981908">next</a><span>|</span><label class="collapse" for="c-39987372">[-]</label><label class="expand" for="c-39987372">[1 more]</label></div><br/><div class="children"><div class="content">CUDA is a proprietary Nvidia API where the SDK license explicitly forbids use for development of apps that might run on other hardware.<p>You <i>do</i> read the licenses of SDKs you use, right?<p>Nothing but Nvidia hardware will ever &quot;support&quot; CUDA.</div><br/></div></div></div></div></div></div></div></div><div id="39981908" class="c"><input type="checkbox" id="c-39981908" checked=""/><div class="controls bullet"><span class="by">YetAnotherNick</span><span>|</span><a href="#39982998">prev</a><span>|</span><a href="#39982063">next</a><span>|</span><label class="collapse" for="c-39981908">[-]</label><label class="expand" for="c-39981908">[2 more]</label></div><br/><div class="children"><div class="content">So now hardware companies stopped reporting FLOP&#x2F;s number and reports in arbitrary unit of parallel operation&#x2F;s.</div><br/><div id="39982338" class="c"><input type="checkbox" id="c-39982338" checked=""/><div class="controls bullet"><span class="by">AnonMO</span><span>|</span><a href="#39981908">parent</a><span>|</span><a href="#39982063">next</a><span>|</span><label class="collapse" for="c-39982338">[-]</label><label class="expand" for="c-39982338">[1 more]</label></div><br/><div class="children"><div class="content">1835 tflops fp8. you have to look for it, but they posted it. The link in the op is just an announcement. the white paper has more info. <a href="https:&#x2F;&#x2F;www.intel.com&#x2F;content&#x2F;www&#x2F;us&#x2F;en&#x2F;content-details&#x2F;817486&#x2F;intel-gaudi-3-ai-accelerator-white-paper.html" rel="nofollow">https:&#x2F;&#x2F;www.intel.com&#x2F;content&#x2F;www&#x2F;us&#x2F;en&#x2F;content-details&#x2F;8174...</a></div><br/></div></div></div></div></div></div></div></div></div></body></html>