<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1694336471950" as="style"/><link rel="stylesheet" href="styles.css?v=1694336471950"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2757236">Moral Crumple Zones: Cautionary Tales in Human-Robot Interaction</a>Â <span class="domain">(<a href="https://papers.ssrn.com">papers.ssrn.com</a>)</span></div><div class="subtext"><span>viburnum</span> | <span>4 comments</span></div><br/><div><div id="37454007" class="c"><input type="checkbox" id="c-37454007" checked=""/><div class="controls bullet"><span class="by">jongjong</span><span>|</span><a href="#37453975">next</a><span>|</span><label class="collapse" for="c-37454007">[-]</label><label class="expand" for="c-37454007">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s an interesting subject to think about and discuss. I think the existing legal system is already equipped with the precedents it needs to handle some aspects of such situations.
The idea of someone carrying out a crime via a proxy is not new; the main difference now is that the proxy may be an AI.<p>I think something which is new though is the question of who should take responsibility for the AI&#x27;s actions? If a crime is committed via a proxy, then both parties will be charged. So it doesn&#x27;t make sense to entirely just waive away the AI&#x27;s responsibility in the crime just as it doesn&#x27;t make sense to acquit the person&#x2F;proxy who carried out the crime on behalf of someone else.<p>I think the answer is that the company(ies) which trained and&#x2F;or operated the company behind the AI should also be held partially responsible for the crime.
Otherwise we could end up with a situation whereby some companies are intentionally creating malicious bots which are trained to intentionally misinterpret benign-sounding language as orders of a more sinister nature in order to shield &#x27;the customer&#x27; from criminal liability.<p>I&#x27;m much more worried about the consequences of humans being under-punished rather than over-punished.<p>Neglecting the role of AI companies seems like a sure way to bring about human extinction. We cannot allow all liability to be shifted to non-human entities. We need a better, more fine-grained way to attribute and punish shared and partial liability.<p>We should think in a more fine-grained way. For example, if someone throws out a plastic Coca Cola bottle on the ground, who is responsible for littering? Obviously the person who threw away the bottle is mostly responsible but isn&#x27;t Coca Cola company also slightly responsible for having made their bottles out of plastic (which doesn&#x27;t break down easily; thus worsening the impact of the littering)? Surely they could just have sold metal cans and glass bottles.</div><br/></div></div><div id="37453975" class="c"><input type="checkbox" id="c-37453975" checked=""/><div class="controls bullet"><span class="by">mattigames</span><span>|</span><a href="#37454007">prev</a><span>|</span><label class="collapse" for="c-37453975">[-]</label><label class="expand" for="c-37453975">[2 more]</label></div><br/><div class="children"><div class="content">Dozens of slept deprived truck drivers have been sentenced to multiple years in jail, and many times they were just trying to make ends meet and took more work than they were physically able to handle, but the judges don&#x27;t care about that, judges don&#x27;t care about root causes, what makes anybody think it would be different with robots and AI? It&#x27;s never about fixing the problem, that&#x27;s always a titanic task, it&#x27;s always the lowest hanging fruit that can be used as a scapegoat, be it a sleepy truck driver just trying to pay an increased rent or a robot operator.</div><br/><div id="37454012" class="c"><input type="checkbox" id="c-37454012" checked=""/><div class="controls bullet"><span class="by">RamblingCTO</span><span>|</span><a href="#37453975">parent</a><span>|</span><label class="collapse" for="c-37454012">[-]</label><label class="expand" for="c-37454012">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not their job to fix the root causes, that&#x27;s politic&#x27;s job. You and most countries have separation of power.</div><br/></div></div></div></div></div></div></div></div></div></body></html>