<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1738227667500" as="style"/><link rel="stylesheet" href="styles.css?v=1738227667500"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/Om-Alve/smolGPT">SmolGPT: A minimal PyTorch implementation for training a small LLM from scratch</a> <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>amrrs</span> | <span>39 comments</span></div><br/><div><div id="42870206" class="c"><input type="checkbox" id="c-42870206" checked=""/><div class="controls bullet"><span class="by">sitkack</span><span>|</span><a href="#42869618">next</a><span>|</span><label class="collapse" for="c-42870206">[-]</label><label class="expand" for="c-42870206">[8 more]</label></div><br/><div class="children"><div class="content">Neat, I love projects like these.<p>The next level down is to do it directly in numpy.<p>And then from there, write a minimal numpy work-a-like to support the model above.<p>You start with a working system using the most powerful abstractions. Then you iteratively remove abstractions, lowering your solution, then when you get low enough but still riding on an external abstraction, you rewrite that, but ONLY to support the layers above you.<p>Following the above pattern, you can bootstrap yourself to have full system understanding. This is not unlike RL+distillation that human persons do learn complex topics.</div><br/><div id="42872400" class="c"><input type="checkbox" id="c-42872400" checked=""/><div class="controls bullet"><span class="by">bee_rider</span><span>|</span><a href="#42870206">parent</a><span>|</span><a href="#42870859">next</a><span>|</span><label class="collapse" for="c-42872400">[-]</label><label class="expand" for="c-42872400">[2 more]</label></div><br/><div class="children"><div class="content">Numpy can use the chipmaker’s BLAS (Intel MKL or AMD’s Blis fork). Trying to replace it could be a good academic exercise but I think most people wisely leave that to the vendors.</div><br/><div id="42872614" class="c"><input type="checkbox" id="c-42872614" checked=""/><div class="controls bullet"><span class="by">sitkack</span><span>|</span><a href="#42870206">root</a><span>|</span><a href="#42872400">parent</a><span>|</span><a href="#42870859">next</a><span>|</span><label class="collapse" for="c-42872614">[-]</label><label class="expand" for="c-42872614">[1 more]</label></div><br/><div class="children"><div class="content">It is a purely pedagogical device, like building a go kart.</div><br/></div></div></div></div><div id="42870859" class="c"><input type="checkbox" id="c-42870859" checked=""/><div class="controls bullet"><span class="by">lagrange77</span><span>|</span><a href="#42870206">parent</a><span>|</span><a href="#42872400">prev</a><span>|</span><a href="#42871283">next</a><span>|</span><label class="collapse" for="c-42870859">[-]</label><label class="expand" for="c-42870859">[4 more]</label></div><br/><div class="children"><div class="content">&gt; but still riding on an external abstraction, you rewrite that, but ONLY to support the layers above you.<p>i don&#x27;t get it. Why do i stop before stripping all abstractions?</div><br/><div id="42871133" class="c"><input type="checkbox" id="c-42871133" checked=""/><div class="controls bullet"><span class="by">byteknight</span><span>|</span><a href="#42870206">root</a><span>|</span><a href="#42870859">parent</a><span>|</span><a href="#42871283">next</a><span>|</span><label class="collapse" for="c-42871133">[-]</label><label class="expand" for="c-42871133">[3 more]</label></div><br/><div class="children"><div class="content">Where do you get that? He is postulating the external abstraction you are using has more features than you use. He is saying implement only the parts you use.</div><br/><div id="42871258" class="c"><input type="checkbox" id="c-42871258" checked=""/><div class="controls bullet"><span class="by">lagrange77</span><span>|</span><a href="#42870206">root</a><span>|</span><a href="#42871133">parent</a><span>|</span><a href="#42871283">next</a><span>|</span><label class="collapse" for="c-42871258">[-]</label><label class="expand" for="c-42871258">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Where do you get that?<p>From &quot;when you get low enough but still riding on an external abstraction&quot;.<p>&gt; He is saying implement only the parts you use.<p>Thanks.</div><br/><div id="42871680" class="c"><input type="checkbox" id="c-42871680" checked=""/><div class="controls bullet"><span class="by">sitkack</span><span>|</span><a href="#42870206">root</a><span>|</span><a href="#42871258">parent</a><span>|</span><a href="#42871283">next</a><span>|</span><label class="collapse" for="c-42871680">[-]</label><label class="expand" for="c-42871680">[1 more]</label></div><br/><div class="children"><div class="content">Correct, I should proof read my posts.</div><br/></div></div></div></div></div></div></div></div><div id="42871283" class="c"><input type="checkbox" id="c-42871283" checked=""/><div class="controls bullet"><span class="by">tomrod</span><span>|</span><a href="#42870206">parent</a><span>|</span><a href="#42870859">prev</a><span>|</span><a href="#42869618">next</a><span>|</span><label class="collapse" for="c-42871283">[-]</label><label class="expand" for="c-42871283">[1 more]</label></div><br/><div class="children"><div class="content">Likewise. And your comment reminded me of real programmers*<p>* <a href="https:&#x2F;&#x2F;xkcd.com&#x2F;378&#x2F;" rel="nofollow">https:&#x2F;&#x2F;xkcd.com&#x2F;378&#x2F;</a></div><br/></div></div></div></div><div id="42869618" class="c"><input type="checkbox" id="c-42869618" checked=""/><div class="controls bullet"><span class="by">numba888</span><span>|</span><a href="#42870206">prev</a><span>|</span><a href="#42875551">next</a><span>|</span><label class="collapse" for="c-42869618">[-]</label><label class="expand" for="c-42869618">[4 more]</label></div><br/><div class="children"><div class="content">github has a bunch of them for years, the most known from Andrej Karpathy:<p><a href="https:&#x2F;&#x2F;github.com&#x2F;karpathy&#x2F;nanoGPT">https:&#x2F;&#x2F;github.com&#x2F;karpathy&#x2F;nanoGPT</a><p>some other have MoE implemented.</div><br/><div id="42872030" class="c"><input type="checkbox" id="c-42872030" checked=""/><div class="controls bullet"><span class="by">syassami</span><span>|</span><a href="#42869618">parent</a><span>|</span><a href="#42870200">next</a><span>|</span><label class="collapse" for="c-42872030">[-]</label><label class="expand" for="c-42872030">[1 more]</label></div><br/><div class="children"><div class="content">Personal fave: <a href="https:&#x2F;&#x2F;github.com&#x2F;karpathy&#x2F;llama2.c">https:&#x2F;&#x2F;github.com&#x2F;karpathy&#x2F;llama2.c</a></div><br/></div></div><div id="42870200" class="c"><input type="checkbox" id="c-42870200" checked=""/><div class="controls bullet"><span class="by">benreesman</span><span>|</span><a href="#42869618">parent</a><span>|</span><a href="#42872030">prev</a><span>|</span><a href="#42875551">next</a><span>|</span><label class="collapse" for="c-42870200">[-]</label><label class="expand" for="c-42870200">[2 more]</label></div><br/><div class="children"><div class="content">nanoGPT is awesome (and I highly recommend his videos on it), but it’s closer to a direct reproduction of GPT-2, so it’s cool to have a really clean implementation of some newer ideas.</div><br/><div id="42870572" class="c"><input type="checkbox" id="c-42870572" checked=""/><div class="controls bullet"><span class="by">Nimitz14</span><span>|</span><a href="#42869618">root</a><span>|</span><a href="#42870200">parent</a><span>|</span><a href="#42875551">next</a><span>|</span><label class="collapse" for="c-42870572">[-]</label><label class="expand" for="c-42870572">[1 more]</label></div><br/><div class="children"><div class="content">nanoGPT contains some new ideas. <a href="https:&#x2F;&#x2F;github.com&#x2F;karpathy&#x2F;minGPT">https:&#x2F;&#x2F;github.com&#x2F;karpathy&#x2F;minGPT</a> is more plain</div><br/></div></div></div></div></div></div><div id="42875551" class="c"><input type="checkbox" id="c-42875551" checked=""/><div class="controls bullet"><span class="by">febin</span><span>|</span><a href="#42869618">prev</a><span>|</span><a href="#42873470">next</a><span>|</span><label class="collapse" for="c-42875551">[-]</label><label class="expand" for="c-42875551">[1 more]</label></div><br/><div class="children"><div class="content">Here&#x27;s a google collab notebook built from this. It takes ~2 hours on A100 GPU if you have collab pro. Might work on free account as well.<p><a href="https:&#x2F;&#x2F;colab.research.google.com&#x2F;drive&#x2F;1dklqzK8TDPfbPbyHrk3llXFOOiOhFUeJ?usp=sharing#scrollTo=BEgEJhqeLAgg" rel="nofollow">https:&#x2F;&#x2F;colab.research.google.com&#x2F;drive&#x2F;1dklqzK8TDPfbPbyHrk3...</a></div><br/></div></div><div id="42873470" class="c"><input type="checkbox" id="c-42873470" checked=""/><div class="controls bullet"><span class="by">c0wb0yc0d3r</span><span>|</span><a href="#42875551">prev</a><span>|</span><a href="#42870507">next</a><span>|</span><label class="collapse" for="c-42873470">[-]</label><label class="expand" for="c-42873470">[7 more]</label></div><br/><div class="children"><div class="content">Can someone help me understand what I’m looking at here? This repository allows me to train a specific model on a specific data set, and finally test the result? Is that correct?<p>I am interested in how large and small language models are trained, but as someone who has little knowledge in this world I find it hard to cut through the noise to find useful information.<p>Really I’m looking for an open source project that helps a person gain this knowledge. Something like a docker container that encapsulates all the dependencies. When training it will use any available gpu or tell me why my gpu can’t be used and then fall back to cpu. Then had a simple interface to test the training results. Finally you can easily pull back the curtain to understand the process in better detail and maybe even adapt it to different model to experiment.<p>Does something like that exist?</div><br/><div id="42873632" class="c"><input type="checkbox" id="c-42873632" checked=""/><div class="controls bullet"><span class="by">timnetworks</span><span>|</span><a href="#42873470">parent</a><span>|</span><a href="#42874310">next</a><span>|</span><label class="collapse" for="c-42873632">[-]</label><label class="expand" for="c-42873632">[1 more]</label></div><br/><div class="children"><div class="content">As opposed to inference (like generating text and images), training requires some more math (fp16 or bf16) and a single CPU generally won&#x27;t cut it.<p>The prepare&#x2F;train&#x2F;generate instructions in the github linked are pretty much it for the &#x27;how&#x27; of training a model. You give it a task and it does it for 1 billion trillion epochs and saves the changes incrementally (or not).<p>Training a LoRA for an image model may be more approachable, there&#x27;s more blog entries etc on this, and the process is largely similar, except you&#x27;re doing it for a single slice instead of the whole network.<p>[edit] I&#x27;m also learning so correct me if I&#x27;m off, hn!</div><br/></div></div><div id="42874310" class="c"><input type="checkbox" id="c-42874310" checked=""/><div class="controls bullet"><span class="by">SJC_Hacker</span><span>|</span><a href="#42873470">parent</a><span>|</span><a href="#42873632">prev</a><span>|</span><a href="#42874947">next</a><span>|</span><label class="collapse" for="c-42874310">[-]</label><label class="expand" for="c-42874310">[3 more]</label></div><br/><div class="children"><div class="content">Do you have a good theoretical foundation in ML ?  You will also need some linear algebra.<p>If not would invest the time in a decent course, there are plenty online, even offline if you are close enough to where its offered.  I took one from Andrew Ng on Coursera years ago, which used Matlab.  There are probably much better, more up-to-date options now, especially now that LLMs are very in-vogue.  The fundamentals such as gradient descent, ANNs and back-propagation however, is still relevant, and hasn&#x27;t changed much.<p>Trying to understand what code is doing without that foundation will be an exercise in futility.</div><br/><div id="42875185" class="c"><input type="checkbox" id="c-42875185" checked=""/><div class="controls bullet"><span class="by">c0wb0yc0d3r</span><span>|</span><a href="#42873470">root</a><span>|</span><a href="#42874310">parent</a><span>|</span><a href="#42874947">next</a><span>|</span><label class="collapse" for="c-42875185">[-]</label><label class="expand" for="c-42875185">[2 more]</label></div><br/><div class="children"><div class="content">I don’t have a solid ML foundation, and it’s been a decade or more since I’ve worked with linear algebra.<p>For now I think that might be too deep for what I’m after. I’m at the beach looking out at the vast ocean that is machine learning and LLMs.</div><br/><div id="42876034" class="c"><input type="checkbox" id="c-42876034" checked=""/><div class="controls bullet"><span class="by">barrenko</span><span>|</span><a href="#42873470">root</a><span>|</span><a href="#42875185">parent</a><span>|</span><a href="#42874947">next</a><span>|</span><label class="collapse" for="c-42876034">[-]</label><label class="expand" for="c-42876034">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;re probably having the right hunch, it takes a crapload of time, especially if you want to implement and not just &quot;get an intuition&quot;.</div><br/></div></div></div></div></div></div><div id="42874947" class="c"><input type="checkbox" id="c-42874947" checked=""/><div class="controls bullet"><span class="by">MacTea</span><span>|</span><a href="#42873470">parent</a><span>|</span><a href="#42874310">prev</a><span>|</span><a href="#42870507">next</a><span>|</span><label class="collapse" for="c-42874947">[-]</label><label class="expand" for="c-42874947">[2 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;course.fast.ai&#x2F;" rel="nofollow">https:&#x2F;&#x2F;course.fast.ai&#x2F;</a> is the best. From their site:
&quot;
A free course designed for people with some coding experience, who want to learn how to apply deep learning and machine learning to practical problems.
&quot;</div><br/><div id="42875241" class="c"><input type="checkbox" id="c-42875241" checked=""/><div class="controls bullet"><span class="by">c0wb0yc0d3r</span><span>|</span><a href="#42873470">root</a><span>|</span><a href="#42874947">parent</a><span>|</span><a href="#42870507">next</a><span>|</span><label class="collapse" for="c-42875241">[-]</label><label class="expand" for="c-42875241">[1 more]</label></div><br/><div class="children"><div class="content">This is at the top of my lunch time learning list. Not quite what I’ve been envisioning but it’s in the right direction. Thanks!</div><br/></div></div></div></div></div></div><div id="42870507" class="c"><input type="checkbox" id="c-42870507" checked=""/><div class="controls bullet"><span class="by">Lerc</span><span>|</span><a href="#42873470">prev</a><span>|</span><a href="#42875328">next</a><span>|</span><label class="collapse" for="c-42870507">[-]</label><label class="expand" for="c-42870507">[1 more]</label></div><br/><div class="children"><div class="content">The example story is interesting.<p>I have made my own implementation from scratch with my own multi-channel tokeniser, each channel gets its own embedding table 32768, 256,256, 64, and 4.  Which are summed along with the position encoding.<p>Yet with all of those differences, my stories have Lily as a protagonist often enough that I thought I had a bug somewhere.<p>Might have to check tinystories for name distribution.<p>Most questionable output from mine so far:<p>&quot;one day, a naughty man and a little boy went to the park place to find some new things.&quot;</div><br/></div></div><div id="42875328" class="c"><input type="checkbox" id="c-42875328" checked=""/><div class="controls bullet"><span class="by">mkagenius</span><span>|</span><a href="#42870507">prev</a><span>|</span><a href="#42871422">next</a><span>|</span><label class="collapse" for="c-42875328">[-]</label><label class="expand" for="c-42875328">[3 more]</label></div><br/><div class="children"><div class="content">Looks like a rip off of - <a href="https:&#x2F;&#x2F;github.com&#x2F;PraveenRaja42&#x2F;Tiny-Stories-GPT">https:&#x2F;&#x2F;github.com&#x2F;PraveenRaja42&#x2F;Tiny-Stories-GPT</a><p>without any credits to above or TinyStories paper.</div><br/><div id="42875745" class="c"><input type="checkbox" id="c-42875745" checked=""/><div class="controls bullet"><span class="by">yorwba</span><span>|</span><a href="#42875328">parent</a><span>|</span><a href="#42871422">next</a><span>|</span><label class="collapse" for="c-42875745">[-]</label><label class="expand" for="c-42875745">[2 more]</label></div><br/><div class="children"><div class="content">The implementations are different, so I don&#x27;t think you can consider it a rip-off.</div><br/><div id="42875979" class="c"><input type="checkbox" id="c-42875979" checked=""/><div class="controls bullet"><span class="by">mkagenius</span><span>|</span><a href="#42875328">root</a><span>|</span><a href="#42875745">parent</a><span>|</span><a href="#42871422">next</a><span>|</span><label class="collapse" for="c-42875979">[-]</label><label class="expand" for="c-42875979">[1 more]</label></div><br/><div class="children"><div class="content">Why do you say implementations are different?</div><br/></div></div></div></div></div></div><div id="42871422" class="c"><input type="checkbox" id="c-42871422" checked=""/><div class="controls bullet"><span class="by">brap</span><span>|</span><a href="#42875328">prev</a><span>|</span><a href="#42874553">next</a><span>|</span><label class="collapse" for="c-42871422">[-]</label><label class="expand" for="c-42871422">[3 more]</label></div><br/><div class="children"><div class="content">It’s interesting that technology so transformative is only a few hundred lines of code (excluding underlying frameworks and such).<p>How big would you guess state of the art models are, in terms of lines of code?</div><br/><div id="42871800" class="c"><input type="checkbox" id="c-42871800" checked=""/><div class="controls bullet"><span class="by">miki123211</span><span>|</span><a href="#42871422">parent</a><span>|</span><a href="#42873817">next</a><span>|</span><label class="collapse" for="c-42871800">[-]</label><label class="expand" for="c-42871800">[1 more]</label></div><br/><div class="children"><div class="content">Llama2 inference can be implemented in 900-ish lines of dependency-free C89, with no code golfing[1]. More modern architectures (at least the dense, non-MoE models) aren&#x27;t that much more complicated.<p>That code is CPU only, uses float32 everywhere and doesn&#x27;t do any optimizations, so it&#x27;s not realistically usable for models beyond 100m params, but that&#x27;s how much it takes to run the core algorithm.<p>[1] <a href="https:&#x2F;&#x2F;github.com&#x2F;karpathy&#x2F;llama2.c">https:&#x2F;&#x2F;github.com&#x2F;karpathy&#x2F;llama2.c</a></div><br/></div></div><div id="42873817" class="c"><input type="checkbox" id="c-42873817" checked=""/><div class="controls bullet"><span class="by">hatthew</span><span>|</span><a href="#42871422">parent</a><span>|</span><a href="#42871800">prev</a><span>|</span><a href="#42874553">next</a><span>|</span><label class="collapse" for="c-42873817">[-]</label><label class="expand" for="c-42873817">[1 more]</label></div><br/><div class="children"><div class="content">A minimal hardcoded definition of the structure: probably a few hundred lines.<p>The actual definition, including reusable components, optional features, and flexibility for experimentation: probably a few thousand.<p>The code needed to train the model, including all the data pipelines and management, training framework, optimization tricks, etc.: tens of thousands.<p>The whole codebase, including experiments, training&#x2F;inference monitoring, modules that didn&#x27;t make it into the final architecture, unit tests, and all custom code written to support everything mentioned so far: hundreds of thousands.</div><br/></div></div></div></div><div id="42869908" class="c"><input type="checkbox" id="c-42869908" checked=""/><div class="controls bullet"><span class="by">ks2048</span><span>|</span><a href="#42874553">prev</a><span>|</span><a href="#42871218">next</a><span>|</span><label class="collapse" for="c-42869908">[-]</label><label class="expand" for="c-42869908">[1 more]</label></div><br/><div class="children"><div class="content">So, this has nothing to do with &quot;SmolLM&quot; - a set of models (with data, training recipes, etc) released by HuggingFace? <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;blog&#x2F;smollm" rel="nofollow">https:&#x2F;&#x2F;huggingface.co&#x2F;blog&#x2F;smollm</a></div><br/></div></div><div id="42871218" class="c"><input type="checkbox" id="c-42871218" checked=""/><div class="controls bullet"><span class="by">antirez</span><span>|</span><a href="#42869908">prev</a><span>|</span><a href="#42870238">next</a><span>|</span><label class="collapse" for="c-42871218">[-]</label><label class="expand" for="c-42871218">[3 more]</label></div><br/><div class="children"><div class="content">No cpu &#x2F; mps support to train on Macs, apparently.</div><br/><div id="42871405" class="c"><input type="checkbox" id="c-42871405" checked=""/><div class="controls bullet"><span class="by">leopoldj</span><span>|</span><a href="#42871218">parent</a><span>|</span><a href="#42870238">next</a><span>|</span><label class="collapse" for="c-42871405">[-]</label><label class="expand" for="c-42871405">[2 more]</label></div><br/><div class="children"><div class="content">You should be able to make a few small changes to support &quot;mps&quot;.<p>In TrainingConfig set the device to &quot;mps&quot;. The run training.<p>In sample.py modify parse_args() and add support for mps as a possible value for the --device argument.</div><br/><div id="42871652" class="c"><input type="checkbox" id="c-42871652" checked=""/><div class="controls bullet"><span class="by">antirez</span><span>|</span><a href="#42871218">root</a><span>|</span><a href="#42871405">parent</a><span>|</span><a href="#42870238">next</a><span>|</span><label class="collapse" for="c-42871652">[-]</label><label class="expand" for="c-42871652">[1 more]</label></div><br/><div class="children"><div class="content">Thanks! I&#x27;ll try. I didn&#x27;t bother believing that if this was developed heavily on CUDA, it was likely going to use kernels that were missing in MPS.</div><br/></div></div></div></div></div></div><div id="42870238" class="c"><input type="checkbox" id="c-42870238" checked=""/><div class="controls bullet"><span class="by">nostradumbasp</span><span>|</span><a href="#42871218">prev</a><span>|</span><a href="#42870754">next</a><span>|</span><label class="collapse" for="c-42870238">[-]</label><label class="expand" for="c-42870238">[1 more]</label></div><br/><div class="children"><div class="content">Cute! Keep making fun things.</div><br/></div></div><div id="42870754" class="c"><input type="checkbox" id="c-42870754" checked=""/><div class="controls bullet"><span class="by">spidermonkey23</span><span>|</span><a href="#42870238">prev</a><span>|</span><a href="#42872401">next</a><span>|</span><label class="collapse" for="c-42870754">[-]</label><label class="expand" for="c-42870754">[1 more]</label></div><br/><div class="children"><div class="content">Is there anything that can run locally on mobile in temrux</div><br/></div></div><div id="42872401" class="c"><input type="checkbox" id="c-42872401" checked=""/><div class="controls bullet"><span class="by">quantadev</span><span>|</span><a href="#42870754">prev</a><span>|</span><a href="#42870317">next</a><span>|</span><label class="collapse" for="c-42872401">[-]</label><label class="expand" for="c-42872401">[1 more]</label></div><br/><div class="children"><div class="content">I noticed several people mentioned Karpathy already, but I wanted to include that his tiny &quot;Micrograd&quot; project (see Youtube Video and GitHub) is a great introduction to Neural Nets (Multilayer Peceptron), which is at the core of [most] machine learning of course.</div><br/></div></div><div id="42870317" class="c"><input type="checkbox" id="c-42870317" checked=""/><div class="controls bullet"><span class="by">the_real_cher</span><span>|</span><a href="#42872401">prev</a><span>|</span><label class="collapse" for="c-42870317">[-]</label><label class="expand" for="c-42870317">[3 more]</label></div><br/><div class="children"><div class="content">Any body have any good readings they read and liked to kind of understand what is going on with how this works?</div><br/><div id="42871007" class="c"><input type="checkbox" id="c-42871007" checked=""/><div class="controls bullet"><span class="by">fragmede</span><span>|</span><a href="#42870317">parent</a><span>|</span><label class="collapse" for="c-42871007">[-]</label><label class="expand" for="c-42871007">[2 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;spreadsheets-are-all-you-need.ai&#x2F;" rel="nofollow">https:&#x2F;&#x2F;spreadsheets-are-all-you-need.ai&#x2F;</a></div><br/><div id="42874308" class="c"><input type="checkbox" id="c-42874308" checked=""/><div class="controls bullet"><span class="by">ianand</span><span>|</span><a href="#42870317">root</a><span>|</span><a href="#42871007">parent</a><span>|</span><label class="collapse" for="c-42874308">[-]</label><label class="expand" for="c-42874308">[1 more]</label></div><br/><div class="children"><div class="content">hey, creator of spreadsheets-are-all-you-need.ai here. Thanks for mentioning!<p>I now have a web version of GPT2 implemented in pure JavaScript for web developers at <a href="https:&#x2F;&#x2F;spreadsheets-are-all-you-need.ai&#x2F;gpt2&#x2F;" rel="nofollow">https:&#x2F;&#x2F;spreadsheets-are-all-you-need.ai&#x2F;gpt2&#x2F;</a>.<p>The best part is that you can debug and step through it in the browser dev tools: <a href="https:&#x2F;&#x2F;youtube.com&#x2F;watch?v=cXKJJEzIGy4" rel="nofollow">https:&#x2F;&#x2F;youtube.com&#x2F;watch?v=cXKJJEzIGy4</a> (100 second demo). Every single step is is in plain vanilla client side JavaScript (even the matrix multiplications). You don&#x27;t need python, etc. Heck, you don&#x27;t even have to leave your browser.<p>I recently did an updated version of my talk with it for JavaScript developers here: <a href="https:&#x2F;&#x2F;youtube.com&#x2F;watch?v=siGKUyTk9M0" rel="nofollow">https:&#x2F;&#x2F;youtube.com&#x2F;watch?v=siGKUyTk9M0</a> (52 min). That should give you a basic grounding on what&#x27;s happening inside a Transformer.</div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>