<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1708074052207" as="style"/><link rel="stylesheet" href="styles.css?v=1708074052207"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://bclarkson-code.github.io/posts/llm-from-scratch-scalar-autograd/post.html">Building an LLM from Scratch: Automatic Differentiation (2023)</a> <span class="domain">(<a href="https://bclarkson-code.github.io">bclarkson-code.github.io</a>)</span></div><div class="subtext"><span>netwrt</span> | <span>15 comments</span></div><br/><div><div id="39389530" class="c"><input type="checkbox" id="c-39389530" checked=""/><div class="controls bullet"><span class="by">cafaxo</span><span>|</span><a href="#39390345">next</a><span>|</span><label class="collapse" for="c-39389530">[-]</label><label class="expand" for="c-39389530">[3 more]</label></div><br/><div class="children"><div class="content">I did a similar thing for Julia:
Llama2.jl contains vanilla Julia code [1] for training small Llama2-style models on the CPU.<p>[1] <a href="https:&#x2F;&#x2F;github.com&#x2F;cafaxo&#x2F;Llama2.jl&#x2F;tree&#x2F;master&#x2F;src&#x2F;training">https:&#x2F;&#x2F;github.com&#x2F;cafaxo&#x2F;Llama2.jl&#x2F;tree&#x2F;master&#x2F;src&#x2F;training</a></div><br/><div id="39394438" class="c"><input type="checkbox" id="c-39394438" checked=""/><div class="controls bullet"><span class="by">3abiton</span><span>|</span><a href="#39389530">parent</a><span>|</span><a href="#39392221">next</a><span>|</span><label class="collapse" for="c-39394438">[-]</label><label class="expand" for="c-39394438">[1 more]</label></div><br/><div class="children"><div class="content">How hard was it to find open source data nowadays? I saw that books3 are already made illegal to train on.</div><br/></div></div><div id="39392221" class="c"><input type="checkbox" id="c-39392221" checked=""/><div class="controls bullet"><span class="by">andxor_</span><span>|</span><a href="#39389530">parent</a><span>|</span><a href="#39394438">prev</a><span>|</span><a href="#39390345">next</a><span>|</span><label class="collapse" for="c-39392221">[-]</label><label class="expand" for="c-39392221">[1 more]</label></div><br/><div class="children"><div class="content">Great stuff. Thanks for sharing.</div><br/></div></div></div></div><div id="39390345" class="c"><input type="checkbox" id="c-39390345" checked=""/><div class="controls bullet"><span class="by">itissid</span><span>|</span><a href="#39389530">prev</a><span>|</span><a href="#39392259">next</a><span>|</span><label class="collapse" for="c-39390345">[-]</label><label class="expand" for="c-39390345">[6 more]</label></div><br/><div class="children"><div class="content">Every one should go through this <i>rite of passage</i> work and get to the &quot;Attention is all you need&quot; implementation. It&#x27;s a world where engineering and the academic papers are very close and reproducible and a must for you to progress in the field.<p>(see also andre karpathys zero to hero nn series on youtube as well its very good and similar to this work)</div><br/><div id="39392031" class="c"><input type="checkbox" id="c-39392031" checked=""/><div class="controls bullet"><span class="by">calebkaiser</span><span>|</span><a href="#39390345">parent</a><span>|</span><a href="#39394549">next</a><span>|</span><label class="collapse" for="c-39392031">[-]</label><label class="expand" for="c-39392031">[2 more]</label></div><br/><div class="children"><div class="content">I would also recommend going through Callum McDougall&#x2F;Neel Nanda&#x27;s fantastic Transformer from Scratch tutorial. It takes a different approach to conceptualizing the model (or at least, it implements it in a way which emphasizes different characteristics of Transformers and self-attention), which I found deeply satisfying when I first explored them.<p><a href="https:&#x2F;&#x2F;arena-ch1-transformers.streamlit.app&#x2F;%5B1.1%5D_Transformer_from_Scratch" rel="nofollow">https:&#x2F;&#x2F;arena-ch1-transformers.streamlit.app&#x2F;%5B1.1%5D_Trans...</a></div><br/><div id="39393950" class="c"><input type="checkbox" id="c-39393950" checked=""/><div class="controls bullet"><span class="by">joshua11</span><span>|</span><a href="#39390345">root</a><span>|</span><a href="#39392031">parent</a><span>|</span><a href="#39394549">next</a><span>|</span><label class="collapse" for="c-39393950">[-]</label><label class="expand" for="c-39393950">[1 more]</label></div><br/><div class="children"><div class="content">Thanks for sharing. This is a nice resource</div><br/></div></div></div></div><div id="39394549" class="c"><input type="checkbox" id="c-39394549" checked=""/><div class="controls bullet"><span class="by">simfoo</span><span>|</span><a href="#39390345">parent</a><span>|</span><a href="#39392031">prev</a><span>|</span><a href="#39391142">next</a><span>|</span><label class="collapse" for="c-39394549">[-]</label><label class="expand" for="c-39394549">[1 more]</label></div><br/><div class="children"><div class="content">That magic moment in Karpathys first video when he gets to the loss function and calls backward for the first time - this is when it clicked for me. Highly recommended!</div><br/></div></div><div id="39391142" class="c"><input type="checkbox" id="c-39391142" checked=""/><div class="controls bullet"><span class="by">bschne</span><span>|</span><a href="#39390345">parent</a><span>|</span><a href="#39394549">prev</a><span>|</span><a href="#39392337">next</a><span>|</span><label class="collapse" for="c-39391142">[-]</label><label class="expand" for="c-39391142">[1 more]</label></div><br/><div class="children"><div class="content">+1 for Karpathy, the series is really good</div><br/></div></div><div id="39392337" class="c"><input type="checkbox" id="c-39392337" checked=""/><div class="controls bullet"><span class="by">wredue</span><span>|</span><a href="#39390345">parent</a><span>|</span><a href="#39391142">prev</a><span>|</span><a href="#39392259">next</a><span>|</span><label class="collapse" for="c-39392337">[-]</label><label class="expand" for="c-39392337">[1 more]</label></div><br/><div class="children"><div class="content">Is this YouTube series also “from scratch (but not really)”<p>Edit - it is. Not to talk down on the series. I’m sure it’s good, but it is actually “LLM with PyTorch”.<p>Edit - I looked again and I was actually not correct. He does ultimately use frameworks, but gives some early talk about how those function under the hood.</div><br/></div></div></div></div><div id="39392259" class="c"><input type="checkbox" id="c-39392259" checked=""/><div class="controls bullet"><span class="by">andxor_</span><span>|</span><a href="#39390345">prev</a><span>|</span><a href="#39391704">next</a><span>|</span><label class="collapse" for="c-39392259">[-]</label><label class="expand" for="c-39392259">[1 more]</label></div><br/><div class="children"><div class="content">Very well written. AD is like magic and this is a good exposition on the basic building block.<p>I quite like Jeremy&#x27;s approach: <a href="https:&#x2F;&#x2F;nbviewer.org&#x2F;github&#x2F;fastai&#x2F;fastbook&#x2F;blob&#x2F;master&#x2F;17_foundations.ipynb" rel="nofollow">https:&#x2F;&#x2F;nbviewer.org&#x2F;github&#x2F;fastai&#x2F;fastbook&#x2F;blob&#x2F;master&#x2F;17_f...</a><p>It shows a very simple &quot;Pythonic&quot; approach to assemble gradient of a composition of functions from the gradients of the components.</div><br/></div></div><div id="39391704" class="c"><input type="checkbox" id="c-39391704" checked=""/><div class="controls bullet"><span class="by">nqzero</span><span>|</span><a href="#39392259">prev</a><span>|</span><a href="#39388788">next</a><span>|</span><label class="collapse" for="c-39391704">[-]</label><label class="expand" for="c-39391704">[2 more]</label></div><br/><div class="children"><div class="content">is there an existing SLM that resembles an LLM in architecture that includes the code for training it ?<p>i realize the cost and time to train may be prohibitive and that quality on general english might be very limited, but is the code itself available ?</div><br/><div id="39392178" class="c"><input type="checkbox" id="c-39392178" checked=""/><div class="controls bullet"><span class="by">sva_</span><span>|</span><a href="#39391704">parent</a><span>|</span><a href="#39388788">next</a><span>|</span><label class="collapse" for="c-39392178">[-]</label><label class="expand" for="c-39392178">[1 more]</label></div><br/><div class="children"><div class="content">Not sure what you mean with SLM, but <a href="https:&#x2F;&#x2F;github.com&#x2F;karpathy&#x2F;nanoGPT">https:&#x2F;&#x2F;github.com&#x2F;karpathy&#x2F;nanoGPT</a></div><br/></div></div></div></div><div id="39388788" class="c"><input type="checkbox" id="c-39388788" checked=""/><div class="controls bullet"><span class="by">asgraham</span><span>|</span><a href="#39391704">prev</a><span>|</span><label class="collapse" for="c-39388788">[-]</label><label class="expand" for="c-39388788">[2 more]</label></div><br/><div class="children"><div class="content">As a chronic premature optimizer my first reaction was, &quot;Is this even possible in vanilla python???&quot; Obviously it&#x27;s <i>possible</i>, but can you train an LLM before the heat death of the universe? A perceptron, sure, of course. A deep learning model, plausible if it&#x27;s not too deep. But a <i>large</i> language model? I.e. the kind of LLM necessary for &quot;from vanilla python to functional coding assistant.&quot;<p>But obviously the author already thought of that. The source repo has a great motto: &quot;It don&#x27;t go fast but it do be goin&#x27;&quot; [1]<p>I love the idea of the project and I&#x27;m curious to see what the endgame runtime will be.<p>[1] <a href="https:&#x2F;&#x2F;github.com&#x2F;bclarkson-code&#x2F;Tricycle">https:&#x2F;&#x2F;github.com&#x2F;bclarkson-code&#x2F;Tricycle</a></div><br/><div id="39389624" class="c"><input type="checkbox" id="c-39389624" checked=""/><div class="controls bullet"><span class="by">gkbrk</span><span>|</span><a href="#39388788">parent</a><span>|</span><label class="collapse" for="c-39389624">[-]</label><label class="expand" for="c-39389624">[1 more]</label></div><br/><div class="children"><div class="content">Why wouldn&#x27;t it be possible? You can generate machine code with Python and call into it with ctypes. All your deep learning code is still in Python, but in the runtime it gets JIT compiled into something faster.</div><br/></div></div></div></div></div></div></div></div></div></body></html>