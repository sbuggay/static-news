<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1694422870094" as="style"/><link rel="stylesheet" href="styles.css?v=1694422870094"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/Yifan-Song793/RestGPT">RestGPT</a>Â <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>omarfarooq</span> | <span>41 comments</span></div><br/><div><div id="37464039" class="c"><input type="checkbox" id="c-37464039" checked=""/><div class="controls bullet"><span class="by">pplonski86</span><span>|</span><a href="#37463432">next</a><span>|</span><label class="collapse" for="c-37464039">[-]</label><label class="expand" for="c-37464039">[1 more]</label></div><br/><div class="children"><div class="content">How RestGPT differs from ToolLLM or Gorilla?<p>papers:<p>1. ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2307.16789" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2307.16789</a><p>2. Gorilla: Large Language Model Connected with Massive APIs <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2305.15334" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2305.15334</a></div><br/></div></div><div id="37463432" class="c"><input type="checkbox" id="c-37463432" checked=""/><div class="controls bullet"><span class="by">two_in_one</span><span>|</span><a href="#37464039">prev</a><span>|</span><a href="#37462548">next</a><span>|</span><label class="collapse" for="c-37463432">[-]</label><label class="expand" for="c-37463432">[11 more]</label></div><br/><div class="children"><div class="content">The problem here is where these actions come from. Generic LLM cannot generate correct actions in many (if not most) real life cases. So, it will have to learn, and LLMs aren&#x27;t good at learning. For example: &quot;I&#x27;m tired, play my favorite&quot;. The action depends on _who_ is saying and on what&#x27;s going on right now. There may be someone sleeping, or watching TV. I&#x27;m afraid that acceptable solution is much more complicated.</div><br/><div id="37464277" class="c"><input type="checkbox" id="c-37464277" checked=""/><div class="controls bullet"><span class="by">pplonski86</span><span>|</span><a href="#37463432">parent</a><span>|</span><a href="#37463685">next</a><span>|</span><label class="collapse" for="c-37464277">[-]</label><label class="expand" for="c-37464277">[2 more]</label></div><br/><div class="children"><div class="content">I think this can be easily fixed, if LLM can do notes on what&#x27;s going on. If it will have additional context before the prompt:<p>```<p>You are home assistant. Here is information what&#x27;s going on in the house:<p>It&#x27;s 4PM.
Bob likes Chopin Fantaisie-Impromptu.
Alice likes Mozart Rondo in D.
Bob is in the house. Alice will be back from office at 5PM.<p>You get a prompt:
I&#x27;m tired, play my favorite<p>```<p>For the above input any LLM will play Chopin.</div><br/><div id="37464612" class="c"><input type="checkbox" id="c-37464612" checked=""/><div class="controls bullet"><span class="by">troupo</span><span>|</span><a href="#37463432">root</a><span>|</span><a href="#37464277">parent</a><span>|</span><a href="#37463685">next</a><span>|</span><label class="collapse" for="c-37464612">[-]</label><label class="expand" for="c-37464612">[1 more]</label></div><br/><div class="children"><div class="content">Where is that input coming from?</div><br/></div></div></div></div><div id="37463685" class="c"><input type="checkbox" id="c-37463685" checked=""/><div class="controls bullet"><span class="by">pmx</span><span>|</span><a href="#37463432">parent</a><span>|</span><a href="#37464277">prev</a><span>|</span><a href="#37462548">next</a><span>|</span><label class="collapse" for="c-37463685">[-]</label><label class="expand" for="c-37463685">[8 more]</label></div><br/><div class="children"><div class="content">DO we have to expect _that_ level of understanding from the agent, though? If my wife said that to me, I may have a good chance of queuing up the song she has in mind, but anyone else? No chance. I don&#x27;t expect tools like this to be able to understand cryptic requests and always come to the right answer. I&#x27;m happy if I can request a song or an action, or anything else in the same way i might ask another human who doesn&#x27;t know me intimately.</div><br/><div id="37463842" class="c"><input type="checkbox" id="c-37463842" checked=""/><div class="controls bullet"><span class="by">swexbe</span><span>|</span><a href="#37463432">root</a><span>|</span><a href="#37463685">parent</a><span>|</span><a href="#37462548">next</a><span>|</span><label class="collapse" for="c-37463842">[-]</label><label class="expand" for="c-37463842">[7 more]</label></div><br/><div class="children"><div class="content">If not, how is this more useful than something like Siri?</div><br/><div id="37464027" class="c"><input type="checkbox" id="c-37464027" checked=""/><div class="controls bullet"><span class="by">og_kalu</span><span>|</span><a href="#37463432">root</a><span>|</span><a href="#37463842">parent</a><span>|</span><a href="#37462548">next</a><span>|</span><label class="collapse" for="c-37464027">[-]</label><label class="expand" for="c-37464027">[6 more]</label></div><br/><div class="children"><div class="content">Natural language understanding. Siri doesn&#x27;t get context at all. You can twist unstructed data or requests however you like and the LLM will deal with it just fine.<p>&quot;Play my favorite&quot; is just a knowledge problem. If GPT fails there, it&#x27;s because it doesn&#x27;t know your favorite, not because it can&#x27;t parse the request or understand what you need it to do.<p>You <i>have</i> to speak certain ways to Siri to get it to do things.<p>Unless specifically hard-coded, Siri will never receive &quot;damn I&#x27;m finding it hard to read&quot; as input as decide to turn on the lights. GPT will.</div><br/><div id="37464286" class="c"><input type="checkbox" id="c-37464286" checked=""/><div class="controls bullet"><span class="by">troupo</span><span>|</span><a href="#37463432">root</a><span>|</span><a href="#37464027">parent</a><span>|</span><a href="#37462548">next</a><span>|</span><label class="collapse" for="c-37464286">[-]</label><label class="expand" for="c-37464286">[5 more]</label></div><br/><div class="children"><div class="content">&quot;Siri doesn&#x27;t get context at all.&quot; and yet immediately &quot;GPT fails there, it&#x27;s because it doesn&#x27;t know your favorite&quot;<p>&quot;Knowing your favorite&quot; <i>is</i> the context.<p>&gt; Unless specifically hard-coded, Siri will never receive &quot;damn I&#x27;m finding it hard to read&quot; as input as decide to turn on the lights. GPT will.<p>Of course it won&#x27;t. You have to very specifically fine tune it to understand what light conditions are, where you are in the house, and what it is you need to turn on.</div><br/><div id="37464563" class="c"><input type="checkbox" id="c-37464563" checked=""/><div class="controls bullet"><span class="by">regularfry</span><span>|</span><a href="#37463432">root</a><span>|</span><a href="#37464286">parent</a><span>|</span><a href="#37464417">next</a><span>|</span><label class="collapse" for="c-37464563">[-]</label><label class="expand" for="c-37464563">[2 more]</label></div><br/><div class="children"><div class="content">&gt; You have to very specifically fine tune it to understand what light conditions are, where you are in the house, and what it is you need to turn on.<p>Where you are in the house and what needs to turn on, at least, is an API query job, not a fine-tuning job.<p>As far as whether it can understand the relevance of lighting to the situation, I just asked ChatGPT 3.5 the question &#x27;Acting as an AI home assistant, if you hear me say &quot;I&#x27;m finding it hard to read&quot;, what actions would you take?&#x27; and &#x27;Adjust the lighting&#x27; was the second option it gave back (after &#x27;ask for clarification&#x27;). I think we&#x27;re there, honestly, we just don&#x27;t have the different parts connected yet.</div><br/><div id="37464603" class="c"><input type="checkbox" id="c-37464603" checked=""/><div class="controls bullet"><span class="by">troupo</span><span>|</span><a href="#37463432">root</a><span>|</span><a href="#37464563">parent</a><span>|</span><a href="#37464417">next</a><span>|</span><label class="collapse" for="c-37464603">[-]</label><label class="expand" for="c-37464603">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Where you are in the house and what needs to turn on, at least, is an API query job, not a fine-tuning job.<p>And that API magically comes form where?<p>&gt; I just asked ChatGPT 3.5 the question &#x27;Acting as an AI home assistant, if you hear me say &quot;I&#x27;m finding it hard to read&quot;, what actions would you take?&#x27;<p>So, basically:<p>- you had to pre-program Chat GPT to act as a home assistant<p>- you had to provide it with specific context and specific phrasing for it<p>- it still failed, asked for clarification, and only then responded<p>And now you have to this song and dance every time you want to coax GPT into doing what you need (and that&#x27;s what RestGPT does).</div><br/></div></div></div></div><div id="37464417" class="c"><input type="checkbox" id="c-37464417" checked=""/><div class="controls bullet"><span class="by">circuit10</span><span>|</span><a href="#37463432">root</a><span>|</span><a href="#37464286">parent</a><span>|</span><a href="#37464563">prev</a><span>|</span><a href="#37462548">next</a><span>|</span><label class="collapse" for="c-37464417">[-]</label><label class="expand" for="c-37464417">[2 more]</label></div><br/><div class="children"><div class="content">They mean context in the sentence or that or that be inferred from âcommon senseâ and without any specific knowledge, I think</div><br/><div id="37464606" class="c"><input type="checkbox" id="c-37464606" checked=""/><div class="controls bullet"><span class="by">troupo</span><span>|</span><a href="#37463432">root</a><span>|</span><a href="#37464417">parent</a><span>|</span><a href="#37462548">next</a><span>|</span><label class="collapse" for="c-37464606">[-]</label><label class="expand" for="c-37464606">[1 more]</label></div><br/><div class="children"><div class="content">I hate Siri as much as anyone, but Chat GPT has no context in the &quot;common sense&quot; either.<p>The sibling comment literally says &quot;I had to provide a long-ish sentence as a context&#x2F;programming instructions before it could do anything&quot;. <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37464563">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37464563</a></div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="37462548" class="c"><input type="checkbox" id="c-37462548" checked=""/><div class="controls bullet"><span class="by">behnamoh</span><span>|</span><a href="#37463432">prev</a><span>|</span><a href="#37463220">next</a><span>|</span><label class="collapse" for="c-37462548">[-]</label><label class="expand" for="c-37462548">[9 more]</label></div><br/><div class="children"><div class="content">It seems after 1-2 years that the true power of LLMs is in DevOps. I got pretty excited when I tried GPT-3 (completion model), but as time went by and OpenAI shifted to chat models, we lost control over the LLM part and found new meaning in taking whatever model OpenAI made available as a blackbox and &quot;chained&quot; it to other tools we already had, like data bases, APIs, function calls&#x2F;tools, etc. I&#x27;d say DevOps is exactly where open source is seriously behind; there are decent open source models but it costs so much to self host them, despite the full power and control we have on them (via text generation webui and the like).<p>OpenAI is playing the DevOps game (starting maybe with introduction of ChatML). Open source community plays the LLM and benchmarks game. Ironically, the two are converging, meaning that OpenAI&#x27;s models are getting dumber (not the API) thanks to censorship and RLHF, to the point that open source models are even better than some OpenAI models in some aspects. On the other hand, open source models are getting better tooling and DevOps thanks to oobabooga, llama.cpp, etc.<p>I&#x27;m seriously waiting for competitors to change nVidia&#x27;s monopoly in this space. Maybe Apple?</div><br/><div id="37464578" class="c"><input type="checkbox" id="c-37464578" checked=""/><div class="controls bullet"><span class="by">sam_goody</span><span>|</span><a href="#37462548">parent</a><span>|</span><a href="#37463206">next</a><span>|</span><label class="collapse" for="c-37464578">[-]</label><label class="expand" for="c-37464578">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I&#x27;m seriously waiting for competitors to change nVidia&#x27;s monopoly in this space. Maybe Apple?<p>I would have thought AMD is the obvious contender. They are #2 in GPU&#x27;s, they have formidable programming talent (based on their advances with Ryzen vs Intel) and they have targeted AI as their goal.<p>Am I missing something?</div><br/></div></div><div id="37463206" class="c"><input type="checkbox" id="c-37463206" checked=""/><div class="controls bullet"><span class="by">antupis</span><span>|</span><a href="#37462548">parent</a><span>|</span><a href="#37464578">prev</a><span>|</span><a href="#37463220">next</a><span>|</span><label class="collapse" for="c-37463206">[-]</label><label class="expand" for="c-37463206">[7 more]</label></div><br/><div class="children"><div class="content">I think currently M2 max is best bang for buck running interface in open source model. But use case is so niche that Apple probably doesn&#x27;t actively start supporting open source models. In the long run I hope some smaller company gets shit together and starts competing with NVIDIA.</div><br/><div id="37463562" class="c"><input type="checkbox" id="c-37463562" checked=""/><div class="controls bullet"><span class="by">rankun203</span><span>|</span><a href="#37462548">root</a><span>|</span><a href="#37463206">parent</a><span>|</span><a href="#37463373">next</a><span>|</span><label class="collapse" for="c-37463562">[-]</label><label class="expand" for="c-37463562">[1 more]</label></div><br/><div class="children"><div class="content">The GPU support in ML frameworks however is really not impressive. I have a Macbook with M1 Max 64G RAM, I can load a 7b model for fine-tuning (Huggingface Trainer, Pytorch, MPS), but the speed is just too slow, can only reach to 50% the speed of an i5-12500 CPU in my tests.</div><br/></div></div><div id="37463373" class="c"><input type="checkbox" id="c-37463373" checked=""/><div class="controls bullet"><span class="by">behnamoh</span><span>|</span><a href="#37462548">root</a><span>|</span><a href="#37463206">parent</a><span>|</span><a href="#37463562">prev</a><span>|</span><a href="#37463220">next</a><span>|</span><label class="collapse" for="c-37463373">[-]</label><label class="expand" for="c-37463373">[5 more]</label></div><br/><div class="children"><div class="content">At $6,000, how is M2 Max the best bang for the buck?!<p>One could get two used 3090s and setup a decent PC at lower prices.</div><br/><div id="37463447" class="c"><input type="checkbox" id="c-37463447" checked=""/><div class="controls bullet"><span class="by">kiratp</span><span>|</span><a href="#37462548">root</a><span>|</span><a href="#37463373">parent</a><span>|</span><a href="#37463769">next</a><span>|</span><label class="collapse" for="c-37463447">[-]</label><label class="expand" for="c-37463447">[3 more]</label></div><br/><div class="children"><div class="content">Two 3090s donât have 96GB of VRAM</div><br/><div id="37463561" class="c"><input type="checkbox" id="c-37463561" checked=""/><div class="controls bullet"><span class="by">behnamoh</span><span>|</span><a href="#37462548">root</a><span>|</span><a href="#37463447">parent</a><span>|</span><a href="#37463769">next</a><span>|</span><label class="collapse" for="c-37463561">[-]</label><label class="expand" for="c-37463561">[2 more]</label></div><br/><div class="children"><div class="content">That&#x27;s true. But OTOH, one can&#x27;t easily upgrade Macs.</div><br/><div id="37463927" class="c"><input type="checkbox" id="c-37463927" checked=""/><div class="controls bullet"><span class="by">aarong11</span><span>|</span><a href="#37462548">root</a><span>|</span><a href="#37463561">parent</a><span>|</span><a href="#37463769">next</a><span>|</span><label class="collapse" for="c-37463927">[-]</label><label class="expand" for="c-37463927">[1 more]</label></div><br/><div class="children"><div class="content">With 96gb of VRAM, will you really need to? Personally I think apple servers might be adopted for AI and LLM workloads soon.</div><br/></div></div></div></div></div></div><div id="37463769" class="c"><input type="checkbox" id="c-37463769" checked=""/><div class="controls bullet"><span class="by">antupis</span><span>|</span><a href="#37462548">root</a><span>|</span><a href="#37463373">parent</a><span>|</span><a href="#37463447">prev</a><span>|</span><a href="#37463220">next</a><span>|</span><label class="collapse" for="c-37463769">[-]</label><label class="expand" for="c-37463769">[1 more]</label></div><br/><div class="children"><div class="content">M2 max studio is 2000$.</div><br/></div></div></div></div></div></div></div></div><div id="37463220" class="c"><input type="checkbox" id="c-37463220" checked=""/><div class="controls bullet"><span class="by">stevage</span><span>|</span><a href="#37462548">prev</a><span>|</span><a href="#37464537">next</a><span>|</span><label class="collapse" for="c-37463220">[-]</label><label class="expand" for="c-37463220">[2 more]</label></div><br/><div class="children"><div class="content">&gt; WARNING: this will remove all your data from spotify!<p>That is quite the caveat.</div><br/><div id="37463374" class="c"><input type="checkbox" id="c-37463374" checked=""/><div class="controls bullet"><span class="by">seanthemon</span><span>|</span><a href="#37463220">parent</a><span>|</span><a href="#37464537">next</a><span>|</span><label class="collapse" for="c-37463374">[-]</label><label class="expand" for="c-37463374">[1 more]</label></div><br/><div class="children"><div class="content">I feel like that script needs a few &#x27;are you completely sure?&#x27; Prompts</div><br/></div></div></div></div><div id="37464537" class="c"><input type="checkbox" id="c-37464537" checked=""/><div class="controls bullet"><span class="by">amelius</span><span>|</span><a href="#37463220">prev</a><span>|</span><a href="#37462264">next</a><span>|</span><label class="collapse" for="c-37464537">[-]</label><label class="expand" for="c-37464537">[2 more]</label></div><br/><div class="children"><div class="content">Waiting for BashGPT.<p>It could use curl to do REST calls too, and a lot more.</div><br/><div id="37464542" class="c"><input type="checkbox" id="c-37464542" checked=""/><div class="controls bullet"><span class="by">pplonski86</span><span>|</span><a href="#37464537">parent</a><span>|</span><a href="#37462264">next</a><span>|</span><label class="collapse" for="c-37464542">[-]</label><label class="expand" for="c-37464542">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;github.com&#x2F;KillianLucas&#x2F;open-interpreter">https:&#x2F;&#x2F;github.com&#x2F;KillianLucas&#x2F;open-interpreter</a></div><br/></div></div></div></div><div id="37462264" class="c"><input type="checkbox" id="c-37462264" checked=""/><div class="controls bullet"><span class="by">salamo</span><span>|</span><a href="#37464537">prev</a><span>|</span><a href="#37462387">next</a><span>|</span><label class="collapse" for="c-37462264">[-]</label><label class="expand" for="c-37462264">[3 more]</label></div><br/><div class="children"><div class="content">It&#x27;s actually really interesting to see GOFAI techniques like planning used in conjunction with LLMs.</div><br/><div id="37462397" class="c"><input type="checkbox" id="c-37462397" checked=""/><div class="controls bullet"><span class="by">cscurmudgeon</span><span>|</span><a href="#37462264">parent</a><span>|</span><a href="#37462419">prev</a><span>|</span><a href="#37462387">next</a><span>|</span><label class="collapse" for="c-37462397">[-]</label><label class="expand" for="c-37462397">[1 more]</label></div><br/><div class="children"><div class="content">I see a GOFAI resurgence thanks to LLMs.</div><br/></div></div></div></div><div id="37462387" class="c"><input type="checkbox" id="c-37462387" checked=""/><div class="controls bullet"><span class="by">albert_e</span><span>|</span><a href="#37462264">prev</a><span>|</span><a href="#37462641">next</a><span>|</span><label class="collapse" for="c-37462387">[-]</label><label class="expand" for="c-37462387">[3 more]</label></div><br/><div class="children"><div class="content">ChatGPT + Noteable is already powerful to get some work done via API calls (after installing and importing the libraries, writing Python code, managing secrets for authentication etc)<p>There is surely scope to streamline this much further<p>I am very intently watching this space</div><br/><div id="37464085" class="c"><input type="checkbox" id="c-37464085" checked=""/><div class="controls bullet"><span class="by">pplonski86</span><span>|</span><a href="#37462387">parent</a><span>|</span><a href="#37463172">next</a><span>|</span><label class="collapse" for="c-37464085">[-]</label><label class="expand" for="c-37464085">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve seen Noteable+ChatGPT demo, where user can chat with ChatGPT and responses where executed in the Noteable-hosted Python notebook. It was cool!<p>It would be also cool to have such plugin for Google Colab.<p>I hope someone will come with a new way to interact with LLM models other than chat UI. It would make code writing even more faster.</div><br/></div></div><div id="37463172" class="c"><input type="checkbox" id="c-37463172" checked=""/><div class="controls bullet"><span class="by">thelittleone</span><span>|</span><a href="#37462387">parent</a><span>|</span><a href="#37464085">prev</a><span>|</span><a href="#37462641">next</a><span>|</span><label class="collapse" for="c-37463172">[-]</label><label class="expand" for="c-37463172">[1 more]</label></div><br/><div class="children"><div class="content">Interested to learn more (big fan of data stories). Do you have any particular use cases you would recommend to look into?</div><br/></div></div></div></div><div id="37462799" class="c"><input type="checkbox" id="c-37462799" checked=""/><div class="controls bullet"><span class="by">impulser_</span><span>|</span><a href="#37462641">prev</a><span>|</span><a href="#37463111">next</a><span>|</span><label class="collapse" for="c-37462799">[-]</label><label class="expand" for="c-37462799">[1 more]</label></div><br/><div class="children"><div class="content">The examples are pretty lame since you can do what the examples do way faster without using a LLM and paying OpenAI.</div><br/></div></div><div id="37463111" class="c"><input type="checkbox" id="c-37463111" checked=""/><div class="controls bullet"><span class="by">cosbgn</span><span>|</span><a href="#37462799">prev</a><span>|</span><a href="#37462819">next</a><span>|</span><label class="collapse" for="c-37463111">[-]</label><label class="expand" for="c-37463111">[3 more]</label></div><br/><div class="children"><div class="content">This is interesting, I do something similar with unfetch.com - I have some examples on unfetch.com&#x2F;directory - There are a lot of potential use cases for LLm &amp; APIs</div><br/><div id="37464209" class="c"><input type="checkbox" id="c-37464209" checked=""/><div class="controls bullet"><span class="by">pplonski86</span><span>|</span><a href="#37463111">parent</a><span>|</span><a href="#37462819">next</a><span>|</span><label class="collapse" for="c-37464209">[-]</label><label class="expand" for="c-37464209">[2 more]</label></div><br/><div class="children"><div class="content">The service unfetch.com looks cool. Can I run it locally on my machine, not in the cloud? Is it open-source?</div><br/><div id="37464626" class="c"><input type="checkbox" id="c-37464626" checked=""/><div class="controls bullet"><span class="by">cosbgn</span><span>|</span><a href="#37463111">root</a><span>|</span><a href="#37464209">parent</a><span>|</span><a href="#37462819">next</a><span>|</span><label class="collapse" for="c-37464626">[-]</label><label class="expand" for="c-37464626">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not opensouce, even though it&#x27;s something I would like to be able to do soon. We offer enterprise plans, which use LLAMA2 instead of openai and can run on your own cloud (or even locally if you have enough RAM). If you are interested send me an email at c@unfetch.com</div><br/></div></div></div></div></div></div><div id="37462819" class="c"><input type="checkbox" id="c-37462819" checked=""/><div class="controls bullet"><span class="by">venky180</span><span>|</span><a href="#37463111">prev</a><span>|</span><a href="#37462929">next</a><span>|</span><label class="collapse" for="c-37462819">[-]</label><label class="expand" for="c-37462819">[1 more]</label></div><br/><div class="children"><div class="content">How does this compare to agentGPT?</div><br/></div></div><div id="37462929" class="c"><input type="checkbox" id="c-37462929" checked=""/><div class="controls bullet"><span class="by">airstrike</span><span>|</span><a href="#37462819">prev</a><span>|</span><a href="#37462556">next</a><span>|</span><label class="collapse" for="c-37462929">[-]</label><label class="expand" for="c-37462929">[1 more]</label></div><br/><div class="children"><div class="content">Finally a use for my IRC bot</div><br/></div></div><div id="37462556" class="c"><input type="checkbox" id="c-37462556" checked=""/><div class="controls bullet"><span class="by">transcriptase</span><span>|</span><a href="#37462929">prev</a><span>|</span><a href="#37462657">next</a><span>|</span><label class="collapse" for="c-37462556">[-]</label><label class="expand" for="c-37462556">[1 more]</label></div><br/><div class="children"><div class="content">Paging the Google Home teamâ¦</div><br/></div></div><div id="37462657" class="c"><input type="checkbox" id="c-37462657" checked=""/><div class="controls bullet"><span class="by">Obscurity4340</span><span>|</span><a href="#37462556">prev</a><span>|</span><label class="collapse" for="c-37462657">[-]</label><label class="expand" for="c-37462657">[1 more]</label></div><br/><div class="children"><div class="content">Is there any local GPT model available, even if its a bit older? I had heard maybe 3.5 leaked but perhaps I&#x27;m mixing up StableDiffusion?</div><br/></div></div></div></div></div></div></div></body></html>