<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1711530068056" as="style"/><link rel="stylesheet" href="styles.css?v=1711530068056"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://medium.com/@jayphelps/backpressure-explained-the-flow-of-data-through-software-2350b3e77ce7">Backpressure explained – the resisted flow of data through software (2019)</a> <span class="domain">(<a href="https://medium.com">medium.com</a>)</span></div><div class="subtext"><span>genericlemon24</span> | <span>25 comments</span></div><br/><div><div id="39814884" class="c"><input type="checkbox" id="c-39814884" checked=""/><div class="controls bullet"><span class="by">steve_gh</span><span>|</span><a href="#39834926">next</a><span>|</span><label class="collapse" for="c-39814884">[-]</label><label class="expand" for="c-39814884">[2 more]</label></div><br/><div class="children"><div class="content">There is a subtler issue. Even if your average input and output rates are OK, the lumpiness (stochastic variations) in input and processing rates can cause queues to build up.<p>In the simplest example, with &quot;well behaved&quot; arrival and processing rates, and a single server (an M&#x2F;M&#x2F;1 queue), the average queue length is 1&#x2F;(1-mu) where the utilization mu = avg arrival rate &#x2F; avg processing rate. So as the arrival rate approaches the processing rate the avg queue length becomes infinite. In reality, you want to keep the average utilization below 80% to keep queue lengths reasonable.</div><br/><div id="39834091" class="c"><input type="checkbox" id="c-39834091" checked=""/><div class="controls bullet"><span class="by">_3u10</span><span>|</span><a href="#39814884">parent</a><span>|</span><a href="#39834926">next</a><span>|</span><label class="collapse" for="c-39834091">[-]</label><label class="expand" for="c-39834091">[1 more]</label></div><br/><div class="children"><div class="content">Use a LIFO with a timeout. When you find a request that exceeds the timeout clear the lifo.</div><br/></div></div></div></div><div id="39834926" class="c"><input type="checkbox" id="c-39834926" checked=""/><div class="controls bullet"><span class="by">sly010</span><span>|</span><a href="#39814884">prev</a><span>|</span><a href="#39835454">next</a><span>|</span><label class="collapse" for="c-39834926">[-]</label><label class="expand" for="c-39834926">[3 more]</label></div><br/><div class="children"><div class="content">I like the article, but I am not sure that I agree with the terminology: I would not call &quot;buffering&quot; a form of back pressure. Imho there is really only one type of back pressure: the one the author calls &quot;control&quot;. The other 2 are just ways to &quot;release&quot; pressure.</div><br/><div id="39835961" class="c"><input type="checkbox" id="c-39835961" checked=""/><div class="controls bullet"><span class="by">oivey</span><span>|</span><a href="#39834926">parent</a><span>|</span><a href="#39834977">next</a><span>|</span><label class="collapse" for="c-39835961">[-]</label><label class="expand" for="c-39835961">[1 more]</label></div><br/><div class="children"><div class="content">I agree. The author has interpreted “backpressure” to mean pressure from behind, but my understanding of the term is the other direction, like water pooling up at a partially blocked drain. Water is prevented from entering the pipe because the pipe is at capacity.<p>Backpressure is an implicit signal from consumer to producer that there is not enough capacity. It propagates backwards from flow like water in a network of pipes.<p>In their example, the conveyor belt keeps adding chocolates because there is no backpressure. The effect is that Lucy engages in load shedding, and the producer of the chocolates has no say or insight into what happens when that load has to be shed. If there was backpressure, the producer gets to choose what happens.</div><br/></div></div><div id="39834977" class="c"><input type="checkbox" id="c-39834977" checked=""/><div class="controls bullet"><span class="by">sly010</span><span>|</span><a href="#39834926">parent</a><span>|</span><a href="#39835961">prev</a><span>|</span><a href="#39835454">next</a><span>|</span><label class="collapse" for="c-39834977">[-]</label><label class="expand" for="c-39834977">[1 more]</label></div><br/><div class="children"><div class="content">Edit: I think the article also misses one of the most important ways to release pressure. And that is scaling throughput either horizontally (e.g. by adding more servers) or vertically (e.g. by optimization of software)</div><br/></div></div></div></div><div id="39835454" class="c"><input type="checkbox" id="c-39835454" checked=""/><div class="controls bullet"><span class="by">apitman</span><span>|</span><a href="#39834926">prev</a><span>|</span><a href="#39834557">next</a><span>|</span><label class="collapse" for="c-39835454">[-]</label><label class="expand" for="c-39835454">[1 more]</label></div><br/><div class="children"><div class="content">WebSockets is an interesting case where the underlying transport (TCP) provides backpressure for free, but the way the API was designed in browsers throws it away. For example, it&#x27;s trivial to fill your device&#x27;s memory by opening a large local file in your browser and attempting to stream it to a server in a tight WebSocket send loop.<p>I&#x27;m not sure if there was an alternative when WebSockets was designed. Did we even have promises yet?<p>This sort of thing is solved nowadays with WhatWG streams. They&#x27;re a bit verbose to work with but I&#x27;ve been impressed with the design.</div><br/></div></div><div id="39834557" class="c"><input type="checkbox" id="c-39834557" checked=""/><div class="controls bullet"><span class="by">socketcluster</span><span>|</span><a href="#39835454">prev</a><span>|</span><a href="#39834522">next</a><span>|</span><label class="collapse" for="c-39834557">[-]</label><label class="expand" for="c-39834557">[2 more]</label></div><br/><div class="children"><div class="content">In case anyone is interested, I wrote an async&#x2F;await stream library for JavaScript&#x2F;Node.js which supports backpressure management. It&#x27;s heavily tested and used as part of SocketCluster (pub&#x2F;sub SDK) <a href="https:&#x2F;&#x2F;socketcluster.io&#x2F;" rel="nofollow">https:&#x2F;&#x2F;socketcluster.io&#x2F;</a> which is also heavily tested.</div><br/><div id="39835743" class="c"><input type="checkbox" id="c-39835743" checked=""/><div class="controls bullet"><span class="by">plugin-baby</span><span>|</span><a href="#39834557">parent</a><span>|</span><a href="#39834522">next</a><span>|</span><label class="collapse" for="c-39835743">[-]</label><label class="expand" for="c-39835743">[1 more]</label></div><br/><div class="children"><div class="content">Please share.</div><br/></div></div></div></div><div id="39834522" class="c"><input type="checkbox" id="c-39834522" checked=""/><div class="controls bullet"><span class="by">Havoc</span><span>|</span><a href="#39834557">prev</a><span>|</span><a href="#39834277">next</a><span>|</span><label class="collapse" for="c-39834522">[-]</label><label class="expand" for="c-39834522">[1 more]</label></div><br/><div class="children"><div class="content">Thanks. Heard the terms somewhere recent in that awkward usage “built in back pressure” and was suitably confused</div><br/></div></div><div id="39834277" class="c"><input type="checkbox" id="c-39834277" checked=""/><div class="controls bullet"><span class="by">tootie</span><span>|</span><a href="#39834522">prev</a><span>|</span><a href="#39834249">next</a><span>|</span><label class="collapse" for="c-39834277">[-]</label><label class="expand" for="c-39834277">[7 more]</label></div><br/><div class="children"><div class="content">Isn&#x27;t the ideal solution to make the throttled system faster? Like autoscale horizontally and&#x2F;or vertically, sharding or just writing better code? Everything in this article is about to cope with back pressure but solving is frequently possible.</div><br/><div id="39834639" class="c"><input type="checkbox" id="c-39834639" checked=""/><div class="controls bullet"><span class="by">jcgrillo</span><span>|</span><a href="#39834277">parent</a><span>|</span><a href="#39835979">next</a><span>|</span><label class="collapse" for="c-39834639">[-]</label><label class="expand" for="c-39834639">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;ll bet your backpressure mechanism can react at least an order of magnitude faster than your scaling mechanism.</div><br/><div id="39835059" class="c"><input type="checkbox" id="c-39835059" checked=""/><div class="controls bullet"><span class="by">vrosas</span><span>|</span><a href="#39834277">root</a><span>|</span><a href="#39834639">parent</a><span>|</span><a href="#39835979">next</a><span>|</span><label class="collapse" for="c-39835059">[-]</label><label class="expand" for="c-39835059">[1 more]</label></div><br/><div class="children"><div class="content">Serverless systems are pretty decent at scaling quickly these days. The problem is rarely lack of servers in my experience, though. You usually run out of database connections or some other bottleneck first.</div><br/></div></div></div></div><div id="39835979" class="c"><input type="checkbox" id="c-39835979" checked=""/><div class="controls bullet"><span class="by">oivey</span><span>|</span><a href="#39834277">parent</a><span>|</span><a href="#39834639">prev</a><span>|</span><a href="#39834684">next</a><span>|</span><label class="collapse" for="c-39835979">[-]</label><label class="expand" for="c-39835979">[1 more]</label></div><br/><div class="children"><div class="content">It is in general never possible because if your load can scale infinitely, then there won’t ever be enough compute to satisfy it. In practice, you may be able to apply some assumptions to bound the amount of compute necessary. It is still almost always good to have a plan on how to shed load if your assumptions fail. Systems built without this are prone to failing catastrophically.</div><br/></div></div><div id="39834684" class="c"><input type="checkbox" id="c-39834684" checked=""/><div class="controls bullet"><span class="by">photonthug</span><span>|</span><a href="#39834277">parent</a><span>|</span><a href="#39835979">prev</a><span>|</span><a href="#39834847">next</a><span>|</span><label class="collapse" for="c-39834684">[-]</label><label class="expand" for="c-39834684">[1 more]</label></div><br/><div class="children"><div class="content">In practice, yeah, this is the fix in most systems because in a microservice context it would feel gross to have a slow consumer reach out and throttle a fast producer.<p>It’s still important to understand though because autoscaling has its own back pressure that you run into eventually.  Accounts may have quotas or regions might be out of a given instance type, or out of a type at your preference spot price.</div><br/></div></div><div id="39834847" class="c"><input type="checkbox" id="c-39834847" checked=""/><div class="controls bullet"><span class="by">_3u10</span><span>|</span><a href="#39834277">parent</a><span>|</span><a href="#39834684">prev</a><span>|</span><a href="#39835062">next</a><span>|</span><label class="collapse" for="c-39834847">[-]</label><label class="expand" for="c-39834847">[1 more]</label></div><br/><div class="children"><div class="content">Ideally yes, in practice… no.<p>In reality you hit amdahl’s law pretty quickly.</div><br/></div></div><div id="39835062" class="c"><input type="checkbox" id="c-39835062" checked=""/><div class="controls bullet"><span class="by">convolvatron</span><span>|</span><a href="#39834277">parent</a><span>|</span><a href="#39834847">prev</a><span>|</span><a href="#39834249">next</a><span>|</span><label class="collapse" for="c-39835062">[-]</label><label class="expand" for="c-39835062">[1 more]</label></div><br/><div class="children"><div class="content">it doesn&#x27;t matter. as long as there is a rate mismatch over a sufficiently long timescale, queues will build up and consume memory, latency will increase, and depending on how things are structured overall throughput will go down because of scheduling overhead and memory pressure.<p>this is actually an inherent problem _within_ horizontally scaled services that have cross dependencies.<p>so no, you should really implement backpressure.</div><br/></div></div></div></div><div id="39834249" class="c"><input type="checkbox" id="c-39834249" checked=""/><div class="controls bullet"><span class="by">kazinator</span><span>|</span><a href="#39834277">prev</a><span>|</span><label class="collapse" for="c-39834249">[-]</label><label class="expand" for="c-39834249">[8 more]</label></div><br/><div class="children"><div class="content">Never heard it outside of the context of flow control in networking.<p>Not a thing in software outside of pieces communicating over a network, not using a protocol which has implicit flow control like TCP.<p>E.g. words like &quot;the lexer was producing tokens too fast, so the parser applied backpressure&quot; have never been heard.</div><br/><div id="39834860" class="c"><input type="checkbox" id="c-39834860" checked=""/><div class="controls bullet"><span class="by">jandrewrogers</span><span>|</span><a href="#39834249">parent</a><span>|</span><a href="#39836014">next</a><span>|</span><label class="collapse" for="c-39834860">[-]</label><label class="expand" for="c-39834860">[1 more]</label></div><br/><div class="children"><div class="content">The general pattern is a fixed set of resources that are consumed&#x2F;retired at a fixed maximum rate, where the optimal design consistently gets as close to the maximum rate as possible without exceeding the resource limit. There are (at least) two other places in software where backpressure is used, both commonly found in the database world:<p>Storage I&#x2F;O scheduling, which unlike the network case is often not interrupt-driven. As you approach the IOPS rate limit for the system due to high priority tasks, the rate of IOPS scheduled for low priority tasks like background write-back in databases is dynamically reduced to maintain headroom for high priority tasks. This is implemented as backpressure on low-priority tasks.<p>In query processing, a query as a user would understand it can materialize upwards of millions of sub-operations on the same server that can run concurrently given adequate system resources. The number of sub-operations that can be in-flight and retired per second is approximately fixed and shared across all concurrent user queries. For large queries, you incrementally materialize these sub-operations at a rate based on the instantaneous capacity of the system to handle new sub-operations. This is backpressure based on execution slot (and related memory) availability.<p>Writing software for barrel processors takes this to the extreme. The entire software design principle is to consistently generate fine-grained concurrent threads of execution at runtime that are close to the hardware concurrency limit globally (which is very high) but never exceeds it. Highly optimized code quickly gets pretty weird but it is basically all backpressure mechanics to maintain throughput.</div><br/></div></div><div id="39836014" class="c"><input type="checkbox" id="c-39836014" checked=""/><div class="controls bullet"><span class="by">ryanjshaw</span><span>|</span><a href="#39834249">parent</a><span>|</span><a href="#39834860">prev</a><span>|</span><a href="#39834493">next</a><span>|</span><label class="collapse" for="c-39836014">[-]</label><label class="expand" for="c-39836014">[1 more]</label></div><br/><div class="children"><div class="content">Here&#x27;s something I do regularly: I have B bits of data, where B is multiple orders of magnitude larger than the RAM I have available. I can process chunks of B in parallel with a near linear improvement in throughput, but still at an overall lower rate than I can read it from storage.<p>In other words, I&#x2F;O is faster than CPU for this task.<p>A naive design where I read the data as fast as possible on a dedicated thread, and dump it into an unbounded queue that a thread-per-core consumes, will quickly run out of memory.<p>By putting a limit on queue depth, the queue can communicate back to the storage reader that it can&#x27;t accept more data. This is backpressure. The reader in turn can decide whether to e.g. wait, slow down, discard etc. as appropriate for the use case.</div><br/></div></div><div id="39834493" class="c"><input type="checkbox" id="c-39834493" checked=""/><div class="controls bullet"><span class="by">majormajor</span><span>|</span><a href="#39834249">parent</a><span>|</span><a href="#39836014">prev</a><span>|</span><a href="#39834886">next</a><span>|</span><label class="collapse" for="c-39834493">[-]</label><label class="expand" for="c-39834493">[2 more]</label></div><br/><div class="children"><div class="content">You won&#x27;t&#x2F;can&#x27;t have it in a direct function call invocation style of programming. E.g. if you have a control loop like &quot;call A, pass result to B, pass result to C&quot; then it&#x27;s impossible for A to be &quot;too fast.&quot;<p>Network calls are the biggest source of asynchronously queued execution, but you can find models where you have it on a local machine too with multiprocessing.  A trivial silly non-network single-machine example might be something like unpacking compressed files than doing [thing] with their contents - maybe you have enough CPU to do them in parallel, but you don&#x27;t want to blow up your disk by unpacking all of them with no throttling. Even in your lexer&#x2F;parser example if you wanted to parallelize those steps with a queue in between them, <i>in theory</i> you could have such a huge input that you ran out of memory... in practice, nah, that&#x27;s not very likely the way you&#x27;d do it, or a problem you&#x27;d have.<p>Sometimes &quot;just drop things&quot; or &quot;just make the slow part faster&quot; still aren&#x27;t really easy&#x2F;feasible&#x2F;acceptable even without distributed systems.<p>I dunno if I&#x27;d really call it something like this like the linked article, though &quot;But other forms of backpressure can happen too: for example, if your software has to wait for the user to take some action.&quot;</div><br/><div id="39834823" class="c"><input type="checkbox" id="c-39834823" checked=""/><div class="controls bullet"><span class="by">ycombobreaker</span><span>|</span><a href="#39834249">root</a><span>|</span><a href="#39834493">parent</a><span>|</span><a href="#39834886">next</a><span>|</span><label class="collapse" for="c-39834823">[-]</label><label class="expand" for="c-39834823">[1 more]</label></div><br/><div class="children"><div class="content">Ehhh I think labeling user input as backpressure, because the software is waiting for _input_, is somewhere between confusing and inaccurate.  When I have seen backpressure discussed in my day job, it has always involved a (theoretical or real) slow consumer, and therefore some queue in front of that consumer.  I agree that &quot;networking&quot; or not, is irrelevant.</div><br/></div></div></div></div><div id="39834886" class="c"><input type="checkbox" id="c-39834886" checked=""/><div class="controls bullet"><span class="by">jrockway</span><span>|</span><a href="#39834249">parent</a><span>|</span><a href="#39834493">prev</a><span>|</span><a href="#39836117">next</a><span>|</span><label class="collapse" for="c-39834886">[-]</label><label class="expand" for="c-39834886">[1 more]</label></div><br/><div class="children"><div class="content">&quot;Nobody drives here, there&#x27;s too much traffic.&quot; is a classic backpressure quote.</div><br/></div></div><div id="39836117" class="c"><input type="checkbox" id="c-39836117" checked=""/><div class="controls bullet"><span class="by">saagarjha</span><span>|</span><a href="#39834249">parent</a><span>|</span><a href="#39834886">prev</a><span>|</span><a href="#39834566">next</a><span>|</span><label class="collapse" for="c-39836117">[-]</label><label class="expand" for="c-39836117">[1 more]</label></div><br/><div class="children"><div class="content">I use it in my decompression software: <a href="https:&#x2F;&#x2F;github.com&#x2F;saagarjha&#x2F;unxip&#x2F;blob&#x2F;65f08339a5168d3745be585c57ff057bd1dc3511&#x2F;unxip.swift#L162">https:&#x2F;&#x2F;github.com&#x2F;saagarjha&#x2F;unxip&#x2F;blob&#x2F;65f08339a5168d3745be...</a>. It’s a natural fit because it operates on a stream of data (due to performance constraints).</div><br/></div></div><div id="39834566" class="c"><input type="checkbox" id="c-39834566" checked=""/><div class="controls bullet"><span class="by">switchbak</span><span>|</span><a href="#39834249">parent</a><span>|</span><a href="#39836117">prev</a><span>|</span><label class="collapse" for="c-39834566">[-]</label><label class="expand" for="c-39834566">[1 more]</label></div><br/><div class="children"><div class="content">So since you’ve never heard of it, it’s not a thing?<p>Check out reactive streaming tech like Akka, they’ve been talking about this for well over a decade now, using exactly this language.</div><br/></div></div></div></div></div></div></div></div></div></body></html>