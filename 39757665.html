<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1710925267191" as="style"/><link rel="stylesheet" href="styles.css?v=1710925267191"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.nature.com/articles/s41593-024-01607-5">Natural language instructions induce generalization in networks of neurons</a> <span class="domain">(<a href="https://www.nature.com">www.nature.com</a>)</span></div><div class="subtext"><span>birriel</span> | <span>87 comments</span></div><br/><div><div id="39759456" class="c"><input type="checkbox" id="c-39759456" checked=""/><div class="controls bullet"><span class="by">nyrikki</span><span>|</span><a href="#39760015">next</a><span>|</span><label class="collapse" for="c-39759456">[-]</label><label class="expand" for="c-39759456">[11 more]</label></div><br/><div class="children"><div class="content">&gt;Tasks that are instructed using conditional clauses also require a simple form of deductive reasoning (if p then q else s)<p>&gt; Our models ofer several experimentally testable predictions 
 outlining how linguistic information must be represented to facilitate  flexible and general cognition in the human brain.<p>Aren&#x27;t those claims falsified by more recent studies that show that even in flys, preferred direction to a moving stimulus uses the timing of spikes.  And that fear conditioning in even mice uses Dendritic Compartmentalization?<p>Or that humans can even do xor with a single neuron.<p>If &quot;must be represented&quot; was &quot;may be modeled by&quot; I would have less of an issue and obviously spikey artificial NNs have had problems with riddled basins and make autograd problematic in general.<p>So ANNs need to be binary and it is best to model biological neurons as such for practical models... but can someone please clarify why &#x27;must&#x27; can apply when using what we know now is an oversimplified artificial neuron models?<p>Here are a couple of recent papers but I think dendritic compartmentalization and spike timing sensitivity has been established for over a decade.<p><a href="https:&#x2F;&#x2F;pubmed.ncbi.nlm.nih.gov&#x2F;35701166&#x2F;" rel="nofollow">https:&#x2F;&#x2F;pubmed.ncbi.nlm.nih.gov&#x2F;35701166&#x2F;</a><p><a href="https:&#x2F;&#x2F;www.sciencedirect.com&#x2F;science&#x2F;article&#x2F;pii&#x2F;S0092867418311061" rel="nofollow">https:&#x2F;&#x2F;www.sciencedirect.com&#x2F;science&#x2F;article&#x2F;pii&#x2F;S009286741...</a></div><br/><div id="39762465" class="c"><input type="checkbox" id="c-39762465" checked=""/><div class="controls bullet"><span class="by">godelski</span><span>|</span><a href="#39759456">parent</a><span>|</span><a href="#39760743">next</a><span>|</span><label class="collapse" for="c-39762465">[-]</label><label class="expand" for="c-39762465">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s also many issues with just interpreting the results of the work.<p><pre><code>  Our best models can perform a previously unseen task with an average performance of 83% correct based solely on linguistic instructions (that is, **zero-shot learning**).
</code></pre>
They used GPT-2 from HuggingFace. I&#x27;m unsure what data this model is trained on. If it is the original GPT-2 checkpoint then that data is unknown. I just refuse to let anyone casually claim &quot;zero-shot&quot; when the training data is unknown. GPT-2 was trained on 40GB of text data (which is A LOT! It includes 8 million documents and 45 million web pages). This may not be the crazy sizes we see today, but even then the community was concerned about accurately stating what was in distribution and out of distribution. You can&#x27;t know if you don&#x27;t know what it was trained on AND how it was trained (since the mathematics can also put pressure on certain things that may not be realized at first).<p>In addition to this, their efforts look to be mainly using clustering techniques. CLIP itself is a clustering algorithm. ANNs frequently do clustering as well, but you know, there&#x27;s some black box nature to them (but not entirely opaque either).<p>It is very hard to draw causal conclusions when you use either of these two things. Not to mention the fact that causality itself is difficult given that different graphs can be indistinguishable.</div><br/></div></div><div id="39760743" class="c"><input type="checkbox" id="c-39760743" checked=""/><div class="controls bullet"><span class="by">robwwilliams</span><span>|</span><a href="#39759456">parent</a><span>|</span><a href="#39762465">prev</a><span>|</span><a href="#39763826">next</a><span>|</span><label class="collapse" for="c-39760743">[-]</label><label class="expand" for="c-39760743">[1 more]</label></div><br/><div class="children"><div class="content">Yes, the word “represented” is too widely used and abused in neuroscience—to the point where a frog has “fly detector” neurons. Humberto Maturana pushed back against this pervasive idea. Chapter 4 of Terry Winograd’s and Francesco Valera’s Understanding Computers and Cognition has a good overview of common presumptions.<p>Given that CNS is a 700 million year hack, there will be lots of odd tricks used to generate effective behaviors.</div><br/></div></div><div id="39763826" class="c"><input type="checkbox" id="c-39763826" checked=""/><div class="controls bullet"><span class="by">barrenko</span><span>|</span><a href="#39759456">parent</a><span>|</span><a href="#39760743">prev</a><span>|</span><a href="#39759810">next</a><span>|</span><label class="collapse" for="c-39763826">[-]</label><label class="expand" for="c-39763826">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m early, so to say, in biochemistry, but could any of this relate to the level &quot;below&quot; neurons - to ion channels?</div><br/></div></div><div id="39759810" class="c"><input type="checkbox" id="c-39759810" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#39759456">parent</a><span>|</span><a href="#39763826">prev</a><span>|</span><a href="#39760470">next</a><span>|</span><label class="collapse" for="c-39759810">[-]</label><label class="expand" for="c-39759810">[3 more]</label></div><br/><div class="children"><div class="content">&gt; Or that humans can even do xor with a single neuron.<p>That&#x27;s news to me.<p>I&#x27;m not <i>hugely</i> surprised given I&#x27;ve heard a biological neuron is supposed to be equivalent to a small ANN network, but still, first I&#x27;ve heard of that claim.</div><br/><div id="39759856" class="c"><input type="checkbox" id="c-39759856" checked=""/><div class="controls bullet"><span class="by">orbifold</span><span>|</span><a href="#39759456">root</a><span>|</span><a href="#39759810">parent</a><span>|</span><a href="#39760470">next</a><span>|</span><label class="collapse" for="c-39759856">[-]</label><label class="expand" for="c-39759856">[2 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;www.science.org&#x2F;doi&#x2F;full&#x2F;10.1126&#x2F;science.aax6239" rel="nofollow">https:&#x2F;&#x2F;www.science.org&#x2F;doi&#x2F;full&#x2F;10.1126&#x2F;science.aax6239</a></div><br/><div id="39760619" class="c"><input type="checkbox" id="c-39760619" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#39759456">root</a><span>|</span><a href="#39759856">parent</a><span>|</span><a href="#39760470">next</a><span>|</span><label class="collapse" for="c-39760619">[-]</label><label class="expand" for="c-39760619">[1 more]</label></div><br/><div class="children"><div class="content">Thanks :)</div><br/></div></div></div></div></div></div><div id="39760470" class="c"><input type="checkbox" id="c-39760470" checked=""/><div class="controls bullet"><span class="by">canjobear</span><span>|</span><a href="#39759456">parent</a><span>|</span><a href="#39759810">prev</a><span>|</span><a href="#39761690">next</a><span>|</span><label class="collapse" for="c-39760470">[-]</label><label class="expand" for="c-39760470">[2 more]</label></div><br/><div class="children"><div class="content">There’s a long debate in neuroscience about whether information is encoded in timing of individual spikes or only their rates (where rate coding is a bit more similar to how ANNs work, but still different). It hasn’t been decided by any one paper, nor is it likely to be: it seems that different populations of neurons in different parts of the brain encode information through different means.</div><br/><div id="39760766" class="c"><input type="checkbox" id="c-39760766" checked=""/><div class="controls bullet"><span class="by">robwwilliams</span><span>|</span><a href="#39759456">root</a><span>|</span><a href="#39760470">parent</a><span>|</span><a href="#39761690">next</a><span>|</span><label class="collapse" for="c-39760766">[-]</label><label class="expand" for="c-39760766">[1 more]</label></div><br/><div class="children"><div class="content">Not either-or. It is both. Spike rate variation is way too slow for some types of low level compute. Spike timing us critical for actions as “simple” as throwing a fast ball into the strike zone.</div><br/></div></div></div></div><div id="39761690" class="c"><input type="checkbox" id="c-39761690" checked=""/><div class="controls bullet"><span class="by">sam0x17</span><span>|</span><a href="#39759456">parent</a><span>|</span><a href="#39760470">prev</a><span>|</span><a href="#39760015">next</a><span>|</span><label class="collapse" for="c-39761690">[-]</label><label class="expand" for="c-39761690">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Or that humans can even do xor with a single neuron.<p>having a single neuron that has learned xor != understanding xor<p>Function approximation is trivial, understanding of what said functions can do and when to use them is much harder (though is arguably still function approximation)</div><br/><div id="39762186" class="c"><input type="checkbox" id="c-39762186" checked=""/><div class="controls bullet"><span class="by">nyrikki</span><span>|</span><a href="#39759456">root</a><span>|</span><a href="#39761690">parent</a><span>|</span><a href="#39760015">next</a><span>|</span><label class="collapse" for="c-39762186">[-]</label><label class="expand" for="c-39762186">[1 more]</label></div><br/><div class="children"><div class="content">Well xor is linearly inseparable, which is impossible with a single perceptron.<p>&gt; Our models by contrast make tractable predictions for what popu-
lation and single-unit neural representations are required to support
compositional generalization and can guide future experimental work
examining the interplay of linguistic and sensorimotor skills in humans.<p>Do you see where that causes an issue with supervenience?  Especially when mixed with STDP which could change that more?<p>It is confusing the map with the territory.  At least with the extreme strength of their claim.</div><br/></div></div></div></div></div></div><div id="39760015" class="c"><input type="checkbox" id="c-39760015" checked=""/><div class="controls bullet"><span class="by">worstspotgain</span><span>|</span><a href="#39759456">prev</a><span>|</span><a href="#39759300">next</a><span>|</span><label class="collapse" for="c-39760015">[-]</label><label class="expand" for="c-39760015">[17 more]</label></div><br/><div class="children"><div class="content">Birds inspired planes. Later, aerodynamics fed back into ornithology. I&#x27;ve been waiting for LLMs to be evaluated as a model of human thought. Complexity and scale have held neuroscience back. It&#x27;s nowhere close to building a high-level brain model up from biological primitives. Like ornithology, it could use some feedback.<p>All arguments about AGI aside, a machine was built that writes like a human. Its design is very un-biological in places, so it&#x27;s tempting to dismiss it. Why not see how deep the rabbit hole goes?<p>Like all conjectures it just might surprise us. For one, the intuition that language is central to thought predates LLMs, but it&#x27;s certainly consistent with it.</div><br/><div id="39760534" class="c"><input type="checkbox" id="c-39760534" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#39760015">parent</a><span>|</span><a href="#39760562">next</a><span>|</span><label class="collapse" for="c-39760534">[-]</label><label class="expand" for="c-39760534">[7 more]</label></div><br/><div class="children"><div class="content">&gt; a machine was built that writes like a human<p>But the real hero here is not the LLM, but the training set. It took ages to collect all the knowledge, ideas and methods we put in books. It cost a lot of human effort to provide the data. Without the data we would have nothing. Without GPT we could use RWKV, Mamba, S4, etc and still get similar results. It&#x27;s the data not the model.<p>&gt; the intuition that language is central to thought predates LLMs<p>Language carries AI and humans. The same distribution of language can be the software running in our brains and in LLMs. I think humans act like conditional language models with multi modality and actions. We use language to plan and solve our problem, work together and learn (a lot) from others.<p>Language itself is an evolutionary system and a self replicator. Its speed is much faster than biology. We&#x27;ve been on the language exponential for millennia, but just now hit the critical mass for LLMs to be possible.<p>It&#x27;s not so important that GPT-4 is a 2T weights model, what matters is that it was trained on 13T tokens of human experience and it now &quot;writes like a human&quot;. Does that mean humans also learn the same skills GPT-4 has learned from its training set mostly by language as well?</div><br/><div id="39761026" class="c"><input type="checkbox" id="c-39761026" checked=""/><div class="controls bullet"><span class="by">AlecSchueler</span><span>|</span><a href="#39760015">root</a><span>|</span><a href="#39760534">parent</a><span>|</span><a href="#39762453">next</a><span>|</span><label class="collapse" for="c-39761026">[-]</label><label class="expand" for="c-39761026">[5 more]</label></div><br/><div class="children"><div class="content">&gt; But the real hero here is not the LLM, but the training set.<p>And in the case of windmills the hero is the wind. But the mill is still a fantastic achievement.</div><br/><div id="39761538" class="c"><input type="checkbox" id="c-39761538" checked=""/><div class="controls bullet"><span class="by">riwsky</span><span>|</span><a href="#39760015">root</a><span>|</span><a href="#39761026">parent</a><span>|</span><a href="#39761376">next</a><span>|</span><label class="collapse" for="c-39761538">[-]</label><label class="expand" for="c-39761538">[2 more]</label></div><br/><div class="children"><div class="content">And if you rearrange the letters in “mill”? “I, LLM.”<p>qed</div><br/><div id="39763090" class="c"><input type="checkbox" id="c-39763090" checked=""/><div class="controls bullet"><span class="by">razodactyl</span><span>|</span><a href="#39760015">root</a><span>|</span><a href="#39761538">parent</a><span>|</span><a href="#39761376">next</a><span>|</span><label class="collapse" for="c-39763090">[-]</label><label class="expand" for="c-39763090">[1 more]</label></div><br/><div class="children"><div class="content">Correlation checks out.</div><br/></div></div></div></div><div id="39761376" class="c"><input type="checkbox" id="c-39761376" checked=""/><div class="controls bullet"><span class="by">mewpmewp2</span><span>|</span><a href="#39760015">root</a><span>|</span><a href="#39761026">parent</a><span>|</span><a href="#39761538">prev</a><span>|</span><a href="#39762453">next</a><span>|</span><label class="collapse" for="c-39761376">[-]</label><label class="expand" for="c-39761376">[2 more]</label></div><br/><div class="children"><div class="content">But can mills easily move? No, people can, so people are still viable.</div><br/><div id="39761989" class="c"><input type="checkbox" id="c-39761989" checked=""/><div class="controls bullet"><span class="by">coldtea</span><span>|</span><a href="#39760015">root</a><span>|</span><a href="#39761376">parent</a><span>|</span><a href="#39762453">next</a><span>|</span><label class="collapse" for="c-39761989">[-]</label><label class="expand" for="c-39761989">[1 more]</label></div><br/><div class="children"><div class="content">&gt;<i>But can mills easily move?</i><p>Yes, that&#x27;s their whole thing: moving when the air blows.</div><br/></div></div></div></div></div></div><div id="39762453" class="c"><input type="checkbox" id="c-39762453" checked=""/><div class="controls bullet"><span class="by">nickpsecurity</span><span>|</span><a href="#39760015">root</a><span>|</span><a href="#39760534">parent</a><span>|</span><a href="#39761026">prev</a><span>|</span><a href="#39760562">next</a><span>|</span><label class="collapse" for="c-39762453">[-]</label><label class="expand" for="c-39762453">[1 more]</label></div><br/><div class="children"><div class="content">Indeed, they are mostly parroting that knowledge with some reasoning from combinations of those patterns. That counts for something. It’s not what we do, though. Or not all we do.<p>Humans can just sit around aimlessly toying with stuff, reading books, etc. They’ll figure out some of these patterns on their own. Whereas, we have to give these things a ton of highly-curated, pre-processed data made by human minds of all kinds. Then, it’s usually 800GB-4TB for the good ones. They’re appear to be not in our league yet as learning machines.<p>We’ll be able to assess it better as multimodal models come online. We can train them like infants, then children, on books, random observations through cameras, TV, people reading to them, supervised feedback… all the stuff we do with humans. Then see if and how they match up in performance.</div><br/></div></div></div></div><div id="39760288" class="c"><input type="checkbox" id="c-39760288" checked=""/><div class="controls bullet"><span class="by">smokel</span><span>|</span><a href="#39760015">parent</a><span>|</span><a href="#39760562">prev</a><span>|</span><a href="#39760527">next</a><span>|</span><label class="collapse" for="c-39760288">[-]</label><label class="expand" for="c-39760288">[6 more]</label></div><br/><div class="children"><div class="content">&gt; Later, aerodynamics fed back into ornithology.<p>You mean to imply that birds have learned from jet fighter designs?<p>I fail to understand the point you&#x27;re making.</div><br/><div id="39760405" class="c"><input type="checkbox" id="c-39760405" checked=""/><div class="controls bullet"><span class="by">vaidhy</span><span>|</span><a href="#39760015">root</a><span>|</span><a href="#39760288">parent</a><span>|</span><a href="#39760388">next</a><span>|</span><label class="collapse" for="c-39760405">[-]</label><label class="expand" for="c-39760405">[1 more]</label></div><br/><div class="children"><div class="content">I believe the point is that we understand the birds&#x27; flight better applying the principles we learnt designing and flying airplanes. Similarly, we can learn more about human brain by applying things we learn from building the ANN back to the study of humans (anthropology in general, maybe neuroscience and psychology )</div><br/></div></div><div id="39760388" class="c"><input type="checkbox" id="c-39760388" checked=""/><div class="controls bullet"><span class="by">worstspotgain</span><span>|</span><a href="#39760015">root</a><span>|</span><a href="#39760288">parent</a><span>|</span><a href="#39760405">prev</a><span>|</span><a href="#39762425">next</a><span>|</span><label class="collapse" for="c-39760388">[-]</label><label class="expand" for="c-39760388">[1 more]</label></div><br/><div class="children"><div class="content">Concepts from the mechanics of flight (e.g. lift and drag) have helped ornithologists understand birds better. Birds themselves did not learn much.</div><br/></div></div><div id="39762425" class="c"><input type="checkbox" id="c-39762425" checked=""/><div class="controls bullet"><span class="by">throwaway_6142</span><span>|</span><a href="#39760015">root</a><span>|</span><a href="#39760288">parent</a><span>|</span><a href="#39760388">prev</a><span>|</span><a href="#39760436">next</a><span>|</span><label class="collapse" for="c-39762425">[-]</label><label class="expand" for="c-39762425">[1 more]</label></div><br/><div class="children"><div class="content">Knowledge learned from airplane propeller development, as well as from jet plane wing aerodynamics, has had a great impact on the design of wind turbine blades, which are now affecting the evolution of birds.</div><br/></div></div><div id="39760436" class="c"><input type="checkbox" id="c-39760436" checked=""/><div class="controls bullet"><span class="by">Sardtok</span><span>|</span><a href="#39760015">root</a><span>|</span><a href="#39760288">parent</a><span>|</span><a href="#39762425">prev</a><span>|</span><a href="#39760348">next</a><span>|</span><label class="collapse" for="c-39760436">[-]</label><label class="expand" for="c-39760436">[1 more]</label></div><br/><div class="children"><div class="content">He didn&#x27;t say it fed back into birds, but into the study of birds.</div><br/></div></div></div></div><div id="39760527" class="c"><input type="checkbox" id="c-39760527" checked=""/><div class="controls bullet"><span class="by">lo_zamoyski</span><span>|</span><a href="#39760015">parent</a><span>|</span><a href="#39760288">prev</a><span>|</span><a href="#39759300">next</a><span>|</span><label class="collapse" for="c-39760527">[-]</label><label class="expand" for="c-39760527">[2 more]</label></div><br/><div class="children"><div class="content">Why assume this is sensible? Aerodynamics can help discover general <i>principles</i> that apply to both birds and planes or whatever else. I don&#x27;t see how this holds for LLMs and brains. The similarity between LLMs and brains is superficial.<p>Besides, with human beings, we have a host of philosophical problems that undermine the neuroscientific presumption that a mechanistic and closed view of the brain can account for mental activity entirely, like the problem of intentionality.</div><br/><div id="39760633" class="c"><input type="checkbox" id="c-39760633" checked=""/><div class="controls bullet"><span class="by">og_kalu</span><span>|</span><a href="#39760015">root</a><span>|</span><a href="#39760527">parent</a><span>|</span><a href="#39759300">next</a><span>|</span><label class="collapse" for="c-39760633">[-]</label><label class="expand" for="c-39760633">[1 more]</label></div><br/><div class="children"><div class="content">&gt;I don&#x27;t see how this holds for LLMs and brains. The similarity between LLMs and brains is superficial.<p>It&#x27;s really not any more superficial than planes and bird flight.</div><br/></div></div></div></div></div></div><div id="39759300" class="c"><input type="checkbox" id="c-39759300" checked=""/><div class="controls bullet"><span class="by">jameshart</span><span>|</span><a href="#39760015">prev</a><span>|</span><a href="#39759096">next</a><span>|</span><label class="collapse" for="c-39759300">[-]</label><label class="expand" for="c-39759300">[25 more]</label></div><br/><div class="children"><div class="content">&gt; We found that language scaffolds sensorimotor representations such that activity for interrelated tasks shares a common geometry with the semantic representations of instructions, allowing language to cue the proper composition of practiced skills in unseen settings.<p>Sapir-Whorf with the surprise comeback?</div><br/><div id="39759855" class="c"><input type="checkbox" id="c-39759855" checked=""/><div class="controls bullet"><span class="by">sisyphus_coding</span><span>|</span><a href="#39759300">parent</a><span>|</span><a href="#39759096">next</a><span>|</span><label class="collapse" for="c-39759855">[-]</label><label class="expand" for="c-39759855">[24 more]</label></div><br/><div class="children"><div class="content">&gt; comeback<p>Did it fall out of favour?</div><br/><div id="39760006" class="c"><input type="checkbox" id="c-39760006" checked=""/><div class="controls bullet"><span class="by">jameshart</span><span>|</span><a href="#39759300">root</a><span>|</span><a href="#39759855">parent</a><span>|</span><a href="#39759096">next</a><span>|</span><label class="collapse" for="c-39760006">[-]</label><label class="expand" for="c-39760006">[23 more]</label></div><br/><div class="children"><div class="content">Strong Sapir-Whorf (linguistic determinism - language <i>constrains</i> thought) became pretty much seen as a joke by the 1980s. Linguistic relativism (weak Sapir-Whorf - language <i>shapes</i> thought) is still respectable (because, I mean, of course it does).<p>Actually, this research might just as well be evidence for linguistic universalism (Chomsky - language <i>enables</i> thought).<p>In general linguistic philosophers have been coming out with either laughably obvious or utterly untestable hypotheses for a century and it’s amusing to see how these AI studies shake up the hornets.</div><br/><div id="39761998" class="c"><input type="checkbox" id="c-39761998" checked=""/><div class="controls bullet"><span class="by">coldtea</span><span>|</span><a href="#39759300">root</a><span>|</span><a href="#39760006">parent</a><span>|</span><a href="#39760322">next</a><span>|</span><label class="collapse" for="c-39761998">[-]</label><label class="expand" for="c-39761998">[3 more]</label></div><br/><div class="children"><div class="content">&gt;<i>Strong Sapir-Whorf (linguistic determinism - language constrains thought) became pretty much seen as a joke by the 1980s</i><p>Was there any substantial empirical reason it was &quot;seen as a joke&quot;, or just changing philosophical fashion?</div><br/><div id="39762290" class="c"><input type="checkbox" id="c-39762290" checked=""/><div class="controls bullet"><span class="by">jameshart</span><span>|</span><a href="#39759300">root</a><span>|</span><a href="#39761998">parent</a><span>|</span><a href="#39760322">next</a><span>|</span><label class="collapse" for="c-39762290">[-]</label><label class="expand" for="c-39762290">[2 more]</label></div><br/><div class="children"><div class="content">In general, as I understand it, there was only ever evidence for a weak version, and many of the cited anthropological examples that make the case turn out to have dubious factual basis - the old ‘Eskimos have hundreds of words for snow’ and ‘there’s a tribe in Africa who have no word for numbers greater than three’ stuff, all filtered through layers of academic anecdote and institutional racism.</div><br/><div id="39762444" class="c"><input type="checkbox" id="c-39762444" checked=""/><div class="controls bullet"><span class="by">throwaway_6142</span><span>|</span><a href="#39759300">root</a><span>|</span><a href="#39762290">parent</a><span>|</span><a href="#39760322">next</a><span>|</span><label class="collapse" for="c-39762444">[-]</label><label class="expand" for="c-39762444">[1 more]</label></div><br/><div class="children"><div class="content"><i>&gt; institutional racism</i><p>are you absolutely certain that your thoughts are not being constrained by your language?</div><br/></div></div></div></div></div></div><div id="39760322" class="c"><input type="checkbox" id="c-39760322" checked=""/><div class="controls bullet"><span class="by">a_gnostic</span><span>|</span><a href="#39759300">root</a><span>|</span><a href="#39760006">parent</a><span>|</span><a href="#39761998">prev</a><span>|</span><a href="#39760443">next</a><span>|</span><label class="collapse" for="c-39760322">[-]</label><label class="expand" for="c-39760322">[11 more]</label></div><br/><div class="children"><div class="content">Oftentimes I find myself understanding complex concepts <i>before</i> I can describe them, even <i>internally</i>. I am sure everyone has this, as I often read comments praising others&#x27; submissions for formulating their thoughts efficiently.
So thoughts occur independent of language, but need it to be expressed and shared, even if through pictures and sounds.</div><br/><div id="39763394" class="c"><input type="checkbox" id="c-39763394" checked=""/><div class="controls bullet"><span class="by">red75prime</span><span>|</span><a href="#39759300">root</a><span>|</span><a href="#39760322">parent</a><span>|</span><a href="#39760481">next</a><span>|</span><label class="collapse" for="c-39763394">[-]</label><label class="expand" for="c-39763394">[1 more]</label></div><br/><div class="children"><div class="content">I a programmer I have to make a sharp distinction between &quot;feeling of understanding&quot; and understanding. The former can easily dissolve when you try to operationalize it, that is to make something that works based on the feeling that you understand it as opposed to producing a string of words based on that feeling.</div><br/></div></div><div id="39760481" class="c"><input type="checkbox" id="c-39760481" checked=""/><div class="controls bullet"><span class="by">vaidhy</span><span>|</span><a href="#39759300">root</a><span>|</span><a href="#39760322">parent</a><span>|</span><a href="#39763394">prev</a><span>|</span><a href="#39762011">next</a><span>|</span><label class="collapse" for="c-39760481">[-]</label><label class="expand" for="c-39760481">[2 more]</label></div><br/><div class="children"><div class="content">Thoughts occur independent of language is same as saying sentient beings think. The question is does the thought you have depend on the language?<p>I speak tamil and english and can distinctly see how the language drives some of my understanding. If you have a language that has evolved to describe 3D space, would be understand spatial ideas better&#x2F;faster?<p>If we are pattern matching creatures, then the patterns are built over a period of time and our earliest scaffolding for the patterns come from our mother tongue (or the languages learnt in early childhood). Subsequent understanding depends on building and expanding on those patterns.</div><br/><div id="39760734" class="c"><input type="checkbox" id="c-39760734" checked=""/><div class="controls bullet"><span class="by">a_gnostic</span><span>|</span><a href="#39759300">root</a><span>|</span><a href="#39760481">parent</a><span>|</span><a href="#39762011">next</a><span>|</span><label class="collapse" for="c-39760734">[-]</label><label class="expand" for="c-39760734">[1 more]</label></div><br/><div class="children"><div class="content">I grew up trilingual, and have noticed that I understand mechanical concepts better in one language, industrial concepts in another… but have mostly defaulted to English nowadays. I find learning new concepts easier by playing translation games; Which language is the root for this word, and how does it mechanically relate to the concept?</div><br/></div></div></div></div><div id="39762011" class="c"><input type="checkbox" id="c-39762011" checked=""/><div class="controls bullet"><span class="by">coldtea</span><span>|</span><a href="#39759300">root</a><span>|</span><a href="#39760322">parent</a><span>|</span><a href="#39760481">prev</a><span>|</span><a href="#39761210">next</a><span>|</span><label class="collapse" for="c-39762011">[-]</label><label class="expand" for="c-39762011">[2 more]</label></div><br/><div class="children"><div class="content">&gt;<i>So thoughts occur independent of language</i><p>Independent of language as the conscious surface level mechanism, maybe - as in, they don&#x27;t have to be in English, say. But independent of language altogether, including symbolic language encoded into brain structures, I wouldn&#x27;t be so sure.<p>Language doesn&#x27;t have to mean conscious internal monologue.</div><br/><div id="39762428" class="c"><input type="checkbox" id="c-39762428" checked=""/><div class="controls bullet"><span class="by">interroboink</span><span>|</span><a href="#39759300">root</a><span>|</span><a href="#39762011">parent</a><span>|</span><a href="#39761210">next</a><span>|</span><label class="collapse" for="c-39762428">[-]</label><label class="expand" for="c-39762428">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Language doesn&#x27;t have to mean conscious internal monologue.<p>Agreed, but boy do I wish we had better words (ha!) for this.<p>Calling everything &quot;language&quot; even if someone internally has a more visual or tactile or some other kind of &quot;internal grammar&quot; really gives an unfortunate tilt to casual conversation.<p>For most people, in everyday discussion, &quot;language&quot; means words&#x2F;text. I wish we had some term for &quot;structured knowledge&quot; that did not rely on the words&#x2F;text analogy, since it can leave different-minded people feeling a bit sidelined.</div><br/></div></div></div></div><div id="39761210" class="c"><input type="checkbox" id="c-39761210" checked=""/><div class="controls bullet"><span class="by">codethief</span><span>|</span><a href="#39759300">root</a><span>|</span><a href="#39760322">parent</a><span>|</span><a href="#39762011">prev</a><span>|</span><a href="#39760450">next</a><span>|</span><label class="collapse" for="c-39761210">[-]</label><label class="expand" for="c-39761210">[1 more]</label></div><br/><div class="children"><div class="content">Sounds like a description of understanding a concept in some latent space while not having fully verbalized it yet. (:</div><br/></div></div><div id="39760450" class="c"><input type="checkbox" id="c-39760450" checked=""/><div class="controls bullet"><span class="by">lo_zamoyski</span><span>|</span><a href="#39759300">root</a><span>|</span><a href="#39760322">parent</a><span>|</span><a href="#39761210">prev</a><span>|</span><a href="#39760443">next</a><span>|</span><label class="collapse" for="c-39760450">[-]</label><label class="expand" for="c-39760450">[4 more]</label></div><br/><div class="children"><div class="content">Expression is not language. What you&#x27;re having trouble doing is expressing what you understand.</div><br/><div id="39760690" class="c"><input type="checkbox" id="c-39760690" checked=""/><div class="controls bullet"><span class="by">Jensson</span><span>|</span><a href="#39759300">root</a><span>|</span><a href="#39760450">parent</a><span>|</span><a href="#39760443">next</a><span>|</span><label class="collapse" for="c-39760690">[-]</label><label class="expand" for="c-39760690">[3 more]</label></div><br/><div class="children"><div class="content">But that would be an impossibility if understanding requires expressing it in language.</div><br/><div id="39762021" class="c"><input type="checkbox" id="c-39762021" checked=""/><div class="controls bullet"><span class="by">coldtea</span><span>|</span><a href="#39759300">root</a><span>|</span><a href="#39760690">parent</a><span>|</span><a href="#39760443">next</a><span>|</span><label class="collapse" for="c-39762021">[-]</label><label class="expand" for="c-39762021">[2 more]</label></div><br/><div class="children"><div class="content">The thinking language doesn&#x27;t have to be the same thing as the expression language.<p>It can still have a language form (manipulation of groups of symbolic structures, terms, and associations), but doesn&#x27;t have to be English, or even at the conscious &quot;internal monologue&quot; level.</div><br/><div id="39763374" class="c"><input type="checkbox" id="c-39763374" checked=""/><div class="controls bullet"><span class="by">red75prime</span><span>|</span><a href="#39759300">root</a><span>|</span><a href="#39762021">parent</a><span>|</span><a href="#39760443">next</a><span>|</span><label class="collapse" for="c-39763374">[-]</label><label class="expand" for="c-39763374">[1 more]</label></div><br/><div class="children"><div class="content">How can you know that it&#x27;s symbolic if you have no conscious access to it? Processes happen in the brain, some results in explicit symbolic representation, others not so much. Bringing &quot;language&quot; into this does not achieve much besides the fact that language we use to communicate plays some role in internal monologue.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="39760443" class="c"><input type="checkbox" id="c-39760443" checked=""/><div class="controls bullet"><span class="by">lo_zamoyski</span><span>|</span><a href="#39759300">root</a><span>|</span><a href="#39760006">parent</a><span>|</span><a href="#39760322">prev</a><span>|</span><a href="#39759096">next</a><span>|</span><label class="collapse" for="c-39760443">[-]</label><label class="expand" for="c-39760443">[8 more]</label></div><br/><div class="children"><div class="content">The distinction between language and &quot;thought&quot; to me is odd. Language and &quot;thought&quot; <i>are the same thing</i>. The mouth sounds or hand scribbles aren&#x27;t the language, but <i>expressions</i> of it.</div><br/><div id="39761139" class="c"><input type="checkbox" id="c-39761139" checked=""/><div class="controls bullet"><span class="by">jameshart</span><span>|</span><a href="#39759300">root</a><span>|</span><a href="#39760443">parent</a><span>|</span><a href="#39760781">next</a><span>|</span><label class="collapse" for="c-39761139">[-]</label><label class="expand" for="c-39761139">[2 more]</label></div><br/><div class="children"><div class="content">One issue here is semantics. The things that happen in our brains which we can put into words tend to be the things we categorize as ‘thoughts’. But there are things that happen in our brains which we struggle to connect to language too, and we might call those ‘feelings’ or ‘emotions’ or ‘instincts’ instead. So we’re trying to use language to think about how we think about language and I suspect this might be why that end of neurolinguistics falls off the deep end into philosophy.</div><br/><div id="39762031" class="c"><input type="checkbox" id="c-39762031" checked=""/><div class="controls bullet"><span class="by">coldtea</span><span>|</span><a href="#39759300">root</a><span>|</span><a href="#39761139">parent</a><span>|</span><a href="#39760781">next</a><span>|</span><label class="collapse" for="c-39762031">[-]</label><label class="expand" for="c-39762031">[1 more]</label></div><br/><div class="children"><div class="content">&gt;<i>But there are things that happen in our brains which we struggle to connect to language too, and we might call those ‘feelings’ or ‘emotions’ or ‘instincts’ instead</i><p>Yes, and we could argue that those are not thoughts, while there still being a distinction between thought language (which could very well be subconscious) and inner monologue&#x2F;spoken language.</div><br/></div></div></div></div><div id="39760781" class="c"><input type="checkbox" id="c-39760781" checked=""/><div class="controls bullet"><span class="by">noiv</span><span>|</span><a href="#39759300">root</a><span>|</span><a href="#39760443">parent</a><span>|</span><a href="#39761139">prev</a><span>|</span><a href="#39760605">next</a><span>|</span><label class="collapse" for="c-39760781">[-]</label><label class="expand" for="c-39760781">[1 more]</label></div><br/><div class="children"><div class="content">I consider a sentence as a formatted thought. That implies a thought exists before it is expressed in words. There&#x27;s a ton of thoughts in my head which can&#x27;t be transformed into any language I speak. I wish I could somehow acquire some proficiency in the other thousands of languages spoken by humans on this planet, just to proof their immense lack of features.<p>Also our natural languages restrict information bandwidth to a few bytes per second. Imagine doing sports like tennis, chess or soccer at this speed...</div><br/></div></div><div id="39760605" class="c"><input type="checkbox" id="c-39760605" checked=""/><div class="controls bullet"><span class="by">somewhereoutth</span><span>|</span><a href="#39759300">root</a><span>|</span><a href="#39760443">parent</a><span>|</span><a href="#39760781">prev</a><span>|</span><a href="#39759096">next</a><span>|</span><label class="collapse" for="c-39760605">[-]</label><label class="expand" for="c-39760605">[4 more]</label></div><br/><div class="children"><div class="content">You don&#x27;t need language to catch a ball, but clearly thinking is required to intercept its trajectory correctly.<p>Language is about <i>communication</i>.</div><br/><div id="39763304" class="c"><input type="checkbox" id="c-39763304" checked=""/><div class="controls bullet"><span class="by">tsimionescu</span><span>|</span><a href="#39759300">root</a><span>|</span><a href="#39760605">parent</a><span>|</span><a href="#39761014">next</a><span>|</span><label class="collapse" for="c-39763304">[-]</label><label class="expand" for="c-39763304">[1 more]</label></div><br/><div class="children"><div class="content">The idea that language is about thought is only referring to the kind of higher level thinking specific to humans. Any animal can catch a tennis ball, but only humans can construct and then execute complex plans of actions.<p>This line of thought stems mostly from two observations: one, that the vast majority of language you use is your internal monologue; and two, that this internal monologue would have been extremely helpful for the hominids that would have first developed it even while the rest of the population had not developed language (in contrast, if language is about communication, then it&#x27;s only useful to a hominid if the whole population speaks language, but then it&#x27;s hard for it to spread initially).</div><br/></div></div><div id="39761014" class="c"><input type="checkbox" id="c-39761014" checked=""/><div class="controls bullet"><span class="by">photonthug</span><span>|</span><a href="#39759300">root</a><span>|</span><a href="#39760605">parent</a><span>|</span><a href="#39763304">prev</a><span>|</span><a href="#39759096">next</a><span>|</span><label class="collapse" for="c-39761014">[-]</label><label class="expand" for="c-39761014">[2 more]</label></div><br/><div class="children"><div class="content">There’s an argument that communication which is internal is still communication, and that a language of trajectories required for coordination is still linguistic in a meaningful sense.  Most of the ways to differentiate thought from language are probably going to end up splitting hairs.  It all comes back to Wittgenstein, and it’s arguable whether the POV is useful, but it’s certainly coherent and defensible.</div><br/><div id="39761811" class="c"><input type="checkbox" id="c-39761811" checked=""/><div class="controls bullet"><span class="by">error_logic</span><span>|</span><a href="#39759300">root</a><span>|</span><a href="#39761014">parent</a><span>|</span><a href="#39759096">next</a><span>|</span><label class="collapse" for="c-39761811">[-]</label><label class="expand" for="c-39761811">[1 more]</label></div><br/><div class="children"><div class="content">I think this entire thread of discussion would benefit from remembering multimodal models exist. In other words, pictures are worth a thousand words and have their own place in thought. The existence of a way to translate between modalities doesn&#x27;t make any of them superior overall--they each have their roles to play.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="39759096" class="c"><input type="checkbox" id="c-39759096" checked=""/><div class="controls bullet"><span class="by">kevindamm</span><span>|</span><a href="#39759300">prev</a><span>|</span><a href="#39759702">next</a><span>|</span><label class="collapse" for="c-39759096">[-]</label><label class="expand" for="c-39759096">[12 more]</label></div><br/><div class="children"><div class="content">It&#x27;s as if language is itself the latent space for these psychophysical tasks, especially compositional instruction.  Their description of it as a scaffolding also seems apt.</div><br/><div id="39760544" class="c"><input type="checkbox" id="c-39760544" checked=""/><div class="controls bullet"><span class="by">mrblah</span><span>|</span><a href="#39759096">parent</a><span>|</span><a href="#39759258">next</a><span>|</span><label class="collapse" for="c-39760544">[-]</label><label class="expand" for="c-39760544">[2 more]</label></div><br/><div class="children"><div class="content">i&#x27;ve always assumed that language was required to give your brain the abstractions needed to reference things in the past compared to your current perception (aka now), like an index. if you think about your earliest memories, they almost certainly came after language. i&#x27;d be interested to know if any of the documented &#x27;wild child&#x27; cases (infants &#x27;raised by wolves&#x27;) ever delved into what the children remembered before, after being taught language as an adolescent.</div><br/><div id="39763341" class="c"><input type="checkbox" id="c-39763341" checked=""/><div class="controls bullet"><span class="by">tsimionescu</span><span>|</span><a href="#39759096">root</a><span>|</span><a href="#39760544">parent</a><span>|</span><a href="#39759258">next</a><span>|</span><label class="collapse" for="c-39763341">[-]</label><label class="expand" for="c-39763341">[1 more]</label></div><br/><div class="children"><div class="content">There were efforts to teach them language as adolescents, but they didn&#x27;t acquire it - as far as we know, it&#x27;s not possible to acquire language if you don&#x27;t do it as an infant.<p>This is similar to other brain functions that aren&#x27;t present at birth and require stimulation, such as sight. That is, if your eyes are forced closed for the first few months of your life, you will never be able to see, even if later they are uncovered, and keep working perfectly. The brain functions responsible for interpreting visual signals can only develop if they get visual signals in a (quite short) developmental window - and we know this with quite a bit of certainty from quite cruel animal studies.<p>Language acquisition is not proven to be the same, as the required studies would be deeply unethical, but the few experiences with feral children are highly suggestive that the same applies.</div><br/></div></div></div></div><div id="39759258" class="c"><input type="checkbox" id="c-39759258" checked=""/><div class="controls bullet"><span class="by">zer00eyz</span><span>|</span><a href="#39759096">parent</a><span>|</span><a href="#39760544">prev</a><span>|</span><a href="#39759482">next</a><span>|</span><label class="collapse" for="c-39759258">[-]</label><label class="expand" for="c-39759258">[6 more]</label></div><br/><div class="children"><div class="content">I hate the reductive nature of the concept of &quot;latent spaces&quot;.<p>A good enough formula for a task isn&#x27;t a solution for every task. Yes Newtonian mechanics work, but Einstein is a better reflection of reality.</div><br/><div id="39759392" class="c"><input type="checkbox" id="c-39759392" checked=""/><div class="controls bullet"><span class="by">bongodongobob</span><span>|</span><a href="#39759096">root</a><span>|</span><a href="#39759258">parent</a><span>|</span><a href="#39760870">next</a><span>|</span><label class="collapse" for="c-39759392">[-]</label><label class="expand" for="c-39759392">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not sure I understand the analogy. The very idea of NNs is that it&#x27;s not perfect, it is messy and not optimal, but is very generalizable.</div><br/><div id="39760892" class="c"><input type="checkbox" id="c-39760892" checked=""/><div class="controls bullet"><span class="by">zer00eyz</span><span>|</span><a href="#39759096">root</a><span>|</span><a href="#39759392">parent</a><span>|</span><a href="#39760870">next</a><span>|</span><label class="collapse" for="c-39760892">[-]</label><label class="expand" for="c-39760892">[1 more]</label></div><br/><div class="children"><div class="content">&gt;&gt; The very idea of NNs is that it&#x27;s not perfect, it is messy and not optimal, but is very generalizable.<p>Newton: Do you need more than that to describe the speed of a thrown baseball on a train? No. DO you you need more than newton to get to the moon? No. Is it going to be accurate at high speed in a large scale system (anything traveling near C)?  NO, it fails spectacularly.<p>NN&#x27;s are great at simulation, language, weather... But what people using them for weather seem to understand and the ML folks (screaming about AI and AGI) dont is that simulation is not a path to emulation. Lorenz showed that there were limits in weather, that most other disciplines have embraced these limits.</div><br/></div></div></div></div><div id="39760870" class="c"><input type="checkbox" id="c-39760870" checked=""/><div class="controls bullet"><span class="by">nerdponx</span><span>|</span><a href="#39759096">root</a><span>|</span><a href="#39759258">parent</a><span>|</span><a href="#39759392">prev</a><span>|</span><a href="#39759482">next</a><span>|</span><label class="collapse" for="c-39760870">[-]</label><label class="expand" for="c-39760870">[3 more]</label></div><br/><div class="children"><div class="content">The entire innovation (discovery?) of LLMs is that a good formula for the task of sequence completion turns out to also be a good formula for a wide range of AI tasks. That emergent property is why language models are called language models.</div><br/><div id="39761824" class="c"><input type="checkbox" id="c-39761824" checked=""/><div class="controls bullet"><span class="by">error_logic</span><span>|</span><a href="#39759096">root</a><span>|</span><a href="#39760870">parent</a><span>|</span><a href="#39762446">next</a><span>|</span><label class="collapse" for="c-39761824">[-]</label><label class="expand" for="c-39761824">[1 more]</label></div><br/><div class="children"><div class="content">The usefulness is why the term is so widespread in <i>familiarity</i> but I think the term would have existed to describe the linguistic mapping even if they hadn&#x27;t proven to have direct problem-solving capabilities.</div><br/></div></div><div id="39762446" class="c"><input type="checkbox" id="c-39762446" checked=""/><div class="controls bullet"><span class="by">hackerlight</span><span>|</span><a href="#39759096">root</a><span>|</span><a href="#39760870">parent</a><span>|</span><a href="#39761824">prev</a><span>|</span><a href="#39759482">next</a><span>|</span><label class="collapse" for="c-39762446">[-]</label><label class="expand" for="c-39762446">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s an inductive bias, not an emergent property. The inductive bias of transformers is that they&#x27;re good at integrating global context from different parts of a sequence without a particular bias towards recent time steps or localized regularities. And that happens to be a good fit for many (but not all) real-world sequence learning tasks.<p>The &quot;emergent property&quot; aspect is when LLMs are good at a task at scale X*3 but were incompetent at scale X.</div><br/></div></div></div></div></div></div><div id="39759482" class="c"><input type="checkbox" id="c-39759482" checked=""/><div class="controls bullet"><span class="by">nothis</span><span>|</span><a href="#39759096">parent</a><span>|</span><a href="#39759258">prev</a><span>|</span><a href="#39759702">next</a><span>|</span><label class="collapse" for="c-39759482">[-]</label><label class="expand" for="c-39759482">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not pretending to understand half the words uttered in this discussion but I&#x27;m constantly reminded of how much it helps me to articulate things (explain them to others, write them down, etc) to understand them. Maybe that thinking indeed happens almost entirely on a linguistic level and I&#x27;m not doing half as much other thinking (visualization, abstract logic, etc.) in the process as I thought. That feels weird.</div><br/><div id="39760852" class="c"><input type="checkbox" id="c-39760852" checked=""/><div class="controls bullet"><span class="by">robwwilliams</span><span>|</span><a href="#39759096">root</a><span>|</span><a href="#39759482">parent</a><span>|</span><a href="#39759702">next</a><span>|</span><label class="collapse" for="c-39760852">[-]</label><label class="expand" for="c-39760852">[2 more]</label></div><br/><div class="children"><div class="content">Or is the real thinking sub-linguistic and “you” and those you talk to are the target audience of language? Sentences emerge from a pre-linguistic space we do not understand.</div><br/><div id="39761865" class="c"><input type="checkbox" id="c-39761865" checked=""/><div class="controls bullet"><span class="by">error_logic</span><span>|</span><a href="#39759096">root</a><span>|</span><a href="#39760852">parent</a><span>|</span><a href="#39759702">next</a><span>|</span><label class="collapse" for="c-39761865">[-]</label><label class="expand" for="c-39761865">[1 more]</label></div><br/><div class="children"><div class="content">I do find it funny that this discussion thread has tried to represent language as a universal form of thought when it would be messy to encode the inner workings of a LLM (the weightings&#x2F;relationships) themselves as natural language.<p>You could sort of represent the deterministic contents of an LLM by compiling all the algorithms and training data in some form, or maybe a visual mosaic of the weights and tokens, or what have you...but that still doesn&#x27;t really explain the outcome when a model is presented with novel strings. The patterns are emergent properties that converge on familiar language--they&#x27;re something deeper than the individual words that result.</div><br/></div></div></div></div></div></div></div></div><div id="39759702" class="c"><input type="checkbox" id="c-39759702" checked=""/><div class="controls bullet"><span class="by">cs702</span><span>|</span><a href="#39759096">prev</a><span>|</span><a href="#39760193">next</a><span>|</span><label class="collapse" for="c-39759702">[-]</label><label class="expand" for="c-39759702">[2 more]</label></div><br/><div class="children"><div class="content">TL;DR: The authors embed task instructions in a vector space with a language model, and train a sensorimotor-controlling model on top to perform tasks given the instruction embeddings. The authors find that the models generalize to previously unseen tasks, specified in natural language. Moreover, the authors show that the hidden states learn to represent task subcomponents, which helps explains why the model is able to generalize.</div><br/><div id="39761270" class="c"><input type="checkbox" id="c-39761270" checked=""/><div class="controls bullet"><span class="by">ShamelessC</span><span>|</span><a href="#39759702">parent</a><span>|</span><a href="#39760193">next</a><span>|</span><label class="collapse" for="c-39761270">[-]</label><label class="expand" for="c-39761270">[1 more]</label></div><br/><div class="children"><div class="content">What is the language model pretrained on? Wouldn’t the far more robust LLM’s priors impact ability to generalize to “unseen” tasks?</div><br/></div></div></div></div><div id="39760193" class="c"><input type="checkbox" id="c-39760193" checked=""/><div class="controls bullet"><span class="by">retskrad</span><span>|</span><a href="#39759702">prev</a><span>|</span><a href="#39760918">next</a><span>|</span><label class="collapse" for="c-39760193">[-]</label><label class="expand" for="c-39760193">[12 more]</label></div><br/><div class="children"><div class="content">It&#x27;s clear that both biological sentient beings and sentient being made in factories in the future will essentially be two sides of the same coin, differing only in their physical composition. Humans today operate as biological AI, powered by cells, and the sentient beings instead operate on transistors. As we progress toward a future where both sentient beings exhibit comparable intelligence, emotions, and learned experiences, the distinction between the two becomes increasingly blurred. It wouldn&#x27;t be crazy to think that we&#x27;ll program a person made out of transistors to go through the same life as a biological human. In such a scenario, why should we consider the sentient being made of cells inherently superior to its transistor-based counterpart?</div><br/><div id="39760270" class="c"><input type="checkbox" id="c-39760270" checked=""/><div class="controls bullet"><span class="by">smokel</span><span>|</span><a href="#39760193">parent</a><span>|</span><a href="#39760230">next</a><span>|</span><label class="collapse" for="c-39760270">[-]</label><label class="expand" for="c-39760270">[7 more]</label></div><br/><div class="children"><div class="content">Hm, no.  To start, cells are able to replicate themselves, whereas most silicon used today is not even close to doing so.<p>The story you suggest seems to be built on a limited understanding of the processes involved.  It&#x27;s pretty hard to predict the future, especially given incorrect assumptions.</div><br/><div id="39760617" class="c"><input type="checkbox" id="c-39760617" checked=""/><div class="controls bullet"><span class="by">Workaccount2</span><span>|</span><a href="#39760193">root</a><span>|</span><a href="#39760270">parent</a><span>|</span><a href="#39760507">next</a><span>|</span><label class="collapse" for="c-39760617">[-]</label><label class="expand" for="c-39760617">[3 more]</label></div><br/><div class="children"><div class="content">Compute is substrate independent.<p>We use transistors because they are wicked fast and efficient. But a 4090 built from metal balls and wood blocks would still be able to perform all the same calculations. Or a 4090 made by drawing X&#x27;s and O&#x27;s on a (really massive) piece of paper. Or one made by connecting a bunch of neurons together for that matter.<p>Saying cells can multiply doesn&#x27;t really mean anything, unless is gives ability to access some higher form of compute that is outside the reach of Turing machines. Which it doesn&#x27;t, because if it did, it would be supernatural.</div><br/><div id="39760749" class="c"><input type="checkbox" id="c-39760749" checked=""/><div class="controls bullet"><span class="by">Jensson</span><span>|</span><a href="#39760193">root</a><span>|</span><a href="#39760617">parent</a><span>|</span><a href="#39760507">next</a><span>|</span><label class="collapse" for="c-39760749">[-]</label><label class="expand" for="c-39760749">[2 more]</label></div><br/><div class="children"><div class="content">Analogue computers aren&#x27;t equivalent to Turing machines.</div><br/><div id="39761308" class="c"><input type="checkbox" id="c-39761308" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#39760193">root</a><span>|</span><a href="#39760749">parent</a><span>|</span><a href="#39760507">next</a><span>|</span><label class="collapse" for="c-39761308">[-]</label><label class="expand" for="c-39761308">[1 more]</label></div><br/><div class="children"><div class="content">No physical computer is a perfect Turing machine, thanks to random noise.<p>Analogue computers can always implement a Turing machine to within the bounds of that noise (and that&#x27;s how transistors, which are really analogue devices, get used for digital signal and information processing).<p>A computer that used infinite-precision real numbers would be more powerful than any Turing machine, <i>however</i> unlimited-precision real numbers in the physical universe are prohibited by the holographic principle and the Bekenstein bound so we can&#x27;t have them.</div><br/></div></div></div></div></div></div><div id="39760507" class="c"><input type="checkbox" id="c-39760507" checked=""/><div class="controls bullet"><span class="by">KoolKat23</span><span>|</span><a href="#39760193">root</a><span>|</span><a href="#39760270">parent</a><span>|</span><a href="#39760617">prev</a><span>|</span><a href="#39760230">next</a><span>|</span><label class="collapse" for="c-39760507">[-]</label><label class="expand" for="c-39760507">[3 more]</label></div><br/><div class="children"><div class="content">Cell division is a solved problem. Install new ram module and ctrl+c, ctrl+v from backup, done.</div><br/><div id="39761341" class="c"><input type="checkbox" id="c-39761341" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#39760193">root</a><span>|</span><a href="#39760507">parent</a><span>|</span><a href="#39760230">next</a><span>|</span><label class="collapse" for="c-39761341">[-]</label><label class="expand" for="c-39761341">[2 more]</label></div><br/><div class="children"><div class="content">That&#x27;s &quot;solved&quot; in the way that viruses &quot;solved&quot; life; I think we <i>might</i> want higher standards than that.<p>Un&#x2F;fortunately (depending on who you ask), there&#x27;s also a lot of automation being developed for every stage of the industrial processes from &quot;where do we even look for the right rocks to get out of the ground?&quot; to &quot;here&#x27;s the RAM chip you wanted to stick in your socket&quot;.</div><br/><div id="39761545" class="c"><input type="checkbox" id="c-39761545" checked=""/><div class="controls bullet"><span class="by">KoolKat23</span><span>|</span><a href="#39760193">root</a><span>|</span><a href="#39761341">parent</a><span>|</span><a href="#39760230">next</a><span>|</span><label class="collapse" for="c-39761545">[-]</label><label class="expand" for="c-39761545">[1 more]</label></div><br/><div class="children"><div class="content">My point is, it&#x27;s irrelevant. Yes we can&#x27;t replicate the process of cell replication but in this case it isn&#x27;t necessary. We can achieve the end objective (which is to repair&#x2F;extend) through other means, this is akin to just replacing organs with factory build versions (memories pre-installed too).</div><br/></div></div></div></div></div></div></div></div><div id="39760230" class="c"><input type="checkbox" id="c-39760230" checked=""/><div class="controls bullet"><span class="by">spr-alex</span><span>|</span><a href="#39760193">parent</a><span>|</span><a href="#39760270">prev</a><span>|</span><a href="#39760218">next</a><span>|</span><label class="collapse" for="c-39760230">[-]</label><label class="expand" for="c-39760230">[1 more]</label></div><br/><div class="children"><div class="content">proof left as exercise to the reader</div><br/></div></div><div id="39760220" class="c"><input type="checkbox" id="c-39760220" checked=""/><div class="controls bullet"><span class="by">arijun</span><span>|</span><a href="#39760193">parent</a><span>|</span><a href="#39760218">prev</a><span>|</span><a href="#39762424">next</a><span>|</span><label class="collapse" for="c-39760220">[-]</label><label class="expand" for="c-39760220">[1 more]</label></div><br/><div class="children"><div class="content">I don’t think it’s a given that people do. Also what does that have to do with the article?</div><br/></div></div><div id="39762424" class="c"><input type="checkbox" id="c-39762424" checked=""/><div class="controls bullet"><span class="by">nickpsecurity</span><span>|</span><a href="#39760193">parent</a><span>|</span><a href="#39760220">prev</a><span>|</span><a href="#39760918">next</a><span>|</span><label class="collapse" for="c-39762424">[-]</label><label class="expand" for="c-39762424">[1 more]</label></div><br/><div class="children"><div class="content">It’s not clear at all. So far, the only sentient, intelligent beings are the ones God made. His Word (Bible) said He made us for Him with predictions for the end times. AI takeover isn’t in there. Also, it implies (a) we won’t ever observe an act of evolution that produces anything like us and (b) any artificial intelligence will likewise require brilliant, intelligent designers to work and be maintained.<p>So far, all these AI’s with a tiny fraction of human capabilities require brilliant designers in fine-tuned environments, like we did. We’ve also observed billions of human and non-human births with no new kinds of animals coming out of them. So, the Word of God is supported by billions of observations plus every AI ever designed while evolutionary or singularity-type views are not. That’s despite so many comments in these discussions referencing evolutionary or mechanical explanations as if they’ve been proven instead of disproven by observations.<p>So, put your trust in Jesus Christ, receive the Spirit of God our Creator, and find out for yourself what’s special about us. Your life will be much more than the product of a biological, cellular process. God is powerful. You’ll see His work in a new light after you personally know Him.</div><br/></div></div></div></div><div id="39760918" class="c"><input type="checkbox" id="c-39760918" checked=""/><div class="controls bullet"><span class="by">vassilis-uk</span><span>|</span><a href="#39760193">prev</a><span>|</span><a href="#39759850">next</a><span>|</span><label class="collapse" for="c-39760918">[-]</label><label class="expand" for="c-39760918">[1 more]</label></div><br/><div class="children"><div class="content">here is a video of the author explaining the work
<a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=miEwuSz7Pts" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=miEwuSz7Pts</a></div><br/></div></div><div id="39760648" class="c"><input type="checkbox" id="c-39760648" checked=""/><div class="controls bullet"><span class="by">alexfromapex</span><span>|</span><a href="#39759850">prev</a><span>|</span><a href="#39759915">next</a><span>|</span><label class="collapse" for="c-39760648">[-]</label><label class="expand" for="c-39760648">[1 more]</label></div><br/><div class="children"><div class="content">I think the title of this is wrong...it should say &quot;Structured Language Patterns Facilitate Structured Generalization in Neural Networks&quot;.</div><br/></div></div><div id="39760352" class="c"><input type="checkbox" id="c-39760352" checked=""/><div class="controls bullet"><span class="by">dmead</span><span>|</span><a href="#39759915">prev</a><span>|</span><label class="collapse" for="c-39760352">[-]</label><label class="expand" for="c-39760352">[3 more]</label></div><br/><div class="children"><div class="content">I hate that we just turned out to be stochastic machines another not something more interesting.</div><br/><div id="39761906" class="c"><input type="checkbox" id="c-39761906" checked=""/><div class="controls bullet"><span class="by">error_logic</span><span>|</span><a href="#39760352">parent</a><span>|</span><a href="#39760480">next</a><span>|</span><label class="collapse" for="c-39761906">[-]</label><label class="expand" for="c-39761906">[1 more]</label></div><br/><div class="children"><div class="content">This reminds me of how &#x27;interesting&#x27; it is when people defend their use of language by downplaying the effects on other people. We really do have so many ripple effects from everything we broadcast to others, and tacking a negative, or a double&#x2F;triple negative into a sentence doesn&#x27;t change the fact that mentioning pink elephants will color an arbitrary portion of someone&#x27;s day.<p>In other words, this is why tone absolutely matters, and I love how this awareness feeds into support for genuine expression. Sarcasm is chaotic with an unknown audience who would be less likely to recognize the intended subversion and toying with meaning, instead taking it in whatever direction the listener feels like without being sure that the speaker is understood.</div><br/></div></div><div id="39760480" class="c"><input type="checkbox" id="c-39760480" checked=""/><div class="controls bullet"><span class="by">KoolKat23</span><span>|</span><a href="#39760352">parent</a><span>|</span><a href="#39761906">prev</a><span>|</span><label class="collapse" for="c-39760480">[-]</label><label class="expand" for="c-39760480">[1 more]</label></div><br/><div class="children"><div class="content">Delusions of grandeur</div><br/></div></div></div></div></div></div></div></div></div></body></html>