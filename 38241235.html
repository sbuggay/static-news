<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1699866063396" as="style"/><link rel="stylesheet" href="styles.css?v=1699866063396"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://twitter.com/abidlabs/status/1723074108739706959">Generate images fast with SD 1.5 while typing on Gradio</a> <span class="domain">(<a href="https://twitter.com">twitter.com</a>)</span></div><div class="subtext"><span>smusamashah</span> | <span>27 comments</span></div><br/><div><div id="38243077" class="c"><input type="checkbox" id="c-38243077" checked=""/><div class="controls bullet"><span class="by">jimmySixDOF</span><span>|</span><a href="#38245593">next</a><span>|</span><label class="collapse" for="c-38243077">[-]</label><label class="expand" for="c-38243077">[2 more]</label></div><br/><div class="children"><div class="content">And here is a demo mashed up using LeapMotion free space hand tracking and a projector to manipulate a &quot;bigGAN&#x27;s high-dimensional space of pseudo-real images&quot; to make it more like a modern dance meets sculpting meets spatial computing with a hat tip to the 2008 work of Johnny Chung Lee while at Carnage Mellon.<p><a href="https:&#x2F;&#x2F;x.com&#x2F;graycrawford&#x2F;status&#x2F;1100935327374626818" rel="nofollow noreferrer">https:&#x2F;&#x2F;x.com&#x2F;graycrawford&#x2F;status&#x2F;1100935327374626818</a></div><br/><div id="38246470" class="c"><input type="checkbox" id="c-38246470" checked=""/><div class="controls bullet"><span class="by">echelon</span><span>|</span><a href="#38243077">parent</a><span>|</span><a href="#38245593">next</a><span>|</span><label class="collapse" for="c-38246470">[-]</label><label class="expand" for="c-38246470">[1 more]</label></div><br/><div class="children"><div class="content">This is incredible.<p>I dream of the day we can sculpt entire 3D worlds with quick, tactile gestures. Or pure thought. This feels tangibly close.<p>Fantastic demo. Very much in the magic style of Johnny Chung Lee.</div><br/></div></div></div></div><div id="38245593" class="c"><input type="checkbox" id="c-38245593" checked=""/><div class="controls bullet"><span class="by">brucethemoose2</span><span>|</span><a href="#38243077">prev</a><span>|</span><a href="#38244630">next</a><span>|</span><label class="collapse" for="c-38245593">[-]</label><label class="expand" for="c-38245593">[1 more]</label></div><br/><div class="children"><div class="content">Now combine this with an optimized SD implementation, like:<p><a href="https:&#x2F;&#x2F;github.com&#x2F;chengzeyi&#x2F;stable-fast">https:&#x2F;&#x2F;github.com&#x2F;chengzeyi&#x2F;stable-fast</a><p>Or AITemplate, and you are at 15FPS on a larger consumer GPU. 10 with a controlnet you can use for some motion consistency.</div><br/></div></div><div id="38244630" class="c"><input type="checkbox" id="c-38244630" checked=""/><div class="controls bullet"><span class="by">r-k-jo</span><span>|</span><a href="#38245593">prev</a><span>|</span><a href="#38244065">next</a><span>|</span><label class="collapse" for="c-38244630">[-]</label><label class="expand" for="c-38244630">[1 more]</label></div><br/><div class="children"><div class="content">Here is a collection of demos with fast LCM on HuggingFace<p><a href="https:&#x2F;&#x2F;huggingface.co&#x2F;collections&#x2F;latent-consistency&#x2F;latent-consistency-model-demos-654e90c52adb0688a0acbe6f" rel="nofollow noreferrer">https:&#x2F;&#x2F;huggingface.co&#x2F;collections&#x2F;latent-consistency&#x2F;latent...</a></div><br/></div></div><div id="38244065" class="c"><input type="checkbox" id="c-38244065" checked=""/><div class="controls bullet"><span class="by">smlacy</span><span>|</span><a href="#38244630">prev</a><span>|</span><a href="#38242976">next</a><span>|</span><label class="collapse" for="c-38244065">[-]</label><label class="expand" for="c-38244065">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;nitter.net&#x2F;abidlabs&#x2F;status&#x2F;1723074108739706959" rel="nofollow noreferrer">https:&#x2F;&#x2F;nitter.net&#x2F;abidlabs&#x2F;status&#x2F;1723074108739706959</a></div><br/></div></div><div id="38242976" class="c"><input type="checkbox" id="c-38242976" checked=""/><div class="controls bullet"><span class="by">Der_Einzige</span><span>|</span><a href="#38244065">prev</a><span>|</span><a href="#38242914">next</a><span>|</span><label class="collapse" for="c-38242976">[-]</label><label class="expand" for="c-38242976">[20 more]</label></div><br/><div class="children"><div class="content">The fact that LCM loras turn regular SD models into psudo-LCM models is insane.<p>Most people in the AI world don&#x27;t understand that ML is like actual alchemy. You can merge models like they are chemicals. A friend of mine called it &quot;a new chemistry of ideas&quot; upon seeing many features in Automatic1111 (including model and token merges) used simultaneously to generate unique images.<p>Also, loras exist on a spectrum based on their dimensionality. Tiny loras should only be capable of relatively tiny changes. My guess is that this is a big lora, nearly the same size as the base checkpoint.</div><br/><div id="38243568" class="c"><input type="checkbox" id="c-38243568" checked=""/><div class="controls bullet"><span class="by">ttul</span><span>|</span><a href="#38242976">parent</a><span>|</span><a href="#38243121">next</a><span>|</span><label class="collapse" for="c-38243568">[-]</label><label class="expand" for="c-38243568">[6 more]</label></div><br/><div class="children"><div class="content">To me, the crazy thing about LoRA is they work perfectly well adapting models checkpoints that were themselves derived from the base model on which the LoRA was trained. So you can take the LCM LoRA for SD1.5 and it works perfectly well on, say, RealisticVision 5.1, a fine-tuned derivative of SD1.5.<p>You’d think that the fine tuning would make the LCM LoRA not work, but it does. Apparently the changes in weights introduced through even pretty heavy fine tuning does not wreck the transformations the LoRA needs to make in order to make LCM or other LoRA adaptations work.<p>To me this is alchemy.</div><br/><div id="38244846" class="c"><input type="checkbox" id="c-38244846" checked=""/><div class="controls bullet"><span class="by">yorwba</span><span>|</span><a href="#38242976">root</a><span>|</span><a href="#38243568">parent</a><span>|</span><a href="#38243121">next</a><span>|</span><label class="collapse" for="c-38244846">[-]</label><label class="expand" for="c-38244846">[5 more]</label></div><br/><div class="children"><div class="content">Finetuning and LoRAs both involve additive modifications to the model weights. Addition is commutative, so the order in which you apply them doesn&#x27;t matter for the resulting weights. Moreover, neural networks are designed to be differentiable, i.e. behave approximately linearly with respect to small additive modifications of the weights, so as long as your finetuning and LoRA change the weights only a little bit, you can finetune with or without the LoRA, respectively train the LoRA on the finetuned model or its base, and get mostly the same result.<p>So this is something that can be somewhat explained using not terribly handwavy mathematics. Picking hyperparameters on the other hand...</div><br/><div id="38245648" class="c"><input type="checkbox" id="c-38245648" checked=""/><div class="controls bullet"><span class="by">rq1</span><span>|</span><a href="#38242976">root</a><span>|</span><a href="#38244846">parent</a><span>|</span><a href="#38243121">next</a><span>|</span><label class="collapse" for="c-38245648">[-]</label><label class="expand" for="c-38245648">[4 more]</label></div><br/><div class="children"><div class="content">This is trivially not true.<p>Pick eg. x -&gt; sin(1&#x2F;x) around zero and its derivatives.<p>The small modifications that you’re talking about are on the argument. These can lead to huuge changes in the values.<p>The stability is more likely due to the diffusive nature of the models and well executed trainings.</div><br/><div id="38245791" class="c"><input type="checkbox" id="c-38245791" checked=""/><div class="controls bullet"><span class="by">kelseyfrog</span><span>|</span><a href="#38242976">root</a><span>|</span><a href="#38245648">parent</a><span>|</span><a href="#38243121">next</a><span>|</span><label class="collapse" for="c-38245791">[-]</label><label class="expand" for="c-38245791">[3 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t recall SD or variants using discontinuous terms like 1&#x2F;x. Sigmoid, softmax, and SiLU are going to be what you&#x27;re looking for.</div><br/><div id="38245985" class="c"><input type="checkbox" id="c-38245985" checked=""/><div class="controls bullet"><span class="by">rq1</span><span>|</span><a href="#38242976">root</a><span>|</span><a href="#38245791">parent</a><span>|</span><a href="#38243121">next</a><span>|</span><label class="collapse" for="c-38245985">[-]</label><label class="expand" for="c-38245985">[2 more]</label></div><br/><div class="children"><div class="content">They don’t use them indeed. I was replying to the general idea about the additions.<p>OTOH Gaussian kernels smoothen almost everything. Maybe it will be stable even with sin(1&#x2F;x) as an “activation”.</div><br/><div id="38247527" class="c"><input type="checkbox" id="c-38247527" checked=""/><div class="controls bullet"><span class="by">yorwba</span><span>|</span><a href="#38242976">root</a><span>|</span><a href="#38245985">parent</a><span>|</span><a href="#38243121">next</a><span>|</span><label class="collapse" for="c-38247527">[-]</label><label class="expand" for="c-38247527">[1 more]</label></div><br/><div class="children"><div class="content">If you want to use a counterexample to refute the general idea about additions, you need to pick one that fulfills the preconditions, like being differentiable. x → sin (1&#x2F;x) is not differentiable at 0 and for any other value where it <i>is</i> differentiable, there&#x27;s a small ɛ and a linear function L such that for all a and b &lt; ɛ, sin(1&#x2F;(x + a + b)) = sin(1&#x2F;x) + L(a + b) + O(ɛ²) and because L is linear, L(a + b) = L(a) + L(b). The wrinkle is that ɛ might have to be extremely small indeed.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="38243121" class="c"><input type="checkbox" id="c-38243121" checked=""/><div class="controls bullet"><span class="by">keonix</span><span>|</span><a href="#38242976">parent</a><span>|</span><a href="#38243568">prev</a><span>|</span><a href="#38243157">next</a><span>|</span><label class="collapse" for="c-38243121">[-]</label><label class="expand" for="c-38243121">[4 more]</label></div><br/><div class="children"><div class="content">Wait until you hear about frankenmodels. You rip parts of one model (often attention heads) and transplant them in another and somehow that produces coherent results! Witchcraft<p><a href="https:&#x2F;&#x2F;huggingface.co&#x2F;chargoddard" rel="nofollow noreferrer">https:&#x2F;&#x2F;huggingface.co&#x2F;chargoddard</a></div><br/><div id="38243160" class="c"><input type="checkbox" id="c-38243160" checked=""/><div class="controls bullet"><span class="by">GaggiX</span><span>|</span><a href="#38242976">root</a><span>|</span><a href="#38243121">parent</a><span>|</span><a href="#38243157">next</a><span>|</span><label class="collapse" for="c-38243160">[-]</label><label class="expand" for="c-38243160">[3 more]</label></div><br/><div class="children"><div class="content">&gt;somehow that produces coherent results<p>with or without finetuning? Also is there a practical motivation for creating them?</div><br/><div id="38243440" class="c"><input type="checkbox" id="c-38243440" checked=""/><div class="controls bullet"><span class="by">keonix</span><span>|</span><a href="#38242976">root</a><span>|</span><a href="#38243160">parent</a><span>|</span><a href="#38243157">next</a><span>|</span><label class="collapse" for="c-38243440">[-]</label><label class="expand" for="c-38243440">[2 more]</label></div><br/><div class="children"><div class="content">&gt; with or without finetuning?<p>With, but it&#x27;s still bonkers that it works so well<p>&gt;Also is there a practical motivation for creating them?<p>You could get in-between model sizes (like 20b instead of 13b or 34b). Before better quantization it was useful for inference (if you are unlucky with vram size), but now I see this being useful only for training because you can&#x27;t train on quants</div><br/><div id="38245858" class="c"><input type="checkbox" id="c-38245858" checked=""/><div class="controls bullet"><span class="by">ShamelessC</span><span>|</span><a href="#38242976">root</a><span>|</span><a href="#38243440">parent</a><span>|</span><a href="#38243157">next</a><span>|</span><label class="collapse" for="c-38245858">[-]</label><label class="expand" for="c-38245858">[1 more]</label></div><br/><div class="children"><div class="content">&gt; With, but it&#x27;s still bonkers that it works so well<p>Ehhhh…</div><br/></div></div></div></div></div></div></div></div><div id="38243157" class="c"><input type="checkbox" id="c-38243157" checked=""/><div class="controls bullet"><span class="by">temp72840</span><span>|</span><a href="#38242976">parent</a><span>|</span><a href="#38243121">prev</a><span>|</span><a href="#38243745">next</a><span>|</span><label class="collapse" for="c-38243157">[-]</label><label class="expand" for="c-38243157">[3 more]</label></div><br/><div class="children"><div class="content">This is nuts. I did a double take at this comment - I thought you <i>must</i> have been talking about LoRAing a LCM distilled from Stable Diffusion.<p>LCMs are spooky black magic, I have no intuitions about them.</div><br/><div id="38243595" class="c"><input type="checkbox" id="c-38243595" checked=""/><div class="controls bullet"><span class="by">ttul</span><span>|</span><a href="#38242976">root</a><span>|</span><a href="#38243157">parent</a><span>|</span><a href="#38243745">next</a><span>|</span><label class="collapse" for="c-38243595">[-]</label><label class="expand" for="c-38243595">[2 more]</label></div><br/><div class="children"><div class="content">When I was taking Jeremy Howard’s course last fall, the breakthrough in SD was going from 1000 steps to 50 steps via classifier-free guidance, which is this neat hack where you run inference with your conditioning and without and then mix the result. To this day I still don’t get it. But it works.<p>Now we find this way to skip to the end by building a model that learns the high dimensional curvature of the path that a diffusion process takes through space on its way to an acceptable image, and we just basically move the model along that path. That’s my naive understanding of LCM. Seems to good to be true, but it does work and it has a good theoretical basis too. Makes you wonder what is next? Will there be a single step network that can train on LCM to predict the final destination? LoL that would be pushing things too far..</div><br/><div id="38244060" class="c"><input type="checkbox" id="c-38244060" checked=""/><div class="controls bullet"><span class="by">hadlock</span><span>|</span><a href="#38242976">root</a><span>|</span><a href="#38243595">parent</a><span>|</span><a href="#38243745">next</a><span>|</span><label class="collapse" for="c-38244060">[-]</label><label class="expand" for="c-38244060">[1 more]</label></div><br/><div class="children"><div class="content">Sounds like we&#x27;ve invented the kind of psychic time travel they use in Minority report. Let me show you right over to the Future Crimes division. We&#x27;re arresting this guy making cat memes today because the curve of his online history traces that of a radicalized blah blah blah</div><br/></div></div></div></div></div></div><div id="38243745" class="c"><input type="checkbox" id="c-38243745" checked=""/><div class="controls bullet"><span class="by">smusamashah</span><span>|</span><a href="#38242976">parent</a><span>|</span><a href="#38243157">prev</a><span>|</span><a href="#38245032">next</a><span>|</span><label class="collapse" for="c-38243745">[-]</label><label class="expand" for="c-38243745">[3 more]</label></div><br/><div class="children"><div class="content">Ok. I have seen the term LCM Lora a number of times. I have used both stable Diffusion and LORAs for fun for quite a while. But I always thought this LCM Lora is a new thing. It&#x27;s simply not possible using current samplers to return an image under 4 steps. What you are saying is that just by adding a Lora we can get existing models and samplers to generate a good enough image in 4 steps?</div><br/><div id="38243807" class="c"><input type="checkbox" id="c-38243807" checked=""/><div class="controls bullet"><span class="by">jyap</span><span>|</span><a href="#38242976">root</a><span>|</span><a href="#38243745">parent</a><span>|</span><a href="#38244255">next</a><span>|</span><label class="collapse" for="c-38243807">[-]</label><label class="expand" for="c-38243807">[1 more]</label></div><br/><div class="children"><div class="content">Yes check out this blog post: <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;blog&#x2F;lcm_lora" rel="nofollow noreferrer">https:&#x2F;&#x2F;huggingface.co&#x2F;blog&#x2F;lcm_lora</a><p>I’ve used it with my home GPU. Really fast which makes it more interactive and real-time.</div><br/></div></div><div id="38244255" class="c"><input type="checkbox" id="c-38244255" checked=""/><div class="controls bullet"><span class="by">catwell</span><span>|</span><a href="#38242976">root</a><span>|</span><a href="#38243745">parent</a><span>|</span><a href="#38243807">prev</a><span>|</span><a href="#38245032">next</a><span>|</span><label class="collapse" for="c-38244255">[-]</label><label class="expand" for="c-38244255">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a different sampler too.</div><br/></div></div></div></div><div id="38245032" class="c"><input type="checkbox" id="c-38245032" checked=""/><div class="controls bullet"><span class="by">esafak</span><span>|</span><a href="#38242976">parent</a><span>|</span><a href="#38243745">prev</a><span>|</span><a href="#38243137">next</a><span>|</span><label class="collapse" for="c-38245032">[-]</label><label class="expand" for="c-38245032">[1 more]</label></div><br/><div class="children"><div class="content">This is what happens when praxis runs ahead of theory.</div><br/></div></div><div id="38243137" class="c"><input type="checkbox" id="c-38243137" checked=""/><div class="controls bullet"><span class="by">GaggiX</span><span>|</span><a href="#38242976">parent</a><span>|</span><a href="#38245032">prev</a><span>|</span><a href="#38242914">next</a><span>|</span><label class="collapse" for="c-38243137">[-]</label><label class="expand" for="c-38243137">[2 more]</label></div><br/><div class="children"><div class="content">lcm-lora-sdv1-5 is 67.5M, lcm-lora-sdxl is 197M, so they are much smaller than the entire model, would be cool to check the rank used with these LoRAs tho</div><br/><div id="38244555" class="c"><input type="checkbox" id="c-38244555" checked=""/><div class="controls bullet"><span class="by">liuliu</span><span>|</span><a href="#38242976">root</a><span>|</span><a href="#38243137">parent</a><span>|</span><a href="#38242914">next</a><span>|</span><label class="collapse" for="c-38244555">[-]</label><label class="expand" for="c-38244555">[1 more]</label></div><br/><div class="children"><div class="content">64.</div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>