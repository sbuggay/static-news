<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1731920460311" as="style"/><link rel="stylesheet" href="styles.css?v=1731920460311"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://rkp.science/an-alternative-construction-of-shannon-entropy/">An alternative construction of Shannon entropy</a> <span class="domain">(<a href="https://rkp.science">rkp.science</a>)</span></div><div class="subtext"><span>rkp8000</span> | <span>9 comments</span></div><br/><div><div id="42170805" class="c"><input type="checkbox" id="c-42170805" checked=""/><div class="controls bullet"><span class="by">mturmon</span><span>|</span><a href="#42169463">next</a><span>|</span><label class="collapse" for="c-42170805">[-]</label><label class="expand" for="c-42170805">[1 more]</label></div><br/><div class="children"><div class="content">This is what I learned as the “theory of types” from Cover and Thomas, chapter 11, from original work by Imre Csiszar. See just under “theorem 6” in<p><a href="https:&#x2F;&#x2F;web.stanford.edu&#x2F;class&#x2F;ee376a&#x2F;files&#x2F;2017-18&#x2F;lecture_13.pdf" rel="nofollow">https:&#x2F;&#x2F;web.stanford.edu&#x2F;class&#x2F;ee376a&#x2F;files&#x2F;2017-18&#x2F;lecture_...</a><p>The key (which is not in OP) is not the construction of E log(p), but in being able to prove that the “typical set” exists (with arbitrarily high probability), and that the entropy is its size.</div><br/></div></div><div id="42169463" class="c"><input type="checkbox" id="c-42169463" checked=""/><div class="controls bullet"><span class="by">IdealeZahlen</span><span>|</span><a href="#42170805">prev</a><span>|</span><a href="#42167700">next</a><span>|</span><label class="collapse" for="c-42169463">[-]</label><label class="expand" for="c-42169463">[1 more]</label></div><br/><div class="children"><div class="content">Calling this &#x27;alternative&#x27; construction seems like coming full circle since this line of combinatorial argument is how Boltzmann came up with his H-function in the first place, which inspired Shannon&#x27;s entropy.</div><br/></div></div><div id="42167700" class="c"><input type="checkbox" id="c-42167700" checked=""/><div class="controls bullet"><span class="by">kgwgk</span><span>|</span><a href="#42169463">prev</a><span>|</span><a href="#42167516">next</a><span>|</span><label class="collapse" for="c-42167700">[-]</label><label class="expand" for="c-42167700">[1 more]</label></div><br/><div class="children"><div class="content">Seems similar to <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Principle_of_maximum_entropy#The_Wallis_derivation" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Principle_of_maximum_entropy#T...</a></div><br/></div></div><div id="42167516" class="c"><input type="checkbox" id="c-42167516" checked=""/><div class="controls bullet"><span class="by">xigoi</span><span>|</span><a href="#42167700">prev</a><span>|</span><a href="#42168628">next</a><span>|</span><label class="collapse" for="c-42167516">[-]</label><label class="expand" for="c-42167516">[2 more]</label></div><br/><div class="children"><div class="content">The site is unreadable on mobile because it disables overflow on the equations (which it shows as images, even though it’s 2024 and all modern browsers support MathML).</div><br/><div id="42168286" class="c"><input type="checkbox" id="c-42168286" checked=""/><div class="controls bullet"><span class="by">masfuerte</span><span>|</span><a href="#42167516">parent</a><span>|</span><a href="#42168628">next</a><span>|</span><label class="collapse" for="c-42168286">[-]</label><label class="expand" for="c-42168286">[1 more]</label></div><br/><div class="children"><div class="content">Today I learned!  I&#x27;d missed the news that MathML was back in Chrome.  I&#x27;ve been publishing web pages using MathML for years, along with a note that the equations don&#x27;t render in Chrome.  I can finally remove the note.</div><br/></div></div></div></div><div id="42168628" class="c"><input type="checkbox" id="c-42168628" checked=""/><div class="controls bullet"><span class="by">ivan_ah</span><span>|</span><a href="#42167516">prev</a><span>|</span><a href="#42168914">next</a><span>|</span><label class="collapse" for="c-42168628">[-]</label><label class="expand" for="c-42168628">[1 more]</label></div><br/><div class="children"><div class="content">Nice!<p>The key step of the derivation is counting the &quot;number of ways&quot; to get the histogram with bar heights L1, L2, ... Ln for a total of L observations.<p>I had to think a bit why the provided formula is true:<p><pre><code>   choose(L,L1) * choose(L-L1,L2) * ... * choose(Ln,Ln)
</code></pre>
The story I came up with for the first term, is that in the sequence of lenght L, you need to choose L1 locations that will get the symbol x1, so there are  choose(L,L1) ways to do that.  Next you have L-L1 remaining spots to fill, and L2 of those need to have the symbol x2, hence the choose(L-L1,L2) term, etc.</div><br/></div></div><div id="42168914" class="c"><input type="checkbox" id="c-42168914" checked=""/><div class="controls bullet"><span class="by">canjobear</span><span>|</span><a href="#42168628">prev</a><span>|</span><a href="#42169504">next</a><span>|</span><label class="collapse" for="c-42168914">[-]</label><label class="expand" for="c-42168914">[1 more]</label></div><br/><div class="children"><div class="content">Interestingly this has a rather frequentist flavor. The probabilities end up coming from frequency ratios in very large samples.</div><br/></div></div><div id="42169504" class="c"><input type="checkbox" id="c-42169504" checked=""/><div class="controls bullet"><span class="by">ziofill</span><span>|</span><a href="#42168914">prev</a><span>|</span><label class="collapse" for="c-42169504">[-]</label><label class="expand" for="c-42169504">[1 more]</label></div><br/><div class="children"><div class="content">Eh ok, but the trick is then taking the limit for L-&gt;infty and use Stirling’s approx which is what Shannon did</div><br/></div></div></div></div></div></div></div></body></html>