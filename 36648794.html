<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1688893260983" as="style"/><link rel="stylesheet" href="styles.css?v=1688893260983"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/raghavan/PdfGptIndexer">PdfGptIndexer: Indexing and searching PDF text data using GPT-2 and FAISS</a> <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>raghavankl</span> | <span>119 comments</span></div><br/><div><div id="36649049" class="c"><input type="checkbox" id="c-36649049" checked=""/><div class="controls bullet"><span class="by">chaxor</span><span>|</span><a href="#36649110">next</a><span>|</span><label class="collapse" for="c-36649049">[-]</label><label class="expand" for="c-36649049">[64 more]</label></div><br/><div class="children"><div class="content">The most frustrating thing about the many, <i>many</i> clones of this exact type of idea is that pretty much <i>all</i> of them require OpenAI.<p>Stop doing that.<p>You will have way more users if you make OpenAI (or anything that requires cloud) the &#x27;technically possible but pretty difficult art of hoops to make it happen&#x27; option, instead of the other way around.<p>The best way to make these apps IMO is to make them work <i>entirely</i> locally, with an easy string that&#x27;s swappable in a .toml file to any huggingface model.  Then if you <i>really</i> want OpenAI crap, you can make it happen with some other docker secret or `pass` chain or something with a key, while changing up the config.<p>The default should be local first, do as much as possible, and then <i>if the user &#x2F;really&#x2F; wants to</i>, make the collated prompt send a very few set of tokens to openAI.</div><br/><div id="36649342" class="c"><input type="checkbox" id="c-36649342" checked=""/><div class="controls bullet"><span class="by">JimmyRuska</span><span>|</span><a href="#36649049">parent</a><span>|</span><a href="#36649339">next</a><span>|</span><label class="collapse" for="c-36649342">[-]</label><label class="expand" for="c-36649342">[18 more]</label></div><br/><div class="children"><div class="content">It&#x27;s difficult to compete. A small business might answer 10,000 requests to their chat bot. The options are<p>- Pay openai less than $50mo<p>- Manage cloud gpus, hire ml engineers &gt; $1000&#x2F;mo<p>- Buy a local 4090 and put it under someone&#x27;s desk, $no reliability +$1500 fixed<p>Any larger business will need scalability and you still can&#x27;t compete with openai pricing.<p>Maybe one of you startup inclined people can make an openllama startup that charges by request and allows for finetuning, vector storage</div><br/><div id="36649800" class="c"><input type="checkbox" id="c-36649800" checked=""/><div class="controls bullet"><span class="by">xigency</span><span>|</span><a href="#36649049">root</a><span>|</span><a href="#36649342">parent</a><span>|</span><a href="#36649563">next</a><span>|</span><label class="collapse" for="c-36649800">[-]</label><label class="expand" for="c-36649800">[6 more]</label></div><br/><div class="children"><div class="content">I’ve got an expensive GPU at home I’m not even using because there aren’t that many things to do with it. Give me more local options.</div><br/><div id="36649816" class="c"><input type="checkbox" id="c-36649816" checked=""/><div class="controls bullet"><span class="by">JimmyRuska</span><span>|</span><a href="#36649049">root</a><span>|</span><a href="#36649800">parent</a><span>|</span><a href="#36652197">next</a><span>|</span><label class="collapse" for="c-36649816">[-]</label><label class="expand" for="c-36649816">[2 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;github.com&#x2F;oobabooga&#x2F;text-generation-webui">https:&#x2F;&#x2F;github.com&#x2F;oobabooga&#x2F;text-generation-webui</a><p><a href="https:&#x2F;&#x2F;github.com&#x2F;bentoml&#x2F;OpenLLM">https:&#x2F;&#x2F;github.com&#x2F;bentoml&#x2F;OpenLLM</a><p><a href="https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;LocalLLaMA&#x2F;top&#x2F;?t=month" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;LocalLLaMA&#x2F;top&#x2F;?t=month</a></div><br/><div id="36652255" class="c"><input type="checkbox" id="c-36652255" checked=""/><div class="controls bullet"><span class="by">ignoramous</span><span>|</span><a href="#36649049">root</a><span>|</span><a href="#36649816">parent</a><span>|</span><a href="#36652197">next</a><span>|</span><label class="collapse" for="c-36652255">[-]</label><label class="expand" for="c-36652255">[1 more]</label></div><br/><div class="children"><div class="content">And<p><a href="https:&#x2F;&#x2F;github.com&#x2F;go-skynet&#x2F;LocalAI">https:&#x2F;&#x2F;github.com&#x2F;go-skynet&#x2F;LocalAI</a><p><a href="https:&#x2F;&#x2F;github.com&#x2F;juliooa&#x2F;secondbrain">https:&#x2F;&#x2F;github.com&#x2F;juliooa&#x2F;secondbrain</a><p><a href="https:&#x2F;&#x2F;github.com&#x2F;louisgv&#x2F;local.ai">https:&#x2F;&#x2F;github.com&#x2F;louisgv&#x2F;local.ai</a></div><br/></div></div></div></div><div id="36652197" class="c"><input type="checkbox" id="c-36652197" checked=""/><div class="controls bullet"><span class="by">PeterStuer</span><span>|</span><a href="#36649049">root</a><span>|</span><a href="#36649800">parent</a><span>|</span><a href="#36649816">prev</a><span>|</span><a href="#36649951">next</a><span>|</span><label class="collapse" for="c-36652197">[-]</label><label class="expand" for="c-36652197">[1 more]</label></div><br/><div class="children"><div class="content">Even if you are not into coding there are many good AI tools that run local. Two very easy examples:<p>I&#x27;ve had great fun with the &quot;
Easiest 1-click way to install and use Stable Diffusion on your computer.&quot;<p><a href="https:&#x2F;&#x2F;github.com&#x2F;easydiffusion&#x2F;easydiffusion">https:&#x2F;&#x2F;github.com&#x2F;easydiffusion&#x2F;easydiffusion</a><p>And while Whisper is OpenAI, it is trivial to use locally and extremely usefull<p><a href="https:&#x2F;&#x2F;github.com&#x2F;chidiwilliams&#x2F;buzz">https:&#x2F;&#x2F;github.com&#x2F;chidiwilliams&#x2F;buzz</a></div><br/></div></div><div id="36649951" class="c"><input type="checkbox" id="c-36649951" checked=""/><div class="controls bullet"><span class="by">tikkun</span><span>|</span><a href="#36649049">root</a><span>|</span><a href="#36649800">parent</a><span>|</span><a href="#36652197">prev</a><span>|</span><a href="#36650128">next</a><span>|</span><label class="collapse" for="c-36649951">[-]</label><label class="expand" for="c-36649951">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;faraday.dev&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;faraday.dev&#x2F;</a></div><br/></div></div><div id="36650128" class="c"><input type="checkbox" id="c-36650128" checked=""/><div class="controls bullet"><span class="by">fragmede</span><span>|</span><a href="#36649049">root</a><span>|</span><a href="#36649800">parent</a><span>|</span><a href="#36649951">prev</a><span>|</span><a href="#36649563">next</a><span>|</span><label class="collapse" for="c-36650128">[-]</label><label class="expand" for="c-36650128">[1 more]</label></div><br/><div class="children"><div class="content">Let other people pay you to run their stuff on your hardware with Vast.ai.</div><br/></div></div></div></div><div id="36649563" class="c"><input type="checkbox" id="c-36649563" checked=""/><div class="controls bullet"><span class="by">srcthr</span><span>|</span><a href="#36649049">root</a><span>|</span><a href="#36649342">parent</a><span>|</span><a href="#36649800">prev</a><span>|</span><a href="#36650645">next</a><span>|</span><label class="collapse" for="c-36649563">[-]</label><label class="expand" for="c-36649563">[1 more]</label></div><br/><div class="children"><div class="content">People don&#x27;t scale. This is personal. Only 3 is a good choice for people in a site with the name hacker something.</div><br/></div></div><div id="36650645" class="c"><input type="checkbox" id="c-36650645" checked=""/><div class="controls bullet"><span class="by">rmbyrro</span><span>|</span><a href="#36649049">root</a><span>|</span><a href="#36649342">parent</a><span>|</span><a href="#36649563">prev</a><span>|</span><a href="#36649636">next</a><span>|</span><label class="collapse" for="c-36650645">[-]</label><label class="expand" for="c-36650645">[2 more]</label></div><br/><div class="children"><div class="content">It depends heavily on the use case, not org size. I consult for a ~70 people org that needs to process ~1M tokens per day. That costs $30K per day on OpenAI ChatGPT API. I&#x27;m sure this is not an extraordinary case.</div><br/><div id="36650898" class="c"><input type="checkbox" id="c-36650898" checked=""/><div class="controls bullet"><span class="by">serjester</span><span>|</span><a href="#36649049">root</a><span>|</span><a href="#36650645">parent</a><span>|</span><a href="#36649636">next</a><span>|</span><label class="collapse" for="c-36650898">[-]</label><label class="expand" for="c-36650898">[1 more]</label></div><br/><div class="children"><div class="content">Each person in the org needs 1M GPT-4 token and semantic search can’t be used to trim queries? I would be super curious to know more about this use case.</div><br/></div></div></div></div><div id="36649636" class="c"><input type="checkbox" id="c-36649636" checked=""/><div class="controls bullet"><span class="by">whoiscroberts</span><span>|</span><a href="#36649049">root</a><span>|</span><a href="#36649342">parent</a><span>|</span><a href="#36650645">prev</a><span>|</span><a href="#36651449">next</a><span>|</span><label class="collapse" for="c-36649636">[-]</label><label class="expand" for="c-36649636">[1 more]</label></div><br/><div class="children"><div class="content">I have a 4080, let’s do a startup. #cancode #hashomelab</div><br/></div></div><div id="36651449" class="c"><input type="checkbox" id="c-36651449" checked=""/><div class="controls bullet"><span class="by">rolisz</span><span>|</span><a href="#36649049">root</a><span>|</span><a href="#36649342">parent</a><span>|</span><a href="#36649636">prev</a><span>|</span><a href="#36649742">next</a><span>|</span><label class="collapse" for="c-36651449">[-]</label><label class="expand" for="c-36651449">[1 more]</label></div><br/><div class="children"><div class="content">FastChat-T5 can work for such a use case and it runs on (beefy) CPUs. With a 700$&#x2F;month instance, it can do 4 conversations simultaneously, without needing GPUs.<p>The instant a company has sensitive data, this becomes very viable.</div><br/></div></div><div id="36649742" class="c"><input type="checkbox" id="c-36649742" checked=""/><div class="controls bullet"><span class="by">tikkun</span><span>|</span><a href="#36649049">root</a><span>|</span><a href="#36649342">parent</a><span>|</span><a href="#36651449">prev</a><span>|</span><a href="#36650044">next</a><span>|</span><label class="collapse" for="c-36649742">[-]</label><label class="expand" for="c-36649742">[4 more]</label></div><br/><div class="children"><div class="content">Doing this. We soft launched yesterday with a paid Falcon-40B playground - 3 models for now Falcon 40b instruct, uncensored, and base. Adding API and per token pricing this week.<p><a href="https:&#x2F;&#x2F;api.llm-utils.org&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;api.llm-utils.org&#x2F;</a><p>And more models coming soon.<p>Vector storage isn’t on the roadmap (what stops using a separate vector store from working well? Could add to roadmap but want to add understand more first), and we could add fine tuning if it’s a common request.</div><br/><div id="36649796" class="c"><input type="checkbox" id="c-36649796" checked=""/><div class="controls bullet"><span class="by">JimmyRuska</span><span>|</span><a href="#36649049">root</a><span>|</span><a href="#36649742">parent</a><span>|</span><a href="#36652042">next</a><span>|</span><label class="collapse" for="c-36649796">[-]</label><label class="expand" for="c-36649796">[2 more]</label></div><br/><div class="children"><div class="content">Lots of people using LLMs to make chat bots from their existing datasets: customer service troubleshooting, FAQs, billing, scheduling. Being able to upload their own pdfs, spreadsheets, docx, crawl their home page, lets the chat bot become personalized to their use case. While you could locally query your own vectordb before prompting, people buy paid service so they won&#x27;t have to manage any of the technical details.<p>If people can drag and drop some files from their nas, you parse them with apache tika or similar <a href="https:&#x2F;&#x2F;tika.apache.org&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;tika.apache.org&#x2F;</a> , they can start using personalized branded bots. It also lets you do things like refusing to answer, if the vector database returns nothing and the use case requires a specific answer from the docs only (not the llm to make stuff up).</div><br/><div id="36649852" class="c"><input type="checkbox" id="c-36649852" checked=""/><div class="controls bullet"><span class="by">tikkun</span><span>|</span><a href="#36649049">root</a><span>|</span><a href="#36649796">parent</a><span>|</span><a href="#36652042">next</a><span>|</span><label class="collapse" for="c-36649852">[-]</label><label class="expand" for="c-36649852">[1 more]</label></div><br/><div class="children"><div class="content">For those use cases the “custom ChatGPT” tools I linked here might be better <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36649777">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36649777</a></div><br/></div></div></div></div><div id="36652042" class="c"><input type="checkbox" id="c-36652042" checked=""/><div class="controls bullet"><span class="by">tartakovsky</span><span>|</span><a href="#36649049">root</a><span>|</span><a href="#36649742">parent</a><span>|</span><a href="#36649796">prev</a><span>|</span><a href="#36650044">next</a><span>|</span><label class="collapse" for="c-36652042">[-]</label><label class="expand" for="c-36652042">[1 more]</label></div><br/><div class="children"><div class="content">Not secure...
NET::ERR_CERT_COMMON_NAME_INVALID
Subject: *.safezone.mcafee.com<p>Issuer: McAfee OV SSL CA 2<p>Expires on: Aug 3, 2023<p>Current date: Jul 8, 2023<p>PEM encoded chain:
-----BEGIN CERTIFICATE-----
MIIGfzCCBWegAwIBAgIQKt9VNrFtaozA1bILX1OcfzANBgkqhkiG9w0BAQsFADBk
MQswCQYDVQQGEwJVUzELMAkGA1UECBMCQ0</div><br/></div></div></div></div><div id="36650044" class="c"><input type="checkbox" id="c-36650044" checked=""/><div class="controls bullet"><span class="by">swader999</span><span>|</span><a href="#36649049">root</a><span>|</span><a href="#36649342">parent</a><span>|</span><a href="#36649742">prev</a><span>|</span><a href="#36649339">next</a><span>|</span><label class="collapse" for="c-36650044">[-]</label><label class="expand" for="c-36650044">[2 more]</label></div><br/><div class="children"><div class="content">Wait until winter time and heat your house!</div><br/><div id="36650707" class="c"><input type="checkbox" id="c-36650707" checked=""/><div class="controls bullet"><span class="by">quickthrower2</span><span>|</span><a href="#36649049">root</a><span>|</span><a href="#36650044">parent</a><span>|</span><a href="#36649339">next</a><span>|</span><label class="collapse" for="c-36650707">[-]</label><label class="expand" for="c-36650707">[1 more]</label></div><br/><div class="children"><div class="content">Good double use of that low entropy energy. Heat pumps excepted.</div><br/></div></div></div></div></div></div><div id="36649339" class="c"><input type="checkbox" id="c-36649339" checked=""/><div class="controls bullet"><span class="by">jstummbillig</span><span>|</span><a href="#36649049">parent</a><span>|</span><a href="#36649342">prev</a><span>|</span><a href="#36649443">next</a><span>|</span><label class="collapse" for="c-36649339">[-]</label><label class="expand" for="c-36649339">[7 more]</label></div><br/><div class="children"><div class="content">What do you (or anyone else, feel free to chime in) do with other LLMs that makes them useable for anything that is not strictly tinkering?<p>Here is my premise: We are past the wonder stage. I want to actually get stuff done efficiently. From what I have tested so far, the only model that allows me to do that halfway reliably is GPT-4.<p>Am I incompetent or are we really just wishfully thinking in HN spirit that other LLMs are a lot better at being applied to actual tasks that require a certain level of quality, consistency and reliability?</div><br/><div id="36649918" class="c"><input type="checkbox" id="c-36649918" checked=""/><div class="controls bullet"><span class="by">mcmoor</span><span>|</span><a href="#36649049">root</a><span>|</span><a href="#36649339">parent</a><span>|</span><a href="#36649851">next</a><span>|</span><label class="collapse" for="c-36649918">[-]</label><label class="expand" for="c-36649918">[4 more]</label></div><br/><div class="children"><div class="content">I still wonder what makes GPT-4 so much better than its contemporaries. That&#x27;s why I saw tons of people trying to explain how GPT-4 works starting from simple neural network distasteful, tons of people already knew and do that but none of them is nearly close to GPT-4.l</div><br/><div id="36650363" class="c"><input type="checkbox" id="c-36650363" checked=""/><div class="controls bullet"><span class="by">losteric</span><span>|</span><a href="#36649049">root</a><span>|</span><a href="#36649918">parent</a><span>|</span><a href="#36650318">next</a><span>|</span><label class="collapse" for="c-36650363">[-]</label><label class="expand" for="c-36650363">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I still wonder what makes GPT-4 so much better than its contemporaries.<p>OpenAI have had many years to craft their dataset down from the noisy public datasets, and GPT4 is (supposedly) a mixture of 8 &quot;expert models&quot; each of which is 220B (5x+ larger than the Falcon 40B) with a total of 1.7B parameters (3x+ Google&#x27;s huge 540B PaLM). The hardware and software to train networks of that scale is also a deep moat. Relatively speaking, the model architecture (&quot;gpt from scratch&quot;) is the easiest piece.</div><br/></div></div><div id="36650318" class="c"><input type="checkbox" id="c-36650318" checked=""/><div class="controls bullet"><span class="by">two_in_one</span><span>|</span><a href="#36649049">root</a><span>|</span><a href="#36649918">parent</a><span>|</span><a href="#36650363">prev</a><span>|</span><a href="#36650627">next</a><span>|</span><label class="collapse" for="c-36650318">[-]</label><label class="expand" for="c-36650318">[1 more]</label></div><br/><div class="children"><div class="content">From my understanding. GPT-4 is the biggest, or one of the biggest. It was trained on low quality internet datasets, like the others. What makes it different is post-training on custom data with human supervision. We know they even outsourced that to Africa. Second, they integrated it with external tools. Like Python interpreter, internet browser. But the first is most important. Also most likely they have experimented and found some tricks which make it bit better.</div><br/></div></div><div id="36650627" class="c"><input type="checkbox" id="c-36650627" checked=""/><div class="controls bullet"><span class="by">sp332</span><span>|</span><a href="#36649049">root</a><span>|</span><a href="#36649918">parent</a><span>|</span><a href="#36650318">prev</a><span>|</span><a href="#36649851">next</a><span>|</span><label class="collapse" for="c-36650627">[-]</label><label class="expand" for="c-36650627">[1 more]</label></div><br/><div class="children"><div class="content">They pay tons of people to type out conversations that they can feed into it. It&#x27;s just a lot of people doing a lot of work.</div><br/></div></div></div></div><div id="36649851" class="c"><input type="checkbox" id="c-36649851" checked=""/><div class="controls bullet"><span class="by">xmprt</span><span>|</span><a href="#36649049">root</a><span>|</span><a href="#36649339">parent</a><span>|</span><a href="#36649918">prev</a><span>|</span><a href="#36651759">next</a><span>|</span><label class="collapse" for="c-36649851">[-]</label><label class="expand" for="c-36649851">[1 more]</label></div><br/><div class="children"><div class="content">This line of thinking only works if it&#x27;s impossible to imagine a world where OpenAI isn&#x27;t the leader. In 2 years if the non OpenAI models are better then it will serve us much better to allow these tools to work with other models as well.</div><br/></div></div><div id="36651759" class="c"><input type="checkbox" id="c-36651759" checked=""/><div class="controls bullet"><span class="by">freediver</span><span>|</span><a href="#36649049">root</a><span>|</span><a href="#36649339">parent</a><span>|</span><a href="#36649851">prev</a><span>|</span><a href="#36649443">next</a><span>|</span><label class="collapse" for="c-36651759">[-]</label><label class="expand" for="c-36651759">[1 more]</label></div><br/><div class="children"><div class="content">You are correct in this assesment. A majority of individuals and startups playing around with turning LLMs into products aim to be prepared for the arrival of the subsequent generation of models. When that occurs, they&#x27;ll already have a product or company in place and can simply integrate the new models.<p>Models are getting commoditized, well executed ideas are not.</div><br/></div></div></div></div><div id="36649443" class="c"><input type="checkbox" id="c-36649443" checked=""/><div class="controls bullet"><span class="by">akira2501</span><span>|</span><a href="#36649049">parent</a><span>|</span><a href="#36649339">prev</a><span>|</span><a href="#36649861">next</a><span>|</span><label class="collapse" for="c-36649443">[-]</label><label class="expand" for="c-36649443">[7 more]</label></div><br/><div class="children"><div class="content">&gt; is that pretty much all of them require OpenAI.<p>They&#x27;re not here to release an actual product.  They&#x27;re here to release part of a CV proving they have &quot;OpenAI&quot; experience.  I&#x27;m assuming this is the result of OpenAI not actually having any homegrown certification program of their own.</div><br/><div id="36649512" class="c"><input type="checkbox" id="c-36649512" checked=""/><div class="controls bullet"><span class="by">gumby</span><span>|</span><a href="#36649049">root</a><span>|</span><a href="#36649443">parent</a><span>|</span><a href="#36649861">next</a><span>|</span><label class="collapse" for="c-36649512">[-]</label><label class="expand" for="c-36649512">[6 more]</label></div><br/><div class="children"><div class="content">&gt; OpenAI not actually having any homegrown certification program<p>A bit off topic but where are certifications (e.g. Cisco, Microsoft) useful?  I am sure they <i>are</i> useful (both to candidates and companies) because people go to the effort to get these certs, and if they were useless everyone would have stopped long ago.  I don&#x27;t assume people do it for ego satisfaction.<p>But I&#x27;ve never worked anywhere where it has come up as an interview criterion (nobody has ever pointed it out when we are looking at a resume, for example).  Is it a big business thing?  Is it just an HR thing?</div><br/><div id="36649869" class="c"><input type="checkbox" id="c-36649869" checked=""/><div class="controls bullet"><span class="by">codingdave</span><span>|</span><a href="#36649049">root</a><span>|</span><a href="#36649512">parent</a><span>|</span><a href="#36649553">next</a><span>|</span><label class="collapse" for="c-36649869">[-]</label><label class="expand" for="c-36649869">[1 more]</label></div><br/><div class="children"><div class="content">It is a consulting &#x2F; business partner thing. Different levels in the business partner programs require minimum number of certified employees in your consulting firm. So if you work in that slice of the industry, certifications matter. Outside of that... not so much.</div><br/></div></div><div id="36649553" class="c"><input type="checkbox" id="c-36649553" checked=""/><div class="controls bullet"><span class="by">tw04</span><span>|</span><a href="#36649049">root</a><span>|</span><a href="#36649512">parent</a><span>|</span><a href="#36649869">prev</a><span>|</span><a href="#36649956">next</a><span>|</span><label class="collapse" for="c-36649553">[-]</label><label class="expand" for="c-36649553">[1 more]</label></div><br/><div class="children"><div class="content">Mainly when applying for a corporate job where you have 0 referrals.  It&#x27;s a guidepost that you at least have some idea what you&#x27;re doing and are worth interviewing when people can&#x27;t find someone who knows you and your previous work.</div><br/></div></div><div id="36649956" class="c"><input type="checkbox" id="c-36649956" checked=""/><div class="controls bullet"><span class="by">halfcat</span><span>|</span><a href="#36649049">root</a><span>|</span><a href="#36649512">parent</a><span>|</span><a href="#36649553">prev</a><span>|</span><a href="#36649532">next</a><span>|</span><label class="collapse" for="c-36649956">[-]</label><label class="expand" for="c-36649956">[2 more]</label></div><br/><div class="children"><div class="content">Years ago, companies could get discounts if they were a “certified gold partner” or whatever.<p>To be a partner, the company would need a certain number of certifications among their employees, so there was tangible value to companies who either used a ton of Microsoft licensing or Cisco&#x2F;Dell hardware, or resold those to their own clients (better discount equating to higher margin).<p>In some cases, getting the higher level certifications like Cisco CCIE was a virtual guarantee of a good job.<p>I feel like this has become less of a thing in recent years, but I’m not involved in that space anymore.</div><br/><div id="36651178" class="c"><input type="checkbox" id="c-36651178" checked=""/><div class="controls bullet"><span class="by">atenni</span><span>|</span><a href="#36649049">root</a><span>|</span><a href="#36649956">parent</a><span>|</span><a href="#36649532">next</a><span>|</span><label class="collapse" for="c-36651178">[-]</label><label class="expand" for="c-36651178">[1 more]</label></div><br/><div class="children"><div class="content">Definitely still a thing with Azure and Atlassian</div><br/></div></div></div></div><div id="36649532" class="c"><input type="checkbox" id="c-36649532" checked=""/><div class="controls bullet"><span class="by">n4te</span><span>|</span><a href="#36649049">root</a><span>|</span><a href="#36649512">parent</a><span>|</span><a href="#36649956">prev</a><span>|</span><a href="#36649861">next</a><span>|</span><label class="collapse" for="c-36649532">[-]</label><label class="expand" for="c-36649532">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve only ever seen it as a people who don&#x27;t have a job thing.</div><br/></div></div></div></div></div></div><div id="36649861" class="c"><input type="checkbox" id="c-36649861" checked=""/><div class="controls bullet"><span class="by">anton5mith2</span><span>|</span><a href="#36649049">parent</a><span>|</span><a href="#36649443">prev</a><span>|</span><a href="#36649493">next</a><span>|</span><label class="collapse" for="c-36649861">[-]</label><label class="expand" for="c-36649861">[2 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;mudler.pm&#x2F;posts&#x2F;smart-slackbot-for-teams&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;mudler.pm&#x2F;posts&#x2F;smart-slackbot-for-teams&#x2F;</a> with LocalAI?</div><br/><div id="36650036" class="c"><input type="checkbox" id="c-36650036" checked=""/><div class="controls bullet"><span class="by">behnamoh</span><span>|</span><a href="#36649049">root</a><span>|</span><a href="#36649861">parent</a><span>|</span><a href="#36649493">next</a><span>|</span><label class="collapse" for="c-36650036">[-]</label><label class="expand" for="c-36650036">[1 more]</label></div><br/><div class="children"><div class="content">This is a well-written tutorial and it&#x27;s exactly what I was looking for! Thanks so much.</div><br/></div></div></div></div><div id="36649493" class="c"><input type="checkbox" id="c-36649493" checked=""/><div class="controls bullet"><span class="by">hospitalJail</span><span>|</span><a href="#36649049">parent</a><span>|</span><a href="#36649861">prev</a><span>|</span><a href="#36649302">next</a><span>|</span><label class="collapse" for="c-36649493">[-]</label><label class="expand" for="c-36649493">[1 more]</label></div><br/><div class="children"><div class="content">ClosedAI has freaked me out with how much power they have, and how irresponsible they are with it.<p>I&#x27;m so horrified that they are going to take away the ability to ask medical questions when the AMA comes knocking at their door.</div><br/></div></div><div id="36649302" class="c"><input type="checkbox" id="c-36649302" checked=""/><div class="controls bullet"><span class="by">trolan</span><span>|</span><a href="#36649049">parent</a><span>|</span><a href="#36649493">prev</a><span>|</span><a href="#36649591">next</a><span>|</span><label class="collapse" for="c-36649302">[-]</label><label class="expand" for="c-36649302">[13 more]</label></div><br/><div class="children"><div class="content">The only OpenAI &#x27;crap&#x27; being used here is to generate the embeddings. Right now, OpenAI has some of the best and cheapest embeddings possible, especially for personal projects.<p>Once the vectors are created tho, you&#x27;re completely off the cloud if you so choose.<p>You can always swap out the embedding generator too, because LangChain abstracts that for your exact gripes.<p>Everything else is already using huggingface here and can be swapped out for any other model besides GPT2 which supports the prompts.</div><br/><div id="36651867" class="c"><input type="checkbox" id="c-36651867" checked=""/><div class="controls bullet"><span class="by">aledalgrande</span><span>|</span><a href="#36649049">root</a><span>|</span><a href="#36649302">parent</a><span>|</span><a href="#36649311">next</a><span>|</span><label class="collapse" for="c-36651867">[-]</label><label class="expand" for="c-36651867">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Once the vectors are created tho, you&#x27;re completely off the cloud if you so choose.<p>Ehr no? You&#x27;ll need to also create an embedding of your query, which makes you totally dependent on OpenAI. If you swap out embedding algorithm you will have to regenerate all the embeddings as well, they might not be even the same size.</div><br/></div></div><div id="36649311" class="c"><input type="checkbox" id="c-36649311" checked=""/><div class="controls bullet"><span class="by">space_fountain</span><span>|</span><a href="#36649049">root</a><span>|</span><a href="#36649302">parent</a><span>|</span><a href="#36651867">prev</a><span>|</span><a href="#36649633">next</a><span>|</span><label class="collapse" for="c-36649311">[-]</label><label class="expand" for="c-36649311">[9 more]</label></div><br/><div class="children"><div class="content">Do you have citations on OpenAI embeddings being some of the cheapest and best? The signs I&#x27;ve seen points almost in the opposite direction?</div><br/><div id="36649480" class="c"><input type="checkbox" id="c-36649480" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#36649049">root</a><span>|</span><a href="#36649311">parent</a><span>|</span><a href="#36649460">next</a><span>|</span><label class="collapse" for="c-36649480">[-]</label><label class="expand" for="c-36649480">[6 more]</label></div><br/><div class="children"><div class="content">The only embeddings I currently see listed on <a href="https:&#x2F;&#x2F;openai.com&#x2F;pricing" rel="nofollow noreferrer">https:&#x2F;&#x2F;openai.com&#x2F;pricing</a> are Ada v2, at $0.1&#x2F;million tokens.<p>Even if the alternative is free, how much do you value your time, how long will it take to set up an alternative, and how much use will you get out of it? If you&#x27;re getting less than a million tokens and it takes half an hour longer to set up, you&#x27;d better be a student with zero literally income because that cost of time matches the UN abject poverty level. This is also why it&#x27;s never been the year of linux on the desktop, and why most businesses still don&#x27;t use Libre Office and GIMP.<p>I can&#x27;t speak for quality; even if I used that API directly, this whole area is changing too fast to really keep up.</div><br/><div id="36649686" class="c"><input type="checkbox" id="c-36649686" checked=""/><div class="controls bullet"><span class="by">akiselev</span><span>|</span><a href="#36649049">root</a><span>|</span><a href="#36649480">parent</a><span>|</span><a href="#36651473">next</a><span>|</span><label class="collapse" for="c-36649686">[-]</label><label class="expand" for="c-36649686">[1 more]</label></div><br/><div class="children"><div class="content">If you look at a embeddings leaderboard [1], one of the top competitors called InstructorXL [2] is just a pip install away. It&#x27;s neck and neck with Ada v2 except for a shorter input length and half the dimensions, with the added benefit that you&#x27;ll always have the model available.<p>Most of the other options just work with the transformers library.<p>[1] <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;mteb&#x2F;leaderboard" rel="nofollow noreferrer">https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;mteb&#x2F;leaderboard</a><p>[2] <a href="https:&#x2F;&#x2F;github.com&#x2F;HKUNLP&#x2F;instructor-embedding">https:&#x2F;&#x2F;github.com&#x2F;HKUNLP&#x2F;instructor-embedding</a></div><br/></div></div><div id="36651473" class="c"><input type="checkbox" id="c-36651473" checked=""/><div class="controls bullet"><span class="by">rolisz</span><span>|</span><a href="#36649049">root</a><span>|</span><a href="#36649480">parent</a><span>|</span><a href="#36649686">prev</a><span>|</span><a href="#36651885">next</a><span>|</span><label class="collapse" for="c-36651473">[-]</label><label class="expand" for="c-36651473">[2 more]</label></div><br/><div class="children"><div class="content">If you&#x27;ve never coded or used Python before, yeah, go with OpenAI. Otherwise, generating embeddings with SentenceBERT takes 5 minutes.<p>And from my personal experience Ada embeddings are not the best. They are large (makes aproximate searching harder), are distributed weirdly, and zimply put, other embeddings give better results for retrieval.<p>Another advantage is that you are not an OA&#x27;s whim: they just announced the deprecation of some previous model. What are you going to do when they will deprecate Ada v2 and you&#x27;ve built a huge system on top of it? You&#x27;ll have to regenerate embeddings and hope everything still works just as well.</div><br/><div id="36651764" class="c"><input type="checkbox" id="c-36651764" checked=""/><div class="controls bullet"><span class="by">space_fountain</span><span>|</span><a href="#36649049">root</a><span>|</span><a href="#36651473">parent</a><span>|</span><a href="#36651885">next</a><span>|</span><label class="collapse" for="c-36651764">[-]</label><label class="expand" for="c-36651764">[1 more]</label></div><br/><div class="children"><div class="content">Yes, exactly this, I also want to say I&#x27;m not someone who generally thinks open models are better. I think embeddings just haven&#x27;t been a focus for OpenAI and it shows. Maybe in the future they will focus on it</div><br/></div></div></div></div><div id="36651885" class="c"><input type="checkbox" id="c-36651885" checked=""/><div class="controls bullet"><span class="by">avereveard</span><span>|</span><a href="#36649049">root</a><span>|</span><a href="#36649480">parent</a><span>|</span><a href="#36651473">prev</a><span>|</span><a href="#36650144">next</a><span>|</span><label class="collapse" for="c-36651885">[-]</label><label class="expand" for="c-36651885">[1 more]</label></div><br/><div class="children"><div class="content">Setting up an embedding alternative out of huggingface sentence transformers is fairly easy, the magical thing openai does is that they will create embedding of 8192 characters at a time while most other emerging will force you to chunk your documents in 512 characters long sequences, losing lot of context, multiplying your queries result, search times etc</div><br/></div></div><div id="36650144" class="c"><input type="checkbox" id="c-36650144" checked=""/><div class="controls bullet"><span class="by">arrowsmith</span><span>|</span><a href="#36649049">root</a><span>|</span><a href="#36649480">parent</a><span>|</span><a href="#36651885">prev</a><span>|</span><a href="#36649460">next</a><span>|</span><label class="collapse" for="c-36650144">[-]</label><label class="expand" for="c-36650144">[1 more]</label></div><br/><div class="children"><div class="content">Running models on your own hardware isn&#x27;t just about cost, there are privacy concerns too.</div><br/></div></div></div></div><div id="36649460" class="c"><input type="checkbox" id="c-36649460" checked=""/><div class="controls bullet"><span class="by">colobas</span><span>|</span><a href="#36649049">root</a><span>|</span><a href="#36649311">parent</a><span>|</span><a href="#36649480">prev</a><span>|</span><a href="#36649633">next</a><span>|</span><label class="collapse" for="c-36649460">[-]</label><label class="expand" for="c-36649460">[2 more]</label></div><br/><div class="children"><div class="content">Can you elucidate on what those signs are? Thanks in advance</div><br/><div id="36649597" class="c"><input type="checkbox" id="c-36649597" checked=""/><div class="controls bullet"><span class="by">muggermuch</span><span>|</span><a href="#36649049">root</a><span>|</span><a href="#36649460">parent</a><span>|</span><a href="#36649633">next</a><span>|</span><label class="collapse" for="c-36649597">[-]</label><label class="expand" for="c-36649597">[1 more]</label></div><br/><div class="children"><div class="content">As per the Massive Text Embedding Benchmark (MTEB) Leaderboard maintained by Huggingface, OpenAI&#x27;s embedding models are <i>not</i> the best.<p><a href="https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;mteb&#x2F;leaderboard" rel="nofollow noreferrer">https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;mteb&#x2F;leaderboard</a><p>Of course, that&#x27;s far from saying that they&#x27;re the worst, or even headed that way. Just not the best (those would be a couple of fully opensource models, including those of the Instructor family, which we use at my workplace).</div><br/></div></div></div></div></div></div><div id="36649633" class="c"><input type="checkbox" id="c-36649633" checked=""/><div class="controls bullet"><span class="by">throwaway675309</span><span>|</span><a href="#36649049">root</a><span>|</span><a href="#36649302">parent</a><span>|</span><a href="#36649311">prev</a><span>|</span><a href="#36649591">next</a><span>|</span><label class="collapse" for="c-36649633">[-]</label><label class="expand" for="c-36649633">[2 more]</label></div><br/><div class="children"><div class="content">What? It&#x27;s only one file, and it definitely looks like it&#x27;s using openAI to make the actual queries.<p><pre><code>    qa = ConversationalRetrievalChain.from_llm(OpenAI(temperature=0.1), db.as_retriever())</code></pre></div><br/><div id="36650670" class="c"><input type="checkbox" id="c-36650670" checked=""/><div class="controls bullet"><span class="by">sp332</span><span>|</span><a href="#36649049">root</a><span>|</span><a href="#36649633">parent</a><span>|</span><a href="#36649591">next</a><span>|</span><label class="collapse" for="c-36650670">[-]</label><label class="expand" for="c-36650670">[1 more]</label></div><br/><div class="children"><div class="content">You can change the arguments to from_llm() to point to a local model instead. Example here: <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;TheBloke&#x2F;MPT-7B-Instruct-GGML&#x2F;discussions&#x2F;2" rel="nofollow noreferrer">https:&#x2F;&#x2F;huggingface.co&#x2F;TheBloke&#x2F;MPT-7B-Instruct-GGML&#x2F;discuss...</a></div><br/></div></div></div></div></div></div><div id="36649591" class="c"><input type="checkbox" id="c-36649591" checked=""/><div class="controls bullet"><span class="by">dmezzetti</span><span>|</span><a href="#36649049">parent</a><span>|</span><a href="#36649302">prev</a><span>|</span><a href="#36649264">next</a><span>|</span><label class="collapse" for="c-36649591">[-]</label><label class="expand" for="c-36649591">[1 more]</label></div><br/><div class="children"><div class="content">txtai makes it easy to use Hugging Face embeddings and Faiss, all local and configurable.
<a href="https:&#x2F;&#x2F;github.com&#x2F;neuml&#x2F;txtai">https:&#x2F;&#x2F;github.com&#x2F;neuml&#x2F;txtai</a><p>paperai is a sub-project focused on processing medical&#x2F;scientific papers. 
<a href="https:&#x2F;&#x2F;github.com&#x2F;neuml&#x2F;paperai">https:&#x2F;&#x2F;github.com&#x2F;neuml&#x2F;paperai</a><p>Disclaimer: I am the author of both</div><br/></div></div><div id="36649264" class="c"><input type="checkbox" id="c-36649264" checked=""/><div class="controls bullet"><span class="by">sheeshkebab</span><span>|</span><a href="#36649049">parent</a><span>|</span><a href="#36649591">prev</a><span>|</span><a href="#36649106">next</a><span>|</span><label class="collapse" for="c-36649264">[-]</label><label class="expand" for="c-36649264">[1 more]</label></div><br/><div class="children"><div class="content">Amen, local first should be the default for anything that sucks all my data.<p>Although until these things can do my laundry none of them deserve any of my compute time either.</div><br/></div></div><div id="36649106" class="c"><input type="checkbox" id="c-36649106" checked=""/><div class="controls bullet"><span class="by">zikohh</span><span>|</span><a href="#36649049">parent</a><span>|</span><a href="#36649264">prev</a><span>|</span><a href="#36649318">next</a><span>|</span><label class="collapse" for="c-36649106">[-]</label><label class="expand" for="c-36649106">[8 more]</label></div><br/><div class="children"><div class="content">Have you seen PrivateGPT. It&#x27;s quite good and free.</div><br/><div id="36649451" class="c"><input type="checkbox" id="c-36649451" checked=""/><div class="controls bullet"><span class="by">mvkel</span><span>|</span><a href="#36649049">root</a><span>|</span><a href="#36649106">parent</a><span>|</span><a href="#36649164">next</a><span>|</span><label class="collapse" for="c-36649451">[-]</label><label class="expand" for="c-36649451">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not nearly usable. It&#x27;s functional in that it spits out a response. Can that response be used for anything useful? No.</div><br/></div></div><div id="36649164" class="c"><input type="checkbox" id="c-36649164" checked=""/><div class="controls bullet"><span class="by">yoyopa</span><span>|</span><a href="#36649049">root</a><span>|</span><a href="#36649106">parent</a><span>|</span><a href="#36649451">prev</a><span>|</span><a href="#36649318">next</a><span>|</span><label class="collapse" for="c-36649164">[-]</label><label class="expand" for="c-36649164">[6 more]</label></div><br/><div class="children"><div class="content">what hardware do you need for that?</div><br/><div id="36649808" class="c"><input type="checkbox" id="c-36649808" checked=""/><div class="controls bullet"><span class="by">qingcharles</span><span>|</span><a href="#36649049">root</a><span>|</span><a href="#36649164">parent</a><span>|</span><a href="#36649258">next</a><span>|</span><label class="collapse" for="c-36649808">[-]</label><label class="expand" for="c-36649808">[1 more]</label></div><br/><div class="children"><div class="content">It runs (slowly) on my 6 year old i5 laptop.</div><br/></div></div><div id="36649258" class="c"><input type="checkbox" id="c-36649258" checked=""/><div class="controls bullet"><span class="by">drdaeman</span><span>|</span><a href="#36649049">root</a><span>|</span><a href="#36649164">parent</a><span>|</span><a href="#36649808">prev</a><span>|</span><a href="#36649318">next</a><span>|</span><label class="collapse" for="c-36649258">[-]</label><label class="expand" for="c-36649258">[4 more]</label></div><br/><div class="children"><div class="content">Consumer-grade, AFAIK it&#x27;s GPT4All with LLaMA.</div><br/><div id="36652225" class="c"><input type="checkbox" id="c-36652225" checked=""/><div class="controls bullet"><span class="by">raffraffraff</span><span>|</span><a href="#36649049">root</a><span>|</span><a href="#36649258">parent</a><span>|</span><a href="#36649303">next</a><span>|</span><label class="collapse" for="c-36652225">[-]</label><label class="expand" for="c-36652225">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s doesn&#x27;t really answer the question.<p>Neither does the github &quot;System requirements&quot; section, which I find disappointing. Ideally, it should give minimum memory requirements and rudimentary performance benchmark table for a sample data set, across a handful of setups (eg, Intel CPU, Apple M1, AMD CPU, with&#x2F;without a bunch of common GPUs). With that information I would know whether or not it&#x27;s worth my time even trying it out on my laptop.<p>Edit: lol, I went through 2 pages of the issues on the github page and most of them could be avoided by putting this basic information into the system requirements:<p><a href="https:&#x2F;&#x2F;github.com&#x2F;imartinez&#x2F;privateGPT&#x2F;issues&#x2F;174">https:&#x2F;&#x2F;github.com&#x2F;imartinez&#x2F;privateGPT&#x2F;issues&#x2F;174</a>
<a href="https:&#x2F;&#x2F;github.com&#x2F;imartinez&#x2F;privateGPT&#x2F;issues&#x2F;179">https:&#x2F;&#x2F;github.com&#x2F;imartinez&#x2F;privateGPT&#x2F;issues&#x2F;179</a>
<a href="https:&#x2F;&#x2F;github.com&#x2F;imartinez&#x2F;privateGPT&#x2F;issues&#x2F;104">https:&#x2F;&#x2F;github.com&#x2F;imartinez&#x2F;privateGPT&#x2F;issues&#x2F;104</a>
<a href="https:&#x2F;&#x2F;github.com&#x2F;imartinez&#x2F;privateGPT&#x2F;issues&#x2F;141">https:&#x2F;&#x2F;github.com&#x2F;imartinez&#x2F;privateGPT&#x2F;issues&#x2F;141</a>
<a href="https:&#x2F;&#x2F;github.com&#x2F;imartinez&#x2F;privateGPT&#x2F;issues&#x2F;282">https:&#x2F;&#x2F;github.com&#x2F;imartinez&#x2F;privateGPT&#x2F;issues&#x2F;282</a>
<a href="https:&#x2F;&#x2F;github.com&#x2F;imartinez&#x2F;privateGPT&#x2F;issues&#x2F;316">https:&#x2F;&#x2F;github.com&#x2F;imartinez&#x2F;privateGPT&#x2F;issues&#x2F;316</a>
<a href="https:&#x2F;&#x2F;github.com&#x2F;imartinez&#x2F;privateGPT&#x2F;issues&#x2F;333">https:&#x2F;&#x2F;github.com&#x2F;imartinez&#x2F;privateGPT&#x2F;issues&#x2F;333</a><p>... And lots more! Some of these people have 128gb memory and 32 cores, and still find it &quot;very slow&quot;. Others having memory pool errors. Some of the answers hand-waving at needing &quot;a more better computer&quot;<p>I reckon a lot of these issues could be closed and linked to a single ticket for proper hardware requirements in the readme.</div><br/></div></div><div id="36649303" class="c"><input type="checkbox" id="c-36649303" checked=""/><div class="controls bullet"><span class="by">EGreg</span><span>|</span><a href="#36649049">root</a><span>|</span><a href="#36649258">parent</a><span>|</span><a href="#36652225">prev</a><span>|</span><a href="#36649318">next</a><span>|</span><label class="collapse" for="c-36649303">[-]</label><label class="expand" for="c-36649303">[2 more]</label></div><br/><div class="children"><div class="content">Link?</div><br/><div id="36649417" class="c"><input type="checkbox" id="c-36649417" checked=""/><div class="controls bullet"><span class="by">hoopsman</span><span>|</span><a href="#36649049">root</a><span>|</span><a href="#36649303">parent</a><span>|</span><a href="#36649318">next</a><span>|</span><label class="collapse" for="c-36649417">[-]</label><label class="expand" for="c-36649417">[1 more]</label></div><br/><div class="children"><div class="content">Presumably <a href="https:&#x2F;&#x2F;github.com&#x2F;imartinez&#x2F;privateGPT">https:&#x2F;&#x2F;github.com&#x2F;imartinez&#x2F;privateGPT</a></div><br/></div></div></div></div></div></div></div></div></div></div><div id="36649318" class="c"><input type="checkbox" id="c-36649318" checked=""/><div class="controls bullet"><span class="by">AussieWog93</span><span>|</span><a href="#36649049">parent</a><span>|</span><a href="#36649106">prev</a><span>|</span><a href="#36649169">next</a><span>|</span><label class="collapse" for="c-36649318">[-]</label><label class="expand" for="c-36649318">[1 more]</label></div><br/><div class="children"><div class="content">Honestly, for me, getting good quality results matters way more than keeping my searches private.  And for that, nothing compares with GPT4.</div><br/></div></div><div id="36651148" class="c"><input type="checkbox" id="c-36651148" checked=""/><div class="controls bullet"><span class="by">bicx</span><span>|</span><a href="#36649049">parent</a><span>|</span><a href="#36649169">prev</a><span>|</span><a href="#36649548">next</a><span>|</span><label class="collapse" for="c-36651148">[-]</label><label class="expand" for="c-36651148">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Stop doing that.<p>This commanding attitude on HN seems to be getting worse lately. Not a fan.</div><br/></div></div><div id="36649548" class="c"><input type="checkbox" id="c-36649548" checked=""/><div class="controls bullet"><span class="by">persedes</span><span>|</span><a href="#36649049">parent</a><span>|</span><a href="#36651148">prev</a><span>|</span><a href="#36649244">next</a><span>|</span><label class="collapse" for="c-36649548">[-]</label><label class="expand" for="c-36649548">[1 more]</label></div><br/><div class="children"><div class="content">Gpt4all does exactly that. You can choose between local model or bring your own openai token.</div><br/></div></div><div id="36649244" class="c"><input type="checkbox" id="c-36649244" checked=""/><div class="controls bullet"><span class="by">Der_Einzige</span><span>|</span><a href="#36649049">parent</a><span>|</span><a href="#36649548">prev</a><span>|</span><a href="#36649110">next</a><span>|</span><label class="collapse" for="c-36649244">[-]</label><label class="expand" for="c-36649244">[1 more]</label></div><br/><div class="children"><div class="content">Even GPT-3.5-turbo-16K isn&#x27;t good enough for most retrieval augmented generation tasks.<p>Locally ran LLMs are far worse.<p>I don&#x27;t like it either, but for now, if you want good RAG, you have to use GPT-4</div><br/></div></div></div></div><div id="36649110" class="c"><input type="checkbox" id="c-36649110" checked=""/><div class="controls bullet"><span class="by">hi</span><span>|</span><a href="#36649049">prev</a><span>|</span><a href="#36649495">next</a><span>|</span><label class="collapse" for="c-36649110">[-]</label><label class="expand" for="c-36649110">[17 more]</label></div><br/><div class="children"><div class="content">Keep your data private and don&#x27;t leak it to third parties. Use something like privateGPT (32k stars). Not your keys, not your data.<p>&quot;Interact privately with your documents using the power of GPT, 100% privately, no data leaks&quot;[0]<p>[0] <a href="https:&#x2F;&#x2F;github.com&#x2F;imartinez&#x2F;privateGPT">https:&#x2F;&#x2F;github.com&#x2F;imartinez&#x2F;privateGPT</a></div><br/><div id="36651382" class="c"><input type="checkbox" id="c-36651382" checked=""/><div class="controls bullet"><span class="by">woeirua</span><span>|</span><a href="#36649110">parent</a><span>|</span><a href="#36649306">next</a><span>|</span><label class="collapse" for="c-36651382">[-]</label><label class="expand" for="c-36651382">[1 more]</label></div><br/><div class="children"><div class="content">It’s significantly worse than OpenAIs offerings, and I’m tired of people pretending as though these models are totally interchangeable yet. They are not.</div><br/></div></div><div id="36649306" class="c"><input type="checkbox" id="c-36649306" checked=""/><div class="controls bullet"><span class="by">unshavedyak</span><span>|</span><a href="#36649110">parent</a><span>|</span><a href="#36651382">prev</a><span>|</span><a href="#36649229">next</a><span>|</span><label class="collapse" for="c-36649306">[-]</label><label class="expand" for="c-36649306">[2 more]</label></div><br/><div class="children"><div class="content">Is this robust enough to feed all your emails and chat logs into it and have convos with it? Will it be able to extract context to figure out questions to recent logs, etc?</div><br/><div id="36649813" class="c"><input type="checkbox" id="c-36649813" checked=""/><div class="controls bullet"><span class="by">qingcharles</span><span>|</span><a href="#36649110">root</a><span>|</span><a href="#36649306">parent</a><span>|</span><a href="#36649229">next</a><span>|</span><label class="collapse" for="c-36649813">[-]</label><label class="expand" for="c-36649813">[1 more]</label></div><br/><div class="children"><div class="content">In theory, yes.<p>I&#x27;ve not got it to work yet though, it ends up hallucinating answers to all the questions about documents I feed it.</div><br/></div></div></div></div><div id="36649229" class="c"><input type="checkbox" id="c-36649229" checked=""/><div class="controls bullet"><span class="by">leach</span><span>|</span><a href="#36649110">parent</a><span>|</span><a href="#36649306">prev</a><span>|</span><a href="#36651499">next</a><span>|</span><label class="collapse" for="c-36649229">[-]</label><label class="expand" for="c-36649229">[3 more]</label></div><br/><div class="children"><div class="content">How does this run on an Intel Mac? I have a 6 core i9. Haven&#x27;t been able to get an M series yet so Im wondering if it would be more worth it to run it in a cloud computing environment with a GPU.</div><br/><div id="36649266" class="c"><input type="checkbox" id="c-36649266" checked=""/><div class="controls bullet"><span class="by">hi</span><span>|</span><a href="#36649110">root</a><span>|</span><a href="#36649229">parent</a><span>|</span><a href="#36651499">next</a><span>|</span><label class="collapse" for="c-36649266">[-]</label><label class="expand" for="c-36649266">[2 more]</label></div><br/><div class="children"><div class="content">&gt;Mac Running Intel
When running a Mac with Intel hardware (not M1), you may run into clang: error: the clang compiler does not support &#x27;-march=native&#x27; during pip install.<p>If so set your archflags during pip install. eg: ARCHFLAGS=&quot;-arch x86_64&quot; pip3 install -r requirements.txt<p><a href="https:&#x2F;&#x2F;github.com&#x2F;imartinez&#x2F;privateGPT#mac-running-intel">https:&#x2F;&#x2F;github.com&#x2F;imartinez&#x2F;privateGPT#mac-running-intel</a></div><br/><div id="36649524" class="c"><input type="checkbox" id="c-36649524" checked=""/><div class="controls bullet"><span class="by">leach</span><span>|</span><a href="#36649110">root</a><span>|</span><a href="#36649266">parent</a><span>|</span><a href="#36651499">next</a><span>|</span><label class="collapse" for="c-36649524">[-]</label><label class="expand" for="c-36649524">[1 more]</label></div><br/><div class="children"><div class="content">I’m curious about the response times though, i imagine they will be quite slow on an intel Mac</div><br/></div></div></div></div></div></div><div id="36651499" class="c"><input type="checkbox" id="c-36651499" checked=""/><div class="controls bullet"><span class="by">Templa</span><span>|</span><a href="#36649110">parent</a><span>|</span><a href="#36649229">prev</a><span>|</span><a href="#36649298">next</a><span>|</span><label class="collapse" for="c-36651499">[-]</label><label class="expand" for="c-36651499">[1 more]</label></div><br/><div class="children"><div class="content">Having something that could be used with confluence would be so nice. Having documentation written and just asking questions about it.</div><br/></div></div><div id="36649469" class="c"><input type="checkbox" id="c-36649469" checked=""/><div class="controls bullet"><span class="by">SecurityNoob</span><span>|</span><a href="#36649110">parent</a><span>|</span><a href="#36649298">prev</a><span>|</span><a href="#36649495">next</a><span>|</span><label class="collapse" for="c-36649469">[-]</label><label class="expand" for="c-36649469">[2 more]</label></div><br/><div class="children"><div class="content">100% private? Hmm. I think with the amount of paranoia that the folks in power have about local LLM’s, I wouldn’t be in the slightest surprised that the Windows telemetry will be reporting back what people are doing with them. And anyone who thinks otherwise is in my view just absolutely naive beyond hope.</div><br/><div id="36650377" class="c"><input type="checkbox" id="c-36650377" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#36649110">root</a><span>|</span><a href="#36649469">parent</a><span>|</span><a href="#36649495">next</a><span>|</span><label class="collapse" for="c-36650377">[-]</label><label class="expand" for="c-36650377">[1 more]</label></div><br/><div class="children"><div class="content">Don&#x27;t have so much pride in yourself. Nobody actually cares what you&#x27;re doing. Well, China might.<p>And this is probably illegal in several countries besides that since queries might have medical information or other protected data.</div><br/></div></div></div></div></div></div><div id="36649495" class="c"><input type="checkbox" id="c-36649495" checked=""/><div class="controls bullet"><span class="by">eminent101</span><span>|</span><a href="#36649110">prev</a><span>|</span><a href="#36651042">next</a><span>|</span><label class="collapse" for="c-36649495">[-]</label><label class="expand" for="c-36649495">[4 more]</label></div><br/><div class="children"><div class="content">Is it going to send my personal data to OpenAI? Isn&#x27;t that a serious problem? Does not sound like a wise thing to do, not at least without redacting all sensitive personal data from the data. Am I missing something?</div><br/><div id="36650296" class="c"><input type="checkbox" id="c-36650296" checked=""/><div class="controls bullet"><span class="by">tedsanders</span><span>|</span><a href="#36649495">parent</a><span>|</span><a href="#36650124">next</a><span>|</span><label class="collapse" for="c-36650296">[-]</label><label class="expand" for="c-36650296">[2 more]</label></div><br/><div class="children"><div class="content">By default, data sent to the OpenAI API is never used for training and is deleted after a maximum of 30 days (mostly).<p>Data usage policies: <a href="https:&#x2F;&#x2F;openai.com&#x2F;policies&#x2F;api-data-usage-policies" rel="nofollow noreferrer">https:&#x2F;&#x2F;openai.com&#x2F;policies&#x2F;api-data-usage-policies</a><p>Data usage policies by model: <a href="https:&#x2F;&#x2F;platform.openai.com&#x2F;docs&#x2F;models&#x2F;how-we-use-your-data" rel="nofollow noreferrer">https:&#x2F;&#x2F;platform.openai.com&#x2F;docs&#x2F;models&#x2F;how-we-use-your-data</a></div><br/><div id="36650644" class="c"><input type="checkbox" id="c-36650644" checked=""/><div class="controls bullet"><span class="by">nomilk</span><span>|</span><a href="#36649495">root</a><span>|</span><a href="#36650296">parent</a><span>|</span><a href="#36650124">next</a><span>|</span><label class="collapse" for="c-36650644">[-]</label><label class="expand" for="c-36650644">[1 more]</label></div><br/><div class="children"><div class="content">A few weeks ago GitHub made a <i>strong</i> statement about code in repos not being viewed by humans, that was very liberating.<p>If OpenAI could offer similar privacy statements it would immediately be much more useful. E.g. if they simply add a &#x27;private&#x27; option, I&#x27;d pay double or triple for it.<p>OpenAI&#x27;s tools are incredibly good and so easy to use, it&#x27;s just that I simply cannot use them for most the things I want to do with them because of the privacy considerations, and that sucks.<p>I suspect OpenAI value the insights they get from looking at the data more than they do the extra revenue they&#x27;d receive if they could ensure privacy.</div><br/></div></div></div></div><div id="36650124" class="c"><input type="checkbox" id="c-36650124" checked=""/><div class="controls bullet"><span class="by">baby_souffle</span><span>|</span><a href="#36649495">parent</a><span>|</span><a href="#36650296">prev</a><span>|</span><a href="#36651042">next</a><span>|</span><label class="collapse" for="c-36650124">[-]</label><label class="expand" for="c-36650124">[1 more]</label></div><br/><div class="children"><div class="content">This is my question as well. Is there a more nuanced way to tell how personal data is used other than confirming that an OpenAI key is or is not needed?</div><br/></div></div></div></div><div id="36651042" class="c"><input type="checkbox" id="c-36651042" checked=""/><div class="controls bullet"><span class="by">Imnimo</span><span>|</span><a href="#36649495">prev</a><span>|</span><a href="#36649058">next</a><span>|</span><label class="collapse" for="c-36651042">[-]</label><label class="expand" for="c-36651042">[1 more]</label></div><br/><div class="children"><div class="content">This readme is very confusing. It says we&#x27;re going to use the GPT-2 tokenizer, and use GPT-2 as an embedding model. But looking at the code, it seems to use the default LangChain OpenAIEmbeddings and OpenAI LLM. Aren&#x27;t those text-embedding-ada-002 and text-davinci-003, respectively?<p>I don&#x27;t understand how GPT-2 enters into this at all.</div><br/></div></div><div id="36649058" class="c"><input type="checkbox" id="c-36649058" checked=""/><div class="controls bullet"><span class="by">AJRF</span><span>|</span><a href="#36651042">prev</a><span>|</span><a href="#36649505">next</a><span>|</span><label class="collapse" for="c-36649058">[-]</label><label class="expand" for="c-36649058">[6 more]</label></div><br/><div class="children"><div class="content">Is there a company that makes a hosted version of something like this? I quite want a little AI that I can feed all my data to to ask questions to.</div><br/><div id="36649146" class="c"><input type="checkbox" id="c-36649146" checked=""/><div class="controls bullet"><span class="by">luccasiau</span><span>|</span><a href="#36649058">parent</a><span>|</span><a href="#36650706">next</a><span>|</span><label class="collapse" for="c-36649146">[-]</label><label class="expand" for="c-36649146">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;libraria.dev&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;libraria.dev&#x2F;</a> offers this and more as a service. It has added conveniences like integration with your google drive, youtube videos, and such</div><br/></div></div><div id="36650706" class="c"><input type="checkbox" id="c-36650706" checked=""/><div class="controls bullet"><span class="by">sdan</span><span>|</span><a href="#36649058">parent</a><span>|</span><a href="#36649146">prev</a><span>|</span><a href="#36651408">next</a><span>|</span><label class="collapse" for="c-36650706">[-]</label><label class="expand" for="c-36650706">[1 more]</label></div><br/><div class="children"><div class="content">If you subscribe to ChatGPT plus, you can use ChatWithPDF (<a href="https:&#x2F;&#x2F;plugins.sdan.io" rel="nofollow noreferrer">https:&#x2F;&#x2F;plugins.sdan.io</a>) which has 50k+ daily active users!</div><br/></div></div><div id="36651408" class="c"><input type="checkbox" id="c-36651408" checked=""/><div class="controls bullet"><span class="by">_pdp_</span><span>|</span><a href="#36649058">parent</a><span>|</span><a href="#36650706">prev</a><span>|</span><a href="#36649797">next</a><span>|</span><label class="collapse" for="c-36651408">[-]</label><label class="expand" for="c-36651408">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;chatbotkit.com" rel="nofollow noreferrer">https:&#x2F;&#x2F;chatbotkit.com</a></div><br/></div></div><div id="36649797" class="c"><input type="checkbox" id="c-36649797" checked=""/><div class="controls bullet"><span class="by">tikkun</span><span>|</span><a href="#36649058">parent</a><span>|</span><a href="#36651408">prev</a><span>|</span><a href="#36649180">next</a><span>|</span><label class="collapse" for="c-36649797">[-]</label><label class="expand" for="c-36649797">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36649777">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36649777</a></div><br/></div></div><div id="36649180" class="c"><input type="checkbox" id="c-36649180" checked=""/><div class="controls bullet"><span class="by">egonschiele</span><span>|</span><a href="#36649058">parent</a><span>|</span><a href="#36649797">prev</a><span>|</span><a href="#36649505">next</a><span>|</span><label class="collapse" for="c-36649180">[-]</label><label class="expand" for="c-36649180">[1 more]</label></div><br/><div class="children"><div class="content">Depending on the size of your data, chiseleditor.com is a free option.</div><br/></div></div></div></div><div id="36649505" class="c"><input type="checkbox" id="c-36649505" checked=""/><div class="controls bullet"><span class="by">cloudking</span><span>|</span><a href="#36649058">prev</a><span>|</span><a href="#36649153">next</a><span>|</span><label class="collapse" for="c-36649505">[-]</label><label class="expand" for="c-36649505">[5 more]</label></div><br/><div class="children"><div class="content">Am I the only one who doesn&#x27;t need to search across my data? What are the use cases here</div><br/><div id="36650237" class="c"><input type="checkbox" id="c-36650237" checked=""/><div class="controls bullet"><span class="by">dkh</span><span>|</span><a href="#36649505">parent</a><span>|</span><a href="#36650050">next</a><span>|</span><label class="collapse" for="c-36650237">[-]</label><label class="expand" for="c-36650237">[1 more]</label></div><br/><div class="children"><div class="content">Sometimes I have the data, but I&#x27;m not sure where it is.<p>Sometimes I know where the data is, but there&#x27;s a lot of it and all I&#x27;m looking for is a quick explanation of something.<p>Sometimes I have a lot of data from a lot of sources, but what I want in the end is a summary based on what most&#x2F;all of them agree on, or possibly a summary of how they differ.<p>There&#x27;s a lot of use-cases here, many of which I think people don&#x27;t get a &quot;lightbulb moment&quot; about their usefulness until they&#x27;ve dug in and seen what is possible, because we are so used to how we approach these tasks normally.<p>But the range of uses is quite broad. A project I&#x27;m working on for myself is a variation of this, where I&#x27;ve ingested years and years of my own notes and journals, and make queries for the purposes of my own introspection and personal growth. (I think there&#x27;s a lot of of potential in this arena in general)</div><br/></div></div><div id="36650050" class="c"><input type="checkbox" id="c-36650050" checked=""/><div class="controls bullet"><span class="by">BeetleB</span><span>|</span><a href="#36649505">parent</a><span>|</span><a href="#36650237">prev</a><span>|</span><a href="#36649153">next</a><span>|</span><label class="collapse" for="c-36650050">[-]</label><label class="expand" for="c-36650050">[3 more]</label></div><br/><div class="children"><div class="content">Example use case:<p>We have a group at work that meets and discusses various investment topics. The guy organizing it is fairly well connected and every week he tries to get an external speaker to come and present. Very educational.<p>I have raw notes for each of these presentations. My goal has always been to go through those notes, and properly organize the knowledge in there into a wiki of sorts. It&#x27;s been 3 years since this all started and I still haven&#x27;t found the time to do it. If I want to be realistic, I should accept that it&#x27;ll never happen.<p>How do I go about finding information that I have in those notes? I could use text search but it&#x27;s too sensitive to my search string - I&#x27;ll often fail to find what I need. Also, the information may be scattered across several files, and I&#x27;d have to open all the hits and scan to find what I need.<p>With technology like this, I can put all my notes into some vector DB, and then use AI to ask in plain English what I need. Locally the system interprets my query and finds the most relevant documents in the DB. It then sends my query and those hits to OpenAI to interpret my question, and find the answer amongst my notes. A while ago I used Langchain to set it up and I got it working as a proof of concept. An Aha moment was when I asked it something and it gave me a response with information that was scattered over two different presentations. My challenge is that there are so many parameters I could play with, and I haven&#x27;t yet thought of a way&#x2F;metric to assess the performance of my system (any pointers would be appreciated!)<p>There&#x27;s nothing personal in these notes, so no privacy concerns. I did want to set a similar thing up with over 20 years of emails, but didn&#x27;t due to privacy. Also, I use a mail indexer (notmuch) which is fairly good so the need to use AI is not as strong.<p>But for other (non-personal) notes? If I can get this system working fairly well, it&#x27;d be a life saver. I&#x27;ve made so many notes on so many topics over the years, and it&#x27;s worth real money not to have to organize it well. Just let me write my notes, and use an AI to retrieve what I need.</div><br/><div id="36651391" class="c"><input type="checkbox" id="c-36651391" checked=""/><div class="controls bullet"><span class="by">theonlybutlet</span><span>|</span><a href="#36649505">root</a><span>|</span><a href="#36650050">parent</a><span>|</span><a href="#36649153">next</a><span>|</span><label class="collapse" for="c-36651391">[-]</label><label class="expand" for="c-36651391">[2 more]</label></div><br/><div class="children"><div class="content">You&#x27;re creating additional hardship for yourself. Why create a pdf only to convert it out of pdf again. Just insert all your notes into the LLM model.</div><br/><div id="36652674" class="c"><input type="checkbox" id="c-36652674" checked=""/><div class="controls bullet"><span class="by">muspimerol</span><span>|</span><a href="#36649505">root</a><span>|</span><a href="#36651391">parent</a><span>|</span><a href="#36649153">next</a><span>|</span><label class="collapse" for="c-36652674">[-]</label><label class="expand" for="c-36652674">[1 more]</label></div><br/><div class="children"><div class="content">Because that requires retraining the model every time you take new notes. And this way you also still have the raw notes as similarity matches from the vector db, rather than them &quot;disappearing&quot; into the LLM model.</div><br/></div></div></div></div></div></div></div></div><div id="36649153" class="c"><input type="checkbox" id="c-36649153" checked=""/><div class="controls bullet"><span class="by">JimmyRuska</span><span>|</span><a href="#36649505">prev</a><span>|</span><a href="#36649286">next</a><span>|</span><label class="collapse" for="c-36649153">[-]</label><label class="expand" for="c-36649153">[4 more]</label></div><br/><div class="children"><div class="content">Anyone know how milvus, quickwit, pinecone compares?<p>I&#x27;ve been thinking about seeing if there&#x27;s consulting opportunities for local businesses for LLMs, finetuning&#x2F;vector search, chat bots. Also making tools to make it easier to drag and drop files and get personalized inference. Recently I saw this one pop into my linkedin feed, <a href="https:&#x2F;&#x2F;gpt-trainer.com&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;gpt-trainer.com&#x2F;</a> . There&#x27;s been a few others for documents I&#x27;ve found<p><a href="https:&#x2F;&#x2F;www.explainpaper.com&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.explainpaper.com&#x2F;</a><p><a href="https:&#x2F;&#x2F;www.konjer.xyz&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.konjer.xyz&#x2F;</a><p>Nope nope, wouldn&#x27;t want to compete with that on pricing. Local open source LLMs on a 3090 would also be a cool service, but wouldn&#x27;t have any scalability.<p>Are there any other finetuning or vector search context startups you&#x27;ve seen?</div><br/><div id="36649777" class="c"><input type="checkbox" id="c-36649777" checked=""/><div class="controls bullet"><span class="by">tikkun</span><span>|</span><a href="#36649153">parent</a><span>|</span><a href="#36650709">next</a><span>|</span><label class="collapse" for="c-36649777">[-]</label><label class="expand" for="c-36649777">[1 more]</label></div><br/><div class="children"><div class="content">Pinecone and Milvus would be alternatives for their use of FAISS for the vector store and search component. I think more of the embeddings difference would be noticed by what’s used for creating the embeddings (eg the ones here <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36649579">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36649579</a> instead of the OpenAI embeddings API they used), rather than noticing differences from the embedding store&#x2F;search alternatives which I can’t think of what the difference would be other than maybe performance at a large scale and cost and personal preference &#x2F; developer experience.<p>Hadn’t heard of Quickwit but from a quick glance at their site it doesn’t look like a vector store, seems perhaps unrelated.<p>For tools for making custom ChatGPTs see my list: <a href="https:&#x2F;&#x2F;llm-utils.org&#x2F;List+of+tools+for+making+a+%22ChatGPT+for+your+data%22" rel="nofollow noreferrer">https:&#x2F;&#x2F;llm-utils.org&#x2F;List+of+tools+for+making+a+%22ChatGPT+...</a><p>Fine tuning as a service there’s Lamini AI, aimed at enterprises.<p>Other embeddings startups there’s Weaviate.</div><br/></div></div><div id="36650709" class="c"><input type="checkbox" id="c-36650709" checked=""/><div class="controls bullet"><span class="by">sdan</span><span>|</span><a href="#36649153">parent</a><span>|</span><a href="#36649777">prev</a><span>|</span><a href="#36650109">next</a><span>|</span><label class="collapse" for="c-36650709">[-]</label><label class="expand" for="c-36650709">[1 more]</label></div><br/><div class="children"><div class="content">I am working on a simple vector db just with numpy: <a href="https:&#x2F;&#x2F;github.com&#x2F;sdan&#x2F;vlite">https:&#x2F;&#x2F;github.com&#x2F;sdan&#x2F;vlite</a><p>I think milvus, quickwit, and pinecone are geared more towards enterprise and are hard to use.</div><br/></div></div><div id="36650109" class="c"><input type="checkbox" id="c-36650109" checked=""/><div class="controls bullet"><span class="by">eddieweng</span><span>|</span><a href="#36649153">parent</a><span>|</span><a href="#36650709">prev</a><span>|</span><a href="#36649286">next</a><span>|</span><label class="collapse" for="c-36650109">[-]</label><label class="expand" for="c-36650109">[1 more]</label></div><br/><div class="children"><div class="content">qdrant is better in my opinion</div><br/></div></div></div></div><div id="36649286" class="c"><input type="checkbox" id="c-36649286" checked=""/><div class="controls bullet"><span class="by">zikohh</span><span>|</span><a href="#36649153">prev</a><span>|</span><a href="#36649147">next</a><span>|</span><label class="collapse" for="c-36649286">[-]</label><label class="expand" for="c-36649286">[1 more]</label></div><br/><div class="children"><div class="content">Also what does this do that llamaindex doesn&#x27;t?</div><br/></div></div><div id="36649147" class="c"><input type="checkbox" id="c-36649147" checked=""/><div class="controls bullet"><span class="by">syntaxing</span><span>|</span><a href="#36649286">prev</a><span>|</span><a href="#36649251">next</a><span>|</span><label class="collapse" for="c-36649147">[-]</label><label class="expand" for="c-36649147">[2 more]</label></div><br/><div class="children"><div class="content">gpt4all has this truly locally. I recommend those with a decent GPU to give it a go.</div><br/><div id="36649294" class="c"><input type="checkbox" id="c-36649294" checked=""/><div class="controls bullet"><span class="by">fbdab103</span><span>|</span><a href="#36649147">parent</a><span>|</span><a href="#36649251">next</a><span>|</span><label class="collapse" for="c-36649294">[-]</label><label class="expand" for="c-36649294">[1 more]</label></div><br/><div class="children"><div class="content">I assume this is the link: <a href="https:&#x2F;&#x2F;github.com&#x2F;nomic-ai&#x2F;gpt4all">https:&#x2F;&#x2F;github.com&#x2F;nomic-ai&#x2F;gpt4all</a> ?</div><br/></div></div></div></div><div id="36649251" class="c"><input type="checkbox" id="c-36649251" checked=""/><div class="controls bullet"><span class="by">csjh</span><span>|</span><a href="#36649147">prev</a><span>|</span><a href="#36649119">next</a><span>|</span><label class="collapse" for="c-36649251">[-]</label><label class="expand" for="c-36649251">[3 more]</label></div><br/><div class="children"><div class="content">Why have the OpenAI dependency when there&#x27;s local embeddings models that would be both faster and more accurate?</div><br/><div id="36649501" class="c"><input type="checkbox" id="c-36649501" checked=""/><div class="controls bullet"><span class="by">yawnxyz</span><span>|</span><a href="#36649251">parent</a><span>|</span><a href="#36649119">next</a><span>|</span><label class="collapse" for="c-36649501">[-]</label><label class="expand" for="c-36649501">[2 more]</label></div><br/><div class="children"><div class="content">Which ones?</div><br/><div id="36649579" class="c"><input type="checkbox" id="c-36649579" checked=""/><div class="controls bullet"><span class="by">minimaxir</span><span>|</span><a href="#36649251">root</a><span>|</span><a href="#36649501">parent</a><span>|</span><a href="#36649119">next</a><span>|</span><label class="collapse" for="c-36649579">[-]</label><label class="expand" for="c-36649579">[1 more]</label></div><br/><div class="children"><div class="content">all-MiniLM-L6-v2 from SentenceTransformers is the most popular one as it balances speed and quality well: <a href="https:&#x2F;&#x2F;www.sbert.net&#x2F;docs&#x2F;pretrained_models.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.sbert.net&#x2F;docs&#x2F;pretrained_models.html</a></div><br/></div></div></div></div></div></div><div id="36649119" class="c"><input type="checkbox" id="c-36649119" checked=""/><div class="controls bullet"><span class="by">quickthrower2</span><span>|</span><a href="#36649251">prev</a><span>|</span><a href="#36649430">next</a><span>|</span><label class="collapse" for="c-36649119">[-]</label><label class="expand" for="c-36649119">[1 more]</label></div><br/><div class="children"><div class="content">The author has a demo of this here: <a href="https:&#x2F;&#x2F;www.swamisivananda.ai&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.swamisivananda.ai&#x2F;</a></div><br/></div></div><div id="36649430" class="c"><input type="checkbox" id="c-36649430" checked=""/><div class="controls bullet"><span class="by">gigel82</span><span>|</span><a href="#36649119">prev</a><span>|</span><a href="#36649331">next</a><span>|</span><label class="collapse" for="c-36649430">[-]</label><label class="expand" for="c-36649430">[3 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t get it, GPT-2 is (one of the few) open models from OpenAI, you can just run it locally, why would you use their API for this?
<a href="https:&#x2F;&#x2F;github.com&#x2F;openai&#x2F;gpt-2">https:&#x2F;&#x2F;github.com&#x2F;openai&#x2F;gpt-2</a></div><br/><div id="36651613" class="c"><input type="checkbox" id="c-36651613" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#36649430">parent</a><span>|</span><a href="#36650562">next</a><span>|</span><label class="collapse" for="c-36651613">[-]</label><label class="expand" for="c-36651613">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not using GPT-2 - the README is incorrect.<p>It&#x27;s using &quot;from langchain.embeddings import OpenAIEmbeddings&quot; - which is the OpenAI embeddings API, text-embedding-ada-002<p>The only aspect of GPT-2 this is using is GPT2TokenizerFast.from_pretrained(&quot;gpt2&quot;) - which it uses as the length function to count tokens for the RecursiveCharacterTextSplitter() langchain utility.<p>Which doesn&#x27;t really make sense - why use the GPT-2 tokenizer for that? May as well just count characters or even count words based on .split(), it&#x27;s not particularly important how the counting works here.</div><br/></div></div><div id="36650562" class="c"><input type="checkbox" id="c-36650562" checked=""/><div class="controls bullet"><span class="by">sumedh</span><span>|</span><a href="#36649430">parent</a><span>|</span><a href="#36651613">prev</a><span>|</span><a href="#36649331">next</a><span>|</span><label class="collapse" for="c-36650562">[-]</label><label class="expand" for="c-36650562">[1 more]</label></div><br/><div class="children"><div class="content">I am assuming GPT 4 will provide better answers to your queries compared to GPT 2.</div><br/></div></div></div></div><div id="36649331" class="c"><input type="checkbox" id="c-36649331" checked=""/><div class="controls bullet"><span class="by">einpoklum</span><span>|</span><a href="#36649430">prev</a><span>|</span><label class="collapse" for="c-36649331">[-]</label><label class="expand" for="c-36649331">[7 more]</label></div><br/><div class="children"><div class="content">Don&#x27;t build a personal ChatGPT, and don&#x27;t let OpenAI, Microsoft and their business partners (and probably the US government) have a bunch of your personal and private information.</div><br/><div id="36650312" class="c"><input type="checkbox" id="c-36650312" checked=""/><div class="controls bullet"><span class="by">tedsanders</span><span>|</span><a href="#36649331">parent</a><span>|</span><a href="#36649554">next</a><span>|</span><label class="collapse" for="c-36650312">[-]</label><label class="expand" for="c-36650312">[3 more]</label></div><br/><div class="children"><div class="content">By default, data sent to the OpenAI API is never used for training and is deleted after a maximum of 30 days (mostly).<p>Data usage policies: <a href="https:&#x2F;&#x2F;openai.com&#x2F;policies&#x2F;api-data-usage-policies" rel="nofollow noreferrer">https:&#x2F;&#x2F;openai.com&#x2F;policies&#x2F;api-data-usage-policies</a><p>Data usage policies by model: <a href="https:&#x2F;&#x2F;platform.openai.com&#x2F;docs&#x2F;models&#x2F;how-we-use-your-data" rel="nofollow noreferrer">https:&#x2F;&#x2F;platform.openai.com&#x2F;docs&#x2F;models&#x2F;how-we-use-your-data</a></div><br/><div id="36650870" class="c"><input type="checkbox" id="c-36650870" checked=""/><div class="controls bullet"><span class="by">two_handfuls</span><span>|</span><a href="#36649331">root</a><span>|</span><a href="#36650312">parent</a><span>|</span><a href="#36652229">next</a><span>|</span><label class="collapse" for="c-36650870">[-]</label><label class="expand" for="c-36650870">[1 more]</label></div><br/><div class="children"><div class="content">So, they don’t promise they won’t look at it - just that they won’t use it for training.</div><br/></div></div><div id="36652229" class="c"><input type="checkbox" id="c-36652229" checked=""/><div class="controls bullet"><span class="by">einpoklum</span><span>|</span><a href="#36649331">root</a><span>|</span><a href="#36650312">parent</a><span>|</span><a href="#36650870">prev</a><span>|</span><a href="#36649554">next</a><span>|</span><label class="collapse" for="c-36652229">[-]</label><label class="expand" for="c-36652229">[1 more]</label></div><br/><div class="children"><div class="content">You many want to read about National Security Letters:<p><a href="https:&#x2F;&#x2F;www.eff.org&#x2F;issues&#x2F;national-security-letters&#x2F;faq" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.eff.org&#x2F;issues&#x2F;national-security-letters&#x2F;faq</a></div><br/></div></div></div></div><div id="36649554" class="c"><input type="checkbox" id="c-36649554" checked=""/><div class="controls bullet"><span class="by">WhackyIdeas</span><span>|</span><a href="#36649331">parent</a><span>|</span><a href="#36650312">prev</a><span>|</span><label class="collapse" for="c-36649554">[-]</label><label class="expand" for="c-36649554">[3 more]</label></div><br/><div class="children"><div class="content">So avoid all Microsoft products too?</div><br/><div id="36649964" class="c"><input type="checkbox" id="c-36649964" checked=""/><div class="controls bullet"><span class="by">cj</span><span>|</span><a href="#36649331">root</a><span>|</span><a href="#36649554">parent</a><span>|</span><a href="#36649794">next</a><span>|</span><label class="collapse" for="c-36649964">[-]</label><label class="expand" for="c-36649964">[1 more]</label></div><br/><div class="children"><div class="content">Does Microsoft have an AI opt out?<p>AWS has an AI opt out at the organizational level that prevents them from using your data to “improve” their other services.<p>(I personally recommend everyone opt out now in AWS if you haven’t already…)<p><a href="https:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;organizations&#x2F;latest&#x2F;userguide&#x2F;orgs_manage_policies_ai-opt-out.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;organizations&#x2F;latest&#x2F;userguide&#x2F;o...</a></div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>