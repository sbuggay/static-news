<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1692867663432" as="style"/><link rel="stylesheet" href="styles.css?v=1692867663432"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://nvidianews.nvidia.com/news/nvidia-announces-financial-results-for-second-quarter-fiscal-2024">Nvidia announces financial results for second quarter fiscal 2024</a> <span class="domain">(<a href="https://nvidianews.nvidia.com">nvidianews.nvidia.com</a>)</span></div><div class="subtext"><span>electriclove</span> | <span>360 comments</span></div><br/><div><div id="37244542" class="c"><input type="checkbox" id="c-37244542" checked=""/><div class="controls bullet"><span class="by">srj</span><span>|</span><a href="#37242626">next</a><span>|</span><label class="collapse" for="c-37244542">[-]</label><label class="expand" for="c-37244542">[24 more]</label></div><br/><div class="children"><div class="content">I interned at NVIDIA in 2009 on the kernel mode driver team. Was super fun there in terms of the project work and the people. If the code still exists, I created the main class that schedules work out to the GPU on Windows.<p>That level of programming gave such rewarding moments in between difficult debugging sessions. When I wanted to test a new kernel driver build I needed to walk into some massive room with all of these interconnected machines that emulated the non-yet-fabricated GPU hardware. One of the full time people on my team was going insane trying to track down a memory corruption issue between GPU memory and main memory when things paged out the entire time I was there.<p>Back then the stock was around $7&#x2F;share and the CEO announced a 10% paycut across the board (even including my intern salary) and had an all hands with everyone in the cafeteria. It&#x27;s pretty cool they went from that vulnerable state, with Intel threatening to build in GPU capabilities, to the powerhouse they are today.</div><br/><div id="37245971" class="c"><input type="checkbox" id="c-37245971" checked=""/><div class="controls bullet"><span class="by">alanfranz</span><span>|</span><a href="#37244542">parent</a><span>|</span><a href="#37245258">next</a><span>|</span><label class="collapse" for="c-37245971">[-]</label><label class="expand" for="c-37245971">[1 more]</label></div><br/><div class="children"><div class="content">&gt;  the CEO announced a 10% paycut across the board<p>Which is still better than a 10% layoff, anyway!</div><br/></div></div><div id="37245258" class="c"><input type="checkbox" id="c-37245258" checked=""/><div class="controls bullet"><span class="by">granshaw</span><span>|</span><a href="#37244542">parent</a><span>|</span><a href="#37245971">prev</a><span>|</span><a href="#37244757">next</a><span>|</span><label class="collapse" for="c-37245258">[-]</label><label class="expand" for="c-37245258">[1 more]</label></div><br/><div class="children"><div class="content">Interned there Summer of 08. Remember mentions of “this CUDA thing” then, that was during its infancy.<p>Midway through, our intern friend group found out one of the smaller buildings had a buffet lunch and started taking the shuttle there often.<p>Saw this tweet just now and that lanyard holder really brought back memories, hasn’t changed at all: <a href="https:&#x2F;&#x2F;x.com&#x2F;jimcramer&#x2F;status&#x2F;1694465908234699243?s=46&amp;t=NA4OwNM8Z_Eu-eHB4CKIjg" rel="nofollow noreferrer">https:&#x2F;&#x2F;x.com&#x2F;jimcramer&#x2F;status&#x2F;1694465908234699243?s=46&amp;t=NA...</a></div><br/></div></div><div id="37244757" class="c"><input type="checkbox" id="c-37244757" checked=""/><div class="controls bullet"><span class="by">1-6</span><span>|</span><a href="#37244542">parent</a><span>|</span><a href="#37245258">prev</a><span>|</span><a href="#37244639">next</a><span>|</span><label class="collapse" for="c-37244757">[-]</label><label class="expand" for="c-37244757">[4 more]</label></div><br/><div class="children"><div class="content">Do you still own stock?</div><br/><div id="37244778" class="c"><input type="checkbox" id="c-37244778" checked=""/><div class="controls bullet"><span class="by">the_svd_doctor</span><span>|</span><a href="#37244542">root</a><span>|</span><a href="#37244757">parent</a><span>|</span><a href="#37244639">next</a><span>|</span><label class="collapse" for="c-37244778">[-]</label><label class="expand" for="c-37244778">[3 more]</label></div><br/><div class="children"><div class="content">He probably didn’t get any as an intern.</div><br/><div id="37244985" class="c"><input type="checkbox" id="c-37244985" checked=""/><div class="controls bullet"><span class="by">enos_feedler</span><span>|</span><a href="#37244542">root</a><span>|</span><a href="#37244778">parent</a><span>|</span><a href="#37244968">next</a><span>|</span><label class="collapse" for="c-37244985">[-]</label><label class="expand" for="c-37244985">[1 more]</label></div><br/><div class="children"><div class="content">I joined as a new college grad (full time) the same year. I remember the 10% pay cut announcement. I didn&#x27;t get any stock granted to me in the 4 years I was there as a SWE working on CUDA. They had an ESPP you could put 10% of your paycheck into or something like that though.</div><br/></div></div><div id="37244968" class="c"><input type="checkbox" id="c-37244968" checked=""/><div class="controls bullet"><span class="by">srj</span><span>|</span><a href="#37244542">root</a><span>|</span><a href="#37244778">parent</a><span>|</span><a href="#37244985">prev</a><span>|</span><a href="#37244639">next</a><span>|</span><label class="collapse" for="c-37244968">[-]</label><label class="expand" for="c-37244968">[1 more]</label></div><br/><div class="children"><div class="content">I vaguely remember that I could participate in the employee purchase program. This was during the financial crisis though and I was an undergrad intern with a paltry ability to invest.<p>Even if I had hit received some great stock award in all likelihood I would have sold it for index funds at my first opportunity. I imagine some of my old coworkers made out quite well though.</div><br/></div></div></div></div></div></div><div id="37244639" class="c"><input type="checkbox" id="c-37244639" checked=""/><div class="controls bullet"><span class="by">radium3d</span><span>|</span><a href="#37244542">parent</a><span>|</span><a href="#37244757">prev</a><span>|</span><a href="#37242626">next</a><span>|</span><label class="collapse" for="c-37244639">[-]</label><label class="expand" for="c-37244639">[17 more]</label></div><br/><div class="children"><div class="content">I do wonder though, why has moore&#x27;s law stopped in its tracks? Using CS:GO benchmark, a 1070 got 218 FPS, while a 4090 is at 477 FPS. Only a ~2.2x increase in FPS in 6 years? :(</div><br/><div id="37244975" class="c"><input type="checkbox" id="c-37244975" checked=""/><div class="controls bullet"><span class="by">dahart</span><span>|</span><a href="#37244542">root</a><span>|</span><a href="#37244639">parent</a><span>|</span><a href="#37245113">next</a><span>|</span><label class="collapse" for="c-37244975">[-]</label><label class="expand" for="c-37244975">[3 more]</label></div><br/><div class="children"><div class="content">Between those 2 GPUs, the fp32 perf went up 12.7x according to TechPowerUp’s specs. The SM count went up 8.5x (which represents Moore’s law and note is almost exactly in line with Moore’s prediction), and the clock rate went up 1.5x. The FPS of CSGO (or any game) is not a good measure of Moore’s law. Games have all kinds of complexities and caveats that will prevent them from scaling linearly. I used to write some of those bottlenecks :P What are the 2080 and 3080 datapoints for CSGO? Did it approach 400-500 fps on the 2080 and never get any faster after that?</div><br/><div id="37245681" class="c"><input type="checkbox" id="c-37245681" checked=""/><div class="controls bullet"><span class="by">radium3d</span><span>|</span><a href="#37244542">root</a><span>|</span><a href="#37244975">parent</a><span>|</span><a href="#37245113">next</a><span>|</span><label class="collapse" for="c-37245681">[-]</label><label class="expand" for="c-37245681">[2 more]</label></div><br/><div class="children"><div class="content">Wow, didn&#x27;t expect to get so many comments. It&#x27;s just interesting to me that we have 500hz monitors, yet games are still coming out that only run at ~70 fps on a 3080, etc. I used CS:GO as a comparison just because it was an example capable of coming near 500 FPS. Avg FPS are not going up fast enough in my opinion. I understand some games purposefully limit FPS for physics calculations, but there are many that do not.</div><br/><div id="37246384" class="c"><input type="checkbox" id="c-37246384" checked=""/><div class="controls bullet"><span class="by">Cloudef</span><span>|</span><a href="#37244542">root</a><span>|</span><a href="#37245681">parent</a><span>|</span><a href="#37245113">next</a><span>|</span><label class="collapse" for="c-37246384">[-]</label><label class="expand" for="c-37246384">[1 more]</label></div><br/><div class="children"><div class="content">Also note that FPS is non-linear value, you want to compare frame times instead.</div><br/></div></div></div></div></div></div><div id="37245113" class="c"><input type="checkbox" id="c-37245113" checked=""/><div class="controls bullet"><span class="by">AnotherGoodName</span><span>|</span><a href="#37244542">root</a><span>|</span><a href="#37244639">parent</a><span>|</span><a href="#37244975">prev</a><span>|</span><a href="#37244845">next</a><span>|</span><label class="collapse" for="c-37245113">[-]</label><label class="expand" for="c-37245113">[3 more]</label></div><br/><div class="children"><div class="content">That&#x27;s because single thread perf of CPUs hasn&#x27;t progressed and ~500fps is where CPUs cap out on that game still to this day. GPUs are doing fine.</div><br/><div id="37245294" class="c"><input type="checkbox" id="c-37245294" checked=""/><div class="controls bullet"><span class="by">teaearlgraycold</span><span>|</span><a href="#37244542">root</a><span>|</span><a href="#37245113">parent</a><span>|</span><a href="#37244845">next</a><span>|</span><label class="collapse" for="c-37245294">[-]</label><label class="expand" for="c-37245294">[2 more]</label></div><br/><div class="children"><div class="content">For anyone that doesn&#x27;t understand why this matters, the CPU still needs to prepare the full scene before sending it over to the GPU for polygons to get rasterized and shaders to get calculated. Most of the time the CPU does all of the physics as well. So even if GPU render time goes to 0ms, 2ms spent by the CPU per frame means 500fps is the best you&#x27;ll get without a better CPU or better code. And I suspect game devs aren&#x27;t looking to shrink their budgeted CPU time just so someone benchmarking can see 1000fps.</div><br/><div id="37246042" class="c"><input type="checkbox" id="c-37246042" checked=""/><div class="controls bullet"><span class="by">izacus</span><span>|</span><a href="#37244542">root</a><span>|</span><a href="#37245294">parent</a><span>|</span><a href="#37244845">next</a><span>|</span><label class="collapse" for="c-37246042">[-]</label><label class="expand" for="c-37246042">[1 more]</label></div><br/><div class="children"><div class="content">CS:GO also doesn&#x27;t use any of the new approaches that reduce CPU time in those operations and more effectively saturate the GPU. Compare CS:GO against Doom:Eternal, which runs at high fps while providing massive improvements to visuals.</div><br/></div></div></div></div></div></div><div id="37244845" class="c"><input type="checkbox" id="c-37244845" checked=""/><div class="controls bullet"><span class="by">HWR_14</span><span>|</span><a href="#37244542">root</a><span>|</span><a href="#37244639">parent</a><span>|</span><a href="#37245113">prev</a><span>|</span><a href="#37244758">next</a><span>|</span><label class="collapse" for="c-37244845">[-]</label><label class="expand" for="c-37244845">[1 more]</label></div><br/><div class="children"><div class="content">At low frame rates, the GPU is (usuallly) the bottleneck most of them time. At very high frame rates, there are other more significant bottlenecks.<p>A much better benchmark would be to take a game designed for 120 or fewer FPS on a 4090 and try it on a 1070.</div><br/></div></div><div id="37244758" class="c"><input type="checkbox" id="c-37244758" checked=""/><div class="controls bullet"><span class="by">ATMLOTTOBEER</span><span>|</span><a href="#37244542">root</a><span>|</span><a href="#37244639">parent</a><span>|</span><a href="#37244845">prev</a><span>|</span><a href="#37244684">next</a><span>|</span><label class="collapse" for="c-37244758">[-]</label><label class="expand" for="c-37244758">[3 more]</label></div><br/><div class="children"><div class="content">Fps in CSGO isn’t really so dependent on the GPU as more modern games, so comparing with a different game might be more accurate.</div><br/><div id="37245750" class="c"><input type="checkbox" id="c-37245750" checked=""/><div class="controls bullet"><span class="by">radium3d</span><span>|</span><a href="#37244542">root</a><span>|</span><a href="#37244758">parent</a><span>|</span><a href="#37244684">next</a><span>|</span><label class="collapse" for="c-37245750">[-]</label><label class="expand" for="c-37245750">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m curious, do you know of a study that has proven that single core CPU or other is the bottleneck in CS:GO?</div><br/><div id="37246145" class="c"><input type="checkbox" id="c-37246145" checked=""/><div class="controls bullet"><span class="by">AaronFriel</span><span>|</span><a href="#37244542">root</a><span>|</span><a href="#37245750">parent</a><span>|</span><a href="#37244684">next</a><span>|</span><label class="collapse" for="c-37246145">[-]</label><label class="expand" for="c-37246145">[1 more]</label></div><br/><div class="children"><div class="content">This is essentially folk wisdom - but I think you can trust the other people in this thread that it&#x27;s accurate. I doubt anyone has done a scientific study on this, but you could see this for yourself by setting your computer&#x27;s clock rate lower and re-running the benchmark.<p>I expect that if you have a 4090, you have an Intel or AMD CPU that exposes a core clock multiplier. You could run this benchmark with whatever value it&#x27;s at, then reduce the modifier by say, half. That should halve your CPU&#x27;s clock rate, and I&#x27;m guessing you&#x27;ll see the frame rate decline similarly. You can conclude that the game is &quot;CPU bound&quot;, then.<p>Even if your GPU was infinitely fast, you have to remember that game developers are not optimizing for the game event loop to run in sub-millisecond times. If the core loop in the game takes under 16ms to run on a common CPU, such as one in a console: that&#x27;s better than 60hz and the overwhelming majority of video game players will never see a benefit.<p>Some game developers, I see someone in another thread mentioned Doom Eternal, pride themselves on that optimization. With a fast enough CPU and GPU, you could probably reach 1000 FPS on Doom Eternal. A quick search suggests this might have been accomplished with a liquid cooled, this was done with a liquid nitrogen cooled PC with a 6.6GHz CPU: <a href="https:&#x2F;&#x2F;www.pcgamer.com&#x2F;heres-doom-eternal-running-at-1000-fps-on-a-liquid-nitrogen-cooled-pc&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.pcgamer.com&#x2F;heres-doom-eternal-running-at-1000-f...</a></div><br/></div></div></div></div></div></div><div id="37244684" class="c"><input type="checkbox" id="c-37244684" checked=""/><div class="controls bullet"><span class="by">bexsella</span><span>|</span><a href="#37244542">root</a><span>|</span><a href="#37244639">parent</a><span>|</span><a href="#37244758">prev</a><span>|</span><a href="#37244840">next</a><span>|</span><label class="collapse" for="c-37244684">[-]</label><label class="expand" for="c-37244684">[1 more]</label></div><br/><div class="children"><div class="content">FPS of one specific game isn&#x27;t a great indicator of GPU grunt.</div><br/></div></div><div id="37244840" class="c"><input type="checkbox" id="c-37244840" checked=""/><div class="controls bullet"><span class="by">fragmede</span><span>|</span><a href="#37244542">root</a><span>|</span><a href="#37244639">parent</a><span>|</span><a href="#37244684">prev</a><span>|</span><a href="#37244783">next</a><span>|</span><label class="collapse" for="c-37244840">[-]</label><label class="expand" for="c-37244840">[1 more]</label></div><br/><div class="children"><div class="content">GS:go aside, the 1070 is said to do 6.5 TFlops to the 4090&#x27;s 1,321 TFlops,
for a 203x improvement in 6 years. Not bad!</div><br/></div></div><div id="37244783" class="c"><input type="checkbox" id="c-37244783" checked=""/><div class="controls bullet"><span class="by">Mechanical9</span><span>|</span><a href="#37244542">root</a><span>|</span><a href="#37244639">parent</a><span>|</span><a href="#37244840">prev</a><span>|</span><a href="#37244704">next</a><span>|</span><label class="collapse" for="c-37244783">[-]</label><label class="expand" for="c-37244783">[1 more]</label></div><br/><div class="children"><div class="content">My guess is that we&#x27;ve reached a peak in the amount of new investment that can be made annually, based on tech nearing total proliferation throughout society. The tech can sort of only advance as fast as tech companies can grow, and they can&#x27;t grow exponentially after they account for some percentage of the global workforce.<p>My guess is that we&#x27;ll see improvements at closer to the current rate rather than at an increasing rate.</div><br/></div></div><div id="37244704" class="c"><input type="checkbox" id="c-37244704" checked=""/><div class="controls bullet"><span class="by">transcriptase</span><span>|</span><a href="#37244542">root</a><span>|</span><a href="#37244639">parent</a><span>|</span><a href="#37244783">prev</a><span>|</span><a href="#37245199">next</a><span>|</span><label class="collapse" for="c-37244704">[-]</label><label class="expand" for="c-37244704">[1 more]</label></div><br/><div class="children"><div class="content">Admittedly knowing nothing, I’m going to assume that a great deal of the advantages of the latest generation aren’t going to improve performance in a decade old game since the engine won’t touch them.<p>How does a 1070 fare versus a 4090 in Hogwarts Legacy or another modern game at 1440 or 4K?</div><br/></div></div><div id="37245199" class="c"><input type="checkbox" id="c-37245199" checked=""/><div class="controls bullet"><span class="by">newZWhoDis</span><span>|</span><a href="#37244542">root</a><span>|</span><a href="#37244639">parent</a><span>|</span><a href="#37244704">prev</a><span>|</span><a href="#37245118">next</a><span>|</span><label class="collapse" for="c-37245199">[-]</label><label class="expand" for="c-37245199">[1 more]</label></div><br/><div class="children"><div class="content">I’m more worried about how human development has seemingly stopped in its tracks, backtracking more like it</div><br/></div></div><div id="37245118" class="c"><input type="checkbox" id="c-37245118" checked=""/><div class="controls bullet"><span class="by">spoonjim</span><span>|</span><a href="#37244542">root</a><span>|</span><a href="#37244639">parent</a><span>|</span><a href="#37245199">prev</a><span>|</span><a href="#37242626">next</a><span>|</span><label class="collapse" for="c-37245118">[-]</label><label class="expand" for="c-37245118">[1 more]</label></div><br/><div class="children"><div class="content">Physics stopped Moore’s law</div><br/></div></div></div></div></div></div><div id="37242626" class="c"><input type="checkbox" id="c-37242626" checked=""/><div class="controls bullet"><span class="by">TheAlchemist</span><span>|</span><a href="#37244542">prev</a><span>|</span><a href="#37241858">next</a><span>|</span><label class="collapse" for="c-37242626">[-]</label><label class="expand" for="c-37242626">[68 more]</label></div><br/><div class="children"><div class="content">What&#x27;s also pretty interesting that they actually didn&#x27;t sell more chips this quarter - they ... just pretty much doubled the prices (hence the huge margin).<p>This is what having a monopoly looks like !<p>This is also why companies that manufacture their cards didn&#x27;t report any uptick in profits. I&#x27;m wondering how this play out in some months ? Do they have any pricing power with respect to NVidia ? Or NVidia could just switch to another manufacturer ?</div><br/><div id="37243297" class="c"><input type="checkbox" id="c-37243297" checked=""/><div class="controls bullet"><span class="by">PheonixPharts</span><span>|</span><a href="#37242626">parent</a><span>|</span><a href="#37243532">next</a><span>|</span><label class="collapse" for="c-37243297">[-]</label><label class="expand" for="c-37243297">[37 more]</label></div><br/><div class="children"><div class="content">&gt; This is what having a monopoly looks like !<p>As someone who has been in the AI&#x2F;ML space for over a decade, and even had an AMD&#x2F;Radeon card for more than half of that, I can&#x27;t help but feel that this is partially AMD&#x27;s own fault.<p>For many, many years it seemed to me that AMD just didn&#x27;t take AI&#x2F;ML seriously whereas, for all it&#x27;s faults, NVIDIA seemed to catch on very early that ML presented a tremendous potential market.<p>To this day getting things like Stable Diffusion to run on an AMD card requires extra work. At least from my perspective it seems like dedicating a few engineers to getting ROCm working on all major OSes with all major scientific computing&#x2F;deep learning libraries would have been a pretty good investment.<p>Is there some context I&#x27;m missing for why AMD never caught up in this space?</div><br/><div id="37243376" class="c"><input type="checkbox" id="c-37243376" checked=""/><div class="controls bullet"><span class="by">ken47</span><span>|</span><a href="#37242626">root</a><span>|</span><a href="#37243297">parent</a><span>|</span><a href="#37244105">next</a><span>|</span><label class="collapse" for="c-37243376">[-]</label><label class="expand" for="c-37243376">[9 more]</label></div><br/><div class="children"><div class="content">Until very recently, AMD was struggling for survival. Rather than making the big bet on AI, they went for the sure thing by banking on revolutionary CPU tech. I&#x27;m sure if they were in a better financial position 5 years ago, they would have gone bigger on AI.</div><br/><div id="37243481" class="c"><input type="checkbox" id="c-37243481" checked=""/><div class="controls bullet"><span class="by">xmprt</span><span>|</span><a href="#37242626">root</a><span>|</span><a href="#37243376">parent</a><span>|</span><a href="#37246049">next</a><span>|</span><label class="collapse" for="c-37243481">[-]</label><label class="expand" for="c-37243481">[2 more]</label></div><br/><div class="children"><div class="content">And arguable their bet on CPU tech worked! AMD is in a much better position today than they were 5+ years ago. They have some catching up to do but that doesn&#x27;t mean their completely out of the game.</div><br/><div id="37246540" class="c"><input type="checkbox" id="c-37246540" checked=""/><div class="controls bullet"><span class="by">xcdzvyn</span><span>|</span><a href="#37242626">root</a><span>|</span><a href="#37243481">parent</a><span>|</span><a href="#37246049">next</a><span>|</span><label class="collapse" for="c-37246540">[-]</label><label class="expand" for="c-37246540">[1 more]</label></div><br/><div class="children"><div class="content">&quot;much better&quot; is an understatement! 
&quot;AMD predicted to go bankrupt by 2020&quot;[0]<p>[0] <a href="https:&#x2F;&#x2F;www.overclock3d.net&#x2F;news&#x2F;cpu_mainboard&#x2F;amd_predicted_to_go_bankrupt_by_2020&#x2F;1" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.overclock3d.net&#x2F;news&#x2F;cpu_mainboard&#x2F;amd_predicted...</a></div><br/></div></div></div></div><div id="37246049" class="c"><input type="checkbox" id="c-37246049" checked=""/><div class="controls bullet"><span class="by">izacus</span><span>|</span><a href="#37242626">root</a><span>|</span><a href="#37243376">parent</a><span>|</span><a href="#37243481">prev</a><span>|</span><a href="#37243878">next</a><span>|</span><label class="collapse" for="c-37246049">[-]</label><label class="expand" for="c-37246049">[5 more]</label></div><br/><div class="children"><div class="content">They also focused on game consoles, where they won contracts for both major platforms this generation.</div><br/><div id="37246169" class="c"><input type="checkbox" id="c-37246169" checked=""/><div class="controls bullet"><span class="by">zirgs</span><span>|</span><a href="#37242626">root</a><span>|</span><a href="#37246049">parent</a><span>|</span><a href="#37246146">next</a><span>|</span><label class="collapse" for="c-37246169">[-]</label><label class="expand" for="c-37246169">[3 more]</label></div><br/><div class="children"><div class="content">The other non-major Nvidia based console has higher sales numbers than both of so-called major consoles combined.</div><br/><div id="37246276" class="c"><input type="checkbox" id="c-37246276" checked=""/><div class="controls bullet"><span class="by">mschuster91</span><span>|</span><a href="#37242626">root</a><span>|</span><a href="#37246169">parent</a><span>|</span><a href="#37246146">next</a><span>|</span><label class="collapse" for="c-37246276">[-]</label><label class="expand" for="c-37246276">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s ... difficult to compare a low-power SoC released in 2015 (so, design dating back to 2014 if not earlier) with high-power consoles developed in 2019 onwards.</div><br/><div id="37246574" class="c"><input type="checkbox" id="c-37246574" checked=""/><div class="controls bullet"><span class="by">zirgs</span><span>|</span><a href="#37242626">root</a><span>|</span><a href="#37246276">parent</a><span>|</span><a href="#37246146">next</a><span>|</span><label class="collapse" for="c-37246574">[-]</label><label class="expand" for="c-37246574">[1 more]</label></div><br/><div class="children"><div class="content">They belong to the same generation. Until Switch 2 is released.</div><br/></div></div></div></div></div></div><div id="37246146" class="c"><input type="checkbox" id="c-37246146" checked=""/><div class="controls bullet"><span class="by">Toutouxc</span><span>|</span><a href="#37242626">root</a><span>|</span><a href="#37246049">parent</a><span>|</span><a href="#37246169">prev</a><span>|</span><a href="#37243878">next</a><span>|</span><label class="collapse" for="c-37246146">[-]</label><label class="expand" for="c-37246146">[1 more]</label></div><br/><div class="children"><div class="content">Previous one too. Xbox One and Series and PS4 and PS5 are all AMD, and there’s several revisions of each (e.g. PS4 OG, Slim, Pro).</div><br/></div></div></div></div></div></div><div id="37244105" class="c"><input type="checkbox" id="c-37244105" checked=""/><div class="controls bullet"><span class="by">uluyol</span><span>|</span><a href="#37242626">root</a><span>|</span><a href="#37243297">parent</a><span>|</span><a href="#37243376">prev</a><span>|</span><a href="#37243332">next</a><span>|</span><label class="collapse" for="c-37244105">[-]</label><label class="expand" for="c-37244105">[2 more]</label></div><br/><div class="children"><div class="content">Catching up in this space requires a significant, sustained investment over multiple years and competent software engineers. It&#x27;s not a simple thing for a hardware company to suddenly become competitive with Nvidia in AI&#x2F;ML.<p>Instead, they&#x27;ve been going after the CPU market (and winning), HPC&#x2F;scientific computing (high FP64 performance, in contrast to Nvidia&#x27;s focus on low-precision ML compute), and integrating Xilinx.<p>However, I agree that it&#x27;s an unfortunate situation, and I hope AMD becomes competitive in this space soon.</div><br/><div id="37244578" class="c"><input type="checkbox" id="c-37244578" checked=""/><div class="controls bullet"><span class="by">slashdev</span><span>|</span><a href="#37242626">root</a><span>|</span><a href="#37244105">parent</a><span>|</span><a href="#37243332">next</a><span>|</span><label class="collapse" for="c-37244578">[-]</label><label class="expand" for="c-37244578">[1 more]</label></div><br/><div class="children"><div class="content">I think their hardware is comparable with nvidia. The problem is the software is awful by comparison. It’s hard to run any of the AI workloads with AMD, and even when you can the performance is poor. The software investment just hasn’t been made. Until then they are not even in the game.</div><br/></div></div></div></div><div id="37243332" class="c"><input type="checkbox" id="c-37243332" checked=""/><div class="controls bullet"><span class="by">edgyquant</span><span>|</span><a href="#37242626">root</a><span>|</span><a href="#37243297">parent</a><span>|</span><a href="#37244105">prev</a><span>|</span><a href="#37244313">next</a><span>|</span><label class="collapse" for="c-37243332">[-]</label><label class="expand" for="c-37243332">[4 more]</label></div><br/><div class="children"><div class="content">100% this.  I, and many others, bought multiple AMD cards due to disliking NVidia and tried to get ROCm set up to no avail.  It just never worked except under hard to maintain configurations.  I switched to an nvidia card and within the hour import tensorflow just worked</div><br/><div id="37243667" class="c"><input type="checkbox" id="c-37243667" checked=""/><div class="controls bullet"><span class="by">fleischhauf</span><span>|</span><a href="#37242626">root</a><span>|</span><a href="#37243332">parent</a><span>|</span><a href="#37244313">next</a><span>|</span><label class="collapse" for="c-37243667">[-]</label><label class="expand" for="c-37243667">[3 more]</label></div><br/><div class="children"><div class="content">to be fair Nvidia drivers are also a nightmare under linux</div><br/><div id="37246207" class="c"><input type="checkbox" id="c-37246207" checked=""/><div class="controls bullet"><span class="by">jacooper</span><span>|</span><a href="#37242626">root</a><span>|</span><a href="#37243667">parent</a><span>|</span><a href="#37244313">next</a><span>|</span><label class="collapse" for="c-37246207">[-]</label><label class="expand" for="c-37246207">[2 more]</label></div><br/><div class="children"><div class="content">Not anymore</div><br/><div id="37246287" class="c"><input type="checkbox" id="c-37246287" checked=""/><div class="controls bullet"><span class="by">kristopolous</span><span>|</span><a href="#37242626">root</a><span>|</span><a href="#37246207">parent</a><span>|</span><a href="#37244313">next</a><span>|</span><label class="collapse" for="c-37246287">[-]</label><label class="expand" for="c-37246287">[1 more]</label></div><br/><div class="children"><div class="content">Until they are. When the system breaks it breaks real bad. Nvcc&#x2F;gcc&#x2F;cuda&#x2F;kernel mismatches are a pain to match up right. It gets gnarly super fast.<p>All systems hit snags. In most, you skid the tires a bit, maybe lose balance. With nvidia you&#x27;re flying over the handlebars on to the asphalt.<p>I got snagged by this just about 2 weeks ago. It gets nasty. Not as bad as CUPS, but probably #2.</div><br/></div></div></div></div></div></div></div></div><div id="37244313" class="c"><input type="checkbox" id="c-37244313" checked=""/><div class="controls bullet"><span class="by">tho23iu423o4324</span><span>|</span><a href="#37242626">root</a><span>|</span><a href="#37243297">parent</a><span>|</span><a href="#37243332">prev</a><span>|</span><a href="#37243569">next</a><span>|</span><label class="collapse" for="c-37244313">[-]</label><label class="expand" for="c-37244313">[2 more]</label></div><br/><div class="children"><div class="content">Yes, this is true.<p>However, a lot of this has to do with the fact that AMD was on the brink of bankruptcy before the launch of Zen in 2016 (when their share price was ~$10). They simply did not have the capital to the kind of things Nvidia was doing (since &#x27;08 ?).<p>The bet on OpenCL and the &#x27;open-source&#x27; community failed. However, ROCM&#x2F;HIP etc. really seems to be catching up (I even see them packaged on Arch linux).</div><br/><div id="37246366" class="c"><input type="checkbox" id="c-37246366" checked=""/><div class="controls bullet"><span class="by">slavik81</span><span>|</span><a href="#37242626">root</a><span>|</span><a href="#37244313">parent</a><span>|</span><a href="#37243569">next</a><span>|</span><label class="collapse" for="c-37246366">[-]</label><label class="expand" for="c-37246366">[1 more]</label></div><br/><div class="children"><div class="content">&gt; However, ROCM&#x2F;HIP etc. really seems to be catching up (I even see them packaged on Arch linux).<p>There are now distro-provided packages on Arch, Gentoo, Debian, Ubuntu, and Fedora.</div><br/></div></div></div></div><div id="37243569" class="c"><input type="checkbox" id="c-37243569" checked=""/><div class="controls bullet"><span class="by">Dalewyn</span><span>|</span><a href="#37242626">root</a><span>|</span><a href="#37243297">parent</a><span>|</span><a href="#37244313">prev</a><span>|</span><a href="#37244940">next</a><span>|</span><label class="collapse" for="c-37243569">[-]</label><label class="expand" for="c-37243569">[18 more]</label></div><br/><div class="children"><div class="content">What really strikes me is Nvidia&#x27;s been working hard on doing practical work on their GPUs even just 10~15 years ago with PhysX, while both Intel and AMD just existed.<p>Nvidia&#x27;s dominance today is the product of at least over a decade of work and investments to make better products. Today they are finally reaping their rewards.</div><br/><div id="37243621" class="c"><input type="checkbox" id="c-37243621" checked=""/><div class="controls bullet"><span class="by">desiarnezjr</span><span>|</span><a href="#37242626">root</a><span>|</span><a href="#37243569">parent</a><span>|</span><a href="#37244268">next</a><span>|</span><label class="collapse" for="c-37243621">[-]</label><label class="expand" for="c-37243621">[12 more]</label></div><br/><div class="children"><div class="content">I remember meeting NVIDIA in the late aughts (2007?) first launching their CUDA efforts. Really the product was a re-branded 780GTX or whatever their high end gaming card was at the time more or less, but they already laid out a clear pathway to today (more or less).</div><br/><div id="37243692" class="c"><input type="checkbox" id="c-37243692" checked=""/><div class="controls bullet"><span class="by">dekhn</span><span>|</span><a href="#37242626">root</a><span>|</span><a href="#37243621">parent</a><span>|</span><a href="#37244268">next</a><span>|</span><label class="collapse" for="c-37243692">[-]</label><label class="expand" for="c-37243692">[11 more]</label></div><br/><div class="children"><div class="content">I remember meeting with them in the mid aughts when they were first talking to HPC folks about using their cards for science.  I&#x27;ll never forget what the chief scientist from nVidia said.  &quot;What is the color of a NaN?  That is, when you render a texture with a nan value, what does it look like?  I&#x27;ll tell: it&#x27;s nvidia green.&quot;</div><br/><div id="37246092" class="c"><input type="checkbox" id="c-37246092" checked=""/><div class="controls bullet"><span class="by">hinoki</span><span>|</span><a href="#37242626">root</a><span>|</span><a href="#37243692">parent</a><span>|</span><a href="#37243802">next</a><span>|</span><label class="collapse" for="c-37246092">[-]</label><label class="expand" for="c-37246092">[2 more]</label></div><br/><div class="children"><div class="content">32-bit NaN is encoded:
s111 1111 1xxx xxxx xxxx xxxx xxxx xxxx<p>Where both the sign (s) and the x bits can be anything and it will still be treated as a NaN.<p>There are lots of ways to encode colour, but there would be too much red with RGBA, and ARGB could be almost any opaque colour, but the red channel has to be at least 0x80, which is still too much red.<p>So NaNs are too red to encode nvidia green.</div><br/><div id="37246225" class="c"><input type="checkbox" id="c-37246225" checked=""/><div class="controls bullet"><span class="by">andersa</span><span>|</span><a href="#37242626">root</a><span>|</span><a href="#37246092">parent</a><span>|</span><a href="#37243802">next</a><span>|</span><label class="collapse" for="c-37246225">[-]</label><label class="expand" for="c-37246225">[1 more]</label></div><br/><div class="children"><div class="content">I once ended up having nans get interpreted as 32 bit colors accidentally, and it made everything red and white, like Christmas decoration.<p>Wonder what caused the difference in the latter bits being all 1 or 0 together.</div><br/></div></div></div></div><div id="37243802" class="c"><input type="checkbox" id="c-37243802" checked=""/><div class="controls bullet"><span class="by">WanderPanda</span><span>|</span><a href="#37242626">root</a><span>|</span><a href="#37243692">parent</a><span>|</span><a href="#37246092">prev</a><span>|</span><a href="#37243789">next</a><span>|</span><label class="collapse" for="c-37243802">[-]</label><label class="expand" for="c-37243802">[2 more]</label></div><br/><div class="children"><div class="content">That is a funny way to signal their commitment to HPC! But compared to other tooling (non GPU) CUDA is still really clunky. Way ahead of everything else in the GPGPU space but still surprisingly clunky. Also I don&#x27;t get what they are fearing with all their &quot;Account required for download&quot; (e.g. for CuDNN) what are they fearing? And is it really worth the trade-off for the pain it causes for dev environments and CI pipelines? It really seems like Intel and AMD have to step in to break this monopoly to force them to improve the situation for everyone.</div><br/><div id="37243944" class="c"><input type="checkbox" id="c-37243944" checked=""/><div class="controls bullet"><span class="by">jjoonathan</span><span>|</span><a href="#37242626">root</a><span>|</span><a href="#37243802">parent</a><span>|</span><a href="#37243789">next</a><span>|</span><label class="collapse" for="c-37243944">[-]</label><label class="expand" for="c-37243944">[1 more]</label></div><br/><div class="children"><div class="content">No, you&#x27;re not missing anything, NVIDIA&#x27;s software is super clunky by the standards of most of the software world. However, for the last decade, the competition has been <i>much</i> worse: OpenCL development on AMD would be riddled with VRAM leaks, hard lockups, invisible limits on things like function length and registers that would cause the hard lockups when you tripped over them without any indication as to what you did wrong or how to fix it, that sort of thing. Cryptic error messages would lead to threads scattered around the internet, years old, with pleas for help and no happy endings.<p>The thing that caused me to ragequit the AMD ecosystem was when I took an OpenCL program I had been fighting for two days straight and ran it on my buddy&#x27;s Nvidia system in hopes of getting an error message that might point me in the right direction. Instead, the program just ran, and it ran much faster, even though the nvidia card was theoretically slower.<p>In terms of quality, I expect the competition to catch up in a generation or two, but then there is still the decade+ of legacy code to consider. Hopefully with how fast AI&#x2F;ML churns that isn&#x27;t actually an insurmountable obstacle.</div><br/></div></div></div></div><div id="37243789" class="c"><input type="checkbox" id="c-37243789" checked=""/><div class="controls bullet"><span class="by">jjoonathan</span><span>|</span><a href="#37242626">root</a><span>|</span><a href="#37243692">parent</a><span>|</span><a href="#37243802">prev</a><span>|</span><a href="#37244349">next</a><span>|</span><label class="collapse" for="c-37243789">[-]</label><label class="expand" for="c-37243789">[5 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a quality meme but I&#x27;m having trouble figuring out the settings that make it work. It looks like RGBA8 would be blue:<p><pre><code>    &gt;&gt;&gt; struct.pack(&#x27;f&#x27;,math.nan)
    b&#x27;\x00\x00\xc0\x7f&#x27;
</code></pre>
maybe that becomes green if you composite over white or something? Or maybe there is a common type of NaN that fills some of the unspecified bits? (&quot;Just use the particular NaN that makes it green&quot; is cheating unless you have an excuse)</div><br/><div id="37244022" class="c"><input type="checkbox" id="c-37244022" checked=""/><div class="controls bullet"><span class="by">nealabq</span><span>|</span><a href="#37242626">root</a><span>|</span><a href="#37243789">parent</a><span>|</span><a href="#37243888">next</a><span>|</span><label class="collapse" for="c-37244022">[-]</label><label class="expand" for="c-37244022">[3 more]</label></div><br/><div class="children"><div class="content">They mean big-endian NaN, taking only the first 3 bytes. No alpha channel.<p><a href="https:&#x2F;&#x2F;encycolorpedia.com&#x2F;76b900" rel="nofollow noreferrer">https:&#x2F;&#x2F;encycolorpedia.com&#x2F;76b900</a> says Nvidia green #76b900.</div><br/><div id="37245579" class="c"><input type="checkbox" id="c-37245579" checked=""/><div class="controls bullet"><span class="by">scns</span><span>|</span><a href="#37242626">root</a><span>|</span><a href="#37244022">parent</a><span>|</span><a href="#37244278">next</a><span>|</span><label class="collapse" for="c-37245579">[-]</label><label class="expand" for="c-37245579">[1 more]</label></div><br/><div class="children"><div class="content">Encycolorpedia looks like a great resource, thank you very much. A similar one would be Colorhexa. Not affiliated.<p><a href="https:&#x2F;&#x2F;colorhexa.com" rel="nofollow noreferrer">https:&#x2F;&#x2F;colorhexa.com</a><p>[Edit]
Could not find it under the name, but it shows how color blind users perceive it. And it loads much faster.<p><a href="https:&#x2F;&#x2F;www.colorhexa.com&#x2F;76b900" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.colorhexa.com&#x2F;76b900</a><p>[Edit]
Encycolorpedia has a color blindness simulator too. Have to check on desktop.</div><br/></div></div><div id="37244278" class="c"><input type="checkbox" id="c-37244278" checked=""/><div class="controls bullet"><span class="by">jjoonathan</span><span>|</span><a href="#37242626">root</a><span>|</span><a href="#37244022">parent</a><span>|</span><a href="#37245579">prev</a><span>|</span><a href="#37243888">next</a><span>|</span><label class="collapse" for="c-37244278">[-]</label><label class="expand" for="c-37244278">[1 more]</label></div><br/><div class="children"><div class="content">Cool, thanks!</div><br/></div></div></div></div><div id="37243888" class="c"><input type="checkbox" id="c-37243888" checked=""/><div class="controls bullet"><span class="by">dekhn</span><span>|</span><a href="#37242626">root</a><span>|</span><a href="#37243789">parent</a><span>|</span><a href="#37244022">prev</a><span>|</span><a href="#37244349">next</a><span>|</span><label class="collapse" for="c-37243888">[-]</label><label class="expand" for="c-37243888">[1 more]</label></div><br/><div class="children"><div class="content">It was an arbitrary decision by the engineers who made the early GPUs, they just mapped NaN to an RGB<p>It was a nice way to debug tensors: render them to the screen, the green sticks out.</div><br/></div></div></div></div><div id="37244349" class="c"><input type="checkbox" id="c-37244349" checked=""/><div class="controls bullet"><span class="by">rasz</span><span>|</span><a href="#37242626">root</a><span>|</span><a href="#37243692">parent</a><span>|</span><a href="#37243789">prev</a><span>|</span><a href="#37244268">next</a><span>|</span><label class="collapse" for="c-37244349">[-]</label><label class="expand" for="c-37244349">[1 more]</label></div><br/><div class="children"><div class="content">I remember uni course on GPGPU and only discovering during first lecture Nvidia donated hardware to make sure it would be Cuda only course.</div><br/></div></div></div></div></div></div><div id="37244268" class="c"><input type="checkbox" id="c-37244268" checked=""/><div class="controls bullet"><span class="by">rasz</span><span>|</span><a href="#37242626">root</a><span>|</span><a href="#37243569">parent</a><span>|</span><a href="#37243621">prev</a><span>|</span><a href="#37244940">next</a><span>|</span><label class="collapse" for="c-37244268">[-]</label><label class="expand" for="c-37244268">[5 more]</label></div><br/><div class="children"><div class="content">&gt;doing practical work ... even just 10~15 years ago with PhysX<p>practical work with PhysX 13 years ago: <a href="https:&#x2F;&#x2F;www.realworldtech.com&#x2F;physx87&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.realworldtech.com&#x2F;physx87&#x2F;</a><p>&quot;For Nvidia, decreasing the baseline CPU performance by using x87 instructions and a single thread makes GPUs look better.&quot;<p>Nvidia magically released PhysX compiled with multithreading enabled and without flags disabling SSE a week after this publication. But couple of days before release they made those funny statements:<p>&quot;It&#x27;s fair to say we&#x27;ve got more room to improve on the CPU. But it&#x27;s not fair to say, in the words of that article, that we&#x27;re intentionally hobbling the CPU,&quot; Skolones told Ars.<p>&quot;nobody ever asked for it, and it wouldn&#x27;t help real games anyway because the bottlenecks are elsewhere&quot;<p>&gt;Nvidia&#x27;s dominance today is the product of at least over a decade of work<p>Nvidias decade of work:<p>Ubisoft comments on Assassin’s Creed DX10.1 controversy <a href="https:&#x2F;&#x2F;techreport.com&#x2F;news&#x2F;14707&#x2F;ubisoft-comments-on-assassins-creed-dx10-1-controversy-updated&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;techreport.com&#x2F;news&#x2F;14707&#x2F;ubisoft-comments-on-assass...</a><p>AMD says Nvidia’s GameWorks “completely sabotaged” Witcher 3 performance <a href="https:&#x2F;&#x2F;arstechnica.com&#x2F;gaming&#x2F;2015&#x2F;05&#x2F;amd-says-nvidias-gameworks-completely-sabotaged-witcher-3-performance&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;arstechnica.com&#x2F;gaming&#x2F;2015&#x2F;05&#x2F;amd-says-nvidias-game...</a><p>AMD Dubs Nvidia’s GameWorks Tragic And Damaging, Fight Over The Developer Program Continues <a href="https:&#x2F;&#x2F;wccftech.com&#x2F;fight-nvidias-gameworks-continues-amd-call-program-tragic&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;wccftech.com&#x2F;fight-nvidias-gameworks-continues-amd-c...</a><p>&quot;Number one: Nvidia Gameworks typically damages the performance on Nvidia hardware as well, which is a bit tragic really. It certainly feels like it’s about reducing the performance, even on high-end graphics cards, so that people have to buy something new.<p>&quot;That’s the consequence of it, whether it’s intended or not - and I guess I can’t read anyone’s minds so I can’t tell you what their intention is. But the consequence of it is it brings PCs to their knees when it’s unnecessary. And if you look at Crysis 2 in particular, you see that they’re tessellating water that’s not visible to millions of triangles every frame, and they’re tessellating blocks of concrete – essentially large rectangular objects – and generating millions of triangles per frame which are useless.&quot;<p>&quot;The world&#x27;s greatest virtual concrete slab&quot; <a href="https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20121002034311&#x2F;http:&#x2F;&#x2F;techreport.com&#x2F;review&#x2F;21404&#x2F;crysis-2-tessellation-too-much-of-a-good-thing&#x2F;2" rel="nofollow noreferrer">https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20121002034311&#x2F;http:&#x2F;&#x2F;techreport...</a> (images &quot;somehow&quot; vanished from original article at techreport where Nvidia runs marketing campaigns)<p>&quot;Unnecessary geometric detail slows down all GPUs, of course, but it just so happens to have a much larger effect on DX11-capable AMD Radeons than it does on DX11-capable Nvidia GeForces. The Fermi architecture underlying all DX11-class GeForce GPUs dedicates more attention (and transistors) to achieving high geometry processing throughput than the competing Radeon GPU architectures.&quot;</div><br/><div id="37244796" class="c"><input type="checkbox" id="c-37244796" checked=""/><div class="controls bullet"><span class="by">_gabe_</span><span>|</span><a href="#37242626">root</a><span>|</span><a href="#37244268">parent</a><span>|</span><a href="#37245222">next</a><span>|</span><label class="collapse" for="c-37244796">[-]</label><label class="expand" for="c-37244796">[3 more]</label></div><br/><div class="children"><div class="content">&gt; But GameWorks&#x27; capabilities are necessarily Nvidia-optimized; such code may perform poorly on AMD GPUs.<p>From the arstechnica article about Witcher 3.<p>How dare Nvidia optimize their game enhancing effects for Nvidia hardware and forget to do it for their competitors hardware as well! And as for a lot of these complaints, could it be that a lot of companies only optimize for hardware that has the largest market share?<p>According to the steam hardware survey in July of 2023, Nvidia accounts for 75% of the GPUs[0]. Nvidia and Amd have a lot of incompatibilities, and it can be hard to make the same code performant on both. It makes sense, as a game company, to prioritize optimizations for the largest market. No collusion and evil corporate mega lord scheming needed for this.<p>Edit: Also, Nvidia does put out a lot of research efforts for free. Path rendering on the GPU for example (PhysX being another). You can find research papers and videos published by Nvidia for these things. I would consider that practical work. You can hate on Nvidia for lots of things, but this is one thing I find weird to be combative over.<p>Second Edit: Also, why do you find the statements Nvidia said about the PhysX improvements funny? They’re right. Most games 13 years ago left a lot of idle time on the GPU while the CPU worked overtime to do logic, physics, sound, culling, etc. Lots of that stuff has also been moved to the GPU to minimize the amount of idle time on either the CPU or GPU. Nothing funny about what they said there.<p>[0]: <a href="https:&#x2F;&#x2F;store.steampowered.com&#x2F;hwsurvey&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;store.steampowered.com&#x2F;hwsurvey&#x2F;</a></div><br/><div id="37245314" class="c"><input type="checkbox" id="c-37245314" checked=""/><div class="controls bullet"><span class="by">girvo</span><span>|</span><a href="#37242626">root</a><span>|</span><a href="#37244796">parent</a><span>|</span><a href="#37245222">next</a><span>|</span><label class="collapse" for="c-37245314">[-]</label><label class="expand" for="c-37245314">[2 more]</label></div><br/><div class="children"><div class="content">&gt; could it be that a lot of companies only optimize for hardware that has the largest market share?<p>Yes, but also Nvidia partners directly with companies too (money can&#x2F;does change hands).<p>Now the flip side is: so does AMD.</div><br/><div id="37245810" class="c"><input type="checkbox" id="c-37245810" checked=""/><div class="controls bullet"><span class="by">Dalewyn</span><span>|</span><a href="#37242626">root</a><span>|</span><a href="#37245314">parent</a><span>|</span><a href="#37245222">next</a><span>|</span><label class="collapse" for="c-37245810">[-]</label><label class="expand" for="c-37245810">[1 more]</label></div><br/><div class="children"><div class="content">&gt;Now the flip side is: so does AMD.<p>And their antics shutting out Nvidia (eg: FSR only, no DLSS) aren&#x27;t being received well, not the least because their offerings are objectively inferior to Nvidia&#x27;s.</div><br/></div></div></div></div></div></div><div id="37245222" class="c"><input type="checkbox" id="c-37245222" checked=""/><div class="controls bullet"><span class="by">paulmd</span><span>|</span><a href="#37242626">root</a><span>|</span><a href="#37244268">parent</a><span>|</span><a href="#37244796">prev</a><span>|</span><a href="#37244940">next</a><span>|</span><label class="collapse" for="c-37245222">[-]</label><label class="expand" for="c-37245222">[1 more]</label></div><br/><div class="children"><div class="content">This is factually jot the case as confirmed by Crytek developers at the time. Wireframe mode turns off clipping and cranks up LOD to max, and normally neither the water table would be visible (under the ground) nor would that block be rendered at that LOD.<p><a href="https:&#x2F;&#x2F;old.reddit.com&#x2F;r&#x2F;pcgaming&#x2F;comments&#x2F;3vppv1&#x2F;crysis_2_tessellation_testing_facts&#x2F;cxq3tf0&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;old.reddit.com&#x2F;r&#x2F;pcgaming&#x2F;comments&#x2F;3vppv1&#x2F;crysis_2_t...</a></div><br/></div></div></div></div></div></div><div id="37244940" class="c"><input type="checkbox" id="c-37244940" checked=""/><div class="controls bullet"><span class="by">htrp</span><span>|</span><a href="#37242626">root</a><span>|</span><a href="#37243297">parent</a><span>|</span><a href="#37243569">prev</a><span>|</span><a href="#37243532">next</a><span>|</span><label class="collapse" for="c-37244940">[-]</label><label class="expand" for="c-37244940">[1 more]</label></div><br/><div class="children"><div class="content">AMD gave up on the market for parallel compute entirely</div><br/></div></div></div></div><div id="37243532" class="c"><input type="checkbox" id="c-37243532" checked=""/><div class="controls bullet"><span class="by">JB_Dev</span><span>|</span><a href="#37242626">parent</a><span>|</span><a href="#37243297">prev</a><span>|</span><a href="#37242675">next</a><span>|</span><label class="collapse" for="c-37243532">[-]</label><label class="expand" for="c-37243532">[2 more]</label></div><br/><div class="children"><div class="content">Nvidia and really all chip designers are limited by the fab companies who are trying to scale as fast as they can. But all the cutting edge fabs are limited by one single supplier - ASML. ASML make the lithography machines and have a total monopoly. Even they cannot make lithography machines fast enough to satisfy demand - their lithography machines are sold out 2 years in advance</div><br/><div id="37246354" class="c"><input type="checkbox" id="c-37246354" checked=""/><div class="controls bullet"><span class="by">paulmd</span><span>|</span><a href="#37242626">root</a><span>|</span><a href="#37243532">parent</a><span>|</span><a href="#37242675">next</a><span>|</span><label class="collapse" for="c-37246354">[-]</label><label class="expand" for="c-37246354">[1 more]</label></div><br/><div class="children"><div class="content">The current limitations are not about litho at all but actually about CoWoS stacking capacity.</div><br/></div></div></div></div><div id="37242675" class="c"><input type="checkbox" id="c-37242675" checked=""/><div class="controls bullet"><span class="by">thfuran</span><span>|</span><a href="#37242626">parent</a><span>|</span><a href="#37243532">prev</a><span>|</span><a href="#37243157">next</a><span>|</span><label class="collapse" for="c-37242675">[-]</label><label class="expand" for="c-37242675">[3 more]</label></div><br/><div class="children"><div class="content">There probably isn&#x27;t another manufacturer they can switch high end stuff to. They recently tried moving at least some of their cards to Samsung but switched back last generation due to yield issues.</div><br/><div id="37242729" class="c"><input type="checkbox" id="c-37242729" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#37242626">root</a><span>|</span><a href="#37242675">parent</a><span>|</span><a href="#37243157">next</a><span>|</span><label class="collapse" for="c-37242729">[-]</label><label class="expand" for="c-37242729">[2 more]</label></div><br/><div class="children"><div class="content">You have to distinguish between fabs and AIBs.</div><br/><div id="37242790" class="c"><input type="checkbox" id="c-37242790" checked=""/><div class="controls bullet"><span class="by">thfuran</span><span>|</span><a href="#37242626">root</a><span>|</span><a href="#37242729">parent</a><span>|</span><a href="#37243157">next</a><span>|</span><label class="collapse" for="c-37242790">[-]</label><label class="expand" for="c-37242790">[1 more]</label></div><br/><div class="children"><div class="content">If they treat their AIBs for their enterprise stuff anything like they do in the consumer space, they don&#x27;t really have anything to worry about there (aside from the rest of them giving up on dealing with Nvidia&#x27;s BS, I guess).</div><br/></div></div></div></div></div></div><div id="37243157" class="c"><input type="checkbox" id="c-37243157" checked=""/><div class="controls bullet"><span class="by">kelvie</span><span>|</span><a href="#37242626">parent</a><span>|</span><a href="#37242675">prev</a><span>|</span><a href="#37244347">next</a><span>|</span><label class="collapse" for="c-37243157">[-]</label><label class="expand" for="c-37243157">[2 more]</label></div><br/><div class="children"><div class="content">For my sake, what number did you look at to come to this conclusion? I&#x27;m not used to reading these quarterly reports.</div><br/><div id="37243777" class="c"><input type="checkbox" id="c-37243777" checked=""/><div class="controls bullet"><span class="by">TheAlchemist</span><span>|</span><a href="#37242626">root</a><span>|</span><a href="#37243157">parent</a><span>|</span><a href="#37244347">next</a><span>|</span><label class="collapse" for="c-37243777">[-]</label><label class="expand" for="c-37243777">[1 more]</label></div><br/><div class="children"><div class="content">You can look at cost of revenue to get an idea.</div><br/></div></div></div></div><div id="37244347" class="c"><input type="checkbox" id="c-37244347" checked=""/><div class="controls bullet"><span class="by">tomnipotent</span><span>|</span><a href="#37242626">parent</a><span>|</span><a href="#37243157">prev</a><span>|</span><a href="#37243680">next</a><span>|</span><label class="collapse" for="c-37244347">[-]</label><label class="expand" for="c-37244347">[1 more]</label></div><br/><div class="children"><div class="content">&gt;  just pretty much doubled the prices<p>They prices were already double, it was just scummy resellers capturing that value rather than Nvidia.</div><br/></div></div><div id="37243680" class="c"><input type="checkbox" id="c-37243680" checked=""/><div class="controls bullet"><span class="by">dekhn</span><span>|</span><a href="#37242626">parent</a><span>|</span><a href="#37244347">prev</a><span>|</span><a href="#37243384">next</a><span>|</span><label class="collapse" for="c-37243680">[-]</label><label class="expand" for="c-37243680">[1 more]</label></div><br/><div class="children"><div class="content">nvidia deserves their monopoly and it&#x27;s in the US&#x27;s best interest to let it continue.<p>the other companies have to up their game to compete with a company that has been executing well for 20+ years.</div><br/></div></div><div id="37243384" class="c"><input type="checkbox" id="c-37243384" checked=""/><div class="controls bullet"><span class="by">BbzzbB</span><span>|</span><a href="#37242626">parent</a><span>|</span><a href="#37243680">prev</a><span>|</span><a href="#37245022">next</a><span>|</span><label class="collapse" for="c-37243384">[-]</label><label class="expand" for="c-37243384">[6 more]</label></div><br/><div class="children"><div class="content">Isn&#x27;t this more a case of supply and demand? Huge ramp on chip demand by every FAAMG, every dev and their grandmothers for AI with a mostly inelastic supply (foundry constrained and very specialized atoms tech involved).<p>It&#x27;s not like Intel and AMD don&#x27;t exist, but if everyone is pushing each other at the door for Nvidia chips..</div><br/><div id="37243651" class="c"><input type="checkbox" id="c-37243651" checked=""/><div class="controls bullet"><span class="by">jfoutz</span><span>|</span><a href="#37242626">root</a><span>|</span><a href="#37243384">parent</a><span>|</span><a href="#37245022">next</a><span>|</span><label class="collapse" for="c-37243651">[-]</label><label class="expand" for="c-37243651">[5 more]</label></div><br/><div class="children"><div class="content">Amazon, Alphabet, Meta. Who are the F and G, and where is apple?</div><br/><div id="37243752" class="c"><input type="checkbox" id="c-37243752" checked=""/><div class="controls bullet"><span class="by">buzzerbetrayed</span><span>|</span><a href="#37242626">root</a><span>|</span><a href="#37243651">parent</a><span>|</span><a href="#37245022">next</a><span>|</span><label class="collapse" for="c-37243752">[-]</label><label class="expand" for="c-37243752">[4 more]</label></div><br/><div class="children"><div class="content">Facebook, Amazon, Apple, Microsoft, and Google</div><br/><div id="37244348" class="c"><input type="checkbox" id="c-37244348" checked=""/><div class="controls bullet"><span class="by">SAI_Peregrinus</span><span>|</span><a href="#37242626">root</a><span>|</span><a href="#37243752">parent</a><span>|</span><a href="#37245022">next</a><span>|</span><label class="collapse" for="c-37244348">[-]</label><label class="expand" for="c-37244348">[3 more]</label></div><br/><div class="children"><div class="content">While I hate using the stupid &quot;meta&quot; name, MAGMA is a much more fun acronym than FAAMG, or GMFAA, or MAGAF, etc.</div><br/><div id="37244723" class="c"><input type="checkbox" id="c-37244723" checked=""/><div class="controls bullet"><span class="by">aiisjustanif</span><span>|</span><a href="#37242626">root</a><span>|</span><a href="#37244348">parent</a><span>|</span><a href="#37245022">next</a><span>|</span><label class="collapse" for="c-37244723">[-]</label><label class="expand" for="c-37244723">[2 more]</label></div><br/><div class="children"><div class="content">Meta Apple Microsoft Alphabet Amazon<p>MAMAA</div><br/></div></div></div></div></div></div></div></div></div></div><div id="37245022" class="c"><input type="checkbox" id="c-37245022" checked=""/><div class="controls bullet"><span class="by">ttunguz</span><span>|</span><a href="#37242626">parent</a><span>|</span><a href="#37243384">prev</a><span>|</span><a href="#37243177">next</a><span>|</span><label class="collapse" for="c-37245022">[-]</label><label class="expand" for="c-37245022">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m curious where did you find the data point that they sold an equal number of units quarter over quarter?</div><br/></div></div><div id="37243177" class="c"><input type="checkbox" id="c-37243177" checked=""/><div class="controls bullet"><span class="by">Mistletoe</span><span>|</span><a href="#37242626">parent</a><span>|</span><a href="#37245022">prev</a><span>|</span><a href="#37242685">next</a><span>|</span><label class="collapse" for="c-37243177">[-]</label><label class="expand" for="c-37243177">[2 more]</label></div><br/><div class="children"><div class="content">How does the Nvidia stranglehold on AI compare to US Steel, Standard Oil and Bell Telephone etc., other monopolies that were broken up?</div><br/><div id="37246282" class="c"><input type="checkbox" id="c-37246282" checked=""/><div class="controls bullet"><span class="by">zirgs</span><span>|</span><a href="#37242626">root</a><span>|</span><a href="#37243177">parent</a><span>|</span><a href="#37242685">next</a><span>|</span><label class="collapse" for="c-37246282">[-]</label><label class="expand" for="c-37246282">[1 more]</label></div><br/><div class="children"><div class="content">There isn&#x27;t a monopoly. Their competitors just are really bad at it.</div><br/></div></div></div></div><div id="37242727" class="c"><input type="checkbox" id="c-37242727" checked=""/><div class="controls bullet"><span class="by">issafram</span><span>|</span><a href="#37242626">parent</a><span>|</span><a href="#37242685">prev</a><span>|</span><a href="#37241858">next</a><span>|</span><label class="collapse" for="c-37242727">[-]</label><label class="expand" for="c-37242727">[10 more]</label></div><br/><div class="children"><div class="content">Not that it&#x27;s much better, but wouldn&#x27;t it be a duopoly considering that AMD is also a big player?<p>Hopefully Intel continues to improve it&#x27;s GPU offerings</div><br/><div id="37242988" class="c"><input type="checkbox" id="c-37242988" checked=""/><div class="controls bullet"><span class="by">capableweb</span><span>|</span><a href="#37242626">root</a><span>|</span><a href="#37242727">parent</a><span>|</span><a href="#37242891">next</a><span>|</span><label class="collapse" for="c-37242988">[-]</label><label class="expand" for="c-37242988">[5 more]</label></div><br/><div class="children"><div class="content">&gt;  Not that it&#x27;s much better, but wouldn&#x27;t it be a duopoly considering that AMD is also a big player?<p>Not sure AMD would be considered a big player, what would be the percentage threshold for that?<p>According to the Steam Hardware (&amp; Software) Survey (<a href="https:&#x2F;&#x2F;store.steampowered.com&#x2F;hwsurvey&#x2F;Steam-Hardware-Software-Survey-Welcome-to-Steam" rel="nofollow noreferrer">https:&#x2F;&#x2F;store.steampowered.com&#x2F;hwsurvey&#x2F;Steam-Hardware-Softw...</a>), ~75% of computers with Steam running has a NVIDIA GPU, while ~15% has a AMD GPU.<p>AMD is the closest to a competitor NVIDIA has, but they are also very far away from even being close to their market-share.<p>I&#x27;m sure in AI&#x2F;ML spaces, NVIDIA holds a even higher market-share due to CUDA and the rest of the ecosystem, at least in gaming things are pretty much &quot;plug and play&quot; when it comes to switching between AMD&#x2F;NVIDIA hardware, but no such luck in most cases with AI&#x2F;ML.</div><br/><div id="37243105" class="c"><input type="checkbox" id="c-37243105" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#37242626">root</a><span>|</span><a href="#37242988">parent</a><span>|</span><a href="#37242891">next</a><span>|</span><label class="collapse" for="c-37243105">[-]</label><label class="expand" for="c-37243105">[4 more]</label></div><br/><div class="children"><div class="content">&gt; ~75% of computers with Steam running has a NVIDIA GPU, while ~15% has a AMD GPU.<p>and thats the consumer market, which lets say is 30% of the B2B enterprise market, which is probably even higher % nvidia</div><br/><div id="37246056" class="c"><input type="checkbox" id="c-37246056" checked=""/><div class="controls bullet"><span class="by">izacus</span><span>|</span><a href="#37242626">root</a><span>|</span><a href="#37243105">parent</a><span>|</span><a href="#37243291">next</a><span>|</span><label class="collapse" for="c-37246056">[-]</label><label class="expand" for="c-37246056">[2 more]</label></div><br/><div class="children"><div class="content">And then there&#x27;s the console market, with more units sold than PC gaming market, with 100% AMD GPUs.</div><br/><div id="37246292" class="c"><input type="checkbox" id="c-37246292" checked=""/><div class="controls bullet"><span class="by">zirgs</span><span>|</span><a href="#37242626">root</a><span>|</span><a href="#37246056">parent</a><span>|</span><a href="#37243291">next</a><span>|</span><label class="collapse" for="c-37246292">[-]</label><label class="expand" for="c-37246292">[1 more]</label></div><br/><div class="children"><div class="content">The Switch is based on Nvidia hardware.</div><br/></div></div></div></div><div id="37243291" class="c"><input type="checkbox" id="c-37243291" checked=""/><div class="controls bullet"><span class="by">User23</span><span>|</span><a href="#37242626">root</a><span>|</span><a href="#37243105">parent</a><span>|</span><a href="#37246056">prev</a><span>|</span><a href="#37242891">next</a><span>|</span><label class="collapse" for="c-37243291">[-]</label><label class="expand" for="c-37243291">[1 more]</label></div><br/><div class="children"><div class="content">AI cloud is something like 95% Nvidia.</div><br/></div></div></div></div></div></div><div id="37242891" class="c"><input type="checkbox" id="c-37242891" checked=""/><div class="controls bullet"><span class="by">tric</span><span>|</span><a href="#37242626">root</a><span>|</span><a href="#37242727">parent</a><span>|</span><a href="#37242988">prev</a><span>|</span><a href="#37241858">next</a><span>|</span><label class="collapse" for="c-37242891">[-]</label><label class="expand" for="c-37242891">[4 more]</label></div><br/><div class="children"><div class="content">&gt; wouldn&#x27;t it be a duopoly considering that AMD is also a big player?<p>I don&#x27;t think GPUs are commoditized. You can&#x27;t swap a Nvida GPU with a AMD GPU, and get the same performance&#x2F;results.</div><br/><div id="37242970" class="c"><input type="checkbox" id="c-37242970" checked=""/><div class="controls bullet"><span class="by">midhir</span><span>|</span><a href="#37242626">root</a><span>|</span><a href="#37242891">parent</a><span>|</span><a href="#37241858">next</a><span>|</span><label class="collapse" for="c-37242970">[-]</label><label class="expand" for="c-37242970">[3 more]</label></div><br/><div class="children"><div class="content">AMD seem to be catching up quickly lately. I&#x27;m running Stable Diffusion, Llama-2, and Pytorch on a 7900XTX right now. Getting it up and running even on an unsupported Linux distro is relatively straightforward. Details for Arch are here: <a href="https:&#x2F;&#x2F;gitlab.com&#x2F;-&#x2F;snippets&#x2F;2584462" rel="nofollow noreferrer">https:&#x2F;&#x2F;gitlab.com&#x2F;-&#x2F;snippets&#x2F;2584462</a><p>The HIP interface even has almost exact interoperability with CUDA, so you don&#x27;t have to rewrite your code.</div><br/><div id="37246305" class="c"><input type="checkbox" id="c-37246305" checked=""/><div class="controls bullet"><span class="by">zirgs</span><span>|</span><a href="#37242626">root</a><span>|</span><a href="#37242970">parent</a><span>|</span><a href="#37243280">next</a><span>|</span><label class="collapse" for="c-37246305">[-]</label><label class="expand" for="c-37246305">[1 more]</label></div><br/><div class="children"><div class="content">Now try doing the same on Windows.</div><br/></div></div><div id="37243280" class="c"><input type="checkbox" id="c-37243280" checked=""/><div class="controls bullet"><span class="by">ABeeSea</span><span>|</span><a href="#37242626">root</a><span>|</span><a href="#37242970">parent</a><span>|</span><a href="#37246305">prev</a><span>|</span><a href="#37241858">next</a><span>|</span><label class="collapse" for="c-37243280">[-]</label><label class="expand" for="c-37243280">[1 more]</label></div><br/><div class="children"><div class="content">Inference and training are not the same things. AMD has basically no market share in training.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="37241858" class="c"><input type="checkbox" id="c-37241858" checked=""/><div class="controls bullet"><span class="by">xnx</span><span>|</span><a href="#37242626">prev</a><span>|</span><a href="#37241920">next</a><span>|</span><label class="collapse" for="c-37241858">[-]</label><label class="expand" for="c-37241858">[52 more]</label></div><br/><div class="children"><div class="content">The good new is that Nvidia&#x27;s high GPU prices motivate everyone (Intel, AMD, ARM, Google, etc.) to try and tackle the problem by making new chips, making more efficient use of current chips, etc. For all the distributed computing efforts that have existed (prime factorization, SETI@Home, Bitcoin, etc.), I&#x27;m surprised there isn&#x27;t some way for gamers to rent out use of their GPU&#x27;s when idle. It wouldn&#x27;t be efficient, but at these prices it could still make sense.</div><br/><div id="37242159" class="c"><input type="checkbox" id="c-37242159" checked=""/><div class="controls bullet"><span class="by">Uehreka</span><span>|</span><a href="#37241858">parent</a><span>|</span><a href="#37242716">next</a><span>|</span><label class="collapse" for="c-37242159">[-]</label><label class="expand" for="c-37242159">[26 more]</label></div><br/><div class="children"><div class="content">They’re all pretty motivated, they’ve been motivated for years, and almost nothing is happening. This situation isn’t exactly a poster child for the Efficient Markets Hypothesis.<p>Every year just sounds like “Nvidia’s new consumer GPUs are adding new features, breaking previous performance ceilings, running games at huge resolutions and framerates. Their datacenter cards are completely sold out because they can spin straw into gold, and Nvidia continues to develop new AI and graphics techniques built on their proprietary CUDA framework (that no one else can implement). Meanwhile AMD has finally sorted out raytracing, and their consumer GPUs are… well not as good as Nvidia’s but they’re a better value if you’re looking for a competitor to one of Nvidia’s 60 or 70 line GPUs!”</div><br/><div id="37242603" class="c"><input type="checkbox" id="c-37242603" checked=""/><div class="controls bullet"><span class="by">lotsofpulp</span><span>|</span><a href="#37241858">root</a><span>|</span><a href="#37242159">parent</a><span>|</span><a href="#37242242">next</a><span>|</span><label class="collapse" for="c-37242603">[-]</label><label class="expand" for="c-37242603">[17 more]</label></div><br/><div class="children"><div class="content">Efficient market hypothesis is unrelated to Nvidia’s competitors being unable to offer a competing product so far.<p><a href="https:&#x2F;&#x2F;www.investopedia.com&#x2F;terms&#x2F;e&#x2F;efficientmarkethypothesis.asp" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.investopedia.com&#x2F;terms&#x2F;e&#x2F;efficientmarkethypothes...</a><p>&gt; The efficient market hypothesis (EMH), alternatively known as the efficient market theory, is a hypothesis that states that share prices reflect all information and consistent alpha generation is impossible.</div><br/><div id="37243019" class="c"><input type="checkbox" id="c-37243019" checked=""/><div class="controls bullet"><span class="by">ikrenji</span><span>|</span><a href="#37241858">root</a><span>|</span><a href="#37242603">parent</a><span>|</span><a href="#37242242">next</a><span>|</span><label class="collapse" for="c-37243019">[-]</label><label class="expand" for="c-37243019">[16 more]</label></div><br/><div class="children"><div class="content">you know what he meant...</div><br/><div id="37246500" class="c"><input type="checkbox" id="c-37246500" checked=""/><div class="controls bullet"><span class="by">kortilla</span><span>|</span><a href="#37241858">root</a><span>|</span><a href="#37243019">parent</a><span>|</span><a href="#37243132">next</a><span>|</span><label class="collapse" for="c-37246500">[-]</label><label class="expand" for="c-37246500">[1 more]</label></div><br/><div class="children"><div class="content">No, spell it out because it’s complete nonsense as it is. The efficient market hypothesis has zero relationship to barriers of entry, network effects, or any of the other dozen concepts that maybe are actually at play here.</div><br/></div></div><div id="37243132" class="c"><input type="checkbox" id="c-37243132" checked=""/><div class="controls bullet"><span class="by">jbc1</span><span>|</span><a href="#37241858">root</a><span>|</span><a href="#37243019">parent</a><span>|</span><a href="#37246500">prev</a><span>|</span><a href="#37242242">next</a><span>|</span><label class="collapse" for="c-37243132">[-]</label><label class="expand" for="c-37243132">[14 more]</label></div><br/><div class="children"><div class="content">I honestly dont. I&#x27;m trying to think of what principle they could have meant with &quot;This situation isn’t exactly a poster child for X&quot; where X is any economic principle and coming up empty.<p>Best I&#x27;ve got is &quot;central planning&quot;. One firm being able to handily out perform others despite them also being both motivated and well capitalised lends itself pretty heavily towards markets being good, but I hardly think they were referring to &quot;central planning&quot; when they wrote &quot;efficient market hypothesis&quot;.<p>If it&#x27;s so obvious to you that you&#x27;re dropping ellipsis, care to clue us in?</div><br/><div id="37243191" class="c"><input type="checkbox" id="c-37243191" checked=""/><div class="controls bullet"><span class="by">mkaic</span><span>|</span><a href="#37241858">root</a><span>|</span><a href="#37243132">parent</a><span>|</span><a href="#37242242">next</a><span>|</span><label class="collapse" for="c-37243191">[-]</label><label class="expand" for="c-37243191">[13 more]</label></div><br/><div class="children"><div class="content">My impression was that they used &quot;Efficient Market Hypothesis&quot; to mean &quot;the theory that free-market competition rapidly drives down prices and breaks up monopolies on its own&quot;.</div><br/><div id="37243688" class="c"><input type="checkbox" id="c-37243688" checked=""/><div class="controls bullet"><span class="by">panick21_</span><span>|</span><a href="#37241858">root</a><span>|</span><a href="#37243191">parent</a><span>|</span><a href="#37243318">next</a><span>|</span><label class="collapse" for="c-37243688">[-]</label><label class="expand" for="c-37243688">[4 more]</label></div><br/><div class="children"><div class="content">&gt; the theory that free-market competition rapidly drives down prices and breaks up monopolies on its own<p>You mean a theory that no economic school actually believes? Not even Austrians would sign that.</div><br/><div id="37245511" class="c"><input type="checkbox" id="c-37245511" checked=""/><div class="controls bullet"><span class="by">Geee</span><span>|</span><a href="#37241858">root</a><span>|</span><a href="#37243688">parent</a><span>|</span><a href="#37244128">next</a><span>|</span><label class="collapse" for="c-37245511">[-]</label><label class="expand" for="c-37245511">[1 more]</label></div><br/><div class="children"><div class="content">Well, patents are certainly a good way to create monopolies, which wouldn&#x27;t exist in an actually free market with no patents. In addition, there&#x27;s interventions in place which don&#x27;t allow certain tech exports to China, for example. Not sure how much better the situation would be without these.<p>I think the principle is called <i>perfect market</i> or <i>perfect competition</i>, but it&#x27;s only a theoretical concept. However, it&#x27;s certainly possible that the market is less perfect than it could be due to interventions and regulations.</div><br/></div></div><div id="37244128" class="c"><input type="checkbox" id="c-37244128" checked=""/><div class="controls bullet"><span class="by">mkaic</span><span>|</span><a href="#37241858">root</a><span>|</span><a href="#37243688">parent</a><span>|</span><a href="#37245511">prev</a><span>|</span><a href="#37244241">next</a><span>|</span><label class="collapse" for="c-37244128">[-]</label><label class="expand" for="c-37244128">[1 more]</label></div><br/><div class="children"><div class="content">Not <i>endorsing</i> that theory, just offering my best guess at what the person probably meant when they used &quot;Efficient Market Theory&quot; in their comment, based on the context.</div><br/></div></div><div id="37244241" class="c"><input type="checkbox" id="c-37244241" checked=""/><div class="controls bullet"><span class="by">shsixhehgf</span><span>|</span><a href="#37241858">root</a><span>|</span><a href="#37243688">parent</a><span>|</span><a href="#37244128">prev</a><span>|</span><a href="#37243318">next</a><span>|</span><label class="collapse" for="c-37244241">[-]</label><label class="expand" for="c-37244241">[1 more]</label></div><br/><div class="children"><div class="content">You sound very confused. That’s economics 101 just about everywhere. The friction is generally termed “barriers to entry” if that helps reorient you.</div><br/></div></div></div></div><div id="37243318" class="c"><input type="checkbox" id="c-37243318" checked=""/><div class="controls bullet"><span class="by">sph</span><span>|</span><a href="#37241858">root</a><span>|</span><a href="#37243191">parent</a><span>|</span><a href="#37243688">prev</a><span>|</span><a href="#37242242">next</a><span>|</span><label class="collapse" for="c-37243318">[-]</label><label class="expand" for="c-37243318">[8 more]</label></div><br/><div class="children"><div class="content">That theory is still valid, the issue is that the competition can&#x27;t or won&#x27;t even try to make a better product or a cheaper one. The rule only applies if there exist competing products in the first place.<p>If there was any, the prices would go down as we have seen a billion times.</div><br/><div id="37243450" class="c"><input type="checkbox" id="c-37243450" checked=""/><div class="controls bullet"><span class="by">roughly</span><span>|</span><a href="#37241858">root</a><span>|</span><a href="#37243318">parent</a><span>|</span><a href="#37243659">next</a><span>|</span><label class="collapse" for="c-37243450">[-]</label><label class="expand" for="c-37243450">[2 more]</label></div><br/><div class="children"><div class="content">So, why’s that not happening, and what’s it imply for the rest of the theoretical framework?</div><br/><div id="37243987" class="c"><input type="checkbox" id="c-37243987" checked=""/><div class="controls bullet"><span class="by">supazek</span><span>|</span><a href="#37241858">root</a><span>|</span><a href="#37243450">parent</a><span>|</span><a href="#37243659">next</a><span>|</span><label class="collapse" for="c-37243987">[-]</label><label class="expand" for="c-37243987">[1 more]</label></div><br/><div class="children"><div class="content">It’s not happening because 10,000 people who have more intimate knowledge of the business than you or I ever will have made decisions to best suit their current conditions. This isn’t an exception to the rule, you’re just looking at a small timeframe and a remarkably performant company. Why is it so bad for a company to be successful when they have provided so much back to society in the form of R&amp;D? Besides, if I’m doing ML my boss has paid for the card anyway so the price doesn’t concern me.</div><br/></div></div></div></div><div id="37243659" class="c"><input type="checkbox" id="c-37243659" checked=""/><div class="controls bullet"><span class="by">AndrewKemendo</span><span>|</span><a href="#37241858">root</a><span>|</span><a href="#37243318">parent</a><span>|</span><a href="#37243450">prev</a><span>|</span><a href="#37242242">next</a><span>|</span><label class="collapse" for="c-37243659">[-]</label><label class="expand" for="c-37243659">[5 more]</label></div><br/><div class="children"><div class="content">This is the point.<p>This is a textbook situation that would be perfect for a competitor to come in and undercut. However not only is that not happening, nobody is even trying.<p>Making the “theory” pretty worthless if it’s not even applicable in cases that would naturally produce this market entrant.<p>The reality is that private equity does not actually want to compete with large global brands.</div><br/><div id="37243999" class="c"><input type="checkbox" id="c-37243999" checked=""/><div class="controls bullet"><span class="by">andrewjl</span><span>|</span><a href="#37241858">root</a><span>|</span><a href="#37243659">parent</a><span>|</span><a href="#37246053">next</a><span>|</span><label class="collapse" for="c-37243999">[-]</label><label class="expand" for="c-37243999">[2 more]</label></div><br/><div class="children"><div class="content">&gt; This is a textbook situation that would be perfect for a competitor to come in and undercut.<p>Is it? A competitor can enter the market and undercut by producing a cheaper and otherwise undifferentiated commodity-type product. Nvidia&#x27;s focus is adding moats that prevent competing on pure specs such as CUDA, design, and so on.</div><br/><div id="37246368" class="c"><input type="checkbox" id="c-37246368" checked=""/><div class="controls bullet"><span class="by">zirgs</span><span>|</span><a href="#37241858">root</a><span>|</span><a href="#37243999">parent</a><span>|</span><a href="#37246053">next</a><span>|</span><label class="collapse" for="c-37246368">[-]</label><label class="expand" for="c-37246368">[1 more]</label></div><br/><div class="children"><div class="content">Nvidia started working on CUDA back in the mid-2000s. Nobody else cared about GPU compute back then.</div><br/></div></div></div></div><div id="37246053" class="c"><input type="checkbox" id="c-37246053" checked=""/><div class="controls bullet"><span class="by">redox99</span><span>|</span><a href="#37241858">root</a><span>|</span><a href="#37243659">parent</a><span>|</span><a href="#37243999">prev</a><span>|</span><a href="#37244234">next</a><span>|</span><label class="collapse" for="c-37246053">[-]</label><label class="expand" for="c-37246053">[1 more]</label></div><br/><div class="children"><div class="content">&gt; However not only is that not happening, nobody is even trying.<p>A lot of companies are trying. It&#x27;s just that nvidia is really good and significantly ahead.</div><br/></div></div><div id="37244234" class="c"><input type="checkbox" id="c-37244234" checked=""/><div class="controls bullet"><span class="by">ElectricalUnion</span><span>|</span><a href="#37241858">root</a><span>|</span><a href="#37243659">parent</a><span>|</span><a href="#37246053">prev</a><span>|</span><a href="#37242242">next</a><span>|</span><label class="collapse" for="c-37244234">[-]</label><label class="expand" for="c-37244234">[1 more]</label></div><br/><div class="children"><div class="content">&gt; This is a textbook situation that would be perfect for a competitor to come in and undercut.<p>They already are undercutting.<p>Some business that are really into hyper-scaling are already pouring man-hours into making those &quot;undercut&quot; alternative products work. Specifically because sometimes you can&#x27;t affort Nvidia at that scale. Or they have a large enough scale that they can make it work with suboptimal tech.<p>It&#x27;s just that for most business the man-hours required to make &quot;undercut&quot; products work still aren&#x27;t cheap enough to win in cost-benefit.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="37242242" class="c"><input type="checkbox" id="c-37242242" checked=""/><div class="controls bullet"><span class="by">ericmay</span><span>|</span><a href="#37241858">root</a><span>|</span><a href="#37242159">parent</a><span>|</span><a href="#37242603">prev</a><span>|</span><a href="#37243055">next</a><span>|</span><label class="collapse" for="c-37242242">[-]</label><label class="expand" for="c-37242242">[2 more]</label></div><br/><div class="children"><div class="content">&gt; This situation isn’t exactly a poster child for the Efficient Markets Hypothesis.<p>I&#x27;m unsure why you&#x27;re criticizing the Efficient Markets Hypothesis or even using it here, but you need to also analyze this with some time horizon because the market and marketplaces are not static.</div><br/><div id="37242493" class="c"><input type="checkbox" id="c-37242493" checked=""/><div class="controls bullet"><span class="by">willis936</span><span>|</span><a href="#37241858">root</a><span>|</span><a href="#37242242">parent</a><span>|</span><a href="#37243055">next</a><span>|</span><label class="collapse" for="c-37242493">[-]</label><label class="expand" for="c-37242493">[1 more]</label></div><br/><div class="children"><div class="content">Their description could be used to describe the situation in 2023, 2022, 2021, 2020, 2019, 2018, 2017, and 2016.</div><br/></div></div></div></div><div id="37243055" class="c"><input type="checkbox" id="c-37243055" checked=""/><div class="controls bullet"><span class="by">kimixa</span><span>|</span><a href="#37241858">root</a><span>|</span><a href="#37242159">parent</a><span>|</span><a href="#37242242">prev</a><span>|</span><a href="#37243632">next</a><span>|</span><label class="collapse" for="c-37243055">[-]</label><label class="expand" for="c-37243055">[2 more]</label></div><br/><div class="children"><div class="content">Tech design and development seems, to me at least, pretty much naturally opposed to the &quot;being kept in check with competition&quot; state - as design isn&#x27;t really a cost that scales per-unit, the company that sells slightly more can afford to put more into development at the same per-unit margin, which snowballs. At some point, they own the entire market - or enough that they functionally control it, and start leveraging this position. I&#x27;d argue we&#x27;re seeing this from Nvidia right now.<p>People talk about AMD being competition - but from most stats I&#x27;ve seen, they&#x27;re ~10% of dGPU sales, with Nvidia being the other 90% (with new Intel offerings being pretty much noise now). That means that if they invest the same proportion into development, NVidia nearly have 10x the resources.<p>It may be that tech companies like this would &quot;naturally&quot; form a monopoly without outside (IE government) interference, as the only reason that multiplier of development resources doesn&#x27;t completely crush new entrants is rather extreme mismanagement, or a new segment is created where the design resource don&#x27;t really cross over that much.<p>I don&#x27;t see anything like that happening in the short term, if anything there seems to be more opportunity for cross pollination of development within these corporations, as there&#x27;s a fair bit of design similarities between various silicon (GPUs, CPUs, accelerators for the current ML techniques etc.) that may encourage <i>more</i> consolidation in the whole semi market to take advantage of that, not less. But again the only thing stepping in the way of that seems to be governments trying to keep national interests, like the blocking of NVidia buying ARM to pull in one of the big CPU players. Plus all their other IP that they may benefit from, like low power GPU designs or other accelerators ARM have designed.</div><br/><div id="37246491" class="c"><input type="checkbox" id="c-37246491" checked=""/><div class="controls bullet"><span class="by">tm-guimaraes</span><span>|</span><a href="#37241858">root</a><span>|</span><a href="#37243055">parent</a><span>|</span><a href="#37243632">next</a><span>|</span><label class="collapse" for="c-37246491">[-]</label><label class="expand" for="c-37246491">[1 more]</label></div><br/><div class="children"><div class="content">At the end of the day, what nvidia does is just producing IP. All manufacture is by other companies.<p>This means that nvidia capital is spend on testing&#x2F;development infrastructure and creative labor.<p>So, you don’t need monopoly breaking to handle nvidia if it keeps growing, but instead rethink IP laws.<p>Testing infrastructure is less capital investment than production manufacture. (See ASML and TSMC beeing booked), and humans can be persuaded to work elsewhere.<p>This means Nvidia cannot fall a sleep, even if they keep snowballing. In a few years a rival can always arrive, or current ones snag key people or have dev&#x2F;test infra breakthrough, or IP law could change as its critics rise every year.<p>Sure, if Nvidia keeps its good game it will keep on growing and get even bigger share, but if it doesn’t, it will happen what happened with intel, intel got greedy on its position, and the company got fat.<p>As long as nvidia keeps its game, it’ll be good for customers even if they swallow more market share, as prices are always limited by the value business customers get from AI, and the investment needed for a competitor is not even close to infrastructure or resource extraction stuff like high end chip fabs, oil extraction, energy grids, telecom grids.<p>Again, Nvidia does not produce any physical goods, only designs.</div><br/></div></div></div></div><div id="37243632" class="c"><input type="checkbox" id="c-37243632" checked=""/><div class="controls bullet"><span class="by">creer</span><span>|</span><a href="#37241858">root</a><span>|</span><a href="#37242159">parent</a><span>|</span><a href="#37243055">prev</a><span>|</span><a href="#37244805">next</a><span>|</span><label class="collapse" for="c-37243632">[-]</label><label class="expand" for="c-37243632">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not like designing this kind of product is easy; or that Nvidia&#x27;s designers are sitting idle; or that everybody else&#x27;s design team is not busy building something else. There are in fact many competent design teams, chipping at their own business.<p>There are in fact startups, also doing what they can (and probably not trying to go head on against the most productive competitor they can find.) And it has been reported countless times that some of the biggest customers of Nvidia are actually trying to design their own.<p>If you want to point out a market with broken competition, this isn&#x27;t it.</div><br/></div></div><div id="37244805" class="c"><input type="checkbox" id="c-37244805" checked=""/><div class="controls bullet"><span class="by">fulafel</span><span>|</span><a href="#37241858">root</a><span>|</span><a href="#37242159">parent</a><span>|</span><a href="#37243632">prev</a><span>|</span><a href="#37243360">next</a><span>|</span><label class="collapse" for="c-37244805">[-]</label><label class="expand" for="c-37244805">[1 more]</label></div><br/><div class="children"><div class="content">To play the free market advocate:<p>The situation is created by artificial restrictions on free market (namely state enforced monopolies on &quot;IPR&quot;, or as some call it, imaginary property).</div><br/></div></div><div id="37243360" class="c"><input type="checkbox" id="c-37243360" checked=""/><div class="controls bullet"><span class="by">sph</span><span>|</span><a href="#37241858">root</a><span>|</span><a href="#37242159">parent</a><span>|</span><a href="#37244805">prev</a><span>|</span><a href="#37242716">next</a><span>|</span><label class="collapse" for="c-37243360">[-]</label><label class="expand" for="c-37243360">[2 more]</label></div><br/><div class="children"><div class="content">Are they motivated? Seems like a massive coincidence how the big two of the GPU world are cousins, and one has been having massive success on the CPU, the other on GPU&#x2F;AI, and every attempt from both side to enter the other&#x27;s niche has been pretty weak.<p>AMD compute is nowhere compared to NVIDIA. NVIDIA wanted to buy ARM, has got its finger in RISC-V, but apart from that, they don&#x27;t really care. To be fair AMD has done decent with GPUs, but never enough to dethrone NVIDIA, whose playbook for the past few gens is &quot;just make everything bigger than last gen and increase the frequency.&quot; Surely AMD could have chosen the same lazy approach to surpass the 4090 only just, but instead they didn&#x27;t, so it&#x27;s still NV undefeated in its space because AMD forgot to squeeze the last 1% out of their card.<p>The market is powerless if the competitors aren&#x27;t really competing. Intel is the only chance, unless they manage to get their own Taiwanese CEO somehow related to Huang and Su.</div><br/><div id="37244144" class="c"><input type="checkbox" id="c-37244144" checked=""/><div class="controls bullet"><span class="by">AlotOfReading</span><span>|</span><a href="#37241858">root</a><span>|</span><a href="#37243360">parent</a><span>|</span><a href="#37242716">next</a><span>|</span><label class="collapse" for="c-37244144">[-]</label><label class="expand" for="c-37244144">[1 more]</label></div><br/><div class="children"><div class="content">Leaving aside the weird conspiracy stuff, I don&#x27;t know how you can see stuff like the nvlink C2C that makes Grace Hopper possible and think they went &quot;just make everything bigger&quot;.</div><br/></div></div></div></div></div></div><div id="37242716" class="c"><input type="checkbox" id="c-37242716" checked=""/><div class="controls bullet"><span class="by">tzhenghao</span><span>|</span><a href="#37241858">parent</a><span>|</span><a href="#37242159">prev</a><span>|</span><a href="#37242941">next</a><span>|</span><label class="collapse" for="c-37242716">[-]</label><label class="expand" for="c-37242716">[1 more]</label></div><br/><div class="children"><div class="content">&gt; motivate everyone (Intel, AMD, ARM, Google, etc.) to try and tackle the problem by making new chips<p>Yes, there has been repeated efforts to chip at Nvidia&#x27;s market share, but there&#x27;s also a graveyard full of AI accelerator companies that fail to find product market fit due to lack of software toolchain support - and that applies even for older Nvidia GPUs and their compatible toolchains, let alone other players like AMD. This isn&#x27;t a hit on Nvidia, I&#x27;m just saying things move so quickly in the space that even the only-game-in-town is trying to catch up.<p>Nvidia is also leading by being one or two hardware cycles ahead of their competition. I&#x27;m pretty confident AI workloads in enterprise is their next major focus [1]. I think this more than anything else will accelerate AI adoption in enterprise if well executed.<p>To your point, I think the industry needs to focus more on the toolchains that sit right between the deep learning frameworks (PyTorch, Tensorflow etc.) and hardware vendors (Nvidia, AMD,  Intel, ARM, Google TPU etc.) Deep learning compilers will dictate if we allow all AI workloads run on just Nvidia or several other chips.<p>[1] - <a href="https:&#x2F;&#x2F;www.nvidia.com&#x2F;en-us&#x2F;data-center&#x2F;solutions&#x2F;confidential-computing" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.nvidia.com&#x2F;en-us&#x2F;data-center&#x2F;solutions&#x2F;confident...</a></div><br/></div></div><div id="37242941" class="c"><input type="checkbox" id="c-37242941" checked=""/><div class="controls bullet"><span class="by">tric</span><span>|</span><a href="#37241858">parent</a><span>|</span><a href="#37242716">prev</a><span>|</span><a href="#37241981">next</a><span>|</span><label class="collapse" for="c-37242941">[-]</label><label class="expand" for="c-37242941">[2 more]</label></div><br/><div class="children"><div class="content">&gt; I&#x27;m surprised there isn&#x27;t some way for gamers to rent out use of their GPU&#x27;s when idle.<p><a href="https:&#x2F;&#x2F;rendernetwork.com&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;rendernetwork.com&#x2F;</a><p>&quot;The Render Network® Provides Near Unlimited Decentralized GPU Computing Power For Next Generation 3D Content Creation.&quot;<p>&quot;Render Network&#x27;s system can be broken down into 2 main roles: Creators and Node Operators. Here&#x27;s a handy guide to figure out where you might fit in on the Render Network:<p>Maybe you&#x27;re a hardware enthusiast with GPUs to spare, or maybe you&#x27;re a cryptocurrency guru with a passing interest in VFX. If you&#x27;ve got GPUs that are sitting idle at any time, you&#x27;re a potential Node Operator who can use that GPU downtime to earn RNDR.&quot;</div><br/><div id="37243211" class="c"><input type="checkbox" id="c-37243211" checked=""/><div class="controls bullet"><span class="by">euazOn</span><span>|</span><a href="#37241858">root</a><span>|</span><a href="#37242941">parent</a><span>|</span><a href="#37241981">next</a><span>|</span><label class="collapse" for="c-37243211">[-]</label><label class="expand" for="c-37243211">[1 more]</label></div><br/><div class="children"><div class="content">Also the Horde for Stable Diffusion, pretty good concept: <a href="https:&#x2F;&#x2F;github.com&#x2F;Haidra-Org&#x2F;AI-Horde&#x2F;blob&#x2F;main&#x2F;FAQ.md">https:&#x2F;&#x2F;github.com&#x2F;Haidra-Org&#x2F;AI-Horde&#x2F;blob&#x2F;main&#x2F;FAQ.md</a></div><br/></div></div></div></div><div id="37241981" class="c"><input type="checkbox" id="c-37241981" checked=""/><div class="controls bullet"><span class="by">Conscat</span><span>|</span><a href="#37241858">parent</a><span>|</span><a href="#37242941">prev</a><span>|</span><a href="#37242660">next</a><span>|</span><label class="collapse" for="c-37241981">[-]</label><label class="expand" for="c-37241981">[1 more]</label></div><br/><div class="children"><div class="content">I am certain that several years ago, I was given an ad for exactly such a service and even tried it out, but I cannot for the life of me remember its name. It had some cute salad motif, and its users are named &quot;chefs&quot;.<p>EDIT: It was just named Salad.
<a href="https:&#x2F;&#x2F;salad.com&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;salad.com&#x2F;</a>
<a href="https:&#x2F;&#x2F;salad.com&#x2F;download" rel="nofollow noreferrer">https:&#x2F;&#x2F;salad.com&#x2F;download</a></div><br/></div></div><div id="37242660" class="c"><input type="checkbox" id="c-37242660" checked=""/><div class="controls bullet"><span class="by">NavinF</span><span>|</span><a href="#37241858">parent</a><span>|</span><a href="#37241981">prev</a><span>|</span><a href="#37242080">next</a><span>|</span><label class="collapse" for="c-37242660">[-]</label><label class="expand" for="c-37242660">[1 more]</label></div><br/><div class="children"><div class="content">You can do that for inference, but most gamers have a single GPU with &lt;24GB VRAM which kinda sucks for training. 3090 or 4090 is the minimum to use reasonable batch sizes</div><br/></div></div><div id="37242080" class="c"><input type="checkbox" id="c-37242080" checked=""/><div class="controls bullet"><span class="by">Goronmon</span><span>|</span><a href="#37241858">parent</a><span>|</span><a href="#37242660">prev</a><span>|</span><a href="#37244178">next</a><span>|</span><label class="collapse" for="c-37242080">[-]</label><label class="expand" for="c-37242080">[7 more]</label></div><br/><div class="children"><div class="content"><i>The good new is that Nvidia&#x27;s high GPU prices motivate everyone (Intel, AMD, ARM, Google, etc.) to try and tackle the problem by making new chips...</i><p>Or their dominance leads to competition throwing in the towel and investing resources in a market with less stiff competition.<p>I wouldn&#x27;t be surprised to see AMD start to pair back ivnestment on high-end GPUs if things continue down this path. I would say Intel likely keeps pushing, but I&#x27;m less convinced they can actually make much headway in the near future.</div><br/><div id="37242135" class="c"><input type="checkbox" id="c-37242135" checked=""/><div class="controls bullet"><span class="by">xnx</span><span>|</span><a href="#37241858">root</a><span>|</span><a href="#37242080">parent</a><span>|</span><a href="#37242847">next</a><span>|</span><label class="collapse" for="c-37242135">[-]</label><label class="expand" for="c-37242135">[5 more]</label></div><br/><div class="children"><div class="content">As was mentioned in another thread on a slightly different topic, it wouldn&#x27;t be surprising to see all non-Nvidia parties unit around some non-CUDA open standard.</div><br/><div id="37242207" class="c"><input type="checkbox" id="c-37242207" checked=""/><div class="controls bullet"><span class="by">josemanuel</span><span>|</span><a href="#37241858">root</a><span>|</span><a href="#37242135">parent</a><span>|</span><a href="#37242847">next</a><span>|</span><label class="collapse" for="c-37242207">[-]</label><label class="expand" for="c-37242207">[4 more]</label></div><br/><div class="children"><div class="content">Do you mean something like OpenCL?</div><br/><div id="37242470" class="c"><input type="checkbox" id="c-37242470" checked=""/><div class="controls bullet"><span class="by">xnx</span><span>|</span><a href="#37241858">root</a><span>|</span><a href="#37242207">parent</a><span>|</span><a href="#37242847">next</a><span>|</span><label class="collapse" for="c-37242470">[-]</label><label class="expand" for="c-37242470">[3 more]</label></div><br/><div class="children"><div class="content">Exactly. More resources might get applied to improving it.</div><br/><div id="37244064" class="c"><input type="checkbox" id="c-37244064" checked=""/><div class="controls bullet"><span class="by">josemanuel</span><span>|</span><a href="#37241858">root</a><span>|</span><a href="#37242470">parent</a><span>|</span><a href="#37242847">next</a><span>|</span><label class="collapse" for="c-37244064">[-]</label><label class="expand" for="c-37244064">[2 more]</label></div><br/><div class="children"><div class="content">I must admit my previous comment was mildly sarcastic.
What I was after is: OpenCL is that language&#x2F;framework that is consortium driven and open.
It’s been there since the start of time.
Still it cannot dethrone CUDA… 
Nvidia struck gold with CUDA and its lock-in</div><br/><div id="37244302" class="c"><input type="checkbox" id="c-37244302" checked=""/><div class="controls bullet"><span class="by">andromeduck</span><span>|</span><a href="#37241858">root</a><span>|</span><a href="#37244064">parent</a><span>|</span><a href="#37242847">next</a><span>|</span><label class="collapse" for="c-37244302">[-]</label><label class="expand" for="c-37244302">[1 more]</label></div><br/><div class="children"><div class="content">The main problem with OpenCL is most people eoue rather work with C++.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="37242847" class="c"><input type="checkbox" id="c-37242847" checked=""/><div class="controls bullet"><span class="by">haldujai</span><span>|</span><a href="#37241858">root</a><span>|</span><a href="#37242080">parent</a><span>|</span><a href="#37242135">prev</a><span>|</span><a href="#37244178">next</a><span>|</span><label class="collapse" for="c-37242847">[-]</label><label class="expand" for="c-37242847">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I would say Intel likely keeps pushing, but I&#x27;m less convinced they can actually make much headway in the near future.<p>It seems that Intel is making great headway on their fabs and may somehow pull off 5 nodes in 4 years. Intel 3 is entering high volume production soon and according to Gelsinger 20A is 6 months ahead of schedule and planned for H2 2024.<p>If they do pull this off and regain leadership that would change outlook.</div><br/></div></div></div></div><div id="37244178" class="c"><input type="checkbox" id="c-37244178" checked=""/><div class="controls bullet"><span class="by">ElectricalUnion</span><span>|</span><a href="#37241858">parent</a><span>|</span><a href="#37242080">prev</a><span>|</span><a href="#37245183">next</a><span>|</span><label class="collapse" for="c-37244178">[-]</label><label class="expand" for="c-37244178">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I&#x27;m surprised there isn&#x27;t some way for gamers to rent out use of their GPU&#x27;s when idle.<p>The main reason why you need massive ammounts of fast VRAM in the first place is that the main limitation of AI is memory bandwidth. Can&#x27;t simply distribute an algorithm that is already throughput limited by memory bandwidth and distribute it with awful latency and bandwidth and hope for any improvement.</div><br/></div></div><div id="37245183" class="c"><input type="checkbox" id="c-37245183" checked=""/><div class="controls bullet"><span class="by">EVa5I7bHFq9mnYK</span><span>|</span><a href="#37241858">parent</a><span>|</span><a href="#37244178">prev</a><span>|</span><a href="#37242027">next</a><span>|</span><label class="collapse" for="c-37245183">[-]</label><label class="expand" for="c-37245183">[2 more]</label></div><br/><div class="children"><div class="content">In bitcoin mining, GPU phase lasted only two years, before been outcompeted first by specialized FPGAs and then by ASICs. Nobody used GPUs for bitcoin mining since 2013. Maybe ML will follow similar path. But the computation is much different from ML, doesnt need memory at all.</div><br/><div id="37245641" class="c"><input type="checkbox" id="c-37245641" checked=""/><div class="controls bullet"><span class="by">PeterStuer</span><span>|</span><a href="#37241858">root</a><span>|</span><a href="#37245183">parent</a><span>|</span><a href="#37242027">next</a><span>|</span><label class="collapse" for="c-37245641">[-]</label><label class="expand" for="c-37245641">[1 more]</label></div><br/><div class="children"><div class="content">Aren&#x27;t tensorcores basically asics for ml?</div><br/></div></div></div></div><div id="37242027" class="c"><input type="checkbox" id="c-37242027" checked=""/><div class="controls bullet"><span class="by">WanderPanda</span><span>|</span><a href="#37241858">parent</a><span>|</span><a href="#37245183">prev</a><span>|</span><a href="#37242091">next</a><span>|</span><label class="collapse" for="c-37242027">[-]</label><label class="expand" for="c-37242027">[7 more]</label></div><br/><div class="children"><div class="content">With interconnect being the biggest limitation these days I don’t think this would work.</div><br/><div id="37242155" class="c"><input type="checkbox" id="c-37242155" checked=""/><div class="controls bullet"><span class="by">xnx</span><span>|</span><a href="#37241858">root</a><span>|</span><a href="#37242027">parent</a><span>|</span><a href="#37242091">next</a><span>|</span><label class="collapse" for="c-37242155">[-]</label><label class="expand" for="c-37242155">[6 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not familiar with all the varied uses of GPUs but it seems like image generation could feasibly be distributed: large upfront download of models, then small inputs of text and settings, and small output of resulting images.</div><br/><div id="37242319" class="c"><input type="checkbox" id="c-37242319" checked=""/><div class="controls bullet"><span class="by">WanderPanda</span><span>|</span><a href="#37241858">root</a><span>|</span><a href="#37242155">parent</a><span>|</span><a href="#37242091">next</a><span>|</span><label class="collapse" for="c-37242319">[-]</label><label class="expand" for="c-37242319">[5 more]</label></div><br/><div class="children"><div class="content">For inference I agree! But training requires centralized gradient steps</div><br/><div id="37242641" class="c"><input type="checkbox" id="c-37242641" checked=""/><div class="controls bullet"><span class="by">vajrabum</span><span>|</span><a href="#37241858">root</a><span>|</span><a href="#37242319">parent</a><span>|</span><a href="#37242091">next</a><span>|</span><label class="collapse" for="c-37242641">[-]</label><label class="expand" for="c-37242641">[4 more]</label></div><br/><div class="children"><div class="content">If you&#x27;re in a data center and running large training jobs then RDMA over Nvidia Mellanox Infiniband cards over high speed ethernet (like 100GB) are used to ship coefficients around without having that transfer bottleneck in the CPU.</div><br/><div id="37242793" class="c"><input type="checkbox" id="c-37242793" checked=""/><div class="controls bullet"><span class="by">xxpor</span><span>|</span><a href="#37241858">root</a><span>|</span><a href="#37242641">parent</a><span>|</span><a href="#37242091">next</a><span>|</span><label class="collapse" for="c-37242793">[-]</label><label class="expand" for="c-37242793">[3 more]</label></div><br/><div class="children"><div class="content">100 gig, that&#x27;s considered cute nowadays.<p><a href="https:&#x2F;&#x2F;aws.amazon.com&#x2F;blogs&#x2F;aws&#x2F;new-amazon-ec2-p5-instances-powered-by-nvidia-h100-tensor-core-gpus-for-accelerating-generative-ai-and-hpc-applications&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;aws.amazon.com&#x2F;blogs&#x2F;aws&#x2F;new-amazon-ec2-p5-instances...</a><p>3.2 terabits.</div><br/><div id="37243715" class="c"><input type="checkbox" id="c-37243715" checked=""/><div class="controls bullet"><span class="by">dekhn</span><span>|</span><a href="#37241858">root</a><span>|</span><a href="#37242793">parent</a><span>|</span><a href="#37242091">next</a><span>|</span><label class="collapse" for="c-37243715">[-]</label><label class="expand" for="c-37243715">[2 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think that machine has a single nic with that bandwidth- I&#x27;d guess it&#x27;s 8 400Gbps cards or something similar.</div><br/><div id="37244007" class="c"><input type="checkbox" id="c-37244007" checked=""/><div class="controls bullet"><span class="by">asciimike</span><span>|</span><a href="#37241858">root</a><span>|</span><a href="#37243715">parent</a><span>|</span><a href="#37242091">next</a><span>|</span><label class="collapse" for="c-37244007">[-]</label><label class="expand" for="c-37244007">[1 more]</label></div><br/><div class="children"><div class="content">Correct, it&#x27;s 8x 400G cards, one per GPU.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="37242091" class="c"><input type="checkbox" id="c-37242091" checked=""/><div class="controls bullet"><span class="by">myth_drannon</span><span>|</span><a href="#37241858">parent</a><span>|</span><a href="#37242027">prev</a><span>|</span><a href="#37243707">next</a><span>|</span><label class="collapse" for="c-37242091">[-]</label><label class="expand" for="c-37242091">[1 more]</label></div><br/><div class="children"><div class="content">vast.ai allows you to rent out gpu</div><br/></div></div><div id="37243707" class="c"><input type="checkbox" id="c-37243707" checked=""/><div class="controls bullet"><span class="by">peter303</span><span>|</span><a href="#37241858">parent</a><span>|</span><a href="#37242091">prev</a><span>|</span><a href="#37242420">next</a><span>|</span><label class="collapse" for="c-37243707">[-]</label><label class="expand" for="c-37243707">[1 more]</label></div><br/><div class="children"><div class="content">The larger language models now employ a trillion parameters. This is faster when memory and computing is tighter, not distributed. Cerebus&#x27;s million core super-wafer addresses this.</div><br/></div></div><div id="37242420" class="c"><input type="checkbox" id="c-37242420" checked=""/><div class="controls bullet"><span class="by">IshKebab</span><span>|</span><a href="#37241858">parent</a><span>|</span><a href="#37243707">prev</a><span>|</span><a href="#37241920">next</a><span>|</span><label class="collapse" for="c-37242420">[-]</label><label class="expand" for="c-37242420">[1 more]</label></div><br/><div class="children"><div class="content">There have been various attempts but you need a workload that&#x27;s basically public and also runs on a single GPU (because you don&#x27;t have NVLink or similar).</div><br/></div></div></div></div><div id="37241920" class="c"><input type="checkbox" id="c-37241920" checked=""/><div class="controls bullet"><span class="by">TechnicolorByte</span><span>|</span><a href="#37241858">prev</a><span>|</span><a href="#37241696">next</a><span>|</span><label class="collapse" for="c-37241920">[-]</label><label class="expand" for="c-37241920">[19 more]</label></div><br/><div class="children"><div class="content">Incredible company. It’s absolutely insane how far ahead they are with the investments they made over a decade ago.<p>So nice to see a “hard” engineering (from silicon to software) SV-founded company getting all this recognition. Especially after what has felt like a decade of SV hype software companies dominating the mainstream financial markets pre-pandemic with a spate of overpriced IPOs or large ad-revenue generating mega corporations.</div><br/><div id="37242285" class="c"><input type="checkbox" id="c-37242285" checked=""/><div class="controls bullet"><span class="by">kccqzy</span><span>|</span><a href="#37241920">parent</a><span>|</span><a href="#37242067">next</a><span>|</span><label class="collapse" for="c-37242285">[-]</label><label class="expand" for="c-37242285">[4 more]</label></div><br/><div class="children"><div class="content">The moniker of &quot;hard&quot; engineering is neither precise nor useful. What makes engineering hard? Is solving problems with distributed systems, even if these systems are for ads, hard? Or do you mean hardware? In that case even Nvidia is not hard enough since they don&#x27;t fabricate their own chips. Or do you mean designing hardware? Then what makes writing system verilog at a desk hard but writing Python not hard?</div><br/><div id="37246558" class="c"><input type="checkbox" id="c-37246558" checked=""/><div class="controls bullet"><span class="by">nsteel</span><span>|</span><a href="#37241920">root</a><span>|</span><a href="#37242285">parent</a><span>|</span><a href="#37242454">next</a><span>|</span><label class="collapse" for="c-37246558">[-]</label><label class="expand" for="c-37246558">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s hard to get complex systems correct. There&#x27;s far less margin for error when you get a hardware design wrong. Correcting a Python software mistake is orders of magnitude easier and cheaper to resolve, it doesn&#x27;t cost multiple billions and take 6 months to iterate. You might consider the hardware design harder in that respect.</div><br/></div></div><div id="37242454" class="c"><input type="checkbox" id="c-37242454" checked=""/><div class="controls bullet"><span class="by">TechnicolorByte</span><span>|</span><a href="#37241920">root</a><span>|</span><a href="#37242285">parent</a><span>|</span><a href="#37246558">prev</a><span>|</span><a href="#37242484">next</a><span>|</span><label class="collapse" for="c-37242454">[-]</label><label class="expand" for="c-37242454">[1 more]</label></div><br/><div class="children"><div class="content">I admit that was a glib comment and unnecessary.<p>I’m really speaking about Nvidia’s ability to perform well in both hardware and software, at chip-scale and datacenter-scale. Also speaking of their product&#x2F;business direction that revolutionizes multiple industries (leaders in graphics with ray tracing and AI frame&#x2F;resolution sacking; leaders in AI infra and datacenter systems, etc.) all resulting in big impacts to their respective industries.<p>You’re right that many of those software-only companies do very real engineering with distributed systems and such. I should’ve been more precise and was really complaining about the SV hype of the 2010s focusing on regulating-breaking companies like Airbnb, Uber, wework, etc. and on companies like Meta and Google who focus on pushing ads for their revenue.</div><br/></div></div><div id="37242484" class="c"><input type="checkbox" id="c-37242484" checked=""/><div class="controls bullet"><span class="by">omniglottal</span><span>|</span><a href="#37241920">root</a><span>|</span><a href="#37242285">parent</a><span>|</span><a href="#37242454">prev</a><span>|</span><a href="#37242067">next</a><span>|</span><label class="collapse" for="c-37242484">[-]</label><label class="expand" for="c-37242484">[1 more]</label></div><br/><div class="children"><div class="content">I suppose the difference is engineering something deterministic (i.e., physics, electronics, logic) versus something soft and indistinct (SEO, ad impressions, customer conversion rate).</div><br/></div></div></div></div><div id="37242067" class="c"><input type="checkbox" id="c-37242067" checked=""/><div class="controls bullet"><span class="by">epolanski</span><span>|</span><a href="#37241920">parent</a><span>|</span><a href="#37242285">prev</a><span>|</span><a href="#37243967">next</a><span>|</span><label class="collapse" for="c-37242067">[-]</label><label class="expand" for="c-37242067">[12 more]</label></div><br/><div class="children"><div class="content">Are they so far ahead?<p>AMD GPUs get comparable results as of late on Stable Diffusion.<p>Software and hardware from competitors will catch up, crunching 4&#x2F;8&#x2F;16 bit width numbers is no rocket science.</div><br/><div id="37242467" class="c"><input type="checkbox" id="c-37242467" checked=""/><div class="controls bullet"><span class="by">david-gpu</span><span>|</span><a href="#37241920">root</a><span>|</span><a href="#37242067">parent</a><span>|</span><a href="#37242161">next</a><span>|</span><label class="collapse" for="c-37242467">[-]</label><label class="expand" for="c-37242467">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Software and hardware from competitors will catch up, crunching 4&#x2F;8&#x2F;16 bit width numbers is no rocket science.<p>I used to think like that, until I got a job there and... Oh, boy! I left five years later still amazed at all the ever more mind bending ways you can multiply two damn matrices. It was the most tedious yet also most intellectually challenging work I&#x27;ve ever done. My coworkers there were also the brightest group of engineers I&#x27;ve ever met.</div><br/><div id="37246530" class="c"><input type="checkbox" id="c-37246530" checked=""/><div class="controls bullet"><span class="by">kortilla</span><span>|</span><a href="#37241920">root</a><span>|</span><a href="#37242467">parent</a><span>|</span><a href="#37242161">next</a><span>|</span><label class="collapse" for="c-37246530">[-]</label><label class="expand" for="c-37246530">[1 more]</label></div><br/><div class="children"><div class="content">&gt; was the most tedious yet also most intellectually challenging work I&#x27;ve ever done<p>What does this mean? Tedious is pretty much the opposite of “intellectually challenging” when I think of careers.</div><br/></div></div></div></div><div id="37242161" class="c"><input type="checkbox" id="c-37242161" checked=""/><div class="controls bullet"><span class="by">johnvanommen</span><span>|</span><a href="#37241920">root</a><span>|</span><a href="#37242067">parent</a><span>|</span><a href="#37242467">prev</a><span>|</span><a href="#37246296">next</a><span>|</span><label class="collapse" for="c-37242161">[-]</label><label class="expand" for="c-37242161">[6 more]</label></div><br/><div class="children"><div class="content">&gt; Software and hardware from competitors will catch up, crunching 4&#x2F;8&#x2F;16 bit width numbers is no rocket science.<p>I made the mistake of buying an A770 from Intel, based on the spec sheet. Hardware is comparable to what Nvidia is selling, for 70% of the price.<p>It&#x27;s basically a useless paperweight. The AI software crashes constantly, and when it&#x27;s not crashing, it performs at half the level of Nvidia&#x27;s cards.<p>Turns out that drivers and software compatibility are a big deal, and Intel is way way behind in that arena.</div><br/><div id="37244549" class="c"><input type="checkbox" id="c-37244549" checked=""/><div class="controls bullet"><span class="by">geodel</span><span>|</span><a href="#37241920">root</a><span>|</span><a href="#37242161">parent</a><span>|</span><a href="#37243184">next</a><span>|</span><label class="collapse" for="c-37244549">[-]</label><label class="expand" for="c-37244549">[2 more]</label></div><br/><div class="children"><div class="content">Its similar story with iPhone&#x2F; iOS vs Android. Endless talk about how Android is about to get so much better in performance compared to iPhone didn&#x27;t yield much. I guess lately people have accepted perf will never match up. At least Android massive market share in rest of the world so with perf&#x2F;pricing&#x2F;compatibily&#x2F; localization it will remain competitive in some sense.<p>I hope but do really foresee that AI&#x2F;ML systems will have similar competitive stack like Nvidia.</div><br/><div id="37245484" class="c"><input type="checkbox" id="c-37245484" checked=""/><div class="controls bullet"><span class="by">callalex</span><span>|</span><a href="#37241920">root</a><span>|</span><a href="#37244549">parent</a><span>|</span><a href="#37243184">next</a><span>|</span><label class="collapse" for="c-37245484">[-]</label><label class="expand" for="c-37245484">[1 more]</label></div><br/><div class="children"><div class="content">I haven’t crossed over to the other side in a while, what do you find lacking in Android performance? I was under the impression that these days it’s solidly in “good enough not to notice” territory.</div><br/></div></div></div></div><div id="37243184" class="c"><input type="checkbox" id="c-37243184" checked=""/><div class="controls bullet"><span class="by">epolanski</span><span>|</span><a href="#37241920">root</a><span>|</span><a href="#37242161">parent</a><span>|</span><a href="#37244549">prev</a><span>|</span><a href="#37245271">next</a><span>|</span><label class="collapse" for="c-37243184">[-]</label><label class="expand" for="c-37243184">[2 more]</label></div><br/><div class="children"><div class="content">Sure, but there&#x27;s lots of room for improvement and plenty of financial benefits to do so.</div><br/><div id="37244467" class="c"><input type="checkbox" id="c-37244467" checked=""/><div class="controls bullet"><span class="by">andromeduck</span><span>|</span><a href="#37241920">root</a><span>|</span><a href="#37243184">parent</a><span>|</span><a href="#37245271">next</a><span>|</span><label class="collapse" for="c-37244467">[-]</label><label class="expand" for="c-37244467">[1 more]</label></div><br/><div class="children"><div class="content">The problem is HW companies like Intel are dominated by EEs and bean counters. Both see software as cost center.</div><br/></div></div></div></div><div id="37245271" class="c"><input type="checkbox" id="c-37245271" checked=""/><div class="controls bullet"><span class="by">ant6n</span><span>|</span><a href="#37241920">root</a><span>|</span><a href="#37242161">parent</a><span>|</span><a href="#37243184">prev</a><span>|</span><a href="#37246296">next</a><span>|</span><label class="collapse" for="c-37245271">[-]</label><label class="expand" for="c-37245271">[1 more]</label></div><br/><div class="children"><div class="content">Has it been improving?</div><br/></div></div></div></div><div id="37246296" class="c"><input type="checkbox" id="c-37246296" checked=""/><div class="controls bullet"><span class="by">skocznymroczny</span><span>|</span><a href="#37241920">root</a><span>|</span><a href="#37242067">parent</a><span>|</span><a href="#37242161">prev</a><span>|</span><a href="#37242543">next</a><span>|</span><label class="collapse" for="c-37246296">[-]</label><label class="expand" for="c-37246296">[2 more]</label></div><br/><div class="children"><div class="content">Perhaps RDNA3 GPUs get comparable results, but RDNA2 GPUs are behind.<p>I bought a RX 6800XT to do some AI work because of the 16GB VRAM, and while the VRAM allows me to do stuff that my 6GB RTX 2060 wasn&#x27;t able to, on performance side it&#x27;s actually a downgrade in many aspects.<p>But the main issue is software support. To get acceptable performance you need to use ROCm, which is Linux only. There was some Windows release of ROCm few weeks ago, but I am not sure how usable it is and none of the libraries have picked up on it yet.<p>Even with a Linux installed, most frameworks still assume CUDA and it&#x27;s an effort to get them to use ROCm. For some tools all it takes is uninstalling PyTorch or Tensorflow and installing a special ROCm enabled version of those libraries. Sometimes it will be enough, sometimes it wasn&#x27;t. Sometimes the project uses some auxiliary library like bitsandbytes which doesn&#x27;t have an official ROCm fork, so you have to use unofficial ones (that you have to compile manually and Makefiles quickly get out of date). Which once again, may work or may not.<p>I have things set up for stable diffusion and text generation (oobabooga), and things mostly work, but sometimes they still don&#x27;t. For example I can train stable diffusion embeddings and dreambooth checkpoints, but for some reason it crashes when I attempt to train a LORA. And I don&#x27;t have enough expertise to debug it myself.<p>For things like video encoding most tools also assume CUDA will be present so you&#x27;re stuck with CPU encoding which takes forever. If you&#x27;re lucky, some tools may have a DirectML backend, which kinda works under Windows for AMD, but it&#x27;s performance is usually far behind a ROCm implementation.</div><br/><div id="37246380" class="c"><input type="checkbox" id="c-37246380" checked=""/><div class="controls bullet"><span class="by">paulmd</span><span>|</span><a href="#37241920">root</a><span>|</span><a href="#37246296">parent</a><span>|</span><a href="#37242543">next</a><span>|</span><label class="collapse" for="c-37246380">[-]</label><label class="expand" for="c-37246380">[1 more]</label></div><br/><div class="children"><div class="content">Video encoding doesn’t use CUDA but rather NVENC.<p>However AMD is still as terrible at H264 as ever, and their AV1 encoder also has a hardware defect they’ve patched by forcing it to round up to 16 line multiples, so it is incapable of encoding a 1080p video and instead outputs 1082p that won’t be ingested properly when streaming.<p><a href="http:&#x2F;&#x2F;freedesktop.org&#x2F;mesa&#x2F;mesa&#x2F;-&#x2F;issues&#x2F;9185#note_1954937" rel="nofollow noreferrer">http:&#x2F;&#x2F;freedesktop.org&#x2F;mesa&#x2F;mesa&#x2F;-&#x2F;issues&#x2F;9185#note_1954937</a></div><br/></div></div></div></div><div id="37242543" class="c"><input type="checkbox" id="c-37242543" checked=""/><div class="controls bullet"><span class="by">smoldesu</span><span>|</span><a href="#37241920">root</a><span>|</span><a href="#37242067">parent</a><span>|</span><a href="#37246296">prev</a><span>|</span><a href="#37243967">next</a><span>|</span><label class="collapse" for="c-37242543">[-]</label><label class="expand" for="c-37242543">[1 more]</label></div><br/><div class="children"><div class="content">Nvidia has a small lead on the industry in a few places, adding up to <i>super</i> attractive backend hardware options. They aren&#x27;t invincible, but they profit off the hostility between their competitors. Until those companies gang up to fund an open alternative, it&#x27;s open season for Nvidia and HPC customers.<p>The recent Stable Diffusion results are great news, but also don&#x27;t include comparisons to an Nvidia card using the same optimizations. Nvidia claims that Microsoft Olive doubles performance on their cards too, so it might be a bit of a wash: <a href="https:&#x2F;&#x2F;blogs.nvidia.com&#x2F;blog&#x2F;2023&#x2F;05&#x2F;23&#x2F;microsoft-build-nvidia-ai-windows-rtx&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;blogs.nvidia.com&#x2F;blog&#x2F;2023&#x2F;05&#x2F;23&#x2F;microsoft-build-nvi...</a><p>Plus, none of those optimizations were any more open than CUDA (since it used DirectML).<p>&gt; crunching 4&#x2F;8&#x2F;16 bit width numbers is no rocket science.<p>Of course not. That&#x27;s why everyone did it: <a href="https:&#x2F;&#x2F;onnxruntime.ai&#x2F;docs&#x2F;execution-providers" rel="nofollow noreferrer">https:&#x2F;&#x2F;onnxruntime.ai&#x2F;docs&#x2F;execution-providers</a><p>The problem with that &quot;15 competing standards&quot; XKCD is that normally one big proprietary standard wins. Nvidia has the history, the stability, the multi-OS and multi-arch support. The industry can definitely overturn it, but they have to work together to obsolete it.</div><br/></div></div></div></div><div id="37243967" class="c"><input type="checkbox" id="c-37243967" checked=""/><div class="controls bullet"><span class="by">systemvoltage</span><span>|</span><a href="#37241920">parent</a><span>|</span><a href="#37242067">prev</a><span>|</span><a href="#37243068">next</a><span>|</span><label class="collapse" for="c-37243967">[-]</label><label class="expand" for="c-37243967">[1 more]</label></div><br/><div class="children"><div class="content">Yeah. NVidia was a docile looking company and in 2012, they were merely a gaming oriented hardware shop.<p>These companies exist today. Which small or ignored companies do you think have a bright future?</div><br/></div></div><div id="37243068" class="c"><input type="checkbox" id="c-37243068" checked=""/><div class="controls bullet"><span class="by">xwdv</span><span>|</span><a href="#37241920">parent</a><span>|</span><a href="#37243967">prev</a><span>|</span><a href="#37241696">next</a><span>|</span><label class="collapse" for="c-37243068">[-]</label><label class="expand" for="c-37243068">[1 more]</label></div><br/><div class="children"><div class="content">Hard times make hard companies. Hard companies make good times. Good times make soft companies. Soft companies make hard times.</div><br/></div></div></div></div><div id="37241696" class="c"><input type="checkbox" id="c-37241696" checked=""/><div class="controls bullet"><span class="by">mikestew</span><span>|</span><a href="#37241920">prev</a><span>|</span><a href="#37244403">next</a><span>|</span><label class="collapse" for="c-37241696">[-]</label><label class="expand" for="c-37241696">[27 more]</label></div><br/><div class="children"><div class="content">Whelp, I guess those September NVDA call options I sold are going to get exercised. Who woulda guessed after the crypto fallout that &quot;AI&quot; would come along and bump the price back up.<p>Record revenues, and a dividend of $0.04 on a $450 stock? That&#x27;s not even worth the paperwork. For example, if you bought 100 shares, that&#x27;s $45K. From that, around September $4 will show up in your account, which you have to pay taxes on. So $3 or so net on a $45,000 investment. Sure, there were stock buybacks, but why keep the token dividend around?</div><br/><div id="37243285" class="c"><input type="checkbox" id="c-37243285" checked=""/><div class="controls bullet"><span class="by">oatmeal1</span><span>|</span><a href="#37241696">parent</a><span>|</span><a href="#37242854">next</a><span>|</span><label class="collapse" for="c-37243285">[-]</label><label class="expand" for="c-37243285">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s probably good for the long term share price if they can say in 20 years they&#x27;ve had a dividend for 20 years, even if that dividend was actually measly.</div><br/></div></div><div id="37242854" class="c"><input type="checkbox" id="c-37242854" checked=""/><div class="controls bullet"><span class="by">_zoltan_</span><span>|</span><a href="#37241696">parent</a><span>|</span><a href="#37243285">prev</a><span>|</span><a href="#37241953">next</a><span>|</span><label class="collapse" for="c-37242854">[-]</label><label class="expand" for="c-37242854">[8 more]</label></div><br/><div class="children"><div class="content">I sold 600C for this Friday an hour or so before earnings. Free money with 168% IV.</div><br/><div id="37246300" class="c"><input type="checkbox" id="c-37246300" checked=""/><div class="controls bullet"><span class="by">theogravity</span><span>|</span><a href="#37241696">root</a><span>|</span><a href="#37242854">parent</a><span>|</span><a href="#37243370">next</a><span>|</span><label class="collapse" for="c-37246300">[-]</label><label class="expand" for="c-37246300">[1 more]</label></div><br/><div class="children"><div class="content">I sold the Fri 560C as a covered call. The high IV was free money for little risk.</div><br/></div></div><div id="37243370" class="c"><input type="checkbox" id="c-37243370" checked=""/><div class="controls bullet"><span class="by">euazOn</span><span>|</span><a href="#37241696">root</a><span>|</span><a href="#37242854">parent</a><span>|</span><a href="#37246300">prev</a><span>|</span><a href="#37244426">next</a><span>|</span><label class="collapse" for="c-37243370">[-]</label><label class="expand" for="c-37243370">[1 more]</label></div><br/><div class="children"><div class="content">It is free money, until it isn’t!</div><br/></div></div><div id="37244426" class="c"><input type="checkbox" id="c-37244426" checked=""/><div class="controls bullet"><span class="by">shpongled</span><span>|</span><a href="#37241696">root</a><span>|</span><a href="#37242854">parent</a><span>|</span><a href="#37243370">prev</a><span>|</span><a href="#37244948">next</a><span>|</span><label class="collapse" for="c-37244426">[-]</label><label class="expand" for="c-37244426">[1 more]</label></div><br/><div class="children"><div class="content">I sold the 590 :)</div><br/></div></div><div id="37244948" class="c"><input type="checkbox" id="c-37244948" checked=""/><div class="controls bullet"><span class="by">yieldcrv</span><span>|</span><a href="#37241696">root</a><span>|</span><a href="#37242854">parent</a><span>|</span><a href="#37244426">prev</a><span>|</span><a href="#37241953">next</a><span>|</span><label class="collapse" for="c-37244948">[-]</label><label class="expand" for="c-37244948">[4 more]</label></div><br/><div class="children"><div class="content">collecting pennies in front of a steamroller</div><br/><div id="37245552" class="c"><input type="checkbox" id="c-37245552" checked=""/><div class="controls bullet"><span class="by">quickthrower2</span><span>|</span><a href="#37241696">root</a><span>|</span><a href="#37244948">parent</a><span>|</span><a href="#37245615">next</a><span>|</span><label class="collapse" for="c-37245552">[-]</label><label class="expand" for="c-37245552">[2 more]</label></div><br/><div class="children"><div class="content">Especially in a post-gamestonk world</div><br/><div id="37245621" class="c"><input type="checkbox" id="c-37245621" checked=""/><div class="controls bullet"><span class="by">_zoltan_</span><span>|</span><a href="#37241696">root</a><span>|</span><a href="#37245552">parent</a><span>|</span><a href="#37245615">next</a><span>|</span><label class="collapse" for="c-37245621">[-]</label><label class="expand" for="c-37245621">[1 more]</label></div><br/><div class="children"><div class="content">very different dynamics.<p>- a GME ape :)</div><br/></div></div></div></div><div id="37245615" class="c"><input type="checkbox" id="c-37245615" checked=""/><div class="controls bullet"><span class="by">_zoltan_</span><span>|</span><a href="#37241696">root</a><span>|</span><a href="#37244948">parent</a><span>|</span><a href="#37245552">prev</a><span>|</span><a href="#37241953">next</a><span>|</span><label class="collapse" for="c-37245615">[-]</label><label class="expand" for="c-37245615">[1 more]</label></div><br/><div class="children"><div class="content">risk&#x2F;reward.</div><br/></div></div></div></div></div></div><div id="37241953" class="c"><input type="checkbox" id="c-37241953" checked=""/><div class="controls bullet"><span class="by">thomas8787</span><span>|</span><a href="#37241696">parent</a><span>|</span><a href="#37242854">prev</a><span>|</span><a href="#37244232">next</a><span>|</span><label class="collapse" for="c-37241953">[-]</label><label class="expand" for="c-37241953">[5 more]</label></div><br/><div class="children"><div class="content">Jensen is one of the largest shareholders. With over 80 million shares that&#x27;s an over 3 million dollar dividend for him.</div><br/><div id="37242053" class="c"><input type="checkbox" id="c-37242053" checked=""/><div class="controls bullet"><span class="by">epolanski</span><span>|</span><a href="#37241696">root</a><span>|</span><a href="#37241953">parent</a><span>|</span><a href="#37244232">next</a><span>|</span><label class="collapse" for="c-37242053">[-]</label><label class="expand" for="c-37242053">[4 more]</label></div><br/><div class="children"><div class="content">Wait 80M shares? He&#x27;s worth 4B $ then. Not bad.</div><br/><div id="37242357" class="c"><input type="checkbox" id="c-37242357" checked=""/><div class="controls bullet"><span class="by">pyrrhotech</span><span>|</span><a href="#37241696">root</a><span>|</span><a href="#37242053">parent</a><span>|</span><a href="#37242761">next</a><span>|</span><label class="collapse" for="c-37242357">[-]</label><label class="expand" for="c-37242357">[2 more]</label></div><br/><div class="children"><div class="content">He&#x27;s worth way more than that. <a href="https:&#x2F;&#x2F;www.bloomberg.com&#x2F;billionaires&#x2F;profiles&#x2F;jenhsun-huang&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.bloomberg.com&#x2F;billionaires&#x2F;profiles&#x2F;jenhsun-huan...</a></div><br/><div id="37243194" class="c"><input type="checkbox" id="c-37243194" checked=""/><div class="controls bullet"><span class="by">epolanski</span><span>|</span><a href="#37241696">root</a><span>|</span><a href="#37242357">parent</a><span>|</span><a href="#37242761">next</a><span>|</span><label class="collapse" for="c-37243194">[-]</label><label class="expand" for="c-37243194">[1 more]</label></div><br/><div class="children"><div class="content">This website is completely unusable on mobile.</div><br/></div></div></div></div><div id="37242761" class="c"><input type="checkbox" id="c-37242761" checked=""/><div class="controls bullet"><span class="by">tyre</span><span>|</span><a href="#37241696">root</a><span>|</span><a href="#37242053">parent</a><span>|</span><a href="#37242357">prev</a><span>|</span><a href="#37244232">next</a><span>|</span><label class="collapse" for="c-37242761">[-]</label><label class="expand" for="c-37242761">[1 more]</label></div><br/><div class="children"><div class="content">just wait until it’s $4bn and another $3m!</div><br/></div></div></div></div></div></div><div id="37244232" class="c"><input type="checkbox" id="c-37244232" checked=""/><div class="controls bullet"><span class="by">AnotherGoodName</span><span>|</span><a href="#37241696">parent</a><span>|</span><a href="#37241953">prev</a><span>|</span><a href="#37241904">next</a><span>|</span><label class="collapse" for="c-37244232">[-]</label><label class="expand" for="c-37244232">[2 more]</label></div><br/><div class="children"><div class="content">There&#x27;s a $25billion buyback this coming quarter. That&#x27;s how they distribute profits these days.</div><br/><div id="37244660" class="c"><input type="checkbox" id="c-37244660" checked=""/><div class="controls bullet"><span class="by">elbasti</span><span>|</span><a href="#37241696">root</a><span>|</span><a href="#37244232">parent</a><span>|</span><a href="#37241904">next</a><span>|</span><label class="collapse" for="c-37244660">[-]</label><label class="expand" for="c-37244660">[1 more]</label></div><br/><div class="children"><div class="content">A stock buyback trades certainty of wealth transfer (you&#x27;re not <i>sure</i> the price will go up, or by how much!) for flexibility in when the investor takes the gains for purposes of fiscal planning.</div><br/></div></div></div></div><div id="37241904" class="c"><input type="checkbox" id="c-37241904" checked=""/><div class="controls bullet"><span class="by">kinghajj</span><span>|</span><a href="#37241696">parent</a><span>|</span><a href="#37244232">prev</a><span>|</span><a href="#37244403">next</a><span>|</span><label class="collapse" for="c-37241904">[-]</label><label class="expand" for="c-37241904">[10 more]</label></div><br/><div class="children"><div class="content">Should have sold a call credit spread instead!<p>For large shareholders, the dividend would still be worthwhile. From what I could find, Jensen has 1.3 million shares, so he&#x27;d receive over $200k in dividends this year. You might think that&#x27;s chump change, but another source lists his salary at just under $1m; another 20% bump in liquid income is nothing to sneeze at.</div><br/><div id="37242062" class="c"><input type="checkbox" id="c-37242062" checked=""/><div class="controls bullet"><span class="by">haldujai</span><span>|</span><a href="#37241696">root</a><span>|</span><a href="#37241904">parent</a><span>|</span><a href="#37242113">next</a><span>|</span><label class="collapse" for="c-37242062">[-]</label><label class="expand" for="c-37242062">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Should have sold a call credit spread instead!<p>Why?<p>&gt; From what I could find, Jensen has 1.3 million shares, so he&#x27;d receive over $200k in dividends this year. You might think that&#x27;s chump change, but another source lists his salary at just under $1m; another 20% bump in liquid income is nothing to sneeze at.<p>Jensen Huang is worth $42 billion and has been a billionaire for probably a decade or so now? Any CEO with that net worth would use stock-secured loans&#x2F;LOCs for liquidity. 200k is very much chump change.</div><br/></div></div><div id="37242113" class="c"><input type="checkbox" id="c-37242113" checked=""/><div class="controls bullet"><span class="by">mikestew</span><span>|</span><a href="#37241696">root</a><span>|</span><a href="#37241904">parent</a><span>|</span><a href="#37242062">prev</a><span>|</span><a href="#37242001">next</a><span>|</span><label class="collapse" for="c-37242113">[-]</label><label class="expand" for="c-37242113">[4 more]</label></div><br/><div class="children"><div class="content"><i>Should have sold a call credit spread instead!</i><p>I&#x27;ll get right on that...after I go look up what that means. :-) I&#x27;m but a simple options trader who sells calls to unload stock I didn&#x27;t want anymore anyway, and the premium is the icing on that cake. Left some money on the table this time, but I otherwise would have just sold the shares outright, and I did make some bank regardless.<p>Gonna be missing that sweet, sweet $0.04 dividend, though.</div><br/><div id="37242178" class="c"><input type="checkbox" id="c-37242178" checked=""/><div class="controls bullet"><span class="by">kinghajj</span><span>|</span><a href="#37241696">root</a><span>|</span><a href="#37242113">parent</a><span>|</span><a href="#37242440">next</a><span>|</span><label class="collapse" for="c-37242178">[-]</label><label class="expand" for="c-37242178">[2 more]</label></div><br/><div class="children"><div class="content">A call credit spread simply means buying an even more out-of-the-money call along with the one you sold. It would have reduced the premium collected, but the long call would appreciate on sudden moves like today&#x27;s.</div><br/><div id="37244061" class="c"><input type="checkbox" id="c-37244061" checked=""/><div class="controls bullet"><span class="by">mikestew</span><span>|</span><a href="#37241696">root</a><span>|</span><a href="#37242178">parent</a><span>|</span><a href="#37242440">next</a><span>|</span><label class="collapse" for="c-37244061">[-]</label><label class="expand" for="c-37244061">[1 more]</label></div><br/><div class="children"><div class="content">Hmm…that actually sounds like a nice hedge. I’ll keep that in mind next time a similar situation comes up. Thanks.</div><br/></div></div></div></div><div id="37242440" class="c"><input type="checkbox" id="c-37242440" checked=""/><div class="controls bullet"><span class="by">kikokikokiko</span><span>|</span><a href="#37241696">root</a><span>|</span><a href="#37242113">parent</a><span>|</span><a href="#37242178">prev</a><span>|</span><a href="#37242001">next</a><span>|</span><label class="collapse" for="c-37242440">[-]</label><label class="expand" for="c-37242440">[1 more]</label></div><br/><div class="children"><div class="content">Theta gang ftw. But I would advise you to stay away from NVDA, as soon as the first quarter with flat or decreasing revenues comes (and it WILL come), the fall would be one to tell your grandchildren about.</div><br/></div></div></div></div><div id="37242001" class="c"><input type="checkbox" id="c-37242001" checked=""/><div class="controls bullet"><span class="by">Vvector</span><span>|</span><a href="#37241696">root</a><span>|</span><a href="#37241904">parent</a><span>|</span><a href="#37242113">prev</a><span>|</span><a href="#37241938">next</a><span>|</span><label class="collapse" for="c-37242001">[-]</label><label class="expand" for="c-37242001">[2 more]</label></div><br/><div class="children"><div class="content">The stock is up 9% or $45&#x2F;share after hours.  Jensen just made $58 million.  $200k doesn&#x27;t pay his dry cleaning bill.</div><br/><div id="37243237" class="c"><input type="checkbox" id="c-37243237" checked=""/><div class="controls bullet"><span class="by">wincy</span><span>|</span><a href="#37241696">root</a><span>|</span><a href="#37242001">parent</a><span>|</span><a href="#37241938">next</a><span>|</span><label class="collapse" for="c-37243237">[-]</label><label class="expand" for="c-37243237">[1 more]</label></div><br/><div class="children"><div class="content">Getting all those leather jackets cleaned is expensive!</div><br/></div></div></div></div><div id="37241938" class="c"><input type="checkbox" id="c-37241938" checked=""/><div class="controls bullet"><span class="by">loeg</span><span>|</span><a href="#37241696">root</a><span>|</span><a href="#37241904">parent</a><span>|</span><a href="#37242001">prev</a><span>|</span><a href="#37241985">next</a><span>|</span><label class="collapse" for="c-37241938">[-]</label><label class="expand" for="c-37241938">[1 more]</label></div><br/><div class="children"><div class="content">This benefit is basically only to large shareholders who can&#x27;t sell stock.  Which might be insiders like Jensen and... anyone else?  Everyone else can just sell, like, 0.0001% of their stock or whatever.</div><br/></div></div><div id="37241985" class="c"><input type="checkbox" id="c-37241985" checked=""/><div class="controls bullet"><span class="by">catchnear4321</span><span>|</span><a href="#37241696">root</a><span>|</span><a href="#37241904">parent</a><span>|</span><a href="#37241938">prev</a><span>|</span><a href="#37244403">next</a><span>|</span><label class="collapse" for="c-37241985">[-]</label><label class="expand" for="c-37241985">[1 more]</label></div><br/><div class="children"><div class="content">many times what a lot of people make in a year is nothing to sneeze at.<p>especially when it is awarded for merely having a stack of papers.</div><br/></div></div></div></div></div></div><div id="37244403" class="c"><input type="checkbox" id="c-37244403" checked=""/><div class="controls bullet"><span class="by">gen220</span><span>|</span><a href="#37241696">prev</a><span>|</span><a href="#37241699">next</a><span>|</span><label class="collapse" for="c-37244403">[-]</label><label class="expand" for="c-37244403">[4 more]</label></div><br/><div class="children"><div class="content">How durable do we think their Revenue is?<p>To remind us all, they&#x27;re selling capitalized assets, not contracts or services.<p>Is the marginal demand for GPU chips over the next 3 years enough to sustain (or grow?) current revenues and keep this valuation afloat? To me, it feels like a comparatively fragile situation to find themselves in, to convince the world of 2025 that they need <i>even more chips</i>, unless &quot;everybody needs to train their own LLM&quot; is a secular trend.<p>I&#x27;m not sure if investors fully appreciate the nuances of this boom, or if I&#x27;m not fully appreciating how many GPUs &quot;need&quot; to be held by different companies (and sovereign entities, if you&#x27;ve read the headlines in the last couple weeks) to train LLMs in the coming decade.</div><br/><div id="37244629" class="c"><input type="checkbox" id="c-37244629" checked=""/><div class="controls bullet"><span class="by">gmm1990</span><span>|</span><a href="#37244403">parent</a><span>|</span><a href="#37245888">prev</a><span>|</span><a href="#37241699">next</a><span>|</span><label class="collapse" for="c-37244629">[-]</label><label class="expand" for="c-37244629">[2 more]</label></div><br/><div class="children"><div class="content">It seems pretty similar to Tesla’s valuation with a product that won’t be as sticky as electric cars</div><br/><div id="37246133" class="c"><input type="checkbox" id="c-37246133" checked=""/><div class="controls bullet"><span class="by">redox99</span><span>|</span><a href="#37244403">root</a><span>|</span><a href="#37244629">parent</a><span>|</span><a href="#37241699">next</a><span>|</span><label class="collapse" for="c-37246133">[-]</label><label class="expand" for="c-37246133">[1 more]</label></div><br/><div class="children"><div class="content">They are not similar at all. Tesla P&#x2F;E is 67, Nvidia&#x27;s P&#x2F;E is 244.</div><br/></div></div></div></div></div></div><div id="37241699" class="c"><input type="checkbox" id="c-37241699" checked=""/><div class="controls bullet"><span class="by">HDThoreaun</span><span>|</span><a href="#37244403">prev</a><span>|</span><a href="#37241694">next</a><span>|</span><label class="collapse" for="c-37241699">[-]</label><label class="expand" for="c-37241699">[32 more]</label></div><br/><div class="children"><div class="content">Up more than 10% after hours compared to close yesterday. I really thought NVDA had hit its ceiling at $1+ trillion, apparently not. Really does feel like a huge opportunity for Intel to me. They have the fab capacity to pump out at least reasonably competitive GPUs if they can figure out the software side of things.<p>P&#x2F;E still above 50 even after the AI craze 9x&#x27;d eps this quarter. Still hard for me to see that valuation ever makes sense but what do i know.</div><br/><div id="37241734" class="c"><input type="checkbox" id="c-37241734" checked=""/><div class="controls bullet"><span class="by">UncleOxidant</span><span>|</span><a href="#37241699">parent</a><span>|</span><a href="#37243867">next</a><span>|</span><label class="collapse" for="c-37241734">[-]</label><label class="expand" for="c-37241734">[29 more]</label></div><br/><div class="children"><div class="content">Intel doesn&#x27;t seem to be able to execute. It&#x27;s not just pumping out GPUs - for AI you need drivers, and the equivilent of CUDA and all the various libraries built on CUDA like cuDNN. They do have OneAPI but it hasn&#x27;t caught on like CUDA in that space. It&#x27;s kind of too bad since OneAPI is open and CUDA is not.</div><br/><div id="37241756" class="c"><input type="checkbox" id="c-37241756" checked=""/><div class="controls bullet"><span class="by">HDThoreaun</span><span>|</span><a href="#37241699">root</a><span>|</span><a href="#37241734">parent</a><span>|</span><a href="#37242145">next</a><span>|</span><label class="collapse" for="c-37241756">[-]</label><label class="expand" for="c-37241756">[19 more]</label></div><br/><div class="children"><div class="content">Right but the market is saying that a dominant GPU business is worth more than a trillion dollars. Just hard for me to believe that they can&#x27;t get the business off the ground with that kind money on the table. Can&#x27;t they just hire all of nvidia&#x27;s developers and pay them 5x as much?</div><br/><div id="37241925" class="c"><input type="checkbox" id="c-37241925" checked=""/><div class="controls bullet"><span class="by">nemothekid</span><span>|</span><a href="#37241699">root</a><span>|</span><a href="#37241756">parent</a><span>|</span><a href="#37241892">next</a><span>|</span><label class="collapse" for="c-37241925">[-]</label><label class="expand" for="c-37241925">[4 more]</label></div><br/><div class="children"><div class="content">&gt;<i>Can&#x27;t they just hire all of nvidia&#x27;s developers and pay them 5x as much?</i><p>As time goes on I don’t see how you break the CUDA moat even if you had all of nvidia Al’s engineers.<p>CUDA means you need everyone in AI to target your new (hopefully open) platform and that platform is faster than CUDA is. Given how most frameworks of the last 10 years have been optimized for CUDA you would need to turn around a global sized cruise ship.<p>If Intel’s GPUs are only 3% faster, will that be enough to rewrite my entire software stack for something not CUDA? If intel opts for a translation layer, could they ever match nvidia’s performance?</div><br/><div id="37242008" class="c"><input type="checkbox" id="c-37242008" checked=""/><div class="controls bullet"><span class="by">HDThoreaun</span><span>|</span><a href="#37241699">root</a><span>|</span><a href="#37241925">parent</a><span>|</span><a href="#37241892">next</a><span>|</span><label class="collapse" for="c-37242008">[-]</label><label class="expand" for="c-37242008">[3 more]</label></div><br/><div class="children"><div class="content">Well I&#x27;m not super experienced with GPU development but aren&#x27;t most people using packages built on top of CUDA like pytroch etc? Would it be impossible to throw tons of resources at those packages so they handle whatever intel comes up with as well as they handle CUDA?<p>If Intel is 10% slower but 50% cheaper and the open source stack you use has been heavily updated to work well with Intel drivers would that not be an enticing product?</div><br/><div id="37242571" class="c"><input type="checkbox" id="c-37242571" checked=""/><div class="controls bullet"><span class="by">michaelt</span><span>|</span><a href="#37241699">root</a><span>|</span><a href="#37242008">parent</a><span>|</span><a href="#37242041">next</a><span>|</span><label class="collapse" for="c-37242571">[-]</label><label class="expand" for="c-37242571">[1 more]</label></div><br/><div class="children"><div class="content"><i>&gt; aren&#x27;t most people using packages built on top of CUDA like pytorch etc?</i><p>Yes, and in fact both AMD and Intel have libraries. You can run Stable Diffusion and suchlike on AMD GPUs today, apparently. And you can export models from most ML frameworks to run in the browser, on phones and suchlike.<p><i>&gt; If Intel is 10% slower but 50% cheaper [...] would that not be an enticing product?</i><p>Sometimes, yes. Some of the largest models apparently cost $600,000 in compute time to train [1], so halving that would be pretty appealing.<p>However, part of the reason for nvidia&#x27;s dominance is that if you&#x27;re hiring an ML engineer for $160,000&#x2F;year spending $1,600 to give them an RTX 4090 is chump change.<p>[1] <a href="https:&#x2F;&#x2F;twitter.com&#x2F;emostaque&#x2F;status&#x2F;1563870674111832066" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;emostaque&#x2F;status&#x2F;1563870674111832066</a></div><br/></div></div><div id="37242041" class="c"><input type="checkbox" id="c-37242041" checked=""/><div class="controls bullet"><span class="by">UncleOxidant</span><span>|</span><a href="#37241699">root</a><span>|</span><a href="#37242008">parent</a><span>|</span><a href="#37242571">prev</a><span>|</span><a href="#37241892">next</a><span>|</span><label class="collapse" for="c-37242041">[-]</label><label class="expand" for="c-37242041">[1 more]</label></div><br/><div class="children"><div class="content">Intel&#x27;s been trying this for several years now (OneAPI and OpenVINO), but so far they haven&#x27;t gotten the traction. CUDA is just really entrenched at this point.</div><br/></div></div></div></div></div></div><div id="37241892" class="c"><input type="checkbox" id="c-37241892" checked=""/><div class="controls bullet"><span class="by">UncleOxidant</span><span>|</span><a href="#37241699">root</a><span>|</span><a href="#37241756">parent</a><span>|</span><a href="#37241925">prev</a><span>|</span><a href="#37241822">next</a><span>|</span><label class="collapse" for="c-37241892">[-]</label><label class="expand" for="c-37241892">[6 more]</label></div><br/><div class="children"><div class="content">&gt;  Can&#x27;t they just hire all of nvidia&#x27;s developers and pay them 5x as much?<p>Lol... Intel is famously stingy when it comes to salaries.</div><br/><div id="37242938" class="c"><input type="checkbox" id="c-37242938" checked=""/><div class="controls bullet"><span class="by">i_have_an_idea</span><span>|</span><a href="#37241699">root</a><span>|</span><a href="#37241892">parent</a><span>|</span><a href="#37241916">next</a><span>|</span><label class="collapse" for="c-37242938">[-]</label><label class="expand" for="c-37242938">[2 more]</label></div><br/><div class="children"><div class="content">You have no idea. There are a lot of senior engineers at NVDA making 7 figures total comp annually. How many are there at Intel?</div><br/><div id="37245976" class="c"><input type="checkbox" id="c-37245976" checked=""/><div class="controls bullet"><span class="by">paulmd</span><span>|</span><a href="#37241699">root</a><span>|</span><a href="#37242938">parent</a><span>|</span><a href="#37241916">next</a><span>|</span><label class="collapse" for="c-37245976">[-]</label><label class="expand" for="c-37245976">[1 more]</label></div><br/><div class="children"><div class="content">Intel has senior engineers who received two and three digit retention bonuses this year, on top of the 20% pay cut.<p>Principals usually broke into the three digit range from what I hear.</div><br/></div></div></div></div><div id="37241916" class="c"><input type="checkbox" id="c-37241916" checked=""/><div class="controls bullet"><span class="by">HDThoreaun</span><span>|</span><a href="#37241699">root</a><span>|</span><a href="#37241892">parent</a><span>|</span><a href="#37242938">prev</a><span>|</span><a href="#37241822">next</a><span>|</span><label class="collapse" for="c-37241916">[-]</label><label class="expand" for="c-37241916">[3 more]</label></div><br/><div class="children"><div class="content">for a trillion dollars though... eventually you have to believe Pat gets fired and replaced by someone who is 100% all in on GPUs if he can&#x27;t figure this out</div><br/><div id="37242017" class="c"><input type="checkbox" id="c-37242017" checked=""/><div class="controls bullet"><span class="by">UncleOxidant</span><span>|</span><a href="#37241699">root</a><span>|</span><a href="#37241916">parent</a><span>|</span><a href="#37242177">next</a><span>|</span><label class="collapse" for="c-37242017">[-]</label><label class="expand" for="c-37242017">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;d argue that Intel being stingy with salaries is a big part of why they&#x27;re so behind here. They just don&#x27;t seem to be very serious about this. Intel has made several runs at the GPU market over the years and they just keep ending up where they are. And now NVDA has such a huge advantage (software and hardware) that it just gets harder and harder (and more expensive) to overcome.<p>Probably Intel&#x27;s best bet now would be to try to be the fab for NVDA.</div><br/></div></div><div id="37242177" class="c"><input type="checkbox" id="c-37242177" checked=""/><div class="controls bullet"><span class="by">orzig</span><span>|</span><a href="#37241699">root</a><span>|</span><a href="#37241916">parent</a><span>|</span><a href="#37242017">prev</a><span>|</span><a href="#37241822">next</a><span>|</span><label class="collapse" for="c-37242177">[-]</label><label class="expand" for="c-37242177">[1 more]</label></div><br/><div class="children"><div class="content">Maybe everything  changes  at $1 trillion, but I definitely see smaller (but public) companies leaving money on the table because it would require  cultural change.</div><br/></div></div></div></div></div></div><div id="37241822" class="c"><input type="checkbox" id="c-37241822" checked=""/><div class="controls bullet"><span class="by">tgma</span><span>|</span><a href="#37241699">root</a><span>|</span><a href="#37241756">parent</a><span>|</span><a href="#37241892">prev</a><span>|</span><a href="#37241894">next</a><span>|</span><label class="collapse" for="c-37241822">[-]</label><label class="expand" for="c-37241822">[1 more]</label></div><br/><div class="children"><div class="content">- Can&#x27;t they just hire all of nvidia&#x27;s developers and pay them 5x as much?<p>No.</div><br/></div></div><div id="37241894" class="c"><input type="checkbox" id="c-37241894" checked=""/><div class="controls bullet"><span class="by">andrepd</span><span>|</span><a href="#37241699">root</a><span>|</span><a href="#37241756">parent</a><span>|</span><a href="#37241822">prev</a><span>|</span><a href="#37242145">next</a><span>|</span><label class="collapse" for="c-37241894">[-]</label><label class="expand" for="c-37241894">[7 more]</label></div><br/><div class="children"><div class="content">The market is also saying that Tesla is worth more than BMW, VW, Audi, Mercedes, Toyota, Hyundai, Fiat, Ford, and dozens of others <i>combined</i>. Mehh, I don&#x27;t know.</div><br/><div id="37241971" class="c"><input type="checkbox" id="c-37241971" checked=""/><div class="controls bullet"><span class="by">UncleOxidant</span><span>|</span><a href="#37241699">root</a><span>|</span><a href="#37241894">parent</a><span>|</span><a href="#37241983">next</a><span>|</span><label class="collapse" for="c-37241971">[-]</label><label class="expand" for="c-37241971">[2 more]</label></div><br/><div class="children"><div class="content">Exactly, the market isn&#x27;t always rational. There&#x27;s a lot of work on quantization in neural nets, for example, that can allow them to work sufficiently well on less capable hardware. It could be that some breakthrough there would obviate the need for NVDA hardware (or at least reduce how many are needed).</div><br/><div id="37242637" class="c"><input type="checkbox" id="c-37242637" checked=""/><div class="controls bullet"><span class="by">lotsofpulp</span><span>|</span><a href="#37241699">root</a><span>|</span><a href="#37241971">parent</a><span>|</span><a href="#37241983">next</a><span>|</span><label class="collapse" for="c-37242637">[-]</label><label class="expand" for="c-37242637">[1 more]</label></div><br/><div class="children"><div class="content">It is rational if you interpret market capitalization and share price movements as “the market is saying Tesla WILL be worth more than x,y z combined between time now and time whenever you want to sell it.”<p>For different people, the timespan between now and when they may want or need to sell it is different, and thus different people will arrive at different conclusions.<p>And note that “worth more” above simply means growth in market capitalization, so as long as someone is willing to buy the shares at a price supporting that increased market cap, then it does not matter if Tesla is still selling fewer cars than the others combined.</div><br/></div></div></div></div><div id="37241983" class="c"><input type="checkbox" id="c-37241983" checked=""/><div class="controls bullet"><span class="by">scrlk</span><span>|</span><a href="#37241699">root</a><span>|</span><a href="#37241894">parent</a><span>|</span><a href="#37241971">prev</a><span>|</span><a href="#37242111">next</a><span>|</span><label class="collapse" for="c-37241983">[-]</label><label class="expand" for="c-37241983">[3 more]</label></div><br/><div class="children"><div class="content">&quot;In the short run, the market is a voting machine but in the long run, it is a weighing machine.&quot;</div><br/><div id="37242412" class="c"><input type="checkbox" id="c-37242412" checked=""/><div class="controls bullet"><span class="by">TheAlchemist</span><span>|</span><a href="#37241699">root</a><span>|</span><a href="#37241983">parent</a><span>|</span><a href="#37242111">next</a><span>|</span><label class="collapse" for="c-37242412">[-]</label><label class="expand" for="c-37242412">[2 more]</label></div><br/><div class="children"><div class="content">Exactly this !<p>And as somebody with a significant short position, I would add - &quot;The market can stay irrational longer than you can stay solvent&quot; !<p>Their numbers for this and next Q are absolutely amazing. It&#x27;s also quite &quot;refreshing&quot; - a company with great product, almost without competition (so far - it will come real quick). And fun part being their main advantage is probably CUDA and not even the chips itself (which by the way they don&#x27;t manufacture - they &quot;only&quot; do the design).<p>But still - even with those numbers, and even with this pace of growth (both being absolutely not sustainable, and will probably reverse hard next year) - the valuation doesn&#x27;t make any sense, especially given the current interest rates.</div><br/><div id="37244665" class="c"><input type="checkbox" id="c-37244665" checked=""/><div class="controls bullet"><span class="by">slashdev</span><span>|</span><a href="#37241699">root</a><span>|</span><a href="#37242412">parent</a><span>|</span><a href="#37242111">next</a><span>|</span><label class="collapse" for="c-37244665">[-]</label><label class="expand" for="c-37244665">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, there is no world where Nvidia grows into this valuation. It would have to be bigger than the entire semiconductor business today by itself. If you think AI can bring that much growth, well then it could happen, but it seems extremely unlikely to me.</div><br/></div></div></div></div></div></div><div id="37242111" class="c"><input type="checkbox" id="c-37242111" checked=""/><div class="controls bullet"><span class="by">peanuty1</span><span>|</span><a href="#37241699">root</a><span>|</span><a href="#37241894">parent</a><span>|</span><a href="#37241983">prev</a><span>|</span><a href="#37242145">next</a><span>|</span><label class="collapse" for="c-37242111">[-]</label><label class="expand" for="c-37242111">[1 more]</label></div><br/><div class="children"><div class="content">And Rivian has a greater market cap than Nissan.</div><br/></div></div></div></div></div></div><div id="37242145" class="c"><input type="checkbox" id="c-37242145" checked=""/><div class="controls bullet"><span class="by">highwaylights</span><span>|</span><a href="#37241699">root</a><span>|</span><a href="#37241734">parent</a><span>|</span><a href="#37241756">prev</a><span>|</span><a href="#37242030">next</a><span>|</span><label class="collapse" for="c-37242145">[-]</label><label class="expand" for="c-37242145">[6 more]</label></div><br/><div class="children"><div class="content">I can really see Intel figuring this out. A lot of people on HN talking about Intel as an also-ran just like they spoke about AMD before Zen.<p>Raptor Lake is at 7nm and incredibly competitive there (~2700 single core on geekbench, taken with a pinch of salt). They’re still planning on being on 1.8nm&#x2F;18A  within 2 years, while at the same time ramping up their GPU efforts (albeit using TSMC for  4nm).  Nvidia is very much in the lead, but this is just the beginning.<p>tldr; I ain’t hear no bell.</div><br/><div id="37242777" class="c"><input type="checkbox" id="c-37242777" checked=""/><div class="controls bullet"><span class="by">andromeduck</span><span>|</span><a href="#37241699">root</a><span>|</span><a href="#37242145">parent</a><span>|</span><a href="#37244081">next</a><span>|</span><label class="collapse" for="c-37242777">[-]</label><label class="expand" for="c-37242777">[2 more]</label></div><br/><div class="children"><div class="content">The problem with Intel is:<p>1. They don&#x27;t pay - Nvidia&#x2F;Google&#x2F;Apple easily pays 1.5-2x Intel before appreciattion.<p>2. They&#x27;re cheap&#x2F;beaurcratic. The office sucks, your laptop sucks.<p>3. They suck at software. <a href="https:&#x2F;&#x2F;pharr.org&#x2F;matt&#x2F;blog&#x2F;2018&#x2F;04&#x2F;18&#x2F;ispc-origins" rel="nofollow noreferrer">https:&#x2F;&#x2F;pharr.org&#x2F;matt&#x2F;blog&#x2F;2018&#x2F;04&#x2F;18&#x2F;ispc-origins</a><p>4. They can&#x27;t develop&#x2F;retain talent. Half the ML-HW&#x2F;FW teams at AMD&#x2F;Google&#x2F;Nvidia&#x2F;Apple are ex-Intel.</div><br/><div id="37245661" class="c"><input type="checkbox" id="c-37245661" checked=""/><div class="controls bullet"><span class="by">Panzer04</span><span>|</span><a href="#37241699">root</a><span>|</span><a href="#37242777">parent</a><span>|</span><a href="#37244081">next</a><span>|</span><label class="collapse" for="c-37245661">[-]</label><label class="expand" for="c-37245661">[1 more]</label></div><br/><div class="children"><div class="content">How is that indicative of not developing talent? Sounds like they have a fairly robust pipeline if so many end up working at other companies...<p>(Retention notwithstanding :P)</div><br/></div></div></div></div><div id="37244081" class="c"><input type="checkbox" id="c-37244081" checked=""/><div class="controls bullet"><span class="by">jjpprrrr</span><span>|</span><a href="#37241699">root</a><span>|</span><a href="#37242145">parent</a><span>|</span><a href="#37242777">prev</a><span>|</span><a href="#37242030">next</a><span>|</span><label class="collapse" for="c-37244081">[-]</label><label class="expand" for="c-37244081">[3 more]</label></div><br/><div class="children"><div class="content">Raptor Lake uses the &quot;Intel 7&quot; node which is actually 10nm, not 7 nm. It does have roughly the same density as TSMC&#x27;s 7nm node.</div><br/><div id="37245726" class="c"><input type="checkbox" id="c-37245726" checked=""/><div class="controls bullet"><span class="by">paulmd</span><span>|</span><a href="#37241699">root</a><span>|</span><a href="#37244081">parent</a><span>|</span><a href="#37242030">next</a><span>|</span><label class="collapse" for="c-37245726">[-]</label><label class="expand" for="c-37245726">[2 more]</label></div><br/><div class="children"><div class="content">In reality it literally is as simple as “intel says it’s 7nm so it’s 7nm”, but density is what determines the node number, insofar as anything determines it beyond marketing.<p>So, if intel 7 is a 10nm class node then so is tsmc N7. But the whole industry cooked their node names a decade ago and intel is allowed to do the same terminology. To do anything otherwise would be a needless marketing disadvantage. If someone’s cheating on marketing, everyone has to - and the reality was everyone but intel was already cheating.</div><br/><div id="37246037" class="c"><input type="checkbox" id="c-37246037" checked=""/><div class="controls bullet"><span class="by">highwaylights</span><span>|</span><a href="#37241699">root</a><span>|</span><a href="#37245726">parent</a><span>|</span><a href="#37242030">next</a><span>|</span><label class="collapse" for="c-37246037">[-]</label><label class="expand" for="c-37246037">[1 more]</label></div><br/><div class="children"><div class="content">This, but also if we took it at face value (we shouldn&#x27;t for the reasons in the reply above), then this means Intel is <i>even further</i> ahead when adjusting for the difference in node sizes.<p>i.e. This would mean Intel will be getting a four-node-scale jump in performance (10nm-&gt;7nm-&gt;5nm-&gt;3nm-&gt;1.8nm) from where they are with Raptor Lake by 2025 if they can stay on track.<p>I don&#x27;t have any insight into this but I would hope Pat Geslinger is righting the salary, perks and incentive structure as a matter of priority to stop the shedding of talent.</div><br/></div></div></div></div></div></div></div></div><div id="37242030" class="c"><input type="checkbox" id="c-37242030" checked=""/><div class="controls bullet"><span class="by">Mountain_Skies</span><span>|</span><a href="#37241699">root</a><span>|</span><a href="#37241734">parent</a><span>|</span><a href="#37242145">prev</a><span>|</span><a href="#37243867">next</a><span>|</span><label class="collapse" for="c-37242030">[-]</label><label class="expand" for="c-37242030">[3 more]</label></div><br/><div class="children"><div class="content">Over the past decade Intel seems to have become more interested in social causes than in technology, maybe with a side of government backrubbing to keep some income flowing.</div><br/><div id="37242074" class="c"><input type="checkbox" id="c-37242074" checked=""/><div class="controls bullet"><span class="by">UncleOxidant</span><span>|</span><a href="#37241699">root</a><span>|</span><a href="#37242030">parent</a><span>|</span><a href="#37243867">next</a><span>|</span><label class="collapse" for="c-37242074">[-]</label><label class="expand" for="c-37242074">[2 more]</label></div><br/><div class="children"><div class="content">Nah, the biggest problem is that Intel became very risk averse. Yeah, they&#x27;ll talk a good game on taking risks, but when it comes down to it people who took risks that failed tend to not be at Intel and other employees see that and think that maybe they need to play it safe.</div><br/><div id="37242237" class="c"><input type="checkbox" id="c-37242237" checked=""/><div class="controls bullet"><span class="by">johnvanommen</span><span>|</span><a href="#37241699">root</a><span>|</span><a href="#37242074">parent</a><span>|</span><a href="#37243867">next</a><span>|</span><label class="collapse" for="c-37242237">[-]</label><label class="expand" for="c-37242237">[1 more]</label></div><br/><div class="children"><div class="content">&gt;  Yeah, they&#x27;ll talk a good game on taking risks, but when it comes down to it people who took risks that failed tend to not be at Intel and other employees see that and think that maybe they need to play it safe.<p>I worked at Sears corporate when Amazon was getting big, about 25 years ago.<p>Always made me chuckle when armchair quarterbacks on TV would wonder why Sears couldn&#x27;t do what Amazon did.<p>Bezos took <i>tremendous</i> risks in the late 90s and early 00s, while Sears was trying to figure out how to wring a few more pennies out of their stores. Sears Corporate was 110% focused on taking the existing business and maximizing profits, not on innovation of any kind whatsoever.</div><br/></div></div></div></div></div></div></div></div><div id="37243867" class="c"><input type="checkbox" id="c-37243867" checked=""/><div class="controls bullet"><span class="by">bemmu</span><span>|</span><a href="#37241699">parent</a><span>|</span><a href="#37241734">prev</a><span>|</span><a href="#37245801">next</a><span>|</span><label class="collapse" for="c-37243867">[-]</label><label class="expand" for="c-37243867">[1 more]</label></div><br/><div class="children"><div class="content">If you melted the moon to turn it into GPUs, we’d still find use for that compute.<p>If they can hold the market and not implode for internal reasons, not sure this has any upper limit?</div><br/></div></div><div id="37245801" class="c"><input type="checkbox" id="c-37245801" checked=""/><div class="controls bullet"><span class="by">smolder</span><span>|</span><a href="#37241699">parent</a><span>|</span><a href="#37243867">prev</a><span>|</span><a href="#37241694">next</a><span>|</span><label class="collapse" for="c-37245801">[-]</label><label class="expand" for="c-37245801">[1 more]</label></div><br/><div class="children"><div class="content">I wonder if this is what Nancy Pelosi&#x27;s husband actually bought all his NVDA in preparation for, way back then. Their prices have been shit for consumers since then, but it&#x27;s still been good for them.</div><br/></div></div></div></div><div id="37241694" class="c"><input type="checkbox" id="c-37241694" checked=""/><div class="controls bullet"><span class="by">NickC25</span><span>|</span><a href="#37241699">prev</a><span>|</span><a href="#37242393">next</a><span>|</span><label class="collapse" for="c-37241694">[-]</label><label class="expand" for="c-37241694">[34 more]</label></div><br/><div class="children"><div class="content">Absolutely monster numbers.  The aftermarket trading is up over 8% as of right now, roughly $41 USD to approximately $513 a share.  Insane.<p>Anyone who is a lot more versed in company valuation methodology see this as being near peak value, or does Nvidia have a lot more room to run?</div><br/><div id="37244452" class="c"><input type="checkbox" id="c-37244452" checked=""/><div class="controls bullet"><span class="by">gen220</span><span>|</span><a href="#37241694">parent</a><span>|</span><a href="#37241722">next</a><span>|</span><label class="collapse" for="c-37244452">[-]</label><label class="expand" for="c-37244452">[1 more]</label></div><br/><div class="children"><div class="content">The fundamental model of company valuation is that the company&#x27;s equity is worth the accumulation of the company&#x27;s future cash flows, typically discounted by some rate so that predicted cash flows 5 years from now are worth some % less than 100%, with the intent of pricing in uncertainty.<p>Nvidia has had a watershed moment of revenue growth, because they&#x27;re the only significant player in the space of top-of-the-line GPUs for training LLMs.<p>Their current valuation bakes in the assumption that not only is this unprecedented level of pricing power durable, but that top line revenue will also <i>grow significantly</i> over the next few years.<p>Reminder that Nvidia is selling chips, mostly to datacenters, whose purchasing habits are primarily driven by &quot;customer&quot; demand (where customers are, in this case, tech companies wanting to train neural nets).<p>So a bet that they go up from here is a bet that datacenters will want <i>at least as many chips</i> in the next N continuous quarters, and will be willing to pay the current premium that Nvidia is charging, today. The corollary is you&#x27;re betting that &quot;customer demand&quot; for ever-improving GPUs is climbing an incredibly upwards, secular (read: permanent, non-cyclical) trajectory, such that it outpaces the assumptions of these already-lofty expectations.<p>I think betray my own opinion, but the price is what it is. :)</div><br/></div></div><div id="37241722" class="c"><input type="checkbox" id="c-37241722" checked=""/><div class="controls bullet"><span class="by">mholm</span><span>|</span><a href="#37241694">parent</a><span>|</span><a href="#37244452">prev</a><span>|</span><a href="#37241880">next</a><span>|</span><label class="collapse" for="c-37241722">[-]</label><label class="expand" for="c-37241722">[3 more]</label></div><br/><div class="children"><div class="content">Nvidia is the pickaxe seller in a gold rush. Their valuation is very much tied to how big AI grows in the next several years, and how quickly competitors can arise. I could easily see them continuing to go up from here, especially if AI keeps on expanding utility instead of leveling off as some fear.</div><br/><div id="37243718" class="c"><input type="checkbox" id="c-37243718" checked=""/><div class="controls bullet"><span class="by">creer</span><span>|</span><a href="#37241694">root</a><span>|</span><a href="#37241722">parent</a><span>|</span><a href="#37243043">next</a><span>|</span><label class="collapse" for="c-37243718">[-]</label><label class="expand" for="c-37243718">[1 more]</label></div><br/><div class="children"><div class="content">Very much so. Nvidia was lucky with the perfect sequence of video and compute farms, then cryptocurrency and model training, and now the model training direction is flowering into application (hopes) left and right. But they did great with their luck. And now they are yet again in the position of selling tools to soak up everyone else&#x27;s capital investment power. They are still now (and yet again) at the perfect spot for a giant new market.<p>But that&#x27;s still a high valuation - that is even if that new market grows to the sky, it&#x27;s not clear that it can justify that new valuation.<p>Is Nvidia failing anytime soon? No. Is it the best investment you can find? That&#x27;s harder to tell which is why the complaint of &quot;very high valuation already&quot;. It&#x27;s not in doubt that it&#x27;s a great business. It&#x27;s less easy to decide whether it&#x27;s a great investment to get in right now.<p>But everything is relative a PE around 40-60 is NOT historically crazy high for the verge of a giant new market. And yet it is very high for a trillion dollar market cap. This is exciting: a trillion dollar market cap at the verge of a giant new market!</div><br/></div></div></div></div><div id="37241880" class="c"><input type="checkbox" id="c-37241880" checked=""/><div class="controls bullet"><span class="by">squeaky-clean</span><span>|</span><a href="#37241694">parent</a><span>|</span><a href="#37241722">prev</a><span>|</span><a href="#37241713">next</a><span>|</span><label class="collapse" for="c-37241880">[-]</label><label class="expand" for="c-37241880">[6 more]</label></div><br/><div class="children"><div class="content">It&#x27;s pretty overpriced already if you&#x27;re looking at the fundamentals, and has been for a while. But fundamentals haven&#x27;t really mattered in tech stocks for a long time.<p>If you want the responsible advice, it&#x27;s overpriced. If you want my personal advice, well I bought more yesterday afternoon.</div><br/><div id="37243372" class="c"><input type="checkbox" id="c-37243372" checked=""/><div class="controls bullet"><span class="by">what_ever</span><span>|</span><a href="#37241694">root</a><span>|</span><a href="#37241880">parent</a><span>|</span><a href="#37243661">next</a><span>|</span><label class="collapse" for="c-37243372">[-]</label><label class="expand" for="c-37243372">[4 more]</label></div><br/><div class="children"><div class="content">Can you add a little more color on what fundamentals is it overpriced? Have you looked at their QoQ growth (not even YoY) for last few quarters? I would say the stock price is just trying to keep up with the numbers they are putting out.</div><br/><div id="37243657" class="c"><input type="checkbox" id="c-37243657" checked=""/><div class="controls bullet"><span class="by">ripper1138</span><span>|</span><a href="#37241694">root</a><span>|</span><a href="#37243372">parent</a><span>|</span><a href="#37245312">prev</a><span>|</span><a href="#37243661">next</a><span>|</span><label class="collapse" for="c-37243657">[-]</label><label class="expand" for="c-37243657">[2 more]</label></div><br/><div class="children"><div class="content">Their quarterly dividend is only $0.04 per share, total assets at 50B (vs 350B+ for other 1T companies), they cannot easily sell more chips and increasing price can only go so far.</div><br/><div id="37243740" class="c"><input type="checkbox" id="c-37243740" checked=""/><div class="controls bullet"><span class="by">AnotherGoodName</span><span>|</span><a href="#37241694">root</a><span>|</span><a href="#37243657">parent</a><span>|</span><a href="#37243661">next</a><span>|</span><label class="collapse" for="c-37243740">[-]</label><label class="expand" for="c-37243740">[1 more]</label></div><br/><div class="children"><div class="content">A lot of stocks don&#x27;t pay dividends at all. They are problematic with tax and theoretically the same benefit can be achieved with buybacks.</div><br/></div></div></div></div></div></div><div id="37243661" class="c"><input type="checkbox" id="c-37243661" checked=""/><div class="controls bullet"><span class="by">AnotherGoodName</span><span>|</span><a href="#37241694">root</a><span>|</span><a href="#37241880">parent</a><span>|</span><a href="#37243372">prev</a><span>|</span><a href="#37241713">next</a><span>|</span><label class="collapse" for="c-37243661">[-]</label><label class="expand" for="c-37243661">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t see it. It would have been overpriced if not for this insane report. 854% YoY earnings growth. A PE that&#x27;s now below 50 (even taking into account the $500 share price).<p>Its not overpriced anymore. In fact if there&#x27;s anything left in the tank or this is at all sustained it&#x27;s cheap.</div><br/></div></div></div></div><div id="37241713" class="c"><input type="checkbox" id="c-37241713" checked=""/><div class="controls bullet"><span class="by">mikeweiss</span><span>|</span><a href="#37241694">parent</a><span>|</span><a href="#37241880">prev</a><span>|</span><a href="#37241779">next</a><span>|</span><label class="collapse" for="c-37241713">[-]</label><label class="expand" for="c-37241713">[2 more]</label></div><br/><div class="children"><div class="content">In my opinion it&#x27;s likely mostly pull forward demand. Companies are racing to buy as many chips as possible and hoard them.<p>I already saw a few posts here on HN from companies that threw down insane amounts of $$ on H100s and are now looking to rent out their excess capacity. I&#x27;m guessing we&#x27;ll be seeing a lot more posts like that soon.</div><br/><div id="37245876" class="c"><input type="checkbox" id="c-37245876" checked=""/><div class="controls bullet"><span class="by">mortehu</span><span>|</span><a href="#37241694">root</a><span>|</span><a href="#37241713">parent</a><span>|</span><a href="#37241779">next</a><span>|</span><label class="collapse" for="c-37245876">[-]</label><label class="expand" for="c-37245876">[1 more]</label></div><br/><div class="children"><div class="content">Looking to rent out, or fully booked for the next year and looking to buy more GPUs?</div><br/></div></div></div></div><div id="37241779" class="c"><input type="checkbox" id="c-37241779" checked=""/><div class="controls bullet"><span class="by">tmn</span><span>|</span><a href="#37241694">parent</a><span>|</span><a href="#37241713">prev</a><span>|</span><a href="#37242119">next</a><span>|</span><label class="collapse" for="c-37241779">[-]</label><label class="expand" for="c-37241779">[2 more]</label></div><br/><div class="children"><div class="content">Valuation fundamentals don&#x27;t justify current prices. That said it could easily go higher (much higher). Passive investing has created a constant bid that has significantly distorted price discovery compared to pre passive era.</div><br/></div></div><div id="37242119" class="c"><input type="checkbox" id="c-37242119" checked=""/><div class="controls bullet"><span class="by">epolanski</span><span>|</span><a href="#37241694">parent</a><span>|</span><a href="#37241779">prev</a><span>|</span><a href="#37243672">next</a><span>|</span><label class="collapse" for="c-37242119">[-]</label><label class="expand" for="c-37242119">[1 more]</label></div><br/><div class="children"><div class="content">This incredible growth was already priced in at 250$.<p>Now it&#x27;s just crazy.</div><br/></div></div><div id="37243672" class="c"><input type="checkbox" id="c-37243672" checked=""/><div class="controls bullet"><span class="by">csomar</span><span>|</span><a href="#37241694">parent</a><span>|</span><a href="#37242119">prev</a><span>|</span><a href="#37241712">next</a><span>|</span><label class="collapse" for="c-37243672">[-]</label><label class="expand" for="c-37243672">[1 more]</label></div><br/><div class="children"><div class="content">I would not predict a peak if I didn&#x27;t predict this rise (which most people didn&#x27;t?). A new crypto that requires GPU mining, continued AI boom, GPUs being used for something else?, etc.. Their price could go infinitely up.</div><br/></div></div><div id="37241712" class="c"><input type="checkbox" id="c-37241712" checked=""/><div class="controls bullet"><span class="by">reilly3000</span><span>|</span><a href="#37241694">parent</a><span>|</span><a href="#37243672">prev</a><span>|</span><a href="#37241832">next</a><span>|</span><label class="collapse" for="c-37241712">[-]</label><label class="expand" for="c-37241712">[9 more]</label></div><br/><div class="children"><div class="content">It’s basically a meme stock now. I don’t think anyone should be surprised by wide swings and irrational pricing going forward into the next few months.</div><br/><div id="37242460" class="c"><input type="checkbox" id="c-37242460" checked=""/><div class="controls bullet"><span class="by">vsareto</span><span>|</span><a href="#37241694">root</a><span>|</span><a href="#37241712">parent</a><span>|</span><a href="#37242330">next</a><span>|</span><label class="collapse" for="c-37242460">[-]</label><label class="expand" for="c-37242460">[2 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think the market leader for graphics cards -- a technically complex product compared to a bunch of brick stores selling video games -- is what you can consider a meme stock</div><br/></div></div><div id="37242330" class="c"><input type="checkbox" id="c-37242330" checked=""/><div class="controls bullet"><span class="by">danielmarkbruce</span><span>|</span><a href="#37241694">root</a><span>|</span><a href="#37241712">parent</a><span>|</span><a href="#37242460">prev</a><span>|</span><a href="#37241753">next</a><span>|</span><label class="collapse" for="c-37242330">[-]</label><label class="expand" for="c-37242330">[1 more]</label></div><br/><div class="children"><div class="content">Top line growing 100% a year, faster recently..... Doesn&#x27;t take long for $50 bill pa to turn into 1 trillion pa at that rate...</div><br/></div></div><div id="37241753" class="c"><input type="checkbox" id="c-37241753" checked=""/><div class="controls bullet"><span class="by">pb7</span><span>|</span><a href="#37241694">root</a><span>|</span><a href="#37241712">parent</a><span>|</span><a href="#37242330">prev</a><span>|</span><a href="#37241832">next</a><span>|</span><label class="collapse" for="c-37241753">[-]</label><label class="expand" for="c-37241753">[5 more]</label></div><br/><div class="children"><div class="content">What makes it a meme stock? It&#x27;s printing money from an industry that is only starting. This isn&#x27;t crypto nonsense.</div><br/><div id="37241835" class="c"><input type="checkbox" id="c-37241835" checked=""/><div class="controls bullet"><span class="by">fnordpiglet</span><span>|</span><a href="#37241694">root</a><span>|</span><a href="#37241753">parent</a><span>|</span><a href="#37242171">next</a><span>|</span><label class="collapse" for="c-37241835">[-]</label><label class="expand" for="c-37241835">[2 more]</label></div><br/><div class="children"><div class="content">Yeah, every company of any note is planning how to use AI, and a lot of the use cases are already proved out. This isn’t speculative nonsense. The question is how big does it get, not will it be big.<p>Crypto and blockchain never had an actual proved out use case. There was an interesting idea but no one ever could figure out a way it was useful. The costs associated were much higher than the risks of not using it.<p>People who think this is a meme aren’t paying attention, and they’re certainly not in the rooms of power where AI planning is happening at megacorps. I’ve been in them, and it’s serious and material and we are just now beginning to scratch the surface.</div><br/><div id="37244511" class="c"><input type="checkbox" id="c-37244511" checked=""/><div class="controls bullet"><span class="by">reilly3000</span><span>|</span><a href="#37241694">root</a><span>|</span><a href="#37241835">parent</a><span>|</span><a href="#37242171">next</a><span>|</span><label class="collapse" for="c-37244511">[-]</label><label class="expand" for="c-37244511">[1 more]</label></div><br/><div class="children"><div class="content">I’m saying all of that growth has been priced in for multiple years now. It’s likely to have very solid fundamentals and new relationships in enterprises everywhere for years to come. As such it’s ripe for overvaluation by both retail and institutional traders. If I had a horse in this race I would ride the wave for a while as others piled on, then take a nice honest profit before one of their many competitors turns in a healthy AI driven quarter like this. It will still be a strong stock, but expect some significant flux in a correction.</div><br/></div></div></div></div><div id="37242171" class="c"><input type="checkbox" id="c-37242171" checked=""/><div class="controls bullet"><span class="by">kelvie</span><span>|</span><a href="#37241694">root</a><span>|</span><a href="#37241753">parent</a><span>|</span><a href="#37241835">prev</a><span>|</span><a href="#37241832">next</a><span>|</span><label class="collapse" for="c-37242171">[-]</label><label class="expand" for="c-37242171">[2 more]</label></div><br/><div class="children"><div class="content">(Not sure if it&#x27;s true), but a meme stock is one whose price is propped up by retail traders, and spreads through social media &#x2F; word-of-mouth, as memes do.<p>How we prove it&#x27;s one is probably another matter.</div><br/><div id="37242620" class="c"><input type="checkbox" id="c-37242620" checked=""/><div class="controls bullet"><span class="by">pb7</span><span>|</span><a href="#37241694">root</a><span>|</span><a href="#37242171">parent</a><span>|</span><a href="#37241832">next</a><span>|</span><label class="collapse" for="c-37242620">[-]</label><label class="expand" for="c-37242620">[1 more]</label></div><br/><div class="children"><div class="content">Retail investors make up a low single digit percent of individual stock ownership. &#x2F;r&#x2F;wallstreetbets is not putting even a dent in a $1T company&#x27;s stock price.</div><br/></div></div></div></div></div></div></div></div><div id="37241832" class="c"><input type="checkbox" id="c-37241832" checked=""/><div class="controls bullet"><span class="by">rvz</span><span>|</span><a href="#37241694">parent</a><span>|</span><a href="#37241712">prev</a><span>|</span><a href="#37242393">next</a><span>|</span><label class="collapse" for="c-37241832">[-]</label><label class="expand" for="c-37241832">[8 more]</label></div><br/><div class="children"><div class="content">&gt; The aftermarket trading is up over 8% as of right now, roughly $41 USD to approximately $513 a share. Insane.<p>8% is close to nothing in stocks. Biotech stocks go up and down more than that without earnings announcements.<p>&gt; Anyone who is a lot more versed in company valuation methodology see this as being near peak value, or does Nvidia have a lot more room to run?<p>As long as fine-tuning, training or even using these models are inefficient and no other efficient alternatives to that without these GPUs, then Nvidia will remain unchallenged unless that changes.<p>EDIT: It is true like it or not AI bros. There are too many to list. For example, just yesterday:<p>Fulcrum Therapeutics, Inc. (FULC) 38% up.<p>China SXT Pharmaceuticals (CM:SXTC) down 25%.<p>Regencell Bioscience Holdings (RGC) 28% up.<p>NanoViricides (NNVC) up 20%.<p>Armata Pharmaceuticals (ARMP) down 23%.<p>[0] <a href="https:&#x2F;&#x2F;simplywall.st&#x2F;stocks&#x2F;us&#x2F;pharmaceuticals-biotech" rel="nofollow noreferrer">https:&#x2F;&#x2F;simplywall.st&#x2F;stocks&#x2F;us&#x2F;pharmaceuticals-biotech</a></div><br/><div id="37242034" class="c"><input type="checkbox" id="c-37242034" checked=""/><div class="controls bullet"><span class="by">pb7</span><span>|</span><a href="#37241694">root</a><span>|</span><a href="#37241832">parent</a><span>|</span><a href="#37242393">next</a><span>|</span><label class="collapse" for="c-37242034">[-]</label><label class="expand" for="c-37242034">[7 more]</label></div><br/><div class="children"><div class="content">Biotechs are lottery tickets, not stocks. You&#x27;re just gambling on binary results.</div><br/><div id="37242215" class="c"><input type="checkbox" id="c-37242215" checked=""/><div class="controls bullet"><span class="by">rvz</span><span>|</span><a href="#37241694">root</a><span>|</span><a href="#37242034">parent</a><span>|</span><a href="#37242044">next</a><span>|</span><label class="collapse" for="c-37242215">[-]</label><label class="expand" for="c-37242215">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Biotechs are lottery tickets, not stocks.<p>Please.<p>Stocks are lottery tickets and Biotech stocks are stocks.<p>&gt; You&#x27;re just gambling on binary results.<p>The risks are no better than most of the AI bros buying Nvidia and overpriced stocks at the very top or all time highs or extremely risky 0DTE strategy trades on earnings announcements.<p>Do AI bros who jumped in late really have to be married to their stocks that are already overpriced to make 8% on earnings when the very early folks start selling to take their profits?</div><br/></div></div><div id="37242044" class="c"><input type="checkbox" id="c-37242044" checked=""/><div class="controls bullet"><span class="by">gorenb</span><span>|</span><a href="#37241694">root</a><span>|</span><a href="#37242034">parent</a><span>|</span><a href="#37242215">prev</a><span>|</span><a href="#37242393">next</a><span>|</span><label class="collapse" for="c-37242044">[-]</label><label class="expand" for="c-37242044">[5 more]</label></div><br/><div class="children"><div class="content">Stocks are lottery tickets…</div><br/><div id="37242600" class="c"><input type="checkbox" id="c-37242600" checked=""/><div class="controls bullet"><span class="by">pb7</span><span>|</span><a href="#37241694">root</a><span>|</span><a href="#37242044">parent</a><span>|</span><a href="#37242144">next</a><span>|</span><label class="collapse" for="c-37242600">[-]</label><label class="expand" for="c-37242600">[2 more]</label></div><br/><div class="children"><div class="content">Not if you understand what stocks are and how betting on biotech stocks is not a wise investment.</div><br/><div id="37242976" class="c"><input type="checkbox" id="c-37242976" checked=""/><div class="controls bullet"><span class="by">rvz</span><span>|</span><a href="#37241694">root</a><span>|</span><a href="#37242600">parent</a><span>|</span><a href="#37242144">next</a><span>|</span><label class="collapse" for="c-37242976">[-]</label><label class="expand" for="c-37242976">[1 more]</label></div><br/><div class="children"><div class="content">My point is, 8% on earnings is hardly volatile.<p>&gt; Not if you understand what stocks are and how betting on biotech stocks is not a wise investment.<p>So you&#x27;re giving investment advice for putting money in NVDA stock at the top or all time highs, right now on earnings as a &#x27;wise investment&#x27; to make 8% (after hours) when others are clearly taking their money out of the market.<p>Unless you already invested in NVDA stock last year, that move is gone and you&#x27;re just telling retail late comers to throw money at NVDA at the top for others to take their profits.</div><br/></div></div></div></div><div id="37242144" class="c"><input type="checkbox" id="c-37242144" checked=""/><div class="controls bullet"><span class="by">rvz</span><span>|</span><a href="#37241694">root</a><span>|</span><a href="#37242044">parent</a><span>|</span><a href="#37242600">prev</a><span>|</span><a href="#37242393">next</a><span>|</span><label class="collapse" for="c-37242144">[-]</label><label class="expand" for="c-37242144">[2 more]</label></div><br/><div class="children"><div class="content">Exactly.<p>Nvidia is just one of many lottery tickets and 8% in one day is hardly volatile in stocks.</div><br/><div id="37244666" class="c"><input type="checkbox" id="c-37244666" checked=""/><div class="controls bullet"><span class="by">mthoms</span><span>|</span><a href="#37241694">root</a><span>|</span><a href="#37242144">parent</a><span>|</span><a href="#37242393">next</a><span>|</span><label class="collapse" for="c-37244666">[-]</label><label class="expand" for="c-37244666">[1 more]</label></div><br/><div class="children"><div class="content">The point is that 8% is volatile <i>relative to the market cap</i>. That&#x27;s a massive amount of (paper) wealth being created.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="37242393" class="c"><input type="checkbox" id="c-37242393" checked=""/><div class="controls bullet"><span class="by">seydor</span><span>|</span><a href="#37241694">prev</a><span>|</span><a href="#37242650">next</a><span>|</span><label class="collapse" for="c-37242393">[-]</label><label class="expand" for="c-37242393">[7 more]</label></div><br/><div class="children"><div class="content">It s come to the point that people are begging competitors to do something in the space. Who knows, maybe some cheap Chinese asic that can do matrix multiplication ends up eating their lunch.<p>You d think that, at the level of capitalization of tech companies, competition would be cutthroat</div><br/><div id="37244924" class="c"><input type="checkbox" id="c-37244924" checked=""/><div class="controls bullet"><span class="by">fulafel</span><span>|</span><a href="#37242393">parent</a><span>|</span><a href="#37242696">next</a><span>|</span><label class="collapse" for="c-37244924">[-]</label><label class="expand" for="c-37244924">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s already non-nvidia ML silicon in phones (Pixel, iPhone, etc) and datacenters (TPUs) that is more efficient than GPU silicon.</div><br/></div></div><div id="37242696" class="c"><input type="checkbox" id="c-37242696" checked=""/><div class="controls bullet"><span class="by">smoldesu</span><span>|</span><a href="#37242393">parent</a><span>|</span><a href="#37244924">prev</a><span>|</span><a href="#37242469">next</a><span>|</span><label class="collapse" for="c-37242696">[-]</label><label class="expand" for="c-37242696">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;re kinda underselling what exactly Nvidia is doing right now. If any Chinese company could compete with something like the DGX GH200, they would be building GPUs for the PRC, not exporting them.<p>There&#x27;s also the problem of industry hostility, anyways. Even <i>if</i> Nvidia was dethroned in the hardware-space, it&#x27;s unlikely their successor would improve the lock-in situation. It will take an intersectional effort to change things.</div><br/></div></div><div id="37242469" class="c"><input type="checkbox" id="c-37242469" checked=""/><div class="controls bullet"><span class="by">TheAlchemist</span><span>|</span><a href="#37242393">parent</a><span>|</span><a href="#37242696">prev</a><span>|</span><a href="#37242413">next</a><span>|</span><label class="collapse" for="c-37242469">[-]</label><label class="expand" for="c-37242469">[3 more]</label></div><br/><div class="children"><div class="content">Capitalization in itself is meaningless. If you have 50% of NVidia outstanding shares, and you try to sell 10% of that, the capitalization would crater.<p>What really counts is the profit. It is pretty huge now, but not &#x27;that&#x27; huge (at least yet).</div><br/><div id="37246431" class="c"><input type="checkbox" id="c-37246431" checked=""/><div class="controls bullet"><span class="by">mortehu</span><span>|</span><a href="#37242393">root</a><span>|</span><a href="#37242469">parent</a><span>|</span><a href="#37243764">next</a><span>|</span><label class="collapse" for="c-37246431">[-]</label><label class="expand" for="c-37246431">[1 more]</label></div><br/><div class="children"><div class="content">Historical acquisition premiums give you a distribution of what you can expect to pay for the whole company given the market cap.</div><br/></div></div><div id="37243764" class="c"><input type="checkbox" id="c-37243764" checked=""/><div class="controls bullet"><span class="by">creer</span><span>|</span><a href="#37242393">root</a><span>|</span><a href="#37242469">parent</a><span>|</span><a href="#37246431">prev</a><span>|</span><a href="#37242413">next</a><span>|</span><label class="collapse" for="c-37243764">[-]</label><label class="expand" for="c-37243764">[1 more]</label></div><br/><div class="children"><div class="content">Try and buy 10% and see what happens!<p>Your point stands but in both directions: The market cap is not &quot;the value of the company&quot; as in, you can neither buy it or sell it at that price.</div><br/></div></div></div></div><div id="37242413" class="c"><input type="checkbox" id="c-37242413" checked=""/><div class="controls bullet"><span class="by">zapdrive</span><span>|</span><a href="#37242393">parent</a><span>|</span><a href="#37242469">prev</a><span>|</span><a href="#37242650">next</a><span>|</span><label class="collapse" for="c-37242413">[-]</label><label class="expand" for="c-37242413">[1 more]</label></div><br/><div class="children"><div class="content">There are a bunch of startups trying to develop AI GPUs. Someone linked them in a comment a few days ago.</div><br/></div></div></div></div><div id="37242650" class="c"><input type="checkbox" id="c-37242650" checked=""/><div class="controls bullet"><span class="by">pier25</span><span>|</span><a href="#37242393">prev</a><span>|</span><a href="#37241732">next</a><span>|</span><label class="collapse" for="c-37242650">[-]</label><label class="expand" for="c-37242650">[2 more]</label></div><br/><div class="children"><div class="content">So gaming is now less than 20% of their business? Holy shit.</div><br/><div id="37243646" class="c"><input type="checkbox" id="c-37243646" checked=""/><div class="controls bullet"><span class="by">AnotherGoodName</span><span>|</span><a href="#37242650">parent</a><span>|</span><a href="#37241732">next</a><span>|</span><label class="collapse" for="c-37243646">[-]</label><label class="expand" for="c-37243646">[1 more]</label></div><br/><div class="children"><div class="content">Well their earnings went up 854% YoY and that&#x27;s basically all in the data center segment so it makes sense.<p>People are having a really hard time grasping that sometimes established companies 10x.</div><br/></div></div></div></div><div id="37241732" class="c"><input type="checkbox" id="c-37241732" checked=""/><div class="controls bullet"><span class="by">solardev</span><span>|</span><a href="#37242650">prev</a><span>|</span><a href="#37244132">next</a><span>|</span><label class="collapse" for="c-37241732">[-]</label><label class="expand" for="c-37241732">[40 more]</label></div><br/><div class="children"><div class="content">I miss the small graphics company that used to care about gamers :(</div><br/><div id="37241839" class="c"><input type="checkbox" id="c-37241839" checked=""/><div class="controls bullet"><span class="by">TechnicolorByte</span><span>|</span><a href="#37241732">parent</a><span>|</span><a href="#37241881">next</a><span>|</span><label class="collapse" for="c-37241839">[-]</label><label class="expand" for="c-37241839">[25 more]</label></div><br/><div class="children"><div class="content">Nvidia is dragging the entire gaming industry forward with ray&#x2F;path tracing and AI-based resolution and frame scaling. Everyone else (I.e., AMD) is following Nvidia’s lead.<p>In what way has Nvidia “forgotten” gamers with the rise of their datacenter business?</div><br/><div id="37241937" class="c"><input type="checkbox" id="c-37241937" checked=""/><div class="controls bullet"><span class="by">tracerbulletx</span><span>|</span><a href="#37241732">root</a><span>|</span><a href="#37241839">parent</a><span>|</span><a href="#37242166">next</a><span>|</span><label class="collapse" for="c-37241937">[-]</label><label class="expand" for="c-37241937">[4 more]</label></div><br/><div class="children"><div class="content">The card prices have gone up pretty significantly and availability has been bad for the last few years, they also have been segmenting their product line in ways where some of the lower tier cards are not very compelling vs previous release cycles. I don&#x27;t know if that&#x27;s attributable to them &quot;forgetting about gamers&quot; but it&#x27;s what people are upset about.</div><br/><div id="37243158" class="c"><input type="checkbox" id="c-37243158" checked=""/><div class="controls bullet"><span class="by">TillE</span><span>|</span><a href="#37241732">root</a><span>|</span><a href="#37241937">parent</a><span>|</span><a href="#37242167">next</a><span>|</span><label class="collapse" for="c-37243158">[-]</label><label class="expand" for="c-37243158">[1 more]</label></div><br/><div class="children"><div class="content">Prices are high, but the cards are fantastic. The only thing you can really complain about is that they&#x27;re stingy with VRAM.<p>Supply issues should be gone too; I got a 4070 Ti shortly after launch, no problem.</div><br/></div></div><div id="37242167" class="c"><input type="checkbox" id="c-37242167" checked=""/><div class="controls bullet"><span class="by">cma</span><span>|</span><a href="#37241732">root</a><span>|</span><a href="#37241937">parent</a><span>|</span><a href="#37243158">prev</a><span>|</span><a href="#37242709">next</a><span>|</span><label class="collapse" for="c-37242167">[-]</label><label class="expand" for="c-37242167">[1 more]</label></div><br/><div class="children"><div class="content">Compare price performance and it isn&#x27;t so bad, assuming you add in an adjustment for AMD&#x27;s lack of features.</div><br/></div></div><div id="37242709" class="c"><input type="checkbox" id="c-37242709" checked=""/><div class="controls bullet"><span class="by">rvz</span><span>|</span><a href="#37241732">root</a><span>|</span><a href="#37241937">parent</a><span>|</span><a href="#37242167">prev</a><span>|</span><a href="#37242166">next</a><span>|</span><label class="collapse" for="c-37242709">[-]</label><label class="expand" for="c-37242709">[1 more]</label></div><br/><div class="children"><div class="content">So even without crypto, the prices of GPUs are still expensive regardless.<p>The hoarding isn&#x27;t going to stop unless there are either efficient alternatives that are competitive on performance and price.<p>Perhaps that is why I keep seeing gamers crying over GPU prices and unable to find cheap Nvidia cards due to the AI bros hoarding them for their &#x27;deep learning&#x27; pet projects.<p>So they settle with AMD instead.</div><br/></div></div></div></div><div id="37242166" class="c"><input type="checkbox" id="c-37242166" checked=""/><div class="controls bullet"><span class="by">wudangmonk</span><span>|</span><a href="#37241732">root</a><span>|</span><a href="#37241839">parent</a><span>|</span><a href="#37241937">prev</a><span>|</span><a href="#37242108">next</a><span>|</span><label class="collapse" for="c-37242166">[-]</label><label class="expand" for="c-37242166">[4 more]</label></div><br/><div class="children"><div class="content">Raytracing isn&#x27;t a thing no matter how much nvidia wants to push it. The performance penalty is too big for what amounts to something that takes a trained eye to notice. AI-resolution scaling is nice to have on lower end devices but the max resolution people actually use is 4k and I can only think of VR where having more than 4k would be nice to have.<p>My main gripe is that at 4k resolution, top of the line GPUs shouldn&#x27;t be using AI frame scaling to get decent fps unless you are taking the raytracing penalty for funsies.</div><br/><div id="37242350" class="c"><input type="checkbox" id="c-37242350" checked=""/><div class="controls bullet"><span class="by">TechnicolorByte</span><span>|</span><a href="#37241732">root</a><span>|</span><a href="#37242166">parent</a><span>|</span><a href="#37246176">next</a><span>|</span><label class="collapse" for="c-37242350">[-]</label><label class="expand" for="c-37242350">[1 more]</label></div><br/><div class="children"><div class="content">Feels like this comment is stuck in 2019 or something. Have you seen DLSS3.5 announced yesterday with ray reconstruction? Have you seen path tracing in CP2077?<p>Seems like you’re really dismissing the massive speed ups these past few years. Agreed that ray tracing in games is only at the beginning. A lot of that is gated by the consoles&#x2F;AMD but that’s generally how it goes. Would love to see Nvidia in one of the powerful consoles to accelerate adoption of these technologies.</div><br/></div></div><div id="37246176" class="c"><input type="checkbox" id="c-37246176" checked=""/><div class="controls bullet"><span class="by">redox99</span><span>|</span><a href="#37241732">root</a><span>|</span><a href="#37242166">parent</a><span>|</span><a href="#37242350">prev</a><span>|</span><a href="#37243314">next</a><span>|</span><label class="collapse" for="c-37246176">[-]</label><label class="expand" for="c-37246176">[1 more]</label></div><br/><div class="children"><div class="content">This comment will age like milk, when in a few years (nvidia 50 series I&#x27;d say) path tracing becomes the norm for high end gaming.</div><br/></div></div><div id="37243314" class="c"><input type="checkbox" id="c-37243314" checked=""/><div class="controls bullet"><span class="by">broodbucket</span><span>|</span><a href="#37241732">root</a><span>|</span><a href="#37242166">parent</a><span>|</span><a href="#37246176">prev</a><span>|</span><a href="#37242108">next</a><span>|</span><label class="collapse" for="c-37243314">[-]</label><label class="expand" for="c-37243314">[1 more]</label></div><br/><div class="children"><div class="content">Agree on raytracing, disagree on upscaling.  DLSS&#x2F;FSR are gamechangers.  They do annoyingly muddy the waters for all the claims of &quot;we run X game at Y FPS on Z resolution&quot; though.</div><br/></div></div></div></div><div id="37242108" class="c"><input type="checkbox" id="c-37242108" checked=""/><div class="controls bullet"><span class="by">epolanski</span><span>|</span><a href="#37241732">root</a><span>|</span><a href="#37241839">parent</a><span>|</span><a href="#37242166">prev</a><span>|</span><a href="#37241853">next</a><span>|</span><label class="collapse" for="c-37242108">[-]</label><label class="expand" for="c-37242108">[4 more]</label></div><br/><div class="children"><div class="content">Raw performance isn&#x27;t increasing much, price&#x2F;performance under the 700$ has barely increased both now and in 2000 series.</div><br/><div id="37245955" class="c"><input type="checkbox" id="c-37245955" checked=""/><div class="controls bullet"><span class="by">paulmd</span><span>|</span><a href="#37241732">root</a><span>|</span><a href="#37242108">parent</a><span>|</span><a href="#37242201">next</a><span>|</span><label class="collapse" for="c-37245955">[-]</label><label class="expand" for="c-37245955">[1 more]</label></div><br/><div class="children"><div class="content">In a world where transistor-per-$ growth is running at most 10-20% per generation, you have to get more out of the transistors you have, or else prices go up. Or both.<p>So raw performance has stagnated and gains have been concentrated in things like DLSS 2.5 that let you get native quality at a 30% speedup or better than native DLAA at 0% speedup, or FSR2 Quality level quality at 50-70% speedup. Cause that gets you more performance out of a small increase of transistors&#x2F;cost.</div><br/></div></div><div id="37242201" class="c"><input type="checkbox" id="c-37242201" checked=""/><div class="controls bullet"><span class="by">cma</span><span>|</span><a href="#37241732">root</a><span>|</span><a href="#37242108">parent</a><span>|</span><a href="#37245955">prev</a><span>|</span><a href="#37241853">next</a><span>|</span><label class="collapse" for="c-37242201">[-]</label><label class="expand" for="c-37242201">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a combination of algorithms and hardware, but raytracing has gone from path traced quake 1 to path traced Cyberpunk 2077 in just a few years.  The raytracing side of things hardware wise has doubled in perf for the same tier card each generation.</div><br/><div id="37243176" class="c"><input type="checkbox" id="c-37243176" checked=""/><div class="controls bullet"><span class="by">epolanski</span><span>|</span><a href="#37241732">root</a><span>|</span><a href="#37242201">parent</a><span>|</span><a href="#37241853">next</a><span>|</span><label class="collapse" for="c-37243176">[-]</label><label class="expand" for="c-37243176">[1 more]</label></div><br/><div class="children"><div class="content">Yes, the RT part did improve but the raw part not much.<p>Thus only gamers that care about RT and only in the games that make a good use of it (virtually none) have any serious benefit.</div><br/></div></div></div></div></div></div><div id="37241853" class="c"><input type="checkbox" id="c-37241853" checked=""/><div class="controls bullet"><span class="by">solardev</span><span>|</span><a href="#37241732">root</a><span>|</span><a href="#37241839">parent</a><span>|</span><a href="#37242108">prev</a><span>|</span><a href="#37241881">next</a><span>|</span><label class="collapse" for="c-37241853">[-]</label><label class="expand" for="c-37241853">[12 more]</label></div><br/><div class="children"><div class="content">Gamers don&#x27;t have datacenter budgets</div><br/><div id="37241934" class="c"><input type="checkbox" id="c-37241934" checked=""/><div class="controls bullet"><span class="by">ancientworldnow</span><span>|</span><a href="#37241732">root</a><span>|</span><a href="#37241853">parent</a><span>|</span><a href="#37241967">next</a><span>|</span><label class="collapse" for="c-37241934">[-]</label><label class="expand" for="c-37241934">[9 more]</label></div><br/><div class="children"><div class="content">Gamers like to ignore inflation and increasing fab costs and pretend cards should cost the same forever with double performance gains every 1.5 years.</div><br/><div id="37244484" class="c"><input type="checkbox" id="c-37244484" checked=""/><div class="controls bullet"><span class="by">solardev</span><span>|</span><a href="#37241732">root</a><span>|</span><a href="#37241934">parent</a><span>|</span><a href="#37242050">next</a><span>|</span><label class="collapse" for="c-37244484">[-]</label><label class="expand" for="c-37244484">[2 more]</label></div><br/><div class="children"><div class="content">Why do GPUs get so much more expensive compared to the rest of the system? CPUs, hard drives, prebuilt systems, laptops etc. haven&#x27;t gotten ridiculously more expensive.<p>It used to be that $200 would get you a low-range GPU, $400 a midrange, and $600 a pretty darned good one. The 1070 launched at $379 (or $480 in 2023 dollars), the 2070 at $499, the 3070 at $499, then all of a sudden the 4070 now is $599. That&#x27;s a big difference, even accounting for inflation.<p>The 1080 Ti was $699, an already-unfathomable price back then that cost more than a whole console setup. Today? The 4080 is $1200. That&#x27;s often more than the rest of the system put together.</div><br/><div id="37245869" class="c"><input type="checkbox" id="c-37245869" checked=""/><div class="controls bullet"><span class="by">paulmd</span><span>|</span><a href="#37241732">root</a><span>|</span><a href="#37244484">parent</a><span>|</span><a href="#37242050">next</a><span>|</span><label class="collapse" for="c-37245869">[-]</label><label class="expand" for="c-37245869">[1 more]</label></div><br/><div class="children"><div class="content">It’s because CPUs tend to be fundamentally limited in the ways they can efficiently utilize transistors to scale performance, by things like cache latency, reorder depth, branch prediction, etc. While gpus have always been god’s strongest soldier for putting transistors on silicon scalably. They were the perfect machine for a world where transistors per dollar doubled every 18 months.<p>On the other hand now that it’s stopped, so has raw performance scaling. There was a few generations of cleanup, but you can’t squeeze blood from a stone forever. Maxwell arguably cut too far and pascal had to start adding functionality back. Gpus are like e-cores, large powerful cores mean you get fewer of them and that often works out to a lower PPA. There aren’t many opportunities for cool tricks and the model doesn’t favor using lots of area. The coding is written for extreme parallelism already, so, that’s not a problem, it’s inherent to the platform.<p>Transistor per $ growth hasn’t <i>completely</i> stopped but it’s certainly nowhere near what it was 10 years ago, even if you factor in things like packaging&#x2F;stacking the total wafer area still runs up a big bill that offset most of the density gains. And that’s what we’ve been seeing over the last 10 years in gpus too.  4070 is about the same area and cutdown as GTX 1070 but wafers cost like 8x as much.<p>What you have to do in this operating regime is find ways to get more performance <i>per transistor</i> - and that’s exactly what Jensen made a big bet on 5 years ago with dlss. 7% more transistors that with DLSS 2.5 give 30% speedup at native quality and 50-70% speedup at iso-quality with FSR2 Quality mode.<p>That’s what the future looks like - rewriting your applications to take advantage of new accelerators that provide large speedups. And the rewriting is very minimal for any application that uses TAAU already. It sucks but if cost&#x2F;transistor is not going to come down you have to get more out of the transistors you have. Work smarter not harder.</div><br/></div></div></div></div><div id="37242050" class="c"><input type="checkbox" id="c-37242050" checked=""/><div class="controls bullet"><span class="by">Mountain_Skies</span><span>|</span><a href="#37241732">root</a><span>|</span><a href="#37241934">parent</a><span>|</span><a href="#37244484">prev</a><span>|</span><a href="#37241967">next</a><span>|</span><label class="collapse" for="c-37242050">[-]</label><label class="expand" for="c-37242050">[6 more]</label></div><br/><div class="children"><div class="content">For much of tech hardware world, declining costs and increasing performance have been the general trends for as long as most of us have been alive.</div><br/><div id="37242915" class="c"><input type="checkbox" id="c-37242915" checked=""/><div class="controls bullet"><span class="by">sgarman</span><span>|</span><a href="#37241732">root</a><span>|</span><a href="#37242050">parent</a><span>|</span><a href="#37241967">next</a><span>|</span><label class="collapse" for="c-37242915">[-]</label><label class="expand" for="c-37242915">[5 more]</label></div><br/><div class="children"><div class="content">Off the top of my head the only thing I can think of that did that was TVs.</div><br/><div id="37246107" class="c"><input type="checkbox" id="c-37246107" checked=""/><div class="controls bullet"><span class="by">distances</span><span>|</span><a href="#37241732">root</a><span>|</span><a href="#37242915">parent</a><span>|</span><a href="#37244676">next</a><span>|</span><label class="collapse" for="c-37246107">[-]</label><label class="expand" for="c-37246107">[1 more]</label></div><br/><div class="children"><div class="content">As far as I can tell computers are still cheaper than they were in the 90s. And that&#x27;s in absolute numbers, not even accounting for inflation.</div><br/></div></div><div id="37244676" class="c"><input type="checkbox" id="c-37244676" checked=""/><div class="controls bullet"><span class="by">HDThoreaun</span><span>|</span><a href="#37241732">root</a><span>|</span><a href="#37242915">parent</a><span>|</span><a href="#37246107">prev</a><span>|</span><a href="#37243932">next</a><span>|</span><label class="collapse" for="c-37244676">[-]</label><label class="expand" for="c-37244676">[2 more]</label></div><br/><div class="children"><div class="content">CPU&#x27;s are cheaper adjusted for inflation before even considering performance. Ram and SSDs are much much cheaper than they were 5 years ago.</div><br/><div id="37245898" class="c"><input type="checkbox" id="c-37245898" checked=""/><div class="controls bullet"><span class="by">paulmd</span><span>|</span><a href="#37241732">root</a><span>|</span><a href="#37244676">parent</a><span>|</span><a href="#37243932">next</a><span>|</span><label class="collapse" for="c-37245898">[-]</label><label class="expand" for="c-37245898">[1 more]</label></div><br/><div class="children"><div class="content">RAM was much cheaper 7 years ago than 5 years ago. There was another DRAM cartel action and prices tripled in less than 6 months back in 2017.</div><br/></div></div></div></div><div id="37243932" class="c"><input type="checkbox" id="c-37243932" checked=""/><div class="controls bullet"><span class="by">buzzerbetrayed</span><span>|</span><a href="#37241732">root</a><span>|</span><a href="#37242915">parent</a><span>|</span><a href="#37244676">prev</a><span>|</span><a href="#37241967">next</a><span>|</span><label class="collapse" for="c-37243932">[-]</label><label class="expand" for="c-37243932">[1 more]</label></div><br/><div class="children"><div class="content">Personal computers have plummeted in price over the decades</div><br/></div></div></div></div></div></div></div></div><div id="37241967" class="c"><input type="checkbox" id="c-37241967" checked=""/><div class="controls bullet"><span class="by">samspenc</span><span>|</span><a href="#37241732">root</a><span>|</span><a href="#37241853">parent</a><span>|</span><a href="#37241934">prev</a><span>|</span><a href="#37241950">next</a><span>|</span><label class="collapse" for="c-37241967">[-]</label><label class="expand" for="c-37241967">[1 more]</label></div><br/><div class="children"><div class="content">I think both this comment and GP comment are true in their own ways. Nvidia is still pushing the gaming &#x2F; 3D industry faster than its competitors and I would still recommend an Nvidia card for reliability and performance over others.<p>BUT that comes at a price - Nvidia consumer chips are also notoriously expensive, but if you want best-of-breed for gaming, it does come at a price.<p>I am hoping that AMD and Intel will be able to compete with Nvidia someday but I&#x27;m not holding my breath.</div><br/></div></div></div></div></div></div><div id="37241881" class="c"><input type="checkbox" id="c-37241881" checked=""/><div class="controls bullet"><span class="by">unpopularopp</span><span>|</span><a href="#37241732">parent</a><span>|</span><a href="#37241839">prev</a><span>|</span><a href="#37241788">next</a><span>|</span><label class="collapse" for="c-37241881">[-]</label><label class="expand" for="c-37241881">[1 more]</label></div><br/><div class="children"><div class="content">I actually have  current gen GPUs from all 3 manufacturers  through my job and I&#x27;m glad there are choices now but I&#x27;d still recommend Nvidia over AMD or Intel to anyone. Of course it depends on the budget, the games you play etc. but DLSS alone is such a difference that AMD still couldn&#x27;t catch up with. I really hope Starfield will deliver because that will be the first game with FSR3.0 and introducing the technology, yet DLSS3.5 was just revealed yesterday. It&#x27;s a huge gamble for sure going all in on Starfield but tbh that&#x27;s one of the hypest game of the year so worth it. And Intel is nowhere near that (apart from the price and getting 16GB for cheap)</div><br/></div></div><div id="37241788" class="c"><input type="checkbox" id="c-37241788" checked=""/><div class="controls bullet"><span class="by">FirmwareBurner</span><span>|</span><a href="#37241732">parent</a><span>|</span><a href="#37241881">prev</a><span>|</span><a href="#37245866">next</a><span>|</span><label class="collapse" for="c-37241788">[-]</label><label class="expand" for="c-37241788">[4 more]</label></div><br/><div class="children"><div class="content">Intel has entered the chat. If you wanna game on  abudget with lots of VRAM go for A750 or A770.</div><br/><div id="37241817" class="c"><input type="checkbox" id="c-37241817" checked=""/><div class="controls bullet"><span class="by">bozhark</span><span>|</span><a href="#37241732">root</a><span>|</span><a href="#37241788">parent</a><span>|</span><a href="#37242101">next</a><span>|</span><label class="collapse" for="c-37241817">[-]</label><label class="expand" for="c-37241817">[2 more]</label></div><br/><div class="children"><div class="content">Intel has left the chat.</div><br/><div id="37241840" class="c"><input type="checkbox" id="c-37241840" checked=""/><div class="controls bullet"><span class="by">FirmwareBurner</span><span>|</span><a href="#37241732">root</a><span>|</span><a href="#37241817">parent</a><span>|</span><a href="#37242101">next</a><span>|</span><label class="collapse" for="c-37241840">[-]</label><label class="expand" for="c-37241840">[1 more]</label></div><br/><div class="children"><div class="content">Intel is very much in the game. Every of their recent big driver update ads double digit performance boosts on AAA titles.</div><br/></div></div></div></div></div></div><div id="37245866" class="c"><input type="checkbox" id="c-37245866" checked=""/><div class="controls bullet"><span class="by">disambiguation</span><span>|</span><a href="#37241732">parent</a><span>|</span><a href="#37241788">prev</a><span>|</span><a href="#37241868">next</a><span>|</span><label class="collapse" for="c-37245866">[-]</label><label class="expand" for="c-37245866">[1 more]</label></div><br/><div class="children"><div class="content">On the flip side, I often wonder if the current AI revolution would have stalled if not for the mature and abundant supply of high powered graphics cards that just happen to also be great for ML.<p>The gamers paved the way!</div><br/></div></div><div id="37241868" class="c"><input type="checkbox" id="c-37241868" checked=""/><div class="controls bullet"><span class="by">fnordpiglet</span><span>|</span><a href="#37241732">parent</a><span>|</span><a href="#37245866">prev</a><span>|</span><a href="#37241831">next</a><span>|</span><label class="collapse" for="c-37241868">[-]</label><label class="expand" for="c-37241868">[3 more]</label></div><br/><div class="children"><div class="content">Well, they still make gamer cards. As a company with more than one employee they are able to multitask, and the knock on benefits of all the investment will improving their gaming products as well. I think there are a fair amount of dual use cards being sold - I know I’ve got a 4090 that I use for local AI stuff, and it renders RTX Witcher 3 like a beast.</div><br/><div id="37244683" class="c"><input type="checkbox" id="c-37244683" checked=""/><div class="controls bullet"><span class="by">HDThoreaun</span><span>|</span><a href="#37241732">root</a><span>|</span><a href="#37241868">parent</a><span>|</span><a href="#37241831">next</a><span>|</span><label class="collapse" for="c-37244683">[-]</label><label class="expand" for="c-37244683">[2 more]</label></div><br/><div class="children"><div class="content">Basically no one can afford a 4080 let alone a 4090. Even 4070 is out of reach for many.</div><br/><div id="37245276" class="c"><input type="checkbox" id="c-37245276" checked=""/><div class="controls bullet"><span class="by">fnordpiglet</span><span>|</span><a href="#37241732">root</a><span>|</span><a href="#37244683">parent</a><span>|</span><a href="#37241831">next</a><span>|</span><label class="collapse" for="c-37245276">[-]</label><label class="expand" for="c-37245276">[1 more]</label></div><br/><div class="children"><div class="content">Ok?  But the other RTX models are fine - I know I had a 3070 until recently. Yes, there is a continuum of models with progressively more power. That’s good - the high end blazes a trail for the low end.  The architecture that supports AI also support gaming. It’s the same overall architecture just different scales and price points. That’s good, it ensures enormous investment at the high end which is scaled down for different price points. If it were not for gaming and crypto and others driving money at nvidia they would have a lot less capital to dedicate towards improving the architecture. The fact they continue to drive forward real time ray tracing and other features is indicative of their continued focus on gaming.</div><br/></div></div></div></div></div></div><div id="37241831" class="c"><input type="checkbox" id="c-37241831" checked=""/><div class="controls bullet"><span class="by">beebeepka</span><span>|</span><a href="#37241732">parent</a><span>|</span><a href="#37241868">prev</a><span>|</span><a href="#37244132">next</a><span>|</span><label class="collapse" for="c-37241831">[-]</label><label class="expand" for="c-37241831">[5 more]</label></div><br/><div class="children"><div class="content">When was that? Surely it must have been at least a decade before the GTX 970 &quot;4GB&quot; but maybe after all the driver cheating in the late 90s and early 2000s.<p>I no longer buy nvidia hardware but I do enjoy stock price getting higher. I just wish I had the sense to buy more, a lot more, stock when it was much cheaper. How does a chicken shit like me make big  money :(</div><br/><div id="37245922" class="c"><input type="checkbox" id="c-37245922" checked=""/><div class="controls bullet"><span class="by">paulmd</span><span>|</span><a href="#37241732">root</a><span>|</span><a href="#37241831">parent</a><span>|</span><a href="#37242821">next</a><span>|</span><label class="collapse" for="c-37245922">[-]</label><label class="expand" for="c-37245922">[1 more]</label></div><br/><div class="children"><div class="content">The tantrum over 970 has gotten even sillier since Microsoft used exactly this same bus structure (with fast&#x2F;slow segments) on the Xbox series X and S.<p>That’s a product designed and manufactured by AMD, eight?</div><br/></div></div><div id="37242821" class="c"><input type="checkbox" id="c-37242821" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#37241732">root</a><span>|</span><a href="#37241831">parent</a><span>|</span><a href="#37245922">prev</a><span>|</span><a href="#37241879">next</a><span>|</span><label class="collapse" for="c-37242821">[-]</label><label class="expand" for="c-37242821">[2 more]</label></div><br/><div class="children"><div class="content">The 970 was amazing for gaming; the 3.5GB problem was just for CUDA.</div><br/><div id="37243268" class="c"><input type="checkbox" id="c-37243268" checked=""/><div class="controls bullet"><span class="by">wincy</span><span>|</span><a href="#37241732">root</a><span>|</span><a href="#37242821">parent</a><span>|</span><a href="#37241879">next</a><span>|</span><label class="collapse" for="c-37243268">[-]</label><label class="expand" for="c-37243268">[1 more]</label></div><br/><div class="children"><div class="content">I literally just replaced my GTX 970 a week ago. Fantastic GPU, lasted me a good ten years. Baldur&#x27;s Gate 3 finally got me to update it, which it could run it but I dunno a new game got me excited. It ran Elden Ring just fine last year though.</div><br/></div></div></div></div><div id="37241879" class="c"><input type="checkbox" id="c-37241879" checked=""/><div class="controls bullet"><span class="by">grouchomarx</span><span>|</span><a href="#37241732">root</a><span>|</span><a href="#37241831">parent</a><span>|</span><a href="#37242821">prev</a><span>|</span><a href="#37244132">next</a><span>|</span><label class="collapse" for="c-37241879">[-]</label><label class="expand" for="c-37241879">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a tough game. Gotta have the guts to get in and stay in</div><br/></div></div></div></div></div></div><div id="37244132" class="c"><input type="checkbox" id="c-37244132" checked=""/><div class="controls bullet"><span class="by">ayakang31415</span><span>|</span><a href="#37241732">prev</a><span>|</span><a href="#37242267">next</a><span>|</span><label class="collapse" for="c-37244132">[-]</label><label class="expand" for="c-37244132">[6 more]</label></div><br/><div class="children"><div class="content">Their GPUs have been very performant for my research (DNN training). However, their VRAM could be much larger. In my mind CPU ram is very cheap (for 32GB, it is currently around $65). But their GPUs for DNN that I use oh HPC are always less than 32GB but the GPUs are very pricey. Does anyone know why they don&#x27;t increase their VRAM capacity so I can test models that require higher VRAM? Is VRAM considerably more expensive to attach to GPU versus CPU ram?</div><br/><div id="37244158" class="c"><input type="checkbox" id="c-37244158" checked=""/><div class="controls bullet"><span class="by">samspenc</span><span>|</span><a href="#37244132">parent</a><span>|</span><a href="#37244296">next</a><span>|</span><label class="collapse" for="c-37244158">[-]</label><label class="expand" for="c-37244158">[2 more]</label></div><br/><div class="children"><div class="content">Folks on Reddit&#x27;s &#x2F;r&#x2F;pcmasterrace have been discussing this for years - the consensus seems to be that Nvidia <i>could</i> add more VRAM to its GPUs without too much additional cost - but they don&#x27;t <i>want</i> to, in order to push higher spending businesses and consumers to buy their more expensive chips to get more VRAM at exponential higher costs.</div><br/><div id="37244223" class="c"><input type="checkbox" id="c-37244223" checked=""/><div class="controls bullet"><span class="by">AnotherGoodName</span><span>|</span><a href="#37244132">root</a><span>|</span><a href="#37244158">parent</a><span>|</span><a href="#37244296">next</a><span>|</span><label class="collapse" for="c-37244223">[-]</label><label class="expand" for="c-37244223">[1 more]</label></div><br/><div class="children"><div class="content">Yeah their high VRAM cards (80gb h100) cost $40k.<p>That&#x27;s their price differentiator. It&#x27;s the reason for their profits. nVidia is now &lt;20% gaming in terms of revenue and that gaming revenue has much tighter margins than the 80% datacenter&#x2F;professional market revenue which is almost all profit sine 80gb ram doesn&#x27;t cost $40k more.<p>So yes it&#x27;d be nice if nVidia made it so there was no reason for their $40k AI cards to exist. But they aren&#x27;t going to do that.</div><br/></div></div></div></div><div id="37244296" class="c"><input type="checkbox" id="c-37244296" checked=""/><div class="controls bullet"><span class="by">eldenring</span><span>|</span><a href="#37244132">parent</a><span>|</span><a href="#37244158">prev</a><span>|</span><a href="#37244188">next</a><span>|</span><label class="collapse" for="c-37244296">[-]</label><label class="expand" for="c-37244296">[2 more]</label></div><br/><div class="children"><div class="content">Yes it is quite expensive. The issue is memory bandwidth is a lot more constrained when youre routing to hundreds or thousands of cores instead of the handful you need to support on a CPU.</div><br/><div id="37244337" class="c"><input type="checkbox" id="c-37244337" checked=""/><div class="controls bullet"><span class="by">ayakang31415</span><span>|</span><a href="#37244132">root</a><span>|</span><a href="#37244296">parent</a><span>|</span><a href="#37244188">next</a><span>|</span><label class="collapse" for="c-37244337">[-]</label><label class="expand" for="c-37244337">[1 more]</label></div><br/><div class="children"><div class="content">So the higher cost from higher VRAM comes from the implementation of higher bandwidth to accommodate more data flow because there are more cores versus CPU?</div><br/></div></div></div></div><div id="37244188" class="c"><input type="checkbox" id="c-37244188" checked=""/><div class="controls bullet"><span class="by">shsixhehgf</span><span>|</span><a href="#37244132">parent</a><span>|</span><a href="#37244296">prev</a><span>|</span><a href="#37242267">next</a><span>|</span><label class="collapse" for="c-37244188">[-]</label><label class="expand" for="c-37244188">[1 more]</label></div><br/><div class="children"><div class="content">You’re looking at it as if there’s some sort of technical bottleneck. Is not, it’s business. VRAM capacity is how they segregate data center&#x2F;AI workloads versus gaming.<p>It will be this way until they get a competitor.</div><br/></div></div></div></div><div id="37242267" class="c"><input type="checkbox" id="c-37242267" checked=""/><div class="controls bullet"><span class="by">anjel</span><span>|</span><a href="#37244132">prev</a><span>|</span><a href="#37246167">next</a><span>|</span><label class="collapse" for="c-37242267">[-]</label><label class="expand" for="c-37242267">[8 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve seen a regular stream of reports on HN about people &quot;sort of&quot; getting AI done on laptops and non and lowly GPU machines. Is it unreasonable or far-fetched to imagine that someone figures out how to efficiently get it all done without GPUs and pull the rug out from under Nvidia?</div><br/><div id="37242311" class="c"><input type="checkbox" id="c-37242311" checked=""/><div class="controls bullet"><span class="by">SpacePortKnight</span><span>|</span><a href="#37242267">parent</a><span>|</span><a href="#37243884">next</a><span>|</span><label class="collapse" for="c-37242311">[-]</label><label class="expand" for="c-37242311">[2 more]</label></div><br/><div class="children"><div class="content">Just like existence of MariaDB does not prevent Snowflake from being worth $50B, just being good enough on laptop is not enough to replace the need for the cutting edge.</div><br/></div></div><div id="37243884" class="c"><input type="checkbox" id="c-37243884" checked=""/><div class="controls bullet"><span class="by">saiojd</span><span>|</span><a href="#37242267">parent</a><span>|</span><a href="#37242311">prev</a><span>|</span><a href="#37242312">next</a><span>|</span><label class="collapse" for="c-37243884">[-]</label><label class="expand" for="c-37243884">[1 more]</label></div><br/><div class="children"><div class="content">If this happens we will just get more things done with the same amount of compute (see: Blinn&#x27;s law). The demand for GPUs does not really come from algorithmic compute requirements but from social expectation of progress in the field of AI. People will use all the compute they can get doing research using the budget they are given. What matters is how this budget is set.</div><br/></div></div><div id="37242312" class="c"><input type="checkbox" id="c-37242312" checked=""/><div class="controls bullet"><span class="by">lsh123</span><span>|</span><a href="#37242267">parent</a><span>|</span><a href="#37243884">prev</a><span>|</span><a href="#37243786">next</a><span>|</span><label class="collapse" for="c-37242312">[-]</label><label class="expand" for="c-37242312">[1 more]</label></div><br/><div class="children"><div class="content">Training is very expensive and requires GPUs. What you read about is running trained model on consumer devices (even phones!).</div><br/></div></div><div id="37243786" class="c"><input type="checkbox" id="c-37243786" checked=""/><div class="controls bullet"><span class="by">creer</span><span>|</span><a href="#37242267">parent</a><span>|</span><a href="#37242312">prev</a><span>|</span><a href="#37242561">next</a><span>|</span><label class="collapse" for="c-37243786">[-]</label><label class="expand" for="c-37243786">[1 more]</label></div><br/><div class="children"><div class="content">The current giants have shown that &quot;it&quot; can be done. From now on we can reasonnably hope for massive progress in efficency at the low end - as well as massive capability improvements at the high end. That goes both ways, probably.</div><br/></div></div><div id="37242561" class="c"><input type="checkbox" id="c-37242561" checked=""/><div class="controls bullet"><span class="by">bob1029</span><span>|</span><a href="#37242267">parent</a><span>|</span><a href="#37243786">prev</a><span>|</span><a href="#37242348">next</a><span>|</span><label class="collapse" for="c-37242561">[-]</label><label class="expand" for="c-37242561">[1 more]</label></div><br/><div class="children"><div class="content">I have an options strategy that is riding on this possibility right now.<p>All you have to do is take 5 seconds in a typical code base to determine that the way we write software today isn&#x27;t exactly... ideal. Given another 6-12 months, I cannot comprehend another ~OOM not being extracted somewhere simply by making the software better.</div><br/></div></div><div id="37242348" class="c"><input type="checkbox" id="c-37242348" checked=""/><div class="controls bullet"><span class="by">FreshStart</span><span>|</span><a href="#37242267">parent</a><span>|</span><a href="#37242561">prev</a><span>|</span><a href="#37246167">next</a><span>|</span><label class="collapse" for="c-37242348">[-]</label><label class="expand" for="c-37242348">[1 more]</label></div><br/><div class="children"><div class="content">Let&#x27;s assume for a moment you could sort of trade parallel computation for vast space, fast search and retrieval. So in this hypotheticals computational theory, you could build a lookup machine from CPUs and ssds.. squeezing the parallel cores into one CPU, by squeezing the shaders running into a million hashes.. And before you know it your simulating a micro verse trying desperately to find out how to avoid climate change. What if God hates recursion?</div><br/></div></div></div></div><div id="37246167" class="c"><input type="checkbox" id="c-37246167" checked=""/><div class="controls bullet"><span class="by">smcleod</span><span>|</span><a href="#37242267">prev</a><span>|</span><a href="#37244259">next</a><span>|</span><label class="collapse" for="c-37246167">[-]</label><label class="expand" for="c-37246167">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s such a shame that these big companies are allowed to make so much profit, &#x27;the shareholder is the customer&#x27; only furthers disproportionate wealth distribution.</div><br/></div></div><div id="37244259" class="c"><input type="checkbox" id="c-37244259" checked=""/><div class="controls bullet"><span class="by">synaesthesisx</span><span>|</span><a href="#37246167">prev</a><span>|</span><a href="#37242867">next</a><span>|</span><label class="collapse" for="c-37244259">[-]</label><label class="expand" for="c-37244259">[2 more]</label></div><br/><div class="children"><div class="content">I’ve been a longtime Nvidia investor (since ~2014 or so) and have no plans on selling anytime soon. Their market dominance will be tough to unseat, and the only other company making strides in silicon is Apple.</div><br/><div id="37244280" class="c"><input type="checkbox" id="c-37244280" checked=""/><div class="controls bullet"><span class="by">andromeduck</span><span>|</span><a href="#37244259">parent</a><span>|</span><a href="#37242867">next</a><span>|</span><label class="collapse" for="c-37244280">[-]</label><label class="expand" for="c-37244280">[1 more]</label></div><br/><div class="children"><div class="content">Isn&#x27;t Google the main competititor in AI training? Maybe tenstorrent, rivos &amp; others too.</div><br/></div></div></div></div><div id="37242867" class="c"><input type="checkbox" id="c-37242867" checked=""/><div class="controls bullet"><span class="by">parhamn</span><span>|</span><a href="#37244259">prev</a><span>|</span><a href="#37241644">next</a><span>|</span><label class="collapse" for="c-37242867">[-]</label><label class="expand" for="c-37242867">[1 more]</label></div><br/><div class="children"><div class="content">A tangent to this I&#x27;ve been thinking about quite a bit is how big a moat drivers are to the software&#x2F;hardware ecosystem.<p>They&#x27;re a major moat&#x2F;hurdle (depending on your perspective) for operating systems, new hardware platforms, graphics cards, custom chips, and more.<p>It&#x27;s interesting to think that we&#x27;re not _that_ far from being able to generate decent drivers for things on the fly with the latest code gen advancements. Relevant to this, that could reduce the monopolies here, but perhaps as interesting is we can have more new complete OSes with more resources allocated to the user experience vs hardware compatibility.</div><br/></div></div><div id="37241644" class="c"><input type="checkbox" id="c-37241644" checked=""/><div class="controls bullet"><span class="by">gigatexal</span><span>|</span><a href="#37242867">prev</a><span>|</span><a href="#37243570">next</a><span>|</span><label class="collapse" for="c-37241644">[-]</label><label class="expand" for="c-37241644">[1 more]</label></div><br/><div class="children"><div class="content">A blockbuster quarter for sure with eps up 854%.</div><br/></div></div><div id="37243570" class="c"><input type="checkbox" id="c-37243570" checked=""/><div class="controls bullet"><span class="by">bdangubic</span><span>|</span><a href="#37241644">prev</a><span>|</span><a href="#37245367">next</a><span>|</span><label class="collapse" for="c-37243570">[-]</label><label class="expand" for="c-37243570">[1 more]</label></div><br/><div class="children"><div class="content">when everyone is digging for gold you want to be the one selling shovels</div><br/></div></div><div id="37245367" class="c"><input type="checkbox" id="c-37245367" checked=""/><div class="controls bullet"><span class="by">omnitron</span><span>|</span><a href="#37243570">prev</a><span>|</span><a href="#37245363">next</a><span>|</span><label class="collapse" for="c-37245367">[-]</label><label class="expand" for="c-37245367">[1 more]</label></div><br/><div class="children"><div class="content">I thought Nvidia just make graphics cards for games, how did they end up making general purpose CPUs like Intel that actually is more powerful than Intel</div><br/></div></div><div id="37245363" class="c"><input type="checkbox" id="c-37245363" checked=""/><div class="controls bullet"><span class="by">omnitron</span><span>|</span><a href="#37245367">prev</a><span>|</span><a href="#37242527">next</a><span>|</span><label class="collapse" for="c-37245363">[-]</label><label class="expand" for="c-37245363">[1 more]</label></div><br/><div class="children"><div class="content">Did Nvidia get lucky even though Intel was bigger at the time or could it have been predicted that AIs would work better in GPUs?</div><br/></div></div><div id="37242527" class="c"><input type="checkbox" id="c-37242527" checked=""/><div class="controls bullet"><span class="by">nabla9</span><span>|</span><a href="#37245363">prev</a><span>|</span><a href="#37245821">next</a><span>|</span><label class="collapse" for="c-37242527">[-]</label><label class="expand" for="c-37242527">[1 more]</label></div><br/><div class="children"><div class="content">Their revenues are seriously supply restricted.  ~2x revenue if chip manufacturing could keep up with demand. Packaging seems to be the bottleneck just now.</div><br/></div></div><div id="37245821" class="c"><input type="checkbox" id="c-37245821" checked=""/><div class="controls bullet"><span class="by">holmesch</span><span>|</span><a href="#37242527">prev</a><span>|</span><a href="#37242481">next</a><span>|</span><label class="collapse" for="c-37245821">[-]</label><label class="expand" for="c-37245821">[1 more]</label></div><br/><div class="children"><div class="content">2024?</div><br/></div></div><div id="37242313" class="c"><input type="checkbox" id="c-37242313" checked=""/><div class="controls bullet"><span class="by">nathias</span><span>|</span><a href="#37242481">prev</a><span>|</span><a href="#37243756">next</a><span>|</span><label class="collapse" for="c-37242313">[-]</label><label class="expand" for="c-37242313">[1 more]</label></div><br/><div class="children"><div class="content">selling shovels for a few different gold rushes seems to be profitable</div><br/></div></div><div id="37243756" class="c"><input type="checkbox" id="c-37243756" checked=""/><div class="controls bullet"><span class="by">pstuart</span><span>|</span><a href="#37242313">prev</a><span>|</span><a href="#37241787">next</a><span>|</span><label class="collapse" for="c-37243756">[-]</label><label class="expand" for="c-37243756">[1 more]</label></div><br/><div class="children"><div class="content">Is there any scuttlebutt on AMD investing in making their GPUs&#x2F;ROCm work as seamlessly with the standard ML tooling as Nvidia?<p>It seems like it would be &quot;easier&quot; now that the path has been cleared and all they have to do is reach parity.</div><br/></div></div><div id="37241707" class="c"><input type="checkbox" id="c-37241707" checked=""/><div class="controls bullet"><span class="by">rightbyte</span><span>|</span><a href="#37241787">prev</a><span>|</span><a href="#37241956">next</a><span>|</span><label class="collapse" for="c-37241707">[-]</label><label class="expand" for="c-37241707">[1 more]</label></div><br/><div class="children"><div class="content">Seems like the shovel seller is on top of this AI thing?</div><br/></div></div><div id="37241956" class="c"><input type="checkbox" id="c-37241956" checked=""/><div class="controls bullet"><span class="by">marricks</span><span>|</span><a href="#37241707">prev</a><span>|</span><a href="#37242123">next</a><span>|</span><label class="collapse" for="c-37241956">[-]</label><label class="expand" for="c-37241956">[7 more]</label></div><br/><div class="children"><div class="content">Why, and what does it mean, for Nvidia to announce fiscal results a year ahead of time.<p>Is it just promise to sell chips in advance, so that&#x27;s how far it&#x27;s booked, do they own a Time Machine...?</div><br/><div id="37242068" class="c"><input type="checkbox" id="c-37242068" checked=""/><div class="controls bullet"><span class="by">scrlk</span><span>|</span><a href="#37241956">parent</a><span>|</span><a href="#37242441">next</a><span>|</span><label class="collapse" for="c-37242068">[-]</label><label class="expand" for="c-37242068">[4 more]</label></div><br/><div class="children"><div class="content">Financial years are named by the calendar year that they end in, so FY24 is the financial year ending in 2024.</div><br/><div id="37242472" class="c"><input type="checkbox" id="c-37242472" checked=""/><div class="controls bullet"><span class="by">lotsofpulp</span><span>|</span><a href="#37241956">root</a><span>|</span><a href="#37242068">parent</a><span>|</span><a href="#37242441">next</a><span>|</span><label class="collapse" for="c-37242472">[-]</label><label class="expand" for="c-37242472">[3 more]</label></div><br/><div class="children"><div class="content">I have never seen it referred to as financial year until now, but I guess it makes sense too.  Fiscal year is the typically used term.</div><br/><div id="37242695" class="c"><input type="checkbox" id="c-37242695" checked=""/><div class="controls bullet"><span class="by">scrlk</span><span>|</span><a href="#37241956">root</a><span>|</span><a href="#37242472">parent</a><span>|</span><a href="#37243329">next</a><span>|</span><label class="collapse" for="c-37242695">[-]</label><label class="expand" for="c-37242695">[1 more]</label></div><br/><div class="children"><div class="content">Looks like it depends on where you are in the world. &quot;Financial year&quot; appears to be the preferred phrase over in the UK.</div><br/></div></div><div id="37243329" class="c"><input type="checkbox" id="c-37243329" checked=""/><div class="controls bullet"><span class="by">bobnamob</span><span>|</span><a href="#37241956">root</a><span>|</span><a href="#37242472">parent</a><span>|</span><a href="#37242695">prev</a><span>|</span><a href="#37242441">next</a><span>|</span><label class="collapse" for="c-37243329">[-]</label><label class="expand" for="c-37243329">[1 more]</label></div><br/><div class="children"><div class="content">Financial year is the common term in other locales (Australia for example)</div><br/></div></div></div></div></div></div><div id="37242441" class="c"><input type="checkbox" id="c-37242441" checked=""/><div class="controls bullet"><span class="by">danielmarkbruce</span><span>|</span><a href="#37241956">parent</a><span>|</span><a href="#37242068">prev</a><span>|</span><a href="#37242079">next</a><span>|</span><label class="collapse" for="c-37242441">[-]</label><label class="expand" for="c-37242441">[1 more]</label></div><br/><div class="children"><div class="content">They announced Q2 results, ending July 31. Their fiscal year is a little unusual, it ends at end of Jan. So their 2024 year ends Jan 31 2024.</div><br/></div></div><div id="37242079" class="c"><input type="checkbox" id="c-37242079" checked=""/><div class="controls bullet"><span class="by">epolanski</span><span>|</span><a href="#37241956">parent</a><span>|</span><a href="#37242441">prev</a><span>|</span><a href="#37242123">next</a><span>|</span><label class="collapse" for="c-37242079">[-]</label><label class="expand" for="c-37242079">[1 more]</label></div><br/><div class="children"><div class="content">Every company I know of estimates future revenue.<p>It&#x27;s not black magic, they have contracts in place and know both how many GPUs will be produced and sold give or take few %s.</div><br/></div></div></div></div><div id="37242123" class="c"><input type="checkbox" id="c-37242123" checked=""/><div class="controls bullet"><span class="by">steno132</span><span>|</span><a href="#37241956">prev</a><span>|</span><label class="collapse" for="c-37242123">[-]</label><label class="expand" for="c-37242123">[14 more]</label></div><br/><div class="children"><div class="content">Nvidia&#x27;s undervalued.<p>Once enterprise adoption of AI picks up, demand for chips will increase 2-3 times further.<p>I&#x27;m told Nvidia&#x27;s building their own fab in Southeast Asia over the next few years. This will massively boost their output.</div><br/><div id="37242549" class="c"><input type="checkbox" id="c-37242549" checked=""/><div class="controls bullet"><span class="by">qwytw</span><span>|</span><a href="#37242123">parent</a><span>|</span><a href="#37242225">next</a><span>|</span><label class="collapse" for="c-37242549">[-]</label><label class="expand" for="c-37242549">[1 more]</label></div><br/><div class="children"><div class="content">&gt; will increase 2-3 times further.<p>That and possibly way more than that is already priced in. Nvidia&#x27;s stock is extremely expensive not because of they are making now (which is not a lot relative to valuation, they just barely surpassed Intel this quarter in revenue) but because investors expect pretty much exponential growth over the next few years..</div><br/></div></div><div id="37242225" class="c"><input type="checkbox" id="c-37242225" checked=""/><div class="controls bullet"><span class="by">kccqzy</span><span>|</span><a href="#37242123">parent</a><span>|</span><a href="#37242549">prev</a><span>|</span><a href="#37242288">next</a><span>|</span><label class="collapse" for="c-37242225">[-]</label><label class="expand" for="c-37242225">[11 more]</label></div><br/><div class="children"><div class="content">It remains debatable whether mass enterprise adoption of AI would happen first, or Nvidia&#x27;s competitors coming up with equivalent chips would happen first.</div><br/><div id="37242444" class="c"><input type="checkbox" id="c-37242444" checked=""/><div class="controls bullet"><span class="by">haldujai</span><span>|</span><a href="#37242123">root</a><span>|</span><a href="#37242225">parent</a><span>|</span><a href="#37242421">next</a><span>|</span><label class="collapse" for="c-37242444">[-]</label><label class="expand" for="c-37242444">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s hard to imagine Nvidia will maintain what is right now effectively 100% market share for training forever, especially given the $ being thrown around.</div><br/></div></div><div id="37242421" class="c"><input type="checkbox" id="c-37242421" checked=""/><div class="controls bullet"><span class="by">danielmarkbruce</span><span>|</span><a href="#37242123">root</a><span>|</span><a href="#37242225">parent</a><span>|</span><a href="#37242444">prev</a><span>|</span><a href="#37242820">next</a><span>|</span><label class="collapse" for="c-37242421">[-]</label><label class="expand" for="c-37242421">[7 more]</label></div><br/><div class="children"><div class="content">On the surface, it&#x27;s not debatable. Enterprises are going full steam ahead on AI. Building out an ecosystem to challenge Nvidia seems like a decade long battle, if it&#x27;s even possible.</div><br/><div id="37242553" class="c"><input type="checkbox" id="c-37242553" checked=""/><div class="controls bullet"><span class="by">haldujai</span><span>|</span><a href="#37242123">root</a><span>|</span><a href="#37242421">parent</a><span>|</span><a href="#37242820">next</a><span>|</span><label class="collapse" for="c-37242553">[-]</label><label class="expand" for="c-37242553">[6 more]</label></div><br/><div class="children"><div class="content">What is full steam ahead for enterprises? It&#x27;s not like they&#x27;re throwing autoregressive LLMs into production any time soon.<p>In any case Nvidia is expecting to ship ~550k H100s in 2023, hardly enough to satisfy every user.<p>Tesla decided to in-house. TPUv4 and Gaudi2 exceeded A100 performance, they just never hit scale or the market and then Hopper added optimization for transformers rendering these chips relatively obsolete.<p>Nvidia&#x27;s lead is not unassailable and it seems incredibly unlikely that they would not face serious competition within the next 2-3 years given the $ being thrown around.</div><br/><div id="37242791" class="c"><input type="checkbox" id="c-37242791" checked=""/><div class="controls bullet"><span class="by">danielmarkbruce</span><span>|</span><a href="#37242123">root</a><span>|</span><a href="#37242553">parent</a><span>|</span><a href="#37242820">next</a><span>|</span><label class="collapse" for="c-37242791">[-]</label><label class="expand" for="c-37242791">[5 more]</label></div><br/><div class="children"><div class="content">Large enterprises are already putting them into production. I have direct experience with it.<p>It&#x27;s not unassailable. But it&#x27;s going to take a lot to make <i>any</i> difference to Nvidia&#x27;s volume or pricing, let alone a meaningful difference. They already face serious competitors in google and aws with TPU and inferentia, but those competitors are at a pretty big disadvantage for now (and others too). The cuda ecosystem is a big advantage. Nvidia has a lot of leverage with semi manufacturers because of volume. They spend way more on chip R&amp;D than their competitors in the space. They have brand recognition. You can buy and own Nvidia chips v tpu and inferentia. It&#x27;s... a tough road ahead for competitors.</div><br/><div id="37243107" class="c"><input type="checkbox" id="c-37243107" checked=""/><div class="controls bullet"><span class="by">haldujai</span><span>|</span><a href="#37242123">root</a><span>|</span><a href="#37242791">parent</a><span>|</span><a href="#37242820">next</a><span>|</span><label class="collapse" for="c-37243107">[-]</label><label class="expand" for="c-37243107">[4 more]</label></div><br/><div class="children"><div class="content">&gt; Large enterprises are already putting them into production. I have direct experience with it.<p>For what function have you experienced LLMs being used at significant scale in production right now? It seems unlikely most enterprises have built up sufficient technical know-how to run these workloads in-house already.<p>&gt; They already face serious competitors in google and aws with TPU and inferentia<p>TPUv4s aren&#x27;t widely available and are not competitive with Hopper. Inferentia isn&#x27;t for training and is also not competitive on throughput.<p>&gt; The cuda ecosystem is a big advantage.<p>Is it really though? A year ago it wasn&#x27;t the case (see TPUs). Nvidia hasn&#x27;t maintained a stranglehold on the software stack.<p>&gt; Nvidia has a lot of leverage with semi manufacturers because of volume.<p>With TSMC*. If we believe Pat Gelsinger, Intel is starting to catch-up and their roadmap would place them ahead of TSMC in H2 2024.<p>&gt; They have brand recognition. You can buy and own Nvidia chips v tpu and inferentia.<p>Intel, AMD and Google don&#x27;t have brand recognition? There isn&#x27;t a competitive alternative <i>today</i> for sale or rent, that doesn&#x27;t mean this can&#x27;t&#x2F;won&#x27;t change. It also doesn&#x27;t mean they won&#x27;t become available for enterprise purchase when we&#x27;re talking about 60B&#x2F;year in revenue.<p>&gt; It&#x27;s... a tough road ahead for competitors.<p>While hard I disagree that their moat is as wide as being touted. At the end of the day, whoever gets the most FLOPS, can deliver product faster and&#x2F;or is cheaper will win as long as it&#x27;s trivial to migrate workloads.<p>I really don&#x27;t believe anyone actually cares who the manufacturer is.</div><br/><div id="37243433" class="c"><input type="checkbox" id="c-37243433" checked=""/><div class="controls bullet"><span class="by">danielmarkbruce</span><span>|</span><a href="#37242123">root</a><span>|</span><a href="#37243107">parent</a><span>|</span><a href="#37242820">next</a><span>|</span><label class="collapse" for="c-37243433">[-]</label><label class="expand" for="c-37243433">[3 more]</label></div><br/><div class="children"><div class="content">Customer support. I&#x27;ve never seen so many people get up to speed so fast on something. It&#x27;s unlike anything ever.<p>Yep.<p>I believe so.<p>I don&#x27;t believe Pat.<p>With the relevant audience, Nvidia is the brand which is the strongest. Google could just drop support for TPU, AMD isn&#x27;t viewed as currently credible for people doing the work, nor Intel.<p>You may be right, only time will tell. I&#x27;ve been involved with GPU use for general purpose workloads since Cuda was launched. At every step of the way there was apparently credible competition at different layers of the stack just around the corner. That&#x27;s over 15 years. OpenCL, ASICs, FPGA, Intel this that and the other, AMD this that and the other. TPU. Others I&#x27;ve forgotten.</div><br/><div id="37243961" class="c"><input type="checkbox" id="c-37243961" checked=""/><div class="controls bullet"><span class="by">haldujai</span><span>|</span><a href="#37242123">root</a><span>|</span><a href="#37243433">parent</a><span>|</span><a href="#37242820">next</a><span>|</span><label class="collapse" for="c-37243961">[-]</label><label class="expand" for="c-37243961">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Customer support. I&#x27;ve never seen so many people get up to speed so fast on something. It&#x27;s unlike anything ever.<p>Are you saying that you&#x27;ve seen enterprises developing, training and running their own in-house LLMs from scratch directly on large (i.e. 100s to 1000s) GPU clusters, whether on-prem or cloud, for this to be relevant to Nvidia?<p>Pardon my skepticism but it seems odd that a generic Fortune 500 co has the in-house talent and will-power to manage large distributed training runs when much easier and cheaper alternatives like OpenAI&#x2F;open-source models or one of the Google&#x2F;MS&#x2F;AWS MLaaS options are available.<p>&gt; With the relevant audience, Nvidia is the brand which is the strongest. Google could just drop support for TPU, AMD isn&#x27;t viewed as currently credible for people doing the work, nor Intel.<p>I think we&#x27;re confusing some things here. Right now, there is no good alternative for anyone requiring H100s for loyalty to even matter, this could very easily change with the next generation of accelerator chips.<p>Intel had the strongest CPU &quot;brand&quot; for a while and enterprises&#x2F;datacenters readily switched to AMD when it became the better option.<p>&gt; You may be right, only time will tell. I&#x27;ve been involved with GPU use for general purpose workloads since Cuda was launched. At every step of the way there was apparently credible competition at different layers of the stack just around the corner. That&#x27;s over 15 years. OpenCL, ASICs, FPGA, Intel this that and the other, AMD this that and the other. TPU. Others I&#x27;ve forgotten.<p>The TAM, and profit margin, for enterprise-grade GPUs (or accelerators) is several orders of magnitude larger than it has ever been including the crypto craze.</div><br/><div id="37245628" class="c"><input type="checkbox" id="c-37245628" checked=""/><div class="controls bullet"><span class="by">danielmarkbruce</span><span>|</span><a href="#37242123">root</a><span>|</span><a href="#37243961">parent</a><span>|</span><a href="#37242820">next</a><span>|</span><label class="collapse" for="c-37245628">[-]</label><label class="expand" for="c-37245628">[1 more]</label></div><br/><div class="children"><div class="content">You seem to be moving the goalposts. First it was using in production, now it&#x27;s building foundation models.. But, to answer: Not foundation models (although, Bloomberg did that for another use case). Fine tuned versions of falcon, now llama 2, open assistant and others. They are running both the fine tuning (not that it&#x27;s much) and inference on A100s, inferentia and TPU. The skillset required to fine tune a model for a customer support use case is night and day from building a (good) foundation model.<p>Right now it doesn&#x27;t matter, but you are suggesting there will be real competition soon. I&#x27;m saying, it will matter.<p>Intel did have a great brand. And they proceeded to screw up and it caught up with them, but it took a long time. A company with a moat can destroy it with time and effort.<p>It is huge market. And it&#x27;s a huge lift to build a product that can compete with Nvidia at this point. I&#x27;d handicap it at 2-1 against someone being a real competitor within a decade.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="37242820" class="c"><input type="checkbox" id="c-37242820" checked=""/><div class="controls bullet"><span class="by">steno132</span><span>|</span><a href="#37242123">root</a><span>|</span><a href="#37242225">parent</a><span>|</span><a href="#37242421">prev</a><span>|</span><a href="#37242288">next</a><span>|</span><label class="collapse" for="c-37242820">[-]</label><label class="expand" for="c-37242820">[2 more]</label></div><br/><div class="children"><div class="content">There’s no competitor to Nvidia for the next 10 years.<p>They’ve got a monopoly. And with AI’s coming explosion, I’d wager 50&#x2F;50 odds Jensen becomes the world’s first trillionaire.</div><br/><div id="37243301" class="c"><input type="checkbox" id="c-37243301" checked=""/><div class="controls bullet"><span class="by">enos_feedler</span><span>|</span><a href="#37242123">root</a><span>|</span><a href="#37242820">parent</a><span>|</span><a href="#37242288">next</a><span>|</span><label class="collapse" for="c-37243301">[-]</label><label class="expand" for="c-37243301">[1 more]</label></div><br/><div class="children"><div class="content">this is a totally insane statement to make. 10 years? it will take at _most_ 2-3 years for the software and hardware ecosystem to rearrange around a competitive landscape. The only reason nvidia has a large time window of opportunity is because of the lead time required to create such a complex ecosystem and the &quot;suddenness&quot; of how meaningful particular category of workloads are (which nvidia happened to be good at, because... pixels)</div><br/></div></div></div></div></div></div><div id="37242288" class="c"><input type="checkbox" id="c-37242288" checked=""/><div class="controls bullet"><span class="by">johnvanommen</span><span>|</span><a href="#37242123">parent</a><span>|</span><a href="#37242225">prev</a><span>|</span><label class="collapse" for="c-37242288">[-]</label><label class="expand" for="c-37242288">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Once enterprise adoption of AI picks up, demand for chips will increase 2-3 times further.<p>Possibly their greatest asset, as an investment, is their crazy high margins. Nvidia in 2023 is where Intel was in 2007, where they could basically charge almost any price because they were so dominant in the market. I remember when E5s were selling for $2000 a pop and data centers were using thousands of them.</div><br/></div></div></div></div></div></div></div></div></div></body></html>