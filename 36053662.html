<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1684918865747" as="style"/><link rel="stylesheet" href="styles.css?v=1684918865747"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.artisana.ai/articles/meta-ai-unleashes-megabyte-a-revolutionary-scalable-model-architecture">Meta AI Unleashes Megabyte, a Revolutionary Scalable Model Architecture</a> <span class="domain">(<a href="https://www.artisana.ai">www.artisana.ai</a>)</span></div><div class="subtext"><span>thunderbong</span> | <span>89 comments</span></div><br/><div><div id="36053964" class="c"><input type="checkbox" id="c-36053964" checked=""/><div class="controls bullet"><span class="by">jacobn</span><span>|</span><a href="#36053745">next</a><span>|</span><label class="collapse" for="c-36053964">[-]</label><label class="expand" for="c-36053964">[59 more]</label></div><br/><div class="children"><div class="content">My main argument against the AI doomsayers has so far been that the current scaling laws simply make runaway singularity style scenarios algorithmically impossible (if for each step of improvement you need 10x parameters and 100x training, you quickly run into a brick wall).<p>This is part of why I’m not worried about the current crop of generative AI. I am however both curious and concerned about what the tsunami of talent and $$$ chasing the current trend will achieve.<p>If this n^(4&#x2F;3) alt transformer compute scaling is real (and there’s been many a pretender, so it’s too early to tell), then that could fundamentally change the overall AI scaling law, substantially lowering the brick wall.<p>And that could be a game changer.</div><br/><div id="36054114" class="c"><input type="checkbox" id="c-36054114" checked=""/><div class="controls bullet"><span class="by">p-e-w</span><span>|</span><a href="#36053964">parent</a><span>|</span><a href="#36054709">next</a><span>|</span><label class="collapse" for="c-36054114">[-]</label><label class="expand" for="c-36054114">[47 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t buy the idea (with either architecture) that &quot;10x&quot;-type scaling is required for another breakthrough.<p>Think of a human with below average intelligence. Then think of a human genius. Now consider how incredibly similar their brains are, despite the massive performance gap. It&#x27;s not like one has 10x the number of neurons&#x2F;synapses&#x2F;connections etc. of the other. They&#x27;re both healthy human brains, and you need powerful technology to even distinguish them structurally.<p>Considering this, it seems perfectly possible that a model like GPT-4 is just a hair&#x27;s breadth away from vastly superhuman performance. It certainly beats the average human at many tasks already. The gap between a moron and a genius is a lot larger than that between GPT-4 and a superhuman.</div><br/><div id="36054821" class="c"><input type="checkbox" id="c-36054821" checked=""/><div class="controls bullet"><span class="by">wudangmonk</span><span>|</span><a href="#36053964">root</a><span>|</span><a href="#36054114">parent</a><span>|</span><a href="#36054315">next</a><span>|</span><label class="collapse" for="c-36054821">[-]</label><label class="expand" for="c-36054821">[7 more]</label></div><br/><div class="children"><div class="content">You mean the average brain with about 100 billion neurons with about 1000 connections each bringing it to around 100 trillion connections. With an estimated 1000 &quot;AI&quot; neurons required per biologial neuron.<p>I don&#x27;t think you are givin these &quot;below average&quot; intelligence individuals enough credit. What we consider a genius is the equivalent of a dog show obstacle course. We measure intelligence&#x2F;genius as whatever is hard for humans and completely ignore what is easy because we fail to see the complexity behind the easy stuff.</div><br/><div id="36055062" class="c"><input type="checkbox" id="c-36055062" checked=""/><div class="controls bullet"><span class="by">mirekrusin</span><span>|</span><a href="#36053964">root</a><span>|</span><a href="#36054821">parent</a><span>|</span><a href="#36055059">next</a><span>|</span><label class="collapse" for="c-36055062">[-]</label><label class="expand" for="c-36055062">[5 more]</label></div><br/><div class="children"><div class="content">Nobody said that nature is optimal. Wheels are trivial, however not present in biology. Nature creates tentacles, not jet engines, nuclear energy etc.<p>Majority of human brain computation is spent on things that are simply not necessary for computer models (how to wiggle limbs, mouth, eyes etc).<p>Current LLM are impressive, but we know they can be much more efficient - we&#x27;re using very low quality training data, we don&#x27;t use any methods to question training input&#x2F;evaluate it against current knowledge etc. Our current language models are based on reciting&#x2F;memorization&#x2F;force-feeding, not true learning.<p>Computer models have massive underlying advantage of working on CPU&#x2F;GPUs where they can be modeled, cloned, retrained, have binary accuracy, can integrate with specialized code instantly, have access to massive memory storage, they are insanely fast and precise etc.<p>Looking at it from first principles, there is no reason to think that near optimal runtime should not be more efficient than human brain on currently available computers.<p>We don&#x27;t need to simulate full brain just like we didn&#x27;t have to create super fancy legs to go to the Moon.</div><br/><div id="36055213" class="c"><input type="checkbox" id="c-36055213" checked=""/><div class="controls bullet"><span class="by">baq</span><span>|</span><a href="#36053964">root</a><span>|</span><a href="#36055062">parent</a><span>|</span><a href="#36055059">next</a><span>|</span><label class="collapse" for="c-36055213">[-]</label><label class="expand" for="c-36055213">[4 more]</label></div><br/><div class="children"><div class="content">&gt; Nobody said that nature is optimal. Wheels are trivial, however not present in biology. Nature creates tentacles, not jet engines, nuclear energy etc.<p>Wheels are trivial but useless without bearings.<p>Bearings most certainly aren&#x27;t trivial. All the things you listed further are dependent on bearings somewhere.</div><br/><div id="36055503" class="c"><input type="checkbox" id="c-36055503" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#36053964">root</a><span>|</span><a href="#36055213">parent</a><span>|</span><a href="#36055283">next</a><span>|</span><label class="collapse" for="c-36055503">[-]</label><label class="expand" for="c-36055503">[1 more]</label></div><br/><div class="children"><div class="content">AFAIK both exist in biology. Bacterial flagellum is effectively a motor, and has a working wheel-like structure. IIRC, some crickets had an equivalent of a bearing somewhere in their anatomy too.<p>Evolution is a greedy, lazy optimizer, so it promotes things that work a-ok for a given environment.<p>It&#x27;s also worth noting that <i>wheels alone</i> are not too useful for transportation, as they&#x27;re only <i>half</i> of the picture. The other half is <i>roads</i>. That is, because we couldn&#x27;t (and mostly still can&#x27;t) figure out all-terrain mobility systems that could navigate diverse environments, we cheated and locally flattened the environment, to reduce the problem to that solvable by a humble wheel. Evolution can&#x27;t cheat like this.</div><br/></div></div><div id="36055283" class="c"><input type="checkbox" id="c-36055283" checked=""/><div class="controls bullet"><span class="by">mirekrusin</span><span>|</span><a href="#36053964">root</a><span>|</span><a href="#36055213">parent</a><span>|</span><a href="#36055503">prev</a><span>|</span><a href="#36055059">next</a><span>|</span><label class="collapse" for="c-36055283">[-]</label><label class="expand" for="c-36055283">[2 more]</label></div><br/><div class="children"><div class="content">I think 5yo kid with lego would have problems agreeing with this otherwise moot statement.</div><br/><div id="36055368" class="c"><input type="checkbox" id="c-36055368" checked=""/><div class="controls bullet"><span class="by">baq</span><span>|</span><a href="#36053964">root</a><span>|</span><a href="#36055283">parent</a><span>|</span><a href="#36055059">next</a><span>|</span><label class="collapse" for="c-36055368">[-]</label><label class="expand" for="c-36055368">[1 more]</label></div><br/><div class="children"><div class="content">Don&#x27;t want to sound mean but I don&#x27;t think you&#x27;ve dealt with bearings if you say so.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="36054315" class="c"><input type="checkbox" id="c-36054315" checked=""/><div class="controls bullet"><span class="by">nemothekid</span><span>|</span><a href="#36053964">root</a><span>|</span><a href="#36054114">parent</a><span>|</span><a href="#36054821">prev</a><span>|</span><a href="#36054502">next</a><span>|</span><label class="collapse" for="c-36054315">[-]</label><label class="expand" for="c-36054315">[35 more]</label></div><br/><div class="children"><div class="content">&gt;<i>Think of a human with below average intelligence. Then think of a human genius.</i><p>LLMs are not AGI. A human with below average intelligence is still a league above a chimpanzee. A chimpanzee will never be able to read, not because &quot;it&#x27;s too dumb&quot;, but because a chimp&#x27;s brain lacks the actual hardware for reading. The LLM is the chimpanzee. The gap between an LLM and a &quot;human with below average intelligence&quot; is far more than 10x.</div><br/><div id="36054840" class="c"><input type="checkbox" id="c-36054840" checked=""/><div class="controls bullet"><span class="by">qup</span><span>|</span><a href="#36053964">root</a><span>|</span><a href="#36054315">parent</a><span>|</span><a href="#36054404">next</a><span>|</span><label class="collapse" for="c-36054840">[-]</label><label class="expand" for="c-36054840">[1 more]</label></div><br/><div class="children"><div class="content">In your metaphor, maybe what the LLM (chimpanzee) &quot;brain&quot; is missing is some things like an inner thought loop, long term and short term storage and context, etc. Pieces we can understand, build, and surround the LLM with. Given the right arrangement, and the correct &quot;abracadabra,&quot; perhaps that gets to where we are.<p>It seems to me that LLMs are perhaps capable of making up the inner thought loop, and the rest of the obvious systems seem doable. The context seems to be the hard problem; pulling in the proper things, and giving them the correct amount of attention.</div><br/></div></div><div id="36054404" class="c"><input type="checkbox" id="c-36054404" checked=""/><div class="controls bullet"><span class="by">p-e-w</span><span>|</span><a href="#36053964">root</a><span>|</span><a href="#36054315">parent</a><span>|</span><a href="#36054840">prev</a><span>|</span><a href="#36054830">next</a><span>|</span><label class="collapse" for="c-36054404">[-]</label><label class="expand" for="c-36054404">[22 more]</label></div><br/><div class="children"><div class="content">&gt; The gap between an LLM and a &quot;human with below average intelligence&quot; is far more than 10x.<p>In which direction?<p>GPT-4 passes the bar exam with a top 10% score. How do you think a human with below average intelligence (or even with average intelligence) would fare?<p>Copilot generates programming code that solves problems, and in most cases the code is correct. It outperforms many junior professional developers. Do you think a human with below average intelligence could do that?</div><br/><div id="36054720" class="c"><input type="checkbox" id="c-36054720" checked=""/><div class="controls bullet"><span class="by">nemothekid</span><span>|</span><a href="#36053964">root</a><span>|</span><a href="#36054404">parent</a><span>|</span><a href="#36055054">next</a><span>|</span><label class="collapse" for="c-36054720">[-]</label><label class="expand" for="c-36054720">[16 more]</label></div><br/><div class="children"><div class="content">&gt;<i>How do you think a human with below average intelligence (or even with average intelligence) would fare?</i><p>I don&#x27;t understand what rote memorization to pass a test has to do with intelligence. For the record Kim Kardashian passed the bar; I imagine anyone given the proper motivation and time to study could do it, it&#x27;s not a hard test.<p>If AGI is a computer passing a test, then AGI was achieved a long time ago. I don&#x27;t think a human with below average intelligence could multiple 2 very large primes but I don&#x27;t mistake my calculator for intelligence. A below average intelligence human can drive a car with a couple hours of training, an LLM can&#x27;t do that (with a far lower power budget as well).<p>I&#x27;m not saying AGI is impossible, but it&#x27;s clear LLMs are not AGIs; it&#x27;s not a matter of having a 100x more powerful LLM, just like making an Ape better at sign language won&#x27;t make them better at abstract reasoning. An Ape&#x27;s brain fundamentally lacks the mental machinery for higher level things that humans do. It&#x27;s not a question of not being smart enough. LLMs are simply one component of the human mind.</div><br/><div id="36054785" class="c"><input type="checkbox" id="c-36054785" checked=""/><div class="controls bullet"><span class="by">p-e-w</span><span>|</span><a href="#36053964">root</a><span>|</span><a href="#36054720">parent</a><span>|</span><a href="#36055478">next</a><span>|</span><label class="collapse" for="c-36054785">[-]</label><label class="expand" for="c-36054785">[7 more]</label></div><br/><div class="children"><div class="content">&gt; If AGI is a computer passing a test, then AGI was achieved a long time ago.<p>AIs couldn&#x27;t even pass a third-grade reading comprehension exam until about 5 years ago. Computers being able to pass tests designed for humans is a <i>very</i> new thing.<p>&gt; it&#x27;s clear LLMs are not AGIs<p>And the main argument for that is that &quot;it&#x27;s clear&quot;. They&#x27;re beating lawyers, doctors, and software engineers, but obviously, that&#x27;s not <i>real</i> intelligence...</div><br/><div id="36054889" class="c"><input type="checkbox" id="c-36054889" checked=""/><div class="controls bullet"><span class="by">shreyshnaccount</span><span>|</span><a href="#36053964">root</a><span>|</span><a href="#36054785">parent</a><span>|</span><a href="#36054851">next</a><span>|</span><label class="collapse" for="c-36054889">[-]</label><label class="expand" for="c-36054889">[4 more]</label></div><br/><div class="children"><div class="content">You&#x27;re assuming that everything needed to write code or make arguments is purely intelligence based and has nothing to do with patterns, structural repetition and things glorified autocomplete could do, and that&#x27;s not true.</div><br/><div id="36054972" class="c"><input type="checkbox" id="c-36054972" checked=""/><div class="controls bullet"><span class="by">flangola7</span><span>|</span><a href="#36053964">root</a><span>|</span><a href="#36054889">parent</a><span>|</span><a href="#36054851">next</a><span>|</span><label class="collapse" for="c-36054972">[-]</label><label class="expand" for="c-36054972">[3 more]</label></div><br/><div class="children"><div class="content">Who said anything about everything? AI could not write code AT ALL until very recently. We could invent a drug that kills 99% of cancers and the next day there would be people bemoaning that it isn&#x27;t a &quot;true&quot; cure.</div><br/><div id="36055243" class="c"><input type="checkbox" id="c-36055243" checked=""/><div class="controls bullet"><span class="by">shreyshnaccount</span><span>|</span><a href="#36053964">root</a><span>|</span><a href="#36054972">parent</a><span>|</span><a href="#36054851">next</a><span>|</span><label class="collapse" for="c-36055243">[-]</label><label class="expand" for="c-36055243">[2 more]</label></div><br/><div class="children"><div class="content">Hey you&#x27;re the one claiming intelligence and all, burden of proving it in squarely on you</div><br/><div id="36055447" class="c"><input type="checkbox" id="c-36055447" checked=""/><div class="controls bullet"><span class="by">dr_dshiv</span><span>|</span><a href="#36053964">root</a><span>|</span><a href="#36055243">parent</a><span>|</span><a href="#36054851">next</a><span>|</span><label class="collapse" for="c-36055447">[-]</label><label class="expand" for="c-36055447">[1 more]</label></div><br/><div class="children"><div class="content">Yes. Let’s define AGI as ability for a single model to pass most human professional tests (no cheating) and to provide genuine human-level flexible cognitive benefit to specialized professionals in diverse fields. Reasonable?</div><br/></div></div></div></div></div></div></div></div><div id="36054851" class="c"><input type="checkbox" id="c-36054851" checked=""/><div class="controls bullet"><span class="by">qup</span><span>|</span><a href="#36053964">root</a><span>|</span><a href="#36054785">parent</a><span>|</span><a href="#36054889">prev</a><span>|</span><a href="#36055478">next</a><span>|</span><label class="collapse" for="c-36054851">[-]</label><label class="expand" for="c-36054851">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Computers being able to pass tests designed for humans is a very new thing.<p>Yes! Captchas so effective!</div><br/><div id="36055209" class="c"><input type="checkbox" id="c-36055209" checked=""/><div class="controls bullet"><span class="by">comex</span><span>|</span><a href="#36053964">root</a><span>|</span><a href="#36054851">parent</a><span>|</span><a href="#36055478">next</a><span>|</span><label class="collapse" for="c-36055209">[-]</label><label class="expand" for="c-36055209">[1 more]</label></div><br/><div class="children"><div class="content">Yes, it would be more accurate to say “computers being able to pass tests designed for humans <i>by humans</i>”, as opposed to CAPTCHAs which are automatically generated tests.</div><br/></div></div></div></div></div></div><div id="36055478" class="c"><input type="checkbox" id="c-36055478" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#36053964">root</a><span>|</span><a href="#36054720">parent</a><span>|</span><a href="#36054785">prev</a><span>|</span><a href="#36054983">next</a><span>|</span><label class="collapse" for="c-36055478">[-]</label><label class="expand" for="c-36055478">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>it&#x27;s not a matter of having a 100x more powerful LLM, just like making an Ape better at sign language won&#x27;t make them better at abstract reasoning. An Ape&#x27;s brain fundamentally lacks the mental machinery for higher level things that humans do. It&#x27;s not a question of not being smart enough. LLMs are simply one component of the human mind.</i><p>I believe you do have a good point overall, but this here is, IMHO, a rather bad example, because I&#x27;d argue GPT-4 is already capable of abstract reasoning, and this seems to be exactly <i>the</i> skill that improves with increasing dimensionality of the latent space.<p>I agree that LLMs are equivalent of a single component of a human mind. Specifically, I think they&#x27;re closest equivalent to our <i>inner voice</i> &#x2F; inner thoughts. But this part is arguably exactly the one that does most of the abstract reasoning (and most reasoning in general), so I think in fact LLMs <i>do</i> have the &quot;hardware&quot; for that specific aspect. What&#x27;s lacking right now is the equivalent of the higher, &quot;conscious&quot; layer, that guides, filters and censors the stream of thought. That, and long-term recall. Short-term memory might atually correspond to what the context window is in LLMs.<p>That, and fusing in all the other senses (sight, sound, smell, taste, touch, time, etc.).</div><br/></div></div><div id="36054983" class="c"><input type="checkbox" id="c-36054983" checked=""/><div class="controls bullet"><span class="by">hawk_</span><span>|</span><a href="#36053964">root</a><span>|</span><a href="#36054720">parent</a><span>|</span><a href="#36055478">prev</a><span>|</span><a href="#36054873">next</a><span>|</span><label class="collapse" for="c-36054983">[-]</label><label class="expand" for="c-36054983">[1 more]</label></div><br/><div class="children"><div class="content">&gt; For the record Kim Kardashian passed the bar;<p>While I know the wider point you&#x27;re trying to make, Kim Kardashian is a very smart business person. She may just not fit your narrow definition of &quot;intelligent&quot;.</div><br/></div></div><div id="36054873" class="c"><input type="checkbox" id="c-36054873" checked=""/><div class="controls bullet"><span class="by">ithkuil</span><span>|</span><a href="#36053964">root</a><span>|</span><a href="#36054720">parent</a><span>|</span><a href="#36054983">prev</a><span>|</span><a href="#36055125">next</a><span>|</span><label class="collapse" for="c-36054873">[-]</label><label class="expand" for="c-36054873">[5 more]</label></div><br/><div class="children"><div class="content">&gt; it&#x27;s not a matter of having a 100x more powerful LLM,<p>I think we all can agree that even the best LLM currently is not AGI. That&#x27;s not what being disputed here I think.<p>However a 100x more powerful LLM is not just 100x better at recall. A 100x more powerful LLM is not just 100x better at being stupid hallucinatory parrot. A model that is just 100x bigger is not necessarily 100x more powerful if you define power is the ability to achieve goals.<p>However pure language models will always lack something else: the ability to ground things in reality.<p>I recently had a dream where I solved some problems and when I woke up I realized that those solutions were bullshit, but I also realized the whole approach of my dreaming self was very similar to what a LLM would have done.</div><br/><div id="36055582" class="c"><input type="checkbox" id="c-36055582" checked=""/><div class="controls bullet"><span class="by">dr_dshiv</span><span>|</span><a href="#36053964">root</a><span>|</span><a href="#36054873">parent</a><span>|</span><a href="#36055001">next</a><span>|</span><label class="collapse" for="c-36055582">[-]</label><label class="expand" for="c-36055582">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I think we all can agree that even the best LLM currently is not AGI.<p>Disagree, for the record. If I’d described the capabilities of contemporary AI to 100 AI scientists 5 years ago, I bet more than half would agree to call that AGI. Further, more than 90% would assume that these capabilities were decades and decades away.</div><br/></div></div><div id="36055001" class="c"><input type="checkbox" id="c-36055001" checked=""/><div class="controls bullet"><span class="by">flangola7</span><span>|</span><a href="#36053964">root</a><span>|</span><a href="#36054873">parent</a><span>|</span><a href="#36055582">prev</a><span>|</span><a href="#36055125">next</a><span>|</span><label class="collapse" for="c-36055001">[-]</label><label class="expand" for="c-36055001">[3 more]</label></div><br/><div class="children"><div class="content">Define grounding things in reality.<p>We only have our 5 senses to go off of. Meta has already put out one multimodal model incorporating multiple data types, openai is undoubtedly working on it too.</div><br/><div id="36055019" class="c"><input type="checkbox" id="c-36055019" checked=""/><div class="controls bullet"><span class="by">ithkuil</span><span>|</span><a href="#36053964">root</a><span>|</span><a href="#36055001">parent</a><span>|</span><a href="#36055125">next</a><span>|</span><label class="collapse" for="c-36055019">[-]</label><label class="expand" for="c-36055019">[2 more]</label></div><br/><div class="children"><div class="content">Grounding in reality can be something as simple as what openai is experimenting with plugins or something much more integrated.<p>It&#x27;s not a matter of which senses you have, but about being able to &quot;continuously&quot; use them.<p>The current LLMs are basically unfiltered raw thoughts that must be continuously refined. A similar thing happens in our brains and only a little bit of that is accessible to our consciousness</div><br/><div id="36055530" class="c"><input type="checkbox" id="c-36055530" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#36053964">root</a><span>|</span><a href="#36055019">parent</a><span>|</span><a href="#36055125">next</a><span>|</span><label class="collapse" for="c-36055530">[-]</label><label class="expand" for="c-36055530">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>The current LLMs are basically unfiltered raw thoughts that must be continuously refined. A similar thing happens in our brains and only a little bit of that is accessible to our consciousness</i><p>Exactly. But, AFAIK, it&#x27;s also the part that does the bulk of actual thinking and decision-making for us. In that sense, LLMs may be closer to AGI than people expect, because they seem to be capturing the actual core of intelligence and reasoning - and the missing bits (like long-term memory and higher-level thought stream filter&#x2F;censor) may be much easier to bolt on to them.</div><br/></div></div></div></div></div></div></div></div><div id="36055125" class="c"><input type="checkbox" id="c-36055125" checked=""/><div class="controls bullet"><span class="by">Kiro</span><span>|</span><a href="#36053964">root</a><span>|</span><a href="#36054720">parent</a><span>|</span><a href="#36054873">prev</a><span>|</span><a href="#36055054">next</a><span>|</span><label class="collapse" for="c-36055125">[-]</label><label class="expand" for="c-36055125">[1 more]</label></div><br/><div class="children"><div class="content">Are you saying that Kim Kardashian is stupid?</div><br/></div></div></div></div><div id="36055054" class="c"><input type="checkbox" id="c-36055054" checked=""/><div class="controls bullet"><span class="by">satellite2</span><span>|</span><a href="#36053964">root</a><span>|</span><a href="#36054404">parent</a><span>|</span><a href="#36054720">prev</a><span>|</span><a href="#36054509">next</a><span>|</span><label class="collapse" for="c-36055054">[-]</label><label class="expand" for="c-36055054">[1 more]</label></div><br/><div class="children"><div class="content">Maybe we are simply culturally inclined to believe that the bar exam is more sophisticated than say, learn how to drive. A lot of the compute power required to drive is simply hidden from us because it&#x27;s inconsious. While intellectual tasks are mostly done consciously. So it remains to be shown which task is actually more complex. And in the meantime it&#x27;s clear than most people, independantly of their academic background can learn how to drive relatively easily.</div><br/></div></div><div id="36054509" class="c"><input type="checkbox" id="c-36054509" checked=""/><div class="controls bullet"><span class="by">intelVISA</span><span>|</span><a href="#36053964">root</a><span>|</span><a href="#36054404">parent</a><span>|</span><a href="#36055054">prev</a><span>|</span><a href="#36054830">next</a><span>|</span><label class="collapse" for="c-36054509">[-]</label><label class="expand" for="c-36054509">[4 more]</label></div><br/><div class="children"><div class="content">&gt; Copilot generates programming code that solves problems, and in most cases the code is correct. It outperforms many junior professional developers. Do you think a human with below average intelligence could do that?<p>Absolutely, it&#x27;s why Javascript is so popular.</div><br/><div id="36054581" class="c"><input type="checkbox" id="c-36054581" checked=""/><div class="controls bullet"><span class="by">p-e-w</span><span>|</span><a href="#36053964">root</a><span>|</span><a href="#36054509">parent</a><span>|</span><a href="#36054830">next</a><span>|</span><label class="collapse" for="c-36054581">[-]</label><label class="expand" for="c-36054581">[3 more]</label></div><br/><div class="children"><div class="content">A human with <i>below average intelligence</i> can outperform many junior <i>professional software engineers</i> because of JavaScript?<p>Do you mean a <i>programmer</i> with below average intelligence (for a programmer)? Because I&#x27;m having a hard time believing that you actually believe what you wrote.<p>BTW, JavaScript is actually a fairly difficult language to learn and use. Python, BASIC, and even Fortran are much simpler conceptually and have far fewer pitfalls. JavaScript is popular because it&#x27;s the only language that every modern computer has an interpreter for, not because it&#x27;s so easy that idiots can use it.</div><br/><div id="36054663" class="c"><input type="checkbox" id="c-36054663" checked=""/><div class="controls bullet"><span class="by">arcanemachiner</span><span>|</span><a href="#36053964">root</a><span>|</span><a href="#36054581">parent</a><span>|</span><a href="#36054745">next</a><span>|</span><label class="collapse" for="c-36054663">[-]</label><label class="expand" for="c-36054663">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s gotta be a low-effort joke.</div><br/></div></div><div id="36054745" class="c"><input type="checkbox" id="c-36054745" checked=""/><div class="controls bullet"><span class="by">intelVISA</span><span>|</span><a href="#36053964">root</a><span>|</span><a href="#36054581">parent</a><span>|</span><a href="#36054663">prev</a><span>|</span><a href="#36054830">next</a><span>|</span><label class="collapse" for="c-36054745">[-]</label><label class="expand" for="c-36054745">[1 more]</label></div><br/><div class="children"><div class="content">It was a bit tongue in cheek I&#x27;ll confess. :)</div><br/></div></div></div></div></div></div></div></div><div id="36054830" class="c"><input type="checkbox" id="c-36054830" checked=""/><div class="controls bullet"><span class="by">ithkuil</span><span>|</span><a href="#36053964">root</a><span>|</span><a href="#36054315">parent</a><span>|</span><a href="#36054404">prev</a><span>|</span><a href="#36055129">next</a><span>|</span><label class="collapse" for="c-36054830">[-]</label><label class="expand" for="c-36054830">[1 more]</label></div><br/><div class="children"><div class="content">The key idea behind the current wave of AI is that the necessary &quot;structure&quot; will be created through training by sheer amount of data. The idea has been dismissed for decades but it turned out one of the most effective ways to get practical results.<p>Now, can and should all structure necessarily come from pure training? Is there a better &quot;seed&quot; structure that can make models more effective? Is there some other bits that are missing that are not in the microstructure but in the way the model is connected to the external world and itself (feedback loops etc)?</div><br/></div></div><div id="36055129" class="c"><input type="checkbox" id="c-36055129" checked=""/><div class="controls bullet"><span class="by">ummonk</span><span>|</span><a href="#36053964">root</a><span>|</span><a href="#36054315">parent</a><span>|</span><a href="#36054830">prev</a><span>|</span><a href="#36054357">next</a><span>|</span><label class="collapse" for="c-36055129">[-]</label><label class="expand" for="c-36055129">[1 more]</label></div><br/><div class="children"><div class="content">From the origins of the first sentient life on Earth half a billion years ago, our common ancestor with the chimpanzees was 98% of the evolutionary timespan on the way to humans. Do you really want to bank on that last 2% being difficult to match in computers?</div><br/></div></div><div id="36054357" class="c"><input type="checkbox" id="c-36054357" checked=""/><div class="controls bullet"><span class="by">epups</span><span>|</span><a href="#36053964">root</a><span>|</span><a href="#36054315">parent</a><span>|</span><a href="#36055129">prev</a><span>|</span><a href="#36054502">next</a><span>|</span><label class="collapse" for="c-36054357">[-]</label><label class="expand" for="c-36054357">[9 more]</label></div><br/><div class="children"><div class="content">By what criteria? In several professional capacities, including coding, LLM&#x27;s are far superior to an average human already.</div><br/><div id="36054405" class="c"><input type="checkbox" id="c-36054405" checked=""/><div class="controls bullet"><span class="by">slowmovintarget</span><span>|</span><a href="#36053964">root</a><span>|</span><a href="#36054357">parent</a><span>|</span><a href="#36054502">next</a><span>|</span><label class="collapse" for="c-36054405">[-]</label><label class="expand" for="c-36054405">[8 more]</label></div><br/><div class="children"><div class="content">No they&#x27;re not. They&#x27;re superior at specific tests when prompted.<p>But asking for a complete application nearly always fails, when an average human that knows programming should be able to make one that works.</div><br/><div id="36054861" class="c"><input type="checkbox" id="c-36054861" checked=""/><div class="controls bullet"><span class="by">qup</span><span>|</span><a href="#36053964">root</a><span>|</span><a href="#36054405">parent</a><span>|</span><a href="#36054526">next</a><span>|</span><label class="collapse" for="c-36054861">[-]</label><label class="expand" for="c-36054861">[1 more]</label></div><br/><div class="children"><div class="content">The LLM knows it doesn&#x27;t work, too, we just don&#x27;t run it long enough to let it try it out. It would try, get an error, and know how to handle the error.<p><a href="https:&#x2F;&#x2F;github.com&#x2F;drifting-in-space&#x2F;botsh">https:&#x2F;&#x2F;github.com&#x2F;drifting-in-space&#x2F;botsh</a><p>Check out some agents that probably can already do more than you knew about.</div><br/></div></div><div id="36054526" class="c"><input type="checkbox" id="c-36054526" checked=""/><div class="controls bullet"><span class="by">p-e-w</span><span>|</span><a href="#36053964">root</a><span>|</span><a href="#36054405">parent</a><span>|</span><a href="#36054861">prev</a><span>|</span><a href="#36054455">next</a><span>|</span><label class="collapse" for="c-36054526">[-]</label><label class="expand" for="c-36054526">[3 more]</label></div><br/><div class="children"><div class="content">&gt; when an average human that knows programming should be able to make one that works.<p>Very few people who &quot;know programming&quot; are actually capable of creating a complete application that serves a specific purpose. Many professional programmers struggle to implement basic algorithms like prime number testing. Coding AIs absolutely outperform the average programming professional, because the average programming professional can barely program. The software industry&#x27;s demand for programmers is far too great for every coding position to be filled with top-class full stack engineers.</div><br/><div id="36054892" class="c"><input type="checkbox" id="c-36054892" checked=""/><div class="controls bullet"><span class="by">shreyshnaccount</span><span>|</span><a href="#36053964">root</a><span>|</span><a href="#36054526">parent</a><span>|</span><a href="#36054455">next</a><span>|</span><label class="collapse" for="c-36054892">[-]</label><label class="expand" for="c-36054892">[2 more]</label></div><br/><div class="children"><div class="content">Who is this average programmer you&#x27;re talking about? We did primality testing in literally the first sem at uni</div><br/><div id="36055389" class="c"><input type="checkbox" id="c-36055389" checked=""/><div class="controls bullet"><span class="by">pedrosorio</span><span>|</span><a href="#36053964">root</a><span>|</span><a href="#36054892">parent</a><span>|</span><a href="#36054455">next</a><span>|</span><label class="collapse" for="c-36055389">[-]</label><label class="expand" for="c-36055389">[1 more]</label></div><br/><div class="children"><div class="content">Take a look at this old, commonly referenced article, might be before your time:<p><a href="https:&#x2F;&#x2F;blog.codinghorror.com&#x2F;why-cant-programmers-program&#x2F;" rel="nofollow">https:&#x2F;&#x2F;blog.codinghorror.com&#x2F;why-cant-programmers-program&#x2F;</a></div><br/></div></div></div></div></div></div><div id="36054455" class="c"><input type="checkbox" id="c-36054455" checked=""/><div class="controls bullet"><span class="by">CamperBob2</span><span>|</span><a href="#36053964">root</a><span>|</span><a href="#36054405">parent</a><span>|</span><a href="#36054526">prev</a><span>|</span><a href="#36054502">next</a><span>|</span><label class="collapse" for="c-36054455">[-]</label><label class="expand" for="c-36054455">[3 more]</label></div><br/><div class="children"><div class="content"><i>But asking for a complete application nearly always fails, when an average human that knows programming should be able to make one that works.</i><p>&quot;This talking dog is a dumbass.  The risotto recipe he gave me sucked, and the C++ code he wrote is full of security holes.  I don&#x27;t see what all the hype is about.&quot;<p>Hint: ML will get better.  <i>Humans will not.</i>  (&quot;Slow moving target,&quot; indeed.)  What we&#x27;re learning is just how many aspects of our vaunted &#x27;intelligence&#x27; are really just features of our languages and the graphs they encode.</div><br/><div id="36054707" class="c"><input type="checkbox" id="c-36054707" checked=""/><div class="controls bullet"><span class="by">riffraff</span><span>|</span><a href="#36053964">root</a><span>|</span><a href="#36054455">parent</a><span>|</span><a href="#36054502">next</a><span>|</span><label class="collapse" for="c-36054707">[-]</label><label class="expand" for="c-36054707">[2 more]</label></div><br/><div class="children"><div class="content">This might be true but it&#x27;s irrelevant to the claim &quot;LLMs are already better than humans&quot;.</div><br/><div id="36054942" class="c"><input type="checkbox" id="c-36054942" checked=""/><div class="controls bullet"><span class="by">CamperBob2</span><span>|</span><a href="#36053964">root</a><span>|</span><a href="#36054707">parent</a><span>|</span><a href="#36054502">next</a><span>|</span><label class="collapse" for="c-36054942">[-]</label><label class="expand" for="c-36054942">[1 more]</label></div><br/><div class="children"><div class="content">You are fixated on the current state of the art, when the first couple of time derivatives are what actually matter.  The assertion in question is already true in a limited sense, and it&#x27;s only going to go in one direction from here.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="36054502" class="c"><input type="checkbox" id="c-36054502" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#36053964">root</a><span>|</span><a href="#36054114">parent</a><span>|</span><a href="#36054315">prev</a><span>|</span><a href="#36055029">next</a><span>|</span><label class="collapse" for="c-36054502">[-]</label><label class="expand" for="c-36054502">[2 more]</label></div><br/><div class="children"><div class="content">&gt; I don&#x27;t buy the idea (with either architecture) that &quot;10x&quot;-type scaling is required for another breakthrough.<p>Scaling can happen in two dimensions - model size and dataset size. What counts is the product of n_examples x n_parameters. That&#x27;s why we have the super-Chinchilla laws, where n_examples &gt;&gt; 20*n_parameters. Scale the data, keep the model lean. Not to mention dataset quality - if you got clean diverse data you need less of it.<p>Another important trend is using LLMs to generate training sets. Example: ConstitutionalAI (pure RLAIF), TinyStories (scaling down LLMs), Alpaca (borrowed RLHF), AlpacaFarm - a recent paper promising fine-tuned models for $200 cost in 24h.</div><br/><div id="36054635" class="c"><input type="checkbox" id="c-36054635" checked=""/><div class="controls bullet"><span class="by">BulgarianIdiot</span><span>|</span><a href="#36053964">root</a><span>|</span><a href="#36054502">parent</a><span>|</span><a href="#36055029">next</a><span>|</span><label class="collapse" for="c-36054635">[-]</label><label class="expand" for="c-36054635">[1 more]</label></div><br/><div class="children"><div class="content">Scaling can happen in many other places. Such as deeper iterative thought during inference such as Chain of Thought, Tree of Thought, which extracts increasingly better performance out of existing parameter and data sizes.<p>Tried to explain here:
<a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36054809" rel="nofollow">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36054809</a></div><br/></div></div></div></div><div id="36055029" class="c"><input type="checkbox" id="c-36055029" checked=""/><div class="controls bullet"><span class="by">raincole</span><span>|</span><a href="#36053964">root</a><span>|</span><a href="#36054114">parent</a><span>|</span><a href="#36054502">prev</a><span>|</span><a href="#36054226">next</a><span>|</span><label class="collapse" for="c-36055029">[-]</label><label class="expand" for="c-36055029">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Now consider how incredibly similar their brains are, despite the massive performance gap.<p>A disk filled with random bits is &quot;similar&quot; to a disk that stores the whole Wikipedia&#x27;s text content. So writing the whole Wikipedia is an effort of a hair&#x27;s breadth...?</div><br/></div></div><div id="36054226" class="c"><input type="checkbox" id="c-36054226" checked=""/><div class="controls bullet"><span class="by">anon291</span><span>|</span><a href="#36053964">root</a><span>|</span><a href="#36054114">parent</a><span>|</span><a href="#36055029">prev</a><span>|</span><a href="#36054709">next</a><span>|</span><label class="collapse" for="c-36054226">[-]</label><label class="expand" for="c-36054226">[1 more]</label></div><br/><div class="children"><div class="content">&gt; It certainly beats the average human at many tasks already<p>This is not the revolution you think it is.<p>```python
&gt; 338383*887282
... ANSWER ...
```<p>Yet skynet never came.</div><br/></div></div></div></div><div id="36054709" class="c"><input type="checkbox" id="c-36054709" checked=""/><div class="controls bullet"><span class="by">godelski</span><span>|</span><a href="#36053964">parent</a><span>|</span><a href="#36054114">prev</a><span>|</span><a href="#36055104">next</a><span>|</span><label class="collapse" for="c-36054709">[-]</label><label class="expand" for="c-36054709">[1 more]</label></div><br/><div class="children"><div class="content">&gt; if for each step of improvement you need 10x parameters and 100x training, you quickly run into a brick wall<p>Btw, PALM2 has far fewer parameters than V1.<p>&gt; The largest model in the PaLM 2 family, PaLM 2-L, is significantly smaller than the largest PaLM model but uses
more training compute. Our evaluation results show that PaLM 2 models significantly outperform PaLM on a variety
of tasks, including natural language generation, translation, and reasoning. These results suggest that model scaling
is not the only way to improve performance.<p>From the leak we know that the large version is 340B parameters, compared to the original 540B parameters. From Table 2 in the document we see that the small version (unknown size) is on par with version 1.<p>ML typically follows a cycle. Improve, distill, repeat. It is unfortunate that the big labs lead these efforts because many smaller labs try to work on the distill part in parallel (out of necessity) but works get rejected (due to lack of SOTA) or ignored. Like all research, we need to be careful and nuanced in our evaluations. There&#x27;s a lot of hype and many trying to take advantage of the confusion and sell snake oil. I think AI&#x2F;ML is and will continue to change our world, but we have to be careful to not let the salesmen dictate the conversations.<p>PaLM <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2305.10403" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2305.10403</a><p>PaLM 2 <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2204.02311" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2204.02311</a></div><br/></div></div><div id="36055104" class="c"><input type="checkbox" id="c-36055104" checked=""/><div class="controls bullet"><span class="by">ummonk</span><span>|</span><a href="#36053964">parent</a><span>|</span><a href="#36054709">prev</a><span>|</span><a href="#36055134">next</a><span>|</span><label class="collapse" for="c-36055104">[-]</label><label class="expand" for="c-36055104">[1 more]</label></div><br/><div class="children"><div class="content">Do you believe that Moore’s Law (or rather Huang’s Law) will stop being true before AI exceeds human capabilities by orders of magnitude?<p>We don’t need a runaway singularity for AI to just render human intelligence obsolete.</div><br/></div></div><div id="36055134" class="c"><input type="checkbox" id="c-36055134" checked=""/><div class="controls bullet"><span class="by">BorisTheBrave</span><span>|</span><a href="#36053964">parent</a><span>|</span><a href="#36055104">prev</a><span>|</span><a href="#36054321">next</a><span>|</span><label class="collapse" for="c-36055134">[-]</label><label class="expand" for="c-36055134">[1 more]</label></div><br/><div class="children"><div class="content">I think you&#x27;ve misunderstood. Megabyte scales better with context window length. I don&#x27;t know if they&#x27;re saying the training data &#x2F; compute are any more efficient.</div><br/></div></div><div id="36054321" class="c"><input type="checkbox" id="c-36054321" checked=""/><div class="controls bullet"><span class="by">vlovich123</span><span>|</span><a href="#36053964">parent</a><span>|</span><a href="#36055134">prev</a><span>|</span><a href="#36054809">next</a><span>|</span><label class="collapse" for="c-36054321">[-]</label><label class="expand" for="c-36054321">[5 more]</label></div><br/><div class="children"><div class="content">I don’t think I follow this argument. AI has been dropping in costs and complexity the more engineering time is spent on it. It seems like the bottleneck is humans creating new AI techniques right? If an AI is capable of developing new AI techniques unsupervised, isn’t that by definition the singularity? Heck doesn’t even need to be unsupervised. If it can even do most of the heavy lifting for a human I feel like that would put us into runaway territory.<p>Granted we’re a long way away from that and likely we’d need an AI that could come up with its own hypotheses for new AI models to make this truly minimal cost and that feels even farther away. But I don’t think I follow the claim that each improvement step change requires to much massive extra scaling as it seems not match what we’ve seen over the past few years (granted I could be misinformed - I’m applying a 10k view spectator and maybe my own mental model here is flawed).</div><br/><div id="36054461" class="c"><input type="checkbox" id="c-36054461" checked=""/><div class="controls bullet"><span class="by">doctor_eval</span><span>|</span><a href="#36053964">root</a><span>|</span><a href="#36054321">parent</a><span>|</span><a href="#36054809">next</a><span>|</span><label class="collapse" for="c-36054461">[-]</label><label class="expand" for="c-36054461">[4 more]</label></div><br/><div class="children"><div class="content">I consider the singularity to be the point at which the certainty of our predictions about our future becomes close to zero. By this definition I reckon we are already in the singularity.<p>It’s not necessarily bad. The problem with the singularity is that that we can’t tell if it’s bad or not.</div><br/><div id="36054583" class="c"><input type="checkbox" id="c-36054583" checked=""/><div class="controls bullet"><span class="by">amoss</span><span>|</span><a href="#36053964">root</a><span>|</span><a href="#36054461">parent</a><span>|</span><a href="#36054809">next</a><span>|</span><label class="collapse" for="c-36054583">[-]</label><label class="expand" for="c-36054583">[3 more]</label></div><br/><div class="children"><div class="content">Certainty about predictions of the future has always been close to zero. If you take a person from an appropriate time and ask them what the future will look like in 1000, 100 or even 20 years then their predictions will bear little resemblence to what actually occurs.<p>As humans we have a tendancy to make linear future predictions based on past observations. Over the timescales that matter significant effects occur from previously unseen kinds of events that become important via interactions with other events.<p>The important measurement would be what the length of the event horizon - the length of time before our predictions rapidly decrease to zero certainty. In a singularity we would expect that length of time to decrease close to zero. What has it been historically? I would claim that 5-10 years is a difficult period to make meaningful predictions about. I think that 20 years has proven to be very difficult but possible in the past. I am unaware of any 100+ year predictions that have landed with better than random chance.<p>Interestingly I think we are entering a period where 5 years will be the upper bound, and even predictions over shorter 2-3 year timespans are going to become difficult.</div><br/><div id="36054654" class="c"><input type="checkbox" id="c-36054654" checked=""/><div class="controls bullet"><span class="by">doctor_eval</span><span>|</span><a href="#36053964">root</a><span>|</span><a href="#36054583">parent</a><span>|</span><a href="#36054809">next</a><span>|</span><label class="collapse" for="c-36054654">[-]</label><label class="expand" for="c-36054654">[2 more]</label></div><br/><div class="children"><div class="content">I would say that we are really saying the same thing. I did intend to imply “short term predictions”.<p>However I feel that these LLMs are not like the internet or the release of the iPhone. We’ve gone in a very short time from LLMs in the lab to ChatGPT to passing the bar exam.<p>Considering the rate of research that’s being published and the fact that what we see today is generally at least many months behind the state of the art, I don’t feel that we can even have any certainty about the next 6 months.</div><br/><div id="36054911" class="c"><input type="checkbox" id="c-36054911" checked=""/><div class="controls bullet"><span class="by">amoss</span><span>|</span><a href="#36053964">root</a><span>|</span><a href="#36054654">parent</a><span>|</span><a href="#36054809">next</a><span>|</span><label class="collapse" for="c-36054911">[-]</label><label class="expand" for="c-36054911">[1 more]</label></div><br/><div class="children"><div class="content">Ah, I did not grasp that reading your comment - then we are saying the same thing.<p>Yes, I think that progress has become rapid enough that we can&#x27;t predict six months out. I suspect that we are only 1-2 inventions away from something quite large and transformative. Obviously LLMs have already created a lot of excitement and opened up new areas of content generation already, but I think something larger is coming.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="36054809" class="c"><input type="checkbox" id="c-36054809" checked=""/><div class="controls bullet"><span class="by">BulgarianIdiot</span><span>|</span><a href="#36053964">parent</a><span>|</span><a href="#36054321">prev</a><span>|</span><a href="#36054617">next</a><span>|</span><label class="collapse" for="c-36054809">[-]</label><label class="expand" for="c-36054809">[2 more]</label></div><br/><div class="children"><div class="content">Your premise is wrong. This has nothing to do with 10x-ing parameters. One could argue the current parameter sizes are good enough as we observe &quot;large breadth, shallow depth&quot; behavior from LLM and to some extent, diffusion models.<p>This suggests the problem is the depth of inference, which is single pass &quot;hot takes&quot; for all language models right now, due to cost of inference and our limited understanding of what makes a model&#x27;s response high quality.<p>Yes, you don&#x27;t need more parameters to increase the depth. You need to iterate, instead. Loop. Imagine programming if looping was not allowed, nor recursion, or not even defining functions and calling them. Everything you write runs at most once during program execution and that&#x27;s it. This is what an AI model is right now during inference. One big flat, single-pass, directed acyclic graph. And soon it won&#x27;t be.<p>Research into Chain of Thought, Tree of Thought reveals this dimension. This means you can take existing models and make them perform much more complex tasks with much better precision, though various ways of letting them iterate. Think of how you&#x27;d perform if you always had exactly 5 seconds to answer a question. Now imagine if you have 5 minutes. 5 hours. 5 days. Lo and behold, turns out an AI isn&#x27;t different in that aspect.<p>We also need more iterations of training (on the same amount of data), we need larger context windows, and we need new architectures, like Meta&#x27;s MEGABYTE, for example.<p>Parameter count and data size could hypothetically have already hit a hard wall (they haven&#x27;t) and AI will keep exponentially improving regardless. There&#x27;s too much low hanging fruit and more grows by the nanosecond.</div><br/><div id="36055519" class="c"><input type="checkbox" id="c-36055519" checked=""/><div class="controls bullet"><span class="by">Henk0</span><span>|</span><a href="#36053964">root</a><span>|</span><a href="#36054809">parent</a><span>|</span><a href="#36054617">next</a><span>|</span><label class="collapse" for="c-36055519">[-]</label><label class="expand" for="c-36055519">[1 more]</label></div><br/><div class="children"><div class="content">This. So much this.<p>I&#x27;m completely dumbfounded by obviously highly intelligent people consistently not getting this, and dismissing current generation AI systems as not being intelligent because they can&#x27;t reliably solve massively complex problems in one go. Like anyone would expect a human programmer or researcher to just intuitively come up with a complex program, or the correct answer for a hard problem every time, instantly<p>Human thinking and problem solving involves a lot of trial and error, iterative thinking, and sharing and discussing the problem with other humans. Processes that AI researchers are just now beginning to explore, with results like increasing reasoning ability by 900% in a recent paper. Every thinking human runs a near constant loop of thought, with no conscious control of which thought will appear next (we&#x27;re very good at fooling ourselves that we have control though)<p>We do have super-intelligences already, but they&#x27;re severely handicapped by lacking a bunch of these - apparently fairly straightforward to implement - abilities, plus a few senses and the ability to directly effect change in the physical world (which really isn&#x27;t needed if they can get access to human agents who will do their bidding, wittingly or unwittingly), and to self-improve. With regards to self-improvement, the increasing coding skills combined with iterative &#x27;thought&#x27; loops should get there in very little time considering the current rate of progress<p>There&#x27;s also the idea that a single AI model should be able to do everything our human brains do, when our brains actually contain a number of specialised subunits that handle different aspects of our behavioural repertoire. It reasonable to allow for the same thing with an AI system, where specialised sub-networks handle input, output and other subtasks. AI systems also have the advantage of being able to add any arbitrary number of subunits to increase its capacity to solve various problems<p>We seem to suffer from a species-wide narcissism with regards to our own intelligence and capabilities, and there&#x27;s this huge focus on the number of connections in the human brain – most of which deal with things that are by no means necessary to act on the world unless one has a meat body and the need to navigate social situations, make friends and mate. Fact is, we have terrible short-term memory (worse than chimpanzees), slow processing time, lots of cognitive heuristics, many of which cause more harm than good in the modern world. We are emotional and easily fooled. Even the most intelligent people historically have believed in what we now consider fairy tales. We are slow to take in information, bad at storing it, and generally bad at transmitting it. A few of us can generate great ideas – building on accumulated knowledge from our forebears and peers – but most of us are just not that great at coming up with anything original or useful<p>I&#x27;ve been actively looking for good arguments against AGI being much closer than we should be comfortable with, and reasons why we should not fear systems that surpass us in intelligence. All I&#x27;ve come across so far is some combination of the above, often expressed with a dismissive attitude, disparaging current LLM:s as parrots (that can apparently reason on the level of university level humans, but much more quickly), and pejorative terms like fearmongerers and doomers to describe those of us who really don&#x27;t think its a good idea to pursue more intelligent systems. My guess is these people will act surprised when the arms race inevitably leads to some very bad unintended consequences. I don&#x27;t see a way to stop it though, so I&#x27;m just strapped in for the ride along with the rest of humankind<p>Again, if you have good arguments against any of the points above, please do share them with me</div><br/></div></div></div></div></div></div><div id="36053745" class="c"><input type="checkbox" id="c-36053745" checked=""/><div class="controls bullet"><span class="by">crakenzak</span><span>|</span><a href="#36053964">prev</a><span>|</span><a href="#36055495">next</a><span>|</span><label class="collapse" for="c-36053745">[-]</label><label class="expand" for="c-36053745">[9 more]</label></div><br/><div class="children"><div class="content">Paper: <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2305.07185" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2305.07185</a><p>Wow, seems like Meta AI is so ahead of the curve compared to even Google and OpenAI recently especially with their open sourcing pushes.<p>Great for the research community as a whole!</div><br/><div id="36054151" class="c"><input type="checkbox" id="c-36054151" checked=""/><div class="controls bullet"><span class="by">1024core</span><span>|</span><a href="#36053745">parent</a><span>|</span><a href="#36054148">next</a><span>|</span><label class="collapse" for="c-36054151">[-]</label><label class="expand" for="c-36054151">[5 more]</label></div><br/><div class="children"><div class="content">Meta has no horse in the race (i.e. they don&#x27;t have a search engine). So, they don&#x27;t mind throwing random things out. Withholding it won&#x27;t really make much of a difference for them, as they don&#x27;t have a way to productionize the tech.</div><br/><div id="36055149" class="c"><input type="checkbox" id="c-36055149" checked=""/><div class="controls bullet"><span class="by">dumpsterdiver</span><span>|</span><a href="#36053745">root</a><span>|</span><a href="#36054151">parent</a><span>|</span><a href="#36055208">next</a><span>|</span><label class="collapse" for="c-36055149">[-]</label><label class="expand" for="c-36055149">[1 more]</label></div><br/><div class="children"><div class="content">While I disagree that having a search engine is the only way to have a &quot;horse in the race&quot;, I must agree that at this point Meta does not appear to have a horse in the race.<p>Other companies are providing services that are so useful that it makes us think twice about how secure our jobs are. Then there is Meta, who seems to think that the world at large will forget about the terrible motion sickness that their VR products have wrought upon us. I for one will not forget. I&#x27;m actually traumatized, and even thinking about putting on VR goggles at this point makes me feel queasy.</div><br/></div></div><div id="36055208" class="c"><input type="checkbox" id="c-36055208" checked=""/><div class="controls bullet"><span class="by">wolfd</span><span>|</span><a href="#36053745">root</a><span>|</span><a href="#36054151">parent</a><span>|</span><a href="#36055149">prev</a><span>|</span><a href="#36055108">next</a><span>|</span><label class="collapse" for="c-36055208">[-]</label><label class="expand" for="c-36055208">[1 more]</label></div><br/><div class="children"><div class="content">I would be _shocked_ if Zuck wasn&#x27;t thinking 24&#x2F;7 about how to capitalize on LLMs. I&#x27;m sure there are a thousand ideas (maybe even a few good ones?) being thrown around Meta at how to use LLMs to beat Google&#x2F;Microsoft+OpenAI at the &quot;search buddy&quot; game.</div><br/></div></div><div id="36055108" class="c"><input type="checkbox" id="c-36055108" checked=""/><div class="controls bullet"><span class="by">abwizz</span><span>|</span><a href="#36053745">root</a><span>|</span><a href="#36054151">parent</a><span>|</span><a href="#36055208">prev</a><span>|</span><a href="#36054148">next</a><span>|</span><label class="collapse" for="c-36055108">[-]</label><label class="expand" for="c-36055108">[2 more]</label></div><br/><div class="children"><div class="content">would not be surprised if they integrated a &quot;suggested conversations&quot; feature based on your chat history and behaviour, where the user just picks sentences from a list and both parties can enjoy a effortless &quot;organic&quot; conversation.</div><br/><div id="36055163" class="c"><input type="checkbox" id="c-36055163" checked=""/><div class="controls bullet"><span class="by">qas123</span><span>|</span><a href="#36053745">root</a><span>|</span><a href="#36055108">parent</a><span>|</span><a href="#36054148">next</a><span>|</span><label class="collapse" for="c-36055163">[-]</label><label class="expand" for="c-36055163">[1 more]</label></div><br/><div class="children"><div class="content">My question then would be how it impacts advertising. we will essentially have bots talking to bots</div><br/></div></div></div></div></div></div><div id="36054148" class="c"><input type="checkbox" id="c-36054148" checked=""/><div class="controls bullet"><span class="by">mturmon</span><span>|</span><a href="#36053745">parent</a><span>|</span><a href="#36054151">prev</a><span>|</span><a href="#36054117">next</a><span>|</span><label class="collapse" for="c-36054148">[-]</label><label class="expand" for="c-36054148">[1 more]</label></div><br/><div class="children"><div class="content">Commoditizing their complement?</div><br/></div></div><div id="36054117" class="c"><input type="checkbox" id="c-36054117" checked=""/><div class="controls bullet"><span class="by">joshxyz</span><span>|</span><a href="#36053745">parent</a><span>|</span><a href="#36054148">prev</a><span>|</span><a href="#36055495">next</a><span>|</span><label class="collapse" for="c-36054117">[-]</label><label class="expand" for="c-36054117">[2 more]</label></div><br/><div class="children"><div class="content">great positioning for zuck, impressive</div><br/></div></div></div></div><div id="36055495" class="c"><input type="checkbox" id="c-36055495" checked=""/><div class="controls bullet"><span class="by">dr_dshiv</span><span>|</span><a href="#36053745">prev</a><span>|</span><a href="#36054299">next</a><span>|</span><label class="collapse" for="c-36055495">[-]</label><label class="expand" for="c-36055495">[1 more]</label></div><br/><div class="children"><div class="content">Wow: “researchers discovered that the Megabyte model&#x27;s maximum capacity exceeded 1.2M tokens. For comparison, OpenAI&#x27;s GPT-4 has a limit of 32,000 tokens, while Anthropic&#x27;s Claude has a limit of 100,000 tokens”<p>In my understanding, this is accomplished through a hierarchical approach of “patches” of tokens.</div><br/></div></div><div id="36054299" class="c"><input type="checkbox" id="c-36054299" checked=""/><div class="controls bullet"><span class="by">zxexz</span><span>|</span><a href="#36055495">prev</a><span>|</span><a href="#36054554">next</a><span>|</span><label class="collapse" for="c-36054299">[-]</label><label class="expand" for="c-36054299">[8 more]</label></div><br/><div class="children"><div class="content">Great paper. But wow, I really wish everyone would use more easily searchable names for their projects. In 6 months, there’s a high probability I’ll end up googling&#x2F;ddging “megabyte model” trying to find this paper again.</div><br/><div id="36055195" class="c"><input type="checkbox" id="c-36055195" checked=""/><div class="controls bullet"><span class="by">machdiamonds</span><span>|</span><a href="#36054299">parent</a><span>|</span><a href="#36055443">next</a><span>|</span><label class="collapse" for="c-36055195">[-]</label><label class="expand" for="c-36055195">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve been using myReach as a bookmark manager lately. I&#x27;ve found it to be pretty useful for resurfacing information from links I have saved. I think they&#x27;re using embeddings to help you track down information across different documents, articles, posts, etc. The big sell is that it&#x27;s a personalized AI assistant that answers your specific queries based on what data you feed it (e.g.,&quot;what was my electricity bill last month&quot;). However, I&#x27;m hesitant about uploading personal data, so I am just using it as a bookmark manager. Their LLM although a little slow, works pretty well. I had this HN link saved about an open-source TTS model. A commenter said they were going to release a model later that week that could be comparable to Elevenlabs. I asked the chatbot on myReach: &quot;What&#x27;s that TTS model that&#x27;s looking to rival ElevenLabs?&quot; It surfaced the article and used the specific comment for a response. I&#x27;m not sure about the future of these kinds of services from startups. Given their ability to integrate browsers, emails, cloud storage, photos, and more, Google and Microsoft are likely to develop a similar service. With the resources at their disposal, they could probably design something superior and streamline the process of joining. But for now, I think I&#x27;ll continue using myReach.</div><br/></div></div><div id="36055443" class="c"><input type="checkbox" id="c-36055443" checked=""/><div class="controls bullet"><span class="by">sfjailbird</span><span>|</span><a href="#36054299">parent</a><span>|</span><a href="#36055195">prev</a><span>|</span><a href="#36054781">next</a><span>|</span><label class="collapse" for="c-36055443">[-]</label><label class="expand" for="c-36055443">[2 more]</label></div><br/><div class="children"><div class="content">&quot;Metabyte&quot;. Missed opportunity.</div><br/><div id="36055481" class="c"><input type="checkbox" id="c-36055481" checked=""/><div class="controls bullet"><span class="by">pixelpoet</span><span>|</span><a href="#36054299">root</a><span>|</span><a href="#36055443">parent</a><span>|</span><a href="#36054781">next</a><span>|</span><label class="collapse" for="c-36055481">[-]</label><label class="expand" for="c-36055481">[1 more]</label></div><br/><div class="children"><div class="content">Absolutely ridiculous how they missed this great name, instead choosing the most un-searchable and generic name imagineable.</div><br/></div></div></div></div><div id="36054781" class="c"><input type="checkbox" id="c-36054781" checked=""/><div class="controls bullet"><span class="by">mitthrowaway2</span><span>|</span><a href="#36054299">parent</a><span>|</span><a href="#36055443">prev</a><span>|</span><a href="#36055073">next</a><span>|</span><label class="collapse" for="c-36054781">[-]</label><label class="expand" for="c-36054781">[3 more]</label></div><br/><div class="children"><div class="content">The trick is to search HN submissions and filter by the date you remember reading about it. That&#x27;s how I deal with these unsearchable names.</div><br/><div id="36054849" class="c"><input type="checkbox" id="c-36054849" checked=""/><div class="controls bullet"><span class="by">bckr</span><span>|</span><a href="#36054299">root</a><span>|</span><a href="#36054781">parent</a><span>|</span><a href="#36055073">next</a><span>|</span><label class="collapse" for="c-36054849">[-]</label><label class="expand" for="c-36054849">[2 more]</label></div><br/><div class="children"><div class="content">One step more effective is to keep track of things that keep your interest in a notes app.</div><br/><div id="36055063" class="c"><input type="checkbox" id="c-36055063" checked=""/><div class="controls bullet"><span class="by">abwizz</span><span>|</span><a href="#36054299">root</a><span>|</span><a href="#36054849">parent</a><span>|</span><a href="#36055073">next</a><span>|</span><label class="collapse" for="c-36055063">[-]</label><label class="expand" for="c-36055063">[1 more]</label></div><br/><div class="children"><div class="content">not bad, thou you&#x27;d still have to search and find it</div><br/></div></div></div></div></div></div><div id="36055073" class="c"><input type="checkbox" id="c-36055073" checked=""/><div class="controls bullet"><span class="by">seydor</span><span>|</span><a href="#36054299">parent</a><span>|</span><a href="#36054781">prev</a><span>|</span><a href="#36054554">next</a><span>|</span><label class="collapse" for="c-36055073">[-]</label><label class="expand" for="c-36055073">[1 more]</label></div><br/><div class="children"><div class="content">Patchformers</div><br/></div></div></div></div><div id="36054554" class="c"><input type="checkbox" id="c-36054554" checked=""/><div class="controls bullet"><span class="by">riwsky</span><span>|</span><a href="#36054299">prev</a><span>|</span><a href="#36054406">next</a><span>|</span><label class="collapse" for="c-36054554">[-]</label><label class="expand" for="c-36054554">[1 more]</label></div><br/><div class="children"><div class="content">My LLM is totally real! And she’s the best, way better than GPT-4. But you wouldn’t know her, she goes to another school. In Canada.</div><br/></div></div><div id="36054406" class="c"><input type="checkbox" id="c-36054406" checked=""/><div class="controls bullet"><span class="by">radq</span><span>|</span><a href="#36054554">prev</a><span>|</span><a href="#36055090">next</a><span>|</span><label class="collapse" for="c-36054406">[-]</label><label class="expand" for="c-36054406">[1 more]</label></div><br/><div class="children"><div class="content">This reminds me of the Octuple MIDI tokenization scheme introduced in the MusicBERT paper (<a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2106.05630.pdf" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2106.05630.pdf</a>). Would be interesting to see how much of a performance difference results from using a smaller decoder model (in Megabyte) instead of just doing a softmax (a la Octuple).</div><br/></div></div><div id="36055090" class="c"><input type="checkbox" id="c-36055090" checked=""/><div class="controls bullet"><span class="by">forrestthewoods</span><span>|</span><a href="#36054406">prev</a><span>|</span><a href="#36054539">next</a><span>|</span><label class="collapse" for="c-36055090">[-]</label><label class="expand" for="c-36055090">[1 more]</label></div><br/><div class="children"><div class="content">First “Transformer” architecture and now “Megabyte”? I swear they’re trolling us!<p>We’re just a generation or two away from the “computer” model.</div><br/></div></div><div id="36054539" class="c"><input type="checkbox" id="c-36054539" checked=""/><div class="controls bullet"><span class="by">antman</span><span>|</span><a href="#36055090">prev</a><span>|</span><a href="#36055035">next</a><span>|</span><label class="collapse" for="c-36054539">[-]</label><label class="expand" for="c-36054539">[1 more]</label></div><br/><div class="children"><div class="content">What infrastructure does it require to test?</div><br/></div></div><div id="36055035" class="c"><input type="checkbox" id="c-36055035" checked=""/><div class="controls bullet"><span class="by">andrewstuart</span><span>|</span><a href="#36054539">prev</a><span>|</span><a href="#36054220">next</a><span>|</span><label class="collapse" for="c-36055035">[-]</label><label class="expand" for="c-36055035">[1 more]</label></div><br/><div class="children"><div class="content">Searchability matters.</div><br/></div></div><div id="36054220" class="c"><input type="checkbox" id="c-36054220" checked=""/><div class="controls bullet"><span class="by">HellDunkel</span><span>|</span><a href="#36055035">prev</a><span>|</span><a href="#36054593">next</a><span>|</span><label class="collapse" for="c-36054220">[-]</label><label class="expand" for="c-36054220">[5 more]</label></div><br/><div class="children"><div class="content">Megabyte sounds tiny.</div><br/><div id="36054391" class="c"><input type="checkbox" id="c-36054391" checked=""/><div class="controls bullet"><span class="by">motoxpro</span><span>|</span><a href="#36054220">parent</a><span>|</span><a href="#36054593">next</a><span>|</span><label class="collapse" for="c-36054391">[-]</label><label class="expand" for="c-36054391">[4 more]</label></div><br/><div class="children"><div class="content">Pretty large when things are measured in kilobytes now.</div><br/><div id="36055068" class="c"><input type="checkbox" id="c-36055068" checked=""/><div class="controls bullet"><span class="by">abwizz</span><span>|</span><a href="#36054220">root</a><span>|</span><a href="#36054391">parent</a><span>|</span><a href="#36054860">prev</a><span>|</span><a href="#36054593">next</a><span>|</span><label class="collapse" for="c-36055068">[-]</label><label class="expand" for="c-36055068">[1 more]</label></div><br/><div class="children"><div class="content">feels like the 80&#x27;s again :)<p>double-density floppy gogo!</div><br/></div></div></div></div></div></div><div id="36054593" class="c"><input type="checkbox" id="c-36054593" checked=""/><div class="controls bullet"><span class="by">iamnotsure</span><span>|</span><a href="#36054220">prev</a><span>|</span><label class="collapse" for="c-36054593">[-]</label><label class="expand" for="c-36054593">[1 more]</label></div><br/><div class="children"><div class="content">Yet another example of words appropriation by a large software company for marketing purposes? <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Cultural_appropriation" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Cultural_appropriation</a> ?</div><br/></div></div></div></div></div></div></div></body></html>