<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1712998867886" as="style"/><link rel="stylesheet" href="styles.css?v=1712998867886"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://arxiv.org/abs/2404.07544">Your LLM Is a Capable Regressor When Given In-Context Examples</a> <span class="domain">(<a href="https://arxiv.org">arxiv.org</a>)</span></div><div class="subtext"><span>TaurenHunter</span> | <span>15 comments</span></div><br/><div><div id="40020010" class="c"><input type="checkbox" id="c-40020010" checked=""/><div class="controls bullet"><span class="by">jairuhme</span><span>|</span><a href="#40019861">next</a><span>|</span><label class="collapse" for="c-40020010">[-]</label><label class="expand" for="c-40020010">[4 more]</label></div><br/><div class="children"><div class="content">I&#x27;m a little skeptical.  I grabbed a small dataset and asked ChatGPT to create a linear regression equation and then did the same in excel.  Perhaps they estimate values for beta differently, maybe ChatGPT is secretly a Bayesian, but the output I got was different.  It was close, which I will say is impressive. Also, maybe I missed it, but I think it would be valuable to add to the prompt to provide the estimates for the parameters.  It seemed as if they sort of just took the prediction values, computed MAE, and took the estimate for what it said.  As I type this, I do wonder if you could use it to compute estimates for the parameters iteratively, average them, and essentially compute a bootstrapped estimate for the population parameters..</div><br/><div id="40020137" class="c"><input type="checkbox" id="c-40020137" checked=""/><div class="controls bullet"><span class="by">waldrews</span><span>|</span><a href="#40020010">parent</a><span>|</span><a href="#40020110">next</a><span>|</span><label class="collapse" for="c-40020137">[-]</label><label class="expand" for="c-40020137">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not surprised that a linear regression estimated by a method that <i>knows</i> it should be estimating a linear regression would beat everything else.<p>The traditional OLS estimator in Excel has all sorts of classical optimality properties when its assumptions (normality, linearity) are true, so no fancy neural net can outperform it even in principle (the only way to outperform it would be to have an informative prior for how you generated the data set&#x27;s parameters).  So if the LLM&#x27;s beat, or even matched, Excel in that case, they would be thinking too narrowly.<p>Same with any other models where we know the form of the answer up to some unknown parameters.<p>If we want parameter estimates, that means we already have a functional form in mind.  In that case, we get to use established statistical theory to design optimal estimators, whether by Bayesian or other methods.  Black box neural magic wouldn&#x27;t help (or it might help indirectly, in computationally intractable cases).<p>What we would want the LLM&#x27;s to do, ideally, is explore the space of known&#x2F;possible &#x27;patterns&#x27; and perform well in situations where the underlying relationship exists, is not known in advance, and is known not to have a simple form we can describe.  Much like they (and we!) produce text without being able to describe why they are producing that particular text, we would expect them to make those predictions without being able to explain them in terms of parameters and functions - not without a whole other layer of explainability machinery.</div><br/><div id="40021440" class="c"><input type="checkbox" id="c-40021440" checked=""/><div class="controls bullet"><span class="by">eru</span><span>|</span><a href="#40020010">root</a><span>|</span><a href="#40020137">parent</a><span>|</span><a href="#40020110">next</a><span>|</span><label class="collapse" for="c-40021440">[-]</label><label class="expand" for="c-40021440">[1 more]</label></div><br/><div class="children"><div class="content">&gt; In that case, we get to use established statistical theory to design optimal estimators, whether by Bayesian or other methods. Black box neural magic wouldn&#x27;t help (or it might help indirectly, in computationally intractable cases).<p>Using &#x27;established statistical theory to design optimal estimators&#x27; isn&#x27;t trivial for most people.  Black box magic might still be useful for them.</div><br/></div></div></div></div></div></div><div id="40019861" class="c"><input type="checkbox" id="c-40019861" checked=""/><div class="controls bullet"><span class="by">waldrews</span><span>|</span><a href="#40020010">prev</a><span>|</span><a href="#40021029">next</a><span>|</span><label class="collapse" for="c-40019861">[-]</label><label class="expand" for="c-40019861">[4 more]</label></div><br/><div class="children"><div class="content">The Friedman functions are sufficiently well known to be in the training set, likely in the form of some csv file from somebody testing other methods on them.  Though likely any data set would not share the same x-values. Still, it&#x27;s surprising performance when we&#x27;re used to the LLM&#x27;s getting confused by straightforward math problems and with arithmetic often crippled by the tokenization system.</div><br/><div id="40019943" class="c"><input type="checkbox" id="c-40019943" checked=""/><div class="controls bullet"><span class="by">nerdponx</span><span>|</span><a href="#40019861">parent</a><span>|</span><a href="#40020288">next</a><span>|</span><label class="collapse" for="c-40019943">[-]</label><label class="expand" for="c-40019943">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s surprising, but in a weird way it makes sense if you think about it as &quot;learning a pattern&quot; instead of &quot;doing math&quot;. The model doesn&#x27;t have to understand logic as we know it (and this class of models doesn&#x27;t seem to be able to do that in general), but it does have to be able to learn the pattern <i>somehow</i>, and we already know LLMs can learn patterns from the input context without any fine-tuning.<p>I&#x27;d like to try it on a dataset like Titanic. That might be a more interesting experiment.<p>Or to avoid training data bias, maybe a completely random dataset generated by some more-sophisticated means, like the scikit-learn data generator which can introduce clusters, irrelevant features, etc.</div><br/></div></div><div id="40020288" class="c"><input type="checkbox" id="c-40020288" checked=""/><div class="controls bullet"><span class="by">ianand</span><span>|</span><a href="#40019861">parent</a><span>|</span><a href="#40019943">prev</a><span>|</span><a href="#40020472">next</a><span>|</span><label class="collapse" for="c-40020288">[-]</label><label class="expand" for="c-40020288">[1 more]</label></div><br/><div class="children"><div class="content">They did invent their own functions to test if the results were due to these functions being on the training date. See the section on data contamination in the paper.<p>Agree it both kind of makes sense (regression is the best way to predict the next token in this context) and kind of ironic (LLMs can do high school regression but can’t do elementary school long digit arithmetic).</div><br/></div></div><div id="40020472" class="c"><input type="checkbox" id="c-40020472" checked=""/><div class="controls bullet"><span class="by">choppaface</span><span>|</span><a href="#40019861">parent</a><span>|</span><a href="#40020288">prev</a><span>|</span><a href="#40021029">next</a><span>|</span><label class="collapse" for="c-40020472">[-]</label><label class="expand" for="c-40020472">[1 more]</label></div><br/><div class="children"><div class="content">Missing from the paper: &quot;We were able to verify that none of the in-context exemplars were in OpenAI&#x27;s training set.&quot;<p>I wonder if this paper will make it through peer review? Now that could be an interesting result.</div><br/></div></div></div></div><div id="40021029" class="c"><input type="checkbox" id="c-40021029" checked=""/><div class="controls bullet"><span class="by">smarri</span><span>|</span><a href="#40019861">prev</a><span>|</span><a href="#40020358">next</a><span>|</span><label class="collapse" for="c-40021029">[-]</label><label class="expand" for="c-40021029">[1 more]</label></div><br/><div class="children"><div class="content">Very interesting indeed. My current masters research is is doing related work and I can&#x27;t get this to work on GPT4 (random forest specifically). My as yet untested assumption is my data set needs to be bigger, and&#x2F;or I need more features scores. So its interesting to see someone is getting this to work.</div><br/></div></div><div id="40020358" class="c"><input type="checkbox" id="c-40020358" checked=""/><div class="controls bullet"><span class="by">plxxyzs</span><span>|</span><a href="#40021029">prev</a><span>|</span><a href="#40020368">next</a><span>|</span><label class="collapse" for="c-40020358">[-]</label><label class="expand" for="c-40020358">[4 more]</label></div><br/><div class="children"><div class="content">Ok I tried to get this to work for a long time ~6 months ago. It doesn’t work. You can find datasets where it will work, but if you select random datasets you generally see 0 correlation between the predicted and actual values.</div><br/><div id="40020850" class="c"><input type="checkbox" id="c-40020850" checked=""/><div class="controls bullet"><span class="by">justanotherjoe</span><span>|</span><a href="#40020358">parent</a><span>|</span><a href="#40020368">next</a><span>|</span><label class="collapse" for="c-40020850">[-]</label><label class="expand" for="c-40020850">[3 more]</label></div><br/><div class="children"><div class="content">Hmmm... What do people think in cases like this.  Is the author just straight up lying?</div><br/><div id="40021182" class="c"><input type="checkbox" id="c-40021182" checked=""/><div class="controls bullet"><span class="by">iamflimflam1</span><span>|</span><a href="#40020358">root</a><span>|</span><a href="#40020850">parent</a><span>|</span><a href="#40020368">next</a><span>|</span><label class="collapse" for="c-40021182">[-]</label><label class="expand" for="c-40021182">[2 more]</label></div><br/><div class="children"><div class="content">Well, the datasets used in the paper are all available (Appendix B) - so recreating the experiment seems possible.<p>What we are currently seeing in the comments are people trying random things and then saying “it doesn’t work”.</div><br/><div id="40021442" class="c"><input type="checkbox" id="c-40021442" checked=""/><div class="controls bullet"><span class="by">rvacareanu</span><span>|</span><a href="#40020358">root</a><span>|</span><a href="#40021182">parent</a><span>|</span><a href="#40020368">next</a><span>|</span><label class="collapse" for="c-40021442">[-]</label><label class="expand" for="c-40021442">[1 more]</label></div><br/><div class="children"><div class="content">Chat examples with GPT-4: <a href="https:&#x2F;&#x2F;github.com&#x2F;robertvacareanu&#x2F;llm4regression&#x2F;tree&#x2F;main&#x2F;data&#x2F;prompts">https:&#x2F;&#x2F;github.com&#x2F;robertvacareanu&#x2F;llm4regression&#x2F;tree&#x2F;main&#x2F;...</a> (the experiments used the API though)<p>For example, for Friedman #1, GPT-4 predicts 12.89 while the true value is 11.69 (<a href="https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;177571ad-3845-46a1-952f-963647620bea" rel="nofollow">https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;177571ad-3845-46a1-952f-963647...</a>)<p>For Original #1, GPT-4 predicts 83.63 while the true value is 80.39 (<a href="https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;808da995-99e6-444a-94da-fc7cd5ad49ff" rel="nofollow">https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;808da995-99e6-444a-94da-fc7cd5...</a>)</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></body></html>