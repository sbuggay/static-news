<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1718701258927" as="style"/><link rel="stylesheet" href="styles.css?v=1718701258927"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://chipsandcheese.com/2024/06/15/intel-details-skymont/">Intel details Skymont</a> <span class="domain">(<a href="https://chipsandcheese.com">chipsandcheese.com</a>)</span></div><div class="subtext"><span>rbanffy</span> | <span>33 comments</span></div><br/><div><div id="40712966" class="c"><input type="checkbox" id="c-40712966" checked=""/><div class="controls bullet"><span class="by">pclmulqdq</span><span>|</span><a href="#40715403">next</a><span>|</span><label class="collapse" for="c-40712966">[-]</label><label class="expand" for="c-40712966">[17 more]</label></div><br/><div class="children"><div class="content">It looks like the next generation of *mont cores will be as big and capable as Skylakes. With E cores like this, who needs P cores?<p>Also, Intel was definitely onto something with the split decoders IMO. The x86 instruction set hurts to decode 8-wide in a single thread, but most code is branchy and loopy, so you only hurt in this configuration if loops are really big. Tight loops come from the uop cache, and branchy code gets 3-way decoding.</div><br/><div id="40713865" class="c"><input type="checkbox" id="c-40713865" checked=""/><div class="controls bullet"><span class="by">phire</span><span>|</span><a href="#40712966">parent</a><span>|</span><a href="#40714360">next</a><span>|</span><label class="collapse" for="c-40713865">[-]</label><label class="expand" for="c-40713865">[9 more]</label></div><br/><div class="children"><div class="content"><i>&gt; Tight loops come from the uop cache, and branchy code gets 3-way decoding.</i><p>First, there is no uop cache on the &quot;mont&quot; cores.<p>Second, Intel aren&#x27;t decoding both sides of the branch.<p>That wouldn&#x27;t actually help much, as modern branch predictors are correct well over 99% of the time. It would be a waste of silicon and power to have an extra decoder producing work which simply decoded most of the time, and an even bigger waste to have two extra decoders.<p>Intel&#x27;s actual approach is way more clever; They run the branch predictor ahead of the decoders by at least 3 branches (probably more). The branch predictor can spit out a new prediction every cycle, and it just plops them on a queue.<p>Each of the three decoders pops a branch prediction off the queue and starts decoding there. At any time, all three decoders will each be decoding a different basic block. A basic block that the branch predictor has predicted that the program counter is about to flow through. The three decoders are leap frogging each other. The decoding of each basic block is limited to a throughput of three instructions per cycle, but Skymont is decoding three basic blocks in parallel.<p>The decoded uops get pushed onto three independent queues, and the re-namer&#x2F;dispatcher merges these three queues back together in original program order before dispatching to the backend. Each decoder can only push three uops per cycle onto its queue, but the re-namer&#x2F;dispatcher can pull them off a single queue at the rate of 9 uops per cycle. The other two queues will continue to fill up while one queue is being drained.<p>The branch prediction result will always land on an instruction boundary, so this design allows the three decoders to combine their efforts and maintain a throughput of 9 uops per cycle, as long as the code is branchy enough. It works on loops too, as far as I&#x27;m aware, intel doesn&#x27;t even have a loop stream buffer on this design; The three decoders will be decoding the exact same instructions in parallel for loop bodies.<p>But Intel have a neat trick to make this work even on code without branches or loops. The branch predictor actually inserts fake branches into the middle of long basic blocks. The branch predictor isn&#x27;t actually checking an address to see if it has a branch. Instead it predicts the gap between branches, and they simply have a limit for the size of those gaps. Looks like that limit for Skymont is 64 bytes (was previously 32 bytes for Crestmont)</div><br/><div id="40715201" class="c"><input type="checkbox" id="c-40715201" checked=""/><div class="controls bullet"><span class="by">gpderetta</span><span>|</span><a href="#40712966">root</a><span>|</span><a href="#40713865">parent</a><span>|</span><a href="#40714900">next</a><span>|</span><label class="collapse" for="c-40715201">[-]</label><label class="expand" for="c-40715201">[1 more]</label></div><br/><div class="children"><div class="content">Thanks, that&#x27;s a nice explanation. I hadn&#x27;t looked in details of how the multiple decoders in the *monts worked. Relying on branches and prediction to find the instruction boundaries is quite a nifty trick.</div><br/></div></div><div id="40714900" class="c"><input type="checkbox" id="c-40714900" checked=""/><div class="controls bullet"><span class="by">ithkuil</span><span>|</span><a href="#40712966">root</a><span>|</span><a href="#40713865">parent</a><span>|</span><a href="#40715201">prev</a><span>|</span><a href="#40714537">next</a><span>|</span><label class="collapse" for="c-40714900">[-]</label><label class="expand" for="c-40714900">[3 more]</label></div><br/><div class="children"><div class="content">If the branch predictor to predict branches ahead it needs to know where the branches instructions are. Is there a mini decoder tasked to just decode the instruction stream just enough to handle the variable length instructions and figure out where the branches are? Or am I fundamentally misunderstanding how branch prediction works (which likely I am)?</div><br/><div id="40715095" class="c"><input type="checkbox" id="c-40715095" checked=""/><div class="controls bullet"><span class="by">phire</span><span>|</span><a href="#40712966">root</a><span>|</span><a href="#40714900">parent</a><span>|</span><a href="#40714537">next</a><span>|</span><label class="collapse" for="c-40715095">[-]</label><label class="expand" for="c-40715095">[2 more]</label></div><br/><div class="children"><div class="content">There seems to be a very common misconception about branch prediction, that its only job is to predict the direction of the branch.<p>In reality, the problem is so much deeper. The instruction fetch stage simply can&#x27;t see the branch at all. Not just conditional branches, but unconditional jumps, calls and even returns too.<p>Even a simple 5 stage &quot;classic RISC&quot; pipeline takes a full two cycles to load the instruction from memory and decode before it can see it, and your instruction fetch stage has already fetched two incorrect instructions (though many RISC implementations cheat with an instruction cache fetch that takes half a cycle, and then adding a delay slot).<p>In one of these massive out-of-order CPUs, the icache fetch might take multiple cycles, (then length decoding on x86),  so it might take 4 or 5 cycles before the instruction could possibly be decoded. And if you are decoding 4 instructions per cycle, that&#x27;s 20 incorrect instructions fetched from icache.<p>To actually continue fetching without any gaps, the branch predictors needs to predict:<p>1. The location of the branch<p>2. The type of branch, and (for conditional branches) if it&#x27;s taken or not.<p>3. The destination of the branch</div><br/><div id="40715231" class="c"><input type="checkbox" id="c-40715231" checked=""/><div class="controls bullet"><span class="by">ithkuil</span><span>|</span><a href="#40712966">root</a><span>|</span><a href="#40715095">parent</a><span>|</span><a href="#40714537">next</a><span>|</span><label class="collapse" for="c-40715231">[-]</label><label class="expand" for="c-40715231">[1 more]</label></div><br/><div class="children"><div class="content">ok that makes much more sense how; thanks!<p>follow up question: if the branch is predicted to not be taken, why does the predictor have to use resources to record its location and the destination?</div><br/></div></div></div></div></div></div><div id="40714537" class="c"><input type="checkbox" id="c-40714537" checked=""/><div class="controls bullet"><span class="by">soulbadguy</span><span>|</span><a href="#40712966">root</a><span>|</span><a href="#40713865">parent</a><span>|</span><a href="#40714900">prev</a><span>|</span><a href="#40714343">next</a><span>|</span><label class="collapse" for="c-40714537">[-]</label><label class="expand" for="c-40714537">[3 more]</label></div><br/><div class="children"><div class="content">I fancy myself of having a good understanding of modern uarch. But i have to agree with @Marthinwurer. This branch predictor structure with parallel predictor and fake branch address is quite wild.<p>Do you know how this compare to what AMD&#x2F;AppleM&#x2F;Qualcom is doing ? This seems super effective, but seems pretty power hungry as opposed to just increasing the chase size and predictor precision. Plus i would assume it makes the cost of miss-predict even higher.</div><br/><div id="40715178" class="c"><input type="checkbox" id="c-40715178" checked=""/><div class="controls bullet"><span class="by">phire</span><span>|</span><a href="#40712966">root</a><span>|</span><a href="#40714537">parent</a><span>|</span><a href="#40715190">next</a><span>|</span><label class="collapse" for="c-40715178">[-]</label><label class="expand" for="c-40715178">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m pretty sure the patten of allowing the branch predictor to run ahead is pretty common.<p>At least, it&#x27;s common to have multi-level branch predictors that take a variable number of cycles to return a result, and it makes a lot of sense to queue up predictions so they are ready when the decoder gets to that point.<p>But I doubt the idea of parallel decoders makes any sense out side of x86&#x27;s complex variable length instructions.<p>It (probably) makes sense on x86 because x86 cores were already spending a bunch of power on instruction decoding and the uop cache.<p><i>&gt; Plus i would assume it makes the cost of miss-predict even higher.</i><p>It shouldn&#x27;t increase the miss-predict cost by too much.<p>The new fetch address will bypass the branch-prediction queue and feed directly into one of the three decoders. And previous implementations already have a uop queue between the decoder and re-name&#x2F;dispatch. It gets flushed and the first three uops should be able to cross it in a single cycle.</div><br/></div></div><div id="40715190" class="c"><input type="checkbox" id="c-40715190" checked=""/><div class="controls bullet"><span class="by">gpderetta</span><span>|</span><a href="#40712966">root</a><span>|</span><a href="#40714537">parent</a><span>|</span><a href="#40715178">prev</a><span>|</span><a href="#40714343">next</a><span>|</span><label class="collapse" for="c-40715190">[-]</label><label class="expand" for="c-40715190">[1 more]</label></div><br/><div class="children"><div class="content">It is actually probably cheaper than the alternative of attempting to decode at all possible instruction boundaries in parallel!</div><br/></div></div></div></div><div id="40714343" class="c"><input type="checkbox" id="c-40714343" checked=""/><div class="controls bullet"><span class="by">Marthinwurer</span><span>|</span><a href="#40712966">root</a><span>|</span><a href="#40713865">parent</a><span>|</span><a href="#40714537">prev</a><span>|</span><a href="#40714360">next</a><span>|</span><label class="collapse" for="c-40714343">[-]</label><label class="expand" for="c-40714343">[1 more]</label></div><br/><div class="children"><div class="content">Thank you for that explanation, I was confused as to what was happening with the multiple decoders. That&#x27;s a wild way to implement a processor front end.</div><br/></div></div></div></div><div id="40714360" class="c"><input type="checkbox" id="c-40714360" checked=""/><div class="controls bullet"><span class="by">skavi</span><span>|</span><a href="#40712966">parent</a><span>|</span><a href="#40713865">prev</a><span>|</span><a href="#40713371">next</a><span>|</span><label class="collapse" for="c-40714360">[-]</label><label class="expand" for="c-40714360">[1 more]</label></div><br/><div class="children"><div class="content">The two generation old Gracemont already beat Skylake [0]. Skymont can beat Raptor Cove [1] (The big core that was paired with Gracemont).<p>[0]: <a href="https:&#x2F;&#x2F;www.anandtech.com&#x2F;show&#x2F;16881&#x2F;a-deep-dive-into-intels-alder-lake-microarchitectures&#x2F;4" rel="nofollow">https:&#x2F;&#x2F;www.anandtech.com&#x2F;show&#x2F;16881&#x2F;a-deep-dive-into-intels...</a><p>[1]: <a href="https:&#x2F;&#x2F;www.anandtech.com&#x2F;show&#x2F;21425&#x2F;intel-lunar-lake-architecture-deep-dive-lion-cove-xe2-and-npu4&#x2F;3" rel="nofollow">https:&#x2F;&#x2F;www.anandtech.com&#x2F;show&#x2F;21425&#x2F;intel-lunar-lake-archit...</a></div><br/></div></div><div id="40713371" class="c"><input type="checkbox" id="c-40713371" checked=""/><div class="controls bullet"><span class="by">deaddodo</span><span>|</span><a href="#40712966">parent</a><span>|</span><a href="#40714360">prev</a><span>|</span><a href="#40714203">next</a><span>|</span><label class="collapse" for="c-40713371">[-]</label><label class="expand" for="c-40713371">[5 more]</label></div><br/><div class="children"><div class="content">&gt; With E cores like this, who needs P cores?<p>Because, presumably, the P-cores are even beefier.<p>Intel and AMD are still trying to gain time on the slow march to ARM (particularly Apple) catching up. Both of their long term strategies seem to differ (AMD edging back into ARM itself, Intel being a little more close lipped), but they can&#x27;t lose their one major edge (raw performance) or potentially more users switch to an x86-excluded (and, more importantly, third-party excluded) platform (Mac).</div><br/><div id="40713563" class="c"><input type="checkbox" id="c-40713563" checked=""/><div class="controls bullet"><span class="by">metadat</span><span>|</span><a href="#40712966">root</a><span>|</span><a href="#40713371">parent</a><span>|</span><a href="#40714203">next</a><span>|</span><label class="collapse" for="c-40713563">[-]</label><label class="expand" for="c-40713563">[4 more]</label></div><br/><div class="children"><div class="content">Is ARM really that special?  Why do you believe this is the case?</div><br/><div id="40713628" class="c"><input type="checkbox" id="c-40713628" checked=""/><div class="controls bullet"><span class="by">thunderbird120</span><span>|</span><a href="#40712966">root</a><span>|</span><a href="#40713563">parent</a><span>|</span><a href="#40714303">next</a><span>|</span><label class="collapse" for="c-40713628">[-]</label><label class="expand" for="c-40713628">[1 more]</label></div><br/><div class="children"><div class="content">The ISA is much less important than many people seem to think. The RISC vs CISC debate is beyond outdated at this point because no modern architecture actually works strictly like either under the hood. Organizations who did x86 architectures historically had much more emphasis on performance while organizations who did ARM had more emphasis on low power devices. The lingering engineering consequences of that history and the experience of the organizations doing design are orders of magnitude more relevant than the difference in actual ISA.</div><br/></div></div><div id="40714303" class="c"><input type="checkbox" id="c-40714303" checked=""/><div class="controls bullet"><span class="by">Dalewyn</span><span>|</span><a href="#40712966">root</a><span>|</span><a href="#40713563">parent</a><span>|</span><a href="#40713628">prev</a><span>|</span><a href="#40714203">next</a><span>|</span><label class="collapse" for="c-40714303">[-]</label><label class="expand" for="c-40714303">[2 more]</label></div><br/><div class="children"><div class="content">ARM is special in that it&#x27;s the only potential, realistic competitor to x86 left in the entire industry. RISC-V? Only if you&#x27;re a zealot breathing fumes for life energy, at least as things stand today.</div><br/><div id="40714613" class="c"><input type="checkbox" id="c-40714613" checked=""/><div class="controls bullet"><span class="by">gary_0</span><span>|</span><a href="#40712966">root</a><span>|</span><a href="#40714303">parent</a><span>|</span><a href="#40714203">next</a><span>|</span><label class="collapse" for="c-40714613">[-]</label><label class="expand" for="c-40714613">[1 more]</label></div><br/><div class="children"><div class="content">The interesting thing about RISC-V is that there are like 10 billion RISC-V microcontrollers out there that otherwise would have been ARM. So ARM has been moving into the PC&#x2F;server space while RISC-V pushes in from behind, at the opposite end of the line from x86.</div><br/></div></div></div></div></div></div></div></div><div id="40714203" class="c"><input type="checkbox" id="c-40714203" checked=""/><div class="controls bullet"><span class="by">ls612</span><span>|</span><a href="#40712966">parent</a><span>|</span><a href="#40713371">prev</a><span>|</span><a href="#40715403">next</a><span>|</span><label class="collapse" for="c-40714203">[-]</label><label class="expand" for="c-40714203">[1 more]</label></div><br/><div class="children"><div class="content">I did the math and even on current 13900k&#x2F;14900k chips each E-core is roughly equivalent to a stock Skylake 6700k core.</div><br/></div></div></div></div><div id="40715403" class="c"><input type="checkbox" id="c-40715403" checked=""/><div class="controls bullet"><span class="by">giladvdn</span><span>|</span><a href="#40712966">prev</a><span>|</span><a href="#40713017">next</a><span>|</span><label class="collapse" for="c-40715403">[-]</label><label class="expand" for="c-40715403">[1 more]</label></div><br/><div class="children"><div class="content">How do these modern Atoms compare to the Apple ARM chips? Does Apple make something comparable in terms of power&#x2F;performance?</div><br/></div></div><div id="40713017" class="c"><input type="checkbox" id="c-40713017" checked=""/><div class="controls bullet"><span class="by">kristianp</span><span>|</span><a href="#40715403">prev</a><span>|</span><a href="#40713030">next</a><span>|</span><label class="collapse" for="c-40713017">[-]</label><label class="expand" for="c-40713017">[1 more]</label></div><br/><div class="children"><div class="content">So Skymont is the architecture of the Efficiency core of Lunar lake:<p><a href="https:&#x2F;&#x2F;www.anandtech.com&#x2F;show&#x2F;21425&#x2F;intel-lunar-lake-architecture-deep-dive-lion-cove-xe2-and-npu4&#x2F;3" rel="nofollow">https:&#x2F;&#x2F;www.anandtech.com&#x2F;show&#x2F;21425&#x2F;intel-lunar-lake-archit...</a><p>It&#x27;s so new that the Wikipedia page hasn&#x27;t been written yet, it still redirects to the old usage of the codename as the previous name of Cannon Lake. Or it should redirect to a Lunar Lake page:<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;?title=Skymont_(microarchitecture)&amp;redirect=no" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;?title=Skymont_(microarchitecture)&amp;...</a></div><br/></div></div><div id="40713030" class="c"><input type="checkbox" id="c-40713030" checked=""/><div class="controls bullet"><span class="by">tedunangst</span><span>|</span><a href="#40713017">prev</a><span>|</span><a href="#40713746">next</a><span>|</span><label class="collapse" for="c-40713030">[-]</label><label class="expand" for="c-40713030">[6 more]</label></div><br/><div class="children"><div class="content">TIL rounding denormals to zero is what -ffast-math actually does.</div><br/><div id="40713621" class="c"><input type="checkbox" id="c-40713621" checked=""/><div class="controls bullet"><span class="by">CJefferson</span><span>|</span><a href="#40713030">parent</a><span>|</span><a href="#40713106">next</a><span>|</span><label class="collapse" for="c-40713621">[-]</label><label class="expand" for="c-40713621">[1 more]</label></div><br/><div class="children"><div class="content">-ffast-mast does a whole bunch of things, which I wish people&#x27;s didn&#x27;t so commonly combine.<p>For example, I think the things it does which are sensible for most people are:<p>* Rounding subnormals to zero<p>* Disabling signed zeroes<p>* Disables support for &#x27;trapping&#x27; (throwing SIGFPE)<p>Then there are the &#x27;middle&#x27; things, which annoy some people:<p>* Allow associative operations, and things like sqrt(x<i>y)=sqrt(x)</i>sqrt(y), exp(x)*exp(y)=exp(x+y)<p>However, it also (which I often find break code) assumes no operation will make a NaN or an Infinity -- these last two don&#x27;t really help, and also break code in confusing ways. This being gcc, they don&#x27;t just change things like std::isnan or std::isinf into an &#x27;abort&#x27; (which would make sense, in -ffast-math they don&#x27;t make sense), they just return nonsense instead.</div><br/></div></div><div id="40713106" class="c"><input type="checkbox" id="c-40713106" checked=""/><div class="controls bullet"><span class="by">kibwen</span><span>|</span><a href="#40713030">parent</a><span>|</span><a href="#40713621">prev</a><span>|</span><a href="#40713208">next</a><span>|</span><label class="collapse" for="c-40713106">[-]</label><label class="expand" for="c-40713106">[1 more]</label></div><br/><div class="children"><div class="content">Not sure if I should be relieved or concerned that even Ted Unangst doesn&#x27;t know what -ffast-math actually does.<p>(For the record, it does a whole lot of terrible things: <a href="https:&#x2F;&#x2F;stackoverflow.com&#x2F;questions&#x2F;7420665&#x2F;what-does-gccs-ffast-math-actually-do" rel="nofollow">https:&#x2F;&#x2F;stackoverflow.com&#x2F;questions&#x2F;7420665&#x2F;what-does-gccs-f...</a> )</div><br/></div></div><div id="40713208" class="c"><input type="checkbox" id="c-40713208" checked=""/><div class="controls bullet"><span class="by">pclmulqdq</span><span>|</span><a href="#40713030">parent</a><span>|</span><a href="#40713106">prev</a><span>|</span><a href="#40715233">next</a><span>|</span><label class="collapse" for="c-40713208">[-]</label><label class="expand" for="c-40713208">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s more. It also enables some limited (unsafe) rearrangement of your floating point expressions, as well as a few other settings inside the floating point system. Flushing denorms to 0 is only part of it.<p>It also will do things like using an approximate reciprocal square root instruction plus a refinement iteration instead of fsqrt then fdiv.</div><br/></div></div><div id="40715233" class="c"><input type="checkbox" id="c-40715233" checked=""/><div class="controls bullet"><span class="by">gpderetta</span><span>|</span><a href="#40713030">parent</a><span>|</span><a href="#40713208">prev</a><span>|</span><a href="#40713972">next</a><span>|</span><label class="collapse" for="c-40715233">[-]</label><label class="expand" for="c-40715233">[1 more]</label></div><br/><div class="children"><div class="content">I think the linking with the flush-to-zero code nonsense has been moved to a separate flag in recent GCCs.</div><br/></div></div><div id="40713972" class="c"><input type="checkbox" id="c-40713972" checked=""/><div class="controls bullet"><span class="by">sgerenser</span><span>|</span><a href="#40713030">parent</a><span>|</span><a href="#40715233">prev</a><span>|</span><a href="#40713746">next</a><span>|</span><label class="collapse" for="c-40713972">[-]</label><label class="expand" for="c-40713972">[1 more]</label></div><br/><div class="children"><div class="content">I also learned from experience that -ffast-math only enables the FTZ&#x2F;DAZ optimization on the main thread, at least on Linux&#x2F;X86. I don’t know if its universal or this has changed since I debugged it ~5-6 years ago, but that proved to be a bit hard to get to the bottom of since I immediately suspected the big CPU spike when the volume was set very low was caused by denormals, yet we were using the —ffast-math gcc flag.</div><br/></div></div></div></div><div id="40714933" class="c"><input type="checkbox" id="c-40714933" checked=""/><div class="controls bullet"><span class="by">srg0</span><span>|</span><a href="#40713746">prev</a><span>|</span><a href="#40715093">next</a><span>|</span><label class="collapse" for="c-40714933">[-]</label><label class="expand" for="c-40714933">[2 more]</label></div><br/><div class="children"><div class="content">Slightly offtopic. What would you suggest as an introductory text on modern CPU architectures?</div><br/><div id="40715191" class="c"><input type="checkbox" id="c-40715191" checked=""/><div class="controls bullet"><span class="by">apples_oranges</span><span>|</span><a href="#40714933">parent</a><span>|</span><a href="#40715093">next</a><span>|</span><label class="collapse" for="c-40715191">[-]</label><label class="expand" for="c-40715191">[1 more]</label></div><br/><div class="children"><div class="content">I would start with a college&#x2F;university course on the topic, there should be tons of slides and lectures available for free. And only after knowing basic concepts and common approaches I would look for some recent documents, probably they can be downloaded from Intel and other chip makers. But I would say that it all depends on where you are starting from and how deep you want to go.</div><br/></div></div></div></div><div id="40715093" class="c"><input type="checkbox" id="c-40715093" checked=""/><div class="controls bullet"><span class="by">formvoltron</span><span>|</span><a href="#40714933">prev</a><span>|</span><a href="#40713827">next</a><span>|</span><label class="collapse" for="c-40715093">[-]</label><label class="expand" for="c-40715093">[2 more]</label></div><br/><div class="children"><div class="content">Could these processors help Intel move further into AI inference?</div><br/><div id="40715258" class="c"><input type="checkbox" id="c-40715258" checked=""/><div class="controls bullet"><span class="by">null_investor</span><span>|</span><a href="#40715093">parent</a><span>|</span><a href="#40713827">next</a><span>|</span><label class="collapse" for="c-40715258">[-]</label><label class="expand" for="c-40715258">[1 more]</label></div><br/><div class="children"><div class="content">They already have the Gaudi chip for AI, Skymont is a different kind</div><br/></div></div></div></div><div id="40714403" class="c"><input type="checkbox" id="c-40714403" checked=""/><div class="controls bullet"><span class="by">badrabbit</span><span>|</span><a href="#40713827">prev</a><span>|</span><label class="collapse" for="c-40714403">[-]</label><label class="expand" for="c-40714403">[1 more]</label></div><br/><div class="children"><div class="content">More cores and memory channels+bandwidth would have been nice.</div><br/></div></div></div></div></div></div></div></body></html>