<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1717059669946" as="style"/><link rel="stylesheet" href="styles.css?v=1717059669946"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://mistral.ai/news/codestral/">Codestral: Mistral&#x27;s Code Model</a> <span class="domain">(<a href="https://mistral.ai">mistral.ai</a>)</span></div><div class="subtext"><span>alexmolas</span> | <span>193 comments</span></div><br/><div><div id="40513224" class="c"><input type="checkbox" id="c-40513224" checked=""/><div class="controls bullet"><span class="by">analyte123</span><span>|</span><a href="#40513020">next</a><span>|</span><label class="collapse" for="c-40513224">[-]</label><label class="expand" for="c-40513224">[52 more]</label></div><br/><div class="children"><div class="content">The license for this [1] prohibits use of the model and its outputs for any commercial activity, or even any &quot;live&quot; (whatever that means) conditions, commercial or not.<p>There seems to be an exclusion for using the code outputs as part of &quot;development&quot;. But wait! It also prohibits &quot;any internal usage by employees in the context of the company&#x27;s business activities&quot;. However you interpret these clauses, this puts their claims and comparisons on completely unequal ground. They only compare to other open-weight models, not GPT-4 or Opus, but a normal company or individual can do whatever they want with the Llama weights and outputs. LangChain? &quot;Your favourite coding and building environment&quot;? Who cares? It seems you&#x27;re not allowed to integrate this with anything else and show it to anyone, even as an art project.<p>[1] <a href="https:&#x2F;&#x2F;mistral.ai&#x2F;licenses&#x2F;MNPL-0.1.md" rel="nofollow">https:&#x2F;&#x2F;mistral.ai&#x2F;licenses&#x2F;MNPL-0.1.md</a></div><br/><div id="40513335" class="c"><input type="checkbox" id="c-40513335" checked=""/><div class="controls bullet"><span class="by">foobiekr</span><span>|</span><a href="#40513224">parent</a><span>|</span><a href="#40513774">next</a><span>|</span><label class="collapse" for="c-40513335">[-]</label><label class="expand" for="c-40513335">[28 more]</label></div><br/><div class="children"><div class="content">There&#x27;s some irony in the fact that people will ignore this license in exactly the same way Mistral and all the other LLM guys ignore the copyright and licensing on the works they ingest.</div><br/><div id="40521467" class="c"><input type="checkbox" id="c-40521467" checked=""/><div class="controls bullet"><span class="by">rldjbpin</span><span>|</span><a href="#40513224">root</a><span>|</span><a href="#40513335">parent</a><span>|</span><a href="#40514558">next</a><span>|</span><label class="collapse" for="c-40521467">[-]</label><label class="expand" for="c-40521467">[1 more]</label></div><br/><div class="children"><div class="content">should it be morally ok to not follow these kinds of license, maybe except when you are selling a service without making any changes? i wonder what people visiting this site thinks about this.</div><br/></div></div><div id="40514558" class="c"><input type="checkbox" id="c-40514558" checked=""/><div class="controls bullet"><span class="by">belter</span><span>|</span><a href="#40513224">root</a><span>|</span><a href="#40513335">parent</a><span>|</span><a href="#40521467">prev</a><span>|</span><a href="#40515646">next</a><span>|</span><label class="collapse" for="c-40514558">[-]</label><label class="expand" for="c-40514558">[1 more]</label></div><br/><div class="children"><div class="content">And nobody will sue anybody because suing means...discovery....</div><br/></div></div><div id="40515646" class="c"><input type="checkbox" id="c-40515646" checked=""/><div class="controls bullet"><span class="by">hehdhdjehehegwv</span><span>|</span><a href="#40513224">root</a><span>|</span><a href="#40513335">parent</a><span>|</span><a href="#40514558">prev</a><span>|</span><a href="#40515727">next</a><span>|</span><label class="collapse" for="c-40515646">[-]</label><label class="expand" for="c-40515646">[17 more]</label></div><br/><div class="children"><div class="content">So basically I, as an open source author, had my code eaten up by Mistral without my consent, but if I want to use their code model I’m subject to a bunch of restrictions that benefit their bottom line?<p>The problem these AI companies have is they live in a glass house and they can’t throw IP rocks around without breaking their own “your content is our training data” foundation.<p>They only reason I can think of that Google doesn’t go after OpenAI for scraping YouTube is then they’d put themselves in the same crosshairs, and may set a precedent they’d also be bound by.<p>Given the model is “on the web” I have the same rights as Mistral to use anything online however I want without regard for IP, right?<p>Utter absurdity.</div><br/><div id="40520315" class="c"><input type="checkbox" id="c-40520315" checked=""/><div class="controls bullet"><span class="by">esperent</span><span>|</span><a href="#40513224">root</a><span>|</span><a href="#40515646">parent</a><span>|</span><a href="#40520356">next</a><span>|</span><label class="collapse" for="c-40520315">[-]</label><label class="expand" for="c-40520315">[1 more]</label></div><br/><div class="children"><div class="content">I used to spend a lot of time (thousands of hours) contributing to open source projects. Over the past few years I&#x27;ve stopped contributing (except minor fixes) to any project under MIT&#x2F;Apache or similar licences.<p>Has anyone else done this?</div><br/></div></div><div id="40520356" class="c"><input type="checkbox" id="c-40520356" checked=""/><div class="controls bullet"><span class="by">rvz</span><span>|</span><a href="#40513224">root</a><span>|</span><a href="#40515646">parent</a><span>|</span><a href="#40520315">prev</a><span>|</span><a href="#40515906">next</a><span>|</span><label class="collapse" for="c-40520356">[-]</label><label class="expand" for="c-40520356">[1 more]</label></div><br/><div class="children"><div class="content">&gt; They only reason I can think of that Google doesn’t go after OpenAI for scraping YouTube is then they’d put themselves in the same crosshairs, and may set a precedent they’d also be bound by.<p>It will be the smartphone patent wars all over again with hundreds of lawsuits against big tech and AI companies.<p>We are already past the &#x27;fair use&#x27; excuses at this point especially when OpenAI is slowly striking deals with news companies to train on their content (with their permission)  and <i>with</i> intent of commercializing the model.</div><br/></div></div><div id="40515906" class="c"><input type="checkbox" id="c-40515906" checked=""/><div class="controls bullet"><span class="by">htrp</span><span>|</span><a href="#40513224">root</a><span>|</span><a href="#40515646">parent</a><span>|</span><a href="#40520356">prev</a><span>|</span><a href="#40520343">next</a><span>|</span><label class="collapse" for="c-40515906">[-]</label><label class="expand" for="c-40515906">[3 more]</label></div><br/><div class="children"><div class="content">call it an Enterprise poison pill.</div><br/><div id="40516446" class="c"><input type="checkbox" id="c-40516446" checked=""/><div class="controls bullet"><span class="by">hehdhdjehehegwv</span><span>|</span><a href="#40513224">root</a><span>|</span><a href="#40515906">parent</a><span>|</span><a href="#40520343">next</a><span>|</span><label class="collapse" for="c-40516446">[-]</label><label class="expand" for="c-40516446">[2 more]</label></div><br/><div class="children"><div class="content">But a pill they also have to swallow.</div><br/><div id="40516969" class="c"><input type="checkbox" id="c-40516969" checked=""/><div class="controls bullet"><span class="by">dodslaser</span><span>|</span><a href="#40513224">root</a><span>|</span><a href="#40516446">parent</a><span>|</span><a href="#40520343">next</a><span>|</span><label class="collapse" for="c-40516969">[-]</label><label class="expand" for="c-40516969">[1 more]</label></div><br/><div class="children"><div class="content">Enterprise suicide cult.</div><br/></div></div></div></div></div></div><div id="40520343" class="c"><input type="checkbox" id="c-40520343" checked=""/><div class="controls bullet"><span class="by">paulddraper</span><span>|</span><a href="#40513224">root</a><span>|</span><a href="#40515646">parent</a><span>|</span><a href="#40515906">prev</a><span>|</span><a href="#40516962">next</a><span>|</span><label class="collapse" for="c-40520343">[-]</label><label class="expand" for="c-40520343">[1 more]</label></div><br/><div class="children"><div class="content">No. You are welcome to learn from Mistral&#x27;s works, either as a meatbag or via machine agent.<p>You are not allowed to reproduce Mistral&#x27;s works (beyond the usual Fair Use allowances).<p>Nor is Mistral entitled to reproduce your works (unless you have licensed as such).<p>If it does, you can sue for copyright infringement.</div><br/></div></div><div id="40516962" class="c"><input type="checkbox" id="c-40516962" checked=""/><div class="controls bullet"><span class="by">IshKebab</span><span>|</span><a href="#40513224">root</a><span>|</span><a href="#40515646">parent</a><span>|</span><a href="#40520343">prev</a><span>|</span><a href="#40515727">next</a><span>|</span><label class="collapse" for="c-40516962">[-]</label><label class="expand" for="c-40516962">[10 more]</label></div><br/><div class="children"><div class="content">&gt; So basically I, as an open source author, had my code eaten up by Mistral without my consent<p>Not necessarily. You consented to people reading your code and learning from it when you posted it on Github. Whether or not there&#x27;s an issue with AI doing the same remains to be settled. It certainly isn&#x27;t clear cut that separate consent would be required.</div><br/><div id="40517089" class="c"><input type="checkbox" id="c-40517089" checked=""/><div class="controls bullet"><span class="by">Liquix</span><span>|</span><a href="#40513224">root</a><span>|</span><a href="#40516962">parent</a><span>|</span><a href="#40519979">next</a><span>|</span><label class="collapse" for="c-40517089">[-]</label><label class="expand" for="c-40517089">[4 more]</label></div><br/><div class="children"><div class="content">MIT&#x2F;BSD code is fair game, but isn&#x27;t the whole point of GPL&#x2F;AGPL &quot;you can read and share and use this, but you can&#x27;t take it and roll it into your closed commercial product for profit&quot;? It seems like what Mistral and co are doing is a fundamental violation of the one thing GPL is striving to enforce.</div><br/><div id="40520249" class="c"><input type="checkbox" id="c-40520249" checked=""/><div class="controls bullet"><span class="by">gpm</span><span>|</span><a href="#40513224">root</a><span>|</span><a href="#40517089">parent</a><span>|</span><a href="#40520414">next</a><span>|</span><label class="collapse" for="c-40520249">[-]</label><label class="expand" for="c-40520249">[1 more]</label></div><br/><div class="children"><div class="content">No. Either MIT&#x2F;BSD code isn&#x27;t fair game because it requires attribution, or GPL&#x2F;AGPL code is fair game because it isn&#x27;t copyright infringement in the first place so no license is required.<p>It&#x27;ll be a court fight to determine which. Worse, it will be a court fight that plays out in a bunch of different countries and they probably won&#x27;t all come to the same conclusion. It&#x27;s unlikely the two licenses have a different effect here though. Either they both forbid it, or neither had the power to forbid it in the first place.</div><br/></div></div><div id="40520414" class="c"><input type="checkbox" id="c-40520414" checked=""/><div class="controls bullet"><span class="by">rvz</span><span>|</span><a href="#40513224">root</a><span>|</span><a href="#40517089">parent</a><span>|</span><a href="#40520249">prev</a><span>|</span><a href="#40518554">next</a><span>|</span><label class="collapse" for="c-40520414">[-]</label><label class="expand" for="c-40520414">[1 more]</label></div><br/><div class="children"><div class="content">&gt; but isn&#x27;t the whole point of GPL&#x2F;AGPL &quot;you can read and share and use this, but you can&#x27;t take it and roll it into your closed commercial product for profit&quot;?<p>You can profit from GPL &#x2F; AGPL code but just also make all your source code open source and available for everyone to see.</div><br/></div></div><div id="40518554" class="c"><input type="checkbox" id="c-40518554" checked=""/><div class="controls bullet"><span class="by">hehdhdjehehegwv</span><span>|</span><a href="#40513224">root</a><span>|</span><a href="#40517089">parent</a><span>|</span><a href="#40520414">prev</a><span>|</span><a href="#40519979">next</a><span>|</span><label class="collapse" for="c-40518554">[-]</label><label class="expand" for="c-40518554">[1 more]</label></div><br/><div class="children"><div class="content">Precisely, this is such a basic violation of GPL it’s mind boggling they went for it.</div><br/></div></div></div></div><div id="40519979" class="c"><input type="checkbox" id="c-40519979" checked=""/><div class="controls bullet"><span class="by">bobthecowboy</span><span>|</span><a href="#40513224">root</a><span>|</span><a href="#40516962">parent</a><span>|</span><a href="#40517089">prev</a><span>|</span><a href="#40517060">next</a><span>|</span><label class="collapse" for="c-40519979">[-]</label><label class="expand" for="c-40519979">[1 more]</label></div><br/><div class="children"><div class="content">&gt; You consented to people reading your code and learning from it when you posted it on Github.<p>And if I never posted my code to github, but someone else did?  What if someone had posted proprietary code they had no rights to to github at the same time the scraper bots were trawling it?  A few years ago some Windows source code was leaked onto Github - did Microsoft consent then?</div><br/></div></div><div id="40517060" class="c"><input type="checkbox" id="c-40517060" checked=""/><div class="controls bullet"><span class="by">hehdhdjehehegwv</span><span>|</span><a href="#40513224">root</a><span>|</span><a href="#40516962">parent</a><span>|</span><a href="#40519979">prev</a><span>|</span><a href="#40515727">next</a><span>|</span><label class="collapse" for="c-40517060">[-]</label><label class="expand" for="c-40517060">[4 more]</label></div><br/><div class="children"><div class="content">I did not give consent to train on my software and the license does not allow commercial use of it.<p>They have taken <i>my</i> code and now are dictating how <i>I</i> can use their derived work.<p>Personally I think these tools are useful, but if the data comes from the commons the model should also belong to the commons. This is just another attempt to gain private benefit from public work.<p>There are legal issues to be resolved, and there is an explosion of lawsuits already, but the fact pattern is simple and applies to nearly all closed-source AI companies.</div><br/><div id="40517151" class="c"><input type="checkbox" id="c-40517151" checked=""/><div class="controls bullet"><span class="by">portaouflop</span><span>|</span><a href="#40513224">root</a><span>|</span><a href="#40517060">parent</a><span>|</span><a href="#40515727">next</a><span>|</span><label class="collapse" for="c-40517151">[-]</label><label class="expand" for="c-40517151">[3 more]</label></div><br/><div class="children"><div class="content">Mistral is as open as they get, most others are far worse. 
Here you can use the model without issues, as others are saying it’s doubtful they would sue you if you were to use code generated by the model in a commercial app</div><br/><div id="40518018" class="c"><input type="checkbox" id="c-40518018" checked=""/><div class="controls bullet"><span class="by">mananaysiempre</span><span>|</span><a href="#40513224">root</a><span>|</span><a href="#40517151">parent</a><span>|</span><a href="#40518542">next</a><span>|</span><label class="collapse" for="c-40518018">[-]</label><label class="expand" for="c-40518018">[1 more]</label></div><br/><div class="children"><div class="content">Replit’s replit-code[1,2] is CC BY-SA 4.0 for the weights, Apache 2.0 for the sources. Replit has its own unpleasant history[3], but the model’s terms are good. (The model itself is not as good, but deciding whether that’s a worthwhile tradeoff is up to you. The tradeoff exists and is meaningful, is my point.)<p>[1] <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;replit&#x2F;replit-code-v1-3b" rel="nofollow">https:&#x2F;&#x2F;huggingface.co&#x2F;replit&#x2F;replit-code-v1-3b</a><p>[2] <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;replit&#x2F;replit-code-v1_5-3b" rel="nofollow">https:&#x2F;&#x2F;huggingface.co&#x2F;replit&#x2F;replit-code-v1_5-3b</a><p>[3] <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=27424195">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=27424195</a></div><br/></div></div><div id="40518542" class="c"><input type="checkbox" id="c-40518542" checked=""/><div class="controls bullet"><span class="by">hehdhdjehehegwv</span><span>|</span><a href="#40513224">root</a><span>|</span><a href="#40517151">parent</a><span>|</span><a href="#40518018">prev</a><span>|</span><a href="#40515727">next</a><span>|</span><label class="collapse" for="c-40518542">[-]</label><label class="expand" for="c-40518542">[1 more]</label></div><br/><div class="children"><div class="content">This model is more restricted than Mistral and Mixtral - this is a new development from them.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="40515727" class="c"><input type="checkbox" id="c-40515727" checked=""/><div class="controls bullet"><span class="by">nullc</span><span>|</span><a href="#40513224">root</a><span>|</span><a href="#40513335">parent</a><span>|</span><a href="#40515646">prev</a><span>|</span><a href="#40513662">next</a><span>|</span><label class="collapse" for="c-40515727">[-]</label><label class="expand" for="c-40515727">[2 more]</label></div><br/><div class="children"><div class="content">Five years ago it would not have been at all controversial that these weights would not be copyrightable in the US, they&#x27;re machine generated output on third party data.  Yet somehow we&#x27;ve entered a weird timeline where obvious copyfraud is fine, by the same entities that are at best on the line of engaging in commercial copyright <i>infringement</i> at a hereto unforeseen scale.</div><br/><div id="40520327" class="c"><input type="checkbox" id="c-40520327" checked=""/><div class="controls bullet"><span class="by">esperent</span><span>|</span><a href="#40513224">root</a><span>|</span><a href="#40515727">parent</a><span>|</span><a href="#40513662">next</a><span>|</span><label class="collapse" for="c-40520327">[-]</label><label class="expand" for="c-40520327">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s clear that when enough money and power is on the line - and fear that other countries will overtake them - all countries are willing to conveniently and pragmatically ignore their laws. I don&#x27;t think this is any kind of surprise.</div><br/></div></div></div></div><div id="40513662" class="c"><input type="checkbox" id="c-40513662" checked=""/><div class="controls bullet"><span class="by">nicce</span><span>|</span><a href="#40513224">root</a><span>|</span><a href="#40513335">parent</a><span>|</span><a href="#40515727">prev</a><span>|</span><a href="#40513381">next</a><span>|</span><label class="collapse" for="c-40513662">[-]</label><label class="expand" for="c-40513662">[5 more]</label></div><br/><div class="children"><div class="content">In many countries you even can&#x27;t claim copyright for the output of the AI to use license like this.</div><br/><div id="40514547" class="c"><input type="checkbox" id="c-40514547" checked=""/><div class="controls bullet"><span class="by">hannasanarion</span><span>|</span><a href="#40513224">root</a><span>|</span><a href="#40513662">parent</a><span>|</span><a href="#40518570">next</a><span>|</span><label class="collapse" for="c-40514547">[-]</label><label class="expand" for="c-40514547">[3 more]</label></div><br/><div class="children"><div class="content">Copyright on the software that produces something isn&#x27;t the same as copyright on the output.<p>The library&#x27;s copyright is intact, as normal, and they can control who uses it and how just like any other software.<p>The <i>output</i> of AI systems is not copyrightable, but the systems themselves are, and associated EULAs are valid.</div><br/><div id="40514960" class="c"><input type="checkbox" id="c-40514960" checked=""/><div class="controls bullet"><span class="by">nicce</span><span>|</span><a href="#40513224">root</a><span>|</span><a href="#40514547">parent</a><span>|</span><a href="#40518570">next</a><span>|</span><label class="collapse" for="c-40514960">[-]</label><label class="expand" for="c-40514960">[2 more]</label></div><br/><div class="children"><div class="content">Is that so certain? To be able to make claims for <i>what</i> you can use the output, can you do it without making any claims for about control and ownership of the output?<p>Of course, they can revoke your right to use the software, but if it goes to court, that would be interesting case.</div><br/><div id="40518281" class="c"><input type="checkbox" id="c-40518281" checked=""/><div class="controls bullet"><span class="by">wrs</span><span>|</span><a href="#40513224">root</a><span>|</span><a href="#40514960">parent</a><span>|</span><a href="#40518570">next</a><span>|</span><label class="collapse" for="c-40518281">[-]</label><label class="expand" for="c-40518281">[1 more]</label></div><br/><div class="children"><div class="content">If there’s no copyright in the weights to begin with, the only restrictions you have are the ones you agreed to when you accepted the license agreement. Find the weights somewhere else and you don’t have to worry about the license.<p>I don’t know why there isn’t more discussion on this point and people just assume there’s an underlying copyright basis to the licensing of weights. As far as I know that isn’t settled at all.</div><br/></div></div></div></div></div></div><div id="40518570" class="c"><input type="checkbox" id="c-40518570" checked=""/><div class="controls bullet"><span class="by">wakawaka28</span><span>|</span><a href="#40513224">root</a><span>|</span><a href="#40513662">parent</a><span>|</span><a href="#40514547">prev</a><span>|</span><a href="#40513381">next</a><span>|</span><label class="collapse" for="c-40518570">[-]</label><label class="expand" for="c-40518570">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;d like to know how they think they&#x27;ll prove I didn&#x27;t write whatever code I generate. Unless it is a direct copy of something else available to the investigator, good luck.</div><br/></div></div></div></div></div></div><div id="40513774" class="c"><input type="checkbox" id="c-40513774" checked=""/><div class="controls bullet"><span class="by">isoprophlex</span><span>|</span><a href="#40513224">parent</a><span>|</span><a href="#40513335">prev</a><span>|</span><a href="#40513312">next</a><span>|</span><label class="collapse" for="c-40513774">[-]</label><label class="expand" for="c-40513774">[1 more]</label></div><br/><div class="children"><div class="content">So, it&#x27;s almost entirely useless with that license, because the average pack of corpo beancounters will never let you use it over whatever Microsoft has already sold them.</div><br/></div></div><div id="40513312" class="c"><input type="checkbox" id="c-40513312" checked=""/><div class="controls bullet"><span class="by">croes</span><span>|</span><a href="#40513224">parent</a><span>|</span><a href="#40513774">prev</a><span>|</span><a href="#40517228">next</a><span>|</span><label class="collapse" for="c-40513312">[-]</label><label class="expand" for="c-40513312">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s more like a demo version you can evaluate before you need to buy a commercial license.<p>On whose code is Mistral trained?</div><br/><div id="40513950" class="c"><input type="checkbox" id="c-40513950" checked=""/><div class="controls bullet"><span class="by">rvnx</span><span>|</span><a href="#40513224">root</a><span>|</span><a href="#40513312">parent</a><span>|</span><a href="#40517228">next</a><span>|</span><label class="collapse" for="c-40513950">[-]</label><label class="expand" for="c-40513950">[1 more]</label></div><br/><div class="children"><div class="content">Your code, my code, etc.
But there is a common case with law; copyright do not apply when you have billions.<p>Examples: recurring infringement from Microsoft on open-source projects, Google scraping content to build their own database, etc...</div><br/></div></div></div></div><div id="40517228" class="c"><input type="checkbox" id="c-40517228" checked=""/><div class="controls bullet"><span class="by">batch12</span><span>|</span><a href="#40513224">parent</a><span>|</span><a href="#40513312">prev</a><span>|</span><a href="#40513405">next</a><span>|</span><label class="collapse" for="c-40517228">[-]</label><label class="expand" for="c-40517228">[1 more]</label></div><br/><div class="children"><div class="content">If they can make agreements with arbitrary terms, why can&#x27;t we? [0]<p>[0] <a href="https:&#x2F;&#x2F;o565.com&#x2F;content-ownership-and-licensing-agreement&#x2F;" rel="nofollow">https:&#x2F;&#x2F;o565.com&#x2F;content-ownership-and-licensing-agreement&#x2F;</a></div><br/></div></div><div id="40513405" class="c"><input type="checkbox" id="c-40513405" checked=""/><div class="controls bullet"><span class="by">rohansood15</span><span>|</span><a href="#40513224">parent</a><span>|</span><a href="#40517228">prev</a><span>|</span><a href="#40513431">next</a><span>|</span><label class="collapse" for="c-40513405">[-]</label><label class="expand" for="c-40513405">[2 more]</label></div><br/><div class="children"><div class="content">That license is just hilarious.</div><br/><div id="40513751" class="c"><input type="checkbox" id="c-40513751" checked=""/><div class="controls bullet"><span class="by">das_keyboard</span><span>|</span><a href="#40513224">root</a><span>|</span><a href="#40513405">parent</a><span>|</span><a href="#40513431">next</a><span>|</span><label class="collapse" for="c-40513751">[-]</label><label class="expand" for="c-40513751">[1 more]</label></div><br/><div class="children"><div class="content">OT, but 7.2 reads like the description of some Yu-Gi-Oh card or something:<p>&gt; Mistral AI may terminate this Agreement at any time [...]. Sections 5, 6, 7 and 8 shall survive the termination of this Agreement.</div><br/></div></div></div></div><div id="40513431" class="c"><input type="checkbox" id="c-40513431" checked=""/><div class="controls bullet"><span class="by">behnamoh</span><span>|</span><a href="#40513224">parent</a><span>|</span><a href="#40513405">prev</a><span>|</span><a href="#40513771">next</a><span>|</span><label class="collapse" for="c-40513431">[-]</label><label class="expand" for="c-40513431">[13 more]</label></div><br/><div class="children"><div class="content">From the website:<p>&gt; licensed under the new Mistral AI Non-Production License, which means that you can use it for research and testing purposes. ...<p>Which basically means &quot;we give you this model. Go find its weaknesses and report on r&#x2F;locallama. Then we&#x27;ll use that to improve our commercial model which we won&#x27;t open-source.&quot;<p>I&#x27;m sick of abusing the word &quot;open-source&quot; in this field.</div><br/><div id="40513543" class="c"><input type="checkbox" id="c-40513543" checked=""/><div class="controls bullet"><span class="by">JimDabell</span><span>|</span><a href="#40513224">root</a><span>|</span><a href="#40513431">parent</a><span>|</span><a href="#40519242">next</a><span>|</span><label class="collapse" for="c-40513543">[-]</label><label class="expand" for="c-40513543">[10 more]</label></div><br/><div class="children"><div class="content">&gt; I&#x27;m sick of abusing the word &quot;open-source&quot; in this field.<p>They don’t call this open source anywhere, do they? As far as I can see, they only say it’s open weights and that it’s available under their Mistral AI Non-Production License for research and testing. That doesn’t scream “open source” to me.</div><br/><div id="40513733" class="c"><input type="checkbox" id="c-40513733" checked=""/><div class="controls bullet"><span class="by">demosthanos</span><span>|</span><a href="#40513224">root</a><span>|</span><a href="#40513543">parent</a><span>|</span><a href="#40514073">next</a><span>|</span><label class="collapse" for="c-40513733">[-]</label><label class="expand" for="c-40513733">[7 more]</label></div><br/><div class="children"><div class="content">They do say &quot;open-weight&quot;, which is I think still very misleading in this context. Open-weight sounds like it should be the same as open-source, just for weights instead of the full source (for example, training data and the code used to generate the weights may not be released). This isn&#x27;t really &quot;open&quot; in any meaningful sense.</div><br/><div id="40516536" class="c"><input type="checkbox" id="c-40516536" checked=""/><div class="controls bullet"><span class="by">boulos</span><span>|</span><a href="#40513224">root</a><span>|</span><a href="#40513733">parent</a><span>|</span><a href="#40514057">next</a><span>|</span><label class="collapse" for="c-40516536">[-]</label><label class="expand" for="c-40516536">[1 more]</label></div><br/><div class="children"><div class="content">This is why I prefer the term &quot;weights available&quot; just like &quot;source available&quot;. It makes it clear that you can get your hands on the copy, you could run this exact thing locally if they go out of business, etc. but it is definitely not open in the OSS sense.</div><br/></div></div><div id="40514057" class="c"><input type="checkbox" id="c-40514057" checked=""/><div class="controls bullet"><span class="by">Zambyte</span><span>|</span><a href="#40513224">root</a><span>|</span><a href="#40513733">parent</a><span>|</span><a href="#40516536">prev</a><span>|</span><a href="#40514073">next</a><span>|</span><label class="collapse" for="c-40514057">[-]</label><label class="expand" for="c-40514057">[5 more]</label></div><br/><div class="children"><div class="content">The fact that I can downloaded it and run it myself is a pretty meaningful amount of openness to me. I can easily ignore their bogus claims about what I&#x27;m allowed to do with it due to their distribution model. I can&#x27;t necessarily do the same with a propriety service, as they can cut me off if the way I use the output makes them sad :(</div><br/><div id="40515377" class="c"><input type="checkbox" id="c-40515377" checked=""/><div class="controls bullet"><span class="by">demosthanos</span><span>|</span><a href="#40513224">root</a><span>|</span><a href="#40514057">parent</a><span>|</span><a href="#40514654">next</a><span>|</span><label class="collapse" for="c-40515377">[-]</label><label class="expand" for="c-40515377">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I can easily ignore their bogus claims about what I&#x27;m allowed to do with it due to their distribution model.<p>If you&#x27;re talking about exclusively personally use, sure. If you&#x27;re talking about a business setting in a jurisdiction that Mistral can sue in, not so much.<p>Being able to use it in a business setting is a pretty darn important part of what Open Source has always meant (it&#x27;s why it exists as a term at all).</div><br/></div></div><div id="40514654" class="c"><input type="checkbox" id="c-40514654" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#40513224">root</a><span>|</span><a href="#40514057">parent</a><span>|</span><a href="#40515377">prev</a><span>|</span><a href="#40514073">next</a><span>|</span><label class="collapse" for="c-40514654">[-]</label><label class="expand" for="c-40514654">[3 more]</label></div><br/><div class="children"><div class="content">&gt; <i>The fact that I can downloaded it and run it myself is a pretty meaningful amount of openness to me</i><p>That&#x27;s typically called <i>freeware</i>, though.</div><br/><div id="40515205" class="c"><input type="checkbox" id="c-40515205" checked=""/><div class="controls bullet"><span class="by">Zambyte</span><span>|</span><a href="#40513224">root</a><span>|</span><a href="#40514654">parent</a><span>|</span><a href="#40514073">next</a><span>|</span><label class="collapse" for="c-40515205">[-]</label><label class="expand" for="c-40515205">[2 more]</label></div><br/><div class="children"><div class="content">The inference engine that I use to run open weight language models is fully free software. The model itself isn&#x27;t really software in the traditional sense. So calling it ____ware seems inaccurate.</div><br/><div id="40516002" class="c"><input type="checkbox" id="c-40516002" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#40513224">root</a><span>|</span><a href="#40515205">parent</a><span>|</span><a href="#40514073">next</a><span>|</span><label class="collapse" for="c-40516002">[-]</label><label class="expand" for="c-40516002">[1 more]</label></div><br/><div class="children"><div class="content">The interpreter is free software. The model is freeware distributed as a binary blob. Code vs. Data is a matter of perspective, but with large neural nets, more than anywhere, it makes no sense to pretend they&#x27;re plain data. All the computational complexity is in the weights, they&#x27;re very much code compiled for an unusual architecture (the inference engine).</div><br/></div></div></div></div></div></div></div></div></div></div><div id="40514073" class="c"><input type="checkbox" id="c-40514073" checked=""/><div class="controls bullet"><span class="by">Rastonbury</span><span>|</span><a href="#40513224">root</a><span>|</span><a href="#40513543">parent</a><span>|</span><a href="#40513733">prev</a><span>|</span><a href="#40513734">next</a><span>|</span><label class="collapse" for="c-40514073">[-]</label><label class="expand" for="c-40514073">[1 more]</label></div><br/><div class="children"><div class="content">No but they do say &quot;empowering developers&quot; and &quot;democratising coding&quot; as the subtitle, I guess only those who pay</div><br/></div></div><div id="40513734" class="c"><input type="checkbox" id="c-40513734" checked=""/><div class="controls bullet"><span class="by">gyudin</span><span>|</span><a href="#40513224">root</a><span>|</span><a href="#40513543">parent</a><span>|</span><a href="#40514073">prev</a><span>|</span><a href="#40519242">next</a><span>|</span><label class="collapse" for="c-40513734">[-]</label><label class="expand" for="c-40513734">[1 more]</label></div><br/><div class="children"><div class="content">All their other models are “open source” and it was the selling point they built their brand on.
I doubt they made their new model completely different from previous ones so it’s supposed be open source too, unless they found some juridical loophole lol</div><br/></div></div></div></div><div id="40519242" class="c"><input type="checkbox" id="c-40519242" checked=""/><div class="controls bullet"><span class="by">benreesman</span><span>|</span><a href="#40513224">root</a><span>|</span><a href="#40513431">parent</a><span>|</span><a href="#40513543">prev</a><span>|</span><a href="#40518259">next</a><span>|</span><label class="collapse" for="c-40519242">[-]</label><label class="expand" for="c-40519242">[1 more]</label></div><br/><div class="children"><div class="content">I use the term “available weight”.<p>This is maybe a debatable claim, but I’ll contend that without the magnificent rebel who leaked the original LLaMA weights the last, what, 15 months would have gone completely differently.<p>The legislators and courts and lawyers will be years if not decades sorting all this out.<p>For now there seems to be a productive if slightly uneasy truce: outside of a few groups at a few firms, everyone seems to be maximizing for innovation and generally behaving under a positive sum expectation.<p>One imagines if some really cool tune of this model shows up as a magnet or even on huggingface, the courteous thing probably happened: Mistral was notified in advance and some mutually beneficial arrangement was agreed to in outline, maybe inked, maybe not.<p>I don’t work for Mistral, so that’s pure speculation, but the big company I spent most of my career at would have certainly said “can we hire this person? can we buy this company? can we collaborate with people who do awesome stuff with our stuff that we didn’t think of?”<p>The icky actors kind of dominate the headlines and I’m as guilty as anyone and guiltier than most of letting that be top of mind too often.<p>In the large this is really cool and kind of new.<p>I’m personally rather optimistic that we’re well past the point when outright piracy or flagrantly adversarial license violations are either necessary or useful.<p>To me this license seems like an invitation to build on Mistral’s work and approach them with the results, and given how well a posture of openness with some safeguards is working out for FAIR and the LLaMA group, that’s certainly the outcome I’d be hoping for in their position.<p>Maybe open AI was an unrealistic goal. Maybe AvailableAI is what we wind up with, and that wouldn’t be too bad.</div><br/></div></div><div id="40518259" class="c"><input type="checkbox" id="c-40518259" checked=""/><div class="controls bullet"><span class="by">wrs</span><span>|</span><a href="#40513224">root</a><span>|</span><a href="#40513431">parent</a><span>|</span><a href="#40519242">prev</a><span>|</span><a href="#40513771">next</a><span>|</span><label class="collapse" for="c-40518259">[-]</label><label class="expand" for="c-40518259">[1 more]</label></div><br/><div class="children"><div class="content">If you want to live on the legal edge, it’s unclear whether there is any copyright in model weights (since they don’t have human authorship), so just wait for someone to post the weights someplace where you can get them without agreeing to the license.</div><br/></div></div></div></div><div id="40513771" class="c"><input type="checkbox" id="c-40513771" checked=""/><div class="controls bullet"><span class="by">meiraleal</span><span>|</span><a href="#40513224">parent</a><span>|</span><a href="#40513431">prev</a><span>|</span><a href="#40514735">next</a><span>|</span><label class="collapse" for="c-40513771">[-]</label><label class="expand" for="c-40513771">[3 more]</label></div><br/><div class="children"><div class="content">&gt; Who cares? It seems you&#x27;re not allowed to integrate this with anything else and show it to anyone, even as an art project.<p>Now they just lack the means to enforce it.</div><br/><div id="40514511" class="c"><input type="checkbox" id="c-40514511" checked=""/><div class="controls bullet"><span class="by">localfirst</span><span>|</span><a href="#40513224">root</a><span>|</span><a href="#40513771">parent</a><span>|</span><a href="#40514735">next</a><span>|</span><label class="collapse" for="c-40514511">[-]</label><label class="expand" for="c-40514511">[2 more]</label></div><br/><div class="children"><div class="content">impossible to enforce</div><br/><div id="40519089" class="c"><input type="checkbox" id="c-40519089" checked=""/><div class="controls bullet"><span class="by">GuB-42</span><span>|</span><a href="#40513224">root</a><span>|</span><a href="#40514511">parent</a><span>|</span><a href="#40514735">next</a><span>|</span><label class="collapse" for="c-40519089">[-]</label><label class="expand" for="c-40519089">[1 more]</label></div><br/><div class="children"><div class="content">They could potentially watermark the model in order to identify the output. There are techniques for doing that, for example by randomly assigning token into groups A and B, group A probability is increased over group B, if group A is over-represented, chances are that that the output comes from the watermarked model.<p>How effective these techniques are and how acceptable as a proof it is is yet to be defined.<p>I don&#x27;t think it is the case here, they probably don&#x27;t really care, and watermarking has a cost.</div><br/></div></div></div></div></div></div></div></div><div id="40513020" class="c"><input type="checkbox" id="c-40513020" checked=""/><div class="controls bullet"><span class="by">ddavis</span><span>|</span><a href="#40513224">prev</a><span>|</span><a href="#40512898">next</a><span>|</span><label class="collapse" for="c-40513020">[-]</label><label class="expand" for="c-40513020">[38 more]</label></div><br/><div class="children"><div class="content">My favorite thing to ask the models designed for programming is: &quot;Using Python write a pure ASGI middleware that intercepts the request body, response headers, and response body, stores that information in a dict, and then JSON encodes it to be sent to an external program using a function called transmit.&quot; None of them ever get it right :)</div><br/><div id="40513463" class="c"><input type="checkbox" id="c-40513463" checked=""/><div class="controls bullet"><span class="by">JimDabell</span><span>|</span><a href="#40513020">parent</a><span>|</span><a href="#40516687">next</a><span>|</span><label class="collapse" for="c-40513463">[-]</label><label class="expand" for="c-40513463">[4 more]</label></div><br/><div class="children"><div class="content">I normally ask about building a multi-tenant system using async SQLAlchemy 2 ORM where some tables are shared between tenants in a global PostgreSQL schema and some are in a per-tenant schema.<p>Nothing gets it right first time, <i>but</i> when ChatGPT 4 first came out, I could talk to it more and it would eventually get it right. Not long after that though, ChatGPT degraded. It would get it wrong on the first try, but with every subsequent follow up it would forget one of the constraints. Then when it was prompted to fix that one, it forgot a different one. And eventually it would cycle through all of the constraints, getting at least one wrong each time.<p>Since then benchmarks came out showing that ChatGPT “didn’t really degrade”, but all of the benchmarks seemed focused on single question&#x2F;answer pairs and not actual multi-turn chat. For this kind of thing, ChatGPT 4 has never managed to recover to as good as it was when it was first released in my experience.<p>It’s been months since I’ve had to deal with that kind of code, so I might be forgetting something, but I just tried it with Codestral and it spat out something that looked reasonable very quickly on its first try.</div><br/><div id="40516046" class="c"><input type="checkbox" id="c-40516046" checked=""/><div class="controls bullet"><span class="by">alephxyz</span><span>|</span><a href="#40513020">root</a><span>|</span><a href="#40513463">parent</a><span>|</span><a href="#40515209">next</a><span>|</span><label class="collapse" for="c-40516046">[-]</label><label class="expand" for="c-40516046">[1 more]</label></div><br/><div class="children"><div class="content">&gt;It would get it wrong on the first try, but with every subsequent follow up it would forget one of the constraints. Then when it was prompted to fix that one, it forgot a different one. And eventually it would cycle through all of the constraints, getting at least one wrong each time.<p>That drives me nuts and makes me ragequit about half the time. Although it&#x27;s usually more effective to go and correct your initial prompt rather than prompt it again</div><br/></div></div><div id="40515209" class="c"><input type="checkbox" id="c-40515209" checked=""/><div class="controls bullet"><span class="by">checkyoursudo</span><span>|</span><a href="#40513020">root</a><span>|</span><a href="#40513463">parent</a><span>|</span><a href="#40516046">prev</a><span>|</span><a href="#40516687">next</a><span>|</span><label class="collapse" for="c-40515209">[-]</label><label class="expand" for="c-40515209">[2 more]</label></div><br/><div class="children"><div class="content">I had a similar experience. I was trying to get GPT 4 to write some R&#x2F;Stan code for a bit of bayesian modelling. It would get the model wrong, and then I would walk it through how to do it right, and by the end it would almost get it right, but on the next step, it would be like, oh, this is what you want, and the output was identical to the first wrong attempt, which would start the loop over again.</div><br/><div id="40517467" class="c"><input type="checkbox" id="c-40517467" checked=""/><div class="controls bullet"><span class="by">happypumpkin</span><span>|</span><a href="#40513020">root</a><span>|</span><a href="#40515209">parent</a><span>|</span><a href="#40516687">next</a><span>|</span><label class="collapse" for="c-40517467">[-]</label><label class="expand" for="c-40517467">[1 more]</label></div><br/><div class="children"><div class="content">Similar experience using GPT4 for help with Apple&#x27;s Accessibility API. I wanted to do some non-happy-path things and it kept looping between solutions that failed to satisfy at least one of a handful of requirements that I had, and in ways that I couldn&#x27;t combine the different &quot;solutions&quot; to meet all the requirements.<p>I was eventually able to figure it out with the help of some early 2010s blog posts. Sadly I didn&#x27;t test giving it that context and having it attempt to find a solution again (and this was before web browsing was integrated with the web app).<p>More of an issue than it not knowing enough to fulfill my request (it was pretty obscure so I didn&#x27;t necessarily expect that it would be able to) was that it didn&#x27;t mind emitting solutions that failed to meet the requirements. &quot;I don&#x27;t know how to do that&quot; would&#x27;ve been a much preferred answer.</div><br/></div></div></div></div></div></div><div id="40516687" class="c"><input type="checkbox" id="c-40516687" checked=""/><div class="controls bullet"><span class="by">spmurrayzzz</span><span>|</span><a href="#40513020">parent</a><span>|</span><a href="#40513463">prev</a><span>|</span><a href="#40513766">next</a><span>|</span><label class="collapse" for="c-40516687">[-]</label><label class="expand" for="c-40516687">[1 more]</label></div><br/><div class="children"><div class="content">I love to ask it to &quot;make me a Node.js library that pings an ipv4 address, but you must use ZERO dependencies, you must only the native Node.js API modules&quot;<p>The majority of models (both proprietary and open-weight) don&#x27;t understand:<p>- by inference, ping means we&#x27;re talking about ICMP<p>- ICMP requires raw sockets<p>- Node.js has no native raw socket API<p>You can do some CoT trickery to help it reason about the problem and maybe finally get it settled on a variety of solutions (usually some flavor of building a native add-on using C&#x2F;C++&#x2F;Rust&#x2F;Go), or just guide it there step by step yourself, but the back and forth to get there requires a ton of pre-knowledge of the problem space which sorta defeats the purpose. If you just feed it the errors you get verbatim trying to run the code it generates, you end up in painful feedback loops.<p>(Note: I never expect the models to get this right, it&#x27;s just a good microcosmic but concrete example of where knowledge &amp; reasoning meets actual programming acumen, so its cool to see how models evolve to get better, if at all, at the task).</div><br/></div></div><div id="40513766" class="c"><input type="checkbox" id="c-40513766" checked=""/><div class="controls bullet"><span class="by">gyudin</span><span>|</span><a href="#40513020">parent</a><span>|</span><a href="#40516687">prev</a><span>|</span><a href="#40513147">next</a><span>|</span><label class="collapse" for="c-40513766">[-]</label><label class="expand" for="c-40513766">[3 more]</label></div><br/><div class="children"><div class="content">I ask software developers to do the same thing and give them the same amount of time. None of them ever write a single line of code :)</div><br/><div id="40514505" class="c"><input type="checkbox" id="c-40514505" checked=""/><div class="controls bullet"><span class="by">dieortin</span><span>|</span><a href="#40513020">root</a><span>|</span><a href="#40513766">parent</a><span>|</span><a href="#40513147">next</a><span>|</span><label class="collapse" for="c-40514505">[-]</label><label class="expand" for="c-40514505">[2 more]</label></div><br/><div class="children"><div class="content">Give an LLM all the time you want, and they will still not get it right. In fact, they most likely will give worse and worse answers with time. That’s a big difference with a software developer.</div><br/><div id="40517504" class="c"><input type="checkbox" id="c-40517504" checked=""/><div class="controls bullet"><span class="by">mypalmike</span><span>|</span><a href="#40513020">root</a><span>|</span><a href="#40514505">parent</a><span>|</span><a href="#40513147">next</a><span>|</span><label class="collapse" for="c-40517504">[-]</label><label class="expand" for="c-40517504">[1 more]</label></div><br/><div class="children"><div class="content">My experience is very different. Often it (ChatGPT or Copilot, depending on what I&#x27;m trying to accomplish) gets things right the first time. When it doesn&#x27;t, it&#x27;s usually close enough that a bit of manual modification is all that&#x27;s needed. Sometimes it&#x27;s totally wrong, but I can usually point it in the right direction.</div><br/></div></div></div></div></div></div><div id="40513147" class="c"><input type="checkbox" id="c-40513147" checked=""/><div class="controls bullet"><span class="by">nicce</span><span>|</span><a href="#40513020">parent</a><span>|</span><a href="#40513766">prev</a><span>|</span><a href="#40513130">next</a><span>|</span><label class="collapse" for="c-40513147">[-]</label><label class="expand" for="c-40513147">[2 more]</label></div><br/><div class="children"><div class="content">I usually through some complex Rust code with lifetime requirements. And ask them to fix it.
LLMs aren&#x27;t capable on providing much help for that in general, other than some very basic cases.<p>The best way to get your work done is still to look into Rust forums.</div><br/><div id="40513824" class="c"><input type="checkbox" id="c-40513824" checked=""/><div class="controls bullet"><span class="by">meiraleal</span><span>|</span><a href="#40513020">root</a><span>|</span><a href="#40513147">parent</a><span>|</span><a href="#40513130">next</a><span>|</span><label class="collapse" for="c-40513824">[-]</label><label class="expand" for="c-40513824">[1 more]</label></div><br/><div class="children"><div class="content">It works amazingly well for the ones that never coded in Rust, at least in my experience. It took me a couple hours and 120 lines of code to set up a WebRTC signaling server.</div><br/></div></div></div></div><div id="40513130" class="c"><input type="checkbox" id="c-40513130" checked=""/><div class="controls bullet"><span class="by">sanex</span><span>|</span><a href="#40513020">parent</a><span>|</span><a href="#40513147">prev</a><span>|</span><a href="#40515078">next</a><span>|</span><label class="collapse" for="c-40513130">[-]</label><label class="expand" for="c-40513130">[2 more]</label></div><br/><div class="children"><div class="content">Can you get it right without an IDE?</div><br/><div id="40513377" class="c"><input type="checkbox" id="c-40513377" checked=""/><div class="controls bullet"><span class="by">ddavis</span><span>|</span><a href="#40513020">root</a><span>|</span><a href="#40513130">parent</a><span>|</span><a href="#40515078">next</a><span>|</span><label class="collapse" for="c-40513377">[-]</label><label class="expand" for="c-40513377">[1 more]</label></div><br/><div class="children"><div class="content">Nope, I don&#x27;t know how to do it at all- that&#x27;s why I have to ask AI!</div><br/></div></div></div></div><div id="40515078" class="c"><input type="checkbox" id="c-40515078" checked=""/><div class="controls bullet"><span class="by">shepardrtc</span><span>|</span><a href="#40513020">parent</a><span>|</span><a href="#40513130">prev</a><span>|</span><a href="#40513167">next</a><span>|</span><label class="collapse" for="c-40515078">[-]</label><label class="expand" for="c-40515078">[1 more]</label></div><br/><div class="children"><div class="content">gpt-4o gets it right on the first try for me.  Just ran it and tested it.</div><br/></div></div><div id="40513183" class="c"><input type="checkbox" id="c-40513183" checked=""/><div class="controls bullet"><span class="by">meiraleal</span><span>|</span><a href="#40513020">parent</a><span>|</span><a href="#40513167">prev</a><span>|</span><a href="#40513108">next</a><span>|</span><label class="collapse" for="c-40513183">[-]</label><label class="expand" for="c-40513183">[1 more]</label></div><br/><div class="children"><div class="content">Interesting. My favorite thing to ask the models is to refactor code I&#x27;ve not touched for too long and this works very well.</div><br/></div></div><div id="40513108" class="c"><input type="checkbox" id="c-40513108" checked=""/><div class="controls bullet"><span class="by">bongodongobob</span><span>|</span><a href="#40513020">parent</a><span>|</span><a href="#40513183">prev</a><span>|</span><a href="#40512898">next</a><span>|</span><label class="collapse" for="c-40513108">[-]</label><label class="expand" for="c-40513108">[22 more]</label></div><br/><div class="children"><div class="content">Cool, you&#x27;ve identified that your prompt is inadequate for the task.<p>&#x27;Pray, Mr. Babbage, if you put into the machine wrong figures, will the right answers come out?&#x27;</div><br/><div id="40513143" class="c"><input type="checkbox" id="c-40513143" checked=""/><div class="controls bullet"><span class="by">TechDebtDevin</span><span>|</span><a href="#40513020">root</a><span>|</span><a href="#40513108">parent</a><span>|</span><a href="#40513301">next</a><span>|</span><label class="collapse" for="c-40513143">[-]</label><label class="expand" for="c-40513143">[18 more]</label></div><br/><div class="children"><div class="content">Damn, show us your brilliant prompt then. LLMs cannot do this, not even in python, of which there are libraries like Blacksheep that honestly make it a trivial task.</div><br/><div id="40513263" class="c"><input type="checkbox" id="c-40513263" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#40513020">root</a><span>|</span><a href="#40513143">parent</a><span>|</span><a href="#40513299">next</a><span>|</span><label class="collapse" for="c-40513263">[-]</label><label class="expand" for="c-40513263">[1 more]</label></div><br/><div class="children"><div class="content">Prompts like yours (I ask them for a fluid dynamics simulator which also doesn&#x27;t succeed) inform us of the level they have reached. A useful benchmark, given how many of the formal ones they breeze through.<p>I&#x27;m glad they can&#x27;t quite manage this yet. Means I still have a job.</div><br/></div></div><div id="40513299" class="c"><input type="checkbox" id="c-40513299" checked=""/><div class="controls bullet"><span class="by">Closi</span><span>|</span><a href="#40513020">root</a><span>|</span><a href="#40513143">parent</a><span>|</span><a href="#40513263">prev</a><span>|</span><a href="#40513190">next</a><span>|</span><label class="collapse" for="c-40513299">[-]</label><label class="expand" for="c-40513299">[8 more]</label></div><br/><div class="children"><div class="content">Break your prompt up into smaller pieces and it can.</div><br/><div id="40513773" class="c"><input type="checkbox" id="c-40513773" checked=""/><div class="controls bullet"><span class="by">qeternity</span><span>|</span><a href="#40513020">root</a><span>|</span><a href="#40513299">parent</a><span>|</span><a href="#40513190">next</a><span>|</span><label class="collapse" for="c-40513773">[-]</label><label class="expand" for="c-40513773">[7 more]</label></div><br/><div class="children"><div class="content">Taken to the extreme, a sufficiently broken down prompt is simply the code itself.<p>The whole point is to prompt less?</div><br/><div id="40514247" class="c"><input type="checkbox" id="c-40514247" checked=""/><div class="controls bullet"><span class="by">Closi</span><span>|</span><a href="#40513020">root</a><span>|</span><a href="#40513773">parent</a><span>|</span><a href="#40513877">next</a><span>|</span><label class="collapse" for="c-40514247">[-]</label><label class="expand" for="c-40514247">[1 more]</label></div><br/><div class="children"><div class="content">More practically, the whole point is to prompt enough to generate valid code.</div><br/></div></div><div id="40513877" class="c"><input type="checkbox" id="c-40513877" checked=""/><div class="controls bullet"><span class="by">meiraleal</span><span>|</span><a href="#40513020">root</a><span>|</span><a href="#40513773">parent</a><span>|</span><a href="#40514247">prev</a><span>|</span><a href="#40519788">next</a><span>|</span><label class="collapse" for="c-40513877">[-]</label><label class="expand" for="c-40513877">[4 more]</label></div><br/><div class="children"><div class="content">&gt; Taken to the extreme, a sufficiently broken down prompt is simply the code itself<p>it is not. But the artifacts generated through the steps will be code. The last prompt will have most of the code supplied to it as the context.</div><br/><div id="40517882" class="c"><input type="checkbox" id="c-40517882" checked=""/><div class="controls bullet"><span class="by">buddhistdude</span><span>|</span><a href="#40513020">root</a><span>|</span><a href="#40513877">parent</a><span>|</span><a href="#40514651">next</a><span>|</span><label class="collapse" for="c-40517882">[-]</label><label class="expand" for="c-40517882">[2 more]</label></div><br/><div class="children"><div class="content">No he is right, he is saying taken to the extreme. The point is the more and more specific you have to prompt, the more you are actually contributing to the result yourself and the less the model is</div><br/><div id="40518166" class="c"><input type="checkbox" id="c-40518166" checked=""/><div class="controls bullet"><span class="by">meiraleal</span><span>|</span><a href="#40513020">root</a><span>|</span><a href="#40517882">parent</a><span>|</span><a href="#40514651">next</a><span>|</span><label class="collapse" for="c-40518166">[-]</label><label class="expand" for="c-40518166">[1 more]</label></div><br/><div class="children"><div class="content">Yes but the build up isn&#x27;t manual. You go patching prompts with responses until the final result. The last prompt will be almost the whole code complete, obviously.</div><br/></div></div></div></div><div id="40514651" class="c"><input type="checkbox" id="c-40514651" checked=""/><div class="controls bullet"><span class="by">achierius</span><span>|</span><a href="#40513020">root</a><span>|</span><a href="#40513877">parent</a><span>|</span><a href="#40517882">prev</a><span>|</span><a href="#40519788">next</a><span>|</span><label class="collapse" for="c-40514651">[-]</label><label class="expand" for="c-40514651">[1 more]</label></div><br/><div class="children"><div class="content">A prompt is just a specification for an output. Code is just what we call a sufficiently detailed specification.</div><br/></div></div></div></div><div id="40519788" class="c"><input type="checkbox" id="c-40519788" checked=""/><div class="controls bullet"><span class="by">bongodongobob</span><span>|</span><a href="#40513020">root</a><span>|</span><a href="#40513773">parent</a><span>|</span><a href="#40513877">prev</a><span>|</span><a href="#40513190">next</a><span>|</span><label class="collapse" for="c-40519788">[-]</label><label class="expand" for="c-40519788">[1 more]</label></div><br/><div class="children"><div class="content">Well now we get into information density and Komolgorov complexity. The more complicated your desired output program is, the more information you&#x27;ll have to put in, ie, more complicated prompts.</div><br/></div></div></div></div></div></div><div id="40513190" class="c"><input type="checkbox" id="c-40513190" checked=""/><div class="controls bullet"><span class="by">bongodongobob</span><span>|</span><a href="#40513020">root</a><span>|</span><a href="#40513143">parent</a><span>|</span><a href="#40513299">prev</a><span>|</span><a href="#40513301">next</a><span>|</span><label class="collapse" for="c-40513190">[-]</label><label class="expand" for="c-40513190">[8 more]</label></div><br/><div class="children"><div class="content">My point is that you shouldn&#x27;t expect to one shot everything. Have it start by writing a spec, then outline classes and methods, then write the code, and feed it debug stuff.</div><br/><div id="40513259" class="c"><input type="checkbox" id="c-40513259" checked=""/><div class="controls bullet"><span class="by">TechDebtDevin</span><span>|</span><a href="#40513020">root</a><span>|</span><a href="#40513190">parent</a><span>|</span><a href="#40513256">next</a><span>|</span><label class="collapse" for="c-40513259">[-]</label><label class="expand" for="c-40513259">[5 more]</label></div><br/><div class="children"><div class="content">I see your point but hand holding isn&#x27;t really a good way to benchmark a models coding capabilities.</div><br/><div id="40513325" class="c"><input type="checkbox" id="c-40513325" checked=""/><div class="controls bullet"><span class="by">Closi</span><span>|</span><a href="#40513020">root</a><span>|</span><a href="#40513259">parent</a><span>|</span><a href="#40513256">next</a><span>|</span><label class="collapse" for="c-40513325">[-]</label><label class="expand" for="c-40513325">[4 more]</label></div><br/><div class="children"><div class="content">Depends if benchmarking is the aim, rather than decreasing the time it takes to build things.</div><br/><div id="40513502" class="c"><input type="checkbox" id="c-40513502" checked=""/><div class="controls bullet"><span class="by">TechDebtDevin</span><span>|</span><a href="#40513020">root</a><span>|</span><a href="#40513325">parent</a><span>|</span><a href="#40513256">next</a><span>|</span><label class="collapse" for="c-40513502">[-]</label><label class="expand" for="c-40513502">[3 more]</label></div><br/><div class="children"><div class="content">Well sure, but that wasn&#x27;t what we were discussing. The original comment says they use that as their benchmark. While their coding task is a bit complex compared to other benchmarking prompts, it&#x27;s not that crazy. Here is an example of prompts used for benchmarking with Python for reference:<p><a href="https:&#x2F;&#x2F;huggingface.co&#x2F;datasets&#x2F;mbpp?row=98" rel="nofollow">https:&#x2F;&#x2F;huggingface.co&#x2F;datasets&#x2F;mbpp?row=98</a><p>At the end of the day LLMs in their current iteration aren&#x27;t intended to do even moderately difficult tasks on their own but it&#x27;s fun to query them to see progress when new claims are made.</div><br/><div id="40513722" class="c"><input type="checkbox" id="c-40513722" checked=""/><div class="controls bullet"><span class="by">Closi</span><span>|</span><a href="#40513020">root</a><span>|</span><a href="#40513502">parent</a><span>|</span><a href="#40513256">next</a><span>|</span><label class="collapse" for="c-40513722">[-]</label><label class="expand" for="c-40513722">[2 more]</label></div><br/><div class="children"><div class="content">The original comment says nothing about benchmarking, they just say that an AI can’t one shot their complex task?</div><br/><div id="40515120" class="c"><input type="checkbox" id="c-40515120" checked=""/><div class="controls bullet"><span class="by">amne</span><span>|</span><a href="#40513020">root</a><span>|</span><a href="#40513722">parent</a><span>|</span><a href="#40513256">next</a><span>|</span><label class="collapse" for="c-40515120">[-]</label><label class="expand" for="c-40515120">[1 more]</label></div><br/><div class="children"><div class="content">When I read<p><i>&quot;My favorite thing to ask the models designed for programming is ....... None of them ever get it right&quot;</i><p>I read &quot;benchmark&quot;.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="40513256" class="c"><input type="checkbox" id="c-40513256" checked=""/><div class="controls bullet"><span class="by">bottom999mottob</span><span>|</span><a href="#40513020">root</a><span>|</span><a href="#40513190">parent</a><span>|</span><a href="#40513259">prev</a><span>|</span><a href="#40513301">next</a><span>|</span><label class="collapse" for="c-40513256">[-]</label><label class="expand" for="c-40513256">[2 more]</label></div><br/><div class="children"><div class="content">Exactly, expecting one shot 100% working code with one prompt is ridiculous at this point. It&#x27;s why libraries like Aider are so useful, because you can iteratively diff generated code until it&#x27;s useable.</div><br/><div id="40513539" class="c"><input type="checkbox" id="c-40513539" checked=""/><div class="controls bullet"><span class="by">TechDebtDevin</span><span>|</span><a href="#40513020">root</a><span>|</span><a href="#40513256">parent</a><span>|</span><a href="#40513301">next</a><span>|</span><label class="collapse" for="c-40513539">[-]</label><label class="expand" for="c-40513539">[1 more]</label></div><br/><div class="children"><div class="content">Sure it&#x27;s impossible at this point, but the point of a benchmark isn&#x27;t to complete the task it&#x27;s to test it&#x27;s efficacy overall and to see progress. None of them are 100% at even the simplistic python benchmarks, doesn&#x27;t mean we shouldn&#x27;t measure that capability. But sure, I get it. That&#x27;s not how they are intended to be used but that&#x27;s also not the point the commenter was laying out.</div><br/></div></div></div></div></div></div></div></div><div id="40513301" class="c"><input type="checkbox" id="c-40513301" checked=""/><div class="controls bullet"><span class="by">ddavis</span><span>|</span><a href="#40513020">root</a><span>|</span><a href="#40513108">parent</a><span>|</span><a href="#40513143">prev</a><span>|</span><a href="#40513765">next</a><span>|</span><label class="collapse" for="c-40513301">[-]</label><label class="expand" for="c-40513301">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s something I know how to do after figuring it out myself and discovering the potential sharp edges, so I&#x27;ve made it into a fun game to test the models. I&#x27;d argue that it&#x27;s a great prompt (to keep using consistently over time) to see the evolution of this wildly accelerating field.</div><br/><div id="40513518" class="c"><input type="checkbox" id="c-40513518" checked=""/><div class="controls bullet"><span class="by">kergonath</span><span>|</span><a href="#40513020">root</a><span>|</span><a href="#40513301">parent</a><span>|</span><a href="#40513765">next</a><span>|</span><label class="collapse" for="c-40513518">[-]</label><label class="expand" for="c-40513518">[1 more]</label></div><br/><div class="children"><div class="content">Do you notice any progress over time?</div><br/></div></div></div></div><div id="40513765" class="c"><input type="checkbox" id="c-40513765" checked=""/><div class="controls bullet"><span class="by">AnimalMuppet</span><span>|</span><a href="#40513020">root</a><span>|</span><a href="#40513108">parent</a><span>|</span><a href="#40513301">prev</a><span>|</span><a href="#40512898">next</a><span>|</span><label class="collapse" for="c-40513765">[-]</label><label class="expand" for="c-40513765">[1 more]</label></div><br/><div class="children"><div class="content">How is that &quot;putting in wrong figures&quot;?  It&#x27;s a perfectly valid prompt, written in clear, proper English.</div><br/></div></div></div></div></div></div><div id="40512898" class="c"><input type="checkbox" id="c-40512898" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#40513020">prev</a><span>|</span><a href="#40513074">next</a><span>|</span><label class="collapse" for="c-40512898">[-]</label><label class="expand" for="c-40512898">[11 more]</label></div><br/><div class="children"><div class="content">i&#x27;ve been noticing that there&#x27;s a divergence in philosophy between Llama style LLMs (Mistral are Meta alums so I&#x27;m counting them in tehre) and OpenAI&#x2F;GPT style LLMs when it comes to code.<p>GPT3.5+ prioritized code very heavily - there&#x27;s no CodeGPT, its just GPT4, and every version is better than the last.<p>Whereas the Llama&#x2F;Mistral models are now shipping the general language model first, then adding CodeLlama&#x2F;Codestral with additional pretraining (it seems like we don&#x27;t know how much more tokens are on this one, but CodeLLama was 500B-1T extra tokens of code).<p>Zuck has mentioned recently that he doesnt see coding ability as important for his usecases, whereas obviously OpenAI is betting heavily on code as a way to improve LLM reasoning for AGI.</div><br/><div id="40512938" class="c"><input type="checkbox" id="c-40512938" checked=""/><div class="controls bullet"><span class="by">memothon</span><span>|</span><a href="#40512898">parent</a><span>|</span><a href="#40513169">next</a><span>|</span><label class="collapse" for="c-40512938">[-]</label><label class="expand" for="c-40512938">[4 more]</label></div><br/><div class="children"><div class="content">&gt;Zuck has mentioned recently<p>That&#x27;s a really surprising thing to hear, where did you see that? The only quote I&#x27;ve seen is this one:<p>&gt;“One hypothesis was that coding isn’t that important because it’s not like a lot of people are going to ask coding questions in WhatsApp,” he says. “It turns out that coding is actually really important structurally for having the LLMs be able to understand the rigor and hierarchical structure of knowledge, and just generally have more of an intuitive sense of logic.”<p><a href="https:&#x2F;&#x2F;www.theverge.com&#x2F;2024&#x2F;1&#x2F;18&#x2F;24042354&#x2F;mark-zuckerberg-meta-agi-reorg-interview" rel="nofollow">https:&#x2F;&#x2F;www.theverge.com&#x2F;2024&#x2F;1&#x2F;18&#x2F;24042354&#x2F;mark-zuckerberg-...</a></div><br/><div id="40513083" class="c"><input type="checkbox" id="c-40513083" checked=""/><div class="controls bullet"><span class="by">imachine1980_</span><span>|</span><a href="#40512898">root</a><span>|</span><a href="#40512938">parent</a><span>|</span><a href="#40514722">next</a><span>|</span><label class="collapse" for="c-40513083">[-]</label><label class="expand" for="c-40513083">[1 more]</label></div><br/><div class="children"><div class="content">Make Sense,  they want better interaction whit users for Whatsapp, Instagram and Facebook marketers, content  creation and moderation,and their glasses(ai &#x2F;ar) I don&#x27;t see in that context why the should push more effort  into llm coding, is sad anyways</div><br/></div></div><div id="40514722" class="c"><input type="checkbox" id="c-40514722" checked=""/><div class="controls bullet"><span class="by">whoami_nr</span><span>|</span><a href="#40512898">root</a><span>|</span><a href="#40512938">parent</a><span>|</span><a href="#40513083">prev</a><span>|</span><a href="#40513169">next</a><span>|</span><label class="collapse" for="c-40514722">[-]</label><label class="expand" for="c-40514722">[2 more]</label></div><br/><div class="children"><div class="content">He mentioned it on the Dwarkesh podcast: <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=bc6uFV9CJGg" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=bc6uFV9CJGg</a></div><br/><div id="40518290" class="c"><input type="checkbox" id="c-40518290" checked=""/><div class="controls bullet"><span class="by">Davidzheng</span><span>|</span><a href="#40512898">root</a><span>|</span><a href="#40514722">parent</a><span>|</span><a href="#40513169">next</a><span>|</span><label class="collapse" for="c-40518290">[-]</label><label class="expand" for="c-40518290">[1 more]</label></div><br/><div class="children"><div class="content">I watched this podcast and i also remember zuck saying it is important</div><br/></div></div></div></div></div></div><div id="40513169" class="c"><input type="checkbox" id="c-40513169" checked=""/><div class="controls bullet"><span class="by">guyomes</span><span>|</span><a href="#40512898">parent</a><span>|</span><a href="#40512938">prev</a><span>|</span><a href="#40518727">next</a><span>|</span><label class="collapse" for="c-40513169">[-]</label><label class="expand" for="c-40513169">[1 more]</label></div><br/><div class="children"><div class="content">&gt; OpenAI is betting heavily on code as a way to improve LLM reasoning for AGI.<p>And researchers from Google Deepmind, University of Wisconsin-Madison and Laboratoire de l’Informatique du Parallélisme, University of Lyon, actually publish some of their results in that direction [1,2].<p>[1]: <a href="https:&#x2F;&#x2F;deepmind.google&#x2F;discover&#x2F;blog&#x2F;funsearch-making-new-discoveries-in-mathematical-sciences-using-large-language-models&#x2F;" rel="nofollow">https:&#x2F;&#x2F;deepmind.google&#x2F;discover&#x2F;blog&#x2F;funsearch-making-new-d...</a><p>[2]: <a href="https:&#x2F;&#x2F;www.nature.com&#x2F;articles&#x2F;s41586-023-06924-6" rel="nofollow">https:&#x2F;&#x2F;www.nature.com&#x2F;articles&#x2F;s41586-023-06924-6</a></div><br/></div></div><div id="40518727" class="c"><input type="checkbox" id="c-40518727" checked=""/><div class="controls bullet"><span class="by">nabakin</span><span>|</span><a href="#40512898">parent</a><span>|</span><a href="#40513169">prev</a><span>|</span><a href="#40513006">next</a><span>|</span><label class="collapse" for="c-40518727">[-]</label><label class="expand" for="c-40518727">[1 more]</label></div><br/><div class="children"><div class="content">&gt; there&#x27;s no CodeGPT, its just GPT4<p>Codex[1] is OpenAI&#x27;s CodeGPT. It&#x27;s what powers GitHub Copilot and it is very good but not publicly accessible. Maybe they don&#x27;t want something else to outcompete Copilot.<p>[1] <a href="https:&#x2F;&#x2F;openai.com&#x2F;index&#x2F;openai-codex&#x2F;" rel="nofollow">https:&#x2F;&#x2F;openai.com&#x2F;index&#x2F;openai-codex&#x2F;</a></div><br/></div></div><div id="40513006" class="c"><input type="checkbox" id="c-40513006" checked=""/><div class="controls bullet"><span class="by">tkellogg</span><span>|</span><a href="#40512898">parent</a><span>|</span><a href="#40518727">prev</a><span>|</span><a href="#40513180">next</a><span>|</span><label class="collapse" for="c-40513006">[-]</label><label class="expand" for="c-40513006">[1 more]</label></div><br/><div class="children"><div class="content">The OpenAI philosophy is that adding modes improves everything. Sure, it’s astronomically expensive, but I tend to think they’re on to something.</div><br/></div></div><div id="40513180" class="c"><input type="checkbox" id="c-40513180" checked=""/><div class="controls bullet"><span class="by">Rastonbury</span><span>|</span><a href="#40512898">parent</a><span>|</span><a href="#40513006">prev</a><span>|</span><a href="#40513040">next</a><span>|</span><label class="collapse" for="c-40513180">[-]</label><label class="expand" for="c-40513180">[1 more]</label></div><br/><div class="children"><div class="content">I thought that was the idea, open source small specific models that most people can run vs general purpose ones that require a massive amount of GPUs</div><br/></div></div><div id="40513452" class="c"><input type="checkbox" id="c-40513452" checked=""/><div class="controls bullet"><span class="by">behnamoh</span><span>|</span><a href="#40512898">parent</a><span>|</span><a href="#40513040">prev</a><span>|</span><a href="#40513074">next</a><span>|</span><label class="collapse" for="c-40513452">[-]</label><label class="expand" for="c-40513452">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Zuck<p>No, if anything he said Meta realized coding abilities make the model overall better, so they focused on those more than before.</div><br/></div></div></div></div><div id="40513074" class="c"><input type="checkbox" id="c-40513074" checked=""/><div class="controls bullet"><span class="by">IMTDb</span><span>|</span><a href="#40512898">prev</a><span>|</span><a href="#40513283">next</a><span>|</span><label class="collapse" for="c-40513074">[-]</label><label class="expand" for="c-40513074">[10 more]</label></div><br/><div class="children"><div class="content">Is there a way to use this within VSCode like copilot , meaning having the &quot;shadow code&quot; appear while you code instead of having to tho back-and-forth between the editor and a chat-like interface ?<p>For me, a significant component of the quality of these tools resides on the &quot;client&quot; side; being able to engineer a prompt that will yield to accurate code being generated by the model. The prompt needs to find and embed the right chunks from the user current workspace, or even from his entire org repos. The model is &quot;just&quot; one piece of the puzzle.</div><br/><div id="40513152" class="c"><input type="checkbox" id="c-40513152" checked=""/><div class="controls bullet"><span class="by">pyepye</span><span>|</span><a href="#40513074">parent</a><span>|</span><a href="#40513365">next</a><span>|</span><label class="collapse" for="c-40513152">[-]</label><label class="expand" for="c-40513152">[4 more]</label></div><br/><div class="children"><div class="content">Not using Codestral (yet) but check out Continue.dev[1] with Ollama[2] running llama3:latest and starcoder2:3b. It gives you a locally running chat and edit via llama3 and autocomplete via starcoder2.<p>It&#x27;s not perfect but it&#x27;s getting better and better.<p>[1] <a href="https:&#x2F;&#x2F;www.continue.dev&#x2F;">https:&#x2F;&#x2F;www.continue.dev&#x2F;</a>
[2] <a href="https:&#x2F;&#x2F;ollama.com&#x2F;">https:&#x2F;&#x2F;ollama.com&#x2F;</a></div><br/><div id="40516395" class="c"><input type="checkbox" id="c-40516395" checked=""/><div class="controls bullet"><span class="by">mijoharas</span><span>|</span><a href="#40513074">root</a><span>|</span><a href="#40513152">parent</a><span>|</span><a href="#40514186">next</a><span>|</span><label class="collapse" for="c-40516395">[-]</label><label class="expand" for="c-40516395">[1 more]</label></div><br/><div class="children"><div class="content">Wow... That site (continue.dev) managed to consistently crash my mobile google chrome.<p>I&#x27;ve had the odd crash now and again, but I can&#x27;t think of many sites that will reliably make it hard crash. It&#x27;s almost impressive.</div><br/></div></div><div id="40514186" class="c"><input type="checkbox" id="c-40514186" checked=""/><div class="controls bullet"><span class="by">jmorgan</span><span>|</span><a href="#40513074">root</a><span>|</span><a href="#40513152">parent</a><span>|</span><a href="#40516395">prev</a><span>|</span><a href="#40514915">next</a><span>|</span><label class="collapse" for="c-40514186">[-]</label><label class="expand" for="c-40514186">[1 more]</label></div><br/><div class="children"><div class="content">Codestral was just published here as well: <a href="https:&#x2F;&#x2F;ollama.com&#x2F;library&#x2F;codestral">https:&#x2F;&#x2F;ollama.com&#x2F;library&#x2F;codestral</a></div><br/></div></div><div id="40514915" class="c"><input type="checkbox" id="c-40514915" checked=""/><div class="controls bullet"><span class="by">sa-code</span><span>|</span><a href="#40513074">root</a><span>|</span><a href="#40513152">parent</a><span>|</span><a href="#40514186">prev</a><span>|</span><a href="#40513365">next</a><span>|</span><label class="collapse" for="c-40514915">[-]</label><label class="expand" for="c-40514915">[1 more]</label></div><br/><div class="children"><div class="content">This doesn&#x27;t give the &quot;shadow text&quot; that the user specifically mentioned</div><br/></div></div></div></div><div id="40513365" class="c"><input type="checkbox" id="c-40513365" checked=""/><div class="controls bullet"><span class="by">jdoss</span><span>|</span><a href="#40513074">parent</a><span>|</span><a href="#40513152">prev</a><span>|</span><a href="#40520100">next</a><span>|</span><label class="collapse" for="c-40513365">[-]</label><label class="expand" for="c-40513365">[1 more]</label></div><br/><div class="children"><div class="content">I have been using Ollama to run the Llama3 model and I chat with it via Obsidian using <a href="https:&#x2F;&#x2F;github.com&#x2F;logancyang&#x2F;obsidian-copilot">https:&#x2F;&#x2F;github.com&#x2F;logancyang&#x2F;obsidian-copilot</a> and I hook VSCode into it with <a href="https:&#x2F;&#x2F;github.com&#x2F;ex3ndr&#x2F;llama-coder">https:&#x2F;&#x2F;github.com&#x2F;ex3ndr&#x2F;llama-coder</a><p>Having the chats in Obsidian lets me save them to reference them later in my notes. When I first started using it in VSCode when programming in Python it felt like a lot of noise at first. It kept generating a lot of useless recommendations, but recently it has been super helpful.<p>I think my only gripe is I sometimes forget to turn off my ollama systemd unit and I get some noticeable video lag when playing games on my workstation. I think for my next video card upgrade, I am going to build a new home server that can fit my current NVIDIA RTX 3090 Ti and use that as a dedicated server for running ollama.</div><br/></div></div><div id="40520100" class="c"><input type="checkbox" id="c-40520100" checked=""/><div class="controls bullet"><span class="by">outlore</span><span>|</span><a href="#40513074">parent</a><span>|</span><a href="#40513365">prev</a><span>|</span><a href="#40513223">next</a><span>|</span><label class="collapse" for="c-40520100">[-]</label><label class="expand" for="c-40520100">[1 more]</label></div><br/><div class="children"><div class="content">There are many extensions that hook up to Ollama: Continue, Twinny, Privy being a few</div><br/></div></div><div id="40513223" class="c"><input type="checkbox" id="c-40513223" checked=""/><div class="controls bullet"><span class="by">croes</span><span>|</span><a href="#40513074">parent</a><span>|</span><a href="#40520100">prev</a><span>|</span><a href="#40513225">next</a><span>|</span><label class="collapse" for="c-40513223">[-]</label><label class="expand" for="c-40513223">[1 more]</label></div><br/><div class="children"><div class="content">You mean like in their example VS code integration shown here?:<p><a href="https:&#x2F;&#x2F;m.youtube.com&#x2F;watch?v=mjltGOJMJZA" rel="nofollow">https:&#x2F;&#x2F;m.youtube.com&#x2F;watch?v=mjltGOJMJZA</a></div><br/></div></div><div id="40513225" class="c"><input type="checkbox" id="c-40513225" checked=""/><div class="controls bullet"><span class="by">jacekm</span><span>|</span><a href="#40513074">parent</a><span>|</span><a href="#40513223">prev</a><span>|</span><a href="#40513144">next</a><span>|</span><label class="collapse" for="c-40513225">[-]</label><label class="expand" for="c-40513225">[1 more]</label></div><br/><div class="children"><div class="content">The article says that the model is available in Tabnine, a direct competitor to Copilot.</div><br/></div></div><div id="40513144" class="c"><input type="checkbox" id="c-40513144" checked=""/><div class="controls bullet"><span class="by">meiraleal</span><span>|</span><a href="#40513074">parent</a><span>|</span><a href="#40513225">prev</a><span>|</span><a href="#40513283">next</a><span>|</span><label class="collapse" for="c-40513144">[-]</label><label class="expand" for="c-40513144">[1 more]</label></div><br/><div class="children"><div class="content">I created a simple CLI app that does this in my workspace, which is under source control so after the LLM execution all the changes are highlighted by diff and the LLM also creates a COMMIT_EDITMSG file describing what it changed. Now I don&#x27;t use chatgpt anymore, only this cli tool.<p>I never saw something like this integrated directly on VSCode tho (and isn&#x27;t my preferred workflow anyway, command line works better).</div><br/></div></div></div></div><div id="40513283" class="c"><input type="checkbox" id="c-40513283" checked=""/><div class="controls bullet"><span class="by">croes</span><span>|</span><a href="#40513074">prev</a><span>|</span><a href="#40512639">next</a><span>|</span><label class="collapse" for="c-40513283">[-]</label><label class="expand" for="c-40513283">[1 more]</label></div><br/><div class="children"><div class="content">&gt;Usage Limitation<p>- You shall only use the Mistral Models and Derivatives (whether or not created by Mistral AI) for testing, research, Personal, or evaluation purposes in Non-Production Environments;<p>- Subject to the foregoing, You shall not supply the Mistral Models, Derivatives, or Outputs in the course of a commercial activity, whether in return for payment or free of charge, in any medium or form, including but not limited to through a hosted or managed service (e.g. SaaS, cloud instances, etc.), or behind a software layer</div><br/></div></div><div id="40512639" class="c"><input type="checkbox" id="c-40512639" checked=""/><div class="controls bullet"><span class="by">Zambyte</span><span>|</span><a href="#40513283">prev</a><span>|</span><a href="#40512869">next</a><span>|</span><label class="collapse" for="c-40512639">[-]</label><label class="expand" for="c-40512639">[1 more]</label></div><br/><div class="children"><div class="content">Link to the huggingface page: <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;mistralai&#x2F;Codestral-22B-v0.1" rel="nofollow">https:&#x2F;&#x2F;huggingface.co&#x2F;mistralai&#x2F;Codestral-22B-v0.1</a></div><br/></div></div><div id="40512869" class="c"><input type="checkbox" id="c-40512869" checked=""/><div class="controls bullet"><span class="by">andruby</span><span>|</span><a href="#40512639">prev</a><span>|</span><a href="#40517121">next</a><span>|</span><label class="collapse" for="c-40512869">[-]</label><label class="expand" for="c-40512869">[19 more]</label></div><br/><div class="children"><div class="content">This is an open weights 22B model. The download on Huggingface is 44GB.<p>Is there a rule-of-thumb estimate for how much RAM this would need to be used locally?<p>Is the RAM requirement the same for a GPU and &quot;unified&quot; RAM like Apple silicon?</div><br/><div id="40512969" class="c"><input type="checkbox" id="c-40512969" checked=""/><div class="controls bullet"><span class="by">mauricio</span><span>|</span><a href="#40512869">parent</a><span>|</span><a href="#40519484">next</a><span>|</span><label class="collapse" for="c-40512969">[-]</label><label class="expand" for="c-40512969">[1 more]</label></div><br/><div class="children"><div class="content">22B params * 2 bytes (FP16) = 44GB just for the weights. Doesn&#x27;t include KV cache and other things.<p>When the model gets quantized to say 4bit ints, it&#x27;ll be 22B params * 0.5 bytes = 11GB for example.</div><br/></div></div><div id="40519484" class="c"><input type="checkbox" id="c-40519484" checked=""/><div class="controls bullet"><span class="by">Terretta</span><span>|</span><a href="#40512869">parent</a><span>|</span><a href="#40512969">prev</a><span>|</span><a href="#40512984">next</a><span>|</span><label class="collapse" for="c-40519484">[-]</label><label class="expand" for="c-40519484">[5 more]</label></div><br/><div class="children"><div class="content">Yes, RAM requirement is BnL same for GPU and using the metal&#x2F;GPU in Apple Silicon.<p>Running LLM models on a MacBook Pro with Apple Silicon vs. a PC with an Nvidia 4090 GPU has trade-offs. My 128GB MacBook Pro handles models using up to 96GB of unified memory, running at a little under half the speed of a 4090.  If you use a quantized version of full floating point model, you can run the largest open models available.<p>While the 4090 has 24GB of dedicated memory and higher bandwidth (1000 GB&#x2F;s vs. 400 GB&#x2F;s on M3 Max), the Mac’s unified memory system (up to 128GB) is flexible and holds smarter models (8 bit and 6 bit models act still mostly all there, 4 bit is so so, 2 bit is brain damaged).<p>The M2 Ultra in Mac Studio offers even more (800 GB&#x2F;s bandwidth and 192GB memory). So, ok, 6 or 8 of 4090 cards or 4 x A6000 cards excels in raw performance, but Apple’s unified memory in a laptop fits in your backback.<p>It&#x27;s not clear to me why Macbooks and Mac Studio Ultras with maxed out RAM aren&#x27;t selling better if you look at the convenience and price relative to model size.  Models that fit in one 4090 or even a pair of 4090s are toys compared to what fits on these, so for the big models you&#x27;re comparing a laptop to a minifridge.</div><br/><div id="40520329" class="c"><input type="checkbox" id="c-40520329" checked=""/><div class="controls bullet"><span class="by">tyfon</span><span>|</span><a href="#40512869">root</a><span>|</span><a href="#40519484">parent</a><span>|</span><a href="#40520662">next</a><span>|</span><label class="collapse" for="c-40520329">[-]</label><label class="expand" for="c-40520329">[2 more]</label></div><br/><div class="children"><div class="content">I have a 5940x with 128 gb ram.<p>It&#x27;s a bit slower perhaps than the mac, but i get the best of both worlds. That is I get a lot of RAM to hold the model and I can offload as much of it as possible to the GPU. This works especially well with models like mixtral 8x22, but also models like llama3 and the old large bloom model.<p>I also get the utility of running Linux instead of the closed up mac os.<p>But running large models locally is not exclusive to mac studio, you can do the same on PC for a much lower cost.</div><br/><div id="40521482" class="c"><input type="checkbox" id="c-40521482" checked=""/><div class="controls bullet"><span class="by">Terretta</span><span>|</span><a href="#40512869">root</a><span>|</span><a href="#40520329">parent</a><span>|</span><a href="#40520662">next</a><span>|</span><label class="collapse" for="c-40521482">[-]</label><label class="expand" for="c-40521482">[1 more]</label></div><br/><div class="children"><div class="content">I get the utility of a laptop that runs 20 hours on battery and slips in the side pocket of my carry-on or shoulder bag.  (The Mac can also split between RAM and GPU.)  Mixtral 8x22 and Llama 3 70b stream at roughly the same speed as last year&#x27;s GPT-4.<p>&gt; <i>closed up MacOS</i><p><a href="https:&#x2F;&#x2F;github.com&#x2F;apple-oss-distributions&#x2F;distribution-macOS">https:&#x2F;&#x2F;github.com&#x2F;apple-oss-distributions&#x2F;distribution-macO...</a><p><pre><code>  curl https:&#x2F;&#x2F;alx.sh | sh
</code></pre>
<a href="https:&#x2F;&#x2F;asahilinux.org&#x2F;" rel="nofollow">https:&#x2F;&#x2F;asahilinux.org&#x2F;</a><p>I prefer the &quot;utility&quot; of BSDs, but that&#x27;s just a preference.</div><br/></div></div></div></div><div id="40520662" class="c"><input type="checkbox" id="c-40520662" checked=""/><div class="controls bullet"><span class="by">daghamm</span><span>|</span><a href="#40512869">root</a><span>|</span><a href="#40519484">parent</a><span>|</span><a href="#40520329">prev</a><span>|</span><a href="#40512984">next</a><span>|</span><label class="collapse" for="c-40520662">[-]</label><label class="expand" for="c-40520662">[2 more]</label></div><br/><div class="children"><div class="content">&quot;It&#x27;s not clear to me why Macbooks and Mac Studio Ultras with maxed out RAM aren&#x27;t selling&quot;<p>Aren&#x27;t these machines extremly expensive and generally not upgradable?</div><br/><div id="40521451" class="c"><input type="checkbox" id="c-40521451" checked=""/><div class="controls bullet"><span class="by">Terretta</span><span>|</span><a href="#40512869">root</a><span>|</span><a href="#40520662">parent</a><span>|</span><a href="#40512984">next</a><span>|</span><label class="collapse" for="c-40521451">[-]</label><label class="expand" for="c-40521451">[1 more]</label></div><br/><div class="children"><div class="content">They cost less than the 4 - 8 graphics cards and monster desktop PC that would be needed, plus, hey, it&#x27;s a laptop.</div><br/></div></div></div></div></div></div><div id="40512984" class="c"><input type="checkbox" id="c-40512984" checked=""/><div class="controls bullet"><span class="by">tosh</span><span>|</span><a href="#40512869">parent</a><span>|</span><a href="#40519484">prev</a><span>|</span><a href="#40513013">next</a><span>|</span><label class="collapse" for="c-40512984">[-]</label><label class="expand" for="c-40512984">[1 more]</label></div><br/><div class="children"><div class="content">B × Q &#x2F; 8<p>B: number of parameters<p>Q: quantization (16 = no quantization)<p>via <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=40090566">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=40090566</a></div><br/></div></div><div id="40512907" class="c"><input type="checkbox" id="c-40512907" checked=""/><div class="controls bullet"><span class="by">fnbr</span><span>|</span><a href="#40512869">parent</a><span>|</span><a href="#40513013">prev</a><span>|</span><a href="#40513258">next</a><span>|</span><label class="collapse" for="c-40512907">[-]</label><label class="expand" for="c-40512907">[5 more]</label></div><br/><div class="children"><div class="content">The rule of thumb is roughly 44gb, as most models are trained in bf16, and require 16 bits per parameter, so 2 bytes. You need a bit more for activations, so maybe 50GB?<p>you need enough RAM and HBM (GPU RAM) so it’s a constraint on both.</div><br/><div id="40513043" class="c"><input type="checkbox" id="c-40513043" checked=""/><div class="controls bullet"><span class="by">Novosell</span><span>|</span><a href="#40512869">root</a><span>|</span><a href="#40512907">parent</a><span>|</span><a href="#40513004">next</a><span>|</span><label class="collapse" for="c-40513043">[-]</label><label class="expand" for="c-40513043">[1 more]</label></div><br/><div class="children"><div class="content">Most GPUs still use GDDR I&#x27;m pretty sure, not HBM. Do you mean VRAM?</div><br/></div></div><div id="40513004" class="c"><input type="checkbox" id="c-40513004" checked=""/><div class="controls bullet"><span class="by">sharbloop</span><span>|</span><a href="#40512869">root</a><span>|</span><a href="#40512907">parent</a><span>|</span><a href="#40513043">prev</a><span>|</span><a href="#40513258">next</a><span>|</span><label class="collapse" for="c-40513004">[-]</label><label class="expand" for="c-40513004">[3 more]</label></div><br/><div class="children"><div class="content">Which GPU card can I buy to run this model? Can it run on commercial RTX3090 or does it need a custom GPU?</div><br/><div id="40513124" class="c"><input type="checkbox" id="c-40513124" checked=""/><div class="controls bullet"><span class="by">Havoc</span><span>|</span><a href="#40512869">root</a><span>|</span><a href="#40513004">parent</a><span>|</span><a href="#40513228">next</a><span>|</span><label class="collapse" for="c-40513124">[-]</label><label class="expand" for="c-40513124">[1 more]</label></div><br/><div class="children"><div class="content">3090 or 4090 will be able to run quantized 22B models.<p>Though realistically for code completion smaller models will be better due to speed</div><br/></div></div><div id="40513228" class="c"><input type="checkbox" id="c-40513228" checked=""/><div class="controls bullet"><span class="by">TechDebtDevin</span><span>|</span><a href="#40512869">root</a><span>|</span><a href="#40513004">parent</a><span>|</span><a href="#40513124">prev</a><span>|</span><a href="#40513258">next</a><span>|</span><label class="collapse" for="c-40513228">[-]</label><label class="expand" for="c-40513228">[1 more]</label></div><br/><div class="children"><div class="content">Easy..</div><br/></div></div></div></div></div></div><div id="40513258" class="c"><input type="checkbox" id="c-40513258" checked=""/><div class="controls bullet"><span class="by">wing-_-nuts</span><span>|</span><a href="#40512869">parent</a><span>|</span><a href="#40512907">prev</a><span>|</span><a href="#40513221">next</a><span>|</span><label class="collapse" for="c-40513258">[-]</label><label class="expand" for="c-40513258">[1 more]</label></div><br/><div class="children"><div class="content">Wait for a gguf release of this and it will fit neatly into a 3090 with a decent quant.  I&#x27;m excited for this model and I&#x27;ll be adding it to my collection.</div><br/></div></div><div id="40513221" class="c"><input type="checkbox" id="c-40513221" checked=""/><div class="controls bullet"><span class="by">TechDebtDevin</span><span>|</span><a href="#40512869">parent</a><span>|</span><a href="#40513258">prev</a><span>|</span><a href="#40513135">next</a><span>|</span><label class="collapse" for="c-40513221">[-]</label><label class="expand" for="c-40513221">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m honestly not sure on how to measure the amount of vRAM required for these models but I suspect this would run relatively fast, depending on your use case, on a mid to high end 20 or 30 series card. No idea about Apple unified RAM. I get a lot out of performance out of even older cards such as a 1080ti but haven&#x27;t tested this model.</div><br/></div></div></div></div><div id="40517121" class="c"><input type="checkbox" id="c-40517121" checked=""/><div class="controls bullet"><span class="by">James_K</span><span>|</span><a href="#40512869">prev</a><span>|</span><a href="#40517870">next</a><span>|</span><label class="collapse" for="c-40517121">[-]</label><label class="expand" for="c-40517121">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Democratising code<p>Did yall see what happened when they democratised art? I don&#x27;t want to have a billion and one AI garbage libraries to sift through before I can find something reliable and human-made. At least the potential for creating horrific political software is slightly lower than with simple images.</div><br/></div></div><div id="40517870" class="c"><input type="checkbox" id="c-40517870" checked=""/><div class="controls bullet"><span class="by">ein0p</span><span>|</span><a href="#40517121">prev</a><span>|</span><a href="#40517020">next</a><span>|</span><label class="collapse" for="c-40517870">[-]</label><label class="expand" for="c-40517870">[1 more]</label></div><br/><div class="children"><div class="content">If I can’t use the output of this in practical code completion use cases, it’s meaningless, because GH Copilot exists. Idk what they’re thinking or what business model they’re envisioning - Copilot is far and away the best model of this kind anyway</div><br/></div></div><div id="40517020" class="c"><input type="checkbox" id="c-40517020" checked=""/><div class="controls bullet"><span class="by">Sytten</span><span>|</span><a href="#40517870">prev</a><span>|</span><a href="#40514131">next</a><span>|</span><label class="collapse" for="c-40517020">[-]</label><label class="expand" for="c-40517020">[1 more]</label></div><br/><div class="children"><div class="content">Is there a vscode extension that could plug any model out there and have a similar experience to copilot. I always want to try them but I cant be bothered to do a whole setup each time.</div><br/></div></div><div id="40514131" class="c"><input type="checkbox" id="c-40514131" checked=""/><div class="controls bullet"><span class="by">asadm</span><span>|</span><a href="#40517020">prev</a><span>|</span><a href="#40517090">next</a><span>|</span><label class="collapse" for="c-40514131">[-]</label><label class="expand" for="c-40514131">[1 more]</label></div><br/><div class="children"><div class="content">How do people do infilling these days? In olden times models used to provide a way to provide suffix separately.</div><br/></div></div><div id="40517090" class="c"><input type="checkbox" id="c-40517090" checked=""/><div class="controls bullet"><span class="by">gsuuon</span><span>|</span><a href="#40514131">prev</a><span>|</span><a href="#40512906">next</a><span>|</span><label class="collapse" for="c-40517090">[-]</label><label class="expand" for="c-40517090">[1 more]</label></div><br/><div class="children"><div class="content">How does the Mistral non-production license work for small&#x2F;hobby&#x2F;indie projects? Has anyone tried to get approval for that kind of use?</div><br/></div></div><div id="40512906" class="c"><input type="checkbox" id="c-40512906" checked=""/><div class="controls bullet"><span class="by">sebzim4500</span><span>|</span><a href="#40517090">prev</a><span>|</span><a href="#40513017">next</a><span>|</span><label class="collapse" for="c-40512906">[-]</label><label class="expand" for="c-40512906">[2 more]</label></div><br/><div class="children"><div class="content">Very impressed with it based on a short live chat, feels insanely fast considering its capability.<p>chat.mistral.ai</div><br/><div id="40513885" class="c"><input type="checkbox" id="c-40513885" checked=""/><div class="controls bullet"><span class="by">kergonath</span><span>|</span><a href="#40512906">parent</a><span>|</span><a href="#40513017">next</a><span>|</span><label class="collapse" for="c-40513885">[-]</label><label class="expand" for="c-40513885">[1 more]</label></div><br/><div class="children"><div class="content">We&#x27;ll see how fast it is on consumer hardware once decent quantisations are available.</div><br/></div></div></div></div><div id="40513017" class="c"><input type="checkbox" id="c-40513017" checked=""/><div class="controls bullet"><span class="by">jhonatan08</span><span>|</span><a href="#40512906">prev</a><span>|</span><a href="#40512636">next</a><span>|</span><label class="collapse" for="c-40513017">[-]</label><label class="expand" for="c-40513017">[1 more]</label></div><br/><div class="children"><div class="content">Do we have a list of the 80+ languages it was trained on? I couldn&#x27;t find it</div><br/></div></div><div id="40512636" class="c"><input type="checkbox" id="c-40512636" checked=""/><div class="controls bullet"><span class="by">mousetree</span><span>|</span><a href="#40513017">prev</a><span>|</span><a href="#40514337">next</a><span>|</span><label class="collapse" for="c-40512636">[-]</label><label class="expand" for="c-40512636">[14 more]</label></div><br/><div class="children"><div class="content">How does this compare to Github Copilot? It&#x27;s not shown in their comparison</div><br/><div id="40512682" class="c"><input type="checkbox" id="c-40512682" checked=""/><div class="controls bullet"><span class="by">nkozyra</span><span>|</span><a href="#40512636">parent</a><span>|</span><a href="#40519247">next</a><span>|</span><label class="collapse" for="c-40512682">[-]</label><label class="expand" for="c-40512682">[1 more]</label></div><br/><div class="children"><div class="content">Not sure how much current Copilot varies from the original Codex, but another set of benchmarks here: <a href="https:&#x2F;&#x2F;paperswithcode.com&#x2F;sota&#x2F;code-generation-on-humaneval" rel="nofollow">https:&#x2F;&#x2F;paperswithcode.com&#x2F;sota&#x2F;code-generation-on-humaneval</a></div><br/></div></div><div id="40519247" class="c"><input type="checkbox" id="c-40519247" checked=""/><div class="controls bullet"><span class="by">esafak</span><span>|</span><a href="#40512636">parent</a><span>|</span><a href="#40512682">prev</a><span>|</span><a href="#40512683">next</a><span>|</span><label class="collapse" for="c-40519247">[-]</label><label class="expand" for="c-40519247">[2 more]</label></div><br/><div class="children"><div class="content">It is fast all right, but the quality is not there. I asked it to implement OAuth with Stytch and Ktor and it made everything up. I pointed out the correct name for the package and asked if it really knew the SDK, and it apologized and repeated the same made up code after merely changing the name of the package.</div><br/><div id="40519629" class="c"><input type="checkbox" id="c-40519629" checked=""/><div class="controls bullet"><span class="by">cco</span><span>|</span><a href="#40512636">root</a><span>|</span><a href="#40519247">parent</a><span>|</span><a href="#40512683">next</a><span>|</span><label class="collapse" for="c-40519629">[-]</label><label class="expand" for="c-40519629">[1 more]</label></div><br/><div class="children"><div class="content">This is actually why we (Stytch) haven&#x27;t rolled out any of these &quot;chatbots for code&quot;.<p>We have a big list of example questions we get from devs trying us out and we&#x27;ve tested several home grown and third party providers and thus far haven&#x27;t seen anything good enough that we&#x27;d put into production.<p>Thanks for testing this out for us! I&#x27;ll cross it off our list :)</div><br/></div></div></div></div><div id="40512683" class="c"><input type="checkbox" id="c-40512683" checked=""/><div class="controls bullet"><span class="by">ramon156</span><span>|</span><a href="#40512636">parent</a><span>|</span><a href="#40519247">prev</a><span>|</span><a href="#40515823">next</a><span>|</span><label class="collapse" for="c-40512683">[-]</label><label class="expand" for="c-40512683">[5 more]</label></div><br/><div class="children"><div class="content">Knowing the training data GH has I doubt it&#x27;s comparable, then again I don&#x27;t have the benchmarks</div><br/><div id="40512746" class="c"><input type="checkbox" id="c-40512746" checked=""/><div class="controls bullet"><span class="by">ramon156</span><span>|</span><a href="#40512636">root</a><span>|</span><a href="#40512683">parent</a><span>|</span><a href="#40512763">next</a><span>|</span><label class="collapse" for="c-40512746">[-]</label><label class="expand" for="c-40512746">[1 more]</label></div><br/><div class="children"><div class="content">After typing this I tried the live chat out and it honestly seems a lot more promising than current GH Copilot, very nice!</div><br/></div></div><div id="40512763" class="c"><input type="checkbox" id="c-40512763" checked=""/><div class="controls bullet"><span class="by">ssgodderidge</span><span>|</span><a href="#40512636">root</a><span>|</span><a href="#40512683">parent</a><span>|</span><a href="#40512746">prev</a><span>|</span><a href="#40515823">next</a><span>|</span><label class="collapse" for="c-40512763">[-]</label><label class="expand" for="c-40512763">[3 more]</label></div><br/><div class="children"><div class="content">Are you saying GH has more than Codestral and therefore GH has a better model? Or that Codestral would be better because Codestral is not littered with &quot;bad&quot; code?</div><br/><div id="40512833" class="c"><input type="checkbox" id="c-40512833" checked=""/><div class="controls bullet"><span class="by">nkozyra</span><span>|</span><a href="#40512636">root</a><span>|</span><a href="#40512763">parent</a><span>|</span><a href="#40515823">next</a><span>|</span><label class="collapse" for="c-40512833">[-]</label><label class="expand" for="c-40512833">[2 more]</label></div><br/><div class="children"><div class="content">Bad code is obviously very subjective, but I would wager that GH places a much higher value on feedback mechanisms like stars, issues, PRs, velocity, etc. Their ubiquity likely allows them to automatically cherry-pick less &quot;bad code.&quot;</div><br/><div id="40515785" class="c"><input type="checkbox" id="c-40515785" checked=""/><div class="controls bullet"><span class="by">nicce</span><span>|</span><a href="#40512636">root</a><span>|</span><a href="#40512833">parent</a><span>|</span><a href="#40515823">next</a><span>|</span><label class="collapse" for="c-40515785">[-]</label><label class="expand" for="c-40515785">[1 more]</label></div><br/><div class="children"><div class="content">Nothing prevents Mistral do the same if they want to. Issues and and PRs are public information, exposed by APIs, and not that much rate limited.</div><br/></div></div></div></div></div></div></div></div><div id="40515823" class="c"><input type="checkbox" id="c-40515823" checked=""/><div class="controls bullet"><span class="by">localfirst</span><span>|</span><a href="#40512636">parent</a><span>|</span><a href="#40512683">prev</a><span>|</span><a href="#40512915">next</a><span>|</span><label class="collapse" for="c-40515823">[-]</label><label class="expand" for="c-40515823">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s miles better.<p>In fact I stopped using expensive GPT-4<p>Codestral just works, its quick, output is accurate its kinda scary.</div><br/></div></div><div id="40512915" class="c"><input type="checkbox" id="c-40512915" checked=""/><div class="controls bullet"><span class="by">rohansood15</span><span>|</span><a href="#40512636">parent</a><span>|</span><a href="#40515823">prev</a><span>|</span><a href="#40514337">next</a><span>|</span><label class="collapse" for="c-40512915">[-]</label><label class="expand" for="c-40512915">[4 more]</label></div><br/><div class="children"><div class="content">Copilot primarily uses GPT-3.5, which is outclassed by Llama3-70B. And this model claims to be slightly better than Llama3-70B.<p>Edit: For those who don&#x27;t believe me, <a href="https:&#x2F;&#x2F;github.com&#x2F;microsoft&#x2F;vscode-copilot-release&#x2F;issues&#x2F;664">https:&#x2F;&#x2F;github.com&#x2F;microsoft&#x2F;vscode-copilot-release&#x2F;issues&#x2F;6...</a>. Gpt-4 for chat, 3.5 for code.</div><br/><div id="40513189" class="c"><input type="checkbox" id="c-40513189" checked=""/><div class="controls bullet"><span class="by">jasonjmcghee</span><span>|</span><a href="#40512636">root</a><span>|</span><a href="#40512915">parent</a><span>|</span><a href="#40513828">next</a><span>|</span><label class="collapse" for="c-40513189">[-]</label><label class="expand" for="c-40513189">[2 more]</label></div><br/><div class="children"><div class="content">GitHub Copilot uses GPT-3.5?<p>I was under the impression it was a custom codex model with a surrogate local model as per <a href="https:&#x2F;&#x2F;github.blog&#x2F;2023-02-14-github-copilot-now-has-a-better-ai-model-and-new-capabilities&#x2F;" rel="nofollow">https:&#x2F;&#x2F;github.blog&#x2F;2023-02-14-github-copilot-now-has-a-bett...</a><p>When did this change?</div><br/><div id="40513286" class="c"><input type="checkbox" id="c-40513286" checked=""/><div class="controls bullet"><span class="by">Rastonbury</span><span>|</span><a href="#40512636">root</a><span>|</span><a href="#40513189">parent</a><span>|</span><a href="#40513828">next</a><span>|</span><label class="collapse" for="c-40513286">[-]</label><label class="expand" for="c-40513286">[1 more]</label></div><br/><div class="children"><div class="content">When it first launched it, I too didn&#x27;t know they had changed the model from the original codex which came similar time as gpt-3.5</div><br/></div></div></div></div><div id="40513828" class="c"><input type="checkbox" id="c-40513828" checked=""/><div class="controls bullet"><span class="by">jasonjmcghee</span><span>|</span><a href="#40512636">root</a><span>|</span><a href="#40512915">parent</a><span>|</span><a href="#40513189">prev</a><span>|</span><a href="#40514337">next</a><span>|</span><label class="collapse" for="c-40513828">[-]</label><label class="expand" for="c-40513828">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Gpt-4 for chat, 3.5 for code<p>That thread is comparing sidebar chat to inline chat. Doesn&#x27;t discuss code completions afaict.</div><br/></div></div></div></div></div></div><div id="40514337" class="c"><input type="checkbox" id="c-40514337" checked=""/><div class="controls bullet"><span class="by">artninja1988</span><span>|</span><a href="#40512636">prev</a><span>|</span><a href="#40513770">next</a><span>|</span><label class="collapse" for="c-40514337">[-]</label><label class="expand" for="c-40514337">[1 more]</label></div><br/><div class="children"><div class="content">This is a business model I can get behind. The model is under a non-commercial license, but it&#x27;s open weights and they have their official API for it</div><br/></div></div><div id="40513770" class="c"><input type="checkbox" id="c-40513770" checked=""/><div class="controls bullet"><span class="by">esafak</span><span>|</span><a href="#40514337">prev</a><span>|</span><a href="#40512838">next</a><span>|</span><label class="collapse" for="c-40513770">[-]</label><label class="expand" for="c-40513770">[5 more]</label></div><br/><div class="children"><div class="content">Are there any IDE plugins that index your entire code base in order to provide contextual responses AND let you pick between the latest models?<p>If not, consider it a product idea ;)</div><br/><div id="40514211" class="c"><input type="checkbox" id="c-40514211" checked=""/><div class="controls bullet"><span class="by">pmmucsd</span><span>|</span><a href="#40513770">parent</a><span>|</span><a href="#40515292">next</a><span>|</span><label class="collapse" for="c-40514211">[-]</label><label class="expand" for="c-40514211">[1 more]</label></div><br/><div class="children"><div class="content">There are plugins for various IDEs that operate like copilot but let you select model you want to use, just supply your key. CodeGPT for JetBrains&#x2F;Android Studio is pretty good. I think you can even use a model running locally.</div><br/></div></div><div id="40515292" class="c"><input type="checkbox" id="c-40515292" checked=""/><div class="controls bullet"><span class="by">elmariachi</span><span>|</span><a href="#40513770">parent</a><span>|</span><a href="#40514211">prev</a><span>|</span><a href="#40514387">next</a><span>|</span><label class="collapse" for="c-40515292">[-]</label><label class="expand" for="c-40515292">[2 more]</label></div><br/><div class="children"><div class="content">Cody by Sourcegraph allows you to do this. It doesn&#x27;t have Codestral yet but probably will soon.</div><br/><div id="40516864" class="c"><input type="checkbox" id="c-40516864" checked=""/><div class="controls bullet"><span class="by">jdorfman</span><span>|</span><a href="#40513770">root</a><span>|</span><a href="#40515292">parent</a><span>|</span><a href="#40514387">next</a><span>|</span><label class="collapse" for="c-40516864">[-]</label><label class="expand" for="c-40516864">[1 more]</label></div><br/><div class="children"><div class="content">We are working on it.</div><br/></div></div></div></div><div id="40514387" class="c"><input type="checkbox" id="c-40514387" checked=""/><div class="controls bullet"><span class="by">saturatedfat</span><span>|</span><a href="#40513770">parent</a><span>|</span><a href="#40515292">prev</a><span>|</span><a href="#40512838">next</a><span>|</span><label class="collapse" for="c-40514387">[-]</label><label class="expand" for="c-40514387">[1 more]</label></div><br/><div class="children"><div class="content">Supermaven, but you don’t get model choice.</div><br/></div></div></div></div><div id="40512838" class="c"><input type="checkbox" id="c-40512838" checked=""/><div class="controls bullet"><span class="by">bloopernova</span><span>|</span><a href="#40513770">prev</a><span>|</span><a href="#40512889">next</a><span>|</span><label class="collapse" for="c-40512838">[-]</label><label class="expand" for="c-40512838">[2 more]</label></div><br/><div class="children"><div class="content">Does anyone know of a link to a codegen comparison page? In other words, you write your request, and it&#x27;s submitted to multiple codegen engines, so you can compare the output.</div><br/><div id="40512887" class="c"><input type="checkbox" id="c-40512887" checked=""/><div class="controls bullet"><span class="by">rohansood15</span><span>|</span><a href="#40512838">parent</a><span>|</span><a href="#40512889">next</a><span>|</span><label class="collapse" for="c-40512887">[-]</label><label class="expand" for="c-40512887">[1 more]</label></div><br/><div class="children"><div class="content">Not the same, but we evaluated how good LLMs are at fixing code and just posted it on HN: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=40511689">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=40511689</a></div><br/></div></div></div></div><div id="40512889" class="c"><input type="checkbox" id="c-40512889" checked=""/><div class="controls bullet"><span class="by">sashank_1509</span><span>|</span><a href="#40512838">prev</a><span>|</span><a href="#40515780">next</a><span>|</span><label class="collapse" for="c-40512889">[-]</label><label class="expand" for="c-40512889">[4 more]</label></div><br/><div class="children"><div class="content">Seems nice but some preliminary testing against GPT-4o shows it’s lacking a bit. It does a pretty good job for easy questions though</div><br/><div id="40513154" class="c"><input type="checkbox" id="c-40513154" checked=""/><div class="controls bullet"><span class="by">jasonjmcghee</span><span>|</span><a href="#40512889">parent</a><span>|</span><a href="#40515857">next</a><span>|</span><label class="collapse" for="c-40513154">[-]</label><label class="expand" for="c-40513154">[2 more]</label></div><br/><div class="children"><div class="content">GPT-4o is really oddly hit or miss for code.<p>Sometimes it outperforms GPT-4 in quality by a fair amount, and other times it starts repeating itself. Duplicating function definitions, even misremembering what things are named.<p>It seems to have to do with length. If the output exceeds a few thousand tokens, it seems to experience some pretty bad failure modes.</div><br/><div id="40514849" class="c"><input type="checkbox" id="c-40514849" checked=""/><div class="controls bullet"><span class="by">afro88</span><span>|</span><a href="#40512889">root</a><span>|</span><a href="#40513154">parent</a><span>|</span><a href="#40515857">next</a><span>|</span><label class="collapse" for="c-40514849">[-]</label><label class="expand" for="c-40514849">[1 more]</label></div><br/><div class="children"><div class="content">4o can only output 4k tokens. So the training to complete an answer within 4k tokens is probably kicking in and nerfing the quality</div><br/></div></div></div></div><div id="40515857" class="c"><input type="checkbox" id="c-40515857" checked=""/><div class="controls bullet"><span class="by">localfirst</span><span>|</span><a href="#40512889">parent</a><span>|</span><a href="#40513154">prev</a><span>|</span><a href="#40515780">next</a><span>|</span><label class="collapse" for="c-40515857">[-]</label><label class="expand" for="c-40515857">[1 more]</label></div><br/><div class="children"><div class="content">personally this has performed consistently and just as good if not better than GPT-4<p>what strikes me is the consistency and lack of hallucination you got in GPT4o making in unusuable for any reliable code gen</div><br/></div></div></div></div><div id="40515780" class="c"><input type="checkbox" id="c-40515780" checked=""/><div class="controls bullet"><span class="by">mirekrusin</span><span>|</span><a href="#40512889">prev</a><span>|</span><a href="#40513748">next</a><span>|</span><label class="collapse" for="c-40515780">[-]</label><label class="expand" for="c-40515780">[1 more]</label></div><br/><div class="children"><div class="content">Fifty shades of &quot;open&quot;.</div><br/></div></div><div id="40513748" class="c"><input type="checkbox" id="c-40513748" checked=""/><div class="controls bullet"><span class="by">isoprophlex</span><span>|</span><a href="#40515780">prev</a><span>|</span><a href="#40513297">next</a><span>|</span><label class="collapse" for="c-40513748">[-]</label><label class="expand" for="c-40513748">[2 more]</label></div><br/><div class="children"><div class="content">Does it do SQL, and if so, which dialects? I am having a hard time figuring out what it is actually trained on</div><br/><div id="40513883" class="c"><input type="checkbox" id="c-40513883" checked=""/><div class="controls bullet"><span class="by">sebzim4500</span><span>|</span><a href="#40513748">parent</a><span>|</span><a href="#40513297">next</a><span>|</span><label class="collapse" for="c-40513883">[-]</label><label class="expand" for="c-40513883">[1 more]</label></div><br/><div class="children"><div class="content">They claim good results in a SQL benchmark but they don&#x27;t specify what dialects it knows.</div><br/></div></div></div></div><div id="40513297" class="c"><input type="checkbox" id="c-40513297" checked=""/><div class="controls bullet"><span class="by">jstummbillig</span><span>|</span><a href="#40513748">prev</a><span>|</span><a href="#40515814">next</a><span>|</span><label class="collapse" for="c-40513297">[-]</label><label class="expand" for="c-40513297">[1 more]</label></div><br/><div class="children"><div class="content">How I interact with new model reports at this point: Open the page, ctrl + f, &quot;gpt-4&quot; and skip the rest.</div><br/></div></div><div id="40515814" class="c"><input type="checkbox" id="c-40515814" checked=""/><div class="controls bullet"><span class="by">isaacrolandson</span><span>|</span><a href="#40513297">prev</a><span>|</span><a href="#40514504">next</a><span>|</span><label class="collapse" for="c-40515814">[-]</label><label class="expand" for="c-40515814">[2 more]</label></div><br/><div class="children"><div class="content">Will this run on an M3 48GB?</div><br/><div id="40516158" class="c"><input type="checkbox" id="c-40516158" checked=""/><div class="controls bullet"><span class="by">piskov</span><span>|</span><a href="#40515814">parent</a><span>|</span><a href="#40514504">next</a><span>|</span><label class="collapse" for="c-40516158">[-]</label><label class="expand" for="c-40516158">[1 more]</label></div><br/><div class="children"><div class="content">You’ll need 44GB just for the weights<p>By default only 75% of unified memory is available to GPU if you have &gt;36GB. So with 48 total only 36 is available for GPU with is lower than 44.<p>tldr; without quantization you will not be able to run it.</div><br/></div></div></div></div><div id="40514504" class="c"><input type="checkbox" id="c-40514504" checked=""/><div class="controls bullet"><span class="by">YetAnotherNick</span><span>|</span><a href="#40515814">prev</a><span>|</span><a href="#40512936">next</a><span>|</span><label class="collapse" for="c-40514504">[-]</label><label class="expand" for="c-40514504">[1 more]</label></div><br/><div class="children"><div class="content">What&#x27;s the business model for semi open source models like these? Is it just because they can&#x27;t be fully closed as they have to then compare with OpenAI. Who would pay for these model if better is available for cheaper from Anthropic or Google.</div><br/></div></div><div id="40512936" class="c"><input type="checkbox" id="c-40512936" checked=""/><div class="controls bullet"><span class="by">colesantiago</span><span>|</span><a href="#40514504">prev</a><span>|</span><a href="#40517175">next</a><span>|</span><label class="collapse" for="c-40512936">[-]</label><label class="expand" for="c-40512936">[17 more]</label></div><br/><div class="children"><div class="content">I&#x27;m so happy now LLMs are democratising access to programming, especially open models like what Meta with Llama and Mistral is doing with Codestral are doing.<p>The abundance of programming is going to allow almost everyone to become a great programmer.<p>This is so exciting to see and each day programming is becoming a solved problem so we can focus on other things.</div><br/><div id="40513529" class="c"><input type="checkbox" id="c-40513529" checked=""/><div class="controls bullet"><span class="by">maskil</span><span>|</span><a href="#40512936">parent</a><span>|</span><a href="#40513273">next</a><span>|</span><label class="collapse" for="c-40513529">[-]</label><label class="expand" for="c-40513529">[4 more]</label></div><br/><div class="children"><div class="content">I would argue the opposite is true.<p>My experience with coding with LLMs is that the only thing it&#x27;s really good at is generating boilerplate that it has more-or-less seen before (essentially a library, even if is somewhat adapted), however it is incapable of the creative thinking that developers regularly need to engage in when architecting a solution for their use case.</div><br/><div id="40514314" class="c"><input type="checkbox" id="c-40514314" checked=""/><div class="controls bullet"><span class="by">Kiro</span><span>|</span><a href="#40512936">root</a><span>|</span><a href="#40513529">parent</a><span>|</span><a href="#40513273">next</a><span>|</span><label class="collapse" for="c-40514314">[-]</label><label class="expand" for="c-40514314">[3 more]</label></div><br/><div class="children"><div class="content">My experience is the opposite. When I started using Copilot I thought it would only be good at standard boilerplate but I&#x27;m constantly surprised how well it understands my completely convoluted legacy architecture that barely I understand myself even though I&#x27;m the only contributor.</div><br/><div id="40519190" class="c"><input type="checkbox" id="c-40519190" checked=""/><div class="controls bullet"><span class="by">maskil</span><span>|</span><a href="#40512936">root</a><span>|</span><a href="#40514314">parent</a><span>|</span><a href="#40515903">next</a><span>|</span><label class="collapse" for="c-40519190">[-]</label><label class="expand" for="c-40519190">[1 more]</label></div><br/><div class="children"><div class="content">Understanding existing code is in its wheelhouse (provided the infrastructure feeding the existing code to the prompt is working well), but I believe if you  examine the totality of work a human programmer is involved in, an LLM is woefully behind in many areas (gathering proper requirements, potentially iterating&#x2F;pushing back on requirements, architecting a solution on a macro level, other gaps an LLm cannot fill).</div><br/></div></div><div id="40515903" class="c"><input type="checkbox" id="c-40515903" checked=""/><div class="controls bullet"><span class="by">localfirst</span><span>|</span><a href="#40512936">root</a><span>|</span><a href="#40514314">parent</a><span>|</span><a href="#40519190">prev</a><span>|</span><a href="#40513273">next</a><span>|</span><label class="collapse" for="c-40515903">[-]</label><label class="expand" for="c-40515903">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve been on both sides of the fence here.<p>Parents problem I experienced -&gt; it gets &quot;stuck&quot; and its limitation of learning loop (humans are always asking why it gets stuck and how to get unstuck), LLMs just power through without understanding what &quot;stuck&quot; is.<p>For explaining existing corpus, algorithm it does a fantastic job.<p>So likely we will see significant wage garnishing in &quot;agency&#x2F;b2b enterprise&quot; shops.</div><br/></div></div></div></div></div></div><div id="40513273" class="c"><input type="checkbox" id="c-40513273" checked=""/><div class="controls bullet"><span class="by">smokel</span><span>|</span><a href="#40512936">parent</a><span>|</span><a href="#40513529">prev</a><span>|</span><a href="#40515167">next</a><span>|</span><label class="collapse" for="c-40513273">[-]</label><label class="expand" for="c-40513273">[3 more]</label></div><br/><div class="children"><div class="content">In my experience these tools amplify the quality of a programmer.<p>I have seen good programmers dramatically increase their productivity, but I&#x27;ve also seen others copy-pasting for loops inside other for loops where one loop would definitely suffice.  We&#x27;re not quite there yet.</div><br/><div id="40515034" class="c"><input type="checkbox" id="c-40515034" checked=""/><div class="controls bullet"><span class="by">bubbleRefuge</span><span>|</span><a href="#40512936">root</a><span>|</span><a href="#40513273">parent</a><span>|</span><a href="#40513519">next</a><span>|</span><label class="collapse" for="c-40515034">[-]</label><label class="expand" for="c-40515034">[1 more]</label></div><br/><div class="children"><div class="content">Absolutely it amplifies.  Complex and esoteric configuration of frameworks, for example, entails so much reading and Googling and can be very time consuming without AI. AI can help to bring custom software to the markets that could not otherwise afford to pay for it.</div><br/></div></div><div id="40513519" class="c"><input type="checkbox" id="c-40513519" checked=""/><div class="controls bullet"><span class="by">croes</span><span>|</span><a href="#40512936">root</a><span>|</span><a href="#40513273">parent</a><span>|</span><a href="#40515034">prev</a><span>|</span><a href="#40515167">next</a><span>|</span><label class="collapse" for="c-40513519">[-]</label><label class="expand" for="c-40513519">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m curious for the long-term effect.<p>I observe a certain laziness in myself when it comes to certain problems. It&#x27;s easier to ask a LLM and debug provided code, but I ask myself if I&#x27;m losing some problem solving capabilities in the long run because of this.<p>Similar to the loss of speed in doing mental arithmetic because of calculators on the smartphone.</div><br/></div></div></div></div><div id="40515167" class="c"><input type="checkbox" id="c-40515167" checked=""/><div class="controls bullet"><span class="by">huygens6363</span><span>|</span><a href="#40512936">parent</a><span>|</span><a href="#40513273">prev</a><span>|</span><a href="#40513411">next</a><span>|</span><label class="collapse" for="c-40515167">[-]</label><label class="expand" for="c-40515167">[1 more]</label></div><br/><div class="children"><div class="content">This enables everyone to be great programmers like how easily available power tools enables everyone to be a great carpenter and general craftsman.<p>You’ll get a lot of shitty stuff and the profession will get hollowed out losing attraction of the smart people. We’ll be left with low-quality, disposable bullshit while wondering where all the programmers went.</div><br/></div></div><div id="40513411" class="c"><input type="checkbox" id="c-40513411" checked=""/><div class="controls bullet"><span class="by">croes</span><span>|</span><a href="#40512936">parent</a><span>|</span><a href="#40515167">prev</a><span>|</span><a href="#40513245">next</a><span>|</span><label class="collapse" for="c-40513411">[-]</label><label class="expand" for="c-40513411">[1 more]</label></div><br/><div class="children"><div class="content">&gt;The abundance of programming is going to allow almost everyone to become a great programmer.<p>How do you become a great programmer if you don&#x27;t really program?</div><br/></div></div><div id="40513245" class="c"><input type="checkbox" id="c-40513245" checked=""/><div class="controls bullet"><span class="by">skydhash</span><span>|</span><a href="#40512936">parent</a><span>|</span><a href="#40513411">prev</a><span>|</span><a href="#40513304">next</a><span>|</span><label class="collapse" for="c-40513245">[-]</label><label class="expand" for="c-40513245">[1 more]</label></div><br/><div class="children"><div class="content">Shadow libraries did more to democratize anything than LLMs. And following a book like Elixir in Action (Manning) will get you there faster than chatting with LLMs or copilot generating code for you.</div><br/></div></div><div id="40513304" class="c"><input type="checkbox" id="c-40513304" checked=""/><div class="controls bullet"><span class="by">icedchai</span><span>|</span><a href="#40512936">parent</a><span>|</span><a href="#40513245">prev</a><span>|</span><a href="#40517175">next</a><span>|</span><label class="collapse" for="c-40513304">[-]</label><label class="expand" for="c-40513304">[6 more]</label></div><br/><div class="children"><div class="content">I&#x27;m skeptical. I&#x27;ve run into people who used LLMs to code, then can&#x27;t debug it without someone else&#x27;s help. It may get you 80% there though.</div><br/><div id="40513442" class="c"><input type="checkbox" id="c-40513442" checked=""/><div class="controls bullet"><span class="by">whiplash451</span><span>|</span><a href="#40512936">root</a><span>|</span><a href="#40513304">parent</a><span>|</span><a href="#40517700">next</a><span>|</span><label class="collapse" for="c-40513442">[-]</label><label class="expand" for="c-40513442">[3 more]</label></div><br/><div class="children"><div class="content">It does not get you 80% there if it achieves what you described.  It rather gets you 100% into trouble.</div><br/><div id="40513546" class="c"><input type="checkbox" id="c-40513546" checked=""/><div class="controls bullet"><span class="by">croes</span><span>|</span><a href="#40512936">root</a><span>|</span><a href="#40513442">parent</a><span>|</span><a href="#40517341">next</a><span>|</span><label class="collapse" for="c-40513546">[-]</label><label class="expand" for="c-40513546">[1 more]</label></div><br/><div class="children"><div class="content">Programmer view vs management view.<p>100% of nothing vs 80% of enough.<p>That&#x27;s the risk of AI.
Not that AI outperforms humans already but that managers believe it does. That and that code writing is the main work of programmers.</div><br/></div></div><div id="40517341" class="c"><input type="checkbox" id="c-40517341" checked=""/><div class="controls bullet"><span class="by">icedchai</span><span>|</span><a href="#40512936">root</a><span>|</span><a href="#40513442">parent</a><span>|</span><a href="#40513546">prev</a><span>|</span><a href="#40517700">next</a><span>|</span><label class="collapse" for="c-40517341">[-]</label><label class="expand" for="c-40517341">[1 more]</label></div><br/><div class="children"><div class="content">I agree with you. I&#x27;ve had to debug some of that junk.</div><br/></div></div></div></div><div id="40517700" class="c"><input type="checkbox" id="c-40517700" checked=""/><div class="controls bullet"><span class="by">Cyphase</span><span>|</span><a href="#40512936">root</a><span>|</span><a href="#40513304">parent</a><span>|</span><a href="#40513442">prev</a><span>|</span><a href="#40517175">next</a><span>|</span><label class="collapse" for="c-40517700">[-]</label><label class="expand" for="c-40517700">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve run into working programmers who were bad at debugging before LLMs existed.</div><br/><div id="40518687" class="c"><input type="checkbox" id="c-40518687" checked=""/><div class="controls bullet"><span class="by">icedchai</span><span>|</span><a href="#40512936">root</a><span>|</span><a href="#40517700">parent</a><span>|</span><a href="#40517175">next</a><span>|</span><label class="collapse" for="c-40518687">[-]</label><label class="expand" for="c-40518687">[1 more]</label></div><br/><div class="children"><div class="content">Absolutely. LLMs aren&#x27;t going to replace good developers. The bad ones, maybe.</div><br/></div></div></div></div></div></div></div></div><div id="40517175" class="c"><input type="checkbox" id="c-40517175" checked=""/><div class="controls bullet"><span class="by">gavin_gee</span><span>|</span><a href="#40512936">prev</a><span>|</span><a href="#40513164">next</a><span>|</span><label class="collapse" for="c-40517175">[-]</label><label class="expand" for="c-40517175">[1 more]</label></div><br/><div class="children"><div class="content">what the heck is this for, if you can&#x27;t use it for commercial work?</div><br/></div></div></div></div></div></div></div></body></html>